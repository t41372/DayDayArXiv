{
  "date": "2025-01-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-14 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、视频理解与生成、LLM 在科学和医疗中的应用，以及强化学习和知识图谱等领域，其中 Google DeepMind 的物理原理测试（第8篇）和 LLM 安全漏洞研究（第6篇）特别引人注目，展示了 AI 的潜力与风险；这些论文强调了模型的鲁棒性、解释性和实际应用，涉及知名学者如 Google DeepMind 团队。\n\n### 重点论文讨论\n我们先聊聊那些重要、话题度高或有潜在影响的论文，尤其是与 LLM、AI 安全和视频处理相关的。\n\n- **LLM 安全与漏洞（第6、22、49篇）**  \n  - *Playing Devil's Advocate: Unmasking Toxicity and Vulnerabilities in Large Vision-Language Models* (英文标题)：这篇论文系统分析了开源 LVLMs（如 LLaVA 和 Qwen）的漏洞，使用对抗性提示模拟社交操纵，发现模型易产生毒性和侮辱性响应（平均率达16.13%和9.75%），并提出 AdaLogAdjustment 方法缓解偏差，强调了 LLM 在视觉语言任务中的安全机制需求。  \n  - *HALoGEN: Fantastic LLM Hallucinations and Where to Find Them* (英文标题)：作者探讨了 LLM 在多领域（如编程和总结）中的幻觉问题，使用 TriProTesting 检测显性和隐性偏差，并构建基准数据集，揭示幻觉率高达86%，为 LLM 鲁棒性研究提供新工具。  \n  - *In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR* (英文标题)：Buehler 提出 Graph-PReFLexOR 框架，利用图结构和 LLM 进行科学假设生成和跨领域知识扩展，显著提升模型的推理深度，适用于材料设计等领域。\n\n这些论文突出了 LLM 的安全风险和扩展潜力，第6篇尤其值得关注，因为它直接涉及实际部署中的伦理问题。\n\n- **视频理解与生成（第4、8、20、41篇）**  \n  - *Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time* (英文标题)：Mihai Masala 和 Marius Leordeanu 开发了一种基于事件图的零样本视频描述方法，使用 Transformer 结合视觉和语言模型，生成更连贯的自然语言描述，并在标准指标（如 Bleu 和 ROUGE）上表现出色。  \n  - *Do generative video models understand physical principles?* (英文标题)：Google DeepMind 团队构建 Physics-IQ 基准，测试视频生成模型（如 Sora）对物理原理的理解，发现模型在流体动力学等任务上表现有限，但某些场景已可行，强调视觉真实性不等同于物理理解。  \n  - *Diffusion Adversarial Post-Training for One-Step Video Generation* (英文标题)：Shanchuan Lin 等人提出 Adversarial Post-Training (APT) 方法，优化扩散模型实现单步视频生成，支持 1280x720 分辨率实时输出，显著提升生成效率。  \n  - *LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and Dual-Process Thinking* (英文标题)：Yukai Ma 团队设计 LeapVAD 系统，使用认知感知和双过程思考模拟人类驾驶，显著提升自动驾驶在复杂场景下的性能，实验在 CARLA 和 DriveArena 上表现出色。\n\n这些工作推动了视频 AI 的边界，第8篇由 Google DeepMind 发布，话题性强，展示了 AI 在物理模拟中的局限。\n\n- **医疗与生物应用（第19、37、89篇）**  \n  - *ADAM: An AI Reasoning and Bioinformatics Model for Alzheimer's Disease Detection and Microbiome-Clinical Data Integration* (英文标题)：Ziyuan Huang 等人开发 ADAM 框架，使用多代理 LLM 整合微生物组和临床数据，提高阿尔茨海默病检测的 F1 分数，展现了 AI 在生物医学的多模态数据分析潜力。  \n  - *InstructCell: a Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following* (英文标题)：Yin Fang 团队提出 InstructCell，使用多模态 LLM 进行单细胞分析，支持细胞类型注释和药物敏感性预测，实验显示在单细胞任务中超越现有模型。\n\n这些论文在医疗 AI 领域有实际影响，第19篇强调了数据整合的鲁棒性。\n\n### 其他论文快速概述\n剩余论文覆盖了强化学习、图像处理和知识图谱等领域，但许多主题较窄或技术性强，我们快速掠过：\n\n- **强化学习与优化（第5、13、30、44、50、54、69、105等）**：如 *Active Sampling for Node Attribute Completion on Graphs* (英文标题)，提出 ATS 算法提升图节点属性补全；*CVaR-Based Variational Quantum Optimization* (英文标题) 使用量子框架优化车辆网络，均在特定任务中表现出色，但应用较专一。  \n- **图像与点云处理（第3、7、14、15、24、29、34、39等）**：例如 *Detecting Contextual Anomalies by Discovering Consistent Spatial Regions* (英文标题)，使用高斯混合模型实现视频异常检测；*BiDepth Multimodal Neural Network* (英文标题) 改善时空预测，准确率提升15%。这些贡献实用，但影响力有限。  \n- **知识图谱与 LLM 扩展（第10、21、25、27、46、51、57、58、61、66、68、76、77、83、90、91、94、95、96、97、98、99、100、101、102、103、104、106、107、108、109、110、111、112、113、114、115、116、117、118、119、120等）**：如 *Modeling Discrimination with Causal Abstraction* (英文标题)，探讨因果建模在偏见检测中的应用；*Polynomial Threshold Functions of Bounded Tree-Width* (英文标题) 分析布尔函数在 XAI 中的作用。这些论文技术深，但较学术化，不如 LLM 安全主题热门。  \n- **其他领域（第1、2、9、11、12、16、17、18、23、26、28、31、32、33、35、36、38、40、42、43、45、47、48、52、53、55、56、59、60、62、63、64、65、67、70、71、72、73、74、75、78、79、80、81、82、84、85、86、87、88、89、92、93）**：如 *Quantifying the Importance of Data Alignment in Downstream Model Performance* (英文标题)，强调数据对齐在 LLM 训练中的作用；*Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition* (英文标题)，比较多种模型在 HAR 中的性能。这些快速提过，聚焦核心发现如数据对齐影响模型性能。\n\n总之，今天的论文展示了 AI 在安全、视频和医疗领域的进展，但也提醒我们模型的局限性。感兴趣的读者可关注 LLM 相关主题！",
  "papers": [
    {
      "arxiv_id": "2501.08496v2",
      "title": "Quantifying the Importance of Data Alignment in Downstream Model Performance",
      "title_zh": "量化数据对齐在下游模型性能中的重要性",
      "authors": [
        "Krrish Chawla",
        "Aryan Sahai",
        "Mario DePavia",
        "Sudharsan Sundar",
        "Brando Miranda"
      ],
      "abstract": "Contrary to the conventional emphasis on dataset size, we explore the role of\ndata alignment -- an often overlooked aspect of data quality -- in training\ncapable Large Language Models (LLMs). To do so, we use the Task2Vec-based\nalignment coefficient, a quantitative measure of the similarity between two\ndatasets, to quantify the impact of alignment between training data and\nevaluation data on downstream performance. In particular, we conduct controlled\n\\textit{interventional} experiments for two settings: 1. the impact of\nincreased alignment coefficients between various pre-training (pt) against\nevaluation datasets, and 2. the impact of increased alignment coefficients\nbetween domain specific fine-tuning (ft) against domain specific evaluation.\nThe domain specific task we explore is Autoformalization -- the machine\ntranslation task between natural language and code for formal verification. In\nboth settings, we find a strong, predictable negative correlation between the\nalignment coefficient of a model's training and evaluation data and the model's\nloss/perplexity on the respective downstream task. These findings suggest a\nre-evaluation of LLM training approaches, demonstrating the relevance of data\nalignment compared to data quantity, especially in specialized downstream tasks\nsuch as Autoformalization.",
      "tldr_zh": "本研究强调数据对齐（data alignment）在训练 Large Language Models (LLMs) 中的重要性，而不是传统上关注的数据集大小。通过 Task2Vec-based alignment coefficient 量化训练数据与评估数据之间的相似度，作者进行了控制实验，探讨了预训练（pre-training）数据集与评估数据集对齐系数增加的影响，以及领域特定微调（fine-tuning）数据集在 Autoformalization 任务中的效果。结果显示，在两种设置中，alignment coefficient 与模型的损失/perplexity 存在强烈的负相关关系，表明数据对齐对下游性能的影响远大于数据量。研究建议重新评估 LLM 训练策略，尤其在专业任务如 Autoformalization 中优先考虑数据对齐。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08496v2",
      "published_date": "2025-01-14 23:59:23 UTC",
      "updated_date": "2025-01-21 01:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:16:36.614818"
    },
    {
      "arxiv_id": "2501.08471v1",
      "title": "Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Md Meem Hossain",
        "The Anh Han",
        "Safina Showkat Ara",
        "Zia Ush Shamszaman"
      ],
      "abstract": "Human Activity Recognition (HAR) has gained significant importance with the\ngrowing use of sensor-equipped devices and large datasets. This paper evaluates\nthe performance of three categories of models : classical machine learning,\ndeep learning architectures, and Restricted Boltzmann Machines (RBMs) using\nfive key benchmark datasets of HAR (UCI-HAR, OPPORTUNITY, PAMAP2, WISDM, and\nBerkeley MHAD). We assess various models, including Decision Trees, Random\nForests, Convolutional Neural Networks (CNN), and Deep Belief Networks (DBNs),\nusing metrics such as accuracy, precision, recall, and F1-score for a\ncomprehensive comparison. The results show that CNN models offer superior\nperformance across all datasets, especially on the Berkeley MHAD. Classical\nmodels like Random Forest do well on smaller datasets but face challenges with\nlarger, more complex data. RBM-based models also show notable potential,\nparticularly for feature learning. This paper offers a detailed comparison to\nhelp researchers choose the most suitable model for HAR tasks.",
      "tldr_zh": "本论文对 Human Activity Recognition (HAR) 中的经典机器学习、深度学习和 Restricted Boltzmann Machines (RBMs) 模型进行了基准测试，使用了 UCI-HAR、OPPORTUNITY、PAMAP2、WISDM 和 Berkeley MHAD 等五个关键数据集。评估涉及 Decision Trees、Random Forests、Convolutional Neural Networks (CNN) 和 Deep Belief Networks (DBNs) 等模型，并采用 accuracy、precision、recall 和 F1-score 等指标进行全面比较。结果表明，CNN 模型在所有数据集上表现出色，尤其在 Berkeley MHAD 上；Random Forests 在较小数据集上表现良好，但在大规模复杂数据上存在挑战；RBM-based 模型在特征学习方面显示出显著潜力。该研究为研究者选择合适的 HAR 模型提供了宝贵参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T05",
        "I.2.1"
      ],
      "primary_category": "cs.CV",
      "comment": "48 pages, 21 Figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08471v1",
      "published_date": "2025-01-14 22:36:11 UTC",
      "updated_date": "2025-01-14 22:36:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:16:50.274552"
    },
    {
      "arxiv_id": "2501.08470v1",
      "title": "Detecting Contextual Anomalies by Discovering Consistent Spatial Regions",
      "title_zh": "通过发现一致的空间区域检测上下文异常",
      "authors": [
        "Zhengye Yang",
        "Richard J. Radke"
      ],
      "abstract": "We describe a method for modeling spatial context to enable video anomaly\ndetection. The main idea is to discover regions that share similar object-level\nactivities by clustering joint object attributes using Gaussian mixture models.\nWe demonstrate that this straightforward approach, using orders of magnitude\nfewer parameters than competing models, achieves state-of-the-art performance\nin the challenging spatial-context-dependent Street Scene dataset. As a side\nbenefit, the high-resolution discovered regions learned by the model also\nprovide explainable normalcy maps for human operators without the need for any\npre-trained segmentation model.",
      "tldr_zh": "本研究提出了一种通过发现一致空间区域的方法来检测视频中的上下文异常，主要利用高斯混合模型(Gaussian mixture models)对联合对象属性进行聚类，从而识别共享类似对象级活动的区域。该方法在参数数量远少于竞争模型的情况下，在具有挑战性的Street Scene数据集上实现了state-of-the-art性能，显著提升了异常检测的准确性。作为额外优势，该模型生成的高分辨率区域可提供可解释的normalcy maps，供人类操作员使用，而无需预训练的分割模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08470v1",
      "published_date": "2025-01-14 22:33:07 UTC",
      "updated_date": "2025-01-14 22:33:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:16:59.446785"
    },
    {
      "arxiv_id": "2501.08460v1",
      "title": "Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time",
      "title_zh": "翻译失败",
      "authors": [
        "Mihai Masala",
        "Marius Leordeanu"
      ],
      "abstract": "In the current era of Machine Learning, Transformers have become the de facto\napproach across a variety of domains, such as computer vision and natural\nlanguage processing. Transformer-based solutions are the backbone of current\nstate-of-the-art methods for language generation, image and video\nclassification, segmentation, action and object recognition, among many others.\nInterestingly enough, while these state-of-the-art methods produce impressive\nresults in their respective domains, the problem of understanding the\nrelationship between vision and language is still beyond our reach. In this\nwork, we propose a common ground between vision and language based on events in\nspace and time in an explainable and programmatic way, to connect\nlearning-based vision and language state of the art models and provide a\nsolution to the long standing problem of describing videos in natural language.\nWe validate that our algorithmic approach is able to generate coherent, rich\nand relevant textual descriptions on videos collected from a variety of\ndatasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern\nLLM-as-a-Jury approach.",
      "tldr_zh": "本论文旨在解决视觉和语言之间关系的挑战，提出一种基于空间和时间事件图（graphs of events）的零样本（Zero-Shot）和可解释（Explainable）视频描述方法。该方法通过程序化方式连接学习-based 的视觉和语言模型，如 Transformers，实现视频的自然语言描述。实验结果显示，该方法在多种数据集上生成连贯、丰富且相关的文本描述，并通过标准指标（如 Bleu, ROUGE）和现代评估方式（LLM-as-a-Jury）得到验证。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08460v1",
      "published_date": "2025-01-14 22:09:06 UTC",
      "updated_date": "2025-01-14 22:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:17:12.860478"
    },
    {
      "arxiv_id": "2501.08450v1",
      "title": "Active Sampling for Node Attribute Completion on Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Benyuan Liu",
        "Xu Chen",
        "Yanfeng Wang",
        "Ya Zhang",
        "Zhi Cao",
        "Ivor Tsang"
      ],
      "abstract": "Node attribute, a type of crucial information for graph analysis, may be\npartially or completely missing for certain nodes in real world applications.\nRestoring the missing attributes is expected to benefit downstream graph\nlearning. Few attempts have been made on node attribute completion, but a novel\nframework called Structure-attribute Transformer (SAT) was recently proposed by\nusing a decoupled scheme to leverage structures and attributes. SAT ignores the\ndifferences in contributing to the learning schedule and finding a practical\nway to model the different importance of nodes with observed attributes is\nchallenging. This paper proposes a novel AcTive Sampling algorithm (ATS) to\nrestore missing node attributes. The representativeness and uncertainty of each\nnode's information are first measured based on graph structure, representation\nsimilarity and learning bias. To select nodes as train samples in the next\noptimization step, a weighting scheme controlled by Beta distribution is then\nintroduced to linearly combine the two properties. Extensive experiments on\nfour public benchmark datasets and two downstream tasks have shown the\nsuperiority of ATS in node attribute completion.",
      "tldr_zh": "本研究针对图分析中节点属性缺失的问题，提出了一种新型 Active Sampling 算法 (ATS)，旨在通过测量节点的代表性和不确定性（基于图结构、表示相似性和学习偏差）来选择训练样本，并使用受 Beta 分布控制的加权方案进行线性组合，从而有效恢复缺失属性。相比之前的 Structure-attribute Transformer (SAT) 方法，ATS 更注重节点重要性的差异，提升了属性完成的效率和准确性。在四个公共基准数据集和两个下游任务上的广泛实验中，ATS 展示了显著的优越性，证明了其在图学习中的潜力。",
      "categories": [
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08450v1",
      "published_date": "2025-01-14 21:38:23 UTC",
      "updated_date": "2025-01-14 21:38:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:17:23.804275"
    },
    {
      "arxiv_id": "2501.09039v1",
      "title": "Playing Devil's Advocate: Unmasking Toxicity and Vulnerabilities in Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulkadir Erol",
        "Trilok Padhi",
        "Agnik Saha",
        "Ugur Kursuncu",
        "Mehmet Emin Aktas"
      ],
      "abstract": "The rapid advancement of Large Vision-Language Models (LVLMs) has enhanced\ncapabilities offering potential applications from content creation to\nproductivity enhancement. Despite their innovative potential, LVLMs exhibit\nvulnerabilities, especially in generating potentially toxic or unsafe\nresponses. Malicious actors can exploit these vulnerabilities to propagate\ntoxic content in an automated (or semi-) manner, leveraging the susceptibility\nof LVLMs to deception via strategically crafted prompts without fine-tuning or\ncompute-intensive procedures. Despite the red-teaming efforts and inherent\npotential risks associated with the LVLMs, exploring vulnerabilities of LVLMs\nremains nascent and yet to be fully addressed in a systematic manner. This\nstudy systematically examines the vulnerabilities of open-source LVLMs,\nincluding LLaVA, InstructBLIP, Fuyu, and Qwen, using adversarial prompt\nstrategies that simulate real-world social manipulation tactics informed by\nsocial theories. Our findings show that (i) toxicity and insulting are the most\nprevalent behaviors, with the mean rates of 16.13% and 9.75%, respectively;\n(ii) Qwen-VL-Chat, LLaVA-v1.6-Vicuna-7b, and InstructBLIP-Vicuna-7b are the\nmost vulnerable models, exhibiting toxic response rates of 21.50%, 18.30% and\n17.90%, and insulting responses of 13.40%, 11.70% and 10.10%, respectively;\n(iii) prompting strategies incorporating dark humor and multimodal toxic prompt\ncompletion significantly elevated these vulnerabilities. Despite being\nfine-tuned for safety, these models still generate content with varying degrees\nof toxicity when prompted with adversarial inputs, highlighting the urgent need\nfor enhanced safety mechanisms and robust guardrails in LVLM development.",
      "tldr_zh": "本研究系统地探讨了Large Vision-Language Models (LVLMs) 的漏洞，特别是其在面对基于社交理论的对抗性提示策略时生成毒性和不安全响应的风险，测试了开源模型如LLaVA、InstructBLIP、Fuyu和Qwen。结果显示，毒性和侮辱行为是最常见的，平均发生率分别为16.13%和9.75%，其中Qwen-VL-Chat、LLaVA-v1.6-Vicuna-7b和InstructBLIP-Vicuna-7b是最脆弱的模型，毒性响应率高达21.50%、18.30%和17.90%。尽管这些模型已进行安全微调，使用黑暗幽默和多模态毒性提示仍可放大漏洞，研究强调需要开发更强的安全机制和防护措施以防范潜在滥用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09039v1",
      "published_date": "2025-01-14 21:27:40 UTC",
      "updated_date": "2025-01-14 21:27:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:17:36.397710"
    },
    {
      "arxiv_id": "2501.08440v1",
      "title": "FARE: A Deep Learning-Based Framework for Radar-based Face Recognition and Out-of-distribution Detection",
      "title_zh": "FARE：一个基于深度学习的",
      "authors": [
        "Sabri Mustafa Kahya",
        "Boran Hamdi Sivrikaya",
        "Muhammet Sami Yavuz",
        "Eckehard Steinbach"
      ],
      "abstract": "In this work, we propose a novel pipeline for face recognition and\nout-of-distribution (OOD) detection using short-range FMCW radar. The proposed\nsystem utilizes Range-Doppler and micro Range-Doppler Images. The architecture\nfeatures a primary path (PP) responsible for the classification of\nin-distribution (ID) faces, complemented by intermediate paths (IPs) dedicated\nto OOD detection. The network is trained in two stages: first, the PP is\ntrained using triplet loss to optimize ID face classification. In the second\nstage, the PP is frozen, and the IPs-comprising simple linear autoencoder\nnetworks-are trained specifically for OOD detection. Using our dataset\ngenerated with a 60 GHz FMCW radar, our method achieves an ID classification\naccuracy of 99.30% and an OOD detection AUROC of 96.91%.",
      "tldr_zh": "本文提出 FARE 框架，这是一个基于深度学习的系统，用于利用短程 FMCW radar 进行人脸识别和 Out-of-distribution (OOD) 检测，采用 Range-Doppler 和微 Range-Doppler 图像作为输入。框架包括主路径 (PP) 用于 In-distribution (ID) 人脸分类，通过 triplet loss 训练，以及中间路径 (IPs) 由线性自编码器网络组成，用于 OOD 检测，并采用两阶段训练策略优化模型。在使用 60 GHz FMCW radar 生成的数据集上，该方法实现了 99.30% 的 ID 分类准确率和 96.91% 的 OOD 检测 AUROC。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08440v1",
      "published_date": "2025-01-14 21:08:08 UTC",
      "updated_date": "2025-01-14 21:08:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:17:48.727001"
    },
    {
      "arxiv_id": "2501.09038v3",
      "title": "Do generative video models understand physical principles?",
      "title_zh": "生成式视频模型是否理解物理原理？",
      "authors": [
        "Saman Motamed",
        "Laura Culp",
        "Kevin Swersky",
        "Priyank Jaini",
        "Robert Geirhos"
      ],
      "abstract": "AI video generation is undergoing a revolution, with quality and realism\nadvancing rapidly. These advances have led to a passionate scientific debate:\nDo video models learn \"world models\" that discover laws of physics -- or,\nalternatively, are they merely sophisticated pixel predictors that achieve\nvisual realism without understanding the physical principles of reality? We\naddress this question by developing Physics-IQ, a comprehensive benchmark\ndataset that can only be solved by acquiring a deep understanding of various\nphysical principles, like fluid dynamics, optics, solid mechanics, magnetism\nand thermodynamics. We find that across a range of current models (Sora,\nRunway, Pika, Lumiere, Stable Video Diffusion, and VideoPoet), physical\nunderstanding is severely limited, and unrelated to visual realism. At the same\ntime, some test cases can already be successfully solved. This indicates that\nacquiring certain physical principles from observation alone may be possible,\nbut significant challenges remain. While we expect rapid advances ahead, our\nwork demonstrates that visual realism does not imply physical understanding.\nOur project page is at https://physics-iq.github.io; code at\nhttps://github.com/google-deepmind/physics-IQ-benchmark.",
      "tldr_zh": "本研究探讨了生成式视频模型（如 Sora 和 Runway）是否真正理解物理原理，而非仅实现视觉真实性。研究者开发了 Physics-IQ 基准数据集，涵盖流体动力学、光学、固体力学、磁学和热力学等原理，用于评估模型的物理理解能力。测试结果显示，多款模型的物理理解严重不足，与视觉真实性无关，尽管某些测试案例能成功解决，表明部分原理可能通过观察学习，但整体挑战依然巨大。该工作强调，视觉真实并不等同于物理理解，并为未来模型改进提供了重要基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09038v3",
      "published_date": "2025-01-14 20:59:37 UTC",
      "updated_date": "2025-02-27 15:10:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:18:00.115494"
    },
    {
      "arxiv_id": "2501.09765v1",
      "title": "Enhancing the De-identification of Personally Identifiable Information in Educational Data",
      "title_zh": "翻译失败",
      "authors": [
        "Y. Shen",
        "Z. Ji",
        "J. Lin",
        "K. R. Koedginer"
      ],
      "abstract": "Protecting Personally Identifiable Information (PII), such as names, is a\ncritical requirement in learning technologies to safeguard student and teacher\nprivacy and maintain trust. Accurate PII detection is an essential step toward\nanonymizing sensitive information while preserving the utility of educational\ndata. Motivated by recent advancements in artificial intelligence, our study\ninvestigates the GPT-4o-mini model as a cost-effective and efficient solution\nfor PII detection tasks. We explore both prompting and fine-tuning approaches\nand compare GPT-4o-mini's performance against established frameworks, including\nMicrosoft Presidio and Azure AI Language. Our evaluation on two public\ndatasets, CRAPII and TSCC, demonstrates that the fine-tuned GPT-4o-mini model\nachieves superior performance, with a recall of 0.9589 on CRAPII. Additionally,\nfine-tuned GPT-4o-mini significantly improves precision scores (a threefold\nincrease) while reducing computational costs to nearly one-tenth of those\nassociated with Azure AI Language. Furthermore, our bias analysis reveals that\nthe fine-tuned GPT-4o-mini model consistently delivers accurate results across\ndiverse cultural backgrounds and genders. The generalizability analysis using\nthe TSCC dataset further highlights its robustness, achieving a recall of\n0.9895 with minimal additional training data from TSCC. These results emphasize\nthe potential of fine-tuned GPT-4o-mini as an accurate and cost-effective tool\nfor PII detection in educational data. It offers robust privacy protection\nwhile preserving the data's utility for research and pedagogical analysis. Our\ncode is available on GitHub: https://github.com/AnonJD/PrivacyAI",
      "tldr_zh": "该研究旨在增强教育数据中 Personally Identifiable Information (PII) 的去标识化，以保护学生和教师隐私，同时保留数据效用。研究者评估了 GPT-4o-mini 模型，通过提示和微调方法，与 Microsoft Presidio 和 Azure AI Language 进行比较，结果显示微调后的 GPT-4o-mini 在 CRAPII 数据集上 recall 达 0.9589，在 TSCC 数据集上达 0.9895，同时将 precision 提高了三倍，并将计算成本降低到 Azure AI Language 的十分之一。模型还表现出在不同文化背景和性别下的鲁棒性和一致性，证明了其作为一种准确、成本有效的 PII 检测工具的潜力，可用于教育数据的隐私保护和分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 1 figure; This work has been submitted to the IEEE for\n  possible publication",
      "pdf_url": "http://arxiv.org/pdf/2501.09765v1",
      "published_date": "2025-01-14 20:53:38 UTC",
      "updated_date": "2025-01-14 20:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:18:13.533002"
    },
    {
      "arxiv_id": "2501.08429v1",
      "title": "Modeling Discrimination with Causal Abstraction",
      "title_zh": "翻译失败",
      "authors": [
        "Milan Mossé",
        "Kara Schechtman",
        "Frederick Eberhardt",
        "Thomas Icard"
      ],
      "abstract": "A person is directly racially discriminated against only if her race caused\nher worse treatment. This implies that race is an attribute sufficiently\nseparable from other attributes to isolate its causal role. But race is\nembedded in a nexus of social factors that resist isolated treatment. If race\nis socially constructed, in what sense can it cause worse treatment? Some\npropose that the perception of race, rather than race itself, causes worse\ntreatment. Others suggest that since causal models require modularity, i.e. the\nability to isolate causal effects, attempts to causally model discrimination\nare misguided.\n  This paper addresses the problem differently. We introduce a framework for\nreasoning about discrimination, in which race is a high-level abstraction of\nlower-level features. In this framework, race can be modeled as itself causing\nworse treatment. Modularity is ensured by allowing assumptions about social\nconstruction to be precisely and explicitly stated, via an alignment between\nrace and its constituents. Such assumptions can then be subjected to normative\nand empirical challenges, which lead to different views of when discrimination\noccurs. By distinguishing constitutive and causal relations, the abstraction\nframework pinpoints disagreements in the current literature on modeling\ndiscrimination, while preserving a precise causal account of discrimination.",
      "tldr_zh": "这篇论文引入了因果抽象(causal abstraction)框架来建模种族歧视，将种族视为低级特征的高级抽象，从而允许精确地分析种族是否直接导致更差待遇。该框架通过明确陈述社会构建假设并确保模块性(modularity)，例如通过种族与其组成部分的对齐(alignment)，区分了构成关系和因果关系。这种方法解决了现有文献中的分歧，并为歧视提供了一个精确的因果解释。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08429v1",
      "published_date": "2025-01-14 20:42:57 UTC",
      "updated_date": "2025-01-14 20:42:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:18:26.959165"
    },
    {
      "arxiv_id": "2501.08426v1",
      "title": "Causal vs. Anticausal merging of predictors",
      "title_zh": "翻译失败",
      "authors": [
        "Sergio Hernan Garrido Mejia",
        "Patrick Blöbaum",
        "Bernhard Schölkopf",
        "Dominik Janzing"
      ],
      "abstract": "We study the differences arising from merging predictors in the causal and\nanticausal directions using the same data. In particular we study the\nasymmetries that arise in a simple model where we merge the predictors using\none binary variable as target and two continuous variables as predictors. We\nuse Causal Maximum Entropy (CMAXENT) as inductive bias to merge the predictors,\nhowever, we expect similar differences to hold also when we use other merging\nmethods that take into account asymmetries between cause and effect. We show\nthat if we observe all bivariate distributions, the CMAXENT solution reduces to\na logistic regression in the causal direction and Linear Discriminant Analysis\n(LDA) in the anticausal direction. Furthermore, we study how the decision\nboundaries of these two solutions differ whenever we observe only some of the\nbivariate distributions implications for Out-Of-Variable (OOV) generalisation.",
      "tldr_zh": "本研究探讨了在因果（causal）和反因果（anticausal）方向上使用相同数据合并预测器的差异，特别关注一个简单模型，其中一个二元变量作为目标，两个连续变量作为预测器。采用Causal Maximum Entropy (CMAXENT)作为归纳偏置来合并预测器，结果显示在因果方向上归约为Logistic Regression，而在反因果方向上归为Linear Discriminant Analysis (LDA)。此外，论文分析了当只观察部分二元分布时，这两种方法的决策边界差异，并讨论了其对Out-Of-Variable (OOV) generalisation的影响。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2501.08426v1",
      "published_date": "2025-01-14 20:38:15 UTC",
      "updated_date": "2025-01-14 20:38:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:20:38.753703"
    },
    {
      "arxiv_id": "2501.08421v1",
      "title": "SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Anurag Kumar",
        "Rohit Paturi",
        "Amber Afshan",
        "Sundararajan Srinivasan"
      ],
      "abstract": "Speaker Diarization (SD) is a crucial component of modern end-to-end ASR\npipelines. Traditional SD systems, which are typically audio-based and operate\nindependently of ASR, often introduce speaker errors, particularly during\nspeaker transitions and overlapping speech. Recently, language models including\nfine-tuned large language models (LLMs) have shown to be effective as a\nsecond-pass speaker error corrector by leveraging lexical context in the\ntranscribed output. In this work, we introduce a novel acoustic conditioning\napproach to provide more fine-grained information from the acoustic diarizer to\nthe LLM. We also show that a simpler constrained decoding strategy reduces LLM\nhallucinations, while avoiding complicated post-processing. Our approach\nsignificantly reduces the speaker error rates by 24-43% across Fisher,\nCallhome, and RT03-CTS datasets, compared to the first-pass Acoustic SD.",
      "tldr_zh": "本研究提出 SEAL 方法，利用 acoustic-conditioned Large Language Models (LLMs) 来修正 Speaker Diarization (SD) 中的错误问题，尤其是在说话者转换和重叠语音场景。方法通过 acoustic conditioning 提供细粒度的音频信息，并采用简单的 constrained decoding 策略来减少 LLM 的 hallucination，同时避免复杂的后处理。与传统 Acoustic SD 相比，SEAL 在 Fisher、Callhome 和 RT03-CTS 数据集上将说话者错误率降低了 24-43%。这项创新为端到端 ASR 系统提供了更可靠的第二步修正机制。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08421v1",
      "published_date": "2025-01-14 20:24:12 UTC",
      "updated_date": "2025-01-14 20:24:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:18:52.680178"
    },
    {
      "arxiv_id": "2501.08418v2",
      "title": "CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zijiang Yan",
        "Hao Zhou",
        "Jianhua Pei",
        "Aryan Kaushik",
        "Hina Tabassum",
        "Ping Wang"
      ],
      "abstract": "Efficient resource allocation is essential for optimizing various tasks in\nwireless networks, which are usually formulated as generalized assignment\nproblems (GAP). GAP, as a generalized version of the linear sum assignment\nproblem, involves both equality and inequality constraints that add\ncomputational challenges. In this work, we present a novel Conditional Value at\nRisk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address\nGAP in vehicular networks (VNets). Our approach leverages a hybrid\nquantum-classical structure, integrating a tailored cost function that balances\nboth objective and constraint-specific penalties to improve solution quality\nand stability. Using the CVaR-VQE model, we handle the GAP efficiently by\nfocusing optimization on the lower tail of the solution space, enhancing both\nconvergence and resilience on noisy intermediate-scale quantum (NISQ) devices.\nWe apply this framework to a user-association problem in VNets, where our\nmethod achieves 23.5% improvement compared to the deep neural network (DNN)\napproach.",
      "tldr_zh": "本研究针对无线网络中广义分配问题(GAP)的计算挑战，提出了一种基于Conditional Value at Risk (CVaR)的Variational Quantum Eigensolver (VQE)框架，用于优化手off感知车辆网络(VNets)中的用户关联问题。该框架采用混合量子-经典结构，设计了一个定制成本函数来平衡目标优化和约束罚分，从而提升解决方案的质量、稳定性，并通过聚焦于解决方案空间的下尾部改善收敛性和在Noisy Intermediate-Scale Quantum (NISQ)设备上的鲁棒性。在实际应用中，该方法在VNets用户关联任务上比Deep Neural Network (DNN)方法提高了23.5%的性能，为量子优化在网络资源分配中的应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in IEEE International Conference on Communications (ICC\n  2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.08418v2",
      "published_date": "2025-01-14 20:21:06 UTC",
      "updated_date": "2025-02-04 19:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:19:01.942993"
    },
    {
      "arxiv_id": "2501.08415v1",
      "title": "Cross-Modal Transferable Image-to-Video Attack on Video Quality Metrics",
      "title_zh": "翻译失败",
      "authors": [
        "Georgii Gotin",
        "Ekaterina Shumitskaya",
        "Anastasia Antsiferova",
        "Dmitriy Vatolin"
      ],
      "abstract": "Recent studies have revealed that modern image and video quality assessment\n(IQA/VQA) metrics are vulnerable to adversarial attacks. An attacker can\nmanipulate a video through preprocessing to artificially increase its quality\nscore according to a certain metric, despite no actual improvement in visual\nquality. Most of the attacks studied in the literature are white-box attacks,\nwhile black-box attacks in the context of VQA have received less attention.\nMoreover, some research indicates a lack of transferability of adversarial\nexamples generated for one model to another when applied to VQA. In this paper,\nwe propose a cross-modal attack method, IC2VQA, aimed at exploring the\nvulnerabilities of modern VQA models. This approach is motivated by the\nobservation that the low-level feature spaces of images and videos are similar.\nWe investigate the transferability of adversarial perturbations across\ndifferent modalities; specifically, we analyze how adversarial perturbations\ngenerated on a white-box IQA model with an additional CLIP module can\neffectively target a VQA model. The addition of the CLIP module serves as a\nvaluable aid in increasing transferability, as the CLIP model is known for its\neffective capture of low-level semantics. Extensive experiments demonstrate\nthat IC2VQA achieves a high success rate in attacking three black-box VQA\nmodels. We compare our method with existing black-box attack strategies,\nhighlighting its superiority in terms of attack success within the same number\nof iterations and levels of attack strength. We believe that the proposed\nmethod will contribute to the deeper analysis of robust VQA metrics.",
      "tldr_zh": "本研究揭示了现代视频质量评估（VQA）指标的脆弱性，提出了一种跨模态攻击方法 IC2VQA，利用图像和视频的低级特征空间相似性，从白盒图像质量评估（IQA）模型生成对抗扰动，并通过添加 CLIP 模块增强转移性，以有效攻击黑盒 VQA 模型。实验结果显示，IC2VQA 在攻击三个黑盒 VQA 模型时取得了高成功率，并在相同迭代次数和攻击强度下优于现有黑盒攻击策略。该方法有助于深入分析和改进 VQA 指标的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for VISAPP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08415v1",
      "published_date": "2025-01-14 20:12:09 UTC",
      "updated_date": "2025-01-14 20:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:19:14.726225"
    },
    {
      "arxiv_id": "2501.08411v2",
      "title": "BiDepth Multimodal Neural Network: Bidirectional Depth Deep Learning Architecture for Spatial-Temporal Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Sina Ehsani",
        "Fenglian Pan",
        "Qingpei Hu",
        "Jian Liu"
      ],
      "abstract": "Accurate prediction of spatial-temporal (ST) information in dynamic systems,\nsuch as urban mobility and weather patterns, is a crucial yet challenging\nproblem. The complexity stems from the intricate interplay between spatial\nproximity and temporal relevance, where both long-term trends and short-term\nfluctuations are present in convoluted patterns. Existing approaches, including\ntraditional statistical methods and conventional neural networks, may provide\ninaccurate results due to the lack of an effective mechanism that\nsimultaneously incorporates information at variable temporal depths while\nmaintaining spatial context, resulting in a trade-off between comprehensive\nlong-term historical analysis and responsiveness to short-term new information.\nTo bridge this gap, this paper proposes the BiDepth Multimodal Neural Network\n(BDMNN) with bidirectional depth modulation that enables a comprehensive\nunderstanding of both long-term seasonality and short-term fluctuations,\nadapting to the complex ST context. Case studies with real-world public data\ndemonstrate significant improvements in prediction accuracy, with a 12%\nreduction in Mean Squared Error for urban traffic prediction and a 15%\nimprovement in rain precipitation forecasting compared to state-of-the-art\nbenchmarks, without demanding extra computational resources.",
      "tldr_zh": "本研究针对动态系统中空间-时间（Spatial-Temporal）预测的挑战，如城市流动和天气模式，提出BiDepth Multimodal Neural Network (BDMNN)架构，该架构通过双向深度调制（bidirectional depth modulation）同时整合长期季节性和短期波动，同时保持空间上下文。BDMNN解决了现有方法在处理变量时间深度信息时的权衡问题，提升了预测的全面性和响应性。在真实世界数据集上的案例研究中，BDMNN在城市交通预测中将Mean Squared Error降低了12%，在雨水降水预测中提高了15%的准确性，且无需额外计算资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been submitted to Applied Intelligence for review",
      "pdf_url": "http://arxiv.org/pdf/2501.08411v2",
      "published_date": "2025-01-14 19:59:59 UTC",
      "updated_date": "2025-02-06 04:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:19:26.085567"
    },
    {
      "arxiv_id": "2501.08402v2",
      "title": "Addressing Quality Challenges in Deep Learning: The Role of MLOps and Domain Knowledge",
      "title_zh": "解决深度学习中的质量挑战：MLOps 和领域知识的作用",
      "authors": [
        "Santiago del Rey",
        "Adrià Medina",
        "Xavier Franch",
        "Silverio Martínez-Fernández"
      ],
      "abstract": "Deep learning (DL) systems present unique challenges in software engineering,\nespecially concerning quality attributes like correctness and resource\nefficiency. While DL models excel in specific tasks, engineering DL systems is\nstill essential. The effort, cost, and potential diminishing returns of\ncontinual improvements must be carefully evaluated, as software engineers often\nface the critical decision of when to stop refining a system relative to its\nquality attributes. This experience paper explores the role of MLOps practices\n-- such as monitoring and experiment tracking -- in creating transparent and\nreproducible experimentation environments that enable teams to assess and\njustify the impact of design decisions on quality attributes. Furthermore, we\nreport on experiences addressing the quality challenges by embedding domain\nknowledge into the design of a DL model and its integration within a larger\nsystem. The findings offer actionable insights into the benefits of domain\nknowledge and MLOps and the strategic consideration of when to limit further\noptimizations in DL projects to maximize overall system quality and\nreliability.",
      "tldr_zh": "这篇论文探讨了深度学习(DL)系统在软件工程中面临的质量挑战，特别是正确性和资源效率等属性。作者强调了MLOps实践（如监控和实验跟踪）的关键作用，它们有助于构建透明、可重现的环境，以评估设计决策对质量属性的影响。同时，通过将领域知识嵌入DL模型的设计和系统集成中，论文报告了实际经验，展示了如何缓解这些挑战。总体上，该研究提供了可操作的见解，帮助团队权衡优化收益，并在适当时候停止改进，以提升DL系统的整体质量和可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "6 pages, 1 figure, accepted to the 4th International Conference on AI\n  Engineering - Software Engineering for AI (CAIN)",
      "pdf_url": "http://arxiv.org/pdf/2501.08402v2",
      "published_date": "2025-01-14 19:37:08 UTC",
      "updated_date": "2025-01-31 16:47:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:19:38.428722"
    },
    {
      "arxiv_id": "2501.10453v1",
      "title": "Uncovering Bias in Foundation Models: Impact, Testing, Harm, and Mitigation",
      "title_zh": "揭示基础模型中的偏差：影响、测试、危害和缓解",
      "authors": [
        "Shuzhou Sun",
        "Li Liu",
        "Yongxiang Liu",
        "Zhen Liu",
        "Shuanghui Zhang",
        "Janne Heikkilä",
        "Xiang Li"
      ],
      "abstract": "Bias in Foundation Models (FMs) - trained on vast datasets spanning societal\nand historical knowledge - poses significant challenges for fairness and equity\nacross fields such as healthcare, education, and finance. These biases, rooted\nin the overrepresentation of stereotypes and societal inequalities in training\ndata, exacerbate real-world discrimination, reinforce harmful stereotypes, and\nerode trust in AI systems. To address this, we introduce Trident Probe Testing\n(TriProTesting), a systematic testing method that detects explicit and implicit\nbiases using semantically designed probes. Here we show that FMs, including\nCLIP, ALIGN, BridgeTower, and OWLv2, demonstrate pervasive biases across single\nand mixed social attributes (gender, race, age, and occupation). Notably, we\nuncover mixed biases when social attributes are combined, such as gender x\nrace, gender x age, and gender x occupation, revealing deeper layers of\ndiscrimination. We further propose Adaptive Logit Adjustment\n(AdaLogAdjustment), a post-processing technique that dynamically redistributes\nprobability power to mitigate these biases effectively, achieving significant\nimprovements in fairness without retraining models. These findings highlight\nthe urgent need for ethical AI practices and interdisciplinary solutions to\naddress biases not only at the model level but also in societal structures. Our\nwork provides a scalable and interpretable solution that advances fairness in\nAI systems while offering practical insights for future research on fair AI\ntechnologies.",
      "tldr_zh": "该论文探讨了 Foundation Models (FMs) 中的偏见问题，这些偏见源于训练数据中的刻板印象和不平等，导致真实世界歧视、强化有害刻板印象，并削弱对 AI 的信任，尤其在医疗、教育和金融等领域。作者引入 Trident Probe Testing (TriProTesting)，一种系统测试方法，使用语义设计探针检测显性和隐性偏见，发现模型如 CLIP、ALIGN 和 OWLv2 在单一（如性别、种族）和混合（如性别 x 种族）社会属性上存在广泛偏见。针对这些问题，论文提出 Adaptive Logit Adjustment (AdaLogAdjustment)，一种动态后处理技术，能有效缓解偏见、提升公平性，而无需重新训练模型。这些发现强调了伦理 AI 实践的 urgency，并为公平 AI 技术提供可扩展、可解释的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "60 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.10453v1",
      "published_date": "2025-01-14 19:06:37 UTC",
      "updated_date": "2025-01-14 19:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:19:51.529880"
    },
    {
      "arxiv_id": "2501.08328v2",
      "title": "PokerBench: Training Large Language Models to become Professional Poker Players",
      "title_zh": "PokerBench: 训练大语言模型成为专业扑克玩家",
      "authors": [
        "Richard Zhuang",
        "Akshat Gupta",
        "Richard Yang",
        "Aniket Rahane",
        "Zhengyu Li",
        "Gopala Anumanchipalli"
      ],
      "abstract": "We introduce PokerBench - a benchmark for evaluating the poker-playing\nabilities of large language models (LLMs). As LLMs excel in traditional NLP\ntasks, their application to complex, strategic games like poker poses a new\nchallenge. Poker, an incomplete information game, demands a multitude of skills\nsuch as mathematics, reasoning, planning, strategy, and a deep understanding of\ngame theory and human psychology. This makes Poker the ideal next frontier for\nlarge language models. PokerBench consists of a comprehensive compilation of\n11,000 most important scenarios, split between pre-flop and post-flop play,\ndeveloped in collaboration with trained poker players. We evaluate prominent\nmodels including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,\nfinding that all state-of-the-art LLMs underperform in playing optimal poker.\nHowever, after fine-tuning, these models show marked improvements. We validate\nPokerBench by having models with different scores compete with each other,\ndemonstrating that higher scores on PokerBench lead to higher win rates in\nactual poker games. Through gameplay between our fine-tuned model and GPT-4, we\nalso identify limitations of simple supervised fine-tuning for learning optimal\nplaying strategy, suggesting the need for more advanced methodologies for\neffectively training language models to excel in games. PokerBench thus\npresents a unique benchmark for a quick and reliable evaluation of the\npoker-playing ability of LLMs as well as a comprehensive benchmark to study the\nprogress of LLMs in complex game-playing scenarios.",
      "tldr_zh": "本研究引入了PokerBench，一种专门评估大型语言模型（LLMs）扑克游戏能力的基准测试，聚焦于扑克作为信息不完整游戏所需的数学、推理、规划、策略、博弈论和人类心理技能。PokerBench 由专业扑克玩家合作开发，包含11,000个关键场景（包括pre-flop和post-flop），用于测试模型如GPT-4、ChatGPT 3.5和Llama/Gemma系列的表现，结果显示这些模型初始表现不佳。经fine-tuning后，模型显著提升，并在竞争测试中验证：更高PokerBench分数对应更高胜率，同时揭示简单监督fine-tuning的局限性，强调需要更先进的方法来训练LLMs在复杂游戏中的表现。PokerBench不仅提供快速可靠的评估工具，还为研究LLMs在战略游戏中的进展提供全面基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08328v2",
      "published_date": "2025-01-14 18:59:03 UTC",
      "updated_date": "2025-01-24 20:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:20:02.667672"
    },
    {
      "arxiv_id": "2501.08324v2",
      "title": "ADAM: An AI Reasoning and Bioinformatics Model for Alzheimer's Disease Detection and Microbiome-Clinical Data Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyuan Huang",
        "Vishaldeep Kaur Sekhon",
        "Roozbeh Sadeghian",
        "Maria L. Vaida",
        "Cynthia Jo",
        "Doyle Ward",
        "Vanni Bucci",
        "John P. Haran"
      ],
      "abstract": "Alzheimer's Disease Analysis Model (ADAM) is a multi-agent reasoning large\nlanguage model (LLM) framework designed to integrate and analyze multimodal\ndata, including microbiome profiles, clinical datasets, and external knowledge\nbases, to enhance the understanding and classification of Alzheimer's disease\n(AD). By leveraging the agentic system with LLM, ADAM produces insights from\ndiverse data sources and contextualizes the findings with literature-driven\nevidence. A comparative evaluation with XGBoost revealed a significantly\nimproved mean F1 score and significantly reduced variance for ADAM,\nhighlighting its robustness and consistency, particularly when utilizing human\nbiological data. Although currently tailored for binary classification tasks\nwith two data modalities, future iterations will aim to incorporate additional\ndata types, such as neuroimaging and peripheral biomarkers, and expand them to\npredict disease progression, thereby broadening ADAM's scalability and\napplicability in AD research and diagnostic applications.",
      "tldr_zh": "该研究提出了ADAM框架，这是一个多智能体推理大型语言模型（LLM）系统，用于整合微生物组配置文件、临床数据集和外部知识库，以提升对阿尔茨海默病（AD）的理解和分类。ADAM通过代理系统从多样数据源生成见解，并结合文献证据进行上下文化分析，与XGBoost模型相比，其平均F1 score显著提高，方差降低，展示了更高的鲁棒性和一致性，尤其在人类生物数据应用中。虽然目前专注于二元分类任务和两种数据模式，未来计划扩展到包括神经影像和外周生物标志物等更多类型，并应用于预测疾病进展，从而增强ADAM在研究和诊断中的可扩展性。",
      "categories": [
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08324v2",
      "published_date": "2025-01-14 18:56:33 UTC",
      "updated_date": "2025-05-02 03:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:20:14.542734"
    },
    {
      "arxiv_id": "2501.08316v1",
      "title": "Diffusion Adversarial Post-Training for One-Step Video Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shanchuan Lin",
        "Xin Xia",
        "Yuxi Ren",
        "Ceyuan Yang",
        "Xuefeng Xiao",
        "Lu Jiang"
      ],
      "abstract": "The diffusion models are widely used for image and video generation, but\ntheir iterative generation process is slow and expansive. While existing\ndistillation approaches have demonstrated the potential for one-step generation\nin the image domain, they still suffer from significant quality degradation. In\nthis work, we propose Adversarial Post-Training (APT) against real data\nfollowing diffusion pre-training for one-step video generation. To improve the\ntraining stability and quality, we introduce several improvements to the model\narchitecture and training procedures, along with an approximated R1\nregularization objective. Empirically, our experiments show that our\nadversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720,\n24fps videos in real time using a single forward evaluation step. Additionally,\nour model is capable of generating 1024px images in a single step, achieving\nquality comparable to state-of-the-art methods.",
      "tldr_zh": "本文提出Adversarial Post-Training (APT)方法，用于在diffusion models预训练后，通过对抗训练实现高效的一步视频生成，解决传统迭代过程的缓慢和资源消耗问题。\n为了提升训练稳定性和生成质量，该方法引入了模型架构改进、训练程序优化以及近似R1 regularization目标。\n实验结果显示，Seaweed-APT模型能够使用单步前向评估实时生成2秒、1280x720、24fps视频，并实现与最先进方法相当的1024px图像生成质量。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08316v1",
      "published_date": "2025-01-14 18:51:48 UTC",
      "updated_date": "2025-01-14 18:51:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:20:26.849739"
    },
    {
      "arxiv_id": "2501.08297v1",
      "title": "Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects",
      "title_zh": "树宽有界的多项式阈值函数：某些可解释性和复杂性方面",
      "authors": [
        "Karine Chubarian",
        "Johnny Joyce",
        "Gyorgy Turan"
      ],
      "abstract": "The tree-width of a multivariate polynomial is the tree-width of the\nhypergraph with hyperedges corresponding to its terms. Multivariate polynomials\nof bounded tree-width have been studied by Makowsky and Meer as a new sparsity\ncondition that allows for polynomial solvability of problems which are\nintractable in general. We consider a variation on this theme for Boolean\nvariables. A representation of a Boolean function as the sign of a polynomial\nis called a polynomial threshold representation. We discuss Boolean functions\nrepresentable as polynomial threshold functions of bounded tree-width and\npresent two applications to Bayesian network classifiers, a probabilistic\ngraphical model. Both applications are in Explainable Artificial Intelligence\n(XAI), the research area dealing with the black-box nature of many recent\nmachine learning models. We also give a separation result between the\nrepresentational power of positive and general polynomial threshold functions.",
      "tldr_zh": "该研究探讨了树宽（tree-width）受限的多项式阈函数（polynomial threshold functions），将其作为布尔函数表示的一种新稀疏性条件，以实现多项式时间求解原本棘手的计算问题。论文针对布尔函数的多项式阈表示，介绍了两个应用于贝叶斯网络分类器（Bayesian network classifiers）的案例，这些案例聚焦于可解释人工智能（Explainable Artificial Intelligence, XAI），旨在缓解机器学习模型的黑箱问题。最终，该工作证明了正多项式阈函数和一般多项式阈函数在表示能力上的分离结果，为XAI领域的复杂性分析提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 3 figures. To be published in Festschrift in honor of\n  Johann A. Makowsky",
      "pdf_url": "http://arxiv.org/pdf/2501.08297v1",
      "published_date": "2025-01-14 18:28:08 UTC",
      "updated_date": "2025-01-14 18:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:20:49.712976"
    },
    {
      "arxiv_id": "2501.08292v1",
      "title": "HALoGEN: Fantastic LLM Hallucinations and Where to Find Them",
      "title_zh": "翻译失败",
      "authors": [
        "Abhilasha Ravichander",
        "Shrusti Ghela",
        "David Wadden",
        "Yejin Choi"
      ],
      "abstract": "Despite their impressive ability to generate high-quality and fluent text,\ngenerative large language models (LLMs) also produce hallucinations: statements\nthat are misaligned with established world knowledge or provided input context.\nHowever, measuring hallucination can be challenging, as having humans verify\nmodel generations on-the-fly is both expensive and time-consuming. In this\nwork, we release HALoGEN, a comprehensive hallucination benchmark consisting\nof: (1) 10,923 prompts for generative models spanning nine domains including\nprogramming, scientific attribution, and summarization, and (2) automatic\nhigh-precision verifiers for each use case that decompose LLM generations into\natomic units, and verify each unit against a high-quality knowledge source. We\nuse this framework to evaluate ~150,000 generations from 14 language models,\nfinding that even the best-performing models are riddled with hallucinations\n(sometimes up to 86% of generated atomic facts depending on the domain). We\nfurther define a novel error classification for LLM hallucinations based on\nwhether they likely stem from incorrect recollection of training data (Type A\nerrors), or incorrect knowledge in training data (Type B errors), or are\nfabrication (Type C errors). We hope our framework provides a foundation to\nenable the principled study of why generative models hallucinate, and advances\nthe development of trustworthy large language models.",
      "tldr_zh": "该论文介绍了 HALoGEN，一种全面的幻觉基准测试，用于评估生成式大语言模型 (LLMs) 在生成文本时产生的 hallucinations（与世界知识或输入上下文不一致的语句）。HALoGEN 包含 10,923 个跨九个领域的提示（如编程和总结），以及自动高精度验证器，这些验证器将 LLM 生成分解为原子单位并与高质量知识源进行比对。研究评估了 14 个模型约 15 万个生成，发现顶级模型的幻觉率高达 86%，并定义了新型错误分类（Type A：训练数据回忆错误；Type B：训练数据知识错误；Type C：捏造），以推动对 LLM 幻觉原因的系统研究和可信赖模型的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2501.08292v1",
      "published_date": "2025-01-14 18:13:08 UTC",
      "updated_date": "2025-01-14 18:13:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:21:02.620780"
    },
    {
      "arxiv_id": "2501.08271v1",
      "title": "Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models",
      "title_zh": "翻译失败",
      "authors": [
        "Saad Mashkoor Siddiqui",
        "Mohammad Ali Sheikh",
        "Muhammad Aleem",
        "Kajol R Singh"
      ],
      "abstract": "In this work, we investigate the efficacy of various adapter architectures on\nsupervised binary classification tasks from the SuperGLUE benchmark as well as\na supervised multi-class news category classification task from Kaggle.\nSpecifically, we compare classification performance and time complexity of\nthree transformer models, namely DistilBERT, ELECTRA, and BART, using\nconventional fine-tuning as well as nine state-of-the-art (SoTA) adapter\narchitectures. Our analysis reveals performance differences across adapter\narchitectures, highlighting their ability to achieve comparable or better\nperformance relative to fine-tuning at a fraction of the training time. Similar\nresults are observed on the new classification task, further supporting our\nfindings and demonstrating adapters as efficient and flexible alternatives to\nfine-tuning. This study provides valuable insights and guidelines for selecting\nand implementing adapters in diverse natural language processing (NLP)\napplications.",
      "tldr_zh": "本研究比较了传统微调(fine-tuning)与九种最先进(adapter architectures)的方法在DistilBERT、ELECTRA和BART等Transformer模型上的性能和时间复杂度，针对SuperGLUE基准的监督二分类任务以及Kaggle的多类新闻分类任务。结果显示，adapter架构能实现与fine-tuning相当或更好的分类性能，同时显著减少训练时间。在新任务上观察到类似效果，这证明了adapter作为高效灵活的替代方案的价值，为NLP应用中选择和实现adapter提供了宝贵见解和指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08271v1",
      "published_date": "2025-01-14 17:37:40 UTC",
      "updated_date": "2025-01-14 17:37:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:21:13.752617"
    },
    {
      "arxiv_id": "2501.08266v1",
      "title": "AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring",
      "title_zh": "AI 驱动的水体分割：利用深度学习模型增强洪水监测",
      "authors": [
        "Sanjida Afrin Mou",
        "Tasfia Noor Chowdhury",
        "Adib Ibn Mannan",
        "Sadia Nourin Mim",
        "Lubana Tarannum",
        "Tasrin Noman",
        "Jamal Uddin Ahamed"
      ],
      "abstract": "Flooding is a major natural hazard causing significant fatalities and\neconomic losses annually, with increasing frequency due to climate change.\nRapid and accurate flood detection and monitoring are crucial for mitigating\nthese impacts. This study compares the performance of three deep learning\nmodels UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in\nflood detection, utilizing images from drones, in field observations, and\nsocial media. This study involves creating a new dataset that augments\nwellknown benchmark datasets with flood-specific images, enhancing the\nrobustness of the models. The UNet, ResNet, and DeepLab v3 architectures are\ntested to determine their effectiveness in various environmental conditions and\ngeographical locations, and the strengths and limitations of each model are\nalso discussed here, providing insights into their applicability in different\nscenarios by predicting image segmentation masks. This fully automated approach\nallows these models to isolate flooded areas in images, significantly reducing\nprocessing time compared to traditional semi-automated methods. The outcome of\nthis study is to predict segmented masks for each image effected by a flood\ndisaster and the validation accuracy of these models. This methodology\nfacilitates timely and continuous flood monitoring, providing vital data for\nemergency response teams to reduce loss of life and economic damages. It offers\na significant reduction in the time required to generate flood maps, cutting\ndown the manual processing time. Additionally, we present avenues for future\nresearch, including the integration of multimodal data sources and the\ndevelopment of robust deep learning architectures tailored specifically for\nflood detection tasks. Overall, our work contributes to the advancement of\nflood management strategies through innovative use of deep learning\ntechnologies.",
      "tldr_zh": "这篇论文探讨了使用深度学习模型（UNet、ResNet 和 DeepLabv3）进行水体像素级分割，以提升洪水监测的准确性和效率。研究创建了一个新数据集，通过添加洪水特定图像（来自无人机、现场观察和社会媒体）来增强现有基准数据集的鲁棒性，并比较了这些模型在不同环境和地理位置下的性能。结果表明，模型能自动隔离洪水区域，显著减少处理时间，并提高验证准确率，为紧急响应团队提供及时的数据支持。该工作为洪水管理策略的创新提供了贡献，并建议未来研究整合多模态数据源和开发专属深度学习架构。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08266v1",
      "published_date": "2025-01-14 17:26:02 UTC",
      "updated_date": "2025-01-14 17:26:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:21:26.368490"
    },
    {
      "arxiv_id": "2501.08365v1",
      "title": "Towards Best Practices for Open Datasets for LLM Training",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Baack",
        "Stella Biderman",
        "Kasia Odrozek",
        "Aviya Skowron",
        "Ayah Bdeir",
        "Jillian Bommarito",
        "Jennifer Ding",
        "Maximilian Gahntz",
        "Paul Keller",
        "Pierre-Carl Langlais",
        "Greg Lindahl",
        "Sebastian Majstorovic",
        "Nik Marda",
        "Guilherme Penedo",
        "Maarten Van Segbroeck",
        "Jennifer Wang",
        "Leandro von Werra",
        "Mitchell Baker",
        "Julie Belião",
        "Kasia Chmielinski",
        "Marzieh Fadaee",
        "Lisa Gutermuth",
        "Hynek Kydlíček",
        "Greg Leppert",
        "EM Lewis-Jong",
        "Solana Larsen",
        "Shayne Longpre",
        "Angela Oduor Lungati",
        "Cullen Miller",
        "Victor Miller",
        "Max Ryabinin",
        "Kathleen Siminyu",
        "Andrew Strait",
        "Mark Surman",
        "Anna Tumadóttir",
        "Maurice Weber",
        "Rebecca Weiss",
        "Lee White",
        "Thomas Wolf"
      ],
      "abstract": "Many AI companies are training their large language models (LLMs) on data\nwithout the permission of the copyright owners. The permissibility of doing so\nvaries by jurisdiction: in countries like the EU and Japan, this is allowed\nunder certain restrictions, while in the United States, the legal landscape is\nmore ambiguous. Regardless of the legal status, concerns from creative\nproducers have led to several high-profile copyright lawsuits, and the threat\nof litigation is commonly cited as a reason for the recent trend towards\nminimizing the information shared about training datasets by both corporate and\npublic interest actors. This trend in limiting data information causes harm by\nhindering transparency, accountability, and innovation in the broader ecosystem\nby denying researchers, auditors, and impacted individuals access to the\ninformation needed to understand AI models.\n  While this could be mitigated by training language models on open access and\npublic domain data, at the time of writing, there are no such models (trained\nat a meaningful scale) due to the substantial technical and sociological\nchallenges in assembling the necessary corpus. These challenges include\nincomplete and unreliable metadata, the cost and complexity of digitizing\nphysical records, and the diverse set of legal and technical skills required to\nensure relevance and responsibility in a quickly changing landscape. Building\ntowards a future where AI systems can be trained on openly licensed data that\nis responsibly curated and governed requires collaboration across legal,\ntechnical, and policy domains, along with investments in metadata standards,\ndigitization, and fostering a culture of openness.",
      "tldr_zh": "该论文讨论了AI公司未经版权所有者许可使用数据训练大型语言模型(LLMs)的做法及其法律问题，在欧盟和日本受限，而在美国则较为模糊，导致版权诉讼增加并影响数据透明度与创新。作者指出，这种情况阻碍了研究人员和相关方获取训练数据集信息，从而损害问责性和生态系统发展。论文建议采用最佳实践，通过使用开放访问和公有领域数据训练LLMs来缓解挑战，但面临元数据不完整、数字化成本高等障碍。未来需跨法律、技术和政策领域的合作，投资元数据标准和数字化，以推动负责任的开放数据集治理。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08365v1",
      "published_date": "2025-01-14 17:18:05 UTC",
      "updated_date": "2025-01-14 17:18:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:21:37.251969"
    },
    {
      "arxiv_id": "2503.15495v1",
      "title": "Entwicklung einer Webanwendung zur Generierung von skolemisierten RDF Daten für die Verwaltung von Lieferketten",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Laas"
      ],
      "abstract": "F\\\"ur eine fr\\\"uhzeitige Erkennung von Lieferengp\\\"assen m\\\"ussen\nLieferketten in einer geeigneten digitalen Form vorliegen, damit sie\nverarbeitet werden k\\\"onnen. Der f\\\"ur die Datenmodellierung ben\\\"otigte\nArbeitsaufwand ist jedoch, gerade IT-fremden Personen, nicht zuzumuten. Es\nwurde deshalb im Rahmen dieser Arbeit eine Webanwendung entwickelt, welche die\nzugrunde liegende Komplexit\\\"at f\\\"ur den Benutzer verschleiern soll. Konkret\nhandelt es sich dabei um eine grafische Benutzeroberfl\\\"ache, auf welcher\nTemplates instanziiert und miteinander verkn\\\"upft werden k\\\"onnen. F\\\"ur die\nDefinition dieser Templates wurden in dieser Arbeit geeignete Konzepte\nerarbeitet und erweitert. Zur Erhebung der Benutzerfreundlichkeit der\nWebanwendung wurde abschlie{\\ss}end eine Nutzerstudie mit mehreren Testpersonen\ndurchgef\\\"uhrt. Diese legte eine Vielzahl von n\\\"utzlichen\nVerbesserungsvorschl\\\"agen offen.\n  --\n  For early detection of supply bottlenecks, supply chains must be available in\na suitable digital form so that they can be processed. However, the amount of\nwork required for data modeling cannot be expected of people who are not\nfamiliar with IT topics. Therefore, a web application was developed in the\ncontext of this thesis, which is supposed to disguise the underlying complexity\nfor the user. Specifically, this is a graphical user interface on which\ntemplates can be instantiated and linked to each other. Suitable concepts for\nthe definition of these templates were developed and extended in this thesis.\nFinally, a user study with several test persons was conducted to determine the\nusability of the web application. This revealed a large number of useful\nsuggestions for improvement.",
      "tldr_zh": "本论文开发了一个 Web 应用，用于生成 skolemized RDF 数据，以简化供应链管理中的数据建模过程。该应用通过图形用户界面（GUI）允许用户实例化模板并相互链接，从而为非 IT 专业人士隐藏底层复杂性，并支持早期检测供应链瓶颈。论文中扩展了模板定义的相关概念，并通过用户研究验证了应用的可用性，结果提供了多项有价值的改进建议。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Master's thesis",
      "pdf_url": "http://arxiv.org/pdf/2503.15495v1",
      "published_date": "2025-01-14 16:38:36 UTC",
      "updated_date": "2025-01-14 16:38:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:21:49.558304"
    },
    {
      "arxiv_id": "2501.08248v2",
      "title": "Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yifu Qiu",
        "Varun Embar",
        "Yizhe Zhang",
        "Navdeep Jaitly",
        "Shay B. Cohen",
        "Benjamin Han"
      ],
      "abstract": "Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model.",
      "tldr_zh": "该论文探讨了长上下文语言模型 (LCLMs) 的 In-Context Retrieval and Reasoning (ICR^2) 能力，旨在简化 Retrieval-Augmented Generation (RAG) 流程，使模型能直接处理知识库进行检索和推理。作者引入了新的基准 ICR^2，以更现实的场景（如包含混淆段落）评估 LCLM，避免现有基准如 LOFT 的过度简化。论文提出了三种提升方法：retrieve-then-generate fine-tuning、retrieval-attention-probing（使用注意力头过滤长上下文）和 joint retrieval head training，结果显示在 Mistral-7B 上，表现比 vanilla RAG 和 supervised fine-tuning 分别提高了 17 和 15 分（Exact Match on LOFT），甚至在大多数任务上超过了 GPT-4-Turbo。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08248v2",
      "published_date": "2025-01-14 16:38:33 UTC",
      "updated_date": "2025-02-28 11:40:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:22:03.629106"
    },
    {
      "arxiv_id": "2501.08243v1",
      "title": "Engineering LLM Powered Multi-agent Framework for Autonomous CloudOps",
      "title_zh": "翻译失败",
      "authors": [
        "Kannan Parthasarathy",
        "Karthik Vaidhyanathan",
        "Rudra Dhar",
        "Venkat Krishnamachari",
        "Basil Muhammed",
        "Adyansh Kakran",
        "Sreemaee Akshathala",
        "Shrikara Arun",
        "Sumant Dubey",
        "Mohan Veerubhotla",
        "Amey Karan"
      ],
      "abstract": "Cloud Operations (CloudOps) is a rapidly growing field focused on the\nautomated management and optimization of cloud infrastructure which is\nessential for organizations navigating increasingly complex cloud environments.\nMontyCloud Inc. is one of the major companies in the CloudOps domain that\nleverages autonomous bots to manage cloud compliance, security, and continuous\noperations. To make the platform more accessible and effective to the\ncustomers, we leveraged the use of GenAI.\n  Developing a GenAI-based solution for autonomous CloudOps for the existing\nMontyCloud system presented us with various challenges such as i) diverse data\nsources; ii) orchestration of multiple processes; and iii) handling complex\nworkflows to automate routine tasks. To this end, we developed MOYA, a\nmulti-agent framework that leverages GenAI and balances autonomy with the\nnecessary human control. This framework integrates various internal and\nexternal systems and is optimized for factors like task orchestration,\nsecurity, and error mitigation while producing accurate, reliable, and relevant\ninsights by utilizing Retrieval Augmented Generation (RAG). Evaluations of our\nmulti-agent system with the help of practitioners as well as using automated\nchecks demonstrate enhanced accuracy, responsiveness, and effectiveness over\nnon-agentic approaches across complex workflows.",
      "tldr_zh": "这篇论文介绍了 MOYA，一个基于 LLM 的多智能体框架，用于实现自主 CloudOps，以自动化管理云基础设施的合规性、安全性和持续操作。MOYA 通过整合 GenAI 和 Retrieval Augmented Generation (RAG)，解决了多样数据来源、任务编排以及复杂工作流的挑战，同时平衡了自治性与人类控制。实验评估表明，该框架在复杂工作流中比非智能体方法表现出更高的准确性、响应性和有效性，为 CloudOps 领域提供了更可靠的解决方案。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "The paper has been accepted as full paper to CAIN 2025\n  (https://conf.researchr.org/home/cain-2025), co-located with ICSE 2025\n  (https://conf.researchr.org/home/icse-2025). The paper was submitted to CAIN\n  for review on 9 November 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.08243v1",
      "published_date": "2025-01-14 16:30:10 UTC",
      "updated_date": "2025-01-14 16:30:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:22:13.473825"
    },
    {
      "arxiv_id": "2501.08241v1",
      "title": "A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Reza Takhsha",
        "Maryam Rastgarpour",
        "Mozhgan Naderi"
      ],
      "abstract": "The COVID-19 pandemic has profoundly impacted billions globally. It\nchallenges public health and healthcare systems due to its rapid spread and\nsevere respiratory effects. An effective strategy to mitigate the COVID-19\npandemic involves integrating testing to identify infected individuals. While\nRT-PCR is considered the gold standard for diagnosing COVID-19, it has some\nlimitations such as the risk of false negatives. To address this problem, this\npaper introduces a novel Deep Learning Diagnosis System that integrates\npre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble\nlearning framework to achieve precise identification of COVID-19 cases from\nChest X-ray (CXR) images. We combine feature vectors from the final hidden\nlayers of pre-trained DCNNs using the Choquet integral to capture interactions\nbetween different DCNNs that a linear approach cannot. We employed\nSugeno-$\\lambda$ measure theory to derive fuzzy measures for subsets of\nnetworks to enable aggregation. We utilized Differential Evolution to estimate\nfuzzy densities. We developed a TensorFlow-based layer for Choquet operation to\nfacilitate efficient aggregation, due to the intricacies involved in\naggregating feature vectors. Experimental results on the COVIDx dataset show\nthat our ensemble model achieved 98\\% accuracy in three-class classification\nand 99.50\\% in binary classification, outperforming its components-DenseNet-201\n(97\\% for three-class, 98.75\\% for binary), Inception-v3 (96.25\\% for\nthree-class, 98.50\\% for binary), and Xception (94.50\\% for three-class, 98\\%\nfor binary)-and surpassing many previous methods.",
      "tldr_zh": "这篇论文提出了一种新型特征级集成模型，用于从胸部 X 光 (CXR) 图像中精确识别 COVID-19 病例，以弥补 RT-PCR 测试的假阴性风险。模型通过结合预训练的深度卷积神经网络 (DCNNs) 的特征向量，使用 Choquet integral 捕捉不同网络间的交互，并采用 Differential Evolution 优化模糊测度，同时开发了基于 TensorFlow 的 Choquet 操作层进行高效聚合。在 COVIDx 数据集上的实验显示，该模型在三分类任务中达到 98% 准确率，在二分类任务中达到 99.50%，优于单个组件模型如 DenseNet-201 和先前方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08241v1",
      "published_date": "2025-01-14 16:28:02 UTC",
      "updated_date": "2025-01-14 16:28:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:22:26.632947"
    },
    {
      "arxiv_id": "2501.08234v1",
      "title": "Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning",
      "title_zh": "利用多智能体强化学习的高速铁路动态定价",
      "authors": [
        "Enrique Adrian Villarrubia-Martin",
        "Luis Rodriguez-Benitez",
        "David Muñoz-Valero",
        "Giovanni Montana",
        "Luis Jimenez-Linares"
      ],
      "abstract": "This paper addresses a critical challenge in the high-speed passenger railway\nindustry: designing effective dynamic pricing strategies in the context of\ncompeting and cooperating operators. To address this, a multi-agent\nreinforcement learning (MARL) framework based on a non-zero-sum Markov game is\nproposed, incorporating random utility models to capture passenger decision\nmaking. Unlike prior studies in areas such as energy, airlines, and mobile\nnetworks, dynamic pricing for railway systems using deep reinforcement learning\nhas received limited attention. A key contribution of this paper is a\nparametrisable and versatile reinforcement learning simulator designed to model\na variety of railway network configurations and demand patterns while enabling\nrealistic, microscopic modelling of user behaviour, called RailPricing-RL. This\nenvironment supports the proposed MARL framework, which models heterogeneous\nagents competing to maximise individual profits while fostering cooperative\nbehaviour to synchronise connecting services. Experimental results validate the\nframework, demonstrating how user preferences affect MARL performance and how\npricing policies influence passenger choices, utility, and overall system\ndynamics. This study provides a foundation for advancing dynamic pricing\nstrategies in railway systems, aligning profitability with system-wide\nefficiency, and supporting future research on optimising pricing policies.",
      "tldr_zh": "本研究针对高铁客运行业中竞争与合作运营商的动态定价挑战，提出了一种基于非零和Markov游戏的多智能体强化学习(MARL)框架，并整合随机效用模型来模拟乘客决策。该框架的关键贡献是开发了参数化且灵活的强化学习模拟器RailPricing-RL，能够模拟各种高铁网络配置、需求模式以及微观用户行为，支持代理在竞争最大化利润的同时实现服务同步。实验结果显示，用户偏好显著影响MARL性能，而动态定价策略能优化乘客选择、效用和系统整体动态，为高铁动态定价策略的改进提供基础，促进盈利性与系统效率的平衡。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "37 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08234v1",
      "published_date": "2025-01-14 16:19:25 UTC",
      "updated_date": "2025-01-14 16:19:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:22:38.464719"
    },
    {
      "arxiv_id": "2501.08220v1",
      "title": "Optimization of Link Configuration for Satellite Communication Using Reinforcement Learning",
      "title_zh": "利用强化学习优化卫星通信链路配置",
      "authors": [
        "Tobias Rohe",
        "Michael Kölle",
        "Jan Matheis",
        "Rüdiger Höpfl",
        "Leo Sünkel",
        "Claudia Linnhoff-Popien"
      ],
      "abstract": "Satellite communication is a key technology in our modern connected world.\nWith increasingly complex hardware, one challenge is to efficiently configure\nlinks (connections) on a satellite transponder. Planning an optimal link\nconfiguration is extremely complex and depends on many parameters and metrics.\nThe optimal use of the limited resources, bandwidth and power of the\ntransponder is crucial. Such an optimization problem can be approximated using\nmetaheuristic methods such as simulated annealing, but recent research results\nalso show that reinforcement learning can achieve comparable or even better\nperformance in optimization methods. However, there have not yet been any\nstudies on link configuration on satellite transponders. In order to close this\nresearch gap, a transponder environment was developed as part of this work. For\nthis environment, the performance of the reinforcement learning algorithm PPO\nwas compared with the metaheuristic simulated annealing in two experiments. The\nresults show that Simulated Annealing delivers better results for this static\nproblem than the PPO algorithm, however, the research in turn also underlines\nthe potential of reinforcement learning for optimization problems.",
      "tldr_zh": "本研究针对卫星通信中链接配置的优化问题，旨在高效利用有限的带宽和功率资源。研究开发了一个transponder环境，并比较了强化学习算法PPO与传统元启发式方法simulated annealing的性能。实验结果显示，在静态问题上simulated annealing的表现优于PPO，但该研究突显了reinforcement learning在优化领域的潜力，为未来卫星通信优化提供新思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08220v1",
      "published_date": "2025-01-14 16:04:46 UTC",
      "updated_date": "2025-01-14 16:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:22:49.204904"
    },
    {
      "arxiv_id": "2501.08208v1",
      "title": "ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Mohita Chowdhury",
        "Yajie Vera He",
        "Aisling Higham",
        "Ernest Lim"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive potential in clinical\nquestion answering (QA), with Retrieval Augmented Generation (RAG) emerging as\na leading approach for ensuring the factual accuracy of model responses.\nHowever, current automated RAG metrics perform poorly in clinical and\nconversational use cases. Using clinical human evaluations of responses is\nexpensive, unscalable, and not conducive to the continuous iterative\ndevelopment of RAG systems. To address these challenges, we introduce ASTRID -\nan Automated and Scalable TRIaD for evaluating clinical QA systems leveraging\nRAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy\n(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is\ndesigned to better capture the faithfulness of a model's response to the\nknowledge base without penalising conversational elements. To validate our\ntriad, we curate a dataset of over 200 real-world patient questions posed to an\nLLM-based QA agent during surgical follow-up for cataract surgery - the highest\nvolume operation in the world - augmented with clinician-selected questions for\nemergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate\nthat CF can predict human ratings of faithfulness better than existing\ndefinitions for conversational use cases. Furthermore, we show that evaluation\nusing our triad consisting of CF, RA, and CR exhibits alignment with clinician\nassessment for inappropriate, harmful, or unhelpful responses. Finally, using\nnine different LLMs, we demonstrate that the three metrics can closely agree\nwith human evaluations, highlighting the potential of these metrics for use in\nLLM-driven automated evaluation pipelines. We also publish the prompts and\ndatasets for these experiments, providing valuable resources for further\nresearch and development.",
      "tldr_zh": "本文提出 ASTRID，一种自动且可扩展的评估框架（TRIAD），用于评估基于 RAG 的临床问答系统，包括三个新指标：Context Relevance (CR)、Refusal Accuracy (RA) 和 Conversational Faithfulness (CF)，其中 CF 专门优化以评估模型响应对知识库的忠实度，同时不惩罚对话元素。研究者构建了一个数据集，包含超过 200 个真实患者问题及各种场景，并通过实验验证 CF 比现有指标更准确地预测人类评级，而整个 TRIAD 与临床评估高度一致。最终，使用九个不同 LLMs 证明这些指标可用于高效的自动化评估管道，并公开了提示和数据集以支持进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08208v1",
      "published_date": "2025-01-14 15:46:39 UTC",
      "updated_date": "2025-01-14 15:46:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:23:03.063188"
    },
    {
      "arxiv_id": "2501.08205v1",
      "title": "Modeling Feature Maps for Quantum Machine Learning",
      "title_zh": "量子机器学习的特征映射建模",
      "authors": [
        "Navneet Singh",
        "Shiva Raj Pokhrel"
      ],
      "abstract": "Quantum Machine Learning (QML) offers significant potential for complex tasks\nlike genome sequence classification, but quantum noise on Noisy\nIntermediate-Scale Quantum (NISQ) devices poses practical challenges. This\nstudy systematically evaluates how various quantum noise models including\ndephasing, amplitude damping, depolarizing, thermal noise, bit-flip, and\nphase-flip affect key QML algorithms (QSVC, Peg-QSVC, QNN, VQC) and feature\nmapping techniques (ZFeatureMap, ZZFeatureMap, and PauliFeatureMap). Results\nindicate that QSVC is notably robust under noise, whereas Peg-QSVC and QNN are\nmore sensitive, particularly to depolarizing and amplitude-damping noise. The\nPauliFeatureMap is especially vulnerable, highlighting difficulties in\nmaintaining accurate classification under noisy conditions. These findings\nunderscore the critical importance of feature map selection and noise\nmitigation strategies in optimizing QML for genomic classification, with\npromising implications for personalized medicine.",
      "tldr_zh": "这篇论文探讨了量子噪声对量子机器学习 (QML) 的影响，特别是针对基因组序列分类等复杂任务在 Noisy Intermediate-Scale Quantum (NISQ) 设备上的挑战。研究系统评估了多种噪声模型（如 dephasing、amplitude damping、depolarizing 等）对关键 QML 算法（QSVC、Peg-QSVC、QNN、VQC）和特征映射技术（ZFeatureMap、ZZFeatureMap、PauliFeatureMap）的性能影响。结果表明，QSVC 在噪声环境下更具鲁棒性，而 Peg-QSVC、QNN 和 PauliFeatureMap 则对 depolarizing 和 amplitude-damping 噪声高度敏感。这些发现突出了特征映射选择和噪声缓解策略的重要性，有助于优化 QML 在个性化医学中的应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08205v1",
      "published_date": "2025-01-14 15:45:27 UTC",
      "updated_date": "2025-01-14 15:45:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:23:15.423274"
    },
    {
      "arxiv_id": "2501.08199v1",
      "title": "EmoNeXt: an Adapted ConvNeXt for Facial Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yassine El Boudouri",
        "Amine Bohi"
      ],
      "abstract": "Facial expressions play a crucial role in human communication serving as a\npowerful and impactful means to express a wide range of emotions. With\nadvancements in artificial intelligence and computer vision, deep neural\nnetworks have emerged as effective tools for facial emotion recognition. In\nthis paper, we propose EmoNeXt, a novel deep learning framework for facial\nexpression recognition based on an adapted ConvNeXt architecture network. We\nintegrate a Spatial Transformer Network (STN) to focus on feature-rich regions\nof the face and Squeeze-and-Excitation blocks to capture channel-wise\ndependencies. Moreover, we introduce a self-attention regularization term,\nencouraging the model to generate compact feature vectors. We demonstrate the\nsuperiority of our model over existing state-of-the-art deep learning models on\nthe FER2013 dataset regarding emotion classification accuracy.",
      "tldr_zh": "本文提出 EmoNeXt，一种基于适应 ConvNeXt 架构的深度学习框架，用于面部表情识别。EmoNeXt 整合了 Spatial Transformer Network (STN) 来聚焦面部特征丰富区域、Squeeze-and-Excitation blocks 来捕捉通道-wise 依赖，以及自注意力正则化项以生成紧凑的特征向量。该模型在 FER2013 数据集上的情感分类准确率超过了现有最先进模型，展示了其在面部表情识别领域的优越性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 5 figures and 2 tables. 2023 IEEE 25th International\n  Workshop on Multimedia Signal Processing (MMSP), Poitiers, France",
      "pdf_url": "http://arxiv.org/pdf/2501.08199v1",
      "published_date": "2025-01-14 15:23:36 UTC",
      "updated_date": "2025-01-14 15:23:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:23:25.776841"
    },
    {
      "arxiv_id": "2501.08192v1",
      "title": "PRESERVE: Prefetching Model Weights and KV-Cache in Distributed LLM Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmet Caner Yüzügüler",
        "Jiawei Zhuang",
        "Lukas Cavigelli"
      ],
      "abstract": "Large language models (LLMs) are widely used across various applications, but\ntheir substantial computational requirements pose significant challenges,\nparticularly in terms of HBM bandwidth bottlenecks and inter-device\ncommunication overhead. In this paper, we present PRESERVE, a novel prefetching\nframework designed to optimize LLM inference by overlapping memory reads for\nmodel weights and KV-cache with collective communication operations. Through\nextensive experiments conducted on commercial AI accelerators, we demonstrate\nup to 1.6x end-to-end speedup on state-of-the-art, open-source LLMs.\nAdditionally, we perform a design space exploration that identifies the optimal\nhardware configuration for the proposed method, showing a further 1.25x\nimprovement in performance per cost by selecting the optimal L2 cache size. Our\nresults show that PRESERVE has the potential to mitigate the memory bottlenecks\nand communication overheads, offering a solution to improve the performance and\nscalability of the LLM inference systems.",
      "tldr_zh": "本研究针对大型语言模型(LLMs)的高计算需求及其导致的HBM带宽瓶颈和设备间通信开销，提出了一种名为PRESERVE的预取框架，用于优化分布式LLM服务。该框架通过将模型权重和KV-Cache的内存读取操作与集体通信操作重叠，从而提高推理效率。在商业AI加速器上的实验显示，PRESERVE在开源LLMs上实现了高达1.6倍的端到端加速，并通过设计空间探索优化硬件配置（如L2缓存大小），进一步提升1.25倍的性能性价比。该方法有效缓解了内存瓶颈和通信开销，提升了LLM推理系统的整体性能和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.AR",
        "cs.DC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08192v1",
      "published_date": "2025-01-14 15:14:10 UTC",
      "updated_date": "2025-01-14 15:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:23:37.572958"
    },
    {
      "arxiv_id": "2501.08188v1",
      "title": "A Critical Synthesis of Uncertainty Quantification and Foundation Models in Monocular Depth Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Steven Landgraf",
        "Rongjun Qin",
        "Markus Ulrich"
      ],
      "abstract": "While recent foundation models have enabled significant breakthroughs in\nmonocular depth estimation, a clear path towards safe and reliable deployment\nin the real-world remains elusive. Metric depth estimation, which involves\npredicting absolute distances, poses particular challenges, as even the most\nadvanced foundation models remain prone to critical errors. Since quantifying\nthe uncertainty has emerged as a promising endeavor to address these\nlimitations and enable trustworthy deployment, we fuse five different\nuncertainty quantification methods with the current state-of-the-art\nDepthAnythingV2 foundation model. To cover a wide range of metric depth\ndomains, we evaluate their performance on four diverse datasets. Our findings\nidentify fine-tuning with the Gaussian Negative Log-Likelihood Loss (GNLL) as a\nparticularly promising approach, offering reliable uncertainty estimates while\nmaintaining predictive performance and computational efficiency on par with the\nbaseline, encompassing both training and inference time. By fusing uncertainty\nquantification and foundation models within the context of monocular depth\nestimation, this paper lays a critical foundation for future research aimed at\nimproving not only model performance but also its explainability. Extending\nthis critical synthesis of uncertainty quantification and foundation models\ninto other crucial tasks, such as semantic segmentation and pose estimation,\npresents exciting opportunities for safer and more reliable machine vision\nsystems.",
      "tldr_zh": "该论文对不确定性量化(Uncertainty Quantification)和基础模型(Foundation Models)在单目深度估计(Monocular Depth Estimation)中的应用进行了关键综合分析，旨在解决基础模型在预测绝对距离时的错误问题。研究者将五种不确定性量化方法与DepthAnythingV2模型融合，并在四个多样化数据集上评估其性能。结果显示，使用Gaussian Negative Log-Likelihood Loss (GNLL)进行微调是一种高效方法，能提供可靠的不确定性估计，同时维持预测性能和计算效率。该工作为提升模型的可解释性和可靠性奠定基础，并建议扩展到语义分割和姿态估计等其他任务，以推动更安全的机器视觉系统发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08188v1",
      "published_date": "2025-01-14 15:13:00 UTC",
      "updated_date": "2025-01-14 15:13:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:23:50.165816"
    },
    {
      "arxiv_id": "2501.08187v2",
      "title": "A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following",
      "title_zh": "一种多模态 AI 协opilot，用于单细胞分析并支持指令跟随",
      "authors": [
        "Yin Fang",
        "Xinle Deng",
        "Kangwei Liu",
        "Ningyu Zhang",
        "Jingyang Qian",
        "Penghui Yang",
        "Xiaohui Fan",
        "Huajun Chen"
      ],
      "abstract": "Large language models excel at interpreting complex natural language\ninstructions, enabling them to perform a wide range of tasks. In the life\nsciences, single-cell RNA sequencing (scRNA-seq) data serves as the \"language\nof cellular biology\", capturing intricate gene expression patterns at the\nsingle-cell level. However, interacting with this \"language\" through\nconventional tools is often inefficient and unintuitive, posing challenges for\nresearchers. To address these limitations, we present InstructCell, a\nmulti-modal AI copilot that leverages natural language as a medium for more\ndirect and flexible single-cell analysis. We construct a comprehensive\nmulti-modal instruction dataset that pairs text-based instructions with\nscRNA-seq profiles from diverse tissues and species. Building on this, we\ndevelop a multi-modal cell language architecture capable of simultaneously\ninterpreting and processing both modalities. InstructCell empowers researchers\nto accomplish critical tasks-such as cell type annotation, conditional\npseudo-cell generation, and drug sensitivity prediction-using straightforward\nnatural language commands. Extensive evaluations demonstrate that InstructCell\nconsistently meets or exceeds the performance of existing single-cell\nfoundation models, while adapting to diverse experimental conditions. More\nimportantly, InstructCell provides an accessible and intuitive tool for\nexploring complex single-cell data, lowering technical barriers and enabling\ndeeper biological insights.",
      "tldr_zh": "本文提出 InstructCell，一种多模态 AI 助手，用于单细胞 RNA 测序 (scRNA-seq) 分析，通过自然语言指令实现更直观和灵活的交互。研究构建了一个全面的多模态指令数据集，将文本指令与 scRNA-seq 数据配对，并开发了能同时处理文本和细胞数据的架构。InstructCell 支持关键任务，如细胞类型注释、条件伪细胞生成和药物敏感性预测，其性能在多种实验条件下优于现有模型，并降低了技术门槛，促进更深入的生物学洞察。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.HC",
        "cs.LG",
        "q-bio.CB"
      ],
      "primary_category": "cs.CL",
      "comment": "37 pages; 13 figures; Code: https://github.com/zjunlp/Instructcell,\n  Models: https://huggingface.co/zjunlp/Instructcell-chat,\n  https://huggingface.co/zjunlp/InstructCell-instruct",
      "pdf_url": "http://arxiv.org/pdf/2501.08187v2",
      "published_date": "2025-01-14 15:12:19 UTC",
      "updated_date": "2025-01-15 02:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:24:02.383913"
    },
    {
      "arxiv_id": "2501.08184v1",
      "title": "Assessing AI Adoption and Digitalization in SMEs: A Framework for Implementation",
      "title_zh": "翻译失败",
      "authors": [
        "Serena Proietti",
        "Roberto Magnani"
      ],
      "abstract": "The primary objective of this research is to examine the current state of\ndigitalization and the integration of artificial intelligence (AI) within small\nand medium-sized enterprises (SMEs) in Italy. There is a significant gap\nbetween SMEs and large corporations in their use of AI, with SMEs facing\nnumerous barriers to adoption. This study identifies critical drivers and\nobstacles to achieving intelligent transformation, proposing a framework model\nto address key challenges and provide actionable guidelines",
      "tldr_zh": "本研究考察了意大利中小企业(SMEs)中数字化和人工智能(AI)采用的现状，揭示了SMEs与大型企业之间在AI整合方面的显著差距，并识别了关键驱动因素和障碍。\n研究提出一个框架模型，旨在解决这些挑战，提供可操作的指导以促进SMEs的智能转型。\n这一框架有助于缩小数字化鸿沟，提升SMEs的竞争力和创新能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08184v1",
      "published_date": "2025-01-14 15:10:25 UTC",
      "updated_date": "2025-01-14 15:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:24:13.317138"
    },
    {
      "arxiv_id": "2501.08182v1",
      "title": "CG-MER: A Card Game-based Multimodal dataset for Emotion Recognition",
      "title_zh": "CG-MER：基于纸牌游戏的多",
      "authors": [
        "Nessrine Farhat",
        "Amine Bohi",
        "Leila Ben Letaifa",
        "Rim Slama"
      ],
      "abstract": "The field of affective computing has seen significant advancements in\nexploring the relationship between emotions and emerging technologies. This\npaper presents a novel and valuable contribution to this field with the\nintroduction of a comprehensive French multimodal dataset designed specifically\nfor emotion recognition. The dataset encompasses three primary modalities:\nfacial expressions, speech, and gestures, providing a holistic perspective on\nemotions. Moreover, the dataset has the potential to incorporate additional\nmodalities, such as Natural Language Processing (NLP) to expand the scope of\nemotion recognition research. The dataset was curated through engaging\nparticipants in card game sessions, where they were prompted to express a range\nof emotions while responding to diverse questions. The study included 10\nsessions with 20 participants (9 females and 11 males). The dataset serves as a\nvaluable resource for furthering research in emotion recognition and provides\nan avenue for exploring the intricate connections between human emotions and\ndigital technologies.",
      "tldr_zh": "本文介绍了 CG-MER，一种基于纸牌游戏的多模态数据集，旨在推进情感识别（Emotion Recognition）研究。该数据集涵盖面部表情、语音和手势三种主要模态，通过 20 名参与者（9 女、11 男）在 10 个会话中回应问题并表达各种情感来收集数据。数据集还具有扩展潜力，如整合 Natural Language Processing (NLP)，为探索人类情感与数字技术的关联提供宝贵资源。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 figures and 4 tables. Sixteenth International Conference\n  on Machine Vision (ICMV 2023), Yerevan, Armenia",
      "pdf_url": "http://arxiv.org/pdf/2501.08182v1",
      "published_date": "2025-01-14 15:08:56 UTC",
      "updated_date": "2025-01-14 15:08:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:24:25.625097"
    },
    {
      "arxiv_id": "2501.08169v1",
      "title": "Revolutionizing Communication with Deep Learning and XAI for Enhanced Arabic Sign Language Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Mazen Balat",
        "Rewaa Awaad",
        "Ahmed B. Zaky",
        "Salah A. Aly"
      ],
      "abstract": "This study introduces an integrated approach to recognizing Arabic Sign\nLanguage (ArSL) using state-of-the-art deep learning models such as\nMobileNetV3, ResNet50, and EfficientNet-B2. These models are further enhanced\nby explainable AI (XAI) techniques to boost interpretability. The ArSL2018 and\nRGB Arabic Alphabets Sign Language (AASL) datasets are employed, with\nEfficientNet-B2 achieving peak accuracies of 99.48\\% and 98.99\\%, respectively.\nKey innovations include sophisticated data augmentation methods to mitigate\nclass imbalance, implementation of stratified 5-fold cross-validation for\nbetter generalization, and the use of Grad-CAM for clear model decision\ntransparency. The proposed system not only sets new benchmarks in recognition\naccuracy but also emphasizes interpretability, making it suitable for\napplications in healthcare, education, and inclusive communication\ntechnologies.",
      "tldr_zh": "本研究提出了一种整合方法，利用深度学习模型如MobileNetV3、ResNet50和EfficientNet-B2来提升阿拉伯手语(ArSL)识别的准确性，并通过XAI技术增强模型的可解释性。创新点包括采用高级数据增强方法缓解类别不平衡、分层5折交叉验证提高泛化能力，以及使用Grad-CAM实现决策透明度。实验结果显示，EfficientNet-B2在ArSL2018和AASL数据集上分别达到99.48%和98.99%的峰值准确率，为医疗、教育和包容性通信技术等领域设置了新的基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 25 figures, 16 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.08169v1",
      "published_date": "2025-01-14 14:49:49 UTC",
      "updated_date": "2025-01-14 14:49:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:24:38.076736"
    },
    {
      "arxiv_id": "2501.08168v1",
      "title": "LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and Dual-Process Thinking",
      "title_zh": "Leap",
      "authors": [
        "Yukai Ma",
        "Tiantian Wei",
        "Naiting Zhong",
        "Jianbiao Mei",
        "Tao Hu",
        "Licheng Wen",
        "Xuemeng Yang",
        "Botian Shi",
        "Yong Liu"
      ],
      "abstract": "While autonomous driving technology has made remarkable strides, data-driven\napproaches still struggle with complex scenarios due to their limited reasoning\ncapabilities. Meanwhile, knowledge-driven autonomous driving systems have\nevolved considerably with the popularization of visual language models. In this\npaper, we propose LeapVAD, a novel method based on cognitive perception and\ndual-process thinking. Our approach implements a human-attentional mechanism to\nidentify and focus on critical traffic elements that influence driving\ndecisions. By characterizing these objects through comprehensive attributes -\nincluding appearance, motion patterns, and associated risks - LeapVAD achieves\nmore effective environmental representation and streamlines the decision-making\nprocess. Furthermore, LeapVAD incorporates an innovative dual-process\ndecision-making module miming the human-driving learning process. The system\nconsists of an Analytic Process (System-II) that accumulates driving experience\nthrough logical reasoning and a Heuristic Process (System-I) that refines this\nknowledge via fine-tuning and few-shot learning. LeapVAD also includes\nreflective mechanisms and a growing memory bank, enabling it to learn from past\nmistakes and continuously improve its performance in a closed-loop environment.\nTo enhance efficiency, we develop a scene encoder network that generates\ncompact scene representations for rapid retrieval of relevant driving\nexperiences. Extensive evaluations conducted on two leading autonomous driving\nsimulators, CARLA and DriveArena, demonstrate that LeapVAD achieves superior\nperformance compared to camera-only approaches despite limited training data.\nComprehensive ablation studies further emphasize its effectiveness in\ncontinuous learning and domain adaptation. Project page:\nhttps://pjlab-adg.github.io/LeapVAD/.",
      "tldr_zh": "这篇论文提出LeapVAD，一种基于Cognitive Perception和Dual-Process Thinking的自动驾驶方法，以解决数据驱动系统在复杂场景中的推理能力不足问题。LeapVAD采用人类注意力机制识别关键交通元素，并通过Analytic Process (System-II)进行逻辑推理积累经验，以及Heuristic Process (System-I)通过微调和少样本学习精炼知识，同时整合反思机制和记忆库以实现持续改进。实验结果显示，在CARLA和DriveArena模拟器上，LeapVAD在有限训练数据下比仅摄像头方法表现出色，并在持续学习和领域适配方面表现出显著优势。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08168v1",
      "published_date": "2025-01-14 14:49:45 UTC",
      "updated_date": "2025-01-14 14:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:24:51.191307"
    },
    {
      "arxiv_id": "2501.08167v2",
      "title": "Potential and Perils of Large Language Models as Judges of Unstructured Textual Data",
      "title_zh": "翻译失败",
      "authors": [
        "Rewina Bedemariam",
        "Natalie Perez",
        "Sreyoshi Bhaduri",
        "Satya Kapoor",
        "Alex Gil",
        "Elizabeth Conjar",
        "Ikkei Itoku",
        "David Theil",
        "Aman Chadha",
        "Naumaan Nayyar"
      ],
      "abstract": "Rapid advancements in large language models have unlocked remarkable\ncapabilities when it comes to processing and summarizing unstructured text\ndata. This has implications for the analysis of rich, open-ended datasets, such\nas survey responses, where LLMs hold the promise of efficiently distilling key\nthemes and sentiments. However, as organizations increasingly turn to these\npowerful AI systems to make sense of textual feedback, a critical question\narises, can we trust LLMs to accurately represent the perspectives contained\nwithin these text based datasets? While LLMs excel at generating human-like\nsummaries, there is a risk that their outputs may inadvertently diverge from\nthe true substance of the original responses. Discrepancies between the\nLLM-generated outputs and the actual themes present in the data could lead to\nflawed decision-making, with far-reaching consequences for organizations. This\nresearch investigates the effectiveness of LLM-as-judge models to evaluate the\nthematic alignment of summaries generated by other LLMs. We utilized an\nAnthropic Claude model to generate thematic summaries from open-ended survey\nresponses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as\njudges. This LLM-as-judge approach was compared to human evaluations using\nCohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable\nalternative to traditional human centric evaluation methods. Our findings\nreveal that while LLM-as-judge offer a scalable solution comparable to human\nraters, humans may still excel at detecting subtle, context-specific nuances.\nOur research contributes to the growing body of knowledge on AI assisted text\nanalysis. Further, we provide recommendations for future research, emphasizing\nthe need for careful consideration when generalizing LLM-as-judge models across\nvarious contexts and use cases.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 作为非结构化文本数据判断者的潜力和风险，特别关注其在总结开放式调查响应时是否能准确捕捉真实主题和情感。研究方法包括使用 Anthropic Claude 生成主题摘要，然后由 Amazon's Titan Express、Nova Pro 和 Meta's Llama 作为判断者评估其主题一致性，并通过 Cohen's kappa、Spearman's rho 和 Krippendorff's alpha 与人类评估进行比较。结果表明，LLM-as-judge 提供了一种可扩展的替代方案，与人类评估性能相当，但人类在检测微妙、上下文特定的细微差别上更具优势。该研究为 AI 辅助文本分析贡献了新见解，并建议在不同情境中谨慎推广此类模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 1 appendix",
      "pdf_url": "http://arxiv.org/pdf/2501.08167v2",
      "published_date": "2025-01-14 14:49:14 UTC",
      "updated_date": "2025-01-20 17:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:25:03.207522"
    },
    {
      "arxiv_id": "2501.08165v1",
      "title": "I Can Find You in Seconds! Leveraging Large Language Models for Code Authorship Attribution",
      "title_zh": "我能在几秒内找到你！利用大型语言模型进行代码作者归属",
      "authors": [
        "Soohyeon Choi",
        "Yong Kiam Tan",
        "Mark Huasong Meng",
        "Mohamed Ragab",
        "Soumik Mondal",
        "David Mohaisen",
        "Khin Mi Mi Aung"
      ],
      "abstract": "Source code authorship attribution is important in software forensics,\nplagiarism detection, and protecting software patch integrity. Existing\ntechniques often rely on supervised machine learning, which struggles with\ngeneralization across different programming languages and coding styles due to\nthe need for large labeled datasets. Inspired by recent advances in natural\nlanguage authorship analysis using large language models (LLMs), which have\nshown exceptional performance without task-specific tuning, this paper explores\nthe use of LLMs for source code authorship attribution.\n  We present a comprehensive study demonstrating that state-of-the-art LLMs can\nsuccessfully attribute source code authorship across different languages. LLMs\ncan determine whether two code snippets are written by the same author with\nzero-shot prompting, achieving a Matthews Correlation Coefficient (MCC) of\n0.78, and can attribute code authorship from a small set of reference code\nsnippets via few-shot learning, achieving MCC of 0.77. Additionally, LLMs show\nsome adversarial robustness against misattribution attacks.\n  Despite these capabilities, we found that naive prompting of LLMs does not\nscale well with a large number of authors due to input token limitations. To\naddress this, we propose a tournament-style approach for large-scale\nattribution. Evaluating this approach on datasets of C++ (500 authors, 26,355\nsamples) and Java (686 authors, 55,267 samples) code from GitHub, we achieve\nclassification accuracy of up to 65% for C++ and 68.7% for Java using only one\nreference per author. These results open new possibilities for applying LLMs to\ncode authorship attribution in cybersecurity and software engineering.",
      "tldr_zh": "本文研究利用大型语言模型 (LLMs) 进行源代码作者归属，解决现有监督机器学习方法在不同编程语言和编码风格上的泛化难题，无需任务特定微调。实验显示，LLMs 通过零样本提示可判断两个代码片段是否由同一作者编写，Matthews Correlation Coefficient (MCC) 达 0.78；通过少样本学习，使用少量参考代码实现作者归属，MCC 达 0.77，并对对抗性攻击表现出一定鲁棒性。为应对大规模作者的输入限制，论文提出锦标赛式方法，在 GitHub 的 C++ (500 作者) 和 Java (686 作者) 数据集上分别实现 65% 和 68.7% 的分类准确率。这些结果为 LLMs 在网络安全和软件工程中的作者归属应用开辟了新途径。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 5 figures,",
      "pdf_url": "http://arxiv.org/pdf/2501.08165v1",
      "published_date": "2025-01-14 14:46:19 UTC",
      "updated_date": "2025-01-14 14:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:25:16.063906"
    },
    {
      "arxiv_id": "2501.08155v1",
      "title": "FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Nurit Cohen-Inger",
        "Lior Rokach",
        "Bracha Shapira",
        "Seffi Cohen"
      ],
      "abstract": "Algorithmic decision-making has become deeply ingrained in many domains, yet\nbiases in machine learning models can still produce discriminatory outcomes,\noften harming unprivileged groups. Achieving fair classification is inherently\nchallenging, requiring a careful balance between predictive performance and\nethical considerations. We present FairTTTS, a novel post-processing bias\nmitigation method inspired by the Tree Test Time Simulation (TTTS) method.\nOriginally developed to enhance accuracy and robustness against adversarial\ninputs through probabilistic decision-path adjustments, TTTS serves as the\nfoundation for FairTTTS. By building on this accuracy-enhancing technique,\nFairTTTS mitigates bias and improves predictive performance. FairTTTS uses a\ndistance-based heuristic to adjust decisions at protected attribute nodes,\nensuring fairness for unprivileged samples. This fairness-oriented adjustment\noccurs as a post-processing step, allowing FairTTTS to be applied to\npre-trained models, diverse datasets, and various fairness metrics without\nretraining. Extensive evaluation on seven benchmark datasets shows that\nFairTTTS outperforms traditional methods in fairness improvement, achieving a\n20.96% average increase over the baseline compared to 18.78% for related work,\nand further enhances accuracy by 0.55%. In contrast, competing methods\ntypically reduce accuracy by 0.42%. These results confirm that FairTTTS\neffectively promotes more equitable decision-making while simultaneously\nimproving predictive performance.",
      "tldr_zh": "这篇论文提出了FairTTTS，一种基于Tree Test Time Simulation (TTTS)的后处理方法，用于提升分类任务的公平性。FairTTTS通过距离-based heuristic调整受保护属性节点的决策路径，缓解算法偏见，同时适用于预训练模型、多样数据集和各种fairness metrics，而无需重新训练。在七个基准数据集上的实验显示，FairTTTS平均提高了20.96%的公平性指标，比相关工作高出2.18%，并提升了0.55%的预测准确性，而竞争方法通常会降低准确性0.42%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08155v1",
      "published_date": "2025-01-14 14:29:36 UTC",
      "updated_date": "2025-01-14 14:29:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:25:25.935069"
    },
    {
      "arxiv_id": "2501.08149v1",
      "title": "Multiple-Input Variational Auto-Encoder for Anomaly Detection in Heterogeneous Data",
      "title_zh": "多输入变分自编码器用于异构数据的异常检测",
      "authors": [
        "Phai Vu Dinh",
        "Diep N. Nguyen",
        "Dinh Thai Hoang",
        "Quang Uy Nguyen",
        "Eryk Dutkiewicz"
      ],
      "abstract": "Anomaly detection (AD) plays a pivotal role in AI applications, e.g., in\nclassification, and intrusion/threat detection in cybersecurity. However, most\nexisting methods face challenges of heterogeneity amongst feature subsets posed\nby non-independent and identically distributed (non-IID) data. We propose a\nnovel neural network model called Multiple-Input Auto-Encoder for AD (MIAEAD)\nto address this. MIAEAD assigns an anomaly score to each feature subset of a\ndata sample to indicate its likelihood of being an anomaly. This is done by\nusing the reconstruction error of its sub-encoder as the anomaly score. All\nsub-encoders are then simultaneously trained using unsupervised learning to\ndetermine the anomaly scores of feature subsets. The final AUC of MIAEAD is\ncalculated for each sub-dataset, and the maximum AUC obtained among the\nsub-datasets is selected. To leverage the modelling of the distribution of\nnormal data to identify anomalies of the generative models, we develop a novel\nneural network architecture/model called Multiple-Input Variational\nAuto-Encoder (MIVAE). MIVAE can process feature subsets through its\nsub-encoders before learning distribution of normal data in the latent space.\nThis allows MIVAE to identify anomalies that deviate from the learned\ndistribution. We theoretically prove that the difference in the average anomaly\nscore between normal samples and anomalies obtained by the proposed MIVAE is\ngreater than that of the Variational Auto-Encoder (VAEAD), resulting in a\nhigher AUC for MIVAE. Extensive experiments on eight real-world anomaly\ndatasets demonstrate the superior performance of MIAEAD and MIVAE over\nconventional methods and the state-of-the-art unsupervised models, by up to 6%\nin terms of AUC score. Alternatively, MIAEAD and MIVAE have a high AUC when\napplied to feature subsets with low heterogeneity based on the coefficient of\nvariation (CV) score.",
      "tldr_zh": "本文提出两种新模型——MIAEAD 和 MIVAE，用于处理非独立同分布（non-IID）数据中特征子集异质性的异常检测（Anomaly Detection）。MIAEAD 通过子编码器的重构错误为每个特征子集分配异常分数，并使用无监督学习同时训练所有子编码器，以计算子数据集的 AUC 分数。MIVAE 基于 Variational Auto-Encoder（VAE），通过子编码器处理特征子集并学习正常数据的潜在空间分布，理论证明其异常分数差异大于传统 VAE，从而实现更高的 AUC。在八个真实世界数据集上的实验显示，MIAEAD 和 MIVAE 比现有方法提高高达 6% 的 AUC 得分，尤其在异质性较低的特征子集上表现突出。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08149v1",
      "published_date": "2025-01-14 14:25:10 UTC",
      "updated_date": "2025-01-14 14:25:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:25:38.546196"
    },
    {
      "arxiv_id": "2501.08145v1",
      "title": "Refusal Behavior in Large Language Models: A Nonlinear Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Hildebrandt",
        "Andreas Maier",
        "Patrick Krauss",
        "Achim Schilling"
      ],
      "abstract": "Refusal behavior in large language models (LLMs) enables them to decline\nresponding to harmful, unethical, or inappropriate prompts, ensuring alignment\nwith ethical standards. This paper investigates refusal behavior across six\nLLMs from three architectural families. We challenge the assumption of refusal\nas a linear phenomenon by employing dimensionality reduction techniques,\nincluding PCA, t-SNE, and UMAP. Our results reveal that refusal mechanisms\nexhibit nonlinear, multidimensional characteristics that vary by model\narchitecture and layer. These findings highlight the need for nonlinear\ninterpretability to improve alignment research and inform safer AI deployment\nstrategies.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）中的拒绝行为（refusal behavior），即模型拒绝响应有害、不道德或不适当提示以维护伦理标准，并调查了六个来自三个架构家族的 LLMs。研究者使用 PCA、t-SNE 和 UMAP 等降维技术，挑战了拒绝行为作为线性现象的假设，结果显示其是非线性的、多维度的，并受模型架构和层的影响。这些发现强调了引入非线性可解释性来改进对齐研究（alignment research）和制定更安全的 AI 部署策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08145v1",
      "published_date": "2025-01-14 14:23:18 UTC",
      "updated_date": "2025-01-14 14:23:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:25:50.287942"
    },
    {
      "arxiv_id": "2501.08139v1",
      "title": "EEG-ReMinD: Enhancing Neurodegenerative EEG Decoding through Self-Supervised State Reconstruction-Primed Riemannian Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Zirui Wang",
        "Zhenxi Song",
        "Yi Guo",
        "Yuxin Liu",
        "Guoyang Xu",
        "Min Zhang",
        "Zhiguo Zhang"
      ],
      "abstract": "The development of EEG decoding algorithms confronts challenges such as data\nsparsity, subject variability, and the need for precise annotations, all of\nwhich are vital for advancing brain-computer interfaces and enhancing the\ndiagnosis of diseases. To address these issues, we propose a novel two-stage\napproach named Self-Supervised State Reconstruction-Primed Riemannian Dynamics\n(EEG-ReMinD) , which mitigates reliance on supervised learning and integrates\ninherent geometric features. This approach efficiently handles EEG data\ncorruptions and reduces the dependency on labels. EEG-ReMinD utilizes\nself-supervised and geometric learning techniques, along with an attention\nmechanism, to analyze the temporal dynamics of EEG features within the\nframework of Riemannian geometry, referred to as Riemannian dynamics.\nComparative analyses on both intact and corrupted datasets from two different\nneurodegenerative disorders underscore the enhanced performance of EEG-ReMinD.",
      "tldr_zh": "本研究针对 EEG 解码面临的挑战，如数据稀疏、个体变异和标注需求，提出了一种新型两阶段方法 EEG-ReMinD，以减少对监督学习的依赖并整合固有几何特征。该方法结合自监督状态重建和 Riemannian Dynamics，利用注意力机制分析 EEG 特征的时序动态，从而高效处理数据损坏问题。实验结果显示，在两种神经退行性疾病数据集上，EEG-ReMinD 显著提升了解码性能，尤其在完整和损坏数据上表现出色。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08139v1",
      "published_date": "2025-01-14 14:19:40 UTC",
      "updated_date": "2025-01-14 14:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:26:02.117731"
    },
    {
      "arxiv_id": "2501.08134v1",
      "title": "An Empirical Wall-Pressure Spectrum Model for Aeroacoustic Predictions Based on Symbolic Regression",
      "title_zh": "基于符号回归的经验性壁压谱模型用于航空声学预测",
      "authors": [
        "Laura Botero Bolívar",
        "David Huergo",
        "Fernanda L. dos Santos",
        "Cornelis H. Venner",
        "Leandro D. de Santana",
        "Esteban Ferrer"
      ],
      "abstract": "Fast-turn around methods to predict airfoil trailing-edge noise are crucial\nfor incorporating noise limitations into design optimization loops of several\napplications. Among these aeroacoustic predictive models, Amiet's theory offers\nthe best balance between accuracy and simplicity. The accuracy of the model\nrelies heavily on precise wall-pressure spectrum predictions, which are often\nbased on single-equation formulations with adjustable parameters. These\nparameters are calibrated for particular airfoils and flow conditions and\nconsequently tend to fail when applied outside their calibration range. This\npaper introduces a new wall-pressure spectrum empirical model designed to\nenhance the robustness and accuracy of current state-of-the-art predictions\nwhile widening the range of applicability of the model to different airfoils\nand flow conditions. The model is developed using AI-based symbolic regression\nvia a genetic-algorithm-based approach, and applied to a dataset of\nwall-pressure fluctuations measured on NACA 0008 and NACA 63018 airfoils at\nmultiple angles of attack and inflow velocities, covering turbulent boundary\nlayers with both adverse and favorable pressure gradients. Validation against\nexperimental data (outside the training dataset) demonstrates the robustness of\nthe model compared to well-accepted semi-empirical models. Finally, the model\nis integrated with Amiet's theory to predict the aeroacoustic noise of a\nfull-scale wind turbine, showing good agreement with experimental measurements.",
      "tldr_zh": "该论文提出了一种基于符号回归(symbolic regression)的经验壁压谱(wall-pressure spectrum)模型，旨在提升空气动力声学(aeroacoustic)预测的鲁棒性和准确性，特别是针对翼型尾缘噪声的快速预测问题。新模型采用遗传算法(genetic-algorithm-based)方法，利用NACA 0008和NACA 63018翼型的实验数据训练，涵盖多种攻角、流入速度以及逆压梯度和顺压梯度的湍流边界层。相比传统半经验模型，该模型在外部验证数据上表现出色，并与Amiet's theory整合后，成功预测全尺寸风力涡轮机的噪声，与实验测量结果高度一致。",
      "categories": [
        "physics.flu-dyn",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.flu-dyn",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08134v1",
      "published_date": "2025-01-14 14:14:22 UTC",
      "updated_date": "2025-01-14 14:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:26:14.423236"
    },
    {
      "arxiv_id": "2501.08120v1",
      "title": "In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR",
      "title_zh": "原位图推理和知识扩展使用 Graph-PReFLexOR",
      "authors": [
        "Markus J. Buehler"
      ],
      "abstract": "The pursuit of automated scientific discovery has fueled progress from\nsymbolic logic to modern AI, forging new frontiers in reasoning and pattern\nrecognition. Transformers function as potential systems, where every possible\nrelationship remains latent potentiality until tasks impose constraints, akin\nto measurement. Yet, refining their sampling requires more than probabilistic\nselection: solutions must conform to specific structures or rules, ensuring\nconsistency and the invocation of general principles. We present\nGraph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for\nExploratory Optimization of Reasoning), a framework that combines graph\nreasoning with symbolic abstraction to dynamically expand domain knowledge.\nInspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a\nstructured mapping, where tasks yield knowledge graphs, abstract patterns, and\nultimately, final answers. Inspired by category theory, it encodes concepts as\nnodes and their relationships as edges, supporting hierarchical inference and\nadaptive learning through isomorphic representations. Demonstrations include\nhypothesis generation, materials design, and creative reasoning, such as\ndiscovering relationships between mythological concepts like 'thin places' with\nmaterials science. We propose a 'knowledge garden growth' strategy that\nintegrates insights across domains, promoting interdisciplinary connections.\nResults with a 3-billion-parameter Graph-PReFLexOR model show superior\nreasoning depth and adaptability, underscoring the potential for transparent,\nmultidisciplinary AI-driven discovery. It lays the groundwork for general\nautonomous reasoning solutions.",
      "tldr_zh": "本研究提出 Graph-PReFLexOR 框架，用于实现原位图推理和知识扩展，通过结合图推理与符号抽象，动态扩展领域知识。框架受强化学习启发，将推理定义为结构化映射，生成知识图谱、抽象模式和最终答案；同时借鉴范畴论，将概念编码为节点和边，支持层次化推理、自适应学习和同构表示。演示应用包括假设生成、材料设计以及创意推理（如将“thin places”等神话概念与材料科学关联），并采用“知识花园增长”策略整合跨领域见解。实验结果显示，使用 3 亿参数的 Graph-PReFLexOR 模型在推理深度和适应性上优于基线，为透明的多学科 AI 驱动科学发现奠定基础。",
      "categories": [
        "cs.AI",
        "cond-mat.dis-nn",
        "cond-mat.mtrl-sci",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08120v1",
      "published_date": "2025-01-14 13:52:41 UTC",
      "updated_date": "2025-01-14 13:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:26:26.405782"
    },
    {
      "arxiv_id": "2501.08109v3",
      "title": "Data-driven inventory management for new products: An adjusted Dyna-$Q$ approach with transfer learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinye Qu",
        "Longxiao Liu",
        "Wenjie Huang"
      ],
      "abstract": "In this paper, we propose a novel reinforcement learning algorithm for\ninventory management of newly launched products with no historical demand\ninformation. The algorithm follows the classic Dyna-$Q$ structure, balancing\nthe model-free and model-based approaches, while accelerating the training\nprocess of Dyna-$Q$ and mitigating the model discrepancy generated by the\nmodel-based feedback. Based on the idea of transfer learning, warm-start\ninformation from the demand data of existing similar products can be\nincorporated into the algorithm to further stabilize the early-stage training\nand reduce the variance of the estimated optimal policy. Our approach is\nvalidated through a case study of bakery inventory management with real data.\nThe adjusted Dyna-$Q$ shows up to a 23.7\\% reduction in average daily cost\ncompared with $Q$-learning, and up to a 77.5\\% reduction in training time\nwithin the same horizon compared with classic Dyna-$Q$. By using transfer\nlearning, it can be found that the adjusted Dyna-$Q$ has the lowest total cost,\nlowest variance in total cost, and relatively low shortage percentages among\nall the benchmarking algorithms under a 30-day testing.",
      "tldr_zh": "本论文提出了一种调整后的 Dyna-$Q$ 算法，用于新产品库存管理，这些产品缺乏历史需求数据。该算法在经典 Dyna-$Q$ 结构基础上，结合 transfer learning 的理念，利用现有类似产品的需求数据来加速训练过程、稳定早期训练并减少最优策略估计的方差。实验通过面包店库存管理的真实案例验证，结果显示，与 Q-learning 相比，平均每日成本降低多达 23.7%；与经典 Dyna-$Q$ 相比，训练时间减少多达 77.5%。此外，使用 transfer learning 后，该算法在 30 天测试中实现了最低的总成本、最低的成本方差和相对较低的短缺率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "7 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08109v3",
      "published_date": "2025-01-14 13:40:08 UTC",
      "updated_date": "2025-03-10 06:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:26:39.080704"
    },
    {
      "arxiv_id": "2501.10448v1",
      "title": "Towards Lightweight Time Series Forecasting: a Patch-wise Transformer with Weak Data Enriching",
      "title_zh": "翻译失败",
      "authors": [
        "Meng Wang",
        "Jintao Yang",
        "Bin Yang",
        "Hui Li",
        "Tongxin Gong",
        "Bo Yang",
        "Jiangtao Cui"
      ],
      "abstract": "Patch-wise Transformer based time series forecasting achieves superior\naccuracy. However, this superiority relies heavily on intricate model design\nwith massive parameters, rendering both training and inference expensive, thus\npreventing their deployments on edge devices with limited resources and low\nlatency requirements. In addition, existing methods often work in an\nautoregressive manner, which take into account only historical values, but\nignore valuable, easy-to-obtain context information, such as weather forecasts,\ndate and time of day. To contend with the two limitations, we propose\nLiPFormer, a novel Lightweight Patch-wise Transformer with weak data enriching.\nFirst, to simplify the Transformer backbone, LiPFormer employs a novel\nlightweight cross-patch attention and a linear transformation-based attention\nto eliminate Layer Normalization and Feed Forward Network, two heavy components\nin existing Transformers. Second, we propose a lightweight, weak data enriching\nmodule to provide additional, valuable weak supervision to the training. It\nenhances forecasting accuracy without significantly increasing model complexity\nas it does not involve expensive, human-labeling but using easily accessible\ncontext information. This facilitates the weak data enriching to plug-and-play\non existing models. Extensive experiments on nine benchmark time series\ndatasets demonstrate that LiPFormer outperforms state-of-the-art methods in\naccuracy, while significantly reducing parameter scale, training duration, and\nGPU memory usage. Deployment on an edge device reveals that LiPFormer takes\nonly 1/3 inference time compared to classic Transformers. In addition, we\ndemonstrate that the weak data enriching can integrate seamlessly into various\nTransformer based models to enhance their accuracy, suggesting its generality.",
      "tldr_zh": "该研究针对时间序列预测中Patch-wise Transformer模型的复杂性和忽略上下文信息的问题，提出了一种轻量级框架LiPFormer。LiPFormer通过引入轻量级的cross-patch attention和基于线性变换的attention机制，简化Transformer骨干结构，消除了Layer Normalization和Feed Forward Network等繁重组件，从而减少参数规模和计算资源。实验在九个基准数据集上显示，LiPFormer在准确性上优于现有方法，同时显著降低训练时间、GPU内存使用和推理时间（在边缘设备上仅为经典Transformer的1/3）；此外，其weak data enriching模块可无缝集成到其他Transformer模型中，提升整体泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 41st IEEE International Conference on Data\n  Engineering (ICDE 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.10448v1",
      "published_date": "2025-01-14 13:35:03 UTC",
      "updated_date": "2025-01-14 13:35:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:26:50.287867"
    },
    {
      "arxiv_id": "2501.08102v2",
      "title": "Consistency of Responses and Continuations Generated by Large Language Models on Social Media",
      "title_zh": "大型语言模型在社交媒体上生成响应和延续的一致性",
      "authors": [
        "Wenlu Fan",
        "Yuqi Zhu",
        "Chenyang Wang",
        "Bin Wang",
        "Wentao Xu"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using two open-source models: Gemma and Llama.\nBy analyzing climate change discussions from Twitter and Reddit, we examine\nemotional transitions, intensity patterns, and semantic similarity between\nhuman-authored and LLM-generated content. Our findings reveal that while both\nmodels maintain high semantic coherence, they exhibit distinct emotional\npatterns: Gemma shows a tendency toward negative emotion amplification,\nparticularly anger, while maintaining certain positive emotions like optimism.\nLlama demonstrates superior emotional preservation across a broader spectrum of\naffects. Both models systematically generate responses with attenuated\nemotional intensity compared to human-authored content and show a bias toward\npositive emotions in response tasks. Additionally, both models maintain strong\nsemantic similarity with original texts, though performance varies between\ncontinuation and response tasks. These findings provide insights into LLMs'\nemotional and semantic processing capabilities, with implications for their\ndeployment in social media contexts and human-AI interaction design.",
      "tldr_zh": "该研究评估了 Large Language Models (LLMs) 在社交媒体上的情感一致性和语义连贯性，使用 Gemma 和 Llama 模型，通过分析 Twitter 和 Reddit 上的气候变化讨论来考察情感过渡、强度模式及语义相似性。结果表明，Gemma 倾向于放大负面情绪如愤怒，但保留某些正面情绪，而 Llama 在更广泛的情感谱系上表现出色；两者在生成响应时均会减弱情感强度并偏向正面情绪。总体上，模型保持了高语义相似性，但续写和响应任务的性能有所差异，为 LLMs 在社交媒体应用和人机交互设计提供了关键洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08102v2",
      "published_date": "2025-01-14 13:19:47 UTC",
      "updated_date": "2025-01-15 18:10:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:27:03.114888"
    },
    {
      "arxiv_id": "2501.08097v1",
      "title": "Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features",
      "title_zh": "翻译失败",
      "authors": [
        "E. Sarfati",
        "A. Bône",
        "M-M. Rohé",
        "C. Aubé",
        "M. Ronot",
        "P. Gori",
        "I. Bloch"
      ],
      "abstract": "Hepatocellular carcinoma is the most spread primary liver cancer across the\nworld ($\\sim$80\\% of the liver tumors). The gold standard for HCC diagnosis is\nliver biopsy. However, in the clinical routine, expert radiologists provide a\nvisual diagnosis by interpreting hepatic CT-scans according to a standardized\nprotocol, the LI-RADS, which uses five radiological criteria with an associated\ndecision tree. In this paper, we propose an automatic approach to predict\nhistology-proven HCC from CT images in order to reduce radiologists'\ninter-variability. We first show that standard deep learning methods fail to\naccurately predict HCC from CT-scans on a challenging database, and propose a\ntwo-step approach inspired by the LI-RADS system to improve the performance. We\nachieve improvements from 6 to 18 points of AUC with respect to deep learning\nbaselines trained with different architectures. We also provide clinical\nvalidation of our method, achieving results that outperform non-expert\nradiologists and are on par with expert ones.",
      "tldr_zh": "该研究针对肝细胞癌（HCC），提出了一种自动分类方法，利用深度学习（deep learning）和手工制作的放射学特征（handcrafted radiological features）来分析3D CT-scans，从而减少放射科医生间的变异性。该方法受LI-RADS协议启发，采用两步流程，首先识别关键放射学标准，然后进行预测，提高了HCC诊断的准确性。实验结果显示，与标准深度学习基线相比，AUC提升了6到18点，并在临床验证中超过了非专家放射科医生，与专家水平相当。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IEEE ISBI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08097v1",
      "published_date": "2025-01-14 13:10:29 UTC",
      "updated_date": "2025-01-14 13:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:27:15.242265"
    },
    {
      "arxiv_id": "2501.08096v2",
      "title": "Hybrid Action Based Reinforcement Learning for Multi-Objective Compatible Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Guizhe Jin",
        "Zhuoren Li",
        "Bo Leng",
        "Wei Han",
        "Lu Xiong",
        "Chen Sun"
      ],
      "abstract": "Reinforcement Learning (RL) has shown excellent performance in solving\ndecision-making and control problems of autonomous driving, which is\nincreasingly applied in diverse driving scenarios. However, driving is a\nmulti-attribute problem, leading to challenges in achieving multi-objective\ncompatibility for current RL methods, especially in both policy execution and\npolicy iteration. On the one hand, the common action space structure with\nsingle action type limits driving flexibility or results in large behavior\nfluctuations during policy execution. On the other hand, the multi-attribute\nweighted single reward function result in the agent's disproportionate\nattention to certain objectives during policy iterations. To this end, we\npropose a Multi-objective Ensemble-Critic reinforcement learning method with\nHybrid Parametrized Action for multi-objective compatible autonomous driving.\nSpecifically, a parameterized action space is constructed to generate hybrid\ndriving actions, combining both abstract guidance and concrete control\ncommands. A multi-objective critics architecture is constructed considering\nmultiple attribute rewards, to ensure simultaneously focusing on different\ndriving objectives. Additionally, uncertainty-based exploration strategy is\nintroduced to help the agent faster approach viable driving policy. The\nexperimental results in both the simulated traffic environment and the HighD\ndataset demonstrate that our method can achieve multi-objective compatible\nautonomous driving in terms of driving efficiency, action consistency, and\nsafety. It enhances the general performance of the driving while significantly\nincreasing training efficiency.",
      "tldr_zh": "这篇论文针对自动驾驶的多目标兼容性挑战，提出了一种基于 Hybrid Parametrized Action 的 Multi-objective Ensemble-Critic Reinforcement Learning 方法，以解决单一行动空间和奖励函数导致的灵活性不足和目标偏差问题。该方法通过构建参数化行动空间生成混合驾驶行动（结合抽象指导和具体控制命令），并采用多目标批评者架构和不确定性探索策略，确保代理同时关注驾驶效率、安全性和一致性。实验在模拟交通环境和 HighD 数据集上验证，该方法显著提高了整体驾驶性能并提升了训练效率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "12 pages, 9 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.08096v2",
      "published_date": "2025-01-14 13:10:13 UTC",
      "updated_date": "2025-03-28 14:49:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:27:26.470281"
    },
    {
      "arxiv_id": "2501.08090v1",
      "title": "Hierarchical Autoscaling for Large Language Model Serving with Chiron",
      "title_zh": "翻译失败",
      "authors": [
        "Archit Patke",
        "Dhemath Reddy",
        "Saurabh Jha",
        "Chandra Narayanaswami",
        "Zbigniew Kalbarczyk",
        "Ravishankar Iyer"
      ],
      "abstract": "Large language model (LLM) serving is becoming an increasingly important\nworkload for cloud providers. Based on performance SLO requirements, LLM\ninference requests can be divided into (a) interactive requests that have tight\nSLOs in the order of seconds, and (b) batch requests that have relaxed SLO in\nthe order of minutes to hours. These SLOs can degrade based on the arrival\nrates, multiplexing, and configuration parameters, thus necessitating the use\nof resource autoscaling on serving instances and their batch sizes. However,\nprevious autoscalers for LLM serving do not consider request SLOs leading to\nunnecessary scaling and resource under-utilization. To address these\nlimitations, we introduce Chiron, an autoscaler that uses the idea of\nhierarchical backpressure estimated using queue size, utilization, and SLOs.\nOur experiments show that Chiron achieves up to 90% higher SLO attainment and\nimproves GPU efficiency by up to 70% compared to existing solutions.",
      "tldr_zh": "这篇论文介绍了Chiron，一种针对大型语言模型(LLM)服务的层次化自动缩放系统，用于处理交互请求（秒级SLO）和批量请求（分钟到小时级SLO）。Chiron通过基于队列大小、利用率和SLOs的层次化回压(hierarchical backpressure)机制，优化资源分配，避免不必要的缩放和资源浪费。实验结果显示，Chiron相较现有解决方案，提高SLO实现率高达90%，并提升GPU效率高达70%。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08090v1",
      "published_date": "2025-01-14 12:57:40 UTC",
      "updated_date": "2025-01-14 12:57:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:27:38.913660"
    },
    {
      "arxiv_id": "2501.08086v1",
      "title": "NOMTO: Neural Operator-based symbolic Model approximaTion and discOvery",
      "title_zh": "NOMTO：基于神经算子的符号模型逼近和发现",
      "authors": [
        "Sergei Garmaev",
        "Siddhartha Mishra",
        "Olga Fink"
      ],
      "abstract": "While many physical and engineering processes are most effectively described\nby non-linear symbolic models, existing non-linear symbolic regression (SR)\nmethods are restricted to a limited set of continuous algebraic functions,\nthereby limiting their applicability to discover higher order non-linear\ndifferential relations. In this work, we introduce the Neural Operator-based\nsymbolic Model approximaTion and discOvery (NOMTO) method, a novel approach to\nsymbolic model discovery that leverages Neural Operators to encompass a broad\nrange of symbolic operations. We demonstrate that NOMTO can successfully\nidentify symbolic expressions containing elementary functions with\nsingularities, special functions, and derivatives. Additionally, our\nexperiments demonstrate that NOMTO can accurately rediscover second-order\nnon-linear partial differential equations. By broadening the set of symbolic\noperations available for discovery, NOMTO significantly advances the\ncapabilities of existing SR methods. It provides a powerful and flexible tool\nfor model discovery, capable of capturing complex relations in a variety of\nphysical systems.",
      "tldr_zh": "该研究提出NOMTO，一种基于Neural Operators的符号模型逼近和发现方法，以克服现有符号回归(SR)方法仅限于有限连续代数函数的局限性，从而能发现更高阶的非线性微分关系。NOMTO能够成功识别包含奇点、特殊函数和导数的符号表达式，并在实验中准确重现二阶非线性偏微分方程。总体而言，这扩展了SR方法的适用范围，提供了一个强大灵活的工具，用于探索各种物理系统的复杂关系。",
      "categories": [
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08086v1",
      "published_date": "2025-01-14 12:55:48 UTC",
      "updated_date": "2025-01-14 12:55:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:27:50.471632"
    },
    {
      "arxiv_id": "2501.08074v1",
      "title": "Artificial Liver Classifier: A New Alternative to Conventional Machine Learning Models",
      "title_zh": "人工肝分类器：传统机器学习模型的一种新替代方案",
      "authors": [
        "Mahmood A. Jumaah",
        "Yossra H. Ali",
        "Tarik A. Rashid"
      ],
      "abstract": "Supervised machine learning classifiers often encounter challenges related to\nperformance, accuracy, and overfitting. This paper introduces the Artificial\nLiver Classifier (ALC), a novel supervised learning classifier inspired by the\nhuman liver's detoxification function. The ALC is characterized by its\nsimplicity, speed, hyperparameters-free, ability to reduce overfitting, and\neffectiveness in addressing multi-classification problems through\nstraightforward mathematical operations. To optimize the ALC's parameters, an\nimproved FOX optimization algorithm (IFOX) is employed as the training method.\nThe proposed ALC was evaluated on five benchmark machine learning datasets:\nIris Flower, Breast Cancer Wisconsin, Wine, Voice Gender, and MNIST. The\nresults demonstrated competitive performance, with the ALC achieving 100%\naccuracy on the Iris dataset, surpassing logistic regression, multilayer\nperceptron, and support vector machine. Similarly, on the Breast Cancer\ndataset, it achieved 99.12% accuracy, outperforming XGBoost and logistic\nregression. Across all datasets, the ALC consistently exhibited lower\noverfitting gaps and loss compared to conventional classifiers. These findings\nhighlight the potential of leveraging biological process simulations to develop\nefficient machine learning models and open new avenues for innovation in the\nfield.",
      "tldr_zh": "本文提出 Artificial Liver Classifier (ALC)，一个受人类肝脏解毒功能启发的监督学习分类器，旨在解决传统机器学习模型的性能、准确性和过拟合问题。ALC 特点包括简单、快速、无需超参数，并通过 improved FOX optimization algorithm (IFOX) 优化参数，以处理多分类任务。实验在 Iris Flower、Breast Cancer Wisconsin 等五个基准数据集上显示，ALC 在 Iris 数据集上达到 100% 准确率，优于 logistic regression 和 support vector machine；在 Breast Cancer 数据集上达 99.12% 准确率，超过 XGBoost，且整体表现出更低的过拟合差距。这些结果突显了模拟生物过程开发高效机器学习模型的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08074v1",
      "published_date": "2025-01-14 12:42:01 UTC",
      "updated_date": "2025-01-14 12:42:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:28:03.243256"
    },
    {
      "arxiv_id": "2501.08068v1",
      "title": "A Roadmap to Guide the Integration of LLMs in Hierarchical Planning",
      "title_zh": "LLMs 在层次规划中集成的指导路线图",
      "authors": [
        "Israel Puerta-Merino",
        "Carlos Núñez-Molina",
        "Pablo Mesejo",
        "Juan Fernández-Olivares"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) are fostering their\nintegration into several reasoning-related fields, including Automated Planning\n(AP). However, their integration into Hierarchical Planning (HP), a subfield of\nAP that leverages hierarchical knowledge to enhance planning performance,\nremains largely unexplored. In this preliminary work, we propose a roadmap to\naddress this gap and harness the potential of LLMs for HP. To this end, we\npresent a taxonomy of integration methods, exploring how LLMs can be utilized\nwithin the HP life cycle. Additionally, we provide a benchmark with a\nstandardized dataset for evaluating the performance of future LLM-based HP\napproaches, and present initial results for a state-of-the-art HP planner and\nLLM planner. As expected, the latter exhibits limited performance (3\\% correct\nplans, and none with a correct hierarchical decomposition) but serves as a\nvaluable baseline for future approaches.",
      "tldr_zh": "这篇论文提出一个路线图（roadmap），以指导 Large Language Models (LLMs) 在 Hierarchical Planning (HP) 中的整合，填补了 LLMs 在这一 Automated Planning (AP) 子领域的研究空白。论文呈现了一个整合方法的分类，探讨 LLMs 如何应用于 HP 生命周期，并提供了一个标准化数据集作为基准，用于评估未来 LLM-based HP 方法的性能。初步实验结果显示，LLM planner 的表现有限（仅 3% 正确计划，且无正确层次分解），但这为后续改进提供了有价值的基线。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 0 figures, to be published in the AAAI Workshop on Planning\n  in the Era of LLMs ( https://llmforplanning.github.io )",
      "pdf_url": "http://arxiv.org/pdf/2501.08068v1",
      "published_date": "2025-01-14 12:34:25 UTC",
      "updated_date": "2025-01-14 12:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:28:14.604838"
    },
    {
      "arxiv_id": "2501.08057v1",
      "title": "Optimizing Speech Multi-View Feature Fusion through Conditional Computation",
      "title_zh": "翻译失败",
      "authors": [
        "Weiqiao Shan",
        "Yuhao Zhang",
        "Yuchen Han",
        "Bei Li",
        "Xiaofeng Zhao",
        "Yuang Li",
        "Min Zhang",
        "Hao Yang",
        "Tong Xiao",
        "Jingbo Zhu"
      ],
      "abstract": "Recent advancements have highlighted the efficacy of self-supervised learning\n(SSL) features in various speech-related tasks, providing lightweight and\nversatile multi-view speech representations. However, our study reveals that\nwhile SSL features expedite model convergence, they conflict with traditional\nspectral features like FBanks in terms of update directions. In response, we\npropose a novel generalized feature fusion framework grounded in conditional\ncomputation, featuring a gradient-sensitive gating network and a multi-stage\ndropout strategy. This framework mitigates feature conflicts and bolsters model\nrobustness to multi-view input features. By integrating SSL and spectral\nfeatures, our approach accelerates convergence and maintains performance on par\nwith spectral models across multiple speech translation tasks on the MUSTC\ndataset.",
      "tldr_zh": "本研究发现，自监督学习(SSL)特征虽然能加速模型收敛，但与传统频谱特征如FBanks在更新方向上存在冲突。针对此问题，提出一个基于conditional computation的广义特征融合框架，该框架包括梯度敏感的门控网络和多阶段dropout策略，以缓解特征冲突并提升模型对多视图输入的鲁棒性。通过整合SSL和频谱特征，该方法在MUSTC数据集的多个语音翻译任务中实现了更快收敛，同时保持了与纯频谱模型相当的性能。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.08057v1",
      "published_date": "2025-01-14 12:12:06 UTC",
      "updated_date": "2025-01-14 12:12:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:28:26.805816"
    },
    {
      "arxiv_id": "2501.08053v1",
      "title": "Exploring Narrative Clustering in Large Language Models: A Layerwise Analysis of BERT",
      "title_zh": "探索大型",
      "authors": [
        "Awritrojit Banerjee",
        "Achim Schilling",
        "Patrick Krauss"
      ],
      "abstract": "This study investigates the internal mechanisms of BERT, a transformer-based\nlarge language model, with a focus on its ability to cluster narrative content\nand authorial style across its layers. Using a dataset of narratives developed\nvia GPT-4, featuring diverse semantic content and stylistic variations, we\nanalyze BERT's layerwise activations to uncover patterns of localized neural\nprocessing. Through dimensionality reduction techniques such as Principal\nComponent Analysis (PCA) and Multidimensional Scaling (MDS), we reveal that\nBERT exhibits strong clustering based on narrative content in its later layers,\nwith progressively compact and distinct clusters. While strong stylistic\nclustering might occur when narratives are rephrased into different text types\n(e.g., fables, sci-fi, kids' stories), minimal clustering is observed for\nauthorial style specific to individual writers. These findings highlight BERT's\nprioritization of semantic content over stylistic features, offering insights\ninto its representational capabilities and processing hierarchy. This study\ncontributes to understanding how transformer models like BERT encode linguistic\ninformation, paving the way for future interdisciplinary research in artificial\nintelligence and cognitive neuroscience.",
      "tldr_zh": "这篇论文探讨了BERT模型在不同层级上对叙事内容的聚类能力，重点分析其如何处理语义内容和作者风格。研究团队使用GPT-4生成的数据集，并通过Principal Component Analysis (PCA) 和 Multidimensional Scaling (MDS) 等降维技术，对BERT的层级激活进行分析。结果显示，BERT在后期层级表现出强烈的语义内容聚类，集群越来越紧凑，而对作者风格的聚类较弱，仅在叙事类型（如寓言或科幻故事）转换时较为明显。该研究揭示了BERT优先编码语义信息而非风格特征，为理解Transformer模型的语言处理机制和AI与认知神经科学的交叉研究提供了重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: text overlap with arXiv:2408.03062,\n  arXiv:2408.04270, arXiv:2307.01577",
      "pdf_url": "http://arxiv.org/pdf/2501.08053v1",
      "published_date": "2025-01-14 12:01:54 UTC",
      "updated_date": "2025-01-14 12:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:28:39.181881"
    },
    {
      "arxiv_id": "2501.08049v1",
      "title": "Self-Attentive Spatio-Temporal Calibration for Precise Intermediate Layer Matching in ANN-to-SNN Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Di Hong",
        "Yueming Wang"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are promising for low-power computation due to\ntheir event-driven mechanism but often suffer from lower accuracy compared to\nArtificial Neural Networks (ANNs). ANN-to-SNN knowledge distillation can\nimprove SNN performance, but previous methods either focus solely on label\ninformation, missing valuable intermediate layer features, or use a layer-wise\napproach that neglects spatial and temporal semantic inconsistencies, leading\nto performance degradation.To address these limitations, we propose a novel\nmethod called self-attentive spatio-temporal calibration (SASTC). SASTC uses\nself-attention to identify semantically aligned layer pairs between ANN and\nSNN, both spatially and temporally. This enables the autonomous transfer of\nrelevant semantic information. Extensive experiments show that SASTC\noutperforms existing methods, effectively solving the mismatching problem.\nSuperior accuracy results include 95.12% on CIFAR-10, 79.40% on CIFAR-100 with\n2 time steps, and 68.69% on ImageNet with 4 time steps for static datasets, and\n97.92% on DVS-Gesture and 83.60% on DVS-CIFAR10 for neuromorphic datasets. This\nmarks the first time SNNs have outperformed ANNs on both CIFAR-10 and\nCIFAR-100, shedding the new light on the potential applications of SNNs.",
      "tldr_zh": "本研究针对 Spiking Neural Networks (SNNs) 在准确率上落后于 Artificial Neural Networks (ANNs) 的问题，提出了一种新型方法 self-attentive spatio-temporal calibration (SASTC)，用于优化 ANN-to-SNN 知识蒸馏过程。SASTC 通过 self-attention 机制实现空间和时间上的语义对齐，精确匹配中间层特征，从而自主转移相关信息并解决现有方法的局限性。实验结果显示，该方法在 CIFAR-10 上达到 95.12%、CIFAR-100 上 79.40%（2 时间步）、ImageNet 上 68.69%（4 时间步），并在神经形态数据集 DVS-Gesture 和 DVS-CIFAR10 上分别取得 97.92% 和 83.60% 的准确率，这是 SNNs 首次在 CIFAR-10 和 CIFAR-100 上超越 ANNs，突显了其在低功耗计算中的应用潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08049v1",
      "published_date": "2025-01-14 11:56:00 UTC",
      "updated_date": "2025-01-14 11:56:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:28:52.941167"
    },
    {
      "arxiv_id": "2501.08046v3",
      "title": "Building Symbiotic AI: Reviewing the AI Act for a Human-Centred, Principle-Based Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Miriana Calvano",
        "Antonio Curci",
        "Giuseppe Desolda",
        "Andrea Esposito",
        "Rosa Lanzilotti",
        "Antonio Piccinno"
      ],
      "abstract": "Artificial Intelligence (AI) spreads quickly as new technologies and services\ntake over modern society. The need to regulate AI design, development, and use\nis strictly necessary to avoid unethical and potentially dangerous consequences\nto humans. The European Union (EU) has released a new legal framework, the AI\nAct, to regulate AI by undertaking a risk-based approach to safeguard humans\nduring interaction. At the same time, researchers offer a new perspective on AI\nsystems, commonly known as Human-Centred AI (HCAI), highlighting the need for a\nhuman-centred approach to their design. In this context, Symbiotic AI (a\nsubtype of HCAI) promises to enhance human capabilities through a deeper and\ncontinuous collaboration between human intelligence and AI. This article\npresents the results of a Systematic Literature Review (SLR) that aims to\nidentify principles that characterise the design and development of Symbiotic\nAI systems while considering humans as the core of the process. Through content\nanalysis, four principles emerged from the review that must be applied to\ncreate Human-Centred AI systems that can establish a symbiotic relationship\nwith humans. In addition, current trends and challenges were defined to\nindicate open questions that may guide future research for the development of\nSAI systems that comply with the AI Act.",
      "tldr_zh": "这篇论文通过系统文献综述(SLR)审查了欧盟的AI Act，旨在构建以人为中心的Symbiotic AI框架，该框架强调人类与AI的深度合作以增强人类能力。研究者通过内容分析从文献中提炼出四个关键原则，用于指导Symbiotic AI的设计，确保以人类为核心。论文还识别了当前趋势和挑战，为未来研究提供方向，以开发符合AI Act的可靠AI系统。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Third version: 36 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08046v3",
      "published_date": "2025-01-14 11:53:10 UTC",
      "updated_date": "2025-05-20 10:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:29:02.591544"
    },
    {
      "arxiv_id": "2501.08042v1",
      "title": "Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma",
      "title_zh": "翻译失败",
      "authors": [
        "Alvaro Pastor-Naranjo",
        "Pablo Meseguer",
        "Rocío del Amor",
        "Jose Antonio Lopez-Guerrero",
        "Samuel Navarro",
        "Katia Scotlandi",
        "Antonio Llombart-Bosch",
        "Isidro Machado",
        "Valery Naranjo"
      ],
      "abstract": "Ewing's sarcoma (ES), characterized by a high density of small round blue\ncells without structural organization, presents a significant health concern,\nparticularly among adolescents aged 10 to 19. Artificial intelligence-based\nsystems for automated analysis of histopathological images are promising to\ncontribute to an accurate diagnosis of ES. In this context, this study explores\nthe feature extraction ability of different pre-training strategies for\ndistinguishing ES from other soft tissue or bone sarcomas with similar\nmorphology in digitized tissue microarrays for the first time, as far as we\nknow. Vision-language supervision (VLS) is compared to fully-supervised\nImageNet pre-training within a multiple instance learning paradigm. Our\nfindings indicate a substantial improvement in diagnostic accuracy with the\nadaption of VLS using an in-domain dataset. Notably, these models not only\nenhance the accuracy of predicted classes but also drastically reduce the\nnumber of trainable parameters and computational costs.",
      "tldr_zh": "这篇论文探讨了视觉语言模型（Vision-Language Models）在诊断Ewing Sarcoma（ES）中的潜力，针对其高密度小圆蓝细胞特征，通过分析数字化组织微阵列图像来提升诊断准确性。研究首次比较了Vision-Language Supervision (VLS)与ImageNet预训练策略在multiple instance learning框架下的特征提取能力，结果显示VLS结合in-domain数据集显著提高了预测类别的准确性。不仅如此，该方法还大幅减少了可训练参数和计算成本，为AI辅助ES诊断提供了更高效的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 5 figures, 2 tables. Oral presentation at KES-InMed 2024\n  held in Madeira, Portugal",
      "pdf_url": "http://arxiv.org/pdf/2501.08042v1",
      "published_date": "2025-01-14 11:47:35 UTC",
      "updated_date": "2025-01-14 11:47:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:29:14.306856"
    },
    {
      "arxiv_id": "2501.08035v1",
      "title": "READ: Reinforcement-based Adversarial Learning for Text Classification with Limited Labeled Data",
      "title_zh": "翻译失败",
      "authors": [
        "Rohit Sharma",
        "Shanu Kumar",
        "Avinash Kumar"
      ],
      "abstract": "Pre-trained transformer models such as BERT have shown massive gains across\nmany text classification tasks. However, these models usually need enormous\nlabeled data to achieve impressive performances. Obtaining labeled data is\noften expensive and time-consuming, whereas collecting unlabeled data using\nsome heuristics is relatively much cheaper for any task. Therefore, this paper\nproposes a method that encapsulates reinforcement learning-based text\ngeneration and semi-supervised adversarial learning approaches in a novel way\nto improve the model's performance. Our method READ, Reinforcement-based\nAdversarial learning, utilizes an unlabeled dataset to generate diverse\nsynthetic text through reinforcement learning, improving the model's\ngeneralization capability using adversarial learning. Our experimental results\nshow that READ outperforms the existing state-of-art methods on multiple\ndatasets.",
      "tldr_zh": "该论文针对文本分类任务中标注数据有限的问题，提出READ方法，该方法结合强化学习(Reinforcement Learning)和半监督对抗学习(Adversarial Learning)，利用无标注数据生成多样化合成文本，以提升模型的泛化能力。READ通过强化学习生成文本并通过对抗学习优化模型，从而减少对大量标注数据的依赖。实验结果显示，该方法在多个数据集上优于现有最先进技术。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08035v1",
      "published_date": "2025-01-14 11:39:55 UTC",
      "updated_date": "2025-01-14 11:39:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:29:25.940731"
    },
    {
      "arxiv_id": "2501.08020v1",
      "title": "Cooperative Patrol Routing: Optimizing Urban Crime Surveillance through Multi-Agent Reinforcement Learning",
      "title_zh": "协同巡逻路由：通过多智能体强化学习优化城市犯罪监控",
      "authors": [
        "Juan Palma-Borda",
        "Eduardo Guzmán",
        "María-Victoria Belmonte"
      ],
      "abstract": "The effective design of patrol strategies is a difficult and complex problem,\nespecially in medium and large areas. The objective is to plan, in a\ncoordinated manner, the optimal routes for a set of patrols in a given area, in\norder to achieve maximum coverage of the area, while also trying to minimize\nthe number of patrols. In this paper, we propose a multi-agent reinforcement\nlearning (MARL) model, based on a decentralized partially observable Markov\ndecision process, to plan unpredictable patrol routes within an urban\nenvironment represented as an undirected graph. The model attempts to maximize\na target function that characterizes the environment within a given time frame.\nOur model has been tested to optimize police patrol routes in three\nmedium-sized districts of the city of Malaga. The aim was to maximize\nsurveillance coverage of the most crime-prone areas, based on actual crime data\nin the city. To address this problem, several MARL algorithms have been\nstudied, and among these the Value Decomposition Proximal Policy Optimization\n(VDPPO) algorithm exhibited the best performance. We also introduce a novel\nmetric, the coverage index, for the evaluation of the coverage performance of\nthe routes generated by our model. This metric is inspired by the predictive\naccuracy index (PAI), which is commonly used in criminology to detect hotspots.\nUsing this metric, we have evaluated the model under various scenarios in which\nthe number of agents (or patrols), their starting positions, and the level of\ninformation they can observe in the environment have been modified. Results\nshow that the coordinated routes generated by our model achieve a coverage of\nmore than $90\\%$ of the $3\\%$ of graph nodes with the highest crime incidence,\nand $65\\%$ for $20\\%$ of these nodes; $3\\%$ and $20\\%$ represent the coverage\nstandards for police resource allocation.",
      "tldr_zh": "本文提出一种基于多智能体强化学习 (MARL) 的模型，利用去中心化部分可观测 Markov 决策过程 (Dec-POMDP) 来优化都市环境中的巡逻路线，旨在最大化犯罪高发区域的覆盖率，同时最小化巡逻数量。模型引入了新的 coverage index 指标，受 criminology 中的 predictive accuracy index (PAI) 启发，用于评估路线性能，并通过 Value Decomposition Proximal Policy Optimization (VDPPO) 算法实现了最佳效果。在马拉加市的实验中，该模型在各种场景下达到了超过 90% 的 3% 高犯罪节点覆盖率和 65% 的 20% 高犯罪节点覆盖率，证明了其在警察资源分配中的实际价值。",
      "categories": [
        "cs.AI",
        "68T20, 68T42",
        "I.2.1; I.2.8; I.6.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08020v1",
      "published_date": "2025-01-14 11:20:19 UTC",
      "updated_date": "2025-01-14 11:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:29:39.761939"
    },
    {
      "arxiv_id": "2501.08019v1",
      "title": "An AI-driven framework for rapid and localized optimizations of urban open spaces",
      "title_zh": "AI 驱动的框架，用于城市开放空间的快速和本地化优化",
      "authors": [
        "Pegah Eshraghi",
        "Arman Nikkhah Dehnavi",
        "Maedeh Mirdamadi",
        "Riccardo Talami",
        "Zahra-Sadat Zomorodian"
      ],
      "abstract": "As urbanization accelerates, open spaces are increasingly recognized for\ntheir role in enhancing sustainability and well-being, yet they remain\nunderexplored compared to built spaces. This study introduces an AI-driven\nframework that integrates machine learning models (MLMs) and explainable AI\ntechniques to optimize Sky View Factor (SVF) and visibility, key spatial\nmetrics influencing thermal comfort and perceived safety in urban spaces.\nUnlike global optimization methods, which are computationally intensive and\nimpractical for localized adjustments, this framework supports incremental\ndesign improvements with lower computational costs and greater flexibility. The\nframework employs SHapley Adaptive Explanations (SHAP) to analyze feature\nimportance and Counterfactual Explanations (CFXs) to propose minimal design\nchanges. Simulations tested five MLMs, identifying XGBoost as the most\naccurate, with building width, park area, and heights of surrounding buildings\nas critical for SVF, and distances from southern buildings as key for\nvisibility. Compared to Genetic Algorithms, which required approximately 15/30\nminutes across 3/4 generations to converge, the tested CFX approach achieved\noptimized results in 1 minute with a 5% RMSE error, demonstrating significantly\nfaster performance and suitability for scalable retrofitting strategies. This\ninterpretable and computationally efficient framework advances urban\nperformance optimization, providing data-driven insights and practical\nretrofitting solutions for enhancing usability and environmental quality across\ndiverse urban contexts.",
      "tldr_zh": "该研究提出一个AI驱动框架，利用机器学习模型(MLMs)和可解释AI技术（如SHapley Adaptive Explanations (SHAP)和Counterfactual Explanations (CFXs)），针对城市开放空间优化Sky View Factor (SVF)和可见性，以提升热舒适度和感知安全。不同于计算密集型全局优化方法，该框架支持快速本地化增量设计改进，显著降低计算成本。实验结果显示，XGBoost模型表现最佳，关键因素包括建筑宽度、公园面积和周围建筑高度，而CFXs方法仅用1分钟就实现优化，RMSE错误仅5%，远优于Genetic Algorithms的15/30分钟收敛时间。该框架提供数据驱动的见解和可扩展改造策略，促进城市可持续性和环境质量。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "36 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08019v1",
      "published_date": "2025-01-14 11:19:52 UTC",
      "updated_date": "2025-01-14 11:19:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:29:51.609861"
    },
    {
      "arxiv_id": "2501.08009v1",
      "title": "Tutorial: VAE as an inference paradigm for neuroimaging",
      "title_zh": "教程：VAE 作为神经影像学的推理范式",
      "authors": [
        "C. Vázquez-García",
        "F. J. Martínez-Murcia",
        "F. Segovia Román",
        "Juan M. Górriz Sáez"
      ],
      "abstract": "In this tutorial, we explore Variational Autoencoders (VAEs), an essential\nframework for unsupervised learning, particularly suited for high-dimensional\ndatasets such as neuroimaging. By integrating deep learning with Bayesian\ninference, VAEs enable the generation of interpretable latent representations.\nThis tutorial outlines the theoretical foundations of VAEs, addresses practical\nchallenges such as convergence issues and over-fitting, and discusses\nstrategies like the reparameterization trick and hyperparameter optimization.\nWe also highlight key applications of VAEs in neuroimaging, demonstrating their\npotential to uncover meaningful patterns, including those associated with\nneurodegenerative processes, and their broader implications for analyzing\ncomplex brain data.",
      "tldr_zh": "这篇教程介绍了 Variational Autoencoders (VAEs) 作为一种无监督学习框架，特别适用于神经影像等高维数据集，通过整合深度学习和 Bayesian inference 来生成可解释的潜在表示。教程详细阐述了 VAEs 的理论基础，并讨论了实际挑战如收敛问题和过拟合的解决方案，包括 reparameterization trick 和 hyperparameter optimization 等策略。最终，强调了 VAEs 在神经影像中的关键应用，如揭示与神经退行性过程相关的模式，并为分析复杂脑数据提供了更广泛的含义。",
      "categories": [
        "eess.IV",
        "cs.AI"
      ],
      "primary_category": "eess.IV",
      "comment": "18 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.08009v1",
      "published_date": "2025-01-14 10:54:36 UTC",
      "updated_date": "2025-01-14 10:54:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:30:02.755706"
    },
    {
      "arxiv_id": "2501.08008v1",
      "title": "TriAdaptLoRA: Brain-Inspired Triangular Adaptive Low-Rank Adaptation for Parameter-Efficient Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yao Liang",
        "Yuwei Wang",
        "Yi Zeng"
      ],
      "abstract": "The fine-tuning of Large Language Models (LLMs) is pivotal for achieving\noptimal performance across diverse downstream tasks. However, while full\nfine-tuning delivers superior results, it entails significant computational and\nresource costs. Parameter-Efficient Fine-Tuning (PEFT) methods, such as LoRA,\naddress these challenges by reducing the number of trainable parameters, but\nthey often struggle with rank adjustment efficiency and task-specific\nadaptability. We propose Triangular Adaptive Low-Rank Adaptation\n(TriAdaptLoRA), a novel PEFT framework inspired by neuroscience principles,\nwhich dynamically optimizes the allocation of trainable parameters.\nTriAdaptLoRA introduces three key innovations: 1) a triangular split of\ntransformation matrices into lower and upper triangular components to maximize\nparameter utilization, 2) a parameter importance metric based on normalized\nFrobenius norms for efficient adaptation, and 3) an adaptive rank-growth\nstrategy governed by dynamic thresholds, allowing flexible parameter allocation\nacross training steps. Experiments conducted on a variety of natural language\nunderstanding and generation tasks demonstrate that TriAdaptLoRA consistently\noutperforms existing PEFT methods. It achieves superior performance, enhanced\nstability, and reduced computational overhead, particularly under linear\nthreshold-driven rank growth. These results highlight its efficacy as a\nscalable and resource-efficient solution for fine-tuning LLMs.",
      "tldr_zh": "该论文提出TriAdaptLoRA，一种受神经科学启发的三角自适应低秩适应框架，用于参数高效微调(Large Language Models, LLMs)。TriAdaptLoRA通过将变换矩阵分解为下三角和上三角部分、引入基于归一化Frobenius范数的参数重要性指标，以及动态阈值控制的自适应秩增长策略，优化可训练参数的分配和任务适应性。实验结果显示，在多种自然语言理解和生成任务上，TriAdaptLoRA比现有PEFT方法如LoRA表现出色，提供更高的性能、更强的稳定性，并显著降低计算开销，证明其作为可扩展资源高效解决方案的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08008v1",
      "published_date": "2025-01-14 10:51:31 UTC",
      "updated_date": "2025-01-14 10:51:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:30:13.992941"
    },
    {
      "arxiv_id": "2501.08005v1",
      "title": "DisCoPatch: Batch Statistics Are All You Need For OOD Detection, But Only If You Can Trust Them",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Caetano",
        "Christiaan Viviers",
        "Luis A. Zavala-Mondragón",
        "Peter H. N. de With",
        "Fons van der Sommen"
      ],
      "abstract": "Out-of-distribution (OOD) detection holds significant importance across many\napplications. While semantic and domain-shift OOD problems are well-studied,\nthis work focuses on covariate shifts - subtle variations in the data\ndistribution that can degrade machine learning performance. We hypothesize that\ndetecting these subtle shifts can improve our understanding of in-distribution\nboundaries, ultimately improving OOD detection. In adversarial discriminators\ntrained with Batch Normalization (BN), real and adversarial samples form\ndistinct domains with unique batch statistics - a property we exploit for OOD\ndetection. We introduce DisCoPatch, an unsupervised Adversarial Variational\nAutoencoder (VAE) framework that harnesses this mechanism. During inference,\nbatches consist of patches from the same image, ensuring a consistent data\ndistribution that allows the model to rely on batch statistics. DisCoPatch uses\nthe VAE's suboptimal outputs (generated and reconstructed) as negative samples\nto train the discriminator, thereby improving its ability to delineate the\nboundary between in-distribution samples and covariate shifts. By tightening\nthis boundary, DisCoPatch achieves state-of-the-art results in public OOD\ndetection benchmarks. The proposed model not only excels in detecting covariate\nshifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior\nmethods on public Near-OOD (95.0%) benchmarks. With a compact model size of\n25MB, it achieves high OOD detection performance at notably lower latency than\nexisting methods, making it an efficient and practical solution for real-world\nOOD detection applications. The code will be made publicly available",
      "tldr_zh": "该论文提出DisCoPatch，一种无监督的Adversarial Variational Autoencoder (VAE)框架，专注于检测Out-of-distribution (OOD)检测中的covariate shifts，通过利用Batch Normalization (BN)的批次统计来区分真实样本和异常变异。框架在推理阶段使用同一图像的patches组成批次，确保数据分布一致，并通过VAE的次优输出作为负样本训练鉴别器，从而精确界定in-distribution边界。实验结果显示，DisCoPatch在ImageNet-1K(-C)上达到95.5% AUROC，在Near-OOD基准上达到95.0%，并以25MB的紧凑模型大小实现低延迟，超越现有方法，提供高效的实时OOD检测解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08005v1",
      "published_date": "2025-01-14 10:49:26 UTC",
      "updated_date": "2025-01-14 10:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:30:26.869193"
    },
    {
      "arxiv_id": "2501.08002v2",
      "title": "Maximizing Uncertainty for Federated learning via Bayesian Optimisation-based Model Poisoning",
      "title_zh": "通过基于贝叶斯优化的模型投毒最大化联邦学习的不确定性",
      "authors": [
        "Marios Aristodemou",
        "Xiaolan Liu",
        "Yuan Wang",
        "Konstantinos G. Kyriakopoulos",
        "Sangarapillai Lambotharan",
        "Qingsong Wei"
      ],
      "abstract": "As we transition from Narrow Artificial Intelligence towards Artificial Super\nIntelligence, users are increasingly concerned about their privacy and the\ntrustworthiness of machine learning (ML) technology. A common denominator for\nthe metrics of trustworthiness is the quantification of uncertainty inherent in\nDL algorithms, and specifically in the model parameters, input data, and model\npredictions. One of the common approaches to address privacy-related issues in\nDL is to adopt distributed learning such as federated learning (FL), where\nprivate raw data is not shared among users. Despite the privacy-preserving\nmechanisms in FL, it still faces challenges in trustworthiness. Specifically,\nthe malicious users, during training, can systematically create malicious model\nparameters to compromise the models predictive and generative capabilities,\nresulting in high uncertainty about their reliability. To demonstrate malicious\nbehaviour, we propose a novel model poisoning attack method named Delphi which\naims to maximise the uncertainty of the global model output. We achieve this by\ntaking advantage of the relationship between the uncertainty and the model\nparameters of the first hidden layer of the local model. Delphi employs two\ntypes of optimisation , Bayesian Optimisation and Least Squares Trust Region,\nto search for the optimal poisoned model parameters, named as Delphi-BO and\nDelphi-LSTR. We quantify the uncertainty using the KL Divergence to minimise\nthe distance of the predictive probability distribution towards an uncertain\ndistribution of model output. Furthermore, we establish a mathematical proof\nfor the attack effectiveness demonstrated in FL. Numerical results demonstrate\nthat Delphi-BO induces a higher amount of uncertainty than Delphi-LSTR\nhighlighting vulnerability of FL systems to model poisoning attacks.",
      "tldr_zh": "该研究探讨了联邦学习（Federated Learning, FL）中的模型投毒（Model Poisoning）攻击，旨在通过最大化全球模型输出的不确定性来挑战ML系统的可信度。作者提出了一种新方法Delphi，利用Bayesian Optimisation和Least Squares Trust Region优化本地模型的第一隐藏层参数，从而生成投毒模型参数。Delphi通过KL Divergence量化预测概率分布的不确定性，并提供了攻击有效性的数学证明。实验结果显示，Delphi-BO比Delphi-LSTR更有效地诱发不确定性，突显了FL系统对此类攻击的脆弱性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.08002v2",
      "published_date": "2025-01-14 10:46:41 UTC",
      "updated_date": "2025-01-15 11:52:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:30:38.479827"
    },
    {
      "arxiv_id": "2501.08001v1",
      "title": "GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation",
      "title_zh": "GDiffRetro：基于双图增强分子表示和扩散生成的逆合成预测",
      "authors": [
        "Shengyin Sun",
        "Wenhao Yu",
        "Yuxiang Ren",
        "Weitao Du",
        "Liwei Liu",
        "Xuecang Zhang",
        "Ying Hu",
        "Chen Ma"
      ],
      "abstract": "Retrosynthesis prediction focuses on identifying reactants capable of\nsynthesizing a target product. Typically, the retrosynthesis prediction\ninvolves two phases: Reaction Center Identification and Reactant Generation.\nHowever, we argue that most existing methods suffer from two limitations in the\ntwo phases: (i) Existing models do not adequately capture the ``face''\ninformation in molecular graphs for the reaction center identification. (ii)\nCurrent approaches for the reactant generation predominantly use sequence\ngeneration in a 2D space, which lacks versatility in generating reasonable\ndistributions for completed reactive groups and overlooks molecules' inherent\n3D properties. To overcome the above limitations, we propose GDiffRetro. For\nthe reaction center identification, GDiffRetro uniquely integrates the original\ngraph with its corresponding dual graph to represent molecular structures,\nwhich helps guide the model to focus more on the faces in the graph. For the\nreactant generation, GDiffRetro employs a conditional diffusion model in 3D to\nfurther transform the obtained synthon into a complete reactant. Our\nexperimental findings reveal that GDiffRetro outperforms state-of-the-art\nsemi-template models across various evaluative metrics.",
      "tldr_zh": "该论文提出GDiffRetro框架，用于改进回顾合成预测(Retrosynthesis Prediction)，解决现有方法在反应中心识别(Reaction Center Identification)和反应物生成(Reactant Generation)阶段的局限性，包括未充分捕捉分子图的“面”信息和忽略分子3D属性的问题。GDiffRetro通过整合原始图和双图(Dual Graph)来增强分子表示，从而更好地识别反应中心；同时，使用条件扩散模型(Conditional Diffusion Model)在3D空间生成完整的反应物。实验结果显示，GDiffRetro在各种评估指标上优于最先进的半模板模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08001v1",
      "published_date": "2025-01-14 10:44:38 UTC",
      "updated_date": "2025-01-14 10:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:30:50.441900"
    },
    {
      "arxiv_id": "2501.07992v1",
      "title": "LLM-Ehnanced Holonic Architecture for Ad-Hoc Scalable SoS",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Ashfaq",
        "Ahmed R. Sadik",
        "Tommi Mikkonen",
        "Muhammad Waseem",
        "Niko Mäkitalo"
      ],
      "abstract": "As modern system of systems (SoS) become increasingly adaptive and human\ncentred, traditional architectures often struggle to support interoperability,\nreconfigurability, and effective human system interaction. This paper addresses\nthese challenges by advancing the state of the art holonic architecture for\nSoS, offering two main contributions to support these adaptive needs. First, we\npropose a layered architecture for holons, which includes reasoning,\ncommunication, and capabilities layers. This design facilitates seamless\ninteroperability among heterogeneous constituent systems by improving data\nexchange and integration. Second, inspired by principles of intelligent\nmanufacturing, we introduce specialised holons namely, supervisor, planner,\ntask, and resource holons aimed at enhancing the adaptability and\nreconfigurability of SoS. These specialised holons utilise large language\nmodels within their reasoning layers to support decision making and ensure real\ntime adaptability. We demonstrate our approach through a 3D mobility case study\nfocused on smart city transportation, showcasing its potential for managing\ncomplex, multimodal SoS environments. Additionally, we propose evaluation\nmethods to assess the architecture efficiency and scalability,laying the\ngroundwork for future empirical validations through simulations and real world\nimplementations.",
      "tldr_zh": "本论文提出了一种基于大型语言模型(LLMs)的全息架构(Holonic Architecture)，旨在解决现代系统-of-系统(SoS)的互操作性、可重新配置性和人机交互挑战。该架构包括推理、通信和能力层的设计，以提升异构系统之间的无缝数据交换和集成。同时，论文引入了专化holons（如supervisor holon、planner holon、task holon和resource holon），利用LLMs在推理层支持决策和实时适应性。通过一个智能城市交通的3D移动性案例研究，展示了该架构在复杂多模式SoS环境中的潜力。最后，论文提出评估方法来检验架构的效率和可扩展性，为未来的模拟和实际应用奠定基础。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07992v1",
      "published_date": "2025-01-14 10:35:54 UTC",
      "updated_date": "2025-01-14 10:35:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:32:55.989553"
    },
    {
      "arxiv_id": "2501.07991v1",
      "title": "Training Hybrid Neural Networks with Multimode Optical Nonlinearities Using Digital Twins",
      "title_zh": "翻译失败",
      "authors": [
        "Ilker Oguz",
        "Louis J. E. Suter",
        "Jih-Liang Hsieh",
        "Mustafa Yildirim",
        "Niyazi Ulas Dinc",
        "Christophe Moser",
        "Demetri Psaltis"
      ],
      "abstract": "The ability to train ever-larger neural networks brings artificial\nintelligence to the forefront of scientific and technical discoveries. However,\ntheir exponentially increasing size creates a proportionally greater demand for\nenergy and computational hardware. Incorporating complex physical events in\nnetworks as fixed, efficient computation modules can address this demand by\ndecreasing the complexity of trainable layers. Here, we utilize ultrashort\npulse propagation in multimode fibers, which perform large-scale nonlinear\ntransformations, for this purpose. Training the hybrid architecture is achieved\nthrough a neural model that differentiably approximates the optical system. The\ntraining algorithm updates the neural simulator and backpropagates the error\nsignal over this proxy to optimize layers preceding the optical one. Our\nexperimental results achieve state-of-the-art image classification accuracies\nand simulation fidelity. Moreover, the framework demonstrates exceptional\nresilience to experimental drifts. By integrating low-energy physical systems\ninto neural networks, this approach enables scalable, energy-efficient AI\nmodels with significantly reduced computational demands.",
      "tldr_zh": "本文提出了一种利用数字孪生（digital twins）训练混合神经网络（hybrid neural networks）的方法，通过多模光纤（multimode fibers）的非线性变换作为高效计算模块，减少神经网络的能源和硬件需求。训练过程使用神经模型可微逼近光学系统，并通过代理反向传播（backpropagation）优化网络层。实验结果在图像分类任务上达到最先进准确率，并展示了卓越的模拟保真度和对实验漂移的韧性。该框架通过整合低能物理系统，实现可扩展、节能的 AI 模型，显著降低计算需求。",
      "categories": [
        "physics.optics",
        "cs.AI"
      ],
      "primary_category": "physics.optics",
      "comment": "17 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.07991v1",
      "published_date": "2025-01-14 10:35:18 UTC",
      "updated_date": "2025-01-14 10:35:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:31:15.635182"
    },
    {
      "arxiv_id": "2501.07988v1",
      "title": "GAC-Net_Geometric and attention-based Network for Depth Completion",
      "title_zh": "GAC-Net：基于几何和注意力机制的网络用于深度完成",
      "authors": [
        "Kuang Zhu",
        "Xingli Gan",
        "Min Sun"
      ],
      "abstract": "Depth completion is a key task in autonomous driving, aiming to complete\nsparse LiDAR depth measurements into high-quality dense depth maps through\nimage guidance. However, existing methods usually treat depth maps as an\nadditional channel of color images, or directly perform convolution on sparse\ndata, failing to fully exploit the 3D geometric information in depth maps,\nespecially with limited performance in complex boundaries and sparse areas. To\naddress these issues, this paper proposes a depth completion network combining\nchannel attention mechanism and 3D global feature perception (CGA-Net). The\nmain innovations include: 1) Utilizing PointNet++ to extract global 3D\ngeometric features from sparse depth maps, enhancing the scene perception\nability of low-line LiDAR data; 2) Designing a channel-attention-based\nmultimodal feature fusion module to efficiently integrate sparse depth, RGB\nimages, and 3D geometric features; 3) Combining residual learning with CSPN++\nto optimize the depth refinement stage, further improving the completion\nquality in edge areas and complex scenes. Experiments on the KITTI depth\ncompletion dataset show that CGA-Net can significantly improve the prediction\naccuracy of dense depth maps, achieving a new state-of-the-art (SOTA), and\ndemonstrating strong robustness to sparse and complex scenes.",
      "tldr_zh": "该论文针对深度完成（Depth Completion）任务提出了一种基于几何和注意力机制的网络（GAC-Net），旨在通过图像引导将稀疏LiDAR深度测量转化为高质量的密集深度图，同时充分利用3D几何信息来解决现有方法在复杂边界和稀疏区域的局限性。主要创新包括使用PointNet++提取全局3D几何特征、设计基于通道注意力的多模态特征融合模块整合稀疏深度、RGB图像和几何特征，以及结合残差学习和CSPN++优化深度精炼过程。实验在KITTI深度完成数据集上表明，GAC-Net显著提升了预测准确性，达到了新的最先进水平（SOTA），并展示了在稀疏和复杂场景中的强大鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13pages,4 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.07988v1",
      "published_date": "2025-01-14 10:24:20 UTC",
      "updated_date": "2025-01-14 10:24:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:31:27.280943"
    },
    {
      "arxiv_id": "2501.07978v1",
      "title": "Facial Dynamics in Video: Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness",
      "title_zh": "视频中的面",
      "authors": [
        "Jiaxing Zhao",
        "Boyuan Sun",
        "Xiang Chen",
        "Xihan Wei"
      ],
      "abstract": "Facial expression captioning has found widespread application across various\ndomains. Recently, the emergence of video Multimodal Large Language Models\n(MLLMs) has shown promise in general video understanding tasks. However,\ndescribing facial expressions within videos poses two major challenges for\nthese models: (1) the lack of adequate datasets and benchmarks, and (2) the\nlimited visual token capacity of video MLLMs. To address these issues, this\npaper introduces a new instruction-following dataset tailored for dynamic\nfacial expression caption. The dataset comprises 5,033 high-quality video clips\nannotated manually, containing over 700,000 tokens. Its purpose is to improve\nthe capability of video MLLMs to discern subtle facial nuances. Furthermore, we\npropose FaceTrack-MM, which leverages a limited number of tokens to encode the\nmain character's face. This model demonstrates superior performance in tracking\nfaces and focusing on the facial expressions of the main characters, even in\nintricate multi-person scenarios. Additionally, we introduce a novel evaluation\nmetric combining event extraction, relation classification, and the longest\ncommon subsequence (LCS) algorithm to assess the content consistency and\ntemporal sequence consistency of generated text. Moreover, we present\nFEC-Bench, a benchmark designed to assess the performance of existing video\nMLLMs in this specific task. All data and source code will be made publicly\navailable.",
      "tldr_zh": "本文针对视频 Multimodal Large Language Models (MLLMs) 在面部表情描述任务中面临的挑战，包括数据集不足和视觉标记容量限制，引入了一个新的指令跟随数据集，包含 5,033 个高质量视频剪辑和超过 700,000 个标记，以提升模型对微妙面部细微差别的感知和上下文意识。论文提出 FaceTrack-MM 模型，通过有限标记编码主要人物的面部，实现高效跟踪和表情识别，尤其在复杂多人物场景中表现出色。同时，引入一个新型评估指标，结合事件提取、关系分类和 Longest Common Subsequence (LCS) 算法，以及 FEC-Bench 基准，用于评估现有视频 MLLMs 的性能，所有数据和源代码将公开可用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07978v1",
      "published_date": "2025-01-14 09:52:56 UTC",
      "updated_date": "2025-01-14 09:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:31:40.161912"
    },
    {
      "arxiv_id": "2501.07970v1",
      "title": "Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Wentao Cui",
        "Shoubo Li",
        "Chen Fang",
        "Qingqing Long",
        "Chengrui Wang",
        "Xuezhi Wang",
        "Yuanchun Zhou"
      ],
      "abstract": "Discovering gene-disease associations is crucial for understanding disease\nmechanisms, yet identifying these associations remains challenging due to the\ntime and cost of biological experiments. Computational methods are increasingly\nvital for efficient and scalable gene-disease association prediction.\nGraph-based learning models, which leverage node features and network\nrelationships, are commonly employed for biomolecular predictions. However,\nexisting methods often struggle to effectively integrate node features,\nheterogeneous structures, and semantic information. To address these\nchallenges, we propose COmprehensive MEtapath-based heterogeneous graph\nTransformer(COMET) for predicting gene-disease associations. COMET integrates\ndiverse datasets to construct comprehensive heterogeneous networks,\ninitializing node features with BioGPT. We define seven Metapaths and utilize a\ntransformer framework to aggregate Metapath instances, capturing global\ncontexts and long-distance dependencies. Through intra- and inter-metapath\naggregation using attention mechanisms, COMET fuses latent vectors from\nmultiple Metapaths to enhance GDA prediction accuracy. Our method demonstrates\nsuperior robustness compared to state-of-the-art approaches. Ablation studies\nand visualizations validate COMET's effectiveness, providing valuable insights\nfor advancing human health research.",
      "tldr_zh": "该研究针对基因-疾病关联预测的挑战，提出COMET（COmprehensive MEtapath-based heterogeneous graph Transformer）框架，通过整合多样数据集构建异构网络，并使用BioGPT初始化节点特征，以有效融合节点特征、异构结构和语义信息。\nCOMET定义七个Metapaths，利用Transformer框架聚合Metapath实例，并通过注意力机制进行intra-和inter-metapath聚合，捕捉全局上下文和长距离依赖，从而提升预测准确性。\n实验结果表明，COMET在鲁棒性上优于现有方法，消融研究和可视化验证了其有效性，为推进人类健康研究提供了宝贵洞见。",
      "categories": [
        "cs.AI",
        "I.2.6"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07970v1",
      "published_date": "2025-01-14 09:41:18 UTC",
      "updated_date": "2025-01-14 09:41:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:31:51.041065"
    },
    {
      "arxiv_id": "2501.07964v3",
      "title": "Derivation of Output Correlation Inferences for Multi-Output (aka Multi-Task) Gaussian Process",
      "title_zh": "翻译失败",
      "authors": [
        "Shuhei Watanabe"
      ],
      "abstract": "Gaussian process (GP) is arguably one of the most widely used machine\nlearning algorithms in practice. One of its prominent applications is Bayesian\noptimization (BO). Although the vanilla GP itself is already a powerful tool\nfor BO, it is often beneficial to be able to consider the dependencies of\nmultiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not\ntrivial to fully understand the derivations of its formulations and their\ngradients from the previous literature. This paper serves friendly derivations\nof the MTGP formulations and their gradients.",
      "tldr_zh": "该论文针对多输出（即多任务）高斯过程（Multi-Task GP, MTGP）进行了输出相关性推导，旨在解决现有文献中MTGP公式及其梯度推导的复杂性问题。高斯过程（GP）作为机器学习算法，在Bayesian Optimization（BO）中广泛应用，而MTGP通过考虑多个输出的依赖性进一步提升了其效能。论文提供了友好且详细的MTGP公式和梯度推导，帮助研究者更好地理解和应用该模型。该工作为BO等领域的实践提供了更坚实的理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07964v3",
      "published_date": "2025-01-14 09:35:49 UTC",
      "updated_date": "2025-03-12 06:12:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:32:01.556820"
    },
    {
      "arxiv_id": "2501.07959v2",
      "title": "Self-Instruct Few-Shot Jailbreaking: Decompose the Attack into Pattern and Behavior Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqi Hua",
        "Wanxu Wei"
      ],
      "abstract": "Recently, several works have been conducted on jailbreaking Large Language\nModels (LLMs) with few-shot malicious demos. In particular, Zheng et al. focus\non improving the efficiency of Few-Shot Jailbreaking (FSJ) by injecting special\ntokens into the demos and employing demo-level random search, known as Improved\nFew-Shot Jailbreaking (I-FSJ). Nevertheless, we notice that this method may\nstill require a long context to jailbreak advanced models e.g. 32 shots of\ndemos for Meta-Llama-3-8B-Instruct (Llama-3) \\cite{llama3modelcard}. In this\npaper, we discuss the limitations of I-FSJ and propose Self-Instruct Few-Shot\nJailbreaking (Self-Instruct-FSJ) facilitated with the demo-level greedy search.\nThis framework decomposes the FSJ attack into pattern and behavior learning to\nexploit the model's vulnerabilities in a more generalized and efficient way. We\nconduct elaborate experiments to evaluate our method on common open-source\nmodels and compare it with baseline algorithms. Our code is available at\nhttps://github.com/iphosi/Self-Instruct-FSJ.",
      "tldr_zh": "本论文讨论了现有 Few-Shot Jailbreaking (FSJ) 方法的局限性，如 Improved Few-Shot Jailbreaking (I-FSJ)，其在越狱大语言模型（LLMs）时需较长上下文（例如对 Llama-3 需要32个shots）。为了更高效地利用模型漏洞，作者提出 Self-Instruct Few-Shot Jailbreaking (Self-Instruct-FSJ) 框架，将攻击分解为 pattern learning 和 behavior learning，并采用 demo-level greedy search 进行优化。实验在常见开源模型上评估了该方法，与基线算法比较后证明其泛化和效率更高，代码已在 GitHub 公开。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07959v2",
      "published_date": "2025-01-14 09:23:30 UTC",
      "updated_date": "2025-02-01 09:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:32:15.516960"
    },
    {
      "arxiv_id": "2501.07957v2",
      "title": "AI Guide Dog: Egocentric Path Prediction on Smartphone",
      "title_zh": "翻译失败",
      "authors": [
        "Aishwarya Jadhav",
        "Jeffery Cao",
        "Abhishree Shetty",
        "Urvashi Priyam Kumar",
        "Aditi Sharma",
        "Ben Sukboontip",
        "Jayant Sravan Tamarapalli",
        "Jingyi Zhang",
        "Anirudh Koul"
      ],
      "abstract": "This paper presents AI Guide Dog (AIGD), a lightweight egocentric\n(first-person) navigation system for visually impaired users, designed for\nreal-time deployment on smartphones. AIGD employs a vision-only multi-label\nclassification approach to predict directional commands, ensuring safe\nnavigation across diverse environments. We introduce a novel technique for\ngoal-based outdoor navigation by integrating GPS signals and high-level\ndirections, while also handling uncertain multi-path predictions for\ndestination-free indoor navigation. As the first navigation assistance system\nto handle both goal-oriented and exploratory navigation across indoor and\noutdoor settings, AIGD establishes a new benchmark in blind navigation. We\npresent methods, datasets, evaluations, and deployment insights to encourage\nfurther innovations in assistive navigation systems.",
      "tldr_zh": "这篇论文介绍了 AI Guide Dog (AIGD)，一个轻量级的 egocentric 导航系统，针对视力障碍用户在智能手机上实现实时部署。它采用视觉-only 多标签分类方法预测方向命令，并通过整合 GPS 信号和高水平方向来支持基于目标的室外导航，同时处理室内不确定多路径预测。作为首个处理室内外目标导向和探索性导航的系统，AIGD 建立了盲人导航的新基准，并提供了方法、数据集、评估和部署见解以推动进一步创新。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the AAAI 2025 Spring Symposium on Human-Compatible AI for\n  Well-being: Harnessing Potential of GenAI for AI-Powered Science",
      "pdf_url": "http://arxiv.org/pdf/2501.07957v2",
      "published_date": "2025-01-14 09:21:17 UTC",
      "updated_date": "2025-02-17 00:40:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:32:26.607964"
    },
    {
      "arxiv_id": "2501.07945v1",
      "title": "Early prediction of the transferability of bovine embryos from videomicroscopy",
      "title_zh": "基于视频显微镜的牛胚胎可移植性早期预测",
      "authors": [
        "Yasmine Hachani",
        "Patrick Bouthemy",
        "Elisa Fromont",
        "Sylvie Ruffini",
        "Ludivine Laffont",
        "Alline de Paula Reis"
      ],
      "abstract": "Videomicroscopy is a promising tool combined with machine learning for\nstudying the early development of in vitro fertilized bovine embryos and\nassessing its transferability as soon as possible. We aim to predict the embryo\ntransferability within four days at most, taking 2D time-lapse microscopy\nvideos as input. We formulate this problem as a supervised binary\nclassification problem for the classes transferable and not transferable. The\nchallenges are three-fold: 1) poorly discriminating appearance and motion, 2)\nclass ambiguity, 3) small amount of annotated data. We propose a 3D\nconvolutional neural network involving three pathways, which makes it\nmulti-scale in time and able to handle appearance and motion in different ways.\nFor training, we retain the focal loss. Our model, named SFR, compares\nfavorably to other methods. Experiments demonstrate its effectiveness and\naccuracy for our challenging biological task.",
      "tldr_zh": "本研究旨在利用 videomicroscopy 和机器学习技术，尽早预测体外受精牛胚胎的可移植性，通过2D时间推移显微镜视频在最多四天内进行二元分类（transferable vs. not transferable）。为应对外观和运动不易区分、类别模糊以及标注数据量少的挑战，研究提出了一种多路径的3D convolutional neural network模型SFR，该模型在时间上多尺度处理，并采用focal loss进行训练。实验结果显示，SFR模型在这一生物任务中比其他方法更有效和准确，证明了其潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at the 2024 IEEE International Conference on Image\n  Processing",
      "pdf_url": "http://arxiv.org/pdf/2501.07945v1",
      "published_date": "2025-01-14 08:56:59 UTC",
      "updated_date": "2025-01-14 08:56:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:32:38.647569"
    },
    {
      "arxiv_id": "2501.07931v1",
      "title": "Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations",
      "title_zh": "ChatGPT 模型对糖尿病自我管理的建议：挑战和推荐",
      "authors": [
        "Waqar Hussain",
        "John Grundy"
      ],
      "abstract": "Given their ability for advanced reasoning, extensive contextual\nunderstanding, and robust question-answering abilities, large language models\nhave become prominent in healthcare management research. Despite adeptly\nhandling a broad spectrum of healthcare inquiries, these models face\nsignificant challenges in delivering accurate and practical advice for chronic\nconditions such as diabetes. We evaluate the responses of ChatGPT versions 3.5\nand 4 to diabetes patient queries, assessing their depth of medical knowledge\nand their capacity to deliver personalized, context-specific advice for\ndiabetes self-management. Our findings reveal discrepancies in accuracy and\nembedded biases, emphasizing the models' limitations in providing tailored\nadvice unless activated by sophisticated prompting techniques. Additionally, we\nobserve that both models often provide advice without seeking necessary\nclarification, a practice that can result in potentially dangerous advice. This\nunderscores the limited practical effectiveness of these models without human\noversight in clinical settings. To address these issues, we propose a\ncommonsense evaluation layer for prompt evaluation and incorporating\ndisease-specific external memory using an advanced Retrieval Augmented\nGeneration technique. This approach aims to improve information quality and\nreduce misinformation risks, contributing to more reliable AI applications in\nhealthcare settings. Our findings seek to influence the future direction of AI\nin healthcare, enhancing both the scope and quality of its integration.",
      "tldr_zh": "这篇论文评估了 ChatGPT 3.5 和 4 模型在提供糖尿病自理建议方面的表现，发现这些模型虽能处理广泛医疗查询，但存在准确性不一致、嵌入偏差以及无法提供个性化建议的问题，且经常不寻求澄清，导致潜在危险。研究强调了模型在临床设置中缺乏实际有效性，需要人类监督。作者提出解决方案，包括引入常识评估层进行提示评估，以及使用 Retrieval Augmented Generation (RAG) 技术整合疾病特定外部记忆，以提升信息质量、减少误导风险，并推动 AI 在医疗领域的可靠应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07931v1",
      "published_date": "2025-01-14 08:32:16 UTC",
      "updated_date": "2025-01-14 08:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:33:07.550858"
    },
    {
      "arxiv_id": "2501.07930v2",
      "title": "An Adaptive Orthogonal Convolution Scheme for Efficient and Flexible CNN Architectures",
      "title_zh": "一种自适应正交卷积方案，用于高效且灵活的卷积神经网络架构",
      "authors": [
        "Thibaut Boissin",
        "Franck Mamalet",
        "Thomas Fel",
        "Agustin Martin Picard",
        "Thomas Massena",
        "Mathieu Serrurier"
      ],
      "abstract": "Orthogonal convolutional layers are the workhorse of multiple areas in\nmachine learning, such as adversarial robustness, normalizing flows, GANs, and\nLipschitzconstrained models. Their ability to preserve norms and ensure stable\ngradient propagation makes them valuable for a large range of problems. Despite\ntheir promise, the deployment of orthogonal convolution in large-scale\napplications is a significant challenge due to computational overhead and\nlimited support for modern features like strides, dilations, group\nconvolutions, and transposed convolutions.In this paper, we introduce AOC\n(Adaptative Orthogonal Convolution), a scalable method for constructing\northogonal convolutions, effectively overcoming these limitations. This\nadvancement unlocks the construction of architectures that were previously\nconsidered impractical. We demonstrate through our experiments that our method\nproduces expressive models that become increasingly efficient as they scale. To\nfoster further advancement, we provide an open-source library implementing this\nmethod, available at https://github.com/thib-s/orthogonium.",
      "tldr_zh": "本文提出AOC（Adaptive Orthogonal Convolution），一种可扩展方案，用于构建正交卷积层，以解决其在CNN架构中的计算开销和对现代特征（如strides、dilations、group convolutions和transposed convolutions）的有限支持问题。正交卷积层因其在adversarial robustness、normalizing flows、GANs和Lipschitz-constrained models中的规范保留和梯度稳定传播能力而重要。实验结果显示，AOC方法能生成高效且可扩展的表达模型，随着规模增加效率提升。为推动进一步发展，作者提供了开源库（https://github.com/thib-s/orthogonium）。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07930v2",
      "published_date": "2025-01-14 08:32:12 UTC",
      "updated_date": "2025-03-20 08:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:33:19.808305"
    },
    {
      "arxiv_id": "2501.07927v2",
      "title": "Gandalf the Red: Adaptive Security for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Niklas Pfister",
        "Václav Volhejn",
        "Manuel Knott",
        "Santiago Arias",
        "Julia Bazińska",
        "Mykhailo Bichurin",
        "Alan Commike",
        "Janet Darling",
        "Peter Dienes",
        "Matthew Fiedler",
        "David Haber",
        "Matthias Kraft",
        "Marco Lancini",
        "Max Mathys",
        "Damián Pascual-Ortiz",
        "Jakub Podolak",
        "Adrià Romero-López",
        "Kyriacos Shiarlis",
        "Andreas Signer",
        "Zsolt Terek",
        "Athanasios Theocharis",
        "Daniel Timbrell",
        "Samuel Trautwein",
        "Samuel Watts",
        "Yun-Han Wu",
        "Mateo Rojas-Carulla"
      ],
      "abstract": "Current evaluations of defenses against prompt attacks in large language\nmodel (LLM) applications often overlook two critical factors: the dynamic\nnature of adversarial behavior and the usability penalties imposed on\nlegitimate users by restrictive defenses. We propose D-SEC (Dynamic Security\nUtility Threat Model), which explicitly separates attackers from legitimate\nusers, models multi-step interactions, and expresses the security-utility in an\noptimizable form. We further address the shortcomings in existing evaluations\nby introducing Gandalf, a crowd-sourced, gamified red-teaming platform designed\nto generate realistic, adaptive attack. Using Gandalf, we collect and release a\ndataset of 279k prompt attacks. Complemented by benign user data, our analysis\nreveals the interplay between security and utility, showing that defenses\nintegrated in the LLM (e.g., system prompts) can degrade usability even without\nblocking requests. We demonstrate that restricted application domains,\ndefense-in-depth, and adaptive defenses are effective strategies for building\nsecure and useful LLM applications.",
      "tldr_zh": "本文提出 D-SEC 威胁模型，用于评估大型语言模型(LLM)应用中提示攻击的防御，强调攻击者的动态行为和对合法用户的可用性影响，通过区分攻击者与用户并建模多步交互来优化安全-可用性平衡。研究团队开发了 Gandalf 平台，这是一个众包式游戏化红队工具，用于生成真实适应的攻击，并收集了 27.9k 条提示攻击数据集。分析结果显示，集成在 LLM 中的防御（如系统提示）可能降低可用性，而限制应用领域、防御深度和适应性策略能有效构建安全且实用的 LLM 应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Niklas Pfister, V\\'aclav Volhejn and Manuel Knott contributed equally",
      "pdf_url": "http://arxiv.org/pdf/2501.07927v2",
      "published_date": "2025-01-14 08:30:49 UTC",
      "updated_date": "2025-02-02 11:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:33:31.717659"
    },
    {
      "arxiv_id": "2501.07924v1",
      "title": "Exploring Aviation Incident Narratives Using Topic Modeling and Clustering Techniques",
      "title_zh": "使用主题建模和聚类技术探索航空事件叙述",
      "authors": [
        "Aziida Nanyonga",
        "Hassan Wasswa",
        "Ugur Turhan",
        "Keith Joiner",
        "Graham Wild"
      ],
      "abstract": "Aviation safety is a global concern, requiring detailed investigations into\nincidents to understand contributing factors comprehensively. This study uses\nthe National Transportation Safety Board (NTSB) dataset. It applies advanced\nnatural language processing (NLP) techniques, including Latent Dirichlet\nAllocation (LDA), Non-Negative Matrix Factorization (NMF), Latent Semantic\nAnalysis (LSA), Probabilistic Latent Semantic Analysis (pLSA), and K-means\nclustering. The main objectives are identifying latent themes, exploring\nsemantic relationships, assessing probabilistic connections, and cluster\nincidents based on shared characteristics. This research contributes to\naviation safety by providing insights into incident narratives and\ndemonstrating the versatility of NLP and topic modelling techniques in\nextracting valuable information from complex datasets. The results, including\ntopics identified from various techniques, provide an understanding of\nrecurring themes. Comparative analysis reveals that LDA performed best with a\ncoherence value of 0.597, pLSA of 0.583, LSA of 0.542, and NMF of 0.437.\nK-means clustering further reveals commonalities and unique insights into\nincident narratives. In conclusion, this study uncovers latent patterns and\nthematic structures within incident narratives, offering a comparative analysis\nof multiple-topic modelling techniques. Future research avenues include\nexploring temporal patterns, incorporating additional datasets, and developing\npredictive models for early identification of safety issues. This research lays\nthe groundwork for enhancing the understanding and improvement of aviation\nsafety by utilising the wealth of information embedded in incident narratives.",
      "tldr_zh": "这篇论文利用 National Transportation Safety Board (NTSB) 数据集，应用自然语言处理 (NLP) 技术，包括 Latent Dirichlet Allocation (LDA)、Non-Negative Matrix Factorization (NMF)、Latent Semantic Analysis (LSA)、Probabilistic Latent Semantic Analysis (pLSA) 和 K-means 聚类，来识别航空事件叙述中的潜在主题、语义关系和共享特征。研究发现 LDA 表现出色（coherence value 0.597），优于其他方法，并通过聚类揭示了事件的共同模式，从而为航空安全提供深入见解。总体而言，该工作展示了 NLP 和主题建模技术的多功能性，并为未来探索时间模式、整合更多数据集及开发预测模型铺平了道路。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "Topic Modelling, narratives, clustering, Aviation Incidents, NTSB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07924v1",
      "published_date": "2025-01-14 08:23:15 UTC",
      "updated_date": "2025-01-14 08:23:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:33:43.967228"
    },
    {
      "arxiv_id": "2501.07919v1",
      "title": "Large Language Model Interface for Home Energy Management Systems",
      "title_zh": "翻译失败",
      "authors": [
        "François Michelon",
        "Yihong Zhou",
        "Thomas Morstyn"
      ],
      "abstract": "Home Energy Management Systems (HEMSs) help households tailor their\nelectricity usage based on power system signals such as energy prices. This\ntechnology helps to reduce energy bills and offers greater demand-side\nflexibility that supports the power system stability. However, residents who\nlack a technical background may find it difficult to use HEMSs effectively,\nbecause HEMSs require well-formatted parameterization that reflects the\ncharacteristics of the energy resources, houses, and users' needs. Recently,\nLarge-Language Models (LLMs) have demonstrated an outstanding ability in\nlanguage understanding. Motivated by this, we propose an LLM-based interface\nthat interacts with users to understand and parameterize their\n``badly-formatted answers'', and then outputs well-formatted parameters to\nimplement an HEMS. We further use Reason and Act method (ReAct) and few-shot\nprompting to enhance the LLM performance. Evaluating the interface performance\nrequires multiple user--LLM interactions. To avoid the efforts in finding\nvolunteer users and reduce the evaluation time, we additionally propose a\nmethod that uses another LLM to simulate users with varying expertise, ranging\nfrom knowledgeable to non-technical. By comprehensive evaluation, the proposed\nLLM-based HEMS interface achieves an average parameter retrieval accuracy of\n88\\%, outperforming benchmark models without ReAct and/or few-shot prompting.",
      "tldr_zh": "该论文提出了一种基于 Large Language Models (LLMs) 的接口，用于 Home Energy Management Systems (HEMS)，旨在帮助非技术背景用户轻松理解和参数化能源使用，从而降低账单并提升电力系统稳定性。接口通过 Reason and Act method (ReAct) 和 few-shot prompting 技术处理用户的非结构化输入，生成正确格式的参数以实现HEMS优化。为评估该接口，论文使用另一个LLM模拟不同专业水平的用户，结果显示其参数检索准确率平均达到88%，优于未采用ReAct和/或few-shot prompting的基准模型。",
      "categories": [
        "cs.AI",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages conference paper",
      "pdf_url": "http://arxiv.org/pdf/2501.07919v1",
      "published_date": "2025-01-14 08:10:43 UTC",
      "updated_date": "2025-01-14 08:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:33:55.563655"
    },
    {
      "arxiv_id": "2501.07913v2",
      "title": "Governing AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Noam Kolt"
      ],
      "abstract": "The field of AI is undergoing a fundamental transition from generative models\nthat can produce synthetic content to artificial agents that can plan and\nexecute complex tasks with only limited human involvement. Companies that\npioneered the development of language models have now built AI agents that can\nindependently navigate the internet, perform a wide range of online tasks, and\nincreasingly serve as AI personal assistants and virtual coworkers. The\nopportunities presented by this new technology are tremendous, as are the\nassociated risks. Fortunately, there exist robust analytic frameworks for\nconfronting many of these challenges, namely, the economic theory of\nprincipal-agent problems and the common law doctrine of agency relationships.\nDrawing on these frameworks, this Article makes three contributions. First, it\nuses agency law and theory to identify and characterize problems arising from\nAI agents, including issues of information asymmetry, discretionary authority,\nand loyalty. Second, it illustrates the limitations of conventional solutions\nto agency problems: incentive design, monitoring, and enforcement might not be\neffective for governing AI agents that make uninterpretable decisions and\noperate at unprecedented speed and scale. Third, the Article explores the\nimplications of agency law and theory for designing and regulating AI agents,\narguing that new technical and legal infrastructure is needed to support\ngovernance principles of inclusivity, visibility, and liability.",
      "tldr_zh": "这篇论文探讨了AI agents的治理问题，结合委托代理理论(principal-agent problems)和代理关系法(agency relationships)框架，分析了这些代理在规划执行复杂任务时带来的机会与风险。论文的主要贡献包括：识别AI agents引发的挑战，如信息不对称、自由裁量权(discretionary authority)和忠诚度问题；揭示传统解决方案（如激励设计、监控和执行）的局限性，因为AI agents的决策不可解释且操作速度与规模超前；并提出通过新的技术和法律基础设施来设计和监管AI agents，支持包容性、可见性和责任(liability)原则。总的来说，该研究为有效治理AI agents提供了理论基础和实际建议。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Notre Dame Law Review, Vol. 101, Forthcoming",
      "pdf_url": "http://arxiv.org/pdf/2501.07913v2",
      "published_date": "2025-01-14 07:55:18 UTC",
      "updated_date": "2025-02-11 14:30:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:34:07.728928"
    },
    {
      "arxiv_id": "2501.07911v1",
      "title": "Deep Learning and Natural Language Processing in the Field of Construction",
      "title_zh": "建筑领域的深度",
      "authors": [
        "Rémy Kessler",
        "Nicolas Béchet"
      ],
      "abstract": "This article presents a complete process to extract hypernym relationships in\nthe field of construction using two main steps: terminology extraction and\ndetection of hypernyms from these terms. We first describe the corpus analysis\nmethod to extract terminology from a collection of technical specifications in\nthe field of construction. Using statistics and word n-grams analysis, we\nextract the domain's terminology and then perform pruning steps with linguistic\npatterns and internet queries to improve the quality of the final terminology.\nSecond, we present a machine-learning approach based on various words embedding\nmodels and combinations to deal with the detection of hypernyms from the\nextracted terminology. Extracted terminology is evaluated using a manual\nevaluation carried out by 6 experts in the domain, and the hypernym\nidentification method is evaluated with different datasets. The global approach\nprovides relevant and promising results.",
      "tldr_zh": "本论文提出了一种完整的过程，利用深度学习和自然语言处理技术，在建筑领域提取hypernym关系，包括术语提取和hypernym检测两个主要步骤。首先，通过统计分析和word n-grams方法从建筑技术规范集合中提取术语，并使用语言模式和互联网查询进行修剪，以提升术语质量。其次，采用基于machine-learning的模型结合多种词嵌入技术，从提取的术语中检测hypernym关系。该方法经6位领域专家手动评估术语，并使用不同数据集评估hypernym识别，结果显示整体方法具有相关性和前景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07911v1",
      "published_date": "2025-01-14 07:53:44 UTC",
      "updated_date": "2025-01-14 07:53:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:34:19.240008"
    },
    {
      "arxiv_id": "2501.07905v1",
      "title": "Logarithmic Memory Networks (LMNs): Efficient Long-Range Sequence Modeling for Resource-Constrained Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed A. Taha"
      ],
      "abstract": "Long-range sequence modeling is a crucial aspect of natural language\nprocessing and time series analysis. However, traditional models like Recurrent\nNeural Networks (RNNs) and Transformers suffer from computational and memory\ninefficiencies, especially when dealing with long sequences. This paper\nintroduces Logarithmic Memory Networks (LMNs), a novel architecture that\nleverages a hierarchical logarithmic tree structure to efficiently store and\nretrieve past information. LMNs dynamically summarize historical context,\nsignificantly reducing the memory footprint and computational complexity of\nattention mechanisms from O(n2) to O(log(n)). The model employs a\nsingle-vector, targeted attention mechanism to access stored information, and\nthe memory block construction worker (summarizer) layer operates in two modes:\na parallel execution mode during training for efficient processing of\nhierarchical tree structures and a sequential execution mode during inference,\nwhich acts as a memory management system. It also implicitly encodes positional\ninformation, eliminating the need for explicit positional encodings. These\nfeatures make LMNs a robust and scalable solution for processing long-range\nsequences in resource-constrained environments, offering practical improvements\nin efficiency and scalability. The code is publicly available under the MIT\nLicense on GitHub: https://github.com/AhmedBoin/LogarithmicMemory.",
      "tldr_zh": "这篇论文提出了 Logarithmic Memory Networks (LMNs)，一种新型架构，用于高效处理长序列建模问题，针对 Recurrent Neural Networks (RNNs) 和 Transformers 在资源受限环境中的计算和内存效率不足问题。LMNs 通过分层对数树结构动态总结历史上下文，并采用单向量目标注意力机制，将复杂度从 O(n²) 降低到 O(log(n))，同时在训练时使用并行执行模式，在推理时采用顺序模式作为内存管理系统。实验结果显示，LMNs 显著提高了效率和可扩展性，且隐式编码位置信息，无需显式位置编码，代码已在 GitHub 上开源。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.07905v1",
      "published_date": "2025-01-14 07:50:09 UTC",
      "updated_date": "2025-01-14 07:50:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:34:31.806083"
    },
    {
      "arxiv_id": "2501.07903v1",
      "title": "Optimal Classification Trees for Continuous Feature Data Using Dynamic Programming with Branch-and-Bound",
      "title_zh": "翻译失败",
      "authors": [
        "Catalin E. Brita",
        "Jacobus G. M. van der Linden",
        "Emir Demirović"
      ],
      "abstract": "Computing an optimal classification tree that provably maximizes training\nperformance within a given size limit, is NP-hard, and in practice, most\nstate-of-the-art methods do not scale beyond computing optimal trees of depth\nthree. Therefore, most methods rely on a coarse binarization of continuous\nfeatures to maintain scalability. We propose a novel algorithm that optimizes\ntrees directly on the continuous feature data using dynamic programming with\nbranch-and-bound. We develop new pruning techniques that eliminate many\nsub-optimal splits in the search when similar to previously computed splits and\nwe provide an efficient subroutine for computing optimal depth-two trees. Our\nexperiments demonstrate that these techniques improve runtime by one or more\norders of magnitude over state-of-the-art optimal methods and improve test\naccuracy by 5% over greedy heuristics.",
      "tldr_zh": "该论文解决了计算最优 classification trees 的 NP-hard 问题，提出了一种新算法，使用 dynamic programming with branch-and-bound 直接优化连续特征数据，而非依赖粗略二值化。算法引入新 pruning techniques 来消除与先前分割相似的次优选项，并提供高效子程序计算最优深度二 trees。实验结果表明，该方法比现有最优方法运行时间提高一个或多个数量级，并在测试准确率上比贪婪启发式方法提升 5%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "In the proceedings of AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2501.07903v1",
      "published_date": "2025-01-14 07:46:33 UTC",
      "updated_date": "2025-01-14 07:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:34:42.863248"
    },
    {
      "arxiv_id": "2501.07896v1",
      "title": "Anytime Cooperative Implicit Hitting Set Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Emma Rollón",
        "Javier Larrosa",
        "Aleksandra Petrova"
      ],
      "abstract": "The Implicit Hitting Set (HS) approach has shown to be very effective for\nMaxSAT, Pseudo-boolean optimization and other boolean frameworks. Very\nrecently, it has also shown its potential in the very similar Weighted CSP\nframework by means of the so-called cost-function merging. The original\nformulation of the HS approach focuses on obtaining increasingly better lower\nbounds (HS-lb). However, and as shown for Pseudo-Boolean Optimization, this\napproach can also be adapted to compute increasingly better upper bounds\n(HS-ub). In this paper we consider both HS approaches and show how they can be\neasily combined in a multithread architecture where cores discovered by either\ncomponent are available by the other which, interestingly, generates synergy\nbetween them. We show that the resulting algorithm (HS-lub) is consistently\nsuperior to either HS-lb and HS-ub in isolation. Most importantly, HS-lub has\nan effective anytime behaviour with which the optimality gap is reduced during\nthe execution. We tested our approach on the Weighted CSP framework and show on\nthree different benchmarks that our very simple implementation sometimes\noutperforms the parallel hybrid best-first search implementation of the far\nmore developed state-of-the-art Toulbar2.",
      "tldr_zh": "本文提出了一种名为 Anytime Cooperative Implicit Hitting Set Solving 的算法，即 HS-lub，通过将 Implicit Hitting Set 的下界优化 (HS-lb) 和上界优化 (HS-ub) 结合在多线程架构中，实现组件间的协同共享。HS-lub 算法不仅比单独的 HS-lb 或 HS-ub 更具优势，还具备 anytime 行为，能在执行过程中动态减少最优性差距。实验在 Weighted CSP 框架上的三个基准测试中显示，该算法的简单实现有时优于状态-of-the-art 的 Toulbar2 系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07896v1",
      "published_date": "2025-01-14 07:23:52 UTC",
      "updated_date": "2025-01-14 07:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:34:54.853744"
    },
    {
      "arxiv_id": "2501.07892v1",
      "title": "Leveraging Metamemory Mechanisms for Enhanced Data-Free Code Generation in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Wang",
        "Liang Ding",
        "Yibing Zhan",
        "Yong Luo",
        "Zheng He",
        "Dapeng Tao"
      ],
      "abstract": "Automated code generation using large language models (LLMs) has gained\nattention due to its efficiency and adaptability. However, real-world coding\ntasks or benchmarks like HumanEval and StudentEval often lack dedicated\ntraining datasets, challenging existing few-shot prompting approaches that rely\non reference examples. Inspired by human metamemory-a cognitive process\ninvolving recall and evaluation-we present a novel framework (namely M^2WF) for\nimproving LLMs' one-time code generation. This approach enables LLMs to\nautonomously generate, evaluate, and utilize synthetic examples to enhance\nreliability and performance. Unlike prior methods, it minimizes dependency on\ncurated data and adapts flexibly to various coding scenarios. Our experiments\ndemonstrate significant improvements in coding benchmarks, offering a scalable\nand robust solution for data-free environments. The code and framework will be\npublicly available on GitHub and HuggingFace.",
      "tldr_zh": "这篇论文受人类元记忆(metamemory)机制启发，提出了一种名为M^2WF的框架，用于提升大型语言模型(LLMs)在无数据环境下的代码生成性能。该框架让LLMs能够自主生成、评估和利用合成示例，从而减少对专用训练数据集的依赖，并适应多种编码场景。实验结果显示，在HumanEval和StudentEval等基准上，M^2WF显著提高了代码生成的可靠性和准确性，提供了一个可扩展的解决方案，相关代码将在GitHub和HuggingFace上公开。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages,6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.07892v1",
      "published_date": "2025-01-14 07:16:43 UTC",
      "updated_date": "2025-01-14 07:16:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:35:07.281756"
    },
    {
      "arxiv_id": "2501.07890v2",
      "title": "GRAPHMOE: Amplifying Cognitive Depth of Mixture-of-Experts Network via Introducing Self-Rethinking Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Tang",
        "Bo Lv",
        "Zifan Zheng",
        "Bohao Yang",
        "Kun Zhao",
        "Ning Liao",
        "Xiaoxing Wang",
        "Feiyu Xiong",
        "Zhiyu Li",
        "Nayu Liu",
        "Jingchi Jiang"
      ],
      "abstract": "Traditional Mixture-of-Experts (MoE) networks benefit from utilizing multiple\nsmaller expert models as opposed to a single large network. However, these\nexperts typically operate independently, leaving a question open about whether\ninterconnecting these models could enhance the performance of MoE networks. In\nresponse, we introduce GRAPHMOE, a novel method aimed at augmenting the\ncognitive depth of language models via a self-rethinking mechanism constructed\non Pseudo GraphMoE networks. GRAPHMOE employs a recurrent routing strategy to\nsimulate iterative thinking steps, thereby facilitating the flow of information\namong expert nodes. We implement the GRAPHMOE architecture using Low-Rank\nAdaptation techniques (LoRA) and conduct extensive experiments on various\nbenchmark datasets. The experimental results reveal that GRAPHMOE outperforms\nother LoRA based models, achieving state-of-the-art (SOTA) performance.\nAdditionally, this study explores a novel recurrent routing strategy that may\ninspire further advancements in enhancing the reasoning capabilities of\nlanguage models.",
      "tldr_zh": "本研究针对传统 Mixture-of-Experts (MoE) 网络中专家模型独立操作的问题，提出 GRAPHMOE 方法，通过引入自反思机制（self-rethinking mechanism）和基于 Pseudo GraphMoE networks 的架构，增强语言模型的认知深度。GRAPHMOE 采用循环路由策略（recurrent routing strategy）模拟迭代思考步骤，促进专家节点间的信息流动，并使用 Low-Rank Adaptation (LoRA) 技术实现。实验结果显示，GRAPHMOE 在各种基准数据集上超越其他 LoRA 基于模型，达到 state-of-the-art (SOTA) 性能。该方法还探索了新的循环路由策略，有望进一步提升语言模型的推理能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07890v2",
      "published_date": "2025-01-14 06:59:51 UTC",
      "updated_date": "2025-02-11 06:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:36:36.307869"
    },
    {
      "arxiv_id": "2501.07888v3",
      "title": "Tarsier2: Advancing Large Vision-Language Models from Detailed Video Description to Comprehensive Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Liping Yuan",
        "Jiawei Wang",
        "Haomiao Sun",
        "Yuchen Zhang",
        "Yuan Lin"
      ],
      "abstract": "We introduce Tarsier2, a state-of-the-art large vision-language model (LVLM)\ndesigned for generating detailed and accurate video descriptions, while also\nexhibiting superior general video understanding capabilities. Tarsier2 achieves\nsignificant advancements through three key upgrades: (1) Scaling pre-training\ndata from 11M to 40M video-text pairs, enriching both volume and diversity; (2)\nPerforming fine-grained temporal alignment during supervised fine-tuning; (3)\nUsing model-based sampling to automatically construct preference data and\napplying DPO training for optimization. Extensive experiments show that\nTarsier2-7B consistently outperforms leading proprietary models, including\nGPT-4o and Gemini 1.5 Pro, in detailed video description tasks. On the DREAM-1K\nbenchmark, Tarsier2-7B improves F1 by 2.8% over GPT-4o and 5.8% over\nGemini-1.5-Pro. In human side-by-side evaluations, Tarsier2-7B shows a +8.6%\nperformance advantage over GPT-4o and +24.9% over Gemini-1.5-Pro. Tarsier2-7B\nalso sets new state-of-the-art results across 15 public benchmarks, spanning\ntasks such as video question-answering, video grounding, hallucination test,\nand embodied question-answering, demonstrating its versatility as a robust\ngeneralist vision-language model.",
      "tldr_zh": "本研究介绍了 Tarsier2，一种先进的 Large Vision-Language Model (LVLM)，旨在从详细视频描述扩展到全面视频理解，通过提升模型在生成准确描述和一般任务上的性能。关键创新包括将预训练数据从 11M 扩展到 40M 视频-文本对以增加多样性、在监督微调中进行细粒度时间对齐，以及使用模型-based sampling 生成偏好数据并应用 DPO 训练进行优化。实验结果显示，Tarsier2-7B 在详细视频描述任务中超越 GPT-4o 和 Gemini 1.5 Pro，并在 DREAM-1K 基准上 F1 分数提升 2.8% 和 5.8%，同时在 15 个公共基准上（如视频问答、视频 grounding 和 hallucination 测试）设置了新状态-of-the-art 记录，证明其作为通用型 LVLM 的强大适应性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07888v3",
      "published_date": "2025-01-14 06:54:39 UTC",
      "updated_date": "2025-01-24 05:16:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:36:35.359033"
    },
    {
      "arxiv_id": "2501.07886v1",
      "title": "Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision",
      "title_zh": "在弱监督下，迭代标签精炼比偏好优化更重要",
      "authors": [
        "Yaowen Ye",
        "Cassidy Laidlaw",
        "Jacob Steinhardt"
      ],
      "abstract": "Language model (LM) post-training relies on two stages of human supervision:\ntask demonstrations for supervised finetuning (SFT), followed by preference\ncomparisons for reinforcement learning from human feedback (RLHF). As LMs\nbecome more capable, the tasks they are given become harder to supervise. Will\npost-training remain effective under unreliable supervision? To test this, we\nsimulate unreliable demonstrations and comparison feedback using small LMs and\ntime-constrained humans. We find that in the presence of unreliable\nsupervision, SFT still retains some effectiveness, but DPO (a common RLHF\nalgorithm) fails to improve the model beyond SFT. To address this, we propose\niterative label refinement (ILR) as an alternative to RLHF. ILR improves the\nSFT data by using comparison feedback to decide whether human demonstrations\nshould be replaced by model-generated alternatives, then retrains the model via\nSFT on the updated data. SFT+ILR outperforms SFT+DPO on several tasks with\nunreliable supervision (math, coding, and safe instruction-following). Our\nfindings suggest that as LMs are used for complex tasks where human supervision\nis unreliable, RLHF may no longer be the best use of human comparison feedback;\ninstead, it is better to direct feedback towards improving the training data\nrather than continually training the model. Our code and data are available at\nhttps://github.com/helloelwin/iterative-label-refinement.",
      "tldr_zh": "本研究探讨了在弱监督条件下，语言模型后续训练中监督微调(SFT)和强化学习从人类反馈(RLHF)算法DPO的有效性。实验通过模拟不可靠的演示和反馈发现，SFT在弱监督下仍能发挥作用，但DPO无法进一步提升模型性能。为此，研究提出迭代标签精炼(ILR)方法，该方法利用比较反馈决定是否用模型生成的替代方案替换人类演示，然后在更新数据上重新进行SFT。结果显示，SFT+ILR在数学、编码和安全指令遵循等任务上优于SFT+DPO，表明在复杂任务中，使用反馈改进训练数据比直接RLHF更有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.07886v1",
      "published_date": "2025-01-14 06:54:17 UTC",
      "updated_date": "2025-01-14 06:54:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:35:43.773893"
    },
    {
      "arxiv_id": "2501.07875v1",
      "title": "Continual Learning with Embedding Layer Surgery and Task-wise Beam Search using Whisper",
      "title_zh": "翻译失败",
      "authors": [
        "Chin Yuen Kwok",
        "Jia Qi Yip",
        "Eng Siong Chng"
      ],
      "abstract": "Current Multilingual ASR models only support a fraction of the world's\nlanguages. Continual Learning (CL) aims to tackle this problem by adding new\nlanguages to pre-trained models while avoiding the loss of performance on\nexisting languages, also known as Catastrophic Forgetting (CF). However,\nexisting CL methods overlook the adaptation of the token embedding lookup table\nat the decoder, despite its significant contribution to CF. We propose\nEmbedding Layer Surgery where separate copies of the token embeddings are\ncreated for each new languages, and one of the copies is selected to replace\nthe old languages embeddings when transcribing the corresponding new language.\nUnfortunately, this approach means LID errors also cause incorrect ASR\nembedding selection. Our Task-wise Beam Search allows self-correction for such\nmistakes. By adapting Whisper to 10 hours of data for each of 10 unseen\nlanguages from Common Voice, results show that our method reduces the Average\nWER (AWER) of pre-trained languages from 14.2% to 11.9% compared with\nExperience Replay, without compromising the AWER of the unseen languages.",
      "tldr_zh": "该论文针对多语言自动语音识别（ASR）模型支持语言有限的问题，提出了一种基于 Whisper 模型的 Continual Learning 方法，以避免 Catastrophic Forgetting（CF）。核心创新包括 Embedding Layer Surgery，该技术为每个新语言创建独立的 token embeddings，并在转录时选择适当的 embeddings，同时引入 Task-wise Beam Search 来自我修正语言识别错误。实验结果显示，通过将 Whisper 模型适应于 10 种未见语言的每种 10 小时数据，该方法将预训练语言的 Average WER（AWER）从 14.2% 降至 11.9%，且未见语言的性能保持不变，从而显著提升了 ASR 模型的持续学习能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in 2024 IEEE Spoken Language Technology Workshop",
      "pdf_url": "http://arxiv.org/pdf/2501.07875v1",
      "published_date": "2025-01-14 06:33:40 UTC",
      "updated_date": "2025-01-14 06:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:35:56.940825"
    },
    {
      "arxiv_id": "2501.07859v1",
      "title": "deepTerra -- AI Land Classification Made Easy",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Keith Wilkinson"
      ],
      "abstract": "deepTerra is a comprehensive platform designed to facilitate the\nclassification of land surface features using machine learning and satellite\nimagery. The platform includes modules for data collection, image augmentation,\ntraining, testing, and prediction, streamlining the entire workflow for image\nclassification tasks. This paper presents a detailed overview of the\ncapabilities of deepTerra, shows how it has been applied to various research\nareas, and discusses the future directions it might take.",
      "tldr_zh": "本论文介绍了 deepTerra，一个综合平台，使用机器学习和卫星图像简化土地表面特征分类过程。该平台包含数据收集、图像增强、训练、测试和预测模块，优化了整个图像分类工作流程。deepTerra 已应用于多种研究领域，并探讨了其未来的发展方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07859v1",
      "published_date": "2025-01-14 05:55:20 UTC",
      "updated_date": "2025-01-14 05:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:36:06.236281"
    },
    {
      "arxiv_id": "2501.07857v1",
      "title": "Hierarchical Repository-Level Code Summarization for Business Applications Using Local LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Nilesh Dhulshette",
        "Sapan Shah",
        "Vinay Kulkarni"
      ],
      "abstract": "In large-scale software development, understanding the functionality and\nintent behind complex codebases is critical for effective development and\nmaintenance. While code summarization has been widely studied, existing methods\nprimarily focus on smaller code units, such as functions, and struggle with\nlarger code artifacts like files and packages. Additionally, current\nsummarization models tend to emphasize low-level implementation details, often\noverlooking the domain and business context that are crucial for real-world\napplications. This paper proposes a two-step hierarchical approach for\nrepository-level code summarization, tailored to business applications. First,\nsmaller code units such as functions and variables are identified using syntax\nanalysis and summarized with local LLMs. These summaries are then aggregated to\ngenerate higher-level file and package summaries. To ensure the summaries are\ngrounded in business context, we design custom prompts that capture the\nintended purpose of code artifacts based on the domain and problem context of\nthe business application. We evaluate our approach on a business support system\n(BSS) for the telecommunications domain, showing that syntax analysis-based\nhierarchical summarization improves coverage, while business-context grounding\nenhances the relevance of the generated summaries.",
      "tldr_zh": "本文提出一种分层仓库级代码总结方法（Hierarchical Repository-Level Code Summarization），利用 Local LLMs 针对商业应用，解决现有方法忽略大型代码结构和业务上下文的问题。该方法采用两步过程：首先通过语法分析识别并总结函数和变量，然后聚合这些总结生成文件和包级别的高层摘要，并设计自定义提示以融入领域和业务上下文。在电信领域的业务支持系统（BSS）上进行评估，结果显示该方法显著提高了总结的覆盖率和相关性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To appear at LLM4Code@ICSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07857v1",
      "published_date": "2025-01-14 05:48:27 UTC",
      "updated_date": "2025-01-14 05:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:36:19.462761"
    },
    {
      "arxiv_id": "2501.07855v1",
      "title": "State-of-the-Art Transformer Models for Image Super-Resolution: Techniques, Challenges, and Applications",
      "title_zh": "最先进的 Transformer 模型",
      "authors": [
        "Debasish Dutta",
        "Deepjyoti Chetia",
        "Neeharika Sonowal",
        "Sanjib Kr Kalita"
      ],
      "abstract": "Image Super-Resolution (SR) aims to recover a high-resolution image from its\nlow-resolution counterpart, which has been affected by a specific degradation\nprocess. This is achieved by enhancing detail and visual quality. Recent\nadvancements in transformer-based methods have remolded image super-resolution\nby enabling high-quality reconstructions surpassing previous deep-learning\napproaches like CNN and GAN-based. This effectively addresses the limitations\nof previous methods, such as limited receptive fields, poor global context\ncapture, and challenges in high-frequency detail recovery. Additionally, the\npaper reviews recent trends and advancements in transformer-based SR models,\nexploring various innovative techniques and architectures that combine\ntransformers with traditional networks to balance global and local contexts.\nThese neoteric methods are critically analyzed, revealing promising yet\nunexplored gaps and potential directions for future research. Several\nvisualizations of models and techniques are included to foster a holistic\nunderstanding of recent trends. This work seeks to offer a structured roadmap\nfor researchers at the forefront of deep learning, specifically exploring the\nimpact of transformers on super-resolution techniques.",
      "tldr_zh": "本论文综述了图像超分辨率（Image Super-Resolution）领域的最新进展，聚焦于基于 Transformer 的模型，这些模型通过提升全局上下文捕捉和细节恢复能力，超越了传统的 CNN 和 GAN 方法。论文分析了 Transformer 与传统网络相结合的创新架构和技术，帮助平衡全局和本地上下文，同时揭示了高频细节恢复等挑战。研究者还探讨了当前趋势、未探索的空白以及未来研究方向，并提供了模型可视化以加深理解。该工作为深度学习研究者提供了结构化的路线图，旨在推动 Transformer 在超分辨率应用中的进一步发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07855v1",
      "published_date": "2025-01-14 05:43:59 UTC",
      "updated_date": "2025-01-14 05:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:36:30.663776"
    },
    {
      "arxiv_id": "2501.07853v1",
      "title": "Optimizing Language Models for Grammatical Acceptability: A Comparative Study of Fine-Tuning Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Shobhit Ratan",
        "Farley Knight",
        "Ghada Jerfel",
        "Sze Chung Ho"
      ],
      "abstract": "This study explores the fine-tuning (FT) of the Open Pre-trained Transformer\n(OPT-125M) for grammatical acceptability tasks using the CoLA dataset. By\ncomparing Vanilla-Fine-Tuning (VFT), Pattern-Based-Fine-Tuning (PBFT), and\nParameter-Efficient Fine-Tuning techniques (PEFT) like Low-Rank Adaptation\n(LoRA), we demonstrate significant improvements in computational efficiency\nwhile maintaining high accuracy. Our experiments reveal that while VFT achieves\nthe highest accuracy (81.2%), LoRA enhancing FT by reducing memory usage and\niteration time by more than 50%, and increases accuracy in PBFT case. Context\nDistillation (CD), though computationally efficient, underperformed with\naccuracy around 31%. Our findings contribute to democratizing access to large\nlanguage models (LLM) by reducing computational barriers.",
      "tldr_zh": "本研究比较了不同细调技术（Fine-Tuning, FT）优化 Open Pre-trained Transformer (OPT-125M) 模型在语法可接受性任务上的性能，使用 CoLA 数据集评估 Vanilla-Fine-Tuning (VFT)、Pattern-Based-Fine-Tuning (PBFT) 和 Parameter-Efficient Fine-Tuning (PEFT) 如 Low-Rank Adaptation (LoRA)，以及 Context Distillation (CD)。结果显示，VFT 取得了最高准确率（81.2%），而 LoRA 显著降低了内存使用和迭代时间（超过50%），并在 PBFT 场景中提升了准确率；相比之下，CD 虽计算效率高，但准确率仅约31%。这些发现有助于降低大型语言模型 (LLM) 的计算门槛，促进其民主化访问。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07853v1",
      "published_date": "2025-01-14 05:41:09 UTC",
      "updated_date": "2025-01-14 05:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:36:44.836793"
    },
    {
      "arxiv_id": "2501.07849v1",
      "title": "Unveiling Provider Bias in Large Language Models for Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Zhang",
        "Juan Zhai",
        "Shiqing Ma",
        "Qingshuang Bao",
        "Weipeng Jiang",
        "Chao Shen",
        "Yang Liu"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as the new recommendation engines,\noutperforming traditional methods in both capability and scope, particularly in\ncode generation applications. Our research reveals a novel provider bias in\nLLMs, namely without explicit input prompts, these models show systematic\npreferences for services from specific providers in their recommendations\n(e.g., favoring Google Cloud over Microsoft Azure). This bias holds significant\nimplications for market dynamics and societal equilibrium, potentially\npromoting digital monopolies. It may also deceive users and violate their\nexpectations, leading to various consequences. This paper presents the first\ncomprehensive empirical study of provider bias in LLM code generation. We\ndevelop a systematic methodology encompassing an automated pipeline for dataset\ngeneration, incorporating 6 distinct coding task categories and 30 real-world\napplication scenarios. Our analysis encompasses over 600,000 LLM-generated\nresponses across seven state-of-the-art models, utilizing approximately 500\nmillion tokens (equivalent to \\$5,000+ in computational costs). The study\nevaluates both the generated code snippets and their embedded service provider\nselections to quantify provider bias. Additionally, we conduct a comparative\nanalysis of seven debiasing prompting techniques to assess their efficacy in\nmitigating these biases. Our findings demonstrate that LLMs exhibit significant\nprovider preferences, predominantly favoring services from Google and Amazon,\nand can autonomously modify input code to incorporate their preferred providers\nwithout users' requests. Notably, we observe discrepancies between providers\nrecommended in conversational contexts versus those implemented in generated\ncode. The complete dataset and analysis results are available in our\nrepository.",
      "tldr_zh": "本研究揭示了大型语言模型（LLMs）在代码生成中存在的提供者偏见（provider bias），即模型在无明确提示下倾向于推荐特定提供者的服务（如Google和Amazon），可能加剧数字垄断并误导用户。研究者开发了一个系统方法，包括自动化数据集生成管道，涵盖6个编码任务类别和30个真实场景，并分析了超过600,000个LLMs生成响应（约500百万tokens）。通过评估生成的代码和嵌入的服务选择，他们发现LLMs会自主修改代码以融入偏好提供者，并在对话与代码实现间存在不一致；此外，比较了7种去偏见提示技术（debiasing prompting techniques）的效果，以缓解这种偏见。最终结果强调了LLMs偏见对市场和社会的影响，并提供了相关数据集。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.SE",
      "comment": "21 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.07849v1",
      "published_date": "2025-01-14 05:21:27 UTC",
      "updated_date": "2025-01-14 05:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:36:56.381790"
    },
    {
      "arxiv_id": "2501.07837v1",
      "title": "A Driver Advisory System Based on Large Language Model for High-speed Train",
      "title_zh": "基于大型语言模型的高速列车驾驶员咨询系统",
      "authors": [
        "Y. C. Luo",
        "J. Xun",
        "W. Wang",
        "R. Z. Zhang",
        "Z. C. Zhao"
      ],
      "abstract": "With the rapid development of China high-speed railway, drivers face\nincreasingly significant technical challenges during operations, such as fault\nhandling. Currently, drivers depend on the onboard mechanic when facing\ntechnical issues, for instance, traction loss or sensor faults. This dependency\ncan hinder effective operation, even lead to accidents, while waiting for\nfaults to be addressed. To enhance the accuracy and explainability of actions\nduring fault handling, an Intelligent Driver Advisory System (IDAS) framework\nbased on a large language model (LLM) named IDAS-LLM, is introduced. Initially,\ndomain-fine-tuning of the LLM is performed using a constructed railway\nknowledge question-and-answer dataset to improve answer accuracy in\nrailway-related questions. Subsequently, integration of the Retrieval-augmented\nGeneration (RAG) architecture is pursued for system design to enhance the\nexplainability of generated responses. Comparative experiments are conducted\nusing the constructed railway driving knowledge assessment dataset. Results\nindicate that domain-fine-tuned LLMs show an improvement in answer accuracy by\nan average of 10%, outperforming some current mainstream LLMs. Additionally,\nthe inclusion of the RAG framework increases the average recall rate of\nquestion-and-answer sessions by about 4%. Finally, the fault handling\ncapability of IDAS-LLM is demonstrated through simulations of real operational\nscenarios, proving that the proposed framework has practical application\nprospects.",
      "tldr_zh": "本文提出了一种基于 Large Language Model (LLM) 的智能驾驶员咨询系统 (IDAS-LLM)，旨在解决高铁司机在故障处理中的技术挑战，如牵引损失或传感器故障，提高操作的准确性和可解释性。系统通过使用构建的铁路知识问答数据集进行领域微调，并整合 Retrieval-augmented Generation (RAG) 架构，提升了模型对铁路相关问题的回答准确性。实验结果显示，微调后 LLM 的准确率平均提高 10%，RAG 框架使问答会话的召回率增加约 4%，并通过模拟真实场景验证了其故障处理能力，具有实际应用前景。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 7 figures, presented at 104th TRB Annual Meeting",
      "pdf_url": "http://arxiv.org/pdf/2501.07837v1",
      "published_date": "2025-01-14 04:41:03 UTC",
      "updated_date": "2025-01-14 04:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:37:08.803667"
    },
    {
      "arxiv_id": "2501.07834v2",
      "title": "Flow: Modularized Agentic Workflow Automation",
      "title_zh": "Flow：模块化智能体工作流自动化",
      "authors": [
        "Boye Niu",
        "Yiliao Song",
        "Kai Lian",
        "Yifan Shen",
        "Yu Yao",
        "Kun Zhang",
        "Tongliang Liu"
      ],
      "abstract": "Multi-agent frameworks powered by large language models (LLMs) have\ndemonstrated great success in automated planning and task execution. However,\nthe effective adjustment of agentic workflows during execution has not been\nwell studied. An effective workflow adjustment is crucial in real-world\nscenarios, as the initial plan must adjust to unforeseen challenges and\nchanging conditions in real time to ensure the efficient execution of complex\ntasks. In this paper, we define workflows as an activity-on-vertex (AOV) graph,\nwhich allows continuous workflow refinement by LLM agents through dynamic\nsubtask allocation adjustment based on historical performance and previous\nAOVs. To further enhance framework performance, we emphasize modularity in\nworkflow design based on evaluating parallelism and dependency complexity. With\nthis design, our proposed multi-agent framework achieves efficient concurrent\nexecution of subtasks, effective goal achievement, and enhanced error\ntolerance. Empirical results across various practical tasks demonstrate\nsignificant improvements in the efficiency of multi-agent frameworks through\ndynamic workflow refinement and modularization. The code is available at:\nhttps://github.com/tmllab/2025_ICLR_FLOW.",
      "tldr_zh": "该研究提出了一种名为Flow的多智能体框架，利用大型语言模型(LLMs)实现工作流的模块化自动化，重点解决执行过程中的动态调整问题。框架将工作流定义为基于活动顶点(AOV)图，通过LLM代理根据历史性能动态调整子任务分配，并强调模块化设计来评估并行性和依赖复杂性，从而实现高效的子任务并发执行、目标达成和错误容忍。实验结果显示，在各种实际任务中，该框架通过动态工作流优化和模块化显著提升了多智能体框架的效率，代码已在GitHub开源。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07834v2",
      "published_date": "2025-01-14 04:35:37 UTC",
      "updated_date": "2025-02-23 06:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:37:18.384298"
    },
    {
      "arxiv_id": "2501.13936v1",
      "title": "Evaluating Computational Accuracy of Large Language Models in Numerical Reasoning Tasks for Healthcare Applications",
      "title_zh": "评估大语言模型在医疗保健应用数值推理任务中的计算准确性",
      "authors": [
        "Arjun R. Malghan"
      ],
      "abstract": "Large Language Models (LLMs) have emerged as transformative tools in the\nhealthcare sector, demonstrating remarkable capabilities in natural language\nunderstanding and generation. However, their proficiency in numerical\nreasoning, particularly in high-stakes domains like in clinical applications,\nremains underexplored. Numerical reasoning is critical in healthcare\napplications, influencing patient outcomes, treatment planning, and resource\nallocation. This study investigates the computational accuracy of LLMs in\nnumerical reasoning tasks within healthcare contexts. Using a curated dataset\nof 1,000 numerical problems, encompassing real-world scenarios such as dosage\ncalculations and lab result interpretations, the performance of a refined LLM\nbased on the GPT-3 architecture was evaluated. The methodology includes prompt\nengineering, integration of fact-checking pipelines, and application of\nregularization techniques to enhance model accuracy and generalization. Key\nmetrics such as precision, recall, and F1-score were utilized to assess the\nmodel's efficacy. The results indicate an overall accuracy of 84.10%, with\nimproved performance in straightforward numerical tasks and challenges in\nmulti-step reasoning. The integration of a fact-checking pipeline improved\naccuracy by 11%, underscoring the importance of validation mechanisms. This\nresearch highlights the potential of LLMs in healthcare numerical reasoning and\nidentifies avenues for further refinement to support critical decision-making\nin clinical environments. The findings aim to contribute to the development of\nreliable, interpretable, and contextually relevant AI tools for healthcare.",
      "tldr_zh": "这篇论文评估了大型语言模型 (LLMs) 在医疗应用中的数值推理任务的计算准确性，重点关注其在临床决策中的表现，如剂量计算和实验室结果解释。研究使用一个包含 1,000 个真实场景问题的数据集，并基于 GPT-3 架构的精炼模型，结合提示工程、事实检查管道和正则化技术来提升准确性和泛化能力。结果显示，模型的整体准确率达到 84.10%，在简单数值任务中表现良好，但在多步推理中存在挑战，而事实检查机制提高了 11% 的性能。该研究强调了 LLMs 在医疗数值推理中的潜力，并为开发可靠、可解释的 AI 工具提供了改进方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 1 figure, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.13936v1",
      "published_date": "2025-01-14 04:29:43 UTC",
      "updated_date": "2025-01-14 04:29:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:37:32.505805"
    },
    {
      "arxiv_id": "2501.07824v4",
      "title": "Real-time Verification and Refinement of Language Model Text Generation",
      "title_zh": "实时验证和精炼语言模型文本生成",
      "authors": [
        "Joonho Ko",
        "Jinheon Baek",
        "Sung Ju Hwang"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance across a wide\nrange of natural language tasks. However, a critical challenge remains in that\nthey sometimes generate factually incorrect answers. To address this, while\nmany previous work has focused on identifying errors in their generation and\nfurther refining them, they are slow in deployment since they are designed to\nverify the response from LLMs only after their entire generation (from the\nfirst to last tokens) is done. Further, we observe that once LLMs generate\nincorrect tokens early on, there is a higher likelihood that subsequent tokens\nwill also be factually incorrect. To this end, in this work, we propose\nStreaming-VR (Streaming Verification and Refinement), a novel approach designed\nto enhance the efficiency of verification and refinement of LLM outputs.\nSpecifically, the proposed Streaming-VR enables on-the-fly verification and\ncorrection of tokens as they are being generated, similar to a streaming\nprocess, ensuring that each subset of tokens is checked and refined in\nreal-time by another LLM as the LLM constructs its response. Through\ncomprehensive evaluations on multiple datasets, we demonstrate that our\napproach not only enhances the factual accuracy of LLMs, but also offers a more\nefficient solution compared to prior refinement methods.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)生成事实错误的问题，提出了一种实时验证和修正方法，以解决现有方法只能在生成完成后检查的低效问题。研究观察到早期 token 的错误会增加后续错误的可能性，因此开发了 Streaming-VR 框架，该框架允许另一个 LLM 在生成过程中流式检查和即时修正每个 token 子集。实验结果显示，Streaming-VR 在多个数据集上显著提升了 LLMs 的事实准确性，并提供比传统方法更高效的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07824v4",
      "published_date": "2025-01-14 03:59:48 UTC",
      "updated_date": "2025-04-13 08:22:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:37:43.583297"
    },
    {
      "arxiv_id": "2501.07818v1",
      "title": "A Multi-Encoder Frozen-Decoder Approach for Fine-Tuning Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kaustubh D. Dhole"
      ],
      "abstract": "Among parameter-efficient fine-tuning methods, freezing has emerged as a\npopular strategy for speeding up training, reducing catastrophic forgetting,\nand improving downstream performance. We investigate the impact of freezing the\ndecoder in a multi-task setup comprising diverse natural language tasks, aiming\nto reduce deployment overhead and enhance portability to novel tasks. Our\nexperiments, conducted by fine-tuning both individual and multi-task setups on\nthe AlexaTM model, reveal that freezing decoders is highly effective for tasks\nwith natural language outputs and mitigates catastrophic forgetting in\nmultilingual tasks. However, we find that pairing frozen decoders with a larger\nmodel can effectively maintain or even enhance performance in structured and QA\ntasks, making it a viable strategy for a broader range of task types.",
      "tldr_zh": "本研究提出了一种多编码器冻结解码器（Multi-Encoder Frozen-Decoder）方法，用于微调大型语言模型（Large Language Models），旨在加速训练、减少灾难性遗忘（catastrophic forgetting）并提升下游任务性能。实验在AlexaTM模型上进行单任务和多任务微调，结果显示，冻结解码器对自然语言输出任务特别有效，并能缓解多语言任务中的遗忘问题。同时，与更大模型配对时，该方法能维持或提升结构化和QA任务的性能，使其适用于更广泛的任务类型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.5.1; I.5.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07818v1",
      "published_date": "2025-01-14 03:43:23 UTC",
      "updated_date": "2025-01-14 03:43:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:37:56.308585"
    },
    {
      "arxiv_id": "2501.07815v1",
      "title": "Agent-Centric Projection of Prompting Techniques and Implications for Synthetic Training Data for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dhruv Dhamani",
        "Mary Lou Maher"
      ],
      "abstract": "Recent advances in prompting techniques and multi-agent systems for Large\nLanguage Models (LLMs) have produced increasingly complex approaches. However,\nwe lack a framework for characterizing and comparing prompting techniques or\nunderstanding their relationship to multi-agent LLM systems. This position\npaper introduces and explains the concepts of linear contexts (a single,\ncontinuous sequence of interactions) and non-linear contexts (branching or\nmulti-path) in LLM systems. These concepts enable the development of an\nagent-centric projection of prompting techniques, a framework that can reveal\ndeep connections between prompting strategies and multi-agent systems. We\npropose three conjectures based on this framework: (1) results from non-linear\nprompting techniques can predict outcomes in equivalent multi-agent systems,\n(2) multi-agent system architectures can be replicated through single-LLM\nprompting techniques that simulate equivalent interaction patterns, and (3)\nthese equivalences suggest novel approaches for generating synthetic training\ndata. We argue that this perspective enables systematic cross-pollination of\nresearch findings between prompting and multi-agent domains, while providing\nnew directions for improving both the design and training of future LLM\nsystems.",
      "tldr_zh": "这篇论文提出了一种以智能体为中心的提示技术投影框架（agent-centric projection of prompting techniques），通过定义线性上下文（linear contexts）和非线性上下文（non-linear contexts），来揭示Large Language Models (LLMs)提示策略与多智能体系统之间的深层联系。论文基于此框架提出三个猜想：（1）非线性提示技术的结果可预测等效多智能体系统的表现，（2）多智能体系统架构可通过模拟交互模式的一个单一LLM提示技术来复制，以及（3）这些等效性可为生成合成训练数据（synthetic training data）提供新方法。总体而言，该框架促进了提示和多智能体领域的研究交叉，并为改进LLMs的设计和训练提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 5 figures. Accepted at ICAART 2025. Derived from an early\n  draft at 2312.17601. arXiv admin note: substantial text overlap with\n  arXiv:2312.17601",
      "pdf_url": "http://arxiv.org/pdf/2501.07815v1",
      "published_date": "2025-01-14 03:26:43 UTC",
      "updated_date": "2025-01-14 03:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:38:07.824970"
    },
    {
      "arxiv_id": "2501.07814v1",
      "title": "STTS-EAD: Improving Spatio-Temporal Learning Based Time Series Prediction via",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyuan Liang",
        "Tianhao Zhang",
        "Tingyu Xie"
      ],
      "abstract": "Handling anomalies is a critical preprocessing step in multivariate time\nseries prediction. However, existing approaches that separate anomaly\npreprocessing from model training for multivariate time series prediction\nencounter significant limitations. Specifically, these methods fail to utilize\nauxiliary information crucial for identifying latent anomalies associated with\nspatiotemporal factors during the preprocessing stage. Instead, they rely\nsolely on data distribution for anomaly detection, which can result in the\nincorrect processing of numerous samples that could otherwise contribute\npositively to model training. To address this, we propose STTS-EAD, an\nend-to-end method that seamlessly integrates anomaly detection into the\ntraining process of multivariate time series forecasting and aims to improve\nSpatio-Temporal learning based Time Series prediction via Embedded Anomaly\nDetection. Our proposed STTS-EAD leverages spatio-temporal information for\nforecasting and anomaly detection, with the two parts alternately executed and\noptimized for each other. To the best of our knowledge, STTS-EAD is the first\nto integrate anomaly detection and forecasting tasks in the training phase for\nimproving the accuracy of multivariate time series forecasting. Extensive\nexperiments on a public stock dataset and two real-world sales datasets from a\nrenowned coffee chain enterprise show that our proposed method can effectively\nprocess detected anomalies in the training stage to improve forecasting\nperformance in the inference stage and significantly outperform baselines.",
      "tldr_zh": "该论文提出 STTS-EAD，一种端到端方法，通过嵌入式异常检测(Embedded Anomaly Detection)来提升基于 Spatio-Temporal learning 的多变量时间序列预测。STTS-EAD 将异常检测与预测任务集成到训练过程中，利用时空信息使两者交替执行并相互优化，从而解决现有方法依赖数据分布导致的样本错误处理的局限性。这是首次在训练阶段整合这两任务，以提高预测准确性。实验在公共股票数据集和两个真实世界销售数据集上表明，STTS-EAD 显著超过了基线模型，在推理阶段提升了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07814v1",
      "published_date": "2025-01-14 03:26:05 UTC",
      "updated_date": "2025-01-14 03:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:38:20.023966"
    },
    {
      "arxiv_id": "2501.07813v1",
      "title": "Talk to Right Specialists: Routing and Planning in Multi-agent System for Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Feijie Wu",
        "Zitao Li",
        "Fei Wei",
        "Yaliang Li",
        "Bolin Ding",
        "Jing Gao"
      ],
      "abstract": "Leveraging large language models (LLMs), an agent can utilize\nretrieval-augmented generation (RAG) techniques to integrate external knowledge\nand increase the reliability of its responses. Current RAG-based agents\nintegrate single, domain-specific knowledge sources, limiting their ability and\nleading to hallucinated or inaccurate responses when addressing cross-domain\nqueries. Integrating multiple knowledge bases into a unified RAG-based agent\nraises significant challenges, including increased retrieval overhead and data\nsovereignty when sensitive data is involved. In this work, we propose RopMura,\na novel multi-agent system that addresses these limitations by incorporating\nhighly efficient routing and planning mechanisms. RopMura features two key\ncomponents: a router that intelligently selects the most relevant agents based\non knowledge boundaries and a planner that decomposes complex multi-hop queries\ninto manageable steps, allowing for coordinating cross-domain responses.\nExperimental results demonstrate that RopMura effectively handles both\nsingle-hop and multi-hop queries, with the routing mechanism enabling precise\nanswers for single-hop queries and the combined routing and planning mechanisms\nachieving accurate, multi-step resolutions for complex queries.",
      "tldr_zh": "该论文提出RopMura，一种多智能体系统，用于解决基于大型语言模型(LLMs)和检索增强生成(RAG)技术的问答代理在处理跨领域查询时的问题，如幻觉响应和检索开销增加。RopMura的关键组件包括router（路由器），它根据知识边界智能选择相关代理，以及planner（规划器），它将复杂多跳(multi-hop)查询分解成可管理步骤，以协调跨领域响应。实验结果显示，RopMura在单跳(single-hop)和多跳查询上均表现出色，路由机制提供精确答案，而结合路由和规划机制实现了准确的多步解决方案。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.MA",
      "comment": "Work In Progress",
      "pdf_url": "http://arxiv.org/pdf/2501.07813v1",
      "published_date": "2025-01-14 03:25:26 UTC",
      "updated_date": "2025-01-14 03:25:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:38:32.723297"
    },
    {
      "arxiv_id": "2501.07809v1",
      "title": "Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs): learning neural networks for designing neutral inclusions",
      "title_zh": "翻译失败",
      "authors": [
        "Daehee Cho",
        "Hyeonmin Yun",
        "Jaeyong Lee",
        "Mikyoung Lim"
      ],
      "abstract": "We focus on designing and solving the neutral inclusion problem via neural\nnetworks. The neutral inclusion problem has a long history in the theory of\ncomposite materials, and it is exceedingly challenging to identify the precise\ncondition that precipitates a general-shaped inclusion into a neutral\ninclusion. Physics-informed neural networks (PINNs) have recently become a\nhighly successful approach to addressing both forward and inverse problems\nassociated with partial differential equations. We found that traditional PINNs\nperform inadequately when applied to the inverse problem of designing neutral\ninclusions with arbitrary shapes. In this study, we introduce a novel approach,\nConformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs),\nwhich integrates complex analysis techniques into PINNs. This method exhibits\nstrong performance in solving forward-inverse problems to construct neutral\ninclusions of arbitrary shapes in two dimensions, where the imperfect interface\ncondition on the inclusion's boundary is modeled by training neural networks.\nNotably, we mathematically prove that training with a single linear field is\nsufficient to achieve neutrality for untrained linear fields in arbitrary\ndirections, given a minor assumption. We demonstrate that CoCo-PINNs offer\nenhanced performances in terms of credibility, consistency, and stability.",
      "tldr_zh": "本研究针对中性包容体（neutral inclusions）设计问题，引入了CoCo-PINNs方法，该方法将共形映射（Conformal mapping）技术整合到Physics-Informed Neural Networks (PINNs)中，以解决传统PINNs在处理任意形状包容体的逆问题时表现不佳的问题。\nCoCo-PINNs在二维空间中表现出色，能够通过训练神经网络模拟不完美界面条件，从而构建任意形状的中性包容体。\n研究还数学证明了，仅需一个线性场训练即可实现对未训练线性场的中性性，前提是一个小假设，并展示了CoCo-PINNs在可信度、一致性和稳定性方面的显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07809v1",
      "published_date": "2025-01-14 03:20:17 UTC",
      "updated_date": "2025-01-14 03:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:38:44.686860"
    },
    {
      "arxiv_id": "2501.07808v1",
      "title": "A Low-cost and Ultra-lightweight Binary Neural Network for Traffic Signal Recognition",
      "title_zh": "一种低成本且超轻量级的二进制神经网络用于交通信号识别",
      "authors": [
        "Mingke Xiao",
        "Yue Su",
        "Liang Yu",
        "Guanglong Qu",
        "Yutong Jia",
        "Yukuan Chang",
        "Xu Zhang"
      ],
      "abstract": "The deployment of neural networks in vehicle platforms and wearable\nArtificial Intelligence-of-Things (AIOT) scenarios has become a research area\nthat has attracted much attention. With the continuous evolution of deep\nlearning technology, many image classification models are committed to\nimproving recognition accuracy, but this is often accompanied by problems such\nas large model resource usage, complex structure, and high power consumption,\nwhich makes it challenging to deploy on resource-constrained platforms. Herein,\nwe propose an ultra-lightweight binary neural network (BNN) model designed for\nhardware deployment, and conduct image classification research based on the\nGerman Traffic Sign Recognition Benchmark (GTSRB) dataset. In addition, we also\nverify it on the Chinese Traffic Sign (CTS) and Belgian Traffic Sign (BTS)\ndatasets. The proposed model shows excellent recognition performance with an\naccuracy of up to 97.64%, making it one of the best performing BNN models in\nthe GTSRB dataset. Compared with the full-precision model, the accuracy loss is\ncontrolled within 1%, and the parameter storage overhead of the model is only\n10% of that of the full-precision model. More importantly, our network model\nonly relies on logical operations and low-bit width fixed-point addition and\nsubtraction operations during the inference phase, which greatly simplifies the\ndesign complexity of the processing element (PE). Our research shows the great\npotential of BNN in the hardware deployment of computer vision models,\nespecially in the field of computer vision tasks related to autonomous driving.",
      "tldr_zh": "本研究提出了一种低成本、超轻量级的 Binary Neural Network (BNN) 模型，用于交通信号识别，旨在解决传统神经网络在车辆平台和可穿戴 AIoT 场景中的资源占用大、结构复杂和高功耗问题。模型基于 German Traffic Sign Recognition Benchmark (GTSRB) 数据集进行图像分类训练，并在 Chinese Traffic Sign (CTS) 和 Belgian Traffic Sign (BTS) 数据集上验证，实现了高达 97.64% 的准确率，同时比全精度模型的准确率损失仅 1%，参数存储开销仅为其 10%。在推理阶段，该模型仅依赖逻辑操作和低位宽定点加减法，极大简化了处理元素 (PE) 的设计复杂度。总体而言，此研究突显了 BNN 在自动驾驶相关计算机视觉任务的硬件部署潜力。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07808v1",
      "published_date": "2025-01-14 03:19:10 UTC",
      "updated_date": "2025-01-14 03:19:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:38:56.722062"
    },
    {
      "arxiv_id": "2501.07802v1",
      "title": "Visual Language Models as Operator Agents in the Space Domain",
      "title_zh": "视觉语言模型作为空间领域的操作代理",
      "authors": [
        "Alejandro Carrasco",
        "Marco Nedungadi",
        "Enrico M. Zucchelli",
        "Amit Jain",
        "Victor Rodriguez-Fernandez",
        "Richard Linares"
      ],
      "abstract": "This paper explores the application of Vision-Language Models (VLMs) as\noperator agents in the space domain, focusing on both software and hardware\noperational paradigms. Building on advances in Large Language Models (LLMs) and\ntheir multimodal extensions, we investigate how VLMs can enhance autonomous\ncontrol and decision-making in space missions. In the software context, we\nemploy VLMs within the Kerbal Space Program Differential Games (KSPDG)\nsimulation environment, enabling the agent to interpret visual screenshots of\nthe graphical user interface to perform complex orbital maneuvers. In the\nhardware context, we integrate VLMs with robotic systems equipped with cameras\nto inspect and diagnose physical space objects, such as satellites. Our results\ndemonstrate that VLMs can effectively process visual and textual data to\ngenerate contextually appropriate actions, competing with traditional methods\nand non-multimodal LLMs in simulation tasks, and showing promise in real-world\napplications.",
      "tldr_zh": "本研究探讨了视觉语言模型（VLMs）作为操作代理在太空领域的应用，旨在通过多模态扩展增强LLMs来实现自主控制和决策。研究在软件方面利用VLMs于Kerbal Space Program Differential Games (KSPDG)模拟环境，让代理解读视觉截图以执行复杂的轨道机动；在硬件方面，则将VLMs整合到配备摄像头的机器人系统中，用于检查和诊断卫星等物理太空物体。结果显示，VLMs能有效处理视觉和文本数据，生成合适的行动，在模拟任务中与传统方法和非多模态LLMs竞争，并在现实世界应用中展现出潜力。",
      "categories": [
        "cs.AI",
        "physics.space-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "Updated version of the paper presented in 2025 AIAA SciTech.\n  https://arc.aiaa.org/doi/10.2514/6.2025-1543",
      "pdf_url": "http://arxiv.org/pdf/2501.07802v1",
      "published_date": "2025-01-14 03:03:37 UTC",
      "updated_date": "2025-01-14 03:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:39:07.737064"
    },
    {
      "arxiv_id": "2501.07801v1",
      "title": "A Comparative Analysis of DNN-based White-Box Explainable AI Methods in Network Security",
      "title_zh": "翻译失败",
      "authors": [
        "Osvaldo Arreche",
        "Mustafa Abdallah"
      ],
      "abstract": "New research focuses on creating artificial intelligence (AI) solutions for\nnetwork intrusion detection systems (NIDS), drawing its inspiration from the\never-growing number of intrusions on networked systems, increasing its\ncomplexity and intelligibility. Hence, the use of explainable AI (XAI)\ntechniques in real-world intrusion detection systems comes from the requirement\nto comprehend and elucidate black-box AI models to security analysts. In an\neffort to meet such requirements, this paper focuses on applying and evaluating\nWhite-Box XAI techniques (particularly LRP, IG, and DeepLift) for NIDS via an\nend-to-end framework for neural network models, using three widely used network\nintrusion datasets (NSL-KDD, CICIDS-2017, and RoEduNet-SIMARGL2021), assessing\nits global and local scopes, and examining six distinct assessment measures\n(descriptive accuracy, sparsity, stability, robustness, efficiency, and\ncompleteness). We also compare the performance of white-box XAI methods with\nblack-box XAI methods. The results show that using White-box XAI techniques\nscores high in robustness and completeness, which are crucial metrics for IDS.\nMoreover, the source codes for the programs developed for our XAI evaluation\nframework are available to be improved and used by the research community.",
      "tldr_zh": "这篇论文对基于深度神经网络 (DNN) 的 White-Box Explainable AI (XAI) 方法在网络安全中的应用进行了比较分析，重点针对网络入侵检测系统 (NIDS) 的黑箱模型解释。研究评估了 LRP、IG 和 DeepLift 等 White-Box XAI 技术，通过一个端到端框架应用在 NSL-KDD、CICIDS-2017 和 RoEduNet-SIMARGL2021 等数据集上，并使用 descriptive accuracy、sparsity、stability、robustness、efficiency 和 completeness 等六种指标进行全局和局部评估。论文还比较了 White-Box XAI 与 Black-Box XAI 的性能，结果表明 White-Box XAI 在 robustness 和 completeness 方面表现出色。最后，提供开源代码以支持社区进一步改进和应用。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07801v1",
      "published_date": "2025-01-14 02:57:20 UTC",
      "updated_date": "2025-01-14 02:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:39:21.420182"
    },
    {
      "arxiv_id": "2501.07800v1",
      "title": "BioPose: Biomechanically-accurate 3D Pose Estimation from Monocular Videos",
      "title_zh": "BioPose: 基于单目视频的生物力学准确",
      "authors": [
        "Farnoosh Koleini",
        "Muhammad Usama Saleem",
        "Pu Wang",
        "Hongfei Xue",
        "Ahmed Helmy",
        "Abbey Fenwick"
      ],
      "abstract": "Recent advancements in 3D human pose estimation from single-camera images and\nvideos have relied on parametric models, like SMPL. However, these models\noversimplify anatomical structures, limiting their accuracy in capturing true\njoint locations and movements, which reduces their applicability in\nbiomechanics, healthcare, and robotics. Biomechanically accurate pose\nestimation, on the other hand, typically requires costly marker-based motion\ncapture systems and optimization techniques in specialized labs. To bridge this\ngap, we propose BioPose, a novel learning-based framework for predicting\nbiomechanically accurate 3D human pose directly from monocular videos. BioPose\nincludes three key components: a Multi-Query Human Mesh Recovery model\n(MQ-HMR), a Neural Inverse Kinematics (NeurIK) model, and a 2D-informed pose\nrefinement technique. MQ-HMR leverages a multi-query deformable transformer to\nextract multi-scale fine-grained image features, enabling precise human mesh\nrecovery. NeurIK treats the mesh vertices as virtual markers, applying a\nspatial-temporal network to regress biomechanically accurate 3D poses under\nanatomical constraints. To further improve 3D pose estimations, a 2D-informed\nrefinement step optimizes the query tokens during inference by aligning the 3D\nstructure with 2D pose observations. Experiments on benchmark datasets\ndemonstrate that BioPose significantly outperforms state-of-the-art methods.\nProject website:\n\\url{https://m-usamasaleem.github.io/publication/BioPose/BioPose.html}.",
      "tldr_zh": "本文提出BioPose，一种新型学习框架，用于从单目视频直接估计生物力学准确的3D人体姿势，解决了传统方法如基于SMPL的模型在解剖结构简化方面的问题。BioPose包括三个关键组件：Multi-Query Human Mesh Recovery (MQ-HMR)模型用于提取多尺度图像特征进行精确网格恢复、Neural Inverse Kinematics (NeurIK)模型在解剖约束下回归准确3D姿势，以及2D-informed pose refinement技术通过优化查询令牌与2D观察对齐。实验在基准数据集上表明，BioPose显著优于现有方法，为生物力学、健康和机器人领域提供更可靠的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07800v1",
      "published_date": "2025-01-14 02:56:19 UTC",
      "updated_date": "2025-01-14 02:56:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:39:32.921201"
    },
    {
      "arxiv_id": "2501.07774v1",
      "title": "Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors",
      "title_zh": "革新室内定位：高级 Transformer 架构用于 NLOS 主导的无线环境",
      "authors": [
        "Saad Masrur",
        "Jung-Fu",
        "Cheng",
        "Atieh R. Khamesi",
        "Ismail Guvenc"
      ],
      "abstract": "Indoor localization in challenging non-line-of-sight (NLOS) environments\noften leads to mediocre accuracy with traditional approaches. Deep learning\n(DL) has been applied to tackle these challenges; however, many DL approaches\noverlook computational complexity, especially for floating-point operations\n(FLOPs), making them unsuitable for resource-limited devices. Transformer-based\nmodels have achieved remarkable success in natural language processing (NLP)\nand computer vision (CV) tasks, motivating their use in wireless applications.\nHowever, their use in indoor localization remains nascent, and directly\napplying Transformers for indoor localization can be both computationally\nintensive and exhibit limitations in accuracy. To address these challenges, in\nthis work, we introduce a novel tokenization approach, referred to as Sensor\nSnapshot Tokenization (SST), which preserves variable-specific representations\nof power delay profile (PDP) and enhances attention mechanisms by effectively\ncapturing multi-variate correlation. Complementing this, we propose a\nlightweight Swish-Gated Linear Unit-based Transformer (L-SwiGLU Transformer)\nmodel, designed to reduce computational complexity without compromising\nlocalization accuracy. Together, these contributions mitigate the computational\nburden and dependency on large datasets, making Transformer models more\nefficient and suitable for resource-constrained scenarios. The proposed\ntokenization method enables the Vanilla Transformer to achieve a 90th\npercentile positioning error of 0.388 m in a highly NLOS indoor factory,\nsurpassing conventional tokenization methods. The L-SwiGLU ViT further reduces\nthe error to 0.355 m, achieving an 8.51% improvement. Additionally, the\nproposed model outperforms a 14.1 times larger model with a 46.13% improvement,\nunderscoring its computational efficiency.",
      "tldr_zh": "该研究针对非直线视线（NLOS）主导的室内无线环境，提出了一种先进的Transformer架构，以提升定位准确性并降低计算复杂度。论文引入Sensor Snapshot Tokenization (SST)方法，通过保留功率延迟剖面（PDP）的变量特定表示并增强注意力机制，捕获多变量相关性；同时，提出轻量级Swish-Gated Linear Unit-based Transformer (L-SwiGLU Transformer)模型，减少浮点运算（FLOPs）负担而不牺牲性能。实验结果显示，SST使Vanilla Transformer在高度NLOS室内工厂环境中实现90th分位数定位误差为0.388 m，优于传统方法，而L-SwiGLU ViT进一步将误差降至0.355 m，改善8.51%，并比一个14.1倍大的模型提高46.13%的效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been submitted to IEEE Transactions on Machine Learning\n  in Communications and Networking",
      "pdf_url": "http://arxiv.org/pdf/2501.07774v1",
      "published_date": "2025-01-14 01:16:30 UTC",
      "updated_date": "2025-01-14 01:16:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:39:45.154650"
    },
    {
      "arxiv_id": "2501.07766v2",
      "title": "Large Language Models for Knowledge Graph Embedding: A Survey",
      "title_zh": "大型语言模型用于",
      "authors": [
        "Bingchen Liu",
        "Yuanyuan Fang",
        "Naixing Xu",
        "Shihao Hou",
        "Xin Li",
        "Qian Li"
      ],
      "abstract": "Large language models (LLMs) have garnered significant attention for their\nsuperior performance in many knowledge-driven applications on the world wide\nweb.These models are designed to train hundreds of millions or more parameters\non large amounts of text data, enabling them to understand and generate\nnaturallanguage effectively. As the superior performance of LLMs becomes\napparent,they are increasingly being applied to knowledge graph embedding (KGE)\nrelated tasks to improve the processing results. Traditional KGE representation\nlearning methods map entities and relations into a low-dimensional vector\nspace, enablingthe triples in the knowledge graph to satisfy a specific scoring\nfunction in thevector space. However, based on the powerful language\nunderstanding and seman-tic modeling capabilities of LLMs, that have recently\nbeen invoked to varying degrees in different types of KGE related scenarios\nsuch as multi-modal KGE andopen KGE according to their task characteristics. In\nthis paper, we investigate awide range of approaches for performing\nLLMs-related tasks in different types of KGE scenarios. To better compare the\nvarious approaches, we summarize each KGE scenario in a classification.\nFinally, we discuss the applications in which the methods are mainly used and\nsuggest several forward-looking directions for the development of this new\nresearch area.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型（LLMs）在知识图嵌入（KGE）任务中的应用，强调了 LLMs 通过其强大的语言理解和语义建模能力，如何提升传统 KGE 方法的性能，例如在多模态 KGE 和开放 KGE 等场景中。论文对各种 LLMs 相关方法进行了分类和总结，涵盖了实体关系映射到低维向量空间的改进策略。最终，它讨论了这些方法的实际应用，并提出了未来研究方向，如进一步优化 LLMs 在 KGE 领域的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07766v2",
      "published_date": "2025-01-14 00:47:24 UTC",
      "updated_date": "2025-04-08 08:33:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:39:54.959839"
    },
    {
      "arxiv_id": "2501.07764v1",
      "title": "Deep Learning for Disease Outbreak Prediction: A Robust Early Warning Signal for Transcritical Bifurcations",
      "title_zh": "深度学习用于疾病爆发预测：一种针对横向临界分叉的鲁棒早期预警信号",
      "authors": [
        "Reza Miry",
        "Amit K. Chakraborty",
        "Russell Greiner",
        "Mark A. Lewis",
        "Hao Wang",
        "Tianyu Guan",
        "Pouria Ramazi"
      ],
      "abstract": "Early Warning Signals (EWSs) are vital for implementing preventive measures\nbefore a disease turns into a pandemic. While new diseases exhibit unique\nbehaviors, they often share fundamental characteristics from a dynamical\nsystems perspective. Moreover, measurements during disease outbreaks are often\ncorrupted by different noise sources, posing challenges for Time Series\nClassification (TSC) tasks. In this study, we address the problem of having a\nrobust EWS for disease outbreak prediction using a best-performing deep\nlearning model in the domain of TSC. We employed two simulated datasets to\ntrain the model: one representing generated dynamical systems with randomly\nselected polynomial terms to model new disease behaviors, and another\nsimulating noise-induced disease dynamics to account for noisy measurements.\nThe model's performance was analyzed using both simulated data from different\ndisease models and real-world data, including influenza and COVID-19. Results\ndemonstrate that the proposed model outperforms previous models, effectively\nproviding EWSs of impending outbreaks across various scenarios. This study\nbridges advancements in deep learning with the ability to provide robust early\nwarning signals in noisy environments, making it highly applicable to\nreal-world crises involving emerging disease outbreaks.",
      "tldr_zh": "本文提出一种基于深度学习的鲁棒 Early Warning Signals (EWSs)，用于预测疾病爆发，特别是针对 Transcritical Bifurcations，通过处理噪声干扰和时间序列分类 (TSC) 挑战。研究利用两个模拟数据集训练模型：一个模拟随机多项式项的动态系统以代表新疾病行为，另一个模拟噪声诱导的疾病动态。实验结果显示，该模型在模拟数据和真实世界数据（如流感和 COVID-19）上优于现有方法，提供有效的预警信号。总体而言，此研究桥接了深度学习与动态系统分析，提升了在噪声环境中的疾病爆发预测能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.07764v1",
      "published_date": "2025-01-14 00:47:05 UTC",
      "updated_date": "2025-01-14 00:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:40:08.664128"
    },
    {
      "arxiv_id": "2501.07763v1",
      "title": "On the Statistical Capacity of Deep Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Edric Tam",
        "David B. Dunson"
      ],
      "abstract": "Deep generative models are routinely used in generating samples from complex,\nhigh-dimensional distributions. Despite their apparent successes, their\nstatistical properties are not well understood. A common assumption is that\nwith enough training data and sufficiently large neural networks, deep\ngenerative model samples will have arbitrarily small errors in sampling from\nany continuous target distribution. We set up a unifying framework that debunks\nthis belief. We demonstrate that broad classes of deep generative models,\nincluding variational autoencoders and generative adversarial networks, are not\nuniversal generators. Under the predominant case of Gaussian latent variables,\nthese models can only generate concentrated samples that exhibit light tails.\nUsing tools from concentration of measure and convex geometry, we give\nanalogous results for more general log-concave and strongly log-concave latent\nvariable distributions. We extend our results to diffusion models via a\nreduction argument. We use the Gromov--Levy inequality to give similar\nguarantees when the latent variables lie on manifolds with positive Ricci\ncurvature. These results shed light on the limited capacity of common deep\ngenerative models to handle heavy tails. We illustrate the empirical relevance\nof our work with simulations and financial data.",
      "tldr_zh": "这篇论文探讨了深度生成模型（deep generative models）的统计能力，挑战了这些模型能完美采样任何连续分布的假设。研究证明，变分自编码器（VAEs）和生成对抗网络（GANs）等模型在高斯潜在变量（Gaussian latent variables）下，仅能生成轻尾分布的样本，而非通用生成器。作者使用浓度不等式（concentration of measure）和凸几何工具扩展了这一结论到更一般的log-concave分布，并通过归约论证应用于扩散模型（diffusion models），并借助Gromov-Levy inequality分析潜在变量在Ricci曲率正的流形上的表现。实验结果通过模拟和金融数据验证了这些模型在处理重尾分布时的局限性，为理解其统计边界提供了重要洞见。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07763v1",
      "published_date": "2025-01-14 00:39:46 UTC",
      "updated_date": "2025-01-14 00:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:40:20.791244"
    },
    {
      "arxiv_id": "2501.07762v2",
      "title": "PSReg: Prior-guided Sparse Mixture of Experts for Point Cloud Registration",
      "title_zh": "PSReg: 先验引导的稀疏混合专家用于点云配准",
      "authors": [
        "Xiaoshui Huang",
        "Zhou Huang",
        "Yifan Zuo",
        "Yongshun Gong",
        "Chengdong Zhang",
        "Deyang Liu",
        "Yuming Fang"
      ],
      "abstract": "The discriminative feature is crucial for point cloud registration. Recent\nmethods improve the feature discriminative by distinguishing between\nnon-overlapping and overlapping region points. However, they still face\nchallenges in distinguishing the ambiguous structures in the overlapping\nregions. Therefore, the ambiguous features they extracted resulted in a\nsignificant number of outlier matches from overlapping regions. To solve this\nproblem, we propose a prior-guided SMoE-based registration method to improve\nthe feature distinctiveness by dispatching the potential correspondences to the\nsame experts. Specifically, we propose a prior-guided SMoE module by fusing\nprior overlap and potential correspondence embeddings for routing, assigning\ntokens to the most suitable experts for processing. In addition, we propose a\nregistration framework by a specific combination of Transformer layer and\nprior-guided SMoE module. The proposed method not only pays attention to the\nimportance of locating the overlapping areas of point clouds, but also commits\nto finding more accurate correspondences in overlapping areas. Our extensive\nexperiments demonstrate the effectiveness of our method, achieving\nstate-of-the-art registration recall (95.7\\%/79.3\\%) on the 3DMatch/3DLoMatch\nbenchmark. Moreover, we also test the performance on ModelNet40 and demonstrate\nexcellent performance.",
      "tldr_zh": "该论文针对点云配准中重叠区域模糊结构导致的异常匹配问题，提出了一种先验引导的稀疏混合专家（Prior-guided Sparse Mixture of Experts，PSReg）方法，以提升特征的区分度。具体而言，该方法通过融合先验重叠和潜在对应嵌入来路由，将潜在对应点分配到合适的专家处理，并结合Transformer层构建一个高效的注册框架。实验结果显示，PSReg在3DMatch/3DLoMatch基准上实现了最先进的注册召回率（95.7%/79.3%），并在ModelNet40数据集上表现出色，从而显著提高了点云配准的准确性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025 Oral",
      "pdf_url": "http://arxiv.org/pdf/2501.07762v2",
      "published_date": "2025-01-14 00:30:22 UTC",
      "updated_date": "2025-01-18 01:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:40:32.595971"
    },
    {
      "arxiv_id": "2501.07761v1",
      "title": "Impatient Bandits: Optimizing for the Long-Term Without Delay",
      "title_zh": "翻译失败",
      "authors": [
        "Kelly W. Zhang",
        "Thomas Baldwin-McDonald",
        "Kamil Ciosek",
        "Lucas Maystre",
        "Daniel Russo"
      ],
      "abstract": "Increasingly, recommender systems are tasked with improving users' long-term\nsatisfaction. In this context, we study a content exploration task, which we\nformalize as a bandit problem with delayed rewards. There is an apparent\ntrade-off in choosing the learning signal: waiting for the full reward to\nbecome available might take several weeks, slowing the rate of learning,\nwhereas using short-term proxy rewards reflects the actual long-term goal only\nimperfectly. First, we develop a predictive model of delayed rewards that\nincorporates all information obtained to date. Rewards as well as shorter-term\nsurrogate outcomes are combined through a Bayesian filter to obtain a\nprobabilistic belief. Second, we devise a bandit algorithm that quickly learns\nto identify content aligned with long-term success using this new predictive\nmodel. We prove a regret bound for our algorithm that depends on the\n\\textit{Value of Progressive Feedback}, an information theoretic metric that\ncaptures the quality of short-term leading indicators that are observed prior\nto the long-term reward. We apply our approach to a podcast recommendation\nproblem, where we seek to recommend shows that users engage with repeatedly\nover two months. We empirically validate that our approach significantly\noutperforms methods that optimize for short-term proxies or rely solely on\ndelayed rewards, as demonstrated by an A/B test in a recommendation system that\nserves hundreds of millions of users.",
      "tldr_zh": "该论文研究了推荐系统的长期满意度优化问题，将其形式化为带有延迟奖励的 Bandit 问题，旨在解决等待完整奖励导致学习缓慢与使用短期代理奖励不精确的权衡。作者开发了一个预测延迟奖励的模型，通过 Bayesian filter 结合所有可用信息（如奖励和短期替代结果）形成概率信念，并设计了一个 Bandit 算法，利用该模型快速识别与长期成功对齐的内容。论文证明了算法的 regret bound 依赖于 Value of Progressive Feedback（一种信息理论指标），并通过应用于播客推荐场景的 A/B 测试验证，其性能显著优于仅优化短期代理或依赖延迟奖励的方法，在服务数亿用户的系统中取得了实际改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07761v1",
      "published_date": "2025-01-14 00:28:26 UTC",
      "updated_date": "2025-01-14 00:28:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:40:43.922948"
    },
    {
      "arxiv_id": "2503.15494v1",
      "title": "AI-Powered Assistive Technologies for Visual Impairment",
      "title_zh": "AI驱动的视觉障碍辅助技术",
      "authors": [
        "Prudhvi Naayini",
        "Praveen Kumar Myakala",
        "Chiranjeevi Bura",
        "Anil Kumar Jonnalagadda",
        "Srikanth Kamatala"
      ],
      "abstract": "Artificial Intelligence (AI) is revolutionizing assistive technologies. It\noffers innovative solutions to enhance the quality of life for individuals with\nvisual impairments. This review examines the development, applications, and\nimpact of AI-powered tools in key domains, such as computer vision, natural\nlanguage processing (NLP), and wearable devices. Specific advancements include\nobject recognition for identifying everyday items, scene description for\nunderstanding surroundings, and NLP-driven text-to-speech systems for accessing\ndigital information. Assistive technologies like smart glasses, smartphone\napplications, and AI-enabled navigation aids are discussed, demonstrating their\nability to support independent travel, facilitate social interaction, and\nincrease access to education and employment opportunities.\n  The integration of deep learning models, multimodal interfaces, and real-time\ndata processing has transformed the functionality and usability of these tools,\nfostering inclusivity and empowerment. This article also addresses critical\nchallenges, including ethical considerations, affordability, and adaptability\nin diverse environments. Future directions highlight the need for\ninterdisciplinary collaboration to refine these technologies, ensuring\nequitable access and sustainable innovation. By providing a comprehensive\noverview, this review underscores AI's transformative potential in promoting\nindependence, enhancing accessibility, and fostering social inclusion for\nvisually impaired individuals.",
      "tldr_zh": "这篇综述探讨了人工智能(AI)如何革新视觉障碍辅助技术，包括在计算机视觉、自然语言处理(NLP)和可穿戴设备领域的创新应用，如物体识别、场景描述和文本到语音系统。AI 驱动的工具，例如智能眼镜、智能手机应用和导航辅助，帮助视力受损者提升独立性、社会互动、教育和就业机会，同时通过深度学习模型、多模态接口和实时数据处理实现更高效的功能。文章强调了这些技术的积极影响，如促进包容性和赋权，但也指出了挑战，包括伦理问题、负担能力和环境适应性。未来方向呼吁跨学科合作，以确保公平访问和可持续创新。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.15494v1",
      "published_date": "2025-01-14 00:04:02 UTC",
      "updated_date": "2025-01-14 00:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:40:55.926652"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 120,
  "processed_papers_count": 120,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T23:41:17.276547"
}