[
  {
    "arxiv_id": "2501.08496v2",
    "title": "Quantifying the Importance of Data Alignment in Downstream Model Performance",
    "authors": [
      "Krrish Chawla",
      "Aryan Sahai",
      "Mario DePavia",
      "Sudharsan Sundar",
      "Brando Miranda"
    ],
    "abstract": "Contrary to the conventional emphasis on dataset size, we explore the role of\ndata alignment -- an often overlooked aspect of data quality -- in training\ncapable Large Language Models (LLMs). To do so, we use the Task2Vec-based\nalignment coefficient, a quantitative measure of the similarity between two\ndatasets, to quantify the impact of alignment between training data and\nevaluation data on downstream performance. In particular, we conduct controlled\n\\textit{interventional} experiments for two settings: 1. the impact of\nincreased alignment coefficients between various pre-training (pt) against\nevaluation datasets, and 2. the impact of increased alignment coefficients\nbetween domain specific fine-tuning (ft) against domain specific evaluation.\nThe domain specific task we explore is Autoformalization -- the machine\ntranslation task between natural language and code for formal verification. In\nboth settings, we find a strong, predictable negative correlation between the\nalignment coefficient of a model's training and evaluation data and the model's\nloss/perplexity on the respective downstream task. These findings suggest a\nre-evaluation of LLM training approaches, demonstrating the relevance of data\nalignment compared to data quantity, especially in specialized downstream tasks\nsuch as Autoformalization.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08496v2",
    "published_date": "2025-01-14 23:59:23 UTC",
    "updated_date": "2025-01-21 01:01:37 UTC"
  },
  {
    "arxiv_id": "2501.08471v1",
    "title": "Benchmarking Classical, Deep, and Generative Models for Human Activity Recognition",
    "authors": [
      "Md Meem Hossain",
      "The Anh Han",
      "Safina Showkat Ara",
      "Zia Ush Shamszaman"
    ],
    "abstract": "Human Activity Recognition (HAR) has gained significant importance with the\ngrowing use of sensor-equipped devices and large datasets. This paper evaluates\nthe performance of three categories of models : classical machine learning,\ndeep learning architectures, and Restricted Boltzmann Machines (RBMs) using\nfive key benchmark datasets of HAR (UCI-HAR, OPPORTUNITY, PAMAP2, WISDM, and\nBerkeley MHAD). We assess various models, including Decision Trees, Random\nForests, Convolutional Neural Networks (CNN), and Deep Belief Networks (DBNs),\nusing metrics such as accuracy, precision, recall, and F1-score for a\ncomprehensive comparison. The results show that CNN models offer superior\nperformance across all datasets, especially on the Berkeley MHAD. Classical\nmodels like Random Forest do well on smaller datasets but face challenges with\nlarger, more complex data. RBM-based models also show notable potential,\nparticularly for feature learning. This paper offers a detailed comparison to\nhelp researchers choose the most suitable model for HAR tasks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T05",
      "I.2.1"
    ],
    "primary_category": "cs.CV",
    "comment": "48 pages, 21 Figures",
    "pdf_url": "http://arxiv.org/pdf/2501.08471v1",
    "published_date": "2025-01-14 22:36:11 UTC",
    "updated_date": "2025-01-14 22:36:11 UTC"
  },
  {
    "arxiv_id": "2501.08470v1",
    "title": "Detecting Contextual Anomalies by Discovering Consistent Spatial Regions",
    "authors": [
      "Zhengye Yang",
      "Richard J. Radke"
    ],
    "abstract": "We describe a method for modeling spatial context to enable video anomaly\ndetection. The main idea is to discover regions that share similar object-level\nactivities by clustering joint object attributes using Gaussian mixture models.\nWe demonstrate that this straightforward approach, using orders of magnitude\nfewer parameters than competing models, achieves state-of-the-art performance\nin the challenging spatial-context-dependent Street Scene dataset. As a side\nbenefit, the high-resolution discovered regions learned by the model also\nprovide explainable normalcy maps for human operators without the need for any\npre-trained segmentation model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08470v1",
    "published_date": "2025-01-14 22:33:07 UTC",
    "updated_date": "2025-01-14 22:33:07 UTC"
  },
  {
    "arxiv_id": "2501.08460v1",
    "title": "Towards Zero-Shot & Explainable Video Description by Reasoning over Graphs of Events in Space and Time",
    "authors": [
      "Mihai Masala",
      "Marius Leordeanu"
    ],
    "abstract": "In the current era of Machine Learning, Transformers have become the de facto\napproach across a variety of domains, such as computer vision and natural\nlanguage processing. Transformer-based solutions are the backbone of current\nstate-of-the-art methods for language generation, image and video\nclassification, segmentation, action and object recognition, among many others.\nInterestingly enough, while these state-of-the-art methods produce impressive\nresults in their respective domains, the problem of understanding the\nrelationship between vision and language is still beyond our reach. In this\nwork, we propose a common ground between vision and language based on events in\nspace and time in an explainable and programmatic way, to connect\nlearning-based vision and language state of the art models and provide a\nsolution to the long standing problem of describing videos in natural language.\nWe validate that our algorithmic approach is able to generate coherent, rich\nand relevant textual descriptions on videos collected from a variety of\ndatasets, using both standard metrics (e.g. Bleu, ROUGE) and the modern\nLLM-as-a-Jury approach.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08460v1",
    "published_date": "2025-01-14 22:09:06 UTC",
    "updated_date": "2025-01-14 22:09:06 UTC"
  },
  {
    "arxiv_id": "2501.08450v1",
    "title": "Active Sampling for Node Attribute Completion on Graphs",
    "authors": [
      "Benyuan Liu",
      "Xu Chen",
      "Yanfeng Wang",
      "Ya Zhang",
      "Zhi Cao",
      "Ivor Tsang"
    ],
    "abstract": "Node attribute, a type of crucial information for graph analysis, may be\npartially or completely missing for certain nodes in real world applications.\nRestoring the missing attributes is expected to benefit downstream graph\nlearning. Few attempts have been made on node attribute completion, but a novel\nframework called Structure-attribute Transformer (SAT) was recently proposed by\nusing a decoupled scheme to leverage structures and attributes. SAT ignores the\ndifferences in contributing to the learning schedule and finding a practical\nway to model the different importance of nodes with observed attributes is\nchallenging. This paper proposes a novel AcTive Sampling algorithm (ATS) to\nrestore missing node attributes. The representativeness and uncertainty of each\nnode's information are first measured based on graph structure, representation\nsimilarity and learning bias. To select nodes as train samples in the next\noptimization step, a weighting scheme controlled by Beta distribution is then\nintroduced to linearly combine the two properties. Extensive experiments on\nfour public benchmark datasets and two downstream tasks have shown the\nsuperiority of ATS in node attribute completion.",
    "categories": [
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08450v1",
    "published_date": "2025-01-14 21:38:23 UTC",
    "updated_date": "2025-01-14 21:38:23 UTC"
  },
  {
    "arxiv_id": "2501.09039v1",
    "title": "Playing Devil's Advocate: Unmasking Toxicity and Vulnerabilities in Large Vision-Language Models",
    "authors": [
      "Abdulkadir Erol",
      "Trilok Padhi",
      "Agnik Saha",
      "Ugur Kursuncu",
      "Mehmet Emin Aktas"
    ],
    "abstract": "The rapid advancement of Large Vision-Language Models (LVLMs) has enhanced\ncapabilities offering potential applications from content creation to\nproductivity enhancement. Despite their innovative potential, LVLMs exhibit\nvulnerabilities, especially in generating potentially toxic or unsafe\nresponses. Malicious actors can exploit these vulnerabilities to propagate\ntoxic content in an automated (or semi-) manner, leveraging the susceptibility\nof LVLMs to deception via strategically crafted prompts without fine-tuning or\ncompute-intensive procedures. Despite the red-teaming efforts and inherent\npotential risks associated with the LVLMs, exploring vulnerabilities of LVLMs\nremains nascent and yet to be fully addressed in a systematic manner. This\nstudy systematically examines the vulnerabilities of open-source LVLMs,\nincluding LLaVA, InstructBLIP, Fuyu, and Qwen, using adversarial prompt\nstrategies that simulate real-world social manipulation tactics informed by\nsocial theories. Our findings show that (i) toxicity and insulting are the most\nprevalent behaviors, with the mean rates of 16.13% and 9.75%, respectively;\n(ii) Qwen-VL-Chat, LLaVA-v1.6-Vicuna-7b, and InstructBLIP-Vicuna-7b are the\nmost vulnerable models, exhibiting toxic response rates of 21.50%, 18.30% and\n17.90%, and insulting responses of 13.40%, 11.70% and 10.10%, respectively;\n(iii) prompting strategies incorporating dark humor and multimodal toxic prompt\ncompletion significantly elevated these vulnerabilities. Despite being\nfine-tuned for safety, these models still generate content with varying degrees\nof toxicity when prompted with adversarial inputs, highlighting the urgent need\nfor enhanced safety mechanisms and robust guardrails in LVLM development.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09039v1",
    "published_date": "2025-01-14 21:27:40 UTC",
    "updated_date": "2025-01-14 21:27:40 UTC"
  },
  {
    "arxiv_id": "2501.08440v1",
    "title": "FARE: A Deep Learning-Based Framework for Radar-based Face Recognition and Out-of-distribution Detection",
    "authors": [
      "Sabri Mustafa Kahya",
      "Boran Hamdi Sivrikaya",
      "Muhammet Sami Yavuz",
      "Eckehard Steinbach"
    ],
    "abstract": "In this work, we propose a novel pipeline for face recognition and\nout-of-distribution (OOD) detection using short-range FMCW radar. The proposed\nsystem utilizes Range-Doppler and micro Range-Doppler Images. The architecture\nfeatures a primary path (PP) responsible for the classification of\nin-distribution (ID) faces, complemented by intermediate paths (IPs) dedicated\nto OOD detection. The network is trained in two stages: first, the PP is\ntrained using triplet loss to optimize ID face classification. In the second\nstage, the PP is frozen, and the IPs-comprising simple linear autoencoder\nnetworks-are trained specifically for OOD detection. Using our dataset\ngenerated with a 60 GHz FMCW radar, our method achieves an ID classification\naccuracy of 99.30% and an OOD detection AUROC of 96.91%.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.08440v1",
    "published_date": "2025-01-14 21:08:08 UTC",
    "updated_date": "2025-01-14 21:08:08 UTC"
  },
  {
    "arxiv_id": "2501.09038v3",
    "title": "Do generative video models understand physical principles?",
    "authors": [
      "Saman Motamed",
      "Laura Culp",
      "Kevin Swersky",
      "Priyank Jaini",
      "Robert Geirhos"
    ],
    "abstract": "AI video generation is undergoing a revolution, with quality and realism\nadvancing rapidly. These advances have led to a passionate scientific debate:\nDo video models learn \"world models\" that discover laws of physics -- or,\nalternatively, are they merely sophisticated pixel predictors that achieve\nvisual realism without understanding the physical principles of reality? We\naddress this question by developing Physics-IQ, a comprehensive benchmark\ndataset that can only be solved by acquiring a deep understanding of various\nphysical principles, like fluid dynamics, optics, solid mechanics, magnetism\nand thermodynamics. We find that across a range of current models (Sora,\nRunway, Pika, Lumiere, Stable Video Diffusion, and VideoPoet), physical\nunderstanding is severely limited, and unrelated to visual realism. At the same\ntime, some test cases can already be successfully solved. This indicates that\nacquiring certain physical principles from observation alone may be possible,\nbut significant challenges remain. While we expect rapid advances ahead, our\nwork demonstrates that visual realism does not imply physical understanding.\nOur project page is at https://physics-iq.github.io; code at\nhttps://github.com/google-deepmind/physics-IQ-benchmark.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.09038v3",
    "published_date": "2025-01-14 20:59:37 UTC",
    "updated_date": "2025-02-27 15:10:51 UTC"
  },
  {
    "arxiv_id": "2501.09765v1",
    "title": "Enhancing the De-identification of Personally Identifiable Information in Educational Data",
    "authors": [
      "Y. Shen",
      "Z. Ji",
      "J. Lin",
      "K. R. Koedginer"
    ],
    "abstract": "Protecting Personally Identifiable Information (PII), such as names, is a\ncritical requirement in learning technologies to safeguard student and teacher\nprivacy and maintain trust. Accurate PII detection is an essential step toward\nanonymizing sensitive information while preserving the utility of educational\ndata. Motivated by recent advancements in artificial intelligence, our study\ninvestigates the GPT-4o-mini model as a cost-effective and efficient solution\nfor PII detection tasks. We explore both prompting and fine-tuning approaches\nand compare GPT-4o-mini's performance against established frameworks, including\nMicrosoft Presidio and Azure AI Language. Our evaluation on two public\ndatasets, CRAPII and TSCC, demonstrates that the fine-tuned GPT-4o-mini model\nachieves superior performance, with a recall of 0.9589 on CRAPII. Additionally,\nfine-tuned GPT-4o-mini significantly improves precision scores (a threefold\nincrease) while reducing computational costs to nearly one-tenth of those\nassociated with Azure AI Language. Furthermore, our bias analysis reveals that\nthe fine-tuned GPT-4o-mini model consistently delivers accurate results across\ndiverse cultural backgrounds and genders. The generalizability analysis using\nthe TSCC dataset further highlights its robustness, achieving a recall of\n0.9895 with minimal additional training data from TSCC. These results emphasize\nthe potential of fine-tuned GPT-4o-mini as an accurate and cost-effective tool\nfor PII detection in educational data. It offers robust privacy protection\nwhile preserving the data's utility for research and pedagogical analysis. Our\ncode is available on GitHub: https://github.com/AnonJD/PrivacyAI",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "14 pages, 1 figure; This work has been submitted to the IEEE for\n  possible publication",
    "pdf_url": "http://arxiv.org/pdf/2501.09765v1",
    "published_date": "2025-01-14 20:53:38 UTC",
    "updated_date": "2025-01-14 20:53:38 UTC"
  },
  {
    "arxiv_id": "2501.08429v1",
    "title": "Modeling Discrimination with Causal Abstraction",
    "authors": [
      "Milan Mossé",
      "Kara Schechtman",
      "Frederick Eberhardt",
      "Thomas Icard"
    ],
    "abstract": "A person is directly racially discriminated against only if her race caused\nher worse treatment. This implies that race is an attribute sufficiently\nseparable from other attributes to isolate its causal role. But race is\nembedded in a nexus of social factors that resist isolated treatment. If race\nis socially constructed, in what sense can it cause worse treatment? Some\npropose that the perception of race, rather than race itself, causes worse\ntreatment. Others suggest that since causal models require modularity, i.e. the\nability to isolate causal effects, attempts to causally model discrimination\nare misguided.\n  This paper addresses the problem differently. We introduce a framework for\nreasoning about discrimination, in which race is a high-level abstraction of\nlower-level features. In this framework, race can be modeled as itself causing\nworse treatment. Modularity is ensured by allowing assumptions about social\nconstruction to be precisely and explicitly stated, via an alignment between\nrace and its constituents. Such assumptions can then be subjected to normative\nand empirical challenges, which lead to different views of when discrimination\noccurs. By distinguishing constitutive and causal relations, the abstraction\nframework pinpoints disagreements in the current literature on modeling\ndiscrimination, while preserving a precise causal account of discrimination.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08429v1",
    "published_date": "2025-01-14 20:42:57 UTC",
    "updated_date": "2025-01-14 20:42:57 UTC"
  },
  {
    "arxiv_id": "2501.08426v1",
    "title": "Causal vs. Anticausal merging of predictors",
    "authors": [
      "Sergio Hernan Garrido Mejia",
      "Patrick Blöbaum",
      "Bernhard Schölkopf",
      "Dominik Janzing"
    ],
    "abstract": "We study the differences arising from merging predictors in the causal and\nanticausal directions using the same data. In particular we study the\nasymmetries that arise in a simple model where we merge the predictors using\none binary variable as target and two continuous variables as predictors. We\nuse Causal Maximum Entropy (CMAXENT) as inductive bias to merge the predictors,\nhowever, we expect similar differences to hold also when we use other merging\nmethods that take into account asymmetries between cause and effect. We show\nthat if we observe all bivariate distributions, the CMAXENT solution reduces to\na logistic regression in the causal direction and Linear Discriminant Analysis\n(LDA) in the anticausal direction. Furthermore, we study how the decision\nboundaries of these two solutions differ whenever we observe only some of the\nbivariate distributions implications for Out-Of-Variable (OOV) generalisation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Presented at the 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2501.08426v1",
    "published_date": "2025-01-14 20:38:15 UTC",
    "updated_date": "2025-01-14 20:38:15 UTC"
  },
  {
    "arxiv_id": "2501.08421v1",
    "title": "SEAL: Speaker Error Correction using Acoustic-conditioned Large Language Models",
    "authors": [
      "Anurag Kumar",
      "Rohit Paturi",
      "Amber Afshan",
      "Sundararajan Srinivasan"
    ],
    "abstract": "Speaker Diarization (SD) is a crucial component of modern end-to-end ASR\npipelines. Traditional SD systems, which are typically audio-based and operate\nindependently of ASR, often introduce speaker errors, particularly during\nspeaker transitions and overlapping speech. Recently, language models including\nfine-tuned large language models (LLMs) have shown to be effective as a\nsecond-pass speaker error corrector by leveraging lexical context in the\ntranscribed output. In this work, we introduce a novel acoustic conditioning\napproach to provide more fine-grained information from the acoustic diarizer to\nthe LLM. We also show that a simpler constrained decoding strategy reduces LLM\nhallucinations, while avoiding complicated post-processing. Our approach\nsignificantly reduces the speaker error rates by 24-43% across Fisher,\nCallhome, and RT03-CTS datasets, compared to the first-pass Acoustic SD.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.08421v1",
    "published_date": "2025-01-14 20:24:12 UTC",
    "updated_date": "2025-01-14 20:24:12 UTC"
  },
  {
    "arxiv_id": "2501.08418v2",
    "title": "CVaR-Based Variational Quantum Optimization for User Association in Handoff-Aware Vehicular Networks",
    "authors": [
      "Zijiang Yan",
      "Hao Zhou",
      "Jianhua Pei",
      "Aryan Kaushik",
      "Hina Tabassum",
      "Ping Wang"
    ],
    "abstract": "Efficient resource allocation is essential for optimizing various tasks in\nwireless networks, which are usually formulated as generalized assignment\nproblems (GAP). GAP, as a generalized version of the linear sum assignment\nproblem, involves both equality and inequality constraints that add\ncomputational challenges. In this work, we present a novel Conditional Value at\nRisk (CVaR)-based Variational Quantum Eigensolver (VQE) framework to address\nGAP in vehicular networks (VNets). Our approach leverages a hybrid\nquantum-classical structure, integrating a tailored cost function that balances\nboth objective and constraint-specific penalties to improve solution quality\nand stability. Using the CVaR-VQE model, we handle the GAP efficiently by\nfocusing optimization on the lower tail of the solution space, enhancing both\nconvergence and resilience on noisy intermediate-scale quantum (NISQ) devices.\nWe apply this framework to a user-association problem in VNets, where our\nmethod achieves 23.5% improvement compared to the deep neural network (DNN)\napproach.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in IEEE International Conference on Communications (ICC\n  2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.08418v2",
    "published_date": "2025-01-14 20:21:06 UTC",
    "updated_date": "2025-02-04 19:51:53 UTC"
  },
  {
    "arxiv_id": "2501.08415v1",
    "title": "Cross-Modal Transferable Image-to-Video Attack on Video Quality Metrics",
    "authors": [
      "Georgii Gotin",
      "Ekaterina Shumitskaya",
      "Anastasia Antsiferova",
      "Dmitriy Vatolin"
    ],
    "abstract": "Recent studies have revealed that modern image and video quality assessment\n(IQA/VQA) metrics are vulnerable to adversarial attacks. An attacker can\nmanipulate a video through preprocessing to artificially increase its quality\nscore according to a certain metric, despite no actual improvement in visual\nquality. Most of the attacks studied in the literature are white-box attacks,\nwhile black-box attacks in the context of VQA have received less attention.\nMoreover, some research indicates a lack of transferability of adversarial\nexamples generated for one model to another when applied to VQA. In this paper,\nwe propose a cross-modal attack method, IC2VQA, aimed at exploring the\nvulnerabilities of modern VQA models. This approach is motivated by the\nobservation that the low-level feature spaces of images and videos are similar.\nWe investigate the transferability of adversarial perturbations across\ndifferent modalities; specifically, we analyze how adversarial perturbations\ngenerated on a white-box IQA model with an additional CLIP module can\neffectively target a VQA model. The addition of the CLIP module serves as a\nvaluable aid in increasing transferability, as the CLIP model is known for its\neffective capture of low-level semantics. Extensive experiments demonstrate\nthat IC2VQA achieves a high success rate in attacking three black-box VQA\nmodels. We compare our method with existing black-box attack strategies,\nhighlighting its superiority in terms of attack success within the same number\nof iterations and levels of attack strength. We believe that the proposed\nmethod will contribute to the deeper analysis of robust VQA metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted for VISAPP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.08415v1",
    "published_date": "2025-01-14 20:12:09 UTC",
    "updated_date": "2025-01-14 20:12:09 UTC"
  },
  {
    "arxiv_id": "2501.08411v2",
    "title": "BiDepth Multimodal Neural Network: Bidirectional Depth Deep Learning Architecture for Spatial-Temporal Prediction",
    "authors": [
      "Sina Ehsani",
      "Fenglian Pan",
      "Qingpei Hu",
      "Jian Liu"
    ],
    "abstract": "Accurate prediction of spatial-temporal (ST) information in dynamic systems,\nsuch as urban mobility and weather patterns, is a crucial yet challenging\nproblem. The complexity stems from the intricate interplay between spatial\nproximity and temporal relevance, where both long-term trends and short-term\nfluctuations are present in convoluted patterns. Existing approaches, including\ntraditional statistical methods and conventional neural networks, may provide\ninaccurate results due to the lack of an effective mechanism that\nsimultaneously incorporates information at variable temporal depths while\nmaintaining spatial context, resulting in a trade-off between comprehensive\nlong-term historical analysis and responsiveness to short-term new information.\nTo bridge this gap, this paper proposes the BiDepth Multimodal Neural Network\n(BDMNN) with bidirectional depth modulation that enables a comprehensive\nunderstanding of both long-term seasonality and short-term fluctuations,\nadapting to the complex ST context. Case studies with real-world public data\ndemonstrate significant improvements in prediction accuracy, with a 12%\nreduction in Mean Squared Error for urban traffic prediction and a 15%\nimprovement in rain precipitation forecasting compared to state-of-the-art\nbenchmarks, without demanding extra computational resources.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been submitted to Applied Intelligence for review",
    "pdf_url": "http://arxiv.org/pdf/2501.08411v2",
    "published_date": "2025-01-14 19:59:59 UTC",
    "updated_date": "2025-02-06 04:35:56 UTC"
  },
  {
    "arxiv_id": "2501.08402v2",
    "title": "Addressing Quality Challenges in Deep Learning: The Role of MLOps and Domain Knowledge",
    "authors": [
      "Santiago del Rey",
      "Adrià Medina",
      "Xavier Franch",
      "Silverio Martínez-Fernández"
    ],
    "abstract": "Deep learning (DL) systems present unique challenges in software engineering,\nespecially concerning quality attributes like correctness and resource\nefficiency. While DL models excel in specific tasks, engineering DL systems is\nstill essential. The effort, cost, and potential diminishing returns of\ncontinual improvements must be carefully evaluated, as software engineers often\nface the critical decision of when to stop refining a system relative to its\nquality attributes. This experience paper explores the role of MLOps practices\n-- such as monitoring and experiment tracking -- in creating transparent and\nreproducible experimentation environments that enable teams to assess and\njustify the impact of design decisions on quality attributes. Furthermore, we\nreport on experiences addressing the quality challenges by embedding domain\nknowledge into the design of a DL model and its integration within a larger\nsystem. The findings offer actionable insights into the benefits of domain\nknowledge and MLOps and the strategic consideration of when to limit further\noptimizations in DL projects to maximize overall system quality and\nreliability.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "6 pages, 1 figure, accepted to the 4th International Conference on AI\n  Engineering - Software Engineering for AI (CAIN)",
    "pdf_url": "http://arxiv.org/pdf/2501.08402v2",
    "published_date": "2025-01-14 19:37:08 UTC",
    "updated_date": "2025-01-31 16:47:16 UTC"
  },
  {
    "arxiv_id": "2501.10453v1",
    "title": "Uncovering Bias in Foundation Models: Impact, Testing, Harm, and Mitigation",
    "authors": [
      "Shuzhou Sun",
      "Li Liu",
      "Yongxiang Liu",
      "Zhen Liu",
      "Shuanghui Zhang",
      "Janne Heikkilä",
      "Xiang Li"
    ],
    "abstract": "Bias in Foundation Models (FMs) - trained on vast datasets spanning societal\nand historical knowledge - poses significant challenges for fairness and equity\nacross fields such as healthcare, education, and finance. These biases, rooted\nin the overrepresentation of stereotypes and societal inequalities in training\ndata, exacerbate real-world discrimination, reinforce harmful stereotypes, and\nerode trust in AI systems. To address this, we introduce Trident Probe Testing\n(TriProTesting), a systematic testing method that detects explicit and implicit\nbiases using semantically designed probes. Here we show that FMs, including\nCLIP, ALIGN, BridgeTower, and OWLv2, demonstrate pervasive biases across single\nand mixed social attributes (gender, race, age, and occupation). Notably, we\nuncover mixed biases when social attributes are combined, such as gender x\nrace, gender x age, and gender x occupation, revealing deeper layers of\ndiscrimination. We further propose Adaptive Logit Adjustment\n(AdaLogAdjustment), a post-processing technique that dynamically redistributes\nprobability power to mitigate these biases effectively, achieving significant\nimprovements in fairness without retraining models. These findings highlight\nthe urgent need for ethical AI practices and interdisciplinary solutions to\naddress biases not only at the model level but also in societal structures. Our\nwork provides a scalable and interpretable solution that advances fairness in\nAI systems while offering practical insights for future research on fair AI\ntechnologies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "60 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.10453v1",
    "published_date": "2025-01-14 19:06:37 UTC",
    "updated_date": "2025-01-14 19:06:37 UTC"
  },
  {
    "arxiv_id": "2501.08328v2",
    "title": "PokerBench: Training Large Language Models to become Professional Poker Players",
    "authors": [
      "Richard Zhuang",
      "Akshat Gupta",
      "Richard Yang",
      "Aniket Rahane",
      "Zhengyu Li",
      "Gopala Anumanchipalli"
    ],
    "abstract": "We introduce PokerBench - a benchmark for evaluating the poker-playing\nabilities of large language models (LLMs). As LLMs excel in traditional NLP\ntasks, their application to complex, strategic games like poker poses a new\nchallenge. Poker, an incomplete information game, demands a multitude of skills\nsuch as mathematics, reasoning, planning, strategy, and a deep understanding of\ngame theory and human psychology. This makes Poker the ideal next frontier for\nlarge language models. PokerBench consists of a comprehensive compilation of\n11,000 most important scenarios, split between pre-flop and post-flop play,\ndeveloped in collaboration with trained poker players. We evaluate prominent\nmodels including GPT-4, ChatGPT 3.5, and various Llama and Gemma series models,\nfinding that all state-of-the-art LLMs underperform in playing optimal poker.\nHowever, after fine-tuning, these models show marked improvements. We validate\nPokerBench by having models with different scores compete with each other,\ndemonstrating that higher scores on PokerBench lead to higher win rates in\nactual poker games. Through gameplay between our fine-tuned model and GPT-4, we\nalso identify limitations of simple supervised fine-tuning for learning optimal\nplaying strategy, suggesting the need for more advanced methodologies for\neffectively training language models to excel in games. PokerBench thus\npresents a unique benchmark for a quick and reliable evaluation of the\npoker-playing ability of LLMs as well as a comprehensive benchmark to study the\nprogress of LLMs in complex game-playing scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.CL",
    "comment": "AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.08328v2",
    "published_date": "2025-01-14 18:59:03 UTC",
    "updated_date": "2025-01-24 20:15:10 UTC"
  },
  {
    "arxiv_id": "2501.08324v2",
    "title": "ADAM: An AI Reasoning and Bioinformatics Model for Alzheimer's Disease Detection and Microbiome-Clinical Data Integration",
    "authors": [
      "Ziyuan Huang",
      "Vishaldeep Kaur Sekhon",
      "Roozbeh Sadeghian",
      "Maria L. Vaida",
      "Cynthia Jo",
      "Doyle Ward",
      "Vanni Bucci",
      "John P. Haran"
    ],
    "abstract": "Alzheimer's Disease Analysis Model (ADAM) is a multi-agent reasoning large\nlanguage model (LLM) framework designed to integrate and analyze multimodal\ndata, including microbiome profiles, clinical datasets, and external knowledge\nbases, to enhance the understanding and classification of Alzheimer's disease\n(AD). By leveraging the agentic system with LLM, ADAM produces insights from\ndiverse data sources and contextualizes the findings with literature-driven\nevidence. A comparative evaluation with XGBoost revealed a significantly\nimproved mean F1 score and significantly reduced variance for ADAM,\nhighlighting its robustness and consistency, particularly when utilizing human\nbiological data. Although currently tailored for binary classification tasks\nwith two data modalities, future iterations will aim to incorporate additional\ndata types, such as neuroimaging and peripheral biomarkers, and expand them to\npredict disease progression, thereby broadening ADAM's scalability and\napplicability in AD research and diagnostic applications.",
    "categories": [
      "cs.AI",
      "68T07"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.08324v2",
    "published_date": "2025-01-14 18:56:33 UTC",
    "updated_date": "2025-05-02 03:07:14 UTC"
  },
  {
    "arxiv_id": "2501.08316v1",
    "title": "Diffusion Adversarial Post-Training for One-Step Video Generation",
    "authors": [
      "Shanchuan Lin",
      "Xin Xia",
      "Yuxi Ren",
      "Ceyuan Yang",
      "Xuefeng Xiao",
      "Lu Jiang"
    ],
    "abstract": "The diffusion models are widely used for image and video generation, but\ntheir iterative generation process is slow and expansive. While existing\ndistillation approaches have demonstrated the potential for one-step generation\nin the image domain, they still suffer from significant quality degradation. In\nthis work, we propose Adversarial Post-Training (APT) against real data\nfollowing diffusion pre-training for one-step video generation. To improve the\ntraining stability and quality, we introduce several improvements to the model\narchitecture and training procedures, along with an approximated R1\nregularization objective. Empirically, our experiments show that our\nadversarial post-trained model, Seaweed-APT, can generate 2-second, 1280x720,\n24fps videos in real time using a single forward evaluation step. Additionally,\nour model is capable of generating 1024px images in a single step, achieving\nquality comparable to state-of-the-art methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08316v1",
    "published_date": "2025-01-14 18:51:48 UTC",
    "updated_date": "2025-01-14 18:51:48 UTC"
  },
  {
    "arxiv_id": "2501.08297v1",
    "title": "Polynomial Threshold Functions of Bounded Tree-Width: Some Explainability and Complexity Aspects",
    "authors": [
      "Karine Chubarian",
      "Johnny Joyce",
      "Gyorgy Turan"
    ],
    "abstract": "The tree-width of a multivariate polynomial is the tree-width of the\nhypergraph with hyperedges corresponding to its terms. Multivariate polynomials\nof bounded tree-width have been studied by Makowsky and Meer as a new sparsity\ncondition that allows for polynomial solvability of problems which are\nintractable in general. We consider a variation on this theme for Boolean\nvariables. A representation of a Boolean function as the sign of a polynomial\nis called a polynomial threshold representation. We discuss Boolean functions\nrepresentable as polynomial threshold functions of bounded tree-width and\npresent two applications to Bayesian network classifiers, a probabilistic\ngraphical model. Both applications are in Explainable Artificial Intelligence\n(XAI), the research area dealing with the black-box nature of many recent\nmachine learning models. We also give a separation result between the\nrepresentational power of positive and general polynomial threshold functions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 3 figures. To be published in Festschrift in honor of\n  Johann A. Makowsky",
    "pdf_url": "http://arxiv.org/pdf/2501.08297v1",
    "published_date": "2025-01-14 18:28:08 UTC",
    "updated_date": "2025-01-14 18:28:08 UTC"
  },
  {
    "arxiv_id": "2501.08292v1",
    "title": "HALoGEN: Fantastic LLM Hallucinations and Where to Find Them",
    "authors": [
      "Abhilasha Ravichander",
      "Shrusti Ghela",
      "David Wadden",
      "Yejin Choi"
    ],
    "abstract": "Despite their impressive ability to generate high-quality and fluent text,\ngenerative large language models (LLMs) also produce hallucinations: statements\nthat are misaligned with established world knowledge or provided input context.\nHowever, measuring hallucination can be challenging, as having humans verify\nmodel generations on-the-fly is both expensive and time-consuming. In this\nwork, we release HALoGEN, a comprehensive hallucination benchmark consisting\nof: (1) 10,923 prompts for generative models spanning nine domains including\nprogramming, scientific attribution, and summarization, and (2) automatic\nhigh-precision verifiers for each use case that decompose LLM generations into\natomic units, and verify each unit against a high-quality knowledge source. We\nuse this framework to evaluate ~150,000 generations from 14 language models,\nfinding that even the best-performing models are riddled with hallucinations\n(sometimes up to 86% of generated atomic facts depending on the domain). We\nfurther define a novel error classification for LLM hallucinations based on\nwhether they likely stem from incorrect recollection of training data (Type A\nerrors), or incorrect knowledge in training data (Type B errors), or are\nfabrication (Type C errors). We hope our framework provides a foundation to\nenable the principled study of why generative models hallucinate, and advances\nthe development of trustworthy large language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2501.08292v1",
    "published_date": "2025-01-14 18:13:08 UTC",
    "updated_date": "2025-01-14 18:13:08 UTC"
  },
  {
    "arxiv_id": "2501.08271v1",
    "title": "Comparative Analysis of Efficient Adapter-Based Fine-Tuning of State-of-the-Art Transformer Models",
    "authors": [
      "Saad Mashkoor Siddiqui",
      "Mohammad Ali Sheikh",
      "Muhammad Aleem",
      "Kajol R Singh"
    ],
    "abstract": "In this work, we investigate the efficacy of various adapter architectures on\nsupervised binary classification tasks from the SuperGLUE benchmark as well as\na supervised multi-class news category classification task from Kaggle.\nSpecifically, we compare classification performance and time complexity of\nthree transformer models, namely DistilBERT, ELECTRA, and BART, using\nconventional fine-tuning as well as nine state-of-the-art (SoTA) adapter\narchitectures. Our analysis reveals performance differences across adapter\narchitectures, highlighting their ability to achieve comparable or better\nperformance relative to fine-tuning at a fraction of the training time. Similar\nresults are observed on the new classification task, further supporting our\nfindings and demonstrating adapters as efficient and flexible alternatives to\nfine-tuning. This study provides valuable insights and guidelines for selecting\nand implementing adapters in diverse natural language processing (NLP)\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08271v1",
    "published_date": "2025-01-14 17:37:40 UTC",
    "updated_date": "2025-01-14 17:37:40 UTC"
  },
  {
    "arxiv_id": "2501.08266v1",
    "title": "AI Driven Water Segmentation with deep learning models for Enhanced Flood Monitoring",
    "authors": [
      "Sanjida Afrin Mou",
      "Tasfia Noor Chowdhury",
      "Adib Ibn Mannan",
      "Sadia Nourin Mim",
      "Lubana Tarannum",
      "Tasrin Noman",
      "Jamal Uddin Ahamed"
    ],
    "abstract": "Flooding is a major natural hazard causing significant fatalities and\neconomic losses annually, with increasing frequency due to climate change.\nRapid and accurate flood detection and monitoring are crucial for mitigating\nthese impacts. This study compares the performance of three deep learning\nmodels UNet, ResNet, and DeepLabv3 for pixelwise water segmentation to aid in\nflood detection, utilizing images from drones, in field observations, and\nsocial media. This study involves creating a new dataset that augments\nwellknown benchmark datasets with flood-specific images, enhancing the\nrobustness of the models. The UNet, ResNet, and DeepLab v3 architectures are\ntested to determine their effectiveness in various environmental conditions and\ngeographical locations, and the strengths and limitations of each model are\nalso discussed here, providing insights into their applicability in different\nscenarios by predicting image segmentation masks. This fully automated approach\nallows these models to isolate flooded areas in images, significantly reducing\nprocessing time compared to traditional semi-automated methods. The outcome of\nthis study is to predict segmented masks for each image effected by a flood\ndisaster and the validation accuracy of these models. This methodology\nfacilitates timely and continuous flood monitoring, providing vital data for\nemergency response teams to reduce loss of life and economic damages. It offers\na significant reduction in the time required to generate flood maps, cutting\ndown the manual processing time. Additionally, we present avenues for future\nresearch, including the integration of multimodal data sources and the\ndevelopment of robust deep learning architectures tailored specifically for\nflood detection tasks. Overall, our work contributes to the advancement of\nflood management strategies through innovative use of deep learning\ntechnologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.08266v1",
    "published_date": "2025-01-14 17:26:02 UTC",
    "updated_date": "2025-01-14 17:26:02 UTC"
  },
  {
    "arxiv_id": "2501.08365v1",
    "title": "Towards Best Practices for Open Datasets for LLM Training",
    "authors": [
      "Stefan Baack",
      "Stella Biderman",
      "Kasia Odrozek",
      "Aviya Skowron",
      "Ayah Bdeir",
      "Jillian Bommarito",
      "Jennifer Ding",
      "Maximilian Gahntz",
      "Paul Keller",
      "Pierre-Carl Langlais",
      "Greg Lindahl",
      "Sebastian Majstorovic",
      "Nik Marda",
      "Guilherme Penedo",
      "Maarten Van Segbroeck",
      "Jennifer Wang",
      "Leandro von Werra",
      "Mitchell Baker",
      "Julie Belião",
      "Kasia Chmielinski",
      "Marzieh Fadaee",
      "Lisa Gutermuth",
      "Hynek Kydlíček",
      "Greg Leppert",
      "EM Lewis-Jong",
      "Solana Larsen",
      "Shayne Longpre",
      "Angela Oduor Lungati",
      "Cullen Miller",
      "Victor Miller",
      "Max Ryabinin",
      "Kathleen Siminyu",
      "Andrew Strait",
      "Mark Surman",
      "Anna Tumadóttir",
      "Maurice Weber",
      "Rebecca Weiss",
      "Lee White",
      "Thomas Wolf"
    ],
    "abstract": "Many AI companies are training their large language models (LLMs) on data\nwithout the permission of the copyright owners. The permissibility of doing so\nvaries by jurisdiction: in countries like the EU and Japan, this is allowed\nunder certain restrictions, while in the United States, the legal landscape is\nmore ambiguous. Regardless of the legal status, concerns from creative\nproducers have led to several high-profile copyright lawsuits, and the threat\nof litigation is commonly cited as a reason for the recent trend towards\nminimizing the information shared about training datasets by both corporate and\npublic interest actors. This trend in limiting data information causes harm by\nhindering transparency, accountability, and innovation in the broader ecosystem\nby denying researchers, auditors, and impacted individuals access to the\ninformation needed to understand AI models.\n  While this could be mitigated by training language models on open access and\npublic domain data, at the time of writing, there are no such models (trained\nat a meaningful scale) due to the substantial technical and sociological\nchallenges in assembling the necessary corpus. These challenges include\nincomplete and unreliable metadata, the cost and complexity of digitizing\nphysical records, and the diverse set of legal and technical skills required to\nensure relevance and responsibility in a quickly changing landscape. Building\ntowards a future where AI systems can be trained on openly licensed data that\nis responsibly curated and governed requires collaboration across legal,\ntechnical, and policy domains, along with investments in metadata standards,\ndigitization, and fostering a culture of openness.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08365v1",
    "published_date": "2025-01-14 17:18:05 UTC",
    "updated_date": "2025-01-14 17:18:05 UTC"
  },
  {
    "arxiv_id": "2503.15495v1",
    "title": "Entwicklung einer Webanwendung zur Generierung von skolemisierten RDF Daten für die Verwaltung von Lieferketten",
    "authors": [
      "Roman Laas"
    ],
    "abstract": "F\\\"ur eine fr\\\"uhzeitige Erkennung von Lieferengp\\\"assen m\\\"ussen\nLieferketten in einer geeigneten digitalen Form vorliegen, damit sie\nverarbeitet werden k\\\"onnen. Der f\\\"ur die Datenmodellierung ben\\\"otigte\nArbeitsaufwand ist jedoch, gerade IT-fremden Personen, nicht zuzumuten. Es\nwurde deshalb im Rahmen dieser Arbeit eine Webanwendung entwickelt, welche die\nzugrunde liegende Komplexit\\\"at f\\\"ur den Benutzer verschleiern soll. Konkret\nhandelt es sich dabei um eine grafische Benutzeroberfl\\\"ache, auf welcher\nTemplates instanziiert und miteinander verkn\\\"upft werden k\\\"onnen. F\\\"ur die\nDefinition dieser Templates wurden in dieser Arbeit geeignete Konzepte\nerarbeitet und erweitert. Zur Erhebung der Benutzerfreundlichkeit der\nWebanwendung wurde abschlie{\\ss}end eine Nutzerstudie mit mehreren Testpersonen\ndurchgef\\\"uhrt. Diese legte eine Vielzahl von n\\\"utzlichen\nVerbesserungsvorschl\\\"agen offen.\n  --\n  For early detection of supply bottlenecks, supply chains must be available in\na suitable digital form so that they can be processed. However, the amount of\nwork required for data modeling cannot be expected of people who are not\nfamiliar with IT topics. Therefore, a web application was developed in the\ncontext of this thesis, which is supposed to disguise the underlying complexity\nfor the user. Specifically, this is a graphical user interface on which\ntemplates can be instantiated and linked to each other. Suitable concepts for\nthe definition of these templates were developed and extended in this thesis.\nFinally, a user study with several test persons was conducted to determine the\nusability of the web application. This revealed a large number of useful\nsuggestions for improvement.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Master's thesis",
    "pdf_url": "http://arxiv.org/pdf/2503.15495v1",
    "published_date": "2025-01-14 16:38:36 UTC",
    "updated_date": "2025-01-14 16:38:36 UTC"
  },
  {
    "arxiv_id": "2501.08248v2",
    "title": "Eliciting In-context Retrieval and Reasoning for Long-context Large Language Models",
    "authors": [
      "Yifu Qiu",
      "Varun Embar",
      "Yizhe Zhang",
      "Navdeep Jaitly",
      "Shay B. Cohen",
      "Benjamin Han"
    ],
    "abstract": "Recent advancements in long-context language models (LCLMs) promise to\ntransform Retrieval-Augmented Generation (RAG) by simplifying pipelines. With\ntheir expanded context windows, LCLMs can process entire knowledge bases and\nperform retrieval and reasoning directly -- a capability we define as\nIn-Context Retrieval and Reasoning (ICR^2). However, existing benchmarks like\nLOFT often overestimate LCLM performance by providing overly simplified\ncontexts. To address this, we introduce ICR^2, a benchmark that evaluates LCLMs\nin more realistic scenarios by including confounding passages retrieved with\nstrong retrievers. We then propose three methods to enhance LCLM performance:\n(1) retrieve-then-generate fine-tuning, (2) retrieval-attention-probing, which\nuses attention heads to filter and de-noise long contexts during decoding, and\n(3) joint retrieval head training alongside the generation head. Our evaluation\nof five well-known LCLMs on LOFT and ICR^2 demonstrates significant gains with\nour best approach applied to Mistral-7B: +17 and +15 points by Exact Match on\nLOFT, and +13 and +2 points on ICR^2, compared to vanilla RAG and supervised\nfine-tuning, respectively. It even outperforms GPT-4-Turbo on most tasks\ndespite being a much smaller model.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08248v2",
    "published_date": "2025-01-14 16:38:33 UTC",
    "updated_date": "2025-02-28 11:40:20 UTC"
  },
  {
    "arxiv_id": "2501.08243v1",
    "title": "Engineering LLM Powered Multi-agent Framework for Autonomous CloudOps",
    "authors": [
      "Kannan Parthasarathy",
      "Karthik Vaidhyanathan",
      "Rudra Dhar",
      "Venkat Krishnamachari",
      "Basil Muhammed",
      "Adyansh Kakran",
      "Sreemaee Akshathala",
      "Shrikara Arun",
      "Sumant Dubey",
      "Mohan Veerubhotla",
      "Amey Karan"
    ],
    "abstract": "Cloud Operations (CloudOps) is a rapidly growing field focused on the\nautomated management and optimization of cloud infrastructure which is\nessential for organizations navigating increasingly complex cloud environments.\nMontyCloud Inc. is one of the major companies in the CloudOps domain that\nleverages autonomous bots to manage cloud compliance, security, and continuous\noperations. To make the platform more accessible and effective to the\ncustomers, we leveraged the use of GenAI.\n  Developing a GenAI-based solution for autonomous CloudOps for the existing\nMontyCloud system presented us with various challenges such as i) diverse data\nsources; ii) orchestration of multiple processes; and iii) handling complex\nworkflows to automate routine tasks. To this end, we developed MOYA, a\nmulti-agent framework that leverages GenAI and balances autonomy with the\nnecessary human control. This framework integrates various internal and\nexternal systems and is optimized for factors like task orchestration,\nsecurity, and error mitigation while producing accurate, reliable, and relevant\ninsights by utilizing Retrieval Augmented Generation (RAG). Evaluations of our\nmulti-agent system with the help of practitioners as well as using automated\nchecks demonstrate enhanced accuracy, responsiveness, and effectiveness over\nnon-agentic approaches across complex workflows.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "The paper has been accepted as full paper to CAIN 2025\n  (https://conf.researchr.org/home/cain-2025), co-located with ICSE 2025\n  (https://conf.researchr.org/home/icse-2025). The paper was submitted to CAIN\n  for review on 9 November 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.08243v1",
    "published_date": "2025-01-14 16:30:10 UTC",
    "updated_date": "2025-01-14 16:30:10 UTC"
  },
  {
    "arxiv_id": "2501.08241v1",
    "title": "A Feature-Level Ensemble Model for COVID-19 Identification in CXR Images using Choquet Integral and Differential Evolution Optimization",
    "authors": [
      "Amir Reza Takhsha",
      "Maryam Rastgarpour",
      "Mozhgan Naderi"
    ],
    "abstract": "The COVID-19 pandemic has profoundly impacted billions globally. It\nchallenges public health and healthcare systems due to its rapid spread and\nsevere respiratory effects. An effective strategy to mitigate the COVID-19\npandemic involves integrating testing to identify infected individuals. While\nRT-PCR is considered the gold standard for diagnosing COVID-19, it has some\nlimitations such as the risk of false negatives. To address this problem, this\npaper introduces a novel Deep Learning Diagnosis System that integrates\npre-trained Deep Convolutional Neural Networks (DCNNs) within an ensemble\nlearning framework to achieve precise identification of COVID-19 cases from\nChest X-ray (CXR) images. We combine feature vectors from the final hidden\nlayers of pre-trained DCNNs using the Choquet integral to capture interactions\nbetween different DCNNs that a linear approach cannot. We employed\nSugeno-$\\lambda$ measure theory to derive fuzzy measures for subsets of\nnetworks to enable aggregation. We utilized Differential Evolution to estimate\nfuzzy densities. We developed a TensorFlow-based layer for Choquet operation to\nfacilitate efficient aggregation, due to the intricacies involved in\naggregating feature vectors. Experimental results on the COVIDx dataset show\nthat our ensemble model achieved 98\\% accuracy in three-class classification\nand 99.50\\% in binary classification, outperforming its components-DenseNet-201\n(97\\% for three-class, 98.75\\% for binary), Inception-v3 (96.25\\% for\nthree-class, 98.50\\% for binary), and Xception (94.50\\% for three-class, 98\\%\nfor binary)-and surpassing many previous methods.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08241v1",
    "published_date": "2025-01-14 16:28:02 UTC",
    "updated_date": "2025-01-14 16:28:02 UTC"
  },
  {
    "arxiv_id": "2501.08234v1",
    "title": "Dynamic Pricing in High-Speed Railways Using Multi-Agent Reinforcement Learning",
    "authors": [
      "Enrique Adrian Villarrubia-Martin",
      "Luis Rodriguez-Benitez",
      "David Muñoz-Valero",
      "Giovanni Montana",
      "Luis Jimenez-Linares"
    ],
    "abstract": "This paper addresses a critical challenge in the high-speed passenger railway\nindustry: designing effective dynamic pricing strategies in the context of\ncompeting and cooperating operators. To address this, a multi-agent\nreinforcement learning (MARL) framework based on a non-zero-sum Markov game is\nproposed, incorporating random utility models to capture passenger decision\nmaking. Unlike prior studies in areas such as energy, airlines, and mobile\nnetworks, dynamic pricing for railway systems using deep reinforcement learning\nhas received limited attention. A key contribution of this paper is a\nparametrisable and versatile reinforcement learning simulator designed to model\na variety of railway network configurations and demand patterns while enabling\nrealistic, microscopic modelling of user behaviour, called RailPricing-RL. This\nenvironment supports the proposed MARL framework, which models heterogeneous\nagents competing to maximise individual profits while fostering cooperative\nbehaviour to synchronise connecting services. Experimental results validate the\nframework, demonstrating how user preferences affect MARL performance and how\npricing policies influence passenger choices, utility, and overall system\ndynamics. This study provides a foundation for advancing dynamic pricing\nstrategies in railway systems, aligning profitability with system-wide\nefficiency, and supporting future research on optimising pricing policies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "37 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.08234v1",
    "published_date": "2025-01-14 16:19:25 UTC",
    "updated_date": "2025-01-14 16:19:25 UTC"
  },
  {
    "arxiv_id": "2501.08220v1",
    "title": "Optimization of Link Configuration for Satellite Communication Using Reinforcement Learning",
    "authors": [
      "Tobias Rohe",
      "Michael Kölle",
      "Jan Matheis",
      "Rüdiger Höpfl",
      "Leo Sünkel",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "Satellite communication is a key technology in our modern connected world.\nWith increasingly complex hardware, one challenge is to efficiently configure\nlinks (connections) on a satellite transponder. Planning an optimal link\nconfiguration is extremely complex and depends on many parameters and metrics.\nThe optimal use of the limited resources, bandwidth and power of the\ntransponder is crucial. Such an optimization problem can be approximated using\nmetaheuristic methods such as simulated annealing, but recent research results\nalso show that reinforcement learning can achieve comparable or even better\nperformance in optimization methods. However, there have not yet been any\nstudies on link configuration on satellite transponders. In order to close this\nresearch gap, a transponder environment was developed as part of this work. For\nthis environment, the performance of the reinforcement learning algorithm PPO\nwas compared with the metaheuristic simulated annealing in two experiments. The\nresults show that Simulated Annealing delivers better results for this static\nproblem than the PPO algorithm, however, the research in turn also underlines\nthe potential of reinforcement learning for optimization problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08220v1",
    "published_date": "2025-01-14 16:04:46 UTC",
    "updated_date": "2025-01-14 16:04:46 UTC"
  },
  {
    "arxiv_id": "2501.08208v1",
    "title": "ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems",
    "authors": [
      "Mohita Chowdhury",
      "Yajie Vera He",
      "Aisling Higham",
      "Ernest Lim"
    ],
    "abstract": "Large Language Models (LLMs) have shown impressive potential in clinical\nquestion answering (QA), with Retrieval Augmented Generation (RAG) emerging as\na leading approach for ensuring the factual accuracy of model responses.\nHowever, current automated RAG metrics perform poorly in clinical and\nconversational use cases. Using clinical human evaluations of responses is\nexpensive, unscalable, and not conducive to the continuous iterative\ndevelopment of RAG systems. To address these challenges, we introduce ASTRID -\nan Automated and Scalable TRIaD for evaluating clinical QA systems leveraging\nRAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy\n(RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is\ndesigned to better capture the faithfulness of a model's response to the\nknowledge base without penalising conversational elements. To validate our\ntriad, we curate a dataset of over 200 real-world patient questions posed to an\nLLM-based QA agent during surgical follow-up for cataract surgery - the highest\nvolume operation in the world - augmented with clinician-selected questions for\nemergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate\nthat CF can predict human ratings of faithfulness better than existing\ndefinitions for conversational use cases. Furthermore, we show that evaluation\nusing our triad consisting of CF, RA, and CR exhibits alignment with clinician\nassessment for inappropriate, harmful, or unhelpful responses. Finally, using\nnine different LLMs, we demonstrate that the three metrics can closely agree\nwith human evaluations, highlighting the potential of these metrics for use in\nLLM-driven automated evaluation pipelines. We also publish the prompts and\ndatasets for these experiments, providing valuable resources for further\nresearch and development.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.08208v1",
    "published_date": "2025-01-14 15:46:39 UTC",
    "updated_date": "2025-01-14 15:46:39 UTC"
  },
  {
    "arxiv_id": "2501.08205v1",
    "title": "Modeling Feature Maps for Quantum Machine Learning",
    "authors": [
      "Navneet Singh",
      "Shiva Raj Pokhrel"
    ],
    "abstract": "Quantum Machine Learning (QML) offers significant potential for complex tasks\nlike genome sequence classification, but quantum noise on Noisy\nIntermediate-Scale Quantum (NISQ) devices poses practical challenges. This\nstudy systematically evaluates how various quantum noise models including\ndephasing, amplitude damping, depolarizing, thermal noise, bit-flip, and\nphase-flip affect key QML algorithms (QSVC, Peg-QSVC, QNN, VQC) and feature\nmapping techniques (ZFeatureMap, ZZFeatureMap, and PauliFeatureMap). Results\nindicate that QSVC is notably robust under noise, whereas Peg-QSVC and QNN are\nmore sensitive, particularly to depolarizing and amplitude-damping noise. The\nPauliFeatureMap is especially vulnerable, highlighting difficulties in\nmaintaining accurate classification under noisy conditions. These findings\nunderscore the critical importance of feature map selection and noise\nmitigation strategies in optimizing QML for genomic classification, with\npromising implications for personalized medicine.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08205v1",
    "published_date": "2025-01-14 15:45:27 UTC",
    "updated_date": "2025-01-14 15:45:27 UTC"
  },
  {
    "arxiv_id": "2501.08199v1",
    "title": "EmoNeXt: an Adapted ConvNeXt for Facial Emotion Recognition",
    "authors": [
      "Yassine El Boudouri",
      "Amine Bohi"
    ],
    "abstract": "Facial expressions play a crucial role in human communication serving as a\npowerful and impactful means to express a wide range of emotions. With\nadvancements in artificial intelligence and computer vision, deep neural\nnetworks have emerged as effective tools for facial emotion recognition. In\nthis paper, we propose EmoNeXt, a novel deep learning framework for facial\nexpression recognition based on an adapted ConvNeXt architecture network. We\nintegrate a Spatial Transformer Network (STN) to focus on feature-rich regions\nof the face and Squeeze-and-Excitation blocks to capture channel-wise\ndependencies. Moreover, we introduce a self-attention regularization term,\nencouraging the model to generate compact feature vectors. We demonstrate the\nsuperiority of our model over existing state-of-the-art deep learning models on\nthe FER2013 dataset regarding emotion classification accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 5 figures and 2 tables. 2023 IEEE 25th International\n  Workshop on Multimedia Signal Processing (MMSP), Poitiers, France",
    "pdf_url": "http://arxiv.org/pdf/2501.08199v1",
    "published_date": "2025-01-14 15:23:36 UTC",
    "updated_date": "2025-01-14 15:23:36 UTC"
  },
  {
    "arxiv_id": "2501.08192v1",
    "title": "PRESERVE: Prefetching Model Weights and KV-Cache in Distributed LLM Serving",
    "authors": [
      "Ahmet Caner Yüzügüler",
      "Jiawei Zhuang",
      "Lukas Cavigelli"
    ],
    "abstract": "Large language models (LLMs) are widely used across various applications, but\ntheir substantial computational requirements pose significant challenges,\nparticularly in terms of HBM bandwidth bottlenecks and inter-device\ncommunication overhead. In this paper, we present PRESERVE, a novel prefetching\nframework designed to optimize LLM inference by overlapping memory reads for\nmodel weights and KV-cache with collective communication operations. Through\nextensive experiments conducted on commercial AI accelerators, we demonstrate\nup to 1.6x end-to-end speedup on state-of-the-art, open-source LLMs.\nAdditionally, we perform a design space exploration that identifies the optimal\nhardware configuration for the proposed method, showing a further 1.25x\nimprovement in performance per cost by selecting the optimal L2 cache size. Our\nresults show that PRESERVE has the potential to mitigate the memory bottlenecks\nand communication overheads, offering a solution to improve the performance and\nscalability of the LLM inference systems.",
    "categories": [
      "cs.AI",
      "cs.AR",
      "cs.DC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08192v1",
    "published_date": "2025-01-14 15:14:10 UTC",
    "updated_date": "2025-01-14 15:14:10 UTC"
  },
  {
    "arxiv_id": "2501.08188v1",
    "title": "A Critical Synthesis of Uncertainty Quantification and Foundation Models in Monocular Depth Estimation",
    "authors": [
      "Steven Landgraf",
      "Rongjun Qin",
      "Markus Ulrich"
    ],
    "abstract": "While recent foundation models have enabled significant breakthroughs in\nmonocular depth estimation, a clear path towards safe and reliable deployment\nin the real-world remains elusive. Metric depth estimation, which involves\npredicting absolute distances, poses particular challenges, as even the most\nadvanced foundation models remain prone to critical errors. Since quantifying\nthe uncertainty has emerged as a promising endeavor to address these\nlimitations and enable trustworthy deployment, we fuse five different\nuncertainty quantification methods with the current state-of-the-art\nDepthAnythingV2 foundation model. To cover a wide range of metric depth\ndomains, we evaluate their performance on four diverse datasets. Our findings\nidentify fine-tuning with the Gaussian Negative Log-Likelihood Loss (GNLL) as a\nparticularly promising approach, offering reliable uncertainty estimates while\nmaintaining predictive performance and computational efficiency on par with the\nbaseline, encompassing both training and inference time. By fusing uncertainty\nquantification and foundation models within the context of monocular depth\nestimation, this paper lays a critical foundation for future research aimed at\nimproving not only model performance but also its explainability. Extending\nthis critical synthesis of uncertainty quantification and foundation models\ninto other crucial tasks, such as semantic segmentation and pose estimation,\npresents exciting opportunities for safer and more reliable machine vision\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08188v1",
    "published_date": "2025-01-14 15:13:00 UTC",
    "updated_date": "2025-01-14 15:13:00 UTC"
  },
  {
    "arxiv_id": "2501.08187v2",
    "title": "A Multi-Modal AI Copilot for Single-Cell Analysis with Instruction Following",
    "authors": [
      "Yin Fang",
      "Xinle Deng",
      "Kangwei Liu",
      "Ningyu Zhang",
      "Jingyang Qian",
      "Penghui Yang",
      "Xiaohui Fan",
      "Huajun Chen"
    ],
    "abstract": "Large language models excel at interpreting complex natural language\ninstructions, enabling them to perform a wide range of tasks. In the life\nsciences, single-cell RNA sequencing (scRNA-seq) data serves as the \"language\nof cellular biology\", capturing intricate gene expression patterns at the\nsingle-cell level. However, interacting with this \"language\" through\nconventional tools is often inefficient and unintuitive, posing challenges for\nresearchers. To address these limitations, we present InstructCell, a\nmulti-modal AI copilot that leverages natural language as a medium for more\ndirect and flexible single-cell analysis. We construct a comprehensive\nmulti-modal instruction dataset that pairs text-based instructions with\nscRNA-seq profiles from diverse tissues and species. Building on this, we\ndevelop a multi-modal cell language architecture capable of simultaneously\ninterpreting and processing both modalities. InstructCell empowers researchers\nto accomplish critical tasks-such as cell type annotation, conditional\npseudo-cell generation, and drug sensitivity prediction-using straightforward\nnatural language commands. Extensive evaluations demonstrate that InstructCell\nconsistently meets or exceeds the performance of existing single-cell\nfoundation models, while adapting to diverse experimental conditions. More\nimportantly, InstructCell provides an accessible and intuitive tool for\nexploring complex single-cell data, lowering technical barriers and enabling\ndeeper biological insights.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.HC",
      "cs.LG",
      "q-bio.CB"
    ],
    "primary_category": "cs.CL",
    "comment": "37 pages; 13 figures; Code: https://github.com/zjunlp/Instructcell,\n  Models: https://huggingface.co/zjunlp/Instructcell-chat,\n  https://huggingface.co/zjunlp/InstructCell-instruct",
    "pdf_url": "http://arxiv.org/pdf/2501.08187v2",
    "published_date": "2025-01-14 15:12:19 UTC",
    "updated_date": "2025-01-15 02:59:32 UTC"
  },
  {
    "arxiv_id": "2501.08184v1",
    "title": "Assessing AI Adoption and Digitalization in SMEs: A Framework for Implementation",
    "authors": [
      "Serena Proietti",
      "Roberto Magnani"
    ],
    "abstract": "The primary objective of this research is to examine the current state of\ndigitalization and the integration of artificial intelligence (AI) within small\nand medium-sized enterprises (SMEs) in Italy. There is a significant gap\nbetween SMEs and large corporations in their use of AI, with SMEs facing\nnumerous barriers to adoption. This study identifies critical drivers and\nobstacles to achieving intelligent transformation, proposing a framework model\nto address key challenges and provide actionable guidelines",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08184v1",
    "published_date": "2025-01-14 15:10:25 UTC",
    "updated_date": "2025-01-14 15:10:25 UTC"
  },
  {
    "arxiv_id": "2501.08182v1",
    "title": "CG-MER: A Card Game-based Multimodal dataset for Emotion Recognition",
    "authors": [
      "Nessrine Farhat",
      "Amine Bohi",
      "Leila Ben Letaifa",
      "Rim Slama"
    ],
    "abstract": "The field of affective computing has seen significant advancements in\nexploring the relationship between emotions and emerging technologies. This\npaper presents a novel and valuable contribution to this field with the\nintroduction of a comprehensive French multimodal dataset designed specifically\nfor emotion recognition. The dataset encompasses three primary modalities:\nfacial expressions, speech, and gestures, providing a holistic perspective on\nemotions. Moreover, the dataset has the potential to incorporate additional\nmodalities, such as Natural Language Processing (NLP) to expand the scope of\nemotion recognition research. The dataset was curated through engaging\nparticipants in card game sessions, where they were prompted to express a range\nof emotions while responding to diverse questions. The study included 10\nsessions with 20 participants (9 females and 11 males). The dataset serves as a\nvaluable resource for furthering research in emotion recognition and provides\nan avenue for exploring the intricate connections between human emotions and\ndigital technologies.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 2 figures and 4 tables. Sixteenth International Conference\n  on Machine Vision (ICMV 2023), Yerevan, Armenia",
    "pdf_url": "http://arxiv.org/pdf/2501.08182v1",
    "published_date": "2025-01-14 15:08:56 UTC",
    "updated_date": "2025-01-14 15:08:56 UTC"
  },
  {
    "arxiv_id": "2501.08169v1",
    "title": "Revolutionizing Communication with Deep Learning and XAI for Enhanced Arabic Sign Language Recognition",
    "authors": [
      "Mazen Balat",
      "Rewaa Awaad",
      "Ahmed B. Zaky",
      "Salah A. Aly"
    ],
    "abstract": "This study introduces an integrated approach to recognizing Arabic Sign\nLanguage (ArSL) using state-of-the-art deep learning models such as\nMobileNetV3, ResNet50, and EfficientNet-B2. These models are further enhanced\nby explainable AI (XAI) techniques to boost interpretability. The ArSL2018 and\nRGB Arabic Alphabets Sign Language (AASL) datasets are employed, with\nEfficientNet-B2 achieving peak accuracies of 99.48\\% and 98.99\\%, respectively.\nKey innovations include sophisticated data augmentation methods to mitigate\nclass imbalance, implementation of stratified 5-fold cross-validation for\nbetter generalization, and the use of Grad-CAM for clear model decision\ntransparency. The proposed system not only sets new benchmarks in recognition\naccuracy but also emphasizes interpretability, making it suitable for\napplications in healthcare, education, and inclusive communication\ntechnologies.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 25 figures, 16 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.08169v1",
    "published_date": "2025-01-14 14:49:49 UTC",
    "updated_date": "2025-01-14 14:49:49 UTC"
  },
  {
    "arxiv_id": "2501.08168v1",
    "title": "LeapVAD: A Leap in Autonomous Driving via Cognitive Perception and Dual-Process Thinking",
    "authors": [
      "Yukai Ma",
      "Tiantian Wei",
      "Naiting Zhong",
      "Jianbiao Mei",
      "Tao Hu",
      "Licheng Wen",
      "Xuemeng Yang",
      "Botian Shi",
      "Yong Liu"
    ],
    "abstract": "While autonomous driving technology has made remarkable strides, data-driven\napproaches still struggle with complex scenarios due to their limited reasoning\ncapabilities. Meanwhile, knowledge-driven autonomous driving systems have\nevolved considerably with the popularization of visual language models. In this\npaper, we propose LeapVAD, a novel method based on cognitive perception and\ndual-process thinking. Our approach implements a human-attentional mechanism to\nidentify and focus on critical traffic elements that influence driving\ndecisions. By characterizing these objects through comprehensive attributes -\nincluding appearance, motion patterns, and associated risks - LeapVAD achieves\nmore effective environmental representation and streamlines the decision-making\nprocess. Furthermore, LeapVAD incorporates an innovative dual-process\ndecision-making module miming the human-driving learning process. The system\nconsists of an Analytic Process (System-II) that accumulates driving experience\nthrough logical reasoning and a Heuristic Process (System-I) that refines this\nknowledge via fine-tuning and few-shot learning. LeapVAD also includes\nreflective mechanisms and a growing memory bank, enabling it to learn from past\nmistakes and continuously improve its performance in a closed-loop environment.\nTo enhance efficiency, we develop a scene encoder network that generates\ncompact scene representations for rapid retrieval of relevant driving\nexperiences. Extensive evaluations conducted on two leading autonomous driving\nsimulators, CARLA and DriveArena, demonstrate that LeapVAD achieves superior\nperformance compared to camera-only approaches despite limited training data.\nComprehensive ablation studies further emphasize its effectiveness in\ncontinuous learning and domain adaptation. Project page:\nhttps://pjlab-adg.github.io/LeapVAD/.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08168v1",
    "published_date": "2025-01-14 14:49:45 UTC",
    "updated_date": "2025-01-14 14:49:45 UTC"
  },
  {
    "arxiv_id": "2501.08167v2",
    "title": "Potential and Perils of Large Language Models as Judges of Unstructured Textual Data",
    "authors": [
      "Rewina Bedemariam",
      "Natalie Perez",
      "Sreyoshi Bhaduri",
      "Satya Kapoor",
      "Alex Gil",
      "Elizabeth Conjar",
      "Ikkei Itoku",
      "David Theil",
      "Aman Chadha",
      "Naumaan Nayyar"
    ],
    "abstract": "Rapid advancements in large language models have unlocked remarkable\ncapabilities when it comes to processing and summarizing unstructured text\ndata. This has implications for the analysis of rich, open-ended datasets, such\nas survey responses, where LLMs hold the promise of efficiently distilling key\nthemes and sentiments. However, as organizations increasingly turn to these\npowerful AI systems to make sense of textual feedback, a critical question\narises, can we trust LLMs to accurately represent the perspectives contained\nwithin these text based datasets? While LLMs excel at generating human-like\nsummaries, there is a risk that their outputs may inadvertently diverge from\nthe true substance of the original responses. Discrepancies between the\nLLM-generated outputs and the actual themes present in the data could lead to\nflawed decision-making, with far-reaching consequences for organizations. This\nresearch investigates the effectiveness of LLM-as-judge models to evaluate the\nthematic alignment of summaries generated by other LLMs. We utilized an\nAnthropic Claude model to generate thematic summaries from open-ended survey\nresponses, with Amazon's Titan Express, Nova Pro, and Meta's Llama serving as\njudges. This LLM-as-judge approach was compared to human evaluations using\nCohen's kappa, Spearman's rho, and Krippendorff's alpha, validating a scalable\nalternative to traditional human centric evaluation methods. Our findings\nreveal that while LLM-as-judge offer a scalable solution comparable to human\nraters, humans may still excel at detecting subtle, context-specific nuances.\nOur research contributes to the growing body of knowledge on AI assisted text\nanalysis. Further, we provide recommendations for future research, emphasizing\nthe need for careful consideration when generalizing LLM-as-judge models across\nvarious contexts and use cases.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 1 appendix",
    "pdf_url": "http://arxiv.org/pdf/2501.08167v2",
    "published_date": "2025-01-14 14:49:14 UTC",
    "updated_date": "2025-01-20 17:34:20 UTC"
  },
  {
    "arxiv_id": "2501.08165v1",
    "title": "I Can Find You in Seconds! Leveraging Large Language Models for Code Authorship Attribution",
    "authors": [
      "Soohyeon Choi",
      "Yong Kiam Tan",
      "Mark Huasong Meng",
      "Mohamed Ragab",
      "Soumik Mondal",
      "David Mohaisen",
      "Khin Mi Mi Aung"
    ],
    "abstract": "Source code authorship attribution is important in software forensics,\nplagiarism detection, and protecting software patch integrity. Existing\ntechniques often rely on supervised machine learning, which struggles with\ngeneralization across different programming languages and coding styles due to\nthe need for large labeled datasets. Inspired by recent advances in natural\nlanguage authorship analysis using large language models (LLMs), which have\nshown exceptional performance without task-specific tuning, this paper explores\nthe use of LLMs for source code authorship attribution.\n  We present a comprehensive study demonstrating that state-of-the-art LLMs can\nsuccessfully attribute source code authorship across different languages. LLMs\ncan determine whether two code snippets are written by the same author with\nzero-shot prompting, achieving a Matthews Correlation Coefficient (MCC) of\n0.78, and can attribute code authorship from a small set of reference code\nsnippets via few-shot learning, achieving MCC of 0.77. Additionally, LLMs show\nsome adversarial robustness against misattribution attacks.\n  Despite these capabilities, we found that naive prompting of LLMs does not\nscale well with a large number of authors due to input token limitations. To\naddress this, we propose a tournament-style approach for large-scale\nattribution. Evaluating this approach on datasets of C++ (500 authors, 26,355\nsamples) and Java (686 authors, 55,267 samples) code from GitHub, we achieve\nclassification accuracy of up to 65% for C++ and 68.7% for Java using only one\nreference per author. These results open new possibilities for applying LLMs to\ncode authorship attribution in cybersecurity and software engineering.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 5 figures,",
    "pdf_url": "http://arxiv.org/pdf/2501.08165v1",
    "published_date": "2025-01-14 14:46:19 UTC",
    "updated_date": "2025-01-14 14:46:19 UTC"
  },
  {
    "arxiv_id": "2501.08155v1",
    "title": "FairTTTS: A Tree Test Time Simulation Method for Fairness-Aware Classification",
    "authors": [
      "Nurit Cohen-Inger",
      "Lior Rokach",
      "Bracha Shapira",
      "Seffi Cohen"
    ],
    "abstract": "Algorithmic decision-making has become deeply ingrained in many domains, yet\nbiases in machine learning models can still produce discriminatory outcomes,\noften harming unprivileged groups. Achieving fair classification is inherently\nchallenging, requiring a careful balance between predictive performance and\nethical considerations. We present FairTTTS, a novel post-processing bias\nmitigation method inspired by the Tree Test Time Simulation (TTTS) method.\nOriginally developed to enhance accuracy and robustness against adversarial\ninputs through probabilistic decision-path adjustments, TTTS serves as the\nfoundation for FairTTTS. By building on this accuracy-enhancing technique,\nFairTTTS mitigates bias and improves predictive performance. FairTTTS uses a\ndistance-based heuristic to adjust decisions at protected attribute nodes,\nensuring fairness for unprivileged samples. This fairness-oriented adjustment\noccurs as a post-processing step, allowing FairTTTS to be applied to\npre-trained models, diverse datasets, and various fairness metrics without\nretraining. Extensive evaluation on seven benchmark datasets shows that\nFairTTTS outperforms traditional methods in fairness improvement, achieving a\n20.96% average increase over the baseline compared to 18.78% for related work,\nand further enhances accuracy by 0.55%. In contrast, competing methods\ntypically reduce accuracy by 0.42%. These results confirm that FairTTTS\neffectively promotes more equitable decision-making while simultaneously\nimproving predictive performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08155v1",
    "published_date": "2025-01-14 14:29:36 UTC",
    "updated_date": "2025-01-14 14:29:36 UTC"
  },
  {
    "arxiv_id": "2501.08149v1",
    "title": "Multiple-Input Variational Auto-Encoder for Anomaly Detection in Heterogeneous Data",
    "authors": [
      "Phai Vu Dinh",
      "Diep N. Nguyen",
      "Dinh Thai Hoang",
      "Quang Uy Nguyen",
      "Eryk Dutkiewicz"
    ],
    "abstract": "Anomaly detection (AD) plays a pivotal role in AI applications, e.g., in\nclassification, and intrusion/threat detection in cybersecurity. However, most\nexisting methods face challenges of heterogeneity amongst feature subsets posed\nby non-independent and identically distributed (non-IID) data. We propose a\nnovel neural network model called Multiple-Input Auto-Encoder for AD (MIAEAD)\nto address this. MIAEAD assigns an anomaly score to each feature subset of a\ndata sample to indicate its likelihood of being an anomaly. This is done by\nusing the reconstruction error of its sub-encoder as the anomaly score. All\nsub-encoders are then simultaneously trained using unsupervised learning to\ndetermine the anomaly scores of feature subsets. The final AUC of MIAEAD is\ncalculated for each sub-dataset, and the maximum AUC obtained among the\nsub-datasets is selected. To leverage the modelling of the distribution of\nnormal data to identify anomalies of the generative models, we develop a novel\nneural network architecture/model called Multiple-Input Variational\nAuto-Encoder (MIVAE). MIVAE can process feature subsets through its\nsub-encoders before learning distribution of normal data in the latent space.\nThis allows MIVAE to identify anomalies that deviate from the learned\ndistribution. We theoretically prove that the difference in the average anomaly\nscore between normal samples and anomalies obtained by the proposed MIVAE is\ngreater than that of the Variational Auto-Encoder (VAEAD), resulting in a\nhigher AUC for MIVAE. Extensive experiments on eight real-world anomaly\ndatasets demonstrate the superior performance of MIAEAD and MIVAE over\nconventional methods and the state-of-the-art unsupervised models, by up to 6%\nin terms of AUC score. Alternatively, MIAEAD and MIVAE have a high AUC when\napplied to feature subsets with low heterogeneity based on the coefficient of\nvariation (CV) score.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.08149v1",
    "published_date": "2025-01-14 14:25:10 UTC",
    "updated_date": "2025-01-14 14:25:10 UTC"
  },
  {
    "arxiv_id": "2501.08145v1",
    "title": "Refusal Behavior in Large Language Models: A Nonlinear Perspective",
    "authors": [
      "Fabian Hildebrandt",
      "Andreas Maier",
      "Patrick Krauss",
      "Achim Schilling"
    ],
    "abstract": "Refusal behavior in large language models (LLMs) enables them to decline\nresponding to harmful, unethical, or inappropriate prompts, ensuring alignment\nwith ethical standards. This paper investigates refusal behavior across six\nLLMs from three architectural families. We challenge the assumption of refusal\nas a linear phenomenon by employing dimensionality reduction techniques,\nincluding PCA, t-SNE, and UMAP. Our results reveal that refusal mechanisms\nexhibit nonlinear, multidimensional characteristics that vary by model\narchitecture and layer. These findings highlight the need for nonlinear\ninterpretability to improve alignment research and inform safer AI deployment\nstrategies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08145v1",
    "published_date": "2025-01-14 14:23:18 UTC",
    "updated_date": "2025-01-14 14:23:18 UTC"
  },
  {
    "arxiv_id": "2501.08139v1",
    "title": "EEG-ReMinD: Enhancing Neurodegenerative EEG Decoding through Self-Supervised State Reconstruction-Primed Riemannian Dynamics",
    "authors": [
      "Zirui Wang",
      "Zhenxi Song",
      "Yi Guo",
      "Yuxin Liu",
      "Guoyang Xu",
      "Min Zhang",
      "Zhiguo Zhang"
    ],
    "abstract": "The development of EEG decoding algorithms confronts challenges such as data\nsparsity, subject variability, and the need for precise annotations, all of\nwhich are vital for advancing brain-computer interfaces and enhancing the\ndiagnosis of diseases. To address these issues, we propose a novel two-stage\napproach named Self-Supervised State Reconstruction-Primed Riemannian Dynamics\n(EEG-ReMinD) , which mitigates reliance on supervised learning and integrates\ninherent geometric features. This approach efficiently handles EEG data\ncorruptions and reduces the dependency on labels. EEG-ReMinD utilizes\nself-supervised and geometric learning techniques, along with an attention\nmechanism, to analyze the temporal dynamics of EEG features within the\nframework of Riemannian geometry, referred to as Riemannian dynamics.\nComparative analyses on both intact and corrupted datasets from two different\nneurodegenerative disorders underscore the enhanced performance of EEG-ReMinD.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08139v1",
    "published_date": "2025-01-14 14:19:40 UTC",
    "updated_date": "2025-01-14 14:19:40 UTC"
  },
  {
    "arxiv_id": "2501.08134v1",
    "title": "An Empirical Wall-Pressure Spectrum Model for Aeroacoustic Predictions Based on Symbolic Regression",
    "authors": [
      "Laura Botero Bolívar",
      "David Huergo",
      "Fernanda L. dos Santos",
      "Cornelis H. Venner",
      "Leandro D. de Santana",
      "Esteban Ferrer"
    ],
    "abstract": "Fast-turn around methods to predict airfoil trailing-edge noise are crucial\nfor incorporating noise limitations into design optimization loops of several\napplications. Among these aeroacoustic predictive models, Amiet's theory offers\nthe best balance between accuracy and simplicity. The accuracy of the model\nrelies heavily on precise wall-pressure spectrum predictions, which are often\nbased on single-equation formulations with adjustable parameters. These\nparameters are calibrated for particular airfoils and flow conditions and\nconsequently tend to fail when applied outside their calibration range. This\npaper introduces a new wall-pressure spectrum empirical model designed to\nenhance the robustness and accuracy of current state-of-the-art predictions\nwhile widening the range of applicability of the model to different airfoils\nand flow conditions. The model is developed using AI-based symbolic regression\nvia a genetic-algorithm-based approach, and applied to a dataset of\nwall-pressure fluctuations measured on NACA 0008 and NACA 63018 airfoils at\nmultiple angles of attack and inflow velocities, covering turbulent boundary\nlayers with both adverse and favorable pressure gradients. Validation against\nexperimental data (outside the training dataset) demonstrates the robustness of\nthe model compared to well-accepted semi-empirical models. Finally, the model\nis integrated with Amiet's theory to predict the aeroacoustic noise of a\nfull-scale wind turbine, showing good agreement with experimental measurements.",
    "categories": [
      "physics.flu-dyn",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "physics.flu-dyn",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08134v1",
    "published_date": "2025-01-14 14:14:22 UTC",
    "updated_date": "2025-01-14 14:14:22 UTC"
  },
  {
    "arxiv_id": "2501.08120v1",
    "title": "In-situ graph reasoning and knowledge expansion using Graph-PReFLexOR",
    "authors": [
      "Markus J. Buehler"
    ],
    "abstract": "The pursuit of automated scientific discovery has fueled progress from\nsymbolic logic to modern AI, forging new frontiers in reasoning and pattern\nrecognition. Transformers function as potential systems, where every possible\nrelationship remains latent potentiality until tasks impose constraints, akin\nto measurement. Yet, refining their sampling requires more than probabilistic\nselection: solutions must conform to specific structures or rules, ensuring\nconsistency and the invocation of general principles. We present\nGraph-PReFLexOR (Graph-based Preference-based Recursive Language Modeling for\nExploratory Optimization of Reasoning), a framework that combines graph\nreasoning with symbolic abstraction to dynamically expand domain knowledge.\nInspired by reinforcement learning, Graph-PReFLexOR defines reasoning as a\nstructured mapping, where tasks yield knowledge graphs, abstract patterns, and\nultimately, final answers. Inspired by category theory, it encodes concepts as\nnodes and their relationships as edges, supporting hierarchical inference and\nadaptive learning through isomorphic representations. Demonstrations include\nhypothesis generation, materials design, and creative reasoning, such as\ndiscovering relationships between mythological concepts like 'thin places' with\nmaterials science. We propose a 'knowledge garden growth' strategy that\nintegrates insights across domains, promoting interdisciplinary connections.\nResults with a 3-billion-parameter Graph-PReFLexOR model show superior\nreasoning depth and adaptability, underscoring the potential for transparent,\nmultidisciplinary AI-driven discovery. It lays the groundwork for general\nautonomous reasoning solutions.",
    "categories": [
      "cs.AI",
      "cond-mat.dis-nn",
      "cond-mat.mtrl-sci",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08120v1",
    "published_date": "2025-01-14 13:52:41 UTC",
    "updated_date": "2025-01-14 13:52:41 UTC"
  },
  {
    "arxiv_id": "2501.08109v3",
    "title": "Data-driven inventory management for new products: An adjusted Dyna-$Q$ approach with transfer learning",
    "authors": [
      "Xinye Qu",
      "Longxiao Liu",
      "Wenjie Huang"
    ],
    "abstract": "In this paper, we propose a novel reinforcement learning algorithm for\ninventory management of newly launched products with no historical demand\ninformation. The algorithm follows the classic Dyna-$Q$ structure, balancing\nthe model-free and model-based approaches, while accelerating the training\nprocess of Dyna-$Q$ and mitigating the model discrepancy generated by the\nmodel-based feedback. Based on the idea of transfer learning, warm-start\ninformation from the demand data of existing similar products can be\nincorporated into the algorithm to further stabilize the early-stage training\nand reduce the variance of the estimated optimal policy. Our approach is\nvalidated through a case study of bakery inventory management with real data.\nThe adjusted Dyna-$Q$ shows up to a 23.7\\% reduction in average daily cost\ncompared with $Q$-learning, and up to a 77.5\\% reduction in training time\nwithin the same horizon compared with classic Dyna-$Q$. By using transfer\nlearning, it can be found that the adjusted Dyna-$Q$ has the lowest total cost,\nlowest variance in total cost, and relatively low shortage percentages among\nall the benchmarking algorithms under a 30-day testing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.08109v3",
    "published_date": "2025-01-14 13:40:08 UTC",
    "updated_date": "2025-03-10 06:43:36 UTC"
  },
  {
    "arxiv_id": "2501.10448v1",
    "title": "Towards Lightweight Time Series Forecasting: a Patch-wise Transformer with Weak Data Enriching",
    "authors": [
      "Meng Wang",
      "Jintao Yang",
      "Bin Yang",
      "Hui Li",
      "Tongxin Gong",
      "Bo Yang",
      "Jiangtao Cui"
    ],
    "abstract": "Patch-wise Transformer based time series forecasting achieves superior\naccuracy. However, this superiority relies heavily on intricate model design\nwith massive parameters, rendering both training and inference expensive, thus\npreventing their deployments on edge devices with limited resources and low\nlatency requirements. In addition, existing methods often work in an\nautoregressive manner, which take into account only historical values, but\nignore valuable, easy-to-obtain context information, such as weather forecasts,\ndate and time of day. To contend with the two limitations, we propose\nLiPFormer, a novel Lightweight Patch-wise Transformer with weak data enriching.\nFirst, to simplify the Transformer backbone, LiPFormer employs a novel\nlightweight cross-patch attention and a linear transformation-based attention\nto eliminate Layer Normalization and Feed Forward Network, two heavy components\nin existing Transformers. Second, we propose a lightweight, weak data enriching\nmodule to provide additional, valuable weak supervision to the training. It\nenhances forecasting accuracy without significantly increasing model complexity\nas it does not involve expensive, human-labeling but using easily accessible\ncontext information. This facilitates the weak data enriching to plug-and-play\non existing models. Extensive experiments on nine benchmark time series\ndatasets demonstrate that LiPFormer outperforms state-of-the-art methods in\naccuracy, while significantly reducing parameter scale, training duration, and\nGPU memory usage. Deployment on an edge device reveals that LiPFormer takes\nonly 1/3 inference time compared to classic Transformers. In addition, we\ndemonstrate that the weak data enriching can integrate seamlessly into various\nTransformer based models to enhance their accuracy, suggesting its generality.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 41st IEEE International Conference on Data\n  Engineering (ICDE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.10448v1",
    "published_date": "2025-01-14 13:35:03 UTC",
    "updated_date": "2025-01-14 13:35:03 UTC"
  },
  {
    "arxiv_id": "2501.08102v2",
    "title": "Consistency of Responses and Continuations Generated by Large Language Models on Social Media",
    "authors": [
      "Wenlu Fan",
      "Yuqi Zhu",
      "Chenyang Wang",
      "Bin Wang",
      "Wentao Xu"
    ],
    "abstract": "Large Language Models (LLMs) demonstrate remarkable capabilities in text\ngeneration, yet their emotional consistency and semantic coherence in social\nmedia contexts remain insufficiently understood. This study investigates how\nLLMs handle emotional content and maintain semantic relationships through\ncontinuation and response tasks using two open-source models: Gemma and Llama.\nBy analyzing climate change discussions from Twitter and Reddit, we examine\nemotional transitions, intensity patterns, and semantic similarity between\nhuman-authored and LLM-generated content. Our findings reveal that while both\nmodels maintain high semantic coherence, they exhibit distinct emotional\npatterns: Gemma shows a tendency toward negative emotion amplification,\nparticularly anger, while maintaining certain positive emotions like optimism.\nLlama demonstrates superior emotional preservation across a broader spectrum of\naffects. Both models systematically generate responses with attenuated\nemotional intensity compared to human-authored content and show a bias toward\npositive emotions in response tasks. Additionally, both models maintain strong\nsemantic similarity with original texts, though performance varies between\ncontinuation and response tasks. These findings provide insights into LLMs'\nemotional and semantic processing capabilities, with implications for their\ndeployment in social media contexts and human-AI interaction design.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08102v2",
    "published_date": "2025-01-14 13:19:47 UTC",
    "updated_date": "2025-01-15 18:10:00 UTC"
  },
  {
    "arxiv_id": "2501.08097v1",
    "title": "Guiding the classification of hepatocellular carcinoma on 3D CT-scans using deep and handcrafted radiological features",
    "authors": [
      "E. Sarfati",
      "A. Bône",
      "M-M. Rohé",
      "C. Aubé",
      "M. Ronot",
      "P. Gori",
      "I. Bloch"
    ],
    "abstract": "Hepatocellular carcinoma is the most spread primary liver cancer across the\nworld ($\\sim$80\\% of the liver tumors). The gold standard for HCC diagnosis is\nliver biopsy. However, in the clinical routine, expert radiologists provide a\nvisual diagnosis by interpreting hepatic CT-scans according to a standardized\nprotocol, the LI-RADS, which uses five radiological criteria with an associated\ndecision tree. In this paper, we propose an automatic approach to predict\nhistology-proven HCC from CT images in order to reduce radiologists'\ninter-variability. We first show that standard deep learning methods fail to\naccurately predict HCC from CT-scans on a challenging database, and propose a\ntwo-step approach inspired by the LI-RADS system to improve the performance. We\nachieve improvements from 6 to 18 points of AUC with respect to deep learning\nbaselines trained with different architectures. We also provide clinical\nvalidation of our method, achieving results that outperform non-expert\nradiologists and are on par with expert ones.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IEEE ISBI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.08097v1",
    "published_date": "2025-01-14 13:10:29 UTC",
    "updated_date": "2025-01-14 13:10:29 UTC"
  },
  {
    "arxiv_id": "2501.08096v2",
    "title": "Hybrid Action Based Reinforcement Learning for Multi-Objective Compatible Autonomous Driving",
    "authors": [
      "Guizhe Jin",
      "Zhuoren Li",
      "Bo Leng",
      "Wei Han",
      "Lu Xiong",
      "Chen Sun"
    ],
    "abstract": "Reinforcement Learning (RL) has shown excellent performance in solving\ndecision-making and control problems of autonomous driving, which is\nincreasingly applied in diverse driving scenarios. However, driving is a\nmulti-attribute problem, leading to challenges in achieving multi-objective\ncompatibility for current RL methods, especially in both policy execution and\npolicy iteration. On the one hand, the common action space structure with\nsingle action type limits driving flexibility or results in large behavior\nfluctuations during policy execution. On the other hand, the multi-attribute\nweighted single reward function result in the agent's disproportionate\nattention to certain objectives during policy iterations. To this end, we\npropose a Multi-objective Ensemble-Critic reinforcement learning method with\nHybrid Parametrized Action for multi-objective compatible autonomous driving.\nSpecifically, a parameterized action space is constructed to generate hybrid\ndriving actions, combining both abstract guidance and concrete control\ncommands. A multi-objective critics architecture is constructed considering\nmultiple attribute rewards, to ensure simultaneously focusing on different\ndriving objectives. Additionally, uncertainty-based exploration strategy is\nintroduced to help the agent faster approach viable driving policy. The\nexperimental results in both the simulated traffic environment and the HighD\ndataset demonstrate that our method can achieve multi-objective compatible\nautonomous driving in terms of driving efficiency, action consistency, and\nsafety. It enhances the general performance of the driving while significantly\nincreasing training efficiency.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 9 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.08096v2",
    "published_date": "2025-01-14 13:10:13 UTC",
    "updated_date": "2025-03-28 14:49:25 UTC"
  },
  {
    "arxiv_id": "2501.08090v1",
    "title": "Hierarchical Autoscaling for Large Language Model Serving with Chiron",
    "authors": [
      "Archit Patke",
      "Dhemath Reddy",
      "Saurabh Jha",
      "Chandra Narayanaswami",
      "Zbigniew Kalbarczyk",
      "Ravishankar Iyer"
    ],
    "abstract": "Large language model (LLM) serving is becoming an increasingly important\nworkload for cloud providers. Based on performance SLO requirements, LLM\ninference requests can be divided into (a) interactive requests that have tight\nSLOs in the order of seconds, and (b) batch requests that have relaxed SLO in\nthe order of minutes to hours. These SLOs can degrade based on the arrival\nrates, multiplexing, and configuration parameters, thus necessitating the use\nof resource autoscaling on serving instances and their batch sizes. However,\nprevious autoscalers for LLM serving do not consider request SLOs leading to\nunnecessary scaling and resource under-utilization. To address these\nlimitations, we introduce Chiron, an autoscaler that uses the idea of\nhierarchical backpressure estimated using queue size, utilization, and SLOs.\nOur experiments show that Chiron achieves up to 90% higher SLO attainment and\nimproves GPU efficiency by up to 70% compared to existing solutions.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08090v1",
    "published_date": "2025-01-14 12:57:40 UTC",
    "updated_date": "2025-01-14 12:57:40 UTC"
  },
  {
    "arxiv_id": "2501.08086v1",
    "title": "NOMTO: Neural Operator-based symbolic Model approximaTion and discOvery",
    "authors": [
      "Sergei Garmaev",
      "Siddhartha Mishra",
      "Olga Fink"
    ],
    "abstract": "While many physical and engineering processes are most effectively described\nby non-linear symbolic models, existing non-linear symbolic regression (SR)\nmethods are restricted to a limited set of continuous algebraic functions,\nthereby limiting their applicability to discover higher order non-linear\ndifferential relations. In this work, we introduce the Neural Operator-based\nsymbolic Model approximaTion and discOvery (NOMTO) method, a novel approach to\nsymbolic model discovery that leverages Neural Operators to encompass a broad\nrange of symbolic operations. We demonstrate that NOMTO can successfully\nidentify symbolic expressions containing elementary functions with\nsingularities, special functions, and derivatives. Additionally, our\nexperiments demonstrate that NOMTO can accurately rediscover second-order\nnon-linear partial differential equations. By broadening the set of symbolic\noperations available for discovery, NOMTO significantly advances the\ncapabilities of existing SR methods. It provides a powerful and flexible tool\nfor model discovery, capable of capturing complex relations in a variety of\nphysical systems.",
    "categories": [
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08086v1",
    "published_date": "2025-01-14 12:55:48 UTC",
    "updated_date": "2025-01-14 12:55:48 UTC"
  },
  {
    "arxiv_id": "2501.08074v1",
    "title": "Artificial Liver Classifier: A New Alternative to Conventional Machine Learning Models",
    "authors": [
      "Mahmood A. Jumaah",
      "Yossra H. Ali",
      "Tarik A. Rashid"
    ],
    "abstract": "Supervised machine learning classifiers often encounter challenges related to\nperformance, accuracy, and overfitting. This paper introduces the Artificial\nLiver Classifier (ALC), a novel supervised learning classifier inspired by the\nhuman liver's detoxification function. The ALC is characterized by its\nsimplicity, speed, hyperparameters-free, ability to reduce overfitting, and\neffectiveness in addressing multi-classification problems through\nstraightforward mathematical operations. To optimize the ALC's parameters, an\nimproved FOX optimization algorithm (IFOX) is employed as the training method.\nThe proposed ALC was evaluated on five benchmark machine learning datasets:\nIris Flower, Breast Cancer Wisconsin, Wine, Voice Gender, and MNIST. The\nresults demonstrated competitive performance, with the ALC achieving 100%\naccuracy on the Iris dataset, surpassing logistic regression, multilayer\nperceptron, and support vector machine. Similarly, on the Breast Cancer\ndataset, it achieved 99.12% accuracy, outperforming XGBoost and logistic\nregression. Across all datasets, the ALC consistently exhibited lower\noverfitting gaps and loss compared to conventional classifiers. These findings\nhighlight the potential of leveraging biological process simulations to develop\nefficient machine learning models and open new avenues for innovation in the\nfield.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "21 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.08074v1",
    "published_date": "2025-01-14 12:42:01 UTC",
    "updated_date": "2025-01-14 12:42:01 UTC"
  },
  {
    "arxiv_id": "2501.08068v1",
    "title": "A Roadmap to Guide the Integration of LLMs in Hierarchical Planning",
    "authors": [
      "Israel Puerta-Merino",
      "Carlos Núñez-Molina",
      "Pablo Mesejo",
      "Juan Fernández-Olivares"
    ],
    "abstract": "Recent advances in Large Language Models (LLMs) are fostering their\nintegration into several reasoning-related fields, including Automated Planning\n(AP). However, their integration into Hierarchical Planning (HP), a subfield of\nAP that leverages hierarchical knowledge to enhance planning performance,\nremains largely unexplored. In this preliminary work, we propose a roadmap to\naddress this gap and harness the potential of LLMs for HP. To this end, we\npresent a taxonomy of integration methods, exploring how LLMs can be utilized\nwithin the HP life cycle. Additionally, we provide a benchmark with a\nstandardized dataset for evaluating the performance of future LLM-based HP\napproaches, and present initial results for a state-of-the-art HP planner and\nLLM planner. As expected, the latter exhibits limited performance (3\\% correct\nplans, and none with a correct hierarchical decomposition) but serves as a\nvaluable baseline for future approaches.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 0 figures, to be published in the AAAI Workshop on Planning\n  in the Era of LLMs ( https://llmforplanning.github.io )",
    "pdf_url": "http://arxiv.org/pdf/2501.08068v1",
    "published_date": "2025-01-14 12:34:25 UTC",
    "updated_date": "2025-01-14 12:34:25 UTC"
  },
  {
    "arxiv_id": "2501.08057v1",
    "title": "Optimizing Speech Multi-View Feature Fusion through Conditional Computation",
    "authors": [
      "Weiqiao Shan",
      "Yuhao Zhang",
      "Yuchen Han",
      "Bei Li",
      "Xiaofeng Zhao",
      "Yuang Li",
      "Min Zhang",
      "Hao Yang",
      "Tong Xiao",
      "Jingbo Zhu"
    ],
    "abstract": "Recent advancements have highlighted the efficacy of self-supervised learning\n(SSL) features in various speech-related tasks, providing lightweight and\nversatile multi-view speech representations. However, our study reveals that\nwhile SSL features expedite model convergence, they conflict with traditional\nspectral features like FBanks in terms of update directions. In response, we\npropose a novel generalized feature fusion framework grounded in conditional\ncomputation, featuring a gradient-sensitive gating network and a multi-stage\ndropout strategy. This framework mitigates feature conflicts and bolsters model\nrobustness to multi-view input features. By integrating SSL and spectral\nfeatures, our approach accelerates convergence and maintains performance on par\nwith spectral models across multiple speech translation tasks on the MUSTC\ndataset.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.08057v1",
    "published_date": "2025-01-14 12:12:06 UTC",
    "updated_date": "2025-01-14 12:12:06 UTC"
  },
  {
    "arxiv_id": "2501.08053v1",
    "title": "Exploring Narrative Clustering in Large Language Models: A Layerwise Analysis of BERT",
    "authors": [
      "Awritrojit Banerjee",
      "Achim Schilling",
      "Patrick Krauss"
    ],
    "abstract": "This study investigates the internal mechanisms of BERT, a transformer-based\nlarge language model, with a focus on its ability to cluster narrative content\nand authorial style across its layers. Using a dataset of narratives developed\nvia GPT-4, featuring diverse semantic content and stylistic variations, we\nanalyze BERT's layerwise activations to uncover patterns of localized neural\nprocessing. Through dimensionality reduction techniques such as Principal\nComponent Analysis (PCA) and Multidimensional Scaling (MDS), we reveal that\nBERT exhibits strong clustering based on narrative content in its later layers,\nwith progressively compact and distinct clusters. While strong stylistic\nclustering might occur when narratives are rephrased into different text types\n(e.g., fables, sci-fi, kids' stories), minimal clustering is observed for\nauthorial style specific to individual writers. These findings highlight BERT's\nprioritization of semantic content over stylistic features, offering insights\ninto its representational capabilities and processing hierarchy. This study\ncontributes to understanding how transformer models like BERT encode linguistic\ninformation, paving the way for future interdisciplinary research in artificial\nintelligence and cognitive neuroscience.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: text overlap with arXiv:2408.03062,\n  arXiv:2408.04270, arXiv:2307.01577",
    "pdf_url": "http://arxiv.org/pdf/2501.08053v1",
    "published_date": "2025-01-14 12:01:54 UTC",
    "updated_date": "2025-01-14 12:01:54 UTC"
  },
  {
    "arxiv_id": "2501.08049v1",
    "title": "Self-Attentive Spatio-Temporal Calibration for Precise Intermediate Layer Matching in ANN-to-SNN Distillation",
    "authors": [
      "Di Hong",
      "Yueming Wang"
    ],
    "abstract": "Spiking Neural Networks (SNNs) are promising for low-power computation due to\ntheir event-driven mechanism but often suffer from lower accuracy compared to\nArtificial Neural Networks (ANNs). ANN-to-SNN knowledge distillation can\nimprove SNN performance, but previous methods either focus solely on label\ninformation, missing valuable intermediate layer features, or use a layer-wise\napproach that neglects spatial and temporal semantic inconsistencies, leading\nto performance degradation.To address these limitations, we propose a novel\nmethod called self-attentive spatio-temporal calibration (SASTC). SASTC uses\nself-attention to identify semantically aligned layer pairs between ANN and\nSNN, both spatially and temporally. This enables the autonomous transfer of\nrelevant semantic information. Extensive experiments show that SASTC\noutperforms existing methods, effectively solving the mismatching problem.\nSuperior accuracy results include 95.12% on CIFAR-10, 79.40% on CIFAR-100 with\n2 time steps, and 68.69% on ImageNet with 4 time steps for static datasets, and\n97.92% on DVS-Gesture and 83.60% on DVS-CIFAR10 for neuromorphic datasets. This\nmarks the first time SNNs have outperformed ANNs on both CIFAR-10 and\nCIFAR-100, shedding the new light on the potential applications of SNNs.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08049v1",
    "published_date": "2025-01-14 11:56:00 UTC",
    "updated_date": "2025-01-14 11:56:00 UTC"
  },
  {
    "arxiv_id": "2501.08046v3",
    "title": "Building Symbiotic AI: Reviewing the AI Act for a Human-Centred, Principle-Based Framework",
    "authors": [
      "Miriana Calvano",
      "Antonio Curci",
      "Giuseppe Desolda",
      "Andrea Esposito",
      "Rosa Lanzilotti",
      "Antonio Piccinno"
    ],
    "abstract": "Artificial Intelligence (AI) spreads quickly as new technologies and services\ntake over modern society. The need to regulate AI design, development, and use\nis strictly necessary to avoid unethical and potentially dangerous consequences\nto humans. The European Union (EU) has released a new legal framework, the AI\nAct, to regulate AI by undertaking a risk-based approach to safeguard humans\nduring interaction. At the same time, researchers offer a new perspective on AI\nsystems, commonly known as Human-Centred AI (HCAI), highlighting the need for a\nhuman-centred approach to their design. In this context, Symbiotic AI (a\nsubtype of HCAI) promises to enhance human capabilities through a deeper and\ncontinuous collaboration between human intelligence and AI. This article\npresents the results of a Systematic Literature Review (SLR) that aims to\nidentify principles that characterise the design and development of Symbiotic\nAI systems while considering humans as the core of the process. Through content\nanalysis, four principles emerged from the review that must be applied to\ncreate Human-Centred AI systems that can establish a symbiotic relationship\nwith humans. In addition, current trends and challenges were defined to\nindicate open questions that may guide future research for the development of\nSAI systems that comply with the AI Act.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Third version: 36 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.08046v3",
    "published_date": "2025-01-14 11:53:10 UTC",
    "updated_date": "2025-05-20 10:39:21 UTC"
  },
  {
    "arxiv_id": "2501.08042v1",
    "title": "Exploring visual language models as a powerful tool in the diagnosis of Ewing Sarcoma",
    "authors": [
      "Alvaro Pastor-Naranjo",
      "Pablo Meseguer",
      "Rocío del Amor",
      "Jose Antonio Lopez-Guerrero",
      "Samuel Navarro",
      "Katia Scotlandi",
      "Antonio Llombart-Bosch",
      "Isidro Machado",
      "Valery Naranjo"
    ],
    "abstract": "Ewing's sarcoma (ES), characterized by a high density of small round blue\ncells without structural organization, presents a significant health concern,\nparticularly among adolescents aged 10 to 19. Artificial intelligence-based\nsystems for automated analysis of histopathological images are promising to\ncontribute to an accurate diagnosis of ES. In this context, this study explores\nthe feature extraction ability of different pre-training strategies for\ndistinguishing ES from other soft tissue or bone sarcomas with similar\nmorphology in digitized tissue microarrays for the first time, as far as we\nknow. Vision-language supervision (VLS) is compared to fully-supervised\nImageNet pre-training within a multiple instance learning paradigm. Our\nfindings indicate a substantial improvement in diagnostic accuracy with the\nadaption of VLS using an in-domain dataset. Notably, these models not only\nenhance the accuracy of predicted classes but also drastically reduce the\nnumber of trainable parameters and computational costs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 5 figures, 2 tables. Oral presentation at KES-InMed 2024\n  held in Madeira, Portugal",
    "pdf_url": "http://arxiv.org/pdf/2501.08042v1",
    "published_date": "2025-01-14 11:47:35 UTC",
    "updated_date": "2025-01-14 11:47:35 UTC"
  },
  {
    "arxiv_id": "2501.08035v1",
    "title": "READ: Reinforcement-based Adversarial Learning for Text Classification with Limited Labeled Data",
    "authors": [
      "Rohit Sharma",
      "Shanu Kumar",
      "Avinash Kumar"
    ],
    "abstract": "Pre-trained transformer models such as BERT have shown massive gains across\nmany text classification tasks. However, these models usually need enormous\nlabeled data to achieve impressive performances. Obtaining labeled data is\noften expensive and time-consuming, whereas collecting unlabeled data using\nsome heuristics is relatively much cheaper for any task. Therefore, this paper\nproposes a method that encapsulates reinforcement learning-based text\ngeneration and semi-supervised adversarial learning approaches in a novel way\nto improve the model's performance. Our method READ, Reinforcement-based\nAdversarial learning, utilizes an unlabeled dataset to generate diverse\nsynthetic text through reinforcement learning, improving the model's\ngeneralization capability using adversarial learning. Our experimental results\nshow that READ outperforms the existing state-of-art methods on multiple\ndatasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08035v1",
    "published_date": "2025-01-14 11:39:55 UTC",
    "updated_date": "2025-01-14 11:39:55 UTC"
  },
  {
    "arxiv_id": "2501.08020v1",
    "title": "Cooperative Patrol Routing: Optimizing Urban Crime Surveillance through Multi-Agent Reinforcement Learning",
    "authors": [
      "Juan Palma-Borda",
      "Eduardo Guzmán",
      "María-Victoria Belmonte"
    ],
    "abstract": "The effective design of patrol strategies is a difficult and complex problem,\nespecially in medium and large areas. The objective is to plan, in a\ncoordinated manner, the optimal routes for a set of patrols in a given area, in\norder to achieve maximum coverage of the area, while also trying to minimize\nthe number of patrols. In this paper, we propose a multi-agent reinforcement\nlearning (MARL) model, based on a decentralized partially observable Markov\ndecision process, to plan unpredictable patrol routes within an urban\nenvironment represented as an undirected graph. The model attempts to maximize\na target function that characterizes the environment within a given time frame.\nOur model has been tested to optimize police patrol routes in three\nmedium-sized districts of the city of Malaga. The aim was to maximize\nsurveillance coverage of the most crime-prone areas, based on actual crime data\nin the city. To address this problem, several MARL algorithms have been\nstudied, and among these the Value Decomposition Proximal Policy Optimization\n(VDPPO) algorithm exhibited the best performance. We also introduce a novel\nmetric, the coverage index, for the evaluation of the coverage performance of\nthe routes generated by our model. This metric is inspired by the predictive\naccuracy index (PAI), which is commonly used in criminology to detect hotspots.\nUsing this metric, we have evaluated the model under various scenarios in which\nthe number of agents (or patrols), their starting positions, and the level of\ninformation they can observe in the environment have been modified. Results\nshow that the coordinated routes generated by our model achieve a coverage of\nmore than $90\\%$ of the $3\\%$ of graph nodes with the highest crime incidence,\nand $65\\%$ for $20\\%$ of these nodes; $3\\%$ and $20\\%$ represent the coverage\nstandards for police resource allocation.",
    "categories": [
      "cs.AI",
      "68T20, 68T42",
      "I.2.1; I.2.8; I.6.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08020v1",
    "published_date": "2025-01-14 11:20:19 UTC",
    "updated_date": "2025-01-14 11:20:19 UTC"
  },
  {
    "arxiv_id": "2501.08019v1",
    "title": "An AI-driven framework for rapid and localized optimizations of urban open spaces",
    "authors": [
      "Pegah Eshraghi",
      "Arman Nikkhah Dehnavi",
      "Maedeh Mirdamadi",
      "Riccardo Talami",
      "Zahra-Sadat Zomorodian"
    ],
    "abstract": "As urbanization accelerates, open spaces are increasingly recognized for\ntheir role in enhancing sustainability and well-being, yet they remain\nunderexplored compared to built spaces. This study introduces an AI-driven\nframework that integrates machine learning models (MLMs) and explainable AI\ntechniques to optimize Sky View Factor (SVF) and visibility, key spatial\nmetrics influencing thermal comfort and perceived safety in urban spaces.\nUnlike global optimization methods, which are computationally intensive and\nimpractical for localized adjustments, this framework supports incremental\ndesign improvements with lower computational costs and greater flexibility. The\nframework employs SHapley Adaptive Explanations (SHAP) to analyze feature\nimportance and Counterfactual Explanations (CFXs) to propose minimal design\nchanges. Simulations tested five MLMs, identifying XGBoost as the most\naccurate, with building width, park area, and heights of surrounding buildings\nas critical for SVF, and distances from southern buildings as key for\nvisibility. Compared to Genetic Algorithms, which required approximately 15/30\nminutes across 3/4 generations to converge, the tested CFX approach achieved\noptimized results in 1 minute with a 5% RMSE error, demonstrating significantly\nfaster performance and suitability for scalable retrofitting strategies. This\ninterpretable and computationally efficient framework advances urban\nperformance optimization, providing data-driven insights and practical\nretrofitting solutions for enhancing usability and environmental quality across\ndiverse urban contexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "36 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.08019v1",
    "published_date": "2025-01-14 11:19:52 UTC",
    "updated_date": "2025-01-14 11:19:52 UTC"
  },
  {
    "arxiv_id": "2501.08009v1",
    "title": "Tutorial: VAE as an inference paradigm for neuroimaging",
    "authors": [
      "C. Vázquez-García",
      "F. J. Martínez-Murcia",
      "F. Segovia Román",
      "Juan M. Górriz Sáez"
    ],
    "abstract": "In this tutorial, we explore Variational Autoencoders (VAEs), an essential\nframework for unsupervised learning, particularly suited for high-dimensional\ndatasets such as neuroimaging. By integrating deep learning with Bayesian\ninference, VAEs enable the generation of interpretable latent representations.\nThis tutorial outlines the theoretical foundations of VAEs, addresses practical\nchallenges such as convergence issues and over-fitting, and discusses\nstrategies like the reparameterization trick and hyperparameter optimization.\nWe also highlight key applications of VAEs in neuroimaging, demonstrating their\npotential to uncover meaningful patterns, including those associated with\nneurodegenerative processes, and their broader implications for analyzing\ncomplex brain data.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "18 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.08009v1",
    "published_date": "2025-01-14 10:54:36 UTC",
    "updated_date": "2025-01-14 10:54:36 UTC"
  },
  {
    "arxiv_id": "2501.08008v1",
    "title": "TriAdaptLoRA: Brain-Inspired Triangular Adaptive Low-Rank Adaptation for Parameter-Efficient Fine-Tuning",
    "authors": [
      "Yao Liang",
      "Yuwei Wang",
      "Yi Zeng"
    ],
    "abstract": "The fine-tuning of Large Language Models (LLMs) is pivotal for achieving\noptimal performance across diverse downstream tasks. However, while full\nfine-tuning delivers superior results, it entails significant computational and\nresource costs. Parameter-Efficient Fine-Tuning (PEFT) methods, such as LoRA,\naddress these challenges by reducing the number of trainable parameters, but\nthey often struggle with rank adjustment efficiency and task-specific\nadaptability. We propose Triangular Adaptive Low-Rank Adaptation\n(TriAdaptLoRA), a novel PEFT framework inspired by neuroscience principles,\nwhich dynamically optimizes the allocation of trainable parameters.\nTriAdaptLoRA introduces three key innovations: 1) a triangular split of\ntransformation matrices into lower and upper triangular components to maximize\nparameter utilization, 2) a parameter importance metric based on normalized\nFrobenius norms for efficient adaptation, and 3) an adaptive rank-growth\nstrategy governed by dynamic thresholds, allowing flexible parameter allocation\nacross training steps. Experiments conducted on a variety of natural language\nunderstanding and generation tasks demonstrate that TriAdaptLoRA consistently\noutperforms existing PEFT methods. It achieves superior performance, enhanced\nstability, and reduced computational overhead, particularly under linear\nthreshold-driven rank growth. These results highlight its efficacy as a\nscalable and resource-efficient solution for fine-tuning LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08008v1",
    "published_date": "2025-01-14 10:51:31 UTC",
    "updated_date": "2025-01-14 10:51:31 UTC"
  },
  {
    "arxiv_id": "2501.08005v1",
    "title": "DisCoPatch: Batch Statistics Are All You Need For OOD Detection, But Only If You Can Trust Them",
    "authors": [
      "Francisco Caetano",
      "Christiaan Viviers",
      "Luis A. Zavala-Mondragón",
      "Peter H. N. de With",
      "Fons van der Sommen"
    ],
    "abstract": "Out-of-distribution (OOD) detection holds significant importance across many\napplications. While semantic and domain-shift OOD problems are well-studied,\nthis work focuses on covariate shifts - subtle variations in the data\ndistribution that can degrade machine learning performance. We hypothesize that\ndetecting these subtle shifts can improve our understanding of in-distribution\nboundaries, ultimately improving OOD detection. In adversarial discriminators\ntrained with Batch Normalization (BN), real and adversarial samples form\ndistinct domains with unique batch statistics - a property we exploit for OOD\ndetection. We introduce DisCoPatch, an unsupervised Adversarial Variational\nAutoencoder (VAE) framework that harnesses this mechanism. During inference,\nbatches consist of patches from the same image, ensuring a consistent data\ndistribution that allows the model to rely on batch statistics. DisCoPatch uses\nthe VAE's suboptimal outputs (generated and reconstructed) as negative samples\nto train the discriminator, thereby improving its ability to delineate the\nboundary between in-distribution samples and covariate shifts. By tightening\nthis boundary, DisCoPatch achieves state-of-the-art results in public OOD\ndetection benchmarks. The proposed model not only excels in detecting covariate\nshifts, achieving 95.5% AUROC on ImageNet-1K(-C) but also outperforms all prior\nmethods on public Near-OOD (95.0%) benchmarks. With a compact model size of\n25MB, it achieves high OOD detection performance at notably lower latency than\nexisting methods, making it an efficient and practical solution for real-world\nOOD detection applications. The code will be made publicly available",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08005v1",
    "published_date": "2025-01-14 10:49:26 UTC",
    "updated_date": "2025-01-14 10:49:26 UTC"
  },
  {
    "arxiv_id": "2501.08002v2",
    "title": "Maximizing Uncertainty for Federated learning via Bayesian Optimisation-based Model Poisoning",
    "authors": [
      "Marios Aristodemou",
      "Xiaolan Liu",
      "Yuan Wang",
      "Konstantinos G. Kyriakopoulos",
      "Sangarapillai Lambotharan",
      "Qingsong Wei"
    ],
    "abstract": "As we transition from Narrow Artificial Intelligence towards Artificial Super\nIntelligence, users are increasingly concerned about their privacy and the\ntrustworthiness of machine learning (ML) technology. A common denominator for\nthe metrics of trustworthiness is the quantification of uncertainty inherent in\nDL algorithms, and specifically in the model parameters, input data, and model\npredictions. One of the common approaches to address privacy-related issues in\nDL is to adopt distributed learning such as federated learning (FL), where\nprivate raw data is not shared among users. Despite the privacy-preserving\nmechanisms in FL, it still faces challenges in trustworthiness. Specifically,\nthe malicious users, during training, can systematically create malicious model\nparameters to compromise the models predictive and generative capabilities,\nresulting in high uncertainty about their reliability. To demonstrate malicious\nbehaviour, we propose a novel model poisoning attack method named Delphi which\naims to maximise the uncertainty of the global model output. We achieve this by\ntaking advantage of the relationship between the uncertainty and the model\nparameters of the first hidden layer of the local model. Delphi employs two\ntypes of optimisation , Bayesian Optimisation and Least Squares Trust Region,\nto search for the optimal poisoned model parameters, named as Delphi-BO and\nDelphi-LSTR. We quantify the uncertainty using the KL Divergence to minimise\nthe distance of the predictive probability distribution towards an uncertain\ndistribution of model output. Furthermore, we establish a mathematical proof\nfor the attack effectiveness demonstrated in FL. Numerical results demonstrate\nthat Delphi-BO induces a higher amount of uncertainty than Delphi-LSTR\nhighlighting vulnerability of FL systems to model poisoning attacks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.08002v2",
    "published_date": "2025-01-14 10:46:41 UTC",
    "updated_date": "2025-01-15 11:52:29 UTC"
  },
  {
    "arxiv_id": "2501.08001v1",
    "title": "GDiffRetro: Retrosynthesis Prediction with Dual Graph Enhanced Molecular Representation and Diffusion Generation",
    "authors": [
      "Shengyin Sun",
      "Wenhao Yu",
      "Yuxiang Ren",
      "Weitao Du",
      "Liwei Liu",
      "Xuecang Zhang",
      "Ying Hu",
      "Chen Ma"
    ],
    "abstract": "Retrosynthesis prediction focuses on identifying reactants capable of\nsynthesizing a target product. Typically, the retrosynthesis prediction\ninvolves two phases: Reaction Center Identification and Reactant Generation.\nHowever, we argue that most existing methods suffer from two limitations in the\ntwo phases: (i) Existing models do not adequately capture the ``face''\ninformation in molecular graphs for the reaction center identification. (ii)\nCurrent approaches for the reactant generation predominantly use sequence\ngeneration in a 2D space, which lacks versatility in generating reasonable\ndistributions for completed reactive groups and overlooks molecules' inherent\n3D properties. To overcome the above limitations, we propose GDiffRetro. For\nthe reaction center identification, GDiffRetro uniquely integrates the original\ngraph with its corresponding dual graph to represent molecular structures,\nwhich helps guide the model to focus more on the faces in the graph. For the\nreactant generation, GDiffRetro employs a conditional diffusion model in 3D to\nfurther transform the obtained synthon into a complete reactant. Our\nexperimental findings reveal that GDiffRetro outperforms state-of-the-art\nsemi-template models across various evaluative metrics.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.08001v1",
    "published_date": "2025-01-14 10:44:38 UTC",
    "updated_date": "2025-01-14 10:44:38 UTC"
  },
  {
    "arxiv_id": "2501.07992v1",
    "title": "LLM-Ehnanced Holonic Architecture for Ad-Hoc Scalable SoS",
    "authors": [
      "Muhammad Ashfaq",
      "Ahmed R. Sadik",
      "Tommi Mikkonen",
      "Muhammad Waseem",
      "Niko Mäkitalo"
    ],
    "abstract": "As modern system of systems (SoS) become increasingly adaptive and human\ncentred, traditional architectures often struggle to support interoperability,\nreconfigurability, and effective human system interaction. This paper addresses\nthese challenges by advancing the state of the art holonic architecture for\nSoS, offering two main contributions to support these adaptive needs. First, we\npropose a layered architecture for holons, which includes reasoning,\ncommunication, and capabilities layers. This design facilitates seamless\ninteroperability among heterogeneous constituent systems by improving data\nexchange and integration. Second, inspired by principles of intelligent\nmanufacturing, we introduce specialised holons namely, supervisor, planner,\ntask, and resource holons aimed at enhancing the adaptability and\nreconfigurability of SoS. These specialised holons utilise large language\nmodels within their reasoning layers to support decision making and ensure real\ntime adaptability. We demonstrate our approach through a 3D mobility case study\nfocused on smart city transportation, showcasing its potential for managing\ncomplex, multimodal SoS environments. Additionally, we propose evaluation\nmethods to assess the architecture efficiency and scalability,laying the\ngroundwork for future empirical validations through simulations and real world\nimplementations.",
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07992v1",
    "published_date": "2025-01-14 10:35:54 UTC",
    "updated_date": "2025-01-14 10:35:54 UTC"
  },
  {
    "arxiv_id": "2501.07991v1",
    "title": "Training Hybrid Neural Networks with Multimode Optical Nonlinearities Using Digital Twins",
    "authors": [
      "Ilker Oguz",
      "Louis J. E. Suter",
      "Jih-Liang Hsieh",
      "Mustafa Yildirim",
      "Niyazi Ulas Dinc",
      "Christophe Moser",
      "Demetri Psaltis"
    ],
    "abstract": "The ability to train ever-larger neural networks brings artificial\nintelligence to the forefront of scientific and technical discoveries. However,\ntheir exponentially increasing size creates a proportionally greater demand for\nenergy and computational hardware. Incorporating complex physical events in\nnetworks as fixed, efficient computation modules can address this demand by\ndecreasing the complexity of trainable layers. Here, we utilize ultrashort\npulse propagation in multimode fibers, which perform large-scale nonlinear\ntransformations, for this purpose. Training the hybrid architecture is achieved\nthrough a neural model that differentiably approximates the optical system. The\ntraining algorithm updates the neural simulator and backpropagates the error\nsignal over this proxy to optimize layers preceding the optical one. Our\nexperimental results achieve state-of-the-art image classification accuracies\nand simulation fidelity. Moreover, the framework demonstrates exceptional\nresilience to experimental drifts. By integrating low-energy physical systems\ninto neural networks, this approach enables scalable, energy-efficient AI\nmodels with significantly reduced computational demands.",
    "categories": [
      "physics.optics",
      "cs.AI"
    ],
    "primary_category": "physics.optics",
    "comment": "17 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.07991v1",
    "published_date": "2025-01-14 10:35:18 UTC",
    "updated_date": "2025-01-14 10:35:18 UTC"
  },
  {
    "arxiv_id": "2501.07988v1",
    "title": "GAC-Net_Geometric and attention-based Network for Depth Completion",
    "authors": [
      "Kuang Zhu",
      "Xingli Gan",
      "Min Sun"
    ],
    "abstract": "Depth completion is a key task in autonomous driving, aiming to complete\nsparse LiDAR depth measurements into high-quality dense depth maps through\nimage guidance. However, existing methods usually treat depth maps as an\nadditional channel of color images, or directly perform convolution on sparse\ndata, failing to fully exploit the 3D geometric information in depth maps,\nespecially with limited performance in complex boundaries and sparse areas. To\naddress these issues, this paper proposes a depth completion network combining\nchannel attention mechanism and 3D global feature perception (CGA-Net). The\nmain innovations include: 1) Utilizing PointNet++ to extract global 3D\ngeometric features from sparse depth maps, enhancing the scene perception\nability of low-line LiDAR data; 2) Designing a channel-attention-based\nmultimodal feature fusion module to efficiently integrate sparse depth, RGB\nimages, and 3D geometric features; 3) Combining residual learning with CSPN++\nto optimize the depth refinement stage, further improving the completion\nquality in edge areas and complex scenes. Experiments on the KITTI depth\ncompletion dataset show that CGA-Net can significantly improve the prediction\naccuracy of dense depth maps, achieving a new state-of-the-art (SOTA), and\ndemonstrating strong robustness to sparse and complex scenes.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13pages,4 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.07988v1",
    "published_date": "2025-01-14 10:24:20 UTC",
    "updated_date": "2025-01-14 10:24:20 UTC"
  },
  {
    "arxiv_id": "2501.07978v1",
    "title": "Facial Dynamics in Video: Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness",
    "authors": [
      "Jiaxing Zhao",
      "Boyuan Sun",
      "Xiang Chen",
      "Xihan Wei"
    ],
    "abstract": "Facial expression captioning has found widespread application across various\ndomains. Recently, the emergence of video Multimodal Large Language Models\n(MLLMs) has shown promise in general video understanding tasks. However,\ndescribing facial expressions within videos poses two major challenges for\nthese models: (1) the lack of adequate datasets and benchmarks, and (2) the\nlimited visual token capacity of video MLLMs. To address these issues, this\npaper introduces a new instruction-following dataset tailored for dynamic\nfacial expression caption. The dataset comprises 5,033 high-quality video clips\nannotated manually, containing over 700,000 tokens. Its purpose is to improve\nthe capability of video MLLMs to discern subtle facial nuances. Furthermore, we\npropose FaceTrack-MM, which leverages a limited number of tokens to encode the\nmain character's face. This model demonstrates superior performance in tracking\nfaces and focusing on the facial expressions of the main characters, even in\nintricate multi-person scenarios. Additionally, we introduce a novel evaluation\nmetric combining event extraction, relation classification, and the longest\ncommon subsequence (LCS) algorithm to assess the content consistency and\ntemporal sequence consistency of generated text. Moreover, we present\nFEC-Bench, a benchmark designed to assess the performance of existing video\nMLLMs in this specific task. All data and source code will be made publicly\navailable.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07978v1",
    "published_date": "2025-01-14 09:52:56 UTC",
    "updated_date": "2025-01-14 09:52:56 UTC"
  },
  {
    "arxiv_id": "2501.07970v1",
    "title": "Comprehensive Metapath-based Heterogeneous Graph Transformer for Gene-Disease Association Prediction",
    "authors": [
      "Wentao Cui",
      "Shoubo Li",
      "Chen Fang",
      "Qingqing Long",
      "Chengrui Wang",
      "Xuezhi Wang",
      "Yuanchun Zhou"
    ],
    "abstract": "Discovering gene-disease associations is crucial for understanding disease\nmechanisms, yet identifying these associations remains challenging due to the\ntime and cost of biological experiments. Computational methods are increasingly\nvital for efficient and scalable gene-disease association prediction.\nGraph-based learning models, which leverage node features and network\nrelationships, are commonly employed for biomolecular predictions. However,\nexisting methods often struggle to effectively integrate node features,\nheterogeneous structures, and semantic information. To address these\nchallenges, we propose COmprehensive MEtapath-based heterogeneous graph\nTransformer(COMET) for predicting gene-disease associations. COMET integrates\ndiverse datasets to construct comprehensive heterogeneous networks,\ninitializing node features with BioGPT. We define seven Metapaths and utilize a\ntransformer framework to aggregate Metapath instances, capturing global\ncontexts and long-distance dependencies. Through intra- and inter-metapath\naggregation using attention mechanisms, COMET fuses latent vectors from\nmultiple Metapaths to enhance GDA prediction accuracy. Our method demonstrates\nsuperior robustness compared to state-of-the-art approaches. Ablation studies\nand visualizations validate COMET's effectiveness, providing valuable insights\nfor advancing human health research.",
    "categories": [
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07970v1",
    "published_date": "2025-01-14 09:41:18 UTC",
    "updated_date": "2025-01-14 09:41:18 UTC"
  },
  {
    "arxiv_id": "2501.07964v3",
    "title": "Derivation of Output Correlation Inferences for Multi-Output (aka Multi-Task) Gaussian Process",
    "authors": [
      "Shuhei Watanabe"
    ],
    "abstract": "Gaussian process (GP) is arguably one of the most widely used machine\nlearning algorithms in practice. One of its prominent applications is Bayesian\noptimization (BO). Although the vanilla GP itself is already a powerful tool\nfor BO, it is often beneficial to be able to consider the dependencies of\nmultiple outputs. To do so, Multi-task GP (MTGP) is formulated, but it is not\ntrivial to fully understand the derivations of its formulations and their\ngradients from the previous literature. This paper serves friendly derivations\nof the MTGP formulations and their gradients.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07964v3",
    "published_date": "2025-01-14 09:35:49 UTC",
    "updated_date": "2025-03-12 06:12:01 UTC"
  },
  {
    "arxiv_id": "2501.07959v2",
    "title": "Self-Instruct Few-Shot Jailbreaking: Decompose the Attack into Pattern and Behavior Learning",
    "authors": [
      "Jiaqi Hua",
      "Wanxu Wei"
    ],
    "abstract": "Recently, several works have been conducted on jailbreaking Large Language\nModels (LLMs) with few-shot malicious demos. In particular, Zheng et al. focus\non improving the efficiency of Few-Shot Jailbreaking (FSJ) by injecting special\ntokens into the demos and employing demo-level random search, known as Improved\nFew-Shot Jailbreaking (I-FSJ). Nevertheless, we notice that this method may\nstill require a long context to jailbreak advanced models e.g. 32 shots of\ndemos for Meta-Llama-3-8B-Instruct (Llama-3) \\cite{llama3modelcard}. In this\npaper, we discuss the limitations of I-FSJ and propose Self-Instruct Few-Shot\nJailbreaking (Self-Instruct-FSJ) facilitated with the demo-level greedy search.\nThis framework decomposes the FSJ attack into pattern and behavior learning to\nexploit the model's vulnerabilities in a more generalized and efficient way. We\nconduct elaborate experiments to evaluate our method on common open-source\nmodels and compare it with baseline algorithms. Our code is available at\nhttps://github.com/iphosi/Self-Instruct-FSJ.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07959v2",
    "published_date": "2025-01-14 09:23:30 UTC",
    "updated_date": "2025-02-01 09:30:34 UTC"
  },
  {
    "arxiv_id": "2501.07957v2",
    "title": "AI Guide Dog: Egocentric Path Prediction on Smartphone",
    "authors": [
      "Aishwarya Jadhav",
      "Jeffery Cao",
      "Abhishree Shetty",
      "Urvashi Priyam Kumar",
      "Aditi Sharma",
      "Ben Sukboontip",
      "Jayant Sravan Tamarapalli",
      "Jingyi Zhang",
      "Anirudh Koul"
    ],
    "abstract": "This paper presents AI Guide Dog (AIGD), a lightweight egocentric\n(first-person) navigation system for visually impaired users, designed for\nreal-time deployment on smartphones. AIGD employs a vision-only multi-label\nclassification approach to predict directional commands, ensuring safe\nnavigation across diverse environments. We introduce a novel technique for\ngoal-based outdoor navigation by integrating GPS signals and high-level\ndirections, while also handling uncertain multi-path predictions for\ndestination-free indoor navigation. As the first navigation assistance system\nto handle both goal-oriented and exploratory navigation across indoor and\noutdoor settings, AIGD establishes a new benchmark in blind navigation. We\npresent methods, datasets, evaluations, and deployment insights to encourage\nfurther innovations in assistive navigation systems.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at the AAAI 2025 Spring Symposium on Human-Compatible AI for\n  Well-being: Harnessing Potential of GenAI for AI-Powered Science",
    "pdf_url": "http://arxiv.org/pdf/2501.07957v2",
    "published_date": "2025-01-14 09:21:17 UTC",
    "updated_date": "2025-02-17 00:40:03 UTC"
  },
  {
    "arxiv_id": "2501.07945v1",
    "title": "Early prediction of the transferability of bovine embryos from videomicroscopy",
    "authors": [
      "Yasmine Hachani",
      "Patrick Bouthemy",
      "Elisa Fromont",
      "Sylvie Ruffini",
      "Ludivine Laffont",
      "Alline de Paula Reis"
    ],
    "abstract": "Videomicroscopy is a promising tool combined with machine learning for\nstudying the early development of in vitro fertilized bovine embryos and\nassessing its transferability as soon as possible. We aim to predict the embryo\ntransferability within four days at most, taking 2D time-lapse microscopy\nvideos as input. We formulate this problem as a supervised binary\nclassification problem for the classes transferable and not transferable. The\nchallenges are three-fold: 1) poorly discriminating appearance and motion, 2)\nclass ambiguity, 3) small amount of annotated data. We propose a 3D\nconvolutional neural network involving three pathways, which makes it\nmulti-scale in time and able to handle appearance and motion in different ways.\nFor training, we retain the focal loss. Our model, named SFR, compares\nfavorably to other methods. Experiments demonstrate its effectiveness and\naccuracy for our challenging biological task.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "q-bio.QM"
    ],
    "primary_category": "eess.IV",
    "comment": "Accepted at the 2024 IEEE International Conference on Image\n  Processing",
    "pdf_url": "http://arxiv.org/pdf/2501.07945v1",
    "published_date": "2025-01-14 08:56:59 UTC",
    "updated_date": "2025-01-14 08:56:59 UTC"
  },
  {
    "arxiv_id": "2501.07931v1",
    "title": "Advice for Diabetes Self-Management by ChatGPT Models: Challenges and Recommendations",
    "authors": [
      "Waqar Hussain",
      "John Grundy"
    ],
    "abstract": "Given their ability for advanced reasoning, extensive contextual\nunderstanding, and robust question-answering abilities, large language models\nhave become prominent in healthcare management research. Despite adeptly\nhandling a broad spectrum of healthcare inquiries, these models face\nsignificant challenges in delivering accurate and practical advice for chronic\nconditions such as diabetes. We evaluate the responses of ChatGPT versions 3.5\nand 4 to diabetes patient queries, assessing their depth of medical knowledge\nand their capacity to deliver personalized, context-specific advice for\ndiabetes self-management. Our findings reveal discrepancies in accuracy and\nembedded biases, emphasizing the models' limitations in providing tailored\nadvice unless activated by sophisticated prompting techniques. Additionally, we\nobserve that both models often provide advice without seeking necessary\nclarification, a practice that can result in potentially dangerous advice. This\nunderscores the limited practical effectiveness of these models without human\noversight in clinical settings. To address these issues, we propose a\ncommonsense evaluation layer for prompt evaluation and incorporating\ndisease-specific external memory using an advanced Retrieval Augmented\nGeneration technique. This approach aims to improve information quality and\nreduce misinformation risks, contributing to more reliable AI applications in\nhealthcare settings. Our findings seek to influence the future direction of AI\nin healthcare, enhancing both the scope and quality of its integration.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07931v1",
    "published_date": "2025-01-14 08:32:16 UTC",
    "updated_date": "2025-01-14 08:32:16 UTC"
  },
  {
    "arxiv_id": "2501.07930v2",
    "title": "An Adaptive Orthogonal Convolution Scheme for Efficient and Flexible CNN Architectures",
    "authors": [
      "Thibaut Boissin",
      "Franck Mamalet",
      "Thomas Fel",
      "Agustin Martin Picard",
      "Thomas Massena",
      "Mathieu Serrurier"
    ],
    "abstract": "Orthogonal convolutional layers are the workhorse of multiple areas in\nmachine learning, such as adversarial robustness, normalizing flows, GANs, and\nLipschitzconstrained models. Their ability to preserve norms and ensure stable\ngradient propagation makes them valuable for a large range of problems. Despite\ntheir promise, the deployment of orthogonal convolution in large-scale\napplications is a significant challenge due to computational overhead and\nlimited support for modern features like strides, dilations, group\nconvolutions, and transposed convolutions.In this paper, we introduce AOC\n(Adaptative Orthogonal Convolution), a scalable method for constructing\northogonal convolutions, effectively overcoming these limitations. This\nadvancement unlocks the construction of architectures that were previously\nconsidered impractical. We demonstrate through our experiments that our method\nproduces expressive models that become increasingly efficient as they scale. To\nfoster further advancement, we provide an open-source library implementing this\nmethod, available at https://github.com/thib-s/orthogonium.",
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07930v2",
    "published_date": "2025-01-14 08:32:12 UTC",
    "updated_date": "2025-03-20 08:31:58 UTC"
  },
  {
    "arxiv_id": "2501.07927v2",
    "title": "Gandalf the Red: Adaptive Security for LLMs",
    "authors": [
      "Niklas Pfister",
      "Václav Volhejn",
      "Manuel Knott",
      "Santiago Arias",
      "Julia Bazińska",
      "Mykhailo Bichurin",
      "Alan Commike",
      "Janet Darling",
      "Peter Dienes",
      "Matthew Fiedler",
      "David Haber",
      "Matthias Kraft",
      "Marco Lancini",
      "Max Mathys",
      "Damián Pascual-Ortiz",
      "Jakub Podolak",
      "Adrià Romero-López",
      "Kyriacos Shiarlis",
      "Andreas Signer",
      "Zsolt Terek",
      "Athanasios Theocharis",
      "Daniel Timbrell",
      "Samuel Trautwein",
      "Samuel Watts",
      "Yun-Han Wu",
      "Mateo Rojas-Carulla"
    ],
    "abstract": "Current evaluations of defenses against prompt attacks in large language\nmodel (LLM) applications often overlook two critical factors: the dynamic\nnature of adversarial behavior and the usability penalties imposed on\nlegitimate users by restrictive defenses. We propose D-SEC (Dynamic Security\nUtility Threat Model), which explicitly separates attackers from legitimate\nusers, models multi-step interactions, and expresses the security-utility in an\noptimizable form. We further address the shortcomings in existing evaluations\nby introducing Gandalf, a crowd-sourced, gamified red-teaming platform designed\nto generate realistic, adaptive attack. Using Gandalf, we collect and release a\ndataset of 279k prompt attacks. Complemented by benign user data, our analysis\nreveals the interplay between security and utility, showing that defenses\nintegrated in the LLM (e.g., system prompts) can degrade usability even without\nblocking requests. We demonstrate that restricted application domains,\ndefense-in-depth, and adaptive defenses are effective strategies for building\nsecure and useful LLM applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Niklas Pfister, V\\'aclav Volhejn and Manuel Knott contributed equally",
    "pdf_url": "http://arxiv.org/pdf/2501.07927v2",
    "published_date": "2025-01-14 08:30:49 UTC",
    "updated_date": "2025-02-02 11:30:27 UTC"
  },
  {
    "arxiv_id": "2501.07924v1",
    "title": "Exploring Aviation Incident Narratives Using Topic Modeling and Clustering Techniques",
    "authors": [
      "Aziida Nanyonga",
      "Hassan Wasswa",
      "Ugur Turhan",
      "Keith Joiner",
      "Graham Wild"
    ],
    "abstract": "Aviation safety is a global concern, requiring detailed investigations into\nincidents to understand contributing factors comprehensively. This study uses\nthe National Transportation Safety Board (NTSB) dataset. It applies advanced\nnatural language processing (NLP) techniques, including Latent Dirichlet\nAllocation (LDA), Non-Negative Matrix Factorization (NMF), Latent Semantic\nAnalysis (LSA), Probabilistic Latent Semantic Analysis (pLSA), and K-means\nclustering. The main objectives are identifying latent themes, exploring\nsemantic relationships, assessing probabilistic connections, and cluster\nincidents based on shared characteristics. This research contributes to\naviation safety by providing insights into incident narratives and\ndemonstrating the versatility of NLP and topic modelling techniques in\nextracting valuable information from complex datasets. The results, including\ntopics identified from various techniques, provide an understanding of\nrecurring themes. Comparative analysis reveals that LDA performed best with a\ncoherence value of 0.597, pLSA of 0.583, LSA of 0.542, and NMF of 0.437.\nK-means clustering further reveals commonalities and unique insights into\nincident narratives. In conclusion, this study uncovers latent patterns and\nthematic structures within incident narratives, offering a comparative analysis\nof multiple-topic modelling techniques. Future research avenues include\nexploring temporal patterns, incorporating additional datasets, and developing\npredictive models for early identification of safety issues. This research lays\nthe groundwork for enhancing the understanding and improvement of aviation\nsafety by utilising the wealth of information embedded in incident narratives.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "Topic Modelling, narratives, clustering, Aviation Incidents, NTSB"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07924v1",
    "published_date": "2025-01-14 08:23:15 UTC",
    "updated_date": "2025-01-14 08:23:15 UTC"
  },
  {
    "arxiv_id": "2501.07919v1",
    "title": "Large Language Model Interface for Home Energy Management Systems",
    "authors": [
      "François Michelon",
      "Yihong Zhou",
      "Thomas Morstyn"
    ],
    "abstract": "Home Energy Management Systems (HEMSs) help households tailor their\nelectricity usage based on power system signals such as energy prices. This\ntechnology helps to reduce energy bills and offers greater demand-side\nflexibility that supports the power system stability. However, residents who\nlack a technical background may find it difficult to use HEMSs effectively,\nbecause HEMSs require well-formatted parameterization that reflects the\ncharacteristics of the energy resources, houses, and users' needs. Recently,\nLarge-Language Models (LLMs) have demonstrated an outstanding ability in\nlanguage understanding. Motivated by this, we propose an LLM-based interface\nthat interacts with users to understand and parameterize their\n``badly-formatted answers'', and then outputs well-formatted parameters to\nimplement an HEMS. We further use Reason and Act method (ReAct) and few-shot\nprompting to enhance the LLM performance. Evaluating the interface performance\nrequires multiple user--LLM interactions. To avoid the efforts in finding\nvolunteer users and reduce the evaluation time, we additionally propose a\nmethod that uses another LLM to simulate users with varying expertise, ranging\nfrom knowledgeable to non-technical. By comprehensive evaluation, the proposed\nLLM-based HEMS interface achieves an average parameter retrieval accuracy of\n88\\%, outperforming benchmark models without ReAct and/or few-shot prompting.",
    "categories": [
      "cs.AI",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages conference paper",
    "pdf_url": "http://arxiv.org/pdf/2501.07919v1",
    "published_date": "2025-01-14 08:10:43 UTC",
    "updated_date": "2025-01-14 08:10:43 UTC"
  },
  {
    "arxiv_id": "2501.07913v2",
    "title": "Governing AI Agents",
    "authors": [
      "Noam Kolt"
    ],
    "abstract": "The field of AI is undergoing a fundamental transition from generative models\nthat can produce synthetic content to artificial agents that can plan and\nexecute complex tasks with only limited human involvement. Companies that\npioneered the development of language models have now built AI agents that can\nindependently navigate the internet, perform a wide range of online tasks, and\nincreasingly serve as AI personal assistants and virtual coworkers. The\nopportunities presented by this new technology are tremendous, as are the\nassociated risks. Fortunately, there exist robust analytic frameworks for\nconfronting many of these challenges, namely, the economic theory of\nprincipal-agent problems and the common law doctrine of agency relationships.\nDrawing on these frameworks, this Article makes three contributions. First, it\nuses agency law and theory to identify and characterize problems arising from\nAI agents, including issues of information asymmetry, discretionary authority,\nand loyalty. Second, it illustrates the limitations of conventional solutions\nto agency problems: incentive design, monitoring, and enforcement might not be\neffective for governing AI agents that make uninterpretable decisions and\noperate at unprecedented speed and scale. Third, the Article explores the\nimplications of agency law and theory for designing and regulating AI agents,\narguing that new technical and legal infrastructure is needed to support\ngovernance principles of inclusivity, visibility, and liability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Notre Dame Law Review, Vol. 101, Forthcoming",
    "pdf_url": "http://arxiv.org/pdf/2501.07913v2",
    "published_date": "2025-01-14 07:55:18 UTC",
    "updated_date": "2025-02-11 14:30:44 UTC"
  },
  {
    "arxiv_id": "2501.07911v1",
    "title": "Deep Learning and Natural Language Processing in the Field of Construction",
    "authors": [
      "Rémy Kessler",
      "Nicolas Béchet"
    ],
    "abstract": "This article presents a complete process to extract hypernym relationships in\nthe field of construction using two main steps: terminology extraction and\ndetection of hypernyms from these terms. We first describe the corpus analysis\nmethod to extract terminology from a collection of technical specifications in\nthe field of construction. Using statistics and word n-grams analysis, we\nextract the domain's terminology and then perform pruning steps with linguistic\npatterns and internet queries to improve the quality of the final terminology.\nSecond, we present a machine-learning approach based on various words embedding\nmodels and combinations to deal with the detection of hypernyms from the\nextracted terminology. Extracted terminology is evaluated using a manual\nevaluation carried out by 6 experts in the domain, and the hypernym\nidentification method is evaluated with different datasets. The global approach\nprovides relevant and promising results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07911v1",
    "published_date": "2025-01-14 07:53:44 UTC",
    "updated_date": "2025-01-14 07:53:44 UTC"
  },
  {
    "arxiv_id": "2501.07905v1",
    "title": "Logarithmic Memory Networks (LMNs): Efficient Long-Range Sequence Modeling for Resource-Constrained Environments",
    "authors": [
      "Mohamed A. Taha"
    ],
    "abstract": "Long-range sequence modeling is a crucial aspect of natural language\nprocessing and time series analysis. However, traditional models like Recurrent\nNeural Networks (RNNs) and Transformers suffer from computational and memory\ninefficiencies, especially when dealing with long sequences. This paper\nintroduces Logarithmic Memory Networks (LMNs), a novel architecture that\nleverages a hierarchical logarithmic tree structure to efficiently store and\nretrieve past information. LMNs dynamically summarize historical context,\nsignificantly reducing the memory footprint and computational complexity of\nattention mechanisms from O(n2) to O(log(n)). The model employs a\nsingle-vector, targeted attention mechanism to access stored information, and\nthe memory block construction worker (summarizer) layer operates in two modes:\na parallel execution mode during training for efficient processing of\nhierarchical tree structures and a sequential execution mode during inference,\nwhich acts as a memory management system. It also implicitly encodes positional\ninformation, eliminating the need for explicit positional encodings. These\nfeatures make LMNs a robust and scalable solution for processing long-range\nsequences in resource-constrained environments, offering practical improvements\nin efficiency and scalability. The code is publicly available under the MIT\nLicense on GitHub: https://github.com/AhmedBoin/LogarithmicMemory.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.07905v1",
    "published_date": "2025-01-14 07:50:09 UTC",
    "updated_date": "2025-01-14 07:50:09 UTC"
  },
  {
    "arxiv_id": "2501.07903v1",
    "title": "Optimal Classification Trees for Continuous Feature Data Using Dynamic Programming with Branch-and-Bound",
    "authors": [
      "Catalin E. Brita",
      "Jacobus G. M. van der Linden",
      "Emir Demirović"
    ],
    "abstract": "Computing an optimal classification tree that provably maximizes training\nperformance within a given size limit, is NP-hard, and in practice, most\nstate-of-the-art methods do not scale beyond computing optimal trees of depth\nthree. Therefore, most methods rely on a coarse binarization of continuous\nfeatures to maintain scalability. We propose a novel algorithm that optimizes\ntrees directly on the continuous feature data using dynamic programming with\nbranch-and-bound. We develop new pruning techniques that eliminate many\nsub-optimal splits in the search when similar to previously computed splits and\nwe provide an efficient subroutine for computing optimal depth-two trees. Our\nexperiments demonstrate that these techniques improve runtime by one or more\norders of magnitude over state-of-the-art optimal methods and improve test\naccuracy by 5% over greedy heuristics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "In the proceedings of AAAI-25",
    "pdf_url": "http://arxiv.org/pdf/2501.07903v1",
    "published_date": "2025-01-14 07:46:33 UTC",
    "updated_date": "2025-01-14 07:46:33 UTC"
  },
  {
    "arxiv_id": "2501.07896v1",
    "title": "Anytime Cooperative Implicit Hitting Set Solving",
    "authors": [
      "Emma Rollón",
      "Javier Larrosa",
      "Aleksandra Petrova"
    ],
    "abstract": "The Implicit Hitting Set (HS) approach has shown to be very effective for\nMaxSAT, Pseudo-boolean optimization and other boolean frameworks. Very\nrecently, it has also shown its potential in the very similar Weighted CSP\nframework by means of the so-called cost-function merging. The original\nformulation of the HS approach focuses on obtaining increasingly better lower\nbounds (HS-lb). However, and as shown for Pseudo-Boolean Optimization, this\napproach can also be adapted to compute increasingly better upper bounds\n(HS-ub). In this paper we consider both HS approaches and show how they can be\neasily combined in a multithread architecture where cores discovered by either\ncomponent are available by the other which, interestingly, generates synergy\nbetween them. We show that the resulting algorithm (HS-lub) is consistently\nsuperior to either HS-lb and HS-ub in isolation. Most importantly, HS-lub has\nan effective anytime behaviour with which the optimality gap is reduced during\nthe execution. We tested our approach on the Weighted CSP framework and show on\nthree different benchmarks that our very simple implementation sometimes\noutperforms the parallel hybrid best-first search implementation of the far\nmore developed state-of-the-art Toulbar2.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07896v1",
    "published_date": "2025-01-14 07:23:52 UTC",
    "updated_date": "2025-01-14 07:23:52 UTC"
  },
  {
    "arxiv_id": "2501.07892v1",
    "title": "Leveraging Metamemory Mechanisms for Enhanced Data-Free Code Generation in LLMs",
    "authors": [
      "Shuai Wang",
      "Liang Ding",
      "Yibing Zhan",
      "Yong Luo",
      "Zheng He",
      "Dapeng Tao"
    ],
    "abstract": "Automated code generation using large language models (LLMs) has gained\nattention due to its efficiency and adaptability. However, real-world coding\ntasks or benchmarks like HumanEval and StudentEval often lack dedicated\ntraining datasets, challenging existing few-shot prompting approaches that rely\non reference examples. Inspired by human metamemory-a cognitive process\ninvolving recall and evaluation-we present a novel framework (namely M^2WF) for\nimproving LLMs' one-time code generation. This approach enables LLMs to\nautonomously generate, evaluate, and utilize synthetic examples to enhance\nreliability and performance. Unlike prior methods, it minimizes dependency on\ncurated data and adapts flexibly to various coding scenarios. Our experiments\ndemonstrate significant improvements in coding benchmarks, offering a scalable\nand robust solution for data-free environments. The code and framework will be\npublicly available on GitHub and HuggingFace.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages,6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.07892v1",
    "published_date": "2025-01-14 07:16:43 UTC",
    "updated_date": "2025-01-14 07:16:43 UTC"
  },
  {
    "arxiv_id": "2501.07890v2",
    "title": "GRAPHMOE: Amplifying Cognitive Depth of Mixture-of-Experts Network via Introducing Self-Rethinking Mechanism",
    "authors": [
      "Chen Tang",
      "Bo Lv",
      "Zifan Zheng",
      "Bohao Yang",
      "Kun Zhao",
      "Ning Liao",
      "Xiaoxing Wang",
      "Feiyu Xiong",
      "Zhiyu Li",
      "Nayu Liu",
      "Jingchi Jiang"
    ],
    "abstract": "Traditional Mixture-of-Experts (MoE) networks benefit from utilizing multiple\nsmaller expert models as opposed to a single large network. However, these\nexperts typically operate independently, leaving a question open about whether\ninterconnecting these models could enhance the performance of MoE networks. In\nresponse, we introduce GRAPHMOE, a novel method aimed at augmenting the\ncognitive depth of language models via a self-rethinking mechanism constructed\non Pseudo GraphMoE networks. GRAPHMOE employs a recurrent routing strategy to\nsimulate iterative thinking steps, thereby facilitating the flow of information\namong expert nodes. We implement the GRAPHMOE architecture using Low-Rank\nAdaptation techniques (LoRA) and conduct extensive experiments on various\nbenchmark datasets. The experimental results reveal that GRAPHMOE outperforms\nother LoRA based models, achieving state-of-the-art (SOTA) performance.\nAdditionally, this study explores a novel recurrent routing strategy that may\ninspire further advancements in enhancing the reasoning capabilities of\nlanguage models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07890v2",
    "published_date": "2025-01-14 06:59:51 UTC",
    "updated_date": "2025-02-11 06:47:01 UTC"
  },
  {
    "arxiv_id": "2501.07888v3",
    "title": "Tarsier2: Advancing Large Vision-Language Models from Detailed Video Description to Comprehensive Video Understanding",
    "authors": [
      "Liping Yuan",
      "Jiawei Wang",
      "Haomiao Sun",
      "Yuchen Zhang",
      "Yuan Lin"
    ],
    "abstract": "We introduce Tarsier2, a state-of-the-art large vision-language model (LVLM)\ndesigned for generating detailed and accurate video descriptions, while also\nexhibiting superior general video understanding capabilities. Tarsier2 achieves\nsignificant advancements through three key upgrades: (1) Scaling pre-training\ndata from 11M to 40M video-text pairs, enriching both volume and diversity; (2)\nPerforming fine-grained temporal alignment during supervised fine-tuning; (3)\nUsing model-based sampling to automatically construct preference data and\napplying DPO training for optimization. Extensive experiments show that\nTarsier2-7B consistently outperforms leading proprietary models, including\nGPT-4o and Gemini 1.5 Pro, in detailed video description tasks. On the DREAM-1K\nbenchmark, Tarsier2-7B improves F1 by 2.8% over GPT-4o and 5.8% over\nGemini-1.5-Pro. In human side-by-side evaluations, Tarsier2-7B shows a +8.6%\nperformance advantage over GPT-4o and +24.9% over Gemini-1.5-Pro. Tarsier2-7B\nalso sets new state-of-the-art results across 15 public benchmarks, spanning\ntasks such as video question-answering, video grounding, hallucination test,\nand embodied question-answering, demonstrating its versatility as a robust\ngeneralist vision-language model.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07888v3",
    "published_date": "2025-01-14 06:54:39 UTC",
    "updated_date": "2025-01-24 05:16:36 UTC"
  },
  {
    "arxiv_id": "2501.07886v1",
    "title": "Iterative Label Refinement Matters More than Preference Optimization under Weak Supervision",
    "authors": [
      "Yaowen Ye",
      "Cassidy Laidlaw",
      "Jacob Steinhardt"
    ],
    "abstract": "Language model (LM) post-training relies on two stages of human supervision:\ntask demonstrations for supervised finetuning (SFT), followed by preference\ncomparisons for reinforcement learning from human feedback (RLHF). As LMs\nbecome more capable, the tasks they are given become harder to supervise. Will\npost-training remain effective under unreliable supervision? To test this, we\nsimulate unreliable demonstrations and comparison feedback using small LMs and\ntime-constrained humans. We find that in the presence of unreliable\nsupervision, SFT still retains some effectiveness, but DPO (a common RLHF\nalgorithm) fails to improve the model beyond SFT. To address this, we propose\niterative label refinement (ILR) as an alternative to RLHF. ILR improves the\nSFT data by using comparison feedback to decide whether human demonstrations\nshould be replaced by model-generated alternatives, then retrains the model via\nSFT on the updated data. SFT+ILR outperforms SFT+DPO on several tasks with\nunreliable supervision (math, coding, and safe instruction-following). Our\nfindings suggest that as LMs are used for complex tasks where human supervision\nis unreliable, RLHF may no longer be the best use of human comparison feedback;\ninstead, it is better to direct feedback towards improving the training data\nrather than continually training the model. Our code and data are available at\nhttps://github.com/helloelwin/iterative-label-refinement.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "22 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.07886v1",
    "published_date": "2025-01-14 06:54:17 UTC",
    "updated_date": "2025-01-14 06:54:17 UTC"
  },
  {
    "arxiv_id": "2501.07875v1",
    "title": "Continual Learning with Embedding Layer Surgery and Task-wise Beam Search using Whisper",
    "authors": [
      "Chin Yuen Kwok",
      "Jia Qi Yip",
      "Eng Siong Chng"
    ],
    "abstract": "Current Multilingual ASR models only support a fraction of the world's\nlanguages. Continual Learning (CL) aims to tackle this problem by adding new\nlanguages to pre-trained models while avoiding the loss of performance on\nexisting languages, also known as Catastrophic Forgetting (CF). However,\nexisting CL methods overlook the adaptation of the token embedding lookup table\nat the decoder, despite its significant contribution to CF. We propose\nEmbedding Layer Surgery where separate copies of the token embeddings are\ncreated for each new languages, and one of the copies is selected to replace\nthe old languages embeddings when transcribing the corresponding new language.\nUnfortunately, this approach means LID errors also cause incorrect ASR\nembedding selection. Our Task-wise Beam Search allows self-correction for such\nmistakes. By adapting Whisper to 10 hours of data for each of 10 unseen\nlanguages from Common Voice, results show that our method reduces the Average\nWER (AWER) of pre-trained languages from 14.2% to 11.9% compared with\nExperience Replay, without compromising the AWER of the unseen languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in 2024 IEEE Spoken Language Technology Workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.07875v1",
    "published_date": "2025-01-14 06:33:40 UTC",
    "updated_date": "2025-01-14 06:33:40 UTC"
  },
  {
    "arxiv_id": "2501.07859v1",
    "title": "deepTerra -- AI Land Classification Made Easy",
    "authors": [
      "Andrew Keith Wilkinson"
    ],
    "abstract": "deepTerra is a comprehensive platform designed to facilitate the\nclassification of land surface features using machine learning and satellite\nimagery. The platform includes modules for data collection, image augmentation,\ntraining, testing, and prediction, streamlining the entire workflow for image\nclassification tasks. This paper presents a detailed overview of the\ncapabilities of deepTerra, shows how it has been applied to various research\nareas, and discusses the future directions it might take.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07859v1",
    "published_date": "2025-01-14 05:55:20 UTC",
    "updated_date": "2025-01-14 05:55:20 UTC"
  },
  {
    "arxiv_id": "2501.07857v1",
    "title": "Hierarchical Repository-Level Code Summarization for Business Applications Using Local LLMs",
    "authors": [
      "Nilesh Dhulshette",
      "Sapan Shah",
      "Vinay Kulkarni"
    ],
    "abstract": "In large-scale software development, understanding the functionality and\nintent behind complex codebases is critical for effective development and\nmaintenance. While code summarization has been widely studied, existing methods\nprimarily focus on smaller code units, such as functions, and struggle with\nlarger code artifacts like files and packages. Additionally, current\nsummarization models tend to emphasize low-level implementation details, often\noverlooking the domain and business context that are crucial for real-world\napplications. This paper proposes a two-step hierarchical approach for\nrepository-level code summarization, tailored to business applications. First,\nsmaller code units such as functions and variables are identified using syntax\nanalysis and summarized with local LLMs. These summaries are then aggregated to\ngenerate higher-level file and package summaries. To ensure the summaries are\ngrounded in business context, we design custom prompts that capture the\nintended purpose of code artifacts based on the domain and problem context of\nthe business application. We evaluate our approach on a business support system\n(BSS) for the telecommunications domain, showing that syntax analysis-based\nhierarchical summarization improves coverage, while business-context grounding\nenhances the relevance of the generated summaries.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "To appear at LLM4Code@ICSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07857v1",
    "published_date": "2025-01-14 05:48:27 UTC",
    "updated_date": "2025-01-14 05:48:27 UTC"
  },
  {
    "arxiv_id": "2501.07855v1",
    "title": "State-of-the-Art Transformer Models for Image Super-Resolution: Techniques, Challenges, and Applications",
    "authors": [
      "Debasish Dutta",
      "Deepjyoti Chetia",
      "Neeharika Sonowal",
      "Sanjib Kr Kalita"
    ],
    "abstract": "Image Super-Resolution (SR) aims to recover a high-resolution image from its\nlow-resolution counterpart, which has been affected by a specific degradation\nprocess. This is achieved by enhancing detail and visual quality. Recent\nadvancements in transformer-based methods have remolded image super-resolution\nby enabling high-quality reconstructions surpassing previous deep-learning\napproaches like CNN and GAN-based. This effectively addresses the limitations\nof previous methods, such as limited receptive fields, poor global context\ncapture, and challenges in high-frequency detail recovery. Additionally, the\npaper reviews recent trends and advancements in transformer-based SR models,\nexploring various innovative techniques and architectures that combine\ntransformers with traditional networks to balance global and local contexts.\nThese neoteric methods are critically analyzed, revealing promising yet\nunexplored gaps and potential directions for future research. Several\nvisualizations of models and techniques are included to foster a holistic\nunderstanding of recent trends. This work seeks to offer a structured roadmap\nfor researchers at the forefront of deep learning, specifically exploring the\nimpact of transformers on super-resolution techniques.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07855v1",
    "published_date": "2025-01-14 05:43:59 UTC",
    "updated_date": "2025-01-14 05:43:59 UTC"
  },
  {
    "arxiv_id": "2501.07853v1",
    "title": "Optimizing Language Models for Grammatical Acceptability: A Comparative Study of Fine-Tuning Techniques",
    "authors": [
      "Shobhit Ratan",
      "Farley Knight",
      "Ghada Jerfel",
      "Sze Chung Ho"
    ],
    "abstract": "This study explores the fine-tuning (FT) of the Open Pre-trained Transformer\n(OPT-125M) for grammatical acceptability tasks using the CoLA dataset. By\ncomparing Vanilla-Fine-Tuning (VFT), Pattern-Based-Fine-Tuning (PBFT), and\nParameter-Efficient Fine-Tuning techniques (PEFT) like Low-Rank Adaptation\n(LoRA), we demonstrate significant improvements in computational efficiency\nwhile maintaining high accuracy. Our experiments reveal that while VFT achieves\nthe highest accuracy (81.2%), LoRA enhancing FT by reducing memory usage and\niteration time by more than 50%, and increases accuracy in PBFT case. Context\nDistillation (CD), though computationally efficient, underperformed with\naccuracy around 31%. Our findings contribute to democratizing access to large\nlanguage models (LLM) by reducing computational barriers.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07853v1",
    "published_date": "2025-01-14 05:41:09 UTC",
    "updated_date": "2025-01-14 05:41:09 UTC"
  },
  {
    "arxiv_id": "2501.07849v1",
    "title": "Unveiling Provider Bias in Large Language Models for Code Generation",
    "authors": [
      "Xiaoyu Zhang",
      "Juan Zhai",
      "Shiqing Ma",
      "Qingshuang Bao",
      "Weipeng Jiang",
      "Chao Shen",
      "Yang Liu"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as the new recommendation engines,\noutperforming traditional methods in both capability and scope, particularly in\ncode generation applications. Our research reveals a novel provider bias in\nLLMs, namely without explicit input prompts, these models show systematic\npreferences for services from specific providers in their recommendations\n(e.g., favoring Google Cloud over Microsoft Azure). This bias holds significant\nimplications for market dynamics and societal equilibrium, potentially\npromoting digital monopolies. It may also deceive users and violate their\nexpectations, leading to various consequences. This paper presents the first\ncomprehensive empirical study of provider bias in LLM code generation. We\ndevelop a systematic methodology encompassing an automated pipeline for dataset\ngeneration, incorporating 6 distinct coding task categories and 30 real-world\napplication scenarios. Our analysis encompasses over 600,000 LLM-generated\nresponses across seven state-of-the-art models, utilizing approximately 500\nmillion tokens (equivalent to \\$5,000+ in computational costs). The study\nevaluates both the generated code snippets and their embedded service provider\nselections to quantify provider bias. Additionally, we conduct a comparative\nanalysis of seven debiasing prompting techniques to assess their efficacy in\nmitigating these biases. Our findings demonstrate that LLMs exhibit significant\nprovider preferences, predominantly favoring services from Google and Amazon,\nand can autonomously modify input code to incorporate their preferred providers\nwithout users' requests. Notably, we observe discrepancies between providers\nrecommended in conversational contexts versus those implemented in generated\ncode. The complete dataset and analysis results are available in our\nrepository.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.SE",
    "comment": "21 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.07849v1",
    "published_date": "2025-01-14 05:21:27 UTC",
    "updated_date": "2025-01-14 05:21:27 UTC"
  },
  {
    "arxiv_id": "2501.07837v1",
    "title": "A Driver Advisory System Based on Large Language Model for High-speed Train",
    "authors": [
      "Y. C. Luo",
      "J. Xun",
      "W. Wang",
      "R. Z. Zhang",
      "Z. C. Zhao"
    ],
    "abstract": "With the rapid development of China high-speed railway, drivers face\nincreasingly significant technical challenges during operations, such as fault\nhandling. Currently, drivers depend on the onboard mechanic when facing\ntechnical issues, for instance, traction loss or sensor faults. This dependency\ncan hinder effective operation, even lead to accidents, while waiting for\nfaults to be addressed. To enhance the accuracy and explainability of actions\nduring fault handling, an Intelligent Driver Advisory System (IDAS) framework\nbased on a large language model (LLM) named IDAS-LLM, is introduced. Initially,\ndomain-fine-tuning of the LLM is performed using a constructed railway\nknowledge question-and-answer dataset to improve answer accuracy in\nrailway-related questions. Subsequently, integration of the Retrieval-augmented\nGeneration (RAG) architecture is pursued for system design to enhance the\nexplainability of generated responses. Comparative experiments are conducted\nusing the constructed railway driving knowledge assessment dataset. Results\nindicate that domain-fine-tuned LLMs show an improvement in answer accuracy by\nan average of 10%, outperforming some current mainstream LLMs. Additionally,\nthe inclusion of the RAG framework increases the average recall rate of\nquestion-and-answer sessions by about 4%. Finally, the fault handling\ncapability of IDAS-LLM is demonstrated through simulations of real operational\nscenarios, proving that the proposed framework has practical application\nprospects.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 7 figures, presented at 104th TRB Annual Meeting",
    "pdf_url": "http://arxiv.org/pdf/2501.07837v1",
    "published_date": "2025-01-14 04:41:03 UTC",
    "updated_date": "2025-01-14 04:41:03 UTC"
  },
  {
    "arxiv_id": "2501.07834v2",
    "title": "Flow: Modularized Agentic Workflow Automation",
    "authors": [
      "Boye Niu",
      "Yiliao Song",
      "Kai Lian",
      "Yifan Shen",
      "Yu Yao",
      "Kun Zhang",
      "Tongliang Liu"
    ],
    "abstract": "Multi-agent frameworks powered by large language models (LLMs) have\ndemonstrated great success in automated planning and task execution. However,\nthe effective adjustment of agentic workflows during execution has not been\nwell studied. An effective workflow adjustment is crucial in real-world\nscenarios, as the initial plan must adjust to unforeseen challenges and\nchanging conditions in real time to ensure the efficient execution of complex\ntasks. In this paper, we define workflows as an activity-on-vertex (AOV) graph,\nwhich allows continuous workflow refinement by LLM agents through dynamic\nsubtask allocation adjustment based on historical performance and previous\nAOVs. To further enhance framework performance, we emphasize modularity in\nworkflow design based on evaluating parallelism and dependency complexity. With\nthis design, our proposed multi-agent framework achieves efficient concurrent\nexecution of subtasks, effective goal achievement, and enhanced error\ntolerance. Empirical results across various practical tasks demonstrate\nsignificant improvements in the efficiency of multi-agent frameworks through\ndynamic workflow refinement and modularization. The code is available at:\nhttps://github.com/tmllab/2025_ICLR_FLOW.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07834v2",
    "published_date": "2025-01-14 04:35:37 UTC",
    "updated_date": "2025-02-23 06:20:37 UTC"
  },
  {
    "arxiv_id": "2501.13936v1",
    "title": "Evaluating Computational Accuracy of Large Language Models in Numerical Reasoning Tasks for Healthcare Applications",
    "authors": [
      "Arjun R. Malghan"
    ],
    "abstract": "Large Language Models (LLMs) have emerged as transformative tools in the\nhealthcare sector, demonstrating remarkable capabilities in natural language\nunderstanding and generation. However, their proficiency in numerical\nreasoning, particularly in high-stakes domains like in clinical applications,\nremains underexplored. Numerical reasoning is critical in healthcare\napplications, influencing patient outcomes, treatment planning, and resource\nallocation. This study investigates the computational accuracy of LLMs in\nnumerical reasoning tasks within healthcare contexts. Using a curated dataset\nof 1,000 numerical problems, encompassing real-world scenarios such as dosage\ncalculations and lab result interpretations, the performance of a refined LLM\nbased on the GPT-3 architecture was evaluated. The methodology includes prompt\nengineering, integration of fact-checking pipelines, and application of\nregularization techniques to enhance model accuracy and generalization. Key\nmetrics such as precision, recall, and F1-score were utilized to assess the\nmodel's efficacy. The results indicate an overall accuracy of 84.10%, with\nimproved performance in straightforward numerical tasks and challenges in\nmulti-step reasoning. The integration of a fact-checking pipeline improved\naccuracy by 11%, underscoring the importance of validation mechanisms. This\nresearch highlights the potential of LLMs in healthcare numerical reasoning and\nidentifies avenues for further refinement to support critical decision-making\nin clinical environments. The findings aim to contribute to the development of\nreliable, interpretable, and contextually relevant AI tools for healthcare.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 1 figure, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.13936v1",
    "published_date": "2025-01-14 04:29:43 UTC",
    "updated_date": "2025-01-14 04:29:43 UTC"
  },
  {
    "arxiv_id": "2501.07824v4",
    "title": "Real-time Verification and Refinement of Language Model Text Generation",
    "authors": [
      "Joonho Ko",
      "Jinheon Baek",
      "Sung Ju Hwang"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance across a wide\nrange of natural language tasks. However, a critical challenge remains in that\nthey sometimes generate factually incorrect answers. To address this, while\nmany previous work has focused on identifying errors in their generation and\nfurther refining them, they are slow in deployment since they are designed to\nverify the response from LLMs only after their entire generation (from the\nfirst to last tokens) is done. Further, we observe that once LLMs generate\nincorrect tokens early on, there is a higher likelihood that subsequent tokens\nwill also be factually incorrect. To this end, in this work, we propose\nStreaming-VR (Streaming Verification and Refinement), a novel approach designed\nto enhance the efficiency of verification and refinement of LLM outputs.\nSpecifically, the proposed Streaming-VR enables on-the-fly verification and\ncorrection of tokens as they are being generated, similar to a streaming\nprocess, ensuring that each subset of tokens is checked and refined in\nreal-time by another LLM as the LLM constructs its response. Through\ncomprehensive evaluations on multiple datasets, we demonstrate that our\napproach not only enhances the factual accuracy of LLMs, but also offers a more\nefficient solution compared to prior refinement methods.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07824v4",
    "published_date": "2025-01-14 03:59:48 UTC",
    "updated_date": "2025-04-13 08:22:51 UTC"
  },
  {
    "arxiv_id": "2501.07818v1",
    "title": "A Multi-Encoder Frozen-Decoder Approach for Fine-Tuning Large Language Models",
    "authors": [
      "Kaustubh D. Dhole"
    ],
    "abstract": "Among parameter-efficient fine-tuning methods, freezing has emerged as a\npopular strategy for speeding up training, reducing catastrophic forgetting,\nand improving downstream performance. We investigate the impact of freezing the\ndecoder in a multi-task setup comprising diverse natural language tasks, aiming\nto reduce deployment overhead and enhance portability to novel tasks. Our\nexperiments, conducted by fine-tuning both individual and multi-task setups on\nthe AlexaTM model, reveal that freezing decoders is highly effective for tasks\nwith natural language outputs and mitigates catastrophic forgetting in\nmultilingual tasks. However, we find that pairing frozen decoders with a larger\nmodel can effectively maintain or even enhance performance in structured and QA\ntasks, making it a viable strategy for a broader range of task types.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.5.1; I.5.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07818v1",
    "published_date": "2025-01-14 03:43:23 UTC",
    "updated_date": "2025-01-14 03:43:23 UTC"
  },
  {
    "arxiv_id": "2501.07815v1",
    "title": "Agent-Centric Projection of Prompting Techniques and Implications for Synthetic Training Data for Large Language Models",
    "authors": [
      "Dhruv Dhamani",
      "Mary Lou Maher"
    ],
    "abstract": "Recent advances in prompting techniques and multi-agent systems for Large\nLanguage Models (LLMs) have produced increasingly complex approaches. However,\nwe lack a framework for characterizing and comparing prompting techniques or\nunderstanding their relationship to multi-agent LLM systems. This position\npaper introduces and explains the concepts of linear contexts (a single,\ncontinuous sequence of interactions) and non-linear contexts (branching or\nmulti-path) in LLM systems. These concepts enable the development of an\nagent-centric projection of prompting techniques, a framework that can reveal\ndeep connections between prompting strategies and multi-agent systems. We\npropose three conjectures based on this framework: (1) results from non-linear\nprompting techniques can predict outcomes in equivalent multi-agent systems,\n(2) multi-agent system architectures can be replicated through single-LLM\nprompting techniques that simulate equivalent interaction patterns, and (3)\nthese equivalences suggest novel approaches for generating synthetic training\ndata. We argue that this perspective enables systematic cross-pollination of\nresearch findings between prompting and multi-agent domains, while providing\nnew directions for improving both the design and training of future LLM\nsystems.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 5 figures. Accepted at ICAART 2025. Derived from an early\n  draft at 2312.17601. arXiv admin note: substantial text overlap with\n  arXiv:2312.17601",
    "pdf_url": "http://arxiv.org/pdf/2501.07815v1",
    "published_date": "2025-01-14 03:26:43 UTC",
    "updated_date": "2025-01-14 03:26:43 UTC"
  },
  {
    "arxiv_id": "2501.07814v1",
    "title": "STTS-EAD: Improving Spatio-Temporal Learning Based Time Series Prediction via",
    "authors": [
      "Yuanyuan Liang",
      "Tianhao Zhang",
      "Tingyu Xie"
    ],
    "abstract": "Handling anomalies is a critical preprocessing step in multivariate time\nseries prediction. However, existing approaches that separate anomaly\npreprocessing from model training for multivariate time series prediction\nencounter significant limitations. Specifically, these methods fail to utilize\nauxiliary information crucial for identifying latent anomalies associated with\nspatiotemporal factors during the preprocessing stage. Instead, they rely\nsolely on data distribution for anomaly detection, which can result in the\nincorrect processing of numerous samples that could otherwise contribute\npositively to model training. To address this, we propose STTS-EAD, an\nend-to-end method that seamlessly integrates anomaly detection into the\ntraining process of multivariate time series forecasting and aims to improve\nSpatio-Temporal learning based Time Series prediction via Embedded Anomaly\nDetection. Our proposed STTS-EAD leverages spatio-temporal information for\nforecasting and anomaly detection, with the two parts alternately executed and\noptimized for each other. To the best of our knowledge, STTS-EAD is the first\nto integrate anomaly detection and forecasting tasks in the training phase for\nimproving the accuracy of multivariate time series forecasting. Extensive\nexperiments on a public stock dataset and two real-world sales datasets from a\nrenowned coffee chain enterprise show that our proposed method can effectively\nprocess detected anomalies in the training stage to improve forecasting\nperformance in the inference stage and significantly outperform baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07814v1",
    "published_date": "2025-01-14 03:26:05 UTC",
    "updated_date": "2025-01-14 03:26:05 UTC"
  },
  {
    "arxiv_id": "2501.07813v1",
    "title": "Talk to Right Specialists: Routing and Planning in Multi-agent System for Question Answering",
    "authors": [
      "Feijie Wu",
      "Zitao Li",
      "Fei Wei",
      "Yaliang Li",
      "Bolin Ding",
      "Jing Gao"
    ],
    "abstract": "Leveraging large language models (LLMs), an agent can utilize\nretrieval-augmented generation (RAG) techniques to integrate external knowledge\nand increase the reliability of its responses. Current RAG-based agents\nintegrate single, domain-specific knowledge sources, limiting their ability and\nleading to hallucinated or inaccurate responses when addressing cross-domain\nqueries. Integrating multiple knowledge bases into a unified RAG-based agent\nraises significant challenges, including increased retrieval overhead and data\nsovereignty when sensitive data is involved. In this work, we propose RopMura,\na novel multi-agent system that addresses these limitations by incorporating\nhighly efficient routing and planning mechanisms. RopMura features two key\ncomponents: a router that intelligently selects the most relevant agents based\non knowledge boundaries and a planner that decomposes complex multi-hop queries\ninto manageable steps, allowing for coordinating cross-domain responses.\nExperimental results demonstrate that RopMura effectively handles both\nsingle-hop and multi-hop queries, with the routing mechanism enabling precise\nanswers for single-hop queries and the combined routing and planning mechanisms\nachieving accurate, multi-step resolutions for complex queries.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.MA",
    "comment": "Work In Progress",
    "pdf_url": "http://arxiv.org/pdf/2501.07813v1",
    "published_date": "2025-01-14 03:25:26 UTC",
    "updated_date": "2025-01-14 03:25:26 UTC"
  },
  {
    "arxiv_id": "2501.07809v1",
    "title": "Conformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs): learning neural networks for designing neutral inclusions",
    "authors": [
      "Daehee Cho",
      "Hyeonmin Yun",
      "Jaeyong Lee",
      "Mikyoung Lim"
    ],
    "abstract": "We focus on designing and solving the neutral inclusion problem via neural\nnetworks. The neutral inclusion problem has a long history in the theory of\ncomposite materials, and it is exceedingly challenging to identify the precise\ncondition that precipitates a general-shaped inclusion into a neutral\ninclusion. Physics-informed neural networks (PINNs) have recently become a\nhighly successful approach to addressing both forward and inverse problems\nassociated with partial differential equations. We found that traditional PINNs\nperform inadequately when applied to the inverse problem of designing neutral\ninclusions with arbitrary shapes. In this study, we introduce a novel approach,\nConformal mapping Coordinates Physics-Informed Neural Networks (CoCo-PINNs),\nwhich integrates complex analysis techniques into PINNs. This method exhibits\nstrong performance in solving forward-inverse problems to construct neutral\ninclusions of arbitrary shapes in two dimensions, where the imperfect interface\ncondition on the inclusion's boundary is modeled by training neural networks.\nNotably, we mathematically prove that training with a single linear field is\nsufficient to achieve neutrality for untrained linear fields in arbitrary\ndirections, given a minor assumption. We demonstrate that CoCo-PINNs offer\nenhanced performances in terms of credibility, consistency, and stability.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07809v1",
    "published_date": "2025-01-14 03:20:17 UTC",
    "updated_date": "2025-01-14 03:20:17 UTC"
  },
  {
    "arxiv_id": "2501.07808v1",
    "title": "A Low-cost and Ultra-lightweight Binary Neural Network for Traffic Signal Recognition",
    "authors": [
      "Mingke Xiao",
      "Yue Su",
      "Liang Yu",
      "Guanglong Qu",
      "Yutong Jia",
      "Yukuan Chang",
      "Xu Zhang"
    ],
    "abstract": "The deployment of neural networks in vehicle platforms and wearable\nArtificial Intelligence-of-Things (AIOT) scenarios has become a research area\nthat has attracted much attention. With the continuous evolution of deep\nlearning technology, many image classification models are committed to\nimproving recognition accuracy, but this is often accompanied by problems such\nas large model resource usage, complex structure, and high power consumption,\nwhich makes it challenging to deploy on resource-constrained platforms. Herein,\nwe propose an ultra-lightweight binary neural network (BNN) model designed for\nhardware deployment, and conduct image classification research based on the\nGerman Traffic Sign Recognition Benchmark (GTSRB) dataset. In addition, we also\nverify it on the Chinese Traffic Sign (CTS) and Belgian Traffic Sign (BTS)\ndatasets. The proposed model shows excellent recognition performance with an\naccuracy of up to 97.64%, making it one of the best performing BNN models in\nthe GTSRB dataset. Compared with the full-precision model, the accuracy loss is\ncontrolled within 1%, and the parameter storage overhead of the model is only\n10% of that of the full-precision model. More importantly, our network model\nonly relies on logical operations and low-bit width fixed-point addition and\nsubtraction operations during the inference phase, which greatly simplifies the\ndesign complexity of the processing element (PE). Our research shows the great\npotential of BNN in the hardware deployment of computer vision models,\nespecially in the field of computer vision tasks related to autonomous driving.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07808v1",
    "published_date": "2025-01-14 03:19:10 UTC",
    "updated_date": "2025-01-14 03:19:10 UTC"
  },
  {
    "arxiv_id": "2501.07802v1",
    "title": "Visual Language Models as Operator Agents in the Space Domain",
    "authors": [
      "Alejandro Carrasco",
      "Marco Nedungadi",
      "Enrico M. Zucchelli",
      "Amit Jain",
      "Victor Rodriguez-Fernandez",
      "Richard Linares"
    ],
    "abstract": "This paper explores the application of Vision-Language Models (VLMs) as\noperator agents in the space domain, focusing on both software and hardware\noperational paradigms. Building on advances in Large Language Models (LLMs) and\ntheir multimodal extensions, we investigate how VLMs can enhance autonomous\ncontrol and decision-making in space missions. In the software context, we\nemploy VLMs within the Kerbal Space Program Differential Games (KSPDG)\nsimulation environment, enabling the agent to interpret visual screenshots of\nthe graphical user interface to perform complex orbital maneuvers. In the\nhardware context, we integrate VLMs with robotic systems equipped with cameras\nto inspect and diagnose physical space objects, such as satellites. Our results\ndemonstrate that VLMs can effectively process visual and textual data to\ngenerate contextually appropriate actions, competing with traditional methods\nand non-multimodal LLMs in simulation tasks, and showing promise in real-world\napplications.",
    "categories": [
      "cs.AI",
      "physics.space-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "Updated version of the paper presented in 2025 AIAA SciTech.\n  https://arc.aiaa.org/doi/10.2514/6.2025-1543",
    "pdf_url": "http://arxiv.org/pdf/2501.07802v1",
    "published_date": "2025-01-14 03:03:37 UTC",
    "updated_date": "2025-01-14 03:03:37 UTC"
  },
  {
    "arxiv_id": "2501.07801v1",
    "title": "A Comparative Analysis of DNN-based White-Box Explainable AI Methods in Network Security",
    "authors": [
      "Osvaldo Arreche",
      "Mustafa Abdallah"
    ],
    "abstract": "New research focuses on creating artificial intelligence (AI) solutions for\nnetwork intrusion detection systems (NIDS), drawing its inspiration from the\never-growing number of intrusions on networked systems, increasing its\ncomplexity and intelligibility. Hence, the use of explainable AI (XAI)\ntechniques in real-world intrusion detection systems comes from the requirement\nto comprehend and elucidate black-box AI models to security analysts. In an\neffort to meet such requirements, this paper focuses on applying and evaluating\nWhite-Box XAI techniques (particularly LRP, IG, and DeepLift) for NIDS via an\nend-to-end framework for neural network models, using three widely used network\nintrusion datasets (NSL-KDD, CICIDS-2017, and RoEduNet-SIMARGL2021), assessing\nits global and local scopes, and examining six distinct assessment measures\n(descriptive accuracy, sparsity, stability, robustness, efficiency, and\ncompleteness). We also compare the performance of white-box XAI methods with\nblack-box XAI methods. The results show that using White-box XAI techniques\nscores high in robustness and completeness, which are crucial metrics for IDS.\nMoreover, the source codes for the programs developed for our XAI evaluation\nframework are available to be improved and used by the research community.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07801v1",
    "published_date": "2025-01-14 02:57:20 UTC",
    "updated_date": "2025-01-14 02:57:20 UTC"
  },
  {
    "arxiv_id": "2501.07800v1",
    "title": "BioPose: Biomechanically-accurate 3D Pose Estimation from Monocular Videos",
    "authors": [
      "Farnoosh Koleini",
      "Muhammad Usama Saleem",
      "Pu Wang",
      "Hongfei Xue",
      "Ahmed Helmy",
      "Abbey Fenwick"
    ],
    "abstract": "Recent advancements in 3D human pose estimation from single-camera images and\nvideos have relied on parametric models, like SMPL. However, these models\noversimplify anatomical structures, limiting their accuracy in capturing true\njoint locations and movements, which reduces their applicability in\nbiomechanics, healthcare, and robotics. Biomechanically accurate pose\nestimation, on the other hand, typically requires costly marker-based motion\ncapture systems and optimization techniques in specialized labs. To bridge this\ngap, we propose BioPose, a novel learning-based framework for predicting\nbiomechanically accurate 3D human pose directly from monocular videos. BioPose\nincludes three key components: a Multi-Query Human Mesh Recovery model\n(MQ-HMR), a Neural Inverse Kinematics (NeurIK) model, and a 2D-informed pose\nrefinement technique. MQ-HMR leverages a multi-query deformable transformer to\nextract multi-scale fine-grained image features, enabling precise human mesh\nrecovery. NeurIK treats the mesh vertices as virtual markers, applying a\nspatial-temporal network to regress biomechanically accurate 3D poses under\nanatomical constraints. To further improve 3D pose estimations, a 2D-informed\nrefinement step optimizes the query tokens during inference by aligning the 3D\nstructure with 2D pose observations. Experiments on benchmark datasets\ndemonstrate that BioPose significantly outperforms state-of-the-art methods.\nProject website:\n\\url{https://m-usamasaleem.github.io/publication/BioPose/BioPose.html}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07800v1",
    "published_date": "2025-01-14 02:56:19 UTC",
    "updated_date": "2025-01-14 02:56:19 UTC"
  },
  {
    "arxiv_id": "2501.07774v1",
    "title": "Transforming Indoor Localization: Advanced Transformer Architecture for NLOS Dominated Wireless Environments with Distributed Sensors",
    "authors": [
      "Saad Masrur",
      "Jung-Fu",
      "Cheng",
      "Atieh R. Khamesi",
      "Ismail Guvenc"
    ],
    "abstract": "Indoor localization in challenging non-line-of-sight (NLOS) environments\noften leads to mediocre accuracy with traditional approaches. Deep learning\n(DL) has been applied to tackle these challenges; however, many DL approaches\noverlook computational complexity, especially for floating-point operations\n(FLOPs), making them unsuitable for resource-limited devices. Transformer-based\nmodels have achieved remarkable success in natural language processing (NLP)\nand computer vision (CV) tasks, motivating their use in wireless applications.\nHowever, their use in indoor localization remains nascent, and directly\napplying Transformers for indoor localization can be both computationally\nintensive and exhibit limitations in accuracy. To address these challenges, in\nthis work, we introduce a novel tokenization approach, referred to as Sensor\nSnapshot Tokenization (SST), which preserves variable-specific representations\nof power delay profile (PDP) and enhances attention mechanisms by effectively\ncapturing multi-variate correlation. Complementing this, we propose a\nlightweight Swish-Gated Linear Unit-based Transformer (L-SwiGLU Transformer)\nmodel, designed to reduce computational complexity without compromising\nlocalization accuracy. Together, these contributions mitigate the computational\nburden and dependency on large datasets, making Transformer models more\nefficient and suitable for resource-constrained scenarios. The proposed\ntokenization method enables the Vanilla Transformer to achieve a 90th\npercentile positioning error of 0.388 m in a highly NLOS indoor factory,\nsurpassing conventional tokenization methods. The L-SwiGLU ViT further reduces\nthe error to 0.355 m, achieving an 8.51% improvement. Additionally, the\nproposed model outperforms a 14.1 times larger model with a 46.13% improvement,\nunderscoring its computational efficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "The paper has been submitted to IEEE Transactions on Machine Learning\n  in Communications and Networking",
    "pdf_url": "http://arxiv.org/pdf/2501.07774v1",
    "published_date": "2025-01-14 01:16:30 UTC",
    "updated_date": "2025-01-14 01:16:30 UTC"
  },
  {
    "arxiv_id": "2501.07766v2",
    "title": "Large Language Models for Knowledge Graph Embedding: A Survey",
    "authors": [
      "Bingchen Liu",
      "Yuanyuan Fang",
      "Naixing Xu",
      "Shihao Hou",
      "Xin Li",
      "Qian Li"
    ],
    "abstract": "Large language models (LLMs) have garnered significant attention for their\nsuperior performance in many knowledge-driven applications on the world wide\nweb.These models are designed to train hundreds of millions or more parameters\non large amounts of text data, enabling them to understand and generate\nnaturallanguage effectively. As the superior performance of LLMs becomes\napparent,they are increasingly being applied to knowledge graph embedding (KGE)\nrelated tasks to improve the processing results. Traditional KGE representation\nlearning methods map entities and relations into a low-dimensional vector\nspace, enablingthe triples in the knowledge graph to satisfy a specific scoring\nfunction in thevector space. However, based on the powerful language\nunderstanding and seman-tic modeling capabilities of LLMs, that have recently\nbeen invoked to varying degrees in different types of KGE related scenarios\nsuch as multi-modal KGE andopen KGE according to their task characteristics. In\nthis paper, we investigate awide range of approaches for performing\nLLMs-related tasks in different types of KGE scenarios. To better compare the\nvarious approaches, we summarize each KGE scenario in a classification.\nFinally, we discuss the applications in which the methods are mainly used and\nsuggest several forward-looking directions for the development of this new\nresearch area.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07766v2",
    "published_date": "2025-01-14 00:47:24 UTC",
    "updated_date": "2025-04-08 08:33:49 UTC"
  },
  {
    "arxiv_id": "2501.07764v1",
    "title": "Deep Learning for Disease Outbreak Prediction: A Robust Early Warning Signal for Transcritical Bifurcations",
    "authors": [
      "Reza Miry",
      "Amit K. Chakraborty",
      "Russell Greiner",
      "Mark A. Lewis",
      "Hao Wang",
      "Tianyu Guan",
      "Pouria Ramazi"
    ],
    "abstract": "Early Warning Signals (EWSs) are vital for implementing preventive measures\nbefore a disease turns into a pandemic. While new diseases exhibit unique\nbehaviors, they often share fundamental characteristics from a dynamical\nsystems perspective. Moreover, measurements during disease outbreaks are often\ncorrupted by different noise sources, posing challenges for Time Series\nClassification (TSC) tasks. In this study, we address the problem of having a\nrobust EWS for disease outbreak prediction using a best-performing deep\nlearning model in the domain of TSC. We employed two simulated datasets to\ntrain the model: one representing generated dynamical systems with randomly\nselected polynomial terms to model new disease behaviors, and another\nsimulating noise-induced disease dynamics to account for noisy measurements.\nThe model's performance was analyzed using both simulated data from different\ndisease models and real-world data, including influenza and COVID-19. Results\ndemonstrate that the proposed model outperforms previous models, effectively\nproviding EWSs of impending outbreaks across various scenarios. This study\nbridges advancements in deep learning with the ability to provide robust early\nwarning signals in noisy environments, making it highly applicable to\nreal-world crises involving emerging disease outbreaks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.07764v1",
    "published_date": "2025-01-14 00:47:05 UTC",
    "updated_date": "2025-01-14 00:47:05 UTC"
  },
  {
    "arxiv_id": "2501.07763v1",
    "title": "On the Statistical Capacity of Deep Generative Models",
    "authors": [
      "Edric Tam",
      "David B. Dunson"
    ],
    "abstract": "Deep generative models are routinely used in generating samples from complex,\nhigh-dimensional distributions. Despite their apparent successes, their\nstatistical properties are not well understood. A common assumption is that\nwith enough training data and sufficiently large neural networks, deep\ngenerative model samples will have arbitrarily small errors in sampling from\nany continuous target distribution. We set up a unifying framework that debunks\nthis belief. We demonstrate that broad classes of deep generative models,\nincluding variational autoencoders and generative adversarial networks, are not\nuniversal generators. Under the predominant case of Gaussian latent variables,\nthese models can only generate concentrated samples that exhibit light tails.\nUsing tools from concentration of measure and convex geometry, we give\nanalogous results for more general log-concave and strongly log-concave latent\nvariable distributions. We extend our results to diffusion models via a\nreduction argument. We use the Gromov--Levy inequality to give similar\nguarantees when the latent variables lie on manifolds with positive Ricci\ncurvature. These results shed light on the limited capacity of common deep\ngenerative models to handle heavy tails. We illustrate the empirical relevance\nof our work with simulations and financial data.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07763v1",
    "published_date": "2025-01-14 00:39:46 UTC",
    "updated_date": "2025-01-14 00:39:46 UTC"
  },
  {
    "arxiv_id": "2501.07762v2",
    "title": "PSReg: Prior-guided Sparse Mixture of Experts for Point Cloud Registration",
    "authors": [
      "Xiaoshui Huang",
      "Zhou Huang",
      "Yifan Zuo",
      "Yongshun Gong",
      "Chengdong Zhang",
      "Deyang Liu",
      "Yuming Fang"
    ],
    "abstract": "The discriminative feature is crucial for point cloud registration. Recent\nmethods improve the feature discriminative by distinguishing between\nnon-overlapping and overlapping region points. However, they still face\nchallenges in distinguishing the ambiguous structures in the overlapping\nregions. Therefore, the ambiguous features they extracted resulted in a\nsignificant number of outlier matches from overlapping regions. To solve this\nproblem, we propose a prior-guided SMoE-based registration method to improve\nthe feature distinctiveness by dispatching the potential correspondences to the\nsame experts. Specifically, we propose a prior-guided SMoE module by fusing\nprior overlap and potential correspondence embeddings for routing, assigning\ntokens to the most suitable experts for processing. In addition, we propose a\nregistration framework by a specific combination of Transformer layer and\nprior-guided SMoE module. The proposed method not only pays attention to the\nimportance of locating the overlapping areas of point clouds, but also commits\nto finding more accurate correspondences in overlapping areas. Our extensive\nexperiments demonstrate the effectiveness of our method, achieving\nstate-of-the-art registration recall (95.7\\%/79.3\\%) on the 3DMatch/3DLoMatch\nbenchmark. Moreover, we also test the performance on ModelNet40 and demonstrate\nexcellent performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025 Oral",
    "pdf_url": "http://arxiv.org/pdf/2501.07762v2",
    "published_date": "2025-01-14 00:30:22 UTC",
    "updated_date": "2025-01-18 01:03:44 UTC"
  },
  {
    "arxiv_id": "2501.07761v1",
    "title": "Impatient Bandits: Optimizing for the Long-Term Without Delay",
    "authors": [
      "Kelly W. Zhang",
      "Thomas Baldwin-McDonald",
      "Kamil Ciosek",
      "Lucas Maystre",
      "Daniel Russo"
    ],
    "abstract": "Increasingly, recommender systems are tasked with improving users' long-term\nsatisfaction. In this context, we study a content exploration task, which we\nformalize as a bandit problem with delayed rewards. There is an apparent\ntrade-off in choosing the learning signal: waiting for the full reward to\nbecome available might take several weeks, slowing the rate of learning,\nwhereas using short-term proxy rewards reflects the actual long-term goal only\nimperfectly. First, we develop a predictive model of delayed rewards that\nincorporates all information obtained to date. Rewards as well as shorter-term\nsurrogate outcomes are combined through a Bayesian filter to obtain a\nprobabilistic belief. Second, we devise a bandit algorithm that quickly learns\nto identify content aligned with long-term success using this new predictive\nmodel. We prove a regret bound for our algorithm that depends on the\n\\textit{Value of Progressive Feedback}, an information theoretic metric that\ncaptures the quality of short-term leading indicators that are observed prior\nto the long-term reward. We apply our approach to a podcast recommendation\nproblem, where we seek to recommend shows that users engage with repeatedly\nover two months. We empirically validate that our approach significantly\noutperforms methods that optimize for short-term proxies or rely solely on\ndelayed rewards, as demonstrated by an A/B test in a recommendation system that\nserves hundreds of millions of users.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07761v1",
    "published_date": "2025-01-14 00:28:26 UTC",
    "updated_date": "2025-01-14 00:28:26 UTC"
  },
  {
    "arxiv_id": "2503.15494v1",
    "title": "AI-Powered Assistive Technologies for Visual Impairment",
    "authors": [
      "Prudhvi Naayini",
      "Praveen Kumar Myakala",
      "Chiranjeevi Bura",
      "Anil Kumar Jonnalagadda",
      "Srikanth Kamatala"
    ],
    "abstract": "Artificial Intelligence (AI) is revolutionizing assistive technologies. It\noffers innovative solutions to enhance the quality of life for individuals with\nvisual impairments. This review examines the development, applications, and\nimpact of AI-powered tools in key domains, such as computer vision, natural\nlanguage processing (NLP), and wearable devices. Specific advancements include\nobject recognition for identifying everyday items, scene description for\nunderstanding surroundings, and NLP-driven text-to-speech systems for accessing\ndigital information. Assistive technologies like smart glasses, smartphone\napplications, and AI-enabled navigation aids are discussed, demonstrating their\nability to support independent travel, facilitate social interaction, and\nincrease access to education and employment opportunities.\n  The integration of deep learning models, multimodal interfaces, and real-time\ndata processing has transformed the functionality and usability of these tools,\nfostering inclusivity and empowerment. This article also addresses critical\nchallenges, including ethical considerations, affordability, and adaptability\nin diverse environments. Future directions highlight the need for\ninterdisciplinary collaboration to refine these technologies, ensuring\nequitable access and sustainable innovation. By providing a comprehensive\noverview, this review underscores AI's transformative potential in promoting\nindependence, enhancing accessibility, and fostering social inclusion for\nvisually impaired individuals.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15494v1",
    "published_date": "2025-01-14 00:04:02 UTC",
    "updated_date": "2025-01-14 00:04:02 UTC"
  }
]