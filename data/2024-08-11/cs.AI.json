{
  "date": "2024-08-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-08-11 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 应用的安全性、效率优化和跨领域整合，涵盖了 AI 生成内容的信任问题、LLM 攻击防御、脑科学启发的 AI 解释性模型，以及高效的图像处理和强化学习方法。其中，AI 在医疗中的过度信任风险和 LLM 攻击机制令人印象深刻，尽管没有知名学者主导，但这些主题具有潜在话题度。\n\n下面，我挑选并简要讨论几篇关键论文，先从重要性和话题度高的入手（如 AI 安全和高效模型），然后快速掠过其他相关或次要内容。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 重点论文讨论\n\n**1. 人们过度信任 AI 生成的医疗响应，并视其为与医生相当的有效（People over trust AI-generated medical responses and view them to be as valid as doctors, despite low accuracy）**  \n这篇论文揭示了非专业人士对 AI 生成医疗响应的过度信任问题。即使 AI 响应准确率低，用户仍倾向于视其为可靠，导致潜在误诊风险。主要贡献：通过实验证明，高准确 AI 响应被过度信任，低准确 AI 响应可能引发有害行为，这对 AI 在医疗中的伦理应用有重要启示。\n\n**2. LLM-Based Robust Product Classification in Commerce and Compliance（基于 LLM 的鲁棒产品分类在商业和合规中的应用）**  \n论文提出使用大型语言模型（LLMs）处理产品分类的实际挑战，如不完整描述。主要发现：LLMs 通过 in-context learning 在不完整数据中表现出色，比传统监督方法更鲁棒，适用于电商和国际贸易的合规优化。\n\n**3. Kov: Transferable and Naturalistic Black-Box LLM Attacks using Markov Decision Processes and Tree Search（Kov: 使用马尔可夫决策过程和树搜索的传输性自然黑盒 LLM 攻击）**  \n这篇印象深刻的研究将红队攻击建模为马尔可夫决策过程（MDP），使用 Monte Carlo 树搜索快速发现 LLM 的有害行为。主要贡献：仅需少量查询（如 10 次）即可攻破 GPT-3.5，但 GPT-4 更抗性，强调了 LLM 安全性的紧迫性。\n\n**4. The Cognitive Revolution in Interpretability: From Explaining Behavior to Interpreting Representations and Algorithms（认知革命在可解释性中的应用：从解释行为到解读表示和算法）**  \n论文将机械可解释性（MI）与认知科学联系，提出一个分类框架，区分语义和算法解释。主要发现：AI 可解释性正像 20 世纪心理学一样转向内部表示，这为深度学习模型的解释提供新路径，具有跨领域启发。\n\n**5. Post-Training Sparse Attention with Double Sparsity（使用双重稀疏性的训练后稀疏注意力）**  \n针对 LLM 的推理瓶颈，论文引入“双重稀疏性”技术，结合 token 和 channel 稀疏减少 KV 缓存访问。主要贡献：在 Llama-2 和 Mixtral 等模型上，实现高达 14.1 倍的注意力加速和 16.3 倍的解码速度提升，同时保持准确性。\n\n**6. Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm（分治预测编码：一种结构化贝叶斯推理算法）**  \n论文提出分治预测编码（DCPC）算法，改进了预测编码在高维问题中的性能。主要发现：DCPC 比传统变分方法更准确，支持脑科学中的“惊喜”信号解释，并提供开源实现。\n\n**7. Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve Partially Observable Markov Decision Processes（利用基于知识图谱的人类-like 记忆系统解决部分可观测马尔可夫决策过程）**  \n这篇论文使用知识图谱（KG）模拟人类记忆，帮助 AI 在 POMDP 中导航和决策。主要贡献：训练代理捕获隐藏状态，提高了记忆管理策略的可解释性和可重用性。\n\n**8. Root Cause Attribution of Delivery Risks via Causal Discovery with Reinforcement Learning（通过因果发现和强化学习归因交付风险的根本原因）**  \n论文整合因果发现和强化学习，分析供应链延迟原因。主要发现：准确识别关键变量（如运输模式），提供优化策略，提升供应链效率。\n\n**9. Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences（时间创造空间：在编码连续感官体验的网络中出现位置场）**  \n基于脑科学，论文显示连续感官输入可产生海马体-like 位置场（place fields）。主要贡献：模拟海马体记忆，支持空间导航，并预测环境变化对位置场的影响。\n\n**10. HateSieve: A Contrastive Learning Framework for Detecting and Segmenting Hateful Content in Multimodal Memes（HateSieve: 用于检测和分割多模态 meme 中仇恨内容的对比学习框架）**  \n论文提出框架检测 meme 中的仇恨元素，使用对比学习和图像-文本对齐。主要发现：在 Hateful Meme 数据集上超越现有模型，提供精确分割，强调 AI 在内容审核中的应用。\n\n### 其他相关论文快速掠过\n剩余论文中，一些次要或特定领域的如第9篇（Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection，实时瞌睡检测使用眼部比率和面部 landmarks）仅简单优化了医疗监测算法；第19篇（Seg-CycleGAN: SAR-to-optical image translation guided by a downstream task，SAR 到光学图像转换）改进了图像翻译但影响有限；第29篇（Top Pass: Improve Code Generation by Pass@k-Maximized Code Ranking，Top Pass: 通过 Pass@k 最大化代码排名改善代码生成）提升了代码生成效率，但不具广泛话题度。这些论文的核心在于技术优化，如稀疏性、强化学习或图像处理，但未有突破性发现，故从简提及。\n\n总之，今天的 arXiv 更新突显 AI 的双刃剑——从安全风险到高效创新，读者可关注 AI 伦理和脑科学相关论文进行深入阅读。明天的快报再见！",
  "papers": [
    {
      "arxiv_id": "2408.15266v1",
      "title": "People over trust AI-generated medical responses and view them to be as valid as doctors, despite low accuracy",
      "title_zh": "人们过度信任 AI",
      "authors": [
        "Shruthi Shekar",
        "Pat Pataranutaporn",
        "Chethan Sarabu",
        "Guillermo A. Cecchi",
        "Pattie Maes"
      ],
      "abstract": "This paper presents a comprehensive analysis of how AI-generated medical\nresponses are perceived and evaluated by non-experts. A total of 300\nparticipants gave evaluations for medical responses that were either written by\na medical doctor on an online healthcare platform, or generated by a large\nlanguage model and labeled by physicians as having high or low accuracy.\nResults showed that participants could not effectively distinguish between\nAI-generated and Doctors' responses and demonstrated a preference for\nAI-generated responses, rating High Accuracy AI-generated responses as\nsignificantly more valid, trustworthy, and complete/satisfactory. Low Accuracy\nAI-generated responses on average performed very similar to Doctors' responses,\nif not more. Participants not only found these low-accuracy AI-generated\nresponses to be valid, trustworthy, and complete/satisfactory but also\nindicated a high tendency to follow the potentially harmful medical advice and\nincorrectly seek unnecessary medical attention as a result of the response\nprovided. This problematic reaction was comparable if not more to the reaction\nthey displayed towards doctors' responses. This increased trust placed on\ninaccurate or inappropriate AI-generated medical advice can lead to\nmisdiagnosis and harmful consequences for individuals seeking help. Further,\nparticipants were more trusting of High Accuracy AI-generated responses when\ntold they were given by a doctor and experts rated AI-generated responses\nsignificantly higher when the source of the response was unknown. Both experts\nand non-experts exhibited bias, finding AI-generated responses to be more\nthorough and accurate than Doctors' responses but still valuing the involvement\nof a Doctor in the delivery of their medical advice. Ensuring AI systems are\nimplemented with medical professionals should be the future of using AI for the\ndelivery of medical advice.",
      "tldr_zh": "这篇论文通过调查300名非专家，分析了他们对AI-generated medical responses的感知和评估，比较了AI生成（高或低准确性）和医生撰写的医疗响应。结果显示，参与者难以区分AI和医生响应，并更倾向于高准确性AI响应，认为其更有效、可信和完整，甚至对低准确性AI响应也表现出类似或更高的信任，导致可能遵循有害建议或寻求不必要医疗。研究还发现，专家和非专家均存在偏见，更青睐AI响应，尤其是当其来源未知或伪装为医生时。论文强调，未来AI系统应与医疗专业人士结合，以减少误诊和有害后果的风险。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15266v1",
      "published_date": "2024-08-11 23:41:28 UTC",
      "updated_date": "2024-08-11 23:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:28:21.271832"
    },
    {
      "arxiv_id": "2408.05874v2",
      "title": "LLM-Based Robust Product Classification in Commerce and Compliance",
      "title_zh": "基于 LLM 的稳健产品分类在商业和合规中",
      "authors": [
        "Sina Gholamian",
        "Gianfranco Romani",
        "Bartosz Rudnikowicz",
        "Stavroula Skylaki"
      ],
      "abstract": "Product classification is a crucial task in international trade, as\ncompliance regulations are verified and taxes and duties are applied based on\nproduct categories. Manual classification of products is time-consuming and\nerror-prone, and the sheer volume of products imported and exported renders the\nmanual process infeasible. Consequently, e-commerce platforms and enterprises\ninvolved in international trade have turned to automatic product classification\nusing machine learning. However, current approaches do not consider the\nreal-world challenges associated with product classification, such as very\nabbreviated and incomplete product descriptions. In addition, recent\nadvancements in generative Large Language Models (LLMs) and their reasoning\ncapabilities are mainly untapped in product classification and e-commerce. In\nthis research, we explore the real-life challenges of industrial classification\nand we propose data perturbations that allow for realistic data simulation.\nFurthermore, we employ LLM-based product classification to improve the\nrobustness of the prediction in presence of incomplete data. Our research shows\nthat LLMs with in-context learning outperform the supervised approaches in the\nclean-data scenario. Additionally, we illustrate that LLMs are significantly\nmore robust than the supervised approaches when data attacks are present.",
      "tldr_zh": "本研究探讨了基于LLM（Large Language Models）的鲁棒产品分类方法，以应对国际贸易中产品描述简短不完整等现实挑战。论文提出数据扰动技术来模拟真实数据，并利用LLM的in-context learning能力进行分类，提高了在不完整数据场景下的预测鲁棒性。实验结果显示，LLM在干净数据条件下优于监督学习方法，且在数据攻击存在时表现出显著更高的鲁棒性。该方法为电商和合规领域提供了更可靠的自动分类解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera-ready version for Customizable NLP Workshop at EMNLP 2024. 11\n  pages",
      "pdf_url": "http://arxiv.org/pdf/2408.05874v2",
      "published_date": "2024-08-11 22:59:32 UTC",
      "updated_date": "2024-10-15 16:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:28:28.619872"
    },
    {
      "arxiv_id": "2408.05861v2",
      "title": "Leveraging Knowledge Graph-Based Human-Like Memory Systems to Solve Partially Observable Markov Decision Processes",
      "title_zh": "翻译失败",
      "authors": [
        "Taewoon Kim",
        "Vincent François-Lavet",
        "Michael Cochez"
      ],
      "abstract": "Humans observe only part of their environment at any moment but can still\nmake complex, long-term decisions thanks to our long-term memory. To test how\nan AI can learn and utilize its long-term memory, we have developed a partially\nobservable Markov decision processes (POMDP) environment, where the agent has\nto answer questions while navigating a maze. The environment is completely\nknowledge graph (KG) based, where the hidden states are dynamic KGs. A KG is\nboth human- and machine-readable, making it easy to see what the agents\nremember and forget. We train and compare agents with different memory systems,\nto shed light on how human brains work when it comes to managing its own\nmemory. By repurposing the given learning objective as learning a memory\nmanagement policy, we were able to capture the most likely hidden state, which\nis not only interpretable but also reusable.",
      "tldr_zh": "该研究探讨了如何利用基于知识图谱（Knowledge Graph, KG）的类人记忆系统来解决部分可观察Markov决策过程（Partially Observable Markov Decision Processes, POMDP）。研究者开发了一个完全基于动态KG的环境，让代理在迷宫中导航并回答问题，同时观察代理的记忆和遗忘过程，以模拟人类大脑的记忆管理。相比传统方法，该框架通过将学习目标转化为记忆管理策略，成功捕获最可能的隐藏状态，提高了决策的可解释性和可重用性。实验结果表明，这种方法为AI模拟人类长期记忆提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05861v2",
      "published_date": "2024-08-11 21:04:14 UTC",
      "updated_date": "2024-08-18 19:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:28:40.309603"
    },
    {
      "arxiv_id": "2408.05860v2",
      "title": "Root Cause Attribution of Delivery Risks via Causal Discovery with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shi Bo",
        "Minheng Xiao"
      ],
      "abstract": "This paper presents a novel approach to root cause attribution of delivery\nrisks within supply chains by integrating causal discovery with reinforcement\nlearning. As supply chains become increasingly complex, traditional methods of\nroot cause analysis struggle to capture the intricate interrelationships\nbetween various factors, often leading to spurious correlations and suboptimal\ndecision-making. Our approach addresses these challenges by leveraging causal\ndiscovery to identify the true causal relationships between operational\nvariables, and reinforcement learning to iteratively refine the causal graph.\nThis method enables the accurate identification of key drivers of late\ndeliveries, such as shipping mode and delivery status, and provides actionable\ninsights for optimizing supply chain performance. We apply our approach to a\nreal-world supply chain dataset, demonstrating its effectiveness in uncovering\nthe underlying causes of delivery delays and offering strategies for mitigating\nthese risks. The findings have significant implications for improving\noperational efficiency, customer satisfaction, and overall profitability within\nsupply chains.",
      "tldr_zh": "这篇论文提出了一种将因果发现（causal discovery）和强化学习（reinforcement learning）相结合的新方法，用于供应链中交付风险的根本原因归因，以解决传统方法无法捕捉复杂变量关系的问题。该方法通过因果发现识别操作变量之间的真实因果关系，并利用强化学习迭代优化因果图，从而准确识别延迟交付的关键驱动因素，如运输模式和交付状态，并提供优化策略。在真实供应链数据集上的实验验证了该方法的有效性，为提升操作效率、客户满意度和整体盈利能力提供了重要见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05860v2",
      "published_date": "2024-08-11 20:52:51 UTC",
      "updated_date": "2025-01-28 04:04:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:28:53.477032"
    },
    {
      "arxiv_id": "2408.05859v1",
      "title": "The Cognitive Revolution in Interpretability: From Explaining Behavior to Interpreting Representations and Algorithms",
      "title_zh": "可解释性中的认知革命：从解释行为到解释表示和算法",
      "authors": [
        "Adam Davies",
        "Ashkan Khakzar"
      ],
      "abstract": "Artificial neural networks have long been understood as \"black boxes\": though\nwe know their computation graphs and learned parameters, the knowledge encoded\nby these weights and functions they perform are not inherently interpretable.\nAs such, from the early days of deep learning, there have been efforts to\nexplain these models' behavior and understand them internally; and recently,\nmechanistic interpretability (MI) has emerged as a distinct research area\nstudying the features and implicit algorithms learned by foundation models such\nas large language models. In this work, we aim to ground MI in the context of\ncognitive science, which has long struggled with analogous questions in\nstudying and explaining the behavior of \"black box\" intelligent systems like\nthe human brain. We leverage several important ideas and developments in the\nhistory of cognitive science to disentangle divergent objectives in MI and\nindicate a clear path forward. First, we argue that current methods are ripe to\nfacilitate a transition in deep learning interpretation echoing the \"cognitive\nrevolution\" in 20th-century psychology that shifted the study of human\npsychology from pure behaviorism toward mental representations and processing.\nSecond, we propose a taxonomy mirroring key parallels in computational\nneuroscience to describe two broad categories of MI research, semantic\ninterpretation (what latent representations are learned and used) and\nalgorithmic interpretation (what operations are performed over representations)\nto elucidate their divergent goals and objects of study. Finally, we elaborate\nthe parallels and distinctions between various approaches in both categories,\nanalyze the respective strengths and weaknesses of representative works,\nclarify underlying assumptions, outline key challenges, and discuss the\npossibility of unifying these modes of interpretation under a common framework.",
      "tldr_zh": "这篇论文探讨了神经网络的解释性问题，将Mechanistic Interpretability (MI)置于认知科学背景下，借鉴其历史从行为主义向心理表示和处理的“认知革命”转变。该研究提出一个分类框架，将MI分为语义解释（semantic interpretation，关注神经网络学习和使用的潜在表示）和算法解释（algorithmic interpretation，聚焦于表示上的操作），以阐明二者的目标和差异。论文分析了这些方法的优势、弱点、潜在假设和挑战，并探讨了在统一框架下整合这些解释方式的可能性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05859v1",
      "published_date": "2024-08-11 20:50:16 UTC",
      "updated_date": "2024-08-11 20:50:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:29:05.215633"
    },
    {
      "arxiv_id": "2408.08899v1",
      "title": "Kov: Transferable and Naturalistic Black-Box LLM Attacks using Markov Decision Processes and Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Robert J. Moss"
      ],
      "abstract": "Eliciting harmful behavior from large language models (LLMs) is an important\ntask to ensure the proper alignment and safety of the models. Often when\ntraining LLMs, ethical guidelines are followed yet alignment failures may still\nbe uncovered through red teaming adversarial attacks. This work frames the\nred-teaming problem as a Markov decision process (MDP) and uses Monte Carlo\ntree search to find harmful behaviors of black-box, closed-source LLMs. We\noptimize token-level prompt suffixes towards targeted harmful behaviors on\nwhite-box LLMs and include a naturalistic loss term, log-perplexity, to\ngenerate more natural language attacks for better interpretability. The\nproposed algorithm, Kov, trains on white-box LLMs to optimize the adversarial\nattacks and periodically evaluates responses from the black-box LLM to guide\nthe search towards more harmful black-box behaviors. In our preliminary study,\nresults indicate that we can jailbreak black-box models, such as GPT-3.5, in\nonly 10 queries, yet fail on GPT-4$-$which may indicate that newer models are\nmore robust to token-level attacks. All work to reproduce these results is open\nsourced (https://github.com/sisl/Kov.jl).",
      "tldr_zh": "这篇论文提出Kov算法，利用Markov Decision Processes (MDP)和Monte Carlo Tree Search (MCTS)来框架化红队测试问题，从而发现黑盒LLMs的有害行为。Kov通过在白盒LLMs上优化token-level提示后缀并引入log-perplexity损失，使攻击更自然且可解释，并定期评估黑盒模型响应以引导搜索优化。在初步实验中，该算法能在10个查询内攻破GPT-3.5，但对GPT-4无效，这表明新模型对token-level攻击更robust，所有代码已开源。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.08899v1",
      "published_date": "2024-08-11 20:31:52 UTC",
      "updated_date": "2024-08-11 20:31:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:29:17.905901"
    },
    {
      "arxiv_id": "2408.07092v2",
      "title": "Post-Training Sparse Attention with Double Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Yang",
        "Ying Sheng",
        "Joseph E. Gonzalez",
        "Ion Stoica",
        "Lianmin Zheng"
      ],
      "abstract": "The inference process for large language models is slow and memory-intensive,\nwith one of the most critical bottlenecks being excessive Key-Value (KV) cache\naccesses. This paper introduces \"Double Sparsity,\" a novel post-training sparse\nattention technique designed to alleviate this bottleneck by reducing KV cache\naccess. Double Sparsity combines token sparsity, which focuses on utilizing\nonly the important tokens for computing self-attention, with channel sparsity,\nan approach that uses important feature channels for identifying important\ntokens. Our key insight is that the pattern of channel sparsity is relatively\nstatic, allowing us to use offline calibration to make it efficient at runtime,\nthereby enabling accurate and efficient identification of important tokens.\nMoreover, this method can be combined with offloading to achieve significant\nmemory usage reduction. Experimental results demonstrate that Double Sparsity\ncan achieve $\\frac{1}{16}$ token and channel sparsity with minimal impact on\naccuracy across various tasks, including wiki-2 perplexity, key-value\nretrieval, and long context benchmarks with models including Llama-2-7B,\nLlama-2-70B, and Mixtral-8x7B. It brings up to a 14.1$\\times$ acceleration in\nattention operations and a 1.9$\\times$ improvement in end-to-end inference on\nGPUs. With offloading, it achieves a decoding speed acceleration of\n16.3$\\times$ compared to state-of-the-art solutions at a sequence length of\n256K. Our code is publicly available at\nhttps://github.com/andy-yang-1/DoubleSparse.",
      "tldr_zh": "这篇论文引入了 Double Sparsity，一种后训练稀疏注意力技术，旨在减少大型语言模型中过多的 Key-Value (KV) cache 访问，从而缓解推理过程的缓慢和内存密集问题。该方法结合 token sparsity（仅使用重要 tokens 计算自注意力）和 channel sparsity（通过重要特征通道识别关键 tokens），并利用 channel sparsity 的静态模式进行离线校准，以实现高效运行。实验结果显示，在模型如 Llama-2-7B 和 Mixtral-8x7B 上，Double Sparsity 实现了高达 14.1× 的注意力操作加速和 16.3× 的解码速度改进，同时对任务准确性影响最小；结合 offloading 后，还能显著降低内存使用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.07092v2",
      "published_date": "2024-08-11 18:40:36 UTC",
      "updated_date": "2024-08-18 17:27:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:29:31.396594"
    },
    {
      "arxiv_id": "2408.05842v5",
      "title": "Open Role-Playing with Delta-Engines",
      "title_zh": "翻译失败",
      "authors": [
        "Hongqiu Wu",
        "Zekai Xu",
        "Tianyang Xu",
        "Shize Wei",
        "Yan Wang",
        "Jiale Hong",
        "Weiqi Wu",
        "Hai Zhao"
      ],
      "abstract": "Game roles can be reflections of personas from a parallel world. In this\npaper, we propose a new style of game-play to bridge self-expression and\nrole-playing: \\emph{open role-playing games (ORPGs)}, where players are allowed\nto craft and embody their unique characters in the game world. Our vision is\nthat, in the real world, we are individually similar when we are born, but we\ngrow into unique ones as a result of the strongly different choices we make\nafterward. Therefore, in an ORPG, we empower players with freedom to decide\ntheir own growing curves through natural language inputs, ultimately becoming\nunique characters. To technically do this, we propose a special engine called\nDelta-Engine. This engine is not a traditional game engine used for game\ndevelopment, but serves as an in-game module to provide new game-play\nexperiences. A delta-engine consists of two components, a base engine and a\nneural proxy. The base engine programs the prototype of the character as well\nas the foundational settings of the game; the neural proxy is an LLM, which\nrealizes the character growth by generating new code snippets on the base\nengine incrementally. In this paper, we self-develop a specific ORPG based on\ndelta-engines. It is adapted from the popular animated series ``Pok\\'emon''. We\npresent our efforts in generating out-of-domain and interesting role data in\nthe development process as well as accessing the performance of a delta-engine.\nWhile the empirical results in this work are specific, we aim for them to\nprovide general insights for future games.",
      "tldr_zh": "本论文提出了一种新的游戏风格——Open Role-Playing Games (ORPGs)，允许玩家通过自然语言输入自由创建和成长独特角色，桥接自我的表达与角色扮演。作者引入Delta-Engine框架，该框架由base engine（提供角色原型和基础游戏设置）和neural proxy（一个LLM，用于增量生成代码实现角色发展）组成。通过改编自《Pokémon》的游戏进行实验，展示了Delta-Engine在生成创新角色数据方面的性能，并为未来游戏设计提供通用洞见。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05842v5",
      "published_date": "2024-08-11 18:32:29 UTC",
      "updated_date": "2025-03-07 04:13:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:29:41.723076"
    },
    {
      "arxiv_id": "2408.05836v1",
      "title": "Real-Time Drowsiness Detection Using Eye Aspect Ratio and Facial Landmark Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Varun Shiva Krishna Rupani",
        "Velpooru Venkata Sai Thushar",
        "Kondadi Tejith"
      ],
      "abstract": "Drowsiness detection is essential for improving safety in areas such as\ntransportation and workplace health. This study presents a real-time system\ndesigned to detect drowsiness using the Eye Aspect Ratio (EAR) and facial\nlandmark detection techniques. The system leverages Dlibs pre-trained shape\npredictor model to accurately detect and monitor 68 facial landmarks, which are\nused to compute the EAR. By establishing a threshold for the EAR, the system\nidentifies when eyes are closed, indicating potential drowsiness. The process\ninvolves capturing a live video stream, detecting faces in each frame,\nextracting eye landmarks, and calculating the EAR to assess alertness. Our\nexperiments show that the system reliably detects drowsiness with high accuracy\nwhile maintaining low computational demands. This study offers a strong\nsolution for real-time drowsiness detection, with promising applications in\ndriver monitoring and workplace safety. Future research will investigate\nincorporating additional physiological and contextual data to further enhance\ndetection accuracy and reliability.",
      "tldr_zh": "本研究提出了一种实时疲劳检测系统，使用 Eye Aspect Ratio (EAR) 和 Facial Landmark Detection 技术，以提升交通和 workplace 安全。系统利用 Dlib 的预训练 shape predictor 模型检测 68 个面部 landmarks，并通过计算 EAR 和设定阈值来识别眼睛闭合状态，从而评估警觉性。实验结果显示，该系统在实时视频流处理中表现出高准确率和低计算需求，具有良好的应用潜力，如驾驶员监控和工作场所安全。未来工作将整合更多生理和 contextual 数据，进一步提高检测的准确性和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05836v1",
      "published_date": "2024-08-11 17:34:24 UTC",
      "updated_date": "2024-08-11 17:34:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:29:52.812946"
    },
    {
      "arxiv_id": "2408.05834v2",
      "title": "Divide-and-Conquer Predictive Coding: a structured Bayesian inference algorithm",
      "title_zh": "分治预测编码：一种结构化的贝叶斯推理算法",
      "authors": [
        "Eli Sennesh",
        "Hao Wu",
        "Tommaso Salvatori"
      ],
      "abstract": "Unexpected stimuli induce \"error\" or \"surprise\" signals in the brain. The\ntheory of predictive coding promises to explain these observations in terms of\nBayesian inference by suggesting that the cortex implements variational\ninference in a probabilistic graphical model. However, when applied to machine\nlearning tasks, this family of algorithms has yet to perform on par with other\nvariational approaches in high-dimensional, structured inference problems. To\naddress this, we introduce a novel predictive coding algorithm for structured\ngenerative models, that we call divide-and-conquer predictive coding (DCPC).\nDCPC differs from other formulations of predictive coding, as it respects the\ncorrelation structure of the generative model and provably performs\nmaximum-likelihood updates of model parameters, all without sacrificing\nbiological plausibility. Empirically, DCPC achieves better numerical\nperformance than competing algorithms and provides accurate inference in a\nnumber of problems not previously addressed with predictive coding. We provide\nan open implementation of DCPC in Pyro on Github.",
      "tldr_zh": "该研究针对大脑对意外刺激的“错误”或“惊喜”信号，基于预测编码（predictive coding）理论提出了一种结构化的贝叶斯推理（Bayesian inference）算法，名为divide-and-conquer predictive coding (DCPC)。DCPC 通过分治策略尊重生成模型的相关结构，同时进行最大似然（maximum-likelihood）参数更新，并保持生物学合理性，以解决高维结构化推理问题的挑战。实验结果显示，DCPC 在性能上优于其他变分方法（variational approaches），并在多种问题上实现了准确推理；该算法的开源实现已在 Pyro 上提供。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "stat.ML",
      "comment": "22 pages, 5 figures, accepted to Neural Information Processing\n  Systems (NeurIPS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05834v2",
      "published_date": "2024-08-11 17:29:03 UTC",
      "updated_date": "2024-10-17 02:10:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:30:03.929792"
    },
    {
      "arxiv_id": "2408.05831v1",
      "title": "Robust Domain Generalization for Multi-modal Object Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxin Qiao",
        "Keqin Li",
        "Junhong Lin",
        "Rong Wei",
        "Chufeng Jiang",
        "Yang Luo",
        "Haoyu Yang"
      ],
      "abstract": "In multi-label classification, machine learning encounters the challenge of\ndomain generalization when handling tasks with distributions differing from the\ntraining data. Existing approaches primarily focus on vision object recognition\nand neglect the integration of natural language. Recent advancements in\nvision-language pre-training leverage supervision from extensive\nvisual-language pairs, enabling learning across diverse domains and enhancing\nrecognition in multi-modal scenarios. However, these approaches face\nlimitations in loss function utilization, generality across backbones, and\nclass-aware visual fusion. This paper proposes solutions to these limitations\nby inferring the actual loss, broadening evaluations to larger vision-language\nbackbones, and introducing Mixup-CLIPood, which incorporates a novel mix-up\nloss for enhanced class-aware visual fusion. Our method demonstrates superior\nperformance in domain generalization across multiple datasets.",
      "tldr_zh": "在多标签分类任务中，机器学习面临领域泛化（domain generalization）的挑战，特别是当处理与训练数据分布不同的任务时，且现有方法主要关注视觉对象识别而忽略自然语言的整合。视觉-语言预训练（vision-language pre-training）利用大量视觉-语言对进行监督学习，以提升多模态场景下的识别能力，但仍存在损失函数利用、骨干网络通用性和类别感知视觉融合的局限性。本文提出改进方案，包括推断实际损失、扩展评估至更大的视觉-语言骨干网络，以及引入Mixup-CLIPood，这是一种新型mix-up损失，用于增强类别感知视觉融合。该方法在多个数据集上展示了优越的领域泛化性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures. This is a preprint version of the article. The\n  final version will be published in the proceedings of the IEEE conference",
      "pdf_url": "http://arxiv.org/pdf/2408.05831v1",
      "published_date": "2024-08-11 17:13:21 UTC",
      "updated_date": "2024-08-11 17:13:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:30:18.569596"
    },
    {
      "arxiv_id": "2408.15263v1",
      "title": "S4DL: Shift-sensitive Spatial-Spectral Disentangling Learning for Hyperspectral Image Unsupervised Domain Adaptation",
      "title_zh": "S4DL：移位敏感的空间-光谱解耦学习，用于高光谱图像无监督域适应",
      "authors": [
        "Jie Feng",
        "Tianshu Zhang",
        "Junpeng Zhang",
        "Ronghua Shang",
        "Weisheng Dong",
        "Guangming Shi",
        "Licheng Jiao"
      ],
      "abstract": "Unsupervised domain adaptation techniques, extensively studied in\nhyperspectral image (HSI) classification, aim to use labeled source domain data\nand unlabeled target domain data to learn domain invariant features for\ncross-scene classification. Compared to natural images, numerous spectral bands\nof HSIs provide abundant semantic information, but they also increase the\ndomain shift significantly. In most existing methods, both explicit alignment\nand implicit alignment simply align feature distribution, ignoring domain\ninformation in the spectrum. We noted that when the spectral channel between\nsource and target domains is distinguished obviously, the transfer performance\nof these methods tends to deteriorate. Additionally, their performance\nfluctuates greatly owing to the varying domain shifts across various datasets.\nTo address these problems, a novel shift-sensitive spatial-spectral\ndisentangling learning (S4DL) approach is proposed. In S4DL, gradient-guided\nspatial-spectral decomposition is designed to separate domain-specific and\ndomain-invariant representations by generating tailored masks under the\nguidance of the gradient from domain classification. A shift-sensitive adaptive\nmonitor is defined to adjust the intensity of disentangling according to the\nmagnitude of domain shift. Furthermore, a reversible neural network is\nconstructed to retain domain information that lies in not only in semantic but\nalso the shallow-level detailed information. Extensive experimental results on\nseveral cross-scene HSI datasets consistently verified that S4DL is better than\nthe state-of-the-art UDA methods. Our source code will be available at\nhttps://github.com/xdu-jjgs/S4DL.",
      "tldr_zh": "本论文提出了一种移位敏感的空间-光谱分离学习方法（S4DL），用于高光谱图像（HSI）的无监督域适应（UDA），旨在解决现有方法忽略光谱中域信息导致的性能下降问题。S4DL 通过梯度引导的空间-光谱分解生成定制掩码，以分离域特定和域不变特征；引入移位敏感自适应监控根据域移位幅度调整分离强度；并构建可逆神经网络保留语义和浅层细节信息。实验结果显示，在多个跨场景 HSI 数据集上，S4DL 比最先进 UDA 方法表现出色，验证了其稳定性和有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.15263v1",
      "published_date": "2024-08-11 15:58:24 UTC",
      "updated_date": "2024-08-11 15:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:30:31.675474"
    },
    {
      "arxiv_id": "2408.05804v1",
      "title": "A Single Goal is All You Need: Skills and Exploration Emerge from Contrastive RL without Rewards, Demonstrations, or Subgoals",
      "title_zh": "翻译失败",
      "authors": [
        "Grace Liu",
        "Michael Tang",
        "Benjamin Eysenbach"
      ],
      "abstract": "In this paper, we present empirical evidence of skills and directed\nexploration emerging from a simple RL algorithm long before any successful\ntrials are observed. For example, in a manipulation task, the agent is given a\nsingle observation of the goal state and learns skills, first for moving its\nend-effector, then for pushing the block, and finally for picking up and\nplacing the block. These skills emerge before the agent has ever successfully\nplaced the block at the goal location and without the aid of any reward\nfunctions, demonstrations, or manually-specified distance metrics. Once the\nagent has learned to reach the goal state reliably, exploration is reduced.\nImplementing our method involves a simple modification of prior work and does\nnot require density estimates, ensembles, or any additional hyperparameters.\nIntuitively, the proposed method seems like it should be terrible at\nexploration, and we lack a clear theoretical understanding of why it works so\neffectively, though our experiments provide some hints.",
      "tldr_zh": "本论文展示了在对比 RL（Contrastive RL）中，仅通过一个单一目标状态观察，代理（agent）即可自发学习技能和进行定向探索，而无需奖励函数、演示或子目标。例如，在操作任务中，代理先学会移动末端执行器，然后推动方块，最后实现拾取和放置方块，这些技能均在成功达到目标前出现。作者的方法是对现有工作的简单修改，不需要密度估计、集成或额外超参数，一旦代理可靠地达到目标，探索就会减少。尽管直观上该方法似乎不利于探索，但实验结果证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code and videos: https://graliuce.github.io/sgcrl/",
      "pdf_url": "http://arxiv.org/pdf/2408.05804v1",
      "published_date": "2024-08-11 15:49:00 UTC",
      "updated_date": "2024-08-11 15:49:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:30:42.265534"
    },
    {
      "arxiv_id": "2408.05798v2",
      "title": "Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaoze Wang",
        "Ronald W. Di Tullio",
        "Spencer Rooke",
        "Vijay Balasubramanian"
      ],
      "abstract": "The vertebrate hippocampus is believed to use recurrent connectivity in area\nCA3 to support episodic memory recall from partial cues. This brain area also\ncontains place cells, whose location-selective firing fields implement maps\nsupporting spatial memory. Here we show that place cells emerge in networks\ntrained to remember temporally continuous sensory episodes. We model CA3 as a\nrecurrent autoencoder that recalls and reconstructs sensory experiences from\nnoisy and partially occluded observations by agents traversing simulated rooms.\nThe agents move in realistic trajectories modeled from rodents and environments\nare modeled as high-dimensional sensory experience maps. Training our\nautoencoder to pattern-complete and reconstruct experiences with a constraint\non total activity causes spatially localized firing fields, i.e., place cells,\nto emerge in the encoding layer. The emergent place fields reproduce key\naspects of hippocampal phenomenology: a) remapping (maintenance of and\nreversion to distinct learned maps in different environments), implemented via\nrepositioning of experience manifolds in the network's hidden layer, b)\northogonality of spatial representations in different arenas, c) robust place\nfield emergence in differently shaped rooms, with single units showing multiple\nplace fields in large or complex spaces, and d) slow representational drift of\nplace fields. We argue that these results arise because continuous traversal of\nspace makes sensory experience temporally continuous. We make testable\npredictions: a) rapidly changing sensory context will disrupt place fields, b)\nplace fields will form even if recurrent connections are blocked, but reversion\nto previously learned representations upon remapping will be abolished, c) the\ndimension of temporally smooth experience sets the dimensionality of place\nfields, including during virtual navigation of abstract spaces.",
      "tldr_zh": "本文研究了在编码连续感官经历的网络中，位置细胞（place cells）的自发出现，模拟了海马体 CA3 区域如何通过循环连接支持空间记忆。作者使用一个循环自编码器（recurrent autoencoder）模型训练代理从噪声和部分遮挡的观察中重建经历，并添加活动总和约束，导致编码层产生了空间本地化的 firing fields。结果显示，这些 emergent place fields 复制了海马体关键现象，如 remapping、正交表示和缓慢的代表漂移，并提出了可测试预测，例如快速变化的感官上下文会破坏 place fields。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05798v2",
      "published_date": "2024-08-11 15:17:11 UTC",
      "updated_date": "2025-01-29 22:01:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:31:04.953024"
    },
    {
      "arxiv_id": "2408.05795v1",
      "title": "A Meta-Engine Framework for Interleaved Task and Motion Planning using Topological Refinements",
      "title_zh": "翻译失败",
      "authors": [
        "Elisa Tosello",
        "Alessandro Valentini",
        "Andrea Micheli"
      ],
      "abstract": "Task And Motion Planning (TAMP) is the problem of finding a solution to an\nautomated planning problem that includes discrete actions executable by\nlow-level continuous motions. This field is gaining increasing interest within\nthe robotics community, as it significantly enhances robot's autonomy in\nreal-world applications. Many solutions and formulations exist, but no clear\nstandard representation has emerged. In this paper, we propose a general and\nopen-source framework for modeling and benchmarking TAMP problems. Moreover, we\nintroduce an innovative meta-technique to solve TAMP problems involving moving\nagents and multiple task-state-dependent obstacles. This approach enables using\nany off-the-shelf task planner and motion planner while leveraging a geometric\nanalysis of the motion planner's search space to prune the task planner's\nexploration, enhancing its efficiency. We also show how to specialize this\nmeta-engine for the case of an incremental SMT-based planner. We demonstrate\nthe effectiveness of our approach across benchmark problems of increasing\ncomplexity, where robots must navigate environments with movable obstacles.\nFinally, we integrate state-of-the-art TAMP algorithms into our framework and\ncompare their performance with our achievements.",
      "tldr_zh": "该论文提出一个通用开源框架，用于Task and Motion Planning (TAMP)问题的建模和基准测试，以提升机器人在真实场景中的自主性。创新的元技术通过拓扑细化对运动规划器的搜索空间进行几何分析，修剪任务规划器的探索，从而提高效率，并支持任何现成的任务和运动规划器。实验结果显示，该方法在涉及移动代理和任务状态依赖障碍的基准问题上表现出色，与最先进的TAMP算法相比，展示了显著的性能提升。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "To appear in ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05795v1",
      "published_date": "2024-08-11 14:57:57 UTC",
      "updated_date": "2024-08-11 14:57:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:31:06.654252"
    },
    {
      "arxiv_id": "2408.05794v2",
      "title": "HateSieve: A Contrastive Learning Framework for Detecting and Segmenting Hateful Content in Multimodal Memes",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanyu Su",
        "Yansong Li",
        "Diana Inkpen",
        "Nathalie Japkowicz"
      ],
      "abstract": "Amidst the rise of Large Multimodal Models (LMMs) and their widespread\napplication in generating and interpreting complex content, the risk of\npropagating biased and harmful memes remains significant. Current safety\nmeasures often fail to detect subtly integrated hateful content within\n``Confounder Memes''. To address this, we introduce \\textsc{HateSieve}, a new\nframework designed to enhance the detection and segmentation of hateful\nelements in memes. \\textsc{HateSieve} features a novel Contrastive Meme\nGenerator that creates semantically paired memes, a customized triplet dataset\nfor contrastive learning, and an Image-Text Alignment module that produces\ncontext-aware embeddings for accurate meme segmentation. Empirical experiments\non the Hateful Meme Dataset show that \\textsc{HateSieve} not only surpasses\nexisting LMMs in performance with fewer trainable parameters but also offers a\nrobust mechanism for precisely identifying and isolating hateful content.\n\\textcolor{red}{Caution: Contains academic discussions of hate speech; viewer\ndiscretion advised.}",
      "tldr_zh": "该研究提出HateSieve框架，利用对比学习方法来检测和分割多模态memes中的仇恨内容，针对Large Multimodal Models (LMMs)在处理“Confounder Memes”时存在的偏见传播风险。框架包括Contrastive Meme Generator用于生成语义配对的memes、定制的三元组数据集支持对比学习，以及Image-Text Alignment模块提供上下文感知的嵌入以实现精确分割。在Hateful Meme Dataset上的实验表明，HateSieve在性能上超越现有LMMs，同时使用更少的训练参数，并为识别和隔离仇恨元素提供可靠机制。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MM",
        "cs.SI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at NAACL 2025 Findings; camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2408.05794v2",
      "published_date": "2024-08-11 14:56:06 UTC",
      "updated_date": "2025-04-30 03:30:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:31:17.474652"
    },
    {
      "arxiv_id": "2408.05788v1",
      "title": "Continual Learning of Nonlinear Independent Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Boyang Sun",
        "Ignavier Ng",
        "Guangyi Chen",
        "Yifan Shen",
        "Qirong Ho",
        "Kun Zhang"
      ],
      "abstract": "Identifying the causal relations between interested variables plays a pivotal\nrole in representation learning as it provides deep insights into the dataset.\nIdentifiability, as the central theme of this approach, normally hinges on\nleveraging data from multiple distributions (intervention, distribution shift,\ntime series, etc.). Despite the exciting development in this field, a practical\nbut often overlooked problem is: what if those distribution shifts happen\nsequentially? In contrast, any intelligence possesses the capacity to abstract\nand refine learned knowledge sequentially -- lifelong learning. In this paper,\nwith a particular focus on the nonlinear independent component analysis (ICA)\nframework, we move one step forward toward the question of enabling models to\nlearn meaningful (identifiable) representations in a sequential manner, termed\ncontinual causal representation learning. We theoretically demonstrate that\nmodel identifiability progresses from a subspace level to a component-wise\nlevel as the number of distributions increases. Empirically, we show that our\nmethod achieves performance comparable to nonlinear ICA methods trained jointly\non multiple offline distributions and, surprisingly, the incoming new\ndistribution does not necessarily benefit the identification of all latent\nvariables.",
      "tldr_zh": "该论文探讨了在顺序分布变化下进行非线性独立成分分析 (nonlinear ICA) 的持续学习问题，旨在实现可识别 (identifiability) 表示，以更好地理解数据集中的因果关系。作者提出持续因果表示学习 (continual causal representation learning) 方法，理论证明随着分布数量增加，可识别性从子空间级别逐步提升到组件级别。实验结果表明，该方法性能与同时训练多个离线分布的 nonlinear ICA 方法相当，但新分布不一定改善所有潜在变量的识别。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 Figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05788v1",
      "published_date": "2024-08-11 14:33:37 UTC",
      "updated_date": "2024-08-11 14:33:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:31:29.249178"
    },
    {
      "arxiv_id": "2408.05781v2",
      "title": "CURLing the Dream: Contrastive Representations for World Modeling in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Augusto Kich",
        "Jair Augusto Bottega",
        "Raul Steinmetz",
        "Ricardo Bedin Grando",
        "Ayano Yorozu",
        "Akihisa Ohya"
      ],
      "abstract": "In this work, we present Curled-Dreamer, a novel reinforcement learning\nalgorithm that integrates contrastive learning into the DreamerV3 framework to\nenhance performance in visual reinforcement learning tasks. By incorporating\nthe contrastive loss from the CURL algorithm and a reconstruction loss from\nautoencoder, Curled-Dreamer achieves significant improvements in various\nDeepMind Control Suite tasks. Our extensive experiments demonstrate that\nCurled-Dreamer consistently outperforms state-of-the-art algorithms, achieving\nhigher mean and median scores across a diverse set of tasks. The results\nindicate that the proposed approach not only accelerates learning but also\nenhances the robustness of the learned policies. This work highlights the\npotential of combining different learning paradigms to achieve superior\nperformance in reinforcement learning applications.",
      "tldr_zh": "本研究提出了一种名为 Curled-Dreamer 的新型强化学习算法，将 CURL 的 contrastive learning 损失整合到 DreamerV3 框架中，以提升视觉强化学习任务的性能。\n该算法结合了 contrastive loss 和 autoencoder 的 reconstruction loss，实现对任务环境的更高效建模。\n在 DeepMind Control Suite 的多种任务中，实验结果显示 Curled-Dreamer 比最先进算法取得了更高的平均和中位分数。\n这项工作证明了结合不同学习范式（如对比学习和重构学习）能够加速学习过程并增强策略的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted for 24th International Conference on Control,\n  Automation and Systems (ICCAS)",
      "pdf_url": "http://arxiv.org/pdf/2408.05781v2",
      "published_date": "2024-08-11 14:13:22 UTC",
      "updated_date": "2024-08-31 21:20:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:31:41.960912"
    },
    {
      "arxiv_id": "2408.05777v1",
      "title": "Seg-CycleGAN : SAR-to-optical image translation guided by a downstream task",
      "title_zh": "翻译失败",
      "authors": [
        "Hannuo Zhang",
        "Huihui Li",
        "Jiarui Lin",
        "Yujie Zhang",
        "Jianghua Fan",
        "Hang Liu"
      ],
      "abstract": "Optical remote sensing and Synthetic Aperture Radar(SAR) remote sensing are\ncrucial for earth observation, offering complementary capabilities. While\noptical sensors provide high-quality images, they are limited by weather and\nlighting conditions. In contrast, SAR sensors can operate effectively under\nadverse conditions. This letter proposes a GAN-based SAR-to-optical image\ntranslation method named Seg-CycleGAN, designed to enhance the accuracy of ship\ntarget translation by leveraging semantic information from a pre-trained\nsemantic segmentation model. Our method utilizes the downstream task of ship\ntarget semantic segmentation to guide the training of image translation\nnetwork, improving the quality of output Optical-styled images. The potential\nof foundation-model-annotated datasets in SAR-to-optical translation tasks is\nrevealed. This work suggests broader research and applications for\ndownstream-task-guided frameworks. The code will be available at\nhttps://github.com/NPULHH/",
      "tldr_zh": "该研究提出了一种名为 Seg-CycleGAN 的 GAN 基于方法，用于将 Synthetic Aperture Radar (SAR) 图像翻译成光学图像，以解决光学遥感受天气和光照限制的问题。Seg-CycleGAN 通过利用预训练的 semantic segmentation 模型和下游任务（船只目标语义分割）来指导训练过程，提高了输出图像的质量和船只目标翻译的准确性。实验结果揭示了 foundation-model-annotated 数据集在 SAR-to-optical 翻译任务中的潜力，并为下游-task-guided 框架的更广泛应用提供了新思路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05777v1",
      "published_date": "2024-08-11 14:01:21 UTC",
      "updated_date": "2024-08-11 14:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:31:52.927905"
    },
    {
      "arxiv_id": "2408.13265v1",
      "title": "Exploiting Formal Concept Analysis for Data Modeling in Data Lakes",
      "title_zh": "翻译失败",
      "authors": [
        "Anes Bendimerad",
        "Romain Mathonat",
        "Youcef Remil",
        "Mehdi Kaytoue"
      ],
      "abstract": "Data lakes are widely used to store extensive and heterogeneous datasets for\nadvanced analytics. However, the unstructured nature of data in these\nrepositories introduces complexities in exploiting them and extracting\nmeaningful insights. This motivates the need of exploring efficient approaches\nfor consolidating data lakes and deriving a common and unified schema. This\npaper introduces a practical data visualization and analysis approach rooted in\nFormal Concept Analysis (FCA) to systematically clean, organize, and design\ndata structures within a data lake. We explore diverse data structures stored\nin our data lake at Infologic, including InfluxDB measurements and\nElasticsearch indexes, aiming to derive conventions for a more accessible data\nmodel. Leveraging FCA, we represent data structures as objects, analyze the\nconcept lattice, and present two strategies-top-down and bottom-up-to unify\nthese structures and establish a common schema. Our methodology yields\nsignificant results, enabling the identification of common concepts in the data\nstructures, such as resources along with their underlying shared fields\n(timestamp, type, usedRatio, etc.). Moreover, the number of distinct data\nstructure field names is reduced by 54 percent (from 190 to 88) in the studied\nsubset of our data lake. We achieve a complete coverage of 80 percent of data\nstructures with only 34 distinct field names, a significant improvement from\nthe initial 121 field names that were needed to reach such coverage. The paper\nprovides insights into the Infologic ecosystem, problem formulation,\nexploration strategies, and presents both qualitative and quantitative results.",
      "tldr_zh": "这篇论文探讨了利用 Formal Concept Analysis (FCA) 来优化数据湖的数据建模问题，以应对数据湖中异构数据集的非结构化挑战。作者提出了一种基于 FCA 的可视化和分析方法，包括将数据结构表示为对象、分析概念 lattice，并采用 top-down 和 bottom-up 策略来统一数据结构并建立共同 schema。实验结果显示，在 Infologic 的数据湖（如 InfluxDB 和 Elasticsearch）中，该方法将数据结构字段名称减少了 54%（从 190 降至 88），并用仅 34 个字段名称实现了 80% 的数据结构覆盖率，显著提升了数据组织的效率和可访问性。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.13265v1",
      "published_date": "2024-08-11 13:58:31 UTC",
      "updated_date": "2024-08-11 13:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:32:05.872037"
    },
    {
      "arxiv_id": "2408.05773v1",
      "title": "Neurosymbolic Methods for Rule Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Agnieszka Lawrynowicz",
        "Luis Galarraga",
        "Mehwish Alam",
        "Berenice Jaulmes",
        "Vaclav Zeman",
        "Tomas Kliegr"
      ],
      "abstract": "In this chapter, we address the problem of rule mining, beginning with\nessential background information, including measures of rule quality. We then\nexplore various rule mining methodologies, categorized into three groups:\ninductive logic programming, path sampling and generalization, and linear\nprogramming. Following this, we delve into neurosymbolic methods, covering\ntopics such as the integration of deep learning with rules, the use of\nembeddings for rule learning, and the application of large language models in\nrule learning.",
      "tldr_zh": "本章探讨了规则挖掘（rule mining）的问题，首先介绍背景知识，包括规则质量衡量措施。随后，分类并分析各种规则挖掘方法，分为三类：inductive logic programming、path sampling and generalization，以及linear programming。然后，深入神经符号方法（neurosymbolic methods），涵盖深度学习（deep learning）与规则的整合、使用embeddings进行规则学习，以及large language models在规则学习中的应用，从而为规则挖掘领域提供全面的理论框架和方法整合。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05773v1",
      "published_date": "2024-08-11 13:50:40 UTC",
      "updated_date": "2024-08-11 13:50:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:32:19.929750"
    },
    {
      "arxiv_id": "2408.05772v1",
      "title": "An analysis of HOI: using a training-free method with multimodal visual foundation models when only the test set is available, without the training set",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoyi Ai"
      ],
      "abstract": "Human-Object Interaction (HOI) aims to identify the pairs of humans and\nobjects in images and to recognize their relationships, ultimately forming\n$\\langle human, object, verb \\rangle$ triplets. Under default settings, HOI\nperformance is nearly saturated, with many studies focusing on long-tail\ndistribution and zero-shot/few-shot scenarios. Let us consider an intriguing\nproblem:``What if there is only test dataset without training dataset, using\nmultimodal visual foundation model in a training-free manner? '' This study\nuses two experimental settings: grounding truth and random arbitrary\ncombinations. We get some interesting conclusion and find that the open\nvocabulary capabilities of the multimodal visual foundation model are not yet\nfully realized. Additionally, replacing the feature extraction with grounding\nDINO further confirms these findings.",
      "tldr_zh": "这篇论文分析了 Human-Object Interaction (HOI)，旨在识别图像中的人类、物体及其关系，形成 <human, object, verb> 三元组，并探讨在没有训练集、仅使用测试集的情况下，如何采用训练-free 方法与多模态视觉基础模型进行研究。研究采用了 grounding truth 和随机任意组合的实验设置，揭示了这些模型的开放词汇能力尚未充分发挥。最终，通过用 grounding DINO 替换特征提取，进一步证实了模型性能的局限性，为 HOI 领域的无监督应用提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05772v1",
      "published_date": "2024-08-11 13:40:02 UTC",
      "updated_date": "2024-08-11 13:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:32:31.545279"
    },
    {
      "arxiv_id": "2408.05767v2",
      "title": "Reference-free Hallucination Detection for Large Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qing Li",
        "Jiahui Geng",
        "Chenyang Lyu",
        "Derui Zhu",
        "Maxim Panov",
        "Fakhri Karray"
      ],
      "abstract": "Large vision-language models (LVLMs) have made significant progress in recent\nyears. While LVLMs exhibit excellent ability in language understanding,\nquestion answering, and conversations of visual inputs, they are prone to\nproducing hallucinations. While several methods are proposed to evaluate the\nhallucinations in LVLMs, most are reference-based and depend on external tools,\nwhich complicates their practical application. To assess the viability of\nalternative methods, it is critical to understand whether the reference-free\napproaches, which do not rely on any external tools, can efficiently detect\nhallucinations. Therefore, we initiate an exploratory study to demonstrate the\neffectiveness of different reference-free solutions in detecting hallucinations\nin LVLMs. In particular, we conduct an extensive study on three kinds of\ntechniques: uncertainty-based, consistency-based, and supervised uncertainty\nquantification methods on four representative LVLMs across two different tasks.\nThe empirical results show that the reference-free approaches are capable of\neffectively detecting non-factual responses in LVLMs, with the supervised\nuncertainty quantification method outperforming the others, achieving the best\nperformance across different settings.",
      "tldr_zh": "本研究针对大型视觉语言模型(LVLMs)容易产生幻觉(hallucinations)的缺陷，提出了一种不依赖参考(reference-free)的检测方法，以简化实际应用。研究者评估了三种技术：uncertainty-based、consistency-based 和 supervised uncertainty quantification 方法，并在四个代表性 LVLMs 和两个任务上进行广泛实验。结果显示，reference-free 方法能有效识别非事实响应，其中 supervised uncertainty quantification 方法表现出色，在不同设置下实现最佳性能。该方法为提升 LVLMs 的可靠性和实用性提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05767v2",
      "published_date": "2024-08-11 13:17:14 UTC",
      "updated_date": "2024-11-19 13:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:32:52.007526"
    },
    {
      "arxiv_id": "2408.05758v1",
      "title": "VQ-CTAP: Cross-Modal Fine-Grained Sequence Representation Learning for Speech Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Chunyu Qiang",
        "Wang Geng",
        "Yi Zhao",
        "Ruibo Fu",
        "Tao Wang",
        "Cheng Gong",
        "Tianrui Wang",
        "Qiuyu Liu",
        "Jiangyan Yi",
        "Zhengqi Wen",
        "Chen Zhang",
        "Hao Che",
        "Longbiao Wang",
        "Jianwu Dang",
        "Jianhua Tao"
      ],
      "abstract": "Deep learning has brought significant improvements to the field of\ncross-modal representation learning. For tasks such as text-to-speech (TTS),\nvoice conversion (VC), and automatic speech recognition (ASR), a cross-modal\nfine-grained (frame-level) sequence representation is desired, emphasizing the\nsemantic content of the text modality while de-emphasizing the paralinguistic\ninformation of the speech modality. We propose a method called \"Vector\nQuantized Contrastive Token-Acoustic Pre-training (VQ-CTAP)\", which uses the\ncross-modal aligned sequence transcoder to bring text and speech into a joint\nmultimodal space, learning how to connect text and speech at the frame level.\nThe proposed VQ-CTAP is a paradigm for cross-modal sequence representation\nlearning, offering a promising solution for fine-grained generation and\nrecognition tasks in speech processing. The VQ-CTAP can be directly applied to\nVC and ASR tasks without fine-tuning or additional structures. We propose a\nsequence-aware semantic connector, which connects multiple frozen pre-trained\nmodules for the TTS task, exhibiting a plug-and-play capability. We design a\nstepping optimization strategy to ensure effective model convergence by\ngradually injecting and adjusting the influence of various loss components.\nFurthermore, we propose a semantic-transfer-wise paralinguistic consistency\nloss to enhance representational capabilities, allowing the model to better\ngeneralize to unseen data and capture the nuances of paralinguistic\ninformation. In addition, VQ-CTAP achieves high-compression speech coding at a\nrate of 25Hz from 24kHz input waveforms, which is a 960-fold reduction in the\nsampling rate. The audio demo is available at\nhttps://qiangchunyu.github.io/VQCTAP/",
      "tldr_zh": "这篇论文提出了 VQ-CTAP，一种用于语音处理的跨模态细粒度序列表示学习方法，通过 Vector Quantized Contrastive Token-Acoustic Pre-training 将文本和语音在 frame-level 上对齐，强调文本语义并减少语音副语言信息。VQ-CTAP 采用 sequence-aware semantic connector 和 stepping optimization strategy，确保模型高效收敛，并引入 semantic-transfer-wise paralinguistic consistency loss 以提升泛化能力和捕捉细微信息。该方法可直接应用于 TTS、VC 和 ASR 任务，实现高压缩率（从 24kHz 输入到 25Hz），并在实验中展示了显著的性能提升。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05758v1",
      "published_date": "2024-08-11 12:24:23 UTC",
      "updated_date": "2024-08-11 12:24:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:32:56.006569"
    },
    {
      "arxiv_id": "2408.05748v1",
      "title": "Low-Dimensional Federated Knowledge Graph Embedding via Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxiong Zhang",
        "Zhiwei Zeng",
        "Xin Zhou",
        "Zhiqi Shen"
      ],
      "abstract": "Federated Knowledge Graph Embedding (FKGE) aims to facilitate collaborative\nlearning of entity and relation embeddings from distributed Knowledge Graphs\n(KGs) across multiple clients, while preserving data privacy. Training FKGE\nmodels with higher dimensions is typically favored due to their potential for\nachieving superior performance. However, high-dimensional embeddings present\nsignificant challenges in terms of storage resource and inference speed. Unlike\ntraditional KG embedding methods, FKGE involves multiple client-server\ncommunication rounds, where communication efficiency is critical. Existing\nembedding compression methods for traditional KGs may not be directly\napplicable to FKGE as they often require multiple model trainings which\npotentially incur substantial communication costs. In this paper, we propose a\nlight-weight component based on Knowledge Distillation (KD) which is titled\nFedKD and tailored specifically for FKGE methods. During client-side local\ntraining, FedKD facilitates the low-dimensional student model to mimic the\nscore distribution of triples from the high-dimensional teacher model using KL\ndivergence loss. Unlike traditional KD way, FedKD adaptively learns a\ntemperature to scale the score of positive triples and separately adjusts the\nscores of corresponding negative triples using a predefined temperature,\nthereby mitigating teacher over-confidence issue. Furthermore, we dynamically\nadjust the weight of KD loss to optimize the training process. Extensive\nexperiments on three datasets support the effectiveness of FedKD.",
      "tldr_zh": "这篇论文针对Federated Knowledge Graph Embedding (FKGE)提出了一种基于Knowledge Distillation (KD)的轻量组件FedKD，以实现低维嵌入，从而减少存储资源消耗和通信开销，同时保护数据隐私。FedKD在客户端本地训练中，使用KL divergence损失让低维学生模型模仿高维教师模型的三元组分数分布，并通过自适应温度调整正负样本分数来缓解教师模型的过度自信问题，同时动态优化KD损失权重。实验在三个数据集上证明了FedKD的有效性，显著提升了FKGE的效率和性能。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05748v1",
      "published_date": "2024-08-11 11:15:41 UTC",
      "updated_date": "2024-08-11 11:15:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:33:08.004896"
    },
    {
      "arxiv_id": "2408.05740v1",
      "title": "MTSCI: A Conditional Diffusion Model for Multivariate Time Series Consistent Imputation",
      "title_zh": "MTSCI：一种用于多元时间序列一致性插值的条件扩散模型",
      "authors": [
        "Jianping Zhou",
        "Junhao Li",
        "Guanjie Zheng",
        "Xinbing Wang",
        "Chenghu Zhou"
      ],
      "abstract": "Missing values are prevalent in multivariate time series, compromising the\nintegrity of analyses and degrading the performance of downstream tasks.\nConsequently, research has focused on multivariate time series imputation,\naiming to accurately impute the missing values based on available observations.\nA key research question is how to ensure imputation consistency, i.e.,\nintra-consistency between observed and imputed values, and inter-consistency\nbetween adjacent windows after imputation. However, previous methods rely\nsolely on the inductive bias of the imputation targets to guide the learning\nprocess, ignoring imputation consistency and ultimately resulting in poor\nperformance. Diffusion models, known for their powerful generative abilities,\nprefer to generate consistent results based on available observations.\nTherefore, we propose a conditional diffusion model for Multivariate Time\nSeries Consistent Imputation (MTSCI). Specifically, MTSCI employs a contrastive\ncomplementary mask to generate dual views during the forward noising process.\nThen, the intra contrastive loss is calculated to ensure intra-consistency\nbetween the imputed and observed values. Meanwhile, MTSCI utilizes a mixup\nmechanism to incorporate conditional information from adjacent windows during\nthe denoising process, facilitating the inter-consistency between imputed\nsamples. Extensive experiments on multiple real-world datasets demonstrate that\nour method achieves the state-of-the-art performance on multivariate time\nseries imputation task under different missing scenarios. Code is available at\nhttps://github.com/JeremyChou28/MTSCI.",
      "tldr_zh": "该论文提出MTSCI，一种条件扩散模型，用于多变量时间序列(Multivariate Time Series)的一致性填充(Imputation)，旨在解决缺失值导致的内部一致性(Intra-Consistency)和外部一致性(Inter-Consistency)问题。MTSCI通过对比互补掩码(Contrastive Complementary Mask)在正向噪声过程(Forward Noising)中生成双视图，并计算内部对比损失(Intra Contrastive Loss)来确保填充值与观察值的匹配；同时，利用Mixup机制在反向去噪过程(Denoising)中整合相邻窗口的条件信息，以提升填充间的连贯性。实验在多个真实数据集上证明，MTSCI在不同缺失场景下实现了最先进性能，代码可从https://github.com/JeremyChou28/MTSCI获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, accepted by CIKM2024",
      "pdf_url": "http://arxiv.org/pdf/2408.05740v1",
      "published_date": "2024-08-11 10:24:53 UTC",
      "updated_date": "2024-08-11 10:24:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:33:30.304212"
    },
    {
      "arxiv_id": "2408.06391v1",
      "title": "Autoregressive Enzyme Function Prediction with Multi-scale Multi-modality Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Dingyi Rong",
        "Wenzhuo Zheng",
        "Bozitao Zhong",
        "Zhouhan Lin",
        "Liang Hong",
        "Ning Liu"
      ],
      "abstract": "Accurate prediction of enzyme function is crucial for elucidating biological\nmechanisms and driving innovation across various sectors. Existing deep\nlearning methods tend to rely solely on either sequence data or structural data\nand predict the EC number as a whole, neglecting the intrinsic hierarchical\nstructure of EC numbers. To address these limitations, we introduce MAPred, a\nnovel multi-modality and multi-scale model designed to autoregressively predict\nthe EC number of proteins. MAPred integrates both the primary amino acid\nsequence and the 3D tokens of proteins, employing a dual-pathway approach to\ncapture comprehensive protein characteristics and essential local functional\nsites. Additionally, MAPred utilizes an autoregressive prediction network to\nsequentially predict the digits of the EC number, leveraging the hierarchical\norganization of EC classifications. Evaluations on benchmark datasets,\nincluding New-392, Price, and New-815, demonstrate that our method outperforms\nexisting models, marking a significant advance in the reliability and\ngranularity of protein function prediction within bioinformatics.",
      "tldr_zh": "本研究提出了一种名为MAPred的多模态和多尺度模型，用于自回归预测蛋白质的EC number，旨在克服现有深度学习方法仅依赖序列数据或结构数据且忽略EC number层次结构的问题。MAPred通过整合蛋白质的氨基酸序列和3D tokens的双路径方法，捕获全面的蛋白特征和局部功能位点，并利用自回归预测网络顺序预测EC number的数字，以充分利用其层次组织。实验结果显示，该模型在新-392、Price和New-815等基准数据集上优于现有模型，在蛋白质功能预测的可靠性和粒度方面取得了显著进展。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.06391v1",
      "published_date": "2024-08-11 08:28:43 UTC",
      "updated_date": "2024-08-11 08:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:33:30.510475"
    },
    {
      "arxiv_id": "2408.05717v1",
      "title": "Deformable Image Registration with Multi-scale Feature Fusion from Shared Encoder, Auxiliary and Pyramid Decoders",
      "title_zh": "基于共享编码器、辅助解码器和金字塔解码器的多尺度特征融合可变形图像配准",
      "authors": [
        "Hongchao Zhou",
        "Shunbo Hu"
      ],
      "abstract": "In this work, we propose a novel deformable convolutional pyramid network for\nunsupervised image registration. Specifically, the proposed network enhances\nthe traditional pyramid network by adding an additional shared auxiliary\ndecoder for image pairs. This decoder provides multi-scale high-level feature\ninformation from unblended image pairs for the registration task. During the\nregistration process, we also design a multi-scale feature fusion block to\nextract the most beneficial features for the registration task from both global\nand local contexts. Validation results indicate that this method can capture\ncomplex deformations while achieving higher registration accuracy and\nmaintaining smooth and plausible deformations.",
      "tldr_zh": "本文提出了一种新型的变形卷积金字塔网络（deformable convolutional pyramid network），用于无监督图像配准（unsupervised image registration），通过添加共享辅助解码器来提供图像对的多尺度高级特征信息。网络还设计了多尺度特征融合块（multi-scale feature fusion），从全局和局部上下文提取最有益的特征，以优化配准过程。验证结果表明，该方法能够捕捉复杂变形，同时实现更高的配准准确性，并保持平滑合理的变形效果。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05717v1",
      "published_date": "2024-08-11 08:02:28 UTC",
      "updated_date": "2024-08-11 08:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:33:42.183604"
    },
    {
      "arxiv_id": "2408.05715v1",
      "title": "Top Pass: Improve Code Generation by Pass@k-Maximized Code Ranking",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi-Cun Lyu",
        "Xin-Ye Li",
        "Zheng Xie",
        "Ming Li"
      ],
      "abstract": "Code generation has been greatly enhanced by the profound advancements in\nLarge Language Models (LLMs) recently. Nevertheless, such LLM-based code\ngeneration approaches still struggle to generate error-free code in a few tries\nwhen faced with complex problems. To address this, the prevailing strategy is\nto sample a huge number of candidate programs, with the hope of any one in them\ncould work. However, users of code generation systems usually expect to find a\ncorrect program by reviewing or testing only a small number of code candidates.\nOtherwise, the system would be unhelpful. In this paper, we propose Top Pass, a\ncode ranking approach that identifies potential correct solutions from a large\nnumber of candidates. Top Pass directly optimizes the pass@k loss function,\nenhancing the quality at the top of the candidate list. This enables the user\nto find the correct solution within as few tries as possible. Experimental\nresults on four benchmarks indicate that our Top Pass method enhances the\nusability of code generation models by producing better ranking results,\nparticularly achieving a 32.9\\% relative improvement in pass@1 on CodeContests\nwhen compared to the state-of-the-art ranking method.",
      "tldr_zh": "这项研究针对 Large Language Models (LLMs) 在代码生成中的挑战，即难以在几次尝试中产生无错误代码，提出了一种名为 Top Pass 的代码排名方法。该方法通过直接优化 pass@k 损失函数，从大量候选程序中优先识别潜在正确的解决方案，从而提升用户在少量尝试中找到正确代码的可能性。在四个基准上的实验结果显示，Top Pass 显著提高了代码生成模型的可用性，尤其在 CodeContests 上，pass@1 指标相对改善了 32.9%。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by Frontier of Computer Science",
      "pdf_url": "http://arxiv.org/pdf/2408.05715v1",
      "published_date": "2024-08-11 07:53:51 UTC",
      "updated_date": "2024-08-11 07:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:33:55.340905"
    },
    {
      "arxiv_id": "2408.05712v1",
      "title": "DeepAir: A Multi-Agent Deep Reinforcement Learning Based Scheme for an Unknown User Location Problem",
      "title_zh": "DeepAir: 一种基于多智能体深度强化学习的方案，用于未知用户位置问题",
      "authors": [
        "Baris Yamansavascilar",
        "Atay Ozgovde",
        "Cem Ersoy"
      ],
      "abstract": "The deployment of unmanned aerial vehicles (UAVs) in many different settings\nhas provided various solutions and strategies for networking paradigms.\nTherefore, it reduces the complexity of the developments for the existing\nproblems, which otherwise require more sophisticated approaches. One of those\nexisting problems is the unknown user locations in an infrastructure-less\nenvironment in which users cannot connect to any communication device or\ncomputation-providing server, which is essential to task offloading in order to\nachieve the required quality of service (QoS). Therefore, in this study, we\ninvestigate this problem thoroughly and propose a novel deep reinforcement\nlearning (DRL) based scheme, DeepAir. DeepAir considers all of the necessary\nsteps including sensing, localization, resource allocation, and multi-access\nedge computing (MEC) to achieve QoS requirements for the offloaded tasks\nwithout violating the maximum tolerable delay. To this end, we use two types of\nUAVs including detector UAVs, and serving UAVs. We utilize detector UAVs as DRL\nagents which ensure sensing, localization, and resource allocation. On the\nother hand, we utilize serving UAVs to provide MEC features. Our experiments\nshow that DeepAir provides a high task success rate by deploying fewer detector\nUAVs in the environment, which includes different numbers of users and user\nattraction points, compared to benchmark methods.",
      "tldr_zh": "本研究针对无基础设施环境中未知用户位置问题提出了一种基于多智能体深度强化学习(DRL)的方案，名为DeepAir，以解决任务卸载和质量服务(QoS)要求。该方案整合了sensing、localization、resource allocation和多接入边缘计算(MEC)，利用detector UAVs作为DRL代理进行感知、定位和资源分配，同时serving UAVs提供MEC功能。实验结果显示，DeepAir在不同用户和用户吸引点环境中，使用较少的detector UAVs即可实现比基准方法更高的任务成功率，从而提升了系统效率和QoS表现。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "12 pages, 8 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2408.05712v1",
      "published_date": "2024-08-11 07:28:35 UTC",
      "updated_date": "2024-08-11 07:28:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:34:07.199143"
    },
    {
      "arxiv_id": "2408.05705v2",
      "title": "TC-KANRecon: High-Quality and Accelerated MRI Reconstruction via Adaptive KAN Mechanisms and Intelligent Feature Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Ruiquan Ge",
        "Xiao Yu",
        "Yifei Chen",
        "Guanyu Zhou",
        "Fan Jia",
        "Shenghao Zhu",
        "Junhao Jia",
        "Chenyan Zhang",
        "Yifei Sun",
        "Dong Zeng",
        "Changmiao Wang",
        "Qiegen Liu",
        "Shanzhou Niu"
      ],
      "abstract": "Magnetic Resonance Imaging (MRI) has become essential in clinical diagnosis\ndue to its high resolution and multiple contrast mechanisms. However, the\nrelatively long acquisition time limits its broader application. To address\nthis issue, this study presents an innovative conditional guided diffusion\nmodel, named as TC-KANRecon, which incorporates the Multi-Free U-KAN (MF-UKAN)\nmodule and a dynamic clipping strategy. TC-KANRecon model aims to accelerate\nthe MRI reconstruction process through deep learning methods while maintaining\nthe quality of the reconstructed images. The MF-UKAN module can effectively\nbalance the tradeoff between image denoising and structure preservation.\nSpecifically, it presents the multi-head attention mechanisms and scalar\nmodulation factors, which significantly enhances the model's robustness and\nstructure preservation capabilities in complex noise environments. Moreover,\nthe dynamic clipping strategy in TC-KANRecon adjusts the cropping interval\naccording to the sampling steps, thereby mitigating image detail loss\ntypicalching the visual features of the images. Furthermore, the MC-Model\nincorporates full-sampling k-space information, realizing efficient fusion of\nconditional information, enhancing the model's ability to process complex data,\nand improving the realism and detail richness of reconstructed images.\nExperimental results demonstrate that the proposed method outperforms other MRI\nreconstruction methods in both qualitative and quantitative evaluations.\nNotably, TC-KANRecon method exhibits excellent reconstruction results when\nprocessing high-noise, low-sampling-rate MRI data. Our source code is available\nat https://github.com/lcbkmm/TC-KANRecon.",
      "tldr_zh": "本研究提出了一种创新的条件引导扩散模型 TC-KANRecon，用于加速 MRI 重建同时保持图像高质量。该模型整合了 Multi-Free U-KAN (MF-UKAN) 模块，该模块通过多头注意力机制和标量调制因子有效平衡图像去噪与结构保留，并采用动态剪裁策略根据采样步骤调整裁剪间隔，以减少细节损失。TC-KANRecon 还利用全采样 k-space 信息实现条件信息的高效融合，提升了对复杂数据（如高噪声、低采样率 MRI 数据）的处理能力。实验结果显示，该方法在定性和定量评估中优于现有技术，为临床 MRI 应用提供了更高效且可靠的解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2408.05705v2",
      "published_date": "2024-08-11 06:31:56 UTC",
      "updated_date": "2025-01-06 10:11:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:34:20.988841"
    },
    {
      "arxiv_id": "2408.05692v1",
      "title": "A Novel Momentum-Based Deep Learning Techniques for Medical Image Classification and Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Koushik Biswas",
        "Ridal Pal",
        "Shaswat Patel",
        "Debesh Jha",
        "Meghana Karri",
        "Amit Reza",
        "Gorkem Durak",
        "Alpay Medetalibeyoglu",
        "Matthew Antalek",
        "Yury Velichko",
        "Daniela Ladner",
        "Amir Borhani",
        "Ulas Bagci"
      ],
      "abstract": "Accurately segmenting different organs from medical images is a critical\nprerequisite for computer-assisted diagnosis and intervention planning. This\nstudy proposes a deep learning-based approach for segmenting various organs\nfrom CT and MRI scans and classifying diseases. Our study introduces a novel\ntechnique integrating momentum within residual blocks for enhanced training\ndynamics in medical image analysis. We applied our method in two distinct\ntasks: segmenting liver, lung, & colon data and classifying abdominal pelvic CT\nand MRI scans. The proposed approach has shown promising results, outperforming\nstate-of-the-art methods on publicly available benchmarking datasets. For\ninstance, in the lung segmentation dataset, our approach yielded significant\nenhancements over the TransNetR model, including a 5.72% increase in dice\nscore, a 5.04% improvement in mean Intersection over Union (mIoU), an 8.02%\nimprovement in recall, and a 4.42% improvement in precision. Hence,\nincorporating momentum led to state-of-the-art performance in both segmentation\nand classification tasks, representing a significant advancement in the field\nof medical imaging.",
      "tldr_zh": "这篇论文提出了一种新型深度学习技术，将 momentum 整合到 residual blocks 中，以提升医疗图像分析的训练动态，主要用于 CT 和 MRI 扫描的器官分割（如肝、肺、结肠）和疾病分类任务。实验结果显示，该方法在公开基准数据集上超越了现有模型，例如在肺分割任务中，相比 TransNetR 模型，dice score 提高了 5.72%、mIoU 提高了 5.04%、recall 提高了 8.02%，precision 提高了 4.42%。总体而言，这种整合 momentum 的方法为医疗图像分割和分类带来了显著进展，代表了该领域的 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2408.05692v1",
      "published_date": "2024-08-11 04:12:35 UTC",
      "updated_date": "2024-08-11 04:12:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:34:33.342315"
    },
    {
      "arxiv_id": "2408.05682v1",
      "title": "Separate Generation and Evaluation for Parallel Greedy Best-First Search",
      "title_zh": "针对并行",
      "authors": [
        "Takumi Shimoda",
        "Alex Fukunaga"
      ],
      "abstract": "Parallelization of Greedy Best First Search (GBFS) has been difficult because\nstraightforward parallelization can result in search behavior which differs\nsignificantly from sequential GBFS, exploring states which would not be\nexplored by sequential GBFS with any tie-breaking strategy. Recent work has\nproposed a class of parallel GBFS algorithms which constrains search to\nexploration of the Bench Transition System (BTS), which is the set of states\nthat can be expanded by GBFS under some tie-breaking policy. However, enforcing\nthis constraint is costly, as such BTS-constrained algorithms are forced to\nspend much of the time waiting so that only states which are guaranteed to be\nin the BTS are expanded. We propose an improvement to parallel search which\ndecouples state generation and state evaluation and significantly improves\nstate evaluation rate, resulting in better search performance.",
      "tldr_zh": "本论文探讨了 Greedy Best First Search (GBFS) 的并行化难题，因为传统方法可能导致探索顺序 GBFS 不会触及的状态，从而改变搜索行为。现有基于 Bench Transition System (BTS) 的并行 GBFS 算法虽能约束探索范围，但需大量等待时间，效率低下。论文提出一种改进方法，将状态生成和状态评估过程分离，从而显著提升状态评估率。实验结果显示，这种分离策略改善了整体搜索性能，为高效的并行搜索提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.DC",
        "cs.DS"
      ],
      "primary_category": "cs.AI",
      "comment": "In Proceedings of ICAPS-2024 Workshop on Heuristics and Search for\n  Domain-Independent Planning (HSDIP-24)\n  https://icaps24.icaps-conference.org/program/workshops/hsdip/",
      "pdf_url": "http://arxiv.org/pdf/2408.05682v1",
      "published_date": "2024-08-11 03:29:17 UTC",
      "updated_date": "2024-08-11 03:29:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:34:45.521680"
    },
    {
      "arxiv_id": "2408.05681v1",
      "title": "SRTFD: Scalable Real-Time Fault Diagnosis through Online Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dandan Zhao",
        "Karthick Sharma",
        "Hongpeng Yin",
        "Yuxin Qi",
        "Shuhao Zhang"
      ],
      "abstract": "Fault diagnosis (FD) is essential for maintaining operational safety and\nminimizing economic losses by detecting system abnormalities. Recently, deep\nlearning (DL)-driven FD methods have gained prominence, offering significant\nimprovements in precision and adaptability through the utilization of extensive\ndatasets and advanced DL models. Modern industrial environments, however,\ndemand FD methods that can handle new fault types, dynamic conditions,\nlarge-scale data, and provide real-time responses with minimal prior\ninformation. Although online continual learning (OCL) demonstrates potential in\naddressing these requirements by enabling DL models to continuously learn from\nstreaming data, it faces challenges such as data redundancy, imbalance, and\nlimited labeled data. To overcome these limitations, we propose SRTFD, a\nscalable real-time fault diagnosis framework that enhances OCL with three\ncritical methods: Retrospect Coreset Selection (RCS), which selects the most\nrelevant data to reduce redundant training and improve efficiency; Global\nBalance Technique (GBT), which ensures balanced coreset selection and robust\nmodel performance; and Confidence and Uncertainty-driven Pseudo-label Learning\n(CUPL), which updates the model using unlabeled data for continuous adaptation.\nExtensive experiments on a real-world dataset and two public simulated datasets\ndemonstrate SRTFD's effectiveness and potential for providing advanced,\nscalable, and precise fault diagnosis in modern industrial systems.",
      "tldr_zh": "这篇论文提出SRTFD框架，通过Online Continual Learning (OCL)实现可扩展的实时故障诊断，旨在解决工业环境中新故障类型、动态条件、大规模数据和数据冗余等问题。SRTFD增强OCL方法，包括Retrospect Coreset Selection (RCS)用于选择相关数据以提高效率、Global Balance Technique (GBT)确保平衡的模型性能，以及Confidence and Uncertainty-driven Pseudo-label Learning (CUPL)利用无标签数据实现持续适应。在真实数据集和两个公共模拟数据集上的实验证明，SRTFD显著提升了故障诊断的精度和可扩展性，为现代工业系统提供可靠的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05681v1",
      "published_date": "2024-08-11 03:26:22 UTC",
      "updated_date": "2024-08-11 03:26:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:34:57.953803"
    },
    {
      "arxiv_id": "2408.05678v1",
      "title": "Efficient Federated Learning Using Dynamic Update and Adaptive Pruning with Momentum on Shared Server Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ji Liu",
        "Juncheng Jia",
        "Hong Zhang",
        "Yuhui Yun",
        "Leye Wang",
        "Yang Zhou",
        "Huaiyu Dai",
        "Dejing Dou"
      ],
      "abstract": "Despite achieving remarkable performance, Federated Learning (FL) encounters\ntwo important problems, i.e., low training efficiency and limited computational\nresources. In this paper, we propose a new FL framework, i.e., FedDUMAP, with\nthree original contributions, to leverage the shared insensitive data on the\nserver in addition to the distributed data in edge devices so as to efficiently\ntrain a global model. First, we propose a simple dynamic server update\nalgorithm, which takes advantage of the shared insensitive data on the server\nwhile dynamically adjusting the update steps on the server in order to speed up\nthe convergence and improve the accuracy. Second, we propose an adaptive\noptimization method with the dynamic server update algorithm to exploit the\nglobal momentum on the server and each local device for superior accuracy.\nThird, we develop a layer-adaptive model pruning method to carry out specific\npruning operations, which is adapted to the diverse features of each layer so\nas to attain an excellent trade-off between effectiveness and efficiency. Our\nproposed FL model, FedDUMAP, combines the three original techniques and has a\nsignificantly better performance compared with baseline approaches in terms of\nefficiency (up to 16.9 times faster), accuracy (up to 20.4% higher), and\ncomputational cost (up to 62.6% smaller).",
      "tldr_zh": "本文提出 FedDUMAP 框架，用于提升 Federated Learning (FL) 的训练效率和计算资源利用，通过利用服务器上的共享不敏感数据。框架的核心贡献包括动态服务器更新算法来加速收敛和提高准确率、自适应优化方法结合全局和本地动量以进一步提升性能，以及层自适应模型剪枝方法根据各层特征进行优化以平衡有效性和效率。实验结果显示，FedDUMAP 相较基线方法在效率上提升至多 16.9 倍、准确率提高至多 20.4%、计算成本降低至多 62.6%。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "27 pages, to appear in TIST",
      "pdf_url": "http://arxiv.org/pdf/2408.05678v1",
      "published_date": "2024-08-11 02:59:11 UTC",
      "updated_date": "2024-08-11 02:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:35:11.594453"
    },
    {
      "arxiv_id": "2408.05669v1",
      "title": "StealthDiffusion: Towards Evading Diffusion Forensic Detection through Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyin Zhou",
        "Ke Sun",
        "Zhongxi Chen",
        "Huafeng Kuang",
        "Xiaoshuai Sun",
        "Rongrong Ji"
      ],
      "abstract": "The rapid progress in generative models has given rise to the critical task\nof AI-Generated Content Stealth (AIGC-S), which aims to create AI-generated\nimages that can evade both forensic detectors and human inspection. This task\nis crucial for understanding the vulnerabilities of existing detection methods\nand developing more robust techniques. However, current adversarial attacks\noften introduce visible noise, have poor transferability, and fail to address\nspectral differences between AI-generated and genuine images. To address this,\nwe propose StealthDiffusion, a framework based on stable diffusion that\nmodifies AI-generated images into high-quality, imperceptible adversarial\nexamples capable of evading state-of-the-art forensic detectors.\nStealthDiffusion comprises two main components: Latent Adversarial\nOptimization, which generates adversarial perturbations in the latent space of\nstable diffusion, and Control-VAE, a module that reduces spectral differences\nbetween the generated adversarial images and genuine images without affecting\nthe original diffusion model's generation process. Extensive experiments show\nthat StealthDiffusion is effective in both white-box and black-box settings,\ntransforming AI-generated images into high-quality adversarial forgeries with\nfrequency spectra similar to genuine images. These forgeries are classified as\ngenuine by advanced forensic classifiers and are difficult for humans to\ndistinguish.",
      "tldr_zh": "该研究针对 AI 生成内容隐蔽（AIGC-S）任务，提出 StealthDiffusion 框架，利用 stable diffusion 模型生成高质量的对抗样本，以逃避先进的取证检测器和人类检查。该框架包括两个核心组件：Latent Adversarial Optimization，在 stable diffusion 的潜在空间生成不可察觉的对抗扰动；以及 Control-VAE，用于减少 AI 生成图像与真实图像的频谱差异，而不影响原生成过程。实验结果显示，StealthDiffusion 在白盒和黑盒设置下均表现出色，能将 AI 生成图像转化为与真实图像相似的伪造样本，这些样本被取证分类器误判为真实，且人类难以辨别。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05669v1",
      "published_date": "2024-08-11 01:22:29 UTC",
      "updated_date": "2024-08-11 01:22:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:35:20.754230"
    },
    {
      "arxiv_id": "2408.13718v1",
      "title": "GPT-4 Emulates Average-Human Emotional Cognition from a Third-Person Perspective",
      "title_zh": "GPT-4 从第三人称视角模拟平均人类的情感认知",
      "authors": [
        "Ala N. Tak",
        "Jonathan Gratch"
      ],
      "abstract": "This paper extends recent investigations on the emotional reasoning abilities\nof Large Language Models (LLMs). Current research on LLMs has not directly\nevaluated the distinction between how LLMs predict the self-attribution of\nemotions and the perception of others' emotions. We first look at carefully\ncrafted emotion-evoking stimuli, originally designed to find patterns of brain\nneural activity representing fine-grained inferred emotional attributions of\nothers. We show that GPT-4 is especially accurate in reasoning about such\nstimuli. This suggests LLMs agree with humans' attributions of others' emotions\nin stereotypical scenarios remarkably more than self-attributions of emotions\nin idiosyncratic situations. To further explore this, our second study utilizes\na dataset containing annotations from both the author and a third-person\nperspective. We find that GPT-4's interpretations align more closely with human\njudgments about the emotions of others than with self-assessments. Notably,\nconventional computational models of emotion primarily rely on self-reported\nground truth as the gold standard. However, an average observer's standpoint,\nwhich LLMs appear to have adopted, might be more relevant for many downstream\napplications, at least in the absence of individual information and adequate\nsafety considerations.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）如 GPT-4 在情感推理方面的能力，特别区分了其对他人情绪感知与自身情绪归属的预测差异。通过使用精心设计的引发情绪刺激和包含作者及第三人称视角注解的数据集，实验显示 GPT-4 在推理他人情绪时与人类判断高度一致，尤其在典型场景中。相比传统依赖自我报告的计算模型，该模型更倾向于采用平均观察者视角，这可能更适用于缺乏个体信息的下游应用，如情感分析和交互系统。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "submitted to 12th International Conference on Affective Computing &\n  Intelligent Interaction, Glasgow, UK, September 15-18, 2024",
      "pdf_url": "http://arxiv.org/pdf/2408.13718v1",
      "published_date": "2024-08-11 01:22:09 UTC",
      "updated_date": "2024-08-11 01:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:35:33.914699"
    },
    {
      "arxiv_id": "2408.05667v3",
      "title": "PhishLang: A Real-Time, Fully Client-Side Phishing Detection Framework Using MobileBERT",
      "title_zh": "翻译失败",
      "authors": [
        "Sayak Saha Roy",
        "Shirin Nilizadeh"
      ],
      "abstract": "In this paper, we introduce PhishLang, the first fully client-side\nanti-phishing framework built on a lightweight ensemble framework that utilizes\nadvanced language models to analyze the contextual features of a website's\nsource code and URL. Unlike traditional heuristic or machine learning\napproaches that rely on static features and struggle to adapt to evolving\nthreats, or deep learning models that are computationally intensive, our\napproach utilizes MobileBERT, a fast and memory-efficient variant of the BERT\narchitecture, to capture nuanced features indicative of phishing attacks. To\nfurther enhance detection accuracy, PhishLang employs a multi-modal ensemble\napproach, combining both the URL and Source detection models. This architecture\nensures robustness by allowing one model to compensate for scenarios where the\nother may fail, or if both models provide ambiguous inferences. As a result,\nPhishLang excels at detecting both regular and evasive phishing threats,\nincluding zero-day attacks, outperforming popular anti-phishing tools, while\noperating without relying on external blocklists and safeguarding user privacy\nby ensuring that browser history remains entirely local and unshared. We\nrelease PhishLang as a Chromium browser extension and also open-source the\nframework to aid the research community.",
      "tldr_zh": "本研究引入PhishLang，这是一个实时、全客户端的防钓鱼框架，使用MobileBERT（一种轻量级BERT变体）来分析网站源代码和URL的上下文特征。PhishLang采用多模态集成方法，将URL检测模型和源代码检测模型相结合，提高了对常规和隐蔽钓鱼威胁（如zero-day attacks）的识别准确性。与传统启发式或机器学习方法相比，该框架在不依赖外部黑名单的情况下，表现出色，出色地保护用户隐私，并优于流行工具。研究团队已将PhishLang作为Chromium浏览器扩展发布，并开源以支持社区发展。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2408.05667v3",
      "published_date": "2024-08-11 01:14:13 UTC",
      "updated_date": "2025-04-16 23:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T14:35:44.317554"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 38,
  "processed_papers_count": 38,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T14:36:07.562365"
}