[
  {
    "arxiv_id": "2403.01031v2",
    "title": "Peacock: A Family of Arabic Multimodal Large Language Models and Benchmarks",
    "authors": [
      "Fakhraddin Alwajih",
      "El Moatez Billah Nagoudi",
      "Gagan Bhatia",
      "Abdelrahman Mohamed",
      "Muhammad Abdul-Mageed"
    ],
    "abstract": "Multimodal large language models (MLLMs) have proven effective in a wide\nrange of tasks requiring complex reasoning and linguistic comprehension.\nHowever, due to a lack of high-quality multimodal resources in languages other\nthan English, success of MLLMs remains relatively limited to English-based\nsettings. This poses significant challenges in developing comparable models for\nother languages, including even those with large speaker populations such as\nArabic. To alleviate this challenge, we introduce a comprehensive family of\nArabic MLLMs, dubbed \\textit{Peacock}, with strong vision and language\ncapabilities. Through comprehensive qualitative and quantitative analysis, we\ndemonstrate the solid performance of our models on various visual reasoning\ntasks and further show their emerging dialectal potential. Additionally, we\nintroduce ~\\textit{Henna}, a new benchmark specifically designed for assessing\nMLLMs on aspects related to Arabic culture, setting the first stone for\nculturally-aware Arabic MLLMs.The GitHub repository for the \\textit{Peacock}\nproject is available at \\url{https://github.com/UBC-NLP/peacock}.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01031v2",
    "published_date": "2024-03-01 23:38:02 UTC",
    "updated_date": "2024-05-24 20:24:36 UTC"
  },
  {
    "arxiv_id": "2403.01024v1",
    "title": "Reservoir Computing Using Measurement-Controlled Quantum Dynamics",
    "authors": [
      "A. H. Abbas",
      "Ivan S. Maksymov"
    ],
    "abstract": "Physical reservoir computing (RC) is a machine learning algorithm that\nemploys the dynamics of a physical system to forecast highly nonlinear and\nchaotic phenomena. In this paper, we introduce a quantum RC system that employs\nthe dynamics of a probed atom in a cavity. The atom experiences coherent\ndriving at a particular rate, leading to a measurement-controlled quantum\nevolution. The proposed quantum reservoir can make fast and reliable forecasts\nusing a small number of artificial neurons compared with the traditional RC\nalgorithm. We theoretically validate the operation of the reservoir,\ndemonstrating its potential to be used in error-tolerant applications, where\napproximate computing approaches may be used to make feasible forecasts in\nconditions of limited computational and energy resources.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01024v1",
    "published_date": "2024-03-01 22:59:41 UTC",
    "updated_date": "2024-03-01 22:59:41 UTC"
  },
  {
    "arxiv_id": "2403.01005v1",
    "title": "Policy Optimization for PDE Control with a Warm Start",
    "authors": [
      "Xiangyuan Zhang",
      "Saviz Mowlavi",
      "Mouhacine Benosman",
      "Tamer Ba≈üar"
    ],
    "abstract": "Dimensionality reduction is crucial for controlling nonlinear partial\ndifferential equations (PDE) through a \"reduce-then-design\" strategy, which\nidentifies a reduced-order model and then implements model-based control\nsolutions. However, inaccuracies in the reduced-order modeling can\nsubstantially degrade controller performance, especially in PDEs with chaotic\nbehavior. To address this issue, we augment the reduce-then-design procedure\nwith a policy optimization (PO) step. The PO step fine-tunes the model-based\ncontroller to compensate for the modeling error from dimensionality reduction.\nThis augmentation shifts the overall strategy into\nreduce-then-design-then-adapt, where the model-based controller serves as a\nwarm start for PO. Specifically, we study the state-feedback tracking control\nof PDEs that aims to align the PDE state with a specific constant target\nsubject to a linear-quadratic cost. Through extensive experiments, we show that\na few iterations of PO can significantly improve the model-based controller\nperformance. Our approach offers a cost-effective alternative to PDE control\nusing end-to-end reinforcement learning.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01005v1",
    "published_date": "2024-03-01 22:03:22 UTC",
    "updated_date": "2024-03-01 22:03:22 UTC"
  },
  {
    "arxiv_id": "2403.01003v1",
    "title": "FlaKat: A Machine Learning-Based Categorization Framework for Flaky Tests",
    "authors": [
      "Shizhe Lin",
      "Ryan Zheng He Liu",
      "Ladan Tahvildari"
    ],
    "abstract": "Flaky tests can pass or fail non-deterministically, without alterations to a\nsoftware system. Such tests are frequently encountered by developers and hinder\nthe credibility of test suites. State-of-the-art research incorporates machine\nlearning solutions into flaky test detection and achieves reasonably good\naccuracy. Moreover, the majority of automated flaky test repair solutions are\ndesigned for specific types of flaky tests. This research work proposes a novel\ncategorization framework, called FlaKat, which uses machine-learning\nclassifiers for fast and accurate prediction of the category of a given flaky\ntest that reflects its root cause. Sampling techniques are applied to address\nthe imbalance between flaky test categories in the International Dataset of\nFlaky Test (IDoFT). A new evaluation metric, called Flakiness Detection\nCapacity (FDC), is proposed for measuring the accuracy of classifiers from the\nperspective of information theory and provides proof for its effectiveness. The\nfinal FDC results are also in agreement with F1 score regarding which\nclassifier yields the best flakiness classification.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.01003v1",
    "published_date": "2024-03-01 22:00:44 UTC",
    "updated_date": "2024-03-01 22:00:44 UTC"
  },
  {
    "arxiv_id": "2403.01002v2",
    "title": "Attribute Structuring Improves LLM-Based Evaluation of Clinical Text Summaries",
    "authors": [
      "Zelalem Gero",
      "Chandan Singh",
      "Yiqing Xie",
      "Sheng Zhang",
      "Praveen Subramanian",
      "Paul Vozila",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ],
    "abstract": "Summarizing clinical text is crucial in health decision-support and clinical\nresearch. Large language models (LLMs) have shown the potential to generate\naccurate clinical text summaries, but still struggle with issues regarding\ngrounding and evaluation, especially in safety-critical domains such as health.\nHolistically evaluating text summaries is challenging because they may contain\nunsubstantiated information. Here, we explore a general mitigation framework\nusing Attribute Structuring (AS), which structures the summary evaluation\nprocess. It decomposes the evaluation process into a grounded procedure that\nuses an LLM for relatively simple structuring and scoring tasks, rather than\nthe full task of holistic summary evaluation. Experiments show that AS\nconsistently improves the correspondence between human annotations and\nautomated metrics in clinical text summarization. Additionally, AS yields\ninterpretations in the form of a short text span corresponding to each output,\nwhich enables efficient human auditing, paving the way towards trustworthy\nevaluation of clinical information in resource-constrained scenarios. We\nrelease our code, prompts, and an open-source benchmark at\nhttps://github.com/microsoft/attribute-structuring.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in ML4H Findings 2024, 4 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.01002v2",
    "published_date": "2024-03-01 21:59:03 UTC",
    "updated_date": "2024-12-14 19:46:43 UTC"
  },
  {
    "arxiv_id": "2403.00994v1",
    "title": "Leveraging Prompt-Based Large Language Models: Predicting Pandemic Health Decisions and Outcomes Through Social Media Language",
    "authors": [
      "Xiaohan Ding",
      "Buse Carik",
      "Uma Sushmitha Gunturi",
      "Valerie Reyna",
      "Eugenia H. Rho"
    ],
    "abstract": "We introduce a multi-step reasoning framework using prompt-based LLMs to\nexamine the relationship between social media language patterns and trends in\nnational health outcomes. Grounded in fuzzy-trace theory, which emphasizes the\nimportance of gists of causal coherence in effective health communication, we\nintroduce Role-Based Incremental Coaching (RBIC), a prompt-based LLM framework,\nto identify gists at-scale. Using RBIC, we systematically extract gists from\nsubreddit discussions opposing COVID-19 health measures (Study 1). We then\ntrack how these gists evolve across key events (Study 2) and assess their\ninfluence on online engagement (Study 3). Finally, we investigate how the\nvolume of gists is associated with national health trends like vaccine uptake\nand hospitalizations (Study 4). Our work is the first to empirically link\nsocial media linguistic patterns to real-world public health trends,\nhighlighting the potential of prompt-based LLMs in identifying critical online\ndiscussion patterns that can form the basis of public health communication\nstrategies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.SI"
    ],
    "primary_category": "cs.HC",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00994v1",
    "published_date": "2024-03-01 21:29:32 UTC",
    "updated_date": "2024-03-01 21:29:32 UTC"
  },
  {
    "arxiv_id": "2403.00993v2",
    "title": "On the Role of Information Structure in Reinforcement Learning for Partially-Observable Sequential Teams and Games",
    "authors": [
      "Awni Altabaa",
      "Zhuoran Yang"
    ],
    "abstract": "In a sequential decision-making problem, the information structure is the\ndescription of how events in the system occurring at different points in time\naffect each other. Classical models of reinforcement learning (e.g., MDPs,\nPOMDPs) assume a simple and highly regular information structure, while more\ngeneral models like predictive state representations do not explicitly model\nthe information structure. By contrast, real-world sequential decision-making\nproblems typically involve a complex and time-varying interdependence of system\nvariables, requiring a rich and flexible representation of information\nstructure. In this paper, we formalize a novel reinforcement learning model\nwhich explicitly represents the information structure. We then use this model\nto carry out an information-structural analysis of the statistical hardness of\ngeneral sequential decision-making problems, obtaining a characterization via a\ngraph-theoretic quantity of the DAG representation of the information\nstructure. We prove an upper bound on the sample complexity of learning a\ngeneral sequential decision-making problem in terms of its information\nstructure by exhibiting an algorithm achieving the upper bound. This recovers\nknown tractability results and gives a novel perspective on reinforcement\nlearning in general sequential decision-making problems, providing a systematic\nway of identifying new tractable classes of problems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "59 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00993v2",
    "published_date": "2024-03-01 21:28:19 UTC",
    "updated_date": "2024-05-27 22:19:40 UTC"
  },
  {
    "arxiv_id": "2403.00986v3",
    "title": "Merging Text Transformer Models from Different Initializations",
    "authors": [
      "Neha Verma",
      "Maha Elbayad"
    ],
    "abstract": "Recent work on permutation-based model merging has shown impressive low- or\nzero-barrier mode connectivity between models from completely different\ninitializations. However, this line of work has not yet extended to the\nTransformer architecture, despite its dominant popularity in the language\ndomain. Therefore, in this work, we investigate the extent to which separate\nTransformer minima learn similar features, and propose a model merging\ntechnique to investigate the relationship between these minima in the loss\nlandscape. The specifics of the architecture, like its residual connections,\nmulti-headed attention, and discrete, sequential input, require specific\ninterventions in order to compute model permutations that remain within the\nsame functional equivalence class. In merging these models with our method, we\nconsistently find lower loss barriers between minima compared to model\naveraging, across models trained on a masked-language modeling task or\nfine-tuned on a language understanding benchmark. Our results show that the\nminima of these models are less sharp and isolated than previously understood,\nand provide a basis for future work on merging separately trained Transformer\nmodels.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "TMLR, November 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00986v3",
    "published_date": "2024-03-01 21:16:29 UTC",
    "updated_date": "2024-12-16 18:00:10 UTC"
  },
  {
    "arxiv_id": "2403.00980v2",
    "title": "Even-Ifs From If-Onlys: Are the Best Semi-Factual Explanations Found Using Counterfactuals As Guides?",
    "authors": [
      "Saugat Aryal",
      "Mark T. Keane"
    ],
    "abstract": "Recently, counterfactuals using \"if-only\" explanations have become very\npopular in eXplainable AI (XAI), as they describe which changes to\nfeature-inputs of a black-box AI system result in changes to a (usually\nnegative) decision-outcome. Even more recently, semi-factuals using \"even-if\"\nexplanations have gained more attention. They elucidate the feature-input\nchanges that do not change the decision-outcome of the AI system, with a\npotential to suggest more beneficial recourses. Some semi-factual methods use\ncounterfactuals to the query-instance to guide semi-factual production\n(so-called counterfactual-guided methods), whereas others do not (so-called\ncounterfactual-free methods). In this work, we perform comprehensive tests of 8\nsemi-factual methods on 7 datasets using 5 key metrics, to determine whether\ncounterfactual guidance is necessary to find the best semi-factuals. The\nresults of these tests suggests not, but rather that computing other aspects of\nthe decision space lead to better semi-factual XAI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "16 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00980v2",
    "published_date": "2024-03-01 21:04:48 UTC",
    "updated_date": "2024-04-25 15:36:15 UTC"
  },
  {
    "arxiv_id": "2403.00975v1",
    "title": "Equipment Health Assessment: Time Series Analysis for Wind Turbine Performance",
    "authors": [
      "Jana Backhus",
      "Aniruddha Rajendra Rao",
      "Chandrasekar Venkatraman",
      "Abhishek Padmanabhan",
      "A. Vinoth Kumar",
      "Chetan Gupta"
    ],
    "abstract": "In this study, we leverage SCADA data from diverse wind turbines to predict\npower output, employing advanced time series methods, specifically Functional\nNeural Networks (FNN) and Long Short-Term Memory (LSTM) networks. A key\ninnovation lies in the ensemble of FNN and LSTM models, capitalizing on their\ncollective learning. This ensemble approach outperforms individual models,\nensuring stable and accurate power output predictions. Additionally, machine\nlearning techniques are applied to detect wind turbine performance\ndeterioration, enabling proactive maintenance strategies and health assessment.\nCrucially, our analysis reveals the uniqueness of each wind turbine,\nnecessitating tailored models for optimal predictions. These insight\nunderscores the importance of providing automatized customization for different\nturbines to keep human modeling effort low. Importantly, the methodologies\ndeveloped in this analysis are not limited to wind turbines; they can be\nextended to predict and optimize performance in various machinery, highlighting\nthe versatility and applicability of our research across diverse industrial\ncontexts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.FA",
      "stat.AP"
    ],
    "primary_category": "cs.LG",
    "comment": "19 Pages, 17 Figures, 3 Tables, Submitted at Applied Sciences (MDPI)",
    "pdf_url": "http://arxiv.org/pdf/2403.00975v1",
    "published_date": "2024-03-01 20:54:31 UTC",
    "updated_date": "2024-03-01 20:54:31 UTC"
  },
  {
    "arxiv_id": "2403.00965v1",
    "title": "Binary Gaussian Copula Synthesis: A Novel Data Augmentation Technique to Advance ML-based Clinical Decision Support Systems for Early Prediction of Dialysis Among CKD Patients",
    "authors": [
      "Hamed Khosravi",
      "Srinjoy Das",
      "Abdullah Al-Mamun",
      "Imtiaz Ahmed"
    ],
    "abstract": "The Center for Disease Control estimates that over 37 million US adults\nsuffer from chronic kidney disease (CKD), yet 9 out of 10 of these individuals\nare unaware of their condition due to the absence of symptoms in the early\nstages. It has a significant impact on patients' quality of life, particularly\nwhen it progresses to the need for dialysis. Early prediction of dialysis is\ncrucial as it can significantly improve patient outcomes and assist healthcare\nproviders in making timely and informed decisions. However, developing an\neffective machine learning (ML)-based Clinical Decision Support System (CDSS)\nfor early dialysis prediction poses a key challenge due to the imbalanced\nnature of data. To address this challenge, this study evaluates various data\naugmentation techniques to understand their effectiveness on real-world\ndatasets. We propose a new approach named Binary Gaussian Copula Synthesis\n(BGCS). BGCS is tailored for binary medical datasets and excels in generating\nsynthetic minority data that mirrors the distribution of the original data.\nBGCS enhances early dialysis prediction by outperforming traditional methods in\ndetecting dialysis patients. For the best ML model, Random Forest, BCGS\nachieved a 72% improvement, surpassing the state-of-the-art augmentation\napproaches. Also, we present a ML-based CDSS, designed to aid clinicians in\nmaking informed decisions. CDSS, which utilizes decision tree models, is\ndeveloped to improve patient outcomes, identify critical variables, and thereby\nenable clinicians to make proactive decisions, and strategize treatment plans\neffectively for CKD patients who are more likely to require dialysis in the\nnear future. Through comprehensive feature analysis and meticulous data\npreparation, we ensure that the CDSS's dialysis predictions are not only\naccurate but also actionable, providing a valuable tool in the management and\ntreatment of CKD.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.AP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00965v1",
    "published_date": "2024-03-01 20:32:17 UTC",
    "updated_date": "2024-03-01 20:32:17 UTC"
  },
  {
    "arxiv_id": "2403.00957v2",
    "title": "Resolution of Simpson's paradox via the common cause principle",
    "authors": [
      "A. Hovhannisyan",
      "A. E. Allahverdyan"
    ],
    "abstract": "Simpson's paradox is an obstacle to establishing a probabilistic association\nbetween two events $a_1$ and $a_2$, given the third (lurking) random variable\n$B$. We focus on scenarios when the random variables $A$ (which combines $a_1$,\n$a_2$, and their complements) and $B$ have a common cause $C$ that need not be\nobserved. Alternatively, we can assume that $C$ screens out $A$ from $B$. For\nsuch cases, the correct association between $a_1$ and $a_2$ is to be defined\nvia conditioning over $C$. This setup generalizes the original Simpson's\nparadox: now its two contradicting options refer to two particular and\ndifferent causes $C$. We show that if $B$ and $C$ are binary and $A$ is\nquaternary (the minimal and the most widespread situation for the Simpson's\nparadox), the conditioning over any binary common cause $C$ establishes the\nsame direction of association between $a_1$ and $a_2$ as the conditioning over\n$B$ in the original formulation of the paradox. Thus, for the minimal common\ncause, one should choose the option of Simpson's paradox that assumes\nconditioning over $B$ and not its marginalization. The same conclusion is\nreached when Simpson's paradox is formulated via 3 continuous Gaussian\nvariables: within the minimal formulation of the paradox (3 scalar continuous\nvariables $A_1$, $A_2$, and $B$), one should choose the option with the\nconditioning over $B$.",
    "categories": [
      "stat.ME",
      "cs.AI",
      "math.PR",
      "physics.data-an",
      "stat.AP"
    ],
    "primary_category": "stat.ME",
    "comment": "Added new results, enhanced references",
    "pdf_url": "http://arxiv.org/pdf/2403.00957v2",
    "published_date": "2024-03-01 20:15:28 UTC",
    "updated_date": "2024-07-21 08:57:48 UTC"
  },
  {
    "arxiv_id": "2403.00953v4",
    "title": "AutoRD: An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontologies-enhanced Large Language Models",
    "authors": [
      "Lang Cao",
      "Jimeng Sun",
      "Adam Cross"
    ],
    "abstract": "Rare diseases affect millions worldwide but often face limited research focus\ndue to their low prevalence. This results in prolonged diagnoses and a lack of\napproved therapies. Recent advancements in Large Language Models (LLMs) have\nshown promise in automating the extraction of medical information, offering\npotential to improve medical diagnosis and management. However, most LLMs lack\nprofessional medical knowledge, especially concerning rare diseases, and\nstruggle to handle the latest rare disease information. They also cannot\neffectively manage rare disease data and are not directly suitable for\ndiagnosis and management tasks. Our objective is to create an end-to-end system\ncalled AutoRD, which automates the extraction of information from medical texts\nabout rare diseases, focusing on entities and their relations. AutoRD\nintegrates up-to-date structured knowledge and demonstrates superior\nperformance in rare disease extraction tasks. We conduct various experiments to\nevaluate AutoRD's performance, aiming to surpass common LLMs and traditional\nmethods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00953v4",
    "published_date": "2024-03-01 20:06:39 UTC",
    "updated_date": "2024-10-25 14:20:32 UTC"
  },
  {
    "arxiv_id": "2403.00942v2",
    "title": "Resilience of Entropy Model in Distributed Neural Networks",
    "authors": [
      "Milin Zhang",
      "Mohammad Abdi",
      "Shahriar Rifat",
      "Francesco Restuccia"
    ],
    "abstract": "Distributed deep neural networks (DNNs) have emerged as a key technique to\nreduce communication overhead without sacrificing performance in edge computing\nsystems. Recently, entropy coding has been introduced to further reduce the\ncommunication overhead. The key idea is to train the distributed DNN jointly\nwith an entropy model, which is used as side information during inference time\nto adaptively encode latent representations into bit streams with variable\nlength. To the best of our knowledge, the resilience of entropy models is yet\nto be investigated. As such, in this paper we formulate and investigate the\nresilience of entropy models to intentional interference (e.g., adversarial\nattacks) and unintentional interference (e.g., weather changes and motion\nblur). Through an extensive experimental campaign with 3 different DNN\narchitectures, 2 entropy models and 4 rate-distortion trade-off factors, we\ndemonstrate that the entropy attacks can increase the communication overhead by\nup to 95%. By separating compression features in frequency and spatial domain,\nwe propose a new defense mechanism that can reduce the transmission overhead of\nthe attacked input by about 9% compared to unperturbed data, with only about 2%\naccuracy loss. Importantly, the proposed defense mechanism is a standalone\napproach which can be applied in conjunction with approaches such as\nadversarial training to further improve robustness. Code will be shared for\nreproducibility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted at ECCV 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00942v2",
    "published_date": "2024-03-01 19:39:19 UTC",
    "updated_date": "2024-07-11 13:51:56 UTC"
  },
  {
    "arxiv_id": "2403.02352v1",
    "title": "ATP: Enabling Fast LLM Serving via Attention on Top Principal Keys",
    "authors": [
      "Yue Niu",
      "Saurav Prakash",
      "Salman Avestimehr"
    ],
    "abstract": "We propose a new attention mechanism with linear complexity, ATP, that\nfixates \\textbf{A}ttention on \\textbf{T}op \\textbf{P}rincipal keys, rather than\non each individual token. Particularly, ATP is driven by an important\nobservation that input sequences are typically low-rank, i.e., input sequences\ncan be represented by a few principal bases. Therefore, instead of directly\niterating over all the input tokens, ATP transforms inputs into an orthogonal\nspace and computes attention only on the top principal bases (keys). Owing to\nthe observed low-rank structure in input sequences, ATP is able to capture\nsemantic relationships in input sequences with a few principal keys.\nFurthermore, the attention complexity is reduced from \\emph{quadratic} to\n\\emph{linear} without incurring a noticeable performance drop. ATP further\nreduces complexity for other linear layers with low-rank inputs, leading to\nmore speedup compared to prior works that solely target the attention module.\nOur evaluations on various models (e.g., BERT and Llama) demonstrate that ATP\nachieves comparable accuracy with much lower computation and memory complexity\nthan the standard attention mechanism. In particular, ATP barely loses accuracy\nwith only $1/2$ principal keys, and only incurs around $2\\%$ accuracy drops\nwith $1/4$ principal keys.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 7 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.02352v1",
    "published_date": "2024-03-01 19:24:37 UTC",
    "updated_date": "2024-03-01 19:24:37 UTC"
  },
  {
    "arxiv_id": "2403.00930v1",
    "title": "Scale-free Adversarial Reinforcement Learning",
    "authors": [
      "Mingyu Chen",
      "Xuezhou Zhang"
    ],
    "abstract": "This paper initiates the study of scale-free learning in Markov Decision\nProcesses (MDPs), where the scale of rewards/losses is unknown to the learner.\nWe design a generic algorithmic framework, \\underline{S}cale\n\\underline{C}lipping \\underline{B}ound (\\texttt{SCB}), and instantiate this\nframework in both the adversarial Multi-armed Bandit (MAB) setting and the\nadversarial MDP setting. Through this framework, we achieve the first minimax\noptimal expected regret bound and the first high-probability regret bound in\nscale-free adversarial MABs, resolving an open problem raised in\n\\cite{hadiji2023adaptation}. On adversarial MDPs, our framework also give birth\nto the first scale-free RL algorithm with a $\\tilde{\\mathcal{O}}(\\sqrt{T})$\nhigh-probability regret guarantee.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00930v1",
    "published_date": "2024-03-01 19:21:10 UTC",
    "updated_date": "2024-03-01 19:21:10 UTC"
  },
  {
    "arxiv_id": "2403.00929v3",
    "title": "PRIME: Scaffolding Manipulation Tasks with Behavior Primitives for Data-Efficient Imitation Learning",
    "authors": [
      "Tian Gao",
      "Soroush Nasiriany",
      "Huihan Liu",
      "Quantao Yang",
      "Yuke Zhu"
    ],
    "abstract": "Imitation learning has shown great potential for enabling robots to acquire\ncomplex manipulation behaviors. However, these algorithms suffer from high\nsample complexity in long-horizon tasks, where compounding errors accumulate\nover the task horizons. We present PRIME (PRimitive-based IMitation with data\nEfficiency), a behavior primitive-based framework designed for improving the\ndata efficiency of imitation learning. PRIME scaffolds robot tasks by\ndecomposing task demonstrations into primitive sequences, followed by learning\na high-level control policy to sequence primitives through imitation learning.\nOur experiments demonstrate that PRIME achieves a significant performance\nimprovement in multi-stage manipulation tasks, with 10-34% higher success rates\nin simulation over state-of-the-art baselines and 20-48% on physical hardware.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00929v3",
    "published_date": "2024-03-01 19:19:56 UTC",
    "updated_date": "2024-08-17 07:50:34 UTC"
  },
  {
    "arxiv_id": "2403.00758v3",
    "title": "Mitigating Reversal Curse in Large Language Models via Semantic-aware Permutation Training",
    "authors": [
      "Qingyan Guo",
      "Rui Wang",
      "Junliang Guo",
      "Xu Tan",
      "Jiang Bian",
      "Yujiu Yang"
    ],
    "abstract": "While large language models (LLMs) have achieved impressive performance\nacross diverse tasks, recent studies showcase that causal LLMs suffer from the\n\"reversal curse\". It is a typical example that the model knows \"A's father is\nB\", but is unable to reason \"B's child is A\". This limitation poses a challenge\nto the advancement of artificial general intelligence (AGI), as it suggests a\ngap in the models' ability to comprehend and apply bidirectional reasoning. In\nthis paper, we first conduct substantial evaluation and identify that the root\ncause of the reversal curse lies in the different word order between the\ntraining and inference stage, namely, the poor ability of causal language\nmodels to predict antecedent words within the training data. Accordingly,\npermutation on the training data is considered as a potential solution, since\nthis can make the model predict antecedent words or tokens. However, previous\npermutation methods may disrupt complete phrases or entities, thereby posing\nchallenges for the model to comprehend and learn from training data. To address\nthis issue, we propose Semantic-aware Permutation Training (SPT), which\naddresses this issue by segmenting the training sentences into semantic units\n(i.e., entities or phrases) with an assistant language model and permuting\nthese units before feeding into the model. Extensive experiments demonstrate\nthat SPT effectively mitigates the reversal curse since the performance on\nreversed questions approximates that on the forward ones, and significantly\nadvances the performance of existing works.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00758v3",
    "published_date": "2024-03-01 18:55:20 UTC",
    "updated_date": "2024-03-20 07:37:24 UTC"
  },
  {
    "arxiv_id": "2403.00742v1",
    "title": "Dialect prejudice predicts AI decisions about people's character, employability, and criminality",
    "authors": [
      "Valentin Hofmann",
      "Pratyusha Ria Kalluri",
      "Dan Jurafsky",
      "Sharese King"
    ],
    "abstract": "Hundreds of millions of people now interact with language models, with uses\nranging from serving as a writing aid to informing hiring decisions. Yet these\nlanguage models are known to perpetuate systematic racial prejudices, making\ntheir judgments biased in problematic ways about groups like African Americans.\nWhile prior research has focused on overt racism in language models, social\nscientists have argued that racism with a more subtle character has developed\nover time. It is unknown whether this covert racism manifests in language\nmodels. Here, we demonstrate that language models embody covert racism in the\nform of dialect prejudice: we extend research showing that Americans hold\nraciolinguistic stereotypes about speakers of African American English and find\nthat language models have the same prejudice, exhibiting covert stereotypes\nthat are more negative than any human stereotypes about African Americans ever\nexperimentally recorded, although closest to the ones from before the civil\nrights movement. By contrast, the language models' overt stereotypes about\nAfrican Americans are much more positive. We demonstrate that dialect prejudice\nhas the potential for harmful consequences by asking language models to make\nhypothetical decisions about people, based only on how they speak. Language\nmodels are more likely to suggest that speakers of African American English be\nassigned less prestigious jobs, be convicted of crimes, and be sentenced to\ndeath. Finally, we show that existing methods for alleviating racial bias in\nlanguage models such as human feedback training do not mitigate the dialect\nprejudice, but can exacerbate the discrepancy between covert and overt\nstereotypes, by teaching language models to superficially conceal the racism\nthat they maintain on a deeper level. Our findings have far-reaching\nimplications for the fair and safe employment of language technology.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00742v1",
    "published_date": "2024-03-01 18:43:09 UTC",
    "updated_date": "2024-03-01 18:43:09 UTC"
  },
  {
    "arxiv_id": "2403.00694v1",
    "title": "Defining Expertise: Applications to Treatment Effect Estimation",
    "authors": [
      "Alihan H√ºy√ºk",
      "Qiyao Wei",
      "Alicia Curth",
      "Mihaela van der Schaar"
    ],
    "abstract": "Decision-makers are often experts of their domain and take actions based on\ntheir domain knowledge. Doctors, for instance, may prescribe treatments by\npredicting the likely outcome of each available treatment. Actions of an expert\nthus naturally encode part of their domain knowledge, and can help make\ninferences within the same domain: Knowing doctors try to prescribe the best\ntreatment for their patients, we can tell treatments prescribed more frequently\nare likely to be more effective. Yet in machine learning, the fact that most\ndecision-makers are experts is often overlooked, and \"expertise\" is seldom\nleveraged as an inductive bias. This is especially true for the literature on\ntreatment effect estimation, where often the only assumption made about actions\nis that of overlap. In this paper, we argue that expertise - particularly the\ntype of expertise the decision-makers of a domain are likely to have - can be\ninformative in designing and selecting methods for treatment effect estimation.\nWe formally define two types of expertise, predictive and prognostic, and\ndemonstrate empirically that: (i) the prominent type of expertise in a domain\nsignificantly influences the performance of different methods in treatment\neffect estimation, and (ii) it is possible to predict the type of expertise\npresent in a dataset, which can provide a quantitative basis for model\nselection.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "stat.ME"
    ],
    "primary_category": "stat.ML",
    "comment": "The 12th International Conference on Learning Representations (ICLR\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.00694v1",
    "published_date": "2024-03-01 17:30:49 UTC",
    "updated_date": "2024-03-01 17:30:49 UTC"
  },
  {
    "arxiv_id": "2403.00898v1",
    "title": "The Algorithm Configuration Problem",
    "authors": [
      "Gabriele Iommazzo",
      "Claudia D'Ambrosio",
      "Antonio Frangioni",
      "Leo Liberti"
    ],
    "abstract": "The field of algorithmic optimization has significantly advanced with the\ndevelopment of methods for the automatic configuration of algorithmic\nparameters. This article delves into the Algorithm Configuration Problem,\nfocused on optimizing parametrized algorithms for solving specific instances of\ndecision/optimization problems. We present a comprehensive framework that not\nonly formalizes the Algorithm Configuration Problem, but also outlines\ndifferent approaches for its resolution, leveraging machine learning models and\nheuristic strategies. The article categorizes existing methodologies into\nper-instance and per-problem approaches, distinguishing between offline and\nonline strategies for model construction and deployment. By synthesizing these\napproaches, we aim to provide a clear pathway for both understanding and\naddressing the complexities inherent in algorithm configuration.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00898v1",
    "published_date": "2024-03-01 17:29:34 UTC",
    "updated_date": "2024-03-01 17:29:34 UTC"
  },
  {
    "arxiv_id": "2403.00692v2",
    "title": "Toward Autonomous Cooperation in Heterogeneous Nanosatellite Constellations Using Dynamic Graph Neural Networks",
    "authors": [
      "Guillem Casadesus-Vila",
      "Joan-Adria Ruiz-de-Azua",
      "Eduard Alarcon"
    ],
    "abstract": "The upcoming landscape of Earth Observation missions will defined by\nnetworked heterogeneous nanosatellite constellations required to meet strict\nmission requirements, such as revisit times and spatial resolution. However,\nscheduling satellite communications in these satellite networks through\nefficiently creating a global satellite Contact Plan (CP) is a complex task,\nwith current solutions requiring ground-based coordination or being limited by\nonboard computational resources. The paper proposes a novel approach to\novercome these challenges by modeling the constellations and CP as dynamic\nnetworks and employing graph-based techniques. The proposed method utilizes a\nstate-of-the-art dynamic graph neural network to evaluate the performance of a\ngiven CP and update it using a heuristic algorithm based on simulated\nannealing. The trained neural network can predict the network delay with a mean\nabsolute error of 3.6 minutes. Simulation results show that the proposed method\ncan successfully design a contact plan for large satellite networks, improving\nthe delay by 29.1%, similar to a traditional approach, while performing the\nobjective evaluations 20x faster.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "eess.SP",
    "comment": "8 pages, 5 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2403.00692v2",
    "published_date": "2024-03-01 17:26:02 UTC",
    "updated_date": "2024-03-04 04:47:46 UTC"
  },
  {
    "arxiv_id": "2403.00691v1",
    "title": "Tri-Modal Motion Retrieval by Learning a Joint Embedding Space",
    "authors": [
      "Kangning Yin",
      "Shihao Zou",
      "Yuxuan Ge",
      "Zheng Tian"
    ],
    "abstract": "Information retrieval is an ever-evolving and crucial research domain. The\nsubstantial demand for high-quality human motion data especially in online\nacquirement has led to a surge in human motion research works. Prior works have\nmainly concentrated on dual-modality learning, such as text and motion tasks,\nbut three-modality learning has been rarely explored. Intuitively, an extra\nintroduced modality can enrich a model's application scenario, and more\nimportantly, an adequate choice of the extra modality can also act as an\nintermediary and enhance the alignment between the other two disparate\nmodalities. In this work, we introduce LAVIMO (LAnguage-VIdeo-MOtion\nalignment), a novel framework for three-modality learning integrating\nhuman-centric videos as an additional modality, thereby effectively bridging\nthe gap between text and motion. Moreover, our approach leverages a specially\ndesigned attention mechanism to foster enhanced alignment and synergistic\neffects among text, video, and motion modalities. Empirically, our results on\nthe HumanML3D and KIT-ML datasets show that LAVIMO achieves state-of-the-art\nperformance in various motion-related cross-modal retrieval tasks, including\ntext-to-motion, motion-to-text, video-to-motion and motion-to-video.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00691v1",
    "published_date": "2024-03-01 17:23:30 UTC",
    "updated_date": "2024-03-01 17:23:30 UTC"
  },
  {
    "arxiv_id": "2403.00690v1",
    "title": "Playing NetHack with LLMs: Potential & Limitations as Zero-Shot Agents",
    "authors": [
      "Dominik Jeurissen",
      "Diego Perez-Liebana",
      "Jeremy Gow",
      "Duygu Cakmak",
      "James Kwan"
    ],
    "abstract": "Large Language Models (LLMs) have shown great success as high-level planners\nfor zero-shot game-playing agents. However, these agents are primarily\nevaluated on Minecraft, where long-term planning is relatively straightforward.\nIn contrast, agents tested in dynamic robot environments face limitations due\nto simplistic environments with only a few objects and interactions. To fill\nthis gap in the literature, we present NetPlay, the first LLM-powered zero-shot\nagent for the challenging roguelike NetHack. NetHack is a particularly\nchallenging environment due to its diverse set of items and monsters, complex\ninteractions, and many ways to die.\n  NetPlay uses an architecture designed for dynamic robot environments,\nmodified for NetHack. Like previous approaches, it prompts the LLM to choose\nfrom predefined skills and tracks past interactions to enhance decision-making.\nGiven NetHack's unpredictable nature, NetPlay detects important game events to\ninterrupt running skills, enabling it to react to unforeseen circumstances.\nWhile NetPlay demonstrates considerable flexibility and proficiency in\ninteracting with NetHack's mechanics, it struggles with ambiguous task\ndescriptions and a lack of explicit feedback. Our findings demonstrate that\nNetPlay performs best with detailed context information, indicating the\nnecessity for dynamic methods in supplying context information for complex\ngames such as NetHack.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00690v1",
    "published_date": "2024-03-01 17:22:16 UTC",
    "updated_date": "2024-03-01 17:22:16 UTC"
  },
  {
    "arxiv_id": "2403.00685v2",
    "title": "Know your exceptions: Towards an Ontology of Exceptions in Knowledge Representation",
    "authors": [
      "Gabriele Sacco",
      "Loris Bozzato",
      "Oliver Kutz"
    ],
    "abstract": "Defeasible reasoning is a kind of reasoning where some generalisations may\nnot be valid in all circumstances, that is general conclusions may fail in some\ncases. Various formalisms have been developed to model this kind of reasoning,\nwhich is characteristic of common-sense contexts. However, it is not easy for a\nmodeller to choose among these systems the one that better fits its domain from\nan ontological point of view. In this paper we first propose a framework based\non the notions of exceptionality and defeasibility in order to be able to\ncompare formalisms and reveal their ontological commitments. Then, we apply\nthis framework to compare four systems, showing the differences that may occur\nfrom an ontological perspective.",
    "categories": [
      "cs.AI",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 4 pages are appendix. (v2 updates: minor revisions on\n  discussions, terminology and text editing)",
    "pdf_url": "http://arxiv.org/pdf/2403.00685v2",
    "published_date": "2024-03-01 17:19:35 UTC",
    "updated_date": "2024-03-05 16:35:43 UTC"
  },
  {
    "arxiv_id": "2403.00897v1",
    "title": "VisRec: A Semi-Supervised Approach to Radio Interferometric Data Reconstruction",
    "authors": [
      "Ruoqi Wang",
      "Haitao Wang",
      "Qiong Luo",
      "Feng Wang",
      "Hejun Wu"
    ],
    "abstract": "Radio telescopes produce visibility data about celestial objects, but these\ndata are sparse and noisy. As a result, images created on raw visibility data\nare of low quality. Recent studies have used deep learning models to\nreconstruct visibility data to get cleaner images. However, these methods rely\non a substantial amount of labeled training data, which requires significant\nlabeling effort from radio astronomers. Addressing this challenge, we propose\nVisRec, a model-agnostic semi-supervised learning approach to the\nreconstruction of visibility data. Specifically, VisRec consists of both a\nsupervised learning module and an unsupervised learning module. In the\nsupervised learning module, we introduce a set of data augmentation functions\nto produce diverse training examples. In comparison, the unsupervised learning\nmodule in VisRec augments unlabeled data and uses reconstructions from\nnon-augmented visibility data as pseudo-labels for training. This hybrid\napproach allows VisRec to effectively leverage both labeled and unlabeled data.\nThis way, VisRec performs well even when labeled data is scarce. Our evaluation\nresults show that VisRec outperforms all baseline methods in reconstruction\nquality, robustness against common observation perturbation, and\ngeneralizability to different telescope configurations.",
    "categories": [
      "eess.IV",
      "astro-ph.GA",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00897v1",
    "published_date": "2024-03-01 16:27:33 UTC",
    "updated_date": "2024-03-01 16:27:33 UTC"
  },
  {
    "arxiv_id": "2403.00642v2",
    "title": "Rethinking The Uniformity Metric in Self-Supervised Learning",
    "authors": [
      "Xianghong Fang",
      "Jian Li",
      "Qiang Sun",
      "Benyou Wang"
    ],
    "abstract": "Uniformity plays an important role in evaluating learned representations,\nproviding insights into self-supervised learning. In our quest for effective\nuniformity metrics, we pinpoint four principled properties that such metrics\nshould possess. Namely, an effective uniformity metric should remain invariant\nto instance permutations and sample replications while accurately capturing\nfeature redundancy and dimensional collapse. Surprisingly, we find that the\nuniformity metric proposed by \\citet{Wang2020UnderstandingCR} fails to satisfy\nthe majority of these properties. Specifically, their metric is sensitive to\nsample replications, and can not account for feature redundancy and dimensional\ncollapse correctly. To overcome these limitations, we introduce a new\nuniformity metric based on the Wasserstein distance, which satisfies all the\naforementioned properties. Integrating this new metric in existing\nself-supervised learning methods effectively mitigates dimensional collapse and\nconsistently improves their performance on downstream tasks involving CIFAR-10\nand CIFAR-100 datasets. Code is available at\n\\url{https://github.com/statsle/WassersteinSSL}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00642v2",
    "published_date": "2024-03-01 16:22:05 UTC",
    "updated_date": "2024-04-26 08:24:11 UTC"
  },
  {
    "arxiv_id": "2403.00632v1",
    "title": "Metamorpheus: Interactive, Affective, and Creative Dream Narration Through Metaphorical Visual Storytelling",
    "authors": [
      "Qian Wan",
      "Xin Feng",
      "Yining Bei",
      "Zhiqi Gao",
      "Zhicong Lu"
    ],
    "abstract": "Human emotions are essentially molded by lived experiences, from which we\nconstruct personalised meaning. The engagement in such meaning-making process\nhas been practiced as an intervention in various psychotherapies to promote\nwellness. Nevertheless, to support recollecting and recounting lived\nexperiences in everyday life remains under explored in HCI. It also remains\nunknown how technologies such as generative AI models can facilitate the\nmeaning making process, and ultimately support affective mindfulness. In this\npaper we present Metamorpheus, an affective interface that engages users in a\ncreative visual storytelling of emotional experiences during dreams.\nMetamorpheus arranges the storyline based on a dream's emotional arc, and\nprovokes self-reflection through the creation of metaphorical images and text\ndepictions. The system provides metaphor suggestions, and generates visual\nmetaphors and text depictions using generative AI models, while users can apply\ngenerations to recolour and re-arrange the interface to be visually affective.\nOur experience-centred evaluation manifests that, by interacting with\nMetamorpheus, users can recall their dreams in vivid detail, through which they\nrelive and reflect upon their experiences in a meaningful way.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00632v1",
    "published_date": "2024-03-01 16:09:32 UTC",
    "updated_date": "2024-03-01 16:09:32 UTC"
  },
  {
    "arxiv_id": "2403.00896v3",
    "title": "DiaHalu: A Dialogue-level Hallucination Evaluation Benchmark for Large Language Models",
    "authors": [
      "Kedi Chen",
      "Qin Chen",
      "Jie Zhou",
      "Yishen He",
      "Liang He"
    ],
    "abstract": "Since large language models (LLMs) achieve significant success in recent\nyears, the hallucination issue remains a challenge, numerous benchmarks are\nproposed to detect the hallucination. Nevertheless, some of these benchmarks\nare not naturally generated by LLMs but are intentionally induced. Also, many\nmerely focus on the factuality hallucination while ignoring the faithfulness\nhallucination. Additionally, although dialogue pattern is more widely utilized\nin the era of LLMs, current benchmarks only concentrate on sentence-level and\npassage-level hallucination. In this study, we propose DiaHalu, the first\ndialogue-level hallucination evaluation benchmark to our knowledge. Initially,\nwe integrate the collected topics into system prompts and facilitate a dialogue\nbetween two ChatGPT3.5. Subsequently, we manually modify the contents that do\nnot adhere to human language conventions and then have LLMs re-generate,\nsimulating authentic human-machine interaction scenarios. Finally, professional\nscholars annotate all the samples in the dataset. DiaHalu covers four common\nmulti-turn dialogue domains and five hallucination subtypes, extended from\nfactuality and faithfulness hallucination. Experiments through some well-known\nLLMs and detection methods on the dataset show that DiaHalu is a challenging\nbenchmark, holding significant value for further research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00896v3",
    "published_date": "2024-03-01 15:38:55 UTC",
    "updated_date": "2024-10-10 08:27:54 UTC"
  },
  {
    "arxiv_id": "2403.00895v3",
    "title": "End-to-End Graph-Sequential Representation Learning for Accurate Recommendations",
    "authors": [
      "Vladimir Baikalov",
      "Evgeny Frolov"
    ],
    "abstract": "Recent recommender system advancements have focused on developing\nsequence-based and graph-based approaches. Both approaches proved useful in\nmodeling intricate relationships within behavioral data, leading to promising\noutcomes in personalized ranking and next-item recommendation tasks while\nmaintaining good scalability. However, they capture very different signals from\ndata. While the former approach represents users directly through ordered\ninteractions with recent items, the latter aims to capture indirect\ndependencies across the interactions graph. This paper presents a novel\nmulti-representational learning framework exploiting these two paradigms'\nsynergies. Our empirical evaluation on several datasets demonstrates that\nmutual training of sequential and graph components with the proposed framework\nsignificantly improves recommendations performance.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "4 pages, 1 figure, submitted to WWW'24, short-paper track",
    "pdf_url": "http://arxiv.org/pdf/2403.00895v3",
    "published_date": "2024-03-01 15:32:44 UTC",
    "updated_date": "2024-03-15 00:40:50 UTC"
  },
  {
    "arxiv_id": "2403.00587v1",
    "title": "Improving Explicit Spatial Relationships in Text-to-Image Generation through an Automatically Derived Dataset",
    "authors": [
      "Ander Salaberria",
      "Gorka Azkune",
      "Oier Lopez de Lacalle",
      "Aitor Soroa",
      "Eneko Agirre",
      "Frank Keller"
    ],
    "abstract": "Existing work has observed that current text-to-image systems do not\naccurately reflect explicit spatial relations between objects such as 'left of'\nor 'below'. We hypothesize that this is because explicit spatial relations\nrarely appear in the image captions used to train these models. We propose an\nautomatic method that, given existing images, generates synthetic captions that\ncontain 14 explicit spatial relations. We introduce the Spatial Relation for\nGeneration (SR4G) dataset, which contains 9.9 millions image-caption pairs for\ntraining, and more than 60 thousand captions for evaluation. In order to test\ngeneralization we also provide an 'unseen' split, where the set of objects in\nthe train and test captions are disjoint. SR4G is the first dataset that can be\nused to spatially fine-tune text-to-image systems. We show that fine-tuning two\ndifferent Stable Diffusion models (denoted as SD$_{SR4G}$) yields up to 9\npoints improvements in the VISOR metric. The improvement holds in the 'unseen'\nsplit, showing that SD$_{SR4G}$ is able to generalize to unseen objects.\nSD$_{SR4G}$ improves the state-of-the-art with fewer parameters, and avoids\ncomplex architectures. Our analysis shows that improvement is consistent for\nall relations. The dataset and the code will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages and 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00587v1",
    "published_date": "2024-03-01 15:09:37 UTC",
    "updated_date": "2024-03-01 15:09:37 UTC"
  },
  {
    "arxiv_id": "2403.00570v2",
    "title": "Rethinking cluster-conditioned diffusion models for label-free image synthesis",
    "authors": [
      "Nikolas Adaloglou",
      "Tim Kaiser",
      "Felix Michels",
      "Markus Kollmann"
    ],
    "abstract": "Diffusion-based image generation models can enhance image quality when\nconditioned on ground truth labels. Here, we conduct a comprehensive\nexperimental study on image-level conditioning for diffusion models using\ncluster assignments. We investigate how individual clustering determinants,\nsuch as the number of clusters and the clustering method, impact image\nsynthesis across three different datasets. Given the optimal number of clusters\nwith respect to image synthesis, we show that cluster-conditioning can achieve\nstate-of-the-art performance, with an FID of 1.67 for CIFAR10 and 2.17 for\nCIFAR100, along with a strong increase in training sample efficiency. We\nfurther propose a novel empirical method to estimate an upper bound for the\noptimal number of clusters. Unlike existing approaches, we find no significant\nassociation between clustering performance and the corresponding\ncluster-conditional FID scores. The code is available at\nhttps://github.com/HHU-MMBS/cedm-official-wavc2025.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in WAVC2025 (21 pages, 15 figures). Code is available at\n  https://github.com/HHU-MMBS/cedm-official-wavc2025",
    "pdf_url": "http://arxiv.org/pdf/2403.00570v2",
    "published_date": "2024-03-01 14:47:46 UTC",
    "updated_date": "2024-11-19 11:00:38 UTC"
  },
  {
    "arxiv_id": "2403.00567v2",
    "title": "Flatten Long-Range Loss Landscapes for Cross-Domain Few-Shot Learning",
    "authors": [
      "Yixiong Zou",
      "Yicong Liu",
      "Yiman Hu",
      "Yuhua Li",
      "Ruixuan Li"
    ],
    "abstract": "Cross-domain few-shot learning (CDFSL) aims to acquire knowledge from limited\ntraining data in the target domain by leveraging prior knowledge transferred\nfrom source domains with abundant training samples. CDFSL faces challenges in\ntransferring knowledge across dissimilar domains and fine-tuning models with\nlimited training data. To address these challenges, we initially extend the\nanalysis of loss landscapes from the parameter space to the representation\nspace, which allows us to simultaneously interpret the transferring and\nfine-tuning difficulties of CDFSL models. We observe that sharp minima in the\nloss landscapes of the representation space result in representations that are\nhard to transfer and fine-tune. Moreover, existing flatness-based methods have\nlimited generalization ability due to their short-range flatness. To enhance\nthe transferability and facilitate fine-tuning, we introduce a simple yet\neffective approach to achieve long-range flattening of the minima in the loss\nlandscape. This approach considers representations that are differently\nnormalized as minima in the loss landscape and flattens the high-loss region in\nthe middle by randomly sampling interpolated representations. We implement this\nmethod as a new normalization layer that replaces the original one in both CNNs\nand ViTs. This layer is simple and lightweight, introducing only a minimal\nnumber of additional parameters. Experimental results on 8 datasets demonstrate\nthat our approach outperforms state-of-the-art methods in terms of average\naccuracy. Moreover, our method achieves performance improvements of up to 9\\%\ncompared to the current best approaches on individual datasets. Our code will\nbe released.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00567v2",
    "published_date": "2024-03-01 14:44:41 UTC",
    "updated_date": "2024-04-19 03:17:16 UTC"
  },
  {
    "arxiv_id": "2403.00565v1",
    "title": "Predicting UAV Type: An Exploration of Sampling and Data Augmentation for Time Series Classification",
    "authors": [
      "Tarik Crnovrsanin",
      "Calvin Yu",
      "Dane Hankamer",
      "Cody Dunne"
    ],
    "abstract": "Unmanned aerial vehicles are becoming common and have many productive uses.\nHowever, their increased prevalence raises safety concerns -- how can we\nprotect restricted airspace? Knowing the type of unmanned aerial vehicle can go\na long way in determining any potential risks it carries. For instance,\nfixed-wing craft can carry more weight over longer distances, thus potentially\nposing a more significant threat. This paper presents a machine learning model\nfor classifying unmanned aerial vehicles as quadrotor, hexarotor, or\nfixed-wing. Our approach effectively applies a Long-Short Term Memory (LSTM)\nneural network for the purpose of time series classification. We performed\nexperiments to test the effects of changing the timestamp sampling method and\naddressing the imbalance in the class distribution. Through these experiments,\nwe identified the top-performing sampling and class imbalance fixing methods.\nAveraging the macro f-scores across 10 folds of data, we found that the\nmajority quadrotor class was predicted well (98.16%), and, despite an extreme\nclass imbalance, the model could also predicted a majority of fixed-wing\nflights correctly (73.15%). Hexarotor instances were often misclassified as\nquadrotors due to the similarity of multirotors in general (42.15%). However,\nresults remained relatively stable across certain methods, which prompted us to\nanalyze and report on their tradeoffs. The supplemental material for this\npaper, including the code and data for running all the experiments and\ngenerating the results tables, is available at https://osf.io/mnsgk/.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "12 pages, 3 figures, 4 tables, submitted to IEEE Transactions on\n  Cybernetics",
    "pdf_url": "http://arxiv.org/pdf/2403.00565v1",
    "published_date": "2024-03-01 14:43:55 UTC",
    "updated_date": "2024-03-01 14:43:55 UTC"
  },
  {
    "arxiv_id": "2403.00894v2",
    "title": "Comparing large language models and human programmers for generating programming code",
    "authors": [
      "Wenpin Hou",
      "Zhicheng Ji"
    ],
    "abstract": "We systematically evaluated the performance of seven large language models in\ngenerating programming code using various prompt strategies, programming\nlanguages, and task difficulties. GPT-4 substantially outperforms other large\nlanguage models, including Gemini Ultra and Claude 2. The coding performance of\nGPT-4 varies considerably with different prompt strategies. In most LeetCode\nand GeeksforGeeks coding contests evaluated in this study, GPT-4 employing the\noptimal prompt strategy outperforms 85 percent of human participants.\nAdditionally, GPT-4 demonstrates strong capabilities in translating code\nbetween different programming languages and in learning from past errors. The\ncomputational efficiency of the code generated by GPT-4 is comparable to that\nof human programmers. These results suggest that GPT-4 has the potential to\nserve as a reliable assistant in programming code generation and software\ndevelopment.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00894v2",
    "published_date": "2024-03-01 14:43:06 UTC",
    "updated_date": "2024-10-05 00:34:44 UTC"
  },
  {
    "arxiv_id": "2403.00564v2",
    "title": "EfficientZero V2: Mastering Discrete and Continuous Control with Limited Data",
    "authors": [
      "Shengjie Wang",
      "Shaohuai Liu",
      "Weirui Ye",
      "Jiacheng You",
      "Yang Gao"
    ],
    "abstract": "Sample efficiency remains a crucial challenge in applying Reinforcement\nLearning (RL) to real-world tasks. While recent algorithms have made\nsignificant strides in improving sample efficiency, none have achieved\nconsistently superior performance across diverse domains. In this paper, we\nintroduce EfficientZero V2, a general framework designed for sample-efficient\nRL algorithms. We have expanded the performance of EfficientZero to multiple\ndomains, encompassing both continuous and discrete actions, as well as visual\nand low-dimensional inputs. With a series of improvements we propose,\nEfficientZero V2 outperforms the current state-of-the-art (SOTA) by a\nsignificant margin in diverse tasks under the limited data setting.\nEfficientZero V2 exhibits a notable advancement over the prevailing general\nalgorithm, DreamerV3, achieving superior outcomes in 50 of 66 evaluated tasks\nacross diverse benchmarks, such as Atari 100k, Proprio Control, and Vision\nControl.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "21 pages,10 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00564v2",
    "published_date": "2024-03-01 14:42:25 UTC",
    "updated_date": "2024-09-12 08:37:27 UTC"
  },
  {
    "arxiv_id": "2403.00561v1",
    "title": "Multi-Task Learning Using Uncertainty to Weigh Losses for Heterogeneous Face Attribute Estimation",
    "authors": [
      "Huaqing Yuan",
      "Yi He",
      "Peng Du",
      "Lu Song"
    ],
    "abstract": "Face images contain a wide variety of attribute information. In this paper,\nwe propose a generalized framework for joint estimation of ordinal and nominal\nattributes based on information sharing. We tackle the correlation problem\nbetween heterogeneous attributes using hard parameter sharing of shallow\nfeatures, and trade-off multiple loss functions by considering homoskedastic\nuncertainty for each attribute estimation task. This leads to optimal\nestimation of multiple attributes of the face and reduces the training cost of\nmultitask learning. Experimental results on benchmarks with multiple face\nattributes show that the proposed approach has superior performance compared to\nstate of the art. Finally, we discuss the bias issues arising from the proposed\napproach in face attribute estimation and validate its feasibility on edge\nsystems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00561v1",
    "published_date": "2024-03-01 14:39:15 UTC",
    "updated_date": "2024-03-01 14:39:15 UTC"
  },
  {
    "arxiv_id": "2403.03962v1",
    "title": "Identify Critical Nodes in Complex Network with Large Language Models",
    "authors": [
      "Jinzhu Mao",
      "Dongyun Zou",
      "Li Sheng",
      "Siyi Liu",
      "Chen Gao",
      "Yue Wang",
      "Yong Li"
    ],
    "abstract": "Identifying critical nodes in networks is a classical decision-making task,\nand many methods struggle to strike a balance between adaptability and utility.\nTherefore, we propose an approach that empowers Evolutionary Algorithm (EA)\nwith Large Language Models (LLMs), to generate a function called \"score\\_nodes\"\nwhich can further be used to identify crucial nodes based on their assigned\nscores. Our model consists of three main components: Manual Initialization,\nPopulation Management, and LLMs-based Evolution. It evolves from initial\npopulations with a set of designed node scoring functions created manually.\nLLMs leverage their strong contextual understanding and rich programming skills\nto perform crossover and mutation operations on the individuals, generating\nexcellent new functions. These functions are then categorized, ranked, and\neliminated to ensure the stable development of the populations while preserving\ndiversity. Extensive experiments demonstrate the excellent performance of our\nmethod, showcasing its strong generalization ability compared to other\nstate-of-the-art algorithms. It can consistently and orderly generate diverse\nand efficient node scoring functions. All source codes and models that can\nreproduce all results in this work are publicly available at this link:\n\\url{https://anonymous.4open.science/r/LLM4CN-6520}",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.03962v1",
    "published_date": "2024-03-01 14:23:26 UTC",
    "updated_date": "2024-03-01 14:23:26 UTC"
  },
  {
    "arxiv_id": "2403.00550v1",
    "title": "Imitation Learning Datasets: A Toolkit For Creating Datasets, Training Agents and Benchmarking",
    "authors": [
      "Nathan Gavenski",
      "Michael Luck",
      "Odinaldo Rodrigues"
    ],
    "abstract": "Imitation learning field requires expert data to train agents in a task. Most\noften, this learning approach suffers from the absence of available data, which\nresults in techniques being tested on its dataset. Creating datasets is a\ncumbersome process requiring researchers to train expert agents from scratch,\nrecord their interactions and test each benchmark method with newly created\ndata. Moreover, creating new datasets for each new technique results in a lack\nof consistency in the evaluation process since each dataset can drastically\nvary in state and action distribution. In response, this work aims to address\nthese issues by creating Imitation Learning Datasets, a toolkit that allows\nfor: (i) curated expert policies with multithreaded support for faster dataset\ncreation; (ii) readily available datasets and techniques with precise\nmeasurements; and (iii) sharing implementations of common imitation learning\ntechniques. Demonstration link:\nhttps://nathangavenski.github.io/#/il-datasets-video",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "his paper has been accepted in the demonstration track for the 23rd\n  International Conference on Autonomous Agents and Multi-Agent Systems",
    "pdf_url": "http://arxiv.org/pdf/2403.00550v1",
    "published_date": "2024-03-01 14:18:46 UTC",
    "updated_date": "2024-03-01 14:18:46 UTC"
  },
  {
    "arxiv_id": "2403.05581v2",
    "title": "Can Interpretability Layouts Influence Human Perception of Offensive Sentences?",
    "authors": [
      "Thiago Freitas dos Santos",
      "Nardine Osman",
      "Marco Schorlemmer"
    ],
    "abstract": "This paper conducts a user study to assess whether three machine learning\n(ML) interpretability layouts can influence participants' views when evaluating\nsentences containing hate speech, focusing on the \"Misogyny\" and \"Racism\"\nclasses. Given the existence of divergent conclusions in the literature, we\nprovide empirical evidence on using ML interpretability in online communities\nthrough statistical and qualitative analyses of questionnaire responses. The\nGeneralized Additive Model estimates participants' ratings, incorporating\nwithin-subject and between-subject designs. While our statistical analysis\nindicates that none of the interpretability layouts significantly influences\nparticipants' views, our qualitative analysis demonstrates the advantages of ML\ninterpretability: 1) triggering participants to provide corrective feedback in\ncase of discrepancies between their views and the model, and 2) providing\ninsights to evaluate a model's behavior beyond traditional performance metrics.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.05581v2",
    "published_date": "2024-03-01 13:25:54 UTC",
    "updated_date": "2025-05-10 07:15:07 UTC"
  },
  {
    "arxiv_id": "2403.00510v3",
    "title": "ROME: Memorization Insights from Text, Logits and Representation",
    "authors": [
      "Bo Li",
      "Qinghua Zhao",
      "Lijie Wen"
    ],
    "abstract": "Previous works have evaluated memorization by comparing model outputs with\ntraining corpora, examining how factors such as data duplication, model size,\nand prompt length influence memorization. However, analyzing these extensive\ntraining corpora is highly time-consuming. To address this challenge, this\npaper proposes an innovative approach named ROME that bypasses direct\nprocessing of the training data. Specifically, we select datasets categorized\ninto three distinct types -- context-independent, conventional, and factual --\nand redefine memorization as the ability to produce correct answers under these\nconditions. Our analysis then focuses on disparities between memorized and\nnon-memorized samples by examining the logits and representations of generated\ntexts. Experimental findings reveal that longer words are less likely to be\nmemorized, higher confidence correlates with greater memorization, and\nrepresentations of the same concepts are more similar across different\ncontexts. Our code and data will be publicly available when the paper is\naccepted.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Submitted to EMNLP, 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00510v3",
    "published_date": "2024-03-01 13:15:30 UTC",
    "updated_date": "2024-06-16 13:53:44 UTC"
  },
  {
    "arxiv_id": "2403.00509v1",
    "title": "Surveying the Dead Minds: Historical-Psychological Text Analysis with Contextualized Construct Representation (CCR) for Classical Chinese",
    "authors": [
      "Yuqi Chen",
      "Sixuan Li",
      "Ying Li",
      "Mohammad Atari"
    ],
    "abstract": "In this work, we develop a pipeline for historical-psychological text\nanalysis in classical Chinese. Humans have produced texts in various languages\nfor thousands of years; however, most of the computational literature is\nfocused on contemporary languages and corpora. The emerging field of historical\npsychology relies on computational techniques to extract aspects of psychology\nfrom historical corpora using new methods developed in natural language\nprocessing (NLP). The present pipeline, called Contextualized Construct\nRepresentations (CCR), combines expert knowledge in psychometrics (i.e.,\npsychological surveys) with text representations generated via\ntransformer-based language models to measure psychological constructs such as\ntraditionalism, norm strength, and collectivism in classical Chinese corpora.\nConsidering the scarcity of available data, we propose an indirect supervised\ncontrastive learning approach and build the first Chinese historical psychology\ncorpus (C-HI-PSY) to fine-tune pre-trained models. We evaluate the pipeline to\ndemonstrate its superior performance compared with other approaches. The CCR\nmethod outperforms word-embedding-based approaches across all of our tasks and\nexceeds prompting with GPT-4 in most tasks. Finally, we benchmark the pipeline\nagainst objective, external data to further verify its validity.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00509v1",
    "published_date": "2024-03-01 13:14:45 UTC",
    "updated_date": "2024-03-01 13:14:45 UTC"
  },
  {
    "arxiv_id": "2403.00504v1",
    "title": "Learning and Leveraging World Models in Visual Representation Learning",
    "authors": [
      "Quentin Garrido",
      "Mahmoud Assran",
      "Nicolas Ballas",
      "Adrien Bardes",
      "Laurent Najman",
      "Yann LeCun"
    ],
    "abstract": "Joint-Embedding Predictive Architecture (JEPA) has emerged as a promising\nself-supervised approach that learns by leveraging a world model. While\npreviously limited to predicting missing parts of an input, we explore how to\ngeneralize the JEPA prediction task to a broader set of corruptions. We\nintroduce Image World Models, an approach that goes beyond masked image\nmodeling and learns to predict the effect of global photometric transformations\nin latent space. We study the recipe of learning performant IWMs and show that\nit relies on three key aspects: conditioning, prediction difficulty, and\ncapacity. Additionally, we show that the predictive world model learned by IWM\ncan be adapted through finetuning to solve diverse tasks; a fine-tuned IWM\nworld model matches or surpasses the performance of previous self-supervised\nmethods. Finally, we show that learning with an IWM allows one to control the\nabstraction level of the learned representations, learning invariant\nrepresentations such as contrastive methods, or equivariant representations\nsuch as masked image modelling.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00504v1",
    "published_date": "2024-03-01 13:05:38 UTC",
    "updated_date": "2024-03-01 13:05:38 UTC"
  },
  {
    "arxiv_id": "2403.00891v1",
    "title": "A Regularization-based Transfer Learning Method for Information Extraction via Instructed Graph Decoder",
    "authors": [
      "Kedi Chen",
      "Jie Zhou",
      "Qin Chen",
      "Shunyu Liu",
      "Liang He"
    ],
    "abstract": "Information extraction (IE) aims to extract complex structured information\nfrom the text. Numerous datasets have been constructed for various IE tasks,\nleading to time-consuming and labor-intensive data annotations. Nevertheless,\nmost prevailing methods focus on training task-specific models, while the\ncommon knowledge among different IE tasks is not explicitly modeled. Moreover,\nthe same phrase may have inconsistent labels in different tasks, which poses a\nbig challenge for knowledge transfer using a unified model. In this study, we\npropose a regularization-based transfer learning method for IE (TIE) via an\ninstructed graph decoder. Specifically, we first construct an instruction pool\nfor datasets from all well-known IE tasks, and then present an instructed graph\ndecoder, which decodes various complex structures into a graph uniformly based\non corresponding instructions. In this way, the common knowledge shared with\nexisting datasets can be learned and transferred to a new dataset with new\nlabels. Furthermore, to alleviate the label inconsistency problem among various\nIE tasks, we introduce a task-specific regularization strategy, which does not\nupdate the gradients of two tasks with 'opposite direction'. We conduct\nextensive experiments on 12 datasets spanning four IE tasks, and the results\ndemonstrate the great advantages of our proposed method",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00891v1",
    "published_date": "2024-03-01 13:04:12 UTC",
    "updated_date": "2024-03-01 13:04:12 UTC"
  },
  {
    "arxiv_id": "2403.00890v2",
    "title": "Improving Android Malware Detection Through Data Augmentation Using Wasserstein Generative Adversarial Networks",
    "authors": [
      "Kawana Stalin",
      "Mikias Berhanu Mekoya"
    ],
    "abstract": "Generative Adversarial Networks (GANs) have demonstrated their versatility\nacross various applications, including data augmentation and malware detection.\nThis research explores the effectiveness of utilizing GAN-generated data to\ntrain a model for the detection of Android malware. Given the considerable\nstorage requirements of Android applications, the study proposes a method to\nsynthetically represent data using GANs, thereby reducing storage demands. The\nproposed methodology involves creating image representations of features\nextracted from an existing dataset. A GAN model is then employed to generate a\nmore extensive dataset consisting of realistic synthetic grayscale images.\nSubsequently, this synthetic dataset is utilized to train a Convolutional\nNeural Network (CNN) designed to identify previously unseen Android malware\napplications. The study includes a comparative analysis of the CNN's\nperformance when trained on real images versus synthetic images generated by\nthe GAN. Furthermore, the research explores variations in performance between\nthe Wasserstein Generative Adversarial Network (WGAN) and the Deep\nConvolutional Generative Adversarial Network (DCGAN). The investigation extends\nto studying the impact of image size and malware obfuscation on the\nclassification model's effectiveness. The data augmentation approach\nimplemented in this study resulted in a notable performance enhancement of the\nclassification model, ranging from 1.5% to 7%, depending on the dataset. The\nhighest achieved F1 score reached 0.975.\n  Keywords--Generative Adversarial Networks, Android Malware, Data\nAugmentation, Wasserstein Generative Adversarial Network",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.00890v2",
    "published_date": "2024-03-01 12:38:52 UTC",
    "updated_date": "2024-03-05 14:33:33 UTC"
  },
  {
    "arxiv_id": "2403.00887v1",
    "title": "SEGAA: A Unified Approach to Predicting Age, Gender, and Emotion in Speech",
    "authors": [
      "Aron R",
      "Indra Sigicharla",
      "Chirag Periwal",
      "Mohanaprasad K",
      "Nithya Darisini P S",
      "Sourabh Tiwari",
      "Shivani Arora"
    ],
    "abstract": "The interpretation of human voices holds importance across various\napplications. This study ventures into predicting age, gender, and emotion from\nvocal cues, a field with vast applications. Voice analysis tech advancements\nspan domains, from improving customer interactions to enhancing healthcare and\nretail experiences. Discerning emotions aids mental health, while age and\ngender detection are vital in various contexts. Exploring deep learning models\nfor these predictions involves comparing single, multi-output, and sequential\nmodels highlighted in this paper. Sourcing suitable data posed challenges,\nresulting in the amalgamation of the CREMA-D and EMO-DB datasets. Prior work\nshowed promise in individual predictions, but limited research considered all\nthree variables simultaneously. This paper identifies flaws in an individual\nmodel approach and advocates for our novel multi-output learning architecture\nSpeech-based Emotion Gender and Age Analysis (SEGAA) model. The experiments\nsuggest that Multi-output models perform comparably to individual models,\nefficiently capturing the intricate relationships between variables and speech\ninputs, all while achieving improved runtime.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00887v1",
    "published_date": "2024-03-01 11:28:37 UTC",
    "updated_date": "2024-03-01 11:28:37 UTC"
  },
  {
    "arxiv_id": "2403.00450v1",
    "title": "Parallel Hyperparameter Optimization Of Spiking Neural Network",
    "authors": [
      "Thomas Firmin",
      "Pierre Boulet",
      "El-Ghazali Talbi"
    ],
    "abstract": "Spiking Neural Networks (SNN). SNNs are based on a more biologically inspired\napproach than usual artificial neural networks. Such models are characterized\nby complex dynamics between neurons and spikes. These are very sensitive to the\nhyperparameters, making their optimization challenging. To tackle\nhyperparameter optimization of SNNs, we initially extended the signal loss\nissue of SNNs to what we call silent networks. These networks fail to emit\nenough spikes at their outputs due to mistuned hyperparameters or architecture.\nGenerally, search spaces are heavily restrained, sometimes even discretized, to\nprevent the sampling of such networks. By defining an early stopping criterion\ndetecting silent networks and by designing specific constraints, we were able\nto instantiate larger and more flexible search spaces. We applied a constrained\nBayesian optimization technique, which was asynchronously parallelized, as the\nevaluation time of a SNN is highly stochastic. Large-scale experiments were\ncarried-out on a multi-GPU Petascale architecture. By leveraging silent\nnetworks, results show an acceleration of the search, while maintaining good\nperformances of both the optimization algorithm and the best solution obtained.\nWe were able to apply our methodology to two popular training algorithms, known\nas spike timing dependent plasticity and surrogate gradient. Early detection\nallowed us to prevent worthless and costly computation, directing the search\ntoward promising hyperparameter combinations. Our methodology could be applied\nto multi-objective problems, where the spiking activity is often minimized to\nreduce the energy consumption. In this scenario, it becomes essential to find\nthe delicate frontier between low-spiking and silent networks. Finally, our\napproach may have implications for neural architecture search, particularly in\ndefining suitable spiking architectures.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00450v1",
    "published_date": "2024-03-01 11:11:59 UTC",
    "updated_date": "2024-03-01 11:11:59 UTC"
  },
  {
    "arxiv_id": "2403.00439v1",
    "title": "Authors' Values and Attitudes Towards AI-bridged Scalable Personalization of Creative Language Arts",
    "authors": [
      "Taewook Kim",
      "Hyomin Han",
      "Eytan Adar",
      "Matthew Kay",
      "John Joon Young Chung"
    ],
    "abstract": "Generative AI has the potential to create a new form of interactive media:\nAI-bridged creative language arts (CLA), which bridge the author and audience\nby personalizing the author's vision to the audience's context and taste at\nscale. However, it is unclear what the authors' values and attitudes would be\nregarding AI-bridged CLA. To identify these values and attitudes, we conducted\nan interview study with 18 authors across eight genres (e.g., poetry, comics)\nby presenting speculative but realistic AI-bridged CLA scenarios. We identified\nthree benefits derived from the dynamics between author, artifact, and\naudience: those that 1) authors get from the process, 2) audiences get from the\nartifact, and 3) authors get from the audience. We found how AI-bridged CLA\nwould either promote or reduce these benefits, along with authors' concerns. We\nhope our investigation hints at how AI can provide intriguing experiences to\nCLA audiences while promoting authors' values.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "16 pages, 6 figures, 2 tables. Accepted to ACM CHI 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00439v1",
    "published_date": "2024-03-01 10:53:10 UTC",
    "updated_date": "2024-03-01 10:53:10 UTC"
  },
  {
    "arxiv_id": "2403.00437v1",
    "title": "LoMOE: Localized Multi-Object Editing via Multi-Diffusion",
    "authors": [
      "Goirik Chakrabarty",
      "Aditya Chandrasekar",
      "Ramya Hebbalaguppe",
      "Prathosh AP"
    ],
    "abstract": "Recent developments in the field of diffusion models have demonstrated an\nexceptional capacity to generate high-quality prompt-conditioned image edits.\nNevertheless, previous approaches have primarily relied on textual prompts for\nimage editing, which tend to be less effective when making precise edits to\nspecific objects or fine-grained regions within a scene containing\nsingle/multiple objects. We introduce a novel framework for zero-shot localized\nmulti-object editing through a multi-diffusion process to overcome this\nchallenge. This framework empowers users to perform various operations on\nobjects within an image, such as adding, replacing, or editing $\\textbf{many}$\nobjects in a complex scene $\\textbf{in one pass}$. Our approach leverages\nforeground masks and corresponding simple text prompts that exert localized\ninfluences on the target regions resulting in high-fidelity image editing. A\ncombination of cross-attention and background preservation losses within the\nlatent space ensures that the characteristics of the object being edited are\npreserved while simultaneously achieving a high-quality, seamless\nreconstruction of the background with fewer artifacts compared to the current\nmethods. We also curate and release a dataset dedicated to multi-object\nediting, named $\\texttt{LoMOE}$-Bench. Our experiments against existing\nstate-of-the-art methods demonstrate the improved effectiveness of our approach\nin terms of both image editing quality and inference speed.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.00437v1",
    "published_date": "2024-03-01 10:46:47 UTC",
    "updated_date": "2024-03-01 10:46:47 UTC"
  },
  {
    "arxiv_id": "2403.00436v1",
    "title": "Abductive Ego-View Accident Video Understanding for Safe Driving Perception",
    "authors": [
      "Jianwu Fang",
      "Lei-lei Li",
      "Junfei Zhou",
      "Junbin Xiao",
      "Hongkai Yu",
      "Chen Lv",
      "Jianru Xue",
      "Tat-Seng Chua"
    ],
    "abstract": "We present MM-AU, a novel dataset for Multi-Modal Accident video\nUnderstanding. MM-AU contains 11,727 in-the-wild ego-view accident videos, each\nwith temporally aligned text descriptions. We annotate over 2.23 million object\nboxes and 58,650 pairs of video-based accident reasons, covering 58 accident\ncategories. MM-AU supports various accident understanding tasks, particularly\nmultimodal video diffusion to understand accident cause-effect chains for safe\ndriving. With MM-AU, we present an Abductive accident Video understanding\nframework for Safe Driving perception (AdVersa-SD). AdVersa-SD performs video\ndiffusion via an Object-Centric Video Diffusion (OAVD) method which is driven\nby an abductive CLIP model. This model involves a contrastive interaction loss\nto learn the pair co-occurrence of normal, near-accident, accident frames with\nthe corresponding text descriptions, such as accident reasons, prevention\nadvice, and accident categories. OAVD enforces the causal region learning while\nfixing the content of the original frame background in video generation, to\nfind the dominant cause-effect chain for certain accidents. Extensive\nexperiments verify the abductive ability of AdVersa-SD and the superiority of\nOAVD against the state-of-the-art diffusion models. Additionally, we provide\ncareful benchmark evaluations for object detection and accident reason\nanswering since AdVersa-SD relies on precise object and accident reason\ninformation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2024. This is not the camera-ready version. The\n  Project page: http://www.lotvsmmau.net",
    "pdf_url": "http://arxiv.org/pdf/2403.00436v1",
    "published_date": "2024-03-01 10:42:52 UTC",
    "updated_date": "2024-03-01 10:42:52 UTC"
  },
  {
    "arxiv_id": "2403.00425v2",
    "title": "HALC: Object Hallucination Reduction via Adaptive Focal-Contrast Decoding",
    "authors": [
      "Zhaorun Chen",
      "Zhuokai Zhao",
      "Hongyin Luo",
      "Huaxiu Yao",
      "Bo Li",
      "Jiawei Zhou"
    ],
    "abstract": "While large vision-language models (LVLMs) have demonstrated impressive\ncapabilities in interpreting multi-modal contexts, they invariably suffer from\nobject hallucinations (OH). We introduce HALC, a novel decoding algorithm\ndesigned to mitigate OH in LVLMs. HALC leverages distinct fine-grained optimal\nvisual information in vision-language tasks and operates on both local and\nglobal contexts simultaneously. Specifically, HALC integrates a robust\nauto-focal grounding mechanism (locally) to correct hallucinated tokens on the\nfly, and a specialized beam search algorithm (globally) to significantly reduce\nOH while preserving text generation quality. Additionally, HALC can be\nintegrated into any LVLMs as a plug-and-play module without extra training.\nExtensive experimental studies demonstrate the effectiveness of HALC in\nreducing OH, outperforming state-of-the-arts across four benchmarks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML camera-ready version. Code is released at\n  https://github.com/BillChan226/HALC",
    "pdf_url": "http://arxiv.org/pdf/2403.00425v2",
    "published_date": "2024-03-01 10:21:52 UTC",
    "updated_date": "2024-06-10 15:21:41 UTC"
  },
  {
    "arxiv_id": "2403.00420v2",
    "title": "Robust Deep Reinforcement Learning Through Adversarial Attacks and Training : A Survey",
    "authors": [
      "Lucas Schott",
      "Josephine Delas",
      "Hatem Hajri",
      "Elies Gherbi",
      "Reda Yaich",
      "Nora Boulahia-Cuppens",
      "Frederic Cuppens",
      "Sylvain Lamprier"
    ],
    "abstract": "Deep Reinforcement Learning (DRL) is a subfield of machine learning for\ntraining autonomous agents that take sequential actions across complex\nenvironments. Despite its significant performance in well-known environments,\nit remains susceptible to minor condition variations, raising concerns about\nits reliability in real-world applications. To improve usability, DRL must\ndemonstrate trustworthiness and robustness. A way to improve the robustness of\nDRL to unknown changes in the environmental conditions and possible\nperturbations is through Adversarial Training, by training the agent against\nwell-suited adversarial attacks on the observations and the dynamics of the\nenvironment. Addressing this critical issue, our work presents an in-depth\nanalysis of contemporary adversarial attack and training methodologies,\nsystematically categorizing them and comparing their objectives and operational\nmechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "61 pages, 17 figues, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2403.00420v2",
    "published_date": "2024-03-01 10:16:46 UTC",
    "updated_date": "2024-12-11 15:03:08 UTC"
  },
  {
    "arxiv_id": "2403.00884v3",
    "title": "Zero-Shot Topic Classification of Column Headers: Leveraging LLMs for Metadata Enrichment",
    "authors": [
      "Margherita Martorana",
      "Tobias Kuhn",
      "Lise Stork",
      "Jacco van Ossenbruggen"
    ],
    "abstract": "Traditional dataset retrieval systems rely on metadata for indexing, rather\nthan on the underlying data values. However, high-quality metadata creation and\nenrichment often require manual annotations, which is a labour-intensive and\nchallenging process to automate. In this study, we propose a method to support\nmetadata enrichment using topic annotations generated by three Large Language\nModels (LLMs): ChatGPT-3.5, GoogleBard, and GoogleGemini. Our analysis focuses\non classifying column headers based on domain-specific topics from the\nConsortium of European Social Science Data Archives (CESSDA), a Linked Data\ncontrolled vocabulary. Our approach operates in a zero-shot setting,\nintegrating the controlled topic vocabulary directly within the input prompt.\nThis integration serves as a Large Context Windows approach, with the aim of\nimproving the results of the topic classification task.\n  We evaluated the performance of the LLMs in terms of internal consistency,\ninter-machine alignment, and agreement with human classification. Additionally,\nwe investigate the impact of contextual information (i.e., dataset description)\non the classification outcomes. Our findings suggest that ChatGPT and\nGoogleGemini outperform GoogleBard in terms of internal consistency as well as\nLLM-human-agreement. Interestingly, we found that contextual information had no\nsignificant impact on LLM performance.\n  This work proposes a novel approach that leverages LLMs for topic\nclassification of column headers using a controlled vocabulary, presenting a\npractical application of LLMs and Large Context Windows within the Semantic Web\ndomain. This approach has the potential to facilitate automated metadata\nenrichment, thereby enhancing dataset retrieval and the Findability,\nAccessibility, Interoperability, and Reusability (FAIR) of research data on the\nWeb.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00884v3",
    "published_date": "2024-03-01 10:01:36 UTC",
    "updated_date": "2024-09-06 14:49:21 UTC"
  },
  {
    "arxiv_id": "2403.00396v1",
    "title": "GLFNET: Global-Local (frequency) Filter Networks for efficient medical image segmentation",
    "authors": [
      "Athanasios Tragakis",
      "Qianying Liu",
      "Chaitanya Kaul",
      "Swalpa Kumar Roy",
      "Hang Dai",
      "Fani Deligianni",
      "Roderick Murray-Smith",
      "Daniele Faccio"
    ],
    "abstract": "We propose a novel transformer-style architecture called Global-Local Filter\nNetwork (GLFNet) for medical image segmentation and demonstrate its\nstate-of-the-art performance. We replace the self-attention mechanism with a\ncombination of global-local filter blocks to optimize model efficiency. The\nglobal filters extract features from the whole feature map whereas the local\nfilters are being adaptively created as 4x4 patches of the same feature map and\nadd restricted scale information. In particular, the feature extraction takes\nplace in the frequency domain rather than the commonly used spatial (image)\ndomain to facilitate faster computations. The fusion of information from both\nspatial and frequency spaces creates an efficient model with regards to\ncomplexity, required data and performance. We test GLFNet on three benchmark\ndatasets achieving state-of-the-art performance on all of them while being\nalmost twice as efficient in terms of GFLOP operations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00396v1",
    "published_date": "2024-03-01 09:35:03 UTC",
    "updated_date": "2024-03-01 09:35:03 UTC"
  },
  {
    "arxiv_id": "2403.00376v3",
    "title": "Spurious Feature Eraser: Stabilizing Test-Time Adaptation for Vision-Language Foundation Model",
    "authors": [
      "Huan Ma",
      "Yan Zhu",
      "Changqing Zhang",
      "Peilin Zhao",
      "Baoyuan Wu",
      "Long-Kai Huang",
      "Qinghua Hu",
      "Bingzhe Wu"
    ],
    "abstract": "Vision-language foundation models have exhibited remarkable success across a\nmultitude of downstream tasks due to their scalability on extensive image-text\npaired data. However, these models also display significant limitations when\napplied to downstream tasks, such as fine-grained image classification, as a\nresult of ``decision shortcuts'' that hinder their generalization capabilities.\nIn this work, we find that the CLIP model possesses a rich set of features,\nencompassing both \\textit{desired invariant causal features} and\n\\textit{undesired decision shortcuts}. Moreover, the underperformance of CLIP\non downstream tasks originates from its inability to effectively utilize\npre-trained features in accordance with specific task requirements. To address\nthis challenge, we propose a simple yet effective method, Spurious Feature\nEraser (SEraser), to alleviate the decision shortcuts by erasing the spurious\nfeatures. Specifically, we introduce a test-time prompt tuning paradigm that\noptimizes a learnable prompt, thereby compelling the model to exploit invariant\nfeatures while disregarding decision shortcuts during the inference phase. The\nproposed method effectively alleviates excessive dependence on potentially\nmisleading spurious information. We conduct comparative analysis of the\nproposed method against various approaches which validates the significant\nsuperiority.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00376v3",
    "published_date": "2024-03-01 09:01:53 UTC",
    "updated_date": "2025-01-14 12:37:26 UTC"
  },
  {
    "arxiv_id": "2403.00880v2",
    "title": "CIDGMed: Causal Inference-Driven Medication Recommendation with Enhanced Dual-Granularity Learning",
    "authors": [
      "Shunpan Liang",
      "Xiang Li",
      "Shi Mu",
      "Chen Li",
      "Yu Lei",
      "Yulei Hou",
      "Tengfei Ma"
    ],
    "abstract": "Medication recommendation aims to integrate patients' long-term health\nrecords to provide accurate and safe medication combinations for specific\nhealth states. Existing methods often fail to deeply explore the true causal\nrelationships between diseases/procedures and medications, resulting in biased\nrecommendations. Additionally, in medication representation learning, the\nrelationships between information at different granularities of medications,\ncoarse-grained (medication itself) and fine-grained (molecular level), are not\neffectively integrated, leading to biases in representation learning. To\naddress these limitations, we propose the Causal Inference-driven\nDual-Granularity Medication Recommendation method (CIDGMed). Our approach\nleverages causal inference to uncover the relationships between\ndiseases/procedures and medications, thereby enhancing the rationality and\ninterpretability of recommendations. By integrating coarse-grained medication\neffects with fine-grained molecular structure information, CIDGMed provides a\ncomprehensive representation of medications. Additionally, we employ a bias\ncorrection model during the prediction phase to further refine recommendations,\nensuring both accuracy and safety. Through extensive experiments, CIDGMed\nsignificantly outperforms current state-of-the-art models across multiple\nmetrics, achieving a 2.54% increase in accuracy, a 3.65% reduction in side\neffects, and a 39.42% improvement in time efficiency. Additionally, we\ndemonstrate the rationale of CIDGMed through a case study.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00880v2",
    "published_date": "2024-03-01 08:50:27 UTC",
    "updated_date": "2024-10-30 05:18:03 UTC"
  },
  {
    "arxiv_id": "2403.00878v1",
    "title": "Crimson: Empowering Strategic Reasoning in Cybersecurity through Large Language Models",
    "authors": [
      "Jiandong Jin",
      "Bowen Tang",
      "Mingxuan Ma",
      "Xiao Liu",
      "Yunfei Wang",
      "Qingnan Lai",
      "Jia Yang",
      "Changling Zhou"
    ],
    "abstract": "We introduces Crimson, a system that enhances the strategic reasoning\ncapabilities of Large Language Models (LLMs) within the realm of cybersecurity.\nBy correlating CVEs with MITRE ATT&CK techniques, Crimson advances threat\nanticipation and strategic defense efforts. Our approach includes defining and\nevaluating cybersecurity strategic tasks, alongside implementing a\ncomprehensive human-in-the-loop data-synthetic workflow to develop the\nCVE-to-ATT&CK Mapping (CVEM) dataset. We further enhance LLMs' reasoning\nabilities through a novel Retrieval-Aware Training (RAT) process and its\nrefined iteration, RAT-R.\n  Our findings demonstrate that an LLM fine-tuned with our techniques,\npossessing 7 billion parameters, approaches the performance level of GPT-4,\nshowing markedly lower rates of hallucination and errors, and surpassing other\nmodels in strategic reasoning tasks. Moreover, domain-specific fine-tuning of\nembedding models significantly improves performance within cybersecurity\ncontexts, underscoring the efficacy of our methodology. By leveraging Crimson\nto convert raw vulnerability data into structured and actionable insights, we\nbolster proactive cybersecurity defenses.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "9 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00878v1",
    "published_date": "2024-03-01 08:43:43 UTC",
    "updated_date": "2024-03-01 08:43:43 UTC"
  },
  {
    "arxiv_id": "2403.00353v1",
    "title": "MS-Net: A Multi-Path Sparse Model for Motion Prediction in Multi-Scenes",
    "authors": [
      "Xiaqiang Tang",
      "Weigao Sun",
      "Siyuan Hu",
      "Yiyang Sun",
      "Yafeng Guo"
    ],
    "abstract": "The multi-modality and stochastic characteristics of human behavior make\nmotion prediction a highly challenging task, which is critical for autonomous\ndriving. While deep learning approaches have demonstrated their great potential\nin this area, it still remains unsolved to establish a connection between\nmultiple driving scenes (e.g., merging, roundabout, intersection) and the\ndesign of deep learning models. Current learning-based methods typically use\none unified model to predict trajectories in different scenarios, which may\nresult in sub-optimal results for one individual scene. To address this issue,\nwe propose Multi-Scenes Network (aka. MS-Net), which is a multi-path sparse\nmodel trained by an evolutionary process. MS-Net selectively activates a subset\nof its parameters during the inference stage to produce prediction results for\neach scene. In the training stage, the motion prediction task under\ndifferentiated scenes is abstracted as a multi-task learning problem, an\nevolutionary algorithm is designed to encourage the network search of the\noptimal parameters for each scene while sharing common knowledge between\ndifferent scenes. Our experiment results show that with substantially reduced\nparameters, MS-Net outperforms existing state-of-the-art methods on\nwell-established pedestrian motion prediction datasets, e.g., ETH and UCY, and\nranks the 2nd place on the INTERACTION challenge.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE Robotics and Automation Letters (RAL)",
    "pdf_url": "http://arxiv.org/pdf/2403.00353v1",
    "published_date": "2024-03-01 08:32:12 UTC",
    "updated_date": "2024-03-01 08:32:12 UTC"
  },
  {
    "arxiv_id": "2403.00876v1",
    "title": "Word Order and World Knowledge",
    "authors": [
      "Qinghua Zhao",
      "Vinit Ravishankar",
      "Nicolas Garneau",
      "Anders S√∏gaard"
    ],
    "abstract": "Word order is an important concept in natural language, and in this work, we\nstudy how word order affects the induction of world knowledge from raw text\nusing language models. We use word analogies to probe for such knowledge.\nSpecifically, in addition to the natural word order, we first respectively\nextract texts of six fixed word orders from five languages and then pretrain\nthe language models on these texts. Finally, we analyze the experimental\nresults of the fixed word orders on word analogies and show that i) certain\nfixed word orders consistently outperform or underperform others, though the\nspecifics vary across languages, and ii) the Wov2Lex hypothesis is not hold in\npre-trained language models, and the natural word order typically yields\nmediocre results. The source code will be made publicly available at\nhttps://github.com/lshowway/probing_by_analogy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00876v1",
    "published_date": "2024-03-01 08:13:48 UTC",
    "updated_date": "2024-03-01 08:13:48 UTC"
  },
  {
    "arxiv_id": "2403.00875v1",
    "title": "Enhancing Protein Predictive Models via Proteins Data Augmentation: A Benchmark and New Directions",
    "authors": [
      "Rui Sun",
      "Lirong Wu",
      "Haitao Lin",
      "Yufei Huang",
      "Stan Z. Li"
    ],
    "abstract": "Augmentation is an effective alternative to utilize the small amount of\nlabeled protein data. However, most of the existing work focuses on design-ing\nnew architectures or pre-training tasks, and relatively little work has studied\ndata augmentation for proteins. This paper extends data augmentation techniques\npreviously used for images and texts to proteins and then benchmarks these\ntechniques on a variety of protein-related tasks, providing the first\ncomprehensive evaluation of protein augmentation. Furthermore, we propose two\nnovel semantic-level protein augmentation methods, namely Integrated Gradients\nSubstitution and Back Translation Substitution, which enable protein\nsemantic-aware augmentation through saliency detection and biological\nknowledge. Finally, we integrate extended and proposed augmentations into an\naugmentation pool and propose a simple but effective framework, namely\nAutomated Protein Augmentation (APA), which can adaptively select the most\nsuitable augmentation combinations for different tasks. Extensive experiments\nhave shown that APA enhances the performance of five protein related tasks by\nan average of 10.55% across three architectures compared to vanilla\nimplementations without augmentation, highlighting its potential to make a\ngreat impact on the field.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG",
      "q-bio.BM"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00875v1",
    "published_date": "2024-03-01 07:58:29 UTC",
    "updated_date": "2024-03-01 07:58:29 UTC"
  },
  {
    "arxiv_id": "2403.00336v2",
    "title": "Never-Ending Behavior-Cloning Agent for Robotic Manipulation",
    "authors": [
      "Wenqi Liang",
      "Gan Sun",
      "Qian He",
      "Yu Ren",
      "Jiahua Dong",
      "Yang Cong"
    ],
    "abstract": "Relying on multi-modal observations, embodied robots could perform multiple\nrobotic manipulation tasks in unstructured real-world environments. However,\nmost language-conditioned behavior-cloning agents still face existing\nlong-standing challenges, i.e., 3D scene representation and human-level task\nlearning, when adapting into new sequential tasks in practical scenarios. We\nhere investigate these above challenges with NBAgent in embodied robots, a\npioneering language-conditioned Never-ending Behavior-cloning Agent. It can\ncontinually learn observation knowledge of novel 3D scene semantics and robot\nmanipulation skills from skill-shared and skill-specific attributes,\nrespectively. Specifically, we propose a skill-sharedsemantic rendering module\nand a skill-shared representation distillation module to effectively learn 3D\nscene semantics from skill-shared attribute, further tackling 3D scene\nrepresentation overlooking. Meanwhile, we establish a skill-specific evolving\nplanner to perform manipulation knowledge decoupling, which can continually\nembed novel skill-specific knowledge like human from latent and low-rank space.\nFinally, we design a never-ending embodied robot manipulation benchmark, and\nexpensive experiments demonstrate the significant performance of our method.\nVisual results, code, and dataset are provided at: https://neragent.github.io.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "17 pages, 6 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.00336v2",
    "published_date": "2024-03-01 07:51:29 UTC",
    "updated_date": "2024-06-07 08:10:11 UTC"
  },
  {
    "arxiv_id": "2403.00329v1",
    "title": "Learning with Logical Constraints but without Shortcut Satisfaction",
    "authors": [
      "Zenan Li",
      "Zehua Liu",
      "Yuan Yao",
      "Jingwei Xu",
      "Taolue Chen",
      "Xiaoxing Ma",
      "Jian L√º"
    ],
    "abstract": "Recent studies in neuro-symbolic learning have explored the integration of\nlogical knowledge into deep learning via encoding logical constraints as an\nadditional loss function. However, existing approaches tend to vacuously\nsatisfy logical constraints through shortcuts, failing to fully exploit the\nknowledge. In this paper, we present a new framework for learning with logical\nconstraints. Specifically, we address the shortcut satisfaction issue by\nintroducing dual variables for logical connectives, encoding how the constraint\nis satisfied. We further propose a variational framework where the encoded\nlogical constraint is expressed as a distributional loss that is compatible\nwith the model's original training loss. The theoretical analysis shows that\nthe proposed approach bears salient properties, and the experimental\nevaluations demonstrate its superior performance in both model generalizability\nand constraint satisfaction.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2023, and code is available\n  at https://github.com/SoftWiser-group/NeSy-without-Shortcuts",
    "pdf_url": "http://arxiv.org/pdf/2403.00329v1",
    "published_date": "2024-03-01 07:17:20 UTC",
    "updated_date": "2024-03-01 07:17:20 UTC"
  },
  {
    "arxiv_id": "2403.00872v1",
    "title": "DFIN-SQL: Integrating Focused Schema with DIN-SQL for Superior Accuracy in Large-Scale Databases",
    "authors": [
      "Shai Volvovsky",
      "Marco Marcassa",
      "Mustafa Panbiharwala"
    ],
    "abstract": "The task of converting natural language queries into SQL queries is\nintricate, necessitating a blend of precise techniques for an accurate\ntranslation. The DIN-SQL (Decomposed-In-Context SQL) methodology represents a\nsignificant development in this domain. This paper introduces DFIN (Decomposed\nFocused-In-Context), an innovative extension of DIN-SQL that enhances\nText-to-SQL conversion by addressing schema linking errors, which are a major\nsource of inaccuracies. DFIN uniquely alternates between prompting techniques\nand Retrieval-Augmented Generation (RAG), adapting to the size and complexity\nof the database schema. A preprocessing phase embeds database definitions and\nleverages annotated files, akin to those in the BIRD dataset, facilitating the\nruntime retrieval of pertinent schema information. This strategy significantly\nreduces the token count for schema linking prompts, enabling the use of a\nstandard GPT-4 model over its larger context variant, thus handling large-scale\ndatabases more effectively and economically. Our evaluation on the BIRD\ndataset, a challenging real-world benchmark, demonstrates that DFIN not only\nscales efficiently but also improves accuracy, achieving a score of 51.69. This\nimprovement surpasses DIN-SQL method (the current third-place), which is the\nhighest-ranked model employing in-context learning rather than fine-tuning,\npreviously scoring 50.72. The advancement of DFIN underscores the evolving\ncapabilities of in-context learning methodologies combined with advanced\nlanguage models, offering a promising avenue for future research in complex\nText-to-SQL conversion tasks.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00872v1",
    "published_date": "2024-03-01 07:14:45 UTC",
    "updated_date": "2024-03-01 07:14:45 UTC"
  },
  {
    "arxiv_id": "2403.00323v1",
    "title": "Softened Symbol Grounding for Neuro-symbolic Systems",
    "authors": [
      "Zenan Li",
      "Yuan Yao",
      "Taolue Chen",
      "Jingwei Xu",
      "Chun Cao",
      "Xiaoxing Ma",
      "Jian L√º"
    ],
    "abstract": "Neuro-symbolic learning generally consists of two separated worlds, i.e.,\nneural network training and symbolic constraint solving, whose success hinges\non symbol grounding, a fundamental problem in AI. This paper presents a novel,\nsoftened symbol grounding process, bridging the gap between the two worlds, and\nresulting in an effective and efficient neuro-symbolic learning framework.\nTechnically, the framework features (1) modeling of symbol solution states as a\nBoltzmann distribution, which avoids expensive state searching and facilitates\nmutually beneficial interactions between network training and symbolic\nreasoning;(2) a new MCMC technique leveraging projection and SMT solvers, which\nefficiently samples from disconnected symbol solution spaces; (3) an annealing\nmechanism that can escape from %being trapped into sub-optimal symbol\ngroundings. Experiments with three representative neuro symbolic learning tasks\ndemonstrate that, owining to its superior symbol grounding capability, our\nframework successfully solves problems well beyond the frontier of the existing\nproposals.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a conference paper at ICLR 2023. Code is available at\n  https://github.com/SoftWiser-group/Soften-NeSy-learning",
    "pdf_url": "http://arxiv.org/pdf/2403.00323v1",
    "published_date": "2024-03-01 06:57:09 UTC",
    "updated_date": "2024-03-01 06:57:09 UTC"
  },
  {
    "arxiv_id": "2403.00318v1",
    "title": "Deep Reinforcement Learning for Solving Management Problems: Towards A Large Management Mode",
    "authors": [
      "Jinyang Jiang",
      "Xiaotian Liu",
      "Tao Ren",
      "Qinghao Wang",
      "Yi Zheng",
      "Yufu Du",
      "Yijie Peng",
      "Cheng Zhang"
    ],
    "abstract": "We introduce a deep reinforcement learning (DRL) approach for solving\nmanagement problems including inventory management, dynamic pricing, and\nrecommendation. This DRL approach has the potential to lead to a large\nmanagement model based on certain transformer neural network structures,\nresulting in an artificial general intelligence paradigm for various management\ntasks. Traditional methods have limitations for solving complex real-world\nproblems, and we demonstrate how DRL can surpass existing heuristic approaches\nfor solving management tasks. We aim to solve the problems in a unified\nframework, considering the interconnections between different tasks. Central to\nour methodology is the development of a foundational decision model\ncoordinating decisions across the different domains through generative\ndecision-making. Our experimental results affirm the effectiveness of our\nDRL-based framework in complex and dynamic business environments. This work\nopens new pathways for the application of DRL in management problems,\nhighlighting its potential to revolutionize traditional business management.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00318v1",
    "published_date": "2024-03-01 06:40:02 UTC",
    "updated_date": "2024-03-01 06:40:02 UTC"
  },
  {
    "arxiv_id": "2403.00315v1",
    "title": "Axe the X in XAI: A Plea for Understandable AI",
    "authors": [
      "Andr√©s P√°ez"
    ],
    "abstract": "In a recent paper, Erasmus et al. (2021) defend the idea that the ambiguity\nof the term \"explanation\" in explainable AI (XAI) can be solved by adopting any\nof four different extant accounts of explanation in the philosophy of science:\nthe Deductive Nomological, Inductive Statistical, Causal Mechanical, and New\nMechanist models. In this chapter, I show that the authors' claim that these\naccounts can be applied to deep neural networks as they would to any natural\nphenomenon is mistaken. I also provide a more general argument as to why the\nnotion of explainability as it is currently used in the XAI literature bears\nlittle resemblance to the traditional concept of scientific explanation. It\nwould be more fruitful to use the label \"understandable AI\" to avoid the\nconfusion that surrounds the goal and purposes of XAI. In the second half of\nthe chapter, I argue for a pragmatic conception of understanding that is better\nsuited to play the central role attributed to explanation in XAI. Following\nKuorikoski & Ylikoski (2015), the conditions of satisfaction for understanding\nan ML system are fleshed out in terms of an agent's success in using the\nsystem, in drawing correct inferences from it.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00315v1",
    "published_date": "2024-03-01 06:28:53 UTC",
    "updated_date": "2024-03-01 06:28:53 UTC"
  },
  {
    "arxiv_id": "2403.00307v1",
    "title": "Embedded Multi-label Feature Selection via Orthogonal Regression",
    "authors": [
      "Xueyuan Xu",
      "Fulin Wei",
      "Tianyuan Jia",
      "Li Zhuo",
      "Feiping Nie",
      "Xia Wu"
    ],
    "abstract": "In the last decade, embedded multi-label feature selection methods,\nincorporating the search for feature subsets into model optimization, have\nattracted considerable attention in accurately evaluating the importance of\nfeatures in multi-label classification tasks. Nevertheless, the\nstate-of-the-art embedded multi-label feature selection algorithms based on\nleast square regression usually cannot preserve sufficient discriminative\ninformation in multi-label data. To tackle the aforementioned challenge, a\nnovel embedded multi-label feature selection method, termed global redundancy\nand relevance optimization in orthogonal regression (GRROOR), is proposed to\nfacilitate the multi-label feature selection. The method employs orthogonal\nregression with feature weighting to retain sufficient statistical and\nstructural information related to local label correlations of the multi-label\ndata in the feature learning process. Additionally, both global feature\nredundancy and global label relevancy information have been considered in the\northogonal regression model, which could contribute to the search for\ndiscriminative and non-redundant feature subsets in the multi-label data. The\ncost function of GRROOR is an unbalanced orthogonal Procrustes problem on the\nStiefel manifold. A simple yet effective scheme is utilized to obtain an\noptimal solution. Extensive experimental results on ten multi-label data sets\ndemonstrate the effectiveness of GRROOR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00307v1",
    "published_date": "2024-03-01 06:18:40 UTC",
    "updated_date": "2024-03-01 06:18:40 UTC"
  },
  {
    "arxiv_id": "2403.00871v1",
    "title": "Teach LLMs to Phish: Stealing Private Information from Language Models",
    "authors": [
      "Ashwinee Panda",
      "Christopher A. Choquette-Choo",
      "Zhengming Zhang",
      "Yaoqing Yang",
      "Prateek Mittal"
    ],
    "abstract": "When large language models are trained on private data, it can be a\nsignificant privacy risk for them to memorize and regurgitate sensitive\ninformation. In this work, we propose a new practical data extraction attack\nthat we call \"neural phishing\". This attack enables an adversary to target and\nextract sensitive or personally identifiable information (PII), e.g., credit\ncard numbers, from a model trained on user data with upwards of 10% attack\nsuccess rates, at times, as high as 50%. Our attack assumes only that an\nadversary can insert as few as 10s of benign-appearing sentences into the\ntraining dataset using only vague priors on the structure of the user data.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00871v1",
    "published_date": "2024-03-01 06:15:07 UTC",
    "updated_date": "2024-03-01 06:15:07 UTC"
  },
  {
    "arxiv_id": "2403.00299v1",
    "title": "Universal Auto-encoder Framework for MIMO CSI Feedback",
    "authors": [
      "Jinhyun So",
      "Hyukjoon Kwon"
    ],
    "abstract": "Existing auto-encoder (AE)-based channel state information (CSI) frameworks\nhave focused on a specific configuration of user equipment (UE) and base\nstation (BS), and thus the input and output sizes of the AE are fixed. However,\nin the real-world scenario, the input and output sizes may vary depending on\nthe number of antennas of the BS and UE and the allocated resource block in the\nfrequency dimension. A naive approach to support the different input and output\nsizes is to use multiple AE models, which is impractical for the UE due to the\nlimited HW resources. In this paper, we propose a universal AE framework that\ncan support different input sizes and multiple compression ratios. The proposed\nAE framework significantly reduces the HW complexity while providing comparable\nperformance in terms of compression ratio-distortion trade-off compared to the\nnaive and state-of-the-art approaches.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "7 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00299v1",
    "published_date": "2024-03-01 05:57:08 UTC",
    "updated_date": "2024-03-01 05:57:08 UTC"
  },
  {
    "arxiv_id": "2403.00290v1",
    "title": "Semantic Text Transmission via Prediction with Small Language Models: Cost-Similarity Trade-off",
    "authors": [
      "Bhavani A Madhabhavi",
      "Gangadhar Karevvanavar",
      "Rajshekhar V Bhat",
      "Nikolaos Pappas"
    ],
    "abstract": "We consider the communication of natural language text from a source to a\ndestination over noiseless and character-erasure channels. We exploit\nlanguage's inherent correlations and predictability to constrain transmission\ncosts by allowing the destination to predict or complete words with potential\ndissimilarity with the source text. Concretely, our objective is to obtain\nachievable $(\\bar{c}, \\bar{s})$ pairs, where $\\bar{c}$ is the average\ntransmission cost at the source and $\\bar{s}$ is the average semantic\nsimilarity measured via cosine similarity between vector embedding of words at\nthe source and those predicted/completed at the destination. We obtain\n$(\\bar{c}, \\bar{s})$ pairs for neural language and first-order Markov\nchain-based small language models (SLM) for prediction, using both a threshold\npolicy that transmits a word if its cosine similarity with that\npredicted/completed at the destination is below a threshold, and a periodic\npolicy, which transmits words after a specific interval and predicts/completes\nthe words in between, at the destination. We adopt an SLM for word completion.\nWe demonstrate that, when communication occurs over a noiseless channel, the\nthreshold policy achieves a higher $\\bar{s}$ for a given $\\bar{c}$ than the\nperiodic policy and that the $\\bar{s}$ achieved with the neural SLM is greater\nthan or equal to that of the Markov chain-based algorithm for the same\n$\\bar{c}$. The improved performance comes with a higher complexity in terms of\ntime and computing requirements. However, when communication occurs over a\ncharacter-erasure channel, all prediction algorithms and scheduling policies\nperform poorly. Furthermore, if character-level Huffman coding is used, the\nrequired $\\bar{c}$ to achieve a given $\\bar{s}$ is reduced, but the above\nobservations still apply.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00290v1",
    "published_date": "2024-03-01 05:20:16 UTC",
    "updated_date": "2024-03-01 05:20:16 UTC"
  },
  {
    "arxiv_id": "2403.00284v2",
    "title": "A Survey of Route Recommendations: Methods, Applications, and Opportunities",
    "authors": [
      "Shiming Zhang",
      "Zhipeng Luo",
      "Li Yang",
      "Fei Teng",
      "Tianrui Li"
    ],
    "abstract": "Nowadays, with advanced information technologies deployed citywide, large\ndata volumes and powerful computational resources are intelligentizing modern\ncity development. As an important part of intelligent transportation, route\nrecommendation and its applications are widely used, directly influencing\ncitizens` travel habits. Developing smart and efficient travel routes based on\nbig data (possibly multi-modal) has become a central challenge in route\nrecommendation research. Our survey offers a comprehensive review of route\nrecommendation work based on urban computing. It is organized by the following\nthree parts: 1) Methodology-wise. We categorize a large volume of traditional\nmachine learning and modern deep learning methods. Also, we discuss their\nhistorical relations and reveal the edge-cutting progress. 2)\nApplication\\-wise. We present numerous novel applications related to route\ncommendation within urban computing scenarios. 3) We discuss current problems\nand challenges and envision several promising research directions. We believe\nthat this survey can help relevant researchers quickly familiarize themselves\nwith the current state of route recommendation research and then direct them to\nfuture research trends.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "24 pages, 13 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.00284v2",
    "published_date": "2024-03-01 05:04:00 UTC",
    "updated_date": "2024-04-06 07:02:46 UTC"
  },
  {
    "arxiv_id": "2403.00868v3",
    "title": "SoftTiger: A Clinical Foundation Model for Healthcare Workflows",
    "authors": [
      "Ye Chen",
      "Igor Couto",
      "Wei Cai",
      "Cong Fu",
      "Bruno Dorneles"
    ],
    "abstract": "We introduce SoftTiger, a clinical large language model (CLaM) designed as a\nfoundation model for healthcare workflows. The narrative and unstructured\nnature of clinical notes is a major obstacle for healthcare intelligentization.\nWe address a critical problem of structuring clinical notes into clinical data,\naccording to international interoperability standards. We collect and annotate\ndata for three subtasks, namely, international patient summary, clinical\nimpression and medical encounter. We then supervised fine-tuned a\nstate-of-the-art LLM using public and credentialed clinical data. The training\nis orchestrated in a way that the target model can first support basic clinical\ntasks such as abbreviation expansion and temporal information extraction, and\nthen learn to perform more complex downstream clinical tasks. Moreover, we\naddress several modeling challenges in the healthcare context, e.g., extra long\ncontext window. Our blind pairwise evaluation shows that SoftTiger outperforms\nother popular open-source models and GPT-3.5, comparable to Gemini-pro, with a\nmild gap from GPT-4. We believe that LLMs may become a step-stone towards\nhealthcare digitalization and democratization. Therefore, we publicly release\nSoftTiger models at scales of 13 billion and 70 billion parameters, as well as\ndatasets and code for our innovative scalable evaluation, hopefully, making a\nsignificant contribution to the healthcare industry.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to AAAI 2024 Spring Symposium on Clinical Foundation Models,\n  Stanford University, Stanford, California",
    "pdf_url": "http://arxiv.org/pdf/2403.00868v3",
    "published_date": "2024-03-01 04:39:16 UTC",
    "updated_date": "2024-08-20 12:37:02 UTC"
  },
  {
    "arxiv_id": "2403.00254v1",
    "title": "Cloud-based Federated Learning Framework for MRI Segmentation",
    "authors": [
      "Rukesh Prajapati",
      "Amr S. El-Wakeel"
    ],
    "abstract": "In contemporary rural healthcare settings, the principal challenge in\ndiagnosing brain images is the scarcity of available data, given that most of\nthe existing deep learning models demand extensive training data to optimize\ntheir performance, necessitating centralized processing methods that\npotentially compromise data privacy. This paper proposes a novel framework\ntailored for brain tissue segmentation in rural healthcare facilities. The\nframework employs a deep reinforcement learning (DRL) environment in tandem\nwith a refinement model (RM) deployed locally at rural healthcare sites. The\nproposed DRL model has a reduced parameter count and practicality for\nimplementation across distributed rural sites. To uphold data privacy and\nenhance model generalization without transgressing privacy constraints, we\nemploy federated learning (FL) for cooperative model training. We demonstrate\nthe efficacy of our approach by training the network with a limited data set\nand observing a substantial performance enhancement, mitigating inaccuracies\nand irregularities in segmentation across diverse sites. Remarkably, the DRL\nmodel attains an accuracy of up to 80%, surpassing the capabilities of\nconventional convolutional neural networks when confronted with data\ninsufficiency. Incorporating our RM results in an additional accuracy\nimprovement of at least 10%, while FL contributes to a further accuracy\nenhancement of up to 5%. Collectively, the framework achieves an average 92%\naccuracy rate within rural healthcare settings characterized by data\nconstraints.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00254v1",
    "published_date": "2024-03-01 03:39:17 UTC",
    "updated_date": "2024-03-01 03:39:17 UTC"
  },
  {
    "arxiv_id": "2403.00252v2",
    "title": "EUROPA: A Legal Multilingual Keyphrase Generation Dataset",
    "authors": [
      "Olivier Sala√ºn",
      "Fr√©d√©ric Piedboeuf",
      "Guillaume Le Berre",
      "David Alfonso Hermelo",
      "Philippe Langlais"
    ],
    "abstract": "Keyphrase generation has primarily been explored within the context of\nacademic research articles, with a particular focus on scientific domains and\nthe English language. In this work, we present EUROPA, a dataset for\nmultilingual keyphrase generation in the legal domain. It is derived from legal\njudgments from the Court of Justice of the European Union (EU), and contains\ninstances in all 24 EU official languages. We run multilingual models on our\ncorpus and analyze the results, showing room for improvement on a\ndomain-specific multilingual corpus such as the one we present.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "19 pages, 2 figures, accepted at ACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.00252v2",
    "published_date": "2024-03-01 03:30:38 UTC",
    "updated_date": "2024-06-14 13:51:01 UTC"
  },
  {
    "arxiv_id": "2403.00867v3",
    "title": "Gradient Cuff: Detecting Jailbreak Attacks on Large Language Models by Exploring Refusal Loss Landscapes",
    "authors": [
      "Xiaomeng Hu",
      "Pin-Yu Chen",
      "Tsung-Yi Ho"
    ],
    "abstract": "Large Language Models (LLMs) are becoming a prominent generative AI tool,\nwhere the user enters a query and the LLM generates an answer. To reduce harm\nand misuse, efforts have been made to align these LLMs to human values using\nadvanced training techniques such as Reinforcement Learning from Human Feedback\n(RLHF). However, recent studies have highlighted the vulnerability of LLMs to\nadversarial jailbreak attempts aiming at subverting the embedded safety\nguardrails. To address this challenge, this paper defines and investigates the\nRefusal Loss of LLMs and then proposes a method called Gradient Cuff to detect\njailbreak attempts. Gradient Cuff exploits the unique properties observed in\nthe refusal loss landscape, including functional values and its smoothness, to\ndesign an effective two-step detection strategy. Experimental results on two\naligned LLMs (LLaMA-2-7B-Chat and Vicuna-7B-V1.5) and six types of jailbreak\nattacks (GCG, AutoDAN, PAIR, TAP, Base64, and LRL) show that Gradient Cuff can\nsignificantly improve the LLM's rejection capability for malicious jailbreak\nqueries, while maintaining the model's performance for benign user queries by\nadjusting the detection threshold.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "Accepted by NeurIPS 2024. Project page:\n  https://huggingface.co/spaces/TrustSafeAI/GradientCuff-Jailbreak-Defense",
    "pdf_url": "http://arxiv.org/pdf/2403.00867v3",
    "published_date": "2024-03-01 03:29:54 UTC",
    "updated_date": "2024-11-07 15:41:38 UTC"
  },
  {
    "arxiv_id": "2403.00250v1",
    "title": "Rethinking Classifier Re-Training in Long-Tailed Recognition: A Simple Logits Retargeting Approach",
    "authors": [
      "Han Lu",
      "Siyu Sun",
      "Yichen Xie",
      "Liqing Zhang",
      "Xiaokang Yang",
      "Junchi Yan"
    ],
    "abstract": "In the long-tailed recognition field, the Decoupled Training paradigm has\ndemonstrated remarkable capabilities among various methods. This paradigm\ndecouples the training process into separate representation learning and\nclassifier re-training. Previous works have attempted to improve both stages\nsimultaneously, making it difficult to isolate the effect of classifier\nre-training. Furthermore, recent empirical studies have demonstrated that\nsimple regularization can yield strong feature representations, emphasizing the\nneed to reassess existing classifier re-training methods. In this study, we\nrevisit classifier re-training methods based on a unified feature\nrepresentation and re-evaluate their performances. We propose a new metric\ncalled Logits Magnitude as a superior measure of model performance, replacing\nthe commonly used Weight Norm. However, since it is hard to directly optimize\nthe new metric during training, we introduce a suitable approximate invariant\ncalled Regularized Standard Deviation. Based on the two newly proposed metrics,\nwe prove that reducing the absolute value of Logits Magnitude when it is nearly\nbalanced can effectively decrease errors and disturbances during training,\nleading to better model performance. Motivated by these findings, we develop a\nsimple logits retargeting approach (LORT) without the requirement of prior\nknowledge of the number of samples per class. LORT divides the original one-hot\nlabel into small true label probabilities and large negative label\nprobabilities distributed across each class. Our method achieves\nstate-of-the-art performance on various imbalanced datasets, including\nCIFAR100-LT, ImageNet-LT, and iNaturalist2018.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00250v1",
    "published_date": "2024-03-01 03:27:08 UTC",
    "updated_date": "2024-03-01 03:27:08 UTC"
  },
  {
    "arxiv_id": "2403.00236v1",
    "title": "Benchmarking zero-shot stance detection with FlanT5-XXL: Insights from training data, prompting, and decoding strategies into its near-SoTA performance",
    "authors": [
      "Rachith Aiyappa",
      "Shruthi Senthilmani",
      "Jisun An",
      "Haewoon Kwak",
      "Yong-Yeol Ahn"
    ],
    "abstract": "We investigate the performance of LLM-based zero-shot stance detection on\ntweets. Using FlanT5-XXL, an instruction-tuned open-source LLM, with the\nSemEval 2016 Tasks 6A, 6B, and P-Stance datasets, we study the performance and\nits variations under different prompts and decoding strategies, as well as the\npotential biases of the model. We show that the zero-shot approach can match or\noutperform state-of-the-art benchmarks, including fine-tuned models. We provide\nvarious insights into its performance including the sensitivity to instructions\nand prompts, the decoding strategies, the perplexity of the prompts, and to\nnegations and oppositions present in prompts. Finally, we ensure that the LLM\nhas not been trained on test datasets, and identify a positivity bias which may\npartially explain the performance differences across decoding strategie",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00236v1",
    "published_date": "2024-03-01 02:33:26 UTC",
    "updated_date": "2024-03-01 02:33:26 UTC"
  },
  {
    "arxiv_id": "2403.00865v1",
    "title": "Fast and Efficient Local Search for Genetic Programming Based Loss Function Learning",
    "authors": [
      "Christian Raymond",
      "Qi Chen",
      "Bing Xue",
      "Mengjie Zhang"
    ],
    "abstract": "In this paper, we develop upon the topic of loss function learning, an\nemergent meta-learning paradigm that aims to learn loss functions that\nsignificantly improve the performance of the models trained under them.\nSpecifically, we propose a new meta-learning framework for task and\nmodel-agnostic loss function learning via a hybrid search approach. The\nframework first uses genetic programming to find a set of symbolic loss\nfunctions. Second, the set of learned loss functions is subsequently\nparameterized and optimized via unrolled differentiation. The versatility and\nperformance of the proposed framework are empirically validated on a diverse\nset of supervised learning tasks. Results show that the learned loss functions\nbring improved convergence, sample efficiency, and inference performance on\ntabulated, computer vision, and natural language processing problems, using a\nvariety of task-specific neural network architectures.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2209.08907",
    "pdf_url": "http://arxiv.org/pdf/2403.00865v1",
    "published_date": "2024-03-01 02:20:04 UTC",
    "updated_date": "2024-03-01 02:20:04 UTC"
  },
  {
    "arxiv_id": "2403.00225v3",
    "title": "Robust Policy Learning via Offline Skill Diffusion",
    "authors": [
      "Woo Kyung Kim",
      "Minjong Yoo",
      "Honguk Woo"
    ],
    "abstract": "Skill-based reinforcement learning (RL) approaches have shown considerable\npromise, especially in solving long-horizon tasks via hierarchical structures.\nThese skills, learned task-agnostically from offline datasets, can accelerate\nthe policy learning process for new tasks. Yet, the application of these skills\nin different domains remains restricted due to their inherent dependency on the\ndatasets, which poses a challenge when attempting to learn a skill-based policy\nvia RL for a target domain different from the datasets' domains. In this paper,\nwe present a novel offline skill learning framework DuSkill which employs a\nguided Diffusion model to generate versatile skills extended from the limited\nskills in datasets, thereby enhancing the robustness of policy learning for\ntasks in different domains. Specifically, we devise a guided diffusion-based\nskill decoder in conjunction with the hierarchical encoding to disentangle the\nskill embedding space into two distinct representations, one for encapsulating\ndomain-invariant behaviors and the other for delineating the factors that\ninduce domain variations in the behaviors. Our DuSkill framework enhances the\ndiversity of skills learned offline, thus enabling to accelerate the learning\nprocedure of high-level policies for different domains. Through experiments, we\nshow that DuSkill outperforms other skill-based imitation learning and RL\nalgorithms for several long-horizon tasks, demonstrating its benefits in\nfew-shot imitation and online RL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 6 figures; Accepted for AAAI Conference on Artificial\n  Intelligence (AAAI 2024); Published version",
    "pdf_url": "http://arxiv.org/pdf/2403.00225v3",
    "published_date": "2024-03-01 02:00:44 UTC",
    "updated_date": "2024-08-22 04:03:10 UTC"
  },
  {
    "arxiv_id": "2403.15408v1",
    "title": "Multi-modal Heart Failure Risk Estimation based on Short ECG and Sampled Long-Term HRV",
    "authors": [
      "Sergio Gonz√°lez",
      "Abel Ko-Chun Yi",
      "Wan-Ting Hsieh",
      "Wei-Chao Chen",
      "Chun-Li Wang",
      "Victor Chien-Chia Wu",
      "Shang-Hung Chang"
    ],
    "abstract": "Cardiovascular diseases, including Heart Failure (HF), remain a leading\nglobal cause of mortality, often evading early detection. In this context,\naccessible and effective risk assessment is indispensable. Traditional\napproaches rely on resource-intensive diagnostic tests, typically administered\nafter the onset of symptoms. The widespread availability of electrocardiogram\n(ECG) technology and the power of Machine Learning are emerging as viable\nalternatives within smart healthcare. In this paper, we propose several\nmulti-modal approaches that combine 30-second ECG recordings and approximate\nlong-term Heart Rate Variability (HRV) data to estimate the risk of HF\nhospitalization. We introduce two survival models: an XGBoost model with\nAccelerated Failure Time (AFT) incorporating comprehensive ECG features and a\nResNet model that learns from the raw ECG. We extend these with our novel\nlong-term HRVs extracted from the combination of ultra-short-term beat-to-beat\nmeasurements taken over the day. To capture their temporal dynamics, we propose\na survival model comprising ResNet and Transformer architectures (TFM-ResNet).\nOur experiments demonstrate high model performance for HF risk assessment with\na concordance index of 0.8537 compared to 14 survival models and competitive\ndiscrimination power on various external ECG datasets. After transferability\ntests with Apple Watch data, our approach implemented in the myHeartScore App\noffers cost-effective and highly accessible HF risk assessment, contributing to\nits prevention and management.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.15408v1",
    "published_date": "2024-03-01 01:16:27 UTC",
    "updated_date": "2024-03-01 01:16:27 UTC"
  },
  {
    "arxiv_id": "2403.00198v1",
    "title": "AXOLOTL: Fairness through Assisted Self-Debiasing of Large Language Model Outputs",
    "authors": [
      "Sana Ebrahimi",
      "Kaiwen Chen",
      "Abolfazl Asudeh",
      "Gautam Das",
      "Nick Koudas"
    ],
    "abstract": "Pre-trained Large Language Models (LLMs) have significantly advanced natural\nlanguage processing capabilities but are susceptible to biases present in their\ntraining data, leading to unfair outcomes in various applications. While\nnumerous strategies have been proposed to mitigate bias, they often require\nextensive computational resources and may compromise model performance. In this\nwork, we introduce AXOLOTL, a novel post-processing framework, which operates\nagnostically across tasks and models, leveraging public APIs to interact with\nLLMs without direct access to internal parameters. Through a three-step process\nresembling zero-shot learning, AXOLOTL identifies biases, proposes resolutions,\nand guides the model to self-debias its outputs. This approach minimizes\ncomputational costs and preserves model performance, making AXOLOTL a promising\ntool for debiasing LLM outputs with broad applicability and ease of use.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.00198v1",
    "published_date": "2024-03-01 00:02:37 UTC",
    "updated_date": "2024-03-01 00:02:37 UTC"
  }
]