{
  "date": "2024-05-26",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-26 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 更新了 66 篇论文，主要聚焦于 AI 模型优化（如 LLM 和多模态生成）、强化学习应用以及医疗 AI 的安全性和潜力，其中第一篇 PhD 论文和 LLM 相关研究（如第 3、7 篇）尤为突出，展示了有影响力学者（如 Jianfeng Gao）的创新工作，同时强调了 AI 在实际领域的挑战和改进。\n\n下面，我挑选并简要讨论几篇重要、令人印象深刻的论文，先从高话题度或知名学者参与的文章入手（如 LLM 和多模态模型），然后快速掠过其他相关或次要论文。重点捕捉每篇的核心贡献、方法和发现。\n\n### 重要论文讨论\n\n**Towards Multi-Task Multi-Modal Models: A Video Generative Perspective（多任务多模态模型：视频生成视角）**  \n这篇 PhD 论文由 Lijun Yu 撰写，探讨了构建多任务多模态模型，用于视频生成和理解。核心贡献是通过高效的视频分词器和可扩展的视觉标记表示，实现了语言模型在视觉合成中超越扩散模型的首次里程石，显著提升了生成质量和效率。\n\n**Crafting Interpretable Embeddings by Asking LLMs Questions（通过询问 LLM 创建可解释嵌入）**  \n作者包括 Jianfeng Gao，这篇论文引入了 QA-Emb 方法，利用 LLM 回答是/否问题生成可解释嵌入。关键发现是这种方法显著提高了 fMRI 预测的准确性，同时适用于简单 NLP 任务，提供更透明的语义表示。\n\n**Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method（自适应激活引导：无需调整的 LLM 真实性改进方法）**  \n论文提出 ACT 方法，通过自适应调整 LLM 激活以提升真实性。主贡献在于处理多种幻觉类型，提高了 LLaMA 等模型的输出准确性（如 LLaMA 提升 142%），并证明了其在更大规模模型上的可扩展性。\n\n**Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models（医疗多模态 LLM 易受攻击：跨模态越狱和不匹配攻击）**  \n这篇研究构建了 3MAD 数据集，并优化了攻击方法，揭示了医疗 MLLM 的安全漏洞。核心发现是即使增强安全性的模型也易受越狱攻击，强调了需要更强的防御机制。\n\n**ID-to-3D: Expressive ID-guided 3D Heads via Score Distillation Sampling（ID 到 3D：通过分数蒸馏采样进行表达性 ID 引导 3D 头部）**  \n作者包括 Stefanos Zafeiriou，论文开发了 ID-to-3D 方法，使用微调的扩散模型生成基于 ID 的 3D 头部。关键贡献是实现了高保真 3D 面部重建，包括发型和配饰，适用于游戏和远程存在场景。\n\n### 相关论文快速掠过\n\n其他论文主题多样，以 AI 生成和医疗为主，以次要顺序简述：\n\n**Zamba: A Compact 7B SSM Hybrid Model（Zamba：紧凑的 7B SSM 混合模型）**  \n提出 Zamba 模型，结合 Mamba 和注意力机制，提升了生成效率和性能，适合长序列任务。\n\n**The AI-DEC: A Card-based Design Method for User-centered AI Explanations（AI-DEC：基于卡片的以用户为中心 AI 解释设计方法）**  \n开发了 AI-DEC 框架，帮助设计 AI 解释，聚焦沟通内容和模式，提高了用户交互体验。\n\n**SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective Citation Recommendation（SymTax：共生关系和分类融合的有效引文推荐）**  \n引入超球面嵌入计算查询-候选相似性，提升了引文推荐的召回率（Recall@5 提升 22.56%）。\n\n**Mixture of Latent Experts Using Tensor Products（潜在专家混合使用张量乘积）**  \n优化多任务学习，通过张量操作提升参数效率，在 T0 基准上超越密集模型。\n\n**A Survey of Multimodal Large Language Model from A Data-centric Perspective（多模态大语言模型的多模态视角调查）**  \n综述了 MLLM 的数据准备和评估方法，强调数据在预训练中的关键作用。\n\n**Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning（Fast TRAC：无参数优化器用于终身强化学习）**  \n提出无参数优化器，缓解分布偏移问题，在 Atari 等环境中提升了适应性。\n\n**Bayesian Inference with Deep Weakly Nonlinear Networks（使用深度弱非线性网络的贝叶斯推理）**  \n分析了神经网络在高维空间的贝叶斯推理，提供了证据和泛化误差的理论界。\n\n其余论文如强化学习、图神经网络和生成模型的变体（如第13、15、39、50篇），虽有贡献但相对常规，快速提及：它们分别在算术学习加速、医疗预测和图攻击防御上提供了新方法，但细节较窄众，不展开讨论。\n\n总之，今天的论文突显了 AI 领域的创新与挑战，LLM 和多模态模型的进展值得关注，期待后续应用！（本快报基于66篇论文精选，保持简洁以便快速阅读。）",
  "papers": [
    {
      "arxiv_id": "2405.16728v1",
      "title": "Towards Multi-Task Multi-Modal Models: A Video Generative Perspective",
      "title_zh": "迈向多任务多模态模型：视频生成视角",
      "authors": [
        "Lijun Yu"
      ],
      "abstract": "Advancements in language foundation models have primarily fueled the recent\nsurge in artificial intelligence. In contrast, generative learning of\nnon-textual modalities, especially videos, significantly trails behind language\nmodeling. This thesis chronicles our endeavor to build multi-task models for\ngenerating videos and other modalities under diverse conditions, as well as for\nunderstanding and compression applications. Given the high dimensionality of\nvisual data, we pursue concise and accurate latent representations. Our\nvideo-native spatial-temporal tokenizers preserve high fidelity. We unveil a\nnovel approach to mapping bidirectionally between visual observation and\ninterpretable lexical terms. Furthermore, our scalable visual token\nrepresentation proves beneficial across generation, compression, and\nunderstanding tasks. This achievement marks the first instances of language\nmodels surpassing diffusion models in visual synthesis and a video tokenizer\noutperforming industry-standard codecs. Within these multi-modal latent spaces,\nwe study the design of multi-task generative models. Our masked multi-task\ntransformer excels at the quality, efficiency, and flexibility of video\ngeneration. We enable a frozen language model, trained solely on text, to\ngenerate visual content. Finally, we build a scalable generative multi-modal\ntransformer trained from scratch, enabling the generation of videos containing\nhigh-fidelity motion with the corresponding audio given diverse conditions.\nThroughout the course, we have shown the effectiveness of integrating multiple\ntasks, crafting high-fidelity latent representation, and generating multiple\nmodalities. This work suggests intriguing potential for future exploration in\ngenerating non-textual data and enabling real-time, interactive experiences\nacross various media forms.",
      "tldr_zh": "该论文探讨了从视频生成视角构建多任务多模态模型，以推进非文本模态（如视频）的生成、理解和压缩。研究团队开发了视频原生的空间-时间标记化器（spatial-temporal tokenizers），实现了高保真潜在表示，并实现了语言模型在视觉合成中超越扩散模型（diffusion models）的首次里程碑。最终，他们设计了蒙版多任务Transformer（masked multi-task transformer），使冻结的语言模型生成视觉内容，并构建可扩展的多模态Transformer，能生成高质量视频和音频，这为非文本数据生成和实时交互体验提供了新潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2405.16728v1",
      "published_date": "2024-05-26 23:56:45 UTC",
      "updated_date": "2024-05-26 23:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:04:56.573387"
    },
    {
      "arxiv_id": "2405.16718v1",
      "title": "Amortized Active Causal Induction with Deep Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yashas Annadani",
        "Panagiotis Tigas",
        "Stefan Bauer",
        "Adam Foster"
      ],
      "abstract": "We present Causal Amortized Active Structure Learning (CAASL), an active\nintervention design policy that can select interventions that are adaptive,\nreal-time and that does not require access to the likelihood. This policy, an\namortized network based on the transformer, is trained with reinforcement\nlearning on a simulator of the design environment, and a reward function that\nmeasures how close the true causal graph is to a causal graph posterior\ninferred from the gathered data. On synthetic data and a single-cell gene\nexpression simulator, we demonstrate empirically that the data acquired through\nour policy results in a better estimate of the underlying causal graph than\nalternative strategies. Our design policy successfully achieves amortized\nintervention design on the distribution of the training environment while also\ngeneralizing well to distribution shifts in test-time design environments.\nFurther, our policy also demonstrates excellent zero-shot generalization to\ndesign environments with dimensionality higher than that during training, and\nto intervention types that it has not been trained on.",
      "tldr_zh": "本研究提出了一种名为Causal Amortized Active Structure Learning (CAASL)的主动干预设计策略，利用基于Transformer的摊销网络和深度强化学习进行训练。该策略能够在模拟环境中通过奖励函数优化干预选择，使推断的因果图更接近真实因果图，且无需访问似然函数。在合成数据和单细胞基因表达模拟器上的实验表明，CAASL获取的数据显著改善了底层因果图的估计，并比传统策略表现更优。此外，该策略展现出优秀的泛化能力，能够适应分布偏移、更高维度环境以及未训练过的干预类型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16718v1",
      "published_date": "2024-05-26 23:14:37 UTC",
      "updated_date": "2024-05-26 23:14:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:05:07.134141"
    },
    {
      "arxiv_id": "2405.16714v1",
      "title": "Crafting Interpretable Embeddings by Asking LLMs Questions",
      "title_zh": "翻译失败",
      "authors": [
        "Vinamra Benara",
        "Chandan Singh",
        "John X. Morris",
        "Richard Antonello",
        "Ion Stoica",
        "Alexander G. Huth",
        "Jianfeng Gao"
      ],
      "abstract": "Large language models (LLMs) have rapidly improved text embeddings for a\ngrowing array of natural-language processing tasks. However, their opaqueness\nand proliferation into scientific domains such as neuroscience have created a\ngrowing need for interpretability. Here, we ask whether we can obtain\ninterpretable embeddings through LLM prompting. We introduce question-answering\nembeddings (QA-Emb), embeddings where each feature represents an answer to a\nyes/no question asked to an LLM. Training QA-Emb reduces to selecting a set of\nunderlying questions rather than learning model weights.\n  We use QA-Emb to flexibly generate interpretable models for predicting fMRI\nvoxel responses to language stimuli. QA-Emb significantly outperforms an\nestablished interpretable baseline, and does so while requiring very few\nquestions. This paves the way towards building flexible feature spaces that can\nconcretize and evaluate our understanding of semantic brain representations. We\nadditionally find that QA-Emb can be effectively approximated with an efficient\nmodel, and we explore broader applications in simple NLP tasks.",
      "tldr_zh": "本文提出 QA-Emb，一种通过向大型语言模型（LLMs）提问是/否问题来生成可解释嵌入的方法，其中每个特征代表一个问题的答案，从而避免了传统模型权重学习。研究应用 QA-Emb 于预测 fMRI 体素对语言刺激的响应，显著优于现有可解释基线，且仅需少量问题，这有助于深化对语义脑表示的理解。进一步探索显示，QA-Emb 可通过高效模型近似，并在简单 NLP 任务中展现潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16714v1",
      "published_date": "2024-05-26 22:30:29 UTC",
      "updated_date": "2024-05-26 22:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:05:18.786900"
    },
    {
      "arxiv_id": "2405.16712v1",
      "title": "Zamba: A Compact 7B SSM Hybrid Model",
      "title_zh": "翻译失败",
      "authors": [
        "Paolo Glorioso",
        "Quentin Anthony",
        "Yury Tokpanov",
        "James Whittington",
        "Jonathan Pilault",
        "Adam Ibrahim",
        "Beren Millidge"
      ],
      "abstract": "In this technical report, we present Zamba, a novel 7B SSM-transformer hybrid\nmodel which achieves competitive performance against leading open-weight models\nat a comparable scale. Zamba is trained on 1T tokens from openly available\ndatasets and is the best non-transformer model at this scale. Zamba pioneers a\nunique architecture combining a Mamba backbone with a single shared attention\nmodule, thus obtaining the benefits of attention at minimal parameter cost. Due\nto its architecture, Zamba is significantly faster at inference than comparable\ntransformer models and requires substantially less memory for generation of\nlong sequences. Zamba is pretrained in two phases: the first phase is based on\nexisting web datasets, while the second one consists of annealing the model\nover high-quality instruct and synthetic datasets, and is characterized by a\nrapid learning rate decay. We open-source the weights and all checkpoints for\nZamba, through both phase 1 and annealing phases.",
      "tldr_zh": "该研究介绍了 Zamba，一种紧凑的 7B 参数 SSM-transformer 混合模型，在同等规模下与领先开源模型竞争表现，并成为最佳非-transformer 模型。Zamba 采用创新架构，将 Mamba 主干与单个共享注意力模块结合，实现了注意力的优势，同时最小化参数成本。模型在 1T 标记的公开数据集上训练，分两个阶段进行：第一阶段基于现有网络数据集，第二阶段通过退火在高质量指令和合成数据集上优化，伴随快速学习率衰减。相比传统 transformer 模型，Zamba 的推理速度更快，且在生成长序列时需要更少内存；作者开源了所有模型权重和检查点，以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16712v1",
      "published_date": "2024-05-26 22:23:02 UTC",
      "updated_date": "2024-05-26 22:23:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:05:32.642828"
    },
    {
      "arxiv_id": "2405.16711v1",
      "title": "The AI-DEC: A Card-based Design Method for User-centered AI Explanations",
      "title_zh": "AI-DEC：一种基于卡片的面向用户中心的 AI 解释设计方法",
      "authors": [
        "Christine P Lee",
        "Min Kyung Lee",
        "Bilge Mutlu"
      ],
      "abstract": "Increasing evidence suggests that many deployed AI systems do not\nsufficiently support end-user interaction and information needs. Engaging\nend-users in the design of these systems can reveal user needs and\nexpectations, yet effective ways of engaging end-users in the AI explanation\ndesign remain under-explored. To address this gap, we developed a design\nmethod, called AI-DEC, that defines four dimensions of AI explanations that are\ncritical for the integration of AI systems -- communication content, modality,\nfrequency, and direction -- and offers design examples for end-users to design\nAI explanations that meet their needs. We evaluated this method through\nco-design sessions with workers in healthcare, finance, and management\nindustries who regularly use AI systems in their daily work. Findings indicate\nthat the AI-DEC effectively supported workers in designing explanations that\naccommodated diverse levels of performance and autonomy needs, which varied\ndepending on the AI system's workplace role and worker values. We discuss the\nimplications of using the AI-DEC for the user-centered design of AI\nexplanations in real-world systems.",
      "tldr_zh": "这篇论文介绍了 AI-DEC，一种基于卡片的(user-centered)设计方法，旨在通过定义四个关键维度——communication content、modality、frequency 和 direction——来帮助用户设计符合自身需求的 AI 解释。方法提供设计示例，并通过与医疗、金融和管理行业从业者的 co-design sessions 进行评估，结果显示 AI-DEC 有效支持用户创建适应不同性能和自治需求的解释，这些需求受 AI 在工作场所角色和用户价值观的影响。最后，论文讨论了将 AI-DEC 应用于真实系统以提升用户中心 AI 设计的启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16711v1",
      "published_date": "2024-05-26 22:18:38 UTC",
      "updated_date": "2024-05-26 22:18:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:05:43.372012"
    },
    {
      "arxiv_id": "2406.01606v1",
      "title": "SymTax: Symbiotic Relationship and Taxonomy Fusion for Effective Citation Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Karan Goyal",
        "Mayank Goel",
        "Vikram Goyal",
        "Mukesh Mohania"
      ],
      "abstract": "Citing pertinent literature is pivotal to writing and reviewing a scientific\ndocument. Existing techniques mainly focus on the local context or the global\ncontext for recommending citations but fail to consider the actual human\ncitation behaviour. We propose SymTax, a three-stage recommendation\narchitecture that considers both the local and the global context, and\nadditionally the taxonomical representations of query-candidate tuples and the\nSymbiosis prevailing amongst them. SymTax learns to embed the infused\ntaxonomies in the hyperbolic space and uses hyperbolic separation as a latent\nfeature to compute query-candidate similarity. We build a novel and large\ndataset ArSyTa containing 8.27 million citation contexts and describe the\ncreation process in detail. We conduct extensive experiments and ablation\nstudies to demonstrate the effectiveness and design choice of each module in\nour framework. Also, combinatorial analysis from our experiments shed light on\nthe choice of language models (LMs) and fusion embedding, and the inclusion of\nsection heading as a signal. Our proposed module that captures the symbiotic\nrelationship solely leads to performance gains of 26.66% and 39.25% in Recall@5\nw.r.t. SOTA on ACL-200 and RefSeer datasets, respectively. The complete\nframework yields a gain of 22.56% in Recall@5 wrt SOTA on our proposed dataset.\nThe code and dataset are available at https://github.com/goyalkaraniit/SymTax",
      "tldr_zh": "本研究提出SymTax框架，一种三阶段的引用推荐架构，融合本地和全局上下文、查询-候选对的taxonomy表示以及它们之间的symbiotic relationship，以更好地模拟人类引用行为。SymTax在双曲空间(hyperbolic space)中嵌入分类学，并利用双曲分离计算相似度，同时构建了一个包含827万引用上下文的新数据集ArSyTa。实验结果显示，该框架在ACL-200和RefSeer数据集上分别提高了26.66%和39.25%的Recall@5性能，并在ArSyTa数据集上实现22.56%的Recall@5提升，证明了各模块的有效性和设计选择。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted in ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.01606v1",
      "published_date": "2024-05-26 21:51:58 UTC",
      "updated_date": "2024-05-26 21:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:05:55.709868"
    },
    {
      "arxiv_id": "2406.00034v2",
      "title": "Adaptive Activation Steering: A Tuning-Free LLM Truthfulness Improvement Method for Diverse Hallucinations Categories",
      "title_zh": "翻译失败",
      "authors": [
        "Tianlong Wang",
        "Xianfeng Jiao",
        "Yinghao Zhu",
        "Zhongzhi Chen",
        "Yifan He",
        "Xu Chu",
        "Junyi Gao",
        "Yasha Wang",
        "Liantao Ma"
      ],
      "abstract": "Recent studies have indicated that Large Language Models (LLMs) harbor an\ninherent understanding of truthfulness, yet often fail to consistently express\nit and generate false statements. This gap between \"knowing\" and \"telling\"\nposes a challenge for ensuring the truthfulness of generated content. Inspired\nby recent work on the practice of encoding human-interpretable concepts\nlinearly within large language models, we treat truthfulness as a specially\nlinearly encoded concept within LLMs, and introduce Adaptive Activation\nSteering (ACT), a tuning-free method that adaptively shifts LLM's activations\nin the \"truthful\" direction during inference. ACT addresses diverse categories\nof hallucinations by utilizing diverse truthfulness-related steering vectors\nand adjusting the steering intensity adaptively. Applied as an add-on across\nvarious models, ACT significantly improves truthfulness in LLaMA ($\\uparrow$\n142%), LLaMA2 ($\\uparrow$ 24%), Alpaca ($\\uparrow$ 36%), Vicuna ($\\uparrow$\n28%), LLaMA2-Chat ($\\uparrow$ 19%), and LLaMA3($\\uparrow$ 34%). Furthermore, we\nverify ACT's scalability across larger models (13B, 33B, 65B), underscoring the\nadaptability of ACT to large-scale language models. Our code is available at\nhttps://github.com/tianlwang/ACT.",
      "tldr_zh": "该研究发现，大语言模型(LLMs)虽然内在理解真实性，但常因“知道”与“表达”脱节而生成虚假语句。论文提出Adaptive Activation Steering (ACT)，一种无需微调的推理方法，通过利用多样真实性相关转向向量并自适应调整激活强度，来处理各种幻觉类别。在多个模型上实验显示，ACT显著提升了真实性表现，如LLaMA提升142%、LLaMA2提升24%，并验证了其在大规模模型(13B、33B、65B)上的可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACM TheWebConf 2025 Conference (WWW 2025) Research Track",
      "pdf_url": "http://arxiv.org/pdf/2406.00034v2",
      "published_date": "2024-05-26 21:39:53 UTC",
      "updated_date": "2025-02-26 14:07:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:06:06.662131"
    },
    {
      "arxiv_id": "2405.16693v1",
      "title": "Detection of decision-making manipulation in the pairwise comparisons method",
      "title_zh": "在成对比较方法中决策操纵的检测",
      "authors": [
        "Michał Strada",
        "Sebastian Ernst",
        "Jacek Szybowski",
        "Konrad Kułakowski"
      ],
      "abstract": "Most decision-making models, including the pairwise comparison method, assume\nthe decision-makers honesty. However, it is easy to imagine a situation where a\ndecision-maker tries to manipulate the ranking results. This paper presents\nthree simple manipulation methods in the pairwise comparison method. We then\ntry to detect these methods using appropriately constructed neural networks.\nExperimental results accompany the proposed solutions on the generated data,\nshowing a considerable manipulation detection level.",
      "tldr_zh": "这篇论文探讨了配对比较方法(pairwise comparisons method)中决策操纵(detection of decision-making manipulation)的潜在问题，强调决策者可能试图扭曲排名结果。作者提出了三种简单的操纵方法，并利用神经网络(neural networks)构建模型来检测这些操纵。实验在生成的数据上显示，该检测方法取得了显著的效果。",
      "categories": [
        "cs.AI",
        "cs.DM"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 5 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.16693v1",
      "published_date": "2024-05-26 20:58:12 UTC",
      "updated_date": "2024-05-26 20:58:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:06:16.847726"
    },
    {
      "arxiv_id": "2407.12145v1",
      "title": "Adoption and Impact of ChatGPT in Computer Science Education: A Case Study on a Database Administration Course",
      "title_zh": "ChatGPT 在计算机科学教育中的采用和影响：一个数据库管理课程的案例研究",
      "authors": [
        "Daniel López-Fernández",
        "Ricardo Vergaz"
      ],
      "abstract": "Contribution: The combination of ChatGPT with traditional learning resources\nis very effective in computer science education. High-performing students are\nthe ones who are using ChatGPT the most. So, a new digital trench could be\nrising between these students and those with lower degree of fundamentals and\nworse prompting skills, who may not take advantage of all the ChatGPT\npossibilities. Background: The irruption of GenAI such as ChatGPT has changed\nthe educational landscape. Therefore, methodological guidelines and more\nempirical experiences in computer science education are needed to better\nunderstand these tools and know how to use them to their fullest potential.\nResearch Questions: This article addresses three questions. The first two\nexplore the degree of use and perceived usefulness of ChatGPT among computer\nscience students to learn database administration, where as the third one\nexplore how the utilization of ChatGPT can impact academic performance.\nMethodology: This contribution presents an exploratory and correlational study\nconducted with 37 students who used ChatGPT as a support tool to learn database\nadministration. The student grades and a comprehensive questionnaire were\nemployed as research instruments. Findings: The obtained results indicate that\ntraditional learning resources, such as teacher explanations and student\nreports, were widely used and correlated positively with student grade. The\nusage and perceived utility of ChatGPT were moderate, but positive correlations\nbetween student grade and ChatGPT usage were found. Indeed, a significantly\nhigher use of this tool was identified among the group of outstanding students.",
      "tldr_zh": "这篇论文探讨了 ChatGPT 在计算机科学教育中的采用和影响，特别针对一门数据库管理课程的案例研究。研究通过对 37 名学生的探索性和相关性分析，包括问卷和成绩评估，发现 ChatGPT 与传统学习资源（如教师解释和学生报告）结合，能有效提升学习效果，且其使用与学术表现正相关。关键发现是，高绩效学生更频繁使用 ChatGPT，这可能加剧 digital trench，即基础薄弱或提示技能较差的学生无法充分利用该工具。总的来说，该研究强调了 GenAI 在教育中的潜力，同时呼吁关注潜在的不平等问题。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12145v1",
      "published_date": "2024-05-26 20:51:28 UTC",
      "updated_date": "2024-05-26 20:51:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:06:30.374418"
    },
    {
      "arxiv_id": "2405.16671v2",
      "title": "Mixture of Latent Experts Using Tensor Products",
      "title_zh": "翻译失败",
      "authors": [
        "Zhan Su",
        "Fengran Mo",
        "Prayag Tiwari",
        "Benyou Wang",
        "Jian-Yun Nie",
        "Jakob Grue Simonsen"
      ],
      "abstract": "In multi-task learning, the conventional approach involves training a model\non multiple tasks simultaneously. However, the training signals from different\ntasks can interfere with one another, potentially leading to \\textit{negative\ntransfer}. To mitigate this, we investigate if modular language models can\nfacilitate positive transfer and systematic generalization. Specifically, we\npropose a novel modular language model (\\texttt{TensorPoly}), that balances\nparameter efficiency with nuanced routing methods. For \\textit{modules}, we\nreparameterize Low-Rank Adaptation (\\texttt{LoRA}) by employing an entangled\ntensor through the use of tensor product operations and name the resulting\napproach \\texttt{TLoRA}. For \\textit{routing function}, we tailor two\ninnovative routing functions according to the granularity:\n\\texttt{TensorPoly-I} which directs to each rank within the entangled tensor\nwhile \\texttt{TensorPoly-II} offers a finer-grained routing approach targeting\neach order of the entangled tensor. The experimental results from the\nmulti-task T0-benchmark demonstrate that: 1) all modular LMs surpass the\ncorresponding dense approaches, highlighting the potential of modular language\nmodels to mitigate negative inference in multi-task learning and deliver\nsuperior outcomes. 2) \\texttt{TensorPoly-I} achieves higher parameter\nefficiency in adaptation and outperforms other modular LMs, which shows the\npotential of our approach in multi-task transfer learning.",
      "tldr_zh": "本研究针对多任务学习(multi-task learning)中任务信号干扰导致的负转移(negative transfer)问题，提出了一种模块化语言模型TensorPoly，以实现参数高效和积极转移。具体而言，TensorPoly通过使用张量乘积(tensor products)重新参数化Low-Rank Adaptation(LoRA)来创建TLoRA模块，并设计了两种路由函数：TensorPoly-I（针对每个秩进行路由）和TensorPoly-II（针对张量阶进行更精细路由）。实验结果显示，在多任务T0-benchmark上，TensorPoly及其变体优于传统密集模型，其中TensorPoly-I在参数效率和性能上表现出色，证明了该方法在多任务转移学习中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/microsoft/mttl/tree/zs_code",
      "pdf_url": "http://arxiv.org/pdf/2405.16671v2",
      "published_date": "2024-05-26 19:25:08 UTC",
      "updated_date": "2024-12-05 19:03:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:06:41.819961"
    },
    {
      "arxiv_id": "2405.20775v2",
      "title": "Medical MLLM is Vulnerable: Cross-Modality Jailbreak and Mismatched Attacks on Medical Multimodal Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xijie Huang",
        "Xinyuan Wang",
        "Hantao Zhang",
        "Yinghao Zhu",
        "Jiawen Xi",
        "Jingkun An",
        "Hao Wang",
        "Hao Liang",
        "Chengwei Pan"
      ],
      "abstract": "Security concerns related to Large Language Models (LLMs) have been\nextensively explored, yet the safety implications for Multimodal Large Language\nModels (MLLMs), particularly in medical contexts (MedMLLMs), remain\ninsufficiently studied. This paper delves into the underexplored security\nvulnerabilities of MedMLLMs, especially when deployed in clinical environments\nwhere the accuracy and relevance of question-and-answer interactions are\ncritically tested against complex medical challenges. By combining existing\nclinical medical data with atypical natural phenomena, we define the mismatched\nmalicious attack (2M-attack) and introduce its optimized version, known as the\noptimized mismatched malicious attack (O2M-attack or 2M-optimization). Using\nthe voluminous 3MAD dataset that we construct, which covers a wide range of\nmedical image modalities and harmful medical scenarios, we conduct a\ncomprehensive analysis and propose the MCM optimization method, which\nsignificantly enhances the attack success rate on MedMLLMs. Evaluations with\nthis dataset and attack methods, including white-box attacks on LLaVA-Med and\ntransfer attacks (black-box) on four other SOTA models, indicate that even\nMedMLLMs designed with enhanced security features remain vulnerable to security\nbreaches. Our work underscores the urgent need for a concerted effort to\nimplement robust security measures and enhance the safety and efficacy of\nopen-source MedMLLMs, particularly given the potential severity of jailbreak\nattacks and other malicious or clinically significant exploits in medical\nsettings. Our code is available at https://github.com/dirtycomputer/O2M_attack.",
      "tldr_zh": "该论文揭示了医疗多模态大语言模型（MedMLLMs）的安全漏洞，特别是在临床环境中面临的跨模态越狱和不匹配攻击。研究者定义了不匹配恶意攻击（2M-attack）及其优化版本（O2M-attack），并构建了涵盖多种医疗图像模态和有害场景的3MAD数据集，同时提出了MCM优化方法来显著提高攻击成功率。实验结果显示，在LLaVA-Med的白盒攻击和四种其他SOTA模型的黑盒转移攻击中，MedMLLMs即使有增强安全功能仍高度脆弱，强调了在医疗设置中强化安全措施的紧迫性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20775v2",
      "published_date": "2024-05-26 19:11:21 UTC",
      "updated_date": "2024-08-21 02:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:06:56.101858"
    },
    {
      "arxiv_id": "2405.16661v2",
      "title": "RLSF: Reinforcement Learning via Symbolic Feedback",
      "title_zh": "RLSF: 通过符号反馈的强化学习",
      "authors": [
        "Piyush Jha",
        "Prithwish Jana",
        "Pranavkrishna Suresh",
        "Arnav Arora",
        "Vijay Ganesh"
      ],
      "abstract": "Reinforcement Learning with Human Feedback (RLHF) is considered a standard\napproach to fine-tuning Large Language Models (LLMs). However, such methods\noften face limitations such as unsound black-box reward models, difficulties in\ncollecting human preference data, and the reliance on sparse scalar rewards.\nThese methods often fall short when applied to tasks that require complex\ndomain-specific understanding.\n  To address these challenges, we propose a new fine-tuning paradigm we refer\nto as Reinforcement Learning via Symbolic Feedback (RLSF), which aims to\nimprove domain-specific understanding of LLMs more effectively than traditional\nreward signals. In the RLSF setting, the LLM being fine-tuned is considered an\nRL agent, while the environment is allowed access to reasoning or domain\nknowledge tools (e.g., solvers, provers, algebra systems, or knowledge bases).\nCrucially, in RLSF, these reasoning tools can provide feedback to the LLMs via\npoly-sized certificates (e.g., proofs), that characterize errors in the\nLLM-generated object with respect to some correctness specification. As a\nbonus, our RLSF approach does not require the reasoning systems we use to be\ndifferentiable. The ability of RLSF-based fine-tuning to leverage\ncertificate-generating symbolic tools enables sound fine-grained (token-level)\nreward signals to LLMs, and thus addresses the limitations of traditional\nreward models mentioned above.\n  Via extensive evaluations, we show that our RLSF-based fine-tuning of LLMs\noutperforms traditional approaches on five different applications, namely,\nprogram synthesis from natural language pseudo-code to programming language,\nthree chemistry tasks, and solving the Game of 24. A takeaway is that\nfine-tuning via RLSF enables relatively smaller LLMs to significantly\noutperform closed-source models that are orders of magnitude larger (e.g.,\nGPT-4).",
      "tldr_zh": "该论文提出了RLSF（Reinforcement Learning via Symbolic Feedback），一种新型微调大型语言模型（LLMs）的范式，以解决传统RLHF（Reinforcement Learning with Human Feedback）方法的局限性，如黑盒奖励模型、人类偏好数据收集困难和稀疏标量奖励问题。RLSF将LLMs视为强化学习代理，通过环境中的推理工具（如求解器或知识库）提供符号反馈，例如poly-sized certificates，来给出细粒度（token-level）的错误反馈，且无需这些工具可微。实验结果显示，RLSF在程序合成、化学任务和Game of 24等五个应用上优于传统方法，甚至使较小的LLMs显著超越如GPT-4这样规模更大的闭源模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16661v2",
      "published_date": "2024-05-26 18:49:59 UTC",
      "updated_date": "2024-10-05 23:17:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:07:06.648735"
    },
    {
      "arxiv_id": "2405.16658v1",
      "title": "Acceleration of Grokking in Learning Arithmetic Operations via Kolmogorov-Arnold Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Yeachan Park",
        "Minseok Kim",
        "Yeoneung Kim"
      ],
      "abstract": "We propose novel methodologies aimed at accelerating the grokking phenomenon,\nwhich refers to the rapid increment of test accuracy after a long period of\noverfitting as reported in~\\cite{power2022grokking}. Focusing on the grokking\nphenomenon that arises in learning arithmetic binary operations via the\ntransformer model, we begin with a discussion on data augmentation in the case\nof commutative binary operations. To further accelerate, we elucidate\narithmetic operations through the lens of the Kolmogorov-Arnold (KA)\nrepresentation theorem, revealing its correspondence to the transformer\narchitecture: embedding, decoder block, and classifier. Observing the shared\nstructure between KA representations associated with binary operations, we\nsuggest various transfer learning mechanisms that expedite grokking. This\ninterpretation is substantiated through a series of rigorous experiments. In\naddition, our approach is successful in learning two nonstandard arithmetic\ntasks: composition of operations and a system of equations. Furthermore, we\nreveal that the model is capable of learning arithmetic operations using a\nlimited number of tokens under embedding transfer, which is supported by a set\nof experiments as well.",
      "tldr_zh": "本研究提出新方法来加速“grokking”现象，即在训练Transformer模型学习算术二元运算时，经过长时间过拟合后测试准确率急剧提升。作者通过Kolmogorov-Arnold (KA) representation定理，将算术运算与Transformer的结构（如嵌入层、解码器块和分类器）对应起来，并结合数据增强和转移学习机制来进一步加快这一过程。实验结果显示，这些方法显著提升了grokking的速度，并在非标准任务如运算组合和方程系统中取得成功；此外，模型还能在嵌入转移下使用有限令牌数学习算术运算。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16658v1",
      "published_date": "2024-05-26 18:29:24 UTC",
      "updated_date": "2024-05-26 18:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:07:19.038811"
    },
    {
      "arxiv_id": "2405.16655v1",
      "title": "Predicting Likely-Vulnerable Code Changes: Machine Learning-based Vulnerability Protections for Android Open Source Project",
      "title_zh": "翻译失败",
      "authors": [
        "Keun Soo Yim"
      ],
      "abstract": "This paper presents a framework that selectively triggers security reviews\nfor incoming source code changes. Functioning as a review bot within a code\nreview service, the framework can automatically request additional security\nreviews at pre-submit time before the code changes are submitted to a source\ncode repository. Because performing such secure code reviews add cost, the\nframework employs a classifier trained to identify code changes with a high\nlikelihood of vulnerabilities. The online classifier leverages various types of\ninput features to analyze the review patterns, track the software engineering\nprocess, and mine specific text patterns within given code changes. The\nclassifier and its features are meticulously chosen and optimized using data\nfrom the submitted code changes and reported vulnerabilities in Android Open\nSource Project (AOSP). The evaluation results demonstrate that our\nVulnerability Prevention (VP) framework identifies approximately 80% of the\nvulnerability-inducing code changes in the dataset with a precision ratio of\naround 98% and a false positive rate of around 1.7%. We discuss the\nimplications of deploying the VP framework in multi-project settings and future\ndirections for Android security research. This paper explores and validates our\napproach to code change-granularity vulnerability prediction, offering a\npreventive technique for software security by preemptively detecting vulnerable\ncode changes before submission.",
      "tldr_zh": "这篇论文提出了一种基于 Machine Learning 的 Vulnerability Prevention (VP) 框架，用于预测 Android Open Source Project (AOSP) 中可能存在漏洞的代码变化。该框架作为一个 review bot，在代码审查服务中自动触发安全审查，通过一个训练好的 classifier 分析审查模式、软件工程过程以及代码变化中的文本模式来识别高风险变化。实验结果显示，该框架在数据集上识别约80%的漏洞代码变化，同时实现了98%的 precision 和1.7%的 false positive rate。这种方法为软件安全提供了预防性检测技术，并讨论了在多项目环境中的部署和未来研究方向。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "This is a preprint of an article that has been submitted to a journal\n  for publication",
      "pdf_url": "http://arxiv.org/pdf/2405.16655v1",
      "published_date": "2024-05-26 18:17:46 UTC",
      "updated_date": "2024-05-26 18:17:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:07:31.442053"
    },
    {
      "arxiv_id": "2405.16642v3",
      "title": "Fast TRAC: A Parameter-Free Optimizer for Lifelong Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aneesh Muppidi",
        "Zhiyu Zhang",
        "Heng Yang"
      ],
      "abstract": "A key challenge in lifelong reinforcement learning (RL) is the loss of\nplasticity, where previous learning progress hinders an agent's adaptation to\nnew tasks. While regularization and resetting can help, they require precise\nhyperparameter selection at the outset and environment-dependent adjustments.\nBuilding on the principled theory of online convex optimization, we present a\nparameter-free optimizer for lifelong RL, called TRAC, which requires no tuning\nor prior knowledge about the distribution shifts. Extensive experiments on\nProcgen, Atari, and Gym Control environments show that TRAC works surprisingly\nwell-mitigating loss of plasticity and rapidly adapting to challenging\ndistribution shifts-despite the underlying optimization problem being nonconvex\nand nonstationary.",
      "tldr_zh": "本研究针对终身强化学习(lifelong reinforcement learning)中的关键挑战——损失可塑性(loss of plasticity)，提出了一种无参数优化器TRAC。TRAC基于在线凸优化(online convex optimization)的理论设计，不需要调参或环境分布的先验知识，能够有效缓解学习干扰并快速适应分布偏移。在Procgen、Atari和Gym Control等环境中的大量实验证明，TRAC在非凸非平稳优化问题下表现出色，显著提升了适应性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Code and Website:\n  https://computationalrobotics.seas.harvard.edu/TRAC/",
      "pdf_url": "http://arxiv.org/pdf/2405.16642v3",
      "published_date": "2024-05-26 17:38:44 UTC",
      "updated_date": "2024-10-30 13:54:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:07:42.753272"
    },
    {
      "arxiv_id": "2405.16640v2",
      "title": "A Survey of Multimodal Large Language Model from A Data-centric Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Bai",
        "Hao Liang",
        "Binwang Wan",
        "Yanran Xu",
        "Xi Li",
        "Shiyu Li",
        "Ling Yang",
        "Bozhou Li",
        "Yifan Wang",
        "Bin Cui",
        "Ping Huang",
        "Jiulong Shan",
        "Conghui He",
        "Binhang Yuan",
        "Wentao Zhang"
      ],
      "abstract": "Multimodal large language models (MLLMs) enhance the capabilities of standard\nlarge language models by integrating and processing data from multiple\nmodalities, including text, vision, audio, video, and 3D environments. Data\nplays a pivotal role in the development and refinement of these models. In this\nsurvey, we comprehensively review the literature on MLLMs from a data-centric\nperspective. Specifically, we explore methods for preparing multimodal data\nduring the pretraining and adaptation phases of MLLMs. Additionally, we analyze\nthe evaluation methods for the datasets and review the benchmarks for\nevaluating MLLMs. Our survey also outlines potential future research\ndirections. This work aims to provide researchers with a detailed understanding\nof the data-driven aspects of MLLMs, fostering further exploration and\ninnovation in this field.",
      "tldr_zh": "这篇调查论文从数据中心视角审视多模态大型语言模型(MLLMs)，强调数据在整合文本、视觉、音频、视频和3D环境等模态方面的关键作用。论文探讨了MLLMs预训练和适应阶段的多模态数据准备方法，并分析了数据集的评估标准和基准测试，以评估模型性能。最终，该工作旨在为研究者提供数据驱动的深入理解，并指出未来研究方向，促进MLLMs领域的创新发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16640v2",
      "published_date": "2024-05-26 17:31:21 UTC",
      "updated_date": "2024-07-18 09:01:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:07:55.397529"
    },
    {
      "arxiv_id": "2405.17507v1",
      "title": "Enhancing Sustainable Urban Mobility Prediction with Telecom Data: A Spatio-Temporal Framework Approach",
      "title_zh": "翻译失败",
      "authors": [
        "ChungYi Lin",
        "Shen-Lung Tung",
        "Hung-Ting Su",
        "Winston H. Hsu"
      ],
      "abstract": "Traditional traffic prediction, limited by the scope of sensor data, falls\nshort in comprehensive traffic management. Mobile networks offer a promising\nalternative using network activity counts, but these lack crucial\ndirectionality. Thus, we present the TeltoMob dataset, featuring undirected\ntelecom counts and corresponding directional flows, to predict directional\nmobility flows on roadways. To address this, we propose a two-stage\nspatio-temporal graph neural network (STGNN) framework. The first stage uses a\npre-trained STGNN to process telecom data, while the second stage integrates\ndirectional and geographic insights for accurate prediction. Our experiments\ndemonstrate the framework's compatibility with various STGNN models and confirm\nits effectiveness. We also show how to incorporate the framework into\nreal-world transportation systems, enhancing sustainable urban mobility.",
      "tldr_zh": "该研究指出，传统交通预测因传感器数据范围有限而无法全面管理，而基于电信数据的网络活动计数虽有潜力但缺少方向性，因此引入 TeltoMob 数据集，该数据集包含无方向电信计数和对应的方向性流量，用于预测道路方向性流动性。  \n为了解决这一问题，研究提出一个两阶段时空图神经网络 (STGNN) 框架：第一阶段使用预训练 STGNN 处理电信数据，第二阶段整合方向性和地理信息以实现准确预测。  \n实验结果显示，该框架兼容多种 STGNN 模型，并证明其有效性，同时探讨了将其整合到真实交通系统中的方法，以提升可持续的城市流动性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "8 Figures, 5 Tables. Just accepted by IJCAI (to appear)",
      "pdf_url": "http://arxiv.org/pdf/2405.17507v1",
      "published_date": "2024-05-26 17:14:50 UTC",
      "updated_date": "2024-05-26 17:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:08:06.844357"
    },
    {
      "arxiv_id": "2405.16630v1",
      "title": "Bayesian Inference with Deep Weakly Nonlinear Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Boris Hanin",
        "Alexander Zlokapa"
      ],
      "abstract": "We show at a physics level of rigor that Bayesian inference with a fully\nconnected neural network and a shaped nonlinearity of the form $\\phi(t) = t +\n\\psi t^3/L$ is (perturbatively) solvable in the regime where the number of\ntraining datapoints $P$ , the input dimension $N_0$, the network layer widths\n$N$, and the network depth $L$ are simultaneously large. Our results hold with\nweak assumptions on the data; the main constraint is that $P < N_0$. We provide\ntechniques to compute the model evidence and posterior to arbitrary order in\n$1/N$ and at arbitrary temperature. We report the following results from the\nfirst-order computation:\n  1. When the width $N$ is much larger than the depth $L$ and training set size\n$P$, neural network Bayesian inference coincides with Bayesian inference using\na kernel. The value of $\\psi$ determines the curvature of a sphere, hyperbola,\nor plane into which the training data is implicitly embedded under the feature\nmap.\n  2. When $LP/N$ is a small constant, neural network Bayesian inference departs\nfrom the kernel regime. At zero temperature, neural network Bayesian inference\nis equivalent to Bayesian inference using a data-dependent kernel, and $LP/N$\nserves as an effective depth that controls the extent of feature learning.\n  3. In the restricted case of deep linear networks ($\\psi=0$) and noisy data,\nwe show a simple data model for which evidence and generalization error are\noptimal at zero temperature. As $LP/N$ increases, both evidence and\ngeneralization further improve, demonstrating the benefit of depth in benign\noverfitting.",
      "tldr_zh": "本研究在物理学严格性下，展示了使用全连接神经网络和弱非线性函数（$\\phi(t) = t + \\psi t^3/L$）的贝叶斯推理（Bayesian inference），在训练数据点数$P$、输入维度$N_0$、网络宽度$N$和深度$L$同时很大的条件下，可以通过扰动方法求解，主要要求$P < N_0$。结果表明，当$N$远大于$L$和$P$时，神经网络贝叶斯推理等同于使用核（kernel）的贝叶斯推理，其中$\\psi$决定了数据隐式嵌入的曲面类型（如球面、双曲面或平面）。此外，当$LP/N$为小常量时，推理脱离核模式，并在零温度下等同于数据依赖核，$LP/N$作为有效深度促进特征学习（feature learning）；在深线性网络（$\\psi=0$）和有噪声数据情况下，证据和泛化误差随$LP/N$增加而优化，突显了深度的益处。该工作提供了计算模型证据和后验的技术，支持神经网络在贝叶斯框架中的应用。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.PR",
        "physics.data-an"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16630v1",
      "published_date": "2024-05-26 17:08:04 UTC",
      "updated_date": "2024-05-26 17:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:08:19.304675"
    },
    {
      "arxiv_id": "2405.16610v1",
      "title": "The devil is in discretization discrepancy. Robustifying Differentiable NAS with Single-Stage Searching Protocol",
      "title_zh": "翻译失败",
      "authors": [
        "Konstanty Subbotko",
        "Wojciech Jablonski",
        "Piotr Bilinski"
      ],
      "abstract": "Neural Architecture Search (NAS) has been widely adopted to design neural\nnetworks for various computer vision tasks. One of its most promising\nsubdomains is differentiable NAS (DNAS), where the optimal architecture is\nfound in a differentiable manner. However, gradient-based methods suffer from\nthe discretization error, which can severely damage the process of obtaining\nthe final architecture. In our work, we first study the risk of discretization\nerror and show how it affects an unregularized supernet. Then, we present that\npenalizing high entropy, a common technique of architecture regularization, can\nhinder the supernet's performance. Therefore, to robustify the DNAS framework,\nwe introduce a novel single-stage searching protocol, which is not reliant on\ndecoding a continuous architecture. Our results demonstrate that this approach\noutperforms other DNAS methods by achieving 75.3% in the searching stage on the\nCityscapes validation dataset and attains performance 1.1% higher than the\noptimal network of DCNAS on the non-dense search space comprising short\nconnections. The entire training process takes only 5.5 GPU days due to the\nweight reuse, and yields a computationally efficient architecture.\nAdditionally, we propose a new dataset split procedure, which substantially\nimproves results and prevents architecture degeneration in DARTS.",
      "tldr_zh": "该论文探讨了可微神经架构搜索(DNAS)中的离散化误差问题，该误差会严重影响最终架构的获取，并发现高熵惩罚技术可能阻碍超网(supernet)的性能。作者提出了一种新颖的单阶段搜索协议(single-stage searching protocol)，通过避免解码连续架构来增强DNAS的鲁棒性。实验结果显示，该方法在Cityscapes验证数据集上搜索阶段达到75.3%的性能，比DCNAS高1.1%，整个训练过程仅需5.5 GPU天，并通过新的数据集分割过程改善结果并防止架构退化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "Published in CVPR-NAS 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.16610v1",
      "published_date": "2024-05-26 15:44:53 UTC",
      "updated_date": "2024-05-26 15:44:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:08:30.768913"
    },
    {
      "arxiv_id": "2405.16604v1",
      "title": "Intelligence as Computation",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Brock"
      ],
      "abstract": "This paper proposes a specific conceptualization of intelligence as\ncomputation. This conceptualization is intended to provide a unified view for\nall disciplines of intelligence research. Already, it unifies several\nconceptualizations currently under investigation, including physical, neural,\nembodied, morphological, and mechanical intelligences. To achieve this, the\nproposed conceptualization explains the differences among existing views by\ndifferent computational paradigms, such as digital, analog, mechanical, or\nmorphological computation. Viewing intelligence as a composition of\ncomputations from different paradigms, the challenges posed by previous\nconceptualizations are resolved. Intelligence is hypothesized as a\nmulti-paradigmatic computation relying on specific computational principles.\nThese principles distinguish intelligence from other, non-intelligent\ncomputations. The proposed conceptualization implies a multi-disciplinary\nresearch agenda that is intended to lead to unified science of intelligence.",
      "tldr_zh": "本论文提出一种将智能视为 computation 的概念化框架，旨在统一物理、神经、具身、形态和机械等智能研究领域。通过不同的 computational paradigms（如数字、模拟、机械或形态 computation），论文解释了现有观点的差异，并将智能视为多-paradigmatic computation，依赖特定计算原则来区分其与非智能计算。最终，该框架解决了先前概念化的挑战，并建议一个多学科研究议程，以推动统一的智能科学发展。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "68T01",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages, 0 figures, submitted for review to a journal",
      "pdf_url": "http://arxiv.org/pdf/2405.16604v1",
      "published_date": "2024-05-26 15:30:34 UTC",
      "updated_date": "2024-05-26 15:30:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:08:42.131143"
    },
    {
      "arxiv_id": "2406.18842v3",
      "title": "The global landscape of academic guidelines for generative AI and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junfeng Jiao",
        "Saleh Afroogh",
        "Kevin Chen",
        "David Atkinson",
        "Amit Dhurandhar"
      ],
      "abstract": "The integration of Generative Artificial Intelligence (GAI) and Large\nLanguage Models (LLMs) in academia has spurred a global discourse on their\npotential pedagogical benefits and ethical considerations. Positive reactions\nhighlight some potential, such as collaborative creativity, increased access to\neducation, and empowerment of trainers and trainees. However, negative\nreactions raise concerns about ethical complexities, balancing innovation and\nacademic integrity, unequal access, and misinformation risks. Through a\nsystematic survey and text-mining-based analysis of global and national\ndirectives, insights from independent research, and eighty university-level\nguidelines, this study provides a nuanced understanding of the opportunities\nand challenges posed by GAI and LLMs in education. It emphasizes the importance\nof balanced approaches that harness the benefits of these technologies while\naddressing ethical considerations and ensuring equitable access and educational\noutcomes. The paper concludes with recommendations for fostering responsible\ninnovation and ethical practices to guide the integration of GAI and LLMs in\nacademia.",
      "tldr_zh": "这篇论文探讨了生成式人工智能(GAI)和大型语言模型(LLMs)在学术界的全球指导方针，分析其教育益处（如协作创意、增加教育访问和赋权）与伦理挑战（如学术诚信风险、不平等访问和错误信息）。通过系统调查、文本挖掘分析全球指令、独立研究以及80个大学指南，该研究提供了对GAI和LLMs机会与挑战的细致理解。论文强调平衡创新与伦理考量，并提出推荐措施，以促进负责任的整合，确保公平教育成果。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18842v3",
      "published_date": "2024-05-26 15:28:24 UTC",
      "updated_date": "2025-03-18 16:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:08:55.005924"
    },
    {
      "arxiv_id": "2405.16595v1",
      "title": "An Evolutionary Framework for Connect-4 as Test-Bed for Comparison of Advanced Minimax, Q-Learning and MCTS",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Taylor",
        "Leonardo Stella"
      ],
      "abstract": "A major challenge in decision making domains with large state spaces is to\neffectively select actions which maximize utility. In recent years, approaches\nsuch as reinforcement learning (RL) and search algorithms have been successful\nto tackle this issue, despite their differences. RL defines a learning\nframework that an agent explores and interacts with. Search algorithms provide\na formalism to search for a solution. However, it is often difficult to\nevaluate the performances of such approaches in a practical way. Motivated by\nthis problem, we focus on one game domain, i.e., Connect-4, and develop a novel\nevolutionary framework to evaluate three classes of algorithms: RL, Minimax and\nMonte Carlo tree search (MCTS). The contribution of this paper is threefold: i)\nwe implement advanced versions of these algorithms and provide a systematic\ncomparison with their standard counterpart, ii) we develop a novel evaluation\nframework, which we call the Evolutionary Tournament, and iii) we conduct an\nextensive evaluation of the relative performance of each algorithm to compare\nour findings. We evaluate different metrics and show that MCTS achieves the\nbest results in terms of win percentage, whereas Minimax and Q-Learning are\nranked in second and third place, respectively, although the latter is shown to\nbe the fastest to make a decision.",
      "tldr_zh": "这篇论文提出了一种进化框架（Evolutionary Tournament），以 Connect-4 游戏作为测试平台，用于比较先进的 Minimax、Q-Learning 和 Monte Carlo Tree Search (MCTS) 算法，旨在评估这些方法在大型状态空间决策中的性能。论文的主要贡献包括实现算法的先进版本、开发新型评估框架，以及进行系统性比较实验。结果显示，MCTS 在获胜百分比方面表现最佳，Minimax 排名第二，而 Q-Learning 虽位居第三但决策速度最快，为强化学习 (RL) 和搜索算法的优化提供参考。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 4 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2405.16595v1",
      "published_date": "2024-05-26 15:11:45 UTC",
      "updated_date": "2024-05-26 15:11:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:09:07.185014"
    },
    {
      "arxiv_id": "2405.16588v1",
      "title": "Attaining Human`s Desirable Outcomes in Human-AI Interaction via Structural Causal Games",
      "title_zh": "翻译失败",
      "authors": [
        "Anjie Liu",
        "Jianhong Wang",
        "Haoxuan Li",
        "Xu Chen",
        "Jun Wang",
        "Samuel Kaski",
        "Mengyue Yang"
      ],
      "abstract": "In human-AI interaction, a prominent goal is to attain human`s desirable\noutcome with the assistance of AI agents, which can be ideally delineated as a\nproblem of seeking the optimal Nash Equilibrium that matches the human`s\ndesirable outcome. However, reaching the outcome is usually challenging due to\nthe existence of multiple Nash Equilibria that are related to the assisting\ntask but do not correspond to the human`s desirable outcome. To tackle this\nissue, we employ a theoretical framework called structural causal game (SCG) to\nformalize the human-AI interactive process. Furthermore, we introduce a\nstrategy referred to as pre-policy intervention on the SCG to steer AI agents\ntowards attaining the human`s desirable outcome. In more detail, a pre-policy\nis learned as a generalized intervention to guide the agents` policy selection,\nunder a transparent and interpretable procedure determined by the SCG. To make\nthe framework practical, we propose a reinforcement learning-like algorithm to\nsearch out this pre-policy. The proposed algorithm is tested in both gridworld\nenvironments and realistic dialogue scenarios with large language models,\ndemonstrating its adaptability in a broader class of problems and potential\neffectiveness in real-world situations.",
      "tldr_zh": "该研究针对人-AI互动中实现人类期望结果的挑战，提出使用Structural Causal Games (SCG)框架来形式化互动过程，从而解决多个Nash Equilibrium导致的偏差问题。主要方法是引入pre-policy intervention策略，通过学习一个通用干预来引导AI代理的策略选择，确保透明性和可解释性。为实现这一框架，研究者开发了一个类似强化学习的算法，用于搜索最优pre-policy，并在gridworld环境和真实对话场景（如大语言模型）中进行测试，展示了其广泛适应性和实际有效性。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "38 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16588v1",
      "published_date": "2024-05-26 14:42:49 UTC",
      "updated_date": "2024-05-26 14:42:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:09:18.428762"
    },
    {
      "arxiv_id": "2405.16587v2",
      "title": "Cost-Effective Online Multi-LLM Selection with Versatile Reward Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangxiang Dai",
        "Jin Li",
        "Xutong Liu",
        "Anqi Yu",
        "John C. S. Lui"
      ],
      "abstract": "With the rapid advancement of large language models (LLMs), the diversity of\nmulti-LLM tasks and the variability in their pricing structures have become\nincreasingly important, as costs can vary greatly between different LLMs. To\ntackle these challenges, we introduce the \\textit{C2MAB-V}, a\n\\underline{C}ost-effective \\underline{C}ombinatorial \\underline{M}ulti-armed\n\\underline{B}andit with \\underline{V}ersatile reward models for optimal LLM\nselection and usage. This online model differs from traditional static\napproaches or those reliant on a single LLM without cost consideration. With\nmultiple LLMs deployed on a scheduling cloud and a local server dedicated to\nhandling user queries, \\textit{C2MAB-V} facilitates the selection of multiple\nLLMs over a combinatorial search space, specifically tailored for various\ncollaborative task types with different reward models. Based on our designed\nonline feedback mechanism and confidence bound technique, \\textit{C2MAB-V} can\neffectively address the multi-LLM selection challenge by managing the\nexploration-exploitation trade-off across different models, while also\nbalancing cost and reward for diverse tasks. The NP-hard integer linear\nprogramming problem for selecting multiple LLMs with trade-off dilemmas is\naddressed by: i) decomposing the integer problem into a relaxed form by the\nlocal server, ii) utilizing a discretization rounding scheme that provides\noptimal LLM combinations by the scheduling cloud, and iii) continual online\nupdates based on feedback. Theoretically, we prove that \\textit{C2MAB-V} offers\nstrict guarantees over versatile reward models, matching state-of-the-art\nresults for regret and violations in some degenerate cases. Empirically, we\nshow that \\textit{C2MAB-V} effectively balances performance and cost-efficiency\nwith nine LLMs for three application scenarios.",
      "tldr_zh": "该论文提出 C2MAB-V，一种成本有效的在线 Combinatorial Multi-Armed Bandit 框架，用于优化多 LLM 选择，解决 LLMs 多样性和定价差异带来的成本挑战。框架通过在线反馈机制和 confidence bound 技术管理 exploration-exploitation 平衡，并针对各种协作任务的 versatile reward models 进行多 LLM 组合选择，同时处理 NP-hard 整数线性规划问题。理论上，C2MAB-V 提供严格的 regret 和 violations 保证；实验结果显示，在三个应用场景中使用九个 LLMs 时，它有效平衡了性能和成本效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages, 14 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2405.16587v2",
      "published_date": "2024-05-26 14:38:24 UTC",
      "updated_date": "2024-10-02 13:22:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:09:32.958994"
    },
    {
      "arxiv_id": "2405.16585v1",
      "title": "Fair Federated Learning under Domain Skew with Local Consistency and Domain Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhang Chen",
        "Wenke Huang",
        "Mang Ye"
      ],
      "abstract": "Federated learning (FL) has emerged as a new paradigm for privacy-preserving\ncollaborative training. Under domain skew, the current FL approaches are biased\nand face two fairness problems. 1) Parameter Update Conflict: data disparity\namong clients leads to varying parameter importance and inconsistent update\ndirections. These two disparities cause important parameters to potentially be\noverwhelmed by unimportant ones of dominant updates. It consequently results in\nsignificant performance decreases for lower-performing clients. 2) Model\nAggregation Bias: existing FL approaches introduce unfair weight allocation and\nneglect domain diversity. It leads to biased model convergence objective and\ndistinct performance among domains. We discover a pronounced directional update\nconsistency in Federated Learning and propose a novel framework to tackle above\nissues. First, leveraging the discovered characteristic, we selectively discard\nunimportant parameter updates to prevent updates from clients with lower\nperformance overwhelmed by unimportant parameters, resulting in fairer\ngeneralization performance. Second, we propose a fair aggregation objective to\nprevent global model bias towards some domains, ensuring that the global model\ncontinuously aligns with an unbiased model. The proposed method is generic and\ncan be combined with other existing FL methods to enhance fairness.\nComprehensive experiments on Digits and Office-Caltech demonstrate the high\nfairness and performance of our method.",
      "tldr_zh": "本论文针对联邦学习（Federated Learning, FL）在领域偏移（Domain Skew）下的公平性问题，提出了一个新框架，解决Parameter Update Conflict和Model Aggregation Bias两大挑战。具体来说，该框架利用FL中的方向更新一致性（Directional Update Consistency），选择性丢弃不重要参数更新，以防止低性能客户端的更新被主导，从而提升公平的泛化性能；同时，引入公平聚合目标，确保全局模型不偏向特定领域，并与无偏模型对齐。该方法通用且可与其他FL方法结合，实验在Digits和Office-Caltech数据集上证明了其高公平性和性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16585v1",
      "published_date": "2024-05-26 14:29:10 UTC",
      "updated_date": "2024-05-26 14:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:09:43.445974"
    },
    {
      "arxiv_id": "2405.16570v2",
      "title": "ID-to-3D: Expressive ID-guided 3D Heads via Score Distillation Sampling",
      "title_zh": "ID-to-3D：通过分数蒸馏采样的富有表现力的ID引导3D头部",
      "authors": [
        "Francesca Babiloni",
        "Alexandros Lattas",
        "Jiankang Deng",
        "Stefanos Zafeiriou"
      ],
      "abstract": "We propose ID-to-3D, a method to generate identity- and text-guided 3D human\nheads with disentangled expressions, starting from even a single casually\ncaptured in-the-wild image of a subject. The foundation of our approach is\nanchored in compositionality, alongside the use of task-specific 2D diffusion\nmodels as priors for optimization. First, we extend a foundational model with a\nlightweight expression-aware and ID-aware architecture, and create 2D priors\nfor geometry and texture generation, via fine-tuning only 0.2% of its available\ntraining parameters. Then, we jointly leverage a neural parametric\nrepresentation for the expressions of each subject and a multi-stage generation\nof highly detailed geometry and albedo texture. This combination of strong face\nidentity embeddings and our neural representation enables accurate\nreconstruction of not only facial features but also accessories and hair and\ncan be meshed to provide render-ready assets for gaming and telepresence. Our\nresults achieve an unprecedented level of identity-consistent and high-quality\ntexture and geometry generation, generalizing to a ``world'' of unseen 3D\nidentities, without relying on large 3D captured datasets of human assets.",
      "tldr_zh": "该研究提出了一种名为 ID-to-3D 的方法，通过 Score Distillation Sampling 技术，从单张随意拍摄的图像生成身份和文本引导的 3D 人类头部模型，并实现表情的分离。方法的核心是扩展 2D diffusion models 为任务特定的先验，仅微调 0.2% 的参数来创建几何和纹理生成模型，并结合神经参数表示和多阶段优化过程，精确重建面部特征、配饰及头发。结果显示，ID-to-3D 实现了前所未有的身份一致性和高质量纹理、几何生成，能够泛化到未见过的 3D 身份，而无需依赖大型 3D 捕获数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Explore our 3D results at: https://idto3d.github.io ; fixed broken\n  url to project page",
      "pdf_url": "http://arxiv.org/pdf/2405.16570v2",
      "published_date": "2024-05-26 13:36:45 UTC",
      "updated_date": "2024-05-28 09:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:09:56.844053"
    },
    {
      "arxiv_id": "2405.16567v2",
      "title": "Automatic Jailbreaking of the Text-to-Image Generative AI Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Minseon Kim",
        "Hyomin Lee",
        "Boqing Gong",
        "Huishuai Zhang",
        "Sung Ju Hwang"
      ],
      "abstract": "Recent AI systems have shown extremely powerful performance, even surpassing\nhuman performance, on various tasks such as information retrieval, language\ngeneration, and image generation based on large language models (LLMs). At the\nsame time, there are diverse safety risks that can cause the generation of\nmalicious contents by circumventing the alignment in LLMs, which are often\nreferred to as jailbreaking. However, most of the previous works only focused\non the text-based jailbreaking in LLMs, and the jailbreaking of the\ntext-to-image (T2I) generation system has been relatively overlooked. In this\npaper, we first evaluate the safety of the commercial T2I generation systems,\nsuch as ChatGPT, Copilot, and Gemini, on copyright infringement with naive\nprompts. From this empirical study, we find that Copilot and Gemini block only\n12% and 17% of the attacks with naive prompts, respectively, while ChatGPT\nblocks 84% of them. Then, we further propose a stronger automated jailbreaking\npipeline for T2I generation systems, which produces prompts that bypass their\nsafety guards. Our automated jailbreaking framework leverages an LLM optimizer\nto generate prompts to maximize degree of violation from the generated images\nwithout any weight updates or gradient computation. Surprisingly, our simple\nyet effective approach successfully jailbreaks the ChatGPT with 11.0% block\nrate, making it generate copyrighted contents in 76% of the time. Finally, we\nexplore various defense strategies, such as post-generation filtering and\nmachine unlearning techniques, but found that they were inadequate, which\nsuggests the necessity of stronger defense mechanisms.",
      "tldr_zh": "该论文评估了商业文本到图像(T2I)生成系统的安全性，发现Copilot和Gemini仅阻挡12%和17%的版权侵犯提示，而ChatGPT阻挡84%。作者提出了一种自动jailbreaking框架，使用LLM优化器生成最大化违反程度的提示，而无需权重更新或梯度计算，从而成功绕过ChatGPT的安全守卫，使其在76%的时间生成受版权保护内容，阻挡率降至11.0%。实验结果显示，现有防御策略如后生成过滤和机器unlearning技术效果不佳，强调了开发更强防御机制的必要性。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2405.16567v2",
      "published_date": "2024-05-26 13:32:24 UTC",
      "updated_date": "2024-05-28 06:37:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:10:08.962586"
    },
    {
      "arxiv_id": "2405.16557v1",
      "title": "Scalable Numerical Embeddings for Multivariate Time Series: Enhancing Healthcare Data Representation Learning",
      "title_zh": "可扩展数值嵌入用于多变量时间",
      "authors": [
        "Chun-Kai Huang",
        "Yi-Hsien Hsieh",
        "Ta-Jung Chien",
        "Li-Cheng Chien",
        "Shao-Hua Sun",
        "Tung-Hung Su",
        "Jia-Horng Kao",
        "Che Lin"
      ],
      "abstract": "Multivariate time series (MTS) data, when sampled irregularly and\nasynchronously, often present extensive missing values. Conventional\nmethodologies for MTS analysis tend to rely on temporal embeddings based on\ntimestamps that necessitate subsequent imputations, yet these imputed values\nfrequently deviate substantially from their actual counterparts, thereby\ncompromising prediction accuracy. Furthermore, these methods typically fail to\nprovide robust initial embeddings for values infrequently observed or even\nabsent within the training set, posing significant challenges to model\ngeneralizability. In response to these challenges, we propose SCAlable\nNumerical Embedding (SCANE), a novel framework that treats each feature value\nas an independent token, effectively bypassing the need for imputation. SCANE\nregularizes the traits of distinct feature embeddings and enhances\nrepresentational learning through a scalable embedding mechanism. Coupling\nSCANE with the Transformer Encoder architecture, we develop the Scalable\nnUMerical eMbeddIng Transformer (SUMMIT), which is engineered to deliver\nprecise predictive outputs for MTS characterized by prevalent missing entries.\nOur experimental validation, conducted across three disparate electronic health\nrecord (EHR) datasets marked by elevated missing value frequencies, confirms\nthe superior performance of SUMMIT over contemporary state-of-the-art\napproaches addressing similar challenges. These results substantiate the\nefficacy of SCANE and SUMMIT, underscoring their potential applicability across\na broad spectrum of MTS data analytical tasks.",
      "tldr_zh": "这篇论文针对多变量时间序列 (MTS) 数据中不规则采样和大量缺失值的问题，提出了一种创新框架 SCAlable Numerical Embedding (SCANE)，将每个特征值视为独立标记，避免传统方法的插值需求，并通过正则化和可扩展嵌入机制提升表示学习。作者将 SCANE 与 Transformer Encoder 结合，开发了 Scalable nUMerical eMbeddIng Transformer (SUMMIT)，用于精确预测高缺失率 MTS 数据。实验结果显示，在三个电子健康记录 (EHR) 数据集上，SUMMIT 优于现有最先进方法，验证了其在医疗数据分析中的适用性和泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16557v1",
      "published_date": "2024-05-26 13:06:45 UTC",
      "updated_date": "2024-05-26 13:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:10:21.910736"
    },
    {
      "arxiv_id": "2405.16552v1",
      "title": "SED: Self-Evaluation Decoding Enhances Large Language Models for Better Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqin Luo",
        "Haixia Han",
        "Haokun Zhao",
        "Guochao Jiang",
        "Chengyu Du",
        "Tingyun Li",
        "Jiaqing Liang",
        "Deqing Yang",
        "Yanghua Xiao"
      ],
      "abstract": "Existing Large Language Models (LLMs) generate text through unidirectional\nautoregressive decoding methods to respond to various user queries. These\nmethods tend to consider token selection in a simple sequential manner, making\nit easy to fall into suboptimal options when encountering uncertain tokens,\nreferred to as chaotic points in our work. Many chaotic points exist in texts\ngenerated by LLMs, and they often significantly affect the quality of\nsubsequently generated tokens, which can interfere with LLMs' generation. This\npaper proposes Self-Evaluation Decoding, SED, a decoding method for enhancing\nmodel generation. Analogous to the human decision-making process, SED\nintegrates speculation and evaluation steps into the decoding process, allowing\nLLMs to make more careful decisions and thus optimize token selection at\nchaotic points. Experimental results across various tasks using different LLMs\ndemonstrate SED's effectiveness.",
      "tldr_zh": "现有的大型语言模型(LLMs)在使用单向自回归解码方法时，容易在不确定性token（chaotic points）上选择次优选项，从而影响后续文本生成质量。本文提出Self-Evaluation Decoding (SED)，一种模仿人类决策过程的解码方法，将推测和评估步骤整合进来，帮助LLMs在chaotic points处做出更谨慎的选择。实验在多种任务和不同LLMs上验证了SED的有效性，提升了模型的生成性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The relevant code will be released in subsequent versions",
      "pdf_url": "http://arxiv.org/pdf/2405.16552v1",
      "published_date": "2024-05-26 12:43:18 UTC",
      "updated_date": "2024-05-26 12:43:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:10:30.256981"
    },
    {
      "arxiv_id": "2405.16550v1",
      "title": "ReCODE: Modeling Repeat Consumption with Neural ODE",
      "title_zh": "翻译失败",
      "authors": [
        "Sunhao Dai",
        "Changle Qu",
        "Sirui Chen",
        "Xiao Zhang",
        "Jun Xu"
      ],
      "abstract": "In real-world recommender systems, such as in the music domain, repeat\nconsumption is a common phenomenon where users frequently listen to a small set\nof preferred songs or artists repeatedly. The key point of modeling repeat\nconsumption is capturing the temporal patterns between a user's repeated\nconsumption of the items. Existing studies often rely on heuristic assumptions,\nsuch as assuming an exponential distribution for the temporal gaps. However,\ndue to the high complexity of real-world recommender systems, these pre-defined\ndistributions may fail to capture the intricate dynamic user consumption\npatterns, leading to sub-optimal performance. Drawing inspiration from the\nflexibility of neural ordinary differential equations (ODE) in capturing the\ndynamics of complex systems, we propose ReCODE, a novel model-agnostic\nframework that utilizes neural ODE to model repeat consumption. ReCODE\ncomprises two essential components: a user's static preference prediction\nmodule and the modeling of user dynamic repeat intention. By considering both\nimmediate choices and historical consumption patterns, ReCODE offers\ncomprehensive modeling of user preferences in the target context. Moreover,\nReCODE seamlessly integrates with various existing recommendation models,\nincluding collaborative-based and sequential-based models, making it easily\napplicable in different scenarios. Experimental results on two real-world\ndatasets consistently demonstrate that ReCODE significantly improves the\nperformance of base models and outperforms other baseline methods.",
      "tldr_zh": "该研究提出ReCODE框架，使用neural ODE（神经普通微分方程）来建模推荐系统中的重复消费现象，解决了传统启发式假设（如指数分布）无法捕捉复杂用户动态模式的问题。ReCODE包括用户的静态偏好预测模块和动态重复意图建模组件，能够同时考虑即时选择和历史消费模式，并与各种推荐模型（如基于协作或序列的模型）无缝整合。实验在两个真实数据集上显示，ReCODE显著提升了基线模型的性能，并优于其他基准方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by SIGIR 2024 (Short Paper)",
      "pdf_url": "http://arxiv.org/pdf/2405.16550v1",
      "published_date": "2024-05-26 12:40:23 UTC",
      "updated_date": "2024-05-26 12:40:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:10:43.395909"
    },
    {
      "arxiv_id": "2405.16542v1",
      "title": "Mamba4KT:An Efficient and Effective Mamba-based Knowledge Tracing Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Cao",
        "Wei Zhang"
      ],
      "abstract": "Knowledge tracing (KT) enhances student learning by leveraging past\nperformance to predict future performance. Current research utilizes models\nbased on attention mechanisms and recurrent neural network structures to\ncapture long-term dependencies and correlations between exercises, aiming to\nimprove model accuracy. Due to the growing amount of data in smart education\nscenarios, this poses a challenge in terms of time and space consumption for\nknowledge tracing models. However, existing research often overlooks the\nefficiency of model training and inference and the constraints of training\nresources. Recognizing the significance of prioritizing model efficiency and\nresource usage in knowledge tracing, we introduce Mamba4KT. This novel model is\nthe first to explore enhanced efficiency and resource utilization in knowledge\ntracing. We also examine the interpretability of the Mamba structure both\nsequence-level and exercise-level to enhance model interpretability.\nExperimental findings across three public datasets demonstrate that Mamba4KT\nachieves comparable prediction accuracy to state-of-the-art models while\nsignificantly improving training and inference efficiency and resource\nutilization. As educational data continues to grow, our work suggests a\npromising research direction for knowledge tracing that improves model\nprediction accuracy, model efficiency, resource utilization, and\ninterpretability simultaneously.",
      "tldr_zh": "该研究针对知识追踪（KT）模型在处理学生表现预测时面临的效率和资源利用挑战，引入了Mamba4KT，这是一个基于Mamba结构的创新模型。Mamba4KT首次强调模型的训练和推理效率，同时在序列级和练习级探索了Mamba的解释性，以提升模型的可解释性。在三个公共数据集上的实验显示，Mamba4KT的预测准确性与最先进模型相当，但显著提高了训练和推理效率以及资源利用，为大规模教育数据场景下的KT研究提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16542v1",
      "published_date": "2024-05-26 12:26:03 UTC",
      "updated_date": "2024-05-26 12:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:10:55.310794"
    },
    {
      "arxiv_id": "2405.16538v1",
      "title": "Gamified AI Approch for Early Detection of Dementia",
      "title_zh": "翻译失败",
      "authors": [
        "Paramita Kundu Maji",
        "Soubhik Acharya",
        "Priti Paul",
        "Sanjay Chakraborty",
        "Saikat Basu"
      ],
      "abstract": "This paper aims to develop a new deep learning-inspired gaming approach for\nearly detection of dementia. This research integrates a robust convolutional\nneural network (CNN)-based model for early dementia detection using health\nmetrics data as well as facial image data through a cognitive assessment-based\ngaming application. We have collected 1000 data samples of health metrics\ndataset from Apollo Diagnostic Center Kolkata that is labeled as either\ndemented or non-demented for the training of MOD-1D-CNN for the game level 1\nand another dataset of facial images containing 1800 facial data that are\nlabeled as either demented or non-demented is collected by our research team\nfor the training of MOD-2D-CNN model in-game level 2. In our work, the loss for\nthe proposed MOD-1D-CNN model is 0.2692 and the highest accuracy is 70.50% for\nidentifying the dementia traits using real-life health metrics data. Similarly,\nthe proposed MOD-2D-CNN model loss is 0.1755 and the highest accuracy is\nobtained here 95.72% for recognizing the dementia status using real-life\nface-based image data. Therefore, a rule-based weightage method is applied to\ncombine both the proposed methods to achieve the final decision. The MOD-1D-CNN\nand MOD-2D-CNN models are more lightweight and computationally efficient\nalternatives because they have a significantly lower number of parameters when\ncompared to the other state-of-the-art models. We have compared their\naccuracies and parameters with the other state-of-the-art deep learning models.",
      "tldr_zh": "本研究提出了一种基于深度学习的游戏化方法，用于痴呆的早期检测，结合了健康指标数据和面部图像数据通过认知评估游戏应用。研究开发了 MOD-1D-CNN 模型（用于处理一维健康指标数据，准确率达70.50%，损失率为0.2692）和 MOD-2D-CNN 模型（用于处理二维面部图像数据，准确率达95.72%，损失率为0.1755）。通过规则-based 权重方法整合两种模型，实现最终决策，并证明这些模型相比其他 SOTA 模型更轻量级，具有更少的参数和更高的计算效率。实验结果基于收集的1000个健康指标样本和1800个面部图像样本，展示了该方法在痴呆检测中的潜在应用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "50 Pages, 29 Figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16538v1",
      "published_date": "2024-05-26 12:01:30 UTC",
      "updated_date": "2024-05-26 12:01:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:11:08.931787"
    },
    {
      "arxiv_id": "2407.11977v1",
      "title": "Building Better AI Agents: A Provocation on the Utilisation of Persona in LLM-based Conversational Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Guangzhi Sun",
        "Xiao Zhan",
        "Jose Such"
      ],
      "abstract": "The incorporation of Large Language Models (LLMs) such as the GPT series into\ndiverse sectors including healthcare, education, and finance marks a\nsignificant evolution in the field of artificial intelligence (AI). The\nincreasing demand for personalised applications motivated the design of\nconversational agents (CAs) to possess distinct personas. This paper commences\nby examining the rationale and implications of imbuing CAs with unique\npersonas, smoothly transitioning into a broader discussion of the\npersonalisation and anthropomorphism of CAs based on LLMs in the LLM era. We\ndelve into the specific applications where the implementation of a persona is\nnot just beneficial but critical for LLM-based CAs. The paper underscores the\nnecessity of a nuanced approach to persona integration, highlighting the\npotential challenges and ethical dilemmas that may arise. Attention is directed\ntowards the importance of maintaining persona consistency, establishing robust\nevaluation mechanisms, and ensuring that the persona attributes are effectively\ncomplemented by domain-specific knowledge.",
      "tldr_zh": "这篇论文探讨了在LLM-based对话代理（CAs）中利用persona（人格设定）来提升AI代理性能的必要性，强调persona能实现个性化（personalisation）和拟人化（anthropomorphism），从而更好地应用于医疗、教育和金融等领域。论文分析了赋予CAs独特persona的理由及其影响，包括在特定场景中的关键作用，同时指出了潜在挑战，如道德困境和一致性问题。最终，它呼吁采用细致的方法，包括建立稳健的评估机制和结合领域特定知识，以构建更可靠的AI代理。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by The international ACM Conversational User Interfaces\n  (CUI) conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.11977v1",
      "published_date": "2024-05-26 11:36:48 UTC",
      "updated_date": "2024-05-26 11:36:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:11:20.107638"
    },
    {
      "arxiv_id": "2405.16522v4",
      "title": "Multi-State TD Target for Model-Free Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Wuhao Wang",
        "Zhiyong Chen",
        "Lepeng Zhang"
      ],
      "abstract": "Temporal difference (TD) learning is a fundamental technique in reinforcement\nlearning that updates value estimates for states or state-action pairs using a\nTD target. This target represents an improved estimate of the true value by\nincorporating both immediate rewards and the estimated value of subsequent\nstates. Traditionally, TD learning relies on the value of a single subsequent\nstate. We propose an enhanced multi-state TD (MSTD) target that utilizes the\nestimated values of multiple subsequent states. Building on this new MSTD\nconcept, we develop complete actor-critic algorithms that include management of\nreplay buffers in two modes, and integrate with deep deterministic policy\noptimization (DDPG) and soft actor-critic (SAC). Experimental results\ndemonstrate that algorithms employing the MSTD target significantly improve\nlearning performance compared to traditional methods.The code is provided on\nGitHub.",
      "tldr_zh": "该论文提出了一种增强的 Multi-State TD (MSTD) target，用于模型无关强化学习 (Model-Free Reinforcement Learning)，它通过利用多个后续状态的估计值来改善传统 Temporal Difference (TD) learning 的价值更新，从而解决单一状态依赖的局限性。基于 MSTD，研究者开发了完整的 actor-critic 算法，包括两种 replay buffer 管理模式，并将其与 Deep Deterministic Policy Gradient (DDPG) 和 Soft Actor-Critic (SAC) 相结合。实验结果显示，使用 MSTD target 的算法在学习性能上显著优于传统方法，且相关代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T05(Primary)"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16522v4",
      "published_date": "2024-05-26 11:17:49 UTC",
      "updated_date": "2024-08-02 00:21:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:11:31.477619"
    },
    {
      "arxiv_id": "2405.16511v1",
      "title": "SE3Set: Harnessing equivariant hypergraph neural networks for molecular representation learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongfei Wu",
        "Lijun Wu",
        "Guoqing Liu",
        "Zhirong Liu",
        "Bin Shao",
        "Zun Wang"
      ],
      "abstract": "In this paper, we develop SE3Set, an SE(3) equivariant hypergraph neural\nnetwork architecture tailored for advanced molecular representation learning.\nHypergraphs are not merely an extension of traditional graphs; they are pivotal\nfor modeling high-order relationships, a capability that conventional\nequivariant graph-based methods lack due to their inherent limitations in\nrepresenting intricate many-body interactions. To achieve this, we first\nconstruct hypergraphs via proposing a new fragmentation method that considers\nboth chemical and three-dimensional spatial information of molecular system. We\nthen design SE3Set, which incorporates equivariance into the hypergragh neural\nnetwork. This ensures that the learned molecular representations are invariant\nto spatial transformations, thereby providing robustness essential for accurate\nprediction of molecular properties. SE3Set has shown performance on par with\nstate-of-the-art (SOTA) models for small molecule datasets like QM9 and MD17.\nIt excels on the MD22 dataset, achieving a notable improvement of approximately\n20% in accuracy across all molecules, which highlights the prevalence of\ncomplex many-body interactions in larger molecules. This exceptional\nperformance of SE3Set across diverse molecular structures underscores its\ntransformative potential in computational chemistry, offering a route to more\naccurate and physically nuanced modeling.",
      "tldr_zh": "本论文提出 SE3Set，一种 SE(3) 等变超图神经网络架构，用于分子表示学习，以更好地捕捉高阶关系和复杂的多体交互。研究首先引入一种新的分子碎片化方法，结合化学和三维空间信息构建超图，然后将等变性融入超图神经网络，确保分子表示对空间变换保持鲁棒性，从而提升分子属性预测的准确性。在实验中，SE3Set 在 QM9 和 MD17 数据集上与最先进模型性能相当，并在 MD22 数据集上实现了约 20% 的准确率提升，突显其在处理较大分子时的潜力，为计算化学提供更精确的建模工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16511v1",
      "published_date": "2024-05-26 10:43:16 UTC",
      "updated_date": "2024-05-26 10:43:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:11:44.526798"
    },
    {
      "arxiv_id": "2405.16510v4",
      "title": "Planning with Multi-Constraints via Collaborative Language Agents",
      "title_zh": "通过协作语言代理的多约束规划",
      "authors": [
        "Cong Zhang",
        "Derrick Goh Xin Deik",
        "Dexun Li",
        "Hao Zhang",
        "Yong Liu"
      ],
      "abstract": "The rapid advancement of neural language models has sparked a new surge of\nintelligent agent research. Unlike traditional agents, large language\nmodel-based agents (LLM agents) have emerged as a promising paradigm for\nachieving artificial general intelligence (AGI) due to their superior reasoning\nand generalization capabilities. Effective planning is crucial for the success\nof LLM agents in real-world tasks, making it a highly pursued topic in the\ncommunity. Current planning methods typically translate tasks into executable\naction sequences. However, determining a feasible or optimal sequence for\ncomplex tasks with multiple constraints at fine granularity, which often\nrequires compositing long chains of heterogeneous actions, remains challenging.\nThis paper introduces Planning with Multi-Constraints (PMC), a zero-shot\nmethodology for collaborative LLM-based multi-agent systems that simplifies\ncomplex task planning with constraints by decomposing it into a hierarchy of\nsubordinate tasks. Each subtask is then mapped into executable actions. PMC was\nassessed on two constraint-intensive benchmarks, TravelPlanner and API-Bank.\nNotably, PMC achieved an average 42.68% success rate on TravelPlanner,\nsignificantly higher than GPT-4 (2.92%), and outperforming GPT-4 with ReAct on\nAPI-Bank by 13.64%, showing the immense potential of integrating LLM with\nmulti-agent systems. We also show that PMC works with small LLM as the planning\ncore, e.g., LLaMA-3.1-8B.",
      "tldr_zh": "本论文提出了一种名为 PMC（Planning with Multi-Constraints）的零样本方法，用于协作 LLM agents（大型语言模型代理）多智能体系统，以简化复杂任务的规划。该方法通过将多约束任务分解成层次化的子任务，并映射到可执行动作，从而处理细粒度异构动作链的挑战。在 TravelPlanner 和 API-Bank 等基准测试中，PMC 实现了 42.68% 的平均成功率，远超 GPT-4（2.92%），并在 API-Bank 上比 GPT-4 with ReAct 高出 13.64%，同时证明了其与小型 LLM 如 LLaMA-3.1-8B 的兼容性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16510v4",
      "published_date": "2024-05-26 10:33:17 UTC",
      "updated_date": "2024-12-16 02:27:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:11:56.631771"
    },
    {
      "arxiv_id": "2405.16507v6",
      "title": "Causal Concept Graph Models: Beyond Causal Opacity in Deep Learning",
      "title_zh": "因果概念图模型：超越深度学习",
      "authors": [
        "Gabriele Dominici",
        "Pietro Barbiero",
        "Mateo Espinosa Zarlenga",
        "Alberto Termine",
        "Martin Gjoreski",
        "Giuseppe Marra",
        "Marc Langheinrich"
      ],
      "abstract": "Causal opacity denotes the difficulty in understanding the \"hidden\" causal\nstructure underlying the decisions of deep neural network (DNN) models. This\nleads to the inability to rely on and verify state-of-the-art DNN-based\nsystems, especially in high-stakes scenarios. For this reason, circumventing\ncausal opacity in DNNs represents a key open challenge at the intersection of\ndeep learning, interpretability, and causality. This work addresses this gap by\nintroducing Causal Concept Graph Models (Causal CGMs), a class of interpretable\nmodels whose decision-making process is causally transparent by design. Our\nexperiments show that Causal CGMs can: (i) match the generalisation performance\nof causally opaque models, (ii) enable human-in-the-loop corrections to\nmispredicted intermediate reasoning steps, boosting not just downstream\naccuracy after corrections but also the reliability of the explanations\nprovided for specific instances, and (iii) support the analysis of\ninterventional and counterfactual scenarios, thereby improving the model's\ncausal interpretability and supporting the effective verification of its\nreliability and fairness.",
      "tldr_zh": "本研究针对深度神经网络 (DNN) 的因果不透明性问题，即难以理解其隐藏的因果结构，导致在高风险场景中难以依赖和验证，提出了一种新的模型类——Causal Concept Graph Models (Causal CGMs)。Causal CGMs 通过设计天生因果透明的决策过程，提升了模型的可解释性。实验结果显示，该模型能匹配因果不透明模型的泛化性能，同时支持人类干预纠正中间推理步骤，并分析干预和反事实场景，从而提高准确性、解释可靠性以及模型的公平性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16507v6",
      "published_date": "2024-05-26 10:15:20 UTC",
      "updated_date": "2025-04-01 10:47:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:12:07.714782"
    },
    {
      "arxiv_id": "2405.16496v2",
      "title": "Exploring a Multimodal Fusion-based Deep Learning Network for Detecting Facial Palsy",
      "title_zh": "翻译失败",
      "authors": [
        "Heng Yim Nicole Oo",
        "Min Hun Lee",
        "Jeong Hoon Lim"
      ],
      "abstract": "Algorithmic detection of facial palsy offers the potential to improve current\npractices, which usually involve labor-intensive and subjective assessment by\nclinicians. In this paper, we present a multimodal fusion-based deep learning\nmodel that utilizes unstructured data (i.e. an image frame with facial line\nsegments) and structured data (i.e. features of facial expressions) to detect\nfacial palsy. We then contribute to a study to analyze the effect of different\ndata modalities and the benefits of a multimodal fusion-based approach using\nvideos of 21 facial palsy patients. Our experimental results show that among\nvarious data modalities (i.e. unstructured data - RGB images and images of\nfacial line segments and structured data - coordinates of facial landmarks and\nfeatures of facial expressions), the feed-forward neural network using features\nof facial expression achieved the highest precision of 76.22 while the\nResNet-based model using images of facial line segments achieved the highest\nrecall of 83.47. When we leveraged both images of facial line segments and\nfeatures of facial expressions, our multimodal fusion-based deep learning model\nslightly improved the precision score to 77.05 at the expense of a decrease in\nthe recall score.",
      "tldr_zh": "本研究提出了一种基于多模态融合的深度学习模型，用于检测面瘫，通过整合非结构化数据（如带有面部线段的图像帧）和结构化数据（如面部表情特征），以改善传统主观评估方法。研究者分析了21名面瘫患者的视频，比较了不同数据模态的表现，结果显示，使用面部表情特征的前馈神经网络取得了最高的precision（76.22%），而基于ResNet的模型使用面部线段图像则达到了最高的recall（83.47%）。当结合面部线段图像和面部表情特征时，该多模态融合模型略微提升了precision至77.05%，但recall有所下降，展示了多模态方法的潜在优势和权衡。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "IJCAI 2024 4th AI for Ageless Aging Workshop (AIAA)",
      "pdf_url": "http://arxiv.org/pdf/2405.16496v2",
      "published_date": "2024-05-26 09:16:34 UTC",
      "updated_date": "2025-03-13 13:56:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:12:20.179798"
    },
    {
      "arxiv_id": "2405.16489v2",
      "title": "Causal-aware Graph Neural Architecture Search under Distribution Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Peiwen Li",
        "Xin Wang",
        "Zeyang Zhang",
        "Yijian Qin",
        "Ziwei Zhang",
        "Jialong Wang",
        "Yang Li",
        "Wenwu Zhu"
      ],
      "abstract": "Graph NAS has emerged as a promising approach for autonomously designing GNN\narchitectures by leveraging the correlations between graphs and architectures.\nExisting methods fail to generalize under distribution shifts that are\nubiquitous in real-world graph scenarios, mainly because the graph-architecture\ncorrelations they exploit might be spurious and varying across distributions.\nWe propose to handle the distribution shifts in the graph architecture search\nprocess by discovering and exploiting the causal relationship between graphs\nand architectures to search for the optimal architectures that can generalize\nunder distribution shifts. The problem remains unexplored with following\nchallenges: how to discover the causal graph-architecture relationship that has\nstable predictive abilities across distributions, and how to handle\ndistribution shifts with the discovered causal graph-architecture relationship\nto search the generalized graph architectures. To address these challenges, we\npropose Causal-aware Graph Neural Architecture Search (CARNAS), which is able\nto capture the causal graph-architecture relationship during the architecture\nsearch process and discover the generalized graph architecture under\ndistribution shifts. Specifically, we propose Disentangled Causal Subgraph\nIdentification to capture the causal subgraphs that have stable prediction\nabilities across distributions. Then, we propose Graph Embedding Intervention\nto intervene on causal subgraphs within the latent space, ensuring that these\nsubgraphs encapsulate essential features for prediction while excluding\nnon-causal elements. Additionally, we propose Invariant Architecture\nCustomization to reinforce the causal invariant nature of the causal subgraphs,\nwhich are utilized to tailor generalized graph architectures. Extensive\nexperiments demonstrate that CARNAS achieves advanced out-of-distribution\ngeneralization ability.",
      "tldr_zh": "本论文提出 Causal-aware Graph Neural Architecture Search (CARNAS)，一种针对分布偏移的图神经架构搜索方法，通过发现和利用图-架构之间的因果关系来提升模型的泛化能力。CARNAS 包括三个关键组件：Disentangled Causal Subgraph Identification 用于捕捉跨分布稳定的因果子图、Graph Embedding Intervention 在潜空间中干预子图以排除非因果元素，以及 Invariant Architecture Customization 来强化因果不变性并定制泛化架构。实验结果表明，CARNAS 在各种分布偏移场景下实现了先进的分布外泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16489v2",
      "published_date": "2024-05-26 08:55:22 UTC",
      "updated_date": "2024-12-30 11:28:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:12:31.873298"
    },
    {
      "arxiv_id": "2405.16486v1",
      "title": "Decomposing the Neurons: Activation Sparsity via Mixture of Experts for Continual Test Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Rongyu Zhang",
        "Aosong Cheng",
        "Yulin Luo",
        "Gaole Dai",
        "Huanrui Yang",
        "Jiaming Liu",
        "Ran Xu",
        "Li Du",
        "Yuan Du",
        "Yanbing Jiang",
        "Shanghang Zhang"
      ],
      "abstract": "Continual Test-Time Adaptation (CTTA), which aims to adapt the pre-trained\nmodel to ever-evolving target domains, emerges as an important task for vision\nmodels. As current vision models appear to be heavily biased towards texture,\ncontinuously adapting the model from one domain distribution to another can\nresult in serious catastrophic forgetting. Drawing inspiration from the human\nvisual system's adeptness at processing both shape and texture according to the\nfamous Trichromatic Theory, we explore the integration of a\nMixture-of-Activation-Sparsity-Experts (MoASE) as an adapter for the CTTA task.\nGiven the distinct reaction of neurons with low/high activation to\ndomain-specific/agnostic features, MoASE decomposes the neural activation into\nhigh-activation and low-activation components with a non-differentiable Spatial\nDifferentiate Dropout (SDD). Based on the decomposition, we devise a multi-gate\nstructure comprising a Domain-Aware Gate (DAG) that utilizes domain information\nto adaptive combine experts that process the post-SDD sparse activations of\ndifferent strengths, and the Activation Sparsity Gate (ASG) that adaptively\nassigned feature selection threshold of the SDD for different experts for more\nprecise feature decomposition. Finally, we introduce a Homeostatic-Proximal\n(HP) loss to bypass the error accumulation problem when continuously adapting\nthe model. Extensive experiments on four prominent benchmarks substantiate that\nour methodology achieves state-of-the-art performance in both classification\nand segmentation CTTA tasks. Our code is now available at\nhttps://github.com/RoyZry98/MoASE-Pytorch.",
      "tldr_zh": "该论文针对 Continual Test-Time Adaptation (CTTA) 任务，提出一种 Mixture-of-Activation-Sparsity-Experts (MoASE) 框架，以缓解视觉模型在适应不断变化域时出现的灾难性遗忘问题。MoASE 通过 Spatial Differentiate Dropout (SDD) 将神经激活分解为高激活和低激活组件，并利用 Domain-Aware Gate (DAG) 和 Activation Sparsity Gate (ASG) 来动态结合专家处理稀疏激活和域信息，实现更精确的特征分解。实验结果显示，该方法在四个基准上的分类和分割任务中达到了 state-of-the-art 性能，并引入 Homeostatic-Proximal (HP) 损失来避免连续适配中的错误积累。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16486v1",
      "published_date": "2024-05-26 08:51:39 UTC",
      "updated_date": "2024-05-26 08:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:12:45.474670"
    },
    {
      "arxiv_id": "2405.16478v1",
      "title": "Vision-Based Approach for Food Weight Estimation from 2D Images",
      "title_zh": "基于视觉的方法用于从2D图像估计食物重量",
      "authors": [
        "Chathura Wimalasiri",
        "Prasan Kumar Sahoo"
      ],
      "abstract": "In response to the increasing demand for efficient and non-invasive methods\nto estimate food weight, this paper presents a vision-based approach utilizing\n2D images. The study employs a dataset of 2380 images comprising fourteen\ndifferent food types in various portions, orientations, and containers. The\nproposed methodology integrates deep learning and computer vision techniques,\nspecifically employing Faster R-CNN for food detection and MobileNetV3 for\nweight estimation. The detection model achieved a mean average precision (mAP)\nof 83.41\\%, an average Intersection over Union (IoU) of 91.82\\%, and a\nclassification accuracy of 100\\%. For weight estimation, the model demonstrated\na root mean squared error (RMSE) of 6.3204, a mean absolute percentage error\n(MAPE) of 0.0640\\%, and an R-squared value of 98.65\\%. The study underscores\nthe potential applications of this technology in healthcare for nutrition\ncounseling, fitness and wellness for dietary intake assessment, and smart food\nstorage solutions to reduce waste. The results indicate that the combination of\nFaster R-CNN and MobileNetV3 provides a robust framework for accurate food\nweight estimation from 2D images, showcasing the synergy of computer vision and\ndeep learning in practical applications.",
      "tldr_zh": "本研究提出了一种基于 2D 图像的视觉方法，用于非侵入式估算食物重量，采用 Faster R-CNN 进行食物检测和 MobileNetV3 进行重量估算。研究基于一个包含 2380 张图像的数据集，涵盖 14 种食物类型、不同份量、方向和容器。结果显示，检测模型的 mAP 为 83.41%、IoU 为 91.82%、分类准确率 100%，而重量估算模型的 RMSE 为 6.3204、MAPE 为 0.0640%、R-squared 为 98.65%。该方法展示了计算机视觉和深度学习在医疗营养咨询、健身饮食评估以及智能食物存储领域的潜在应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Six pages, Six figures, The final version of this paper is published\n  in IEEE Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.16478v1",
      "published_date": "2024-05-26 08:03:51 UTC",
      "updated_date": "2024-05-26 08:03:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:12:59.734737"
    },
    {
      "arxiv_id": "2405.16475v3",
      "title": "Looks Too Good To Be True: An Information-Theoretic Analysis of Hallucinations in Generative Restoration Models",
      "title_zh": "翻译失败",
      "authors": [
        "Regev Cohen",
        "Idan Kligvasser",
        "Ehud Rivlin",
        "Daniel Freedman"
      ],
      "abstract": "The pursuit of high perceptual quality in image restoration has driven the\ndevelopment of revolutionary generative models, capable of producing results\noften visually indistinguishable from real data. However, as their perceptual\nquality continues to improve, these models also exhibit a growing tendency to\ngenerate hallucinations - realistic-looking details that do not exist in the\nground truth images. Hallucinations in these models create uncertainty about\ntheir reliability, raising major concerns about their practical application.\nThis paper investigates this phenomenon through the lens of information theory,\nrevealing a fundamental tradeoff between uncertainty and perception. We\nrigorously analyze the relationship between these two factors, proving that the\nglobal minimal uncertainty in generative models grows in tandem with\nperception. In particular, we define the inherent uncertainty of the\nrestoration problem and show that attaining perfect perceptual quality entails\nat least twice this uncertainty. Additionally, we establish a relation between\ndistortion, uncertainty and perception, through which we prove the\naforementioned uncertainly-perception tradeoff induces the well-known\nperception-distortion tradeoff. We demonstrate our theoretical findings through\nexperiments with super-resolution and inpainting algorithms. This work uncovers\nfundamental limitations of generative models in achieving both high perceptual\nquality and reliable predictions for image restoration. Thus, we aim to raise\nawareness among practitioners about this inherent tradeoff, empowering them to\nmake informed decisions and potentially prioritize safety over perceptual\nperformance.",
      "tldr_zh": "这篇论文从信息理论角度分析了生成式图像恢复模型中的hallucinations问题，揭示了不确定性(uncertainty)和感知质量(perception)之间存在的根本权衡。作者证明了模型的不确定性会随着感知质量的提升而增加，且实现完美感知质量至少需要原始不确定性的两倍；此外，他们建立了失真(distortion)、不确定性和感知之间的关系，证明了感知-失真权衡。实验通过超分辨率和修复算法验证了这些理论发现，并提醒从业者在图像恢复应用中优先考虑安全可靠性，而不是单纯追求高感知性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.IV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16475v3",
      "published_date": "2024-05-26 07:58:51 UTC",
      "updated_date": "2024-10-25 19:40:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:13:10.681295"
    },
    {
      "arxiv_id": "2405.16473v1",
      "title": "M$^3$CoT: A Novel Benchmark for Multi-Domain Multi-step Multi-modal Chain-of-Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Qiguang Chen",
        "Libo Qin",
        "Jin Zhang",
        "Zhi Chen",
        "Xiao Xu",
        "Wanxiang Che"
      ],
      "abstract": "Multi-modal Chain-of-Thought (MCoT) requires models to leverage knowledge\nfrom both textual and visual modalities for step-by-step reasoning, which gains\nincreasing attention. Nevertheless, the current MCoT benchmark still faces some\nchallenges: (1) absence of visual modal reasoning, (2) single-step visual modal\nreasoning, and (3) Domain missing, thereby hindering the development of MCoT.\nMotivated by this, we introduce a novel benchmark (M$^3$CoT) to address the\nabove challenges, advancing the multi-domain, multi-step, and multi-modal CoT.\nAdditionally, we conduct a thorough evaluation involving abundant MCoT\napproaches on Vision Large Language Models (VLLMs). In addition, we highlight\nthat the current VLLMs still struggle to correctly reason in M$^3$CoT and there\nremains a large gap between existing VLLMs and human performance in M$^3$CoT,\ndespite their superior results on previous MCoT benchmarks. To our knowledge,\nwe take the first meaningful step toward the multi-domain, multi-step, and\nmulti-modal scenario in MCoT. We hope that M$^3$CoT can serve as a valuable\nresource, providing a pioneering foundation in multi-domain, multi-step,\nmulti-modal chain-of-thought research.",
      "tldr_zh": "本研究引入了一个新基准M$^3$CoT，用于评估多领域、多步、多模态的Chain-of-Thought (CoT) 推理，旨在解决现有Multi-modal Chain-of-Thought (MCoT) 基准的不足，如缺少视觉模态推理、仅限于单步推理和领域覆盖缺失。M$^3$CoT 通过整合文本和视觉模态，支持更全面的逐步推理，并对多种Vision Large Language Models (VLLMs) 进行了彻底评估，结果显示这些模型在M$^3$CoT 上表现不佳，与人类性能存在较大差距。尽管VLLMs 在先前基准上表现出色，这一发现突显了新基准的价值，为多领域、多步、多模态CoT 研究提供了开创性基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at ACL2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2405.16473v1",
      "published_date": "2024-05-26 07:56:30 UTC",
      "updated_date": "2024-05-26 07:56:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:13:22.691979"
    },
    {
      "arxiv_id": "2405.16460v1",
      "title": "Probabilistic Contrastive Learning with Explicit Concentration on the Hypersphere",
      "title_zh": "翻译失败",
      "authors": [
        "Hongwei Bran Li",
        "Cheng Ouyang",
        "Tamaz Amiranashvili",
        "Matthew S. Rosen",
        "Bjoern Menze",
        "Juan Eugenio Iglesias"
      ],
      "abstract": "Self-supervised contrastive learning has predominantly adopted deterministic\nmethods, which are not suited for environments characterized by uncertainty and\nnoise. This paper introduces a new perspective on incorporating uncertainty\ninto contrastive learning by embedding representations within a spherical\nspace, inspired by the von Mises-Fisher distribution (vMF). We introduce an\nunnormalized form of vMF and leverage the concentration parameter, kappa, as a\ndirect, interpretable measure to quantify uncertainty explicitly. This approach\nnot only provides a probabilistic interpretation of the embedding space but\nalso offers a method to calibrate model confidence against varying levels of\ndata corruption and characteristics. Our empirical results demonstrate that the\nestimated concentration parameter correlates strongly with the degree of\nunforeseen data corruption encountered at test time, enables failure analysis,\nand enhances existing out-of-distribution detection methods.",
      "tldr_zh": "这篇论文提出了一种概率对比学习方法，将表示嵌入 hypersphere 中，并受 von Mises-Fisher distribution (vMF) 启发，旨在处理自监督学习在不确定性和噪声环境中的局限性。作者引入了 unnormalized vMF 形式，并使用 concentration parameter kappa 作为直接可解释的度量来量化不确定性，从而提供一个概率解释的嵌入空间，并实现模型置信度的校准。实验结果显示，kappa 参数与测试时的数据损坏程度高度相关，有助于故障分析，并显著提升了现有的 out-of-distribution detection 方法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "technical report",
      "pdf_url": "http://arxiv.org/pdf/2405.16460v1",
      "published_date": "2024-05-26 07:08:13 UTC",
      "updated_date": "2024-05-26 07:08:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:13:34.158118"
    },
    {
      "arxiv_id": "2405.16456v1",
      "title": "Dominant Shuffle: A Simple Yet Powerful Data Augmentation for Time-series Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Zhao",
        "Zuojie He",
        "Alex Hung",
        "Dan Zeng"
      ],
      "abstract": "Recent studies have suggested frequency-domain Data augmentation (DA) is\neffec tive for time series prediction. Existing frequency-domain augmentations\ndisturb the original data with various full-spectrum noises, leading to excess\ndomain gap between augmented and original data. Although impressive performance\nhas been achieved in certain cases, frequency-domain DA has yet to be\ngeneralized to time series prediction datasets. In this paper, we found that\nfrequency-domain augmentations can be significantly improved by two\nmodifications that limit the perturbations. First, we found that limiting the\nperturbation to only dominant frequencies significantly outperforms\nfull-spectrum perturbations. Dominant fre quencies represent the main\nperiodicity and trends of the signal and are more important than other\nfrequencies. Second, we found that simply shuffling the dominant frequency\ncomponents is superior over sophisticated designed random perturbations.\nShuffle rearranges the original components (magnitudes and phases) and limits\nthe external noise. With these two modifications, we proposed dominant shuffle,\na simple yet effective data augmentation for time series prediction. Our method\nis very simple yet powerful and can be implemented with just a few lines of\ncode. Extensive experiments with eight datasets and six popular time series\nmodels demonstrate that our method consistently improves the baseline\nperformance under various settings and significantly outperforms other DA\nmethods. Code can be accessed at https://kaizhao.net/time-series.",
      "tldr_zh": "本文提出 Dominant Shuffle，一种简单有效的时序预测数据增强方法，通过仅对主导频率进行洗牌扰动，解决了现有频率域增强的过度干扰问题，避免了全谱噪声带来的领域差距。相比复杂随机扰动，该方法重新排列主导频率的幅度和相位组件，保持信号的主要周期性和趋势。实验在八个数据集和六种流行时序模型上显示，Dominant Shuffle 显著提升基线性能，并优于其他数据增强技术。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://kaizhao.net/time-series",
      "pdf_url": "http://arxiv.org/pdf/2405.16456v1",
      "published_date": "2024-05-26 07:00:12 UTC",
      "updated_date": "2024-05-26 07:00:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:13:45.438296"
    },
    {
      "arxiv_id": "2405.16453v1",
      "title": "A Slices Perspective for Incremental Nonparametric Inference in High Dimensional State Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Moshe Shienman",
        "Ohad Levy-Or",
        "Michael Kaess",
        "Vadim Indelman"
      ],
      "abstract": "We introduce an innovative method for incremental nonparametric probabilistic\ninference in high-dimensional state spaces. Our approach leverages \\slices from\nhigh-dimensional surfaces to efficiently approximate posterior distributions of\nany shape. Unlike many existing graph-based methods, our \\slices perspective\neliminates the need for additional intermediate reconstructions, maintaining a\nmore accurate representation of posterior distributions. Additionally, we\npropose a novel heuristic to balance between accuracy and efficiency, enabling\nreal-time operation in nonparametric scenarios. In empirical evaluations on\nsynthetic and real-world datasets, our \\slices approach consistently\noutperforms other state-of-the-art methods. It demonstrates superior accuracy\nand achieves a significant reduction in computational complexity, often by an\norder of magnitude.",
      "tldr_zh": "本研究提出了一种创新方法，用于高维状态空间中的增量非参数推断，通过利用高维表面的 slices 来高效近似任意形状的后验分布。与现有基于图的方法不同，该方法无需额外中间重建，从而保持更准确的分布表示。研究还引入了一种新颖的启发式策略，以平衡准确性和效率，实现实时操作。在合成和真实数据集上的实证评估中，该方法在准确性上 consistently outperforms 其他最先进的方法，并显著降低了计算复杂度，往往减少一个数量级。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 Pages, 7 figures, Submitted to IEEE IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16453v1",
      "published_date": "2024-05-26 06:52:56 UTC",
      "updated_date": "2024-05-26 06:52:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:13:58.184918"
    },
    {
      "arxiv_id": "2405.19366v2",
      "title": "ECG Semantic Integrator (ESI): A Foundation ECG Model Pretrained with LLM-Enhanced Cardiological Text",
      "title_zh": "翻译失败",
      "authors": [
        "Han Yu",
        "Peikun Guo",
        "Akane Sano"
      ],
      "abstract": "The utilization of deep learning on electrocardiogram (ECG) analysis has\nbrought the advanced accuracy and efficiency of cardiac healthcare diagnostics.\nBy leveraging the capabilities of deep learning in semantic understanding,\nespecially in feature extraction and representation learning, this study\nintroduces a new multimodal contrastive pretaining framework that aims to\nimprove the quality and robustness of learned representations of 12-lead ECG\nsignals. Our framework comprises two key components, including Cardio Query\nAssistant (CQA) and ECG Semantics Integrator(ESI). CQA integrates a\nretrieval-augmented generation (RAG) pipeline to leverage large language models\n(LLMs) and external medical knowledge to generate detailed textual descriptions\nof ECGs. The generated text is enriched with information about demographics and\nwaveform patterns. ESI integrates both contrastive and captioning loss to\npretrain ECG encoders for enhanced representations. We validate our approach\nthrough various downstream tasks, including arrhythmia detection and ECG-based\nsubject identification. Our experimental results demonstrate substantial\nimprovements over strong baselines in these tasks. These baselines encompass\nsupervised and self-supervised learning methods, as well as prior multimodal\npretraining approaches.",
      "tldr_zh": "本研究引入了ECG Semantic Integrator (ESI)，一个基于多模态对比预训练框架，旨在提升12-lead ECG信号的表示学习质量和鲁棒性，以改进心脏医疗诊断。该框架包括两个关键组件：Cardio Query Assistant (CQA)，它利用检索增强生成 (RAG) 管道结合大型语言模型 (LLMs) 和外部医疗知识，生成包含人口统计和波形模式的ECG详细文本描述；以及ESI本身，通过整合对比损失和标题损失来预训练ECG编码器。实验结果显示，该方法在下游任务如心律失常检测和ECG-based主体识别上，比监督学习、自监督学习和现有多模态预训练基线取得了显著改进。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19366v2",
      "published_date": "2024-05-26 06:45:39 UTC",
      "updated_date": "2024-10-23 18:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:14:10.684933"
    },
    {
      "arxiv_id": "2405.16450v3",
      "title": "Synthesizing Programmatic Reinforcement Learning Policies with Large Language Model Guided Search",
      "title_zh": "翻译失败",
      "authors": [
        "Max Liu",
        "Chan-Hung Yu",
        "Wei-Hsu Lee",
        "Cheng-Wei Hung",
        "Yen-Chun Chen",
        "Shao-Hua Sun"
      ],
      "abstract": "Programmatic reinforcement learning (PRL) has been explored for representing\npolicies through programs as a means to achieve interpretability and\ngeneralization. Despite promising outcomes, current state-of-the-art PRL\nmethods are hindered by sample inefficiency, necessitating tens of millions of\nprogram-environment interactions. To tackle this challenge, we introduce a\nnovel LLM-guided search framework (LLM-GS). Our key insight is to leverage the\nprogramming expertise and common sense reasoning of LLMs to enhance the\nefficiency of assumption-free, random-guessing search methods. We address the\nchallenge of LLMs' inability to generate precise and grammatically correct\nprograms in domain-specific languages (DSLs) by proposing a Pythonic-DSL\nstrategy - an LLM is instructed to initially generate Python codes and then\nconvert them into DSL programs. To further optimize the LLM-generated programs,\nwe develop a search algorithm named Scheduled Hill Climbing, designed to\nefficiently explore the programmatic search space to improve the programs\nconsistently. Experimental results in the Karel domain demonstrate our LLM-GS\nframework's superior effectiveness and efficiency. Extensive ablation studies\nfurther verify the critical role of our Pythonic-DSL strategy and Scheduled\nHill Climbing algorithm. Moreover, we conduct experiments with two novel tasks,\nshowing that LLM-GS enables users without programming skills and knowledge of\nthe domain or DSL to describe the tasks in natural language to obtain\nperformant programs.",
      "tldr_zh": "本研究针对程序化强化学习（PRL）的样本效率问题，提出了一种基于大型语言模型（LLM）指导搜索的框架（LLM-GS），旨在通过LLM的编程专长和常识推理提升策略搜索的效率。核心方法包括Pythonic-DSL策略，让LLM先生成Python代码再转换为特定领域语言（DSL）程序，以及Scheduled Hill Climbing算法，用于高效探索和优化程序空间。实验在Karel领域证明，LLM-GS显著提高了PRL的有效性和效率，比传统方法更出色；此外，消融研究和新型任务测试显示，该框架允许非编程用户用自然语言描述任务，从而生成高性能程序。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16450v3",
      "published_date": "2024-05-26 06:33:48 UTC",
      "updated_date": "2025-03-11 12:52:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:14:22.919742"
    },
    {
      "arxiv_id": "2405.16440v1",
      "title": "MambaTS: Improved Selective State Space Models for Long-term Time Series Forecasting",
      "title_zh": "MambaTS：改进的选择性状态空间模型用于长期时间序列预测",
      "authors": [
        "Xiuding Cai",
        "Yaoyao Zhu",
        "Xueyao Wang",
        "Yu Yao"
      ],
      "abstract": "In recent years, Transformers have become the de-facto architecture for\nlong-term sequence forecasting (LTSF), but faces challenges such as quadratic\ncomplexity and permutation invariant bias. A recent model, Mamba, based on\nselective state space models (SSMs), has emerged as a competitive alternative\nto Transformer, offering comparable performance with higher throughput and\nlinear complexity related to sequence length. In this study, we analyze the\nlimitations of current Mamba in LTSF and propose four targeted improvements,\nleading to MambaTS. We first introduce variable scan along time to arrange the\nhistorical information of all the variables together. We suggest that causal\nconvolution in Mamba is not necessary for LTSF and propose the Temporal Mamba\nBlock (TMB). We further incorporate a dropout mechanism for selective\nparameters of TMB to mitigate model overfitting. Moreover, we tackle the issue\nof variable scan order sensitivity by introducing variable permutation\ntraining. We further propose variable-aware scan along time to dynamically\ndiscover variable relationships during training and decode the optimal variable\nscan order by solving the shortest path visiting all nodes problem during\ninference. Extensive experiments conducted on eight public datasets demonstrate\nthat MambaTS achieves new state-of-the-art performance.",
      "tldr_zh": "该研究分析了Mamba模型在长期时间序列预测(LTSF)中的局限性，如变量顺序敏感性和潜在过拟合问题，并提出四点针对性改进，形成了MambaTS模型。\n改进包括引入variable scan along time来组织变量历史信息、提出Temporal Mamba Block (TMB)去除不必要的因果卷积、添加dropout机制到TMB的选择性参数中以缓解过拟合，以及通过variable permutation training和variable-aware scan along time动态优化变量扫描顺序。\n实验结果显示，MambaTS在八个公共数据集上实现了新的最先进性能，提供了一种高效的Selective State Space Models替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16440v1",
      "published_date": "2024-05-26 05:50:17 UTC",
      "updated_date": "2024-05-26 05:50:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:14:35.138846"
    },
    {
      "arxiv_id": "2405.16439v3",
      "title": "Multi-Agent Inverse Reinforcement Learning in Real World Unstructured Pedestrian Crowds",
      "title_zh": "多智能体逆强化学习在真实世界非结构化行人人群中的应用",
      "authors": [
        "Rohan Chandra",
        "Haresh Karnan",
        "Negar Mehr",
        "Peter Stone",
        "Joydeep Biswas"
      ],
      "abstract": "Social robot navigation in crowded public spaces such as university campuses,\nrestaurants, grocery stores, and hospitals, is an increasingly important area\nof research. One of the core strategies for achieving this goal is to\nunderstand humans' intent--underlying psychological factors that govern their\nmotion--by learning their reward functions, typically via inverse reinforcement\nlearning (IRL). Despite significant progress in IRL, learning reward functions\nof multiple agents simultaneously in dense unstructured pedestrian crowds has\nremained intractable due to the nature of the tightly coupled social\ninteractions that occur in these scenarios \\textit{e.g.} passing,\nintersections, swerving, weaving, etc. In this paper, we present a new\nmulti-agent maximum entropy inverse reinforcement learning algorithm for real\nworld unstructured pedestrian crowds. Key to our approach is a simple, but\neffective, mathematical trick which we name the so-called\ntractability-rationality trade-off trick that achieves tractability at the cost\nof a slight reduction in accuracy. We compare our approach to the classical\nsingle-agent MaxEnt IRL as well as state-of-the-art trajectory prediction\nmethods on several datasets including the ETH, UCY, SCAND, JRDB, and a new\ndataset, called Speedway, collected at a busy intersection on a University\ncampus focusing on dense, complex agent interactions. Our key findings show\nthat, on the dense Speedway dataset, our approach ranks 1st among top 7\nbaselines with >2X improvement over single-agent IRL, and is competitive with\nstate-of-the-art large transformer-based encoder-decoder models on sparser\ndatasets such as ETH/UCY (ranks 3rd among top 7 baselines).",
      "tldr_zh": "本研究针对社会机器人导航在真实世界非结构化人群（如大学校园交叉口）中的挑战，提出了一种多代理最大熵逆强化学习（Multi-Agent Maximum Entropy IRL）算法，以同时学习多个代理的奖励函数，从而理解人类的意图和运动行为。算法的关键创新是引入tractability-rationality trade-off trick，这是一种简单有效的数学技巧，通过轻微牺牲准确性来提升计算可行性。实验在ETH、UCY、SCAND、JRDB和新的Speedway数据集上进行，结果显示，该方法在密集的Speedway数据集上比单代理MaxEnt IRL改善超过2倍，并在较稀疏数据集如ETH/UCY上与最先进transformer模型竞争，排名前三。总的来说，该工作为机器人处理复杂社会互动提供了更可靠的框架。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16439v3",
      "published_date": "2024-05-26 05:48:21 UTC",
      "updated_date": "2025-03-26 21:19:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:14:48.226806"
    },
    {
      "arxiv_id": "2405.16436v3",
      "title": "Provably Mitigating Overoptimization in RLHF: Your SFT Loss is Implicitly an Adversarial Regularizer",
      "title_zh": "可证明地缓解 RLHF 中的过优化：你的 SFT 损失隐式地是一个对抗正则化器",
      "authors": [
        "Zhihan Liu",
        "Miao Lu",
        "Shenao Zhang",
        "Boyi Liu",
        "Hongyi Guo",
        "Yingxiang Yang",
        "Jose Blanchet",
        "Zhaoran Wang"
      ],
      "abstract": "Aligning generative models with human preference via RLHF typically suffers\nfrom overoptimization, where an imperfectly learned reward model can misguide\nthe generative model to output undesired responses. We investigate this problem\nin a principled manner by identifying the source of the misalignment as a form\nof distributional shift and uncertainty in learning human preferences. To\nmitigate overoptimization, we first propose a theoretical algorithm that\nchooses the best policy for an adversarially chosen reward model; one that\nsimultaneously minimizes the maximum likelihood estimation of the loss and a\nreward penalty term. Here, the reward penalty term is introduced to prevent the\npolicy from choosing actions with spurious high proxy rewards, resulting in\nprovable sample efficiency of the algorithm under a partial coverage style\ncondition. Moving from theory to practice, the proposed algorithm further\nenjoys an equivalent but surprisingly easy-to-implement reformulation. Using\nthe equivalence between reward models and the corresponding optimal policy, the\nalgorithm features a simple objective that combines: (i) a preference\noptimization loss that directly aligns the policy with human preference, and\n(ii) a supervised learning loss that explicitly imitates the policy with a\n(suitable) baseline distribution. In the context of aligning large language\nmodels (LLM), this objective fuses the direct preference optimization (DPO)\nloss with the supervised fine-tuning (SFT) loss to help mitigate the\noveroptimization towards undesired responses, for which we name the algorithm\nRegularized Preference Optimization (RPO). Experiments of aligning LLMs\ndemonstrate the improved performance of RPO compared with DPO baselines. Our\nwork sheds light on the interplay between preference optimization and SFT in\ntuning LLMs with both theoretical guarantees and empirical evidence.",
      "tldr_zh": "本研究探讨了在强化学习从人类反馈（RLHF）中缓解过度优化（overoptimization）问题，该问题源于分布偏移（distributional shift）和人类偏好学习的不确定性，导致生成模型输出 undesired responses。作者提出一个理论算法，通过最小化最大似然估计损失并引入奖励惩罚项（reward penalty term），以选择最佳策略，并在部分覆盖条件（partial coverage style condition）下证明其样本效率。实践上，该算法转化为 Regularized Preference Optimization (RPO)，将直接偏好优化损失（DPO）与监督微调损失（SFT）结合，实现对大型语言模型（LLMs）的更稳定对齐。实验结果显示，RPO 比 DPO 基线在对齐 LLMs 时表现出色，提供了理论保证和经验证据，支持了偏好优化与 SFT 的相互作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by The Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems. 31 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.16436v3",
      "published_date": "2024-05-26 05:38:50 UTC",
      "updated_date": "2024-12-04 08:15:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:15:00.701579"
    },
    {
      "arxiv_id": "2405.16434v2",
      "title": "The Importance of Directional Feedback for LLM-based Optimizers",
      "title_zh": "翻译失败",
      "authors": [
        "Allen Nie",
        "Ching-An Cheng",
        "Andrey Kolobov",
        "Adith Swaminathan"
      ],
      "abstract": "We study the potential of using large language models (LLMs) as an\ninteractive optimizer for solving maximization problems in a text space using\nnatural language and numerical feedback. Inspired by the classical optimization\nliterature, we classify the natural language feedback into directional and\nnon-directional, where the former is a generalization of the first-order\nfeedback to the natural language space. We find that LLMs are especially\ncapable of optimization when they are provided with {directional feedback}.\nBased on this insight, we design a new LLM-based optimizer that synthesizes\ndirectional feedback from the historical optimization trace to achieve reliable\nimprovement over iterations. Empirically, we show our LLM-based optimizer is\nmore stable and efficient in solving optimization problems, from maximizing\nmathematical functions to optimizing prompts for writing poems, compared with\nexisting techniques.",
      "tldr_zh": "论文探讨了使用大型语言模型(LLMs)作为交互式优化器来解决文本空间的最大化问题，强调了方向性反馈(directional feedback)的关键作用，因为它能显著提升LLMs的优化性能。作者将反馈分类为方向性(directional)和非方向性(non-directional)，并设计了一个新LLM-based optimizer，通过从历史优化轨迹中合成方向性反馈，实现更可靠的迭代改进。实验结果表明，该优化器在最大化数学函数和优化诗歌提示等任务上，比现有技术更稳定和高效。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted and Presented at Foundation Models for Decision Making at\n  NeurIPS 2023 (December 15, 2023). Work completed from June 2023 to September\n  2023",
      "pdf_url": "http://arxiv.org/pdf/2405.16434v2",
      "published_date": "2024-05-26 05:22:35 UTC",
      "updated_date": "2024-06-20 16:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:15:14.104899"
    },
    {
      "arxiv_id": "2405.16433v3",
      "title": "CPsyCoun: A Report-based Multi-turn Dialogue Reconstruction and Evaluation Framework for Chinese Psychological Counseling",
      "title_zh": "CPsyCoun：一个基于报告的多轮对话重构与评估框架，用于中文心理咨询",
      "authors": [
        "Chenhao Zhang",
        "Renhao Li",
        "Minghuan Tan",
        "Min Yang",
        "Jingwei Zhu",
        "Di Yang",
        "Jiahao Zhao",
        "Guancheng Ye",
        "Chengming Li",
        "Xiping Hu"
      ],
      "abstract": "Using large language models (LLMs) to assist psychological counseling is a\nsignificant but challenging task at present. Attempts have been made on\nimproving empathetic conversations or acting as effective assistants in the\ntreatment with LLMs. However, the existing datasets lack consulting knowledge,\nresulting in LLMs lacking professional consulting competence. Moreover, how to\nautomatically evaluate multi-turn dialogues within the counseling process\nremains an understudied area. To bridge the gap, we propose CPsyCoun, a\nreport-based multi-turn dialogue reconstruction and evaluation framework for\nChinese psychological counseling. To fully exploit psychological counseling\nreports, a two-phase approach is devised to construct high-quality dialogues\nwhile a comprehensive evaluation benchmark is developed for the effective\nautomatic evaluation of multi-turn psychological consultations. Competitive\nexperimental results demonstrate the effectiveness of our proposed framework in\npsychological counseling. We open-source the datasets and model for future\nresearch at https://github.com/CAS-SIAT-XinHai/CPsyCoun",
      "tldr_zh": "该论文针对使用大型语言模型 (LLMs) 辅助心理咨询的挑战，提出 CPsyCoun 框架，这是一个基于报告的多轮对话重建和评估系统，专注于中文心理咨询领域。框架采用两阶段方法从心理咨询报告中构建高质量对话，并开发了一个全面的评估基准，以自动评估多轮对话的有效性。实验结果显示，CPsyCoun 在提升 LLMs 的专业咨询能力方面表现出色，并开源了数据集和模型以支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "Appectped to Findings of ACL2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16433v3",
      "published_date": "2024-05-26 05:18:00 UTC",
      "updated_date": "2024-06-10 11:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:15:24.097189"
    },
    {
      "arxiv_id": "2405.16424v1",
      "title": "Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Min Hun Lee",
        "Silvana Xin Yi Choo",
        "Shamala D/O Thilarajah"
      ],
      "abstract": "With advanced AI/ML, there has been growing research on explainable AI (XAI)\nand studies on how humans interact with AI and XAI for effective human-AI\ncollaborative decision-making. However, we still have a lack of understanding\nof how AI systems and XAI should be first presented to users without technical\nbackgrounds. In this paper, we present the findings of semi-structured\ninterviews with health professionals (n=12) and students (n=4) majoring in\nmedicine and health to study how to improve onboarding with AI and XAI. For the\ninterviews, we built upon human-AI interaction guidelines to create onboarding\nmaterials of an AI system for stroke rehabilitation assessment and AI\nexplanations and introduce them to the participants. Our findings reveal that\nbeyond presenting traditional performance metrics on AI, participants desired\nbenchmark information, the practical benefits of AI, and interaction trials to\nbetter contextualize AI performance, and refine the objectives and performance\nof AI. Based on these findings, we highlight directions for improving\nonboarding with AI and XAI and human-AI collaborative decision-making.",
      "tldr_zh": "本文研究了如何通过AI和XAI改善健康专业人士的onboarding过程，以实现可信赖的人类-AI协作决策。研究者对12名健康专业人士和4名医学学生进行了半结构化访谈，使用基于人类-AI交互指南创建的onboarding材料，包括AI系统（针对中风康复评估）和AI解释。访谈发现，参与者不仅希望看到传统性能指标，还需要基准信息、AI的实际益处以及交互试用，以更好地 contextualize AI性能并优化其目标和效果。基于这些发现，论文提出了提升onboarding和人类-AI协作决策的潜在方向。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16424v1",
      "published_date": "2024-05-26 04:30:17 UTC",
      "updated_date": "2024-05-26 04:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:15:37.192881"
    },
    {
      "arxiv_id": "2405.16422v1",
      "title": "AI-Generated Text Detection and Classification Based on BERT Deep Learning Algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Wang",
        "Jianwei Li",
        "Zhengyu Li"
      ],
      "abstract": "AI-generated text detection plays an increasingly important role in various\nfields. In this study, we developed an efficient AI-generated text detection\nmodel based on the BERT algorithm, which provides new ideas and methods for\nsolving related problems. In the data preprocessing stage, a series of steps\nwere taken to process the text, including operations such as converting to\nlowercase, word splitting, removing stop words, stemming extraction, removing\ndigits, and eliminating redundant spaces, to ensure data quality and accuracy.\nBy dividing the dataset into a training set and a test set in the ratio of 60%\nand 40%, and observing the changes in the accuracy and loss values during the\ntraining process, we found that the model performed well during the training\nprocess. The accuracy increases steadily from the initial 94.78% to 99.72%,\nwhile the loss value decreases from 0.261 to 0.021 and converges gradually,\nwhich indicates that the BERT model is able to detect AI-generated text with\nhigh accuracy and the prediction results are gradually approaching the real\nclassification results. Further analysis of the results of the training and\ntest sets reveals that in terms of loss value, the average loss of the training\nset is 0.0565, while the average loss of the test set is 0.0917, showing a\nslightly higher loss value. As for the accuracy, the average accuracy of the\ntraining set reaches 98.1%, while the average accuracy of the test set is\n97.71%, which is not much different from each other, indicating that the model\nhas good generalisation ability. In conclusion, the AI-generated text detection\nmodel based on the BERT algorithm proposed in this study shows high accuracy\nand stability in experiments, providing an effective solution for related\nfields.",
      "tldr_zh": "本研究开发了一种基于 BERT 算法的 AI 生成文本检测和分类模型，以解决相关领域的检测需求。研究在数据预处理阶段包括文本转小写、分词、移除停用词、词干提取、删除数字和冗余空格等步骤，并将数据集按 60% 训练集和 40% 测试集比例划分。训练结果显示，模型准确率从 94.78% 稳步上升至 99.72%，损失值从 0.261 降至 0.021，且训练集平均准确率达 98.1%、测试集为 97.71%，表明模型具有高准确性和良好的泛化能力。该模型为 AI 生成文本检测提供了高效稳定的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16422v1",
      "published_date": "2024-05-26 04:26:07 UTC",
      "updated_date": "2024-05-26 04:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:15:49.553065"
    },
    {
      "arxiv_id": "2405.16421v1",
      "title": "Towards Sustainable IoT: Challenges, Solutions, and Future Directions for Device Longevity",
      "title_zh": "迈向可持续物联网：设备长寿命的挑战、解决方案和未来方向",
      "authors": [
        "Ghazaleh Shirvani",
        "Saeid Ghasemshirazi"
      ],
      "abstract": "In an era dominated by the Internet of Things, ensuring the longevity and\nsustainability of IoT devices has emerged as a pressing concern. This study\nexplores the various complex difficulties which contributed to the early\ndecommissioning of IoT devices and suggests methods to improve their lifespan\nmanagement. By examining factors such as security vulnerabilities, user\nawareness gaps, and the influence of fashion-driven technology trends, the\npaper underscores the need for legislative interventions, consumer education,\nand industry accountability. Additionally, it explores innovative approaches to\nimproving IoT longevity, including the integration of sustainability\nconsiderations into architectural design through requirements engineering\nmethodologies. Furthermore, the paper discusses the potential of distributed\nledger technology, or blockchain, to promote transparent and decentralized\nprocesses for device provisioning and tracking. This study promotes a\nsustainable IoT ecosystem by integrating technology innovation, legal change,\nand social awareness to reduce environmental impact and enhance resilience for\nthe digital future",
      "tldr_zh": "这篇论文探讨了物联网（IoT）设备的长寿命和可持续性挑战，包括安全漏洞、用户意识缺口以及时尚驱动的技术趋势等因素。论文建议通过立法干预、消费者教育和行业责任来改善设备寿命管理，并探索创新方法，如在架构设计中整合可持续性考虑（通过 requirements engineering 方法）。此外，它强调利用 blockchain 技术实现设备供应和跟踪的透明、去中心化过程，最终推动技术创新、法律变革和社会意识，以构建一个减少环境影响的可持续 IoT 生态系统。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16421v1",
      "published_date": "2024-05-26 04:05:01 UTC",
      "updated_date": "2024-05-26 04:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:16:11.183029"
    },
    {
      "arxiv_id": "2405.17503v3",
      "title": "Code Repair with LLMs gives an Exploration-Exploitation Tradeoff",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Tang",
        "Keya Hu",
        "Jin Peng Zhou",
        "Sicheng Zhong",
        "Wei-Long Zheng",
        "Xujie Si",
        "Kevin Ellis"
      ],
      "abstract": "Iteratively improving and repairing source code with large language models\n(LLMs), known as refinement, has emerged as a popular way of generating\nprograms that would be too complex to construct in one shot. Given a bank of\ntest cases, together with a candidate program, an LLM can improve that program\nby being prompted with failed test cases. But it remains an open question how\nto best iteratively refine code, with prior work employing simple greedy or\nbreadth-first strategies. We show here that refinement exposes an\nexplore-exploit tradeoff: exploit by refining the program that passes the most\ntest cases, or explore by refining a lesser considered program. We frame this\nas an arm-acquiring bandit problem, which we solve with Thompson Sampling. The\nresulting LLM-based program synthesis algorithm is broadly applicable: Across\nloop invariant synthesis, visual reasoning puzzles, and competition programming\nproblems, we find that our new method can solve more problems using fewer\nlanguage model calls.",
      "tldr_zh": "本文研究了使用大型语言模型（LLMs）进行代码修复（refinement）的过程，揭示了其中的explore-exploit tradeoff：即是优先改进通过最多测试用例的程序（exploit），还是探索较少考虑的程序（explore）。作者将这个问题建模为arm-acquiring bandit问题，并采用Thompson Sampling算法来优化迭代改进策略。实验结果显示，该方法在loop invariant synthesis、visual reasoning puzzles和competition programming problems等任务中，比现有greedy或breadth-first策略更高效，使用更少的LLM调用解决了更多问题。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.17503v3",
      "published_date": "2024-05-26 04:00:30 UTC",
      "updated_date": "2024-10-29 20:01:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:16:12.129545"
    },
    {
      "arxiv_id": "2405.16419v2",
      "title": "Enhancing Feature Diversity Boosts Channel-Adaptive Vision Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Chau Pham",
        "Bryan A. Plummer"
      ],
      "abstract": "Multi-Channel Imaging (MCI) contains an array of challenges for encoding\nuseful feature representations not present in traditional images. For example,\nimages from two different satellites may both contain RGB channels, but the\nremaining channels can be different for each imaging source. Thus, MCI models\nmust support a variety of channel configurations at test time. Recent work has\nextended traditional visual encoders for MCI, such as Vision Transformers\n(ViT), by supplementing pixel information with an encoding representing the\nchannel configuration. However, these methods treat each channel equally, i.e.,\nthey do not consider the unique properties of each channel type, which can\nresult in needless and potentially harmful redundancies in the learned\nfeatures. For example, if RGB channels are always present, the other channels\ncan focus on extracting information that cannot be captured by the RGB\nchannels. To this end, we propose DiChaViT, which aims to enhance the diversity\nin the learned features of MCI-ViT models. This is achieved through a novel\nchannel sampling strategy that encourages the selection of more distinct\nchannel sets for training. Additionally, we employ regularization and\ninitialization techniques to increase the likelihood that new information is\nlearned from each channel. Many of our improvements are architecture agnostic\nand can be incorporated into new architectures as they are developed.\nExperiments on both satellite and cell microscopy datasets, CHAMMI, JUMP-CP,\nand So2Sat, report DiChaViT yields a 1.5 - 5.0% gain over the state-of-the-art.\nOur code is publicly available at\nhttps://github.com/chaudatascience/diverse_channel_vit.",
      "tldr_zh": "该论文针对 Multi-Channel Imaging (MCI) 的通道配置多样性挑战，提出 DiChaViT 方法，以提升 Vision Transformers (ViT) 模型的特征多样性和适应性。DiChaViT 通过创新的通道采样策略、正则化和初始化技术，鼓励模型从不同通道中学习独特信息，减少冗余并优化特征表示。这些改进是架构无关的，可轻松整合到新模型中。在 CHAMMI、JUMP-CP 和 So2Sat 等卫星和细胞显微镜数据集上，DiChaViT 比最先进方法提高了 1.5% 到 5.0% 的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16419v2",
      "published_date": "2024-05-26 03:41:40 UTC",
      "updated_date": "2024-10-28 13:07:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:16:26.358019"
    },
    {
      "arxiv_id": "2405.16418v2",
      "title": "Unraveling the Smoothness Properties of Diffusion Models: A Gaussian Mixture Perspective",
      "title_zh": "揭示扩散模型的平滑性属性：高斯混合视角",
      "authors": [
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Yufa Zhou"
      ],
      "abstract": "Diffusion models have made rapid progress in generating high-quality samples\nacross various domains. However, a theoretical understanding of the Lipschitz\ncontinuity and second momentum properties of the diffusion process is still\nlacking. In this paper, we bridge this gap by providing a detailed examination\nof these smoothness properties for the case where the target data distribution\nis a mixture of Gaussians, which serves as a universal approximator for smooth\ndensities such as image data. We prove that if the target distribution is a\n$k$-mixture of Gaussians, the density of the entire diffusion process will also\nbe a $k$-mixture of Gaussians. We then derive tight upper bounds on the\nLipschitz constant and second momentum that are independent of the number of\nmixture components $k$. Finally, we apply our analysis to various diffusion\nsolvers, both SDE and ODE based, to establish concrete error guarantees in\nterms of the total variation distance and KL divergence between the target and\nlearned distributions. Our results provide deeper theoretical insights into the\ndynamics of the diffusion process under common data distributions.",
      "tldr_zh": "本论文从高斯混合物(Gaussian Mixture)视角分析了扩散模型(Diffusion Models)的平滑性属性，包括Lipschitz连续性和第二动量(second momentum)。研究证明，如果目标数据分布是k-高斯混合物，则整个扩散过程的密度也为k-高斯混合物，并导出了独立于混合成分数k的紧上界。作者将这一分析应用于SDE和ODE基于的各种扩散求解器，建立了目标分布和学习分布之间总变差(total variation distance)和KL散度(KL divergence)的具体误差保证。这些结果为扩散过程的动态提供了更深入的理论洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16418v2",
      "published_date": "2024-05-26 03:32:27 UTC",
      "updated_date": "2024-10-14 03:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:16:37.408887"
    },
    {
      "arxiv_id": "2405.17502v1",
      "title": "Exploring Nutritional Impact on Alzheimer's Mortality: An Explainable AI Approach",
      "title_zh": "探索营养对阿尔茨海默病死亡率的影响：一种可解释人工智能方法",
      "authors": [
        "Ziming Liu",
        "Longjian Liu",
        "Robert E. Heidel",
        "Xiaopeng Zhao"
      ],
      "abstract": "This article uses machine learning (ML) and explainable artificial\nintelligence (XAI) techniques to investigate the relationship between\nnutritional status and mortality rates associated with Alzheimers disease (AD).\nThe Third National Health and Nutrition Examination Survey (NHANES III)\ndatabase is employed for analysis. The random forest model is selected as the\nbase model for XAI analysis, and the Shapley Additive Explanations (SHAP)\nmethod is used to assess feature importance. The results highlight significant\nnutritional factors such as serum vitamin B12 and glycated hemoglobin. The\nstudy demonstrates the effectiveness of random forests in predicting AD\nmortality compared to other diseases. This research provides insights into the\nimpact of nutrition on AD and contributes to a deeper understanding of disease\nprogression.",
      "tldr_zh": "这篇论文使用 machine learning (ML) 和 explainable artificial intelligence (XAI) 技术，探讨营养状态对 Alzheimer’s disease (AD) 死亡率的影响，基于 Third National Health and Nutrition Examination Survey (NHANES III) 数据库进行分析。研究采用 random forest 模型作为基础，并运用 Shapley Additive Explanations (SHAP) 方法评估特征重要性，结果突出了血清维生素 B12 和糖化血红蛋白等关键营养因素。相比其他疾病，random forest 在预测 AD 死亡率方面表现出色，该研究为理解营养对 AD 进展的影响提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.17502v1",
      "published_date": "2024-05-26 03:18:47 UTC",
      "updated_date": "2024-05-26 03:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:16:50.429528"
    },
    {
      "arxiv_id": "2405.16413v1",
      "title": "Augmented Risk Prediction for the Onset of Alzheimer's Disease from Electronic Health Records with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiankun Wang",
        "Sumyeong Ahn",
        "Taykhoom Dalal",
        "Xiaodan Zhang",
        "Weishen Pan",
        "Qiannan Zhang",
        "Bin Chen",
        "Hiroko H. Dodge",
        "Fei Wang",
        "Jiayu Zhou"
      ],
      "abstract": "Alzheimer's disease (AD) is the fifth-leading cause of death among Americans\naged 65 and older. Screening and early detection of AD and related dementias\n(ADRD) are critical for timely intervention and for identifying clinical trial\nparticipants. The widespread adoption of electronic health records (EHRs)\noffers an important resource for developing ADRD screening tools such as\nmachine learning based predictive models. Recent advancements in large language\nmodels (LLMs) demonstrate their unprecedented capability of encoding knowledge\nand performing reasoning, which offers them strong potential for enhancing risk\nprediction. This paper proposes a novel pipeline that augments risk prediction\nby leveraging the few-shot inference power of LLMs to make predictions on cases\nwhere traditional supervised learning methods (SLs) may not excel.\nSpecifically, we develop a collaborative pipeline that combines SLs and LLMs\nvia a confidence-driven decision-making mechanism, leveraging the strengths of\nSLs in clear-cut cases and LLMs in more complex scenarios. We evaluate this\npipeline using a real-world EHR data warehouse from Oregon Health \\& Science\nUniversity (OHSU) Hospital, encompassing EHRs from over 2.5 million patients\nand more than 20 million patient encounters. Our results show that our proposed\napproach effectively combines the power of SLs and LLMs, offering significant\nimprovements in predictive performance. This advancement holds promise for\nrevolutionizing ADRD screening and early detection practices, with potential\nimplications for better strategies of patient management and thus improving\nhealthcare.",
      "tldr_zh": "这篇论文提出了一种增强阿尔茨海默病（AD）发病风险预测的管道，利用大型语言模型（LLMs）的少样本推理能力来补充传统监督学习方法（SLs），通过基于置信度的决策机制处理复杂案例。研究在俄勒冈健康与科学大学（OHSU）医院的真实电子健康记录（EHRs）数据上进行评估，涵盖超过250万患者和2000万就诊记录。结果显示，该方法显著提高了预测性能，有望革新AD相关痴呆（ADRD）的筛查和早检测实践，从而改善患者管理和医疗策略。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16413v1",
      "published_date": "2024-05-26 03:05:10 UTC",
      "updated_date": "2024-05-26 03:05:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:17:02.920963"
    },
    {
      "arxiv_id": "2405.16411v2",
      "title": "Tensor Attention Training: Provably Efficient Learning of Higher-order Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Yufa Zhou"
      ],
      "abstract": "Tensor Attention, a multi-view attention that is able to capture high-order\ncorrelations among multiple modalities, can overcome the representational\nlimitations of classical matrix attention. However, the $O(n^3)$ time\ncomplexity of tensor attention poses a significant obstacle to its utilization\nin transformers, where $n$ is the input sequence length. In this work, we prove\nthat the backward gradient of tensor attention training can be computed in\nalmost linear time $n^{1+o(1)}$, the same complexity as its forward computation\nunder the bounded entries assumption. We provide a closed-form solution for the\ngradient and propose a fast computation method utilizing polynomial\napproximation methods and tensor algebraic techniques. Furthermore, we prove\nthe necessity and tightness of our assumption through hardness analysis,\nshowing that slightly weakening it renders the gradient problem unsolvable in\ntruly subcubic time. Our theoretical results establish the feasibility of\nefficient higher-order transformer training and may facilitate practical\napplications of tensor attention architectures.",
      "tldr_zh": "本文提出 Tensor Attention，一种能捕捉多模态高阶相关性的多视图注意力机制，以克服经典矩阵注意力的表示局限性，但其 O(n^3) 时间复杂度阻碍了在 Transformers 中的应用。作者证明，在 bounded entries 假设下，Tensor Attention 训练的梯度可实现几乎线性时间 n^{1+o(1)} 计算，并通过闭合形式解、多项式逼近和张量代数技术提供快速计算方法。实验和硬度分析证实了该假设的必要性和紧密度，为高效的高阶 Transformer 训练的可行性和实际应用奠定了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16411v2",
      "published_date": "2024-05-26 02:59:13 UTC",
      "updated_date": "2024-10-14 04:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:17:15.621575"
    },
    {
      "arxiv_id": "2405.16409v1",
      "title": "Network Interdiction Goes Neural",
      "title_zh": "网络阻断转向神经网络",
      "authors": [
        "Lei Zhang",
        "Zhiqian Chen",
        "Chang-Tien Lu",
        "Liang Zhao"
      ],
      "abstract": "Network interdiction problems are combinatorial optimization problems\ninvolving two players: one aims to solve an optimization problem on a network,\nwhile the other seeks to modify the network to thwart the first player's\nobjectives. Such problems typically emerge in an attacker-defender context,\nencompassing areas such as military operations, disease spread analysis, and\ncommunication network management. The primary bottleneck in network\ninterdiction arises from the high time complexity of using conventional exact\nsolvers and the challenges associated with devising efficient heuristic\nsolvers. GNNs, recognized as a cutting-edge methodology, have shown significant\neffectiveness in addressing single-level CO problems on graphs, such as the\ntraveling salesman problem, graph matching, and graph edit distance.\nNevertheless, network interdiction presents a bi-level optimization challenge,\nwhich current GNNs find difficult to manage. To address this gap, we represent\nnetwork interdiction problems as Mixed-Integer Linear Programming (MILP)\ninstances, then apply a multipartite GNN with sufficient representational\ncapacity to learn these formulations. This approach ensures that our neural\nnetwork is more compatible with the mathematical algorithms designed to solve\nnetwork interdiction problems, resulting in improved generalization. Through\ntwo distinct tasks, we demonstrate that our proposed method outperforms\ntheoretical baseline models and provides advantages over traditional exact\nsolvers.",
      "tldr_zh": "该论文探讨了网络拦截(Network Interdiction)问题，这是一种双层优化问题，涉及攻击者和防御者，常见于军事、疾病传播和通信网络管理等领域，但传统求解器因计算复杂度高而效率低下。作者提出一种新方法，将问题表示为混合整数线性规划(MILP)实例，并使用多部分GNN(multipartite GNN)来学习这些公式，从而提升神经网络与数学算法的兼容性和泛化能力。通过两个具体任务的实验，该方法优于理论基线模型，并在性能上超越传统精确求解器。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16409v1",
      "published_date": "2024-05-26 02:34:26 UTC",
      "updated_date": "2024-05-26 02:34:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:17:26.740708"
    },
    {
      "arxiv_id": "2405.16406v4",
      "title": "SpinQuant: LLM quantization with learned rotations",
      "title_zh": "SpinQuant：利用学习旋转的LLM量化",
      "authors": [
        "Zechun Liu",
        "Changsheng Zhao",
        "Igor Fedorov",
        "Bilge Soran",
        "Dhruv Choudhary",
        "Raghuraman Krishnamoorthi",
        "Vikas Chandra",
        "Yuandong Tian",
        "Tijmen Blankevoort"
      ],
      "abstract": "Post-training quantization (PTQ) techniques applied to weights, activations,\nand the KV cache greatly reduce memory usage, latency, and power consumption of\nLarge Language Models (LLMs), but may lead to large quantization errors when\noutliers are present. Rotating activation or weight matrices helps remove\noutliers and benefits quantization. In this work, we identify a collection of\napplicable rotation parameterizations that lead to identical outputs in\nfull-precision Transformer architectures while enhancing quantization accuracy.\nIn addition, we find that some random rotations lead to much better\nquantization than others, with an up to 13 points difference in downstream\nzero-shot reasoning performance. As a result, we propose SpinQuant, a novel\napproach that incorporates learned rotation matrices for optimal quantized\nnetwork accuracy. With 4-bit quantization of weight, activation, and KV-cache,\nSpinQuant narrows the accuracy gap on zero-shot reasoning tasks with full\nprecision to merely 2.9 points on the LLaMA-2 7B model, surpassing LLM-QAT by\n19.1 points and SmoothQuant by 25.0 points. Furthermore, SpinQuant also\noutperforms concurrent work QuaRot, which applies random rotations to remove\noutliers. In particular, for LLaMA-3 8B models that are hard to quantize,\nSpinQuant reduces the gap to full precision by up to 45.1% relative to QuaRot.\nCode is available at https://github.com/facebookresearch/SpinQuant.",
      "tldr_zh": "该研究探讨了后训练量化 (PTQ) 在大语言模型 (LLMs) 中的应用问题，特别是异常值导致的量化错误，并提出 SpinQuant，一种通过学习旋转矩阵来移除异常值并优化权重、激活和 KV 缓存的量化方法。SpinQuant 相比随机旋转方法（如 QuaRot），在 LLaMA-2 7B 模型的 4-bit 量化下，将零样本推理任务的精度差距缩小到仅 2.9 分，优于 LLM-QAT 和 SmoothQuant。实验结果显示，对于难量化的 LLaMA-3 8B 模型，SpinQuant 相对 QuaRot 减少了高达 45.1% 的性能差距，提供开源代码以供进一步验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.16406v4",
      "published_date": "2024-05-26 02:15:49 UTC",
      "updated_date": "2025-02-20 06:07:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:17:39.289767"
    },
    {
      "arxiv_id": "2405.16405v2",
      "title": "Intruding with Words: Towards Understanding Graph Injection Attacks at the Text Level",
      "title_zh": "翻译失败",
      "authors": [
        "Runlin Lei",
        "Yuwei Hu",
        "Yuchen Ren",
        "Zhewei Wei"
      ],
      "abstract": "Graph Neural Networks (GNNs) excel across various applications but remain\nvulnerable to adversarial attacks, particularly Graph Injection Attacks (GIAs),\nwhich inject malicious nodes into the original graph and pose realistic\nthreats. Text-attributed graphs (TAGs), where nodes are associated with textual\nfeatures, are crucial due to their prevalence in real-world applications and\nare commonly used to evaluate these vulnerabilities. However, existing research\nonly focuses on embedding-level GIAs, which inject node embeddings rather than\nactual textual content, limiting their applicability and simplifying detection.\nIn this paper, we pioneer the exploration of GIAs at the text level, presenting\nthree novel attack designs that inject textual content into the graph. Through\ntheoretical and empirical analysis, we demonstrate that text interpretability,\na factor previously overlooked at the embedding level, plays a crucial role in\nattack strength. Among the designs we investigate, the Word-frequency-based\nText-level GIA (WTGIA) is particularly notable for its balance between\nperformance and interpretability. Despite the success of WTGIA, we discover\nthat defenders can easily enhance their defenses with customized text embedding\nmethods or large language model (LLM)--based predictors. These insights\nunderscore the necessity for further research into the potential and practical\nsignificance of text-level GIAs.",
      "tldr_zh": "该研究探讨了Graph Neural Networks (GNNs) 在Text-attributed graphs (TAGs) 中的Graph Injection Attacks (GIAs)，强调现有攻击仅限于embedding-level 而非实际文本注入，限制了其真实威胁。论文首次提出三种text-level GIA 设计，通过注入文本内容来增强攻击效果，并通过理论和实证分析揭示文本可解释性（text interpretability）对攻击强度的关键作用。其中，Word-frequency-based Text-level GIA (WTGIA) 表现出色，在性能和可解释性之间实现了平衡。尽管WTGIA 有效，但研究发现防御者可通过定制文本嵌入方法或large language model (LLM)-基于预测器来强化防护，呼吁进一步探究text-level GIAs 的实际意义。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.16405v2",
      "published_date": "2024-05-26 02:12:02 UTC",
      "updated_date": "2024-11-01 12:15:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:17:51.670041"
    },
    {
      "arxiv_id": "2405.16402v1",
      "title": "Assessing Empathy in Large Language Models with Real-World Physician-Patient Interactions",
      "title_zh": "通过真实世界医生-患者互动评估大语言模型中的共情",
      "authors": [
        "Man Luo",
        "Christopher J. Warren",
        "Lu Cheng",
        "Haidar M. Abdul-Muhsin",
        "Imon Banerjee"
      ],
      "abstract": "The integration of Large Language Models (LLMs) into the healthcare domain\nhas the potential to significantly enhance patient care and support through the\ndevelopment of empathetic, patient-facing chatbots. This study investigates an\nintriguing question Can ChatGPT respond with a greater degree of empathy than\nthose typically offered by physicians? To answer this question, we collect a\nde-identified dataset of patient messages and physician responses from Mayo\nClinic and generate alternative replies using ChatGPT. Our analyses incorporate\nnovel empathy ranking evaluation (EMRank) involving both automated metrics and\nhuman assessments to gauge the empathy level of responses. Our findings\nindicate that LLM-powered chatbots have the potential to surpass human\nphysicians in delivering empathetic communication, suggesting a promising\navenue for enhancing patient care and reducing professional burnout. The study\nnot only highlights the importance of empathy in patient interactions but also\nproposes a set of effective automatic empathy ranking metrics, paving the way\nfor the broader adoption of LLMs in healthcare.",
      "tldr_zh": "本研究评估大型语言模型 (LLMs) 在医疗互动中的同理心表现，探讨 ChatGPT 是否能提供比医生更具同理心的回应。研究团队从 Mayo Clinic 收集真实患者消息和医生回应，并使用 ChatGPT 生成替代回复，然后通过新型同理心排名评估 (EMRank) 结合自动化指标和人工评估进行分析。结果显示，LLM 驱动的聊天机器人可能在同理心沟通上超越人类医生，从而提升患者护理质量并减轻医疗专业人员的职业倦怠。该研究不仅强调了同理心在患者互动中的重要性，还提出了有效的自动同理心排名指标，促进 LLMs 在医疗领域的更广泛应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16402v1",
      "published_date": "2024-05-26 01:58:57 UTC",
      "updated_date": "2024-05-26 01:58:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:18:02.399836"
    },
    {
      "arxiv_id": "2405.16393v2",
      "title": "Disentangling Foreground and Background Motion for Enhanced Realism in Human Video Generation",
      "title_zh": "分离前景和背景运动以提升人类视频生成的真实性",
      "authors": [
        "Jinlin Liu",
        "Kai Yu",
        "Mengyang Feng",
        "Xiefan Guo",
        "Miaomiao Cui"
      ],
      "abstract": "Recent advancements in human video synthesis have enabled the generation of\nhigh-quality videos through the application of stable diffusion models.\nHowever, existing methods predominantly concentrate on animating solely the\nhuman element (the foreground) guided by pose information, while leaving the\nbackground entirely static. Contrary to this, in authentic, high-quality\nvideos, backgrounds often dynamically adjust in harmony with foreground\nmovements, eschewing stagnancy. We introduce a technique that concurrently\nlearns both foreground and background dynamics by segregating their movements\nusing distinct motion representations. Human figures are animated leveraging\npose-based motion, capturing intricate actions. Conversely, for backgrounds, we\nemploy sparse tracking points to model motion, thereby reflecting the natural\ninteraction between foreground activity and environmental changes. Training on\nreal-world videos enhanced with this innovative motion depiction approach, our\nmodel generates videos exhibiting coherent movement in both foreground subjects\nand their surrounding contexts. To further extend video generation to longer\nsequences without accumulating errors, we adopt a clip-by-clip generation\nstrategy, introducing global features at each step. To ensure seamless\ncontinuity across these segments, we ingeniously link the final frame of a\nproduced clip with input noise to spawn the succeeding one, maintaining\nnarrative flow. Throughout the sequential generation process, we infuse the\nfeature representation of the initial reference image into the network,\neffectively curtailing any cumulative color inconsistencies that may otherwise\narise. Empirical evaluations attest to the superiority of our method in\nproducing videos that exhibit harmonious interplay between foreground actions\nand responsive background dynamics, surpassing prior methodologies in this\nregard.",
      "tldr_zh": "本文提出了一种新方法，通过分离前景和背景运动，提升人类视频生成的真实性。现有方法仅关注基于姿势信息的前景动画，而忽略背景动态；本研究则同时学习前景（使用姿势-based motion）和背景（使用sparse tracking points）运动，确保两者和谐互动。采用clip-by-clip生成策略，并在每个步骤注入全局特征，以避免错误积累和颜色不一致。实验评估证明，该方法在真实视频合成方面优于现有技术，实现了前景动作与背景响应的无缝结合。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16393v2",
      "published_date": "2024-05-26 00:53:26 UTC",
      "updated_date": "2024-05-28 05:25:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:18:15.071165"
    },
    {
      "arxiv_id": "2405.16390v1",
      "title": "Safe and Balanced: A Framework for Constrained Multi-Objective Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shangding Gu",
        "Bilgehan Sel",
        "Yuhao Ding",
        "Lu Wang",
        "Qingwei Lin",
        "Alois Knoll",
        "Ming Jin"
      ],
      "abstract": "In numerous reinforcement learning (RL) problems involving safety-critical\nsystems, a key challenge lies in balancing multiple objectives while\nsimultaneously meeting all stringent safety constraints. To tackle this issue,\nwe propose a primal-based framework that orchestrates policy optimization\nbetween multi-objective learning and constraint adherence. Our method employs a\nnovel natural policy gradient manipulation method to optimize multiple RL\nobjectives and overcome conflicting gradients between different tasks, since\nthe simple weighted average gradient direction may not be beneficial for\nspecific tasks' performance due to misaligned gradients of different task\nobjectives. When there is a violation of a hard constraint, our algorithm steps\nin to rectify the policy to minimize this violation. We establish theoretical\nconvergence and constraint violation guarantees in a tabular setting.\nEmpirically, our proposed method also outperforms prior state-of-the-art\nmethods on challenging safe multi-objective reinforcement learning tasks.",
      "tldr_zh": "这篇论文提出了一种名为 Safe and Balanced 的框架，用于处理强化学习（Reinforcement Learning, RL）中多目标优化与严格安全约束的平衡问题。该框架采用 novel natural policy gradient manipulation 方法来优化多个 RL 目标，解决不同任务间梯度冲突，确保策略不会因简单加权平均而影响特定任务性能；同时，当硬约束被违反时，算法会自动修正策略以最小化违反。理论上，该方法在表格设置中证明了收敛性和约束违反保证；实验结果显示，它在 challenging 的安全多目标 RL 任务中超过了现有最先进方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.16390v1",
      "published_date": "2024-05-26 00:42:10 UTC",
      "updated_date": "2024-05-26 00:42:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:18:27.847926"
    },
    {
      "arxiv_id": "2405.16386v3",
      "title": "Variational Offline Multi-agent Skill Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayu Chen",
        "Tian Lan",
        "Vaneet Aggarwal"
      ],
      "abstract": "Skills are effective temporal abstractions established for sequential\ndecision making, which enable efficient hierarchical learning for long-horizon\ntasks and facilitate multi-task learning through their transferability. Despite\nextensive research, research gaps remain in multi-agent scenarios, particularly\nfor automatically extracting subgroup coordination patterns in a multi-agent\ntask. In this case, we propose two novel auto-encoder schemes: VO-MASD-3D and\nVO-MASD-Hier, to simultaneously capture subgroup- and temporal-level\nabstractions and form multi-agent skills, which firstly solves the\naforementioned challenge. An essential algorithm component of these schemes is\na dynamic grouping function that can automatically detect latent subgroups\nbased on agent interactions in a task. Further, our method can be applied to\noffline multi-task data, and the discovered subgroup skills can be transferred\nacross relevant tasks without retraining. Empirical evaluations on StarCraft\ntasks indicate that our approach significantly outperforms existing\nhierarchical multi-agent reinforcement learning (MARL) methods. Moreover,\nskills discovered using our method can effectively reduce the learning\ndifficulty in MARL scenarios with delayed and sparse reward signals. The\ncodebase is available at https://github.com/LucasCJYSDL/VOMASD.",
      "tldr_zh": "该论文提出了一种变分离线多智能体技能发现方法（Variational Offline Multi-agent Skill Discovery），旨在自动提取多智能体任务中的子群协调模式，以提升分层学习效率。研究引入了两个新颖的 auto-encoder 方案——VO-MASD-3D 和 VO-MASD-Hier——这些方案通过动态分组函数同时捕获子群级和时间级抽象，形成可转移的技能，并在离线多任务数据上实现无需重新训练的转移。实验结果显示，该方法在 StarCraft 任务中显著优于现有分层多智能体强化学习 (MARL) 方法，并有效降低了延迟和稀疏奖励信号下的学习难度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This work will appear in the proceedings of IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.16386v3",
      "published_date": "2024-05-26 00:24:46 UTC",
      "updated_date": "2025-04-30 16:48:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T12:18:39.307566"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 69,
  "processed_papers_count": 69,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T12:19:01.600558"
}