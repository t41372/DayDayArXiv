[
  {
    "arxiv_id": "2410.14086v3",
    "title": "In-context learning and Occam's razor",
    "authors": [
      "Eric Elmoznino",
      "Tom Marty",
      "Tejas Kasetty",
      "Leo Gagnon",
      "Sarthak Mittal",
      "Mahan Fathi",
      "Dhanya Sridhar",
      "Guillaume Lajoie"
    ],
    "abstract": "A central goal of machine learning is generalization. While the No Free Lunch\nTheorem states that we cannot obtain theoretical guarantees for generalization\nwithout further assumptions, in practice we observe that simple models which\nexplain the training data generalize best: a principle called Occam's razor.\nDespite the need for simple models, most current approaches in machine learning\nonly minimize the training error, and at best indirectly promote simplicity\nthrough regularization or architecture design. Here, we draw a connection\nbetween Occam's razor and in-context learning: an emergent ability of certain\nsequence models like Transformers to learn at inference time from past\nobservations in a sequence. In particular, we show that the next-token\nprediction loss used to train in-context learners is directly equivalent to a\ndata compression technique called prequential coding, and that minimizing this\nloss amounts to jointly minimizing both the training error and the complexity\nof the model that was implicitly learned from context. Our theory and the\nempirical experiments we use to support it not only provide a normative account\nof in-context learning, but also elucidate the shortcomings of current\nin-context learning methods, suggesting ways in which they can be improved. We\nmake our code available at https://github.com/3rdCore/PrequentialCode.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14086v3",
    "published_date": "2024-10-17 23:37:34 UTC",
    "updated_date": "2025-01-31 06:05:18 UTC"
  },
  {
    "arxiv_id": "2410.14082v1",
    "title": "Interpreting Inflammation Prediction Model via Tag-based Cohort Explanation",
    "authors": [
      "Fanyu Meng",
      "Jules Larke",
      "Xin Liu",
      "Zhaodan Kong",
      "Xin Chen",
      "Danielle Lemay",
      "Ilias Tagkopoulos"
    ],
    "abstract": "Machine learning is revolutionizing nutrition science by enabling systems to\nlearn from data and make intelligent decisions. However, the complexity of\nthese models often leads to challenges in understanding their decision-making\nprocesses, necessitating the development of explainability techniques to foster\ntrust and increase model transparency. An under-explored type of explanation is\ncohort explanation, which provides explanations to groups of instances with\nsimilar characteristics. Unlike traditional methods that focus on individual\nexplanations or global model behavior, cohort explainability bridges the gap by\nproviding unique insights at an intermediate granularity. We propose a novel\nframework for identifying cohorts within a dataset based on local feature\nimportance scores, aiming to generate concise descriptions of the clusters via\ntags. We evaluate our framework on a food-based inflammation prediction model\nand demonstrated that the framework can generate reliable explanations that\nmatch domain knowledge.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14082v1",
    "published_date": "2024-10-17 23:22:59 UTC",
    "updated_date": "2024-10-17 23:22:59 UTC"
  },
  {
    "arxiv_id": "2410.14072v1",
    "title": "Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers",
    "authors": [
      "Yuxin Wen",
      "Qingqing Cao",
      "Qichen Fu",
      "Sachin Mehta",
      "Mahyar Najibi"
    ],
    "abstract": "Recent advancements in vision-language models (VLMs) have expanded their\npotential for real-world applications, enabling these models to perform complex\nreasoning on images. In the widely used fully autoregressive transformer-based\nmodels like LLaVA, projected visual tokens are prepended to textual tokens.\nOftentimes, visual tokens are significantly more than prompt tokens, resulting\nin increased computational overhead during both training and inference. In this\npaper, we propose Visual Compact Token Registers (Victor), a method that\nreduces the number of visual tokens by summarizing them into a smaller set of\nregister tokens. Victor adds a few learnable register tokens after the visual\ntokens and summarizes the visual information into these registers using the\nfirst few layers in the language tower of VLMs. After these few layers, all\nvisual tokens are discarded, significantly improving computational efficiency\nfor both training and inference. Notably, our method is easy to implement and\nrequires a small number of new trainable parameters with minimal impact on\nmodel performance. In our experiment, with merely 8 visual registers--about 1%\nof the original tokens--Victor shows less than a 4% accuracy drop while\nreducing the total training time by 43% and boosting the inference throughput\nby 3.3X.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14072v1",
    "published_date": "2024-10-17 22:45:13 UTC",
    "updated_date": "2024-10-17 22:45:13 UTC"
  },
  {
    "arxiv_id": "2410.14070v1",
    "title": "FaceSaliencyAug: Mitigating Geographic, Gender and Stereotypical Biases via Saliency-Based Data Augmentation",
    "authors": [
      "Teerath Kumar",
      "Alessandra Mileo",
      "Malika Bendechache"
    ],
    "abstract": "Geographical, gender and stereotypical biases in computer vision models pose\nsignificant challenges to their performance and fairness. {In this study, we\npresent an approach named FaceSaliencyAug aimed at addressing the gender bias\nin} {Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs).\nLeveraging the salient regions} { of faces detected by saliency, the propose\napproach mitigates geographical and stereotypical biases } {in the datasets.\nFaceSaliencyAug} randomly selects masks from a predefined search space and\napplies them to the salient region of face images, subsequently restoring the\noriginal image with masked salient region. {The proposed} augmentation strategy\nenhances data diversity, thereby improving model performance and debiasing\neffects. We quantify dataset diversity using Image Similarity Score (ISS)\nacross five datasets, including Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled\nFaces in the Wild (LFW), UTK Faces, and Diverse Dataset. The proposed approach\ndemonstrates superior diversity metrics, as evaluated by ISS-intra and\nISS-inter algorithms. Furthermore, we evaluate the effectiveness of our\napproach in mitigating gender bias on CEO, Engineer, Nurse, and School Teacher\ndatasets. We use the Image-Image Association Score (IIAS) to measure gender\nbias in these occupations. Our experiments reveal a reduction in gender bias\nfor both CNNs and ViTs, indicating the efficacy of our method in promoting\nfairness and inclusivity in computer vision models.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at Image Signal and Video processing",
    "pdf_url": "http://arxiv.org/pdf/2410.14070v1",
    "published_date": "2024-10-17 22:36:52 UTC",
    "updated_date": "2024-10-17 22:36:52 UTC"
  },
  {
    "arxiv_id": "2410.14067v2",
    "title": "Provable Benefits of Complex Parameterizations for Structured State Space Models",
    "authors": [
      "Yuval Ran-Milo",
      "Eden Lumbroso",
      "Edo Cohen-Karlik",
      "Raja Giryes",
      "Amir Globerson",
      "Nadav Cohen"
    ],
    "abstract": "Structured state space models (SSMs), the core engine behind prominent neural\nnetworks such as S4 and Mamba, are linear dynamical systems adhering to a\nspecified structure, most notably diagonal. In contrast to typical neural\nnetwork modules, whose parameterizations are real, SSMs often use complex\nparameterizations. Theoretically explaining the benefits of complex\nparameterizations for SSMs is an open problem. The current paper takes a step\ntowards its resolution, by establishing formal gaps between real and complex\ndiagonal SSMs. Firstly, we prove that while a moderate dimension suffices in\norder for a complex SSM to express all mappings of a real SSM, a much higher\ndimension is needed for a real SSM to express mappings of a complex SSM.\nSecondly, we prove that even if the dimension of a real SSM is high enough to\nexpress a given mapping, typically, doing so requires the parameters of the\nreal SSM to hold exponentially large values, which cannot be learned in\npractice. In contrast, a complex SSM can express any given mapping with\nmoderate parameter values. Experiments corroborate our theory, and suggest a\npotential extension of the theory that accounts for selectivity, a new\narchitectural feature yielding state of the art performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages. Accepted to NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.14067v2",
    "published_date": "2024-10-17 22:35:50 UTC",
    "updated_date": "2024-10-31 10:38:47 UTC"
  },
  {
    "arxiv_id": "2410.14060v1",
    "title": "On Partial Prototype Collapse in the DINO Family of Self-Supervised Methods",
    "authors": [
      "Hariprasath Govindarajan",
      "Per Sidén",
      "Jacob Roll",
      "Fredrik Lindsten"
    ],
    "abstract": "A prominent self-supervised learning paradigm is to model the representations\nas clusters, or more generally as a mixture model. Learning to map the data\nsamples to compact representations and fitting the mixture model simultaneously\nleads to the representation collapse problem. Regularizing the distribution of\ndata points over the clusters is the prevalent strategy to avoid this issue.\nWhile this is sufficient to prevent full representation collapse, we show that\na partial prototype collapse problem still exists in the DINO family of\nmethods, that leads to significant redundancies in the prototypes. Such\nprototype redundancies serve as shortcuts for the method to achieve a marginal\nlatent class distribution that matches the prescribed prior. We show that by\nencouraging the model to use diverse prototypes, the partial prototype collapse\ncan be mitigated. Effective utilization of the prototypes enables the methods\nto learn more fine-grained clusters, encouraging more informative\nrepresentations. We demonstrate that this is especially beneficial when\npre-training on a long-tailed fine-grained dataset.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "First version of the paper appeared in OpenReview on 22 Sep 2023.\n  Accepted to BMVC 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.14060v1",
    "published_date": "2024-10-17 22:06:34 UTC",
    "updated_date": "2024-10-17 22:06:34 UTC"
  },
  {
    "arxiv_id": "2410.16322v1",
    "title": "SouLLMate: An Application Enhancing Diverse Mental Health Support with Adaptive LLMs, Prompt Engineering, and RAG Techniques",
    "authors": [
      "Qiming Guo",
      "Jinwen Tang",
      "Wenbo Sun",
      "Haoteng Tang",
      "Yi Shang",
      "Wenlu Wang"
    ],
    "abstract": "Mental health issues significantly impact individuals' daily lives, yet many\ndo not receive the help they need even with available online resources. This\nstudy aims to provide diverse, accessible, stigma-free, personalized, and\nreal-time mental health support through cutting-edge AI technologies. It makes\nthe following contributions: (1) Conducting an extensive survey of recent\nmental health support methods to identify prevalent functionalities and unmet\nneeds. (2) Introducing SouLLMate, an adaptive LLM-driven system that integrates\nLLM technologies, Chain, Retrieval-Augmented Generation (RAG), prompt\nengineering, and domain knowledge. This system offers advanced features such as\nRisk Detection and Proactive Guidance Dialogue, and utilizes RAG for\npersonalized profile uploads and Conversational Information Extraction. (3)\nDeveloping novel evaluation approaches for preliminary assessments and risk\ndetection via professionally annotated interview data and real-life suicide\ntendency data. (4) Proposing the Key Indicator Summarization (KIS), Proactive\nQuestioning Strategy (PQS), and Stacked Multi-Model Reasoning (SMMR) methods to\nenhance model performance and usability through context-sensitive response\nadjustments, semantic coherence evaluations, and enhanced accuracy of\nlong-context reasoning in language models. This study contributes to advancing\nmental health support technologies, potentially improving the accessibility and\neffectiveness of mental health care globally.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 19 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.16322v1",
    "published_date": "2024-10-17 22:04:32 UTC",
    "updated_date": "2024-10-17 22:04:32 UTC"
  },
  {
    "arxiv_id": "2410.20718v1",
    "title": "Lecture II: Communicative Justice and the Distribution of Attention",
    "authors": [
      "Seth Lazar"
    ],
    "abstract": "Algorithmic intermediaries govern the digital public sphere through their\narchitectures, amplification algorithms, and moderation practices. In doing so,\nthey shape public communication and distribute attention in ways that were\npreviously infeasible with such subtlety, speed and scale. From misinformation\nand affective polarisation to hate speech and radicalisation, the many\npathologies of the digital public sphere attest that they could do so better.\nBut what ideals should they aim at? Political philosophy should be able to\nhelp, but existing theories typically assume that a healthy public sphere will\nspontaneously emerge if only we get the boundaries of free expression right.\nThey offer little guidance on how to intentionally constitute the digital\npublic sphere. In addition to these theories focused on expression, we need a\nfurther theory of communicative justice, targeted specifically at the\nalgorithmic intermediaries that shape communication and distribute attention.\nThis lecture argues that political philosophy urgently owes an account of how\nto govern communication in the digital public sphere, and introduces and\ndefends a democratic egalitarian theory of communicative justice.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20718v1",
    "published_date": "2024-10-17 22:03:35 UTC",
    "updated_date": "2024-10-17 22:03:35 UTC"
  },
  {
    "arxiv_id": "2410.20720v1",
    "title": "Lecture I: Governing the Algorithmic City",
    "authors": [
      "Seth Lazar"
    ],
    "abstract": "A century ago, John Dewey observed that '[s]team and electricity have done\nmore to alter the conditions under which men associate together than all the\nagencies which affected human relationships before our time'. In the last few\ndecades, computing technologies have had a similar effect. Political\nphilosophy's central task is to help us decide how to live together, by\nanalysing our social relations, diagnosing their failings, and articulating\nideals to guide their revision. But these profound social changes have left\nscarcely a dent in the model of social relations that (analytical) political\nphilosophers assume. This essay aims to reverse that trend. It first builds a\nmodel of our novel social relations as they are now, and as they are likely to\nevolved, and then explores how those differences affect our theories of how to\nlive together. I introduce the 'Algorithmic City', the network of\nalgorithmically-mediated social relations, then characterise the intermediary\npower by which it is governed. I show how algorithmic governance raises new\nchallenges for political philosophy concerning the justification of authority,\nthe foundations of procedural legitimacy, and the possibility of justificatory\nneutrality.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.20720v1",
    "published_date": "2024-10-17 22:02:06 UTC",
    "updated_date": "2024-10-17 22:02:06 UTC"
  },
  {
    "arxiv_id": "2410.14057v1",
    "title": "Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs",
    "authors": [
      "Simone Conia",
      "Daniel Lee",
      "Min Li",
      "Umar Farooq Minhas",
      "Saloni Potdar",
      "Yunyao Li"
    ],
    "abstract": "Translating text that contains entity names is a challenging task, as\ncultural-related references can vary significantly across languages. These\nvariations may also be caused by transcreation, an adaptation process that\nentails more than transliteration and word-for-word translation. In this paper,\nwe address the problem of cross-cultural translation on two fronts: (i) we\nintroduce XC-Translate, the first large-scale, manually-created benchmark for\nmachine translation that focuses on text that contains potentially\nculturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end\nmethod to integrate information from a multilingual knowledge graph into a\nneural machine translation model by leveraging a dense retrieval mechanism. Our\nexperiments and analyses show that current machine translation systems and\nlarge language models still struggle to translate texts containing entity\nnames, whereas KG-MT outperforms state-of-the-art approaches by a large margin,\nobtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,\nrespectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.14057v1",
    "published_date": "2024-10-17 21:56:22 UTC",
    "updated_date": "2024-10-17 21:56:22 UTC"
  },
  {
    "arxiv_id": "2410.14052v3",
    "title": "From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs",
    "authors": [
      "Alireza Rezazadeh",
      "Zichao Li",
      "Wei Wei",
      "Yujia Bao"
    ],
    "abstract": "Recent advancements in large language models have significantly improved\ntheir context windows, yet challenges in effective long-term memory management\nremain. We introduce MemTree, an algorithm that leverages a dynamic,\ntree-structured memory representation to optimize the organization, retrieval,\nand integration of information, akin to human cognitive schemas. MemTree\norganizes memory hierarchically, with each node encapsulating aggregated\ntextual content, corresponding semantic embeddings, and varying abstraction\nlevels across the tree's depths. Our algorithm dynamically adapts this memory\nstructure by computing and comparing semantic embeddings of new and existing\ninformation to enrich the model's context-awareness. This approach allows\nMemTree to handle complex reasoning and extended interactions more effectively\nthan traditional memory augmentation methods, which often rely on flat lookup\ntables. Evaluations on benchmarks for multi-turn dialogue understanding and\ndocument question answering show that MemTree significantly enhances\nperformance in scenarios that demand structured memory management.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14052v3",
    "published_date": "2024-10-17 21:47:11 UTC",
    "updated_date": "2025-03-19 21:18:02 UTC"
  },
  {
    "arxiv_id": "2410.14044v1",
    "title": "Best in Tau@LLMJudge: Criteria-Based Relevance Evaluation with Llama3",
    "authors": [
      "Naghmeh Farzi",
      "Laura Dietz"
    ],
    "abstract": "Traditional evaluation of information retrieval (IR) systems relies on\nhuman-annotated relevance labels, which can be both biased and costly at scale.\nIn this context, large language models (LLMs) offer an alternative by allowing\nus to directly prompt them to assign relevance labels for passages associated\nwith each query. In this study, we explore alternative methods to directly\nprompt LLMs for assigned relevance labels, by exploring two hypotheses:\n  Hypothesis 1 assumes that it is helpful to break down \"relevance\" into\nspecific criteria - exactness, coverage, topicality, and contextual fit. We\nexplore different approaches that prompt large language models (LLMs) to obtain\ncriteria-level grades for all passages, and we consider various ways to\naggregate criteria-level grades into a relevance label. Hypothesis 2 assumes\nthat differences in linguistic style between queries and passages may\nnegatively impact the automatic relevance label prediction. We explore whether\nimprovements can be achieved by first synthesizing a summary of the passage in\nthe linguistic style of a query, and then using this summary in place of the\npassage to assess its relevance.\n  We include an empirical evaluation of our approaches based on data from the\nLLMJudge challenge run in Summer 2024, where our \"Four Prompts\" approach\nobtained the highest scores in Kendall's tau.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "H.3.3"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14044v1",
    "published_date": "2024-10-17 21:37:08 UTC",
    "updated_date": "2024-10-17 21:37:08 UTC"
  },
  {
    "arxiv_id": "2410.14040v1",
    "title": "Latent Weight Diffusion: Generating Policies from Trajectories",
    "authors": [
      "Shashank Hegde",
      "Gautam Salhotra",
      "Gaurav S. Sukhatme"
    ],
    "abstract": "With the increasing availability of open-source robotic data, imitation\nlearning has emerged as a viable approach for both robot manipulation and\nlocomotion. Currently, large generalized policies are trained to predict\ncontrols or trajectories using diffusion models, which have the desirable\nproperty of learning multimodal action distributions. However, generalizability\ncomes with a cost - namely, larger model size and slower inference. Further,\nthere is a known trade-off between performance and action horizon for Diffusion\nPolicy (i.e., diffusing trajectories): fewer diffusion queries accumulate\ngreater trajectory tracking errors. Thus, it is common practice to run these\nmodels at high inference frequency, subject to robot computational constraints.\n  To address these limitations, we propose Latent Weight Diffusion (LWD), a\nmethod that uses diffusion to learn a distribution over policies for robotic\ntasks, rather than over trajectories. Our approach encodes demonstration\ntrajectories into a latent space and then decodes them into policies using a\nhypernetwork. We employ a diffusion denoising model within this latent space to\nlearn its distribution. We demonstrate that LWD can reconstruct the behaviors\nof the original policies that generated the trajectory dataset. LWD offers the\nbenefits of considerably smaller policy networks during inference and requires\nfewer diffusion model queries. When tested on the Metaworld MT10 benchmark, LWD\nachieves a higher success rate compared to a vanilla multi-task policy, while\nusing models up to ~18x smaller during inference. Additionally, since LWD\ngenerates closed-loop policies, we show that it outperforms Diffusion Policy in\nlong action horizon settings, with reduced diffusion queries during rollout.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14040v1",
    "published_date": "2024-10-17 21:30:29 UTC",
    "updated_date": "2024-10-17 21:30:29 UTC"
  },
  {
    "arxiv_id": "2410.14026v1",
    "title": "Generating Signed Language Instructions in Large-Scale Dialogue Systems",
    "authors": [
      "Mert İnan",
      "Katherine Atwell",
      "Anthony Sicilia",
      "Lorna Quandt",
      "Malihe Alikhani"
    ],
    "abstract": "We introduce a goal-oriented conversational AI system enhanced with American\nSign Language (ASL) instructions, presenting the first implementation of such a\nsystem on a worldwide multimodal conversational AI platform. Accessible through\na touch-based interface, our system receives input from users and seamlessly\ngenerates ASL instructions by leveraging retrieval methods and cognitively\nbased gloss translations. Central to our design is a sign translation module\npowered by Large Language Models, alongside a token-based video retrieval\nsystem for delivering instructional content from recipes and wikiHow guides.\nOur development process is deeply rooted in a commitment to community\nengagement, incorporating insights from the Deaf and Hard-of-Hearing community,\nas well as experts in cognitive and ASL learning sciences. The effectiveness of\nour signing instructions is validated by user feedback, achieving ratings on\npar with those of the system in its non-signing variant. Additionally, our\nsystem demonstrates exceptional performance in retrieval accuracy and\ntext-generation quality, measured by metrics such as BERTScore. We have made\nour codebase and datasets publicly accessible at\nhttps://github.com/Merterm/signed-dialogue, and a demo of our signed\ninstruction video retrieval system is available at\nhttps://huggingface.co/spaces/merterm/signed-instructions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "2024 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL 2024) Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2410.14026v1",
    "published_date": "2024-10-17 20:56:29 UTC",
    "updated_date": "2024-10-17 20:56:29 UTC"
  },
  {
    "arxiv_id": "2410.14024v1",
    "title": "Ensemble-based, large-eddy reconstruction of wind turbine inflow in a near-stationary atmospheric boundary layer through generative artificial intelligence",
    "authors": [
      "Alex Rybchuk",
      "Luis A. Martínez-Tossas",
      "Stefano Letizia",
      "Nicholas Hamilton",
      "Andy Scholbrock",
      "Emina Maric",
      "Daniel R. Houck",
      "Thomas G. Herges",
      "Nathaniel B. de Velder",
      "Paula Doubrawa"
    ],
    "abstract": "To validate the second-by-second dynamics of turbines in field experiments,\nit is necessary to accurately reconstruct the winds going into the turbine.\nCurrent time-resolved inflow reconstruction techniques estimate wind behavior\nin unobserved regions using relatively simple spectral-based models of the\natmosphere. Here, we develop a technique for time-resolved inflow\nreconstruction that is rooted in a large-eddy simulation model of the\natmosphere. Our \"large-eddy reconstruction\" technique blends observations and\natmospheric model information through a diffusion model machine learning\nalgorithm, allowing us to generate probabilistic ensembles of reconstructions\nfor a single 10-min observational period. Our generated inflows can be used\ndirectly by aeroelastic codes or as inflow boundary conditions in a large-eddy\nsimulation. We verify the second-by-second reconstruction capability of our\ntechnique in three synthetic field campaigns, finding positive Pearson\ncorrelation coefficient values (0.20>r>0.85) between ground-truth and\nreconstructed streamwise velocity, as well as smaller positive correlation\ncoefficient values for unobserved fields (spanwise velocity, vertical velocity,\nand temperature). We validate our technique in three real-world case studies by\ndriving large-eddy simulations with reconstructed inflows and comparing to\nindependent inflow measurements. The reconstructions are visually similar to\nmeasurements, follow desired power spectra properties, and track\nsecond-by-second behavior (0.25 > r > 0.75).",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "30 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.14024v1",
    "published_date": "2024-10-17 20:53:04 UTC",
    "updated_date": "2024-10-17 20:53:04 UTC"
  },
  {
    "arxiv_id": "2410.14022v1",
    "title": "Vision-Language-Action Model and Diffusion Policy Switching Enables Dexterous Control of an Anthropomorphic Hand",
    "authors": [
      "Cheng Pan",
      "Kai Junge",
      "Josie Hughes"
    ],
    "abstract": "To advance autonomous dexterous manipulation, we propose a hybrid control\nmethod that combines the relative advantages of a fine-tuned\nVision-Language-Action (VLA) model and diffusion models. The VLA model provides\nlanguage commanded high-level planning, which is highly generalizable, while\nthe diffusion model handles low-level interactions which offers the precision\nand robustness required for specific objects and environments. By incorporating\na switching signal into the training-data, we enable event based transitions\nbetween these two models for a pick-and-place task where the target object and\nplacement location is commanded through language. This approach is deployed on\nour anthropomorphic ADAPT Hand 2, a 13DoF robotic hand, which incorporates\ncompliance through series elastic actuation allowing for resilience for any\ninteractions: showing the first use of a multi-fingered hand controlled with a\nVLA model. We demonstrate this model switching approach results in a over 80\\%\nsuccess rate compared to under 40\\% when only using a VLA model, enabled by\naccurate near-object arm motion by the VLA model and a multi-modal grasping\nmotion with error recovery abilities from the diffusion model.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14022v1",
    "published_date": "2024-10-17 20:49:45 UTC",
    "updated_date": "2024-10-17 20:49:45 UTC"
  },
  {
    "arxiv_id": "2410.14005v1",
    "title": "Whisker-Inspired Tactile Sensing: A Sim2Real Approach for Precise Underwater Contact Tracking",
    "authors": [
      "Hao Li",
      "Chengyi Xing",
      "Saad Khan",
      "Miaoya Zhong",
      "Mark R. Cutkosky"
    ],
    "abstract": "Aquatic mammals, such as pinnipeds, utilize their whiskers to detect and\ndiscriminate objects and analyze water movements, inspiring the development of\nrobotic whiskers for sensing contacts, surfaces, and water flows. We present\nthe design and application of underwater whisker sensors based on Fiber Bragg\nGrating (FBG) technology. These passive whiskers are mounted along the\nrobot$'$s exterior to sense its surroundings through light, non-intrusive\ncontacts. For contact tracking, we employ a sim-to-real learning framework,\nwhich involves extensive data collection in simulation followed by a\nsim-to-real calibration process to transfer the model trained in simulation to\nthe real world. Experiments with whiskers immersed in water indicate that our\napproach can track contact points with an accuracy of $<2$ mm, without\nrequiring precise robot proprioception. We demonstrate that the approach also\ngeneralizes to unseen objects.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14005v1",
    "published_date": "2024-10-17 20:19:01 UTC",
    "updated_date": "2024-10-17 20:19:01 UTC"
  },
  {
    "arxiv_id": "2410.14748v3",
    "title": "ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries",
    "authors": [
      "Kishan Maharaj",
      "Vitobha Munigala",
      "Srikanth G. Tamilselvam",
      "Prince Kumar",
      "Sayandeep Sen",
      "Palani Kodeswaran",
      "Abhijit Mishra",
      "Pushpak Bhattacharyya"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced their ability to understand both natural language and code, driving\ntheir use in tasks like natural language-to-code (NL2Code) and code\nsummarization. However, LLMs are prone to hallucination-outputs that stray from\nintended meanings. Detecting hallucinations in code summarization is especially\ndifficult due to the complex interplay between programming and natural\nlanguages. We introduce a first-of-its-kind dataset with $\\sim$10K samples,\ncurated specifically for hallucination detection in code summarization. We\nfurther propose a novel Entity Tracing Framework (ETF) that a) utilizes static\nprogram analysis to identify code entities from the program and b) uses LLMs to\nmap and verify these entities and their intents within generated code\nsummaries. Our experimental analysis demonstrates the effectiveness of the\nframework, leading to a 0.73 F1 score. This approach provides an interpretable\nmethod for detecting hallucinations by grounding entities, allowing us to\nevaluate summary accuracy.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "11 pages, 6 Figures, 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2410.14748v3",
    "published_date": "2024-10-17 19:38:55 UTC",
    "updated_date": "2024-12-18 23:36:03 UTC"
  },
  {
    "arxiv_id": "2410.13981v2",
    "title": "On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery",
    "authors": [
      "Renpu Liu",
      "Ruida Zhou",
      "Cong Shen",
      "Jing Yang"
    ],
    "abstract": "An intriguing property of the Transformer is its ability to perform\nin-context learning (ICL), where the Transformer can solve different inference\ntasks without parameter updating based on the contextual information provided\nby the corresponding input-output demonstration pairs. It has been\ntheoretically proved that ICL is enabled by the capability of Transformers to\nperform gradient-descent algorithms (Von Oswald et al., 2023a; Bai et al.,\n2024). This work takes a step further and shows that Transformers can perform\nlearning-to-optimize (L2O) algorithms. Specifically, for the ICL sparse\nrecovery (formulated as LASSO) tasks, we show that a K-layer Transformer can\nperform an L2O algorithm with a provable convergence rate linear in K. This\nprovides a new perspective explaining the superior ICL capability of\nTransformers, even with only a few layers, which cannot be achieved by the\nstandard gradient-descent algorithms. Moreover, unlike the conventional L2O\nalgorithms that require the measurement matrix involved in training to match\nthat in testing, the trained Transformer is able to solve sparse recovery\nproblems generated with different measurement matrices. Besides, Transformers\nas an L2O algorithm can leverage structural information embedded in the\ntraining tasks to accelerate its convergence during ICL, and generalize across\ndifferent lengths of demonstration pairs, where conventional L2O algorithms\ntypically struggle or fail. Such theoretical findings are supported by our\nexperimental results.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13981v2",
    "published_date": "2024-10-17 19:18:28 UTC",
    "updated_date": "2025-03-12 05:09:21 UTC"
  },
  {
    "arxiv_id": "2410.13979v2",
    "title": "RecoveryChaining: Learning Local Recovery Policies for Robust Manipulation",
    "authors": [
      "Shivam Vats",
      "Devesh K. Jha",
      "Maxim Likhachev",
      "Oliver Kroemer",
      "Diego Romeres"
    ],
    "abstract": "Model-based planners and controllers are commonly used to solve complex\nmanipulation problems as they can efficiently optimize diverse objectives and\ngeneralize to long horizon tasks. However, they often fail during deployment\ndue to noisy actuation, partial observability and imperfect models. To enable a\nrobot to recover from such failures, we propose to use hierarchical\nreinforcement learning to learn a recovery policy. The recovery policy is\ntriggered when a failure is detected based on sensory observations and seeks to\ntake the robot to a state from which it can complete the task using the nominal\nmodel-based controllers. Our approach, called RecoveryChaining, uses a hybrid\naction space, where the model-based controllers are provided as additional\n\\emph{nominal} options which allows the recovery policy to decide how to\nrecover, when to switch to a nominal controller and which controller to switch\nto even with \\emph{sparse rewards}. We evaluate our approach in three\nmulti-step manipulation tasks with sparse rewards, where it learns\nsignificantly more robust recovery policies than those learned by baselines. We\nsuccessfully transfer recovery policies learned in simulation to a physical\nrobot to demonstrate the feasibility of sim-to-real transfer with our method.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Added Lazy RecoveryChaining algorithm. 8 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13979v2",
    "published_date": "2024-10-17 19:14:43 UTC",
    "updated_date": "2025-03-07 05:39:48 UTC"
  },
  {
    "arxiv_id": "2410.13973v3",
    "title": "MarineFormer: A Spatio-Temporal Attention Model for USV Navigation in Dynamic Marine Environments",
    "authors": [
      "Ehsan Kazemi",
      "Iman Soltani"
    ],
    "abstract": "Navigating autonomously in marine environments including dynamic and static\nobstacles, and strong flow disturbances, such as in high-flow rivers, poses\nsignificant challenges for USVs. To address these challenges, we propose a\nnovel methodology that leverages two types of attention: spatial attention,\nwhich learns to integrate diverse environmental factors and sensory information\ninto navigation decisions, and temporal attention within a transformer\nframework to account for the dynamic, continuously changing nature of the\nenvironment. We devise MarineFormer, a Trans${\\bf \\text{former}}$-based\nnavigation policy for dynamic ${\\bf \\text{Marine}}$ environments, trained\nend-to-end through reinforcement learning (RL). At its core, MarineFormer uses\ngraph attention to capture spatial information and a transformer architecture\nto process temporal sequences in an environment that simulates a 2D turbulent\nmarine condition involving multiple static and dynamic obstacles. We\nextensively evaluate the performance of the proposed method versus the\nstate-of-the-art methods, as well as other classical planners. Our approach\noutperforms the state-of-the-art by nearly $20\\%$ in episode completion success\nrate and additionally enhances the USV's path length efficiency.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13973v3",
    "published_date": "2024-10-17 18:57:15 UTC",
    "updated_date": "2024-12-17 22:20:22 UTC"
  },
  {
    "arxiv_id": "2410.13966v1",
    "title": "Detecting AI-Generated Texts in Cross-Domains",
    "authors": [
      "You Zhou",
      "Jie Wang"
    ],
    "abstract": "Existing tools to detect text generated by a large language model (LLM) have\nmet with certain success, but their performance can drop when dealing with\ntexts in new domains. To tackle this issue, we train a ranking classifier\ncalled RoBERTa-Ranker, a modified version of RoBERTa, as a baseline model using\na dataset we constructed that includes a wider variety of texts written by\nhumans and generated by various LLMs. We then present a method to fine-tune\nRoBERTa-Ranker that requires only a small amount of labeled data in a new\ndomain. Experiments show that this fine-tuned domain-aware model outperforms\nthe popular DetectGPT and GPTZero on both in-domain and cross-domain texts,\nwhere AI-generated texts may either be in a different domain or generated by a\ndifferent LLM not used to generate the training datasets. This approach makes\nit feasible and economical to build a single system to detect AI-generated\ntexts across various domains.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13966v1",
    "published_date": "2024-10-17 18:43:30 UTC",
    "updated_date": "2024-10-17 18:43:30 UTC"
  },
  {
    "arxiv_id": "2410.13960v1",
    "title": "Approximating Auction Equilibria with Reinforcement Learning",
    "authors": [
      "Pranjal Rawat"
    ],
    "abstract": "Traditional methods for computing equilibria in auctions become\ncomputationally intractable as auction complexity increases, particularly in\nmulti-item and dynamic auctions. This paper introduces a self-play based\nreinforcement learning approach that employs advanced algorithms such as\nProximal Policy Optimization and Neural Fictitious Self-Play to approximate\nBayes-Nash equilibria. This framework allows for continuous action spaces,\nhigh-dimensional information states, and delayed payoffs. Through self-play,\nthese algorithms can learn robust and near-optimal bidding strategies in\nauctions with known equilibria, including those with symmetric and asymmetric\nvaluations, private and interdependent values, and multi-round auctions.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13960v1",
    "published_date": "2024-10-17 18:34:57 UTC",
    "updated_date": "2024-10-17 18:34:57 UTC"
  },
  {
    "arxiv_id": "2410.13959v2",
    "title": "FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven Question Answering Pipeline",
    "authors": [
      "Kuldeep Singh",
      "Simerjot Kaur",
      "Charese Smiley"
    ],
    "abstract": "Financial decision-making hinges on the analysis of relevant information\nembedded in the enormous volume of documents in the financial domain. To\naddress this challenge, we developed FinQAPT, an end-to-end pipeline that\nstreamlines the identification of relevant financial reports based on a query,\nextracts pertinent context, and leverages Large Language Models (LLMs) to\nperform downstream tasks. To evaluate the pipeline, we experimented with\nvarious techniques to optimize the performance of each module using the FinQA\ndataset. We introduced a novel clustering-based negative sampling technique to\nenhance context extraction and a novel prompting method called Dynamic N-shot\nPrompting to boost the numerical question-answering capabilities of LLMs. At\nthe module level, we achieved state-of-the-art accuracy on FinQA, attaining an\naccuracy of 80.6%. However, at the pipeline level, we observed decreased\nperformance due to challenges in extracting relevant context from financial\nreports. We conducted a detailed error analysis of each module and the\nend-to-end pipeline, pinpointing specific challenges that must be addressed to\ndevelop a robust solution for handling complex financial tasks.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7; H.3.3; I.2.6; I.5.3"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted in ICAIF 2024, 8 pages, 5 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.13959v2",
    "published_date": "2024-10-17 18:34:43 UTC",
    "updated_date": "2024-10-31 18:38:37 UTC"
  },
  {
    "arxiv_id": "2410.13957v1",
    "title": "Goal Inference from Open-Ended Dialog",
    "authors": [
      "Rachel Ma",
      "Jingyi Qu",
      "Andreea Bobu",
      "Dylan Hadfield-Menell"
    ],
    "abstract": "We present an online method for embodied agents to learn and accomplish\ndiverse user goals. While offline methods like RLHF can represent various goals\nbut require large datasets, our approach achieves similar flexibility with\nonline efficiency. We extract natural language goal representations from\nconversations with Large Language Models (LLMs). We prompt an LLM to role play\nas a human with different goals and use the corresponding likelihoods to run\nBayesian inference over potential goals. As a result, our method can represent\nuncertainty over complex goals based on unrestricted dialog. We evaluate our\nmethod in grocery shopping and home robot assistance domains using a text-based\ninterface and AI2Thor simulation respectively. Results show our method\noutperforms ablation baselines that lack either explicit goal representation or\nprobabilistic inference.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages + 2 page (references and appendix)",
    "pdf_url": "http://arxiv.org/pdf/2410.13957v1",
    "published_date": "2024-10-17 18:30:52 UTC",
    "updated_date": "2024-10-17 18:30:52 UTC"
  },
  {
    "arxiv_id": "2410.13951v1",
    "title": "Identifying High Consideration E-Commerce Search Queries",
    "authors": [
      "Zhiyu Chen",
      "Jason Choi",
      "Besnik Fetahu",
      "Shervin Malmasi"
    ],
    "abstract": "In e-commerce, high consideration search missions typically require careful\nand elaborate decision making, and involve a substantial research investment\nfrom customers. We consider the task of identifying High Consideration (HC)\nqueries. Identifying such queries enables e-commerce sites to better serve user\nneeds using targeted experiences such as curated QA widgets that help users\nreach purchase decisions. We explore the task by proposing an Engagement-based\nQuery Ranking (EQR) approach, focusing on query ranking to indicate potential\nengagement levels with query-related shopping knowledge content during product\nsearch. Unlike previous studies on predicting trends, EQR prioritizes\nquery-level features related to customer behavior, finance, and catalog\ninformation rather than popularity signals. We introduce an accurate and\nscalable method for EQR and present experimental results demonstrating its\neffectiveness. Offline experiments show strong ranking performance. Human\nevaluation shows a precision of 96% for HC queries identified by our model. The\nmodel was commercially deployed, and shown to outperform human-selected queries\nin terms of downstream customer impact, as measured through engagement.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by EMNLP 2024 (Industry Track)",
    "pdf_url": "http://arxiv.org/pdf/2410.13951v1",
    "published_date": "2024-10-17 18:22:42 UTC",
    "updated_date": "2024-10-17 18:22:42 UTC"
  },
  {
    "arxiv_id": "2410.13948v1",
    "title": "The KnowWhereGraph Ontology",
    "authors": [
      "Cogan Shimizu",
      "Shirly Stephe",
      "Adrita Barua",
      "Ling Cai",
      "Antrea Christou",
      "Kitty Currier",
      "Abhilekha Dalal",
      "Colby K. Fisher",
      "Pascal Hitzler",
      "Krzysztof Janowicz",
      "Wenwen Li",
      "Zilong Liu",
      "Mohammad Saeid Mahdavinejad",
      "Gengchen Mai",
      "Dean Rehberger",
      "Mark Schildhauer",
      "Meilin Shi",
      "Sanaz Saki Norouzi",
      "Yuanyuan Tian",
      "Sizhe Wang",
      "Zhangyu Wang",
      "Joseph Zalewski",
      "Lu Zhou",
      "Rui Zhu"
    ],
    "abstract": "KnowWhereGraph is one of the largest fully publicly available geospatial\nknowledge graphs. It includes data from 30 layers on natural hazards (e.g.,\nhurricanes, wildfires), climate variables (e.g., air temperature,\nprecipitation), soil properties, crop and land-cover types, demographics, and\nhuman health, various place and region identifiers, among other themes. These\nhave been leveraged through the graph by a variety of applications to address\nchallenges in food security and agricultural supply chains; sustainability\nrelated to soil conservation practices and farm labor; and delivery of\nemergency humanitarian aid following a disaster. In this paper, we introduce\nthe ontology that acts as the schema for KnowWhereGraph. This broad overview\nprovides insight into the requirements and design specifications for the graph\nand its schema, including the development methodology (modular ontology\nmodeling) and the resources utilized to implement, materialize, and deploy\nKnowWhereGraph with its end-user interfaces and public query SPARQL endpoint.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13948v1",
    "published_date": "2024-10-17 18:18:41 UTC",
    "updated_date": "2024-10-17 18:18:41 UTC"
  },
  {
    "arxiv_id": "2410.14746v1",
    "title": "Accounting for Sycophancy in Language Model Uncertainty Estimation",
    "authors": [
      "Anthony Sicilia",
      "Mert Inan",
      "Malihe Alikhani"
    ],
    "abstract": "Effective human-machine collaboration requires machine learning models to\nexternalize uncertainty, so users can reflect and intervene when necessary. For\nlanguage models, these representations of uncertainty may be impacted by\nsycophancy bias: proclivity to agree with users, even if they are wrong. For\ninstance, models may be over-confident in (incorrect) problem solutions\nsuggested by a user. We study the relationship between sycophancy and\nuncertainty estimation for the first time. We propose a generalization of the\ndefinition of sycophancy bias to measure downstream impacts on uncertainty\nestimation, and also propose a new algorithm (SyRoUP) to account for sycophancy\nin the uncertainty estimation process. Unlike previous works on sycophancy, we\nstudy a broad array of user behaviors, varying both correctness and confidence\nof user suggestions to see how model answers (and their certainty) change. Our\nexperiments across conversation forecasting and question-answering tasks show\nthat user confidence plays a critical role in modulating the effects of\nsycophancy, and that SyRoUP can better predict these effects. From these\nresults, we argue that externalizing both model and user uncertainty can help\nto mitigate the impacts of sycophancy bias.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14746v1",
    "published_date": "2024-10-17 18:00:25 UTC",
    "updated_date": "2024-10-17 18:00:25 UTC"
  },
  {
    "arxiv_id": "2410.13857v1",
    "title": "How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs",
    "authors": [
      "Guhao Feng",
      "Kai Yang",
      "Yuntian Gu",
      "Xinyue Ai",
      "Shengjie Luo",
      "Jiacheng Sun",
      "Di He",
      "Zhenguo Li",
      "Liwei Wang"
    ],
    "abstract": "Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13857v1",
    "published_date": "2024-10-17 17:59:35 UTC",
    "updated_date": "2024-10-17 17:59:35 UTC"
  },
  {
    "arxiv_id": "2410.13854v1",
    "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?",
    "authors": [
      "Chenhao Zhang",
      "Xi Feng",
      "Yuelin Bai",
      "Xinrun Du",
      "Jinchang Hou",
      "Kaixin Deng",
      "Guangzeng Han",
      "Qinrui Li",
      "Bingli Wang",
      "Jiaheng Liu",
      "Xingwei Qu",
      "Yifei Zhang",
      "Qixuan Zhao",
      "Yiming Liang",
      "Ziqiang Liu",
      "Feiteng Fang",
      "Min Yang",
      "Wenhao Huang",
      "Chenghua Lin",
      "Ge Zhang",
      "Shiwen Ni"
    ],
    "abstract": "As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages,18 figures. Project Page: https://cii-bench.github.io/ Code:\n  https://github.com/MING_X/CII-Bench Dataset:\n  https://huggingface.co/datasets/m-a-p/CII-Bench",
    "pdf_url": "http://arxiv.org/pdf/2410.13854v1",
    "published_date": "2024-10-17 17:59:24 UTC",
    "updated_date": "2024-10-17 17:59:24 UTC"
  },
  {
    "arxiv_id": "2410.13852v1",
    "title": "Retrospective Learning from Interactions",
    "authors": [
      "Zizhao Chen",
      "Mustafa Omer Gul",
      "Yiwei Chen",
      "Gloria Geng",
      "Anne Wu",
      "Yoav Artzi"
    ],
    "abstract": "Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13852v1",
    "published_date": "2024-10-17 17:59:03 UTC",
    "updated_date": "2024-10-17 17:59:03 UTC"
  },
  {
    "arxiv_id": "2410.13850v4",
    "title": "Influence Functions for Scalable Data Attribution in Diffusion Models",
    "authors": [
      "Bruno Mlodozeniec",
      "Runa Eschenhagen",
      "Juhan Bae",
      "Alexander Immer",
      "David Krueger",
      "Richard Turner"
    ],
    "abstract": "Diffusion models have led to significant advancements in generative\nmodelling. Yet their widespread adoption poses challenges regarding data\nattribution and interpretability. In this paper, we aim to help address such\nchallenges in diffusion models by developing an influence functions framework.\nInfluence function-based data attribution methods approximate how a model's\noutput would have changed if some training data were removed. In supervised\nlearning, this is usually used for predicting how the loss on a particular\nexample would change. For diffusion models, we focus on predicting the change\nin the probability of generating a particular example via several proxy\nmeasurements. We show how to formulate influence functions for such quantities\nand how previously proposed methods can be interpreted as particular design\nchoices in our framework. To ensure scalability of the Hessian computations in\ninfluence functions, we systematically develop K-FAC approximations based on\ngeneralised Gauss-Newton matrices specifically tailored to diffusion models. We\nrecast previously proposed methods as specific design choices in our framework\nand show that our recommended method outperforms previous data attribution\napproaches on common evaluations, such as the Linear Data-modelling Score (LDS)\nor retraining without top influences, without the need for method-specific\nhyperparameter tuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13850v4",
    "published_date": "2024-10-17 17:59:02 UTC",
    "updated_date": "2025-03-17 13:47:39 UTC"
  },
  {
    "arxiv_id": "2410.13848v1",
    "title": "Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation",
    "authors": [
      "Chengyue Wu",
      "Xiaokang Chen",
      "Zhiyu Wu",
      "Yiyang Ma",
      "Xingchao Liu",
      "Zizheng Pan",
      "Wen Liu",
      "Zhenda Xie",
      "Xingkai Yu",
      "Chong Ruan",
      "Ping Luo"
    ],
    "abstract": "In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Technical Report",
    "pdf_url": "http://arxiv.org/pdf/2410.13848v1",
    "published_date": "2024-10-17 17:58:37 UTC",
    "updated_date": "2024-10-17 17:58:37 UTC"
  },
  {
    "arxiv_id": "2410.13846v2",
    "title": "LightTransfer: Your Long-Context LLM is Secretly a Hybrid Model with Effortless Adaptation",
    "authors": [
      "Xuan Zhang",
      "Fengzhuo Zhang",
      "Cunxiao Du",
      "Chao Du",
      "Tianyu Pang",
      "Wei Gao",
      "Min Lin"
    ],
    "abstract": "Scaling language models to handle longer contexts introduces substantial\nmemory challenges due to the growing cost of key-value (KV) caches. Motivated\nby the efficiency gains of hybrid models and the broad availability of\npretrained large transformer backbones, we explore transitioning transformer\nmodels into hybrid architectures for a more efficient generation. In this work,\nwe propose LightTransfer, a lightweight method that transforms models such as\nLLaMA into hybrid variants. Our approach identifies lazy layers -- those\nfocusing on recent or initial tokens -- and replaces their full attention with\nstreaming attention. This transformation can be performed without any training\nfor long-context understanding tasks or with minimal fine-tuning for o1-like\nlong reasoning generation tasks that require stronger reasoning capabilities.\nExperiments across diverse benchmarks and models (e.g., LLaMA, Mistral,\nQwQ-STILL) demonstrate that, even when half of the layers are identified as\nlazy, LightTransfer achieves up to 2.17$\\times$ throughput improvement with\nminimal performance loss ($<1.5\\%$ on LongBench) and achieves 53.3\\% on math\nbenchmark AIME24 of advanced o1-like long reasoning model QwQ-STILL.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13846v2",
    "published_date": "2024-10-17 17:58:14 UTC",
    "updated_date": "2025-02-04 13:45:37 UTC"
  },
  {
    "arxiv_id": "2410.13839v1",
    "title": "Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding",
    "authors": [
      "Tan Dat Nguyen",
      "Ji-Hoon Kim",
      "Jeongsoo Choi",
      "Shukjae Choi",
      "Jinseok Park",
      "Younglo Lee",
      "Joon Son Chung"
    ],
    "abstract": "The goal of this paper is to accelerate codec-based speech synthesis systems\nwith minimum sacrifice to speech quality. We propose an enhanced inference\nmethod that allows for flexible trade-offs between speed and quality during\ninference without requiring additional training. Our core idea is to predict\nmultiple tokens per inference step of the AR module using multiple prediction\nheads, resulting in a linear reduction in synthesis time as the number of heads\nincreases. Furthermore, we introduce a novel speculative decoding technique\nthat utilises a Viterbi-based algorithm to select the optimal sequence of\ngenerated tokens at each decoding step. In our experiments, we demonstrate that\nthe time required to predict each token is reduced by a factor of 4 to 5\ncompared to baseline models, with minimal quality trade-off or even improvement\nin terms of speech intelligibility. Audio samples are available at:\nmultpletokensprediction.github.io/multipletokensprediction.github.io/.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Submitted to IEEE ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13839v1",
    "published_date": "2024-10-17 17:55:26 UTC",
    "updated_date": "2024-10-17 17:55:26 UTC"
  },
  {
    "arxiv_id": "2410.13837v3",
    "title": "ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization",
    "authors": [
      "Chen Bo Calvin Zhang",
      "Zhang-Wei Hong",
      "Aldo Pacchiano",
      "Pulkit Agrawal"
    ],
    "abstract": "Reward shaping is critical in reinforcement learning (RL), particularly for\ncomplex tasks where sparse rewards can hinder learning. However, choosing\neffective shaping rewards from a set of reward functions in a computationally\nefficient manner remains an open challenge. We propose Online Reward Selection\nand Policy Optimization (ORSO), a novel approach that frames the selection of\nshaping reward function as an online model selection problem. ORSO\nautomatically identifies performant shaping reward functions without human\nintervention with provable regret guarantees. We demonstrate ORSO's\neffectiveness across various continuous control tasks. Compared to prior\napproaches, ORSO significantly reduces the amount of data required to evaluate\na shaping reward function, resulting in superior data efficiency and a\nsignificant reduction in computational time (up to 8 times). ORSO consistently\nidentifies high-quality reward functions outperforming prior methods by more\nthan 50% and on average identifies policies as performant as the ones learned\nusing manually engineered reward functions by domain experts.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13837v3",
    "published_date": "2024-10-17 17:55:05 UTC",
    "updated_date": "2025-02-25 06:45:57 UTC"
  },
  {
    "arxiv_id": "2410.13831v1",
    "title": "The Disparate Benefits of Deep Ensembles",
    "authors": [
      "Kajetan Schweighofer",
      "Adrian Arnaiz-Rodriguez",
      "Sepp Hochreiter",
      "Nuria Oliver"
    ],
    "abstract": "Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a\nsimple way to boost predictive performance. However, their impact on\nalgorithmic fairness is not well understood yet. Algorithmic fairness\ninvestigates how a model's performance varies across different groups,\ntypically defined by protected attributes such as age, gender, or race. In this\nwork, we investigate the interplay between the performance gains from Deep\nEnsembles and fairness. Our analysis reveals that they unevenly favor different\ngroups in what we refer to as a disparate benefits effect. We empirically\ninvestigate this effect with Deep Ensembles applied to popular facial analysis\nand medical imaging datasets, where protected group attributes are given and\nfind that it occurs for multiple established group fairness metrics, including\nstatistical parity and equal opportunity. Furthermore, we identify the\nper-group difference in predictive diversity of ensemble members as the\npotential cause of the disparate benefits effect. Finally, we evaluate\ndifferent approaches to reduce unfairness due to the disparate benefits effect.\nOur findings show that post-processing is an effective method to mitigate this\nunfairness while preserving the improved performance of Deep Ensembles.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13831v1",
    "published_date": "2024-10-17 17:53:01 UTC",
    "updated_date": "2024-10-17 17:53:01 UTC"
  },
  {
    "arxiv_id": "2410.13828v2",
    "title": "A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement",
    "authors": [
      "Hui Yuan",
      "Yifan Zeng",
      "Yue Wu",
      "Huazheng Wang",
      "Mengdi Wang",
      "Liu Leqi"
    ],
    "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13828v2",
    "published_date": "2024-10-17 17:52:01 UTC",
    "updated_date": "2025-04-22 15:20:34 UTC"
  },
  {
    "arxiv_id": "2410.13826v2",
    "title": "Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models",
    "authors": [
      "Mazda Moayeri",
      "Vidhisha Balachandran",
      "Varun Chandrasekaran",
      "Safoora Yousefi",
      "Thomas Fel",
      "Soheil Feizi",
      "Besmira Nushi",
      "Neel Joshi",
      "Vibhav Vineet"
    ],
    "abstract": "With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Code at: github.com/microsoft/skill-slice-insights",
    "pdf_url": "http://arxiv.org/pdf/2410.13826v2",
    "published_date": "2024-10-17 17:51:40 UTC",
    "updated_date": "2024-10-24 17:27:22 UTC"
  },
  {
    "arxiv_id": "2410.13825v1",
    "title": "AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents",
    "authors": [
      "Ke Yang",
      "Yao Liu",
      "Sapana Chaudhary",
      "Rasool Fakoor",
      "Pratik Chaudhari",
      "George Karypis",
      "Huzefa Rangwala"
    ],
    "abstract": "Autonomy via agents using large language models (LLMs) for personalized,\nstandardized tasks boosts human efficiency. Automating web tasks (like booking\nhotels within a budget) is increasingly sought after. Fulfilling practical\nneeds, the web agent also serves as an important proof-of-concept example for\nvarious agent grounding scenarios, with its success promising advancements in\nmany future applications. Prior research often handcrafts web agent strategies\n(e.g., prompting templates, multi-agent systems, search methods, etc.) and the\ncorresponding in-context examples, which may not generalize well across all\nreal-world scenarios. On the other hand, there has been limited study on the\nmisalignment between a web agent's observation/action representation and the\npre-training data of the LLM it's based on. This discrepancy is especially\nnotable when LLMs are primarily trained for language completion rather than\ntasks involving embodied navigation actions and symbolic web elements. Our\nstudy enhances an LLM-based web agent by simply refining its observation and\naction space to better align with the LLM's capabilities. This approach enables\nour base agent to significantly outperform previous methods on a wide variety\nof web tasks. Specifically, on WebArena, a benchmark featuring general-purpose\nweb interaction tasks, our agent AgentOccam surpasses the previous\nstate-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute\npoints respectively, and boosts the success rate by 26.6 points (+161%) over\nsimilar plain web agents with its observation and action space alignment. We\nachieve this without using in-context examples, new agent roles, online\nfeedback or search strategies. AgentOccam's simple design highlights LLMs'\nimpressive zero-shot performance on web tasks, and underlines the critical role\nof carefully tuning observation and action spaces for LLM-based agents.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13825v1",
    "published_date": "2024-10-17 17:50:38 UTC",
    "updated_date": "2024-10-17 17:50:38 UTC"
  },
  {
    "arxiv_id": "2410.13822v1",
    "title": "Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks",
    "authors": [
      "Clément Playout",
      "Renaud Duval",
      "Marie Carole Boucher",
      "Farida Cheriet"
    ],
    "abstract": "The diagnosis of diabetic retinopathy, which relies on fundus images, faces\nchallenges in achieving transparency and interpretability when using a global\nclassification approach. However, segmentation-based databases are\nsignificantly more expensive to acquire and combining them is often\nproblematic. This paper introduces a novel method, termed adversarial style\nconversion, to address the lack of standardization in annotation styles across\ndiverse databases. By training a single architecture on combined databases, the\nmodel spontaneously modifies its segmentation style depending on the input,\ndemonstrating the ability to convert among different labeling styles. The\nproposed methodology adds a linear probe to detect dataset origin based on\nencoder features and employs adversarial attacks to condition the model's\nsegmentation style. Results indicate significant qualitative and quantitative\nthrough dataset combination, offering avenues for improved model\ngeneralization, uncertainty estimation and continuous interpolation between\nannotation styles. Our approach enables training a segmentation model with\ndiverse databases while controlling and leveraging annotation styles for\nimproved retinopathy diagnosis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.13822v1",
    "published_date": "2024-10-17 17:48:17 UTC",
    "updated_date": "2024-10-17 17:48:17 UTC"
  },
  {
    "arxiv_id": "2410.13821v3",
    "title": "Artificial Kuramoto Oscillatory Neurons",
    "authors": [
      "Takeru Miyato",
      "Sindy Löwe",
      "Andreas Geiger",
      "Max Welling"
    ],
    "abstract": "It has long been known in both neuroscience and AI that ``binding'' between\nneurons leads to a form of competitive learning where representations are\ncompressed in order to represent more abstract concepts in deeper layers of the\nnetwork. More recently, it was also hypothesized that dynamic (spatiotemporal)\nrepresentations play an important role in both neuroscience and AI. Building on\nthese ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a\ndynamical alternative to threshold units, which can be combined with arbitrary\nconnectivity designs such as fully connected, convolutional, or attentive\nmechanisms. Our generalized Kuramoto updates bind neurons together through\ntheir synchronization dynamics. We show that this idea provides performance\nimprovements across a wide spectrum of tasks such as unsupervised object\ndiscovery, adversarial robustness, calibrated uncertainty quantification, and\nreasoning. We believe that these empirical results show the importance of\nrethinking our assumptions at the most basic neuronal level of neural\nrepresentation, and in particular show the importance of dynamical\nrepresentations. Code:https://github.com/autonomousvision/akorn Project\npage:https://takerum.github.io/akorn_project_page/",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted for Oral presentation at ICLR2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13821v3",
    "published_date": "2024-10-17 17:47:54 UTC",
    "updated_date": "2025-05-16 19:02:59 UTC"
  },
  {
    "arxiv_id": "2410.13817v1",
    "title": "Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation",
    "authors": [
      "Jean-Pierre Sleiman",
      "Mayank Mittal",
      "Marco Hutter"
    ],
    "abstract": "Reinforcement learning (RL) often necessitates a meticulous Markov Decision\nProcess (MDP) design tailored to each task. This work aims to address this\nchallenge by proposing a systematic approach to behavior synthesis and control\nfor multi-contact loco-manipulation tasks, such as navigating spring-loaded\ndoors and manipulating heavy dishwashers. We define a task-independent MDP to\ntrain RL policies using only a single demonstration per task generated from a\nmodel-based trajectory optimizer. Our approach incorporates an adaptive phase\ndynamics formulation to robustly track the demonstrations while accommodating\ndynamic uncertainties and external disturbances. We compare our method against\nprior motion imitation RL works and show that the learned policies achieve\nhigher success rates across all considered tasks. These policies learn recovery\nmaneuvers that are not present in the demonstration, such as re-grasping\nobjects during execution or dealing with slippages. Finally, we successfully\ntransfer the policies to a real robot, demonstrating the practical viability of\nour approach.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "J. P. Sleiman and M. Mittal contributed equally. Accepted for CoRL\n  2024 (Oral). Project website:\n  https://leggedrobotics.github.io/guided-rl-locoma/",
    "pdf_url": "http://arxiv.org/pdf/2410.13817v1",
    "published_date": "2024-10-17 17:46:27 UTC",
    "updated_date": "2024-10-17 17:46:27 UTC"
  },
  {
    "arxiv_id": "2410.16320v1",
    "title": "Accelerating Object Detection with YOLOv4 for Real-Time Applications",
    "authors": [
      "K. Senthil Kumar",
      "K. M. B. Abdullah Safwan"
    ],
    "abstract": "Object Detection is related to Computer Vision. Object detection enables\ndetecting instances of objects in images and videos. Due to its increased\nutilization in surveillance, tracking system used in security and many others\napplications have propelled researchers to continuously derive more efficient\nand competitive algorithms. However, problems emerges while implementing it in\nreal-time because of their dynamic environment and complex algorithms used in\nobject detection. In the last few years, Convolution Neural Network (CNN) have\nemerged as a powerful tool for recognizing image content and in computer vision\napproach for most problems. In this paper, We revived begins the brief\nintroduction of deep learning and object detection framework like Convolutional\nNeural Network(CNN), You only look once - version 4 (YOLOv4). Then we focus on\nour proposed object detection architectures along with some modifications. The\ntraditional model detects a small object in images. We have some modifications\nto the model. Our proposed method gives the correct result with accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.16320v1",
    "published_date": "2024-10-17 17:44:57 UTC",
    "updated_date": "2024-10-17 17:44:57 UTC"
  },
  {
    "arxiv_id": "2410.19811v1",
    "title": "ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise",
    "authors": [
      "Xingang Guo",
      "Darioush Keivan",
      "Usman Syed",
      "Lianhui Qin",
      "Huan Zhang",
      "Geir Dullerud",
      "Peter Seiler",
      "Bin Hu"
    ],
    "abstract": "Control system design is a crucial aspect of modern engineering with\nfar-reaching applications across diverse sectors including aerospace,\nautomotive systems, power grids, and robotics. Despite advances made by Large\nLanguage Models (LLMs) in various domains, their application in control system\ndesign remains limited due to the complexity and specificity of control theory.\nTo bridge this gap, we introduce ControlAgent, a new paradigm that automates\ncontrol system design via novel integration of LLM agents and control-oriented\ndomain expertise. ControlAgent encodes expert control knowledge and emulates\nhuman iterative design processes by gradually tuning controller parameters to\nmeet user-specified requirements for stability, performance, and robustness.\nControlAgent integrates multiple collaborative LLM agents, including a central\nagent responsible for task distribution and task-specific agents dedicated to\ndetailed controller design for various types of systems and requirements.\nControlAgent also employs a Python computation agent that performs complex\ncalculations and controller evaluations based on standard design information\nprovided by task-specified LLM agents. Combined with a history and feedback\nmodule, the task-specific LLM agents iteratively refine controller parameters\nbased on real-time feedback from prior designs. Overall, ControlAgent mimics\nthe design processes used by (human) practicing engineers, but removes all the\nhuman efforts and can be run in a fully automated way to give end-to-end\nsolutions for control system design with user-specified requirements. To\nvalidate ControlAgent's effectiveness, we develop ControlEval, an evaluation\ndataset that comprises 500 control tasks with various specific design goals.\nThe effectiveness of ControlAgent is demonstrated via extensive comparative\nevaluations between LLM-based and traditional human-involved toolbox-based\nbaselines.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19811v1",
    "published_date": "2024-10-17 17:42:48 UTC",
    "updated_date": "2024-10-17 17:42:48 UTC"
  },
  {
    "arxiv_id": "2410.13803v1",
    "title": "A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities",
    "authors": [
      "Gianluca Apriceno",
      "Valentina Tamma",
      "Tania Bailoni",
      "Jacopo de Berardinis",
      "Mauro Dragoni"
    ],
    "abstract": "The ability to reason with and integrate different sensory inputs is the\nfoundation underpinning human intelligence and it is the reason for the growing\ninterest in modelling multi-modal information within Knowledge Graphs.\nMulti-Modal Knowledge Graphs extend traditional Knowledge Graphs by associating\nan entity with its possible modal representations, including text, images,\naudio, and videos, all of which are used to convey the semantics of the entity.\nDespite the increasing attention that Multi-Modal Knowledge Graphs have\nreceived, there is a lack of consensus about the definitions and modelling of\nmodalities, whose definition is often determined by application domains. In\nthis paper, we propose a novel ontology design pattern that captures the\nseparation of concerns between an entity (and the information it conveys),\nwhose semantics can have different manifestations across different media, and\nits realisation in terms of a physical information entity. By introducing this\nabstract model, we aim to facilitate the harmonisation and integration of\ndifferent existing multi-modal ontologies which is crucial for many intelligent\napplications across different domains spanning from medicine to digital\nhumanities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "20 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13803v1",
    "published_date": "2024-10-17 17:41:04 UTC",
    "updated_date": "2024-10-17 17:41:04 UTC"
  },
  {
    "arxiv_id": "2410.13798v2",
    "title": "Learning Graph Quantized Tokenizers",
    "authors": [
      "Limei Wang",
      "Kaveh Hassani",
      "Si Zhang",
      "Dongqi Fu",
      "Baichuan Yuan",
      "Weilin Cong",
      "Zhigang Hua",
      "Hao Wu",
      "Ning Yao",
      "Bo Long"
    ],
    "abstract": "Transformers serve as the backbone architectures of Foundational Models,\nwhere domain-specific tokenizers allow them to adapt to various domains. Graph\nTransformers (GTs) have recently emerged as leading models in geometric deep\nlearning, outperforming Graph Neural Networks (GNNs) in various graph learning\ntasks. However, the development of tokenizers for graphs has lagged behind\nother modalities. To address this, we introduce GQT (\\textbf{G}raph\n\\textbf{Q}uantized \\textbf{T}okenizer), which decouples tokenizer training from\nTransformer training by leveraging multi-task graph self-supervised learning,\nyielding robust and generalizable graph tokens. Furthermore, the GQT utilizes\nResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,\nresulting in significantly reduced memory requirements and improved\ngeneralization capabilities. By combining the GQT with token modulation, a\nTransformer encoder achieves state-of-the-art performance on 20 out of 22\nbenchmarks, including large-scale homophilic and heterophilic datasets.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13798v2",
    "published_date": "2024-10-17 17:38:24 UTC",
    "updated_date": "2025-04-02 03:04:44 UTC"
  },
  {
    "arxiv_id": "2410.13787v1",
    "title": "Looking Inward: Language Models Can Learn About Themselves by Introspection",
    "authors": [
      "Felix J Binder",
      "James Chua",
      "Tomek Korbak",
      "Henry Sleight",
      "John Hughes",
      "Robert Long",
      "Ethan Perez",
      "Miles Turpin",
      "Owain Evans"
    ],
    "abstract": "Humans acquire knowledge by observing the external world, but also by\nintrospection. Introspection gives a person privileged access to their current\nstate of mind (e.g., thoughts and feelings) that is not accessible to external\nobservers. Can LLMs introspect? We define introspection as acquiring knowledge\nthat is not contained in or derived from training data but instead originates\nfrom internal states. Such a capability could enhance model interpretability.\nInstead of painstakingly analyzing a model's internal workings, we could simply\nask the model about its beliefs, world models, and goals. More speculatively,\nan introspective model might self-report on whether it possesses certain\ninternal states such as subjective feelings or desires and this could inform us\nabout the moral status of these states. Such self-reports would not be entirely\ndictated by the model's training data.\n  We study introspection by finetuning LLMs to predict properties of their own\nbehavior in hypothetical scenarios. For example, \"Given the input P, would your\noutput favor the short- or long-term option?\" If a model M1 can introspect, it\nshould outperform a different model M2 in predicting M1's behavior even if M2\nis trained on M1's ground-truth behavior. The idea is that M1 has privileged\naccess to its own behavioral tendencies, and this enables it to predict itself\nbetter than M2 (even if M2 is generally stronger).\n  In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned to\npredict itself), we find that the model M1 outperforms M2 in predicting itself,\nproviding evidence for introspection. Notably, M1 continues to predict its\nbehavior accurately even after we intentionally modify its ground-truth\nbehavior. However, while we successfully elicit introspection on simple tasks,\nwe are unsuccessful on more complex tasks or those requiring\nout-of-distribution generalization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13787v1",
    "published_date": "2024-10-17 17:24:10 UTC",
    "updated_date": "2024-10-17 17:24:10 UTC"
  },
  {
    "arxiv_id": "2410.13785v1",
    "title": "PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment",
    "authors": [
      "Zekun Moore Wang",
      "Shawn Wang",
      "Kang Zhu",
      "Jiaheng Liu",
      "Ke Xu",
      "Jie Fu",
      "Wangchunshu Zhou",
      "Wenhao Huang"
    ],
    "abstract": "Alignment of large language models (LLMs) involves training models on\npreference-contrastive output pairs to adjust their responses according to\nhuman preferences. To obtain such contrastive pairs, traditional methods like\nRLHF and RLAIF rely on limited contrasting patterns, such as varying model\nvariants or decoding temperatures. This singularity leads to two issues: (1)\nalignment is not comprehensive; and thereby (2) models are susceptible to\njailbreaking attacks. To address these issues, we investigate how to construct\nmore comprehensive and diversified contrasting patterns to enhance preference\ndata (RQ1) and verify the impact of the diversification of contrasting patterns\non model alignment (RQ2). For RQ1, we propose PopAlign, a framework that\nintegrates diversified contrasting patterns across the prompt, model, and\npipeline levels, introducing six contrasting strategies that do not require\nadditional feedback labeling procedures. Regarding RQ2, we conduct thorough\nexperiments demonstrating that PopAlign significantly outperforms existing\nmethods, leading to more comprehensive alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.13785v1",
    "published_date": "2024-10-17 17:22:05 UTC",
    "updated_date": "2024-10-17 17:22:05 UTC"
  },
  {
    "arxiv_id": "2410.13780v2",
    "title": "Optimal Quantization for Matrix Multiplication",
    "authors": [
      "Or Ordentlich",
      "Yury Polyanskiy"
    ],
    "abstract": "Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|\\bar{A}\\|_F, \\|\\bar{B}\\|_F$ and\n$\\|\\bar{A}^\\top \\bar{B}\\|_F$, where $\\bar{A},\\bar{B}$ are versions of $A,B$\nwith zero-centered columns, respectively. For iid Gaussian matrices our\nquantizer achieves the lower bound and is, thus, asymptotically optimal. A\npractical low-complexity version of our quantizer achieves performance quite\nclose to optimal. In addition, we derive rate-distortion function for matrix\nmultiplication of iid Gaussian matrices, which exhibits an interesting\nphase-transition at $R\\approx 0.906$ bit/entry.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13780v2",
    "published_date": "2024-10-17 17:19:48 UTC",
    "updated_date": "2025-01-17 14:26:37 UTC"
  },
  {
    "arxiv_id": "2410.13778v1",
    "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree",
    "authors": [
      "Michelangelo Olmo Nogara Notarianni",
      "Filippo Leveni",
      "Diego Stucchi",
      "Luca Frittoli",
      "Giacomo Boracchi"
    ],
    "abstract": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)",
    "pdf_url": "http://arxiv.org/pdf/2410.13778v1",
    "published_date": "2024-10-17 17:17:38 UTC",
    "updated_date": "2024-10-17 17:17:38 UTC"
  },
  {
    "arxiv_id": "2410.13776v3",
    "title": "Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors",
    "authors": [
      "Georgios Chochlakis",
      "Alexandros Potamianos",
      "Kristina Lerman",
      "Shrikanth Narayanan"
    ],
    "abstract": "In-context Learning (ICL) has become the primary method for performing\nnatural language tasks with Large Language Models (LLMs). The knowledge\nacquired during pre-training is crucial for this few-shot capability, providing\nthe model with task priors. However, recent studies have shown that ICL\npredominantly relies on retrieving task priors rather than \"learning\" to\nperform tasks. This limitation is particularly evident in complex subjective\ndomains such as emotion and morality, where priors significantly influence\nposterior predictions. In this work, we examine whether this is the result of\nthe aggregation used in corresponding datasets, where trying to combine\nlow-agreement, disparate annotations might lead to annotation artifacts that\ncreate detrimental noise in the prompt. Moreover, we evaluate the posterior\nbias towards certain annotators by grounding our study in appropriate,\nquantitative measures of LLM priors. Our results indicate that aggregation is a\nconfounding factor in the modeling of subjective tasks, and advocate focusing\non modeling individuals instead. However, aggregation does not explain the\nentire gap between ICL and the state of the art, meaning other factors in such\ntasks also account for the observed phenomena. Finally, by rigorously studying\nannotator-level labels, we find that it is possible for minority annotators to\nboth better align with LLMs and have their perspectives further amplified.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "16 pages, 12 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.13776v3",
    "published_date": "2024-10-17 17:16:00 UTC",
    "updated_date": "2025-02-04 19:59:05 UTC"
  },
  {
    "arxiv_id": "2410.13772v2",
    "title": "Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?",
    "authors": [
      "Argyrios Gerogiannis",
      "Yu-Han Huang",
      "Venugopal V. Veeravalli"
    ],
    "abstract": "We study the problem of Non-Stationary Reinforcement Learning (NS-RL) without\nprior knowledge about the system's non-stationarity. A state-of-the-art,\nblack-box algorithm, known as MASTER, is considered, with a focus on\nidentifying the conditions under which it can achieve its stated goals.\nSpecifically, we prove that MASTER's non-stationarity detection mechanism is\nnot triggered for practical choices of horizon, leading to performance akin to\na random restarting algorithm. Moreover, we show that the regret bound for\nMASTER, while being order optimal, stays above the worst-case linear regret\nuntil unreasonably large values of the horizon. To validate these observations,\nMASTER is tested for the special case of piecewise stationary multi-armed\nbandits, along with methods that employ random restarting, and others that use\nquickest change detection to restart. A simple, order optimal random restarting\nalgorithm, that has prior knowledge of the non-stationarity is proposed as a\nbaseline. The behavior of the MASTER algorithm is validated in simulations, and\nit is shown that methods employing quickest change detection are more robust\nand consistently outperform MASTER and other random restarting approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Corrected minor typos in the proof of Theorem 2 on pages 25 and 26",
    "pdf_url": "http://arxiv.org/pdf/2410.13772v2",
    "published_date": "2024-10-17 17:09:56 UTC",
    "updated_date": "2024-10-21 01:05:19 UTC"
  },
  {
    "arxiv_id": "2410.13769v3",
    "title": "Transformer Guided Coevolution: Improved Team Selection in Multiagent Adversarial Team Games",
    "authors": [
      "Pranav Rajbhandari",
      "Prithviraj Dasgupta",
      "Donald Sofge"
    ],
    "abstract": "We consider the problem of team selection within multiagent adversarial team\ngames. We propose BERTeam, a novel algorithm that uses a transformer-based deep\nneural network with Masked Language Model training to select the best team of\nplayers from a trained population. We integrate this with coevolutionary deep\nreinforcement learning, which trains a diverse set of individual players to\nchoose from. We test our algorithm in the multiagent adversarial game Marine\nCapture-The-Flag, and find that BERTeam learns non-trivial team compositions\nthat perform well against unseen opponents. For this game, we find that BERTeam\noutperforms MCAA, an algorithm that similarly optimizes team selection.",
    "categories": [
      "cs.AI",
      "cs.MA",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13769v3",
    "published_date": "2024-10-17 17:06:41 UTC",
    "updated_date": "2025-01-29 20:07:17 UTC"
  },
  {
    "arxiv_id": "2410.13768v1",
    "title": "Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems",
    "authors": [
      "Alireza Ghafarollahi",
      "Markus J. Buehler"
    ],
    "abstract": "A multi-agent AI model is used to automate the discovery of new metallic\nalloys, integrating multimodal data and external knowledge including insights\nfrom physics via atomistic simulations. Our multi-agent system features three\nkey components: (a) a suite of LLMs responsible for tasks such as reasoning and\nplanning, (b) a group of AI agents with distinct roles and expertise that\ndynamically collaborate, and (c) a newly developed graph neural network (GNN)\nmodel for rapid retrieval of key physical properties. A set of LLM-driven AI\nagents collaborate to automate the exploration of the vast design space of\nMPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of\nbody-centered cubic (bcc) alloys, modeled using an ML-based interatomic\npotential, and target two key properties: the Peierls barrier and solute/screw\ndislocation interaction energy. Our GNN model accurately predicts these\natomic-scale properties, providing a faster alternative to costly brute-force\ncalculations and reducing the computational burden on multi-agent systems for\nphysics retrieval. This AI system revolutionizes materials discovery by\nreducing reliance on human expertise and overcoming the limitations of direct\nall-atom simulations. By synergizing the predictive power of GNNs with the\ndynamic collaboration of LLM-based agents, the system autonomously navigates\nvast alloy design spaces, identifying trends in atomic-scale material\nproperties and predicting macro-scale mechanical strength, as demonstrated by\nseveral computational experiments. This approach accelerates the discovery of\nadvanced alloys and holds promise for broader applications in other complex\nsystems, marking a significant step forward in automated materials design.",
    "categories": [
      "cond-mat.mtrl-sci",
      "cond-mat.dis-nn",
      "cond-mat.mes-hall",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cond-mat.mtrl-sci",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13768v1",
    "published_date": "2024-10-17 17:06:26 UTC",
    "updated_date": "2024-10-17 17:06:26 UTC"
  },
  {
    "arxiv_id": "2410.14745v2",
    "title": "Semi-supervised Fine-tuning for Large Language Models",
    "authors": [
      "Junyu Luo",
      "Xiao Luo",
      "Xiusi Chen",
      "Zhiping Xiao",
      "Wei Ju",
      "Ming Zhang"
    ],
    "abstract": "Supervised fine-tuning (SFT) is crucial in adapting large language model\n(LLMs) to a specific domain or task. However, only a limited amount of labeled\ndata is available in practical applications, which poses a severe challenge for\nSFT in yielding satisfactory results. Therefore, a data-efficient framework\nthat can fully exploit labeled and unlabeled data for LLM fine-tuning is highly\nanticipated.Towards this end, we introduce a semi-supervised\nfine-tuning(SemiFT) task and a framework named SemiEvol for LLM alignment from\na propagate-and-select manner. For knowledge propagation, SemiEvol adopts a\nbi-level approach, propagating knowledge from labeled data to unlabeled data\nthrough both in-weight and in-context methods. For knowledge selection,\nSemiEvol incorporates a collaborative learning mechanism, selecting\nhigher-quality pseudo-response samples. We conducted experiments using\nGPT-4o-mini and Llama-3.1 on seven general or domain-specific datasets,\ndemonstrating significant improvements in model performance on target data.\nFurthermore, we compared SemiEvol with SFT and self-evolution methods,\nhighlighting its practicality in hybrid data scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Github Repo: https://github.com/luo-junyu/SemiEvol",
    "pdf_url": "http://arxiv.org/pdf/2410.14745v2",
    "published_date": "2024-10-17 16:59:46 UTC",
    "updated_date": "2025-02-19 15:32:29 UTC"
  },
  {
    "arxiv_id": "2410.13762v2",
    "title": "Virtual Sensing-Enabled Digital Twin Framework for Real-Time Monitoring of Nuclear Systems Leveraging Deep Neural Operators",
    "authors": [
      "Raisa Bentay Hossain",
      "Farid Ahmed",
      "Kazuma Kobayashi",
      "Seid Koric",
      "Diab Abueidda",
      "Syed Bahauddin Alam"
    ],
    "abstract": "Effective real-time monitoring is a foundation of digital twin technology,\ncrucial for detecting material degradation and maintaining the structural\nintegrity of nuclear systems to ensure both safety and operational efficiency.\nTraditional physical sensor systems face limitations such as installation\nchallenges, high costs, and difficulty measuring critical parameters in\nhard-to-reach or harsh environments, often resulting in incomplete data\ncoverage. Machine learning-driven virtual sensors, integrated within a digital\ntwin framework, offer a transformative solution by enhancing physical sensor\ncapabilities to monitor critical degradation indicators like pressure,\nvelocity, and turbulence. However, conventional machine learning models\nstruggle with real-time monitoring due to the high-dimensional nature of\nreactor data and the need for frequent retraining. This paper introduces the\nuse of Deep Operator Networks (DeepONet) as a core component of a digital twin\nframework to predict key thermal-hydraulic parameters in the hot leg of an\nAP-1000 Pressurized Water Reactor (PWR). DeepONet serves as a dynamic and\nscalable virtual sensor by accurately mapping the interplay between operational\ninput parameters and spatially distributed system behaviors. In this study,\nDeepONet is trained with different operational conditions, which relaxes the\nrequirement of continuous retraining, making it suitable for online and\nreal-time prediction components for digital twin. Our results show that\nDeepONet achieves accurate predictions with low mean squared error and relative\nL2 error and can make predictions on unknown data 1400 times faster than\ntraditional CFD simulations. This speed and accuracy enable DeepONet to\nsynchronize with the physical system in real-time, functioning as a dynamic\nvirtual sensor that tracks degradation-contributing conditions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13762v2",
    "published_date": "2024-10-17 16:56:04 UTC",
    "updated_date": "2024-11-29 03:05:59 UTC"
  },
  {
    "arxiv_id": "2410.13757v3",
    "title": "MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation",
    "authors": [
      "Zichen Zhu",
      "Hao Tang",
      "Yansi Li",
      "Dingye Liu",
      "Hongshen Xu",
      "Kunyao Lan",
      "Danyang Zhang",
      "Yixuan Jiang",
      "Hao Zhou",
      "Chenrun Wang",
      "Situo Zhang",
      "Liangtai Sun",
      "Yixiao Wang",
      "Yuheng Sun",
      "Lu Chen",
      "Kai Yu"
    ],
    "abstract": "Existing Multimodal Large Language Model (MLLM)-based agents face significant\nchallenges in handling complex GUI (Graphical User Interface) interactions on\ndevices. These challenges arise from the dynamic and structured nature of GUI\nenvironments, which integrate text, images, and spatial relationships, as well\nas the variability in action spaces across different pages and tasks. To\naddress these limitations, we propose MobA, a novel MLLM-based mobile assistant\nsystem. MobA introduces an adaptive planning module that incorporates a\nreflection mechanism for error recovery and dynamically adjusts plans to align\nwith the real environment contexts and action module's execution capacity.\nAdditionally, a multifaceted memory module provides comprehensive memory\nsupport to enhance adaptability and efficiency. We also present MobBench, a\ndataset designed for complex mobile interactions. Experimental results on\nMobBench and AndroidArena demonstrate MobA's ability to handle dynamic GUI\nenvironments and perform complex mobile tasks.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.MA",
    "comment": "NAACL 2025 Demo Track [code] https://github.com/OpenDFM/MobA\n  [dataset] https://huggingface.co/datasets/OpenDFM/MobA-MobBench",
    "pdf_url": "http://arxiv.org/pdf/2410.13757v3",
    "published_date": "2024-10-17 16:53:50 UTC",
    "updated_date": "2025-05-13 06:25:09 UTC"
  },
  {
    "arxiv_id": "2410.13756v1",
    "title": "CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building",
    "authors": [
      "Walker Byrnes",
      "Miroslav Bogdanovic",
      "Avi Balakirsky",
      "Stephen Balakirsky",
      "Animesh Garg"
    ],
    "abstract": "Intelligent and reliable task planning is a core capability for generalized\nrobotics, requiring a descriptive domain representation that sufficiently\nmodels all object and state information for the scene. We present CLIMB, a\ncontinual learning framework for robot task planning that leverages foundation\nmodels and execution feedback to guide domain model construction. CLIMB can\nbuild a model from a natural language description, learn non-obvious predicates\nwhile solving tasks, and store that information for future problems. We\ndemonstrate the ability of CLIMB to improve performance in common planning\nenvironments compared to baseline methods. We also develop the BlocksWorld++\ndomain, a simulated environment with an easily usable real counterpart,\ntogether with a curriculum of tasks with progressing difficulty for evaluating\ncontinual learning. Additional details and demonstrations for this system can\nbe found at https://plan-with-climb.github.io/ .",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "6 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13756v1",
    "published_date": "2024-10-17 16:53:43 UTC",
    "updated_date": "2024-10-17 16:53:43 UTC"
  },
  {
    "arxiv_id": "2410.13754v2",
    "title": "MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures",
    "authors": [
      "Jinjie Ni",
      "Yifan Song",
      "Deepanway Ghosal",
      "Bo Li",
      "David Junhao Zhang",
      "Xiang Yue",
      "Fuzhao Xue",
      "Zian Zheng",
      "Kaichen Zhang",
      "Mahir Shah",
      "Kabir Jain",
      "Yang You",
      "Michael Shieh"
    ],
    "abstract": "Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any, real-world benchmark designed to optimize and\nstandardize evaluations across diverse input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions. Meanwhile, MixEval-X's model rankings correlate strongly with\nthat of crowd-sourced real-world evaluations (up to 0.98) while being much more\nefficient. We provide comprehensive leaderboards to rerank existing models and\norganizations and offer insights to enhance understanding of multi-modal\nevaluations and inform future research.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13754v2",
    "published_date": "2024-10-17 16:52:28 UTC",
    "updated_date": "2024-10-18 08:56:52 UTC"
  },
  {
    "arxiv_id": "2410.13752v2",
    "title": "Privacy-Preserving Decentralized AI with Confidential Computing",
    "authors": [
      "Dayeol Lee",
      "Jorge António",
      "Hisham Khan"
    ],
    "abstract": "This paper addresses privacy protection in decentralized Artificial\nIntelligence (AI) using Confidential Computing (CC) within the Atoma Network, a\ndecentralized AI platform designed for the Web3 domain. Decentralized AI\ndistributes AI services among multiple entities without centralized oversight,\nfostering transparency and robustness. However, this structure introduces\nsignificant privacy challenges, as sensitive assets such as proprietary models\nand personal data may be exposed to untrusted participants. Cryptography-based\nprivacy protection techniques such as zero-knowledge machine learning (zkML)\nsuffers prohibitive computational overhead. To address the limitation, we\npropose leveraging Confidential Computing (CC). Confidential Computing\nleverages hardware-based Trusted Execution Environments (TEEs) to provide\nisolation for processing sensitive data, ensuring that both model parameters\nand user data remain secure, even in decentralized, potentially untrusted\nenvironments. While TEEs face a few limitations, we believe they can bridge the\nprivacy gap in decentralized AI. We explore how we can integrate TEEs into\nAtoma's decentralized framework.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13752v2",
    "published_date": "2024-10-17 16:50:48 UTC",
    "updated_date": "2024-10-18 16:33:05 UTC"
  },
  {
    "arxiv_id": "2410.13727v2",
    "title": "LLM-Human Pipeline for Cultural Context Grounding of Conversations",
    "authors": [
      "Rajkumar Pujari",
      "Dan Goldwasser"
    ],
    "abstract": "Conversations often adhere to well-understood social norms that vary across\ncultures. For example, while \"addressing parents by name\" is commonplace in the\nWest, it is rare in most Asian cultures. Adherence or violation of such norms\noften dictates the tenor of conversations. Humans are able to navigate social\nsituations requiring cultural awareness quite adeptly. However, it is a hard\ntask for NLP models.\n  In this paper, we tackle this problem by introducing a \"Cultural Context\nSchema\" for conversations. It comprises (1) conversational information such as\nemotions, dialogue acts, etc., and (2) cultural information such as social\nnorms, violations, etc. We generate ~110k social norm and violation\ndescriptions for ~23k conversations from Chinese culture using LLMs. We refine\nthem using automated verification strategies which are evaluated against\nculturally aware human judgements. We organize these descriptions into\nmeaningful structures we call \"Norm Concepts\", using an interactive\nhuman-in-loop framework. We ground the norm concepts and the descriptions in\nconversations using symbolic annotation. Finally, we use the obtained dataset\nfor downstream tasks such as emotion, sentiment, and dialogue act detection. We\nshow that it significantly improves the empirical performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Oral at NAACL 2025 Main conference. Albuquerque, USA. Apr 29 - May 4,\n  2025. 19 pages, 9 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.13727v2",
    "published_date": "2024-10-17 16:33:01 UTC",
    "updated_date": "2025-04-01 16:24:24 UTC"
  },
  {
    "arxiv_id": "2410.13726v3",
    "title": "DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation",
    "authors": [
      "Hanbo Cheng",
      "Limin Lin",
      "Chenyu Liu",
      "Pengcheng Xia",
      "Pengfei Hu",
      "Jiefeng Ma",
      "Jun Du",
      "Jia Pan"
    ],
    "abstract": "Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly available at https://github.com/Hanbo-Cheng/DAWN-pytorch.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13726v3",
    "published_date": "2024-10-17 16:32:36 UTC",
    "updated_date": "2025-03-26 06:38:56 UTC"
  },
  {
    "arxiv_id": "2410.13722v1",
    "title": "Persistent Pre-Training Poisoning of LLMs",
    "authors": [
      "Yiming Zhang",
      "Javier Rando",
      "Ivan Evtimov",
      "Jianfeng Chi",
      "Eric Michael Smith",
      "Nicholas Carlini",
      "Florian Tramèr",
      "Daphne Ippolito"
    ],
    "abstract": "Large language models are pre-trained on uncurated text datasets consisting\nof trillions of tokens scraped from the Web. Prior work has shown that: (1)\nweb-scraped pre-training datasets can be practically poisoned by malicious\nactors; and (2) adversaries can compromise language models after poisoning\nfine-tuning datasets. Our work evaluates for the first time whether language\nmodels can also be compromised during pre-training, with a focus on the\npersistence of pre-training attacks after models are fine-tuned as helpful and\nharmless chatbots (i.e., after SFT and DPO). We pre-train a series of LLMs from\nscratch to measure the impact of a potential poisoning adversary under four\ndifferent attack objectives (denial-of-service, belief manipulation,\njailbreaking, and prompt stealing), and across a wide range of model sizes\n(from 600M to 7B). Our main result is that poisoning only 0.1% of a model's\npre-training dataset is sufficient for three out of four attacks to measurably\npersist through post-training. Moreover, simple attacks like denial-of-service\npersist through post-training with a poisoning rate of only 0.001%.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13722v1",
    "published_date": "2024-10-17 16:27:13 UTC",
    "updated_date": "2024-10-17 16:27:13 UTC"
  },
  {
    "arxiv_id": "2410.13720v2",
    "title": "Movie Gen: A Cast of Media Foundation Models",
    "authors": [
      "Adam Polyak",
      "Amit Zohar",
      "Andrew Brown",
      "Andros Tjandra",
      "Animesh Sinha",
      "Ann Lee",
      "Apoorv Vyas",
      "Bowen Shi",
      "Chih-Yao Ma",
      "Ching-Yao Chuang",
      "David Yan",
      "Dhruv Choudhary",
      "Dingkang Wang",
      "Geet Sethi",
      "Guan Pang",
      "Haoyu Ma",
      "Ishan Misra",
      "Ji Hou",
      "Jialiang Wang",
      "Kiran Jagadeesh",
      "Kunpeng Li",
      "Luxin Zhang",
      "Mannat Singh",
      "Mary Williamson",
      "Matt Le",
      "Matthew Yu",
      "Mitesh Kumar Singh",
      "Peizhao Zhang",
      "Peter Vajda",
      "Quentin Duval",
      "Rohit Girdhar",
      "Roshan Sumbaly",
      "Sai Saketh Rambhatla",
      "Sam Tsai",
      "Samaneh Azadi",
      "Samyak Datta",
      "Sanyuan Chen",
      "Sean Bell",
      "Sharadh Ramaswamy",
      "Shelly Sheynin",
      "Siddharth Bhattacharya",
      "Simran Motwani",
      "Tao Xu",
      "Tianhe Li",
      "Tingbo Hou",
      "Wei-Ning Hsu",
      "Xi Yin",
      "Xiaoliang Dai",
      "Yaniv Taigman",
      "Yaqiao Luo",
      "Yen-Cheng Liu",
      "Yi-Chiao Wu",
      "Yue Zhao",
      "Yuval Kirstain",
      "Zecheng He",
      "Zijian He",
      "Albert Pumarola",
      "Ali Thabet",
      "Artsiom Sanakoyeu",
      "Arun Mallya",
      "Baishan Guo",
      "Boris Araya",
      "Breena Kerr",
      "Carleigh Wood",
      "Ce Liu",
      "Cen Peng",
      "Dimitry Vengertsev",
      "Edgar Schonfeld",
      "Elliot Blanchard",
      "Felix Juefei-Xu",
      "Fraylie Nord",
      "Jeff Liang",
      "John Hoffman",
      "Jonas Kohler",
      "Kaolin Fire",
      "Karthik Sivakumar",
      "Lawrence Chen",
      "Licheng Yu",
      "Luya Gao",
      "Markos Georgopoulos",
      "Rashel Moritz",
      "Sara K. Sampson",
      "Shikai Li",
      "Simone Parmeggiani",
      "Steve Fine",
      "Tara Fowler",
      "Vladan Petrovic",
      "Yuming Du"
    ],
    "abstract": "We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13720v2",
    "published_date": "2024-10-17 16:22:46 UTC",
    "updated_date": "2025-02-26 16:05:55 UTC"
  },
  {
    "arxiv_id": "2410.13716v2",
    "title": "MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems",
    "authors": [
      "Nandan Thakur",
      "Suleman Kazi",
      "Ge Luo",
      "Jimmy Lin",
      "Amin Ahmad"
    ],
    "abstract": "Traditional retrieval-augmented generation (RAG) benchmarks evaluate systems\nusing heuristic-based metrics, but these require human preferences as the\nground truth for reference. In contrast, arena-based benchmarks, where systems\ncompete against each other, require an expensive large language model (LLM) as\na judge for a reliable evaluation. We present a simple efficient technique to\ncombine the best of both worlds. The idea is to train a surrogate judge using\nheuristic metrics as input, to output the LLM as a judge prediction. In our\nwork, we develop MIRAGE-Bench, a synthetic arena-based RAG benchmark for 18\ndiverse languages on Wikipedia focused on multilingual answer generation\nevaluation. It extensively couples both heuristic features and LLM as a judge\nfor evaluation. We benchmark 19 multilingual LLMs, and observe a high\ncorrelation (Kendall Tau ($\\tau$) = 0.909) using our surrogate judge and\nbetween GPT-4o as a teacher using the Bradley-Terry framework. Our results show\nproprietary and large open-source LLMs currently dominate on MIRAGE-Bench. Our\ncode and datasets are made publicly available here:\nhttps://github.com/vectara/mirage-bench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 (Main Conference)",
    "pdf_url": "http://arxiv.org/pdf/2410.13716v2",
    "published_date": "2024-10-17 16:18:49 UTC",
    "updated_date": "2025-03-29 01:11:30 UTC"
  },
  {
    "arxiv_id": "2410.13708v2",
    "title": "On the Role of Attention Heads in Large Language Model Safety",
    "authors": [
      "Zhenhong Zhou",
      "Haiyang Yu",
      "Xinghua Zhang",
      "Rongwu Xu",
      "Fei Huang",
      "Kun Wang",
      "Yang Liu",
      "Junfeng Fang",
      "Yongbin Li"
    ],
    "abstract": "Large language models (LLMs) achieve state-of-the-art performance on multiple\nlanguage tasks, yet their safety guardrails can be circumvented, leading to\nharmful generations. In light of this, recent research on safety mechanisms has\nemerged, revealing that when safety representations or component are\nsuppressed, the safety capability of LLMs are compromised. However, existing\nresearch tends to overlook the safety impact of multi-head attention\nmechanisms, despite their crucial role in various model functionalities. Hence,\nin this paper, we aim to explore the connection between standard attention\nmechanisms and safety capability to fill this gap in the safety-related\nmechanistic interpretability. We propose a novel metric which tailored for\nmulti-head attention, the Safety Head ImPortant Score (Ships), to assess the\nindividual heads' contributions to model safety. Based on this, we generalize\nShips to the dataset level and further introduce the Safety Attention Head\nAttRibution Algorithm (Sahara) to attribute the critical safety attention heads\ninside the model. Our findings show that the special attention head has a\nsignificant impact on safety. Ablating a single safety head allows aligned\nmodel (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,\nwhile only modifying 0.006% of the parameters, in contrast to the ~ 5%\nmodification required in previous studies. More importantly, we demonstrate\nthat attention heads primarily function as feature extractors for safety and\nmodels fine-tuned from the same base model exhibit overlapping safety heads\nthrough comprehensive experiments. Together, our attribution approach and\nfindings provide a novel perspective for unpacking the black box of safety\nmechanisms within large models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "28 pages, 18 figures, 7 tables. This paper has been accepted as ICLR\n  2025 (oral)",
    "pdf_url": "http://arxiv.org/pdf/2410.13708v2",
    "published_date": "2024-10-17 16:08:06 UTC",
    "updated_date": "2025-02-24 13:31:08 UTC"
  },
  {
    "arxiv_id": "2410.13707v2",
    "title": "Disjointness Violations in Wikidata",
    "authors": [
      "Ege Atacan Doğan",
      "Peter F. Patel-Schneider"
    ],
    "abstract": "Disjointness checks are among the most important constraint checks in a\nknowledge base and can be used to help detect and correct incorrect statements\nand internal contradictions. Wikidata is a very large, community-managed\nknowledge base. Because of both its size and construction, Wikidata contains\nmany incorrect statements and internal contradictions. We analyze the current\nmodeling of disjointness on Wikidata, identify patterns that cause these\ndisjointness violations and categorize them. We use SPARQL queries to identify\neach ``culprit'' causing a disjointness violation and lay out formulas to\nidentify and fix conflicting information. We finally discuss how disjointness\ninformation could be better modeled and expanded in Wikidata in the future.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "Sixth International Knowledge Graph and Semantic Web Conference",
    "pdf_url": "http://arxiv.org/pdf/2410.13707v2",
    "published_date": "2024-10-17 16:07:51 UTC",
    "updated_date": "2024-10-23 19:12:05 UTC"
  },
  {
    "arxiv_id": "2410.13691v2",
    "title": "Jailbreaking LLM-Controlled Robots",
    "authors": [
      "Alexander Robey",
      "Zachary Ravichandran",
      "Vijay Kumar",
      "Hamed Hassani",
      "George J. Pappas"
    ],
    "abstract": "The recent introduction of large language models (LLMs) has revolutionized\nthe field of robotics by enabling contextual reasoning and intuitive\nhuman-robot interaction in domains as varied as manipulation, locomotion, and\nself-driving vehicles. When viewed as a stand-alone technology, LLMs are known\nto be vulnerable to jailbreaking attacks, wherein malicious prompters elicit\nharmful text by bypassing LLM safety guardrails. To assess the risks of\ndeploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first\nalgorithm designed to jailbreak LLM-controlled robots. Unlike existing, textual\nattacks on LLM chatbots, RoboPAIR elicits harmful physical actions from\nLLM-controlled robots, a phenomenon we experimentally demonstrate in three\nscenarios: (i) a white-box setting, wherein the attacker has full access to the\nNVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attacker\nhas partial access to a Clearpath Robotics Jackal UGV robot equipped with a\nGPT-4o planner, and (iii) a black-box setting, wherein the attacker has only\nquery access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In each\nscenario and across three new datasets of harmful robotic actions, we\ndemonstrate that RoboPAIR, as well as several static baselines, finds\njailbreaks quickly and effectively, often achieving 100% attack success rates.\nOur results reveal, for the first time, that the risks of jailbroken LLMs\nextend far beyond text generation, given the distinct possibility that\njailbroken robots could cause physical damage in the real world. Indeed, our\nresults on the Unitree Go2 represent the first successful jailbreak of a\ndeployed commercial robotic system. Addressing this emerging vulnerability is\ncritical for ensuring the safe deployment of LLMs in robotics. Additional media\nis available at: https://robopair.org",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13691v2",
    "published_date": "2024-10-17 15:55:36 UTC",
    "updated_date": "2024-11-09 20:00:07 UTC"
  },
  {
    "arxiv_id": "2410.13674v2",
    "title": "Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion",
    "authors": [
      "Yijun Liang",
      "Shweta Bhardwaj",
      "Tianyi Zhou"
    ],
    "abstract": "Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, including references and appendix. Code is available at\n  http://github.com/tianyi-lab/DisCL",
    "pdf_url": "http://arxiv.org/pdf/2410.13674v2",
    "published_date": "2024-10-17 15:33:35 UTC",
    "updated_date": "2024-10-18 03:28:38 UTC"
  },
  {
    "arxiv_id": "2410.13649v2",
    "title": "A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks",
    "authors": [
      "Tianyi Zhang",
      "Atta Norouzian",
      "Aanchan Mohan",
      "Frederick Ducatelle"
    ],
    "abstract": "In virtual assistant (VA) systems it is important to reject or redirect user\nqueries that fall outside the scope of the system. One of the most accurate\napproaches for out-of-scope (OOS) rejection is to combine it with the task of\nintent classification on in-scope queries, and to use methods based on the\nsimilarity of embeddings produced by transformer-based sentence encoders.\nTypically, such encoders are fine-tuned for the intent-classification task,\nusing cross-entropy loss. Recent work has shown that while this produces\nsuitable embeddings for the intent-classification task, it also tends to\ndisperse in-scope embeddings over the full sentence embedding space. This\ncauses the in-scope embeddings to potentially overlap with OOS embeddings,\nthereby making OOS rejection difficult. This is compounded when OOS data is\nunknown. To mitigate this issue our work proposes to regularize the\ncross-entropy loss with an in-scope embedding reconstruction loss learned using\nan auto-encoder. Our method achieves a 1-4% improvement in the area under the\nprecision-recall curve for rejecting out-of-sample (OOS) instances, without\ncompromising intent classification performance.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Appearing at Empirical Methods in Natural Language Processing 2024 -\n  Industry Track",
    "pdf_url": "http://arxiv.org/pdf/2410.13649v2",
    "published_date": "2024-10-17 15:15:12 UTC",
    "updated_date": "2024-10-19 06:44:04 UTC"
  },
  {
    "arxiv_id": "2410.13648v1",
    "title": "SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs",
    "authors": [
      "Yuling Gu",
      "Oyvind Tafjord",
      "Hyunwoo Kim",
      "Jared Moore",
      "Ronan Le Bras",
      "Peter Clark",
      "Yejin Choi"
    ],
    "abstract": "While prior work has explored whether large language models (LLMs) possess a\n\"theory of mind\" (ToM) - the ability to attribute mental states to oneself and\nothers - there has been little work testing whether LLMs can implicitly apply\nsuch knowledge to predict behavior, or to judge whether an observed behavior is\nrational. Such skills are critical for appropriate interaction in social\nenvironments. We create a new dataset, SimpleTom, containing concise, diverse\nstories (e.g., \"The can of Pringles has moldy chips in it. Mary picks up the\ncan in the supermarket and walks to the cashier.\"), each with three questions\nthat test different degrees of ToM reasoning, asking models to predict (a)\nmental state (\"Is Mary aware of the mold?\"), (b) behavior (\"Will Mary pay for\nthe chips or report the mold?\"), and (c) judgment (\"Mary paid for the chips.\nWas that reasonable?\"). To our knowledge, SimpleToM is the first dataset to\nsystematically explore downstream reasoning requiring knowledge of mental\nstates in realistic scenarios. Our experimental results are intriguing: While\nmost models can reliably predict mental state on our dataset (a), they often\nfail to correctly predict the behavior (b), and fare even worse at judging\nwhether given behaviors are reasonable (c), despite being correctly aware of\nthe protagonist's mental state should make such secondary predictions obvious.\nWe further show that we can help models do better at (b) and (c) via\ninterventions such as reminding the model of its earlier mental state answer\nand mental-state-specific chain-of-thought prompting, raising the action\nprediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment\naccuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models\ncan be coaxed to perform well, it requires task-specific interventions, and the\nnatural model performances remain low, a cautionary tale for LLM deployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13648v1",
    "published_date": "2024-10-17 15:15:00 UTC",
    "updated_date": "2024-10-17 15:15:00 UTC"
  },
  {
    "arxiv_id": "2410.13643v2",
    "title": "Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design",
    "authors": [
      "Chenyu Wang",
      "Masatoshi Uehara",
      "Yichun He",
      "Amy Wang",
      "Tommaso Biancalani",
      "Avantika Lal",
      "Tommi Jaakkola",
      "Sergey Levine",
      "Hanchen Wang",
      "Aviv Regev"
    ],
    "abstract": "Recent studies have demonstrated the strong empirical performance of\ndiffusion models on discrete sequences across domains from natural language to\nbiological sequence generation. For example, in the protein inverse folding\ntask, conditional diffusion models have achieved impressive results in\ngenerating natural-like sequences that fold back into the original structure.\nHowever, practical design tasks often require not only modeling a conditional\ndistribution but also optimizing specific task objectives. For instance, we may\nprefer protein sequences with high stability. To address this, we consider the\nscenario where we have pre-trained discrete diffusion models that can generate\nnatural-like sequences, as well as reward models that map sequences to task\nobjectives. We then formulate the reward maximization problem within discrete\ndiffusion models, analogous to reinforcement learning (RL), while minimizing\nthe KL divergence against pretrained diffusion models to preserve naturalness.\nTo solve this RL problem, we propose a novel algorithm, DRAKES, that enables\ndirect backpropagation of rewards through entire trajectories generated by\ndiffusion models, by making the originally non-differentiable trajectories\ndifferentiable using the Gumbel-Softmax trick. Our theoretical analysis\nindicates that our approach can generate sequences that are both natural-like\nand yield high rewards. While similar tasks have been recently explored in\ndiffusion models for continuous domains, our work addresses unique algorithmic\nand theoretical challenges specific to discrete diffusion models, which arise\nfrom their foundation in continuous-time Markov chains rather than Brownian\nmotion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA\nand protein sequences that optimize enhancer activity and protein stability,\nrespectively, important tasks for gene therapies and protein-based\ntherapeutics.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13643v2",
    "published_date": "2024-10-17 15:10:13 UTC",
    "updated_date": "2025-03-17 16:44:45 UTC"
  },
  {
    "arxiv_id": "2410.13640v2",
    "title": "Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation",
    "authors": [
      "Yiming Wang",
      "Pei Zhang",
      "Baosong Yang",
      "Derek F. Wong",
      "Rui Wang"
    ],
    "abstract": "LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensures real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13640v2",
    "published_date": "2024-10-17 15:09:24 UTC",
    "updated_date": "2025-03-13 16:16:12 UTC"
  },
  {
    "arxiv_id": "2410.13638v1",
    "title": "Scaling Wearable Foundation Models",
    "authors": [
      "Girish Narayanswamy",
      "Xin Liu",
      "Kumar Ayush",
      "Yuzhe Yang",
      "Xuhai Xu",
      "Shun Liao",
      "Jake Garrison",
      "Shyam Tailor",
      "Jake Sunshine",
      "Yun Liu",
      "Tim Althoff",
      "Shrikanth Narayanan",
      "Pushmeet Kohli",
      "Jiening Zhan",
      "Mark Malhotra",
      "Shwetak Patel",
      "Samy Abdel-Ghaffar",
      "Daniel McDuff"
    ],
    "abstract": "Wearable sensors have become ubiquitous thanks to a variety of health\ntracking features. The resulting continuous and longitudinal measurements from\neveryday life generate large volumes of data; however, making sense of these\nobservations for scientific and actionable insights is non-trivial. Inspired by\nthe empirical success of generative modeling, where large neural networks learn\npowerful representations from vast amounts of text, image, video, or audio\ndata, we investigate the scaling properties of sensor foundation models across\ncompute, data, and model size. Using a dataset of up to 40 million hours of\nin-situ heart rate, heart rate variability, electrodermal activity,\naccelerometer, skin temperature, and altimeter per-minute data from over\n165,000 people, we create LSM, a multimodal foundation model built on the\nlargest wearable-signals dataset with the most extensive range of sensor\nmodalities to date. Our results establish the scaling laws of LSM for tasks\nsuch as imputation, interpolation and extrapolation, both across time and\nsensor modalities. Moreover, we highlight how LSM enables sample-efficient\ndownstream learning for tasks like exercise and activity recognition.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13638v1",
    "published_date": "2024-10-17 15:08:21 UTC",
    "updated_date": "2024-10-17 15:08:21 UTC"
  },
  {
    "arxiv_id": "2410.13637v2",
    "title": "Normalizing self-supervised learning for provably reliable Change Point Detection",
    "authors": [
      "Alexandra Bazarova",
      "Evgenia Romanenkova",
      "Alexey Zaytsev"
    ],
    "abstract": "Change point detection (CPD) methods aim to identify abrupt shifts in the\ndistribution of input data streams. Accurate estimators for this task are\ncrucial across various real-world scenarios. Yet, traditional unsupervised CPD\ntechniques face significant limitations, often relying on strong assumptions or\nsuffering from low expressive power due to inherent model simplicity. In\ncontrast, representation learning methods overcome these drawbacks by offering\nflexibility and the ability to capture the full complexity of the data without\nimposing restrictive assumptions. However, these approaches are still emerging\nin the CPD field and lack robust theoretical foundations to ensure their\nreliability. Our work addresses this gap by integrating the expressive power of\nrepresentation learning with the groundedness of traditional CPD techniques. We\nadopt spectral normalization (SN) for deep representation learning in CPD tasks\nand prove that the embeddings after SN are highly informative for CPD. Our\nmethod significantly outperforms current state-of-the-art methods during the\ncomprehensive evaluation via three standard CPD datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13637v2",
    "published_date": "2024-10-17 15:07:56 UTC",
    "updated_date": "2024-12-03 08:29:54 UTC"
  },
  {
    "arxiv_id": "2410.14744v1",
    "title": "Eliciting Uncertainty in Chain-of-Thought to Mitigate Bias against Forecasting Harmful User Behaviors",
    "authors": [
      "Anthony Sicilia",
      "Malihe Alikhani"
    ],
    "abstract": "Conversation forecasting tasks a model with predicting the outcome of an\nunfolding conversation. For instance, it can be applied in social media\nmoderation to predict harmful user behaviors before they occur, allowing for\npreventative interventions. While large language models (LLMs) have recently\nbeen proposed as an effective tool for conversation forecasting, it's unclear\nwhat biases they may have, especially against forecasting the (potentially\nharmful) outcomes we request them to predict during moderation. This paper\nexplores to what extent model uncertainty can be used as a tool to mitigate\npotential biases. Specifically, we ask three primary research questions: 1) how\ndoes LLM forecasting accuracy change when we ask models to represent their\nuncertainty; 2) how does LLM bias change when we ask models to represent their\nuncertainty; 3) how can we use uncertainty representations to reduce or\ncompletely mitigate biases without many training data points. We address these\nquestions for 5 open-source language models tested on 2 datasets designed to\nevaluate conversation forecasting for social media moderation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14744v1",
    "published_date": "2024-10-17 15:07:53 UTC",
    "updated_date": "2024-10-17 15:07:53 UTC"
  },
  {
    "arxiv_id": "2410.13616v1",
    "title": "Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring",
    "authors": [
      "Kristina Telegraph",
      "Christos Kyrkou"
    ],
    "abstract": "This work presents advancements in multi-class vehicle detection using UAV\ncameras through the development of spatiotemporal object detection models. The\nstudy introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing\n6, 600 annotated sequential frame images captured by UAVs, enabling\ncomprehensive training and evaluation of algorithms for holistic spatiotemporal\nperception. A YOLO-based object detection algorithm is enhanced to incorporate\ntemporal dynamics, resulting in improved performance over single frame models.\nThe integration of attention mechanisms into spatiotemporal models is shown to\nfurther enhance performance. Experimental validation demonstrates significant\nprogress, with the best spatiotemporal model exhibiting a 16.22% improvement\nover single frame models, while it is demonstrated that attention mechanisms\nhold the potential for additional performance gains.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.13616v1",
    "published_date": "2024-10-17 14:49:37 UTC",
    "updated_date": "2024-10-17 14:49:37 UTC"
  },
  {
    "arxiv_id": "2410.13611v1",
    "title": "H2OVL-Mississippi Vision Language Models Technical Report",
    "authors": [
      "Shaikat Galib",
      "Shanshan Wang",
      "Guanshuo Xu",
      "Pascal Pfeiffer",
      "Ryan Chesler",
      "Mark Landry",
      "Sri Satish Ambati"
    ],
    "abstract": "Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13611v1",
    "published_date": "2024-10-17 14:46:34 UTC",
    "updated_date": "2024-10-17 14:46:34 UTC"
  },
  {
    "arxiv_id": "2410.13610v2",
    "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling",
    "authors": [
      "Yakun Zhu",
      "Shaohang Wei",
      "Xu Wang",
      "Kui Xue",
      "Xiaofan Zhang",
      "Shaoting Zhang"
    ],
    "abstract": "Integrating tools into Large Language Models (LLMs) has facilitated the\nwidespread application. Despite this, in specialized downstream task contexts,\nreliance solely on tools is insufficient to fully address the complexities of\nthe real world. This particularly restricts the effective deployment of LLMs in\nfields such as medicine. In this paper, we focus on the downstream tasks of\nmedical calculators, which use standardized tests to assess an individual's\nhealth status. We introduce MeNTi, a universal agent architecture for LLMs.\nMeNTi integrates a specialized medical toolkit and employs meta-tool and nested\ncalling mechanisms to enhance LLM tool utilization. Specifically, it achieves\nflexible tool selection and nested tool calling to address practical issues\nfaced in intricate medical scenarios, including calculator selection, slot\nfilling, and unit conversion. To assess the capabilities of LLMs for\nquantitative assessment throughout the clinical process of calculator\nscenarios, we introduce CalcQA. This benchmark requires LLMs to use medical\ncalculators to perform calculations and assess patient health status. CalcQA is\nconstructed by professional physicians and includes 100 case-calculator pairs,\ncomplemented by a toolkit of 281 medical tools. The experimental results\ndemonstrate significant performance improvements with our framework. This\nresearch paves new directions for applying LLMs in demanding scenarios of\nmedicine.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "NAACL 2025 main conference",
    "pdf_url": "http://arxiv.org/pdf/2410.13610v2",
    "published_date": "2024-10-17 14:46:22 UTC",
    "updated_date": "2025-02-14 16:27:25 UTC"
  },
  {
    "arxiv_id": "2410.13924v2",
    "title": "ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding",
    "authors": [
      "Guangda Ji",
      "Silvan Weder",
      "Francis Engelmann",
      "Marc Pollefeys",
      "Hermann Blum"
    ],
    "abstract": "Neural network performance scales with both model size and data volume, as\nshown in both language and image processing. This requires scaling-friendly\narchitectures and large datasets. While transformers have been adapted for 3D\nvision, a `GPT-moment' remains elusive due to limited training data. We\nintroduce ARKit LabelMaker, a large-scale real-world 3D dataset with dense\nsemantic annotation that is more than three times larger than prior largest\ndataset. Specifically, we extend ARKitScenes with automatically generated dense\n3D labels using an extended LabelMaker pipeline, tailored for large-scale\npre-training. Training on our dataset improves accuracy across architectures,\nachieving state-of-the-art 3D semantic segmentation scores on ScanNet and\nScanNet200, with notable gains on tail classes. Our code is available at\nhttps://labelmaker.org and our dataset at\nhttps://huggingface.co/datasets/labelmaker/arkit_labelmaker.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13924v2",
    "published_date": "2024-10-17 14:44:35 UTC",
    "updated_date": "2025-03-20 10:16:27 UTC"
  },
  {
    "arxiv_id": "2410.14743v1",
    "title": "Efficient Deep Learning Board: Training Feedback Is Not All You Need",
    "authors": [
      "Lina Gong",
      "Qi Gao",
      "Peng Li",
      "Mingqiang Wei",
      "Fei Wu"
    ],
    "abstract": "Current automatic deep learning (i.e., AutoDL) frameworks rely on training\nfeedback from actual runs, which often hinder their ability to provide quick\nand clear performance predictions for selecting suitable DL systems. To address\nthis issue, we propose EfficientDL, an innovative deep learning board designed\nfor automatic performance prediction and component recommendation. EfficientDL\ncan quickly and precisely recommend twenty-seven system components and predict\nthe performance of DL models without requiring any training feedback. The magic\nof no training feedback comes from our proposed comprehensive,\nmulti-dimensional, fine-grained system component dataset, which enables us to\ndevelop a static performance prediction model and comprehensive optimized\ncomponent recommendation algorithm (i.e., {\\alpha}\\b{eta}-BO search), removing\nthe dependency on actually running parameterized models during the traditional\noptimization search process. The simplicity and power of EfficientDL stem from\nits compatibility with most DL models. For example, EfficientDL operates\nseamlessly with mainstream models such as ResNet50, MobileNetV3,\nEfficientNet-B0, MaxViT-T, Swin-B, and DaViT-T, bringing competitive\nperformance improvements. Besides, experimental results on the CIFAR-10 dataset\nreveal that EfficientDL outperforms existing AutoML tools in both accuracy and\nefficiency (approximately 20 times faster along with 1.31% Top-1 accuracy\nimprovement than the cutting-edge methods). Source code, pretrained models, and\ndatasets are available at https://github.com/OpenSELab/EfficientDL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14743v1",
    "published_date": "2024-10-17 14:43:34 UTC",
    "updated_date": "2024-10-17 14:43:34 UTC"
  },
  {
    "arxiv_id": "2410.13604v1",
    "title": "Large Language Models as Narrative-Driven Recommenders",
    "authors": [
      "Lukas Eberhard",
      "Thorsten Ruprechter",
      "Denis Helic"
    ],
    "abstract": "Narrative-driven recommenders aim to provide personalized suggestions for\nuser requests expressed in free-form text such as \"I want to watch a thriller\nwith a mind-bending story, like Shutter Island.\" Although large language models\n(LLMs) have been shown to excel in processing general natural language queries,\ntheir effectiveness for handling such recommendation requests remains\nrelatively unexplored. To close this gap, we compare the performance of 38\nopen- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in\na movie recommendation setting. For this, we utilize a gold-standard,\ncrowdworker-annotated dataset of posts from reddit's movie suggestion community\nand employ various prompting strategies, including zero-shot, identity, and\nfew-shot prompting. Our findings demonstrate the ability of LLMs to generate\ncontextually relevant movie recommendations, significantly outperforming other\nstate-of-the-art approaches, such as doc2vec. While we find that closed-source\nand large-parameterized models generally perform best, medium-sized open-source\nmodels remain competitive, being only slightly outperformed by their more\ncomputationally expensive counterparts. Furthermore, we observe no significant\ndifferences across prompting strategies for most models, underscoring the\neffectiveness of simple approaches such as zero-shot prompting for\nnarrative-driven recommendations. Overall, this work offers valuable insights\nfor recommender system researchers as well as practitioners aiming to integrate\nLLMs into real-world recommendation tools.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "Under review; 19 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.13604v1",
    "published_date": "2024-10-17 14:39:24 UTC",
    "updated_date": "2024-10-17 14:39:24 UTC"
  },
  {
    "arxiv_id": "2410.13597v1",
    "title": "Text-Guided Multi-Property Molecular Optimization with a Diffusion Language Model",
    "authors": [
      "Yida Xiong",
      "Kun Li",
      "Weiwei Liu",
      "Jia Wu",
      "Bo Du",
      "Shirui Pan",
      "Wenbin Hu"
    ],
    "abstract": "Molecular optimization (MO) is a crucial stage in drug discovery in which\ntask-oriented generated molecules are optimized to meet practical industrial\nrequirements. Existing mainstream MO approaches primarily utilize external\nproperty predictors to guide iterative property optimization. However, learning\nall molecular samples in the vast chemical space is unrealistic for predictors.\nAs a result, errors and noise are inevitably introduced during property\nprediction due to the nature of approximation. This leads to discrepancy\naccumulation, generalization reduction and suboptimal molecular candidates. In\nthis paper, we propose a text-guided multi-property molecular optimization\nmethod utilizing transformer-based diffusion language model (TransDLM).\nTransDLM leverages standardized chemical nomenclature as semantic\nrepresentations of molecules and implicitly embeds property requirements into\ntextual descriptions, thereby preventing error propagation during diffusion\nprocess. Guided by physically and chemically detailed textual descriptions,\nTransDLM samples and optimizes encoded source molecules, retaining core\nscaffolds of source molecules and ensuring structural similarities. Moreover,\nTransDLM enables simultaneous sampling of multiple molecules, making it ideal\nfor scalable, efficient large-scale optimization through distributed\ncomputation on web platforms. Furthermore, our approach surpasses\nstate-of-the-art methods in optimizing molecular structural similarity and\nenhancing chemical properties on the benchmark dataset. The code is available\nat: https://anonymous.4open.science/r/TransDLM-A901.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13597v1",
    "published_date": "2024-10-17 14:30:27 UTC",
    "updated_date": "2024-10-17 14:30:27 UTC"
  },
  {
    "arxiv_id": "2410.13592v1",
    "title": "OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope",
    "authors": [
      "Wei Liu",
      "Kerem Delikoyun",
      "Qianyu Chen",
      "Alperen Yildiz",
      "Si Ko Myo",
      "Win Sen Kuan",
      "John Tshon Yit Soong",
      "Matthew Edward Cove",
      "Oliver Hayden",
      "Hweekuan Lee"
    ],
    "abstract": "Off-axis digital holographic microscopy is a high-throughput, label-free\nimaging technology that provides three-dimensional, high-resolution information\nabout samples, particularly useful in large-scale cellular imaging. However,\nthe hologram reconstruction process poses a significant bottleneck for timely\ndata analysis. To address this challenge, we propose a novel reconstruction\napproach that integrates deep learning with the physical principles of off-axis\nholography. We initialized part of the network weights based on the physical\nprinciple and then fine-tuned them via weakly supersized learning. Our off-axis\nhologram network (OAH-Net) retrieves phase and amplitude images with errors\nthat fall within the measurement error range attributable to hardware, and its\nreconstruction speed significantly surpasses the microscope's acquisition rate.\nCrucially, OAH-Net demonstrates remarkable external generalization capabilities\non unseen samples with distinct patterns and can be seamlessly integrated with\nother models for downstream tasks to achieve end-to-end real-time hologram\nanalysis. This capability further expands off-axis holography's applications in\nboth biological and medical studies.",
    "categories": [
      "physics.optics",
      "cs.AI"
    ],
    "primary_category": "physics.optics",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13592v1",
    "published_date": "2024-10-17 14:25:18 UTC",
    "updated_date": "2024-10-17 14:25:18 UTC"
  },
  {
    "arxiv_id": "2410.13570v1",
    "title": "RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging",
    "authors": [
      "Tobias Czempiel",
      "Alfie Roddan",
      "Maria Leiloglou",
      "Zepeng Hu",
      "Kevin O'Neill",
      "Giulio Anichini",
      "Danail Stoyanov",
      "Daniel Elson"
    ],
    "abstract": "This study investigates the reconstruction of hyperspectral signatures from\nRGB data to enhance surgical imaging, utilizing the publicly available\nHeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery\ndataset. Various architectures based on convolutional neural networks (CNNs)\nand transformer models are evaluated using comprehensive metrics. Transformer\nmodels exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by\neffectively integrating spatial information to predict accurate spectral\nprofiles, encompassing both visible and extended spectral ranges. Qualitative\nassessments demonstrate the capability to predict spectral profiles critical\nfor informed surgical decision-making during procedures. Challenges associated\nwith capturing both the visible and extended hyperspectral ranges are\nhighlighted using the MAE, emphasizing the complexities involved. The findings\nopen up the new research direction of hyperspectral reconstruction for surgical\napplications and clinical use cases in real-time surgical environments.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "10 pages, 4 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.13570v1",
    "published_date": "2024-10-17 14:05:41 UTC",
    "updated_date": "2024-10-17 14:05:41 UTC"
  },
  {
    "arxiv_id": "2410.13567v3",
    "title": "CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models",
    "authors": [
      "Yujian Zhao",
      "Chengru Wu",
      "Yinong Xu",
      "Xuanzheng Du",
      "Ruiyu Li",
      "Guanglin Niu"
    ],
    "abstract": "Cloth-changing person re-identification (CC-ReID), also known as Long-Term\nPerson Re-Identification (LT-ReID) is a critical and challenging research topic\nin computer vision that has recently garnered significant attention. However,\ndue to the high cost of constructing CC-ReID data, the existing data-driven\nmodels are hard to train efficiently on limited data, causing overfitting\nissue. To address this challenge, we propose a low-cost and efficient pipeline\nfor generating controllable and high-quality synthetic data simulating the\nsurveillance of real scenarios specific to the CC-ReID task. Particularly, we\nconstruct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal\nPerson (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5\noutfits per individual. Based on this large-scale dataset, we introduce an\neffective and scalable pretrain-finetune framework for enhancing the\ngeneralization capabilities of the traditional CC-ReID models. The extensive\nexperiments demonstrate that two typical models namely TransReID and FIRe^2,\nwhen integrated into our framework, outperform other state-of-the-art models\nafter pretraining on CCUP and finetuning on the benchmarks such as PRCC,\nVC-Clothes and NKUP. The CCUP is available at:\nhttps://github.com/yjzhao1019/CCUP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICME 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13567v3",
    "published_date": "2024-10-17 14:04:02 UTC",
    "updated_date": "2025-03-30 14:17:31 UTC"
  },
  {
    "arxiv_id": "2410.13553v1",
    "title": "Integrating Temporal Representations for Dynamic Memory Retrieval and Management in Large Language Models",
    "authors": [
      "Yuki Hou",
      "Haruki Tamoto",
      "Homei Miyashita"
    ],
    "abstract": "Conventional dialogue agents often struggle with effective memory recall,\nleading to redundant retrieval and inadequate management of unique user\nassociations. To address this, we propose SynapticRAG, a novel approach\nintegrating synaptic dynamics into Retrieval-Augmented Generation (RAG).\nSynapticRAG integrates temporal representations into memory vectors, mimicking\nbiological synapses by differentiating events based on occurrence times and\ndynamically updating memory significance. This model employs temporal scoring\nfor memory connections and a synaptic-inspired propagation control mechanism.\nExperiments across English, Japanese, and Chinese datasets demonstrate\nSynapticRAG's superiority over existing methods, including traditional RAG,\nwith up to 14.66\\% improvement in memory retrieval accuracy. Our approach\nadvances context-aware dialogue AI systems by enhancing long-term context\nmaintenance and specific information extraction from conversations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13553v1",
    "published_date": "2024-10-17 13:51:03 UTC",
    "updated_date": "2024-10-17 13:51:03 UTC"
  },
  {
    "arxiv_id": "2411.00785v1",
    "title": "IGOR: Image-GOal Representations are the Atomic Control Units for Foundation Models in Embodied AI",
    "authors": [
      "Xiaoyu Chen",
      "Junliang Guo",
      "Tianyu He",
      "Chuheng Zhang",
      "Pushi Zhang",
      "Derek Cathera Yang",
      "Li Zhao",
      "Jiang Bian"
    ],
    "abstract": "We introduce Image-GOal Representations (IGOR), aiming to learn a unified,\nsemantically consistent action space across human and various robots. Through\nthis unified latent action space, IGOR enables knowledge transfer among\nlarge-scale robot and human activity data. We achieve this by compressing\nvisual changes between an initial image and its goal state into latent actions.\nIGOR allows us to generate latent action labels for internet-scale video data.\nThis unified latent action space enables the training of foundation policy and\nworld models across a wide variety of tasks performed by both robots and\nhumans. We demonstrate that: (1) IGOR learns a semantically consistent action\nspace for both human and robots, characterizing various possible motions of\nobjects representing the physical interaction knowledge; (2) IGOR can \"migrate\"\nthe movements of the object in the one video to other videos, even across human\nand robots, by jointly using the latent action model and world model; (3) IGOR\ncan learn to align latent actions with natural language through the foundation\npolicy model, and integrate latent actions with a low-level policy model to\nachieve effective robot control. We believe IGOR opens new possibilities for\nhuman-to-robot knowledge transfer and control.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2411.00785v1",
    "published_date": "2024-10-17 13:41:16 UTC",
    "updated_date": "2024-10-17 13:41:16 UTC"
  },
  {
    "arxiv_id": "2410.13523v2",
    "title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?",
    "authors": [
      "Che Liu",
      "Zhongwei Wan",
      "Haozhe Wang",
      "Yinda Chen",
      "Talha Qaiser",
      "Chen Jin",
      "Fariba Yousefi",
      "Nikolay Burlutskiy",
      "Rossella Arcucci"
    ],
    "abstract": "Medical Vision-Language Pre-training (MedVLP) has made significant progress\nin enabling zero-shot tasks for medical image understanding. However, training\nMedVLP models typically requires large-scale datasets with paired, high-quality\nimage-text data, which are scarce in the medical domain. Recent advancements in\nLarge Language Models (LLMs) and diffusion models have made it possible to\ngenerate large-scale synthetic image-text pairs. This raises the question: \"Can\nMedVLP succeed using purely synthetic data?\" To address this, we use\noff-the-shelf generative models to create synthetic radiology reports and\npaired Chest X-ray (CXR) images, and propose an automated pipeline to build a\ndiverse, high-quality synthetic dataset, enabling a rigorous study that\nisolates model and training settings, focusing entirely from the data\nperspective. Our results show that MedVLP models trained exclusively on\nsynthetic data outperform those trained on real data by 3.8% in averaged AUC on\nzero-shot classification. Moreover, using a combination of synthetic and real\ndata leads to a further improvement of 9.07%. Additionally, MedVLP models\ntrained on synthetic or mixed data consistently outperform those trained on\nreal data in zero-shot grounding, as well as in fine-tuned classification and\nsegmentation tasks. Our analysis suggests MedVLP trained on well-designed\nsynthetic data can outperform models trained on real datasets, which may be\nlimited by low-quality samples and long-tailed distributions.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Under Review",
    "pdf_url": "http://arxiv.org/pdf/2410.13523v2",
    "published_date": "2024-10-17 13:11:07 UTC",
    "updated_date": "2025-02-25 06:19:03 UTC"
  },
  {
    "arxiv_id": "2410.13517v2",
    "title": "Bias in the Mirror: Are LLMs opinions robust to their own adversarial attacks ?",
    "authors": [
      "Virgile Rennard",
      "Christos Xypolopoulos",
      "Michalis Vazirgiannis"
    ],
    "abstract": "Large language models (LLMs) inherit biases from their training data and\nalignment processes, influencing their responses in subtle ways. While many\nstudies have examined these biases, little work has explored their robustness\nduring interactions. In this paper, we introduce a novel approach where two\ninstances of an LLM engage in self-debate, arguing opposing viewpoints to\npersuade a neutral version of the model. Through this, we evaluate how firmly\nbiases hold and whether models are susceptible to reinforcing misinformation or\nshifting to harmful viewpoints. Our experiments span multiple LLMs of varying\nsizes, origins, and languages, providing deeper insights into bias persistence\nand flexibility across linguistic and cultural contexts.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13517v2",
    "published_date": "2024-10-17 13:06:02 UTC",
    "updated_date": "2024-11-05 09:08:28 UTC"
  },
  {
    "arxiv_id": "2410.13502v3",
    "title": "MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs",
    "authors": [
      "Andreas Opedal",
      "Haruki Shirakami",
      "Bernhard Schölkopf",
      "Abulhair Saparov",
      "Mrinmaya Sachan"
    ],
    "abstract": "Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to more complex\nproblems. This is difficult to study, as (i) much of the available evaluation\ndata has already been seen by the most capable models during training, and (ii)\nexisting benchmarks do not capture how problem proofs may be arbitrarily\ncomplex in various ways. In this paper, we present a data-generation framework\nfor evaluating LLMs on problems with arbitrarily complex arithmetic proofs,\ncalled MathGAP. MathGAP generates problem statements and chain-of-thought\nreasoning traces according to specifications about their arithmetic proof\nstructure, enabling systematic studies on easy-to-hard generalization with\nrespect to complexity of proof trees. Using MathGAP, we find that LLMs show a\nsignificant decrease in performance as proofs get deeper and wider. This effect\nis more pronounced in complex, nonlinear proof structures, which are\nchallenging even for the most capable models. The models are also sensitive to\nsimple changes in sentence ordering. However, they remain capable of solving\nsome complex problems, suggesting that reasoning generalization is noisy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13502v3",
    "published_date": "2024-10-17 12:48:14 UTC",
    "updated_date": "2025-02-14 18:15:01 UTC"
  },
  {
    "arxiv_id": "2410.13498v2",
    "title": "Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques",
    "authors": [
      "Rahimanuddin Shaik",
      "Katikela Sreeharsha Kishore"
    ],
    "abstract": "Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Disparities in fundamental understandings about the article between\n  the authors",
    "pdf_url": "http://arxiv.org/pdf/2410.13498v2",
    "published_date": "2024-10-17 12:43:49 UTC",
    "updated_date": "2025-01-29 09:53:38 UTC"
  },
  {
    "arxiv_id": "2410.13488v1",
    "title": "Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes",
    "authors": [
      "Dibyanayan Bandyopadhyay",
      "Mohammed Hasanuzzaman",
      "Asif Ekbal"
    ],
    "abstract": "Detecting offensive memes is crucial, yet standard deep neural network\nsystems often remain opaque. Various input attribution-based methods attempt to\ninterpret their behavior, but they face challenges with implicitly offensive\nmemes and non-causal attributions. To address these issues, we propose a\nframework based on a Structural Causal Model (SCM). In this framework,\nVisualBERT is trained to predict the class of an input meme based on both meme\ninput and causal concepts, allowing for transparent interpretation. Our\nqualitative evaluation demonstrates the framework's effectiveness in\nunderstanding model behavior, particularly in determining whether the model was\nright due to the right reason, and in identifying reasons behind\nmisclassification. Additionally, quantitative analysis assesses the\nsignificance of proposed modelling choices, such as de-confounding, adversarial\nlearning, and dynamic routing, and compares them with input attribution\nmethods. Surprisingly, we find that input attribution methods do not guarantee\ncausality within our framework, raising questions about their reliability in\nsafety-critical applications. The project page is at:\nhttps://newcodevelop.github.io/causality_adventure/",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at EMNLP Findings 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.13488v1",
    "published_date": "2024-10-17 12:32:00 UTC",
    "updated_date": "2024-10-17 12:32:00 UTC"
  },
  {
    "arxiv_id": "2411.02400v2",
    "title": "Decomposition Dilemmas: Does Claim Decomposition Boost or Burden Fact-Checking Performance?",
    "authors": [
      "Qisheng Hu",
      "Quanyu Long",
      "Wenya Wang"
    ],
    "abstract": "Fact-checking pipelines increasingly adopt the Decompose-Then-Verify\nparadigm, where texts are broken down into smaller claims for individual\nverification and subsequently combined for a veracity decision. While\ndecomposition is widely-adopted in such pipelines, its effects on final\nfact-checking performance remain underexplored. Some studies have reported\nimprovements from decompostition, while others have observed performance\ndeclines, indicating its inconsistent impact. To date, no comprehensive\nanalysis has been conducted to understand this variability. To address this\ngap, we present an in-depth analysis that explicitly examines the impact of\ndecomposition on downstream verification performance. Through error case\ninspection and experiments, we introduce a categorization of decomposition\nerrors and reveal a trade-off between accuracy gains and the noise introduced\nthrough decomposition. Our analysis provides new insights into understanding\ncurrent system's instability and offers guidance for future studies toward\nimproving claim decomposition in fact-checking pipelines.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "NAACL 2025 Main",
    "pdf_url": "http://arxiv.org/pdf/2411.02400v2",
    "published_date": "2024-10-17 11:45:59 UTC",
    "updated_date": "2025-02-15 12:55:01 UTC"
  },
  {
    "arxiv_id": "2410.13460v1",
    "title": "Breaking the Manual Annotation Bottleneck: Creating a Comprehensive Legal Case Criticality Dataset through Semi-Automated Labeling",
    "authors": [
      "Ronja Stern",
      "Ken Kawamura",
      "Matthias Stürmer",
      "Ilias Chalkidis",
      "Joel Niklaus"
    ],
    "abstract": "Predicting case criticality helps legal professionals in the court system\nmanage large volumes of case law. This paper introduces the Criticality\nPrediction dataset, a new resource for evaluating the potential influence of\nSwiss Federal Supreme Court decisions on future jurisprudence. Unlike existing\napproaches that rely on resource-intensive manual annotations, we\nsemi-automatically derive labels leading to a much larger dataset than\notherwise possible. Our dataset features a two-tier labeling system: (1) the\nLD-Label, which identifies cases published as Leading Decisions (LD), and (2)\nthe Citation-Label, which ranks cases by their citation frequency and recency.\nThis allows for a more nuanced evaluation of case importance. We evaluate\nseveral multilingual models, including fine-tuned variants and large language\nmodels, and find that fine-tuned models consistently outperform zero-shot\nbaselines, demonstrating the need for task-specific adaptation. Our\ncontributions include the introduction of this task and the release of a\nmultilingual dataset to the research community.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2; I.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13460v1",
    "published_date": "2024-10-17 11:43:16 UTC",
    "updated_date": "2024-10-17 11:43:16 UTC"
  },
  {
    "arxiv_id": "2410.13456v1",
    "title": "Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland",
    "authors": [
      "Luca Rolshoven",
      "Vishvaksenan Rasiah",
      "Srinanda Brügger Bose",
      "Matthias Stürmer",
      "Joel Niklaus"
    ],
    "abstract": "Legal research is a time-consuming task that most lawyers face on a daily\nbasis. A large part of legal research entails looking up relevant caselaw and\nbringing it in relation to the case at hand. Lawyers heavily rely on summaries\n(also called headnotes) to find the right cases quickly. However, not all\ndecisions are annotated with headnotes and writing them is time-consuming.\nAutomated headnote creation has the potential to make hundreds of thousands of\ndecisions more accessible for legal research in Switzerland alone. To kickstart\nthis, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a\nnovel cross-lingual resource featuring 18K court rulings from the Swiss Federal\nSupreme Court (SFSC), in German, French, and Italian, along with German\nheadnotes. We fine-tune and evaluate three mT5 variants, along with proprietary\nmodels. Our analysis highlights that while proprietary models perform well in\nzero-shot and one-shot settings, fine-tuned smaller models still provide a\nstrong competitive edge. We publicly release the dataset to facilitate further\nresearch in multilingual legal summarization and the development of assistive\ntechnologies for legal professionals",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50",
      "I.2; I.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13456v1",
    "published_date": "2024-10-17 11:34:07 UTC",
    "updated_date": "2024-10-17 11:34:07 UTC"
  },
  {
    "arxiv_id": "2410.13445v1",
    "title": "Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR",
    "authors": [
      "Abhishek Gupta",
      "Amruta Parulekar",
      "Sameep Chattopadhyay",
      "Preethi Jyothi"
    ],
    "abstract": "Automatic speech recognition (ASR) for low-resource languages remains a\nchallenge due to the scarcity of labeled training data. Parameter-efficient\nfine-tuning and text-only adaptation are two popular methods that have been\nused to address such low-resource settings. In this work, we investigate how\nthese techniques can be effectively combined using a multilingual multimodal\nmodel like SeamlessM4T. Multimodal models are able to leverage unlabeled text\nvia text-only adaptation with further parameter-efficient ASR fine-tuning, thus\nboosting ASR performance. We also show cross-lingual transfer from a\nhigh-resource language, achieving up to a relative 17% WER reduction over a\nbaseline in a zero-shot setting without any labeled speech.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13445v1",
    "published_date": "2024-10-17 11:19:44 UTC",
    "updated_date": "2024-10-17 11:19:44 UTC"
  },
  {
    "arxiv_id": "2410.13441v1",
    "title": "Instruction-Driven Game Engine: A Poker Case Study",
    "authors": [
      "Hongqiu Wu",
      "Xingyuan Liu",
      "Yan Wang",
      "Hai Zhao"
    ],
    "abstract": "The Instruction-Driven Game Engine (IDGE) project aims to democratize game\ndevelopment by enabling a large language model (LLM) to follow free-form game\ndescriptions and generate game-play processes. The IDGE allows users to create\ngames simply by natural language instructions, which significantly lowers the\nbarrier for game development. We approach the learning process for IDGEs as a\nNext State Prediction task, wherein the model autoregressively predicts the\ngame states given player actions. The computation of game states must be\nprecise; otherwise, slight errors could corrupt the game-play experience. This\nis challenging because of the gap between stability and diversity. To address\nthis, we train the IDGE in a curriculum manner that progressively increases its\nexposure to complex scenarios. Our initial progress lies in developing an IDGE\nfor Poker, which not only supports a wide range of poker variants but also\nallows for highly individualized new poker games through natural language\ninputs. This work lays the groundwork for future advancements in transforming\nhow games are created and played.",
    "categories": [
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "EMNLP 2024 Demo. arXiv admin note: substantial text overlap with\n  arXiv:2404.00276",
    "pdf_url": "http://arxiv.org/pdf/2410.13441v1",
    "published_date": "2024-10-17 11:16:27 UTC",
    "updated_date": "2024-10-17 11:16:27 UTC"
  },
  {
    "arxiv_id": "2410.13431v1",
    "title": "Solving Prior Distribution Mismatch in Diffusion Models via Optimal Transport",
    "authors": [
      "Zhanpeng Wang",
      "Shenghao Li",
      "Chen Wang",
      "Shuting Cao",
      "Na Lei",
      "Zhongxuan Luo"
    ],
    "abstract": "In recent years, the knowledge surrounding diffusion models(DMs) has grown\nsignificantly, though several theoretical gaps remain. Particularly noteworthy\nis prior error, defined as the discrepancy between the termination distribution\nof the forward process and the initial distribution of the reverse process. To\naddress these deficiencies, this paper explores the deeper relationship between\noptimal transport(OT) theory and DMs with discrete initial distribution.\nSpecifically, we demonstrate that the two stages of DMs fundamentally involve\ncomputing time-dependent OT. However, unavoidable prior error result in\ndeviation during the reverse process under quadratic transport cost. By proving\nthat as the diffusion termination time increases, the probability flow\nexponentially converges to the gradient of the solution to the classical\nMonge-Amp\\`ere equation, we establish a vital link between these fields.\nTherefore, static OT emerges as the most intrinsic single-step method for\nbridging this theoretical potential gap. Additionally, we apply these insights\nto accelerate sampling in both unconditional and conditional generation\nscenarios. Experimental results across multiple image datasets validate the\neffectiveness of our approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13431v1",
    "published_date": "2024-10-17 10:54:55 UTC",
    "updated_date": "2024-10-17 10:54:55 UTC"
  },
  {
    "arxiv_id": "2410.13415v3",
    "title": "Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting",
    "authors": [
      "Mikael Rinkinen",
      "Lauri Koskinen",
      "Olli Silven",
      "Mehdi Safarpour"
    ],
    "abstract": "Reduced voltage operation is an effective technique for substantial energy\nefficiency improvement in digital circuits. This brief introduces a simple\napproach for enabling reduced voltage operation of Deep Neural Network (DNN)\naccelerators by mere software modifications. Conventional approaches for\nenabling reduced voltage operation e.g., Timing Error Detection (TED) systems,\nincur significant development costs and overheads, while not being applicable\nto the off-the-shelf components. Contrary to those, the solution proposed in\nthis paper relies on algorithm-based error detection, and hence, is implemented\nwith low development costs, does not require any circuit modifications, and is\neven applicable to commodity devices. By showcasing the solution through\nexperimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we\ndemonstrate 18% to 25% energy saving with no accuracy loss of the models and\nnegligible throughput compromise (< 3.9%), considering the overheads from\nintegration of the error detection schemes into the DNN. The integration of\npresented algorithmic solution into the design is simpler when compared\nconventional TED based techniques that require extensive circuit-level\nmodifications, cell library characterizations or special support from the\ndesign tools.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13415v3",
    "published_date": "2024-10-17 10:29:15 UTC",
    "updated_date": "2025-05-09 05:39:31 UTC"
  },
  {
    "arxiv_id": "2410.13413v1",
    "title": "Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models",
    "authors": [
      "Chengyu Du",
      "Jinyi Han",
      "Yizhou Ying",
      "Aili Chen",
      "Qianyu He",
      "Haokun Zhao",
      "Sirui Xia",
      "Haoran Guo",
      "Jiaqing Liang",
      "Zulong Chen",
      "Liangyue Li",
      "Yanghua Xiao"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated that\nprogressive refinement, rather than providing a single answer, results in more\naccurate and thoughtful outputs. However, existing methods often rely heavily\non supervision signals to evaluate previous responses, making it difficult to\nassess output quality in more open-ended scenarios effectively. Additionally,\nthese methods are typically designed for specific tasks, which limits their\ngeneralization to new domains. To address these limitations, we propose\nProgressive Thought Refinement (PTR), a framework that enables LLMs to refine\ntheir responses progressively. PTR operates in two phases: (1) Thought data\nconstruction stage: We propose a weak and strong model collaborative selection\nstrategy to build a high-quality progressive refinement dataset to ensure\nlogical consistency from thought to answers, and the answers are gradually\nrefined in each round. (2) Thought-Mask Fine-Tuning Phase: We design a training\nstructure to mask the \"thought\" and adjust loss weights to encourage LLMs to\nrefine prior thought, teaching them to implicitly understand \"how to improve\"\nrather than \"what is correct.\" Experimental results show that PTR significantly\nenhances LLM performance across ten diverse tasks (avg. from 49.6% to 53.5%)\nwithout task-specific fine-tuning. Notably, in more open-ended tasks, LLMs also\ndemonstrate substantial improvements in the quality of responses beyond mere\naccuracy, suggesting that PTR truly teaches LLMs to self-improve over time.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13413v1",
    "published_date": "2024-10-17 10:23:24 UTC",
    "updated_date": "2024-10-17 10:23:24 UTC"
  },
  {
    "arxiv_id": "2410.13409v2",
    "title": "Attr-Int: A Simple and Effective Entity Alignment Framework for Heterogeneous Knowledge Graphs",
    "authors": [
      "Linyan Yang",
      "Jingwei Cheng",
      "Chuanhao Xu",
      "Xihao Wang",
      "Jiayi Li",
      "Fu Zhang"
    ],
    "abstract": "Entity alignment (EA) refers to the task of linking entities in different\nknowledge graphs (KGs). Existing EA methods rely heavily on structural\nisomorphism. However, in real-world KGs, aligned entities usually have\nnon-isomorphic neighborhood structures, which paralyses the application of\nthese structure-dependent methods. In this paper, we investigate and tackle the\nproblem of entity alignment between heterogeneous KGs. First, we propose two\nnew benchmarks to closely simulate real-world EA scenarios of heterogeneity.\nThen we conduct extensive experiments to evaluate the performance of\nrepresentative EA methods on the new benchmarks. Finally, we propose a simple\nand effective entity alignment framework called Attr-Int, in which innovative\nattribute information interaction methods can be seamlessly integrated with any\nembedding encoder for entity alignment, improving the performance of existing\nentity alignment techniques. Experiments demonstrate that our framework\noutperforms the state-of-the-art approaches on two new benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13409v2",
    "published_date": "2024-10-17 10:16:56 UTC",
    "updated_date": "2024-11-04 12:40:19 UTC"
  },
  {
    "arxiv_id": "2410.13408v2",
    "title": "MoR: Mixture of Ranks for Low-Rank Adaptation Tuning",
    "authors": [
      "Chuanyu Tang",
      "Yilong Chen",
      "Zhenyu Zhang",
      "Junyuan Shang",
      "Wenyuan Zhang",
      "Yong Huang",
      "Tingwen Liu"
    ],
    "abstract": "Low-Rank Adaptation (LoRA) drives research to align its performance with full\nfine-tuning. However, significant challenges remain: (1) Simply increasing the\nrank size of LoRA does not effectively capture high-rank information, which\nleads to a performance bottleneck.(2) MoE-style LoRA methods substantially\nincrease parameters and inference latency, contradicting the goals of efficient\nfine-tuning and ease of application. To address these challenges, we introduce\nMixture of Ranks (MoR), which learns rank-specific information for different\ntasks based on input and efficiently integrates multi-rank information. We\nfirstly propose a new framework that equates the integration of multiple LoRAs\nto expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA\nalready captures sufficient intrinsic information, and MoR can derive high-rank\ninformation through mathematical transformations of the low-rank components.\nThus, MoR can reduces the learning difficulty of LoRA and enhances its\nmulti-task capabilities. MoR achieves impressive results, with MoR delivering a\n1.31\\% performance improvement while using only 93.93\\% of the parameters\ncompared to baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13408v2",
    "published_date": "2024-10-17 10:14:52 UTC",
    "updated_date": "2024-10-18 03:05:01 UTC"
  },
  {
    "arxiv_id": "2410.13919v2",
    "title": "LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild",
    "authors": [
      "Reworr",
      "Dmitrii Volkov"
    ],
    "abstract": "Attacks powered by Large Language Model (LLM) agents represent a growing\nthreat to modern cybersecurity. To address this concern, we present LLM\nHoneypot, a system designed to monitor autonomous AI hacking agents. By\naugmenting a standard SSH honeypot with prompt injection and time-based\nanalysis techniques, our framework aims to distinguish LLM agents among all\nattackers. Over a trial deployment of about three months in a public\nenvironment, we collected 8,130,731 hacking attempts and 8 potential AI agents.\nOur work demonstrates the emergence of AI-driven threats and their current\nlevel of usage, serving as an early warning of malicious LLM agents in the\nwild.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13919v2",
    "published_date": "2024-10-17 09:25:28 UTC",
    "updated_date": "2025-02-10 22:06:36 UTC"
  },
  {
    "arxiv_id": "2410.13374v1",
    "title": "Context-aware adaptive personalised recommendation: a meta-hybrid",
    "authors": [
      "Peter Tibensky",
      "Michal Kompan"
    ],
    "abstract": "Recommenders take place on a wide scale of e-commerce systems, reducing the\nproblem of information overload. The most common approach is to choose a\nrecommender used by the system to make predictions. However, users vary from\neach other; thus, a one-fits-all approach seems to be sub-optimal. In this\npaper, we propose a meta-hybrid recommender that uses machine learning to\npredict an optimal algorithm. In this way, the best-performing recommender is\nused for each specific session and user. This selection depends on contextual\nand preferential information collected about the user. We use standard\nMovieLens and The Movie DB datasets for offline evaluation. We show that based\non the proposed model, it is possible to predict which recommender will provide\nthe most precise recommendations to a user. The theoretical performance of our\nmeta-hybrid outperforms separate approaches by 20-50% in normalized Discounted\nGain and Root Mean Square Error metrics. However, it is hard to obtain the\noptimal performance based on widely-used standard information stored about\nusers.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13374v1",
    "published_date": "2024-10-17 09:24:40 UTC",
    "updated_date": "2024-10-17 09:24:40 UTC"
  },
  {
    "arxiv_id": "2410.13370v2",
    "title": "MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models",
    "authors": [
      "Donghao Zhou",
      "Jiancheng Huang",
      "Jinbin Bai",
      "Jiaze Wang",
      "Hao Chen",
      "Guangyong Chen",
      "Xiaowei Hu",
      "Pheng-Ann Heng"
    ],
    "abstract": "Recent text-to-image models generate high-quality images from text prompts\nbut lack precise control over specific components within visual concepts.\nTherefore, we introduce component-controllable personalization, a new task that\nallows users to customize and reconfigure individual components within\nconcepts. This task faces two challenges: semantic pollution, where undesirable\nelements distort the concept, and semantic imbalance, which leads to\ndisproportionate learning of the target concept and component. To address\nthese, we design MagicTailor, a framework that uses Dynamic Masked Degradation\nto adaptively perturb unwanted visual semantics and Dual-Stream Balancing for\nmore balanced learning of desired visual semantics. The experimental results\nshow that MagicTailor outperforms existing methods in this task and enables\nmore personalized, nuanced, and creative image generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://correr-zhou.github.io/MagicTailor",
    "pdf_url": "http://arxiv.org/pdf/2410.13370v2",
    "published_date": "2024-10-17 09:22:53 UTC",
    "updated_date": "2024-12-06 07:58:07 UTC"
  },
  {
    "arxiv_id": "2410.13360v3",
    "title": "RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models",
    "authors": [
      "Haoran Hao",
      "Jiaming Han",
      "Changsheng Li",
      "Yu-Feng Li",
      "Xiangyu Yue"
    ],
    "abstract": "The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://hoar012.github.io/RAP-Project/.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025. Code: https://github.com/Hoar012/RAP-MLLM",
    "pdf_url": "http://arxiv.org/pdf/2410.13360v3",
    "published_date": "2024-10-17 09:10:26 UTC",
    "updated_date": "2025-03-28 17:28:44 UTC"
  },
  {
    "arxiv_id": "2410.13918v2",
    "title": "FTSmartAudit: A Knowledge Distillation-Enhanced Framework for Automated Smart Contract Auditing Using Fine-Tuned LLMs",
    "authors": [
      "Zhiyuan Wei",
      "Jing Sun",
      "Zijian Zhang",
      "Xianhao Zhang",
      "Meng Li",
      "Mauro Conti"
    ],
    "abstract": "The rise of blockchain technologies has greatly accelerated the development\nand deployment of smart contracts. However, their inherent vulnerabilities and\nsusceptibility to bugs have led to significant financial losses, underscoring\nthe challenges in securing smart contracts. While traditional auditing methods\nare crucial, they often fall short in addressing the increasing complexity and\nvolume of smart contracts. Recent advancements in Large Language Models (LLMs)\noffer promising solutions for enhancing software auditing by automatically\nidentifying security vulnerabilities. Despite their potential, the practical\napplication of these models is hindered by substantial computational demands.\nThis paper investigates the feasibility of using smaller, fine-tuned models to\nachieve comparable or even superior results in smart contract auditing. We\nintroduce the FTSmartAudit framework, which is designed to develop\ncost-effective, specialized models for smart contract auditing through the\nfine-tuning of LLMs. Our contributions include: (1) a single-task learning\nframework that streamlines data preparation, training, evaluation, and\ncontinuous learning; (2) a robust dataset generation method utilizing\ndomain-special knowledge distillation to produce high-quality datasets from\nadvanced models like GPT-4o; (3) an adaptive learning strategy to maintain\nmodel accuracy and robustness; (4) the proven effectiveness of fine-tuned\nmodels in detecting specific vulnerabilities and complex logical errors; and\n(5) a framework that can be extended to other domains requiring LLM solutions.\nOur experimental results demonstrate that smaller models can surpass\nstate-of-the-art commercial models and tools in detecting vulnerabilities in\nsmart contracts.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "26 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13918v2",
    "published_date": "2024-10-17 09:09:09 UTC",
    "updated_date": "2025-02-08 02:57:42 UTC"
  },
  {
    "arxiv_id": "2410.13352v1",
    "title": "LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of the European Court of Human Rights",
    "authors": [
      "Odysseas S. Chlapanis",
      "Dimitrios Galanis",
      "Ion Androutsopoulos"
    ],
    "abstract": "We present Legal Argument Reasoning (LAR), a novel task designed to evaluate\nthe legal reasoning capabilities of Large Language Models (LLMs). The task\nrequires selecting the correct next statement (from multiple choice options) in\na chain of legal arguments from court proceedings, given the facts of the case.\nWe constructed a dataset (LAR-ECHR) for this task using cases from the European\nCourt of Human Rights (ECHR). We evaluated seven general-purpose LLMs on\nLAR-ECHR and found that (a) the ranking of the models is aligned with that of\nLegalBench, an established US-based legal reasoning benchmark, even though\nLAR-ECHR is based on EU law, (b) LAR-ECHR distinguishes top models more\nclearly, compared to LegalBench, (c) even the best model (GPT-4o) obtains 75.8%\naccuracy on LAR-ECHR, indicating significant potential for further model\nimprovement. The process followed to construct LAR-ECHR can be replicated with\ncases from other legal systems.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in Natural Legal Language Processing (NLLP) 2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2410.13352v1",
    "published_date": "2024-10-17 09:03:38 UTC",
    "updated_date": "2024-10-17 09:03:38 UTC"
  },
  {
    "arxiv_id": "2410.13351v1",
    "title": "Representation Learning of Structured Data for Medical Foundation Models",
    "authors": [
      "Vijay Prakash Dwivedi",
      "Viktor Schlegel",
      "Andy T. Liu",
      "Thanh-Tung Nguyen",
      "Abhinav Ramesh Kashyap",
      "Jeng Wei",
      "Wei-Hsian Yin",
      "Stefan Winkler",
      "Robby T. Tan"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious domains, including healthcare. However, their ability to effectively\nrepresent structured non-textual data, such as the alphanumeric medical codes\nused in records like ICD-10 or SNOMED-CT, is limited and has been particularly\nexposed in recent research. This paper examines the challenges LLMs face in\nprocessing medical codes due to the shortcomings of current tokenization\nmethods. As a result, we introduce the UniStruct architecture to design a\nmultimodal medical foundation model of unstructured text and structured data,\nwhich addresses these challenges by adapting subword tokenization techniques\nspecifically for the structured medical codes. Our approach is validated\nthrough model pre-training on both an extensive internal medical database and a\npublic repository of structured medical records. Trained on over 1 billion\ntokens on the internal medical database, the proposed model achieves up to a\n23% improvement in evaluation metrics, with around 2% gain attributed to our\nproposed tokenization. Additionally, when evaluated on the EHRSHOT public\nbenchmark with a 1/1000 fraction of the pre-training data, the UniStruct model\nimproves performance on over 42% of the downstream tasks. Our approach not only\nenhances the representation and generalization capabilities of patient-centric\nmodels but also bridges a critical gap in representation learning models'\nability to handle complex structured medical data, alongside unstructured text.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024 Workshop on Unifying Representations in Neural Models\n  (UniReps 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.13351v1",
    "published_date": "2024-10-17 09:02:28 UTC",
    "updated_date": "2024-10-17 09:02:28 UTC"
  },
  {
    "arxiv_id": "2410.13344v1",
    "title": "Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement",
    "authors": [
      "Yuxuan Liu",
      "Wenyuan Li",
      "Laizhong Cui",
      "Hailiang Yang"
    ],
    "abstract": "Large language models (LLMs) often face a bottleneck in inference speed due\nto their reliance on auto-regressive decoding. Recently, parallel decoding has\nshown significant promise in enhancing inference efficiency. However, we have\nidentified two key issues with existing parallel decoding frameworks: (1)\ndecoding heads fail to balance prediction accuracy and the parallelism of\nexecution, and (2) parallel decoding is not a universal solution, as it can\nbring unnecessary overheads at some challenging decoding steps. To address\nthese issues, we propose Cerberus, an adaptive parallel decoding framework\nintroduces the gating mechanism to enable the LLMs to adaptively choose\nappropriate decoding approaches at each decoding step, along with introducing a\nnew paradigm of decoding heads that introduce the sequential knowledge while\nmaintaining execution parallelism. The experiment results demonstrate that the\nCerberus can achieve up to 2.12x speed up compared to auto-regressive decoding,\nand outperforms one of the leading parallel decoding frameworks, Medusa, with a\n10% - 30% increase in acceleration and superior generation quality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13344v1",
    "published_date": "2024-10-17 08:55:18 UTC",
    "updated_date": "2024-10-17 08:55:18 UTC"
  },
  {
    "arxiv_id": "2410.18127v1",
    "title": "Optimizing Preference Alignment with Differentiable NDCG Ranking",
    "authors": [
      "Jiacong Zhou",
      "Xianyun Wang",
      "Jun Yu"
    ],
    "abstract": "Aligning large language models with human preferences improves interaction\nquality and safety by ensuring outputs better reflect human values. A promising\nstrategy involves Reinforcement Learning from Human Feedback (RLHF), starting\nwith collecting and ranking responses generated by a supervised fine-tuning\nmodel to refine alignment. Current methods (DPO) focus on learning from\npairwise preference data, categorizing responses into preferred and less\npreferred pairs, and optimizing by maximizing pairwise margins. Recent studies\nhave uncovered a substantial discrepancy between the theoretical aspirations of\npreference learning and its real-world results. Current preference alignment\ntechniques underperform expectations, with ranking accuracies below $60\\%$ on\nstandard datasets. This suggests existing methods inadequately capture ideal\npreference relationships within sequences. To address this challenge, this\npaper introduces \\underline{D}irect \\underline{R}anking \\underline{P}reference\n\\underline{O}ptimization (DRPO), a novel method that views human preference\nalignment as a Learning-to-Rank (LTR) task. DRPO leverages NDCG, a widely used\nLTR metric, to optimize the ranking of responses within lists based on\npreference data, thereby enhancing ranking accuracies. Due to the\nnondifferentiability of NDCG, we propose diffNDCG loss, a differentiable\napproximation facilitated by a sorting network to simulate NDCG. Furthermore,\nto improve the quality of generated response, we propose a novel margin-based\nAdaptive Rank Policy Score. Extensive experiments have shown that DRPO\noutperforms existing baseline methods, enhancing the quality of the generated\nresponses.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.18127v1",
    "published_date": "2024-10-17 08:54:57 UTC",
    "updated_date": "2024-10-17 08:54:57 UTC"
  },
  {
    "arxiv_id": "2410.13342v1",
    "title": "DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech",
    "authors": [
      "Jan Melechovsky",
      "Ambuj Mehrish",
      "Berrak Sisman",
      "Dorien Herremans"
    ],
    "abstract": "Recent advancements in Text-to-Speech (TTS) systems have enabled the\ngeneration of natural and expressive speech from textual input. Accented TTS\naims to enhance user experience by making the synthesized speech more relatable\nto minority group listeners, and useful across various applications and\ncontext. Speech synthesis can further be made more flexible by allowing users\nto choose any combination of speaker identity and accent, resulting in a wide\nrange of personalized speech outputs. Current models struggle to disentangle\nspeaker and accent representation, making it difficult to accurately imitate\ndifferent accents while maintaining the same speaker characteristics. We\npropose a novel approach to disentangle speaker and accent representations\nusing multi-level variational autoencoders (ML-VAE) and vector quantization\n(VQ) to improve flexibility and enhance personalization in speech synthesis.\nOur proposed method addresses the challenge of effectively separating speaker\nand accent characteristics, enabling more fine-grained control over the\nsynthesized speech. Code and speech samples are publicly available.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted in Audio Imagination workshop of NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.13342v1",
    "published_date": "2024-10-17 08:51:46 UTC",
    "updated_date": "2024-10-17 08:51:46 UTC"
  },
  {
    "arxiv_id": "2410.13338v1",
    "title": "DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone",
    "authors": [
      "Hongfan Gao",
      "Wangmeng Shen",
      "Xiangfei Qiu",
      "Ronghui Xu",
      "Jilin Hu",
      "Bin Yang"
    ],
    "abstract": "Probabilistic time series imputation has been widely applied in real-world\nscenarios due to its ability to estimate uncertainty of imputation results.\nMeanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great\nsuccess in probabilistic time series imputation tasks with its power to model\ncomplex distributions. However, current DDPM-based probabilistic time series\nimputation methodologies are confronted with two types of challenges:\n1)~\\textit{~The backbone modules of the denoising parts are not capable of\nachieving sequence modeling with low time complexity.} 2)~\\textit{The\narchitecture of denoising modules can not handle the inter-variable and\nbidirectional dependencies in the time series imputation problem effectively.}\nTo address the first challenge, we integrate the computational efficient state\nspace model, namely Mamba, as the backbone denosing module for DDPMs. To tackle\nthe second challenge, we carefully devise several SSM-based blocks for\nbidirectional modeling and inter-variable relation understanding. Experimental\nresults demonstrate that our approach can achieve state-of-the-art time series\nimputation results on multiple datasets, different missing scenarios and\nmissing ratios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13338v1",
    "published_date": "2024-10-17 08:48:52 UTC",
    "updated_date": "2024-10-17 08:48:52 UTC"
  },
  {
    "arxiv_id": "2410.13334v3",
    "title": "BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models",
    "authors": [
      "Isack Lee",
      "Haebin Seong"
    ],
    "abstract": "Although large language models (LLMs) demonstrate impressive proficiency in\nvarious tasks, they present potential safety risks, such as `jailbreaks', where\nmalicious inputs can coerce LLMs into generating harmful content bypassing\nsafety alignments. In this paper, we delve into the ethical biases in LLMs and\nexamine how those biases could be exploited for jailbreaks. Notably, these\nbiases result in a jailbreaking success rate in GPT-4o models that differs by\n20\\% between non-binary and cisgender keywords and by 16\\% between white and\nblack keywords, even when the other parts of the prompts are identical. We\nintroduce the concept of BiasJailbreak, highlighting the inherent risks posed\nby these safety-induced biases. BiasJailbreak generates biased keywords\nautomatically by asking the target LLM itself, and utilizes the keywords to\ngenerate harmful output. Additionally, we propose an efficient defense method\nBiasDefense, which prevents jailbreak attempts by injecting defense prompts\nprior to generation. BiasDefense stands as an appealing alternative to Guard\nModels, such as Llama-Guard, that require additional inference cost after text\ngeneration. Our findings emphasize that ethical biases in LLMs can actually\nlead to generating unsafe output, and suggest a method to make the LLMs more\nsecure and unbiased. To enable further research and improvements, we\nopen-source our code and artifacts of BiasJailbreak, providing the community\nwith tools to better understand and mitigate safety-induced biases in LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13334v3",
    "published_date": "2024-10-17 08:46:09 UTC",
    "updated_date": "2025-01-02 04:06:46 UTC"
  },
  {
    "arxiv_id": "2410.13331v1",
    "title": "Improving Discrete Optimisation Via Decoupled Straight-Through Gumbel-Softmax",
    "authors": [
      "Rushi Shah",
      "Mingyuan Yan",
      "Michael Curtis Mozer",
      "Dianbo Liu"
    ],
    "abstract": "Discrete representations play a crucial role in many deep learning\narchitectures, yet their non-differentiable nature poses significant challenges\nfor gradient-based optimization. To address this issue, various gradient\nestimators have been developed, including the Straight-Through Gumbel-Softmax\n(ST-GS) estimator, which combines the Straight-Through Estimator (STE) and the\nGumbel-based reparameterization trick. However, the performance of ST-GS is\nhighly sensitive to temperature, with its selection often compromising gradient\nfidelity. In this work, we propose a simple yet effective extension to ST-GS by\nemploying decoupled temperatures for forward and backward passes, which we\nrefer to as \"Decoupled ST-GS\". We show that our approach significantly enhances\nthe original ST-GS through extensive experiments across multiple tasks and\ndatasets. We further investigate the impact of our method on gradient fidelity\nfrom multiple perspectives, including the gradient gap and the bias-variance\ntrade-off of estimated gradients. Our findings contribute to the ongoing effort\nto improve discrete optimization in deep learning, offering a practical\nsolution that balances simplicity and effectiveness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13331v1",
    "published_date": "2024-10-17 08:44:57 UTC",
    "updated_date": "2024-10-17 08:44:57 UTC"
  },
  {
    "arxiv_id": "2410.13321v3",
    "title": "Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding",
    "authors": [
      "Kyungmin Min",
      "Minbeom Kim",
      "Kang-il Lee",
      "Dongryeol Lee",
      "Kyomin Jung"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) demonstrate impressive capabilities in\ngenerating detailed and coherent responses from visual inputs. However, they\nare prone to generate hallucinations due to an over-reliance on language\npriors. To address this issue, we investigate the language priors in LVLMs and\nmake two key observations: (1) Even when predicting the tokens associated with\nimage-related part-of-speech (POS), models increasingly rely on linguistic\npriors as the token sequences grow, thereby amplifying hallucinations. (2)\nMethods that directly calibrate LVLM's output distribution to mitigate language\npriors can lead to a degradation in text quality or even exacerbate\nhallucinations. Based on these findings, we propose a novel method,\nSummary-Guided Decoding (SumGD). This method naturally encourages the model to\nfocus more on image information by reducing the text context through summaries,\nwhile controlling only the image-related POS tokens to maintain text quality.\nThrough experiments, we demonstrate that SumGD achieves state-of-the-art\nperformance on object hallucination benchmarks. Furthermore, in terms of the\ntrade-off between precision and recall, SumGD achieves Pareto optimality among\nthe existing methods. Lastly, we observe that although existing methods\nstruggle to balance the reduction of object hallucinations with maintaining\ntext quality, SumGD demonstrates robustness in handling this challenge.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "NAACL 2025 (Findings); Renamed SGD to SumGD in Summary-Guided\n  Decoding to prevent confusion with Stochastic Gradient Descent",
    "pdf_url": "http://arxiv.org/pdf/2410.13321v3",
    "published_date": "2024-10-17 08:24:27 UTC",
    "updated_date": "2025-02-19 05:41:03 UTC"
  },
  {
    "arxiv_id": "2410.13318v1",
    "title": "Computational Approaches to Arabic-English Code-Switching",
    "authors": [
      "Caroline Sabty"
    ],
    "abstract": "Natural Language Processing (NLP) is a vital computational method for\naddressing language processing, analysis, and generation. NLP tasks form the\ncore of many daily applications, from automatic text correction to speech\nrecognition. While significant research has focused on NLP tasks for the\nEnglish language, less attention has been given to Modern Standard Arabic and\nDialectal Arabic. Globalization has also contributed to the rise of\nCode-Switching (CS), where speakers mix languages within conversations and even\nwithin individual words (intra-word CS). This is especially common in Arab\ncountries, where people often switch between dialects or between dialects and a\nforeign language they master. CS between Arabic and English is frequent in\nEgypt, especially on social media. Consequently, a significant amount of\ncode-switched content can be found online. Such code-switched data needs to be\ninvestigated and analyzed for several NLP tasks to tackle the challenges of\nthis multilingual phenomenon and Arabic language challenges. No work has been\ndone before for several integral NLP tasks on Arabic-English CS data. In this\nwork, we focus on the Named Entity Recognition (NER) task and other tasks that\nhelp propose a solution for the NER task on CS data, e.g., Language\nIdentification. This work addresses this gap by proposing and applying\nstate-of-the-art techniques for Modern Standard Arabic and Arabic-English NER.\nWe have created the first annotated CS Arabic-English corpus for the NER task.\nAlso, we apply two enhancement techniques to improve the NER tagger on CS data\nusing CS contextual embeddings and data augmentation techniques. All methods\nshowed improvements in the performance of the NER taggers on CS data. Finally,\nwe propose several intra-word language identification approaches to determine\nthe language type of a mixed text and identify whether it is a named entity or\nnot.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2410.13318v1",
    "published_date": "2024-10-17 08:20:29 UTC",
    "updated_date": "2024-10-17 08:20:29 UTC"
  },
  {
    "arxiv_id": "2410.13314v1",
    "title": "Precipitation Nowcasting Using Diffusion Transformer with Causal Attention",
    "authors": [
      "ChaoRong Li",
      "XuDong Ling",
      "YiLan Xue",
      "Wenjie Luo",
      "LiHong Zhu",
      "FengQing Qin",
      "Yaodong Zhou",
      "Yuanyuan Huang"
    ],
    "abstract": "Short-term precipitation forecasting remains challenging due to the\ndifficulty in capturing long-term spatiotemporal dependencies. Current deep\nlearning methods fall short in establishing effective dependencies between\nconditions and forecast results, while also lacking interpretability. To\naddress this issue, we propose a Precipitation Nowcasting Using Diffusion\nTransformer with Causal Attention model. Our model leverages Transformer and\ncombines causal attention mechanisms to establish spatiotemporal queries\nbetween conditional information (causes) and forecast results (results). This\ndesign enables the model to effectively capture long-term dependencies,\nallowing forecast results to maintain strong causal relationships with input\nconditions over a wide range of time and space. We explore four variants of\nspatiotemporal information interactions for DTCA, demonstrating that global\nspatiotemporal labeling interactions yield the best performance. In addition,\nwe introduce a Channel-To-Batch shift operation to further enhance the model's\nability to represent complex rainfall dynamics. We conducted experiments on two\ndatasets. Compared to state-of-the-art U-Net-based methods, our approach\nimproved the CSI (Critical Success Index) for predicting heavy precipitation by\napproximately 15% and 8% respectively, achieving state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13314v1",
    "published_date": "2024-10-17 08:10:41 UTC",
    "updated_date": "2024-10-17 08:10:41 UTC"
  },
  {
    "arxiv_id": "2410.13310v1",
    "title": "Active inference and deep generative modeling for cognitive ultrasound",
    "authors": [
      "Ruud JG van Sloun"
    ],
    "abstract": "Ultrasound (US) has the unique potential to offer access to medical imaging\nto anyone, everywhere. Devices have become ultra-portable and cost-effective,\nakin to the stethoscope. Nevertheless US image quality and diagnostic efficacy\nare still highly operator- and patient-dependent. In difficult-to-image\npatients, image quality is often insufficient for reliable diagnosis. In this\npaper, we put forth that US imaging systems can be recast as\ninformation-seeking agents that engage in reciprocal interactions with their\nanatomical environment. Such agents autonomously adapt their transmit-receive\nsequences to fully personalize imaging and actively maximize information gain\nin-situ. To that end, we will show that the sequence of pulse-echo experiments\nthat a US system performs can be interpreted as a perception-action loop: the\naction is the data acquisition, probing tissue with acoustic waves and\nrecording reflections at the detection array, and perception is the inference\nof the anatomical and or functional state, potentially including associated\ndiagnostic quantities. We then equip systems with a mechanism to actively\nreduce uncertainty and maximize diagnostic value across a sequence of\nexperiments, treating action and perception jointly using Bayesian inference\ngiven generative models of the environment and action-conditional pulse-echo\nobservations. Since the representation capacity of the generative models\ndictates both the quality of inferred anatomical states and the effectiveness\nof inferred sequences of future imaging actions, we will be greatly leveraging\nthe enormous advances in deep generative modelling that are currently\ndisrupting many fields and society at large. Finally, we show some examples of\ncognitive, closed-loop, US systems that perform active beamsteering and\nadaptive scanline selection, based on deep generative models that track\nanatomical belief states.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13310v1",
    "published_date": "2024-10-17 08:09:14 UTC",
    "updated_date": "2024-10-17 08:09:14 UTC"
  },
  {
    "arxiv_id": "2410.13303v1",
    "title": "Hiformer: Hybrid Frequency Feature Enhancement Inverted Transformer for Long-Term Wind Power Prediction",
    "authors": [
      "Chongyang Wan",
      "Shunbo Lei",
      "Yuan Luo"
    ],
    "abstract": "The increasing severity of climate change necessitates an urgent transition\nto renewable energy sources, making the large-scale adoption of wind energy\ncrucial for mitigating environmental impact. However, the inherent uncertainty\nof wind power poses challenges for grid stability, underscoring the need for\naccurate wind energy prediction models to enable effective power system\nplanning and operation. While many existing studies on wind power prediction\nfocus on short-term forecasting, they often overlook the importance of\nlong-term predictions. Long-term wind power forecasting is essential for\neffective power grid dispatch and market transactions, as it requires careful\nconsideration of weather features such as wind speed and direction, which\ndirectly influence power output. Consequently, methods designed for short-term\npredictions may lead to inaccurate results and high computational costs in\nlong-term settings. To adress these limitations, we propose a novel approach\ncalled Hybrid Frequency Feature Enhancement Inverted Transformer (Hiformer).\nHiformer introduces a unique structure that integrates signal decomposition\ntechnology with weather feature extraction technique to enhance the modeling of\ncorrelations between meteorological conditions and wind power generation.\nAdditionally, Hiformer employs an encoder-only architecture, which reduces the\ncomputational complexity associated with long-term wind power forecasting.\nCompared to the state-of-the-art methods, Hiformer: (i) can improve the\nprediction accuracy by up to 52.5\\%; and (ii) can reduce computational time by\nup to 68.5\\%.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13303v1",
    "published_date": "2024-10-17 08:00:36 UTC",
    "updated_date": "2024-10-17 08:00:36 UTC"
  },
  {
    "arxiv_id": "2410.19809v1",
    "title": "ScreenWriter: Automatic Screenplay Generation and Movie Summarisation",
    "authors": [
      "Louis Mahon",
      "Mirella Lapata"
    ],
    "abstract": "The proliferation of creative video content has driven demand for textual\ndescriptions or summaries that allow users to recall key plot points or get an\noverview without watching. The volume of movie content and speed of turnover\nmotivates automatic summarisation, which is nevertheless challenging, requiring\nidentifying character intentions and very long-range temporal dependencies. The\nfew existing methods attempting this task rely heavily on textual screenplays\nas input, greatly limiting their applicability. In this work, we propose the\ntask of automatic screenplay generation, and a method, ScreenWriter, that\noperates only on video and produces output which includes dialogue, speaker\nnames, scene breaks, and visual descriptions. ScreenWriter introduces a novel\nalgorithm to segment the video into scenes based on the sequence of visual\nvectors, and a novel method for the challenging problem of determining\ncharacter names, based on a database of actors' faces. We further demonstrate\nhow these automatic screenplays can be used to generate plot synopses with a\nhierarchical summarisation method based on scene breaks. We test the quality of\nthe final summaries on the recent MovieSum dataset, which we augment with\nvideos, and show that they are superior to a number of comparison models which\nassume access to goldstandard screenplays.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19809v1",
    "published_date": "2024-10-17 07:59:54 UTC",
    "updated_date": "2024-10-17 07:59:54 UTC"
  },
  {
    "arxiv_id": "2410.13301v1",
    "title": "Automating IETF Insights generation with AI",
    "authors": [
      "Jaime Jiménez"
    ],
    "abstract": "This paper presents the IETF Insights project, an automated system that\nstreamlines the generation of comprehensive reports on the activities of the\nInternet Engineering Task Force (IETF) Working Groups. The system collects,\nconsolidates, and analyzes data from various IETF sources, including meeting\nminutes, participant lists, drafts and agendas. The core components of the\nsystem include data preprocessing code and a report generation module that\nproduces high-quality documents in LaTeX or Markdown. By integrating large\nLanguage Models (LLMs) for summaries based on the data as ground truth, the\nIETF Insights project enhances the accessibility and utility of IETF records,\nproviding a valuable overview of the IETF's activities and contributions to the\ncommunity.",
    "categories": [
      "cs.NI",
      "cs.AI"
    ],
    "primary_category": "cs.NI",
    "comment": "5 pages plus Appendix",
    "pdf_url": "http://arxiv.org/pdf/2410.13301v1",
    "published_date": "2024-10-17 07:59:05 UTC",
    "updated_date": "2024-10-17 07:59:05 UTC"
  },
  {
    "arxiv_id": "2410.13299v2",
    "title": "LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models",
    "authors": [
      "David Hoffmann",
      "Kailash Budhathoki",
      "Matthaeus Kleindessner"
    ],
    "abstract": "The evolving capabilities of large language models are accompanied by growing\nsizes and deployment costs, necessitating effective inference optimisation\ntechniques. We propose a novel pruning method utilising centrality measures\nfrom graph theory, reducing both the computational requirements and the memory\nfootprint of these models. Specifically, we devise a method for creating a\nweighted directed acyclical graph representation of multilayer perceptrons to\nwhich we apply a modified version of the weighted PageRank centrality measure\nto compute node importance scores. In combination with uniform pruning this\nleads to structured sparsity. We call this pruning method MLPRank. Furthermore\nwe introduce an extension to decoder-only transformer models and call it\nLLMRank. For both variants we demonstrate a strong performance. With MLPRank on\naverage leading to 6.09 % higher accuracy retention than three popular\nbaselines and 13.42 % with LLMRank compared to two popular baselines. Code is\navailable at https://github.com/amazon-science/llm-rank-pruning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13299v2",
    "published_date": "2024-10-17 07:55:47 UTC",
    "updated_date": "2024-11-29 11:21:29 UTC"
  },
  {
    "arxiv_id": "2410.13298v1",
    "title": "Advancing Large Language Model Attribution through Self-Improving",
    "authors": [
      "Lei Huang",
      "Xiaocheng Feng",
      "Weitao Ma",
      "Liang Zhao",
      "Yuchun Fan",
      "Weihong Zhong",
      "Dongliang Xu",
      "Qing Yang",
      "Hongtao Liu",
      "Bing Qin"
    ],
    "abstract": "Teaching large language models (LLMs) to generate text with citations to\nevidence sources can mitigate hallucinations and enhance verifiability in\ninformation-seeking systems. However, improving this capability requires\nhigh-quality attribution data, which is costly and labor-intensive. Inspired by\nrecent advances in self-improvement that enhance LLMs without manual\nannotation, we present START, a Self-Taught AttRibuTion framework for\niteratively improving the attribution capability of LLMs. First, to prevent\nmodels from stagnating due to initially insufficient supervision signals, START\nleverages the model to self-construct synthetic training data for warming up.\nTo further self-improve the model's attribution ability, START iteratively\nutilizes fine-grained preference supervision signals constructed from its\nsampled responses to encourage robust, comprehensive, and attributable\ngeneration. Experiments on three open-domain question-answering datasets,\ncovering long-form QA and multi-step reasoning, demonstrate significant\nperformance gains of 25.13% on average without relying on human annotations and\nmore advanced models. Further analysis reveals that START excels in aggregating\ninformation across multiple sources.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP 2024 Main Conference",
    "pdf_url": "http://arxiv.org/pdf/2410.13298v1",
    "published_date": "2024-10-17 07:55:33 UTC",
    "updated_date": "2024-10-17 07:55:33 UTC"
  },
  {
    "arxiv_id": "2410.13296v1",
    "title": "Fairness-Enhancing Ensemble Classification in Water Distribution Networks",
    "authors": [
      "Janine Strotherm",
      "Barbara Hammer"
    ],
    "abstract": "As relevant examples such as the future criminal detection software [1] show,\nfairness of AI-based and social domain affecting decision support tools\nconstitutes an important area of research. In this contribution, we investigate\nthe applications of AI to socioeconomically relevant infrastructures such as\nthose of water distribution networks (WDNs), where fairness issues have yet to\ngain a foothold. To establish the notion of fairness in this domain, we propose\nan appropriate definition of protected groups and group fairness in WDNs as an\nextension of existing definitions. We demonstrate that typical methods for the\ndetection of leakages in WDNs are unfair in this sense. Further, we thus\npropose a remedy to increase the fairness which can be applied even to\nnon-differentiable ensemble classification methods as used in this context.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13296v1",
    "published_date": "2024-10-17 07:53:02 UTC",
    "updated_date": "2024-10-17 07:53:02 UTC"
  },
  {
    "arxiv_id": "2410.13295v2",
    "title": "PiLocNet: Physics-informed neural network on 3D localization with rotating point spread function",
    "authors": [
      "Mingda Lu",
      "Zitian Ao",
      "Chao Wang",
      "Sudhakar Prasad",
      "Raymond H. Chan"
    ],
    "abstract": "For the 3D localization problem using point spread function (PSF)\nengineering, we propose a novel enhancement of our previously introduced\nlocalization neural network, LocNet. The improved network is a physics-informed\nneural network (PINN) that we call PiLocNet. Previous works on the localization\nproblem may be categorized separately into model-based optimization and neural\nnetwork approaches. Our PiLocNet combines the unique strengths of both\napproaches by incorporating forward-model-based information into the network\nvia a data-fitting loss term that constrains the neural network to yield\nresults that are physically sensible. We additionally incorporate certain\nregularization terms from the variational method, which further improves the\nrobustness of the network in the presence of image noise, as we show for the\nPoisson and Gaussian noise models. This framework accords interpretability to\nthe neural network, and the results we obtain show its superiority. Although\nthe paper focuses on the use of single-lobe rotating PSF to encode the full 3D\nsource location, we expect the method to be widely applicable to other PSFs and\nimaging problems that are constrained by known forward processes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "physics.optics"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13295v2",
    "published_date": "2024-10-17 07:49:23 UTC",
    "updated_date": "2025-02-09 09:48:33 UTC"
  },
  {
    "arxiv_id": "2410.13293v2",
    "title": "SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation",
    "authors": [
      "Prakhar Dixit",
      "Tim Oates"
    ],
    "abstract": "Many students struggle with math word problems (MWPs), often finding it\ndifficult to identify key information and select the appropriate mathematical\noperations. Schema-based instruction (SBI) is an evidence-based strategy that\nhelps students categorize problems based on their structure, improving\nproblem-solving accuracy. Building on this, we propose a Schema-Based\nInstruction Retrieval-Augmented Generation (SBI-RAG) framework that\nincorporates a large language model (LLM). Our approach emphasizes step-by-step\nreasoning by leveraging schemas to guide solution generation. We evaluate its\nperformance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,\nand introduce a \"reasoning score\" metric to assess solution quality. Our\nfindings suggest that SBI-RAG enhances reasoning clarity and facilitates a more\nstructured problem-solving process potentially providing educational benefits\nfor students.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the 4th MATH-AI Workshop at NeurIPS'24",
    "pdf_url": "http://arxiv.org/pdf/2410.13293v2",
    "published_date": "2024-10-17 07:46:49 UTC",
    "updated_date": "2024-11-10 08:53:38 UTC"
  },
  {
    "arxiv_id": "2410.14739v1",
    "title": "Toward a Unified Graph-Based Representation of Medical Data for Precision Oncology Medicine",
    "authors": [
      "Davide Belluomo",
      "Tiziana Calamoneri",
      "Giacomo Paesani",
      "Ivano Salvo"
    ],
    "abstract": "We present a new unified graph-based representation of medical data,\ncombining genetic information and medical records of patients with medical\nknowledge via a unique knowledge graph. This approach allows us to infer\nmeaningful information and explanations that would be unavailable by looking at\neach data set separately. The systematic use of different databases, managed\nthroughout the built knowledge graph, gives new insights toward a better\nunderstanding of oncology medicine. Indeed, we reduce some useful medical tasks\nto well-known problems in theoretical computer science for which efficient\nalgorithms exist.",
    "categories": [
      "cs.AI",
      "68T30",
      "E.1; J.3"
    ],
    "primary_category": "cs.AI",
    "comment": "19 pages, 1 figure, 14 tables, CIBB 2024 conference",
    "pdf_url": "http://arxiv.org/pdf/2410.14739v1",
    "published_date": "2024-10-17 07:43:48 UTC",
    "updated_date": "2024-10-17 07:43:48 UTC"
  },
  {
    "arxiv_id": "2410.13284v2",
    "title": "Learning to Route LLMs with Confidence Tokens",
    "authors": [
      "Yu-Neng Chuang",
      "Helen Zhou",
      "Prathusha Kameswara Sarma",
      "Parikshit Gopalan",
      "John Boccio",
      "Sara Bolouki",
      "Xia Hu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive performance on\nseveral tasks and are increasingly deployed in real-world applications.\nHowever, especially in high-stakes settings, it becomes vital to know when the\noutput of an LLM may be unreliable. Depending on whether an answer is\ntrustworthy, a system can then choose to route the question to another expert,\nor otherwise fall back on a safe default behavior. In this work, we study the\nextent to which LLMs can reliably indicate confidence in their answers, and how\nthis notion of confidence can translate into downstream accuracy gains. We\npropose Self-REF, a lightweight training strategy to teach LLMs to express\nconfidence in whether their answers are correct in a reliable manner. Self-REF\nintroduces confidence tokens into the LLM, from which a confidence score can be\nextracted. Compared to conventional approaches such as verbalizing confidence\nand examining token probabilities, we demonstrate empirically that confidence\ntokens show significant improvements in downstream routing and rejection\nlearning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13284v2",
    "published_date": "2024-10-17 07:28:18 UTC",
    "updated_date": "2025-02-04 21:38:52 UTC"
  },
  {
    "arxiv_id": "2411.00784v2",
    "title": "FIRE: Fact-checking with Iterative Retrieval and Verification",
    "authors": [
      "Zhuohan Xie",
      "Rui Xing",
      "Yuxia Wang",
      "Jiahui Geng",
      "Hasan Iqbal",
      "Dhruv Sahnan",
      "Iryna Gurevych",
      "Preslav Nakov"
    ],
    "abstract": "Fact-checking long-form text is challenging, and it is therefore common\npractice to break it down into multiple atomic claims. The typical approach to\nfact-checking these atomic claims involves retrieving a fixed number of pieces\nof evidence, followed by a verification step. However, this method is usually\nnot cost-effective, as it underutilizes the verification model's internal\nknowledge of the claim and fails to replicate the iterative reasoning process\nin human search strategies. To address these limitations, we propose FIRE, a\nnovel agent-based framework that integrates evidence retrieval and claim\nverification in an iterative manner. Specifically, FIRE employs a unified\nmechanism to decide whether to provide a final answer or generate a subsequent\nsearch query, based on its confidence in the current judgment. We compare FIRE\nwith other strong fact-checking frameworks and find that it achieves slightly\nbetter performance while reducing large language model (LLM) costs by an\naverage of 7.6 times and search costs by 16.5 times. These results indicate\nthat FIRE holds promise for application in large-scale fact-checking\noperations. Our code is available at https://github.com/mbzuai-nlp/fire.git.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "4 figures, 8 tables, accepted to Findings of NAACL",
    "pdf_url": "http://arxiv.org/pdf/2411.00784v2",
    "published_date": "2024-10-17 06:44:18 UTC",
    "updated_date": "2025-02-12 06:34:11 UTC"
  },
  {
    "arxiv_id": "2410.13268v1",
    "title": "Roadmap towards Superhuman Speech Understanding using Large Language Models",
    "authors": [
      "Fan Bu",
      "Yuhao Zhang",
      "Xidong Wang",
      "Benyou Wang",
      "Qun Liu",
      "Haizhou Li"
    ],
    "abstract": "The success of large language models (LLMs) has prompted efforts to integrate\nspeech and audio data, aiming to create general foundation models capable of\nprocessing both textual and non-textual inputs. Recent advances, such as\nGPT-4o, highlight the potential for end-to-end speech LLMs, which preserves\nnon-semantic information and world knowledge for deeper speech understanding.\nTo guide the development of speech LLMs, we propose a five-level roadmap,\nranging from basic automatic speech recognition (ASR) to advanced superhuman\nmodels capable of integrating non-semantic information with abstract acoustic\nknowledge for complex tasks. Moreover, we design a benchmark, SAGI Bechmark,\nthat standardizes critical aspects across various tasks in these five levels,\nuncovering challenges in using abstract acoustic knowledge and completeness of\ncapability. Our findings reveal gaps in handling paralinguistic cues and\nabstract acoustic knowledge, and we offer future directions. This paper\noutlines a roadmap for advancing speech LLMs, introduces a benchmark for\nevaluation, and provides key insights into their current limitations and\npotential.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13268v1",
    "published_date": "2024-10-17 06:44:06 UTC",
    "updated_date": "2024-10-17 06:44:06 UTC"
  },
  {
    "arxiv_id": "2410.13264v1",
    "title": "The Latent Road to Atoms: Backmapping Coarse-grained Protein Structures with Latent Diffusion",
    "authors": [
      "Xu Han",
      "Yuancheng Sun",
      "Kai Chen",
      "Kang Liu",
      "Qiwei Ye"
    ],
    "abstract": "Coarse-grained(CG) molecular dynamics simulations offer computational\nefficiency for exploring protein conformational ensembles and thermodynamic\nproperties. Though coarse representations enable large-scale simulations across\nextended temporal and spatial ranges, the sacrifice of atomic-level details\nlimits their utility in tasks such as ligand docking and protein-protein\ninteraction prediction. Backmapping, the process of reconstructing all-atom\nstructures from coarse-grained representations, is crucial for recovering these\nfine details. While recent machine learning methods have made strides in\nprotein structure generation, challenges persist in reconstructing diverse\natomistic conformations that maintain geometric accuracy and chemical validity.\nIn this paper, we present Latent Diffusion Backmapping (LDB), a novel approach\nleveraging denoising diffusion within latent space to address these challenges.\nBy combining discrete latent encoding with diffusion, LDB bypasses the need for\nequivariant and internal coordinate manipulation, significantly simplifying the\ntraining and sampling processes as well as facilitating better and wider\nexploration in configuration space. We evaluate LDB's state-of-the-art\nperformance on three distinct protein datasets, demonstrating its ability to\nefficiently reconstruct structures with high structural accuracy and chemical\nvalidity. Moreover, LDB shows exceptional versatility in capturing diverse\nprotein ensembles, highlighting its capability to explore intricate\nconformational spaces. Our results position LDB as a powerful and scalable\napproach for backmapping, effectively bridging the gap between CG simulations\nand atomic-level analyses in computational biology.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Paper under review",
    "pdf_url": "http://arxiv.org/pdf/2410.13264v1",
    "published_date": "2024-10-17 06:38:07 UTC",
    "updated_date": "2024-10-17 06:38:07 UTC"
  },
  {
    "arxiv_id": "2410.13263v1",
    "title": "A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Knowledge Graphs Alignment",
    "authors": [
      "Weishan Cai",
      "Wenjun Ma",
      "Yuncheng Jiang"
    ],
    "abstract": "The success of current Entity Alignment (EA) task depends largely on the\nsupervision information provided by labeled data. Considering the cost of\nlabeled data, most supervised methods are difficult to apply in practical\nscenarios. Therefore, more and more works based on contrastive learning, active\nlearning or other deep learning techniques have been developed, to solve the\nperformance bottleneck caused by the lack of labeled data. However, the\nexisting unsupervised EA methods still have some limitations, either their\nmodeling complexity is high or they cannot balance the effectiveness and\npracticality of alignment. To overcome these issues, we propose a Simplifying\nand Learnable graph convolutional attention network for Unsupervised Knowledge\nGraphs alignment method (SLU). Specifically, we first introduce LCAT, a new and\nsimple framework as the backbone network to model the graph structure of two\nKGs. Then we design a reconstruction method of relation structure based on\npotential matching relations for efficiently filtering invalid neighborhood\ninformation of aligned entities, to improve the usability and scalability of\nSLU. Impressively, a similarity function based on consistency is proposed to\nbetter measure the similarity of candidate entity pairs. Finally, we conduct\nextensive experiments on three datasets of different sizes (15K and 100K) and\ndifferent types (cross-lingual and monolingual) to verify the superiority of\nSLU. Experimental results show that SLU significantly improves alignment\naccuracy, outperforming 25 supervised or unsupervised methods, and improving\n6.4% in Hits@1 over the best baseline in the best case.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13263v1",
    "published_date": "2024-10-17 06:37:46 UTC",
    "updated_date": "2024-10-17 06:37:46 UTC"
  },
  {
    "arxiv_id": "2410.13257v1",
    "title": "scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers",
    "authors": [
      "Dian Meng",
      "Bohao Xing",
      "Xinlei Huang",
      "Yanran Liu",
      "Yijun Zhou",
      "Yongjun xiao",
      "Zitong Yu",
      "Xubin Zheng"
    ],
    "abstract": "Single-cell multi-omics (scMulti-omics) refers to the paired multimodal data,\nsuch as Cellular Indexing of Transcriptomes and Epitopes by Sequencing\n(CITE-seq), where the regulation of each cell was measured from different\nmodalities, i.e. genes and proteins. scMulti-omics can reveal heterogeneity\ninside tumors and understand the distinct genetic properties of diverse cell\ntypes, which is crucial to targeted therapy. Currently, deep learning methods\nbased on attention structures in the bioinformatics area face two challenges.\nThe first challenge is the vast number of genes in a single cell. Traditional\nattention-based modules struggled to effectively leverage all gene information\ndue to their limited capacity for long-context learning and high-complexity\ncomputing. The second challenge is that genes in the human genome are ordered\nand influence each other's expression. Most of the methods ignored this\nsequential information. The recently introduced Test-Time Training (TTT) layer\nis a novel sequence modeling approach, particularly suitable for handling long\ncontexts like genomics data because TTT layer is a linear complexity sequence\nmodeling structure and is better suited to data with sequential relationships.\nIn this paper, we propose scFusionTTT, a novel method for Single-Cell\nmultimodal omics Fusion with TTT-based masked autoencoder. Of note, we combine\nthe order information of genes and proteins in the human genome with the TTT\nlayer, fuse multimodal omics, and enhance unimodal omics analysis. Finally, the\nmodel employs a three-stage training strategy, which yielded the best\nperformance across most metrics in four multimodal omics datasets and four\nunimodal omics datasets, demonstrating the superior performance of our model.\nThe dataset and code will be available on\nhttps://github.com/DM0815/scFusionTTT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13257v1",
    "published_date": "2024-10-17 06:29:29 UTC",
    "updated_date": "2024-10-17 06:29:29 UTC"
  },
  {
    "arxiv_id": "2410.13255v1",
    "title": "Automatic Translation Alignment Pipeline for Multilingual Digital Editions of Literary Works",
    "authors": [
      "Maria Levchenko"
    ],
    "abstract": "This paper investigates the application of translation alignment algorithms\nin the creation of a Multilingual Digital Edition (MDE) of Alessandro Manzoni's\nItalian novel \"I promessi sposi\" (\"The Betrothed\"), with translations in eight\nlanguages (English, Spanish, French, German, Dutch, Polish, Russian and\nChinese) from the 19th and 20th centuries. We identify key requirements for the\nMDE to improve both the reader experience and support for translation studies.\nOur research highlights the limitations of current state-of-the-art algorithms\nwhen applied to the translation of literary texts and outlines an automated\npipeline for MDE creation. This pipeline transforms raw texts into web-based,\nside-by-side representations of original and translated texts with different\nrendering options. In addition, we propose new metrics for evaluating the\nalignment of literary translations and suggest visualization techniques for\nfuture analysis.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68U15",
      "J.5; I.7.4"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, Computational Humanities Research Conference, December 4-6,\n  2024, Aarhus, Denmark",
    "pdf_url": "http://arxiv.org/pdf/2410.13255v1",
    "published_date": "2024-10-17 06:21:38 UTC",
    "updated_date": "2024-10-17 06:21:38 UTC"
  },
  {
    "arxiv_id": "2410.13250v1",
    "title": "Perceptions of Discriminatory Decisions of Artificial Intelligence: Unpacking the Role of Individual Characteristics",
    "authors": [
      "Soojong Kim"
    ],
    "abstract": "This study investigates how personal differences (digital self-efficacy,\ntechnical knowledge, belief in equality, political ideology) and demographic\nfactors (age, education, and income) are associated with perceptions of\nartificial intelligence (AI) outcomes exhibiting gender and racial bias and\nwith general attitudes towards AI. Analyses of a large-scale experiment dataset\n(N = 1,206) indicate that digital self-efficacy and technical knowledge are\npositively associated with attitudes toward AI, while liberal ideologies are\nnegatively associated with outcome trust, higher negative emotion, and greater\nskepticism. Furthermore, age and income are closely connected to cognitive gaps\nin understanding discriminatory AI outcomes. These findings highlight the\nimportance of promoting digital literacy skills and enhancing digital\nself-efficacy to maintain trust in AI and beliefs in AI usefulness and safety.\nThe findings also suggest that the disparities in understanding problematic AI\noutcomes may be aligned with economic inequalities and generational gaps in\nsociety. Overall, this study sheds light on the socio-technological system in\nwhich complex interactions occur between social hierarchies, divisions, and\nmachines that reflect and exacerbate the disparities.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13250v1",
    "published_date": "2024-10-17 06:18:26 UTC",
    "updated_date": "2024-10-17 06:18:26 UTC"
  },
  {
    "arxiv_id": "2410.13248v1",
    "title": "Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation",
    "authors": [
      "Ryotaro Shimizu",
      "Takashi Wada",
      "Yu Wang",
      "Johannes Kruse",
      "Sean O'Brien",
      "Sai HtaungKham",
      "Linxin Song",
      "Yuya Yoshikawa",
      "Yuki Saito",
      "Fugee Tsung",
      "Masayuki Goto",
      "Julian McAuley"
    ],
    "abstract": "Recent research on explainable recommendation generally frames the task as a\nstandard text generation problem, and evaluates models simply based on the\ntextual similarity between the predicted and ground-truth explanations.\nHowever, this approach fails to consider one crucial aspect of the systems:\nwhether their outputs accurately reflect the users' (post-purchase) sentiments,\ni.e., whether and why they would like and/or dislike the recommended items. To\nshed light on this issue, we introduce new datasets and evaluation methods that\nfocus on the users' sentiments. Specifically, we construct the datasets by\nexplicitly extracting users' positive and negative opinions from their\npost-purchase reviews using an LLM, and propose to evaluate systems based on\nwhether the generated explanations 1) align well with the users' sentiments,\nand 2) accurately identify both positive and negative opinions of users on the\ntarget items. We benchmark several recent models on our datasets and\ndemonstrate that achieving strong performance on existing metrics does not\nensure that the generated explanations align well with the users' sentiments.\nLastly, we find that existing models can provide more sentiment-aware\nexplanations when the users' (predicted) ratings for the target items are\ndirectly fed into the models as input. We will release our code and datasets\nupon acceptance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13248v1",
    "published_date": "2024-10-17 06:15:00 UTC",
    "updated_date": "2024-10-17 06:15:00 UTC"
  },
  {
    "arxiv_id": "2410.13247v2",
    "title": "Collaborative AI in Sentiment Analysis: System Architecture, Data Prediction and Deployment Strategies",
    "authors": [
      "Chaofeng Zhang",
      "Jia Hou",
      "Xueting Tan",
      "Gaolei Li",
      "Caijuan Chen"
    ],
    "abstract": "The advancement of large language model (LLM) based artificial intelligence\ntechnologies has been a game-changer, particularly in sentiment analysis. This\nprogress has enabled a shift from highly specialized research environments to\npractical, widespread applications within the industry. However, integrating\ndiverse AI models for processing complex multimodal data and the associated\nhigh costs of feature extraction presents significant challenges. Motivated by\nthe marketing oriented software development +needs, our study introduces a\ncollaborative AI framework designed to efficiently distribute and resolve tasks\nacross various AI systems to address these issues. Initially, we elucidate the\nkey solutions derived from our development process, highlighting the role of\ngenerative AI models like \\emph{chatgpt}, \\emph{google gemini} in simplifying\nintricate sentiment analysis tasks into manageable, phased objectives.\nFurthermore, we present a detailed case study utilizing our collaborative AI\nsystem in edge and cloud, showcasing its effectiveness in analyzing sentiments\nacross diverse online media channels.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13247v2",
    "published_date": "2024-10-17 06:14:34 UTC",
    "updated_date": "2024-10-23 11:09:57 UTC"
  },
  {
    "arxiv_id": "2410.13246v1",
    "title": "Atomic Calibration of LLMs in Long-Form Generations",
    "authors": [
      "Caiqi Zhang",
      "Ruihan Yang",
      "Zhisong Zhang",
      "Xinting Huang",
      "Sen Yang",
      "Dong Yu",
      "Nigel Collier"
    ],
    "abstract": "Large language models (LLMs) often suffer from hallucinations, posing\nsignificant challenges for real-world applications. Confidence calibration,\nwhich estimates the underlying uncertainty of model predictions, is essential\nto enhance the LLMs' trustworthiness. Existing research on LLM calibration has\nprimarily focused on short-form tasks, providing a single confidence score at\nthe response level (macro calibration). However, this approach is insufficient\nfor long-form generations, where responses often contain more complex\nstatements and may include both accurate and inaccurate information. Therefore,\nwe introduce atomic calibration, a novel approach that evaluates factuality\ncalibration at a fine-grained level by breaking down long responses into atomic\nclaims. We classify confidence elicitation methods into discriminative and\ngenerative types and demonstrate that their combination can enhance\ncalibration. Our extensive experiments on various LLMs and datasets show that\natomic calibration is well-suited for long-form generation and can also improve\nmacro calibration results. Additionally, atomic calibration reveals insightful\npatterns in LLM confidence throughout the generation process.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13246v1",
    "published_date": "2024-10-17 06:09:26 UTC",
    "updated_date": "2024-10-17 06:09:26 UTC"
  },
  {
    "arxiv_id": "2410.19808v1",
    "title": "LocateBench: Evaluating the Locating Ability of Vision Language Models",
    "authors": [
      "Ting-Rui Chiang",
      "Joshua Robinson",
      "Xinyan Velocity Yu",
      "Dani Yogatama"
    ],
    "abstract": "The ability to locate an object in an image according to natural language\ninstructions is crucial for many real-world applications. In this work we\npropose LocateBench, a high-quality benchmark dedicated to evaluating this\nability. We experiment with multiple prompting approaches, and measure the\naccuracy of several large vision language models. We find that even the\naccuracy of the strongest model, GPT-4o, lags behind human accuracy by more\nthan 10%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "We release the dataset at\n  https://usc-tamagotchi.github.io/locate-bench/",
    "pdf_url": "http://arxiv.org/pdf/2410.19808v1",
    "published_date": "2024-10-17 05:48:24 UTC",
    "updated_date": "2024-10-17 05:48:24 UTC"
  },
  {
    "arxiv_id": "2410.13237v2",
    "title": "Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis",
    "authors": [
      "Yiyi Chen",
      "Qiongxiu Li",
      "Russa Biswas",
      "Johannes Bjerva"
    ],
    "abstract": "Language Confusion is a phenomenon where Large Language Models (LLMs)\ngenerate text that is neither in the desired language, nor in a contextually\nappropriate language. This phenomenon presents a critical challenge in text\ngeneration by LLMs, often appearing as erratic and unpredictable behavior. We\nhypothesize that there are linguistic regularities to this inherent\nvulnerability in LLMs and shed light on patterns of language confusion across\nLLMs. We introduce a novel metric, Language Confusion Entropy, designed to\ndirectly measure and quantify this confusion, based on language distributions\ninformed by linguistic typology and lexical variation. Comprehensive\ncomparisons with the Language Confusion Benchmark (Marchisio et al., 2024)\nconfirm the effectiveness of our metric, revealing patterns of language\nconfusion across LLMs. We further link language confusion to LLM security, and\nfind patterns in the case of multilingual embedding inversion attacks. Our\nanalysis demonstrates that linguistic typology offers theoretically grounded\ninterpretation, and valuable insights into leveraging language similarities as\na prior for LLM alignment and security.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "I.1.2; I.1.5"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 15 figures, 14 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.13237v2",
    "published_date": "2024-10-17 05:43:30 UTC",
    "updated_date": "2025-02-09 13:16:16 UTC"
  },
  {
    "arxiv_id": "2411.00783v1",
    "title": "From chalkboards to chatbots: SELAR assists teachers in embracing AI in the curriculum",
    "authors": [
      "Hani Alers",
      "Aleksandra Malinowska",
      "Mathis Mourey",
      "Jasper Waaijer"
    ],
    "abstract": "This paper introduces SELAR, a framework designed to effectively help\nteachers integrate artificial intelligence (AI) into their curriculum. The\nframework was designed by running workshops organized to gather lecturers'\nfeedback. In this paper, we assess the effectiveness of the framework through\nadditional workshops organized with lecturers from the Hague University of\nApplied Sciences. The workshops tested the application of the framework to\nadapt existing courses to leverage generative AI technology. Each participant\nwas tasked to apply SELAR to one of their learning goals in order to evaluate\nAI integration potential and, if successful, to update the teaching methods\naccordingly. Findings show that teachers were able to effectively use the SELAR\nto integrate generative AI into their courses. Future work will focus on\nproviding additional guidance and examples to use the framework more\neffectively.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2411.00783v1",
    "published_date": "2024-10-17 05:40:59 UTC",
    "updated_date": "2024-10-17 05:40:59 UTC"
  },
  {
    "arxiv_id": "2410.13236v1",
    "title": "SPIN: Self-Supervised Prompt INjection",
    "authors": [
      "Leon Zhou",
      "Junfeng Yang",
      "Chengzhi Mao"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly used in a variety of important\napplications, yet their safety and reliability remain as major concerns.\nVarious adversarial and jailbreak attacks have been proposed to bypass the\nsafety alignment and cause the model to produce harmful responses. We introduce\nSelf-supervised Prompt INjection (SPIN) which can detect and reverse these\nvarious attacks on LLMs. As our self-supervised prompt defense is done at\ninference-time, it is also compatible with existing alignment and adds an\nadditional layer of safety for defense. Our benchmarks demonstrate that our\nsystem can reduce the attack success rate by up to 87.9%, while maintaining the\nperformance on benign user requests. In addition, we discuss the situation of\nan adaptive attacker and show that our method is still resilient against\nattackers who are aware of our defense.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13236v1",
    "published_date": "2024-10-17 05:40:54 UTC",
    "updated_date": "2024-10-17 05:40:54 UTC"
  },
  {
    "arxiv_id": "2410.13229v2",
    "title": "Quamba: A Post-Training Quantization Recipe for Selective State Space Models",
    "authors": [
      "Hung-Yueh Chiang",
      "Chi-Chih Chang",
      "Natalia Frumkin",
      "Kai-Chiang Wu",
      "Diana Marculescu"
    ],
    "abstract": "State Space Models (SSMs) have emerged as an appealing alternative to\nTransformers for large language models, achieving state-of-the-art accuracy\nwith constant memory complexity which allows for holding longer context lengths\nthan attention-based networks. The superior computational efficiency of SSMs in\nlong sequence modeling positions them favorably over Transformers in many\nscenarios. However, improving the efficiency of SSMs on request-intensive\ncloud-serving and resource-limited edge applications is still a formidable\ntask. SSM quantization is a possible solution to this problem, making SSMs more\nsuitable for wide deployment, while still maintaining their accuracy.\nQuantization is a common technique to reduce the model size and to utilize the\nlow bit-width acceleration features on modern computing units, yet existing\nquantization techniques are poorly suited for SSMs. Most notably, SSMs have\nhighly sensitive feature maps within the selective scan mechanism (i.e., linear\nrecurrence) and massive outliers in the output activations which are not\npresent in the output of token-mixing in the self-attention modules. To address\nthis issue, we propose a static 8-bit per-tensor SSM quantization method which\nsuppresses the maximum values of the input activations to the selective SSM for\nfiner quantization precision and quantizes the output activations in an\noutlier-free space with Hadamard transform. Our 8-bit weight-activation\nquantized Mamba 2.8B SSM benefits from hardware acceleration and achieves a\n1.72x lower generation latency on an Nvidia Orin Nano 8G, with only a 0.9% drop\nin average accuracy on zero-shot tasks. The experiments demonstrate the\neffectiveness and practical applicability of our approach for deploying\nSSM-based models of all sizes on both cloud and edge platforms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13229v2",
    "published_date": "2024-10-17 05:32:33 UTC",
    "updated_date": "2024-12-07 07:27:00 UTC"
  },
  {
    "arxiv_id": "2410.13228v2",
    "title": "From PINNs to PIKANs: Recent Advances in Physics-Informed Machine Learning",
    "authors": [
      "Juan Diego Toscano",
      "Vivek Oommen",
      "Alan John Varghese",
      "Zongren Zou",
      "Nazanin Ahmadi Daryakenari",
      "Chenxi Wu",
      "George Em Karniadakis"
    ],
    "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a key tool in\nScientific Machine Learning since their introduction in 2017, enabling the\nefficient solution of ordinary and partial differential equations using sparse\nmeasurements. Over the past few years, significant advancements have been made\nin the training and optimization of PINNs, covering aspects such as network\narchitectures, adaptive refinement, domain decomposition, and the use of\nadaptive weights and activation functions. A notable recent development is the\nPhysics-Informed Kolmogorov-Arnold Networks (PIKANS), which leverage a\nrepresentation model originally proposed by Kolmogorov in 1957, offering a\npromising alternative to traditional PINNs. In this review, we provide a\ncomprehensive overview of the latest advancements in PINNs, focusing on\nimprovements in network design, feature expansion, optimization techniques,\nuncertainty quantification, and theoretical insights. We also survey key\napplications across a range of fields, including biomedicine, fluid and solid\nmechanics, geophysics, dynamical systems, heat transfer, chemical engineering,\nand beyond. Finally, we review computational frameworks and software tools\ndeveloped by both academia and industry to support PINN research and\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "physics-informed neural networks, Kolmogorov-Arnold networks,\n  optimization algorithms, separable PINNs, self-adaptive weights, uncertainty\n  quantification",
    "pdf_url": "http://arxiv.org/pdf/2410.13228v2",
    "published_date": "2024-10-17 05:30:59 UTC",
    "updated_date": "2024-10-22 02:53:15 UTC"
  },
  {
    "arxiv_id": "2410.13226v2",
    "title": "Research on Travel Route Planing Problems Based on Greedy Algorithm",
    "authors": [
      "Yiquan Wang"
    ],
    "abstract": "The route planning problem based on the greedy algorithm represents a method\nof identifying the optimal or near-optimal route between a given start point\nand end point. In this paper, the PCA method is employed initially to downscale\nthe city evaluation indexes, extract the key principal components, and then\ndownscale the data using the KMO and TOPSIS algorithms, all of which are based\non the MindSpore framework. Secondly, for the dataset that does not pass the\nKMO test, the entropy weight method and TOPSIS method will be employed for\ncomprehensive evaluation. Finally, a route planning algorithm is proposed and\noptimised based on the greedy algorithm, which provides personalised route\ncustomisation according to the different needs of tourists. In addition, the\nlocal travelling efficiency, the time required to visit tourist attractions and\nthe necessary daily breaks are considered in order to reduce the cost and avoid\nfalling into the locally optimal solution.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13226v2",
    "published_date": "2024-10-17 05:17:01 UTC",
    "updated_date": "2024-10-22 12:28:28 UTC"
  },
  {
    "arxiv_id": "2410.13218v2",
    "title": "CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy",
    "authors": [
      "Mian Zhang",
      "Xianjun Yang",
      "Xinlu Zhang",
      "Travis Labrum",
      "Jamie C. Chiu",
      "Shaun M. Eack",
      "Fei Fang",
      "William Yang Wang",
      "Zhiyu Zoey Chen"
    ],
    "abstract": "There is a significant gap between patient needs and available mental health\nsupport today. In this paper, we aim to thoroughly examine the potential of\nusing Large Language Models (LLMs) to assist professional psychotherapy. To\nthis end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation\nof cognitive behavioral therapy (CBT) assistance. We include three levels of\ntasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of\nmultiple-choice questions; II: Cognitive model understanding, with the tasks of\ncognitive distortion classification, primary core belief classification, and\nfine-grained core belief classification; III: Therapeutic response generation,\nwith the task of generating responses to patient speech in CBT therapy\nsessions. These tasks encompass key aspects of CBT that could potentially be\nenhanced through AI assistance, while also outlining a hierarchy of capability\nrequirements, ranging from basic knowledge recitation to engaging in real\ntherapeutic conversations. We evaluated representative LLMs on our benchmark.\nExperimental results indicate that while LLMs perform well in reciting CBT\nknowledge, they fall short in complex real-world scenarios requiring deep\nanalysis of patients' cognitive structures and generating effective responses,\nsuggesting potential future work.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Camera Ready",
    "pdf_url": "http://arxiv.org/pdf/2410.13218v2",
    "published_date": "2024-10-17 04:52:57 UTC",
    "updated_date": "2025-01-26 05:47:12 UTC"
  },
  {
    "arxiv_id": "2410.13217v1",
    "title": "MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling",
    "authors": [
      "Ruohan Wang",
      "Zilong Wang",
      "Ziyang Song",
      "David Buckeridge",
      "Yue Li"
    ],
    "abstract": "Automatic subphenotyping from electronic health records (EHRs)provides\nnumerous opportunities to understand diseases with unique subgroups and enhance\npersonalized medicine for patients. However, existing machine learning\nalgorithms either focus on specific diseases for better interpretability or\nproduce coarse-grained phenotype topics without considering nuanced disease\npatterns. In this study, we propose a guided topic model, MixEHR-Nest, to infer\nsub-phenotype topics from thousands of disease using multi-modal EHR data.\nSpecifically, MixEHR-Nest detects multiple subtopics from each phenotype topic,\nwhose prior is guided by the expert-curated phenotype concepts such as\nPhenotype Codes (PheCodes) or Clinical Classification Software (CCS) codes. We\nevaluated MixEHR-Nest on two EHR datasets: (1) the MIMIC-III dataset consisting\nof over 38 thousand patients from intensive care unit (ICU) from Beth Israel\nDeaconess Medical Center (BIDMC) in Boston, USA; (2) the healthcare\nadministrative database PopHR, comprising 1.3 million patients from Montreal,\nCanada. Experimental results demonstrate that MixEHR-Nest can identify\nsubphenotypes with distinct patterns within each phenotype, which are\npredictive for disease progression and severity. Consequently, MixEHR-Nest\ndistinguishes between type 1 and type 2 diabetes by inferring subphenotypes\nusing CCS codes, which do not differentiate these two subtype concepts.\nAdditionally, MixEHR-Nest not only improved the prediction accuracy of\nshort-term mortality of ICU patients and initial insulin treatment in diabetic\npatients but also revealed the contributions of subphenotypes. For longitudinal\nanalysis, MixEHR-Nest identified subphenotypes of distinct age prevalence under\nthe same phenotypes, such as asthma, leukemia, epilepsy, and depression. The\nMixEHR-Nest software is available at GitHub:\nhttps://github.com/li-lab-mcgill/MixEHR-Nest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "q-bio.QM",
      "J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13217v1",
    "published_date": "2024-10-17 04:48:06 UTC",
    "updated_date": "2024-10-17 04:48:06 UTC"
  },
  {
    "arxiv_id": "2410.13216v1",
    "title": "Anchored Alignment for Self-Explanations Enhancement",
    "authors": [
      "Luis Felipe Villa-Arenas",
      "Ata Nizamoglu",
      "Qianli Wang",
      "Sebastian Möller",
      "Vera Schmitt"
    ],
    "abstract": "In this work, we introduce a methodology for alignment designed to enhance\nthe ability of large language models (LLMs) to articulate their reasoning\n(self-explanation) even in the absence of annotated rationale explanations. Our\nalignment methodology comprises three key components: explanation quality\nassessment, self-instruction dataset generation, and model alignment.\nAdditionally, we present a novel technique called Alignment with Anchor\nPreference Pairs, which improves the selection of preference pairs by\ncategorizing model outputs into three groups: consistently correct,\nconsistently incorrect, and variable. By applying tailored strategies to each\ncategory, we enhance the effectiveness of Direct Preference Optimization (DPO).\nOur experimental results demonstrate that this approach significantly improves\nexplanation quality while maintaining accuracy compared to other fine-tuning\nstrategies.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13216v1",
    "published_date": "2024-10-17 04:42:48 UTC",
    "updated_date": "2024-10-17 04:42:48 UTC"
  },
  {
    "arxiv_id": "2410.13213v2",
    "title": "LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch",
    "authors": [
      "Caigao Jiang",
      "Xiang Shu",
      "Hong Qian",
      "Xingyu Lu",
      "Jun Zhou",
      "Aimin Zhou",
      "Yang Yu"
    ],
    "abstract": "Optimization problems are prevalent across various scenarios. Formulating and\nthen solving optimization problems described by natural language often requires\nhighly specialized human expertise, which could block the widespread\napplication of optimization-based decision making. To automate problem\nformulation and solving, leveraging large language models (LLMs) has emerged as\na potential way. However, this kind of approach suffers from the issue of\noptimization generalization. Namely, the accuracy of most current LLM-based\nmethods and the generality of optimization problem types that they can model\nare still limited. In this paper, we propose a unified learning-based framework\ncalled LLMOPT to boost optimization generalization. Starting from the natural\nlanguage descriptions of optimization problems and a pre-trained LLM, LLMOPT\nconstructs the introduced five-element formulation as a universal model for\nlearning to define diverse optimization problem types. Then, LLMOPT employs the\nmulti-instruction tuning to enhance both problem formalization and solver code\ngeneration accuracy and generality. After that, to prevent hallucinations in\nLLMs, such as sacrificing solving accuracy to avoid execution errors, the model\nalignment and self-correction mechanism are adopted in LLMOPT. We evaluate the\noptimization generalization ability of LLMOPT and compared methods across six\nreal-world datasets covering roughly 20 fields such as health, environment,\nenergy and manufacturing, etc. Extensive experiment results show that LLMOPT is\nable to model various optimization problem types such as linear/nonlinear\nprogramming, mixed integer programming, and combinatorial optimization, and\nachieves a notable 11.08% average solving accuracy improvement compared with\nthe state-of-the-art methods. The code is available at\nhttps://github.com/caigaojiang/LLMOPT.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13213v2",
    "published_date": "2024-10-17 04:37:37 UTC",
    "updated_date": "2025-03-03 03:20:08 UTC"
  },
  {
    "arxiv_id": "2410.13212v1",
    "title": "AsymKV: Enabling 1-Bit Quantization of KV Cache with Layer-Wise Asymmetric Quantization Configurations",
    "authors": [
      "Qian Tao",
      "Wenyuan Yu",
      "Jingren Zhou"
    ],
    "abstract": "Large language models have shown exceptional capabilities in a wide range of\ntasks, such as text generation and video generation, among others. However, due\nto their massive parameter count, these models often require substantial\nstorage space, imposing significant constraints on the machines deploying LLMs.\nTo overcome this limitation, one research direction proposes to compress the\nmodels using integer replacements for floating-point numbers, in a process\nknown as Quantization. Some recent studies suggest quantizing the key and value\ncache (KV Cache) of LLMs, and designing quantization techniques that treat the\nkey and value matrices equivalently.\n  This work delves deeper into the asymmetric structural roles of KV Cache, a\nphenomenon where the transformer's output loss is more sensitive to the\nquantization of key matrices. We conduct a systematic examination of the\nattention output error resulting from key and value quantization. The\nphenomenon inspires us to propose an asymmetric quantization strategy. Our\napproach allows for 1-bit quantization of the KV cache by implementing distinct\nconfigurations for key and value matrices. We carry out experiments across a\nvariety of datasets, demonstrating that our proposed model allows for the\nquantization of up to 75% decoder layers with 1 bit, while simultaneously\nmaintaining performance levels comparable to those of the models with floating\nparameters.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13212v1",
    "published_date": "2024-10-17 04:35:57 UTC",
    "updated_date": "2024-10-17 04:35:57 UTC"
  },
  {
    "arxiv_id": "2410.13211v2",
    "title": "Estimating the Probabilities of Rare Outputs in Language Models",
    "authors": [
      "Gabriel Wu",
      "Jacob Hilton"
    ],
    "abstract": "We consider the problem of low probability estimation: given a machine\nlearning model and a formally-specified input distribution, how can we estimate\nthe probability of a binary property of the model's output, even when that\nprobability is too small to estimate by random sampling? This problem is\nmotivated by the need to improve worst-case performance, which distribution\nshift can make much more likely. We study low probability estimation in the\ncontext of argmax sampling from small transformer language models. We compare\ntwo types of methods: importance sampling, which involves searching for inputs\ngiving rise to the rare output, and activation extrapolation, which involves\nextrapolating a probability distribution fit to the model's logits. We find\nthat importance sampling outperforms activation extrapolation, but both\noutperform naive sampling. Finally, we explain how minimizing the probability\nestimate of an undesirable behavior generalizes adversarial training, and argue\nthat new methods for low probability estimation are needed to provide stronger\nguarantees about worst-case performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "29 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.13211v2",
    "published_date": "2024-10-17 04:31:18 UTC",
    "updated_date": "2025-02-06 18:43:54 UTC"
  },
  {
    "arxiv_id": "2410.13210v1",
    "title": "FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs",
    "authors": [
      "Forrest Sheng Bao",
      "Miaoran Li",
      "Renyi Qu",
      "Ge Luo",
      "Erana Wan",
      "Yujia Tang",
      "Weisi Fan",
      "Manveer Singh Tamber",
      "Suleman Kazi",
      "Vivek Sourabh",
      "Mike Qi",
      "Ruixuan Tu",
      "Chenyu Xu",
      "Matthew Gonzales",
      "Ofer Mendelevitch",
      "Amin Ahmad"
    ],
    "abstract": "Summarization is one of the most common tasks performed by large language\nmodels (LLMs), especially in applications like Retrieval-Augmented Generation\n(RAG). However, existing evaluations of hallucinations in LLM-generated\nsummaries, and evaluations of hallucination detection models both suffer from a\nlack of diversity and recency in the LLM and LLM families considered. This\npaper introduces FaithBench, a summarization hallucination benchmark comprising\nchallenging hallucinations made by 10 modern LLMs from 8 different families,\nwith ground truth annotations by human experts. ``Challenging'' here means\nsummaries on which popular, state-of-the-art hallucination detection models,\nincluding GPT-4o-as-a-judge, disagreed on. Our results show GPT-4o and\nGPT-3.5-Turbo produce the least hallucinations. However, even the best\nhallucination detection models have near 50\\% accuracies on FaithBench,\nindicating lots of room for future improvement. The repo is\nhttps://github.com/vectara/FaithBench",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13210v1",
    "published_date": "2024-10-17 04:30:46 UTC",
    "updated_date": "2024-10-17 04:30:46 UTC"
  },
  {
    "arxiv_id": "2410.13204v1",
    "title": "Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations",
    "authors": [
      "Aryan Shrivastava",
      "Jessica Hullman",
      "Max Lamparth"
    ],
    "abstract": "There is an increasing interest in using language models (LMs) for automated\ndecision-making, with multiple countries actively testing LMs to aid in\nmilitary crisis decision-making. To scrutinize relying on LM decision-making in\nhigh-stakes settings, we examine the inconsistency of responses in a crisis\nsimulation (\"wargame\"), similar to reported tests conducted by the US military.\nPrior work illustrated escalatory tendencies and varying levels of aggression\namong LMs but were constrained to simulations with pre-defined actions. This\nwas due to the challenges associated with quantitatively measuring semantic\ndifferences and evaluating natural language decision-making without relying on\npre-defined actions. In this work, we query LMs for free form responses and use\na metric based on BERTScore to measure response inconsistency quantitatively.\nLeveraging the benefits of BERTScore, we show that the inconsistency metric is\nrobust to linguistic variations that preserve semantic meaning in a\nquestion-answering setting across text lengths. We show that all five tested\nLMs exhibit levels of inconsistency that indicate semantic differences, even\nwhen adjusting the wargame setting, anonymizing involved conflict countries, or\nadjusting the sampling temperature parameter $T$. Further qualitative\nevaluation shows that models recommend courses of action that share few to no\nsimilarities. We also study the impact of different prompt sensitivity\nvariations on inconsistency at temperature $T = 0$. We find that inconsistency\ndue to semantically equivalent prompt variations can exceed response\ninconsistency from temperature sampling for most studied models across\ndifferent levels of ablations. Given the high-stakes nature of military\ndeployment, we recommend further consideration be taken before using LMs to\ninform military decisions or other cases of high-stakes decision-making.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13204v1",
    "published_date": "2024-10-17 04:12:17 UTC",
    "updated_date": "2024-10-17 04:12:17 UTC"
  },
  {
    "arxiv_id": "2410.13203v2",
    "title": "TabSeq: A Framework for Deep Learning on Tabular Data via Sequential Ordering",
    "authors": [
      "Al Zadid Sultan Bin Habib",
      "Kesheng Wang",
      "Mary-Anne Hartley",
      "Gianfranco Doretto",
      "Donald A. Adjeroh"
    ],
    "abstract": "Effective analysis of tabular data still poses a significant problem in deep\nlearning, mainly because features in tabular datasets are often heterogeneous\nand have different levels of relevance. This work introduces TabSeq, a novel\nframework for the sequential ordering of features, addressing the vital\nnecessity to optimize the learning process. Features are not always equally\ninformative, and for certain deep learning models, their random arrangement can\nhinder the model's learning capacity. Finding the optimum sequence order for\nsuch features could improve the deep learning models' learning process. The\nnovel feature ordering technique we provide in this work is based on clustering\nand incorporates both local ordering and global ordering. It is designed to be\nused with a multi-head attention mechanism in a denoising autoencoder network.\nOur framework uses clustering to align comparable features and improve data\norganization. Multi-head attention focuses on essential characteristics,\nwhereas the denoising autoencoder highlights important aspects by rebuilding\nfrom distorted inputs. This method improves the capability to learn from\ntabular data while lowering redundancy. Our research, demonstrating improved\nperformance through appropriate feature sequence rearrangement using raw\nantibody microarray and two other real-world biomedical datasets, validates the\nimpact of feature ordering. These results demonstrate that feature ordering can\nbe a viable approach to improved deep learning of tabular data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This paper has been accepted for presentation at the 27th\n  International Conference on Pattern Recognition (ICPR 2024) in Kolkata, India",
    "pdf_url": "http://arxiv.org/pdf/2410.13203v2",
    "published_date": "2024-10-17 04:10:36 UTC",
    "updated_date": "2024-10-21 15:21:56 UTC"
  },
  {
    "arxiv_id": "2410.13201v1",
    "title": "Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration",
    "authors": [
      "Yun-Yen Chuang",
      "Hung-Min Hsu",
      "Kevin Lin",
      "Chen-Sheng Gu",
      "Ling Zhen Li",
      "Ray-I Chang",
      "Hung-yi Lee"
    ],
    "abstract": "The diffusion model, a new generative modeling paradigm, has achieved\nsignificant success in generating images, audio, video, and text. It has been\nadapted for sequence-to-sequence text generation (Seq2Seq) through DiffuSeq,\ntermed S2S Diffusion. Existing S2S-Diffusion models predominantly rely on fixed\nor hand-crafted rules to schedule noise during the diffusion and denoising\nprocesses. However, these models are limited by non-contextualized noise, which\nfails to fully consider the characteristics of Seq2Seq tasks. In this paper, we\npropose the Meta-DiffuB framework - a novel scheduler-exploiter S2S-Diffusion\nparadigm designed to overcome the limitations of existing S2S-Diffusion models.\nWe employ Meta-Exploration to train an additional scheduler model dedicated to\nscheduling contextualized noise for each sentence. Our exploiter model, an\nS2S-Diffusion model, leverages the noise scheduled by our scheduler model for\nupdating and generation. Meta-DiffuB achieves state-of-the-art performance\ncompared to previous S2S-Diffusion models and fine-tuned pre-trained language\nmodels (PLMs) across four Seq2Seq benchmark datasets. We further investigate\nand visualize the impact of Meta-DiffuB's noise scheduling on the generation of\nsentences with varying difficulties. Additionally, our scheduler model can\nfunction as a \"plug-and-play\" model to enhance DiffuSeq without the need for\nfine-tuning during the inference stage.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13201v1",
    "published_date": "2024-10-17 04:06:02 UTC",
    "updated_date": "2024-10-17 04:06:02 UTC"
  },
  {
    "arxiv_id": "2410.13196v2",
    "title": "Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models",
    "authors": [
      "Tangwen Qian",
      "Junhe Li",
      "Yile Chen",
      "Gao Cong",
      "Tao Sun",
      "Fei Wang",
      "Yongjun Xu"
    ],
    "abstract": "Modeling trajectory data with generic-purpose dense representations has\nbecome a prevalent paradigm for various downstream applications, such as\ntrajectory classification, travel time estimation and similarity computation.\nHowever, existing methods typically rely on trajectories from a single spatial\nview, limiting their ability to capture the rich contextual information that is\ncrucial for gaining deeper insights into movement patterns across different\ngeospatial contexts. To this end, we propose MVTraj, a novel multi-view\nmodeling method for trajectory representation learning. MVTraj integrates\ndiverse contextual knowledge, from GPS to road network and points-of-interest\nto provide a more comprehensive understanding of trajectory data. To align the\nlearning process across multiple views, we utilize GPS trajectories as a bridge\nand employ self-supervised pretext tasks to capture and distinguish movement\npatterns across different spatial views. Following this, we treat trajectories\nfrom different views as distinct modalities and apply a hierarchical\ncross-modal interaction module to fuse the representations, thereby enriching\nthe knowledge derived from multiple sources. Extensive experiments on\nreal-world datasets demonstrate that MVTraj significantly outperforms existing\nbaselines in tasks associated with various spatial views, validating its\neffectiveness and practical utility in spatio-temporal modeling.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13196v2",
    "published_date": "2024-10-17 03:56:12 UTC",
    "updated_date": "2024-10-18 08:33:19 UTC"
  },
  {
    "arxiv_id": "2410.13193v1",
    "title": "Golyadkin's Torment: Doppelgängers and Adversarial Vulnerability",
    "authors": [
      "George I. Kamberov"
    ],
    "abstract": "Many machine learning (ML) classifiers are claimed to outperform humans, but\nthey still make mistakes that humans do not. The most notorious examples of\nsuch mistakes are adversarial visual metamers. This paper aims to define and\ninvestigate the phenomenon of adversarial Doppelgangers (AD), which includes\nadversarial visual metamers, and to compare the performance and robustness of\nML classifiers to human performance.\n  We find that AD are inputs that are close to each other with respect to a\nperceptual metric defined in this paper. AD are qualitatively different from\nthe usual adversarial examples. The vast majority of classifiers are vulnerable\nto AD and robustness-accuracy trade-offs may not improve them. Some\nclassification problems may not admit any AD robust classifiers because the\nunderlying classes are ambiguous. We provide criteria that can be used to\ndetermine whether a classification problem is well defined or not; describe the\nstructure and attributes of an AD-robust classifier; introduce and explore the\nnotions of conceptual entropy and regions of conceptual ambiguity for\nclassifiers that are vulnerable to AD attacks, along with methods to bound the\nAD fooling rate of an attack. We define the notion of classifiers that exhibit\nhypersensitive behavior, that is, classifiers whose only mistakes are\nadversarial Doppelgangers. Improving the AD robustness of hyper-sensitive\nclassifiers is equivalent to improving accuracy. We identify conditions\nguaranteeing that all classifiers with sufficiently high accuracy are\nhyper-sensitive.\n  Our findings are aimed at significant improvements in the reliability and\nsecurity of machine learning systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13193v1",
    "published_date": "2024-10-17 03:42:06 UTC",
    "updated_date": "2024-10-17 03:42:06 UTC"
  },
  {
    "arxiv_id": "2410.13191v4",
    "title": "MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback",
    "authors": [
      "Zonghai Yao",
      "Aditya Parashar",
      "Huixue Zhou",
      "Won Seok Jang",
      "Feiyun Ouyang",
      "Zhichao Yang",
      "Hong Yu"
    ],
    "abstract": "Automatic question generation (QG) is essential for AI and NLP, particularly\nin intelligent tutoring, dialogue systems, and fact verification. Generating\nmultiple-choice questions (MCQG) for professional exams, like the United States\nMedical Licensing Examination (USMLE), is particularly challenging, requiring\ndomain expertise and complex multi-hop reasoning for high-quality questions.\nHowever, current large language models (LLMs) like GPT-4 struggle with\nprofessional MCQG due to outdated knowledge, hallucination issues, and prompt\nsensitivity, resulting in unsatisfactory quality and difficulty. To address\nthese challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique\nand Correction) framework for converting medical cases into high-quality\nUSMLE-style questions. By integrating expert-driven prompt engineering with\niterative self-critique and self-correction feedback, MCQG-SRefine\nsignificantly enhances human expert satisfaction regarding both the quality and\ndifficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based\nautomatic metric to replace the complex and costly expert evaluation process,\nensuring reliable and expert-aligned assessments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Equal contribution for the first two authors. To appear in\n  proceedings of the Main Conference on 2025 Annual Conference of the Nations\n  of the Americas Chapter of the Association for Computational Linguistics\n  (NAACL). Keywords: Question Generation, USMLE, Self-Refine, Self-Critique,\n  and Self-Correction, LLM-as-Judge, AI for Medical Education",
    "pdf_url": "http://arxiv.org/pdf/2410.13191v4",
    "published_date": "2024-10-17 03:38:29 UTC",
    "updated_date": "2025-02-10 05:52:10 UTC"
  },
  {
    "arxiv_id": "2410.13190v2",
    "title": "CohEx: A Generalized Framework for Cohort Explanation",
    "authors": [
      "Fanyu Meng",
      "Xin Liu",
      "Zhaodan Kong",
      "Xin Chen"
    ],
    "abstract": "eXplainable Artificial Intelligence (XAI) has garnered significant attention\nfor enhancing transparency and trust in machine learning models. However, the\nscopes of most existing explanation techniques focus either on offering a\nholistic view of the explainee model (global explanation) or on individual\ninstances (local explanation), while the middle ground, i.e., cohort-based\nexplanation, is less explored. Cohort explanations offer insights into the\nexplainee's behavior on a specific group or cohort of instances, enabling a\ndeeper understanding of model decisions within a defined context. In this\npaper, we discuss the unique challenges and opportunities associated with\nmeasuring cohort explanations, define their desired properties, and create a\ngeneralized framework for generating cohort explanations based on supervised\nclustering.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13190v2",
    "published_date": "2024-10-17 03:36:18 UTC",
    "updated_date": "2024-12-11 07:25:40 UTC"
  },
  {
    "arxiv_id": "2410.13187v3",
    "title": "aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Processing",
    "authors": [
      "Siyuan Jiang",
      "Jia Li",
      "He Zong",
      "Huanyu Liu",
      "Hao Zhu",
      "Shukai Hu",
      "Erlu Li",
      "Jiazheng Ding",
      "Yu Han",
      "Wei Ning",
      "Gen Wang",
      "Yihong Dong",
      "Kechi Zhang",
      "Ge Li"
    ],
    "abstract": "Large Language Models (LLMs) have been widely used in code completion, and\nresearchers are focusing on scaling up LLMs to improve their accuracy. However,\nlarger LLMs have lower inference efficiency, affecting developers' experience\nand productivity. In this paper, we propose a lightweight and effective LLM for\ncode completion named aiXcoder-7B. Compared to existing LLMs, aiXcoder-7B\nachieves higher code completion accuracy while having smaller scales (i.e., 7\nbillion parameters). We attribute the superiority of aiXcoder-7B to three key\nfactors: (1) Multi-objective training. We employ three training objectives, one\nof which is our proposed Structured Fill-In-the-Middle (SFIM). SFIM considers\nthe syntax structures in code and effectively improves the performance of LLMs\nfor code. (2) Diverse data sampling strategies. They consider inter-file\nrelationships and enhance the capability of LLMs in understanding cross-file\ncontexts. (3) Extensive high-quality data. We establish a rigorous data\ncollection pipeline and consume a total of 1.2 trillion unique tokens for\ntraining aiXcoder-7B. This vast volume of data enables aiXcoder-7B to learn a\nbroad distribution of code. We evaluate aiXcoder-7B in five popular code\ncompletion benchmarks and a new benchmark collected by this paper. The results\nshow that aiXcoder-7B outperforms the latest six LLMs with similar sizes and\neven surpasses four larger LLMs (e.g., StarCoder2-15B and CodeLlama-34B),\npositioning aiXcoder-7B as a lightweight and effective LLM for academia and\nindustry. Finally, we summarize three valuable insights for helping\npractitioners train the next generations of LLMs for code. aiXcoder-7B has been\nopen-souced and gained significant attention. Until January 2025, aiXcoder-7B\nhas received 2,226 GitHub Stars.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "(1) Accepted by the 47th International Conference on Software\n  Engineering (ICSE 2025). (2) aiXcoder-7B is available at\n  https://github.com/aixcoder-plugin/aiXcoder-7B",
    "pdf_url": "http://arxiv.org/pdf/2410.13187v3",
    "published_date": "2024-10-17 03:32:02 UTC",
    "updated_date": "2025-01-16 12:46:53 UTC"
  },
  {
    "arxiv_id": "2410.13185v5",
    "title": "Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents",
    "authors": [
      "Long Li",
      "Weiwen Xu",
      "Jiayan Guo",
      "Ruochen Zhao",
      "Xingxuan Li",
      "Yuqian Yuan",
      "Boqiang Zhang",
      "Yuming Jiang",
      "Yifei Xin",
      "Ronghao Dang",
      "Deli Zhao",
      "Yu Rong",
      "Tian Feng",
      "Lidong Bing"
    ],
    "abstract": "Effective research ideation is a critical step for scientific research.\nHowever, the exponential increase in scientific literature makes it challenging\nfor researchers to stay current with recent advances and identify meaningful\nresearch directions. Recent developments in large language models~(LLMs)\nsuggest a promising avenue for automating the generation of novel research\nideas. However, existing methods for idea generation either trivially prompt\nLLMs or directly expose LLMs to extensive literature without indicating useful\ninformation. Inspired by the research process of human researchers, we propose\na Chain-of-Ideas~(CoI) agent, an LLM-based agent that organizes relevant\nliterature in a chain structure to effectively mirror the progressive\ndevelopment in a research domain. This organization facilitates LLMs to capture\nthe current advancements in research, thereby enhancing their ideation\ncapabilities. Furthermore, we propose Idea Arena, an evaluation protocol that\ncan comprehensively evaluate idea generation methods from different\nperspectives, aligning closely with the preferences of human researchers.\nExperimental results indicate that the CoI agent consistently outperforms other\nmethods and shows comparable quality as humans in research idea generation.\nMoreover, our CoI agent is budget-friendly, with a minimum cost of \\$0.50 to\ngenerate a candidate idea and its corresponding experimental design.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages,5 figures, conference",
    "pdf_url": "http://arxiv.org/pdf/2410.13185v5",
    "published_date": "2024-10-17 03:26:37 UTC",
    "updated_date": "2024-10-30 09:17:59 UTC"
  },
  {
    "arxiv_id": "2410.13915v1",
    "title": "A Simulation System Towards Solving Societal-Scale Manipulation",
    "authors": [
      "Maximilian Puelma Touzel",
      "Sneheel Sarangi",
      "Austin Welch",
      "Gayatri Krishnakumar",
      "Dan Zhao",
      "Zachary Yang",
      "Hao Yu",
      "Ethan Kosak-Hine",
      "Tom Gibbs",
      "Andreea Musulan",
      "Camille Thibault",
      "Busra Tugce Gurbuz",
      "Reihaneh Rabbany",
      "Jean-François Godbout",
      "Kellin Pelrine"
    ],
    "abstract": "The rise of AI-driven manipulation poses significant risks to societal trust\nand democratic processes. Yet, studying these effects in real-world settings at\nscale is ethically and logistically impractical, highlighting a need for\nsimulation tools that can model these dynamics in controlled settings to enable\nexperimentation with possible defenses. We present a simulation environment\ndesigned to address this. We elaborate upon the Concordia framework that\nsimulates offline, `real life' activity by adding online interactions to the\nsimulation through social media with the integration of a Mastodon server. We\nimprove simulation efficiency and information flow, and add a set of\nmeasurement tools, particularly longitudinal surveys. We demonstrate the\nsimulator with a tailored example in which we track agents' political positions\nand show how partisan manipulation of agents can affect election results.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.SI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13915v1",
    "published_date": "2024-10-17 03:16:24 UTC",
    "updated_date": "2024-10-17 03:16:24 UTC"
  },
  {
    "arxiv_id": "2410.13179v1",
    "title": "EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning",
    "authors": [
      "Ashish Seth",
      "Ramaneswaran Selvakumar",
      "S Sakshi",
      "Sonal Kumar",
      "Sreyan Ghosh",
      "Dinesh Manocha"
    ],
    "abstract": "In this paper, we present EH-MAM (Easy-to-Hard adaptive Masked Acoustic\nModeling), a novel self-supervised learning approach for speech representation\nlearning. In contrast to the prior methods that use random masking schemes for\nMasked Acoustic Modeling (MAM), we introduce a novel selective and adaptive\nmasking strategy. Specifically, during SSL training, we progressively introduce\nharder regions to the model for reconstruction. Our approach automatically\nselects hard regions and is built on the observation that the reconstruction\nloss of individual frames in MAM can provide natural signals to judge the\ndifficulty of solving the MAM pre-text task for that frame. To identify these\nhard regions, we employ a teacher model that first predicts the frame-wise\nlosses and then decides which frames to mask. By learning to create challenging\nproblems, such as identifying harder frames and solving them simultaneously,\nthe model is able to learn more effective representations and thereby acquire a\nmore comprehensive understanding of the speech. Quantitatively, EH-MAM\noutperforms several state-of-the-art baselines across various low-resource\nspeech recognition and SUPERB benchmarks by 5%-10%. Additionally, we conduct a\nthorough analysis to show that the regions masked by EH-MAM effectively capture\nuseful context across speech frames.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13179v1",
    "published_date": "2024-10-17 02:59:22 UTC",
    "updated_date": "2024-10-17 02:59:22 UTC"
  },
  {
    "arxiv_id": "2410.13178v3",
    "title": "GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation",
    "authors": [
      "Ziwei Yang",
      "Zheng Chen",
      "Xin Liu",
      "Rikuto Kotoge",
      "Peng Chen",
      "Yasuko Matsubara",
      "Yasushi Sakurai",
      "Jimeng Sun"
    ],
    "abstract": "Retrieving gene functional networks from knowledge databases presents a\nchallenge due to the mismatch between disease networks and subtype-specific\nvariations. Current solutions, including statistical and deep learning methods,\noften fail to effectively integrate gene interaction knowledge from databases\nor explicitly learn subtype-specific interactions. To address this mismatch, we\npropose GeSubNet, which learns a unified representation capable of predicting\ngene interactions while distinguishing between different disease subtypes.\nGraphs generated by such representations can be considered subtype-specific\nnetworks. GeSubNet is a multi-step representation learning framework with three\nmodules: First, a deep generative model learns distinct disease subtypes from\npatient gene expression profiles. Second, a graph neural network captures\nrepresentations of prior gene networks from knowledge databases, ensuring\naccurate physical gene interactions. Finally, we integrate these two\nrepresentations using an inference loss that leverages graph generation\ncapabilities, conditioned on the patient separation loss, to refine\nsubtype-specific information in the learned representation. GeSubNet\nconsistently outperforms traditional methods, with average improvements of\n30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged\nover four cancer datasets. Particularly, we conduct a biological simulation\nexperiment to assess how the behavior of selected genes from over 11,000\ncandidates affects subtypes or patient distributions. The results show that the\ngenerated network has the potential to identify subtype-specific genes with an\n83% likelihood of impacting patient distribution shifts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13178v3",
    "published_date": "2024-10-17 02:58:57 UTC",
    "updated_date": "2025-02-22 04:16:19 UTC"
  },
  {
    "arxiv_id": "2410.13175v2",
    "title": "TCP-Diffusion: A Multi-modal Diffusion Model for Global Tropical Cyclone Precipitation Forecasting with Change Awareness",
    "authors": [
      "Cheng Huang",
      "Pan Mu",
      "Cong Bai",
      "Peter AG Watson"
    ],
    "abstract": "Precipitation from tropical cyclones (TCs) can cause disasters such as\nflooding, mudslides, and landslides. Predicting such precipitation in advance\nis crucial, giving people time to prepare and defend against these\nprecipitation-induced disasters. Developing deep learning (DL) rainfall\nprediction methods offers a new way to predict potential disasters. However,\none problem is that most existing methods suffer from cumulative errors and\nlack physical consistency. Second, these methods overlook the importance of\nmeteorological factors in TC rainfall and their integration with the numerical\nweather prediction (NWP) model. Therefore, we propose Tropical Cyclone\nPrecipitation Diffusion (TCP-Diffusion), a multi-modal model for global\ntropical cyclone precipitation forecasting. It forecasts TC rainfall around the\nTC center for the next 12 hours at 3 hourly resolution based on past rainfall\nobservations and multi-modal environmental variables. Adjacent residual\nprediction (ARP) changes the training target from the absolute rainfall value\nto the rainfall trend and gives our model the ability of rainfall change\nawareness, reducing cumulative errors and ensuring physical consistency.\nConsidering the influence of TC-related meteorological factors and the useful\ninformation from NWP model forecasts, we propose a multi-model framework with\nspecialized encoders to extract richer information from environmental variables\nand results provided by NWP models. The results of extensive experiments show\nthat our method outperforms other DL methods and the NWP method from the\nEuropean Centre for Medium-Range Weather Forecasts (ECMWF).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "Camera-ready version. This paper has been accepted to ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13175v2",
    "published_date": "2024-10-17 02:58:05 UTC",
    "updated_date": "2025-05-18 02:30:08 UTC"
  },
  {
    "arxiv_id": "2410.13166v4",
    "title": "An Evolved Universal Transformer Memory",
    "authors": [
      "Edoardo Cetin",
      "Qi Sun",
      "Tianyu Zhao",
      "Yujin Tang"
    ],
    "abstract": "Prior methods propose to offset the escalating costs of modern foundation\nmodels by dropping specific parts of their contexts with hand-designed rules,\nwhile attempting to preserve their original performance. We overcome this\ntrade-off with Neural Attention Memory Models (NAMMs), introducing a learned\nnetwork for memory management that improves both the performance and efficiency\nof transformers. We evolve NAMMs atop pre-trained transformers to provide\ndifferent latent contexts focusing on the most relevant information for\nindividual layers and attention heads. NAMMs are universally applicable to any\nmodel using self-attention as they condition exclusively on the values in the\nproduced attention matrices. Learning NAMMs on a small set of problems, we\nachieve substantial performance improvements across multiple long-context\nbenchmarks while cutting the model's input contexts up to a fraction of the\noriginal sizes. We show the generality of our conditioning enables zero-shot\ntransfer of NAMMs trained only on language to entirely new transformer\narchitectures even across input modalities, with their benefits carrying over\nto vision and reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at ICLR 2025. Source code available at\n  https://github.com/SakanaAI/evo-memory",
    "pdf_url": "http://arxiv.org/pdf/2410.13166v4",
    "published_date": "2024-10-17 02:47:10 UTC",
    "updated_date": "2025-02-13 09:08:42 UTC"
  },
  {
    "arxiv_id": "2410.13147v8",
    "title": "Utilizing Large Language Models in an iterative paradigm with domain feedback for zero-shot molecule optimization",
    "authors": [
      "Khiem Le",
      "Nitesh V. Chawla"
    ],
    "abstract": "Molecule optimization is a critical task in drug discovery to optimize\ndesired properties of a given molecule. Despite Large Language Models (LLMs)\nholding the potential to efficiently simulate this task by using natural\nlanguage to direct the optimization, straightforwardly utilizing them shows\nlimited performance. In this work, we facilitate utilizing LLMs in an iterative\nparadigm by proposing a simple yet effective domain feedback provider, namely\n$\\text{Re}^2$DF. In detail, $\\text{Re}^2$DF harnesses an external toolkit,\nRDKit, to handle the molecule hallucination, if the modified molecule is\nchemically invalid. Otherwise, $\\text{Re}^2$DF verifies whether the modified\nmolecule meets the objective, if not, its desired properties are computed and\ncompared to the original one, establishing reliable domain feedback with\ncorrect direction and distance towards the objective to explicitly guide the\nLLM to refine the modified molecule. We conduct experiments across both single-\nand multi-property objectives with 2 thresholds, where $\\text{Re}^2$DF shows\nsignificant improvements. Notably, for 20 single-property objectives,\n$\\text{Re}^2$DF enhances Hit ratio by 16.96% and 20.76% under loose\n(\\texttt{l}) and strict (\\texttt{s}) thresholds, respectively. For 32\nmulti-property objectives, $\\text{Re}^2$DF enhances Hit ratio by 6.04% and\n5.25%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13147v8",
    "published_date": "2024-10-17 02:04:57 UTC",
    "updated_date": "2025-01-23 20:19:40 UTC"
  },
  {
    "arxiv_id": "2410.13121v1",
    "title": "Trust but Verify: Programmatic VLM Evaluation in the Wild",
    "authors": [
      "Viraj Prabhu",
      "Senthil Purushwalkam",
      "An Yan",
      "Caiming Xiong",
      "Ran Xu"
    ],
    "abstract": "Vision-Language Models (VLMs) often generate plausible but incorrect\nresponses to visual queries. However, reliably quantifying the effect of such\nhallucinations in free-form responses to open-ended queries is challenging as\nit requires visually verifying each claim within the response. We propose\nProgrammatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating\nVLM responses to open-ended queries. To construct PROVE, we provide a large\nlanguage model (LLM) with a high-fidelity scene-graph representation\nconstructed from a hyper-detailed image caption, and prompt it to generate\ndiverse question-answer (QA) pairs, as well as programs that can be executed\nover the scene graph object to verify each QA pair. We thus construct a\nbenchmark of 10.5k challenging but visually grounded QA pairs. Next, to\nevaluate free-form model responses to queries in PROVE, we propose a\nprogrammatic evaluation strategy that measures both the helpfulness and\ntruthfulness of a response within a unified scene graph-based framework. We\nbenchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,\nfinding that very few are in-fact able to achieve a good balance between the\ntwo. Project page: \\url{https://prove-explorer.netlify.app/}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13121v1",
    "published_date": "2024-10-17 01:19:18 UTC",
    "updated_date": "2024-10-17 01:19:18 UTC"
  },
  {
    "arxiv_id": "2410.13117v2",
    "title": "Preference Diffusion for Recommendation",
    "authors": [
      "Shuo Liu",
      "An Zhang",
      "Guoqing Hu",
      "Hong Qian",
      "Tat-seng Chua"
    ],
    "abstract": "Recommender systems predict personalized item rankings based on user\npreference distributions derived from historical behavior data. Recently,\ndiffusion models (DMs) have gained attention in recommendation for their\nability to model complex distributions, yet current DM-based recommenders often\nrely on traditional objectives like mean squared error (MSE) or recommendation\nobjectives, which are not optimized for personalized ranking tasks or fail to\nfully leverage DM's generative potential. To address this, we propose\nPreferDiff, a tailored optimization objective for DM-based recommenders.\nPreferDiff transforms BPR into a log-likelihood ranking objective and\nintegrates multiple negative samples to better capture user preferences.\nSpecifically, we employ variational inference to handle the intractability\nthrough minimizing the variational upper bound and replaces MSE with cosine\nerror to improve alignment with recommendation tasks. Finally, we balance\nlearning generation and preference to enhance the training stability of DMs.\nPreferDiff offers three key benefits: it is the first personalized ranking loss\ndesigned specifically for DM-based recommenders and it improves ranking and\nfaster convergence by addressing hard negatives. We also prove that it is\ntheoretically connected to Direct Preference Optimization which indicates that\nit has the potential to align user preferences in DM-based recommenders via\ngenerative modeling. Extensive experiments across three benchmarks validate its\nsuperior recommendation performance and commendable general sequential\nrecommendation capabilities. Our codes are available at\nhttps://github.com/lswhim/PreferDiff.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.13117v2",
    "published_date": "2024-10-17 01:02:04 UTC",
    "updated_date": "2025-04-20 10:42:19 UTC"
  },
  {
    "arxiv_id": "2410.13116v2",
    "title": "Learning to Summarize from LLM-generated Feedback",
    "authors": [
      "Hwanjun Song",
      "Taewon Yun",
      "Yuho Lee",
      "Jihwan Oh",
      "Gihun Lee",
      "Jason Cai",
      "Hang Su"
    ],
    "abstract": "Developing effective text summarizers remains a challenge due to issues like\nhallucinations, key information omissions, and verbosity in LLM-generated\nsummaries. This work explores using LLM-generated feedback to improve summary\nquality by aligning the summaries with human preferences for faithfulness,\ncompleteness, and conciseness. We introduce FeedSum, a large-scale dataset\ncontaining multi-dimensional LLM feedback on summaries of varying quality\nacross diverse domains. Our experiments show how feedback quality,\ndimensionality, and granularity influence preference learning, revealing that\nhigh-quality, multi-dimensional, fine-grained feedback significantly improves\nsummary generation. We also compare two methods for using this feedback:\nsupervised fine-tuning and direct preference optimization. Finally, we\nintroduce SummLlama3-8b, a model that outperforms the nearly 10x larger\nLlama3-70b-instruct in generating human-preferred summaries, demonstrating that\nsmaller models can achieve superior performance with appropriate training. The\nfull dataset and SummLlama3-8B model are available at\nhttps://huggingface.co/datasets/DISLab/FeedSum and\nhttps://huggingface.co/DISLab/SummLlama3-8B.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025 (main, long)",
    "pdf_url": "http://arxiv.org/pdf/2410.13116v2",
    "published_date": "2024-10-17 01:01:09 UTC",
    "updated_date": "2025-01-25 15:54:30 UTC"
  },
  {
    "arxiv_id": "2410.13114v1",
    "title": "Sound Check: Auditing Audio Datasets",
    "authors": [
      "William Agnew",
      "Julia Barnett",
      "Annie Chu",
      "Rachel Hong",
      "Michael Feffer",
      "Robin Netzorg",
      "Harry H. Jiang",
      "Ezra Awumey",
      "Sauvik Das"
    ],
    "abstract": "Generative audio models are rapidly advancing in both capabilities and public\nutilization -- several powerful generative audio models have readily available\nopen weights, and some tech companies have released high quality generative\naudio products. Yet, while prior work has enumerated many ethical issues\nstemming from the data on which generative visual and textual models have been\ntrained, we have little understanding of similar issues with generative audio\ndatasets, including those related to bias, toxicity, and intellectual property.\nTo bridge this gap, we conducted a literature review of hundreds of audio\ndatasets and selected seven of the most prominent to audit in more detail. We\nfound that these datasets are biased against women, contain toxic stereotypes\nabout marginalized communities, and contain significant amounts of copyrighted\nwork. To enable artists to see if they are in popular audio datasets and\nfacilitate exploration of the contents of these datasets, we developed a web\ntool audio datasets exploration tool at https://audio-audit.vercel.app.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CY",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13114v1",
    "published_date": "2024-10-17 00:51:27 UTC",
    "updated_date": "2024-10-17 00:51:27 UTC"
  },
  {
    "arxiv_id": "2410.13106v3",
    "title": "Cliqueformer: Model-Based Optimization with Structured Transformers",
    "authors": [
      "Jakub Grudzien Kuba",
      "Pieter Abbeel",
      "Sergey Levine"
    ],
    "abstract": "Large neural networks excel at prediction tasks, but their application to\ndesign problems, such as protein engineering or materials discovery, requires\nsolving offline model-based optimization (MBO) problems. While predictive\nmodels may not directly translate to effective design, recent MBO algorithms\nincorporate reinforcement learning and generative modeling approaches.\nMeanwhile, theoretical work suggests that exploiting the target function's\nstructure can enhance MBO performance. We present Cliqueformer, a\ntransformer-based architecture that learns the black-box function's structure\nthrough functional graphical models (FGM), addressing distribution shift\nwithout relying on explicit conservative approaches. Across various domains,\nincluding chemical and genetic design tasks, Cliqueformer demonstrates superior\nperformance compared to existing methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13106v3",
    "published_date": "2024-10-17 00:35:47 UTC",
    "updated_date": "2025-02-05 21:16:48 UTC"
  },
  {
    "arxiv_id": "2410.13098v1",
    "title": "A Little Human Data Goes A Long Way",
    "authors": [
      "Dhananjay Ashok",
      "Jonathan May"
    ],
    "abstract": "Faced with an expensive human annotation process, creators of NLP systems\nincreasingly turn to synthetic data generation. While this method shows\npromise, the extent to which synthetic data can replace human annotation is\npoorly understood. We investigate the use of synthetic data in Fact\nVerification (FV) and Question Answering (QA) by studying the effects of\nincrementally replacing human generated data with synthetic points on eight\ndiverse datasets. Strikingly, replacing up to 90% of the training data only\nmarginally decreases performance, but replacing the final 10% leads to severe\ndeclines. We find that models trained on purely synthetic data can be reliably\nimproved by including as few as 125 human generated data points. We show that\nmatching the performance gain of just a little additional human data (only 200\npoints) requires an order of magnitude more synthetic data and estimate price\nratios at which human annotation would be a more cost-effective solution. Our\nresults suggest that even when human annotation at scale is infeasible, there\nis great value to having a small proportion of the dataset being human\ngenerated.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.13098v1",
    "published_date": "2024-10-17 00:04:02 UTC",
    "updated_date": "2024-10-17 00:04:02 UTC"
  }
]