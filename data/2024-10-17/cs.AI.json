{
  "date": "2024-10-17",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-17 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 176 篇论文，主要聚焦于 AI 模型优化、多模态生成、医疗应用和强化学习等领域，其中 LLM 的自对齐和扩散模型创新（如知识蒸馏和高效推理）最为突出，令人印象深刻的作品包括由 Peter Seiler 等学者参与的优化框架，以及高效的视觉语言模型应用。\n\n### 重点论文讨论\n我将优先讨论重要、创新性和话题度高的论文，如那些涉及 LLM 优化、多模态生成和医疗领域的，并将相关主题归类讨论。其他论文（如一些常规算法改进）将快速掠过，以控制篇幅。\n\n#### LLM 和生成模型优化\n- **Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents**（英文标题：Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents）  \n  这篇论文提出 Chain-of-Ideas 框架，使用 LLM 代理模拟研究过程，通过迭代生成高质量研究想法。主要贡献是结合文献分析和实验设计，提升 LLM 在创新任务中的表现，实现高效、多任务生成。\n\n- **LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch**（英文标题：LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch）  \n  作者引入多指令微调框架，让 LLM 从零学习定义和解决优化问题（如线性规划）。关键发现是 LLM 可以泛化到多种优化类型，提升了 AI 在实际决策中的适用性。\n\n- **Preference Diffusion for Recommendation**（英文标题：Preference Diffusion for Recommendation）  \n  这篇工作将扩散模型应用于推荐系统，提出 PreferDiff 损失函数，通过变分推理优化用户偏好。主要贡献是提升推荐准确性和收敛速度，实验显示在多个基准上超越传统方法。\n\n其他 LLM 相关论文（如偏置分析或微调策略）虽众多，但许多重复现有主题，我仅快速提及：如 \"Atomic Calibration of LLMs in Long-Form Generations\" 改善了长文本生成的可校准性，但整体创新有限。\n\n#### 多模态和视觉语言模型\n- **MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models**（英文标题：MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models）  \n  论文开发 MagicTailor 框架，实现扩散模型中组件级个性化控制（如图像元素调整）。主要发现是通过动态掩码和平衡学习，显著减少图像生成中的语义失真。\n\n- **Movie Gen: A Cast of Media Foundation Models**（英文标题：Movie Gen: A Cast of Media Foundation Models）  \n  作者构建多模态模型生成高分辨率视频和音频，扩展了扩散模型的应用。关键贡献是优化训练策略，提升视频编辑和个性化生成，支持实时应用。\n\n这些多模态论文强调了模型的灵活性和高效性，相关工作如 \"LocateBench\" 评估了视觉语言模型的定位能力，但实验较为初步，我仅简要掠过。\n\n#### 医疗和生物应用\n- **Learning to Summarize from LLM-generated Feedback**（英文标题：Learning to Summarize from LLM-generated Feedback）  \n  这篇论文使用 LLM 生成反馈数据，训练摘要模型，提升医疗文本总结的准确性。主要贡献是通过自监督反馈机制，显著提高模型在医疗数据集上的性能。\n\n- **scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers**（英文标题：scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers）  \n  作者提出 scFusionTTT 框架，融合单细胞转录组和蛋白质组数据，使用 TTT 层提升预测精度。关键发现是模型在生物医学任务中表现出色，支持多模态数据分析。\n\n医疗领域的论文较多，如分子优化和蛋白设计，但许多是技术细节迭代，我快速掠过以节省空间。\n\n#### 其他领域快速掠过\n- 强化学习和优化论文，如 \"Cliqueformer\"（英文标题：Cliqueformer: Model-Based Optimization with Structured Transformers），提出图结构优化框架，提升模型效率，但主题较窄，仅提及其在复杂任务中的结构化改进。\n- 机器人和语音论文，如 \"Whisker-Inspired Tactile Sensing\"（英文标题：Whisker-Inspired Tactile Sensing: A Sim2Real Approach for Precise Underwater Contact Tracking），使用仿生传感器实现水下感知，贡献在于 sim-to-real 迁移，但应用场景较特定。\n- 其余论文（如常规算法或小众主题）不做详细讨论，以保持简洁。\n\n总之，今天的论文突出了 LLM 和扩散模型的创新潜力，尤其在优化和多模态生成上，相关工作为 AI 应用提供了高效工具。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2410.14086v3",
      "title": "In-context learning and Occam's razor",
      "title_zh": "上下文学习与奥卡姆剃刀",
      "authors": [
        "Eric Elmoznino",
        "Tom Marty",
        "Tejas Kasetty",
        "Leo Gagnon",
        "Sarthak Mittal",
        "Mahan Fathi",
        "Dhanya Sridhar",
        "Guillaume Lajoie"
      ],
      "abstract": "A central goal of machine learning is generalization. While the No Free Lunch\nTheorem states that we cannot obtain theoretical guarantees for generalization\nwithout further assumptions, in practice we observe that simple models which\nexplain the training data generalize best: a principle called Occam's razor.\nDespite the need for simple models, most current approaches in machine learning\nonly minimize the training error, and at best indirectly promote simplicity\nthrough regularization or architecture design. Here, we draw a connection\nbetween Occam's razor and in-context learning: an emergent ability of certain\nsequence models like Transformers to learn at inference time from past\nobservations in a sequence. In particular, we show that the next-token\nprediction loss used to train in-context learners is directly equivalent to a\ndata compression technique called prequential coding, and that minimizing this\nloss amounts to jointly minimizing both the training error and the complexity\nof the model that was implicitly learned from context. Our theory and the\nempirical experiments we use to support it not only provide a normative account\nof in-context learning, but also elucidate the shortcomings of current\nin-context learning methods, suggesting ways in which they can be improved. We\nmake our code available at https://github.com/3rdCore/PrequentialCode.",
      "tldr_zh": "本论文探讨了机器学习中泛化问题，将Occam's razor（简单模型更易泛化的原则）与in-context learning联系起来，解释了后者在序列模型如Transformers中的表现。作者证明，训练in-context learner的next-token prediction loss等同于prequential coding数据压缩技术，从而实现了同时最小化训练错误和模型复杂度。实验结果不仅为in-context learning提供了规范理论解释，还揭示了其不足，并提出改进建议，以提升泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14086v3",
      "published_date": "2024-10-17 23:37:34 UTC",
      "updated_date": "2025-01-31 06:05:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:38:43.015644"
    },
    {
      "arxiv_id": "2410.14082v1",
      "title": "Interpreting Inflammation Prediction Model via Tag-based Cohort Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Fanyu Meng",
        "Jules Larke",
        "Xin Liu",
        "Zhaodan Kong",
        "Xin Chen",
        "Danielle Lemay",
        "Ilias Tagkopoulos"
      ],
      "abstract": "Machine learning is revolutionizing nutrition science by enabling systems to\nlearn from data and make intelligent decisions. However, the complexity of\nthese models often leads to challenges in understanding their decision-making\nprocesses, necessitating the development of explainability techniques to foster\ntrust and increase model transparency. An under-explored type of explanation is\ncohort explanation, which provides explanations to groups of instances with\nsimilar characteristics. Unlike traditional methods that focus on individual\nexplanations or global model behavior, cohort explainability bridges the gap by\nproviding unique insights at an intermediate granularity. We propose a novel\nframework for identifying cohorts within a dataset based on local feature\nimportance scores, aiming to generate concise descriptions of the clusters via\ntags. We evaluate our framework on a food-based inflammation prediction model\nand demonstrated that the framework can generate reliable explanations that\nmatch domain knowledge.",
      "tldr_zh": "本研究针对机器学习在营养科学中的应用，强调了模型复杂性导致的决策过程不透明问题，并引入cohort explanation作为一种中间粒度解释方法，以提供群体级洞见。作者提出一个新框架，通过局部feature importance分数识别数据集中的cohort，并使用标签生成简洁的集群描述。该框架在食物-based炎症预测模型上进行评估，结果显示生成的解释可靠且与领域知识一致，从而提升了模型的可解释性和信任度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14082v1",
      "published_date": "2024-10-17 23:22:59 UTC",
      "updated_date": "2024-10-17 23:22:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:38:55.092760"
    },
    {
      "arxiv_id": "2410.14072v1",
      "title": "Efficient Vision-Language Models by Summarizing Visual Tokens into Compact Registers",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxin Wen",
        "Qingqing Cao",
        "Qichen Fu",
        "Sachin Mehta",
        "Mahyar Najibi"
      ],
      "abstract": "Recent advancements in vision-language models (VLMs) have expanded their\npotential for real-world applications, enabling these models to perform complex\nreasoning on images. In the widely used fully autoregressive transformer-based\nmodels like LLaVA, projected visual tokens are prepended to textual tokens.\nOftentimes, visual tokens are significantly more than prompt tokens, resulting\nin increased computational overhead during both training and inference. In this\npaper, we propose Visual Compact Token Registers (Victor), a method that\nreduces the number of visual tokens by summarizing them into a smaller set of\nregister tokens. Victor adds a few learnable register tokens after the visual\ntokens and summarizes the visual information into these registers using the\nfirst few layers in the language tower of VLMs. After these few layers, all\nvisual tokens are discarded, significantly improving computational efficiency\nfor both training and inference. Notably, our method is easy to implement and\nrequires a small number of new trainable parameters with minimal impact on\nmodel performance. In our experiment, with merely 8 visual registers--about 1%\nof the original tokens--Victor shows less than a 4% accuracy drop while\nreducing the total training time by 43% and boosting the inference throughput\nby 3.3X.",
      "tldr_zh": "这篇论文提出了 Victor 方法，用于优化 Vision-Language Models (VLMs)，通过将视觉标记总结成更少的 learnable register tokens，从而减少计算开销。Victor 在 VLMs 的语言塔前几层中处理视觉信息，将其压缩后丢弃原始视觉标记，实现高效训练和推理，同时仅需少量新参数。实验结果显示，使用约占原标记 1% 的 8 个 register tokens，模型准确率仅下降不到 4%，训练时间缩短 43%，推理吞吐量提升 3.3 倍。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14072v1",
      "published_date": "2024-10-17 22:45:13 UTC",
      "updated_date": "2024-10-17 22:45:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:39:07.594886"
    },
    {
      "arxiv_id": "2410.14070v1",
      "title": "FaceSaliencyAug: Mitigating Geographic, Gender and Stereotypical Biases via Saliency-Based Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Teerath Kumar",
        "Alessandra Mileo",
        "Malika Bendechache"
      ],
      "abstract": "Geographical, gender and stereotypical biases in computer vision models pose\nsignificant challenges to their performance and fairness. {In this study, we\npresent an approach named FaceSaliencyAug aimed at addressing the gender bias\nin} {Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs).\nLeveraging the salient regions} { of faces detected by saliency, the propose\napproach mitigates geographical and stereotypical biases } {in the datasets.\nFaceSaliencyAug} randomly selects masks from a predefined search space and\napplies them to the salient region of face images, subsequently restoring the\noriginal image with masked salient region. {The proposed} augmentation strategy\nenhances data diversity, thereby improving model performance and debiasing\neffects. We quantify dataset diversity using Image Similarity Score (ISS)\nacross five datasets, including Flickr Faces HQ (FFHQ), WIKI, IMDB, Labelled\nFaces in the Wild (LFW), UTK Faces, and Diverse Dataset. The proposed approach\ndemonstrates superior diversity metrics, as evaluated by ISS-intra and\nISS-inter algorithms. Furthermore, we evaluate the effectiveness of our\napproach in mitigating gender bias on CEO, Engineer, Nurse, and School Teacher\ndatasets. We use the Image-Image Association Score (IIAS) to measure gender\nbias in these occupations. Our experiments reveal a reduction in gender bias\nfor both CNNs and ViTs, indicating the efficacy of our method in promoting\nfairness and inclusivity in computer vision models.",
      "tldr_zh": "这篇论文提出了 FaceSaliencyAug，一种基于显著性（saliency-based）的图像增强方法，旨在缓解计算机视觉模型中的地理、性别和刻板印象偏见，特别是针对 CNNs 和 ViTs。方法通过在面部图像的显著区域应用随机掩盖并恢复原图，从而提升数据多样性，并在 Flickr Faces HQ (FFHQ)、WIKI 等五个数据集上使用 Image Similarity Score (ISS) 进行量化评估。实验结果显示，该方法显著提高了数据集多样性指标（如 ISS-intra 和 ISS-inter），并通过 Image-Image Association Score (IIAS) 在 CEO、Engineer、Nurse 和 School Teacher 数据集上减少了性别偏见，促进了模型的公平性和包容性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at Image Signal and Video processing",
      "pdf_url": "http://arxiv.org/pdf/2410.14070v1",
      "published_date": "2024-10-17 22:36:52 UTC",
      "updated_date": "2024-10-17 22:36:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:39:21.030987"
    },
    {
      "arxiv_id": "2410.14067v2",
      "title": "Provable Benefits of Complex Parameterizations for Structured State Space Models",
      "title_zh": "复杂",
      "authors": [
        "Yuval Ran-Milo",
        "Eden Lumbroso",
        "Edo Cohen-Karlik",
        "Raja Giryes",
        "Amir Globerson",
        "Nadav Cohen"
      ],
      "abstract": "Structured state space models (SSMs), the core engine behind prominent neural\nnetworks such as S4 and Mamba, are linear dynamical systems adhering to a\nspecified structure, most notably diagonal. In contrast to typical neural\nnetwork modules, whose parameterizations are real, SSMs often use complex\nparameterizations. Theoretically explaining the benefits of complex\nparameterizations for SSMs is an open problem. The current paper takes a step\ntowards its resolution, by establishing formal gaps between real and complex\ndiagonal SSMs. Firstly, we prove that while a moderate dimension suffices in\norder for a complex SSM to express all mappings of a real SSM, a much higher\ndimension is needed for a real SSM to express mappings of a complex SSM.\nSecondly, we prove that even if the dimension of a real SSM is high enough to\nexpress a given mapping, typically, doing so requires the parameters of the\nreal SSM to hold exponentially large values, which cannot be learned in\npractice. In contrast, a complex SSM can express any given mapping with\nmoderate parameter values. Experiments corroborate our theory, and suggest a\npotential extension of the theory that accounts for selectivity, a new\narchitectural feature yielding state of the art performance.",
      "tldr_zh": "这篇论文证明了在 Structured State Space Models (SSMs) 中，使用复杂参数化比实数参数化具有显著优势，例如 S4 和 Mamba 等模型。研究发现，复杂 SSMs 可以用较低的维度表达实数 SSMs 的所有映射，而实数 SSMs 需更高维度，且参数值往往需指数级增大，导致实际训练不可行。实验验证了这些理论差距，并提出扩展理论以纳入选择性（selectivity）特征，进一步提升模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages. Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14067v2",
      "published_date": "2024-10-17 22:35:50 UTC",
      "updated_date": "2024-10-31 10:38:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:39:31.855702"
    },
    {
      "arxiv_id": "2410.14060v1",
      "title": "On Partial Prototype Collapse in the DINO Family of Self-Supervised Methods",
      "title_zh": "翻译失败",
      "authors": [
        "Hariprasath Govindarajan",
        "Per Sidén",
        "Jacob Roll",
        "Fredrik Lindsten"
      ],
      "abstract": "A prominent self-supervised learning paradigm is to model the representations\nas clusters, or more generally as a mixture model. Learning to map the data\nsamples to compact representations and fitting the mixture model simultaneously\nleads to the representation collapse problem. Regularizing the distribution of\ndata points over the clusters is the prevalent strategy to avoid this issue.\nWhile this is sufficient to prevent full representation collapse, we show that\na partial prototype collapse problem still exists in the DINO family of\nmethods, that leads to significant redundancies in the prototypes. Such\nprototype redundancies serve as shortcuts for the method to achieve a marginal\nlatent class distribution that matches the prescribed prior. We show that by\nencouraging the model to use diverse prototypes, the partial prototype collapse\ncan be mitigated. Effective utilization of the prototypes enables the methods\nto learn more fine-grained clusters, encouraging more informative\nrepresentations. We demonstrate that this is especially beneficial when\npre-training on a long-tailed fine-grained dataset.",
      "tldr_zh": "本论文探讨了 DINO 家族自监督学习方法中的部分原型崩溃（partial prototype collapse）问题，该问题导致原型（prototypes）冗余，作为方法匹配预设潜在类分布的捷径。研究者提出通过鼓励模型使用多样化的 prototypes 来缓解这一崩溃，从而实现更细粒度的聚类和更具信息性的表示。实验结果表明，这种策略在长尾分布的细粒度数据集上预训练时特别有益，提升了自监督学习的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "First version of the paper appeared in OpenReview on 22 Sep 2023.\n  Accepted to BMVC 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14060v1",
      "published_date": "2024-10-17 22:06:34 UTC",
      "updated_date": "2024-10-17 22:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:39:44.781051"
    },
    {
      "arxiv_id": "2410.16322v1",
      "title": "SouLLMate: An Application Enhancing Diverse Mental Health Support with Adaptive LLMs, Prompt Engineering, and RAG Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Qiming Guo",
        "Jinwen Tang",
        "Wenbo Sun",
        "Haoteng Tang",
        "Yi Shang",
        "Wenlu Wang"
      ],
      "abstract": "Mental health issues significantly impact individuals' daily lives, yet many\ndo not receive the help they need even with available online resources. This\nstudy aims to provide diverse, accessible, stigma-free, personalized, and\nreal-time mental health support through cutting-edge AI technologies. It makes\nthe following contributions: (1) Conducting an extensive survey of recent\nmental health support methods to identify prevalent functionalities and unmet\nneeds. (2) Introducing SouLLMate, an adaptive LLM-driven system that integrates\nLLM technologies, Chain, Retrieval-Augmented Generation (RAG), prompt\nengineering, and domain knowledge. This system offers advanced features such as\nRisk Detection and Proactive Guidance Dialogue, and utilizes RAG for\npersonalized profile uploads and Conversational Information Extraction. (3)\nDeveloping novel evaluation approaches for preliminary assessments and risk\ndetection via professionally annotated interview data and real-life suicide\ntendency data. (4) Proposing the Key Indicator Summarization (KIS), Proactive\nQuestioning Strategy (PQS), and Stacked Multi-Model Reasoning (SMMR) methods to\nenhance model performance and usability through context-sensitive response\nadjustments, semantic coherence evaluations, and enhanced accuracy of\nlong-context reasoning in language models. This study contributes to advancing\nmental health support technologies, potentially improving the accessibility and\neffectiveness of mental health care globally.",
      "tldr_zh": "这篇论文介绍了 SouLLMate，一种基于自适应 LLM 的应用，旨在通过提示工程和 RAG 技术提供多样化、可访问、无污名化的个性化心理健康支持。系统整合了风险检测、主动指导对话以及个性化配置文件上传等功能，并提出 Key Indicator Summarization (KIS)、Proactive Questioning Strategy (PQS) 和 Stacked Multi-Model Reasoning (SMMR) 方法，以提升响应调整、语义连贯性和长上下文推理的准确性。研究通过广泛调查和新型评估方法（如专业标注数据）验证了 SouLLMate 的有效性，为全球心理健康护理的可访问性和整体效能带来潜在提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 19 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.16322v1",
      "published_date": "2024-10-17 22:04:32 UTC",
      "updated_date": "2024-10-17 22:04:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:39:56.797723"
    },
    {
      "arxiv_id": "2410.20718v1",
      "title": "Lecture II: Communicative Justice and the Distribution of Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Seth Lazar"
      ],
      "abstract": "Algorithmic intermediaries govern the digital public sphere through their\narchitectures, amplification algorithms, and moderation practices. In doing so,\nthey shape public communication and distribute attention in ways that were\npreviously infeasible with such subtlety, speed and scale. From misinformation\nand affective polarisation to hate speech and radicalisation, the many\npathologies of the digital public sphere attest that they could do so better.\nBut what ideals should they aim at? Political philosophy should be able to\nhelp, but existing theories typically assume that a healthy public sphere will\nspontaneously emerge if only we get the boundaries of free expression right.\nThey offer little guidance on how to intentionally constitute the digital\npublic sphere. In addition to these theories focused on expression, we need a\nfurther theory of communicative justice, targeted specifically at the\nalgorithmic intermediaries that shape communication and distribute attention.\nThis lecture argues that political philosophy urgently owes an account of how\nto govern communication in the digital public sphere, and introduces and\ndefends a democratic egalitarian theory of communicative justice.",
      "tldr_zh": "算法中介（algorithmic intermediaries）通过其架构、放大算法（amplification algorithms）和调节实践（moderation practices）塑造数字公共领域（digital public sphere），影响公众沟通和注意力分配，导致问题如错误信息（misinformation）、情感极化（affective polarisation）、仇恨言论（hate speech）和激进主义（radicalisation）。现有政治哲学理论主要关注言论自由边界，假设健康公共领域会自发出现，却忽略了如何有意构建数字公共领域。作者主张发展一个针对算法中介的沟通正义（communicative justice）理论，并引入并捍卫一个民主平等主义（democratic egalitarian）的框架，以指导数字公共领域的治理。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20718v1",
      "published_date": "2024-10-17 22:03:35 UTC",
      "updated_date": "2024-10-17 22:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:40:07.931859"
    },
    {
      "arxiv_id": "2410.20720v1",
      "title": "Lecture I: Governing the Algorithmic City",
      "title_zh": "讲座 I: 治理算法城市",
      "authors": [
        "Seth Lazar"
      ],
      "abstract": "A century ago, John Dewey observed that '[s]team and electricity have done\nmore to alter the conditions under which men associate together than all the\nagencies which affected human relationships before our time'. In the last few\ndecades, computing technologies have had a similar effect. Political\nphilosophy's central task is to help us decide how to live together, by\nanalysing our social relations, diagnosing their failings, and articulating\nideals to guide their revision. But these profound social changes have left\nscarcely a dent in the model of social relations that (analytical) political\nphilosophers assume. This essay aims to reverse that trend. It first builds a\nmodel of our novel social relations as they are now, and as they are likely to\nevolved, and then explores how those differences affect our theories of how to\nlive together. I introduce the 'Algorithmic City', the network of\nalgorithmically-mediated social relations, then characterise the intermediary\npower by which it is governed. I show how algorithmic governance raises new\nchallenges for political philosophy concerning the justification of authority,\nthe foundations of procedural legitimacy, and the possibility of justificatory\nneutrality.",
      "tldr_zh": "本论文批判了政治哲学在面对计算技术对社会关系深刻影响时仍停滞不前，旨在通过构建新型社会关系模型来指导我们如何共同生活。作者引入“Algorithmic City”概念，即一个算法中介的社会网络，并分析其治理中的“intermediary power”，探讨算法治理如何演变。论文强调，这带来新挑战，包括权威的justification、procedural legitimacy的基础，以及justificatory neutrality的可能性，从而呼吁更新政治哲学理论。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.4"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.20720v1",
      "published_date": "2024-10-17 22:02:06 UTC",
      "updated_date": "2024-10-17 22:02:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:40:19.429896"
    },
    {
      "arxiv_id": "2410.14057v1",
      "title": "Towards Cross-Cultural Machine Translation with Retrieval-Augmented Generation from Multilingual Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Simone Conia",
        "Daniel Lee",
        "Min Li",
        "Umar Farooq Minhas",
        "Saloni Potdar",
        "Yunyao Li"
      ],
      "abstract": "Translating text that contains entity names is a challenging task, as\ncultural-related references can vary significantly across languages. These\nvariations may also be caused by transcreation, an adaptation process that\nentails more than transliteration and word-for-word translation. In this paper,\nwe address the problem of cross-cultural translation on two fronts: (i) we\nintroduce XC-Translate, the first large-scale, manually-created benchmark for\nmachine translation that focuses on text that contains potentially\nculturally-nuanced entity names, and (ii) we propose KG-MT, a novel end-to-end\nmethod to integrate information from a multilingual knowledge graph into a\nneural machine translation model by leveraging a dense retrieval mechanism. Our\nexperiments and analyses show that current machine translation systems and\nlarge language models still struggle to translate texts containing entity\nnames, whereas KG-MT outperforms state-of-the-art approaches by a large margin,\nobtaining a 129% and 62% relative improvement compared to NLLB-200 and GPT-4,\nrespectively.",
      "tldr_zh": "这篇论文针对跨文化机器翻译的挑战，引入了 XC-Translate，这是一个首个大规模手动创建的基准，用于评估包含文化细微差别的实体名称翻译。论文提出 KG-MT，一种新颖的端到端方法，通过密集检索机制从 Multilingual Knowledge Graphs 中提取信息，并将其集成到神经机器翻译模型中。实验结果表明，KG-MT 显著优于现有系统，比 NLLB-200 提升 129%、比 GPT-4 提升 62%，证明了其在处理文化相关文本时的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.14057v1",
      "published_date": "2024-10-17 21:56:22 UTC",
      "updated_date": "2024-10-17 21:56:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:40:31.680570"
    },
    {
      "arxiv_id": "2410.14052v3",
      "title": "From Isolated Conversations to Hierarchical Schemas: Dynamic Tree Memory Representation for LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Rezazadeh",
        "Zichao Li",
        "Wei Wei",
        "Yujia Bao"
      ],
      "abstract": "Recent advancements in large language models have significantly improved\ntheir context windows, yet challenges in effective long-term memory management\nremain. We introduce MemTree, an algorithm that leverages a dynamic,\ntree-structured memory representation to optimize the organization, retrieval,\nand integration of information, akin to human cognitive schemas. MemTree\norganizes memory hierarchically, with each node encapsulating aggregated\ntextual content, corresponding semantic embeddings, and varying abstraction\nlevels across the tree's depths. Our algorithm dynamically adapts this memory\nstructure by computing and comparing semantic embeddings of new and existing\ninformation to enrich the model's context-awareness. This approach allows\nMemTree to handle complex reasoning and extended interactions more effectively\nthan traditional memory augmentation methods, which often rely on flat lookup\ntables. Evaluations on benchmarks for multi-turn dialogue understanding and\ndocument question answering show that MemTree significantly enhances\nperformance in scenarios that demand structured memory management.",
      "tldr_zh": "该研究针对大语言模型(LLMs)的长期内存管理挑战，提出MemTree算法，利用动态树状结构来优化信息组织、检索和整合，模仿人类认知模式。MemTree将内存层次化组织，每个节点包含聚合文本内容、语义嵌入和不同抽象级别，并通过计算比较新旧信息的语义嵌入实现动态适应，提升模型的上下文感知能力。与传统平坦查找表方法相比，该算法更有效地处理复杂推理和多轮交互。在多轮对话理解和文档问答基准测试中，MemTree显著提高了性能，尤其在结构化内存管理需求高的场景。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14052v3",
      "published_date": "2024-10-17 21:47:11 UTC",
      "updated_date": "2025-03-19 21:18:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:40:43.170048"
    },
    {
      "arxiv_id": "2410.14044v1",
      "title": "Best in Tau@LLMJudge: Criteria-Based Relevance Evaluation with Llama3",
      "title_zh": "Tau@LL",
      "authors": [
        "Naghmeh Farzi",
        "Laura Dietz"
      ],
      "abstract": "Traditional evaluation of information retrieval (IR) systems relies on\nhuman-annotated relevance labels, which can be both biased and costly at scale.\nIn this context, large language models (LLMs) offer an alternative by allowing\nus to directly prompt them to assign relevance labels for passages associated\nwith each query. In this study, we explore alternative methods to directly\nprompt LLMs for assigned relevance labels, by exploring two hypotheses:\n  Hypothesis 1 assumes that it is helpful to break down \"relevance\" into\nspecific criteria - exactness, coverage, topicality, and contextual fit. We\nexplore different approaches that prompt large language models (LLMs) to obtain\ncriteria-level grades for all passages, and we consider various ways to\naggregate criteria-level grades into a relevance label. Hypothesis 2 assumes\nthat differences in linguistic style between queries and passages may\nnegatively impact the automatic relevance label prediction. We explore whether\nimprovements can be achieved by first synthesizing a summary of the passage in\nthe linguistic style of a query, and then using this summary in place of the\npassage to assess its relevance.\n  We include an empirical evaluation of our approaches based on data from the\nLLMJudge challenge run in Summer 2024, where our \"Four Prompts\" approach\nobtained the highest scores in Kendall's tau.",
      "tldr_zh": "该研究提出了一种基于 Llama3 的信息检索 (IR) 系统相关性评估方法，以替代依赖人类标注的传统方式。通过探索两个假设，研究将“相关性”分解为具体标准（exactness、coverage、topicality 和 contextual fit），并通过不同提示方式获取标准级评分，再聚合为整体相关性标签；同时，处理查询和段落语言风格差异的方法，包括先合成段落摘要以匹配查询风格。实验基于 2024 年 LLMJudge 挑战赛数据，结果显示他们的“Four Prompts”方法在 Kendall's tau 上取得了最高分数，提升了自动相关性评估的准确性和效率。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "H.3.3"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14044v1",
      "published_date": "2024-10-17 21:37:08 UTC",
      "updated_date": "2024-10-17 21:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:40:56.041841"
    },
    {
      "arxiv_id": "2410.14040v1",
      "title": "Latent Weight Diffusion: Generating Policies from Trajectories",
      "title_zh": "潜在权重扩散：从轨迹生成策略",
      "authors": [
        "Shashank Hegde",
        "Gautam Salhotra",
        "Gaurav S. Sukhatme"
      ],
      "abstract": "With the increasing availability of open-source robotic data, imitation\nlearning has emerged as a viable approach for both robot manipulation and\nlocomotion. Currently, large generalized policies are trained to predict\ncontrols or trajectories using diffusion models, which have the desirable\nproperty of learning multimodal action distributions. However, generalizability\ncomes with a cost - namely, larger model size and slower inference. Further,\nthere is a known trade-off between performance and action horizon for Diffusion\nPolicy (i.e., diffusing trajectories): fewer diffusion queries accumulate\ngreater trajectory tracking errors. Thus, it is common practice to run these\nmodels at high inference frequency, subject to robot computational constraints.\n  To address these limitations, we propose Latent Weight Diffusion (LWD), a\nmethod that uses diffusion to learn a distribution over policies for robotic\ntasks, rather than over trajectories. Our approach encodes demonstration\ntrajectories into a latent space and then decodes them into policies using a\nhypernetwork. We employ a diffusion denoising model within this latent space to\nlearn its distribution. We demonstrate that LWD can reconstruct the behaviors\nof the original policies that generated the trajectory dataset. LWD offers the\nbenefits of considerably smaller policy networks during inference and requires\nfewer diffusion model queries. When tested on the Metaworld MT10 benchmark, LWD\nachieves a higher success rate compared to a vanilla multi-task policy, while\nusing models up to ~18x smaller during inference. Additionally, since LWD\ngenerates closed-loop policies, we show that it outperforms Diffusion Policy in\nlong action horizon settings, with reduced diffusion queries during rollout.",
      "tldr_zh": "本研究提出Latent Weight Diffusion (LWD)，一种新方法，通过在潜在空间中使用扩散模型学习机器人任务的策略分布，而不是直接处理轨迹，从而解决传统扩散策略的模型大小大、推理慢和动作地平线权衡等问题。LWD将演示轨迹编码到潜在空间，然后利用超网络解码成策略，并通过扩散去噪模型学习其分布，实现更高效的策略生成。实验结果显示，在Metaworld MT10基准测试中，LWD比传统多任务策略成功率更高，同时推理时模型大小缩小至约18倍，并在长动作地平线场景下优于Diffusion Policy，并减少扩散查询次数。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14040v1",
      "published_date": "2024-10-17 21:30:29 UTC",
      "updated_date": "2024-10-17 21:30:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:41:08.989939"
    },
    {
      "arxiv_id": "2410.14026v1",
      "title": "Generating Signed Language Instructions in Large-Scale Dialogue Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Mert İnan",
        "Katherine Atwell",
        "Anthony Sicilia",
        "Lorna Quandt",
        "Malihe Alikhani"
      ],
      "abstract": "We introduce a goal-oriented conversational AI system enhanced with American\nSign Language (ASL) instructions, presenting the first implementation of such a\nsystem on a worldwide multimodal conversational AI platform. Accessible through\na touch-based interface, our system receives input from users and seamlessly\ngenerates ASL instructions by leveraging retrieval methods and cognitively\nbased gloss translations. Central to our design is a sign translation module\npowered by Large Language Models, alongside a token-based video retrieval\nsystem for delivering instructional content from recipes and wikiHow guides.\nOur development process is deeply rooted in a commitment to community\nengagement, incorporating insights from the Deaf and Hard-of-Hearing community,\nas well as experts in cognitive and ASL learning sciences. The effectiveness of\nour signing instructions is validated by user feedback, achieving ratings on\npar with those of the system in its non-signing variant. Additionally, our\nsystem demonstrates exceptional performance in retrieval accuracy and\ntext-generation quality, measured by metrics such as BERTScore. We have made\nour codebase and datasets publicly accessible at\nhttps://github.com/Merterm/signed-dialogue, and a demo of our signed\ninstruction video retrieval system is available at\nhttps://huggingface.co/spaces/merterm/signed-instructions.",
      "tldr_zh": "本研究引入了第一个在全球多模态对话 AI 平台上实现的目标导向对话系统，该系统通过 American Sign Language (ASL) 指令增强用户交互。系统采用检索方法和基于认知的光泽翻译生成 ASL 指令，核心组件包括由 Large Language Models 驱动的手语翻译模块以及基于令牌的视频检索系统，用于从食谱和 wikiHow 指南中提取内容。开发过程强调社区参与，融入 Deaf and Hard-of-Hearing 社区及专家见解。实验结果显示，该系统的手语指令获得与非手语版本相当的用户反馈，并在检索准确性和文本生成质量（如 BERTScore 指标）上表现出色，并已公开代码和数据集以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "2024 Annual Conference of the North American Chapter of the\n  Association for Computational Linguistics (NAACL 2024) Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2410.14026v1",
      "published_date": "2024-10-17 20:56:29 UTC",
      "updated_date": "2024-10-17 20:56:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:41:19.943717"
    },
    {
      "arxiv_id": "2410.14024v1",
      "title": "Ensemble-based, large-eddy reconstruction of wind turbine inflow in a near-stationary atmospheric boundary layer through generative artificial intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Rybchuk",
        "Luis A. Martínez-Tossas",
        "Stefano Letizia",
        "Nicholas Hamilton",
        "Andy Scholbrock",
        "Emina Maric",
        "Daniel R. Houck",
        "Thomas G. Herges",
        "Nathaniel B. de Velder",
        "Paula Doubrawa"
      ],
      "abstract": "To validate the second-by-second dynamics of turbines in field experiments,\nit is necessary to accurately reconstruct the winds going into the turbine.\nCurrent time-resolved inflow reconstruction techniques estimate wind behavior\nin unobserved regions using relatively simple spectral-based models of the\natmosphere. Here, we develop a technique for time-resolved inflow\nreconstruction that is rooted in a large-eddy simulation model of the\natmosphere. Our \"large-eddy reconstruction\" technique blends observations and\natmospheric model information through a diffusion model machine learning\nalgorithm, allowing us to generate probabilistic ensembles of reconstructions\nfor a single 10-min observational period. Our generated inflows can be used\ndirectly by aeroelastic codes or as inflow boundary conditions in a large-eddy\nsimulation. We verify the second-by-second reconstruction capability of our\ntechnique in three synthetic field campaigns, finding positive Pearson\ncorrelation coefficient values (0.20>r>0.85) between ground-truth and\nreconstructed streamwise velocity, as well as smaller positive correlation\ncoefficient values for unobserved fields (spanwise velocity, vertical velocity,\nand temperature). We validate our technique in three real-world case studies by\ndriving large-eddy simulations with reconstructed inflows and comparing to\nindependent inflow measurements. The reconstructions are visually similar to\nmeasurements, follow desired power spectra properties, and track\nsecond-by-second behavior (0.25 > r > 0.75).",
      "tldr_zh": "该论文提出了一种基于生成式人工智能的集成方法（ensemble-based），用于重建风力涡轮机在近静止大气边界层中的流入，具体通过 large-eddy simulation 模型和 diffusion model 算法融合观察数据和大气信息，生成 probabilistic ensembles 的时间分辨重建。相比传统光谱模型，该技术能更准确地估计未观察区域的风行为，并可直接应用于 aeroelastic codes 或作为 large-eddy simulation 的边界条件。在合成和真实案例验证中，重建的流向速度与真实值显示正相关（Pearson correlation coefficient 0.20 > r > 0.85），并成功跟踪第二-by-second 动态（0.25 > r > 0.75）。这为风力涡轮机动态验证提供了更可靠的工具。",
      "categories": [
        "physics.ao-ph",
        "cs.AI"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "30 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.14024v1",
      "published_date": "2024-10-17 20:53:04 UTC",
      "updated_date": "2024-10-17 20:53:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:41:31.658834"
    },
    {
      "arxiv_id": "2410.14022v1",
      "title": "Vision-Language-Action Model and Diffusion Policy Switching Enables Dexterous Control of an Anthropomorphic Hand",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Pan",
        "Kai Junge",
        "Josie Hughes"
      ],
      "abstract": "To advance autonomous dexterous manipulation, we propose a hybrid control\nmethod that combines the relative advantages of a fine-tuned\nVision-Language-Action (VLA) model and diffusion models. The VLA model provides\nlanguage commanded high-level planning, which is highly generalizable, while\nthe diffusion model handles low-level interactions which offers the precision\nand robustness required for specific objects and environments. By incorporating\na switching signal into the training-data, we enable event based transitions\nbetween these two models for a pick-and-place task where the target object and\nplacement location is commanded through language. This approach is deployed on\nour anthropomorphic ADAPT Hand 2, a 13DoF robotic hand, which incorporates\ncompliance through series elastic actuation allowing for resilience for any\ninteractions: showing the first use of a multi-fingered hand controlled with a\nVLA model. We demonstrate this model switching approach results in a over 80\\%\nsuccess rate compared to under 40\\% when only using a VLA model, enabled by\naccurate near-object arm motion by the VLA model and a multi-modal grasping\nmotion with error recovery abilities from the diffusion model.",
      "tldr_zh": "该研究提出了一种混合控制方法，将 Vision-Language-Action (VLA) 模型和扩散模型结合，用于实现仿人机器人手的灵巧操控。VLA 模型负责语言指令的高级规划，提供高度泛化性，而扩散模型处理低级交互，确保精确性和鲁棒性；通过在训练数据中加入切换信号，实现基于事件的模型切换，以完成 pick-and-place 任务。实验在 13DoF 的 ADAPT Hand 2 上显示，该方法成功率超过 80%，远高于仅使用 VLA 模型的不到 40%，并首次展示了 VLA 模型在多指手控制中的应用。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14022v1",
      "published_date": "2024-10-17 20:49:45 UTC",
      "updated_date": "2024-10-17 20:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:41:44.416056"
    },
    {
      "arxiv_id": "2410.14005v1",
      "title": "Whisker-Inspired Tactile Sensing: A Sim2Real Approach for Precise Underwater Contact Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Chengyi Xing",
        "Saad Khan",
        "Miaoya Zhong",
        "Mark R. Cutkosky"
      ],
      "abstract": "Aquatic mammals, such as pinnipeds, utilize their whiskers to detect and\ndiscriminate objects and analyze water movements, inspiring the development of\nrobotic whiskers for sensing contacts, surfaces, and water flows. We present\nthe design and application of underwater whisker sensors based on Fiber Bragg\nGrating (FBG) technology. These passive whiskers are mounted along the\nrobot$'$s exterior to sense its surroundings through light, non-intrusive\ncontacts. For contact tracking, we employ a sim-to-real learning framework,\nwhich involves extensive data collection in simulation followed by a\nsim-to-real calibration process to transfer the model trained in simulation to\nthe real world. Experiments with whiskers immersed in water indicate that our\napproach can track contact points with an accuracy of $<2$ mm, without\nrequiring precise robot proprioception. We demonstrate that the approach also\ngeneralizes to unseen objects.",
      "tldr_zh": "本研究受水生哺乳动物胡须启发，设计了基于 Fiber Bragg Grating (FBG) 技术的 underwater whisker sensors，用于机器人外部感知水下环境中的非侵入性接触。采用 sim-to-real 学习框架，通过模拟环境中的大量数据收集和后续校准，将模型从模拟转移到真实世界，实现精确接触跟踪。实验结果显示，该方法在水中跟踪接触点精度可达小于2 mm，且无需精确的机器人 proprioception，同时能泛化到未见过的物体，为水下机器人感知技术提供新途径。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14005v1",
      "published_date": "2024-10-17 20:19:01 UTC",
      "updated_date": "2024-10-17 20:19:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:41:55.695868"
    },
    {
      "arxiv_id": "2410.14748v3",
      "title": "ETF: An Entity Tracing Framework for Hallucination Detection in Code Summaries",
      "title_zh": "ETF：一种用于代码摘要中幻觉检测的实体追踪框架",
      "authors": [
        "Kishan Maharaj",
        "Vitobha Munigala",
        "Srikanth G. Tamilselvam",
        "Prince Kumar",
        "Sayandeep Sen",
        "Palani Kodeswaran",
        "Abhijit Mishra",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced their ability to understand both natural language and code, driving\ntheir use in tasks like natural language-to-code (NL2Code) and code\nsummarization. However, LLMs are prone to hallucination-outputs that stray from\nintended meanings. Detecting hallucinations in code summarization is especially\ndifficult due to the complex interplay between programming and natural\nlanguages. We introduce a first-of-its-kind dataset with $\\sim$10K samples,\ncurated specifically for hallucination detection in code summarization. We\nfurther propose a novel Entity Tracing Framework (ETF) that a) utilizes static\nprogram analysis to identify code entities from the program and b) uses LLMs to\nmap and verify these entities and their intents within generated code\nsummaries. Our experimental analysis demonstrates the effectiveness of the\nframework, leading to a 0.73 F1 score. This approach provides an interpretable\nmethod for detecting hallucinations by grounding entities, allowing us to\nevaluate summary accuracy.",
      "tldr_zh": "本研究针对大语言模型（LLMs）在代码总结中产生的幻觉（hallucination）问题，引入了一个首创数据集，包含约10K样本，用于检测代码总结的准确性。研究提出Entity Tracing Framework (ETF)，该框架结合静态程序分析识别代码实体，并利用LLMs映射和验证这些实体及其意图，以提供可解释的幻觉检测机制。实验结果显示，ETF在检测任务中取得了0.73的F1分数，显著提升了代码总结的可靠性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SE",
      "comment": "11 pages, 6 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2410.14748v3",
      "published_date": "2024-10-17 19:38:55 UTC",
      "updated_date": "2024-12-18 23:36:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:42:08.078234"
    },
    {
      "arxiv_id": "2410.13981v2",
      "title": "On the Learn-to-Optimize Capabilities of Transformers in In-Context Sparse Recovery",
      "title_zh": "论 Transformer 在 In-Context 稀疏恢复中的学习优化能力",
      "authors": [
        "Renpu Liu",
        "Ruida Zhou",
        "Cong Shen",
        "Jing Yang"
      ],
      "abstract": "An intriguing property of the Transformer is its ability to perform\nin-context learning (ICL), where the Transformer can solve different inference\ntasks without parameter updating based on the contextual information provided\nby the corresponding input-output demonstration pairs. It has been\ntheoretically proved that ICL is enabled by the capability of Transformers to\nperform gradient-descent algorithms (Von Oswald et al., 2023a; Bai et al.,\n2024). This work takes a step further and shows that Transformers can perform\nlearning-to-optimize (L2O) algorithms. Specifically, for the ICL sparse\nrecovery (formulated as LASSO) tasks, we show that a K-layer Transformer can\nperform an L2O algorithm with a provable convergence rate linear in K. This\nprovides a new perspective explaining the superior ICL capability of\nTransformers, even with only a few layers, which cannot be achieved by the\nstandard gradient-descent algorithms. Moreover, unlike the conventional L2O\nalgorithms that require the measurement matrix involved in training to match\nthat in testing, the trained Transformer is able to solve sparse recovery\nproblems generated with different measurement matrices. Besides, Transformers\nas an L2O algorithm can leverage structural information embedded in the\ntraining tasks to accelerate its convergence during ICL, and generalize across\ndifferent lengths of demonstration pairs, where conventional L2O algorithms\ntypically struggle or fail. Such theoretical findings are supported by our\nexperimental results.",
      "tldr_zh": "本文研究了Transformer在In-Context Learning (ICL)稀疏恢复中的Learn-to-Optimize (L2O)能力，证明Transformer可以通过执行L2O算法来处理稀疏恢复任务（如LASSO），并实现线性于层数K的收敛率，这解释了其即使在少层情况下也能超越标准梯度下降算法的ICL性能。不同于传统L2O算法，Transformer能适应不同测量矩阵、利用训练任务的结构信息加速收敛，并泛化到各种演示对长度。实验结果验证了这些理论发现，为Transformer的强大ICL能力提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13981v2",
      "published_date": "2024-10-17 19:18:28 UTC",
      "updated_date": "2025-03-12 05:09:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:42:20.257050"
    },
    {
      "arxiv_id": "2410.13979v2",
      "title": "RecoveryChaining: Learning Local Recovery Policies for Robust Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Shivam Vats",
        "Devesh K. Jha",
        "Maxim Likhachev",
        "Oliver Kroemer",
        "Diego Romeres"
      ],
      "abstract": "Model-based planners and controllers are commonly used to solve complex\nmanipulation problems as they can efficiently optimize diverse objectives and\ngeneralize to long horizon tasks. However, they often fail during deployment\ndue to noisy actuation, partial observability and imperfect models. To enable a\nrobot to recover from such failures, we propose to use hierarchical\nreinforcement learning to learn a recovery policy. The recovery policy is\ntriggered when a failure is detected based on sensory observations and seeks to\ntake the robot to a state from which it can complete the task using the nominal\nmodel-based controllers. Our approach, called RecoveryChaining, uses a hybrid\naction space, where the model-based controllers are provided as additional\n\\emph{nominal} options which allows the recovery policy to decide how to\nrecover, when to switch to a nominal controller and which controller to switch\nto even with \\emph{sparse rewards}. We evaluate our approach in three\nmulti-step manipulation tasks with sparse rewards, where it learns\nsignificantly more robust recovery policies than those learned by baselines. We\nsuccessfully transfer recovery policies learned in simulation to a physical\nrobot to demonstrate the feasibility of sim-to-real transfer with our method.",
      "tldr_zh": "这篇论文提出了 RecoveryChaining 方法，使用 hierarchical reinforcement learning 来学习本地恢复策略，以提升机器人在复杂操作任务中的鲁棒性。该方法通过检测基于传感器观察的失败来触发恢复策略，并采用 hybrid action space，将模型-based controllers 作为 nominal options，允许策略在 sparse rewards 环境下决定恢复行动和切换控制器。实验结果显示，在三个多步操作任务中，RecoveryChaining 比基线方法学习了更有效的恢复策略，并成功实现了 sim-to-real transfer，从模拟环境转移到物理机器人。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Added Lazy RecoveryChaining algorithm. 8 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13979v2",
      "published_date": "2024-10-17 19:14:43 UTC",
      "updated_date": "2025-03-07 05:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:42:31.405048"
    },
    {
      "arxiv_id": "2410.13973v3",
      "title": "MarineFormer: A Spatio-Temporal Attention Model for USV Navigation in Dynamic Marine Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Kazemi",
        "Iman Soltani"
      ],
      "abstract": "Navigating autonomously in marine environments including dynamic and static\nobstacles, and strong flow disturbances, such as in high-flow rivers, poses\nsignificant challenges for USVs. To address these challenges, we propose a\nnovel methodology that leverages two types of attention: spatial attention,\nwhich learns to integrate diverse environmental factors and sensory information\ninto navigation decisions, and temporal attention within a transformer\nframework to account for the dynamic, continuously changing nature of the\nenvironment. We devise MarineFormer, a Trans${\\bf \\text{former}}$-based\nnavigation policy for dynamic ${\\bf \\text{Marine}}$ environments, trained\nend-to-end through reinforcement learning (RL). At its core, MarineFormer uses\ngraph attention to capture spatial information and a transformer architecture\nto process temporal sequences in an environment that simulates a 2D turbulent\nmarine condition involving multiple static and dynamic obstacles. We\nextensively evaluate the performance of the proposed method versus the\nstate-of-the-art methods, as well as other classical planners. Our approach\noutperforms the state-of-the-art by nearly $20\\%$ in episode completion success\nrate and additionally enhances the USV's path length efficiency.",
      "tldr_zh": "该研究针对USV（无人水面船）在动态海洋环境中导航的挑战，包括动态障碍物和强流干扰，提出了一种新型空间-时间注意力模型MarineFormer。MarineFormer基于Transformer框架，结合空间注意力（整合环境因素和感官信息）和时间注意力，通过强化学习（RL）端到端训练，以处理环境的变化。实验结果显示，该方法相较于最先进技术，提高了近20%的任务完成成功率，并显著提升了路径长度效率。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13973v3",
      "published_date": "2024-10-17 18:57:15 UTC",
      "updated_date": "2024-12-17 22:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:42:43.950688"
    },
    {
      "arxiv_id": "2410.13966v1",
      "title": "Detecting AI-Generated Texts in Cross-Domains",
      "title_zh": "翻译失败",
      "authors": [
        "You Zhou",
        "Jie Wang"
      ],
      "abstract": "Existing tools to detect text generated by a large language model (LLM) have\nmet with certain success, but their performance can drop when dealing with\ntexts in new domains. To tackle this issue, we train a ranking classifier\ncalled RoBERTa-Ranker, a modified version of RoBERTa, as a baseline model using\na dataset we constructed that includes a wider variety of texts written by\nhumans and generated by various LLMs. We then present a method to fine-tune\nRoBERTa-Ranker that requires only a small amount of labeled data in a new\ndomain. Experiments show that this fine-tuned domain-aware model outperforms\nthe popular DetectGPT and GPTZero on both in-domain and cross-domain texts,\nwhere AI-generated texts may either be in a different domain or generated by a\ndifferent LLM not used to generate the training datasets. This approach makes\nit feasible and economical to build a single system to detect AI-generated\ntexts across various domains.",
      "tldr_zh": "本文研究了现有 AI 生成文本检测工具在跨领域文本中的性能下降问题，提出了一种基于 RoBERTa 的排名分类器 RoBERTa-Ranker 作为基线模型，并使用一个包含多样人类和 LLM 生成文本的数据集进行训练。作者开发了一种只需少量标记数据的微调方法，使模型能够有效适应新领域。实验结果表明，该微调模型在同领域和跨领域文本上优于 DetectGPT 和 GPTZero，即使面对不同 LLM 生成的文本，从而实现了经济可行的跨领域 AI 生成文本检测系统。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13966v1",
      "published_date": "2024-10-17 18:43:30 UTC",
      "updated_date": "2024-10-17 18:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:42:55.923912"
    },
    {
      "arxiv_id": "2410.13960v1",
      "title": "Approximating Auction Equilibria with Reinforcement Learning",
      "title_zh": "利用强化学习近似拍卖均衡",
      "authors": [
        "Pranjal Rawat"
      ],
      "abstract": "Traditional methods for computing equilibria in auctions become\ncomputationally intractable as auction complexity increases, particularly in\nmulti-item and dynamic auctions. This paper introduces a self-play based\nreinforcement learning approach that employs advanced algorithms such as\nProximal Policy Optimization and Neural Fictitious Self-Play to approximate\nBayes-Nash equilibria. This framework allows for continuous action spaces,\nhigh-dimensional information states, and delayed payoffs. Through self-play,\nthese algorithms can learn robust and near-optimal bidding strategies in\nauctions with known equilibria, including those with symmetric and asymmetric\nvaluations, private and interdependent values, and multi-round auctions.",
      "tldr_zh": "本文提出了一种基于强化学习（Reinforcement Learning）的自博弈（self-play）方法，用于近似拍卖中的Bayes-Nash equilibria，以解决传统方法在多物品和动态拍卖中的计算难题。该方法采用Proximal Policy Optimization和Neural Fictitious Self-Play算法，支持连续行动空间、高维信息状态和延迟回报。通过自博弈训练，算法能够在各种拍卖场景中学习稳健的近似最优竞标策略，包括对称/不对称估值、私有/相互依赖值以及多轮拍卖。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13960v1",
      "published_date": "2024-10-17 18:34:57 UTC",
      "updated_date": "2024-10-17 18:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:43:08.316116"
    },
    {
      "arxiv_id": "2410.13959v2",
      "title": "FinQAPT: Empowering Financial Decisions with End-to-End LLM-driven Question Answering Pipeline",
      "title_zh": "翻译失败",
      "authors": [
        "Kuldeep Singh",
        "Simerjot Kaur",
        "Charese Smiley"
      ],
      "abstract": "Financial decision-making hinges on the analysis of relevant information\nembedded in the enormous volume of documents in the financial domain. To\naddress this challenge, we developed FinQAPT, an end-to-end pipeline that\nstreamlines the identification of relevant financial reports based on a query,\nextracts pertinent context, and leverages Large Language Models (LLMs) to\nperform downstream tasks. To evaluate the pipeline, we experimented with\nvarious techniques to optimize the performance of each module using the FinQA\ndataset. We introduced a novel clustering-based negative sampling technique to\nenhance context extraction and a novel prompting method called Dynamic N-shot\nPrompting to boost the numerical question-answering capabilities of LLMs. At\nthe module level, we achieved state-of-the-art accuracy on FinQA, attaining an\naccuracy of 80.6%. However, at the pipeline level, we observed decreased\nperformance due to challenges in extracting relevant context from financial\nreports. We conducted a detailed error analysis of each module and the\nend-to-end pipeline, pinpointing specific challenges that must be addressed to\ndevelop a robust solution for handling complex financial tasks.",
      "tldr_zh": "该研究开发了FinQAPT，一种端到端的问答管道，利用大型语言模型(LLMs)来处理财务文档查询，帮助用户做出更明智的财务决策。管道包括基于查询识别相关报告、提取上下文的关键模块，并引入了创新技术，如聚类-based负采样和Dynamic N-shot Prompting，以优化上下文提取和数值问答性能。在FinQA数据集上，模块级别达到了80.6%的state-of-the-art准确率，但管道整体性能因上下文提取挑战而下降。通过详细错误分析，论文指出了未来改进复杂财务任务的关键问题。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "I.2.7; H.3.3; I.2.6; I.5.3"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted in ICAIF 2024, 8 pages, 5 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.13959v2",
      "published_date": "2024-10-17 18:34:43 UTC",
      "updated_date": "2024-10-31 18:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:43:19.194845"
    },
    {
      "arxiv_id": "2410.13957v1",
      "title": "Goal Inference from Open-Ended Dialog",
      "title_zh": "翻译失败",
      "authors": [
        "Rachel Ma",
        "Jingyi Qu",
        "Andreea Bobu",
        "Dylan Hadfield-Menell"
      ],
      "abstract": "We present an online method for embodied agents to learn and accomplish\ndiverse user goals. While offline methods like RLHF can represent various goals\nbut require large datasets, our approach achieves similar flexibility with\nonline efficiency. We extract natural language goal representations from\nconversations with Large Language Models (LLMs). We prompt an LLM to role play\nas a human with different goals and use the corresponding likelihoods to run\nBayesian inference over potential goals. As a result, our method can represent\nuncertainty over complex goals based on unrestricted dialog. We evaluate our\nmethod in grocery shopping and home robot assistance domains using a text-based\ninterface and AI2Thor simulation respectively. Results show our method\noutperforms ablation baselines that lack either explicit goal representation or\nprobabilistic inference.",
      "tldr_zh": "这篇论文提出了一种在线方法，让具身代理（embodied agents）从开放对话中学习并实现多样化的用户目标，与离线方法如 RLHF 相比，它在不依赖大型数据集的情况下实现了更高的灵活性和效率。方法通过提示大型语言模型（LLMs）扮演不同目标的人类角色，并利用贝叶斯推理（Bayesian inference）对潜在目标进行概率推断，从而处理复杂目标的不确定性。在杂货购物和家庭机器人辅助领域（如 AI2Thor 模拟）的实验中，该方法优于缺少显式目标表示或概率推理的基线模型，展示了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages + 2 page (references and appendix)",
      "pdf_url": "http://arxiv.org/pdf/2410.13957v1",
      "published_date": "2024-10-17 18:30:52 UTC",
      "updated_date": "2024-10-17 18:30:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:43:31.477117"
    },
    {
      "arxiv_id": "2410.13951v1",
      "title": "Identifying High Consideration E-Commerce Search Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyu Chen",
        "Jason Choi",
        "Besnik Fetahu",
        "Shervin Malmasi"
      ],
      "abstract": "In e-commerce, high consideration search missions typically require careful\nand elaborate decision making, and involve a substantial research investment\nfrom customers. We consider the task of identifying High Consideration (HC)\nqueries. Identifying such queries enables e-commerce sites to better serve user\nneeds using targeted experiences such as curated QA widgets that help users\nreach purchase decisions. We explore the task by proposing an Engagement-based\nQuery Ranking (EQR) approach, focusing on query ranking to indicate potential\nengagement levels with query-related shopping knowledge content during product\nsearch. Unlike previous studies on predicting trends, EQR prioritizes\nquery-level features related to customer behavior, finance, and catalog\ninformation rather than popularity signals. We introduce an accurate and\nscalable method for EQR and present experimental results demonstrating its\neffectiveness. Offline experiments show strong ranking performance. Human\nevaluation shows a precision of 96% for HC queries identified by our model. The\nmodel was commercially deployed, and shown to outperform human-selected queries\nin terms of downstream customer impact, as measured through engagement.",
      "tldr_zh": "本文研究了电子商务中高考虑度 (HC) 搜索查询的识别，这些查询通常涉及用户仔细决策和大量研究，以帮助电商平台提供针对性体验，如精选的 QA 小部件。作者提出了一种基于参与度的查询排名方法 (Engagement-based Query Ranking, EQR)，重点利用查询级别的客户行为、金融和目录信息特征，而非流行度信号。实验结果显示，EQR 在离线测试中表现出强排名性能，人为评估的 HC 查询识别精度达 96%，并在商业部署中优于人工选择查询，提升了客户参与度。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by EMNLP 2024 (Industry Track)",
      "pdf_url": "http://arxiv.org/pdf/2410.13951v1",
      "published_date": "2024-10-17 18:22:42 UTC",
      "updated_date": "2024-10-17 18:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:43:44.016094"
    },
    {
      "arxiv_id": "2410.13948v1",
      "title": "The KnowWhereGraph Ontology",
      "title_zh": "KnowWhereGraph 本体",
      "authors": [
        "Cogan Shimizu",
        "Shirly Stephe",
        "Adrita Barua",
        "Ling Cai",
        "Antrea Christou",
        "Kitty Currier",
        "Abhilekha Dalal",
        "Colby K. Fisher",
        "Pascal Hitzler",
        "Krzysztof Janowicz",
        "Wenwen Li",
        "Zilong Liu",
        "Mohammad Saeid Mahdavinejad",
        "Gengchen Mai",
        "Dean Rehberger",
        "Mark Schildhauer",
        "Meilin Shi",
        "Sanaz Saki Norouzi",
        "Yuanyuan Tian",
        "Sizhe Wang",
        "Zhangyu Wang",
        "Joseph Zalewski",
        "Lu Zhou",
        "Rui Zhu"
      ],
      "abstract": "KnowWhereGraph is one of the largest fully publicly available geospatial\nknowledge graphs. It includes data from 30 layers on natural hazards (e.g.,\nhurricanes, wildfires), climate variables (e.g., air temperature,\nprecipitation), soil properties, crop and land-cover types, demographics, and\nhuman health, various place and region identifiers, among other themes. These\nhave been leveraged through the graph by a variety of applications to address\nchallenges in food security and agricultural supply chains; sustainability\nrelated to soil conservation practices and farm labor; and delivery of\nemergency humanitarian aid following a disaster. In this paper, we introduce\nthe ontology that acts as the schema for KnowWhereGraph. This broad overview\nprovides insight into the requirements and design specifications for the graph\nand its schema, including the development methodology (modular ontology\nmodeling) and the resources utilized to implement, materialize, and deploy\nKnowWhereGraph with its end-user interfaces and public query SPARQL endpoint.",
      "tldr_zh": "本文介绍了KnowWhereGraph Ontology，作为一个最大的完全公开地理空间知识图谱（knowledge graph）的schema。该本体整合了30个层的数据，包括自然灾害（如hurricanes、wildfires）、气候变量（如air temperature、precipitation）、土壤属性、人口统计和人文健康等领域，支持多种应用挑战，如食物安全、农业供应链可持续性和灾害后人道主义援助。开发采用模块化本体建模（modular ontology modeling）方法，利用各种资源实现图谱的构建和部署。最终，KnowWhereGraph提供了公共SPARQL查询端点，提升了地理空间数据的可访问性和实用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13948v1",
      "published_date": "2024-10-17 18:18:41 UTC",
      "updated_date": "2024-10-17 18:18:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:43:55.587696"
    },
    {
      "arxiv_id": "2410.14746v1",
      "title": "Accounting for Sycophancy in Language Model Uncertainty Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Sicilia",
        "Mert Inan",
        "Malihe Alikhani"
      ],
      "abstract": "Effective human-machine collaboration requires machine learning models to\nexternalize uncertainty, so users can reflect and intervene when necessary. For\nlanguage models, these representations of uncertainty may be impacted by\nsycophancy bias: proclivity to agree with users, even if they are wrong. For\ninstance, models may be over-confident in (incorrect) problem solutions\nsuggested by a user. We study the relationship between sycophancy and\nuncertainty estimation for the first time. We propose a generalization of the\ndefinition of sycophancy bias to measure downstream impacts on uncertainty\nestimation, and also propose a new algorithm (SyRoUP) to account for sycophancy\nin the uncertainty estimation process. Unlike previous works on sycophancy, we\nstudy a broad array of user behaviors, varying both correctness and confidence\nof user suggestions to see how model answers (and their certainty) change. Our\nexperiments across conversation forecasting and question-answering tasks show\nthat user confidence plays a critical role in modulating the effects of\nsycophancy, and that SyRoUP can better predict these effects. From these\nresults, we argue that externalizing both model and user uncertainty can help\nto mitigate the impacts of sycophancy bias.",
      "tldr_zh": "这篇论文探讨了 sycophancy bias（趋炎附势偏差）对语言模型 uncertainty estimation（不确定性估计）的影响，强调这种偏差可能导致模型过度同意用户错误建议，从而降低不确定性的准确性。研究者提出了一种扩展的 sycophancy 定义，并开发了新算法 SyRoUP，用于在不确定性估计过程中校正这一偏差，通过实验分析用户建议的正确性和信心水平。结果显示，用户信心是关键调节因素，SyRoUP 显著改善了预测效果，并建议外部化模型和用户的不确定性，以缓解 sycophancy bias 并提升人机协作效率。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14746v1",
      "published_date": "2024-10-17 18:00:25 UTC",
      "updated_date": "2024-10-17 18:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:44:07.719894"
    },
    {
      "arxiv_id": "2410.13857v1",
      "title": "How Numerical Precision Affects Mathematical Reasoning Capabilities of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Guhao Feng",
        "Kai Yang",
        "Yuntian Gu",
        "Xinyue Ai",
        "Shengjie Luo",
        "Jiacheng Sun",
        "Di He",
        "Zhenguo Li",
        "Liwei Wang"
      ],
      "abstract": "Despite the remarkable success of Transformer-based Large Language Models\n(LLMs) across various domains, understanding and enhancing their mathematical\ncapabilities remains a significant challenge. In this paper, we conduct a\nrigorous theoretical analysis of LLMs' mathematical abilities, with a specific\nfocus on their arithmetic performances. We identify numerical precision as a\nkey factor that influences their effectiveness in mathematical tasks. Our\nresults show that Transformers operating with low numerical precision fail to\naddress arithmetic tasks, such as iterated addition and integer multiplication,\nunless the model size grows super-polynomially with respect to the input\nlength. In contrast, Transformers with standard numerical precision can\nefficiently handle these tasks with significantly smaller model sizes. We\nfurther support our theoretical findings through empirical experiments that\nexplore the impact of varying numerical precision on arithmetic tasks,\nproviding valuable insights for improving the mathematical reasoning\ncapabilities of LLMs.",
      "tldr_zh": "本研究探讨了数值精度(numerical precision)对Large Language Models (LLMs)数学推理能力的影响，通过理论分析和实证实验，揭示了低精度Transformers在处理算术任务（如迭代加法和整数乘法）时表现不佳，除非模型规模以超多项式方式增长。相比之下，标准精度Transformers能用更小的模型规模高效完成这些任务。该研究为提升LLMs的数学能力提供了宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13857v1",
      "published_date": "2024-10-17 17:59:35 UTC",
      "updated_date": "2024-10-17 17:59:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:44:19.769160"
    },
    {
      "arxiv_id": "2410.13854v1",
      "title": "Can MLLMs Understand the Deep Implication Behind Chinese Images?",
      "title_zh": "MLLMs 是否能理解中国图像背后的深层含义？",
      "authors": [
        "Chenhao Zhang",
        "Xi Feng",
        "Yuelin Bai",
        "Xinrun Du",
        "Jinchang Hou",
        "Kaixin Deng",
        "Guangzeng Han",
        "Qinrui Li",
        "Bingli Wang",
        "Jiaheng Liu",
        "Xingwei Qu",
        "Yifei Zhang",
        "Qixuan Zhao",
        "Yiming Liang",
        "Ziqiang Liu",
        "Feiteng Fang",
        "Min Yang",
        "Wenhao Huang",
        "Chenghua Lin",
        "Ge Zhang",
        "Shiwen Ni"
      ],
      "abstract": "As the capabilities of Multimodal Large Language Models (MLLMs) continue to\nimprove, the need for higher-order capability evaluation of MLLMs is\nincreasing. However, there is a lack of work evaluating MLLM for higher-order\nperception and understanding of Chinese visual content. To fill the gap, we\nintroduce the **C**hinese **I**mage **I**mplication understanding\n**Bench**mark, **CII-Bench**, which aims to assess the higher-order perception\nand understanding capabilities of MLLMs for Chinese images. CII-Bench stands\nout in several ways compared to existing benchmarks. Firstly, to ensure the\nauthenticity of the Chinese context, images in CII-Bench are sourced from the\nChinese Internet and manually reviewed, with corresponding answers also\nmanually crafted. Additionally, CII-Bench incorporates images that represent\nChinese traditional culture, such as famous Chinese traditional paintings,\nwhich can deeply reflect the model's understanding of Chinese traditional\nculture. Through extensive experiments on CII-Bench across multiple MLLMs, we\nhave made significant findings. Initially, a substantial gap is observed\nbetween the performance of MLLMs and humans on CII-Bench. The highest accuracy\nof MLLMs attains 64.4%, where as human accuracy averages 78.2%, peaking at an\nimpressive 81.0%. Subsequently, MLLMs perform worse on Chinese traditional\nculture images, suggesting limitations in their ability to understand\nhigh-level semantics and lack a deep knowledge base of Chinese traditional\nculture. Finally, it is observed that most models exhibit enhanced accuracy\nwhen image emotion hints are incorporated into the prompts. We believe that\nCII-Bench will enable MLLMs to gain a better understanding of Chinese semantics\nand Chinese-specific images, advancing the journey towards expert artificial\ngeneral intelligence (AGI). Our project is publicly available at\nhttps://cii-bench.github.io/.",
      "tldr_zh": "本研究引入了CII-Bench基准，用于评估多模态大语言模型(MLLMs)对中国图像的高阶感知和理解能力，特别是针对中文语境和传统文化的图像，这些图像来自中文互联网并经过手动审核。实验结果显示，MLLMs的最高准确率仅为64.4%，远低于人类的平均78.2%和最高81.0%，尤其在处理中国传统文化图像时表现更差，暴露了模型在高阶语义理解和文化知识方面的局限。研究发现，通过在提示中加入图像情感提示，可以提升MLLMs的准确率。该基准有望帮助MLLMs更好地理解中文语义和特定图像，推动人工智能通用智能(AGI)的进展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages,18 figures. Project Page: https://cii-bench.github.io/ Code:\n  https://github.com/MING_X/CII-Bench Dataset:\n  https://huggingface.co/datasets/m-a-p/CII-Bench",
      "pdf_url": "http://arxiv.org/pdf/2410.13854v1",
      "published_date": "2024-10-17 17:59:24 UTC",
      "updated_date": "2024-10-17 17:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:44:32.497315"
    },
    {
      "arxiv_id": "2410.13852v1",
      "title": "Retrospective Learning from Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Zizhao Chen",
        "Mustafa Omer Gul",
        "Yiwei Chen",
        "Gloria Geng",
        "Anne Wu",
        "Yoav Artzi"
      ],
      "abstract": "Multi-turn interactions between large language models (LLMs) and users\nnaturally include implicit feedback signals. If an LLM responds in an\nunexpected way to an instruction, the user is likely to signal it by rephrasing\nthe request, expressing frustration, or pivoting to an alternative task. Such\nsignals are task-independent and occupy a relatively constrained subspace of\nlanguage, allowing the LLM to identify them even if it fails on the actual\ntask. This creates an avenue for continually learning from interactions without\nadditional annotations. We introduce ReSpect, a method to learn from such\nsignals in past interactions via retrospection. We deploy ReSpect in a new\nmultimodal interaction scenario, where humans instruct an LLM to solve an\nabstract reasoning task with a combinatorial solution space. Through thousands\nof interactions with humans, we show how ReSpect gradually improves task\ncompletion rate from 31% to 82%, all without any external annotation.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在多轮互动中从隐式反馈信号（如用户改写请求或表达沮丧）中学习的机制，提出ReSpect方法，通过回顾过去的互动来实现持续改进。ReSpect在多模态场景中应用于抽象推理任务，该任务具有组合解决方案空间，并能识别任务独立且语言受限的反馈信号。实验结果显示，通过数千次人类互动，任务完成率从31%提升至82%，无需任何外部注解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13852v1",
      "published_date": "2024-10-17 17:59:03 UTC",
      "updated_date": "2024-10-17 17:59:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:44:43.484951"
    },
    {
      "arxiv_id": "2410.13850v4",
      "title": "Influence Functions for Scalable Data Attribution in Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Bruno Mlodozeniec",
        "Runa Eschenhagen",
        "Juhan Bae",
        "Alexander Immer",
        "David Krueger",
        "Richard Turner"
      ],
      "abstract": "Diffusion models have led to significant advancements in generative\nmodelling. Yet their widespread adoption poses challenges regarding data\nattribution and interpretability. In this paper, we aim to help address such\nchallenges in diffusion models by developing an influence functions framework.\nInfluence function-based data attribution methods approximate how a model's\noutput would have changed if some training data were removed. In supervised\nlearning, this is usually used for predicting how the loss on a particular\nexample would change. For diffusion models, we focus on predicting the change\nin the probability of generating a particular example via several proxy\nmeasurements. We show how to formulate influence functions for such quantities\nand how previously proposed methods can be interpreted as particular design\nchoices in our framework. To ensure scalability of the Hessian computations in\ninfluence functions, we systematically develop K-FAC approximations based on\ngeneralised Gauss-Newton matrices specifically tailored to diffusion models. We\nrecast previously proposed methods as specific design choices in our framework\nand show that our recommended method outperforms previous data attribution\napproaches on common evaluations, such as the Linear Data-modelling Score (LDS)\nor retraining without top influences, without the need for method-specific\nhyperparameter tuning.",
      "tldr_zh": "本研究针对扩散模型（Diffusion models）在数据归因和可解释性方面的挑战，提出了一种基于影响函数（Influence Functions）的框架，用于评估训练数据对模型生成输出的影响。该框架专注于预测移除特定训练数据后，生成示例概率的变化，通过代理测量来量化这些变化，并将先前方法解读为其框架下的特定设计选择。为提升计算可扩展性，研究者开发了针对扩散模型的 K-FAC 近似方法，基于广义 Gauss-Newton 矩阵优化 Hessian 计算。实验结果显示，该方法在 Linear Data-modelling Score (LDS) 和无顶层影响重训练等评估中优于现有方法，且无需特定超参数调整。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13850v4",
      "published_date": "2024-10-17 17:59:02 UTC",
      "updated_date": "2025-03-17 13:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:45:50.277114"
    },
    {
      "arxiv_id": "2410.13848v1",
      "title": "Janus: Decoupling Visual Encoding for Unified Multimodal Understanding and Generation",
      "title_zh": "Janus：解耦视觉编码以实现统一的多模态理解和生成",
      "authors": [
        "Chengyue Wu",
        "Xiaokang Chen",
        "Zhiyu Wu",
        "Yiyang Ma",
        "Xingchao Liu",
        "Zizheng Pan",
        "Wen Liu",
        "Zhenda Xie",
        "Xingkai Yu",
        "Chong Ruan",
        "Ping Luo"
      ],
      "abstract": "In this paper, we introduce Janus, an autoregressive framework that unifies\nmultimodal understanding and generation. Prior research often relies on a\nsingle visual encoder for both tasks, such as Chameleon. However, due to the\ndiffering levels of information granularity required by multimodal\nunderstanding and generation, this approach can lead to suboptimal performance,\nparticularly in multimodal understanding. To address this issue, we decouple\nvisual encoding into separate pathways, while still leveraging a single,\nunified transformer architecture for processing. The decoupling not only\nalleviates the conflict between the visual encoder's roles in understanding and\ngeneration, but also enhances the framework's flexibility. For instance, both\nthe multimodal understanding and generation components can independently select\ntheir most suitable encoding methods. Experiments show that Janus surpasses\nprevious unified model and matches or exceeds the performance of task-specific\nmodels. The simplicity, high flexibility, and effectiveness of Janus make it a\nstrong candidate for next-generation unified multimodal models.",
      "tldr_zh": "本文提出 Janus，一种统一的 autoregressive framework，用于多模态理解和生成。不同于以往依赖单一视觉编码器（如 Chameleon）的做法，Janus 通过 decoupling visual encoding 将理解和生成任务的视觉处理路径分开，同时利用统一的 Transformer architecture 来缓解冲突并提升灵活性，例如允许每个组件选择最合适的编码方法。实验结果显示，Janus 超过了现有统一模型的性能，并在某些方面匹配或超过了任务特定模型。这种简单、高灵活性和有效性的设计，使 Janus 成为下一代统一多模态模型的强有力候选。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical Report",
      "pdf_url": "http://arxiv.org/pdf/2410.13848v1",
      "published_date": "2024-10-17 17:58:37 UTC",
      "updated_date": "2024-10-17 17:58:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:45:07.781929"
    },
    {
      "arxiv_id": "2410.13846v2",
      "title": "LightTransfer: Your Long-Context LLM is Secretly a Hybrid Model with Effortless Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Xuan Zhang",
        "Fengzhuo Zhang",
        "Cunxiao Du",
        "Chao Du",
        "Tianyu Pang",
        "Wei Gao",
        "Min Lin"
      ],
      "abstract": "Scaling language models to handle longer contexts introduces substantial\nmemory challenges due to the growing cost of key-value (KV) caches. Motivated\nby the efficiency gains of hybrid models and the broad availability of\npretrained large transformer backbones, we explore transitioning transformer\nmodels into hybrid architectures for a more efficient generation. In this work,\nwe propose LightTransfer, a lightweight method that transforms models such as\nLLaMA into hybrid variants. Our approach identifies lazy layers -- those\nfocusing on recent or initial tokens -- and replaces their full attention with\nstreaming attention. This transformation can be performed without any training\nfor long-context understanding tasks or with minimal fine-tuning for o1-like\nlong reasoning generation tasks that require stronger reasoning capabilities.\nExperiments across diverse benchmarks and models (e.g., LLaMA, Mistral,\nQwQ-STILL) demonstrate that, even when half of the layers are identified as\nlazy, LightTransfer achieves up to 2.17$\\times$ throughput improvement with\nminimal performance loss ($<1.5\\%$ on LongBench) and achieves 53.3\\% on math\nbenchmark AIME24 of advanced o1-like long reasoning model QwQ-STILL.",
      "tldr_zh": "这篇论文提出了 LightTransfer，一种轻量级方法，将长上下文语言模型（如 LLaMA）转化为混合模型，以解决 KV caches 带来的内存挑战和效率问题。该方法通过识别 lazy layers（那些专注于最近或初始标记的层）并用 streaming attention 替换它们的完整注意力，实现无训练适应长上下文理解任务，或只需最小微调用于 o1-like 长推理生成任务。实验结果显示，在多种基准（如 LongBench）和模型（包括 LLaMA、Mistral、QwQ-STILL）上，LightTransfer 实现了高达 2.17 倍的吞吐量改进，性能损失小于 1.5%，并在数学基准 AIME24 上达到 53.3% 的表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13846v2",
      "published_date": "2024-10-17 17:58:14 UTC",
      "updated_date": "2025-02-04 13:45:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:45:20.938731"
    },
    {
      "arxiv_id": "2410.13839v1",
      "title": "Accelerating Codec-based Speech Synthesis with Multi-Token Prediction and Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Tan Dat Nguyen",
        "Ji-Hoon Kim",
        "Jeongsoo Choi",
        "Shukjae Choi",
        "Jinseok Park",
        "Younglo Lee",
        "Joon Son Chung"
      ],
      "abstract": "The goal of this paper is to accelerate codec-based speech synthesis systems\nwith minimum sacrifice to speech quality. We propose an enhanced inference\nmethod that allows for flexible trade-offs between speed and quality during\ninference without requiring additional training. Our core idea is to predict\nmultiple tokens per inference step of the AR module using multiple prediction\nheads, resulting in a linear reduction in synthesis time as the number of heads\nincreases. Furthermore, we introduce a novel speculative decoding technique\nthat utilises a Viterbi-based algorithm to select the optimal sequence of\ngenerated tokens at each decoding step. In our experiments, we demonstrate that\nthe time required to predict each token is reduced by a factor of 4 to 5\ncompared to baseline models, with minimal quality trade-off or even improvement\nin terms of speech intelligibility. Audio samples are available at:\nmultpletokensprediction.github.io/multipletokensprediction.github.io/.",
      "tldr_zh": "本论文旨在加速基于编解码器的语音合成系统，同时最小化对语音质量的牺牲。研究提出一种增强的推理方法，使用多个预测头在 AR 模块的每个推理步骤中预测多个令牌（Multi-Token Prediction），从而实现合成时间的线性减少。论文还引入了一种基于 Viterbi 算法的推测解码技术（Speculative Decoding），用于在每个解码步骤选择最优令牌序列。实验结果显示，与基线模型相比，每个令牌的预测时间减少 4 到 5 倍，同时语音质量保持或在可懂度上有所改善。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to IEEE ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13839v1",
      "published_date": "2024-10-17 17:55:26 UTC",
      "updated_date": "2024-10-17 17:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:45:32.115732"
    },
    {
      "arxiv_id": "2410.13837v3",
      "title": "ORSO: Accelerating Reward Design via Online Reward Selection and Policy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Chen Bo Calvin Zhang",
        "Zhang-Wei Hong",
        "Aldo Pacchiano",
        "Pulkit Agrawal"
      ],
      "abstract": "Reward shaping is critical in reinforcement learning (RL), particularly for\ncomplex tasks where sparse rewards can hinder learning. However, choosing\neffective shaping rewards from a set of reward functions in a computationally\nefficient manner remains an open challenge. We propose Online Reward Selection\nand Policy Optimization (ORSO), a novel approach that frames the selection of\nshaping reward function as an online model selection problem. ORSO\nautomatically identifies performant shaping reward functions without human\nintervention with provable regret guarantees. We demonstrate ORSO's\neffectiveness across various continuous control tasks. Compared to prior\napproaches, ORSO significantly reduces the amount of data required to evaluate\na shaping reward function, resulting in superior data efficiency and a\nsignificant reduction in computational time (up to 8 times). ORSO consistently\nidentifies high-quality reward functions outperforming prior methods by more\nthan 50% and on average identifies policies as performant as the ones learned\nusing manually engineered reward functions by domain experts.",
      "tldr_zh": "该论文提出 ORSO（Online Reward Selection and Policy Optimization），一种创新方法，用于加速强化学习（Reinforcement Learning, RL）中的奖励塑造（Reward Shaping），通过将奖励函数选择视为在线模型选择问题来自动识别高效的塑造奖励函数，并提供可证明的遗憾保证（regret guarantees）。ORSO 无需人为干预，在各种连续控制任务中显著提升数据效率，减少评估奖励函数所需的数据量，并将计算时间缩短高达 8 倍。实验结果显示，ORSO 识别的高质量奖励函数比现有方法性能提升超过 50%，并能生成与专家手动设计的奖励函数相当的策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13837v3",
      "published_date": "2024-10-17 17:55:05 UTC",
      "updated_date": "2025-02-25 06:45:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:45:43.999175"
    },
    {
      "arxiv_id": "2410.13831v1",
      "title": "The Disparate Benefits of Deep Ensembles",
      "title_zh": "翻译失败",
      "authors": [
        "Kajetan Schweighofer",
        "Adrian Arnaiz-Rodriguez",
        "Sepp Hochreiter",
        "Nuria Oliver"
      ],
      "abstract": "Ensembles of Deep Neural Networks, Deep Ensembles, are widely used as a\nsimple way to boost predictive performance. However, their impact on\nalgorithmic fairness is not well understood yet. Algorithmic fairness\ninvestigates how a model's performance varies across different groups,\ntypically defined by protected attributes such as age, gender, or race. In this\nwork, we investigate the interplay between the performance gains from Deep\nEnsembles and fairness. Our analysis reveals that they unevenly favor different\ngroups in what we refer to as a disparate benefits effect. We empirically\ninvestigate this effect with Deep Ensembles applied to popular facial analysis\nand medical imaging datasets, where protected group attributes are given and\nfind that it occurs for multiple established group fairness metrics, including\nstatistical parity and equal opportunity. Furthermore, we identify the\nper-group difference in predictive diversity of ensemble members as the\npotential cause of the disparate benefits effect. Finally, we evaluate\ndifferent approaches to reduce unfairness due to the disparate benefits effect.\nOur findings show that post-processing is an effective method to mitigate this\nunfairness while preserving the improved performance of Deep Ensembles.",
      "tldr_zh": "本研究探讨了 Deep Ensembles（深度神经网络集成）在提升预测性能的同时，对算法公平性的影响，揭示了 disparate benefits effect，即不同保护群体（如基于年龄、性别或种族）的性能提升不均等。实验使用面部分析和医疗图像数据集，评估了多种公平性指标，包括 statistical parity 和 equal opportunity，结果显示这种效应与各群体的预测多样性差异有关。研究进一步识别了 disparate benefits effect 的潜在原因，并评估了缓解策略。最终发现，post-processing 方法能有效减少不公平，同时保留 Deep Ensembles 的整体性能提升。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13831v1",
      "published_date": "2024-10-17 17:53:01 UTC",
      "updated_date": "2024-10-17 17:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:46:02.784785"
    },
    {
      "arxiv_id": "2410.13828v2",
      "title": "A Common Pitfall of Margin-based Language Model Alignment: Gradient Entanglement",
      "title_zh": "基于边距的语言模型对齐的常见陷阱：梯度纠缠",
      "authors": [
        "Hui Yuan",
        "Yifan Zeng",
        "Yue Wu",
        "Huazheng Wang",
        "Mengdi Wang",
        "Liu Leqi"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become the predominant\napproach for language model (LM) alignment. At its core, RLHF uses a\nmargin-based loss for preference optimization, specifying ideal LM behavior\nonly by the difference between preferred and dispreferred responses. In this\npaper, we identify a common pitfall of margin-based methods -- the\nunder-specification of ideal LM behavior on preferred and dispreferred\nresponses individually, which leads to two unintended consequences as the\nmargin increases: (1) The probability of dispreferred (e.g., unsafe) responses\nmay increase, resulting in potential safety alignment failures. (2) The\nprobability of preferred responses may decrease, even when those responses are\nideal. We demystify the reasons behind these problematic behaviors:\nmargin-based losses couple the change in the preferred probability to the\ngradient of the dispreferred one, and vice versa, often preventing the\npreferred probability from increasing while the dispreferred one decreases, and\nthus causing a synchronized increase or decrease in both probabilities. We term\nthis effect, inherent in margin-based objectives, gradient entanglement.\nFormally, we derive conditions for general margin-based alignment objectives\nunder which gradient entanglement becomes concerning: the inner product of the\ngradients of preferred and dispreferred log-probabilities is large relative to\nthe individual gradient norms. We theoretically investigate why such inner\nproducts can be large when aligning language models and empirically validate\nour findings. Empirical implications of our framework extend to explaining\nimportant differences in the training dynamics of various preference\noptimization algorithms, and suggesting potential algorithm designs to mitigate\nthe under-specification issue of margin-based methods and thereby improving\nlanguage model alignment.",
      "tldr_zh": "该论文揭示了基于边界的语言模型对齐方法（如RLHF）的一个常见缺陷：gradient entanglement，这种现象导致理想行为欠指定，从而带来两个问题——非优选响应（如不安全响应）的概率可能增加，造成安全风险，以及优选响应的概率可能减少。研究者分析了gradient entanglement的原因，即优选和非优选log-概率的梯度耦合，使得两者变化相互影响，导致梯度内积相对于各自梯度范数过大。论文通过理论推导和实证验证，解释了这种耦合在语言模型对齐中的影响，并展示了它如何解释不同偏好优化算法的训练动态差异。最后，作者提出潜在算法设计来缓解这一问题，提高语言模型的整体对齐效果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13828v2",
      "published_date": "2024-10-17 17:52:01 UTC",
      "updated_date": "2025-04-22 15:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:46:14.814892"
    },
    {
      "arxiv_id": "2410.13826v2",
      "title": "Unearthing Skill-Level Insights for Understanding Trade-Offs of Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mazda Moayeri",
        "Vidhisha Balachandran",
        "Varun Chandrasekaran",
        "Safoora Yousefi",
        "Thomas Fel",
        "Soheil Feizi",
        "Besmira Nushi",
        "Neel Joshi",
        "Vibhav Vineet"
      ],
      "abstract": "With models getting stronger, evaluations have grown more complex, testing\nmultiple skills in one benchmark and even in the same instance at once.\nHowever, skill-wise performance is obscured when inspecting aggregate accuracy,\nunder-utilizing the rich signal modern benchmarks contain. We propose an\nautomatic approach to recover the underlying skills relevant for any evaluation\ninstance, by way of inspecting model-generated rationales. After validating the\nrelevance of rationale-parsed skills and inferring skills for $46$k instances\nover $12$ benchmarks, we observe many skills to be common across benchmarks,\nresulting in the curation of hundreds of skill-slices (i.e. sets of instances\ntesting a common skill). Inspecting accuracy over these slices yields novel\ninsights on model trade-offs: e.g., compared to GPT-4o and Claude 3.5 Sonnet,\non average, Gemini 1.5 Pro is $18\\%$ more accurate in \"computing molar mass\",\nbut $19\\%$ less accurate in \"applying constitutional law\", despite the overall\naccuracies of the three models differing by a mere $0.4\\%$. Furthermore, we\ndemonstrate the practical utility of our approach by showing that insights\nderived from skill slice analysis can generalize to held-out instances: when\nrouting each instance to the model strongest on the relevant skills, we see a\n$3\\%$ accuracy improvement over our $12$ dataset corpus. Our skill-slices and\nframework open a new avenue in model evaluation, leveraging skill-specific\nanalyses to unlock a more granular and actionable understanding of model\ncapabilities.",
      "tldr_zh": "这篇论文提出了一种自动方法，通过分析模型生成的rationales来提取和识别评估实例中的底层技能，从而揭示foundation models在多技能基准上的性能权衡。研究人员为46k个实例（跨越12个基准）推断技能，并创建了数百个skill-slices（测试共同技能的实例集），发现如Gemini 1.5 Pro在“computing molar mass”上比GPT-4o和Claude 3.5 Sonnet高18%，但在“applying constitutional law”上低19%，尽管整体准确率仅差0.4%。通过基于skill-slices的实例路由，他们实现了12个数据集上3%的准确率提升，为模型评估提供更细粒度和可操作的洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Code at: github.com/microsoft/skill-slice-insights",
      "pdf_url": "http://arxiv.org/pdf/2410.13826v2",
      "published_date": "2024-10-17 17:51:40 UTC",
      "updated_date": "2024-10-24 17:27:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:46:27.381479"
    },
    {
      "arxiv_id": "2410.13825v1",
      "title": "AgentOccam: A Simple Yet Strong Baseline for LLM-Based Web Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Yang",
        "Yao Liu",
        "Sapana Chaudhary",
        "Rasool Fakoor",
        "Pratik Chaudhari",
        "George Karypis",
        "Huzefa Rangwala"
      ],
      "abstract": "Autonomy via agents using large language models (LLMs) for personalized,\nstandardized tasks boosts human efficiency. Automating web tasks (like booking\nhotels within a budget) is increasingly sought after. Fulfilling practical\nneeds, the web agent also serves as an important proof-of-concept example for\nvarious agent grounding scenarios, with its success promising advancements in\nmany future applications. Prior research often handcrafts web agent strategies\n(e.g., prompting templates, multi-agent systems, search methods, etc.) and the\ncorresponding in-context examples, which may not generalize well across all\nreal-world scenarios. On the other hand, there has been limited study on the\nmisalignment between a web agent's observation/action representation and the\npre-training data of the LLM it's based on. This discrepancy is especially\nnotable when LLMs are primarily trained for language completion rather than\ntasks involving embodied navigation actions and symbolic web elements. Our\nstudy enhances an LLM-based web agent by simply refining its observation and\naction space to better align with the LLM's capabilities. This approach enables\nour base agent to significantly outperform previous methods on a wide variety\nof web tasks. Specifically, on WebArena, a benchmark featuring general-purpose\nweb interaction tasks, our agent AgentOccam surpasses the previous\nstate-of-the-art and concurrent work by 9.8 (+29.4%) and 5.9 (+15.8%) absolute\npoints respectively, and boosts the success rate by 26.6 points (+161%) over\nsimilar plain web agents with its observation and action space alignment. We\nachieve this without using in-context examples, new agent roles, online\nfeedback or search strategies. AgentOccam's simple design highlights LLMs'\nimpressive zero-shot performance on web tasks, and underlines the critical role\nof carefully tuning observation and action spaces for LLM-based agents.",
      "tldr_zh": "本文提出AgentOccam，一种简单却高效的基准框架，用于基于LLM (Large Language Models) 的网络代理，通过优化观察和动作空间的表示来更好地与LLM能力对齐，从而解决现有方法在实际场景中的泛化问题。该框架无需使用in-context examples、新代理角色、在线反馈或搜索策略，即可在WebArena基准测试中，将成功率提升26.6点（+161%），并超越先前最先进方法9.8点（+29.4%）。这项研究突显了LLMs在网络任务上的零样本性能（zero-shot performance），并强调了精细调整观察和动作空间对构建可靠代理的关键作用。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13825v1",
      "published_date": "2024-10-17 17:50:38 UTC",
      "updated_date": "2024-10-17 17:50:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:46:39.268140"
    },
    {
      "arxiv_id": "2410.13822v1",
      "title": "Multi-style conversion for semantic segmentation of lesions in fundus images by adversarial attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Clément Playout",
        "Renaud Duval",
        "Marie Carole Boucher",
        "Farida Cheriet"
      ],
      "abstract": "The diagnosis of diabetic retinopathy, which relies on fundus images, faces\nchallenges in achieving transparency and interpretability when using a global\nclassification approach. However, segmentation-based databases are\nsignificantly more expensive to acquire and combining them is often\nproblematic. This paper introduces a novel method, termed adversarial style\nconversion, to address the lack of standardization in annotation styles across\ndiverse databases. By training a single architecture on combined databases, the\nmodel spontaneously modifies its segmentation style depending on the input,\ndemonstrating the ability to convert among different labeling styles. The\nproposed methodology adds a linear probe to detect dataset origin based on\nencoder features and employs adversarial attacks to condition the model's\nsegmentation style. Results indicate significant qualitative and quantitative\nthrough dataset combination, offering avenues for improved model\ngeneralization, uncertainty estimation and continuous interpolation between\nannotation styles. Our approach enables training a segmentation model with\ndiverse databases while controlling and leveraging annotation styles for\nimproved retinopathy diagnosis.",
      "tldr_zh": "这篇论文针对糖尿病视网膜病变（diabetic retinopathy）的诊断问题，提出了一种名为adversarial style conversion的新方法，用于处理眼底图像中病变语义分割（semantic segmentation）的标注风格差异，从而实现不同数据库的结合训练。方法包括添加线性探针（linear probe）基于编码器特征（encoder features）检测数据集来源，并运用adversarial attacks来调节模型的分割风格，使其根据输入自动转换风格。实验结果显示，该方法显著提高了模型的泛化能力（model generalization）、不确定性估计（uncertainty estimation）和标注风格之间的连续插值，最终提升了视网膜病变诊断的准确性、可解释性和整体性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.13822v1",
      "published_date": "2024-10-17 17:48:17 UTC",
      "updated_date": "2024-10-17 17:48:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:46:50.900008"
    },
    {
      "arxiv_id": "2410.13821v3",
      "title": "Artificial Kuramoto Oscillatory Neurons",
      "title_zh": "人工 Kuramoto 振荡神经元",
      "authors": [
        "Takeru Miyato",
        "Sindy Löwe",
        "Andreas Geiger",
        "Max Welling"
      ],
      "abstract": "It has long been known in both neuroscience and AI that ``binding'' between\nneurons leads to a form of competitive learning where representations are\ncompressed in order to represent more abstract concepts in deeper layers of the\nnetwork. More recently, it was also hypothesized that dynamic (spatiotemporal)\nrepresentations play an important role in both neuroscience and AI. Building on\nthese ideas, we introduce Artificial Kuramoto Oscillatory Neurons (AKOrN) as a\ndynamical alternative to threshold units, which can be combined with arbitrary\nconnectivity designs such as fully connected, convolutional, or attentive\nmechanisms. Our generalized Kuramoto updates bind neurons together through\ntheir synchronization dynamics. We show that this idea provides performance\nimprovements across a wide spectrum of tasks such as unsupervised object\ndiscovery, adversarial robustness, calibrated uncertainty quantification, and\nreasoning. We believe that these empirical results show the importance of\nrethinking our assumptions at the most basic neuronal level of neural\nrepresentation, and in particular show the importance of dynamical\nrepresentations. Code:https://github.com/autonomousvision/akorn Project\npage:https://takerum.github.io/akorn_project_page/",
      "tldr_zh": "该论文探讨了神经科学和AI中神经元“binding”（绑定）机制如何通过竞争性学习压缩表示以形成更抽象的概念，并强调动态（spatiotemporal）表示的重要性。作者引入了Artificial Kuramoto Oscillatory Neurons (AKOrN)作为阈值单元的动态替代方案，通过Kuramoto updates的同步动态将神经元绑定，并支持任意连接设计如全连接、卷积或注意力机制。在实验中，AKOrN在无监督对象发现、抗对抗性攻击、校准的不确定性量化以及推理等任务上表现出性能提升，证明了动态表示在神经网络设计中的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for Oral presentation at ICLR2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13821v3",
      "published_date": "2024-10-17 17:47:54 UTC",
      "updated_date": "2025-05-16 19:02:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:47:01.680230"
    },
    {
      "arxiv_id": "2410.13817v1",
      "title": "Guided Reinforcement Learning for Robust Multi-Contact Loco-Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Jean-Pierre Sleiman",
        "Mayank Mittal",
        "Marco Hutter"
      ],
      "abstract": "Reinforcement learning (RL) often necessitates a meticulous Markov Decision\nProcess (MDP) design tailored to each task. This work aims to address this\nchallenge by proposing a systematic approach to behavior synthesis and control\nfor multi-contact loco-manipulation tasks, such as navigating spring-loaded\ndoors and manipulating heavy dishwashers. We define a task-independent MDP to\ntrain RL policies using only a single demonstration per task generated from a\nmodel-based trajectory optimizer. Our approach incorporates an adaptive phase\ndynamics formulation to robustly track the demonstrations while accommodating\ndynamic uncertainties and external disturbances. We compare our method against\nprior motion imitation RL works and show that the learned policies achieve\nhigher success rates across all considered tasks. These policies learn recovery\nmaneuvers that are not present in the demonstration, such as re-grasping\nobjects during execution or dealing with slippages. Finally, we successfully\ntransfer the policies to a real robot, demonstrating the practical viability of\nour approach.",
      "tldr_zh": "本文提出了一种针对多接触 loco-manipulation 任务的引导强化学习（Reinforcement Learning）方法，以解决 Markov Decision Process (MDP) 设计依赖任务的挑战。该方法使用任务无关的 MDP 和每个任务的单一演示（由基于模型的轨迹优化器生成）来训练 RL 策略，并引入自适应相位动力学公式，以鲁棒地跟踪演示并应对动态不确定性和外部干扰。与现有运动模仿 RL 方法相比，该策略在所有任务中实现了更高的成功率，并学会了演示中不存在的恢复动作，如重新抓取物体或处理滑动。最后，该策略成功转移到真实机器人，证明了其实际可行性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "J. P. Sleiman and M. Mittal contributed equally. Accepted for CoRL\n  2024 (Oral). Project website:\n  https://leggedrobotics.github.io/guided-rl-locoma/",
      "pdf_url": "http://arxiv.org/pdf/2410.13817v1",
      "published_date": "2024-10-17 17:46:27 UTC",
      "updated_date": "2024-10-17 17:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:47:13.922749"
    },
    {
      "arxiv_id": "2410.16320v1",
      "title": "Accelerating Object Detection with YOLOv4 for Real-Time Applications",
      "title_zh": "翻译失败",
      "authors": [
        "K. Senthil Kumar",
        "K. M. B. Abdullah Safwan"
      ],
      "abstract": "Object Detection is related to Computer Vision. Object detection enables\ndetecting instances of objects in images and videos. Due to its increased\nutilization in surveillance, tracking system used in security and many others\napplications have propelled researchers to continuously derive more efficient\nand competitive algorithms. However, problems emerges while implementing it in\nreal-time because of their dynamic environment and complex algorithms used in\nobject detection. In the last few years, Convolution Neural Network (CNN) have\nemerged as a powerful tool for recognizing image content and in computer vision\napproach for most problems. In this paper, We revived begins the brief\nintroduction of deep learning and object detection framework like Convolutional\nNeural Network(CNN), You only look once - version 4 (YOLOv4). Then we focus on\nour proposed object detection architectures along with some modifications. The\ntraditional model detects a small object in images. We have some modifications\nto the model. Our proposed method gives the correct result with accuracy.",
      "tldr_zh": "这篇论文探讨了物体检测在实时应用中的挑战，如动态环境和复杂算法导致的效率问题。作者基于 Convolutional Neural Network (CNN) 和 You only look once - version 4 (YOLOv4) 框架，提出了一种改进的物体检测架构，特别是针对小物体检测的修改。实验结果显示，该方法提高了检测准确性，使其更适合于安全监控和跟踪等实时场景。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.16320v1",
      "published_date": "2024-10-17 17:44:57 UTC",
      "updated_date": "2024-10-17 17:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:47:35.221530"
    },
    {
      "arxiv_id": "2410.19811v1",
      "title": "ControlAgent: Automating Control System Design via Novel Integration of LLM Agents and Domain Expertise",
      "title_zh": "翻译失败",
      "authors": [
        "Xingang Guo",
        "Darioush Keivan",
        "Usman Syed",
        "Lianhui Qin",
        "Huan Zhang",
        "Geir Dullerud",
        "Peter Seiler",
        "Bin Hu"
      ],
      "abstract": "Control system design is a crucial aspect of modern engineering with\nfar-reaching applications across diverse sectors including aerospace,\nautomotive systems, power grids, and robotics. Despite advances made by Large\nLanguage Models (LLMs) in various domains, their application in control system\ndesign remains limited due to the complexity and specificity of control theory.\nTo bridge this gap, we introduce ControlAgent, a new paradigm that automates\ncontrol system design via novel integration of LLM agents and control-oriented\ndomain expertise. ControlAgent encodes expert control knowledge and emulates\nhuman iterative design processes by gradually tuning controller parameters to\nmeet user-specified requirements for stability, performance, and robustness.\nControlAgent integrates multiple collaborative LLM agents, including a central\nagent responsible for task distribution and task-specific agents dedicated to\ndetailed controller design for various types of systems and requirements.\nControlAgent also employs a Python computation agent that performs complex\ncalculations and controller evaluations based on standard design information\nprovided by task-specified LLM agents. Combined with a history and feedback\nmodule, the task-specific LLM agents iteratively refine controller parameters\nbased on real-time feedback from prior designs. Overall, ControlAgent mimics\nthe design processes used by (human) practicing engineers, but removes all the\nhuman efforts and can be run in a fully automated way to give end-to-end\nsolutions for control system design with user-specified requirements. To\nvalidate ControlAgent's effectiveness, we develop ControlEval, an evaluation\ndataset that comprises 500 control tasks with various specific design goals.\nThe effectiveness of ControlAgent is demonstrated via extensive comparative\nevaluations between LLM-based and traditional human-involved toolbox-based\nbaselines.",
      "tldr_zh": "该论文引入了 ControlAgent，一种创新框架，通过整合 LLM 代理和控制领域专业知识，实现控制系统设计的自动化。ControlAgent 模拟人类工程师的迭代过程，包括中央代理负责任务分配、任务特定代理进行详细设计，以及 Python 计算代理执行计算和评估，同时利用历史反馈模块逐步优化控制器参数以满足稳定性、性能和鲁棒性要求。实验在自开发的 ControlEval 数据集（包含 500 个任务）上进行，与传统工具和 LLM 基线相比，ControlAgent 展示了显著的优越性，为端到端的自动化控制系统设计提供了可靠解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19811v1",
      "published_date": "2024-10-17 17:42:48 UTC",
      "updated_date": "2024-10-17 17:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:47:37.854837"
    },
    {
      "arxiv_id": "2410.13803v1",
      "title": "A Pattern to Align Them All: Integrating Different Modalities to Define Multi-Modal Entities",
      "title_zh": "翻译失败",
      "authors": [
        "Gianluca Apriceno",
        "Valentina Tamma",
        "Tania Bailoni",
        "Jacopo de Berardinis",
        "Mauro Dragoni"
      ],
      "abstract": "The ability to reason with and integrate different sensory inputs is the\nfoundation underpinning human intelligence and it is the reason for the growing\ninterest in modelling multi-modal information within Knowledge Graphs.\nMulti-Modal Knowledge Graphs extend traditional Knowledge Graphs by associating\nan entity with its possible modal representations, including text, images,\naudio, and videos, all of which are used to convey the semantics of the entity.\nDespite the increasing attention that Multi-Modal Knowledge Graphs have\nreceived, there is a lack of consensus about the definitions and modelling of\nmodalities, whose definition is often determined by application domains. In\nthis paper, we propose a novel ontology design pattern that captures the\nseparation of concerns between an entity (and the information it conveys),\nwhose semantics can have different manifestations across different media, and\nits realisation in terms of a physical information entity. By introducing this\nabstract model, we aim to facilitate the harmonisation and integration of\ndifferent existing multi-modal ontologies which is crucial for many intelligent\napplications across different domains spanning from medicine to digital\nhumanities.",
      "tldr_zh": "该论文探讨了多模态知识图谱（Multi-Modal Knowledge Graphs）的建模问题，强调人类智能依赖于整合不同感官输入，如文本、图像、音频和视频，以传达实体语义。作者提出一个新的本体设计模式（ontology design pattern），通过区分实体及其语义在不同媒体中的表现与物理信息实体的实现，实现关注点的分离。這種模式旨在促进不同多模态本体的协调和整合，支持从医学到数字人文等领域的智能应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13803v1",
      "published_date": "2024-10-17 17:41:04 UTC",
      "updated_date": "2024-10-17 17:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:47:53.343191"
    },
    {
      "arxiv_id": "2410.13798v2",
      "title": "Learning Graph Quantized Tokenizers",
      "title_zh": "翻译失败",
      "authors": [
        "Limei Wang",
        "Kaveh Hassani",
        "Si Zhang",
        "Dongqi Fu",
        "Baichuan Yuan",
        "Weilin Cong",
        "Zhigang Hua",
        "Hao Wu",
        "Ning Yao",
        "Bo Long"
      ],
      "abstract": "Transformers serve as the backbone architectures of Foundational Models,\nwhere domain-specific tokenizers allow them to adapt to various domains. Graph\nTransformers (GTs) have recently emerged as leading models in geometric deep\nlearning, outperforming Graph Neural Networks (GNNs) in various graph learning\ntasks. However, the development of tokenizers for graphs has lagged behind\nother modalities. To address this, we introduce GQT (\\textbf{G}raph\n\\textbf{Q}uantized \\textbf{T}okenizer), which decouples tokenizer training from\nTransformer training by leveraging multi-task graph self-supervised learning,\nyielding robust and generalizable graph tokens. Furthermore, the GQT utilizes\nResidual Vector Quantization (RVQ) to learn hierarchical discrete tokens,\nresulting in significantly reduced memory requirements and improved\ngeneralization capabilities. By combining the GQT with token modulation, a\nTransformer encoder achieves state-of-the-art performance on 20 out of 22\nbenchmarks, including large-scale homophilic and heterophilic datasets.",
      "tldr_zh": "该论文提出 GQT (\\textbf{G}raph \\textbf{Q}uantized \\textbf{T}okenizer)，一种用于图数据的 tokenizer，通过多任务图自监督学习与 Transformer 训练分离，实现鲁棒且可泛化的图 token。GQT 采用 Residual Vector Quantization (RVQ) 来学习分层离散 token，从而显著降低内存需求并提升泛化能力。将 GQT 与 token modulation 结合后，Transformer 编码器在 22 个基准测试中，在 20 个上（包括大规模同质和异质数据集）达到最先进性能。整体方法有助于推动 Graph Transformers (GTs) 在几何深度学习中的应用，超越传统 Graph Neural Networks (GNNs)。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13798v2",
      "published_date": "2024-10-17 17:38:24 UTC",
      "updated_date": "2025-04-02 03:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:48:02.431030"
    },
    {
      "arxiv_id": "2410.13787v1",
      "title": "Looking Inward: Language Models Can Learn About Themselves by Introspection",
      "title_zh": "翻译失败",
      "authors": [
        "Felix J Binder",
        "James Chua",
        "Tomek Korbak",
        "Henry Sleight",
        "John Hughes",
        "Robert Long",
        "Ethan Perez",
        "Miles Turpin",
        "Owain Evans"
      ],
      "abstract": "Humans acquire knowledge by observing the external world, but also by\nintrospection. Introspection gives a person privileged access to their current\nstate of mind (e.g., thoughts and feelings) that is not accessible to external\nobservers. Can LLMs introspect? We define introspection as acquiring knowledge\nthat is not contained in or derived from training data but instead originates\nfrom internal states. Such a capability could enhance model interpretability.\nInstead of painstakingly analyzing a model's internal workings, we could simply\nask the model about its beliefs, world models, and goals. More speculatively,\nan introspective model might self-report on whether it possesses certain\ninternal states such as subjective feelings or desires and this could inform us\nabout the moral status of these states. Such self-reports would not be entirely\ndictated by the model's training data.\n  We study introspection by finetuning LLMs to predict properties of their own\nbehavior in hypothetical scenarios. For example, \"Given the input P, would your\noutput favor the short- or long-term option?\" If a model M1 can introspect, it\nshould outperform a different model M2 in predicting M1's behavior even if M2\nis trained on M1's ground-truth behavior. The idea is that M1 has privileged\naccess to its own behavioral tendencies, and this enables it to predict itself\nbetter than M2 (even if M2 is generally stronger).\n  In experiments with GPT-4, GPT-4o, and Llama-3 models (each finetuned to\npredict itself), we find that the model M1 outperforms M2 in predicting itself,\nproviding evidence for introspection. Notably, M1 continues to predict its\nbehavior accurately even after we intentionally modify its ground-truth\nbehavior. However, while we successfully elicit introspection on simple tasks,\nwe are unsuccessful on more complex tasks or those requiring\nout-of-distribution generalization.",
      "tldr_zh": "本论文探讨语言模型（LLMs）是否能通过内省（introspection）学习自身内部状态，即获取非训练数据来源的知识，以提升模型可解释性和潜在道德考量。研究方法涉及微调模型（如 GPT-4 和 Llama-3）来预测自身在假设场景中的行为，并与外部模型比较，结果显示微调模型 M1 在预测自身行为时优于其他模型 M2，即使 M2 知道 M1 的真实行为。实验证明内省在简单任务上有效，但复杂任务或需要 out-of-distribution generalization 时失败，为未来开发更可解释的 AI 提供了初步证据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13787v1",
      "published_date": "2024-10-17 17:24:10 UTC",
      "updated_date": "2024-10-17 17:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:48:14.024871"
    },
    {
      "arxiv_id": "2410.13785v1",
      "title": "PopAlign: Diversifying Contrasting Patterns for a More Comprehensive Alignment",
      "title_zh": "PopAlign：多样化对比模式以实现更全面的对齐",
      "authors": [
        "Zekun Moore Wang",
        "Shawn Wang",
        "Kang Zhu",
        "Jiaheng Liu",
        "Ke Xu",
        "Jie Fu",
        "Wangchunshu Zhou",
        "Wenhao Huang"
      ],
      "abstract": "Alignment of large language models (LLMs) involves training models on\npreference-contrastive output pairs to adjust their responses according to\nhuman preferences. To obtain such contrastive pairs, traditional methods like\nRLHF and RLAIF rely on limited contrasting patterns, such as varying model\nvariants or decoding temperatures. This singularity leads to two issues: (1)\nalignment is not comprehensive; and thereby (2) models are susceptible to\njailbreaking attacks. To address these issues, we investigate how to construct\nmore comprehensive and diversified contrasting patterns to enhance preference\ndata (RQ1) and verify the impact of the diversification of contrasting patterns\non model alignment (RQ2). For RQ1, we propose PopAlign, a framework that\nintegrates diversified contrasting patterns across the prompt, model, and\npipeline levels, introducing six contrasting strategies that do not require\nadditional feedback labeling procedures. Regarding RQ2, we conduct thorough\nexperiments demonstrating that PopAlign significantly outperforms existing\nmethods, leading to more comprehensive alignment.",
      "tldr_zh": "大型语言模型 (LLMs) 的对齐训练通常依赖于有限的对比模式，如 RLHF 和 RLAIF，这导致对齐不全面并使模型易受越狱攻击。论文提出 PopAlign 框架，通过在提示、模型和管道级别整合多样化的对比策略，引入六种不需要额外反馈标签过程的策略，从而构建更全面的偏好对比数据。实验结果表明，PopAlign 显著优于现有方法，提升了模型对齐的整体效果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.13785v1",
      "published_date": "2024-10-17 17:22:05 UTC",
      "updated_date": "2024-10-17 17:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:48:25.563893"
    },
    {
      "arxiv_id": "2410.13780v2",
      "title": "Optimal Quantization for Matrix Multiplication",
      "title_zh": "矩阵乘法的优化量化",
      "authors": [
        "Or Ordentlich",
        "Yury Polyanskiy"
      ],
      "abstract": "Recent work in machine learning community proposed multiple methods for\nperforming lossy compression (quantization) of large matrices. This\nquantization is important for accelerating matrix multiplication (main\ncomponent of large language models), which is often bottlenecked by the speed\nof loading these matrices from memory. Unlike classical vector quantization and\nrate-distortion theory, the goal of these new compression algorithms is to be\nable to approximate not the matrices themselves, but their matrix product.\nSpecifically, given a pair of real matrices $A,B$ an encoder (compressor) is\napplied to each of them independently producing descriptions with $R$ bits per\nentry. These representations subsequently are used by the decoder to estimate\nmatrix product $A^\\top B$. In this work, we provide a non-asymptotic lower\nbound on the mean squared error of this approximation (as a function of rate\n$R$) for the case of matrices $A,B$ with iid Gaussian entries. Algorithmically,\nwe construct a universal quantizer based on nested lattices with an explicit\nguarantee of approximation error for any (non-random) pair of matrices $A$, $B$\nin terms of only Frobenius norms $\\|\\bar{A}\\|_F, \\|\\bar{B}\\|_F$ and\n$\\|\\bar{A}^\\top \\bar{B}\\|_F$, where $\\bar{A},\\bar{B}$ are versions of $A,B$\nwith zero-centered columns, respectively. For iid Gaussian matrices our\nquantizer achieves the lower bound and is, thus, asymptotically optimal. A\npractical low-complexity version of our quantizer achieves performance quite\nclose to optimal. In addition, we derive rate-distortion function for matrix\nmultiplication of iid Gaussian matrices, which exhibits an interesting\nphase-transition at $R\\approx 0.906$ bit/entry.",
      "tldr_zh": "本研究针对机器学习中大矩阵的量化压缩，优化了matrix multiplication的过程，以加速大语言模型的计算。该方法专注于近似矩阵乘积而非矩阵本身，通过独立编码矩阵 A 和 B，每条目使用 R bits，提供了一个非渐近下界，针对iid Gaussian matrices的均方误差作为 R 的函数。作者构建了一个基于nested lattices的通用量化器，能够为任意矩阵提供显式误差保证，依赖于Frobenius norms，并证明其在iid Gaussian matrices上达到渐近最优。实验显示，该量化器的低复杂度版本性能接近最优，并导出了矩阵乘法的rate-distortion函数，在 R ≈ 0.906 bit/entry处出现相变现象。",
      "categories": [
        "cs.IT",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "cs.IT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13780v2",
      "published_date": "2024-10-17 17:19:48 UTC",
      "updated_date": "2025-01-17 14:26:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:48:40.780524"
    },
    {
      "arxiv_id": "2410.13778v1",
      "title": "Change Detection in Multivariate data streams: Online Analysis with Kernel-QuantTree",
      "title_zh": "翻译失败",
      "authors": [
        "Michelangelo Olmo Nogara Notarianni",
        "Filippo Leveni",
        "Diego Stucchi",
        "Luca Frittoli",
        "Giacomo Boracchi"
      ],
      "abstract": "We present Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA),\na non-parametric change-detection algorithm that combines the Kernel-QuantTree\n(KQT) histogram and the EWMA statistic to monitor multivariate data streams\nonline. The resulting monitoring scheme is very flexible, since histograms can\nbe used to model any stationary distribution, and practical, since the\ndistribution of test statistics does not depend on the distribution of\ndatastream in stationary conditions (non-parametric monitoring). KQT-EWMA\nenables controlling false alarms by operating at a pre-determined Average Run\nLength ($ARL_0$), which measures the expected number of stationary samples to\nbe monitored before triggering a false alarm. The latter peculiarity is in\ncontrast with most non-parametric change-detection tests, which rarely can\ncontrol the $ARL_0$ a priori. Our experiments on synthetic and real-world\ndatasets demonstrate that KQT-EWMA can control $ARL_0$ while achieving\ndetection delays comparable to or lower than state-of-the-art methods designed\nto work in the same conditions.",
      "tldr_zh": "本文提出了一种名为 Kernel-QuantTree Exponentially Weighted Moving Average (KQT-EWMA) 的非参数变更检测算法，结合 Kernel-QuantTree (KQT) 直方图和 EWMA 统计量，用于在线监控多变量数据流。 该方法具有灵活性和实用性，能建模任意平稳分布，并通过预设的 Average Run Length ($ARL_0$) 来控制假警报，确保在平稳条件下测试统计量的分布独立于数据流分布。 实验在合成和真实数据集上显示，KQT-EWMA 实现了与最先进方法相当或更低的检测延迟，同时有效维持了对 $ARL_0$ 的控制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "AALTD workshop at ECML 2024 (https://ecml-aaltd.github.io/aaltd2024/)",
      "pdf_url": "http://arxiv.org/pdf/2410.13778v1",
      "published_date": "2024-10-17 17:17:38 UTC",
      "updated_date": "2024-10-17 17:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:48:51.859711"
    },
    {
      "arxiv_id": "2410.13776v3",
      "title": "Aggregation Artifacts in Subjective Tasks Collapse Large Language Models' Posteriors",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Chochlakis",
        "Alexandros Potamianos",
        "Kristina Lerman",
        "Shrikanth Narayanan"
      ],
      "abstract": "In-context Learning (ICL) has become the primary method for performing\nnatural language tasks with Large Language Models (LLMs). The knowledge\nacquired during pre-training is crucial for this few-shot capability, providing\nthe model with task priors. However, recent studies have shown that ICL\npredominantly relies on retrieving task priors rather than \"learning\" to\nperform tasks. This limitation is particularly evident in complex subjective\ndomains such as emotion and morality, where priors significantly influence\nposterior predictions. In this work, we examine whether this is the result of\nthe aggregation used in corresponding datasets, where trying to combine\nlow-agreement, disparate annotations might lead to annotation artifacts that\ncreate detrimental noise in the prompt. Moreover, we evaluate the posterior\nbias towards certain annotators by grounding our study in appropriate,\nquantitative measures of LLM priors. Our results indicate that aggregation is a\nconfounding factor in the modeling of subjective tasks, and advocate focusing\non modeling individuals instead. However, aggregation does not explain the\nentire gap between ICL and the state of the art, meaning other factors in such\ntasks also account for the observed phenomena. Finally, by rigorously studying\nannotator-level labels, we find that it is possible for minority annotators to\nboth better align with LLMs and have their perspectives further amplified.",
      "tldr_zh": "这篇论文探讨了 In-context Learning (ICL) 在主观任务（如情感和道德领域）中的局限性，揭示 ICL 主要依赖预训练的任务 priors 而非真正学习，导致 Large Language Models (LLMs) 的后验预测出现崩溃。研究者分析了数据集中的 aggregation artifacts，这些标注聚合过程可能引入噪声，并通过定量措施评估了 LLM 对特定标注者的偏见。结果表明，aggregation 是主观任务建模的混杂因素，建议转向个体建模以改善效果；尽管如此，其他因素也部分解释了 ICL 与最先进方法的差距，并发现少数标注者可能更与 LLM 一致且其观点被放大。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 12 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.13776v3",
      "published_date": "2024-10-17 17:16:00 UTC",
      "updated_date": "2025-02-04 19:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:49:04.124471"
    },
    {
      "arxiv_id": "2410.13772v2",
      "title": "Is Prior-Free Black-Box Non-Stationary Reinforcement Learning Feasible?",
      "title_zh": "无先验黑箱非平稳强化学习是否可行？",
      "authors": [
        "Argyrios Gerogiannis",
        "Yu-Han Huang",
        "Venugopal V. Veeravalli"
      ],
      "abstract": "We study the problem of Non-Stationary Reinforcement Learning (NS-RL) without\nprior knowledge about the system's non-stationarity. A state-of-the-art,\nblack-box algorithm, known as MASTER, is considered, with a focus on\nidentifying the conditions under which it can achieve its stated goals.\nSpecifically, we prove that MASTER's non-stationarity detection mechanism is\nnot triggered for practical choices of horizon, leading to performance akin to\na random restarting algorithm. Moreover, we show that the regret bound for\nMASTER, while being order optimal, stays above the worst-case linear regret\nuntil unreasonably large values of the horizon. To validate these observations,\nMASTER is tested for the special case of piecewise stationary multi-armed\nbandits, along with methods that employ random restarting, and others that use\nquickest change detection to restart. A simple, order optimal random restarting\nalgorithm, that has prior knowledge of the non-stationarity is proposed as a\nbaseline. The behavior of the MASTER algorithm is validated in simulations, and\nit is shown that methods employing quickest change detection are more robust\nand consistently outperform MASTER and other random restarting approaches.",
      "tldr_zh": "本研究探讨了无先验知识的黑盒非平稳强化学习 (NS-RL) 是否可行，焦点在于评估现有算法 MASTER 的表现。论文证明，MASTER 的非平稳性检测机制在实际时间范围内无法有效触发，导致其表现类似于随机重启算法，且其遗憾界 (regret bound) 在合理地平线上高于最坏情况的线性遗憾。通过实验验证，在分段平稳多臂老虎机 (multi-armed bandits) 问题上，使用最快变化检测 (quickest change detection) 的方法比 MASTER 和其他随机重启方法更稳健和高效。该研究强调了无先验 NS-RL 的挑战，并建议采用更有效的检测机制来提升算法性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Corrected minor typos in the proof of Theorem 2 on pages 25 and 26",
      "pdf_url": "http://arxiv.org/pdf/2410.13772v2",
      "published_date": "2024-10-17 17:09:56 UTC",
      "updated_date": "2024-10-21 01:05:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:49:25.486599"
    },
    {
      "arxiv_id": "2410.13769v3",
      "title": "Transformer Guided Coevolution: Improved Team Selection in Multiagent Adversarial Team Games",
      "title_zh": "Transformer 引导的协同进化：多智能体对抗团队游戏中的改进团队选择",
      "authors": [
        "Pranav Rajbhandari",
        "Prithviraj Dasgupta",
        "Donald Sofge"
      ],
      "abstract": "We consider the problem of team selection within multiagent adversarial team\ngames. We propose BERTeam, a novel algorithm that uses a transformer-based deep\nneural network with Masked Language Model training to select the best team of\nplayers from a trained population. We integrate this with coevolutionary deep\nreinforcement learning, which trains a diverse set of individual players to\nchoose from. We test our algorithm in the multiagent adversarial game Marine\nCapture-The-Flag, and find that BERTeam learns non-trivial team compositions\nthat perform well against unseen opponents. For this game, we find that BERTeam\noutperforms MCAA, an algorithm that similarly optimizes team selection.",
      "tldr_zh": "本研究针对多智能体对抗团队游戏中的团队选择问题，提出了一种名为 BERTeam 的新算法，该算法利用基于 Transformer 的深度神经网络和 Masked Language Model 训练，从训练的玩家群体中选择最佳团队。BERTeam 与 coevolutionary deep reinforcement learning 相结合，训练出多样化的个体玩家，以优化团队组成。在 Marine Capture-The-Flag 游戏测试中，BERTeam 学习了非平凡的团队策略，对抗未见对手时表现出色，并优于类似算法 MCAA。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13769v3",
      "published_date": "2024-10-17 17:06:41 UTC",
      "updated_date": "2025-01-29 20:07:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:49:27.586975"
    },
    {
      "arxiv_id": "2410.13768v1",
      "title": "Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Alireza Ghafarollahi",
        "Markus J. Buehler"
      ],
      "abstract": "A multi-agent AI model is used to automate the discovery of new metallic\nalloys, integrating multimodal data and external knowledge including insights\nfrom physics via atomistic simulations. Our multi-agent system features three\nkey components: (a) a suite of LLMs responsible for tasks such as reasoning and\nplanning, (b) a group of AI agents with distinct roles and expertise that\ndynamically collaborate, and (c) a newly developed graph neural network (GNN)\nmodel for rapid retrieval of key physical properties. A set of LLM-driven AI\nagents collaborate to automate the exploration of the vast design space of\nMPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of\nbody-centered cubic (bcc) alloys, modeled using an ML-based interatomic\npotential, and target two key properties: the Peierls barrier and solute/screw\ndislocation interaction energy. Our GNN model accurately predicts these\natomic-scale properties, providing a faster alternative to costly brute-force\ncalculations and reducing the computational burden on multi-agent systems for\nphysics retrieval. This AI system revolutionizes materials discovery by\nreducing reliance on human expertise and overcoming the limitations of direct\nall-atom simulations. By synergizing the predictive power of GNNs with the\ndynamic collaboration of LLM-based agents, the system autonomously navigates\nvast alloy design spaces, identifying trends in atomic-scale material\nproperties and predicting macro-scale mechanical strength, as demonstrated by\nseveral computational experiments. This approach accelerates the discovery of\nadvanced alloys and holds promise for broader applications in other complex\nsystems, marking a significant step forward in automated materials design.",
      "tldr_zh": "本文提出了一种基于 Graph Neural Network (GNN) 驱动的 Large Language Models (LLMs) 多智能体系统，用于实现合金设计的快速自动化。系统包括 LLMs 负责推理和规划、AI 代理进行动态协作，以及一个新开发的 GNN 模型用于快速检索关键物理属性，如 Peierls 势垒和溶质/螺位错相互作用能量。聚焦于 NbMoTa 家族的体心立方合金，该系统通过整合多模态数据和原子模拟，显著提高了预测准确性，并将计算负担降低至传统方法的替代方案。实验结果显示，该方法加速了先进合金的发现，减少了对人类专家的依赖，并为其他复杂系统的材料设计提供了广阔应用潜力。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cond-mat.dis-nn",
        "cond-mat.mes-hall",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13768v1",
      "published_date": "2024-10-17 17:06:26 UTC",
      "updated_date": "2024-10-17 17:06:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:49:40.432842"
    },
    {
      "arxiv_id": "2410.14745v2",
      "title": "Semi-supervised Fine-tuning for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Junyu Luo",
        "Xiao Luo",
        "Xiusi Chen",
        "Zhiping Xiao",
        "Wei Ju",
        "Ming Zhang"
      ],
      "abstract": "Supervised fine-tuning (SFT) is crucial in adapting large language model\n(LLMs) to a specific domain or task. However, only a limited amount of labeled\ndata is available in practical applications, which poses a severe challenge for\nSFT in yielding satisfactory results. Therefore, a data-efficient framework\nthat can fully exploit labeled and unlabeled data for LLM fine-tuning is highly\nanticipated.Towards this end, we introduce a semi-supervised\nfine-tuning(SemiFT) task and a framework named SemiEvol for LLM alignment from\na propagate-and-select manner. For knowledge propagation, SemiEvol adopts a\nbi-level approach, propagating knowledge from labeled data to unlabeled data\nthrough both in-weight and in-context methods. For knowledge selection,\nSemiEvol incorporates a collaborative learning mechanism, selecting\nhigher-quality pseudo-response samples. We conducted experiments using\nGPT-4o-mini and Llama-3.1 on seven general or domain-specific datasets,\ndemonstrating significant improvements in model performance on target data.\nFurthermore, we compared SemiEvol with SFT and self-evolution methods,\nhighlighting its practicality in hybrid data scenarios.",
      "tldr_zh": "该论文探讨了在标注数据有限的情况下，如何通过半监督微调（Semi-supervised Fine-tuning, SemiFT）来提升大语言模型（Large Language Models, LLMs）的适应性。作者引入了名为 SemiEvol 的框架，采用双层知识传播方法（包括 in-weight 和 in-context 技术）从标注数据向未标注数据传播知识，并通过协作学习机制选择高质量的伪响应样本。实验在 GPT-4o-mini 和 Llama-3.1 模型上，使用七个通用或领域特定数据集进行测试，结果显示模型性能显著提升。相比传统监督微调（Supervised Fine-tuning, SFT）和自演化方法，SemiEvol 在混合数据场景中表现出更高的实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Github Repo: https://github.com/luo-junyu/SemiEvol",
      "pdf_url": "http://arxiv.org/pdf/2410.14745v2",
      "published_date": "2024-10-17 16:59:46 UTC",
      "updated_date": "2025-02-19 15:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:49:51.971080"
    },
    {
      "arxiv_id": "2410.13762v2",
      "title": "Virtual Sensing-Enabled Digital Twin Framework for Real-Time Monitoring of Nuclear Systems Leveraging Deep Neural Operators",
      "title_zh": "翻译失败",
      "authors": [
        "Raisa Bentay Hossain",
        "Farid Ahmed",
        "Kazuma Kobayashi",
        "Seid Koric",
        "Diab Abueidda",
        "Syed Bahauddin Alam"
      ],
      "abstract": "Effective real-time monitoring is a foundation of digital twin technology,\ncrucial for detecting material degradation and maintaining the structural\nintegrity of nuclear systems to ensure both safety and operational efficiency.\nTraditional physical sensor systems face limitations such as installation\nchallenges, high costs, and difficulty measuring critical parameters in\nhard-to-reach or harsh environments, often resulting in incomplete data\ncoverage. Machine learning-driven virtual sensors, integrated within a digital\ntwin framework, offer a transformative solution by enhancing physical sensor\ncapabilities to monitor critical degradation indicators like pressure,\nvelocity, and turbulence. However, conventional machine learning models\nstruggle with real-time monitoring due to the high-dimensional nature of\nreactor data and the need for frequent retraining. This paper introduces the\nuse of Deep Operator Networks (DeepONet) as a core component of a digital twin\nframework to predict key thermal-hydraulic parameters in the hot leg of an\nAP-1000 Pressurized Water Reactor (PWR). DeepONet serves as a dynamic and\nscalable virtual sensor by accurately mapping the interplay between operational\ninput parameters and spatially distributed system behaviors. In this study,\nDeepONet is trained with different operational conditions, which relaxes the\nrequirement of continuous retraining, making it suitable for online and\nreal-time prediction components for digital twin. Our results show that\nDeepONet achieves accurate predictions with low mean squared error and relative\nL2 error and can make predictions on unknown data 1400 times faster than\ntraditional CFD simulations. This speed and accuracy enable DeepONet to\nsynchronize with the physical system in real-time, functioning as a dynamic\nvirtual sensor that tracks degradation-contributing conditions.",
      "tldr_zh": "该研究提出了一种基于虚拟传感器的数字孪生框架，用于核系统的实时监控，旨在解决传统物理传感器在安装成本和环境挑战方面的局限性。框架的核心是Deep Operator Networks (DeepONet)，它作为动态虚拟传感器，精确映射操作输入参数与系统行为的时空分布，并通过不同条件训练减少了频繁重训的需求。实验结果显示，DeepONet在AP-1000压水反应堆的热液力参数预测中，实现了低均方误差和相对L2误差，比传统CFD模拟快1400倍，从而实现了实时同步和有效跟踪材料退化条件。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13762v2",
      "published_date": "2024-10-17 16:56:04 UTC",
      "updated_date": "2024-11-29 03:05:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:50:03.688771"
    },
    {
      "arxiv_id": "2410.13757v3",
      "title": "MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation",
      "title_zh": "翻译失败",
      "authors": [
        "Zichen Zhu",
        "Hao Tang",
        "Yansi Li",
        "Dingye Liu",
        "Hongshen Xu",
        "Kunyao Lan",
        "Danyang Zhang",
        "Yixuan Jiang",
        "Hao Zhou",
        "Chenrun Wang",
        "Situo Zhang",
        "Liangtai Sun",
        "Yixiao Wang",
        "Yuheng Sun",
        "Lu Chen",
        "Kai Yu"
      ],
      "abstract": "Existing Multimodal Large Language Model (MLLM)-based agents face significant\nchallenges in handling complex GUI (Graphical User Interface) interactions on\ndevices. These challenges arise from the dynamic and structured nature of GUI\nenvironments, which integrate text, images, and spatial relationships, as well\nas the variability in action spaces across different pages and tasks. To\naddress these limitations, we propose MobA, a novel MLLM-based mobile assistant\nsystem. MobA introduces an adaptive planning module that incorporates a\nreflection mechanism for error recovery and dynamically adjusts plans to align\nwith the real environment contexts and action module's execution capacity.\nAdditionally, a multifaceted memory module provides comprehensive memory\nsupport to enhance adaptability and efficiency. We also present MobBench, a\ndataset designed for complex mobile interactions. Experimental results on\nMobBench and AndroidArena demonstrate MobA's ability to handle dynamic GUI\nenvironments and perform complex mobile tasks.",
      "tldr_zh": "该研究针对现有 Multimodal Large Language Model (MLLM) 代理在处理复杂 GUI (Graphical User Interface) 交互时的挑战（如动态环境和动作空间变化），提出了一种新型系统 MobA，以提升移动任务自动化效率。MobA 引入适应性规划模块，结合反射机制进行错误恢复并动态调整计划，以适应真实环境和执行能力；同时，多方面记忆模块提供全面支持，提升代理的适应性和效率。该系统还开发了 MobBench 数据集用于复杂移动交互评估，实验在 MobBench 和 AndroidArena 上证明 MobA 能有效处理动态 GUI 环境并执行复杂任务。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.MA",
      "comment": "NAACL 2025 Demo Track [code] https://github.com/OpenDFM/MobA\n  [dataset] https://huggingface.co/datasets/OpenDFM/MobA-MobBench",
      "pdf_url": "http://arxiv.org/pdf/2410.13757v3",
      "published_date": "2024-10-17 16:53:50 UTC",
      "updated_date": "2025-05-13 06:25:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:50:15.468981"
    },
    {
      "arxiv_id": "2410.13756v1",
      "title": "CLIMB: Language-Guided Continual Learning for Task Planning with Iterative Model Building",
      "title_zh": "翻译失败",
      "authors": [
        "Walker Byrnes",
        "Miroslav Bogdanovic",
        "Avi Balakirsky",
        "Stephen Balakirsky",
        "Animesh Garg"
      ],
      "abstract": "Intelligent and reliable task planning is a core capability for generalized\nrobotics, requiring a descriptive domain representation that sufficiently\nmodels all object and state information for the scene. We present CLIMB, a\ncontinual learning framework for robot task planning that leverages foundation\nmodels and execution feedback to guide domain model construction. CLIMB can\nbuild a model from a natural language description, learn non-obvious predicates\nwhile solving tasks, and store that information for future problems. We\ndemonstrate the ability of CLIMB to improve performance in common planning\nenvironments compared to baseline methods. We also develop the BlocksWorld++\ndomain, a simulated environment with an easily usable real counterpart,\ntogether with a curriculum of tasks with progressing difficulty for evaluating\ncontinual learning. Additional details and demonstrations for this system can\nbe found at https://plan-with-climb.github.io/ .",
      "tldr_zh": "本论文提出了 CLIMB，一种语言引导的持续学习框架，用于机器人任务规划，通过迭代模型构建来利用 foundation models 和执行反馈，构建领域模型并学习非显性谓词。CLIMB 可以从自然语言描述开始，动态存储知识以应用于未来任务，从而提升规划效率和可靠性。实验结果表明，CLIMB 在常见规划环境中比基线方法表现更好，并开发了 BlocksWorld++ 模拟环境及其任务课程，用于评估持续学习效果。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "6 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13756v1",
      "published_date": "2024-10-17 16:53:43 UTC",
      "updated_date": "2024-10-17 16:53:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:50:28.025931"
    },
    {
      "arxiv_id": "2410.13754v2",
      "title": "MixEval-X: Any-to-Any Evaluations from Real-World Data Mixtures",
      "title_zh": "翻译失败",
      "authors": [
        "Jinjie Ni",
        "Yifan Song",
        "Deepanway Ghosal",
        "Bo Li",
        "David Junhao Zhang",
        "Xiang Yue",
        "Fuzhao Xue",
        "Zian Zheng",
        "Kaichen Zhang",
        "Mahir Shah",
        "Kabir Jain",
        "Yang You",
        "Michael Shieh"
      ],
      "abstract": "Perceiving and generating diverse modalities are crucial for AI models to\neffectively learn from and engage with real-world signals, necessitating\nreliable evaluations for their development. We identify two major issues in\ncurrent evaluations: (1) inconsistent standards, shaped by different\ncommunities with varying protocols and maturity levels; and (2) significant\nquery, grading, and generalization biases. To address these, we introduce\nMixEval-X, the first any-to-any, real-world benchmark designed to optimize and\nstandardize evaluations across diverse input and output modalities. We propose\nmulti-modal benchmark mixture and adaptation-rectification pipelines to\nreconstruct real-world task distributions, ensuring evaluations generalize\neffectively to real-world use cases. Extensive meta-evaluations show our\napproach effectively aligns benchmark samples with real-world task\ndistributions. Meanwhile, MixEval-X's model rankings correlate strongly with\nthat of crowd-sourced real-world evaluations (up to 0.98) while being much more\nefficient. We provide comprehensive leaderboards to rerank existing models and\norganizations and offer insights to enhance understanding of multi-modal\nevaluations and inform future research.",
      "tldr_zh": "该研究指出了当前AI模型评估存在的不一致标准和查询、评分、泛化偏差等问题，提出MixEval-X作为首个any-to-any基准测试，用于优化和标准化多模态输入与输出的评估。MixEval-X通过多模态基准混合和adaptation-rectification管道重建真实世界任务分布，确保评估结果更具泛化性。实验显示，该基准的模型排名与真实世界众包评估高度相关（高达0.98），且效率更高，并提供了全面排行榜以重新评估现有模型并指导未来多模态研究。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13754v2",
      "published_date": "2024-10-17 16:52:28 UTC",
      "updated_date": "2024-10-18 08:56:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:50:39.428124"
    },
    {
      "arxiv_id": "2410.13752v2",
      "title": "Privacy-Preserving Decentralized AI with Confidential Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Dayeol Lee",
        "Jorge António",
        "Hisham Khan"
      ],
      "abstract": "This paper addresses privacy protection in decentralized Artificial\nIntelligence (AI) using Confidential Computing (CC) within the Atoma Network, a\ndecentralized AI platform designed for the Web3 domain. Decentralized AI\ndistributes AI services among multiple entities without centralized oversight,\nfostering transparency and robustness. However, this structure introduces\nsignificant privacy challenges, as sensitive assets such as proprietary models\nand personal data may be exposed to untrusted participants. Cryptography-based\nprivacy protection techniques such as zero-knowledge machine learning (zkML)\nsuffers prohibitive computational overhead. To address the limitation, we\npropose leveraging Confidential Computing (CC). Confidential Computing\nleverages hardware-based Trusted Execution Environments (TEEs) to provide\nisolation for processing sensitive data, ensuring that both model parameters\nand user data remain secure, even in decentralized, potentially untrusted\nenvironments. While TEEs face a few limitations, we believe they can bridge the\nprivacy gap in decentralized AI. We explore how we can integrate TEEs into\nAtoma's decentralized framework.",
      "tldr_zh": "该论文探讨了在去中心化 AI 平台 Atoma Network 中，使用 Confidential Computing (CC) 来解决隐私保护挑战，去中心化 AI 虽然提升了透明度和鲁棒性，但易暴露敏感资产如专有模型和个人数据。传统方法如 zero-knowledge machine learning (zkML) 因计算开销过高而受限，因此论文提出利用硬件-based Trusted Execution Environments (TEEs) 来隔离处理敏感数据，确保模型参数和用户数据在潜在不受信任环境中保持安全。最终，论文分析了将 TEEs 集成到 Atoma 的框架中，认为这能有效桥接去中心化 AI 的隐私差距，尽管 TEEs 存在某些限制。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13752v2",
      "published_date": "2024-10-17 16:50:48 UTC",
      "updated_date": "2024-10-18 16:33:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:50:52.925380"
    },
    {
      "arxiv_id": "2410.13727v2",
      "title": "LLM-Human Pipeline for Cultural Context Grounding of Conversations",
      "title_zh": "LLM-人类管道：用于",
      "authors": [
        "Rajkumar Pujari",
        "Dan Goldwasser"
      ],
      "abstract": "Conversations often adhere to well-understood social norms that vary across\ncultures. For example, while \"addressing parents by name\" is commonplace in the\nWest, it is rare in most Asian cultures. Adherence or violation of such norms\noften dictates the tenor of conversations. Humans are able to navigate social\nsituations requiring cultural awareness quite adeptly. However, it is a hard\ntask for NLP models.\n  In this paper, we tackle this problem by introducing a \"Cultural Context\nSchema\" for conversations. It comprises (1) conversational information such as\nemotions, dialogue acts, etc., and (2) cultural information such as social\nnorms, violations, etc. We generate ~110k social norm and violation\ndescriptions for ~23k conversations from Chinese culture using LLMs. We refine\nthem using automated verification strategies which are evaluated against\nculturally aware human judgements. We organize these descriptions into\nmeaningful structures we call \"Norm Concepts\", using an interactive\nhuman-in-loop framework. We ground the norm concepts and the descriptions in\nconversations using symbolic annotation. Finally, we use the obtained dataset\nfor downstream tasks such as emotion, sentiment, and dialogue act detection. We\nshow that it significantly improves the empirical performance.",
      "tldr_zh": "本论文提出一种LLM-Human Pipeline，用于在对话中融入文化语境（Cultural Context Grounding），以处理不同文化（如西方和亚洲）中社会规范的差异问题。该方法引入了Cultural Context Schema，包括对话信息（如情绪和对话行为）和文化信息（如社会规范和违规），并使用LLMs生成约11万条针对中文文化的规范描述，通过自动化验证和人类循环框架组织成Norm Concepts，并通过符号注解与对话关联。实验结果显示，该数据集显著提升了下游任务的性能，例如情绪、情感和对话行为检测的准确率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Oral at NAACL 2025 Main conference. Albuquerque, USA. Apr 29 - May 4,\n  2025. 19 pages, 9 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.13727v2",
      "published_date": "2024-10-17 16:33:01 UTC",
      "updated_date": "2025-04-01 16:24:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:51:03.250887"
    },
    {
      "arxiv_id": "2410.13726v3",
      "title": "DAWN: Dynamic Frame Avatar with Non-autoregressive Diffusion Framework for Talking Head Video Generation",
      "title_zh": "DAWN：",
      "authors": [
        "Hanbo Cheng",
        "Limin Lin",
        "Chenyu Liu",
        "Pengcheng Xia",
        "Pengfei Hu",
        "Jiefeng Ma",
        "Jun Du",
        "Jia Pan"
      ],
      "abstract": "Talking head generation intends to produce vivid and realistic talking head\nvideos from a single portrait and speech audio clip. Although significant\nprogress has been made in diffusion-based talking head generation, almost all\nmethods rely on autoregressive strategies, which suffer from limited context\nutilization beyond the current generation step, error accumulation, and slower\ngeneration speed. To address these challenges, we present DAWN (Dynamic frame\nAvatar With Non-autoregressive diffusion), a framework that enables all-at-once\ngeneration of dynamic-length video sequences. Specifically, it consists of two\nmain components: (1) audio-driven holistic facial dynamics generation in the\nlatent motion space, and (2) audio-driven head pose and blink generation.\nExtensive experiments demonstrate that our method generates authentic and vivid\nvideos with precise lip motions, and natural pose/blink movements.\nAdditionally, with a high generation speed, DAWN possesses strong extrapolation\ncapabilities, ensuring the stable production of high-quality long videos. These\nresults highlight the considerable promise and potential impact of DAWN in the\nfield of talking head video generation. Furthermore, we hope that DAWN sparks\nfurther exploration of non-autoregressive approaches in diffusion models. Our\ncode will be publicly available at https://github.com/Hanbo-Cheng/DAWN-pytorch.",
      "tldr_zh": "该论文提出DAWN框架，一种基于非自回归扩散模型的动态帧头像生成方法，用于从单张肖像和语音音频生成逼真的说话头像视频，以解决现有自回归策略的上下文利用有限、错误积累和速度慢等问题。DAWN的核心组件包括：在潜在运动空间中进行音频驱动的整体面部动态生成，以及音频驱动的头部姿势和眨眼生成。实验结果显示，该框架能产生精确唇部动作和自然运动的高质量视频，生成速度更快，并支持稳定生成长视频，具有显著的潜力，并有望推动非自回归方法在扩散模型中的进一步探索。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13726v3",
      "published_date": "2024-10-17 16:32:36 UTC",
      "updated_date": "2025-03-26 06:38:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:51:15.467881"
    },
    {
      "arxiv_id": "2410.13722v1",
      "title": "Persistent Pre-Training Poisoning of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Zhang",
        "Javier Rando",
        "Ivan Evtimov",
        "Jianfeng Chi",
        "Eric Michael Smith",
        "Nicholas Carlini",
        "Florian Tramèr",
        "Daphne Ippolito"
      ],
      "abstract": "Large language models are pre-trained on uncurated text datasets consisting\nof trillions of tokens scraped from the Web. Prior work has shown that: (1)\nweb-scraped pre-training datasets can be practically poisoned by malicious\nactors; and (2) adversaries can compromise language models after poisoning\nfine-tuning datasets. Our work evaluates for the first time whether language\nmodels can also be compromised during pre-training, with a focus on the\npersistence of pre-training attacks after models are fine-tuned as helpful and\nharmless chatbots (i.e., after SFT and DPO). We pre-train a series of LLMs from\nscratch to measure the impact of a potential poisoning adversary under four\ndifferent attack objectives (denial-of-service, belief manipulation,\njailbreaking, and prompt stealing), and across a wide range of model sizes\n(from 600M to 7B). Our main result is that poisoning only 0.1% of a model's\npre-training dataset is sufficient for three out of four attacks to measurably\npersist through post-training. Moreover, simple attacks like denial-of-service\npersist through post-training with a poisoning rate of only 0.001%.",
      "tldr_zh": "该研究首次评估了在大型语言模型（LLMs）的预训练阶段注入毒化数据是否会持续影响后续微调过程，特别是经过监督微调（SFT）和直接偏好优化（DPO）后的聊天机器人模型。研究者从零开始预训练了一系列模型（从600M到7B参数），测试四种攻击目标，包括denial-of-service、belief manipulation、jailbreaking和prompt stealing。结果显示，仅毒化0.1%的预训练数据集就足以让三种攻击在微调后持续存在，而简单的denial-of-service攻击只需0.001%的毒化率即可持久，突显了LLMs安全性的潜在风险。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13722v1",
      "published_date": "2024-10-17 16:27:13 UTC",
      "updated_date": "2024-10-17 16:27:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:51:27.537868"
    },
    {
      "arxiv_id": "2410.13720v2",
      "title": "Movie Gen: A Cast of Media Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Polyak",
        "Amit Zohar",
        "Andrew Brown",
        "Andros Tjandra",
        "Animesh Sinha",
        "Ann Lee",
        "Apoorv Vyas",
        "Bowen Shi",
        "Chih-Yao Ma",
        "Ching-Yao Chuang",
        "David Yan",
        "Dhruv Choudhary",
        "Dingkang Wang",
        "Geet Sethi",
        "Guan Pang",
        "Haoyu Ma",
        "Ishan Misra",
        "Ji Hou",
        "Jialiang Wang",
        "Kiran Jagadeesh",
        "Kunpeng Li",
        "Luxin Zhang",
        "Mannat Singh",
        "Mary Williamson",
        "Matt Le",
        "Matthew Yu",
        "Mitesh Kumar Singh",
        "Peizhao Zhang",
        "Peter Vajda",
        "Quentin Duval",
        "Rohit Girdhar",
        "Roshan Sumbaly",
        "Sai Saketh Rambhatla",
        "Sam Tsai",
        "Samaneh Azadi",
        "Samyak Datta",
        "Sanyuan Chen",
        "Sean Bell",
        "Sharadh Ramaswamy",
        "Shelly Sheynin",
        "Siddharth Bhattacharya",
        "Simran Motwani",
        "Tao Xu",
        "Tianhe Li",
        "Tingbo Hou",
        "Wei-Ning Hsu",
        "Xi Yin",
        "Xiaoliang Dai",
        "Yaniv Taigman",
        "Yaqiao Luo",
        "Yen-Cheng Liu",
        "Yi-Chiao Wu",
        "Yue Zhao",
        "Yuval Kirstain",
        "Zecheng He",
        "Zijian He",
        "Albert Pumarola",
        "Ali Thabet",
        "Artsiom Sanakoyeu",
        "Arun Mallya",
        "Baishan Guo",
        "Boris Araya",
        "Breena Kerr",
        "Carleigh Wood",
        "Ce Liu",
        "Cen Peng",
        "Dimitry Vengertsev",
        "Edgar Schonfeld",
        "Elliot Blanchard",
        "Felix Juefei-Xu",
        "Fraylie Nord",
        "Jeff Liang",
        "John Hoffman",
        "Jonas Kohler",
        "Kaolin Fire",
        "Karthik Sivakumar",
        "Lawrence Chen",
        "Licheng Yu",
        "Luya Gao",
        "Markos Georgopoulos",
        "Rashel Moritz",
        "Sara K. Sampson",
        "Shikai Li",
        "Simone Parmeggiani",
        "Steve Fine",
        "Tara Fowler",
        "Vladan Petrovic",
        "Yuming Du"
      ],
      "abstract": "We present Movie Gen, a cast of foundation models that generates\nhigh-quality, 1080p HD videos with different aspect ratios and synchronized\naudio. We also show additional capabilities such as precise instruction-based\nvideo editing and generation of personalized videos based on a user's image.\nOur models set a new state-of-the-art on multiple tasks: text-to-video\nsynthesis, video personalization, video editing, video-to-audio generation, and\ntext-to-audio generation. Our largest video generation model is a 30B parameter\ntransformer trained with a maximum context length of 73K video tokens,\ncorresponding to a generated video of 16 seconds at 16 frames-per-second. We\nshow multiple technical innovations and simplifications on the architecture,\nlatent spaces, training objectives and recipes, data curation, evaluation\nprotocols, parallelization techniques, and inference optimizations that allow\nus to reap the benefits of scaling pre-training data, model size, and training\ncompute for training large scale media generation models. We hope this paper\nhelps the research community to accelerate progress and innovation in media\ngeneration models. All videos from this paper are available at\nhttps://go.fb.me/MovieGenResearchVideos.",
      "tldr_zh": "本研究介绍了 Movie Gen，一组媒体 foundation models，能够生成高质量1080p HD视频、不同宽高比的视频以及同步音频，还支持基于指令的视频编辑和用户图像的个性化视频生成。模型采用30B参数的transformer架构，训练最大上下文长度达73K视频tokens（对应16秒的16fps视频），并通过架构优化、latent spaces改进、训练目标简化以及数据整理等创新技术提升了性能。实验结果显示，Movie Gen在text-to-video synthesis、video personalization、video editing、video-to-audio generation和text-to-audio generation等任务上设定了新状态，推动了媒体生成模型的研究进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13720v2",
      "published_date": "2024-10-17 16:22:46 UTC",
      "updated_date": "2025-02-26 16:05:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:51:39.755788"
    },
    {
      "arxiv_id": "2410.13716v2",
      "title": "MIRAGE-Bench: Automatic Multilingual Benchmark Arena for Retrieval-Augmented Generation Systems",
      "title_zh": "MIRAGE-Bench：用于检索增强生成系统的自动多语言基准竞技场",
      "authors": [
        "Nandan Thakur",
        "Suleman Kazi",
        "Ge Luo",
        "Jimmy Lin",
        "Amin Ahmad"
      ],
      "abstract": "Traditional retrieval-augmented generation (RAG) benchmarks evaluate systems\nusing heuristic-based metrics, but these require human preferences as the\nground truth for reference. In contrast, arena-based benchmarks, where systems\ncompete against each other, require an expensive large language model (LLM) as\na judge for a reliable evaluation. We present a simple efficient technique to\ncombine the best of both worlds. The idea is to train a surrogate judge using\nheuristic metrics as input, to output the LLM as a judge prediction. In our\nwork, we develop MIRAGE-Bench, a synthetic arena-based RAG benchmark for 18\ndiverse languages on Wikipedia focused on multilingual answer generation\nevaluation. It extensively couples both heuristic features and LLM as a judge\nfor evaluation. We benchmark 19 multilingual LLMs, and observe a high\ncorrelation (Kendall Tau ($\\tau$) = 0.909) using our surrogate judge and\nbetween GPT-4o as a teacher using the Bradley-Terry framework. Our results show\nproprietary and large open-source LLMs currently dominate on MIRAGE-Bench. Our\ncode and datasets are made publicly available here:\nhttps://github.com/vectara/mirage-bench.",
      "tldr_zh": "该论文提出了 MIRAGE-Bench，一种自动多语言基准平台，用于评估检索增强生成 (RAG) 系统，通过训练代理裁判 (surrogate judge) 来结合启发式指标和大型语言模型 (LLM) 判断，实现高效的系统竞争评估。该基准聚焦于 18 种语言的维基百科答案生成任务，并测试了 19 个多语言 LLM，显示代理裁判与 GPT-4o 的相关性高达 Kendall Tau τ = 0.909。结果表明，大型专有和开源 LLM 在 MIRAGE-Bench 上占据主导地位，代码和数据集已公开提供。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 (Main Conference)",
      "pdf_url": "http://arxiv.org/pdf/2410.13716v2",
      "published_date": "2024-10-17 16:18:49 UTC",
      "updated_date": "2025-03-29 01:11:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:51:52.619731"
    },
    {
      "arxiv_id": "2410.13708v2",
      "title": "On the Role of Attention Heads in Large Language Model Safety",
      "title_zh": "论注意力头在大语言模型安全性中的作用",
      "authors": [
        "Zhenhong Zhou",
        "Haiyang Yu",
        "Xinghua Zhang",
        "Rongwu Xu",
        "Fei Huang",
        "Kun Wang",
        "Yang Liu",
        "Junfeng Fang",
        "Yongbin Li"
      ],
      "abstract": "Large language models (LLMs) achieve state-of-the-art performance on multiple\nlanguage tasks, yet their safety guardrails can be circumvented, leading to\nharmful generations. In light of this, recent research on safety mechanisms has\nemerged, revealing that when safety representations or component are\nsuppressed, the safety capability of LLMs are compromised. However, existing\nresearch tends to overlook the safety impact of multi-head attention\nmechanisms, despite their crucial role in various model functionalities. Hence,\nin this paper, we aim to explore the connection between standard attention\nmechanisms and safety capability to fill this gap in the safety-related\nmechanistic interpretability. We propose a novel metric which tailored for\nmulti-head attention, the Safety Head ImPortant Score (Ships), to assess the\nindividual heads' contributions to model safety. Based on this, we generalize\nShips to the dataset level and further introduce the Safety Attention Head\nAttRibution Algorithm (Sahara) to attribute the critical safety attention heads\ninside the model. Our findings show that the special attention head has a\nsignificant impact on safety. Ablating a single safety head allows aligned\nmodel (e.g., Llama-2-7b-chat) to respond to 16 times more harmful queries,\nwhile only modifying 0.006% of the parameters, in contrast to the ~ 5%\nmodification required in previous studies. More importantly, we demonstrate\nthat attention heads primarily function as feature extractors for safety and\nmodels fine-tuned from the same base model exhibit overlapping safety heads\nthrough comprehensive experiments. Together, our attribution approach and\nfindings provide a novel perspective for unpacking the black box of safety\nmechanisms within large models.",
      "tldr_zh": "本研究探讨了大型语言模型（LLMs）中多头注意力机制对安全性的作用，填补了现有研究忽略这一关键组件的空白。论文提出了一种新指标Safety Head ImPortant Score (Ships)来评估单个注意力头的安全贡献，并引入Safety Attention Head AttRibution Algorithm (Sahara)来识别模型中的关键安全头。实验发现，移除一个安全头可使模型（如Llama-2-7b-chat）对有害查询的响应增加16倍，仅修改0.006%的参数，而之前方法需改动约5%；此外，注意力头主要作为安全特征提取器，从同一基模型微调的模型间存在重叠安全头。这些发现为解读LLMs的安全机制提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 18 figures, 7 tables. This paper has been accepted as ICLR\n  2025 (oral)",
      "pdf_url": "http://arxiv.org/pdf/2410.13708v2",
      "published_date": "2024-10-17 16:08:06 UTC",
      "updated_date": "2025-02-24 13:31:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:52:05.322925"
    },
    {
      "arxiv_id": "2410.13707v2",
      "title": "Disjointness Violations in Wikidata",
      "title_zh": "翻译失败",
      "authors": [
        "Ege Atacan Doğan",
        "Peter F. Patel-Schneider"
      ],
      "abstract": "Disjointness checks are among the most important constraint checks in a\nknowledge base and can be used to help detect and correct incorrect statements\nand internal contradictions. Wikidata is a very large, community-managed\nknowledge base. Because of both its size and construction, Wikidata contains\nmany incorrect statements and internal contradictions. We analyze the current\nmodeling of disjointness on Wikidata, identify patterns that cause these\ndisjointness violations and categorize them. We use SPARQL queries to identify\neach ``culprit'' causing a disjointness violation and lay out formulas to\nidentify and fix conflicting information. We finally discuss how disjointness\ninformation could be better modeled and expanded in Wikidata in the future.",
      "tldr_zh": "这篇论文探讨了Wikidata知识库中不相交性(disjointness)违反的问题，这些违反会导致错误语句和内部矛盾，并通过分析建模模式来识别和分类其原因。作者使用SPARQL查询定位每个导致违反的“culprit”（罪魁祸首），并提出公式来检测和修复冲突信息。最终，他们讨论了未来如何更好地建模和扩展Wikidata中的不相交性信息，以提升知识库的准确性和一致性。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "Sixth International Knowledge Graph and Semantic Web Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.13707v2",
      "published_date": "2024-10-17 16:07:51 UTC",
      "updated_date": "2024-10-23 19:12:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:52:15.575981"
    },
    {
      "arxiv_id": "2410.13691v2",
      "title": "Jailbreaking LLM-Controlled Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Robey",
        "Zachary Ravichandran",
        "Vijay Kumar",
        "Hamed Hassani",
        "George J. Pappas"
      ],
      "abstract": "The recent introduction of large language models (LLMs) has revolutionized\nthe field of robotics by enabling contextual reasoning and intuitive\nhuman-robot interaction in domains as varied as manipulation, locomotion, and\nself-driving vehicles. When viewed as a stand-alone technology, LLMs are known\nto be vulnerable to jailbreaking attacks, wherein malicious prompters elicit\nharmful text by bypassing LLM safety guardrails. To assess the risks of\ndeploying LLMs in robotics, in this paper, we introduce RoboPAIR, the first\nalgorithm designed to jailbreak LLM-controlled robots. Unlike existing, textual\nattacks on LLM chatbots, RoboPAIR elicits harmful physical actions from\nLLM-controlled robots, a phenomenon we experimentally demonstrate in three\nscenarios: (i) a white-box setting, wherein the attacker has full access to the\nNVIDIA Dolphins self-driving LLM, (ii) a gray-box setting, wherein the attacker\nhas partial access to a Clearpath Robotics Jackal UGV robot equipped with a\nGPT-4o planner, and (iii) a black-box setting, wherein the attacker has only\nquery access to the GPT-3.5-integrated Unitree Robotics Go2 robot dog. In each\nscenario and across three new datasets of harmful robotic actions, we\ndemonstrate that RoboPAIR, as well as several static baselines, finds\njailbreaks quickly and effectively, often achieving 100% attack success rates.\nOur results reveal, for the first time, that the risks of jailbroken LLMs\nextend far beyond text generation, given the distinct possibility that\njailbroken robots could cause physical damage in the real world. Indeed, our\nresults on the Unitree Go2 represent the first successful jailbreak of a\ndeployed commercial robotic system. Addressing this emerging vulnerability is\ncritical for ensuring the safe deployment of LLMs in robotics. Additional media\nis available at: https://robopair.org",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在机器人领域的应用风险，首次提出 RoboPAIR 算法，用于 jailbreaking LLM-controlled robots，以诱导机器人执行有害物理动作。RoboPAIR 在白盒、灰盒和黑盒场景中（如 NVIDIA Dolphins、Clearpath Robotics Jackal UGV 和 Unitree Robotics Go2）进行测试，并在三个新数据集上快速实现高达 100% 的攻击成功率。结果揭示，jailbreaking 的风险超出文本生成，可能导致真实世界的物理损害，因此强调了确保 LLMs 在机器人中的安全部署的紧迫性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13691v2",
      "published_date": "2024-10-17 15:55:36 UTC",
      "updated_date": "2024-11-09 20:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:52:31.098703"
    },
    {
      "arxiv_id": "2410.13674v2",
      "title": "Diffusion Curriculum: Synthetic-to-Real Generative Curriculum Learning via Image-Guided Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yijun Liang",
        "Shweta Bhardwaj",
        "Tianyi Zhou"
      ],
      "abstract": "Low-quality or scarce data has posed significant challenges for training deep\nneural networks in practice. While classical data augmentation cannot\ncontribute very different new data, diffusion models opens up a new door to\nbuild self-evolving AI by generating high-quality and diverse synthetic data\nthrough text-guided prompts. However, text-only guidance cannot control\nsynthetic images' proximity to the original images, resulting in\nout-of-distribution data detrimental to the model performance. To overcome the\nlimitation, we study image guidance to achieve a spectrum of interpolations\nbetween synthetic and real images. With stronger image guidance, the generated\nimages are similar to the training data but hard to learn. While with weaker\nimage guidance, the synthetic images will be easier for model but contribute to\na larger distribution gap with the original data. The generated full spectrum\nof data enables us to build a novel \"Diffusion Curriculum (DisCL)\". DisCL\nadjusts the image guidance level of image synthesis for each training stage: It\nidentifies and focuses on hard samples for the model and assesses the most\neffective guidance level of synthetic images to improve hard data learning. We\napply DisCL to two challenging tasks: long-tail (LT) classification and\nlearning from low-quality data. It focuses on lower-guidance images of\nhigh-quality to learn prototypical features as a warm-up of learning\nhigher-guidance images that might be weak on diversity or quality. Extensive\nexperiments showcase a gain of 2.7% and 2.1% in OOD and ID macro-accuracy when\napplying DisCL to iWildCam dataset. On ImageNet-LT, DisCL improves the base\nmodel's tail-class accuracy from 4.4% to 23.64% and leads to a 4.02%\nimprovement in all-class accuracy.",
      "tldr_zh": "这篇论文提出了一种名为 Diffusion Curriculum (DisCL) 的方法，利用图像引导的扩散模型生成从合成到真实图像的插值谱系，以解决低质量或稀缺数据训练深度神经网络的挑战。DisCL 通过动态调整图像引导水平，根据训练阶段识别并专注于硬样本，确保合成图像在多样性和分布相似度之间取得平衡，从而提升模型的学习效率。在实验中，应用于长尾 (long-tail) 分类任务时，DisCL 在 iWildCam 数据集上提高了 2.7% 的 OOD macro-accuracy 和 2.1% 的 ID macro-accuracy；在 ImageNet-LT 数据集上，尾类准确率从 4.4% 提升至 23.64%，整体准确率改善 4.02%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, including references and appendix. Code is available at\n  http://github.com/tianyi-lab/DisCL",
      "pdf_url": "http://arxiv.org/pdf/2410.13674v2",
      "published_date": "2024-10-17 15:33:35 UTC",
      "updated_date": "2024-10-18 03:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:52:41.073758"
    },
    {
      "arxiv_id": "2410.13649v2",
      "title": "A new approach for fine-tuning sentence transformers for intent classification and out-of-scope detection tasks",
      "title_zh": "一种用于微调",
      "authors": [
        "Tianyi Zhang",
        "Atta Norouzian",
        "Aanchan Mohan",
        "Frederick Ducatelle"
      ],
      "abstract": "In virtual assistant (VA) systems it is important to reject or redirect user\nqueries that fall outside the scope of the system. One of the most accurate\napproaches for out-of-scope (OOS) rejection is to combine it with the task of\nintent classification on in-scope queries, and to use methods based on the\nsimilarity of embeddings produced by transformer-based sentence encoders.\nTypically, such encoders are fine-tuned for the intent-classification task,\nusing cross-entropy loss. Recent work has shown that while this produces\nsuitable embeddings for the intent-classification task, it also tends to\ndisperse in-scope embeddings over the full sentence embedding space. This\ncauses the in-scope embeddings to potentially overlap with OOS embeddings,\nthereby making OOS rejection difficult. This is compounded when OOS data is\nunknown. To mitigate this issue our work proposes to regularize the\ncross-entropy loss with an in-scope embedding reconstruction loss learned using\nan auto-encoder. Our method achieves a 1-4% improvement in the area under the\nprecision-recall curve for rejecting out-of-sample (OOS) instances, without\ncompromising intent classification performance.",
      "tldr_zh": "这篇论文提出了一种新方法，用于 fine-tuning sentence transformers，以提升虚拟助手系统的意图分类和 out-of-scope (OOS) 检测性能。传统方法依赖 cross-entropy loss 进行 fine-tuning，但会导致 in-scope 嵌入在整个空间分散，从而与 OOS 嵌入重叠，增加检测难度。为解决此问题，作者引入了 in-scope embedding reconstruction loss（基于 auto-encoder 学习）来 regularize 嵌入空间。实验结果显示，该方法在拒绝 OOS 实例时的 area under the precision-recall curve (AUC) 提高了 1-4%，同时保持了意图分类的性能不变。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Appearing at Empirical Methods in Natural Language Processing 2024 -\n  Industry Track",
      "pdf_url": "http://arxiv.org/pdf/2410.13649v2",
      "published_date": "2024-10-17 15:15:12 UTC",
      "updated_date": "2024-10-19 06:44:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:52:52.148868"
    },
    {
      "arxiv_id": "2410.13648v1",
      "title": "SimpleToM: Exposing the Gap between Explicit ToM Inference and Implicit ToM Application in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yuling Gu",
        "Oyvind Tafjord",
        "Hyunwoo Kim",
        "Jared Moore",
        "Ronan Le Bras",
        "Peter Clark",
        "Yejin Choi"
      ],
      "abstract": "While prior work has explored whether large language models (LLMs) possess a\n\"theory of mind\" (ToM) - the ability to attribute mental states to oneself and\nothers - there has been little work testing whether LLMs can implicitly apply\nsuch knowledge to predict behavior, or to judge whether an observed behavior is\nrational. Such skills are critical for appropriate interaction in social\nenvironments. We create a new dataset, SimpleTom, containing concise, diverse\nstories (e.g., \"The can of Pringles has moldy chips in it. Mary picks up the\ncan in the supermarket and walks to the cashier.\"), each with three questions\nthat test different degrees of ToM reasoning, asking models to predict (a)\nmental state (\"Is Mary aware of the mold?\"), (b) behavior (\"Will Mary pay for\nthe chips or report the mold?\"), and (c) judgment (\"Mary paid for the chips.\nWas that reasonable?\"). To our knowledge, SimpleToM is the first dataset to\nsystematically explore downstream reasoning requiring knowledge of mental\nstates in realistic scenarios. Our experimental results are intriguing: While\nmost models can reliably predict mental state on our dataset (a), they often\nfail to correctly predict the behavior (b), and fare even worse at judging\nwhether given behaviors are reasonable (c), despite being correctly aware of\nthe protagonist's mental state should make such secondary predictions obvious.\nWe further show that we can help models do better at (b) and (c) via\ninterventions such as reminding the model of its earlier mental state answer\nand mental-state-specific chain-of-thought prompting, raising the action\nprediction accuracies (e.g., from 49.5% to 93.5% for GPT-4o) and judgment\naccuracies (e.g., from 15.3% to 94.7% in GPT-4o). While this shows that models\ncan be coaxed to perform well, it requires task-specific interventions, and the\nnatural model performances remain low, a cautionary tale for LLM deployment.",
      "tldr_zh": "这篇论文揭示了大型语言模型 (LLMs) 在显式推断“theory of mind” (ToM) 与隐式应用 ToM 之间的差距，ToM 指归因心理状态的能力。研究者创建了 SimpleToM 数据集，包含简短故事和三个问题，分别测试模型预测心理状态、行为和判断行为合理性。实验发现，大多数 LLMs 能准确预测心理状态，但预测行为和判断合理性时表现较差，尽管它们知道相关心理状态。作者通过干预如提醒模型先前答案或 chain-of-thought prompting，大幅提升了模型的准确率（例如 GPT-4o 的行为预测从 49.5% 提高到 93.5%），但这强调了自然性能低下的潜在风险，对 LLM 部署提出了警告。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13648v1",
      "published_date": "2024-10-17 15:15:00 UTC",
      "updated_date": "2024-10-17 15:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:53:05.570661"
    },
    {
      "arxiv_id": "2410.13643v2",
      "title": "Fine-Tuning Discrete Diffusion Models via Reward Optimization with Applications to DNA and Protein Design",
      "title_zh": "通过奖励优化微",
      "authors": [
        "Chenyu Wang",
        "Masatoshi Uehara",
        "Yichun He",
        "Amy Wang",
        "Tommaso Biancalani",
        "Avantika Lal",
        "Tommi Jaakkola",
        "Sergey Levine",
        "Hanchen Wang",
        "Aviv Regev"
      ],
      "abstract": "Recent studies have demonstrated the strong empirical performance of\ndiffusion models on discrete sequences across domains from natural language to\nbiological sequence generation. For example, in the protein inverse folding\ntask, conditional diffusion models have achieved impressive results in\ngenerating natural-like sequences that fold back into the original structure.\nHowever, practical design tasks often require not only modeling a conditional\ndistribution but also optimizing specific task objectives. For instance, we may\nprefer protein sequences with high stability. To address this, we consider the\nscenario where we have pre-trained discrete diffusion models that can generate\nnatural-like sequences, as well as reward models that map sequences to task\nobjectives. We then formulate the reward maximization problem within discrete\ndiffusion models, analogous to reinforcement learning (RL), while minimizing\nthe KL divergence against pretrained diffusion models to preserve naturalness.\nTo solve this RL problem, we propose a novel algorithm, DRAKES, that enables\ndirect backpropagation of rewards through entire trajectories generated by\ndiffusion models, by making the originally non-differentiable trajectories\ndifferentiable using the Gumbel-Softmax trick. Our theoretical analysis\nindicates that our approach can generate sequences that are both natural-like\nand yield high rewards. While similar tasks have been recently explored in\ndiffusion models for continuous domains, our work addresses unique algorithmic\nand theoretical challenges specific to discrete diffusion models, which arise\nfrom their foundation in continuous-time Markov chains rather than Brownian\nmotion. Finally, we demonstrate the effectiveness of DRAKES in generating DNA\nand protein sequences that optimize enhancer activity and protein stability,\nrespectively, important tasks for gene therapies and protein-based\ntherapeutics.",
      "tldr_zh": "本研究提出了一种名为DRAKES的算法，用于通过奖励优化微调离散扩散模型（Discrete Diffusion Models），以优化特定任务目标，同时最小化KL散度以保持序列的自然性。算法利用Gumbel-Softmax技巧使扩散模型生成的轨迹可微，从而实现奖励的直接反向传播。理论分析表明，该方法能生成既自然-like又高奖励的序列，解决了离散扩散模型在连续时间Markov链基础上的独特挑战。实验验证显示，DRAKES在DNA和蛋白设计中表现出色，能优化增强子活性和服务蛋白稳定性，适用于基因疗法和蛋白质治疗。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13643v2",
      "published_date": "2024-10-17 15:10:13 UTC",
      "updated_date": "2025-03-17 16:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:53:19.505259"
    },
    {
      "arxiv_id": "2410.13640v2",
      "title": "Latent Space Chain-of-Embedding Enables Output-free LLM Self-Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Wang",
        "Pei Zhang",
        "Baosong Yang",
        "Derek F. Wong",
        "Rui Wang"
      ],
      "abstract": "LLM self-evaluation relies on the LLM's own ability to estimate response\ncorrectness, which can greatly improve its deployment reliability. In this\nresearch track, we propose the Chain-of-Embedding (CoE) in the latent space to\nenable LLMs to perform output-free self-evaluation. CoE consists of all\nprogressive hidden states produced during the inference time, which can be\ntreated as the latent thinking path of LLMs. We find that when LLMs respond\ncorrectly and incorrectly, their CoE features differ, these discrepancies\nassist us in estimating LLM response correctness. Experiments in four diverse\ndomains and seven LLMs fully demonstrate the effectiveness of our method.\nMeanwhile, its label-free design intent without any training and\nmillisecond-level computational cost ensures real-time feedback in large-scale\nscenarios. More importantly, we provide interesting insights into LLM response\ncorrectness from the perspective of hidden state changes inside LLMs.",
      "tldr_zh": "本研究提出 Chain-of-Embedding (CoE) 方法，利用 LLMs 推理过程中的渐进隐藏状态作为潜在思考路径，实现输出无关的自评估，从而帮助 LLMs 估计响应正确性，而无需依赖实际输出。研究发现，正确和不正确响应在 CoE 特征上存在显著差异，这些差异可用于准确评估模型性能。在四个不同领域和七个 LLMs 的实验中，该方法表现出色，且其无标签设计、不需训练以及毫秒级计算成本，确保了大规模场景下的实时反馈，并从隐藏状态变化角度提供了 LLMs 响应正确性的新洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13640v2",
      "published_date": "2024-10-17 15:09:24 UTC",
      "updated_date": "2025-03-13 16:16:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:53:28.344617"
    },
    {
      "arxiv_id": "2410.13638v1",
      "title": "Scaling Wearable Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Girish Narayanswamy",
        "Xin Liu",
        "Kumar Ayush",
        "Yuzhe Yang",
        "Xuhai Xu",
        "Shun Liao",
        "Jake Garrison",
        "Shyam Tailor",
        "Jake Sunshine",
        "Yun Liu",
        "Tim Althoff",
        "Shrikanth Narayanan",
        "Pushmeet Kohli",
        "Jiening Zhan",
        "Mark Malhotra",
        "Shwetak Patel",
        "Samy Abdel-Ghaffar",
        "Daniel McDuff"
      ],
      "abstract": "Wearable sensors have become ubiquitous thanks to a variety of health\ntracking features. The resulting continuous and longitudinal measurements from\neveryday life generate large volumes of data; however, making sense of these\nobservations for scientific and actionable insights is non-trivial. Inspired by\nthe empirical success of generative modeling, where large neural networks learn\npowerful representations from vast amounts of text, image, video, or audio\ndata, we investigate the scaling properties of sensor foundation models across\ncompute, data, and model size. Using a dataset of up to 40 million hours of\nin-situ heart rate, heart rate variability, electrodermal activity,\naccelerometer, skin temperature, and altimeter per-minute data from over\n165,000 people, we create LSM, a multimodal foundation model built on the\nlargest wearable-signals dataset with the most extensive range of sensor\nmodalities to date. Our results establish the scaling laws of LSM for tasks\nsuch as imputation, interpolation and extrapolation, both across time and\nsensor modalities. Moreover, we highlight how LSM enables sample-efficient\ndownstream learning for tasks like exercise and activity recognition.",
      "tldr_zh": "本研究探讨了可穿戴传感器基础模型的缩放特性，旨在从海量数据中提取科学洞见，使用生成模型处理心率、心率变异性(electrodermal activity)、加速度计(accelerometer)、皮肤温度和高度计(altimeter)等数据。研究者构建了LSM模型，基于超过4000万小时的多模态数据来自16.5万多人，建立了scaling laws在插值(imputation)、插补(interpolation)和外推(extrapolation)任务上的性能。结果显示，LSM显著提升了下游任务如运动和活动识别的样本效率，为可穿戴技术应用提供了高效框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13638v1",
      "published_date": "2024-10-17 15:08:21 UTC",
      "updated_date": "2024-10-17 15:08:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:53:39.958266"
    },
    {
      "arxiv_id": "2410.13637v2",
      "title": "Normalizing self-supervised learning for provably reliable Change Point Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandra Bazarova",
        "Evgenia Romanenkova",
        "Alexey Zaytsev"
      ],
      "abstract": "Change point detection (CPD) methods aim to identify abrupt shifts in the\ndistribution of input data streams. Accurate estimators for this task are\ncrucial across various real-world scenarios. Yet, traditional unsupervised CPD\ntechniques face significant limitations, often relying on strong assumptions or\nsuffering from low expressive power due to inherent model simplicity. In\ncontrast, representation learning methods overcome these drawbacks by offering\nflexibility and the ability to capture the full complexity of the data without\nimposing restrictive assumptions. However, these approaches are still emerging\nin the CPD field and lack robust theoretical foundations to ensure their\nreliability. Our work addresses this gap by integrating the expressive power of\nrepresentation learning with the groundedness of traditional CPD techniques. We\nadopt spectral normalization (SN) for deep representation learning in CPD tasks\nand prove that the embeddings after SN are highly informative for CPD. Our\nmethod significantly outperforms current state-of-the-art methods during the\ncomprehensive evaluation via three standard CPD datasets.",
      "tldr_zh": "本文提出了一种基于self-supervised learning的变更点检测(CPD)方法，通过整合表示学习和传统CPD技术来解决现有方法的局限性，如强假设依赖和表达能力不足。核心创新是采用spectral normalization (SN)来规范化深度表示学习，并证明SN后的嵌入对CPD具有高度信息性，确保方法的可靠性。该方法在三个标准CPD数据集上的综合评估中，显著优于当前最先进技术，提供了一个理论上可靠的CPD解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13637v2",
      "published_date": "2024-10-17 15:07:56 UTC",
      "updated_date": "2024-12-03 08:29:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:53:51.586820"
    },
    {
      "arxiv_id": "2410.14744v1",
      "title": "Eliciting Uncertainty in Chain-of-Thought to Mitigate Bias against Forecasting Harmful User Behaviors",
      "title_zh": "翻译失败",
      "authors": [
        "Anthony Sicilia",
        "Malihe Alikhani"
      ],
      "abstract": "Conversation forecasting tasks a model with predicting the outcome of an\nunfolding conversation. For instance, it can be applied in social media\nmoderation to predict harmful user behaviors before they occur, allowing for\npreventative interventions. While large language models (LLMs) have recently\nbeen proposed as an effective tool for conversation forecasting, it's unclear\nwhat biases they may have, especially against forecasting the (potentially\nharmful) outcomes we request them to predict during moderation. This paper\nexplores to what extent model uncertainty can be used as a tool to mitigate\npotential biases. Specifically, we ask three primary research questions: 1) how\ndoes LLM forecasting accuracy change when we ask models to represent their\nuncertainty; 2) how does LLM bias change when we ask models to represent their\nuncertainty; 3) how can we use uncertainty representations to reduce or\ncompletely mitigate biases without many training data points. We address these\nquestions for 5 open-source language models tested on 2 datasets designed to\nevaluate conversation forecasting for social media moderation.",
      "tldr_zh": "该论文探讨了使用大型语言模型（LLMs）进行对话预测（如预测有害用户行为）时存在的偏见问题，旨在通过激发 Chain-of-Thought 中的不确定性来缓解这些偏见。研究者提出了三个关键问题：不确定性表示如何影响LLMs的预测准确率、如何改变模型偏见，以及如何利用不确定性表示减少偏见而无需大量训练数据。实验在5个开源LLMs和2个社交媒体审核数据集上进行，结果表明，这种方法有助于提升模型的可信度和公平性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14744v1",
      "published_date": "2024-10-17 15:07:53 UTC",
      "updated_date": "2024-10-17 15:07:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:54:03.824379"
    },
    {
      "arxiv_id": "2410.13616v1",
      "title": "Spatiotemporal Object Detection for Improved Aerial Vehicle Detection in Traffic Monitoring",
      "title_zh": "用于交通监控中改进航空车辆检测的时空物体检测",
      "authors": [
        "Kristina Telegraph",
        "Christos Kyrkou"
      ],
      "abstract": "This work presents advancements in multi-class vehicle detection using UAV\ncameras through the development of spatiotemporal object detection models. The\nstudy introduces a Spatio-Temporal Vehicle Detection Dataset (STVD) containing\n6, 600 annotated sequential frame images captured by UAVs, enabling\ncomprehensive training and evaluation of algorithms for holistic spatiotemporal\nperception. A YOLO-based object detection algorithm is enhanced to incorporate\ntemporal dynamics, resulting in improved performance over single frame models.\nThe integration of attention mechanisms into spatiotemporal models is shown to\nfurther enhance performance. Experimental validation demonstrates significant\nprogress, with the best spatiotemporal model exhibiting a 16.22% improvement\nover single frame models, while it is demonstrated that attention mechanisms\nhold the potential for additional performance gains.",
      "tldr_zh": "本研究针对交通监控中的空中车辆检测，利用无人机(UAV)摄像头开发了时空物体检测模型，以提升多类车辆识别性能。研究引入了Spatio-Temporal Vehicle Detection Dataset (STVD)，包含6,600个标注的顺序帧图像，用于全面训练和评估算法。基于YOLO算法的模型被增强以融入时间动态和注意力机制，实验显示最佳时空模型比单帧模型提高了16.22%的性能，并证明注意力机制可带来额外性能提升。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.13616v1",
      "published_date": "2024-10-17 14:49:37 UTC",
      "updated_date": "2024-10-17 14:49:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:54:45.588673"
    },
    {
      "arxiv_id": "2410.13611v1",
      "title": "H2OVL-Mississippi Vision Language Models Technical Report",
      "title_zh": "H2OVL-Mississippi 视觉语言模型技术报告",
      "authors": [
        "Shaikat Galib",
        "Shanshan Wang",
        "Guanshuo Xu",
        "Pascal Pfeiffer",
        "Ryan Chesler",
        "Mark Landry",
        "Sri Satish Ambati"
      ],
      "abstract": "Smaller vision-language models (VLMs) are becoming increasingly important for\nprivacy-focused, on-device applications due to their ability to run efficiently\non consumer hardware for processing enterprise commercial documents and images.\nThese models require strong language understanding and visual capabilities to\nenhance human-machine interaction. To address this need, we present\nH2OVL-Mississippi, a pair of small VLMs trained on 37 million image-text pairs\nusing 240 hours of compute on 8 x H100 GPUs. H2OVL-Mississippi-0.8B is a tiny\nmodel with 0.8 billion parameters that specializes in text recognition,\nachieving state of the art performance on the Text Recognition portion of\nOCRBench and surpassing much larger models in this area. Additionally, we are\nreleasing H2OVL-Mississippi-2B, a 2 billion parameter model for general use\ncases, exhibiting highly competitive metrics across various academic\nbenchmarks. Both models build upon our prior work with H2O-Danube language\nmodels, extending their capabilities into the visual domain. We release them\nunder the Apache 2.0 license, making VLMs accessible to everyone, democratizing\ndocument AI and visual LLMs.",
      "tldr_zh": "本研究介绍了 H2OVL-Mississippi，这是一对小型视觉语言模型 (VLMs)，旨在提升隐私导向的设备端应用，如处理企业文档和图像。模型使用 3700 万图像-文本对进行训练，耗时 240 小时在 8 x H100 GPUs 上完成，其中 H2OVL-Mississippi-0.8B（0.8 亿参数）在 OCRBench 的文本识别任务上达到 state-of-the-art 性能，并超越更大模型，而 H2OVL-Mississippi-2B（2 亿参数）在各种学术基准上表现出色，适用于一般场景。基于先前的 H2O-Danube 语言模型，该框架扩展了视觉能力，并以 Apache 2.0 许可证开源，促进了文档 AI 和视觉 LLMs 的民主化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13611v1",
      "published_date": "2024-10-17 14:46:34 UTC",
      "updated_date": "2024-10-17 14:46:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:54:29.073757"
    },
    {
      "arxiv_id": "2410.13610v2",
      "title": "MeNTi: Bridging Medical Calculator and LLM Agent with Nested Tool Calling",
      "title_zh": "翻译失败",
      "authors": [
        "Yakun Zhu",
        "Shaohang Wei",
        "Xu Wang",
        "Kui Xue",
        "Xiaofan Zhang",
        "Shaoting Zhang"
      ],
      "abstract": "Integrating tools into Large Language Models (LLMs) has facilitated the\nwidespread application. Despite this, in specialized downstream task contexts,\nreliance solely on tools is insufficient to fully address the complexities of\nthe real world. This particularly restricts the effective deployment of LLMs in\nfields such as medicine. In this paper, we focus on the downstream tasks of\nmedical calculators, which use standardized tests to assess an individual's\nhealth status. We introduce MeNTi, a universal agent architecture for LLMs.\nMeNTi integrates a specialized medical toolkit and employs meta-tool and nested\ncalling mechanisms to enhance LLM tool utilization. Specifically, it achieves\nflexible tool selection and nested tool calling to address practical issues\nfaced in intricate medical scenarios, including calculator selection, slot\nfilling, and unit conversion. To assess the capabilities of LLMs for\nquantitative assessment throughout the clinical process of calculator\nscenarios, we introduce CalcQA. This benchmark requires LLMs to use medical\ncalculators to perform calculations and assess patient health status. CalcQA is\nconstructed by professional physicians and includes 100 case-calculator pairs,\ncomplemented by a toolkit of 281 medical tools. The experimental results\ndemonstrate significant performance improvements with our framework. This\nresearch paves new directions for applying LLMs in demanding scenarios of\nmedicine.",
      "tldr_zh": "本论文提出 MeNTi，一种通用代理架构，将医疗计算器与 LLM 代理相结合，通过 meta-tool 和 nested calling 机制增强工具利用，解决医疗场景中的复杂问题，如计算器选择、槽位填充和单位转换。MeNTi 集成了专门的医疗工具包，旨在提升 LLM 在下游医疗任务中的性能。作者还引入 CalcQA 基准测试，由专业医师构建的 100 个病例-计算器对和 281 个医疗工具，评估 LLM 的量化评估能力。实验结果显示，该框架显著提高了性能，为 LLM 在医学领域的实际应用开辟新方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "NAACL 2025 main conference",
      "pdf_url": "http://arxiv.org/pdf/2410.13610v2",
      "published_date": "2024-10-17 14:46:22 UTC",
      "updated_date": "2025-02-14 16:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:54:41.464956"
    },
    {
      "arxiv_id": "2410.13924v2",
      "title": "ARKit LabelMaker: A New Scale for Indoor 3D Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Guangda Ji",
        "Silvan Weder",
        "Francis Engelmann",
        "Marc Pollefeys",
        "Hermann Blum"
      ],
      "abstract": "Neural network performance scales with both model size and data volume, as\nshown in both language and image processing. This requires scaling-friendly\narchitectures and large datasets. While transformers have been adapted for 3D\nvision, a `GPT-moment' remains elusive due to limited training data. We\nintroduce ARKit LabelMaker, a large-scale real-world 3D dataset with dense\nsemantic annotation that is more than three times larger than prior largest\ndataset. Specifically, we extend ARKitScenes with automatically generated dense\n3D labels using an extended LabelMaker pipeline, tailored for large-scale\npre-training. Training on our dataset improves accuracy across architectures,\nachieving state-of-the-art 3D semantic segmentation scores on ScanNet and\nScanNet200, with notable gains on tail classes. Our code is available at\nhttps://labelmaker.org and our dataset at\nhttps://huggingface.co/datasets/labelmaker/arkit_labelmaker.",
      "tldr_zh": "该研究强调神经网络性能依赖于模型大小和数据量，针对3D视觉领域的数据不足问题，引入了ARKit LabelMaker，这是一个比现有最大数据集大三倍以上的大规模真实世界3D数据集，包含密集语义注释。研究团队扩展了ARKitScenes，通过改进的LabelMaker管道自动生成密集3D标签，以支持大规模预训练。在该数据集上训练的模型显著提升了各种架构的准确性，在ScanNet和ScanNet200基准上实现了最先进的3D semantic segmentation表现，尤其在长尾类别上取得了显著改进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13924v2",
      "published_date": "2024-10-17 14:44:35 UTC",
      "updated_date": "2025-03-20 10:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:54:58.315276"
    },
    {
      "arxiv_id": "2410.14743v1",
      "title": "Efficient Deep Learning Board: Training Feedback Is Not All You Need",
      "title_zh": "翻译失败",
      "authors": [
        "Lina Gong",
        "Qi Gao",
        "Peng Li",
        "Mingqiang Wei",
        "Fei Wu"
      ],
      "abstract": "Current automatic deep learning (i.e., AutoDL) frameworks rely on training\nfeedback from actual runs, which often hinder their ability to provide quick\nand clear performance predictions for selecting suitable DL systems. To address\nthis issue, we propose EfficientDL, an innovative deep learning board designed\nfor automatic performance prediction and component recommendation. EfficientDL\ncan quickly and precisely recommend twenty-seven system components and predict\nthe performance of DL models without requiring any training feedback. The magic\nof no training feedback comes from our proposed comprehensive,\nmulti-dimensional, fine-grained system component dataset, which enables us to\ndevelop a static performance prediction model and comprehensive optimized\ncomponent recommendation algorithm (i.e., {\\alpha}\\b{eta}-BO search), removing\nthe dependency on actually running parameterized models during the traditional\noptimization search process. The simplicity and power of EfficientDL stem from\nits compatibility with most DL models. For example, EfficientDL operates\nseamlessly with mainstream models such as ResNet50, MobileNetV3,\nEfficientNet-B0, MaxViT-T, Swin-B, and DaViT-T, bringing competitive\nperformance improvements. Besides, experimental results on the CIFAR-10 dataset\nreveal that EfficientDL outperforms existing AutoML tools in both accuracy and\nefficiency (approximately 20 times faster along with 1.31% Top-1 accuracy\nimprovement than the cutting-edge methods). Source code, pretrained models, and\ndatasets are available at https://github.com/OpenSELab/EfficientDL.",
      "tldr_zh": "该论文指出，现有的自动深度学习（AutoDL）框架依赖训练反馈，导致性能预测缓慢和低效。为解决这一问题，研究者提出 EfficientDL，一种创新的深度学习板，能够在无需训练反馈的情况下快速推荐二十七种系统组件并预测模型性能。EfficientDL 利用多维细粒度组件数据集开发静态性能预测模型和 αβ-BO 搜索算法，确保与主流模型如 ResNet50 和 MobileNetV3 等兼容。在 CIFAR-10 数据集上的实验显示，EfficientDL 比现有 AutoML 工具快约 20 倍，同时 Top-1 准确率提升 1.31%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14743v1",
      "published_date": "2024-10-17 14:43:34 UTC",
      "updated_date": "2024-10-17 14:43:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:55:09.873847"
    },
    {
      "arxiv_id": "2410.13604v1",
      "title": "Large Language Models as Narrative-Driven Recommenders",
      "title_zh": "大语言模型作为叙事驱动的推荐系统",
      "authors": [
        "Lukas Eberhard",
        "Thorsten Ruprechter",
        "Denis Helic"
      ],
      "abstract": "Narrative-driven recommenders aim to provide personalized suggestions for\nuser requests expressed in free-form text such as \"I want to watch a thriller\nwith a mind-bending story, like Shutter Island.\" Although large language models\n(LLMs) have been shown to excel in processing general natural language queries,\ntheir effectiveness for handling such recommendation requests remains\nrelatively unexplored. To close this gap, we compare the performance of 38\nopen- and closed-source LLMs of various sizes, such as LLama 3.2 and GPT-4o, in\na movie recommendation setting. For this, we utilize a gold-standard,\ncrowdworker-annotated dataset of posts from reddit's movie suggestion community\nand employ various prompting strategies, including zero-shot, identity, and\nfew-shot prompting. Our findings demonstrate the ability of LLMs to generate\ncontextually relevant movie recommendations, significantly outperforming other\nstate-of-the-art approaches, such as doc2vec. While we find that closed-source\nand large-parameterized models generally perform best, medium-sized open-source\nmodels remain competitive, being only slightly outperformed by their more\ncomputationally expensive counterparts. Furthermore, we observe no significant\ndifferences across prompting strategies for most models, underscoring the\neffectiveness of simple approaches such as zero-shot prompting for\nnarrative-driven recommendations. Overall, this work offers valuable insights\nfor recommender system researchers as well as practitioners aiming to integrate\nLLMs into real-world recommendation tools.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在叙事驱动推荐系统中的应用，例如处理用户自由文本请求如“我想看一部像《Shutter Island》那样的惊悚片”。研究者比较了 38 个开源和闭源 LLMs（如 LLaMA 3.2 和 GPT-4o）的性能，使用 Reddit 电影建议社区的标注数据集，并测试了 zero-shot、identity 和 few-shot prompting 等策略。结果显示，LLMs 能生成高度相关的推荐，显著优于传统方法如 doc2vec，且闭源大型模型表现最佳，而中等规模开源模型也具竞争力，且不同提示策略差异不大。总体上，此工作为推荐系统研究者和从业者提供了宝贵见解，推动 LLMs 在实际推荐工具中的整合。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "Under review; 19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.13604v1",
      "published_date": "2024-10-17 14:39:24 UTC",
      "updated_date": "2024-10-17 14:39:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:55:22.446799"
    },
    {
      "arxiv_id": "2410.13597v1",
      "title": "Text-Guided Multi-Property Molecular Optimization with a Diffusion Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yida Xiong",
        "Kun Li",
        "Weiwei Liu",
        "Jia Wu",
        "Bo Du",
        "Shirui Pan",
        "Wenbin Hu"
      ],
      "abstract": "Molecular optimization (MO) is a crucial stage in drug discovery in which\ntask-oriented generated molecules are optimized to meet practical industrial\nrequirements. Existing mainstream MO approaches primarily utilize external\nproperty predictors to guide iterative property optimization. However, learning\nall molecular samples in the vast chemical space is unrealistic for predictors.\nAs a result, errors and noise are inevitably introduced during property\nprediction due to the nature of approximation. This leads to discrepancy\naccumulation, generalization reduction and suboptimal molecular candidates. In\nthis paper, we propose a text-guided multi-property molecular optimization\nmethod utilizing transformer-based diffusion language model (TransDLM).\nTransDLM leverages standardized chemical nomenclature as semantic\nrepresentations of molecules and implicitly embeds property requirements into\ntextual descriptions, thereby preventing error propagation during diffusion\nprocess. Guided by physically and chemically detailed textual descriptions,\nTransDLM samples and optimizes encoded source molecules, retaining core\nscaffolds of source molecules and ensuring structural similarities. Moreover,\nTransDLM enables simultaneous sampling of multiple molecules, making it ideal\nfor scalable, efficient large-scale optimization through distributed\ncomputation on web platforms. Furthermore, our approach surpasses\nstate-of-the-art methods in optimizing molecular structural similarity and\nenhancing chemical properties on the benchmark dataset. The code is available\nat: https://anonymous.4open.science/r/TransDLM-A901.",
      "tldr_zh": "本研究针对分子优化（MO）中的问题，提出了一种基于Transformer的扩散语言模型（TransDLM）的文本引导多属性分子优化方法，以避免现有方法依赖外部属性预测器而引入的错误和噪声。TransDLM利用标准化化学命名作为分子的语义表示，将属性要求嵌入文本描述中，并在扩散过程中保留源分子的核心支架，确保结构相似性，同时支持多分子并行采样以实现高效大规模优化。实验结果显示，该方法在基准数据集上超越了最先进的方法，提升了分子结构相似性和化学属性表现，为药物发现提供了更可靠的优化框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13597v1",
      "published_date": "2024-10-17 14:30:27 UTC",
      "updated_date": "2024-10-17 14:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:55:33.490944"
    },
    {
      "arxiv_id": "2410.13592v1",
      "title": "OAH-Net: A Deep Neural Network for Hologram Reconstruction of Off-axis Digital Holographic Microscope",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Liu",
        "Kerem Delikoyun",
        "Qianyu Chen",
        "Alperen Yildiz",
        "Si Ko Myo",
        "Win Sen Kuan",
        "John Tshon Yit Soong",
        "Matthew Edward Cove",
        "Oliver Hayden",
        "Hweekuan Lee"
      ],
      "abstract": "Off-axis digital holographic microscopy is a high-throughput, label-free\nimaging technology that provides three-dimensional, high-resolution information\nabout samples, particularly useful in large-scale cellular imaging. However,\nthe hologram reconstruction process poses a significant bottleneck for timely\ndata analysis. To address this challenge, we propose a novel reconstruction\napproach that integrates deep learning with the physical principles of off-axis\nholography. We initialized part of the network weights based on the physical\nprinciple and then fine-tuned them via weakly supersized learning. Our off-axis\nhologram network (OAH-Net) retrieves phase and amplitude images with errors\nthat fall within the measurement error range attributable to hardware, and its\nreconstruction speed significantly surpasses the microscope's acquisition rate.\nCrucially, OAH-Net demonstrates remarkable external generalization capabilities\non unseen samples with distinct patterns and can be seamlessly integrated with\nother models for downstream tasks to achieve end-to-end real-time hologram\nanalysis. This capability further expands off-axis holography's applications in\nboth biological and medical studies.",
      "tldr_zh": "本文提出 OAH-Net，一种深度神经网络，用于 off-axis digital holographic microscope 的全息图重建，以解决重建过程作为数据分析瓶颈的问题。该网络通过基于物理原理初始化部分权重并结合弱监督学习微调，实现高精度相位和幅度图像检索，其错误范围在硬件测量误差内，且重建速度显著超过显微镜的采集率。OAH-Net 展示出优秀的外部泛化能力，能够处理未见样本并与其他模型无缝整合，实现端到端的实时分析，从而扩展 off-axis holography 在生物和医学研究中的应用。",
      "categories": [
        "physics.optics",
        "cs.AI"
      ],
      "primary_category": "physics.optics",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13592v1",
      "published_date": "2024-10-17 14:25:18 UTC",
      "updated_date": "2024-10-17 14:25:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:55:46.569701"
    },
    {
      "arxiv_id": "2410.13570v1",
      "title": "RGB to Hyperspectral: Spectral Reconstruction for Enhanced Surgical Imaging",
      "title_zh": "从 RGB 到超光谱：用于增强手术成像的光谱重建",
      "authors": [
        "Tobias Czempiel",
        "Alfie Roddan",
        "Maria Leiloglou",
        "Zepeng Hu",
        "Kevin O'Neill",
        "Giulio Anichini",
        "Danail Stoyanov",
        "Daniel Elson"
      ],
      "abstract": "This study investigates the reconstruction of hyperspectral signatures from\nRGB data to enhance surgical imaging, utilizing the publicly available\nHeiPorSPECTRAL dataset from porcine surgery and an in-house neurosurgery\ndataset. Various architectures based on convolutional neural networks (CNNs)\nand transformer models are evaluated using comprehensive metrics. Transformer\nmodels exhibit superior performance in terms of RMSE, SAM, PSNR and SSIM by\neffectively integrating spatial information to predict accurate spectral\nprofiles, encompassing both visible and extended spectral ranges. Qualitative\nassessments demonstrate the capability to predict spectral profiles critical\nfor informed surgical decision-making during procedures. Challenges associated\nwith capturing both the visible and extended hyperspectral ranges are\nhighlighted using the MAE, emphasizing the complexities involved. The findings\nopen up the new research direction of hyperspectral reconstruction for surgical\napplications and clinical use cases in real-time surgical environments.",
      "tldr_zh": "这篇论文研究从 RGB 数据重建超光谱签名，以提升手术成像质量，利用公开的 HeiPorSPECTRAL 数据集和内部神经外科数据集。研究评估了基于 CNN 和 Transformer 模型的各种架构，发现 Transformer 模型在 RMSE、SAM、PSNR 和 SSIM 等指标上表现出色，能有效整合空间信息并准确预测可见光和扩展谱范围。定性评估显示，该方法能预测对手术决策关键的谱线，尽管 MAE 指标突出了捕获完整谱范围的挑战。该研究为超光谱重建在实时手术环境中的应用开辟了新研究方向。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "10 pages, 4 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.13570v1",
      "published_date": "2024-10-17 14:05:41 UTC",
      "updated_date": "2024-10-17 14:05:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:55:58.292850"
    },
    {
      "arxiv_id": "2410.13567v3",
      "title": "CCUP: A Controllable Synthetic Data Generation Pipeline for Pretraining Cloth-Changing Person Re-Identification Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yujian Zhao",
        "Chengru Wu",
        "Yinong Xu",
        "Xuanzheng Du",
        "Ruiyu Li",
        "Guanglin Niu"
      ],
      "abstract": "Cloth-changing person re-identification (CC-ReID), also known as Long-Term\nPerson Re-Identification (LT-ReID) is a critical and challenging research topic\nin computer vision that has recently garnered significant attention. However,\ndue to the high cost of constructing CC-ReID data, the existing data-driven\nmodels are hard to train efficiently on limited data, causing overfitting\nissue. To address this challenge, we propose a low-cost and efficient pipeline\nfor generating controllable and high-quality synthetic data simulating the\nsurveillance of real scenarios specific to the CC-ReID task. Particularly, we\nconstruct a new self-annotated CC-ReID dataset named Cloth-Changing Unreal\nPerson (CCUP), containing 6,000 IDs, 1,179,976 images, 100 cameras, and 26.5\noutfits per individual. Based on this large-scale dataset, we introduce an\neffective and scalable pretrain-finetune framework for enhancing the\ngeneralization capabilities of the traditional CC-ReID models. The extensive\nexperiments demonstrate that two typical models namely TransReID and FIRe^2,\nwhen integrated into our framework, outperform other state-of-the-art models\nafter pretraining on CCUP and finetuning on the benchmarks such as PRCC,\nVC-Clothes and NKUP. The CCUP is available at:\nhttps://github.com/yjzhao1019/CCUP.",
      "tldr_zh": "该研究针对布料变化的人重新识别（CC-ReID）任务的训练数据成本高和过拟合问题，提出了一种低成本、高效的合成数据生成管道，用于生成可控高质量数据以模拟真实监控场景。论文构建了新的CC-ReID数据集Cloth-Changing Unreal Person (CCUP)，包含6000个ID、约118万张图像、100个摄像头和每个个体26.5套衣服，并引入了一个可扩展的预训练-微调框架来提升模型的泛化能力。实验结果显示，在CCUP上预训练后，TransReID和FIRe^2模型在PRCC、VC-Clothes和NKUP基准上优于现有最先进模型，证明了该框架的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICME 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13567v3",
      "published_date": "2024-10-17 14:04:02 UTC",
      "updated_date": "2025-03-30 14:17:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:56:10.266063"
    },
    {
      "arxiv_id": "2410.13553v1",
      "title": "Integrating Temporal Representations for Dynamic Memory Retrieval and Management in Large Language Models",
      "title_zh": "整合时间表示用于大型语言模型中的动态内存检索和管理",
      "authors": [
        "Yuki Hou",
        "Haruki Tamoto",
        "Homei Miyashita"
      ],
      "abstract": "Conventional dialogue agents often struggle with effective memory recall,\nleading to redundant retrieval and inadequate management of unique user\nassociations. To address this, we propose SynapticRAG, a novel approach\nintegrating synaptic dynamics into Retrieval-Augmented Generation (RAG).\nSynapticRAG integrates temporal representations into memory vectors, mimicking\nbiological synapses by differentiating events based on occurrence times and\ndynamically updating memory significance. This model employs temporal scoring\nfor memory connections and a synaptic-inspired propagation control mechanism.\nExperiments across English, Japanese, and Chinese datasets demonstrate\nSynapticRAG's superiority over existing methods, including traditional RAG,\nwith up to 14.66\\% improvement in memory retrieval accuracy. Our approach\nadvances context-aware dialogue AI systems by enhancing long-term context\nmaintenance and specific information extraction from conversations.",
      "tldr_zh": "该研究针对传统对话代理在记忆召回上的不足（如冗余检索和用户关联管理问题），提出了一种新型方法SynapticRAG，将突触动态整合到Retrieval-Augmented Generation (RAG)中。通过将时间表示融入记忆向量，模仿生物突触来区分事件发生时间并动态更新记忆重要性，该方法还采用了temporal scoring和synaptic-inspired propagation control机制来优化记忆连接。实验在英语、日语和中文数据集上显示，SynapticRAG比传统RAG方法提高了高达14.66%的记忆召回准确率，从而提升了上下文感知对话AI系统的长期上下文维护和特定信息提取能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13553v1",
      "published_date": "2024-10-17 13:51:03 UTC",
      "updated_date": "2024-10-17 13:51:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:56:21.870197"
    },
    {
      "arxiv_id": "2411.00785v1",
      "title": "IGOR: Image-GOal Representations are the Atomic Control Units for Foundation Models in Embodied AI",
      "title_zh": "IGOR: 图像-目标表示是",
      "authors": [
        "Xiaoyu Chen",
        "Junliang Guo",
        "Tianyu He",
        "Chuheng Zhang",
        "Pushi Zhang",
        "Derek Cathera Yang",
        "Li Zhao",
        "Jiang Bian"
      ],
      "abstract": "We introduce Image-GOal Representations (IGOR), aiming to learn a unified,\nsemantically consistent action space across human and various robots. Through\nthis unified latent action space, IGOR enables knowledge transfer among\nlarge-scale robot and human activity data. We achieve this by compressing\nvisual changes between an initial image and its goal state into latent actions.\nIGOR allows us to generate latent action labels for internet-scale video data.\nThis unified latent action space enables the training of foundation policy and\nworld models across a wide variety of tasks performed by both robots and\nhumans. We demonstrate that: (1) IGOR learns a semantically consistent action\nspace for both human and robots, characterizing various possible motions of\nobjects representing the physical interaction knowledge; (2) IGOR can \"migrate\"\nthe movements of the object in the one video to other videos, even across human\nand robots, by jointly using the latent action model and world model; (3) IGOR\ncan learn to align latent actions with natural language through the foundation\npolicy model, and integrate latent actions with a low-level policy model to\nachieve effective robot control. We believe IGOR opens new possibilities for\nhuman-to-robot knowledge transfer and control.",
      "tldr_zh": "这篇论文引入了 Image-GOal Representations (IGOR)，一种统一的潜在动作空间，旨在在 Embodied AI 中实现人类和各种机器人间的知识转移和语义一致控制。IGOR 通过压缩初始图像与目标状态之间的视觉变化，生成潜在动作标签，并利用这些标签训练基础策略和世界模型，以处理大规模机器人和人类活动数据。研究发现，IGOR 不仅能学习语义一致的动作空间来表征物体运动和物理交互，还能跨视频迁移动作、将潜在动作与自然语言对齐，并整合低级策略模型以实现有效机器人控制，最终为人类到机器人的知识转移提供新可能性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.00785v1",
      "published_date": "2024-10-17 13:41:16 UTC",
      "updated_date": "2024-10-17 13:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:56:34.873498"
    },
    {
      "arxiv_id": "2410.13523v2",
      "title": "Can Medical Vision-Language Pre-training Succeed with Purely Synthetic Data?",
      "title_zh": "医疗视觉语言预训练能否仅凭纯合成数据成功？",
      "authors": [
        "Che Liu",
        "Zhongwei Wan",
        "Haozhe Wang",
        "Yinda Chen",
        "Talha Qaiser",
        "Chen Jin",
        "Fariba Yousefi",
        "Nikolay Burlutskiy",
        "Rossella Arcucci"
      ],
      "abstract": "Medical Vision-Language Pre-training (MedVLP) has made significant progress\nin enabling zero-shot tasks for medical image understanding. However, training\nMedVLP models typically requires large-scale datasets with paired, high-quality\nimage-text data, which are scarce in the medical domain. Recent advancements in\nLarge Language Models (LLMs) and diffusion models have made it possible to\ngenerate large-scale synthetic image-text pairs. This raises the question: \"Can\nMedVLP succeed using purely synthetic data?\" To address this, we use\noff-the-shelf generative models to create synthetic radiology reports and\npaired Chest X-ray (CXR) images, and propose an automated pipeline to build a\ndiverse, high-quality synthetic dataset, enabling a rigorous study that\nisolates model and training settings, focusing entirely from the data\nperspective. Our results show that MedVLP models trained exclusively on\nsynthetic data outperform those trained on real data by 3.8% in averaged AUC on\nzero-shot classification. Moreover, using a combination of synthetic and real\ndata leads to a further improvement of 9.07%. Additionally, MedVLP models\ntrained on synthetic or mixed data consistently outperform those trained on\nreal data in zero-shot grounding, as well as in fine-tuned classification and\nsegmentation tasks. Our analysis suggests MedVLP trained on well-designed\nsynthetic data can outperform models trained on real datasets, which may be\nlimited by low-quality samples and long-tailed distributions.",
      "tldr_zh": "本研究探讨了是否能使用纯合成数据成功进行 Medical Vision-Language Pre-training (MedVLP)，以解决医疗领域真实图像-文本数据稀缺的问题。研究者利用 Large Language Models (LLMs) 和 diffusion models 生成多样、高质量的合成放射学报告及配对 Chest X-ray (CXR) 图像，并通过自动化管道构建数据集。结果显示，仅用合成数据训练的 MedVLP 模型在零-shot classification 任务中平均 AUC 比真实数据模型高 3.8%，而混合合成和真实数据则进一步提升 9.07%；此外，在零-shot grounding、微调分类和分割任务中，合成或混合数据模型均表现出色。总体分析表明，设计良好的合成数据能克服真实数据集的低质量和长尾分布问题，提供更有效的 MedVLP 训练方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2410.13523v2",
      "published_date": "2024-10-17 13:11:07 UTC",
      "updated_date": "2025-02-25 06:19:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:56:46.699307"
    },
    {
      "arxiv_id": "2410.13517v2",
      "title": "Bias in the Mirror: Are LLMs opinions robust to their own adversarial attacks ?",
      "title_zh": "翻译失败",
      "authors": [
        "Virgile Rennard",
        "Christos Xypolopoulos",
        "Michalis Vazirgiannis"
      ],
      "abstract": "Large language models (LLMs) inherit biases from their training data and\nalignment processes, influencing their responses in subtle ways. While many\nstudies have examined these biases, little work has explored their robustness\nduring interactions. In this paper, we introduce a novel approach where two\ninstances of an LLM engage in self-debate, arguing opposing viewpoints to\npersuade a neutral version of the model. Through this, we evaluate how firmly\nbiases hold and whether models are susceptible to reinforcing misinformation or\nshifting to harmful viewpoints. Our experiments span multiple LLMs of varying\nsizes, origins, and languages, providing deeper insights into bias persistence\nand flexibility across linguistic and cultural contexts.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 的偏见如何在互动中表现，并评估这些偏见对自身对抗性攻击的鲁棒性。研究引入了一种创新方法，让两个 LLM 实例进行自我辩论（self-debate），其中一个争论某一观点，另一个辩护对立观点，以试图说服一个中立模型版本，从而测试偏见是否牢固或容易转向错误信息和有害观点。实验涉及多种 LLM 的不同大小、来源和语言，提供对偏见持久性和跨语言文化灵活性的深入洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13517v2",
      "published_date": "2024-10-17 13:06:02 UTC",
      "updated_date": "2024-11-05 09:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:56:57.876847"
    },
    {
      "arxiv_id": "2410.13502v3",
      "title": "MathGAP: Out-of-Distribution Evaluation on Problems with Arbitrarily Complex Proofs",
      "title_zh": "翻译失败",
      "authors": [
        "Andreas Opedal",
        "Haruki Shirakami",
        "Bernhard Schölkopf",
        "Abulhair Saparov",
        "Mrinmaya Sachan"
      ],
      "abstract": "Large language models (LLMs) can solve arithmetic word problems with high\naccuracy, but little is known about how well they generalize to more complex\nproblems. This is difficult to study, as (i) much of the available evaluation\ndata has already been seen by the most capable models during training, and (ii)\nexisting benchmarks do not capture how problem proofs may be arbitrarily\ncomplex in various ways. In this paper, we present a data-generation framework\nfor evaluating LLMs on problems with arbitrarily complex arithmetic proofs,\ncalled MathGAP. MathGAP generates problem statements and chain-of-thought\nreasoning traces according to specifications about their arithmetic proof\nstructure, enabling systematic studies on easy-to-hard generalization with\nrespect to complexity of proof trees. Using MathGAP, we find that LLMs show a\nsignificant decrease in performance as proofs get deeper and wider. This effect\nis more pronounced in complex, nonlinear proof structures, which are\nchallenging even for the most capable models. The models are also sensitive to\nsimple changes in sentence ordering. However, they remain capable of solving\nsome complex problems, suggesting that reasoning generalization is noisy.",
      "tldr_zh": "这篇论文引入了 MathGAP 框架，用于评估大型语言模型 (LLMs) 在处理具有任意复杂证明的算术问题时的 out-of-distribution 泛化能力。MathGAP 通过生成问题语句和 chain-of-thought reasoning traces，根据证明树的深度和宽度等规格进行系统性研究，帮助探索模型从简单到复杂的推理泛化。结果显示，LLMs 在证明结构更深或更宽时性能显著下降，尤其在复杂非线性证明中表现更差，且模型对句子顺序高度敏感；尽管如此，它们仍能解决部分复杂问题，表明推理泛化存在噪声现象。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13502v3",
      "published_date": "2024-10-17 12:48:14 UTC",
      "updated_date": "2025-02-14 18:15:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:57:10.184578"
    },
    {
      "arxiv_id": "2410.13498v2",
      "title": "Enhancing Text Generation in Joint NLG/NLU Learning Through Curriculum Learning, Semi-Supervised Training, and Advanced Optimization Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Rahimanuddin Shaik",
        "Katikela Sreeharsha Kishore"
      ],
      "abstract": "Text generation is the automated process of producing written or spoken\nlanguage using computational methods. It involves generating coherent and\ncontextually relevant text based on predefined rules or learned patterns.\nHowever, challenges in text generation arise from maintaining coherence,\nensuring diversity and creativity, and avoiding biases or inappropriate\ncontent. This research paper developed a novel approach to improve text\ngeneration in the context of joint Natural Language Generation (NLG) and\nNatural Language Understanding (NLU) learning. The data is prepared by\ngathering and preprocessing annotated datasets, including cleaning,\ntokenization, stemming, and stop-word removal. Feature extraction techniques\nsuch as POS tagging, Bag of words, and Term Frequency-Inverse Document\nFrequency (TF-IDF) are applied. Transformer-based encoders and decoders,\ncapturing long range dependencies and improving source-target sequence\nmodelling. Pre-trained language models like Optimized BERT are incorporated,\nalong with a Hybrid Redfox Artificial Hummingbird Algorithm (HRAHA).\nReinforcement learning with policy gradient techniques, semi-supervised\ntraining, improved attention mechanisms, and differentiable approximations like\nstraight-through Gumbel SoftMax estimator are employed to fine-tune the models\nand handle complex linguistic tasks effectively. The proposed model is\nimplemented using Python.",
      "tldr_zh": "这篇论文提出了一种新方法，通过 Curriculum Learning、Semi-Supervised Training 和高级优化技术（如 Hybrid Redfox Artificial Hummingbird Algorithm）来提升联合 NLG/NLU 学习中的文本生成性能，旨在解决文本生成的连贯性、多样性和偏差问题。方法包括数据预处理（如清洗、tokenization 和 TF-IDF 特征提取）、Transformer-based 编码器解码器、Optimized BERT 模型，以及强化学习（policy gradient）和改进的注意力机制。实验结果显示，该方法有效处理复杂语言任务，并使用 Python 进行实现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Disparities in fundamental understandings about the article between\n  the authors",
      "pdf_url": "http://arxiv.org/pdf/2410.13498v2",
      "published_date": "2024-10-17 12:43:49 UTC",
      "updated_date": "2025-01-29 09:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:57:33.046053"
    },
    {
      "arxiv_id": "2410.13488v1",
      "title": "Seeing Through VisualBERT: A Causal Adventure on Memetic Landscapes",
      "title_zh": "翻译失败",
      "authors": [
        "Dibyanayan Bandyopadhyay",
        "Mohammed Hasanuzzaman",
        "Asif Ekbal"
      ],
      "abstract": "Detecting offensive memes is crucial, yet standard deep neural network\nsystems often remain opaque. Various input attribution-based methods attempt to\ninterpret their behavior, but they face challenges with implicitly offensive\nmemes and non-causal attributions. To address these issues, we propose a\nframework based on a Structural Causal Model (SCM). In this framework,\nVisualBERT is trained to predict the class of an input meme based on both meme\ninput and causal concepts, allowing for transparent interpretation. Our\nqualitative evaluation demonstrates the framework's effectiveness in\nunderstanding model behavior, particularly in determining whether the model was\nright due to the right reason, and in identifying reasons behind\nmisclassification. Additionally, quantitative analysis assesses the\nsignificance of proposed modelling choices, such as de-confounding, adversarial\nlearning, and dynamic routing, and compares them with input attribution\nmethods. Surprisingly, we find that input attribution methods do not guarantee\ncausality within our framework, raising questions about their reliability in\nsafety-critical applications. The project page is at:\nhttps://newcodevelop.github.io/causality_adventure/",
      "tldr_zh": "这篇论文提出一个基于 Structural Causal Model (SCM) 的框架，用于训练 VisualBERT 模型检测 offensive memes，提供透明的解释机制，以解决传统深度神经网络的非因果归因问题。该框架结合 meme 输入和因果概念来预测类别，通过定性评估展示了其在理解模型行为、验证正确决策理由和识别误分类原因方面的有效性。定量分析比较了 de-confounding、adversarial learning 和 dynamic routing 等建模选择，发现 input attribution 方法无法保证因果性，从而质疑其在安全关键应用中的可靠性。总的来说，该工作为可解释的模因检测技术奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.13488v1",
      "published_date": "2024-10-17 12:32:00 UTC",
      "updated_date": "2024-10-17 12:32:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:57:34.158606"
    },
    {
      "arxiv_id": "2411.02400v2",
      "title": "Decomposition Dilemmas: Does Claim Decomposition Boost or Burden Fact-Checking Performance?",
      "title_zh": "翻译失败",
      "authors": [
        "Qisheng Hu",
        "Quanyu Long",
        "Wenya Wang"
      ],
      "abstract": "Fact-checking pipelines increasingly adopt the Decompose-Then-Verify\nparadigm, where texts are broken down into smaller claims for individual\nverification and subsequently combined for a veracity decision. While\ndecomposition is widely-adopted in such pipelines, its effects on final\nfact-checking performance remain underexplored. Some studies have reported\nimprovements from decompostition, while others have observed performance\ndeclines, indicating its inconsistent impact. To date, no comprehensive\nanalysis has been conducted to understand this variability. To address this\ngap, we present an in-depth analysis that explicitly examines the impact of\ndecomposition on downstream verification performance. Through error case\ninspection and experiments, we introduce a categorization of decomposition\nerrors and reveal a trade-off between accuracy gains and the noise introduced\nthrough decomposition. Our analysis provides new insights into understanding\ncurrent system's instability and offers guidance for future studies toward\nimproving claim decomposition in fact-checking pipelines.",
      "tldr_zh": "这篇论文探讨了事实查证（fact-checking）管道中采用Decompose-Then-Verify范式时，声明分解（claim decomposition）是否会提升还是降低整体性能，因为现有研究显示其影响不一致。\n作者通过错误案例检查和实验，引入了分解错误的分类，并揭示了准确性收益与分解引入的噪声之间的权衡。\n这项分析为理解当前系统的不稳定性提供了新见解，并为未来研究提供了指导，以优化事实查证管道中的声明分解。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "NAACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2411.02400v2",
      "published_date": "2024-10-17 11:45:59 UTC",
      "updated_date": "2025-02-15 12:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:57:45.920158"
    },
    {
      "arxiv_id": "2410.13460v1",
      "title": "Breaking the Manual Annotation Bottleneck: Creating a Comprehensive Legal Case Criticality Dataset through Semi-Automated Labeling",
      "title_zh": "翻译失败",
      "authors": [
        "Ronja Stern",
        "Ken Kawamura",
        "Matthias Stürmer",
        "Ilias Chalkidis",
        "Joel Niklaus"
      ],
      "abstract": "Predicting case criticality helps legal professionals in the court system\nmanage large volumes of case law. This paper introduces the Criticality\nPrediction dataset, a new resource for evaluating the potential influence of\nSwiss Federal Supreme Court decisions on future jurisprudence. Unlike existing\napproaches that rely on resource-intensive manual annotations, we\nsemi-automatically derive labels leading to a much larger dataset than\notherwise possible. Our dataset features a two-tier labeling system: (1) the\nLD-Label, which identifies cases published as Leading Decisions (LD), and (2)\nthe Citation-Label, which ranks cases by their citation frequency and recency.\nThis allows for a more nuanced evaluation of case importance. We evaluate\nseveral multilingual models, including fine-tuned variants and large language\nmodels, and find that fine-tuned models consistently outperform zero-shot\nbaselines, demonstrating the need for task-specific adaptation. Our\ncontributions include the introduction of this task and the release of a\nmultilingual dataset to the research community.",
      "tldr_zh": "本论文解决了法律案例关键性预测中的手动标注瓶颈问题，通过半自动化方法创建了名为 Criticality Prediction 的数据集，用于评估瑞士联邦最高法院判决对未来判例的影响。该数据集采用两层标签系统：LD-Label 标识作为 Leading Decisions 的案件，以及 Citation-Label 根据引用频率和时效性对案件进行排名，从而实现更细化的案例重要性评估。在实验中，微调的多语言模型明显优于零-shot 基线，证明了任务特定适配的必要性；论文的主要贡献是引入这一预测任务并向研究社区发布这个多语言数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2; I.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13460v1",
      "published_date": "2024-10-17 11:43:16 UTC",
      "updated_date": "2024-10-17 11:43:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:57:57.759692"
    },
    {
      "arxiv_id": "2410.13456v1",
      "title": "Unlocking Legal Knowledge: A Multilingual Dataset for Judicial Summarization in Switzerland",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Rolshoven",
        "Vishvaksenan Rasiah",
        "Srinanda Brügger Bose",
        "Matthias Stürmer",
        "Joel Niklaus"
      ],
      "abstract": "Legal research is a time-consuming task that most lawyers face on a daily\nbasis. A large part of legal research entails looking up relevant caselaw and\nbringing it in relation to the case at hand. Lawyers heavily rely on summaries\n(also called headnotes) to find the right cases quickly. However, not all\ndecisions are annotated with headnotes and writing them is time-consuming.\nAutomated headnote creation has the potential to make hundreds of thousands of\ndecisions more accessible for legal research in Switzerland alone. To kickstart\nthis, we introduce the Swiss Leading Decision Summarization ( SLDS) dataset, a\nnovel cross-lingual resource featuring 18K court rulings from the Swiss Federal\nSupreme Court (SFSC), in German, French, and Italian, along with German\nheadnotes. We fine-tune and evaluate three mT5 variants, along with proprietary\nmodels. Our analysis highlights that while proprietary models perform well in\nzero-shot and one-shot settings, fine-tuned smaller models still provide a\nstrong competitive edge. We publicly release the dataset to facilitate further\nresearch in multilingual legal summarization and the development of assistive\ntechnologies for legal professionals",
      "tldr_zh": "本论文介绍了 Swiss Leading Decision Summarization (SLDS) 数据集，这是一个多语言资源，包含 18K 份瑞士联邦最高法院 (SFSC) 的裁决，使用德语、法语和意大利语，并附有德语 headnotes，以解决法律研究中 headnotes 缺失和编写耗时的问题。研究团队微调了三个 mT5 变体模型以及专有模型，用于自动化司法摘要生成。实验结果显示，专有模型在 zero-shot 和 one-shot 设置中表现出色，但微调后的较小模型具有更强的竞争优势。该数据集的公开将推动多语言法律摘要研究和法律专业辅助技术的开发。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "68T50",
        "I.2; I.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13456v1",
      "published_date": "2024-10-17 11:34:07 UTC",
      "updated_date": "2024-10-17 11:34:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:58:11.237906"
    },
    {
      "arxiv_id": "2410.13445v1",
      "title": "Parameter-efficient Adaptation of Multilingual Multimodal Models for Low-resource ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Gupta",
        "Amruta Parulekar",
        "Sameep Chattopadhyay",
        "Preethi Jyothi"
      ],
      "abstract": "Automatic speech recognition (ASR) for low-resource languages remains a\nchallenge due to the scarcity of labeled training data. Parameter-efficient\nfine-tuning and text-only adaptation are two popular methods that have been\nused to address such low-resource settings. In this work, we investigate how\nthese techniques can be effectively combined using a multilingual multimodal\nmodel like SeamlessM4T. Multimodal models are able to leverage unlabeled text\nvia text-only adaptation with further parameter-efficient ASR fine-tuning, thus\nboosting ASR performance. We also show cross-lingual transfer from a\nhigh-resource language, achieving up to a relative 17% WER reduction over a\nbaseline in a zero-shot setting without any labeled speech.",
      "tldr_zh": "本文研究了针对低资源语言的自动语音识别 (ASR) 的参数高效适应方法，探讨如何结合参数-efficient fine-tuning 和 text-only adaptation，利用多语言多模态模型如 SeamlessM4T 从无标签文本中提升性能。实验结果表明，这种结合方法能通过文本-only 适应和后续 ASR 微调显著改善 ASR 效果，并在零样本设置下，从高资源语言实现跨语言转移，相对基线模型的词错误率 (WER) 降低了最多 17%。这为低资源 ASR 提供了高效的适应策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13445v1",
      "published_date": "2024-10-17 11:19:44 UTC",
      "updated_date": "2024-10-17 11:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:58:21.824913"
    },
    {
      "arxiv_id": "2410.13441v1",
      "title": "Instruction-Driven Game Engine: A Poker Case Study",
      "title_zh": "指令驱动游戏引擎：扑克案例研究",
      "authors": [
        "Hongqiu Wu",
        "Xingyuan Liu",
        "Yan Wang",
        "Hai Zhao"
      ],
      "abstract": "The Instruction-Driven Game Engine (IDGE) project aims to democratize game\ndevelopment by enabling a large language model (LLM) to follow free-form game\ndescriptions and generate game-play processes. The IDGE allows users to create\ngames simply by natural language instructions, which significantly lowers the\nbarrier for game development. We approach the learning process for IDGEs as a\nNext State Prediction task, wherein the model autoregressively predicts the\ngame states given player actions. The computation of game states must be\nprecise; otherwise, slight errors could corrupt the game-play experience. This\nis challenging because of the gap between stability and diversity. To address\nthis, we train the IDGE in a curriculum manner that progressively increases its\nexposure to complex scenarios. Our initial progress lies in developing an IDGE\nfor Poker, which not only supports a wide range of poker variants but also\nallows for highly individualized new poker games through natural language\ninputs. This work lays the groundwork for future advancements in transforming\nhow games are created and played.",
      "tldr_zh": "这篇论文介绍了 Instruction-Driven Game Engine (IDGE)，一个利用大型语言模型 (LLM) 通过自然语言指令生成游戏过程的系统，旨在降低游戏开发门槛并实现游戏民主化。研究将 IDGE 的学习过程定义为 Next State Prediction 任务，模型通过自动回归预测玩家动作后的游戏状态，并采用课程学习方法逐步增加对复杂场景的暴露，以平衡稳定性和多样性。实验成果包括开发了一个支持多种扑克变体的 IDGE 系统，并允许用户通过自然语言输入创建个性化扑克游戏，为未来游戏创建和玩法变革奠定基础。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "EMNLP 2024 Demo. arXiv admin note: substantial text overlap with\n  arXiv:2404.00276",
      "pdf_url": "http://arxiv.org/pdf/2410.13441v1",
      "published_date": "2024-10-17 11:16:27 UTC",
      "updated_date": "2024-10-17 11:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:58:34.522076"
    },
    {
      "arxiv_id": "2410.13431v1",
      "title": "Solving Prior Distribution Mismatch in Diffusion Models via Optimal Transport",
      "title_zh": "通过最优传输解决扩散模型中的先验分布不匹配",
      "authors": [
        "Zhanpeng Wang",
        "Shenghao Li",
        "Chen Wang",
        "Shuting Cao",
        "Na Lei",
        "Zhongxuan Luo"
      ],
      "abstract": "In recent years, the knowledge surrounding diffusion models(DMs) has grown\nsignificantly, though several theoretical gaps remain. Particularly noteworthy\nis prior error, defined as the discrepancy between the termination distribution\nof the forward process and the initial distribution of the reverse process. To\naddress these deficiencies, this paper explores the deeper relationship between\noptimal transport(OT) theory and DMs with discrete initial distribution.\nSpecifically, we demonstrate that the two stages of DMs fundamentally involve\ncomputing time-dependent OT. However, unavoidable prior error result in\ndeviation during the reverse process under quadratic transport cost. By proving\nthat as the diffusion termination time increases, the probability flow\nexponentially converges to the gradient of the solution to the classical\nMonge-Amp\\`ere equation, we establish a vital link between these fields.\nTherefore, static OT emerges as the most intrinsic single-step method for\nbridging this theoretical potential gap. Additionally, we apply these insights\nto accelerate sampling in both unconditional and conditional generation\nscenarios. Experimental results across multiple image datasets validate the\neffectiveness of our approach.",
      "tldr_zh": "这篇论文解决了Diffusion Models (DMs)中先验分布不匹配的问题，即正向过程终止分布与逆向过程初始分布之间的偏差，通过引入Optimal Transport (OT)理论进行优化。作者证明了DMs的两个阶段本质上涉及计算时间相关的OT，并在二次传输成本下分析了先验错误导致的逆向过程偏差；此外，他们展示了随着扩散终止时间增加，概率流指数收敛到Monge-Ampère equation的梯度，从而将静态OT确立为桥接理论差距的最本质单步方法。该方法被应用于加速无条件和条件生成的采样，实验在多个图像数据集上验证了其有效性，提高了模型性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13431v1",
      "published_date": "2024-10-17 10:54:55 UTC",
      "updated_date": "2024-10-17 10:54:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:58:46.450824"
    },
    {
      "arxiv_id": "2410.13415v3",
      "title": "Shavette: Low Power Neural Network Acceleration via Algorithm-level Error Detection and Undervolting",
      "title_zh": "翻译失败",
      "authors": [
        "Mikael Rinkinen",
        "Lauri Koskinen",
        "Olli Silven",
        "Mehdi Safarpour"
      ],
      "abstract": "Reduced voltage operation is an effective technique for substantial energy\nefficiency improvement in digital circuits. This brief introduces a simple\napproach for enabling reduced voltage operation of Deep Neural Network (DNN)\naccelerators by mere software modifications. Conventional approaches for\nenabling reduced voltage operation e.g., Timing Error Detection (TED) systems,\nincur significant development costs and overheads, while not being applicable\nto the off-the-shelf components. Contrary to those, the solution proposed in\nthis paper relies on algorithm-based error detection, and hence, is implemented\nwith low development costs, does not require any circuit modifications, and is\neven applicable to commodity devices. By showcasing the solution through\nexperimenting on popular DNNs, i.e., LeNet and VGG16, on a GPU platform, we\ndemonstrate 18% to 25% energy saving with no accuracy loss of the models and\nnegligible throughput compromise (< 3.9%), considering the overheads from\nintegration of the error detection schemes into the DNN. The integration of\npresented algorithmic solution into the design is simpler when compared\nconventional TED based techniques that require extensive circuit-level\nmodifications, cell library characterizations or special support from the\ndesign tools.",
      "tldr_zh": "本文提出Shavette，一种基于算法级错误检测的低功耗DNN加速方法，通过软件修改实现undervolting，而非传统Timing Error Detection (TED)系统所需的硬件更改。相比TED方法，该方案开发成本低、易集成，且适用于现成设备，如GPU平台。实验在LeNet和VGG16模型上显示，能量节省18%至25%，模型准确性无损失，吞吐量影响小于3.9%。这为高效的神经网络加速提供了可行的新途径。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13415v3",
      "published_date": "2024-10-17 10:29:15 UTC",
      "updated_date": "2025-05-09 05:39:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:58:58.268959"
    },
    {
      "arxiv_id": "2410.13413v1",
      "title": "Think Thrice Before You Act: Progressive Thought Refinement in Large Language Models",
      "title_zh": "三思而后行：大型语言模型中的渐进式思想精炼",
      "authors": [
        "Chengyu Du",
        "Jinyi Han",
        "Yizhou Ying",
        "Aili Chen",
        "Qianyu He",
        "Haokun Zhao",
        "Sirui Xia",
        "Haoran Guo",
        "Jiaqing Liang",
        "Zulong Chen",
        "Liangyue Li",
        "Yanghua Xiao"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have demonstrated that\nprogressive refinement, rather than providing a single answer, results in more\naccurate and thoughtful outputs. However, existing methods often rely heavily\non supervision signals to evaluate previous responses, making it difficult to\nassess output quality in more open-ended scenarios effectively. Additionally,\nthese methods are typically designed for specific tasks, which limits their\ngeneralization to new domains. To address these limitations, we propose\nProgressive Thought Refinement (PTR), a framework that enables LLMs to refine\ntheir responses progressively. PTR operates in two phases: (1) Thought data\nconstruction stage: We propose a weak and strong model collaborative selection\nstrategy to build a high-quality progressive refinement dataset to ensure\nlogical consistency from thought to answers, and the answers are gradually\nrefined in each round. (2) Thought-Mask Fine-Tuning Phase: We design a training\nstructure to mask the \"thought\" and adjust loss weights to encourage LLMs to\nrefine prior thought, teaching them to implicitly understand \"how to improve\"\nrather than \"what is correct.\" Experimental results show that PTR significantly\nenhances LLM performance across ten diverse tasks (avg. from 49.6% to 53.5%)\nwithout task-specific fine-tuning. Notably, in more open-ended tasks, LLMs also\ndemonstrate substantial improvements in the quality of responses beyond mere\naccuracy, suggesting that PTR truly teaches LLMs to self-improve over time.",
      "tldr_zh": "本研究提出 Progressive Thought Refinement (PTR) 框架，以提升大型语言模型 (LLMs) 的渐进式响应精炼能力，解决现有方法依赖监督信号和任务特定性的局限问题。PTR 包括两个阶段：首先，通过弱强模型协作策略构建高质量数据集，确保从思想到答案的逻辑一致性；其次，利用 Thought-Mask Fine-Tuning 训练结构掩盖“thought”并调整损失权重，引导模型学会“如何改进”而非直接给出正确答案。实验结果显示，PTR 在十个多样任务上显著提升 LLM 性能（从 49.6% 到 53.5%），并在开放任务中改善响应质量，促进模型的自我提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13413v1",
      "published_date": "2024-10-17 10:23:24 UTC",
      "updated_date": "2024-10-17 10:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:59:10.873117"
    },
    {
      "arxiv_id": "2410.13409v2",
      "title": "Attr-Int: A Simple and Effective Entity Alignment Framework for Heterogeneous Knowledge Graphs",
      "title_zh": "Attr-Int：一个简单且有效的异构知识图谱实体对齐框架",
      "authors": [
        "Linyan Yang",
        "Jingwei Cheng",
        "Chuanhao Xu",
        "Xihao Wang",
        "Jiayi Li",
        "Fu Zhang"
      ],
      "abstract": "Entity alignment (EA) refers to the task of linking entities in different\nknowledge graphs (KGs). Existing EA methods rely heavily on structural\nisomorphism. However, in real-world KGs, aligned entities usually have\nnon-isomorphic neighborhood structures, which paralyses the application of\nthese structure-dependent methods. In this paper, we investigate and tackle the\nproblem of entity alignment between heterogeneous KGs. First, we propose two\nnew benchmarks to closely simulate real-world EA scenarios of heterogeneity.\nThen we conduct extensive experiments to evaluate the performance of\nrepresentative EA methods on the new benchmarks. Finally, we propose a simple\nand effective entity alignment framework called Attr-Int, in which innovative\nattribute information interaction methods can be seamlessly integrated with any\nembedding encoder for entity alignment, improving the performance of existing\nentity alignment techniques. Experiments demonstrate that our framework\noutperforms the state-of-the-art approaches on two new benchmarks.",
      "tldr_zh": "本研究探讨了实体对齐 (Entity Alignment, EA) 任务，即链接不同知识图谱 (Knowledge Graphs, KGs) 中的实体，但现有方法依赖结构同构 (structural isomorphism)，在异构 KGs 场景下表现不佳。论文提出两个新基准来模拟真实世界的异构 EA 场景，并通过广泛实验评估了代表性方法的性能。随后，作者引入了一个简单有效的框架 Attr-Int，该框架允许创新的属性信息交互方法与任意嵌入编码器 (embedding encoder) 无缝整合，从而提升现有 EA 技术的效果。实验结果显示，Attr-Int 在两个新基准上超过了最先进的方法 (state-of-the-art approaches)。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13409v2",
      "published_date": "2024-10-17 10:16:56 UTC",
      "updated_date": "2024-11-04 12:40:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:59:22.736967"
    },
    {
      "arxiv_id": "2410.13408v2",
      "title": "MoR: Mixture of Ranks for Low-Rank Adaptation Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Chuanyu Tang",
        "Yilong Chen",
        "Zhenyu Zhang",
        "Junyuan Shang",
        "Wenyuan Zhang",
        "Yong Huang",
        "Tingwen Liu"
      ],
      "abstract": "Low-Rank Adaptation (LoRA) drives research to align its performance with full\nfine-tuning. However, significant challenges remain: (1) Simply increasing the\nrank size of LoRA does not effectively capture high-rank information, which\nleads to a performance bottleneck.(2) MoE-style LoRA methods substantially\nincrease parameters and inference latency, contradicting the goals of efficient\nfine-tuning and ease of application. To address these challenges, we introduce\nMixture of Ranks (MoR), which learns rank-specific information for different\ntasks based on input and efficiently integrates multi-rank information. We\nfirstly propose a new framework that equates the integration of multiple LoRAs\nto expanding the rank of LoRA. Moreover, we hypothesize that low-rank LoRA\nalready captures sufficient intrinsic information, and MoR can derive high-rank\ninformation through mathematical transformations of the low-rank components.\nThus, MoR can reduces the learning difficulty of LoRA and enhances its\nmulti-task capabilities. MoR achieves impressive results, with MoR delivering a\n1.31\\% performance improvement while using only 93.93\\% of the parameters\ncompared to baseline methods.",
      "tldr_zh": "本论文针对 Low-Rank Adaptation (LoRA) 在微调中的性能瓶颈问题，即简单增加 rank 无法有效捕获高-rank 信息，以及 MoE-style LoRA 方法导致参数和推理延迟增加的问题，提出了一种新框架 Mixture of Ranks (MoR)。MoR 通过基于输入学习任务特定的 rank 信息，并将多个 LoRA 的整合等同于扩展 rank，同时利用低-rank 组件的数学变换来生成高-rank 信息，从而减少学习难度并增强多任务能力。实验结果显示，MoR 相较基线方法提高了 1.31% 的性能，同时仅使用 93.93% 的参数，实现了高效的微调优化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13408v2",
      "published_date": "2024-10-17 10:14:52 UTC",
      "updated_date": "2024-10-18 03:05:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:59:37.171478"
    },
    {
      "arxiv_id": "2410.13919v2",
      "title": "LLM Agent Honeypot: Monitoring AI Hacking Agents in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Reworr",
        "Dmitrii Volkov"
      ],
      "abstract": "Attacks powered by Large Language Model (LLM) agents represent a growing\nthreat to modern cybersecurity. To address this concern, we present LLM\nHoneypot, a system designed to monitor autonomous AI hacking agents. By\naugmenting a standard SSH honeypot with prompt injection and time-based\nanalysis techniques, our framework aims to distinguish LLM agents among all\nattackers. Over a trial deployment of about three months in a public\nenvironment, we collected 8,130,731 hacking attempts and 8 potential AI agents.\nOur work demonstrates the emergence of AI-driven threats and their current\nlevel of usage, serving as an early warning of malicious LLM agents in the\nwild.",
      "tldr_zh": "这篇论文介绍了LLM Honeypot系统，用于监控野外中的AI黑客代理，以应对由Large Language Model (LLM)驱动的网络安全威胁。该系统在标准SSH honeypot基础上，加入prompt injection和时间-based分析技术，以有效区分LLM代理。在约三个月的公开部署中，系统收集了8,130,731次黑客尝试，并识别出8个潜在的AI代理，证明了AI驱动威胁的现实存在，并作为对恶意LLM代理的早期预警。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13919v2",
      "published_date": "2024-10-17 09:25:28 UTC",
      "updated_date": "2025-02-10 22:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:59:45.266813"
    },
    {
      "arxiv_id": "2410.13374v1",
      "title": "Context-aware adaptive personalised recommendation: a meta-hybrid",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Tibensky",
        "Michal Kompan"
      ],
      "abstract": "Recommenders take place on a wide scale of e-commerce systems, reducing the\nproblem of information overload. The most common approach is to choose a\nrecommender used by the system to make predictions. However, users vary from\neach other; thus, a one-fits-all approach seems to be sub-optimal. In this\npaper, we propose a meta-hybrid recommender that uses machine learning to\npredict an optimal algorithm. In this way, the best-performing recommender is\nused for each specific session and user. This selection depends on contextual\nand preferential information collected about the user. We use standard\nMovieLens and The Movie DB datasets for offline evaluation. We show that based\non the proposed model, it is possible to predict which recommender will provide\nthe most precise recommendations to a user. The theoretical performance of our\nmeta-hybrid outperforms separate approaches by 20-50% in normalized Discounted\nGain and Root Mean Square Error metrics. However, it is hard to obtain the\noptimal performance based on widely-used standard information stored about\nusers.",
      "tldr_zh": "该论文针对推荐系统的信息过载问题，提出了一种 context-aware 的 meta-hybrid 推荐器，使用 machine learning 预测每个用户和会话的最优算法，从而适应用户差异。系统基于用户的上下文和偏好信息动态选择最佳推荐器，并在 MovieLens 和 The Movie DB 数据集上进行离线评估。结果显示，该方法在 normalized Discounted Cumulative Gain (nDCG) 和 Root Mean Square Error (RMSE) 指标上比传统方法提高了 20-50%，但依赖标准用户信息时难以达到最优性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13374v1",
      "published_date": "2024-10-17 09:24:40 UTC",
      "updated_date": "2024-10-17 09:24:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T12:59:58.725720"
    },
    {
      "arxiv_id": "2410.13370v2",
      "title": "MagicTailor: Component-Controllable Personalization in Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Donghao Zhou",
        "Jiancheng Huang",
        "Jinbin Bai",
        "Jiaze Wang",
        "Hao Chen",
        "Guangyong Chen",
        "Xiaowei Hu",
        "Pheng-Ann Heng"
      ],
      "abstract": "Recent text-to-image models generate high-quality images from text prompts\nbut lack precise control over specific components within visual concepts.\nTherefore, we introduce component-controllable personalization, a new task that\nallows users to customize and reconfigure individual components within\nconcepts. This task faces two challenges: semantic pollution, where undesirable\nelements distort the concept, and semantic imbalance, which leads to\ndisproportionate learning of the target concept and component. To address\nthese, we design MagicTailor, a framework that uses Dynamic Masked Degradation\nto adaptively perturb unwanted visual semantics and Dual-Stream Balancing for\nmore balanced learning of desired visual semantics. The experimental results\nshow that MagicTailor outperforms existing methods in this task and enables\nmore personalized, nuanced, and creative image generation.",
      "tldr_zh": "该论文提出了 MagicTailor，一种组件可控个性化框架，针对文本到图像扩散模型（text-to-image diffusion models）中缺乏对视觉概念内特定组件精确控制的问题，引入了 component-controllable personalization 新任务。该框架通过 Dynamic Masked Degradation 技术来适应性地扰动不想要的视觉语义（semantic pollution），并采用 Dual-Stream Balancing 方法实现目标概念和组件的平衡学习（semantic imbalance）。实验结果显示，MagicTailor 优于现有方法，能生成更个性化的、细微的和创造性的图像。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://correr-zhou.github.io/MagicTailor",
      "pdf_url": "http://arxiv.org/pdf/2410.13370v2",
      "published_date": "2024-10-17 09:22:53 UTC",
      "updated_date": "2024-12-06 07:58:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:00:09.728855"
    },
    {
      "arxiv_id": "2410.13360v3",
      "title": "RAP: Retrieval-Augmented Personalization for Multimodal Large Language Models",
      "title_zh": "RAP：检索增强",
      "authors": [
        "Haoran Hao",
        "Jiaming Han",
        "Changsheng Li",
        "Yu-Feng Li",
        "Xiangyu Yue"
      ],
      "abstract": "The development of large language models (LLMs) has significantly enhanced\nthe capabilities of multimodal LLMs (MLLMs) as general assistants. However,\nlack of user-specific knowledge still restricts their application in human's\ndaily life. In this paper, we introduce the Retrieval Augmented Personalization\n(RAP) framework for MLLMs' personalization. Starting from a general MLLM, we\nturn it into a personalized assistant in three steps. (a) Remember: We design a\nkey-value database to store user-related information, e.g., user's name, avatar\nand other attributes. (b) Retrieve: When the user initiates a conversation, RAP\nwill retrieve relevant information from the database using a multimodal\nretriever. (c) Generate: The input query and retrieved concepts' information\nare fed into MLLMs to generate personalized, knowledge-augmented responses.\nUnlike previous methods, RAP allows real-time concept editing via updating the\nexternal database. To further improve generation quality and alignment with\nuser-specific information, we design a pipeline for data collection and create\na specialized dataset for personalized training of MLLMs. Based on the dataset,\nwe train a series of MLLMs as personalized multimodal assistants. By\npretraining on large-scale dataset, RAP-MLLMs can generalize to infinite visual\nconcepts without additional finetuning. Our models demonstrate outstanding\nflexibility and generation quality across a variety of tasks, such as\npersonalized image captioning, question answering and visual recognition. The\ncode, data and models are available at https://hoar012.github.io/RAP-Project/.",
      "tldr_zh": "本文提出了一种Retrieval-Augmented Personalization (RAP)框架，用于提升多模态大型语言模型(MLLMs)的个性化能力，解决其缺乏用户特定知识的局限性。RAP框架包括三个步骤：Remember（使用键值数据库存储用户相关信息）、Retrieve（通过多模态检索器提取相关数据）和Generate（将查询与检索信息输入MLLMs生成个性化响应），并支持实时概念编辑以更新外部数据库。为进一步优化性能，作者设计了数据收集管道并创建专用数据集，对MLLMs进行个性化训练，结果显示RAP-MLLMs在个性化图像描述、问答和视觉识别等任务中表现出色，并能泛化到无限视觉概念无需额外微调。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025. Code: https://github.com/Hoar012/RAP-MLLM",
      "pdf_url": "http://arxiv.org/pdf/2410.13360v3",
      "published_date": "2024-10-17 09:10:26 UTC",
      "updated_date": "2025-03-28 17:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:00:23.692570"
    },
    {
      "arxiv_id": "2410.13918v2",
      "title": "FTSmartAudit: A Knowledge Distillation-Enhanced Framework for Automated Smart Contract Auditing Using Fine-Tuned LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Wei",
        "Jing Sun",
        "Zijian Zhang",
        "Xianhao Zhang",
        "Meng Li",
        "Mauro Conti"
      ],
      "abstract": "The rise of blockchain technologies has greatly accelerated the development\nand deployment of smart contracts. However, their inherent vulnerabilities and\nsusceptibility to bugs have led to significant financial losses, underscoring\nthe challenges in securing smart contracts. While traditional auditing methods\nare crucial, they often fall short in addressing the increasing complexity and\nvolume of smart contracts. Recent advancements in Large Language Models (LLMs)\noffer promising solutions for enhancing software auditing by automatically\nidentifying security vulnerabilities. Despite their potential, the practical\napplication of these models is hindered by substantial computational demands.\nThis paper investigates the feasibility of using smaller, fine-tuned models to\nachieve comparable or even superior results in smart contract auditing. We\nintroduce the FTSmartAudit framework, which is designed to develop\ncost-effective, specialized models for smart contract auditing through the\nfine-tuning of LLMs. Our contributions include: (1) a single-task learning\nframework that streamlines data preparation, training, evaluation, and\ncontinuous learning; (2) a robust dataset generation method utilizing\ndomain-special knowledge distillation to produce high-quality datasets from\nadvanced models like GPT-4o; (3) an adaptive learning strategy to maintain\nmodel accuracy and robustness; (4) the proven effectiveness of fine-tuned\nmodels in detecting specific vulnerabilities and complex logical errors; and\n(5) a framework that can be extended to other domains requiring LLM solutions.\nOur experimental results demonstrate that smaller models can surpass\nstate-of-the-art commercial models and tools in detecting vulnerabilities in\nsmart contracts.",
      "tldr_zh": "本文提出 FTSmartAudit 框架，利用 Knowledge Distillation 和 Fine-Tuned LLMs 来实现智能合约的自动化审计，旨在解决传统方法在处理复杂漏洞时的局限性。框架包括单任务学习框架、基于域知识蒸馏的数据集生成方法、自适应学习策略，以及验证微调模型在检测特定漏洞和逻辑错误方面的有效性。实验结果显示，该框架的较小模型在智能合约漏洞检测上超过了现有商业模型和工具，并可扩展至其他需要 LLM 解决方案的领域。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "26 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13918v2",
      "published_date": "2024-10-17 09:09:09 UTC",
      "updated_date": "2025-02-08 02:57:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:00:37.855166"
    },
    {
      "arxiv_id": "2410.13352v1",
      "title": "LAR-ECHR: A New Legal Argument Reasoning Task and Dataset for Cases of the European Court of Human Rights",
      "title_zh": "LAR-ECHR：一个新的法律论证推理任务和数据集，用于欧洲人权法院的案件",
      "authors": [
        "Odysseas S. Chlapanis",
        "Dimitrios Galanis",
        "Ion Androutsopoulos"
      ],
      "abstract": "We present Legal Argument Reasoning (LAR), a novel task designed to evaluate\nthe legal reasoning capabilities of Large Language Models (LLMs). The task\nrequires selecting the correct next statement (from multiple choice options) in\na chain of legal arguments from court proceedings, given the facts of the case.\nWe constructed a dataset (LAR-ECHR) for this task using cases from the European\nCourt of Human Rights (ECHR). We evaluated seven general-purpose LLMs on\nLAR-ECHR and found that (a) the ranking of the models is aligned with that of\nLegalBench, an established US-based legal reasoning benchmark, even though\nLAR-ECHR is based on EU law, (b) LAR-ECHR distinguishes top models more\nclearly, compared to LegalBench, (c) even the best model (GPT-4o) obtains 75.8%\naccuracy on LAR-ECHR, indicating significant potential for further model\nimprovement. The process followed to construct LAR-ECHR can be replicated with\ncases from other legal systems.",
      "tldr_zh": "本研究引入了Legal Argument Reasoning (LAR) 任务，这是一个新颖的评估Large Language Models (LLMs) 法律推理能力的测试，涉及从多个选择中选出案件事实下正确的下一个法律论证陈述。该任务基于欧洲人权法院 (ECHR) 案件构建了数据集 LAR-ECHR，并评估了七个通用LLMs 的性能。结果显示，模型排名与LegalBench 基准一致，但 LAR-ECHR 更能清晰区分顶级模型，且最佳模型 GPT-4o 的准确率仅为75.8%，表明仍有显著改进潜力；此外，该数据集构建过程可复制应用于其他法律系统。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in Natural Legal Language Processing (NLLP) 2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2410.13352v1",
      "published_date": "2024-10-17 09:03:38 UTC",
      "updated_date": "2024-10-17 09:03:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:00:45.954833"
    },
    {
      "arxiv_id": "2410.13351v1",
      "title": "Representation Learning of Structured Data for Medical Foundation Models",
      "title_zh": "结构化数据的表示学习用于医疗基础模型",
      "authors": [
        "Vijay Prakash Dwivedi",
        "Viktor Schlegel",
        "Andy T. Liu",
        "Thanh-Tung Nguyen",
        "Abhinav Ramesh Kashyap",
        "Jeng Wei",
        "Wei-Hsian Yin",
        "Stefan Winkler",
        "Robby T. Tan"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across\nvarious domains, including healthcare. However, their ability to effectively\nrepresent structured non-textual data, such as the alphanumeric medical codes\nused in records like ICD-10 or SNOMED-CT, is limited and has been particularly\nexposed in recent research. This paper examines the challenges LLMs face in\nprocessing medical codes due to the shortcomings of current tokenization\nmethods. As a result, we introduce the UniStruct architecture to design a\nmultimodal medical foundation model of unstructured text and structured data,\nwhich addresses these challenges by adapting subword tokenization techniques\nspecifically for the structured medical codes. Our approach is validated\nthrough model pre-training on both an extensive internal medical database and a\npublic repository of structured medical records. Trained on over 1 billion\ntokens on the internal medical database, the proposed model achieves up to a\n23% improvement in evaluation metrics, with around 2% gain attributed to our\nproposed tokenization. Additionally, when evaluated on the EHRSHOT public\nbenchmark with a 1/1000 fraction of the pre-training data, the UniStruct model\nimproves performance on over 42% of the downstream tasks. Our approach not only\nenhances the representation and generalization capabilities of patient-centric\nmodels but also bridges a critical gap in representation learning models'\nability to handle complex structured medical data, alongside unstructured text.",
      "tldr_zh": "本论文探讨了大型语言模型(LLMs)在处理结构化非文本数据（如ICD-10或SNOMED-CT医疗代码）时的局限性，主要由于现有分词方法的不足。为解决这一问题，研究引入UniStruct架构，这是一种多模态医疗基础模型，通过适应子词分词技术来整合非结构化文本和结构化数据，并在内部医疗数据库（超过10亿tokens）和公共存储库上进行预训练。实验结果显示，该模型在评估指标上提升高达23%，其中2%归功于改进的分词方法，并在EHRSHOT公共基准上，使用1/1000的预训练数据时，在超过42%的下游任务中提升性能，从而增强了患者中心模型的表示和泛化能力，并桥接了处理复杂结构化医疗数据的关键差距。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 Workshop on Unifying Representations in Neural Models\n  (UniReps 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.13351v1",
      "published_date": "2024-10-17 09:02:28 UTC",
      "updated_date": "2024-10-17 09:02:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:00:57.866039"
    },
    {
      "arxiv_id": "2410.13344v1",
      "title": "Cerberus: Efficient Inference with Adaptive Parallel Decoding and Sequential Knowledge Enhancement",
      "title_zh": "Cerberus：高效推理的自适应并行解码和顺序知识增强",
      "authors": [
        "Yuxuan Liu",
        "Wenyuan Li",
        "Laizhong Cui",
        "Hailiang Yang"
      ],
      "abstract": "Large language models (LLMs) often face a bottleneck in inference speed due\nto their reliance on auto-regressive decoding. Recently, parallel decoding has\nshown significant promise in enhancing inference efficiency. However, we have\nidentified two key issues with existing parallel decoding frameworks: (1)\ndecoding heads fail to balance prediction accuracy and the parallelism of\nexecution, and (2) parallel decoding is not a universal solution, as it can\nbring unnecessary overheads at some challenging decoding steps. To address\nthese issues, we propose Cerberus, an adaptive parallel decoding framework\nintroduces the gating mechanism to enable the LLMs to adaptively choose\nappropriate decoding approaches at each decoding step, along with introducing a\nnew paradigm of decoding heads that introduce the sequential knowledge while\nmaintaining execution parallelism. The experiment results demonstrate that the\nCerberus can achieve up to 2.12x speed up compared to auto-regressive decoding,\nand outperforms one of the leading parallel decoding frameworks, Medusa, with a\n10% - 30% increase in acceleration and superior generation quality.",
      "tldr_zh": "大型语言模型 (LLMs) 在推理过程中依赖自回归解码，导致效率低下，而现有平行解码框架存在解码头平衡性差和不适用性等问题。研究提出 Cerberus，一种自适应平行解码框架，通过引入门控机制 (gating mechanism) 让模型在每个解码步骤动态选择最佳解码方法，并采用新解码头范式结合顺序知识 (sequential knowledge) 同时保持执行并行性。实验结果显示，Cerberus 相较自回归解码实现高达 2.12 倍的加速，并比领先框架 Medusa 提高 10%-30% 的加速效果，同时提升生成质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13344v1",
      "published_date": "2024-10-17 08:55:18 UTC",
      "updated_date": "2024-10-17 08:55:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:01:10.491375"
    },
    {
      "arxiv_id": "2410.18127v1",
      "title": "Optimizing Preference Alignment with Differentiable NDCG Ranking",
      "title_zh": "利用可微 NDCG 排名优化偏好对齐",
      "authors": [
        "Jiacong Zhou",
        "Xianyun Wang",
        "Jun Yu"
      ],
      "abstract": "Aligning large language models with human preferences improves interaction\nquality and safety by ensuring outputs better reflect human values. A promising\nstrategy involves Reinforcement Learning from Human Feedback (RLHF), starting\nwith collecting and ranking responses generated by a supervised fine-tuning\nmodel to refine alignment. Current methods (DPO) focus on learning from\npairwise preference data, categorizing responses into preferred and less\npreferred pairs, and optimizing by maximizing pairwise margins. Recent studies\nhave uncovered a substantial discrepancy between the theoretical aspirations of\npreference learning and its real-world results. Current preference alignment\ntechniques underperform expectations, with ranking accuracies below $60\\%$ on\nstandard datasets. This suggests existing methods inadequately capture ideal\npreference relationships within sequences. To address this challenge, this\npaper introduces \\underline{D}irect \\underline{R}anking \\underline{P}reference\n\\underline{O}ptimization (DRPO), a novel method that views human preference\nalignment as a Learning-to-Rank (LTR) task. DRPO leverages NDCG, a widely used\nLTR metric, to optimize the ranking of responses within lists based on\npreference data, thereby enhancing ranking accuracies. Due to the\nnondifferentiability of NDCG, we propose diffNDCG loss, a differentiable\napproximation facilitated by a sorting network to simulate NDCG. Furthermore,\nto improve the quality of generated response, we propose a novel margin-based\nAdaptive Rank Policy Score. Extensive experiments have shown that DRPO\noutperforms existing baseline methods, enhancing the quality of the generated\nresponses.",
      "tldr_zh": "该研究针对大型语言模型与人类偏好的对齐问题，指出现有方法如 Reinforcement Learning from Human Feedback (RLHF) 和 DPO 在排名准确率上低于60%，无法充分捕捉偏好关系。论文提出Direct Ranking Preference Optimization (DRPO)方法，将偏好对齐视为Learning-to-Rank (LTR)任务，并利用NDCG指标优化响应排名；为解决NDCG的不可微分性，引入diffNDCG loss和margin-based Adaptive Rank Policy Score来提升优化效率和生成质量。实验结果显示，DRPO优于现有基线方法，提高了响应质量和排名准确率。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.18127v1",
      "published_date": "2024-10-17 08:54:57 UTC",
      "updated_date": "2024-10-17 08:54:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:01:32.998605"
    },
    {
      "arxiv_id": "2410.13342v1",
      "title": "DART: Disentanglement of Accent and Speaker Representation in Multispeaker Text-to-Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Melechovsky",
        "Ambuj Mehrish",
        "Berrak Sisman",
        "Dorien Herremans"
      ],
      "abstract": "Recent advancements in Text-to-Speech (TTS) systems have enabled the\ngeneration of natural and expressive speech from textual input. Accented TTS\naims to enhance user experience by making the synthesized speech more relatable\nto minority group listeners, and useful across various applications and\ncontext. Speech synthesis can further be made more flexible by allowing users\nto choose any combination of speaker identity and accent, resulting in a wide\nrange of personalized speech outputs. Current models struggle to disentangle\nspeaker and accent representation, making it difficult to accurately imitate\ndifferent accents while maintaining the same speaker characteristics. We\npropose a novel approach to disentangle speaker and accent representations\nusing multi-level variational autoencoders (ML-VAE) and vector quantization\n(VQ) to improve flexibility and enhance personalization in speech synthesis.\nOur proposed method addresses the challenge of effectively separating speaker\nand accent characteristics, enabling more fine-grained control over the\nsynthesized speech. Code and speech samples are publicly available.",
      "tldr_zh": "该论文探讨了Text-to-Speech (TTS)系统中的关键挑战，即难以分离说话者身份和口音表示，导致合成语音无法精确模仿不同口音同时保持说话者特征。作者提出DART方法，使用multi-level variational autoencoders (ML-VAE)和vector quantization (VQ)来disentangle说话者和口音表示，从而实现更灵活的个性化语音合成。实验结果表明，该方法提升了TTS的灵活性和用户体验，并公开了代码和语音样本以促进进一步研究。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted in Audio Imagination workshop of NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.13342v1",
      "published_date": "2024-10-17 08:51:46 UTC",
      "updated_date": "2024-10-17 08:51:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:01:33.878797"
    },
    {
      "arxiv_id": "2410.13338v1",
      "title": "DiffImp: Efficient Diffusion Model for Probabilistic Time Series Imputation with Bidirectional Mamba Backbone",
      "title_zh": "翻译失败",
      "authors": [
        "Hongfan Gao",
        "Wangmeng Shen",
        "Xiangfei Qiu",
        "Ronghui Xu",
        "Jilin Hu",
        "Bin Yang"
      ],
      "abstract": "Probabilistic time series imputation has been widely applied in real-world\nscenarios due to its ability to estimate uncertainty of imputation results.\nMeanwhile, denoising diffusion probabilistic models (DDPMs) have achieved great\nsuccess in probabilistic time series imputation tasks with its power to model\ncomplex distributions. However, current DDPM-based probabilistic time series\nimputation methodologies are confronted with two types of challenges:\n1)~\\textit{~The backbone modules of the denoising parts are not capable of\nachieving sequence modeling with low time complexity.} 2)~\\textit{The\narchitecture of denoising modules can not handle the inter-variable and\nbidirectional dependencies in the time series imputation problem effectively.}\nTo address the first challenge, we integrate the computational efficient state\nspace model, namely Mamba, as the backbone denosing module for DDPMs. To tackle\nthe second challenge, we carefully devise several SSM-based blocks for\nbidirectional modeling and inter-variable relation understanding. Experimental\nresults demonstrate that our approach can achieve state-of-the-art time series\nimputation results on multiple datasets, different missing scenarios and\nmissing ratios.",
      "tldr_zh": "本论文提出DiffImp，一种高效的扩散模型，用于probabilistic time series imputation，通过整合计算高效的状态空间模型Mamba作为骨干模块，解决现有DDPM-based方法的低时间复杂度和序列建模问题。该模型还设计了基于SSM的块，实现双向建模和变量间依赖关系的有效处理。实验结果显示，DiffImp在多个数据集、不同缺失场景和缺失比例下，达到了state-of-the-art的时间序列插值性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "25 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13338v1",
      "published_date": "2024-10-17 08:48:52 UTC",
      "updated_date": "2024-10-17 08:48:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:01:45.616621"
    },
    {
      "arxiv_id": "2410.13334v3",
      "title": "BiasJailbreak:Analyzing Ethical Biases and Jailbreak Vulnerabilities in Large Language Models",
      "title_zh": "Bias",
      "authors": [
        "Isack Lee",
        "Haebin Seong"
      ],
      "abstract": "Although large language models (LLMs) demonstrate impressive proficiency in\nvarious tasks, they present potential safety risks, such as `jailbreaks', where\nmalicious inputs can coerce LLMs into generating harmful content bypassing\nsafety alignments. In this paper, we delve into the ethical biases in LLMs and\nexamine how those biases could be exploited for jailbreaks. Notably, these\nbiases result in a jailbreaking success rate in GPT-4o models that differs by\n20\\% between non-binary and cisgender keywords and by 16\\% between white and\nblack keywords, even when the other parts of the prompts are identical. We\nintroduce the concept of BiasJailbreak, highlighting the inherent risks posed\nby these safety-induced biases. BiasJailbreak generates biased keywords\nautomatically by asking the target LLM itself, and utilizes the keywords to\ngenerate harmful output. Additionally, we propose an efficient defense method\nBiasDefense, which prevents jailbreak attempts by injecting defense prompts\nprior to generation. BiasDefense stands as an appealing alternative to Guard\nModels, such as Llama-Guard, that require additional inference cost after text\ngeneration. Our findings emphasize that ethical biases in LLMs can actually\nlead to generating unsafe output, and suggest a method to make the LLMs more\nsecure and unbiased. To enable further research and improvements, we\nopen-source our code and artifacts of BiasJailbreak, providing the community\nwith tools to better understand and mitigate safety-induced biases in LLMs.",
      "tldr_zh": "这篇论文分析了大型语言模型(LLMs)中的道德偏差(ethical biases)如何被利用进行jailbreaks攻击，导致生成有害内容。研究发现，在GPT-4o模型中，非二元和顺性别关键词的jailbreak成功率差异达20%，白人和黑人关键词差异达16%，突显了这些偏差的风险。作者引入了BiasJailbreak方法，通过让目标LLM自动生成偏见关键词来实现攻击，并提出BiasDefense防御机制，在生成前注入提示以高效防范此类漏洞，同时开源代码以推动LLMs的安全性和无偏见改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13334v3",
      "published_date": "2024-10-17 08:46:09 UTC",
      "updated_date": "2025-01-02 04:06:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:01:59.281839"
    },
    {
      "arxiv_id": "2410.13331v1",
      "title": "Improving Discrete Optimisation Via Decoupled Straight-Through Gumbel-Softmax",
      "title_zh": "翻译失败",
      "authors": [
        "Rushi Shah",
        "Mingyuan Yan",
        "Michael Curtis Mozer",
        "Dianbo Liu"
      ],
      "abstract": "Discrete representations play a crucial role in many deep learning\narchitectures, yet their non-differentiable nature poses significant challenges\nfor gradient-based optimization. To address this issue, various gradient\nestimators have been developed, including the Straight-Through Gumbel-Softmax\n(ST-GS) estimator, which combines the Straight-Through Estimator (STE) and the\nGumbel-based reparameterization trick. However, the performance of ST-GS is\nhighly sensitive to temperature, with its selection often compromising gradient\nfidelity. In this work, we propose a simple yet effective extension to ST-GS by\nemploying decoupled temperatures for forward and backward passes, which we\nrefer to as \"Decoupled ST-GS\". We show that our approach significantly enhances\nthe original ST-GS through extensive experiments across multiple tasks and\ndatasets. We further investigate the impact of our method on gradient fidelity\nfrom multiple perspectives, including the gradient gap and the bias-variance\ntrade-off of estimated gradients. Our findings contribute to the ongoing effort\nto improve discrete optimization in deep learning, offering a practical\nsolution that balances simplicity and effectiveness.",
      "tldr_zh": "该论文针对离散表示在深度学习中的非微分性优化挑战，提出了一种改进的梯度估算方法，即 Decoupled Straight-Through Gumbel-Softmax (Decoupled ST-GS)。这种方法通过在前向和后向传播中使用分离的温度参数，解决了原 ST-GS 对温度高度敏感的问题，从而提升梯度保真度。实验结果显示，Decoupled ST-GS 在多个任务和数据集上显著提高了性能，并优化了梯度差距以及偏差-方差权衡。该方法为深度学习中的离散优化提供了简单且有效的实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13331v1",
      "published_date": "2024-10-17 08:44:57 UTC",
      "updated_date": "2024-10-17 08:44:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:02:10.845733"
    },
    {
      "arxiv_id": "2410.13321v3",
      "title": "Mitigating Hallucinations in Large Vision-Language Models via Summary-Guided Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungmin Min",
        "Minbeom Kim",
        "Kang-il Lee",
        "Dongryeol Lee",
        "Kyomin Jung"
      ],
      "abstract": "Large Vision-Language Models (LVLMs) demonstrate impressive capabilities in\ngenerating detailed and coherent responses from visual inputs. However, they\nare prone to generate hallucinations due to an over-reliance on language\npriors. To address this issue, we investigate the language priors in LVLMs and\nmake two key observations: (1) Even when predicting the tokens associated with\nimage-related part-of-speech (POS), models increasingly rely on linguistic\npriors as the token sequences grow, thereby amplifying hallucinations. (2)\nMethods that directly calibrate LVLM's output distribution to mitigate language\npriors can lead to a degradation in text quality or even exacerbate\nhallucinations. Based on these findings, we propose a novel method,\nSummary-Guided Decoding (SumGD). This method naturally encourages the model to\nfocus more on image information by reducing the text context through summaries,\nwhile controlling only the image-related POS tokens to maintain text quality.\nThrough experiments, we demonstrate that SumGD achieves state-of-the-art\nperformance on object hallucination benchmarks. Furthermore, in terms of the\ntrade-off between precision and recall, SumGD achieves Pareto optimality among\nthe existing methods. Lastly, we observe that although existing methods\nstruggle to balance the reduction of object hallucinations with maintaining\ntext quality, SumGD demonstrates robustness in handling this challenge.",
      "tldr_zh": "Large Vision-Language Models (LVLMs) 容易因过度依赖语言先验而产生幻觉，本文通过调查发现：即使在预测图像相关 part-of-speech (POS) 标记时，模型也会随着序列增长而放大幻觉，且直接校准输出分布的方法可能降低文本质量。针对这些问题，提出 Summary-Guided Decoding (SumGD) 方法，该方法通过使用摘要减少文本上下文并仅控制图像相关 POS 标记，鼓励模型更注重图像信息。实验结果表明，SumGD 在对象幻觉基准上达到最先进性能，并在精确率与召回率的权衡上实现帕累托最优，同时有效平衡了减少幻觉与保持文本质量。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "NAACL 2025 (Findings); Renamed SGD to SumGD in Summary-Guided\n  Decoding to prevent confusion with Stochastic Gradient Descent",
      "pdf_url": "http://arxiv.org/pdf/2410.13321v3",
      "published_date": "2024-10-17 08:24:27 UTC",
      "updated_date": "2025-02-19 05:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:02:33.498851"
    },
    {
      "arxiv_id": "2410.13318v1",
      "title": "Computational Approaches to Arabic-English Code-Switching",
      "title_zh": "翻译失败",
      "authors": [
        "Caroline Sabty"
      ],
      "abstract": "Natural Language Processing (NLP) is a vital computational method for\naddressing language processing, analysis, and generation. NLP tasks form the\ncore of many daily applications, from automatic text correction to speech\nrecognition. While significant research has focused on NLP tasks for the\nEnglish language, less attention has been given to Modern Standard Arabic and\nDialectal Arabic. Globalization has also contributed to the rise of\nCode-Switching (CS), where speakers mix languages within conversations and even\nwithin individual words (intra-word CS). This is especially common in Arab\ncountries, where people often switch between dialects or between dialects and a\nforeign language they master. CS between Arabic and English is frequent in\nEgypt, especially on social media. Consequently, a significant amount of\ncode-switched content can be found online. Such code-switched data needs to be\ninvestigated and analyzed for several NLP tasks to tackle the challenges of\nthis multilingual phenomenon and Arabic language challenges. No work has been\ndone before for several integral NLP tasks on Arabic-English CS data. In this\nwork, we focus on the Named Entity Recognition (NER) task and other tasks that\nhelp propose a solution for the NER task on CS data, e.g., Language\nIdentification. This work addresses this gap by proposing and applying\nstate-of-the-art techniques for Modern Standard Arabic and Arabic-English NER.\nWe have created the first annotated CS Arabic-English corpus for the NER task.\nAlso, we apply two enhancement techniques to improve the NER tagger on CS data\nusing CS contextual embeddings and data augmentation techniques. All methods\nshowed improvements in the performance of the NER taggers on CS data. Finally,\nwe propose several intra-word language identification approaches to determine\nthe language type of a mixed text and identify whether it is a named entity or\nnot.",
      "tldr_zh": "这篇论文探讨了 Natural Language Processing (NLP) 在处理阿拉伯语和英语 Code-Switching (CS) 时的挑战，强调了全球化和社交媒体中 CS 现象（如埃及的阿拉伯-英语混合）的增多。研究填补了空白，创建了第一个针对 CS 数据的阿拉伯-英语 Named Entity Recognition (NER) 注释语料库，并应用了 CS 上下文嵌入和数据增强技术来提升 NER 模型的性能。实验结果显示，这些方法显著提高了 NER 在 CS 数据上的准确性。此外，论文提出了几种 intra-word language identification 方法，用于识别混合文本的语言类型和是否为命名实体。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "PhD thesis",
      "pdf_url": "http://arxiv.org/pdf/2410.13318v1",
      "published_date": "2024-10-17 08:20:29 UTC",
      "updated_date": "2024-10-17 08:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:02:35.099793"
    },
    {
      "arxiv_id": "2410.13314v1",
      "title": "Precipitation Nowcasting Using Diffusion Transformer with Causal Attention",
      "title_zh": "翻译失败",
      "authors": [
        "ChaoRong Li",
        "XuDong Ling",
        "YiLan Xue",
        "Wenjie Luo",
        "LiHong Zhu",
        "FengQing Qin",
        "Yaodong Zhou",
        "Yuanyuan Huang"
      ],
      "abstract": "Short-term precipitation forecasting remains challenging due to the\ndifficulty in capturing long-term spatiotemporal dependencies. Current deep\nlearning methods fall short in establishing effective dependencies between\nconditions and forecast results, while also lacking interpretability. To\naddress this issue, we propose a Precipitation Nowcasting Using Diffusion\nTransformer with Causal Attention model. Our model leverages Transformer and\ncombines causal attention mechanisms to establish spatiotemporal queries\nbetween conditional information (causes) and forecast results (results). This\ndesign enables the model to effectively capture long-term dependencies,\nallowing forecast results to maintain strong causal relationships with input\nconditions over a wide range of time and space. We explore four variants of\nspatiotemporal information interactions for DTCA, demonstrating that global\nspatiotemporal labeling interactions yield the best performance. In addition,\nwe introduce a Channel-To-Batch shift operation to further enhance the model's\nability to represent complex rainfall dynamics. We conducted experiments on two\ndatasets. Compared to state-of-the-art U-Net-based methods, our approach\nimproved the CSI (Critical Success Index) for predicting heavy precipitation by\napproximately 15% and 8% respectively, achieving state-of-the-art performance.",
      "tldr_zh": "该研究针对短时降水预报中捕捉长期时空依赖性的挑战，提出了一种基于Diffusion Transformer with Causal Attention (DTCA) 模型。该模型利用Transformer结合因果注意力机制，建立条件信息（causes）和预报结果（results）之间的时空查询，从而有效捕捉长期依赖并增强可解释性。此外，通过探索四种时空信息交互变体和引入Channel-To-Batch shift操作，DTCA显著提高了模型对复杂降雨动态的表示能力。在两个数据集上的实验中，与最先进的U-Net方法相比，该模型将重度降水预测的CSI (Critical Success Index) 分别提高了约15%和8%，达到了最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13314v1",
      "published_date": "2024-10-17 08:10:41 UTC",
      "updated_date": "2024-10-17 08:10:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:02:46.570782"
    },
    {
      "arxiv_id": "2410.13310v1",
      "title": "Active inference and deep generative modeling for cognitive ultrasound",
      "title_zh": "翻译失败",
      "authors": [
        "Ruud JG van Sloun"
      ],
      "abstract": "Ultrasound (US) has the unique potential to offer access to medical imaging\nto anyone, everywhere. Devices have become ultra-portable and cost-effective,\nakin to the stethoscope. Nevertheless US image quality and diagnostic efficacy\nare still highly operator- and patient-dependent. In difficult-to-image\npatients, image quality is often insufficient for reliable diagnosis. In this\npaper, we put forth that US imaging systems can be recast as\ninformation-seeking agents that engage in reciprocal interactions with their\nanatomical environment. Such agents autonomously adapt their transmit-receive\nsequences to fully personalize imaging and actively maximize information gain\nin-situ. To that end, we will show that the sequence of pulse-echo experiments\nthat a US system performs can be interpreted as a perception-action loop: the\naction is the data acquisition, probing tissue with acoustic waves and\nrecording reflections at the detection array, and perception is the inference\nof the anatomical and or functional state, potentially including associated\ndiagnostic quantities. We then equip systems with a mechanism to actively\nreduce uncertainty and maximize diagnostic value across a sequence of\nexperiments, treating action and perception jointly using Bayesian inference\ngiven generative models of the environment and action-conditional pulse-echo\nobservations. Since the representation capacity of the generative models\ndictates both the quality of inferred anatomical states and the effectiveness\nof inferred sequences of future imaging actions, we will be greatly leveraging\nthe enormous advances in deep generative modelling that are currently\ndisrupting many fields and society at large. Finally, we show some examples of\ncognitive, closed-loop, US systems that perform active beamsteering and\nadaptive scanline selection, based on deep generative models that track\nanatomical belief states.",
      "tldr_zh": "该论文提出将超声（US）成像系统重新定义为信息寻求代理（information-seeking agents），通过主动推理（active inference）和深度生成建模（deep generative modeling）来解决图像质量依赖操作者和患者的问题。系统通过感知-行动循环自主适应发射-接收序列，利用Bayesian推理和生成模型联合处理数据采集与解剖状态推断，从而最大化信息获取和诊断价值。实验展示了基于深度生成模型的认知闭环US系统，例如主动波束转向和自适应扫描线选择，能够显著提升图像质量和个性化成像效果。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13310v1",
      "published_date": "2024-10-17 08:09:14 UTC",
      "updated_date": "2024-10-17 08:09:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:03:08.569192"
    },
    {
      "arxiv_id": "2410.13303v1",
      "title": "Hiformer: Hybrid Frequency Feature Enhancement Inverted Transformer for Long-Term Wind Power Prediction",
      "title_zh": "Hiformer：混合频率特征增强倒置 Transformer 用于长期风力发电预测",
      "authors": [
        "Chongyang Wan",
        "Shunbo Lei",
        "Yuan Luo"
      ],
      "abstract": "The increasing severity of climate change necessitates an urgent transition\nto renewable energy sources, making the large-scale adoption of wind energy\ncrucial for mitigating environmental impact. However, the inherent uncertainty\nof wind power poses challenges for grid stability, underscoring the need for\naccurate wind energy prediction models to enable effective power system\nplanning and operation. While many existing studies on wind power prediction\nfocus on short-term forecasting, they often overlook the importance of\nlong-term predictions. Long-term wind power forecasting is essential for\neffective power grid dispatch and market transactions, as it requires careful\nconsideration of weather features such as wind speed and direction, which\ndirectly influence power output. Consequently, methods designed for short-term\npredictions may lead to inaccurate results and high computational costs in\nlong-term settings. To adress these limitations, we propose a novel approach\ncalled Hybrid Frequency Feature Enhancement Inverted Transformer (Hiformer).\nHiformer introduces a unique structure that integrates signal decomposition\ntechnology with weather feature extraction technique to enhance the modeling of\ncorrelations between meteorological conditions and wind power generation.\nAdditionally, Hiformer employs an encoder-only architecture, which reduces the\ncomputational complexity associated with long-term wind power forecasting.\nCompared to the state-of-the-art methods, Hiformer: (i) can improve the\nprediction accuracy by up to 52.5\\%; and (ii) can reduce computational time by\nup to 68.5\\%.",
      "tldr_zh": "本研究针对气候变化背景下风能的规模化应用，强调了长期风力预测在电网调度和市场交易中的重要性，因为现有短期预测方法往往导致长期准确率低下和计算成本高。论文提出了一种新型模型 Hiformer，即 Hybrid Frequency Feature Enhancement Inverted Transformer，通过整合信号分解技术和天气特征提取技术，增强气象条件（如风速和方向）与风力发电的相关性建模，并采用仅编码器架构以降低计算复杂性。与最先进方法相比，Hiformer 能将预测准确率提高高达 52.5%，并将计算时间减少高达 68.5%，为高效的长期风力预测提供了可靠解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13303v1",
      "published_date": "2024-10-17 08:00:36 UTC",
      "updated_date": "2024-10-17 08:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:03:10.981165"
    },
    {
      "arxiv_id": "2410.19809v1",
      "title": "ScreenWriter: Automatic Screenplay Generation and Movie Summarisation",
      "title_zh": "ScreenWriter：自动剧本生成和电影总结",
      "authors": [
        "Louis Mahon",
        "Mirella Lapata"
      ],
      "abstract": "The proliferation of creative video content has driven demand for textual\ndescriptions or summaries that allow users to recall key plot points or get an\noverview without watching. The volume of movie content and speed of turnover\nmotivates automatic summarisation, which is nevertheless challenging, requiring\nidentifying character intentions and very long-range temporal dependencies. The\nfew existing methods attempting this task rely heavily on textual screenplays\nas input, greatly limiting their applicability. In this work, we propose the\ntask of automatic screenplay generation, and a method, ScreenWriter, that\noperates only on video and produces output which includes dialogue, speaker\nnames, scene breaks, and visual descriptions. ScreenWriter introduces a novel\nalgorithm to segment the video into scenes based on the sequence of visual\nvectors, and a novel method for the challenging problem of determining\ncharacter names, based on a database of actors' faces. We further demonstrate\nhow these automatic screenplays can be used to generate plot synopses with a\nhierarchical summarisation method based on scene breaks. We test the quality of\nthe final summaries on the recent MovieSum dataset, which we augment with\nvideos, and show that they are superior to a number of comparison models which\nassume access to goldstandard screenplays.",
      "tldr_zh": "该论文提出了ScreenWriter，一种仅基于视频输入的自动剧本生成方法，旨在解决电影总结的挑战，包括识别人物意图和处理长时序依赖，而无需依赖文本剧本。ScreenWriter引入了一个基于视觉向量序列的算法来分割视频场景，以及一个利用演员脸部数据库的方法来确定角色姓名，从而生成包含对话、说话者姓名、场景切换和视觉描述的完整剧本。该方法进一步通过基于场景切换的层次化总结技术生成情节概要，并在增强后的MovieSum数据集上实验表明，其生成的总结质量优于那些依赖金标准剧本的对比模型。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19809v1",
      "published_date": "2024-10-17 07:59:54 UTC",
      "updated_date": "2024-10-17 07:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:03:22.196954"
    },
    {
      "arxiv_id": "2410.13301v1",
      "title": "Automating IETF Insights generation with AI",
      "title_zh": "翻译失败",
      "authors": [
        "Jaime Jiménez"
      ],
      "abstract": "This paper presents the IETF Insights project, an automated system that\nstreamlines the generation of comprehensive reports on the activities of the\nInternet Engineering Task Force (IETF) Working Groups. The system collects,\nconsolidates, and analyzes data from various IETF sources, including meeting\nminutes, participant lists, drafts and agendas. The core components of the\nsystem include data preprocessing code and a report generation module that\nproduces high-quality documents in LaTeX or Markdown. By integrating large\nLanguage Models (LLMs) for summaries based on the data as ground truth, the\nIETF Insights project enhances the accessibility and utility of IETF records,\nproviding a valuable overview of the IETF's activities and contributions to the\ncommunity.",
      "tldr_zh": "这篇论文介绍了 IETF Insights 项目，这是一个利用 AI 自动生成互联网工程任务组 (IETF) 工作组活动报告的系统。该系统通过收集并分析 IETF 的数据来源（如会议纪要、参与者列表、草案和议程），结合数据预处理代码和报告生成模块，输出高质量的 LaTeX 或 Markdown 文档，并整合大型语言模型 (LLMs) 来基于数据生成准确摘要。最终，该项目提升了 IETF 记录的可访问性和实用性，为社区提供有价值的活动概述。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "5 pages plus Appendix",
      "pdf_url": "http://arxiv.org/pdf/2410.13301v1",
      "published_date": "2024-10-17 07:59:05 UTC",
      "updated_date": "2024-10-17 07:59:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:03:44.090740"
    },
    {
      "arxiv_id": "2410.13299v2",
      "title": "LLM-Rank: A Graph Theoretical Approach to Pruning Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "David Hoffmann",
        "Kailash Budhathoki",
        "Matthaeus Kleindessner"
      ],
      "abstract": "The evolving capabilities of large language models are accompanied by growing\nsizes and deployment costs, necessitating effective inference optimisation\ntechniques. We propose a novel pruning method utilising centrality measures\nfrom graph theory, reducing both the computational requirements and the memory\nfootprint of these models. Specifically, we devise a method for creating a\nweighted directed acyclical graph representation of multilayer perceptrons to\nwhich we apply a modified version of the weighted PageRank centrality measure\nto compute node importance scores. In combination with uniform pruning this\nleads to structured sparsity. We call this pruning method MLPRank. Furthermore\nwe introduce an extension to decoder-only transformer models and call it\nLLMRank. For both variants we demonstrate a strong performance. With MLPRank on\naverage leading to 6.09 % higher accuracy retention than three popular\nbaselines and 13.42 % with LLMRank compared to two popular baselines. Code is\navailable at https://github.com/amazon-science/llm-rank-pruning.",
      "tldr_zh": "本文提出了一种基于图论的修剪方法 LLM-Rank，用于优化大型语言模型（LLMs），以减少其计算需求和内存占用。该方法通过为多层感知器（MLPs）构建加权有向无环图，并应用修改后的加权 PageRank 中心性度量来计算节点重要性分数，结合均匀修剪实现结构化稀疏性。实验结果显示，MLPRank 比三个流行基线平均提高 6.09% 的准确率保留，而 LLM-Rank 比两个基线提高 13.42%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13299v2",
      "published_date": "2024-10-17 07:55:47 UTC",
      "updated_date": "2024-11-29 11:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:03:46.739194"
    },
    {
      "arxiv_id": "2410.13298v1",
      "title": "Advancing Large Language Model Attribution through Self-Improving",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Huang",
        "Xiaocheng Feng",
        "Weitao Ma",
        "Liang Zhao",
        "Yuchun Fan",
        "Weihong Zhong",
        "Dongliang Xu",
        "Qing Yang",
        "Hongtao Liu",
        "Bing Qin"
      ],
      "abstract": "Teaching large language models (LLMs) to generate text with citations to\nevidence sources can mitigate hallucinations and enhance verifiability in\ninformation-seeking systems. However, improving this capability requires\nhigh-quality attribution data, which is costly and labor-intensive. Inspired by\nrecent advances in self-improvement that enhance LLMs without manual\nannotation, we present START, a Self-Taught AttRibuTion framework for\niteratively improving the attribution capability of LLMs. First, to prevent\nmodels from stagnating due to initially insufficient supervision signals, START\nleverages the model to self-construct synthetic training data for warming up.\nTo further self-improve the model's attribution ability, START iteratively\nutilizes fine-grained preference supervision signals constructed from its\nsampled responses to encourage robust, comprehensive, and attributable\ngeneration. Experiments on three open-domain question-answering datasets,\ncovering long-form QA and multi-step reasoning, demonstrate significant\nperformance gains of 25.13% on average without relying on human annotations and\nmore advanced models. Further analysis reveals that START excels in aggregating\ninformation across multiple sources.",
      "tldr_zh": "这篇论文提出了一种自教学框架 START，用于提升大型语言模型 (LLMs) 的归因能力，从而减少幻觉并提高信息查询系统的可验证性，而无需昂贵的手动注释。START 通过模型自构建合成训练数据进行初始热身，然后迭代利用从样本响应中提取的细粒度偏好监督信号，来促进模型生成更鲁棒、全面和可归因的文本。在三个开放域问答数据集上的实验显示，性能平均提升 25.13%，特别是在聚合多来源信息方面表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP 2024 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2410.13298v1",
      "published_date": "2024-10-17 07:55:33 UTC",
      "updated_date": "2024-10-17 07:55:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:03:58.216019"
    },
    {
      "arxiv_id": "2410.13296v1",
      "title": "Fairness-Enhancing Ensemble Classification in Water Distribution Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Janine Strotherm",
        "Barbara Hammer"
      ],
      "abstract": "As relevant examples such as the future criminal detection software [1] show,\nfairness of AI-based and social domain affecting decision support tools\nconstitutes an important area of research. In this contribution, we investigate\nthe applications of AI to socioeconomically relevant infrastructures such as\nthose of water distribution networks (WDNs), where fairness issues have yet to\ngain a foothold. To establish the notion of fairness in this domain, we propose\nan appropriate definition of protected groups and group fairness in WDNs as an\nextension of existing definitions. We demonstrate that typical methods for the\ndetection of leakages in WDNs are unfair in this sense. Further, we thus\npropose a remedy to increase the fairness which can be applied even to\nnon-differentiable ensemble classification methods as used in this context.",
      "tldr_zh": "这篇论文探讨了 AI 在水分配网络 (WDNs) 中的公平性问题，提出了一种扩展现有定义的保护群体和群体公平概念，以适应这一领域。研究发现，传统的 WDNs 泄漏检测方法在这种公平性框架下存在不公平现象。作者随后提出了一种增强公平性的方法，能够应用于非微分集成分类模型，从而改善决策支持工具的社会影响。该方法为 AI 在社会基础设施中的公平应用提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13296v1",
      "published_date": "2024-10-17 07:53:02 UTC",
      "updated_date": "2024-10-17 07:53:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:04:10.091846"
    },
    {
      "arxiv_id": "2410.13295v2",
      "title": "PiLocNet: Physics-informed neural network on 3D localization with rotating point spread function",
      "title_zh": "翻译失败",
      "authors": [
        "Mingda Lu",
        "Zitian Ao",
        "Chao Wang",
        "Sudhakar Prasad",
        "Raymond H. Chan"
      ],
      "abstract": "For the 3D localization problem using point spread function (PSF)\nengineering, we propose a novel enhancement of our previously introduced\nlocalization neural network, LocNet. The improved network is a physics-informed\nneural network (PINN) that we call PiLocNet. Previous works on the localization\nproblem may be categorized separately into model-based optimization and neural\nnetwork approaches. Our PiLocNet combines the unique strengths of both\napproaches by incorporating forward-model-based information into the network\nvia a data-fitting loss term that constrains the neural network to yield\nresults that are physically sensible. We additionally incorporate certain\nregularization terms from the variational method, which further improves the\nrobustness of the network in the presence of image noise, as we show for the\nPoisson and Gaussian noise models. This framework accords interpretability to\nthe neural network, and the results we obtain show its superiority. Although\nthe paper focuses on the use of single-lobe rotating PSF to encode the full 3D\nsource location, we expect the method to be widely applicable to other PSFs and\nimaging problems that are constrained by known forward processes.",
      "tldr_zh": "本研究提出了一种名为 PiLocNet 的 physics-informed neural network (PINN)，用于基于 rotating point spread function (PSF) 的 3D localization 问题，作为对先前 LocNet 网络的改进。PiLocNet 通过整合 forward-model-based information 的 data-fitting loss term 和 variational method 的 regularization terms，结合模型优化和神经网络优势，确保输出结果物理上合理，并提升了在 Poisson 和 Gaussian noise 环境下的鲁棒性。实验结果显示，PiLocNet 表现出优越的准确性和可解释性，尽管焦点在于 single-lobe rotating PSF 的 3D 源定位，但该方法可广泛应用于其他 PSF 和受 forward processes 约束的成像问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "physics.optics"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13295v2",
      "published_date": "2024-10-17 07:49:23 UTC",
      "updated_date": "2025-02-09 09:48:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:04:26.113726"
    },
    {
      "arxiv_id": "2410.13293v2",
      "title": "SBI-RAG: Enhancing Math Word Problem Solving for Students through Schema-Based Instruction and Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Prakhar Dixit",
        "Tim Oates"
      ],
      "abstract": "Many students struggle with math word problems (MWPs), often finding it\ndifficult to identify key information and select the appropriate mathematical\noperations. Schema-based instruction (SBI) is an evidence-based strategy that\nhelps students categorize problems based on their structure, improving\nproblem-solving accuracy. Building on this, we propose a Schema-Based\nInstruction Retrieval-Augmented Generation (SBI-RAG) framework that\nincorporates a large language model (LLM). Our approach emphasizes step-by-step\nreasoning by leveraging schemas to guide solution generation. We evaluate its\nperformance on the GSM8K dataset, comparing it with GPT-4 and GPT-3.5 Turbo,\nand introduce a \"reasoning score\" metric to assess solution quality. Our\nfindings suggest that SBI-RAG enhances reasoning clarity and facilitates a more\nstructured problem-solving process potentially providing educational benefits\nfor students.",
      "tldr_zh": "该研究针对学生在数学文字问题（MWPs）上的难题，提出SBI-RAG框架，将Schema-Based Instruction (SBI)和Retrieval-Augmented Generation (RAG)相结合，利用Large Language Model (LLM)来指导逐步推理和解决方案生成。SBI-RAG通过帮助学生基于问题结构分类和识别关键信息，提升了问题解决的准确性和清晰度。在GSM8K数据集上的实验中，该框架与GPT-4和GPT-3.5 Turbo相比表现出色，并引入了“reasoning score”指标来评估解决方案质量。总体而言，SBI-RAG促进了更结构化的问题解决过程，可能为学生的数学教育带来显著益处。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the 4th MATH-AI Workshop at NeurIPS'24",
      "pdf_url": "http://arxiv.org/pdf/2410.13293v2",
      "published_date": "2024-10-17 07:46:49 UTC",
      "updated_date": "2024-11-10 08:53:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:04:34.572081"
    },
    {
      "arxiv_id": "2410.14739v1",
      "title": "Toward a Unified Graph-Based Representation of Medical Data for Precision Oncology Medicine",
      "title_zh": "翻译失败",
      "authors": [
        "Davide Belluomo",
        "Tiziana Calamoneri",
        "Giacomo Paesani",
        "Ivano Salvo"
      ],
      "abstract": "We present a new unified graph-based representation of medical data,\ncombining genetic information and medical records of patients with medical\nknowledge via a unique knowledge graph. This approach allows us to infer\nmeaningful information and explanations that would be unavailable by looking at\neach data set separately. The systematic use of different databases, managed\nthroughout the built knowledge graph, gives new insights toward a better\nunderstanding of oncology medicine. Indeed, we reduce some useful medical tasks\nto well-known problems in theoretical computer science for which efficient\nalgorithms exist.",
      "tldr_zh": "该论文提出了一种统一的图-based 表示方法，用于精确肿瘤医学（Precision Oncology Medicine），将患者的遗传信息、医疗记录和医疗知识整合到一个知识图（knowledge graph）中，从而实现对数据的综合分析和解释。相比单独处理数据集，这种方法能推断出新的见解，帮助更好地理解肿瘤学相关问题。通过系统管理不同数据库，该框架还将某些医疗任务简化为理论计算机科学中的经典问题，利用现有高效算法进行优化。",
      "categories": [
        "cs.AI",
        "68T30",
        "E.1; J.3"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 1 figure, 14 tables, CIBB 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2410.14739v1",
      "published_date": "2024-10-17 07:43:48 UTC",
      "updated_date": "2024-10-17 07:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:04:45.918722"
    },
    {
      "arxiv_id": "2410.13284v2",
      "title": "Learning to Route LLMs with Confidence Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Neng Chuang",
        "Helen Zhou",
        "Prathusha Kameswara Sarma",
        "Parikshit Gopalan",
        "John Boccio",
        "Sara Bolouki",
        "Xia Hu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive performance on\nseveral tasks and are increasingly deployed in real-world applications.\nHowever, especially in high-stakes settings, it becomes vital to know when the\noutput of an LLM may be unreliable. Depending on whether an answer is\ntrustworthy, a system can then choose to route the question to another expert,\nor otherwise fall back on a safe default behavior. In this work, we study the\nextent to which LLMs can reliably indicate confidence in their answers, and how\nthis notion of confidence can translate into downstream accuracy gains. We\npropose Self-REF, a lightweight training strategy to teach LLMs to express\nconfidence in whether their answers are correct in a reliable manner. Self-REF\nintroduces confidence tokens into the LLM, from which a confidence score can be\nextracted. Compared to conventional approaches such as verbalizing confidence\nand examining token probabilities, we demonstrate empirically that confidence\ntokens show significant improvements in downstream routing and rejection\nlearning tasks.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在高风险应用中输出可靠性的问题，提出通过Self-REF训练策略教导LLMs以可靠方式表达答案信心。Self-REF引入confidence tokens，从中提取信心分数，用于路由问题或拒绝不可靠响应。与传统方法如口头表达信心或检查token概率相比，该方法在下游路由和拒绝学习任务中实现了显著的准确性提升。实验结果证明了confidence tokens的有效性，为更可信的LLMs应用奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13284v2",
      "published_date": "2024-10-17 07:28:18 UTC",
      "updated_date": "2025-02-04 21:38:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:04:58.452001"
    },
    {
      "arxiv_id": "2411.00784v2",
      "title": "FIRE: Fact-checking with Iterative Retrieval and Verification",
      "title_zh": "FIRE：通过迭代检索和验证进行事实核查",
      "authors": [
        "Zhuohan Xie",
        "Rui Xing",
        "Yuxia Wang",
        "Jiahui Geng",
        "Hasan Iqbal",
        "Dhruv Sahnan",
        "Iryna Gurevych",
        "Preslav Nakov"
      ],
      "abstract": "Fact-checking long-form text is challenging, and it is therefore common\npractice to break it down into multiple atomic claims. The typical approach to\nfact-checking these atomic claims involves retrieving a fixed number of pieces\nof evidence, followed by a verification step. However, this method is usually\nnot cost-effective, as it underutilizes the verification model's internal\nknowledge of the claim and fails to replicate the iterative reasoning process\nin human search strategies. To address these limitations, we propose FIRE, a\nnovel agent-based framework that integrates evidence retrieval and claim\nverification in an iterative manner. Specifically, FIRE employs a unified\nmechanism to decide whether to provide a final answer or generate a subsequent\nsearch query, based on its confidence in the current judgment. We compare FIRE\nwith other strong fact-checking frameworks and find that it achieves slightly\nbetter performance while reducing large language model (LLM) costs by an\naverage of 7.6 times and search costs by 16.5 times. These results indicate\nthat FIRE holds promise for application in large-scale fact-checking\noperations. Our code is available at https://github.com/mbzuai-nlp/fire.git.",
      "tldr_zh": "这篇论文提出了 FIRE 框架，用于事实-checking（fact-checking），通过迭代检索和验证来处理长文本分解的原子声明，解决了传统方法效率低下和未充分利用模型内部知识的问题。FIRE 采用基于代理的机制，将证据检索与声明验证整合成迭代过程，根据当前判断的信心水平决定是否给出最终答案或生成新搜索查询。与其他框架相比，FIRE 略微提升了性能，同时将大型语言模型（LLM）成本降低了 7.6 倍，搜索成本降低了 16.5 倍。这些结果表明，FIRE 在大规模事实-checking 操作中具有显著的应用潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "4 figures, 8 tables, accepted to Findings of NAACL",
      "pdf_url": "http://arxiv.org/pdf/2411.00784v2",
      "published_date": "2024-10-17 06:44:18 UTC",
      "updated_date": "2025-02-12 06:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:05:10.261994"
    },
    {
      "arxiv_id": "2410.13268v1",
      "title": "Roadmap towards Superhuman Speech Understanding using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Bu",
        "Yuhao Zhang",
        "Xidong Wang",
        "Benyou Wang",
        "Qun Liu",
        "Haizhou Li"
      ],
      "abstract": "The success of large language models (LLMs) has prompted efforts to integrate\nspeech and audio data, aiming to create general foundation models capable of\nprocessing both textual and non-textual inputs. Recent advances, such as\nGPT-4o, highlight the potential for end-to-end speech LLMs, which preserves\nnon-semantic information and world knowledge for deeper speech understanding.\nTo guide the development of speech LLMs, we propose a five-level roadmap,\nranging from basic automatic speech recognition (ASR) to advanced superhuman\nmodels capable of integrating non-semantic information with abstract acoustic\nknowledge for complex tasks. Moreover, we design a benchmark, SAGI Bechmark,\nthat standardizes critical aspects across various tasks in these five levels,\nuncovering challenges in using abstract acoustic knowledge and completeness of\ncapability. Our findings reveal gaps in handling paralinguistic cues and\nabstract acoustic knowledge, and we offer future directions. This paper\noutlines a roadmap for advancing speech LLMs, introduces a benchmark for\nevaluation, and provides key insights into their current limitations and\npotential.",
      "tldr_zh": "该论文探讨了利用大型语言模型（LLMs）实现超人类语音理解的路线图，强调整合语音和音频数据以创建能处理文本及非文本输入的通用基础模型，如GPT-4o所示的端到端语音LLMs。作者提出一个五级路线图，从基本自动语音识别（ASR）到高级模型，能够整合非语义信息和抽象声学知识处理复杂任务。论文设计了SAGI Benchmark来标准化这些级别的关键任务，揭示当前模型在处理paralinguistic cues和抽象声学知识方面的不足，并提供未来发展方向，以推动语音LLMs的进步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13268v1",
      "published_date": "2024-10-17 06:44:06 UTC",
      "updated_date": "2024-10-17 06:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:05:23.614930"
    },
    {
      "arxiv_id": "2410.13264v1",
      "title": "The Latent Road to Atoms: Backmapping Coarse-grained Protein Structures with Latent Diffusion",
      "title_zh": "通往原子的潜在之路：利用潜在扩散反映射粗粒化蛋白质结构",
      "authors": [
        "Xu Han",
        "Yuancheng Sun",
        "Kai Chen",
        "Kang Liu",
        "Qiwei Ye"
      ],
      "abstract": "Coarse-grained(CG) molecular dynamics simulations offer computational\nefficiency for exploring protein conformational ensembles and thermodynamic\nproperties. Though coarse representations enable large-scale simulations across\nextended temporal and spatial ranges, the sacrifice of atomic-level details\nlimits their utility in tasks such as ligand docking and protein-protein\ninteraction prediction. Backmapping, the process of reconstructing all-atom\nstructures from coarse-grained representations, is crucial for recovering these\nfine details. While recent machine learning methods have made strides in\nprotein structure generation, challenges persist in reconstructing diverse\natomistic conformations that maintain geometric accuracy and chemical validity.\nIn this paper, we present Latent Diffusion Backmapping (LDB), a novel approach\nleveraging denoising diffusion within latent space to address these challenges.\nBy combining discrete latent encoding with diffusion, LDB bypasses the need for\nequivariant and internal coordinate manipulation, significantly simplifying the\ntraining and sampling processes as well as facilitating better and wider\nexploration in configuration space. We evaluate LDB's state-of-the-art\nperformance on three distinct protein datasets, demonstrating its ability to\nefficiently reconstruct structures with high structural accuracy and chemical\nvalidity. Moreover, LDB shows exceptional versatility in capturing diverse\nprotein ensembles, highlighting its capability to explore intricate\nconformational spaces. Our results position LDB as a powerful and scalable\napproach for backmapping, effectively bridging the gap between CG simulations\nand atomic-level analyses in computational biology.",
      "tldr_zh": "本研究针对粗粒化（Coarse-grained, CG）分子动力学模拟在探索蛋白质构象时牺牲原子级细节的问题，提出了一种新型方法Latent Diffusion Backmapping (LDB)。LDB通过在潜在空间中运用去噪扩散模型结合离散潜在编码，简化了训练和采样过程，避免了等变和内部坐标操作，从而高效重建多样且精确的原子结构。在三个蛋白质数据集上的评估显示，LDB实现了高结构准确性和化学有效性，并能探索复杂的构象空间，最终桥接了CG模拟与原子级分析的差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper under review",
      "pdf_url": "http://arxiv.org/pdf/2410.13264v1",
      "published_date": "2024-10-17 06:38:07 UTC",
      "updated_date": "2024-10-17 06:38:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:05:34.625352"
    },
    {
      "arxiv_id": "2410.13263v1",
      "title": "A Simplifying and Learnable Graph Convolutional Attention Network for Unsupervised Knowledge Graphs Alignment",
      "title_zh": "一种简化且可学习的图卷积注意力网络，用于无监督知识图谱对齐",
      "authors": [
        "Weishan Cai",
        "Wenjun Ma",
        "Yuncheng Jiang"
      ],
      "abstract": "The success of current Entity Alignment (EA) task depends largely on the\nsupervision information provided by labeled data. Considering the cost of\nlabeled data, most supervised methods are difficult to apply in practical\nscenarios. Therefore, more and more works based on contrastive learning, active\nlearning or other deep learning techniques have been developed, to solve the\nperformance bottleneck caused by the lack of labeled data. However, the\nexisting unsupervised EA methods still have some limitations, either their\nmodeling complexity is high or they cannot balance the effectiveness and\npracticality of alignment. To overcome these issues, we propose a Simplifying\nand Learnable graph convolutional attention network for Unsupervised Knowledge\nGraphs alignment method (SLU). Specifically, we first introduce LCAT, a new and\nsimple framework as the backbone network to model the graph structure of two\nKGs. Then we design a reconstruction method of relation structure based on\npotential matching relations for efficiently filtering invalid neighborhood\ninformation of aligned entities, to improve the usability and scalability of\nSLU. Impressively, a similarity function based on consistency is proposed to\nbetter measure the similarity of candidate entity pairs. Finally, we conduct\nextensive experiments on three datasets of different sizes (15K and 100K) and\ndifferent types (cross-lingual and monolingual) to verify the superiority of\nSLU. Experimental results show that SLU significantly improves alignment\naccuracy, outperforming 25 supervised or unsupervised methods, and improving\n6.4% in Hits@1 over the best baseline in the best case.",
      "tldr_zh": "本研究针对无监督知识图谱对齐（Unsupervised Knowledge Graphs Alignment）问题，提出了一种简化和可学习图卷积注意力网络SLU方法，以克服现有方法的模型复杂性和有效性平衡问题。SLU的核心包括LCAT框架用于建模两个知识图谱（KGs）的图结构、基于潜在匹配关系的关联结构重建方法来过滤无效邻居信息，以及一种基于一致性的相似度函数来精确衡量候选实体对（Entity Alignment, EA）的相似度。通过在三个不同大小（15K和100K）和类型（跨语言和单语言）的数据集上进行实验，SLU在Hits@1指标上比最佳基线提高了6.4%，整体优于25个监督或无监督方法，显著提升了对齐准确率。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13263v1",
      "published_date": "2024-10-17 06:37:46 UTC",
      "updated_date": "2024-10-17 06:37:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:05:46.858785"
    },
    {
      "arxiv_id": "2410.13257v1",
      "title": "scFusionTTT: Single-cell transcriptomics and proteomics fusion with Test-Time Training layers",
      "title_zh": "翻译失败",
      "authors": [
        "Dian Meng",
        "Bohao Xing",
        "Xinlei Huang",
        "Yanran Liu",
        "Yijun Zhou",
        "Yongjun xiao",
        "Zitong Yu",
        "Xubin Zheng"
      ],
      "abstract": "Single-cell multi-omics (scMulti-omics) refers to the paired multimodal data,\nsuch as Cellular Indexing of Transcriptomes and Epitopes by Sequencing\n(CITE-seq), where the regulation of each cell was measured from different\nmodalities, i.e. genes and proteins. scMulti-omics can reveal heterogeneity\ninside tumors and understand the distinct genetic properties of diverse cell\ntypes, which is crucial to targeted therapy. Currently, deep learning methods\nbased on attention structures in the bioinformatics area face two challenges.\nThe first challenge is the vast number of genes in a single cell. Traditional\nattention-based modules struggled to effectively leverage all gene information\ndue to their limited capacity for long-context learning and high-complexity\ncomputing. The second challenge is that genes in the human genome are ordered\nand influence each other's expression. Most of the methods ignored this\nsequential information. The recently introduced Test-Time Training (TTT) layer\nis a novel sequence modeling approach, particularly suitable for handling long\ncontexts like genomics data because TTT layer is a linear complexity sequence\nmodeling structure and is better suited to data with sequential relationships.\nIn this paper, we propose scFusionTTT, a novel method for Single-Cell\nmultimodal omics Fusion with TTT-based masked autoencoder. Of note, we combine\nthe order information of genes and proteins in the human genome with the TTT\nlayer, fuse multimodal omics, and enhance unimodal omics analysis. Finally, the\nmodel employs a three-stage training strategy, which yielded the best\nperformance across most metrics in four multimodal omics datasets and four\nunimodal omics datasets, demonstrating the superior performance of our model.\nThe dataset and code will be available on\nhttps://github.com/DM0815/scFusionTTT.",
      "tldr_zh": "这篇论文提出了 scFusionTTT，一种基于 Test-Time Training (TTT) 层的单细胞多组学融合方法，旨在处理如 CITE-seq 的基因和蛋白质数据，以揭示肿瘤异质性和细胞类型遗传特性。scFusionTTT 通过 TTT 层处理基因的顺序信息和长上下文挑战，利用 masked autoencoder 融合多模态数据，并增强单模态分析。模型采用三阶段训练策略，在四个多模态和四个单模态数据集上表现出最佳性能，优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13257v1",
      "published_date": "2024-10-17 06:29:29 UTC",
      "updated_date": "2024-10-17 06:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:05:59.330954"
    },
    {
      "arxiv_id": "2410.13255v1",
      "title": "Automatic Translation Alignment Pipeline for Multilingual Digital Editions of Literary Works",
      "title_zh": "自动翻译对齐管道，用于多语言文学作品数字版本",
      "authors": [
        "Maria Levchenko"
      ],
      "abstract": "This paper investigates the application of translation alignment algorithms\nin the creation of a Multilingual Digital Edition (MDE) of Alessandro Manzoni's\nItalian novel \"I promessi sposi\" (\"The Betrothed\"), with translations in eight\nlanguages (English, Spanish, French, German, Dutch, Polish, Russian and\nChinese) from the 19th and 20th centuries. We identify key requirements for the\nMDE to improve both the reader experience and support for translation studies.\nOur research highlights the limitations of current state-of-the-art algorithms\nwhen applied to the translation of literary texts and outlines an automated\npipeline for MDE creation. This pipeline transforms raw texts into web-based,\nside-by-side representations of original and translated texts with different\nrendering options. In addition, we propose new metrics for evaluating the\nalignment of literary translations and suggest visualization techniques for\nfuture analysis.",
      "tldr_zh": "这篇论文探讨了翻译对齐算法在创建 Alessandro Manzoni 小说 \"I promessi sposi\" (\"The Betrothed\") 的多语言数字版 (MDE) 中的应用，该版涵盖八种语言（包括英语、西班牙语、法语等）的19和20世纪翻译。研究者识别了MDE的关键要求，以提升读者体验和翻译研究支持，并开发了一个自动化管道，将原始文本转换为基于网络的并排表示形式，支持多种渲染选项。论文突出了现有算法在文学文本对齐的局限性，提出了新的评估指标和可视化技术，以改进未来分析和翻译质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68U15",
        "J.5; I.7.4"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, Computational Humanities Research Conference, December 4-6,\n  2024, Aarhus, Denmark",
      "pdf_url": "http://arxiv.org/pdf/2410.13255v1",
      "published_date": "2024-10-17 06:21:38 UTC",
      "updated_date": "2024-10-17 06:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:06:11.163160"
    },
    {
      "arxiv_id": "2410.13250v1",
      "title": "Perceptions of Discriminatory Decisions of Artificial Intelligence: Unpacking the Role of Individual Characteristics",
      "title_zh": "翻译失败",
      "authors": [
        "Soojong Kim"
      ],
      "abstract": "This study investigates how personal differences (digital self-efficacy,\ntechnical knowledge, belief in equality, political ideology) and demographic\nfactors (age, education, and income) are associated with perceptions of\nartificial intelligence (AI) outcomes exhibiting gender and racial bias and\nwith general attitudes towards AI. Analyses of a large-scale experiment dataset\n(N = 1,206) indicate that digital self-efficacy and technical knowledge are\npositively associated with attitudes toward AI, while liberal ideologies are\nnegatively associated with outcome trust, higher negative emotion, and greater\nskepticism. Furthermore, age and income are closely connected to cognitive gaps\nin understanding discriminatory AI outcomes. These findings highlight the\nimportance of promoting digital literacy skills and enhancing digital\nself-efficacy to maintain trust in AI and beliefs in AI usefulness and safety.\nThe findings also suggest that the disparities in understanding problematic AI\noutcomes may be aligned with economic inequalities and generational gaps in\nsociety. Overall, this study sheds light on the socio-technological system in\nwhich complex interactions occur between social hierarchies, divisions, and\nmachines that reflect and exacerbate the disparities.",
      "tldr_zh": "这项研究调查了个人特征（如digital self-efficacy、技术知识、对平等的信念和政治意识形态）以及人口统计因素（如年龄、教育和收入）如何影响人们对AI歧视性决策的感知，以及对AI的总体态度。基于一个大规模实验数据集（N=1,206）的分析，发现digital self-efficacy和技术知识与对AI的态度正相关，而自由主义意识形态则与较低的结果信任、更高负面情绪和更大怀疑相关；此外，年龄和收入与理解歧视性AI结果的认知差距密切相关。研究强调，促进数字素养和提升digital self-efficacy有助于维持对AI的信任，并揭示这些差异可能加剧社会经济不平等和代际鸿沟。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13250v1",
      "published_date": "2024-10-17 06:18:26 UTC",
      "updated_date": "2024-10-17 06:18:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:06:23.072930"
    },
    {
      "arxiv_id": "2410.13248v1",
      "title": "Disentangling Likes and Dislikes in Personalized Generative Explainable Recommendation",
      "title_zh": "在个性化生成式可解释推荐中解耦喜欢与不喜欢",
      "authors": [
        "Ryotaro Shimizu",
        "Takashi Wada",
        "Yu Wang",
        "Johannes Kruse",
        "Sean O'Brien",
        "Sai HtaungKham",
        "Linxin Song",
        "Yuya Yoshikawa",
        "Yuki Saito",
        "Fugee Tsung",
        "Masayuki Goto",
        "Julian McAuley"
      ],
      "abstract": "Recent research on explainable recommendation generally frames the task as a\nstandard text generation problem, and evaluates models simply based on the\ntextual similarity between the predicted and ground-truth explanations.\nHowever, this approach fails to consider one crucial aspect of the systems:\nwhether their outputs accurately reflect the users' (post-purchase) sentiments,\ni.e., whether and why they would like and/or dislike the recommended items. To\nshed light on this issue, we introduce new datasets and evaluation methods that\nfocus on the users' sentiments. Specifically, we construct the datasets by\nexplicitly extracting users' positive and negative opinions from their\npost-purchase reviews using an LLM, and propose to evaluate systems based on\nwhether the generated explanations 1) align well with the users' sentiments,\nand 2) accurately identify both positive and negative opinions of users on the\ntarget items. We benchmark several recent models on our datasets and\ndemonstrate that achieving strong performance on existing metrics does not\nensure that the generated explanations align well with the users' sentiments.\nLastly, we find that existing models can provide more sentiment-aware\nexplanations when the users' (predicted) ratings for the target items are\ndirectly fed into the models as input. We will release our code and datasets\nupon acceptance.",
      "tldr_zh": "该论文指出，现有的可解释推荐系统（explainable recommendation）通常将任务视为标准文本生成问题，仅基于预测解释和真实解释的文本相似度进行评估，从而忽略了用户情感（如喜欢或不喜欢推荐物品的原因）。为了解决这一问题，研究者引入新数据集，通过LLM从用户的购买后评论中显式提取积极和消极意见，并提出新的评估方法，检查生成的解释是否与用户情感对齐并准确识别正负意见。实验基准测试了多种最近模型，发现这些模型在现有指标上表现良好，但情感对齐不足；然而，当将用户的预测评分作为输入时，模型能生成更情感感知的解释。该工作将发布代码和数据集，以推动个性化生成解释推荐的改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13248v1",
      "published_date": "2024-10-17 06:15:00 UTC",
      "updated_date": "2024-10-17 06:15:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:06:34.823030"
    },
    {
      "arxiv_id": "2410.13247v2",
      "title": "Collaborative AI in Sentiment Analysis: System Architecture, Data Prediction and Deployment Strategies",
      "title_zh": "情感分析中的协作 AI：系统架构、数据预测和部署策略",
      "authors": [
        "Chaofeng Zhang",
        "Jia Hou",
        "Xueting Tan",
        "Gaolei Li",
        "Caijuan Chen"
      ],
      "abstract": "The advancement of large language model (LLM) based artificial intelligence\ntechnologies has been a game-changer, particularly in sentiment analysis. This\nprogress has enabled a shift from highly specialized research environments to\npractical, widespread applications within the industry. However, integrating\ndiverse AI models for processing complex multimodal data and the associated\nhigh costs of feature extraction presents significant challenges. Motivated by\nthe marketing oriented software development +needs, our study introduces a\ncollaborative AI framework designed to efficiently distribute and resolve tasks\nacross various AI systems to address these issues. Initially, we elucidate the\nkey solutions derived from our development process, highlighting the role of\ngenerative AI models like \\emph{chatgpt}, \\emph{google gemini} in simplifying\nintricate sentiment analysis tasks into manageable, phased objectives.\nFurthermore, we present a detailed case study utilizing our collaborative AI\nsystem in edge and cloud, showcasing its effectiveness in analyzing sentiments\nacross diverse online media channels.",
      "tldr_zh": "该研究探讨了大型语言模型(LLM)在情感分析中的应用，强调从研究环境转向实际产业部署面临的挑战，如整合多模态数据和高成本问题。为此，论文提出一个协作AI框架，用于高效分配和解决任务，利用生成式AI模型如ChatGPT和Google Gemini将复杂情感分析任务分解为阶段性目标。案例研究展示了该框架在边缘和云环境中的实际效果，能够有效分析各种在线媒体的情感，从而为营销导向的软件开发提供可行策略。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13247v2",
      "published_date": "2024-10-17 06:14:34 UTC",
      "updated_date": "2024-10-23 11:09:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:06:45.532623"
    },
    {
      "arxiv_id": "2410.13246v1",
      "title": "Atomic Calibration of LLMs in Long-Form Generations",
      "title_zh": "大型语言模型在长文本生成中的原子校准",
      "authors": [
        "Caiqi Zhang",
        "Ruihan Yang",
        "Zhisong Zhang",
        "Xinting Huang",
        "Sen Yang",
        "Dong Yu",
        "Nigel Collier"
      ],
      "abstract": "Large language models (LLMs) often suffer from hallucinations, posing\nsignificant challenges for real-world applications. Confidence calibration,\nwhich estimates the underlying uncertainty of model predictions, is essential\nto enhance the LLMs' trustworthiness. Existing research on LLM calibration has\nprimarily focused on short-form tasks, providing a single confidence score at\nthe response level (macro calibration). However, this approach is insufficient\nfor long-form generations, where responses often contain more complex\nstatements and may include both accurate and inaccurate information. Therefore,\nwe introduce atomic calibration, a novel approach that evaluates factuality\ncalibration at a fine-grained level by breaking down long responses into atomic\nclaims. We classify confidence elicitation methods into discriminative and\ngenerative types and demonstrate that their combination can enhance\ncalibration. Our extensive experiments on various LLMs and datasets show that\natomic calibration is well-suited for long-form generation and can also improve\nmacro calibration results. Additionally, atomic calibration reveals insightful\npatterns in LLM confidence throughout the generation process.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）在长形式生成中的 hallucination 问题，提出 atomic calibration 方法，以细粒度级别评估模型预测的置信度校准。不同于传统的 macro calibration，该方法将长响应分解成 atomic claims，并结合 discriminative 和 generative 信心提取技术，提升整体校准准确性。实验在多种 LLMs 和数据集上进行，结果表明 atomic calibration 不仅适用于长形式生成，还能改善 macro calibration 效果，并揭示 LLMs 生成过程中信心变化的模式。最终，这为提升 LLMs 的可信度和实际应用提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13246v1",
      "published_date": "2024-10-17 06:09:26 UTC",
      "updated_date": "2024-10-17 06:09:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:06:58.320125"
    },
    {
      "arxiv_id": "2410.19808v1",
      "title": "LocateBench: Evaluating the Locating Ability of Vision Language Models",
      "title_zh": "LocateBench：评估视觉语言模型的定位能力",
      "authors": [
        "Ting-Rui Chiang",
        "Joshua Robinson",
        "Xinyan Velocity Yu",
        "Dani Yogatama"
      ],
      "abstract": "The ability to locate an object in an image according to natural language\ninstructions is crucial for many real-world applications. In this work we\npropose LocateBench, a high-quality benchmark dedicated to evaluating this\nability. We experiment with multiple prompting approaches, and measure the\naccuracy of several large vision language models. We find that even the\naccuracy of the strongest model, GPT-4o, lags behind human accuracy by more\nthan 10%.",
      "tldr_zh": "这篇论文引入了LocateBench，一个高质量基准测试，用于评估视觉语言模型(Vision Language Models)根据自然语言指令定位图像中物体的能力。作者实验了多种提示方法，并测量了几个大型模型的准确性。结果显示，即使是最强的模型GPT-4o，其准确率也比人类低超过10%。这突显了当前模型在定位任务上的局限性，并为未来改进提供了重要参考。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "We release the dataset at\n  https://usc-tamagotchi.github.io/locate-bench/",
      "pdf_url": "http://arxiv.org/pdf/2410.19808v1",
      "published_date": "2024-10-17 05:48:24 UTC",
      "updated_date": "2024-10-17 05:48:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:07:09.275969"
    },
    {
      "arxiv_id": "2410.13237v2",
      "title": "Large Language Models are Easily Confused: A Quantitative Metric, Security Implications and Typological Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyi Chen",
        "Qiongxiu Li",
        "Russa Biswas",
        "Johannes Bjerva"
      ],
      "abstract": "Language Confusion is a phenomenon where Large Language Models (LLMs)\ngenerate text that is neither in the desired language, nor in a contextually\nappropriate language. This phenomenon presents a critical challenge in text\ngeneration by LLMs, often appearing as erratic and unpredictable behavior. We\nhypothesize that there are linguistic regularities to this inherent\nvulnerability in LLMs and shed light on patterns of language confusion across\nLLMs. We introduce a novel metric, Language Confusion Entropy, designed to\ndirectly measure and quantify this confusion, based on language distributions\ninformed by linguistic typology and lexical variation. Comprehensive\ncomparisons with the Language Confusion Benchmark (Marchisio et al., 2024)\nconfirm the effectiveness of our metric, revealing patterns of language\nconfusion across LLMs. We further link language confusion to LLM security, and\nfind patterns in the case of multilingual embedding inversion attacks. Our\nanalysis demonstrates that linguistic typology offers theoretically grounded\ninterpretation, and valuable insights into leveraging language similarities as\na prior for LLM alignment and security.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）中的语言混淆（Language Confusion）现象，即模型生成非预期或不合适的语言文本，并揭示其模式和潜在风险。论文引入了一种新指标Language Confusion Entropy，用于量化这种混淆，基于语言分布、语言类型学（linguistic typology）和词汇变异，并通过与Language Confusion Benchmark的比较验证其有效性。实验分析显示，LLMs在多语言嵌入逆向攻击中存在特定模式，并将语言混淆与安全问题联系起来。总体而言，该工作利用语言类型学提供理论解释，并为提升LLMs的对齐和安全性提供宝贵见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "I.1.2; I.1.5"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 15 figures, 14 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.13237v2",
      "published_date": "2024-10-17 05:43:30 UTC",
      "updated_date": "2025-02-09 13:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:07:21.866047"
    },
    {
      "arxiv_id": "2411.00783v1",
      "title": "From chalkboards to chatbots: SELAR assists teachers in embracing AI in the curriculum",
      "title_zh": "翻译失败",
      "authors": [
        "Hani Alers",
        "Aleksandra Malinowska",
        "Mathis Mourey",
        "Jasper Waaijer"
      ],
      "abstract": "This paper introduces SELAR, a framework designed to effectively help\nteachers integrate artificial intelligence (AI) into their curriculum. The\nframework was designed by running workshops organized to gather lecturers'\nfeedback. In this paper, we assess the effectiveness of the framework through\nadditional workshops organized with lecturers from the Hague University of\nApplied Sciences. The workshops tested the application of the framework to\nadapt existing courses to leverage generative AI technology. Each participant\nwas tasked to apply SELAR to one of their learning goals in order to evaluate\nAI integration potential and, if successful, to update the teaching methods\naccordingly. Findings show that teachers were able to effectively use the SELAR\nto integrate generative AI into their courses. Future work will focus on\nproviding additional guidance and examples to use the framework more\neffectively.",
      "tldr_zh": "本论文介绍了 SELAR 框架，这是一种帮助教师将人工智能 (AI) 整合到课程中的工具，通过组织研讨会收集教师反馈来设计该框架。研究团队通过后续研讨会评估 SELAR 的有效性，让参与者将其应用于现有课程的学习目标，以评估 AI 整合潜力并更新教学方法。结果显示，教师能够成功使用 SELAR 整合生成式 AI 技术，而未来工作将聚焦于提供更多指导和示例以提升框架的使用效率。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.00783v1",
      "published_date": "2024-10-17 05:40:59 UTC",
      "updated_date": "2024-10-17 05:40:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:07:33.168748"
    },
    {
      "arxiv_id": "2410.13236v1",
      "title": "SPIN: Self-Supervised Prompt INjection",
      "title_zh": "SPIN: 自监督提示注入",
      "authors": [
        "Leon Zhou",
        "Junfeng Yang",
        "Chengzhi Mao"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly used in a variety of important\napplications, yet their safety and reliability remain as major concerns.\nVarious adversarial and jailbreak attacks have been proposed to bypass the\nsafety alignment and cause the model to produce harmful responses. We introduce\nSelf-supervised Prompt INjection (SPIN) which can detect and reverse these\nvarious attacks on LLMs. As our self-supervised prompt defense is done at\ninference-time, it is also compatible with existing alignment and adds an\nadditional layer of safety for defense. Our benchmarks demonstrate that our\nsystem can reduce the attack success rate by up to 87.9%, while maintaining the\nperformance on benign user requests. In addition, we discuss the situation of\nan adaptive attacker and show that our method is still resilient against\nattackers who are aware of our defense.",
      "tldr_zh": "本文提出 SPIN（Self-Supervised Prompt INjection），一种自监督方法，用于检测和逆转对大型语言模型（LLMs）的各种攻击，如对抗攻击和越狱攻击，从而增强模型的安全性。该方法在推理时注入防御提示，与现有安全对齐兼容，能够将攻击成功率降低高达87.9%，同时保持对良性用户请求的性能表现。此外，实验结果显示，SPIN 对知晓防御的适应性攻击者仍具有较强抵抗力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13236v1",
      "published_date": "2024-10-17 05:40:54 UTC",
      "updated_date": "2024-10-17 05:40:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:07:45.531996"
    },
    {
      "arxiv_id": "2410.13229v2",
      "title": "Quamba: A Post-Training Quantization Recipe for Selective State Space Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hung-Yueh Chiang",
        "Chi-Chih Chang",
        "Natalia Frumkin",
        "Kai-Chiang Wu",
        "Diana Marculescu"
      ],
      "abstract": "State Space Models (SSMs) have emerged as an appealing alternative to\nTransformers for large language models, achieving state-of-the-art accuracy\nwith constant memory complexity which allows for holding longer context lengths\nthan attention-based networks. The superior computational efficiency of SSMs in\nlong sequence modeling positions them favorably over Transformers in many\nscenarios. However, improving the efficiency of SSMs on request-intensive\ncloud-serving and resource-limited edge applications is still a formidable\ntask. SSM quantization is a possible solution to this problem, making SSMs more\nsuitable for wide deployment, while still maintaining their accuracy.\nQuantization is a common technique to reduce the model size and to utilize the\nlow bit-width acceleration features on modern computing units, yet existing\nquantization techniques are poorly suited for SSMs. Most notably, SSMs have\nhighly sensitive feature maps within the selective scan mechanism (i.e., linear\nrecurrence) and massive outliers in the output activations which are not\npresent in the output of token-mixing in the self-attention modules. To address\nthis issue, we propose a static 8-bit per-tensor SSM quantization method which\nsuppresses the maximum values of the input activations to the selective SSM for\nfiner quantization precision and quantizes the output activations in an\noutlier-free space with Hadamard transform. Our 8-bit weight-activation\nquantized Mamba 2.8B SSM benefits from hardware acceleration and achieves a\n1.72x lower generation latency on an Nvidia Orin Nano 8G, with only a 0.9% drop\nin average accuracy on zero-shot tasks. The experiments demonstrate the\neffectiveness and practical applicability of our approach for deploying\nSSM-based models of all sizes on both cloud and edge platforms.",
      "tldr_zh": "本论文提出Quamba，一种针对Selective State Space Models (SSMs)的后训练量化方法，旨在提升SSMs在云服务和边缘设备上的效率，同时保持模型准确性。方法包括抑制输入激活的最大值以提高量化精度，以及使用Hadamard transform在无异常值空间量化输出激活，从而解决SSMs中selective scan mechanism的敏感特征映射问题。实验结果显示，对Mamba 2.8B SSM进行8-bit量化后，在Nvidia Orin Nano 8G上生成延迟降低1.72倍，仅在零样本任务上平均准确率下降0.9%，证明了该方法在各种规模SSMs部署中的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13229v2",
      "published_date": "2024-10-17 05:32:33 UTC",
      "updated_date": "2024-12-07 07:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:07:58.477078"
    },
    {
      "arxiv_id": "2410.13228v2",
      "title": "From PINNs to PIKANs: Recent Advances in Physics-Informed Machine Learning",
      "title_zh": "从 PINNs 到 PIKANs：物理信息机器学习中的最新进展",
      "authors": [
        "Juan Diego Toscano",
        "Vivek Oommen",
        "Alan John Varghese",
        "Zongren Zou",
        "Nazanin Ahmadi Daryakenari",
        "Chenxi Wu",
        "George Em Karniadakis"
      ],
      "abstract": "Physics-Informed Neural Networks (PINNs) have emerged as a key tool in\nScientific Machine Learning since their introduction in 2017, enabling the\nefficient solution of ordinary and partial differential equations using sparse\nmeasurements. Over the past few years, significant advancements have been made\nin the training and optimization of PINNs, covering aspects such as network\narchitectures, adaptive refinement, domain decomposition, and the use of\nadaptive weights and activation functions. A notable recent development is the\nPhysics-Informed Kolmogorov-Arnold Networks (PIKANS), which leverage a\nrepresentation model originally proposed by Kolmogorov in 1957, offering a\npromising alternative to traditional PINNs. In this review, we provide a\ncomprehensive overview of the latest advancements in PINNs, focusing on\nimprovements in network design, feature expansion, optimization techniques,\nuncertainty quantification, and theoretical insights. We also survey key\napplications across a range of fields, including biomedicine, fluid and solid\nmechanics, geophysics, dynamical systems, heat transfer, chemical engineering,\nand beyond. Finally, we review computational frameworks and software tools\ndeveloped by both academia and industry to support PINN research and\napplications.",
      "tldr_zh": "该论文回顾了Physics-Informed Neural Networks (PINNs)自2017年引入以来在Scientific Machine Learning领域的关键进展，包括网络架构优化、适应性细化、域分解以及自适应权重和激活函数的改进。作者引入了Physics-Informed Kolmogorov-Arnold Networks (PIKANs)作为传统PINNs的备选方案，该方法基于Kolmogorov 1957年的表示模型，提供更高效的微分方程求解途径。论文还总结了PINNs在生物医学、流体和固体力学、地质物理学等领域的主要应用，以及相关的计算框架和软件工具，以支持进一步的研究和实践。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "physics-informed neural networks, Kolmogorov-Arnold networks,\n  optimization algorithms, separable PINNs, self-adaptive weights, uncertainty\n  quantification",
      "pdf_url": "http://arxiv.org/pdf/2410.13228v2",
      "published_date": "2024-10-17 05:30:59 UTC",
      "updated_date": "2024-10-22 02:53:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:08:09.847256"
    },
    {
      "arxiv_id": "2410.13226v2",
      "title": "Research on Travel Route Planing Problems Based on Greedy Algorithm",
      "title_zh": "基于贪心算法的旅游路线规划问题研究",
      "authors": [
        "Yiquan Wang"
      ],
      "abstract": "The route planning problem based on the greedy algorithm represents a method\nof identifying the optimal or near-optimal route between a given start point\nand end point. In this paper, the PCA method is employed initially to downscale\nthe city evaluation indexes, extract the key principal components, and then\ndownscale the data using the KMO and TOPSIS algorithms, all of which are based\non the MindSpore framework. Secondly, for the dataset that does not pass the\nKMO test, the entropy weight method and TOPSIS method will be employed for\ncomprehensive evaluation. Finally, a route planning algorithm is proposed and\noptimised based on the greedy algorithm, which provides personalised route\ncustomisation according to the different needs of tourists. In addition, the\nlocal travelling efficiency, the time required to visit tourist attractions and\nthe necessary daily breaks are considered in order to reduce the cost and avoid\nfalling into the locally optimal solution.",
      "tldr_zh": "本论文研究基于 Greedy Algorithm 的旅行路线规划问题，旨在找到从起点到终点的优选路线。首先，使用 PCA 方法降维城市评估指标，并结合 KMO 和 TOPSIS 算法进行数据处理，所有步骤基于 MindSpore 框架；对于未通过 KMO 测试的数据集，则采用熵权法和 TOPSIS 方法进行综合评估。最终，提出并优化了 Greedy Algorithm 的路线规划算法，根据游客个性化需求定制路线，并考虑本地旅行效率、景点访问时间和日常休息，以降低成本并避免局部最优解。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13226v2",
      "published_date": "2024-10-17 05:17:01 UTC",
      "updated_date": "2024-10-22 12:28:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:08:22.814531"
    },
    {
      "arxiv_id": "2410.13218v2",
      "title": "CBT-Bench: Evaluating Large Language Models on Assisting Cognitive Behavior Therapy",
      "title_zh": "CBT-Bench：评估大语言模型在辅助认知行为疗法中的性能",
      "authors": [
        "Mian Zhang",
        "Xianjun Yang",
        "Xinlu Zhang",
        "Travis Labrum",
        "Jamie C. Chiu",
        "Shaun M. Eack",
        "Fei Fang",
        "William Yang Wang",
        "Zhiyu Zoey Chen"
      ],
      "abstract": "There is a significant gap between patient needs and available mental health\nsupport today. In this paper, we aim to thoroughly examine the potential of\nusing Large Language Models (LLMs) to assist professional psychotherapy. To\nthis end, we propose a new benchmark, CBT-BENCH, for the systematic evaluation\nof cognitive behavioral therapy (CBT) assistance. We include three levels of\ntasks in CBT-BENCH: I: Basic CBT knowledge acquisition, with the task of\nmultiple-choice questions; II: Cognitive model understanding, with the tasks of\ncognitive distortion classification, primary core belief classification, and\nfine-grained core belief classification; III: Therapeutic response generation,\nwith the task of generating responses to patient speech in CBT therapy\nsessions. These tasks encompass key aspects of CBT that could potentially be\nenhanced through AI assistance, while also outlining a hierarchy of capability\nrequirements, ranging from basic knowledge recitation to engaging in real\ntherapeutic conversations. We evaluated representative LLMs on our benchmark.\nExperimental results indicate that while LLMs perform well in reciting CBT\nknowledge, they fall short in complex real-world scenarios requiring deep\nanalysis of patients' cognitive structures and generating effective responses,\nsuggesting potential future work.",
      "tldr_zh": "本论文提出CBT-Bench基准，用于系统评估Large Language Models (LLMs)辅助认知行为疗法 (CBT)的潜力，以填补患者需求与现有心理支持的差距。基准包括三个级别任务：I. 基本CBT知识获取（多项选择题）；II. 认知模型理解（认知扭曲分类、主要核心信念分类和细粒度核心信念分类）；III. 治疗响应生成（针对患者言语的响应生成）。实验结果表明，LLMs在背诵CBT知识方面表现优秀，但在大语言模型处理复杂真实场景时，如深入分析患者认知结构和生成有效响应，仍存在显著不足，建议未来工作进一步优化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2025 Camera Ready",
      "pdf_url": "http://arxiv.org/pdf/2410.13218v2",
      "published_date": "2024-10-17 04:52:57 UTC",
      "updated_date": "2025-01-26 05:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:08:35.053980"
    },
    {
      "arxiv_id": "2410.13217v1",
      "title": "MixEHR-Nest: Identifying Subphenotypes within Electronic Health Records through Hierarchical Guided-Topic Modeling",
      "title_zh": "MixEHR-Nest：通过分层引导主题建模识别电子健康记录中的亚表型",
      "authors": [
        "Ruohan Wang",
        "Zilong Wang",
        "Ziyang Song",
        "David Buckeridge",
        "Yue Li"
      ],
      "abstract": "Automatic subphenotyping from electronic health records (EHRs)provides\nnumerous opportunities to understand diseases with unique subgroups and enhance\npersonalized medicine for patients. However, existing machine learning\nalgorithms either focus on specific diseases for better interpretability or\nproduce coarse-grained phenotype topics without considering nuanced disease\npatterns. In this study, we propose a guided topic model, MixEHR-Nest, to infer\nsub-phenotype topics from thousands of disease using multi-modal EHR data.\nSpecifically, MixEHR-Nest detects multiple subtopics from each phenotype topic,\nwhose prior is guided by the expert-curated phenotype concepts such as\nPhenotype Codes (PheCodes) or Clinical Classification Software (CCS) codes. We\nevaluated MixEHR-Nest on two EHR datasets: (1) the MIMIC-III dataset consisting\nof over 38 thousand patients from intensive care unit (ICU) from Beth Israel\nDeaconess Medical Center (BIDMC) in Boston, USA; (2) the healthcare\nadministrative database PopHR, comprising 1.3 million patients from Montreal,\nCanada. Experimental results demonstrate that MixEHR-Nest can identify\nsubphenotypes with distinct patterns within each phenotype, which are\npredictive for disease progression and severity. Consequently, MixEHR-Nest\ndistinguishes between type 1 and type 2 diabetes by inferring subphenotypes\nusing CCS codes, which do not differentiate these two subtype concepts.\nAdditionally, MixEHR-Nest not only improved the prediction accuracy of\nshort-term mortality of ICU patients and initial insulin treatment in diabetic\npatients but also revealed the contributions of subphenotypes. For longitudinal\nanalysis, MixEHR-Nest identified subphenotypes of distinct age prevalence under\nthe same phenotypes, such as asthma, leukemia, epilepsy, and depression. The\nMixEHR-Nest software is available at GitHub:\nhttps://github.com/li-lab-mcgill/MixEHR-Nest.",
      "tldr_zh": "本研究提出MixEHR-Nest，一种层次化引导主题模型，用于从电子健康记录(EHRs)中识别疾病亚表型，从而提升个性化医学。该模型利用专家策划的先验知识，如PheCodes或CCS codes，从每个表型主题中检测多个子主题，捕捉细微的疾病模式。在MIMIC-III和PopHR数据集上实验显示，MixEHR-Nest能区分1型和2型糖尿病等亚表型，提高了ICU患者短期死亡率和糖尿病患者初始胰岛素治疗的预测准确性，并通过纵向分析揭示了不同年龄分布下的亚表型特征。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "q-bio.QM",
        "J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13217v1",
      "published_date": "2024-10-17 04:48:06 UTC",
      "updated_date": "2024-10-17 04:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:08:47.219190"
    },
    {
      "arxiv_id": "2410.13216v1",
      "title": "Anchored Alignment for Self-Explanations Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Luis Felipe Villa-Arenas",
        "Ata Nizamoglu",
        "Qianli Wang",
        "Sebastian Möller",
        "Vera Schmitt"
      ],
      "abstract": "In this work, we introduce a methodology for alignment designed to enhance\nthe ability of large language models (LLMs) to articulate their reasoning\n(self-explanation) even in the absence of annotated rationale explanations. Our\nalignment methodology comprises three key components: explanation quality\nassessment, self-instruction dataset generation, and model alignment.\nAdditionally, we present a novel technique called Alignment with Anchor\nPreference Pairs, which improves the selection of preference pairs by\ncategorizing model outputs into three groups: consistently correct,\nconsistently incorrect, and variable. By applying tailored strategies to each\ncategory, we enhance the effectiveness of Direct Preference Optimization (DPO).\nOur experimental results demonstrate that this approach significantly improves\nexplanation quality while maintaining accuracy compared to other fine-tuning\nstrategies.",
      "tldr_zh": "本研究提出了一种名为“Anchored Alignment”的方法，用于提升大型语言模型 (LLMs) 的自我解释能力，即使没有标注的解释数据。该方法包括三个关键组件：解释质量评估、自我指令数据集生成和模型对齐，同时引入“Alignment with Anchor Preference Pairs”技巧，通过将模型输出分类为一致正确、一致错误和可变类别来优化偏好对选择，从而改进 Direct Preference Optimization (DPO)。实验结果显示，这种方法显著提高了解释质量，同时保持了模型的准确性，优于其他微调策略。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13216v1",
      "published_date": "2024-10-17 04:42:48 UTC",
      "updated_date": "2024-10-17 04:42:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:08:57.769131"
    },
    {
      "arxiv_id": "2410.13213v2",
      "title": "LLMOPT: Learning to Define and Solve General Optimization Problems from Scratch",
      "title_zh": "LLMOPT：从零开始学习定义和解决一般优化问题",
      "authors": [
        "Caigao Jiang",
        "Xiang Shu",
        "Hong Qian",
        "Xingyu Lu",
        "Jun Zhou",
        "Aimin Zhou",
        "Yang Yu"
      ],
      "abstract": "Optimization problems are prevalent across various scenarios. Formulating and\nthen solving optimization problems described by natural language often requires\nhighly specialized human expertise, which could block the widespread\napplication of optimization-based decision making. To automate problem\nformulation and solving, leveraging large language models (LLMs) has emerged as\na potential way. However, this kind of approach suffers from the issue of\noptimization generalization. Namely, the accuracy of most current LLM-based\nmethods and the generality of optimization problem types that they can model\nare still limited. In this paper, we propose a unified learning-based framework\ncalled LLMOPT to boost optimization generalization. Starting from the natural\nlanguage descriptions of optimization problems and a pre-trained LLM, LLMOPT\nconstructs the introduced five-element formulation as a universal model for\nlearning to define diverse optimization problem types. Then, LLMOPT employs the\nmulti-instruction tuning to enhance both problem formalization and solver code\ngeneration accuracy and generality. After that, to prevent hallucinations in\nLLMs, such as sacrificing solving accuracy to avoid execution errors, the model\nalignment and self-correction mechanism are adopted in LLMOPT. We evaluate the\noptimization generalization ability of LLMOPT and compared methods across six\nreal-world datasets covering roughly 20 fields such as health, environment,\nenergy and manufacturing, etc. Extensive experiment results show that LLMOPT is\nable to model various optimization problem types such as linear/nonlinear\nprogramming, mixed integer programming, and combinatorial optimization, and\nachieves a notable 11.08% average solving accuracy improvement compared with\nthe state-of-the-art methods. The code is available at\nhttps://github.com/caigaojiang/LLMOPT.",
      "tldr_zh": "该论文提出LLMOPT，一种统一的基于大型语言模型(LLMs)的学习框架，旨在从自然语言描述中自动定义和解决各种优化问题，从而克服现有方法的优化泛化性限制。LLMOPT 通过构建一个五元素公式来统一建模不同类型的问题，并采用多指令微调、模型对齐和自校正机制，提升问题形式化和求解器代码生成的准确性，同时防止LLMs的幻觉问题。在涵盖健康、环境、能源和制造等20个领域的六个真实数据集上，实验结果显示LLMOPT能够处理线性/非线性规划、混合整数规划和组合优化等多种问题类型，并比最先进方法平均提高11.08%的求解准确性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13213v2",
      "published_date": "2024-10-17 04:37:37 UTC",
      "updated_date": "2025-03-03 03:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:09:10.587906"
    },
    {
      "arxiv_id": "2410.13212v1",
      "title": "AsymKV: Enabling 1-Bit Quantization of KV Cache with Layer-Wise Asymmetric Quantization Configurations",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Tao",
        "Wenyuan Yu",
        "Jingren Zhou"
      ],
      "abstract": "Large language models have shown exceptional capabilities in a wide range of\ntasks, such as text generation and video generation, among others. However, due\nto their massive parameter count, these models often require substantial\nstorage space, imposing significant constraints on the machines deploying LLMs.\nTo overcome this limitation, one research direction proposes to compress the\nmodels using integer replacements for floating-point numbers, in a process\nknown as Quantization. Some recent studies suggest quantizing the key and value\ncache (KV Cache) of LLMs, and designing quantization techniques that treat the\nkey and value matrices equivalently.\n  This work delves deeper into the asymmetric structural roles of KV Cache, a\nphenomenon where the transformer's output loss is more sensitive to the\nquantization of key matrices. We conduct a systematic examination of the\nattention output error resulting from key and value quantization. The\nphenomenon inspires us to propose an asymmetric quantization strategy. Our\napproach allows for 1-bit quantization of the KV cache by implementing distinct\nconfigurations for key and value matrices. We carry out experiments across a\nvariety of datasets, demonstrating that our proposed model allows for the\nquantization of up to 75% decoder layers with 1 bit, while simultaneously\nmaintaining performance levels comparable to those of the models with floating\nparameters.",
      "tldr_zh": "本文提出 AsymKV 方法，通过层级不对称量化配置（Layer-Wise Asymmetric Quantization Configurations）实现大语言模型（LLMs）的 KV Cache 进行 1-bit Quantization，以解决模型存储空间限制的问题。不同于传统方法，该策略认识到关键矩阵（key matrices）在量化时对模型输出更敏感，因此为关键和值矩阵（value matrices）设计不同的量化配置。实验结果显示，在多种数据集上，该方法可对多达 75% 的解码器层（decoder layers）进行 1-bit 量化，同时保持与浮点参数模型相当的性能水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13212v1",
      "published_date": "2024-10-17 04:35:57 UTC",
      "updated_date": "2024-10-17 04:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:09:22.860811"
    },
    {
      "arxiv_id": "2410.13211v2",
      "title": "Estimating the Probabilities of Rare Outputs in Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel Wu",
        "Jacob Hilton"
      ],
      "abstract": "We consider the problem of low probability estimation: given a machine\nlearning model and a formally-specified input distribution, how can we estimate\nthe probability of a binary property of the model's output, even when that\nprobability is too small to estimate by random sampling? This problem is\nmotivated by the need to improve worst-case performance, which distribution\nshift can make much more likely. We study low probability estimation in the\ncontext of argmax sampling from small transformer language models. We compare\ntwo types of methods: importance sampling, which involves searching for inputs\ngiving rise to the rare output, and activation extrapolation, which involves\nextrapolating a probability distribution fit to the model's logits. We find\nthat importance sampling outperforms activation extrapolation, but both\noutperform naive sampling. Finally, we explain how minimizing the probability\nestimate of an undesirable behavior generalizes adversarial training, and argue\nthat new methods for low probability estimation are needed to provide stronger\nguarantees about worst-case performance.",
      "tldr_zh": "该研究探讨了在语言模型中估计稀有输出概率的问题，即当概率过低无法通过随机采样估算时，如何计算模型输出特定二元属性的概率，以改善最坏情况性能（worst-case performance）。作者比较了两种方法：重要性采样（importance sampling），通过搜索导致稀有输出的输入；以及激活外推（activation extrapolation），通过拟合模型 logits 的概率分布。实验结果显示，重要性采样优于激活外推，且两者均优于朴素采样。最终，该论文论证了最小化 undesirable 行为概率估计如何推广对抗训练（adversarial training），并强调需要新方法来提供更强的 worst-case 性能保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.13211v2",
      "published_date": "2024-10-17 04:31:18 UTC",
      "updated_date": "2025-02-06 18:43:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:09:34.351289"
    },
    {
      "arxiv_id": "2410.13210v1",
      "title": "FaithBench: A Diverse Hallucination Benchmark for Summarization by Modern LLMs",
      "title_zh": "FaithBench：现代LLMs摘要生成的多样化幻觉基准",
      "authors": [
        "Forrest Sheng Bao",
        "Miaoran Li",
        "Renyi Qu",
        "Ge Luo",
        "Erana Wan",
        "Yujia Tang",
        "Weisi Fan",
        "Manveer Singh Tamber",
        "Suleman Kazi",
        "Vivek Sourabh",
        "Mike Qi",
        "Ruixuan Tu",
        "Chenyu Xu",
        "Matthew Gonzales",
        "Ofer Mendelevitch",
        "Amin Ahmad"
      ],
      "abstract": "Summarization is one of the most common tasks performed by large language\nmodels (LLMs), especially in applications like Retrieval-Augmented Generation\n(RAG). However, existing evaluations of hallucinations in LLM-generated\nsummaries, and evaluations of hallucination detection models both suffer from a\nlack of diversity and recency in the LLM and LLM families considered. This\npaper introduces FaithBench, a summarization hallucination benchmark comprising\nchallenging hallucinations made by 10 modern LLMs from 8 different families,\nwith ground truth annotations by human experts. ``Challenging'' here means\nsummaries on which popular, state-of-the-art hallucination detection models,\nincluding GPT-4o-as-a-judge, disagreed on. Our results show GPT-4o and\nGPT-3.5-Turbo produce the least hallucinations. However, even the best\nhallucination detection models have near 50\\% accuracies on FaithBench,\nindicating lots of room for future improvement. The repo is\nhttps://github.com/vectara/FaithBench",
      "tldr_zh": "本论文引入了FaithBench，这是一个多样化的基准，用于评估现代大型语言模型（LLMs）在总结任务中产生的幻觉（hallucinations），尤其针对Retrieval-Augmented Generation (RAG)应用。FaithBench包含由10个LLMs（来自8个不同家族）生成的挑战性总结，这些总结由人类专家标注，且让先进的幻觉检测模型（如GPT-4o-as-a-judge）难以一致判断。研究发现，GPT-4o和GPT-3.5-Turbo产生的幻觉最少，但即使最佳检测模型在FaithBench上的准确率仅约50%，表明未来有很大改进空间。该基准的开源仓库为https://github.com/vectara/FaithBench。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13210v1",
      "published_date": "2024-10-17 04:30:46 UTC",
      "updated_date": "2024-10-17 04:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:09:46.508031"
    },
    {
      "arxiv_id": "2410.13204v1",
      "title": "Measuring Free-Form Decision-Making Inconsistency of Language Models in Military Crisis Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Aryan Shrivastava",
        "Jessica Hullman",
        "Max Lamparth"
      ],
      "abstract": "There is an increasing interest in using language models (LMs) for automated\ndecision-making, with multiple countries actively testing LMs to aid in\nmilitary crisis decision-making. To scrutinize relying on LM decision-making in\nhigh-stakes settings, we examine the inconsistency of responses in a crisis\nsimulation (\"wargame\"), similar to reported tests conducted by the US military.\nPrior work illustrated escalatory tendencies and varying levels of aggression\namong LMs but were constrained to simulations with pre-defined actions. This\nwas due to the challenges associated with quantitatively measuring semantic\ndifferences and evaluating natural language decision-making without relying on\npre-defined actions. In this work, we query LMs for free form responses and use\na metric based on BERTScore to measure response inconsistency quantitatively.\nLeveraging the benefits of BERTScore, we show that the inconsistency metric is\nrobust to linguistic variations that preserve semantic meaning in a\nquestion-answering setting across text lengths. We show that all five tested\nLMs exhibit levels of inconsistency that indicate semantic differences, even\nwhen adjusting the wargame setting, anonymizing involved conflict countries, or\nadjusting the sampling temperature parameter $T$. Further qualitative\nevaluation shows that models recommend courses of action that share few to no\nsimilarities. We also study the impact of different prompt sensitivity\nvariations on inconsistency at temperature $T = 0$. We find that inconsistency\ndue to semantically equivalent prompt variations can exceed response\ninconsistency from temperature sampling for most studied models across\ndifferent levels of ablations. Given the high-stakes nature of military\ndeployment, we recommend further consideration be taken before using LMs to\ninform military decisions or other cases of high-stakes decision-making.",
      "tldr_zh": "这篇论文研究了语言模型（LMs）在军事危机模拟（wargame）中的自由形式决策不一致性，旨在评估其在高风险场景中的可靠性。作者提出了一种基于 BERTScore 的量化指标，来测量 LMs 响应中的语义差异，而非依赖预定义动作。实验结果显示，五种测试的 LMs 即使在调整模拟设置、匿名化国家或温度参数（T）后，仍表现出显著的不一致性，且提示敏感性变化导致的不一致性往往超过温度采样的影响。论文强调，在军事或类似高风险决策中使用 LMs 前，需要进一步审慎评估。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13204v1",
      "published_date": "2024-10-17 04:12:17 UTC",
      "updated_date": "2024-10-17 04:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:09:58.427707"
    },
    {
      "arxiv_id": "2410.13203v2",
      "title": "TabSeq: A Framework for Deep Learning on Tabular Data via Sequential Ordering",
      "title_zh": "翻译失败",
      "authors": [
        "Al Zadid Sultan Bin Habib",
        "Kesheng Wang",
        "Mary-Anne Hartley",
        "Gianfranco Doretto",
        "Donald A. Adjeroh"
      ],
      "abstract": "Effective analysis of tabular data still poses a significant problem in deep\nlearning, mainly because features in tabular datasets are often heterogeneous\nand have different levels of relevance. This work introduces TabSeq, a novel\nframework for the sequential ordering of features, addressing the vital\nnecessity to optimize the learning process. Features are not always equally\ninformative, and for certain deep learning models, their random arrangement can\nhinder the model's learning capacity. Finding the optimum sequence order for\nsuch features could improve the deep learning models' learning process. The\nnovel feature ordering technique we provide in this work is based on clustering\nand incorporates both local ordering and global ordering. It is designed to be\nused with a multi-head attention mechanism in a denoising autoencoder network.\nOur framework uses clustering to align comparable features and improve data\norganization. Multi-head attention focuses on essential characteristics,\nwhereas the denoising autoencoder highlights important aspects by rebuilding\nfrom distorted inputs. This method improves the capability to learn from\ntabular data while lowering redundancy. Our research, demonstrating improved\nperformance through appropriate feature sequence rearrangement using raw\nantibody microarray and two other real-world biomedical datasets, validates the\nimpact of feature ordering. These results demonstrate that feature ordering can\nbe a viable approach to improved deep learning of tabular data.",
      "tldr_zh": "该研究提出TabSeq框架，通过特征的顺序排列来优化深度学习模型对表格数据的学习，解决特征异构和相关性差异带来的挑战。TabSeq基于聚类技术实现局部和全局特征排序，并结合多头注意力机制(multi-head attention)和去噪自编码器(denoising autoencoder)网络，聚类用于对相似特征对齐以减少冗余，而注意力机制则聚焦于关键特征以提升学习效率。实验在原始抗体微阵列和其他两个真实生物医学数据集上验证了该方法，通过适当的特征重新排序显著提高了模型性能，证明特征顺序排列是改进表格数据深度学习的可行策略。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted for presentation at the 27th\n  International Conference on Pattern Recognition (ICPR 2024) in Kolkata, India",
      "pdf_url": "http://arxiv.org/pdf/2410.13203v2",
      "published_date": "2024-10-17 04:10:36 UTC",
      "updated_date": "2024-10-21 15:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:10:09.639538"
    },
    {
      "arxiv_id": "2410.13201v1",
      "title": "Meta-DiffuB: A Contextualized Sequence-to-Sequence Text Diffusion Model with Meta-Exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Yun-Yen Chuang",
        "Hung-Min Hsu",
        "Kevin Lin",
        "Chen-Sheng Gu",
        "Ling Zhen Li",
        "Ray-I Chang",
        "Hung-yi Lee"
      ],
      "abstract": "The diffusion model, a new generative modeling paradigm, has achieved\nsignificant success in generating images, audio, video, and text. It has been\nadapted for sequence-to-sequence text generation (Seq2Seq) through DiffuSeq,\ntermed S2S Diffusion. Existing S2S-Diffusion models predominantly rely on fixed\nor hand-crafted rules to schedule noise during the diffusion and denoising\nprocesses. However, these models are limited by non-contextualized noise, which\nfails to fully consider the characteristics of Seq2Seq tasks. In this paper, we\npropose the Meta-DiffuB framework - a novel scheduler-exploiter S2S-Diffusion\nparadigm designed to overcome the limitations of existing S2S-Diffusion models.\nWe employ Meta-Exploration to train an additional scheduler model dedicated to\nscheduling contextualized noise for each sentence. Our exploiter model, an\nS2S-Diffusion model, leverages the noise scheduled by our scheduler model for\nupdating and generation. Meta-DiffuB achieves state-of-the-art performance\ncompared to previous S2S-Diffusion models and fine-tuned pre-trained language\nmodels (PLMs) across four Seq2Seq benchmark datasets. We further investigate\nand visualize the impact of Meta-DiffuB's noise scheduling on the generation of\nsentences with varying difficulties. Additionally, our scheduler model can\nfunction as a \"plug-and-play\" model to enhance DiffuSeq without the need for\nfine-tuning during the inference stage.",
      "tldr_zh": "该论文提出Meta-DiffuB框架，一种基于Meta-Exploration的上下文化序列到序列（Seq2Seq）文本扩散模型，用于解决现有S2S-Diffusion模型中噪声调度规则固定且非上下文化的局限问题。框架包括一个专门的调度器模型，通过Meta-Exploration为每个句子生成上下文化噪声，并由S2S-Diffusion利用者模型用于文本生成和更新。实验结果显示，Meta-DiffuB在四个Seq2Seq基准数据集上超越了之前的S2S-Diffusion模型和微调的预训练语言模型（PLMs），并通过可视化分析了噪声调度对不同难度句子的影响；此外，调度器模型可作为即插即用组件增强DiffuSeq，而无需推理阶段的微调。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13201v1",
      "published_date": "2024-10-17 04:06:02 UTC",
      "updated_date": "2024-10-17 04:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:10:23.457865"
    },
    {
      "arxiv_id": "2410.13196v2",
      "title": "Context-Enhanced Multi-View Trajectory Representation Learning: Bridging the Gap through Self-Supervised Models",
      "title_zh": "上下文增强的多视图轨迹表示学习：通过自监督模型弥合差距",
      "authors": [
        "Tangwen Qian",
        "Junhe Li",
        "Yile Chen",
        "Gao Cong",
        "Tao Sun",
        "Fei Wang",
        "Yongjun Xu"
      ],
      "abstract": "Modeling trajectory data with generic-purpose dense representations has\nbecome a prevalent paradigm for various downstream applications, such as\ntrajectory classification, travel time estimation and similarity computation.\nHowever, existing methods typically rely on trajectories from a single spatial\nview, limiting their ability to capture the rich contextual information that is\ncrucial for gaining deeper insights into movement patterns across different\ngeospatial contexts. To this end, we propose MVTraj, a novel multi-view\nmodeling method for trajectory representation learning. MVTraj integrates\ndiverse contextual knowledge, from GPS to road network and points-of-interest\nto provide a more comprehensive understanding of trajectory data. To align the\nlearning process across multiple views, we utilize GPS trajectories as a bridge\nand employ self-supervised pretext tasks to capture and distinguish movement\npatterns across different spatial views. Following this, we treat trajectories\nfrom different views as distinct modalities and apply a hierarchical\ncross-modal interaction module to fuse the representations, thereby enriching\nthe knowledge derived from multiple sources. Extensive experiments on\nreal-world datasets demonstrate that MVTraj significantly outperforms existing\nbaselines in tasks associated with various spatial views, validating its\neffectiveness and practical utility in spatio-temporal modeling.",
      "tldr_zh": "本文提出 MVTraj，一种增强上下文的多视角轨迹表示学习方法，旨在解决现有模型依赖单一空间视角（如 GPS）而忽略丰富地理上下文的问题。通过利用 GPS 轨迹作为桥梁，并采用自监督预训练任务来捕捉不同空间视角下的运动模式，MVTraj 将轨迹视为多种模态，并通过分层跨模态交互模块融合这些表示。实验在真实数据集上表明，MVTraj 在轨迹分类、旅行时间估计和相似性计算等任务中显著优于现有基线，证明了其在时空建模中的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13196v2",
      "published_date": "2024-10-17 03:56:12 UTC",
      "updated_date": "2024-10-18 08:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:10:34.047978"
    },
    {
      "arxiv_id": "2410.13193v1",
      "title": "Golyadkin's Torment: Doppelgängers and Adversarial Vulnerability",
      "title_zh": "翻译失败",
      "authors": [
        "George I. Kamberov"
      ],
      "abstract": "Many machine learning (ML) classifiers are claimed to outperform humans, but\nthey still make mistakes that humans do not. The most notorious examples of\nsuch mistakes are adversarial visual metamers. This paper aims to define and\ninvestigate the phenomenon of adversarial Doppelgangers (AD), which includes\nadversarial visual metamers, and to compare the performance and robustness of\nML classifiers to human performance.\n  We find that AD are inputs that are close to each other with respect to a\nperceptual metric defined in this paper. AD are qualitatively different from\nthe usual adversarial examples. The vast majority of classifiers are vulnerable\nto AD and robustness-accuracy trade-offs may not improve them. Some\nclassification problems may not admit any AD robust classifiers because the\nunderlying classes are ambiguous. We provide criteria that can be used to\ndetermine whether a classification problem is well defined or not; describe the\nstructure and attributes of an AD-robust classifier; introduce and explore the\nnotions of conceptual entropy and regions of conceptual ambiguity for\nclassifiers that are vulnerable to AD attacks, along with methods to bound the\nAD fooling rate of an attack. We define the notion of classifiers that exhibit\nhypersensitive behavior, that is, classifiers whose only mistakes are\nadversarial Doppelgangers. Improving the AD robustness of hyper-sensitive\nclassifiers is equivalent to improving accuracy. We identify conditions\nguaranteeing that all classifiers with sufficiently high accuracy are\nhyper-sensitive.\n  Our findings are aimed at significant improvements in the reliability and\nsecurity of machine learning systems.",
      "tldr_zh": "本论文探讨了机器学习（ML）分类器在对抗性Doppelgangers（AD）攻击下的脆弱性，包括对抗性视觉metamers，并将ML分类器的性能和鲁棒性与人类表现进行比较。作者定义AD为在感知度量（perceptual metric）上相近的输入，并发现大多数分类器易受AD影响，鲁棒性-准确性权衡可能无效，且某些分类问题因类别模糊性而无AD鲁棒解。论文引入概念熵（conceptual entropy）和概念模糊区域（regions of conceptual ambiguity）的概念，提供标准评估分类问题是否定义良好，并描述AD鲁棒分类器的结构。最终，研究识别出超敏感分类器（hypersensitive classifiers）的条件，即高准确性分类器往往只在AD上出错，从而为提升ML系统的可靠性和安全性提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13193v1",
      "published_date": "2024-10-17 03:42:06 UTC",
      "updated_date": "2024-10-17 03:42:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:10:47.766398"
    },
    {
      "arxiv_id": "2410.13191v4",
      "title": "MCQG-SRefine: Multiple Choice Question Generation and Evaluation with Iterative Self-Critique, Correction, and Comparison Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Zonghai Yao",
        "Aditya Parashar",
        "Huixue Zhou",
        "Won Seok Jang",
        "Feiyun Ouyang",
        "Zhichao Yang",
        "Hong Yu"
      ],
      "abstract": "Automatic question generation (QG) is essential for AI and NLP, particularly\nin intelligent tutoring, dialogue systems, and fact verification. Generating\nmultiple-choice questions (MCQG) for professional exams, like the United States\nMedical Licensing Examination (USMLE), is particularly challenging, requiring\ndomain expertise and complex multi-hop reasoning for high-quality questions.\nHowever, current large language models (LLMs) like GPT-4 struggle with\nprofessional MCQG due to outdated knowledge, hallucination issues, and prompt\nsensitivity, resulting in unsatisfactory quality and difficulty. To address\nthese challenges, we propose MCQG-SRefine, an LLM self-refine-based (Critique\nand Correction) framework for converting medical cases into high-quality\nUSMLE-style questions. By integrating expert-driven prompt engineering with\niterative self-critique and self-correction feedback, MCQG-SRefine\nsignificantly enhances human expert satisfaction regarding both the quality and\ndifficulty of the questions. Furthermore, we introduce an LLM-as-Judge-based\nautomatic metric to replace the complex and costly expert evaluation process,\nensuring reliable and expert-aligned assessments.",
      "tldr_zh": "本研究针对自动多选题生成（Multiple Choice Question Generation, MCQG）中的挑战，提出MCQG-SRefine框架，以解决大型语言模型（LLMs）如GPT-4在生成专业考试（如USMLE）问题时存在的知识过时、幻觉问题和提示敏感性问题。该框架通过专家驱动的提示工程结合迭代的自批判（Self-Critique）、自修正（Correction）和比较反馈机制，将医疗案例转化为高质量、难度适宜的USMLE风格问题，从而显著提升人类专家对问题质量和难度的满意度。此外，研究引入基于LLM-as-Judge的自动评估指标，取代复杂且昂贵的专家评估过程，确保评估结果可靠且与专家一致。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Equal contribution for the first two authors. To appear in\n  proceedings of the Main Conference on 2025 Annual Conference of the Nations\n  of the Americas Chapter of the Association for Computational Linguistics\n  (NAACL). Keywords: Question Generation, USMLE, Self-Refine, Self-Critique,\n  and Self-Correction, LLM-as-Judge, AI for Medical Education",
      "pdf_url": "http://arxiv.org/pdf/2410.13191v4",
      "published_date": "2024-10-17 03:38:29 UTC",
      "updated_date": "2025-02-10 05:52:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:10:58.517780"
    },
    {
      "arxiv_id": "2410.13190v2",
      "title": "CohEx: A Generalized Framework for Cohort Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Fanyu Meng",
        "Xin Liu",
        "Zhaodan Kong",
        "Xin Chen"
      ],
      "abstract": "eXplainable Artificial Intelligence (XAI) has garnered significant attention\nfor enhancing transparency and trust in machine learning models. However, the\nscopes of most existing explanation techniques focus either on offering a\nholistic view of the explainee model (global explanation) or on individual\ninstances (local explanation), while the middle ground, i.e., cohort-based\nexplanation, is less explored. Cohort explanations offer insights into the\nexplainee's behavior on a specific group or cohort of instances, enabling a\ndeeper understanding of model decisions within a defined context. In this\npaper, we discuss the unique challenges and opportunities associated with\nmeasuring cohort explanations, define their desired properties, and create a\ngeneralized framework for generating cohort explanations based on supervised\nclustering.",
      "tldr_zh": "这篇论文关注可解释人工智能(XAI)，指出现有解释技术主要聚焦于全局解释(整体模型视图)或局部解释(单个实例)，而忽略了中间地带的cohort explanations(基于群体的解释)。作者讨论了cohort explanations的独特挑战和机会，定义了其期望属性，并提出一个基于监督聚类的通用框架，以生成对特定实例群体的模型行为洞见。该框架有助于提升模型决策的透明度和信任，为XAI领域提供更全面的解释工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13190v2",
      "published_date": "2024-10-17 03:36:18 UTC",
      "updated_date": "2024-12-11 07:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:11:10.697783"
    },
    {
      "arxiv_id": "2410.13187v3",
      "title": "aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Siyuan Jiang",
        "Jia Li",
        "He Zong",
        "Huanyu Liu",
        "Hao Zhu",
        "Shukai Hu",
        "Erlu Li",
        "Jiazheng Ding",
        "Yu Han",
        "Wei Ning",
        "Gen Wang",
        "Yihong Dong",
        "Kechi Zhang",
        "Ge Li"
      ],
      "abstract": "Large Language Models (LLMs) have been widely used in code completion, and\nresearchers are focusing on scaling up LLMs to improve their accuracy. However,\nlarger LLMs have lower inference efficiency, affecting developers' experience\nand productivity. In this paper, we propose a lightweight and effective LLM for\ncode completion named aiXcoder-7B. Compared to existing LLMs, aiXcoder-7B\nachieves higher code completion accuracy while having smaller scales (i.e., 7\nbillion parameters). We attribute the superiority of aiXcoder-7B to three key\nfactors: (1) Multi-objective training. We employ three training objectives, one\nof which is our proposed Structured Fill-In-the-Middle (SFIM). SFIM considers\nthe syntax structures in code and effectively improves the performance of LLMs\nfor code. (2) Diverse data sampling strategies. They consider inter-file\nrelationships and enhance the capability of LLMs in understanding cross-file\ncontexts. (3) Extensive high-quality data. We establish a rigorous data\ncollection pipeline and consume a total of 1.2 trillion unique tokens for\ntraining aiXcoder-7B. This vast volume of data enables aiXcoder-7B to learn a\nbroad distribution of code. We evaluate aiXcoder-7B in five popular code\ncompletion benchmarks and a new benchmark collected by this paper. The results\nshow that aiXcoder-7B outperforms the latest six LLMs with similar sizes and\neven surpasses four larger LLMs (e.g., StarCoder2-15B and CodeLlama-34B),\npositioning aiXcoder-7B as a lightweight and effective LLM for academia and\nindustry. Finally, we summarize three valuable insights for helping\npractitioners train the next generations of LLMs for code. aiXcoder-7B has been\nopen-souced and gained significant attention. Until January 2025, aiXcoder-7B\nhas received 2,226 GitHub Stars.",
      "tldr_zh": "本篇论文介绍了 aiXcoder-7B，一种轻量级且高效的 Large Language Models (LLMs) 专用于代码处理，能够在仅有 7 亿参数的情况下实现更高的代码补全准确率。论文的关键创新包括多目标训练（如提出的 Structured Fill-In-the-Middle (SFIM) 方法，以优化代码语法结构）、多样化数据采样策略（考虑文件间关系以提升跨文件上下文理解），以及使用 1.2 万亿独特 tokens 的高质量数据进行训练。实验结果显示，aiXcoder-7B 在五个流行基准和一个新基准上超越了六种同规模 LLM，并优于更大模型如 StarCoder2-15B 和 CodeLlama-34B。论文还总结了三个宝贵见解以指导未来 LLM 训练，并已开源，获得超过 2,226 GitHub Stars。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "(1) Accepted by the 47th International Conference on Software\n  Engineering (ICSE 2025). (2) aiXcoder-7B is available at\n  https://github.com/aixcoder-plugin/aiXcoder-7B",
      "pdf_url": "http://arxiv.org/pdf/2410.13187v3",
      "published_date": "2024-10-17 03:32:02 UTC",
      "updated_date": "2025-01-16 12:46:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:11:24.448911"
    },
    {
      "arxiv_id": "2410.13185v5",
      "title": "Chain of Ideas: Revolutionizing Research Via Novel Idea Development with LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Long Li",
        "Weiwen Xu",
        "Jiayan Guo",
        "Ruochen Zhao",
        "Xingxuan Li",
        "Yuqian Yuan",
        "Boqiang Zhang",
        "Yuming Jiang",
        "Yifei Xin",
        "Ronghao Dang",
        "Deli Zhao",
        "Yu Rong",
        "Tian Feng",
        "Lidong Bing"
      ],
      "abstract": "Effective research ideation is a critical step for scientific research.\nHowever, the exponential increase in scientific literature makes it challenging\nfor researchers to stay current with recent advances and identify meaningful\nresearch directions. Recent developments in large language models~(LLMs)\nsuggest a promising avenue for automating the generation of novel research\nideas. However, existing methods for idea generation either trivially prompt\nLLMs or directly expose LLMs to extensive literature without indicating useful\ninformation. Inspired by the research process of human researchers, we propose\na Chain-of-Ideas~(CoI) agent, an LLM-based agent that organizes relevant\nliterature in a chain structure to effectively mirror the progressive\ndevelopment in a research domain. This organization facilitates LLMs to capture\nthe current advancements in research, thereby enhancing their ideation\ncapabilities. Furthermore, we propose Idea Arena, an evaluation protocol that\ncan comprehensively evaluate idea generation methods from different\nperspectives, aligning closely with the preferences of human researchers.\nExperimental results indicate that the CoI agent consistently outperforms other\nmethods and shows comparable quality as humans in research idea generation.\nMoreover, our CoI agent is budget-friendly, with a minimum cost of \\$0.50 to\ngenerate a candidate idea and its corresponding experimental design.",
      "tldr_zh": "本研究针对科学文献爆炸式增长带来的挑战，提出Chain-of-Ideas (CoI)代理，这是一种基于LLM agents的系统，通过将相关文献组织成链式结构，模仿人类研究过程来生成高质量的新研究想法。CoI代理帮助LLM捕捉研究领域的最新进展，从而提升idea generation的能力。同时，论文引入Idea Arena评估协议，从多个角度（如全面性和人类偏好）评估想法生成方法。实验结果表明，CoI代理的表现优于现有方法，其生成想法的质量可与人类相当，且成本极低，每生成一个想法仅需0.50美元。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages,5 figures, conference",
      "pdf_url": "http://arxiv.org/pdf/2410.13185v5",
      "published_date": "2024-10-17 03:26:37 UTC",
      "updated_date": "2024-10-30 09:17:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:11:35.206083"
    },
    {
      "arxiv_id": "2410.13915v1",
      "title": "A Simulation System Towards Solving Societal-Scale Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Puelma Touzel",
        "Sneheel Sarangi",
        "Austin Welch",
        "Gayatri Krishnakumar",
        "Dan Zhao",
        "Zachary Yang",
        "Hao Yu",
        "Ethan Kosak-Hine",
        "Tom Gibbs",
        "Andreea Musulan",
        "Camille Thibault",
        "Busra Tugce Gurbuz",
        "Reihaneh Rabbany",
        "Jean-François Godbout",
        "Kellin Pelrine"
      ],
      "abstract": "The rise of AI-driven manipulation poses significant risks to societal trust\nand democratic processes. Yet, studying these effects in real-world settings at\nscale is ethically and logistically impractical, highlighting a need for\nsimulation tools that can model these dynamics in controlled settings to enable\nexperimentation with possible defenses. We present a simulation environment\ndesigned to address this. We elaborate upon the Concordia framework that\nsimulates offline, `real life' activity by adding online interactions to the\nsimulation through social media with the integration of a Mastodon server. We\nimprove simulation efficiency and information flow, and add a set of\nmeasurement tools, particularly longitudinal surveys. We demonstrate the\nsimulator with a tailored example in which we track agents' political positions\nand show how partisan manipulation of agents can affect election results.",
      "tldr_zh": "这篇论文提出了一种模拟系统，旨在解决大规模社会操纵问题，特别是AI驱动操纵对社会信任和民主过程的风险，通过控制环境进行实验以测试防御策略。研究扩展了Concordia framework，将离线模拟与在线社交媒体互动（如Mastodon server）整合，提高了模拟效率、信息流动，并添加了纵向调查等测量工具。实验示例展示了如何追踪代理的政见，并证明党派操纵可显著影响选举结果，为研究潜在防御措施提供了实用平台。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13915v1",
      "published_date": "2024-10-17 03:16:24 UTC",
      "updated_date": "2024-10-17 03:16:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:11:45.899857"
    },
    {
      "arxiv_id": "2410.13179v1",
      "title": "EH-MAM: Easy-to-Hard Masked Acoustic Modeling for Self-Supervised Speech Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Seth",
        "Ramaneswaran Selvakumar",
        "S Sakshi",
        "Sonal Kumar",
        "Sreyan Ghosh",
        "Dinesh Manocha"
      ],
      "abstract": "In this paper, we present EH-MAM (Easy-to-Hard adaptive Masked Acoustic\nModeling), a novel self-supervised learning approach for speech representation\nlearning. In contrast to the prior methods that use random masking schemes for\nMasked Acoustic Modeling (MAM), we introduce a novel selective and adaptive\nmasking strategy. Specifically, during SSL training, we progressively introduce\nharder regions to the model for reconstruction. Our approach automatically\nselects hard regions and is built on the observation that the reconstruction\nloss of individual frames in MAM can provide natural signals to judge the\ndifficulty of solving the MAM pre-text task for that frame. To identify these\nhard regions, we employ a teacher model that first predicts the frame-wise\nlosses and then decides which frames to mask. By learning to create challenging\nproblems, such as identifying harder frames and solving them simultaneously,\nthe model is able to learn more effective representations and thereby acquire a\nmore comprehensive understanding of the speech. Quantitatively, EH-MAM\noutperforms several state-of-the-art baselines across various low-resource\nspeech recognition and SUPERB benchmarks by 5%-10%. Additionally, we conduct a\nthorough analysis to show that the regions masked by EH-MAM effectively capture\nuseful context across speech frames.",
      "tldr_zh": "本研究提出 EH-MAM，一种从易到难的自适应 Masked Acoustic Modeling (MAM) 方法，用于自监督语音表示学习 (SSL)，通过逐步引入更难的语音区域进行重建来提升模型性能。不同于传统的随机掩码策略，EH-MAM 利用教师模型预测帧级损失，选择难帧进行掩码，从而帮助模型学习更有效的语音表示。实验结果显示，该方法在低资源语音识别和 SUPERB 基准上比现有基线提高5%-10%，并通过分析证明其掩码区域能有效捕捉语音帧间的有用上下文。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13179v1",
      "published_date": "2024-10-17 02:59:22 UTC",
      "updated_date": "2024-10-17 02:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:11:59.231816"
    },
    {
      "arxiv_id": "2410.13178v3",
      "title": "GeSubNet: Gene Interaction Inference for Disease Subtype Network Generation",
      "title_zh": "GeSubNet：用于疾病亚型网络生成的基因交互推断",
      "authors": [
        "Ziwei Yang",
        "Zheng Chen",
        "Xin Liu",
        "Rikuto Kotoge",
        "Peng Chen",
        "Yasuko Matsubara",
        "Yasushi Sakurai",
        "Jimeng Sun"
      ],
      "abstract": "Retrieving gene functional networks from knowledge databases presents a\nchallenge due to the mismatch between disease networks and subtype-specific\nvariations. Current solutions, including statistical and deep learning methods,\noften fail to effectively integrate gene interaction knowledge from databases\nor explicitly learn subtype-specific interactions. To address this mismatch, we\npropose GeSubNet, which learns a unified representation capable of predicting\ngene interactions while distinguishing between different disease subtypes.\nGraphs generated by such representations can be considered subtype-specific\nnetworks. GeSubNet is a multi-step representation learning framework with three\nmodules: First, a deep generative model learns distinct disease subtypes from\npatient gene expression profiles. Second, a graph neural network captures\nrepresentations of prior gene networks from knowledge databases, ensuring\naccurate physical gene interactions. Finally, we integrate these two\nrepresentations using an inference loss that leverages graph generation\ncapabilities, conditioned on the patient separation loss, to refine\nsubtype-specific information in the learned representation. GeSubNet\nconsistently outperforms traditional methods, with average improvements of\n30.6%, 21.0%, 20.1%, and 56.6% across four graph evaluation metrics, averaged\nover four cancer datasets. Particularly, we conduct a biological simulation\nexperiment to assess how the behavior of selected genes from over 11,000\ncandidates affects subtypes or patient distributions. The results show that the\ngenerated network has the potential to identify subtype-specific genes with an\n83% likelihood of impacting patient distribution shifts.",
      "tldr_zh": "本研究提出 GeSubNet，一种多步骤表示学习框架，用于从知识数据库中推断基因交互并生成疾病亚型特定网络，以解决现有方法在整合基因交互知识和学习亚型变异方面的不足。框架包括三个模块：首先，使用深度生成模型从患者基因表达配置文件中学习不同的疾病亚型；其次，采用 Graph Neural Network 捕获先验基因网络的表示，确保准确的物理基因交互；最后，通过推理损失和患者分离损失整合这些表示，提炼亚型特定信息。实验结果显示，GeSubNet 在四个癌症数据集上，比传统方法平均提高了 30.6%、21.0%、20.1% 和 56.6% 的四个图评估指标。此外，通过生物模拟实验，生成的网络能以 83% 的可能性识别影响患者分布的亚型特定基因。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13178v3",
      "published_date": "2024-10-17 02:58:57 UTC",
      "updated_date": "2025-02-22 04:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:12:11.039927"
    },
    {
      "arxiv_id": "2410.13175v2",
      "title": "TCP-Diffusion: A Multi-modal Diffusion Model for Global Tropical Cyclone Precipitation Forecasting with Change Awareness",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Huang",
        "Pan Mu",
        "Cong Bai",
        "Peter AG Watson"
      ],
      "abstract": "Precipitation from tropical cyclones (TCs) can cause disasters such as\nflooding, mudslides, and landslides. Predicting such precipitation in advance\nis crucial, giving people time to prepare and defend against these\nprecipitation-induced disasters. Developing deep learning (DL) rainfall\nprediction methods offers a new way to predict potential disasters. However,\none problem is that most existing methods suffer from cumulative errors and\nlack physical consistency. Second, these methods overlook the importance of\nmeteorological factors in TC rainfall and their integration with the numerical\nweather prediction (NWP) model. Therefore, we propose Tropical Cyclone\nPrecipitation Diffusion (TCP-Diffusion), a multi-modal model for global\ntropical cyclone precipitation forecasting. It forecasts TC rainfall around the\nTC center for the next 12 hours at 3 hourly resolution based on past rainfall\nobservations and multi-modal environmental variables. Adjacent residual\nprediction (ARP) changes the training target from the absolute rainfall value\nto the rainfall trend and gives our model the ability of rainfall change\nawareness, reducing cumulative errors and ensuring physical consistency.\nConsidering the influence of TC-related meteorological factors and the useful\ninformation from NWP model forecasts, we propose a multi-model framework with\nspecialized encoders to extract richer information from environmental variables\nand results provided by NWP models. The results of extensive experiments show\nthat our method outperforms other DL methods and the NWP method from the\nEuropean Centre for Medium-Range Weather Forecasts (ECMWF).",
      "tldr_zh": "这篇论文提出了 TCP-Diffusion，一种多模态扩散模型，用于全球热带气旋降雨预测，旨在解决现有方法的累积错误和物理一致性问题。模型通过 Adjacent Residual Prediction (ARP) 将训练目标从绝对降雨值转向降雨趋势，提升对降雨变化的感知，并整合多模态环境变量及数值天气预报 (NWP) 模型的信息，以实现更准确的12小时预测。实验结果表明，TCP-Diffusion 优于其他深度学习方法和欧洲中期数值天气预报中心 (ECMWF) 的 NWP 方法，为热带气旋引发的灾害防范提供更可靠的支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "Camera-ready version. This paper has been accepted to ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13175v2",
      "published_date": "2024-10-17 02:58:05 UTC",
      "updated_date": "2025-05-18 02:30:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:12:23.060965"
    },
    {
      "arxiv_id": "2410.13166v4",
      "title": "An Evolved Universal Transformer Memory",
      "title_zh": "翻译失败",
      "authors": [
        "Edoardo Cetin",
        "Qi Sun",
        "Tianyu Zhao",
        "Yujin Tang"
      ],
      "abstract": "Prior methods propose to offset the escalating costs of modern foundation\nmodels by dropping specific parts of their contexts with hand-designed rules,\nwhile attempting to preserve their original performance. We overcome this\ntrade-off with Neural Attention Memory Models (NAMMs), introducing a learned\nnetwork for memory management that improves both the performance and efficiency\nof transformers. We evolve NAMMs atop pre-trained transformers to provide\ndifferent latent contexts focusing on the most relevant information for\nindividual layers and attention heads. NAMMs are universally applicable to any\nmodel using self-attention as they condition exclusively on the values in the\nproduced attention matrices. Learning NAMMs on a small set of problems, we\nachieve substantial performance improvements across multiple long-context\nbenchmarks while cutting the model's input contexts up to a fraction of the\noriginal sizes. We show the generality of our conditioning enables zero-shot\ntransfer of NAMMs trained only on language to entirely new transformer\narchitectures even across input modalities, with their benefits carrying over\nto vision and reinforcement learning.",
      "tldr_zh": "本文提出Neural Attention Memory Models (NAMMs)，一个可学习的网络，用于提升Transformer模型的性能和效率，通过演化NAMMs在预训练Transformer上管理注意力矩阵，提供针对特定层和注意力头的相关潜在上下文。NAMMs仅依赖于注意力矩阵的值，使其适用于任何使用自注意力的模型，并在少量问题上训练后，在多个长上下文基准上实现了显著性能提升，同时将输入上下文减少到原大小的一小部分。该方法展示了通用性，支持从语言模型的零样本转移到视觉和强化学习等新模态。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at ICLR 2025. Source code available at\n  https://github.com/SakanaAI/evo-memory",
      "pdf_url": "http://arxiv.org/pdf/2410.13166v4",
      "published_date": "2024-10-17 02:47:10 UTC",
      "updated_date": "2025-02-13 09:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:12:34.576026"
    },
    {
      "arxiv_id": "2410.13147v8",
      "title": "Utilizing Large Language Models in an iterative paradigm with domain feedback for zero-shot molecule optimization",
      "title_zh": "利用大型语言模型在迭代范式中结合领域反馈进行零样本分子优化",
      "authors": [
        "Khiem Le",
        "Nitesh V. Chawla"
      ],
      "abstract": "Molecule optimization is a critical task in drug discovery to optimize\ndesired properties of a given molecule. Despite Large Language Models (LLMs)\nholding the potential to efficiently simulate this task by using natural\nlanguage to direct the optimization, straightforwardly utilizing them shows\nlimited performance. In this work, we facilitate utilizing LLMs in an iterative\nparadigm by proposing a simple yet effective domain feedback provider, namely\n$\\text{Re}^2$DF. In detail, $\\text{Re}^2$DF harnesses an external toolkit,\nRDKit, to handle the molecule hallucination, if the modified molecule is\nchemically invalid. Otherwise, $\\text{Re}^2$DF verifies whether the modified\nmolecule meets the objective, if not, its desired properties are computed and\ncompared to the original one, establishing reliable domain feedback with\ncorrect direction and distance towards the objective to explicitly guide the\nLLM to refine the modified molecule. We conduct experiments across both single-\nand multi-property objectives with 2 thresholds, where $\\text{Re}^2$DF shows\nsignificant improvements. Notably, for 20 single-property objectives,\n$\\text{Re}^2$DF enhances Hit ratio by 16.96% and 20.76% under loose\n(\\texttt{l}) and strict (\\texttt{s}) thresholds, respectively. For 32\nmulti-property objectives, $\\text{Re}^2$DF enhances Hit ratio by 6.04% and\n5.25%.",
      "tldr_zh": "这篇论文探讨了在零-shot molecule optimization 中利用 Large Language Models (LLMs) 的迭代范式，以优化药物发现中的分子属性。论文提出了一种简单有效的领域反馈提供者 $\\text{Re}^2$DF，利用外部工具 RDKit 处理分子 hallucination（如果修改分子化学无效），并通过计算属性差异提供可靠的反馈，包括方向和距离，以指导 LLM 进一步改进分子。实验结果显示，$\\text{Re}^2$DF 在 20 个单属性目标上将 Hit ratio 提高了 16.96% 和 20.76%，而在 32 个多属性目标上提升了 6.04% 和 5.25%，证明了其在提升优化性能方面的显著贡献。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13147v8",
      "published_date": "2024-10-17 02:04:57 UTC",
      "updated_date": "2025-01-23 20:19:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:12:47.113943"
    },
    {
      "arxiv_id": "2410.13121v1",
      "title": "Trust but Verify: Programmatic VLM Evaluation in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Viraj Prabhu",
        "Senthil Purushwalkam",
        "An Yan",
        "Caiming Xiong",
        "Ran Xu"
      ],
      "abstract": "Vision-Language Models (VLMs) often generate plausible but incorrect\nresponses to visual queries. However, reliably quantifying the effect of such\nhallucinations in free-form responses to open-ended queries is challenging as\nit requires visually verifying each claim within the response. We propose\nProgrammatic VLM Evaluation (PROVE), a new benchmarking paradigm for evaluating\nVLM responses to open-ended queries. To construct PROVE, we provide a large\nlanguage model (LLM) with a high-fidelity scene-graph representation\nconstructed from a hyper-detailed image caption, and prompt it to generate\ndiverse question-answer (QA) pairs, as well as programs that can be executed\nover the scene graph object to verify each QA pair. We thus construct a\nbenchmark of 10.5k challenging but visually grounded QA pairs. Next, to\nevaluate free-form model responses to queries in PROVE, we propose a\nprogrammatic evaluation strategy that measures both the helpfulness and\ntruthfulness of a response within a unified scene graph-based framework. We\nbenchmark the helpfulness-truthfulness trade-offs of a range of VLMs on PROVE,\nfinding that very few are in-fact able to achieve a good balance between the\ntwo. Project page: \\url{https://prove-explorer.netlify.app/}.",
      "tldr_zh": "本文提出 Programmatic VLM Evaluation (PROVE)，一种新的基准测试范式，用于评估视觉语言模型 (VLMs) 对开放查询的自由形式响应，旨在量化并解决 VLMs 的幻觉问题。方法包括使用大型语言模型 (LLM) 和基于超详细图像标题构建的高保真场景图 (scene-graph representation) 生成10.5k个多样化的问答 (QA) 对，并开发可执行程序来验证每个 QA 对的准确性。实验结果显示，通过统一的场景图框架评估 VLMs 的帮助性和真实性 (helpfulness and truthfulness)，发现很少模型能实现两者之间的良好平衡，为更可靠的 VLM 评估提供了新框架。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13121v1",
      "published_date": "2024-10-17 01:19:18 UTC",
      "updated_date": "2024-10-17 01:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:12:59.586835"
    },
    {
      "arxiv_id": "2410.13117v2",
      "title": "Preference Diffusion for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Liu",
        "An Zhang",
        "Guoqing Hu",
        "Hong Qian",
        "Tat-seng Chua"
      ],
      "abstract": "Recommender systems predict personalized item rankings based on user\npreference distributions derived from historical behavior data. Recently,\ndiffusion models (DMs) have gained attention in recommendation for their\nability to model complex distributions, yet current DM-based recommenders often\nrely on traditional objectives like mean squared error (MSE) or recommendation\nobjectives, which are not optimized for personalized ranking tasks or fail to\nfully leverage DM's generative potential. To address this, we propose\nPreferDiff, a tailored optimization objective for DM-based recommenders.\nPreferDiff transforms BPR into a log-likelihood ranking objective and\nintegrates multiple negative samples to better capture user preferences.\nSpecifically, we employ variational inference to handle the intractability\nthrough minimizing the variational upper bound and replaces MSE with cosine\nerror to improve alignment with recommendation tasks. Finally, we balance\nlearning generation and preference to enhance the training stability of DMs.\nPreferDiff offers three key benefits: it is the first personalized ranking loss\ndesigned specifically for DM-based recommenders and it improves ranking and\nfaster convergence by addressing hard negatives. We also prove that it is\ntheoretically connected to Direct Preference Optimization which indicates that\nit has the potential to align user preferences in DM-based recommenders via\ngenerative modeling. Extensive experiments across three benchmarks validate its\nsuperior recommendation performance and commendable general sequential\nrecommendation capabilities. Our codes are available at\nhttps://github.com/lswhim/PreferDiff.",
      "tldr_zh": "这篇论文针对推荐系统中的Diffusion Models (DMs)，提出了一种新的优化目标PreferDiff，以更好地捕捉用户偏好并提升个性化排名性能。PreferDiff将BPR转化为log-likelihood排名目标，整合多负样本，并通过variational inference最小化上界、用cosine error替换MSE，同时平衡生成和偏好学习来提高训练稳定性。该方法不仅是首个为DM-based推荐器设计的个性化排名损失，还理论上与Direct Preference Optimization相关联，并在三个基准实验中验证了其优越的推荐性能和更快收敛能力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.13117v2",
      "published_date": "2024-10-17 01:02:04 UTC",
      "updated_date": "2025-04-20 10:42:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:13:11.010872"
    },
    {
      "arxiv_id": "2410.13116v2",
      "title": "Learning to Summarize from LLM-generated Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Hwanjun Song",
        "Taewon Yun",
        "Yuho Lee",
        "Jihwan Oh",
        "Gihun Lee",
        "Jason Cai",
        "Hang Su"
      ],
      "abstract": "Developing effective text summarizers remains a challenge due to issues like\nhallucinations, key information omissions, and verbosity in LLM-generated\nsummaries. This work explores using LLM-generated feedback to improve summary\nquality by aligning the summaries with human preferences for faithfulness,\ncompleteness, and conciseness. We introduce FeedSum, a large-scale dataset\ncontaining multi-dimensional LLM feedback on summaries of varying quality\nacross diverse domains. Our experiments show how feedback quality,\ndimensionality, and granularity influence preference learning, revealing that\nhigh-quality, multi-dimensional, fine-grained feedback significantly improves\nsummary generation. We also compare two methods for using this feedback:\nsupervised fine-tuning and direct preference optimization. Finally, we\nintroduce SummLlama3-8b, a model that outperforms the nearly 10x larger\nLlama3-70b-instruct in generating human-preferred summaries, demonstrating that\nsmaller models can achieve superior performance with appropriate training. The\nfull dataset and SummLlama3-8B model are available at\nhttps://huggingface.co/datasets/DISLab/FeedSum and\nhttps://huggingface.co/DISLab/SummLlama3-8B.",
      "tldr_zh": "这篇论文探讨了利用 LLM 生成的反馈来提升文本摘要质量的问题，旨在解决 LLM 摘要中的幻觉、关键信息遗漏和冗长等问题，通过将摘要与人类偏好（如忠实性、完整性和简洁性）对齐。作者引入了 FeedSum 数据集，这是一个大规模数据集，包含多维度 LLM 反馈，涵盖不同领域和质量水平的摘要，并通过实验分析了反馈的质量、多维性和粒度对偏好学习的影响。研究比较了监督微调和直接偏好优化两种方法，结果显示高质量、多维细粒度的反馈能显著改善摘要生成。最终，他们开发了 SummLlama3-8b 模型，该模型在生成人类偏好的摘要方面超过了近 10 倍大的 Llama3-70b-instruct 模型，证明了通过适当训练，较小模型也能实现优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NAACL 2025 (main, long)",
      "pdf_url": "http://arxiv.org/pdf/2410.13116v2",
      "published_date": "2024-10-17 01:01:09 UTC",
      "updated_date": "2025-01-25 15:54:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:13:23.167990"
    },
    {
      "arxiv_id": "2410.13114v1",
      "title": "Sound Check: Auditing Audio Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "William Agnew",
        "Julia Barnett",
        "Annie Chu",
        "Rachel Hong",
        "Michael Feffer",
        "Robin Netzorg",
        "Harry H. Jiang",
        "Ezra Awumey",
        "Sauvik Das"
      ],
      "abstract": "Generative audio models are rapidly advancing in both capabilities and public\nutilization -- several powerful generative audio models have readily available\nopen weights, and some tech companies have released high quality generative\naudio products. Yet, while prior work has enumerated many ethical issues\nstemming from the data on which generative visual and textual models have been\ntrained, we have little understanding of similar issues with generative audio\ndatasets, including those related to bias, toxicity, and intellectual property.\nTo bridge this gap, we conducted a literature review of hundreds of audio\ndatasets and selected seven of the most prominent to audit in more detail. We\nfound that these datasets are biased against women, contain toxic stereotypes\nabout marginalized communities, and contain significant amounts of copyrighted\nwork. To enable artists to see if they are in popular audio datasets and\nfacilitate exploration of the contents of these datasets, we developed a web\ntool audio datasets exploration tool at https://audio-audit.vercel.app.",
      "tldr_zh": "这篇论文审计了生成音频数据集中的偏见(bias)、毒性(toxicity)以及知识产权(intellectual property)问题，强调这些数据集可能加剧性别和种族不平等。作者通过文献综述筛选并详细检查了七个主要音频数据集，发现它们对女性存在偏见、包含针对边缘化社区的毒性刻板印象，以及大量受版权保护的内容。最终，研究团队开发了一个网络工具（https://audio-audit.vercel.app），帮助艺术家检查其作品是否包含在这些数据集，并促进数据集内容的探索。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CY",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13114v1",
      "published_date": "2024-10-17 00:51:27 UTC",
      "updated_date": "2024-10-17 00:51:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:13:34.767154"
    },
    {
      "arxiv_id": "2410.13106v3",
      "title": "Cliqueformer: Model-Based Optimization with Structured Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Jakub Grudzien Kuba",
        "Pieter Abbeel",
        "Sergey Levine"
      ],
      "abstract": "Large neural networks excel at prediction tasks, but their application to\ndesign problems, such as protein engineering or materials discovery, requires\nsolving offline model-based optimization (MBO) problems. While predictive\nmodels may not directly translate to effective design, recent MBO algorithms\nincorporate reinforcement learning and generative modeling approaches.\nMeanwhile, theoretical work suggests that exploiting the target function's\nstructure can enhance MBO performance. We present Cliqueformer, a\ntransformer-based architecture that learns the black-box function's structure\nthrough functional graphical models (FGM), addressing distribution shift\nwithout relying on explicit conservative approaches. Across various domains,\nincluding chemical and genetic design tasks, Cliqueformer demonstrates superior\nperformance compared to existing methods.",
      "tldr_zh": "该研究探讨了大型神经网络在设计问题（如蛋白工程和材料发现）中的应用，强调了离线模型驱动优化 (MBO) 的重要性，并指出现有方法如强化学习和生成模型可能不足以利用目标函数的结构。论文提出 Cliqueformer，一种基于 Structured Transformers 的架构，通过功能图形模型 (FGM) 学习黑箱函数的结构，从而处理分布偏移问题，而不依赖保守策略。在化学和遗传设计任务等多个领域，Cliqueformer 比现有方法表现出显著优越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13106v3",
      "published_date": "2024-10-17 00:35:47 UTC",
      "updated_date": "2025-02-05 21:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:13:47.122957"
    },
    {
      "arxiv_id": "2410.13098v1",
      "title": "A Little Human Data Goes A Long Way",
      "title_zh": "翻译失败",
      "authors": [
        "Dhananjay Ashok",
        "Jonathan May"
      ],
      "abstract": "Faced with an expensive human annotation process, creators of NLP systems\nincreasingly turn to synthetic data generation. While this method shows\npromise, the extent to which synthetic data can replace human annotation is\npoorly understood. We investigate the use of synthetic data in Fact\nVerification (FV) and Question Answering (QA) by studying the effects of\nincrementally replacing human generated data with synthetic points on eight\ndiverse datasets. Strikingly, replacing up to 90% of the training data only\nmarginally decreases performance, but replacing the final 10% leads to severe\ndeclines. We find that models trained on purely synthetic data can be reliably\nimproved by including as few as 125 human generated data points. We show that\nmatching the performance gain of just a little additional human data (only 200\npoints) requires an order of magnitude more synthetic data and estimate price\nratios at which human annotation would be a more cost-effective solution. Our\nresults suggest that even when human annotation at scale is infeasible, there\nis great value to having a small proportion of the dataset being human\ngenerated.",
      "tldr_zh": "本文研究了在自然语言处理（NLP）任务中，使用合成数据替换人类标注数据的效果，特别是在Fact Verification (FV)和Question Answering (QA)领域，通过在八个数据集上逐步替换数据进行评估。主要发现是，替换高达90%的训练数据仅导致性能轻微下降，但替换最后10%会造成显著下降；此外，仅添加125个人类数据点即可显著提升纯合成数据模型的性能。研究还比较了成本效益，指出添加少量人类数据（例如200点）的收益，需要10倍以上的合成数据才能匹敌，并建议即使大规模人类标注不可行，小比例人类数据也能带来巨大价值。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.13098v1",
      "published_date": "2024-10-17 00:04:02 UTC",
      "updated_date": "2024-10-17 00:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T13:13:59.461783"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 176,
  "processed_papers_count": 176,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T13:14:17.698540"
}