{
  "date": "2024-12-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-12-14 的 arXiv 中文 TLDR 快报！今天的论文主要聚焦于 AI 在医疗推理、计算机视觉、语言模型和强化学习等领域的创新应用，亮点包括大型语言模型（LLM）在医疗决策上超越人类表现，以及高效的图像生成和蛋白质对接模型；令人印象深刻的文章有第 27 篇的超人级医疗推理，以及第 8 篇的药物发现工具；知名学者如 Jure Leskovec 在第 5 篇中参与的混合预测系统值得关注。\n\n下面，我将挑选重点论文优先讨论，将相关主题归类（如 AI 代理和医疗应用），并快速掠过次要内容。每篇论文会列出标题（中文 + 英文），并简要描述主要贡献和发现。\n\n### AI 代理与协作工具\n- **Cocoa: Co-Planning and Co-Execution with AI Agents（Cocoa: 与 AI 代理的联合规划和执行）**  \n  这篇论文引入了交互式计划设计，支持人类与 AI 代理在多步任务中的协作。通过实验验证，Cocoa 提升了代理的可控性，同时保持易用性，主要贡献是提出一种新型的人机协作范式，适用于复杂任务如科学研究。\n\n- **Composers' Evaluations of an AI Music Tool: Insights for Human-Centred Design（作曲家对 AI 音乐工具的评估：人类中心设计的洞见）**  \n  作者探讨了生成式 AI 在音乐创作中的用户中心设计，通过作曲家访谈优化模型的透明度和可控性。关键发现是强调信任和可追溯性，以改进 AI 工具的实际应用。\n\n### 计算机视觉与图像处理\n- **RapidNet: Multi-Level Dilated Convolution Based Mobile Backbone（RapidNet: 基于多级扩张卷积的移动骨干网络）**  \n  这篇令人印象深刻的论文提出了一种纯 CNN 架构，优于混合模型，在图像分类和检测任务中实现更快速度和更高准确率（如 ImageNet-1K 上 76.3% top-1 准确率）。主要贡献是利用多级扩张卷积扩展感受野，提升移动设备上的视觉性能。\n\n- **SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer（SoftVQ-VAE: 高效的 1 维连续标记器）**  \n  论文开发了一种图像标记方法，支持高压缩比的生成模型，显著加速图像生成（如 256x256 图像生成速度提升 18 倍）。核心发现是聚合多个代码词增强表示能力，适用于变分自编码器。\n\n- **FlowDock: Geometric Flow Matching for Generative Protein-Ligand Docking and Affinity Prediction（FlowDock: 用于生成蛋白-配体对接和亲和力预测的几何流匹配）**  \n  这篇有话题度的论文提出基于条件流匹配的模型，支持多配体对接和亲和力估计，在药物发现中表现出色（如 CASP16 排名前五）。主要贡献是直接从非结合结构映射到结合结构，提高虚拟筛选效率。\n\n### 医疗 AI 与推理\n- **Superhuman performance of a large language model on the reasoning tasks of a physician（大型语言模型在医生推理任务上的超人表现）**  \n  这是今日最引人注目的论文之一，LLM 在临床推理任务中超越人类专家，通过真实急诊案例验证。关键发现是 LLM 在诊断和管理的表现优于医生，强调了其在医疗决策中的潜力，但需进一步临床试验。\n\n- **MedG-KRP: Medical Graph Knowledge Representation Probing（MedG-KRP: 医疗图知识表示探查）**  \n  作者评估 LLM 在生物医学推理中的能力，使用知识图谱比较模型表现。核心贡献是可视化 LLM 的推理路径，帮助安全部署临床应用，如 GPT-4 在人类评估中表现最佳。\n\n- **LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages（LLMs-in-the-Loop 第 2 部分: 用于多语言 PHI 匿名化和去标识的专家小型 AI 模型）**  \n  论文开发了小型 AI 模型处理医疗数据隐私，支持多语言（如英语和阿拉伯语）。主要发现是这些模型在去标识任务中优于 GPT-4，提供更安全且高效的解决方案。\n\n其他论文主题多样，以次要或快速形式提及：\n- **Hybrid Forecasting of Geopolitical Events（混合预测地缘政治事件）** 和 **Navigating Dialectal Bias and Ethical Complexities in Levantine Arabic Hate Speech Detection（处理黎凡特阿拉伯语仇恨言论检测中的方言偏差和伦理复杂性）**：前者提出混合人类-机器预测系统，提升事件预测准确性；后者强调文化敏感的 NLP 工具，快速掠过作为伦理 AI 的补充。\n- **PSMGD: Periodic Stochastic Multi-Gradient Descent for Fast Multi-Objective Optimization（PSMGD: 用于快速多目标优化的周期随机多梯度下降）** 和 **ST-FiT: Inductive Spatial-Temporal Forecasting with Limited Training Data（ST-FiT: 基于有限训练数据的归纳时空预测）**：分别优化多目标学习和时空预测效率，贡献在于减少计算开销和数据需求。\n- 其余如 **TinySubNets（微型子网络）**、**WaveGNN（波形图神经网络）** 和 **RAT: Adversarial Attacks on Deep Reinforcement Agents（RAT: 对深度强化代理的对抗攻击）** 等，均展示了 AI 效率提升，但非核心焦点，仅提及其在连续学习和攻击防御中的进展。\n\n总之，今天的 arXiv 更新突显 AI 在实际应用中的潜力，特别是医疗和视觉领域，但也提醒了模型鲁棒性和伦理挑战。感兴趣的读者可关注上述亮点论文进行深入阅读！",
  "papers": [
    {
      "arxiv_id": "2412.10999v3",
      "title": "Cocoa: Co-Planning and Co-Execution with AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "K. J. Kevin Feng",
        "Kevin Pu",
        "Matt Latzke",
        "Tal August",
        "Pao Siangliulue",
        "Jonathan Bragg",
        "Daniel S. Weld",
        "Amy X. Zhang",
        "Joseph Chee Chang"
      ],
      "abstract": "Human collaboration benefits from continuous coordination -- planning,\ndelegating tasks, sharing progress, and adjusting objectives -- to align on\nshared goals. However, agentic AI systems often limit users to previewing or\nreviewing an agent's plans for fully autonomous execution. While this may be\nuseful for confirmation and correction, it does not support deeper\ncollaboration between humans and AI agents. We present Cocoa, a system that\nintroduces a novel design pattern -- interactive plans -- for collaborating\nwith an AI agent on complex, multi-step tasks. Informed by a formative study\n($n=9$), Cocoa builds on interaction designs from computational notebooks and\ndocument editors to support flexible delegation of agency through Co-planning\nand Co-execution, where users collaboratively compose and execute plans with an\nAgent. Using scientific research as a sample domain, our lab (n=16) and field\ndeployment (n=7) studies found that Cocoa improved agent steerability without\nsacrificing ease-of-use compared to a strong chat baseline. Additionally,\nresearchers valued Cocoa for real-world projects and saw the interleaving of\nco-planning and co-execution as an effective novel paradigm for human-AI\ncollaboration.",
      "tldr_zh": "该论文介绍了 Cocoa 系统，一种支持人类与 AI 代理深度协作的新设计模式，通过交互式计划（interactive plans）实现共同规划（Co-planning）和共同执行（Co-execution），以处理复杂多步任务。系统借鉴计算笔记本和文档编辑器的交互设计，并基于一个成型研究（formative study, n=9）进行开发，以科学研究领域为样本。实验结果显示，在实验室研究（n=16）和现场部署（n=7）中，Cocoa 相对于聊天基线提升了代理的可操控性（agent steerability），而不降低易用性，且研究人员认为其为真实项目提供了有效的人类-AI 协作范式。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10999v3",
      "published_date": "2024-12-14 23:59:42 UTC",
      "updated_date": "2025-04-15 18:47:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:33:55.954101"
    },
    {
      "arxiv_id": "2412.10995v1",
      "title": "RapidNet: Multi-Level Dilated Convolution Based Mobile Backbone",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Munir",
        "Md Mostafijur Rahman",
        "Radu Marculescu"
      ],
      "abstract": "Vision transformers (ViTs) have dominated computer vision in recent years.\nHowever, ViTs are computationally expensive and not well suited for mobile\ndevices; this led to the prevalence of convolutional neural network (CNN) and\nViT-based hybrid models for mobile vision applications. Recently, Vision GNN\n(ViG) and CNN hybrid models have also been proposed for mobile vision tasks.\nHowever, all of these methods remain slower compared to pure CNN-based models.\nIn this work, we propose Multi-Level Dilated Convolutions to devise a purely\nCNN-based mobile backbone. Using Multi-Level Dilated Convolutions allows for a\nlarger theoretical receptive field than standard convolutions. Different levels\nof dilation also allow for interactions between the short-range and long-range\nfeatures in an image. Experiments show that our proposed model outperforms\nstate-of-the-art (SOTA) mobile CNN, ViT, ViG, and hybrid architectures in terms\nof accuracy and/or speed on image classification, object detection, instance\nsegmentation, and semantic segmentation. Our fastest model, RapidNet-Ti,\nachieves 76.3\\% top-1 accuracy on ImageNet-1K with 0.9 ms inference latency on\nan iPhone 13 mini NPU, which is faster and more accurate than MobileNetV2x1.4\n(74.7\\% top-1 with 1.0 ms latency). Our work shows that pure CNN architectures\ncan beat SOTA hybrid and ViT models in terms of accuracy and speed when\ndesigned properly.",
      "tldr_zh": "本研究针对视觉变换器(ViTs)计算开销大、不适合移动设备的问题，提出了一种纯CNN架构RapidNet，该模型基于Multi-Level Dilated Convolutions，利用多级扩张卷积扩大理论感受野并促进图像中短距离和长距离特征的交互。相比现有的CNN、ViT、ViG和混合模型，RapidNet在图像分类、物体检测、实例分割和语义分割任务上实现了更高的准确性和速度优势。实验结果显示，RapidNet-Ti在ImageNet-1K上达到76.3% top-1准确率，并在iPhone 13 mini NPU上实现0.9 ms推理延迟，比MobileNetV2x1.4更快更准确。该工作证明了设计得当的纯CNN架构可超越SOTA混合和ViT模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in 2025 IEEE/CVF Winter Conference on Applications of\n  Computer Vision (WACV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.10995v1",
      "published_date": "2024-12-14 23:39:03 UTC",
      "updated_date": "2024-12-14 23:39:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:34:07.974895"
    },
    {
      "arxiv_id": "2412.10991v1",
      "title": "Navigating Dialectal Bias and Ethical Complexities in Levantine Arabic Hate Speech Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Ahmed Haj Ahmed",
        "Rui-Jie Yew",
        "Xerxes Minocher",
        "Suresh Venkatasubramanian"
      ],
      "abstract": "Social media platforms have become central to global communication, yet they\nalso facilitate the spread of hate speech. For underrepresented dialects like\nLevantine Arabic, detecting hate speech presents unique cultural, ethical, and\nlinguistic challenges. This paper explores the complex sociopolitical and\nlinguistic landscape of Levantine Arabic and critically examines the\nlimitations of current datasets used in hate speech detection. We highlight the\nscarcity of publicly available, diverse datasets and analyze the consequences\nof dialectal bias within existing resources. By emphasizing the need for\nculturally and contextually informed natural language processing (NLP) tools,\nwe advocate for a more nuanced and inclusive approach to hate speech detection\nin the Arab world.",
      "tldr_zh": "这篇论文探讨了在黎凡特阿拉伯语(Levantine Arabic)仇恨言论检测中存在的方言偏见(dialectal bias)和伦理复杂性(ethical complexities)，强调了社交媒体平台上文化、伦理及语言挑战。作者分析了现有数据集的稀缺性和偏见问题，并批评这些资源未能充分反映黎凡特阿拉伯语的社会政治和语言景观。论文主张开发更注重文化和语境的自然语言处理(NLP)工具，以实现对阿拉伯世界仇恨言论的更细致和包容式检测。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10991v1",
      "published_date": "2024-12-14 23:02:46 UTC",
      "updated_date": "2024-12-14 23:02:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:34:19.577732"
    },
    {
      "arxiv_id": "2412.10982v2",
      "title": "MedG-KRP: Medical Graph Knowledge Representation Probing",
      "title_zh": "翻译失败",
      "authors": [
        "Gabriel R. Rosenbaum",
        "Lavender Yao Jiang",
        "Ivaxi Sheth",
        "Jaden Stryker",
        "Anton Alyakin",
        "Daniel Alexander Alber",
        "Nicolas K. Goff",
        "Young Joon Fred Kwon",
        "John Markert",
        "Mustafa Nasir-Moin",
        "Jan Moritz Niehues",
        "Karl L. Sangwon",
        "Eunice Yang",
        "Eric Karl Oermann"
      ],
      "abstract": "Large language models (LLMs) have recently emerged as powerful tools, finding\nmany medical applications. LLMs' ability to coalesce vast amounts of\ninformation from many sources to generate a response-a process similar to that\nof a human expert-has led many to see potential in deploying LLMs for clinical\nuse. However, medicine is a setting where accurate reasoning is paramount. Many\nresearchers are questioning the effectiveness of multiple choice question\nanswering (MCQA) benchmarks, frequently used to test LLMs. Researchers and\nclinicians alike must have complete confidence in LLMs' abilities for them to\nbe deployed in a medical setting. To address this need for understanding, we\nintroduce a knowledge graph (KG)-based method to evaluate the biomedical\nreasoning abilities of LLMs. Essentially, we map how LLMs link medical concepts\nin order to better understand how they reason. We test GPT-4, Llama3-70b, and\nPalmyraMed-70b, a specialized medical model. We enlist a panel of medical\nstudents to review a total of 60 LLM-generated graphs and compare these graphs\nto BIOS, a large biomedical KG. We observe GPT-4 to perform best in our human\nreview but worst in our ground truth comparison; vice-versa with PalmyraMed,\nthe medical model. Our work provides a means of visualizing the medical\nreasoning pathways of LLMs so they can be implemented in clinical settings\nsafely and effectively.",
      "tldr_zh": "本文提出 MedG-KRP，一种基于知识图谱（KG）的评估方法，用于检验大型语言模型（LLMs）的生物医学推理能力，以弥补传统多选题（MCQA）基准的局限性。研究方法包括映射 LLMs 如何连接医疗概念、生成图谱，并由医疗学生审查60个图谱，与现有生物医学 KG（BIOS）进行比较。实验测试了 GPT-4、Llama3-70b 和 PalmyraMed-70b，结果显示 GPT-4 在人类评估中表现最佳，但在地面真相比较中最差，而 PalmyraMed 则相反。此方法提供可视化 LLMs 医疗推理路径的手段，有助于确保其在临床环境中的安全有效部署。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Findings paper presented at Machine Learning for Health (ML4H)\n  symposium 2024, December 15-16, 2024, Vancouver, Canada, 19 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.10982v2",
      "published_date": "2024-12-14 22:23:20 UTC",
      "updated_date": "2024-12-17 02:06:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:34:32.546808"
    },
    {
      "arxiv_id": "2412.10981v1",
      "title": "Hybrid Forecasting of Geopolitical Events",
      "title_zh": "地缘政治事件的混合预测",
      "authors": [
        "Daniel M. Benjamin",
        "Fred Morstatter",
        "Ali E. Abbas",
        "Andres Abeliuk",
        "Pavel Atanasov",
        "Stephen Bennett",
        "Andreas Beger",
        "Saurabh Birari",
        "David V. Budescu",
        "Michele Catasta",
        "Emilio Ferrara",
        "Lucas Haravitch",
        "Mark Himmelstein",
        "KSM Tozammel Hossain",
        "Yuzhong Huang",
        "Woojeong Jin",
        "Regina Joseph",
        "Jure Leskovec",
        "Akira Matsui",
        "Mehrnoosh Mirtaheri",
        "Xiang Ren",
        "Gleb Satyukov",
        "Rajiv Sethi",
        "Amandeep Singh",
        "Rok Sosic",
        "Mark Steyvers",
        "Pedro A Szekely",
        "Michael D. Ward",
        "Aram Galstyan"
      ],
      "abstract": "Sound decision-making relies on accurate prediction for tangible outcomes\nranging from military conflict to disease outbreaks. To improve crowdsourced\nforecasting accuracy, we developed SAGE, a hybrid forecasting system that\ncombines human and machine generated forecasts. The system provides a platform\nwhere users can interact with machine models and thus anchor their judgments on\nan objective benchmark. The system also aggregates human and machine forecasts\nweighting both for propinquity and based on assessed skill while adjusting for\noverconfidence. We present results from the Hybrid Forecasting Competition\n(HFC) - larger than comparable forecasting tournaments - including 1085 users\nforecasting 398 real-world forecasting problems over eight months. Our main\nresult is that the hybrid system generated more accurate forecasts compared to\na human-only baseline which had no machine generated predictions. We found that\nskilled forecasters who had access to machine-generated forecasts outperformed\nthose who only viewed historical data. We also demonstrated the inclusion of\nmachine-generated forecasts in our aggregation algorithms improved performance,\nboth in terms of accuracy and scalability. This suggests that hybrid\nforecasting systems, which potentially require fewer human resources, can be a\nviable approach for maintaining a competitive level of accuracy over a larger\nnumber of forecasting questions.",
      "tldr_zh": "该研究开发了SAGE混合预测系统，结合人类判断和机器生成预测，以提升地缘政治事件（如军事冲突或疾病爆发）的预测准确性。系统提供互动平台，让用户基于机器基准锚定判断，并通过加权聚合算法（考虑接近性、技能评估和过度自信调整）整合预测。在Hybrid Forecasting Competition (HFC)中，1085名用户预测了398个真实问题，混合系统比仅人类基线更准确，且熟练预测者使用机器预测时表现更优。该方法提高了预测的准确性和可扩展性，表明混合系统能以更少人力资源维持高水平性能。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "20 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.10981v1",
      "published_date": "2024-12-14 22:09:45 UTC",
      "updated_date": "2024-12-14 22:09:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:34:43.878663"
    },
    {
      "arxiv_id": "2412.10975v1",
      "title": "Recursive Aggregates as Intensional Functions in Answer Set Programming: Semantics and Strong Equivalence",
      "title_zh": "翻译失败",
      "authors": [
        "Jorge Fandinno",
        "Zachary Hansen"
      ],
      "abstract": "This paper shows that the semantics of programs with aggregates implemented\nby the solvers clingo and dlv can be characterized as extended First-Order\nformulas with intensional functions in the logic of Here-and-There.\nFurthermore, this characterization can be used to study the strong equivalence\nof programs with aggregates under either semantics. We also present a\ntransformation that reduces the task of checking strong equivalence to\nreasoning in classical First-Order logic, which serves as a foundation for\nautomating this procedure.",
      "tldr_zh": "这篇论文探讨了 Answer Set Programming (ASP) 中递归聚合函数的语义，证明了 clingo 和 dlv 求解器的实现可以被表征为 Here-and-There 逻辑中的扩展一阶公式，其中包含 intensional functions。论文利用这一表征来研究程序的 strong equivalence，分析了不同语义下的等价性。此外，论文提出了一种转换方法，将 strong equivalence 的检查简化为经典 First-Order 逻辑推理，从而为自动化这一过程提供了基础。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for publication in the Proceedings of the 39th Annual AAAI\n  Conference on Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2412.10975v1",
      "published_date": "2024-12-14 21:34:55 UTC",
      "updated_date": "2024-12-14 21:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:34:55.299920"
    },
    {
      "arxiv_id": "2412.10968v1",
      "title": "Composers' Evaluations of an AI Music Tool: Insights for Human-Centred Design",
      "title_zh": "翻译失败",
      "authors": [
        "Eleanor Row",
        "György Fazekas"
      ],
      "abstract": "We present a study that explores the role of user-centred design in\ndeveloping Generative AI (GenAI) tools for music composition. Through\nsemi-structured interviews with professional composers, we gathered insights on\na novel generative model for creating variations, highlighting concerns around\ntrust, transparency, and ethical design. The findings helped form a feedback\nloop, guiding improvements to the model that emphasised traceability,\ntransparency and explainability. They also revealed new areas for innovation,\nincluding novel features for controllability and research questions on the\nethical and practical implementation of GenAI models.",
      "tldr_zh": "本研究通过与专业作曲家的半结构化访谈，探讨了用户中心设计（user-centred design）在开发生成式 AI（GenAI）音乐工具中的作用，焦点在于一个用于创建音乐变体的生成模型。访谈揭示了作曲家对信任、透明性和道德设计的担忧，这些反馈形成了改进循环，强调了可追溯性（traceability）、透明性（transparency）和可解释性（explainability）。此外，该研究指出了创新机会，如增强模型的可控性（controllability）功能，以及关于 GenAI 模型的伦理和实际实施的新研究问题。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to NeurIPS 2024 Workshop on Generative AI and Creativity: A\n  dialogue between machine learning researchers and creative professionals in\n  Vancouver, Canada",
      "pdf_url": "http://arxiv.org/pdf/2412.10968v1",
      "published_date": "2024-12-14 20:56:23 UTC",
      "updated_date": "2024-12-14 20:56:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:35:06.567834"
    },
    {
      "arxiv_id": "2412.10966v3",
      "title": "FlowDock: Geometric Flow Matching for Generative Protein-Ligand Docking and Affinity Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Morehead",
        "Jianlin Cheng"
      ],
      "abstract": "Powerful generative AI models of protein-ligand structure have recently been\nproposed, but few of these methods support both flexible protein-ligand docking\nand affinity estimation. Of those that do, none can directly model multiple\nbinding ligands concurrently or have been rigorously benchmarked on\npharmacologically relevant drug targets, hindering their widespread adoption in\ndrug discovery efforts. In this work, we propose FlowDock, the first deep\ngeometric generative model based on conditional flow matching that learns to\ndirectly map unbound (apo) structures to their bound (holo) counterparts for an\narbitrary number of binding ligands. Furthermore, FlowDock provides predicted\nstructural confidence scores and binding affinity values with each of its\ngenerated protein-ligand complex structures, enabling fast virtual screening of\nnew (multi-ligand) drug targets. For the well-known PoseBusters Benchmark\ndataset, FlowDock outperforms single-sequence AlphaFold 3 with a 51% blind\ndocking success rate using unbound (apo) protein input structures and without\nany information derived from multiple sequence alignments, and for the\nchallenging new DockGen-E dataset, FlowDock outperforms single-sequence\nAlphaFold 3 and matches single-sequence Chai-1 for binding pocket\ngeneralization. Additionally, in the ligand category of the 16th community-wide\nCritical Assessment of Techniques for Structure Prediction (CASP16), FlowDock\nranked among the top-5 methods for pharmacological binding affinity estimation\nacross 140 protein-ligand complexes, demonstrating the efficacy of its learned\nrepresentations in virtual screening. Source code, data, and pre-trained models\nare available at https://github.com/BioinfoMachineLearning/FlowDock.",
      "tldr_zh": "本研究提出FlowDock，一种基于conditional flow matching的深度几何生成模型，用于生成蛋白-配体对接和亲和力预测，支持直接将apo结构映射到holo结构，并处理任意数量的结合配体。FlowDock还提供结构置信度分数和结合亲和力值，以加速虚拟筛选药物靶点。在基准测试中，该模型在PoseBusters Benchmark数据集上实现51%的盲对接成功率，优于单序列AlphaFold 3；在DockGen-E数据集上超越AlphaFold 3并与Chai-1相当，并在CASP16的配体类别中排名前5，证明其在药理学应用中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM",
        "q-bio.QM",
        "I.2.1; J.3"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 2 tables, 2 algorithms, 11 figures. Code, data, pre-trained\n  models, and baseline method predictions are available at\n  https://github.com/BioinfoMachineLearning/FlowDock",
      "pdf_url": "http://arxiv.org/pdf/2412.10966v3",
      "published_date": "2024-12-14 20:54:37 UTC",
      "updated_date": "2025-03-24 16:50:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:35:19.476975"
    },
    {
      "arxiv_id": "2412.10961v2",
      "title": "PSMGD: Periodic Stochastic Multi-Gradient Descent for Fast Multi-Objective Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Mingjing Xu",
        "Peizhong Ju",
        "Jia Liu",
        "Haibo Yang"
      ],
      "abstract": "Multi-objective optimization (MOO) lies at the core of many machine learning\n(ML) applications that involve multiple, potentially conflicting objectives\n(e.g., multi-task learning, multi-objective reinforcement learning, among many\nothers). Despite the long history of MOO, recent years have witnessed a surge\nin interest within the ML community in the development of gradient manipulation\nalgorithms for MOO, thanks to the availability of gradient information in many\nML problems. However, existing gradient manipulation methods for MOO often\nsuffer from long training times, primarily due to the need for computing\ndynamic weights by solving an additional optimization problem to determine a\ncommon descent direction that can decrease all objectives simultaneously. To\naddress this challenge, we propose a new and efficient algorithm called\nPeriodic Stochastic Multi-Gradient Descent (PSMGD) to accelerate MOO. PSMGD is\nmotivated by the key observation that dynamic weights across objectives exhibit\nsmall changes under minor updates over short intervals during the optimization\nprocess. Consequently, our PSMGD algorithm is designed to periodically compute\nthese dynamic weights and utilizes them repeatedly, thereby effectively\nreducing the computational overload. Theoretically, we prove that PSMGD can\nachieve state-of-the-art convergence rates for strongly-convex, general convex,\nand non-convex functions. Additionally, we introduce a new computational\ncomplexity measure, termed backpropagation complexity, and demonstrate that\nPSMGD could achieve an objective-independent backpropagation complexity.\nThrough extensive experiments, we verify that PSMGD can provide comparable or\nsuperior performance to state-of-the-art MOO algorithms while significantly\nreducing training time.",
      "tldr_zh": "这篇论文针对多目标优化 (Multi-Objective Optimization, MOO) 在机器学习应用中的训练时间问题，提出了一种高效算法 Periodic Stochastic Multi-Gradient Descent (PSMGD)。PSMGD 利用动态权重在短时间内变化小的观察，通过定期计算这些权重并重复使用，显著减少了计算额外优化问题的开销。理论上，作者证明 PSMGD 能实现最先进的收敛率，适用于强凸、通用凸和非凸函数，并引入了新的 backpropagation complexity 指标，显示其计算复杂度与目标无关。实验验证表明，PSMGD 与最先进算法相比，提供相当或优越的性能，同时大幅缩短训练时间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10961v2",
      "published_date": "2024-12-14 20:47:36 UTC",
      "updated_date": "2024-12-17 04:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:35:32.390011"
    },
    {
      "arxiv_id": "2412.10958v3",
      "title": "SoftVQ-VAE: Efficient 1-Dimensional Continuous Tokenizer",
      "title_zh": "SoftVQ-VAE：高效的一维连续标记化器",
      "authors": [
        "Hao Chen",
        "Ze Wang",
        "Xiang Li",
        "Ximeng Sun",
        "Fangyi Chen",
        "Jiang Liu",
        "Jindong Wang",
        "Bhiksha Raj",
        "Zicheng Liu",
        "Emad Barsoum"
      ],
      "abstract": "Efficient image tokenization with high compression ratios remains a critical\nchallenge for training generative models. We present SoftVQ-VAE, a continuous\nimage tokenizer that leverages soft categorical posteriors to aggregate\nmultiple codewords into each latent token, substantially increasing the\nrepresentation capacity of the latent space. When applied to Transformer-based\narchitectures, our approach compresses 256x256 and 512x512 images using as few\nas 32 or 64 1-dimensional tokens. Not only does SoftVQ-VAE show consistent and\nhigh-quality reconstruction, more importantly, it also achieves\nstate-of-the-art and significantly faster image generation results across\ndifferent denoising-based generative models. Remarkably, SoftVQ-VAE improves\ninference throughput by up to 18x for generating 256x256 images and 55x for\n512x512 images while achieving competitive FID scores of 1.78 and 2.21 for\nSiT-XL. It also improves the training efficiency of the generative models by\nreducing the number of training iterations by 2.3x while maintaining comparable\nperformance. With its fully-differentiable design and semantic-rich latent\nspace, our experiment demonstrates that SoftVQ-VAE achieves efficient\ntokenization without compromising generation quality, paving the way for more\nefficient generative models. Code and model are released.",
      "tldr_zh": "本研究提出SoftVQ-VAE，一种高效的1维连续图像标记器，通过利用软分类后验（soft categorical posteriors）聚合多个代码词到每个潜在标记，从而显著提升潜在空间的表示能力。相比传统方法，SoftVQ-VAE能将256x256和512x512图像压缩到仅32或64个1维标记，并在Transformer-based架构中实现高品质重建和state-of-the-art图像生成结果。实验显示，它将图像生成推断速度提高18倍（256x256）和55倍（512x512），FID scores分别达到1.78和2.21，同时减少2.3倍训练迭代，提高了生成模型的整体效率。整体设计完全可微且语义丰富，为高效生成模型铺平了道路。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and model: https://github.com/Hhhhhhao/continuous_tokenizer",
      "pdf_url": "http://arxiv.org/pdf/2412.10958v3",
      "published_date": "2024-12-14 20:29:29 UTC",
      "updated_date": "2025-03-14 22:22:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:37:36.459037"
    },
    {
      "arxiv_id": "2412.10953v1",
      "title": "Optimizing AI-Assisted Code Generation",
      "title_zh": "优化 AI 辅助代码生成",
      "authors": [
        "Simon Torka",
        "Sahin Albayrak"
      ],
      "abstract": "In recent years, the rise of AI-assisted code-generation tools has\nsignificantly transformed software development. While code generators have\nmainly been used to support conventional software development, their use will\nbe extended to powerful and secure AI systems. Systems capable of generating\ncode, such as ChatGPT, OpenAI Codex, GitHub Copilot, and AlphaCode, take\nadvantage of advances in machine learning (ML) and natural language processing\n(NLP) enabled by large language models (LLMs). However, it must be borne in\nmind that these models work probabilistically, which means that although they\ncan generate complex code from natural language input, there is no guarantee\nfor the functionality and security of the generated code.\n  However, to fully exploit the considerable potential of this technology, the\nsecurity, reliability, functionality, and quality of the generated code must be\nguaranteed. This paper examines the implementation of these goals to date and\nexplores strategies to optimize them. In addition, we explore how these systems\ncan be optimized to create safe, high-performance, and executable artificial\nintelligence (AI) models, and consider how to improve their accessibility to\nmake AI development more inclusive and equitable.",
      "tldr_zh": "本论文探讨了AI辅助代码生成工具（如ChatGPT和GitHub Copilot）的兴起及其在软件开发中的应用，这些工具依赖于机器学习(ML)和自然语言处理(NLP)的大语言模型(LLMs)，但由于其概率性输出，可能导致生成的代码功能或安全问题。论文审视了现有实现，并提出优化策略来提升代码的安全性、可靠性和质量，包括通过改进系统设计来创建高性能AI模型。最终，研究强调增强这些工具的可访问性，以促进AI开发的包容性和公平性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10953v1",
      "published_date": "2024-12-14 20:14:44 UTC",
      "updated_date": "2024-12-14 20:14:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:37:46.816994"
    },
    {
      "arxiv_id": "2412.10950v1",
      "title": "ALPACA -- Adaptive Learning Pipeline for Comprehensive AI",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Torka",
        "Sahin Albayrak"
      ],
      "abstract": "The advancement of AI technologies has greatly increased the complexity of AI\npipelines as they include many stages such as data collection, pre-processing,\ntraining, evaluation and visualisation. To provide effective and accessible AI\nsolutions, it is important to design pipelines for different user groups such\nas experts, professionals from different fields and laypeople. Ease of use and\ntrust play a central role in the acceptance of AI systems.\n  The presented system, ALPACA (Adaptive Learning Pipeline for Advanced\nComprehensive AI Analysis), offers a comprehensive AI pipeline that addresses\nthe needs of diverse user groups. ALPACA integrates visual and code-based\ndevelopment and facilitates all key phases of the AI pipeline. Its architecture\nis based on Celery (with Redis backend) for efficient task management, MongoDB\nfor seamless data storage and Kubernetes for cloud-based scalability and\nresource utilisation.\n  Future versions of ALPACA will support modern techniques such as federated\nand continuous learning as well as explainable AI methods to further improve\nsecurity, usability and trustworthiness. The application is demonstrated by an\nAndroid app for similarity recognition, which emphasises ALPACA's potential for\nuse in everyday life.",
      "tldr_zh": "该论文介绍了 ALPACA（Adaptive Learning Pipeline for Comprehensive AI），一个适应性 AI 学习管道，旨在简化复杂 AI 流程（如数据收集、预处理、训练、评估和可视化），并针对专家、专业人士和普通用户提供易用且可信的解决方案。\nALPACA 整合了视觉和代码-based 开发，其架构利用 Celery（以 Redis 后端）、MongoDB 进行数据存储，以及 Kubernetes 实现云端可扩展性。\n未来版本将支持 federated learning、continuous learning 和 explainable AI 方法，以提升安全性与可用性，并通过一个 Android 应用演示其在日常相似性识别中的潜力。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10950v1",
      "published_date": "2024-12-14 20:10:18 UTC",
      "updated_date": "2024-12-14 20:10:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:38:00.402046"
    },
    {
      "arxiv_id": "2412.10941v1",
      "title": "APAR: Modeling Irregular Target Functions in Tabular Regression via Arithmetic-Aware Pre-Training and Adaptive-Regularized Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Hong-Wei Wu",
        "Wei-Yao Wang",
        "Kuang-Da Wang",
        "Wen-Chih Peng"
      ],
      "abstract": "Tabular data are fundamental in common machine learning applications, ranging\nfrom finance to genomics and healthcare. This paper focuses on tabular\nregression tasks, a field where deep learning (DL) methods are not consistently\nsuperior to machine learning (ML) models due to the challenges posed by\nirregular target functions inherent in tabular data, causing sensitive label\nchanges with minor variations from features. To address these issues, we\npropose a novel Arithmetic-Aware Pre-training and Adaptive-Regularized\nFine-tuning framework (APAR), which enables the model to fit irregular target\nfunction in tabular data while reducing the negative impact of overfitting. In\nthe pre-training phase, APAR introduces an arithmetic-aware pretext objective\nto capture intricate sample-wise relationships from the perspective of\ncontinuous labels. In the fine-tuning phase, a consistency-based adaptive\nregularization technique is proposed to self-learn appropriate data\naugmentation. Extensive experiments across 10 datasets demonstrated that APAR\noutperforms existing GBDT-, supervised NN-, and pretrain-finetune NN-based\nmethods in RMSE (+9.43% $\\sim$ 20.37%), and empirically validated the effects\nof pre-training tasks, including the study of arithmetic operations. Our code\nand data are publicly available at https://github.com/johnnyhwu/APAR.",
      "tldr_zh": "这篇论文针对表格回归任务中不规则目标函数的问题，提出了APAR框架，通过算术感知预训练(arithmetic-aware pretext objective)和自适应正则化微调(adaptive-regularized fine-tuning)来帮助模型更好地拟合数据并减少过拟合风险。预训练阶段引入算术感知预文本目标，以捕捉连续标签的复杂样本关系；微调阶段则采用基于一致性的自适应正则化技术，实现数据增强的自学习。实验结果显示，APAR在10个数据集上比现有GBDT、监督NN和预训练-微调NN方法在RMSE上提高了9.43%到20.37%，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI 2025 Main Track",
      "pdf_url": "http://arxiv.org/pdf/2412.10941v1",
      "published_date": "2024-12-14 19:33:21 UTC",
      "updated_date": "2024-12-14 19:33:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:38:12.655308"
    },
    {
      "arxiv_id": "2412.10939v1",
      "title": "Human-Centric NLP or AI-Centric Illusion?: A Critical Investigation",
      "title_zh": "翻译失败",
      "authors": [
        "Piyapath T Spencer"
      ],
      "abstract": "Human-Centric NLP often claims to prioritise human needs and values, yet many\nimplementations reveal an underlying AI-centric focus. Through an analysis of\ncase studies in language modelling, behavioural testing, and multi-modal\nalignment, this study identifies a significant gap between the ideas of\nhuman-centricity and actual practices. Key issues include misalignment with\nhuman-centred design principles, the reduction of human factors to mere\nbenchmarks, and insufficient consideration of real-world impacts. The\ndiscussion explores whether Human-Centric NLP embodies true human-centred\ndesign, emphasising the need for interdisciplinary collaboration and ethical\nconsiderations. The paper advocates for a redefinition of Human-Centric NLP,\nurging a broader focus on real-world utility and societal implications to\nensure that language technologies genuinely serve and empower users.",
      "tldr_zh": "本论文通过对语言建模、行为测试和多模态对齐的案例研究，批判性地调查了Human-Centric NLP是否真正以人为本，还是AI-Centric幻觉。研究发现，现有实施存在显著差距，包括不符合人类中心设计原则、将人类因素简化为基准，以及对现实世界影响的不足考虑。作者强调需要跨学科合作和伦理考量，并倡导重新定义Human-Centric NLP，以关注实际效用和社会影响，确保语言技术真正服务和赋能用户。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Preprint to be published in Proceedings of PACLIC38",
      "pdf_url": "http://arxiv.org/pdf/2412.10939v1",
      "published_date": "2024-12-14 19:16:53 UTC",
      "updated_date": "2024-12-14 19:16:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:38:23.467100"
    },
    {
      "arxiv_id": "2412.10925v1",
      "title": "Video Representation Learning with Joint-Embedding Predictive Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Katrina Drozdov",
        "Ravid Shwartz-Ziv",
        "Yann LeCun"
      ],
      "abstract": "Video representation learning is an increasingly important topic in machine\nlearning research. We present Video JEPA with Variance-Covariance\nRegularization (VJ-VCR): a joint-embedding predictive architecture for\nself-supervised video representation learning that employs variance and\ncovariance regularization to avoid representation collapse. We show that hidden\nrepresentations from our VJ-VCR contain abstract, high-level information about\nthe input data. Specifically, they outperform representations obtained from a\ngenerative baseline on downstream tasks that require understanding of the\nunderlying dynamics of moving objects in the videos. Additionally, we explore\ndifferent ways to incorporate latent variables into the VJ-VCR framework that\ncapture information about uncertainty in the future in non-deterministic\nsettings.",
      "tldr_zh": "本研究提出了一种名为 Video JEPA with Variance-Covariance Regularization (VJ-VCR) 的联合嵌入预测架构（Joint-Embedding Predictive Architectures），用于自监督视频表示学习，通过方差和协方差正则化避免表示坍缩。VJ-VCR 生成的隐藏表示包含输入数据的抽象和高阶信息，在下游任务中表现优于生成基线模型，尤其是在理解视频中移动物体动态方面。实验结果显示，该方法在涉及物体运动理解的任务上表现出色，此外，论文还探讨了整合潜变量来捕捉非确定性场景中未来的不确定性信息。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10925v1",
      "published_date": "2024-12-14 18:33:29 UTC",
      "updated_date": "2024-12-14 18:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:38:36.535496"
    },
    {
      "arxiv_id": "2412.10924v4",
      "title": "Tokens, the oft-overlooked appetizer: Large language models, the distributional hypothesis, and meaning",
      "title_zh": "翻译失败",
      "authors": [
        "Julia Witte Zimmerman",
        "Denis Hudon",
        "Kathryn Cramer",
        "Alejandro J. Ruiz",
        "Calla Beauregard",
        "Ashley Fehr",
        "Mikaela Irene Fudolig",
        "Bradford Demarest",
        "Yoshi Meke Bird",
        "Milo Z. Trujillo",
        "Christopher M. Danforth",
        "Peter Sheridan Dodds"
      ],
      "abstract": "Tokenization is a necessary component within the current architecture of many\nlanguage models, including the transformer-based large language models (LLMs)\nof Generative AI, yet its impact on the model's cognition is often overlooked.\nWe argue that LLMs demonstrate that the Distributional Hypothesis (DH) is\nsufficient for reasonably human-like language performance, and that the\nemergence of human-meaningful linguistic units among tokens and current\nstructural constraints motivate changes to existing, linguistically-agnostic\ntokenization techniques, particularly with respect to their roles as (1)\nsemantic primitives and as (2) vehicles for conveying salient distributional\npatterns from human language to the model. We explore tokenizations from a BPE\ntokenizer; extant model vocabularies obtained from Hugging Face and tiktoken;\nand the information in exemplar token vectors as they move through the layers\nof a RoBERTa (large) model. Besides creating sub-optimal semantic building\nblocks and obscuring the model's access to the necessary distributional\npatterns, we describe how tokens and pretraining can act as a backdoor for bias\nand other unwanted content, which current alignment practices may not\nremediate. Additionally, we relay evidence that the tokenization algorithm's\nobjective function impacts the LLM's cognition, despite being arguably\nmeaningfully insulated from the main system intelligence. [First uploaded to\narXiv in December, 2024.]",
      "tldr_zh": "该论文探讨了在大型语言模型（LLMs）中，tokenization 作为一种常被忽略的关键组件，如何影响模型的认知，并论证了分布假设（Distributional Hypothesis, DH）足以支持类似人类的语言性能。作者通过分析 BPE tokenization、Hugging Face 和 tiktoken 的模型词汇表，以及 RoBERTa (large) 模型中 token 向量的层级变化，揭示了 tokenization 可能创建次优语义原语、遮蔽重要分布模式，并充当偏见和不想要内容的后门。研究强调，改进 tokenization 技术，尤其是其作为语义基元和分布模式载体的角色，能够提升模型的可靠性，尽管当前对齐实践可能无法完全解决这些问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10924v4",
      "published_date": "2024-12-14 18:18:52 UTC",
      "updated_date": "2025-04-13 16:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:38:46.926783"
    },
    {
      "arxiv_id": "2412.10919v1",
      "title": "Predicting Survival of Hemodialysis Patients using Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Abhiram Raju",
        "Praneeth Vepakomma"
      ],
      "abstract": "Hemodialysis patients who are on donor lists for kidney transplant may get\nmisidentified, delaying their wait time. Thus, predicting their survival time\nis crucial for optimizing waiting lists and personalizing treatment plans.\nPredicting survival times for patients often requires large quantities of high\nquality but sensitive data. This data is siloed and since individual datasets\nare smaller and less diverse, locally trained survival models do not perform as\nwell as centralized ones. Hence, we propose the use of Federated Learning in\nthe context of predicting survival for hemodialysis patients. Federated\nLearning or FL can have comparatively better performances than local models\nwhile not sharing data between centers. However, despite the increased use of\nsuch technologies, the application of FL in survival and even more, dialysis\npatients remains sparse. This paper studies the performance of FL for data of\nhemodialysis patients from NephroPlus, the largest private network of dialysis\ncenters in India.",
      "tldr_zh": "该研究针对血液透析(Hemodialysis)患者的生存时间预测问题提出使用 Federated Learning 方法，以优化肾移植等待列表和个性化治疗计划。传统本地模型因数据孤岛和敏感性限制而性能不足，而 Federated Learning 允许多中心协作训练模型而不共享原始数据，从而提升预测准确性。论文基于印度 NephroPlus 网络的患者数据进行实验，结果表明 Federated Learning 在生存预测任务中表现出色，为临床应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 2 figures, 4 tables, Presented at MIT Undergraduate Research\n  Technology Conference and to be published as conference proceeding at IEEE\n  Xplore",
      "pdf_url": "http://arxiv.org/pdf/2412.10919v1",
      "published_date": "2024-12-14 18:10:44 UTC",
      "updated_date": "2024-12-14 18:10:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:39:00.167914"
    },
    {
      "arxiv_id": "2412.10918v1",
      "title": "LLMs-in-the-Loop Part 2: Expert Small AI Models for Anonymization and De-identification of PHI Across Multiple Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Murat Gunay",
        "Bunyamin Keles",
        "Raife Hizlan"
      ],
      "abstract": "The rise of chronic diseases and pandemics like COVID-19 has emphasized the\nneed for effective patient data processing while ensuring privacy through\nanonymization and de-identification of protected health information (PHI).\nAnonymized data facilitates research without compromising patient\nconfidentiality. This paper introduces expert small AI models developed using\nthe LLM-in-the-loop methodology to meet the demand for domain-specific\nde-identification NER models. These models overcome the privacy risks\nassociated with large language models (LLMs) used via APIs by eliminating the\nneed to transmit or store sensitive data. More importantly, they consistently\noutperform LLMs in de-identification tasks, offering superior performance and\nreliability. Our de-identification NER models, developed in eight languages\n(English, German, Italian, French, Romanian, Turkish, Spanish, and Arabic)\nachieved f1-micro score averages of 0.966, 0.975, 0.976, 0.970, 0.964, 0.974,\n0.978, and 0.953 respectively. These results establish them as the most\naccurate healthcare anonymization solutions, surpassing existing small models\nand even general-purpose LLMs such as GPT-4o. While Part-1 of this series\nintroduced the LLM-in-the-loop methodology for bio-medical document\ntranslation, this second paper showcases its success in developing\ncost-effective expert small NER models in de-identification tasks. Our findings\nlay the groundwork for future healthcare AI innovations, including biomedical\nentity and relation extraction, demonstrating the value of specialized models\nfor domain-specific challenges.",
      "tldr_zh": "这篇论文介绍了使用LLM-in-the-loop方法开发的专家小型AI模型，用于多语言PHI（受保护的健康信息）的匿名化和去标识化（de-identification），以解决医疗数据处理中的隐私风险问题。这些模型无需传输敏感数据，并在八种语言（English, German, Italian, French, Romanian, Turkish, Spanish 和 Arabic）上实现了高F1-micro分数（平均0.966-0.978），显著优于现有小型模型和通用LLMs如GPT-4o。该研究扩展了LLM-in-the-loop在医疗领域的应用，为未来生物医学实体提取等AI创新提供了可靠的基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.10918v1",
      "published_date": "2024-12-14 18:10:29 UTC",
      "updated_date": "2024-12-14 18:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:39:13.857005"
    },
    {
      "arxiv_id": "2412.10917v2",
      "title": "Adaptive Reward Design for Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Minjae Kwon",
        "Ingy ElSayed-Aly",
        "Lu Feng"
      ],
      "abstract": "There is a surge of interest in using formal languages such as Linear\nTemporal Logic (LTL) to precisely and succinctly specify complex tasks and\nderive reward functions for Reinforcement Learning (RL). However, existing\nmethods often assign sparse rewards (e.g., giving a reward of 1 only if a task\nis completed and 0 otherwise). By providing feedback solely upon task\ncompletion, these methods fail to encourage successful subtask completion. This\nis particularly problematic in environments with inherent uncertainty, where\ntask completion may be unreliable despite progress on intermediate goals. To\naddress this limitation, we propose a suite of reward functions that\nincentivize an RL agent to complete a task specified by an LTL formula as much\nas possible, and develop an adaptive reward shaping approach that dynamically\nupdates reward functions during the learning process. Experimental results on a\nrange of benchmark RL environments demonstrate that the proposed approach\ngenerally outperforms baselines, achieving earlier convergence to a better\npolicy with higher expected return and task completion rate.",
      "tldr_zh": "该论文针对强化学习（RL）中基于线性时序逻辑（LTL）任务指定的奖励设计问题，指出现有稀疏奖励方法（如仅在任务完成时给予奖励）忽略了子任务的进展，尤其在不确定环境中。作者提出一组奖励函数来激励代理尽可能完成 LTL 公式指定的任务，并开发自适应奖励塑造方法，在学习过程中动态更新奖励以优化反馈。实验结果显示，该方法在多种基准 RL 环境中优于基线模型，实现更早的策略收敛、更高预期回报和任务完成率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "68T40 (Primary) 93E35, 03B44 (Secondary)"
      ],
      "primary_category": "cs.RO",
      "comment": "UAI 2025 Camera Ready Version",
      "pdf_url": "http://arxiv.org/pdf/2412.10917v2",
      "published_date": "2024-12-14 18:04:18 UTC",
      "updated_date": "2025-05-17 21:14:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:39:23.683816"
    },
    {
      "arxiv_id": "2412.10912v2",
      "title": "ST-FiT: Inductive Spatial-Temporal Forecasting with Limited Training Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenyu Lei",
        "Yushun Dong",
        "Jundong Li",
        "Chen Chen"
      ],
      "abstract": "Spatial-temporal graphs are widely used in a variety of real-world\napplications. Spatial-Temporal Graph Neural Networks (STGNNs) have emerged as a\npowerful tool to extract meaningful insights from this data. However, in\nreal-world applications, most nodes may not possess any available temporal data\nduring training. For example, the pandemic dynamics of most cities on a\ngeographical graph may not be available due to the asynchronous nature of\noutbreaks. Such a phenomenon disagrees with the training requirements of most\nexisting spatial-temporal forecasting methods, which jeopardizes their\neffectiveness and thus blocks broader deployment. In this paper, we propose to\nformulate a novel problem of inductive forecasting with limited training data.\nIn particular, given a spatial-temporal graph, we aim to learn a\nspatial-temporal forecasting model that can be easily generalized onto those\nnodes without any available temporal training data. To handle this problem, we\npropose a principled framework named ST-FiT. ST-FiT consists of two key\nlearning components: temporal data augmentation and spatial graph topology\nlearning. With such a design, ST-FiT can be used on top of any existing STGNNs\nto achieve superior performance on the nodes without training data. Extensive\nexperiments verify the effectiveness of ST-FiT in multiple key perspectives.",
      "tldr_zh": "本研究针对空间-时间图神经网络 (STGNNs) 在实际应用中面临的挑战，提出了一种新的归纳预测 (inductive forecasting) 问题，即在训练数据有限的情况下（如某些节点缺少时间数据），学习一个可泛化至无训练数据的模型。论文引入了 ST-FiT 框架，该框架包括时间数据增强 (temporal data augmentation) 和空间图拓扑学习 (spatial graph topology learning) 两个关键组件，能够与现有 STGNNs 无缝整合。实验结果显示，ST-FiT 在多个方面显著提升了模型在无训练数据节点的预测性能，从而推动了空间-时间预测在真实场景中的部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10912v2",
      "published_date": "2024-12-14 17:51:29 UTC",
      "updated_date": "2024-12-17 02:29:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:39:35.878710"
    },
    {
      "arxiv_id": "2412.10904v1",
      "title": "CEKER: A Generalizable LLM Framework for Literature Analysis with a Case Study in Unikernel Security",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Wollman",
        "John Hastings"
      ],
      "abstract": "Literature reviews are a critical component of formulating and justifying new\nresearch, but are a manual and often time-consuming process. This research\nintroduces a novel, generalizable approach to literature analysis called CEKER\nwhich uses a three-step process to streamline the collection of literature, the\nextraction of key insights, and the summarized analysis of key trends and gaps.\nLeveraging Large Language Models (LLMs), this methodology represents a\nsignificant shift from traditional manual literature reviews, offering a\nscalable, flexible, and repeatable approach that can be applied across diverse\nresearch domains.\n  A case study on unikernel security illustrates CEKER's ability to generate\nnovel insights validated against previous manual methods. CEKER's analysis\nhighlighted reduced attack surface as the most prominent theme. Key security\ngaps included the absence of Address Space Layout Randomization, missing\ndebugging tools, and limited entropy generation, all of which represent\nimportant challenges to unikernel security. The study also revealed a reliance\non hypervisors as a potential attack vector and emphasized the need for dynamic\nsecurity adjustments to address real-time threats.",
      "tldr_zh": "本研究提出CEKER，这是一个通用的Large Language Models (LLMs)框架，用于简化文献分析过程，通过三步流程（收集文献、提取关键洞见和总结趋势及空白）来取代传统手动方法，提供可扩展、灵活且可重复的解决方案，可应用于多种研究领域。  \n以Unikernel Security为例，CEKER生成的新洞见经与手动方法验证一致，突显减少攻击面作为主要主题，并识别关键空白如缺少Address Space Layout Randomization、调试工具和熵生成，以及对hypervisor的依赖作为潜在攻击向量，强调动态安全调整的必要性。  \n这项工作标志着文献分析领域的重大转变，有望加速研究创新。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "K.6.5; I.2.7; H.3.1; A.1; D.4.1"
      ],
      "primary_category": "cs.CR",
      "comment": "7 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.10904v1",
      "published_date": "2024-12-14 17:28:43 UTC",
      "updated_date": "2024-12-14 17:28:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:39:47.761965"
    },
    {
      "arxiv_id": "2412.10893v1",
      "title": "BgGPT 1.0: Extending English-centric LLMs to other languages",
      "title_zh": "翻译失败",
      "authors": [
        "Anton Alexandrov",
        "Veselin Raychev",
        "Dimitar I. Dimitrov",
        "Ce Zhang",
        "Martin Vechev",
        "Kristina Toutanova"
      ],
      "abstract": "We present BgGPT-Gemma-2-27B-Instruct and BgGPT-Gemma-2-9B-Instruct:\ncontinually pretrained and fine-tuned versions of Google's Gemma-2 models,\nspecifically optimized for Bulgarian language understanding and generation.\nLeveraging Gemma-2's multilingual capabilities and over 100 billion tokens of\nBulgarian and English text data, our models demonstrate strong performance in\nBulgarian language tasks, setting a new standard for language-specific AI\nmodels. Our approach maintains the robust capabilities of the original Gemma-2\nmodels, ensuring that the English language performance remains intact. To\npreserve the base model capabilities, we incorporate continual learning\nstrategies based on recent Branch-and-Merge techniques as well as thorough\ncuration and selection of training data. We provide detailed insights into our\nmethodology, including the release of model weights with a commercial-friendly\nlicense, enabling broader adoption by researchers, companies, and hobbyists.\nFurther, we establish a comprehensive set of benchmarks based on non-public\neducational data sources to evaluate models on Bulgarian language tasks as well\nas safety and chat capabilities. Our findings demonstrate the effectiveness of\nfine-tuning state-of-the-art models like Gemma 2 to enhance language-specific\nAI applications while maintaining cross-lingual capabilities.",
      "tldr_zh": "本研究推出了 BgGPT 1.0，包括 BgGPT-Gemma-2-27B-Instruct 和 BgGPT-Gemma-2-9B-Instruct 模型，这些是基于 Google 的 Gemma-2 模型，通过持续预训练和微调，扩展了英语中心 LLMs 到保加利亚语领域。研究团队利用超过 100 亿保加利亚语和英语文本数据，并采用 Branch-and-Merge 技术以及数据 curation 策略，确保模型在保加利亚语任务上表现出色，同时保持了原模型的英语性能。实验结果显示，这些模型在基于非公开教育数据的基准测试中表现强劲，提升了语言特定 AI 应用，并以商业友好许可发布了模型权重，促进更广泛的采用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10893v1",
      "published_date": "2024-12-14 16:49:52 UTC",
      "updated_date": "2024-12-14 16:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:39:59.994925"
    },
    {
      "arxiv_id": "2412.10892v2",
      "title": "Know Unreported Roadway Incidents in Real-time: Early Traffic Anomaly Detection",
      "title_zh": "实时知晓未报告道路事件：早期交通异常检测",
      "authors": [
        "Haocheng Duan",
        "Hao Wu",
        "Sean Qian"
      ],
      "abstract": "This research aims to know traffic anomalies as early as possible. A traffic\nanomaly refers to a generic incident on the road that influences traffic flow\nand calls for urgent traffic management measures. `Knowing'' the occurrence of\na traffic anomaly is twofold: the ability to detect this anomaly before it is\nreported anywhere, or it may be such that an anomaly can be predicted before it\nactually occurs on the road (e.g., non-recurrent traffic breakdown). In either\nway, the objective is to inform traffic operators of unreported incidents in\nreal time and as early as possible. The key is to stay ahead of the curve. Time\nis of the essence.\n  Conventional automatic incident detection (AID) methods often struggle with\nearly detection due to their limited consideration of spatial effects and\nearly-stage characteristics. Therefore, we propose a deep learning framework\nutilizing prior domain knowledge and model-designing strategies. This allows\nthe model to detect a broader range of anomalies, not only incidents that\nsignificantly influence traffic flow but also early characteristics of\nincidents along with historically unreported anomalies. We specially design the\nmodel to target the early-stage detection/prediction of an incident.\nAdditionally, unlike most conventional AID studies, our method is highly\nscalable and generalizable, as it is fully automated with no manual selection\nof historical reports required, relies solely on widely available low-cost\ndata, and requires no additional detectors. The experimental results across\nnumerous road segments on different maps demonstrate that our model leads to\nmore effective and early anomaly detection.",
      "tldr_zh": "这篇论文针对交通异常（traffic anomaly）提出了一种实时检测未报告路段事件的方法，旨在尽早识别或预测这些事件，以支持紧急交通管理。研究者开发了一个深度学习框架（deep learning framework），它整合了先验领域知识和模型设计策略，能够捕捉空间效应和早期特征，从而检测更广泛的异常，包括历史未报告的事件，且无需手动选择数据或额外检测器。实验结果显示，该框架在多个路段的测试中比传统自动事件检测（AID）方法更有效，提升了早期检测能力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10892v2",
      "published_date": "2024-12-14 16:49:29 UTC",
      "updated_date": "2025-04-23 18:02:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:40:11.501566"
    },
    {
      "arxiv_id": "2412.10871v1",
      "title": "Fully Test-time Adaptation for Tabular Data",
      "title_zh": "翻译失败",
      "authors": [
        "Zhi Zhou",
        "Kun-Yang Yu",
        "Lan-Zhe Guo",
        "Yu-Feng Li"
      ],
      "abstract": "Tabular data plays a vital role in various real-world scenarios and finds\nextensive applications. Although recent deep tabular models have shown\nremarkable success, they still struggle to handle data distribution shifts,\nleading to performance degradation when testing distributions change. To remedy\nthis, a robust tabular model must adapt to generalize to unknown distributions\nduring testing. In this paper, we investigate the problem of fully test-time\nadaptation (FTTA) for tabular data, where the model is adapted using only the\ntesting data. We identify three key challenges: the existence of label and\ncovariate distribution shifts, the lack of effective data augmentation, and the\nsensitivity of adaptation, which render existing FTTA methods ineffective for\ntabular data. To this end, we propose the Fully Test-time Adaptation for\nTabular data, namely FTAT, which enables FTTA methods to robustly optimize the\nlabel distribution of predictions, adapt to shifted covariate distributions,\nand suit a variety of tasks and models effectively. We conduct comprehensive\nexperiments on six benchmark datasets, which are evaluated using three metrics.\nThe experimental results demonstrate that FTAT outperforms state-of-the-art\nmethods by a margin.",
      "tldr_zh": "本研究针对表格数据在分布偏移下的性能下降问题，探讨了Fully Test-time Adaptation (FTTA)，即仅使用测试数据进行模型适应的技术。论文提出了一种新方法FTAT，能够优化预测的标签分布、适应偏移的协变量分布，并适用于多种任务和模型，同时克服了数据增强不足和适应敏感性的挑战。在六个基准数据集上的实验结果显示，FTAT在使用三种评估指标时，显著优于现有最先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025. Code is available at:\n  https://wnjxyk.github.io/FTTA",
      "pdf_url": "http://arxiv.org/pdf/2412.10871v1",
      "published_date": "2024-12-14 15:49:53 UTC",
      "updated_date": "2024-12-14 15:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:40:22.699442"
    },
    {
      "arxiv_id": "2412.10869v2",
      "title": "TinySubNets: An efficient and low capacity continual learning strategy",
      "title_zh": "TinySubNets：一种高效且低容量的持续学习策略",
      "authors": [
        "Marcin Pietroń",
        "Kamil Faber",
        "Dominik Żurek",
        "Roberto Corizzo"
      ],
      "abstract": "Continual Learning (CL) is a highly relevant setting gaining traction in\nrecent machine learning research. Among CL works, architectural and hybrid\nstrategies are particularly effective due to their potential to adapt the model\narchitecture as new tasks are presented. However, many existing solutions do\nnot efficiently exploit model sparsity, and are prone to capacity saturation\ndue to their inefficient use of available weights, which limits the number of\nlearnable tasks. In this paper, we propose TinySubNets (TSN), a novel\narchitectural CL strategy that addresses the issues through the unique\ncombination of pruning with different sparsity levels, adaptive quantization,\nand weight sharing. Pruning identifies a subset of weights that preserve model\nperformance, making less relevant weights available for future tasks. Adaptive\nquantization allows a single weight to be separated into multiple parts which\ncan be assigned to different tasks. Weight sharing between tasks boosts the\nexploitation of capacity and task similarity, allowing for the identification\nof a better trade-off between model accuracy and capacity. These features allow\nTSN to efficiently leverage the available capacity, enhance knowledge transfer,\nand reduce computational resource consumption. Experimental results involving\ncommon benchmark CL datasets and scenarios show that our proposed strategy\nachieves better results in terms of accuracy than existing state-of-the-art CL\nstrategies. Moreover, our strategy is shown to provide a significantly improved\nmodel capacity exploitation. Code released at:\nhttps://github.com/lifelonglab/tinysubnets.",
      "tldr_zh": "该论文提出了一种名为 TinySubNets (TSN) 的新型 architectural continual learning (CL) 策略，旨在通过高效利用模型稀疏性来解决现有方法在容量饱和和权重利用上的不足。TSN 结合 pruning（不同稀疏度剪枝）、adaptive quantization（自适应量化）和 weight sharing（权重共享）来识别关键权重子集、分配权重给多个任务，并提升任务间知识转移，从而优化模型容量和计算资源消耗。在常见基准 CL 数据集和场景的实验中，TSN 在准确性上优于现有 state-of-the-art 策略，并显著提高了模型容量利用，代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10869v2",
      "published_date": "2024-12-14 15:43:38 UTC",
      "updated_date": "2025-02-25 16:10:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:40:35.067934"
    },
    {
      "arxiv_id": "2412.10861v1",
      "title": "Heterogeneous Graph Transformer for Multiple Tiny Object Tracking in RGB-T Videos",
      "title_zh": "异构图变换器用于 RGB-T 视频中的多小目标跟踪",
      "authors": [
        "Qingyu Xu",
        "Longguang Wang",
        "Weidong Sheng",
        "Yingqian Wang",
        "Chao Xiao",
        "Chao Ma",
        "Wei An"
      ],
      "abstract": "Tracking multiple tiny objects is highly challenging due to their weak\nappearance and limited features. Existing multi-object tracking algorithms\ngenerally focus on single-modality scenes, and overlook the complementary\ncharacteristics of tiny objects captured by multiple remote sensors. To enhance\ntracking performance by integrating complementary information from multiple\nsources, we propose a novel framework called {HGT-Track (Heterogeneous Graph\nTransformer based Multi-Tiny-Object Tracking)}. Specifically, we first employ a\nTransformer-based encoder to embed images from different modalities.\nSubsequently, we utilize Heterogeneous Graph Transformer to aggregate spatial\nand temporal information from multiple modalities to generate detection and\ntracking features. Additionally, we introduce a target re-detection module\n(ReDet) to ensure tracklet continuity by maintaining consistency across\ndifferent modalities. Furthermore, this paper introduces the first benchmark\nVT-Tiny-MOT (Visible-Thermal Tiny Multi-Object Tracking) for RGB-T fused\nmultiple tiny object tracking. Extensive experiments are conducted on\nVT-Tiny-MOT, and the results have demonstrated the effectiveness of our method.\nCompared to other state-of-the-art methods, our method achieves better\nperformance in terms of MOTA (Multiple-Object Tracking Accuracy) and ID-F1\nscore. The code and dataset will be made available at\nhttps://github.com/xuqingyu26/HGTMT.",
      "tldr_zh": "该论文针对RGB-T视频中多个微小物体的跟踪挑战，提出了一种新框架HGT-Track（基于Heterogeneous Graph Transformer的多微小物体跟踪），以整合多模态信息的互补特性。框架首先使用Transformer-based encoder嵌入不同模态的图像，然后通过Heterogeneous Graph Transformer聚合空间和时间信息生成检测跟踪特征，并引入目标重新检测模块(ReDet)来维持轨迹连续性和模态一致性。作为贡献，该论文还引入了首个RGB-T融合基准数据集VT-Tiny-MOT，并在实验中证明了方法的有效性，在MOTA和ID-F1得分上优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "N/A",
      "pdf_url": "http://arxiv.org/pdf/2412.10861v1",
      "published_date": "2024-12-14 15:17:49 UTC",
      "updated_date": "2024-12-14 15:17:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:40:48.106309"
    },
    {
      "arxiv_id": "2412.10849v2",
      "title": "Superhuman performance of a large language model on the reasoning tasks of a physician",
      "title_zh": "大型语言模型在医师推理任务上的超人类性能",
      "authors": [
        "Peter G. Brodeur",
        "Thomas A. Buckley",
        "Zahir Kanjee",
        "Ethan Goh",
        "Evelyn Bin Ling",
        "Priyank Jain",
        "Stephanie Cabral",
        "Raja-Elie Abdulnour",
        "Adrian D. Haimovich",
        "Jason A. Freed",
        "Andrew Olson",
        "Daniel J. Morgan",
        "Jason Hom",
        "Robert Gallo",
        "Liam G. McCoy",
        "Haadi Mombini",
        "Christopher Lucas",
        "Misha Fotoohi",
        "Matthew Gwiazdon",
        "Daniele Restifo",
        "Daniel Restrepo",
        "Eric Horvitz",
        "Jonathan Chen",
        "Arjun K. Manrai",
        "Adam Rodman"
      ],
      "abstract": "A seminal paper published by Ledley and Lusted in 1959 introduced complex\nclinical diagnostic reasoning cases as the gold standard for the evaluation of\nexpert medical computing systems, a standard that has held ever since. Here, we\nreport the results of a physician evaluation of a large language model (LLM) on\nchallenging clinical cases against a baseline of hundreds of physicians. We\nconduct five experiments to measure clinical reasoning across differential\ndiagnosis generation, display of diagnostic reasoning, triage differential\ndiagnosis, probabilistic reasoning, and management reasoning, all adjudicated\nby physician experts with validated psychometrics. We then report a real-world\nstudy comparing human expert and AI second opinions in randomly-selected\npatients in the emergency room of a major tertiary academic medical center in\nBoston, MA. We compared LLMs and board-certified physicians at three predefined\ndiagnostic touchpoints: triage in the emergency room, initial evaluation by a\nphysician, and admission to the hospital or intensive care unit. In all\nexperiments--both vignettes and emergency room second opinions--the LLM\ndisplayed superhuman diagnostic and reasoning abilities, as well as continued\nimprovement from prior generations of AI clinical decision support. Our study\nsuggests that LLMs have achieved superhuman performance on general medical\ndiagnostic and management reasoning, fulfilling the vision put forth by Ledley\nand Lusted, and motivating the urgent need for prospective trials.",
      "tldr_zh": "这篇论文评估了Large Language Model (LLM) 在临床推理任务上的表现，并将其与数百名医生进行比较，以验证其是否达到超人类水平。研究通过五项实验（包括差分诊断生成、诊断推理展示、急诊分诊、概率推理和管理推理）以及一个真实世界急诊室案例研究，证明LLM在诊断和决策方面优于人类专家，并在波士顿一家大型学术医疗中心表现出持续改进。结果表明，LLM已实现超人类的医疗诊断和管理能力，实现了1959年Ledley和Lusted提出的愿景，并强调了开展前瞻性试验的紧迫性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10849v2",
      "published_date": "2024-12-14 14:46:18 UTC",
      "updated_date": "2025-05-19 14:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:41:01.046302"
    },
    {
      "arxiv_id": "2412.10848v1",
      "title": "Large Language Models for Medical Forecasting -- Foresight 2",
      "title_zh": "大型语言模型用于医疗预测 -- Foresight 2",
      "authors": [
        "Zeljko Kraljevic",
        "Joshua Au Yeung",
        "Daniel Bean",
        "James Teo",
        "Richard J. Dobson"
      ],
      "abstract": "Foresight 2 (FS2) is a large language model fine-tuned on hospital data for\nmodelling patient timelines (GitHub 'removed for anon'). It can understand\npatients' clinical notes and predict SNOMED codes for a wide range of\nbiomedical use cases, including diagnosis suggestions, risk forecasting, and\nprocedure and medication recommendations. FS2 is trained on the free text\nportion of the MIMIC-III dataset, firstly through extracting biomedical\nconcepts and then creating contextualised patient timelines, upon which the\nmodel is then fine-tuned. The results show significant improvement over the\nprevious state-of-the-art for the next new biomedical concept prediction (P/R -\n0.73/0.66 vs 0.52/0.32) and a similar improvement specifically for the next new\ndisorder prediction (P/R - 0.69/0.62 vs 0.46/0.25). Finally, on the task of\nrisk forecast, we compare our model to GPT-4-turbo (and a range of open-source\nbiomedical LLMs) and show that FS2 performs significantly better on such tasks\n(P@5 - 0.90 vs 0.65). This highlights the need to incorporate hospital data\ninto LLMs and shows that small models outperform much larger ones when\nfine-tuned on high-quality, specialised data.",
      "tldr_zh": "本研究介绍了 Foresight 2 (FS2)，一个基于 Large Language Models (LLMs) 微调于医院数据的模型，用于理解患者临床笔记并预测 SNOMED codes，支持诊断建议、风险预测、程序和药物推荐。\nFS2 通过提取 MIMIC-III 数据集的自由文本部分、构建上下文化患者时间线并进行微调来实现训练。\n结果显示，FS2 在下一个新生物医学概念预测上 (P/R - 0.73/0.66) 和新疾病预测上 (P/R - 0.69/0.62) 显著优于先前最先进模型，在风险预测任务中也超越 GPT-4-turbo (P@5 - 0.90 vs 0.65)。\n这证明了将医院数据整合到 LLMs 中的重要性，并表明小模型在高品质专业数据上微调后可 outperform 更大模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10848v1",
      "published_date": "2024-12-14 14:45:28 UTC",
      "updated_date": "2024-12-14 14:45:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:42:55.323139"
    },
    {
      "arxiv_id": "2412.17833v1",
      "title": "Transfer Learning with Active Sampling for Rapid Training and Calibration in BCI-P300 Across Health States and Multi-centre Data",
      "title_zh": "翻译失败",
      "authors": [
        "Christian Flores",
        "Marcelo Contreras",
        "Ichiro Macedo",
        "Javier Andreu-Perez"
      ],
      "abstract": "Machine learning and deep learning advancements have boosted Brain-Computer\nInterface (BCI) performance, but their wide-scale applicability is limited due\nto factors like individual health, hardware variations, and cultural\ndifferences affecting neural data. Studies often focus on uniform single-site\nexperiments in uniform settings, leading to high performance that may not\ntranslate well to real-world diversity. Deep learning models aim to enhance BCI\nclassification accuracy, and transfer learning has been suggested to adapt\nmodels to individual neural patterns using a base model trained on others'\ndata. This approach promises better generalizability and reduced overfitting,\nyet challenges remain in handling diverse and imbalanced datasets from\ndifferent equipment, subjects, multiple centres in different countries, and\nboth healthy and patient populations for effective model transfer and tuning.\n  In a setting characterized by maximal heterogeneity, we proposed P300 wave\ndetection in BCIs employing a convolutional neural network fitted with adaptive\ntransfer learning based on Poison Sampling Disk (PDS) called Active Sampling\n(AS), which flexibly adjusts the transition from source data to the target\ndomain. Our results reported for subject adaptive with 40% of adaptive\nfine-tuning that the averaged classification accuracy improved by 5.36% and\nstandard deviation reduced by 12.22% using two distinct, internationally\nreplicated datasets. These results outperformed in classification accuracy,\ncomputational time, and training efficiency, mainly due to the proposed Active\nSampling (AS) method for transfer learning.",
      "tldr_zh": "该研究探讨了脑机接口(BCI-P300)中的迁移学习(Transfer Learning)，旨在解决神经数据受个体健康状态、硬件差异和多中心数据多样性影响的问题。研究提出了一种结合卷积神经网络(Convolutional Neural Network)和自适应采样方法Active Sampling (AS)，基于Poison Sampling Disk (PDS)进行快速训练和校准，以提升模型从源数据到目标域的过渡适应性。在两个国际数据集上实验显示，使用40%自适应微调后，平均分类准确率提高了5.36%，标准差降低了12.22%，并在计算时间和训练效率上表现出色，从而改善了BCI的泛化性能和实际应用潜力。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "68",
        "I.2; J.6"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.17833v1",
      "published_date": "2024-12-14 14:20:21 UTC",
      "updated_date": "2024-12-14 14:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:41:24.436112"
    },
    {
      "arxiv_id": "2412.10838v1",
      "title": "Deep Learning Models for Colloidal Nanocrystal Synthesis",
      "title_zh": "胶体纳米晶体合成的深度学习模型",
      "authors": [
        "Kai Gu",
        "Yingping Liang",
        "Jiaming Su",
        "Peihan Sun",
        "Jia Peng",
        "Naihua Miao",
        "Zhimei Sun",
        "Ying Fu",
        "Haizheng Zhong",
        "Jun Zhang"
      ],
      "abstract": "Colloidal synthesis of nanocrystals usually includes complex chemical\nreactions and multi-step crystallization processes. Despite the great success\nin the past 30 years, it remains challenging to clarify the correlations\nbetween synthetic parameters of chemical reaction and physical properties of\nnanocrystals. Here, we developed a deep learning-based nanocrystal synthesis\nmodel that correlates synthetic parameters with the final size and shape of\ntarget nanocrystals, using a dataset of 3500 recipes covering 348 distinct\nnanocrystal compositions. The size and shape labels were obtained from\ntransmission electron microscope images using a segmentation model trained with\na semi-supervised algorithm on a dataset comprising 1.2 million nanocrystals.\nBy applying the reaction intermediate-based data augmentation method and\nelaborated descriptors, the synthesis model was able to predict nanocrystal's\nsize with a mean absolute error of 1.39 nm, while reaching an 89% average\naccuracy for shape classification. The synthesis model shows knowledge transfer\ncapabilities across different nanocrystals with inputs of new recipes. With\nthat, the influence of chemicals on the final size of nanocrystals was further\nevaluated, revealing the importance order of nanocrystal composition, precursor\nor ligand, and solvent. Overall, the deep learning-based nanocrystal synthesis\nmodel offers a powerful tool to expedite the development of high-quality\nnanocrystals.",
      "tldr_zh": "本研究开发了一个基于 deep learning 的模型，用于分析胶体纳米晶合成中合成参数（如化学反应条件）与纳米晶最终大小和形状的相关性。模型利用一个包含 3500 个配方的数据集（覆盖 348 种纳米晶组成），结合半监督算法训练的分割模型从透射电子显微镜图像中提取标签，并通过反应中间体数据增强和详细描述符进行预测。结果显示，该模型能以 1.39 nm 的平均绝对误差预测纳米晶大小，并达到 89% 的形状分类准确率，同时展现了知识转移能力，能评估化学成分、前体或配体、溶剂对大小的影响顺序。总之，这一工具有望加速高品质纳米晶的开发。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10838v1",
      "published_date": "2024-12-14 14:18:59 UTC",
      "updated_date": "2024-12-14 14:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:41:36.631250"
    },
    {
      "arxiv_id": "2412.12198v1",
      "title": "Pop-out vs. Glue: A Study on the pre-attentive and focused attention stages in Visual Search tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Hendrik Beukelman",
        "Wilder C. Rodrigues"
      ],
      "abstract": "This study explores visual search asymmetry and the detection process between\nparallel and serial search strategies, building upon Treisman's Feature\nIntegration Theory [3]. Our experiment examines how easy it is to locate an\noblique line among vertical distractors versus a vertical line among oblique\ndistractors, a framework previously validated by Treisman & Gormican (1988) [4]\nand Gupta et al. (2015) [1]. We hypothesised that an oblique target among\nvertical lines would produce a perceptual 'pop-out' effect, allowing for\nfaster, parallel search, while the reverse condition would require serial\nsearch strategy. Seventy-eight participants from Utrecht University engaged in\ntrials with varied target-distractor orientations and number of items. We\nmeasured reaction times and found a significant effect of target type on search\nspeed: oblique targets were identified more quickly, reflecting 'pop-out'\nbehaviour, while vertical targets demanded focused attention ('glue phase').\nOur results align with past findings, supporting our hypothesis on search\nasymmetry and its dependency on distinct visual features. Future research could\nbenefit from eye-tracking and neural network analysis, particularly for\nidentifying the neural processing of visual features in both parallel and\nserial search conditions.",
      "tldr_zh": "本研究基于 Treisman's Feature Integration Theory，探讨了视觉搜索任务中 pre-attentive 和 focused attention 阶段的不对称性，通过实验比较在垂直干扰项中寻找斜线（期望产生 pop-out 效果）和在斜线干扰项中寻找垂直线（期望需要串行搜索）。参与者包括78名 Utrecht University 学生，他们在不同目标-干扰项组合下进行试验，测量反应时间。结果显示，斜线目标被更快识别，体现了 pop-out 行为，而垂直目标则需要更多 focused attention，支持了搜索不对称性的假设。未来研究可借助 eye-tracking 和 neural network analysis，进一步分析视觉特征的神经处理过程。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Replication of Gupta et al work from 2015 paper",
      "pdf_url": "http://arxiv.org/pdf/2412.12198v1",
      "published_date": "2024-12-14 13:31:27 UTC",
      "updated_date": "2024-12-14 13:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:43:07.265836"
    },
    {
      "arxiv_id": "2412.10827v3",
      "title": "Rethinking Chain-of-Thought from the Perspective of Self-Training",
      "title_zh": "从自训练的视角重新审视链式思维",
      "authors": [
        "Zongqian Wu",
        "Baoduo Xu",
        "Ruochen Cui",
        "Mengmeng Zhan",
        "Xiaofeng Zhu",
        "Lei Feng"
      ],
      "abstract": "Chain-of-thought (CoT) reasoning has emerged as an effective approach for\nactivating latent capabilities in LLMs. Interestingly, we observe that both CoT\nreasoning and self-training share the core objective: iteratively leveraging\nmodel-generated information to progressively reduce prediction uncertainty.\nBuilding on this insight, we propose a novel CoT framework to improve reasoning\nperformance. Our framework integrates two key components: (i) a task-specific\nprompt module that optimizes the initial reasoning process, and (ii) an\nadaptive reasoning iteration module that dynamically refines the reasoning\nprocess and addresses the limitations of previous CoT approaches, \\ie\nover-reasoning and high similarity between consecutive reasoning iterations.\nExtensive experiments demonstrate that the proposed method achieves significant\nadvantages in both performance and computational efficiency.",
      "tldr_zh": "该研究从self-training的视角重新审视Chain-of-Thought (CoT) 推理，观察到两者共享核心目标：通过迭代利用模型生成的information来减少预测不确定性。论文提出一个新框架，包括任务-specific prompt module优化初始推理过程，以及adaptive reasoning iteration module动态精炼推理流程，以解决over-reasoning和高相似性问题。实验结果显示，该方法在性能和计算效率上均取得显著优势。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.10827v3",
      "published_date": "2024-12-14 13:12:50 UTC",
      "updated_date": "2025-02-12 11:41:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:43:18.981104"
    },
    {
      "arxiv_id": "2412.10826v1",
      "title": "Generative AI: A Pix2pix-GAN-Based Machine Learning Approach for Robust and Efficient Lung Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Sharmin Akter"
      ],
      "abstract": "Chest radiography is climacteric in identifying different pulmonary diseases,\nyet radiologist workload and inefficiency can lead to misdiagnoses. Automatic,\naccurate, and efficient segmentation of lung from X-ray images of chest is\nparamount for early disease detection. This study develops a deep learning\nframework using a Pix2pix Generative Adversarial Network (GAN) to segment\npulmonary abnormalities from CXR images. This framework's image preprocessing\nand augmentation techniques were properly incorporated with a U-Net-inspired\ngenerator-discriminator architecture. Initially, it loaded the CXR images and\nmanual masks from the Montgomery and Shenzhen datasets, after which\npreprocessing and resizing were performed. A U-Net generator is applied to the\nprocessed CXR images that yield segmented masks; then, a Discriminator Network\ndifferentiates between the generated and real masks. Montgomery dataset served\nas the model's training set in the study, and the Shenzhen dataset was used to\ntest its robustness, which was used here for the first time. An adversarial\nloss and an L1 distance were used to optimize the model in training. All\nmetrics, which assess precision, recall, F1 score, and Dice coefficient, prove\nthe effectiveness of this framework in pulmonary abnormality segmentation. It,\ntherefore, sets the basis for future studies to be performed shortly using\ndiverse datasets that could further confirm its clinical applicability in\nmedical imaging.",
      "tldr_zh": "这篇论文提出了一种基于 Pix2pix GAN 的深度学习框架，用于自动、准确地从胸部 X 光图像中分割肺部异常，以提高早期疾病检测效率并减少放射科医生的误诊风险。该框架整合了图像预处理、增强技术以及 U-Net 启发的生成器-判别器架构，使用 Montgomery 数据集进行训练，并在 Shenzhen 数据集上首次测试，通过对抗损失和 L1 距离优化模型。实验结果显示，该方法在精确度、召回率、F1 分数和 Dice coefficient 等指标上表现出色，为未来在更多数据集上的临床应用提供了坚实基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "6 pages, 12 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2412.10826v1",
      "published_date": "2024-12-14 13:12:09 UTC",
      "updated_date": "2024-12-14 13:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:43:31.458189"
    },
    {
      "arxiv_id": "2412.10817v2",
      "title": "Enhance Vision-Language Alignment with Noise",
      "title_zh": "利用噪声增强视觉-语言对齐",
      "authors": [
        "Sida Huang",
        "Hongyuan Zhang",
        "Xuelong Li"
      ],
      "abstract": "With the advancement of pre-trained vision-language (VL) models, enhancing\nthe alignment between visual and linguistic modalities in downstream tasks has\nemerged as a critical challenge. Different from existing fine-tuning methods\nthat add extra modules to these two modalities, we investigate whether the\nfrozen model can be fine-tuned by customized noise. Our approach is motivated\nby the scientific study of beneficial noise, namely Positive-incentive Noise\n(Pi-noise or $\\pi$-noise) , which quantitatively analyzes the impact of noise.\nIt therefore implies a new scheme to learn beneficial noise distribution that\ncan be employed to fine-tune VL models. Focusing on few-shot classification\ntasks based on CLIP, we reformulate the inference process of CLIP and apply\nvariational inference, demonstrating how to generate $\\pi$-noise towards visual\nand linguistic modalities. Then, we propose Positive-incentive Noise Injector\n(PiNI), which can fine-tune CLIP via injecting noise into both visual and text\nencoders. Since the proposed method can learn the distribution of beneficial\nnoise, we can obtain more diverse embeddings of vision and language to better\nalign these two modalities for specific downstream tasks within limited\ncomputational resources. We evaluate different noise incorporation approaches\nand network architectures of PiNI. The evaluation across 11 datasets\ndemonstrates its effectiveness.",
      "tldr_zh": "该论文探讨了通过定制化噪声提升视觉语言（VL）模型中视觉和语言模态的 alignment。作者引入 Positive-incentive Noise (Pi-noise) 概念，并基于 CLIP 的推理过程应用变分推理来生成有益噪声。论文提出 Positive-incentive Noise Injector (PiNI) 方法，通过向视觉和文本编码器注入噪声，微调冻结模型以获得更丰富的嵌入，从而改善 few-shot classification 任务的性能。在 11 个数据集上的评估结果证明了该方法的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10817v2",
      "published_date": "2024-12-14 12:58:15 UTC",
      "updated_date": "2024-12-17 02:35:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:43:42.435704"
    },
    {
      "arxiv_id": "2412.10804v1",
      "title": "Medical Manifestation-Aware De-Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Yuan Tian",
        "Shuo Wang",
        "Guangtao Zhai"
      ],
      "abstract": "Face de-identification (DeID) has been widely studied for common scenes, but\nremains under-researched for medical scenes, mostly due to the lack of\nlarge-scale patient face datasets. In this paper, we release MeMa, consisting\nof over 40,000 photo-realistic patient faces. MeMa is re-generated from massive\nreal patient photos. By carefully modulating the generation and data-filtering\nprocedures, MeMa avoids breaching real patient privacy, while ensuring rich and\nplausible medical manifestations. We recruit expert clinicians to annotate MeMa\nwith both coarse- and fine-grained labels, building the first medical-scene\nDeID benchmark. Additionally, we propose a baseline approach for this new\nmedical-aware DeID task, by integrating data-driven medical semantic priors\ninto the DeID procedure. Despite its conciseness and simplicity, our approach\nsubstantially outperforms previous ones. Dataset is available at\nhttps://github.com/tianyuan168326/MeMa-Pytorch.",
      "tldr_zh": "本研究针对医疗场景中的面部去识别（DeID）问题，发布了MeMa数据集，该数据集包含超过40,000张逼真的患者面部图像，通过生成和数据过滤技术确保隐私保护并保留丰富的医疗表现特征。研究者招募专家临床医生对MeMa进行粗粒度和细粒度标签标注，建立了首个医疗场景DeID基准。作者提出了一种基线方法，将数据驱动的医疗语义先验集成到DeID过程中，尽管方法简洁，但显著优于现有技术，为医疗图像隐私保护提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10804v1",
      "published_date": "2024-12-14 12:09:41 UTC",
      "updated_date": "2024-12-14 12:09:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:43:54.478421"
    },
    {
      "arxiv_id": "2412.12196v1",
      "title": "TrendSim: Simulating Trending Topics in Social Media Under Poisoning Attacks with LLM-based Multi-agent System",
      "title_zh": "翻译失败",
      "authors": [
        "Zeyu Zhang",
        "Jianxun Lian",
        "Chen Ma",
        "Yaning Qu",
        "Ye Luo",
        "Lei Wang",
        "Rui Li",
        "Xu Chen",
        "Yankai Lin",
        "Le Wu",
        "Xing Xie",
        "Ji-Rong Wen"
      ],
      "abstract": "Trending topics have become a significant part of modern social media,\nattracting users to participate in discussions of breaking events. However,\nthey also bring in a new channel for poisoning attacks, resulting in negative\nimpacts on society. Therefore, it is urgent to study this critical problem and\ndevelop effective strategies for defense. In this paper, we propose TrendSim,\nan LLM-based multi-agent system to simulate trending topics in social media\nunder poisoning attacks. Specifically, we create a simulation environment for\ntrending topics that incorporates a time-aware interaction mechanism,\ncentralized message dissemination, and an interactive system. Moreover, we\ndevelop LLM-based human-like agents to simulate users in social media, and\npropose prototype-based attackers to replicate poisoning attacks. Besides, we\nevaluate TrendSim from multiple aspects to validate its effectiveness. Based on\nTrendSim, we conduct simulation experiments to study four critical problems\nabout poisoning attacks on trending topics for social benefit.",
      "tldr_zh": "本文提出 TrendSim，一种基于 LLM-based multi-agent system，用于模拟社交媒体 Trending Topics 在 poisoning attacks 下的动态，旨在研究这些攻击对社会的影响。TrendSim 构建了包含时间感知交互机制、集中式消息传播和交互系统的模拟环境，并开发了 LLM-based human-like agents 来模拟用户行为，以及 prototype-based attackers 来重现攻击场景。通过多方面评估和实验，TrendSim 验证了其有效性，并探讨了四个关键问题，以制定防御策略并实现社会利益。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "19 pages, 9 tables, 8 figure",
      "pdf_url": "http://arxiv.org/pdf/2412.12196v1",
      "published_date": "2024-12-14 12:04:49 UTC",
      "updated_date": "2024-12-14 12:04:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:44:06.314040"
    },
    {
      "arxiv_id": "2412.10798v2",
      "title": "AuctionNet: A Novel Benchmark for Decision-Making in Large-Scale Games",
      "title_zh": "AuctionNet：大规模游戏决策的新型基准",
      "authors": [
        "Kefan Su",
        "Yusen Huo",
        "Zhilin Zhang",
        "Shuai Dou",
        "Chuan Yu",
        "Jian Xu",
        "Zongqing Lu",
        "Bo Zheng"
      ],
      "abstract": "Decision-making in large-scale games is an essential research area in\nartificial intelligence (AI) with significant real-world impact. However, the\nlimited access to realistic large-scale game environments has hindered research\nprogress in this area. In this paper, we present AuctionNet, a benchmark for\nbid decision-making in large-scale ad auctions derived from a real-world online\nadvertising platform. AuctionNet is composed of three parts: an ad auction\nenvironment, a pre-generated dataset based on the environment, and performance\nevaluations of several baseline bid decision-making algorithms. More\nspecifically, the environment effectively replicates the integrity and\ncomplexity of real-world ad auctions through the interaction of several\nmodules: the ad opportunity generation module employs deep generative networks\nto bridge the gap between simulated and real-world data while mitigating the\nrisk of sensitive data exposure; the bidding module implements diverse\nauto-bidding agents trained with different decision-making algorithms; and the\nauction module is anchored in the classic Generalized Second Price (GSP)\nauction but also allows for customization of auction mechanisms as needed. To\nfacilitate research and provide insights into the environment, we have also\npre-generated a substantial dataset based on the environment. The dataset\ncontains 10 million ad opportunities, 48 diverse auto-bidding agents, and over\n500 million auction records. Performance evaluations of baseline algorithms\nsuch as linear programming, reinforcement learning, and generative models for\nbid decision-making are also presented as a part of AuctionNet. We believe that\nAuctionNet is applicable not only to research on bid decision-making in ad\nauctions but also to the general area of decision-making in large-scale games.",
      "tldr_zh": "本文提出 AuctionNet，一种新型基准，用于评估大规模游戏中决策问题，特别针对在线广告竞拍的出价决策，以解决真实环境缺失的挑战。AuctionNet 由广告竞拍环境（包括使用深度生成网络的广告机会生成模块、多种算法的自动出价代理，以及基于 Generalized Second Price (GSP) 拍卖的模块）、一个包含 1000 万广告机会和超过 5 亿拍卖记录的预生成数据集，以及对基线算法如线性规划、强化学习和生成模型的性能评估组成。实验结果展示了这些算法的表现，该基准不仅适用于广告竞拍决策研究，还可扩展到一般大规模游戏决策领域。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10798v2",
      "published_date": "2024-12-14 11:31:21 UTC",
      "updated_date": "2024-12-28 08:30:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:44:19.664482"
    },
    {
      "arxiv_id": "2412.10786v1",
      "title": "Optimizing Few-Step Sampler for Diffusion Probabilistic Model",
      "title_zh": "针对扩散概率模型的少步采样器优化",
      "authors": [
        "Jen-Yuan Huang"
      ],
      "abstract": "Diffusion Probabilistic Models (DPMs) have demonstrated exceptional\ncapability of generating high-quality and diverse images, but their practical\napplication is hindered by the intensive computational cost during inference.\nThe DPM generation process requires solving a Probability-Flow Ordinary\nDifferential Equation (PF-ODE), which involves discretizing the integration\ndomain into intervals for numerical approximation. This corresponds to the\nsampling schedule of a diffusion ODE solver, and we notice the solution from a\nfirst-order solver can be expressed as a convex combination of model outputs at\nall scheduled time-steps. We derive an upper bound for the discretization error\nof the sampling schedule, which can be efficiently optimized with Monte-Carlo\nestimation. Building on these theoretical results, we purpose a two-phase\nalternating optimization algorithm. In Phase-1, the sampling schedule is\noptimized for the pre-trained DPM; in Phase-2, the DPM further tuned on the\nselected time-steps. Experiments on a pre-trained DPM for ImageNet64 dataset\ndemonstrate the purposed method consistently improves the baseline across\nvarious number of sampling steps.",
      "tldr_zh": "本研究针对Diffusion Probabilistic Models (DPMs) 在图像生成中计算成本高的难题，提出了一种优化Few-Step Sampler的方法。通过推导采样时间表(discretization error)的上界，并利用Monte-Carlo estimation进行高效优化，论文设计了一个两阶段交替优化算法：Phase-1优化预训练DPM的采样时间表，Phase-2在选定时间步上进一步微调DPM。实验结果显示，该方法在ImageNet64数据集上，在各种采样步数下均显著提升了基线模型的性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10786v1",
      "published_date": "2024-12-14 10:47:52 UTC",
      "updated_date": "2024-12-14 10:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:44:30.045184"
    },
    {
      "arxiv_id": "2412.10782v2",
      "title": "ANaGRAM: A Natural Gradient Relative to Adapted Model for efficient PINNs learning",
      "title_zh": "翻译失败",
      "authors": [
        "Nilo Schwencke",
        "Cyril Furtlehner"
      ],
      "abstract": "In the recent years, Physics Informed Neural Networks (PINNs) have received\nstrong interest as a method to solve PDE driven systems, in particular for data\nassimilation purpose. This method is still in its infancy, with many\nshortcomings and failures that remain not properly understood. In this paper we\npropose a natural gradient approach to PINNs which contributes to speed-up and\nimprove the accuracy of the training. Based on an in depth analysis of the\ndifferential geometric structures of the problem, we come up with two distinct\ncontributions: (i) a new natural gradient algorithm that scales as $\\min(P^2S,\nS^2P)$, where $P$ is the number of parameters, and $S$ the batch size; (ii) a\nmathematically principled reformulation of the PINNs problem that allows the\nextension of natural gradient to it, with proved connections to Green's\nfunction theory.",
      "tldr_zh": "这篇论文针对 Physics Informed Neural Networks (PINNs) 在解决 PDE 驱动系统时存在的训练效率和准确性问题，提出了一种新的自然梯度方法 ANaGRAM，以加速和优化 PINNs 的学习过程。通过对问题差分几何结构的深入分析，该方法贡献包括：(i) 一个计算复杂度为 min(P²S, S²P) 的自然梯度算法，其中 P 为参数数量、S 为批量大小；(ii) 一个数学上严谨的 PINNs 问题重述，将自然梯度扩展到该领域，并与 Green's function theory 建立联系。该方法为 PINNs 的数据同化应用提供了更高效且准确的框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "math.OC",
        "I.2.8"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted in ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10782v2",
      "published_date": "2024-12-14 10:38:09 UTC",
      "updated_date": "2025-03-19 00:47:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:44:43.162857"
    },
    {
      "arxiv_id": "2412.10778v2",
      "title": "Sample-efficient Unsupervised Policy Cloning from Ensemble Self-supervised Labeled Videos",
      "title_zh": "基于集成自监督标记视频的样本高效无监督策略克隆",
      "authors": [
        "Xin Liu",
        "Yaran Chen",
        "Haoran Li"
      ],
      "abstract": "Current advanced policy learning methodologies have demonstrated the ability\nto develop expert-level strategies when provided enough information. However,\ntheir requirements, including task-specific rewards, action-labeled expert\ntrajectories, and huge environmental interactions, can be expensive or even\nunavailable in many scenarios. In contrast, humans can efficiently acquire\nskills within a few trials and errors by imitating easily accessible internet\nvideos, in the absence of any other supervision. In this paper, we try to let\nmachines replicate this efficient watching-and-learning process through\nUnsupervised Policy from Ensemble Self-supervised labeled Videos (UPESV), a\nnovel framework to efficiently learn policies from action-free videos without\nrewards and any other expert supervision. UPESV trains a video labeling model\nto infer the expert actions in expert videos through several organically\ncombined self-supervised tasks. Each task performs its duties, and they\ntogether enable the model to make full use of both action-free videos and\nreward-free interactions for robust dynamics understanding and advanced action\nprediction. Simultaneously, UPESV clones a policy from the labeled expert\nvideos, in turn collecting environmental interactions for self-supervised\ntasks. After a sample-efficient, unsupervised, and iterative training process,\nUPESV obtains an advanced policy based on a robust video labeling model.\nExtensive experiments in sixteen challenging procedurally generated\nenvironments demonstrate that the proposed UPESV achieves state-of-the-art\ninteraction-limited policy learning performance (outperforming five current\nadvanced baselines on 12/16 tasks) without exposure to any other supervision\nexcept for videos.",
      "tldr_zh": "本文提出 UPESV 框架，通过自监督任务从无动作视频中实现样本高效的无监督政策克隆（Unsupervised Policy Cloning），无需任务特定奖励或专家监督。该框架训练视频标记模型来推断专家动作，利用多个有机结合的自监督任务进行稳健的动态理解和动作预测，同时通过迭代过程从标记视频克隆政策并收集环境交互。在 16 个挑战性环境中，UPESV 在 12/16 任务上超越了 5 个先进基线方法，展示了其高效的学习性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ICRA 2025, 8 pages",
      "pdf_url": "http://arxiv.org/pdf/2412.10778v2",
      "published_date": "2024-12-14 10:12:22 UTC",
      "updated_date": "2025-04-08 08:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:44:55.308939"
    },
    {
      "arxiv_id": "2412.10776v1",
      "title": "Boosting ViT-based MRI Reconstruction from the Perspectives of Frequency Modulation, Spatial Purification, and Scale Diversification",
      "title_zh": "从频率调制、空间净化和尺度多样化的视角提升基于 ViT 的 MRI 重建",
      "authors": [
        "Yucong Meng",
        "Zhiwei Yang",
        "Yonghong Shi",
        "Zhijian Song"
      ],
      "abstract": "The accelerated MRI reconstruction process presents a challenging ill-posed\ninverse problem due to the extensive under-sampling in k-space. Recently,\nVision Transformers (ViTs) have become the mainstream for this task,\ndemonstrating substantial performance improvements. However, there are still\nthree significant issues remain unaddressed: (1) ViTs struggle to capture\nhigh-frequency components of images, limiting their ability to detect local\ntextures and edge information, thereby impeding MRI restoration; (2) Previous\nmethods calculate multi-head self-attention (MSA) among both related and\nunrelated tokens in content, introducing noise and significantly increasing\ncomputational burden; (3) The naive feed-forward network in ViTs cannot model\nthe multi-scale information that is important for image restoration. In this\npaper, we propose FPS-Former, a powerful ViT-based framework, to address these\nissues from the perspectives of frequency modulation, spatial purification, and\nscale diversification. Specifically, for issue (1), we introduce a frequency\nmodulation attention module to enhance the self-attention map by adaptively\nre-calibrating the frequency information in a Laplacian pyramid. For issue (2),\nwe customize a spatial purification attention module to capture interactions\namong closely related tokens, thereby reducing redundant or irrelevant feature\nrepresentations. For issue (3), we propose an efficient feed-forward network\nbased on a hybrid-scale fusion strategy. Comprehensive experiments conducted on\nthree public datasets show that our FPS-Former outperforms state-of-the-art\nmethods while requiring lower computational costs.",
      "tldr_zh": "该论文针对Vision Transformers (ViTs)在MRI重建中的不足，提出了一种名为FPS-Former的框架，从频率调制、空间净化和尺度多样化角度解决问题。具体而言，它引入频率调制注意力模块使用Laplacian pyramid自适应校准高频信息、空间净化注意力模块仅捕捉相关token交互以减少噪声，以及基于混合尺度融合策略的前馈网络来建模多尺度特征。实验结果显示，FPS-Former在三个公共数据集上优于现有最先进方法，同时显著降低了计算成本。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10776v1",
      "published_date": "2024-12-14 10:03:08 UTC",
      "updated_date": "2024-12-14 10:03:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:45:06.975898"
    },
    {
      "arxiv_id": "2412.10761v1",
      "title": "Rebalanced Vision-Language Retrieval Considering Structure-Aware Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Yang",
        "Wenjuan Xi",
        "Luping Zhou",
        "Jinhui Tang"
      ],
      "abstract": "Vision-language retrieval aims to search for similar instances in one\nmodality based on queries from another modality. The primary objective is to\nlearn cross-modal matching representations in a latent common space. Actually,\nthe assumption underlying cross-modal matching is modal balance, where each\nmodality contains sufficient information to represent the others. However,\nnoise interference and modality insufficiency often lead to modal imbalance,\nmaking it a common phenomenon in practice. The impact of imbalance on retrieval\nperformance remains an open question. In this paper, we first demonstrate that\nultimate cross-modal matching is generally sub-optimal for cross-modal\nretrieval when imbalanced modalities exist. The structure of instances in the\ncommon space is inherently influenced when facing imbalanced modalities, posing\na challenge to cross-modal similarity measurement. To address this issue, we\nemphasize the importance of meaningful structure-preserved matching.\nAccordingly, we propose a simple yet effective method to rebalance cross-modal\nmatching by learning structure-preserved matching representations.\nSpecifically, we design a novel multi-granularity cross-modal matching that\nincorporates structure-aware distillation alongside the cross-modal matching\nloss. While the cross-modal matching loss constraints instance-level matching,\nthe structure-aware distillation further regularizes the geometric consistency\nbetween learned matching representations and intra-modal representations\nthrough the developed relational matching. Extensive experiments on different\ndatasets affirm the superior cross-modal retrieval performance of our approach,\nsimultaneously enhancing single-modal retrieval capabilities compared to the\nbaseline models.",
      "tldr_zh": "该论文探讨了视觉语言检索(Vision-Language Retrieval)中模态不平衡问题，证明了传统跨模态匹配(Cross-Modal Matching)在噪声干扰和模态不足情况下会降低性能。作者提出了一种重新平衡方法，通过多粒度跨模态匹配结合结构感知蒸馏(Structure-Aware Distillation)，来学习结构保留的匹配表示，确保实例级匹配和几何一致性。实验在多个数据集上验证了该方法的有效性，不仅提升了跨模态检索性能，还同时改善了单模态检索能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10761v1",
      "published_date": "2024-12-14 09:10:36 UTC",
      "updated_date": "2024-12-14 09:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:45:19.409222"
    },
    {
      "arxiv_id": "2412.10726v1",
      "title": "NoisyEQA: Benchmarking Embodied Question Answering Against Noisy Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Wu",
        "Chuhao Zhou",
        "Yen Heng Wong",
        "Lin Gu",
        "Jianfei Yang"
      ],
      "abstract": "The rapid advancement of Vision-Language Models (VLMs) has significantly\nadvanced the development of Embodied Question Answering (EQA), enhancing\nagents' abilities in language understanding and reasoning within complex and\nrealistic scenarios. However, EQA in real-world scenarios remains challenging,\nas human-posed questions often contain noise that can interfere with an agent's\nexploration and response, bringing challenges especially for language beginners\nand non-expert users. To address this, we introduce a NoisyEQA benchmark\ndesigned to evaluate an agent's ability to recognize and correct noisy\nquestions. This benchmark introduces four common types of noise found in\nreal-world applications: Latent Hallucination Noise, Memory Noise, Perception\nNoise, and Semantic Noise generated through an automated dataset creation\nframework. Additionally, we also propose a 'Self-Correction' prompting\nmechanism and a new evaluation metric to enhance and measure both noise\ndetection capability and answer quality. Our comprehensive evaluation reveals\nthat current EQA agents often struggle to detect noise in questions, leading to\nresponses that frequently contain erroneous information. Through our\nSelf-Correct Prompting mechanism, we can effectively improve the accuracy of\nagent answers.",
      "tldr_zh": "该研究引入了 NoisyEQA 基准，用于评估 Embodied Question Answering (EQA) 代理在处理现实世界噪声查询时的性能，针对人类提问中的常见问题如 Latent Hallucination Noise、Memory Noise、Perception Noise 和 Semantic Noise，通过自动数据集创建框架生成这些噪声。论文提出 'Self-Correction' prompting 机制和一个新评价指标，以提升代理的噪声检测能力和答案质量。实验结果显示，当前 EQA 代理在识别噪声方面存在困难，导致响应错误，但使用该机制可显著提高答案准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10726v1",
      "published_date": "2024-12-14 07:52:24 UTC",
      "updated_date": "2024-12-14 07:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:45:31.192016"
    },
    {
      "arxiv_id": "2502.15684v1",
      "title": "An Agent Framework for Real-Time Financial Information Searching with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinzheng Li",
        "Jingshu Zhang",
        "Hongguang Li",
        "Yiqing Shen"
      ],
      "abstract": "Financial decision-making requires processing vast amounts of real-time\ninformation while understanding their complex temporal relationships. While\ntraditional search engines excel at providing real-time information access,\nthey often struggle to comprehend sophisticated user intentions and contextual\nnuances. Conversely, Large Language Models (LLMs) demonstrate reasoning and\ninteraction capabilities but may generate unreliable outputs without access to\ncurrent data. While recent attempts have been made to combine LLMs with search\ncapabilities, they suffer from (1) restricted access to specialized financial\ndata, (2) static query structures that cannot adapt to dynamic market\nconditions, and (3) insufficient temporal awareness in result generation. To\naddress these challenges, we present FinSearch, a novel agent-based search\nframework specifically designed for financial applications that interface with\ndiverse financial data sources including market, stock, and news data.\nInnovatively, FinSearch comprises four components: (1) an LLM-based multi-step\nsearch pre-planner that decomposes user queries into structured sub-queries\nmapped to specific data sources through a graph representation; (2) a search\nexecutor with an LLM-based adaptive query rewriter that executes the searching\nof each sub-query while dynamically refining the sub-queries in its subsequent\nnode based on intermediate search results; (3) a temporal weighting mechanism\nthat prioritizes information relevance based on the deduced time context from\nthe user's query; (4) an LLM-based response generator that synthesizes results\ninto coherent, contextually appropriate outputs. To evaluate FinSearch, we\nconstruct FinSearchBench-24, a benchmark of 1,500 four-choice questions across\nthe stock market, rate changes, monetary policy, and industry developments\nspanning from June to October 2024.",
      "tldr_zh": "这篇论文提出了FinSearch，一个基于Large Language Models (LLMs)的代理框架，用于实时金融信息搜索，旨在解决传统搜索引擎理解用户意图不足以及LLMs缺乏实时数据访问的问题。框架包括四个关键组件：(1) LLM-based multi-step search pre-planner，将用户查询分解为结构化子查询并映射到特定数据源；(2) 搜索执行器，结合LLM-based adaptive query rewriter，根据中间结果动态调整查询；(3) temporal weighting mechanism，根据查询的时间上下文优先相关信息；(4) LLM-based response generator，合成连贯的输出。作者构建了FinSearchBench-24基准，包含1500个四选一问题，涵盖2024年6月至10月的股票市场、利率变化、货币政策和行业发展，以评估框架的性能。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15684v1",
      "published_date": "2024-12-14 07:26:39 UTC",
      "updated_date": "2024-12-14 07:26:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:45:44.138080"
    },
    {
      "arxiv_id": "2412.10719v1",
      "title": "Just a Few Glances: Open-Set Visual Perception with Image Prompt Paradigm",
      "title_zh": "只需几瞥：基于图像提示范式的开放集视觉感知",
      "authors": [
        "Jinrong Zhang",
        "Penghui Wang",
        "Chunxiao Liu",
        "Wei Liu",
        "Dian Jin",
        "Qiong Zhang",
        "Erli Meng",
        "Zhengnan Hu"
      ],
      "abstract": "To break through the limitations of pre-training models on fixed categories,\nOpen-Set Object Detection (OSOD) and Open-Set Segmentation (OSS) have attracted\na surge of interest from researchers. Inspired by large language models,\nmainstream OSOD and OSS methods generally utilize text as a prompt, achieving\nremarkable performance. Following SAM paradigm, some researchers use visual\nprompts, such as points, boxes, and masks that cover detection or segmentation\ntargets. Despite these two prompt paradigms exhibit excellent performance, they\nalso reveal inherent limitations. On the one hand, it is difficult to\naccurately describe characteristics of specialized category using textual\ndescription. On the other hand, existing visual prompt paradigms heavily rely\non multi-round human interaction, which hinders them being applied to fully\nautomated pipeline. To address the above issues, we propose a novel prompt\nparadigm in OSOD and OSS, that is, \\textbf{Image Prompt Paradigm}. This brand\nnew prompt paradigm enables to detect or segment specialized categories without\nmulti-round human intervention. To achieve this goal, the proposed image prompt\nparadigm uses just a few image instances as prompts, and we propose a novel\nframework named \\textbf{MI Grounding} for this new paradigm. In this framework,\nhigh-quality image prompts are automatically encoded, selected and fused,\nachieving the single-stage and non-interactive inference. We conduct extensive\nexperiments on public datasets, showing that MI Grounding achieves competitive\nperformance on OSOD and OSS benchmarks compared to text prompt paradigm methods\nand visual prompt paradigm methods. Moreover, MI Grounding can greatly\noutperform existing method on our constructed specialized ADR50K dataset.",
      "tldr_zh": "该论文针对 Open-Set Object Detection (OSOD) 和 Open-Set Segmentation (OSS) 的局限性，提出了一种新颖的 Image Prompt Paradigm，使用少数图像实例作为提示，避免了文本提示的描述不准和视觉提示的多轮交互依赖。作者开发了 MI Grounding 框架，该框架自动编码、选择和融合高质量图像提示，实现单阶段、非交互式推理。实验结果显示，MI Grounding 在公共数据集上与文本和视觉提示方法相比具有竞争力，并在自建的专用数据集 ADR50K 上显著优于现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.4"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10719v1",
      "published_date": "2024-12-14 07:23:14 UTC",
      "updated_date": "2024-12-14 07:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:45:55.316312"
    },
    {
      "arxiv_id": "2412.10717v1",
      "title": "HITgram: A Platform for Experimenting with n-gram Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Shibaranjani Dasgupta",
        "Chandan Maity",
        "Somdip Mukherjee",
        "Rohan Singh",
        "Diptendu Dutta",
        "Debasish Jana"
      ],
      "abstract": "Large language models (LLMs) are powerful but resource intensive, limiting\naccessibility. HITgram addresses this gap by offering a lightweight platform\nfor n-gram model experimentation, ideal for resource-constrained environments.\nIt supports unigrams to 4-grams and incorporates features like context\nsensitive weighting, Laplace smoothing, and dynamic corpus management to\ne-hance prediction accuracy, even for unseen word sequences. Experiments\ndemonstrate HITgram's efficiency, achieving 50,000 tokens/second and generating\n2-grams from a 320MB corpus in 62 seconds. HITgram scales efficiently,\nconstructing 4-grams from a 1GB file in under 298 seconds on an 8 GB RAM\nsystem. Planned enhancements include multilingual support, advanced smoothing,\nparallel processing, and model saving, further broadening its utility.",
      "tldr_zh": "HITgram 是一个轻量级平台，旨在解决大型语言模型(LLMs)资源密集问题，提供 n-gram 模型实验工具，适合资源受限环境。平台支持从 unigrams 到 4-grams，并整合上下文敏感权重、Laplace smoothing 和动态语料库管理，以提升对未见词序列的预测准确性。实验结果显示其高效性能，可处理 50,000 tokens/秒，并从 320MB 语料库生成 2-grams 在 62 秒内完成，从 1GB 文件构建 4-grams 在 8GB RAM 系统上不到 298 秒。未来计划包括添加多语言支持、先进平滑技术、并行处理和模型保存，进一步提升其实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10717v1",
      "published_date": "2024-12-14 07:20:35 UTC",
      "updated_date": "2024-12-14 07:20:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:46:08.205714"
    },
    {
      "arxiv_id": "2412.10716v1",
      "title": "Control of Overfitting with Physics",
      "title_zh": "翻译失败",
      "authors": [
        "Sergei V. Kozyrev",
        "Ilya A Lopatin",
        "Alexander N Pechen"
      ],
      "abstract": "While there are many works on the applications of machine learning, not so\nmany of them are trying to understand the theoretical justifications to explain\ntheir efficiency. In this work, overfitting control (or generalization\nproperty) in machine learning is explained using analogies from physics and\nbiology. For stochastic gradient Langevin dynamics, we show that the Eyring\nformula of kinetic theory allows to control overfitting in the algorithmic\nstability approach - when wide minima of the risk function with low free energy\ncorrespond to low overfitting. For the generative adversarial network (GAN)\nmodel, we establish an analogy between GAN and the predator-prey model in\nbiology. An application of this analogy allows us to explain the selection of\nwide likelihood maxima and overfitting reduction for GANs.",
      "tldr_zh": "这篇论文探讨了机器学习中过拟合控制（或泛化性能）的理论基础，通过物理和生物学的类比进行解释。对于 stochastic gradient Langevin dynamics，作者运用 Eyring formula 和算法稳定性方法，证明风险函数的宽最小值与低自由能对应低过拟合。对于 generative adversarial network (GAN) 模型，论文建立 GAN 与生物学 predator-prey 模型的类比，从而解释 GAN 如何选择宽似然最大值并减少过拟合。这些发现为机器学习的理论基础提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.10716v1",
      "published_date": "2024-12-14 07:20:33 UTC",
      "updated_date": "2024-12-14 07:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:48:19.160096"
    },
    {
      "arxiv_id": "2412.10713v1",
      "title": "RAT: Adversarial Attacks on Deep Reinforcement Agents for Targeted Behaviors",
      "title_zh": "翻译失败",
      "authors": [
        "Fengshuo Bai",
        "Runze Liu",
        "Yali Du",
        "Ying Wen",
        "Yaodong Yang"
      ],
      "abstract": "Evaluating deep reinforcement learning (DRL) agents against targeted behavior\nattacks is critical for assessing their robustness. These attacks aim to\nmanipulate the victim into specific behaviors that align with the attacker's\nobjectives, often bypassing traditional reward-based defenses. Prior methods\nhave primarily focused on reducing cumulative rewards; however, rewards are\ntypically too generic to capture complex safety requirements effectively. As a\nresult, focusing solely on reward reduction can lead to suboptimal attack\nstrategies, particularly in safety-critical scenarios where more precise\nbehavior manipulation is needed. To address these challenges, we propose RAT, a\nmethod designed for universal, targeted behavior attacks. RAT trains an\nintention policy that is explicitly aligned with human preferences, serving as\na precise behavioral target for the adversary. Concurrently, an adversary\nmanipulates the victim's policy to follow this target behavior. To enhance the\neffectiveness of these attacks, RAT dynamically adjusts the state occupancy\nmeasure within the replay buffer, allowing for more controlled and effective\nbehavior manipulation. Our empirical results on robotic simulation tasks\ndemonstrate that RAT outperforms existing adversarial attack algorithms in\ninducing specific behaviors. Additionally, RAT shows promise in improving agent\nrobustness, leading to more resilient policies. We further validate RAT by\nguiding Decision Transformer agents to adopt behaviors aligned with human\npreferences in various MuJoCo tasks, demonstrating its effectiveness across\ndiverse tasks.",
      "tldr_zh": "本文提出 RAT 方法，用于针对深度强化学习(DRL)代理的通用、针对性行为攻击，旨在解决现有攻击策略仅关注奖励减少而忽略复杂安全需求的局限性。RAT 通过训练一个与人类偏好对齐的意图策略，并动态调整回放缓冲区的状态占用度，来精确操纵代理执行特定行为。实验在机器人模拟任务中显示，RAT 比现有算法更有效，且能提升代理的鲁棒性，导致更坚固的政策。在 MuJoCo 任务中，RAT 成功指导 Decision Transformer 代理采用与人类偏好对齐的行为，证明其在多样任务中的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10713v1",
      "published_date": "2024-12-14 06:56:11 UTC",
      "updated_date": "2024-12-14 06:56:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:46:34.299794"
    },
    {
      "arxiv_id": "2412.15246v1",
      "title": "Accelerating Retrieval-Augmented Generation",
      "title_zh": "加速检索增强生成",
      "authors": [
        "Derrick Quinn",
        "Mohammad Nouri",
        "Neel Patel",
        "John Salihu",
        "Alireza Salemi",
        "Sukhan Lee",
        "Hamed Zamani",
        "Mohammad Alian"
      ],
      "abstract": "An evolving solution to address hallucination and enhance accuracy in large\nlanguage models (LLMs) is Retrieval-Augmented Generation (RAG), which involves\naugmenting LLMs with information retrieved from an external knowledge source,\nsuch as the web. This paper profiles several RAG execution pipelines and\ndemystifies the complex interplay between their retrieval and generation\nphases. We demonstrate that while exact retrieval schemes are expensive, they\ncan reduce inference time compared to approximate retrieval variants because an\nexact retrieval model can send a smaller but more accurate list of documents to\nthe generative model while maintaining the same end-to-end accuracy. This\nobservation motivates the acceleration of the exact nearest neighbor search for\nRAG.\n  In this work, we design Intelligent Knowledge Store (IKS), a type-2 CXL\ndevice that implements a scale-out near-memory acceleration architecture with a\nnovel cache-coherent interface between the host CPU and near-memory\naccelerators. IKS offers 13.4-27.9x faster exact nearest neighbor search over a\n512GB vector database compared with executing the search on Intel Sapphire\nRapids CPUs. This higher search performance translates to 1.7-26.3x lower\nend-to-end inference time for representative RAG applications. IKS is\ninherently a memory expander; its internal DRAM can be disaggregated and used\nfor other applications running on the server to prevent DRAM, which is the most\nexpensive component in today's servers, from being stranded.",
      "tldr_zh": "这篇论文探讨了如何加速 Retrieval-Augmented Generation (RAG)，以减少大型语言模型 (LLMs) 中的 hallucination 并提升准确性。作者分析了 RAG 的执行管道，发现精确的 nearest neighbor search 尽管计算开销较大，却能通过发送更小且准确的文档列表来缩短整体推理时间，从而激发了对其加速的需求。论文引入了 Intelligent Knowledge Store (IKS)，一个基于 type-2 CXL 设备的 scale-out near-memory 加速架构，能够将 512GB 向量数据库的 nearest neighbor search 速度比 Intel Sapphire Rapids CPUs 提高 13.4-27.9 倍，导致 RAG 应用的端到端推理时间降低 1.7-26.3 倍；此外，IKS 还可作为内存扩展器，将内部 DRAM 用于其他服务器应用，避免资源浪费。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.AR",
        "cs.DC",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.15246v1",
      "published_date": "2024-12-14 06:47:56 UTC",
      "updated_date": "2024-12-14 06:47:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:46:43.227054"
    },
    {
      "arxiv_id": "2412.10705v1",
      "title": "Efficient Adaptation of Multilingual Models for Japanese ASR",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Bajo",
        "Haruka Fukukawa",
        "Ryuji Morita",
        "Yuma Ogasawara"
      ],
      "abstract": "This study explores fine-tuning multilingual ASR (Automatic Speech\nRecognition) models, specifically OpenAI's Whisper-Tiny, to improve performance\nin Japanese. While multilingual models like Whisper offer versatility, they\noften lack precision in specific languages. Conversely, monolingual models like\nReazonSpeech excel in language-specific tasks but are less adaptable. Using\nJapanese-specific datasets and Low-Rank Adaptation (LoRA) along with end-to-end\n(E2E) training, we fine-tuned Whisper-Tiny to bridge this gap. Our results show\nthat fine-tuning reduced Whisper-Tiny's Character Error Rate (CER) from 32.7 to\n20.8 with LoRA and to 14.7 with end-to-end fine-tuning, surpassing\nWhisper-Base's CER of 20.2. However, challenges with domain-specific terms\nremain, highlighting the need for specialized datasets. These findings\ndemonstrate that fine-tuning multilingual models can achieve strong\nlanguage-specific performance while retaining their flexibility. This approach\nprovides a scalable solution for improving ASR in resource-constrained\nenvironments and languages with complex writing systems like Japanese.",
      "tldr_zh": "本研究探讨了微调多语言ASR（Automatic Speech Recognition）模型Whisper-Tiny，以提升日语识别性能，采用日语特定数据集、Low-Rank Adaptation (LoRA)以及端到端(E2E)训练方法。结果显示，Whisper-Tiny的Character Error Rate (CER)从32.7降低到20.8（使用LoRA）和14.7（E2E训练），超过了Whisper-Base的20.2。虽仍面临领域特定术语的挑战，但此方法证明微调多语言模型能实现强有力的语言特定性能，同时保持灵活性，为资源受限环境和复杂书写系统语言如日语提供可扩展解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10705v1",
      "published_date": "2024-12-14 06:32:16 UTC",
      "updated_date": "2024-12-14 06:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:48:55.666912"
    },
    {
      "arxiv_id": "2412.10689v1",
      "title": "Learning to Verify Summary Facts with Fine-Grained LLM Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Jihwan Oh",
        "Jeonghwan Choi",
        "Nicole Hee-Yeon Kim",
        "Taewon Yun",
        "Hwanjun Song"
      ],
      "abstract": "Training automatic summary fact verifiers often faces the challenge of a lack\nof human-labeled data. In this paper, we explore alternative way of leveraging\nLarge Language Model (LLM) generated feedback to address the inherent\nlimitation of using human-labeled data. We introduce FineSumFact, a large-scale\ndataset containing fine-grained factual feedback on summaries. We employ 10\ndistinct LLMs for diverse summary generation and Llama-3-70B-Instruct for\nfeedback. We utilize this dataset to fine-tune the lightweight open-source\nmodel Llama-3-8B-Instruct, optimizing resource efficiency while maintaining\nhigh performance. Our experimental results reveal that the model trained on\nextensive LLM-generated datasets surpasses that trained on smaller\nhuman-annotated datasets when evaluated using human-generated test sets.\nFine-tuning fact verification models with LLM feedback can be more effective\nand cost-efficient than using human feedback. The dataset is available at\nhttps://github.com/DISL-Lab/FineSumFact.",
      "tldr_zh": "本论文探讨了训练摘要事实验证器时缺乏人类标注数据的挑战，并提出使用细粒度Large Language Model (LLM)反馈作为替代方案。研究构建了FineSumFact数据集，通过10个不同LLM生成摘要，并利用Llama-3-70B-Instruct提供事实反馈，然后微调Llama-3-8B-Instruct模型以实现资源高效和高性能。实验结果表明，使用LLM生成的数据集训练的模型在人类生成测试集上表现优于小型人类标注数据集，证明了LLM反馈在有效性和成本方面更具优势。该方法为未来事实验证任务提供了高效的训练框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at COLING 2025",
      "pdf_url": "http://arxiv.org/pdf/2412.10689v1",
      "published_date": "2024-12-14 05:28:44 UTC",
      "updated_date": "2024-12-14 05:28:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:49:07.494239"
    },
    {
      "arxiv_id": "2412.10675v1",
      "title": "Chasing Progress, Not Perfection: Revisiting Strategies for End-to-End LLM Plan Generation",
      "title_zh": "追逐进步，而非完美：重新审视端到端 LLM 计划生成的策略",
      "authors": [
        "Sukai Huang",
        "Trevor Cohn",
        "Nir Lipovetzky"
      ],
      "abstract": "The capability of Large Language Models (LLMs) to plan remains a topic of\ndebate. Some critics argue that strategies to boost LLMs' reasoning skills are\nineffective in planning tasks, while others report strong outcomes merely from\ntraining models on a planning corpus. This study reassesses recent strategies\nby developing an end-to-end LLM planner and employing diverse metrics for a\nthorough evaluation. We find that merely fine-tuning LLMs on a corpus of\nplanning instances does not lead to robust planning skills, as indicated by\npoor performance on out-of-distribution test sets. At the same time, we find\nthat various strategies, including Chain-of-Thought, do enhance the probability\nof a plan being executable. This indicates progress towards better plan\nquality, despite not directly enhancing the final validity rate. Among the\nstrategies we evaluated, reinforcement learning with our novel `Longest\nContiguous Common Subsequence' reward emerged as the most effective,\ncontributing to both plan validity and executability. Overall, our research\naddresses key misconceptions in the LLM-planning literature; we validate\nincremental progress in plan executability, although plan validity remains a\nchallenge. Hence, future strategies should focus on both these aspects, drawing\ninsights from our findings.",
      "tldr_zh": "本研究重新评估了 Large Language Models (LLMs) 在规划任务中的策略，通过开发一个端到端的 LLM 规划器并使用多样化指标进行全面评估。结果显示，仅在规划语料上微调 LLMs 无法产生鲁棒的规划技能，尤其在分布外测试集上表现不佳，而策略如 Chain-of-Thought 可以提高计划的可执行概率，但不直接提升最终有效率。研究引入了创新的 'Longest Contiguous Common Subsequence' 奖励机制，与 reinforcement learning 结合，成为最有效的途径，提升了计划的有效性和可执行性。总体而言，该工作纠正了 LLM 规划文献中的误解，强调了在可执行性上的渐进进步，并建议未来策略应同时关注计划有效性和可执行性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages main body, 10 pages appendix, accepted by Workshop on\n  Planning in the Era of LLMs (LM4Plan @ AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2412.10675v1",
      "published_date": "2024-12-14 04:23:14 UTC",
      "updated_date": "2024-12-14 04:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:49:19.433996"
    },
    {
      "arxiv_id": "2412.10674v3",
      "title": "USM: Unbiased Survey Modeling for Limiting Negative User Experiences in Recommendation Systems",
      "title_zh": "USM：不偏见的调查建模，用于限制推荐系统中的",
      "authors": [
        "Chenghui Yu",
        "Peiyi Li",
        "Haoze Wu",
        "Yiri Wen",
        "Bingfeng Deng",
        "Hongyu Xiong"
      ],
      "abstract": "Reducing negative user experiences is essential for the success of\nrecommendation platforms. Exposing users to inappropriate content could not\nonly adversely affect users' psychological well-beings, but also potentially\ndrive users away from the platform, sabotaging the platform's long-term\nsuccess. However, recommendation algorithms tend to weigh more heavily on\npositive feedback signals due to the scarcity of negative ones, which may\nresult in the neglect of valuable negative user feedback. In this paper, we\npropose an approach aimed at limiting negative user experiences. Our method\nprimarily relies on distributing in-feed surveys to the users, modeling the\nusers' feedback collected from the survey, and integrating the model\npredictions into the recommendation system. We further enhance the baseline\nsurvey model by integrating the Learning Hidden Unit Contributions module and\nthe Squeeze-and-Excitation module. In addition, we strive to resolve the\nproblem of response Bias by applying a survey-submit model; The A/B testing\nresults indicate a reduction in survey sexual rate and survey inappropriate\nrate, ranging from -1.44\\% to -3.9\\%. Additionally, we compared our methods\nagainst an online baseline that does not incorporate our approach. The results\nindicate that our approach significantly reduces the report rate and dislike\nrate by 1\\% to 2.27\\% compared to the baseline, confirming the effectiveness of\nour methods in enhancing user experience. After we launched the survey model\nbased our approach on our platform, the model is able to bring reductions of\n1.75\\%, 2.57\\%, 2.06\\% on reports, dislikes, survey inappropriate rate,\nrespectively.",
      "tldr_zh": "这篇论文提出了 USM（Unbiased Survey Modeling）方法，用于减少推荐系统中的负面用户体验，通过分发 in-feed 调查收集用户反馈、建模这些反馈并将其整合到推荐系统中。该方法增强了基线模型，加入了 Learning Hidden Unit Contributions 模块和 Squeeze-and-Excitation 模块，并采用 survey-submit 模型来缓解响应偏见。实验结果显示，A/B 测试和上线应用均显著降低了负面指标，包括报告率、不喜欢率和 survey inappropriate rate，分别减少了 1% 到 2.27% 及更高。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2412.10674v3",
      "published_date": "2024-12-14 04:22:09 UTC",
      "updated_date": "2025-02-15 08:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:49:31.266454"
    },
    {
      "arxiv_id": "2412.10673v1",
      "title": "Proposing and solving olympiad geometry with guided tree search",
      "title_zh": "使用引导式树搜索提出与解决奥林匹克几何问题",
      "authors": [
        "Chi Zhang",
        "Jiajun Song",
        "Siyu Li",
        "Yitao Liang",
        "Yuxi Ma",
        "Wei Wang",
        "Yixin Zhu",
        "Song-Chun Zhu"
      ],
      "abstract": "Mathematics olympiads are prestigious competitions, with problem proposing\nand solving highly honored. Building artificial intelligence that proposes and\nsolves olympiads presents an unresolved challenge in automated theorem\ndiscovery and proving, especially in geometry for its combination of numerical\nand spatial elements. We introduce TongGeometry, a Euclidean geometry system\nsupporting tree-search-based guided problem proposing and solving. The\nefficient geometry system establishes the most extensive repository of geometry\ntheorems to date: within the same computational budget as the existing\nstate-of-the-art, TongGeometry discovers 6.7 billion geometry theorems\nrequiring auxiliary constructions, including 4.1 billion exhibiting geometric\nsymmetry. Among them, 10 theorems were proposed to regional mathematical\nolympiads with 3 of TongGeometry's proposals selected in real competitions,\nearning spots in a national team qualifying exam or a top civil olympiad in\nChina and the US. Guided by fine-tuned large language models, TongGeometry\nsolved all International Mathematical Olympiad geometry in IMO-AG-30,\noutperforming gold medalists for the first time. It also surpasses the existing\nstate-of-the-art across a broader spectrum of olympiad-level problems. The full\ncapabilities of the system can be utilized on a consumer-grade machine, making\nthe model more accessible and fostering widespread democratization of its use.\nBy analogy, unlike existing systems that merely solve problems like students,\nTongGeometry acts like a geometry coach, discovering, presenting, and proving\ntheorems.",
      "tldr_zh": "本研究引入了TongGeometry系统，这是一个支持引导树搜索的欧几里得几何框架，用于提出和解决数学奥林匹克几何问题。系统在相同计算预算下，发现了67亿个需要辅助构造的几何定理，其中41亿个展示了几何对称性，并已将10个定理提出到区域奥林匹克竞赛中，3个被选中用于中国和美国的国家队资格考试。借助微调的大型语言模型指导，TongGeometry成功解决了IMO-AG-30中的所有国际数学奥林匹克几何问题，首次超越金牌获得者的表现，并在更广泛的奥林匹克级问题上超过了现有最先进系统。该系统可在消费级机器上运行，促进几何定理发现的民主化，并像几何教练一样，不仅解决问题，还能发现、呈现和证明定理。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10673v1",
      "published_date": "2024-12-14 04:20:47 UTC",
      "updated_date": "2024-12-14 04:20:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:49:44.217162"
    },
    {
      "arxiv_id": "2412.10658v3",
      "title": "Combining Priors with Experience: Confidence Calibration Based on Binomial Process Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Jinzong Dong",
        "Zhaohui Jiang",
        "Dong Pan",
        "Haoyang Yu"
      ],
      "abstract": "Confidence calibration of classification models is a technique to estimate\nthe true posterior probability of the predicted class, which is critical for\nensuring reliable decision-making in practical applications. Existing\nconfidence calibration methods mostly use statistical techniques to estimate\nthe calibration curve from data or fit a user-defined calibration function, but\noften overlook fully mining and utilizing the prior distribution behind the\ncalibration curve. However, a well-informed prior distribution can provide\nvaluable insights beyond the empirical data under the limited data or\nlow-density regions of confidence scores. To fill this gap, this paper proposes\na new method that integrates the prior distribution behind the calibration\ncurve with empirical data to estimate a continuous calibration curve, which is\nrealized by modeling the sampling process of calibration data as a binomial\nprocess and maximizing the likelihood function of the binomial process. We\nprove that the calibration curve estimating method is Lipschitz continuous with\nrespect to data distribution and requires a sample size of $3/B$ of that\nrequired for histogram binning, where $B$ represents the number of bins. Also,\na new calibration metric ($TCE_{bpm}$), which leverages the estimated\ncalibration curve to estimate the true calibration error (TCE), is designed.\n$TCE_{bpm}$ is proven to be a consistent calibration measure. Furthermore,\nrealistic calibration datasets can be generated by the binomial process\nmodeling from a preset true calibration curve and confidence score\ndistribution, which can serve as a benchmark to measure and compare the\ndiscrepancy between existing calibration metrics and the true calibration\nerror. The effectiveness of our calibration method and metric are verified in\nreal-world and simulated data.",
      "tldr_zh": "该论文提出了一种新的置信度校准（confidence calibration）方法，通过整合校准曲线的先验分布（priors）和经验数据来估计连续校准曲线，该方法将校准数据的采样过程建模为二项过程（binomial process）并最大化其似然函数。相比现有方法，该方法被证明具有Lipschitz连续性，且所需样本量仅为直方图分箱法（histogram binning）的1/B，其中B为分箱数，从而提高了效率。论文还引入了新的校准指标TCE_bpm，用于估计真实校准误差（TCE），并证明其是一致的校准度量，同时通过二项过程建模生成现实数据集作为基准，以评估现有指标的准确性。在真实和模拟数据中，实验验证了该方法的有效性。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ME",
      "comment": "Accepted by AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2412.10658v3",
      "published_date": "2024-12-14 03:04:05 UTC",
      "updated_date": "2025-02-18 12:23:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:49:55.712747"
    },
    {
      "arxiv_id": "2501.00013v1",
      "title": "Relation-Aware Equivariant Graph Networks for Epitope-Unknown Antibody Design and Specificity Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Lirong Wu",
        "Haitao Lin",
        "Yufei Huang",
        "Zhangyang Gao",
        "Cheng Tan",
        "Yunfan Liu",
        "Tailin Wu",
        "Stan Z. Li"
      ],
      "abstract": "Antibodies are Y-shaped proteins that protect the host by binding to specific\nantigens, and their binding is mainly determined by the Complementary\nDetermining Regions (CDRs) in the antibody. Despite the great progress made in\nCDR design, existing computational methods still encounter several challenges:\n1) poor capability of modeling complex CDRs with long sequences due to\ninsufficient contextual information; 2) conditioned on pre-given antigenic\nepitopes and their static interaction with the target antibody; 3) neglect of\nspecificity during antibody optimization leads to non-specific antibodies. In\nthis paper, we take into account a variety of node features, edge features, and\nedge relations to include more contextual and geometric information. We propose\na novel Relation-Aware Antibody Design (RAAD) framework, which dynamically\nmodels antigen-antibody interactions for co-designing the sequences and\nstructures of antigen-specific CDRs. Furthermore, we propose a new evaluation\nmetric to better measure antibody specificity and develop a contrasting\nspecificity-enhancing constraint to optimize the specificity of antibodies.\nExtensive experiments have demonstrated the superior capability of RAAD in\nterms of antibody modeling, generation, and optimization across different CDR\ntypes, sequence lengths, pre-training strategies, and input contexts.",
      "tldr_zh": "该研究针对抗体设计中的挑战，提出了一种Relation-Aware Antibody Design (RAAD)框架，利用Relation-Aware Equivariant Graph Networks来动态建模抗原-抗体互动，从而共同设计抗原特异性的Complementary Determining Regions (CDRs)序列和结构。RAAD框架通过整合节点特征、边特征和边关系，解决了现有方法在处理复杂长序列CDRs时缺乏上下文信息的问题，并引入了一个新的评价指标和对比特异性增强约束来优化抗体特异性，避免生成非特异性抗体。实验结果显示，RAAD在不同CDR类型、序列长度、预训练策略和输入上下文下的抗体建模、生成和优化方面均表现出色。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.00013v1",
      "published_date": "2024-12-14 03:00:44 UTC",
      "updated_date": "2024-12-14 03:00:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:50:07.572942"
    },
    {
      "arxiv_id": "2412.10651v1",
      "title": "LAN: Learning to Adapt Noise for Image Denoising",
      "title_zh": "翻译失败",
      "authors": [
        "Changjin Kim",
        "Tae Hyun Kim",
        "Sungyong Baik"
      ],
      "abstract": "Removing noise from images, a.k.a image denoising, can be a very challenging\ntask since the type and amount of noise can greatly vary for each image due to\nmany factors including a camera model and capturing environments. While there\nhave been striking improvements in image denoising with the emergence of\nadvanced deep learning architectures and real-world datasets, recent denoising\nnetworks struggle to maintain performance on images with noise that has not\nbeen seen during training. One typical approach to address the challenge would\nbe to adapt a denoising network to new noise distribution. Instead, in this\nwork, we shift our focus to adapting the input noise itself, rather than\nadapting a network. Thus, we keep a pretrained network frozen, and adapt an\ninput noise to capture the fine-grained deviations. As such, we propose a new\ndenoising algorithm, dubbed Learning-to-Adapt-Noise (LAN), where a learnable\nnoise offset is directly added to a given noisy image to bring a given input\nnoise closer towards the noise distribution a denoising network is trained to\nhandle. Consequently, the proposed framework exhibits performance improvement\non images with unseen noise, displaying the potential of the proposed research\ndirection. The code is available at https://github.com/chjinny/LAN",
      "tldr_zh": "这篇论文提出了一种新颖的图像去噪方法，LAN（Learning-to-Adapt-Noise），针对现有深度学习模型在处理训练中未见过的噪声时表现不佳的问题。不同于传统方法，该框架保持预训练网络不变，而是通过添加可学习的噪声偏移来调整输入噪声，使其更接近网络训练时的噪声分布。实验结果显示，LAN显著提高了对未知噪声图像的去噪性能，展示了这种适应噪声策略的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2412.10651v1",
      "published_date": "2024-12-14 02:46:25 UTC",
      "updated_date": "2024-12-14 02:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:50:18.496979"
    },
    {
      "arxiv_id": "2412.10649v1",
      "title": "Hidden Echoes Survive Training in Audio To Audio Generative Instrument Models",
      "title_zh": "翻译失败",
      "authors": [
        "Christopher J. Tralie",
        "Matt Amery",
        "Benjamin Douglas",
        "Ian Utz"
      ],
      "abstract": "As generative techniques pervade the audio domain, there has been increasing\ninterest in tracing back through these complicated models to understand how\nthey draw on their training data to synthesize new examples, both to ensure\nthat they use properly licensed data and also to elucidate their black box\nbehavior. In this paper, we show that if imperceptible echoes are hidden in the\ntraining data, a wide variety of audio to audio architectures (differentiable\ndigital signal processing (DDSP), Realtime Audio Variational autoEncoder\n(RAVE), and ``Dance Diffusion'') will reproduce these echoes in their outputs.\nHiding a single echo is particularly robust across all architectures, but we\nalso show promising results hiding longer time spread echo patterns for an\nincreased information capacity. We conclude by showing that echoes make their\nway into fine tuned models, that they survive mixing/demixing, and that they\nsurvive pitch shift augmentation during training. Hence, this simple, classical\nidea in watermarking shows significant promise for tagging generative audio\nmodels.",
      "tldr_zh": "这篇论文探讨了在音频生成模型中隐藏不可感知的回声（echoes）作为水印的方法，测试了 DDSP、RAVE 和 Dance Diffusion 等架构，以追踪模型对训练数据的依赖。研究发现，单个回声在这些模型中高度稳健，并能经受微调、混合/分离以及音高移位增强等过程，而更长的回声模式也显示出增加信息容量的潜力。主要贡献在于证明这种经典水印技术可用于标记生成音频模型，确保数据许可合规并揭示模型的“黑箱”行为。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS",
        "I.2; I.5.4; J.5"
      ],
      "primary_category": "cs.SD",
      "comment": "8 pages, 11 Figures, Proceedings of 2025 AAAI Workshop on AI for\n  Music",
      "pdf_url": "http://arxiv.org/pdf/2412.10649v1",
      "published_date": "2024-12-14 02:36:45 UTC",
      "updated_date": "2024-12-14 02:36:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:50:31.432071"
    },
    {
      "arxiv_id": "2412.10644v1",
      "title": "Model-driven deep neural network for enhanced direction finding with commodity 5G gNodeB",
      "title_zh": "翻译失败",
      "authors": [
        "Shengheng Liu",
        "Zihuan Mao",
        "Xingkang Li",
        "Mengguan Pan",
        "Peng Liu",
        "Yongming Huang",
        "Xiaohu You"
      ],
      "abstract": "Pervasive and high-accuracy positioning has become increasingly important as\na fundamental enabler for intelligent connected devices in mobile networks.\nNevertheless, current wireless networks heavily rely on pure model-driven\ntechniques to achieve positioning functionality, often succumbing to\nperformance deterioration due to hardware impairments in practical scenarios.\nHere we reformulate the direction finding or angle-of-arrival (AoA) estimation\nproblem as an image recovery task of the spatial spectrum and propose a new\nmodel-driven deep neural network (MoD-DNN) framework. The proposed MoD-DNN\nscheme comprises three modules: a multi-task autoencoder-based beamformer, a\ncoarray spectrum generation module, and a model-driven deep learning-based\nspatial spectrum reconstruction module. Our technique enables automatic\ncalibration of angular-dependent phase error thereby enhancing the resilience\nof direction-finding precision against realistic system non-idealities. We\nvalidate the proposed scheme both using numerical simulations and field tests.\nThe results show that the proposed MoD-DNN framework enables effective spectrum\ncalibration and accurate AoA estimation. To the best of our knowledge, this\nstudy marks the first successful demonstration of hybrid data-and-model-driven\ndirection finding utilizing readily available commodity 5G gNodeB.",
      "tldr_zh": "该论文针对当前无线网络中依赖纯模型驱动技术的定位功能易受硬件缺陷影响的问题，提出了一种模型驱动深度神经网络（MoD-DNN）框架，将角度到达（AoA）估计问题转化为空间谱的图像恢复任务。MoD-DNN 包括多任务自动编码器-based beamformer、coarray spectrum generation module 和模型驱动深度学习-based 空间谱重建模块，能够自动校准角度相关的相位误差，从而提高方向查找的鲁棒性和精度。通过数值模拟和现场测试验证，该框架在商用 5G gNodeB 上实现了有效的谱校准和精确 AoA 估计，这是首个成功演示混合数据和模型驱动方向查找的方法。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "To appear in ACM TOSN. A preliminary version of this article was\n  presented at the AAAI'2024 Main Technical Track",
      "pdf_url": "http://arxiv.org/pdf/2412.10644v1",
      "published_date": "2024-12-14 02:09:36 UTC",
      "updated_date": "2024-12-14 02:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:50:45.600177"
    },
    {
      "arxiv_id": "2412.10629v1",
      "title": "Rapid Reconstruction of Extremely Accelerated Liver 4D MRI via Chained Iterative Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Di Xu",
        "Xin Miao",
        "Hengjie Liu",
        "Jessica E. Scholey",
        "Wensha Yang",
        "Mary Feng",
        "Michael Ohliger",
        "Hui Lin",
        "Yi Lao",
        "Yang Yang",
        "Ke Sheng"
      ],
      "abstract": "Abstract Purpose: High-quality 4D MRI requires an impractically long scanning\ntime for dense k-space signal acquisition covering all respiratory phases.\nAccelerated sparse sampling followed by reconstruction enhancement is desired\nbut often results in degraded image quality and long reconstruction time. We\nhereby propose the chained iterative reconstruction network (CIRNet) for\nefficient sparse-sampling reconstruction while maintaining clinically\ndeployable quality. Methods: CIRNet adopts the denoising diffusion\nprobabilistic framework to condition the image reconstruction through a\nstochastic iterative denoising process. During training, a forward Markovian\ndiffusion process is designed to gradually add Gaussian noise to the densely\nsampled ground truth (GT), while CIRNet is optimized to iteratively reverse the\nMarkovian process from the forward outputs. At the inference stage, CIRNet\nperforms the reverse process solely to recover signals from noise, conditioned\nupon the undersampled input. CIRNet processed the 4D data (3D+t) as temporal\nslices (2D+t). The proposed framework is evaluated on a data cohort consisting\nof 48 patients (12332 temporal slices) who underwent free-breathing liver 4D\nMRI. 3-, 6-, 10-, 20- and 30-times acceleration were examined with a\nretrospective random undersampling scheme. Compressed sensing (CS)\nreconstruction with a spatiotemporal constraint and a recently proposed deep\nnetwork, Re-Con-GAN, are selected as baselines. Results: CIRNet consistently\nachieved superior performance compared to CS and Re-Con-GAN. The inference time\nof CIRNet, CS, and Re-Con-GAN are 11s, 120s, and 0.15s. Conclusion: A novel\nframework, CIRNet, is presented. CIRNet maintains useable image quality for\nacceleration up to 30 times, significantly reducing the burden of 4DMRI.",
      "tldr_zh": "本文提出CIRNet，一种基于denoising diffusion probabilistic框架的链式迭代重建网络，用于快速重建加速后的肝脏4D MRI，从而减少扫描时间并维持图像质量。该方法通过正向Markovian过程添加噪声并优化逆向迭代去噪过程，从稀疏采样数据中恢复信号，并在2D+t切片上处理4D数据。实验在48名患者的12332个时序切片上显示，CIRNet在3-30倍加速因子下优于CS和Re-Con-GAN基准模型，重建时间仅需11秒，同时保持临床可用的图像质量。该框架显著降低了4D MRI的负担，为高效医学成像提供新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10629v1",
      "published_date": "2024-12-14 00:43:11 UTC",
      "updated_date": "2024-12-14 00:43:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:50:56.461820"
    },
    {
      "arxiv_id": "2412.10622v3",
      "title": "A recent evaluation on the performance of LLMs on radiation oncology physics using questions of randomly shuffled options",
      "title_zh": "翻译失败",
      "authors": [
        "Peilong Wang",
        "Jason Holmes",
        "Zhengliang Liu",
        "Dequan Chen",
        "Tianming Liu",
        "Jiajian Shen",
        "Wei Liu"
      ],
      "abstract": "Purpose: We present an updated study evaluating the performance of large\nlanguage models (LLMs) in answering radiation oncology physics questions,\nfocusing on the recently released models.\n  Methods: A set of 100 multiple-choice radiation oncology physics questions,\npreviously created by a well-experienced physicist, was used for this study.\nThe answer options of the questions were randomly shuffled to create \"new\" exam\nsets. Five LLMs -- OpenAI o1-preview, GPT-4o, LLaMA 3.1 (405B), Gemini 1.5 Pro,\nand Claude 3.5 Sonnet -- with the versions released before September 30, 2024,\nwere queried using these new exam sets. To evaluate their deductive reasoning\nability, the correct answer options in the questions were replaced with \"None\nof the above.\" Then, the explain-first and step-by-step instruction prompts\nwere used to test if this strategy improved their reasoning ability. The\nperformance of the LLMs was compared with the answers from medical physicists.\n  Results: All models demonstrated expert-level performance on these questions,\nwith o1-preview even surpassing medical physicists with a majority vote. When\nreplacing the correct answer options with 'None of the above', all models\nexhibited a considerable decline in performance, suggesting room for\nimprovement. The explain-first and step-by-step instruction prompts helped\nenhance the reasoning ability of the LLaMA 3.1 (405B), Gemini 1.5 Pro, and\nClaude 3.5 Sonnet models.\n  Conclusion: These recently released LLMs demonstrated expert-level\nperformance in answering radiation oncology physics questions, exhibiting great\npotential to assist in radiation oncology physics education and training.",
      "tldr_zh": "本研究评估了五种大型语言模型（LLMs），包括 OpenAI o1-preview、GPT-4o、LLaMA 3.1 (405B)、Gemini 1.5 Pro 和 Claude 3.5 Sonnet，在辐射肿瘤物理多选题上的性能，使用100个随机打乱选项的问题集进行测试。结果显示，所有模型表现出专家级表现，其中o1-preview甚至超过了医疗物理学家的多数票决，但当正确答案替换为“None of the above”时，模型的推理能力显著下降。研究还发现，使用explain-first和step-by-step指令提示能提升LLaMA 3.1 (405B)、Gemini 1.5 Pro和Claude 3.5 Sonnet的推理表现。总体而言，这些LLMs展示了在辐射肿瘤物理教育和训练中辅助潜力的巨大价值。",
      "categories": [
        "physics.med-ph",
        "cs.AI"
      ],
      "primary_category": "physics.med-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10622v3",
      "published_date": "2024-12-14 00:05:42 UTC",
      "updated_date": "2025-01-21 17:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:51:09.685946"
    },
    {
      "arxiv_id": "2412.10621v1",
      "title": "WaveGNN: Modeling Irregular Multivariate Time Series for Accurate Predictions",
      "title_zh": "WaveGNN：建模不规则多变量时间序列以实现准确预测",
      "authors": [
        "Arash Hajisafi",
        "Maria Despoina Siampou",
        "Bita Azarijoo",
        "Cyrus Shahabi"
      ],
      "abstract": "Accurately modeling and analyzing time series data is crucial for downstream\napplications across various fields, including healthcare, finance, astronomy,\nand epidemiology. However, real-world time series often exhibit irregularities\nsuch as misaligned timestamps, missing entries, and variable sampling rates,\ncomplicating their analysis. Existing approaches often rely on imputation,\nwhich can introduce biases. A few approaches that directly model irregularity\ntend to focus exclusively on either capturing intra-series patterns or\ninter-series relationships, missing the benefits of integrating both. To this\nend, we present WaveGNN, a novel framework designed to directly (i.e., no\nimputation) embed irregularly sampled multivariate time series data for\naccurate predictions. WaveGNN utilizes a Transformer-based encoder to capture\nintra-series patterns by directly encoding the temporal dynamics of each time\nseries. To capture inter-series relationships, WaveGNN uses a dynamic graph\nneural network model, where each node represents a sensor, and the edges\ncapture the long- and short-term relationships between them. Our experimental\nresults on real-world healthcare datasets demonstrate that WaveGNN consistently\noutperforms existing state-of-the-art methods, with an average relative\nimprovement of 14.7% in F1-score when compared to the second-best baseline in\ncases with extreme sparsity. Our ablation studies reveal that both intra-series\nand inter-series modeling significantly contribute to this notable improvement.",
      "tldr_zh": "这篇论文提出了WaveGNN框架，用于直接处理不规则的多变量时间序列数据，避免了传统插值方法可能带来的偏差。WaveGNN结合Transformer-based encoder捕获序列内部模式，以及动态Graph Neural Network建模序列间关系（如传感器间的长期和短期联系），从而实现更准确的预测。在真实医疗数据集上的实验表明，WaveGNN比现有方法平均提升14.7%的F1分数，尤其在极端稀疏场景下表现突出，且消融研究证实了内部和外部建模的双重贡献。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2412.10621v1",
      "published_date": "2024-12-14 00:03:44 UTC",
      "updated_date": "2024-12-14 00:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T12:51:19.990268"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 62,
  "processed_papers_count": 62,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T12:51:36.760510"
}