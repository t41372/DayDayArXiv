[
  {
    "arxiv_id": "2405.08989v1",
    "title": "What is it for a Machine Learning Model to Have a Capability?",
    "authors": [
      "Jacqueline Harding",
      "Nathaniel Sharadin"
    ],
    "abstract": "What can contemporary machine learning (ML) models do? Given the\nproliferation of ML models in society, answering this question matters to a\nvariety of stakeholders, both public and private. The evaluation of models'\ncapabilities is rapidly emerging as a key subfield of modern ML, buoyed by\nregulatory attention and government grants. Despite this, the notion of an ML\nmodel possessing a capability has not been interrogated: what are we saying\nwhen we say that a model is able to do something? And what sorts of evidence\nbear upon this question? In this paper, we aim to answer these questions, using\nthe capabilities of large language models (LLMs) as a running example. Drawing\non the large philosophical literature on abilities, we develop an account of ML\nmodels' capabilities which can be usefully applied to the nascent science of\nmodel evaluation. Our core proposal is a conditional analysis of model\nabilities (CAMA): crudely, a machine learning model has a capability to X just\nwhen it would reliably succeed at doing X if it 'tried'. The main contribution\nof the paper is making this proposal precise in the context of ML, resulting in\nan operationalisation of CAMA applicable to LLMs. We then put CAMA to work,\nshowing that it can help make sense of various features of ML model evaluation\npractice, as well as suggest procedures for performing fair inter-model\ncomparisons.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "forthcoming in the British Journal for the Philosophy of Science\n  (BJPS)",
    "pdf_url": "http://arxiv.org/pdf/2405.08989v1",
    "published_date": "2024-05-14 23:03:52 UTC",
    "updated_date": "2024-05-14 23:03:52 UTC"
  },
  {
    "arxiv_id": "2405.08965v3",
    "title": "Meaning-Typed Programming: Language-level Abstractions and Runtime for GenAI Applications",
    "authors": [
      "Jason Mars",
      "Yiping Kang",
      "Jayanaka L. Dantanarayana",
      "Kugesan Sivasothynathan",
      "Christopher Clarke",
      "Baichuan Li",
      "Krisztian Flautner",
      "Lingjia Tang"
    ],
    "abstract": "Software is rapidly evolving from being programmed with traditional logical\ncode, to neuro-integrated applications that leverage generative AI and large\nlanguage models (LLMs) for application functionality. This shift increases the\ncomplexity of building applications, as developers now must reasoning about,\nprogram, and prompt LLMs. Despite efforts to create tools to assist with prompt\nengineering, these solutions often introduce additional layers of complexity to\nthe development of neuro-integrated applications. This paper proposes\nmeaning-typed programming (MTP), a novel approach to simplify the creation of\nneuro-integrated applications by introducing new language-level abstractions\nthat hide the complexities of LLM integration. Our key insight is that typical\nconventional code already possesses a high level of semantic richness that can\nbe automatically reasoned about, as it is designed to be readable and\nmaintainable by humans. Leveraging this insight, we conceptualize LLMs as\nmeaning-typed code constructs and introduce a by abstraction at the language\nlevel, MT-IR, a new meaning-based intermediate representation at the compiler\nlevel, and MT Runtime, an automated run-time engine for LLM integration and\noperations. We implement MTP in a production-grade Python super-set language\ncalled Jac and perform an extensive evaluation. Our results demonstrate that\nMTP not only simplifies the development process but also meets or exceeds the\nefficacy of state-of-the-art manual and tool-assisted prompt engineering\ntechniques in terms of accuracy and usability.",
    "categories": [
      "cs.PL",
      "cs.AI"
    ],
    "primary_category": "cs.PL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08965v3",
    "published_date": "2024-05-14 21:12:01 UTC",
    "updated_date": "2025-01-16 18:56:27 UTC"
  },
  {
    "arxiv_id": "2405.08961v1",
    "title": "Bird's-Eye View to Street-View: A Survey",
    "authors": [
      "Khawlah Bajbaa",
      "Muhammad Usman",
      "Saeed Anwar",
      "Ibrahim Radwan",
      "Abdul Bais"
    ],
    "abstract": "In recent years, street view imagery has grown to become one of the most\nimportant sources of geospatial data collection and urban analytics, which\nfacilitates generating meaningful insights and assisting in decision-making.\nSynthesizing a street-view image from its corresponding satellite image is a\nchallenging task due to the significant differences in appearance and viewpoint\nbetween the two domains. In this study, we screened 20 recent research papers\nto provide a thorough review of the state-of-the-art of how street-view images\nare synthesized from their corresponding satellite counterparts. The main\nfindings are: (i) novel deep learning techniques are required for synthesizing\nmore realistic and accurate street-view images; (ii) more datasets need to be\ncollected for public usage; and (iii) more specific evaluation metrics need to\nbe investigated for evaluating the generated images appropriately. We conclude\nthat, due to applying outdated deep learning techniques, the recent literature\nfailed to generate detailed and diverse street-view images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08961v1",
    "published_date": "2024-05-14 21:01:12 UTC",
    "updated_date": "2024-05-14 21:01:12 UTC"
  },
  {
    "arxiv_id": "2405.08944v1",
    "title": "Challenges in Deploying Long-Context Transformers: A Theoretical Peak Performance Analysis",
    "authors": [
      "Yao Fu"
    ],
    "abstract": "Transformer-based long context generative models power emerging AI\napplications like hour-long video understanding and project-level coding agent.\nDeploying long context transformers (e.g., 100K to 10M tokens) is prohibitively\nexpensive compared to short context (e.g., 4K tokens) model variants. Reducing\nthe cost of long-context transformers is becoming a pressing research and\nengineering challenge starting from the year of 2024. This work describes a\nconcurrent programming framework for quantitatively analyzing the efficiency\nchallenges in serving multiple long-context requests under limited size of GPU\nhigh-bandwidth memory (HBM) regime. We give a detailed analysis of how all\nadditional computational costs, compared to 4K context, trace back to\n\\textit{one single source: the large size of the KV cache}. We use a 34B\nGPT-3.5 level model of 50K context on A100 NVLink as a running example, and\ndescribe how its large KV cache causes four types of deployment challenges: (1)\nprefilling long inputs takes much longer compute time and GPU memory than short\ninputs; (2) after prefilling, the large KV cache residing on the GPU HBM\nsubstantially restricts the number of concurrent users being served; (3) during\ndecoding, repeatedly reading the KV cache from HBM to SM largely increases\nlatency; (4) when KV cache memory overflows, swapping it from HBM to DDR causes\nsignificant context switching latency. We use this framework to analyze\nexisting works and identify possibilities of combining them to build end-to-end\nsystems. Overall, this work offers a foundational framework for analyzing long\ncontext transformer deployment and identifies directions towards reducing the\ninference cost of 1M context to be as cheap as 4K.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08944v1",
    "published_date": "2024-05-14 20:17:22 UTC",
    "updated_date": "2024-05-14 20:17:22 UTC"
  },
  {
    "arxiv_id": "2405.08932v1",
    "title": "Self-supervised vision-langage alignment of deep learning representations for bone X-rays analysis",
    "authors": [
      "Alexandre Englebert",
      "Anne-Sophie Collin",
      "Olivier Cornu",
      "Christophe De Vleeschouwer"
    ],
    "abstract": "This paper proposes leveraging vision-language pretraining on bone X-rays\npaired with French reports to address downstream tasks of interest on bone\nradiography. A practical processing pipeline is introduced to anonymize and\nprocess French medical reports. Pretraining then consists in the\nself-supervised alignment of visual and textual embedding spaces derived from\ndeep model encoders. The resulting image encoder is then used to handle various\ndownstream tasks, including quantification of osteoarthritis, estimation of\nbone age on pediatric wrists, bone fracture and anomaly detection. Our approach\ndemonstrates competitive performance on downstream tasks, compared to\nalternatives requiring a significantly larger amount of human expert\nannotations. Our work stands as the first study to integrate French reports to\nshape the embedding space devoted to bone X-Rays representations, capitalizing\non the large quantity of paired images and reports data available in an\nhospital. By relying on generic vision-laguage deep models in a\nlanguage-specific scenario, it contributes to the deployement of vision models\nfor wider healthcare applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08932v1",
    "published_date": "2024-05-14 19:53:20 UTC",
    "updated_date": "2024-05-14 19:53:20 UTC"
  },
  {
    "arxiv_id": "2405.09580v1",
    "title": "Error-margin Analysis for Hidden Neuron Activation Labels",
    "authors": [
      "Abhilekha Dalal",
      "Rushrukh Rayan",
      "Pascal Hitzler"
    ],
    "abstract": "Understanding how high-level concepts are represented within artificial\nneural networks is a fundamental challenge in the field of artificial\nintelligence. While existing literature in explainable AI emphasizes the\nimportance of labeling neurons with concepts to understand their functioning,\nthey mostly focus on identifying what stimulus activates a neuron in most\ncases, this corresponds to the notion of recall in information retrieval. We\nargue that this is only the first-part of a two-part job, it is imperative to\nalso investigate neuron responses to other stimuli, i.e., their precision. We\ncall this the neuron labels error margin.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.09580v1",
    "published_date": "2024-05-14 19:13:50 UTC",
    "updated_date": "2024-05-14 19:13:50 UTC"
  },
  {
    "arxiv_id": "2405.08888v1",
    "title": "Large Language Models for Human-Machine Collaborative Particle Accelerator Tuning through Natural Language",
    "authors": [
      "Jan Kaiser",
      "Annika Eichler",
      "Anne Lauscher"
    ],
    "abstract": "Autonomous tuning of particle accelerators is an active and challenging field\nof research with the goal of enabling novel accelerator technologies\ncutting-edge high-impact applications, such as physics discovery, cancer\nresearch and material sciences. A key challenge with autonomous accelerator\ntuning remains that the most capable algorithms require an expert in\noptimisation, machine learning or a similar field to implement the algorithm\nfor every new tuning task. In this work, we propose the use of large language\nmodels (LLMs) to tune particle accelerators. We demonstrate on a\nproof-of-principle example the ability of LLMs to successfully and autonomously\ntune a particle accelerator subsystem based on nothing more than a natural\nlanguage prompt from the operator, and compare the performance of our LLM-based\nsolution to state-of-the-art optimisation algorithms, such as Bayesian\noptimisation (BO) and reinforcement learning-trained optimisation (RLO). In\ndoing so, we also show how LLMs can perform numerical optimisation of a highly\nnon-linear real-world objective function. Ultimately, this work represents yet\nanother complex task that LLMs are capable of solving and promises to help\naccelerate the deployment of autonomous tuning algorithms to the day-to-day\noperations of particle accelerators.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "physics.acc-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "22 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.08888v1",
    "published_date": "2024-05-14 18:05:44 UTC",
    "updated_date": "2024-05-14 18:05:44 UTC"
  },
  {
    "arxiv_id": "2405.08792v1",
    "title": "Towards Enhanced RAC Accessibility: Leveraging Datasets and LLMs",
    "authors": [
      "Edison Jair Bejarano Sepulveda",
      "Nicolai Potes Hector",
      "Santiago Pineda Montoya",
      "Felipe Ivan Rodriguez",
      "Jaime Enrique Orduy",
      "Alec Rosales Cabezas",
      "Danny Traslaviña Navarrete",
      "Sergio Madrid Farfan"
    ],
    "abstract": "This paper explores the potential of large language models (LLMs) to make the\nAeronautical Regulations of Colombia (RAC) more accessible. Given the\ncomplexity and extensive technicality of the RAC, this study introduces a novel\napproach to simplifying these regulations for broader understanding. By\ndeveloping the first-ever RAC database, which contains 24,478 expertly labeled\nquestion-and-answer pairs, and fine-tuning LLMs specifically for RAC\napplications, the paper outlines the methodology for dataset assembly,\nexpert-led annotation, and model training. Utilizing the Gemma1.1 2b model\nalong with advanced techniques like Unsloth for efficient VRAM usage and flash\nattention mechanisms, the research aims to expedite training processes. This\ninitiative establishes a foundation to enhance the comprehensibility and\naccessibility of RAC, potentially benefiting novices and reducing dependence on\nexpert consultations for navigating the aviation industry's regulatory\nlandscape.\n  You can visit the dataset\n(https://huggingface.co/somosnlp/gemma-1.1-2b-it_ColombiaRAC_FullyCurated_format_chatML_V1)\nand the model\n(https://huggingface.co/datasets/somosnlp/ColombiaRAC_FullyCurated) here.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08792v1",
    "published_date": "2024-05-14 17:41:07 UTC",
    "updated_date": "2024-05-14 17:41:07 UTC"
  },
  {
    "arxiv_id": "2405.08790v2",
    "title": "Kolmogorov-Arnold Networks (KANs) for Time Series Analysis",
    "authors": [
      "Cristian J. Vaca-Rubio",
      "Luis Blanco",
      "Roberto Pereira",
      "Màrius Caus"
    ],
    "abstract": "This paper introduces a novel application of Kolmogorov-Arnold Networks\n(KANs) to time series forecasting, leveraging their adaptive activation\nfunctions for enhanced predictive modeling. Inspired by the Kolmogorov-Arnold\nrepresentation theorem, KANs replace traditional linear weights with\nspline-parametrized univariate functions, allowing them to learn activation\npatterns dynamically. We demonstrate that KANs outperforms conventional\nMulti-Layer Perceptrons (MLPs) in a real-world satellite traffic forecasting\ntask, providing more accurate results with considerably fewer number of\nlearnable parameters. We also provide an ablation study of KAN-specific\nparameters impact on performance. The proposed approach opens new avenues for\nadaptive forecasting models, emphasizing the potential of KANs as a powerful\ntool in predictive analytics.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08790v2",
    "published_date": "2024-05-14 17:38:17 UTC",
    "updated_date": "2024-09-25 12:47:46 UTC"
  },
  {
    "arxiv_id": "2405.08780v2",
    "title": "Harnessing the power of longitudinal medical imaging for eye disease prognosis using Transformer-based sequence modeling",
    "authors": [
      "Gregory Holste",
      "Mingquan Lin",
      "Ruiwen Zhou",
      "Fei Wang",
      "Lei Liu",
      "Qi Yan",
      "Sarah H. Van Tassel",
      "Kyle Kovacs",
      "Emily Y. Chew",
      "Zhiyong Lu",
      "Zhangyang Wang",
      "Yifan Peng"
    ],
    "abstract": "Deep learning has enabled breakthroughs in automated diagnosis from medical\nimaging, with many successful applications in ophthalmology. However, standard\nmedical image classification approaches only assess disease presence at the\ntime of acquisition, neglecting the common clinical setting of longitudinal\nimaging. For slow, progressive eye diseases like age-related macular\ndegeneration (AMD) and primary open-angle glaucoma (POAG), patients undergo\nrepeated imaging over time to track disease progression and forecasting the\nfuture risk of developing disease is critical to properly plan treatment. Our\nproposed Longitudinal Transformer for Survival Analysis (LTSA) enables dynamic\ndisease prognosis from longitudinal medical imaging, modeling the time to\ndisease from sequences of fundus photography images captured over long,\nirregular time periods. Using longitudinal imaging data from the Age-Related\nEye Disease Study (AREDS) and Ocular Hypertension Treatment Study (OHTS), LTSA\nsignificantly outperformed a single-image baseline in 19/20 head-to-head\ncomparisons on late AMD prognosis and 18/20 comparisons on POAG prognosis. A\ntemporal attention analysis also suggested that, while the most recent image is\ntypically the most influential, prior imaging still provides additional\nprognostic value.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to npj Digital Medicine",
    "pdf_url": "http://arxiv.org/pdf/2405.08780v2",
    "published_date": "2024-05-14 17:15:28 UTC",
    "updated_date": "2024-07-30 03:42:00 UTC"
  },
  {
    "arxiv_id": "2405.08768v1",
    "title": "EfficientTrain++: Generalized Curriculum Learning for Efficient Visual Backbone Training",
    "authors": [
      "Yulin Wang",
      "Yang Yue",
      "Rui Lu",
      "Yizeng Han",
      "Shiji Song",
      "Gao Huang"
    ],
    "abstract": "The superior performance of modern visual backbones usually comes with a\ncostly training procedure. We contribute to this issue by generalizing the idea\nof curriculum learning beyond its original formulation, i.e., training models\nusing easier-to-harder data. Specifically, we reformulate the training\ncurriculum as a soft-selection function, which uncovers progressively more\ndifficult patterns within each example during training, instead of performing\neasier-to-harder sample selection. Our work is inspired by an intriguing\nobservation on the learning dynamics of visual backbones: during the earlier\nstages of training, the model predominantly learns to recognize some\n'easier-to-learn' discriminative patterns in the data. These patterns, when\nobserved through frequency and spatial domains, incorporate lower-frequency\ncomponents, and the natural image contents without distortion or data\naugmentation. Motivated by these findings, we propose a curriculum where the\nmodel always leverages all the training data at every learning stage, yet the\nexposure to the 'easier-to-learn' patterns of each example is initiated first,\nwith harder patterns gradually introduced as training progresses. To implement\nthis idea in a computationally efficient way, we introduce a cropping operation\nin the Fourier spectrum of the inputs, enabling the model to learn from only\nthe lower-frequency components. Then we show that exposing the contents of\nnatural images can be readily achieved by modulating the intensity of data\naugmentation. Finally, we integrate these aspects and design curriculum\nschedules with tailored search algorithms. The resulting method,\nEfficientTrain++, is simple, general, yet surprisingly effective. It reduces\nthe training time of a wide variety of popular models by 1.5-3.0x on\nImageNet-1K/22K without sacrificing accuracy. It also demonstrates efficacy in\nself-supervised learning (e.g., MAE).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by IEEE Transactions on Pattern Analysis and Machine\n  Intelligence (TPAMI). Journal version of arXiv:2211.09703 (ICCV 2023). Code\n  is available at: https://github.com/LeapLabTHU/EfficientTrain",
    "pdf_url": "http://arxiv.org/pdf/2405.08768v1",
    "published_date": "2024-05-14 17:00:43 UTC",
    "updated_date": "2024-05-14 17:00:43 UTC"
  },
  {
    "arxiv_id": "2405.08760v2",
    "title": "Is the Pope Catholic? Yes, the Pope is Catholic. Generative Evaluation of Non-Literal Intent Resolution in LLMs",
    "authors": [
      "Akhila Yerukola",
      "Saujas Vaduguru",
      "Daniel Fried",
      "Maarten Sap"
    ],
    "abstract": "Humans often express their communicative intents indirectly or non-literally,\nwhich requires their interlocutors -- human or AI -- to understand beyond the\nliteral meaning of words. While most existing work has focused on\ndiscriminative evaluations, we present a new approach to generatively evaluate\nlarge language models' (LLMs') intention understanding by examining their\nresponses to non-literal utterances. Ideally, an LLM should respond in line\nwith the true intention of a non-literal utterance, not its literal\ninterpretation. Our findings show that LLMs struggle to generate pragmatically\nrelevant responses to non-literal language, achieving only 50-55% accuracy on\naverage. While explicitly providing oracle intentions significantly improves\nperformance (e.g., 75% for Mistral-Instruct), this still indicates challenges\nin leveraging given intentions to produce appropriate responses. Using\nchain-of-thought to make models spell out intentions yields much smaller gains\n(60% for Mistral-Instruct). These findings suggest that LLMs are not yet\neffective pragmatic interlocutors, highlighting the need for better approaches\nfor modeling intentions and utilizing them for pragmatic generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08760v2",
    "published_date": "2024-05-14 16:48:56 UTC",
    "updated_date": "2024-06-19 19:07:47 UTC"
  },
  {
    "arxiv_id": "2405.08755v2",
    "title": "Distributed Threat Intelligence at the Edge Devices: A Large Language Model-Driven Approach",
    "authors": [
      "Syed Mhamudul Hasan",
      "Alaa M. Alotaibi",
      "Sajedul Talukder",
      "Abdur R. Shahid"
    ],
    "abstract": "With the proliferation of edge devices, there is a significant increase in\nattack surface on these devices. The decentralized deployment of threat\nintelligence on edge devices, coupled with adaptive machine learning techniques\nsuch as the in-context learning feature of Large Language Models (LLMs),\nrepresents a promising paradigm for enhancing cybersecurity on\nresource-constrained edge devices. This approach involves the deployment of\nlightweight machine learning models directly onto edge devices to analyze local\ndata streams, such as network traffic and system logs, in real-time.\nAdditionally, distributing computational tasks to an edge server reduces\nlatency and improves responsiveness while also enhancing privacy by processing\nsensitive data locally. LLM servers can enable these edge servers to\nautonomously adapt to evolving threats and attack patterns, continuously\nupdating their models to improve detection accuracy and reduce false positives.\nFurthermore, collaborative learning mechanisms facilitate peer-to-peer secure\nand trustworthy knowledge sharing among edge devices, enhancing the collective\nintelligence of the network and enabling dynamic threat mitigation measures\nsuch as device quarantine in response to detected anomalies. The scalability\nand flexibility of this approach make it well-suited for diverse and evolving\nnetwork environments, as edge devices only send suspicious information such as\nnetwork traffic and system log changes, offering a resilient and efficient\nsolution to combat emerging cyber threats at the network edge. Thus, our\nproposed framework can improve edge computing security by providing better\nsecurity in cyber threat detection and mitigation by isolating the edge devices\nfrom the network.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08755v2",
    "published_date": "2024-05-14 16:40:37 UTC",
    "updated_date": "2024-05-26 06:06:08 UTC"
  },
  {
    "arxiv_id": "2405.08729v1",
    "title": "Targeted Augmentation for Low-Resource Event Extraction",
    "authors": [
      "Sijia Wang",
      "Lifu Huang"
    ],
    "abstract": "Addressing the challenge of low-resource information extraction remains an\nongoing issue due to the inherent information scarcity within limited training\nexamples. Existing data augmentation methods, considered potential solutions,\nstruggle to strike a balance between weak augmentation (e.g., synonym\naugmentation) and drastic augmentation (e.g., conditional generation without\nproper guidance). This paper introduces a novel paradigm that employs targeted\naugmentation and back validation to produce augmented examples with enhanced\ndiversity, polarity, accuracy, and coherence. Extensive experimental results\ndemonstrate the effectiveness of the proposed paradigm. Furthermore, identified\nlimitations are discussed, shedding light on areas for future improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08729v1",
    "published_date": "2024-05-14 16:15:31 UTC",
    "updated_date": "2024-05-14 16:15:31 UTC"
  },
  {
    "arxiv_id": "2405.08726v2",
    "title": "I-CTRL: Imitation to Control Humanoid Robots Through Constrained Reinforcement Learning",
    "authors": [
      "Yashuai Yan",
      "Esteve Valls Mascaro",
      "Tobias Egle",
      "Dongheui Lee"
    ],
    "abstract": "Humanoid robots have the potential to mimic human motions with high visual\nfidelity, yet translating these motions into practical, physical execution\nremains a significant challenge. Existing techniques in the graphics community\noften prioritize visual fidelity over physics-based feasibility, posing a\nsignificant challenge for deploying bipedal systems in practical applications.\nThis paper addresses these issues through bounded residual reinforcement\nlearning to produce physics-based high-quality motion imitation onto legged\nhumanoid robots that enhance motion resemblance while successfully following\nthe reference human trajectory. Our framework, Imitation to Control Humanoid\nRobots Through Bounded Residual Reinforcement Learning (I-CTRL), reformulates\nmotion imitation as a constrained refinement over non-physics-based retargeted\nmotions. I-CTRL excels in motion imitation with simple and unique rewards that\ngeneralize across five robots. Moreover, our framework introduces an automatic\npriority scheduler to manage large-scale motion datasets when efficiently\ntraining a unified RL policy across diverse motions. The proposed approach\nsignifies a crucial step forward in advancing the control of bipedal robots,\nemphasizing the importance of aligning visual and physical realism for\nsuccessful motion imitation.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08726v2",
    "published_date": "2024-05-14 16:12:27 UTC",
    "updated_date": "2025-02-17 14:32:21 UTC"
  },
  {
    "arxiv_id": "2405.08852v1",
    "title": "A Click-Through Rate Prediction Method Based on Cross-Importance of Multi-Order Features",
    "authors": [
      "Hao Wang",
      "Nao Li"
    ],
    "abstract": "Most current click-through rate prediction(CTR)models create explicit or\nimplicit high-order feature crosses through Hadamard product or inner product,\nwith little attention to the importance of feature crossing; only few models\nare either limited to the second-order explicit feature crossing, implicitly to\nhigh-order feature crossing, or can learn the importance of high-order explicit\nfeature crossing but fail to provide good interpretability for the model. This\npaper proposes a new model, FiiNet (Multiple Order Feature Interaction\nImportance Neural Networks). The model first uses the selective kernel network\n(SKNet) to explicitly construct multi-order feature crosses. It dynamically\nlearns the importance of feature interaction combinations in a fine grained\nmanner, increasing the attention weight of important feature cross combinations\nand reducing the weight of featureless crosses. To verify that the FiiNet model\ncan dynamically learn the importance of feature interaction combinations in a\nfine-grained manner and improve the model's recommendation performance and\ninterpretability, this paper compares it with many click-through rate\nprediction models on two real datasets, proving that the FiiNet model\nincorporating the selective kernel network can effectively improve the\nrecommendation effect and provide better interpretability. FiiNet model\nimplementations are available in PyTorch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08852v1",
    "published_date": "2024-05-14 16:05:57 UTC",
    "updated_date": "2024-05-14 16:05:57 UTC"
  },
  {
    "arxiv_id": "2405.08681v1",
    "title": "Achieving Fairness Through Channel Pruning for Dermatological Disease Diagnosis",
    "authors": [
      "Qingpeng Kong",
      "Ching-Hao Chiu",
      "Dewen Zeng",
      "Yu-Jen Chen",
      "Tsung-Yi Ho",
      "Jingtong hu",
      "Yiyu Shi"
    ],
    "abstract": "Numerous studies have revealed that deep learning-based medical image\nclassification models may exhibit bias towards specific demographic attributes,\nsuch as race, gender, and age. Existing bias mitigation methods often achieve\nhigh level of fairness at the cost of significant accuracy degradation. In\nresponse to this challenge, we propose an innovative and adaptable Soft Nearest\nNeighbor Loss-based channel pruning framework, which achieves fairness through\nchannel pruning. Traditionally, channel pruning is utilized to accelerate\nneural network inference. However, our work demonstrates that pruning can also\nbe a potent tool for achieving fairness. Our key insight is that different\nchannels in a layer contribute differently to the accuracy of different groups.\nBy selectively pruning critical channels that lead to the accuracy difference\nbetween the privileged and unprivileged groups, we can effectively improve\nfairness without sacrificing accuracy significantly. Experiments conducted on\ntwo skin lesion diagnosis datasets across multiple sensitive attributes\nvalidate the effectiveness of our method in achieving state-of-the-art\ntrade-off between accuracy and fairness. Our code is available at\nhttps://github.com/Kqp1227/Sensitive-Channel-Pruning.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 3 figures, early accepted by International Conference on\n  Medical Image Computing and Computer-Assisted Intervention (MICCAI), 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08681v1",
    "published_date": "2024-05-14 15:04:46 UTC",
    "updated_date": "2024-05-14 15:04:46 UTC"
  },
  {
    "arxiv_id": "2406.18841v4",
    "title": "Navigating LLM Ethics: Advancements, Challenges, and Future Directions",
    "authors": [
      "Junfeng Jiao",
      "Saleh Afroogh",
      "Yiming Xu",
      "Connor Phillips"
    ],
    "abstract": "This study addresses ethical issues surrounding Large Language Models (LLMs)\nwithin the field of artificial intelligence. It explores the common ethical\nchallenges posed by both LLMs and other AI systems, such as privacy and\nfairness, as well as ethical challenges uniquely arising from LLMs. It\nhighlights challenges such as hallucination, verifiable accountability, and\ndecoding censorship complexity, which are unique to LLMs and distinct from\nthose encountered in traditional AI systems. The study underscores the need to\ntackle these complexities to ensure accountability, reduce biases, and enhance\ntransparency in the influential role that LLMs play in shaping information\ndissemination. It proposes mitigation strategies and future directions for LLM\nethics, advocating for interdisciplinary collaboration. It recommends ethical\nframeworks tailored to specific domains and dynamic auditing systems adapted to\ndiverse contexts. This roadmap aims to guide responsible development and\nintegration of LLMs, envisioning a future where ethical considerations govern\nAI advancements in society.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18841v4",
    "published_date": "2024-05-14 15:03:05 UTC",
    "updated_date": "2025-03-18 16:57:17 UTC"
  },
  {
    "arxiv_id": "2405.08679v1",
    "title": "Investigating Design Choices in Joint-Embedding Predictive Architectures for General Audio Representation Learning",
    "authors": [
      "Alain Riou",
      "Stefan Lattner",
      "Gaëtan Hadjeres",
      "Geoffroy Peeters"
    ],
    "abstract": "This paper addresses the problem of self-supervised general-purpose audio\nrepresentation learning. We explore the use of Joint-Embedding Predictive\nArchitectures (JEPA) for this task, which consists of splitting an input\nmel-spectrogram into two parts (context and target), computing neural\nrepresentations for each, and training the neural network to predict the target\nrepresentations from the context representations. We investigate several design\nchoices within this framework and study their influence through extensive\nexperiments by evaluating our models on various audio classification\nbenchmarks, including environmental sounds, speech and music downstream tasks.\nWe focus notably on which part of the input data is used as context or target\nand show experimentally that it significantly impacts the model's quality. In\nparticular, we notice that some effective design choices in the image domain\nlead to poor performance on audio, thus highlighting major differences between\nthese two modalities.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Self-supervision in Audio, Speech and Beyond workshop, IEEE\n  International Conference on Acoustics, Speech, and Signal Processing, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08679v1",
    "published_date": "2024-05-14 15:00:09 UTC",
    "updated_date": "2024-05-14 15:00:09 UTC"
  },
  {
    "arxiv_id": "2405.08674v1",
    "title": "Expensive Multi-Objective Bayesian Optimization Based on Diffusion Models",
    "authors": [
      "Bingdong Li",
      "Zixiang Di",
      "Yongfan Lu",
      "Hong Qian",
      "Feng Wang",
      "Peng Yang",
      "Ke Tang",
      "Aimin Zhou"
    ],
    "abstract": "Multi-objective Bayesian optimization (MOBO) has shown promising performance\non various expensive multi-objective optimization problems (EMOPs). However,\neffectively modeling complex distributions of the Pareto optimal solutions is\ndifficult with limited function evaluations. Existing Pareto set learning\nalgorithms may exhibit considerable instability in such expensive scenarios,\nleading to significant deviations between the obtained solution set and the\nPareto set (PS). In this paper, we propose a novel Composite Diffusion Model\nbased Pareto Set Learning algorithm, namely CDM-PSL, for expensive MOBO.\nCDM-PSL includes both unconditional and conditional diffusion model for\ngenerating high-quality samples. Besides, we introduce an information entropy\nbased weighting method to balance different objectives of EMOPs. This method is\nintegrated with the guiding strategy, ensuring that all the objectives are\nappropriately balanced and given due consideration during the optimization\nprocess; Extensive experimental results on both synthetic benchmarks and\nreal-world problems demonstrates that our proposed algorithm attains superior\nperformance compared with various state-of-the-art MOBO algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08674v1",
    "published_date": "2024-05-14 14:55:57 UTC",
    "updated_date": "2024-05-14 14:55:57 UTC"
  },
  {
    "arxiv_id": "2405.08668v1",
    "title": "Promoting AI Equity in Science: Generalized Domain Prompt Learning for Accessible VLM Research",
    "authors": [
      "Qinglong Cao",
      "Yuntian Chen",
      "Lu Lu",
      "Hao Sun",
      "Zhenzhong Zeng",
      "Xiaokang Yang",
      "Dongxiao Zhang"
    ],
    "abstract": "Large-scale Vision-Language Models (VLMs) have demonstrated exceptional\nperformance in natural vision tasks, motivating researchers across domains to\nexplore domain-specific VLMs. However, the construction of powerful\ndomain-specific VLMs demands vast amounts of annotated data, substantial\nelectrical energy, and computing resources, primarily accessible to industry,\nyet hindering VLM research in academia. To address this challenge and foster\nsustainable and equitable VLM research, we present the Generalized Domain\nPrompt Learning (GDPL) framework. GDPL facilitates the transfer of VLMs' robust\nrecognition capabilities from natural vision to specialized domains, without\nthe need for extensive data or resources. By leveraging small-scale\ndomain-specific foundation models and minimal prompt samples, GDPL empowers the\nlanguage branch with domain knowledge through quaternion networks, uncovering\ncross-modal relationships between domain-specific vision features and natural\nvision-based contextual embeddings. Simultaneously, GDPL guides the vision\nbranch into specific domains through hierarchical propagation of generated\nvision prompt features, grounded in well-matched vision-language relations.\nFurthermore, to fully harness the domain adaptation potential of VLMs, we\nintroduce a novel low-rank adaptation approach. Extensive experiments across\ndiverse domains like remote sensing, medical imaging, geology, Synthetic\nAperture Radar, and fluid dynamics, validate the efficacy of GDPL,\ndemonstrating its ability to achieve state-of-the-art domain recognition\nperformance in a prompt learning paradigm. Our framework paves the way for\nsustainable and inclusive VLM research, transcending the barriers between\nacademia and industry.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "stat.AP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08668v1",
    "published_date": "2024-05-14 14:51:12 UTC",
    "updated_date": "2024-05-14 14:51:12 UTC"
  },
  {
    "arxiv_id": "2405.08658v2",
    "title": "Beyond the Black Box: Do More Complex Deep Learning Models Provide Superior XAI Explanations?",
    "authors": [
      "Mateusz Cedro",
      "Marcin Chlebus"
    ],
    "abstract": "The increasing complexity of Artificial Intelligence models poses challenges\nto interpretability, particularly in the healthcare sector. This study\ninvestigates the impact of deep learning model complexity and Explainable AI\n(XAI) efficacy, utilizing four ResNet architectures (ResNet-18, 34, 50, 101).\nThrough methodical experimentation on 4,369 lung X-ray images of\nCOVID-19-infected and healthy patients, the research evaluates models'\nclassification performance and the relevance of corresponding XAI explanations\nwith respect to the ground-truth disease masks. Results indicate that the\nincrease in model complexity is associated with a decrease in classification\naccuracy and AUC-ROC scores (ResNet-18: 98.4%, 0.997; ResNet-101: 95.9%,\n0.988). Notably, in eleven out of twelve statistical tests performed, no\nstatistically significant differences occurred between XAI quantitative metrics\n- Relevance Rank Accuracy and the proposed Positive Attribution Ratio - across\ntrained models. These results suggest that increased model complexity does not\nconsistently lead to higher performance or relevance of explanations for\nmodels' decision-making processes.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 9 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.08658v2",
    "published_date": "2024-05-14 14:35:35 UTC",
    "updated_date": "2024-10-05 16:36:09 UTC"
  },
  {
    "arxiv_id": "2405.08655v2",
    "title": "A Distributed Approach to Autonomous Intersection Management via Multi-Agent Reinforcement Learning",
    "authors": [
      "Matteo Cederle",
      "Marco Fabris",
      "Gian Antonio Susto"
    ],
    "abstract": "Autonomous intersection management (AIM) poses significant challenges due to\nthe intricate nature of real-world traffic scenarios and the need for a highly\nexpensive centralised server in charge of simultaneously controlling all the\nvehicles. This study addresses such issues by proposing a novel distributed\napproach to AIM utilizing multi-agent reinforcement learning (MARL). We show\nthat by leveraging the 3D surround view technology for advanced assistance\nsystems, autonomous vehicles can accurately navigate intersection scenarios\nwithout needing any centralised controller. The contributions of this paper\nthus include a MARL-based algorithm for the autonomous management of a 4-way\nintersection and also the introduction of a new strategy called prioritised\nscenario replay for improved training efficacy. We validate our approach as an\ninnovative alternative to conventional centralised AIM techniques, ensuring the\nfull reproducibility of our results. Specifically, experiments conducted in\nvirtual environments using the SMARTS platform highlight its superiority over\nbenchmarks across various metrics.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "15 pages, 2 figures, submitted to Agents in Traffic and\n  Transportation (ATT2024). Status: accepted",
    "pdf_url": "http://arxiv.org/pdf/2405.08655v2",
    "published_date": "2024-05-14 14:34:24 UTC",
    "updated_date": "2024-09-24 12:04:50 UTC"
  },
  {
    "arxiv_id": "2405.08654v2",
    "title": "Can we Defend Against the Unknown? An Empirical Study About Threshold Selection for Neural Network Monitoring",
    "authors": [
      "Khoi Tran Dang",
      "Kevin Delmas",
      "Jérémie Guiochet",
      "Joris Guérin"
    ],
    "abstract": "With the increasing use of neural networks in critical systems, runtime\nmonitoring becomes essential to reject unsafe predictions during inference.\nVarious techniques have emerged to establish rejection scores that maximize the\nseparability between the distributions of safe and unsafe predictions. The\nefficacy of these approaches is mostly evaluated using threshold-agnostic\nmetrics, such as the area under the receiver operating characteristic curve.\nHowever, in real-world applications, an effective monitor also requires\nidentifying a good threshold to transform these scores into meaningful binary\ndecisions. Despite the pivotal importance of threshold optimization, this\nproblem has received little attention. A few studies touch upon this question,\nbut they typically assume that the runtime data distribution mirrors the\ntraining distribution, which is a strong assumption as monitors are supposed to\nsafeguard a system against potentially unforeseen threats. In this work, we\npresent rigorous experiments on various image datasets to investigate: 1. The\neffectiveness of monitors in handling unforeseen threats, which are not\navailable during threshold adjustments. 2. Whether integrating generic threats\ninto the threshold optimization scheme can enhance the robustness of monitors.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.IV"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 5 figures, 6 tables. To appear in the proceedings of the\n  40th Conference on Uncertainty in Artificial Intelligence (UAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.08654v2",
    "published_date": "2024-05-14 14:32:58 UTC",
    "updated_date": "2024-05-21 07:38:02 UTC"
  },
  {
    "arxiv_id": "2405.08644v1",
    "title": "Thinking Tokens for Language Modeling",
    "authors": [
      "David Herel",
      "Tomas Mikolov"
    ],
    "abstract": "How much is 56 times 37? Language models often make mistakes in these types\nof difficult calculations. This is usually explained by their inability to\nperform complex reasoning. Since language models rely on large training sets\nand great memorization capability, naturally they are not equipped to run\ncomplex calculations. However, one can argue that humans also cannot perform\nthis calculation immediately and require a considerable amount of time to\nconstruct the solution. In order to enhance the generalization capability of\nlanguage models, and as a parallel to human behavior, we propose to use special\n'thinking tokens' which allow the model to perform much more calculations\nwhenever a complex problem is encountered.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "AITP 2023 (May 10, 2023)",
    "pdf_url": "http://arxiv.org/pdf/2405.08644v1",
    "published_date": "2024-05-14 14:21:43 UTC",
    "updated_date": "2024-05-14 14:21:43 UTC"
  },
  {
    "arxiv_id": "2405.08604v3",
    "title": "Context-aware Diversity Enhancement for Neural Multi-Objective Combinatorial Optimization",
    "authors": [
      "Yongfan Lu",
      "Zixiang Di",
      "Bingdong Li",
      "Shengcai Liu",
      "Hong Qian",
      "Peng Yang",
      "Ke Tang",
      "Aimin Zhou"
    ],
    "abstract": "Multi-objective combinatorial optimization (MOCO) problems are prevalent in\nvarious real-world applications. Most existing neural MOCO methods rely on\nproblem decomposition to transform an MOCO problem into a series of\nsinge-objective combinatorial optimization (SOCO) problems and train attention\nmodels based on a single-step and deterministic greedy rollout. However,\ninappropriate decomposition and undesirable short-sighted behaviors of previous\nmethods tend to induce a decline in diversity. To address the above limitation,\nwe design a Context-aware Diversity Enhancement algorithm named CDE, which\ncasts the neural MOCO problems as conditional sequence modeling via\nautoregression (node-level context awareness) and establishes a direct\nrelationship between the mapping of preferences and diversity indicator of\nreward based on hypervolume expectation maximization (solution-level context\nawareness). Based on the solution-level context awareness, we further propose a\nhypervolume residual update strategy to enable the Pareto attention model to\ncapture both local and non-local information of the Pareto set/front. The\nproposed CDE can effectively and efficiently grasp the context information,\nresulting in diversity enhancement. Experimental results on three classic MOCO\nproblems demonstrate that our CDE outperforms several state-of-the-art\nbaselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08604v3",
    "published_date": "2024-05-14 13:42:19 UTC",
    "updated_date": "2025-01-26 01:42:34 UTC"
  },
  {
    "arxiv_id": "2405.13015v1",
    "title": "Assisted Debate Builder with Large Language Models",
    "authors": [
      "Elliot Faugier",
      "Frédéric Armetta",
      "Angela Bonifati",
      "Bruno Yun"
    ],
    "abstract": "We introduce ADBL2, an assisted debate builder tool. It is based on the\ncapability of large language models to generalise and perform relation-based\nargument mining in a wide-variety of domains. It is the first open-source tool\nthat leverages relation-based mining for (1) the verification of\npre-established relations in a debate and (2) the assisted creation of new\narguments by means of large language models. ADBL2 is highly modular and can\nwork with any open-source large language models that are used as plugins. As a\nby-product, we also provide the first fine-tuned Mistral-7B large language\nmodel for relation-based argument mining, usable by ADBL2, which outperforms\nexisting approaches for this task with an overall F1-score of 90.59% across all\ndomains.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.13015v1",
    "published_date": "2024-05-14 13:42:12 UTC",
    "updated_date": "2024-05-14 13:42:12 UTC"
  },
  {
    "arxiv_id": "2405.08587v1",
    "title": "EchoTracker: Advancing Myocardial Point Tracking in Echocardiography",
    "authors": [
      "Md Abulkalam Azad",
      "Artem Chernyshov",
      "John Nyberg",
      "Ingrid Tveten",
      "Lasse Lovstakken",
      "Håvard Dalen",
      "Bjørnar Grenne",
      "Andreas Østvik"
    ],
    "abstract": "Tissue tracking in echocardiography is challenging due to the complex cardiac\nmotion and the inherent nature of ultrasound acquisitions. Although optical\nflow methods are considered state-of-the-art (SOTA), they struggle with\nlong-range tracking, noise occlusions, and drift throughout the cardiac cycle.\nRecently, novel learning-based point tracking techniques have been introduced\nto tackle some of these issues. In this paper, we build upon these techniques\nand introduce EchoTracker, a two-fold coarse-to-fine model that facilitates the\ntracking of queried points on a tissue surface across ultrasound image\nsequences. The architecture contains a preliminary coarse initialization of the\ntrajectories, followed by reinforcement iterations based on fine-grained\nappearance changes. It is efficient, light, and can run on mid-range GPUs.\nExperiments demonstrate that the model outperforms SOTA methods, with an\naverage position accuracy of 67% and a median trajectory error of 2.86 pixels.\nFurthermore, we show a relative improvement of 25% when using our model to\ncalculate the global longitudinal strain (GLS) in a clinical test-retest\ndataset compared to other methods. This implies that learning-based point\ntracking can potentially improve performance and yield a higher diagnostic and\nprognostic value for clinical measurements than current techniques. Our source\ncode is available at: https://github.com/riponazad/echotracker/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Submitted version that got provisionally (early) accepted (top 11%)\n  to MICCAI2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08587v1",
    "published_date": "2024-05-14 13:24:51 UTC",
    "updated_date": "2024-05-14 13:24:51 UTC"
  },
  {
    "arxiv_id": "2405.08576v1",
    "title": "Hearing Touch: Audio-Visual Pretraining for Contact-Rich Manipulation",
    "authors": [
      "Jared Mejia",
      "Victoria Dean",
      "Tess Hellebrekers",
      "Abhinav Gupta"
    ],
    "abstract": "Although pre-training on a large amount of data is beneficial for robot\nlearning, current paradigms only perform large-scale pretraining for visual\nrepresentations, whereas representations for other modalities are trained from\nscratch. In contrast to the abundance of visual data, it is unclear what\nrelevant internet-scale data may be used for pretraining other modalities such\nas tactile sensing. Such pretraining becomes increasingly crucial in the\nlow-data regimes common in robotics applications. In this paper, we address\nthis gap by using contact microphones as an alternative tactile sensor. Our key\ninsight is that contact microphones capture inherently audio-based information,\nallowing us to leverage large-scale audio-visual pretraining to obtain\nrepresentations that boost the performance of robotic manipulation. To the best\nof our knowledge, our method is the first approach leveraging large-scale\nmultisensory pre-training for robotic manipulation. For supplementary\ninformation including videos of real robot experiments, please see\nhttps://sites.google.com/view/hearing-touch.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to ICRA 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08576v1",
    "published_date": "2024-05-14 13:16:46 UTC",
    "updated_date": "2024-05-14 13:16:46 UTC"
  },
  {
    "arxiv_id": "2405.13014v2",
    "title": "QCRD: Quality-guided Contrastive Rationale Distillation for Large Language Models",
    "authors": [
      "Wei Wang",
      "Zhaowei Li",
      "Qi Xu",
      "Yiqing Cai",
      "Hang Song",
      "Qi Qi",
      "Ran Zhou",
      "Zhida Huang",
      "Tao Wang",
      "Li Xiao"
    ],
    "abstract": "The deployment of large language models (LLMs) faces considerable challenges\nconcerning resource constraints and inference efficiency. Recent research has\nincreasingly focused on smaller, task-specific models enhanced by distilling\nknowledge from LLMs. However, prior studies have often overlooked the diversity\nand quality of knowledge, especially the untapped potential of negative\nknowledge. Constructing effective negative knowledge remains severely\nunderstudied. In this paper, we introduce a novel framework called\nquality-guided contrastive rationale distillation aimed at enhancing reasoning\ncapabilities through contrastive knowledge learning. For positive knowledge, we\nenrich its diversity through temperature sampling and employ self-consistency\nfor further denoising and refinement. For negative knowledge, we propose an\ninnovative self-adversarial approach that generates low-quality rationales by\nsampling previous iterations of smaller language models, embracing the idea\nthat one can learn from one's own weaknesses. A contrastive loss is developed\nto distill both positive and negative knowledge into smaller language models,\nwhere an online-updating discriminator is integrated to assess qualities of\nrationales and assign them appropriate weights, optimizing the training\nprocess. Through extensive experiments across multiple reasoning tasks, we\ndemonstrate that our method consistently outperforms existing distillation\ntechniques, yielding higher-quality rationales.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13014v2",
    "published_date": "2024-05-14 13:07:10 UTC",
    "updated_date": "2024-09-19 07:23:42 UTC"
  },
  {
    "arxiv_id": "2405.08540v1",
    "title": "Generalizing Knowledge Graph Embedding with Universal Orthogonal Parameterization",
    "authors": [
      "Rui Li",
      "Chaozhuo Li",
      "Yanming Shen",
      "Zeyu Zhang",
      "Xu Chen"
    ],
    "abstract": "Recent advances in knowledge graph embedding (KGE) rely on\nEuclidean/hyperbolic orthogonal relation transformations to model intrinsic\nlogical patterns and topological structures. However, existing approaches are\nconfined to rigid relational orthogonalization with restricted dimension and\nhomogeneous geometry, leading to deficient modeling capability. In this work,\nwe move beyond these approaches in terms of both dimension and geometry by\nintroducing a powerful framework named GoldE, which features a universal\northogonal parameterization based on a generalized form of Householder\nreflection. Such parameterization can naturally achieve dimensional extension\nand geometric unification with theoretical guarantees, enabling our framework\nto simultaneously capture crucial logical patterns and inherent topological\nheterogeneity of knowledge graphs. Empirically, GoldE achieves state-of-the-art\nperformance on three standard benchmarks. Codes are available at\nhttps://github.com/xxrep/GoldE.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08540v1",
    "published_date": "2024-05-14 12:26:19 UTC",
    "updated_date": "2024-05-14 12:26:19 UTC"
  },
  {
    "arxiv_id": "2406.00006v1",
    "title": "A Prompt-driven Task Planning Method for Multi-drones based on Large Language Model",
    "authors": [
      "Yaohua Liu"
    ],
    "abstract": "With the rapid development of drone technology, the application of\nmulti-drones is becoming increasingly widespread in various fields. However,\nthe task planning technology for multi-drones still faces challenges such as\nthe complexity of remote operation and the convenience of human-machine\ninteraction. To address these issues, this paper proposes a prompt-driven task\nplanning method for multi-drones based on large language models. By introducing\nthe Prompt technique, appropriate prompt information is provided for the\nmulti-drone system.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00006v1",
    "published_date": "2024-05-14 12:24:39 UTC",
    "updated_date": "2024-05-14 12:24:39 UTC"
  },
  {
    "arxiv_id": "2405.08528v2",
    "title": "From Internet of Things Data to Business Processes: Challenges and a Framework",
    "authors": [
      "Juergen Mangler",
      "Ronny Seiger",
      "Janik-Vasily Benzin",
      "Joscha Grüger",
      "Yusuf Kirikkayis",
      "Florian Gallik",
      "Lukas Malburg",
      "Matthias Ehrendorfer",
      "Yannis Bertrand",
      "Marco Franceschetti",
      "Barbara Weber",
      "Stefanie Rinderle-Ma",
      "Ralph Bergmann",
      "Estefanía Serral Asensio",
      "Manfred Reichert"
    ],
    "abstract": "The IoT and Business Process Management (BPM) communities co-exist in many\nshared application domains, such as manufacturing and healthcare. The IoT\ncommunity has a strong focus on hardware, connectivity and data; the BPM\ncommunity focuses mainly on finding, controlling, and enhancing the structured\ninteractions among the IoT devices in processes. While the field of Process\nMining deals with the extraction of process models and process analytics from\nprocess event logs, the data produced by IoT sensors often is at a lower\ngranularity than these process-level events. The fundamental questions about\nextracting and abstracting process-related data from streams of IoT sensor\nvalues are: (1) Which sensor values can be clustered together as part of\nprocess events?, (2) Which sensor values signify the start and end of such\nevents?, (3) Which sensor values are related but not essential? This work\nproposes a framework to semi-automatically perform a set of structured steps to\nconvert low-level IoT sensor data into higher-level process events that are\nsuitable for process mining. The framework is meant to provide a generic\nsequence of abstract steps to guide the event extraction, abstraction, and\ncorrelation, with variation points for plugging in specific analysis techniques\nand algorithms for each step. To assess the completeness of the framework, we\npresent a set of challenges, how they can be tackled through the framework, and\nan example on how to instantiate the framework in a real-world demonstration\nfrom the field of smart manufacturing. Based on this framework, future research\ncan be conducted in a structured manner through refining and improving\nindividual steps.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "H.3.3; I.2.1"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08528v2",
    "published_date": "2024-05-14 12:07:07 UTC",
    "updated_date": "2024-05-22 13:10:54 UTC"
  },
  {
    "arxiv_id": "2405.08848v1",
    "title": "Automated Repair of AI Code with Large Language Models and Formal Verification",
    "authors": [
      "Yiannis Charalambous",
      "Edoardo Manino",
      "Lucas C. Cordeiro"
    ],
    "abstract": "The next generation of AI systems requires strong safety guarantees. This\nreport looks at the software implementation of neural networks and related\nmemory safety properties, including NULL pointer deference, out-of-bound\naccess, double-free, and memory leaks. Our goal is to detect these\nvulnerabilities, and automatically repair them with the help of large language\nmodels. To this end, we first expand the size of NeuroCodeBench, an existing\ndataset of neural network code, to about 81k programs via an automated process\nof program mutation. Then, we verify the memory safety of the mutated neural\nnetwork implementations with ESBMC, a state-of-the-art software verifier.\nWhenever ESBMC spots a vulnerability, we invoke a large language model to\nrepair the source code. For the latest task, we compare the performance of\nvarious state-of-the-art prompt engineering techniques, and an iterative\napproach that repeatedly calls the large language model.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08848v1",
    "published_date": "2024-05-14 11:52:56 UTC",
    "updated_date": "2024-05-14 11:52:56 UTC"
  },
  {
    "arxiv_id": "2405.08510v1",
    "title": "Growing Artificial Neural Networks for Control: the Role of Neuronal Diversity",
    "authors": [
      "Eleni Nisioti",
      "Erwan Plantec",
      "Milton Montero",
      "Joachim Winther Pedersen",
      "Sebastian Risi"
    ],
    "abstract": "In biological evolution complex neural structures grow from a handful of\ncellular ingredients. As genomes in nature are bounded in size, this complexity\nis achieved by a growth process where cells communicate locally to decide\nwhether to differentiate, proliferate and connect with other cells. This\nself-organisation is hypothesized to play an important part in the\ngeneralisation, and robustness of biological neural networks. Artificial neural\nnetworks (ANNs), on the other hand, are traditionally optimized in the space of\nweights. Thus, the benefits and challenges of growing artificial neural\nnetworks remain understudied. Building on the previously introduced Neural\nDevelopmental Programs (NDP), in this work we present an algorithm for growing\nANNs that solve reinforcement learning tasks. We identify a key challenge:\nensuring phenotypic complexity requires maintaining neuronal diversity, but\nthis diversity comes at the cost of optimization stability. To address this, we\nintroduce two mechanisms: (a) equipping neurons with an intrinsic state\ninherited upon neurogenesis; (b) lateral inhibition, a mechanism inspired by\nbiological growth, which controlls the pace of growth, helping diversity\npersist. We show that both mechanisms contribute to neuronal diversity and\nthat, equipped with them, NDPs achieve comparable results to existing direct\nand developmental encodings in complex locomotion tasks",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08510v1",
    "published_date": "2024-05-14 11:21:52 UTC",
    "updated_date": "2024-05-14 11:21:52 UTC"
  },
  {
    "arxiv_id": "2405.17441v2",
    "title": "When Large Language Models Meet Optical Networks: Paving the Way for Automation",
    "authors": [
      "Danshi Wang",
      "Yidi Wang",
      "Xiaotian Jiang",
      "Yao Zhang",
      "Yue Pang",
      "Min Zhang"
    ],
    "abstract": "Since the advent of GPT, large language models (LLMs) have brought about\nrevolutionary advancements in all walks of life. As a superior natural language\nprocessing (NLP) technology, LLMs have consistently achieved state-of-the-art\nperformance on numerous areas. However, LLMs are considered to be\ngeneral-purpose models for NLP tasks, which may encounter challenges when\napplied to complex tasks in specialized fields such as optical networks. In\nthis study, we propose a framework of LLM-empowered optical networks,\nfacilitating intelligent control of the physical layer and efficient\ninteraction with the application layer through an LLM-driven agent (AI-Agent)\ndeployed in the control layer. The AI-Agent can leverage external tools and\nextract domain knowledge from a comprehensive resource library specifically\nestablished for optical networks. This is achieved through user input and\nwell-crafted prompts, enabling the generation of control instructions and\nresult representations for autonomous operation and maintenance in optical\nnetworks. To improve LLM's capability in professional fields and stimulate its\npotential on complex tasks, the details of performing prompt engineering,\nestablishing domain knowledge library, and implementing complex tasks are\nillustrated in this study. Moreover, the proposed framework is verified on two\ntypical tasks: network alarm analysis and network performance optimization. The\ngood response accuracies and sematic similarities of 2,400 test situations\nexhibit the great potential of LLM in optical networks.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.CL",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.17441v2",
    "published_date": "2024-05-14 10:46:33 UTC",
    "updated_date": "2024-06-25 03:23:00 UTC"
  },
  {
    "arxiv_id": "2405.13013v2",
    "title": "Amplifying Aspect-Sentence Awareness: A Novel Approach for Aspect-Based Sentiment Analysis",
    "authors": [
      "Adamu Lawan",
      "Juhua Pu",
      "Haruna Yunusa",
      "Jawad Muhammad",
      "Aliyu Umar"
    ],
    "abstract": "Aspect-Based Sentiment Analysis (ABSA) is increasingly crucial in Natural\nLanguage Processing (NLP) for applications such as customer feedback analysis\nand product recommendation systems. ABSA goes beyond traditional sentiment\nanalysis by extracting sentiments related to specific aspects mentioned in the\ntext; existing attention-based models often need help to effectively connect\naspects with context due to language complexity and multiple sentiment\npolarities in a single sentence. Recent research underscores the value of\nintegrating syntactic information, such as dependency trees, to understand\nlong-range syntactic relationships better and link aspects with context.\nDespite these advantages, challenges persist, including sensitivity to parsing\nerrors and increased computational complexity when combining syntactic and\nsemantic information. To address these issues, we propose Amplifying\nAspect-Sentence Awareness (A3SN), a novel technique designed to enhance ABSA\nthrough amplifying aspect-sentence awareness attention. Following the\ntransformer's standard process, our innovative approach incorporates multi-head\nattention mechanisms to augment the model with sentence and aspect semantic\ninformation. We added another multi-head attention module: amplify\naspect-sentence awareness attention. By doubling its focus between the sentence\nand aspect, we effectively highlighted aspect importance within the sentence\ncontext. This enables accurate capture of subtle relationships and\ndependencies. Additionally, gated fusion integrates feature representations\nfrom multi-head and amplified aspect-sentence awareness attention mechanisms,\nwhich is essential for ABSA. Experimental results across three benchmark\ndatasets demonstrate A3SN's effectiveness and outperform state-of-the-art\n(SOTA) baseline models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "24 pages, 4 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.13013v2",
    "published_date": "2024-05-14 10:29:59 UTC",
    "updated_date": "2024-10-26 21:09:33 UTC"
  },
  {
    "arxiv_id": "2405.08483v1",
    "title": "RDPN6D: Residual-based Dense Point-wise Network for 6Dof Object Pose Estimation Based on RGB-D Images",
    "authors": [
      "Zong-Wei Hong",
      "Yen-Yang Hung",
      "Chu-Song Chen"
    ],
    "abstract": "In this work, we introduce a novel method for calculating the 6DoF pose of an\nobject using a single RGB-D image. Unlike existing methods that either directly\npredict objects' poses or rely on sparse keypoints for pose recovery, our\napproach addresses this challenging task using dense correspondence, i.e., we\nregress the object coordinates for each visible pixel. Our method leverages\nexisting object detection methods. We incorporate a re-projection mechanism to\nadjust the camera's intrinsic matrix to accommodate cropping in RGB-D images.\nMoreover, we transform the 3D object coordinates into a residual\nrepresentation, which can effectively reduce the output space and yield\nsuperior performance. We conducted extensive experiments to validate the\nefficacy of our approach for 6D pose estimation. Our approach outperforms most\nprevious methods, especially in occlusion scenarios, and demonstrates notable\nimprovements over the state-of-the-art methods. Our code is available on\nhttps://github.com/AI-Application-and-Integration-Lab/RDPN6D.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR Workshop DLGC, 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08483v1",
    "published_date": "2024-05-14 10:10:45 UTC",
    "updated_date": "2024-05-14 10:10:45 UTC"
  },
  {
    "arxiv_id": "2405.08469v1",
    "title": "GPT-3.5 for Grammatical Error Correction",
    "authors": [
      "Anisia Katinskaia",
      "Roman Yangarber"
    ],
    "abstract": "This paper investigates the application of GPT-3.5 for Grammatical Error\nCorrection (GEC) in multiple languages in several settings: zero-shot GEC,\nfine-tuning for GEC, and using GPT-3.5 to re-rank correction hypotheses\ngenerated by other GEC models. In the zero-shot setting, we conduct automatic\nevaluations of the corrections proposed by GPT-3.5 using several methods:\nestimating grammaticality with language models (LMs), the Scribendi test, and\ncomparing the semantic embeddings of sentences. GPT-3.5 has a known tendency to\nover-correct erroneous sentences and propose alternative corrections. For\nseveral languages, such as Czech, German, Russian, Spanish, and Ukrainian,\nGPT-3.5 substantially alters the source sentences, including their semantics,\nwhich presents significant challenges for evaluation with reference-based\nmetrics. For English, GPT-3.5 demonstrates high recall, generates fluent\ncorrections, and generally preserves sentence semantics. However, human\nevaluation for both English and Russian reveals that, despite its strong\nerror-detection capabilities, GPT-3.5 struggles with several error types,\nincluding punctuation mistakes, tense errors, syntactic dependencies between\nwords, and lexical compatibility at the sentence level.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08469v1",
    "published_date": "2024-05-14 09:51:09 UTC",
    "updated_date": "2024-05-14 09:51:09 UTC"
  },
  {
    "arxiv_id": "2405.08468v1",
    "title": "Challenges and Opportunities in Text Generation Explainability",
    "authors": [
      "Kenza Amara",
      "Rita Sevastjanova",
      "Mennatallah El-Assady"
    ],
    "abstract": "The necessity for interpretability in natural language processing (NLP) has\nrisen alongside the growing prominence of large language models. Among the\nmyriad tasks within NLP, text generation stands out as a primary objective of\nautoregressive models. The NLP community has begun to take a keen interest in\ngaining a deeper understanding of text generation, leading to the development\nof model-agnostic explainable artificial intelligence (xAI) methods tailored to\nthis task. The design and evaluation of explainability methods are non-trivial\nsince they depend on many factors involved in the text generation process,\ne.g., the autoregressive model and its stochastic nature. This paper outlines\n17 challenges categorized into three groups that arise during the development\nand assessment of attribution-based explainability methods. These challenges\nencompass issues concerning tokenization, defining explanation similarity,\ndetermining token importance and prediction change metrics, the level of human\nintervention required, and the creation of suitable test datasets. The paper\nillustrates how these challenges can be intertwined, showcasing new\nopportunities for the community. These include developing probabilistic\nword-level explainability methods and engaging humans in the explainability\npipeline, from the data design to the final evaluation, to draw robust\nconclusions on xAI methods.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 5 figures, xAI-2024 Conference, Main track",
    "pdf_url": "http://arxiv.org/pdf/2405.08468v1",
    "published_date": "2024-05-14 09:44:52 UTC",
    "updated_date": "2024-05-14 09:44:52 UTC"
  },
  {
    "arxiv_id": "2405.08467v1",
    "title": "Equilibrium Propagation: the Quantum and the Thermal Cases",
    "authors": [
      "Serge Massar",
      "Bortolo Matteo Mognetti"
    ],
    "abstract": "Equilibrium propagation is a recently introduced method to use and train\nartificial neural networks in which the network is at the minimum (more\ngenerally extremum) of an energy functional. Equilibrium propagation has shown\ngood performance on a number of benchmark tasks. Here we extend equilibrium\npropagation in two directions. First we show that there is a natural quantum\ngeneralization of equilibrium propagation in which a quantum neural network is\ntaken to be in the ground state (more generally any eigenstate) of the network\nHamiltonian, with a similar training mechanism that exploits the fact that the\nmean energy is extremal on eigenstates. Second we extend the analysis of\nequilibrium propagation at finite temperature, showing that thermal\nfluctuations allow one to naturally train the network without having to clamp\nthe output layer during training. We also study the low temperature limit of\nequilibrium propagation.",
    "categories": [
      "quant-ph",
      "cond-mat.stat-mech",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08467v1",
    "published_date": "2024-05-14 09:43:32 UTC",
    "updated_date": "2024-05-14 09:43:32 UTC"
  },
  {
    "arxiv_id": "2405.08465v1",
    "title": "How to Surprisingly Consider Recommendations? A Knowledge-Graph-based Approach Relying on Complex Network Metrics",
    "authors": [
      "Oliver Baumann",
      "Durgesh Nandini",
      "Anderson Rossanez",
      "Mirco Schoenfeld",
      "Julio Cesar dos Reis"
    ],
    "abstract": "Traditional recommendation proposals, including content-based and\ncollaborative filtering, usually focus on similarity between items or users.\nExisting approaches lack ways of introducing unexpectedness into\nrecommendations, prioritizing globally popular items over exposing users to\nunforeseen items. This investigation aims to design and evaluate a novel layer\non top of recommender systems suited to incorporate relational information and\nsuggest items with a user-defined degree of surprise. We propose a Knowledge\nGraph (KG) based recommender system by encoding user interactions on item\ncatalogs. Our study explores whether network-level metrics on KGs can influence\nthe degree of surprise in recommendations. We hypothesize that surprisingness\ncorrelates with certain network metrics, treating user profiles as subgraphs\nwithin a larger catalog KG. The achieved solution reranks recommendations based\non their impact on structural graph metrics. Our research contributes to\noptimizing recommendations to reflect the metrics. We experimentally evaluate\nour approach on two datasets of LastFM listening histories and synthetic\nNetflix viewing profiles. We find that reranking items based on complex network\nmetrics leads to a more unexpected and surprising composition of recommendation\nlists.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "cs.SI",
      "H.5.0; H.5.1; H.3.4; H.4.0; I.2.4"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08465v1",
    "published_date": "2024-05-14 09:38:44 UTC",
    "updated_date": "2024-05-14 09:38:44 UTC"
  },
  {
    "arxiv_id": "2405.08460v3",
    "title": "Is Your LLM Outdated? A Deep Look at Temporal Generalization",
    "authors": [
      "Chenghao Zhu",
      "Nuo Chen",
      "Yufei Gao",
      "Yunyi Zhang",
      "Prayag Tiwari",
      "Benyou Wang"
    ],
    "abstract": "The rapid advancement of Large Language Models (LLMs) has led to the\ndevelopment of benchmarks that consider temporal dynamics, however, there\nremains a gap in understanding how well these models can generalize across\ntemporal contexts due to the inherent dynamic nature of language and\ninformation. This paper introduces the concept of temporal generalization in\nLLMs, including bias in past and future generalizations. Then we introduce\nFreshBench, a new evaluation framework that employs fresh text and event\nprediction for assessing LLMs' temporal adaptability, ensuring the evaluation\nprocess free from data leakage and subjective bias. The experiment shows\nsignificant temporal biases and a decline in performance over time. Our\nfindings reveal that powerful models, while initially superior, tend to decline\nmore rapidly in future generalization. Additionally, powerful open-source\nmodels demonstrate better long-term adaptability compared to their\nclosed-source counterparts. Our code is available at\nhttps://github.com/FreedomIntelligence/FreshBench.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2025 Oral",
    "pdf_url": "http://arxiv.org/pdf/2405.08460v3",
    "published_date": "2024-05-14 09:31:31 UTC",
    "updated_date": "2025-04-02 07:20:24 UTC"
  },
  {
    "arxiv_id": "2405.08448v1",
    "title": "Understanding the performance gap between online and offline alignment algorithms",
    "authors": [
      "Yunhao Tang",
      "Daniel Zhaohan Guo",
      "Zeyu Zheng",
      "Daniele Calandriello",
      "Yuan Cao",
      "Eugene Tarassov",
      "Rémi Munos",
      "Bernardo Ávila Pires",
      "Michal Valko",
      "Yong Cheng",
      "Will Dabney"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) is the canonical framework\nfor large language model alignment. However, rising popularity in offline\nalignment algorithms challenge the need for on-policy sampling in RLHF. Within\nthe context of reward over-optimization, we start with an opening set of\nexperiments that demonstrate the clear advantage of online methods over offline\nmethods. This prompts us to investigate the causes to the performance\ndiscrepancy through a series of carefully designed experimental ablations. We\nshow empirically that hypotheses such as offline data coverage and data quality\nby itself cannot convincingly explain the performance difference. We also find\nthat while offline algorithms train policy to become good at pairwise\nclassification, it is worse at generations; in the meantime the policies\ntrained by online algorithms are good at generations while worse at pairwise\nclassification. This hints at a unique interplay between discriminative and\ngenerative capabilities, which is greatly impacted by the sampling process.\nLastly, we observe that the performance discrepancy persists for both\ncontrastive and non-contrastive loss functions, and appears not to be addressed\nby simply scaling up policy networks. Taken together, our study sheds light on\nthe pivotal role of on-policy sampling in AI alignment, and hints at certain\nfundamental challenges of offline alignment algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08448v1",
    "published_date": "2024-05-14 09:12:30 UTC",
    "updated_date": "2024-05-14 09:12:30 UTC"
  },
  {
    "arxiv_id": "2405.08427v1",
    "title": "Impact of Stickers on Multimodal Chat Sentiment Analysis and Intent Recognition: A New Task, Dataset and Baseline",
    "authors": [
      "Yuanchen Shi",
      "Biao Ma",
      "Fang Kong"
    ],
    "abstract": "Stickers are increasingly used in social media to express sentiment and\nintent. When finding typing troublesome, people often use a sticker instead.\nDespite the significant impact of stickers on sentiment analysis and intent\nrecognition, little research has been conducted. To address this gap, we\npropose a new task: Multimodal chat Sentiment Analysis and Intent Recognition\ninvolving Stickers (MSAIRS). Additionally, we introduce a novel multimodal\ndataset containing Chinese chat records and stickers excerpted from several\nmainstream social media platforms. Our dataset includes paired data with the\nsame text but different stickers, and various stickers consisting of the same\nimages with different texts, allowing us to better understand the impact of\nstickers on chat sentiment and intent. We also propose an effective multimodal\njoint model, MMSAIR, for our task, which is validated on our datasets and\nindicates that visual information of stickers counts. Our dataset and code will\nbe publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.08427v1",
    "published_date": "2024-05-14 08:42:49 UTC",
    "updated_date": "2024-05-14 08:42:49 UTC"
  },
  {
    "arxiv_id": "2405.08843v1",
    "title": "FLEXIBLE: Forecasting Cellular Traffic by Leveraging Explicit Inductive Graph-Based Learning",
    "authors": [
      "Duc Thinh Ngo",
      "Kandaraj Piamrat",
      "Ons Aouedi",
      "Thomas Hassan",
      "Philippe Raipin-Parvédy"
    ],
    "abstract": "From a telecommunication standpoint, the surge in users and services\nchallenges next-generation networks with escalating traffic demands and limited\nresources. Accurate traffic prediction can offer network operators valuable\ninsights into network conditions and suggest optimal allocation policies.\nRecently, spatio-temporal forecasting, employing Graph Neural Networks (GNNs),\nhas emerged as a promising method for cellular traffic prediction. However,\nexisting studies, inspired by road traffic forecasting formulations, overlook\nthe dynamic deployment and removal of base stations, requiring the GNN-based\nforecaster to handle an evolving graph. This work introduces a novel inductive\nlearning scheme and a generalizable GNN-based forecasting model that can\nprocess diverse graphs of cellular traffic with one-time training. We also\ndemonstrate that this model can be easily leveraged by transfer learning with\nminimal effort, making it applicable to different areas. Experimental results\nshow up to 9.8% performance improvement compared to the state-of-the-art,\nespecially in rare-data settings with training data reduced to below 20%.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08843v1",
    "published_date": "2024-05-14 07:53:23 UTC",
    "updated_date": "2024-05-14 07:53:23 UTC"
  },
  {
    "arxiv_id": "2405.08842v1",
    "title": "Automated Deep Learning for Load Forecasting",
    "authors": [
      "Julie Keisler",
      "Sandra Claudel",
      "Gilles Cabriel",
      "Margaux Brégère"
    ],
    "abstract": "Accurate forecasting of electricity consumption is essential to ensure the\nperformance and stability of the grid, especially as the use of renewable\nenergy increases. Forecasting electricity is challenging because it depends on\nmany external factors, such as weather and calendar variables. While\nregression-based models are currently effective, the emergence of new\nexplanatory variables and the need to refine the temporality of the signals to\nbe forecasted is encouraging the exploration of novel methodologies, in\nparticular deep learning models. However, Deep Neural Networks (DNNs) struggle\nwith this task due to the lack of data points and the different types of\nexplanatory variables (e.g. integer, float, or categorical). In this paper, we\nexplain why and how we used Automated Deep Learning (AutoDL) to find performing\nDNNs for load forecasting. We ended up creating an AutoDL framework called\nEnergyDragon by extending the DRAGON package and applying it to load\nforecasting. EnergyDragon automatically selects the features embedded in the\nDNN training in an innovative way and optimizes the architecture and the\nhyperparameters of the networks. We demonstrate on the French load signal that\nEnergyDragon can find original DNNs that outperform state-of-the-art load\nforecasting methods as well as other AutoDL approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08842v1",
    "published_date": "2024-05-14 07:51:55 UTC",
    "updated_date": "2024-05-14 07:51:55 UTC"
  },
  {
    "arxiv_id": "2405.08380v1",
    "title": "CIER: A Novel Experience Replay Approach with Causal Inference in Deep Reinforcement Learning",
    "authors": [
      "Jingwen Wang",
      "Dehui Du",
      "Yida Li",
      "Yiyang Li",
      "Yikang Chen"
    ],
    "abstract": "In the training process of Deep Reinforcement Learning (DRL), agents require\nrepetitive interactions with the environment. With an increase in training\nvolume and model complexity, it is still a challenging problem to enhance data\nutilization and explainability of DRL training. This paper addresses these\nchallenges by focusing on the temporal correlations within the time dimension\nof time series. We propose a novel approach to segment multivariate time series\ninto meaningful subsequences and represent the time series based on these\nsubsequences. Furthermore, the subsequences are employed for causal inference\nto identify fundamental causal factors that significantly impact training\noutcomes. We design a module to provide feedback on the causality during DRL\ntraining. Several experiments demonstrate the feasibility of our approach in\ncommon environments, confirming its ability to enhance the effectiveness of DRL\ntraining and impart a certain level of explainability to the training process.\nAdditionally, we extended our approach with priority experience replay\nalgorithm, and experimental results demonstrate the continued effectiveness of\nour approach.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08380v1",
    "published_date": "2024-05-14 07:23:10 UTC",
    "updated_date": "2024-05-14 07:23:10 UTC"
  },
  {
    "arxiv_id": "2407.12131v1",
    "title": "Improving Health Information Access in the World's Largest Maternal Mobile Health Program via Bandit Algorithms",
    "authors": [
      "Arshika Lalan",
      "Shresth Verma",
      "Paula Rodriguez Diaz",
      "Panayiotis Danassis",
      "Amrita Mahale",
      "Kumar Madhu Sudan",
      "Aparna Hegde",
      "Milind Tambe",
      "Aparna Taneja"
    ],
    "abstract": "Harnessing the wide-spread availability of cell phones, many nonprofits have\nlaunched mobile health (mHealth) programs to deliver information via voice or\ntext to beneficiaries in underserved communities, with maternal and infant\nhealth being a key area of such mHealth programs. Unfortunately, dwindling\nlistenership is a major challenge, requiring targeted interventions using\nlimited resources. This paper focuses on Kilkari, the world's largest mHealth\nprogram for maternal and child care - with over 3 million active subscribers at\na time - launched by India's Ministry of Health and Family Welfare (MoHFW) and\nrun by the non-profit ARRMAN. We present a system called CHAHAK that aims to\nreduce automated dropouts as well as boost engagement with the program through\nthe strategic allocation of interventions to beneficiaries. Past work in a\nsimilar domain has focused on a much smaller scale mHealth program and used\nmarkovian restless multiarmed bandits to optimize a single limited intervention\nresource. However this paper demonstrates the challenges in adopting a\nmarkovian approach in Kilkari; therefore CHAHAK instead relies on non-markovian\ntime-series restless bandits, and optimizes multiple interventions to improve\nlistenership. We use real Kilkari data from the Odisha state in India to show\nCHAHAK's effectiveness in harnessing multiple interventions to boost\nlistenership, benefiting marginalized communities. When deployed CHAHAK will\nassist the largest maternal mHealth program to date.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CY",
    "comment": "Published at Innovative Applications of Artificial Intelligence (IAAI\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2407.12131v1",
    "published_date": "2024-05-14 07:21:49 UTC",
    "updated_date": "2024-05-14 07:21:49 UTC"
  },
  {
    "arxiv_id": "2405.08839v1",
    "title": "PromptMind Team at EHRSQL-2024: Improving Reliability of SQL Generation using Ensemble LLMs",
    "authors": [
      "Satya K Gundabathula",
      "Sriram R Kolar"
    ],
    "abstract": "This paper presents our approach to the EHRSQL-2024 shared task, which aims\nto develop a reliable Text-to-SQL system for electronic health records. We\npropose two approaches that leverage large language models (LLMs) for prompting\nand fine-tuning to generate EHRSQL queries. In both techniques, we concentrate\non bridging the gap between the real-world knowledge on which LLMs are trained\nand the domain specific knowledge required for the task. The paper provides the\nresults of each approach individually, demonstrating that they achieve high\nexecution accuracy. Additionally, we show that an ensemble approach further\nenhances generation reliability by reducing errors. This approach secured us\n2nd place in the shared task competition. The methodologies outlined in this\npaper are designed to be transferable to domain-specific Text-to-SQL problems\nthat emphasize both accuracy and reliability.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DB",
    "comment": "Accepted as a poster for Clinical NLP workshop at NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08839v1",
    "published_date": "2024-05-14 07:16:56 UTC",
    "updated_date": "2024-05-14 07:16:56 UTC"
  },
  {
    "arxiv_id": "2405.08373v1",
    "title": "PromptMind Team at MEDIQA-CORR 2024: Improving Clinical Text Correction with Error Categorization and LLM Ensembles",
    "authors": [
      "Satya Kesav Gundabathula",
      "Sriram R Kolar"
    ],
    "abstract": "This paper describes our approach to the MEDIQA-CORR shared task, which\ninvolves error detection and correction in clinical notes curated by medical\nprofessionals. This task involves handling three subtasks: detecting the\npresence of errors, identifying the specific sentence containing the error, and\ncorrecting it. Through our work, we aim to assess the capabilities of Large\nLanguage Models (LLMs) trained on a vast corpora of internet data that contain\nboth factual and unreliable information. We propose to comprehensively address\nall subtasks together, and suggest employing a unique prompt-based in-context\nlearning strategy. We will evaluate its efficacy in this specialized task\ndemanding a combination of general reasoning and medical knowledge. In medical\nsystems where prediction errors can have grave consequences, we propose\nleveraging self-consistency and ensemble methods to enhance error correction\nand error detection performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted for oral presentation at Clinical NLP workshop, NAACL\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08373v1",
    "published_date": "2024-05-14 07:16:36 UTC",
    "updated_date": "2024-05-14 07:16:36 UTC"
  },
  {
    "arxiv_id": "2405.08838v1",
    "title": "PolyGlotFake: A Novel Multilingual and Multimodal DeepFake Dataset",
    "authors": [
      "Yang Hou",
      "Haitao Fu",
      "Chuankai Chen",
      "Zida Li",
      "Haoyu Zhang",
      "Jianjun Zhao"
    ],
    "abstract": "With the rapid advancement of generative AI, multimodal deepfakes, which\nmanipulate both audio and visual modalities, have drawn increasing public\nconcern. Currently, deepfake detection has emerged as a crucial strategy in\ncountering these growing threats. However, as a key factor in training and\nvalidating deepfake detectors, most existing deepfake datasets primarily focus\non the visual modal, and the few that are multimodal employ outdated\ntechniques, and their audio content is limited to a single language, thereby\nfailing to represent the cutting-edge advancements and globalization trends in\ncurrent deepfake technologies. To address this gap, we propose a novel,\nmultilingual, and multimodal deepfake dataset: PolyGlotFake. It includes\ncontent in seven languages, created using a variety of cutting-edge and popular\nText-to-Speech, voice cloning, and lip-sync technologies. We conduct\ncomprehensive experiments using state-of-the-art detection methods on\nPolyGlotFake dataset. These experiments demonstrate the dataset's significant\nchallenges and its practical value in advancing research into multimodal\ndeepfake detection.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "68T45",
      "I.4.9"
    ],
    "primary_category": "cs.SD",
    "comment": "13 page, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.08838v1",
    "published_date": "2024-05-14 06:40:05 UTC",
    "updated_date": "2024-05-14 06:40:05 UTC"
  },
  {
    "arxiv_id": "2405.08337v2",
    "title": "Perivascular space Identification Nnunet for Generalised Usage (PINGU)",
    "authors": [
      "Benjamin Sinclair",
      "Lucy Vivash",
      "Jasmine Moses",
      "Miranda Lynch",
      "William Pham",
      "Karina Dorfman",
      "Cassandra Marotta",
      "Shaun Koh",
      "Jacob Bunyamin",
      "Ella Rowsthorn",
      "Alex Jarema",
      "Himashi Peiris",
      "Zhaolin Chen",
      "Sandy R Shultz",
      "David K Wright",
      "Dexiao Kong",
      "Sharon L. Naismith",
      "Terence J. OBrien",
      "Meng Law"
    ],
    "abstract": "Perivascular spaces(PVSs) form a central component of the brain\\'s waste\nclearance system, the glymphatic system. These structures are visible on MRI\nimages, and their morphology is associated with aging and neurological disease.\nManual quantification of PVS is time consuming and subjective. Numerous deep\nlearning methods for PVS segmentation have been developed, however the majority\nhave been developed and evaluated on homogenous datasets and high resolution\nscans, perhaps limiting their applicability for the wide range of image\nqualities acquired in clinic and research. In this work we train a nnUNet, a\ntop-performing biomedical image segmentation algorithm, on a heterogenous\ntraining sample of manually segmented MRI images of a range of different\nqualities and resolutions from 6 different datasets. These are compared to\npublicly available deep learning methods for 3D segmentation of PVS. The\nresulting model, PINGU (Perivascular space Identification Nnunet for\nGeneralised Usage), achieved voxel and cluster level dice scores of\n0.50(SD=0.15), 0.63(0.17) in the white matter(WM), and 0.54(0.11), 0.66(0.17)\nin the basal ganglia(BG). Performance on data from unseen sites was\nsubstantially lower for both PINGU(0.20-0.38(WM, voxel), 0.29-0.58(WM,\ncluster), 0.22-0.36(BG, voxel), 0.46-0.60(BG, cluster)) and the publicly\navailable algorithms(0.18-0.30(WM, voxel), 0.29-0.38(WM cluster), 0.10-0.20(BG,\nvoxel), 0.15-0.37(BG, cluster)), but PINGU strongly outperformed the publicly\navailable algorithms, particularly in the BG. Finally, training PINGU on manual\nsegmentations from a single site with homogenous scan properties gave\nmarginally lower performances on internal cross-validation, but in some cases\ngave higher performance on external validation. PINGU stands out as broad-use\nPVS segmentation tool, with particular strength in the BG, an area of PVS\nrelated to vascular disease and pathology.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08337v2",
    "published_date": "2024-05-14 06:16:13 UTC",
    "updated_date": "2024-05-17 06:47:44 UTC"
  },
  {
    "arxiv_id": "2405.08334v2",
    "title": "Could Chemical LLMs benefit from Message Passing",
    "authors": [
      "Jiaqing Xie",
      "Ziheng Chi"
    ],
    "abstract": "Pretrained language models (LMs) showcase significant capabilities in\nprocessing molecular text, while concurrently, message passing neural networks\n(MPNNs) demonstrate resilience and versatility in the domain of molecular\nscience. Despite these advancements, we find there are limited studies\ninvestigating the bidirectional interactions between molecular structures and\ntheir corresponding textual representations. Therefore, in this paper, we\npropose two strategies to evaluate whether an information integration can\nenhance the performance: contrast learning, which involves utilizing an MPNN to\nsupervise the training of the LM, and fusion, which exploits information from\nboth models. Our empirical analysis reveals that the integration approaches\nexhibit superior performance compared to baselines when applied to smaller\nmolecular graphs, while these integration approaches do not yield performance\nenhancements on large scale graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ACL @ Languages and Molecules 2024. In Proceedings of ACL\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08334v2",
    "published_date": "2024-05-14 06:09:08 UTC",
    "updated_date": "2024-08-26 08:24:14 UTC"
  },
  {
    "arxiv_id": "2405.08329v1",
    "title": "Cross-Dataset Generalization For Retinal Lesions Segmentation",
    "authors": [
      "Clément Playout",
      "Farida Cheriet"
    ],
    "abstract": "Identifying lesions in fundus images is an important milestone toward an\nautomated and interpretable diagnosis of retinal diseases. To support research\nin this direction, multiple datasets have been released, proposing groundtruth\nmaps for different lesions. However, important discrepancies exist between the\nannotations and raise the question of generalization across datasets. This\nstudy characterizes several known datasets and compares different techniques\nthat have been proposed to enhance the generalisation performance of a model,\nsuch as stochastic weight averaging, model soups and ensembles. Our results\nprovide insights into how to combine coarsely labelled data with a\nfinely-grained dataset in order to improve the lesions segmentation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.08329v1",
    "published_date": "2024-05-14 05:52:01 UTC",
    "updated_date": "2024-05-14 05:52:01 UTC"
  },
  {
    "arxiv_id": "2405.08311v1",
    "title": "A Decoupling and Aggregating Framework for Joint Extraction of Entities and Relations",
    "authors": [
      "Yao Wang",
      "Xin Liu",
      "Weikun Kong",
      "Hai-Tao Yu",
      "Teeradaj Racharak",
      "Kyoung-Sook Kim",
      "Minh Le Nguyen"
    ],
    "abstract": "Named Entity Recognition and Relation Extraction are two crucial and\nchallenging subtasks in the field of Information Extraction. Despite the\nsuccesses achieved by the traditional approaches, fundamental research\nquestions remain open. First, most recent studies use parameter sharing for a\nsingle subtask or shared features for both two subtasks, ignoring their\nsemantic differences. Second, information interaction mainly focuses on the two\nsubtasks, leaving the fine-grained informtion interaction among the\nsubtask-specific features of encoding subjects, relations, and objects\nunexplored. Motivated by the aforementioned limitations, we propose a novel\nmodel to jointly extract entities and relations. The main novelties are as\nfollows: (1) We propose to decouple the feature encoding process into three\nparts, namely encoding subjects, encoding objects, and encoding relations.\nThanks to this, we are able to use fine-grained subtask-specific features. (2)\nWe propose novel inter-aggregation and intra-aggregation strategies to enhance\nthe information interaction and construct individual fine-grained\nsubtask-specific features, respectively. The experimental results demonstrate\nthat our model outperforms several previous state-of-the-art models. Extensive\nadditional experiments further confirm the effectiveness of our model.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08311v1",
    "published_date": "2024-05-14 04:27:16 UTC",
    "updated_date": "2024-05-14 04:27:16 UTC"
  },
  {
    "arxiv_id": "2405.08304v2",
    "title": "Computational Thought Experiments for a More Rigorous Philosophy and Science of the Mind",
    "authors": [
      "Iris Oved",
      "Nikhil Krishnaswamy",
      "James Pustejovsky",
      "Joshua Hartshorne"
    ],
    "abstract": "We offer philosophical motivations for a method we call Virtual World\nCognitive Science (VW CogSci), in which researchers use virtual embodied agents\nthat are embedded in virtual worlds to explore questions in the field of\nCognitive Science. We focus on questions about mental and linguistic\nrepresentation and the ways that such computational modeling can add rigor to\nphilosophical thought experiments, as well as the terminology used in the\nscientific study of such representations. We find that this method forces\nresearchers to take a god's-eye view when describing dynamical relationships\nbetween entities in minds and entities in an environment in a way that\neliminates the need for problematic talk of belief and concept types, such as\nthe belief that cats are silly, and the concept CAT, while preserving belief\nand concept tokens in individual cognizers' minds. We conclude with some\nfurther key advantages of VW CogSci for the scientific study of mental and\nlinguistic representation and for Cognitive Science more broadly.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.CL",
    "comment": "6 pages, 4 figures, to appear at CogSci 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08304v2",
    "published_date": "2024-05-14 03:58:19 UTC",
    "updated_date": "2024-05-15 02:32:00 UTC"
  },
  {
    "arxiv_id": "2405.08297v2",
    "title": "Distance-Restricted Explanations: Theoretical Underpinnings & Efficient Implementation",
    "authors": [
      "Yacine Izza",
      "Xuanxiang Huang",
      "Antonio Morgado",
      "Jordi Planes",
      "Alexey Ignatiev",
      "Joao Marques-Silva"
    ],
    "abstract": "The uses of machine learning (ML) have snowballed in recent years. In many\ncases, ML models are highly complex, and their operation is beyond the\nunderstanding of human decision-makers. Nevertheless, some uses of ML models\ninvolve high-stakes and safety-critical applications. Explainable artificial\nintelligence (XAI) aims to help human decision-makers in understanding the\noperation of such complex ML models, thus eliciting trust in their operation.\nUnfortunately, the majority of past XAI work is based on informal approaches,\nthat offer no guarantees of rigor. Unsurprisingly, there exists comprehensive\nexperimental and theoretical evidence confirming that informal methods of XAI\ncan provide human-decision makers with erroneous information. Logic-based XAI\nrepresents a rigorous approach to explainability; it is model-based and offers\nthe strongest guarantees of rigor of computed explanations. However, a\nwell-known drawback of logic-based XAI is the complexity of logic reasoning,\nespecially for highly complex ML models. Recent work proposed\ndistance-restricted explanations, i.e. explanations that are rigorous provided\nthe distance to a given input is small enough. Distance-restricted\nexplainability is tightly related with adversarial robustness, and it has been\nshown to scale for moderately complex ML models, but the number of inputs still\nrepresents a key limiting factor. This paper investigates novel algorithms for\nscaling up the performance of logic-based explainers when computing and\nenumerating ML model explanations with a large number of inputs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08297v2",
    "published_date": "2024-05-14 03:42:33 UTC",
    "updated_date": "2024-12-24 08:12:26 UTC"
  },
  {
    "arxiv_id": "2405.08834v1",
    "title": "Adversarial Machine Learning Threats to Spacecraft",
    "authors": [
      "Rajiv Thummala",
      "Shristi Sharma",
      "Matteo Calabrese",
      "Gregory Falco"
    ],
    "abstract": "Spacecraft are among the earliest autonomous systems. Their ability to\nfunction without a human in the loop have afforded some of humanity's grandest\nachievements. As reliance on autonomy grows, space vehicles will become\nincreasingly vulnerable to attacks designed to disrupt autonomous\nprocesses-especially probabilistic ones based on machine learning. This paper\naims to elucidate and demonstrate the threats that adversarial machine learning\n(AML) capabilities pose to spacecraft. First, an AML threat taxonomy for\nspacecraft is introduced. Next, we demonstrate the execution of AML attacks\nagainst spacecraft through experimental simulations using NASA's Core Flight\nSystem (cFS) and NASA's On-board Artificial Intelligence Research (OnAIR)\nPlatform. Our findings highlight the imperative for incorporating AML-focused\nsecurity measures in spacecraft that engage autonomy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2405.08834v1",
    "published_date": "2024-05-14 02:42:40 UTC",
    "updated_date": "2024-05-14 02:42:40 UTC"
  },
  {
    "arxiv_id": "2405.08252v1",
    "title": "Smart Sampling: Self-Attention and Bootstrapping for Improved Ensembled Q-Learning",
    "authors": [
      "Muhammad Junaid Khan",
      "Syed Hammad Ahmed",
      "Gita Sukthankar"
    ],
    "abstract": "We present a novel method aimed at enhancing the sample efficiency of\nensemble Q learning. Our proposed approach integrates multi-head self-attention\ninto the ensembled Q networks while bootstrapping the state-action pairs\ningested by the ensemble. This not only results in performance improvements\nover the original REDQ (Chen et al. 2021) and its variant DroQ (Hi-raoka et al.\n2022), thereby enhancing Q predictions, but also effectively reduces both the\naverage normalized bias and standard deviation of normalized bias within\nQ-function ensembles. Importantly, our method also performs well even in\nscenarios with a low update-to-data (UTD) ratio. Notably, the implementation of\nour proposed method is straightforward, requiring minimal modifications to the\nbase model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "FLAIRS-37 (2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.08252v1",
    "published_date": "2024-05-14 00:57:02 UTC",
    "updated_date": "2024-05-14 00:57:02 UTC"
  },
  {
    "arxiv_id": "2405.08247v1",
    "title": "Automated classification of multi-parametric body MRI series",
    "authors": [
      "Boah Kim",
      "Tejas Sudharshan Mathai",
      "Kimberly Helm",
      "Ronald M. Summers"
    ],
    "abstract": "Multi-parametric MRI (mpMRI) studies are widely available in clinical\npractice for the diagnosis of various diseases. As the volume of mpMRI exams\nincreases yearly, there are concomitant inaccuracies that exist within the\nDICOM header fields of these exams. This precludes the use of the header\ninformation for the arrangement of the different series as part of the\nradiologist's hanging protocol, and clinician oversight is needed for\ncorrection. In this pilot work, we propose an automated framework to classify\nthe type of 8 different series in mpMRI studies. We used 1,363 studies acquired\nby three Siemens scanners to train a DenseNet-121 model with 5-fold\ncross-validation. Then, we evaluated the performance of the DenseNet-121\nensemble on a held-out test set of 313 mpMRI studies. Our method achieved an\naverage precision of 96.6%, sensitivity of 96.6%, specificity of 99.6%, and F1\nscore of 96.6% for the MRI series classification task. To the best of our\nknowledge, we are the first to develop a method to classify the series type in\nmpMRI studies acquired at the level of the chest, abdomen, and pelvis. Our\nmethod has the capability for robust automation of hanging protocols in modern\nradiology practice.",
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08247v1",
    "published_date": "2024-05-14 00:39:21 UTC",
    "updated_date": "2024-05-14 00:39:21 UTC"
  },
  {
    "arxiv_id": "2405.08246v1",
    "title": "Compositional Text-to-Image Generation with Dense Blob Representations",
    "authors": [
      "Weili Nie",
      "Sifei Liu",
      "Morteza Mardani",
      "Chao Liu",
      "Benjamin Eckart",
      "Arash Vahdat"
    ],
    "abstract": "Existing text-to-image models struggle to follow complex text prompts,\nraising the need for extra grounding inputs for better controllability. In this\nwork, we propose to decompose a scene into visual primitives - denoted as dense\nblob representations - that contain fine-grained details of the scene while\nbeing modular, human-interpretable, and easy-to-construct. Based on blob\nrepresentations, we develop a blob-grounded text-to-image diffusion model,\ntermed BlobGEN, for compositional generation. Particularly, we introduce a new\nmasked cross-attention module to disentangle the fusion between blob\nrepresentations and visual features. To leverage the compositionality of large\nlanguage models (LLMs), we introduce a new in-context learning approach to\ngenerate blob representations from text prompts. Our extensive experiments show\nthat BlobGEN achieves superior zero-shot generation quality and better\nlayout-guided controllability on MS-COCO. When augmented by LLMs, our method\nexhibits superior numerical and spatial correctness on compositional image\ngeneration benchmarks. Project page: https://blobgen-2d.github.io.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.08246v1",
    "published_date": "2024-05-14 00:22:06 UTC",
    "updated_date": "2024-05-14 00:22:06 UTC"
  },
  {
    "arxiv_id": "2405.08245v2",
    "title": "Progressive enhancement and restoration for mural images under low-light and defected conditions based on multi-receptive field strategy",
    "authors": [
      "Xiameng Wei",
      "Binbin Fan",
      "Ying Wang",
      "Yanxiang Feng",
      "Laiyi Fu"
    ],
    "abstract": "Ancient murals are valuable cultural heritage with great archaeological\nvalue. They provide insights into ancient religions, ceremonies, folklore,\namong other things through their content. However, due to long-term oxidation\nand inadequate protection, ancient murals have suffered continuous damage,\nincluding peeling and mold etc. Additionally, since ancient murals were\ntypically painted indoors, the light intensity in images captured by digital\ndevices is often low. The poor visibility hampers the further restoration of\ndamaged areas. To address the escalating damage to ancient murals and\nfacilitate batch restoration at archaeological sites, we propose a two-stage\nrestoration model with automatic defect area detection strategy which called\nMER(Mural Enhancement and Restoration net) for ancient murals that are damaged\nand have been captured in low light. Our two-stage model not only enhances the\nvisual quality of restored images but also achieves commendable results in\nrelevant metric evaluations compared with other competitors. Furthermore, we\nhave launched a website dedicated to the restoration of ancient mural\npaintings, utilizing the proposed model. Code is available at\nhttps://gitee.com/bbfan2024/MER.git.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.08245v2",
    "published_date": "2024-05-14 00:20:32 UTC",
    "updated_date": "2024-07-17 03:36:57 UTC"
  },
  {
    "arxiv_id": "2407.04711v1",
    "title": "MetaFruit Meets Foundation Models: Leveraging a Comprehensive Multi-Fruit Dataset for Advancing Agricultural Foundation Models",
    "authors": [
      "Jiajia Li",
      "Kyle Lammers",
      "Xunyuan Yin",
      "Xiang Yin",
      "Long He",
      "Renfu Lu",
      "Zhaojian Li"
    ],
    "abstract": "Fruit harvesting poses a significant labor and financial burden for the\nindustry, highlighting the critical need for advancements in robotic harvesting\nsolutions. Machine vision-based fruit detection has been recognized as a\ncrucial component for robust identification of fruits to guide robotic\nmanipulation. Despite considerable progress in leveraging deep learning and\nmachine learning techniques for fruit detection, a common shortfall is the\ninability to swiftly extend the developed models across different orchards\nand/or various fruit species. Additionally, the limited availability of\npertinent data further compounds these challenges. In this work, we introduce\nMetaFruit, the largest publicly available multi-class fruit dataset, comprising\n4,248 images and 248,015 manually labeled instances across diverse U.S.\norchards. Furthermore, this study proposes an innovative open-set fruit\ndetection system leveraging advanced Vision Foundation Models (VFMs) for fruit\ndetection that can adeptly identify a wide array of fruit types under varying\norchard conditions. This system not only demonstrates remarkable adaptability\nin learning from minimal data through few-shot learning but also shows the\nability to interpret human instructions for subtle detection tasks. The\nperformance of the developed foundation model is comprehensively evaluated\nusing several metrics, which outperforms the existing state-of-the-art\nalgorithms in both our MetaFruit dataset and other open-sourced fruit datasets,\nthereby setting a new benchmark in the field of agricultural technology and\nrobotic harvesting. The MetaFruit dataset and detection framework are\nopen-sourced to foster future research in vision-based fruit harvesting,\nmarking a significant stride toward addressing the urgent needs of the\nagricultural sector.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "14 pages, 5 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2407.04711v1",
    "published_date": "2024-05-14 00:13:47 UTC",
    "updated_date": "2024-05-14 00:13:47 UTC"
  }
]