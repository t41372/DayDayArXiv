{
  "date": "2025-01-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-11 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 45 篇论文，主要聚焦 AI 模型优化、生成式 AI 应用以及跨领域整合，亮点包括 LLM 偏好优化和常识推理的创新方法，以及 Mark Gerstein 等学者的 ChemAgent 论文，强调了 AI 在化学推理和实际应用中的潜力。\n\n### 重点论文亮点\n我们先聊聊今天最令人印象深刻的论文，这些涉及 AI 核心技术创新、实际应用和潜在话题度高的内容。相关论文已归类，便于连贯讨论。\n\n**1. LLM 偏好优化领域**  \n- **FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings（中文：FocalPO：通过关注正确偏好排名增强偏好优化；英文：FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings）**  \n  作者包括 Volker Tresp，这篇论文提出 FocalPO，一种 DPO 变体，通过动态缩放损失函数优先处理已正确排名的偏好对，提升大语言模型（如 Mistral-Base-7B）在 Alpaca Eval 2.0 等基准上的性能，主要贡献是揭示 DPO 训练的局限性，并改善模型对人类偏好的对齐。\n\n- **Guided Code Generation with LLMs: A Multi-Agent Framework for Complex Code Tasks（中文：引导代码生成：用于复杂代码任务的多代理框架；英文：Guided Code Generation with LLMs: A Multi-Agent Framework for Complex Code Tasks）**  \n  这篇与 FocalPO 相关，引入多代理框架增强 LLM 在复杂代码生成的推理能力，使用 Llama 3.1 8B 模型在 HumanEval 基准上提升 23.79% 的准确率，主要发现是通过结构化引导克服 LLM 的上下文和推理弱点。\n\n- **Common Sense Is All You Need（中文：常识就是你所需要的；英文：Common Sense Is All You Need）**  \n  作者 Hugo Latapie 讨论 AI 缺乏常识的问题，提出从最小先验知识开始的上下文学习和适应性推理框架，强调整合常识是实现 AI 自治的关键贡献，适用于抽象任务如 ARC 和图灵测试。\n\n**2. 多模态和生成模型应用**  \n- **ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation（中文：ChartCoder：推进多模态大语言模型用于图表到代码生成；英文：ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation）**  \n  作者包括 Wanxiang Che 和 Zhiyuan Liu，这篇论文构建了首个 Chart-to-Code MLLM，通过 Snippet-of-Thought 方法和 Chart2Code-160k 数据集，提升代码生成的可执行性和图表细节恢复，在基准上超越现有模型，主要发现是多模态融合的实用性。\n\n- **ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning（中文：ChemAgent：大语言模型的自更新库提升化学推理；英文：ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning）**  \n  作者 Mark Gerstein 参与，这篇备受关注，提出动态自更新库框架分解化学任务，提升 LLM 在 SciBench 等数据集上的性能达 46%，主要贡献是记忆机制在药物发现等领域的潜力。\n\n- **MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare（中文：MedCT：用于医疗生成 AI 应用的临床术语图；英文：MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare）**  \n  这篇聚焦医疗 AI，构建了中文临床术语图和 MedBERT 模型，通过实体链接减少 LLM 幻觉问题，在 EHR 生成和诊断搜索中表现出色，主要发现是标准化术语在非英语社区的普适性。\n\n**3. 其他值得一提的论文**  \n- **Enhancing Path Planning Performance through Image Representation Learning of High-Dimensional Configuration Spaces（中文：通过高维配置空间图像表示学习提升路径规划性能；英文：Enhancing Path Planning Performance through Image Representation Learning of High-Dimensional Configuration Spaces）**  \n  快速提一下，这篇使用 WGAN-GP 算法加速路径规划，实验显示在时间约束下表现出色，主要贡献是处理多模态数据和确保算法完整性。\n\n- **TopoFormer: Integrating Transformers and ConvLSTMs for Coastal Topography Prediction（中文：TopoFormer：整合 Transformer 和 ConvLSTM 用于海岸地形预测；英文：TopoFormer: Integrating Transformers and ConvLSTM for Coastal Topography Prediction）**  \n  这篇结合 Transformer 和 ConvLSTM 预测海岸地形，MAE 低至 2 cm，主要发现是处理时序数据和环境变异的能力。\n\n其他论文如语音处理（Discrete Speech Unit Extraction via Independent Component Analysis）、社交科学应用（Transforming Social Science Research with Transfer Learning）等，虽然有价值，但相对小众，我们就快速掠过不做深入讨论。总之，今天的更新突显 AI 向实用性和鲁棒性进化的趋势，感兴趣的读者可关注 LLM 优化和多模态领域。明日见！",
  "papers": [
    {
      "arxiv_id": "2501.06645v1",
      "title": "FocalPO: Enhancing Preference Optimizing by Focusing on Correct Preference Rankings",
      "title_zh": "FocalPO：通过聚焦于正确的偏好排名来提升偏好优化",
      "authors": [
        "Tong Liu",
        "Xiao Yu",
        "Wenxuan Zhou",
        "Jindong Gu",
        "Volker Tresp"
      ],
      "abstract": "Efficient preference optimization algorithms such as Direct Preference\nOptimization (DPO) have become a popular approach in aligning large language\nmodels (LLMs) with human preferences. These algorithms implicitly treat the LLM\nas a reward model, and focus on training it to correct misranked preference\npairs. However, recent work~\\citep{chen2024preference} empirically finds that\nDPO training \\textit{rarely improves these misranked preference pairs}, despite\nits gradient emphasizing on these cases. We introduce FocalPO, a DPO variant\nthat instead \\textit{down-weighs} misranked preference pairs and prioritizes\nenhancing the model's understanding of pairs that it can already rank\ncorrectly. Inspired by Focal Loss used in vision tasks, FocalPO achieves this\nby adding a modulating factor to dynamically scale DPO loss. Our experiment\ndemonstrates that FocalPO surpasses DPO and its variants on popular benchmarks\nlike Alpaca Eval 2.0 using Mistral-Base-7B and Llama-3-Instruct-8B.\nAdditionally, we empirically reveals how FocalPO affects training on correct\nand incorrect sample groups, further underscoring its effectiveness.",
      "tldr_zh": "该研究针对Direct Preference Optimization (DPO)算法在训练Large Language Models (LLMs)时，难以有效改善错误排序偏好对的问题，提出FocalPO作为其变体。FocalPO通过添加一个调节因子动态缩放DPO损失，降低错误偏好对的权重，并优先增强模型对已正确排序偏好对的理解，受Focal Loss启发。实验结果显示，FocalPO在使用Mistral-Base-7B和Llama-3-Instruct-8B模型的Alpaca Eval 2.0等基准上，超越了DPO及其变体，并揭示了其对正确和错误样本组训练的有效影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06645v1",
      "published_date": "2025-01-11 21:41:27 UTC",
      "updated_date": "2025-01-11 21:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:28:08.779251"
    },
    {
      "arxiv_id": "2501.06642v1",
      "title": "Common Sense Is All You Need",
      "title_zh": "常识就是你所需要的一切",
      "authors": [
        "Hugo Latapie"
      ],
      "abstract": "Artificial intelligence (AI) has made significant strides in recent years,\nyet it continues to struggle with a fundamental aspect of cognition present in\nall animals: common sense. Current AI systems, including those designed for\ncomplex tasks like autonomous driving, problem-solving challenges such as the\nAbstraction and Reasoning Corpus (ARC), and conversational benchmarks like the\nTuring Test, often lack the ability to adapt to new situations without\nextensive prior knowledge. This manuscript argues that integrating common sense\ninto AI systems is essential for achieving true autonomy and unlocking the full\nsocietal and commercial value of AI.\n  We propose a shift in the order of knowledge acquisition emphasizing the\nimportance of developing AI systems that start from minimal prior knowledge and\nare capable of contextual learning, adaptive reasoning, and embodiment -- even\nwithin abstract domains. Additionally, we highlight the need to rethink the AI\nsoftware stack to address this foundational challenge. Without common sense, AI\nsystems may never reach true autonomy, instead exhibiting asymptotic\nperformance that approaches theoretical ideals like AIXI but remains\nunattainable in practice due to infinite resource and computation requirements.\n  While scaling AI models and passing benchmarks like the Turing Test have\nbrought significant advancements in applications that do not require autonomy,\nthese approaches alone are insufficient to achieve autonomous AI with common\nsense. By redefining existing benchmarks and challenges to enforce constraints\nthat require genuine common sense, and by broadening our understanding of\nembodiment to include both physical and abstract domains, we can encourage the\ndevelopment of AI systems better equipped to handle the complexities of\nreal-world and abstract environments.",
      "tldr_zh": "本文认为，AI 虽然取得了重大进展，但缺乏常识(Common Sense)导致其在自主驾驶、Abstraction and Reasoning Corpus (ARC) 和图灵测试(Turing Test) 等任务中难以适应新情况，无法实现真正自治。作者主张重新设计 AI 知识获取顺序，从最小先验知识出发，强调上下文学习、适应性推理和具身性(Embodiment)，并重构 AI 软件栈，以应对这一基础挑战。最终，论文呼吁通过重新定义基准和扩展具身性概念，促进 AI 系统在真实世界和抽象领域中实现更高的自治潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06642v1",
      "published_date": "2025-01-11 21:23:41 UTC",
      "updated_date": "2025-01-11 21:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:28:20.009568"
    },
    {
      "arxiv_id": "2501.06639v1",
      "title": "Enhancing Path Planning Performance through Image Representation Learning of High-Dimensional Configuration Spaces",
      "title_zh": "通过高维配置空间的图像表示学习提升路径规划性能",
      "authors": [
        "Jorge Ocampo Jimenez",
        "Wael Suleiman"
      ],
      "abstract": "This paper presents a novel method for accelerating path-planning tasks in\nunknown scenes with obstacles by utilizing Wasserstein Generative Adversarial\nNetworks (WGANs) with Gradient Penalty (GP) to approximate the distribution of\nwaypoints for a collision-free path using the Rapidly-exploring Random Tree\nalgorithm. Our approach involves conditioning the WGAN-GP with a forward\ndiffusion process in a continuous latent space to handle multimodal datasets\neffectively. We also propose encoding the waypoints of a collision-free path as\na matrix, where the multidimensional ordering of the waypoints is naturally\npreserved. This method not only improves model learning but also enhances\ntraining convergence. Furthermore, we propose a method to assess whether the\ntrained model fails to accurately capture the true waypoints. In such cases, we\nrevert to uniform sampling to ensure the algorithm's probabilistic\ncompleteness; a process that traditionally involves manually determining an\noptimal ratio for each scenario in other machine learning-based methods. Our\nexperiments demonstrate promising results in accelerating path-planning tasks\nunder critical time constraints. The source code is openly available at\nhttps://bitbucket.org/joro3001/imagewgangpplanning/src/master/.",
      "tldr_zh": "本论文提出了一种新方法，使用 WGANs with Gradient Penalty (WGAN-GP) 结合前向扩散过程（forward diffusion process）在连续潜在空间中近似 Rapidly-exploring Random Tree (RRT) 算法的碰撞-free 路径分布，从而加速未知障碍场景下的路径规划任务。方法创新性地将路径点编码为矩阵，以保留多维顺序，提高模型学习和训练收敛效率。论文还引入了一种评估机制来检测模型是否准确捕获路径点，若失败则自动回退到均匀采样，确保算法的 probabilistic completeness，而无需手动调整采样比率。实验结果显示，该方法在时间紧迫的场景中显著提升了路径规划性能，源代码已公开。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06639v1",
      "published_date": "2025-01-11 21:14:52 UTC",
      "updated_date": "2025-01-11 21:14:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:28:31.116726"
    },
    {
      "arxiv_id": "2501.06628v1",
      "title": "Quantifying Relational Exploration in Cultural Heritage Knowledge Graphs with LLMs: A Neuro-Symbolic Approach",
      "title_zh": "使用 LLMs 量化文化遗产知识图谱中的关系探索：一种神经符号方法",
      "authors": [
        "Mohammed Maree"
      ],
      "abstract": "This paper introduces a neuro-symbolic approach for relational exploration in\ncultural heritage knowledge graphs, leveraging Large Language Models (LLMs) for\nexplanation generation and a novel mathematical framework to quantify the\ninterestingness of relationships. We demonstrate the importance of\ninterestingness measure using a quantitative analysis, by highlighting its\nimpact on the overall performance of our proposed system, particularly in terms\nof precision, recall, and F1-score. Using the Wikidata Cultural Heritage Linked\nOpen Data (WCH-LOD) dataset, our approach yields a precision of 0.70, recall of\n0.68, and an F1-score of 0.69, representing an improvement compared to\ngraph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) and knowledge-based\nbaselines (precision: 0.45, recall: 0.42, F1-score: 0.43). Furthermore, our\nLLM-powered explanations exhibit better quality, reflected in BLEU (0.52),\nROUGE-L (0.58), and METEOR (0.63) scores, all higher than the baseline\napproaches. We show a strong correlation (0.65) between interestingness measure\nand the quality of generated explanations, validating its effectiveness. The\nfindings highlight the importance of LLMs and a mathematical formalization for\ninterestingness in enhancing the effectiveness of relational exploration in\ncultural heritage knowledge graphs, with results that are measurable and\ntestable. We further show that the system enables more effective exploration\ncompared to purely knowledge-based and graph-based methods.",
      "tldr_zh": "本论文提出了一种 neuro-symbolic approach，用于文化遗产知识图谱（如 Wikidata Cultural Heritage Linked Open Data）的关系探索，结合 LLMs 生成解释并引入数学框架量化关系的 interestingness。实验结果显示，该方法显著提升了系统性能，在 WCH-LOD 数据集上实现 precision 0.70、recall 0.68 和 F1-score 0.69，比 graph-based (precision: 0.28, recall: 0.25, F1-score: 0.26) 和 knowledge-based 基线 (precision: 0.45, recall: 0.42, F1-score: 0.43) 有了明显改进。LLM 生成的解释质量也更高，BLEU 0.52、ROUGE-L 0.58 和 METEOR 0.63 分数均优于基线，且 interestingness 测量与解释质量的相关性达 0.65，证明了该框架在提升关系探索有效性方面的关键作用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06628v1",
      "published_date": "2025-01-11 19:50:09 UTC",
      "updated_date": "2025-01-11 19:50:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:28:44.956045"
    },
    {
      "arxiv_id": "2501.06625v1",
      "title": "Guided Code Generation with LLMs: A Multi-Agent Framework for Complex Code Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Amr Almorsi",
        "Mohanned Ahmed",
        "Walid Gomaa"
      ],
      "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in code\ngeneration tasks, yet they face significant limitations in handling complex,\nlong-context programming challenges and demonstrating complex compositional\nreasoning abilities. This paper introduces a novel agentic framework for\n``guided code generation'' that tries to address these limitations through a\ndeliberately structured, fine-grained approach to code generation tasks. Our\nframework leverages LLMs' strengths as fuzzy searchers and approximate\ninformation retrievers while mitigating their weaknesses in long sequential\nreasoning and long-context understanding. Empirical evaluation using OpenAI's\nHumanEval benchmark with Meta's Llama 3.1 8B model (int4 precision)\ndemonstrates a 23.79\\% improvement in solution accuracy compared to direct\none-shot generation. Our results indicate that structured, guided approaches to\ncode generation can significantly enhance the practical utility of LLMs in\nsoftware development while overcoming their inherent limitations in\ncompositional reasoning and context handling.",
      "tldr_zh": "本论文针对大型语言模型（LLMs）在处理复杂代码任务时的局限性（如组合推理能力和长上下文理解不足），提出了一种多代理框架（multi-agent framework）来实现“guided code generation”。该框架采用结构化的细粒度方法，利用LLMs的优势（如模糊搜索和近似信息检索），同时缓解其在长序列推理方面的弱点。实验在HumanEval基准上使用Meta的Llama 3.1 8B模型（int4 precision）进行评估，结果显示解决方案准确率比直接一-shot生成提高了23.79%。总体而言，这种指导性方法显著提升了LLMs在软件开发中的实用性，并有效克服了其固有局限性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06625v1",
      "published_date": "2025-01-11 19:21:53 UTC",
      "updated_date": "2025-01-11 19:21:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:28:56.560103"
    },
    {
      "arxiv_id": "2501.06598v1",
      "title": "ChartCoder: Advancing Multimodal Large Language Model for Chart-to-Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Xuanle Zhao",
        "Xianzhen Luo",
        "Qi Shi",
        "Chi Chen",
        "Shuo Wang",
        "Wanxiang Che",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in chart understanding tasks. However, interpreting charts with\ntextual descriptions often leads to information loss, as it fails to fully\ncapture the dense information embedded in charts. In contrast, parsing charts\ninto code provides lossless representations that can effectively contain all\ncritical details. Although existing open-source MLLMs have achieved success in\nchart understanding tasks, they still face two major challenges when applied to\nchart-to-code tasks.: (1) Low executability and poor restoration of chart\ndetails in the generated code and (2) Lack of large-scale and diverse training\ndata. To address these challenges, we propose \\textbf{ChartCoder}, the first\ndedicated chart-to-code MLLM, which leverages Code LLMs as the language\nbackbone to enhance the executability of the generated code. Furthermore, we\nintroduce \\textbf{Chart2Code-160k}, the first large-scale and diverse dataset\nfor chart-to-code generation, and propose the \\textbf{Snippet-of-Thought (SoT)}\nmethod, which transforms direct chart-to-code generation data into step-by-step\ngeneration. Experiments demonstrate that ChartCoder, with only 7B parameters,\nsurpasses existing open-source MLLMs on chart-to-code benchmarks, achieving\nsuperior chart restoration and code excitability. Our code will be available at\nhttps://github.com/thunlp/ChartCoder.",
      "tldr_zh": "本文提出 ChartCoder，一种专为图表到代码生成优化的 Multimodal Large Language Model (MLLMs)，旨在解决现有模型在代码可执行性差和训练数据不足的挑战。ChartCoder 以 Code LLMs 作为语言骨干，结合新引入的 Chart2Code-160k 大规模数据集和 Snippet-of-Thought (SoT) 方法，实现步步为营的代码生成，从而提升图表细节的恢复和代码执行质量。实验结果表明，仅有 7B 参数的 ChartCoder 在 chart-to-code 基准上超过了开源 MLLMs，提供更可靠的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06598v1",
      "published_date": "2025-01-11 17:52:22 UTC",
      "updated_date": "2025-01-11 17:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:31:01.452266"
    },
    {
      "arxiv_id": "2501.06591v1",
      "title": "Exploring Pose-Based Anomaly Detection for Retail Security: A Real-World Shoplifting Dataset and Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Narges Rashvand",
        "Ghazal Alinezhad Noghre",
        "Armin Danesh Pazho",
        "Shanle Yao",
        "Hamed Tabkhi"
      ],
      "abstract": "Shoplifting poses a significant challenge for retailers, resulting in\nbillions of dollars in annual losses. Traditional security measures often fall\nshort, highlighting the need for intelligent solutions capable of detecting\nshoplifting behaviors in real time. This paper frames shoplifting detection as\nan anomaly detection problem, focusing on the identification of deviations from\ntypical shopping patterns. We introduce PoseLift, a privacy-preserving dataset\nspecifically designed for shoplifting detection, addressing challenges such as\ndata scarcity, privacy concerns, and model biases. PoseLift is built in\ncollaboration with a retail store and contains anonymized human pose data from\nreal-world scenarios. By preserving essential behavioral information while\nanonymizing identities, PoseLift balances privacy and utility. We benchmark\nstate-of-the-art pose-based anomaly detection models on this dataset,\nevaluating performance using a comprehensive set of metrics. Our results\ndemonstrate that pose-based approaches achieve high detection accuracy while\neffectively addressing privacy and bias concerns inherent in traditional\nmethods. As one of the first datasets capturing real-world shoplifting\nbehaviors, PoseLift offers researchers a valuable tool to advance computer\nvision ethically and will be publicly available to foster innovation and\ncollaboration. The dataset is available at\nhttps://github.com/TeCSAR-UNCC/PoseLift.",
      "tldr_zh": "这篇论文探讨了基于姿势的 anomaly detection 在零售安全中的应用，将 shoplifting 视为异常检测问题，以识别与典型购物模式不同的行为。研究团队引入了 PoseLift 数据集，这是一个隐私保护的真实世界数据集，由零售店合作构建，包含匿名人体姿势数据，并平衡了隐私与实用性。他们对 state-of-the-art 姿势-based anomaly detection 模型进行了基准测试，结果显示这些方法实现了高检测准确率，同时有效缓解了传统方法的隐私和偏差问题。作为首个捕捉真实 shoplifting 行为的公开数据集，PoseLift 将在 GitHub 上提供，促进计算机视觉领域的伦理创新。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06591v1",
      "published_date": "2025-01-11 17:19:53 UTC",
      "updated_date": "2025-01-11 17:19:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:29:19.978813"
    },
    {
      "arxiv_id": "2501.06590v1",
      "title": "ChemAgent: Self-updating Library in Large Language Models Improves Chemical Reasoning",
      "title_zh": "ChemAgent：大语言模型中自我更新库改善化学推理",
      "authors": [
        "Xiangru Tang",
        "Tianyu Hu",
        "Muyang Ye",
        "Yanjun Shao",
        "Xunjian Yin",
        "Siru Ouyang",
        "Wangchunshu Zhou",
        "Pan Lu",
        "Zhuosheng Zhang",
        "Yilun Zhao",
        "Arman Cohan",
        "Mark Gerstein"
      ],
      "abstract": "Chemical reasoning usually involves complex, multi-step processes that demand\nprecise calculations, where even minor errors can lead to cascading failures.\nFurthermore, large language models (LLMs) encounter difficulties handling\ndomain-specific formulas, executing reasoning steps accurately, and integrating\ncode effectively when tackling chemical reasoning tasks. To address these\nchallenges, we present ChemAgent, a novel framework designed to improve the\nperformance of LLMs through a dynamic, self-updating library. This library is\ndeveloped by decomposing chemical tasks into sub-tasks and compiling these\nsub-tasks into a structured collection that can be referenced for future\nqueries. Then, when presented with a new problem, ChemAgent retrieves and\nrefines pertinent information from the library, which we call memory,\nfacilitating effective task decomposition and the generation of solutions. Our\nmethod designs three types of memory and a library-enhanced reasoning\ncomponent, enabling LLMs to improve over time through experience. Experimental\nresults on four chemical reasoning datasets from SciBench demonstrate that\nChemAgent achieves performance gains of up to 46% (GPT-4), significantly\noutperforming existing methods. Our findings suggest substantial potential for\nfuture applications, including tasks such as drug discovery and materials\nscience. Our code can be found at https://github.com/gersteinlab/chemagent",
      "tldr_zh": "该研究提出 ChemAgent 框架，利用动态自更新库来提升大语言模型（LLMs）在化学推理中的性能，解决处理领域特定公式、准确执行多步推理和代码整合的挑战。框架通过将化学任务分解成子任务、构建三种类型的 memory 系统，并集成库增强推理组件，使模型能够基于经验不断改进和优化。实验结果显示，在 SciBench 的四个化学推理数据集上，ChemAgent 使 GPT-4 的性能提升高达 46%，显著优于现有方法。该框架为药物发现和材料科学等领域的实际应用提供了重要潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06590v1",
      "published_date": "2025-01-11 17:10:30 UTC",
      "updated_date": "2025-01-11 17:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:29:32.365063"
    },
    {
      "arxiv_id": "2501.06577v1",
      "title": "Transforming Social Science Research with Transfer Learning: Social Science Survey Data Integration with AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Amini"
      ],
      "abstract": "Large-N nationally representative surveys, which have profoundly shaped\nAmerican politics scholarship, represent related but distinct domains -a key\ncondition for transfer learning applications. These surveys are related through\ntheir shared demographic, party identification, and ideological variables, yet\ndiffer in that individual surveys often lack specific policy preference\nquestions that researchers require. Our study introduces a novel application of\ntransfer learning (TL) to address these gaps, marking the first systematic use\nof TL paradigms in the context of survey data. Specifically, models pre-trained\non the Cooperative Election Study (CES) dataset are fine-tuned for use in the\nAmerican National Election Studies (ANES) dataset to predict policy questions\nbased on demographic variables. Even with a naive architecture, our transfer\nlearning approach achieves approximately 92 percentage accuracy in predicting\nmissing variables across surveys, demonstrating the robust potential of this\nmethod. Beyond this specific application, our paper argues that transfer\nlearning is a promising framework for maximizing the utility of existing survey\ndata. We contend that artificial intelligence, particularly transfer learning,\nopens new frontiers in social science methodology by enabling systematic\nknowledge transfer between well-administered surveys that share common\nvariables but differ in their outcomes of interest.",
      "tldr_zh": "该研究探讨了转移学习（Transfer Learning）在社会科学调查数据整合中的应用，旨在解决大型全国代表性调查（如影响美国政治研究的那些）共享变量（如人口统计、党派认同和意识形态）但缺少特定政策偏好问题的局限性。研究首次系统地将转移学习应用于调查数据，将在 Cooperative Election Study (CES) 数据集上预训练的模型微调用于 American National Election Studies (ANES) 数据集，以基于人口变量预测缺失的政策问题。即使采用简单架构，该方法在预测缺失变量时达到了约92%的准确率。总体而言，该论文论证了转移学习作为人工智能框架的潜力，能够最大化现有调查数据的效用，并在社会科学方法中实现共享变量调查之间的知识转移。",
      "categories": [
        "cs.AI",
        "I.2.7, I.2.6, H.1.2, I.2.10"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 5 figures, Presented and Submitted to SPSA 2025 (Political\n  Methodology Panel)",
      "pdf_url": "http://arxiv.org/pdf/2501.06577v1",
      "published_date": "2025-01-11 16:01:44 UTC",
      "updated_date": "2025-01-11 16:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:29:44.088928"
    },
    {
      "arxiv_id": "2501.08466v1",
      "title": "A Short-Term Predict-Then-Cluster Framework for Meal Delivery Services",
      "title_zh": "翻译失败",
      "authors": [
        "Jingyi Cheng",
        "Shadi Sharif Azadeh"
      ],
      "abstract": "Micro-delivery services offer promising solutions for on-demand city\nlogistics, but their success relies on efficient real-time delivery operations\nand fleet management. On-demand meal delivery platforms seek to optimize\nreal-time operations based on anticipatory insights into citywide demand\ndistributions. To address these needs, this study proposes a short-term\npredict-then-cluster framework for on-demand meal delivery services. The\nframework utilizes ensemble-learning methods for point and distributional\nforecasting with multivariate features, including lagged-dependent inputs to\ncapture demand dynamics. We introduce Constrained K-Means Clustering (CKMC) and\nContiguity Constrained Hierarchical Clustering with Iterative Constraint\nEnforcement (CCHC-ICE) to generate dynamic clusters based on predicted demand\nand geographical proximity, tailored to user-defined operational constraints.\nEvaluations of European and Taiwanese case studies demonstrate that the\nproposed methods outperform traditional time series approaches in both accuracy\nand computational efficiency. Clustering results demonstrate that the\nincorporation of distributional predictions effectively addresses demand\nuncertainties, improving the quality of operational insights. Additionally, a\nsimulation study demonstrates the practical value of short-term demand\npredictions for proactive strategies, such as idle fleet rebalancing,\nsignificantly enhancing delivery efficiency. By addressing demand uncertainties\nand operational constraints, our predict-then-cluster framework provides\nactionable insights for optimizing real-time operations. The approach is\nadaptable to other on-demand platform-based city logistics and passenger\nmobility services, promoting sustainable and efficient urban operations.",
      "tldr_zh": "这篇论文提出了一种短期的 predict-then-cluster 框架，用于优化按需餐送服务的实时操作，通过 ensemble-learning 方法进行点和分布预测，利用多变量特征（如 lagged-dependent inputs）捕捉需求动态。框架引入 Constrained K-Means Clustering (CKMC) 和 Contiguity Constrained Hierarchical Clustering with Iterative Constraint Enforcement (CCHC-ICE) 算法，基于预测需求和地理位置生成动态聚类，同时考虑用户定义的操作约束。在欧洲和台湾的案例研究中，该方法在准确性和计算效率上优于传统时间序列方法，并通过模拟证明了其在处理需求不确定性和提升交付效率（如闲置车队再平衡）方面的实际价值。该框架可适应其他按需平台-based的城市物流服务，促进可持续的城市运营。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.08466v1",
      "published_date": "2025-01-11 15:59:30 UTC",
      "updated_date": "2025-01-11 15:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:29:56.821825"
    },
    {
      "arxiv_id": "2501.06571v1",
      "title": "Active Rule Mining for Multivariate Anomaly Detection in Radio Access Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ebenezer R. H. P. Isaac",
        "Joseph H. R. Isaac"
      ],
      "abstract": "Multivariate anomaly detection finds its importance in diverse applications.\nDespite the existence of many detectors to solve this problem, one cannot\nsimply define why an obtained anomaly inferred by the detector is anomalous.\nThis reasoning is required for network operators to understand the root cause\nof the anomaly and the remedial action that should be taken to counteract its\noccurrence. Existing solutions in explainable AI may give cues to features that\ninfluence an anomaly, but they do not formulate generalizable rules that can be\nassessed by a domain expert. Furthermore, not all outliers are anomalous in a\nbusiness sense. There is an unfulfilled need for a system that can interpret\nanomalies predicted by a multivariate anomaly detector and map these patterns\nto actionable rules. This paper aims to fulfill this need by proposing a\nsemi-autonomous anomaly rule miner. The proposed method is applicable to both\ndiscrete and time series data and is tailored for radio access network (RAN)\nanomaly detection use cases. The proposed method is demonstrated in this paper\nwith time series RAN data.",
      "tldr_zh": "该论文针对多变量异常检测（Multivariate Anomaly Detection）在无线接入网络（Radio Access Networks, RAN）中的应用，强调了异常解释的必要性，因为现有检测器无法提供可操作的根因分析。论文提出了一种半自治异常规则挖掘器（semi-autonomous anomaly rule miner），该方法能将检测到的异常模式转化为可由领域专家评估的通用规则，并适用于离散和时间序列数据。实验在时间序列 RAN 数据上进行了演示，展示了该方法如何提升异常的可解释性和业务实用性，从而帮助网络运营商采取针对性补救措施。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06571v1",
      "published_date": "2025-01-11 15:42:25 UTC",
      "updated_date": "2025-01-11 15:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:31:12.233638"
    },
    {
      "arxiv_id": "2501.06562v1",
      "title": "Discrete Speech Unit Extraction via Independent Component Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Tomohiko Nakamura",
        "Kwanghee Choi",
        "Keigo Hojo",
        "Yoshiaki Bando",
        "Satoru Fukayama",
        "Shinji Watanabe"
      ],
      "abstract": "Self-supervised speech models (S3Ms) have become a common tool for the speech\nprocessing community, leveraging representations for downstream tasks.\nClustering S3M representations yields discrete speech units (DSUs), which serve\nas compact representations for speech signals. DSUs are typically obtained by\nk-means clustering. Using DSUs often leads to strong performance in various\ntasks, including automatic speech recognition (ASR). However, even with the\nhigh dimensionality and redundancy of S3M representations, preprocessing S3M\nrepresentations for better clustering remains unexplored, even though it can\naffect the quality of DSUs. In this paper, we investigate the potential of\nlinear preprocessing methods for extracting DSUs. We evaluate standardization,\nprincipal component analysis, whitening, and independent component analysis\n(ICA) on DSU-based ASR benchmarks and demonstrate their effectiveness as\npreprocessing for k-means. We also conduct extensive analyses of their\nbehavior, such as orthogonality or interpretability of individual components of\nICA.",
      "tldr_zh": "本文研究了通过线性预处理方法改进自监督语音模型 (S3Ms) 表示的聚类过程，以提取高质量的离散语音单位 (DSUs)。方法包括标准化、主成分分析 (PCA)、白化和独立成分分析 (ICA)，随后应用于 k-means 聚类，并在 DSU-based 自动语音识别 (ASR) 基准上进行评估。结果显示，这些预处理技术显著提升了性能，并对 ICA 的正交性和可解释性进行了深入分析。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted to ICASSP 2025 SALMA Workshop. Code available at\n  https://github.com/TomohikoNakamura/ica_dsu_espnet",
      "pdf_url": "http://arxiv.org/pdf/2501.06562v1",
      "published_date": "2025-01-11 14:45:03 UTC",
      "updated_date": "2025-01-11 14:45:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:31:24.902856"
    },
    {
      "arxiv_id": "2501.06561v1",
      "title": "Where to Go Next Day: Multi-scale Spatial-Temporal Decoupled Model for Mid-term Human Mobility Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zongyuan Huang",
        "Weipeng Wang",
        "Shaoyu Huang",
        "Marta C. Gonzalez",
        "Yaohui Jin",
        "Yanyan Xu"
      ],
      "abstract": "Predicting individual mobility patterns is crucial across various\napplications. While current methods mainly focus on predicting the next\nlocation for personalized services like recommendations, they often fall short\nin supporting broader applications such as traffic management and epidemic\ncontrol, which require longer period forecasts of human mobility. This study\naddresses mid-term mobility prediction, aiming to capture daily travel patterns\nand forecast trajectories for the upcoming day or week. We propose a novel\nMulti-scale Spatial-Temporal Decoupled Predictor (MSTDP) designed to\nefficiently extract spatial and temporal information by decoupling daily\ntrajectories into distinct location-duration chains. Our approach employs a\nhierarchical encoder to model multi-scale temporal patterns, including daily\nrecurrence and weekly periodicity, and utilizes a transformer-based decoder to\nglobally attend to predicted information in the location or duration chain.\nAdditionally, we introduce a spatial heterogeneous graph learner to capture\nmulti-scale spatial relationships, enhancing semantic-rich representations.\nExtensive experiments, including statistical physics analysis, are conducted on\nlarge-scale mobile phone records in five cities (Boston, Los Angeles, SF Bay\nArea, Shanghai, and Tokyo), to demonstrate MSTDP's advantages. Applied to\nepidemic modeling in Boston, MSTDP significantly outperforms the\nbest-performing baseline, achieving a remarkable 62.8% reduction in MAE for\ncumulative new cases.",
      "tldr_zh": "本研究针对中期人类移动性预测（如未来一天或一周的轨迹），提出了一种新型 Multi-scale Spatial-Temporal Decoupled Predictor (MSTDP) 模型，以解决现有方法在交通管理和流行病控制等应用中的局限性。MSTDP 通过将每日轨迹解耦为位置-持续时间链，利用分层编码器捕捉多尺度时间模式（如每日重复和每周周期性），并结合 Transformer-based 解码器和空间异构图学习器来提取丰富的空间关系。实验在波士顿、洛杉矶、旧金山湾区、上海和东京等五城市的移动电话记录上验证了模型的优越性，并在波士顿的流行病建模中，比最佳基线减少了 62.8% 的 MAE，为实际应用提供了显著改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06561v1",
      "published_date": "2025-01-11 14:41:47 UTC",
      "updated_date": "2025-01-11 14:41:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:31:37.116762"
    },
    {
      "arxiv_id": "2501.06557v2",
      "title": "A Survey on Spoken Italian Datasets and Corpora",
      "title_zh": "关于意大利口语数据集和语料库的综述",
      "authors": [
        "Marco Giordano",
        "Claudia Rinaldi"
      ],
      "abstract": "Spoken language datasets are vital for advancing linguistic research, Natural\nLanguage Processing, and speech technology. However, resources dedicated to\nItalian, a linguistically rich and diverse Romance language, remain\nunderexplored compared to major languages like English or Mandarin. This survey\nprovides a comprehensive analysis of 66 spoken Italian datasets, highlighting\ntheir characteristics, methodologies, and applications. The datasets are\ncategorized by speech type, source and context, and demographic and linguistic\nfeatures, with a focus on their utility in fields such as Automatic Speech\nRecognition, emotion detection, and education. Challenges related to dataset\nscarcity, representativeness, and accessibility are discussed alongside\nrecommendations for enhancing dataset creation and utilization. The full\ndataset inventory is publicly accessible via GitHub and archived on Zenodo,\nserving as a valuable resource for researchers and developers. By addressing\ncurrent gaps and proposing future directions, this work aims to support the\nadvancement of Italian speech technologies and linguistic research.",
      "tldr_zh": "本调查综述了66个意大利口语数据集，强调其在语言研究、自然语言处理(NLP)和语音技术中的重要性，同时指出意大利语资源相对于英语或普通话的不足。数据集按语音类型、来源上下文、人口统计和语言特征进行分类，并探讨其在自动语音识别(ASR)、情感检测和教育等领域的应用。文章分析了数据集稀缺性、代表性和可访问性的挑战，并提供改进建议，同时公开数据集清单于GitHub和Zenodo，以推动意大利语音技术和语言研究的进步。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL",
        "A.1; I.2.7; J.5"
      ],
      "primary_category": "cs.CL",
      "comment": "Published on IEEE Access Journal on Feb 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.06557v2",
      "published_date": "2025-01-11 14:33:57 UTC",
      "updated_date": "2025-03-12 13:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:31:48.043749"
    },
    {
      "arxiv_id": "2501.06554v1",
      "title": "Hierarchical Reinforcement Learning for Optimal Agent Grouping in Cooperative Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Liyuan Hu"
      ],
      "abstract": "This paper presents a hierarchical reinforcement learning (RL) approach to\naddress the agent grouping or pairing problem in cooperative multi-agent\nsystems. The goal is to simultaneously learn the optimal grouping and agent\npolicy. By employing a hierarchical RL framework, we distinguish between\nhigh-level decisions of grouping and low-level agents' actions. Our approach\nutilizes the CTDE (Centralized Training with Decentralized Execution) paradigm,\nensuring efficient learning and scalable execution. We incorporate\npermutation-invariant neural networks to handle the homogeneity and cooperation\namong agents, enabling effective coordination. The option-critic algorithm is\nadapted to manage the hierarchical decision-making process, allowing for\ndynamic and optimal policy adjustments.",
      "tldr_zh": "这篇论文提出了一种hierarchical reinforcement learning方法，用于解决合作多智能体系统中的智能体分组问题，目标是同时学习最优分组和高层策略。框架将高层决策（如分组）和低层动作区分开来，并采用CTDE（Centralized Training with Decentralized Execution）范式以及permutation-invariant neural networks，以实现高效学习、可扩展执行和智能体间的有效协调。最终，通过改编option-critic算法，该方法支持动态策略调整，提升了多智能体系统的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06554v1",
      "published_date": "2025-01-11 14:22:10 UTC",
      "updated_date": "2025-01-11 14:22:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:32:00.317879"
    },
    {
      "arxiv_id": "2501.06546v1",
      "title": "Natural Language Supervision for Low-light Image Enhancement",
      "title_zh": "基于自然语言监督的低光照图像增强",
      "authors": [
        "Jiahui Tang",
        "Kaihua Zhou",
        "Zhijian Luo",
        "Yueen Hou"
      ],
      "abstract": "With the development of deep learning, numerous methods for low-light image\nenhancement (LLIE) have demonstrated remarkable performance. Mainstream LLIE\nmethods typically learn an end-to-end mapping based on pairs of low-light and\nnormal-light images. However, normal-light images under varying illumination\nconditions serve as reference images, making it difficult to define a\n``perfect'' reference image This leads to the challenge of reconciling\nmetric-oriented and visual-friendly results. Recently, many cross-modal studies\nhave found that side information from other related modalities can guide visual\nrepresentation learning. Based on this, we introduce a Natural Language\nSupervision (NLS) strategy, which learns feature maps from text corresponding\nto images, offering a general and flexible interface for describing an image\nunder different illumination.\n  However, image distributions conditioned on textual descriptions are highly\nmultimodal, which makes training difficult. To address this issue, we design a\nTextual Guidance Conditioning Mechanism (TCM) that incorporates the connections\nbetween image regions and sentence words, enhancing the ability to capture\nfine-grained cross-modal cues for images and text. This strategy not only\nutilizes a wider range of supervised sources, but also provides a new paradigm\nfor LLIE based on visual and textual feature alignment. In order to effectively\nidentify and merge features from various levels of image and textual\ninformation, we design an Information Fusion Attention (IFA) module to enhance\ndifferent regions at different levels. We integrate the proposed TCM and IFA\ninto a Natural Language Supervision network for LLIE, named NaLSuper. Finally,\nextensive experiments demonstrate the robustness and superior effectiveness of\nour proposed NaLSuper.",
      "tldr_zh": "本文提出了一种基于Natural Language Supervision (NLS)的低光照图像增强（Low-light Image Enhancement, LLIE）方法，使用文本描述作为侧信息来指导图像特征学习，从而解决传统方法依赖不完美参考图像的挑战。论文设计了Textual Guidance Conditioning Mechanism (TCM)来捕捉图像区域与句子单词的细粒度跨模态连接，并引入Information Fusion Attention (IFA)模块以融合多层次图像和文本特征。最终，将这些组件整合到名为NaLSuper的网络中，实验结果证明了其在鲁棒性和增强效果上的显著优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06546v1",
      "published_date": "2025-01-11 13:53:10 UTC",
      "updated_date": "2025-01-11 13:53:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:32:13.377079"
    },
    {
      "arxiv_id": "2501.06532v2",
      "title": "Determination of galaxy photometric redshifts using Conditional Generative Adversarial Networks (CGANs)",
      "title_zh": "利用条件生成对抗网络 (CGANs) 确定星系光度学红移",
      "authors": [
        "M. Garcia-Fernandez"
      ],
      "abstract": "Accurate and reliable photometric redshift determination is one of the key\naspects for wide-field photometric surveys. Determination of photometric\nredshift for galaxies, has been traditionally solved by use of machine-learning\nand artificial intelligence techniques trained on a calibration sample of\ngalaxies, where both photometry and spectrometry are available. On this paper,\nwe present a new algorithmic approach for determining photometric redshifts of\ngalaxies using Conditional Generative Adversarial Networks (CGANs). The\nproposed implementation is able to determine both point-estimation and\nprobability-density estimations for photometric redshifts. The methodology is\ntested with data from Dark Energy Survey (DES) Y1 data and compared with other\nexisting algorithm such as a Mixture Density Network (MDN). Although results\nobtained show a superiority of MDN, CGAN quality-metrics are close to the MDN\nresults, opening the door to the use of CGAN at photometric redshift\nestimation.",
      "tldr_zh": "本研究提出了一种新算法，使用 Conditional Generative Adversarial Networks (CGANs) 来确定星系的光度红移（photometric redshifts），旨在提高宽场光度调查的准确性和可靠性。该方法不仅能提供点估计（point-estimation），还支持概率密度估计（probability-density estimations），并基于 Dark Energy Survey (DES) Y1 数据进行测试。与现有算法如 Mixture Density Network (MDN) 相比，CGANs 的质量指标接近 MDN，但整体表现略逊一筹。这为光度红移估计提供了新的潜在工具，展示了 CGANs 在天文数据分析中的应用潜力。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06532v2",
      "published_date": "2025-01-11 12:42:07 UTC",
      "updated_date": "2025-03-13 12:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:32:25.810065"
    },
    {
      "arxiv_id": "2501.06527v1",
      "title": "Scaffolding Creativity: Integrating Generative AI Tools and Real-world Experiences in Business Education",
      "title_zh": "翻译失败",
      "authors": [
        "Nicole C. Wang"
      ],
      "abstract": "This case study explores the integration of Generative AI tools and\nreal-world experiences in business education. Through a study of an innovative\nundergraduate course, we investigate how AI-assisted learning, combined with\nexperiential components, impacts students' creative processes and learning\noutcomes. Our findings reveal that this integrated approach accelerates\nknowledge acquisition, enables students to overcome traditional creative\nbarriers, and facilitates a dynamic interplay between AI-generated insights and\nreal-world observations. The study also highlights challenges, including the\nneed for instructors with high AI literacy and the rapid evolution of AI tools\ncreating a moving target for curriculum design. These insights contribute to\nthe growing body of literature on AI in education and provide actionable\nrecommendations for educators preparing students for the complexities of modern\nbusiness environments.",
      "tldr_zh": "这篇论文通过一个案例研究，探讨了在商业教育中整合生成式 AI 工具和真实世界经验的创新方法。研究发现，这种整合能加速学生的知识获取，帮助他们克服传统创造障碍，并促进 AI 生成洞见与实际观察的动态互动。论文同时强调了挑战，包括教师需要具备高 AI 素养，以及 AI 工具的快速演变对课程设计的冲击。这些见解为 AI 在教育领域的应用提供了可操作建议，以帮助学生适应现代商业环境的复杂性。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06527v1",
      "published_date": "2025-01-11 12:31:10 UTC",
      "updated_date": "2025-01-11 12:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:32:36.952902"
    },
    {
      "arxiv_id": "2501.06514v1",
      "title": "Neural Codec Source Tracing: Toward Comprehensive Attribution in Open-Set Condition",
      "title_zh": "翻译失败",
      "authors": [
        "Yuankun Xie",
        "Xiaopeng Wang",
        "Zhiyong Wang",
        "Ruibo Fu",
        "Zhengqi Wen",
        "Songjun Cao",
        "Long Ma",
        "Chenxing Li",
        "Haonnan Cheng",
        "Long Ye"
      ],
      "abstract": "Current research in audio deepfake detection is gradually transitioning from\nbinary classification to multi-class tasks, referred as audio deepfake source\ntracing task. However, existing studies on source tracing consider only\nclosed-set scenarios and have not considered the challenges posed by open-set\nconditions. In this paper, we define the Neural Codec Source Tracing (NCST)\ntask, which is capable of performing open-set neural codec classification and\ninterpretable ALM detection. Specifically, we constructed the ST-Codecfake\ndataset for the NCST task, which includes bilingual audio samples generated by\n11 state-of-the-art neural codec methods and ALM-based out-ofdistribution (OOD)\ntest samples. Furthermore, we establish a comprehensive source tracing\nbenchmark to assess NCST models in open-set conditions. The experimental\nresults reveal that although the NCST models perform well in in-distribution\n(ID) classification and OOD detection, they lack robustness in classifying\nunseen real audio. The ST-codecfake dataset and code are available.",
      "tldr_zh": "本文定义了Neural Codec Source Tracing (NCST) 任务，旨在处理音频深度伪造检测从二元分类转向多类来源追踪的挑战，特别是针对开集条件下的神经编解码器分类和可解释的ALM检测。作者构建了ST-Codecfake数据集，包括11种最先进神经编解码器生成的双语音频样本以及基于ALM的OOD测试样本，并建立了全面基准来评估NCST模型在开集场景下的性能。实验结果显示，NCST模型在ID分类和OOD检测上表现出色，但对未见真实音频的分类缺乏鲁棒性，该数据集和代码已公开以促进进一步研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06514v1",
      "published_date": "2025-01-11 11:15:58 UTC",
      "updated_date": "2025-01-11 11:15:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:32:49.647612"
    },
    {
      "arxiv_id": "2501.06506v1",
      "title": "Resource Allocation under the Latin Square Constraint",
      "title_zh": "在拉丁方阵约束下的资源分配",
      "authors": [
        "Yasushi Kawase",
        "Bodhayan Roy",
        "Mohammad Azharuddin Sanpui"
      ],
      "abstract": "A Latin square is an $n \\times n$ matrix filled with $n$ distinct symbols,\neach of which appears exactly once in each row and exactly once in each column.\nWe introduce a problem of allocating $n$ indivisible items among $n$ agents\nover $n$ rounds while satisfying the Latin square constraint. This constraint\nensures that each agent receives no more than one item per round and receives\neach item at most once. Each agent has an additive valuation on the item--round\npairs. Real-world applications like scheduling, resource management, and\nexperimental design require the Latin square constraint to satisfy fairness or\nbalancedness in allocation. Our goal is to find a partial or complete\nallocation that maximizes the sum of the agents' valuations (utilitarian social\nwelfare) or the minimum of the agents' valuations (egalitarian social welfare).\nFor the problem of maximizing utilitarian social welfare, we prove NP-hardness\neven when the valuations are binary additive. We then provide $(1-1/e)$ and\n$(1-1/e)/4$-approximation algorithms for partial and complete settings,\nrespectively. Additionally, we present fixed-parameter tractable (FPT)\nalgorithms with respect to the order of Latin square and the optimum value for\nboth partial and complete settings. For the problem of maximizing egalitarian\nsocial welfare, we establish that deciding whether the optimum value is at most\n$1$ or at least $2$ is NP-hard for both the partial and complete settings, even\nwhen the valuations are binary. Furthermore, we demonstrate that checking the\nexistence of a complete allocation that satisfies each of envy-free,\nproportional, equitable, envy-free up to any good, proportional up to any good,\nor equitable up to any good is NP-hard, even when the valuations are identical.",
      "tldr_zh": "这篇论文引入了在 Latin square 约束下分配 n 个不可分割物品给 n 个代理人的问题，该约束确保每个代理人在每轮只收到一个物品，且每个物品只被分配一次，以实现公平或平衡的资源管理。针对最大化 utilitarian social welfare 的目标，论文证明了该问题是 NP-hardness，即使估值是二元的，并提供了 (1-1/e) 和 (1-1/e)/4 的近似算法，以及针对 Latin square 阶和最优值的 fixed-parameter tractable (FPT) 算法。针对最大化 egalitarian social welfare 的问题，论文展示了相关决策问题（如最优值是否至少为 2）的 NP-hardness，并证明了检查 envy-free、proportional 等公平分配是否存在也是 NP-hard，即使估值相同。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "This paper has been accepted in AAMAS 2025 as an extended abstract",
      "pdf_url": "http://arxiv.org/pdf/2501.06506v1",
      "published_date": "2025-01-11 10:53:48 UTC",
      "updated_date": "2025-01-11 10:53:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:33:01.244998"
    },
    {
      "arxiv_id": "2501.06497v2",
      "title": "PASS: Presentation Automation for Slide Generation and Speech",
      "title_zh": "翻译失败",
      "authors": [
        "Tushar Aggarwal",
        "Aarohi Bhand"
      ],
      "abstract": "In today's fast-paced world, effective presentations have become an essential\ntool for communication in both online and offline meetings. The crafting of a\ncompelling presentation requires significant time and effort, from gathering\nkey insights to designing slides that convey information clearly and concisely.\nHowever, despite the wealth of resources available, people often find\nthemselves manually extracting crucial points, analyzing data, and organizing\ncontent in a way that ensures clarity and impact. Furthermore, a successful\npresentation goes beyond just the slides; it demands rehearsal and the ability\nto weave a captivating narrative to fully engage the audience. Although there\nhas been some exploration of automating document-to-slide generation, existing\nresearch is largely centered on converting research papers. In addition,\nautomation of the delivery of these presentations has yet to be addressed. We\nintroduce PASS, a pipeline used to generate slides from general Word documents,\ngoing beyond just research papers, which also automates the oral delivery of\nthe generated slides. PASS analyzes user documents to create a dynamic,\nengaging presentation with an AI-generated voice. Additionally, we developed an\nLLM-based evaluation metric to assess our pipeline across three critical\ndimensions of presentations: relevance, coherence, and redundancy. The data and\ncodes are available at https://github.com/AggarwalTushar/PASS.",
      "tldr_zh": "本研究针对演示文稿制作的耗时问题，提出PASS系统，这是一个自动化管道，用于从一般Word文档生成幻灯片，并实现口头表达自动化。PASS通过分析文档内容，创建动态且引人入胜的演示，并利用AI生成声音来模拟演讲，从而提升演示的清晰度和吸引力。该系统还开发了基于LLM的评估指标，评估幻灯片在相关性、一致性和冗余方面的表现，并公开了数据和代码以供进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06497v2",
      "published_date": "2025-01-11 10:22:04 UTC",
      "updated_date": "2025-01-15 20:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:33:12.060714"
    },
    {
      "arxiv_id": "2502.00018v1",
      "title": "An Expectation-Maximization Algorithm-based Autoregressive Model for the Fuzzy Job Shop Scheduling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Yijian Wang",
        "Tongxian Guo",
        "Zhaoqiang Liu"
      ],
      "abstract": "The fuzzy job shop scheduling problem (FJSSP) emerges as an innovative\nextension to the job shop scheduling problem (JSSP), incorporating a layer of\nuncertainty that aligns the problem more closely with the complexities of\nreal-world manufacturing environments. This improvement increases the\ncomputational complexity of deriving the solution while improving its\napplicability. In the domain of deterministic scheduling, neural combinatorial\noptimization (NCO) has recently demonstrated remarkable efficacy. However, its\napplication to the realm of fuzzy scheduling has been relatively unexplored.\nThis paper aims to bridge this gap by investigating the feasibility of\nemploying neural networks to assimilate and process fuzzy information for the\nresolution of FJSSP, thereby leveraging the advancements in NCO to enhance\nfuzzy scheduling methodologies. To achieve this, we approach the FJSSP as a\ngenerative task and introduce an expectation-maximization algorithm-based\nautoregressive model (EMARM) to address it. During training, our model\nalternates between generating scheduling schemes from given instances (E-step)\nand adjusting the autoregressive model weights based on these generated schemes\n(M-step). This novel methodology effectively navigates around the substantial\nhurdle of obtaining ground-truth labels, which is a prevalent issue in NCO\nframeworks. In testing, the experimental results demonstrate the superior\ncapability of EMARM in addressing the FJSSP, showcasing its effectiveness and\npotential for practical applications in fuzzy scheduling.",
      "tldr_zh": "这篇论文针对模糊作业车间调度问题 (FJSSP) 提出了一种基于期望最大化算法 (Expectation-Maximization Algorithm) 的自回归模型 (EMARM)，旨在将神经组合优化 (NCO) 应用于处理不确定性的调度任务。EMARM 通过交替的 E-step（从实例生成调度方案）和 M-step（基于方案调整模型权重）进行训练，从而绕过获取真实标签的难题，提高了模型在模糊环境下的适应性。实验结果表明，该模型在 FJSSP 测试中表现出色，具有显著的实际应用潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00018v1",
      "published_date": "2025-01-11 10:20:16 UTC",
      "updated_date": "2025-01-11 10:20:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:33:24.971117"
    },
    {
      "arxiv_id": "2501.06494v1",
      "title": "TopoFormer: Integrating Transformers and ConvLSTMs for Coastal Topography Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Santosh Munian",
        "Oktay Karakuş",
        "William Russell",
        "Gwyn Nelson"
      ],
      "abstract": "This paper presents \\textit{TopoFormer}, a novel hybrid deep learning\narchitecture that integrates transformer-based encoders with convolutional long\nshort-term memory (ConvLSTM) layers for the precise prediction of topographic\nbeach profiles referenced to elevation datums, with a particular focus on Mean\nLow Water Springs (MLWS) and Mean Low Water Neaps (MLWN). Accurate topographic\nestimation down to MLWS is critical for coastal management, navigation safety,\nand environmental monitoring. Leveraging a comprehensive dataset from the Wales\nCoastal Monitoring Centre (WCMC), consisting of over 2000 surveys across 36\ncoastal survey units, TopoFormer addresses key challenges in topographic\nprediction, including temporal variability and data gaps in survey\nmeasurements. The architecture uniquely combines multi-head attention\nmechanisms and ConvLSTM layers to capture both long-range dependencies and\nlocalized temporal patterns inherent in beach profiles data. TopoFormer's\npredictive performance was rigorously evaluated against state-of-the-art\nmodels, including DenseNet, 1D/2D CNNs, and LSTMs. While all models\ndemonstrated strong performance, \\textit{TopoFormer} achieved the lowest mean\nabsolute error (MAE), as low as 2 cm, and provided superior accuracy in both\nin-distribution (ID) and out-of-distribution (OOD) evaluations.",
      "tldr_zh": "本研究提出TopoFormer，一种新型混合深度学习架构，将Transformer-based encoders与ConvLSTM layers整合，用于精确预测海岸地形轮廓，特别是参考Mean Low Water Springs (MLWS)和Mean Low Water Neaps (MLWN)的海拔基准，以支持海岸管理、导航安全和环境监测。利用Wales Coastal Monitoring Centre (WCMC)的超过2000次调查数据，该模型通过multi-head attention机制捕捉长程依赖性，并结合ConvLSTM处理局部时间模式和数据缺口等挑战。与DenseNet、1D/2D CNNs和LSTMs等基准模型相比，TopoFormer在in-distribution (ID)和out-of-distribution (OOD)评估中实现了最低的Mean Absolute Error (MAE)，低至2 cm，显著提升了预测准确性。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "11 pages, 5 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2501.06494v1",
      "published_date": "2025-01-11 09:46:02 UTC",
      "updated_date": "2025-01-11 09:46:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:33:36.775896"
    },
    {
      "arxiv_id": "2501.06491v1",
      "title": "Improving Requirements Classification with SMOTE-Tomek Preprocessing",
      "title_zh": "翻译失败",
      "authors": [
        "Barak Or"
      ],
      "abstract": "This study emphasizes the domain of requirements engineering by applying the\nSMOTE-Tomek preprocessing technique, combined with stratified K-fold\ncross-validation, to address class imbalance in the PROMISE dataset. This\ndataset comprises 969 categorized requirements, classified into functional and\nnon-functional types. The proposed approach enhances the representation of\nminority classes while maintaining the integrity of validation folds, leading\nto a notable improvement in classification accuracy. Logistic regression\nachieved 76.16\\%, significantly surpassing the baseline of 58.31\\%. These\nresults highlight the applicability and efficiency of machine learning models\nas scalable and interpretable solutions.",
      "tldr_zh": "这篇论文针对需求工程中的类别不平衡问题，应用SMOTE-Tomek预处理技术结合分层K-fold交叉验证，处理PROMISE数据集（包含969个分类需求，包括功能性和非功能性类型）。该方法提升了少数类别的表示，同时保持验证折的完整性，导致分类准确率显著提高。结果显示，Logistic Regression模型的准确率从基线58.31%提升至76.16%，突出了机器学习模型作为可扩展和可解释解决方案的适用性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.SE",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06491v1",
      "published_date": "2025-01-11 09:36:14 UTC",
      "updated_date": "2025-01-11 09:36:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:33:48.788736"
    },
    {
      "arxiv_id": "2501.06488v1",
      "title": "NVS-SQA: Exploring Self-Supervised Quality Representation Learning for Neurally Synthesized Scenes without References",
      "title_zh": "翻译失败",
      "authors": [
        "Qiang Qu",
        "Yiran Shen",
        "Xiaoming Chen",
        "Yuk Ying Chung",
        "Weidong Cai",
        "Tongliang Liu"
      ],
      "abstract": "Neural View Synthesis (NVS), such as NeRF and 3D Gaussian Splatting,\neffectively creates photorealistic scenes from sparse viewpoints, typically\nevaluated by quality assessment methods like PSNR, SSIM, and LPIPS. However,\nthese full-reference methods, which compare synthesized views to reference\nviews, may not fully capture the perceptual quality of neurally synthesized\nscenes (NSS), particularly due to the limited availability of dense reference\nviews. Furthermore, the challenges in acquiring human perceptual labels hinder\nthe creation of extensive labeled datasets, risking model overfitting and\nreduced generalizability. To address these issues, we propose NVS-SQA, a NSS\nquality assessment method to learn no-reference quality representations through\nself-supervision without reliance on human labels. Traditional self-supervised\nlearning predominantly relies on the \"same instance, similar representation\"\nassumption and extensive datasets. However, given that these conditions do not\napply in NSS quality assessment, we employ heuristic cues and quality scores as\nlearning objectives, along with a specialized contrastive pair preparation\nprocess to improve the effectiveness and efficiency of learning. The results\nshow that NVS-SQA outperforms 17 no-reference methods by a large margin (i.e.,\non average 109.5% in SRCC, 98.6% in PLCC, and 91.5% in KRCC over the second\nbest) and even exceeds 16 full-reference methods across all evaluation metrics\n(i.e., 22.9% in SRCC, 19.1% in PLCC, and 18.6% in KRCC over the second best).",
      "tldr_zh": "本研究针对神经视图合成 (NVS) 场景，如 NeRF 和 3D Gaussian Splatting，在缺乏参考视图和人类感知标签的情况下，提出了一种无参考的自监督质量评估方法 NVS-SQA。NVS-SQA 通过利用启发式线索、质量分数作为学习目标，并设计专门的对比对准备过程，实现高效的自监督质量表示学习，从而解决传统评估方法（如 PSNR、SSIM 和 LPIPS）的局限性。实验结果表明，NVS-SQA 在 SRCC、PLCC 和 KRCC 等指标上大幅优于 17 个无参考方法（平均提高 109.5% 在 SRCC 等）和 16 个全参考方法（平均提高 22.9% 在 SRCC 等），显著提升了神经合成场景的质量评估性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06488v1",
      "published_date": "2025-01-11 09:12:43 UTC",
      "updated_date": "2025-01-11 09:12:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:34:02.440900"
    },
    {
      "arxiv_id": "2501.06485v1",
      "title": "A Diffusive Data Augmentation Framework for Reconstruction of Complex Network Evolutionary History",
      "title_zh": "翻译失败",
      "authors": [
        "En Xu",
        "Can Rong",
        "Jingtao Ding",
        "Yong Li"
      ],
      "abstract": "The evolutionary processes of complex systems contain critical information\nregarding their functional characteristics. The generation time of edges\nprovides insights into the historical evolution of various networked complex\nsystems, such as protein-protein interaction networks, ecosystems, and social\nnetworks. Recovering these evolutionary processes holds significant scientific\nvalue, including aiding in the interpretation of the evolution of\nprotein-protein interaction networks. However, existing methods are capable of\npredicting the generation times of remaining edges given a partial temporal\nnetwork but often perform poorly in cross-network prediction tasks. These\nmethods frequently fail in edge generation time recovery tasks for static\nnetworks that lack timestamps. In this work, we adopt a comparative\nparadigm-based framework that fuses multiple networks for training, enabling\ncross-network learning of the relationship between network structure and edge\ngeneration times. Compared to separate training, this approach yields an\naverage accuracy improvement of 16.98%. Furthermore, given the difficulty in\ncollecting temporal networks, we propose a novel diffusion-model-based\ngeneration method to produce a large number of temporal networks. By combining\nreal temporal networks with generated ones for training, we achieve an\nadditional average accuracy improvement of 5.46% through joint training.",
      "tldr_zh": "本研究提出一个基于比较范式的框架，用于重建复杂网络的演化历史，通过融合多个网络进行训练，实现跨网络学习网络结构与边生成时间的关系，比单独训练提高16.98%的准确率。该框架特别适用于预测部分时间网络的边生成时间，并扩展到缺乏时间戳的静态网络中。此外，作者引入一种基于diffusion model的生成方法，来产生大量时间网络，与真实网络结合进行联合训练，进一步提升平均准确率5.46%。这项工作为理解蛋白质交互网络、生态系统和社会网络等系统的演化过程提供了更有效的工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06485v1",
      "published_date": "2025-01-11 08:39:33 UTC",
      "updated_date": "2025-01-11 08:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:34:12.818729"
    },
    {
      "arxiv_id": "2501.06472v1",
      "title": "YO-CSA-T: A Real-time Badminton Tracking System Utilizing YOLO Based on Contextual and Spatial Attention",
      "title_zh": "YO-CSA-T：一种基于上下文和空间注意力的YOLO实时",
      "authors": [
        "Yuan Lai",
        "Zhiwei Shi",
        "Chengxi Zhu"
      ],
      "abstract": "The 3D trajectory of a shuttlecock required for a badminton rally robot for\nhuman-robot competition demands real-time performance with high accuracy.\nHowever, the fast flight speed of the shuttlecock, along with various visual\neffects, and its tendency to blend with environmental elements, such as court\nlines and lighting, present challenges for rapid and accurate 2D detection. In\nthis paper, we first propose the YO-CSA detection network, which optimizes and\nreconfigures the YOLOv8s model's backbone, neck, and head by incorporating\ncontextual and spatial attention mechanisms to enhance model's ability in\nextracting and integrating both global and local features. Next, we integrate\nthree major subtasks, detection, prediction, and compensation, into a real-time\n3D shuttlecock trajectory detection system. Specifically, our system maps the\n2D coordinate sequence extracted by YO-CSA into 3D space using stereo vision,\nthen predicts the future 3D coordinates based on historical information, and\nre-projects them onto the left and right views to update the position\nconstraints for 2D detection. Additionally, our system includes a compensation\nmodule to fill in missing intermediate frames, ensuring a more complete\ntrajectory. We conduct extensive experiments on our own dataset to evaluate\nboth YO-CSA's performance and system effectiveness. Experimental results show\nthat YO-CSA achieves a high accuracy of 90.43% mAP@0.75, surpassing both\nYOLOv8s and YOLO11s. Our system performs excellently, maintaining a speed of\nover 130 fps across 12 test sequences.",
      "tldr_zh": "这篇论文提出了 YO-CSA 检测网络，通过在 YOLOv8s 模型的 backbone、neck 和 head 中整合 contextual 和 spatial attention 机制，提升了羽毛球的实时 2D 检测能力，以应对其高速飞行和环境干扰。YO-CSA-T 系统将检测、预测和补偿子任务结合，使用立体视觉将 2D 坐标映射到 3D 空间，并基于历史信息预测未来轨迹，同时通过补偿模块填充缺失帧，确保轨迹完整。实验在自有数据集上显示，YO-CSA 达到了 90.43% mAP@0.75 的准确率，优于 YOLOv8s 和 YOLO11s，且系统在 12 个测试序列上维持超过 130 fps 的速度。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages,14 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06472v1",
      "published_date": "2025-01-11 08:00:25 UTC",
      "updated_date": "2025-01-11 08:00:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:34:26.068359"
    },
    {
      "arxiv_id": "2501.06471v1",
      "title": "The Internet of Large Language Models: An Orchestration Framework for LLM Training and Knowledge Exchange Toward Artificial General Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "Wilson Wei",
        "Nicholas Chen",
        "Yuxuan Li"
      ],
      "abstract": "This paper explores the multi-dimensional challenges faced during the\ndevelopment of Large Language Models (LLMs), including the massive scale of\nmodel parameters and file sizes, the complexity of development environment\nconfiguration, the singularity of model functionality, and the high costs of\ncomputational resources. To address these challenges, this paper proposes three\ncore technical solutions: LLM sharing protocol, LLM universal environment\nframework, and Agent optimal path module. To solve the computational resource\nconstraints in the early stages of research, we further innovatively propose a\njoint mining mechanism, achieving bilateral value sharing between computing\npower providers and model designers, including breakthrough rewards for optimal\nmodel paths and long-term profit distribution, thereby providing researchers\nwith cost-optimized computational resource support and promoting the continuous\ndevelopment of LLM research and applications.",
      "tldr_zh": "这篇论文探讨了开发大型语言模型 (LLMs) 面临的挑战，包括模型参数规模庞大、开发环境配置复杂、模型功能单一以及计算资源成本高。论文提出三个核心技术解决方案：LLM sharing protocol、LLM universal environment framework 和 Agent optimal path module，以优化模型训练和知识交换。进一步创新性地引入联合挖掘机制 (joint mining mechanism)，实现计算力提供者和模型设计者之间的双边价值共享，包括最优模型路径的奖励和长期利润分配，从而为研究者提供成本优化的资源支持，并推动向人工智能通用智能 (AGI) 的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06471v1",
      "published_date": "2025-01-11 08:00:24 UTC",
      "updated_date": "2025-01-11 08:00:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:34:37.234290"
    },
    {
      "arxiv_id": "2501.06468v1",
      "title": "First Token Probability Guided RAG for Telecom Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Tingwei Chen",
        "Jiayi Chen",
        "Zijian Zhao",
        "Haolong Chen",
        "Liang Zhang",
        "Guangxu Zhu"
      ],
      "abstract": "Large Language Models (LLMs) have garnered significant attention for their\nimpressive general-purpose capabilities. For applications requiring intricate\ndomain knowledge, Retrieval-Augmented Generation (RAG) has shown a distinct\nadvantage in incorporating domain-specific information into LLMs. However,\nexisting RAG research has not fully addressed the challenges of Multiple Choice\nQuestion Answering (MCQA) in telecommunications, particularly in terms of\nretrieval quality and mitigating hallucinations. To tackle these challenges, we\npropose a novel first token probability guided RAG framework. This framework\nleverages confidence scores to optimize key hyperparameters, such as chunk\nnumber and chunk window size, while dynamically adjusting the context. Our\nmethod starts by retrieving the most relevant chunks and generates a single\ntoken as the potential answer. The probabilities of all options are then\nnormalized to serve as confidence scores, which guide the dynamic adjustment of\nthe context. By iteratively optimizing the hyperparameters based on these\nconfidence scores, we can continuously improve RAG performance. We conducted\nexperiments to validate the effectiveness of our framework, demonstrating its\npotential to enhance accuracy in domain-specific MCQA tasks.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在电信领域多选题问答（MCQA）中的检索质量和幻觉问题，提出了一种创新的 first token probability guided RAG 框架。该框架利用置信度分数优化关键超参数，如 chunk number 和 chunk window size，并动态调整上下文，从而提升检索和生成性能。具体方法包括先检索相关 chunks 生成单 token 潜在答案，然后归一化选项概率作为置信度分数，并基于此迭代优化超参数。实验结果显示，该框架显著提高了电信领域 MCQA 任务的准确率，证明了其在处理领域特定知识方面的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06468v1",
      "published_date": "2025-01-11 07:47:31 UTC",
      "updated_date": "2025-01-11 07:47:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:34:48.740007"
    },
    {
      "arxiv_id": "2501.06465v3",
      "title": "MedCT: A Clinical Terminology Graph for Generative AI Applications in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Ye Chen",
        "Dongdong Huang",
        "Haoyun Xu",
        "Cong Fu",
        "Lin Sheng",
        "Qingli Zhou",
        "Yuqiang Shen",
        "Kai Wang"
      ],
      "abstract": "We introduce the world's first clinical terminology for the Chinese\nhealthcare community, namely MedCT, accompanied by a clinical foundation model\nMedBERT and an entity linking model MedLink. The MedCT system enables\nstandardized and programmable representation of Chinese clinical data,\nsuccessively stimulating the development of new medicines, treatment pathways,\nand better patient outcomes for the populous Chinese community. Moreover, the\nMedCT knowledge graph provides a principled mechanism to minimize the\nhallucination problem of large language models (LLMs), therefore achieving\nsignificant levels of accuracy and safety in LLM-based clinical applications.\nBy leveraging the LLMs' emergent capabilities of generativeness and\nexpressiveness, we were able to rapidly built a production-quality terminology\nsystem and deployed to real-world clinical field within three months, while\nclassical terminologies like SNOMED CT have gone through more than twenty years\ndevelopment. Our experiments show that the MedCT system achieves\nstate-of-the-art (SOTA) performance in semantic matching and entity linking\ntasks, not only for Chinese but also for English. We also conducted a\nlongitudinal field experiment by applying MedCT and LLMs in a representative\nspectrum of clinical tasks, including electronic health record (EHR)\nauto-generation and medical document search for diagnostic decision making. Our\nstudy shows a multitude of values of MedCT for clinical workflows and patient\noutcomes, especially in the new genre of clinical LLM applications. We present\nour approach in sufficient engineering detail, such that implementing a\nclinical terminology for other non-English societies should be readily\nreproducible. We openly release our terminology, models and algorithms, along\nwith real-world clinical datasets for the development.",
      "tldr_zh": "本研究引入了MedCT，一种针对中国医疗社区的首个临床术语图谱，结合临床基础模型MedBERT和实体链接模型MedLink，实现中文临床数据的标准化表示，并通过知识图谱减少大型语言模型(LLMs)的幻觉问题，提高AI在医疗中的准确性和安全性。MedCT利用LLMs的生成和表达能力，仅用三个月就构建并部署了生产级系统，并在语义匹配和实体链接任务上达到SOTA性能，支持中文和英文。实验和现场应用显示，MedCT显著提升了电子健康记录(EHR)自动生成、医疗文档搜索等临床工作流程，并为患者结果带来多重价值；研究还开源了术语、模型、算法和数据集，促进全球非英语社区的复制。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted into ICCS 2025 and published in Springer's LNCS Series",
      "pdf_url": "http://arxiv.org/pdf/2501.06465v3",
      "published_date": "2025-01-11 07:35:51 UTC",
      "updated_date": "2025-04-10 07:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:35:01.286039"
    },
    {
      "arxiv_id": "2501.06461v1",
      "title": "Assessing instructor-AI cooperation for grading essay-type questions in an introductory sociology course",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Olivos",
        "Tobias Kamelski",
        "Sebastián Ascui-Gac"
      ],
      "abstract": "This study explores the use of artificial intelligence (AI) as a\ncomplementary tool for grading essay-type questions in higher education,\nfocusing on its consistency with human grading and potential to reduce biases.\nUsing 70 handwritten exams from an introductory sociology course, we evaluated\ngenerative pre-trained transformers (GPT) models' performance in transcribing\nand scoring students' responses. GPT models were tested under various settings\nfor both transcription and grading tasks. Results show high similarity between\nhuman and GPT transcriptions, with GPT-4o-mini outperforming GPT-4o in\naccuracy. For grading, GPT demonstrated strong correlations with the human\ngrader scores, especially when template answers were provided. However,\ndiscrepancies remained, highlighting GPT's role as a \"second grader\" to flag\ninconsistencies for assessment reviewing rather than fully replace human\nevaluation. This study contributes to the growing literature on AI in\neducation, demonstrating its potential to enhance fairness and efficiency in\ngrading essay-type questions.",
      "tldr_zh": "这篇论文评估了AI（特别是GPT模型）在高等教育中作为辅助工具评分作文型问题的效果，焦点在于AI与人类评分的一致性以及减少偏见潜力。研究使用70份手写社会学入门课程考试，测试了GPT模型在转录和评分任务中的表现，结果显示GPT-4o-mini在转录准确性上优于GPT-4o，且提供模板答案时评分与人类高度相关。论文强调GPT适合作为“第二评分者”来标记不一致性，而不是完全取代人类，从而提升评分的公平性和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.06461v1",
      "published_date": "2025-01-11 07:18:12 UTC",
      "updated_date": "2025-01-11 07:18:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:37:12.888979"
    },
    {
      "arxiv_id": "2501.06444v1",
      "title": "On the Computational Capability of Graph Neural Networks: A Circuit Complexity Bound Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyu Li",
        "Yingyu Liang",
        "Zhenmei Shi",
        "Zhao Song",
        "Wei Wang",
        "Jiahao Zhang"
      ],
      "abstract": "Graph Neural Networks (GNNs) have become the standard approach for learning\nand reasoning over relational data, leveraging the message-passing mechanism\nthat iteratively propagates node embeddings through graph structures. While\nGNNs have achieved significant empirical success, their theoretical limitations\nremain an active area of research. Existing studies primarily focus on\ncharacterizing GNN expressiveness through Weisfeiler-Lehman (WL) graph\nisomorphism tests. In this paper, we take a fundamentally different approach by\nexploring the computational limitations of GNNs through the lens of circuit\ncomplexity. Specifically, we analyze the circuit complexity of common GNN\narchitectures and prove that under constraints of constant-depth layers, linear\nor sublinear embedding sizes, and polynomial precision, GNNs cannot solve key\nproblems such as graph connectivity and graph isomorphism unless $\\mathsf{TC}^0\n= \\mathsf{NC}^1$. These results reveal the intrinsic expressivity limitations\nof GNNs behind their empirical success and introduce a novel framework for\nanalyzing GNN expressiveness that can be extended to a broader range of GNN\nmodels and graph decision problems.",
      "tldr_zh": "该论文从电路复杂度的角度探讨了图神经网络(GNNs)的计算能力，揭示其在处理关系数据时的内在限制。作者分析了常见GNN架构，证明在恒定深度层、线性或次线性嵌入大小以及多项式精度的条件下，GNNs无法解决图连通性和图同构等问题，除非\\(\\mathsf{TC}^0 = \\mathsf{NC}^1\\)。这些发现扩展了现有基于Weisfeiler-Lehman (WL)测试的研究框架，为评估GNN的表达能力和适用性提供了新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06444v1",
      "published_date": "2025-01-11 05:54:10 UTC",
      "updated_date": "2025-01-11 05:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:35:24.723485"
    },
    {
      "arxiv_id": "2501.06442v1",
      "title": "ARES: Auxiliary Range Expansion for Outlier Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Eui-Soo Jung",
        "Hae-Hun Seo",
        "Hyun-Woo Jung",
        "Je-Geon Oh",
        "Yoon-Yeong Kim"
      ],
      "abstract": "Recent successes of artificial intelligence and deep learning often depend on\nthe well-collected training dataset which is assumed to have an identical\ndistribution with the test dataset. However, this assumption, which is called\nclosed-set learning, is hard to meet in realistic scenarios for deploying deep\nlearning models. As one of the solutions to mitigate this assumption, research\non out-of-distribution (OOD) detection has been actively explored in various\ndomains. In OOD detection, we assume that we are given the data of a new class\nthat was not seen in the training phase, i.e., outlier, at the evaluation\nphase. The ultimate goal of OOD detection is to detect and classify such unseen\noutlier data as a novel \"unknown\" class. Among various research branches for\nOOD detection, generating a virtual outlier during the training phase has been\nproposed. However, conventional generation-based methodologies utilize\nin-distribution training dataset to imitate outlier instances, which limits the\nquality of the synthesized virtual outlier instance itself. In this paper, we\npropose a novel methodology for OOD detection named Auxiliary Range Expansion\nfor Outlier Synthesis, or ARES. ARES models the region for generating\nout-of-distribution instances by escaping from the given in-distribution\nregion; instead of remaining near the boundary of in-distribution region.\nVarious stages consists ARES to ultimately generate valuable OOD-like virtual\ninstances. The energy score-based discriminator is then trained to effectively\nseparate in-distribution data and outlier data. Quantitative experiments on\nbroad settings show the improvement of performance by our method, and\nqualitative results provide logical explanations of the mechanism behind it.",
      "tldr_zh": "该论文针对深度学习模型的闭集学习假设问题，提出了一种新的 OOD（Out-of-Distribution）检测方法 ARES（Auxiliary Range Expansion for Outlier Synthesis），旨在通过从 in-distribution 数据区域逃逸来生成高质量的虚拟异常实例，而不是局限于边界附近。ARES 包括多个阶段，利用辅助范围扩展技术合成有价值的 OOD-like 数据，并结合基于能量分数的鉴别器来有效区分 in-distribution 数据和异常数据。实验结果显示，该方法在各种设置下显著提高了 OOD 检测性能，并通过定量和定性分析提供了方法的逻辑解释。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06442v1",
      "published_date": "2025-01-11 05:44:33 UTC",
      "updated_date": "2025-01-11 05:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:35:36.433807"
    },
    {
      "arxiv_id": "2501.06434v1",
      "title": "Synthetic Feature Augmentation Improves Generalization Performance of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ashok Choudhary",
        "Cornelius Thiels",
        "Hojjat Salehinejad"
      ],
      "abstract": "Training and fine-tuning deep learning models, especially large language\nmodels (LLMs), on limited and imbalanced datasets poses substantial challenges.\nThese issues often result in poor generalization, where models overfit to\ndominant classes and underperform on minority classes, leading to biased\npredictions and reduced robustness in real-world applications. To overcome\nthese challenges, we propose augmenting features in the embedding space by\ngenerating synthetic samples using a range of techniques. By upsampling\nunderrepresented classes, this method improves model performance and alleviates\ndata imbalance. We validate the effectiveness of this approach across multiple\nopen-source text classification benchmarks, demonstrating its potential to\nenhance model robustness and generalization in imbalanced data scenarios.",
      "tldr_zh": "该论文探讨了在有限和不平衡数据集上训练大型语言模型（LLMs）时面临的泛化性能问题，导致模型过拟合主导类并在少数类上表现不佳。作者提出Synthetic Feature Augmentation方法，通过在嵌入空间生成合成样本并上采样 underrepresented classes，来缓解数据不平衡并提升模型性能。该方法在多个开源文本分类基准上得到验证，显著提高了模型的鲁棒性和泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for presentation at IEEE SSCI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.06434v1",
      "published_date": "2025-01-11 04:31:18 UTC",
      "updated_date": "2025-01-11 04:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:35:48.663232"
    },
    {
      "arxiv_id": "2501.06432v1",
      "title": "Deep Learning on Hester Davis Scores for Inpatient Fall Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hojjat Salehinejad",
        "Ricky Rojas",
        "Kingsley Iheasirim",
        "Mohammed Yousufuddin",
        "Bijan Borah"
      ],
      "abstract": "Fall risk prediction among hospitalized patients is a critical aspect of\npatient safety in clinical settings, and accurate models can help prevent\nadverse events. The Hester Davis Score (HDS) is commonly used to assess fall\nrisk, with current clinical practice relying on a threshold-based approach. In\nthis method, a patient is classified as high-risk when their HDS exceeds a\npredefined threshold. However, this approach may fail to capture dynamic\npatterns in fall risk over time. In this study, we model the threshold-based\napproach and propose two machine learning approaches for enhanced fall\nprediction: One-step ahead fall prediction and sequence-to-point fall\nprediction. The one-step ahead model uses the HDS at the current timestamp to\npredict the risk at the next timestamp, while the sequence-to-point model\nleverages all preceding HDS values to predict fall risk using deep learning. We\ncompare these approaches to assess their accuracy in fall risk prediction,\ndemonstrating that deep learning can outperform the traditional threshold-based\nmethod by capturing temporal patterns and improving prediction reliability.\nThese findings highlight the potential for data-driven approaches to enhance\npatient safety through more reliable fall prevention strategies.",
      "tldr_zh": "本研究针对住院患者跌倒风险预测，使用Hester Davis Score (HDS)作为评估指标，指出传统阈值-based方法可能忽略风险的动态模式。研究提出两种机器学习方法：One-step ahead fall prediction，利用当前HDS预测下一个时间点的风险；以及sequence-to-point fall prediction，通过深度学习整合所有前置HDS值来提升预测准确性。通过比较实验，结果显示深度学习方法比传统方法更有效地捕捉时间模式，提高了预测可靠性，并为患者安全策略提供了数据驱动的改进途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for presentation at IEEE SSCI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.06432v1",
      "published_date": "2025-01-11 04:20:13 UTC",
      "updated_date": "2025-01-11 04:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:38:00.306859"
    },
    {
      "arxiv_id": "2501.06431v1",
      "title": "Aug3D: Augmenting large scale outdoor datasets for Generalizable Novel View Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Rauniyar",
        "Omar Alama",
        "Silong Yong",
        "Katia Sycara",
        "Sebastian Scherer"
      ],
      "abstract": "Recent photorealistic Novel View Synthesis (NVS) advances have increasingly\ngained attention. However, these approaches remain constrained to small indoor\nscenes. While optimization-based NVS models have attempted to address this,\ngeneralizable feed-forward methods, offering significant advantages, remain\nunderexplored. In this work, we train PixelNeRF, a feed-forward NVS model, on\nthe large-scale UrbanScene3D dataset. We propose four training strategies to\ncluster and train on this dataset, highlighting that performance is hindered by\nlimited view overlap. To address this, we introduce Aug3D, an augmentation\ntechnique that leverages reconstructed scenes using traditional\nStructure-from-Motion (SfM). Aug3D generates well-conditioned novel views\nthrough grid and semantic sampling to enhance feed-forward NVS model learning.\nOur experiments reveal that reducing the number of views per cluster from 20 to\n10 improves PSNR by 10%, but the performance remains suboptimal. Aug3D further\naddresses this by combining the newly generated novel views with the original\ndataset, demonstrating its effectiveness in improving the model's ability to\npredict novel views.",
      "tldr_zh": "本文探讨了 Generalizable Novel View Synthesis (NVS) 在户外大场景中的挑战，训练 PixelNeRF 模型于 UrbanScene3D 数据集，并提出四种训练策略来处理视图重叠有限的问题。作者引入 Aug3D 增强技术，利用 Structure-from-Motion (SfM) 重建场景，通过网格和语义采样生成高质量新视图，从而提升 feed-forward NVS 模型的学习效果。实验显示，减少每个聚类视图数从20到10可提高 PSNR 10%，而结合 Aug3D 后，模型在预测新视图方面的性能进一步优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "IROS 2024 Workshop, 9 Pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06431v1",
      "published_date": "2025-01-11 04:13:26 UTC",
      "updated_date": "2025-01-11 04:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:36:13.816928"
    },
    {
      "arxiv_id": "2501.06425v3",
      "title": "Tensor Product Attention Is All You Need",
      "title_zh": "张量积注意力就是你所需要的全部",
      "authors": [
        "Yifan Zhang",
        "Yifeng Liu",
        "Huizhuo Yuan",
        "Zhen Qin",
        "Yang Yuan",
        "Quanquan Gu",
        "Andrew Chi-Chih Yao"
      ],
      "abstract": "Scaling language models to handle longer input sequences typically\nnecessitates large key-value (KV) caches, resulting in substantial memory\noverhead during inference. In this paper, we propose Tensor Product Attention\n(TPA), a novel attention mechanism that uses tensor decompositions to represent\nqueries, keys, and values compactly, significantly shrinking KV cache size at\ninference time. By factorizing these representations into contextual low-rank\ncomponents (contextual factorization) and seamlessly integrating with RoPE, TPA\nachieves improved model quality alongside memory efficiency. Based on TPA, we\nintroduce the Tensor ProducT ATTenTion Transformer (T6), a new model\narchitecture for sequence modeling. Through extensive empirical evaluation of\nlanguage modeling tasks, we demonstrate that T6 exceeds the performance of\nstandard Transformer baselines including MHA, MQA, GQA, and MLA across various\nmetrics, including perplexity and a range of renowned evaluation benchmarks.\nNotably, TPA's memory efficiency enables the processing of significantly longer\nsequences under fixed resource constraints, addressing a critical scalability\nchallenge in modern language models. The code is available at\nhttps://github.com/tensorgi/T6.",
      "tldr_zh": "该论文提出了一种名为 Tensor Product Attention (TPA) 的新注意力机制，通过张量分解来紧凑表示查询、键和值，从而显著减少语言模型推理时的 KV 缓存内存开销。TPA 结合上下文低秩组件（contextual factorization）和 RoPE 的无缝集成，构建了新的模型架构 Tensor Product ATTenTion Transformer (T6)，用于序列建模。实验结果显示，T6 在语言建模任务中超越标准 Transformer 基线（如 MHA、MQA、GQA 和 MLA），在困惑度和各种基准上表现出色，同时其内存效率支持处理更长序列，解决了现代语言模型的可伸缩性挑战。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "31 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06425v3",
      "published_date": "2025-01-11 03:37:10 UTC",
      "updated_date": "2025-04-09 20:51:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:36:24.533988"
    },
    {
      "arxiv_id": "2501.06423v1",
      "title": "AlgoPilot: Fully Autonomous Program Synthesis Without Human-Written Programs",
      "title_zh": "AlgoPilot：完全自治的程序合成，无需人类编写的程序",
      "authors": [
        "Xiaoxin Yin"
      ],
      "abstract": "Program synthesis has traditionally relied on human-provided specifications,\nexamples, or prior knowledge to generate functional algorithms. Existing\nmethods either emulate human-written algorithms or solve specific tasks without\ngenerating reusable programmatic logic, limiting their ability to create novel\nalgorithms. We introduce AlgoPilot, a groundbreaking approach for fully\nautomated program synthesis without human-written programs or trajectories.\nAlgoPilot leverages reinforcement learning (RL) guided by a Trajectory Language\nModel (TLM) to synthesize algorithms from scratch. The TLM, trained on\ntrajectories generated by random Python functions, serves as a soft constraint\nduring the RL process, aligning generated sequences with patterns likely to\nrepresent valid algorithms. Using sorting as a test case, AlgoPilot\ndemonstrates its ability to generate trajectories that are interpretable as\nclassical algorithms, such as Bubble Sort, while operating without prior\nalgorithmic knowledge. This work establishes a new paradigm for algorithm\ndiscovery and lays the groundwork for future advancements in autonomous program\nsynthesis.",
      "tldr_zh": "本文提出 AlgoPilot，一种无需人类编写程序或轨迹的全自动程序合成方法，旨在克服传统方法对先验知识的依赖。AlgoPilot 通过强化学习 (RL) 结合 Trajectory Language Model (TLM) 从零开始生成算法，其中 TLM 基于随机 Python 函数生成的轨迹作为软约束，确保输出序列符合有效算法模式。以排序为例，该方法成功生成了可解释为 Bubble Sort 的经典算法，并为算法发现和自主程序合成开辟了新范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06423v1",
      "published_date": "2025-01-11 03:29:14 UTC",
      "updated_date": "2025-01-11 03:29:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:36:36.531936"
    },
    {
      "arxiv_id": "2501.06417v1",
      "title": "DiscQuant: A Quantization Method for Neural Networks Inspired by Discrepancy Theory",
      "title_zh": "DiscQuant: 一种受Discrepancy Theory启发的神经网络量化方法",
      "authors": [
        "Jerry Chee",
        "Arturs Backurs",
        "Rainie Heck",
        "Li Zhang",
        "Janardhan Kulkarni",
        "Thomas Rothvoss",
        "Sivakanth Gopi"
      ],
      "abstract": "Quantizing the weights of a neural network has two steps: (1) Finding a good\nlow bit-complexity representation for weights (which we call the quantization\ngrid) and (2) Rounding the original weights to values in the quantization grid.\nIn this paper, we study the problem of rounding optimally given any\nquantization grid. The simplest and most commonly used way to round is\nRound-to-Nearest (RTN). By rounding in a data-dependent way instead, one can\nimprove the quality of the quantized model significantly.\n  We study the rounding problem from the lens of \\emph{discrepancy theory},\nwhich studies how well we can round a continuous solution to a discrete\nsolution without affecting solution quality too much. We prove that given\n$m=\\mathrm{poly}(1/\\epsilon)$ samples from the data distribution, we can round\nall but $O(m)$ model weights such that the expected approximation error of the\nquantized model on the true data distribution is $\\le \\epsilon$ as long as the\nspace of gradients of the original model is approximately low rank (which we\nempirically validate).\n  Our proof, which is algorithmic, inspired a simple and practical rounding\nalgorithm called \\emph{DiscQuant}. In our experiments, we demonstrate that\nDiscQuant significantly improves over the prior state-of-the-art rounding\nmethod called GPTQ and the baseline RTN over a range of benchmarks on\nPhi3mini-3.8B and Llama3.1-8B. For example, rounding Phi3mini-3.8B to a fixed\nquantization grid with 3.25 bits per parameter using DiscQuant gets 64\\%\naccuracy on the GSM8k dataset, whereas GPTQ achieves 54\\% and RTN achieves 31\\%\n(the original model achieves 84\\%). We make our code available at\nhttps://github.com/jerry-chee/DiscQuant.",
      "tldr_zh": "本研究提出了一种神经网络量化方法DiscQuant，灵感来源于Discrepancy Theory，用于优化权重舍入过程，以减少量化模型的近似误差。不同于传统的Round-to-Nearest (RTN)方法，DiscQuant通过数据依赖的舍入策略，并在给定样本条件下证明了其有效性，确保量化模型在梯度空间低秩假设下实现较低误差。实验结果显示，DiscQuant在Phi3mini-3.8B和Llama3.1-8B模型上显著优于GPTQ和RTN基准，例如在GSM8k数据集上，DiscQuant实现了64%的准确率，而GPTQ为54%、RTN仅为31%。这项工作为高效神经网络量化提供了实用算法，并开源代码以便进一步应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06417v1",
      "published_date": "2025-01-11 03:14:43 UTC",
      "updated_date": "2025-01-11 03:14:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:36:48.829440"
    },
    {
      "arxiv_id": "2501.06416v2",
      "title": "Influencing Humans to Conform to Preference Models for RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Stephane Hatgis-Kessell",
        "W. Bradley Knox",
        "Serena Booth",
        "Scott Niekum",
        "Peter Stone"
      ],
      "abstract": "Designing a reinforcement learning from human feedback (RLHF) algorithm to\napproximate a human's unobservable reward function requires assuming,\nimplicitly or explicitly, a model of human preferences. A preference model that\npoorly describes how humans generate preferences risks learning a poor\napproximation of the human's reward function. In this paper, we conduct three\nhuman studies to asses whether one can influence the expression of real human\npreferences to more closely conform to a desired preference model. Importantly,\nour approach does not seek to alter the human's unobserved reward function.\nRather, we change how humans use this reward function to generate preferences,\nsuch that they better match whatever preference model is assumed by a\nparticular RLHF algorithm. We introduce three interventions: showing humans the\nquantities that underlie a preference model, which is normally unobservable\ninformation derived from the reward function; training people to follow a\nspecific preference model; and modifying the preference elicitation question.\nAll intervention types show significant effects, providing practical tools to\nimprove preference data quality and the resultant alignment of the learned\nreward functions. Overall we establish a novel research direction in model\nalignment: designing interfaces and training interventions to increase human\nconformance with the modeling assumptions of the algorithm that will learn from\ntheir input.",
      "tldr_zh": "本文研究如何通过干预措施影响人类偏好表达，使其更符合RLHF（强化学习从人类反馈）算法的偏好模型，从而提升学习到的奖励函数的准确性。作者开展了三个人类研究，包括展示偏好模型的底层量（通常不可观察）、训练人们遵循特定偏好模型，以及修改偏好收集问题，这些干预均显示出显著效果。总体上，该工作提供了实用工具来改善偏好数据质量和模型alignment，并开辟了新研究方向，即设计界面和训练干预以增强人类对算法假设的符合度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06416v2",
      "published_date": "2025-01-11 03:12:53 UTC",
      "updated_date": "2025-02-08 05:44:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:37:00.554834"
    },
    {
      "arxiv_id": "2501.14794v1",
      "title": "HeteroLLM: Accelerating Large Language Model Inference on Mobile SoCs platform with Heterogeneous AI Accelerators",
      "title_zh": "翻译失败",
      "authors": [
        "Le Chen",
        "Dahu Feng",
        "Erhu Feng",
        "Rong Zhao",
        "Yingrui Wang",
        "Yubin Xia",
        "Haibo Chen",
        "Pinjie Xu"
      ],
      "abstract": "With the rapid advancement of artificial intelligence technologies such as\nChatGPT, AI agents and video generation,contemporary mobile systems have begun\nintegrating these AI capabilities on local devices to enhance privacy and\nreduce response latency. To meet the computational demands of AI tasks, current\nmobile SoCs are equipped with diverse AI accelerators, including GPUs and\nNeural Processing Units (NPUs). However, there has not been a comprehensive\ncharacterization of these heterogeneous processors, and existing designs\ntypically only leverage a single AI accelerator for LLM inference, leading to\nsuboptimal use of computational resources and memory bandwidth. In this paper,\nwe first summarize key performance characteristics of mobile SoC, including\nheterogeneous processors, unified memory, synchronization, etc. Drawing on\nthese observations, we propose different tensor partition strategies to fulfill\nthe distinct requirements of the prefill and decoding phases. We further design\na fast synchronization mechanism that leverages the unified memory address\nprovided by mobile SoCs. By employing these techniques, we present HeteroLLM,\nthe fastest LLM inference engine in mobile devices which supports both\nlayer-level and tensor-level heterogeneous execution. Evaluation results show\nthat HeteroLLM achieves 9.99 and 4.36 performance improvement over other\nmobile-side LLM inference engines: MLC and MNN.",
      "tldr_zh": "该研究针对移动 SoC 平台上的 Large Language Model (LLM) 推理问题，提出 HeteroLLM 框架，利用异构 AI 加速器（如 GPU 和 Neural Processing Units (NPUs)）来优化计算资源和内存带宽利用。\nHeteroLLM 通过总结移动 SoC 的关键性能特征（如异构处理器和统一内存）、设计不同的张量分区策略以及快速同步机制，支持预填充和解码阶段的异构执行。\n实验结果表明，HeteroLLM 相较于现有引擎 MLC 和 MNN，分别实现了 9.99 和 4.36 倍的性能提升，为高效的移动端 AI 应用奠定了基础。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.14794v1",
      "published_date": "2025-01-11 02:42:02 UTC",
      "updated_date": "2025-01-11 02:42:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:38:12.781254"
    },
    {
      "arxiv_id": "2501.06405v1",
      "title": "FocusDD: Real-World Scene Infusion for Robust Dataset Distillation",
      "title_zh": "FocusDD：真实世界场景注入用于稳健数据集蒸馏",
      "authors": [
        "Youbing Hu",
        "Yun Cheng",
        "Olga Saukh",
        "Firat Ozdemir",
        "Anqi Lu",
        "Zhiqiang Cao",
        "Zhijun Li"
      ],
      "abstract": "Dataset distillation has emerged as a strategy to compress real-world\ndatasets for efficient training. However, it struggles with large-scale and\nhigh-resolution datasets, limiting its practicality. This paper introduces a\nnovel resolution-independent dataset distillation method Focus ed Dataset\nDistillation (FocusDD), which achieves diversity and realism in distilled data\nby identifying key information patches, thereby ensuring the generalization\ncapability of the distilled dataset across different network architectures.\nSpecifically, FocusDD leverages a pre-trained Vision Transformer (ViT) to\nextract key image patches, which are then synthesized into a single distilled\nimage. These distilled images, which capture multiple targets, are suitable not\nonly for classification tasks but also for dense tasks such as object\ndetection. To further improve the generalization of the distilled dataset, each\nsynthesized image is augmented with a downsampled view of the original image.\nExperimental results on the ImageNet-1K dataset demonstrate that, with 100\nimages per class (IPC), ResNet50 and MobileNet-v2 achieve validation accuracies\nof 71.0% and 62.6%, respectively, outperforming state-of-the-art methods by\n2.8% and 4.7%. Notably, FocusDD is the first method to use distilled datasets\nfor object detection tasks. On the COCO2017 dataset, with an IPC of 50,\nYOLOv11n and YOLOv11s achieve 24.4% and 32.1% mAP, respectively, further\nvalidating the effectiveness of our approach.",
      "tldr_zh": "本论文提出了一种新的数据集蒸馏方法FocusDD，通过注入真实场景信息来提升蒸馏数据的多样性和鲁棒性，从而解决大规模、高分辨率数据集的训练挑战。该方法利用预训练的Vision Transformer (ViT)提取关键图像patches，并将它们合成成单一蒸馏图像，同时通过添加原图像的降采样视图来增强泛化能力，使其适用于分类任务和密集任务如物体检测。实验结果显示，在ImageNet-1K数据集上，使用100 images per class (IPC)，ResNet50和MobileNet-v2的验证准确率分别达到71.0%和62.6%，比最先进方法高出2.8%和4.7%；在COCO2017数据集上，使用50 IPC，YOLOv11n和YOLOv11s的mAP分别达到24.4%和32.1%，这是首个应用于物体检测任务的蒸馏数据集方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06405v1",
      "published_date": "2025-01-11 02:06:29 UTC",
      "updated_date": "2025-01-11 02:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:40:25.354107"
    },
    {
      "arxiv_id": "2501.06404v1",
      "title": "A Hybrid Framework for Reinsurance Optimization: Integrating Generative Models and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Stella C. Dong",
        "James R. Finlay"
      ],
      "abstract": "Reinsurance optimization is critical for insurers to manage risk exposure,\nensure financial stability, and maintain solvency. Traditional approaches often\nstruggle with dynamic claim distributions, high-dimensional constraints, and\nevolving market conditions. This paper introduces a novel hybrid framework that\nintegrates {Generative Models}, specifically Variational Autoencoders (VAEs),\nwith {Reinforcement Learning (RL)} using Proximal Policy Optimization (PPO).\nThe framework enables dynamic and scalable optimization of reinsurance\nstrategies by combining the generative modeling of complex claim distributions\nwith the adaptive decision-making capabilities of reinforcement learning.\n  The VAE component generates synthetic claims, including rare and catastrophic\nevents, addressing data scarcity and variability, while the PPO algorithm\ndynamically adjusts reinsurance parameters to maximize surplus and minimize\nruin probability. The framework's performance is validated through extensive\nexperiments, including out-of-sample testing, stress-testing scenarios (e.g.,\npandemic impacts, catastrophic events), and scalability analysis across\nportfolio sizes. Results demonstrate its superior adaptability, scalability,\nand robustness compared to traditional optimization techniques, achieving\nhigher final surpluses and computational efficiency.\n  Key contributions include the development of a hybrid approach for\nhigh-dimensional optimization, dynamic reinsurance parameterization, and\nvalidation against stochastic claim distributions. The proposed framework\noffers a transformative solution for modern reinsurance challenges, with\npotential applications in multi-line insurance operations, catastrophe\nmodeling, and risk-sharing strategy design.",
      "tldr_zh": "该论文提出了一种混合框架，用于再保险优化，将生成模型（特别是 Variational Autoencoders, VAEs）与强化学习（Reinforcement Learning, RL）中的 Proximal Policy Optimization (PPO) 相结合，以应对动态索赔分布、高维约束和市场变化的挑战。VAEs 用于生成合成索赔数据，包括稀有和灾难性事件，从而解决数据稀缺问题，而 PPO 算法则动态调整再保险参数，以最大化盈余并最小化破产概率。通过广泛实验验证，包括样本外测试和压力场景（如疫情影响），该框架展示了比传统方法更高的适应性、可扩展性和鲁棒性，实现了更高的最终盈余和计算效率。关键贡献在于开发高维优化的混合方法和动态再保险参数化，为多线保险运营、灾难建模和风险共享策略提供潜在应用。",
      "categories": [
        "econ.EM",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "econ.EM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06404v1",
      "published_date": "2025-01-11 02:02:32 UTC",
      "updated_date": "2025-01-11 02:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:38:36.483054"
    },
    {
      "arxiv_id": "2501.06399v1",
      "title": "Has an AI model been trained on your images?",
      "title_zh": "翻译失败",
      "authors": [
        "Matyas Bohacek",
        "Hany Farid"
      ],
      "abstract": "From a simple text prompt, generative-AI image models can create stunningly\nrealistic and creative images bounded, it seems, by only our imagination. These\nmodels have achieved this remarkable feat thanks, in part, to the ingestion of\nbillions of images collected from nearly every corner of the internet. Many\ncreators have understandably expressed concern over how their intellectual\nproperty has been ingested without their permission or a mechanism to opt out\nof training. As a result, questions of fair use and copyright infringement have\nquickly emerged. We describe a method that allows us to determine if a model\nwas trained on a specific image or set of images. This method is\ncomputationally efficient and assumes no explicit knowledge of the model\narchitecture or weights (so-called black-box membership inference). We\nanticipate that this method will be crucial for auditing existing models and,\nlooking ahead, ensuring the fairer development and deployment of generative AI\nmodels.",
      "tldr_zh": "这篇论文探讨了生成式 AI 图像模型在训练中使用未经授权图像的问题，导致版权侵权和公平使用争议。作者提出了一种计算高效的黑箱成员推理方法，能够检测特定图像是否被用于训练模型，而无需了解模型的架构或权重。该方法有助于审计现有 AI 模型，并推动更公平的生成式 AI 开发和部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06399v1",
      "published_date": "2025-01-11 01:12:23 UTC",
      "updated_date": "2025-01-11 01:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:38:46.891888"
    },
    {
      "arxiv_id": "2501.06394v1",
      "title": "Unispeaker: A Unified Approach for Multimodality-driven Speaker Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhengyan Sheng",
        "Zhihao Du",
        "Heng Lu",
        "Shiliang Zhang",
        "Zhen-Hua Ling"
      ],
      "abstract": "Recent advancements in personalized speech generation have brought synthetic\nspeech increasingly close to the realism of target speakers' recordings, yet\nmultimodal speaker generation remains on the rise. This paper introduces\nUniSpeaker, a unified approach for multimodality-driven speaker generation.\nSpecifically, we propose a unified voice aggregator based on KV-Former,\napplying soft contrastive loss to map diverse voice description modalities into\na shared voice space, ensuring that the generated voice aligns more closely\nwith the input descriptions. To evaluate multimodality-driven voice control, we\nbuild the first multimodality-based voice control (MVC) benchmark, focusing on\nvoice suitability, voice diversity, and speech quality. UniSpeaker is evaluated\nacross five tasks using the MVC benchmark, and the experimental results\ndemonstrate that UniSpeaker outperforms previous modality-specific models.\nSpeech samples are available at \\url{https://UniSpeaker.github.io}.",
      "tldr_zh": "本文提出 UniSpeaker，一种统一的处理多模态驱动说话者生成的方法，旨在提升语音生成与输入描述的精确匹配。UniSpeaker 采用基于 KV-Former 的语音聚合器，并应用 soft contrastive loss 将不同语音描述模态映射到共享语音空间。研究者构建了首个多模态驱动语音控制 (MVC) 基准，评估语音适用性、语音多样性和语音质量。在五个任务上的实验结果表明，UniSpeaker 优于之前的模态特定模型，相关语音样本可通过指定链接访问。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06394v1",
      "published_date": "2025-01-11 00:47:29 UTC",
      "updated_date": "2025-01-11 00:47:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:38:59.285043"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 45,
  "processed_papers_count": 45,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T22:40:40.296710"
}