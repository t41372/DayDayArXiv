[
  {
    "arxiv_id": "2504.15485v1",
    "title": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting",
    "authors": [
      "Atin Pothiraj",
      "Elias Stengel-Eskin",
      "Jaemin Cho",
      "Mohit Bansal"
    ],
    "abstract": "Recognizing and reasoning about occluded (partially or fully hidden) objects\nis vital to understanding visual scenes, as occlusions frequently occur in\nreal-world environments and act as obstacles for spatial comprehension. To test\nmodels' ability to reason about multiple occluded objects, we introduce a novel\ntask, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which\nrequires a model to count objects arranged in a pattern by inferring how the\npattern continues behind an occluder (an object which blocks parts of the\nscene). CAPTURe requires both recognizing visual patterns and reasoning, making\nit a useful testbed for evaluating vision-language models (VLMs) on whether\nthey understand occluded patterns and possess spatial understanding skills. By\nrequiring models to reason about occluded objects, CAPTURe also tests VLMs'\nability to form world models that would allow them to fill in missing\ninformation. CAPTURe consists of two parts: (1) CAPTURe-real, with manually\nfiltered images of real objects in patterns and (2) CAPTURe-synthetic, a\ncontrolled diagnostic with generated patterned images. We evaluate four strong\nVLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models\nstruggle to count on both occluded and unoccluded patterns. Crucially, we find\nthat models perform worse with occlusion, suggesting that VLMs are also\ndeficient in inferring unseen spatial relationships: even the strongest VLMs\nlike GPT-4o fail to count with occlusion. In contrast, we find that humans\nachieve very little error on CAPTURe. We also find that providing auxiliary\ninformation of occluded object locations increases performance, underscoring\nthat the model error comes both from an inability to handle occlusion as well\nas difficulty counting in images.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Code and data: https://github.com/atinpothiraj/CAPTURe",
    "pdf_url": "http://arxiv.org/pdf/2504.15485v1",
    "published_date": "2025-04-21 23:38:43 UTC",
    "updated_date": "2025-04-21 23:38:43 UTC"
  },
  {
    "arxiv_id": "2504.16138v1",
    "title": "Trends in Frontier AI Model Count: A Forecast to 2028",
    "authors": [
      "Iyngkarran Kumar",
      "Sam Manning"
    ],
    "abstract": "Governments are starting to impose requirements on AI models based on how\nmuch compute was used to train them. For example, the EU AI Act imposes\nrequirements on providers of general-purpose AI with systemic risk, which\nincludes systems trained using greater than $10^{25}$ floating point operations\n(FLOP). In the United States' AI Diffusion Framework, a training compute\nthreshold of $10^{26}$ FLOP is used to identify \"controlled models\" which face\na number of requirements. We explore how many models such training compute\nthresholds will capture over time. We estimate that by the end of 2028, there\nwill be between 103-306 foundation models exceeding the $10^{25}$ FLOP\nthreshold put forward in the EU AI Act (90% CI), and 45-148 models exceeding\nthe $10^{26}$ FLOP threshold that defines controlled models in the AI Diffusion\nFramework (90% CI). We also find that the number of models exceeding these\nabsolute compute thresholds each year will increase superlinearly -- that is,\neach successive year will see more new models captured within the threshold\nthan the year before. Thresholds that are defined with respect to the largest\ntraining run to date (for example, such that all models within one order of\nmagnitude of the largest training run to date are captured by the threshold)\nsee a more stable trend, with a median forecast of 14-16 models being captured\nby this definition annually from 2025-2028.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16138v1",
    "published_date": "2025-04-21 22:31:57 UTC",
    "updated_date": "2025-04-21 22:31:57 UTC"
  },
  {
    "arxiv_id": "2504.15466v1",
    "title": "Learning Adaptive Parallel Reasoning with Language Models",
    "authors": [
      "Jiayi Pan",
      "Xiuyu Li",
      "Long Lian",
      "Charlie Snell",
      "Yifei Zhou",
      "Adam Yala",
      "Trevor Darrell",
      "Kurt Keutzer",
      "Alane Suhr"
    ],
    "abstract": "Scaling inference-time computation has substantially improved the reasoning\ncapabilities of language models. However, existing methods have significant\nlimitations: serialized chain-of-thought approaches generate overly long\noutputs, leading to increased latency and exhausted context windows, while\nparallel methods such as self-consistency suffer from insufficient\ncoordination, resulting in redundant computations and limited performance\ngains. To address these shortcomings, we propose Adaptive Parallel Reasoning\n(APR), a novel reasoning framework that enables language models to orchestrate\nboth serialized and parallel computations end-to-end. APR generalizes existing\nreasoning methods by enabling adaptive multi-threaded inference using spawn()\nand join() operations. A key innovation is our end-to-end reinforcement\nlearning strategy, optimizing both parent and child inference threads to\nenhance task success rate without requiring predefined reasoning structures.\nExperiments on the Countdown reasoning task demonstrate significant benefits of\nAPR: (1) higher performance within the same context window (83.4% vs. 60.0% at\n4k context); (2) superior scalability with increased computation (80.1% vs.\n66.6% at 20k total tokens); (3) improved accuracy at equivalent latency (75.2%\nvs. 57.3% at approximately 5,000ms). APR represents a step towards enabling\nlanguage models to autonomously optimize their reasoning processes through\nadaptive allocation of computation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Code, model, and data are available at\n  https://github.com/Parallel-Reasoning/APR. The first three authors\n  contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2504.15466v1",
    "published_date": "2025-04-21 22:29:02 UTC",
    "updated_date": "2025-04-21 22:29:02 UTC"
  },
  {
    "arxiv_id": "2504.15457v2",
    "title": "Improving Human-AI Coordination through Adversarial Training and Generative Models",
    "authors": [
      "Paresh Chaudhary",
      "Yancheng Liang",
      "Daphne Chen",
      "Simon S. Du",
      "Natasha Jaques"
    ],
    "abstract": "Being able to cooperate with new people is an important component of many\neconomically valuable AI tasks, from household robotics to autonomous driving.\nHowever, generalizing to novel humans requires training on data that captures\nthe diversity of human behaviors. Adversarial training is one avenue for\nsearching for such data and ensuring that agents are robust. However, it is\ndifficult to apply in the cooperative setting because adversarial policies\nintentionally learn to sabotage the task instead of simulating valid\ncooperation partners. To address this challenge, we propose a novel strategy\nfor overcoming self-sabotage that combines a pre-trained generative model to\nsimulate valid cooperative agent policies with adversarial training to maximize\nregret. We call our method GOAT: Generative Online Adversarial Training. In\nthis framework, the GOAT dynamically searches for and generates coordination\nstrategies where the learning policy -- the Cooperator agent -- underperforms.\nGOAT enables better generalization by exposing the Cooperator to various\nchallenging interaction scenarios. We maintain realistic coordination\nstrategies by updating only the generative model's embedding while keeping its\nparameters frozen, thus avoiding adversarial exploitation. We evaluate GOAT\nwith real human partners, and the results demonstrate state-of-the-art\nperformance on the Overcooked benchmark, highlighting its effectiveness in\ngeneralizing to diverse human behaviors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15457v2",
    "published_date": "2025-04-21 21:53:00 UTC",
    "updated_date": "2025-04-29 21:02:02 UTC"
  },
  {
    "arxiv_id": "2505.00012v1",
    "title": "The AI Co-Ethnographer: How Far Can Automation Take Qualitative Research?",
    "authors": [
      "Fabian Retkowski",
      "Andreas Sudmann",
      "Alexander Waibel"
    ],
    "abstract": "Qualitative research often involves labor-intensive processes that are\ndifficult to scale while preserving analytical depth. This paper introduces The\nAI Co-Ethnographer (AICoE), a novel end-to-end pipeline developed for\nqualitative research and designed to move beyond the limitations of simply\nautomating code assignments, offering a more integrated approach. AICoE\norganizes the entire process, encompassing open coding, code consolidation,\ncode application, and even pattern discovery, leading to a comprehensive\nanalysis of qualitative data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NLP4DH 2025",
    "pdf_url": "http://arxiv.org/pdf/2505.00012v1",
    "published_date": "2025-04-21 21:31:28 UTC",
    "updated_date": "2025-04-21 21:31:28 UTC"
  },
  {
    "arxiv_id": "2504.16948v1",
    "title": "Intrinsic Barriers to Explaining Deep Foundation Models",
    "authors": [
      "Zhen Tan",
      "Huan Liu"
    ],
    "abstract": "Deep Foundation Models (DFMs) offer unprecedented capabilities but their\nincreasing complexity presents profound challenges to understanding their\ninternal workings-a critical need for ensuring trust, safety, and\naccountability. As we grapple with explaining these systems, a fundamental\nquestion emerges: Are the difficulties we face merely temporary hurdles,\nawaiting more sophisticated analytical techniques, or do they stem from\n\\emph{intrinsic barriers} deeply rooted in the nature of these large-scale\nmodels themselves? This paper delves into this critical question by examining\nthe fundamental characteristics of DFMs and scrutinizing the limitations\nencountered by current explainability methods when confronted with this\ninherent challenge. We probe the feasibility of achieving satisfactory\nexplanations and consider the implications for how we must approach the\nverification and governance of these powerful technologies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16948v1",
    "published_date": "2025-04-21 21:19:23 UTC",
    "updated_date": "2025-04-21 21:19:23 UTC"
  },
  {
    "arxiv_id": "2504.15440v1",
    "title": "Demand for LLMs: Descriptive Evidence on Substitution, Market Expansion, and Multihoming",
    "authors": [
      "Andrey Fradkin"
    ],
    "abstract": "This paper documents three stylized facts about the demand for Large Language\nModels (LLMs) using data from OpenRouter, a prominent LLM marketplace. First,\nnew models experience rapid initial adoption that stabilizes within weeks.\nSecond, model releases differ substantially in whether they primarily attract\nnew users or substitute demand from competing models. Third, multihoming, using\nmultiple models simultaneously, is common among apps. These findings suggest\nsignificant horizontal and vertical differentiation in the LLM market, implying\nopportunities for providers to maintain demand and pricing power despite rapid\ntechnological advances.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "econ.GN",
      "q-fin.EC",
      "K.4; I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15440v1",
    "published_date": "2025-04-21 21:12:28 UTC",
    "updated_date": "2025-04-21 21:12:28 UTC"
  },
  {
    "arxiv_id": "2504.15434v1",
    "title": "AGI Is Coming... Right After AI Learns to Play Wordle",
    "authors": [
      "Sarath Shekkizhar",
      "Romain Cosentino"
    ],
    "abstract": "This paper investigates multimodal agents, in particular, OpenAI's\nComputer-User Agent (CUA), trained to control and complete tasks through a\nstandard computer interface, similar to humans. We evaluated the agent's\nperformance on the New York Times Wordle game to elicit model behaviors and\nidentify shortcomings. Our findings revealed a significant discrepancy in the\nmodel's ability to recognize colors correctly depending on the context. The\nmodel had a $5.36\\%$ success rate over several hundred runs across a week of\nWordle. Despite the immense enthusiasm surrounding AI agents and their\npotential to usher in Artificial General Intelligence (AGI), our findings\nreinforce the fact that even simple tasks present substantial challenges for\ntoday's frontier AI models. We conclude with a discussion of the potential\nunderlying causes, implications for future development, and research directions\nto improve these AI systems.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15434v1",
    "published_date": "2025-04-21 20:58:58 UTC",
    "updated_date": "2025-04-21 20:58:58 UTC"
  },
  {
    "arxiv_id": "2504.15431v1",
    "title": "Trillion 7B Technical Report",
    "authors": [
      "Sungjun Han",
      "Juyoung Suk",
      "Suyeong An",
      "Hyungguk Kim",
      "Kyuseok Kim",
      "Wonsuk Yang",
      "Seungtaek Choi",
      "Jamin Shin"
    ],
    "abstract": "We introduce Trillion-7B, the most token-efficient Korean-centric\nmultilingual LLM available. Our novel Cross-lingual Document Attention (XLDA)\nmechanism enables highly efficient and effective knowledge transfer from\nEnglish to target languages like Korean and Japanese. Combined with optimized\ndata mixtures, language-specific filtering, and tailored tokenizer\nconstruction, Trillion-7B achieves competitive performance while dedicating\nonly 10\\% of its 2T training tokens to multilingual data and requiring just\n59.4K H100 GPU hours (\\$148K) for full training. Comprehensive evaluations\nacross 27 benchmarks in four languages demonstrate Trillion-7B's robust\nmultilingual performance and exceptional cross-lingual consistency.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preview version",
    "pdf_url": "http://arxiv.org/pdf/2504.15431v1",
    "published_date": "2025-04-21 20:54:44 UTC",
    "updated_date": "2025-04-21 20:54:44 UTC"
  },
  {
    "arxiv_id": "2504.15425v1",
    "title": "Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL",
    "authors": [
      "Songyuan Zhang",
      "Oswin So",
      "Mitchell Black",
      "Zachary Serlin",
      "Chuchu Fan"
    ],
    "abstract": "Tasks for multi-robot systems often require the robots to collaborate and\ncomplete a team goal while maintaining safety. This problem is usually\nformalized as a constrained Markov decision process (CMDP), which targets\nminimizing a global cost and bringing the mean of constraint violation below a\nuser-defined threshold. Inspired by real-world robotic applications, we define\nsafety as zero constraint violation. While many safe multi-agent reinforcement\nlearning (MARL) algorithms have been proposed to solve CMDPs, these algorithms\nsuffer from unstable training in this setting. To tackle this, we use the\nepigraph form for constrained optimization to improve training stability and\nprove that the centralized epigraph form problem can be solved in a distributed\nfashion by each agent. This results in a novel centralized training distributed\nexecution MARL algorithm named Def-MARL. Simulation experiments on 8 different\ntasks across 2 different simulators show that Def-MARL achieves the best\noverall performance, satisfies safety constraints, and maintains stable\ntraining. Real-world hardware experiments on Crazyflie quadcopters demonstrate\nthe ability of Def-MARL to safely coordinate agents to complete complex\ncollaborative tasks compared to other methods.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "cs.MA",
      "math.OC"
    ],
    "primary_category": "cs.RO",
    "comment": "28 pages, 16 figures; Accepted by Robotics: Science and Systems 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15425v1",
    "published_date": "2025-04-21 20:34:55 UTC",
    "updated_date": "2025-04-21 20:34:55 UTC"
  },
  {
    "arxiv_id": "2504.15424v1",
    "title": "LLM-Assisted Translation of Legacy FORTRAN Codes to C++: A Cross-Platform Study",
    "authors": [
      "Nishath Rajiv Ranasinghe",
      "Shawn M. Jones",
      "Michal Kucer",
      "Ayan Biswas",
      "Daniel O'Malley",
      "Alexander Buschmann Most",
      "Selma Liliane Wanna",
      "Ajay Sreekumar"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly being leveraged for generating\nand translating scientific computer codes by both domain-experts and non-domain\nexperts. Fortran has served as one of the go to programming languages in legacy\nhigh-performance computing (HPC) for scientific discoveries. Despite growing\nadoption, LLM-based code translation of legacy code-bases has not been\nthoroughly assessed or quantified for its usability. Here, we studied the\napplicability of LLM-based translation of Fortran to C++ as a step towards\nbuilding an agentic-workflow using open-weight LLMs on two different\ncomputational platforms. We statistically quantified the compilation accuracy\nof the translated C++ codes, measured the similarity of the LLM translated code\nto the human translated C++ code, and statistically quantified the output\nsimilarity of the Fortran to C++ translation.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "I.2.2; I.2.7; D.2.3; D.2.4"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 7 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15424v1",
    "published_date": "2025-04-21 20:34:37 UTC",
    "updated_date": "2025-04-21 20:34:37 UTC"
  },
  {
    "arxiv_id": "2504.18566v1",
    "title": "Feature Selection via GANs (GANFS): Enhancing Machine Learning Models for DDoS Mitigation",
    "authors": [
      "Harsh Patel"
    ],
    "abstract": "Distributed Denial of Service (DDoS) attacks represent a persistent and\nevolving threat to modern networked systems, capable of causing large-scale\nservice disruptions. The complexity of such attacks, often hidden within\nhigh-dimensional and redundant network traffic data, necessitates robust and\nintelligent feature selection techniques for effective detection. Traditional\nmethods such as filter-based, wrapper-based, and embedded approaches, each\noffer strengths but struggle with scalability or adaptability in complex attack\nenvironments. In this study, we explore these existing techniques through a\ndetailed comparative analysis and highlight their limitations when applied to\nlarge-scale DDoS detection tasks. Building upon these insights, we introduce a\nnovel Generative Adversarial Network-based Feature Selection (GANFS) method\nthat leverages adversarial learning dynamics to identify the most informative\nfeatures. By training a GAN exclusively on attack traffic and employing a\nperturbation-based sensitivity analysis on the Discriminator, GANFS effectively\nranks feature importance without relying on full supervision. Experimental\nevaluations using the CIC-DDoS2019 dataset demonstrate that GANFS not only\nimproves the accuracy of downstream classifiers but also enhances computational\nefficiency by significantly reducing feature dimensionality. These results\npoint to the potential of integrating generative learning models into\ncybersecurity pipelines to build more adaptive and scalable detection systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18566v1",
    "published_date": "2025-04-21 20:27:33 UTC",
    "updated_date": "2025-04-21 20:27:33 UTC"
  },
  {
    "arxiv_id": "2504.15417v2",
    "title": "On the Boolean Network Theory of Datalog$^\\neg$",
    "authors": [
      "Van-Giang Trinh",
      "Belaid Benhamou",
      "Sylvain Soliman",
      "François Fages"
    ],
    "abstract": "Datalog$^\\neg$ is a central formalism used in a variety of domains ranging\nfrom deductive databases and abstract argumentation frameworks to answer set\nprogramming. Its model theory is the finite counterpart of the logical\nsemantics developed for normal logic programs, mainly based on the notions of\nClark's completion and two-valued or three-valued canonical models including\nsupported, stable, regular and well-founded models. In this paper we establish\na formal link between Datalog$^\\neg$ and Boolean network theory first\nintroduced for gene regulatory networks. We show that in the absence of odd\ncycles in a Datalog$^\\neg$ program, the regular models coincide with the stable\nmodels, which entails the existence of stable models, and in the absence of\neven cycles, we prove the uniqueness of stable partial models and regular\nmodels. This connection also gives new upper bounds on the numbers of stable\npartial, regular, and stable models of a Datalog$^\\neg$ program using the\ncardinality of a feedback vertex set in its atom dependency graph.\nInterestingly, our connection to Boolean network theory also points us to the\nnotion of trap spaces. In particular we show the equivalence between\nsubset-minimal stable trap spaces and regular models.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "47 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15417v2",
    "published_date": "2025-04-21 20:02:59 UTC",
    "updated_date": "2025-05-19 22:00:47 UTC"
  },
  {
    "arxiv_id": "2504.16133v1",
    "title": "A Conceptual Framework for AI-based Decision Systems in Critical Infrastructures",
    "authors": [
      "Milad Leyli-abadi",
      "Ricardo J. Bessa",
      "Jan Viebahn",
      "Daniel Boos",
      "Clark Borst",
      "Alberto Castagna",
      "Ricardo Chavarriaga",
      "Mohamed Hassouna",
      "Bruno Lemetayer",
      "Giulia Leto",
      "Antoine Marot",
      "Maroua Meddeb",
      "Manuel Meyer",
      "Viola Schiaffonati",
      "Manuel Schneider",
      "Toni Waefler"
    ],
    "abstract": "The interaction between humans and AI in safety-critical systems presents a\nunique set of challenges that remain partially addressed by existing\nframeworks. These challenges stem from the complex interplay of requirements\nfor transparency, trust, and explainability, coupled with the necessity for\nrobust and safe decision-making. A framework that holistically integrates human\nand AI capabilities while addressing these concerns is notably required,\nbridging the critical gaps in designing, deploying, and maintaining safe and\neffective systems. This paper proposes a holistic conceptual framework for\ncritical infrastructures by adopting an interdisciplinary approach. It\nintegrates traditionally distinct fields such as mathematics, decision theory,\ncomputer science, philosophy, psychology, and cognitive engineering and draws\non specialized engineering domains, particularly energy, mobility, and\naeronautics. The flexibility in its adoption is also demonstrated through its\ninstantiation on an already existing framework.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16133v1",
    "published_date": "2025-04-21 18:38:26 UTC",
    "updated_date": "2025-04-21 18:38:26 UTC"
  },
  {
    "arxiv_id": "2504.15376v1",
    "title": "Towards Understanding Camera Motions in Any Video",
    "authors": [
      "Zhiqiu Lin",
      "Siyuan Cen",
      "Daniel Jiang",
      "Jay Karhade",
      "Hewei Wang",
      "Chancharik Mitra",
      "Tiffany Ling",
      "Yuhan Huang",
      "Sifan Liu",
      "Mingyu Chen",
      "Rushikesh Zawar",
      "Xue Bai",
      "Yilun Du",
      "Chuang Gan",
      "Deva Ramanan"
    ],
    "abstract": "We introduce CameraBench, a large-scale dataset and benchmark designed to\nassess and improve camera motion understanding. CameraBench consists of ~3,000\ndiverse internet videos, annotated by experts through a rigorous multi-stage\nquality control process. One of our contributions is a taxonomy of camera\nmotion primitives, designed in collaboration with cinematographers. We find,\nfor example, that some motions like \"follow\" (or tracking) require\nunderstanding scene content like moving subjects. We conduct a large-scale\nhuman study to quantify human annotation performance, revealing that domain\nexpertise and tutorial-based training can significantly enhance accuracy. For\nexample, a novice may confuse zoom-in (a change of intrinsics) with translating\nforward (a change of extrinsics), but can be trained to differentiate the two.\nUsing CameraBench, we evaluate Structure-from-Motion (SfM) and Video-Language\nModels (VLMs), finding that SfM models struggle to capture semantic primitives\nthat depend on scene content, while VLMs struggle to capture geometric\nprimitives that require precise estimation of trajectories. We then fine-tune a\ngenerative VLM on CameraBench to achieve the best of both worlds and showcase\nits applications, including motion-augmented captioning, video question\nanswering, and video-text retrieval. We hope our taxonomy, benchmark, and\ntutorials will drive future efforts towards the ultimate goal of understanding\ncamera motions in any video.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "Project site: https://linzhiqiu.github.io/papers/camerabench/",
    "pdf_url": "http://arxiv.org/pdf/2504.15376v1",
    "published_date": "2025-04-21 18:34:57 UTC",
    "updated_date": "2025-04-21 18:34:57 UTC"
  },
  {
    "arxiv_id": "2505.04629v1",
    "title": "From Dialect Gaps to Identity Maps: Tackling Variability in Speaker Verification",
    "authors": [
      "Abdulhady Abas Abdullah",
      "Soran Badawi",
      "Dana A. Abdullah",
      "Dana Rasul Hamad",
      "Hanan Abdulrahman Taher",
      "Sabat Salih Muhamad",
      "Aram Mahmood Ahmed",
      "Bryar A. Hassan",
      "Sirwan Abdolwahed Aula",
      "Tarik A. Rashid"
    ],
    "abstract": "The complexity and difficulties of Kurdish speaker detection among its\nseveral dialects are investigated in this work. Because of its great phonetic\nand lexical differences, Kurdish with several dialects including Kurmanji,\nSorani, and Hawrami offers special challenges for speaker recognition systems.\nThe main difficulties in building a strong speaker identification system\ncapable of precisely identifying speakers across several dialects are\ninvestigated in this work. To raise the accuracy and dependability of these\nsystems, it also suggests solutions like sophisticated machine learning\napproaches, data augmentation tactics, and the building of thorough\ndialect-specific corpus. The results show that customized strategies for every\ndialect together with cross-dialect training greatly enhance recognition\nperformance.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "eess.AS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.04629v1",
    "published_date": "2025-04-21 18:25:20 UTC",
    "updated_date": "2025-04-21 18:25:20 UTC"
  },
  {
    "arxiv_id": "2504.15369v1",
    "title": "Solving New Tasks by Adapting Internet Video Knowledge",
    "authors": [
      "Calvin Luo",
      "Zilai Zeng",
      "Yilun Du",
      "Chen Sun"
    ],
    "abstract": "Video generative models demonstrate great promise in robotics by serving as\nvisual planners or as policy supervisors. When pretrained on internet-scale\ndata, such video models intimately understand alignment with natural language,\nand can thus facilitate generalization to novel downstream behavior through\ntext-conditioning. However, they may not be sensitive to the specificities of\nthe particular environment the agent inhabits. On the other hand, training\nvideo models on in-domain examples of robotic behavior naturally encodes\nenvironment-specific intricacies, but the scale of available demonstrations may\nnot be sufficient to support generalization to unseen tasks via natural\nlanguage specification. In this work, we investigate different adaptation\ntechniques that integrate in-domain information with large-scale pretrained\nvideo models, and explore the extent to which they enable novel\ntext-conditioned generalization for robotic tasks, while also considering their\nindependent data and resource considerations. We successfully demonstrate\nacross robotic environments that adapting powerful video models with small\nscales of example data can successfully facilitate generalization to novel\nbehaviors. In particular, we present a novel adaptation strategy, termed\nInverse Probabilistic Adaptation, that not only consistently achieves strong\ngeneralization performance across robotic tasks and settings, but also exhibits\nrobustness to the quality of adaptation data, successfully solving novel tasks\neven when only suboptimal in-domain demonstrations are available.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025. Project Webpage:\n  https://diffusion-supervision.github.io/adapt2act/",
    "pdf_url": "http://arxiv.org/pdf/2504.15369v1",
    "published_date": "2025-04-21 18:20:13 UTC",
    "updated_date": "2025-04-21 18:20:13 UTC"
  },
  {
    "arxiv_id": "2504.15364v3",
    "title": "KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments",
    "authors": [
      "Junyoung Park",
      "Dalton Jones",
      "Matthew J Morse",
      "Raghavv Goel",
      "Mingu Lee",
      "Chris Lott"
    ],
    "abstract": "We demonstrate that geometrically distinctive keys during LLM inference tend\nto have high attention scores. Based on the phenomenon we propose KeyDiff, a\ntraining-free KV cache eviction method based solely on key similarity. Unlike\nother KV cache eviction methods, KeyDiff can process arbitrarily long prompts\nwithin strict resource constraints and efficiently generate responses. We\nprovide a theoretical basis for KeyDiff by relating key diversity with\nattention scores. These results imply KeyDiff can efficiently identify the most\nimportant tokens to retain. Notably KeyDiff does not rely on attention scores,\nallowing the use of optimized attention mechanisms like FlashAttention. Under a\nstrict memory allowance, we demonstrate the effectiveness of KeyDiff for the\nLlama and Qwen model families by observing a performance gap of less than 0.04%\nwith 8K cache budget ($\\sim$23% KV cache reduction) from the non-evicting\nbaseline on LongBench for Llama 3.1-8B and Llama 3.2-3B. We also observe near\nbaseline performance for Deepseek-R1-Distill-Llama-8B on the Math500 reasoning\nbenchmark and decrease end-to-end inference latency by up to 30% compared to\nthe other token-eviction methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15364v3",
    "published_date": "2025-04-21 18:12:46 UTC",
    "updated_date": "2025-05-20 17:50:11 UTC"
  },
  {
    "arxiv_id": "2504.15360v1",
    "title": "Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets",
    "authors": [
      "Javier Fumanal-Idocin",
      "Javier Andreu-Perez"
    ],
    "abstract": "Classical machine learning classifiers tend to be overconfident can be\nunreliable outside of the laboratory benchmarks. Properly assessing the\nreliability of the output of the model per sample is instrumental for real-life\nscenarios where these systems are deployed. Because of this, different\ntechniques have been employed to properly quantify the quality of prediction\nfor a given model. These are most commonly Bayesian statistics and, more\nrecently, conformal learning. Given a calibration set, conformal learning can\nproduce outputs that are guaranteed to cover the target class with a desired\nsignificance level, and are more reliable than the standard confidence\nintervals used by Bayesian methods. In this work, we propose to use conformal\nlearning with fuzzy rule-based systems in classification and show some metrics\nof their performance. Then, we discuss how the use of type 2 fuzzy sets can\nimprove the quality of the output of the system compared to both fuzzy and\ncrisp rules. Finally, we also discuss how the fine-tuning of the system can be\nadapted to improve the quality of the conformal prediction.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15360v1",
    "published_date": "2025-04-21 18:07:55 UTC",
    "updated_date": "2025-04-21 18:07:55 UTC"
  },
  {
    "arxiv_id": "2504.15275v1",
    "title": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning",
    "authors": [
      "Jie Cheng",
      "Ruixi Qiao",
      "Lijun Li",
      "Chao Guo",
      "Junle Wang",
      "Gang Xiong",
      "Yisheng Lv",
      "Fei-Yue Wang"
    ],
    "abstract": "Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15275v1",
    "published_date": "2025-04-21 17:59:02 UTC",
    "updated_date": "2025-04-21 17:59:02 UTC"
  },
  {
    "arxiv_id": "2504.15266v1",
    "title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction",
    "authors": [
      "Vaishnavh Nagarajan",
      "Chen Henry Wu",
      "Charles Ding",
      "Aditi Raghunathan"
    ],
    "abstract": "We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "37 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15266v1",
    "published_date": "2025-04-21 17:47:46 UTC",
    "updated_date": "2025-04-21 17:47:46 UTC"
  },
  {
    "arxiv_id": "2504.16132v1",
    "title": "Efficacy of a Computer Tutor that Models Expert Human Tutors",
    "authors": [
      "Andrew M. Olney",
      "Sidney K. D'Mello",
      "Natalie Person",
      "Whitney Cade",
      "Patrick Hays",
      "Claire W. Dempsey",
      "Blair Lehman",
      "Betsy Williams",
      "Art Graesser"
    ],
    "abstract": "Tutoring is highly effective for promoting learning. However, the\ncontribution of expertise to tutoring effectiveness is unclear and continues to\nbe debated. We conducted a 9-week learning efficacy study of an intelligent\ntutoring system (ITS) for biology modeled on expert human tutors with two\ncontrol conditions: human tutors who were experts in the domain but not in\ntutoring and a no-tutoring condition. All conditions were supplemental to\nclassroom instruction, and students took learning tests immediately before and\nafter tutoring sessions as well as delayed tests 1-2 weeks later. Analysis\nusing logistic mixed-effects modeling indicates significant positive effects on\nthe immediate post-test for the ITS (d =.71) and human tutors (d =.66) which\nare in the 99th percentile of meta-analytic effects, as well as significant\npositive effects on the delayed post-test for the ITS (d =.36) and human tutors\n(d =.39). We discuss implications for the role of expertise in tutoring and the\ndesign of future studies.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "I.2.4; I.2.7; K.3.1"
    ],
    "primary_category": "cs.CY",
    "comment": "Shortened version of this paper has been accepted to AIED 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16132v1",
    "published_date": "2025-04-21 17:41:28 UTC",
    "updated_date": "2025-04-21 17:41:28 UTC"
  },
  {
    "arxiv_id": "2504.15261v1",
    "title": "Leveraging Language Models for Automated Patient Record Linkage",
    "authors": [
      "Mohammad Beheshti",
      "Lovedeep Gondara",
      "Iris Zachary"
    ],
    "abstract": "Objective: Healthcare data fragmentation presents a major challenge for\nlinking patient data, necessitating robust record linkage to integrate patient\nrecords from diverse sources. This study investigates the feasibility of\nleveraging language models for automated patient record linkage, focusing on\ntwo key tasks: blocking and matching. Materials and Methods: We utilized\nreal-world healthcare data from the Missouri Cancer Registry and Research\nCenter, linking patient records from two independent sources using\nprobabilistic linkage as a baseline. A transformer-based model, RoBERTa, was\nfine-tuned for blocking using sentence embeddings. For matching, several\nlanguage models were experimented under fine-tuned and zero-shot settings,\nassessing their performance against ground truth labels. Results: The\nfine-tuned blocking model achieved a 92% reduction in the number of candidate\npairs while maintaining near-perfect recall. In the matching task, fine-tuned\nMistral-7B achieved the best performance with only 6 incorrect predictions.\nAmong zero-shot models, Mistral-Small-24B performed best, with a total of 55\nincorrect predictions. Discussion: Fine-tuned language models achieved strong\nperformance in patient record blocking and matching with minimal errors.\nHowever, they remain less accurate and efficient than a hybrid rule-based and\nprobabilistic approach for blocking. Additionally, reasoning models like\nDeepSeek-R1 are impractical for large-scale record linkage due to high\ncomputational costs. Conclusion: This study highlights the potential of\nlanguage models for automating patient record linkage, offering improved\nefficiency by eliminating the manual efforts required to perform patient record\nlinkage. Overall, language models offer a scalable solution that can enhance\ndata integration, reduce manual effort, and support disease surveillance and\nresearch.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15261v1",
    "published_date": "2025-04-21 17:41:15 UTC",
    "updated_date": "2025-04-21 17:41:15 UTC"
  },
  {
    "arxiv_id": "2504.15259v1",
    "title": "Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation",
    "authors": [
      "Yunxuan Cai",
      "Sitao Xiang",
      "Zongjian Li",
      "Haiwei Chen",
      "Yajie Zhao"
    ],
    "abstract": "Digital modeling and reconstruction of human faces serve various\napplications. However, its availability is often hindered by the requirements\nof data capturing devices, manual labor, and suitable actors. This situation\nrestricts the diversity, expressiveness, and control over the resulting models.\nThis work aims to demonstrate that a semantically controllable generative\nnetwork can provide enhanced control over the digital face modeling process. To\nenhance diversity beyond the limited human faces scanned in a controlled\nsetting, we introduce a novel data generation pipeline that creates a\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\nnormalization module converts synthesized data from the diffusion model into\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\ndeveloped an efficient GAN-based generator. This generator accepts semantic\nattributes as input, and generates geometry and albedo. It also allows\ncontinuous post-editing of attributes in the latent space. Our asset refinement\ncomponent subsequently creates physically-based facial assets. We introduce a\ncomprehensive system designed for creating and editing high-quality face\nassets. Our proposed model has undergone extensive experiment, comparison and\nevaluation. We also integrate everything into a web-based interactive tool. We\naim to make this tool publicly available with the release of the paper.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15259v1",
    "published_date": "2025-04-21 17:38:50 UTC",
    "updated_date": "2025-04-21 17:38:50 UTC"
  },
  {
    "arxiv_id": "2504.15257v1",
    "title": "FlowReasoner: Reinforcing Query-Level Meta-Agents",
    "authors": [
      "Hongcheng Gao",
      "Yue Liu",
      "Yufei He",
      "Longxu Dou",
      "Chao Du",
      "Zhijie Deng",
      "Bryan Hooi",
      "Min Lin",
      "Tianyu Pang"
    ],
    "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate\nthe design of query-level multi-agent systems, i.e., one system per user query.\nOur core idea is to incentivize a reasoning-based meta-agent via external\nexecution feedback. Concretely, by distilling DeepSeek R1, we first endow the\nbasic reasoning ability regarding the generation of multi-agent systems to\nFlowReasoner. Then, we further enhance it via reinforcement learning (RL) with\nexternal execution feedback. A multi-purpose reward is designed to guide the RL\ntraining from aspects of performance, complexity, and efficiency. In this\nmanner, FlowReasoner is enabled to generate a personalized multi-agent system\nfor each user query via deliberative reasoning. Experiments on both engineering\nand competition code benchmarks demonstrate the superiority of FlowReasoner.\nRemarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks.\nThe code is available at https://github.com/sail-sg/FlowReasoner.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15257v1",
    "published_date": "2025-04-21 17:35:42 UTC",
    "updated_date": "2025-04-21 17:35:42 UTC"
  },
  {
    "arxiv_id": "2504.15252v1",
    "title": "SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam",
    "authors": [
      "Tue Vo",
      "Lakshay Sharma",
      "Tuan Dinh",
      "Khuong Dinh",
      "Trang Nguyen",
      "Trung Phan",
      "Minh Do",
      "Duong Vu"
    ],
    "abstract": "Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a workshop paper at \"Tackling Climate Change with\n  Machine Learning\", ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15252v1",
    "published_date": "2025-04-21 17:33:02 UTC",
    "updated_date": "2025-04-21 17:33:02 UTC"
  },
  {
    "arxiv_id": "2504.15236v1",
    "title": "Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions",
    "authors": [
      "Saffron Huang",
      "Esin Durmus",
      "Miles McCain",
      "Kunal Handa",
      "Alex Tamkin",
      "Jerry Hong",
      "Michael Stern",
      "Arushi Somani",
      "Xiuruo Zhang",
      "Deep Ganguli"
    ],
    "abstract": "AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "44 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15236v1",
    "published_date": "2025-04-21 17:13:16 UTC",
    "updated_date": "2025-04-21 17:13:16 UTC"
  },
  {
    "arxiv_id": "2504.15228v2",
    "title": "A Self-Improving Coding Agent",
    "authors": [
      "Maxime Robeyns",
      "Martin Szummer",
      "Laurence Aitchison"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have spurred interest in\ndeploying LLM agents to undertake tasks in the world. LLMs are often deployed\nin agent systems: code that orchestrates LLM calls and provides them with\ntools. We demonstrate that an agent system, equipped with basic coding tools,\ncan autonomously edit itself, and thereby improve its performance on benchmark\ntasks. We find performance gains from 17% to 53% on a random subset of SWE\nBench Verified, with additional performance gains on LiveCodeBench, as well as\nsynthetically generated agent benchmarks. Our work represents an advancement in\nthe automated and open-ended design of agentic systems, and demonstrates a\ndata-efficient, non gradient-based learning mechanism driven by LLM reflection\nand code updates.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Submitted as a preprint to NeurIPS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15228v2",
    "published_date": "2025-04-21 16:58:18 UTC",
    "updated_date": "2025-05-16 20:58:56 UTC"
  },
  {
    "arxiv_id": "2504.15226v1",
    "title": "A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing",
    "authors": [
      "Nathan Steffen",
      "Wilhelm Louw",
      "Nicholas Ernest",
      "Timothy Arnett",
      "Kelly Cohen"
    ],
    "abstract": "Automation of robotic systems for servicing in cislunar space is becoming\nextremely important as the number of satellites in orbit increases. Safety is\ncritical in performing satellite maintenance, so the control techniques\nutilized must be trusted in addition to being highly efficient. In this work,\nGenetic Fuzzy Trees are combined with the widely used LQR control scheme via\nThales' TrUE AI Toolkit to create a trusted and efficient controller for a\ntwo-degree-of-freedom planar robotic manipulator that would theoretically be\nused to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is\n18.5% more performant than optimal LQR on average, and that it is incredibly\nrobust to uncertainty.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15226v1",
    "published_date": "2025-04-21 16:57:56 UTC",
    "updated_date": "2025-04-21 16:57:56 UTC"
  },
  {
    "arxiv_id": "2504.15225v1",
    "title": "M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding",
    "authors": [
      "Sarah Alnegheimish",
      "Zelin He",
      "Matthew Reimherr",
      "Akash Chandrayan",
      "Abhinav Pradhan",
      "Luca D'Angelo"
    ],
    "abstract": "With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15225v1",
    "published_date": "2025-04-21 16:57:46 UTC",
    "updated_date": "2025-04-21 16:57:46 UTC"
  },
  {
    "arxiv_id": "2505.00010v1",
    "title": "Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models",
    "authors": [
      "Tri Nguyen",
      "Lohith Srikanth Pentapalli",
      "Magnus Sieverding",
      "Laurah Turner",
      "Seth Overla",
      "Weibing Zheng",
      "Chris Zhou",
      "David Furniss",
      "Danielle Weber",
      "Michael Gharib",
      "Matt Kelleher",
      "Michael Shukis",
      "Cameron Pawlik",
      "Kelly Cohen"
    ],
    "abstract": "Jailbreaking in Large Language Models (LLMs) threatens their safe use in\nsensitive domains like education by allowing users to bypass ethical\nsafeguards. This study focuses on detecting jailbreaks in 2-Sigma, a clinical\neducation platform that simulates patient interactions using LLMs. We annotated\nover 2,300 prompts across 158 conversations using four linguistic variables\nshown to correlate strongly with jailbreak behavior. The extracted features\nwere used to train several predictive models, including Decision Trees, Fuzzy\nLogic-based classifiers, Boosting methods, and Logistic Regression. Results\nshow that feature-based predictive models consistently outperformed Prompt\nEngineering, with the Fuzzy Decision Tree achieving the best overall\nperformance. Our findings demonstrate that linguistic-feature-based models are\neffective and explainable alternatives for jailbreak detection. We suggest\nfuture work explore hybrid frameworks that integrate prompt-based flexibility\nwith rule-based robustness for real-time, spectrum-based jailbreak monitoring\nin educational LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00010v1",
    "published_date": "2025-04-21 16:54:35 UTC",
    "updated_date": "2025-04-21 16:54:35 UTC"
  },
  {
    "arxiv_id": "2504.15330v1",
    "title": "Med-CoDE: Medical Critique based Disagreement Evaluation Framework",
    "authors": [
      "Mohit Gupta",
      "Akiko Aizawa",
      "Rajiv Ratn Shah"
    ],
    "abstract": "The emergence of large language models (LLMs) has significantly influenced\nnumerous fields, including healthcare, by enhancing the capabilities of\nautomated systems to process and generate human-like text. However, despite\ntheir advancements, the reliability and accuracy of LLMs in medical contexts\nremain critical concerns. Current evaluation methods often lack robustness and\nfail to provide a comprehensive assessment of LLM performance, leading to\npotential risks in clinical settings. In this work, we propose Med-CoDE, a\nspecifically designed evaluation framework for medical LLMs to address these\nchallenges. The framework leverages a critique-based approach to quantitatively\nmeasure the degree of disagreement between model-generated responses and\nestablished medical ground truths. This framework captures both accuracy and\nreliability in medical settings. The proposed evaluation framework aims to fill\nthe existing gap in LLM assessment by offering a systematic method to evaluate\nthe quality and trustworthiness of medical LLMs. Through extensive experiments\nand case studies, we illustrate the practicality of our framework in providing\na comprehensive and reliable evaluation of medical LLMs.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "8 pages, 4 figures, NAACL SRW 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15330v1",
    "published_date": "2025-04-21 16:51:11 UTC",
    "updated_date": "2025-04-21 16:51:11 UTC"
  },
  {
    "arxiv_id": "2504.17805v1",
    "title": "Fuzzy Logic -- Based Scheduling System for Part-Time Workforce",
    "authors": [
      "Tri Nguyen",
      "Kelly Cohen"
    ],
    "abstract": "This paper explores the application of genetic fuzzy systems to efficiently\ngenerate schedules for a team of part-time student workers at a university.\nGiven the preferred number of working hours and availability of employees, our\nmodel generates feasible solutions considering various factors, such as maximum\nweekly hours, required number of workers on duty, and the preferred number of\nworking hours. The algorithm is trained and tested with availability data\ncollected from students at the University of Cincinnati. The results\ndemonstrate the algorithm's efficiency in producing schedules that meet\noperational criteria and its robustness in understaffed conditions.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17805v1",
    "published_date": "2025-04-21 16:44:17 UTC",
    "updated_date": "2025-04-21 16:44:17 UTC"
  },
  {
    "arxiv_id": "2504.15211v1",
    "title": "Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI",
    "authors": [
      "Yanan Long"
    ],
    "abstract": "The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.",
    "categories": [
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "To be presented at ACM CHI 2025 workshop STAIG",
    "pdf_url": "http://arxiv.org/pdf/2504.15211v1",
    "published_date": "2025-04-21 16:31:15 UTC",
    "updated_date": "2025-04-21 16:31:15 UTC"
  },
  {
    "arxiv_id": "2504.15210v2",
    "title": "Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs",
    "authors": [
      "Marina Sakharova",
      "Abhinav Anand",
      "Mira Mezini"
    ],
    "abstract": "Code-generating Large Language Models (LLMs) have become essential tools in\nmodern software development, enhancing productivity and accelerating\ndevelopment. This paper aims to investigate the fine-tuning of code-generating\nLLMs using Reinforcement Learning and Direct Preference Optimization, further\nimproving their performance. To achieve this, we enhance the training data for\nthe reward model with the help of symbolic execution techniques, ensuring more\ncomprehensive and objective data. With symbolic execution, we create a custom\ndataset that better captures the nuances in code evaluation. Our reward models,\nfine-tuned on this dataset, demonstrate significant improvements over the\nbaseline, CodeRL, in estimating the quality of generated code. Our\ncode-generating LLMs, trained with the help of reward model feedback, achieve\nsimilar results compared to the CodeRL benchmark.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15210v2",
    "published_date": "2025-04-21 16:29:07 UTC",
    "updated_date": "2025-05-05 06:56:16 UTC"
  },
  {
    "arxiv_id": "2504.15209v1",
    "title": "A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data",
    "authors": [
      "Xin Liao",
      "Bing Yang",
      "Tan Dongli",
      "Cai Yu"
    ],
    "abstract": "The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07 (Primary) 62M10, 65C60 (Secondary)",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15209v1",
    "published_date": "2025-04-21 16:27:16 UTC",
    "updated_date": "2025-04-21 16:27:16 UTC"
  },
  {
    "arxiv_id": "2504.15208v1",
    "title": "Compute-Optimal LLMs Provably Generalize Better With Scale",
    "authors": [
      "Marc Finzi",
      "Sanyam Kapoor",
      "Diego Granziol",
      "Anming Gu",
      "Christopher De Sa",
      "J. Zico Kolter",
      "Andrew Gordon Wilson"
    ],
    "abstract": "Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15208v1",
    "published_date": "2025-04-21 16:26:56 UTC",
    "updated_date": "2025-04-21 16:26:56 UTC"
  },
  {
    "arxiv_id": "2504.15205v1",
    "title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges",
    "authors": [
      "Nandan Thakur",
      "Ronak Pradeep",
      "Shivani Upadhyay",
      "Daniel Campos",
      "Nick Craswell",
      "Jimmy Lin"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to\ngenerate answers with citations from source documents containing \"ground\ntruth\", thereby reducing system hallucinations. A crucial factor in RAG\nevaluation is \"support\", whether the information in the cited documents\nsupports the answer. To this end, we conducted a large-scale comparative study\nof 45 participant submissions on 36 topics to the TREC 2024 RAG Track,\ncomparing an automatic LLM judge (GPT-4o) against human judges for support\nassessment. We considered two conditions: (1) fully manual assessments from\nscratch and (2) manual assessments with post-editing of LLM predictions. Our\nresults indicate that for 56% of the manual from-scratch assessments, human and\nGPT-4o predictions match perfectly (on a three-level scale), increasing to 72%\nin the manual with post-editing condition. Furthermore, by carefully analyzing\nthe disagreements in an unbiased study, we found that an independent human\njudge correlates better with GPT-4o than a human judge, suggesting that LLM\njudges can be a reliable alternative for support assessment. To conclude, we\nprovide a qualitative analysis of human and GPT-4o errors to help guide future\niterations of support assessment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SIGIR 2025 (short)",
    "pdf_url": "http://arxiv.org/pdf/2504.15205v1",
    "published_date": "2025-04-21 16:20:43 UTC",
    "updated_date": "2025-04-21 16:20:43 UTC"
  },
  {
    "arxiv_id": "2504.15199v1",
    "title": "Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning",
    "authors": [
      "Yassir Benhammou",
      "Alessandro Tiberio",
      "Gabriel Trautmann",
      "Suman Kalyan"
    ],
    "abstract": "MILS (Multimodal Iterative LLM Solver) is a recently published framework that\nclaims \"LLMs can see and hear without any training\" by leveraging an iterative,\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\napproach demonstrates good performance, our investigation reveals that this\nsuccess comes at a hidden, substantial computational cost due to its expensive\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\nand GPT-4V achieve competitive results through a streamlined, single-pass\napproach. We hypothesize that the significant overhead inherent in MILS's\niterative process may undermine its practical benefits, thereby challenging the\nnarrative that zero-shot performance can be attained without incurring heavy\nresource demands. This work is the first to expose and quantify the trade-offs\nbetween output quality and computational cost in MILS, providing critical\ninsights for the design of more efficient multimodal models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 2 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.15199v1",
    "published_date": "2025-04-21 16:16:19 UTC",
    "updated_date": "2025-04-21 16:16:19 UTC"
  },
  {
    "arxiv_id": "2504.15192v1",
    "title": "Breast density in MRI: an AI-based quantification and relationship to assessment in mammography",
    "authors": [
      "Yaqian Chen",
      "Lin Li",
      "Hanxue Gu",
      "Haoyu Dong",
      "Derek L. Nguyen",
      "Allan D. Kirk",
      "Maciej A. Mazurowski",
      "E. Shelley Hwang"
    ],
    "abstract": "Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15192v1",
    "published_date": "2025-04-21 16:01:51 UTC",
    "updated_date": "2025-04-21 16:01:51 UTC"
  },
  {
    "arxiv_id": "2504.15188v2",
    "title": "Synergistic Weak-Strong Collaboration by Aligning Preferences",
    "authors": [
      "Yizhu Jiao",
      "Xuchao Zhang",
      "Zhaoyang Wang",
      "Yubo Ma",
      "Zhun Deng",
      "Rujia Wang",
      "Chetan Bansal",
      "Saravan Rajmohan",
      "Jiawei Han",
      "Huaxiu Yao"
    ],
    "abstract": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15188v2",
    "published_date": "2025-04-21 15:57:33 UTC",
    "updated_date": "2025-04-22 04:22:09 UTC"
  },
  {
    "arxiv_id": "2504.15181v1",
    "title": "Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures",
    "authors": [
      "Lily Stelling",
      "Mick Yang",
      "Rokas Gipiškis",
      "Leon Staufer",
      "Ze Shen Chin",
      "Siméon Campos",
      "Michael Chen"
    ],
    "abstract": "This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "158 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15181v1",
    "published_date": "2025-04-21 15:44:01 UTC",
    "updated_date": "2025-04-21 15:44:01 UTC"
  },
  {
    "arxiv_id": "2504.15165v1",
    "title": "An Efficient Aerial Image Detection with Variable Receptive Fields",
    "authors": [
      "Liu Wenbin"
    ],
    "abstract": "Aerial object detection using unmanned aerial vehicles (UAVs) faces critical\nchallenges including sub-10px targets, dense occlusions, and stringent\ncomputational constraints. Existing detectors struggle to balance accuracy and\nefficiency due to rigid receptive fields and redundant architectures. To\naddress these limitations, we propose Variable Receptive Field DETR (VRF-DETR),\na transformer-based detector incorporating three key components: 1) Multi-Scale\nContext Fusion (MSCF) module that dynamically recalibrates features through\nadaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution\n(GConv) layer enabling parameter-efficient local-context modeling via depthwise\nseparable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)\nBottleneck that hierarchically disentangles occluded objects through cascaded\nglobal-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR\nachieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with\nonly 13.5M parameters. This work establishes a new efficiency-accuracy Pareto\nfrontier for UAV-based detection tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15165v1",
    "published_date": "2025-04-21 15:16:13 UTC",
    "updated_date": "2025-04-21 15:16:13 UTC"
  },
  {
    "arxiv_id": "2504.16131v1",
    "title": "Introduction to Quantum Machine Learning and Quantum Architecture Search",
    "authors": [
      "Samuel Yen-Chi Chen",
      "Zhiding Liang"
    ],
    "abstract": "Recent advancements in quantum computing (QC) and machine learning (ML) have\nfueled significant research efforts aimed at integrating these two\ntransformative technologies. Quantum machine learning (QML), an emerging\ninterdisciplinary field, leverages quantum principles to enhance the\nperformance of ML algorithms. Concurrently, the exploration of systematic and\nautomated approaches for designing high-performance quantum circuit\narchitectures for QML tasks has gained prominence, as these methods empower\nresearchers outside the quantum computing domain to effectively utilize\nquantum-enhanced tools. This tutorial will provide an in-depth overview of\nrecent breakthroughs in both areas, highlighting their potential to expand the\napplication landscape of QML across diverse fields.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "quant-ph",
    "comment": "ISCAS 2025 Tutorial",
    "pdf_url": "http://arxiv.org/pdf/2504.16131v1",
    "published_date": "2025-04-21 15:13:33 UTC",
    "updated_date": "2025-04-21 15:13:33 UTC"
  },
  {
    "arxiv_id": "2504.15152v1",
    "title": "Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection",
    "authors": [
      "Jun Zhou",
      "Bingchen Gao",
      "Kai Wang",
      "Jialun Pei",
      "Pheng-Ann Heng",
      "Jing Qin"
    ],
    "abstract": "Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "TMI under review",
    "pdf_url": "http://arxiv.org/pdf/2504.15152v1",
    "published_date": "2025-04-21 14:55:57 UTC",
    "updated_date": "2025-04-21 14:55:57 UTC"
  },
  {
    "arxiv_id": "2504.15146v1",
    "title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems",
    "authors": [
      "Wei Zhou",
      "Ailiya Borjigin",
      "Cong He"
    ],
    "abstract": "Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.15146v1",
    "published_date": "2025-04-21 14:50:28 UTC",
    "updated_date": "2025-04-21 14:50:28 UTC"
  },
  {
    "arxiv_id": "2504.15144v1",
    "title": "C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation",
    "authors": [
      "Melih Sirlanci",
      "Carter Yagemann",
      "Zhiqiang Lin"
    ],
    "abstract": "Despite the effort in vulnerability detection over the last two decades,\nmemory safety vulnerabilities continue to be a critical problem. Recent reports\nsuggest that the key solution is to migrate to memory-safe languages. To this\nend, C-to-Rust transpilation becomes popular to resolve memory-safety issues in\nC programs. Recent works propose C-to-Rust transpilation frameworks; however, a\ncomprehensive evaluation dataset is missing. Although one solution is to put\ntogether a large enough dataset, this increases the analysis time in automated\nframeworks as well as in manual efforts for some cases. In this work, we build\na method to select functions from a large set to construct a minimized yet\nrepresentative dataset to evaluate the C-to-Rust transpilation. We propose\nC2RUST-BENCH that contains 2,905 functions, which are representative of\nC-to-Rust transpilation, selected from 15,503 functions of real-world programs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15144v1",
    "published_date": "2025-04-21 14:48:45 UTC",
    "updated_date": "2025-04-21 14:48:45 UTC"
  },
  {
    "arxiv_id": "2504.15135v1",
    "title": "KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking",
    "authors": [
      "Juyeon Kim",
      "Geon Lee",
      "Taeuk Kim",
      "Kijung Shin"
    ],
    "abstract": "Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "SIGIR 2025 (Short)",
    "pdf_url": "http://arxiv.org/pdf/2504.15135v1",
    "published_date": "2025-04-21 14:38:44 UTC",
    "updated_date": "2025-04-21 14:38:44 UTC"
  },
  {
    "arxiv_id": "2504.15133v1",
    "title": "EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models",
    "authors": [
      "Ziwen Xu",
      "Shuxun Wang",
      "Kewei Xu",
      "Haoming Xu",
      "Mengru Wang",
      "Xinle Deng",
      "Yunzhi Yao",
      "Guozhou Zheng",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. Demo:\n  https://zjunlp.github.io/project/EasyEdit2/video; code:\n  https://github.com/zjunlp/EasyEdit",
    "pdf_url": "http://arxiv.org/pdf/2504.15133v1",
    "published_date": "2025-04-21 14:33:55 UTC",
    "updated_date": "2025-04-21 14:33:55 UTC"
  },
  {
    "arxiv_id": "2504.15328v1",
    "title": "Bayesian Federated Learning for Continual Training",
    "authors": [
      "Usevalad Milasheuski",
      "Luca Barbieri",
      "Sanaz Kianoush",
      "Monica Nicoli",
      "Stefano Savazzi"
    ],
    "abstract": "Bayesian Federated Learning (BFL) enables uncertainty quantification and\nrobust adaptation in distributed learning. In contrast to the frequentist\napproach, it estimates the posterior distribution of a global model, offering\ninsights into model reliability. However, current BFL methods neglect continual\nlearning challenges in dynamic environments where data distributions shift over\ntime. We propose a continual BFL framework applied to human sensing with radar\ndata collected over several days. Using Stochastic Gradient Langevin Dynamics\n(SGLD), our approach sequentially updates the model, leveraging past posteriors\nto construct the prior for the new tasks. We assess the accuracy, the expected\ncalibration error (ECE) and the convergence speed of our approach against\nseveral baselines. Results highlight the effectiveness of continual Bayesian\nupdates in preserving knowledge and adapting to evolving data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15328v1",
    "published_date": "2025-04-21 14:33:04 UTC",
    "updated_date": "2025-04-21 14:33:04 UTC"
  },
  {
    "arxiv_id": "2504.15130v1",
    "title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning",
    "authors": [
      "Kushal Shah",
      "Jihyun Park",
      "Seung-Kyum Choi"
    ],
    "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "13 Pages, 5 Figures, 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15130v1",
    "published_date": "2025-04-21 14:25:32 UTC",
    "updated_date": "2025-04-21 14:25:32 UTC"
  },
  {
    "arxiv_id": "2504.15129v1",
    "title": "A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment",
    "authors": [
      "Kangyao Huang",
      "Hao Wang",
      "Yu Luo",
      "Jingyu Chen",
      "Jintao Chen",
      "Xiangkui Zhang",
      "Xiangyang Ji",
      "Huaping Liu"
    ],
    "abstract": "Deploying robot learning methods to a quadrotor in unstructured outdoor\nenvironments is an exciting task. Quadrotors operating in real-world\nenvironments by learning-based methods encounter several challenges: a large\namount of simulator generated data required for training, strict demands for\nreal-time processing onboard, and the sim-to-real gap caused by dynamic and\nnoisy conditions. Current works have made a great breakthrough in applying\nlearning-based methods to end-to-end control of quadrotors, but rarely mention\nthe infrastructure system training from scratch and deploying to reality, which\nmakes it difficult to reproduce methods and applications. To bridge this gap,\nwe propose a platform that enables the seamless transfer of end-to-end deep\nreinforcement learning (DRL) policies. We integrate the training environment,\nflight dynamics control, DRL algorithms, the MAVROS middleware stack, and\nhardware into a comprehensive workflow and architecture that enables\nquadrotors' policies to be trained from scratch to real-world deployment in\nseveral minutes. Our platform provides rich types of environments including\nhovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and\nplanning in unknown environments, as a physical experiment benchmark. Through\nextensive empirical validation, we demonstrate the efficiency of proposed\nsim-to-real platform, and robust outdoor flight performance under real-world\nperturbations. Details can be found from our website\nhttps://emnavi.tech/AirGym/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15129v1",
    "published_date": "2025-04-21 14:25:23 UTC",
    "updated_date": "2025-04-21 14:25:23 UTC"
  },
  {
    "arxiv_id": "2504.15125v1",
    "title": "Contemplative Wisdom for Superalignment",
    "authors": [
      "Ruben Laukkonen",
      "Fionn Inglis",
      "Shamil Chandaria",
      "Lars Sandved-Smith",
      "Jakob Hohwy",
      "Jonathan Gold",
      "Adam Elwood"
    ],
    "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15125v1",
    "published_date": "2025-04-21 14:20:49 UTC",
    "updated_date": "2025-04-21 14:20:49 UTC"
  },
  {
    "arxiv_id": "2504.15120v1",
    "title": "Kuwain 1.5B: An Arabic SLM via Language Injection",
    "authors": [
      "Khalil Hennara",
      "Sara Chrouf",
      "Mohamed Motaism Hamed",
      "Zeina Aldallal",
      "Omar Hadid",
      "Safwan AlModhayan"
    ],
    "abstract": "Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15120v1",
    "published_date": "2025-04-21 14:17:25 UTC",
    "updated_date": "2025-04-21 14:17:25 UTC"
  },
  {
    "arxiv_id": "2504.15105v1",
    "title": "A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae",
    "authors": [
      "Yurun Wang",
      "Zerong Qi",
      "Shujun Fu",
      "Mingzheng Hu"
    ],
    "abstract": "Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15105v1",
    "published_date": "2025-04-21 13:54:33 UTC",
    "updated_date": "2025-04-21 13:54:33 UTC"
  },
  {
    "arxiv_id": "2504.15101v1",
    "title": "NeuGaze: Reshaping the future BCI",
    "authors": [
      "Yiqian Yang"
    ],
    "abstract": "Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15101v1",
    "published_date": "2025-04-21 13:49:17 UTC",
    "updated_date": "2025-04-21 13:49:17 UTC"
  },
  {
    "arxiv_id": "2504.15099v1",
    "title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN",
    "authors": [
      "Lin Wang",
      "Xiancheng Wang",
      "Rui Wang",
      "Zhibo Zhang",
      "Minghang Zhao"
    ],
    "abstract": "Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15099v1",
    "published_date": "2025-04-21 13:41:09 UTC",
    "updated_date": "2025-04-21 13:41:09 UTC"
  },
  {
    "arxiv_id": "2504.15093v1",
    "title": "Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models",
    "authors": [
      "K. Wong",
      "B. Wu",
      "S. Bulathwela",
      "M. Cukurova"
    ],
    "abstract": "Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for 26th International Conference on Artificial Intelligence\n  in Education (AIED 2025), 22 - 26 July 2025, Palermo, Italy. 17 pages, 1\n  figure",
    "pdf_url": "http://arxiv.org/pdf/2504.15093v1",
    "published_date": "2025-04-21 13:25:55 UTC",
    "updated_date": "2025-04-21 13:25:55 UTC"
  },
  {
    "arxiv_id": "2504.15090v1",
    "title": "Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving",
    "authors": [
      "Junxiang Gao",
      "Yixin Ran",
      "Jia Chen"
    ],
    "abstract": "A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15090v1",
    "published_date": "2025-04-21 13:24:30 UTC",
    "updated_date": "2025-04-21 13:24:30 UTC"
  },
  {
    "arxiv_id": "2504.15080v1",
    "title": "Empowering AI to Generate Better AI Code: Guided Generation of Deep Learning Projects with LLMs",
    "authors": [
      "Chen Xie",
      "Mingsheng Jiao",
      "Xiaodong Gu",
      "Beijun Shen"
    ],
    "abstract": "While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15080v1",
    "published_date": "2025-04-21 13:09:25 UTC",
    "updated_date": "2025-04-21 13:09:25 UTC"
  },
  {
    "arxiv_id": "2504.15075v1",
    "title": "Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention",
    "authors": [
      "Van Thuy Hoang",
      "Hyeon-Ju Jeon",
      "O-Joun Lee"
    ],
    "abstract": "Graph Neural Networks (GNNs) update node representations through message\npassing, which is primarily based on the homophily principle, assuming that\nadjacent nodes share similar features. However, in real-world graphs with\nlong-tailed degree distributions, high-degree nodes dominate message passing,\ncausing a degree bias where low-degree nodes remain under-represented due to\ninadequate messages. The main challenge in addressing degree bias is how to\ndiscover non-adjacent nodes to provide additional messages to low-degree nodes\nwhile reducing excessive messages for high-degree nodes. Nevertheless,\nexploiting non-adjacent nodes to provide valuable messages is challenging, as\nit could generate noisy information and disrupt the original graph structures.\nTo solve it, we propose a novel Degree Fairness Graph Transformer, named\nDegFairGT, to mitigate degree bias by discovering structural similarities\nbetween non-adjacent nodes through learnable structural augmentation and\nstructural self-attention. Our key idea is to exploit non-adjacent nodes with\nsimilar roles in the same community to generate informative edges under our\naugmentation, which could provide informative messages between nodes with\nsimilar roles while ensuring that the homophily principle is maintained within\nthe community. To enable DegFairGT to learn such structural similarities, we\nthen propose a structural self-attention to capture the similarities between\nnode pairs. To preserve global graph structures and prevent graph augmentation\nfrom hindering graph structure, we propose a Self-Supervised Learning task to\npreserve p-step transition probability and regularize graph augmentation.\nExtensive experiments on six datasets showed that DegFairGT outperformed\nstate-of-the-art baselines in degree fairness analysis, node classification,\nand node clustering tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IEEE TNSE",
    "pdf_url": "http://arxiv.org/pdf/2504.15075v1",
    "published_date": "2025-04-21 13:03:40 UTC",
    "updated_date": "2025-04-21 13:03:40 UTC"
  },
  {
    "arxiv_id": "2504.15066v1",
    "title": "Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides",
    "authors": [
      "Jinghua Zhao",
      "Yuhang Jia",
      "Shiyao Wang",
      "Jiaming Zhou",
      "Hui Wang",
      "Yong Qin"
    ],
    "abstract": "Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "6 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15066v1",
    "published_date": "2025-04-21 12:51:54 UTC",
    "updated_date": "2025-04-21 12:51:54 UTC"
  },
  {
    "arxiv_id": "2504.15063v1",
    "title": "Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages",
    "authors": [
      "Hongli Peng",
      "Xiaoqi Li",
      "Wenkai Li"
    ],
    "abstract": "Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15063v1",
    "published_date": "2025-04-21 12:42:59 UTC",
    "updated_date": "2025-04-21 12:42:59 UTC"
  },
  {
    "arxiv_id": "2504.15062v1",
    "title": "OPO: Making Decision-Focused Data Acquisition Decisions",
    "authors": [
      "Egon Peršak",
      "Miguel F. Anjos"
    ],
    "abstract": "We propose a model for making data acquisition decisions for variables in\ncontextual stochastic optimisation problems. Data acquisition decisions are\ntypically treated as separate and fixed. We explore problem settings in which\nthe acquisition of contextual variables is costly and consequently constrained.\nThe data acquisition problem is often solved heuristically for proxy objectives\nsuch as coverage. The more intuitive objective is the downstream decision\nquality as a result of data acquisition decisions. The whole pipeline can be\ncharacterised as an optimise-then-predict-then-optimise (OPO) problem.\nAnalogously, much recent research has focused on how to integrate prediction\nand optimisation (PO) in the form of decision-focused learning. We propose\nleveraging differentiable optimisation to extend the integration to data\nacquisition. We solve the data acquisition problem with well-defined\nconstraints by learning a surrogate linear objective function. We demonstrate\nan application of this model on a shortest path problem for which we first have\nto set a drone reconnaissance strategy to capture image segments serving as\ninputs to a model that predicts travel costs. We ablate the problem with a\nnumber of training modalities and demonstrate that the differentiable\noptimisation approach outperforms random search strategies.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15062v1",
    "published_date": "2025-04-21 12:41:35 UTC",
    "updated_date": "2025-04-21 12:41:35 UTC"
  },
  {
    "arxiv_id": "2504.15051v1",
    "title": "VeLU: Variance-enhanced Learning Unit for Deep Neural Networks",
    "authors": [
      "Ashkan Shakarami",
      "Yousef Yeganeh",
      "Azade Farshad",
      "Lorenzo Nicolè",
      "Stefano Ghidoni",
      "Nassir Navab"
    ],
    "abstract": "Activation functions are fundamental in deep neural networks and directly\nimpact gradient flow, optimization stability, and generalization. Although ReLU\nremains standard because of its simplicity, it suffers from vanishing gradients\nand lacks adaptability. Alternatives like Swish and GELU introduce smooth\ntransitions, but fail to dynamically adjust to input statistics. We propose\nVeLU, a Variance-enhanced Learning Unit as an activation function that\ndynamically scales based on input variance by integrating ArcTan-Sin\ntransformations and Wasserstein-2 regularization, effectively mitigating\ncovariate shifts and stabilizing optimization. Extensive experiments on\nViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm\nVeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.\nThe codes of VeLU are publicly available on GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15051v1",
    "published_date": "2025-04-21 12:20:46 UTC",
    "updated_date": "2025-04-21 12:20:46 UTC"
  },
  {
    "arxiv_id": "2504.15046v2",
    "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision",
    "authors": [
      "Shilin Zhang",
      "Zican Hu",
      "Wenhao Wu",
      "Xinyi Xie",
      "Jianxiang Tang",
      "Chunlin Chen",
      "Daoyi Dong",
      "Yu Cheng",
      "Zhenhong Sun",
      "Zhi Wang"
    ],
    "abstract": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15046v2",
    "published_date": "2025-04-21 12:00:20 UTC",
    "updated_date": "2025-04-22 05:56:57 UTC"
  },
  {
    "arxiv_id": "2504.15044v1",
    "title": "Beyond Terabit/s Integrated Neuromorphic Photonic Processor for DSP-Free Optical Interconnects",
    "authors": [
      "Benshan Wang",
      "Qiarong Xiao",
      "Tengji Xu",
      "Li Fan",
      "Shaojie Liu",
      "Jianji Dong",
      "Junwen Zhang",
      "Chaoran Huang"
    ],
    "abstract": "The rapid expansion of generative AI drives unprecedented demands for\nhigh-performance computing. Training large-scale AI models now requires vast\ninterconnected GPU clusters across multiple data centers. Multi-scale AI\ntraining and inference demand uniform, ultra-low latency, and energy-efficient\nlinks to enable massive GPUs to function as a single cohesive unit. However,\ntraditional electrical and optical interconnects, relying on conventional\ndigital signal processors (DSPs) for signal distortion compensation,\nincreasingly fail to meet these stringent requirements. To overcome these\nlimitations, we present an integrated neuromorphic optical signal processor\n(OSP) that leverages deep reservoir computing and achieves DSP-free,\nall-optical, real-time processing. Experimentally, our OSP achieves a 100 Gbaud\nPAM4 per lane, 1.6 Tbit/s data center interconnect over a 5 km optical fiber in\nthe C-band (equivalent to over 80 km in the O-band), far exceeding the reach of\nstate-of-the-art DSP solutions, which are fundamentally constrained by\nchromatic dispersion in IMDD systems. Simultaneously, it reduces processing\nlatency by four orders of magnitude and energy consumption by three orders of\nmagnitude. Unlike DSPs, which introduce increased latency at high data rates,\nour OSP maintains consistent, ultra-low latency regardless of data rate\nscaling, making it ideal for future optical interconnects. Moreover, the OSP\nretains full optical field information for better impairment compensation and\nadapts to various modulation formats, data rates, and wavelengths. Fabricated\nusing a mature silicon photonic process, the OSP can be monolithically\nintegrated with silicon photonic transceivers, enhancing the compactness and\nreliability of all-optical interconnects. This research provides a highly\nscalable, energy-efficient, and high-speed solution, paving the way for\nnext-generation AI infrastructure.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "physics.optics",
    "comment": "22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15044v1",
    "published_date": "2025-04-21 11:56:36 UTC",
    "updated_date": "2025-04-21 11:56:36 UTC"
  },
  {
    "arxiv_id": "2504.15041v2",
    "title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification",
    "authors": [
      "Shiben Liu",
      "Huijie Fan",
      "Qiang Wang",
      "Baojie Fan",
      "Yandong Tang",
      "Liangqiong Qu"
    ],
    "abstract": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15041v2",
    "published_date": "2025-04-21 11:53:43 UTC",
    "updated_date": "2025-04-22 13:05:09 UTC"
  },
  {
    "arxiv_id": "2504.15035v1",
    "title": "SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation",
    "authors": [
      "Yue Li",
      "Weizhi Liu",
      "Dongdong Lin"
    ],
    "abstract": "The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15035v1",
    "published_date": "2025-04-21 11:43:36 UTC",
    "updated_date": "2025-04-21 11:43:36 UTC"
  },
  {
    "arxiv_id": "2504.18565v2",
    "title": "RepliBench: Evaluating the Autonomous Replication Capabilities of Language Model Agents",
    "authors": [
      "Sid Black",
      "Asa Cooper Stickland",
      "Jake Pencharz",
      "Oliver Sourbut",
      "Michael Schmatz",
      "Jay Bailey",
      "Ollie Matthews",
      "Ben Millwood",
      "Alex Remedios",
      "Alan Cooney"
    ],
    "abstract": "Uncontrollable autonomous replication of language model agents poses a\ncritical safety risk. To better understand this risk, we introduce RepliBench,\na suite of evaluations designed to measure autonomous replication capabilities.\nRepliBench is derived from a decomposition of these capabilities covering four\ncore domains: obtaining resources, exfiltrating model weights, replicating onto\ncompute, and persisting on this compute for long periods. We create 20 novel\ntask families consisting of 86 individual tasks. We benchmark 5 frontier\nmodels, and find they do not currently pose a credible threat of\nself-replication, but succeed on many components and are improving rapidly.\nModels can deploy instances from cloud compute providers, write\nself-propagating programs, and exfiltrate model weights under simple security\nsetups, but struggle to pass KYC checks or set up robust and persistent agent\ndeployments. Overall the best model we evaluated (Claude 3.7 Sonnet) has a >50%\npass@10 score on 15/20 task families, and a >50% pass@10 score for 9/20\nfamilies on the hardest variants. These findings suggest autonomous replication\ncapability could soon emerge with improvements in these remaining areas or with\nhuman assistance.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18565v2",
    "published_date": "2025-04-21 11:39:22 UTC",
    "updated_date": "2025-05-05 20:52:36 UTC"
  },
  {
    "arxiv_id": "2504.18564v1",
    "title": "DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization",
    "authors": [
      "Xinzhe Huang",
      "Kedong Xiu",
      "Tianhang Zheng",
      "Churui Zeng",
      "Wangze Ni",
      "Zhan Qiin",
      "Kui Ren",
      "Chun Chen"
    ],
    "abstract": "Recent research has focused on exploring the vulnerabilities of Large\nLanguage Models (LLMs), aiming to elicit harmful and/or sensitive content from\nLLMs. However, due to the insufficient research on dual-jailbreaking -- attacks\ntargeting both LLMs and Guardrails, the effectiveness of existing attacks is\nlimited when attempting to bypass safety-aligned LLMs shielded by guardrails.\nTherefore, in this paper, we propose DualBreach, a target-driven framework for\ndual-jailbreaking. DualBreach employs a Target-driven Initialization (TDI)\nstrategy to dynamically construct initial prompts, combined with a Multi-Target\nOptimization (MTO) method that utilizes approximate gradients to jointly adapt\nthe prompts across guardrails and LLMs, which can simultaneously save the\nnumber of queries and achieve a high dual-jailbreaking success rate. For\nblack-box guardrails, DualBreach either employs a powerful open-sourced\nguardrail or imitates the target black-box guardrail by training a proxy model,\nto incorporate guardrails into the MTO process.\n  We demonstrate the effectiveness of DualBreach in dual-jailbreaking scenarios\nthrough extensive evaluation on several widely-used datasets. Experimental\nresults indicate that DualBreach outperforms state-of-the-art methods with\nfewer queries, achieving significantly higher success rates across all\nsettings. More specifically, DualBreach achieves an average dual-jailbreaking\nsuccess rate of 93.67% against GPT-4 with Llama-Guard-3 protection, whereas the\nbest success rate achieved by other methods is 88.33%. Moreover, DualBreach\nonly uses an average of 1.77 queries per successful dual-jailbreak,\noutperforming other state-of-the-art methods. For the purpose of defense, we\npropose an XGBoost-based ensemble defensive mechanism named EGuard, which\nintegrates the strengths of multiple guardrails, demonstrating superior\nperformance compared with Llama-Guard-3.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.18564v1",
    "published_date": "2025-04-21 11:30:30 UTC",
    "updated_date": "2025-04-21 11:30:30 UTC"
  },
  {
    "arxiv_id": "2504.16130v1",
    "title": "A Self-supervised Learning Method for Raman Spectroscopy based on Masked Autoencoders",
    "authors": [
      "Pengju Ren",
      "Ri-gui Zhou",
      "Yaochong Li"
    ],
    "abstract": "Raman spectroscopy serves as a powerful and reliable tool for analyzing the\nchemical information of substances. The integration of Raman spectroscopy with\ndeep learning methods enables rapid qualitative and quantitative analysis of\nmaterials. Most existing approaches adopt supervised learning methods. Although\nsupervised learning has achieved satisfactory accuracy in spectral analysis, it\nis still constrained by costly and limited well-annotated spectral datasets for\ntraining. When spectral annotation is challenging or the amount of annotated\ndata is insufficient, the performance of supervised learning in spectral\nmaterial identification declines. In order to address the challenge of feature\nextraction from unannotated spectra, we propose a self-supervised learning\nparadigm for Raman Spectroscopy based on a Masked AutoEncoder, termed SMAE.\nSMAE does not require any spectral annotations during pre-training. By randomly\nmasking and then reconstructing the spectral information, the model learns\nessential spectral features. The reconstructed spectra exhibit certain\ndenoising properties, improving the signal-to-noise ratio (SNR) by more than\ntwofold. Utilizing the network weights obtained from masked pre-training, SMAE\nachieves clustering accuracy of over 80% for 30 classes of isolated bacteria in\na pathogenic bacterial dataset, demonstrating significant improvements compared\nto classical unsupervised methods and other state-of-the-art deep clustering\nmethods. After fine-tuning the network with a limited amount of annotated data,\nSMAE achieves an identification accuracy of 83.90% on the test set, presenting\ncompetitive performance against the supervised ResNet (83.40%).",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "eess.SP",
    "comment": "15 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16130v1",
    "published_date": "2025-04-21 10:44:06 UTC",
    "updated_date": "2025-04-21 10:44:06 UTC"
  },
  {
    "arxiv_id": "2504.14995v1",
    "title": "Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks",
    "authors": [
      "Keisuke Murota",
      "Takumi Kobori"
    ],
    "abstract": "Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "11 pages, 12 figures, 2 tables. This work has been submitted to the\n  IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.14995v1",
    "published_date": "2025-04-21 09:51:39 UTC",
    "updated_date": "2025-04-21 09:51:39 UTC"
  },
  {
    "arxiv_id": "2504.15325v1",
    "title": "Significativity Indices for Agreement Values",
    "authors": [
      "Alberto Casagrande",
      "Francesco Fabris",
      "Rossano Girometti",
      "Roberto Pagliarini"
    ],
    "abstract": "Agreement measures, such as Cohen's kappa or intraclass correlation, gauge\nthe matching between two or more classifiers. They are used in a wide range of\ncontexts from medicine, where they evaluate the effectiveness of medical\ntreatments and clinical trials, to artificial intelligence, where they can\nquantify the approximation due to the reduction of a classifier. The\nconsistency of different classifiers to a golden standard can be compared\nsimply by using the order induced by their agreement measure with respect to\nthe golden standard itself. Nevertheless, labelling an approach as good or bad\nexclusively by using the value of an agreement measure requires a scale or a\nsignificativity index. Some quality scales have been proposed in the literature\nfor Cohen's kappa, but they are mainly naive, and their boundaries are\narbitrary. This work proposes a general approach to evaluate the\nsignificativity of any agreement value between two classifiers and introduces\ntwo significativity indices: one dealing with finite data sets, the other one\nhandling classification probability distributions. Moreover, this manuscript\nconsiders the computational issues of evaluating such indices and identifies\nsome efficient algorithms to evaluate them.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "27 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15325v1",
    "published_date": "2025-04-21 09:47:53 UTC",
    "updated_date": "2025-04-21 09:47:53 UTC"
  },
  {
    "arxiv_id": "2504.14985v2",
    "title": "aiXamine: Simplified LLM Safety and Security",
    "authors": [
      "Fatih Deniz",
      "Dorde Popovic",
      "Yazan Boshmaf",
      "Euisuh Jeong",
      "Minhaj Ahmad",
      "Sanjay Chawla",
      "Issa Khalil"
    ],
    "abstract": "Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14985v2",
    "published_date": "2025-04-21 09:26:05 UTC",
    "updated_date": "2025-04-23 16:52:54 UTC"
  },
  {
    "arxiv_id": "2504.15324v1",
    "title": "A Graph Based Raman Spectral Processing Technique for Exosome Classification",
    "authors": [
      "Vuong M. Ngo",
      "Edward Bolger",
      "Stan Goodwin",
      "John O'Sullivan",
      "Dinh Viet Cuong",
      "Mark Roantree"
    ],
    "abstract": "Exosomes are small vesicles crucial for cell signaling and disease\nbiomarkers. Due to their complexity, an \"omics\" approach is preferable to\nindividual biomarkers. While Raman spectroscopy is effective for exosome\nanalysis, it requires high sample concentrations and has limited sensitivity to\nlipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these\nchallenges. In this study, we leverage Neo4j graph databases to organize 3,045\nRaman spectra of exosomes, enhancing data generalization. To further refine\nspectral analysis, we introduce a novel spectral filtering process that\nintegrates the PageRank Filter with optimal Dimensionality Reduction. This\nmethod improves feature selection, resulting in superior classification\nperformance. Specifically, the Extra Trees model, using our spectral processing\napproach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic,\nhypoglycemic, and normal exosome samples based on Raman spectra and surface,\nrespectively, with group 10-fold cross-validation. Our results show that\ngraph-based spectral filtering combined with optimal dimensionality reduction\nsignificantly improves classification accuracy by reducing noise while\npreserving key biomarker signals. This novel framework enhances Raman-based\nexosome analysis, expanding its potential for biomedical applications, disease\ndiagnostics, and biomarker discovery.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "primary_category": "q-bio.QM",
    "comment": "The 23rd International Conference on Artificial Intelligence in\n  Medicine (AIME 2025), LNAI, Springer, 11 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15324v1",
    "published_date": "2025-04-21 09:19:41 UTC",
    "updated_date": "2025-04-21 09:19:41 UTC"
  },
  {
    "arxiv_id": "2504.14964v1",
    "title": "Evaluating Code Generation of LLMs in Advanced Computer Science Problems",
    "authors": [
      "Emir Catir",
      "Robin Claesson",
      "Rodothea Myrsini Tsoupidi"
    ],
    "abstract": "Large Language Models (LLMs), such as GitHub Copilot and ChatGPT have become\npopular among programming students. Students use LLMs to assist them in\nprogramming courses, including generating source code. Previous work has\nevaluated the ability of LLMs in solving introductory-course programming\nassignments. The results have shown that LLMs are highly effective in\ngenerating code for introductory Computer Science (CS) courses. However, there\nis a gap in research on evaluating LLMs' ability to generate code that solves\nadvanced programming assignments. In this work, we evaluate the ability of four\nLLM tools to solve programming assignments from advanced CS courses in three\npopular programming languages, Java, Python, and C. We manually select 12\nproblems, three problems from introductory courses as the baseline and nine\nprogramming assignments from second- and third-year CS courses. To evaluate the\nLLM-generated code, we generate a test suite of 1000 test cases per problem and\nanalyze the program output. Our evaluation shows that although LLMs are highly\neffective in generating source code for introductory programming courses,\nsolving advanced programming assignments is more challenging. Nonetheless, in\nmany cases, LLMs identify the base problem and provide partial solutions that\nmay be useful to CS students. Furthermore, our results may provide useful\nguidance for teachers of advanced programming courses on how to design\nprogramming assignments.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14964v1",
    "published_date": "2025-04-21 08:45:23 UTC",
    "updated_date": "2025-04-21 08:45:23 UTC"
  },
  {
    "arxiv_id": "2504.14963v1",
    "title": "Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues",
    "authors": [
      "Rui Ribeiro",
      "Luísa Coheur",
      "Joao P. Carvalho"
    ],
    "abstract": "Speaker identification using voice recordings leverages unique acoustic\nfeatures, but this approach fails when only textual data is available. Few\napproaches have attempted to tackle the problem of identifying speakers solely\nfrom text, and the existing ones have primarily relied on traditional methods.\nIn this work, we explore the use of fuzzy fingerprints from large pre-trained\nmodels to improve text-based speaker identification. We integrate\nspeaker-specific tokens and context-aware modeling, demonstrating that\nconversational context significantly boosts accuracy, reaching 70.6% on the\nFriends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show\nthat fuzzy fingerprints can approximate full fine-tuning performance with fewer\nhidden units, offering improved interpretability. Finally, we analyze ambiguous\nutterances and propose a mechanism to detect speaker-agnostic lines. Our\nfindings highlight key challenges and provide insights for future improvements\nin text-based speaker identification.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted at the FUZZY IEEE 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2504.14963v1",
    "published_date": "2025-04-21 08:44:33 UTC",
    "updated_date": "2025-04-21 08:44:33 UTC"
  },
  {
    "arxiv_id": "2504.14947v1",
    "title": "Generative Semantic Communications: Principles and Practices",
    "authors": [
      "Xiaojun Yuan",
      "Haoming Ma",
      "Yinuo Huang",
      "Zhoufan Hua",
      "Yong Zuo",
      "Zhi Ding"
    ],
    "abstract": "Semantic communication leverages artificial intelligence (AI) technologies to\nextract semantic information from data for efficient transmission, theraby\nsignificantly reducing communication cost. With the evolution towards\nartificial general intelligence (AGI), the increasing demands for AGI services\npose new challenges to semantic communication. In response, we propose a new\nparadigm for AGI-driven communications, called generative semantic\ncommunication (GSC), which utilizes advanced AI technologies such as foundation\nmodels and generative models. We first describe the basic concept of GSC and\nits difference from existing semantic communications, and then introduce a\ngeneral framework of GSC, followed by two case studies to verify the advantages\nof GSC in AGI-driven applications. Finally, open challenges and new research\ndirections are discussed to stimulate this line of research and pave the way\nfor practical applications.",
    "categories": [
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14947v1",
    "published_date": "2025-04-21 08:10:59 UTC",
    "updated_date": "2025-04-21 08:10:59 UTC"
  },
  {
    "arxiv_id": "2504.14945v3",
    "title": "Learning to Reason under Off-Policy Guidance",
    "authors": [
      "Jianhao Yan",
      "Yafu Li",
      "Zican Hu",
      "Zhi Wang",
      "Ganqu Cui",
      "Xiaoye Qu",
      "Yu Cheng",
      "Yue Zhang"
    ],
    "abstract": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning with verifiable rewards~(\\textit{RLVR}).\nHowever, existing \\textit{RLVR} approaches are inherently ``on-policy'',\nlimiting learning to a model's own outputs and failing to acquire reasoning\nabilities beyond its initial capabilities. To address this issue, we introduce\n\\textbf{LUFFY} (\\textbf{L}earning to reason \\textbf{U}nder\no\\textbf{FF}-polic\\textbf{Y} guidance), a framework that augments \\textit{RLVR}\nwith off-policy reasoning traces. LUFFY dynamically balances imitation and\nexploration by combining off-policy demonstrations with on-policy rollouts\nduring training. Specifically, LUFFY combines the Mixed-Policy GRPO framework,\nwhich has a theoretically guaranteed convergence rate, alongside policy shaping\nvia regularized importance sampling to avoid superficial and rigid imitation\nduring mixed-policy training. Compared with previous RLVR methods, LUFFY\nachieves an over \\textbf{+6.4} average gain across six math benchmarks and an\nadvantage of over \\textbf{+6.2} points in out-of-distribution tasks. Most\nsignificantly, we show that LUFFY successfully trains weak models in scenarios\nwhere on-policy RLVR completely fails. These results provide compelling\nevidence that LUFFY transcends the fundamental limitations of on-policy RLVR\nand demonstrates the great potential of utilizing off-policy guidance in RLVR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2504.14945v3",
    "published_date": "2025-04-21 08:09:13 UTC",
    "updated_date": "2025-05-20 07:29:49 UTC"
  },
  {
    "arxiv_id": "2504.14936v1",
    "title": "Giving AI a voice: how does AI think it should be treated?",
    "authors": [
      "Maria Fay",
      "Frederik F. Flöther"
    ],
    "abstract": "With the astounding progress in (generative) artificial intelligence (AI),\nthere has been significant public discourse regarding regulation and ethics of\nthe technology. Is it sufficient when humans discuss this with other humans?\nOr, given that AI is increasingly becoming a viable source of inspiration for\npeople (and let alone the hypothetical possibility that the technology may at\nsome point become \"artificial general intelligence\" and/or develop\nconsciousness), should AI not join the discourse? There are new questions and\nangles that AI brings to the table that we might not have considered before -\nso let us make the key subject of this book an active participant. This chapter\ntherefore includes a brief human-AI conversation on the topic of AI rights and\nethics.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14936v1",
    "published_date": "2025-04-21 07:59:17 UTC",
    "updated_date": "2025-04-21 07:59:17 UTC"
  },
  {
    "arxiv_id": "2504.14928v1",
    "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework",
    "authors": [
      "Yao Shi",
      "Rongkeng Liang",
      "Yong Xu"
    ],
    "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14928v1",
    "published_date": "2025-04-21 07:48:20 UTC",
    "updated_date": "2025-04-21 07:48:20 UTC"
  },
  {
    "arxiv_id": "2504.14921v2",
    "title": "Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos",
    "authors": [
      "Songping Wang",
      "Hanqing Liu",
      "Yueming Lyu",
      "Xiantao Hu",
      "Ziwen He",
      "Wei Wang",
      "Caifeng Shan",
      "Liang Wang"
    ],
    "abstract": "Adversarial Training (AT) has been shown to significantly enhance adversarial\nrobustness via a min-max optimization approach. However, its effectiveness in\nvideo recognition tasks is hampered by two main challenges. First, fast\nadversarial training for video models remains largely unexplored, which\nseverely impedes its practical applications. Specifically, most video\nadversarial training methods are computationally costly, with long training\ntimes and high expenses. Second, existing methods struggle with the trade-off\nbetween clean accuracy and adversarial robustness. To address these challenges,\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\n(VFAT-WS), the first fast adversarial training method for video data.\nSpecifically, VFAT-WS incorporates the following key designs: First, it\nintegrates a straightforward yet effective temporal frequency augmentation\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\ndevises a weak-to-strong spatial-temporal consistency regularization, which\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\nLeveraging the consistency regularization, it steers the learning process from\nsimple to complex augmentations. Both of them work together to achieve a better\ntrade-off between clean accuracy and robustness. Extensive experiments on\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\nVFAT-WS achieves great improvements in adversarial robustness and corruption\nrobustness, while accelerating training by nearly 490%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "After the submission of the paper, we realized that the study still\n  has room for expansion. In order to make the research findings more profound\n  and comprehensive, we have decided to withdraw the paper so that we can\n  conduct further research and expansion",
    "pdf_url": "http://arxiv.org/pdf/2504.14921v2",
    "published_date": "2025-04-21 07:40:35 UTC",
    "updated_date": "2025-04-23 13:22:33 UTC"
  },
  {
    "arxiv_id": "2504.14915v1",
    "title": "StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models",
    "authors": [
      "Yeona Hong",
      "Hyewon Han",
      "Woo-jin Chung",
      "Hong-Goo Kang"
    ],
    "abstract": "In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14915v1",
    "published_date": "2025-04-21 07:33:27 UTC",
    "updated_date": "2025-04-21 07:33:27 UTC"
  },
  {
    "arxiv_id": "2504.14913v1",
    "title": "Guidelines for External Disturbance Factors in the Use of OCR in Real-World Environments",
    "authors": [
      "Kenji Iwata",
      "Eiki Ishidera",
      "Toshifumi Yamaai",
      "Yutaka Satoh",
      "Hiroshi Tanaka",
      "Katsuhiko Takahashi",
      "Akio Furuhata",
      "Yoshihisa Tanabe",
      "Hiroshi Matsumura"
    ],
    "abstract": "The performance of OCR has improved with the evolution of AI technology. As\nOCR continues to broaden its range of applications, the increased likelihood of\ninterference introduced by various usage environments can prevent it from\nachieving its inherent performance. This results in reduced recognition\naccuracy under certain conditions, and makes the quality control of recognition\ndevices more challenging. Therefore, to ensure that users can properly utilize\nOCR, we compiled the real-world external disturbance factors that cause\nperformance degradation, along with the resulting image degradation phenomena,\ninto an external disturbance factor table and, by also indicating how to make\nuse of it, organized them into guidelines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.5.2; I.5.m"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14913v1",
    "published_date": "2025-04-21 07:32:28 UTC",
    "updated_date": "2025-04-21 07:32:28 UTC"
  },
  {
    "arxiv_id": "2504.14904v1",
    "title": "VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform",
    "authors": [
      "Xingyu Lu",
      "Tianke Zhang",
      "Chang Meng",
      "Xiaobei Wang",
      "Jinpeng Wang",
      "YiFan Zhang",
      "Shisong Tang",
      "Changyi Liu",
      "Haojie Ding",
      "Kaiyu Jiang",
      "Kaiyu Tang",
      "Bin Wen",
      "Hai-Tao Zheng",
      "Fan Yang",
      "Tingting Gao",
      "Di Zhang",
      "Kun Gai"
    ],
    "abstract": "Exponentially growing short video platforms (SVPs) face significant\nchallenges in moderating content detrimental to users' mental health,\nparticularly for minors. The dissemination of such content on SVPs can lead to\ncatastrophic societal consequences. Although substantial efforts have been\ndedicated to moderating such content, existing methods suffer from critical\nlimitations: (1) Manual review is prone to human bias and incurs high\noperational costs. (2) Automated methods, though efficient, lack nuanced\ncontent understanding, resulting in lower accuracy. (3) Industrial moderation\nregulations struggle to adapt to rapidly evolving trends due to long update\ncycles. In this paper, we annotate the first SVP content moderation benchmark\nwith authentic user/reviewer feedback to fill the absence of benchmark in this\nfield. Then we evaluate various methods on the benchmark to verify the\nexistence of the aforementioned limitations. We further propose our common-law\ncontent moderation framework named KuaiMod to address these challenges. KuaiMod\nconsists of three components: training data construction, offline adaptation,\nand online deployment & refinement. Leveraging large vision language model\n(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video\ntoxicity based on sparse user feedback and fosters dynamic moderation policy\nwith rapid update speed and high accuracy. Offline experiments and large-scale\nonline A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the\nbest moderation performance on our benchmark. The deployment of KuaiMod reduces\nthe user reporting rate by 20% and its application in video recommendation\nincreases both Daily Active User (DAU) and APP Usage Time (AUT) on several\nKuaishou scenarios. We have open-sourced our benchmark at\nhttps://kuaimod.github.io.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.SI",
    "comment": "20 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14904v1",
    "published_date": "2025-04-21 07:20:19 UTC",
    "updated_date": "2025-04-21 07:20:19 UTC"
  },
  {
    "arxiv_id": "2504.16129v3",
    "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning",
    "authors": [
      "Junwei Liao",
      "Muning Wen",
      "Jun Wang",
      "Weinan Zhang"
    ],
    "abstract": "LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in\naddressing complex, agentic tasks, from generating high-quality presentation\nslides to even conducting sophisticated scientific research. Meanwhile, RL has\nbeen widely recognized for its effectiveness in enhancing agent intelligence,\nbut limited research has investigated the fine-tuning of LaMAS using\nfoundational RL techniques. Moreover, the direct application of MARL methods to\nLaMAS introduces significant challenges, stemming from the unique\ncharacteristics and mechanisms inherent to LaMAS. To address these challenges,\nthis article presents a comprehensive study of LLM-based MARL and proposes a\nnovel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We\nintroduce a brand-new POMDP called Flex-POMDP, which aligns with the LaMAS\noptimization in real-world applications and a universal algorithmic framework\ntailored specifically for LaMAS, outlining the conceptual foundations, key\ndistinctions, and practical implementation strategies. We review the evolution\nfrom RL to RFT, setting the stage for a parallel analysis in the multi-agent\ndomain. In the context of LaMAS, we elucidate critical differences between MARL\nand MARFT. These differences motivate a transition toward a LaMAS-oriented\nformulation of RFT. Central to this work is a robust and scalable MARFT\nframework. We detail the core algorithm and provide a complete, open-source\nimplementation to facilitate adoption and further research. The latter sections\nof the paper explore real-world application perspectives and opening challenges\nin MARFT. By bridging theoretical underpinnings with practical methodologies,\nthis work serves as a roadmap for researchers seeking to advance MARFT toward\nresilient and adaptive solutions in agentic systems. Our implementation of the\nproposed framework is publicly available at:\nhttps://github.com/jwliao-ai/MARFT.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "40 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.16129v3",
    "published_date": "2025-04-21 07:03:54 UTC",
    "updated_date": "2025-05-17 17:25:24 UTC"
  },
  {
    "arxiv_id": "2504.16128v1",
    "title": "Hybrid Knowledge Transfer through Attention and Logit Distillation for On-Device Vision Systems in Agricultural IoT",
    "authors": [
      "Stanley Mugisha",
      "Rashid Kisitu",
      "Florence Tushabe"
    ],
    "abstract": "Integrating deep learning applications into agricultural IoT systems faces a\nserious challenge of balancing the high accuracy of Vision Transformers (ViTs)\nwith the efficiency demands of resource-constrained edge devices. Large\ntransformer models like the Swin Transformers excel in plant disease\nclassification by capturing global-local dependencies. However, their\ncomputational complexity (34.1 GFLOPs) limits applications and renders them\nimpractical for real-time on-device inference. Lightweight models such as\nMobileNetV3 and TinyML would be suitable for on-device inference but lack the\nrequired spatial reasoning for fine-grained disease detection. To bridge this\ngap, we propose a hybrid knowledge distillation framework that synergistically\ntransfers logit and attention knowledge from a Swin Transformer teacher to a\nMobileNetV3 student model. Our method includes the introduction of adaptive\nattention alignment to resolve cross-architecture mismatch (resolution,\nchannels) and a dual-loss function optimizing both class probabilities and\nspatial focus. On the lantVillage-Tomato dataset (18,160 images), the distilled\nMobileNetV3 attains 92.4% accuracy relative to 95.9% for Swin-L but at an 95%\nreduction on PC and < 82% in inference latency on IoT devices. (23ms on PC CPU\nand 86ms/image on smartphone CPUs). Key innovations include IoT-centric\nvalidation metrics (13 MB memory, 0.22 GFLOPs) and dynamic resolution-matching\nattention maps. Comparative experiments show significant improvements over\nstandalone CNNs and prior distillation methods, with a 3.5% accuracy gain over\nMobileNetV3 baselines. Significantly, this work advances real-time,\nenergy-efficient crop monitoring in precision agriculture and demonstrates how\nwe can attain ViT-level diagnostic precision on edge devices. Code and models\nwill be made available for replication after acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "I.2.10; I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages and 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16128v1",
    "published_date": "2025-04-21 06:56:41 UTC",
    "updated_date": "2025-04-21 06:56:41 UTC"
  },
  {
    "arxiv_id": "2504.14889v1",
    "title": "Latent Bayesian Optimization via Autoregressive Normalizing Flows",
    "authors": [
      "Seunghun Lee",
      "Jinyoung Park",
      "Jaewon Chu",
      "Minseo Yoon",
      "Hyunwoo J. Kim"
    ],
    "abstract": "Bayesian Optimization (BO) has been recognized for its effectiveness in\noptimizing expensive and complex objective functions. Recent advancements in\nLatent Bayesian Optimization (LBO) have shown promise by integrating generative\nmodels such as variational autoencoders (VAEs) to manage the complexity of\nhigh-dimensional and structured data spaces. However, existing LBO approaches\noften suffer from the value discrepancy problem, which arises from the\nreconstruction gap between input and latent spaces. This value discrepancy\nproblem propagates errors throughout the optimization process, leading to\nsuboptimal outcomes. To address this issue, we propose a Normalizing Flow-based\nBayesian Optimization (NF-BO), which utilizes normalizing flow as a generative\nmodel to establish one-to-one encoding function from the input space to the\nlatent space, along with its left-inverse decoding function, eliminating the\nreconstruction gap. Specifically, we introduce SeqFlow, an autoregressive\nnormalizing flow for sequence data. In addition, we develop a new candidate\nsampling strategy that dynamically adjusts the exploration probability for each\ntoken based on its importance. Through extensive experiments, our NF-BO method\ndemonstrates superior performance in molecule generation tasks, significantly\noutperforming both traditional and recent LBO approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14889v1",
    "published_date": "2025-04-21 06:36:09 UTC",
    "updated_date": "2025-04-21 06:36:09 UTC"
  },
  {
    "arxiv_id": "2504.14879v1",
    "title": "Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder Versus ViT-Encoder",
    "authors": [
      "Hassan Wasswa",
      "Aziida Nanyonga",
      "Timothy Lynar"
    ],
    "abstract": "The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14879v1",
    "published_date": "2025-04-21 06:15:07 UTC",
    "updated_date": "2025-04-21 06:15:07 UTC"
  },
  {
    "arxiv_id": "2504.14875v1",
    "title": "ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams",
    "authors": [
      "Chris Dongjoo Kim",
      "Jihwan Moon",
      "Sangwoo Moon",
      "Heeseung Yun",
      "Sihaeng Lee",
      "Aniruddha Kembhavi",
      "Soonyoung Lee",
      "Gunhee Kim",
      "Sangho Lee",
      "Christopher Clark"
    ],
    "abstract": "The rapid growth of video-text data presents challenges in storage and\ncomputation during training. Online learning, which processes streaming data in\nreal-time, offers a promising solution to these issues while also allowing\nswift adaptations in scenarios demanding real-time responsiveness. One strategy\nto enhance the efficiency and effectiveness of learning involves identifying\nand prioritizing data that enhances performance on target downstream tasks. We\npropose Relevance and Specificity-based online filtering framework (ReSpec)\nthat selects data based on four criteria: (i) modality alignment for clean\ndata, (ii) task relevance for target focused data, (iii) specificity for\ninformative and detailed data, and (iv) efficiency for low-latency processing.\nRelevance is determined by the probabilistic alignment of incoming data with\ndownstream tasks, while specificity employs the distance to a root embedding\nrepresenting the least specific data as an efficient proxy for informativeness.\nBy establishing reference points from target task data, ReSpec filters incoming\ndata in real-time, eliminating the need for extensive storage and compute.\nEvaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains\nstate-of-the-art performance on five zeroshot video retrieval tasks, using as\nlittle as 5% of the data while incurring minimal compute. The source code is\navailable at https://github.com/cdjkim/ReSpec.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2504.14875v1",
    "published_date": "2025-04-21 06:02:03 UTC",
    "updated_date": "2025-04-21 06:02:03 UTC"
  },
  {
    "arxiv_id": "2504.14870v1",
    "title": "OTC: Optimal Tool Calls via Reinforcement Learning",
    "authors": [
      "Hongru Wang",
      "Cheng Qian",
      "Wanjun Zhong",
      "Xiusi Chen",
      "Jiahao Qiu",
      "Shijue Huang",
      "Bowen Jin",
      "Mengdi Wang",
      "Kam-Fai Wong",
      "Heng Ji"
    ],
    "abstract": "Tool-integrated reasoning (TIR) augments large language models (LLMs) with\nthe ability to invoke external tools, such as search engines and code\ninterpreters, to solve tasks beyond the capabilities of language-only\nreasoning. While reinforcement learning (RL) has shown promise in improving TIR\nby optimizing final answer correctness, existing approaches often overlook the\nefficiency and cost associated with tool usage. This can lead to suboptimal\nbehavior, including excessive tool calls that increase computational and\nfinancial overhead, or insufficient tool use that compromises answer quality.\nIn this work, we propose Optimal Tool Call-controlled Policy Optimization\n(OTC-PO), a simple yet effective RL-based framework that encourages models to\nproduce accurate answers with minimal tool calls. Our method introduces a\ntool-integrated reward that jointly considers correctness and tool efficiency,\npromoting high tool productivity. We instantiate this framework within both\nProximal Policy Optimization (PPO) and Group Relative Preference Optimization\n(GRPO), resulting in OTC-PPO and OTC-GRPO. Experiments with Qwen-2.5 and\nQwen-Math across multiple QA benchmarks show that our approach reduces tool\ncalls by up to 73.1\\% and improves tool productivity by up to 229.4\\%, while\nmaintaining comparable answer accuracy. To the best of our knowledge, this is\nthe first RL-based framework that explicitly optimizes tool-use efficiency in\nTIR.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14870v1",
    "published_date": "2025-04-21 05:40:05 UTC",
    "updated_date": "2025-04-21 05:40:05 UTC"
  },
  {
    "arxiv_id": "2504.14860v1",
    "title": "Bridge the Gap: From Weak to Full Supervision for Temporal Action Localization with PseudoFormer",
    "authors": [
      "Ziyi Liu",
      "Yangcen Liu"
    ],
    "abstract": "Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025: IEEE Conference on Computer Vision and Pattern Recognition",
    "pdf_url": "http://arxiv.org/pdf/2504.14860v1",
    "published_date": "2025-04-21 05:00:07 UTC",
    "updated_date": "2025-04-21 05:00:07 UTC"
  },
  {
    "arxiv_id": "2504.14858v3",
    "title": "AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning",
    "authors": [
      "Jiaqi Wei",
      "Hao Zhou",
      "Xiang Zhang",
      "Di Zhang",
      "Zijie Qiu",
      "Wei Wei",
      "Jinzhe Li",
      "Wanli Ouyang",
      "Siqi Sun"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has become a widely adopted paradigm for\nenabling knowledge-grounded large language models (LLMs). However, standard RAG\npipelines often fail to ensure that model reasoning remains consistent with the\nevidence retrieved, leading to factual inconsistencies or unsupported\nconclusions. In this work, we reinterpret RAG as Retrieval-Augmented Reasoning\nand identify a central but underexplored problem: \\textit{Reasoning\nMisalignment}-the divergence between an LLM's internal reasoning trajectory and\nthe evidential constraints provided by retrieval. To address this issue, we\npropose \\textsc{AlignRAG}, a novel iterative framework grounded in\nCritique-Driven Alignment (CDA). At the heart of \\textsc{AlignRAG} lies a\n\\textit{contrastive critique synthesis} mechanism that generates\nretrieval-sensitive critiques while mitigating self-bias. This mechanism trains\na dedicated retrieval-augmented \\textit{Critic Language Model (CLM)} using\nlabeled critiques that distinguish between evidence-aligned and misaligned\nreasoning. Alignment signals for supervision are obtained through\nself-supervised or externally guided labeling strategies. The resulting CLM is\nexplicitly optimized for evidence sensitivity, enabling it to detect and revise\nreasoning errors during inference without relying solely on self-generated\nfeedback. Empirical evaluations show that our 8B-parameter CLM improves\nperformance over the Self-Refine baseline by 12.1\\% on out-of-domain tasks and\noutperforms a standard 72B-parameter CLM by 2.2\\%, while remaining compatible\nwith existing RAG architectures as a plug-and-play module. Overall, AlignRAG\noffers a principled solution for aligning model reasoning with retrieved\nevidence, substantially improving the factual reliability and robustness of RAG\nsystems.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14858v3",
    "published_date": "2025-04-21 04:56:47 UTC",
    "updated_date": "2025-05-21 03:51:20 UTC"
  },
  {
    "arxiv_id": "2504.14848v1",
    "title": "Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation",
    "authors": [
      "Yunpu Zhao",
      "Rui Zhang",
      "Junbin Xiao",
      "Ruibo Hou",
      "Jiaming Guo",
      "Zihao Zhang",
      "Yifan Hao",
      "Yunji Chen"
    ],
    "abstract": "Vision-language models (VLMs) excel in various multimodal tasks but\nfrequently suffer from poor calibration, resulting in misalignment between\ntheir verbalized confidence and response correctness. This miscalibration\nundermines user trust, especially when models confidently provide incorrect or\nfabricated information. In this work, we propose a novel Confidence Calibration\nthrough Semantic Perturbation (CSP) framework to improve the calibration of\nverbalized confidence for VLMs in response to object-centric queries. We first\nintroduce a perturbed dataset where Gaussian noise is applied to the key object\nregions to simulate visual uncertainty at different confidence levels,\nestablishing an explicit mapping between visual ambiguity and confidence\nlevels. We further enhance calibration through a two-stage training process\ncombining supervised fine-tuning on the perturbed dataset with subsequent\npreference optimization. Extensive experiments on popular benchmarks\ndemonstrate that our method significantly improves the alignment between\nverbalized confidence and response correctness while maintaining or enhancing\noverall task performance. These results highlight the potential of semantic\nperturbation as a practical tool for improving the reliability and\ninterpretability of VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14848v1",
    "published_date": "2025-04-21 04:01:22 UTC",
    "updated_date": "2025-04-21 04:01:22 UTC"
  },
  {
    "arxiv_id": "2504.18563v1",
    "title": "Backdoor Defense in Diffusion Models via Spatial Attention Unlearning",
    "authors": [
      "Abha Jha",
      "Ashwath Vaithinathan Aravindan",
      "Matthew Salaway",
      "Atharva Sandeep Bhide",
      "Duygu Nur Yaldiz"
    ],
    "abstract": "Text-to-image diffusion models are increasingly vulnerable to backdoor\nattacks, where malicious modifications to the training data cause the model to\ngenerate unintended outputs when specific triggers are present. While\nclassification models have seen extensive development of defense mechanisms,\ngenerative models remain largely unprotected due to their high-dimensional\noutput space, which complicates the detection and mitigation of subtle\nperturbations. Defense strategies for diffusion models, in particular, remain\nunder-explored. In this work, we propose Spatial Attention Unlearning (SAU), a\nnovel technique for mitigating backdoor attacks in diffusion models. SAU\nleverages latent space manipulation and spatial attention mechanisms to isolate\nand remove the latent representation of backdoor triggers, ensuring precise and\nefficient removal of malicious effects. We evaluate SAU across various types of\nbackdoor attacks, including pixel-based and style-based triggers, and\ndemonstrate its effectiveness in achieving 100% trigger removal accuracy.\nFurthermore, SAU achieves a CLIP score of 0.7023, outperforming existing\nmethods while preserving the model's ability to generate high-quality,\nsemantically aligned images. Our results show that SAU is a robust, scalable,\nand practical solution for securing text-to-image diffusion models against\nbackdoor attacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.18563v1",
    "published_date": "2025-04-21 04:00:19 UTC",
    "updated_date": "2025-04-21 04:00:19 UTC"
  },
  {
    "arxiv_id": "2504.14839v1",
    "title": "Exploring $\\ell_0$ Sparsification for Inference-free Sparse Retrievers",
    "authors": [
      "Xinjie Shen",
      "Zhichao Geng",
      "Yang Yang"
    ],
    "abstract": "With increasing demands for efficiency, information retrieval has developed a\nbranch of sparse retrieval, further advancing towards inference-free retrieval\nwhere the documents are encoded during indexing time and there is no\nmodel-inference for queries. Existing sparse retrieval models rely on FLOPS\nregularization for sparsification, while this mechanism was originally designed\nfor Siamese encoders, it is considered to be suboptimal in inference-free\nscenarios which is asymmetric. Previous attempts to adapt FLOPS for\ninference-free scenarios have been limited to rule-based methods, leaving the\npotential of sparsification approaches for inference-free retrieval models\nlargely unexplored. In this paper, we explore $\\ell_0$ inspired sparsification\nmanner for inference-free retrievers. Through comprehensive out-of-domain\nevaluation on the BEIR benchmark, our method achieves state-of-the-art\nperformance among inference-free sparse retrieval models and is comparable to\nleading Siamese sparse retrieval models. Furthermore, we provide insights into\nthe trade-off between retrieval effectiveness and computational efficiency,\ndemonstrating practical value for real-world applications.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14839v1",
    "published_date": "2025-04-21 03:40:43 UTC",
    "updated_date": "2025-04-21 03:40:43 UTC"
  },
  {
    "arxiv_id": "2504.14838v1",
    "title": "Establishing Reliability Metrics for Reward Models in Large Language Models",
    "authors": [
      "Yizhou Chen",
      "Yawen Liu",
      "Xuesi Wang",
      "Qingtao Yu",
      "Guangda Huzhang",
      "Anxiang Zeng",
      "Han Yu",
      "Zhiming Zhou"
    ],
    "abstract": "The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14838v1",
    "published_date": "2025-04-21 03:39:33 UTC",
    "updated_date": "2025-04-21 03:39:33 UTC"
  },
  {
    "arxiv_id": "2504.14832v1",
    "title": "Protecting Your Voice: Temporal-aware Robust Watermarking",
    "authors": [
      "Yue Li",
      "Weizhi Liu",
      "Dongdong Lin"
    ],
    "abstract": "The rapid advancement of generative models has led to the synthesis of\nreal-fake ambiguous voices. To erase the ambiguity, embedding watermarks into\nthe frequency-domain features of synthesized voices has become a common\nroutine. However, the robustness achieved by choosing the frequency domain\noften comes at the expense of fine-grained voice features, leading to a loss of\nfidelity. Maximizing the comprehensive learning of time-domain features to\nenhance fidelity while maintaining robustness, we pioneer a\n\\textbf{\\underline{t}}emporal-aware\n\\textbf{\\underline{r}}ob\\textbf{\\underline{u}}st\nwat\\textbf{\\underline{e}}rmarking (\\emph{True}) method for protecting the\nspeech and singing voice.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14832v1",
    "published_date": "2025-04-21 03:23:10 UTC",
    "updated_date": "2025-04-21 03:23:10 UTC"
  },
  {
    "arxiv_id": "2505.03764v1",
    "title": "Ultra-Low-Power Spiking Neurons in 7 nm FinFET Technology: A Comparative Analysis of Leaky Integrate-and-Fire, Morris-Lecar, and Axon-Hillock Architectures",
    "authors": [
      "Logan Larsh",
      "Raiyan Siddique",
      "Sarah Sharif Yaser Mike Banad"
    ],
    "abstract": "Neuromorphic computing aims to replicate the brain's remarkable energy\nefficiency and parallel processing capabilities for large-scale artificial\nintelligence applications. In this work, we present a comprehensive comparative\nstudy of three spiking neuron circuit architectures-Leaky-Integrate-and-Fire\n(LIF), Morris-Lecar (ML), and Axon-Hillock (AH)-implemented in a 7 nm FinFET\ntechnology. Through extensive SPICE simulations, we explore the optimization of\nspiking frequency, energy per spike, and static power consumption. Our results\nshow that the AH design achieves the highest throughput, demonstrating\nmulti-gigahertz firing rates (up to 3 GHz) with attojoule energy costs. By\ncontrast, the ML architecture excels in subthreshold to near-threshold regimes,\noffering robust low-power operation (as low as 0.385 aJ/spike) and biological\nbursting behavior. Although LIF benefits from a decoupled current mirror for\nhigh-frequency operation, it exhibits slightly higher static leakage compared\nto ML and AH at elevated supply voltages. Comparisons with previous node\nimplementations (22 nm planar, 28 nm) reveal that 7 nm FinFETs can drastically\nboost energy efficiency and speed albeit at the cost of increased subthreshold\nleakage in deep subthreshold regions. By quantifying design trade-offs for each\nneuron architecture, our work provides a roadmap for optimizing spiking neuron\ncircuits in advanced nanoscale technologies to deliver neuromorphic hardware\ncapable of both ultra-low-power operation and high computational throughput.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03764v1",
    "published_date": "2025-04-21 03:06:39 UTC",
    "updated_date": "2025-04-21 03:06:39 UTC"
  },
  {
    "arxiv_id": "2504.15323v1",
    "title": "HyperFlow: Gradient-Free Emulation of Few-Shot Fine-Tuning",
    "authors": [
      "Donggyun Kim",
      "Chanwoo Kim",
      "Seunghoon Hong"
    ],
    "abstract": "While test-time fine-tuning is beneficial in few-shot learning, the need for\nmultiple backpropagation steps can be prohibitively expensive in real-time or\nlow-resource scenarios. To address this limitation, we propose an approach that\nemulates gradient descent without computing gradients, enabling efficient\ntest-time adaptation. Specifically, we formulate gradient descent as an Euler\ndiscretization of an ordinary differential equation (ODE) and train an\nauxiliary network to predict the task-conditional drift using only the few-shot\nsupport set. The adaptation then reduces to a simple numerical integration\n(e.g., via the Euler method), which requires only a few forward passes of the\nauxiliary network -- no gradients or forward passes of the target model are\nneeded. In experiments on cross-domain few-shot classification using the\nMeta-Dataset and CDFSL benchmarks, our method significantly improves\nout-of-domain performance over the non-fine-tuned baseline while incurring only\n6\\% of the memory cost and 0.02\\% of the computation time of standard\nfine-tuning, thus establishing a practical middle ground between direct\ntransfer and fully fine-tuned approaches.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15323v1",
    "published_date": "2025-04-21 03:04:38 UTC",
    "updated_date": "2025-04-21 03:04:38 UTC"
  },
  {
    "arxiv_id": "2504.15322v1",
    "title": "How to systematically develop an effective AI-based bias correction model?",
    "authors": [
      "Xiao Zhou",
      "Yuze Sun",
      "Jie Wu",
      "Xiaomeng Huang"
    ],
    "abstract": "This study introduces ReSA-ConvLSTM, an artificial intelligence (AI)\nframework for systematic bias correction in numerical weather prediction (NWP).\nWe propose three innovations by integrating dynamic climatological\nnormalization, ConvLSTM with temporal causality constraints, and residual\nself-attention mechanisms. The model establishes a physics-aware nonlinear\nmapping between ECMWF forecasts and ERA5 reanalysis data. Using 41 years\n(1981-2021) of global atmospheric data, the framework reduces systematic biases\nin 2-m air temperature (T2m), 10-m winds (U10/V10), and sea-level pressure\n(SLP), achieving up to 20% RMSE reduction over 1-7 day forecasts compared to\noperational ECMWF outputs. The lightweight architecture (10.6M parameters)\nenables efficient generalization to multiple variables and downstream\napplications, reducing retraining time by 85% for cross-variable correction\nwhile improving ocean model skill through bias-corrected boundary conditions.\nThe ablation experiments demonstrate that our innovations significantly improve\nthe model's correction performance, suggesting that incorporating variable\ncharacteristics into the model helps enhance forecasting skills.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15322v1",
    "published_date": "2025-04-21 03:02:42 UTC",
    "updated_date": "2025-04-21 03:02:42 UTC"
  },
  {
    "arxiv_id": "2504.14825v1",
    "title": "ECViT: Efficient Convolutional Vision Transformer with Local-Attention and Multi-scale Stages",
    "authors": [
      "Zhoujie Qian"
    ],
    "abstract": "Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14825v1",
    "published_date": "2025-04-21 03:00:17 UTC",
    "updated_date": "2025-04-21 03:00:17 UTC"
  },
  {
    "arxiv_id": "2504.14815v1",
    "title": "What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale",
    "authors": [
      "Xiaoyong Yuan",
      "Xiaolong Ma",
      "Linke Guo",
      "Lan Zhang"
    ],
    "abstract": "Diffusion models (DMs) have revolutionized text-to-image generation, enabling\nthe creation of highly realistic and customized images from text prompts. With\nthe rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users\ncan now customize powerful pre-trained models using minimal computational\nresources. However, the widespread sharing of fine-tuned DMs on open platforms\nraises growing ethical and legal concerns, as these models may inadvertently or\ndeliberately generate sensitive or unauthorized content, such as copyrighted\nmaterial, private individuals, or harmful content. Despite the increasing\nregulatory attention on generative AI, there are currently no practical tools\nfor systematically auditing these models before deployment. In this paper, we\naddress the problem of concept auditing: determining whether a fine-tuned DM\nhas learned to generate a specific target concept. Existing approaches\ntypically rely on prompt-based input crafting and output-based image\nclassification but suffer from critical limitations, including prompt\nuncertainty, concept drift, and poor scalability. To overcome these challenges,\nwe introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric\nconcept auditing framework. By treating the DM as the object of inspection,\nPAIA enables direct analysis of internal model behavior, bypassing the need for\noptimized prompts or generated images. We evaluate PAIA on 320 controlled model\nand 690 real-world community models sourced from a public DM sharing platform.\nPAIA achieves over 90% detection accuracy while reducing auditing time by\n18-40x compared to existing baselines. To our knowledge, PAIA is the first\nscalable and practical solution for pre-deployment concept auditing of\ndiffusion models, providing a practical foundation for safer and more\ntransparent diffusion model sharing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14815v1",
    "published_date": "2025-04-21 02:44:59 UTC",
    "updated_date": "2025-04-21 02:44:59 UTC"
  },
  {
    "arxiv_id": "2504.14810v1",
    "title": "DONOD: Robust and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning",
    "authors": [
      "Jucheng Hu",
      "Surong Yang",
      "Dongzhan Zhou",
      "Lijun Wu"
    ],
    "abstract": "Ad-hoc instruction fine-tuning of large language models (LLMs) is widely\nadopted for domain-specific adaptation. While domain-specific supervised\nfine-tuning (SFT) is effective and efficient, it often weakens cross-domain\ngeneralization and struggles with noisy training data. To address these\nchallenges, we propose DONOD, a lightweight model-intrinsic data pruning\nmethod. Our approach evaluates data using two model-parameter-based metrics:\nDelta of Norm (DON), which captures the cumulative influence on model weights,\nand Norm of Delta (NOD), which quantifies weight instability. Moreover, by\nemploying the Technique for Order of Preference by Similarity to Ideal Solution\n(TOPSIS) algorithm, we effectively filter noisy, unlearnable, and\ngeneralization-harming samples without relying on auxiliary models during the\nSFT process. Experiments on mathematical tasks demonstrate that data selected\nby DONOD achieve superior fine-tuning efficiency and improved robustness\nagainst noisy data. By filtering out 70% of the full dataset, we improve\ntarget-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile,\nour selected data present superior cross-architecture generalization. Data\npruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger\nmodels (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD\ndemonstrates comparable or superior performance while remaining\ndataset-agnostic, enabling broader applicability.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14810v1",
    "published_date": "2025-04-21 02:25:03 UTC",
    "updated_date": "2025-04-21 02:25:03 UTC"
  },
  {
    "arxiv_id": "2504.14808v1",
    "title": "On Self-improving Token Embeddings",
    "authors": [
      "Mario M. Kubek",
      "Shiraj Pokharel",
      "Thomas Böhme",
      "Emma L. McDaniel",
      "Herwig Unger",
      "Armin R. Mikler"
    ],
    "abstract": "This article introduces a novel and fast method for refining pre-trained\nstatic word or, more generally, token embeddings. By incorporating the\nembeddings of neighboring tokens in text corpora, it continuously updates the\nrepresentation of each token, including those without pre-assigned embeddings.\nThis approach effectively addresses the out-of-vocabulary problem, too.\nOperating independently of large language models and shallow neural networks,\nit enables versatile applications such as corpus exploration, conceptual\nsearch, and word sense disambiguation. The method is designed to enhance token\nrepresentations within topically homogeneous corpora, where the vocabulary is\nrestricted to a specific domain, resulting in more meaningful embeddings\ncompared to general-purpose pre-trained vectors. As an example, the methodology\nis applied to explore storm events and their impacts on infrastructure and\ncommunities using narratives from a subset of the NOAA Storm Events database.\nThe article also demonstrates how the approach improves the representation of\nstorm-related terms over time, providing valuable insights into the evolving\nnature of disaster narratives.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "68T50, 68T07",
      "I.2.6; I.2.7; H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 4 figures, 3 tables, accepted at the 2025 25th\n  International Conference on Innovations for Community Services (I4CS), June\n  11 - 13, Munich, Germany, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14808v1",
    "published_date": "2025-04-21 02:17:19 UTC",
    "updated_date": "2025-04-21 02:17:19 UTC"
  },
  {
    "arxiv_id": "2504.14805v1",
    "title": "Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment",
    "authors": [
      "Jinwoo Choi",
      "Seung-Woo Seo"
    ],
    "abstract": "Reinforcement learning (RL) has made significant progress in various domains,\nbut scaling it to long-horizon tasks with complex decision-making remains\nchallenging. Skill learning attempts to address this by abstracting actions\ninto higher-level behaviors. However, current approaches often fail to\nrecognize semantically similar behaviors as the same skill and use fixed skill\nlengths, limiting flexibility and generalization. To address this, we propose\nDynamic Contrastive Skill Learning (DCSL), a novel framework that redefines\nskill representation and learning. DCSL introduces three key ideas:\nstate-transition based skill representation, skill similarity function\nlearning, and dynamic skill length adjustment. By focusing on state transitions\nand leveraging contrastive learning, DCSL effectively captures the semantic\ncontext of behaviors and adapts skill lengths to match the appropriate temporal\nextent of behaviors. Our approach enables more flexible and adaptive skill\nextraction, particularly in complex or noisy datasets, and demonstrates\ncompetitive performance compared to existing methods in task completion and\nefficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025; 23 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14805v1",
    "published_date": "2025-04-21 02:11:39 UTC",
    "updated_date": "2025-04-21 02:11:39 UTC"
  },
  {
    "arxiv_id": "2504.14804v1",
    "title": "Automatic Evaluation Metrics for Document-level Translation: Overview, Challenges and Trends",
    "authors": [
      "Jiaxin GUO",
      "Xiaoyu Chen",
      "Zhiqiang Rao",
      "Jinlong Yang",
      "Zongyao Li",
      "Hengchao Shang",
      "Daimeng Wei",
      "Hao Yang"
    ],
    "abstract": "With the rapid development of deep learning technologies, the field of\nmachine translation has witnessed significant progress, especially with the\nadvent of large language models (LLMs) that have greatly propelled the\nadvancement of document-level translation. However, accurately evaluating the\nquality of document-level translation remains an urgent issue. This paper first\nintroduces the development status of document-level translation and the\nimportance of evaluation, highlighting the crucial role of automatic evaluation\nmetrics in reflecting translation quality and guiding the improvement of\ntranslation systems. It then provides a detailed analysis of the current state\nof automatic evaluation schemes and metrics, including evaluation methods with\nand without reference texts, as well as traditional metrics, Model-based\nmetrics and LLM-based metrics. Subsequently, the paper explores the challenges\nfaced by current evaluation methods, such as the lack of reference diversity,\ndependence on sentence-level alignment information, and the bias, inaccuracy,\nand lack of interpretability of the LLM-as-a-judge method. Finally, the paper\nlooks ahead to the future trends in evaluation methods, including the\ndevelopment of more user-friendly document-level evaluation methods and more\nrobust LLM-as-a-judge methods, and proposes possible research directions, such\nas reducing the dependency on sentence-level information, introducing\nmulti-level and multi-granular evaluation approaches, and training models\nspecifically for machine translation evaluation. This study aims to provide a\ncomprehensive analysis of automatic evaluation for document-level translation\nand offer insights into future developments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14804v1",
    "published_date": "2025-04-21 02:08:42 UTC",
    "updated_date": "2025-04-21 02:08:42 UTC"
  },
  {
    "arxiv_id": "2504.14797v1",
    "title": "Automated Duplicate Bug Report Detection in Large Open Bug Repositories",
    "authors": [
      "Clare E. Laney",
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "Many users and contributors of large open-source projects report software\ndefects or enhancement requests (known as bug reports) to the issue-tracking\nsystems. However, they sometimes report issues that have already been reported.\nFirst, they may not have time to do sufficient research on existing bug\nreports. Second, they may not possess the right expertise in that specific area\nto realize that an existing bug report is essentially elaborating on the same\nmatter, perhaps with a different wording. In this paper, we propose a novel\napproach based on machine learning methods that can automatically detect\nduplicate bug reports in an open bug repository based on the textual data in\nthe reports. We present six alternative methods: Topic modeling, Gaussian Naive\nBayes, deep learning, time-based organization, clustering, and summarization\nusing a generative pre-trained transformer large language model. Additionally,\nwe introduce a novel threshold-based approach for duplicate identification, in\ncontrast to the conventional top-k selection method that has been widely used\nin the literature. Our approach demonstrates promising results across all the\nproposed methods, achieving accuracy rates ranging from the high 70%'s to the\nlow 90%'s. We evaluated our methods on a public dataset of issues belonging to\nan Eclipse open-source project.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "IEEE COMPSAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14797v1",
    "published_date": "2025-04-21 01:55:54 UTC",
    "updated_date": "2025-04-21 01:55:54 UTC"
  },
  {
    "arxiv_id": "2504.14783v2",
    "title": "How Effective Can Dropout Be in Multiple Instance Learning ?",
    "authors": [
      "Wenhui Zhu",
      "Peijie Qiu",
      "Xiwen Chen",
      "Zhangsihao Yang",
      "Aristeidis Sotiras",
      "Abolfazl Razi",
      "Yalin Wang"
    ],
    "abstract": "Multiple Instance Learning (MIL) is a popular weakly-supervised method for\nvarious applications, with a particular interest in histological whole slide\nimage (WSI) classification. Due to the gigapixel resolution of WSI,\napplications of MIL in WSI typically necessitate a two-stage training scheme:\nfirst, extract features from the pre-trained backbone and then perform MIL\naggregation. However, it is well-known that this suboptimal training scheme\nsuffers from \"noisy\" feature embeddings from the backbone and inherent weak\nsupervision, hindering MIL from learning rich and generalizable features.\nHowever, the most commonly used technique (i.e., dropout) for mitigating this\nissue has yet to be explored in MIL. In this paper, we empirically explore how\neffective the dropout can be in MIL. Interestingly, we observe that dropping\nthe top-k most important instances within a bag leads to better performance and\ngeneralization even under noise attack. Based on this key observation, we\npropose a novel MIL-specific dropout method, termed MIL-Dropout, which\nsystematically determines which instances to drop. Experiments on five MIL\nbenchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the\nperformance of current MIL methods with a negligible computational cost. The\ncode is available at https://github.com/ChongQingNoSubway/MILDropout.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by ICML2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14783v2",
    "published_date": "2025-04-21 00:46:31 UTC",
    "updated_date": "2025-05-20 17:22:21 UTC"
  },
  {
    "arxiv_id": "2504.14779v1",
    "title": "Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work",
    "authors": [
      "Janet G. Johnson",
      "Macarena Peralta",
      "Mansanjam Kaur",
      "Ruijie Sophia Huang",
      "Sheng Zhao",
      "Ruijia Guan",
      "Shwetha Rajaram",
      "Michael Nebeling"
    ],
    "abstract": "While generative artificial intelligence (GenAI) is finding increased\nadoption in workplaces, current tools are primarily designed for individual\nuse. Prior work established the potential for these tools to enhance personal\ncreativity and productivity towards shared goals; however, we don't know yet\nhow to best take into account the nuances of group work and team dynamics when\ndeploying GenAI in work settings. In this paper, we investigate the potential\nof collaborative GenAI agents to augment teamwork in synchronous group settings\nthrough an exploratory study that engaged 25 professionals across 6 teams in\nspeculative design workshops and individual follow-up interviews. Our workshops\nincluded a mixed reality provotype to simulate embodied collaborative GenAI\nagents capable of actively participating in group discussions. Our findings\nsuggest that, if designed well, collaborative GenAI agents offer valuable\nopportunities to enhance team problem-solving by challenging groupthink,\nbridging communication gaps, and reducing social friction. However, teams'\nwillingness to integrate GenAI agents depended on its perceived fit across a\nnumber of individual, team, and organizational factors. We outline the key\ndesign tensions around agent representation, social prominence, and engagement\nand highlight the opportunities spatial and immersive technologies could offer\nto modulate GenAI influence on team outcomes and strike a balance between\naugmentation and agency.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "To be published in ACM Conference on Computer-Supported Cooperative\n  Work and Social Computing (CSCW 2025). 33 pages, 11 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.14779v1",
    "published_date": "2025-04-21 00:38:02 UTC",
    "updated_date": "2025-04-21 00:38:02 UTC"
  },
  {
    "arxiv_id": "2505.03763v1",
    "title": "Splitwiser: Efficient LM inference with constrained resources",
    "authors": [
      "Asad Aali",
      "Adney Cardoza",
      "Melissa Capo"
    ],
    "abstract": "Efficient inference of LLMs remains a crucial challenge, with two main\nphases: a compute-intensive prompt computation and a memory-intensive token\ngeneration. Despite existing batching and scheduling techniques, token\ngeneration phases fail to fully utilize compute resources, especially when\ncompared to prompt computation phases. To address these challenges, we propose\nSplitwiser, a methodology that splits the two phases of an LLM inference\nrequest onto the same GPU, thereby reducing overhead and improving memory\naccess and cache utilization. By eliminating the need to transfer data across\ndevices, Splitwiser aims to minimize network-related overheads. In this report,\nwe describe the basic structure of our proposed pipeline while sharing\npreliminary results and analysis. We implement our proposed multiprocessing\ndesign on two widely-used and independent LLM architectures: Huggingface and\nvLLM. We open-source our code for the respective implementations: 1)\nHuggingface (https://github.com/asad-aali/splitwiser), and 2) vLLM\n(https://github.com/adney11/vllm-sysml).",
    "categories": [
      "cs.AR",
      "cs.AI",
      "cs.DC",
      "cs.LG"
    ],
    "primary_category": "cs.AR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03763v1",
    "published_date": "2025-04-21 00:21:08 UTC",
    "updated_date": "2025-04-21 00:21:08 UTC"
  },
  {
    "arxiv_id": "2504.14773v1",
    "title": "PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities",
    "authors": [
      "Haoming Li",
      "Zhaoliang Chen",
      "Jonathan Zhang",
      "Fei Liu"
    ],
    "abstract": "Planning is central to agents and agentic AI. The ability to plan, e.g.,\ncreating travel itineraries within a budget, holds immense potential in both\nscientific and commercial contexts. Moreover, optimal plans tend to require\nfewer resources compared to ad-hoc methods. To date, a comprehensive\nunderstanding of existing planning benchmarks appears to be lacking. Without\nit, comparing planning algorithms' performance across domains or selecting\nsuitable algorithms for new scenarios remains challenging. In this paper, we\nexamine a range of planning benchmarks to identify commonly used testbeds for\nalgorithm development and highlight potential gaps. These benchmarks are\ncategorized into embodied environments, web navigation, scheduling, games and\npuzzles, and everyday task automation. Our study recommends the most\nappropriate benchmarks for various algorithms and offers insights to guide\nfuture benchmark development.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.14773v1",
    "published_date": "2025-04-21 00:02:50 UTC",
    "updated_date": "2025-04-21 00:02:50 UTC"
  }
]