[
  {
    "arxiv_id": "2504.15275v1",
    "title": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning",
    "authors": [
      "Jie Cheng",
      "Ruixi Qiao",
      "Lijun Li",
      "Chao Guo",
      "Junle Wang",
      "Gang Xiong",
      "Yisheng Lv",
      "Fei-Yue Wang"
    ],
    "abstract": "Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15275v1",
    "published_date": "2025-04-21 17:59:02 UTC",
    "updated_date": "2025-04-21 17:59:02 UTC"
  },
  {
    "arxiv_id": "2504.15266v1",
    "title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction",
    "authors": [
      "Vaishnavh Nagarajan",
      "Chen Henry Wu",
      "Charles Ding",
      "Aditi Raghunathan"
    ],
    "abstract": "We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "37 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15266v1",
    "published_date": "2025-04-21 17:47:46 UTC",
    "updated_date": "2025-04-21 17:47:46 UTC"
  },
  {
    "arxiv_id": "2504.15261v1",
    "title": "Leveraging Language Models for Automated Patient Record Linkage",
    "authors": [
      "Mohammad Beheshti",
      "Lovedeep Gondara",
      "Iris Zachary"
    ],
    "abstract": "Objective: Healthcare data fragmentation presents a major challenge for\nlinking patient data, necessitating robust record linkage to integrate patient\nrecords from diverse sources. This study investigates the feasibility of\nleveraging language models for automated patient record linkage, focusing on\ntwo key tasks: blocking and matching. Materials and Methods: We utilized\nreal-world healthcare data from the Missouri Cancer Registry and Research\nCenter, linking patient records from two independent sources using\nprobabilistic linkage as a baseline. A transformer-based model, RoBERTa, was\nfine-tuned for blocking using sentence embeddings. For matching, several\nlanguage models were experimented under fine-tuned and zero-shot settings,\nassessing their performance against ground truth labels. Results: The\nfine-tuned blocking model achieved a 92% reduction in the number of candidate\npairs while maintaining near-perfect recall. In the matching task, fine-tuned\nMistral-7B achieved the best performance with only 6 incorrect predictions.\nAmong zero-shot models, Mistral-Small-24B performed best, with a total of 55\nincorrect predictions. Discussion: Fine-tuned language models achieved strong\nperformance in patient record blocking and matching with minimal errors.\nHowever, they remain less accurate and efficient than a hybrid rule-based and\nprobabilistic approach for blocking. Additionally, reasoning models like\nDeepSeek-R1 are impractical for large-scale record linkage due to high\ncomputational costs. Conclusion: This study highlights the potential of\nlanguage models for automating patient record linkage, offering improved\nefficiency by eliminating the manual efforts required to perform patient record\nlinkage. Overall, language models offer a scalable solution that can enhance\ndata integration, reduce manual effort, and support disease surveillance and\nresearch.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15261v1",
    "published_date": "2025-04-21 17:41:15 UTC",
    "updated_date": "2025-04-21 17:41:15 UTC"
  },
  {
    "arxiv_id": "2504.15259v1",
    "title": "Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation",
    "authors": [
      "Yunxuan Cai",
      "Sitao Xiang",
      "Zongjian Li",
      "Haiwei Chen",
      "Yajie Zhao"
    ],
    "abstract": "Digital modeling and reconstruction of human faces serve various\napplications. However, its availability is often hindered by the requirements\nof data capturing devices, manual labor, and suitable actors. This situation\nrestricts the diversity, expressiveness, and control over the resulting models.\nThis work aims to demonstrate that a semantically controllable generative\nnetwork can provide enhanced control over the digital face modeling process. To\nenhance diversity beyond the limited human faces scanned in a controlled\nsetting, we introduce a novel data generation pipeline that creates a\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\nnormalization module converts synthesized data from the diffusion model into\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\ndeveloped an efficient GAN-based generator. This generator accepts semantic\nattributes as input, and generates geometry and albedo. It also allows\ncontinuous post-editing of attributes in the latent space. Our asset refinement\ncomponent subsequently creates physically-based facial assets. We introduce a\ncomprehensive system designed for creating and editing high-quality face\nassets. Our proposed model has undergone extensive experiment, comparison and\nevaluation. We also integrate everything into a web-based interactive tool. We\naim to make this tool publicly available with the release of the paper.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15259v1",
    "published_date": "2025-04-21 17:38:50 UTC",
    "updated_date": "2025-04-21 17:38:50 UTC"
  },
  {
    "arxiv_id": "2504.15257v1",
    "title": "FlowReasoner: Reinforcing Query-Level Meta-Agents",
    "authors": [
      "Hongcheng Gao",
      "Yue Liu",
      "Yufei He",
      "Longxu Dou",
      "Chao Du",
      "Zhijie Deng",
      "Bryan Hooi",
      "Min Lin",
      "Tianyu Pang"
    ],
    "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate\nthe design of query-level multi-agent systems, i.e., one system per user query.\nOur core idea is to incentivize a reasoning-based meta-agent via external\nexecution feedback. Concretely, by distilling DeepSeek R1, we first endow the\nbasic reasoning ability regarding the generation of multi-agent systems to\nFlowReasoner. Then, we further enhance it via reinforcement learning (RL) with\nexternal execution feedback. A multi-purpose reward is designed to guide the RL\ntraining from aspects of performance, complexity, and efficiency. In this\nmanner, FlowReasoner is enabled to generate a personalized multi-agent system\nfor each user query via deliberative reasoning. Experiments on both engineering\nand competition code benchmarks demonstrate the superiority of FlowReasoner.\nRemarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks.\nThe code is available at https://github.com/sail-sg/FlowReasoner.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15257v1",
    "published_date": "2025-04-21 17:35:42 UTC",
    "updated_date": "2025-04-21 17:35:42 UTC"
  },
  {
    "arxiv_id": "2504.15252v1",
    "title": "SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam",
    "authors": [
      "Tue Vo",
      "Lakshay Sharma",
      "Tuan Dinh",
      "Khuong Dinh",
      "Trang Nguyen",
      "Trung Phan",
      "Minh Do",
      "Duong Vu"
    ],
    "abstract": "Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.",
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published as a workshop paper at \"Tackling Climate Change with\n  Machine Learning\", ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15252v1",
    "published_date": "2025-04-21 17:33:02 UTC",
    "updated_date": "2025-04-21 17:33:02 UTC"
  },
  {
    "arxiv_id": "2504.15236v1",
    "title": "Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions",
    "authors": [
      "Saffron Huang",
      "Esin Durmus",
      "Miles McCain",
      "Kunal Handa",
      "Alex Tamkin",
      "Jerry Hong",
      "Michael Stern",
      "Arushi Somani",
      "Xiuruo Zhang",
      "Deep Ganguli"
    ],
    "abstract": "AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "44 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15236v1",
    "published_date": "2025-04-21 17:13:16 UTC",
    "updated_date": "2025-04-21 17:13:16 UTC"
  },
  {
    "arxiv_id": "2504.15228v1",
    "title": "A Self-Improving Coding Agent",
    "authors": [
      "Maxime Robeyns",
      "Martin Szummer",
      "Laurence Aitchison"
    ],
    "abstract": "We demonstrate that an LLM coding agent, equipped with basic coding tools,\ncan autonomously edit itself, and thereby improve its performance on benchmark\ntasks. We find performance gains from 17% to 53% on a random subset of SWE\nBench Verified, with additional performance gains on LiveCodeBench, as well as\nsynthetically generated agent benchmarks. Our work represents an advancement in\nthe automated and open-ended design of agentic systems, and provides a\nreference agent framework for those seeking to post-train LLMs on tool use and\nother agentic tasks.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at an ICLR 2025 workshop on Scaling Self-Improving\n  Foundation Models",
    "pdf_url": "http://arxiv.org/pdf/2504.15228v1",
    "published_date": "2025-04-21 16:58:18 UTC",
    "updated_date": "2025-04-21 16:58:18 UTC"
  },
  {
    "arxiv_id": "2504.15226v1",
    "title": "A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing",
    "authors": [
      "Nathan Steffen",
      "Wilhelm Louw",
      "Nicholas Ernest",
      "Timothy Arnett",
      "Kelly Cohen"
    ],
    "abstract": "Automation of robotic systems for servicing in cislunar space is becoming\nextremely important as the number of satellites in orbit increases. Safety is\ncritical in performing satellite maintenance, so the control techniques\nutilized must be trusted in addition to being highly efficient. In this work,\nGenetic Fuzzy Trees are combined with the widely used LQR control scheme via\nThales' TrUE AI Toolkit to create a trusted and efficient controller for a\ntwo-degree-of-freedom planar robotic manipulator that would theoretically be\nused to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is\n18.5% more performant than optimal LQR on average, and that it is incredibly\nrobust to uncertainty.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15226v1",
    "published_date": "2025-04-21 16:57:56 UTC",
    "updated_date": "2025-04-21 16:57:56 UTC"
  },
  {
    "arxiv_id": "2504.15225v1",
    "title": "M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding",
    "authors": [
      "Sarah Alnegheimish",
      "Zelin He",
      "Matthew Reimherr",
      "Akash Chandrayan",
      "Abhinav Pradhan",
      "Luca D'Angelo"
    ],
    "abstract": "With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15225v1",
    "published_date": "2025-04-21 16:57:46 UTC",
    "updated_date": "2025-04-21 16:57:46 UTC"
  },
  {
    "arxiv_id": "2504.15211v1",
    "title": "Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI",
    "authors": [
      "Yanan Long"
    ],
    "abstract": "The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.",
    "categories": [
      "cs.AI",
      "stat.AP"
    ],
    "primary_category": "cs.AI",
    "comment": "To be presented at ACM CHI 2025 workshop STAIG",
    "pdf_url": "http://arxiv.org/pdf/2504.15211v1",
    "published_date": "2025-04-21 16:31:15 UTC",
    "updated_date": "2025-04-21 16:31:15 UTC"
  },
  {
    "arxiv_id": "2504.15210v1",
    "title": "Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs",
    "authors": [
      "Marina Sakharova",
      "Abhinav Anand",
      "Mira Mezini"
    ],
    "abstract": "Code-generating Large Language Models (LLMs) have become essential tools in\nmodern software development, enhancing productivity and accelerating\ndevelopment. This paper aims to investigate the fine-tuning of code-generating\nLLMs using Reinforcement Learning and Direct Preference Optimization, further\nimproving their performance. To achieve this, we enhance the training data for\nthe reward model with the help of symbolic execution techniques, ensuring more\ncomprehensive and objective data. With symbolic execution, we create a custom\ndataset that better captures the nuances in code evaluation. Our reward models,\nfine-tuned on this dataset, demonstrate significant improvements over the\nbaseline, CodeRL, in estimating the quality of generated code. Our\ncode-generating LLMs, trained with the help of reward model feedback, achieve\nsimilar results compared to the CodeRL benchmark.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15210v1",
    "published_date": "2025-04-21 16:29:07 UTC",
    "updated_date": "2025-04-21 16:29:07 UTC"
  },
  {
    "arxiv_id": "2504.15209v1",
    "title": "A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data",
    "authors": [
      "Xin Liao",
      "Bing Yang",
      "Tan Dongli",
      "Cai Yu"
    ],
    "abstract": "The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "68T07 (Primary) 62M10, 65C60 (Secondary)",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15209v1",
    "published_date": "2025-04-21 16:27:16 UTC",
    "updated_date": "2025-04-21 16:27:16 UTC"
  },
  {
    "arxiv_id": "2504.15208v1",
    "title": "Compute-Optimal LLMs Provably Generalize Better With Scale",
    "authors": [
      "Marc Finzi",
      "Sanyam Kapoor",
      "Diego Granziol",
      "Anming Gu",
      "Christopher De Sa",
      "J. Zico Kolter",
      "Andrew Gordon Wilson"
    ],
    "abstract": "Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.15208v1",
    "published_date": "2025-04-21 16:26:56 UTC",
    "updated_date": "2025-04-21 16:26:56 UTC"
  },
  {
    "arxiv_id": "2504.15205v1",
    "title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges",
    "authors": [
      "Nandan Thakur",
      "Ronak Pradeep",
      "Shivani Upadhyay",
      "Daniel Campos",
      "Nick Craswell",
      "Jimmy Lin"
    ],
    "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to\ngenerate answers with citations from source documents containing \"ground\ntruth\", thereby reducing system hallucinations. A crucial factor in RAG\nevaluation is \"support\", whether the information in the cited documents\nsupports the answer. To this end, we conducted a large-scale comparative study\nof 45 participant submissions on 36 topics to the TREC 2024 RAG Track,\ncomparing an automatic LLM judge (GPT-4o) against human judges for support\nassessment. We considered two conditions: (1) fully manual assessments from\nscratch and (2) manual assessments with post-editing of LLM predictions. Our\nresults indicate that for 56% of the manual from-scratch assessments, human and\nGPT-4o predictions match perfectly (on a three-level scale), increasing to 72%\nin the manual with post-editing condition. Furthermore, by carefully analyzing\nthe disagreements in an unbiased study, we found that an independent human\njudge correlates better with GPT-4o than a human judge, suggesting that LLM\njudges can be a reliable alternative for support assessment. To conclude, we\nprovide a qualitative analysis of human and GPT-4o errors to help guide future\niterations of support assessment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at SIGIR 2025 (short)",
    "pdf_url": "http://arxiv.org/pdf/2504.15205v1",
    "published_date": "2025-04-21 16:20:43 UTC",
    "updated_date": "2025-04-21 16:20:43 UTC"
  },
  {
    "arxiv_id": "2504.15199v1",
    "title": "Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning",
    "authors": [
      "Yassir Benhammou",
      "Alessandro Tiberio",
      "Gabriel Trautmann",
      "Suman Kalyan"
    ],
    "abstract": "MILS (Multimodal Iterative LLM Solver) is a recently published framework that\nclaims \"LLMs can see and hear without any training\" by leveraging an iterative,\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\napproach demonstrates good performance, our investigation reveals that this\nsuccess comes at a hidden, substantial computational cost due to its expensive\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\nand GPT-4V achieve competitive results through a streamlined, single-pass\napproach. We hypothesize that the significant overhead inherent in MILS's\niterative process may undermine its practical benefits, thereby challenging the\nnarrative that zero-shot performance can be attained without incurring heavy\nresource demands. This work is the first to expose and quantify the trade-offs\nbetween output quality and computational cost in MILS, providing critical\ninsights for the design of more efficient multimodal models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "cs.PF"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 2 tables, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.15199v1",
    "published_date": "2025-04-21 16:16:19 UTC",
    "updated_date": "2025-04-21 16:16:19 UTC"
  },
  {
    "arxiv_id": "2504.15192v1",
    "title": "Breast density in MRI: an AI-based quantification and relationship to assessment in mammography",
    "authors": [
      "Yaqian Chen",
      "Lin Li",
      "Hanxue Gu",
      "Haoyu Dong",
      "Derek L. Nguyen",
      "Allan D. Kirk",
      "Maciej A. Mazurowski",
      "E. Shelley Hwang"
    ],
    "abstract": "Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15192v1",
    "published_date": "2025-04-21 16:01:51 UTC",
    "updated_date": "2025-04-21 16:01:51 UTC"
  },
  {
    "arxiv_id": "2504.15188v2",
    "title": "Synergistic Weak-Strong Collaboration by Aligning Preferences",
    "authors": [
      "Yizhu Jiao",
      "Xuchao Zhang",
      "Zhaoyang Wang",
      "Yubo Ma",
      "Zhun Deng",
      "Rujia Wang",
      "Chetan Bansal",
      "Saravan Rajmohan",
      "Jiawei Han",
      "Huaxiu Yao"
    ],
    "abstract": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15188v2",
    "published_date": "2025-04-21 15:57:33 UTC",
    "updated_date": "2025-04-22 04:22:09 UTC"
  },
  {
    "arxiv_id": "2504.15181v1",
    "title": "Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures",
    "authors": [
      "Lily Stelling",
      "Mick Yang",
      "Rokas Gipiškis",
      "Leon Staufer",
      "Ze Shen Chin",
      "Siméon Campos",
      "Michael Chen"
    ],
    "abstract": "This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "158 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.15181v1",
    "published_date": "2025-04-21 15:44:01 UTC",
    "updated_date": "2025-04-21 15:44:01 UTC"
  },
  {
    "arxiv_id": "2504.15165v1",
    "title": "An Efficient Aerial Image Detection with Variable Receptive Fields",
    "authors": [
      "Liu Wenbin"
    ],
    "abstract": "Aerial object detection using unmanned aerial vehicles (UAVs) faces critical\nchallenges including sub-10px targets, dense occlusions, and stringent\ncomputational constraints. Existing detectors struggle to balance accuracy and\nefficiency due to rigid receptive fields and redundant architectures. To\naddress these limitations, we propose Variable Receptive Field DETR (VRF-DETR),\na transformer-based detector incorporating three key components: 1) Multi-Scale\nContext Fusion (MSCF) module that dynamically recalibrates features through\nadaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution\n(GConv) layer enabling parameter-efficient local-context modeling via depthwise\nseparable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)\nBottleneck that hierarchically disentangles occluded objects through cascaded\nglobal-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR\nachieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with\nonly 13.5M parameters. This work establishes a new efficiency-accuracy Pareto\nfrontier for UAV-based detection tasks.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15165v1",
    "published_date": "2025-04-21 15:16:13 UTC",
    "updated_date": "2025-04-21 15:16:13 UTC"
  },
  {
    "arxiv_id": "2504.15152v1",
    "title": "Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection",
    "authors": [
      "Jun Zhou",
      "Bingchen Gao",
      "Kai Wang",
      "Jialun Pei",
      "Pheng-Ann Heng",
      "Jing Qin"
    ],
    "abstract": "Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "TMI under review",
    "pdf_url": "http://arxiv.org/pdf/2504.15152v1",
    "published_date": "2025-04-21 14:55:57 UTC",
    "updated_date": "2025-04-21 14:55:57 UTC"
  },
  {
    "arxiv_id": "2504.15146v1",
    "title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems",
    "authors": [
      "Wei Zhou",
      "Ailiya Borjigin",
      "Cong He"
    ],
    "abstract": "Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "17 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.15146v1",
    "published_date": "2025-04-21 14:50:28 UTC",
    "updated_date": "2025-04-21 14:50:28 UTC"
  },
  {
    "arxiv_id": "2504.15144v1",
    "title": "C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation",
    "authors": [
      "Melih Sirlanci",
      "Carter Yagemann",
      "Zhiqiang Lin"
    ],
    "abstract": "Despite the effort in vulnerability detection over the last two decades,\nmemory safety vulnerabilities continue to be a critical problem. Recent reports\nsuggest that the key solution is to migrate to memory-safe languages. To this\nend, C-to-Rust transpilation becomes popular to resolve memory-safety issues in\nC programs. Recent works propose C-to-Rust transpilation frameworks; however, a\ncomprehensive evaluation dataset is missing. Although one solution is to put\ntogether a large enough dataset, this increases the analysis time in automated\nframeworks as well as in manual efforts for some cases. In this work, we build\na method to select functions from a large set to construct a minimized yet\nrepresentative dataset to evaluate the C-to-Rust transpilation. We propose\nC2RUST-BENCH that contains 2,905 functions, which are representative of\nC-to-Rust transpilation, selected from 15,503 functions of real-world programs.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15144v1",
    "published_date": "2025-04-21 14:48:45 UTC",
    "updated_date": "2025-04-21 14:48:45 UTC"
  },
  {
    "arxiv_id": "2504.15135v1",
    "title": "KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking",
    "authors": [
      "Juyeon Kim",
      "Geon Lee",
      "Taeuk Kim",
      "Kijung Shin"
    ],
    "abstract": "Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.IR",
    "comment": "SIGIR 2025 (Short)",
    "pdf_url": "http://arxiv.org/pdf/2504.15135v1",
    "published_date": "2025-04-21 14:38:44 UTC",
    "updated_date": "2025-04-21 14:38:44 UTC"
  },
  {
    "arxiv_id": "2504.15133v1",
    "title": "EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models",
    "authors": [
      "Ziwen Xu",
      "Shuxun Wang",
      "Kewei Xu",
      "Haoming Xu",
      "Mengru Wang",
      "Xinle Deng",
      "Yunzhi Yao",
      "Guozhou Zheng",
      "Huajun Chen",
      "Ningyu Zhang"
    ],
    "abstract": "In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in progress. Demo:\n  https://zjunlp.github.io/project/EasyEdit2/video; code:\n  https://github.com/zjunlp/EasyEdit",
    "pdf_url": "http://arxiv.org/pdf/2504.15133v1",
    "published_date": "2025-04-21 14:33:55 UTC",
    "updated_date": "2025-04-21 14:33:55 UTC"
  },
  {
    "arxiv_id": "2504.15130v1",
    "title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning",
    "authors": [
      "Kushal Shah",
      "Jihyun Park",
      "Seung-Kyum Choi"
    ],
    "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "13 Pages, 5 Figures, 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2504.15130v1",
    "published_date": "2025-04-21 14:25:32 UTC",
    "updated_date": "2025-04-21 14:25:32 UTC"
  },
  {
    "arxiv_id": "2504.15129v1",
    "title": "A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment",
    "authors": [
      "Kangyao Huang",
      "Hao Wang",
      "Yu Luo",
      "Jingyu Chen",
      "Jintao Chen",
      "Xiangkui Zhang",
      "Xiangyang Ji",
      "Huaping Liu"
    ],
    "abstract": "Deploying robot learning methods to a quadrotor in unstructured outdoor\nenvironments is an exciting task. Quadrotors operating in real-world\nenvironments by learning-based methods encounter several challenges: a large\namount of simulator generated data required for training, strict demands for\nreal-time processing onboard, and the sim-to-real gap caused by dynamic and\nnoisy conditions. Current works have made a great breakthrough in applying\nlearning-based methods to end-to-end control of quadrotors, but rarely mention\nthe infrastructure system training from scratch and deploying to reality, which\nmakes it difficult to reproduce methods and applications. To bridge this gap,\nwe propose a platform that enables the seamless transfer of end-to-end deep\nreinforcement learning (DRL) policies. We integrate the training environment,\nflight dynamics control, DRL algorithms, the MAVROS middleware stack, and\nhardware into a comprehensive workflow and architecture that enables\nquadrotors' policies to be trained from scratch to real-world deployment in\nseveral minutes. Our platform provides rich types of environments including\nhovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and\nplanning in unknown environments, as a physical experiment benchmark. Through\nextensive empirical validation, we demonstrate the efficiency of proposed\nsim-to-real platform, and robust outdoor flight performance under real-world\nperturbations. Details can be found from our website\nhttps://emnavi.tech/AirGym/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15129v1",
    "published_date": "2025-04-21 14:25:23 UTC",
    "updated_date": "2025-04-21 14:25:23 UTC"
  },
  {
    "arxiv_id": "2504.15125v1",
    "title": "Contemplative Wisdom for Superalignment",
    "authors": [
      "Ruben Laukkonen",
      "Fionn Inglis",
      "Shamil Chandaria",
      "Lars Sandved-Smith",
      "Jakob Hohwy",
      "Jonathan Gold",
      "Adam Elwood"
    ],
    "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15125v1",
    "published_date": "2025-04-21 14:20:49 UTC",
    "updated_date": "2025-04-21 14:20:49 UTC"
  },
  {
    "arxiv_id": "2504.15120v1",
    "title": "Kuwain 1.5B: An Arabic SLM via Language Injection",
    "authors": [
      "Khalil Hennara",
      "Sara Chrouf",
      "Mohamed Motaism Hamed",
      "Zeina Aldallal",
      "Omar Hadid",
      "Safwan AlModhayan"
    ],
    "abstract": "Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15120v1",
    "published_date": "2025-04-21 14:17:25 UTC",
    "updated_date": "2025-04-21 14:17:25 UTC"
  },
  {
    "arxiv_id": "2504.15105v1",
    "title": "A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae",
    "authors": [
      "Yurun Wang",
      "Zerong Qi",
      "Shujun Fu",
      "Mingzheng Hu"
    ],
    "abstract": "Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15105v1",
    "published_date": "2025-04-21 13:54:33 UTC",
    "updated_date": "2025-04-21 13:54:33 UTC"
  },
  {
    "arxiv_id": "2504.15101v1",
    "title": "NeuGaze: Reshaping the future BCI",
    "authors": [
      "Yiqian Yang"
    ],
    "abstract": "Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15101v1",
    "published_date": "2025-04-21 13:49:17 UTC",
    "updated_date": "2025-04-21 13:49:17 UTC"
  },
  {
    "arxiv_id": "2504.15099v1",
    "title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN",
    "authors": [
      "Lin Wang",
      "Xiancheng Wang",
      "Rui Wang",
      "Zhibo Zhang",
      "Minghang Zhao"
    ],
    "abstract": "Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15099v1",
    "published_date": "2025-04-21 13:41:09 UTC",
    "updated_date": "2025-04-21 13:41:09 UTC"
  },
  {
    "arxiv_id": "2504.15093v1",
    "title": "Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models",
    "authors": [
      "K. Wong",
      "B. Wu",
      "S. Bulathwela",
      "M. Cukurova"
    ],
    "abstract": "Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted for 26th International Conference on Artificial Intelligence\n  in Education (AIED 2025), 22 - 26 July 2025, Palermo, Italy. 17 pages, 1\n  figure",
    "pdf_url": "http://arxiv.org/pdf/2504.15093v1",
    "published_date": "2025-04-21 13:25:55 UTC",
    "updated_date": "2025-04-21 13:25:55 UTC"
  },
  {
    "arxiv_id": "2504.15090v1",
    "title": "Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving",
    "authors": [
      "Junxiang Gao",
      "Yixin Ran",
      "Jia Chen"
    ],
    "abstract": "A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15090v1",
    "published_date": "2025-04-21 13:24:30 UTC",
    "updated_date": "2025-04-21 13:24:30 UTC"
  },
  {
    "arxiv_id": "2504.15080v1",
    "title": "Empowering AI to Generate Better AI Code: Guided Generation of Deep Learning Projects with LLMs",
    "authors": [
      "Chen Xie",
      "Mingsheng Jiao",
      "Xiaodong Gu",
      "Beijun Shen"
    ],
    "abstract": "While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15080v1",
    "published_date": "2025-04-21 13:09:25 UTC",
    "updated_date": "2025-04-21 13:09:25 UTC"
  },
  {
    "arxiv_id": "2504.15075v1",
    "title": "Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention",
    "authors": [
      "Van Thuy Hoang",
      "Hyeon-Ju Jeon",
      "O-Joun Lee"
    ],
    "abstract": "Graph Neural Networks (GNNs) update node representations through message\npassing, which is primarily based on the homophily principle, assuming that\nadjacent nodes share similar features. However, in real-world graphs with\nlong-tailed degree distributions, high-degree nodes dominate message passing,\ncausing a degree bias where low-degree nodes remain under-represented due to\ninadequate messages. The main challenge in addressing degree bias is how to\ndiscover non-adjacent nodes to provide additional messages to low-degree nodes\nwhile reducing excessive messages for high-degree nodes. Nevertheless,\nexploiting non-adjacent nodes to provide valuable messages is challenging, as\nit could generate noisy information and disrupt the original graph structures.\nTo solve it, we propose a novel Degree Fairness Graph Transformer, named\nDegFairGT, to mitigate degree bias by discovering structural similarities\nbetween non-adjacent nodes through learnable structural augmentation and\nstructural self-attention. Our key idea is to exploit non-adjacent nodes with\nsimilar roles in the same community to generate informative edges under our\naugmentation, which could provide informative messages between nodes with\nsimilar roles while ensuring that the homophily principle is maintained within\nthe community. To enable DegFairGT to learn such structural similarities, we\nthen propose a structural self-attention to capture the similarities between\nnode pairs. To preserve global graph structures and prevent graph augmentation\nfrom hindering graph structure, we propose a Self-Supervised Learning task to\npreserve p-step transition probability and regularize graph augmentation.\nExtensive experiments on six datasets showed that DegFairGT outperformed\nstate-of-the-art baselines in degree fairness analysis, node classification,\nand node clustering tasks.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IEEE TNSE",
    "pdf_url": "http://arxiv.org/pdf/2504.15075v1",
    "published_date": "2025-04-21 13:03:40 UTC",
    "updated_date": "2025-04-21 13:03:40 UTC"
  },
  {
    "arxiv_id": "2504.15066v1",
    "title": "Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides",
    "authors": [
      "Jinghua Zhao",
      "Yuhang Jia",
      "Shiyao Wang",
      "Jiaming Zhou",
      "Hui Wang",
      "Yong Qin"
    ],
    "abstract": "Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/",
    "categories": [
      "cs.MM",
      "cs.AI"
    ],
    "primary_category": "cs.MM",
    "comment": "6 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15066v1",
    "published_date": "2025-04-21 12:51:54 UTC",
    "updated_date": "2025-04-21 12:51:54 UTC"
  },
  {
    "arxiv_id": "2504.15063v1",
    "title": "Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages",
    "authors": [
      "Hongli Peng",
      "Xiaoqi Li",
      "Wenkai Li"
    ],
    "abstract": "Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15063v1",
    "published_date": "2025-04-21 12:42:59 UTC",
    "updated_date": "2025-04-21 12:42:59 UTC"
  },
  {
    "arxiv_id": "2504.15062v1",
    "title": "OPO: Making Decision-Focused Data Acquisition Decisions",
    "authors": [
      "Egon Peršak",
      "Miguel F. Anjos"
    ],
    "abstract": "We propose a model for making data acquisition decisions for variables in\ncontextual stochastic optimisation problems. Data acquisition decisions are\ntypically treated as separate and fixed. We explore problem settings in which\nthe acquisition of contextual variables is costly and consequently constrained.\nThe data acquisition problem is often solved heuristically for proxy objectives\nsuch as coverage. The more intuitive objective is the downstream decision\nquality as a result of data acquisition decisions. The whole pipeline can be\ncharacterised as an optimise-then-predict-then-optimise (OPO) problem.\nAnalogously, much recent research has focused on how to integrate prediction\nand optimisation (PO) in the form of decision-focused learning. We propose\nleveraging differentiable optimisation to extend the integration to data\nacquisition. We solve the data acquisition problem with well-defined\nconstraints by learning a surrogate linear objective function. We demonstrate\nan application of this model on a shortest path problem for which we first have\nto set a drone reconnaissance strategy to capture image segments serving as\ninputs to a model that predicts travel costs. We ablate the problem with a\nnumber of training modalities and demonstrate that the differentiable\noptimisation approach outperforms random search strategies.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15062v1",
    "published_date": "2025-04-21 12:41:35 UTC",
    "updated_date": "2025-04-21 12:41:35 UTC"
  },
  {
    "arxiv_id": "2504.15051v1",
    "title": "VeLU: Variance-enhanced Learning Unit for Deep Neural Networks",
    "authors": [
      "Ashkan Shakarami",
      "Yousef Yeganeh",
      "Azade Farshad",
      "Lorenzo Nicolè",
      "Stefano Ghidoni",
      "Nassir Navab"
    ],
    "abstract": "Activation functions are fundamental in deep neural networks and directly\nimpact gradient flow, optimization stability, and generalization. Although ReLU\nremains standard because of its simplicity, it suffers from vanishing gradients\nand lacks adaptability. Alternatives like Swish and GELU introduce smooth\ntransitions, but fail to dynamically adjust to input statistics. We propose\nVeLU, a Variance-enhanced Learning Unit as an activation function that\ndynamically scales based on input variance by integrating ArcTan-Sin\ntransformations and Wasserstein-2 regularization, effectively mitigating\ncovariate shifts and stabilizing optimization. Extensive experiments on\nViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm\nVeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.\nThe codes of VeLU are publicly available on GitHub.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15051v1",
    "published_date": "2025-04-21 12:20:46 UTC",
    "updated_date": "2025-04-21 12:20:46 UTC"
  },
  {
    "arxiv_id": "2504.15046v2",
    "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision",
    "authors": [
      "Shilin Zhang",
      "Zican Hu",
      "Wenhao Wu",
      "Xinyi Xie",
      "Jianxiang Tang",
      "Chunlin Chen",
      "Daoyi Dong",
      "Yu Cheng",
      "Zhenhong Sun",
      "Zhi Wang"
    ],
    "abstract": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15046v2",
    "published_date": "2025-04-21 12:00:20 UTC",
    "updated_date": "2025-04-22 05:56:57 UTC"
  },
  {
    "arxiv_id": "2504.15044v1",
    "title": "Beyond Terabit/s Integrated Neuromorphic Photonic Processor for DSP-Free Optical Interconnects",
    "authors": [
      "Benshan Wang",
      "Qiarong Xiao",
      "Tengji Xu",
      "Li Fan",
      "Shaojie Liu",
      "Jianji Dong",
      "Junwen Zhang",
      "Chaoran Huang"
    ],
    "abstract": "The rapid expansion of generative AI drives unprecedented demands for\nhigh-performance computing. Training large-scale AI models now requires vast\ninterconnected GPU clusters across multiple data centers. Multi-scale AI\ntraining and inference demand uniform, ultra-low latency, and energy-efficient\nlinks to enable massive GPUs to function as a single cohesive unit. However,\ntraditional electrical and optical interconnects, relying on conventional\ndigital signal processors (DSPs) for signal distortion compensation,\nincreasingly fail to meet these stringent requirements. To overcome these\nlimitations, we present an integrated neuromorphic optical signal processor\n(OSP) that leverages deep reservoir computing and achieves DSP-free,\nall-optical, real-time processing. Experimentally, our OSP achieves a 100 Gbaud\nPAM4 per lane, 1.6 Tbit/s data center interconnect over a 5 km optical fiber in\nthe C-band (equivalent to over 80 km in the O-band), far exceeding the reach of\nstate-of-the-art DSP solutions, which are fundamentally constrained by\nchromatic dispersion in IMDD systems. Simultaneously, it reduces processing\nlatency by four orders of magnitude and energy consumption by three orders of\nmagnitude. Unlike DSPs, which introduce increased latency at high data rates,\nour OSP maintains consistent, ultra-low latency regardless of data rate\nscaling, making it ideal for future optical interconnects. Moreover, the OSP\nretains full optical field information for better impairment compensation and\nadapts to various modulation formats, data rates, and wavelengths. Fabricated\nusing a mature silicon photonic process, the OSP can be monolithically\nintegrated with silicon photonic transceivers, enhancing the compactness and\nreliability of all-optical interconnects. This research provides a highly\nscalable, energy-efficient, and high-speed solution, paving the way for\nnext-generation AI infrastructure.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "physics.optics",
    "comment": "22 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15044v1",
    "published_date": "2025-04-21 11:56:36 UTC",
    "updated_date": "2025-04-21 11:56:36 UTC"
  },
  {
    "arxiv_id": "2504.15041v2",
    "title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification",
    "authors": [
      "Shiben Liu",
      "Huijie Fan",
      "Qiang Wang",
      "Baojie Fan",
      "Yandong Tang",
      "Liangqiong Qu"
    ],
    "abstract": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.15041v2",
    "published_date": "2025-04-21 11:53:43 UTC",
    "updated_date": "2025-04-22 13:05:09 UTC"
  },
  {
    "arxiv_id": "2504.15035v1",
    "title": "SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation",
    "authors": [
      "Yue Li",
      "Weizhi Liu",
      "Dongdong Lin"
    ],
    "abstract": "The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.15035v1",
    "published_date": "2025-04-21 11:43:36 UTC",
    "updated_date": "2025-04-21 11:43:36 UTC"
  },
  {
    "arxiv_id": "2504.14995v1",
    "title": "Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks",
    "authors": [
      "Keisuke Murota",
      "Takumi Kobori"
    ],
    "abstract": "Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "11 pages, 12 figures, 2 tables. This work has been submitted to the\n  IEEE for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2504.14995v1",
    "published_date": "2025-04-21 09:51:39 UTC",
    "updated_date": "2025-04-21 09:51:39 UTC"
  },
  {
    "arxiv_id": "2504.14985v1",
    "title": "aiXamine: LLM Safety and Security Simplified",
    "authors": [
      "Fatih Deniz",
      "Dorde Popovic",
      "Yazan Boshmaf",
      "Euisuh Jeong",
      "Minhaj Ahmad",
      "Sanjay Chawla",
      "Issa Khalil"
    ],
    "abstract": "Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14985v1",
    "published_date": "2025-04-21 09:26:05 UTC",
    "updated_date": "2025-04-21 09:26:05 UTC"
  },
  {
    "arxiv_id": "2504.14964v1",
    "title": "Evaluating Code Generation of LLMs in Advanced Computer Science Problems",
    "authors": [
      "Emir Catir",
      "Robin Claesson",
      "Rodothea Myrsini Tsoupidi"
    ],
    "abstract": "Large Language Models (LLMs), such as GitHub Copilot and ChatGPT have become\npopular among programming students. Students use LLMs to assist them in\nprogramming courses, including generating source code. Previous work has\nevaluated the ability of LLMs in solving introductory-course programming\nassignments. The results have shown that LLMs are highly effective in\ngenerating code for introductory Computer Science (CS) courses. However, there\nis a gap in research on evaluating LLMs' ability to generate code that solves\nadvanced programming assignments. In this work, we evaluate the ability of four\nLLM tools to solve programming assignments from advanced CS courses in three\npopular programming languages, Java, Python, and C. We manually select 12\nproblems, three problems from introductory courses as the baseline and nine\nprogramming assignments from second- and third-year CS courses. To evaluate the\nLLM-generated code, we generate a test suite of 1000 test cases per problem and\nanalyze the program output. Our evaluation shows that although LLMs are highly\neffective in generating source code for introductory programming courses,\nsolving advanced programming assignments is more challenging. Nonetheless, in\nmany cases, LLMs identify the base problem and provide partial solutions that\nmay be useful to CS students. Furthermore, our results may provide useful\nguidance for teachers of advanced programming courses on how to design\nprogramming assignments.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14964v1",
    "published_date": "2025-04-21 08:45:23 UTC",
    "updated_date": "2025-04-21 08:45:23 UTC"
  },
  {
    "arxiv_id": "2504.14963v1",
    "title": "Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues",
    "authors": [
      "Rui Ribeiro",
      "Luísa Coheur",
      "Joao P. Carvalho"
    ],
    "abstract": "Speaker identification using voice recordings leverages unique acoustic\nfeatures, but this approach fails when only textual data is available. Few\napproaches have attempted to tackle the problem of identifying speakers solely\nfrom text, and the existing ones have primarily relied on traditional methods.\nIn this work, we explore the use of fuzzy fingerprints from large pre-trained\nmodels to improve text-based speaker identification. We integrate\nspeaker-specific tokens and context-aware modeling, demonstrating that\nconversational context significantly boosts accuracy, reaching 70.6% on the\nFriends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show\nthat fuzzy fingerprints can approximate full fine-tuning performance with fewer\nhidden units, offering improved interpretability. Finally, we analyze ambiguous\nutterances and propose a mechanism to detect speaker-agnostic lines. Our\nfindings highlight key challenges and provide insights for future improvements\nin text-based speaker identification.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.CL",
    "comment": "Paper accepted at the FUZZY IEEE 2025 conference",
    "pdf_url": "http://arxiv.org/pdf/2504.14963v1",
    "published_date": "2025-04-21 08:44:33 UTC",
    "updated_date": "2025-04-21 08:44:33 UTC"
  },
  {
    "arxiv_id": "2504.14947v1",
    "title": "Generative Semantic Communications: Principles and Practices",
    "authors": [
      "Xiaojun Yuan",
      "Haoming Ma",
      "Yinuo Huang",
      "Zhoufan Hua",
      "Yong Zuo",
      "Zhi Ding"
    ],
    "abstract": "Semantic communication leverages artificial intelligence (AI) technologies to\nextract semantic information from data for efficient transmission, theraby\nsignificantly reducing communication cost. With the evolution towards\nartificial general intelligence (AGI), the increasing demands for AGI services\npose new challenges to semantic communication. In response, we propose a new\nparadigm for AGI-driven communications, called generative semantic\ncommunication (GSC), which utilizes advanced AI technologies such as foundation\nmodels and generative models. We first describe the basic concept of GSC and\nits difference from existing semantic communications, and then introduce a\ngeneral framework of GSC, followed by two case studies to verify the advantages\nof GSC in AGI-driven applications. Finally, open challenges and new research\ndirections are discussed to stimulate this line of research and pave the way\nfor practical applications.",
    "categories": [
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14947v1",
    "published_date": "2025-04-21 08:10:59 UTC",
    "updated_date": "2025-04-21 08:10:59 UTC"
  },
  {
    "arxiv_id": "2504.14945v2",
    "title": "Learning to Reason under Off-Policy Guidance",
    "authors": [
      "Jianhao Yan",
      "Yafu Li",
      "Zican Hu",
      "Zhi Wang",
      "Ganqu Cui",
      "Xiaoye Qu",
      "Yu Cheng",
      "Yue Zhang"
    ],
    "abstract": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning (RL) with simple rule-based rewards. However,\nexisting zero-RL approaches are inherently ``on-policy'', limiting learning to\na model's own outputs and failing to acquire reasoning abilities beyond its\ninitial capabilities. We introduce LUFFY (Learning to reason Under oFF-policY\nguidance), a framework that augments zero-RL with off-policy reasoning traces.\nLUFFY dynamically balances imitation and exploration by combining off-policy\ndemonstrations with on-policy rollouts during training. Notably, we propose\npolicy shaping via regularized importance sampling to avoid superficial and\nrigid imitation during mixed-policy training. Remarkably, LUFFY achieves an\nover +7.0 average gain across six math benchmarks and an advantage of over +6.2\npoints in out-of-distribution tasks. It also substantially surpasses\nimitation-based supervised fine-tuning (SFT), particularly in generalization.\nAnalysis shows LUFFY not only imitates effectively but also explores beyond\ndemonstrations, offering a scalable path to train generalizable reasoning\nmodels with off-policy guidance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Work in progress",
    "pdf_url": "http://arxiv.org/pdf/2504.14945v2",
    "published_date": "2025-04-21 08:09:13 UTC",
    "updated_date": "2025-04-22 15:37:25 UTC"
  },
  {
    "arxiv_id": "2504.14936v1",
    "title": "Giving AI a voice: how does AI think it should be treated?",
    "authors": [
      "Maria Fay",
      "Frederik F. Flöther"
    ],
    "abstract": "With the astounding progress in (generative) artificial intelligence (AI),\nthere has been significant public discourse regarding regulation and ethics of\nthe technology. Is it sufficient when humans discuss this with other humans?\nOr, given that AI is increasingly becoming a viable source of inspiration for\npeople (and let alone the hypothetical possibility that the technology may at\nsome point become \"artificial general intelligence\" and/or develop\nconsciousness), should AI not join the discourse? There are new questions and\nangles that AI brings to the table that we might not have considered before -\nso let us make the key subject of this book an active participant. This chapter\ntherefore includes a brief human-AI conversation on the topic of AI rights and\nethics.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14936v1",
    "published_date": "2025-04-21 07:59:17 UTC",
    "updated_date": "2025-04-21 07:59:17 UTC"
  },
  {
    "arxiv_id": "2504.14928v1",
    "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework",
    "authors": [
      "Yao Shi",
      "Rongkeng Liang",
      "Yong Xu"
    ],
    "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.",
    "categories": [
      "cs.AI",
      "cs.CE",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14928v1",
    "published_date": "2025-04-21 07:48:20 UTC",
    "updated_date": "2025-04-21 07:48:20 UTC"
  },
  {
    "arxiv_id": "2504.14921v1",
    "title": "Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos",
    "authors": [
      "Songping Wang",
      "Hanqing Liu",
      "Yueming Lyu",
      "Xiantao Hu",
      "Ziwen He",
      "Wei Wang",
      "Caifeng Shan",
      "Liang Wang"
    ],
    "abstract": "Adversarial Training (AT) has been shown to significantly enhance adversarial\nrobustness via a min-max optimization approach. However, its effectiveness in\nvideo recognition tasks is hampered by two main challenges. First, fast\nadversarial training for video models remains largely unexplored, which\nseverely impedes its practical applications. Specifically, most video\nadversarial training methods are computationally costly, with long training\ntimes and high expenses. Second, existing methods struggle with the trade-off\nbetween clean accuracy and adversarial robustness. To address these challenges,\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\n(VFAT-WS), the first fast adversarial training method for video data.\nSpecifically, VFAT-WS incorporates the following key designs: First, it\nintegrates a straightforward yet effective temporal frequency augmentation\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\ndevises a weak-to-strong spatial-temporal consistency regularization, which\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\nLeveraging the consistency regularization, it steers the learning process from\nsimple to complex augmentations. Both of them work together to achieve a better\ntrade-off between clean accuracy and robustness. Extensive experiments on\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\nVFAT-WS achieves great improvements in adversarial robustness and corruption\nrobustness, while accelerating training by nearly 490%.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14921v1",
    "published_date": "2025-04-21 07:40:35 UTC",
    "updated_date": "2025-04-21 07:40:35 UTC"
  },
  {
    "arxiv_id": "2504.14915v1",
    "title": "StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models",
    "authors": [
      "Yeona Hong",
      "Hyewon Han",
      "Woo-jin Chung",
      "Hong-Goo Kang"
    ],
    "abstract": "In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.",
    "categories": [
      "eess.AS",
      "cs.AI"
    ],
    "primary_category": "eess.AS",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14915v1",
    "published_date": "2025-04-21 07:33:27 UTC",
    "updated_date": "2025-04-21 07:33:27 UTC"
  },
  {
    "arxiv_id": "2504.14913v1",
    "title": "Guidelines for External Disturbance Factors in the Use of OCR in Real-World Environments",
    "authors": [
      "Kenji Iwata",
      "Eiki Ishidera",
      "Toshifumi Yamaai",
      "Yutaka Satoh",
      "Hiroshi Tanaka",
      "Katsuhiko Takahashi",
      "Akio Furuhata",
      "Yoshihisa Tanabe",
      "Hiroshi Matsumura"
    ],
    "abstract": "The performance of OCR has improved with the evolution of AI technology. As\nOCR continues to broaden its range of applications, the increased likelihood of\ninterference introduced by various usage environments can prevent it from\nachieving its inherent performance. This results in reduced recognition\naccuracy under certain conditions, and makes the quality control of recognition\ndevices more challenging. Therefore, to ensure that users can properly utilize\nOCR, we compiled the real-world external disturbance factors that cause\nperformance degradation, along with the resulting image degradation phenomena,\ninto an external disturbance factor table and, by also indicating how to make\nuse of it, organized them into guidelines.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.5.2; I.5.m"
    ],
    "primary_category": "cs.CV",
    "comment": "16 pages, 14 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14913v1",
    "published_date": "2025-04-21 07:32:28 UTC",
    "updated_date": "2025-04-21 07:32:28 UTC"
  },
  {
    "arxiv_id": "2504.14904v1",
    "title": "VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform",
    "authors": [
      "Xingyu Lu",
      "Tianke Zhang",
      "Chang Meng",
      "Xiaobei Wang",
      "Jinpeng Wang",
      "YiFan Zhang",
      "Shisong Tang",
      "Changyi Liu",
      "Haojie Ding",
      "Kaiyu Jiang",
      "Kaiyu Tang",
      "Bin Wen",
      "Hai-Tao Zheng",
      "Fan Yang",
      "Tingting Gao",
      "Di Zhang",
      "Kun Gai"
    ],
    "abstract": "Exponentially growing short video platforms (SVPs) face significant\nchallenges in moderating content detrimental to users' mental health,\nparticularly for minors. The dissemination of such content on SVPs can lead to\ncatastrophic societal consequences. Although substantial efforts have been\ndedicated to moderating such content, existing methods suffer from critical\nlimitations: (1) Manual review is prone to human bias and incurs high\noperational costs. (2) Automated methods, though efficient, lack nuanced\ncontent understanding, resulting in lower accuracy. (3) Industrial moderation\nregulations struggle to adapt to rapidly evolving trends due to long update\ncycles. In this paper, we annotate the first SVP content moderation benchmark\nwith authentic user/reviewer feedback to fill the absence of benchmark in this\nfield. Then we evaluate various methods on the benchmark to verify the\nexistence of the aforementioned limitations. We further propose our common-law\ncontent moderation framework named KuaiMod to address these challenges. KuaiMod\nconsists of three components: training data construction, offline adaptation,\nand online deployment & refinement. Leveraging large vision language model\n(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video\ntoxicity based on sparse user feedback and fosters dynamic moderation policy\nwith rapid update speed and high accuracy. Offline experiments and large-scale\nonline A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the\nbest moderation performance on our benchmark. The deployment of KuaiMod reduces\nthe user reporting rate by 20% and its application in video recommendation\nincreases both Daily Active User (DAU) and APP Usage Time (AUT) on several\nKuaishou scenarios. We have open-sourced our benchmark at\nhttps://kuaimod.github.io.",
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.MM"
    ],
    "primary_category": "cs.SI",
    "comment": "20 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14904v1",
    "published_date": "2025-04-21 07:20:19 UTC",
    "updated_date": "2025-04-21 07:20:19 UTC"
  },
  {
    "arxiv_id": "2504.14889v1",
    "title": "Latent Bayesian Optimization via Autoregressive Normalizing Flows",
    "authors": [
      "Seunghun Lee",
      "Jinyoung Park",
      "Jaewon Chu",
      "Minseo Yoon",
      "Hyunwoo J. Kim"
    ],
    "abstract": "Bayesian Optimization (BO) has been recognized for its effectiveness in\noptimizing expensive and complex objective functions. Recent advancements in\nLatent Bayesian Optimization (LBO) have shown promise by integrating generative\nmodels such as variational autoencoders (VAEs) to manage the complexity of\nhigh-dimensional and structured data spaces. However, existing LBO approaches\noften suffer from the value discrepancy problem, which arises from the\nreconstruction gap between input and latent spaces. This value discrepancy\nproblem propagates errors throughout the optimization process, leading to\nsuboptimal outcomes. To address this issue, we propose a Normalizing Flow-based\nBayesian Optimization (NF-BO), which utilizes normalizing flow as a generative\nmodel to establish one-to-one encoding function from the input space to the\nlatent space, along with its left-inverse decoding function, eliminating the\nreconstruction gap. Specifically, we introduce SeqFlow, an autoregressive\nnormalizing flow for sequence data. In addition, we develop a new candidate\nsampling strategy that dynamically adjusts the exploration probability for each\ntoken based on its importance. Through extensive experiments, our NF-BO method\ndemonstrates superior performance in molecule generation tasks, significantly\noutperforming both traditional and recent LBO approaches.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14889v1",
    "published_date": "2025-04-21 06:36:09 UTC",
    "updated_date": "2025-04-21 06:36:09 UTC"
  },
  {
    "arxiv_id": "2504.14879v1",
    "title": "Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder Versus ViT-Encoder",
    "authors": [
      "Hassan Wasswa",
      "Aziida Nanyonga",
      "Timothy Lynar"
    ],
    "abstract": "The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14879v1",
    "published_date": "2025-04-21 06:15:07 UTC",
    "updated_date": "2025-04-21 06:15:07 UTC"
  },
  {
    "arxiv_id": "2504.14875v1",
    "title": "ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams",
    "authors": [
      "Chris Dongjoo Kim",
      "Jihwan Moon",
      "Sangwoo Moon",
      "Heeseung Yun",
      "Sihaeng Lee",
      "Aniruddha Kembhavi",
      "Soonyoung Lee",
      "Gunhee Kim",
      "Sangho Lee",
      "Christopher Clark"
    ],
    "abstract": "The rapid growth of video-text data presents challenges in storage and\ncomputation during training. Online learning, which processes streaming data in\nreal-time, offers a promising solution to these issues while also allowing\nswift adaptations in scenarios demanding real-time responsiveness. One strategy\nto enhance the efficiency and effectiveness of learning involves identifying\nand prioritizing data that enhances performance on target downstream tasks. We\npropose Relevance and Specificity-based online filtering framework (ReSpec)\nthat selects data based on four criteria: (i) modality alignment for clean\ndata, (ii) task relevance for target focused data, (iii) specificity for\ninformative and detailed data, and (iv) efficiency for low-latency processing.\nRelevance is determined by the probabilistic alignment of incoming data with\ndownstream tasks, while specificity employs the distance to a root embedding\nrepresenting the least specific data as an efficient proxy for informativeness.\nBy establishing reference points from target task data, ReSpec filters incoming\ndata in real-time, eliminating the need for extensive storage and compute.\nEvaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains\nstate-of-the-art performance on five zeroshot video retrieval tasks, using as\nlittle as 5% of the data while incurring minimal compute. The source code is\navailable at https://github.com/cdjkim/ReSpec.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025 (main conference)",
    "pdf_url": "http://arxiv.org/pdf/2504.14875v1",
    "published_date": "2025-04-21 06:02:03 UTC",
    "updated_date": "2025-04-21 06:02:03 UTC"
  },
  {
    "arxiv_id": "2504.14870v1",
    "title": "OTC: Optimal Tool Calls via Reinforcement Learning",
    "authors": [
      "Hongru Wang",
      "Cheng Qian",
      "Wanjun Zhong",
      "Xiusi Chen",
      "Jiahao Qiu",
      "Shijue Huang",
      "Bowen Jin",
      "Mengdi Wang",
      "Kam-Fai Wong",
      "Heng Ji"
    ],
    "abstract": "Tool-integrated reasoning (TIR) augments large language models (LLMs) with\nthe ability to invoke external tools, such as search engines and code\ninterpreters, to solve tasks beyond the capabilities of language-only\nreasoning. While reinforcement learning (RL) has shown promise in improving TIR\nby optimizing final answer correctness, existing approaches often overlook the\nefficiency and cost associated with tool usage. This can lead to suboptimal\nbehavior, including excessive tool calls that increase computational and\nfinancial overhead, or insufficient tool use that compromises answer quality.\nIn this work, we propose Optimal Tool Call-controlled Policy Optimization\n(OTC-PO), a simple yet effective RL-based framework that encourages models to\nproduce accurate answers with minimal tool calls. Our method introduces a\ntool-integrated reward that jointly considers correctness and tool efficiency,\npromoting high tool productivity. We instantiate this framework within both\nProximal Policy Optimization (PPO) and Group Relative Preference Optimization\n(GRPO), resulting in OTC-PPO and OTC-GRPO. Experiments with Qwen-2.5 and\nQwen-Math across multiple QA benchmarks show that our approach reduces tool\ncalls by up to 73.1\\% and improves tool productivity by up to 229.4\\%, while\nmaintaining comparable answer accuracy. To the best of our knowledge, this is\nthe first RL-based framework that explicitly optimizes tool-use efficiency in\nTIR.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14870v1",
    "published_date": "2025-04-21 05:40:05 UTC",
    "updated_date": "2025-04-21 05:40:05 UTC"
  },
  {
    "arxiv_id": "2504.14860v1",
    "title": "Bridge the Gap: From Weak to Full Supervision for Temporal Action Localization with PseudoFormer",
    "authors": [
      "Ziyi Liu",
      "Yangcen Liu"
    ],
    "abstract": "Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025: IEEE Conference on Computer Vision and Pattern Recognition",
    "pdf_url": "http://arxiv.org/pdf/2504.14860v1",
    "published_date": "2025-04-21 05:00:07 UTC",
    "updated_date": "2025-04-21 05:00:07 UTC"
  },
  {
    "arxiv_id": "2504.14858v1",
    "title": "AlignRAG: An Adaptable Framework for Resolving Misalignments in Retrieval-Aware Reasoning of RAG",
    "authors": [
      "Jiaqi Wei",
      "Hao Zhou",
      "Xiang Zhang",
      "Di Zhang",
      "Zijie Qiu",
      "Wei Wei",
      "Jinzhe Li",
      "Wanli Ouyang",
      "Siqi Sun"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a foundational paradigm\nfor knowledge-grounded text generation. However, existing RAG pipelines often\nfail to ensure that the reasoning trajectories align with the evidential\nconstraints imposed by retrieved content. In this paper, we reframe RAG as a\nproblem of retrieval-aware reasoning and identify a core challenge: reasoning\nmisalignment-the mismatch between a model's reasoning trajectory and the\nretrieved evidence. To address this challenge, we propose AlignRAG, a novel\ntest-time framework that mitigates reasoning misalignment through iterative\nCritique-Driven Alignment (CDA) steps. In contrast to prior approaches that\nrely on static training or post-hoc selection, AlignRAG actively refines\nreasoning trajectories during inference by enforcing fine-grained alignment\nwith evidence. Our framework introduces a new paradigm for retrieval-aware\nreasoning by: (1) constructing context-rich training corpora; (2) generating\ncontrastive critiques from preference-aware reasoning trajectories; (3)\ntraining a dedicated \\textit{Critic Language Model (CLM)} to identify reasoning\nmisalignments; and (4) applying CDA steps to optimize reasoning trajectories\niteratively. Empirical results demonstrate that AlignRAG consistently\noutperforms all baselines and could integrate as a plug-and-play module into\nexisting RAG pipelines without further changes. By reconceptualizing RAG as a\nstructured reasoning trajectory and establishing the test-time framework for\ncorrecting reasoning misalignments in RAG, AlignRAG provides practical\nadvancements for retrieval-aware generation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14858v1",
    "published_date": "2025-04-21 04:56:47 UTC",
    "updated_date": "2025-04-21 04:56:47 UTC"
  },
  {
    "arxiv_id": "2504.14848v1",
    "title": "Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation",
    "authors": [
      "Yunpu Zhao",
      "Rui Zhang",
      "Junbin Xiao",
      "Ruibo Hou",
      "Jiaming Guo",
      "Zihao Zhang",
      "Yifan Hao",
      "Yunji Chen"
    ],
    "abstract": "Vision-language models (VLMs) excel in various multimodal tasks but\nfrequently suffer from poor calibration, resulting in misalignment between\ntheir verbalized confidence and response correctness. This miscalibration\nundermines user trust, especially when models confidently provide incorrect or\nfabricated information. In this work, we propose a novel Confidence Calibration\nthrough Semantic Perturbation (CSP) framework to improve the calibration of\nverbalized confidence for VLMs in response to object-centric queries. We first\nintroduce a perturbed dataset where Gaussian noise is applied to the key object\nregions to simulate visual uncertainty at different confidence levels,\nestablishing an explicit mapping between visual ambiguity and confidence\nlevels. We further enhance calibration through a two-stage training process\ncombining supervised fine-tuning on the perturbed dataset with subsequent\npreference optimization. Extensive experiments on popular benchmarks\ndemonstrate that our method significantly improves the alignment between\nverbalized confidence and response correctness while maintaining or enhancing\noverall task performance. These results highlight the potential of semantic\nperturbation as a practical tool for improving the reliability and\ninterpretability of VLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14848v1",
    "published_date": "2025-04-21 04:01:22 UTC",
    "updated_date": "2025-04-21 04:01:22 UTC"
  },
  {
    "arxiv_id": "2504.14839v1",
    "title": "Exploring $\\ell_0$ Sparsification for Inference-free Sparse Retrievers",
    "authors": [
      "Xinjie Shen",
      "Zhichao Geng",
      "Yang Yang"
    ],
    "abstract": "With increasing demands for efficiency, information retrieval has developed a\nbranch of sparse retrieval, further advancing towards inference-free retrieval\nwhere the documents are encoded during indexing time and there is no\nmodel-inference for queries. Existing sparse retrieval models rely on FLOPS\nregularization for sparsification, while this mechanism was originally designed\nfor Siamese encoders, it is considered to be suboptimal in inference-free\nscenarios which is asymmetric. Previous attempts to adapt FLOPS for\ninference-free scenarios have been limited to rule-based methods, leaving the\npotential of sparsification approaches for inference-free retrieval models\nlargely unexplored. In this paper, we explore $\\ell_0$ inspired sparsification\nmanner for inference-free retrievers. Through comprehensive out-of-domain\nevaluation on the BEIR benchmark, our method achieves state-of-the-art\nperformance among inference-free sparse retrieval models and is comparable to\nleading Siamese sparse retrieval models. Furthermore, we provide insights into\nthe trade-off between retrieval effectiveness and computational efficiency,\ndemonstrating practical value for real-world applications.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14839v1",
    "published_date": "2025-04-21 03:40:43 UTC",
    "updated_date": "2025-04-21 03:40:43 UTC"
  },
  {
    "arxiv_id": "2504.14838v1",
    "title": "Establishing Reliability Metrics for Reward Models in Large Language Models",
    "authors": [
      "Yizhou Chen",
      "Yawen Liu",
      "Xuesi Wang",
      "Qingtao Yu",
      "Guangda Huzhang",
      "Anxiang Zeng",
      "Han Yu",
      "Zhiming Zhou"
    ],
    "abstract": "The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14838v1",
    "published_date": "2025-04-21 03:39:33 UTC",
    "updated_date": "2025-04-21 03:39:33 UTC"
  },
  {
    "arxiv_id": "2504.14832v1",
    "title": "Protecting Your Voice: Temporal-aware Robust Watermarking",
    "authors": [
      "Yue Li",
      "Weizhi Liu",
      "Dongdong Lin"
    ],
    "abstract": "The rapid advancement of generative models has led to the synthesis of\nreal-fake ambiguous voices. To erase the ambiguity, embedding watermarks into\nthe frequency-domain features of synthesized voices has become a common\nroutine. However, the robustness achieved by choosing the frequency domain\noften comes at the expense of fine-grained voice features, leading to a loss of\nfidelity. Maximizing the comprehensive learning of time-domain features to\nenhance fidelity while maintaining robustness, we pioneer a\n\\textbf{\\underline{t}}emporal-aware\n\\textbf{\\underline{r}}ob\\textbf{\\underline{u}}st\nwat\\textbf{\\underline{e}}rmarking (\\emph{True}) method for protecting the\nspeech and singing voice.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14832v1",
    "published_date": "2025-04-21 03:23:10 UTC",
    "updated_date": "2025-04-21 03:23:10 UTC"
  },
  {
    "arxiv_id": "2504.14825v1",
    "title": "ECViT: Efficient Convolutional Vision Transformer with Local-Attention and Multi-scale Stages",
    "authors": [
      "Zhoujie Qian"
    ],
    "abstract": "Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14825v1",
    "published_date": "2025-04-21 03:00:17 UTC",
    "updated_date": "2025-04-21 03:00:17 UTC"
  },
  {
    "arxiv_id": "2504.14815v1",
    "title": "What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale",
    "authors": [
      "Xiaoyong Yuan",
      "Xiaolong Ma",
      "Linke Guo",
      "Lan Zhang"
    ],
    "abstract": "Diffusion models (DMs) have revolutionized text-to-image generation, enabling\nthe creation of highly realistic and customized images from text prompts. With\nthe rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users\ncan now customize powerful pre-trained models using minimal computational\nresources. However, the widespread sharing of fine-tuned DMs on open platforms\nraises growing ethical and legal concerns, as these models may inadvertently or\ndeliberately generate sensitive or unauthorized content, such as copyrighted\nmaterial, private individuals, or harmful content. Despite the increasing\nregulatory attention on generative AI, there are currently no practical tools\nfor systematically auditing these models before deployment. In this paper, we\naddress the problem of concept auditing: determining whether a fine-tuned DM\nhas learned to generate a specific target concept. Existing approaches\ntypically rely on prompt-based input crafting and output-based image\nclassification but suffer from critical limitations, including prompt\nuncertainty, concept drift, and poor scalability. To overcome these challenges,\nwe introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric\nconcept auditing framework. By treating the DM as the object of inspection,\nPAIA enables direct analysis of internal model behavior, bypassing the need for\noptimized prompts or generated images. We evaluate PAIA on 320 controlled model\nand 690 real-world community models sourced from a public DM sharing platform.\nPAIA achieves over 90% detection accuracy while reducing auditing time by\n18-40x compared to existing baselines. To our knowledge, PAIA is the first\nscalable and practical solution for pre-deployment concept auditing of\ndiffusion models, providing a practical foundation for safer and more\ntransparent diffusion model sharing.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "17 pages, 15 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14815v1",
    "published_date": "2025-04-21 02:44:59 UTC",
    "updated_date": "2025-04-21 02:44:59 UTC"
  },
  {
    "arxiv_id": "2504.14810v1",
    "title": "DONOD: Robust and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning",
    "authors": [
      "Jucheng Hu",
      "Surong Yang",
      "Dongzhan Zhou",
      "Lijun Wu"
    ],
    "abstract": "Ad-hoc instruction fine-tuning of large language models (LLMs) is widely\nadopted for domain-specific adaptation. While domain-specific supervised\nfine-tuning (SFT) is effective and efficient, it often weakens cross-domain\ngeneralization and struggles with noisy training data. To address these\nchallenges, we propose DONOD, a lightweight model-intrinsic data pruning\nmethod. Our approach evaluates data using two model-parameter-based metrics:\nDelta of Norm (DON), which captures the cumulative influence on model weights,\nand Norm of Delta (NOD), which quantifies weight instability. Moreover, by\nemploying the Technique for Order of Preference by Similarity to Ideal Solution\n(TOPSIS) algorithm, we effectively filter noisy, unlearnable, and\ngeneralization-harming samples without relying on auxiliary models during the\nSFT process. Experiments on mathematical tasks demonstrate that data selected\nby DONOD achieve superior fine-tuning efficiency and improved robustness\nagainst noisy data. By filtering out 70% of the full dataset, we improve\ntarget-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile,\nour selected data present superior cross-architecture generalization. Data\npruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger\nmodels (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD\ndemonstrates comparable or superior performance while remaining\ndataset-agnostic, enabling broader applicability.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14810v1",
    "published_date": "2025-04-21 02:25:03 UTC",
    "updated_date": "2025-04-21 02:25:03 UTC"
  },
  {
    "arxiv_id": "2504.14808v1",
    "title": "On Self-improving Token Embeddings",
    "authors": [
      "Mario M. Kubek",
      "Shiraj Pokharel",
      "Thomas Böhme",
      "Emma L. McDaniel",
      "Herwig Unger",
      "Armin R. Mikler"
    ],
    "abstract": "This article introduces a novel and fast method for refining pre-trained\nstatic word or, more generally, token embeddings. By incorporating the\nembeddings of neighboring tokens in text corpora, it continuously updates the\nrepresentation of each token, including those without pre-assigned embeddings.\nThis approach effectively addresses the out-of-vocabulary problem, too.\nOperating independently of large language models and shallow neural networks,\nit enables versatile applications such as corpus exploration, conceptual\nsearch, and word sense disambiguation. The method is designed to enhance token\nrepresentations within topically homogeneous corpora, where the vocabulary is\nrestricted to a specific domain, resulting in more meaningful embeddings\ncompared to general-purpose pre-trained vectors. As an example, the methodology\nis applied to explore storm events and their impacts on infrastructure and\ncommunities using narratives from a subset of the NOAA Storm Events database.\nThe article also demonstrates how the approach improves the representation of\nstorm-related terms over time, providing valuable insights into the evolving\nnature of disaster narratives.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG",
      "68T50, 68T07",
      "I.2.6; I.2.7; H.3.3"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 4 figures, 3 tables, accepted at the 2025 25th\n  International Conference on Innovations for Community Services (I4CS), June\n  11 - 13, Munich, Germany, 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14808v1",
    "published_date": "2025-04-21 02:17:19 UTC",
    "updated_date": "2025-04-21 02:17:19 UTC"
  },
  {
    "arxiv_id": "2504.14805v1",
    "title": "Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment",
    "authors": [
      "Jinwoo Choi",
      "Seung-Woo Seo"
    ],
    "abstract": "Reinforcement learning (RL) has made significant progress in various domains,\nbut scaling it to long-horizon tasks with complex decision-making remains\nchallenging. Skill learning attempts to address this by abstracting actions\ninto higher-level behaviors. However, current approaches often fail to\nrecognize semantically similar behaviors as the same skill and use fixed skill\nlengths, limiting flexibility and generalization. To address this, we propose\nDynamic Contrastive Skill Learning (DCSL), a novel framework that redefines\nskill representation and learning. DCSL introduces three key ideas:\nstate-transition based skill representation, skill similarity function\nlearning, and dynamic skill length adjustment. By focusing on state transitions\nand leveraging contrastive learning, DCSL effectively captures the semantic\ncontext of behaviors and adapts skill lengths to match the appropriate temporal\nextent of behaviors. Our approach enables more flexible and adaptive skill\nextraction, particularly in complex or noisy datasets, and demonstrates\ncompetitive performance compared to existing methods in task completion and\nefficiency.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025; 23 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.14805v1",
    "published_date": "2025-04-21 02:11:39 UTC",
    "updated_date": "2025-04-21 02:11:39 UTC"
  },
  {
    "arxiv_id": "2504.14804v1",
    "title": "Automatic Evaluation Metrics for Document-level Translation: Overview, Challenges and Trends",
    "authors": [
      "Jiaxin GUO",
      "Xiaoyu Chen",
      "Zhiqiang Rao",
      "Jinlong Yang",
      "Zongyao Li",
      "Hengchao Shang",
      "Daimeng Wei",
      "Hao Yang"
    ],
    "abstract": "With the rapid development of deep learning technologies, the field of\nmachine translation has witnessed significant progress, especially with the\nadvent of large language models (LLMs) that have greatly propelled the\nadvancement of document-level translation. However, accurately evaluating the\nquality of document-level translation remains an urgent issue. This paper first\nintroduces the development status of document-level translation and the\nimportance of evaluation, highlighting the crucial role of automatic evaluation\nmetrics in reflecting translation quality and guiding the improvement of\ntranslation systems. It then provides a detailed analysis of the current state\nof automatic evaluation schemes and metrics, including evaluation methods with\nand without reference texts, as well as traditional metrics, Model-based\nmetrics and LLM-based metrics. Subsequently, the paper explores the challenges\nfaced by current evaluation methods, such as the lack of reference diversity,\ndependence on sentence-level alignment information, and the bias, inaccuracy,\nand lack of interpretability of the LLM-as-a-judge method. Finally, the paper\nlooks ahead to the future trends in evaluation methods, including the\ndevelopment of more user-friendly document-level evaluation methods and more\nrobust LLM-as-a-judge methods, and proposes possible research directions, such\nas reducing the dependency on sentence-level information, introducing\nmulti-level and multi-granular evaluation approaches, and training models\nspecifically for machine translation evaluation. This study aims to provide a\ncomprehensive analysis of automatic evaluation for document-level translation\nand offer insights into future developments.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14804v1",
    "published_date": "2025-04-21 02:08:42 UTC",
    "updated_date": "2025-04-21 02:08:42 UTC"
  },
  {
    "arxiv_id": "2504.14797v1",
    "title": "Automated Duplicate Bug Report Detection in Large Open Bug Repositories",
    "authors": [
      "Clare E. Laney",
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "Many users and contributors of large open-source projects report software\ndefects or enhancement requests (known as bug reports) to the issue-tracking\nsystems. However, they sometimes report issues that have already been reported.\nFirst, they may not have time to do sufficient research on existing bug\nreports. Second, they may not possess the right expertise in that specific area\nto realize that an existing bug report is essentially elaborating on the same\nmatter, perhaps with a different wording. In this paper, we propose a novel\napproach based on machine learning methods that can automatically detect\nduplicate bug reports in an open bug repository based on the textual data in\nthe reports. We present six alternative methods: Topic modeling, Gaussian Naive\nBayes, deep learning, time-based organization, clustering, and summarization\nusing a generative pre-trained transformer large language model. Additionally,\nwe introduce a novel threshold-based approach for duplicate identification, in\ncontrast to the conventional top-k selection method that has been widely used\nin the literature. Our approach demonstrates promising results across all the\nproposed methods, achieving accuracy rates ranging from the high 70%'s to the\nlow 90%'s. We evaluated our methods on a public dataset of issues belonging to\nan Eclipse open-source project.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "IEEE COMPSAC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.14797v1",
    "published_date": "2025-04-21 01:55:54 UTC",
    "updated_date": "2025-04-21 01:55:54 UTC"
  },
  {
    "arxiv_id": "2504.14783v1",
    "title": "How Effective Can Dropout Be in Multiple Instance Learning ?",
    "authors": [
      "Wenhui Zhu",
      "Peijie Qiu",
      "Xiwen Chen",
      "Zhangsihao Yang",
      "Aristeidis Sotiras",
      "Abolfazl Razi",
      "Yalin Wang"
    ],
    "abstract": "Multiple Instance Learning (MIL) is a popular weakly-supervised method for\nvarious applications, with a particular interest in histological whole slide\nimage (WSI) classification. Due to the gigapixel resolution of WSI,\napplications of MIL in WSI typically necessitate a two-stage training scheme:\nfirst, extract features from the pre-trained backbone and then perform MIL\naggregation. However, it is well-known that this suboptimal training scheme\nsuffers from \"noisy\" feature embeddings from the backbone and inherent weak\nsupervision, hindering MIL from learning rich and generalizable features.\nHowever, the most commonly used technique (i.e., dropout) for mitigating this\nissue has yet to be explored in MIL. In this paper, we empirically explore how\neffective the dropout can be in MIL. Interestingly, we observe that dropping\nthe top-k most important instances within a bag leads to better performance and\ngeneralization even under noise attack. Based on this key observation, we\npropose a novel MIL-specific dropout method, termed MIL-Dropout, which\nsystematically determines which instances to drop. Experiments on five MIL\nbenchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the\nperformance of current MIL methods with a negligible computational cost. The\ncode is available at https://github.com/ChongQingNoSubway/MILDropout.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "stat.ML"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.14783v1",
    "published_date": "2025-04-21 00:46:31 UTC",
    "updated_date": "2025-04-21 00:46:31 UTC"
  },
  {
    "arxiv_id": "2504.14779v1",
    "title": "Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work",
    "authors": [
      "Janet G. Johnson",
      "Macarena Peralta",
      "Mansanjam Kaur",
      "Ruijie Sophia Huang",
      "Sheng Zhao",
      "Ruijia Guan",
      "Shwetha Rajaram",
      "Michael Nebeling"
    ],
    "abstract": "While generative artificial intelligence (GenAI) is finding increased\nadoption in workplaces, current tools are primarily designed for individual\nuse. Prior work established the potential for these tools to enhance personal\ncreativity and productivity towards shared goals; however, we don't know yet\nhow to best take into account the nuances of group work and team dynamics when\ndeploying GenAI in work settings. In this paper, we investigate the potential\nof collaborative GenAI agents to augment teamwork in synchronous group settings\nthrough an exploratory study that engaged 25 professionals across 6 teams in\nspeculative design workshops and individual follow-up interviews. Our workshops\nincluded a mixed reality provotype to simulate embodied collaborative GenAI\nagents capable of actively participating in group discussions. Our findings\nsuggest that, if designed well, collaborative GenAI agents offer valuable\nopportunities to enhance team problem-solving by challenging groupthink,\nbridging communication gaps, and reducing social friction. However, teams'\nwillingness to integrate GenAI agents depended on its perceived fit across a\nnumber of individual, team, and organizational factors. We outline the key\ndesign tensions around agent representation, social prominence, and engagement\nand highlight the opportunities spatial and immersive technologies could offer\nto modulate GenAI influence on team outcomes and strike a balance between\naugmentation and agency.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "To be published in ACM Conference on Computer-Supported Cooperative\n  Work and Social Computing (CSCW 2025). 33 pages, 11 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.14779v1",
    "published_date": "2025-04-21 00:38:02 UTC",
    "updated_date": "2025-04-21 00:38:02 UTC"
  },
  {
    "arxiv_id": "2504.14773v1",
    "title": "PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities",
    "authors": [
      "Haoming Li",
      "Zhaoliang Chen",
      "Jonathan Zhang",
      "Fei Liu"
    ],
    "abstract": "Planning is central to agents and agentic AI. The ability to plan, e.g.,\ncreating travel itineraries within a budget, holds immense potential in both\nscientific and commercial contexts. Moreover, optimal plans tend to require\nfewer resources compared to ad-hoc methods. To date, a comprehensive\nunderstanding of existing planning benchmarks appears to be lacking. Without\nit, comparing planning algorithms' performance across domains or selecting\nsuitable algorithms for new scenarios remains challenging. In this paper, we\nexamine a range of planning benchmarks to identify commonly used testbeds for\nalgorithm development and highlight potential gaps. These benchmarks are\ncategorized into embodied environments, web navigation, scheduling, games and\npuzzles, and everyday task automation. Our study recommends the most\nappropriate benchmarks for various algorithms and offers insights to guide\nfuture benchmark development.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.14773v1",
    "published_date": "2025-04-21 00:02:50 UTC",
    "updated_date": "2025-04-21 00:02:50 UTC"
  }
]