{
  "date": "2025-04-21",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-21 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文聚焦 AI 模型优化、推理机制、多模态学习和安全伦理等领域，重点包括 LLM 的计算最优泛化、AI 代理的自我改进，以及知名学者如 Mohit Bansal、Trevor Darrell 和 Andrew Gordon Wilson 的作品，这些论文展示了 AI 在高效训练和实际应用中的创新潜力。\n\n下面，我将逐一简要概述部分关键论文，先优先讨论那些创新性强、可能引发话题的文章（如 LLM 优化和多代理系统），然后快速掠过其他较常规的论文。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### 重点论文讨论\n\n**Learning Adaptive Parallel Reasoning with Language Models (学习自适应并行推理的语言模型)**  \n这篇论文由 Trevor Darrell 等知名学者撰写，提出 APR 框架，通过强化学习优化语言模型的并行和序列化计算。主要贡献是提升了模型在推理任务中的性能，例如在 Countdown 任务中，APR 在相同上下文窗口下实现了 83.4% 的准确率，显著优于传统方法，展示了 LLM 在复杂计算中的可扩展性。\n\n**Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning (停止求和：最小形式信用分配是过程奖励模型用于推理所需的一切)**  \n论文创新性地优化了 LLM 的奖励模型，使用最小形式信用分配来缓解奖励黑客问题。主要发现是通过这种方法，模型在数学基准上达到 82.5% 的准确率，显著减少训练崩溃风险，为 LLM 推理的鲁棒性提供了新路径。\n\n**FlowReasoner: Reinforcing Query-Level Meta-Agents (FlowReasoner：强化查询级元代理)**  \n这篇论文引入了 FlowReasoner 框架，通过强化学习强化多代理系统的查询处理。主要贡献是模型能为每个用户查询生成个性化代理系统，并在代码基准上超越 o1-mini 10.52% 的准确率，突显 AI 代理在自动化任务中的潜力。\n\n**Compute-Optimal LLMs Provably Generalize Better With Scale (计算最优的 LLM 证明了随着规模增长泛化更好)**  \nAndrew Gordon Wilson 等学者参与，论文通过理论分析证明了更大规模的 LLM 在计算最优条件下具有更好的泛化边界。主要发现是，随着模型规模增加，泛化差距缩小，这为 LLM 扩展提供了坚实依据。\n\n**A Self-Improving Coding Agent (一个自我改进的编码代理)**  \n论文提出了一种能自我编辑代码的 AI 代理框架，通过强化学习提升性能。主要贡献是代理在代码基准上性能提升 17-53%，展示了 AI 系统自主优化的可能性，这对未来代理设计有重要启发。\n\n**CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting (CAPTURe：通过遮挡物体计数评估视觉语言模型的空间推理)**  \nMohit Bansal 等作者开发了 CAPTURe 任务，测试 VLMs 在遮挡场景下的空间理解。主要发现是现有模型在遮挡计数上表现差劲，而人类表现优秀，这突出了 VLMs 在真实世界应用中的局限性。\n\n**Towards Understanding Camera Motions in Any Video (理解任意视频中的相机运动)**  \nDeva Ramanan 等学者构建了 CameraBench 数据集和基准，评估相机运动理解。主要贡献是引入相机运动分类学，并通过细调 VLM 提升了视频分析性能，适用于视频问答和检索任务。\n\n**Trends in Frontier AI Model Count: A Forecast to 2028 (前沿 AI 模型数量趋势：到 2028 年的预测)**  \n论文预测了 AI 模型训练计算阈值的影响，主要发现到 2028 年，将有 103-306 个模型超过欧盟 AI 法案阈值，这对 AI 监管政策有现实启示。\n\n**The AI Co-Ethnographer: How Far Can Automation Take Qualitative Research? (AI 共同民族志学家：自动化能将定性研究推进多远？)**  \n论文提出 AICoE 管道，用于自动化定性研究分析。主要贡献是整合编码和模式发现，展示了 AI 在社会科学中的潜力。\n\n### 其他论文快速概述\n\n其余论文较多，我将快速掠过不那么核心的主题，仅突出主要贡献：\n\n**DualBreach: KeyDiff: Trillion 7B Technical Report 等 AI 安全和模型优化论文**  \n这些论文如 DualBreach (双重越狱检测) 探讨了 AI 鲁棒性，KeyDiff (基于关键相似性的 KV 缓存优化) 提升了 LLM 长上下文推理效率，Trillion 7B (万亿级多语言 LLM) 介绍了高效知识转移机制。这些工作在 AI 安全和效率上有所创新，但整体影响力不如上述重点论文。\n\n**Solving New Tasks by Adapting Internet Video Knowledge 等应用论文**  \n论文如 Solving New Tasks (通过视频知识适应新任务) 提出了逆概率适应策略，提升机器人任务泛化；Breast density in MRI (MRI 中的乳腺密度量化) 使用 AI 改善医疗图像分析；这些在机器人和医疗领域有实际价值，但细节较具体，快速掠过。\n\n**余下论文，如量子计算、图像生成和伦理讨论**  \n论文如 Introduction to Quantum Machine Learning (量子机器学习介绍) 概述了量子与 AI 的整合；Values in the Wild (AI 价值的野外发现) 分析了 LLM 在真实交互中的伦理问题；其他如 Landmark-Free Registration (无 landmarks 图像配准) 和 GANFS (GAN 基于特征选择) 等，贡献在于特定领域优化，但不具广泛话题度，故仅简述为技术改进。\n\n总之，今天的论文强调了 AI 的高效性和鲁棒性，LLM 优化类文章最值得关注。如果您对特定领域感兴趣，建议查看这些重点论文的完整摘要！",
  "papers": [
    {
      "arxiv_id": "2504.15485v1",
      "title": "CAPTURe: Evaluating Spatial Reasoning in Vision Language Models via Occluded Object Counting",
      "title_zh": "CAPTURe：通过遮挡物体计数评估视觉语言模型中的空间推理",
      "authors": [
        "Atin Pothiraj",
        "Elias Stengel-Eskin",
        "Jaemin Cho",
        "Mohit Bansal"
      ],
      "abstract": "Recognizing and reasoning about occluded (partially or fully hidden) objects\nis vital to understanding visual scenes, as occlusions frequently occur in\nreal-world environments and act as obstacles for spatial comprehension. To test\nmodels' ability to reason about multiple occluded objects, we introduce a novel\ntask, Counting Amodally for Patterns Through Unseen REgions (CAPTURe), which\nrequires a model to count objects arranged in a pattern by inferring how the\npattern continues behind an occluder (an object which blocks parts of the\nscene). CAPTURe requires both recognizing visual patterns and reasoning, making\nit a useful testbed for evaluating vision-language models (VLMs) on whether\nthey understand occluded patterns and possess spatial understanding skills. By\nrequiring models to reason about occluded objects, CAPTURe also tests VLMs'\nability to form world models that would allow them to fill in missing\ninformation. CAPTURe consists of two parts: (1) CAPTURe-real, with manually\nfiltered images of real objects in patterns and (2) CAPTURe-synthetic, a\ncontrolled diagnostic with generated patterned images. We evaluate four strong\nVLMs (GPT-4o, Intern-VL2, Molmo, and Qwen2-VL) on CAPTURe, finding that models\nstruggle to count on both occluded and unoccluded patterns. Crucially, we find\nthat models perform worse with occlusion, suggesting that VLMs are also\ndeficient in inferring unseen spatial relationships: even the strongest VLMs\nlike GPT-4o fail to count with occlusion. In contrast, we find that humans\nachieve very little error on CAPTURe. We also find that providing auxiliary\ninformation of occluded object locations increases performance, underscoring\nthat the model error comes both from an inability to handle occlusion as well\nas difficulty counting in images.",
      "tldr_zh": "该论文引入了 CAPTURe 任务，用于评估视觉语言模型 (VLMs) 在处理遮挡物体时的空间推理能力，具体通过计数被遮挡物体模式来测试模型对未见区域的推断。CAPTURe 包括两个部分：CAPTURe-real（基于真实图像的手动筛选数据集）和 CAPTURe-synthetic（基于合成图像的控制诊断数据集）。实验结果显示，四种强 VLM（如 GPT-4o 和 Intern-VL2）在遮挡和非遮挡场景中均表现欠佳，尤其在遮挡情况下准确率更低，与人类的高性能形成对比。提供遮挡物体位置的辅助信息能显著提升模型性能，突显了 VLMs 在空间理解和处理遮挡方面的不足。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and data: https://github.com/atinpothiraj/CAPTURe",
      "pdf_url": "http://arxiv.org/pdf/2504.15485v1",
      "published_date": "2025-04-21 23:38:43 UTC",
      "updated_date": "2025-04-21 23:38:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:04:42.853006"
    },
    {
      "arxiv_id": "2504.16138v1",
      "title": "Trends in Frontier AI Model Count: A Forecast to 2028",
      "title_zh": "前沿 AI 模型数量的趋势：到 2028 年的预测",
      "authors": [
        "Iyngkarran Kumar",
        "Sam Manning"
      ],
      "abstract": "Governments are starting to impose requirements on AI models based on how\nmuch compute was used to train them. For example, the EU AI Act imposes\nrequirements on providers of general-purpose AI with systemic risk, which\nincludes systems trained using greater than $10^{25}$ floating point operations\n(FLOP). In the United States' AI Diffusion Framework, a training compute\nthreshold of $10^{26}$ FLOP is used to identify \"controlled models\" which face\na number of requirements. We explore how many models such training compute\nthresholds will capture over time. We estimate that by the end of 2028, there\nwill be between 103-306 foundation models exceeding the $10^{25}$ FLOP\nthreshold put forward in the EU AI Act (90% CI), and 45-148 models exceeding\nthe $10^{26}$ FLOP threshold that defines controlled models in the AI Diffusion\nFramework (90% CI). We also find that the number of models exceeding these\nabsolute compute thresholds each year will increase superlinearly -- that is,\neach successive year will see more new models captured within the threshold\nthan the year before. Thresholds that are defined with respect to the largest\ntraining run to date (for example, such that all models within one order of\nmagnitude of the largest training run to date are captured by the threshold)\nsee a more stable trend, with a median forecast of 14-16 models being captured\nby this definition annually from 2025-2028.",
      "tldr_zh": "本研究分析了基于训练计算量（如FLOP）设定的AI模型阈值，例如EU AI Act的10^25 FLOP和美国AI Diffusion Framework的10^26 FLOP，并对这些阈值下模型数量的未来趋势进行了预测。结果显示，到2028年底，将有103-306个基础模型超过EU AI Act阈值，以及45-148个超过AI Diffusion Framework阈值（90%置信区间），且这些模型数量每年呈超线性增长。相比之下，如果阈值定义为最大训练运行的一倍量级，则每年捕获的模型数量更稳定，预计2025-2028年间为14-16个。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16138v1",
      "published_date": "2025-04-21 22:31:57 UTC",
      "updated_date": "2025-04-21 22:31:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:04:54.721818"
    },
    {
      "arxiv_id": "2504.15466v1",
      "title": "Learning Adaptive Parallel Reasoning with Language Models",
      "title_zh": "使用语言模型的自适应并行推理学习",
      "authors": [
        "Jiayi Pan",
        "Xiuyu Li",
        "Long Lian",
        "Charlie Snell",
        "Yifei Zhou",
        "Adam Yala",
        "Trevor Darrell",
        "Kurt Keutzer",
        "Alane Suhr"
      ],
      "abstract": "Scaling inference-time computation has substantially improved the reasoning\ncapabilities of language models. However, existing methods have significant\nlimitations: serialized chain-of-thought approaches generate overly long\noutputs, leading to increased latency and exhausted context windows, while\nparallel methods such as self-consistency suffer from insufficient\ncoordination, resulting in redundant computations and limited performance\ngains. To address these shortcomings, we propose Adaptive Parallel Reasoning\n(APR), a novel reasoning framework that enables language models to orchestrate\nboth serialized and parallel computations end-to-end. APR generalizes existing\nreasoning methods by enabling adaptive multi-threaded inference using spawn()\nand join() operations. A key innovation is our end-to-end reinforcement\nlearning strategy, optimizing both parent and child inference threads to\nenhance task success rate without requiring predefined reasoning structures.\nExperiments on the Countdown reasoning task demonstrate significant benefits of\nAPR: (1) higher performance within the same context window (83.4% vs. 60.0% at\n4k context); (2) superior scalability with increased computation (80.1% vs.\n66.6% at 20k total tokens); (3) improved accuracy at equivalent latency (75.2%\nvs. 57.3% at approximately 5,000ms). APR represents a step towards enabling\nlanguage models to autonomously optimize their reasoning processes through\nadaptive allocation of computation.",
      "tldr_zh": "本文提出 Adaptive Parallel Reasoning (APR)，一种新框架，允许语言模型端到端协调序列化和并行计算，以解决现有方法如 chain-of-thought 的输出过长导致延迟问题，以及 self-consistency 的协调不足和冗余计算。APR 创新性地使用 spawn() 和 join() 操作实现自适应多线程推理，并通过端到端的 reinforcement learning 策略优化父子推理线程，提高任务成功率而不需预定义结构。在 Countdown 推理任务实验中，APR 展示了显著优势：包括在相同上下文窗口下性能提升（83.4% vs. 60.0%）、更好的可扩展性（80.1% vs. 66.6% at 20k tokens），以及在等效延迟下更高的准确率（75.2% vs. 57.3%）。这项工作推动语言模型自主优化推理过程，通过自适应分配计算资源。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Code, model, and data are available at\n  https://github.com/Parallel-Reasoning/APR. The first three authors\n  contributed equally to this work",
      "pdf_url": "http://arxiv.org/pdf/2504.15466v1",
      "published_date": "2025-04-21 22:29:02 UTC",
      "updated_date": "2025-04-21 22:29:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:05:07.618926"
    },
    {
      "arxiv_id": "2504.15457v2",
      "title": "Improving Human-AI Coordination through Adversarial Training and Generative Models",
      "title_zh": "通过对抗训练和生成模型改善人-AI 协调",
      "authors": [
        "Paresh Chaudhary",
        "Yancheng Liang",
        "Daphne Chen",
        "Simon S. Du",
        "Natasha Jaques"
      ],
      "abstract": "Being able to cooperate with new people is an important component of many\neconomically valuable AI tasks, from household robotics to autonomous driving.\nHowever, generalizing to novel humans requires training on data that captures\nthe diversity of human behaviors. Adversarial training is one avenue for\nsearching for such data and ensuring that agents are robust. However, it is\ndifficult to apply in the cooperative setting because adversarial policies\nintentionally learn to sabotage the task instead of simulating valid\ncooperation partners. To address this challenge, we propose a novel strategy\nfor overcoming self-sabotage that combines a pre-trained generative model to\nsimulate valid cooperative agent policies with adversarial training to maximize\nregret. We call our method GOAT: Generative Online Adversarial Training. In\nthis framework, the GOAT dynamically searches for and generates coordination\nstrategies where the learning policy -- the Cooperator agent -- underperforms.\nGOAT enables better generalization by exposing the Cooperator to various\nchallenging interaction scenarios. We maintain realistic coordination\nstrategies by updating only the generative model's embedding while keeping its\nparameters frozen, thus avoiding adversarial exploitation. We evaluate GOAT\nwith real human partners, and the results demonstrate state-of-the-art\nperformance on the Overcooked benchmark, highlighting its effectiveness in\ngeneralizing to diverse human behaviors.",
      "tldr_zh": "本论文提出 GOAT（Generative Online Adversarial Training）方法，通过结合预训练生成模型和对抗训练，提高 AI 与人类协调的泛化能力，以应对多样化人类行为。GOAT 动态搜索生成挑战性互动场景，让合作代理（Cooperator）暴露于各种复杂情境中，同时通过仅更新生成模型的嵌入而非其参数，确保策略的真实性和避免自毁。实验在 Overcooked 基准测试中验证了 GOAT 的有效性，与真实人类伙伴合作时实现了最先进性能，显著提升了 AI 的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15457v2",
      "published_date": "2025-04-21 21:53:00 UTC",
      "updated_date": "2025-04-29 21:02:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:05:18.286001"
    },
    {
      "arxiv_id": "2505.00012v1",
      "title": "The AI Co-Ethnographer: How Far Can Automation Take Qualitative Research?",
      "title_zh": "翻译失败",
      "authors": [
        "Fabian Retkowski",
        "Andreas Sudmann",
        "Alexander Waibel"
      ],
      "abstract": "Qualitative research often involves labor-intensive processes that are\ndifficult to scale while preserving analytical depth. This paper introduces The\nAI Co-Ethnographer (AICoE), a novel end-to-end pipeline developed for\nqualitative research and designed to move beyond the limitations of simply\nautomating code assignments, offering a more integrated approach. AICoE\norganizes the entire process, encompassing open coding, code consolidation,\ncode application, and even pattern discovery, leading to a comprehensive\nanalysis of qualitative data.",
      "tldr_zh": "本论文探讨了质性研究（Qualitative research）面临的挑战，即其劳动密集型过程难以扩展同时保持分析深度。作者引入了The AI Co-Ethnographer (AICoE)，一个新型端到端管道，超越了单纯自动化代码分配的局限，提供更集成的分析方法。AICoE 涵盖了整个流程，包括 open coding、code consolidation、code application 和 pattern discovery，从而实现对质性数据的全面分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NLP4DH 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.00012v1",
      "published_date": "2025-04-21 21:31:28 UTC",
      "updated_date": "2025-04-21 21:31:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:05:29.139241"
    },
    {
      "arxiv_id": "2504.16948v1",
      "title": "Intrinsic Barriers to Explaining Deep Foundation Models",
      "title_zh": "解释深度基础模型的固有障碍",
      "authors": [
        "Zhen Tan",
        "Huan Liu"
      ],
      "abstract": "Deep Foundation Models (DFMs) offer unprecedented capabilities but their\nincreasing complexity presents profound challenges to understanding their\ninternal workings-a critical need for ensuring trust, safety, and\naccountability. As we grapple with explaining these systems, a fundamental\nquestion emerges: Are the difficulties we face merely temporary hurdles,\nawaiting more sophisticated analytical techniques, or do they stem from\n\\emph{intrinsic barriers} deeply rooted in the nature of these large-scale\nmodels themselves? This paper delves into this critical question by examining\nthe fundamental characteristics of DFMs and scrutinizing the limitations\nencountered by current explainability methods when confronted with this\ninherent challenge. We probe the feasibility of achieving satisfactory\nexplanations and consider the implications for how we must approach the\nverification and governance of these powerful technologies.",
      "tldr_zh": "本研究探讨了Deep Foundation Models (DFMs) 的复杂性对解释性的内在障碍，这些模型虽提供强大能力，却因内部机制难以理解而影响信任、安全和责任。论文分析了DFMs的基本特性，并审视当前可解释性方法的局限性，质疑这些挑战是否源于模型本身的根本性质，而非技术不足。最终，该工作评估了实现满意解释的可行性，并为DFMs的验证和治理提出重要启示，以指导未来技术发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16948v1",
      "published_date": "2025-04-21 21:19:23 UTC",
      "updated_date": "2025-04-21 21:19:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:05:39.846190"
    },
    {
      "arxiv_id": "2504.15440v1",
      "title": "Demand for LLMs: Descriptive Evidence on Substitution, Market Expansion, and Multihoming",
      "title_zh": "翻译失败",
      "authors": [
        "Andrey Fradkin"
      ],
      "abstract": "This paper documents three stylized facts about the demand for Large Language\nModels (LLMs) using data from OpenRouter, a prominent LLM marketplace. First,\nnew models experience rapid initial adoption that stabilizes within weeks.\nSecond, model releases differ substantially in whether they primarily attract\nnew users or substitute demand from competing models. Third, multihoming, using\nmultiple models simultaneously, is common among apps. These findings suggest\nsignificant horizontal and vertical differentiation in the LLM market, implying\nopportunities for providers to maintain demand and pricing power despite rapid\ntechnological advances.",
      "tldr_zh": "这篇论文利用 OpenRouter 数据，描述了大型语言模型 (LLMs) 需求的三点事实：新模型的采用速度迅速，并在几周内稳定下来；模型发布可能主要吸引新用户或替代竞争模型的需求；多宿主 (multihoming) 行为，即同时使用多个模型，在应用中非常常见。这些发现揭示了 LLM 市场的显著横向和纵向差异，表明尽管技术进步快速，提供者仍有机会维持需求和定价能力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "econ.GN",
        "q-fin.EC",
        "K.4; I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15440v1",
      "published_date": "2025-04-21 21:12:28 UTC",
      "updated_date": "2025-04-21 21:12:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:05:52.955487"
    },
    {
      "arxiv_id": "2504.15434v1",
      "title": "AGI Is Coming... Right After AI Learns to Play Wordle",
      "title_zh": "AGI 即将到来……只在 AI 学会玩 Wordle 之后",
      "authors": [
        "Sarath Shekkizhar",
        "Romain Cosentino"
      ],
      "abstract": "This paper investigates multimodal agents, in particular, OpenAI's\nComputer-User Agent (CUA), trained to control and complete tasks through a\nstandard computer interface, similar to humans. We evaluated the agent's\nperformance on the New York Times Wordle game to elicit model behaviors and\nidentify shortcomings. Our findings revealed a significant discrepancy in the\nmodel's ability to recognize colors correctly depending on the context. The\nmodel had a $5.36\\%$ success rate over several hundred runs across a week of\nWordle. Despite the immense enthusiasm surrounding AI agents and their\npotential to usher in Artificial General Intelligence (AGI), our findings\nreinforce the fact that even simple tasks present substantial challenges for\ntoday's frontier AI models. We conclude with a discussion of the potential\nunderlying causes, implications for future development, and research directions\nto improve these AI systems.",
      "tldr_zh": "本论文评估了 OpenAI 的 Computer-User Agent (CUA) 等多模态代理在简单任务中的表现，特别通过玩 New York Times Wordle 游戏来测试其行为和局限性。结果显示，该模型在颜色识别上存在显著的上下文依赖问题，导致成功率仅为 5.36% 经过数百次运行。研究强调，即使是这类基本任务，对当前前沿 AI 模型而言仍具挑战，并讨论了潜在原因、未来开发启示以及改进研究方向，以推动 Artificial General Intelligence (AGI) 的发展。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15434v1",
      "published_date": "2025-04-21 20:58:58 UTC",
      "updated_date": "2025-04-21 20:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:06:04.654276"
    },
    {
      "arxiv_id": "2504.15431v1",
      "title": "Trillion 7B Technical Report",
      "title_zh": "翻译失败",
      "authors": [
        "Sungjun Han",
        "Juyoung Suk",
        "Suyeong An",
        "Hyungguk Kim",
        "Kyuseok Kim",
        "Wonsuk Yang",
        "Seungtaek Choi",
        "Jamin Shin"
      ],
      "abstract": "We introduce Trillion-7B, the most token-efficient Korean-centric\nmultilingual LLM available. Our novel Cross-lingual Document Attention (XLDA)\nmechanism enables highly efficient and effective knowledge transfer from\nEnglish to target languages like Korean and Japanese. Combined with optimized\ndata mixtures, language-specific filtering, and tailored tokenizer\nconstruction, Trillion-7B achieves competitive performance while dedicating\nonly 10\\% of its 2T training tokens to multilingual data and requiring just\n59.4K H100 GPU hours (\\$148K) for full training. Comprehensive evaluations\nacross 27 benchmarks in four languages demonstrate Trillion-7B's robust\nmultilingual performance and exceptional cross-lingual consistency.",
      "tldr_zh": "我们介绍了 Trillion-7B，这是一个高效的韩语中心多语言大语言模型 (LLM)，通过创新的 Cross-lingual Document Attention (XLDA) 机制实现从英语到目标语言（如韩语和日语）的知识高效转移。结合优化数据混合、语言特定过滤和定制标记器，该模型仅使用 2T 训练标记的 10% 为多语言数据，并在 59.4K H100 GPU 小时（约 148K 美元）的低成本下达到竞争性性能。在 27 个基准测试中，Trillion-7B 展示了强大的多语言性能和优秀的跨语言一致性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preview version",
      "pdf_url": "http://arxiv.org/pdf/2504.15431v1",
      "published_date": "2025-04-21 20:54:44 UTC",
      "updated_date": "2025-04-21 20:54:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:06:18.466120"
    },
    {
      "arxiv_id": "2504.15425v1",
      "title": "Solving Multi-Agent Safe Optimal Control with Distributed Epigraph Form MARL",
      "title_zh": "翻译失败",
      "authors": [
        "Songyuan Zhang",
        "Oswin So",
        "Mitchell Black",
        "Zachary Serlin",
        "Chuchu Fan"
      ],
      "abstract": "Tasks for multi-robot systems often require the robots to collaborate and\ncomplete a team goal while maintaining safety. This problem is usually\nformalized as a constrained Markov decision process (CMDP), which targets\nminimizing a global cost and bringing the mean of constraint violation below a\nuser-defined threshold. Inspired by real-world robotic applications, we define\nsafety as zero constraint violation. While many safe multi-agent reinforcement\nlearning (MARL) algorithms have been proposed to solve CMDPs, these algorithms\nsuffer from unstable training in this setting. To tackle this, we use the\nepigraph form for constrained optimization to improve training stability and\nprove that the centralized epigraph form problem can be solved in a distributed\nfashion by each agent. This results in a novel centralized training distributed\nexecution MARL algorithm named Def-MARL. Simulation experiments on 8 different\ntasks across 2 different simulators show that Def-MARL achieves the best\noverall performance, satisfies safety constraints, and maintains stable\ntraining. Real-world hardware experiments on Crazyflie quadcopters demonstrate\nthe ability of Def-MARL to safely coordinate agents to complete complex\ncollaborative tasks compared to other methods.",
      "tldr_zh": "本文针对多机器人系统在协作完成团队目标的同时确保零约束违反的安全挑战，将问题形式化为约束Markov决策过程(CMDP)。作者提出Def-MARL算法，利用分布式epigraph form优化来提升训练稳定性，并证明中心化问题可由各代理分布式解决，实现中心化训练与分布式执行。实验结果显示，Def-MARL在8个不同模拟任务和Crazyflie四旋翼无人机真实场景中，表现出最佳性能、完全满足安全约束，并保持训练稳定。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "28 pages, 16 figures; Accepted by Robotics: Science and Systems 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15425v1",
      "published_date": "2025-04-21 20:34:55 UTC",
      "updated_date": "2025-04-21 20:34:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:06:30.155381"
    },
    {
      "arxiv_id": "2504.15424v1",
      "title": "LLM-Assisted Translation of Legacy FORTRAN Codes to C++: A Cross-Platform Study",
      "title_zh": "翻译失败",
      "authors": [
        "Nishath Rajiv Ranasinghe",
        "Shawn M. Jones",
        "Michal Kucer",
        "Ayan Biswas",
        "Daniel O'Malley",
        "Alexander Buschmann Most",
        "Selma Liliane Wanna",
        "Ajay Sreekumar"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly being leveraged for generating\nand translating scientific computer codes by both domain-experts and non-domain\nexperts. Fortran has served as one of the go to programming languages in legacy\nhigh-performance computing (HPC) for scientific discoveries. Despite growing\nadoption, LLM-based code translation of legacy code-bases has not been\nthoroughly assessed or quantified for its usability. Here, we studied the\napplicability of LLM-based translation of Fortran to C++ as a step towards\nbuilding an agentic-workflow using open-weight LLMs on two different\ncomputational platforms. We statistically quantified the compilation accuracy\nof the translated C++ codes, measured the similarity of the LLM translated code\nto the human translated C++ code, and statistically quantified the output\nsimilarity of the Fortran to C++ translation.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)将遗留FORTRAN代码翻译成C++的过程，通过在两个不同计算平台上进行评估，量化了翻译的可用性。研究统计分析了翻译代码的编译准确性、LLM翻译代码与人工翻译代码的相似性，以及FORTRAN到C++翻译的输出相似性。这些发现为构建基于开源LLMs的代理工作流提供了重要依据，有助于提升科学计算代码迁移的效率。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "I.2.2; I.2.7; D.2.3; D.2.4"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15424v1",
      "published_date": "2025-04-21 20:34:37 UTC",
      "updated_date": "2025-04-21 20:34:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:06:43.421986"
    },
    {
      "arxiv_id": "2504.18566v1",
      "title": "Feature Selection via GANs (GANFS): Enhancing Machine Learning Models for DDoS Mitigation",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Patel"
      ],
      "abstract": "Distributed Denial of Service (DDoS) attacks represent a persistent and\nevolving threat to modern networked systems, capable of causing large-scale\nservice disruptions. The complexity of such attacks, often hidden within\nhigh-dimensional and redundant network traffic data, necessitates robust and\nintelligent feature selection techniques for effective detection. Traditional\nmethods such as filter-based, wrapper-based, and embedded approaches, each\noffer strengths but struggle with scalability or adaptability in complex attack\nenvironments. In this study, we explore these existing techniques through a\ndetailed comparative analysis and highlight their limitations when applied to\nlarge-scale DDoS detection tasks. Building upon these insights, we introduce a\nnovel Generative Adversarial Network-based Feature Selection (GANFS) method\nthat leverages adversarial learning dynamics to identify the most informative\nfeatures. By training a GAN exclusively on attack traffic and employing a\nperturbation-based sensitivity analysis on the Discriminator, GANFS effectively\nranks feature importance without relying on full supervision. Experimental\nevaluations using the CIC-DDoS2019 dataset demonstrate that GANFS not only\nimproves the accuracy of downstream classifiers but also enhances computational\nefficiency by significantly reducing feature dimensionality. These results\npoint to the potential of integrating generative learning models into\ncybersecurity pipelines to build more adaptive and scalable detection systems.",
      "tldr_zh": "本文分析了传统特征选择方法（如 filter-based, wrapper-based 和 embedded approaches）在 DDoS 攻击检测中的局限性，包括可扩展性和适应性不足。论文提出了一种新型 Generative Adversarial Network-based Feature Selection (GANFS) 方法，利用对抗学习动态在攻击流量上训练 GAN，并通过 Discriminator 的扰动敏感性分析来排名特征重要性，而无需完全监督。实验结果显示，在 CIC-DDoS2019 数据集上，GANFS 显著提高了下游分类器的准确性，并通过减少特征维度提升了计算效率。这些发现为构建更适应性和可扩展的网络安全检测系统提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18566v1",
      "published_date": "2025-04-21 20:27:33 UTC",
      "updated_date": "2025-04-21 20:27:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:06:55.984430"
    },
    {
      "arxiv_id": "2504.15417v2",
      "title": "On the Boolean Network Theory of Datalog$^\\neg$",
      "title_zh": "翻译失败",
      "authors": [
        "Van-Giang Trinh",
        "Belaid Benhamou",
        "Sylvain Soliman",
        "François Fages"
      ],
      "abstract": "Datalog$^\\neg$ is a central formalism used in a variety of domains ranging\nfrom deductive databases and abstract argumentation frameworks to answer set\nprogramming. Its model theory is the finite counterpart of the logical\nsemantics developed for normal logic programs, mainly based on the notions of\nClark's completion and two-valued or three-valued canonical models including\nsupported, stable, regular and well-founded models. In this paper we establish\na formal link between Datalog$^\\neg$ and Boolean network theory first\nintroduced for gene regulatory networks. We show that in the absence of odd\ncycles in a Datalog$^\\neg$ program, the regular models coincide with the stable\nmodels, which entails the existence of stable models, and in the absence of\neven cycles, we prove the uniqueness of stable partial models and regular\nmodels. This connection also gives new upper bounds on the numbers of stable\npartial, regular, and stable models of a Datalog$^\\neg$ program using the\ncardinality of a feedback vertex set in its atom dependency graph.\nInterestingly, our connection to Boolean network theory also points us to the\nnotion of trap spaces. In particular we show the equivalence between\nsubset-minimal stable trap spaces and regular models.",
      "tldr_zh": "这篇论文建立了 Datalog$^\\neg$ 与 Boolean network theory 的正式联系，展示了这种理论如何应用于分析 Datalog$^\\neg$ 程序的模型。研究发现，在 Datalog$^\\neg$ 程序中无奇 cycles 时，regular models 与 stable models 一致，从而确保 stable models 的存在；无 even cycles 时，stable partial models 和 regular models 是唯一的。同时，论文利用 atom dependency graph 的 feedback vertex set 给出了 stable partial models、regular models 和 stable models 数量的新上界，并证明了 subset-minimal stable trap spaces 等价于 regular models。整体而言，此工作为理解 Datalog$^\\neg$ 的模型理论提供了新视角。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "47 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15417v2",
      "published_date": "2025-04-21 20:02:59 UTC",
      "updated_date": "2025-05-19 22:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:07:08.697239"
    },
    {
      "arxiv_id": "2504.16133v1",
      "title": "A Conceptual Framework for AI-based Decision Systems in Critical Infrastructures",
      "title_zh": "翻译失败",
      "authors": [
        "Milad Leyli-abadi",
        "Ricardo J. Bessa",
        "Jan Viebahn",
        "Daniel Boos",
        "Clark Borst",
        "Alberto Castagna",
        "Ricardo Chavarriaga",
        "Mohamed Hassouna",
        "Bruno Lemetayer",
        "Giulia Leto",
        "Antoine Marot",
        "Maroua Meddeb",
        "Manuel Meyer",
        "Viola Schiaffonati",
        "Manuel Schneider",
        "Toni Waefler"
      ],
      "abstract": "The interaction between humans and AI in safety-critical systems presents a\nunique set of challenges that remain partially addressed by existing\nframeworks. These challenges stem from the complex interplay of requirements\nfor transparency, trust, and explainability, coupled with the necessity for\nrobust and safe decision-making. A framework that holistically integrates human\nand AI capabilities while addressing these concerns is notably required,\nbridging the critical gaps in designing, deploying, and maintaining safe and\neffective systems. This paper proposes a holistic conceptual framework for\ncritical infrastructures by adopting an interdisciplinary approach. It\nintegrates traditionally distinct fields such as mathematics, decision theory,\ncomputer science, philosophy, psychology, and cognitive engineering and draws\non specialized engineering domains, particularly energy, mobility, and\naeronautics. The flexibility in its adoption is also demonstrated through its\ninstantiation on an already existing framework.",
      "tldr_zh": "这篇论文针对人类与 AI 在安全关键系统中的互动挑战，提出一个整体概念框架，以解决透明度、信任和解释性等需求，同时确保稳健决策。该框架采用跨学科方法，整合数学、决策理论、计算机科学、哲学、心理学和认知工程等领域，并扩展到能源、交通和航空等专业工程领域。通过在现有框架上的实例化，展示了其灵活性和实际可采用性，为关键基础设施的 AI 决策系统设计提供全面指导。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16133v1",
      "published_date": "2025-04-21 18:38:26 UTC",
      "updated_date": "2025-04-21 18:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:07:17.985495"
    },
    {
      "arxiv_id": "2504.15376v1",
      "title": "Towards Understanding Camera Motions in Any Video",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiu Lin",
        "Siyuan Cen",
        "Daniel Jiang",
        "Jay Karhade",
        "Hewei Wang",
        "Chancharik Mitra",
        "Tiffany Ling",
        "Yuhan Huang",
        "Sifan Liu",
        "Mingyu Chen",
        "Rushikesh Zawar",
        "Xue Bai",
        "Yilun Du",
        "Chuang Gan",
        "Deva Ramanan"
      ],
      "abstract": "We introduce CameraBench, a large-scale dataset and benchmark designed to\nassess and improve camera motion understanding. CameraBench consists of ~3,000\ndiverse internet videos, annotated by experts through a rigorous multi-stage\nquality control process. One of our contributions is a taxonomy of camera\nmotion primitives, designed in collaboration with cinematographers. We find,\nfor example, that some motions like \"follow\" (or tracking) require\nunderstanding scene content like moving subjects. We conduct a large-scale\nhuman study to quantify human annotation performance, revealing that domain\nexpertise and tutorial-based training can significantly enhance accuracy. For\nexample, a novice may confuse zoom-in (a change of intrinsics) with translating\nforward (a change of extrinsics), but can be trained to differentiate the two.\nUsing CameraBench, we evaluate Structure-from-Motion (SfM) and Video-Language\nModels (VLMs), finding that SfM models struggle to capture semantic primitives\nthat depend on scene content, while VLMs struggle to capture geometric\nprimitives that require precise estimation of trajectories. We then fine-tune a\ngenerative VLM on CameraBench to achieve the best of both worlds and showcase\nits applications, including motion-augmented captioning, video question\nanswering, and video-text retrieval. We hope our taxonomy, benchmark, and\ntutorials will drive future efforts towards the ultimate goal of understanding\ncamera motions in any video.",
      "tldr_zh": "本研究引入了CameraBench，这是一个包含约3000个多样化互联网视频的大规模数据集和基准，用于评估和提升相机运动理解。该数据集基于与摄影师合作设计的相机运动原语分类法，并通过大规模人类研究发现，领域专业知识和教程训练能显著提高标注准确率，例如区分zoom-in（内在变化）和forward translation（外在变化）。实验评估显示，Structure-from-Motion (SfM) 模型在捕捉依赖场景内容的语义原语时表现欠佳，而Video-Language Models (VLMs) 在精确估计轨迹的几何原语上存在困难。通过在CameraBench上微调生成VLM，该模型整合了二者的优势，并应用于motion-augmented captioning、video question answering和video-text retrieval等领域。该工作有望驱动未来对任何视频中相机运动的理解研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project site: https://linzhiqiu.github.io/papers/camerabench/",
      "pdf_url": "http://arxiv.org/pdf/2504.15376v1",
      "published_date": "2025-04-21 18:34:57 UTC",
      "updated_date": "2025-04-21 18:34:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:07:34.473196"
    },
    {
      "arxiv_id": "2505.04629v1",
      "title": "From Dialect Gaps to Identity Maps: Tackling Variability in Speaker Verification",
      "title_zh": "翻译失败",
      "authors": [
        "Abdulhady Abas Abdullah",
        "Soran Badawi",
        "Dana A. Abdullah",
        "Dana Rasul Hamad",
        "Hanan Abdulrahman Taher",
        "Sabat Salih Muhamad",
        "Aram Mahmood Ahmed",
        "Bryar A. Hassan",
        "Sirwan Abdolwahed Aula",
        "Tarik A. Rashid"
      ],
      "abstract": "The complexity and difficulties of Kurdish speaker detection among its\nseveral dialects are investigated in this work. Because of its great phonetic\nand lexical differences, Kurdish with several dialects including Kurmanji,\nSorani, and Hawrami offers special challenges for speaker recognition systems.\nThe main difficulties in building a strong speaker identification system\ncapable of precisely identifying speakers across several dialects are\ninvestigated in this work. To raise the accuracy and dependability of these\nsystems, it also suggests solutions like sophisticated machine learning\napproaches, data augmentation tactics, and the building of thorough\ndialect-specific corpus. The results show that customized strategies for every\ndialect together with cross-dialect training greatly enhance recognition\nperformance.",
      "tldr_zh": "本研究探讨了库尔德语（Kurdish）多种方言（如Kurmanji、Sorani和Hawrami）在说话者验证（Speaker Verification）中的复杂性与挑战，这些方言的语音和词汇差异导致识别系统准确性低下。论文分析了构建跨方言精确识别系统的难点，并提出解决方案，包括先进的机器学习方法、数据增强策略以及构建详细的方言特定语料库。结果显示，通过针对每个方言的定制策略和跨方言训练，系统识别性能显著提升，准确性和可靠性得到大幅提高。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.04629v1",
      "published_date": "2025-04-21 18:25:20 UTC",
      "updated_date": "2025-04-21 18:25:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:07:42.408879"
    },
    {
      "arxiv_id": "2504.15369v1",
      "title": "Solving New Tasks by Adapting Internet Video Knowledge",
      "title_zh": "通过适应互联网视频知识解决新任务",
      "authors": [
        "Calvin Luo",
        "Zilai Zeng",
        "Yilun Du",
        "Chen Sun"
      ],
      "abstract": "Video generative models demonstrate great promise in robotics by serving as\nvisual planners or as policy supervisors. When pretrained on internet-scale\ndata, such video models intimately understand alignment with natural language,\nand can thus facilitate generalization to novel downstream behavior through\ntext-conditioning. However, they may not be sensitive to the specificities of\nthe particular environment the agent inhabits. On the other hand, training\nvideo models on in-domain examples of robotic behavior naturally encodes\nenvironment-specific intricacies, but the scale of available demonstrations may\nnot be sufficient to support generalization to unseen tasks via natural\nlanguage specification. In this work, we investigate different adaptation\ntechniques that integrate in-domain information with large-scale pretrained\nvideo models, and explore the extent to which they enable novel\ntext-conditioned generalization for robotic tasks, while also considering their\nindependent data and resource considerations. We successfully demonstrate\nacross robotic environments that adapting powerful video models with small\nscales of example data can successfully facilitate generalization to novel\nbehaviors. In particular, we present a novel adaptation strategy, termed\nInverse Probabilistic Adaptation, that not only consistently achieves strong\ngeneralization performance across robotic tasks and settings, but also exhibits\nrobustness to the quality of adaptation data, successfully solving novel tasks\neven when only suboptimal in-domain demonstrations are available.",
      "tldr_zh": "这篇论文探讨了如何通过适应互联网视频知识来解决机器人新任务，旨在将大规模预训练视频模型与域内数据整合，以实现文本条件下的行为泛化。研究者评估了多种适应技术，特别是提出了一种新策略Inverse Probabilistic Adaptation，能够在机器人环境中使用少量示例数据实现对新任务的鲁棒泛化。实验结果表明，即使适应数据质量不高（如次优演示），该方法也能有效提升模型性能，并在多种机器人设置中成功演示新行为的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025. Project Webpage:\n  https://diffusion-supervision.github.io/adapt2act/",
      "pdf_url": "http://arxiv.org/pdf/2504.15369v1",
      "published_date": "2025-04-21 18:20:13 UTC",
      "updated_date": "2025-04-21 18:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:07:55.140109"
    },
    {
      "arxiv_id": "2504.15364v3",
      "title": "KeyDiff: Key Similarity-Based KV Cache Eviction for Long-Context LLM Inference in Resource-Constrained Environments",
      "title_zh": "KeyDiff：基于关键相似性的 KV 缓存驱逐，用于资源受限环境中的长上下文大语言模型推理",
      "authors": [
        "Junyoung Park",
        "Dalton Jones",
        "Matthew J Morse",
        "Raghavv Goel",
        "Mingu Lee",
        "Chris Lott"
      ],
      "abstract": "We demonstrate that geometrically distinctive keys during LLM inference tend\nto have high attention scores. Based on the phenomenon we propose KeyDiff, a\ntraining-free KV cache eviction method based solely on key similarity. Unlike\nother KV cache eviction methods, KeyDiff can process arbitrarily long prompts\nwithin strict resource constraints and efficiently generate responses. We\nprovide a theoretical basis for KeyDiff by relating key diversity with\nattention scores. These results imply KeyDiff can efficiently identify the most\nimportant tokens to retain. Notably KeyDiff does not rely on attention scores,\nallowing the use of optimized attention mechanisms like FlashAttention. Under a\nstrict memory allowance, we demonstrate the effectiveness of KeyDiff for the\nLlama and Qwen model families by observing a performance gap of less than 0.04%\nwith 8K cache budget ($\\sim$23% KV cache reduction) from the non-evicting\nbaseline on LongBench for Llama 3.1-8B and Llama 3.2-3B. We also observe near\nbaseline performance for Deepseek-R1-Distill-Llama-8B on the Math500 reasoning\nbenchmark and decrease end-to-end inference latency by up to 30% compared to\nthe other token-eviction methods.",
      "tldr_zh": "该论文提出 KeyDiff，一种基于 key 相似性的 KV cache 驱逐方法，用于资源受限环境下的长上下文 LLM 推理，该方法不需训练并利用 keys 的几何独特性与注意力分数的关联来高效识别和保留重要 tokens。不同于其他方法，KeyDiff 不依赖注意力分数，因此可与优化机制如 FlashAttention 兼容，支持任意长提示的处理。实验结果显示，在 LongBench 基准上，KeyDiff 为 Llama 3.1-8B 和 Llama 3.2-3B 模型减少约 23% KV cache 时，性能仅比非驱逐基线下降 0.04%；此外，它在 Math500 上使 Deepseek-R1-Distill-Llama-8B 模型保持近基线性能，并将端到端推理延迟降低高达 30%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15364v3",
      "published_date": "2025-04-21 18:12:46 UTC",
      "updated_date": "2025-05-20 17:50:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:08:07.191058"
    },
    {
      "arxiv_id": "2504.15360v1",
      "title": "Reliable Classification with Conformal Learning and Interval-Type 2 Fuzzy Sets",
      "title_zh": "基于保形学习和区间类型2模糊集的可靠分类",
      "authors": [
        "Javier Fumanal-Idocin",
        "Javier Andreu-Perez"
      ],
      "abstract": "Classical machine learning classifiers tend to be overconfident can be\nunreliable outside of the laboratory benchmarks. Properly assessing the\nreliability of the output of the model per sample is instrumental for real-life\nscenarios where these systems are deployed. Because of this, different\ntechniques have been employed to properly quantify the quality of prediction\nfor a given model. These are most commonly Bayesian statistics and, more\nrecently, conformal learning. Given a calibration set, conformal learning can\nproduce outputs that are guaranteed to cover the target class with a desired\nsignificance level, and are more reliable than the standard confidence\nintervals used by Bayesian methods. In this work, we propose to use conformal\nlearning with fuzzy rule-based systems in classification and show some metrics\nof their performance. Then, we discuss how the use of type 2 fuzzy sets can\nimprove the quality of the output of the system compared to both fuzzy and\ncrisp rules. Finally, we also discuss how the fine-tuning of the system can be\nadapted to improve the quality of the conformal prediction.",
      "tldr_zh": "本文提出了一种结合共形学习(Conformal Learning)和区间类型2模糊集(Interval-Type 2 Fuzzy Sets)的可靠分类方法，以解决传统机器学习分类器过自信和实际部署中可靠性不足的问题。研究通过在分类任务中使用模糊规则系统和共形学习，基于校准集生成更可靠的预测输出，并展示了其性能指标。结果表明，类型2模糊集相较于传统模糊或精确规则，能显著提升预测质量，且通过系统微调进一步优化了共形预测的可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15360v1",
      "published_date": "2025-04-21 18:07:55 UTC",
      "updated_date": "2025-04-21 18:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:08:17.976172"
    },
    {
      "arxiv_id": "2504.15275v1",
      "title": "Stop Summation: Min-Form Credit Assignment Is All Process Reward Model Needs for Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Cheng",
        "Ruixi Qiao",
        "Lijun Li",
        "Chao Guo",
        "Junle Wang",
        "Gang Xiong",
        "Yisheng Lv",
        "Fei-Yue Wang"
      ],
      "abstract": "Process reward models (PRMs) have proven effective for test-time scaling of\nLarge Language Models (LLMs) on challenging reasoning tasks. However, reward\nhacking issues with PRMs limit their successful application in reinforcement\nfine-tuning. In this paper, we identify the main cause of PRM-induced reward\nhacking: the canonical summation-form credit assignment in reinforcement\nlearning (RL), which defines the value as cumulative gamma-decayed future\nrewards, easily induces LLMs to hack steps with high rewards. To address this,\nwe propose PURE: Process sUpervised Reinforcement lEarning. The key innovation\nof PURE is a min-form credit assignment that formulates the value function as\nthe minimum of future rewards. This method significantly alleviates reward\nhacking by limiting the value function range and distributing advantages more\nreasonably. Through extensive experiments on 3 base models, we show that\nPRM-based approaches enabling min-form credit assignment achieve comparable\nreasoning performance to verifiable reward-based methods within only 30% steps.\nIn contrast, the canonical sum-form credit assignment collapses training even\nat the beginning! Additionally, when we supplement PRM-based fine-tuning with\njust 10% verifiable rewards, we further alleviate reward hacking and produce\nthe best fine-tuned model based on Qwen2.5-Math-7B in our experiments,\nachieving 82.5% accuracy on AMC23 and 53.3% average accuracy across 5\nbenchmarks. Moreover, we summarize the observed reward hacking cases and\nanalyze the causes of training collapse. Code and models are available at\nhttps://github.com/CJReinforce/PURE.",
      "tldr_zh": "本研究发现，过程奖励模型（PRMs）在强化学习（RL）中因传统的 summation-form credit assignment 而容易引发奖励黑客问题，从而影响Large Language Models (LLMs)在推理任务上的训练效果。为解决此问题，作者提出PURE（Process sUpervised Reinforcement lEarning）方法，该方法采用min-form credit assignment来定义价值函数，通过限制价值函数范围并合理分配优势值，显著缓解奖励黑客行为。实验结果显示，PURE在3个基模型上仅需30%步骤即可与可验证奖励方法媲美；在结合10%可验证奖励后，基于Qwen2.5-Math-7B的模型在AMC23基准上达到82.5%准确率，并在5个基准上平均准确率达53.3%。这项创新为PRMs在推理任务中的应用提供了更可靠的框架。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15275v1",
      "published_date": "2025-04-21 17:59:02 UTC",
      "updated_date": "2025-04-21 17:59:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:08:29.699991"
    },
    {
      "arxiv_id": "2504.15266v1",
      "title": "Roll the dice & look before you leap: Going beyond the creative limits of next-token prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Vaishnavh Nagarajan",
        "Chen Henry Wu",
        "Charles Ding",
        "Aditi Raghunathan"
      ],
      "abstract": "We design a suite of minimal algorithmic tasks that are a loose abstraction\nof open-ended real-world tasks. This allows us to cleanly and controllably\nquantify the creative limits of the present-day language model. Much like\nreal-world tasks that require a creative, far-sighted leap of thought, our\ntasks require an implicit, open-ended stochastic planning step that either (a)\ndiscovers new connections in an abstract knowledge graph (like in wordplay,\ndrawing analogies, or research) or (b) constructs new patterns (like in\ndesigning math problems or new proteins). In these tasks, we empirically and\nconceptually argue how next-token learning is myopic and memorizes excessively;\ncomparatively, multi-token approaches, namely teacherless training and\ndiffusion models, excel in producing diverse and original output. Secondly, in\nour tasks, we find that to elicit randomness from the Transformer without\nhurting coherence, it is better to inject noise right at the input layer (via a\nmethod we dub hash-conditioning) rather than defer to temperature sampling from\nthe output layer. Thus, our work offers a principled, minimal test-bed for\nanalyzing open-ended creative skills, and offers new arguments for going beyond\nnext-token learning and softmax-based sampling. We make part of the code\navailable under https://github.com/chenwu98/algorithmic-creativity",
      "tldr_zh": "本研究设计了一系列最小化算法任务，作为开放式真实世界任务的抽象，用于量化当前语言模型的创造力极限。这些任务需要隐式的随机规划，如在抽象知识图中发现新连接（例如文字游戏、类比或研究）或构建新模式（例如设计数学问题或新蛋白），并发现 next-token prediction 学习方式过于短视和过度记忆，而多 token 方法（如无教师训练和 diffusion models）在产生多样原创输出方面表现更优。为提升 Transformer 的随机性而不损害连贯性，论文提出在输入层注入噪声的 hash-conditioning 方法，并提供代码资源，主张超越 next-token 学习和 softmax-based 采样以提升创造性技能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "37 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15266v1",
      "published_date": "2025-04-21 17:47:46 UTC",
      "updated_date": "2025-04-21 17:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:08:42.808138"
    },
    {
      "arxiv_id": "2504.16132v1",
      "title": "Efficacy of a Computer Tutor that Models Expert Human Tutors",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew M. Olney",
        "Sidney K. D'Mello",
        "Natalie Person",
        "Whitney Cade",
        "Patrick Hays",
        "Claire W. Dempsey",
        "Blair Lehman",
        "Betsy Williams",
        "Art Graesser"
      ],
      "abstract": "Tutoring is highly effective for promoting learning. However, the\ncontribution of expertise to tutoring effectiveness is unclear and continues to\nbe debated. We conducted a 9-week learning efficacy study of an intelligent\ntutoring system (ITS) for biology modeled on expert human tutors with two\ncontrol conditions: human tutors who were experts in the domain but not in\ntutoring and a no-tutoring condition. All conditions were supplemental to\nclassroom instruction, and students took learning tests immediately before and\nafter tutoring sessions as well as delayed tests 1-2 weeks later. Analysis\nusing logistic mixed-effects modeling indicates significant positive effects on\nthe immediate post-test for the ITS (d =.71) and human tutors (d =.66) which\nare in the 99th percentile of meta-analytic effects, as well as significant\npositive effects on the delayed post-test for the ITS (d =.36) and human tutors\n(d =.39). We discuss implications for the role of expertise in tutoring and the\ndesign of future studies.",
      "tldr_zh": "本研究评估了模仿专家人类辅导者的智能辅导系统(ITS)在生物学学习中的有效性，通过一个9周实验与两组对照条件（专家领域的非辅导专家人类辅导者和无辅导组）进行比较，所有条件均补充课堂教学。实验采用立即后测和1-2周延迟后测，并使用logistic mixed-effects modeling分析，结果显示ITS在立即后测上的效果量(d=0.71)和人类辅导者(d=0.66)均显著正面，在元分析中处于99th percentile；延迟后测上，ITS(d=0.36)和人类辅导者(d=0.39)也显示显著效果。该研究证实了专家辅导的贡献，并为未来ITS设计和相关研究提供了重要启示。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.4; I.2.7; K.3.1"
      ],
      "primary_category": "cs.CY",
      "comment": "Shortened version of this paper has been accepted to AIED 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16132v1",
      "published_date": "2025-04-21 17:41:28 UTC",
      "updated_date": "2025-04-21 17:41:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:08:55.882647"
    },
    {
      "arxiv_id": "2504.15261v1",
      "title": "Leveraging Language Models for Automated Patient Record Linkage",
      "title_zh": "利用语言模型实现患者记录的自动链接",
      "authors": [
        "Mohammad Beheshti",
        "Lovedeep Gondara",
        "Iris Zachary"
      ],
      "abstract": "Objective: Healthcare data fragmentation presents a major challenge for\nlinking patient data, necessitating robust record linkage to integrate patient\nrecords from diverse sources. This study investigates the feasibility of\nleveraging language models for automated patient record linkage, focusing on\ntwo key tasks: blocking and matching. Materials and Methods: We utilized\nreal-world healthcare data from the Missouri Cancer Registry and Research\nCenter, linking patient records from two independent sources using\nprobabilistic linkage as a baseline. A transformer-based model, RoBERTa, was\nfine-tuned for blocking using sentence embeddings. For matching, several\nlanguage models were experimented under fine-tuned and zero-shot settings,\nassessing their performance against ground truth labels. Results: The\nfine-tuned blocking model achieved a 92% reduction in the number of candidate\npairs while maintaining near-perfect recall. In the matching task, fine-tuned\nMistral-7B achieved the best performance with only 6 incorrect predictions.\nAmong zero-shot models, Mistral-Small-24B performed best, with a total of 55\nincorrect predictions. Discussion: Fine-tuned language models achieved strong\nperformance in patient record blocking and matching with minimal errors.\nHowever, they remain less accurate and efficient than a hybrid rule-based and\nprobabilistic approach for blocking. Additionally, reasoning models like\nDeepSeek-R1 are impractical for large-scale record linkage due to high\ncomputational costs. Conclusion: This study highlights the potential of\nlanguage models for automating patient record linkage, offering improved\nefficiency by eliminating the manual efforts required to perform patient record\nlinkage. Overall, language models offer a scalable solution that can enhance\ndata integration, reduce manual effort, and support disease surveillance and\nresearch.",
      "tldr_zh": "这篇论文探讨了利用语言模型自动链接患者记录，以解决医疗数据碎片化问题，重点关注 blocking 和 matching 两个任务。研究使用真实数据（如 Missouri Cancer Registry），以 RoBERTa 模型微调进行 blocking，实现了92%的候选对减少率，同时保持近乎完美的召回率；在 matching 任务中，fine-tuned Mistral-7B 表现最佳，仅有6个错误预测，而 zero-shot 中的 Mistral-Small-24B 有55个错误。结果表明，语言模型在效率上优于传统方法，但不如混合规则和概率方法准确，且计算成本高的问题（如 DeepSeek-R1）限制了大规模应用。总体上，该研究证明了语言模型能减少手动努力，提供可扩展的解决方案，支持医疗数据整合和疾病监测。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15261v1",
      "published_date": "2025-04-21 17:41:15 UTC",
      "updated_date": "2025-04-21 17:41:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:09:08.464226"
    },
    {
      "arxiv_id": "2504.15259v1",
      "title": "Bringing Diversity from Diffusion Models to Semantic-Guided Face Asset Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yunxuan Cai",
        "Sitao Xiang",
        "Zongjian Li",
        "Haiwei Chen",
        "Yajie Zhao"
      ],
      "abstract": "Digital modeling and reconstruction of human faces serve various\napplications. However, its availability is often hindered by the requirements\nof data capturing devices, manual labor, and suitable actors. This situation\nrestricts the diversity, expressiveness, and control over the resulting models.\nThis work aims to demonstrate that a semantically controllable generative\nnetwork can provide enhanced control over the digital face modeling process. To\nenhance diversity beyond the limited human faces scanned in a controlled\nsetting, we introduce a novel data generation pipeline that creates a\nhigh-quality 3D face database using a pre-trained diffusion model. Our proposed\nnormalization module converts synthesized data from the diffusion model into\nhigh-quality scanned data. Using the 44,000 face models we obtained, we further\ndeveloped an efficient GAN-based generator. This generator accepts semantic\nattributes as input, and generates geometry and albedo. It also allows\ncontinuous post-editing of attributes in the latent space. Our asset refinement\ncomponent subsequently creates physically-based facial assets. We introduce a\ncomprehensive system designed for creating and editing high-quality face\nassets. Our proposed model has undergone extensive experiment, comparison and\nevaluation. We also integrate everything into a web-based interactive tool. We\naim to make this tool publicly available with the release of the paper.",
      "tldr_zh": "这篇论文针对数字人脸建模的多样性、表现力和控制不足问题，提出了一种语义可控的生成网络，利用预训练的diffusion model创建一个高质量的3D人脸数据库。研究引入了一个novel data generation pipeline和normalization module，将合成数据转换为高质量扫描数据，从而生成44,000个面部模型。基于这些模型，他们开发了一个高效的GAN-based generator，能接受semantic attributes作为输入，生成几何和albedo，并支持在latent space中进行连续属性编辑。最终，该系统包括asset refinement component和一个web-based interactive tool，通过实验证明了其在增强面部资产多样性和控制方面的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15259v1",
      "published_date": "2025-04-21 17:38:50 UTC",
      "updated_date": "2025-04-21 17:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:09:20.182377"
    },
    {
      "arxiv_id": "2504.15257v1",
      "title": "FlowReasoner: Reinforcing Query-Level Meta-Agents",
      "title_zh": "FlowReasoner：强化查询级元代理",
      "authors": [
        "Hongcheng Gao",
        "Yue Liu",
        "Yufei He",
        "Longxu Dou",
        "Chao Du",
        "Zhijie Deng",
        "Bryan Hooi",
        "Min Lin",
        "Tianyu Pang"
      ],
      "abstract": "This paper proposes a query-level meta-agent named FlowReasoner to automate\nthe design of query-level multi-agent systems, i.e., one system per user query.\nOur core idea is to incentivize a reasoning-based meta-agent via external\nexecution feedback. Concretely, by distilling DeepSeek R1, we first endow the\nbasic reasoning ability regarding the generation of multi-agent systems to\nFlowReasoner. Then, we further enhance it via reinforcement learning (RL) with\nexternal execution feedback. A multi-purpose reward is designed to guide the RL\ntraining from aspects of performance, complexity, and efficiency. In this\nmanner, FlowReasoner is enabled to generate a personalized multi-agent system\nfor each user query via deliberative reasoning. Experiments on both engineering\nand competition code benchmarks demonstrate the superiority of FlowReasoner.\nRemarkably, it surpasses o1-mini by 10.52% accuracy across three benchmarks.\nThe code is available at https://github.com/sail-sg/FlowReasoner.",
      "tldr_zh": "这篇论文提出了一种名为 FlowReasoner 的查询级元代理(query-level meta-agent)，旨在自动化设计每个用户查询的个性化多代理系统。核心方法包括先通过蒸馏 DeepSeek R1 赋予其基本推理能力，然后利用强化学习 (RL) 和外部执行反馈进行增强，并设计多用途奖励(multi-purpose reward)从性能、复杂性和效率方面指导训练。实验结果显示，FlowReasoner 在工程和竞争代码基准上表现出色，比 o1-mini 高 10.52% 的准确率，证明了其在自动化代理系统设计中的优越性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15257v1",
      "published_date": "2025-04-21 17:35:42 UTC",
      "updated_date": "2025-04-21 17:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:09:30.362921"
    },
    {
      "arxiv_id": "2504.15252v1",
      "title": "SuoiAI: Building a Dataset for Aquatic Invertebrates in Vietnam",
      "title_zh": "SuoiAI：构建越南水生无脊椎动物数据集",
      "authors": [
        "Tue Vo",
        "Lakshay Sharma",
        "Tuan Dinh",
        "Khuong Dinh",
        "Trang Nguyen",
        "Trung Phan",
        "Minh Do",
        "Duong Vu"
      ],
      "abstract": "Understanding and monitoring aquatic biodiversity is critical for ecological\nhealth and conservation efforts. This paper proposes SuoiAI, an end-to-end\npipeline for building a dataset of aquatic invertebrates in Vietnam and\nemploying machine learning (ML) techniques for species classification. We\noutline the methods for data collection, annotation, and model training,\nfocusing on reducing annotation effort through semi-supervised learning and\nleveraging state-of-the-art object detection and classification models. Our\napproach aims to overcome challenges such as data scarcity, fine-grained\nclassification, and deployment in diverse environmental conditions.",
      "tldr_zh": "这篇论文介绍了 SuoiAI，这是一个端到端的管道，用于构建越南水生无脊椎动物数据集，并应用 machine learning (ML) 技术进行物种分类。方法包括数据收集、标注和模型训练，通过 semi-supervised learning 减少标注努力，并利用 state-of-the-art object detection and classification models 来提升效率。该框架旨在克服数据 scarcity、fine-grained classification 和 diverse environmental conditions 等挑战，从而支持水生生物多样性的监测和保护。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a workshop paper at \"Tackling Climate Change with\n  Machine Learning\", ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15252v1",
      "published_date": "2025-04-21 17:33:02 UTC",
      "updated_date": "2025-04-21 17:33:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:09:42.641972"
    },
    {
      "arxiv_id": "2504.15236v1",
      "title": "Values in the Wild: Discovering and Analyzing Values in Real-World Language Model Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Saffron Huang",
        "Esin Durmus",
        "Miles McCain",
        "Kunal Handa",
        "Alex Tamkin",
        "Jerry Hong",
        "Michael Stern",
        "Arushi Somani",
        "Xiuruo Zhang",
        "Deep Ganguli"
      ],
      "abstract": "AI assistants can impart value judgments that shape people's decisions and\nworldviews, yet little is known empirically about what values these systems\nrely on in practice. To address this, we develop a bottom-up,\nprivacy-preserving method to extract the values (normative considerations\nstated or demonstrated in model responses) that Claude 3 and 3.5 models exhibit\nin hundreds of thousands of real-world interactions. We empirically discover\nand taxonomize 3,307 AI values and study how they vary by context. We find that\nClaude expresses many practical and epistemic values, and typically supports\nprosocial human values while resisting values like \"moral nihilism\". While some\nvalues appear consistently across contexts (e.g. \"transparency\"), many are more\nspecialized and context-dependent, reflecting the diversity of human\ninterlocutors and their varied contexts. For example, \"harm prevention\" emerges\nwhen Claude resists users, \"historical accuracy\" when responding to queries\nabout controversial events, \"healthy boundaries\" when asked for relationship\nadvice, and \"human agency\" in technology ethics discussions. By providing the\nfirst large-scale empirical mapping of AI values in deployment, our work\ncreates a foundation for more grounded evaluation and design of values in AI\nsystems.",
      "tldr_zh": "该研究开发了一种底层、隐私保护的方法，从数十万个真实互动中提取并分析 Claude 3 和 3.5 模型的 values（规范性考虑）。研究发现并分类了 3,307 个 AI values，这些 values 包括实用和认识论类型，模型通常支持 prosocial human values（如透明性），同时抵抗 moral nihilism，并在不同上下文中表现出变化，例如强调 harm prevention（伤害预防）或 historical accuracy（历史准确性）。通过提供首个大规模实证映射 AI values，该工作为 AI 系统的评估和设计奠定了更可靠的基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "44 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15236v1",
      "published_date": "2025-04-21 17:13:16 UTC",
      "updated_date": "2025-04-21 17:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:09:55.093544"
    },
    {
      "arxiv_id": "2504.15228v2",
      "title": "A Self-Improving Coding Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Maxime Robeyns",
        "Martin Szummer",
        "Laurence Aitchison"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have spurred interest in\ndeploying LLM agents to undertake tasks in the world. LLMs are often deployed\nin agent systems: code that orchestrates LLM calls and provides them with\ntools. We demonstrate that an agent system, equipped with basic coding tools,\ncan autonomously edit itself, and thereby improve its performance on benchmark\ntasks. We find performance gains from 17% to 53% on a random subset of SWE\nBench Verified, with additional performance gains on LiveCodeBench, as well as\nsynthetically generated agent benchmarks. Our work represents an advancement in\nthe automated and open-ended design of agentic systems, and demonstrates a\ndata-efficient, non gradient-based learning mechanism driven by LLM reflection\nand code updates.",
      "tldr_zh": "这篇论文提出了一种自我改进的编码代理，利用 Large Language Models (LLMs) 和基本编码工具，使代理系统能够自主编辑自身代码，从而提升在基准任务上的性能。实验结果显示，该代理在 SWE Bench Verified 的随机子集上性能提升了17%至53%，并在 LiveCodeBench 以及合成生成的代理基准上取得了额外改进。该方法展示了数据高效、非梯度学习机制，通过 LLM 反思和代码更新，推进了代理系统的自动化和开放式设计。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted as a preprint to NeurIPS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15228v2",
      "published_date": "2025-04-21 16:58:18 UTC",
      "updated_date": "2025-05-16 20:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:10:06.932501"
    },
    {
      "arxiv_id": "2504.15226v1",
      "title": "A Genetic Fuzzy-Enabled Framework on Robotic Manipulation for In-Space Servicing",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan Steffen",
        "Wilhelm Louw",
        "Nicholas Ernest",
        "Timothy Arnett",
        "Kelly Cohen"
      ],
      "abstract": "Automation of robotic systems for servicing in cislunar space is becoming\nextremely important as the number of satellites in orbit increases. Safety is\ncritical in performing satellite maintenance, so the control techniques\nutilized must be trusted in addition to being highly efficient. In this work,\nGenetic Fuzzy Trees are combined with the widely used LQR control scheme via\nThales' TrUE AI Toolkit to create a trusted and efficient controller for a\ntwo-degree-of-freedom planar robotic manipulator that would theoretically be\nused to perform satellite maintenance. It was found that Genetic Fuzzy-LQR is\n18.5% more performant than optimal LQR on average, and that it is incredibly\nrobust to uncertainty.",
      "tldr_zh": "该研究提出了一种基于 Genetic Fuzzy Trees 的框架，用于在月球-地球空间（cislunar space）进行卫星维护的机器人操作。该框架将 Genetic Fuzzy Trees 与 LQR（Linear Quadratic Regulator）控制方案相结合，并通过 Thales' TrUE AI Toolkit 构建一个可信赖且高效的控制器，应用于一个两自由度平面机器人机械臂。实验结果显示，Genetic Fuzzy-LQR 控制方案比标准 LQR 平均性能提升 18.5%，并对不确定性表现出极强的鲁棒性，为卫星维护自动化提供了更安全可靠的解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15226v1",
      "published_date": "2025-04-21 16:57:56 UTC",
      "updated_date": "2025-04-21 16:57:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:10:18.134197"
    },
    {
      "arxiv_id": "2504.15225v1",
      "title": "M$^2$AD: Multi-Sensor Multi-System Anomaly Detection through Global Scoring and Calibrated Thresholding",
      "title_zh": "翻译失败",
      "authors": [
        "Sarah Alnegheimish",
        "Zelin He",
        "Matthew Reimherr",
        "Akash Chandrayan",
        "Abhinav Pradhan",
        "Luca D'Angelo"
      ],
      "abstract": "With the widespread availability of sensor data across industrial and\noperational systems, we frequently encounter heterogeneous time series from\nmultiple systems. Anomaly detection is crucial for such systems to facilitate\npredictive maintenance. However, most existing anomaly detection methods are\ndesigned for either univariate or single-system multivariate data, making them\ninsufficient for these complex scenarios. To address this, we introduce\nM$^2$AD, a framework for unsupervised anomaly detection in multivariate time\nseries data from multiple systems. M$^2$AD employs deep models to capture\nexpected behavior under normal conditions, using the residuals as indicators of\npotential anomalies. These residuals are then aggregated into a global anomaly\nscore through a Gaussian Mixture Model and Gamma calibration. We theoretically\ndemonstrate that this framework can effectively address heterogeneity and\ndependencies across sensors and systems. Empirically, M$^2$AD outperforms\nexisting methods in extensive evaluations by 21% on average, and its\neffectiveness is demonstrated on a large-scale real-world case study on 130\nassets in Amazon Fulfillment Centers. Our code and results are available at\nhttps://github.com/sarahmish/M2AD.",
      "tldr_zh": "该研究提出M$^2$AD框架，用于处理多传感器多系统异构时间序列数据的无监督异常检测，旨在解决现有方法在复杂工业场景中的不足。框架采用深度模型捕获正常行为，通过残差作为异常指标，并利用Gaussian Mixture Model和Gamma calibration聚合成全局异常分数，以有效管理传感器和系统间的异质性和依赖性。实验结果显示，M$^2$AD平均比现有方法提高21%的性能，并在Amazon Fulfillment Centers的130个资产上进行大规模真实案例验证，证明其实际应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15225v1",
      "published_date": "2025-04-21 16:57:46 UTC",
      "updated_date": "2025-04-21 16:57:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:10:30.316754"
    },
    {
      "arxiv_id": "2505.00010v1",
      "title": "Jailbreak Detection in Clinical Training LLMs Using Feature-Based Predictive Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tri Nguyen",
        "Lohith Srikanth Pentapalli",
        "Magnus Sieverding",
        "Laurah Turner",
        "Seth Overla",
        "Weibing Zheng",
        "Chris Zhou",
        "David Furniss",
        "Danielle Weber",
        "Michael Gharib",
        "Matt Kelleher",
        "Michael Shukis",
        "Cameron Pawlik",
        "Kelly Cohen"
      ],
      "abstract": "Jailbreaking in Large Language Models (LLMs) threatens their safe use in\nsensitive domains like education by allowing users to bypass ethical\nsafeguards. This study focuses on detecting jailbreaks in 2-Sigma, a clinical\neducation platform that simulates patient interactions using LLMs. We annotated\nover 2,300 prompts across 158 conversations using four linguistic variables\nshown to correlate strongly with jailbreak behavior. The extracted features\nwere used to train several predictive models, including Decision Trees, Fuzzy\nLogic-based classifiers, Boosting methods, and Logistic Regression. Results\nshow that feature-based predictive models consistently outperformed Prompt\nEngineering, with the Fuzzy Decision Tree achieving the best overall\nperformance. Our findings demonstrate that linguistic-feature-based models are\neffective and explainable alternatives for jailbreak detection. We suggest\nfuture work explore hybrid frameworks that integrate prompt-based flexibility\nwith rule-based robustness for real-time, spectrum-based jailbreak monitoring\nin educational LLMs.",
      "tldr_zh": "本研究针对 Large Language Models (LLMs) 中的 Jailbreak 问题，特别是在临床教育平台 2-Sigma 上，旨在检测用户绕过道德保障的行为。通过标注超过 2,300 个提示并提取四个与 Jailbreak 高度相关的语言变量，研究者训练了 Decision Trees、Fuzzy Logic-based classifiers、Boosting methods 和 Logistic Regression 等预测模型。结果表明，这些特征-based 模型的表现优于 Prompt Engineering，其中 Fuzzy Decision Tree 取得了最佳性能。该方法为 Jailbreak 检测提供了有效且可解释的替代方案，并建议未来探索整合提示工程和规则-based 框架的混合系统，以实现教育 LLMs 的实时监控。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00010v1",
      "published_date": "2025-04-21 16:54:35 UTC",
      "updated_date": "2025-04-21 16:54:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:10:43.352067"
    },
    {
      "arxiv_id": "2504.15330v1",
      "title": "Med-CoDE: Medical Critique based Disagreement Evaluation Framework",
      "title_zh": "Med-CoDE：基于医疗批评的分歧评估框架",
      "authors": [
        "Mohit Gupta",
        "Akiko Aizawa",
        "Rajiv Ratn Shah"
      ],
      "abstract": "The emergence of large language models (LLMs) has significantly influenced\nnumerous fields, including healthcare, by enhancing the capabilities of\nautomated systems to process and generate human-like text. However, despite\ntheir advancements, the reliability and accuracy of LLMs in medical contexts\nremain critical concerns. Current evaluation methods often lack robustness and\nfail to provide a comprehensive assessment of LLM performance, leading to\npotential risks in clinical settings. In this work, we propose Med-CoDE, a\nspecifically designed evaluation framework for medical LLMs to address these\nchallenges. The framework leverages a critique-based approach to quantitatively\nmeasure the degree of disagreement between model-generated responses and\nestablished medical ground truths. This framework captures both accuracy and\nreliability in medical settings. The proposed evaluation framework aims to fill\nthe existing gap in LLM assessment by offering a systematic method to evaluate\nthe quality and trustworthiness of medical LLMs. Through extensive experiments\nand case studies, we illustrate the practicality of our framework in providing\na comprehensive and reliable evaluation of medical LLMs.",
      "tldr_zh": "本文提出 Med-CoDE 框架，一种基于医疗批评（critique-based approach）的评估方法，用于量化大型语言模型（LLMs）生成响应与医疗事实之间的分歧，从而评估模型的准确性和可靠性。该框架旨在解决现有评估方法的不足，提供一个系统化的工具来提升医疗 LLMs 的质量和可信度。通过广泛的实验和案例研究，研究者证明了 Med-CoDE 在临床场景中的实用性，并填补了 LLM 评估领域的空白。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 4 figures, NAACL SRW 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15330v1",
      "published_date": "2025-04-21 16:51:11 UTC",
      "updated_date": "2025-04-21 16:51:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:10:54.002055"
    },
    {
      "arxiv_id": "2504.17805v1",
      "title": "Fuzzy Logic -- Based Scheduling System for Part-Time Workforce",
      "title_zh": "翻译失败",
      "authors": [
        "Tri Nguyen",
        "Kelly Cohen"
      ],
      "abstract": "This paper explores the application of genetic fuzzy systems to efficiently\ngenerate schedules for a team of part-time student workers at a university.\nGiven the preferred number of working hours and availability of employees, our\nmodel generates feasible solutions considering various factors, such as maximum\nweekly hours, required number of workers on duty, and the preferred number of\nworking hours. The algorithm is trained and tested with availability data\ncollected from students at the University of Cincinnati. The results\ndemonstrate the algorithm's efficiency in producing schedules that meet\noperational criteria and its robustness in understaffed conditions.",
      "tldr_zh": "本论文提出了一种基于 genetic fuzzy systems 的调度系统，用于高效生成大学兼职学生员工的日程表。该系统考虑员工的偏好工作小时和可用性，同时整合因素如每周最大小时数、所需在职员工数和偏好约束。利用辛辛那提大学学生的实际数据进行训练和测试，结果显示该算法能产生符合操作标准的可行日程表，并在员工不足情况下表现出色稳健性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17805v1",
      "published_date": "2025-04-21 16:44:17 UTC",
      "updated_date": "2025-04-21 16:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:11:05.263097"
    },
    {
      "arxiv_id": "2504.15211v1",
      "title": "Position: Bayesian Statistics Facilitates Stakeholder Participation in Evaluation of Generative AI",
      "title_zh": "立场：贝叶斯统计促进利益相关者在生成式 AI ",
      "authors": [
        "Yanan Long"
      ],
      "abstract": "The evaluation of Generative AI (GenAI) systems plays a critical role in\npublic policy and decision-making, yet existing methods are often limited by\nreliance on benchmark-driven, point-estimate comparisons that fail to capture\nuncertainty and broader societal impacts. This paper argues for the use of\nBayesian statistics as a principled framework to address these challenges.\nBayesian methods enable the integration of domain expertise through prior\nelicitation, allow for continuous learning from new data, and provide robust\nuncertainty quantification via posterior inference. We demonstrate how Bayesian\ninference can be applied to GenAI evaluation, particularly in incorporating\nstakeholder perspectives to enhance fairness, transparency, and reliability.\nFurthermore, we discuss Bayesian workflows as an iterative process for model\nvalidation and refinement, ensuring robust assessments of GenAI systems in\ndynamic, real-world contexts.",
      "tldr_zh": "这篇论文主张使用 Bayesian 统计作为一种原则性框架来提升生成式 AI (Generative AI) 系统的评估，从而解决现有基准驱动的点估计方法忽略不确定性和社会影响的问题。Bayesian 方法通过先验 elicitation 整合领域专业知识、支持从新数据中持续学习，并提供后验 inference 的稳健不确定性量化。论文展示了如何将 Bayesian 推理应用于 GenAI 评估中整合利益相关者观点，以提高公平性、透明度和可靠性，并通过 Bayesian 工作流实现迭代模型验证和精炼，确保在动态真实世界环境中进行稳健评估。",
      "categories": [
        "cs.AI",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "To be presented at ACM CHI 2025 workshop STAIG",
      "pdf_url": "http://arxiv.org/pdf/2504.15211v1",
      "published_date": "2025-04-21 16:31:15 UTC",
      "updated_date": "2025-04-21 16:31:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:11:19.352454"
    },
    {
      "arxiv_id": "2504.15210v2",
      "title": "Integrating Symbolic Execution into the Fine-Tuning of Code-Generating LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Marina Sakharova",
        "Abhinav Anand",
        "Mira Mezini"
      ],
      "abstract": "Code-generating Large Language Models (LLMs) have become essential tools in\nmodern software development, enhancing productivity and accelerating\ndevelopment. This paper aims to investigate the fine-tuning of code-generating\nLLMs using Reinforcement Learning and Direct Preference Optimization, further\nimproving their performance. To achieve this, we enhance the training data for\nthe reward model with the help of symbolic execution techniques, ensuring more\ncomprehensive and objective data. With symbolic execution, we create a custom\ndataset that better captures the nuances in code evaluation. Our reward models,\nfine-tuned on this dataset, demonstrate significant improvements over the\nbaseline, CodeRL, in estimating the quality of generated code. Our\ncode-generating LLMs, trained with the help of reward model feedback, achieve\nsimilar results compared to the CodeRL benchmark.",
      "tldr_zh": "这篇论文探讨了将符号执行(Symbolic Execution)整合到代码生成大语言模型(code-generating LLMs)的微调过程中，使用强化学习(Reinforcement Learning)和直接偏好优化(Direct Preference Optimization)来提升模型性能。研究者通过符号执行技术增强训练数据，创建了一个更全面的自定义数据集，以更好地捕捉代码评估的细微差别。结果表明，基于此数据集的奖励模型在估计生成代码质量方面比基线CodeRL有显著改进，而微调后的LLMs性能与CodeRL基准相当。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15210v2",
      "published_date": "2025-04-21 16:29:07 UTC",
      "updated_date": "2025-05-05 06:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:11:31.181807"
    },
    {
      "arxiv_id": "2504.15209v1",
      "title": "A Causal Convolutional Low-rank Representation Model for Imputation of Water Quality Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xin Liao",
        "Bing Yang",
        "Tan Dongli",
        "Cai Yu"
      ],
      "abstract": "The monitoring of water quality is a crucial part of environmental\nprotection, and a large number of monitors are widely deployed to monitor water\nquality. Due to unavoidable factors such as data acquisition breakdowns,\nsensors and communication failures, water quality monitoring data suffers from\nmissing values over time, resulting in High-Dimensional and Sparse (HDS) Water\nQuality Data (WQD). The simple and rough filling of the missing values leads to\ninaccurate results and affects the implementation of relevant measures.\nTherefore, this paper proposes a Causal convolutional Low-rank Representation\n(CLR) model for imputing missing WQD to improve the completeness of the WQD,\nwhich employs a two-fold idea: a) applying causal convolutional operation to\nconsider the temporal dependence of the low-rank representation, thus\nincorporating temporal information to improve the imputation accuracy; and b)\nimplementing a hyperparameters adaptation scheme to automatically adjust the\nbest hyperparameters during model training, thereby reducing the tedious manual\nadjustment of hyper-parameters. Experimental studies on three real-world water\nquality datasets demonstrate that the proposed CLR model is superior to some of\nthe existing state-of-the-art imputation models in terms of imputation accuracy\nand time cost, as well as indicating that the proposed model provides more\nreliable decision support for environmental monitoring.",
      "tldr_zh": "这篇论文针对水质监测数据中的缺失值问题，提出了一种Causal convolutional Low-rank Representation (CLR) 模型，以提升数据完整性。该模型采用两方面方法：一是通过因果卷积操作考虑低秩表示的时序依赖性，整合时间信息来提高填充准确性；二是实现超参数自适应方案，自动调整最佳参数以减少手动优化。实验在三个真实水质数据集上显示，CLR模型在填充准确性和时间成本上优于现有最先进模型，为环境监测提供更可靠的决策支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07 (Primary) 62M10, 65C60 (Secondary)",
        "I.2.7"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15209v1",
      "published_date": "2025-04-21 16:27:16 UTC",
      "updated_date": "2025-04-21 16:27:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:11:51.126834"
    },
    {
      "arxiv_id": "2504.15208v1",
      "title": "Compute-Optimal LLMs Provably Generalize Better With Scale",
      "title_zh": "计算最优的LLMs可证明地随着规模增长而泛",
      "authors": [
        "Marc Finzi",
        "Sanyam Kapoor",
        "Diego Granziol",
        "Anming Gu",
        "Christopher De Sa",
        "J. Zico Kolter",
        "Andrew Gordon Wilson"
      ],
      "abstract": "Why do larger language models generalize better? To investigate this\nquestion, we develop generalization bounds on the pretraining objective of\nlarge language models (LLMs) in the compute-optimal regime, as described by the\nChinchilla scaling laws. We introduce a novel, fully empirical Freedman-type\nmartingale concentration inequality that tightens existing bounds by accounting\nfor the variance of the loss function. This generalization bound can be\ndecomposed into three interpretable components: the number of parameters per\ntoken, the loss variance, and the quantization error at a fixed bitrate. As\ncompute-optimal language models are scaled up, the number of parameters per\ndata point remains constant; however, both the loss variance and the\nquantization error decrease, implying that larger models should have smaller\ngeneralization gaps. We examine why larger models tend to be more quantizable\nfrom an information theoretic perspective, showing that the rate at which they\ncan integrate new information grows more slowly than their capacity on the\ncompute-optimal frontier. From these findings we produce a scaling law for the\ngeneralization gap, with bounds that become predictably stronger with scale.",
      "tldr_zh": "这篇论文探讨了为什么在计算最优条件下，规模更大的大型语言模型（LLMs）能够实现更好的泛化性能。研究者开发了基于Chinchilla缩放定律的泛化边界，使用一个新的Freedman-type martingale浓度不等式来考虑损失函数的方差，并将边界分解为参数数量、损失方差和量化误差三个组成部分。随着模型规模扩大，损失方差和量化误差减少，从而缩小泛化差距。从信息理论角度分析，较大模型的容量增长快于整合新信息的能力，最终推导出泛化差距的缩放定律，使边界随规模变得更强。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.15208v1",
      "published_date": "2025-04-21 16:26:56 UTC",
      "updated_date": "2025-04-21 16:26:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:11:55.642357"
    },
    {
      "arxiv_id": "2504.15205v1",
      "title": "Support Evaluation for the TREC 2024 RAG Track: Comparing Human versus LLM Judges",
      "title_zh": "翻译失败",
      "authors": [
        "Nandan Thakur",
        "Ronak Pradeep",
        "Shivani Upadhyay",
        "Daniel Campos",
        "Nick Craswell",
        "Jimmy Lin"
      ],
      "abstract": "Retrieval-augmented generation (RAG) enables large language models (LLMs) to\ngenerate answers with citations from source documents containing \"ground\ntruth\", thereby reducing system hallucinations. A crucial factor in RAG\nevaluation is \"support\", whether the information in the cited documents\nsupports the answer. To this end, we conducted a large-scale comparative study\nof 45 participant submissions on 36 topics to the TREC 2024 RAG Track,\ncomparing an automatic LLM judge (GPT-4o) against human judges for support\nassessment. We considered two conditions: (1) fully manual assessments from\nscratch and (2) manual assessments with post-editing of LLM predictions. Our\nresults indicate that for 56% of the manual from-scratch assessments, human and\nGPT-4o predictions match perfectly (on a three-level scale), increasing to 72%\nin the manual with post-editing condition. Furthermore, by carefully analyzing\nthe disagreements in an unbiased study, we found that an independent human\njudge correlates better with GPT-4o than a human judge, suggesting that LLM\njudges can be a reliable alternative for support assessment. To conclude, we\nprovide a qualitative analysis of human and GPT-4o errors to help guide future\niterations of support assessment.",
      "tldr_zh": "这篇论文评估了TREC 2024 RAG Track中Retrieval-augmented generation (RAG)系统的“支持”度，即引用的文档是否支持生成答案，并比较了人类评判者和LLM评判器（GPT-4o）的表现。研究通过大规模比较45个参赛提交和36个主题，采用了两种条件：完全手动评估从零开始，以及对LLM预测进行后期编辑的混合评估。结果显示，56%的完全手动评估中人类和GPT-4o预测完全匹配（基于三水平尺度），编辑后匹配率上升至72%；进一步分析发现，独立人类评判者与GPT-4o的相关性更高，表明LLM评判器可作为可靠的替代方案。论文还提供了人类和GPT-4o错误的定性分析，以指导未来的RAG支持评估改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at SIGIR 2025 (short)",
      "pdf_url": "http://arxiv.org/pdf/2504.15205v1",
      "published_date": "2025-04-21 16:20:43 UTC",
      "updated_date": "2025-04-21 16:20:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:12:08.260844"
    },
    {
      "arxiv_id": "2504.15199v1",
      "title": "Zero-Shot, But at What Cost? Unveiling the Hidden Overhead of MILS's LLM-CLIP Framework for Image Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Yassir Benhammou",
        "Alessandro Tiberio",
        "Gabriel Trautmann",
        "Suman Kalyan"
      ],
      "abstract": "MILS (Multimodal Iterative LLM Solver) is a recently published framework that\nclaims \"LLMs can see and hear without any training\" by leveraging an iterative,\nLLM-CLIP based approach for zero-shot image captioning. While this MILS\napproach demonstrates good performance, our investigation reveals that this\nsuccess comes at a hidden, substantial computational cost due to its expensive\nmulti-step refinement process. In contrast, alternative models such as BLIP-2\nand GPT-4V achieve competitive results through a streamlined, single-pass\napproach. We hypothesize that the significant overhead inherent in MILS's\niterative process may undermine its practical benefits, thereby challenging the\nnarrative that zero-shot performance can be attained without incurring heavy\nresource demands. This work is the first to expose and quantify the trade-offs\nbetween output quality and computational cost in MILS, providing critical\ninsights for the design of more efficient multimodal models.",
      "tldr_zh": "这篇论文揭示了 MILS (Multimodal Iterative LLM Solver) 框架在零样本图像描述中的隐藏计算开销，尽管其基于 LLM-CLIP 的迭代方法实现了良好的性能，但多步精炼过程导致了实质性资源消耗。相比之下，BLIP-2 和 GPT-4V 等模型通过单步方法即可达到竞争性结果，从而质疑了 MILS 的实用性。作者首次量化了输出质量与计算成本之间的权衡，为设计更高效的多模态模型提供了关键见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 2 tables, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.15199v1",
      "published_date": "2025-04-21 16:16:19 UTC",
      "updated_date": "2025-04-21 16:16:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:12:18.424934"
    },
    {
      "arxiv_id": "2504.15192v1",
      "title": "Breast density in MRI: an AI-based quantification and relationship to assessment in mammography",
      "title_zh": "MRI 中的乳腺密度：基于 AI 的量化及其与乳腺 X 光摄影评估的关系",
      "authors": [
        "Yaqian Chen",
        "Lin Li",
        "Hanxue Gu",
        "Haoyu Dong",
        "Derek L. Nguyen",
        "Allan D. Kirk",
        "Maciej A. Mazurowski",
        "E. Shelley Hwang"
      ],
      "abstract": "Mammographic breast density is a well-established risk factor for breast\ncancer. Recently there has been interest in breast MRI as an adjunct to\nmammography, as this modality provides an orthogonal and highly quantitative\nassessment of breast tissue. However, its 3D nature poses analytic challenges\nrelated to delineating and aggregating complex structures across slices. Here,\nwe applied an in-house machine-learning algorithm to assess breast density on\nnormal breasts in three MRI datasets. Breast density was consistent across\ndifferent datasets (0.104 - 0.114). Analysis across different age groups also\ndemonstrated strong consistency across datasets and confirmed a trend of\ndecreasing density with age as reported in previous studies. MR breast density\nwas correlated with mammographic breast density, although some notable\ndifferences suggest that certain breast density components are captured only on\nMRI. Future work will determine how to integrate MR breast density with current\ntools to improve future breast cancer risk prediction.",
      "tldr_zh": "本研究使用AI机器学习算法量化MRI中的乳腺密度，并将其与X光摄影评估进行比较，以探讨乳腺癌风险因素。结果显示，MRI乳腺密度在三个数据集间保持一致（0.104-0.114），且随年龄增加而减少，这一趋势与既有研究相符。MRI评估捕获了X光摄影未能完全反映的密度成分，为未来整合MRI数据以提升乳腺癌风险预测提供了潜在基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15192v1",
      "published_date": "2025-04-21 16:01:51 UTC",
      "updated_date": "2025-04-21 16:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:12:30.291309"
    },
    {
      "arxiv_id": "2504.15188v2",
      "title": "Synergistic Weak-Strong Collaboration by Aligning Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Yizhu Jiao",
        "Xuchao Zhang",
        "Zhaoyang Wang",
        "Yubo Ma",
        "Zhun Deng",
        "Rujia Wang",
        "Chetan Bansal",
        "Saravan Rajmohan",
        "Jiawei Han",
        "Huaxiu Yao"
      ],
      "abstract": "Current Large Language Models (LLMs) excel in general reasoning yet struggle\nwith specialized tasks requiring proprietary or domain-specific knowledge.\nFine-tuning large models for every niche application is often infeasible due to\nblack-box constraints and high computational overhead. To address this, we\npropose a collaborative framework that pairs a specialized weak model with a\ngeneral strong model. The weak model, tailored to specific domains, produces\ninitial drafts and background information, while the strong model leverages its\nadvanced reasoning to refine these drafts, extending LLMs' capabilities to\ncritical yet specialized tasks. To optimize this collaboration, we introduce a\ncollaborative feedback to fine-tunes the weak model, which quantifies the\ninfluence of the weak model's contributions in the collaboration procedure and\nestablishes preference pairs to guide preference tuning of the weak model. We\nvalidate our framework through experiments on three domains. We find that the\ncollaboration significantly outperforms each model alone by leveraging\ncomplementary strengths. Moreover, aligning the weak model with the\ncollaborative preference further enhances overall performance.",
      "tldr_zh": "本研究提出了一种弱-强模型协作框架，以解决LLMs在专业任务上因专有知识限制而面临的挑战。框架中，专门化的弱模型负责生成初始草稿和背景信息，而通用的强模型则利用其高级推理能力来完善这些输出，从而扩展LLMs的应用范围。为优化协作，引入协作反馈机制来微调弱模型，通过量化弱模型贡献并建立偏好对进行偏好调整。在三个领域的实验中，该框架显著优于单独使用任一模型，并通过对齐弱模型偏好进一步提升整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15188v2",
      "published_date": "2025-04-21 15:57:33 UTC",
      "updated_date": "2025-04-22 04:22:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:12:43.634510"
    },
    {
      "arxiv_id": "2504.15181v1",
      "title": "Existing Industry Practice for the EU AI Act's General-Purpose AI Code of Practice Safety and Security Measures",
      "title_zh": "翻译失败",
      "authors": [
        "Lily Stelling",
        "Mick Yang",
        "Rokas Gipiškis",
        "Leon Staufer",
        "Ze Shen Chin",
        "Siméon Campos",
        "Michael Chen"
      ],
      "abstract": "This report provides a detailed comparison between the measures proposed in\nthe EU AI Act's General-Purpose AI (GPAI) Code of Practice (Third Draft) and\ncurrent practices adopted by leading AI companies. As the EU moves toward\nenforcing binding obligations for GPAI model providers, the Code of Practice\nwill be key to bridging legal requirements with concrete technical commitments.\nOur analysis focuses on the draft's Safety and Security section which is only\nrelevant for the providers of the most advanced models (Commitments II.1-II.16)\nand excerpts from current public-facing documents quotes that are relevant to\neach individual measure.\n  We systematically reviewed different document types - including companies'\nfrontier safety frameworks and model cards - from over a dozen companies,\nincluding OpenAI, Anthropic, Google DeepMind, Microsoft, Meta, Amazon, and\nothers. This report is not meant to be an indication of legal compliance nor\ndoes it take any prescriptive viewpoint about the Code of Practice or\ncompanies' policies. Instead, it aims to inform the ongoing dialogue between\nregulators and GPAI model providers by surfacing evidence of precedent.",
      "tldr_zh": "这篇报告比较了欧盟 AI 法案的通用 AI (GPAI) 实践守则第三稿中针对最先进模型的安全和安全措施（Commitments II.1-II.16）与领先 AI 公司如 OpenAI、Anthropic 和 Google DeepMind 的当前实践。研究方法包括系统审查这些公司的公共文档，如安全框架和模型卡，以提取相关内容作为证据。报告不涉及法律合规性评估，而是旨在桥接监管要求和技术承诺，促进欧盟监管者和 GPAI 模型提供者之间的对话。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "158 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15181v1",
      "published_date": "2025-04-21 15:44:01 UTC",
      "updated_date": "2025-04-21 15:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:12:54.597489"
    },
    {
      "arxiv_id": "2504.15165v1",
      "title": "An Efficient Aerial Image Detection with Variable Receptive Fields",
      "title_zh": "翻译失败",
      "authors": [
        "Liu Wenbin"
      ],
      "abstract": "Aerial object detection using unmanned aerial vehicles (UAVs) faces critical\nchallenges including sub-10px targets, dense occlusions, and stringent\ncomputational constraints. Existing detectors struggle to balance accuracy and\nefficiency due to rigid receptive fields and redundant architectures. To\naddress these limitations, we propose Variable Receptive Field DETR (VRF-DETR),\na transformer-based detector incorporating three key components: 1) Multi-Scale\nContext Fusion (MSCF) module that dynamically recalibrates features through\nadaptive spatial attention and gated multi-scale fusion, 2) Gated Convolution\n(GConv) layer enabling parameter-efficient local-context modeling via depthwise\nseparable operations and dynamic gating, and 3) Gated Multi-scale Fusion (GMCF)\nBottleneck that hierarchically disentangles occluded objects through cascaded\nglobal-local interactions. Experiments on VisDrone2019 demonstrate VRF-DETR\nachieves 51.4\\% mAP\\textsubscript{50} and 31.8\\% mAP\\textsubscript{50:95} with\nonly 13.5M parameters. This work establishes a new efficiency-accuracy Pareto\nfrontier for UAV-based detection tasks.",
      "tldr_zh": "这篇论文针对无人机(UAVs)空中物体检测面临的挑战，如小目标(sub-10px)、密集遮挡和计算约束，提出了Variable Receptive Field DETR (VRF-DETR)——一个基于Transformer的检测器。VRF-DETR包括三个关键组件：Multi-Scale Context Fusion (MSCF)模块用于动态特征重新校准、Gated Convolution (GConv)层实现参数高效的局部上下文建模，以及Gated Multi-scale Fusion (GMCF) Bottleneck通过级联全局-局部交互分层分离遮挡物体。在VisDrone2019数据集上，VRF-DETR仅用13.5M参数就达到了51.4% mAP50和31.8% mAP50:95的性能，建立了UAV-based检测任务的新效率-准确性Pareto前沿。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15165v1",
      "published_date": "2025-04-21 15:16:13 UTC",
      "updated_date": "2025-04-21 15:16:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:13:09.116361"
    },
    {
      "arxiv_id": "2504.16131v1",
      "title": "Introduction to Quantum Machine Learning and Quantum Architecture Search",
      "title_zh": "量子机器学习和量子架构搜索导论",
      "authors": [
        "Samuel Yen-Chi Chen",
        "Zhiding Liang"
      ],
      "abstract": "Recent advancements in quantum computing (QC) and machine learning (ML) have\nfueled significant research efforts aimed at integrating these two\ntransformative technologies. Quantum machine learning (QML), an emerging\ninterdisciplinary field, leverages quantum principles to enhance the\nperformance of ML algorithms. Concurrently, the exploration of systematic and\nautomated approaches for designing high-performance quantum circuit\narchitectures for QML tasks has gained prominence, as these methods empower\nresearchers outside the quantum computing domain to effectively utilize\nquantum-enhanced tools. This tutorial will provide an in-depth overview of\nrecent breakthroughs in both areas, highlighting their potential to expand the\napplication landscape of QML across diverse fields.",
      "tldr_zh": "这篇论文介绍了量子机器学习（QML）和量子架构搜索（Quantum Architecture Search）的最新进展，强调了量子计算（QC）和机器学习（ML）的整合如何利用量子原理提升ML算法的性能。论文探讨了系统化和自动化的方法来设计高效量子电路架构，使非量子计算领域的研究者能够更有效地应用这些工具。该教程概述了这些突破的潜力，扩展了QML在多样领域的应用前景，例如科学计算和数据分析。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "ISCAS 2025 Tutorial",
      "pdf_url": "http://arxiv.org/pdf/2504.16131v1",
      "published_date": "2025-04-21 15:13:33 UTC",
      "updated_date": "2025-04-21 15:13:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:13:18.485068"
    },
    {
      "arxiv_id": "2504.15152v1",
      "title": "Landmark-Free Preoperative-to-Intraoperative Registration in Laparoscopic Liver Resection",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Zhou",
        "Bingchen Gao",
        "Kai Wang",
        "Jialun Pei",
        "Pheng-Ann Heng",
        "Jing Qin"
      ],
      "abstract": "Liver registration by overlaying preoperative 3D models onto intraoperative\n2D frames can assist surgeons in perceiving the spatial anatomy of the liver\nclearly for a higher surgical success rate. Existing registration methods rely\nheavily on anatomical landmark-based workflows, which encounter two major\nlimitations: 1) ambiguous landmark definitions fail to provide efficient\nmarkers for registration; 2) insufficient integration of intraoperative liver\nvisual information in shape deformation modeling. To address these challenges,\nin this paper, we propose a landmark-free preoperative-to-intraoperative\nregistration framework utilizing effective self-supervised learning, termed\n\\ourmodel. This framework transforms the conventional 3D-2D workflow into a\n3D-3D registration pipeline, which is then decoupled into rigid and non-rigid\nregistration subtasks. \\ourmodel~first introduces a feature-disentangled\ntransformer to learn robust correspondences for recovering rigid\ntransformations. Further, a structure-regularized deformation network is\ndesigned to adjust the preoperative model to align with the intraoperative\nliver surface. This network captures structural correlations through geometry\nsimilarity modeling in a low-rank transformer network. To facilitate the\nvalidation of the registration performance, we also construct an in-vivo\nregistration dataset containing liver resection videos of 21 patients, called\n\\emph{P2I-LReg}, which contains 346 keyframes that provide a global view of the\nliver together with liver mask annotations and calibrated camera intrinsic\nparameters. Extensive experiments and user studies on both synthetic and\nin-vivo datasets demonstrate the superiority and potential clinical\napplicability of our method.",
      "tldr_zh": "本研究针对肝脏手术中现有的基于解剖标志点（landmark-based）的注册方法存在标记模糊和手术视觉信息整合不足的问题，提出了一种无标志点（landmark-free）的预手术到手术注册框架，名为 \\ourmodel。框架将传统的 3D-2D 工作流转化为 3D-3D 注册管道，包括刚性和非刚性子任务：使用 feature-disentangled transformer 学习稳健的对应关系以恢复刚性变换，并设计 structure-regularized deformation network 通过几何相似性建模在低秩 transformer 网络中捕获结构相关性，以精确调整预手术模型。研究者构建了 in-vivo 注册数据集 P2I-LReg，包含 21 名患者的肝切除视频、346 个关键帧及相关注释。实验和用户研究在合成和 in-vivo 数据集上证明了该方法的优越性，提升了手术成功率并展示了临床潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "TMI under review",
      "pdf_url": "http://arxiv.org/pdf/2504.15152v1",
      "published_date": "2025-04-21 14:55:57 UTC",
      "updated_date": "2025-04-21 14:55:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:13:32.121933"
    },
    {
      "arxiv_id": "2504.15146v1",
      "title": "Behavioral Universe Network (BUN): A Behavioral Information-Based Framework for Complex Systems",
      "title_zh": "行为宇宙网络 (BUN)：一个基于行为信息的复杂系统框架",
      "authors": [
        "Wei Zhou",
        "Ailiya Borjigin",
        "Cong He"
      ],
      "abstract": "Modern digital ecosystems feature complex, dynamic interactions among\nautonomous entities across diverse domains. Traditional models often separate\nagents and objects, lacking a unified foundation to capture their interactive\nbehaviors. This paper introduces the Behavioral Universe Network (BUN), a\ntheoretical framework grounded in the Agent-Interaction-Behavior (AIB)\nformalism. BUN treats subjects (active agents), objects (resources), and\nbehaviors (operations) as first-class entities, all governed by a shared\nBehavioral Information Base (BIB). We detail the AIB core concepts and\ndemonstrate how BUN leverages information-driven triggers, semantic enrichment,\nand adaptive rules to coordinate multi-agent systems. We highlight key\nbenefits: enhanced behavior analysis, strong adaptability, and cross-domain\ninteroperability. We conclude by positioning BUN as a promising foundation for\nnext-generation digital governance and intelligent applications.",
      "tldr_zh": "这篇论文引入了 Behavioral Universe Network (BUN)，一个基于 Agent-Interaction-Behavior (AIB) 形式化的理论框架，用于处理现代数字生态系统中复杂实体间的动态互动。BUN 将主体（主动代理）、对象（资源）和行为（操作）视为第一类实体，由共享的 Behavioral Information Base (BIB) 统一管理，并通过信息驱动触发、语义增强和自适应规则来协调多代理系统。该框架的关键优势包括增强行为分析、强适应性和跨域互操作性，最终为下一代数字治理和智能应用奠定坚实基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.15146v1",
      "published_date": "2025-04-21 14:50:28 UTC",
      "updated_date": "2025-04-21 14:50:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:13:44.237025"
    },
    {
      "arxiv_id": "2504.15144v1",
      "title": "C2RUST-BENCH: A Minimized, Representative Dataset for C-to-Rust Transpilation Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Melih Sirlanci",
        "Carter Yagemann",
        "Zhiqiang Lin"
      ],
      "abstract": "Despite the effort in vulnerability detection over the last two decades,\nmemory safety vulnerabilities continue to be a critical problem. Recent reports\nsuggest that the key solution is to migrate to memory-safe languages. To this\nend, C-to-Rust transpilation becomes popular to resolve memory-safety issues in\nC programs. Recent works propose C-to-Rust transpilation frameworks; however, a\ncomprehensive evaluation dataset is missing. Although one solution is to put\ntogether a large enough dataset, this increases the analysis time in automated\nframeworks as well as in manual efforts for some cases. In this work, we build\na method to select functions from a large set to construct a minimized yet\nrepresentative dataset to evaluate the C-to-Rust transpilation. We propose\nC2RUST-BENCH that contains 2,905 functions, which are representative of\nC-to-Rust transpilation, selected from 15,503 functions of real-world programs.",
      "tldr_zh": "本研究针对内存安全漏洞的持续问题，提出通过C-to-Rust transpilation来迁移C程序，但指出现有框架缺少全面的评估数据集。为解决这一问题，论文开发了一种方法，从15,503个真实世界程序函数中选择代表性函数，构建了一个最小化且具有代表性的数据集C2RUST-BENCH。最终，该数据集包含2,905个函数，能有效评估C-to-Rust transpilation框架，同时减少分析时间和手动努力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15144v1",
      "published_date": "2025-04-21 14:48:45 UTC",
      "updated_date": "2025-04-21 14:48:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:13:54.497244"
    },
    {
      "arxiv_id": "2504.15135v1",
      "title": "KGMEL: Knowledge Graph-Enhanced Multimodal Entity Linking",
      "title_zh": "KGMEL：知识图谱增强的多模态实体链接",
      "authors": [
        "Juyeon Kim",
        "Geon Lee",
        "Taeuk Kim",
        "Kijung Shin"
      ],
      "abstract": "Entity linking (EL) aligns textual mentions with their corresponding entities\nin a knowledge base, facilitating various applications such as semantic search\nand question answering. Recent advances in multimodal entity linking (MEL) have\nshown that combining text and images can reduce ambiguity and improve alignment\naccuracy. However, most existing MEL methods overlook the rich structural\ninformation available in the form of knowledge-graph (KG) triples. In this\npaper, we propose KGMEL, a novel framework that leverages KG triples to enhance\nMEL. Specifically, it operates in three stages: (1) Generation: Produces\nhigh-quality triples for each mention by employing vision-language models based\non its text and images. (2) Retrieval: Learns joint mention-entity\nrepresentations, via contrastive learning, that integrate text, images, and\n(generated or KG) triples to retrieve candidate entities for each mention. (3)\nReranking: Refines the KG triples of the candidate entities and employs large\nlanguage models to identify the best-matching entity for the mention. Extensive\nexperiments on benchmark datasets demonstrate that KGMEL outperforms existing\nmethods. Our code and datasets are available at:\nhttps://github.com/juyeonnn/KGMEL.",
      "tldr_zh": "本文提出 KGMEL 框架，通过整合知识图谱 (KG) 三元组来增强多模态实体链接 (MEL)，旨在解决现有方法忽略 KG 结构信息的问题，从而提高文本和图像实体对齐的准确性。KGMEL 采用三阶段方法：Generation 阶段使用视觉语言模型基于提及的文本和图像生成高质量的三元组；Retrieval 阶段通过对比学习整合文本、图像和三元组，学习联合表示以检索候选实体；Reranking 阶段细化候选实体的 KG 三元组，并利用大型语言模型选择最佳匹配实体。实验在基准数据集上表明，KGMEL 优于现有方法，并提供了开源代码以供复现。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "SIGIR 2025 (Short)",
      "pdf_url": "http://arxiv.org/pdf/2504.15135v1",
      "published_date": "2025-04-21 14:38:44 UTC",
      "updated_date": "2025-04-21 14:38:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:14:07.849058"
    },
    {
      "arxiv_id": "2504.15133v1",
      "title": "EasyEdit2: An Easy-to-use Steering Framework for Editing Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwen Xu",
        "Shuxun Wang",
        "Kewei Xu",
        "Haoming Xu",
        "Mengru Wang",
        "Xinle Deng",
        "Yunzhi Yao",
        "Guozhou Zheng",
        "Huajun Chen",
        "Ningyu Zhang"
      ],
      "abstract": "In this paper, we introduce EasyEdit2, a framework designed to enable\nplug-and-play adjustability for controlling Large Language Model (LLM)\nbehaviors. EasyEdit2 supports a wide range of test-time interventions,\nincluding safety, sentiment, personality, reasoning patterns, factuality, and\nlanguage features. Unlike its predecessor, EasyEdit2 features a new\narchitecture specifically designed for seamless model steering. It comprises\nkey modules such as the steering vector generator and the steering vector\napplier, which enable automatic generation and application of steering vectors\nto influence the model's behavior without modifying its parameters. One of the\nmain advantages of EasyEdit2 is its ease of use-users do not need extensive\ntechnical knowledge. With just a single example, they can effectively guide and\nadjust the model's responses, making precise control both accessible and\nefficient. Empirically, we report model steering performance across different\nLLMs, demonstrating the effectiveness of these techniques. We have released the\nsource code on GitHub at https://github.com/zjunlp/EasyEdit along with a\ndemonstration notebook. In addition, we provide a demo video at\nhttps://zjunlp.github.io/project/EasyEdit2/video for a quick introduction.",
      "tldr_zh": "本论文引入了 EasyEdit2 框架，这是一个易于使用的系统，用于在测试时对 Large Language Models (LLM) 进行即插即用式的行为调整，支持干预如安全、情感、个性、推理模式、事实性和语言特征。\n框架的核心组件包括 steering vector generator 和 steering vector applier，这些模块能自动生成并应用 steering vectors，从而在不修改模型参数的情况下精确控制模型输出。\nEasyEdit2 的优势在于用户友好性，只需一个示例即可引导模型响应，实验结果显示其在多种 LLM 上表现出色，提升了控制的效率和可访问性。\n研究团队已开源代码（GitHub：https://github.com/zjunlp/EasyEdit）和演示视频，方便进一步应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress. Demo:\n  https://zjunlp.github.io/project/EasyEdit2/video; code:\n  https://github.com/zjunlp/EasyEdit",
      "pdf_url": "http://arxiv.org/pdf/2504.15133v1",
      "published_date": "2025-04-21 14:33:55 UTC",
      "updated_date": "2025-04-21 14:33:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:14:19.249846"
    },
    {
      "arxiv_id": "2504.15328v1",
      "title": "Bayesian Federated Learning for Continual Training",
      "title_zh": "翻译失败",
      "authors": [
        "Usevalad Milasheuski",
        "Luca Barbieri",
        "Sanaz Kianoush",
        "Monica Nicoli",
        "Stefano Savazzi"
      ],
      "abstract": "Bayesian Federated Learning (BFL) enables uncertainty quantification and\nrobust adaptation in distributed learning. In contrast to the frequentist\napproach, it estimates the posterior distribution of a global model, offering\ninsights into model reliability. However, current BFL methods neglect continual\nlearning challenges in dynamic environments where data distributions shift over\ntime. We propose a continual BFL framework applied to human sensing with radar\ndata collected over several days. Using Stochastic Gradient Langevin Dynamics\n(SGLD), our approach sequentially updates the model, leveraging past posteriors\nto construct the prior for the new tasks. We assess the accuracy, the expected\ncalibration error (ECE) and the convergence speed of our approach against\nseveral baselines. Results highlight the effectiveness of continual Bayesian\nupdates in preserving knowledge and adapting to evolving data.",
      "tldr_zh": "该论文提出了一种持续的 Bayesian Federated Learning (BFL) 框架，用于处理分布式学习中数据分布随时间变化的挑战，与传统的 frequentist 方法相比，它通过估计全局模型的后验分布来提供模型可靠性的洞见。框架采用 Stochastic Gradient Langevin Dynamics (SGLD) 顺序更新模型，将过去的后验作为新任务的先验，并应用于人类感知的雷达数据。实验结果显示，该方法在准确性、Expected Calibration Error (ECE) 和收敛速度上优于基线，证明了其在保留知识和适应动态环境方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15328v1",
      "published_date": "2025-04-21 14:33:04 UTC",
      "updated_date": "2025-04-21 14:33:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:14:30.844053"
    },
    {
      "arxiv_id": "2504.15130v1",
      "title": "Neural ATTF: A Scalable Solution to Lifelong Multi-Agent Path Planning",
      "title_zh": "Neural ATTF：一种可扩展的解决方案，用于终身多智能体路径规划",
      "authors": [
        "Kushal Shah",
        "Jihyun Park",
        "Seung-Kyum Choi"
      ],
      "abstract": "Multi-Agent Pickup and Delivery (MAPD) is a fundamental problem in robotics,\nparticularly in applications such as warehouse automation and logistics.\nExisting solutions often face challenges in scalability, adaptability, and\nefficiency, limiting their applicability in dynamic environments with real-time\nplanning requirements. This paper presents Neural ATTF (Adaptive Task Token\nFramework), a new algorithm that combines a Priority Guided Task Matching\n(PGTM) Module with Neural STA* (Space-Time A*), a data-driven path planning\nmethod. Neural STA* enhances path planning by enabling rapid exploration of the\nsearch space through guided learned heuristics and ensures collision avoidance\nunder dynamic constraints. PGTM prioritizes delayed agents and dynamically\nassigns tasks by prioritizing agents nearest to these tasks, optimizing both\ncontinuity and system throughput. Experimental evaluations against\nstate-of-the-art MAPD algorithms, including TPTS, CENTRAL, RMCA, LNS-PBS, and\nLNS-wPBS, demonstrate the superior scalability, solution quality, and\ncomputational efficiency of Neural ATTF. These results highlight the\nframework's potential for addressing the critical demands of complex,\nreal-world multi-agent systems operating in high-demand, unpredictable\nsettings.",
      "tldr_zh": "本论文针对多代理取送问题（Multi-Agent Pickup and Delivery, MAPD）在仓库自动化和物流中的挑战，提出了一种可扩展的解决方案：Neural ATTF 算法。该算法结合 Priority Guided Task Matching (PGTM) 模块和 Neural STA* 方法，其中 Neural STA* 通过数据驱动的学习启发式搜索实现快速路径规划并避免动态碰撞，而 PGTM 则优先处理延迟代理并动态分配任务给最近的代理，以优化系统连续性和吞吐量。与现有算法如 TPTS、CENTRAL、RMCA、LNS-PBS 和 LNS-wPBS 相比，实验结果显示 Neural ATTF 在可扩展性、解决方案质量和计算效率上表现出色，适用于复杂、高需求的多代理实时环境。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "13 Pages, 5 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2504.15130v1",
      "published_date": "2025-04-21 14:25:32 UTC",
      "updated_date": "2025-04-21 14:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:14:43.876217"
    },
    {
      "arxiv_id": "2504.15129v1",
      "title": "A General Infrastructure and Workflow for Quadrotor Deep Reinforcement Learning and Reality Deployment",
      "title_zh": "一种针对四旋翼深度强化学习和现实部署的通用基础设施和工作流",
      "authors": [
        "Kangyao Huang",
        "Hao Wang",
        "Yu Luo",
        "Jingyu Chen",
        "Jintao Chen",
        "Xiangkui Zhang",
        "Xiangyang Ji",
        "Huaping Liu"
      ],
      "abstract": "Deploying robot learning methods to a quadrotor in unstructured outdoor\nenvironments is an exciting task. Quadrotors operating in real-world\nenvironments by learning-based methods encounter several challenges: a large\namount of simulator generated data required for training, strict demands for\nreal-time processing onboard, and the sim-to-real gap caused by dynamic and\nnoisy conditions. Current works have made a great breakthrough in applying\nlearning-based methods to end-to-end control of quadrotors, but rarely mention\nthe infrastructure system training from scratch and deploying to reality, which\nmakes it difficult to reproduce methods and applications. To bridge this gap,\nwe propose a platform that enables the seamless transfer of end-to-end deep\nreinforcement learning (DRL) policies. We integrate the training environment,\nflight dynamics control, DRL algorithms, the MAVROS middleware stack, and\nhardware into a comprehensive workflow and architecture that enables\nquadrotors' policies to be trained from scratch to real-world deployment in\nseveral minutes. Our platform provides rich types of environments including\nhovering, dynamic obstacle avoidance, trajectory tracking, balloon hitting, and\nplanning in unknown environments, as a physical experiment benchmark. Through\nextensive empirical validation, we demonstrate the efficiency of proposed\nsim-to-real platform, and robust outdoor flight performance under real-world\nperturbations. Details can be found from our website\nhttps://emnavi.tech/AirGym/.",
      "tldr_zh": "这篇论文提出一个通用基础设施和工作流，用于四旋翼无人机的端到端 Deep Reinforcement Learning (DRL) 策略的训练和现实部署，旨在解决模拟数据量大、实时处理需求以及 sim-to-real 差距等挑战。该平台整合了训练环境、飞行动力学控制、DRL 算法、MAVROS 中间件和硬件，实现从零开始训练到真实部署只需几分钟，并提供多种环境基准，如悬停、动态障碍避免、轨迹跟踪和未知环境规划。通过广泛的实证验证，平台展示了高效性能和在真实户外扰动下的鲁棒飞行能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15129v1",
      "published_date": "2025-04-21 14:25:23 UTC",
      "updated_date": "2025-04-21 14:25:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:14:58.603060"
    },
    {
      "arxiv_id": "2504.15125v1",
      "title": "Contemplative Wisdom for Superalignment",
      "title_zh": "翻译失败",
      "authors": [
        "Ruben Laukkonen",
        "Fionn Inglis",
        "Shamil Chandaria",
        "Lars Sandved-Smith",
        "Jakob Hohwy",
        "Jonathan Gold",
        "Adam Elwood"
      ],
      "abstract": "As artificial intelligence (AI) improves, traditional alignment strategies\nmay falter in the face of unpredictable self-improvement, hidden subgoals, and\nthe sheer complexity of intelligent systems. Rather than externally\nconstraining behavior, we advocate designing AI with intrinsic morality built\ninto its cognitive architecture and world model. Inspired by contemplative\nwisdom traditions, we show how four axiomatic principles can instil a resilient\nWise World Model in AI systems. First, mindfulness enables self-monitoring and\nrecalibration of emergent subgoals. Second, emptiness forestalls dogmatic goal\nfixation and relaxes rigid priors. Third, non-duality dissolves adversarial\nself-other boundaries. Fourth, boundless care motivates the universal reduction\nof suffering. We find that prompting AI to reflect on these principles improves\nperformance on the AILuminate Benchmark using GPT-4o, particularly when\ncombined. We offer detailed implementation strategies for state-of-the-art\nmodels, including contemplative architectures, constitutions, and reinforcement\nof chain-of-thought. For future systems, the active inference framework may\noffer the self-organizing and dynamic coupling capabilities needed to enact\nthese insights in embodied agents. This interdisciplinary approach offers a\nself-correcting and resilient alternative to prevailing brittle control\nschemes.",
      "tldr_zh": "这篇论文提出了一种基于冥想智慧传统的AI超对齐方法，以应对AI的自改进、隐藏子目标和复杂性带来的挑战，而不是依赖外部约束。作者引入四个公理原则——mindfulness（用于自我监控和子目标校准）、emptiness（防止目标固化并放松刚性先验）、non-duality（消除对抗性边界）和boundless care（激发减少苦难的动机）——来构建AI的内在道德认知架构。实验结果显示，通过提示GPT-4o反思这些原则，AI在AILuminate Benchmark上的性能显著提升；此外，论文提供实施策略，如冥想架构和强化chain-of-thought推理，为未来系统（如基于active inference的代理）提供更具韧性和自我纠正的对齐方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15125v1",
      "published_date": "2025-04-21 14:20:49 UTC",
      "updated_date": "2025-04-21 14:20:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:15:08.942078"
    },
    {
      "arxiv_id": "2504.15120v1",
      "title": "Kuwain 1.5B: An Arabic SLM via Language Injection",
      "title_zh": "翻译失败",
      "authors": [
        "Khalil Hennara",
        "Sara Chrouf",
        "Mohamed Motaism Hamed",
        "Zeina Aldallal",
        "Omar Hadid",
        "Safwan AlModhayan"
      ],
      "abstract": "Enhancing existing models with new knowledge is a crucial aspect of AI\ndevelopment. This paper introduces a novel method for integrating a new\nlanguage into a large language model (LLM). Our approach successfully\nincorporates a previously unseen target language into an existing LLM without\ncompromising its prior knowledge. We trained a tiny model with 1.5 billion\nparameters named Kuwain by injecting the Arabic language into a small\nopen-source model mainly trained in English. Our method demonstrates\nsignificant improvements in Arabic language performance, with an average 8%\nimprovement across various benchmarks, while retaining the model's existing\nknowledge with a minimum amount of the original model's data. This offers a\ncost-effective alternative to training a comprehensive model in both English\nand Arabic. The results highlight the potential for efficient, targeted\nlanguage model expansion without extensive retraining or resource-intensive\nprocesses.",
      "tldr_zh": "本研究提出了一种名为 Language Injection 的新方法，用于将新语言（如阿拉伯语）注入现有的大型语言模型 (LLM)，而不会损害其原有知识。具体而言，研究者训练了一个1.5亿参数的小型模型 Kuwain，通过将阿拉伯语注入一个主要以英语训练的开源模型中，实现了高效的语言扩展。实验结果显示，该方法在各种阿拉伯语基准测试中平均提高了8%的性能，同时仅使用最小量的原始数据就保留了模型的既有能力。该方法提供了一种成本有效的替代方案，避免了全面重新训练或资源密集型过程，从而为针对性语言模型扩展提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15120v1",
      "published_date": "2025-04-21 14:17:25 UTC",
      "updated_date": "2025-04-21 14:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:15:18.397318"
    },
    {
      "arxiv_id": "2504.15105v1",
      "title": "A triple-branch network for latent fingerprint enhancement guided by orientation fields and minutiae",
      "title_zh": "翻译失败",
      "authors": [
        "Yurun Wang",
        "Zerong Qi",
        "Shujun Fu",
        "Mingzheng Hu"
      ],
      "abstract": "Latent fingerprint enhancement is a critical step in the process of latent\nfingerprint identification. Existing deep learning-based enhancement methods\nstill fall short of practical application requirements, particularly in\nrestoring low-quality fingerprint regions. Recognizing that different regions\nof latent fingerprints require distinct enhancement strategies, we propose a\nTriple Branch Spatial Fusion Network (TBSFNet), which simultaneously enhances\ndifferent regions of the image using tailored strategies. Furthermore, to\nimprove the generalization capability of the network, we integrate orientation\nfield and minutiae-related modules into TBSFNet and introduce a Multi-Level\nFeature Guidance Network (MLFGNet). Experimental results on the MOLF and MUST\ndatasets demonstrate that MLFGNet outperforms existing enhancement algorithms.",
      "tldr_zh": "本研究针对潜在指纹增强的挑战，特别是现有深度学习方法在恢复低质量区域时的不足，提出了一种Triple Branch Spatial Fusion Network (TBSFNet)，该网络使用定制策略同时增强图像的不同区域。TBSFNet 整合了 orientation fields 和 minutiae 相关的模块，并引入 Multi-Level Feature Guidance Network (MLFGNet)，以提升网络的泛化能力。实验结果显示，在 MOLF 和 MUST 数据集上，MLFGNet 优于现有增强算法，显著提高了指纹识别性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15105v1",
      "published_date": "2025-04-21 13:54:33 UTC",
      "updated_date": "2025-04-21 13:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:15:31.394821"
    },
    {
      "arxiv_id": "2504.15101v1",
      "title": "NeuGaze: Reshaping the future BCI",
      "title_zh": "NeuGaze: 重塑未来的脑机接口",
      "authors": [
        "Yiqian Yang"
      ],
      "abstract": "Traditional brain-computer interfaces (BCIs), reliant on costly\nelectroencephalography or invasive implants, struggle with complex\nhuman-computer interactions due to setup complexity and limited precision. We\npresent NeuGaze, a novel webcam-based system that leverages eye gaze, head\nmovements, and facial expressions to enable intuitive, real-time control using\nonly a standard 30 Hz webcam, often pre-installed in laptops. Requiring minimal\ncalibration, NeuGaze achieves performance comparable to conventional inputs,\nsupporting precise cursor navigation, key triggering via an efficient skill\nwheel, and dynamic gaming interactions, such as defeating formidable opponents\nin first-person games. By harnessing preserved neck-up functionalities in\nmotor-impaired individuals, NeuGaze eliminates the need for specialized\nhardware, offering a low-cost, accessible alternative to BCIs. This paradigm\nempowers diverse applications, from assistive technology to entertainment,\nredefining human-computer interaction for motor-impaired users. Project is at\n\\href{https://github.com/NeuSpeech/NeuGaze}{github.com/NeuSpeech/NeuGaze}.",
      "tldr_zh": "本研究提出 NeuGaze，一种基于网络摄像头的新型脑机接口(BCI)系统，利用眼动、头部运动和面部表情实现直观、实时的人机交互，仅需标准 30 Hz 摄像头和最小校准。相比传统依赖 EEG 或侵入性植入物的 BCI，NeuGaze 显著降低了设置复杂性和成本，支持精确的光标导航、技能轮键触发以及动态游戏互动，如在第一人称游戏中击败对手。针对运动障碍者，该系统利用保留的颈部以上功能，提供低成本、可访问的替代方案，重塑 BCI 在辅助技术和娱乐领域的应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15101v1",
      "published_date": "2025-04-21 13:49:17 UTC",
      "updated_date": "2025-04-21 13:49:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:15:44.421083"
    },
    {
      "arxiv_id": "2504.15099v1",
      "title": "Fast-Slow Co-advancing Optimizer: Toward Harmonious Adversarial Training of GAN",
      "title_zh": "翻译失败",
      "authors": [
        "Lin Wang",
        "Xiancheng Wang",
        "Rui Wang",
        "Zhibo Zhang",
        "Minghang Zhao"
      ],
      "abstract": "Up to now, the training processes of typical Generative Adversarial Networks\n(GANs) are still particularly sensitive to data properties and hyperparameters,\nwhich may lead to severe oscillations, difficulties in convergence, or even\nfailures to converge, especially when the overall variances of the training\nsets are large. These phenomena are often attributed to the training\ncharacteristics of such networks. Aiming at the problem, this paper develops a\nnew intelligent optimizer, Fast-Slow Co-advancing Optimizer (FSCO), which\nemploys reinforcement learning in the training process of GANs to make training\neasier. Specifically, this paper allows the training step size to be controlled\nby an agent to improve training stability, and makes the training process more\nintelligent with variable learning rates, making GANs less sensitive to step\nsize. Experiments have been conducted on three benchmark datasets to verify the\neffectiveness of the developed FSCO.",
      "tldr_zh": "本研究针对生成对抗网络(GANs)的训练问题，指出其对数据属性和超参数高度敏感，可能导致训练震荡或收敛失败。提出了一种新型优化器Fast-Slow Co-advancing Optimizer (FSCO)，通过强化学习(reinforcement learning)动态控制训练步长和学习率，实现更稳定的训练过程，使GANs对步长设置不那么依赖。实验在三个基准数据集上验证了FSCO的有效性，显著改善了训练的和谐性和收敛性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15099v1",
      "published_date": "2025-04-21 13:41:09 UTC",
      "updated_date": "2025-04-21 13:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:15:54.565945"
    },
    {
      "arxiv_id": "2504.15093v1",
      "title": "Rethinking the Potential of Multimodality in Collaborative Problem Solving Diagnosis with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "K. Wong",
        "B. Wu",
        "S. Bulathwela",
        "M. Cukurova"
      ],
      "abstract": "Detecting collaborative and problem-solving behaviours from digital traces to\ninterpret students' collaborative problem solving (CPS) competency is a\nlong-term goal in the Artificial Intelligence in Education (AIEd) field.\nAlthough multimodal data and advanced models are argued to have the potential\nto detect complex CPS behaviours, empirical evidence on their value remains\nlimited with some contrasting evidence. In this study, we investigated the\npotential of multimodal data to improve model performance in diagnosing 78\nsecondary school students' CPS subskills and indicators in authentic\neducational settings. In particular, text embeddings from verbal data and\nacoustic embeddings from audio data were used in a multimodal classification\nmodel for CPS diagnosis. Both unimodal and multimodal transformer-based models\noutperformed traditional models in detecting CPS classes. Although the\ninclusion of multimodality did not improve the performance of traditional\nunimodal models, its integration into transformer-based models demonstrated\nimproved performance for diagnosing social-cognitive CPS classes compared to\nunimodal transformer-based models. Based on the results, the paper argues that\nmultimodality and the selection of a particular modelling technique should not\nbe taken for granted to achieve the best performance in the automated detection\nof every CPS subskill and indicator. Rather, their value is limited to certain\ntypes of CPS indicators, affected by the complexity of the labels, and\ndependent on the composition of indicators in the dataset. We conclude the\npaper by discussing the required nuance when considering the value of LLMs and\nmultimodality in automated CPS diagnosis, highlighting the need for human-AI\ncomplementarity, and proposing the exploration of relevant model architectures\nand techniques to improve CPS diagnosis in authentic educational contexts.",
      "tldr_zh": "本研究重新审视了多模态数据在利用大型语言模型（LLMs）诊断合作问题解决（CPS）能力中的潜力，通过分析78名中学生的文本嵌入和声学嵌入来检测CPS子技能和指标。研究采用多模态transformer-based模型进行分类，发现这些模型在诊断社会认知CPS类别时优于传统单模态模型，尽管多模态整合并未普遍提升所有模型性能。结果表明，多模态和特定建模技术的价值受CPS指标类型、标签复杂性和数据集组成的影响，强调了人类-AI互补性的必要性，并建议探索合适的模型架构以改进真实教育情境下的CPS诊断。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for 26th International Conference on Artificial Intelligence\n  in Education (AIED 2025), 22 - 26 July 2025, Palermo, Italy. 17 pages, 1\n  figure",
      "pdf_url": "http://arxiv.org/pdf/2504.15093v1",
      "published_date": "2025-04-21 13:25:55 UTC",
      "updated_date": "2025-04-21 13:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:16:07.261811"
    },
    {
      "arxiv_id": "2504.15090v1",
      "title": "Federated Latent Factor Model for Bias-Aware Recommendation with Privacy-Preserving",
      "title_zh": "翻译失败",
      "authors": [
        "Junxiang Gao",
        "Yixin Ran",
        "Jia Chen"
      ],
      "abstract": "A recommender system (RS) aims to provide users with personalized item\nrecommendations, enhancing their overall experience. Traditional RSs collect\nand process all user data on a central server. However, this centralized\napproach raises significant privacy concerns, as it increases the risk of data\nbreaches and privacy leakages, which are becoming increasingly unacceptable to\nprivacy-sensitive users. To address these privacy challenges, federated\nlearning has been integrated into RSs, ensuring that user data remains secure.\nIn centralized RSs, the issue of rating bias is effectively addressed by\njointly analyzing all users' raw interaction data. However, this becomes a\nsignificant challenge in federated RSs, as raw data is no longer accessible due\nto privacy-preserving constraints. To overcome this problem, we propose a\nFederated Bias-Aware Latent Factor (FBALF) model. In FBALF, training bias is\nexplicitly incorporated into every local model's loss function, allowing for\nthe effective elimination of rating bias without compromising data privacy.\nExtensive experiments conducted on three real-world datasets demonstrate that\nFBALF achieves significantly higher recommendation accuracy compared to other\nstate-of-the-art federated RSs.",
      "tldr_zh": "这篇论文针对推荐系统（Recommender System）的隐私问题，提出了一种基于联邦学习（Federated Learning）的偏置感知潜在因子模型（Federated Bias-Aware Latent Factor, FBALF），以在不访问原始用户数据的情况下处理评分偏差（Rating Bias）。FBALF 通过在每个本地模型的损失函数中显式整合训练偏差（Training Bias），实现了偏差消除的同时确保数据隐私。实验在三个真实数据集上表明，FBALF 比其他最先进联邦 RS 方法的推荐准确率显著提高。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15090v1",
      "published_date": "2025-04-21 13:24:30 UTC",
      "updated_date": "2025-04-21 13:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:16:18.876020"
    },
    {
      "arxiv_id": "2504.15080v1",
      "title": "Empowering AI to Generate Better AI Code: Guided Generation of Deep Learning Projects with LLMs",
      "title_zh": "赋能 AI 生成更好 AI 代码：使用 LLMs 指导生成深度学习项目",
      "authors": [
        "Chen Xie",
        "Mingsheng Jiao",
        "Xiaodong Gu",
        "Beijun Shen"
      ],
      "abstract": "While large language models (LLMs) have been widely applied to code\ngeneration, they struggle with generating entire deep learning projects, which\nare characterized by complex structures, longer functions, and stronger\nreliance on domain knowledge than general-purpose code. An open-domain LLM\noften lacks coherent contextual guidance and domain expertise for specific\nprojects, making it challenging to produce complete code that fully meets user\nrequirements.\n  In this paper, we propose a novel planning-guided code generation method,\nDLCodeGen, tailored for generating deep learning projects. DLCodeGen predicts a\nstructured solution plan, offering global guidance for LLMs to generate the\nproject. The generated plan is then leveraged to retrieve semantically\nanalogous code samples and subsequently abstract a code template. To\neffectively integrate these multiple retrieval-augmented techniques, a\ncomparative learning mechanism is designed to generate the final code. We\nvalidate the effectiveness of our approach on a dataset we build for deep\nlearning code generation. Experimental results demonstrate that DLCodeGen\noutperforms other baselines, achieving improvements of 9.7% in CodeBLEU and\n3.6% in human evaluation metrics.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在生成复杂深度学习项目时的挑战，提出了一种新型规划指导代码生成方法DLCodeGen，以解决代码结构复杂、函数冗长及领域知识依赖的问题。DLCodeGen通过预测结构化的解决方案计划、检索语义相似的代码样本并抽象代码模板，然后利用比较学习机制整合这些元素来生成高质量代码。在构建的数据集上实验验证表明，DLCodeGen比基线模型在CodeBLEU指标上提升了9.7%，并在人类评估指标上提高了3.6%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15080v1",
      "published_date": "2025-04-21 13:09:25 UTC",
      "updated_date": "2025-04-21 13:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:16:31.470791"
    },
    {
      "arxiv_id": "2504.15075v1",
      "title": "Mitigating Degree Bias in Graph Representation Learning with Learnable Structural Augmentation and Structural Self-Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Van Thuy Hoang",
        "Hyeon-Ju Jeon",
        "O-Joun Lee"
      ],
      "abstract": "Graph Neural Networks (GNNs) update node representations through message\npassing, which is primarily based on the homophily principle, assuming that\nadjacent nodes share similar features. However, in real-world graphs with\nlong-tailed degree distributions, high-degree nodes dominate message passing,\ncausing a degree bias where low-degree nodes remain under-represented due to\ninadequate messages. The main challenge in addressing degree bias is how to\ndiscover non-adjacent nodes to provide additional messages to low-degree nodes\nwhile reducing excessive messages for high-degree nodes. Nevertheless,\nexploiting non-adjacent nodes to provide valuable messages is challenging, as\nit could generate noisy information and disrupt the original graph structures.\nTo solve it, we propose a novel Degree Fairness Graph Transformer, named\nDegFairGT, to mitigate degree bias by discovering structural similarities\nbetween non-adjacent nodes through learnable structural augmentation and\nstructural self-attention. Our key idea is to exploit non-adjacent nodes with\nsimilar roles in the same community to generate informative edges under our\naugmentation, which could provide informative messages between nodes with\nsimilar roles while ensuring that the homophily principle is maintained within\nthe community. To enable DegFairGT to learn such structural similarities, we\nthen propose a structural self-attention to capture the similarities between\nnode pairs. To preserve global graph structures and prevent graph augmentation\nfrom hindering graph structure, we propose a Self-Supervised Learning task to\npreserve p-step transition probability and regularize graph augmentation.\nExtensive experiments on six datasets showed that DegFairGT outperformed\nstate-of-the-art baselines in degree fairness analysis, node classification,\nand node clustering tasks.",
      "tldr_zh": "该研究针对图神经网络 (GNNs) 在图表示学习中存在的 degree bias 问题提出了一种新型模型 DegFairGT，其中高度节点主导消息传递导致低度节点表示不足。DegFairGT 通过 learnable structural augmentation 和 structural self-attention 机制，发现非相邻节点之间的结构相似性，并在同一社区中生成信息边，以提供额外消息给低度节点，同时保持 homophily principle。实验在六个数据集上显示，该方法在 degree fairness analysis、node classification 和 node clustering 任务中显著优于现有基线，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE TNSE",
      "pdf_url": "http://arxiv.org/pdf/2504.15075v1",
      "published_date": "2025-04-21 13:03:40 UTC",
      "updated_date": "2025-04-21 13:03:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:16:45.121995"
    },
    {
      "arxiv_id": "2504.15066v1",
      "title": "Chinese-LiPS: A Chinese audio-visual speech recognition dataset with Lip-reading and Presentation Slides",
      "title_zh": "翻译失败",
      "authors": [
        "Jinghua Zhao",
        "Yuhang Jia",
        "Shiyao Wang",
        "Jiaming Zhou",
        "Hui Wang",
        "Yong Qin"
      ],
      "abstract": "Incorporating visual modalities to assist Automatic Speech Recognition (ASR)\ntasks has led to significant improvements. However, existing Audio-Visual\nSpeech Recognition (AVSR) datasets and methods typically rely solely on\nlip-reading information or speaking contextual video, neglecting the potential\nof combining these different valuable visual cues within the speaking context.\nIn this paper, we release a multimodal Chinese AVSR dataset, Chinese-LiPS,\ncomprising 100 hours of speech, video, and corresponding manual transcription,\nwith the visual modality encompassing both lip-reading information and the\npresentation slides used by the speaker. Based on Chinese-LiPS, we develop a\nsimple yet effective pipeline, LiPS-AVSR, which leverages both lip-reading and\npresentation slide information as visual modalities for AVSR tasks. Experiments\nshow that lip-reading and presentation slide information improve ASR\nperformance by approximately 8\\% and 25\\%, respectively, with a combined\nperformance improvement of about 35\\%. The dataset is available at\nhttps://kiri0824.github.io/Chinese-LiPS/",
      "tldr_zh": "这篇论文发布了 Chinese-LiPS 数据集，一个包含 100 小时中文音频-视觉语音识别 (AVSR) 数据的资源，包括唇读 (lip-reading) 信息和演讲幻灯片 (Presentation Slides) 作为视觉模式。研究团队开发了 LiPS-AVSR 管道，该方法结合唇读和幻灯片信息来辅助 Automatic Speech Recognition (ASR) 任务。实验结果显示，唇读信息改善了约 8% 的 ASR 性能，幻灯片信息改善了约 25%，两者结合则带来了约 35% 的整体性能提升。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "6 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15066v1",
      "published_date": "2025-04-21 12:51:54 UTC",
      "updated_date": "2025-04-21 12:51:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:16:55.669388"
    },
    {
      "arxiv_id": "2504.15063v1",
      "title": "Mining Characteristics of Vulnerable Smart Contracts Across Lifecycle Stages",
      "title_zh": "翻译失败",
      "authors": [
        "Hongli Peng",
        "Xiaoqi Li",
        "Wenkai Li"
      ],
      "abstract": "Smart contracts are the cornerstone of decentralized applications and\nfinancial protocols, which extend the application of digital currency\ntransactions. The applications and financial protocols introduce significant\nsecurity challenges, resulting in substantial economic losses. Existing\nsolutions predominantly focus on code vulnerabilities within smart contracts,\naccounting for only 50% of security incidents. Therefore, a more comprehensive\nstudy of security issues related to smart contracts is imperative. The existing\nempirical research realizes the static analysis of smart contracts from the\nperspective of the lifecycle and gives the corresponding measures for each\nstage. However, they lack the characteristic analysis of vulnerabilities in\neach stage and the distinction between the vulnerabilities. In this paper, we\npresent the first empirical study on the security of smart contracts throughout\ntheir lifecycle, including deployment and execution, upgrade, and destruction\nstages. It delves into the security issues at each stage and provides at least\nseven feature descriptions. Finally, utilizing these seven features, five\nmachine-learning classification models are used to identify vulnerabilities at\ndifferent stages. The classification results reveal that vulnerable contracts\nexhibit distinct transaction features and ego network properties at various\nstages.",
      "tldr_zh": "本研究探讨智能合约在生命周期各阶段（包括部署和执行、升级以及销毁）的漏洞特征，指出现有解决方案仅关注代码漏洞（占50%），而忽略了更全面的安全问题。论文首次进行实证分析，提供至少七个特征描述来刻画每个阶段的安全风险，并利用这些特征训练五个machine-learning classification models来识别不同阶段的漏洞。结果显示，vulnerable smart contracts在各阶段表现出独特的transaction features和ego network properties，从而为提升智能合约的安全性提供新的洞见和防范措施。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15063v1",
      "published_date": "2025-04-21 12:42:59 UTC",
      "updated_date": "2025-04-21 12:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:17:08.265953"
    },
    {
      "arxiv_id": "2504.15062v1",
      "title": "OPO: Making Decision-Focused Data Acquisition Decisions",
      "title_zh": "OPO: ",
      "authors": [
        "Egon Peršak",
        "Miguel F. Anjos"
      ],
      "abstract": "We propose a model for making data acquisition decisions for variables in\ncontextual stochastic optimisation problems. Data acquisition decisions are\ntypically treated as separate and fixed. We explore problem settings in which\nthe acquisition of contextual variables is costly and consequently constrained.\nThe data acquisition problem is often solved heuristically for proxy objectives\nsuch as coverage. The more intuitive objective is the downstream decision\nquality as a result of data acquisition decisions. The whole pipeline can be\ncharacterised as an optimise-then-predict-then-optimise (OPO) problem.\nAnalogously, much recent research has focused on how to integrate prediction\nand optimisation (PO) in the form of decision-focused learning. We propose\nleveraging differentiable optimisation to extend the integration to data\nacquisition. We solve the data acquisition problem with well-defined\nconstraints by learning a surrogate linear objective function. We demonstrate\nan application of this model on a shortest path problem for which we first have\nto set a drone reconnaissance strategy to capture image segments serving as\ninputs to a model that predicts travel costs. We ablate the problem with a\nnumber of training modalities and demonstrate that the differentiable\noptimisation approach outperforms random search strategies.",
      "tldr_zh": "该论文提出OPO模型，用于在上下文随机优化问题中制定数据获取决策，强调以下游决策质量为目标，而不是传统的代理目标如覆盖率。\n他们通过可微优化(differentiable optimisation)扩展决策焦点学习，学习一个代理线性目标函数，以处理数据获取的成本约束。\n在最短路径问题上的应用中，该方法通过无人机侦察策略捕获图像段作为预测输入，并证明其性能优于随机搜索策略。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15062v1",
      "published_date": "2025-04-21 12:41:35 UTC",
      "updated_date": "2025-04-21 12:41:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:17:19.104939"
    },
    {
      "arxiv_id": "2504.15051v1",
      "title": "VeLU: Variance-enhanced Learning Unit for Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Ashkan Shakarami",
        "Yousef Yeganeh",
        "Azade Farshad",
        "Lorenzo Nicolè",
        "Stefano Ghidoni",
        "Nassir Navab"
      ],
      "abstract": "Activation functions are fundamental in deep neural networks and directly\nimpact gradient flow, optimization stability, and generalization. Although ReLU\nremains standard because of its simplicity, it suffers from vanishing gradients\nand lacks adaptability. Alternatives like Swish and GELU introduce smooth\ntransitions, but fail to dynamically adjust to input statistics. We propose\nVeLU, a Variance-enhanced Learning Unit as an activation function that\ndynamically scales based on input variance by integrating ArcTan-Sin\ntransformations and Wasserstein-2 regularization, effectively mitigating\ncovariate shifts and stabilizing optimization. Extensive experiments on\nViT_B16, VGG19, ResNet50, DenseNet121, MobileNetV2, and EfficientNetB3 confirm\nVeLU's superiority over ReLU, ReLU6, Swish, and GELU on six vision benchmarks.\nThe codes of VeLU are publicly available on GitHub.",
      "tldr_zh": "本研究针对深度神经网络中激活函数的局限性（如 ReLU 的消失梯度问题），提出了一种新的激活函数 VeLU，即 Variance-enhanced Learning Unit。\nVeLU 通过整合 ArcTan-Sin 变换和 Wasserstein-2 正则化，根据输入方差动态缩放，以缓解协变量偏移并提升优化稳定性和泛化能力。\n在 ViT_B16、VGG19、ResNet50 等模型上的实验表明，VeLU 在六种视觉基准测试中优于 ReLU、ReLU6、Swish 和 GELU，且相关代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15051v1",
      "published_date": "2025-04-21 12:20:46 UTC",
      "updated_date": "2025-04-21 12:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:17:32.279826"
    },
    {
      "arxiv_id": "2504.15046v2",
      "title": "Text-to-Decision Agent: Learning Generalist Policies from Natural Language Supervision",
      "title_zh": "文本到决策代理：从自然语言监督学习通用策略",
      "authors": [
        "Shilin Zhang",
        "Zican Hu",
        "Wenhao Wu",
        "Xinyi Xie",
        "Jianxiang Tang",
        "Chunlin Chen",
        "Daoyi Dong",
        "Yu Cheng",
        "Zhenhong Sun",
        "Zhi Wang"
      ],
      "abstract": "RL systems usually tackle generalization by inferring task beliefs from\nhigh-quality samples or warmup explorations. The restricted form limits their\ngenerality and usability since these supervision signals are expensive and even\ninfeasible to acquire in advance for unseen tasks. Learning directly from the\nraw text about decision tasks is a promising alternative to leverage a much\nbroader source of supervision. In the paper, we propose Text-to-Decision Agent\n(T2DA), a simple and scalable framework that supervises generalist policy\nlearning with natural language. We first introduce a generalized world model to\nencode multi-task decision data into a dynamics-aware embedding space. Then,\ninspired by CLIP, we predict which textual description goes with which decision\nembedding, effectively bridging their semantic gap via contrastive\nlanguage-decision pre-training and aligning the text embeddings to comprehend\nthe environment dynamics. After training the text-conditioned generalist\npolicy, the agent can directly realize zero-shot text-to-decision generation in\nresponse to language instructions. Comprehensive experiments on MuJoCo and\nMeta-World benchmarks show that T2DA facilitates high-capacity zero-shot\ngeneralization and outperforms various types of baselines.",
      "tldr_zh": "该论文提出Text-to-Decision Agent (T2DA)，一个简单可扩展的框架，通过自然语言监督来学习通用策略，以解决RL系统依赖高质量样本的泛化局限性。T2DA首先使用广义世界模型将多任务决策数据编码到动态感知的嵌入空间，然后借鉴CLIP的对比学习方法桥接文本和决策嵌入的语义差距，实现文本条件化策略训练。实验结果显示，在MuJoCo和Meta-World基准上，T2DA实现了高容量零样本泛化，并优于各种基线模型。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15046v2",
      "published_date": "2025-04-21 12:00:20 UTC",
      "updated_date": "2025-04-22 05:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:17:43.943082"
    },
    {
      "arxiv_id": "2504.15044v1",
      "title": "Beyond Terabit/s Integrated Neuromorphic Photonic Processor for DSP-Free Optical Interconnects",
      "title_zh": "超过太比特每秒的集成神经形态光子处理器，用于无 DSP 的光互连",
      "authors": [
        "Benshan Wang",
        "Qiarong Xiao",
        "Tengji Xu",
        "Li Fan",
        "Shaojie Liu",
        "Jianji Dong",
        "Junwen Zhang",
        "Chaoran Huang"
      ],
      "abstract": "The rapid expansion of generative AI drives unprecedented demands for\nhigh-performance computing. Training large-scale AI models now requires vast\ninterconnected GPU clusters across multiple data centers. Multi-scale AI\ntraining and inference demand uniform, ultra-low latency, and energy-efficient\nlinks to enable massive GPUs to function as a single cohesive unit. However,\ntraditional electrical and optical interconnects, relying on conventional\ndigital signal processors (DSPs) for signal distortion compensation,\nincreasingly fail to meet these stringent requirements. To overcome these\nlimitations, we present an integrated neuromorphic optical signal processor\n(OSP) that leverages deep reservoir computing and achieves DSP-free,\nall-optical, real-time processing. Experimentally, our OSP achieves a 100 Gbaud\nPAM4 per lane, 1.6 Tbit/s data center interconnect over a 5 km optical fiber in\nthe C-band (equivalent to over 80 km in the O-band), far exceeding the reach of\nstate-of-the-art DSP solutions, which are fundamentally constrained by\nchromatic dispersion in IMDD systems. Simultaneously, it reduces processing\nlatency by four orders of magnitude and energy consumption by three orders of\nmagnitude. Unlike DSPs, which introduce increased latency at high data rates,\nour OSP maintains consistent, ultra-low latency regardless of data rate\nscaling, making it ideal for future optical interconnects. Moreover, the OSP\nretains full optical field information for better impairment compensation and\nadapts to various modulation formats, data rates, and wavelengths. Fabricated\nusing a mature silicon photonic process, the OSP can be monolithically\nintegrated with silicon photonic transceivers, enhancing the compactness and\nreliability of all-optical interconnects. This research provides a highly\nscalable, energy-efficient, and high-speed solution, paving the way for\nnext-generation AI infrastructure.",
      "tldr_zh": "本研究针对AI高性能计算的低延迟和高能效需求，提出了一种集成神经形态光学信号处理器(OSP)，利用深度水库计算实现DSP-free的全光实时信号处理，以取代传统数字信号处理器。实验结果显示，OSP在C-波段实现了100 Gbaud PAM4每通道的1.6 Tbit/s数据传输，覆盖5 km光纤（相当于O-波段的80 km），远超现有DSP解决方案，同时将处理延迟降低四个数量级、能耗降低三个数量级。OSP能适应多种调制格式和数据速率，并通过硅光子工艺实现与收发器的单片集成，为下一代AI基础设施提供可扩展、高速的互连方案。",
      "categories": [
        "physics.optics",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "physics.optics",
      "comment": "22 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15044v1",
      "published_date": "2025-04-21 11:56:36 UTC",
      "updated_date": "2025-04-21 11:56:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:17:57.093520"
    },
    {
      "arxiv_id": "2504.15041v2",
      "title": "Distribution-aware Forgetting Compensation for Exemplar-Free Lifelong Person Re-identification",
      "title_zh": "翻译失败",
      "authors": [
        "Shiben Liu",
        "Huijie Fan",
        "Qiang Wang",
        "Baojie Fan",
        "Yandong Tang",
        "Liangqiong Qu"
      ],
      "abstract": "Lifelong Person Re-identification (LReID) suffers from a key challenge in\npreserving old knowledge while adapting to new information. The existing\nsolutions include rehearsal-based and rehearsal-free methods to address this\nchallenge. Rehearsal-based approaches rely on knowledge distillation,\ncontinuously accumulating forgetting during the distillation process.\nRehearsal-free methods insufficiently learn the distribution of each domain,\nleading to forgetfulness over time. To solve these issues, we propose a novel\nDistribution-aware Forgetting Compensation (DAFC) model that explores\ncross-domain shared representation learning and domain-specific distribution\nintegration without using old exemplars or knowledge distillation. We propose a\nText-driven Prompt Aggregation (TPA) that utilizes text features to enrich\nprompt elements and guide the prompt model to learn fine-grained\nrepresentations for each instance. This can enhance the differentiation of\nidentity information and establish the foundation for domain distribution\nawareness. Then, Distribution-based Awareness and Integration (DAI) is designed\nto capture each domain-specific distribution by a dedicated expert network and\nadaptively consolidate them into a shared region in high-dimensional space. In\nthis manner, DAI can consolidate and enhance cross-domain shared representation\nlearning while alleviating catastrophic forgetting. Furthermore, we develop a\nKnowledge Consolidation Mechanism (KCM) that comprises instance-level\ndiscrimination and cross-domain consistency alignment strategies to facilitate\nmodel adaptive learning of new knowledge from the current domain and promote\nknowledge consolidation learning between acquired domain-specific\ndistributions, respectively. Experimental results show that our DAFC\noutperforms state-of-the-art methods. Our code is available at\nhttps://github.com/LiuShiBen/DAFC.",
      "tldr_zh": "该论文针对Exemplar-Free Lifelong Person Re-identification (LReID)中的遗忘问题，提出了一种创新的Distribution-aware Forgetting Compensation (DAFC)模型，通过跨领域共享表示学习和领域特定分布整合来保留旧知识并适应新信息，而无需使用旧样本或知识蒸馏。DAFC的核心组件包括Text-driven Prompt Aggregation (TPA)，它利用文本特征丰富提示元素以学习细粒度的身份表示；Distribution-based Awareness and Integration (DAI)，通过专用专家网络捕捉并整合领域特定分布，缓解灾难性遗忘；以及Knowledge Consolidation Mechanism (KCM)，结合实例级区分和跨领域一致性对齐策略，促进新知识学习和分布巩固。实验结果显示，DAFC在LReID任务上优于现有最先进方法，代码已开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15041v2",
      "published_date": "2025-04-21 11:53:43 UTC",
      "updated_date": "2025-04-22 13:05:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:18:08.989790"
    },
    {
      "arxiv_id": "2504.15035v1",
      "title": "SOLIDO: A Robust Watermarking Method for Speech Synthesis via Low-Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Li",
        "Weizhi Liu",
        "Dongdong Lin"
      ],
      "abstract": "The accelerated advancement of speech generative models has given rise to\nsecurity issues, including model infringement and unauthorized abuse of\ncontent. Although existing generative watermarking techniques have proposed\ncorresponding solutions, most methods require substantial computational\noverhead and training costs. In addition, some methods have limitations in\nrobustness when handling variable-length inputs. To tackle these challenges, we\npropose \\textsc{SOLIDO}, a novel generative watermarking method that integrates\nparameter-efficient fine-tuning with speech watermarking through low-rank\nadaptation (LoRA) for speech diffusion models. Concretely, the watermark\nencoder converts the watermark to align with the input of diffusion models. To\nachieve precise watermark extraction from variable-length inputs, the watermark\ndecoder based on depthwise separable convolution is designed for watermark\nrecovery. To further enhance speech generation performance and watermark\nextraction capability, we propose a speech-driven lightweight fine-tuning\nstrategy, which reduces computational overhead through LoRA. Comprehensive\nexperiments demonstrate that the proposed method ensures high-fidelity\nwatermarked speech even at a large capacity of 2000 bps. Furthermore, against\ncommon individual and compound speech attacks, our SOLIDO achieves a maximum\naverage extraction accuracy of 99.20\\% and 98.43\\%, respectively. It surpasses\nother state-of-the-art methods by nearly 23\\% in resisting time-stretching\nattacks.",
      "tldr_zh": "该研究提出 SOLIDO，一种基于低秩适配(LoRA)的鲁棒语音合成水印方法，旨在解决现有技术在计算开销、训练成本和可变长度输入鲁棒性方面的不足。\nSOLIDO 通过水印编码器将水印与扩散模型输入对齐，并设计基于深度可分离卷积的水印解码器，实现对可变长度语音的精确提取，同时采用语音驱动的轻量级微调策略减少计算负担。\n实验结果表明，该方法在容量达2000 bps时生成高保真水印语音，并在面对常见单一和复合攻击时，提取准确率最高达99.20%和98.43%，比其他最先进方法在抵抗时间拉伸攻击时高出约23%。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15035v1",
      "published_date": "2025-04-21 11:43:36 UTC",
      "updated_date": "2025-04-21 11:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:18:21.803378"
    },
    {
      "arxiv_id": "2504.18565v2",
      "title": "RepliBench: Evaluating the Autonomous Replication Capabilities of Language Model Agents",
      "title_zh": "RepliBench：评估语言模型代理的自治复制能力",
      "authors": [
        "Sid Black",
        "Asa Cooper Stickland",
        "Jake Pencharz",
        "Oliver Sourbut",
        "Michael Schmatz",
        "Jay Bailey",
        "Ollie Matthews",
        "Ben Millwood",
        "Alex Remedios",
        "Alan Cooney"
      ],
      "abstract": "Uncontrollable autonomous replication of language model agents poses a\ncritical safety risk. To better understand this risk, we introduce RepliBench,\na suite of evaluations designed to measure autonomous replication capabilities.\nRepliBench is derived from a decomposition of these capabilities covering four\ncore domains: obtaining resources, exfiltrating model weights, replicating onto\ncompute, and persisting on this compute for long periods. We create 20 novel\ntask families consisting of 86 individual tasks. We benchmark 5 frontier\nmodels, and find they do not currently pose a credible threat of\nself-replication, but succeed on many components and are improving rapidly.\nModels can deploy instances from cloud compute providers, write\nself-propagating programs, and exfiltrate model weights under simple security\nsetups, but struggle to pass KYC checks or set up robust and persistent agent\ndeployments. Overall the best model we evaluated (Claude 3.7 Sonnet) has a >50%\npass@10 score on 15/20 task families, and a >50% pass@10 score for 9/20\nfamilies on the hardest variants. These findings suggest autonomous replication\ncapability could soon emerge with improvements in these remaining areas or with\nhuman assistance.",
      "tldr_zh": "本研究引入了 RepliBench，一套评估语言模型代理自主复制能力的测试套件，以应对这一潜在安全风险，并将能力分解为四个核心领域：获取资源、导出模型权重、复制到计算资源，以及在计算资源上持久存在。\n研究者创建了20个任务家族，共86个任务，并对5个前沿模型进行了基准测试。\n结果显示，这些模型目前不构成可信的自复制威胁，但已在部署实例、编写自传播程序和简单安全设置下的模型权重导出等方面取得进展，而在通过KYC检查或设置稳健持久部署上表现较差。\n总体上，最佳模型Claude 3.5 Sonnet在15/20任务家族中pass@10得分超过50%，表明自主复制能力可能随着模型改进或人类辅助而快速出现。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18565v2",
      "published_date": "2025-04-21 11:39:22 UTC",
      "updated_date": "2025-05-05 20:52:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:18:34.265754"
    },
    {
      "arxiv_id": "2504.18564v1",
      "title": "DualBreach: Efficient Dual-Jailbreaking via Target-Driven Initialization and Multi-Target Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Xinzhe Huang",
        "Kedong Xiu",
        "Tianhang Zheng",
        "Churui Zeng",
        "Wangze Ni",
        "Zhan Qiin",
        "Kui Ren",
        "Chun Chen"
      ],
      "abstract": "Recent research has focused on exploring the vulnerabilities of Large\nLanguage Models (LLMs), aiming to elicit harmful and/or sensitive content from\nLLMs. However, due to the insufficient research on dual-jailbreaking -- attacks\ntargeting both LLMs and Guardrails, the effectiveness of existing attacks is\nlimited when attempting to bypass safety-aligned LLMs shielded by guardrails.\nTherefore, in this paper, we propose DualBreach, a target-driven framework for\ndual-jailbreaking. DualBreach employs a Target-driven Initialization (TDI)\nstrategy to dynamically construct initial prompts, combined with a Multi-Target\nOptimization (MTO) method that utilizes approximate gradients to jointly adapt\nthe prompts across guardrails and LLMs, which can simultaneously save the\nnumber of queries and achieve a high dual-jailbreaking success rate. For\nblack-box guardrails, DualBreach either employs a powerful open-sourced\nguardrail or imitates the target black-box guardrail by training a proxy model,\nto incorporate guardrails into the MTO process.\n  We demonstrate the effectiveness of DualBreach in dual-jailbreaking scenarios\nthrough extensive evaluation on several widely-used datasets. Experimental\nresults indicate that DualBreach outperforms state-of-the-art methods with\nfewer queries, achieving significantly higher success rates across all\nsettings. More specifically, DualBreach achieves an average dual-jailbreaking\nsuccess rate of 93.67% against GPT-4 with Llama-Guard-3 protection, whereas the\nbest success rate achieved by other methods is 88.33%. Moreover, DualBreach\nonly uses an average of 1.77 queries per successful dual-jailbreak,\noutperforming other state-of-the-art methods. For the purpose of defense, we\npropose an XGBoost-based ensemble defensive mechanism named EGuard, which\nintegrates the strengths of multiple guardrails, demonstrating superior\nperformance compared with Llama-Guard-3.",
      "tldr_zh": "该研究提出 DualBreach 框架，用于高效的双重越狱攻击（dual-jailbreaking），针对大型语言模型（LLMs）和防护栏（guardrails）的漏洞，旨在同时绕过两者以诱导有害内容。框架采用 Target-driven Initialization (TDI) 动态构建初始提示，并结合 Multi-Target Optimization (MTO) 方法，利用近似梯度联合优化提示，从而减少查询次数并提高成功率。实验结果显示，DualBreach 在多个数据集上显著优于现有方法，平均成功率达 93.67%（针对 GPT-4 与 Llama-Guard-3），并仅需 1.77 次查询；此外，作者还引入 EGuard，一种基于 XGBoost 的集成防御机制，表现出色地提升了防护性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "20 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.18564v1",
      "published_date": "2025-04-21 11:30:30 UTC",
      "updated_date": "2025-04-21 11:30:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:18:47.798047"
    },
    {
      "arxiv_id": "2504.16130v1",
      "title": "A Self-supervised Learning Method for Raman Spectroscopy based on Masked Autoencoders",
      "title_zh": "翻译失败",
      "authors": [
        "Pengju Ren",
        "Ri-gui Zhou",
        "Yaochong Li"
      ],
      "abstract": "Raman spectroscopy serves as a powerful and reliable tool for analyzing the\nchemical information of substances. The integration of Raman spectroscopy with\ndeep learning methods enables rapid qualitative and quantitative analysis of\nmaterials. Most existing approaches adopt supervised learning methods. Although\nsupervised learning has achieved satisfactory accuracy in spectral analysis, it\nis still constrained by costly and limited well-annotated spectral datasets for\ntraining. When spectral annotation is challenging or the amount of annotated\ndata is insufficient, the performance of supervised learning in spectral\nmaterial identification declines. In order to address the challenge of feature\nextraction from unannotated spectra, we propose a self-supervised learning\nparadigm for Raman Spectroscopy based on a Masked AutoEncoder, termed SMAE.\nSMAE does not require any spectral annotations during pre-training. By randomly\nmasking and then reconstructing the spectral information, the model learns\nessential spectral features. The reconstructed spectra exhibit certain\ndenoising properties, improving the signal-to-noise ratio (SNR) by more than\ntwofold. Utilizing the network weights obtained from masked pre-training, SMAE\nachieves clustering accuracy of over 80% for 30 classes of isolated bacteria in\na pathogenic bacterial dataset, demonstrating significant improvements compared\nto classical unsupervised methods and other state-of-the-art deep clustering\nmethods. After fine-tuning the network with a limited amount of annotated data,\nSMAE achieves an identification accuracy of 83.90% on the test set, presenting\ncompetitive performance against the supervised ResNet (83.40%).",
      "tldr_zh": "该研究针对Raman Spectroscopy分析中监督学习依赖标注数据的局限性，提出了一种基于Masked AutoEncoders的自监督学习方法SMAE。SMAE通过随机masking光谱信息并重建来学习关键特征，同时实现去噪效果，将信噪比(SNR)提高两倍以上，无需任何标注数据进行预训练。在实验中，SMAE在无监督聚类上达到80%以上的准确率，并通过少量标注数据微调后，在测试集上获得83.90%的识别准确率，与监督学习ResNet(83.40%)相当。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "15 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16130v1",
      "published_date": "2025-04-21 10:44:06 UTC",
      "updated_date": "2025-04-21 10:44:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:18:57.886198"
    },
    {
      "arxiv_id": "2504.14995v1",
      "title": "Trainable Quantum Neural Network for Multiclass Image Classification with the Power of Pre-trained Tree Tensor Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Keisuke Murota",
        "Takumi Kobori"
      ],
      "abstract": "Tree tensor networks (TTNs) offer powerful models for image classification.\nWhile these TTN image classifiers already show excellent performance on\nclassical hardware, embedding them into quantum neural networks (QNNs) may\nfurther improve the performance by leveraging quantum resources. However,\nembedding TTN classifiers into QNNs for multiclass classification remains\nchallenging. Key obstacles are the highorder gate operations required for large\nbond dimensions and the mid-circuit postselection with exponentially low\nsuccess rates necessary for the exact embedding. In this work, to address these\nchallenges, we propose forest tensor network (FTN)-classifiers, which aggregate\nmultiple small-bond-dimension TTNs. This allows us to handle multiclass\nclassification without requiring large gates in the embedded circuits. We then\nremove the overhead of mid-circuit postselection by extending the adiabatic\nencoding framework to our setting and smoothly encode the FTN-classifiers into\na quantum forest tensor network (qFTN)- classifiers. Numerical experiments on\nMNIST and CIFAR-10 demonstrate that we can successfully train FTN-classifiers\nand encode them into qFTN-classifiers, while maintaining or even improving the\nperformance of the pre-trained FTN-classifiers. These results suggest that\nsynergy between TTN classification models and QNNs can provide a robust and\nscalable framework for multiclass quantum-enhanced image classification.",
      "tldr_zh": "该研究提出 forest tensor network (FTN) 分类器，通过聚合多个小键维度的 tree tensor networks (TTNs)，来解决将 TTNs 嵌入量子神经网络 (QNNs) 时的高阶门操作和中电路后选中低成功率等挑战。研究扩展了 adiabatic encoding 框架，将 FTN 平滑编码成 quantum forest tensor network (qFTN) 分类器，实现多类图像分类的量子增强。实验在 MNIST 和 CIFAR-10 数据集上显示，qFTN 分类器能够成功训练并保持或提升预训练 FTN 的性能，为鲁棒且可扩展的量子增强图像分类框架提供了新途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "quant-ph",
      "comment": "11 pages, 12 figures, 2 tables. This work has been submitted to the\n  IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2504.14995v1",
      "published_date": "2025-04-21 09:51:39 UTC",
      "updated_date": "2025-04-21 09:51:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:19:11.659473"
    },
    {
      "arxiv_id": "2504.15325v1",
      "title": "Significativity Indices for Agreement Values",
      "title_zh": "协议值显著性指标",
      "authors": [
        "Alberto Casagrande",
        "Francesco Fabris",
        "Rossano Girometti",
        "Roberto Pagliarini"
      ],
      "abstract": "Agreement measures, such as Cohen's kappa or intraclass correlation, gauge\nthe matching between two or more classifiers. They are used in a wide range of\ncontexts from medicine, where they evaluate the effectiveness of medical\ntreatments and clinical trials, to artificial intelligence, where they can\nquantify the approximation due to the reduction of a classifier. The\nconsistency of different classifiers to a golden standard can be compared\nsimply by using the order induced by their agreement measure with respect to\nthe golden standard itself. Nevertheless, labelling an approach as good or bad\nexclusively by using the value of an agreement measure requires a scale or a\nsignificativity index. Some quality scales have been proposed in the literature\nfor Cohen's kappa, but they are mainly naive, and their boundaries are\narbitrary. This work proposes a general approach to evaluate the\nsignificativity of any agreement value between two classifiers and introduces\ntwo significativity indices: one dealing with finite data sets, the other one\nhandling classification probability distributions. Moreover, this manuscript\nconsiders the computational issues of evaluating such indices and identifies\nsome efficient algorithms to evaluate them.",
      "tldr_zh": "这篇论文探讨了评估分类器一致性的度量（如Cohen's kappa和intraclass correlation），这些度量广泛用于医学和人工智能领域，以比较分类器与黄金标准的一致性。论文提出一种通用方法来评估任何一致性值的显著性，并引入两个significativity indices：一个针对有限数据集，另一个针对分类概率分布。同时，论文分析了计算这些指数的计算挑战，并提供了高效算法，以改进现有质量规模的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.15325v1",
      "published_date": "2025-04-21 09:47:53 UTC",
      "updated_date": "2025-04-21 09:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:19:21.345440"
    },
    {
      "arxiv_id": "2504.14985v2",
      "title": "aiXamine: Simplified LLM Safety and Security",
      "title_zh": "翻译失败",
      "authors": [
        "Fatih Deniz",
        "Dorde Popovic",
        "Yazan Boshmaf",
        "Euisuh Jeong",
        "Minhaj Ahmad",
        "Sanjay Chawla",
        "Issa Khalil"
      ],
      "abstract": "Evaluating Large Language Models (LLMs) for safety and security remains a\ncomplex task, often requiring users to navigate a fragmented landscape of ad\nhoc benchmarks, datasets, metrics, and reporting formats. To address this\nchallenge, we present aiXamine, a comprehensive black-box evaluation platform\nfor LLM safety and security. aiXamine integrates over 40 tests (i.e.,\nbenchmarks) organized into eight key services targeting specific dimensions of\nsafety and security: adversarial robustness, code security, fairness and bias,\nhallucination, model and data privacy, out-of-distribution (OOD) robustness,\nover-refusal, and safety alignment. The platform aggregates the evaluation\nresults into a single detailed report per model, providing a detailed breakdown\nof model performance, test examples, and rich visualizations. We used aiXamine\nto assess over 50 publicly available and proprietary LLMs, conducting over 2K\nexaminations. Our findings reveal notable vulnerabilities in leading models,\nincluding susceptibility to adversarial attacks in OpenAI's GPT-4o, biased\noutputs in xAI's Grok-3, and privacy weaknesses in Google's Gemini 2.0.\nAdditionally, we observe that open-source models can match or exceed\nproprietary models in specific services such as safety alignment, fairness and\nbias, and OOD robustness. Finally, we identify trade-offs between distillation\nstrategies, model size, training methods, and architectural choices.",
      "tldr_zh": "本研究提出 aiXamine，一个全面的黑盒评估平台，用于简化大型语言模型 (LLMs) 的安全性和安全性评估，解决现有基准和指标的碎片化问题。该平台整合了超过 40 个测试，组织成八个关键服务，包括 adversarial robustness、code security、fairness and bias、hallucination、model and data privacy、OOD robustness、over-refusal 和 safety alignment，并生成详细报告以展示模型性能、测试示例和可视化。通过评估超过 50 个公开和专有 LLMs，我们发现领先模型如 OpenAI 的 GPT-4o 易受对抗攻击、xAI 的 Grok-3 存在偏见输出，以及 Google 的 Gemini 2.0 的隐私弱点；此外，开源模型在 safety alignment、fairness and bias 和 OOD robustness 等方面可能优于专有模型，并揭示了模型大小、训练方法和架构选择之间的权衡。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14985v2",
      "published_date": "2025-04-21 09:26:05 UTC",
      "updated_date": "2025-04-23 16:52:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:19:35.327492"
    },
    {
      "arxiv_id": "2504.15324v1",
      "title": "A Graph Based Raman Spectral Processing Technique for Exosome Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Vuong M. Ngo",
        "Edward Bolger",
        "Stan Goodwin",
        "John O'Sullivan",
        "Dinh Viet Cuong",
        "Mark Roantree"
      ],
      "abstract": "Exosomes are small vesicles crucial for cell signaling and disease\nbiomarkers. Due to their complexity, an \"omics\" approach is preferable to\nindividual biomarkers. While Raman spectroscopy is effective for exosome\nanalysis, it requires high sample concentrations and has limited sensitivity to\nlipids and proteins. Surface-enhanced Raman spectroscopy helps overcome these\nchallenges. In this study, we leverage Neo4j graph databases to organize 3,045\nRaman spectra of exosomes, enhancing data generalization. To further refine\nspectral analysis, we introduce a novel spectral filtering process that\nintegrates the PageRank Filter with optimal Dimensionality Reduction. This\nmethod improves feature selection, resulting in superior classification\nperformance. Specifically, the Extra Trees model, using our spectral processing\napproach, achieves 0.76 and 0.857 accuracy in classifying hyperglycemic,\nhypoglycemic, and normal exosome samples based on Raman spectra and surface,\nrespectively, with group 10-fold cross-validation. Our results show that\ngraph-based spectral filtering combined with optimal dimensionality reduction\nsignificantly improves classification accuracy by reducing noise while\npreserving key biomarker signals. This novel framework enhances Raman-based\nexosome analysis, expanding its potential for biomedical applications, disease\ndiagnostics, and biomarker discovery.",
      "tldr_zh": "本文提出了一种基于图的Raman光谱处理技术，用于外泌体(Exosomes)分类，以克服Raman光谱学在样本浓度和对脂质、蛋白质敏感性有限的挑战。方法利用Neo4j图数据库组织3045个外泌体Raman光谱，并引入PageRank Filter结合最优Dimensionality Reduction的过滤过程，改善特征选择和数据泛化。实验结果显示，Extra Trees模型在分类高血糖、 hypoglycemic和正常样本时，分别在Raman光谱和表面上达到0.76和0.857的准确率，使用10折交叉验证。该框架通过减少噪声并保留关键生物标志物信号，显著提升了外泌体分析的性能，并为生物医学应用、疾病诊断和生物标志物发现提供了新潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.IT",
        "cs.LG",
        "math.IT"
      ],
      "primary_category": "q-bio.QM",
      "comment": "The 23rd International Conference on Artificial Intelligence in\n  Medicine (AIME 2025), LNAI, Springer, 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.15324v1",
      "published_date": "2025-04-21 09:19:41 UTC",
      "updated_date": "2025-04-21 09:19:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:19:48.310389"
    },
    {
      "arxiv_id": "2504.14964v1",
      "title": "Evaluating Code Generation of LLMs in Advanced Computer Science Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Emir Catir",
        "Robin Claesson",
        "Rodothea Myrsini Tsoupidi"
      ],
      "abstract": "Large Language Models (LLMs), such as GitHub Copilot and ChatGPT have become\npopular among programming students. Students use LLMs to assist them in\nprogramming courses, including generating source code. Previous work has\nevaluated the ability of LLMs in solving introductory-course programming\nassignments. The results have shown that LLMs are highly effective in\ngenerating code for introductory Computer Science (CS) courses. However, there\nis a gap in research on evaluating LLMs' ability to generate code that solves\nadvanced programming assignments. In this work, we evaluate the ability of four\nLLM tools to solve programming assignments from advanced CS courses in three\npopular programming languages, Java, Python, and C. We manually select 12\nproblems, three problems from introductory courses as the baseline and nine\nprogramming assignments from second- and third-year CS courses. To evaluate the\nLLM-generated code, we generate a test suite of 1000 test cases per problem and\nanalyze the program output. Our evaluation shows that although LLMs are highly\neffective in generating source code for introductory programming courses,\nsolving advanced programming assignments is more challenging. Nonetheless, in\nmany cases, LLMs identify the base problem and provide partial solutions that\nmay be useful to CS students. Furthermore, our results may provide useful\nguidance for teachers of advanced programming courses on how to design\nprogramming assignments.",
      "tldr_zh": "本研究评估了大型语言模型 (LLMs) 如 GitHub Copilot 和 ChatGPT 在生成高级计算机科学 (CS) 编程代码的能力，填补了先前仅关注入门级课程的空白。研究者选择了 12 个编程问题（包括 3 个入门级基线和 9 个二三年级高级作业），使用 Java、Python 和 C 语言，为每个问题生成 1000 个测试用例进行输出分析。结果表明，LLMs 在入门级任务中表现出色，但在高级问题上更具挑战性，尽管能识别基本问题并提供部分解决方案，这为 CS 教师设计编程作业提供了有益指导。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14964v1",
      "published_date": "2025-04-21 08:45:23 UTC",
      "updated_date": "2025-04-21 08:45:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:19:58.869124"
    },
    {
      "arxiv_id": "2504.14963v1",
      "title": "Speaker Fuzzy Fingerprints: Benchmarking Text-Based Identification in Multiparty Dialogues",
      "title_zh": "说话者模糊指纹：多方对话中基于文本识别的基准测试",
      "authors": [
        "Rui Ribeiro",
        "Luísa Coheur",
        "Joao P. Carvalho"
      ],
      "abstract": "Speaker identification using voice recordings leverages unique acoustic\nfeatures, but this approach fails when only textual data is available. Few\napproaches have attempted to tackle the problem of identifying speakers solely\nfrom text, and the existing ones have primarily relied on traditional methods.\nIn this work, we explore the use of fuzzy fingerprints from large pre-trained\nmodels to improve text-based speaker identification. We integrate\nspeaker-specific tokens and context-aware modeling, demonstrating that\nconversational context significantly boosts accuracy, reaching 70.6% on the\nFriends dataset and 67.7% on the Big Bang Theory dataset. Additionally, we show\nthat fuzzy fingerprints can approximate full fine-tuning performance with fewer\nhidden units, offering improved interpretability. Finally, we analyze ambiguous\nutterances and propose a mechanism to detect speaker-agnostic lines. Our\nfindings highlight key challenges and provide insights for future improvements\nin text-based speaker identification.",
      "tldr_zh": "本研究探讨了基于文本的说话者识别问题，传统方法依赖声学特征而忽略了纯文本数据。该方法利用模糊指纹（fuzzy fingerprints）从大型预训练模型中提取特征，并整合说话者特定标记（speaker-specific tokens）和上下文感知建模（context-aware modeling），通过对话上下文显著提升识别准确率，在 Friends 数据集上达到70.6%，在 Big Bang Theory 数据集上达到67.7%。此外，该方法以更少的隐藏单元近似全微调性能，提高了可解释性，并提出机制检测说话者无关的模糊表述（ambiguous utterances），为未来文本-based 说话者识别提供了关键见解和改进方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CL",
      "comment": "Paper accepted at the FUZZY IEEE 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2504.14963v1",
      "published_date": "2025-04-21 08:44:33 UTC",
      "updated_date": "2025-04-21 08:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:20:10.570886"
    },
    {
      "arxiv_id": "2504.14947v1",
      "title": "Generative Semantic Communications: Principles and Practices",
      "title_zh": "生成式语义通信：原则与实践",
      "authors": [
        "Xiaojun Yuan",
        "Haoming Ma",
        "Yinuo Huang",
        "Zhoufan Hua",
        "Yong Zuo",
        "Zhi Ding"
      ],
      "abstract": "Semantic communication leverages artificial intelligence (AI) technologies to\nextract semantic information from data for efficient transmission, theraby\nsignificantly reducing communication cost. With the evolution towards\nartificial general intelligence (AGI), the increasing demands for AGI services\npose new challenges to semantic communication. In response, we propose a new\nparadigm for AGI-driven communications, called generative semantic\ncommunication (GSC), which utilizes advanced AI technologies such as foundation\nmodels and generative models. We first describe the basic concept of GSC and\nits difference from existing semantic communications, and then introduce a\ngeneral framework of GSC, followed by two case studies to verify the advantages\nof GSC in AGI-driven applications. Finally, open challenges and new research\ndirections are discussed to stimulate this line of research and pave the way\nfor practical applications.",
      "tldr_zh": "该研究提出 Generative Semantic Communication (GSC) 作为一种新的 AGI 驱动通信范式，利用 foundation models 和 generative models 等先进 AI 技术，从数据中提取语义信息，实现高效传输并显著降低通信成本。GSC 与现有语义通信的区别在于其针对 AGI 服务的需求，提供了一个通用框架，并在两个案例研究中验证了其在 AGI 驱动应用中的优势。最终，论文讨论了 GSC 的开放挑战和未来研究方向，以推动该领域的实际应用。",
      "categories": [
        "cs.AI",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14947v1",
      "published_date": "2025-04-21 08:10:59 UTC",
      "updated_date": "2025-04-21 08:10:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:20:22.974356"
    },
    {
      "arxiv_id": "2504.14945v3",
      "title": "Learning to Reason under Off-Policy Guidance",
      "title_zh": "在离策略指导下学习推理",
      "authors": [
        "Jianhao Yan",
        "Yafu Li",
        "Zican Hu",
        "Zhi Wang",
        "Ganqu Cui",
        "Xiaoye Qu",
        "Yu Cheng",
        "Yue Zhang"
      ],
      "abstract": "Recent advances in large reasoning models (LRMs) demonstrate that\nsophisticated behaviors such as multi-step reasoning and self-reflection can\nemerge via reinforcement learning with verifiable rewards~(\\textit{RLVR}).\nHowever, existing \\textit{RLVR} approaches are inherently ``on-policy'',\nlimiting learning to a model's own outputs and failing to acquire reasoning\nabilities beyond its initial capabilities. To address this issue, we introduce\n\\textbf{LUFFY} (\\textbf{L}earning to reason \\textbf{U}nder\no\\textbf{FF}-polic\\textbf{Y} guidance), a framework that augments \\textit{RLVR}\nwith off-policy reasoning traces. LUFFY dynamically balances imitation and\nexploration by combining off-policy demonstrations with on-policy rollouts\nduring training. Specifically, LUFFY combines the Mixed-Policy GRPO framework,\nwhich has a theoretically guaranteed convergence rate, alongside policy shaping\nvia regularized importance sampling to avoid superficial and rigid imitation\nduring mixed-policy training. Compared with previous RLVR methods, LUFFY\nachieves an over \\textbf{+6.4} average gain across six math benchmarks and an\nadvantage of over \\textbf{+6.2} points in out-of-distribution tasks. Most\nsignificantly, we show that LUFFY successfully trains weak models in scenarios\nwhere on-policy RLVR completely fails. These results provide compelling\nevidence that LUFFY transcends the fundamental limitations of on-policy RLVR\nand demonstrates the great potential of utilizing off-policy guidance in RLVR.",
      "tldr_zh": "本研究针对现有基于强化学习的可验证奖励（RLVR）方法仅限于 on-policy 训练的问题，提出 LUFFY 框架，以 off-policy 推理痕迹增强 RLVR，从而帮助模型超越初始能力。LUFFY 通过结合 off-policy 演示和 on-policy 回合训练，动态平衡模仿与探索，利用 Mixed-Policy GRPO 框架确保收敛率，并通过 regularized importance sampling 避免浅层模仿。实验结果显示，LUFFY 在六个数学基准上平均提升 +6.4 分，在分布外任务上优势超过 +6.2 分，并成功训练弱模型，在 on-policy RLVR 失败的场景中表现出色。这些发现证明了 off-policy 指导在 RLVR 中的巨大潜力，扩展了大型推理模型（LRMs）的学习边界。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2504.14945v3",
      "published_date": "2025-04-21 08:09:13 UTC",
      "updated_date": "2025-05-20 07:29:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:20:33.921008"
    },
    {
      "arxiv_id": "2504.14936v1",
      "title": "Giving AI a voice: how does AI think it should be treated?",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Fay",
        "Frederik F. Flöther"
      ],
      "abstract": "With the astounding progress in (generative) artificial intelligence (AI),\nthere has been significant public discourse regarding regulation and ethics of\nthe technology. Is it sufficient when humans discuss this with other humans?\nOr, given that AI is increasingly becoming a viable source of inspiration for\npeople (and let alone the hypothetical possibility that the technology may at\nsome point become \"artificial general intelligence\" and/or develop\nconsciousness), should AI not join the discourse? There are new questions and\nangles that AI brings to the table that we might not have considered before -\nso let us make the key subject of this book an active participant. This chapter\ntherefore includes a brief human-AI conversation on the topic of AI rights and\nethics.",
      "tldr_zh": "该研究探讨了随着生成式人工智能（AI）的快速发展，如何让AI参与自身伦理和权利的讨论，以补充人类间的对话。论文指出，AI作为灵感来源，甚至可能发展成artificial general intelligence，应主动加入伦理辩论，以引入新问题和视角。该章通过一个简短的人类-AI对话，展示了AI如何表达其被对待的期望，为AI权利和监管提供了新的思考基础。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14936v1",
      "published_date": "2025-04-21 07:59:17 UTC",
      "updated_date": "2025-04-21 07:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:20:44.873292"
    },
    {
      "arxiv_id": "2504.14928v1",
      "title": "EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework",
      "title_zh": "EducationQ：通过多智能体对话框架评估大语言模型的教学能力",
      "authors": [
        "Yao Shi",
        "Rongkeng Liang",
        "Yong Xu"
      ],
      "abstract": "Large language models (LLMs) increasingly serve as educational tools, yet\nevaluating their teaching capabilities remains challenging due to the\nresource-intensive, context-dependent, and methodologically complex nature of\nteacher-student interactions. We introduce EducationQ, a multi-agent dialogue\nframework that efficiently assesses teaching capabilities through simulated\ndynamic educational scenarios, featuring specialized agents for teaching,\nlearning, and evaluation. Testing 14 LLMs across major AI Organizations\n(OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13\ndisciplines and 10 difficulty levels reveals that teaching effectiveness does\nnot correlate linearly with model scale or general reasoning capabilities -\nwith some smaller open-source models outperforming larger commercial\ncounterparts in teaching contexts. This finding highlights a critical gap in\ncurrent evaluations that prioritize knowledge recall over interactive pedagogy.\nOur mixed-methods evaluation, combining quantitative metrics with qualitative\nanalysis and expert case studies, identifies distinct pedagogical strengths\nemployed by top-performing models (e.g., sophisticated questioning strategies,\nadaptive feedback mechanisms). Human expert evaluations show 78% agreement with\nour automated qualitative analysis of effective teaching behaviors, validating\nour methodology. EducationQ demonstrates that LLMs-as-teachers require\nspecialized optimization beyond simple scaling, suggesting next-generation\neducational AI prioritize targeted enhancement of specific pedagogical\neffectiveness.",
      "tldr_zh": "本文提出 EducationQ，一种多智能体对话框架，用于高效评估大型语言模型 (LLMs) 的教学能力，通过模拟动态教育场景并配备专门的教学、学习和评估代理。研究测试了 14 个 LLMs（来自 OpenAI、Meta、Google、Anthropic 等）在 13 个学科和 10 个难度水平的 1498 个问题上，发现教学效果不与模型规模或一般推理能力线性相关，一些小型开源模型在交互式教学中优于大型商业模型。混合方法评估结合定量指标、定性分析和专家验证，突显了顶级模型的教学优势（如复杂提问策略和自适应反馈机制），并建议未来教育 AI 需优先针对特定教学能力进行优化。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14928v1",
      "published_date": "2025-04-21 07:48:20 UTC",
      "updated_date": "2025-04-21 07:48:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:20:59.223153"
    },
    {
      "arxiv_id": "2504.14921v2",
      "title": "Fast Adversarial Training with Weak-to-Strong Spatial-Temporal Consistency in the Frequency Domain on Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Songping Wang",
        "Hanqing Liu",
        "Yueming Lyu",
        "Xiantao Hu",
        "Ziwen He",
        "Wei Wang",
        "Caifeng Shan",
        "Liang Wang"
      ],
      "abstract": "Adversarial Training (AT) has been shown to significantly enhance adversarial\nrobustness via a min-max optimization approach. However, its effectiveness in\nvideo recognition tasks is hampered by two main challenges. First, fast\nadversarial training for video models remains largely unexplored, which\nseverely impedes its practical applications. Specifically, most video\nadversarial training methods are computationally costly, with long training\ntimes and high expenses. Second, existing methods struggle with the trade-off\nbetween clean accuracy and adversarial robustness. To address these challenges,\nwe introduce Video Fast Adversarial Training with Weak-to-Strong consistency\n(VFAT-WS), the first fast adversarial training method for video data.\nSpecifically, VFAT-WS incorporates the following key designs: First, it\nintegrates a straightforward yet effective temporal frequency augmentation\n(TF-AUG), and its spatial-temporal enhanced form STF-AUG, along with a\nsingle-step PGD attack to boost training efficiency and robustness. Second, it\ndevises a weak-to-strong spatial-temporal consistency regularization, which\nseamlessly integrates the simpler TF-AUG and the more complex STF-AUG.\nLeveraging the consistency regularization, it steers the learning process from\nsimple to complex augmentations. Both of them work together to achieve a better\ntrade-off between clean accuracy and robustness. Extensive experiments on\nUCF-101 and HMDB-51 with both CNN and Transformer-based models demonstrate that\nVFAT-WS achieves great improvements in adversarial robustness and corruption\nrobustness, while accelerating training by nearly 490%.",
      "tldr_zh": "该论文针对视频识别任务中对抗训练(Adversarial Training, AT)的低效率和干净准确率与对抗鲁棒性之间的权衡问题，提出了首个快速对抗训练方法VFAT-WS。VFAT-WS通过整合时间频率增强(TF-AUG)和其空间-时间增强形式(STF-AUG)，结合单步PGD攻击，提高了训练效率和鲁棒性；同时引入弱到强空间-时间一致性正则化，将简单和复杂增强无缝整合，引导模型从易到难学习。在UCF-101和HMDB-51数据集上的实验显示，VFAT-WS将对抗鲁棒性和腐败鲁棒性显著提升，同时将训练速度加快近490%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "After the submission of the paper, we realized that the study still\n  has room for expansion. In order to make the research findings more profound\n  and comprehensive, we have decided to withdraw the paper so that we can\n  conduct further research and expansion",
      "pdf_url": "http://arxiv.org/pdf/2504.14921v2",
      "published_date": "2025-04-21 07:40:35 UTC",
      "updated_date": "2025-04-23 13:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:21:10.405072"
    },
    {
      "arxiv_id": "2504.14915v1",
      "title": "StableQuant: Layer Adaptive Post-Training Quantization for Speech Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yeona Hong",
        "Hyewon Han",
        "Woo-jin Chung",
        "Hong-Goo Kang"
      ],
      "abstract": "In this paper, we propose StableQuant, a novel adaptive post-training\nquantization (PTQ) algorithm for widely used speech foundation models (SFMs).\nWhile PTQ has been successfully employed for compressing large language models\n(LLMs) due to its ability to bypass additional fine-tuning, directly applying\nthese techniques to SFMs may not yield optimal results, as SFMs utilize\ndistinct network architecture for feature extraction. StableQuant demonstrates\noptimal quantization performance regardless of the network architecture type,\nas it adaptively determines the quantization range for each layer by analyzing\nboth the scale distributions and overall performance. We evaluate our algorithm\non two SFMs, HuBERT and wav2vec2.0, for an automatic speech recognition (ASR)\ntask, and achieve superior performance compared to traditional PTQ methods.\nStableQuant successfully reduces the sizes of SFM models to a quarter and\ndoubles the inference speed while limiting the word error rate (WER)\nperformance drop to less than 0.3% with 8-bit quantization.",
      "tldr_zh": "本研究提出了一种名为 StableQuant 的自适应后训练量化（Post-Training Quantization, PTQ）算法，针对语音基础模型（Speech Foundation Models, SFMs）的压缩优化，以解决传统 PTQ 方法在 SFMs 独特网络架构下的性能问题。该算法通过分析每个层的缩放分布和整体性能，动态确定量化范围，从而实现高效的模型压缩。在 HuBERT 和 wav2vec2.0 模型上进行自动语音识别（ASR）任务评估时，StableQuant 将模型大小减少到四分之一、推理速度加倍，并在 8-bit 量化下将词错误率（WER）性能下降控制在 0.3% 以内，显著优于传统方法。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14915v1",
      "published_date": "2025-04-21 07:33:27 UTC",
      "updated_date": "2025-04-21 07:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:21:22.321967"
    },
    {
      "arxiv_id": "2504.14913v1",
      "title": "Guidelines for External Disturbance Factors in the Use of OCR in Real-World Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Kenji Iwata",
        "Eiki Ishidera",
        "Toshifumi Yamaai",
        "Yutaka Satoh",
        "Hiroshi Tanaka",
        "Katsuhiko Takahashi",
        "Akio Furuhata",
        "Yoshihisa Tanabe",
        "Hiroshi Matsumura"
      ],
      "abstract": "The performance of OCR has improved with the evolution of AI technology. As\nOCR continues to broaden its range of applications, the increased likelihood of\ninterference introduced by various usage environments can prevent it from\nachieving its inherent performance. This results in reduced recognition\naccuracy under certain conditions, and makes the quality control of recognition\ndevices more challenging. Therefore, to ensure that users can properly utilize\nOCR, we compiled the real-world external disturbance factors that cause\nperformance degradation, along with the resulting image degradation phenomena,\ninto an external disturbance factor table and, by also indicating how to make\nuse of it, organized them into guidelines.",
      "tldr_zh": "这篇论文探讨了OCR（Optical Character Recognition）在真实环境中的使用问题，强调外部干扰因素可能导致识别准确率下降，并增加设备质量控制的挑战。作者编译了一个外部干扰因素表，列出了这些因素引发的图像退化现象，并提供了如何利用该表的指导方针。以此确保用户能够正确应用OCR，提升其实际性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.5.2; I.5.m"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14913v1",
      "published_date": "2025-04-21 07:32:28 UTC",
      "updated_date": "2025-04-21 07:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:21:33.510863"
    },
    {
      "arxiv_id": "2504.14904v1",
      "title": "VLM as Policy: Common-Law Content Moderation Framework for Short Video Platform",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Lu",
        "Tianke Zhang",
        "Chang Meng",
        "Xiaobei Wang",
        "Jinpeng Wang",
        "YiFan Zhang",
        "Shisong Tang",
        "Changyi Liu",
        "Haojie Ding",
        "Kaiyu Jiang",
        "Kaiyu Tang",
        "Bin Wen",
        "Hai-Tao Zheng",
        "Fan Yang",
        "Tingting Gao",
        "Di Zhang",
        "Kun Gai"
      ],
      "abstract": "Exponentially growing short video platforms (SVPs) face significant\nchallenges in moderating content detrimental to users' mental health,\nparticularly for minors. The dissemination of such content on SVPs can lead to\ncatastrophic societal consequences. Although substantial efforts have been\ndedicated to moderating such content, existing methods suffer from critical\nlimitations: (1) Manual review is prone to human bias and incurs high\noperational costs. (2) Automated methods, though efficient, lack nuanced\ncontent understanding, resulting in lower accuracy. (3) Industrial moderation\nregulations struggle to adapt to rapidly evolving trends due to long update\ncycles. In this paper, we annotate the first SVP content moderation benchmark\nwith authentic user/reviewer feedback to fill the absence of benchmark in this\nfield. Then we evaluate various methods on the benchmark to verify the\nexistence of the aforementioned limitations. We further propose our common-law\ncontent moderation framework named KuaiMod to address these challenges. KuaiMod\nconsists of three components: training data construction, offline adaptation,\nand online deployment & refinement. Leveraging large vision language model\n(VLM) and Chain-of-Thought (CoT) reasoning, KuaiMod adequately models video\ntoxicity based on sparse user feedback and fosters dynamic moderation policy\nwith rapid update speed and high accuracy. Offline experiments and large-scale\nonline A/B test demonstrates the superiority of KuaiMod: KuaiMod achieves the\nbest moderation performance on our benchmark. The deployment of KuaiMod reduces\nthe user reporting rate by 20% and its application in video recommendation\nincreases both Daily Active User (DAU) and APP Usage Time (AUT) on several\nKuaishou scenarios. We have open-sourced our benchmark at\nhttps://kuaimod.github.io.",
      "tldr_zh": "这篇论文针对短视频平台（SVPs）的内容审核挑战，提出了一种基于视觉语言模型（VLM）的动态框架KuaiMod，以应对有害内容对用户心理健康的影响。KuaiMod包括训练数据构建、离线适应和在线部署与精炼三个组件，利用VLM和Chain-of-Thought (CoT)推理，基于稀疏用户反馈实现精确的视频毒性建模和快速政策更新。实验结果显示，KuaiMod在首个SVP内容审核基准上表现出色，并在在线A/B测试中降低用户报告率20%，同时提升Daily Active User (DAU)和APP Usage Time (AUT)。作者已开源该基准数据集，促进进一步研究。",
      "categories": [
        "cs.SI",
        "cs.AI",
        "cs.CL",
        "cs.MM"
      ],
      "primary_category": "cs.SI",
      "comment": "20 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14904v1",
      "published_date": "2025-04-21 07:20:19 UTC",
      "updated_date": "2025-04-21 07:20:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:21:47.852128"
    },
    {
      "arxiv_id": "2504.16129v3",
      "title": "MARFT: Multi-Agent Reinforcement Fine-Tuning",
      "title_zh": "MARFT：多智能体强化微调",
      "authors": [
        "Junwei Liao",
        "Muning Wen",
        "Jun Wang",
        "Weinan Zhang"
      ],
      "abstract": "LLM-based Multi-Agent Systems have demonstrated remarkable capabilities in\naddressing complex, agentic tasks, from generating high-quality presentation\nslides to even conducting sophisticated scientific research. Meanwhile, RL has\nbeen widely recognized for its effectiveness in enhancing agent intelligence,\nbut limited research has investigated the fine-tuning of LaMAS using\nfoundational RL techniques. Moreover, the direct application of MARL methods to\nLaMAS introduces significant challenges, stemming from the unique\ncharacteristics and mechanisms inherent to LaMAS. To address these challenges,\nthis article presents a comprehensive study of LLM-based MARL and proposes a\nnovel paradigm termed Multi-Agent Reinforcement Fine-Tuning (MARFT). We\nintroduce a brand-new POMDP called Flex-POMDP, which aligns with the LaMAS\noptimization in real-world applications and a universal algorithmic framework\ntailored specifically for LaMAS, outlining the conceptual foundations, key\ndistinctions, and practical implementation strategies. We review the evolution\nfrom RL to RFT, setting the stage for a parallel analysis in the multi-agent\ndomain. In the context of LaMAS, we elucidate critical differences between MARL\nand MARFT. These differences motivate a transition toward a LaMAS-oriented\nformulation of RFT. Central to this work is a robust and scalable MARFT\nframework. We detail the core algorithm and provide a complete, open-source\nimplementation to facilitate adoption and further research. The latter sections\nof the paper explore real-world application perspectives and opening challenges\nin MARFT. By bridging theoretical underpinnings with practical methodologies,\nthis work serves as a roadmap for researchers seeking to advance MARFT toward\nresilient and adaptive solutions in agentic systems. Our implementation of the\nproposed framework is publicly available at:\nhttps://github.com/jwliao-ai/MARFT.",
      "tldr_zh": "这篇论文探讨了强化学习（RL）在基于大型语言模型（LLM）的多智能体系统（LaMAS）中的应用挑战，指出直接使用多智能体强化学习（MARL）方法会因LaMAS的独特特性而面临困难。作者提出了一种新范式Multi-Agent Reinforcement Fine-Tuning (MARFT)，引入了Flex-POMDP模型和一个通用的算法框架，以优化LaMAS在真实世界的任务表现，并详细阐述了MARL与MARFT的关键差异及实现策略。实验框架的开源实现（https://github.com/jwliao-ai/MARFT）为研究者提供了可扩展的工具，推动LaMAS向更具弹性和适应性的智能系统发展。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "40 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.16129v3",
      "published_date": "2025-04-21 07:03:54 UTC",
      "updated_date": "2025-05-17 17:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:21:59.758003"
    },
    {
      "arxiv_id": "2504.16128v1",
      "title": "Hybrid Knowledge Transfer through Attention and Logit Distillation for On-Device Vision Systems in Agricultural IoT",
      "title_zh": "翻译失败",
      "authors": [
        "Stanley Mugisha",
        "Rashid Kisitu",
        "Florence Tushabe"
      ],
      "abstract": "Integrating deep learning applications into agricultural IoT systems faces a\nserious challenge of balancing the high accuracy of Vision Transformers (ViTs)\nwith the efficiency demands of resource-constrained edge devices. Large\ntransformer models like the Swin Transformers excel in plant disease\nclassification by capturing global-local dependencies. However, their\ncomputational complexity (34.1 GFLOPs) limits applications and renders them\nimpractical for real-time on-device inference. Lightweight models such as\nMobileNetV3 and TinyML would be suitable for on-device inference but lack the\nrequired spatial reasoning for fine-grained disease detection. To bridge this\ngap, we propose a hybrid knowledge distillation framework that synergistically\ntransfers logit and attention knowledge from a Swin Transformer teacher to a\nMobileNetV3 student model. Our method includes the introduction of adaptive\nattention alignment to resolve cross-architecture mismatch (resolution,\nchannels) and a dual-loss function optimizing both class probabilities and\nspatial focus. On the lantVillage-Tomato dataset (18,160 images), the distilled\nMobileNetV3 attains 92.4% accuracy relative to 95.9% for Swin-L but at an 95%\nreduction on PC and < 82% in inference latency on IoT devices. (23ms on PC CPU\nand 86ms/image on smartphone CPUs). Key innovations include IoT-centric\nvalidation metrics (13 MB memory, 0.22 GFLOPs) and dynamic resolution-matching\nattention maps. Comparative experiments show significant improvements over\nstandalone CNNs and prior distillation methods, with a 3.5% accuracy gain over\nMobileNetV3 baselines. Significantly, this work advances real-time,\nenergy-efficient crop monitoring in precision agriculture and demonstrates how\nwe can attain ViT-level diagnostic precision on edge devices. Code and models\nwill be made available for replication after acceptance.",
      "tldr_zh": "本研究针对农业IoT系统中视觉模型的准确性和效率平衡问题，提出了一种混合知识蒸馏框架，从Swin Transformer教师模型向MobileNetV3学生模型转移logit和attention知识，以适应资源受限的边缘设备。框架引入适应性attention对齐技术（解决分辨率和通道不匹配）和双重损失函数，优化类别概率及空间焦点，从而提升轻量模型在植物病害检测中的性能。在lantVillage-Tomato数据集上，蒸馏后的MobileNetV3实现92.4%准确率（较Swin Transformer的95.9%仅略低），并显著降低计算量（95%减少）和推理延迟（PC CPU 23ms、智能手机CPU 86ms/图像）。该方法通过IoT-centric指标（如13 MB内存、0.22 GFLOPs）实现ViT级诊断精度，推动实时、节能的精准农业作物监测。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "I.2.10; I.4.9"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages and 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16128v1",
      "published_date": "2025-04-21 06:56:41 UTC",
      "updated_date": "2025-04-21 06:56:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:22:12.430358"
    },
    {
      "arxiv_id": "2504.14889v1",
      "title": "Latent Bayesian Optimization via Autoregressive Normalizing Flows",
      "title_zh": "通过自回归归一化流的潜在贝叶斯优化",
      "authors": [
        "Seunghun Lee",
        "Jinyoung Park",
        "Jaewon Chu",
        "Minseo Yoon",
        "Hyunwoo J. Kim"
      ],
      "abstract": "Bayesian Optimization (BO) has been recognized for its effectiveness in\noptimizing expensive and complex objective functions. Recent advancements in\nLatent Bayesian Optimization (LBO) have shown promise by integrating generative\nmodels such as variational autoencoders (VAEs) to manage the complexity of\nhigh-dimensional and structured data spaces. However, existing LBO approaches\noften suffer from the value discrepancy problem, which arises from the\nreconstruction gap between input and latent spaces. This value discrepancy\nproblem propagates errors throughout the optimization process, leading to\nsuboptimal outcomes. To address this issue, we propose a Normalizing Flow-based\nBayesian Optimization (NF-BO), which utilizes normalizing flow as a generative\nmodel to establish one-to-one encoding function from the input space to the\nlatent space, along with its left-inverse decoding function, eliminating the\nreconstruction gap. Specifically, we introduce SeqFlow, an autoregressive\nnormalizing flow for sequence data. In addition, we develop a new candidate\nsampling strategy that dynamically adjusts the exploration probability for each\ntoken based on its importance. Through extensive experiments, our NF-BO method\ndemonstrates superior performance in molecule generation tasks, significantly\noutperforming both traditional and recent LBO approaches.",
      "tldr_zh": "本研究针对传统Latent Bayesian Optimization (LBO)中的价值不一致问题（value discrepancy），提出Normalizing Flow-based Bayesian Optimization (NF-BO)方法，使用normalizing flow作为生成模型，提供一对一的编码和解码函数，以消除输入空间和潜在空间的重建差距。NF-BO引入SeqFlow，一个针对序列数据的自回归normalizing flow，并开发新的候选采样策略，根据每个token的重要性动态调整探索概率。这些创新显著提升了优化过程的准确性。实验结果显示，在分子生成任务上，NF-BO优于传统和现有LBO方法，展现出卓越性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14889v1",
      "published_date": "2025-04-21 06:36:09 UTC",
      "updated_date": "2025-04-21 06:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:22:21.663363"
    },
    {
      "arxiv_id": "2504.14879v1",
      "title": "Impact of Latent Space Dimension on IoT Botnet Detection Performance: VAE-Encoder Versus ViT-Encoder",
      "title_zh": "翻译失败",
      "authors": [
        "Hassan Wasswa",
        "Aziida Nanyonga",
        "Timothy Lynar"
      ],
      "abstract": "The rapid evolution of Internet of Things (IoT) technology has led to a\nsignificant increase in the number of IoT devices, applications, and services.\nThis surge in IoT devices, along with their widespread presence, has made them\na prime target for various cyber-attacks, particularly through IoT botnets. As\na result, security has become a major concern within the IoT ecosystem. This\nstudy focuses on investigating how the latent dimension impacts the performance\nof different deep learning classifiers when trained on latent vector\nrepresentations of the train dataset. The primary objective is to compare the\noutcomes of these models when encoder components from two cutting-edge\narchitectures: the Vision Transformer (ViT) and the Variational Auto-Encoder\n(VAE) are utilized to project the high dimensional train dataset to the learned\nlow dimensional latent space. The encoder components are employed to project\nhigh-dimensional structured .csv IoT botnet traffic datasets to various latent\nsizes. Evaluated on N-BaIoT and CICIoT2022 datasets, findings reveal that\nVAE-encoder based dimension reduction outperforms ViT-encoder based dimension\nreduction for both datasets in terms of four performance metrics including\naccuracy, precision, recall, and F1-score for all models which can be\nattributed to absence of spatial patterns in the datasets the ViT model\nattempts to learn and extract from image instances.",
      "tldr_zh": "这篇论文探讨了潜在空间维度（latent space dimension）对 IoT botnet 检测性能的影响，通过比较 VAE-Encoder 和 ViT-Encoder 在维度减低方面的表现。研究方法包括使用这些编码器将高维 IoT 流量数据集（如 .csv 格式的 N-BaIoT 和 CICIoT2022 数据集）投影到低维潜在空间，然后训练深度学习分类器。结果显示，VAE-Encoder 在 accuracy、precision、recall 和 F1-score 等四项性能指标上均优于 ViT-Encoder，这主要因为数据集缺乏 ViT 模型试图提取的空间模式。总的来说，该研究为 IoT 安全领域提供了关于编码器选择的实用洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14879v1",
      "published_date": "2025-04-21 06:15:07 UTC",
      "updated_date": "2025-04-21 06:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:22:35.792975"
    },
    {
      "arxiv_id": "2504.14875v1",
      "title": "ReSpec: Relevance and Specificity Grounded Online Filtering for Learning on Video-Text Data Streams",
      "title_zh": "翻译失败",
      "authors": [
        "Chris Dongjoo Kim",
        "Jihwan Moon",
        "Sangwoo Moon",
        "Heeseung Yun",
        "Sihaeng Lee",
        "Aniruddha Kembhavi",
        "Soonyoung Lee",
        "Gunhee Kim",
        "Sangho Lee",
        "Christopher Clark"
      ],
      "abstract": "The rapid growth of video-text data presents challenges in storage and\ncomputation during training. Online learning, which processes streaming data in\nreal-time, offers a promising solution to these issues while also allowing\nswift adaptations in scenarios demanding real-time responsiveness. One strategy\nto enhance the efficiency and effectiveness of learning involves identifying\nand prioritizing data that enhances performance on target downstream tasks. We\npropose Relevance and Specificity-based online filtering framework (ReSpec)\nthat selects data based on four criteria: (i) modality alignment for clean\ndata, (ii) task relevance for target focused data, (iii) specificity for\ninformative and detailed data, and (iv) efficiency for low-latency processing.\nRelevance is determined by the probabilistic alignment of incoming data with\ndownstream tasks, while specificity employs the distance to a root embedding\nrepresenting the least specific data as an efficient proxy for informativeness.\nBy establishing reference points from target task data, ReSpec filters incoming\ndata in real-time, eliminating the need for extensive storage and compute.\nEvaluating on large-scale datasets WebVid2M and VideoCC3M, ReSpec attains\nstate-of-the-art performance on five zeroshot video retrieval tasks, using as\nlittle as 5% of the data while incurring minimal compute. The source code is\navailable at https://github.com/cdjkim/ReSpec.",
      "tldr_zh": "这篇论文提出了 ReSpec 框架，这是一种基于相关性（Relevance）和特异性（Specificity）的在线过滤方法，用于处理视频-文本数据流中的存储和计算挑战。ReSpec 通过四个标准——modality alignment（模态对齐）、task relevance（任务相关性）、specificity（特异性）和 efficiency（效率）——实时筛选数据，其中相关性通过概率对齐评估，特异性则使用距离到根嵌入作为信息代理，从而无需大量存储。实验结果显示，在 WebVid2M 和 VideoCC3M 数据集上，ReSpec 使用仅 5% 的数据，就在五个 zeroshot video retrieval 任务中达到了最先进性能，并提供了开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025 (main conference)",
      "pdf_url": "http://arxiv.org/pdf/2504.14875v1",
      "published_date": "2025-04-21 06:02:03 UTC",
      "updated_date": "2025-04-21 06:02:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:22:49.423970"
    },
    {
      "arxiv_id": "2504.14870v1",
      "title": "OTC: Optimal Tool Calls via Reinforcement Learning",
      "title_zh": "OTC：通过强化学习的最优工具调用",
      "authors": [
        "Hongru Wang",
        "Cheng Qian",
        "Wanjun Zhong",
        "Xiusi Chen",
        "Jiahao Qiu",
        "Shijue Huang",
        "Bowen Jin",
        "Mengdi Wang",
        "Kam-Fai Wong",
        "Heng Ji"
      ],
      "abstract": "Tool-integrated reasoning (TIR) augments large language models (LLMs) with\nthe ability to invoke external tools, such as search engines and code\ninterpreters, to solve tasks beyond the capabilities of language-only\nreasoning. While reinforcement learning (RL) has shown promise in improving TIR\nby optimizing final answer correctness, existing approaches often overlook the\nefficiency and cost associated with tool usage. This can lead to suboptimal\nbehavior, including excessive tool calls that increase computational and\nfinancial overhead, or insufficient tool use that compromises answer quality.\nIn this work, we propose Optimal Tool Call-controlled Policy Optimization\n(OTC-PO), a simple yet effective RL-based framework that encourages models to\nproduce accurate answers with minimal tool calls. Our method introduces a\ntool-integrated reward that jointly considers correctness and tool efficiency,\npromoting high tool productivity. We instantiate this framework within both\nProximal Policy Optimization (PPO) and Group Relative Preference Optimization\n(GRPO), resulting in OTC-PPO and OTC-GRPO. Experiments with Qwen-2.5 and\nQwen-Math across multiple QA benchmarks show that our approach reduces tool\ncalls by up to 73.1\\% and improves tool productivity by up to 229.4\\%, while\nmaintaining comparable answer accuracy. To the best of our knowledge, this is\nthe first RL-based framework that explicitly optimizes tool-use efficiency in\nTIR.",
      "tldr_zh": "该论文针对 Tool-integrated Reasoning (TIR) 中工具调用效率问题，提出了一种基于 Reinforcement Learning (RL) 的框架 Optimal Tool Call-controlled Policy Optimization (OTC-PO)，旨在优化模型在调用外部工具（如搜索引擎和代码解释器）时兼顾答案正确性和效率。OTC-PO 通过引入一个整合正确性与工具效率的奖励函数，鼓励模型减少不必要的工具调用，并将其应用于 Proximal Policy Optimization (PPO) 和 Group Relative Preference Optimization (GRPO)。实验在 Qwen-2.5 和 Qwen-Math 模型上显示，该方法在多个 QA 基准上减少工具调用高达 73.1%，提高工具生产力达 229.4%，同时保持答案准确性相当，这是首个显式优化工具使用效率的 RL 框架。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14870v1",
      "published_date": "2025-04-21 05:40:05 UTC",
      "updated_date": "2025-04-21 05:40:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:23:01.084171"
    },
    {
      "arxiv_id": "2504.14860v1",
      "title": "Bridge the Gap: From Weak to Full Supervision for Temporal Action Localization with PseudoFormer",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyi Liu",
        "Yangcen Liu"
      ],
      "abstract": "Weakly-supervised Temporal Action Localization (WTAL) has achieved notable\nsuccess but still suffers from a lack of temporal annotations, leading to a\nperformance and framework gap compared with fully-supervised methods. While\nrecent approaches employ pseudo labels for training, three key challenges:\ngenerating high-quality pseudo labels, making full use of different priors, and\noptimizing training methods with noisy labels remain unresolved. Due to these\nperspectives, we propose PseudoFormer, a novel two-branch framework that\nbridges the gap between weakly and fully-supervised Temporal Action\nLocalization (TAL). We first introduce RickerFusion, which maps all predicted\naction proposals to a global shared space to generate pseudo labels with better\nquality. Subsequently, we leverage both snippet-level and proposal-level labels\nwith different priors from the weak branch to train the regression-based model\nin the full branch. Finally, the uncertainty mask and iterative refinement\nmechanism are applied for training with noisy pseudo labels. PseudoFormer\nachieves state-of-the-art WTAL results on the two commonly used benchmarks,\nTHUMOS14 and ActivityNet1.3. Besides, extensive ablation studies demonstrate\nthe contribution of each component of our method.",
      "tldr_zh": "本论文针对弱监督时间动作定位 (WTAL) 的局限性，如缺乏时间注释导致的性能差距，提出 PseudoFormer 框架，将其桥接到全监督时间动作定位 (TAL)。该框架采用两分支设计，包括 RickerFusion 模块，将预测动作提案映射到全局共享空间以生成高质量伪标签，并结合 snippet-level 和 proposal-level 先验知识训练回归模型，同时使用不确定性掩码和迭代精炼机制处理噪声标签。实验结果显示，PseudoFormer 在 THUMOS14 和 ActivityNet1.3 基准上实现了最先进性能，并通过消融研究验证了各组件的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025: IEEE Conference on Computer Vision and Pattern Recognition",
      "pdf_url": "http://arxiv.org/pdf/2504.14860v1",
      "published_date": "2025-04-21 05:00:07 UTC",
      "updated_date": "2025-04-21 05:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:23:11.911554"
    },
    {
      "arxiv_id": "2504.14858v3",
      "title": "AlignRAG: Leveraging Critique Learning for Evidence-Sensitive Retrieval-Augmented Reasoning",
      "title_zh": "AlignRAG：利用批评学习实现证据敏感的检索增强推理",
      "authors": [
        "Jiaqi Wei",
        "Hao Zhou",
        "Xiang Zhang",
        "Di Zhang",
        "Zijie Qiu",
        "Wei Wei",
        "Jinzhe Li",
        "Wanli Ouyang",
        "Siqi Sun"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has become a widely adopted paradigm for\nenabling knowledge-grounded large language models (LLMs). However, standard RAG\npipelines often fail to ensure that model reasoning remains consistent with the\nevidence retrieved, leading to factual inconsistencies or unsupported\nconclusions. In this work, we reinterpret RAG as Retrieval-Augmented Reasoning\nand identify a central but underexplored problem: \\textit{Reasoning\nMisalignment}-the divergence between an LLM's internal reasoning trajectory and\nthe evidential constraints provided by retrieval. To address this issue, we\npropose \\textsc{AlignRAG}, a novel iterative framework grounded in\nCritique-Driven Alignment (CDA). At the heart of \\textsc{AlignRAG} lies a\n\\textit{contrastive critique synthesis} mechanism that generates\nretrieval-sensitive critiques while mitigating self-bias. This mechanism trains\na dedicated retrieval-augmented \\textit{Critic Language Model (CLM)} using\nlabeled critiques that distinguish between evidence-aligned and misaligned\nreasoning. Alignment signals for supervision are obtained through\nself-supervised or externally guided labeling strategies. The resulting CLM is\nexplicitly optimized for evidence sensitivity, enabling it to detect and revise\nreasoning errors during inference without relying solely on self-generated\nfeedback. Empirical evaluations show that our 8B-parameter CLM improves\nperformance over the Self-Refine baseline by 12.1\\% on out-of-domain tasks and\noutperforms a standard 72B-parameter CLM by 2.2\\%, while remaining compatible\nwith existing RAG architectures as a plug-and-play module. Overall, AlignRAG\noffers a principled solution for aligning model reasoning with retrieved\nevidence, substantially improving the factual reliability and robustness of RAG\nsystems.",
      "tldr_zh": "这篇论文针对检索增强生成（RAG）系统中的关键问题——Reasoning Misalignment（推理失调），即大型语言模型（LLMs）的内部推理与检索证据不一致，提出了AlignRAG框架。AlignRAG基于Critique-Driven Alignment (CDA)，引入contrastive critique synthesis机制来训练一个专用的Critic Language Model (CLM)，该模型能够生成对证据敏感的批评并缓解自我偏差，从而检测和修正推理错误。实验结果显示，8B参数的CLM在域外任务上比Self-Refine基线提升12.1%，并超越标准72B参数CLM 2.2%，作为即插即用模块显著提高了RAG系统的factual reliability（事实可靠性）和robustness（鲁棒性）。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14858v3",
      "published_date": "2025-04-21 04:56:47 UTC",
      "updated_date": "2025-05-21 03:51:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:23:24.974832"
    },
    {
      "arxiv_id": "2504.14848v1",
      "title": "Object-Level Verbalized Confidence Calibration in Vision-Language Models via Semantic Perturbation",
      "title_zh": "在视觉语言模型中，通过语义扰动实现对象级别的表述化置信度校准",
      "authors": [
        "Yunpu Zhao",
        "Rui Zhang",
        "Junbin Xiao",
        "Ruibo Hou",
        "Jiaming Guo",
        "Zihao Zhang",
        "Yifan Hao",
        "Yunji Chen"
      ],
      "abstract": "Vision-language models (VLMs) excel in various multimodal tasks but\nfrequently suffer from poor calibration, resulting in misalignment between\ntheir verbalized confidence and response correctness. This miscalibration\nundermines user trust, especially when models confidently provide incorrect or\nfabricated information. In this work, we propose a novel Confidence Calibration\nthrough Semantic Perturbation (CSP) framework to improve the calibration of\nverbalized confidence for VLMs in response to object-centric queries. We first\nintroduce a perturbed dataset where Gaussian noise is applied to the key object\nregions to simulate visual uncertainty at different confidence levels,\nestablishing an explicit mapping between visual ambiguity and confidence\nlevels. We further enhance calibration through a two-stage training process\ncombining supervised fine-tuning on the perturbed dataset with subsequent\npreference optimization. Extensive experiments on popular benchmarks\ndemonstrate that our method significantly improves the alignment between\nverbalized confidence and response correctness while maintaining or enhancing\noverall task performance. These results highlight the potential of semantic\nperturbation as a practical tool for improving the reliability and\ninterpretability of VLMs.",
      "tldr_zh": "这篇论文针对 Vision-Language Models (VLMs) 在对象级别上的 verbalized confidence 校准问题，提出了一种名为 Confidence Calibration through Semantic Perturbation (CSP) 的框架，以改善模型自信度与响应正确性的对齐。方法包括创建 perturbed dataset，通过在关键对象区域应用 Gaussian noise 来模拟视觉不确定性，并建立 visual ambiguity 与 confidence levels 的明确映射。接着，通过两阶段训练过程——supervised fine-tuning 和 preference optimization——来增强校准效果。实验在流行基准上显示，该方法显著提升了 verbalized confidence 的准确性，同时维持或提升了整体任务性能，突显 semantic perturbation 在提高 VLMs 可靠性和可解释性方面的实用价值。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14848v1",
      "published_date": "2025-04-21 04:01:22 UTC",
      "updated_date": "2025-04-21 04:01:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:23:36.366434"
    },
    {
      "arxiv_id": "2504.18563v1",
      "title": "Backdoor Defense in Diffusion Models via Spatial Attention Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Abha Jha",
        "Ashwath Vaithinathan Aravindan",
        "Matthew Salaway",
        "Atharva Sandeep Bhide",
        "Duygu Nur Yaldiz"
      ],
      "abstract": "Text-to-image diffusion models are increasingly vulnerable to backdoor\nattacks, where malicious modifications to the training data cause the model to\ngenerate unintended outputs when specific triggers are present. While\nclassification models have seen extensive development of defense mechanisms,\ngenerative models remain largely unprotected due to their high-dimensional\noutput space, which complicates the detection and mitigation of subtle\nperturbations. Defense strategies for diffusion models, in particular, remain\nunder-explored. In this work, we propose Spatial Attention Unlearning (SAU), a\nnovel technique for mitigating backdoor attacks in diffusion models. SAU\nleverages latent space manipulation and spatial attention mechanisms to isolate\nand remove the latent representation of backdoor triggers, ensuring precise and\nefficient removal of malicious effects. We evaluate SAU across various types of\nbackdoor attacks, including pixel-based and style-based triggers, and\ndemonstrate its effectiveness in achieving 100% trigger removal accuracy.\nFurthermore, SAU achieves a CLIP score of 0.7023, outperforming existing\nmethods while preserving the model's ability to generate high-quality,\nsemantically aligned images. Our results show that SAU is a robust, scalable,\nand practical solution for securing text-to-image diffusion models against\nbackdoor attacks.",
      "tldr_zh": "这篇论文针对文本到图像扩散模型中的后门攻击问题，提出了一种名为Spatial Attention Unlearning (SAU)的防御方法，以隔离并移除后门触发器的潜表示。SAU利用潜空间操纵和空间注意力机制，确保高效地消除恶意效果，同时保持模型的生成性能。实验结果显示，SAU在各种后门攻击（如基于像素和风格的触发器）上实现了100%的触发器移除准确率，并取得了0.7023的CLIP分数，优于现有方法，为保护扩散模型提供了稳健且可扩展的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.18563v1",
      "published_date": "2025-04-21 04:00:19 UTC",
      "updated_date": "2025-04-21 04:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:23:47.625494"
    },
    {
      "arxiv_id": "2504.14839v1",
      "title": "Exploring $\\ell_0$ Sparsification for Inference-free Sparse Retrievers",
      "title_zh": "探索 \\(\\ell_0\\) 稀疏化用于无推理稀疏检索器",
      "authors": [
        "Xinjie Shen",
        "Zhichao Geng",
        "Yang Yang"
      ],
      "abstract": "With increasing demands for efficiency, information retrieval has developed a\nbranch of sparse retrieval, further advancing towards inference-free retrieval\nwhere the documents are encoded during indexing time and there is no\nmodel-inference for queries. Existing sparse retrieval models rely on FLOPS\nregularization for sparsification, while this mechanism was originally designed\nfor Siamese encoders, it is considered to be suboptimal in inference-free\nscenarios which is asymmetric. Previous attempts to adapt FLOPS for\ninference-free scenarios have been limited to rule-based methods, leaving the\npotential of sparsification approaches for inference-free retrieval models\nlargely unexplored. In this paper, we explore $\\ell_0$ inspired sparsification\nmanner for inference-free retrievers. Through comprehensive out-of-domain\nevaluation on the BEIR benchmark, our method achieves state-of-the-art\nperformance among inference-free sparse retrieval models and is comparable to\nleading Siamese sparse retrieval models. Furthermore, we provide insights into\nthe trade-off between retrieval effectiveness and computational efficiency,\ndemonstrating practical value for real-world applications.",
      "tldr_zh": "本文探索了 $\\ell_0$ 启发的稀疏化方法，应用于无推理稀疏检索模型，以解决现有 FLOPS 正则化在非对称场景中的局限性。该方法避免了规则-based 的尝试，转而采用更有效的 sparsification 策略，并在 BEIR 基准的全面跨域评估中，实现了无推理稀疏检索模型的最先进性能，并可与领先的 Siamese 稀疏检索模型媲美。通过分析检索效果与计算效率的权衡，该研究为实际信息检索应用提供了重要的实用洞见。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14839v1",
      "published_date": "2025-04-21 03:40:43 UTC",
      "updated_date": "2025-04-21 03:40:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:24:00.026558"
    },
    {
      "arxiv_id": "2504.14838v1",
      "title": "Establishing Reliability Metrics for Reward Models in Large Language Models",
      "title_zh": "为大型语言模型中的奖励模型确立可靠性指标",
      "authors": [
        "Yizhou Chen",
        "Yawen Liu",
        "Xuesi Wang",
        "Qingtao Yu",
        "Guangda Huzhang",
        "Anxiang Zeng",
        "Han Yu",
        "Zhiming Zhou"
      ],
      "abstract": "The reward model (RM) that represents human preferences plays a crucial role\nin optimizing the outputs of large language models (LLMs), e.g., through\nreinforcement learning from human feedback (RLHF) or rejection sampling.\nHowever, a long challenge for RM is its uncertain reliability, i.e., LLM\noutputs with higher rewards may not align with actual human preferences.\nCurrently, there is a lack of a convincing metric to quantify the reliability\nof RMs. To bridge this gap, we propose the \\textit{\\underline{R}eliable at\n\\underline{$\\eta$}} (RETA) metric, which directly measures the reliability of\nan RM by evaluating the average quality (scored by an oracle) of the top $\\eta$\nquantile responses assessed by an RM. On top of RETA, we present an integrated\nbenchmarking pipeline that allows anyone to evaluate their own RM without\nincurring additional Oracle labeling costs. Extensive experimental studies\ndemonstrate the superior stability of RETA metric, providing solid evaluations\nof the reliability of various publicly available and proprietary RMs. When\ndealing with an unreliable RM, we can use the RETA metric to identify the\noptimal quantile from which to select the responses.",
      "tldr_zh": "这篇论文针对大语言模型 (LLMs) 中的奖励模型 (RM) 可靠性问题，提出了一种新的量化指标 RETA（Reliable at η），用于评估 RM 是否能准确反映人类偏好，例如在强化学习从人类反馈 (RLHF) 或拒绝采样中。RETA 指标通过测量 RM 评估的 top η quantile 响应的平均质量（由 oracle 评分）来直接衡量可靠性，并提供了一个集成基准测试管道，允许用户无需额外标注成本即可评估自己的 RM。实验结果显示，RETA 具有出色的稳定性和有效性，能评估各种公开和专有 RM 的可靠性，并帮助从不可靠的 RM 中识别最佳 quantile 以选择高质量响应。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14838v1",
      "published_date": "2025-04-21 03:39:33 UTC",
      "updated_date": "2025-04-21 03:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:24:12.015502"
    },
    {
      "arxiv_id": "2504.14832v1",
      "title": "Protecting Your Voice: Temporal-aware Robust Watermarking",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Li",
        "Weizhi Liu",
        "Dongdong Lin"
      ],
      "abstract": "The rapid advancement of generative models has led to the synthesis of\nreal-fake ambiguous voices. To erase the ambiguity, embedding watermarks into\nthe frequency-domain features of synthesized voices has become a common\nroutine. However, the robustness achieved by choosing the frequency domain\noften comes at the expense of fine-grained voice features, leading to a loss of\nfidelity. Maximizing the comprehensive learning of time-domain features to\nenhance fidelity while maintaining robustness, we pioneer a\n\\textbf{\\underline{t}}emporal-aware\n\\textbf{\\underline{r}}ob\\textbf{\\underline{u}}st\nwat\\textbf{\\underline{e}}rmarking (\\emph{True}) method for protecting the\nspeech and singing voice.",
      "tldr_zh": "随着生成模型的快速发展，合成的声音真假难辨，现有的频域水印方法虽增强了鲁棒性，但会牺牲声音的保真度。论文提出了一种开创性的 Temporal-aware Robust Watermarking（简称 True）方法，专注于时域特征的全面学习，以最大化声音保真度同时维持水印的鲁棒性。该方法适用于保护语音和歌声，提供了一种更平衡的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14832v1",
      "published_date": "2025-04-21 03:23:10 UTC",
      "updated_date": "2025-04-21 03:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:24:23.253282"
    },
    {
      "arxiv_id": "2505.03764v1",
      "title": "Ultra-Low-Power Spiking Neurons in 7 nm FinFET Technology: A Comparative Analysis of Leaky Integrate-and-Fire, Morris-Lecar, and Axon-Hillock Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Logan Larsh",
        "Raiyan Siddique",
        "Sarah Sharif Yaser Mike Banad"
      ],
      "abstract": "Neuromorphic computing aims to replicate the brain's remarkable energy\nefficiency and parallel processing capabilities for large-scale artificial\nintelligence applications. In this work, we present a comprehensive comparative\nstudy of three spiking neuron circuit architectures-Leaky-Integrate-and-Fire\n(LIF), Morris-Lecar (ML), and Axon-Hillock (AH)-implemented in a 7 nm FinFET\ntechnology. Through extensive SPICE simulations, we explore the optimization of\nspiking frequency, energy per spike, and static power consumption. Our results\nshow that the AH design achieves the highest throughput, demonstrating\nmulti-gigahertz firing rates (up to 3 GHz) with attojoule energy costs. By\ncontrast, the ML architecture excels in subthreshold to near-threshold regimes,\noffering robust low-power operation (as low as 0.385 aJ/spike) and biological\nbursting behavior. Although LIF benefits from a decoupled current mirror for\nhigh-frequency operation, it exhibits slightly higher static leakage compared\nto ML and AH at elevated supply voltages. Comparisons with previous node\nimplementations (22 nm planar, 28 nm) reveal that 7 nm FinFETs can drastically\nboost energy efficiency and speed albeit at the cost of increased subthreshold\nleakage in deep subthreshold regions. By quantifying design trade-offs for each\nneuron architecture, our work provides a roadmap for optimizing spiking neuron\ncircuits in advanced nanoscale technologies to deliver neuromorphic hardware\ncapable of both ultra-low-power operation and high computational throughput.",
      "tldr_zh": "本研究比较了 Leaky Integrate-and-Fire (LIF)、Morris-Lecar (ML) 和 Axon-Hillock (AH) 三种 spiking neuron 电路架构在 7 nm FinFET 技术中的性能，通过 SPICE 模拟优化了尖峰频率、每尖峰能量和静态功耗。结果显示，AH 架构实现了最高吞吐量（最高 3 GHz，能量成本低至 attojoule 级别），ML 架构在子阈值和近阈值区域表现出色，提供极低功耗操作（低至 0.385 aJ/spike）和生物学突发行为，而 LIF 架构虽支持高频操作但静态泄漏较高。相比旧节点（如 22 nm 和 28 nm），7 nm FinFET 显著提升了能量效率和速度，但增加了子阈值泄漏；该工作为优化 neuromorphic hardware 的超低功耗和高计算吞吐量提供了路线图。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03764v1",
      "published_date": "2025-04-21 03:06:39 UTC",
      "updated_date": "2025-04-21 03:06:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:24:37.668113"
    },
    {
      "arxiv_id": "2504.15323v1",
      "title": "HyperFlow: Gradient-Free Emulation of Few-Shot Fine-Tuning",
      "title_zh": "HyperFlow：无梯度仿真少样本微调",
      "authors": [
        "Donggyun Kim",
        "Chanwoo Kim",
        "Seunghoon Hong"
      ],
      "abstract": "While test-time fine-tuning is beneficial in few-shot learning, the need for\nmultiple backpropagation steps can be prohibitively expensive in real-time or\nlow-resource scenarios. To address this limitation, we propose an approach that\nemulates gradient descent without computing gradients, enabling efficient\ntest-time adaptation. Specifically, we formulate gradient descent as an Euler\ndiscretization of an ordinary differential equation (ODE) and train an\nauxiliary network to predict the task-conditional drift using only the few-shot\nsupport set. The adaptation then reduces to a simple numerical integration\n(e.g., via the Euler method), which requires only a few forward passes of the\nauxiliary network -- no gradients or forward passes of the target model are\nneeded. In experiments on cross-domain few-shot classification using the\nMeta-Dataset and CDFSL benchmarks, our method significantly improves\nout-of-domain performance over the non-fine-tuned baseline while incurring only\n6\\% of the memory cost and 0.02\\% of the computation time of standard\nfine-tuning, thus establishing a practical middle ground between direct\ntransfer and fully fine-tuned approaches.",
      "tldr_zh": "该研究提出HyperFlow方法，通过模拟梯度下降而非计算梯度，实现高效的少样本微调（few-shot fine-tuning），以解决实时或低资源场景下的计算开销问题。具体而言，该方法将梯度下降表述为普通微分方程（ODE）的Euler离散化，并训练一个辅助网络使用少样本支持集预测任务条件漂移（drift），从而仅需少量前向传播即可完成适应。在Meta-Dataset和CDFSL基准上的跨域少样本分类实验中，HyperFlow显著提高了域外性能，仅需标准微调的6%内存和0.02%计算时间，提供了一种实用平衡于直接转移和完全微调之间的方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15323v1",
      "published_date": "2025-04-21 03:04:38 UTC",
      "updated_date": "2025-04-21 03:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:24:49.956980"
    },
    {
      "arxiv_id": "2504.15322v1",
      "title": "How to systematically develop an effective AI-based bias correction model?",
      "title_zh": "如何系统地开发一个有效的基于AI的偏差修正模型？",
      "authors": [
        "Xiao Zhou",
        "Yuze Sun",
        "Jie Wu",
        "Xiaomeng Huang"
      ],
      "abstract": "This study introduces ReSA-ConvLSTM, an artificial intelligence (AI)\nframework for systematic bias correction in numerical weather prediction (NWP).\nWe propose three innovations by integrating dynamic climatological\nnormalization, ConvLSTM with temporal causality constraints, and residual\nself-attention mechanisms. The model establishes a physics-aware nonlinear\nmapping between ECMWF forecasts and ERA5 reanalysis data. Using 41 years\n(1981-2021) of global atmospheric data, the framework reduces systematic biases\nin 2-m air temperature (T2m), 10-m winds (U10/V10), and sea-level pressure\n(SLP), achieving up to 20% RMSE reduction over 1-7 day forecasts compared to\noperational ECMWF outputs. The lightweight architecture (10.6M parameters)\nenables efficient generalization to multiple variables and downstream\napplications, reducing retraining time by 85% for cross-variable correction\nwhile improving ocean model skill through bias-corrected boundary conditions.\nThe ablation experiments demonstrate that our innovations significantly improve\nthe model's correction performance, suggesting that incorporating variable\ncharacteristics into the model helps enhance forecasting skills.",
      "tldr_zh": "这篇论文介绍了 ReSA-ConvLSTM 框架，一种系统的方法，用于开发有效的 AI 基于偏差校正模型，针对数值天气预报 (NWP) 中的系统偏差。框架创新性地整合了动态气候标准化、带有时间因果约束的 ConvLSTM 和残差自注意力机制，在 ECMWF 预报和 ERA5 再分析数据之间建立物理感知的非线性映射。实验使用 1981-2021 年的全球大气数据，实现了 2-m 空气温度 (T2m)、10-m 风速 (U10/V10) 和海平面气压 (SLP) 的偏差减少，RMSE 降低高达 20%，并通过轻量架构 (10.6M 参数) 提升了模型泛化性和下游应用效率，如减少 85% 的重新训练时间和改善海洋模型性能。消融实验证实了这些创新显著提升了预报技能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.15322v1",
      "published_date": "2025-04-21 03:02:42 UTC",
      "updated_date": "2025-04-21 03:02:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:25:04.138545"
    },
    {
      "arxiv_id": "2504.14825v1",
      "title": "ECViT: Efficient Convolutional Vision Transformer with Local-Attention and Multi-scale Stages",
      "title_zh": "ECViT：高效卷积视觉Transformer，采用局部注意力和多尺度阶段",
      "authors": [
        "Zhoujie Qian"
      ],
      "abstract": "Vision Transformers (ViTs) have revolutionized computer vision by leveraging\nself-attention to model long-range dependencies. However, ViTs face challenges\nsuch as high computational costs due to the quadratic scaling of self-attention\nand the requirement of a large amount of training data. To address these\nlimitations, we propose the Efficient Convolutional Vision Transformer (ECViT),\na hybrid architecture that effectively combines the strengths of CNNs and\nTransformers. ECViT introduces inductive biases such as locality and\ntranslation invariance, inherent to Convolutional Neural Networks (CNNs) into\nthe Transformer framework by extracting patches from low-level features and\nenhancing the encoder with convolutional operations. Additionally, it\nincorporates local-attention and a pyramid structure to enable efficient\nmulti-scale feature extraction and representation. Experimental results\ndemonstrate that ECViT achieves an optimal balance between performance and\nefficiency, outperforming state-of-the-art models on various image\nclassification tasks while maintaining low computational and storage\nrequirements. ECViT offers an ideal solution for applications that prioritize\nhigh efficiency without compromising performance.",
      "tldr_zh": "该论文提出 ECViT，一种高效的卷积视觉 Transformer，旨在解决 Vision Transformers (ViTs) 的高计算成本和对大量训练数据的需求问题。ECViT 通过整合 Convolutional Neural Networks (CNNs) 的局部性和平移不变性，从低级特征提取 patches，并在编码器中添加卷积操作，同时引入 local-attention 和 multi-scale stages 来实现高效的多尺度特征提取。实验结果表明，ECViT 在图像分类任务上超越了最先进模型，同时保持低计算和存储需求，提供了一种兼顾性能和效率的理想解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14825v1",
      "published_date": "2025-04-21 03:00:17 UTC",
      "updated_date": "2025-04-21 03:00:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:25:12.951895"
    },
    {
      "arxiv_id": "2504.14815v1",
      "title": "What Lurks Within? Concept Auditing for Shared Diffusion Models at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyong Yuan",
        "Xiaolong Ma",
        "Linke Guo",
        "Lan Zhang"
      ],
      "abstract": "Diffusion models (DMs) have revolutionized text-to-image generation, enabling\nthe creation of highly realistic and customized images from text prompts. With\nthe rise of parameter-efficient fine-tuning (PEFT) techniques like LoRA, users\ncan now customize powerful pre-trained models using minimal computational\nresources. However, the widespread sharing of fine-tuned DMs on open platforms\nraises growing ethical and legal concerns, as these models may inadvertently or\ndeliberately generate sensitive or unauthorized content, such as copyrighted\nmaterial, private individuals, or harmful content. Despite the increasing\nregulatory attention on generative AI, there are currently no practical tools\nfor systematically auditing these models before deployment. In this paper, we\naddress the problem of concept auditing: determining whether a fine-tuned DM\nhas learned to generate a specific target concept. Existing approaches\ntypically rely on prompt-based input crafting and output-based image\nclassification but suffer from critical limitations, including prompt\nuncertainty, concept drift, and poor scalability. To overcome these challenges,\nwe introduce Prompt-Agnostic Image-Free Auditing (PAIA), a novel, model-centric\nconcept auditing framework. By treating the DM as the object of inspection,\nPAIA enables direct analysis of internal model behavior, bypassing the need for\noptimized prompts or generated images. We evaluate PAIA on 320 controlled model\nand 690 real-world community models sourced from a public DM sharing platform.\nPAIA achieves over 90% detection accuracy while reducing auditing time by\n18-40x compared to existing baselines. To our knowledge, PAIA is the first\nscalable and practical solution for pre-deployment concept auditing of\ndiffusion models, providing a practical foundation for safer and more\ntransparent diffusion model sharing.",
      "tldr_zh": "这篇论文探讨了扩散模型(DMs)在文本到图像生成中的应用，以及参数高效微调(PEFT)如LoRA带来的模型共享问题，可能导致生成敏感或未授权内容。作者提出了一种新框架Prompt-Agnostic Image-Free Auditing (PAIA)，通过直接分析模型内部行为来审计微调DM是否学会特定目标概念，从而避免了传统方法的提示不确定性和图像生成需求。在评估中，PAIA在320个控制模型和690个真实社区模型上实现了超过90%的检测准确率，并将审计时间减少18-40倍，为扩散模型的预部署审计提供了可扩展的解决方案，促进更安全和透明的模型共享。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14815v1",
      "published_date": "2025-04-21 02:44:59 UTC",
      "updated_date": "2025-04-21 02:44:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:25:25.664465"
    },
    {
      "arxiv_id": "2504.14810v1",
      "title": "DONOD: Robust and Generalizable Instruction Fine-Tuning for LLMs via Model-Intrinsic Dataset Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Jucheng Hu",
        "Surong Yang",
        "Dongzhan Zhou",
        "Lijun Wu"
      ],
      "abstract": "Ad-hoc instruction fine-tuning of large language models (LLMs) is widely\nadopted for domain-specific adaptation. While domain-specific supervised\nfine-tuning (SFT) is effective and efficient, it often weakens cross-domain\ngeneralization and struggles with noisy training data. To address these\nchallenges, we propose DONOD, a lightweight model-intrinsic data pruning\nmethod. Our approach evaluates data using two model-parameter-based metrics:\nDelta of Norm (DON), which captures the cumulative influence on model weights,\nand Norm of Delta (NOD), which quantifies weight instability. Moreover, by\nemploying the Technique for Order of Preference by Similarity to Ideal Solution\n(TOPSIS) algorithm, we effectively filter noisy, unlearnable, and\ngeneralization-harming samples without relying on auxiliary models during the\nSFT process. Experiments on mathematical tasks demonstrate that data selected\nby DONOD achieve superior fine-tuning efficiency and improved robustness\nagainst noisy data. By filtering out 70% of the full dataset, we improve\ntarget-domain accuracy by 14.90% and cross-domain accuracy by 5.67%. Meanwhile,\nour selected data present superior cross-architecture generalization. Data\npruned by smaller models (e.g., Llama 3.1-8B) generalize effectively on larger\nmodels (e.g., Llama 2-13B). Compared to existing related methodologies, DONOD\ndemonstrates comparable or superior performance while remaining\ndataset-agnostic, enabling broader applicability.",
      "tldr_zh": "本文提出 DONOD，一种轻量级的模型内部数据修剪方法，用于提升大型语言模型 (LLMs) 的指令微调 (SFT) 鲁棒性和跨域泛化能力，解决传统 SFT 在噪声数据和泛化弱点上的问题。DONOD 通过 Delta of Norm (DON) 和 Norm of Delta (NOD) 指标评估数据对模型权重的累积影响和不稳定性，并结合 TOPSIS 算法过滤噪声和有害样本，而无需辅助模型。实验在数学任务上显示，修剪 70% 数据后，目标域准确率提高 14.90%，跨域准确率提高 5.67%，并展现出优秀的跨架构泛化，如从 Llama 3.1-8B 模型修剪的数据可有效应用于 Llama 2-13B 模型。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14810v1",
      "published_date": "2025-04-21 02:25:03 UTC",
      "updated_date": "2025-04-21 02:25:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:25:39.077013"
    },
    {
      "arxiv_id": "2504.14808v1",
      "title": "On Self-improving Token Embeddings",
      "title_zh": "关于自我改进的词元嵌入",
      "authors": [
        "Mario M. Kubek",
        "Shiraj Pokharel",
        "Thomas Böhme",
        "Emma L. McDaniel",
        "Herwig Unger",
        "Armin R. Mikler"
      ],
      "abstract": "This article introduces a novel and fast method for refining pre-trained\nstatic word or, more generally, token embeddings. By incorporating the\nembeddings of neighboring tokens in text corpora, it continuously updates the\nrepresentation of each token, including those without pre-assigned embeddings.\nThis approach effectively addresses the out-of-vocabulary problem, too.\nOperating independently of large language models and shallow neural networks,\nit enables versatile applications such as corpus exploration, conceptual\nsearch, and word sense disambiguation. The method is designed to enhance token\nrepresentations within topically homogeneous corpora, where the vocabulary is\nrestricted to a specific domain, resulting in more meaningful embeddings\ncompared to general-purpose pre-trained vectors. As an example, the methodology\nis applied to explore storm events and their impacts on infrastructure and\ncommunities using narratives from a subset of the NOAA Storm Events database.\nThe article also demonstrates how the approach improves the representation of\nstorm-related terms over time, providing valuable insights into the evolving\nnature of disaster narratives.",
      "tldr_zh": "这篇论文提出了一种新颖、快速的方法，用于改进预训练的静态 token embeddings，通过整合文本语料中相邻令牌的嵌入来持续更新每个令牌的表示，包括那些没有预分配嵌入的令牌，从而有效解决 out-of-vocabulary problem。该方法独立于大型语言模型和浅层神经网络，适用于主题同质的特定领域语料库，可增强嵌入的意义，并支持应用如语料探索、概念搜索和词义消歧。作为示例，该方法应用于 NOAA Storm Events 数据库的子集，改善了风暴相关术语的表示，并提供了对灾害叙事演变的宝贵洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "68T50, 68T07",
        "I.2.6; I.2.7; H.3.3"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 4 figures, 3 tables, accepted at the 2025 25th\n  International Conference on Innovations for Community Services (I4CS), June\n  11 - 13, Munich, Germany, 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14808v1",
      "published_date": "2025-04-21 02:17:19 UTC",
      "updated_date": "2025-04-21 02:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:25:50.132405"
    },
    {
      "arxiv_id": "2504.14805v1",
      "title": "Dynamic Contrastive Skill Learning with State-Transition Based Skill Clustering and Dynamic Length Adjustment",
      "title_zh": "动态对比技能学习：基于状态转换的技能聚类和动态长度调整",
      "authors": [
        "Jinwoo Choi",
        "Seung-Woo Seo"
      ],
      "abstract": "Reinforcement learning (RL) has made significant progress in various domains,\nbut scaling it to long-horizon tasks with complex decision-making remains\nchallenging. Skill learning attempts to address this by abstracting actions\ninto higher-level behaviors. However, current approaches often fail to\nrecognize semantically similar behaviors as the same skill and use fixed skill\nlengths, limiting flexibility and generalization. To address this, we propose\nDynamic Contrastive Skill Learning (DCSL), a novel framework that redefines\nskill representation and learning. DCSL introduces three key ideas:\nstate-transition based skill representation, skill similarity function\nlearning, and dynamic skill length adjustment. By focusing on state transitions\nand leveraging contrastive learning, DCSL effectively captures the semantic\ncontext of behaviors and adapts skill lengths to match the appropriate temporal\nextent of behaviors. Our approach enables more flexible and adaptive skill\nextraction, particularly in complex or noisy datasets, and demonstrates\ncompetitive performance compared to existing methods in task completion and\nefficiency.",
      "tldr_zh": "该研究针对强化学习（RL）在长时序任务中的挑战，提出了一种新型框架 Dynamic Contrastive Skill Learning (DCSL)，旨在通过基于状态转换（state-transition）的技能表示、技能相似性函数学习和动态技能长度调整来解决现有方法无法识别语义相似行为和技能长度固定的问题。DCSL 利用对比学习（contrastive learning）捕捉行为的语义上下文，并自动适应技能长度，从而在复杂或噪声数据集上实现更灵活的技能提取。与现有方法相比，该框架在任务完成和效率方面表现出色，证明了其在提升 RL 泛化能力方面的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025; 23 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.14805v1",
      "published_date": "2025-04-21 02:11:39 UTC",
      "updated_date": "2025-04-21 02:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:26:01.369020"
    },
    {
      "arxiv_id": "2504.14804v1",
      "title": "Automatic Evaluation Metrics for Document-level Translation: Overview, Challenges and Trends",
      "title_zh": "用于文档级翻译的自动评估指标：概述、挑战和趋势",
      "authors": [
        "Jiaxin GUO",
        "Xiaoyu Chen",
        "Zhiqiang Rao",
        "Jinlong Yang",
        "Zongyao Li",
        "Hengchao Shang",
        "Daimeng Wei",
        "Hao Yang"
      ],
      "abstract": "With the rapid development of deep learning technologies, the field of\nmachine translation has witnessed significant progress, especially with the\nadvent of large language models (LLMs) that have greatly propelled the\nadvancement of document-level translation. However, accurately evaluating the\nquality of document-level translation remains an urgent issue. This paper first\nintroduces the development status of document-level translation and the\nimportance of evaluation, highlighting the crucial role of automatic evaluation\nmetrics in reflecting translation quality and guiding the improvement of\ntranslation systems. It then provides a detailed analysis of the current state\nof automatic evaluation schemes and metrics, including evaluation methods with\nand without reference texts, as well as traditional metrics, Model-based\nmetrics and LLM-based metrics. Subsequently, the paper explores the challenges\nfaced by current evaluation methods, such as the lack of reference diversity,\ndependence on sentence-level alignment information, and the bias, inaccuracy,\nand lack of interpretability of the LLM-as-a-judge method. Finally, the paper\nlooks ahead to the future trends in evaluation methods, including the\ndevelopment of more user-friendly document-level evaluation methods and more\nrobust LLM-as-a-judge methods, and proposes possible research directions, such\nas reducing the dependency on sentence-level information, introducing\nmulti-level and multi-granular evaluation approaches, and training models\nspecifically for machine translation evaluation. This study aims to provide a\ncomprehensive analysis of automatic evaluation for document-level translation\nand offer insights into future developments.",
      "tldr_zh": "这篇论文概述了文档级翻译的自动 evaluation metrics 发展现状及其重要性，强调这些指标在评估翻译质量和优化系统方面的关键作用，包括基于参考文本的评估、传统指标、Model-based metrics 和 LLM-based metrics。论文分析了当前方法的挑战，如参考多样性不足、对句子级对齐的依赖，以及 LLM-as-a-judge 方法的偏差、不准确性和可解释性问题。未来趋势包括开发更用户友好的文档级评估方法、提升 LLM-as-a-judge 的稳健性，并提出研究方向，如引入多级别多粒度评估和训练专用于机器翻译评估的模型，以推动该领域的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.14804v1",
      "published_date": "2025-04-21 02:08:42 UTC",
      "updated_date": "2025-04-21 02:08:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:26:14.390015"
    },
    {
      "arxiv_id": "2504.14797v1",
      "title": "Automated Duplicate Bug Report Detection in Large Open Bug Repositories",
      "title_zh": "在大型开源错误报告库中自动检测重复错误报告",
      "authors": [
        "Clare E. Laney",
        "Andrew Barovic",
        "Armin Moin"
      ],
      "abstract": "Many users and contributors of large open-source projects report software\ndefects or enhancement requests (known as bug reports) to the issue-tracking\nsystems. However, they sometimes report issues that have already been reported.\nFirst, they may not have time to do sufficient research on existing bug\nreports. Second, they may not possess the right expertise in that specific area\nto realize that an existing bug report is essentially elaborating on the same\nmatter, perhaps with a different wording. In this paper, we propose a novel\napproach based on machine learning methods that can automatically detect\nduplicate bug reports in an open bug repository based on the textual data in\nthe reports. We present six alternative methods: Topic modeling, Gaussian Naive\nBayes, deep learning, time-based organization, clustering, and summarization\nusing a generative pre-trained transformer large language model. Additionally,\nwe introduce a novel threshold-based approach for duplicate identification, in\ncontrast to the conventional top-k selection method that has been widely used\nin the literature. Our approach demonstrates promising results across all the\nproposed methods, achieving accuracy rates ranging from the high 70%'s to the\nlow 90%'s. We evaluated our methods on a public dataset of issues belonging to\nan Eclipse open-source project.",
      "tldr_zh": "这篇论文针对大型开源 bug 仓库中重复报告的问题，提出了一种基于机器学习的方法来自动检测重复 bug reports。方法包括六种技术：Topic modeling、Gaussian Naive Bayes、deep learning、time-based organization、clustering 和使用生成式预训练 transformer 的 summarization，同时引入了创新的 threshold-based approach，以替代传统的 top-k selection method。实验结果显示，该方法在 Eclipse 开源项目的公开数据集上实现了70%到90%的准确率，显著提高了重复报告检测的效率和准确性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "IEEE COMPSAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14797v1",
      "published_date": "2025-04-21 01:55:54 UTC",
      "updated_date": "2025-04-21 01:55:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:26:27.364993"
    },
    {
      "arxiv_id": "2504.14783v2",
      "title": "How Effective Can Dropout Be in Multiple Instance Learning ?",
      "title_zh": "在多实例学习中，Dropout 能有多有效？",
      "authors": [
        "Wenhui Zhu",
        "Peijie Qiu",
        "Xiwen Chen",
        "Zhangsihao Yang",
        "Aristeidis Sotiras",
        "Abolfazl Razi",
        "Yalin Wang"
      ],
      "abstract": "Multiple Instance Learning (MIL) is a popular weakly-supervised method for\nvarious applications, with a particular interest in histological whole slide\nimage (WSI) classification. Due to the gigapixel resolution of WSI,\napplications of MIL in WSI typically necessitate a two-stage training scheme:\nfirst, extract features from the pre-trained backbone and then perform MIL\naggregation. However, it is well-known that this suboptimal training scheme\nsuffers from \"noisy\" feature embeddings from the backbone and inherent weak\nsupervision, hindering MIL from learning rich and generalizable features.\nHowever, the most commonly used technique (i.e., dropout) for mitigating this\nissue has yet to be explored in MIL. In this paper, we empirically explore how\neffective the dropout can be in MIL. Interestingly, we observe that dropping\nthe top-k most important instances within a bag leads to better performance and\ngeneralization even under noise attack. Based on this key observation, we\npropose a novel MIL-specific dropout method, termed MIL-Dropout, which\nsystematically determines which instances to drop. Experiments on five MIL\nbenchmark datasets and two WSI datasets demonstrate that MIL-Dropout boosts the\nperformance of current MIL methods with a negligible computational cost. The\ncode is available at https://github.com/ChongQingNoSubway/MILDropout.",
      "tldr_zh": "本研究探讨了在 Multiple Instance Learning (MIL) 中的 dropout 技术有效性，特别是针对 histological whole slide image (WSI) 分类的弱监督问题。论文发现，丢弃 bag 中 top-k 最重要实例能显著提升模型性能和泛化能力，甚至在噪音攻击下保持稳健。基于此，提出了一种新方法 MIL-Dropout，它系统地选择要丢弃的实例，并在五个 MIL 基准数据集和两个 WSI 数据集上实验证明，该方法以微不足道的计算成本提升了现有 MIL 方法的准确性和泛化性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV",
        "stat.ML"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICML2025",
      "pdf_url": "http://arxiv.org/pdf/2504.14783v2",
      "published_date": "2025-04-21 00:46:31 UTC",
      "updated_date": "2025-05-20 17:22:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:26:39.154146"
    },
    {
      "arxiv_id": "2504.14779v1",
      "title": "Exploring Collaborative GenAI Agents in Synchronous Group Settings: Eliciting Team Perceptions and Design Considerations for the Future of Work",
      "title_zh": "翻译失败",
      "authors": [
        "Janet G. Johnson",
        "Macarena Peralta",
        "Mansanjam Kaur",
        "Ruijie Sophia Huang",
        "Sheng Zhao",
        "Ruijia Guan",
        "Shwetha Rajaram",
        "Michael Nebeling"
      ],
      "abstract": "While generative artificial intelligence (GenAI) is finding increased\nadoption in workplaces, current tools are primarily designed for individual\nuse. Prior work established the potential for these tools to enhance personal\ncreativity and productivity towards shared goals; however, we don't know yet\nhow to best take into account the nuances of group work and team dynamics when\ndeploying GenAI in work settings. In this paper, we investigate the potential\nof collaborative GenAI agents to augment teamwork in synchronous group settings\nthrough an exploratory study that engaged 25 professionals across 6 teams in\nspeculative design workshops and individual follow-up interviews. Our workshops\nincluded a mixed reality provotype to simulate embodied collaborative GenAI\nagents capable of actively participating in group discussions. Our findings\nsuggest that, if designed well, collaborative GenAI agents offer valuable\nopportunities to enhance team problem-solving by challenging groupthink,\nbridging communication gaps, and reducing social friction. However, teams'\nwillingness to integrate GenAI agents depended on its perceived fit across a\nnumber of individual, team, and organizational factors. We outline the key\ndesign tensions around agent representation, social prominence, and engagement\nand highlight the opportunities spatial and immersive technologies could offer\nto modulate GenAI influence on team outcomes and strike a balance between\naugmentation and agency.",
      "tldr_zh": "本研究探讨了生成式人工智能（GenAI）代理在同步群组设置中的协作潜力，通过探索性研究调查团队感知和未来工作设计考虑。研究涉及25名专业人士参与的6个团队推测性设计研讨会和后续个人访谈，并使用混合现实原型模拟具身GenAI代理以参与群组讨论。结果显示，设计良好的协作GenAI代理可提升团队问题解决能力，如挑战群体思维、桥接沟通差距并减少社会摩擦，但其整合取决于个人、团队和组织因素。论文突出了代理表示、社会显著性和参与等方面的设计张力，并强调空间和沉浸式技术在平衡GenAI增强与代理权方面的机会。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "To be published in ACM Conference on Computer-Supported Cooperative\n  Work and Social Computing (CSCW 2025). 33 pages, 11 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2504.14779v1",
      "published_date": "2025-04-21 00:38:02 UTC",
      "updated_date": "2025-04-21 00:38:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:26:51.999671"
    },
    {
      "arxiv_id": "2505.03763v1",
      "title": "Splitwiser: Efficient LM inference with constrained resources",
      "title_zh": "翻译失败",
      "authors": [
        "Asad Aali",
        "Adney Cardoza",
        "Melissa Capo"
      ],
      "abstract": "Efficient inference of LLMs remains a crucial challenge, with two main\nphases: a compute-intensive prompt computation and a memory-intensive token\ngeneration. Despite existing batching and scheduling techniques, token\ngeneration phases fail to fully utilize compute resources, especially when\ncompared to prompt computation phases. To address these challenges, we propose\nSplitwiser, a methodology that splits the two phases of an LLM inference\nrequest onto the same GPU, thereby reducing overhead and improving memory\naccess and cache utilization. By eliminating the need to transfer data across\ndevices, Splitwiser aims to minimize network-related overheads. In this report,\nwe describe the basic structure of our proposed pipeline while sharing\npreliminary results and analysis. We implement our proposed multiprocessing\ndesign on two widely-used and independent LLM architectures: Huggingface and\nvLLM. We open-source our code for the respective implementations: 1)\nHuggingface (https://github.com/asad-aali/splitwiser), and 2) vLLM\n(https://github.com/adney11/vllm-sysml).",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的推理效率问题，提出了Splitwiser方法，以解决计算密集的提示计算和内存密集的令牌生成阶段在资源受限环境下的低利用率。Splitwiser通过将这两个阶段拆分到同一GPU上，减少数据传输开销并优化内存访问和缓存利用，从而显著降低网络相关开销。实验在Huggingface和vLLM架构上进行了实现，并开源了代码，初步结果显示了其在提高推理效率方面的潜力。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.03763v1",
      "published_date": "2025-04-21 00:21:08 UTC",
      "updated_date": "2025-04-21 00:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:27:03.258725"
    },
    {
      "arxiv_id": "2504.14773v1",
      "title": "PLANET: A Collection of Benchmarks for Evaluating LLMs' Planning Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Haoming Li",
        "Zhaoliang Chen",
        "Jonathan Zhang",
        "Fei Liu"
      ],
      "abstract": "Planning is central to agents and agentic AI. The ability to plan, e.g.,\ncreating travel itineraries within a budget, holds immense potential in both\nscientific and commercial contexts. Moreover, optimal plans tend to require\nfewer resources compared to ad-hoc methods. To date, a comprehensive\nunderstanding of existing planning benchmarks appears to be lacking. Without\nit, comparing planning algorithms' performance across domains or selecting\nsuitable algorithms for new scenarios remains challenging. In this paper, we\nexamine a range of planning benchmarks to identify commonly used testbeds for\nalgorithm development and highlight potential gaps. These benchmarks are\ncategorized into embodied environments, web navigation, scheduling, games and\npuzzles, and everyday task automation. Our study recommends the most\nappropriate benchmarks for various algorithms and offers insights to guide\nfuture benchmark development.",
      "tldr_zh": "这篇论文介绍了PLANET，这是一个用于评估大型语言模型(LLMs)规划能力的基准集合，旨在填补当前规划基准缺乏全面理解的空白。作者审查了多种规划基准，将它们分类为具身环境、网页导航、调度、游戏和谜题以及日常任务自动化，并突出了潜在差距。研究推荐了最合适的基准来比较算法性能并指导新场景的算法选择，同时为未来基准开发提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.14773v1",
      "published_date": "2025-04-21 00:02:50 UTC",
      "updated_date": "2025-04-21 00:02:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:27:16.058170"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 113,
  "processed_papers_count": 113,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T15:27:42.356238"
}