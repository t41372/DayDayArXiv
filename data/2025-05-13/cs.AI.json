{
  "date": "2025-05-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-13 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，特别是大型语言模型（LLM）的优化、强化学习在机器人和决策中的应用，以及跨领域创新如图像处理和生物信息学，其中 LLM 可靠性提升（如第 1 篇）和强化学习在自主驾驶中的进展（如第 56 篇）最为引人注目，同时有名学者如 Michael Bowling 的参与（第 10 篇）增添了学术深度。\n\n以下是今日论文的精选摘要，我优先讨论重要、话题性和影响力强的文章（如 LLM 和强化学习相关），并将相关主题归类讨论；其他领域如图像处理或生物信息学等较常规的论文则快速掠过，只简述核心贡献。每个条目列出论文标题（中文 + 英文），并保留关键学术术语，力求简洁明了。\n\n### LLM 和 AI 优化相关（重点讨论，约 10 篇）\n这些论文探讨了 LLM 的可靠性、生成和应用，强调了在复杂任务中的改进和潜在挑战，是今日的热点。\n- **Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification（提升 LLM 可靠性的方法：结合 CoT、RAG、自一致性和自验证）**：主要贡献是通过结合链式思考（CoT）、检索增强生成（RAG）、自一致性和自验证策略，减少 LLM 的幻觉问题，提高事实准确性；发现这种组合在多步推理任务中更有效。\n- **Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation（测试作为提示：LLM 代码生成的测试驱动开发基准）**：提出 WebApp1K 基准，评估 LLM 在测试驱动开发中的性能；发现指令遵循和上下文学习对代码生成至关重要，揭示了长提示中的指令丢失问题。\n- **Automated Meta Prompt Engineering for Alignment with the Theory of Mind（自动元提示工程：与理论心智对齐）**：作者包括 Aaron Baughman 和 Rahul Agarwal，利用强化学习优化 LLM 的提示以匹配人类心智期望；发现这种方法在内容生成中实现了 100% 的心智对齐，提高了文本质量。\n- **AI-Mediated Code Comment Improvement（AI 辅助代码注释改进）**：使用 LLM 重写代码注释以提升质量轴（如清晰度和准确性）；贡献包括一个可内部分布的简化模型，实验显示显著改善注释质量。\n- **Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation（可微量子架构搜索在量子增强神经网络参数生成中的应用）**：提出端到端优化量子电路架构；发现这种方法在分类和强化学习任务中匹配或超越手动设计，提升了参数生成效率。\n- **Generative AI for Autonomous Driving: Frontiers and Opportunities（生成式 AI 用于自主驾驶：前沿与机遇）**：作者众多，包括 Marco Pavone 和 Ming-Hsuan Yang，提供生成模型在自主驾驶中的全面综述；关键发现包括在图像和轨迹生成中的进展，以及挑战如泛化性和安全。\n- **Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions（模板引导的肺段重建：使用神经隐式函数）**：提出神经隐式函数方法重建肺段；贡献包括新数据集 Lung3D 和精确解剖重建，超越现有方法。\n- **WaLLM – Insights from an LLM-Powered Chatbot deployment via WhatsApp（WaLLM：通过 WhatsApp 部署的 LLM 驱动聊天机器人洞见）**：分析 LLM 在发展中地区的应用；发现健康主题查询占主导，并通过奖励系统提升用户参与。\n- **Optimized Couplings for Watermarking Large Language Models（优化耦合用于 LLM 水印）**：作者包括 Haim Permuter 和 Flavio P. Calmon，提出新水印方案减少 LLM 生成文本的干扰；发现该方法在检测率和鲁棒性上优于基线。\n- **Memorization-Compression Cycles Improve Generalization（记忆-压缩循环提升泛化）**：探索 LLM 训练中的记忆和压缩循环；贡献包括新目标函数 IBLM 和算法 GAPT，提升了泛化性能并减少了遗忘。\n\n### 强化学习和机器人相关（次重点讨论，约 5 篇）\n这些论文强调强化学习在决策和机器人控制中的创新，特别在实际应用中。\n- **Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control（蒙te卡洛束搜索用于 Actor-Critic 强化学习在连续控制中）**：提出 MCBS 方法结合 TD3 改进探索；发现它在基准任务中提升了样本效率和收敛率。\n- **Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation（深度强化学习用于电力网格多阶段级联故障缓解）**：作者包括 Bo Meng，使用 DRL 模拟电力故障；主要发现是该方法在 IEEE 系统上有效缓解多阶段故障。\n- **Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning（通过分层多代理强化学习提升空中作战策略）**：提出分层框架训练代理；贡献包括在模拟环境中实现高效决策，支持实时控制。\n- **Generalization in Monitored Markov Decision Processes (Mon-MDPs)（监控 Markov 决策过程的泛化）**：作者 Michael Bowling 探索功能逼近在 Mon-MDPs 中的应用；发现奖励模型可实现近似最优策略，但需防范过泛化。\n- **Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections（基于深度强化学习的自动车辆在信号交叉口的纵向控制策略）**：提出 DRL 算法优化车辆控制；发现它在安全和效率上优于人类驾驶。\n\n### 其他领域快速掠过（简要提及，约 5 篇）\n这些论文涉及图像处理、生物和量子计算等领域，不如上述主题热门，故仅概述主要点。\n- **Block-Biased Mamba for Long-Range Sequence Processing（块偏差 Mamba 用于长序列处理）**：改进状态空间模型处理长序列；贡献包括新架构 B2S6，提升了长程任务性能。\n- **GPML: Graph Processing for Machine Learning（GPML：用于机器学习的图处理）**：提出库检测网络异常；发现它增强了实时检测和取证分析。\n- **Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work（追踪无形：理解学生在 AI 支持设计中的判断）**：分析学生与 AI 的协作判断；发现新判断类型如代理分配和可靠性。\n- **When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes（当重复驱动词汇：T2T 灵长类基因组的 Byte-Pair 编码分析）**：作者 Aleksey Komissarov 分析基因组编码；主要发现是重复元素影响比较基因组学。\n- **A New Tractable Description Logic under Categorical Semantics（在范畴语义下的一种新可处理描述逻辑）**：提出扩展 EL 逻辑；贡献包括保持可处理性同时添加弱否定。\n\n今日 arXiv 论文丰富多元，LLM 和强化学习领域的创新尤为突出，展示了 AI 在实际应用中的潜力。如果你对特定论文感兴趣，可以深入探索这些核心贡献！（总字数控制在合理范围内，聚焦高影响力内容）",
  "papers": [
    {
      "arxiv_id": "2505.09031v1",
      "title": "Improving the Reliability of LLMs: Combining CoT, RAG, Self-Consistency, and Self-Verification",
      "title_zh": "改善 LLMs 的可靠性：结合 CoT、RAG、Self-Consistency 和 Self-Verification",
      "authors": [
        "Adarsh Kumar",
        "Hwiyoon Kim",
        "Jawahar Sai Nathani",
        "Neil Roy"
      ],
      "abstract": "Hallucination, where large language models (LLMs) generate confident but\nincorrect or irrelevant information, remains a key limitation in their\napplication to complex, open-ended tasks. Chain-of-thought (CoT) prompting has\nemerged as a promising method for improving multistep reasoning by guiding\nmodels through intermediate steps. However, CoT alone does not fully address\nthe hallucination problem. In this work, we investigate how combining CoT with\nretrieval-augmented generation (RAG), as well as applying self-consistency and\nself-verification strategies, can reduce hallucinations and improve factual\naccuracy. By incorporating external knowledge sources during reasoning and\nenabling models to verify or revise their own outputs, we aim to generate more\naccurate and coherent responses. We present a comparative evaluation of\nbaseline LLMs against CoT, CoT+RAG, self-consistency, and self-verification\ntechniques. Our results highlight the effectiveness of each method and identify\nthe most robust approach for minimizing hallucinations while preserving fluency\nand reasoning depth.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)的幻觉问题，提出了一种结合Chain-of-Thought (CoT)提示、Retrieval-Augmented Generation (RAG)、Self-Consistency和Self-Verification策略的综合方法，以减少模型生成不准确或无关信息并提升事实准确性。通过整合外部知识源并让模型自我验证输出，该方法旨在生成更连贯的响应。实验结果显示，这些技术组合显著优于基线LLMs，提高了准确性，同时保持了流畅性和推理深度，并识别出最稳健的方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09031v1",
      "published_date": "2025-05-13 23:57:02 UTC",
      "updated_date": "2025-05-13 23:57:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:19:23.695061"
    },
    {
      "arxiv_id": "2505.09029v1",
      "title": "Monte Carlo Beam Search for Actor-Critic Reinforcement Learning in Continuous Control",
      "title_zh": "翻译失败",
      "authors": [
        "Hazim Alzorgan",
        "Abolfazl Razi"
      ],
      "abstract": "Actor-critic methods, like Twin Delayed Deep Deterministic Policy Gradient\n(TD3), depend on basic noise-based exploration, which can result in less than\noptimal policy convergence. In this study, we introduce Monte Carlo Beam Search\n(MCBS), a new hybrid method that combines beam search and Monte Carlo rollouts\nwith TD3 to improve exploration and action selection. MCBS produces several\ncandidate actions around the policy's output and assesses them through\nshort-horizon rollouts, enabling the agent to make better-informed choices. We\ntest MCBS across various continuous-control benchmarks, including\nHalfCheetah-v4, Walker2d-v5, and Swimmer-v5, showing enhanced sample efficiency\nand performance compared to standard TD3 and other baseline methods like SAC,\nPPO, and A2C. Our findings emphasize MCBS's capability to enhance policy\nlearning through structured look-ahead search while ensuring computational\nefficiency. Additionally, we offer a detailed analysis of crucial\nhyperparameters, such as beam width and rollout depth, and explore adaptive\nstrategies to optimize MCBS for complex control tasks. Our method shows a\nhigher convergence rate across different environments compared to TD3, SAC,\nPPO, and A2C. For instance, we achieved 90% of the maximum achievable reward\nwithin around 200 thousand timesteps compared to 400 thousand timesteps for the\nsecond-best method.",
      "tldr_zh": "本研究提出了一种新的混合方法Monte Carlo Beam Search (MCBS)，旨在提升actor-critic强化学习在连续控制任务中的探索和行动选择，通过将beam search和Monte Carlo rollouts与Twin Delayed Deep Deterministic Policy Gradient (TD3)相结合，生成多个候选动作并通过短时限rollouts进行评估。相比标准TD3、SAC、PPO和A2C，MCBS在HalfCheetah-v4、Walker2d-v5和Swimmer-v5等基准环境中显示出更高的样本效率和性能，例如在约20万timesteps内达到90%的最大奖励，而第二佳方法需40万timesteps。研究还分析了关键超参数如beam width和rollout depth，并探索自适应策略，以优化MCBS在复杂控制任务中的应用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09029v1",
      "published_date": "2025-05-13 23:56:12 UTC",
      "updated_date": "2025-05-13 23:56:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:19:35.661625"
    },
    {
      "arxiv_id": "2505.09027v1",
      "title": "Tests as Prompt: A Test-Driven-Development Benchmark for LLM Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Cui"
      ],
      "abstract": "We introduce WebApp1K, a novel benchmark for evaluating large language models\n(LLMs) in test-driven development (TDD) tasks, where test cases serve as both\nprompt and verification for code generation. Unlike traditional approaches\nrelying on natural language prompts, our benchmark emphasizes the ability of\nLLMs to interpret and implement functionality directly from test cases,\nreflecting real-world software development practices. Comprising 1000 diverse\nchallenges across 20 application domains, the benchmark evaluates LLMs on their\nability to generate compact, functional code under the constraints of context\nlength and multi-feature complexity. Our findings highlight instruction\nfollowing and in-context learning as critical capabilities for TDD success,\nsurpassing the importance of general coding proficiency or pretraining\nknowledge. Through comprehensive evaluation of 19 frontier models, we reveal\nperformance bottlenecks, such as instruction loss in long prompts, and provide\na detailed error analysis spanning multiple root causes. This work underscores\nthe practical value of TDD-specific benchmarks and lays the foundation for\nadvancing LLM capabilities in rigorous, application-driven coding scenarios.",
      "tldr_zh": "本研究引入了WebApp1K基准，用于评估大型语言模型(LLMs)在测试驱动开发(TDD)任务中的性能，其中测试用例同时作为提示和代码生成验证。基准包含1000个多样化挑战，跨越20个应用领域，强调LLMs从测试用例中直接解释并生成紧凑、功能性代码的能力，同时考虑上下文长度和多特征复杂性的约束。研究发现，指令遵循和上下文学习是TDD成功的关键因素，比一般编码熟练度或预训练知识更重要；通过评估19个前沿模型，揭示了长提示中的指令丢失等性能瓶颈，并提供了详细错误分析，为提升LLMs在实际应用驱动编码场景中的能力奠定基础。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "arXiv admin note: text overlap with arXiv:2409.05177",
      "pdf_url": "http://arxiv.org/pdf/2505.09027v1",
      "published_date": "2025-05-13 23:47:12 UTC",
      "updated_date": "2025-05-13 23:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:19:47.371206"
    },
    {
      "arxiv_id": "2505.09024v1",
      "title": "Automated Meta Prompt Engineering for Alignment with the Theory of Mind",
      "title_zh": "翻译失败",
      "authors": [
        "Aaron Baughman",
        "Rahul Agarwal",
        "Eduardo Morales",
        "Gozde Akay"
      ],
      "abstract": "We introduce a method of meta-prompting that jointly produces fluent text for\ncomplex tasks while optimizing the similarity of neural states between a\nhuman's mental expectation and a Large Language Model's (LLM) neural\nprocessing. A technique of agentic reinforcement learning is applied, in which\nan LLM as a Judge (LLMaaJ) teaches another LLM, through in-context learning,\nhow to produce content by interpreting the intended and unintended generated\ntext traits. To measure human mental beliefs around content production, users\nmodify long form AI-generated text articles before publication at the US Open\n2024 tennis Grand Slam. Now, an LLMaaJ can solve the Theory of Mind (ToM)\nalignment problem by anticipating and including human edits within the creation\nof text from an LLM. Throughout experimentation and by interpreting the results\nof a live production system, the expectations of human content reviewers had\n100% of alignment with AI 53.8% of the time with an average iteration count of\n4.38. The geometric interpretation of content traits such as factualness,\nnovelty, repetitiveness, and relevancy over a Hilbert vector space combines\nspatial volume (all trait importance) with vertices alignment (individual trait\nrelevance) enabled the LLMaaJ to optimize on Human ToM. This resulted in an\nincrease in content quality by extending the coverage of tennis action. Our\nwork that was deployed at the US Open 2024 has been used across other live\nevents within sports and entertainment.",
      "tldr_zh": "本研究提出了一种自动化 meta-prompting 方法，旨在优化 Large Language Model (LLM) 的神经处理与人类 Theory of Mind (ToM) 心理期望的相似性，同时生成流畅的复杂任务文本。该方法采用 agentic reinforcement learning 和 LLM as Judge (LLMaaJ)，通过 in-context learning 教导 LLM 预测并整合人类编辑，以提升内容生成的质量。实验基于 US Open 2024 的用户修改数据，实现了 53.8% 的完全对齐率，平均迭代次数 4.38，并利用 Hilbert 向量空间的几何解释优化内容特征，如 factualness 和 novelty。该工作已在体育和娱乐事件中部署，显著扩展了 AI 生成内容的覆盖范围和准确性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "9 pages, 6 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.09024v1",
      "published_date": "2025-05-13 23:42:36 UTC",
      "updated_date": "2025-05-13 23:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:20:00.674437"
    },
    {
      "arxiv_id": "2505.09022v1",
      "title": "Block-Biased Mamba for Long-Range Sequence Processing",
      "title_zh": "翻译失败",
      "authors": [
        "Annan Yu",
        "N. Benjamin Erichson"
      ],
      "abstract": "Mamba extends earlier state space models (SSMs) by introducing\ninput-dependent dynamics, and has demonstrated strong empirical performance\nacross a range of domains, including language modeling, computer vision, and\nfoundation models. However, a surprising weakness remains: despite being built\non architectures designed for long-range dependencies, Mamba performs poorly on\nlong-range sequential tasks. Understanding and addressing this gap is important\nfor improving Mamba's universality and versatility. In this work, we analyze\nMamba's limitations through three perspectives: expressiveness, inductive bias,\nand training stability. Our theoretical results show how Mamba falls short in\neach of these aspects compared to earlier SSMs such as S4D. To address these\nissues, we propose $\\text{B}_2\\text{S}_6$, a simple extension of Mamba's S6\nunit that combines block-wise selective dynamics with a channel-specific bias.\nWe prove that these changes equip the model with a better-suited inductive bias\nand improve its expressiveness and stability. Empirically,\n$\\text{B}_2\\text{S}_6$ outperforms S4 and S4D on Long-Range Arena (LRA) tasks\nwhile maintaining Mamba's performance on language modeling benchmarks.",
      "tldr_zh": "本研究分析了Mamba模型在处理长序列任务时的局限性，包括表达能力(expressiveness)、归纳偏差(inductive bias)和训练稳定性(training stability)方面的不足，与早期SSMs如S4D相比表现较差。作者提出$\\text{B}_2\\text{S}_6$，这是一种Mamba的S6单元扩展，通过结合块-wise selective dynamics和channel-specific bias，提升了模型的归纳偏差、表达能力和稳定性。实验结果表明，$\\text{B}_2\\text{S}_6$在Long-Range Arena (LRA)任务上优于S4和S4D，同时在语言建模基准上保持了Mamba的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09022v1",
      "published_date": "2025-05-13 23:34:09 UTC",
      "updated_date": "2025-05-13 23:34:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:20:12.216823"
    },
    {
      "arxiv_id": "2505.09021v1",
      "title": "AI-Mediated Code Comment Improvement",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Dhakal",
        "Chia-Yi Su",
        "Robert Wallace",
        "Chris Fakhimi",
        "Aakash Bansal",
        "Toby Li",
        "Yu Huang",
        "Collin McMillan"
      ],
      "abstract": "This paper describes an approach to improve code comments along different\nquality axes by rewriting those comments with customized Artificial\nIntelligence (AI)-based tools. We conduct an empirical study followed by\ngrounded theory qualitative analysis to determine the quality axes to improve.\nThen we propose a procedure using a Large Language Model (LLM) to rewrite\nexisting code comments along the quality axes. We implement our procedure using\nGPT-4o, then distil the results into a smaller model capable of being run\nin-house, so users can maintain data custody. We evaluate both our approach\nusing GPT-4o and the distilled model versions. We show in an evaluation how our\nprocedure improves code comments along the quality axes. We release all data\nand source code in an online repository for reproducibility.",
      "tldr_zh": "本文提出了一种使用 AI 工具改进代码注释质量的方法，通过实证研究和定性分析来识别多个质量维度，并利用 Large Language Model (LLM) 如 GPT-4o 重写现有注释。研究过程包括实现该程序、将模型提炼为较小的内部版本以维护数据托管，并对原始和提炼模型进行评估。结果显示，该方法显著提升了代码注释的质量，且所有数据和源代码已开源以支持可重复性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09021v1",
      "published_date": "2025-05-13 23:31:32 UTC",
      "updated_date": "2025-05-13 23:31:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:20:22.868192"
    },
    {
      "arxiv_id": "2505.09012v1",
      "title": "Deep Reinforcement Learning for Power Grid Multi-Stage Cascading Failure Mitigation",
      "title_zh": "深度强化学习用于电网多阶段级联故障缓解",
      "authors": [
        "Bo Meng",
        "Chenghao Xu",
        "Yongli Zhu"
      ],
      "abstract": "Cascading failures in power grids can lead to grid collapse, causing severe\ndisruptions to social operations and economic activities. In certain cases,\nmulti-stage cascading failures can occur. However, existing\ncascading-failure-mitigation strategies are usually single-stage-based,\noverlooking the complexity of the multi-stage scenario. This paper treats the\nmulti-stage cascading failure problem as a reinforcement learning task and\ndevelops a simulation environment. The reinforcement learning agent is then\ntrained via the deterministic policy gradient algorithm to achieve continuous\nactions. Finally, the effectiveness of the proposed approach is validated on\nthe IEEE 14-bus and IEEE 118-bus systems.",
      "tldr_zh": "本文提出了一种基于Deep Reinforcement Learning的方法，用于缓解电力网格的多阶段级联故障问题，以避免电网崩溃对社会和经济造成严重影响。现有策略通常局限于单阶段，而该方法将多阶段故障视为强化学习任务，开发了一个模拟环境，并使用deterministic policy gradient algorithm训练代理以实现连续动作。实验在IEEE 14-bus和IEEE 118-bus系统中验证了该方法的有效性，展示了其在处理复杂多阶段场景中的显著优势。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted and presented at ICLR 2025 in Singapore,\n  Apr. 28, 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09012v1",
      "published_date": "2025-05-13 23:01:34 UTC",
      "updated_date": "2025-05-13 23:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:20:35.266108"
    },
    {
      "arxiv_id": "2505.09003v1",
      "title": "Continual Reinforcement Learning via Autoencoder-Driven Task and New Environment Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Zeki Doruk Erden",
        "Donia Gasmi",
        "Boi Faltings"
      ],
      "abstract": "Continual learning for reinforcement learning agents remains a significant\nchallenge, particularly in preserving and leveraging existing information\nwithout an external signal to indicate changes in tasks or environments. In\nthis study, we explore the effectiveness of autoencoders in detecting new tasks\nand matching observed environments to previously encountered ones. Our approach\nintegrates policy optimization with familiarity autoencoders within an\nend-to-end continual learning system. This system can recognize and learn new\ntasks or environments while preserving knowledge from earlier experiences and\ncan selectively retrieve relevant knowledge when re-encountering a known\nenvironment. Initial results demonstrate successful continual learning without\nexternal signals to indicate task changes or reencounters, showing promise for\nthis methodology.",
      "tldr_zh": "本文研究了强化学习(reinforcement learning)中的持续学习(continual learning)挑战，提出了一种使用自编码器(autoencoders)来检测新任务和匹配已知环境的创新方法。该方法将策略优化(policy optimization)与熟悉度自编码器整合到一个端到端系统中，实现新任务/环境的识别与学习，同时保留先前知识并在重新遇到已知环境时选择性检索相关信息。初步结果显示，该系统无需外部信号即可成功进行持续学习，展现出显著的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published in the Autonomous Robots and Multirobot Systems (ARMS)\n  workshop at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.09003v1",
      "published_date": "2025-05-13 22:38:54 UTC",
      "updated_date": "2025-05-13 22:38:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:20:47.334158"
    },
    {
      "arxiv_id": "2505.08995v1",
      "title": "Enhancing Aerial Combat Tactics through Hierarchical Multi-Agent Reinforcement Learning",
      "title_zh": "通过分层多智能体强化学习增强空中作战战术",
      "authors": [
        "Ardian Selmonaj",
        "Oleg Szehr",
        "Giacomo Del Rio",
        "Alessandro Antonucci",
        "Adrian Schneider",
        "Michael Rüegsegger"
      ],
      "abstract": "This work presents a Hierarchical Multi-Agent Reinforcement Learning\nframework for analyzing simulated air combat scenarios involving heterogeneous\nagents. The objective is to identify effective Courses of Action that lead to\nmission success within preset simulations, thereby enabling the exploration of\nreal-world defense scenarios at low cost and in a safe-to-fail setting.\nApplying deep Reinforcement Learning in this context poses specific challenges,\nsuch as complex flight dynamics, the exponential size of the state and action\nspaces in multi-agent systems, and the capability to integrate real-time\ncontrol of individual units with look-ahead planning. To address these\nchallenges, the decision-making process is split into two levels of\nabstraction: low-level policies control individual units, while a high-level\ncommander policy issues macro commands aligned with the overall mission\ntargets. This hierarchical structure facilitates the training process by\nexploiting policy symmetries of individual agents and by separating control\nfrom command tasks. The low-level policies are trained for individual combat\ncontrol in a curriculum of increasing complexity. The high-level commander is\nthen trained on mission targets given pre-trained control policies. The\nempirical validation confirms the advantages of the proposed framework.",
      "tldr_zh": "本研究提出了一种Hierarchical Multi-Agent Reinforcement Learning框架，用于分析涉及异构智能体的模拟空战场景，旨在识别有效的行动方案以低成本和安全方式探索真实防御情境。框架将决策分为两个层次：低层policies负责单个单位的实时控制，高层commander policy发布与整体任务目标一致的宏观命令，从而应对复杂飞行动态、状态和动作空间的挑战。训练过程采用递增复杂度的curriculum learning，先训练低层policies，然后基于预训练的控制政策训练高层commander。实验验证显示，该框架显著提升了空战策略的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as journal chapter in Deep Learning Applications, Vol. 1,\n  by Taylor & Francis",
      "pdf_url": "http://arxiv.org/pdf/2505.08995v1",
      "published_date": "2025-05-13 22:13:48 UTC",
      "updated_date": "2025-05-13 22:13:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:20:58.633394"
    },
    {
      "arxiv_id": "2505.08988v1",
      "title": "Generalization in Monitored Markov Decision Processes (Mon-MDPs)",
      "title_zh": "监控马尔可夫决策过程 (Mon-MDPs) 中的泛化",
      "authors": [
        "Montaser Mohammedalamen",
        "Michael Bowling"
      ],
      "abstract": "Reinforcement learning (RL) typically models the interaction between the\nagent and environment as a Markov decision process (MDP), where the rewards\nthat guide the agent's behavior are always observable. However, in many\nreal-world scenarios, rewards are not always observable, which can be modeled\nas a monitored Markov decision process (Mon-MDP). Prior work on Mon-MDPs have\nbeen limited to simple, tabular cases, restricting their applicability to\nreal-world problems. This work explores Mon-MDPs using function approximation\n(FA) and investigates the challenges involved. We show that combining function\napproximation with a learned reward model enables agents to generalize from\nmonitored states with observable rewards, to unmonitored environment states\nwith unobservable rewards. Therefore, we demonstrate that such generalization\nwith a reward model achieves near-optimal policies in environments formally\ndefined as unsolvable. However, we identify a critical limitation of such\nfunction approximation, where agents incorrectly extrapolate rewards due to\novergeneralization, resulting in undesirable behaviors. To mitigate\novergeneralization, we propose a cautious police optimization method leveraging\nreward uncertainty. This work serves as a step towards bridging this gap\nbetween Mon-MDP theory and real-world applications.",
      "tldr_zh": "本文探讨了Monitored Markov Decision Processes (Mon-MDPs)，一种强化学习环境，其中奖励并非总是可观测的，并使用函数逼近(FA)来解决传统方法的局限性。通过结合FA和学习奖励模型，研究表明代理能够从可观测奖励状态泛化到不可观测状态，从而在理论上不可解的环境中实现近似最优策略。然而，这种方法可能导致过度泛化并产生错误行为，为此作者提出了一种基于奖励不确定性的谨慎策略优化方法，以缓解这些问题。该工作为将Mon-MDP理论应用于真实世界场景奠定了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2505.08988v1",
      "published_date": "2025-05-13 21:58:25 UTC",
      "updated_date": "2025-05-13 21:58:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:21:11.999083"
    },
    {
      "arxiv_id": "2505.08964v1",
      "title": "GPML: Graph Processing for Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Majed Jaber",
        "Julien Michel",
        "Nicolas Boutry",
        "Pierre Parrend"
      ],
      "abstract": "The dramatic increase of complex, multi-step, and rapidly evolving attacks in\ndynamic networks involves advanced cyber-threat detectors. The GPML (Graph\nProcessing for Machine Learning) library addresses this need by transforming\nraw network traffic traces into graph representations, enabling advanced\ninsights into network behaviors. The library provides tools to detect anomalies\nin interaction and community shifts in dynamic networks. GPML supports\ncommunity and spectral metrics extraction, enhancing both real-time detection\nand historical forensics analysis. This library supports modern cybersecurity\nchallenges with a robust, graph-based approach.",
      "tldr_zh": "这篇论文介绍了 GPML 库（Graph Processing for Machine Learning），它通过将原始网络流量转化为图表示，来应对动态网络中复杂攻击的检测需求。GPML 提供工具支持异常交互检测、社区变化分析，以及社区和谱指标提取，从而提升实时检测和历史取证能力。该库采用图-based 方法，为现代网络安全挑战提供了稳健的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08964v1",
      "published_date": "2025-05-13 21:10:46 UTC",
      "updated_date": "2025-05-13 21:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:21:23.417931"
    },
    {
      "arxiv_id": "2505.08939v1",
      "title": "Tracing the Invisible: Understanding Students' Judgment in AI-Supported Design Work",
      "title_zh": "翻译失败",
      "authors": [
        "Suchismita Naik",
        "Prakash Shukla",
        "Ike Obi",
        "Jessica Backus",
        "Nancy Rasche",
        "Paul Parsons"
      ],
      "abstract": "As generative AI tools become integrated into design workflows, students\nincreasingly engage with these tools not just as aids, but as collaborators.\nThis study analyzes reflections from 33 student teams in an HCI design course\nto examine the kinds of judgments students make when using AI tools. We found\nboth established forms of design judgment (e.g., instrumental, appreciative,\nquality) and emergent types: agency-distribution judgment and reliability\njudgment. These new forms capture how students negotiate creative\nresponsibility with AI and assess the trustworthiness of its outputs. Our\nfindings suggest that generative AI introduces new layers of complexity into\ndesign reasoning, prompting students to reflect not only on what AI produces,\nbut also on how and when to rely on it. By foregrounding these judgments, we\noffer a conceptual lens for understanding how students engage in co-creative\nsensemaking with AI in design contexts.",
      "tldr_zh": "本研究分析了33个学生团队在HCI设计课程中使用生成式AI工具时的判断类型，通过考察他们的反思，识别出既有设计判断（如工具性、欣赏性和质量判断）以及新兴判断形式，包括agency-distribution judgment和reliability judgment。agency-distribution judgment涉及学生与AI协商创意责任，而reliability judgment则评估AI输出的可信度。这些发现揭示了AI在设计流程中引入的复杂性，促使学生反思AI的产出及其依赖时机。该框架为理解学生在设计上下文中与AI进行共同创造性意义构建提供了新的概念视角。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "5 pages, 2 Tables, In Creativity and Cognition 2025, June 23--25,\n  2025, Virtual, United Kingdom",
      "pdf_url": "http://arxiv.org/pdf/2505.08939v1",
      "published_date": "2025-05-13 20:08:10 UTC",
      "updated_date": "2025-05-13 20:08:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:21:35.824822"
    },
    {
      "arxiv_id": "2505.08919v1",
      "title": "Template-Guided Reconstruction of Pulmonary Segments with Neural Implicit Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Kangxian Xie",
        "Yufei Zhu",
        "Kaiming Kuang",
        "Li Zhang",
        "Hongwei Bran Li",
        "Mingchen Gao",
        "Jiancheng Yang"
      ],
      "abstract": "High-quality 3D reconstruction of pulmonary segments plays a crucial role in\nsegmentectomy and surgical treatment planning for lung cancer. Due to the\nresolution requirement of the target reconstruction, conventional deep\nlearning-based methods often suffer from computational resource constraints or\nlimited granularity. Conversely, implicit modeling is favored due to its\ncomputational efficiency and continuous representation at any resolution. We\npropose a neural implicit function-based method to learn a 3D surface to\nachieve anatomy-aware, precise pulmonary segment reconstruction, represented as\na shape by deforming a learnable template. Additionally, we introduce two\nclinically relevant evaluation metrics to assess the reconstruction\ncomprehensively. Further, due to the absence of publicly available shape\ndatasets to benchmark reconstruction algorithms, we developed a shape dataset\nnamed Lung3D, including the 3D models of 800 labeled pulmonary segments and the\ncorresponding airways, arteries, veins, and intersegmental veins. We\ndemonstrate that the proposed approach outperforms existing methods, providing\na new perspective for pulmonary segment reconstruction. Code and data will be\navailable at https://github.com/M3DV/ImPulSe.",
      "tldr_zh": "该论文提出了一种基于neural implicit functions的模板引导方法，用于精确重建肺段的3D表面，实现anatomy-aware的肺癌手术规划。该方法通过变形一个可学习的模板来处理传统深度学习方法的计算资源限制和颗粒度问题，并引入了两个临床相关的评估指标进行全面评估。为了支持基准测试，研究团队开发了Lung3D数据集，包含800个标记的肺段3D模型及其相关结构，如airways、arteries、veins和intersegmental veins。实验结果表明，该方法优于现有技术，为肺段重建提供了新视角。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "In revision process",
      "pdf_url": "http://arxiv.org/pdf/2505.08919v1",
      "published_date": "2025-05-13 19:31:01 UTC",
      "updated_date": "2025-05-13 19:31:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:21:47.905893"
    },
    {
      "arxiv_id": "2505.08918v1",
      "title": "When repeats drive the vocabulary: a Byte-Pair Encoding analysis of T2T primate genomes",
      "title_zh": "翻译失败",
      "authors": [
        "Marina Popova",
        "Iaroslav Chelombitko",
        "Aleksey Komissarov"
      ],
      "abstract": "The emergence of telomere-to-telomere (T2T) genome assemblies has opened new\navenues for comparative genomics, yet effective tokenization strategies for\ngenomic sequences remain underexplored. In this pilot study, we apply Byte Pair\nEncoding (BPE) to nine T2T primate genomes including three human assemblies by\ntraining independent BPE tokenizers with a fixed vocabulary of 512,000 tokens\nusing our custom tool, dnaBPE. Our analysis reveals that only 11,569 tokens are\nshared across all assemblies, while nearly 991,854 tokens are unique to a\nsingle genome, indicating a rapid decline in shared vocabulary with increasing\nassembly comparisons. Moreover, phylogenetic trees derived from token overlap\nfailed to recapitulate established primate relationships, a discrepancy\nattributed to the disproportionate influence of species-specific high-copy\nrepetitive elements. These findings underscore the dual nature of BPE\ntokenization: while it effectively compresses repetitive sequences, its\nsensitivity to high-copy elements limits its utility as a universal tool for\ncomparative genomics. We discuss potential hybrid strategies and repeat-masking\napproaches to refine genomic tokenization, emphasizing the need for\ndomain-specific adaptations in the development of large-scale genomic language\nmodels. The dnaBPE tool used in this study is open-source and available at\nhttps://github.com/aglabx/dnaBPE.",
      "tldr_zh": "本研究使用 Byte-Pair Encoding (BPE) 分析了九个 T2T 灵长类基因组，包括三个人类组装，通过自定义工具 dnaBPE 训练独立标记器，发现仅 11,569 个标记在所有组装中共享，而近 991,854 个标记是独有的，导致基于标记重叠构建的系统发育树无法重现已知灵长类关系，主要归因于物种特异的高拷贝重复元素的影响。研究强调 BPE 在压缩重复序列方面有效，但其对高拷贝元素的敏感性限制了其在比较基因组学中的应用，并提出采用混合策略和重复屏蔽方法来改进基因组标记化，以支持大规模基因组语言模型的领域特定适应。该工具 dnaBPE 已开源，可在 GitHub 上获取。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "ICLR 2025 Workshop on Machine Learning for Genomics Explorations",
      "pdf_url": "http://arxiv.org/pdf/2505.08918v1",
      "published_date": "2025-05-13 19:27:58 UTC",
      "updated_date": "2025-05-13 19:27:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:22:00.515161"
    },
    {
      "arxiv_id": "2505.08916v1",
      "title": "A New Tractable Description Logic under Categorical Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Chan Le Duc",
        "Ludovic Brieulle"
      ],
      "abstract": "Biomedical ontologies contain numerous concept or role names involving\nnegative knowledge such as lacks_part, absence_of. Such a representation with\nlabels rather than logical constructors would not allow a reasoner to interpret\nlacks_part as a kind of negation of has_part. It is known that adding negation\nto the tractable Description Logic (DL) EL allowing for conjunction,\nexistential restriction and concept inclusion makes it intractable since the\nobtained logic includes implicitly disjunction and universal restriction which\ninteract with other constructors. In this paper, we propose a new extension of\nEL with a weakened negation allowing to represent negative knowledge while\nretaining tractability. To this end, we introduce categorical semantics of all\nlogical constructors of the DL SH including EL with disjunction, negation,\nuniversal restriction, role inclusion and transitive roles. The categorical\nsemantics of a logical constructor is usually described as a set of categorical\nproperties referring to several objects without using set membership. To\nrestore tractability, we have to weaken semantics of disjunction and universal\nrestriction by identifying \\emph{independent} categorical properties that are\nresponsible for intractability, and dropping them from the set of categorical\nproperties. We show that the logic resulting from weakening semantics is more\nexpressive than EL with the bottom concept, transitive roles and role\ninclusion.",
      "tldr_zh": "本论文针对生物医学本体中涉及负面知识（如 lacks_part）的表示问题，提出了一种 EL 描述逻辑（DL）的扩展，通过引入弱化的 negation 来表示负面知识，同时保持算法的可处理性（tractability）。作者引入了 SH 逻辑的 categorical semantics，对 disjunction 和 universal restriction 的语义进行弱化，具体是通过去除导致不可处理性的独立 categorical properties。结果表明，这种新逻辑比 EL（加上 bottom concept、transitive roles 和 role inclusion）更具表现力，为处理负面知识提供了高效的框架。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08916v1",
      "published_date": "2025-05-13 19:25:21 UTC",
      "updated_date": "2025-05-13 19:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:22:11.373249"
    },
    {
      "arxiv_id": "2505.09653v1",
      "title": "Differentiable Quantum Architecture Search in Quantum-Enhanced Neural Network Parameter Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Yen-Chi Chen",
        "Chen-Yu Liu",
        "Kuan-Cheng Chen",
        "Wei-Jia Huang",
        "Yen-Jui Chang",
        "Wei-Hao Huang"
      ],
      "abstract": "The rapid advancements in quantum computing (QC) and machine learning (ML)\nhave led to the emergence of quantum machine learning (QML), which integrates\nthe strengths of both fields. Among QML approaches, variational quantum\ncircuits (VQCs), also known as quantum neural networks (QNNs), have shown\npromise both empirically and theoretically. However, their broader adoption is\nhindered by reliance on quantum hardware during inference. Hardware\nimperfections and limited access to quantum devices pose practical challenges.\nTo address this, the Quantum-Train (QT) framework leverages the exponential\nscaling of quantum amplitudes to generate classical neural network parameters,\nenabling inference without quantum hardware and achieving significant parameter\ncompression. Yet, designing effective quantum circuit architectures for such\nquantum-enhanced neural programmers remains non-trivial and often requires\nexpertise in quantum information science. In this paper, we propose an\nautomated solution using differentiable optimization. Our method jointly\noptimizes both conventional circuit parameters and architectural parameters in\nan end-to-end manner via automatic differentiation. We evaluate the proposed\nframework on classification, time-series prediction, and reinforcement learning\ntasks. Simulation results show that our method matches or outperforms manually\ndesigned QNN architectures. This work offers a scalable and automated pathway\nfor designing QNNs that can generate classical neural network parameters across\ndiverse applications.",
      "tldr_zh": "该论文探讨了量子机器学习（QML）中的变分量子电路（VQCs），也称量子神经网络（QNNs），其受限于量子硬件依赖的问题。作者提出一种基于可微优化（Differentiable Optimization）的量子架构搜索方法，通过端到端自动微分联合优化电路参数和架构参数，从而自动设计量子增强神经网络参数生成框架。实验结果显示，该方法在分类、时间序列预测和强化学习任务上与手动设计的 QNN 架构相当或更优，为跨领域应用的 QNN 设计提供了可扩展的自动化途径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09653v1",
      "published_date": "2025-05-13 19:01:08 UTC",
      "updated_date": "2025-05-13 19:01:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:22:25.289960"
    },
    {
      "arxiv_id": "2505.08905v2",
      "title": "Grounding Synthetic Data Evaluations of Language Models in Unsupervised Document Corpora",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Majurski",
        "Cynthia Matuszek"
      ],
      "abstract": "Language Models (LMs) continue to advance, improving response quality and\ncoherence. Given Internet-scale training datasets, LMs have likely encountered\nmuch of what users may ask them to generate in some form during their training.\nA plethora of evaluation benchmarks have been constructed to assess model\nquality, response appropriateness, and reasoning capabilities. However, the\nhuman effort required for benchmark construction is rapidly being outpaced by\nthe size and scope of the models under evaluation. Having humans build a\nbenchmark for every possible domain of interest is impractical. Therefore, we\npropose a methodology for automating the construction of fact-based synthetic\ndata model evaluations grounded in document populations. This work leverages\nthe same LMs to evaluate domain-specific knowledge automatically, using only\ngrounding documents (e.g., a textbook) as input. This synthetic data\nbenchmarking approach corresponds well with human curated questions producing a\nSpearman ranking correlation of 0.97 and a benchmark evaluation Pearson\naccuracy correlation of 0.75. This novel approach supports generating both\nmultiple choice and open-ended synthetic data questions to gain diagnostic\ninsight of LM capability. We apply this methodology to evaluate model\nperformance on two recent arXiv preprints, discovering a surprisingly strong\nperformance from Gemma-3 models on open-ended questions. Code is available at\nhttps://github.com/mmajurski/grounded-synth-lm-benchmark",
      "tldr_zh": "该论文提出了一种自动化方法，用于在无监督文档语料库中构建基于事实的合成数据基准，以评估Language Models (LMs)的性能。该方法利用LMs自身生成和评估领域特定知识，仅需grounding documents（如教科书）作为输入，支持创建多选题和开放式问题，提供对模型能力的诊断洞察。实验结果显示，该合成数据基准与人工基准高度一致，Spearman ranking correlation达0.97，Pearson accuracy correlation达0.75，并在两个arXiv预印本上评估中发现Gemma-3 models在开放式问题上表现出色。代码可在https://github.com/mmajurski/grounded-synth-lm-benchmark获取。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08905v2",
      "published_date": "2025-05-13 18:50:03 UTC",
      "updated_date": "2025-05-16 01:35:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:22:35.398875"
    },
    {
      "arxiv_id": "2505.08904v1",
      "title": "FareShare: A Tool for Labor Organizers to Estimate Lost Wages and Contest Arbitrary AI and Algorithmic Deactivations",
      "title_zh": "翻译失败",
      "authors": [
        "Varun Nagaraj Rao",
        "Samantha Dalal",
        "Andrew Schwartz",
        "Amna Liaqat",
        "Dana Calacci",
        "Andrés Monroy-Hernández"
      ],
      "abstract": "What happens when a rideshare driver is suddenly locked out of the platform\nconnecting them to riders, wages, and daily work? Deactivation-the abrupt\nremoval of gig workers' platform access-typically occurs through arbitrary AI\nand algorithmic decisions with little explanation or recourse. This represents\none of the most severe forms of algorithmic control and often devastates\nworkers' financial stability. Recent U.S. state policies now mandate appeals\nprocesses and recovering compensation during the period of wrongful\ndeactivation based on past earnings. Yet, labor organizers still lack effective\ntools to support these complex, error-prone workflows. We designed FareShare, a\ncomputational tool automating lost wage estimation for deactivated drivers,\nthrough a 6 month partnership with the State of Washington's largest rideshare\nlabor union. Over the following 3 months, our field deployment of FareShare\nregistered 178 account signups. We observed that the tool could reduce lost\nwage calculation time by over 95%, eliminate manual data entry errors, and\nenable legal teams to generate arbitration-ready reports more efficiently.\nBeyond these gains, the deployment also surfaced important socio-technical\nchallenges around trust, consent, and tool adoption in high-stakes labor\ncontexts.",
      "tldr_zh": "本研究介绍了 FareShare，一款专为劳工组织者设计的工具，用于估算因 AI 和 algorithmic deactivations 导致的失工资，并协助争端解决。工具通过与华盛顿州最大骑手工会的6个月合作开发，自动化计算失工资流程，显著减少手动数据输入错误。部署后，FareShare 吸引了178个账户注册，将计算时间缩短95%以上，并提升法律团队生成仲裁报告的效率。该工具不仅提高了工作效率，还揭示了在高风险劳工环境中信任、同意和工具采用等社会技术挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08904v1",
      "published_date": "2025-05-13 18:46:47 UTC",
      "updated_date": "2025-05-13 18:46:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:22:46.861142"
    },
    {
      "arxiv_id": "2505.08902v1",
      "title": "Performance Gains of LLMs With Humans in a World of LLMs Versus Humans",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas McCullum",
        "Pelagie Ami Agassi",
        "Leo Anthony Celi",
        "Daniel K. Ebner",
        "Chrystinne Oliveira Fernandes",
        "Rachel S. Hicklen",
        "Mkliwa Koumbia",
        "Lisa Soleymani Lehmann",
        "David Restrepo"
      ],
      "abstract": "Currently, a considerable research effort is devoted to comparing LLMs to a\ngroup of human experts, where the term \"expert\" is often ill-defined or\nvariable, at best, in a state of constantly updating LLM releases. Without\nproper safeguards in place, LLMs will threaten to cause harm to the established\nstructure of safe delivery of patient care which has been carefully developed\nthroughout history to keep the safety of the patient at the forefront. A key\ndriver of LLM innovation is founded on community research efforts which, if\ncontinuing to operate under \"humans versus LLMs\" principles, will expedite this\ntrend. Therefore, research efforts moving forward must focus on effectively\ncharacterizing the safe use of LLMs in clinical settings that persist across\nthe rapid development of novel LLM models. In this communication, we\ndemonstrate that rather than comparing LLMs to humans, there is a need to\ndevelop strategies enabling efficient work of humans with LLMs in an almost\nsymbiotic manner.",
      "tldr_zh": "该研究指出，目前的大语言模型（LLMs）与人类专家的比较研究存在问题，“专家”定义模糊且LLMs不断更新，这可能威胁到临床患者护理的安全结构。作者强调，如果继续采用“人类对抗LLMs”的框架，将加速负面趋势，因此未来研究应聚焦于开发策略，确保LLMs在临床环境中的安全应用。论文主张转变为“人类与LLMs”协同合作模式，形成一种高效的共生关系，以实现持续的性能提升和安全保障。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08902v1",
      "published_date": "2025-05-13 18:44:22 UTC",
      "updated_date": "2025-05-13 18:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:22:58.448004"
    },
    {
      "arxiv_id": "2505.08896v1",
      "title": "Deep reinforcement learning-based longitudinal control strategy for automated vehicles at signalised intersections",
      "title_zh": "翻译失败",
      "authors": [
        "Pankaj Kumar",
        "Aditya Mishra",
        "Pranamesh Chakraborty",
        "Subrahmanya Swamy Peruru"
      ],
      "abstract": "Developing an autonomous vehicle control strategy for signalised\nintersections (SI) is one of the challenging tasks due to its inherently\ncomplex decision-making process. This study proposes a Deep Reinforcement\nLearning (DRL) based longitudinal vehicle control strategy at SI. A\ncomprehensive reward function has been formulated with a particular focus on\n(i) distance headway-based efficiency reward, (ii) decision-making criteria\nduring amber light, and (iii) asymmetric acceleration/ deceleration response,\nalong with the traditional safety and comfort criteria. This reward function\nhas been incorporated with two popular DRL algorithms, Deep Deterministic\nPolicy Gradient (DDPG) and Soft-Actor Critic (SAC), which can handle the\ncontinuous action space of acceleration/deceleration. The proposed models have\nbeen trained on the combination of real-world leader vehicle (LV) trajectories\nand simulated trajectories generated using the Ornstein-Uhlenbeck (OU) process.\nThe overall performance of the proposed models has been tested using Cumulative\nDistribution Function (CDF) plots and compared with the real-world trajectory\ndata. The results show that the RL models successfully maintain lower distance\nheadway (i.e., higher efficiency) and jerk compared to human-driven vehicles\nwithout compromising safety. Further, to assess the robustness of the proposed\nmodels, we evaluated the model performance on diverse safety-critical\nscenarios, in terms of car-following and traffic signal compliance. Both DDPG\nand SAC models successfully handled the critical scenarios, while the DDPG\nmodel showed smoother action profiles compared to the SAC model. Overall, the\nresults confirm that DRL-based longitudinal vehicle control strategy at SI can\nhelp to improve traffic safety, efficiency, and comfort.",
      "tldr_zh": "这篇论文提出了一种基于 Deep Reinforcement Learning (DRL) 的纵向控制策略，用于自动车辆在信号灯交叉口 (SI) 的决策，旨在处理其复杂性。研究设计了一个全面的奖励函数，包括距离头距效率奖励、琥珀灯决策标准、非对称加/减速响应，以及安全和舒适标准，并结合 DDPG 和 SAC 算法处理连续动作空间。实验结果显示，该策略在真实和模拟轨迹上训练后，比人类驾驶车辆实现了更高的效率和更低的颠簸，同时确保安全，并在多样安全关键场景中表现出色，证明了其在改善交通安全、效率和舒适方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08896v1",
      "published_date": "2025-05-13 18:38:42 UTC",
      "updated_date": "2025-05-13 18:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:23:12.589048"
    },
    {
      "arxiv_id": "2505.08894v1",
      "title": "WaLLM -- Insights from an LLM-Powered Chatbot deployment via WhatsApp",
      "title_zh": "WaLLM：通过 WhatsApp 部署的 LLM 驱动聊天机器人的洞见",
      "authors": [
        "Hiba Eltigani",
        "Rukhshan Haroon",
        "Asli Kocak",
        "Abdullah Bin Faisal",
        "Noah Martin",
        "Fahad Dogar"
      ],
      "abstract": "Recent advances in generative AI, such as ChatGPT, have transformed access to\ninformation in education, knowledge-seeking, and everyday decision-making.\nHowever, in many developing regions, access remains a challenge due to the\npersistent digital divide. To help bridge this gap, we developed WaLLM - a\ncustom AI chatbot over WhatsApp, a widely used communication platform in\ndeveloping regions. Beyond answering queries, WaLLM offers several features to\nenhance user engagement: a daily top question, suggested follow-up questions,\ntrending and recent queries, and a leaderboard-based reward system. Our service\nhas been operational for over 6 months, amassing over 14.7K queries from\napproximately 100 users. In this paper, we present WaLLM's design and a\nsystematic analysis of logs to understand user interactions. Our results show\nthat 55% of user queries seek factual information. \"Health and well-being\" was\nthe most popular topic (28%), including queries about nutrition and disease,\nsuggesting users view WaLLM as a reliable source. Two-thirds of users' activity\noccurred within 24 hours of the daily top question. Users who accessed the\n\"Leaderboard\" interacted with WaLLM 3x as those who did not. We conclude by\ndiscussing implications for culture-based customization, user interface design,\nand appropriate calibration of users' trust in AI systems for developing\nregions.",
      "tldr_zh": "本研究开发了WaLLM，一种基于LLM的聊天机器人，通过WhatsApp平台在发展中国家提供信息访问服务，以桥接数字鸿沟。该系统包括回答查询、每日热门问题、建议后续问题、趋势查询以及排行榜奖励机制，已运行6个月，处理了14.7K条查询。分析结果显示，55%的用户查询涉及事实信息，“健康和福祉”主题占比28%，且三分之二的用户活动发生在每日热门问题后的24小时内，使用排行榜的用户互动频率高出3倍。论文讨论了针对发展地区的文化定制、用户界面设计以及校准用户对AI信任的启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08894v1",
      "published_date": "2025-05-13 18:36:18 UTC",
      "updated_date": "2025-05-13 18:36:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:23:26.013966"
    },
    {
      "arxiv_id": "2505.08878v1",
      "title": "Optimized Couplings for Watermarking Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dor Tsur",
        "Carol Xuan Long",
        "Claudio Mayrink Verdun",
        "Hsiang Hsu",
        "Haim Permuter",
        "Flavio P. Calmon"
      ],
      "abstract": "Large-language models (LLMs) are now able to produce text that is, in many\ncases, seemingly indistinguishable from human-generated content. This has\nfueled the development of watermarks that imprint a ``signal'' in LLM-generated\ntext with minimal perturbation of an LLM's output. This paper provides an\nanalysis of text watermarking in a one-shot setting. Through the lens of\nhypothesis testing with side information, we formulate and analyze the\nfundamental trade-off between watermark detection power and distortion in\ngenerated textual quality. We argue that a key component in watermark design is\ngenerating a coupling between the side information shared with the watermark\ndetector and a random partition of the LLM vocabulary. Our analysis identifies\nthe optimal coupling and randomization strategy under the worst-case LLM\nnext-token distribution that satisfies a min-entropy constraint. We provide a\nclosed-form expression of the resulting detection rate under the proposed\nscheme and quantify the cost in a max-min sense. Finally, we provide an array\nof numerical results, comparing the proposed scheme with the theoretical\noptimum and existing schemes, in both synthetic data and LLM watermarking. Our\ncode is available at https://github.com/Carol-Long/CC_Watermark",
      "tldr_zh": "这篇论文分析了大型语言模型(LLMs)生成文本中水印技术的优化问题，聚焦于检测能力和文本质量扭曲之间的根本权衡，通过假设测试和附带信息的视角进行建模。作者提出了最优耦合策略，将共享给检测器的附带信息与LLMs词汇表的随机分区相结合，并在最坏情况下的LLMs下一 token 分布下，给出了检测率的闭合表达式。实验结果显示，该方案在合成数据和实际LLMs水印应用中优于现有方法，并提供了开源代码以供验证。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at ISIT25",
      "pdf_url": "http://arxiv.org/pdf/2505.08878v1",
      "published_date": "2025-05-13 18:08:12 UTC",
      "updated_date": "2025-05-13 18:08:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:23:36.205276"
    },
    {
      "arxiv_id": "2505.08854v1",
      "title": "Generative AI for Autonomous Driving: Frontiers and Opportunities",
      "title_zh": "生成式 AI 用于自动驾驶：前沿与机会",
      "authors": [
        "Yuping Wang",
        "Shuo Xing",
        "Cui Can",
        "Renjie Li",
        "Hongyuan Hua",
        "Kexin Tian",
        "Zhaobin Mo",
        "Xiangbo Gao",
        "Keshu Wu",
        "Sulong Zhou",
        "Hengxu You",
        "Juntong Peng",
        "Junge Zhang",
        "Zehao Wang",
        "Rui Song",
        "Mingxuan Yan",
        "Walter Zimmer",
        "Xingcheng Zhou",
        "Peiran Li",
        "Zhaohan Lu",
        "Chia-Ju Chen",
        "Yue Huang",
        "Ryan A. Rossi",
        "Lichao Sun",
        "Hongkai Yu",
        "Zhiwen Fan",
        "Frank Hao Yang",
        "Yuhao Kang",
        "Ross Greer",
        "Chenxi Liu",
        "Eun Hak Lee",
        "Xuan Di",
        "Xinyue Ye",
        "Liu Ren",
        "Alois Knoll",
        "Xiaopeng Li",
        "Shuiwang Ji",
        "Masayoshi Tomizuka",
        "Marco Pavone",
        "Tianbao Yang",
        "Jing Du",
        "Ming-Hsuan Yang",
        "Hua Wei",
        "Ziran Wang",
        "Yang Zhou",
        "Jiachen Li",
        "Zhengzhong Tu"
      ],
      "abstract": "Generative Artificial Intelligence (GenAI) constitutes a transformative\ntechnological wave that reconfigures industries through its unparalleled\ncapabilities for content creation, reasoning, planning, and multimodal\nunderstanding. This revolutionary force offers the most promising path yet\ntoward solving one of engineering's grandest challenges: achieving reliable,\nfully autonomous driving, particularly the pursuit of Level 5 autonomy. This\nsurvey delivers a comprehensive and critical synthesis of the emerging role of\nGenAI across the autonomous driving stack. We begin by distilling the\nprinciples and trade-offs of modern generative modeling, encompassing VAEs,\nGANs, Diffusion Models, and Large Language Models (LLMs). We then map their\nfrontier applications in image, LiDAR, trajectory, occupancy, video generation\nas well as LLM-guided reasoning and decision making. We categorize practical\napplications, such as synthetic data workflows, end-to-end driving strategies,\nhigh-fidelity digital twin systems, smart transportation networks, and\ncross-domain transfer to embodied AI. We identify key obstacles and\npossibilities such as comprehensive generalization across rare cases,\nevaluation and safety checks, budget-limited implementation, regulatory\ncompliance, ethical concerns, and environmental effects, while proposing\nresearch plans across theoretical assurances, trust metrics, transport\nintegration, and socio-technical influence. By unifying these threads, the\nsurvey provides a forward-looking reference for researchers, engineers, and\npolicymakers navigating the convergence of generative AI and advanced\nautonomous mobility. An actively maintained repository of cited works is\navailable at https://github.com/taco-group/GenAI4AD.",
      "tldr_zh": "这篇调查论文探讨了Generative AI (GenAI) 在自动驾驶领域的潜力，特别是实现可靠的Level 5自治。论文总结了现代生成模型的原理和权衡，包括VAEs、GANs、Diffusion Models和Large Language Models (LLMs)，并映射了它们在图像、LiDAR、轨迹生成以及LLM引导决策中的前沿应用，如合成数据工作流、端到端驾驶策略和高保真数字孪生系统。作者识别了关键挑战包括泛化能力、评估安全、伦理问题和环境影响，并提出了研究方向，如理论保证、交通集成和社会技术影响，以推动GenAI在自动驾驶中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08854v1",
      "published_date": "2025-05-13 17:59:20 UTC",
      "updated_date": "2025-05-13 17:59:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:23:48.353789"
    },
    {
      "arxiv_id": "2505.08783v1",
      "title": "CodePDE: An Inference Framework for LLM-driven PDE Solver Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shanda Li",
        "Tanya Marwah",
        "Junhong Shen",
        "Weiwei Sun",
        "Andrej Risteski",
        "Yiming Yang",
        "Ameet Talwalkar"
      ],
      "abstract": "Partial differential equations (PDEs) are fundamental to modeling physical\nsystems, yet solving them remains a complex challenge. Traditional numerical\nsolvers rely on expert knowledge to implement and are computationally\nexpensive, while neural-network-based solvers require large training datasets\nand often lack interpretability. In this work, we frame PDE solving as a code\ngeneration task and introduce CodePDE, the first inference framework for\ngenerating PDE solvers using large language models (LLMs). Leveraging advanced\ninference-time algorithms and scaling strategies, CodePDE unlocks critical\ncapacities of LLM for PDE solving: reasoning, debugging, selfrefinement, and\ntest-time scaling -- all without task-specific tuning. CodePDE achieves\nsuperhuman performance across a range of representative PDE problems. We also\npresent a systematic empirical analysis of LLM generated solvers, analyzing\ntheir accuracy, efficiency, and numerical scheme choices. Our findings\nhighlight the promise and the current limitations of LLMs in PDE solving,\noffering a new perspective on solver design and opportunities for future model\ndevelopment. Our code is available at https://github.com/LithiumDA/CodePDE.",
      "tldr_zh": "该研究将偏微分方程 (PDE) 求解转化为代码生成任务，引入 CodePDE 框架，这是首个利用大型语言模型 (LLMs) 生成 PDE 求解器的推理框架。CodePDE 通过高级推理时算法和缩放策略，启用 LLMs 的关键能力，包括推理、调试、自我改进和测试时缩放，而无需任务特定微调。实验结果显示，CodePDE 在多种代表性 PDE 问题上实现了超人性能，并通过系统实证分析评估了生成求解器的准确性、效率和数值方案选择。该框架突出了 LLMs 在 PDE 求解中的潜力，同时指出了其当前局限性，并为未来求解器设计提供新视角。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08783v1",
      "published_date": "2025-05-13 17:58:08 UTC",
      "updated_date": "2025-05-13 17:58:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:24:01.503191"
    },
    {
      "arxiv_id": "2505.08778v1",
      "title": "ARC-NCA: Towards Developmental Solutions to the Abstraction and Reasoning Corpus",
      "title_zh": "翻译失败",
      "authors": [
        "Etienne Guichard",
        "Felix Reimers",
        "Mia Kvalsund",
        "Mikkel Lepperød",
        "Stefano Nichele"
      ],
      "abstract": "The Abstraction and Reasoning Corpus (ARC), later renamed ARC-AGI, poses a\nfundamental challenge in artificial general intelligence (AGI), requiring\nsolutions that exhibit robust abstraction and reasoning capabilities across\ndiverse tasks, while only few (with median count of three) correct examples are\npresented. While ARC-AGI remains very challenging for artificial intelligence\nsystems, it is rather easy for humans. This paper introduces ARC-NCA, a\ndevelopmental approach leveraging standard Neural Cellular Automata (NCA) and\nNCA enhanced with hidden memories (EngramNCA) to tackle the ARC-AGI benchmark.\nNCAs are employed for their inherent ability to simulate complex dynamics and\nemergent patterns, mimicking developmental processes observed in biological\nsystems. Developmental solutions may offer a promising avenue for enhancing\nAI's problem-solving capabilities beyond mere training data extrapolation.\nARC-NCA demonstrates how integrating developmental principles into\ncomputational models can foster adaptive reasoning and abstraction. We show\nthat our ARC-NCA proof-of-concept results may be comparable to, and sometimes\nsurpass, that of ChatGPT 4.5, at a fraction of the cost.",
      "tldr_zh": "这篇论文提出了 ARC-NCA，一种基于开发性方法的框架，用于解决 Abstraction and Reasoning Corpus (ARC-AGI) 基准，该基准要求 AI 在仅有少量示例（如中位数三个）的情况下进行鲁棒的抽象和推理。ARC-NCA 利用标准 Neural Cellular Automata (NCA) 和其增强版 EngramNCA 来模拟生物系统的复杂动态和新兴模式，从而提升 AI 的适应性问题解决能力。实验结果显示，该方法的初步性能可与 ChatGPT 4.5 相当或优于它，且计算成本更低，为 AI 超越训练数据外推的局限提供了新方向。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08778v1",
      "published_date": "2025-05-13 17:55:43 UTC",
      "updated_date": "2025-05-13 17:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:24:13.138869"
    },
    {
      "arxiv_id": "2505.08765v2",
      "title": "Towards Autonomous UAV Visual Object Search in City Space: Benchmark and Agentic Methodology",
      "title_zh": "翻译失败",
      "authors": [
        "Yatai Ji",
        "Zhengqiu Zhu",
        "Yong Zhao",
        "Beidan Liu",
        "Chen Gao",
        "Yihao Zhao",
        "Sihang Qiu",
        "Yue Hu",
        "Quanjun Yin",
        "Yong Li"
      ],
      "abstract": "Aerial Visual Object Search (AVOS) tasks in urban environments require\nUnmanned Aerial Vehicles (UAVs) to autonomously search for and identify target\nobjects using visual and textual cues without external guidance. Existing\napproaches struggle in complex urban environments due to redundant semantic\nprocessing, similar object distinction, and the exploration-exploitation\ndilemma. To bridge this gap and support the AVOS task, we introduce CityAVOS,\nthe first benchmark dataset for autonomous search of common urban objects. This\ndataset comprises 2,420 tasks across six object categories with varying\ndifficulty levels, enabling comprehensive evaluation of UAV agents' search\ncapabilities. To solve the AVOS tasks, we also propose PRPSearcher\n(Perception-Reasoning-Planning Searcher), a novel agentic method powered by\nmulti-modal large language models (MLLMs) that mimics human three-tier\ncognition. Specifically, PRPSearcher constructs three specialized maps: an\nobject-centric dynamic semantic map enhancing spatial perception, a 3D\ncognitive map based on semantic attraction values for target reasoning, and a\n3D uncertainty map for balanced exploration-exploitation search. Also, our\napproach incorporates a denoising mechanism to mitigate interference from\nsimilar objects and utilizes an Inspiration Promote Thought (IPT) prompting\nmechanism for adaptive action planning. Experimental results on CityAVOS\ndemonstrate that PRPSearcher surpasses existing baselines in both success rate\nand search efficiency (on average: +37.69% SR, +28.96% SPL, -30.69% MSS, and\n-46.40% NE). While promising, the performance gap compared to humans highlights\nthe need for better semantic reasoning and spatial exploration capabilities in\nAVOS tasks. This work establishes a foundation for future advances in embodied\ntarget search. Dataset and source code are available at\nhttps://anonymous.4open.science/r/CityAVOS-3DF8.",
      "tldr_zh": "本文针对城市环境中无人机的自主视觉物体搜索(AVOS)任务，引入了首个基准数据集CityAVOS，该数据集包含2,420个任务，涵盖六类常见物体和不同难度水平，用于全面评估UAV代理的搜索能力。作者提出PRPSearcher方法，该方法基于多模态大语言模型(MLLMs)模仿人类三层认知，构建物体中心动态语义地图、基于语义吸引值的3D认知地图和3D不确定性地图，并通过去噪机制和Inspiration Promote Thought(IPT)提示机制实现平衡探索-利用和自适应行动规划。在CityAVOS基准上的实验结果显示，PRPSearcher成功率提升37.69%、SPL提升28.96%、MSS降低30.69%和NE降低46.40%，显著优于现有基线，但与人类相比仍存在差距，强调未来需加强语义推理和空间探索能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08765v2",
      "published_date": "2025-05-13 17:34:54 UTC",
      "updated_date": "2025-05-14 01:30:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:24:28.204848"
    },
    {
      "arxiv_id": "2505.08747v1",
      "title": "Advancing Food Nutrition Estimation via Visual-Ingredient Feature Fusion",
      "title_zh": "通过视觉-成分特征融合推进食物营养估算",
      "authors": [
        "Huiyan Qi",
        "Bin Zhu",
        "Chong-Wah Ngo",
        "Jingjing Chen",
        "Ee-Peng Lim"
      ],
      "abstract": "Nutrition estimation is an important component of promoting healthy eating\nand mitigating diet-related health risks. Despite advances in tasks such as\nfood classification and ingredient recognition, progress in nutrition\nestimation is limited due to the lack of datasets with nutritional annotations.\nTo address this issue, we introduce FastFood, a dataset with 84,446 images\nacross 908 fast food categories, featuring ingredient and nutritional\nannotations. In addition, we propose a new model-agnostic Visual-Ingredient\nFeature Fusion (VIF$^2$) method to enhance nutrition estimation by integrating\nvisual and ingredient features. Ingredient robustness is improved through\nsynonym replacement and resampling strategies during training. The\ningredient-aware visual feature fusion module combines ingredient features and\nvisual representation to achieve accurate nutritional prediction. During\ntesting, ingredient predictions are refined using large multimodal models by\ndata augmentation and majority voting. Our experiments on both FastFood and\nNutrition5k datasets validate the effectiveness of our proposed method built in\ndifferent backbones (e.g., Resnet, InceptionV3 and ViT), which demonstrates the\nimportance of ingredient information in nutrition estimation.\nhttps://huiyanqi.github.io/fastfood-nutrition-estimation/.",
      "tldr_zh": "该论文介绍了 FastFood 数据集，该数据集包含 84,446 张图像、908 个快餐类别，并附带成分和营养标注，以解决营养估算领域数据缺乏的问题。作者提出了一种模型无关的方法 Visual-Ingredient Feature Fusion (VIF²)，通过整合视觉特征和成分特征、利用同义词替换、重采样策略以及成分感知融合模块来提升营养预测的准确性，并在测试时采用大型多模态模型进行成分预测精炼。实验在 FastFood 和 Nutrition5k 数据集上验证了 VIF² 的有效性，适用于不同骨干网络（如 Resnet、InceptionV3 和 ViT），证明了成分信息在营养估算中的关键作用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for publication in ACM International Conference on\n  Multimedia Retrieval 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08747v1",
      "published_date": "2025-05-13 17:01:21 UTC",
      "updated_date": "2025-05-13 17:01:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:24:36.452400"
    },
    {
      "arxiv_id": "2505.08744v1",
      "title": "DeepMath-Creative: A Benchmark for Evaluating Mathematical Creativity of Large Language Models",
      "title_zh": "DeepMath-Creative：用于评估大型语言模型数学创造力的基准",
      "authors": [
        "Xiaoyang Chen",
        "Xinan Dai",
        "Yu Du",
        "Qian Feng",
        "Naixu Guo",
        "Tingshuo Gu",
        "Yuting Gao",
        "Yingyi Gao",
        "Xudong Han",
        "Xiang Jiang",
        "Yilin Jin",
        "Hongyi Lin",
        "Shisheng Lin",
        "Xiangnan Li",
        "Yuante Li",
        "Yixing Li",
        "Zhentao Lai",
        "Zilu Ma",
        "Yingrong Peng",
        "Jiacheng Qian",
        "Hao-Yu Sun",
        "Jianbo Sun",
        "Zirui Wang",
        "Siwei Wu",
        "Zian Wang",
        "Bin Xu",
        "Jianghao Xu",
        "Yiyang Yu",
        "Zichuan Yang",
        "Hongji Zha",
        "Ruichong Zhang"
      ],
      "abstract": "To advance the mathematical proficiency of large language models (LLMs), the\nDeepMath team has launched an open-source initiative aimed at developing an\nopen mathematical LLM and systematically evaluating its mathematical\ncreativity. This paper represents the initial contribution of this initiative.\nWhile recent developments in mathematical LLMs have predominantly emphasized\nreasoning skills, as evidenced by benchmarks on elementary to\nundergraduate-level mathematical tasks, the creative capabilities of these\nmodels have received comparatively little attention, and evaluation datasets\nremain scarce. To address this gap, we propose an evaluation criteria for\nmathematical creativity and introduce DeepMath-Creative, a novel, high-quality\nbenchmark comprising constructive problems across algebra, geometry, analysis,\nand other domains. We conduct a systematic evaluation of mainstream LLMs'\ncreative problem-solving abilities using this dataset. Experimental results\nshow that even under lenient scoring criteria -- emphasizing core solution\ncomponents and disregarding minor inaccuracies, such as small logical gaps,\nincomplete justifications, or redundant explanations -- the best-performing\nmodel, O3 Mini, achieves merely 70% accuracy, primarily on basic\nundergraduate-level constructive tasks. Performance declines sharply on more\ncomplex problems, with models failing to provide substantive strategies for\nopen problems. These findings suggest that, although current LLMs display a\ndegree of constructive proficiency on familiar and lower-difficulty problems,\nsuch performance is likely attributable to the recombination of memorized\npatterns rather than authentic creative insight or novel synthesis.",
      "tldr_zh": "DeepMath 团队提出了一种开源倡议，开发开源数学大型语言模型(LLMs)并评估其数学创造力，本文作为该项目的初步贡献。论文引入 DeepMath-Creative 基准，这是一个高质量的评估数据集，包含代数、几何、分析等领域的高阶构造问题，并定义了数学创造力的评估标准。实验结果显示，即使采用宽松评分标准（如忽略小逻辑漏洞），最佳模型 O3 Mini 在基本本科级任务上仅达到 70% 准确率，而在更复杂或开放问题上表现急剧下降，无法提供实质性策略。这些发现表明，当前 LLMs 的创造力表现可能源于记忆模式的重组，而非真正的创新洞察。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08744v1",
      "published_date": "2025-05-13 16:58:05 UTC",
      "updated_date": "2025-05-13 16:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:24:48.959147"
    },
    {
      "arxiv_id": "2505.08728v2",
      "title": "Securing RAG: A Risk Assessment and Mitigation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Ammann",
        "Sara Ott",
        "Christoph R. Landolt",
        "Marco P. Lehmann"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) has emerged as the de facto industry\nstandard for user-facing NLP applications, offering the ability to integrate\ndata without re-training or fine-tuning Large Language Models (LLMs). This\ncapability enhances the quality and accuracy of responses but also introduces\nnovel security and privacy challenges, particularly when sensitive data is\nintegrated. With the rapid adoption of RAG, securing data and services has\nbecome a critical priority. This paper first reviews the vulnerabilities of RAG\npipelines, and outlines the attack surface from data pre-processing and data\nstorage management to integration with LLMs. The identified risks are then\npaired with corresponding mitigations in a structured overview. In a second\nstep, the paper develops a framework that combines RAG-specific security\nconsiderations, with existing general security guidelines, industry standards,\nand best practices. The proposed framework aims to guide the implementation of\nrobust, compliant, secure, and trustworthy RAG systems.",
      "tldr_zh": "该论文审视了Retrieval Augmented Generation (RAG)系统在整合数据时引入的安全和隐私挑战，特别是涉及敏感数据的情况。作者首先概述了RAG管道的漏洞，包括从数据预处理、存储管理到与Large Language Models (LLMs)集成的攻击面，并为这些风险提供了相应的缓解措施。最终，论文提出一个综合框架，将RAG特定的安全考虑与现有通用安全指南、行业标准和最佳实践相结合，以指导构建稳健、合规且可信的RAG系统。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 3 figures, Sara Ott and Lukas Ammann contributed equally.\n  This work has been submitted to the IEEE for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2505.08728v2",
      "published_date": "2025-05-13 16:39:00 UTC",
      "updated_date": "2025-05-21 09:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:25:00.074663"
    },
    {
      "arxiv_id": "2505.08727v1",
      "title": "Memorization-Compression Cycles Improve Generalization",
      "title_zh": "记忆-压缩循环改善泛化",
      "authors": [
        "Fangyuan Yu"
      ],
      "abstract": "We prove theoretically that generalization improves not only through data\nscaling but also by compressing internal representations. To operationalize\nthis insight, we introduce the Information Bottleneck Language Modeling (IBLM)\nobjective, which reframes language modeling as a constrained optimization\nproblem: minimizing representation entropy subject to optimal prediction\nperformance. Empirically, we observe an emergent memorization-compression cycle\nduring LLM pretraining, evidenced by oscillation positive/negative gradient\nalignment between cross-entropy and Matrix-Based Entropy (MBE), a measure of\nrepresentation entropy. This pattern closely mirrors the predictive-compressive\ntrade-off prescribed by IBLM and also parallels the biological alternation\nbetween awake learning and sleep consolidation. Motivated by this observation,\nwe propose Gated Phase Transition (GAPT), a training algorithm that adaptively\nswitches between memorization and compression phases. When applied to GPT-2\npretraining on FineWeb dataset, GAPT reduces MBE by 50% and improves\ncross-entropy by 4.8%. GAPT improves OOD generalizatino by 35% in a pretraining\ntask on arithmetic multiplication. In a setting designed to simulate\ncatastrophic forgetting, GAPT reduces interference by compressing and\nseparating representations, achieving a 97% improvement in separation -\nparalleling the functional role of sleep consolidation.",
      "tldr_zh": "本文证明，通过压缩内部表示不仅能改善模型泛化，还能与数据扩展相结合。研究者引入了 Information Bottleneck Language Modeling (IBLM) 目标，将语言建模重构为一个约束优化问题，即在保持最佳预测性能的同时最小化表示熵。实验观察到 LLM 预训练中出现记忆-压缩循环，这种现象类似于生物学的觉醒学习和睡眠巩固。基于此，他们提出 Gated Phase Transition (GAPT) 算法，自适应切换记忆和压缩阶段，结果显示 GAPT 在 GPT-2 预训练上减少 Matrix-Based Entropy (MBE) 50%，改善交叉熵 4.8%，并在算术任务中提升 OOD generalization 35%，同时在模拟灾难性遗忘场景中实现 97% 的表示分离改善。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08727v1",
      "published_date": "2025-05-13 16:37:54 UTC",
      "updated_date": "2025-05-13 16:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:25:14.108179"
    },
    {
      "arxiv_id": "2505.08719v1",
      "title": "PWC-MoE: Privacy-Aware Wireless Collaborative Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Su",
        "Na Yan",
        "Yansha Deng",
        "Robert Schober"
      ],
      "abstract": "Large language models (LLMs) hosted on cloud servers alleviate the\ncomputational and storage burdens on local devices but raise privacy concerns\ndue to sensitive data transmission and require substantial communication\nbandwidth, which is challenging in constrained environments. In contrast, small\nlanguage models (SLMs) running locally enhance privacy but suffer from limited\nperformance on complex tasks. To balance computational cost, performance, and\nprivacy protection under bandwidth constraints, we propose a privacy-aware\nwireless collaborative mixture of experts (PWC-MoE) framework. Specifically,\nPWC-MoE employs a sparse privacy-aware gating network to dynamically route\nsensitive tokens to privacy experts located on local clients, while\nnon-sensitive tokens are routed to non-privacy experts located at the remote\nbase station. To achieve computational efficiency, the gating network ensures\nthat each token is dynamically routed to and processed by only one expert. To\nenhance scalability and prevent overloading of specific experts, we introduce a\ngroup-wise load-balancing mechanism for the gating network that evenly\ndistributes sensitive tokens among privacy experts and non-sensitive tokens\namong non-privacy experts. To adapt to bandwidth constraints while preserving\nmodel performance, we propose a bandwidth-adaptive and importance-aware token\noffloading scheme. This scheme incorporates an importance predictor to evaluate\nthe importance scores of non-sensitive tokens, prioritizing the most important\ntokens for transmission to the base station based on their predicted importance\nand the available bandwidth. Experiments demonstrate that the PWC-MoE framework\neffectively preserves privacy and maintains high performance even in\nbandwidth-constrained environments, offering a practical solution for deploying\nLLMs in privacy-sensitive and bandwidth-limited scenarios.",
      "tldr_zh": "该研究提出PWC-MoE框架，一种隐私感知的无线协作混合专家(Mixture of Experts)模型，旨在平衡大型语言模型(LLMs)的计算成本、性能和隐私保护问题，尤其在带宽受限环境中。框架采用稀疏隐私感知门控网络(sparse privacy-aware gating network)动态路由敏感令牌到本地客户端的隐私专家，而非敏感令牌则路由到远程基站的非隐私专家，同时引入组级负载均衡机制(group-wise load-balancing mechanism)以均匀分布令牌并提升计算效率。为适应带宽约束，该框架还包括带宽自适应和重要性感知令牌卸载方案(bandwidth-adaptive and importance-aware token offloading scheme)，通过重要性预测器优先传输关键令牌。实验结果显示，PWC-MoE在隐私保护和性能方面表现出色，为部署LLMs于隐私敏感和带宽有限的场景提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08719v1",
      "published_date": "2025-05-13 16:27:07 UTC",
      "updated_date": "2025-05-13 16:27:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:25:27.553324"
    },
    {
      "arxiv_id": "2505.08849v1",
      "title": "Improved Algorithms for Differentially Private Language Model Alignment",
      "title_zh": "改进的差分隐私语言模型对齐算法",
      "authors": [
        "Keyu Chen",
        "Hao Tang",
        "Qinglin Liu",
        "Yizhao Xu"
      ],
      "abstract": "Language model alignment is crucial for ensuring that large language models\n(LLMs) align with human preferences, yet it often involves sensitive user data,\nraising significant privacy concerns. While prior work has integrated\ndifferential privacy (DP) with alignment techniques, their performance remains\nlimited. In this paper, we propose novel algorithms for privacy-preserving\nalignment and rigorously analyze their effectiveness across varying privacy\nbudgets and models. Our framework can be deployed on two celebrated alignment\ntechniques, namely direct preference optimization (DPO) and reinforcement\nlearning from human feedback (RLHF). Through systematic experiments on\nlarge-scale language models, we demonstrate that our approach achieves\nstate-of-the-art performance. Notably, one of our algorithms, DP-AdamW,\ncombined with DPO, surpasses existing methods, improving alignment quality by\nup to 15% under moderate privacy budgets ({\\epsilon}=2-5). We further\ninvestigate the interplay between privacy guarantees, alignment efficacy, and\ncomputational demands, providing practical guidelines for optimizing these\ntrade-offs.",
      "tldr_zh": "这篇论文提出了改进的算法，用于在差异隐私(DP)条件下进行语言模型对齐，以解决涉及敏感用户数据的隐私问题。新的框架可应用于直接偏好优化(DPO)和强化学习从人类反馈(RLHF)，并引入了如DP-AdamW的算法，以提升对齐性能。实验结果显示，该方法在大型语言模型上实现了最先进水平，在中等隐私预算(ε=2-5)下，对齐质量提高了15%。此外，论文分析了隐私保证、对齐效果和计算需求之间的权衡，并提供了实用优化指南。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08849v1",
      "published_date": "2025-05-13 16:18:59 UTC",
      "updated_date": "2025-05-13 16:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:25:39.704422"
    },
    {
      "arxiv_id": "2505.08706v1",
      "title": "Big Data and the Computational Social Science of Entrepreneurship and Innovation",
      "title_zh": "大数据与创业和创新的计算社会科学",
      "authors": [
        "Ningzi Li",
        "Shiyang Lai",
        "James Evans"
      ],
      "abstract": "As large-scale social data explode and machine-learning methods evolve,\nscholars of entrepreneurship and innovation face new research opportunities but\nalso unique challenges. This chapter discusses the difficulties of leveraging\nlarge-scale data to identify technological and commercial novelty, document new\nventure origins, and forecast competition between new technologies and\ncommercial forms. It suggests how scholars can take advantage of new text,\nnetwork, image, audio, and video data in two distinct ways that advance\ninnovation and entrepreneurship research. First, machine-learning models,\ncombined with large-scale data, enable the construction of precision\nmeasurements that function as system-level observatories of innovation and\nentrepreneurship across human societies. Second, new artificial intelligence\nmodels fueled by big data generate 'digital doubles' of technology and\nbusiness, forming laboratories for virtual experimentation about innovation and\nentrepreneurship processes and policies. The chapter argues for the advancement\nof theory development and testing in entrepreneurship and innovation by\ncoupling big data with big models.",
      "tldr_zh": "这篇论文探讨了大数据和计算社会科学在创业和创新研究中的应用，强调了大规模社会数据和机器学习方法的兴起带来的机遇与挑战，如识别技术与商业新颖性、记录新企业起源以及预测竞争。论文建议学者利用文本、网络、图像、音频和视频等新数据，通过两种方式推进研究：一是结合机器学习模型构建精确测量，作为创新和创业的系统级观测台；二是利用大数据驱动的AI模型生成技术与业务的“数字双胞胎”，用于虚拟实验。最终，论文主张通过大数据与大模型的整合，加速创业和创新理论的发展与测试。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.CY",
        "cs.SI",
        "q-fin.EC",
        "stat.AP"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08706v1",
      "published_date": "2025-05-13 16:13:18 UTC",
      "updated_date": "2025-05-13 16:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:25:50.397250"
    },
    {
      "arxiv_id": "2505.08705v1",
      "title": "Controllable Image Colorization with Instance-aware Texts and Masks",
      "title_zh": "翻译失败",
      "authors": [
        "Yanru An",
        "Ling Gui",
        "Qiang Hu",
        "Chunlei Cai",
        "Tianxiao Ye",
        "Xiaoyun Zhang",
        "Yanfeng Wang"
      ],
      "abstract": "Recently, the application of deep learning in image colorization has received\nwidespread attention. The maturation of diffusion models has further advanced\nthe development of image colorization models. However, current mainstream image\ncolorization models still face issues such as color bleeding and color binding\nerrors, and cannot colorize images at the instance level. In this paper, we\npropose a diffusion-based colorization method MT-Color to achieve precise\ninstance-aware colorization with use-provided guidance. To tackle color\nbleeding issue, we design a pixel-level mask attention mechanism that\nintegrates latent features and conditional gray image features through\ncross-attention. We use segmentation masks to construct cross-attention masks,\npreventing pixel information from exchanging between different instances. We\nalso introduce an instance mask and text guidance module that extracts instance\nmasks and text representations of each instance, which are then fused with\nlatent features through self-attention, utilizing instance masks to form\nself-attention masks to prevent instance texts from guiding the colorization of\nother areas, thus mitigating color binding errors. Furthermore, we apply a\nmulti-instance sampling strategy, which involves sampling each instance region\nseparately and then fusing the results. Additionally, we have created a\nspecialized dataset for instance-level colorization tasks, GPT-color, by\nleveraging large visual language models on existing image datasets. Qualitative\nand quantitative experiments show that our model and dataset outperform\nprevious methods and datasets.",
      "tldr_zh": "本文提出了一种基于扩散模型的图像着色方法MT-Color，利用实例感知文本和掩码实现精确的可控着色，解决了传统模型的颜色溢出（color bleeding）和颜色绑定错误（color binding errors）等问题。核心机制包括像素级掩码注意力，通过交叉注意力整合特征并使用分割掩码防止实例间像素信息交换，以及实例掩码和文本指导模块，通过自注意力和多实例采样策略确保每个实例的独立着色。作者还构建了专门的GPT-color数据集，并通过定性和定量实验证明，该方法在实例级着色任务上优于现有模型和数据集。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08705v1",
      "published_date": "2025-05-13 16:13:06 UTC",
      "updated_date": "2025-05-13 16:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:26:03.900179"
    },
    {
      "arxiv_id": "2505.08704v1",
      "title": "LLM-based Prompt Ensemble for Reliable Medical Entity Recognition from EHRs",
      "title_zh": "翻译失败",
      "authors": [
        "K M Sajjadul Islam",
        "Ayesha Siddika Nipu",
        "Jiawei Wu",
        "Praveen Madiraju"
      ],
      "abstract": "Electronic Health Records (EHRs) are digital records of patient information,\noften containing unstructured clinical text. Named Entity Recognition (NER) is\nessential in EHRs for extracting key medical entities like problems, tests, and\ntreatments to support downstream clinical applications. This paper explores\nprompt-based medical entity recognition using large language models (LLMs),\nspecifically GPT-4o and DeepSeek-R1, guided by various prompt engineering\ntechniques, including zero-shot, few-shot, and an ensemble approach. Among all\nstrategies, GPT-4o with prompt ensemble achieved the highest classification\nperformance with an F1-score of 0.95 and recall of 0.98, outperforming\nDeepSeek-R1 on the task. The ensemble method improved reliability by\naggregating outputs through embedding-based similarity and majority voting.",
      "tldr_zh": "本研究探讨了基于大语言模型（LLMs）如 GPT-4o 和 DeepSeek-R1 的提示工程技术，用于从电子健康记录（EHRs）中进行可靠的命名实体识别（NER），以提取医疗实体如问题、测试和治疗。方法包括 zero-shot、few-shot 和提示集成（ensemble）策略，其中集成方法通过 embedding-based similarity 和 majority voting 聚合输出，提升了模型的可靠性。结果显示，GPT-4o 结合提示集成取得了最佳性能，F1-score 达 0.95 和 recall 0.98，优于 DeepSeek-R1，从而为临床应用中的实体提取提供了更高效的解决方案。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "IEEE 26th International Conference on Information Reuse and\n  Integration for Data Science (IRI 2025), San Jose, CA, USA",
      "pdf_url": "http://arxiv.org/pdf/2505.08704v1",
      "published_date": "2025-05-13 16:11:29 UTC",
      "updated_date": "2025-05-13 16:11:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:26:14.866564"
    },
    {
      "arxiv_id": "2505.08694v1",
      "title": "A Survey of Deep Learning for Complex Speech Spectrograms",
      "title_zh": "翻译失败",
      "authors": [
        "Yuying Xie",
        "Zheng-Hua Tan"
      ],
      "abstract": "Recent advancements in deep learning have significantly impacted the field of\nspeech signal processing, particularly in the analysis and manipulation of\ncomplex spectrograms. This survey provides a comprehensive overview of the\nstate-of-the-art techniques leveraging deep neural networks for processing\ncomplex spectrograms, which encapsulate both magnitude and phase information.\nWe begin by introducing complex spectrograms and their associated features for\nvarious speech processing tasks. Next, we explore the key components and\narchitectures of complex-valued neural networks, which are specifically\ndesigned to handle complex-valued data and have been applied for complex\nspectrogram processing. We then discuss various training strategies and loss\nfunctions tailored for training neural networks to process and model complex\nspectrograms. The survey further examines key applications, including phase\nretrieval, speech enhancement, and speech separation, where deep learning has\nachieved significant progress by leveraging complex spectrograms or their\nderived feature representations. Additionally, we examine the intersection of\ncomplex spectrograms with generative models. This survey aims to serve as a\nvaluable resource for researchers and practitioners in the field of speech\nsignal processing and complex-valued neural networks.",
      "tldr_zh": "这篇调查论文概述了深度学习在处理复杂语音谱图（complex spectrograms）方面的最新进展，这些谱图包含幅度和相位信息。论文介绍了复杂谱图的关键特征、复杂值神经网络（complex-valued neural networks）的架构和组件，以及针对其训练的策略和损失函数。重点讨论了深度学习在相位检索、语音增强和语音分离等应用中的显著成就，并探讨了与生成模型的结合，为语音信号处理领域的研究者和从业者提供宝贵资源。",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08694v1",
      "published_date": "2025-05-13 15:53:01 UTC",
      "updated_date": "2025-05-13 15:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:26:25.685011"
    },
    {
      "arxiv_id": "2505.08691v1",
      "title": "VizCV: AI-assisted visualization of researchers' publications tracks",
      "title_zh": "翻译失败",
      "authors": [
        "Vladimír Lazárik",
        "Marco Agus",
        "Barbora Kozlíková",
        "Pere-Pau Vázquez"
      ],
      "abstract": "Analyzing how the publication records of scientists and research groups have\nevolved over the years is crucial for assessing their expertise since it can\nsupport the management of academic environments by assisting with career\nplanning and evaluation. We introduce VizCV, a novel web-based end-to-end\nvisual analytics framework that enables the interactive exploration of\nresearchers' scientific trajectories. It incorporates AI-assisted analysis and\nsupports automated reporting of career evolution. Our system aims to model\ncareer progression through three key dimensions: a) research topic evolution to\ndetect and visualize shifts in scholarly focus over time, b) publication record\nand the corresponding impact, c) collaboration dynamics depicting the growth\nand transformation of a researcher's co-authorship network. AI-driven insights\nprovide automated explanations of career transitions, detecting significant\nshifts in research direction, impact surges, or collaboration expansions. The\nsystem also supports comparative analysis between researchers, allowing users\nto compare topic trajectories and impact growth. Our interactive, multi-tab and\nmultiview system allows for the exploratory analysis of career milestones under\ndifferent perspectives, such as the most impactful articles, emerging research\nthemes, or obtaining a detailed analysis of the contribution of the researcher\nin a subfield. The key contributions include AI/ML techniques for: a) topic\nanalysis, b) dimensionality reduction for visualizing patterns and trends, c)\nthe interactive creation of textual descriptions of facets of data through\nconfigurable prompt generation and large language models, that include key\nindicators, to help understanding the career development of individuals or\ngroups.",
      "tldr_zh": "VizCV 是一个新型的网络端到端视觉分析框架，旨在通过交互式探索帮助评估研究人员和团队的出版轨迹，包括研究主题演变、出版影响以及合作网络动态。系统利用 AI 驱动的分析技术，如主题分析和降维可视化，来自动检测职业转变、影响 surges 和合作扩展，并生成可配置的文本报告以解释这些变化。VizCV 的关键贡献在于其 AI/ML 方法支持比较分析和探索性研究，例如比较主题轨迹或分析职业里程碑，从而辅助学术职业规划和评估。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "11 pages, 9 figures. Subtmitted",
      "pdf_url": "http://arxiv.org/pdf/2505.08691v1",
      "published_date": "2025-05-13 15:47:59 UTC",
      "updated_date": "2025-05-13 15:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:26:38.133952"
    },
    {
      "arxiv_id": "2505.08687v1",
      "title": "AC-PKAN: Attention-Enhanced and Chebyshev Polynomial-Based Physics-Informed Kolmogorov-Arnold Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Hangwei Zhang",
        "Zhimu Huang",
        "Yan Wang"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) have recently shown promise for solving\npartial differential equations (PDEs). Yet their original formulation is\ncomputationally and memory intensive, motivating the introduction of Chebyshev\nType-I-based KANs (Chebyshev1KANs). Although Chebyshev1KANs have outperformed\nthe vanilla KANs architecture, our rigorous theoretical analysis reveals that\nthey still suffer from rank collapse, ultimately limiting their expressive\ncapacity. To overcome these limitations, we enhance Chebyshev1KANs by\nintegrating wavelet-activated MLPs with learnable parameters and an internal\nattention mechanism. We prove that this design preserves a full-rank Jacobian\nand is capable of approximating solutions to PDEs of arbitrary order.\nFurthermore, to alleviate the loss instability and imbalance introduced by the\nChebyshev polynomial basis, we externally incorporate a Residual Gradient\nAttention (RGA) mechanism that dynamically re-weights individual loss terms\naccording to their gradient norms and residual magnitudes. By jointly\nleveraging internal and external attention, we present AC-PKAN, a novel\narchitecture that constitutes an enhancement to weakly supervised\nPhysics-Informed Neural Networks (PINNs) and extends the expressive power of\nKANs. Experimental results from nine benchmark tasks across three domains show\nthat AC-PKAN consistently outperforms or matches state-of-the-art models such\nas PINNsFormer, establishing it as a highly effective tool for solving complex\nreal-world engineering problems in zero-data or data-sparse regimes. The code\nwill be made publicly available upon acceptance.",
      "tldr_zh": "本研究针对 Kolmogorov-Arnold Networks (KANs) 在解决偏微分方程 (PDEs) 时存在的计算密集和 rank collapse 问题，提出了 AC-PKAN 模型，该模型基于 Chebyshev1KANs，并通过整合 wavelet-activated MLPs 和内部 attention 机制来增强表达能力。\nAC-PKAN 证明了其 Jacobian 为满秩，能够逼近任意阶 PDE 的解，同时外部引入 Residual Gradient Attention (RGA) 机制，以动态调整损失项，缓解 Chebyshev 多项式带来的不稳定性。\n实验结果显示，该模型在九个跨领域的基准任务中，优于或匹敌最先进模型如 PINNsFormer，尤其适用于零数据或数据稀缺的复杂工程问题。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08687v1",
      "published_date": "2025-05-13 15:46:10 UTC",
      "updated_date": "2025-05-13 15:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:26:51.169171"
    },
    {
      "arxiv_id": "2505.08681v1",
      "title": "A Mamba-based Network for Semi-supervised Singing Melody Extraction Using Confidence Binary Regularization",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoliang He",
        "Kangjie Dong",
        "Jingkai Cao",
        "Shuai Yu",
        "Wei Li",
        "Yi Yu"
      ],
      "abstract": "Singing melody extraction (SME) is a key task in the field of music\ninformation retrieval. However, existing methods are facing several\nlimitations: firstly, prior models use transformers to capture the contextual\ndependencies, which requires quadratic computation resulting in low efficiency\nin the inference stage. Secondly, prior works typically rely on\nfrequencysupervised methods to estimate the fundamental frequency (f0), which\nignores that the musical performance is actually based on notes. Thirdly,\ntransformers typically require large amounts of labeled data to achieve optimal\nperformances, but the SME task lacks of sufficient annotated data. To address\nthese issues, in this paper, we propose a mamba-based network, called\nSpectMamba, for semi-supervised singing melody extraction using confidence\nbinary regularization. In particular, we begin by introducing vision mamba to\nachieve computational linear complexity. Then, we propose a novel note-f0\ndecoder that allows the model to better mimic the musical performance. Further,\nto alleviate the scarcity of the labeled data, we introduce a confidence binary\nregularization (CBR) module to leverage the unlabeled data by maximizing the\nprobability of the correct classes. The proposed method is evaluated on several\npublic datasets and the conducted experiments demonstrate the effectiveness of\nour proposed method.",
      "tldr_zh": "这篇论文提出了一种基于 Mamba 的网络 SpectMamba，用于半监督的唱歌旋律提取（SME），以解决现有方法在计算效率、音乐表现建模和数据标注不足方面的局限性。SpectMamba 引入 Vision Mamba 实现线性计算复杂度、开发 note-f0 解码器来更好地模仿基于音符的音乐性能，并采用 Confidence Binary Regularization (CBR) 模块利用未标注数据，通过最大化正确类别概率来提升模型性能。实验在多个公共数据集上验证了该方法的有效性，证明其在 SME 任务中取得了显著改进。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08681v1",
      "published_date": "2025-05-13 15:43:35 UTC",
      "updated_date": "2025-05-13 15:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:27:02.110567"
    },
    {
      "arxiv_id": "2505.08673v1",
      "title": "A Study of Data-driven Methods for Inventory Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Lee Yeung Ping",
        "Patrick Wong",
        "Tan Cheng Han"
      ],
      "abstract": "This paper shows a comprehensive analysis of three algorithms (Time Series,\nRandom Forest (RF) and Deep Reinforcement Learning) into three inventory models\n(the Lost Sales, Dual-Sourcing and Multi-Echelon Inventory Model). These\nmethodologies are applied in the supermarket context. The main purpose is to\nanalyse efficient methods for the data-driven. Their possibility, potential and\ncurrent challenges are taken into consideration in this report. By comparing\nthe results in each model, the effectiveness of each algorithm is evaluated\nbased on several key performance indicators, including forecast accuracy,\nadaptability to market changes, and overall impact on inventory costs and\ncustomer satisfaction levels. The data visualization tools and statistical\nmetrics are the indicators for the comparisons and show some obvious trends and\npatterns that can guide decision-making in inventory management. These tools\nenable managers to not only track the performance of different algorithms in\nreal-time but also to drill down into specific data points to understand the\nunderlying causes of inventory fluctuations. This level of detail is crucial\nfor pinpointing inefficiencies and areas for improvement within the supply\nchain.",
      "tldr_zh": "本研究对数据驱动方法在库存优化中的应用进行了全面分析，聚焦于 Time Series、Random Forest (RF) 和 Deep Reinforcement Learning 算法在 Lost Sales、Dual-Sourcing 和 Multi-Echelon Inventory Model 等三类库存模型中的表现。研究在超市环境下评估了这些算法的预测准确性、市场适应性，以及对库存成本和客户满意度的影响，通过数据可视化和统计指标进行比较。结果显示，每种算法在关键绩效指标上存在明显差异，帮助识别趋势和模式，以指导库存管理的决策和改进。整体而言，该分析突出了数据驱动方法的潜力，同时指出了当前挑战，为优化供应链提供实用见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08673v1",
      "published_date": "2025-05-13 15:35:23 UTC",
      "updated_date": "2025-05-13 15:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:27:13.902279"
    },
    {
      "arxiv_id": "2505.08847v1",
      "title": "On the interplay of Explainability, Privacy and Predictive Performance with Explanation-assisted Model Extraction",
      "title_zh": "翻译失败",
      "authors": [
        "Fatima Ezzeddine",
        "Rinad Akel",
        "Ihab Sbeity",
        "Silvia Giordano",
        "Marc Langheinrich",
        "Omran Ayoub"
      ],
      "abstract": "Machine Learning as a Service (MLaaS) has gained important attraction as a\nmeans for deploying powerful predictive models, offering ease of use that\nenables organizations to leverage advanced analytics without substantial\ninvestments in specialized infrastructure or expertise. However, MLaaS\nplatforms must be safeguarded against security and privacy attacks, such as\nmodel extraction (MEA) attacks. The increasing integration of explainable AI\n(XAI) within MLaaS has introduced an additional privacy challenge, as attackers\ncan exploit model explanations particularly counterfactual explanations (CFs)\nto facilitate MEA. In this paper, we investigate the trade offs among model\nperformance, privacy, and explainability when employing Differential Privacy\n(DP), a promising technique for mitigating CF facilitated MEA. We evaluate two\ndistinct DP strategies: implemented during the classification model training\nand at the explainer during CF generation.",
      "tldr_zh": "这篇论文探讨了在 Machine Learning as a Service (MLaaS) 中，可解释性 (XAI)、隐私和预测性能之间的权衡，特别是针对模型提取 (MEA) 攻击。攻击者可能利用反事实解释 (CFs) 来增强 MEA，因此作者调查了 Differential Privacy (DP) 作为缓解策略的效果。论文评估了两种 DP 策略：一种在分类模型训练期间实现，另一种在 CF 生成的解释器上应用，并分析了这些方法对模型性能、隐私和可解释性的影响。实验结果突出了 DP 在平衡这些因素时的潜在优势。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08847v1",
      "published_date": "2025-05-13 15:27:06 UTC",
      "updated_date": "2025-05-13 15:27:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:27:25.842947"
    },
    {
      "arxiv_id": "2505.08664v1",
      "title": "A Social Robot with Inner Speech for Dietary Guidance",
      "title_zh": "一种用于饮食指导的内语社交机器人",
      "authors": [
        "Valerio Belcamino",
        "Alessandro Carfì",
        "Valeria Seidita",
        "Fulvio Mastrogiovanni",
        "Antonio Chella"
      ],
      "abstract": "We explore the use of inner speech as a mechanism to enhance transparency and\ntrust in social robots for dietary advice. In humans, inner speech structures\nthought processes and decision-making; in robotics, it improves explainability\nby making reasoning explicit. This is crucial in healthcare scenarios, where\ntrust in robotic assistants depends on both accurate recommendations and\nhuman-like dialogue, which make interactions more natural and engaging.\nBuilding on this, we developed a social robot that provides dietary advice, and\nwe provided the architecture with inner speech capabilities to validate user\ninput, refine reasoning, and generate clear justifications. The system\nintegrates large language models for natural language understanding and a\nknowledge graph for structured dietary information. By making decisions more\ntransparent, our approach strengthens trust and improves human-robot\ninteraction in healthcare. We validated this by measuring the computational\nefficiency of our architecture and conducting a small user study, which\nassessed the reliability of inner speech in explaining the robot's behavior.",
      "tldr_zh": "本研究探索了使用内部语音（inner speech）机制来提升社交机器人在饮食指导中的透明度和信任度，该机制类似于人类思考过程，能使机器人的推理过程更显性化。研究开发了一个社交机器人架构，该机器人整合大型语言模型（large language models）用于自然语言理解，以及知识图谱（knowledge graph）用于结构化饮食信息，通过内部语音验证用户输入、精炼决策并生成清晰解释。结果显示，这种方法显著改善了人机交互的自然性和可靠性，并通过计算效率测试和小规模用户研究验证了其在医疗场景中的实际价值。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08664v1",
      "published_date": "2025-05-13 15:26:52 UTC",
      "updated_date": "2025-05-13 15:26:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:27:38.368288"
    },
    {
      "arxiv_id": "2505.08657v1",
      "title": "A Comparative Study of Human Activity Recognition: Motion, Tactile, and multi-modal Approaches",
      "title_zh": "人类活动识别的比较研究：运动、触觉和多模态方法",
      "authors": [
        "Valerio Belcamino",
        "Nhat Minh Dinh Le",
        "Quan Khanh Luu",
        "Alessandro Carfì",
        "Van Anh Ho",
        "Fulvio Mastrogiovanni"
      ],
      "abstract": "Human activity recognition (HAR) is essential for effective Human-Robot\nCollaboration (HRC), enabling robots to interpret and respond to human actions.\nThis study evaluates the ability of a vision-based tactile sensor to classify\n15 activities, comparing its performance to an IMU-based data glove.\nAdditionally, we propose a multi-modal framework combining tactile and motion\ndata to leverage their complementary strengths. We examined three approaches:\nmotion-based classification (MBC) using IMU data, tactile-based classification\n(TBC) with single or dual video streams, and multi-modal classification (MMC)\nintegrating both. Offline validation on segmented datasets assessed each\nconfiguration's accuracy under controlled conditions, while online validation\non continuous action sequences tested online performance. Results showed the\nmulti-modal approach consistently outperformed single-modality methods,\nhighlighting the potential of integrating tactile and motion sensing to enhance\nHAR systems for collaborative robotics.",
      "tldr_zh": "本研究比较了人类活动识别 (HAR) 在人机协作 (HRC) 中的不同方法，包括基于运动的分类 (MBC) 使用 IMU 数据、基于触觉的分类 (TBC) 利用单或双视频流，以及多模态分类 (MMC) 整合触觉和运动数据。研究评估了视觉触觉传感器对 15 种活动的分类性能，并将其与 IMU-based 数据手套进行对比，同时提出一个多模态框架来发挥两者的互补优势。通过离线验证（在分割数据集上）和在线验证（在连续动作序列上），实验结果显示 MMC 方法在准确性上 consistently outperformed 单模态方法，提升了 HAR 系统在协作机器人中的潜力。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08657v1",
      "published_date": "2025-05-13 15:20:21 UTC",
      "updated_date": "2025-05-13 15:20:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:27:49.860382"
    },
    {
      "arxiv_id": "2505.08643v1",
      "title": "WixQA: A Multi-Dataset Benchmark for Enterprise Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Dvir Cohen",
        "Lin Burg",
        "Sviatoslav Pykhnivskyi",
        "Hagit Gur",
        "Stanislav Kovynov",
        "Olga Atzmon",
        "Gilad Barkan"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) is a cornerstone of modern question\nanswering (QA) systems, enabling grounded answers based on external knowledge.\nAlthough recent progress has been driven by open-domain datasets, enterprise QA\nsystems need datasets that mirror the concrete, domain-specific issues users\nraise in day-to-day support scenarios. Critically, evaluating end-to-end RAG\nsystems requires benchmarks comprising not only question--answer pairs but also\nthe specific knowledge base (KB) snapshot from which answers were derived. To\naddress this need, we introduce WixQA, a benchmark suite featuring QA datasets\nprecisely grounded in the released KB corpus, enabling holistic evaluation of\nretrieval and generation components. WixQA includes three distinct QA datasets\nderived from Wix.com customer support interactions and grounded in a snapshot\nof the public Wix Help Center KB: (i) WixQA-ExpertWritten, 200 real user\nqueries with expert-authored, multi-step answers; (ii) WixQA-Simulated, 200\nexpert-validated QA pairs distilled from user dialogues; and (iii)\nWixQA-Synthetic, 6,222 LLM-generated QA pairs, with one pair systematically\nderived from each article in the knowledge base. We release the KB snapshot\nalongside the datasets under MIT license and provide comprehensive baseline\nresults, forming a unique benchmark for evaluating enterprise RAG systems in\nrealistic enterprise environments.",
      "tldr_zh": "这篇论文引入了 WixQA，一种多数据集基准，用于评估企业环境下的 Retrieval-Augmented Generation (RAG) 系统，以解决传统开源数据集无法覆盖的具体领域问题。WixQA 包括三个数据集：WixQA-ExpertWritten（200 个真实用户查询配以专家撰写的多步答案）、WixQA-Simulated（200 个从用户对话中提炼并专家验证的 QA 对），以及 WixQA-Synthetic（6,222 个基于知识库文章的 LLM 生成 QA 对）。该基准还发布了知识基快照和全面基准结果，支持对 RAG 的检索和生成组件进行整体评估，从而为真实企业问答场景提供可靠的测试框架。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08643v1",
      "published_date": "2025-05-13 15:02:54 UTC",
      "updated_date": "2025-05-13 15:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:28:02.639304"
    },
    {
      "arxiv_id": "2505.08846v1",
      "title": "Evaluating Simplification Algorithms for Interpretability of Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Marti-Perez",
        "Brigt Håvardstun",
        "Cèsar Ferri",
        "Carlos Monserrat",
        "Jan Arne Telle"
      ],
      "abstract": "In this work, we introduce metrics to evaluate the use of simplified time\nseries in the context of interpretability of a TSC - a Time Series Classifier.\nSuch simplifications are important because time series data, in contrast to\ntext and image data, are not intuitively understandable to humans. These\nmetrics are related to the complexity of the simplifications - how many\nsegments they contain - and to their loyalty - how likely they are to maintain\nthe classification of the original time series. We employ these metrics to\nevaluate four distinct simplification algorithms, across several TSC algorithms\nand across datasets of varying characteristics, from seasonal or stationary to\nshort or long. Our findings suggest that using simplifications for\ninterpretability of TSC is much better than using the original time series,\nparticularly when the time series are seasonal, non-stationary and/or with low\nentropy.",
      "tldr_zh": "本研究评估了简化算法在时间序列分类器(TSC)可解释性方面的应用，引入了两个关键指标：简化复杂性（即包含的段数）和忠诚度（即保持原时间序列分类的可能性）。这些指标被用于测试四种不同简化算法，涵盖多种TSC算法和各种数据集特性，如季节性、非平稳或短长序列。结果表明，使用简化时间序列进行解释比直接使用原时间序列更有效，特别是在季节性、非平稳和低熵数据集上。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08846v1",
      "published_date": "2025-05-13 15:00:56 UTC",
      "updated_date": "2025-05-13 15:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:28:13.422616"
    },
    {
      "arxiv_id": "2505.08638v2",
      "title": "TRAIL: Trace Reasoning and Agentic Issue Localization",
      "title_zh": "TRAIL：跟踪推理和智能体问题定位",
      "authors": [
        "Darshan Deshpande",
        "Varun Gangal",
        "Hersh Mehta",
        "Jitin Krishnan",
        "Anand Kannappan",
        "Rebecca Qian"
      ],
      "abstract": "The increasing adoption of agentic workflows across diverse domains brings a\ncritical need to scalably and systematically evaluate the complex traces these\nsystems generate. Current evaluation methods depend on manual, domain-specific\nhuman analysis of lengthy workflow traces - an approach that does not scale\nwith the growing complexity and volume of agentic outputs. Error analysis in\nthese settings is further complicated by the interplay of external tool outputs\nand language model reasoning, making it more challenging than traditional\nsoftware debugging. In this work, we (1) articulate the need for robust and\ndynamic evaluation methods for agentic workflow traces, (2) introduce a formal\ntaxonomy of error types encountered in agentic systems, and (3) present a set\nof 148 large human-annotated traces (TRAIL) constructed using this taxonomy and\ngrounded in established agentic benchmarks. To ensure ecological validity, we\ncurate traces from both single and multi-agent systems, focusing on real-world\napplications such as software engineering and open-world information retrieval.\nOur evaluations reveal that modern long context LLMs perform poorly at trace\ndebugging, with the best Gemini-2.5-pro model scoring a mere 11% on TRAIL. Our\ndataset and code are made publicly available to support and accelerate future\nresearch in scalable evaluation for agentic workflows.",
      "tldr_zh": "该论文强调了代理工作流（agentic workflows）追踪评估的必要性，因为现有方法依赖手动分析，无法应对其复杂性和规模。研究者引入了一个正式错误类型分类（taxonomy），并构建了TRAIL数据集，包含148个由人类标注的追踪，基于真实应用如软件工程和开放世界信息检索。实验结果显示，现代长上下文LLMs在追踪调试任务上表现欠佳，最佳的Gemini-2.5-pro模型仅得11%。数据集和代码已公开，以推动可扩展代理系统评估的研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Dataset: https://huggingface.co/datasets/PatronusAI/TRAIL",
      "pdf_url": "http://arxiv.org/pdf/2505.08638v2",
      "published_date": "2025-05-13 14:55:31 UTC",
      "updated_date": "2025-05-19 15:15:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:28:27.052160"
    },
    {
      "arxiv_id": "2505.08628v1",
      "title": "Integrating Natural Language Processing and Exercise Monitoring for Early Diagnosis of Metabolic Syndrome: A Deep Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Zhao",
        "Yuhua Wang",
        "Xi Cheng",
        "Junhao Fang",
        "Yang Yang"
      ],
      "abstract": "Metabolic syndrome (MetS) is a medication condition characterized by\nabdominal obesity, insulin resistance, hypertension and hyperlipidemia. It\nincreases the risk of majority of chronic diseases, including type 2 diabetes\nmellitus, and affects about one quarter of the global population. Therefore,\nearly detection and timely intervention for MetS are crucial. Standard\ndiagnosis for MetS components requires blood tests conducted within medical\ninstitutions. However, it is frequently underestimated, leading to unmet need\nfor care for MetS population. This study aims to use the least physiological\ndata and free texts about exercises related activities, which are obtained\neasily in daily life, to diagnosis MetS. We collected the data from 40\nvolunteers in a nursing home and used data augmentation to reduce the\nimbalance. We propose a deep learning framework for classifying MetS that\nintegrates natural language processing (NLP) and exercise monitoring. The\nresults showed that the best model reported a high positive result (AUROC=0.806\nand REC=76.3%) through 3-fold cross-validation. Feature importance analysis\nrevealed that text and minimum heart rate on a daily basis contribute the most\nin the classification of MetS. This study demonstrates the potential\napplication of data that are easily measurable in daily life for the early\ndiagnosis of MetS, which could contribute to reducing the cost of screening and\nmanagement for MetS population.",
      "tldr_zh": "本文提出了一种整合Natural Language Processing (NLP) 和运动监测的深度学习框架，用于代谢综合征(MetS)的早期诊断，旨在利用日常生活中容易获取的生理数据和运动相关文本数据，减少对血液测试的依赖。研究收集了40名养老院志愿者的数据，并通过数据增强处理样本不平衡问题。实验结果显示，最佳模型在3折交叉验证中达到AUROC=0.806和REC=76.3%，特征重要性分析表明文本数据和每日最小心率对分类贡献最大。该方法证明了使用易测数据进行MetS早期诊断的可行性，有助于降低筛查和管理成本。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08628v1",
      "published_date": "2025-05-13 14:48:36 UTC",
      "updated_date": "2025-05-13 14:48:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:28:39.330258"
    },
    {
      "arxiv_id": "2505.08622v1",
      "title": "Visually Guided Decoding: Gradient-Free Hard Prompt Inversion with Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Donghoon Kim",
        "Minji Bae",
        "Kyuhong Shim",
        "Byonghyo Shim"
      ],
      "abstract": "Text-to-image generative models like DALL-E and Stable Diffusion have\nrevolutionized visual content creation across various applications, including\nadvertising, personalized media, and design prototyping. However, crafting\neffective textual prompts to guide these models remains challenging, often\nrequiring extensive trial and error. Existing prompt inversion approaches, such\nas soft and hard prompt techniques, are not so effective due to the limited\ninterpretability and incoherent prompt generation. To address these issues, we\npropose Visually Guided Decoding (VGD), a gradient-free approach that leverages\nlarge language models (LLMs) and CLIP-based guidance to generate coherent and\nsemantically aligned prompts. In essence, VGD utilizes the robust text\ngeneration capabilities of LLMs to produce human-readable prompts. Further, by\nemploying CLIP scores to ensure alignment with user-specified visual concepts,\nVGD enhances the interpretability, generalization, and flexibility of prompt\ngeneration without the need for additional training. Our experiments\ndemonstrate that VGD outperforms existing prompt inversion techniques in\ngenerating understandable and contextually relevant prompts, facilitating more\nintuitive and controllable interactions with text-to-image models.",
      "tldr_zh": "该论文提出 Visually Guided Decoding (VGD)，一种无梯度（gradient-free）的硬提示反演方法，利用 large language models (LLMs) 和 CLIP-based 指导来生成连贯且语义对齐的文本提示，解决文本到图像生成模型（如 DALL-E 和 Stable Diffusion）中提示创建的试错问题。VGD 利用 LLMs 的文本生成能力产生可读提示，同时通过 CLIP 分数确保提示与用户指定视觉概念的精确对齐，从而提升提示的可解释性、泛化和灵活性，而无需额外训练。实验结果表明，VGD 在生成可理解和上下文相关的提示方面优于现有软提示和硬提示技术，便于更直观的文本到图像模型交互。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08622v1",
      "published_date": "2025-05-13 14:40:22 UTC",
      "updated_date": "2025-05-13 14:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:28:50.649356"
    },
    {
      "arxiv_id": "2505.08620v1",
      "title": "Resource-Efficient Language Models: Quantization for Fast and Accessible Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Tollef Emil Jørgensen"
      ],
      "abstract": "Large language models have significantly advanced natural language\nprocessing, yet their heavy resource demands pose severe challenges regarding\nhardware accessibility and energy consumption. This paper presents a focused\nand high-level review of post-training quantization (PTQ) techniques designed\nto optimize the inference efficiency of LLMs by the end-user, including details\non various quantization schemes, granularities, and trade-offs. The aim is to\nprovide a balanced overview between the theory and applications of\npost-training quantization.",
      "tldr_zh": "这篇论文审视了大型语言模型（LLMs）的资源需求问题，如硬件可访问性和能源消耗，并介绍了后训练量化（PTQ）技术作为优化推理效率的解决方案。论文提供了一个高水平综述，涵盖各种量化方案、粒度和权衡，平衡了理论基础与实际应用。最终，该工作旨在帮助最终用户实现更快速、可访问的LLMs推理，从而缓解资源挑战。",
      "categories": [
        "cs.AI",
        "68T07",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 9 figures, preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.08620v1",
      "published_date": "2025-05-13 14:39:33 UTC",
      "updated_date": "2025-05-13 14:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:29:01.955088"
    },
    {
      "arxiv_id": "2505.08845v1",
      "title": "Validation of Conformal Prediction in Cervical Atypia Classification",
      "title_zh": "共形预测",
      "authors": [
        "Misgina Tsighe Hagos",
        "Antti Suutala",
        "Dmitrii Bychkov",
        "Hakan Kücükel",
        "Joar von Bahr",
        "Milda Poceviciute",
        "Johan Lundin",
        "Nina Linder",
        "Claes Lundström"
      ],
      "abstract": "Deep learning based cervical cancer classification can potentially increase\naccess to screening in low-resource regions. However, deep learning models are\noften overconfident and do not reliably reflect diagnostic uncertainty.\nMoreover, they are typically optimized to generate maximum-likelihood\npredictions, which fail to convey uncertainty or ambiguity in their results.\nSuch challenges can be addressed using conformal prediction, a model-agnostic\nframework for generating prediction sets that contain likely classes for\ntrained deep-learning models. The size of these prediction sets indicates model\nuncertainty, contracting as model confidence increases. However, existing\nconformal prediction evaluation primarily focuses on whether the prediction set\nincludes or covers the true class, often overlooking the presence of extraneous\nclasses. We argue that prediction sets should be truthful and valuable to end\nusers, ensuring that the listed likely classes align with human expectations\nrather than being overly relaxed and including false positives or unlikely\nclasses. In this study, we comprehensively validate conformal prediction sets\nusing expert annotation sets collected from multiple annotators. We evaluate\nthree conformal prediction approaches applied to three deep-learning models\ntrained for cervical atypia classification. Our expert annotation-based\nanalysis reveals that conventional coverage-based evaluations overestimate\nperformance and that current conformal prediction methods often produce\nprediction sets that are not well aligned with human labels. Additionally, we\nexplore the capabilities of the conformal prediction methods in identifying\nambiguous and out-of-distribution data.",
      "tldr_zh": "这篇论文验证了 Conformal Prediction 在宫颈非典型病变分类中的应用，以解决深度学习模型的过度自信和不确定性问题。研究通过专家标注评估三种 Conformal Prediction 方法应用于三种训练模型，发现传统覆盖率评估高估了性能，且预测集常包含不相关类，与人类期望不一致。主要贡献包括探索这些方法在识别模糊和分布外数据方面的能力，从而提升模型的可靠性和实用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08845v1",
      "published_date": "2025-05-13 14:37:58 UTC",
      "updated_date": "2025-05-13 14:37:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:29:13.248518"
    },
    {
      "arxiv_id": "2505.08844v1",
      "title": "CellTypeAgent: Trustworthy cell type annotation with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawen Chen",
        "Jianghao Zhang",
        "Huaxiu Yao",
        "Yun Li"
      ],
      "abstract": "Cell type annotation is a critical yet laborious step in single-cell RNA\nsequencing analysis. We present a trustworthy large language model (LLM)-agent,\nCellTypeAgent, which integrates LLMs with verification from relevant databases.\nCellTypeAgent achieves higher accuracy than existing methods while mitigating\nhallucinations. We evaluated CellTypeAgent across nine real datasets involving\n303 cell types from 36 tissues. This combined approach holds promise for more\nefficient and reliable cell type annotation.",
      "tldr_zh": "本研究针对单细胞 RNA 测序分析中耗时的细胞类型注释问题，提出了一种可信赖的 LLM-agent 框架，名为 CellTypeAgent，它通过整合 Large Language Models (LLMs) 与相关数据库的验证机制来提高准确性和减少 hallucinations。CellTypeAgent 在九个真实数据集上进行了评估，涵盖 303 种细胞类型和 36 种组织，结果显示其准确性超过了现有方法。这种结合方法有望实现更高效和可靠的细胞类型注释。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "68T20",
        "I.2.1"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08844v1",
      "published_date": "2025-05-13 14:34:11 UTC",
      "updated_date": "2025-05-13 14:34:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:29:26.526512"
    },
    {
      "arxiv_id": "2505.08599v1",
      "title": "MINIMALIST: switched-capacitor circuits for efficient in-memory computation of gated recurrent units",
      "title_zh": "MINIMALIST：开关电容电路用于门控循环单元的高效内存内计算",
      "authors": [
        "Sebastian Billaudelle",
        "Laura Kriener",
        "Filippo Moro",
        "Tristan Torchet",
        "Melika Payvand"
      ],
      "abstract": "Recurrent neural networks (RNNs) have been a long-standing candidate for\nprocessing of temporal sequence data, especially in memory-constrained systems\nthat one may find in embedded edge computing environments. Recent advances in\ntraining paradigms have now inspired new generations of efficient RNNs. We\nintroduce a streamlined and hardware-compatible architecture based on minimal\ngated recurrent units (GRUs), and an accompanying efficient mixed-signal\nhardware implementation of the model. The proposed design leverages\nswitched-capacitor circuits not only for in-memory computation (IMC), but also\nfor the gated state updates. The mixed-signal cores rely solely on commodity\ncircuits consisting of metal capacitors, transmission gates, and a clocked\ncomparator, thus greatly facilitating scaling and transfer to other technology\nnodes.\n  We benchmark the performance of our architecture on time series data,\nintroducing all constraints required for a direct mapping to the hardware\nsystem. The direct compatibility is verified in mixed-signal simulations,\nreproducing data recorded from the software-only network model.",
      "tldr_zh": "本研究提出MINIMALIST架构，一种基于最小化gated recurrent units (GRUs)的流线型设计，旨在提升RNNs在内存受限嵌入式边缘计算环境中的时间序列数据处理效率。该架构利用switched-capacitor circuits进行in-memory computation (IMC)和gated state updates，仅依赖简单的商品电路如metal capacitors、transmission gates和clocked comparator，便于技术节点扩展。实验结果显示，该设计在时间序列数据基准测试中表现出色，并通过mixed-signal simulations验证了与软件模型的直接兼容性。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08599v1",
      "published_date": "2025-05-13 14:13:41 UTC",
      "updated_date": "2025-05-13 14:13:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:29:37.331072"
    },
    {
      "arxiv_id": "2505.08589v1",
      "title": "MESSI: A Multi-Elevation Semantic Segmentation Image Dataset of an Urban Environment",
      "title_zh": "MESSI：城市环境的多高度语义分割图像数据集",
      "authors": [
        "Barak Pinkovich",
        "Boaz Matalon",
        "Ehud Rivlin",
        "Hector Rotstein"
      ],
      "abstract": "This paper presents a Multi-Elevation Semantic Segmentation Image (MESSI)\ndataset comprising 2525 images taken by a drone flying over dense urban\nenvironments. MESSI is unique in two main features. First, it contains images\nfrom various altitudes, allowing us to investigate the effect of depth on\nsemantic segmentation. Second, it includes images taken from several different\nurban regions (at different altitudes). This is important since the variety\ncovers the visual richness captured by a drone's 3D flight, performing\nhorizontal and vertical maneuvers. MESSI contains images annotated with\nlocation, orientation, and the camera's intrinsic parameters and can be used to\ntrain a deep neural network for semantic segmentation or other applications of\ninterest (e.g., localization, navigation, and tracking). This paper describes\nthe dataset and provides annotation details. It also explains how semantic\nsegmentation was performed using several neural network models and shows\nseveral relevant statistics. MESSI will be published in the public domain to\nserve as an evaluation benchmark for semantic segmentation using images\ncaptured by a drone or similar vehicle flying over a dense urban environment.",
      "tldr_zh": "本研究引入了MESSI数据集，该数据集包含2525张由无人机在密集城市环境中拍摄的图像，独特之处在于图像来自不同高度和多个城市区域，从而允许研究高度对语义分割的影响。数据集标注了位置、方向和相机内在参数，可用于训练深度神经网络进行语义分割或其他应用，如定位、导航和跟踪。论文详细描述了数据集的标注过程、神经网络模型的性能统计，并将MESSI公开发布，作为无人机图像语义分割的基准评估工具。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08589v1",
      "published_date": "2025-05-13 14:01:07 UTC",
      "updated_date": "2025-05-13 14:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:29:49.649076"
    },
    {
      "arxiv_id": "2505.08588v1",
      "title": "Small but Significant: On the Promise of Small Language Models for Accessible AIED",
      "title_zh": "翻译失败",
      "authors": [
        "Yumou Wei",
        "Paulo Carvalho",
        "John Stamper"
      ],
      "abstract": "GPT has become nearly synonymous with large language models (LLMs), an\nincreasingly popular term in AIED proceedings. A simple keyword-based search\nreveals that 61% of the 76 long and short papers presented at AIED 2024\ndescribe novel solutions using LLMs to address some of the long-standing\nchallenges in education, and 43% specifically mention GPT. Although LLMs\npioneered by GPT create exciting opportunities to strengthen the impact of AI\non education, we argue that the field's predominant focus on GPT and other\nresource-intensive LLMs (with more than 10B parameters) risks neglecting the\npotential impact that small language models (SLMs) can make in providing\nresource-constrained institutions with equitable and affordable access to\nhigh-quality AI tools. Supported by positive results on knowledge component\n(KC) discovery, a critical challenge in AIED, we demonstrate that SLMs such as\nPhi-2 can produce an effective solution without elaborate prompting strategies.\nHence, we call for more attention to developing SLM-based AIED approaches.",
      "tldr_zh": "这篇论文强调，在AIED（AI in Education）领域，过度依赖资源密集型大型语言模型（LLMs）如GPT，可能忽略小型语言模型（SLMs）的潜力，后者能为资源有限的机构提供公平、负担得起的AI工具。作者通过知识组件（KC）发现实验，证明SLMs如Phi-2无需复杂提示策略即可产生有效解决方案。研究呼吁更多关注基于SLM的AIED方法，以促进教育AI的可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "This vision paper advocates using small language models (e.g., Phi-2)\n  in AI for education (AIED)",
      "pdf_url": "http://arxiv.org/pdf/2505.08588v1",
      "published_date": "2025-05-13 13:58:29 UTC",
      "updated_date": "2025-05-13 13:58:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:30:02.416638"
    },
    {
      "arxiv_id": "2505.08552v1",
      "title": "DFA-CON: A Contrastive Learning Approach for Detecting Copyright Infringement in DeepFake Art",
      "title_zh": "DFA-CON：一种用于检测 DeepFake 艺术中版权侵权的对比学习方法",
      "authors": [
        "Haroon Wahab",
        "Hassan Ugail",
        "Irfan Mehmood"
      ],
      "abstract": "Recent proliferation of generative AI tools for visual content\ncreation-particularly in the context of visual artworks-has raised serious\nconcerns about copyright infringement and forgery. The large-scale datasets\nused to train these models often contain a mixture of copyrighted and\nnon-copyrighted artworks. Given the tendency of generative models to memorize\ntraining patterns, they are susceptible to varying degrees of copyright\nviolation. Building on the recently proposed DeepfakeArt Challenge benchmark,\nthis work introduces DFA-CON, a contrastive learning framework designed to\ndetect copyright-infringing or forged AI-generated art. DFA-CON learns a\ndiscriminative representation space, posing affinity among original artworks\nand their forged counterparts within a contrastive learning framework. The\nmodel is trained across multiple attack types, including inpainting, style\ntransfer, adversarial perturbation, and cutmix. Evaluation results demonstrate\nrobust detection performance across most attack types, outperforming recent\npretrained foundation models. Code and model checkpoints will be released\npublicly upon acceptance.",
      "tldr_zh": "本研究针对生成式 AI 在视觉艺术中导致的版权侵犯和伪造问题，提出了 DFA-CON，一种基于 contrastive learning 的框架，用于检测 AI 生成艺术中的侵权内容。该框架通过学习一个 discriminative representation space，将原创艺术品及其伪造版本在对比学习中建立亲和关系，并针对多种攻击类型（如 inpainting、style transfer、adversarial perturbation 和 cutmix）进行训练。实验结果显示，DFA-CON 在 DeepfakeArt Challenge 基准上表现出色，检测性能优于现有预训练基础模型，并计划公开代码和模型检查点。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08552v1",
      "published_date": "2025-05-13 13:23:52 UTC",
      "updated_date": "2025-05-13 13:23:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:30:15.078998"
    },
    {
      "arxiv_id": "2505.08548v1",
      "title": "From Seeing to Doing: Bridging Reasoning and Decision for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Yifu Yuan",
        "Haiqin Cui",
        "Yibin Chen",
        "Zibin Dong",
        "Fei Ni",
        "Longxin Kou",
        "Jinyi Liu",
        "Pengyi Li",
        "Yan Zheng",
        "Jianye Hao"
      ],
      "abstract": "Achieving generalization in robotic manipulation remains a critical\nchallenge, particularly for unseen scenarios and novel tasks. Current\nVision-Language-Action (VLA) models, while building on top of general\nVision-Language Models (VLMs), still fall short of achieving robust zero-shot\nperformance due to the scarcity and heterogeneity prevalent in embodied\ndatasets. To address these limitations, we propose FSD (From Seeing to Doing),\na novel vision-language model that generates intermediate representations\nthrough spatial relationship reasoning, providing fine-grained guidance for\nrobotic manipulation. Our approach combines a hierarchical data pipeline for\ntraining with a self-consistency mechanism that aligns spatial coordinates with\nvisual signals. Through extensive experiments, we comprehensively validated\nFSD's capabilities in both \"seeing\" and \"doing,\" achieving outstanding\nperformance across 8 benchmarks for general spatial reasoning and embodied\nreference abilities, as well as on our proposed more challenging benchmark\nVABench. We also verified zero-shot capabilities in robot manipulation,\ndemonstrating significant performance improvements over baseline methods in\nboth SimplerEnv and real robot settings. Experimental results show that FSD\nachieves 54.1% success rate in SimplerEnv and 72% success rate across 8\nreal-world tasks, outperforming the strongest baseline by 30%.",
      "tldr_zh": "该论文提出 FSD（From Seeing to Doing）模型，以解决机器人操作中泛化挑战，特别是对新场景和新任务的 Vision-Language-Action (VLA) 模型零样本性能不足问题。FSD 通过空间关系推理生成中间表示，并结合 hierarchical data pipeline 和 self-consistency mechanism，将空间坐标与视觉信号对齐，提供细粒度的操作指导。实验结果显示，FSD 在 8 个基准测试和新提出的 VABench 上表现出色，并在 SimplerEnv 中实现 54.1% 成功率，以及在 8 个真实机器人任务中达到 72% 成功率，比最强基线方法提升 30%。这验证了 FSD 在 zero-shot 机器人操作中的显著性能优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Early version",
      "pdf_url": "http://arxiv.org/pdf/2505.08548v1",
      "published_date": "2025-05-13 13:20:46 UTC",
      "updated_date": "2025-05-13 13:20:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:30:27.512593"
    },
    {
      "arxiv_id": "2505.08542v1",
      "title": "Guiding LLM-based Smart Contract Generation with Finite State Machine",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Luo",
        "Yuhao Lin",
        "Xiao Yan",
        "Xintong Hu",
        "Yuxiang Wang",
        "Qiming Zeng",
        "Hao Wang",
        "Jiawei Jiang"
      ],
      "abstract": "Smart contract is a kind of self-executing code based on blockchain\ntechnology with a wide range of application scenarios, but the traditional\ngeneration method relies on manual coding and expert auditing, which has a high\nthreshold and low efficiency. Although Large Language Models (LLMs) show great\npotential in programming tasks, they still face challenges in smart contract\ngeneration w.r.t. effectiveness and security. To solve these problems, we\npropose FSM-SCG, a smart contract generation framework based on finite state\nmachine (FSM) and LLMs, which significantly improves the quality of the\ngenerated code by abstracting user requirements to generate FSM, guiding LLMs\nto generate smart contracts, and iteratively optimizing the code with the\nfeedback of compilation and security checks. The experimental results show that\nFSM-SCG significantly improves the quality of smart contract generation.\nCompared to the best baseline, FSM-SCG improves the compilation success rate of\ngenerated smart contract code by at most 48%, and reduces the average\nvulnerability risk score by approximately 68%.",
      "tldr_zh": "这篇论文提出 FSM-SCG 框架，利用有限状态机 (FSM) 指导大语言模型 (LLMs) 生成智能合约，以解决传统手动编码的门槛高和效率低问题，以及 LLMs 在有效性和安全性方面的挑战。该框架通过将用户需求抽象为 FSM、引导 LLMs 生成代码，并基于编译和安全检查的反馈进行迭代优化，从而显著提升生成代码的质量。实验结果显示，与最佳基线相比，FSM-SCG 将智能合约的编译成功率提高了最多 48%，并将平均漏洞风险分数降低了约 68%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08542v1",
      "published_date": "2025-05-13 13:13:26 UTC",
      "updated_date": "2025-05-13 13:13:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:30:37.654058"
    },
    {
      "arxiv_id": "2505.08532v1",
      "title": "The Truth Becomes Clearer Through Debate! Multi-Agent Systems with Large Language Models Unmask Fake News",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Liu",
        "Yuxuan Liu",
        "Xiaoqing Zhang",
        "Xiuying Chen",
        "Rui Yan"
      ],
      "abstract": "In today's digital environment, the rapid propagation of fake news via social\nnetworks poses significant social challenges. Most existing detection methods\neither employ traditional classification models, which suffer from low\ninterpretability and limited generalization capabilities, or craft specific\nprompts for large language models (LLMs) to produce explanations and results\ndirectly, failing to leverage LLMs' reasoning abilities fully. Inspired by the\nsaying that \"truth becomes clearer through debate,\" our study introduces a\nnovel multi-agent system with LLMs named TruEDebate (TED) to enhance the\ninterpretability and effectiveness of fake news detection. TED employs a\nrigorous debate process inspired by formal debate settings. Central to our\napproach are two innovative components: the DebateFlow Agents and the\nInsightFlow Agents. The DebateFlow Agents organize agents into two teams, where\none supports and the other challenges the truth of the news. These agents\nengage in opening statements, cross-examination, rebuttal, and closing\nstatements, simulating a rigorous debate process akin to human discourse\nanalysis, allowing for a thorough evaluation of news content. Concurrently, the\nInsightFlow Agents consist of two specialized sub-agents: the Synthesis Agent\nand the Analysis Agent. The Synthesis Agent summarizes the debates and provides\nan overarching viewpoint, ensuring a coherent and comprehensive evaluation. The\nAnalysis Agent, which includes a role-aware encoder and a debate graph,\nintegrates role embeddings and models the interactions between debate roles and\narguments using an attention mechanism, providing the final judgment.",
      "tldr_zh": "本文提出了一种名为 TruEDebate (TED) 的多智能体系统，利用 Large Language Models (LLMs) 通过模拟辩论过程来提升假新闻检测的解释性和有效性，以解决传统分类模型的泛化能力不足和现有 LLM 提示方法的局限性。系统核心包括 DebateFlow Agents，它们将代理分成支持与挑战两队，进行开场陈述、交叉审问、反驳和结尾陈述，以全面评估新闻内容。InsightFlow Agents 则由 Synthesis Agent 和 Analysis Agent 组成，前者总结辩论并提供整体观点，后者通过角色感知编码器和辩论图整合互动信息给出最终判断。这种方法充分利用了 LLMs 的推理能力，有望在假新闻检测中实现更可靠的评估。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08532v1",
      "published_date": "2025-05-13 13:03:20 UTC",
      "updated_date": "2025-05-13 13:03:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:30:51.266342"
    },
    {
      "arxiv_id": "2505.08529v1",
      "title": "ExEBench: Benchmarking Foundation Models on Extreme Earth Events",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Zhao",
        "Zhitong Xiong",
        "Jie Zhao",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Our planet is facing increasingly frequent extreme events, which pose major\nrisks to human lives and ecosystems. Recent advances in machine learning (ML),\nespecially with foundation models (FMs) trained on extensive datasets, excel in\nextracting features and show promise in disaster management. Nevertheless,\nthese models often inherit biases from training data, challenging their\nperformance over extreme values. To explore the reliability of FM in the\ncontext of extreme events, we introduce \\textbf{ExE}Bench (\\textbf{Ex}treme\n\\textbf{E}arth Benchmark), a collection of seven extreme event categories\nacross floods, wildfires, storms, tropical cyclones, extreme precipitation,\nheatwaves, and cold waves. The dataset features global coverage, varying data\nvolumes, and diverse data sources with different spatial, temporal, and\nspectral characteristics. To broaden the real-world impact of FMs, we include\nmultiple challenging ML tasks that are closely aligned with operational needs\nin extreme events detection, monitoring, and forecasting. ExEBench aims to (1)\nassess FM generalizability across diverse, high-impact tasks and domains, (2)\npromote the development of novel ML methods that benefit disaster management,\nand (3) offer a platform for analyzing the interactions and cascading effects\nof extreme events to advance our understanding of Earth system, especially\nunder the climate change expected in the decades to come. The dataset and code\nare public https://github.com/zhaoshan2/EarthExtreme-Bench.",
      "tldr_zh": "本研究引入了 ExEBench，这是一个基准数据集，用于评估 Foundation Models (FMs) 在极端地球事件（如洪水、野火、风暴、热浪等七个类别）上的性能，以解决模型在极端值上存在的偏见和可靠性问题。ExEBench 包含全球覆盖的数据、多样数据来源（不同空间、时间和光谱特性），并设计了多种 ML 任务，聚焦于极端事件的检测、监测和预测。数据集旨在评估 FMs 的泛化能力，促进新型 ML 方法的发展，并提供平台分析极端事件的相互作用及其在气候变化下的级联效应；相关代码已在 GitHub 上公开。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08529v1",
      "published_date": "2025-05-13 13:02:04 UTC",
      "updated_date": "2025-05-13 13:02:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:31:01.612345"
    },
    {
      "arxiv_id": "2505.08528v1",
      "title": "GradMix: Gradient-based Selective Mixup for Robust Data Augmentation in Class-Incremental Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Minsu Kim",
        "Seong-Hyeon Hwang",
        "Steven Euijong Whang"
      ],
      "abstract": "In the context of continual learning, acquiring new knowledge while\nmaintaining previous knowledge presents a significant challenge. Existing\nmethods often use experience replay techniques that store a small portion of\nprevious task data for training. In experience replay approaches, data\naugmentation has emerged as a promising strategy to further improve the model\nperformance by mixing limited previous task data with sufficient current task\ndata. However, we theoretically and empirically analyze that training with\nmixed samples from random sample pairs may harm the knowledge of previous tasks\nand cause greater catastrophic forgetting. We then propose GradMix, a robust\ndata augmentation method specifically designed for mitigating catastrophic\nforgetting in class-incremental learning. GradMix performs gradient-based\nselective mixup using a class-based criterion that mixes only samples from\nhelpful class pairs and not from detrimental class pairs for reducing\ncatastrophic forgetting. Our experiments on various real datasets show that\nGradMix outperforms data augmentation baselines in accuracy by minimizing the\nforgetting of previous knowledge.",
      "tldr_zh": "本文研究了在类增量学习（class-incremental learning）中，使用数据增强技术（如混合样本）可能导致灾难性遗忘（catastrophic forgetting）的挑战，通过理论和实证分析证明随机样本混合会损害旧知识。提出 GradMix，一种基于梯度的选择性混合（gradient-based selective mixup）方法，该方法使用基于类的标准，仅混合有助于减少遗忘的类对样本，而避免有害的类对。实验结果显示，GradMix 在各种真实数据集上比基线数据增强方法在准确率上表现出色，有效最小化了旧知识的遗忘。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08528v1",
      "published_date": "2025-05-13 13:01:38 UTC",
      "updated_date": "2025-05-13 13:01:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:31:15.068954"
    },
    {
      "arxiv_id": "2505.08522v1",
      "title": "On the Complexity and Properties of Preferential Propositional Dependence Logic",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Sauerwald",
        "Arne Meier",
        "Juha Kontinen"
      ],
      "abstract": "This paper considers the complexity and properties of KLM-style preferential\nreasoning in the setting of propositional logic with team semantics and\ndependence atoms, also known as propositional dependence logic. Preferential\nteam-based reasoning is shown to be cumulative, yet violates System~P. We give\nintuitive conditions that fully characterise those cases where preferential\npropositional dependence logic satisfies System~P. We show that these\ncharacterisations do, surprisingly, not carry over to preferential team-based\npropositional logic. Furthermore, we show how classical entailment and\ndependence logic entailment can be expressed in terms of non-trivial\npreferential models. Finally, we present the complexity of preferential\nteam-based reasoning for two natural representations. This includes novel\ncomplexity results for classical (non-team-based) preferential reasoning.",
      "tldr_zh": "这篇论文探讨了 KLM-style preferential reasoning 在命题逻辑（propositional logic）中结合团队语义（team semantics）和依赖原子（dependence atoms）的复杂性和属性。研究发现，preferential team-based reasoning 是 cumulative 的，但违反了 System P，并给出了直观的条件来完全表征 preferential propositional dependence logic 满足 System P 的情况。这些条件意外地不适用于 preferential team-based propositional logic；此外，论文展示了如何用非平凡的 preferential 模型表达经典蕴涵和依赖逻辑蕴涵，并分析了两种自然表示下的 preferential team-based reasoning 的复杂性，包括一些经典（非团队-based）preferential reasoning 的新复杂性结果。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "03B70, 03B62",
        "I.2.3; F.4.1"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08522v1",
      "published_date": "2025-05-13 12:54:59 UTC",
      "updated_date": "2025-05-13 12:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:31:28.300737"
    },
    {
      "arxiv_id": "2505.08516v1",
      "title": "Learning Advanced Self-Attention for Linear Transformers in the Singular Value Domain",
      "title_zh": "在奇异值域中学习线性Transformer的高级自注意力机制",
      "authors": [
        "Hyowon Wi",
        "Jeongwhan Choi",
        "Noseong Park"
      ],
      "abstract": "Transformers have demonstrated remarkable performance across diverse domains.\nThe key component of Transformers is self-attention, which learns the\nrelationship between any two tokens in the input sequence. Recent studies have\nrevealed that the self-attention can be understood as a normalized adjacency\nmatrix of a graph. Notably, from the perspective of graph signal processing\n(GSP), the self-attention can be equivalently defined as a simple graph filter,\napplying GSP using the value vector as the signal. However, the self-attention\nis a graph filter defined with only the first order of the polynomial matrix,\nand acts as a low-pass filter preventing the effective leverage of various\nfrequency information. Consequently, existing self-attention mechanisms are\ndesigned in a rather simplified manner. Therefore, we propose a novel method,\ncalled \\underline{\\textbf{A}}ttentive \\underline{\\textbf{G}}raph\n\\underline{\\textbf{F}}ilter (AGF), interpreting the self-attention as learning\nthe graph filter in the singular value domain from the perspective of graph\nsignal processing for directed graphs with the linear complexity w.r.t. the\ninput length $n$, i.e., $\\mathcal{O}(nd^2)$. In our experiments, we demonstrate\nthat AGF achieves state-of-the-art performance on various tasks, including Long\nRange Arena benchmark and time series classification.",
      "tldr_zh": "本研究探讨了 Transformers 中 self-attention 机制的局限性，通过 Graph Signal Processing (GSP) 视角，将其视为一阶图滤波器（低通滤波器），这导致无法有效利用各种频率信息。针对这一问题，作者提出了一种新方法 Attentive Graph Filter (AGF)，它将 self-attention 解释为在 Singular Value Domain 中学习图滤波器，支持有向图，并实现线性复杂度 O(nd^2)。实验结果显示，AGF 在 Long Range Arena 基准和时间序列分类任务上取得了最先进性能，证明了其在处理长序列方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI25 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.08516v1",
      "published_date": "2025-05-13 12:48:04 UTC",
      "updated_date": "2025-05-13 12:48:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:31:38.439157"
    },
    {
      "arxiv_id": "2505.08508v1",
      "title": "TrialMatchAI: An End-to-End AI-powered Clinical Trial Recommendation System to Streamline Patient-to-Trial Matching",
      "title_zh": "TrialMatchAI：端到端的AI驱动临床试验推荐系统，用于优化患者到试验匹配",
      "authors": [
        "Majd Abdallah",
        "Sigve Nakken",
        "Mariska Bierkens",
        "Johanna Galvis",
        "Alexis Groppi",
        "Slim Karkar",
        "Lana Meiqari",
        "Maria Alexandra Rujano",
        "Steve Canham",
        "Rodrigo Dienstmann",
        "Remond Fijneman",
        "Eivind Hovig",
        "Gerrit Meijer",
        "Macha Nikolski"
      ],
      "abstract": "Patient recruitment remains a major bottleneck in clinical trials, calling\nfor scalable and automated solutions. We present TrialMatchAI, an AI-powered\nrecommendation system that automates patient-to-trial matching by processing\nheterogeneous clinical data, including structured records and unstructured\nphysician notes. Built on fine-tuned, open-source large language models (LLMs)\nwithin a retrieval-augmented generation framework, TrialMatchAI ensures\ntransparency and reproducibility and maintains a lightweight deployment\nfootprint suitable for clinical environments. The system normalizes biomedical\nentities, retrieves relevant trials using a hybrid search strategy combining\nlexical and semantic similarity, re-ranks results, and performs criterion-level\neligibility assessments using medical Chain-of-Thought reasoning. This pipeline\ndelivers explainable outputs with traceable decision rationales. In real-world\nvalidation, 92 percent of oncology patients had at least one relevant trial\nretrieved within the top 20 recommendations. Evaluation across synthetic and\nreal clinical datasets confirmed state-of-the-art performance, with expert\nassessment validating over 90 percent accuracy in criterion-level eligibility\nclassification, particularly excelling in biomarker-driven matches. Designed\nfor modularity and privacy, TrialMatchAI supports Phenopackets-standardized\ndata, enables secure local deployment, and allows seamless replacement of LLM\ncomponents as more advanced models emerge. By enhancing efficiency and\ninterpretability and offering lightweight, open-source deployment, TrialMatchAI\nprovides a scalable solution for AI-driven clinical trial matching in precision\nmedicine.",
      "tldr_zh": "本研究介绍了 TrialMatchAI，一种端到端的 AI 驱动临床试验推荐系统，旨在通过处理异构临床数据（如结构化记录和非结构化医师笔记）来自动化患者与试验匹配，从而缓解临床试验招募的瓶颈。系统基于微调的开源大型语言模型 (LLMs) 和检索增强生成框架 (retrieval-augmented generation)，结合混合搜索策略（包括词汇和语义相似性）、再排序以及医疗 Chain-of-Thought 推理，进行生物医学实体标准化和资格评估，提供可解释的决策输出。在真实验证中，TrialMatchAI 在肿瘤学患者中实现92%的 top 20 推荐相关率，并在合成和真实数据集上达到最先进性能，资格分类准确率超过90%，尤其在生物标志物驱动匹配中表现出色。该系统设计模块化、隐私友好，支持 Phenopackets 标准化数据和本地部署，为精确医学提供可扩展的开源解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08508v1",
      "published_date": "2025-05-13 12:39:06 UTC",
      "updated_date": "2025-05-13 12:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:31:52.279992"
    },
    {
      "arxiv_id": "2505.08498v1",
      "title": "LCES: Zero-shot Automated Essay Scoring via Pairwise Comparisons Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Takumi Shibata",
        "Yuichi Miyamura"
      ],
      "abstract": "Recent advances in large language models (LLMs) have enabled zero-shot\nautomated essay scoring (AES), providing a promising way to reduce the cost and\neffort of essay scoring in comparison with manual grading. However, most\nexisting zero-shot approaches rely on LLMs to directly generate absolute\nscores, which often diverge from human evaluations owing to model biases and\ninconsistent scoring. To address these limitations, we propose LLM-based\nComparative Essay Scoring (LCES), a method that formulates AES as a pairwise\ncomparison task. Specifically, we instruct LLMs to judge which of two essays is\nbetter, collect many such comparisons, and convert them into continuous scores.\nConsidering that the number of possible comparisons grows quadratically with\nthe number of essays, we improve scalability by employing RankNet to\nefficiently transform LLM preferences into scalar scores. Experiments using AES\nbenchmark datasets show that LCES outperforms conventional zero-shot methods in\naccuracy while maintaining computational efficiency. Moreover, LCES is robust\nacross different LLM backbones, highlighting its applicability to real-world\nzero-shot AES.",
      "tldr_zh": "该研究提出LCES方法，利用Large Language Models (LLMs)通过成对比较(pairwise comparisons)实现零样本自动作文评分 (zero-shot AES)，以解决现有方法因模型偏差和评分不一致而偏离人类评估的问题。具体而言，LCES指导LLMs判断两篇作文孰优，收集比较结果并使用RankNet高效转换为连续分数，从而提升可扩展性和准确性。实验在AES基准数据集上显示，LCES在准确性上优于传统零样本方法，同时保持计算效率，并在不同LLM基础上表现出色，适用于实际场景。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08498v1",
      "published_date": "2025-05-13 12:26:16 UTC",
      "updated_date": "2025-05-13 12:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:32:01.776796"
    },
    {
      "arxiv_id": "2505.08492v2",
      "title": "Achieving Scalable Robot Autonomy via neurosymbolic planning using lightweight local LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Nicholas Attolino",
        "Alessio Capitanelli",
        "Fulvio Mastrogiovanni"
      ],
      "abstract": "PDDL-based symbolic task planning remains pivotal for robot autonomy yet\nstruggles with dynamic human-robot collaboration due to scalability,\nre-planning demands, and delayed plan availability. Although a few\nneurosymbolic frameworks have previously leveraged LLMs such as GPT-3 to\naddress these challenges, reliance on closed-source, remote models with limited\ncontext introduced critical constraints: third-party dependency, inconsistent\nresponse times, restricted plan length and complexity, and multi-domain\nscalability issues. We present Gideon, a novel framework that enables the\ntransition to modern, smaller, local LLMs with extended context length. Gideon\nintegrates a novel problem generator to systematically generate large-scale\ndatasets of realistic domain-problem-plan tuples for any domain, and adapts\nneurosymbolic planning for local LLMs, enabling on-device execution and\nextended context for multi-domain support. Preliminary experiments in\nsingle-domain scenarios performed on Qwen-2.5 1.5B and trained on 8k-32k\nsamples, demonstrate a valid plan percentage of 66.1% (32k model) and show that\nthe figure can be further scaled through additional data. Multi-domain tests on\n16k samples yield an even higher 70.6% planning validity rate, proving\nextensibility across domains and signaling that data variety can have a\npositive effect on learning efficiency. Although long-horizon planning and\nreduced model size make Gideon training much less efficient than baseline\nmodels based on larger LLMs, the results are still significant considering that\nthe trained model is about 120x smaller than baseline and that significant\nadvantages can be achieved in inference efficiency, scalability, and\nmulti-domain adaptability, all critical factors in human-robot collaboration.\nTraining inefficiency can be mitigated by Gideon's streamlined data generation\npipeline.",
      "tldr_zh": "本研究针对PDDL-based symbolic task planning在动态人机协作中的可伸缩性、再规划需求和延迟问题，提出Gideon框架，使用轻量级本地LLM（如Qwen-2.5 1.5B）实现neurosymbolic planning的改进。Gideon整合了一个新颖的问题生成器，系统生成大规模的真实域-问题-计划数据集，并适应本地LLM以支持设备端执行和扩展上下文的多域应用。实验结果显示，在单域场景中训练8k-32k样本后，模型达到66.1%（32k样本）的有效计划百分比，而多域测试在16k样本下达70.6%，证明数据多样性提升了学习效率；尽管训练效率较低，但Gideon的模型大小约比基线小120倍，在推理效率、可伸缩性和多域适应性上具有显著优势，可通过其流线型数据生成管道缓解训练瓶颈。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO",
        "I.2.6; I.2.8; I.2.9"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 3 figures, 4 tables, accepted at IAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08492v2",
      "published_date": "2025-05-13 12:22:38 UTC",
      "updated_date": "2025-05-17 11:55:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:32:15.730254"
    },
    {
      "arxiv_id": "2505.08487v1",
      "title": "An adaptive sampling algorithm for data-generation to build a data-manifold for physical problem surrogate modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Chetra Mang",
        "Axel TahmasebiMoradi",
        "David Danan",
        "Mouadh Yagoubi"
      ],
      "abstract": "Physical models classically involved Partial Differential equations (PDE) and\ndepending of their underlying complexity and the level of accuracy required,\nand known to be computationally expensive to numerically solve them. Thus, an\nidea would be to create a surrogate model relying on data generated by such\nsolver. However, training such a model on an imbalanced data have been shown to\nbe a very difficult task. Indeed, if the distribution of input leads to a poor\nresponse manifold representation, the model may not learn well and\nconsequently, it may not predict the outcome with acceptable accuracy. In this\nwork, we present an Adaptive Sampling Algorithm for Data Generation (ASADG)\ninvolving a physical model. As the initial input data may not accurately\nrepresent the response manifold in higher dimension, this algorithm iteratively\nadds input data into it. At each step the barycenter of each simplicial\ncomplex, that the manifold is discretized into, is added as new input data, if\na certain threshold is satisfied. We demonstrate the efficiency of the data\nsampling algorithm in comparison with LHS method for generating more\nrepresentative input data. To do so, we focus on the construction of a harmonic\ntransport problem metamodel by generating data through a classical solver. By\nusing such algorithm, it is possible to generate the same number of input data\nas LHS while providing a better representation of the response manifold.",
      "tldr_zh": "这篇论文针对物理问题代理建模提出了一种自适应采样算法 ASADG，用于生成更具代表性的输入数据以构建数据流形。ASADG 通过迭代计算单纯复形（simplicial complex）的重心，并在满足阈值条件下添加新数据点，从而解决传统数据不平衡导致的模型训练难题。实验结果显示，与 LHS 方法相比，ASADG 在谐波传输问题上生成相同数量的数据却提供了更好的响应流形表示，提高了代理模型的预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08487v1",
      "published_date": "2025-05-13 12:17:10 UTC",
      "updated_date": "2025-05-13 12:17:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:32:26.523046"
    },
    {
      "arxiv_id": "2505.09651v1",
      "title": "Unlocking Location Intelligence: A Survey from Deep Learning to The LLM Era",
      "title_zh": "翻译失败",
      "authors": [
        "Xixuan Hao",
        "Yutian Jiang",
        "Xingchen Zou",
        "Jiabo Liu",
        "Yifang Yin",
        "Yuxuan Liang"
      ],
      "abstract": "Location Intelligence (LI), the science of transforming location-centric\ngeospatial data into actionable knowledge, has become a cornerstone of modern\nspatial decision-making. The rapid evolution of Geospatial Representation\nLearning is fundamentally reshaping LI development through two successive\ntechnological revolutions: the deep learning breakthrough and the emerging\nlarge language model (LLM) paradigm. While deep neural networks (DNNs) have\ndemonstrated remarkable success in automated feature extraction from structured\ngeospatial data (e.g., satellite imagery, GPS trajectories), the recent\nintegration of LLMs introduces transformative capabilities for cross-modal\ngeospatial reasoning and unstructured geo-textual data processing. This survey\npresents a comprehensive review of geospatial representation learning across\nboth technological eras, organizing them into a structured taxonomy based on\nthe complete pipeline comprising: (1) data perspective, (2) methodological\nperspective and (3) application perspective. We also highlight current\nadvancements, discuss existing limitations, and propose potential future\nresearch directions in the LLM era. This work offers a thorough exploration of\nthe field and providing a roadmap for further innovation in LI. The summary of\nthe up-to-date paper list can be found in\nhttps://github.com/CityMind-Lab/Awesome-Location-Intelligence and will undergo\ncontinuous updates.",
      "tldr_zh": "这篇调查论文探讨了 Location Intelligence (LI)，即将位置中心地理空间数据转化为可行动知识的核心科学，从 Deep Learning 到 Large Language Models (LLMs) 时代的演进。论文回顾了 Geospatial Representation Learning 的发展，强调 Deep Neural Networks (DNNs) 在结构化数据（如卫星图像和 GPS 轨迹）特征提取中的成功，以及 LLMs 在跨模态地理空间推理和非结构化数据处理中的变革性作用。通过数据视角、方法视角和应用视角的结构化分类，论文总结了当前进展、现有局限性，并提出 LLM 时代的未来研究方向。该工作为 LI 领域的创新提供了全面路线图。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.09651v1",
      "published_date": "2025-05-13 12:16:26 UTC",
      "updated_date": "2025-05-13 12:16:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:32:39.686703"
    },
    {
      "arxiv_id": "2505.08485v1",
      "title": "BAT: Benchmark for Auto-bidding Task",
      "title_zh": "翻译失败",
      "authors": [
        "Alexandra Khirianova",
        "Ekaterina Solodneva",
        "Andrey Pudovikov",
        "Sergey Osokin",
        "Egor Samosvat",
        "Yuriy Dorn",
        "Alexander Ledovsky",
        "Yana Zenkova"
      ],
      "abstract": "The optimization of bidding strategies for online advertising slot auctions\npresents a critical challenge across numerous digital marketplaces. A\nsignificant obstacle to the development, evaluation, and refinement of\nreal-time autobidding algorithms is the scarcity of comprehensive datasets and\nstandardized benchmarks.\n  To address this deficiency, we present an auction benchmark encompassing the\ntwo most prevalent auction formats. We implement a series of robust baselines\non a novel dataset, addressing the most salient Real-Time Bidding (RTB) problem\ndomains: budget pacing uniformity and Cost Per Click (CPC) constraint\noptimization. This benchmark provides a user-friendly and intuitive framework\nfor researchers and practitioners to develop and refine innovative autobidding\nalgorithms, thereby facilitating advancements in the field of programmatic\nadvertising. The implementation and additional resources can be accessed at the\nfollowing repository (https://github.com/avito-tech/bat-autobidding-benchmark,\nhttps://doi.org/10.5281/zenodo.14794182).",
      "tldr_zh": "本研究针对在线广告竞价策略优化中的关键挑战——缺乏全面数据集和标准化基准——引入了 BAT 基准，涵盖两种最常见的拍卖格式。研究者使用一个新数据集实现了多个基线模型，专注于 Real-Time Bidding (RTB) 领域的预算 pacing uniformity 和 Cost Per Click (CPC) 约束优化问题。该基准提供了一个用户友好的框架，帮助研究者和从业者开发及改进自动竞价算法，从而推动程序化广告领域的创新和进步。资源可通过 GitHub 仓库（https://github.com/avito-tech/bat-autobidding-benchmark）和 DOI（https://doi.org/10.5281/zenodo.14794182）获取。",
      "categories": [
        "cs.AI",
        "stat.ML",
        "91B26"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 10 figures, WWW 2025 conference",
      "pdf_url": "http://arxiv.org/pdf/2505.08485v1",
      "published_date": "2025-05-13 12:12:34 UTC",
      "updated_date": "2025-05-13 12:12:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:32:51.446324"
    },
    {
      "arxiv_id": "2505.08474v1",
      "title": "Distributed Quantum Neural Networks on Distributed Photonic Quantum Computing",
      "title_zh": "分布式量子神经网络在分布式光子量子计算上",
      "authors": [
        "Kuan-Cheng Chen",
        "Chen-Yu Liu",
        "Yu Shang",
        "Felix Burt",
        "Kin K. Leung"
      ],
      "abstract": "We introduce a distributed quantum-classical framework that synergizes\nphotonic quantum neural networks (QNNs) with matrix-product-state (MPS) mapping\nto achieve parameter-efficient training of classical neural networks. By\nleveraging universal linear-optical decompositions of $M$-mode interferometers\nand photon-counting measurement statistics, our architecture generates neural\nparameters through a hybrid quantum-classical workflow: photonic QNNs with\n$M(M+1)/2$ trainable parameters produce high-dimensional probability\ndistributions that are mapped to classical network weights via an MPS model\nwith bond dimension $\\chi$. Empirical validation on MNIST classification\ndemonstrates that photonic QT achieves an accuracy of $95.50\\% \\pm 0.84\\%$\nusing 3,292 parameters ($\\chi = 10$), compared to $96.89\\% \\pm 0.31\\%$ for\nclassical baselines with 6,690 parameters. Moreover, a ten-fold compression\nratio is achieved at $\\chi = 4$, with a relative accuracy loss of less than\n$3\\%$. The framework outperforms classical compression techniques (weight\nsharing/pruning) by 6--12\\% absolute accuracy while eliminating quantum\nhardware requirements during inference through classical deployment of\ncompressed parameters. Simulations incorporating realistic photonic noise\ndemonstrate the framework's robustness to near-term hardware imperfections.\nAblation studies confirm quantum necessity: replacing photonic QNNs with random\ninputs collapses accuracy to chance level ($10.0\\% \\pm 0.5\\%$). Photonic\nquantum computing's room-temperature operation, inherent scalability through\nspatial-mode multiplexing, and HPC-integrated architecture establish a\npractical pathway for distributed quantum machine learning, combining the\nexpressivity of photonic Hilbert spaces with the deployability of classical\nneural networks.",
      "tldr_zh": "本研究提出了一种分布式量子-经典框架，将光子量子神经网络 (photonic QNNs) 与矩阵乘积状态 (MPS) 映射相结合，实现经典神经网络的参数高效训练。该框架利用通用线性光学分解和光子计数测量统计，生成高维概率分布，并通过 MPS 模型（bond dimension χ）映射为经典网络权重，在 MNIST 分类任务上达到 95.50% ± 0.84% 准确率，仅需 3,292 参数，而经典基线需 6,690 参数，并实现了十倍压缩比（χ=4）且准确率损失不到 3%。与经典压缩技术（如权重共享或修剪）相比，该框架在准确率上高出 6-12%，且无需量子硬件进行推理，同时模拟显示其对光子噪声具有鲁棒性，为分布式量子机器学习提供了可扩展的实用路径。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08474v1",
      "published_date": "2025-05-13 11:58:45 UTC",
      "updated_date": "2025-05-13 11:58:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:33:04.947037"
    },
    {
      "arxiv_id": "2505.08463v1",
      "title": "RepCali: High Efficient Fine-tuning Via Representation Calibration in Latent Space for Pre-trained Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fujun Zhang",
        "XiangDong Su"
      ],
      "abstract": "Fine-tuning pre-trained language models (PLMs) has become a dominant paradigm\nin applying PLMs to downstream tasks. However, with limited fine-tuning, PLMs\nstill struggle with the discrepancies between the representation obtained from\nthe PLMs' encoder and the optimal input to the PLMs' decoder. This paper\ntackles this challenge by learning to calibrate the representation of PLMs in\nthe latent space. In the proposed representation calibration method (RepCali),\nwe integrate a specific calibration block to the latent space after the encoder\nand use the calibrated output as the decoder input. The merits of the proposed\nRepCali include its universality to all PLMs with encoder-decoder\narchitectures, its plug-and-play nature, and ease of implementation. Extensive\nexperiments on 25 PLM-based models across 8 tasks (including both English and\nChinese datasets) demonstrate that the proposed RepCali offers desirable\nenhancements to PLMs (including LLMs) and significantly improves the\nperformance of downstream tasks. Comparison experiments across 4 benchmark\ntasks indicate that RepCali is superior to the representative fine-tuning\nbaselines.",
      "tldr_zh": "该论文提出RepCali方法，通过在潜在空间中校准表示来高效微调预训练语言模型(PLMs)，以解决编码器输出与解码器最佳输入之间的不一致问题。RepCali在编码器后集成一个校准块，使用校准后的输出作为解码器输入，具有通用性、即插即用和易实现的特点。实验在25个PLM-based模型和8个任务（包括英文和中文数据集）上表明，该方法显著提升下游任务性能，并在基准比较中优于传统fine-tuning方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08463v1",
      "published_date": "2025-05-13 11:47:00 UTC",
      "updated_date": "2025-05-13 11:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:33:15.316232"
    },
    {
      "arxiv_id": "2505.08841v1",
      "title": "Will AI Take My Job? Evolving Perceptions of Automation and Labor Risk in Latin America",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Cremaschi",
        "Dae-Jin Lee",
        "Manuele Leonelli"
      ],
      "abstract": "As artificial intelligence and robotics increasingly reshape the global labor\nmarket, understanding public perceptions of these technologies becomes\ncritical. We examine how these perceptions have evolved across Latin America,\nusing survey data from the 2017, 2018, 2020, and 2023 waves of the\nLatinobar\\'ometro. Drawing on responses from over 48,000 individuals across 16\ncountries, we analyze fear of job loss due to artificial intelligence and\nrobotics. Using statistical modeling and latent class analysis, we identify key\nstructural and ideological predictors of concern, with education level and\npolitical orientation emerging as the most consistent drivers. Our findings\nreveal substantial temporal and cross-country variation, with a notable peak in\nfear during 2018 and distinct attitudinal profiles emerging from latent\nsegmentation. These results offer new insights into the social and structural\ndimensions of AI anxiety in emerging economies and contribute to a broader\nunderstanding of public attitudes toward automation beyond the Global North.",
      "tldr_zh": "这篇论文探讨了拉丁美洲公众对人工智能(AI)和机器人导致工作丧失的恐惧如何演变，使用2017至2023年Latinobarómetro调查数据分析了超过48,000个来自16个国家的个体响应。通过统计建模和潜在类分析(latent class analysis)，研究发现教育水平和政治倾向是最主要的结构性与意识形态预测因素。结果显示恐惧在2018年达到高峰，并存在显著的时间和国家差异，为理解新兴经济体中AI焦虑的社会维度提供了新见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08841v1",
      "published_date": "2025-05-13 11:43:02 UTC",
      "updated_date": "2025-05-13 11:43:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:33:27.762327"
    },
    {
      "arxiv_id": "2505.08459v1",
      "title": "Strategy-Augmented Planning for Large Language Models via Opponent Exploitation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Xu",
        "Sijia Cui",
        "Yanna Wang",
        "Bo Xu",
        "Qi Wang"
      ],
      "abstract": "Efficiently modeling and exploiting opponents is a long-standing challenge in\nadversarial domains. Large Language Models (LLMs) trained on extensive textual\ndata have recently demonstrated outstanding performance in general tasks,\nintroducing new research directions for opponent modeling. Some studies\nprimarily focus on directly using LLMs to generate decisions based on the\nelaborate prompt context that incorporates opponent descriptions, while these\napproaches are limited to scenarios where LLMs possess adequate domain\nexpertise. To address that, we introduce a two-stage Strategy-Augmented\nPlanning (SAP) framework that significantly enhances the opponent exploitation\ncapabilities of LLM-based agents by utilizing a critical component, the\nStrategy Evaluation Network (SEN). Specifically, in the offline stage, we\nconstruct an explicit strategy space and subsequently collect strategy-outcome\npair data for training the SEN network. During the online phase, SAP\ndynamically recognizes the opponent's strategies and greedily exploits them by\nsearching best response strategy on the well-trained SEN, finally translating\nstrategy to a course of actions by carefully designed prompts. Experimental\nresults show that SAP exhibits robust generalization capabilities, allowing it\nto perform effectively not only against previously encountered opponent\nstrategies but also against novel, unseen strategies. In the MicroRTS\nenvironment, SAP achieves a 85.35\\% performance improvement over baseline\nmethods and matches the competitiveness of reinforcement learning approaches\nagainst state-of-the-art (SOTA) rule-based AI.",
      "tldr_zh": "这篇论文提出了一种 Strategy-Augmented Planning (SAP) 框架，通过 Strategy Evaluation Network (SEN) 来提升 Large Language Models (LLMs) 在对抗领域的对手利用能力，解决现有方法依赖领域知识的局限性。SAP 采用两阶段方法：在离线阶段构建策略空间并收集数据训练 SEN，在在线阶段动态识别对手策略并搜索最佳响应策略，最终通过精心设计的提示转化为行动序列。实验结果显示，SAP 在 MicroRTS 环境中比基线方法提高了 85.35% 的性能，并展现出强鲁棒性和泛化能力，与强化学习方法相当，对抗状态-of-the-art (SOTA) 规则-based AI。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to IJCNN 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08459v1",
      "published_date": "2025-05-13 11:41:10 UTC",
      "updated_date": "2025-05-13 11:41:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:33:39.275811"
    },
    {
      "arxiv_id": "2505.08451v2",
      "title": "Adaptive Bias Generalized Rollout Policy Adaptation on the Flexible Job-Shop Scheduling Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Lotfi Kobrosly",
        "Marc-Emmanuel Coupvent des Graviers",
        "Christophe Guettier",
        "Tristan Cazenave"
      ],
      "abstract": "The Flexible Job-Shop Scheduling Problem (FJSSP) is an NP-hard combinatorial\noptimization problem, with several application domains, especially for\nmanufacturing purposes. The objective is to efficiently schedule multiple\noperations on dissimilar machines. These operations are gathered into jobs, and\noperations pertaining to the same job need to be scheduled sequentially.\nDifferent methods have been previously tested to solve this problem, such as\nConstraint Solving, Tabu Search, Genetic Algorithms, or Monte Carlo Tree Search\n(MCTS). We propose a novel algorithm derived from the Generalized Nested\nRollout Policy Adaptation, developed to solve the FJSSP. We report encouraging\nexperimental results, as our algorithm performs better than other MCTS-based\napproaches, even if makespans obtained on large instances are still far from\nknown upper bounds.",
      "tldr_zh": "本文研究了 Flexible Job-Shop Scheduling Problem (FJSSP)，这是一个 NP-hard 的组合优化问题，主要涉及在不同机器上高效调度多个作业操作，其中同一作业的操作需按顺序执行。论文提出了一种新算法，Adaptive Bias Generalized Rollout Policy Adaptation，基于 Generalized Nested Rollout Policy Adaptation 框架，旨在优化 FJSSP 的调度过程。实验结果表明，该算法在性能上优于其他 Monte Carlo Tree Search (MCTS) 方法，尽管在大实例上的 makespan 仍远低于已知上界，为制造领域的调度优化提供了新思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "The 19th Learning and Intelligent OptimizatioN Conference, LION19\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08451v2",
      "published_date": "2025-05-13 11:27:18 UTC",
      "updated_date": "2025-05-20 09:34:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:33:51.040312"
    },
    {
      "arxiv_id": "2505.08446v1",
      "title": "Agent-as-a-Service based on Agent Network",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Zhu",
        "Haojie Liu",
        "Jian Wang",
        "Bing Li",
        "Zikang Yin",
        "Yefei Liao"
      ],
      "abstract": "The rise of large model-based AI agents has spurred interest in Multi-Agent\nSystems (MAS) for their capabilities in decision-making, collaboration, and\nadaptability. While the Model Context Protocol (MCP) addresses tool invocation\nand data exchange challenges via a unified protocol, it lacks support for\norganizing agent-level collaboration. To bridge this gap, we propose\nAgent-as-a-Service based on Agent Network (AaaS-AN), a service-oriented\nparadigm grounded in the Role-Goal-Process-Service (RGPS) standard. AaaS-AN\nunifies the entire agent lifecycle, including construction, integration,\ninteroperability, and networked collaboration, through two core components: (1)\na dynamic Agent Network, which models agents and agent groups as vertexes that\nself-organize within the network based on task and role dependencies; (2)\nservice-oriented agents, incorporating service discovery, registration, and\ninteroperability protocols. These are orchestrated by a Service Scheduler,\nwhich leverages an Execution Graph to enable distributed coordination, context\ntracking, and runtime task management. We validate AaaS-AN on mathematical\nreasoning and application-level code generation tasks, which outperforms\nstate-of-the-art baselines. Notably, we constructed a MAS based on AaaS-AN\ncontaining agent groups, Robotic Process Automation (RPA) workflows, and MCP\nservers over 100 agent services. We also release a dataset containing 10,000\nlong-horizon multi-agent workflows to facilitate future research on long-chain\ncollaboration in MAS.",
      "tldr_zh": "该论文提出 Agent-as-a-Service based on Agent Network (AaaS-AN)，一个基于 Role-Goal-Process-Service (RGPS) 标准的框架，旨在解决 Multi-Agent Systems (MAS) 中代理协作的不足，特别是 Model Context Protocol (MCP) 缺乏代理级组织支持。AaaS-AN 通过动态 Agent Network（将代理和代理组建模为顶点并根据任务依赖自组织）和 service-oriented agents（包括服务发现、注册和互操作性协议）来统一代理的整个生命周期，并利用 Service Scheduler 和 Execution Graph 实现分布式协调和任务管理。在数学推理及应用级代码生成任务上，AaaS-AN 优于现有基线，并构建了一个包含超过 100 个代理服务的 MAS 系统，包括代理组、Robotic Process Automation (RPA) 工作流和 MCP 服务器，同时发布了一个包含 10,000 个长horizon 多代理工作流的数据集，以推动未来研究。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.08446v1",
      "published_date": "2025-05-13 11:15:19 UTC",
      "updated_date": "2025-05-13 11:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:34:05.393342"
    },
    {
      "arxiv_id": "2505.08445v1",
      "title": "Optimizing Retrieval-Augmented Generation: Analysis of Hyperparameter Impact on Performance and Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Adel Ammar",
        "Anis Koubaa",
        "Omer Nacar",
        "Wadii Boulila"
      ],
      "abstract": "Large language models achieve high task performance yet often hallucinate or\nrely on outdated knowledge. Retrieval-augmented generation (RAG) addresses\nthese gaps by coupling generation with external search. We analyse how\nhyperparameters influence speed and quality in RAG systems, covering Chroma and\nFaiss vector stores, chunking policies, cross-encoder re-ranking, and\ntemperature, and we evaluate six metrics: faithfulness, answer correctness,\nanswer relevancy, context precision, context recall, and answer similarity.\nChroma processes queries 13% faster, whereas Faiss yields higher retrieval\nprecision, revealing a clear speed-accuracy trade-off. Naive fixed-length\nchunking with small windows and minimal overlap outperforms semantic\nsegmentation while remaining the quickest option. Re-ranking provides modest\ngains in retrieval quality yet increases runtime by roughly a factor of 5, so\nits usefulness depends on latency constraints. These results help practitioners\nbalance computational cost and accuracy when tuning RAG systems for\ntransparent, up-to-date responses. Finally, we re-evaluate the top\nconfigurations with a corrective RAG workflow and show that their advantages\npersist when the model can iteratively request additional evidence. We obtain a\nnear-perfect context precision (99%), which demonstrates that RAG systems can\nachieve extremely high retrieval accuracy with the right combination of\nhyperparameters, with significant implications for applications where retrieval\nquality directly impacts downstream task performance, such as clinical decision\nsupport in healthcare.",
      "tldr_zh": "本研究分析了Retrieval-Augmented Generation (RAG)系统的超参数对性能和效率的影响，旨在解决大型语言模型的幻觉和过时知识问题，通过评估Chroma和Faiss向量存储、分块策略、cross-encoder re-ranking以及temperature等因素，并使用faithfulness、answer correctness等六大指标进行测试。结果显示，Chroma查询处理速度快13%，但Faiss提供更高检索精度，揭示了速度与准确性的权衡；固定长度小窗口分块策略在质量上优于语义分割，且更快速，而re-ranking虽提升检索质量但会增加运行时间约5倍，需根据延迟约束选择。最终，在corrective RAG工作流下，顶级配置实现近乎完美的context precision (99%)，为优化RAG系统以平衡计算成本和准确性提供了实用指导，尤其在医疗决策支持等高精度应用中。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08445v1",
      "published_date": "2025-05-13 11:13:27 UTC",
      "updated_date": "2025-05-13 11:13:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:34:16.260202"
    },
    {
      "arxiv_id": "2505.08438v1",
      "title": "A Survey of 3D Reconstruction with Event Cameras: From Event-based Geometry to Neural 3D Rendering",
      "title_zh": "事件相机在三维重建中的综述：从基于",
      "authors": [
        "Chuanzhi Xu",
        "Haoxian Zhou",
        "Langyi Chen",
        "Haodong Chen",
        "Ying Zhou",
        "Vera Chung",
        "Qiang Qu"
      ],
      "abstract": "Event cameras have emerged as promising sensors for 3D reconstruction due to\ntheir ability to capture per-pixel brightness changes asynchronously. Unlike\nconventional frame-based cameras, they produce sparse and temporally rich data\nstreams, which enable more accurate 3D reconstruction and open up the\npossibility of performing reconstruction in extreme environments such as\nhigh-speed motion, low light, or high dynamic range scenes. In this survey, we\nprovide the first comprehensive review focused exclusively on 3D reconstruction\nusing event cameras. The survey categorises existing works into three major\ntypes based on input modality - stereo, monocular, and multimodal systems, and\nfurther classifies them by reconstruction approach, including geometry-based,\ndeep learning-based, and recent neural rendering techniques such as Neural\nRadiance Fields and 3D Gaussian Splatting. Methods with a similar research\nfocus were organised chronologically into the most subdivided groups. We also\nsummarise public datasets relevant to event-based 3D reconstruction. Finally,\nwe highlight current research limitations in data availability, evaluation,\nrepresentation, and dynamic scene handling, and outline promising future\nresearch directions. This survey aims to serve as a comprehensive reference and\na roadmap for future developments in event-driven 3D reconstruction.",
      "tldr_zh": "这篇调查论文综述了使用 Event Cameras 进行 3D Reconstruction 的技术进展，这些相机能异步捕获像素亮度变化，提供稀疏且时间丰富的数据，特别适合高速度、低光照或高动态范围环境。论文将现有工作分类为基于立体、单目和多模态系统的三类，并进一步按重建方法分为几何-based、深度学习-based 和神经渲染技术（如 Neural Radiance Fields 和 3D Gaussian Splatting），并按时间顺序组织相关子组。作者还总结了公共数据集，讨论了当前挑战包括数据可用性、评估方法、表示形式和动态场景处理，并指出了未来研究方向，如改进事件驱动重建的全面性和鲁棒性。总的来说，这为 Event Cameras 在 3D Reconstruction 领域的应用提供了详尽参考和路线图。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "35 pages, 12 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08438v1",
      "published_date": "2025-05-13 11:04:04 UTC",
      "updated_date": "2025-05-13 11:04:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:34:26.861954"
    },
    {
      "arxiv_id": "2505.08435v2",
      "title": "Hakim: Farsi Text Embedding Model",
      "title_zh": "翻译失败",
      "authors": [
        "Mehran Sarmadi",
        "Morteza Alikhani",
        "Erfan Zinvandi",
        "Zahra Pourbahman"
      ],
      "abstract": "Recent advancements in text embedding have significantly improved natural\nlanguage understanding across many languages, yet Persian remains notably\nunderrepresented in large-scale embedding research. In this paper, we present\nHakim, a novel state-of-the-art Persian text embedding model that achieves a\n8.5% performance improvement over existing approaches on the FaMTEB benchmark,\noutperforming all previously developed Persian language models. As part of this\nwork, we introduce three new datasets - Corpesia, Pairsia-sup, and\nPairsia-unsup - to support supervised and unsupervised training scenarios.\nAdditionally, Hakim is designed for applications in chatbots and\nretrieval-augmented generation (RAG) systems, particularly addressing retrieval\ntasks that require incorporating message history within these systems. We also\npropose a new baseline model built on the BERT architecture. Our language model\nconsistently achieves higher accuracy across various Persian NLP tasks, while\nthe RetroMAE-based model proves particularly effective for textual information\nretrieval applications. Together, these contributions establish a new\nfoundation for advancing Persian language understanding.",
      "tldr_zh": "本研究介绍了Hakim，一种先进的波斯语（Farsi）文本嵌入模型，在FaMTEB基准上比现有方法提升8.5%的性能，超越所有先前波斯语模型。研究团队引入了三个新数据集——Corpesia、Pairsia-sup和Pairsia-unsup，以支持监督和无监督训练场景。Hakim针对聊天机器人和检索增强生成（RAG）系统进行了优化，尤其在整合消息历史的检索任务中表现出色，同时提出基于BERT架构的新基线模型。基于RetroMAE的变体在文本信息检索应用中特别有效，这些贡献为推进波斯语自然语言理解奠定了新基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08435v2",
      "published_date": "2025-05-13 10:57:32 UTC",
      "updated_date": "2025-05-14 13:47:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:34:38.672269"
    },
    {
      "arxiv_id": "2505.08404v1",
      "title": "Explaining Autonomous Vehicles with Intention-aware Policy Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Sara Montese",
        "Victor Gimenez-Abalos",
        "Atia Cortés",
        "Ulises Cortés",
        "Sergio Alvarez-Napagao"
      ],
      "abstract": "The potential to improve road safety, reduce human driving error, and promote\nenvironmental sustainability have enabled the field of autonomous driving to\nprogress rapidly over recent decades. The performance of autonomous vehicles\nhas significantly improved thanks to advancements in Artificial Intelligence,\nparticularly Deep Learning. Nevertheless, the opacity of their decision-making,\nrooted in the use of accurate yet complex AI models, has created barriers to\ntheir societal trust and regulatory acceptance, raising the need for\nexplainability. We propose a post-hoc, model-agnostic solution to provide\nteleological explanations for the behaviour of an autonomous vehicle in urban\nenvironments. Building on Intention-aware Policy Graphs, our approach enables\nthe extraction of interpretable and reliable explanations of vehicle behaviour\nin the nuScenes dataset from global and local perspectives. We demonstrate the\npotential of these explanations to assess whether the vehicle operates within\nacceptable legal boundaries and to identify possible vulnerabilities in\nautonomous driving datasets and models.",
      "tldr_zh": "该论文针对自动驾驶车辆决策的不透明性问题，提出一种后验（post-hoc）和模型无关（model-agnostic）的解释方法，以提升社会信任和监管接受。方法基于 Intention-aware Policy Graphs，从全局和本地视角提取车辆行为的teleological解释，分析其意图和决策过程。在nuScenes数据集上的实验表明，此方法能评估车辆是否符合法律边界，并识别自动驾驶数据集和模型中的潜在漏洞。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to Workshop EXTRAAMAS 2025 in AAMAS Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.08404v1",
      "published_date": "2025-05-13 09:58:32 UTC",
      "updated_date": "2025-05-13 09:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:34:50.268205"
    },
    {
      "arxiv_id": "2505.08403v1",
      "title": "ConDiSim: Conditional Diffusion Models for Simulation Based Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Mayank Nautiyal",
        "Andreas Hellander",
        "Prashant Singh"
      ],
      "abstract": "We present a conditional diffusion model - ConDiSim, for simulation-based\ninference of complex systems with intractable likelihoods. ConDiSim leverages\ndenoising diffusion probabilistic models to approximate posterior\ndistributions, consisting of a forward process that adds Gaussian noise to\nparameters, and a reverse process learning to denoise, conditioned on observed\ndata. This approach effectively captures complex dependencies and\nmulti-modalities within posteriors. ConDiSim is evaluated across ten benchmark\nproblems and two real-world test problems, where it demonstrates effective\nposterior approximation accuracy while maintaining computational efficiency and\nstability in model training. ConDiSim offers a robust and extensible framework\nfor simulation-based inference, particularly suitable for parameter inference\nworkflows requiring fast inference methods.",
      "tldr_zh": "本研究提出ConDiSim，一种条件扩散模型，用于处理模拟基于推理的复杂系统，其中难以计算似然分布的问题。ConDiSim利用去噪扩散概率模型（denoising diffusion probabilistic models），通过正向过程添加高斯噪声到参数，以及反向过程学习基于观察数据的去噪，从而有效捕捉后验分布中的复杂依赖性和多模态性。在十个基准问题和两个真实世界测试问题上，ConDiSim展示了出色的后验近似准确性，同时确保了计算效率和模型训练稳定性。该框架提供了一个鲁棒且可扩展的解决方案，特别适用于需要快速参数推断的工作流。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08403v1",
      "published_date": "2025-05-13 09:58:23 UTC",
      "updated_date": "2025-05-13 09:58:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:35:02.635146"
    },
    {
      "arxiv_id": "2505.08392v2",
      "title": "Accelerating Chain-of-Thought Reasoning: When Goal-Gradient Importance Meets Dynamic Skipping",
      "title_zh": "翻译失败",
      "authors": [
        "Ren Zhuang",
        "Ben Wang",
        "Shuifa Sun"
      ],
      "abstract": "Large Language Models leverage Chain-of-Thought (CoT) prompting for complex\ntasks, but their reasoning traces are often excessively verbose and\ninefficient, leading to significant computational costs and latency. Current\nCoT compression techniques typically rely on generic importance metrics and\nstatic compression rates, which may inadvertently remove functionally critical\ntokens or fail to adapt to varying reasoning complexity. To overcome these\nlimitations, we propose Adaptive GoGI-Skip, a novel framework learning dynamic\nCoT compression via supervised fine-tuning. This approach introduces two\nsynergistic innovations: (1) Goal-Gradient Importance (GoGI), a novel metric\naccurately identifying functionally relevant tokens by measuring the gradient\ninfluence of their intermediate representations on the final answer loss, and\n(2) Adaptive Dynamic Skipping (ADS), a mechanism dynamically regulating the\ncompression rate based on runtime model uncertainty while ensuring local\ncoherence through an adaptive N-token constraint. To our knowledge, this is the\nfirst work unifying a goal-oriented, gradient-based importance metric with\ndynamic, uncertainty-aware skipping for CoT compression. Trained on compressed\nMATH data, Adaptive GoGI-Skip demonstrates strong cross-domain generalization\nacross diverse reasoning benchmarks including AIME, GPQA, and GSM8K. It\nachieves substantial efficiency gains - reducing CoT token counts by over 45%\non average and delivering 1.6-2.0 times inference speedups - while maintaining\nhigh reasoning accuracy. Notably, it significantly outperforms existing\nbaselines by preserving accuracy even at high effective compression rates,\nadvancing the state of the art in the CoT reasoning efficiency-accuracy\ntrade-off.",
      "tldr_zh": "该论文针对大型语言模型的Chain-of-Thought (CoT)推理过程过于冗长和低效的问题，提出了一种新型框架Adaptive GoGI-Skip，通过监督微调实现动态CoT压缩。框架的核心创新包括Goal-Gradient Importance (GoGI)，一种基于梯度影响的指标来识别功能关键token，以及Adaptive Dynamic Skipping (ADS)，它根据模型运行时不确定性动态调整压缩率，同时通过自适应N-token约束保持局部连贯性。实验结果显示，该框架在AIME、GPQA和GSM8K等基准上实现了跨域泛化，平均减少CoT token数量超过45%、推理速度提高1.6-2.0倍，同时在高压缩率下维持高准确性，并显著优于现有基准，提升了CoT推理的效率-准确性权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08392v2",
      "published_date": "2025-05-13 09:39:18 UTC",
      "updated_date": "2025-05-17 14:59:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:35:15.714187"
    },
    {
      "arxiv_id": "2505.08376v1",
      "title": "Adaptive Diffusion Policy Optimization for Robotic Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Huiyun Jiang",
        "Zhuang Yang"
      ],
      "abstract": "Recent studies have shown the great potential of diffusion models in\nimproving reinforcement learning (RL) by modeling complex policies, expressing\na high degree of multi-modality, and efficiently handling high-dimensional\ncontinuous control tasks. However, there is currently limited research on how\nto optimize diffusion-based polices (e.g., Diffusion Policy) fast and stably.\nIn this paper, we propose an Adam-based Diffusion Policy Optimization (ADPO), a\nfast algorithmic framework containing best practices for fine-tuning\ndiffusion-based polices in robotic control tasks using the adaptive gradient\ndescent method in RL. Adaptive gradient method is less studied in training RL,\nlet alone diffusion-based policies. We confirm that ADPO outperforms other\ndiffusion-based RL methods in terms of overall effectiveness for fine-tuning on\nstandard robotic tasks. Concretely, we conduct extensive experiments on\nstandard robotic control tasks to test ADPO, where, particularly, six popular\ndiffusion-based RL methods are provided as benchmark methods. Experimental\nresults show that ADPO acquires better or comparable performance than the\nbaseline methods. Finally, we systematically analyze the sensitivity of\nmultiple hyperparameters in standard robotics tasks, providing guidance for\nsubsequent practical applications. Our video demonstrations are released in\nhttps://github.com/Timeless-lab/ADPO.git.",
      "tldr_zh": "该研究提出了一种基于 Adam 的自适应梯度下降方法——Adaptive Diffusion Policy Optimization (ADPO)，用于高效微调扩散-based 策略（例如 Diffusion Policy），以提升强化学习 (RL) 在机器人操控任务中的性能。ADPO 通过处理高维连续控制任务的多模态特性，实现比传统方法更快的稳定优化，并在标准机器人任务上与六种基准扩散-based RL 方法的实验中表现出优越或相当的性能。最后，论文系统分析了多个超参数的敏感性，为实际机器人应用提供指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08376v1",
      "published_date": "2025-05-13 09:21:45 UTC",
      "updated_date": "2025-05-13 09:21:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:35:28.041288"
    },
    {
      "arxiv_id": "2505.08366v1",
      "title": "Non-contact Vital Signs Detection in Dynamic Environments",
      "title_zh": "在动态环境中的非接触式生命体征检测",
      "authors": [
        "Shuai Sun",
        "Chong-Xi Liang",
        "Chengwei Ye",
        "Huanzhen Zhang",
        "Kangsheng Wang"
      ],
      "abstract": "Accurate phase demodulation is critical for vital sign detection using\nmillimeter-wave radar. However, in complex environments, time-varying DC\noffsets and phase imbalances can severely degrade demodulation performance. To\naddress this, we propose a novel DC offset calibration method alongside a\nHilbert and Differential Cross-Multiply (HADCM) demodulation algorithm. The\napproach estimates time-varying DC offsets from neighboring signal peaks and\nvalleys, then employs both differential forms and Hilbert transforms of the I/Q\nchannel signals to extract vital sign information. Simulation and experimental\nresults demonstrate that the proposed method maintains robust performance under\nlow signal-to-noise ratios. Compared to existing demodulation techniques, it\noffers more accurate signal recovery in challenging scenarios and effectively\nsuppresses noise interference.",
      "tldr_zh": "该论文针对毫米波雷达在动态环境下的非接触式生命体征检测问题，提出了一种新颖的 DC offset 校准方法和 Hilbert and Differential Cross-Multiply (HADCM) 解调算法，以应对时间变化的 DC offset 和相位不平衡导致的性能下降。该方法通过从相邻信号峰值和谷值估计时间变化的 DC offset，并结合 I/Q 通道信号的差分形式和 Hilbert transform，精确提取生命体征信息。实验和模拟结果表明，该算法在低信噪比条件下保持稳健性能，比现有技术更准确地恢复信号并有效抑制噪声干扰。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08366v1",
      "published_date": "2025-05-13 09:11:48 UTC",
      "updated_date": "2025-05-13 09:11:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:35:39.549085"
    },
    {
      "arxiv_id": "2505.08364v1",
      "title": "Learning Like Humans: Advancing LLM Reasoning Capabilities via Adaptive Difficulty Curriculum Learning and Expert-Guided Self-Reformulation",
      "title_zh": "像人类学习：通过自适应难度课程学习和专家指导的自重述提升 LLM 推理能力",
      "authors": [
        "Enci Zhang",
        "Xingang Yan",
        "Wei Lin",
        "Tianxiang Zhang",
        "Qianchun Lu"
      ],
      "abstract": "Despite impressive progress in areas like mathematical reasoning, large\nlanguage models still face significant challenges in consistently solving\ncomplex problems. Drawing inspiration from key human learning strategies, we\npropose two novel strategies to enhance the capability of large language models\nto solve these complex problems. First, Adaptive Difficulty Curriculum Learning\n(ADCL) is a novel curriculum learning strategy that tackles the Difficulty\nShift phenomenon (i.e., a model's perception of problem difficulty dynamically\nchanges during training) by periodically re-estimating difficulty within\nupcoming data batches to maintain alignment with the model's evolving\ncapabilities. Second, Expert-Guided Self-Reformulation (EGSR) is a novel\nreinforcement learning strategy that bridges the gap between imitation learning\nand pure exploration by guiding models to reformulate expert solutions within\ntheir own conceptual framework, rather than relying on direct imitation,\nfostering deeper understanding and knowledge assimilation. Extensive\nexperiments on challenging mathematical reasoning benchmarks, using Qwen2.5-7B\nas the base model, demonstrate that these human-inspired strategies\nsynergistically and significantly enhance performance. Notably, their combined\napplication improves performance over the standard Zero-RL baseline by 10% on\nthe AIME24 benchmark and 16.6% on AIME25.",
      "tldr_zh": "该论文受人类学习启发，提出两种策略来提升大型语言模型（LLM）的复杂问题推理能力。Adaptive Difficulty Curriculum Learning (ADCL) 通过定期重新评估数据批次难度来应对Difficulty Shift现象，确保训练过程与模型能力动态匹配。Expert-Guided Self-Reformulation (EGSR) 是一种强化学习策略，引导模型在自身概念框架内重述专家解决方案，促进更深入的知识吸收。实验结果显示，在Qwen2.5-7B基模型上，这些策略结合应用，使AIME24基准性能提升10%，AIME25基准提升16.6%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 3 figs",
      "pdf_url": "http://arxiv.org/pdf/2505.08364v1",
      "published_date": "2025-05-13 09:10:48 UTC",
      "updated_date": "2025-05-13 09:10:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:35:52.217329"
    },
    {
      "arxiv_id": "2505.08361v1",
      "title": "Modeling Unseen Environments with Language-guided Composable Causal Components in Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyue Wang",
        "Biwei Huang"
      ],
      "abstract": "Generalization in reinforcement learning (RL) remains a significant\nchallenge, especially when agents encounter novel environments with unseen\ndynamics. Drawing inspiration from human compositional reasoning -- where known\ncomponents are reconfigured to handle new situations -- we introduce World\nModeling with Compositional Causal Components (WM3C). This novel framework\nenhances RL generalization by learning and leveraging compositional causal\ncomponents. Unlike previous approaches focusing on invariant representation\nlearning or meta-learning, WM3C identifies and utilizes causal dynamics among\ncomposable elements, facilitating robust adaptation to new tasks. Our approach\nintegrates language as a compositional modality to decompose the latent space\ninto meaningful components and provides theoretical guarantees for their unique\nidentification under mild assumptions. Our practical implementation uses a\nmasked autoencoder with mutual information constraints and adaptive sparsity\nregularization to capture high-level semantic information and effectively\ndisentangle transition dynamics. Experiments on numerical simulations and\nreal-world robotic manipulation tasks demonstrate that WM3C significantly\noutperforms existing methods in identifying latent processes, improving policy\nlearning, and generalizing to unseen tasks.",
      "tldr_zh": "该研究针对强化学习（Reinforcement Learning, RL）中代理在未知环境下的泛化挑战，提出了一种名为 World Modeling with Compositional Causal Components (WM3C) 的框架。该框架借鉴人类组合推理，通过学习和利用可组合的因果组件来识别环境动态，并以语言作为指导模态分解潜在空间，提供理论保证确保组件的唯一性。实验结果显示，WM3C 在数值模拟和真实机器人操作任务中显著优于现有方法，提升了潜在过程识别、政策学习和对未见任务的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08361v1",
      "published_date": "2025-05-13 09:08:28 UTC",
      "updated_date": "2025-05-13 09:08:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:36:03.004183"
    },
    {
      "arxiv_id": "2505.08350v2",
      "title": "STORYANCHORS: Generating Consistent Multi-Scene Story Frames for Long-Form Narratives",
      "title_zh": "STORYANCHORS：为长形式叙事生成一致的多场景故事框架",
      "authors": [
        "Bo Wang",
        "Haoyang Huang",
        "Zhiying Lu",
        "Fengyuan Liu",
        "Guoqing Ma",
        "Jianlong Yuan",
        "Yuan Zhang",
        "Nan Duan",
        "Daxin Jiang"
      ],
      "abstract": "This paper introduces StoryAnchors, a unified framework for generating\nhigh-quality, multi-scene story frames with strong temporal consistency. The\nframework employs a bidirectional story generator that integrates both past and\nfuture contexts to ensure temporal consistency, character continuity, and\nsmooth scene transitions throughout the narrative. Specific conditions are\nintroduced to distinguish story frame generation from standard video synthesis,\nfacilitating greater scene diversity and enhancing narrative richness. To\nfurther improve generation quality, StoryAnchors integrates Multi-Event Story\nFrame Labeling and Progressive Story Frame Training, enabling the model to\ncapture both overarching narrative flow and event-level dynamics. This approach\nsupports the creation of editable and expandable story frames, allowing for\nmanual modifications and the generation of longer, more complex sequences.\nExtensive experiments show that StoryAnchors outperforms existing open-source\nmodels in key areas such as consistency, narrative coherence, and scene\ndiversity. Its performance in narrative consistency and story richness is also\non par with GPT-4o. Ultimately, StoryAnchors pushes the boundaries of\nstory-driven frame generation, offering a scalable, flexible, and highly\neditable foundation for future research.",
      "tldr_zh": "这篇论文介绍了 StoryAnchors 框架，用于生成高质量、多场景故事框架，确保长篇叙事的时间一致性、角色连续性和场景平滑过渡。框架采用 bidirectional story generator 整合过去和未来上下文，并通过引入特定条件、Multi-Event Story Frame Labeling 和 Progressive Story Frame Training 来提升场景多样性、叙事丰富性和可编辑性。实验显示，StoryAnchors 在一致性、叙事连贯性和场景多样性方面优于现有开源模型，并与 GPT-4o 相当，最终为故事驱动的框架生成提供了一个可扩展、灵活的基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08350v2",
      "published_date": "2025-05-13 08:48:10 UTC",
      "updated_date": "2025-05-17 00:50:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:36:15.819919"
    },
    {
      "arxiv_id": "2505.08349v1",
      "title": "FAD: Frequency Adaptation and Diversion for Cross-domain Few-shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruixiao Shi",
        "Fu Feng",
        "Yucheng Xie",
        "Jing Wang",
        "Xin Geng"
      ],
      "abstract": "Cross-domain few-shot learning (CD-FSL) requires models to generalize from\nlimited labeled samples under significant distribution shifts. While recent\nmethods enhance adaptability through lightweight task-specific modules, they\noperate solely in the spatial domain and overlook frequency-specific variations\nthat are often critical for robust transfer. We observe that spatially similar\nimages across domains can differ substantially in their spectral\nrepresentations, with low and high frequencies capturing complementary semantic\ninformation at coarse and fine levels. This indicates that uniform spatial\nadaptation may overlook these spectral distinctions, thus constraining\ngeneralization. To address this, we introduce Frequency Adaptation and\nDiversion (FAD), a frequency-aware framework that explicitly models and\nmodulates spectral components. At its core is the Frequency Diversion Adapter,\nwhich transforms intermediate features into the frequency domain using the\ndiscrete Fourier transform (DFT), partitions them into low, mid, and\nhigh-frequency bands via radial masks, and reconstructs each band using inverse\nDFT (IDFT). Each frequency band is then adapted using a dedicated convolutional\nbranch with a kernel size tailored to its spectral scale, enabling targeted and\ndisentangled adaptation across frequencies. Extensive experiments on the\nMeta-Dataset benchmark demonstrate that FAD consistently outperforms\nstate-of-the-art methods on both seen and unseen domains, validating the\nutility of frequency-domain representations and band-wise adaptation for\nimproving generalization in CD-FSL.",
      "tldr_zh": "该论文针对 Cross-domain Few-shot Learning (CD-FSL) 的分布偏移问题，提出 Frequency Adaptation and Diversion (FAD) 框架，以频率域视角增强模型的泛化能力。FAD 的核心组件 Frequency Diversion Adapter 通过 discrete Fourier transform (DFT) 将中间特征转换为频率域，并将它们分区为低、中、高频带，使用 radial masks 和 inverse DFT (IDFT) 重建每个频带，然后通过专用卷积分支进行针对性适应。实验结果显示，在 Meta-Dataset 基准上，FAD 在已见和未见领域均超越最先进方法，验证了频率域表示和带状适应的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08349v1",
      "published_date": "2025-05-13 08:48:06 UTC",
      "updated_date": "2025-05-13 08:48:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:36:28.520858"
    },
    {
      "arxiv_id": "2505.08345v1",
      "title": "SHAP-based Explanations are Sensitive to Feature Representation",
      "title_zh": "基于SHAP的解释对特征表示敏感",
      "authors": [
        "Hyunseung Hwang",
        "Andrew Bell",
        "Joao Fonseca",
        "Venetia Pliatsika",
        "Julia Stoyanovich",
        "Steven Euijong Whang"
      ],
      "abstract": "Local feature-based explanations are a key component of the XAI toolkit.\nThese explanations compute feature importance values relative to an\n``interpretable'' feature representation. In tabular data, feature values\nthemselves are often considered interpretable. This paper examines the impact\nof data engineering choices on local feature-based explanations. We demonstrate\nthat simple, common data engineering techniques, such as representing age with\na histogram or encoding race in a specific way, can manipulate feature\nimportance as determined by popular methods like SHAP. Notably, the sensitivity\nof explanations to feature representation can be exploited by adversaries to\nobscure issues like discrimination. While the intuition behind these results is\nstraightforward, their systematic exploration has been lacking. Previous work\nhas focused on adversarial attacks on feature-based explainers by biasing data\nor manipulating models. To the best of our knowledge, this is the first study\ndemonstrating that explainers can be misled by standard, seemingly innocuous\ndata engineering techniques.",
      "tldr_zh": "这篇论文揭示了基于 SHAP 的本地特征-based 解释在 XAI（可解释人工智能）工具包中对特征 representation 的敏感性。研究者通过实验证明，常见的数据 engineering 技术，如用直方图表示年龄或特定方式编码种族，能显著改变特征重要性值，从而误导解释结果。论文强调，这种敏感性可能被对手利用来隐藏歧视等问题，而这也是首次系统探索标准数据工程技术对解释器的影响，为未来 XAI 应用的安全性提供了重要警示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ACM FAccT 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08345v1",
      "published_date": "2025-05-13 08:43:09 UTC",
      "updated_date": "2025-05-13 08:43:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:36:39.260398"
    },
    {
      "arxiv_id": "2505.08343v1",
      "title": "An Identifiable Cost-Aware Causal Decision-Making Framework Using Counterfactual Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruichu Cai",
        "Xi Chen",
        "Jie Qiao",
        "Zijian Li",
        "Yuequn Liu",
        "Wei Chen",
        "Keli Zhang",
        "Jiale Zheng"
      ],
      "abstract": "Decision making under abnormal conditions is a critical process that involves\nevaluating the current state and determining the optimal action to restore the\nsystem to a normal state at an acceptable cost. However, in such scenarios,\nexisting decision-making frameworks highly rely on reinforcement learning or\nroot cause analysis, resulting in them frequently neglecting the cost of the\nactions or failing to incorporate causal mechanisms adequately. By relaxing the\nexisting causal decision framework to solve the necessary cause, we propose a\nminimum-cost causal decision (MiCCD) framework via counterfactual reasoning to\naddress the above challenges. Emphasis is placed on making counterfactual\nreasoning processes identifiable in the presence of a large amount of mixed\nanomaly data, as well as finding the optimal intervention state in a continuous\ndecision space. Specifically, it formulates a surrogate model based on causal\ngraphs, using abnormal pattern clustering labels as supervisory signals. This\nenables the approximation of the structural causal model among the variables\nand lays a foundation for identifiable counterfactual reasoning. With the\ncausal structure approximated, we then established an optimization model based\non counterfactual estimation. The Sequential Least Squares Programming (SLSQP)\nalgorithm is further employed to optimize intervention strategies while taking\ncosts into account. Experimental evaluations on both synthetic and real-world\ndatasets reveal that MiCCD outperforms conventional methods across multiple\nmetrics, including F1-score, cost efficiency, and ranking quality(nDCG@k\nvalues), thus validating its efficacy and broad applicability.",
      "tldr_zh": "这篇论文提出了一种可识别的成本感知因果决策框架（MiCCD），利用反事实推理（Counterfactual Reasoning）来解决异常条件下决策的问题，强调最小化行动成本并整合因果机制。框架通过基于因果图的代理模型和异常模式聚类标签作为监督信号，近似变量间的结构因果模型，并采用 Sequential Least Squares Programming (SLSQP) 算法优化干预策略，以在连续决策空间中找到最优状态。实验结果表明，MiCCD 在合成和真实数据集上在 F1-score、成本效率和 nDCG@k 等指标上优于传统方法，证明了其有效性和广泛适用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08343v1",
      "published_date": "2025-05-13 08:41:45 UTC",
      "updated_date": "2025-05-13 08:41:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:36:51.797343"
    },
    {
      "arxiv_id": "2505.08341v1",
      "title": "Benchmarking AI scientists in omics data-driven biological research",
      "title_zh": "翻译失败",
      "authors": [
        "Erpai Luo",
        "Jinmeng Jia",
        "Yifan Xiong",
        "Xiangyu Li",
        "Xiaobo Guo",
        "Baoqi Yu",
        "Lei Wei",
        "Xuegong Zhang"
      ],
      "abstract": "The rise of large language models and multi-agent systems has sparked growing\ninterest in AI scientists capable of autonomous biological research. However,\nexisting benchmarks either focus on reasoning without data or on data analysis\nwith predefined statistical answers, lacking realistic, data-driven evaluation\nsettings. Here, we introduce the Biological AI Scientist Benchmark (BaisBench),\na benchmark designed to assess AI scientists' ability to generate biological\ndiscoveries through data analysis and reasoning with external knowledge.\nBaisBench comprises two tasks: cell type annotation on 31 expert-labeled\nsingle-cell datasets, and scientific discovery through answering 198\nmultiple-choice questions derived from the biological insights of 41 recent\nsingle-cell studies. Systematic experiments on state-of-the-art AI scientists\nand LLM agents showed that while promising, current models still substantially\nunderperform human experts on both tasks. We hope BaisBench will fill this gap\nand serve as a foundation for advancing and evaluating AI models for scientific\ndiscovery. The benchmark can be found at: https://github.com/EperLuo/BaisBench.",
      "tldr_zh": "本文提出 BaisBench 基准，用于评估 AI scientists 在 omics 数据驱动的生物研究中的能力，填补了现有基准忽略真实数据分析和推理的不足。BaisBench 包括两个任务：基于 31 个专家标记的 single-cell datasets 进行细胞类型注释，以及回答 198 个多选题，这些问题源于 41 个最近 single-cell 研究的生物洞见。实验结果显示，当前最先进的 AI 模型在这些任务上仍远低于人类专家，该基准可作为推进 AI 科学发现的评估基础，并提供于 GitHub（https://github.com/EperLuo/BaisBench）。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "q-bio.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08341v1",
      "published_date": "2025-05-13 08:33:54 UTC",
      "updated_date": "2025-05-13 08:33:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:37:03.196150"
    },
    {
      "arxiv_id": "2505.08336v1",
      "title": "A computer vision-based model for occupancy detection using low-resolution thermal images",
      "title_zh": "基于计算机视觉的占用检测模型，使用低分辨率热图像",
      "authors": [
        "Xue Cui",
        "Vincent Gbouna Zakka",
        "Minhyun Lee"
      ],
      "abstract": "Occupancy plays an essential role in influencing the energy consumption and\noperation of heating, ventilation, and air conditioning (HVAC) systems.\nTraditional HVAC typically operate on fixed schedules without considering\noccupancy. Advanced occupant-centric control (OCC) adopted occupancy status in\nregulating HVAC operations. RGB images combined with computer vision (CV)\ntechniques are widely used for occupancy detection, however, the detailed\nfacial and body features they capture raise significant privacy concerns.\nLow-resolution thermal images offer a non-invasive solution that mitigates\nprivacy issues. The study developed an occupancy detection model utilizing\nlow-resolution thermal images and CV techniques, where transfer learning was\napplied to fine-tune the You Only Look Once version 5 (YOLOv5) model. The\ndeveloped model ultimately achieved satisfactory performance, with precision,\nrecall, mAP50, and mAP50 values approaching 1.000. The contributions of this\nmodel lie not only in mitigating privacy concerns but also in reducing\ncomputing resource demands.",
      "tldr_zh": "这篇论文提出了一种基于 computer vision (CV) 的占用检测模型，使用低分辨率热图像来解决传统 HVAC 系统忽略占用状态以及 RGB 图像带来的隐私问题。模型通过 transfer learning 微调 You Only Look Once version 5 (YOLOv5) 网络，实现对占用情况的准确识别。实验结果显示，该模型的 precision、recall 和 mAP50 值接近 1.000，性能出色。其主要贡献在于缓解隐私担忧并降低计算资源需求。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08336v1",
      "published_date": "2025-05-13 08:27:50 UTC",
      "updated_date": "2025-05-13 08:27:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:37:16.169165"
    },
    {
      "arxiv_id": "2505.08838v2",
      "title": "Ultrasound Report Generation with Multimodal Large Language Models for Standardized Texts",
      "title_zh": "翻译失败",
      "authors": [
        "Peixuan Ge",
        "Tongkun Su",
        "Faqin Lv",
        "Baoliang Zhao",
        "Peng Zhang",
        "Chi Hong Wong",
        "Liang Yao",
        "Yu Sun",
        "Zenan Wang",
        "Pak Kin Wong",
        "Ying Hu"
      ],
      "abstract": "Ultrasound (US) report generation is a challenging task due to the\nvariability of US images, operator dependence, and the need for standardized\ntext. Unlike X-ray and CT, US imaging lacks consistent datasets, making\nautomation difficult. In this study, we propose a unified framework for\nmulti-organ and multilingual US report generation, integrating fragment-based\nmultilingual training and leveraging the standardized nature of US reports. By\naligning modular text fragments with diverse imaging data and curating a\nbilingual English-Chinese dataset, the method achieves consistent and\nclinically accurate text generation across organ sites and languages.\nFine-tuning with selective unfreezing of the vision transformer (ViT) further\nimproves text-image alignment. Compared to the previous state-of-the-art KMVE\nmethod, our approach achieves relative gains of about 2\\% in BLEU scores,\napproximately 3\\% in ROUGE-L, and about 15\\% in CIDEr, while significantly\nreducing errors such as missing or incorrect content. By unifying multi-organ\nand multi-language report generation into a single, scalable framework, this\nwork demonstrates strong potential for real-world clinical workflows.",
      "tldr_zh": "这项研究针对超声（US）报告生成的挑战，如图像变异性、操作者依赖性和标准化文本需求，提出一个统一的框架，支持多器官和多语言报告生成。该框架通过基于片段的多语言训练、对模块化文本片段与多样化图像数据的对齐，以及选择性地微调视觉变压器（ViT），构建了一个英中双语数据集，实现跨器官和语言的临床准确文本生成。与现有最先进方法 KMVE 相比，该方法在 BLEU 得分上提高约 2%、ROUGE-L 上提高约 3%、CIDEr 上提高约 15%，并显著减少了缺失或错误内容。通过将多器官和多语言报告整合到一个可扩展框架中，该工作展示了在真实临床工作流中的强大潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08838v2",
      "published_date": "2025-05-13 08:27:01 UTC",
      "updated_date": "2025-05-19 04:30:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:37:28.848132"
    },
    {
      "arxiv_id": "2505.08327v1",
      "title": "Low-Complexity Inference in Continual Learning via Compressed Knowledge Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenrong Liu",
        "Janne M. J. Huttunen",
        "Mikko Honkala"
      ],
      "abstract": "Continual learning (CL) aims to train models that can learn a sequence of\ntasks without forgetting previously acquired knowledge. A core challenge in CL\nis balancing stability -- preserving performance on old tasks -- and plasticity\n-- adapting to new ones. Recently, large pre-trained models have been widely\nadopted in CL for their ability to support both, offering strong generalization\nfor new tasks and resilience against forgetting. However, their high\ncomputational cost at inference time limits their practicality in real-world\napplications, especially those requiring low latency or energy efficiency. To\naddress this issue, we explore model compression techniques, including pruning\nand knowledge distillation (KD), and propose two efficient frameworks tailored\nfor class-incremental learning (CIL), a challenging CL setting where task\nidentities are unavailable during inference. The pruning-based framework\nincludes pre- and post-pruning strategies that apply compression at different\ntraining stages. The KD-based framework adopts a teacher-student architecture,\nwhere a large pre-trained teacher transfers downstream-relevant knowledge to a\ncompact student. Extensive experiments on multiple CIL benchmarks demonstrate\nthat the proposed frameworks achieve a better trade-off between accuracy and\ninference complexity, consistently outperforming strong baselines. We further\nanalyze the trade-offs between the two frameworks in terms of accuracy and\nefficiency, offering insights into their use across different scenarios.",
      "tldr_zh": "本论文针对持续学习（Continual Learning）中模型推理的高计算成本问题，提出两种基于压缩知识转移的低复杂度框架，以平衡稳定性（保持旧任务性能）和可塑性（适应新任务）。框架包括基于修剪（Pruning）的策略（如预修剪和后修剪），以及基于知识蒸馏（Knowledge Distillation）的教师-学生架构，让大型预训练模型将相关知识转移到紧凑的学生模型上，用于类增量学习（Class-Incremental Learning）场景。实验在多个CIL基准上显示，这些框架在准确性和推理效率之间实现了更好的权衡，显著优于现有基线，并提供了框架间权衡的深入分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08327v1",
      "published_date": "2025-05-13 08:07:40 UTC",
      "updated_date": "2025-05-13 08:07:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:37:40.868893"
    },
    {
      "arxiv_id": "2505.08325v1",
      "title": "FedRS-Bench: Realistic Federated Learning Datasets and Benchmarks in Remote Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Haodong Zhao",
        "Peng Peng",
        "Chiyu Chen",
        "Linqing Huang",
        "Gongshen Liu"
      ],
      "abstract": "Remote sensing (RS) images are usually produced at an unprecedented scale,\nyet they are geographically and institutionally distributed, making centralized\nmodel training challenging due to data-sharing restrictions and privacy\nconcerns. Federated learning (FL) offers a solution by enabling collaborative\nmodel training across decentralized RS data sources without exposing raw data.\nHowever, there lacks a realistic federated dataset and benchmark in RS. Prior\nworks typically rely on manually partitioned single dataset, which fail to\ncapture the heterogeneity and scale of real-world RS data, and often use\ninconsistent experimental setups, hindering fair comparison. To address this\ngap, we propose a realistic federated RS dataset, termed FedRS. FedRS consists\nof eight datasets that cover various sensors and resolutions and builds 135\nclients, which is representative of realistic operational scenarios. Data for\neach client come from the same source, exhibiting authentic federated\nproperties such as skewed label distributions, imbalanced client data volumes,\nand domain heterogeneity across clients. These characteristics reflect\npractical challenges in federated RS and support evaluation of FL methods at\nscale. Based on FedRS, we implement 10 baseline FL algorithms and evaluation\nmetrics to construct the comprehensive FedRS-Bench. The experimental results\ndemonstrate that FL can consistently improve model performance over training on\nisolated data silos, while revealing performance trade-offs of different\nmethods under varying client heterogeneity and availability conditions. We hope\nFedRS-Bench will accelerate research on large-scale, realistic FL in RS by\nproviding a standardized, rich testbed and facilitating fair comparisons across\nfuture works. The source codes and dataset are available at\nhttps://fedrs-bench.github.io/.",
      "tldr_zh": "该论文针对遥感(Remote Sensing)领域的联邦学习(Federated Learning, FL)问题，提出FedRS数据集和FedRS-Bench基准，以解决现有数据集无法捕捉真实数据异质性和规模的局限性。FedRS包括八个数据集，覆盖各种传感器和分辨率，构建了135个客户端，模拟真实场景中的标签分布倾斜、数据量不平衡和域异质性。基于FedRS，研究者实现了10个基线FL算法和评估指标，进行全面实验评估，结果显示FL能显著提升模型性能，并揭示不同方法在客户端异质性和可用性条件下的权衡。FedRS-Bench提供了一个标准化的测试平台，有望加速大规模FL在遥感领域的研发，并促进未来研究的公平比较。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08325v1",
      "published_date": "2025-05-13 08:04:03 UTC",
      "updated_date": "2025-05-13 08:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:37:52.082191"
    },
    {
      "arxiv_id": "2505.08319v1",
      "title": "Reciprocity as the Foundational Substrate of Society: How Reciprocal Dynamics Scale into Social Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Egil Diau"
      ],
      "abstract": "A major bottleneck in multi-agent AI is the lack of simulateable models for\nthe bottom-up emergence of social structure under realistic behavioral\nconstraints. Similarly, many foundational theories in economics and sociology\nincluding the concepts of \"institutions\" and \"norms\" tend to describe social\nstructures post hoc, often relying on implicit assumptions of shared culture,\nmorality, or symbolic agreement. These concepts are often treated as primitives\nrather than reconstructed from agent-level behavior, leaving both their origins\nand operational definitions under-specified. To address this, we propose a\nthree-stage bottom-up framework: Reciprocal Dynamics, capturing\nindividual-level reciprocal exchanges; Norm Stabilization, the consolidation of\nshared expectations; and Institutional Construction, the externalization of\nstable patterns into scalable structures. By grounding social emergence in\nagent-level reciprocity, our framework enables the systematic exploration of\nhow moral, cultural, and institutional structures emerge from cognitively\nminimal interactions.",
      "tldr_zh": "该论文指出，多智能体 AI 面临模拟社会结构从底层行为约束中涌现的瓶颈，而经济学和社会学理论（如\"institutions\"和\"norms\"）往往事后描述这些结构，依赖于共享文化或道德的隐含假设，却未从代理级行为中重建。作者提出一个三阶段自下而上的框架：Reciprocal Dynamics（捕捉个体水平的互惠交换）、Norm Stabilization（巩固共享期望）和Institutional Construction（将稳定模式外化成可扩展结构）。通过将社会涌现建立在代理级reciprocity基础上，该框架系统地探索道德、文化和机构结构如何从认知最小化的互动中自然产生。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CY",
      "comment": "First draft extending the first position paper. Main framework\n  complete; historical examples and references will be updated",
      "pdf_url": "http://arxiv.org/pdf/2505.08319v1",
      "published_date": "2025-05-13 07:50:01 UTC",
      "updated_date": "2025-05-13 07:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:38:03.175076"
    },
    {
      "arxiv_id": "2505.08295v1",
      "title": "A Practical Introduction to Deep Reinforcement Learning",
      "title_zh": "深度强化学习的实用介绍",
      "authors": [
        "Yinghan Sun",
        "Hongxi Wang",
        "Hua Chen",
        "Wei Zhang"
      ],
      "abstract": "Deep reinforcement learning (DRL) has emerged as a powerful framework for\nsolving sequential decision-making problems, achieving remarkable success in a\nwide range of applications, including game AI, autonomous driving, biomedicine,\nand large language models. However, the diversity of algorithms and the\ncomplexity of theoretical foundations often pose significant challenges for\nbeginners seeking to enter the field. This tutorial aims to provide a concise,\nintuitive, and practical introduction to DRL, with a particular focus on the\nProximal Policy Optimization (PPO) algorithm, which is one of the most widely\nused and effective DRL methods. To facilitate learning, we organize all\nalgorithms under the Generalized Policy Iteration (GPI) framework, offering\nreaders a unified and systematic perspective. Instead of lengthy theoretical\nproofs, we emphasize intuitive explanations, illustrative examples, and\npractical engineering techniques. This work serves as an efficient and\naccessible guide, helping readers rapidly progress from basic concepts to the\nimplementation of advanced DRL algorithms.",
      "tldr_zh": "这篇教程为初学者提供了一个简洁、直观且实用的深度强化学习 (DRL) 介绍，强调其在游戏 AI、自动驾驶、生物医学和大语言模型等领域的成功应用。论文特别聚焦于 Proximal Policy Optimization (PPO) 算法，并将所有算法组织在 Generalized Policy Iteration (GPI) 框架下，以统一视角简化理解。不同于冗长的理论证明，它优先采用直观解释、示例和工程技巧，帮助读者快速从基础概念过渡到高级 DRL 算法的实际实现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08295v1",
      "published_date": "2025-05-13 07:19:16 UTC",
      "updated_date": "2025-05-13 07:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:38:15.721524"
    },
    {
      "arxiv_id": "2505.08293v2",
      "title": "M3G: Multi-Granular Gesture Generator for Audio-Driven Full-Body Human Motion Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Zhizhuo Yin",
        "Yuk Hang Tsui",
        "Pan Hui"
      ],
      "abstract": "Generating full-body human gestures encompassing face, body, hands, and\nglobal movements from audio is a valuable yet challenging task in virtual\navatar creation. Previous systems focused on tokenizing the human gestures\nframewisely and predicting the tokens of each frame from the input audio.\nHowever, one observation is that the number of frames required for a complete\nexpressive human gesture, defined as granularity, varies among different human\ngesture patterns. Existing systems fail to model these gesture patterns due to\nthe fixed granularity of their gesture tokens. To solve this problem, we\npropose a novel framework named Multi-Granular Gesture Generator (M3G) for\naudio-driven holistic gesture generation. In M3G, we propose a novel\nMulti-Granular VQ-VAE (MGVQ-VAE) to tokenize motion patterns and reconstruct\nmotion sequences from different temporal granularities. Subsequently, we\nproposed a multi-granular token predictor that extracts multi-granular\ninformation from audio and predicts the corresponding motion tokens. Then M3G\nreconstructs the human gestures from the predicted tokens using the MGVQ-VAE.\nBoth objective and subjective experiments demonstrate that our proposed M3G\nframework outperforms the state-of-the-art methods in terms of generating\nnatural and expressive full-body human gestures.",
      "tldr_zh": "该研究提出 M3G 框架，用于从音频驱动生成包括面部、身体、手部和全局运动的全身人类手势，解决现有系统因固定粒度而无法有效处理不同手势模式的问题。M3G 引入 Multi-Granular VQ-VAE (MGVQ-VAE) 来标记运动模式并从不同时间粒度重建序列，以及 multi-granular token predictor 从音频提取多粒度信息并预测相应标记。最终，通过 MGVQ-VAE 重建手势，实验显示 M3G 在客观和主观评估中优于最先进方法，能生成更自然和富有表现力的手势。",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV",
        "cs.SD",
        "eess.AS",
        "I.3.6"
      ],
      "primary_category": "cs.GR",
      "comment": "9 Pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08293v2",
      "published_date": "2025-05-13 07:16:58 UTC",
      "updated_date": "2025-05-19 14:01:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:38:28.329067"
    },
    {
      "arxiv_id": "2505.08266v1",
      "title": "Open the Eyes of MPNN: Vision Enhances MPNN in Link Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Yanbin Wei",
        "Xuehao Wang",
        "Zhan Zhuang",
        "Yang Chen",
        "Shuhao Chen",
        "Yulong Zhang",
        "Yu Zhang",
        "James Kwok"
      ],
      "abstract": "Message-passing graph neural networks (MPNNs) and structural features (SFs)\nare cornerstones for the link prediction task. However, as a common and\nintuitive mode of understanding, the potential of visual perception has been\noverlooked in the MPNN community. For the first time, we equip MPNNs with\nvision structural awareness by proposing an effective framework called Graph\nVision Network (GVN), along with a more efficient variant (E-GVN). Extensive\nempirical results demonstrate that with the proposed frameworks, GVN\nconsistently benefits from the vision enhancement across seven link prediction\ndatasets, including challenging large-scale graphs. Such improvements are\ncompatible with existing state-of-the-art (SOTA) methods and GVNs achieve new\nSOTA results, thereby underscoring a promising novel direction for link\nprediction.",
      "tldr_zh": "本研究指出，Message-passing graph neural networks (MPNNs) 和 structural features (SFs) 是链接预测任务的核心，但视觉感知长期被忽略。为此，首次提出 Graph Vision Network (GVN) 框架及其高效变体 E-GVN，以赋予 MPNNs 视觉结构感知能力。实验结果显示，GVN 在七个链接预测数据集上，包括大规模图，实现了显著性能提升，并与现有 state-of-the-art (SOTA) 方法兼容，取得新的 SOTA 结果。该框架为链接预测任务开辟了一个有前景的新方向。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08266v1",
      "published_date": "2025-05-13 06:32:23 UTC",
      "updated_date": "2025-05-13 06:32:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:38:39.822371"
    },
    {
      "arxiv_id": "2505.08265v2",
      "title": "Large Language Model Enhancers for Graph Neural Networks: An Analysis from the Perspective of Causal Mechanism Identification",
      "title_zh": "大型语言模型增强器用于图神经网络：从因果机制识别视角的分析",
      "authors": [
        "Hang Gao",
        "Wenxuan Huang",
        "Fengge Wu",
        "Junsuo Zhao",
        "Changwen Zheng",
        "Huaping Liu"
      ],
      "abstract": "The use of large language models (LLMs) as feature enhancers to optimize node\nrepresentations, which are then used as inputs for graph neural networks\n(GNNs), has shown significant potential in graph representation learning.\nHowever, the fundamental properties of this approach remain underexplored. To\naddress this issue, we propose conducting a more in-depth analysis of this\nissue based on the interchange intervention method. First, we construct a\nsynthetic graph dataset with controllable causal relationships, enabling\nprecise manipulation of semantic relationships and causal modeling to provide\ndata for analysis. Using this dataset, we conduct interchange interventions to\nexamine the deeper properties of LLM enhancers and GNNs, uncovering their\nunderlying logic and internal mechanisms. Building on the analytical results,\nwe design a plug-and-play optimization module to improve the information\ntransfer between LLM enhancers and GNNs. Experiments across multiple datasets\nand models validate the proposed module.",
      "tldr_zh": "该论文从因果机制识别角度分析了使用 Large Language Models (LLMs) 作为特征增强器来优化 Graph Neural Networks (GNNs) 的节点表示，从而提升图表示学习的效果。作者构建了具有可控因果关系的合成图数据集，并通过 interchange intervention 方法考察 LLM 增强器和 GNNs 的深层属性，揭示了它们的内部逻辑和机制。基于这些分析结果，论文设计了一个即插即用优化模块，以改善信息传输，并在多个数据集和模型上验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08265v2",
      "published_date": "2025-05-13 06:29:25 UTC",
      "updated_date": "2025-05-15 23:46:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:38:52.060448"
    },
    {
      "arxiv_id": "2505.08264v1",
      "title": "Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning",
      "title_zh": "针对驾驶场景的自动课程学习：朝向鲁棒且高效的强化学习",
      "authors": [
        "Ahmed Abouelazm",
        "Tim Weinstein",
        "Tim Joseph",
        "Philip Schörner",
        "J. Marius Zöllner"
      ],
      "abstract": "This paper addresses the challenges of training end-to-end autonomous driving\nagents using Reinforcement Learning (RL). RL agents are typically trained in a\nfixed set of scenarios and nominal behavior of surrounding road users in\nsimulations, limiting their generalization and real-life deployment. While\ndomain randomization offers a potential solution by randomly sampling driving\nscenarios, it frequently results in inefficient training and sub-optimal\npolicies due to the high variance among training scenarios. To address these\nlimitations, we propose an automatic curriculum learning framework that\ndynamically generates driving scenarios with adaptive complexity based on the\nagent's evolving capabilities. Unlike manually designed curricula that\nintroduce expert bias and lack scalability, our framework incorporates a\n``teacher'' that automatically generates and mutates driving scenarios based on\ntheir learning potential -- an agent-centric metric derived from the agent's\ncurrent policy -- eliminating the need for expert design. The framework\nenhances training efficiency by excluding scenarios the agent has mastered or\nfinds too challenging. We evaluate our framework in a reinforcement learning\nsetting where the agent learns a driving policy from camera images. Comparative\nresults against baseline methods, including fixed scenario training and domain\nrandomization, demonstrate that our approach leads to enhanced generalization,\nachieving higher success rates: +9\\% in low traffic density, +21\\% in high\ntraffic density, and faster convergence with fewer training steps. Our findings\nhighlight the potential of ACL in improving the robustness and efficiency of\nRL-based autonomous driving agents.",
      "tldr_zh": "本文提出了一种自动课程学习框架（Automatic Curriculum Learning），用于强化学习（RL）中的自动驾驶场景训练，以解决传统方法在泛化和效率方面的局限性。该框架通过一个“教师”组件动态生成和调整驾驶场景的复杂度，基于代理当前策略的学习潜力（learning potential），自动排除已掌握或过于挑战性的场景，从而避免专家偏差并提升训练效率。在实验中，与固定场景训练和领域随机化（domain randomization）基线相比，该方法显著提高了代理的泛化能力，在低交通密度场景成功率提升9%、高交通密度提升21%，并实现了更快收敛。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted in the 36th IEEE Intelligent Vehicles Symposium (IV 2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.08264v1",
      "published_date": "2025-05-13 06:26:57 UTC",
      "updated_date": "2025-05-13 06:26:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:39:03.920841"
    },
    {
      "arxiv_id": "2505.08261v1",
      "title": "Enhancing Cache-Augmented Generation (CAG) with Adaptive Contextual Compression for Scalable Knowledge Integration",
      "title_zh": "翻译失败",
      "authors": [
        "Rishabh Agrawal",
        "Himanshu Kumar"
      ],
      "abstract": "The rapid progress in large language models (LLMs) has paved the way for\nnovel approaches in knowledge-intensive tasks. Among these, Cache-Augmented\nGeneration (CAG) has emerged as a promising alternative to Retrieval-Augmented\nGeneration (RAG). CAG minimizes retrieval latency and simplifies system design\nby preloading knowledge into the model's context. However, challenges persist\nin scaling CAG to accommodate large and dynamic knowledge bases effectively.\nThis paper introduces Adaptive Contextual Compression (ACC), an innovative\ntechnique designed to dynamically compress and manage context inputs, enabling\nefficient utilization of the extended memory capabilities of modern LLMs. To\nfurther address the limitations of standalone CAG, we propose a Hybrid CAG-RAG\nFramework, which integrates selective retrieval to augment preloaded contexts\nin scenarios requiring additional information. Comprehensive evaluations on\ndiverse datasets highlight the proposed methods' ability to enhance\nscalability, optimize efficiency, and improve multi-hop reasoning performance,\noffering practical solutions for real-world knowledge integration challenges.",
      "tldr_zh": "这篇论文针对Cache-Augmented Generation (CAG)在处理大型动态知识库时的挑战，提出了Adaptive Contextual Compression (ACC)技术，用于动态压缩和管理上下文输入，从而高效利用现代大型语言模型 (LLMs) 的扩展内存能力。作者进一步开发了Hybrid CAG-RAG Framework，将选择性检索整合到预加载上下文中，以应对需要额外信息的场景。综合评估结果显示，这些方法显著提升了系统的可扩展性、效率和多跳推理性能，为实际知识集成任务提供了实用解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08261v1",
      "published_date": "2025-05-13 06:24:48 UTC",
      "updated_date": "2025-05-13 06:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:39:15.242085"
    },
    {
      "arxiv_id": "2505.08835v1",
      "title": "Robustness Analysis against Adversarial Patch Attacks in Fully Unmanned Stores",
      "title_zh": "翻译失败",
      "authors": [
        "Hyunsik Na",
        "Wonho Lee",
        "Seungdeok Roh",
        "Sohee Park",
        "Daeseon Choi"
      ],
      "abstract": "The advent of convenient and efficient fully unmanned stores equipped with\nartificial intelligence-based automated checkout systems marks a new era in\nretail. However, these systems have inherent artificial intelligence security\nvulnerabilities, which are exploited via adversarial patch attacks,\nparticularly in physical environments. This study demonstrated that adversarial\npatches can severely disrupt object detection models used in unmanned stores,\nleading to issues such as theft, inventory discrepancies, and interference. We\ninvestigated three types of adversarial patch attacks -- Hiding, Creating, and\nAltering attacks -- and highlighted their effectiveness. We also introduce the\nnovel color histogram similarity loss function by leveraging attacker knowledge\nof the color information of a target class object. Besides the traditional\nconfusion-matrix-based attack success rate, we introduce a new\nbounding-boxes-based metric to analyze the practical impact of these attacks.\nStarting with attacks on object detection models trained on snack and fruit\ndatasets in a digital environment, we evaluated the effectiveness of\nadversarial patches in a physical testbed that mimicked a real unmanned store\nwith RGB cameras and realistic conditions. Furthermore, we assessed the\nrobustness of these attacks in black-box scenarios, demonstrating that shadow\nattacks can enhance success rates of attacks even without direct access to\nmodel parameters. Our study underscores the necessity for robust defense\nstrategies to protect unmanned stores from adversarial threats. Highlighting\nthe limitations of the current defense mechanisms in real-time detection\nsystems and discussing various proactive measures, we provide insights into\nimproving the robustness of object detection models and fortifying unmanned\nretail environments against these attacks.",
      "tldr_zh": "该研究分析了全无人商店中基于人工智能的自动结账系统对 adversarial patch attacks 的鲁棒性，揭示这些攻击可严重干扰物体检测模型，导致盗窃、库存不一致等问题。研究者调查了 Hiding、Creating 和 Altering 三种攻击类型，并引入了新型 color histogram similarity loss function，利用目标类对象的颜色信息来提升攻击效果；同时，提出了 bounding-boxes-based metric 作为新评估指标，以评估攻击的实际影响。实验在数字和物理测试环境中进行，证明了这些攻击在黑盒场景下的有效性，并通过 shadow attacks 进一步提高了成功率，最终强调了开发 robust defense strategies 的必要性，以强化无人零售环境的防护。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08835v1",
      "published_date": "2025-05-13 06:24:32 UTC",
      "updated_date": "2025-05-13 06:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:39:27.643092"
    },
    {
      "arxiv_id": "2505.08253v1",
      "title": "Evaluating LLM Metrics Through Real-World Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Justin K Miller",
        "Wenjia Tang"
      ],
      "abstract": "As generative AI becomes increasingly embedded in everyday workflows, it is\nimportant to evaluate its performance in ways that reflect real-world usage\nrather than abstract notions of intelligence. Unlike many existing benchmarks\nthat assess general intelligence, our approach focuses on real-world utility,\nevaluating how well models support users in everyday tasks. While current\nbenchmarks emphasize code generation or factual recall, users rely on AI for a\nmuch broader range of activities-from writing assistance and summarization to\ncitation formatting and stylistic feedback. In this paper, we analyze\nlarge-scale survey data and usage logs to identify six core capabilities that\nrepresent how people commonly use Large Language Models (LLMs): Summarization,\nTechnical Assistance, Reviewing Work, Data Structuring, Generation, and\nInformation Retrieval. We then assess the extent to which existing benchmarks\ncover these capabilities, revealing significant gaps in coverage, efficiency\nmeasurement, and interpretability. Drawing on this analysis, we use\nhuman-centered criteria to identify gaps in how well current benchmarks reflect\ncommon usage that is grounded in five practical criteria: coherence, accuracy,\nclarity, relevance, and efficiency. For four of the six capabilities, we\nidentify the benchmarks that best align with real-world tasks and use them to\ncompare leading models. We find that Google Gemini outperforms other\nmodels-including OpenAI's GPT, xAI's Grok, Meta's LLaMA, Anthropic's Claude,\nDeepSeek, and Qwen from Alibaba-on these utility-focused metrics.",
      "tldr_zh": "这篇论文评估 Large Language Models (LLMs) 的性能，强调通过真实世界应用（如写作辅助、总结和信息检索）而非抽象智能进行评估。研究者分析大规模调查数据和使用日志，识别六大核心能力：Summarization、Technical Assistance、Reviewing Work、Data Structuring、Generation 和 Information Retrieval。结果显示，现有的基准测试在覆盖、效率和可解释性方面存在显著缺口，并基于人类中心标准（coherence、accuracy、clarity、relevance 和 efficiency）进行评估。对于其中四种能力，论文比较了领先模型，发现 Google Gemini 在这些实用指标上优于 OpenAI 的 GPT、xAI 的 Grok 等模型。",
      "categories": [
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages main text, 5 pages references, 20 pages appendix; includes 3\n  figures and 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08253v1",
      "published_date": "2025-05-13 06:02:37 UTC",
      "updated_date": "2025-05-13 06:02:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:39:40.868814"
    },
    {
      "arxiv_id": "2505.08245v1",
      "title": "Large Language Model Psychometrics: A Systematic Review of Evaluation, Validation, and Enhancement",
      "title_zh": "大语言模型心理测量学：评估、验证和增强的系统综述",
      "authors": [
        "Haoran Ye",
        "Jing Jin",
        "Yuhang Xie",
        "Xin Zhang",
        "Guojie Song"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has outpaced\ntraditional evaluation methodologies. It presents novel challenges, such as\nmeasuring human-like psychological constructs, navigating beyond static and\ntask-specific benchmarks, and establishing human-centered evaluation. These\nchallenges intersect with Psychometrics, the science of quantifying the\nintangible aspects of human psychology, such as personality, values, and\nintelligence. This survey introduces and synthesizes an emerging\ninterdisciplinary field of LLM Psychometrics, which leverages psychometric\ninstruments, theories, and principles to evaluate, understand, and enhance\nLLMs. We systematically explore the role of Psychometrics in shaping\nbenchmarking principles, broadening evaluation scopes, refining methodologies,\nvalidating results, and advancing LLM capabilities. This paper integrates\ndiverse perspectives to provide a structured framework for researchers across\ndisciplines, enabling a more comprehensive understanding of this nascent field.\nUltimately, we aim to provide actionable insights for developing future\nevaluation paradigms that align with human-level AI and promote the advancement\nof human-centered AI systems for societal benefit. A curated repository of LLM\npsychometric resources is available at\nhttps://github.com/valuebyte-ai/Awesome-LLM-Psychometrics.",
      "tldr_zh": "这篇论文系统综述了大型语言模型（LLMs）的心理测量学评估、验证和提升方法，强调了Psychometrics（心理测量学）在应对LLMs挑战中的作用，如测量人类心理结构、超越静态基准和建立人类中心评估。该研究引入LLM Psychometrics这一新兴跨学科领域，通过整合心理测量学工具、理论和原则，构建了一个结构化框架，用于改进基准原则、扩展评估范围、优化方法和验证结果，从而提升LLMs的能力。最终，论文提供可操作见解，支持开发与人类水平AI对齐的人类中心AI系统，并附带一个资源仓库（https://github.com/valuebyte-ai/Awesome-LLM-Psychometrics）。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "63 pages, 482 references",
      "pdf_url": "http://arxiv.org/pdf/2505.08245v1",
      "published_date": "2025-05-13 05:47:51 UTC",
      "updated_date": "2025-05-13 05:47:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:39:51.305530"
    },
    {
      "arxiv_id": "2505.08834v1",
      "title": "Crowd Scene Analysis using Deep Learning Techniques",
      "title_zh": "使用深度学习技术的群体场景分析",
      "authors": [
        "Muhammad Junaid Asif"
      ],
      "abstract": "Our research is focused on two main applications of crowd scene analysis\ncrowd counting and anomaly detection In recent years a large number of\nresearches have been presented in the domain of crowd counting We addressed two\nmain challenges in this domain 1 Deep learning models are datahungry paradigms\nand always need a large amount of annotated data for the training of algorithm\nIt is timeconsuming and costly task to annotate such large amount of data\nSelfsupervised training is proposed to deal with this challenge 2 MCNN consists\nof multicolumns of CNN with different sizes of filters by presenting a novel\napproach based on a combination of selfsupervised training and MultiColumn CNN\nThis enables the model to learn features at different levels and makes it\neffective in dealing with challenges of occluded scenes nonuniform density\ncomplex backgrounds and scale invariation The proposed model was evaluated on\npublicly available data sets such as ShanghaiTech and UCFQNRF by means of MAE\nand MSE A spatiotemporal model based on VGG19 is proposed for crowd anomaly\ndetection addressing challenges like lighting environmental conditions\nunexpected objects and scalability The model extracts spatial and temporal\nfeatures allowing it to be generalized to realworld scenes Spatial features are\nlearned using CNN while temporal features are learned using LSTM blocks The\nmodel works on binary classification and can detect normal or abnormal behavior\nThe models performance is improved by replacing fully connected layers with\ndense residual blocks Experiments on the Hockey Fight dataset and SCVD dataset\nshow our models outperform other stateoftheart approaches",
      "tldr_zh": "本研究聚焦于使用深度学习技术的人群场景分析，主要涉及人群计数和异常检测两个应用。针对人群计数面临的挑战，如数据标注成本高和场景复杂（如遮挡、不均匀密度），作者提出了一种结合自监督训练和 MultiColumn CNN (MCNN) 的新方法，该方法通过不同大小的过滤器学习多级别特征，并在 ShanghaiTech 和 UCFQNRF 数据集上使用 MAE 和 MSE 指标表现出色。针对异常检测，研究基于 VGG19 的时空模型，使用 CNN 提取空间特征、LSTM 提取时间特征，并通过替换全连接层为密集残差块提升性能，该模型在 Hockey Fight 和 SCVD 数据集上优于现有方法。整体贡献在于提高模型的泛化能力和准确性，为真实场景应用提供有效解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "MS Graduate Research Thesis",
      "pdf_url": "http://arxiv.org/pdf/2505.08834v1",
      "published_date": "2025-05-13 05:29:30 UTC",
      "updated_date": "2025-05-13 05:29:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:40:04.480219"
    },
    {
      "arxiv_id": "2505.08234v1",
      "title": "Removing Watermarks with Partial Regeneration using Semantic Information",
      "title_zh": "使用语义信息进行部分再生的水印移除",
      "authors": [
        "Krti Tallam",
        "John Kevin Cava",
        "Caleb Geniesse",
        "N. Benjamin Erichson",
        "Michael W. Mahoney"
      ],
      "abstract": "As AI-generated imagery becomes ubiquitous, invisible watermarks have emerged\nas a primary line of defense for copyright and provenance. The newest\nwatermarking schemes embed semantic signals - content-aware patterns that are\ndesigned to survive common image manipulations - yet their true robustness\nagainst adaptive adversaries remains under-explored. We expose a previously\nunreported vulnerability and introduce SemanticRegen, a three-stage, label-free\nattack that erases state-of-the-art semantic and invisible watermarks while\nleaving an image's apparent meaning intact. Our pipeline (i) uses a\nvision-language model to obtain fine-grained captions, (ii) extracts foreground\nmasks with zero-shot segmentation, and (iii) inpaints only the background via\nan LLM-guided diffusion model, thereby preserving salient objects and style\ncues. Evaluated on 1,000 prompts across four watermarking systems - TreeRing,\nStegaStamp, StableSig, and DWT/DCT - SemanticRegen is the only method to defeat\nthe semantic TreeRing watermark (p = 0.10 > 0.05) and reduces bit-accuracy\nbelow 0.75 for the remaining schemes, all while maintaining high perceptual\nquality (masked SSIM = 0.94 +/- 0.01). We further introduce masked SSIM (mSSIM)\nto quantify fidelity within foreground regions, showing that our attack\nachieves up to 12 percent higher mSSIM than prior diffusion-based attackers.\nThese results highlight an urgent gap between current watermark defenses and\nthe capabilities of adaptive, semantics-aware adversaries, underscoring the\nneed for watermarking algorithms that are resilient to content-preserving\nregenerative attacks.",
      "tldr_zh": "这篇论文提出了一种名为SemanticRegen的三阶段、无标签攻击方法，用于去除AI生成图像中的语义和不可见水印（如TreeRing、StegaStamp、StableSig和DWT/DCT），同时保留图像的主要内容和风格。方法包括使用视觉语言模型获取细粒度标题、零样本分割提取前景掩码，以及LLM引导的扩散模型仅修复背景。实验结果显示，SemanticRegen成功击败TreeRing水印（p = 0.10 > 0.05），并将其他水印的位准确率降至低于0.75，同时保持高感知质量（masked SSIM = 0.94 +/- 0.01）。论文还引入masked SSIM (mSSIM)指标，表明该攻击比先前扩散-based方法高出12%，突显了当前水印防御对适应性攻击的脆弱性，并呼吁开发更坚固的水印算法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08234v1",
      "published_date": "2025-05-13 05:25:06 UTC",
      "updated_date": "2025-05-13 05:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:40:17.562087"
    },
    {
      "arxiv_id": "2505.08228v1",
      "title": "Object detection in adverse weather conditions for autonomous vehicles using Instruct Pix2Pix",
      "title_zh": "使用 Instruct Pix2Pix 在恶劣天气条件下进行自动驾驶车辆的物体检测",
      "authors": [
        "Unai Gurbindo",
        "Axel Brando",
        "Jaume Abella",
        "Caroline König"
      ],
      "abstract": "Enhancing the robustness of object detection systems under adverse weather\nconditions is crucial for the advancement of autonomous driving technology.\nThis study presents a novel approach leveraging the diffusion model Instruct\nPix2Pix to develop prompting methodologies that generate realistic datasets\nwith weather-based augmentations aiming to mitigate the impact of adverse\nweather on the perception capabilities of state-of-the-art object detection\nmodels, including Faster R-CNN and YOLOv10. Experiments were conducted in two\nenvironments, in the CARLA simulator where an initial evaluation of the\nproposed data augmentation was provided, and then on the real-world image data\nsets BDD100K and ACDC demonstrating the effectiveness of the approach in real\nenvironments.\n  The key contributions of this work are twofold: (1) identifying and\nquantifying the performance gap in object detection models under challenging\nweather conditions, and (2) demonstrating how tailored data augmentation\nstrategies can significantly enhance the robustness of these models. This\nresearch establishes a solid foundation for improving the reliability of\nperception systems in demanding environmental scenarios, and provides a pathway\nfor future advancements in autonomous driving.",
      "tldr_zh": "本研究针对自动驾驶车辆在恶劣天气条件下进行物体检测的鲁棒性问题，提出了一种新方法，利用扩散模型 Instruct Pix2Pix 生成带有天气增强的真实数据集，从而缓解对先进物体检测模型（如 Faster R-CNN 和 YOLOv10）的感知影响。实验在 CARLA 模拟器以及真实数据集 BDD100K 和 ACDC 上进行，结果显示该方法显著缩小了模型在挑战性天气下的性能差距。总体贡献包括量化了物体检测模型的性能缺陷，并证明了定制数据增强策略的有效性，为提升感知系统的可靠性和自动驾驶技术的发展提供了坚实基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.6; I.2.10; I.4.8; I.5.1"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 5 figures. Accepted at the International Joint Conference on\n  Neural Networks (IJCNN) 2025 (to appear)",
      "pdf_url": "http://arxiv.org/pdf/2505.08228v1",
      "published_date": "2025-05-13 05:12:07 UTC",
      "updated_date": "2025-05-13 05:12:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:40:27.478708"
    },
    {
      "arxiv_id": "2505.08223v1",
      "title": "Reinforcement Learning-based Fault-Tolerant Control for Quadrotor with Online Transformer Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Dohyun Kim",
        "Jayden Dongwoo Lee",
        "Hyochoong Bang",
        "Jungho Bae"
      ],
      "abstract": "Multirotors play a significant role in diverse field robotics applications\nbut remain highly susceptible to actuator failures, leading to rapid\ninstability and compromised mission reliability. While various fault-tolerant\ncontrol (FTC) strategies using reinforcement learning (RL) have been widely\nexplored, most previous approaches require prior knowledge of the multirotor\nmodel or struggle to adapt to new configurations. To address these limitations,\nwe propose a novel hybrid RL-based FTC framework integrated with a\ntransformer-based online adaptation module. Our framework leverages a\ntransformer architecture to infer latent representations in real time, enabling\nadaptation to previously unseen system models without retraining. We evaluate\nour method in a PyBullet simulation under loss-of-effectiveness actuator\nfaults, achieving a 95% success rate and a positional root mean square error\n(RMSE) of 0.129 m, outperforming existing adaptation methods with 86% success\nand an RMSE of 0.153 m. Further evaluations on quadrotors with varying\nconfigurations confirm the robustness of our framework across untrained\ndynamics. These results demonstrate the potential of our framework to enhance\nthe adaptability and reliability of multirotors, enabling efficient fault\nmanagement in dynamic and uncertain environments. Website is available at\nhttp://00dhkim.me/paper/rl-ftc",
      "tldr_zh": "本文提出了一种基于 Reinforcement Learning (RL) 的故障耐受控制 (FTC) 框架，用于 Quadrotor，集成在线 Transformer 适应模块，以解决现有方法依赖先验模型或适应性不足的问题。该框架利用 Transformer 架构实时推断潜在表示，允许 Quadrotor 在未见过的系统配置下快速适应，而无需重新训练。在 PyBullet 模拟实验中，该方法在 actuator 故障场景下实现了95%的成功率和0.129 m 的位置 RMSE，比现有方法（86%成功率和0.153 m RMSE）显著提升，证明了其在动态环境中的鲁棒性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Accpted at the 2025 IEEE International Conference on Robotics &\n  Automation (ICRA) Workshop: Robots in the Wild",
      "pdf_url": "http://arxiv.org/pdf/2505.08223v1",
      "published_date": "2025-05-13 04:50:29 UTC",
      "updated_date": "2025-05-13 04:50:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:40:40.145293"
    },
    {
      "arxiv_id": "2505.08222v1",
      "title": "Scaling Multi Agent Reinforcement Learning for Underwater Acoustic Tracking via Autonomous Vehicles",
      "title_zh": "翻译失败",
      "authors": [
        "Matteo Gallici",
        "Ivan Masmitja",
        "Mario Martín"
      ],
      "abstract": "Autonomous vehicles (AV) offer a cost-effective solution for scientific\nmissions such as underwater tracking. Recently, reinforcement learning (RL) has\nemerged as a powerful method for controlling AVs in complex marine\nenvironments. However, scaling these techniques to a fleet--essential for\nmulti-target tracking or targets with rapid, unpredictable motion--presents\nsignificant computational challenges. Multi-Agent Reinforcement Learning (MARL)\nis notoriously sample-inefficient, and while high-fidelity simulators like\nGazebo's LRAUV provide 100x faster-than-real-time single-robot simulations,\nthey offer no significant speedup for multi-vehicle scenarios, making MARL\ntraining impractical. To address these limitations, we propose an iterative\ndistillation method that transfers high-fidelity simulations into a simplified,\nGPU-accelerated environment while preserving high-level dynamics. This approach\nachieves up to a 30,000x speedup over Gazebo through parallelization, enabling\nefficient training via end-to-end GPU acceleration. Additionally, we introduce\na novel Transformer-based architecture (TransfMAPPO) that learns multi-agent\npolicies invariant to the number of agents and targets, significantly improving\nsample efficiency. Following large-scale curriculum learning conducted entirely\non GPU, we perform extensive evaluations in Gazebo, demonstrating that our\nmethod maintains tracking errors below 5 meters over extended durations, even\nin the presence of multiple fast-moving targets. This work bridges the gap\nbetween large-scale MARL training and high-fidelity deployment, providing a\nscalable framework for autonomous fleet control in real-world sea missions.",
      "tldr_zh": "本文探讨了使用自主车辆进行水下声学跟踪时，多智能体强化学习(MARL)的计算挑战和样本效率问题，提出了一种迭代蒸馏方法，将高保真模拟（如Gazebo的LRAUV）转移到简化GPU加速环境，实现高达30,000倍的训练加速。研究还引入了基于Transformer的TransfMAPPO架构，学习对代理和目标数量不敏感的多智能体策略，从而显著提升样本效率。通过大规模GPU课程学习，在Gazebo中进行的评估显示，该方法能将跟踪错误控制在5米以下，即使面对多个快速移动目标。该框架桥接了大规模MARL训练与高保真部署，为真实海域自主舰队控制提供了可扩展解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08222v1",
      "published_date": "2025-05-13 04:42:30 UTC",
      "updated_date": "2025-05-13 04:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:40:52.720737"
    },
    {
      "arxiv_id": "2505.11528v1",
      "title": "LaDi-WM: A Latent Diffusion-based World Model for Predictive Manipulation",
      "title_zh": "LaDi-WM：一种基于潜扩散的世界模型，用于预测性操控",
      "authors": [
        "Yuhang Huang",
        "JIazhao Zhang",
        "Shilong Zou",
        "XInwang Liu",
        "Ruizhen Hu",
        "Kai Xu"
      ],
      "abstract": "Predictive manipulation has recently gained considerable attention in the\nEmbodied AI community due to its potential to improve robot policy performance\nby leveraging predicted states. However, generating accurate future visual\nstates of robot-object interactions from world models remains a well-known\nchallenge, particularly in achieving high-quality pixel-level representations.\nTo this end, we propose LaDi-WM, a world model that predicts the latent space\nof future states using diffusion modeling. Specifically, LaDi-WM leverages the\nwell-established latent space aligned with pre-trained Visual Foundation Models\n(VFMs), which comprises both geometric features (DINO-based) and semantic\nfeatures (CLIP-based). We find that predicting the evolution of the latent\nspace is easier to learn and more generalizable than directly predicting\npixel-level images. Building on LaDi-WM, we design a diffusion policy that\niteratively refines output actions by incorporating forecasted states, thereby\ngenerating more consistent and accurate results. Extensive experiments on both\nsynthetic and real-world benchmarks demonstrate that LaDi-WM significantly\nenhances policy performance by 27.9\\% on the LIBERO-LONG benchmark and 20\\% on\nthe real-world scenario. Furthermore, our world model and policies achieve\nimpressive generalizability in real-world experiments.",
      "tldr_zh": "该论文提出LaDi-WM，一种基于潜在扩散模型的World Model，用于提升预测性操作（Predictive Manipulation）在机器人策略中的性能，通过预测未来状态的潜在空间而非直接生成像素级图像。LaDi-WM利用预训练的Visual Foundation Models (VFMs)潜在空间，包括DINO-based的几何特征和CLIP-based的语义特征，发现这种方法更易学习且具有更好的泛化性。实验结果显示，该模型显著提升策略性能，在LIBERO-LONG基准上提高27.9%，在真实世界场景上提高20%，并展示了出色的泛化能力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11528v1",
      "published_date": "2025-05-13 04:42:14 UTC",
      "updated_date": "2025-05-13 04:42:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:41:04.634111"
    },
    {
      "arxiv_id": "2505.08215v1",
      "title": "Unveiling the Best Practices for Applying Speech Foundation Models to Speech Intelligibility Prediction for Hearing-Impaired People",
      "title_zh": "翻译失败",
      "authors": [
        "Haoshuai Zhou",
        "Boxuan Cao",
        "Changgeng Mo",
        "Linkai Li",
        "Shan Xiang Wang"
      ],
      "abstract": "Speech foundation models (SFMs) have demonstrated strong performance across a\nvariety of downstream tasks, including speech intelligibility prediction for\nhearing-impaired people (SIP-HI). However, optimizing SFMs for SIP-HI has been\ninsufficiently explored. In this paper, we conduct a comprehensive study to\nidentify key design factors affecting SIP-HI performance with 5 SFMs, focusing\non encoder layer selection, prediction head architecture, and ensemble\nconfigurations. Our findings show that, contrary to traditional use-all-layers\nmethods, selecting a single encoder layer yields better results. Additionally,\ntemporal modeling is crucial for effective prediction heads. We also\ndemonstrate that ensembling multiple SFMs improves performance, with stronger\nindividual models providing greater benefit. Finally, we explore the\nrelationship between key SFM attributes and their impact on SIP-HI performance.\nOur study offers practical insights into effectively adapting SFMs for speech\nintelligibility prediction for hearing-impaired populations.",
      "tldr_zh": "本研究探讨了优化 Speech Foundation Models (SFMs) 用于听力障碍者语音可懂度预测 (SIP-HI) 的最佳实践，通过对5个SFMs进行全面分析，焦点包括编码器层选择、预测头架构和集成配置。研究发现，与传统使用所有层的方法不同，选择单个编码器层并加入时间建模能显著提升预测性能；此外，集成多个SFMs可进一步改善效果，且强模型带来更大益处。作者还分析了SFM属性（如关键特征）与SIP-HI性能的关系，提供实用指导，帮助更好地适应SFMs于听力障碍人群的语音预测任务。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08215v1",
      "published_date": "2025-05-13 04:07:59 UTC",
      "updated_date": "2025-05-13 04:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:41:16.861083"
    },
    {
      "arxiv_id": "2505.08202v1",
      "title": "AI and Generative AI Transforming Disaster Management: A Survey of Damage Assessment and Response Techniques",
      "title_zh": "翻译失败",
      "authors": [
        "Aman Raj",
        "Lakshit Arora",
        "Sanjay Surendranath Girija",
        "Shashank Kapoor",
        "Dipen Pradhan",
        "Ankit Shetgaonkar"
      ],
      "abstract": "Natural disasters, including earthquakes, wildfires and cyclones, bear a huge\nrisk on human lives as well as infrastructure assets. An effective response to\ndisaster depends on the ability to rapidly and efficiently assess the intensity\nof damage. Artificial Intelligence (AI) and Generative Artificial Intelligence\n(GenAI) presents a breakthrough solution, capable of combining knowledge from\nmultiple types and sources of data, simulating realistic scenarios of disaster,\nand identifying emerging trends at a speed previously unimaginable. In this\npaper, we present a comprehensive review on the prospects of AI and GenAI in\ndamage assessment for various natural disasters, highlighting both its\nstrengths and limitations. We talk about its application to multimodal data\nsuch as text, image, video, and audio, and also cover major issues of data\nprivacy, security, and ethical use of the technology during crises. The paper\nalso recognizes the threat of Generative AI misuse, in the form of\ndissemination of misinformation and for adversarial attacks. Finally, we\noutline avenues of future research, emphasizing the need for secure, reliable,\nand ethical Generative AI systems for disaster management in general. We\nbelieve that this work represents the first comprehensive survey of Gen-AI\ntechniques being used in the field of Disaster Assessment and Response.",
      "tldr_zh": "这篇论文对AI和Generative AI (GenAI)在灾害管理中的应用进行了全面调查，重点关注自然灾害（如地震、野火和旋风）中的损害评估和响应技术。论文强调AI和GenAI能够快速整合多模态数据（如文本、图像、视频和音频），模拟现实场景并识别趋势，从而提升灾害响应的效率，同时讨论了数据隐私、安全和伦理问题的挑战，以及GenAI潜在误用风险如传播错误信息和敌对攻击。最终，论文概述了未来研究方向，呼吁开发安全、可靠且伦理的GenAI系统，并声称这是该领域的首个全面调查。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted in IEEE Compsac 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08202v1",
      "published_date": "2025-05-13 03:33:31 UTC",
      "updated_date": "2025-05-13 03:33:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:41:28.496462"
    },
    {
      "arxiv_id": "2505.08200v1",
      "title": "A Head to Predict and a Head to Question: Pre-trained Uncertainty Quantification Heads for Hallucination Detection in LLM Outputs",
      "title_zh": "翻译失败",
      "authors": [
        "Artem Shelmanov",
        "Ekaterina Fadeeva",
        "Akim Tsvigun",
        "Ivan Tsvigun",
        "Zhuohan Xie",
        "Igor Kiselev",
        "Nico Daheim",
        "Caiqi Zhang",
        "Artem Vazhentsev",
        "Mrinmaya Sachan",
        "Preslav Nakov",
        "Timothy Baldwin"
      ],
      "abstract": "Large Language Models (LLMs) have the tendency to hallucinate, i.e., to\nsporadically generate false or fabricated information. This presents a major\nchallenge, as hallucinations often appear highly convincing and users generally\nlack the tools to detect them. Uncertainty quantification (UQ) provides a\nframework for assessing the reliability of model outputs, aiding in the\nidentification of potential hallucinations. In this work, we introduce\npre-trained UQ heads: supervised auxiliary modules for LLMs that substantially\nenhance their ability to capture uncertainty compared to unsupervised UQ\nmethods. Their strong performance stems from the powerful Transformer\narchitecture in their design and informative features derived from LLM\nattention maps. Experimental evaluation shows that these heads are highly\nrobust and achieve state-of-the-art performance in claim-level hallucination\ndetection across both in-domain and out-of-domain prompts. Moreover, these\nmodules demonstrate strong generalization to languages they were not explicitly\ntrained on. We pre-train a collection of UQ heads for popular LLM series,\nincluding Mistral, Llama, and Gemma 2. We publicly release both the code and\nthe pre-trained heads.",
      "tldr_zh": "该论文针对大语言模型 (LLMs) 的幻觉问题（即生成虚假信息），提出了一种预训练的不确定性量化 (UQ) heads 机制，作为监督辅助模块，以提升模型输出可靠性的评估能力。UQ heads 采用 Transformer 架构和从 LLM 注意力地图中提取的特征，比无监督方法更有效地捕捉不确定性。实验结果显示，这些 heads 在声明级幻觉检测中达到最先进水平，并在域内/域外提示以及未训练语言上表现出强鲁棒性和泛化能力。作者公开了代码和预训练模型，包括适用于 Mistral、Llama 和 Gemma 2 等 LLM 系列的版本。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08200v1",
      "published_date": "2025-05-13 03:30:26 UTC",
      "updated_date": "2025-05-13 03:30:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:41:41.674551"
    },
    {
      "arxiv_id": "2505.08830v1",
      "title": "Federated Large Language Models: Feasibility, Robustness, Security and Future Directions",
      "title_zh": "联邦大语言模型：可行性、鲁棒性、安全以及未来方向",
      "authors": [
        "Wenhao Jiang",
        "Yuchuan Luo",
        "Guilin Deng",
        "Silong Chen",
        "Xu Yang",
        "Shihong Wu",
        "Xinwen Gao",
        "Lin Liu",
        "Shaojing Fu"
      ],
      "abstract": "The integration of Large Language Models (LLMs) and Federated Learning (FL)\npresents a promising solution for joint training on distributed data while\npreserving privacy and addressing data silo issues. However, this emerging\nfield, known as Federated Large Language Models (FLLM), faces significant\nchallenges, including communication and computation overheads, heterogeneity,\nprivacy and security concerns. Current research has primarily focused on the\nfeasibility of FLLM, but future trends are expected to emphasize enhancing\nsystem robustness and security. This paper provides a comprehensive review of\nthe latest advancements in FLLM, examining challenges from four critical\nperspectives: feasibility, robustness, security, and future directions. We\npresent an exhaustive survey of existing studies on FLLM feasibility, introduce\nmethods to enhance robustness in the face of resource, data, and task\nheterogeneity, and analyze novel risks associated with this integration,\nincluding privacy threats and security challenges. We also review the latest\ndevelopments in defense mechanisms and explore promising future research\ndirections, such as few-shot learning, machine unlearning, and IP protection.\nThis survey highlights the pressing need for further research to enhance system\nrobustness and security while addressing the unique challenges posed by the\nintegration of FL and LLM.",
      "tldr_zh": "这篇论文审查了 Federated Large Language Models (FLLM)，即将 Large Language Models (LLMs) 与 Federated Learning (FL) 整合，以实现分布式数据联合训练，同时保护隐私并解决数据孤岛问题。论文从可行性、鲁棒性和安全性四个关键视角分析了 FLLM 的挑战，包括通信计算开销、异质性和隐私威胁，并介绍了增强系统鲁棒性的方法，如处理资源、数据和任务异质性，以及最新的防御机制。最终，论文强调未来研究方向，如 few-shot learning、machine unlearning 和 IP protection，以提升 FLLM 的可靠性和安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08830v1",
      "published_date": "2025-05-13 03:23:54 UTC",
      "updated_date": "2025-05-13 03:23:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:41:52.747973"
    },
    {
      "arxiv_id": "2505.08195v1",
      "title": "Aitomia: Your Intelligent Assistant for AI-Driven Atomistic and Quantum Chemical Simulations",
      "title_zh": "翻译失败",
      "authors": [
        "Jinming Hu",
        "Hassan Nawaz",
        "Yuting Rui",
        "Lijie Chi",
        "Arif Ullah",
        "Pavlo O. Dral"
      ],
      "abstract": "We have developed Aitomia - a platform powered by AI to assist in performing\nAI-driven atomistic and quantum chemical (QC) simulations. This intelligent\nassistant platform is equipped with chatbots and AI agents to help experts and\nguide non-experts in setting up and running the atomistic simulations,\nmonitoring their computation status, analyzing the simulation results, and\nsummarizing them for the user in text and graphical forms. We achieve these\ngoals by exploiting fine-tuned open-source large language models (LLMs),\nrule-based agents, and a retrieval-augmented generation (RAG) system. Aitomia\nleverages the versatility of our MLatom ecosystem for AI-enhanced computational\nchemistry. This intelligent assistant is going to be integrated into the\nAitomistic Hub and XACS online computing services, with some functionality\nalready publicly available as described at http://mlatom.com/aitomia. Aitomia\nis expected to lower the barrier to performing atomistic simulations,\naccelerating research and development in the relevant fields.",
      "tldr_zh": "该研究介绍了 Aitomia，一个基于 AI 的智能助手平台，用于辅助进行原子尺度和量子化学 (QC) 模拟。Aitomia 利用微调的开源大型语言模型 (LLMs)、基于规则的代理和检索增强生成 (RAG) 系统，帮助用户设置、运行模拟、监控进度、分析结果，并以文本和图形形式总结输出。平台将整合到 MLatom 生态系统、Aitomistic Hub 和 XACS 在线服务中，已有部分功能公开，可降低原子模拟的门槛，加速相关领域的研发和创新。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "physics.chem-ph"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08195v1",
      "published_date": "2025-05-13 03:11:41 UTC",
      "updated_date": "2025-05-13 03:11:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:42:04.096020"
    },
    {
      "arxiv_id": "2505.08189v1",
      "title": "DSADF: Thinking Fast and Slow for Decision Making",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Zhihao Dou",
        "Dongfei Cui",
        "Jun Yan",
        "Weida Wang",
        "Benteng Chen",
        "Haoming Wang",
        "Zeke Xie",
        "Shufei Zhang"
      ],
      "abstract": "Although Reinforcement Learning (RL) agents are effective in well-defined\nenvironments, they often struggle to generalize their learned policies to\ndynamic settings due to their reliance on trial-and-error interactions. Recent\nwork has explored applying Large Language Models (LLMs) or Vision Language\nModels (VLMs) to boost the generalization of RL agents through policy\noptimization guidance or prior knowledge. However, these approaches often lack\nseamless coordination between the RL agent and the foundation model, leading to\nunreasonable decision-making in unfamiliar environments and efficiency\nbottlenecks. Making full use of the inferential capabilities of foundation\nmodels and the rapid response capabilities of RL agents and enhancing the\ninteraction between the two to form a dual system is still a lingering\nscientific question. To address this problem, we draw inspiration from\nKahneman's theory of fast thinking (System 1) and slow thinking (System 2),\ndemonstrating that balancing intuition and deep reasoning can achieve nimble\ndecision-making in a complex world. In this study, we propose a Dual-System\nAdaptive Decision Framework (DSADF), integrating two complementary modules:\nSystem 1, comprising an RL agent and a memory space for fast and intuitive\ndecision making, and System 2, driven by a VLM for deep and analytical\nreasoning. DSADF facilitates efficient and adaptive decision-making by\ncombining the strengths of both systems. The empirical study in the video game\nenvironment: Crafter and Housekeep demonstrates the effectiveness of our\nproposed method, showing significant improvements in decision abilities for\nboth unseen and known tasks.",
      "tldr_zh": "该研究针对强化学习 (RL) 代理在动态环境中泛化能力不足的问题，提出 Dual-System Adaptive Decision Framework (DSADF)，受 Kahneman 的快速思考 (System 1) 和缓慢思考 (System 2) 理论启发。DSADF 整合了 System 1（由 RL 代理和记忆空间驱动，实现快速直观决策）和 System 2（由 Vision Language Models (VLMs) 驱动，进行深度分析推理），从而提升决策的效率和适应性。在视频游戏环境如 Crafter 和 Housekeep 的实证研究中，该框架显著提高了代理在已知和未知任务上的决策性能，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08189v1",
      "published_date": "2025-05-13 02:58:04 UTC",
      "updated_date": "2025-05-13 02:58:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:42:16.455093"
    },
    {
      "arxiv_id": "2505.08179v2",
      "title": "Feasibility-Aware Pessimistic Estimation: Toward Long-Horizon Safety in Offline RL",
      "title_zh": "翻译失败",
      "authors": [
        "Zhikun Tao",
        "Gang Xiong",
        "He Fang",
        "Zhen Shen",
        "Yunjun Han",
        "Qing-Shan Jia"
      ],
      "abstract": "Offline safe reinforcement learning(OSRL) derives constraint-satisfying\npolicies from pre-collected datasets, offers a promising avenue for deploying\nRL in safety-critical real-world domains such as robotics. However, the\nmajority of existing approaches emphasize only short-term safety, neglecting\nlong-horizon considerations. Consequently, they may violate safety constraints\nand fail to ensure sustained protection during online deployment. Moreover, the\nlearned policies often struggle to handle states and actions that are not\npresent or out-of-distribution(OOD) from the offline dataset, and exhibit\nlimited sample efficiency. To address these challenges, we propose a novel\nframework Feasibility-Aware offline Safe Reinforcement Learning with CVAE-based\nPessimism (FASP). First, we employ Hamilton-Jacobi (H-J) reachability analysis\nto generate reliable safety labels, which serve as supervisory signals for\ntraining both a conditional variational autoencoder (CVAE) and a safety\nclassifier. This approach not only ensures high sampling efficiency but also\nprovides rigorous long-horizon safety guarantees. Furthermore, we utilize\npessimistic estimation methods to estimate the Q-value of reward and cost,\nwhich mitigates the extrapolation errors induces by OOD actions, and penalize\nunsafe actions to enabled the agent to proactively avoid high-risk behaviors.\nMoreover, we theoretically prove the validity of this pessimistic estimation.\nExtensive experiments on DSRL benchmarks demonstrate that FASP algorithm\nachieves competitive performance across multiple experimental tasks,\nparticularly outperforming state-of-the-art algorithms in terms of safety.",
      "tldr_zh": "该研究针对离线强化学习（Offline RL）中的安全问题，提出了一种新框架Feasibility-Aware offline Safe Reinforcement Learning with CVAE-based Pessimism (FASP)，旨在解决现有方法忽略长期安全（long-horizon safety）和处理分布外（OOD）状态/动作的挑战。FASP框架利用Hamilton-Jacobi (H-J) reachability analysis生成可靠的安全标签，并结合conditional variational autoencoder (CVAE)训练安全分类器，以提升采样效率并提供严格的长期安全保证。同时，通过pessimistic estimation方法估计奖励和成本的Q-value，减少OOD动作的误差并惩罚高风险行为，该方法还得到理论证明。在DSRL基准实验中，FASP在多个任务中表现出色，尤其在安全性能上优于现有算法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The text is suspected of plagiarism in the description of\n  methodology. We decided to withdraw it for systematic academic standard\n  verification and expression optimization",
      "pdf_url": "http://arxiv.org/pdf/2505.08179v2",
      "published_date": "2025-05-13 02:32:49 UTC",
      "updated_date": "2025-05-20 16:40:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:42:28.591269"
    },
    {
      "arxiv_id": "2505.08176v1",
      "title": "Behind the Noise: Conformal Quantile Regression Reveals Emergent Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Petrus H. Zwart",
        "Tamas Varga",
        "Odeta Qafoku",
        "James A. Sethian"
      ],
      "abstract": "Scientific imaging often involves long acquisition times to obtain\nhigh-quality data, especially when probing complex, heterogeneous systems.\nHowever, reducing acquisition time to increase throughput inevitably introduces\nsignificant noise into the measurements. We present a machine learning approach\nthat not only denoises low-quality measurements with calibrated uncertainty\nbounds, but also reveals emergent structure in the latent space. By using\nensembles of lightweight, randomly structured neural networks trained via\nconformal quantile regression, our method performs reliable denoising while\nuncovering interpretable spatial and chemical features -- without requiring\nlabels or segmentation. Unlike conventional approaches focused solely on image\nrestoration, our framework leverages the denoising process itself to drive the\nemergence of meaningful representations. We validate the approach on real-world\ngeobiochemical imaging data, showing how it supports confident interpretation\nand guides experimental design under resource constraints.",
      "tldr_zh": "该研究针对科学成像中缩短获取时间导致的噪声问题，提出了一种基于机器学习的框架，使用 conformal quantile regression 训练的轻量级神经网络集合（ensembles of lightweight, randomly structured neural networks），实现可靠的图像去噪并提供校准的不确定性边界。同时，该方法无需标签或分割，就能揭示潜在空间的 emergent representations，包括可解释的空间和化学特征。实验在真实世界的地质生化成像数据上验证，证明该框架不仅提升了图像恢复质量，还支持自信的解释和实验设计指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08176v1",
      "published_date": "2025-05-13 02:27:12 UTC",
      "updated_date": "2025-05-13 02:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:42:40.491438"
    },
    {
      "arxiv_id": "2505.08175v3",
      "title": "Fast Text-to-Audio Generation with Adversarial Post-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Zachary Novack",
        "Zach Evans",
        "Zack Zukowski",
        "Josiah Taylor",
        "CJ Carr",
        "Julian Parker",
        "Adnan Al-Sinan",
        "Gian Marco Iodice",
        "Julian McAuley",
        "Taylor Berg-Kirkpatrick",
        "Jordi Pons"
      ],
      "abstract": "Text-to-audio systems, while increasingly performant, are slow at inference\ntime, thus making their latency unpractical for many creative applications. We\npresent Adversarial Relativistic-Contrastive (ARC) post-training, the first\nadversarial acceleration algorithm for diffusion/flow models not based on\ndistillation. While past adversarial post-training methods have struggled to\ncompare against their expensive distillation counterparts, ARC post-training is\na simple procedure that (1) extends a recent relativistic adversarial\nformulation to diffusion/flow post-training and (2) combines it with a novel\ncontrastive discriminator objective to encourage better prompt adherence. We\npair ARC post-training with a number optimizations to Stable Audio Open and\nbuild a model capable of generating $\\approx$12s of 44.1kHz stereo audio in\n$\\approx$75ms on an H100, and $\\approx$7s on a mobile edge-device, the fastest\ntext-to-audio model to our knowledge.",
      "tldr_zh": "本文提出Adversarial Relativistic-Contrastive (ARC) post-training，一种新型对抗性加速算法，用于提升文本到音频系统的推理速度，而不依赖于蒸馏技术。该算法扩展了相对论对抗性公式，并结合新型对比鉴别器目标，以提高提示遵守性和生成效率。在Stable Audio Open模型上优化后，该方法实现了在H100上生成约12秒44.1kHz立体音频仅需75ms，在移动边缘设备上只需约7s，成为已知的最快文本到音频生成模型。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08175v3",
      "published_date": "2025-05-13 02:25:47 UTC",
      "updated_date": "2025-05-20 02:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:42:53.019037"
    },
    {
      "arxiv_id": "2505.08168v1",
      "title": "Exploiting Text Semantics for Few and Zero Shot Node Classification on Text-attributed Graph",
      "title_zh": "利用文本语义进行文本属性图上的少样本和零样本节点分类",
      "authors": [
        "Yuxiang Wang",
        "Xiao Yan",
        "Shiyu Jin",
        "Quanqing Xu",
        "Chuang Hu",
        "Yuanyuan Zhu",
        "Bo Du",
        "Jia Wu",
        "Jiawei Jiang"
      ],
      "abstract": "Text-attributed graph (TAG) provides a text description for each graph node,\nand few- and zero-shot node classification on TAGs have many applications in\nfields such as academia and social networks. Existing work utilizes various\ngraph-based augmentation techniques to train the node and text embeddings,\nwhile text-based augmentations are largely unexplored. In this paper, we\npropose Text Semantics Augmentation (TSA) to improve accuracy by introducing\nmore text semantic supervision signals. Specifically, we design two\naugmentation techniques, i.e., positive semantics matching and negative\nsemantics contrast, to provide more reference texts for each graph node or text\ndescription. Positive semantic matching retrieves texts with similar embeddings\nto match with a graph node. Negative semantic contrast adds a negative prompt\nto construct a text description with the opposite semantics, which is\ncontrasted with the original node and text. We evaluate TSA on 5 datasets and\ncompare with 13 state-of-the-art baselines. The results show that TSA\nconsistently outperforms all baselines, and its accuracy improvements over the\nbest-performing baseline are usually over 5%.",
      "tldr_zh": "本文针对文本属性图 (TAG) 中的少样本 (few-shot) 和零样本 (zero-shot) 节点分类问题，提出 Text Semantics Augmentation (TSA) 方法，通过引入更多文本语义监督信号来提升分类准确率。具体而言，TSA 包括 positive semantics matching（检索相似嵌入的文本作为正向匹配）和 negative semantics contrast（添加负向提示构建语义相反的文本描述进行对比）。在 5 个数据集上的实验结果显示，TSA 比 13 个最先进基线模型的表现提高了超过 5%，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08168v1",
      "published_date": "2025-05-13 02:06:08 UTC",
      "updated_date": "2025-05-13 02:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:43:04.989224"
    },
    {
      "arxiv_id": "2505.08167v2",
      "title": "Fusing Bidirectional Chains of Thought and Reward Mechanisms A Method for Enhancing Question-Answering Capabilities of Large Language Models for Chinese Intangible Cultural Heritage",
      "title_zh": "翻译失败",
      "authors": [
        "Ruilin Liu",
        "Zhixiao Zhao",
        "Jieqiong Li",
        "Chang Liu",
        "Dongbo Wang"
      ],
      "abstract": "The rapid development of large language models (LLMs) has provided\nsignificant support and opportunities for the advancement of domain-specific\nLLMs. However, fine-tuning these large models using Intangible Cultural\nHeritage (ICH) data inevitably faces challenges such as bias, incorrect\nknowledge inheritance, and catastrophic forgetting. To address these issues, we\npropose a novel training method that integrates a bidirectional chains of\nthought and a reward mechanism. This method is built upon ICH-Qwen, a large\nlanguage model specifically designed for the field of intangible cultural\nheritage. The proposed method enables the model to not only perform forward\nreasoning but also enhances the accuracy of the generated answers by utilizing\nreverse questioning and reverse reasoning to activate the model's latent\nknowledge. Additionally, a reward mechanism is introduced during training to\noptimize the decision-making process. This mechanism improves the quality of\nthe model's outputs through structural and content evaluations with different\nweighting schemes. We conduct comparative experiments on ICH-Qwen, with results\ndemonstrating that our method outperforms 0-shot, step-by-step reasoning,\nknowledge distillation, and question augmentation methods in terms of accuracy,\nBleu-4, and Rouge-L scores on the question-answering task. Furthermore, the\npaper highlights the effectiveness of combining the bidirectional chains of\nthought and reward mechanism through ablation experiments. In addition, a\nseries of generalizability experiments are conducted, with results showing that\nthe proposed method yields improvements on various domain-specific datasets and\nadvanced models in areas such as Finance, Wikidata, and StrategyQA. This\ndemonstrates that the method is adaptable to multiple domains and provides a\nvaluable approach for model training in future applications across diverse\nfields.",
      "tldr_zh": "本文提出了一种新方法，将双向链式思维(bidirectional chains of thought)和奖励机制(reward mechanism)整合到大语言模型(LLMs)训练中，旨在提升针对中国非物质文化遗产(ICH)的问答能力。该方法基于 ICH-Qwen 模型，通过正向推理和反向质疑/推理激活模型的潜在知识，并利用奖励机制进行结构和内容评估以优化决策过程。实验结果显示，该方法在 ICH 问答任务上优于 0-shot、step-by-step reasoning 等基线方法，在准确率、Bleu-4 和 Rouge-L 指标上表现出显著改善。消融实验和泛化实验进一步证明，该方法具有良好的适应性，可应用于金融、Wikidata 和 StrategyQA 等其他领域。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.08167v2",
      "published_date": "2025-05-13 02:05:25 UTC",
      "updated_date": "2025-05-14 01:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:43:17.913942"
    },
    {
      "arxiv_id": "2505.08163v1",
      "title": "Decoding Neighborhood Environments with Large Language Models",
      "title_zh": "使用大型语言模型解码邻里环境",
      "authors": [
        "Andrew Cart",
        "Shaohu Zhang",
        "Melanie Escue",
        "Xugui Zhou",
        "Haitao Zhao",
        "Prashanth BusiReddyGari",
        "Beiyu Lin",
        "Shuang Li"
      ],
      "abstract": "Neighborhood environments include physical and environmental conditions such\nas housing quality, roads, and sidewalks, which significantly influence human\nhealth and well-being. Traditional methods for assessing these environments,\nincluding field surveys and geographic information systems (GIS), are\nresource-intensive and challenging to evaluate neighborhood environments at\nscale. Although machine learning offers potential for automated analysis, the\nlaborious process of labeling training data and the lack of accessible models\nhinder scalability. This study explores the feasibility of large language\nmodels (LLMs) such as ChatGPT and Gemini as tools for decoding neighborhood\nenvironments (e.g., sidewalk and powerline) at scale. We train a robust\nYOLOv11-based model, which achieves an average accuracy of 99.13% in detecting\nsix environmental indicators, including streetlight, sidewalk, powerline,\napartment, single-lane road, and multilane road. We then evaluate four LLMs,\nincluding ChatGPT, Gemini, Claude, and Grok, to assess their feasibility,\nrobustness, and limitations in identifying these indicators, with a focus on\nthe impact of prompting strategies and fine-tuning. We apply majority voting\nwith the top three LLMs to achieve over 88% accuracy, which demonstrates LLMs\ncould be a useful tool to decode the neighborhood environment without any\ntraining effort.",
      "tldr_zh": "该研究探讨了使用大型语言模型（LLMs）来大规模识别社区环境（如人行道和电线），以解决传统评估方法（如实地调查和 GIS）的资源密集问题。研究者训练了一个基于 YOLOv11 的模型，实现了99.13%的平均准确率，用于检测六种环境指标，包括街灯、人行道、电线等。随后，他们评估了 ChatGPT、Gemini、Claude 和 Grok 等四种 LLMs 的可行性、鲁棒性和局限性，焦点在于提示策略和微调的影响。通过采用前三名 LLMs 的多数投票方法，准确率超过了88%。这项工作证明了 LLMs 可以作为无需额外训练的工具，有效解码社区环境，从而提升健康和福祉评估的效率。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08163v1",
      "published_date": "2025-05-13 01:54:54 UTC",
      "updated_date": "2025-05-13 01:54:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:43:31.231121"
    },
    {
      "arxiv_id": "2505.08158v1",
      "title": "Feature Fitted Online Conformal Prediction for Deep Time Series Forecasting Model",
      "title_zh": "翻译失败",
      "authors": [
        "Xiannan Huang",
        "Shuhan Qiu"
      ],
      "abstract": "Time series forecasting is critical for many applications, where deep\nlearning-based point prediction models have demonstrated strong performance.\nHowever, in practical scenarios, there is also a need to quantify predictive\nuncertainty through online confidence intervals. Existing confidence interval\nmodeling approaches building upon these deep point prediction models suffer\nfrom key limitations: they either require costly retraining, fail to fully\nleverage the representational strengths of deep models, or lack theoretical\nguarantees. To address these gaps, we propose a lightweight conformal\nprediction method that provides valid coverage and shorter interval lengths\nwithout retraining. Our approach leverages features extracted from pre-trained\npoint prediction models to fit a residual predictor and construct confidence\nintervals, further enhanced by an adaptive coverage control mechanism.\nTheoretically, we prove that our method achieves asymptotic coverage\nconvergence, with error bounds dependent on the feature quality of the\nunderlying point prediction model. Experiments on 12 datasets demonstrate that\nour method delivers tighter confidence intervals while maintaining desired\ncoverage rates. Code, model and dataset in\n\\href{https://github.com/xiannanhuang/FFDCI}{Github}",
      "tldr_zh": "该研究针对深度学习时间序列预测模型，提出了一种轻量级的在线 Conformal Prediction 方法，以量化预测不确定性并构建置信区间。该方法利用预训练点预测模型提取的特征来拟合残差预测器，并引入自适应覆盖控制机制，避免了昂贵的重新训练，同时充分利用了深度模型的表示能力。理论上，该方法证明了渐进覆盖收敛，并提供了错误边界依赖于底层模型特征质量的分析。在12个数据集的实验中，该方法实现了更紧凑的置信区间，同时保持了预期的覆盖率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08158v1",
      "published_date": "2025-05-13 01:33:53 UTC",
      "updated_date": "2025-05-13 01:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:43:41.768020"
    },
    {
      "arxiv_id": "2505.08157v1",
      "title": "Hyperbolic Contrastive Learning with Model-augmentation for Knowledge-aware Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Shengyin Sun",
        "Chen Ma"
      ],
      "abstract": "Benefiting from the effectiveness of graph neural networks (GNNs) and\ncontrastive learning, GNN-based contrastive learning has become mainstream for\nknowledge-aware recommendation. However, most existing contrastive\nlearning-based methods have difficulties in effectively capturing the\nunderlying hierarchical structure within user-item bipartite graphs and\nknowledge graphs. Moreover, they commonly generate positive samples for\ncontrastive learning by perturbing the graph structure, which may lead to a\nshift in user preference learning. To overcome these limitations, we propose\nhyperbolic contrastive learning with model-augmentation for knowledge-aware\nrecommendation. To capture the intrinsic hierarchical graph structures, we\nfirst design a novel Lorentzian knowledge aggregation mechanism, which enables\nmore effective representations of users and items. Then, we propose three\nmodel-level augmentation techniques to assist Hyperbolic contrastive learning.\nDifferent from the classical structure-level augmentation (e.g., edge\ndropping), the proposed model-augmentations can avoid preference shifts between\nthe augmented positive pair. Finally, we conduct extensive experiments to\ndemonstrate the superiority (maximum improvement of $11.03\\%$) of proposed\nmethods over existing baselines.",
      "tldr_zh": "这篇论文针对知识aware推荐中的问题，提出了Hyperbolic Contrastive Learning with Model-augmentation方法，以更好地捕捉用户-物品二分图和知识图的层次结构。不同于传统结构级增强（如边删除）可能导致用户偏好偏移，该方法引入Lorentzian Knowledge Aggregation机制来更有效地表示用户和物品，并设计三种model-level augmentation技巧来生成正样本。实验结果显示，该方法在性能上比现有基线提高了最多11.03%。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08157v1",
      "published_date": "2025-05-13 01:30:27 UTC",
      "updated_date": "2025-05-13 01:30:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:43:52.931033"
    },
    {
      "arxiv_id": "2505.08155v3",
      "title": "Efficient and Scalable Neural Symbolic Search for Knowledge Graph Complex Query Answering",
      "title_zh": "高效且可扩展的神经符号搜索用于知识",
      "authors": [
        "Weizhi Fei",
        "Zihao Wang",
        "hang Yin",
        "Shukai Zhao",
        "Wei Zhang",
        "Yangqiu Song"
      ],
      "abstract": "Complex Query Answering (CQA) aims to retrieve answer sets for complex\nlogical formulas from incomplete knowledge graphs, which is a crucial yet\nchallenging task in knowledge graph reasoning. While neuro-symbolic search\nutilized neural link predictions achieve superior accuracy, they encounter\nsignificant complexity bottlenecks: (i) Data complexity typically scales\nquadratically with the number of entities in the knowledge graph, and (ii)\nQuery complexity becomes NP-hard for cyclic queries. Consequently, these\napproaches struggle to effectively scale to larger knowledge graphs and more\ncomplex queries. To address these challenges, we propose an efficient and\nscalable symbolic search framework. First, we propose two constraint strategies\nto compute neural logical indices to reduce the domain of variables, thereby\ndecreasing the data complexity of symbolic search. Additionally, we introduce\nan approximate algorithm based on local search to tackle the NP query\ncomplexity of cyclic queries. Experiments on various CQA benchmarks demonstrate\nthat our framework reduces the computational load of symbolic methods by 90\\%\nwhile maintaining nearly the same performance, thus alleviating both efficiency\nand scalability issues.",
      "tldr_zh": "本论文针对知识图谱的Complex Query Answering (CQA)任务，解决了神经符号搜索在数据复杂性（随实体数量平方增长）和查询复杂性（对循环查询为NP-hard）方面的瓶颈。研究提出一个高效且可扩展的符号搜索框架，包括两项约束策略来计算神经逻辑索引以缩小变量域，以及基于局部搜索的近似算法来处理循环查询，从而显著降低计算负载。实验在多种CQA基准上显示，该框架将符号方法的计算负载减少90%，同时保持几乎相同的性能水平，显著提升了效率和可扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08155v3",
      "published_date": "2025-05-13 01:24:09 UTC",
      "updated_date": "2025-05-20 12:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:44:05.402625"
    },
    {
      "arxiv_id": "2505.08151v1",
      "title": "Foundation Models Knowledge Distillation For Battery Capacity Degradation Forecast",
      "title_zh": "翻译失败",
      "authors": [
        "Joey Chan",
        "Zhen Chen",
        "Ershun Pan"
      ],
      "abstract": "Accurate estimation of lithium-ion battery capacity degradation is critical\nfor enhancing the reliability and safety of battery operations. Traditional\nexpert models, tailored to specific scenarios, provide isolated estimations.\nWith the rapid advancement of data-driven techniques, a series of\ngeneral-purpose time-series foundation models have been developed. However,\nfoundation models specifically designed for battery capacity degradation remain\nlargely unexplored. To enable zero-shot generalization in battery degradation\nprediction using large model technology, this study proposes a\ndegradation-aware fine-tuning strategy for time-series foundation models. We\napply this strategy to fine-tune the Timer model on approximately 10 GB of\nopen-source battery charge discharge data. Validation on our released\nCycleLife-SJTUIE dataset demonstrates that the fine-tuned Battery-Timer\npossesses strong zero-shot generalization capability in capacity degradation\nforecasting. To address the computational challenges of deploying large models,\nwe further propose a knowledge distillation framework that transfers the\nknowledge of pre-trained foundation models into compact expert models.\nDistillation results across several state-of-the-art time-series expert models\nconfirm that foundation model knowledge significantly improves the\nmulti-condition generalization of expert models.",
      "tldr_zh": "该研究针对锂离子电池容量退化预测问题，提出了一种基于 foundation models 的知识蒸馏框架，以解决传统专家模型在特定场景下的局限性。研究者开发了 degradation-aware fine-tuning 策略，对 time-series foundation models 如 Timer 模型进行微调，使用约 10 GB 开源数据训练出 Battery-Timer，实现零-shot generalization。实验在 CycleLife-SJTUIE 数据集上验证，fine-tuned 模型表现出色，而通过 knowledge distillation 将 foundation models 的知识转移到紧凑专家模型中，显著提升了专家模型的多条件泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08151v1",
      "published_date": "2025-05-13 01:03:35 UTC",
      "updated_date": "2025-05-13 01:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:44:16.841026"
    },
    {
      "arxiv_id": "2505.08829v2",
      "title": "Aggregating Concepts of Accuracy and Fairness in Prediction Algorithms",
      "title_zh": "预测算法中准确性和公平性概念的聚合",
      "authors": [
        "David Kinney"
      ],
      "abstract": "An algorithm that outputs predictions about the state of the world will\nalmost always be designed with the implicit or explicit goal of outputting\naccurate predictions (i.e., predictions that are likely to be true). In\naddition, the rise of increasingly powerful predictive algorithms brought about\nby the recent revolution in artificial intelligence has led to an emphasis on\nbuilding predictive algorithms that are fair, in the sense that their\npredictions do not systematically evince bias or bring about harm to certain\nindividuals or groups. This state of affairs presents two conceptual\nchallenges. First, the goals of accuracy and fairness can sometimes be in\ntension, and there are no obvious normative guidelines for managing the\ntrade-offs between these two desiderata when they arise. Second, there are many\ndistinct ways of measuring both the accuracy and fairness of a predictive\nalgorithm; here too, there are no obvious guidelines on how to aggregate our\npreferences for predictive algorithms that satisfy disparate measures of\nfairness and accuracy to various extents. The goal of this paper is to address\nthese challenges by arguing that there are good reasons for using a linear\ncombination of accuracy and fairness metrics to measure the\nall-things-considered value of a predictive algorithm for agents who care about\nboth accuracy and fairness. My argument depends crucially on a classic result\nin the preference aggregation literature due to Harsanyi. After making this\nformal argument, I apply my result to an analysis of accuracy-fairness\ntrade-offs using the COMPAS dataset compiled by Angwin et al.",
      "tldr_zh": "这篇论文探讨了预测算法中准确性(accuracy)和公平性(fairness)的聚合问题，强调二者可能冲突时的权衡挑战，并指出多种衡量指标的偏好整合难题。作者基于Harsanyi的经典偏好聚合理论，论证使用准确性和公平性指标的线性组合(linear combination)来评估算法的整体价值，为处理这些权衡提供规范性指导。最终，论文将这一方法应用于COMPAS dataset的实证分析中，展示了其在实际场景中的应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08829v2",
      "published_date": "2025-05-13 01:00:25 UTC",
      "updated_date": "2025-05-15 12:19:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:44:28.916475"
    },
    {
      "arxiv_id": "2505.08148v1",
      "title": "A Large-Scale Empirical Analysis of Custom GPTs' Vulnerabilities in the OpenAI Ecosystem",
      "title_zh": "翻译失败",
      "authors": [
        "Sunday Oyinlola Ogundoyin",
        "Muhammad Ikram",
        "Hassan Jameel Asghar",
        "Benjamin Zi Hao Zhao",
        "Dali Kaafar"
      ],
      "abstract": "Millions of users leverage generative pretrained transformer (GPT)-based\nlanguage models developed by leading model providers for a wide range of tasks.\nTo support enhanced user interaction and customization, many platforms-such as\nOpenAI-now enable developers to create and publish tailored model instances,\nknown as custom GPTs, via dedicated repositories or application stores. These\ncustom GPTs empower users to browse and interact with specialized applications\ndesigned to meet specific needs. However, as custom GPTs see growing adoption,\nconcerns regarding their security vulnerabilities have intensified. Existing\nresearch on these vulnerabilities remains largely theoretical, often lacking\nempirical, large-scale, and statistically rigorous assessments of associated\nrisks.\n  In this study, we analyze 14,904 custom GPTs to assess their susceptibility\nto seven exploitable threats, such as roleplay-based attacks, system prompt\nleakage, phishing content generation, and malicious code synthesis, across\nvarious categories and popularity tiers within the OpenAI marketplace. We\nintroduce a multi-metric ranking system to examine the relationship between a\ncustom GPT's popularity and its associated security risks.\n  Our findings reveal that over 95% of custom GPTs lack adequate security\nprotections. The most prevalent vulnerabilities include roleplay-based\nvulnerabilities (96.51%), system prompt leakage (92.20%), and phishing\n(91.22%). Furthermore, we demonstrate that OpenAI's foundational models exhibit\ninherent security weaknesses, which are often inherited or amplified in custom\nGPTs. These results highlight the urgent need for enhanced security measures\nand stricter content moderation to ensure the safe deployment of GPT-based\napplications.",
      "tldr_zh": "本研究对 OpenAI 生态中的 14,904 个 custom GPTs 进行了大规模实证分析，评估了七种安全漏洞，包括 roleplay-based attacks、system prompt leakage、phishing content generation 和 malicious code synthesis。研究引入多指标排名系统，探讨了 custom GPTs 的流行度与风险之间的关系，发现超过 95% 的 custom GPTs 缺乏足够保护，最常见漏洞为 roleplay-based vulnerabilities (96.51%)、system prompt leakage (92.20%) 和 phishing (91.22%)。此外，OpenAI 的基础模型固有弱点在 custom GPTs 中被继承或放大，强调了加强安全措施和内容审核的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08148v1",
      "published_date": "2025-05-13 00:51:07 UTC",
      "updated_date": "2025-05-13 00:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:44:42.984157"
    },
    {
      "arxiv_id": "2505.08828v1",
      "title": "Human-AI Collaboration or Academic Misconduct? Measuring AI Use in Student Writing Through Stylometric Evidence",
      "title_zh": "翻译失败",
      "authors": [
        "Eduardo Araujo Oliveira",
        "Madhavi Mohoni",
        "Sonsoles López-Pernas",
        "Mohammed Saqr"
      ],
      "abstract": "As human-AI collaboration becomes increasingly prevalent in educational\ncontexts, understanding and measuring the extent and nature of such\ninteractions pose significant challenges. This research investigates the use of\nauthorship verification (AV) techniques not as a punitive measure, but as a\nmeans to quantify AI assistance in academic writing, with a focus on promoting\ntransparency, interpretability, and student development. Building on prior\nwork, we structured our investigation into three stages: dataset selection and\nexpansion, AV method development, and systematic evaluation. Using three\ndatasets - including a public dataset (PAN-14) and two from University of\nMelbourne students from various courses - we expanded the data to include\nLLM-generated texts, totalling 1,889 documents and 540 authorship problems from\n506 students. We developed an adapted Feature Vector Difference AV methodology\nto construct robust academic writing profiles for students, designed to capture\nmeaningful, individual characteristics of their writing. The method's\neffectiveness was evaluated across multiple scenarios, including distinguishing\nbetween student-authored and LLM-generated texts and testing resilience against\nLLMs' attempts to mimic student writing styles. Results demonstrate the\nenhanced AV classifier's ability to identify stylometric discrepancies and\nmeasure human-AI collaboration at word and sentence levels while providing\neducators with a transparent tool to support academic integrity investigations.\nThis work advances AV technology, offering actionable insights into the\ndynamics of academic writing in an AI-driven era.",
      "tldr_zh": "这篇论文探讨了使用 authorship verification (AV) 技术来量化 AI 在学生学术写作中的辅助程度，旨在促进透明性、解释性和学生发展，而非单纯的惩罚措施。研究者扩展了数据集（包括 PAN-14 和两个墨尔本大学学生数据集，总计 1,889 文档），并开发了 Feature Vector Difference AV 方法，以捕捉学生的个人写作特征，并评估其在区分学生写作与 LLM 生成文本方面的有效性。结果显示，该方法在词和句子级别成功识别 stylometric 差异，并能抵抗 LLM 模仿学生风格的尝试，为教育者提供可靠工具，支持学术诚信调查和人类-AI 协作的动态分析。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 10 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.08828v1",
      "published_date": "2025-05-13 00:36:36 UTC",
      "updated_date": "2025-05-13 00:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:44:54.585332"
    },
    {
      "arxiv_id": "2505.08143v1",
      "title": "Communication Styles and Reader Preferences of LLM and Human Experts in Explaining Health Information",
      "title_zh": "LLM 与人类专家在解释健康信息时的沟通风格及读者偏好",
      "authors": [
        "Jiawei Zhou",
        "Kritika Venkatachalam",
        "Minje Choi",
        "Koustuv Saha",
        "Munmun De Choudhury"
      ],
      "abstract": "With the wide adoption of large language models (LLMs) in information\nassistance, it is essential to examine their alignment with human communication\nstyles and values. We situate this study within the context of fact-checking\nhealth information, given the critical challenge of rectifying conceptions and\nbuilding trust. Recent studies have explored the potential of LLM for health\ncommunication, but style differences between LLMs and human experts and\nassociated reader perceptions remain under-explored. In this light, our study\nevaluates the communication styles of LLMs, focusing on how their explanations\ndiffer from those of humans in three core components of health communication:\ninformation, sender, and receiver. We compiled a dataset of 1498 health\nmisinformation explanations from authoritative fact-checking organizations and\ngenerated LLM responses to inaccurate health information. Drawing from health\ncommunication theory, we evaluate communication styles across three key\ndimensions of information linguistic features, sender persuasive strategies,\nand receiver value alignments. We further assessed human perceptions through a\nblinded evaluation with 99 participants. Our findings reveal that LLM-generated\narticles showed significantly lower scores in persuasive strategies, certainty\nexpressions, and alignment with social values and moral foundations. However,\nhuman evaluation demonstrated a strong preference for LLM content, with over\n60% responses favoring LLM articles for clarity, completeness, and\npersuasiveness. Our results suggest that LLMs' structured approach to\npresenting information may be more effective at engaging readers despite\nscoring lower on traditional measures of quality in fact-checking and health\ncommunication.",
      "tldr_zh": "本研究比较了大型语言模型（LLMs）和人类专家在解释健康信息时的沟通风格及其读者偏好，焦点在于事实检查健康信息的语境。研究者编译了1498条健康错误信息解释数据集，并生成LLM响应，基于健康沟通理论评估三个维度：信息语言特征、发送者说服策略和接收者价值对齐，同时通过99名参与者的盲评调查人类感知。结果显示，LLM生成的内容在说服策略、确定性表达和社会价值对齐上得分较低，但超过60%的受访者更青睐LLM文章，认为其更清晰、完整和具有说服力。该发现表明，LLMs的结构化方法可能更有效吸引读者，尽管在传统健康沟通质量评估中表现不佳。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08143v1",
      "published_date": "2025-05-13 00:32:38 UTC",
      "updated_date": "2025-05-13 00:32:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:45:05.491435"
    },
    {
      "arxiv_id": "2505.08140v2",
      "title": "Lost in Transmission: When and Why LLMs Fail to Reason Globally",
      "title_zh": "Lost in Transmission: LLMs 何时以及为什么无法进行全局推理",
      "authors": [
        "Tobias Schnabel",
        "Kiran Tomlinson",
        "Adith Swaminathan",
        "Jennifer Neville"
      ],
      "abstract": "Despite their many successes, transformer-based large language models (LLMs)\ncontinue to struggle with tasks that require complex reasoning over large parts\nof their input. We argue that these failures arise due to capacity limits on\nthe accurate flow of information within LLMs. To formalize this issue, we\nintroduce the bounded attention prefix oracle (BAPO) model, a new computational\nframework that models bandwidth constraints on attention heads, the mechanism\nfor internal communication in LLMs. We show that several important reasoning\nproblems like graph reachability require high communication bandwidth for BAPOs\nto solve; we call these problems BAPO-hard. Our experiments corroborate our\ntheoretical predictions: GPT-4o, Claude, and Gemini succeed on BAPO-easy tasks\nand fail even on relatively small BAPO-hard tasks. BAPOs also reveal another\nbenefit of chain of thought (CoT): we prove that breaking down a task using CoT\ncan turn any BAPO-hard problem into a BAPO-easy one. Our results offer\nprincipled explanations for key LLM failures and suggest directions for\narchitectures and inference methods that mitigate bandwidth limits.",
      "tldr_zh": "本文研究了大型语言模型(LLMs)在处理需要全局复杂推理的任务时失败的原因，归因于信息流动的容量限制和注意力头的带宽约束。作者引入了bounded attention prefix oracle (BAPO)模型来形式化这一问题，并证明某些推理任务（如图可达性）是BAPO-hard，需要高通信带宽，而实验显示GPT-4o、Claude和Gemini在这些任务上表现不佳。Chain of Thought (CoT)被证明能将BAPO-hard问题转化为BAPO-easy，从而提升模型性能。该工作为LLM失败提供原理解释，并建议优化架构和推理方法来缓解带宽限制。",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08140v2",
      "published_date": "2025-05-13 00:25:23 UTC",
      "updated_date": "2025-05-19 16:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:45:18.751094"
    },
    {
      "arxiv_id": "2505.08138v1",
      "title": "Mirror Mirror on the Wall, Have I Forgotten it All? A New Framework for Evaluating Machine Unlearning",
      "title_zh": "翻译失败",
      "authors": [
        "Brennon Brimhall",
        "Philip Mathew",
        "Neil Fendley",
        "Yinzhi Cao",
        "Matthew Green"
      ],
      "abstract": "Machine unlearning methods take a model trained on a dataset and a forget\nset, then attempt to produce a model as if it had only been trained on the\nexamples not in the forget set. We empirically show that an adversary is able\nto distinguish between a mirror model (a control model produced by retraining\nwithout the data to forget) and a model produced by an unlearning method across\nrepresentative unlearning methods from the literature. We build distinguishing\nalgorithms based on evaluation scores in the literature (i.e. membership\ninference scores) and Kullback-Leibler divergence.\n  We propose a strong formal definition for machine unlearning called\ncomputational unlearning. Computational unlearning is defined as the inability\nfor an adversary to distinguish between a mirror model and a model produced by\nan unlearning method. If the adversary cannot guess better than random (except\nwith negligible probability), then we say that an unlearning method achieves\ncomputational unlearning.\n  Our computational unlearning definition provides theoretical structure to\nprove unlearning feasibility results. For example, our computational unlearning\ndefinition immediately implies that there are no deterministic computational\nunlearning methods for entropic learning algorithms. We also explore the\nrelationship between differential privacy (DP)-based unlearning methods and\ncomputational unlearning, showing that DP-based approaches can satisfy\ncomputational unlearning at the cost of an extreme utility collapse. These\nresults demonstrate that current methodology in the literature fundamentally\nfalls short of achieving computational unlearning. We conclude by identifying\nseveral open questions for future work.",
      "tldr_zh": "这篇论文提出了一种新框架来评估机器遗忘（machine unlearning），通过实验证明现有方法无法有效隐藏遗忘数据，因为攻击者能利用成员推理分数（membership inference scores）和 Kullback-Leibler divergence 区分遗忘后的模型与镜像模型（retrained without forgotten data）。作者定义了计算遗忘（computational unlearning）作为强有力标准，即攻击者无法比随机猜测更准确地识别模型来源，并证明了某些熵学习算法的确定性遗忘方法不可行。研究还探讨了差分隐私（differential privacy）方法，虽然能满足计算遗忘但会显著牺牲模型效用，从而强调了当前技术的局限性和未来研究方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08138v1",
      "published_date": "2025-05-13 00:23:17 UTC",
      "updated_date": "2025-05-13 00:23:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:45:30.923927"
    },
    {
      "arxiv_id": "2505.08135v1",
      "title": "Leveraging AI for Productive and Trustworthy HPC Software: Challenges and Research Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Keita Teranishi",
        "Harshitha Menon",
        "William F. Godoy",
        "Prasanna Balaprakash",
        "David Bau",
        "Tal Ben-Nun",
        "Abhinav Bhatele",
        "Franz Franchetti",
        "Michael Franusich",
        "Todd Gamblin",
        "Giorgis Georgakoudis",
        "Tom Goldstein",
        "Arjun Guha",
        "Steven Hahn",
        "Costin Iancu",
        "Zheming Jin",
        "Terry Jones",
        "Tze Meng Low",
        "Het Mankad",
        "Narasinga Rao Miniskar",
        "Mohammad Alaul Haque Monil",
        "Daniel Nichols",
        "Konstantinos Parasyris",
        "Swaroop Pophale",
        "Pedro Valero-Lara",
        "Jeffrey S. Vetter",
        "Samuel Williams",
        "Aaron Young"
      ],
      "abstract": "We discuss the challenges and propose research directions for using AI to\nrevolutionize the development of high-performance computing (HPC) software. AI\ntechnologies, in particular large language models, have transformed every\naspect of software development. For its part, HPC software is recognized as a\nhighly specialized scientific field of its own. We discuss the challenges\nassociated with leveraging state-of-the-art AI technologies to develop such a\nunique and niche class of software and outline our research directions in the\ntwo US Department of Energy--funded projects for advancing HPC Software via AI:\nEllora and Durban.",
      "tldr_zh": "该论文讨论了利用 AI 技术（尤其是大型语言模型）来提升高性能计算 (HPC) 软件开发效率和可信性的挑战与研究方向。HPC 软件作为高度专业化的科学领域，面临着 AI 应用中的领域知识缺口、模型适应性等问题。作者概述了两个美国能源部资助的项目——Ellora 和 Durban——作为推进 AI 在 HPC 软件开发中的关键研究路径，以实现更高效和可靠的软件创新。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.DC",
        "cs.PF"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 1 Figure, Accepted at \"The 1st International Workshop on\n  Foundational Large Language Models Advances for HPC\" LLM4HPC to be held in\n  conjunction with ISC High Performance 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.08135v1",
      "published_date": "2025-05-13 00:12:45 UTC",
      "updated_date": "2025-05-13 00:12:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:45:41.408068"
    },
    {
      "arxiv_id": "2505.08133v2",
      "title": "One Bad NOFO? AI Governance in Federal Grantmaking",
      "title_zh": "翻译失败",
      "authors": [
        "Dan Bateyko",
        "Karen Levy"
      ],
      "abstract": "Much scholarship considers how U.S. federal agencies govern artificial\nintelligence (AI) through rulemaking and their own internal use policies. But\nagencies have an overlooked AI governance role: setting discretionary grant\npolicy when directing billions of dollars in federal financial assistance.\nThese dollars enable state and local entities to study, create, and use AI.\nThis funding not only goes to dedicated AI programs, but also to grantees using\nAI in the course of meeting their routine grant objectives. As discretionary\ngrantmakers, agencies guide and restrict what grant winners do -- a hidden\nlever for AI governance. Agencies pull this lever by setting program\nobjectives, judging criteria, and restrictions for AI use. Using a novel\ndataset of over 40,000 non-defense federal grant notices of funding opportunity\n(NOFOs) posted to the U.S. federal grants website between 2009 and 2024, we\nanalyze how agencies regulate the use of AI by grantees. We select records\nmentioning AI and review their stated goals and requirements. We find agencies\npromoting AI in notice narratives, shaping adoption in ways other records of\ngrant policy might fail to capture. Of the grant opportunities that mention AI,\nwe find only a handful of AI-specific judging criteria or restrictions. This\nsilence holds even when agencies fund AI uses in contexts affecting people's\nrights and which, under an analogous federal procurement regime, would result\nin extra oversight. These findings recast grant notices as a site of AI\npolicymaking -- albeit one that is developing out of step with other regulatory\nefforts and incomplete in its consideration of transparency, accountability,\nand privacy protections. The paper concludes by drawing lessons from AI\nprocurement scholarship, while identifying distinct challenges in grantmaking\nthat invite further study.",
      "tldr_zh": "这项研究探讨了美国联邦机构在AI治理中的一个被忽略角色：通过设置可自由裁量资助政策来指导数十亿美元的联邦资助资金，从而影响州和地方实体对AI的研究、创建和使用。研究者利用一个包含2009年至2024年超过40,000个非国防资助通知(NOFOs)的新数据集，分析了机构如何在这些通知中推广AI，同时审查其目标和要求。结果发现，虽然机构在通知中积极推动AI采用，但AI特定的判断标准或使用限制极少，甚至在涉及人民权利的语境中也缺乏透明性、问责性和隐私保护的考虑。论文强调，NOFOs作为AI政策制定场所的角色与联邦采购制度脱节，并从AI采购研究中汲取教训，指出资助领域的独特挑战需要进一步研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "In The 2025 ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT '25), June 23---26, 2025, Athens, Greece. 13 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.08133v2",
      "published_date": "2025-05-13 00:08:22 UTC",
      "updated_date": "2025-05-21 18:33:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:45:55.461417"
    },
    {
      "arxiv_id": "2505.08130v1",
      "title": "ALOHA: Empowering Multilingual Agent for University Orientation with Hierarchical Retrieval",
      "title_zh": "ALOHA：通过分层检索赋能多语言大学迎新代理",
      "authors": [
        "Mingxu Tao",
        "Bowen Tang",
        "Mingxuan Ma",
        "Yining Zhang",
        "Hourun Li",
        "Feifan Wen",
        "Hao Ma",
        "Jia Yang"
      ],
      "abstract": "The rise of Large Language Models~(LLMs) revolutionizes information\nretrieval, allowing users to obtain required answers through complex\ninstructions within conversations. However, publicly available services remain\ninadequate in addressing the needs of faculty and students to search\ncampus-specific information. It is primarily due to the LLM's lack of\ndomain-specific knowledge and the limitation of search engines in supporting\nmultilingual and timely scenarios. To tackle these challenges, we introduce\nALOHA, a multilingual agent enhanced by hierarchical retrieval for university\norientation. We also integrate external APIs into the front-end interface to\nprovide interactive service. The human evaluation and case study show our\nproposed system has strong capabilities to yield correct, timely, and\nuser-friendly responses to the queries in multiple languages, surpassing\ncommercial chatbots and search engines. The system has been deployed and has\nprovided service for more than 12,000 people.",
      "tldr_zh": "该研究引入了 ALOHA 系统，这是一个基于 Hierarchical Retrieval 的多语言代理，旨在解决大型语言模型 (LLMs) 在处理校园特定信息时的领域知识不足和多语言支持限制问题。ALOHA 通过分层检索机制和外部 API 的整合，提供交互式的前端服务，支持用户在对话中获取正确、及时和友好的多语言响应。人类评估和案例研究显示，ALOHA 优于商业聊天机器人和搜索引擎，已部署并为超过12,000人提供大学定向服务。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in NAACL 2025 Demo Track",
      "pdf_url": "http://arxiv.org/pdf/2505.08130v1",
      "published_date": "2025-05-13 00:01:03 UTC",
      "updated_date": "2025-05-13 00:01:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:46:05.513921"
    },
    {
      "arxiv_id": "2505.08129v1",
      "title": "High-order Regularization for Machine Learning and Learning-based Control",
      "title_zh": "高阶正则化在机器学习和基于学习控制",
      "authors": [
        "Xinghua Liu",
        "Ming Cao"
      ],
      "abstract": "The paper proposes a novel regularization procedure for machine learning. The\nproposed high-order regularization (HR) provides new insight into\nregularization, which is widely used to train a neural network that can be\nutilized to approximate the action-value function in general reinforcement\nlearning problems. The proposed HR method ensures the provable convergence of\nthe approximation algorithm, which makes the much-needed connection between\nregularization and explainable learning using neural networks. The proposed HR\nmethod theoretically demonstrates that regularization can be regarded as an\napproximation in terms of inverse mapping with explicitly calculable\napproximation error, and the $L_2$ regularization is a lower-order case of the\nproposed method. We provide lower and upper bounds for the error of the\nproposed HR solution, which helps build a reliable model. We also find that\nregularization with the proposed HR can be regarded as a contraction. We prove\nthat the generalizability of neural networks can be maximized with a proper\nregularization matrix, and the proposed HR is applicable for neural networks\nwith any mapping matrix. With the theoretical explanation of the extreme\nlearning machine for neural network training and the proposed high-order\nregularization, one can better interpret the output of the neural network, thus\nleading to explainable learning. We present a case study based on regularized\nextreme learning neural networks to demonstrate the application of the proposed\nHR and give the corresponding incremental HR solution. We verify the\nperformance of the proposed HR method by solving a classic control problem in\nreinforcement learning. The result demonstrates the superior performance of the\nmethod with significant enhancement in the generalizability of the neural\nnetwork.",
      "tldr_zh": "该论文提出了一种新颖的高阶正则化 (HR) 方法，用于机器学习和基于学习的控制系统，旨在训练神经网络以近似强化学习中的行动价值函数，并确保算法的收敛性。HR 通过理论证明，将正则化视为逆映射的近似，并提供可计算的误差上下界，同时将 $L_2$ 正则化视为其低阶特例，从而提升神经网络的可解释性和泛化能力。实验结果显示，HR 在强化学习的经典控制问题上显著提高了神经网络的性能和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.08129v1",
      "published_date": "2025-05-13 00:00:23 UTC",
      "updated_date": "2025-05-13 00:00:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T22:46:18.621809"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 135,
  "processed_papers_count": 135,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T22:46:44.682421"
}