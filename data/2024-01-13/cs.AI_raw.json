[
  {
    "arxiv_id": "2401.07159v1",
    "title": "Quantized Side Tuning: Fast and Memory-Efficient Tuning of Quantized Large Language Models",
    "authors": [
      "Zhengxin Zhang",
      "Dan Zhao",
      "Xupeng Miao",
      "Gabriele Oliaro",
      "Qing Li",
      "Yong Jiang",
      "Zhihao Jia"
    ],
    "abstract": "Finetuning large language models (LLMs) has been empirically effective on a\nvariety of downstream tasks. Existing approaches to finetuning an LLM either\nfocus on parameter-efficient finetuning, which only updates a small number of\ntrainable parameters, or attempt to reduce the memory footprint during the\ntraining phase of the finetuning. Typically, the memory footprint during\nfinetuning stems from three contributors: model weights, optimizer states, and\nintermediate activations. However, existing works still require considerable\nmemory and none can simultaneously mitigate memory footprint for all three\nsources. In this paper, we present Quantized Side Tuing (QST), which enables\nmemory-efficient and fast finetuning of LLMs by operating through a dual-stage\nprocess. First, QST quantizes an LLM's model weights into 4-bit to reduce the\nmemory footprint of the LLM's original weights; QST also introduces a side\nnetwork separated from the LLM, which utilizes the hidden states of the LLM to\nmake task-specific predictions. Using a separate side network avoids performing\nbackpropagation through the LLM, thus reducing the memory requirement of the\nintermediate activations. Furthermore, QST leverages several low-rank adaptors\nand gradient-free downsample modules to significantly reduce the trainable\nparameters, so as to save the memory footprint of the optimizer states.\nExperiments show that QST can reduce the total memory footprint by up to 2.3\n$\\times$ and speed up the finetuning process by up to 3 $\\times$ while\nachieving competent performance compared with the state-of-the-art. When it\ncomes to full finetuning, QST can reduce the total memory footprint up to 7\n$\\times$.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07159v1",
    "published_date": "2024-01-13 21:00:21 UTC",
    "updated_date": "2024-01-13 21:00:21 UTC"
  },
  {
    "arxiv_id": "2401.07145v1",
    "title": "Scalable and Efficient Methods for Uncertainty Estimation and Reduction in Deep Learning",
    "authors": [
      "Soyed Tuhin Ahmed"
    ],
    "abstract": "Neural networks (NNs) can achieved high performance in various fields such as\ncomputer vision, and natural language processing. However, deploying NNs in\nresource-constrained safety-critical systems has challenges due to uncertainty\nin the prediction caused by out-of-distribution data, and hardware\nnon-idealities. To address the challenges of deploying NNs in\nresource-constrained safety-critical systems, this paper summarizes the (4th\nyear) PhD thesis work that explores scalable and efficient methods for\nuncertainty estimation and reduction in deep learning, with a focus on\nComputation-in-Memory (CIM) using emerging resistive non-volatile memories. We\ntackle the inherent uncertainties arising from out-of-distribution inputs and\nhardware non-idealities, crucial in maintaining functional safety in automated\ndecision-making systems. Our approach encompasses problem-aware training\nalgorithms, novel NN topologies, and hardware co-design solutions, including\ndropout-based \\emph{binary} Bayesian Neural Networks leveraging spintronic\ndevices and variational inference techniques. These innovations significantly\nenhance OOD data detection, inference accuracy, and energy efficiency, thereby\ncontributing to the reliability and robustness of NN implementations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07145v1",
    "published_date": "2024-01-13 19:30:34 UTC",
    "updated_date": "2024-01-13 19:30:34 UTC"
  },
  {
    "arxiv_id": "2401.12983v1",
    "title": "Assessing Large Language Models in Mechanical Engineering Education: A Study on Mechanics-Focused Conceptual Understanding",
    "authors": [
      "Jie Tian",
      "Jixin Hou",
      "Zihao Wu",
      "Peng Shu",
      "Zhengliang Liu",
      "Yujie Xiang",
      "Beikang Gu",
      "Nicholas Filla",
      "Yiwei Li",
      "Ning Liu",
      "Xianyan Chen",
      "Keke Tang",
      "Tianming Liu",
      "Xianqiao Wang"
    ],
    "abstract": "This study is a pioneering endeavor to investigate the capabilities of Large\nLanguage Models (LLMs) in addressing conceptual questions within the domain of\nmechanical engineering with a focus on mechanics. Our examination involves a\nmanually crafted exam encompassing 126 multiple-choice questions, spanning\nvarious aspects of mechanics courses, including Fluid Mechanics, Mechanical\nVibration, Engineering Statics and Dynamics, Mechanics of Materials, Theory of\nElasticity, and Continuum Mechanics. Three LLMs, including ChatGPT (GPT-3.5),\nChatGPT (GPT-4), and Claude (Claude-2.1), were subjected to evaluation against\nengineering faculties and students with or without mechanical engineering\nbackground. The findings reveal GPT-4's superior performance over the other two\nLLMs and human cohorts in answering questions across various mechanics topics,\nexcept for Continuum Mechanics. This signals the potential future improvements\nfor GPT models in handling symbolic calculations and tensor analyses. The\nperformances of LLMs were all significantly improved with explanations prompted\nprior to direct responses, underscoring the crucial role of prompt engineering.\nInterestingly, GPT-3.5 demonstrates improved performance with prompts covering\na broader domain, while GPT-4 excels with prompts focusing on specific\nsubjects. Finally, GPT-4 exhibits notable advancements in mitigating input\nbias, as evidenced by guessing preferences for humans. This study unveils the\nsubstantial potential of LLMs as highly knowledgeable assistants in both\nmechanical pedagogy and scientific research.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "physics.ed-ph"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 7 figures, and 1 table",
    "pdf_url": "http://arxiv.org/pdf/2401.12983v1",
    "published_date": "2024-01-13 19:19:04 UTC",
    "updated_date": "2024-01-13 19:19:04 UTC"
  },
  {
    "arxiv_id": "2401.10917v1",
    "title": "Artificial intelligence to automate the systematic review of scientific literature",
    "authors": [
      "José de la Torre-López",
      "Aurora Ramírez",
      "José Raúl Romero"
    ],
    "abstract": "Artificial intelligence (AI) has acquired notorious relevance in modern\ncomputing as it effectively solves complex tasks traditionally done by humans.\nAI provides methods to represent and infer knowledge, efficiently manipulate\ntexts and learn from vast amount of data. These characteristics are applicable\nin many activities that human find laborious or repetitive, as is the case of\nthe analysis of scientific literature. Manually preparing and writing a\nsystematic literature review (SLR) takes considerable time and effort, since it\nrequires planning a strategy, conducting the literature search and analysis,\nand reporting the findings. Depending on the area under study, the number of\npapers retrieved can be of hundreds or thousands, meaning that filtering those\nrelevant ones and extracting the key information becomes a costly and\nerror-prone process. However, some of the involved tasks are repetitive and,\ntherefore, subject to automation by means of AI. In this paper, we present a\nsurvey of AI techniques proposed in the last 15 years to help researchers\nconduct systematic analyses of scientific literature. We describe the tasks\ncurrently supported, the types of algorithms applied, and available tools\nproposed in 34 primary studies. This survey also provides a historical\nperspective of the evolution of the field and the role that humans can play in\nan increasingly automated SLR process.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "68T01",
      "I.2.m; A.1"
    ],
    "primary_category": "cs.IR",
    "comment": "25 pages, 3 figures, 1 table, journal paper",
    "pdf_url": "http://arxiv.org/pdf/2401.10917v1",
    "published_date": "2024-01-13 19:12:49 UTC",
    "updated_date": "2024-01-13 19:12:49 UTC"
  },
  {
    "arxiv_id": "2401.07139v1",
    "title": "Deep Blind Super-Resolution for Satellite Video",
    "authors": [
      "Yi Xiao",
      "Qiangqiang Yuan",
      "Qiang Zhang",
      "Liangpei Zhang"
    ],
    "abstract": "Recent efforts have witnessed remarkable progress in Satellite Video\nSuper-Resolution (SVSR). However, most SVSR methods usually assume the\ndegradation is fixed and known, e.g., bicubic downsampling, which makes them\nvulnerable in real-world scenes with multiple and unknown degradations. To\nalleviate this issue, blind SR has thus become a research hotspot.\nNevertheless, existing approaches are mainly engaged in blur kernel estimation\nwhile losing sight of another critical aspect for VSR tasks: temporal\ncompensation, especially compensating for blurry and smooth pixels with vital\nsharpness from severely degraded satellite videos. Therefore, this paper\nproposes a practical Blind SVSR algorithm (BSVSR) to explore more sharp cues by\nconsidering the pixel-wise blur levels in a coarse-to-fine manner.\nSpecifically, we employed multi-scale deformable convolution to coarsely\naggregate the temporal redundancy into adjacent frames by window-slid\nprogressive fusion. Then the adjacent features are finely merged into\nmid-feature using deformable attention, which measures the blur levels of\npixels and assigns more weights to the informative pixels, thus inspiring the\nrepresentation of sharpness. Moreover, we devise a pyramid spatial\ntransformation module to adjust the solution space of sharp mid-feature,\nresulting in flexible feature adaptation in multi-level domains. Quantitative\nand qualitative evaluations on both simulated and real-world satellite videos\ndemonstrate that our BSVSR performs favorably against state-of-the-art\nnon-blind and blind SR models. Code will be available at\nhttps://github.com/XY-boy/Blind-Satellite-VSR",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "Published in IEEE TGRS",
    "pdf_url": "http://arxiv.org/pdf/2401.07139v1",
    "published_date": "2024-01-13 18:56:18 UTC",
    "updated_date": "2024-01-13 18:56:18 UTC"
  },
  {
    "arxiv_id": "2401.07128v3",
    "title": "EHRAgent: Code Empowers Large Language Models for Few-shot Complex Tabular Reasoning on Electronic Health Records",
    "authors": [
      "Wenqi Shi",
      "Ran Xu",
      "Yuchen Zhuang",
      "Yue Yu",
      "Jieyu Zhang",
      "Hang Wu",
      "Yuanda Zhu",
      "Joyce Ho",
      "Carl Yang",
      "May D. Wang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated exceptional capabilities in\nplanning and tool utilization as autonomous agents, but few have been developed\nfor medical problem-solving. We propose EHRAgent, an LLM agent empowered with a\ncode interface, to autonomously generate and execute code for multi-tabular\nreasoning within electronic health records (EHRs). First, we formulate an EHR\nquestion-answering task into a tool-use planning process, efficiently\ndecomposing a complicated task into a sequence of manageable actions. By\nintegrating interactive coding and execution feedback, EHRAgent learns from\nerror messages and improves the originally generated code through iterations.\nFurthermore, we enhance the LLM agent by incorporating long-term memory, which\nallows EHRAgent to effectively select and build upon the most relevant\nsuccessful cases from past experiences. Experiments on three real-world\nmulti-tabular EHR datasets show that EHRAgent outperforms the strongest\nbaseline by up to 29.6% in success rate. EHRAgent leverages the emerging\nfew-shot learning capabilities of LLMs, enabling autonomous code generation and\nexecution to tackle complex clinical tasks with minimal demonstrations.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in EMNLP 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2401.07128v3",
    "published_date": "2024-01-13 18:09:05 UTC",
    "updated_date": "2024-10-04 05:56:56 UTC"
  },
  {
    "arxiv_id": "2401.07118v1",
    "title": "Exploring of Discrete and Continuous Input Control for AI-enhanced Assistive Robotic Arms",
    "authors": [
      "Max Pascher",
      "Kevin Zinta",
      "Jens Gerken"
    ],
    "abstract": "Robotic arms, integral in domestic care for individuals with motor\nimpairments, enable them to perform Activities of Daily Living (ADLs)\nindependently, reducing dependence on human caregivers. These collaborative\nrobots require users to manage multiple Degrees-of-Freedom (DoFs) for tasks\nlike grasping and manipulating objects. Conventional input devices, typically\nlimited to two DoFs, necessitate frequent and complex mode switches to control\nindividual DoFs. Modern adaptive controls with feed-forward multi-modal\nfeedback reduce the overall task completion time, number of mode switches, and\ncognitive load. Despite the variety of input devices available, their\neffectiveness in adaptive settings with assistive robotics has yet to be\nthoroughly assessed. This study explores three different input devices by\nintegrating them into an established XR framework for assistive robotics,\nevaluating them and providing empirical insights through a preliminary study\nfor future developments.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "Companion of the 2024 ACM/IEEE International Conference on\n  Human-Robot Interaction",
    "pdf_url": "http://arxiv.org/pdf/2401.07118v1",
    "published_date": "2024-01-13 16:57:40 UTC",
    "updated_date": "2024-01-13 16:57:40 UTC"
  },
  {
    "arxiv_id": "2401.07115v3",
    "title": "Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Models",
    "authors": [
      "Lucio La Cava",
      "Andrea Tagarelli"
    ],
    "abstract": "The emergence of unveiling human-like behaviors in Large Language Models\n(LLMs) has led to a closer connection between NLP and human psychology.\nScholars have been studying the inherent personalities exhibited by LLMs and\nattempting to incorporate human traits and behaviors into them. However, these\nefforts have primarily focused on commercially-licensed LLMs, neglecting the\nwidespread use and notable advancements seen in Open LLMs. This work aims to\naddress this gap by employing a set of 12 LLM Agents based on the most\nrepresentative Open models and subject them to a series of assessments\nconcerning the Myers-Briggs Type Indicator (MBTI) test and the Big Five\nInventory (BFI) test. Our approach involves evaluating the intrinsic\npersonality traits of Open LLM agents and determining the extent to which these\nagents can mimic human personalities when conditioned by specific personalities\nand roles. Our findings unveil that $(i)$ each Open LLM agent showcases\ndistinct human personalities; $(ii)$ personality-conditioned prompting produces\nvarying effects on the agents, with only few successfully mirroring the imposed\npersonality, while most of them being ``closed-minded'' (i.e., they retain\ntheir intrinsic traits); and $(iii)$ combining role and personality\nconditioning can enhance the agents' ability to mimic human personalities. Our\nwork represents a step up in understanding the dense relationship between NLP\nand human psychology through the lens of Open LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC",
      "physics.soc-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted and presented at the AAAI 2025 Conference. CHANGES in\n  version v2: (i) Enhanced methodology and evaluation based on BFI in addition\n  to MBTI, with expanded set of LLM agents; (ii) author list changed w.r.t.\n  version (v1), see Acknowledgements",
    "pdf_url": "http://arxiv.org/pdf/2401.07115v3",
    "published_date": "2024-01-13 16:41:40 UTC",
    "updated_date": "2025-03-22 22:45:12 UTC"
  },
  {
    "arxiv_id": "2401.08694v2",
    "title": "Combining Confidence Elicitation and Sample-based Methods for Uncertainty Quantification in Misinformation Mitigation",
    "authors": [
      "Mauricio Rivera",
      "Jean-François Godbout",
      "Reihaneh Rabbany",
      "Kellin Pelrine"
    ],
    "abstract": "Large Language Models have emerged as prime candidates to tackle\nmisinformation mitigation. However, existing approaches struggle with\nhallucinations and overconfident predictions. We propose an uncertainty\nquantification framework that leverages both direct confidence elicitation and\nsampled-based consistency methods to provide better calibration for NLP\nmisinformation mitigation solutions. We first investigate the calibration of\nsample-based consistency methods that exploit distinct features of consistency\nacross sample sizes and stochastic levels. Next, we evaluate the performance\nand distributional shift of a robust numeric verbalization prompt across single\nvs. two-step confidence elicitation procedure. We also compare the performance\nof the same prompt with different versions of GPT and different numerical\nscales. Finally, we combine the sample-based consistency and verbalized methods\nto propose a hybrid framework that yields a better uncertainty estimation for\nGPT models. Overall, our work proposes novel uncertainty quantification methods\nthat will improve the reliability of Large Language Models in misinformation\nmitigation applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.08694v2",
    "published_date": "2024-01-13 16:36:58 UTC",
    "updated_date": "2024-01-30 21:59:08 UTC"
  },
  {
    "arxiv_id": "2401.07105v3",
    "title": "Graph Language Models",
    "authors": [
      "Moritz Plenz",
      "Anette Frank"
    ],
    "abstract": "While Language Models (LMs) are the workhorses of NLP, their interplay with\nstructured knowledge graphs (KGs) is still actively researched. Current methods\nfor encoding such graphs typically either (i) linearize them for embedding with\nLMs -- which underutilize structural information, or (ii) use Graph Neural\nNetworks (GNNs) to preserve the graph structure -- but GNNs cannot represent\ntext features as well as pretrained LMs. In our work we introduce a novel LM\ntype, the Graph Language Model (GLM), that integrates the strengths of both\napproaches and mitigates their weaknesses. The GLM parameters are initialized\nfrom a pretrained LM to enhance understanding of individual graph concepts and\ntriplets. Simultaneously, we design the GLM's architecture to incorporate graph\nbiases, thereby promoting effective knowledge distribution within the graph.\nThis enables GLMs to process graphs, texts, and interleaved inputs of both.\nEmpirical evaluations on relation classification tasks show that GLM embeddings\nsurpass both LM- and GNN-based baselines in supervised and zero-shot setting,\ndemonstrating their versatility.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "I.2.0; I.2.4; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ACL 2024. 9 pages, 10 figures, 9 tables",
    "pdf_url": "http://arxiv.org/pdf/2401.07105v3",
    "published_date": "2024-01-13 16:09:49 UTC",
    "updated_date": "2024-06-03 12:14:34 UTC"
  },
  {
    "arxiv_id": "2401.07102v1",
    "title": "Evolving Code with A Large Language Model",
    "authors": [
      "Erik Hemberg",
      "Stephen Moskal",
      "Una-May O'Reilly"
    ],
    "abstract": "Algorithms that use Large Language Models (LLMs) to evolve code arrived on\nthe Genetic Programming (GP) scene very recently. We present LLM GP, a\nformalized LLM-based evolutionary algorithm designed to evolve code. Like GP,\nit uses evolutionary operators, but its designs and implementations of those\noperators radically differ from GP's because they enlist an LLM, using\nprompting and the LLM's pre-trained pattern matching and sequence completion\ncapability. We also present a demonstration-level variant of LLM GP and share\nits code. By addressing algorithms that range from the formal to hands-on, we\ncover design and LLM-usage considerations as well as the scientific challenges\nthat arise when using an LLM for genetic programming.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "I.2.8"
    ],
    "primary_category": "cs.NE",
    "comment": "34 pages, 9 figures, 6 Tables",
    "pdf_url": "http://arxiv.org/pdf/2401.07102v1",
    "published_date": "2024-01-13 15:57:54 UTC",
    "updated_date": "2024-01-13 15:57:54 UTC"
  },
  {
    "arxiv_id": "2401.07085v3",
    "title": "Three Mechanisms of Feature Learning in a Linear Network",
    "authors": [
      "Yizhou Xu",
      "Liu Ziyin"
    ],
    "abstract": "Understanding the dynamics of neural networks in different width regimes is\ncrucial for improving their training and performance. We present an exact\nsolution for the learning dynamics of a one-hidden-layer linear network, with\none-dimensional data, across any finite width, uniquely exhibiting both kernel\nand feature learning phases. This study marks a technical advancement by\nenabling the analysis of the training trajectory from any initialization and a\ndetailed phase diagram under varying common hyperparameters such as width,\nlayer-wise learning rates, and scales of output and initialization. We identify\nthree novel prototype mechanisms specific to the feature learning regime: (1)\nlearning by alignment, (2) learning by disalignment, and (3) learning by\nrescaling, which contrast starkly with the dynamics observed in the kernel\nregime. Our theoretical findings are substantiated with empirical evidence\nshowing that these mechanisms also manifest in deep nonlinear networks handling\nreal-world tasks, enhancing our understanding of neural network training\ndynamics and guiding the design of more effective learning strategies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07085v3",
    "published_date": "2024-01-13 14:21:46 UTC",
    "updated_date": "2025-02-21 11:50:09 UTC"
  },
  {
    "arxiv_id": "2401.07072v1",
    "title": "InterEvo-TR: Interactive Evolutionary Test Generation With Readability Assessment",
    "authors": [
      "Pedro Delgado-Pérez",
      "Aurora Ramírez",
      "Kevin J. Valle-Gómez",
      "Inmaculada Medina-Bulo",
      "José Raúl Romero"
    ],
    "abstract": "Automated test case generation has proven to be useful to reduce the usually\nhigh expenses of software testing. However, several studies have also noted the\nskepticism of testers regarding the comprehension of generated test suites when\ncompared to manually designed ones. This fact suggests that involving testers\nin the test generation process could be helpful to increase their acceptance of\nautomatically-produced test suites. In this paper, we propose incorporating\ninteractive readability assessments made by a tester into EvoSuite, a\nwidely-known evolutionary test generation tool. Our approach, InterEvo-TR,\ninteracts with the tester at different moments during the search and shows\ndifferent test cases covering the same coverage target for their subjective\nevaluation. The design of such an interactive approach involves a schedule of\ninteraction, a method to diversify the selected targets, a plan to save and\nhandle the readability values, and some mechanisms to customize the level of\nengagement in the revision, among other aspects. To analyze the potential and\npracticability of our proposal, we conduct a controlled experiment in which 39\nparticipants, including academics, professional developers, and student\ncollaborators, interact with InterEvo-TR. Our results show that the strategy to\nselect and present intermediate results is effective for the purpose of\nreadability assessment. Furthermore, the participants' actions and responses to\na questionnaire allowed us to analyze the aspects influencing test code\nreadability and the benefits and limitations of an interactive approach in the\ncontext of test case generation, paving the way for future developments based\non interactivity.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "68T20",
      "D.2.5; I.2.8"
    ],
    "primary_category": "cs.SE",
    "comment": "17 pages, 10 figures, 5 tables, journal paper",
    "pdf_url": "http://arxiv.org/pdf/2401.07072v1",
    "published_date": "2024-01-13 13:14:29 UTC",
    "updated_date": "2024-01-13 13:14:29 UTC"
  },
  {
    "arxiv_id": "2401.07065v1",
    "title": "Tensor Graph Convolutional Network for Dynamic Graph Representation Learning",
    "authors": [
      "Ling Wang",
      "Ye Yuan"
    ],
    "abstract": "Dynamic graphs (DG) describe dynamic interactions between entities in many\npractical scenarios. Most existing DG representation learning models combine\ngraph convolutional network and sequence neural network, which model\nspatial-temporal dependencies through two different types of neural networks.\nHowever, this hybrid design cannot well capture the spatial-temporal continuity\nof a DG. In this paper, we propose a tensor graph convolutional network to\nlearn DG representations in one convolution framework based on the tensor\nproduct with the following two-fold ideas: a) representing the information of\nDG by tensor form; b) adopting tensor product to design a tensor graph\nconvolutional network modeling spatial-temporal feature simultaneously.\nExperiments on real-world DG datasets demonstrate that our model obtains\nstate-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07065v1",
    "published_date": "2024-01-13 12:49:56 UTC",
    "updated_date": "2024-01-13 12:49:56 UTC"
  },
  {
    "arxiv_id": "2401.07062v1",
    "title": "Dirichlet-Based Prediction Calibration for Learning with Noisy Labels",
    "authors": [
      "Chen-Chen Zong",
      "Ye-Wen Wang",
      "Ming-Kun Xie",
      "Sheng-Jun Huang"
    ],
    "abstract": "Learning with noisy labels can significantly hinder the generalization\nperformance of deep neural networks (DNNs). Existing approaches address this\nissue through loss correction or example selection methods. However, these\nmethods often rely on the model's predictions obtained from the softmax\nfunction, which can be over-confident and unreliable. In this study, we\nidentify the translation invariance of the softmax function as the underlying\ncause of this problem and propose the \\textit{Dirichlet-based Prediction\nCalibration} (DPC) method as a solution. Our method introduces a calibrated\nsoftmax function that breaks the translation invariance by incorporating a\nsuitable constant in the exponent term, enabling more reliable model\npredictions. To ensure stable model training, we leverage a Dirichlet\ndistribution to assign probabilities to predicted labels and introduce a novel\nevidence deep learning (EDL) loss. The proposed loss function encourages\npositive and sufficiently large logits for the given label, while penalizing\nnegative and small logits for other labels, leading to more distinct logits and\nfacilitating better example selection based on a large-margin criterion.\nThrough extensive experiments on diverse benchmark datasets, we demonstrate\nthat DPC achieves state-of-the-art performance. The code is available at\nhttps://github.com/chenchenzong/DPC.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07062v1",
    "published_date": "2024-01-13 12:33:04 UTC",
    "updated_date": "2024-01-13 12:33:04 UTC"
  },
  {
    "arxiv_id": "2401.07058v1",
    "title": "Does More Advice Help? The Effects of Second Opinions in AI-Assisted Decision Making",
    "authors": [
      "Zhuoran Lu",
      "Dakuo Wang",
      "Ming Yin"
    ],
    "abstract": "AI assistance in decision-making has become popular, yet people's\ninappropriate reliance on AI often leads to unsatisfactory human-AI\ncollaboration performance. In this paper, through three pre-registered,\nrandomized human subject experiments, we explore whether and how the provision\nof {second opinions} may affect decision-makers' behavior and performance in\nAI-assisted decision-making. We find that if both the AI model's decision\nrecommendation and a second opinion are always presented together,\ndecision-makers reduce their over-reliance on AI while increase their\nunder-reliance on AI, regardless whether the second opinion is generated by a\npeer or another AI model. However, if decision-makers have the control to\ndecide when to solicit a peer's second opinion, we find that their active\nsolicitations of second opinions have the potential to mitigate over-reliance\non AI without inducing increased under-reliance in some cases. We conclude by\ndiscussing the implications of our findings for promoting effective human-AI\ncollaborations in decision-making.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07058v1",
    "published_date": "2024-01-13 12:19:01 UTC",
    "updated_date": "2024-01-13 12:19:01 UTC"
  },
  {
    "arxiv_id": "2401.07056v1",
    "title": "Aquarium: A Comprehensive Framework for Exploring Predator-Prey Dynamics through Multi-Agent Reinforcement Learning Algorithms",
    "authors": [
      "Michael Kölle",
      "Yannick Erpelding",
      "Fabian Ritz",
      "Thomy Phan",
      "Steffen Illium",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "Recent advances in Multi-Agent Reinforcement Learning have prompted the\nmodeling of intricate interactions between agents in simulated environments. In\nparticular, the predator-prey dynamics have captured substantial interest and\nvarious simulations been tailored to unique requirements. To prevent further\ntime-intensive developments, we introduce Aquarium, a comprehensive Multi-Agent\nReinforcement Learning environment for predator-prey interaction, enabling the\nstudy of emergent behavior. Aquarium is open source and offers a seamless\nintegration of the PettingZoo framework, allowing a quick start with proven\nalgorithm implementations. It features physics-based agent movement on a\ntwo-dimensional, edge-wrapping plane. The agent-environment interaction\n(observations, actions, rewards) and the environment settings (agent speed,\nprey reproduction, predator starvation, and others) are fully customizable.\nBesides a resource-efficient visualization, Aquarium supports to record video\nfiles, providing a visual comprehension of agent behavior. To demonstrate the\nenvironment's capabilities, we conduct preliminary studies which use PPO to\ntrain multiple prey agents to evade a predator. In accordance to the\nliterature, we find Individual Learning to result in worse performance than\nParameter Sharing, which significantly improves coordination and\nsample-efficiency.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICAART",
    "pdf_url": "http://arxiv.org/pdf/2401.07056v1",
    "published_date": "2024-01-13 12:09:49 UTC",
    "updated_date": "2024-01-13 12:09:49 UTC"
  },
  {
    "arxiv_id": "2401.07054v1",
    "title": "A Reinforcement Learning Environment for Directed Quantum Circuit Synthesis",
    "authors": [
      "Michael Kölle",
      "Tom Schubert",
      "Philipp Altmann",
      "Maximilian Zorn",
      "Jonas Stein",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "With recent advancements in quantum computing technology, optimizing quantum\ncircuits and ensuring reliable quantum state preparation have become\nincreasingly vital. Traditional methods often demand extensive expertise and\nmanual calculations, posing challenges as quantum circuits grow in qubit- and\ngate-count. Therefore, harnessing machine learning techniques to handle the\ngrowing variety of gate-to-qubit combinations is a promising approach. In this\nwork, we introduce a comprehensive reinforcement learning environment for\nquantum circuit synthesis, where circuits are constructed utilizing gates from\nthe the Clifford+T gate set to prepare specific target states. Our experiments\nfocus on exploring the relationship between the depth of synthesized quantum\ncircuits and the circuit depths used for target initialization, as well as\nqubit count. We organize the environment configurations into multiple\nevaluation levels and include a range of well-known quantum states for\nbenchmarking purposes. We also lay baselines for evaluating the environment\nusing Proximal Policy Optimization. By applying the trained agents to benchmark\ntests, we demonstrated their ability to reliably design minimal quantum\ncircuits for a selection of 2-qubit Bell states.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07054v1",
    "published_date": "2024-01-13 11:55:54 UTC",
    "updated_date": "2024-01-13 11:55:54 UTC"
  },
  {
    "arxiv_id": "2401.07051v1",
    "title": "COIN: Chance-Constrained Imitation Learning for Uncertainty-aware Adaptive Resource Oversubscription Policy",
    "authors": [
      "Lu Wang",
      "Mayukh Das",
      "Fangkai Yang",
      "Chao Duo",
      "Bo Qiao",
      "Hang Dong",
      "Si Qin",
      "Chetan Bansal",
      "Qingwei Lin",
      "Saravan Rajmohan",
      "Dongmei Zhang",
      "Qi Zhang"
    ],
    "abstract": "We address the challenge of learning safe and robust decision policies in\npresence of uncertainty in context of the real scientific problem of adaptive\nresource oversubscription to enhance resource efficiency while ensuring safety\nagainst resource congestion risk.\n  Traditional supervised prediction or forecasting models are ineffective in\nlearning adaptive policies whereas standard online optimization or\nreinforcement learning is difficult to deploy on real systems. Offline methods\nsuch as imitation learning (IL) are ideal since we can directly leverage\nhistorical resource usage telemetry. But, the underlying aleatoric uncertainty\nin such telemetry is a critical bottleneck.\n  We solve this with our proposed novel chance-constrained imitation learning\nframework, which ensures implicit safety against uncertainty in a principled\nmanner via a combination of stochastic (chance) constraints on resource\ncongestion risk and ensemble value functions. This leads to substantial\n($\\approx 3-4\\times$) improvement in resource efficiency and safety in many\noversubscription scenarios, including resource management in cloud services.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2401.07051v1",
    "published_date": "2024-01-13 11:43:25 UTC",
    "updated_date": "2024-01-13 11:43:25 UTC"
  },
  {
    "arxiv_id": "2401.07043v1",
    "title": "Quantum Advantage Actor-Critic for Reinforcement Learning",
    "authors": [
      "Michael Kölle",
      "Mohamad Hgog",
      "Fabian Ritz",
      "Philipp Altmann",
      "Maximilian Zorn",
      "Jonas Stein",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "Quantum computing offers efficient encapsulation of high-dimensional states.\nIn this work, we propose a novel quantum reinforcement learning approach that\ncombines the Advantage Actor-Critic algorithm with variational quantum circuits\nby substituting parts of the classical components. This approach addresses\nreinforcement learning's scalability concerns while maintaining high\nperformance. We empirically test multiple quantum Advantage Actor-Critic\nconfigurations with the well known Cart Pole environment to evaluate our\napproach in control tasks with continuous state spaces. Our results indicate\nthat the hybrid strategy of using either a quantum actor or quantum critic with\nclassical post-processing yields a substantial performance increase compared to\npure classical and pure quantum variants with similar parameter counts. They\nfurther reveal the limits of current quantum approaches due to the hardware\nconstraints of noisy intermediate-scale quantum computers, suggesting further\nresearch to scale hybrid approaches for larger and more complex control tasks.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted at ICAART 24",
    "pdf_url": "http://arxiv.org/pdf/2401.07043v1",
    "published_date": "2024-01-13 11:08:45 UTC",
    "updated_date": "2024-01-13 11:08:45 UTC"
  },
  {
    "arxiv_id": "2401.07042v1",
    "title": "GEML: A Grammar-based Evolutionary Machine Learning Approach for Design-Pattern Detection",
    "authors": [
      "Rafael Barbudo",
      "Aurora Ramírez",
      "Francisco Servant",
      "José Raúl Romero"
    ],
    "abstract": "Design patterns (DPs) are recognised as a good practice in software\ndevelopment. However, the lack of appropriate documentation often hampers\ntraceability, and their benefits are blurred among thousands of lines of code.\nAutomatic methods for DP detection have become relevant but are usually based\non the rigid analysis of either software metrics or specific properties of the\nsource code. We propose GEML, a novel detection approach based on evolutionary\nmachine learning using software properties of diverse nature. Firstly, GEML\nmakes use of an evolutionary algorithm to extract those characteristics that\nbetter describe the DP, formulated in terms of human-readable rules, whose\nsyntax is conformant with a context-free grammar. Secondly, a rule-based\nclassifier is built to predict whether new code contains a hidden DP\nimplementation. GEML has been validated over five DPs taken from a public\nrepository recurrently adopted by machine learning studies. Then, we increase\nthis number up to 15 diverse DPs, showing its effectiveness and robustness in\nterms of detection capability. An initial parameter study served to tune a\nparameter setup whose performance guarantees the general applicability of this\napproach without the need to adjust complex parameters to a specific pattern.\nFinally, a demonstration tool is also provided.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "68W50",
      "D.2.7; I.2.8"
    ],
    "primary_category": "cs.SE",
    "comment": "27 pages, 18 tables, 10 figures, journal paper",
    "pdf_url": "http://arxiv.org/pdf/2401.07042v1",
    "published_date": "2024-01-13 11:05:24 UTC",
    "updated_date": "2024-01-13 11:05:24 UTC"
  },
  {
    "arxiv_id": "2401.07037v1",
    "title": "xCoT: Cross-lingual Instruction Tuning for Cross-lingual Chain-of-Thought Reasoning",
    "authors": [
      "Linzheng Chai",
      "Jian Yang",
      "Tao Sun",
      "Hongcheng Guo",
      "Jiaheng Liu",
      "Bing Wang",
      "Xiannian Liang",
      "Jiaqi Bai",
      "Tongliang Li",
      "Qiyao Peng",
      "Zhoujun Li"
    ],
    "abstract": "Chain-of-thought (CoT) has emerged as a powerful technique to elicit\nreasoning in large language models and improve a variety of downstream tasks.\nCoT mainly demonstrates excellent performance in English, but its usage in\nlow-resource languages is constrained due to poor language generalization. To\nbridge the gap among different languages, we propose a cross-lingual\ninstruction fine-tuning framework (xCOT) to transfer knowledge from\nhigh-resource languages to low-resource languages. Specifically, the\nmultilingual instruction training data (xCOT-INSTRUCT) is created to encourage\nthe semantic alignment of multiple languages. We introduce cross-lingual\nin-context few-shot learning (xICL)) to accelerate multilingual agreement in\ninstruction tuning, where some fragments of source languages in examples are\nrandomly substituted by their counterpart translations of target languages.\nDuring multilingual instruction tuning, we adopt the randomly online CoT\nstrategy to enhance the multilingual reasoning ability of the large language\nmodel by first translating the query to another language and then answering in\nEnglish. To further facilitate the language transfer, we leverage the\nhigh-resource CoT to supervise the training of low-resource languages with\ncross-lingual distillation. Experimental results on previous benchmarks\ndemonstrate the superior performance of xCoT in reducing the gap among\ndifferent languages, highlighting its potential to reduce the cross-lingual\ngap.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.07037v1",
    "published_date": "2024-01-13 10:53:53 UTC",
    "updated_date": "2024-01-13 10:53:53 UTC"
  },
  {
    "arxiv_id": "2401.07031v2",
    "title": "Code Security Vulnerability Repair Using Reinforcement Learning with Large Language Models",
    "authors": [
      "Nafis Tanveer Islam",
      "Mohammad Bahrami Karkevandi",
      "Peyman Najafirad"
    ],
    "abstract": "With the recent advancement of Large Language Models (LLMs), generating\nfunctionally correct code has become less complicated for a wide array of\ndevelopers. While using LLMs has sped up the functional development process, it\nposes a heavy risk to code security. Code generation with proper security\nmeasures using LLM is a significantly more challenging task than functional\ncode generation. Security measures may include adding a pair of lines of code\nwith the original code, consisting of null pointer checking or prepared\nstatements for SQL injection prevention. Currently, available code repair LLMs\ngenerate code repair by supervised fine-tuning, where the model looks at\ncross-entropy loss. However, the original and repaired codes are mostly similar\nin functionality and syntactically, except for a few (1-2) lines, which act as\nsecurity measures. This imbalance between the lines needed for security\nmeasures and the functional code enforces the supervised fine-tuned model to\nprioritize generating functional code without adding proper security measures,\nwhich also benefits the model by resulting in minimal loss. Therefore, in this\nwork, for security hardening and strengthening of generated code from LLMs, we\npropose a reinforcement learning-based method for program-specific repair with\nthe combination of semantic and syntactic reward mechanisms that focus heavily\non adding security and functional measures in the code, respectively.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.07031v2",
    "published_date": "2024-01-13 10:19:26 UTC",
    "updated_date": "2024-01-30 20:50:56 UTC"
  },
  {
    "arxiv_id": "2401.07022v1",
    "title": "Edge-Enabled Anomaly Detection and Information Completion for Social Network Knowledge Graphs",
    "authors": [
      "Fan Lu",
      "Quan Qi",
      "Huaibin Qin"
    ],
    "abstract": "In the rapidly advancing information era, various human behaviors are being\nprecisely recorded in the form of data, including identity information,\ncriminal records, and communication data. Law enforcement agencies can\neffectively maintain social security and precisely combat criminal activities\nby analyzing the aforementioned data. In comparison to traditional data\nanalysis methods, deep learning models, relying on the robust computational\npower in cloud centers, exhibit higher accuracy in extracting data features and\ninferring data. However, within the architecture of cloud centers, the\ntransmission of data from end devices introduces significant latency, hindering\nreal-time inference of data. Furthermore, low-latency edge computing\narchitectures face limitations in direct deployment due to relatively weak\ncomputing and storage capacities of nodes. To address these challenges, a\nlightweight distributed knowledge graph completion architecture is proposed.\nFirstly, we introduce a lightweight distributed knowledge graph completion\narchitecture that utilizes knowledge graph embedding for data analysis.\nSubsequently, to filter out substandard data, a personnel data quality\nassessment method named PDQA is proposed. Lastly, we present a model pruning\nalgorithm that significantly reduces the model size while maximizing\nperformance, enabling lightweight deployment. In experiments, we compare the\neffects of 11 advanced models on completing the knowledge graph of public\nsecurity personnel information. The results indicate that the RotatE model\noutperforms other models significantly in knowledge graph completion, with the\npruned model size reduced by 70\\%, and hits@10 reaching 86.97\\%.}",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 6 figures, Has been accepted by Wireless Network",
    "pdf_url": "http://arxiv.org/pdf/2401.07022v1",
    "published_date": "2024-01-13 09:27:37 UTC",
    "updated_date": "2024-01-13 09:27:37 UTC"
  },
  {
    "arxiv_id": "2401.07014v1",
    "title": "Weak Labeling for Cropland Mapping in Africa",
    "authors": [
      "Gilles Quentin Hacheme",
      "Akram Zaytar",
      "Girmaw Abebe Tadesse",
      "Caleb Robinson",
      "Rahul Dodhia",
      "Juan M. Lavista Ferres",
      "Stephen Wood"
    ],
    "abstract": "Cropland mapping can play a vital role in addressing environmental,\nagricultural, and food security challenges. However, in the context of Africa,\npractical applications are often hindered by the limited availability of\nhigh-resolution cropland maps. Such maps typically require extensive human\nlabeling, thereby creating a scalability bottleneck. To address this, we\npropose an approach that utilizes unsupervised object clustering to refine\nexisting weak labels, such as those obtained from global cropland maps. The\nrefined labels, in conjunction with sparse human annotations, serve as training\ndata for a semantic segmentation network designed to identify cropland areas.\nWe conduct experiments to demonstrate the benefits of the improved weak labels\ngenerated by our method. In a scenario where we train our model with only 33\nhuman-annotated labels, the F_1 score for the cropland category increases from\n0.53 to 0.84 when we add the mined negative labels.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2401.07014v1",
    "published_date": "2024-01-13 08:45:41 UTC",
    "updated_date": "2024-01-13 08:45:41 UTC"
  },
  {
    "arxiv_id": "2401.07009v1",
    "title": "Joint Extraction of Uyghur Medicine Knowledge with Edge Computing",
    "authors": [
      "Fan Lu",
      "Quan Qi",
      "Huaibin Qin"
    ],
    "abstract": "Medical knowledge extraction methods based on edge computing deploy deep\nlearning models on edge devices to achieve localized entity and relation\nextraction. This approach avoids transferring substantial sensitive data to\ncloud data centers, effectively safeguarding the privacy of healthcare\nservices. However, existing relation extraction methods mainly employ a\nsequential pipeline approach, which classifies relations between determined\nentities after entity recognition. This mode faces challenges such as error\npropagation between tasks, insufficient consideration of dependencies between\nthe two subtasks, and the neglect of interrelations between different relations\nwithin a sentence. To address these challenges, a joint extraction model with\nparameter sharing in edge computing is proposed, named CoEx-Bert. This model\nleverages shared parameterization between two models to jointly extract\nentities and relations. Specifically, CoEx-Bert employs two models, each\nseparately sharing hidden layer parameters, and combines these two loss\nfunctions for joint backpropagation to optimize the model parameters.\nAdditionally, it effectively resolves the issue of entity overlapping when\nextracting knowledge from unstructured Uyghur medical texts by considering\ncontextual relations. Finally, this model is deployed on edge devices for\nreal-time extraction and inference of Uyghur medical knowledge. Experimental\nresults demonstrate that CoEx-Bert outperforms existing state-of-the-art\nmethods, achieving accuracy, recall, and F1 scores of 90.65\\%, 92.45\\%, and\n91.54\\%, respectively, in the Uyghur traditional medical literature dataset.\nThese improvements represent a 6.45\\% increase in accuracy, a 9.45\\% increase\nin recall, and a 7.95\\% increase in F1 score compared to the baseline.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages,6 figures,Has been accepted by Tsinghua Science and\n  Technology",
    "pdf_url": "http://arxiv.org/pdf/2401.07009v1",
    "published_date": "2024-01-13 08:27:24 UTC",
    "updated_date": "2024-01-13 08:27:24 UTC"
  },
  {
    "arxiv_id": "2401.06992v1",
    "title": "Progressive Feature Fusion Network for Enhancing Image Quality Assessment",
    "authors": [
      "Kaiqun Wu",
      "Xiaoling Jiang",
      "Rui Yu",
      "Yonggang Luo",
      "Tian Jiang",
      "Xi Wu",
      "Peng Wei"
    ],
    "abstract": "Image compression has been applied in the fields of image storage and video\nbroadcasting. However, it's formidably tough to distinguish the subtle quality\ndifferences between those distorted images generated by different algorithms.\nIn this paper, we propose a new image quality assessment framework to decide\nwhich image is better in an image group. To capture the subtle differences, a\nfine-grained network is adopted to acquire multi-scale features. Subsequently,\nwe design a cross subtract block for separating and gathering the information\nwithin positive and negative image pairs. Enabling image comparison in feature\nspace. After that, a progressive feature fusion block is designed, which fuses\nmulti-scale features in a novel progressive way. Hierarchical spatial 2D\nfeatures can thus be processed gradually. Experimental results show that\ncompared with the current mainstream image quality assessment methods, the\nproposed network can achieve more accurate image quality assessment and ranks\nsecond in the benchmark of CLIC in the image perceptual model track.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Data Compression Conference",
    "pdf_url": "http://arxiv.org/pdf/2401.06992v1",
    "published_date": "2024-01-13 06:34:32 UTC",
    "updated_date": "2024-01-13 06:34:32 UTC"
  },
  {
    "arxiv_id": "2401.06979v1",
    "title": "Distance-aware Attention Reshaping: Enhance Generalization of Neural Solver for Large-scale Vehicle Routing Problems",
    "authors": [
      "Yang Wang",
      "Ya-Hui Jia",
      "Wei-Neng Chen",
      "Yi Mei"
    ],
    "abstract": "Neural solvers based on attention mechanism have demonstrated remarkable\neffectiveness in solving vehicle routing problems. However, in the\ngeneralization process from small scale to large scale, we find a phenomenon of\nthe dispersion of attention scores in existing neural solvers, which leads to\npoor performance. To address this issue, this paper proposes a distance-aware\nattention reshaping method, assisting neural solvers in solving large-scale\nvehicle routing problems. Specifically, without the need for additional\ntraining, we utilize the Euclidean distance information between current nodes\nto adjust attention scores. This enables a neural solver trained on small-scale\ninstances to make rational choices when solving a large-scale problem.\nExperimental results show that the proposed method significantly outperforms\nexisting state-of-the-art neural solvers on the large-scale CVRPLib dataset.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06979v1",
    "published_date": "2024-01-13 05:01:14 UTC",
    "updated_date": "2024-01-13 05:01:14 UTC"
  },
  {
    "arxiv_id": "2401.06977v1",
    "title": "Singing the Body Electric: The Impact of Robot Embodiment on User Expectations",
    "authors": [
      "Nathaniel Dennler",
      "Stefanos Nikolaidis",
      "Maja Matarić"
    ],
    "abstract": "Users develop mental models of robots to conceptualize what kind of\ninteractions they can have with those robots. The conceptualizations are often\nformed before interactions with the robot and are based only on observing the\nrobot's physical design. As a result, understanding conceptualizations formed\nfrom physical design is necessary to understand how users intend to interact\nwith the robot. We propose to use multimodal features of robot embodiments to\npredict what kinds of expectations users will have about a given robot's social\nand physical capabilities. We show that using such features provides\ninformation about general mental models of the robots that generalize across\nsocially interactive robots. We describe how these models can be incorporated\ninto interaction design and physical design for researchers working with\nsocially interactive robots.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.RO",
    "comment": "Presented at the RSS Workshop on Social Intelligence in Humans and\n  Robots, 2023",
    "pdf_url": "http://arxiv.org/pdf/2401.06977v1",
    "published_date": "2024-01-13 04:42:48 UTC",
    "updated_date": "2024-01-13 04:42:48 UTC"
  },
  {
    "arxiv_id": "2401.06961v2",
    "title": "CHAMP: A Competition-level Dataset for Fine-Grained Analyses of LLMs' Mathematical Reasoning Capabilities",
    "authors": [
      "Yujun Mao",
      "Yoon Kim",
      "Yilun Zhou"
    ],
    "abstract": "Recent large language models (LLMs) have shown indications of mathematical\nreasoning ability on challenging competition-level problems, especially with\nself-generated verbalizations of intermediate reasoning steps (i.e.,\nchain-of-thought prompting). However, current evaluations mainly focus on the\nend-to-end final answer correctness, and it is unclear whether LLMs can make\nuse of helpful side information such as problem-specific hints. In this paper,\nwe propose a challenging benchmark dataset for enabling such analyses. The\nConcept and Hint-Annotated Math Problems (CHAMP) consists of high school math\ncompetition problems, annotated with concepts, or general math facts, and\nhints, or problem-specific tricks. These annotations allow us to explore the\neffects of additional information, such as relevant hints, misleading concepts,\nor related problems. This benchmark is difficult, with the best model only\nscoring 58.1% in standard settings. With concepts and hints, performance\nsometimes improves, indicating that some models can make use of such side\ninformation. Furthermore, we annotate model-generated solutions for their\ncorrectness. Using this corpus, we find that models often arrive at the correct\nfinal answer through wrong reasoning steps. In addition, we test whether models\nare able to verify these solutions, and find that most models struggle.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "ACL 2024 (Findings). Project website at\n  https://yujunmao1.github.io/CHAMP/",
    "pdf_url": "http://arxiv.org/pdf/2401.06961v2",
    "published_date": "2024-01-13 03:18:16 UTC",
    "updated_date": "2024-06-09 01:47:26 UTC"
  },
  {
    "arxiv_id": "2401.06960v2",
    "title": "Transformer for Object Re-Identification: A Survey",
    "authors": [
      "Mang Ye",
      "Shuoyi Chen",
      "Chenyue Li",
      "Wei-Shi Zheng",
      "David Crandall",
      "Bo Du"
    ],
    "abstract": "Object Re-identification (Re-ID) aims to identify specific objects across\ndifferent times and scenes, which is a widely researched task in computer\nvision. For a prolonged period, this field has been predominantly driven by\ndeep learning technology based on convolutional neural networks. In recent\nyears, the emergence of Vision Transformers has spurred a growing number of\nstudies delving deeper into Transformer-based Re-ID, continuously breaking\nperformance records and witnessing significant progress in the Re-ID field.\nOffering a powerful, flexible, and unified solution, Transformers cater to a\nwide array of Re-ID tasks with unparalleled efficacy. This paper provides a\ncomprehensive review and in-depth analysis of the Transformer-based Re-ID. In\ncategorizing existing works into Image/Video-Based Re-ID, Re-ID with limited\ndata/annotations, Cross-Modal Re-ID, and Special Re-ID Scenarios, we thoroughly\nelucidate the advantages demonstrated by the Transformer in addressing a\nmultitude of challenges across these domains. Considering the trending\nunsupervised Re-ID, we propose a new Transformer baseline, UntransReID,\nachieving state-of-the-art performance on both single/cross modal tasks. For\nthe under-explored animal Re-ID, we devise a standardized experimental\nbenchmark and conduct extensive experiments to explore the applicability of\nTransformer for this task and facilitate future research. Finally, we discuss\nsome important yet under-investigated open issues in the large foundation model\nera, we believe it will serve as a new handbook for researchers in this field.\nA periodically updated website will be available at\nhttps://github.com/mangye16/ReID-Survey.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by International Journal of Computer Vision (IJCV) in\n  October 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.06960v2",
    "published_date": "2024-01-13 03:17:57 UTC",
    "updated_date": "2024-10-22 07:17:47 UTC"
  },
  {
    "arxiv_id": "2401.06952v1",
    "title": "Reinforcement Learning for Scalable Train Timetable Rescheduling with Graph Representation",
    "authors": [
      "Peng Yue",
      "Yaochu Jin",
      "Xuewu Dai",
      "Zhenhua Feng",
      "Dongliang Cui"
    ],
    "abstract": "Train timetable rescheduling (TTR) aims to promptly restore the original\noperation of trains after unexpected disturbances or disruptions. Currently,\nthis work is still done manually by train dispatchers, which is challenging to\nmaintain performance under various problem instances. To mitigate this issue,\nthis study proposes a reinforcement learning-based approach to TTR, which makes\nthe following contributions compared to existing work. First, we design a\nsimple directed graph to represent the TTR problem, enabling the automatic\nextraction of informative states through graph neural networks. Second, we\nreformulate the construction process of TTR's solution, not only decoupling the\ndecision model from the problem size but also ensuring the generated scheme's\nfeasibility. Third, we design a learning curriculum for our model to handle the\nscenarios with different levels of delay. Finally, a simple local search method\nis proposed to assist the learned decision model, which can significantly\nimprove solution quality with little additional computation cost, further\nenhancing the practical value of our method. Extensive experimental results\ndemonstrate the effectiveness of our method. The learned decision model can\nachieve better performance for various problems with varying degrees of train\ndelay and different scales when compared to handcrafted rules and\nstate-of-the-art solvers.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06952v1",
    "published_date": "2024-01-13 02:14:35 UTC",
    "updated_date": "2024-01-13 02:14:35 UTC"
  },
  {
    "arxiv_id": "2401.06951v3",
    "title": "E^2-LLM: Efficient and Extreme Length Extension of Large Language Models",
    "authors": [
      "Jiaheng Liu",
      "Zhiqi Bai",
      "Yuanxing Zhang",
      "Chenchen Zhang",
      "Yu Zhang",
      "Ge Zhang",
      "Jiakai Wang",
      "Haoran Que",
      "Yukang Chen",
      "Wenbo Su",
      "Tiezheng Ge",
      "Jie Fu",
      "Wenhu Chen",
      "Bo Zheng"
    ],
    "abstract": "Typically, training LLMs with long context sizes is computationally\nexpensive, requiring extensive training hours and GPU resources. Existing\nlong-context extension methods usually need additional training procedures to\nsupport corresponding long-context windows, where the long-context training\ndata (e.g., 32k) is needed, and high GPU training costs are assumed. To address\nthe aforementioned issues, we propose an Efficient and Extreme length extension\nmethod for Large Language Models, called E 2 -LLM, with only one training\nprocedure and dramatically reduced computation cost, which also removes the\nneed to collect long-context data. Concretely, first, the training data of our\nE 2 -LLM only requires a short length (e.g., 4k), which reduces the tuning cost\ngreatly. Second, the training procedure on the short training context window is\nperformed only once time, and we can support different evaluation context\nwindows at inference. Third, in E 2 - LLM, based on RoPE position embeddings,\nwe introduce two different augmentation methods on the scale and position index\nparameters for different samples in training. It aims to make the model more\nrobust to the different relative differences when directly interpolating the\narbitrary context length at inference. Comprehensive experimental results on\nmultiple benchmark datasets demonstrate the effectiveness of our E 2 -LLM on\nchallenging long-context tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06951v3",
    "published_date": "2024-01-13 02:11:20 UTC",
    "updated_date": "2024-02-22 12:49:10 UTC"
  },
  {
    "arxiv_id": "2401.06949v2",
    "title": "ORGANA: A Robotic Assistant for Automated Chemistry Experimentation and Characterization",
    "authors": [
      "Kourosh Darvish",
      "Marta Skreta",
      "Yuchi Zhao",
      "Naruki Yoshikawa",
      "Sagnik Som",
      "Miroslav Bogdanovic",
      "Yang Cao",
      "Han Hao",
      "Haoping Xu",
      "Alán Aspuru-Guzik",
      "Animesh Garg",
      "Florian Shkurti"
    ],
    "abstract": "Chemistry experiments can be resource- and labor-intensive, often requiring\nmanual tasks like polishing electrodes in electrochemistry. Traditional lab\nautomation infrastructure faces challenges adapting to new experiments. To\naddress this, we introduce ORGANA, an assistive robotic system that automates\ndiverse chemistry experiments using decision-making and perception tools. It\nmakes decisions with chemists in the loop to control robots and lab devices.\nORGANA interacts with chemists using Large Language Models (LLMs) to derive\nexperiment goals, handle disambiguation, and provide experiment logs. ORGANA\nplans and executes complex tasks with visual feedback, while supporting\nscheduling and parallel task execution. We demonstrate ORGANA's capabilities in\nsolubility, pH measurement, recrystallization, and electrochemistry\nexperiments. In electrochemistry, it executes a 19-step plan in parallel to\ncharacterize quinone derivatives for flow batteries. Our user study shows\nORGANA reduces frustration and physical demand by over 50%, with users saving\nan average of 80.3% of their time when using it.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06949v2",
    "published_date": "2024-01-13 02:03:28 UTC",
    "updated_date": "2025-01-07 05:00:50 UTC"
  },
  {
    "arxiv_id": "2401.06947v1",
    "title": "Parameter-Efficient Detoxification with Contrastive Decoding",
    "authors": [
      "Tong Niu",
      "Caiming Xiong",
      "Semih Yavuz",
      "Yingbo Zhou"
    ],
    "abstract": "The field of natural language generation has witnessed significant\nadvancements in recent years, including the development of controllable text\ngeneration techniques. However, controlling the attributes of the generated\ntext remains a challenge, especially when aiming to avoid undesirable behavior\nsuch as toxicity. In this work, we introduce Detoxification Generator\n(DETOXIGEN), an inference-time algorithm that steers the generation away from\nunwanted styles. DETOXIGEN is an ensemble of a pre-trained language model\n(generator) and a detoxifier. The detoxifier is trained intentionally on the\ntoxic data representative of the undesirable attribute, encouraging it to\ngenerate text in that style exclusively. During the actual generation, we use\nthe trained detoxifier to produce undesirable tokens for the generator to\ncontrast against at each decoding step. This approach directly informs the\ngenerator to avoid generating tokens that the detoxifier considers highly\nlikely. We evaluate DETOXIGEN on the commonly used REALTOXICITYPROMPTS\nbenchmark (Gehman et al., 2020) with various language models as generators. We\nfind that it significantly outperforms previous approaches in detoxification\nmetrics while not compromising on the generation quality. Moreover, the\ndetoxifier is obtained by soft prompt-tuning using the same backbone language\nmodel as the generator. Hence, DETOXIGEN requires only a tiny amount of extra\nweights from the virtual tokens of the detoxifier to be loaded into GPU memory\nwhile decoding, making it a promising lightweight, practical, and\nparameter-efficient detoxification strategy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2401.06947v1",
    "published_date": "2024-01-13 01:46:20 UTC",
    "updated_date": "2024-01-13 01:46:20 UTC"
  },
  {
    "arxiv_id": "2401.06946v1",
    "title": "3D Object Detection and High-Resolution Traffic Parameters Extraction Using Low-Resolution LiDAR Data",
    "authors": [
      "Linlin Zhang",
      "Xiang Yu",
      "Armstrong Aboah",
      "Yaw Adu-Gyamfi"
    ],
    "abstract": "Traffic volume data collection is a crucial aspect of transportation\nengineering and urban planning, as it provides vital insights into traffic\npatterns, congestion, and infrastructure efficiency. Traditional manual methods\nof traffic data collection are both time-consuming and costly. However, the\nemergence of modern technologies, particularly Light Detection and Ranging\n(LiDAR), has revolutionized the process by enabling efficient and accurate data\ncollection. Despite the benefits of using LiDAR for traffic data collection,\nprevious studies have identified two major limitations that have impeded its\nwidespread adoption. These are the need for multiple LiDAR systems to obtain\ncomplete point cloud information of objects of interest, as well as the\nlabor-intensive process of annotating 3D bounding boxes for object detection\ntasks. In response to these challenges, the current study proposes an\ninnovative framework that alleviates the need for multiple LiDAR systems and\nsimplifies the laborious 3D annotation process. To achieve this goal, the study\nemployed a single LiDAR system, that aims at reducing the data acquisition cost\nand addressed its accompanying limitation of missing point cloud information by\ndeveloping a Point Cloud Completion (PCC) framework to fill in missing point\ncloud information using point density. Furthermore, we also used zero-shot\nlearning techniques to detect vehicles and pedestrians, as well as proposed a\nunique framework for extracting low to high features from the object of\ninterest, such as height, acceleration, and speed. Using the 2D bounding box\ndetection and extracted height information, this study is able to generate 3D\nbounding boxes automatically without human intervention.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 11 figures. This paper has been submitted for consideration\n  for presentation at the 103rd Annual Meeting of the Transportation Research\n  Board, January 2024",
    "pdf_url": "http://arxiv.org/pdf/2401.06946v1",
    "published_date": "2024-01-13 01:22:20 UTC",
    "updated_date": "2024-01-13 01:22:20 UTC"
  }
]