[
  {
    "arxiv_id": "2504.06492v1",
    "title": "Exploiting Meta-Learning-based Poisoning Attacks for Graph Link Prediction",
    "authors": [
      "Mingchen Li",
      "Di Zhuang",
      "Keyu Chen",
      "Dumindu Samaraweera",
      "Morris Chang"
    ],
    "abstract": "Link prediction in graph data utilizes various algorithms and machine\nlearning/deep learning models to predict potential relationships between graph\nnodes. This technique has found widespread use in numerous real-world\napplications, including recommendation systems, community networks, and\nbiological structures. However, recent research has highlighted the\nvulnerability of link prediction models to adversarial attacks, such as\npoisoning and evasion attacks. Addressing the vulnerability of these models is\ncrucial to ensure stable and robust performance in link prediction\napplications. While many works have focused on enhancing the robustness of the\nGraph Convolution Network (GCN) model, the Variational Graph Auto-Encoder\n(VGAE), a sophisticated model for link prediction, has not been thoroughly\ninvestigated in the context of graph adversarial attacks. To bridge this gap,\nthis article proposes an unweighted graph poisoning attack approach using\nmeta-learning techniques to undermine VGAE's link prediction performance. We\nconducted comprehensive experiments on diverse datasets to evaluate the\nproposed method and its parameters, comparing it with existing approaches in\nsimilar settings. Our results demonstrate that our approach significantly\ndiminishes link prediction performance and outperforms other state-of-the-art\nmethods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06492v1",
    "published_date": "2025-04-08 23:36:29 UTC",
    "updated_date": "2025-04-08 23:36:29 UTC"
  },
  {
    "arxiv_id": "2504.07998v1",
    "title": "CDM-QTA: Quantized Training Acceleration for Efficient LoRA Fine-Tuning of Diffusion Model",
    "authors": [
      "Jinming Lu",
      "Minghao She",
      "Wendong Mao",
      "Zhongfeng Wang"
    ],
    "abstract": "Fine-tuning large diffusion models for custom applications demands\nsubstantial power and time, which poses significant challenges for efficient\nimplementation on mobile devices. In this paper, we develop a novel training\naccelerator specifically for Low-Rank Adaptation (LoRA) of diffusion models,\naiming to streamline the process and reduce computational complexity. By\nleveraging a fully quantized training scheme for LoRA fine-tuning, we achieve\nsubstantial reductions in memory usage and power consumption while maintaining\nhigh model fidelity. The proposed accelerator features flexible dataflow,\nenabling high utilization for irregular and variable tensor shapes during the\nLoRA process. Experimental results show up to 1.81x training speedup and 5.50x\nenergy efficiency improvements compared to the baseline, with minimal impact on\nimage generation quality.",
    "categories": [
      "cs.GR",
      "cs.AI",
      "cs.AR",
      "cs.CV"
    ],
    "primary_category": "cs.GR",
    "comment": "ISCAS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.07998v1",
    "published_date": "2025-04-08 22:40:29 UTC",
    "updated_date": "2025-04-08 22:40:29 UTC"
  },
  {
    "arxiv_id": "2504.06469v2",
    "title": "AI-Assisted Transport of Radioactive Ion Beams",
    "authors": [
      "Sergio Lopez-Caceres",
      "Daniel Santiago-Gonzalez"
    ],
    "abstract": "Beams of radioactive heavy ions allow researchers to study rare and unstable\natomic nuclei, shedding light into the internal structure of exotic nuclei and\non how chemical elements are formed in stars. However, the extraction and\ntransport of radioactive beams rely on time-consuming expert-driven tuning\nmethods, where hundreds of parameters are manually optimized. Here, we\nintroduce a system that employs Artificial Intelligence (AI), specifically\nutilizing Bayesian Optimization, to assist in the transport process of\nradioactive beams. We apply our methodology to real-life scenarios showing\nadvantages when compared with standard tuning methods. This AI-assisted\napproach can be extended to other radioactive beam facilities around the world\nto improve operational efficiency and enhance scientific output.",
    "categories": [
      "physics.acc-ph",
      "cs.AI",
      "nucl-ex"
    ],
    "primary_category": "physics.acc-ph",
    "comment": "6 pages, 6 figures; Section headings added for clarity.\n  Implementation and Results sections expanded. Minor revisions to Abstract and\n  to Summary and Conclusion",
    "pdf_url": "http://arxiv.org/pdf/2504.06469v2",
    "published_date": "2025-04-08 22:21:54 UTC",
    "updated_date": "2025-04-17 00:25:50 UTC"
  },
  {
    "arxiv_id": "2504.06468v1",
    "title": "Agent-Arena: A General Framework for Evaluating Control Algorithms",
    "authors": [
      "Halid Abdulrahim Kadi",
      "Kasim Terzić"
    ],
    "abstract": "Robotic research is inherently challenging, requiring expertise in diverse\nenvironments and control algorithms. Adapting algorithms to new environments\noften poses significant difficulties, compounded by the need for extensive\nhyper-parameter tuning in data-driven methods. To address these challenges, we\npresent Agent-Arena, a Python framework designed to streamline the integration,\nreplication, development, and testing of decision-making policies across a wide\nrange of benchmark environments. Unlike existing frameworks, Agent-Arena is\nuniquely generalised to support all types of control algorithms and is\nadaptable to both simulation and real-robot scenarios. Please see our GitHub\nrepository https://github.com/halid1020/agent-arena-v0.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.RO",
    "comment": "20 pages and 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.06468v1",
    "published_date": "2025-04-08 22:20:50 UTC",
    "updated_date": "2025-04-08 22:20:50 UTC"
  },
  {
    "arxiv_id": "2504.06457v1",
    "title": "Federated Neural Architecture Search with Model-Agnostic Meta Learning",
    "authors": [
      "Xinyuan Huang",
      "Jiechao Gao"
    ],
    "abstract": "Federated Learning (FL) often struggles with data heterogeneity due to the\nnaturally uneven distribution of user data across devices. Federated Neural\nArchitecture Search (NAS) enables collaborative search for optimal model\narchitectures tailored to heterogeneous data to achieve higher accuracy.\nHowever, this process is time-consuming due to extensive search space and\nretraining. To overcome this, we introduce FedMetaNAS, a framework that\nintegrates meta-learning with NAS within the FL context to expedite the\narchitecture search by pruning the search space and eliminating the retraining\nstage. Our approach first utilizes the Gumbel-Softmax reparameterization to\nfacilitate relaxation of the mixed operations in the search space. We then\nrefine the local search process by incorporating Model-Agnostic Meta-Learning,\nwhere a task-specific learner adapts both weights and architecture parameters\n(alphas) for individual tasks, while a meta learner adjusts the overall model\nweights and alphas based on the gradient information from task learners.\nFollowing the meta-update, we propose soft pruning using the same trick on\nsearch space to gradually sparsify the architecture, ensuring that the\nperformance of the chosen architecture remains robust after pruning which\nallows for immediate use of the model without retraining. Experimental\nevaluations demonstrate that FedMetaNAS significantly accelerates the search\nprocess by more than 50\\% with higher accuracy compared to FedNAS.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06457v1",
    "published_date": "2025-04-08 21:57:40 UTC",
    "updated_date": "2025-04-08 21:57:40 UTC"
  },
  {
    "arxiv_id": "2504.06446v1",
    "title": "Can you Finetune your Binoculars? Embedding Text Watermarks into the Weights of Large Language Models",
    "authors": [
      "Fay Elhassan",
      "Niccolò Ajroldi",
      "Antonio Orvieto",
      "Jonas Geiping"
    ],
    "abstract": "The indistinguishability of AI-generated content from human text raises\nchallenges in transparency and accountability. While several methods exist to\nwatermark models behind APIs, embedding watermark strategies directly into\nmodel weights that are later reflected in the outputs of the model is\nchallenging. In this study we propose a strategy to finetune a pair of low-rank\nadapters of a model, one serving as the text-generating model, and the other as\nthe detector, so that a subtle watermark is embedded into the text generated by\nthe first model and simultaneously optimized for detectability by the second.\nIn this way, the watermarking strategy is fully learned end-to-end. This\nprocess imposes an optimization challenge, as balancing watermark robustness,\nnaturalness, and task performance requires trade-offs. We discuss strategies on\nhow to optimize this min-max objective and present results showing the effect\nof this modification to instruction finetuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06446v1",
    "published_date": "2025-04-08 21:34:02 UTC",
    "updated_date": "2025-04-08 21:34:02 UTC"
  },
  {
    "arxiv_id": "2504.06438v1",
    "title": "Don't Let It Hallucinate: Premise Verification via Retrieval-Augmented Logical Reasoning",
    "authors": [
      "Yuehan Qin",
      "Shawn Li",
      "Yi Nian",
      "Xinyan Velocity Yu",
      "Yue Zhao",
      "Xuezhe Ma"
    ],
    "abstract": "Large language models (LLMs) have shown substantial capacity for generating\nfluent, contextually appropriate responses. However, they can produce\nhallucinated outputs, especially when a user query includes one or more false\npremises-claims that contradict established facts. Such premises can mislead\nLLMs into offering fabricated or misleading details. Existing approaches\ninclude pretraining, fine-tuning, and inference-time techniques that often rely\non access to logits or address hallucinations after they occur. These methods\ntend to be computationally expensive, require extensive training data, or lack\nproactive mechanisms to prevent hallucination before generation, limiting their\nefficiency in real-time applications. We propose a retrieval-based framework\nthat identifies and addresses false premises before generation. Our method\nfirst transforms a user's query into a logical representation, then applies\nretrieval-augmented generation (RAG) to assess the validity of each premise\nusing factual sources. Finally, we incorporate the verification results into\nthe LLM's prompt to maintain factual consistency in the final output.\nExperiments show that this approach effectively reduces hallucinations,\nimproves factual accuracy, and does not require access to model logits or\nlarge-scale fine-tuning.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06438v1",
    "published_date": "2025-04-08 21:14:48 UTC",
    "updated_date": "2025-04-08 21:14:48 UTC"
  },
  {
    "arxiv_id": "2504.06436v1",
    "title": "Language-Dependent Political Bias in AI: A Study of ChatGPT and Gemini",
    "authors": [
      "Dogus Yuksel",
      "Mehmet Cem Catalbas",
      "Bora Oc"
    ],
    "abstract": "As leading examples of large language models, ChatGPT and Gemini claim to\nprovide accurate and unbiased information, emphasizing their commitment to\npolitical neutrality and avoidance of personal bias. This research investigates\nthe political tendency of large language models and the existence of\ndifferentiation according to the query language. For this purpose, ChatGPT and\nGemini were subjected to a political axis test using 14 different languages.\nThe findings of the study suggest that these large language models do exhibit\npolitical tendencies, with both models demonstrating liberal and leftist\nbiases. A comparative analysis revealed that Gemini exhibited a more pronounced\nliberal and left-wing tendency compared to ChatGPT. The study also found that\nthese political biases varied depending on the language used for inquiry. The\nstudy delves into the factors that constitute political tendencies and\nlinguistic differentiation, exploring differences in the sources and scope of\neducational data, structural and grammatical features of languages, cultural\nand political contexts, and the model's response to linguistic features. From\nthis standpoint, and an ethical perspective, it is proposed that artificial\nintelligence tools should refrain from asserting a lack of political tendencies\nand neutrality, instead striving for political neutrality and executing user\nqueries by incorporating these tendencies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "stat.AP"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.06436v1",
    "published_date": "2025-04-08 21:13:01 UTC",
    "updated_date": "2025-04-08 21:13:01 UTC"
  },
  {
    "arxiv_id": "2504.06413v1",
    "title": "Evaluating Mutation Techniques in Genetic Algorithm-Based Quantum Circuit Synthesis",
    "authors": [
      "Michael Kölle",
      "Tom Bintener",
      "Maximilian Zorn",
      "Gerhard Stenzel",
      "Leo Sünkel",
      "Thomas Gabor",
      "Claudia Linnhoff-Popien"
    ],
    "abstract": "Quantum computing leverages the unique properties of qubits and quantum\nparallelism to solve problems intractable for classical systems, offering\nunparalleled computational potential. However, the optimization of quantum\ncircuits remains critical, especially for noisy intermediate-scale quantum\n(NISQ) devices with limited qubits and high error rates. Genetic algorithms\n(GAs) provide a promising approach for efficient quantum circuit synthesis by\nautomating optimization tasks. This work examines the impact of various\nmutation strategies within a GA framework for quantum circuit synthesis. By\nanalyzing how different mutations transform circuits, it identifies strategies\nthat enhance efficiency and performance. Experiments utilized a fitness\nfunction emphasizing fidelity, while accounting for circuit depth and T\noperations, to optimize circuits with four to six qubits. Comprehensive\nhyperparameter testing revealed that combining delete and swap strategies\noutperformed other approaches, demonstrating their effectiveness in developing\nrobust GA-based quantum circuit optimizers.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "Accepted at GECCO 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.06413v1",
    "published_date": "2025-04-08 20:14:35 UTC",
    "updated_date": "2025-04-08 20:14:35 UTC"
  },
  {
    "arxiv_id": "2504.06407v1",
    "title": "Understanding Machine Unlearning Through the Lens of Mode Connectivity",
    "authors": [
      "Jiali Cheng",
      "Hadi Amiri"
    ],
    "abstract": "Machine Unlearning aims to remove undesired information from trained models\nwithout requiring full retraining from scratch. Despite recent advancements,\ntheir underlying loss landscapes and optimization dynamics received less\nattention. In this paper, we investigate and analyze machine unlearning through\nthe lens of mode connectivity - the phenomenon where independently trained\nmodels can be connected by smooth low-loss paths in the parameter space. We\ndefine and study mode connectivity in unlearning across a range of overlooked\nconditions, including connections between different unlearning methods, models\ntrained with and without curriculum learning, and models optimized with\nfirst-order and secondorder techniques. Our findings show distinct patterns of\nfluctuation of different evaluation metrics along the curve, as well as the\nmechanistic (dis)similarity between unlearning methods. To the best of our\nknowledge, this is the first study on mode connectivity in the context of\nmachine unlearning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06407v1",
    "published_date": "2025-04-08 20:02:10 UTC",
    "updated_date": "2025-04-08 20:02:10 UTC"
  },
  {
    "arxiv_id": "2504.06404v1",
    "title": "Physical spline for denoising object trajectory data by combining splines, ML feature regression and model knowledge",
    "authors": [
      "Jonas Torzewski"
    ],
    "abstract": "This article presents a method for estimating the dynamic driving states\n(position, velocity, acceleration and heading) from noisy measurement data. The\nproposed approach is effective with both complete and partial observations,\nproducing refined trajectory signals with kinematic consistency, ensuring that\nvelocity is the integral of acceleration and position is the integral of\nvelocity. Additionally, the method accounts for the constraint that vehicles\ncan only move in the direction of their orientation. The method is implemented\nas a configurable python library that also enables trajectory estimation solely\nbased on position data. Regularization is applied to prevent extreme state\nvariations. A key application is enhancing recorded trajectory data for use as\nreference inputs in machine learning models. At the end, the article presents\nthe results of the method along with a comparison to ground truth data.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "7 pages, 7 figures, https://github.com/jonasTorz/physical_spline",
    "pdf_url": "http://arxiv.org/pdf/2504.06404v1",
    "published_date": "2025-04-08 19:53:57 UTC",
    "updated_date": "2025-04-08 19:53:57 UTC"
  },
  {
    "arxiv_id": "2504.06265v2",
    "title": "GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization",
    "authors": [
      "Bojana Ranković",
      "Philippe Schwaller"
    ],
    "abstract": "Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06265v2",
    "published_date": "2025-04-08 17:59:57 UTC",
    "updated_date": "2025-04-09 23:45:44 UTC"
  },
  {
    "arxiv_id": "2504.06260v1",
    "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability",
    "authors": [
      "Nayantara Mudur",
      "Hao Cui",
      "Subhashini Venugopalan",
      "Paul Raccuglia",
      "Michael P. Brenner",
      "Peter Norgaard"
    ],
    "abstract": "Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.AI",
    "comment": "39 pages. Accepted at the NeurIPS 2024 Workshops on Mathematical\n  Reasoning and AI and Open-World Agents",
    "pdf_url": "http://arxiv.org/pdf/2504.06260v1",
    "published_date": "2025-04-08 17:59:39 UTC",
    "updated_date": "2025-04-08 17:59:39 UTC"
  },
  {
    "arxiv_id": "2504.06235v2",
    "title": "Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis",
    "authors": [
      "Shahryar Zehtabi",
      "Dong-Jun Han",
      "Seyyedali Hosseinalipour",
      "Christopher G. Brinton"
    ],
    "abstract": "Much of the federated learning (FL) literature focuses on settings where\nlocal dataset statistics remain the same between training and testing time.\nRecent advances in domain generalization (DG) aim to use data from source\n(training) domains to train a model that generalizes well to data from unseen\ntarget (testing) domains. In this paper, we are motivated by two major gaps in\nexisting work on FL and DG: (1) the lack of formal mathematical analysis of DG\nobjectives and training processes; and (2) DG research in FL being limited to\nthe conventional star-topology architecture. Addressing the second gap, we\ndevelop $\\textit{Decentralized Federated Domain Generalization with Style\nSharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to\nallow devices in a peer-to-peer network to achieve DG based on sharing style\ninformation inferred from their datasets. Additionally, we fill the first gap\nby providing the first systematic approach to mathematically analyzing\nstyle-based DG training optimization. We cast existing centralized DG\nalgorithms within our framework, and employ their formalisms to model\n$\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which\na sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through\nexperiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$\ncan obtain significant improvements in accuracy across target domains with\nminimal added communication overhead compared to decentralized gradient methods\nthat do not employ style sharing.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06235v2",
    "published_date": "2025-04-08 17:32:56 UTC",
    "updated_date": "2025-04-17 08:52:03 UTC"
  },
  {
    "arxiv_id": "2504.07994v1",
    "title": "Evaluating the Fitness of Ontologies for the Task of Question Generation",
    "authors": [
      "Samah Alkhuzaey",
      "Floriana Grasso",
      "Terry R. Payne",
      "Valentina Tamma"
    ],
    "abstract": "Ontology-based question generation is an important application of\nsemantic-aware systems that enables the creation of large question banks for\ndiverse learning environments. The effectiveness of these systems, both in\nterms of the calibre and cognitive difficulty of the resulting questions,\ndepends heavily on the quality and modelling approach of the underlying\nontologies, making it crucial to assess their fitness for this task. To date,\nthere has been no comprehensive investigation into the specific ontology\naspects or characteristics that affect the question generation process.\nTherefore, this paper proposes a set of requirements and task-specific metrics\nfor evaluating the fitness of ontologies for question generation tasks in\npedagogical settings. Using the ROMEO methodology, a structured framework for\nderiving task-specific metrics, an expert-based approach is employed to assess\nthe performance of various ontologies in Automatic Question Generation (AQG)\ntasks, which is then evaluated over a set of ontologies. Our results\ndemonstrate that ontology characteristics significantly impact the\neffectiveness of question generation, with different ontologies exhibiting\nvarying performance levels. This highlights the importance of assessing\nontology quality with respect to AQG tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07994v1",
    "published_date": "2025-04-08 17:10:04 UTC",
    "updated_date": "2025-04-08 17:10:04 UTC"
  },
  {
    "arxiv_id": "2504.06214v1",
    "title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models",
    "authors": [
      "Chejian Xu",
      "Wei Ping",
      "Peng Xu",
      "Zihan Liu",
      "Boxin Wang",
      "Mohammad Shoeybi",
      "Bo Li",
      "Bryan Catanzaro"
    ],
    "abstract": "Long-context capabilities are essential for a wide range of applications,\nincluding document and video understanding, in-context learning, and\ninference-time scaling, all of which require models to process and reason over\nlong sequences of text and multimodal data. In this work, we introduce a\nefficient training recipe for building ultra-long context LLMs from aligned\ninstruct model, pushing the boundaries of context lengths from 128K to 1M, 2M,\nand 4M tokens. Our approach leverages efficient continued pretraining\nstrategies to extend the context window and employs effective instruction\ntuning to maintain the instruction-following and reasoning abilities. Our\nUltraLong-8B, built on Llama3.1-Instruct with our recipe, achieves\nstate-of-the-art performance across a diverse set of long-context benchmarks.\nImportantly, models trained with our approach maintain competitive performance\non standard benchmarks, demonstrating balanced improvements for both long and\nshort context tasks. We further provide an in-depth analysis of key design\nchoices, highlighting the impacts of scaling strategies and data composition.\nOur findings establish a robust framework for efficiently scaling context\nlengths while preserving general model capabilities. We release all model\nweights at: https://ultralong.github.io/.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06214v1",
    "published_date": "2025-04-08 16:58:58 UTC",
    "updated_date": "2025-04-08 16:58:58 UTC"
  },
  {
    "arxiv_id": "2504.06207v1",
    "title": "An experimental survey and Perspective View on Meta-Learning for Automated Algorithms Selection and Parametrization",
    "authors": [
      "Moncef Garouani"
    ],
    "abstract": "Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06207v1",
    "published_date": "2025-04-08 16:51:22 UTC",
    "updated_date": "2025-04-08 16:51:22 UTC"
  },
  {
    "arxiv_id": "2504.06196v1",
    "title": "TxGemma: Efficient and Agentic LLMs for Therapeutics",
    "authors": [
      "Eric Wang",
      "Samuel Schmidgall",
      "Paul F. Jaeger",
      "Fan Zhang",
      "Rory Pilgrim",
      "Yossi Matias",
      "Joelle Barral",
      "David Fleet",
      "Shekoofeh Azizi"
    ],
    "abstract": "Therapeutic development is a costly and high-risk endeavor that is often\nplagued by high failure rates. To address this, we introduce TxGemma, a suite\nof efficient, generalist large language models (LLMs) capable of therapeutic\nproperty prediction as well as interactive reasoning and explainability. Unlike\ntask-specific models, TxGemma synthesizes information from diverse sources,\nenabling broad application across the therapeutic development pipeline. The\nsuite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a\ncomprehensive dataset of small molecules, proteins, nucleic acids, diseases,\nand cell lines. Across 66 therapeutic development tasks, TxGemma achieved\nsuperior or comparable performance to the state-of-the-art generalist model on\n64 (superior on 45), and against state-of-the-art specialist models on 50\n(superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks,\nsuch as clinical trial adverse event prediction, requires less training data\nthan fine-tuning base LLMs, making TxGemma suitable for data-limited\napplications. Beyond these predictive capabilities, TxGemma features\nconversational models that bridge the gap between general LLMs and specialized\nproperty predictors. These allow scientists to interact in natural language,\nprovide mechanistic reasoning for predictions based on molecular structure, and\nengage in scientific discussions. Building on this, we further introduce\nAgentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that\nreasons, acts, manages diverse workflows, and acquires external domain\nknowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last\nExam benchmark (Chemistry & Biology) with 52.3% relative improvement over\no3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels\nwith improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over\no3-mini (high).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06196v1",
    "published_date": "2025-04-08 16:39:02 UTC",
    "updated_date": "2025-04-08 16:39:02 UTC"
  },
  {
    "arxiv_id": "2504.06193v1",
    "title": "Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction",
    "authors": [
      "Zongyue Qin",
      "Shichang Zhang",
      "Mingxuan Ju",
      "Tong Zhao",
      "Neil Shah",
      "Yizhou Sun"
    ],
    "abstract": "Link prediction is a crucial graph-learning task with applications including\ncitation prediction and product recommendation. Distilling Graph Neural\nNetworks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has\nemerged as an effective approach to achieve strong performance and reducing\ncomputational cost by removing graph dependency. However, existing distillation\nmethods only use standard GNNs and overlook alternative teachers such as\nspecialized model for link prediction (GNN4LP) and heuristic methods (e.g.,\ncommon neighbors). This paper first explores the impact of different teachers\nin GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do not\nalways produce stronger students: MLPs distilled from GNN4LP can underperform\nthose distilled from simpler GNNs, while weaker heuristic methods can teach\nMLPs to near-GNN performance with drastically reduced training costs. Building\non these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), which\neliminates graph dependencies while effectively integrating complementary\nsignals via a gating mechanism. Experiments on ten datasets show an average\n7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times less\ntraining time, indicating EHDM is an efficient and effective link prediction\nmethod.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06193v1",
    "published_date": "2025-04-08 16:35:11 UTC",
    "updated_date": "2025-04-08 16:35:11 UTC"
  },
  {
    "arxiv_id": "2504.06188v1",
    "title": "SkillFlow: Efficient Skill and Code Transfer Through Communication in Adapting AI Agents",
    "authors": [
      "Pagkratios Tagkopoulos",
      "Fangzhou Li",
      "Ilias Tagkopoulos"
    ],
    "abstract": "AI agents are autonomous systems that can execute specific tasks based on\npredefined programming. Here, we present SkillFlow, a modular,\ntechnology-agnostic framework that allows agents to expand their functionality\nin an ad-hoc fashion by acquiring new skills from their environment or other\nagents. We present a theoretical model that examines under which conditions\nthis framework would be beneficial, and we then explore SkillFlow's ability to\naccelerate task completion and lead to lower cumulative costs in a real-world\napplication, namely scheduling agents for calendar events. We demonstrate that\nwithin a few iterations, SkillFlow leads to considerable (24.8%, p-value =\n$6.4\\times10^{-3}$) gains in time and cost, especially when the communication\ncost is high. Finally, we draw analogies from well-studied biological systems\nand compare this framework to that of lateral gene transfer, a significant\nprocess of adaptation and evolution in novel environments.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06188v1",
    "published_date": "2025-04-08 16:33:24 UTC",
    "updated_date": "2025-04-08 16:33:24 UTC"
  },
  {
    "arxiv_id": "2504.06185v1",
    "title": "WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care",
    "authors": [
      "Vanessa Borst",
      "Timo Dittus",
      "Tassilo Dege",
      "Astrid Schmieder",
      "Samuel Kounev"
    ],
    "abstract": "Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For fair comparison, we\nstandardize training, data augmentation, and evaluation, conducting\ncross-validationto minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates, and evaluate this, along with mask\nquality, for the best models based on physician assessments. Overall, the\ntransformer-based TransNeXt showed the highest levels of generalizability.\nDespite variations in inference times, all models processed at least one image\nper second on the CPU, which is deemed adequate for the intended application.\nInterpretability analysis typically revealed prominent activations in wound\nregions, emphasizing focus on clinically relevant features. Expert evaluation\nshowed high mask approval for all analyzed models, with VWFormer and ConvNeXtS\nbackbone performing the best. Size retrieval accuracy was similar across\nmodels, and predictions closely matched expert annotations. Finally, we\ndemonstrate how our AI-driven wound size estimation framework, WoundAmbit, can\nbe integrated into a custom telehealth system. Our code will be made available\non GitHub upon publication.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Main paper: 17 pages; supplementary material: 16 pages; paper\n  submitted to the application track of the European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECML PKDD 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.06185v1",
    "published_date": "2025-04-08 16:25:59 UTC",
    "updated_date": "2025-04-08 16:25:59 UTC"
  },
  {
    "arxiv_id": "2504.06176v2",
    "title": "A Self-Supervised Framework for Space Object Behaviour Characterisation",
    "authors": [
      "Ian Groves",
      "Andrew Campbell",
      "James Fernandes",
      "Diego Ramírez Rodríguez",
      "Paul Murray",
      "Massimiliano Vasile",
      "Victoria Nockles"
    ],
    "abstract": "Foundation Models, pre-trained on large unlabelled datasets before\ntask-specific fine-tuning, are increasingly being applied to specialised\ndomains. Recent examples include ClimaX for climate and Clay for satellite\nEarth observation, but a Foundation Model for Space Object Behavioural Analysis\nhas not yet been developed. As orbital populations grow, automated methods for\ncharacterising space object behaviour are crucial for space safety. We present\na Space Safety and Sustainability Foundation Model focusing on space object\nbehavioural analysis using light curves (LCs). We implemented a\nPerceiver-Variational Autoencoder (VAE) architecture, pre-trained with\nself-supervised reconstruction and masked reconstruction on 227,000 LCs from\nthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,\nand LC generation. We fine-tuned the model for anomaly detection & motion\nprediction using two independent LC simulators (CASSANDRA and GRIAL\nrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink\nplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,\nidentifying potentially anomalous light curves through reconstruction\ndifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90\nand 0.95 ROC AUC scores respectively in both anomaly detection and motion mode\nprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly\npredictions on real data revealed distinct patterns including characteristic\nobject profiles and satellite glinting. Here, we demonstrate how\nself-supervised learning can simultaneously enable anomaly detection, motion\nprediction, and synthetic data generation from rich representations learned in\npre-training. Our work therefore supports space safety and sustainability\nthrough automated monitoring and simulation capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.space-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.06176v2",
    "published_date": "2025-04-08 16:19:19 UTC",
    "updated_date": "2025-04-11 08:14:37 UTC"
  },
  {
    "arxiv_id": "2504.06173v1",
    "title": "Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles Using Deep Learning",
    "authors": [
      "Muhammad Baqer Mollah",
      "Honggang Wang",
      "Mohammad Ataul Karim",
      "Hua Fang"
    ],
    "abstract": "Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.ET",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.NI",
    "comment": "15 Pages",
    "pdf_url": "http://arxiv.org/pdf/2504.06173v1",
    "published_date": "2025-04-08 16:18:00 UTC",
    "updated_date": "2025-04-08 16:18:00 UTC"
  },
  {
    "arxiv_id": "2504.06165v1",
    "title": "Real-Time Pitch/F0 Detection Using Spectrogram Images and Convolutional Neural Networks",
    "authors": [
      "Xufang Zhao",
      "Omer Tsimhoni"
    ],
    "abstract": "This paper presents a novel approach to detect F0 through Convolutional\nNeural Networks and image processing techniques to directly estimate pitch from\nspectrogram images. Our new approach demonstrates a very good detection\naccuracy; a total of 92% of predicted pitch contours have strong or moderate\ncorrelations to the true pitch contours. Furthermore, the experimental\ncomparison between our new approach and other state-of-the-art CNN methods\nreveals that our approach can enhance the detection rate by approximately 5%\nacross various Signal-to-Noise Ratio conditions.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06165v1",
    "published_date": "2025-04-08 16:01:25 UTC",
    "updated_date": "2025-04-08 16:01:25 UTC"
  },
  {
    "arxiv_id": "2504.06160v3",
    "title": "Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups",
    "authors": [
      "Rijul Magu",
      "Arka Dutta",
      "Sean Kim",
      "Ashiqur R. KhudaBukhsh",
      "Munmun De Choudhury"
    ],
    "abstract": "Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI",
      "J.4; K.4.1; K.4.2"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06160v3",
    "published_date": "2025-04-08 15:56:57 UTC",
    "updated_date": "2025-04-11 20:13:11 UTC"
  },
  {
    "arxiv_id": "2504.06143v1",
    "title": "ARLO: A Tailorable Approach for Transforming Natural Language Software Requirements into Architecture using LLMs",
    "authors": [
      "Tooraj Helmi"
    ],
    "abstract": "Software requirements expressed in natural language (NL) frequently suffer\nfrom verbosity, ambiguity, and inconsistency. This creates a range of\nchallenges, including selecting an appropriate architecture for a system and\nassessing different architectural alternatives. Relying on human expertise to\naccomplish the task of mapping NL requirements to architecture is\ntime-consuming and error-prone. This paper proposes ARLO, an approach that\nautomates this task by leveraging (1) a set of NL requirements for a system,\n(2) an existing standard that specifies architecturally relevant software\nquality attributes, and (3) a readily available Large Language Model (LLM).\nSpecifically, ARLO determines the subset of NL requirements for a given system\nthat is architecturally relevant and maps that subset to a tailorable matrix of\narchitectural choices. ARLO applies integer linear programming on the\narchitectural-choice matrix to determine the optimal architecture for the\ncurrent requirements. We demonstrate ARLO's efficacy using a set of real-world\nexamples. We highlight ARLO's ability (1) to trace the selected architectural\nchoices to the requirements and (2) to isolate NL requirements that exert a\nparticular influence on a system's architecture. This allows the\nidentification, comparative assessment, and exploration of alternative\narchitectural choices based on the requirements and constraints expressed\ntherein.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06143v1",
    "published_date": "2025-04-08 15:38:42 UTC",
    "updated_date": "2025-04-08 15:38:42 UTC"
  },
  {
    "arxiv_id": "2504.06138v2",
    "title": "A Multimedia Analytics Model for the Foundation Model Era",
    "authors": [
      "Marcel Worring",
      "Jan Zahálka",
      "Stef van den Elzen",
      "Maximilian T. Fischer",
      "Daniel A. Keim"
    ],
    "abstract": "The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.",
    "categories": [
      "cs.MM",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.MM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06138v2",
    "published_date": "2025-04-08 15:35:59 UTC",
    "updated_date": "2025-04-10 10:52:41 UTC"
  },
  {
    "arxiv_id": "2504.13904v1",
    "title": "Generative Framework for Personalized Persuasion: Inferring Causal, Counterfactual, and Latent Knowledge",
    "authors": [
      "Donghuo Zeng",
      "Roberto Legaspi",
      "Yuewen Sun",
      "Xinshuai Dong",
      "Kazushi Ikeda",
      "Peter Spirtes",
      "Kun Zhang"
    ],
    "abstract": "We hypothesize that optimal system responses emerge from adaptive strategies\ngrounded in causal and counterfactual knowledge. Counterfactual inference\nallows us to create hypothetical scenarios to examine the effects of\nalternative system responses. We enhance this process through causal discovery,\nwhich identifies the strategies informed by the underlying causal structure\nthat govern system behaviors. Moreover, we consider the psychological\nconstructs and unobservable noises that might be influencing user-system\ninteractions as latent factors. We show that these factors can be effectively\nestimated. We employ causal discovery to identify strategy-level causal\nrelationships among user and system utterances, guiding the generation of\npersonalized counterfactual dialogues. We model the user utterance strategies\nas causal factors, enabling system strategies to be treated as counterfactual\nactions. Furthermore, we optimize policies for selecting system responses based\non counterfactual data. Our results using a real-world dataset on social good\ndemonstrate significant improvements in persuasive system outcomes, with\nincreased cumulative rewards validating the efficacy of causal discovery in\nguiding personalized counterfactual inference and optimizing dialogue policies\nfor a persuasive dialogue system.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.HC",
    "comment": "12 pages, 10 figures, 1 table. Accepted by ACM UMAP 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.13904v1",
    "published_date": "2025-04-08 15:33:54 UTC",
    "updated_date": "2025-04-08 15:33:54 UTC"
  },
  {
    "arxiv_id": "2505.03747v1",
    "title": "The Evolution of Rough Sets 1970s-1981",
    "authors": [
      "Viktor Marek",
      "Ewa Orłowska",
      "Ivo Düntsch"
    ],
    "abstract": "In this note research and publications by Zdzis{\\l}aw Pawlak and his\ncollaborators from 1970s and 1981 are recalled. Focus is placed on the sources\nof inspiration which one can identify on the basis of those publications.\nFinally, developments from 1981 related to rough sets and information systems\nare outlined.",
    "categories": [
      "math.HO",
      "cs.AI"
    ],
    "primary_category": "math.HO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.03747v1",
    "published_date": "2025-04-08 15:33:51 UTC",
    "updated_date": "2025-04-08 15:33:51 UTC"
  },
  {
    "arxiv_id": "2504.06136v1",
    "title": "QGen Studio: An Adaptive Question-Answer Generation, Training and Evaluation Platform",
    "authors": [
      "Movina Moses",
      "Mohab Elkaref",
      "James Barry",
      "Shinnosuke Tanaka",
      "Vishnudev Kuruvanthodi",
      "Nathan Herr",
      "Campbell D Watson",
      "Geeth De Mel"
    ],
    "abstract": "We present QGen Studio: an adaptive question-answer generation, training, and\nevaluation platform. QGen Studio enables users to leverage large language\nmodels (LLMs) to create custom question-answer datasets and fine-tune models on\nthis synthetic data. It features a dataset viewer and model explorer to\nstreamline this process. The dataset viewer provides key metrics and visualizes\nthe context from which the QA pairs are generated, offering insights into data\nquality. The model explorer supports model comparison, allowing users to\ncontrast the performance of their trained LLMs against other models, supporting\nperformance benchmarking and refinement. QGen Studio delivers an interactive,\nend-to-end solution for generating QA datasets and training scalable,\ndomain-adaptable models. The studio will be open-sourced soon, allowing users\nto deploy it locally.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06136v1",
    "published_date": "2025-04-08 15:32:09 UTC",
    "updated_date": "2025-04-08 15:32:09 UTC"
  },
  {
    "arxiv_id": "2504.06135v1",
    "title": "Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index for Scalable Agent Reasoning",
    "authors": [
      "Tooraj Helmi"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) and vector-based search have become\nfoundational tools for memory in AI systems, yet they struggle with\nabstraction, scalability, and semantic precision - especially in decentralized\nenvironments. We present SHIMI (Semantic Hierarchical Memory Index), a unified\narchitecture that models knowledge as a dynamically structured hierarchy of\nconcepts, enabling agents to retrieve information based on meaning rather than\nsurface similarity. SHIMI organizes memory into layered semantic nodes and\nsupports top-down traversal from abstract intent to specific entities, offering\nmore precise and explainable retrieval. Critically, SHIMI is natively designed\nfor decentralized ecosystems, where agents maintain local memory trees and\nsynchronize them asynchronously across networks. We introduce a lightweight\nsync protocol that leverages Merkle-DAG summaries, Bloom filters, and\nCRDT-style conflict resolution to enable partial synchronization with minimal\noverhead. Through benchmark experiments and use cases involving decentralized\nagent collaboration, we demonstrate SHIMI's advantages in retrieval accuracy,\nsemantic fidelity, and scalability - positioning it as a core infrastructure\nlayer for decentralized cognitive systems.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06135v1",
    "published_date": "2025-04-08 15:31:00 UTC",
    "updated_date": "2025-04-08 15:31:00 UTC"
  },
  {
    "arxiv_id": "2504.06122v2",
    "title": "Leanabell-Prover: Posttraining Scaling in Formal Reasoning",
    "authors": [
      "Jingyuan Zhang",
      "Qi Wang",
      "Xingguang Ji",
      "Yahui Liu",
      "Yang Yue",
      "Fuzheng Zhang",
      "Di Zhang",
      "Guorui Zhou",
      "Kun Gai"
    ],
    "abstract": "Recent advances in automated theorem proving (ATP) through LLMs have\nhighlighted the potential of formal reasoning with Lean 4 codes. However, ATP\nhas not yet be revolutionized by the recent posttraining scaling as\ndemonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the\nentire posttraining of ATP, aiming to align it with breakthroughs in reasoning\nmodels in natural languages. To begin, we continual train current ATP models\nwith a hybrid dataset, which consists of numerous statement-proof pairs, and\nadditional data aimed at incorporating cognitive behaviors that emulate human\nreasoning and hypothesis refinement. Next, we explore reinforcement learning\nwith the use of outcome reward returned by Lean 4 compiler. Through our\ndesigned continual training and reinforcement learning processes, we have\nsuccessfully improved existing formal provers, including both\nDeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance\nin the field of whole-proof generation. For example, we achieve a 59.8% pass\nrate (pass@32) on MiniF2F. This is an on-going project and we will\nprogressively update our findings, release our data and training details.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.06122v2",
    "published_date": "2025-04-08 15:15:26 UTC",
    "updated_date": "2025-04-09 04:03:00 UTC"
  },
  {
    "arxiv_id": "2504.06105v1",
    "title": "Uncertainty-Aware Hybrid Machine Learning in Virtual Sensors for Vehicle Sideslip Angle Estimation",
    "authors": [
      "Abinav Kalyanasundaram",
      "Karthikeyan Chandra Sekaran",
      "Philipp Stauber",
      "Michael Lange",
      "Wolfgang Utschick",
      "Michael Botsch"
    ],
    "abstract": "Precise vehicle state estimation is crucial for safe and reliable autonomous\ndriving. The number of measurable states and their precision offered by the\nonboard vehicle sensor system are often constrained by cost. For instance,\nmeasuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses\nsignificant commercial challenges using current optical sensors. This paper\naddresses these limitations by focusing on the development of high-performance\nvirtual sensors to enhance vehicle state estimation for active safety. The\nproposed Uncertainty-Aware Hybrid Learning (UAHL) architecture integrates a\nmachine learning model with vehicle motion models to estimate VSA directly from\nonboard sensor data. A key aspect of the UAHL architecture is its focus on\nuncertainty quantification for individual model estimates and hybrid fusion.\nThese mechanisms enable the dynamic weighting of uncertainty-aware predictions\nfrom machine learning and vehicle motion models to produce accurate and\nreliable hybrid VSA estimates. This work also presents a novel dataset named\nReal-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized\nmeasurements from advanced vehicle dynamic sensors. The experimental results\ndemonstrate the superior performance of the proposed method for VSA estimation,\nhighlighting UAHL as a promising architecture for advancing virtual sensors and\nenhancing active safety in autonomous vehicles.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted at the 2025 IEEE Intelligent Vehicles Symposium (IV)",
    "pdf_url": "http://arxiv.org/pdf/2504.06105v1",
    "published_date": "2025-04-08 14:49:58 UTC",
    "updated_date": "2025-04-08 14:49:58 UTC"
  },
  {
    "arxiv_id": "2504.06099v1",
    "title": "Towards Varroa destructor mite detection using a narrow spectra illumination",
    "authors": [
      "Samuel Bielik",
      "Simon Bilik"
    ],
    "abstract": "This paper focuses on the development and modification of a beehive\nmonitoring device and Varroa destructor detection on the bees with the help of\nhyperspectral imagery while utilizing a U-net, semantic segmentation\narchitecture, and conventional computer vision methods. The main objectives\nwere to collect a dataset of bees and mites, and propose the computer vision\nmodel which can achieve the detection between bees and mites.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06099v1",
    "published_date": "2025-04-08 14:41:42 UTC",
    "updated_date": "2025-04-08 14:41:42 UTC"
  },
  {
    "arxiv_id": "2504.06091v1",
    "title": "Real-Time LaCAM",
    "authors": [
      "Runzhe Liang",
      "Rishi Veerapaneni",
      "Daniel Harabor",
      "Jiaoyang Li",
      "Maxim Likhachev"
    ],
    "abstract": "The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06091v1",
    "published_date": "2025-04-08 14:31:05 UTC",
    "updated_date": "2025-04-08 14:31:05 UTC"
  },
  {
    "arxiv_id": "2504.06088v1",
    "title": "MCAT: Visual Query-Based Localization of Standard Anatomical Clips in Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer",
    "authors": [
      "Divyanshu Mishra",
      "Pramit Saha",
      "He Zhao",
      "Netzahualcoyotl Hernandez-Cruz",
      "Olga Patey",
      "Aris Papageorghiou",
      "J. Alison Noble"
    ],
    "abstract": "Accurate standard plane acquisition in fetal ultrasound (US) videos is\ncrucial for fetal growth assessment, anomaly detection, and adherence to\nclinical guidelines. However, manually selecting standard frames is\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\nmethods primarily rely on image-based approaches that capture standard frames\nand then classify the input frames across different anatomies. This ignores the\ndynamic nature of video acquisition and its interpretation. To address these\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\nvisual query-based video clip localization (VQ-VCL) method, to assist\nsonographers by enabling them to capture a quick US sweep. By then providing a\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\ncontaining the standard frames for that anatomy, facilitating thorough\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\nefficiency and accuracy have significant potential implications for public\nhealth, especially in low- and middle-income countries (LMICs), where it may\nenhance prenatal care by streamlining standard plane acquisition, simplifying\nUS-based screening, diagnosis and allowing sonographers to examine more\npatients.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.06088v1",
    "published_date": "2025-04-08 14:29:15 UTC",
    "updated_date": "2025-04-08 14:29:15 UTC"
  },
  {
    "arxiv_id": "2504.08798v1",
    "title": "Exploring Gradient-Guided Masked Language Model to Detect Textual Adversarial Attacks",
    "authors": [
      "Xiaomei Zhang",
      "Zhaoxi Zhang",
      "Yanjun Zhang",
      "Xufei Zheng",
      "Leo Yu Zhang",
      "Shengshan Hu",
      "Shirui Pan"
    ],
    "abstract": "Textual adversarial examples pose serious threats to the reliability of\nnatural language processing systems. Recent studies suggest that adversarial\nexamples tend to deviate from the underlying manifold of normal texts, whereas\npre-trained masked language models can approximate the manifold of normal data.\nThese findings inspire the exploration of masked language models for detecting\ntextual adversarial attacks. We first introduce Masked Language Model-based\nDetection (MLMD), leveraging the mask and unmask operations of the masked\nlanguage modeling (MLM) objective to induce the difference in manifold changes\nbetween normal and adversarial texts. Although MLMD achieves competitive\ndetection performance, its exhaustive one-by-one masking strategy introduces\nsignificant computational overhead. Our posterior analysis reveals that a\nsignificant number of non-keywords in the input are not important for detection\nbut consume resources. Building on this, we introduce Gradient-guided MLMD\n(GradMLMD), which leverages gradient information to identify and skip\nnon-keywords during detection, significantly reducing resource consumption\nwithout compromising detection performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08798v1",
    "published_date": "2025-04-08 14:10:57 UTC",
    "updated_date": "2025-04-08 14:10:57 UTC"
  },
  {
    "arxiv_id": "2504.06330v1",
    "title": "Analyzing the Impact of Low-Rank Adaptation for Cross-Domain Few-Shot Object Detection in Aerial Images",
    "authors": [
      "Hicham Talaoubrid",
      "Anissa Mokraoui",
      "Ismail Ben Ayed",
      "Axel Prouvost",
      "Sonimith Hang",
      "Monit Korn",
      "Rémi Harvey"
    ],
    "abstract": "This paper investigates the application of Low-Rank Adaptation (LoRA) to\nsmall models for cross-domain few-shot object detection in aerial images.\nOriginally designed for large-scale models, LoRA helps mitigate overfitting,\nmaking it a promising approach for resource-constrained settings. We integrate\nLoRA into DiffusionDet, and evaluate its performance on the DOTA and DIOR\ndatasets. Our results show that LoRA applied after an initial fine-tuning\nslightly improves performance in low-shot settings (e.g., 1-shot and 5-shot),\nwhile full fine-tuning remains more effective in higher-shot configurations.\nThese findings highlight LoRA's potential for efficient adaptation in aerial\nobject detection, encouraging further research into parameter-efficient\nfine-tuning strategies for few-shot learning. Our code is available here:\nhttps://github.com/HichTala/LoRA-DiffusionDet.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06330v1",
    "published_date": "2025-04-08 14:10:39 UTC",
    "updated_date": "2025-04-08 14:10:39 UTC"
  },
  {
    "arxiv_id": "2504.06037v2",
    "title": "Confidence Regularized Masked Language Modeling using Text Length",
    "authors": [
      "Seunghyun Ji",
      "Soowon Lee"
    ],
    "abstract": "Masked language modeling is a widely used method for learning language\nrepresentations, where the model predicts a randomly masked word in each input.\nHowever, this approach typically considers only a single correct answer during\ntraining, ignoring the variety of plausible alternatives that humans might\nchoose. This issue becomes more pronounced when the input text is short, as the\npossible word distribution tends to have higher entropy, potentially causing\nthe model to become overconfident in its predictions. To mitigate this, we\npropose a novel confidence regularizer that adaptively adjusts the\nregularization strength based on the input length. Experiments on the GLUE and\nSQuAD benchmarks show that our method improves both accuracy and expected\ncalibration error",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.06037v2",
    "published_date": "2025-04-08 13:37:08 UTC",
    "updated_date": "2025-04-09 02:32:58 UTC"
  },
  {
    "arxiv_id": "2504.06020v1",
    "title": "Information-Theoretic Reward Decomposition for Generalizable RLHF",
    "authors": [
      "Liyuan Mao",
      "Haoran Xu",
      "Amy Zhang",
      "Weinan Zhang",
      "Chenjia Bai"
    ],
    "abstract": "A generalizable reward model is crucial in Reinforcement Learning from Human\nFeedback (RLHF) as it enables correctly evaluating unseen prompt-response\npairs. However, existing reward models lack this ability, as they are typically\ntrained by increasing the reward gap between chosen and rejected responses,\nwhile overlooking the prompts that the responses are conditioned on.\nConsequently, when the trained reward model is evaluated on prompt-response\npairs that lie outside the data distribution, neglecting the effect of prompts\nmay result in poor generalization of the reward model. To address this issue,\nwe decompose the reward value into two independent components: prompt-free\nreward and prompt-related reward. Prompt-free reward represents the evaluation\nthat is determined only by responses, while the prompt-related reward reflects\nthe reward that derives from both the prompt and the response. We extract these\ntwo components from an information-theoretic perspective, which requires no\nextra models. Subsequently, we propose a new reward learning algorithm by\nprioritizing data samples based on their prompt-free reward values. Through toy\nexamples, we demonstrate that the extracted prompt-free and prompt-related\nrewards effectively characterize two parts of the reward model. Further,\nstandard evaluations show that our method improves both the alignment\nperformance and the generalization capability of the reward model.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Work done during internships at Institute of Artificial Intelligence\n  (TeleAI), China Telecom",
    "pdf_url": "http://arxiv.org/pdf/2504.06020v1",
    "published_date": "2025-04-08 13:26:07 UTC",
    "updated_date": "2025-04-08 13:26:07 UTC"
  },
  {
    "arxiv_id": "2504.06328v1",
    "title": "A Geometric-Aware Perspective and Beyond: Hybrid Quantum-Classical Machine Learning Methods",
    "authors": [
      "Azadeh Alavia",
      "Hossein Akhoundib",
      "Fatemeh Kouchmeshkib",
      "Mojtaba Mahmoodianc",
      "Sanduni Jayasinghec",
      "Yongli Rena",
      "Abdolrahman Alavi"
    ],
    "abstract": "Geometric Machine Learning (GML) has shown that respecting non-Euclidean\ngeometry in data spaces can significantly improve performance over naive\nEuclidean assumptions. In parallel, Quantum Machine Learning (QML) has emerged\nas a promising paradigm that leverages superposition, entanglement, and\ninterference within quantum state manifolds for learning tasks. This paper\noffers a unifying perspective by casting QML as a specialized yet more\nexpressive branch of GML. We argue that quantum states, whether pure or mixed,\nreside on curved manifolds (e.g., projective Hilbert spaces or density-operator\nmanifolds), mirroring how covariance matrices inhabit the manifold of symmetric\npositive definite (SPD) matrices or how image sets occupy Grassmann manifolds.\nHowever, QML also benefits from purely quantum properties, such as\nentanglement-induced curvature, that can yield richer kernel structures and\nmore nuanced data embeddings.\n  We illustrate these ideas with published and newly discussed results,\nincluding hybrid classical -quantum pipelines for diabetic foot ulcer\nclassification and structural health monitoring. Despite near-term hardware\nlimitations that constrain purely quantum solutions, hybrid architectures\nalready demonstrate tangible benefits by combining classical manifold-based\nfeature extraction with quantum embeddings. We present a detailed mathematical\ntreatment of the geometrical underpinnings of quantum states, emphasizing\nparallels to classical Riemannian geometry and manifold-based optimization.\nFinally, we outline open research challenges and future directions, including\nQuantum Large Language Models (LLMs), quantum reinforcement learning, and\nemerging hardware approaches, demonstrating how synergizing GML and QML\nprinciples can unlock the next generation of machine intelligence.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "quant-ph",
    "comment": "19 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.06328v1",
    "published_date": "2025-04-08 13:24:55 UTC",
    "updated_date": "2025-04-08 13:24:55 UTC"
  },
  {
    "arxiv_id": "2504.06016v1",
    "title": "The Hall of AI Fears and Hopes: Comparing the Views of AI Influencers and those of Members of the U.S. Public Through an Interactive Platform",
    "authors": [
      "Gustavo Moreira",
      "Edyta Paulina Bogucka",
      "Marios Constantinides",
      "Daniele Quercia"
    ],
    "abstract": "AI development is shaped by academics and industry leaders - let us call them\n``influencers'' - but it is unclear how their views align with those of the\npublic. To address this gap, we developed an interactive platform that served\nas a data collection tool for exploring public views on AI, including their\nfears, hopes, and overall sense of hopefulness. We made the platform available\nto 330 participants representative of the U.S. population in terms of age, sex,\nethnicity, and political leaning, and compared their views with those of 100 AI\ninfluencers identified by Time magazine. The public fears AI getting out of\ncontrol, while influencers emphasize regulation, seemingly to deflect attention\nfrom their alleged focus on monetizing AI's potential. Interestingly, the views\nof AI influencers from underrepresented groups such as women and people of\ncolor often differ from the views of underrepresented groups in the public.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "I.2; K.4.1; K.4.2; K.4.3"
    ],
    "primary_category": "cs.HC",
    "comment": "27 pages, 11 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.06016v1",
    "published_date": "2025-04-08 13:21:31 UTC",
    "updated_date": "2025-04-08 13:21:31 UTC"
  },
  {
    "arxiv_id": "2504.06006v2",
    "title": "Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?",
    "authors": [
      "Roman Kochnev",
      "Arash Torabi Goodarzi",
      "Zofia Antonina Bentyn",
      "Dmitry Ignatov",
      "Radu Timofte"
    ],
    "abstract": "Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of leveraging large language models (LLMs) for hyperparameter\noptimization by fine-tuning a parameter-efficient version of Code Llama using\nLoRA. The adapted LLM is capable of generating accurate and efficient\nhyperparameter recommendations tailored to diverse neural network\narchitectures. Unlike traditional approaches such as Optuna, which rely on\ncomputationally intensive trial-and-error procedures, our method achieves\ncompetitive or superior results in terms of Root Mean Square Error (RMSE) while\nsignificantly reducing computational overhead. Our findings demonstrate that\nLLM-based optimization not only matches the performance of state-of-the-art\ntechniques like Tree-structured Parzen Estimators (TPE) but also substantially\naccelerates the tuning process. This positions LLMs as a promising alternative\nfor rapid experimentation, particularly in resource-constrained environments\nsuch as edge devices and mobile platforms, where computational efficiency is\nessential. In addition to improved efficiency, the method offers time savings\nand consistent performance across various tasks, highlighting its robustness\nand generalizability. All generated hyperparameters are included in the LEMUR\nNeural Network (NN) Dataset, which is publicly available and serves as an\nopen-source benchmark for hyperparameter optimization research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06006v2",
    "published_date": "2025-04-08 13:15:47 UTC",
    "updated_date": "2025-04-11 20:43:00 UTC"
  },
  {
    "arxiv_id": "2504.05995v1",
    "title": "NativQA Framework: Enabling LLMs with Native, Local, and Everyday Knowledge",
    "authors": [
      "Firoj Alam",
      "Md Arid Hasan",
      "Sahinur Rahman Laskar",
      "Mucahid Kutlu",
      "Shammur Absar Chowdhury"
    ],
    "abstract": "The rapid advancement of large language models (LLMs) has raised concerns\nabout cultural bias, fairness, and their applicability in diverse linguistic\nand underrepresented regional contexts. To enhance and benchmark the\ncapabilities of LLMs, there is a need to develop large-scale resources focused\non multilingual, local, and cultural contexts. In this study, we propose a\nframework, NativQA, that can seamlessly construct large-scale, culturally and\nregionally aligned QA datasets in native languages. The framework utilizes\nuser-defined seed queries and leverages search engines to collect\nlocation-specific, everyday information. It has been evaluated across 39\nlocations in 24 countries and in 7 languages, ranging from extremely\nlow-resource to high-resource languages, which resulted over 300K Question\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\nfurther fine-tuning. The framework has been made publicly available for the\ncommunity (https://gitlab.com/nativqa/nativqa-framework).",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50",
      "F.2.2; I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "LLMs, Native, Multilingual, Language Diversity, Contextual\n  Understanding, Minority Languages, Culturally Informed, Foundation Models,\n  Large Language Models",
    "pdf_url": "http://arxiv.org/pdf/2504.05995v1",
    "published_date": "2025-04-08 13:01:51 UTC",
    "updated_date": "2025-04-08 13:01:51 UTC"
  },
  {
    "arxiv_id": "2504.05956v1",
    "title": "Temporal Alignment-Free Video Matching for Few-shot Action Recognition",
    "authors": [
      "SuBeen Lee",
      "WonJun Moon",
      "Hyun Seok Seong",
      "Jae-Pil Heo"
    ],
    "abstract": "Few-Shot Action Recognition (FSAR) aims to train a model with only a few\nlabeled video instances. A key challenge in FSAR is handling divergent\nnarrative trajectories for precise video matching. While the frame- and\ntuple-level alignment approaches have been promising, their methods heavily\nrely on pre-defined and length-dependent alignment units (e.g., frames or\ntuples), which limits flexibility for actions of varying lengths and speeds. In\nthis work, we introduce a novel TEmporal Alignment-free Matching (TEAM)\napproach, which eliminates the need for temporal units in action representation\nand brute-force alignment during matching. Specifically, TEAM represents each\nvideo with a fixed set of pattern tokens that capture globally discriminative\nclues within the video instance regardless of action length or speed, ensuring\nits flexibility. Furthermore, TEAM is inherently efficient, using token-wise\ncomparisons to measure similarity between videos, unlike existing methods that\nrely on pairwise comparisons for temporal alignment. Additionally, we propose\nan adaptation process that identifies and removes common information across\nclasses, establishing clear boundaries even between novel categories. Extensive\nexperiments demonstrate the effectiveness of TEAM. Codes are available at\ngithub.com/leesb7426/TEAM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 7 figures, 6 tables, Accepted to CVPR 2025 as Oral\n  Presentation",
    "pdf_url": "http://arxiv.org/pdf/2504.05956v1",
    "published_date": "2025-04-08 12:11:11 UTC",
    "updated_date": "2025-04-08 12:11:11 UTC"
  },
  {
    "arxiv_id": "2504.05951v1",
    "title": "Representing Normative Regulations in OWL DL for Automated Compliance Checking Supported by Text Annotation",
    "authors": [
      "Ildar Baimuratov",
      "Denis Turygin"
    ],
    "abstract": "Compliance checking is the process of determining whether a regulated entity\nadheres to these regulations. Currently, compliance checking is predominantly\nmanual, requiring significant time and highly skilled experts, while still\nbeing prone to errors caused by the human factor. Various approaches have been\nexplored to automate compliance checking, however, representing regulations in\nOWL DL language which enables compliance checking through OWL reasoning has not\nbeen adopted. In this work, we propose an annotation schema and an algorithm\nthat transforms text annotations into machine-interpretable OWL DL code. The\nproposed approach is validated through a proof-of-concept implementation\napplied to examples from the building construction domain.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05951v1",
    "published_date": "2025-04-08 12:05:21 UTC",
    "updated_date": "2025-04-08 12:05:21 UTC"
  },
  {
    "arxiv_id": "2504.05950v1",
    "title": "AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems",
    "authors": [
      "Zhuoli Zhuang",
      "Cheng-You Lu",
      "Yu-Cheng Fred Chang",
      "Yu-Kai Wang",
      "Thomas Do",
      "Chin-Teng Lin"
    ],
    "abstract": "Improving decision-making capabilities in Autonomous Intelligent Vehicles\n(AIVs) has been a heated topic in recent years. Despite advancements, training\nmachines to capture regions of interest for comprehensive scene understanding,\nlike human perception and reasoning, remains a significant challenge. This\nstudy introduces a novel framework, Human Attention-based Explainable Guidance\nfor Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention,\nconverted from eye-tracking, to guide reinforcement learning (RL) models to\nidentify critical regions of interest for decision-making. AEGIS uses a\npre-trained human attention model to guide RL models to identify critical\nregions of interest for decision-making. By collecting 1.2 million frames from\n20 participants across six scenarios, AEGIS pre-trains a model to predict human\nattention patterns.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05950v1",
    "published_date": "2025-04-08 12:04:52 UTC",
    "updated_date": "2025-04-08 12:04:52 UTC"
  },
  {
    "arxiv_id": "2504.06325v1",
    "title": "MM-STFlowNet: A Transportation Hub-Oriented Multi-Mode Passenger Flow Prediction Method via Spatial-Temporal Dynamic Graph Modeling",
    "authors": [
      "Ronghui Zhang",
      "Wenbin Xing",
      "Mengran Li",
      "Zihan Wang",
      "Junzhou Chen",
      "Xiaolei Ma",
      "Zhiyuan Liu",
      "Zhengbing He"
    ],
    "abstract": "Accurate and refined passenger flow prediction is essential for optimizing\nthe collaborative management of multiple collection and distribution modes in\nlarge-scale transportation hubs. Traditional methods often focus only on the\noverall passenger volume, neglecting the interdependence between different\nmodes within the hub. To address this limitation, we propose MM-STFlowNet, a\ncomprehensive multi-mode prediction framework grounded in dynamic\nspatial-temporal graph modeling. Initially, an integrated temporal feature\nprocessing strategy is implemented using signal decomposition and convolution\ntechniques to address data spikes and high volatility. Subsequently, we\nintroduce the Spatial-Temporal Dynamic Graph Convolutional Recurrent Network\n(STDGCRN) to capture detailed spatial-temporal dependencies across multiple\ntraffic modes, enhanced by an adaptive channel attention mechanism. Finally,\nthe self-attention mechanism is applied to incorporate various external\nfactors, further enhancing prediction accuracy. Experiments on a real-world\ndataset from Guangzhounan Railway Station in China demonstrate that\nMM-STFlowNet achieves state-of-the-art performance, particularly during peak\nperiods, providing valuable insight for transportation hub management.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06325v1",
    "published_date": "2025-04-08 12:00:06 UTC",
    "updated_date": "2025-04-08 12:00:06 UTC"
  },
  {
    "arxiv_id": "2504.05945v1",
    "title": "CKGAN: Training Generative Adversarial Networks Using Characteristic Kernel Integral Probability Metrics",
    "authors": [
      "Kuntian Zhang",
      "Simin Yu",
      "Yaoshu Wang",
      "Makoto Onizuka",
      "Chuan Xiao"
    ],
    "abstract": "In this paper, we propose CKGAN, a novel generative adversarial network (GAN)\nvariant based on an integral probability metrics framework with characteristic\nkernel (CKIPM). CKIPM, as a distance between two probability distributions, is\ndesigned to optimize the lowerbound of the maximum mean discrepancy (MMD) in a\nreproducing kernel Hilbert space, and thus can be used to train GANs. CKGAN\nmitigates the notorious problem of mode collapse by mapping the generated\nimages back to random noise. To save the effort of selecting the kernel\nfunction manually, we propose a soft selection method to automatically learn a\ncharacteristic kernel function. The experimental evaluation conducted on a set\nof synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that\nCKGAN generally outperforms other MMD-based GANs. The results also show that at\nthe cost of moderately more training time, the automatically selected kernel\nfunction delivers very close performance to the best of manually fine-tuned one\non real image benchmarks and is able to improve the performances of other\nMMD-based GANs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Source codes are available at https://github.com/chuanxiao1983/CKGAN/",
    "pdf_url": "http://arxiv.org/pdf/2504.05945v1",
    "published_date": "2025-04-08 11:58:56 UTC",
    "updated_date": "2025-04-08 11:58:56 UTC"
  },
  {
    "arxiv_id": "2504.06324v1",
    "title": "From Stability to Inconsistency: A Study of Moral Preferences in LLMs",
    "authors": [
      "Monika Jotautaite",
      "Mary Phuong",
      "Chatrik Singh Mangat",
      "Maria Angelica Martinez"
    ],
    "abstract": "As large language models (LLMs) increasingly integrate into our daily lives,\nit becomes crucial to understand their implicit biases and moral tendencies. To\naddress this, we introduce a Moral Foundations LLM dataset (MFD-LLM) grounded\nin Moral Foundations Theory, which conceptualizes human morality through six\ncore foundations. We propose a novel evaluation method that captures the full\nspectrum of LLMs' revealed moral preferences by answering a range of real-world\nmoral dilemmas. Our findings reveal that state-of-the-art models have\nremarkably homogeneous value preferences, yet demonstrate a lack of\nconsistency.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06324v1",
    "published_date": "2025-04-08 11:52:50 UTC",
    "updated_date": "2025-04-08 11:52:50 UTC"
  },
  {
    "arxiv_id": "2504.06323v1",
    "title": "Mosaic: Composite Projection Pruning for Resource-efficient LLMs",
    "authors": [
      "Bailey J. Eccles",
      "Leon Wong",
      "Blesson Varghese"
    ],
    "abstract": "Extensive compute and memory requirements limit the deployment of large\nlanguage models (LLMs) on any hardware. Compression methods, such as pruning,\ncan reduce model size, which in turn reduces resource requirements.\nState-of-the-art pruning is based on coarse-grained methods. They are\ntime-consuming and inherently remove critical model parameters, adversely\nimpacting the quality of the pruned model. This paper introduces projection\npruning, a novel fine-grained method for pruning LLMs. In addition, LLM\nprojection pruning is enhanced by a new approach we refer to as composite\nprojection pruning - the synergistic combination of unstructured pruning that\nretains accuracy and structured pruning that reduces model size. We develop\nMosaic, a novel system to create and deploy pruned LLMs using composite\nprojection pruning. Mosaic is evaluated using a range of performance and\nquality metrics on multiple hardware platforms, LLMs, and datasets. Mosaic is\n7.19x faster in producing models than existing approaches. Mosaic models\nachieve up to 84.2% lower perplexity and 31.4% higher accuracy than models\nobtained from coarse-grained pruning. Up to 67% faster inference and 68% lower\nGPU memory use is noted for Mosaic models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06323v1",
    "published_date": "2025-04-08 11:51:35 UTC",
    "updated_date": "2025-04-08 11:51:35 UTC"
  },
  {
    "arxiv_id": "2504.05923v1",
    "title": "Uncovering Fairness through Data Complexity as an Early Indicator",
    "authors": [
      "Juliett Suárez Ferreira",
      "Marija Slavkovik",
      "Jorge Casillas"
    ],
    "abstract": "Fairness constitutes a concern within machine learning (ML) applications.\nCurrently, there is no study on how disparities in classification complexity\nbetween privileged and unprivileged groups could influence the fairness of\nsolutions, which serves as a preliminary indicator of potential unfairness. In\nthis work, we investigate this gap, specifically, we focus on synthetic\ndatasets designed to capture a variety of biases ranging from historical bias\nto measurement and representational bias to evaluate how various complexity\nmetrics differences correlate with group fairness metrics. We then apply\nassociation rule mining to identify patterns that link disproportionate\ncomplexity differences between groups with fairness-related outcomes, offering\ndata-centric indicators to guide bias mitigation. Our findings are also\nvalidated by their application in real-world problems, providing evidence that\nquantifying group-wise classification complexity can uncover early indicators\nof potential fairness challenges. This investigation helps practitioners to\nproactively address bias in classification tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DS"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05923v1",
    "published_date": "2025-04-08 11:28:40 UTC",
    "updated_date": "2025-04-08 11:28:40 UTC"
  },
  {
    "arxiv_id": "2504.05908v1",
    "title": "PRIMEDrive-CoT: A Precognitive Chain-of-Thought Framework for Uncertainty-Aware Object Interaction in Driving Scene Scenario",
    "authors": [
      "Sriram Mandalika",
      "Lalitha V",
      "Athira Nambiar"
    ],
    "abstract": "Driving scene understanding is a critical real-world problem that involves\ninterpreting and associating various elements of a driving environment, such as\nvehicles, pedestrians, and traffic signals. Despite advancements in autonomous\ndriving, traditional pipelines rely on deterministic models that fail to\ncapture the probabilistic nature and inherent uncertainty of real-world\ndriving. To address this, we propose PRIMEDrive-CoT, a novel uncertainty-aware\nmodel for object interaction and Chain-of-Thought (CoT) reasoning in driving\nscenarios. In particular, our approach combines LiDAR-based 3D object detection\nwith multi-view RGB references to ensure interpretable and reliable scene\nunderstanding. Uncertainty and risk assessment, along with object interactions,\nare modelled using Bayesian Graph Neural Networks (BGNNs) for probabilistic\nreasoning under ambiguous conditions. Interpretable decisions are facilitated\nthrough CoT reasoning, leveraging object dynamics and contextual cues, while\nGrad-CAM visualizations highlight attention regions. Extensive evaluations on\nthe DriveCoT dataset demonstrate that PRIMEDrive-CoT outperforms\nstate-of-the-art CoT and risk-aware models.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at The IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition 2025 - CVPRW",
    "pdf_url": "http://arxiv.org/pdf/2504.05908v1",
    "published_date": "2025-04-08 11:06:02 UTC",
    "updated_date": "2025-04-08 11:06:02 UTC"
  },
  {
    "arxiv_id": "2504.05882v1",
    "title": "Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban LiDAR Segmentation with Semi-Supervised Techniques",
    "authors": [
      "Luca Barco",
      "Giacomo Blanco",
      "Gaetano Chiriaco",
      "Alessia Intini",
      "Luigi La Riccia",
      "Vittorio Scolamiero",
      "Piero Boccardo",
      "Paolo Garza",
      "Fabrizio Dominici"
    ],
    "abstract": "3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPRW2025 - USM3D",
    "pdf_url": "http://arxiv.org/pdf/2504.05882v1",
    "published_date": "2025-04-08 10:17:14 UTC",
    "updated_date": "2025-04-08 10:17:14 UTC"
  },
  {
    "arxiv_id": "2504.06322v1",
    "title": "Assessing employment and labour issues implicated by using AI",
    "authors": [
      "Thijs Willems",
      "Darion Jin Hotan",
      "Jiawen Cheryl Tang",
      "Norakmal Hakim bin Norhashim",
      "King Wang Poon",
      "Zi An Galvyn Goh",
      "Radha Vinod"
    ],
    "abstract": "This chapter critiques the dominant reductionist approach in AI and work\nstudies, which isolates tasks and skills as replaceable components. Instead, it\nadvocates for a systemic perspective that emphasizes the interdependence of\ntasks, roles, and workplace contexts. Two complementary approaches are\nproposed: an ethnographic, context-rich method that highlights how AI\nreconfigures work environments and expertise; and a relational task-based\nanalysis that bridges micro-level work descriptions with macro-level labor\ntrends. The authors argue that effective AI impact assessments must go beyond\npredicting automation rates to include ethical, well-being, and\nexpertise-related questions. Drawing on empirical case studies, they\ndemonstrate how AI reshapes human-technology relations, professional roles, and\ntacit knowledge practices. The chapter concludes by calling for a\nhuman-centric, holistic framework that guides organizational and policy\ndecisions, balancing technological possibilities with social desirability and\nsustainability of work.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "This manuscript is accepted for publication in Emad Yaghmaei, et al.,\n  eds., Global Perspectives on AI Impact Assessment (Oxford University Press,\n  forthcoming 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.06322v1",
    "published_date": "2025-04-08 10:14:19 UTC",
    "updated_date": "2025-04-08 10:14:19 UTC"
  },
  {
    "arxiv_id": "2504.05874v2",
    "title": "Systematic Parameter Decision in Approximate Model Counting",
    "authors": [
      "Jinping Lei",
      "Toru Takisaka",
      "Junqiang Peng",
      "Mingyu Xiao"
    ],
    "abstract": "This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05874v2",
    "published_date": "2025-04-08 09:58:41 UTC",
    "updated_date": "2025-05-21 12:50:58 UTC"
  },
  {
    "arxiv_id": "2504.05871v1",
    "title": "Agent Guide: A Simple Agent Behavioral Watermarking Framework",
    "authors": [
      "Kaibo Huang",
      "Zhongliang Yang",
      "Linna Zhou"
    ],
    "abstract": "The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.",
    "categories": [
      "cs.AI",
      "K.6.5"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05871v1",
    "published_date": "2025-04-08 09:54:49 UTC",
    "updated_date": "2025-04-08 09:54:49 UTC"
  },
  {
    "arxiv_id": "2504.05862v2",
    "title": "Are Generative AI Agents Effective Personalized Financial Advisors?",
    "authors": [
      "Takehiro Takayanagi",
      "Kiyoshi Izumi",
      "Javier Sanz-Cruzado",
      "Richard McCreadie",
      "Iadh Ounis"
    ],
    "abstract": "Large language model-based agents are becoming increasingly popular as a\nlow-cost mechanism to provide personalized, conversational advice, and have\ndemonstrated impressive capabilities in relatively simple scenarios, such as\nmovie recommendations. But how do these agents perform in complex high-stakes\ndomains, where domain expertise is essential and mistakes carry substantial\nrisk? This paper investigates the effectiveness of LLM-advisors in the finance\ndomain, focusing on three distinct challenges: (1) eliciting user preferences\nwhen users themselves may be unsure of their needs, (2) providing personalized\nguidance for diverse investment preferences, and (3) leveraging advisor\npersonality to build relationships and foster trust. Via a lab-based user study\nwith 64 participants, we show that LLM-advisors often match human advisor\nperformance when eliciting preferences, although they can struggle to resolve\nconflicting user needs. When providing personalized advice, the LLM was able to\npositively influence user behavior, but demonstrated clear failure modes. Our\nresults show that accurate preference elicitation is key, otherwise, the\nLLM-advisor has little impact, or can even direct the investor toward\nunsuitable assets. More worryingly, users appear insensitive to the quality of\nadvice being given, or worse these can have an inverse relationship. Indeed,\nusers reported a preference for and increased satisfaction as well as emotional\ntrust with LLMs adopting an extroverted persona, even though those agents\nprovided worse advice.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "cs.IR",
      "q-fin.CP"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for presentation at SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05862v2",
    "published_date": "2025-04-08 09:41:03 UTC",
    "updated_date": "2025-04-15 01:14:43 UTC"
  },
  {
    "arxiv_id": "2504.05857v1",
    "title": "Towards an AI-Driven Video-Based American Sign Language Dictionary: Exploring Design and Usage Experience with Learners",
    "authors": [
      "Saad Hassan",
      "Matyas Bohacek",
      "Chaelin Kim",
      "Denise Crochet"
    ],
    "abstract": "Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05857v1",
    "published_date": "2025-04-08 09:35:46 UTC",
    "updated_date": "2025-04-08 09:35:46 UTC"
  },
  {
    "arxiv_id": "2504.05855v1",
    "title": "Enhancing Coreference Resolution with Pretrained Language Models: Bridging the Gap Between Syntax and Semantics",
    "authors": [
      "Xingzu Liu",
      "Songhang deng",
      "Mingbang Wang",
      "Zhang Dong",
      "Le Dai",
      "Jiyuan Li",
      "Ruilin Nong"
    ],
    "abstract": "Large language models have made significant advancements in various natural\nlanguage processing tasks, including coreference resolution. However,\ntraditional methods often fall short in effectively distinguishing referential\nrelationships due to a lack of integration between syntactic and semantic\ninformation. This study introduces an innovative framework aimed at enhancing\ncoreference resolution by utilizing pretrained language models. Our approach\ncombines syntax parsing with semantic role labeling to accurately capture finer\ndistinctions in referential relationships. By employing state-of-the-art\npretrained models to gather contextual embeddings and applying an attention\nmechanism for fine-tuning, we improve the performance of coreference tasks.\nExperimental results across diverse datasets show that our method surpasses\nconventional coreference resolution systems, achieving notable accuracy in\ndisambiguating references. This development not only improves coreference\nresolution outcomes but also positively impacts other natural language\nprocessing tasks that depend on precise referential understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "acl submission",
    "pdf_url": "http://arxiv.org/pdf/2504.05855v1",
    "published_date": "2025-04-08 09:33:09 UTC",
    "updated_date": "2025-04-08 09:33:09 UTC"
  },
  {
    "arxiv_id": "2504.05852v1",
    "title": "Physics-aware generative models for turbulent fluid flows through energy-consistent stochastic interpolants",
    "authors": [
      "Nikolaj T. Mücke",
      "Benjamin Sanderse"
    ],
    "abstract": "Generative models have demonstrated remarkable success in domains such as\ntext, image, and video synthesis. In this work, we explore the application of\ngenerative models to fluid dynamics, specifically for turbulence simulation,\nwhere classical numerical solvers are computationally expensive. We propose a\nnovel stochastic generative model based on stochastic interpolants, which\nenables probabilistic forecasting while incorporating physical constraints such\nas energy stability and divergence-freeness. Unlike conventional stochastic\ngenerative models, which are often agnostic to underlying physical laws, our\napproach embeds energy consistency by making the parameters of the stochastic\ninterpolant learnable coefficients. We evaluate our method on a benchmark\nturbulence problem - Kolmogorov flow - demonstrating superior accuracy and\nstability over state-of-the-art alternatives such as autoregressive conditional\ndiffusion models (ACDMs) and PDE-Refiner. Furthermore, we achieve stable\nresults for significantly longer roll-outs than standard stochastic\ninterpolants. Our results highlight the potential of physics-aware generative\nmodels in accelerating and enhancing turbulence simulations while preserving\nfundamental conservation properties.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.CE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05852v1",
    "published_date": "2025-04-08 09:29:01 UTC",
    "updated_date": "2025-04-08 09:29:01 UTC"
  },
  {
    "arxiv_id": "2504.05846v1",
    "title": "PathGPT: Leveraging Large Language Models for Personalized Route Generation",
    "authors": [
      "Steeve Cuthbert Marcelyn",
      "Yucen Gao",
      "Yuzhe Zhang",
      "Xiaofeng Gao",
      "Guihai Chen"
    ],
    "abstract": "The proliferation of GPS enabled devices has led to the accumulation of a\nsubstantial corpus of historical trajectory data. By leveraging these data for\ntraining machine learning models,researchers have devised novel data-driven\nmethodologies that address the personalized route recommendation (PRR) problem.\nIn contrast to conventional algorithms such as Dijkstra shortest path\nalgorithm,these novel algorithms possess the capacity to discern and learn\npatterns within the data,thereby facilitating the generation of more\npersonalized paths. However,once these models have been trained,their\napplication is constrained to the generation of routes that align with their\ntraining patterns. This limitation renders them less adaptable to novel\nscenarios and the deployment of multiple machine learning models might be\nnecessary to address new possible scenarios,which can be costly as each model\nmust be trained separately. Inspired by recent advances in the field of Large\nLanguage Models (LLMs),we leveraged their natural language understanding\ncapabilities to develop a unified model to solve the PRR problem while being\nseamlessly adaptable to new scenarios without additional training. To\naccomplish this,we combined the extensive knowledge LLMs acquired during\ntraining with further access to external hand-crafted context\ninformation,similar to RAG (Retrieved Augmented Generation) systems,to enhance\ntheir ability to generate paths according to user-defined requirements.\nExtensive experiments on different datasets show a considerable uplift in LLM\nperformance on the PRR problem.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05846v1",
    "published_date": "2025-04-08 09:25:21 UTC",
    "updated_date": "2025-04-08 09:25:21 UTC"
  },
  {
    "arxiv_id": "2504.06320v1",
    "title": "Hybrid Temporal Differential Consistency Autoencoder for Efficient and Sustainable Anomaly Detection in Cyber-Physical Systems",
    "authors": [
      "Michael Somma"
    ],
    "abstract": "Cyberattacks on critical infrastructure, particularly water distribution\nsystems, have increased due to rapid digitalization and the integration of IoT\ndevices and industrial control systems (ICS). These cyber-physical systems\n(CPS) introduce new vulnerabilities, requiring robust and automated intrusion\ndetection systems (IDS) to mitigate potential threats. This study addresses key\nchallenges in anomaly detection by leveraging time correlations in sensor data,\nintegrating physical principles into machine learning models, and optimizing\ncomputational efficiency for edge applications. We build upon the concept of\ntemporal differential consistency (TDC) loss to capture the dynamics of the\nsystem, ensuring meaningful relationships between dynamic states. Expanding on\nthis foundation, we propose a hybrid autoencoder-based approach, referred to as\nhybrid TDC-AE, which extends TDC by incorporating both deterministic nodes and\nconventional statistical nodes. This hybrid structure enables the model to\naccount for non-deterministic processes. Our approach achieves state-of-the-art\nclassification performance while improving time to detect anomalies by 3%,\noutperforming the BATADAL challenge leader without requiring domain-specific\nknowledge, making it broadly applicable. Additionally, it maintains the\ncomputational efficiency of conventional autoencoders while reducing the number\nof fully connected layers, resulting in a more sustainable and efficient\nsolution. The method demonstrates how leveraging physics-inspired consistency\nprinciples enhances anomaly detection and strengthens the resilience of\ncyber-physical systems.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06320v1",
    "published_date": "2025-04-08 09:22:44 UTC",
    "updated_date": "2025-04-08 09:22:44 UTC"
  },
  {
    "arxiv_id": "2504.05840v1",
    "title": "Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed RL Environments",
    "authors": [
      "Dolton Fernandes",
      "Pramod Kaushik",
      "Harsh Shukla",
      "Bapi Raju Surampudi"
    ],
    "abstract": "Traditional Reinforcement Learning (RL) algorithms assume the distribution of\nthe data to be uniform or mostly uniform. However, this is not the case with\nmost real-world applications like autonomous driving or in nature where animals\nroam. Some experiences are encountered frequently, and most of the remaining\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\ninspiration from the theory of complementary learning systems, an architecture\nfor learning from Zipfian distributions is proposed where important long tail\ntrajectories are discovered in an unsupervised manner. The proposal comprises\nan episodic memory buffer containing a prioritised memory module to ensure\nimportant rare trajectories are kept longer to address the Zipfian problem,\nwhich needs credit assignment to happen in a sample efficient manner. The\nexperiences are then reinstated from episodic memory and given weighted\nimportance forming the trajectory to be executed. Notably, the proposed\narchitecture is modular, can be incorporated in any RL architecture and yields\nimproved performance in multiple Zipfian tasks over traditional architectures.\nOur method outperforms IMPALA by a significant margin on all three tasks and\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\ngives improvements on most Atari environments that are considered challenging",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05840v1",
    "published_date": "2025-04-08 09:21:39 UTC",
    "updated_date": "2025-04-08 09:21:39 UTC"
  },
  {
    "arxiv_id": "2504.05838v1",
    "title": "Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking",
    "authors": [
      "Junxi Chen",
      "Junhao Dong",
      "Xiaohua Xie"
    ],
    "abstract": "Recently, the Image Prompt Adapter (IP-Adapter) has been increasingly\nintegrated into text-to-image diffusion models (T2I-DMs) to improve\ncontrollability. However, in this paper, we reveal that T2I-DMs equipped with\nthe IP-Adapter (T2I-IP-DMs) enable a new jailbreak attack named the hijacking\nattack. We demonstrate that, by uploading imperceptible image-space adversarial\nexamples (AEs), the adversary can hijack massive benign users to jailbreak an\nImage Generation Service (IGS) driven by T2I-IP-DMs and mislead the public to\ndiscredit the service provider. Worse still, the IP-Adapter's dependency on\nopen-source image encoders reduces the knowledge required to craft AEs.\nExtensive experiments verify the technical feasibility of the hijacking attack.\nIn light of the revealed threat, we investigate several existing defenses and\nexplore combining the IP-Adapter with adversarially trained models to overcome\nexisting defenses' limitations. Our code is available at\nhttps://github.com/fhdnskfbeuv/attackIPA.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2025 as Highlight",
    "pdf_url": "http://arxiv.org/pdf/2504.05838v1",
    "published_date": "2025-04-08 09:20:29 UTC",
    "updated_date": "2025-04-08 09:20:29 UTC"
  },
  {
    "arxiv_id": "2504.06319v1",
    "title": "Accelerating LLM Inference Throughput via Asynchronous KV Cache Prefetching",
    "authors": [
      "Yanhao Dong",
      "Yubo Miao",
      "Weinan Li",
      "Xiao Zheng",
      "Chao Wang",
      "Feng Lyu"
    ],
    "abstract": "Large Language Models (LLMs) exhibit pronounced memory-bound characteristics\nduring inference due to High Bandwidth Memory (HBM) bandwidth constraints. In\nthis paper, we propose an L2 Cache-oriented asynchronous KV Cache prefetching\nmethod to break through the memory bandwidth bottleneck in LLM inference\nthrough computation-load overlap. By strategically scheduling idle memory\nbandwidth during active computation windows, our method proactively prefetches\nrequired KV Cache into GPU L2 cache, enabling high-speed L2 cache hits for\nsubsequent accesses and effectively hiding HBM access latency within\ncomputational cycles. Extensive experiments on NVIDIA H20 GPUs demonstrate that\nthe proposed method achieves 2.15x improvement in attention kernel efficiency\nand up to 1.97x end-to-end throughput enhancement, surpassing state-of-the-art\nbaseline FlashAttention-3. Notably, our solution maintains orthogonality to\nexisting optimization techniques and can be integrated with current inference\nframeworks, providing a scalable latency-hiding solution for next-generation\nLLM inference engines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.06319v1",
    "published_date": "2025-04-08 09:17:35 UTC",
    "updated_date": "2025-04-08 09:17:35 UTC"
  },
  {
    "arxiv_id": "2504.05830v1",
    "title": "Human Activity Recognition using RGB-Event based Sensors: A Multi-modal Heat Conduction Model and A Benchmark Dataset",
    "authors": [
      "Shiao Wang",
      "Xiao Wang",
      "Bo Jiang",
      "Lin Zhu",
      "Guoqi Li",
      "Yaowei Wang",
      "Yonghong Tian",
      "Jin Tang"
    ],
    "abstract": "Human Activity Recognition (HAR) primarily relied on traditional RGB cameras\nto achieve high-performance activity recognition. However, the challenging\nfactors in real-world scenarios, such as insufficient lighting and rapid\nmovements, inevitably degrade the performance of RGB cameras. To address these\nchallenges, biologically inspired event cameras offer a promising solution to\novercome the limitations of traditional RGB cameras. In this work, we rethink\nhuman activity recognition by combining the RGB and event cameras. The first\ncontribution is the proposed large-scale multi-modal RGB-Event human activity\nrecognition benchmark dataset, termed HARDVS 2.0, which bridges the dataset\ngaps. It contains 300 categories of everyday real-world actions with a total of\n107,646 paired videos covering various challenging scenarios. Inspired by the\nphysics-informed heat conduction model, we propose a novel multi-modal heat\nconduction operation framework for effective activity recognition, termed\nMMHCO-HAR. More in detail, given the RGB frames and event streams, we first\nextract the feature embeddings using a stem network. Then, multi-modal Heat\nConduction blocks are designed to fuse the dual features, the key module of\nwhich is the multi-modal Heat Conduction Operation layer. We integrate RGB and\nevent embeddings through a multi-modal DCT-IDCT layer while adaptively\nincorporating the thermal conductivity coefficient via FVEs into this module.\nAfter that, we propose an adaptive fusion module based on a policy routing\nstrategy for high-performance classification. Comprehensive experiments\ndemonstrate that our method consistently performs well, validating its\neffectiveness and robustness. The source code and benchmark dataset will be\nreleased on https://github.com/Event-AHU/HARDVS/tree/HARDVSv2",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Journal Extension of HARDVS (AAAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2504.05830v1",
    "published_date": "2025-04-08 09:14:24 UTC",
    "updated_date": "2025-04-08 09:14:24 UTC"
  },
  {
    "arxiv_id": "2504.05815v1",
    "title": "Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models",
    "authors": [
      "Jiahao Chen",
      "Yu Pan",
      "Yi Du",
      "Chunkai Wu",
      "Lin Wang"
    ],
    "abstract": "Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05815v1",
    "published_date": "2025-04-08 08:53:47 UTC",
    "updated_date": "2025-04-08 08:53:47 UTC"
  },
  {
    "arxiv_id": "2504.05806v1",
    "title": "Meta-Continual Learning of Neural Fields",
    "authors": [
      "Seungyoon Woo",
      "Junhyeog Yun",
      "Gunhee Kim"
    ],
    "abstract": "Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05806v1",
    "published_date": "2025-04-08 08:38:37 UTC",
    "updated_date": "2025-04-08 08:38:37 UTC"
  },
  {
    "arxiv_id": "2504.05804v1",
    "title": "StealthRank: LLM Ranking Manipulation via Stealthy Prompt Optimization",
    "authors": [
      "Yiming Tang",
      "Yi Fan",
      "Chenxiao Yu",
      "Tiankai Yang",
      "Yue Zhao",
      "Xiyang Hu"
    ],
    "abstract": "The integration of large language models (LLMs) into information retrieval\nsystems introduces new attack surfaces, particularly for adversarial ranking\nmanipulations. We present StealthRank, a novel adversarial ranking attack that\nmanipulates LLM-driven product recommendation systems while maintaining textual\nfluency and stealth. Unlike existing methods that often introduce detectable\nanomalies, StealthRank employs an energy-based optimization framework combined\nwith Langevin dynamics to generate StealthRank Prompts (SRPs)-adversarial text\nsequences embedded within product descriptions that subtly yet effectively\ninfluence LLM ranking mechanisms. We evaluate StealthRank across multiple LLMs,\ndemonstrating its ability to covertly boost the ranking of target products\nwhile avoiding explicit manipulation traces that can be easily detected. Our\nresults show that StealthRank consistently outperforms state-of-the-art\nadversarial ranking baselines in both effectiveness and stealth, highlighting\ncritical vulnerabilities in LLM-driven recommendation systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05804v1",
    "published_date": "2025-04-08 08:36:18 UTC",
    "updated_date": "2025-04-08 08:36:18 UTC"
  },
  {
    "arxiv_id": "2504.05801v1",
    "title": "From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and LLM",
    "authors": [
      "Jianyu Liu",
      "Yi Huang",
      "Sheng Bi",
      "Junlan Feng",
      "Guilin Qi"
    ],
    "abstract": "In a conversational system, dynamically generating follow-up questions based\non context can help users explore information and provide a better user\nexperience. Humans are usually able to ask questions that involve some general\nlife knowledge and demonstrate higher order cognitive skills. However, the\nquestions generated by existing methods are often limited to shallow contextual\nquestions that are uninspiring and have a large gap to the human level. In this\npaper, we propose a three-stage external knowledge-enhanced follow-up question\ngeneration method, which generates questions by identifying contextual topics,\nconstructing a knowledge graph (KG) online, and finally combining these with a\nlarge language model to generate the final question. The model generates\ninformation-rich and exploratory follow-up questions by introducing external\ncommon sense knowledge and performing a knowledge fusion operation. Experiments\nshow that compared to baseline models, our method generates questions that are\nmore informative and closer to human questioning levels while maintaining\ncontextual relevance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Proceedings of the 31st International Conference on Computational\n  Linguistics",
    "pdf_url": "http://arxiv.org/pdf/2504.05801v1",
    "published_date": "2025-04-08 08:31:03 UTC",
    "updated_date": "2025-04-08 08:31:03 UTC"
  },
  {
    "arxiv_id": "2504.10500v1",
    "title": "Leveraging Auto-Distillation and Generative Self-Supervised Learning in Residual Graph Transformers for Enhanced Recommender Systems",
    "authors": [
      "Eya Mhedhbi",
      "Youssef Mourchid",
      "Alice Othmani"
    ],
    "abstract": "This paper introduces a cutting-edge method for enhancing recommender systems\nthrough the integration of generative self-supervised learning (SSL) with a\nResidual Graph Transformer. Our approach emphasizes the importance of superior\ndata enhancement through the use of pertinent pretext tasks, automated through\nrationale-aware SSL to distill clear ways of how users and items interact. The\nResidual Graph Transformer incorporates a topology-aware transformer for global\ncontext and employs residual connections to improve graph representation\nlearning. Additionally, an auto-distillation process refines self-supervised\nsignals to uncover consistent collaborative rationales. Experimental\nevaluations on multiple datasets demonstrate that our approach consistently\noutperforms baseline methods.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.10500v1",
    "published_date": "2025-04-08 08:15:04 UTC",
    "updated_date": "2025-04-08 08:15:04 UTC"
  },
  {
    "arxiv_id": "2504.05786v1",
    "title": "How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM",
    "authors": [
      "Jirong Zha",
      "Yuxuan Fan",
      "Xiao Yang",
      "Chen Gao",
      "Xinlei Chen"
    ],
    "abstract": "3D spatial understanding is essential in real-world applications such as\nrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,\nLarge Language Models (LLMs), having demonstrated remarkable success across\nvarious domains, have been leveraged to enhance 3D understanding tasks, showing\npotential to surpass traditional computer vision methods. In this survey, we\npresent a comprehensive review of methods integrating LLMs with 3D spatial\nunderstanding. We propose a taxonomy that categorizes existing methods into\nthree branches: image-based methods deriving 3D understanding from 2D visual\ndata, point cloud-based methods working directly with 3D representations, and\nhybrid modality-based methods combining multiple data streams. We\nsystematically review representative methods along these categories, covering\ndata representations, architectural modifications, and training strategies that\nbridge textual and 3D modalities. Finally, we discuss current limitations,\nincluding dataset scarcity and computational challenges, while highlighting\npromising research directions in spatial perception, multi-modal fusion, and\nreal-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05786v1",
    "published_date": "2025-04-08 08:11:39 UTC",
    "updated_date": "2025-04-08 08:11:39 UTC"
  },
  {
    "arxiv_id": "2504.05783v1",
    "title": "Video Flow as Time Series: Discovering Temporal Consistency and Variability for VideoQA",
    "authors": [
      "Zijie Song",
      "Zhenzhen Hu",
      "Yixiao Ma",
      "Jia Li",
      "Richang Hong"
    ],
    "abstract": "Video Question Answering (VideoQA) is a complex video-language task that\ndemands a sophisticated understanding of both visual content and temporal\ndynamics. Traditional Transformer-style architectures, while effective in\nintegrating multimodal data, often simplify temporal dynamics through\npositional encoding and fail to capture non-linear interactions within video\nsequences. In this paper, we introduce the Temporal Trio Transformer (T3T), a\nnovel architecture that models time consistency and time variability. The T3T\nintegrates three key components: Temporal Smoothing (TS), Temporal Difference\n(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge for\ncapturing smooth, continuous temporal transitions, while the TD module\nidentifies and encodes significant temporal variations and abrupt changes\nwithin the video content. Subsequently, the TF module synthesizes these\ntemporal features with textual cues, facilitating a deeper contextual\nunderstanding and response accuracy. The efficacy of the T3T is demonstrated\nthrough extensive testing on multiple VideoQA benchmark datasets. Our results\nunderscore the importance of a nuanced approach to temporal modeling in\nimproving the accuracy and depth of video-based question answering.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05783v1",
    "published_date": "2025-04-08 08:08:03 UTC",
    "updated_date": "2025-04-08 08:08:03 UTC"
  },
  {
    "arxiv_id": "2504.05782v1",
    "title": "MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in Multimodal Large Language Models",
    "authors": [
      "Pengfei Zhou",
      "Fanrui Zhang",
      "Xiaopeng Peng",
      "Zhaopan Xu",
      "Jiaxin Ai",
      "Yansheng Qiu",
      "Chuanhao Li",
      "Zhen Li",
      "Ming Li",
      "Yukang Feng",
      "Jianwen Sun",
      "Haoquan Zhang",
      "Zizhen Li",
      "Xiaofeng Mao",
      "Wangbo Zhao",
      "Kai Wang",
      "Xiaojun Chang",
      "Wenqi Shao",
      "Yang You",
      "Kaipeng Zhang"
    ],
    "abstract": "Multimodal reasoning, which integrates language and visual cues into problem\nsolving and decision making, is a fundamental aspect of human intelligence and\na crucial step toward artificial general intelligence. However, the evaluation\nof multimodal reasoning capabilities in Multimodal Large Language Models\n(MLLMs) remains inadequate. Most existing reasoning benchmarks are constrained\nby limited data size, narrow domain coverage, and unstructured knowledge\ndistribution. To close these gaps, we introduce MDK12-Bench, a\nmulti-disciplinary benchmark assessing the reasoning capabilities of MLLMs via\nreal-world K-12 examinations. Spanning six disciplines (math, physics,\nchemistry, biology, geography, and information science), our benchmark\ncomprises 140K reasoning instances across diverse difficulty levels from\nprimary school to 12th grade. It features 6,827 instance-level knowledge point\nannotations based on a well-organized knowledge structure, detailed answer\nexplanations, difficulty labels and cross-year partitions, providing a robust\nplatform for comprehensive evaluation. Additionally, we present a novel dynamic\nevaluation framework to mitigate data contamination issues by bootstrapping\nquestion forms, question types, and image styles during evaluation. Extensive\nexperiment on MDK12-Bench reveals the significant limitation of current MLLMs\nin multimodal reasoning. The findings on our benchmark provide insights into\nthe development of the next-generation models. Our data and codes are available\nat https://github.com/LanceZPF/MDK12.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05782v1",
    "published_date": "2025-04-08 08:06:53 UTC",
    "updated_date": "2025-04-08 08:06:53 UTC"
  },
  {
    "arxiv_id": "2504.05774v1",
    "title": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation",
    "authors": [
      "Enming Zhang",
      "Zhengyu Li",
      "Yanru Wu",
      "Jingge Wang",
      "Yang Tan",
      "Ruizhe Zhao",
      "Guan Wang",
      "Yang Li"
    ],
    "abstract": "Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05774v1",
    "published_date": "2025-04-08 07:53:51 UTC",
    "updated_date": "2025-04-08 07:53:51 UTC"
  },
  {
    "arxiv_id": "2504.05770v1",
    "title": "A Lightweight Multi-Module Fusion Approach for Korean Character Recognition",
    "authors": [
      "Inho Jake Park",
      "Jaehoon Jay Jeong",
      "Ho-Sang Jo"
    ],
    "abstract": "Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T07",
      "I.2.10"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.05770v1",
    "published_date": "2025-04-08 07:50:19 UTC",
    "updated_date": "2025-04-08 07:50:19 UTC"
  },
  {
    "arxiv_id": "2504.05768v1",
    "title": "Temporal Dynamic Embedding for Irregularly Sampled Time Series",
    "authors": [
      "Mincheol Kim",
      "Soo-Yong Shin"
    ],
    "abstract": "In several practical applications, particularly healthcare, clinical data of\neach patient is individually recorded in a database at irregular intervals as\nrequired. This causes a sparse and irregularly sampled time series, which makes\nit difficult to handle as a structured representation of the prerequisites of\nneural network models. We therefore propose temporal dynamic embedding (TDE),\nwhich enables neural network models to receive data that change the number of\nvariables over time. TDE regards each time series variable as an embedding\nvector evolving over time, instead of a conventional fixed structured\nrepresentation, which causes a critical missing problem. For each time step,\nTDE allows for the selective adoption and aggregation of only observed variable\nsubsets and represents the current status of patient based on current\nobservations. The experiment was conducted on three clinical datasets:\nPhysioNet 2012, MIMIC-III, and PhysioNet 2019. The TDE model performed\ncompetitively or better than the imputation-based baseline and several recent\nstate-of-the-art methods with reduced training runtime.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05768v1",
    "published_date": "2025-04-08 07:49:22 UTC",
    "updated_date": "2025-04-08 07:49:22 UTC"
  },
  {
    "arxiv_id": "2504.05755v2",
    "title": "Unraveling Human-AI Teaming: A Review and Outlook",
    "authors": [
      "Bowen Lou",
      "Tian Lu",
      "T. S. Raghu",
      "Yingjie Zhang"
    ],
    "abstract": "Artificial Intelligence (AI) is advancing at an unprecedented pace, with\nclear potential to enhance decision-making and productivity. Yet, the\ncollaborative decision-making process between humans and AI remains\nunderdeveloped, often falling short of its transformative possibilities. This\npaper explores the evolution of AI agents from passive tools to active\ncollaborators in human-AI teams, emphasizing their ability to learn, adapt, and\noperate autonomously in complex environments. This paradigm shifts challenges\ntraditional team dynamics, requiring new interaction protocols, delegation\nstrategies, and responsibility distribution frameworks. Drawing on Team\nSituation Awareness (SA) theory, we identify two critical gaps in current\nhuman-AI teaming research: the difficulty of aligning AI agents with human\nvalues and objectives, and the underutilization of AI's capabilities as genuine\nteam members. Addressing these gaps, we propose a structured research outlook\ncentered on four key aspects of human-AI teaming: formulation, coordination,\nmaintenance, and training. Our framework highlights the importance of shared\nmental models, trust-building, conflict resolution, and skill adaptation for\neffective teaming. Furthermore, we discuss the unique challenges posed by\nvarying team compositions, goals, and complexities. This paper provides a\nfoundational agenda for future research and practical design of sustainable,\nhigh-performing human-AI teams.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05755v2",
    "published_date": "2025-04-08 07:37:25 UTC",
    "updated_date": "2025-04-09 12:20:05 UTC"
  },
  {
    "arxiv_id": "2504.07140v2",
    "title": "Secure Text Mail Encryption with Generative Adversarial Networks",
    "authors": [
      "Alexej Schelle"
    ],
    "abstract": "This work presents an encryption model based on Generative Adversarial\nNetworks (GANs). Encryption of RTF-8 data is realized by dynamically generating\ndecimal numbers that lead to the encryption and decryption of alphabetic\nstrings in integer representation by simple addition rules, the modulus of the\ndimension of the considered alphabet. The binary numbers for the private\ndynamic keys correspond to the binary numbers of public reference keys, as\ndefined by a specific GAN configuration. For reversible encryption with a\nbijective mapping between dynamic and reference keys, as defined by the GAN\nencryptor, secure text encryption can be achieved by transferring a\nGAN-encrypted public key along with the encrypted text from a sender to a\nreceiver. Using the technique described above, secure text mail transfer can be\nrealized through component-wise encryption and decryption of text mail strings,\nwith total key sizes of up to $10^{8}$ bits that define random decimal numbers\ngenerated by the GAN. From the present model, we assert that encrypted texts\ncan be transmitted more efficiently and securely than from RSA encryption, as\nlong as users of the specific configuration of the GAN encryption model are\nunaware of the GAN encryptor circuit and configuration, respectively.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "7 pages, 3 figures, one table; Preprint before publication",
    "pdf_url": "http://arxiv.org/pdf/2504.07140v2",
    "published_date": "2025-04-08 07:27:57 UTC",
    "updated_date": "2025-04-14 10:48:41 UTC"
  },
  {
    "arxiv_id": "2504.05741v2",
    "title": "DDT: Decoupled Diffusion Transformer",
    "authors": [
      "Shuai Wang",
      "Zhi Tian",
      "Weilin Huang",
      "Limin Wang"
    ],
    "abstract": "Diffusion transformers have demonstrated remarkable generation quality,\nalbeit requiring longer training iterations and numerous inference steps. In\neach denoising step, diffusion transformers encode the noisy inputs to extract\nthe lower-frequency semantic component and then decode the higher frequency\nwith identical modules. This scheme creates an inherent optimization dilemma:\nencoding low-frequency semantics necessitates reducing high-frequency\ncomponents, creating tension between semantic encoding and high-frequency\ndecoding. To resolve this challenge, we propose a new\n\\textbf{\\color{ddt}D}ecoupled \\textbf{\\color{ddt}D}iffusion\n\\textbf{\\color{ddt}T}ransformer~(\\textbf{\\color{ddt}DDT}), with a decoupled\ndesign of a dedicated condition encoder for semantic extraction alongside a\nspecialized velocity decoder. Our experiments reveal that a more substantial\nencoder yields performance improvements as model size increases. For ImageNet\n$256\\times256$, Our DDT-XL/2 achieves a new state-of-the-art performance of\n{1.31 FID}~(nearly $4\\times$ faster training convergence compared to previous\ndiffusion transformers). For ImageNet $512\\times512$, Our DDT-XL/2 achieves a\nnew state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our\ndecoupled architecture enhances inference speed by enabling the sharing\nself-condition between adjacent denoising steps. To minimize performance\ndegradation, we propose a novel statistical dynamic programming approach to\nidentify optimal sharing strategies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "sota on ImageNet256 and ImageNet512",
    "pdf_url": "http://arxiv.org/pdf/2504.05741v2",
    "published_date": "2025-04-08 07:17:45 UTC",
    "updated_date": "2025-04-09 04:23:38 UTC"
  },
  {
    "arxiv_id": "2504.05736v1",
    "title": "Rank-Then-Score: Enhancing Large Language Models for Automated Essay Scoring",
    "authors": [
      "Yida Cai",
      "Kun Liang",
      "Sanwoo Lee",
      "Qinghan Wang",
      "Yunfang Wu"
    ],
    "abstract": "In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.05736v1",
    "published_date": "2025-04-08 07:10:51 UTC",
    "updated_date": "2025-04-08 07:10:51 UTC"
  },
  {
    "arxiv_id": "2504.05728v1",
    "title": "AI-Driven Prognostics for State of Health Prediction in Li-ion Batteries: A Comprehensive Analysis with Validation",
    "authors": [
      "Tianqi Ding",
      "Dawei Xiang",
      "Tianyao Sun",
      "YiJiashum Qi",
      "Zunduo Zhao"
    ],
    "abstract": "This paper presents a comprehensive review of AI-driven prognostics for State\nof Health (SoH) prediction in lithium-ion batteries. We compare the\neffectiveness of various AI algorithms, including FFNN, LSTM, and BiLSTM,\nacross multiple datasets (CALCE, NASA, UDDS) and scenarios (e.g., varying\ntemperatures and driving conditions). Additionally, we analyze the factors\ninfluencing SoH fluctuations, such as temperature and charge-discharge rates,\nand validate our findings through simulations. The results demonstrate that\nBiLSTM achieves the highest accuracy, with an average RMSE reduction of 15%\ncompared to LSTM, highlighting its robustness in real-world applications.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 12 figures, Accepted by 2025 6th International Conference on\n  Electrical Technology and Automatic Control(ICETAC 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.05728v1",
    "published_date": "2025-04-08 06:58:39 UTC",
    "updated_date": "2025-04-08 06:58:39 UTC"
  },
  {
    "arxiv_id": "2504.05711v1",
    "title": "Automated Archival Descriptions with Federated Intelligence of LLMs",
    "authors": [
      "Jinghua Groppe",
      "Andreas Marquet",
      "Annabel Walz",
      "Sven Groppe"
    ],
    "abstract": "Enforcing archival standards requires specialized expertise, and manually\ncreating metadata descriptions for archival materials is a tedious and\nerror-prone task. This work aims at exploring the potential of agentic AI and\nlarge language models (LLMs) in addressing the challenges of implementing a\nstandardized archival description process. To this end, we introduce an agentic\nAI-driven system for automated generation of high-quality metadata descriptions\nof archival materials. We develop a federated optimization approach that unites\nthe intelligence of multiple LLMs to construct optimal archival metadata. We\nalso suggest methods to overcome the challenges associated with using LLMs for\nconsistent metadata generation. To evaluate the feasibility and effectiveness\nof our techniques, we conducted extensive experiments using a real-world\ndataset of archival materials, which covers a variety of document types and\ndata formats. The evaluation results demonstrate the feasibility of our\ntechniques and highlight the superior performance of the federated optimization\napproach compared to single-model solutions in metadata quality and\nreliability.",
    "categories": [
      "cs.AI",
      "cs.DL",
      "cs.IR",
      "cs.LG",
      "I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.05711v1",
    "published_date": "2025-04-08 06:11:05 UTC",
    "updated_date": "2025-04-08 06:11:05 UTC"
  },
  {
    "arxiv_id": "2504.05695v3",
    "title": "Architecture independent generalization bounds for overparametrized deep ReLU networks",
    "authors": [
      "Thomas Chen",
      "Chun-Kai Kevin Chien",
      "Patricia Muñoz Ewald",
      "Andrew G. Moore"
    ],
    "abstract": "We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP",
      "math.OC",
      "stat.ML",
      "57R70, 62M45"
    ],
    "primary_category": "cs.LG",
    "comment": "AMS Latex, 13 pages. Both main theorems are now in Section 1",
    "pdf_url": "http://arxiv.org/pdf/2504.05695v3",
    "published_date": "2025-04-08 05:37:38 UTC",
    "updated_date": "2025-05-22 15:45:56 UTC"
  },
  {
    "arxiv_id": "2504.05694v2",
    "title": "Large Language Models Enhanced Hyperbolic Space Recommender Systems",
    "authors": [
      "Wentao Cheng",
      "Zhida Qin",
      "Zexue Wu",
      "Pengzhan Zhou",
      "Tianyu Huang"
    ],
    "abstract": "Large Language Models (LLMs) have attracted significant attention in\nrecommender systems for their excellent world knowledge capabilities. However,\nexisting methods that rely on Euclidean space struggle to capture the rich\nhierarchical information inherent in textual and semantic data, which is\nessential for capturing user preferences. The geometric properties of\nhyperbolic space offer a promising solution to address this issue.\nNevertheless, integrating LLMs-based methods with hyperbolic space to\neffectively extract and incorporate diverse hierarchical information is\nnon-trivial. To this end, we propose a model-agnostic framework, named\nHyperLLM, which extracts and integrates hierarchical information from both\nstructural and semantic perspectives. Structurally, HyperLLM uses LLMs to\ngenerate multi-level classification tags with hierarchical parent-child\nrelationships for each item. Then, tag-item and user-item interactions are\njointly learned and aligned through contrastive learning, thereby providing the\nmodel with clear hierarchical information. Semantically, HyperLLM introduces a\nnovel meta-optimized strategy to extract hierarchical information from semantic\nembeddings and bridge the gap between the semantic and collaborative spaces for\nseamless integration. Extensive experiments show that HyperLLM significantly\noutperforms recommender systems based on hyperbolic space and LLMs, achieving\nperformance improvements of over 40%. Furthermore, HyperLLM not only improves\nrecommender performance but also enhances training stability, highlighting the\ncritical role of hierarchical information in recommender systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted as a SIGIR'25 full paper",
    "pdf_url": "http://arxiv.org/pdf/2504.05694v2",
    "published_date": "2025-04-08 05:35:38 UTC",
    "updated_date": "2025-04-19 14:01:51 UTC"
  },
  {
    "arxiv_id": "2504.05693v1",
    "title": "STRIVE: A Think & Improve Approach with Iterative Refinement for Enhancing Question Quality Estimation",
    "authors": [
      "Aniket Deroy",
      "Subhankar Maity"
    ],
    "abstract": "Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "5 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05693v1",
    "published_date": "2025-04-08 05:34:38 UTC",
    "updated_date": "2025-04-08 05:34:38 UTC"
  },
  {
    "arxiv_id": "2504.05691v1",
    "title": "StayLTC: A Cost-Effective Multimodal Framework for Hospital Length of Stay Forecasting",
    "authors": [
      "Sudeshna Jana",
      "Manjira Sinha",
      "Tirthankar Dasgupta"
    ],
    "abstract": "Accurate prediction of Length of Stay (LOS) in hospitals is crucial for\nimproving healthcare services, resource management, and cost efficiency. This\npaper presents StayLTC, a multimodal deep learning framework developed to\nforecast real-time hospital LOS using Liquid Time-Constant Networks (LTCs).\nLTCs, with their continuous-time recurrent dynamics, are evaluated against\ntraditional models using structured data from Electronic Health Records (EHRs)\nand clinical notes. Our evaluation, conducted on the MIMIC-III dataset,\ndemonstrated that LTCs significantly outperform most of the other time series\nmodels, offering enhanced accuracy, robustness, and efficiency in resource\nutilization. Additionally, LTCs demonstrate a comparable performance in LOS\nprediction compared to time series large language models, while requiring\nsignificantly less computational power and memory, underscoring their potential\nto advance Natural Language Processing (NLP) tasks in healthcare.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "4 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05691v1",
    "published_date": "2025-04-08 05:27:53 UTC",
    "updated_date": "2025-04-08 05:27:53 UTC"
  },
  {
    "arxiv_id": "2504.05686v1",
    "title": "kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive Synthesis and Concatenation Smoothness Optimization",
    "authors": [
      "Keren Shao",
      "Ke Chen",
      "Matthew Baas",
      "Shlomo Dubnov"
    ],
    "abstract": "Robustness is critical in zero-shot singing voice conversion (SVC). This\npaper introduces two novel methods to strengthen the robustness of the kNN-VC\nframework for SVC. First, kNN-VC's core representation, WavLM, lacks harmonic\nemphasis, resulting in dull sounds and ringing artifacts. To address this, we\nleverage the bijection between WavLM, pitch contours, and spectrograms to\nperform additive synthesis, integrating the resulting waveform into the model\nto mitigate these issues. Second, kNN-VC overlooks concatenative smoothness, a\nkey perceptual factor in SVC. To enhance smoothness, we propose a new distance\nmetric that filters out unsuitable kNN candidates and optimize the summing\nweights of the candidates during inference. Although our techniques are built\non the kNN-VC framework for implementation convenience, they are broadly\napplicable to general concatenative neural synthesis models. Experimental\nresults validate the effectiveness of these modifications in achieving robust\nSVC. Demo: http://knnsvc.com Code: https://github.com/SmoothKen/knn-svc",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 6 figures, 1 table, Proceedings of the International\n  Conference on Acoustics, Speech, and Signal Processing, ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05686v1",
    "published_date": "2025-04-08 04:59:56 UTC",
    "updated_date": "2025-04-08 04:59:56 UTC"
  },
  {
    "arxiv_id": "2504.05684v1",
    "title": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis",
    "authors": [
      "Tri Ton",
      "Ji Woo Hong",
      "Chang D. Yoo"
    ],
    "abstract": "This paper introduces Timestep-Adaptive Representation Alignment with\nOnset-Aware Conditioning (TARO), a novel framework for high-fidelity and\ntemporally coherent video-to-audio synthesis. Built upon flow-based\ntransformers, which offer stable training and continuous transformations for\nenhanced synchronization and audio quality, TARO introduces two key\ninnovations: (1) Timestep-Adaptive Representation Alignment (TRA), which\ndynamically aligns latent representations by adjusting alignment strength based\non the noise schedule, ensuring smooth evolution and improved fidelity, and (2)\nOnset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp\nevent-driven markers of audio-relevant visual moments to enhance\nsynchronization with dynamic visual events. Extensive experiments on the\nVGGSound and Landscape datasets demonstrate that TARO outperforms prior\nmethods, achieving relatively 53\\% lower Frechet Distance (FD), 29% lower\nFrechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its\nsuperior audio quality and synchronization precision.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.SD",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05684v1",
    "published_date": "2025-04-08 04:49:36 UTC",
    "updated_date": "2025-04-08 04:49:36 UTC"
  },
  {
    "arxiv_id": "2504.05683v1",
    "title": "Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs Ready for HR Spoken Interview Transcript Analysis?",
    "authors": [
      "Subhankar Maity",
      "Aniket Deroy",
      "Sudeshna Sarkar"
    ],
    "abstract": "This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "32 pages, 24 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05683v1",
    "published_date": "2025-04-08 04:46:10 UTC",
    "updated_date": "2025-04-08 04:46:10 UTC"
  },
  {
    "arxiv_id": "2504.05657v1",
    "title": "Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing",
    "authors": [
      "Tianchi Liu",
      "Duc-Tuan Truong",
      "Rohan Kumar Das",
      "Kong Aik Lee",
      "Haizhou Li"
    ],
    "abstract": "Speech foundation models have significantly advanced various speech-related\ntasks by providing exceptional representation capabilities. However, their\nhigh-dimensional output features often create a mismatch with downstream task\nmodels, which typically require lower-dimensional inputs. A common solution is\nto apply a dimensionality reduction (DR) layer, but this approach increases\nparameter overhead, computational costs, and risks losing valuable information.\nTo address these issues, we propose Nested Res2Net (Nes2Net), a lightweight\nback-end architecture designed to directly process high-dimensional features\nwithout DR layers. The nested structure enhances multi-scale feature\nextraction, improves feature interaction, and preserves high-dimensional\ninformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfake\ndetection dataset, and report a 22% performance improvement and an 87% back-end\ncomputational cost reduction over the state-of-the-art baseline. Additionally,\nextensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,\nPartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial\nattacks, partial spoofing, and real-world scenarios, consistently highlights\nNes2Net's superior robustness and generalization capabilities. The code package\nand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "This manuscript has been submitted for peer review",
    "pdf_url": "http://arxiv.org/pdf/2504.05657v1",
    "published_date": "2025-04-08 04:11:28 UTC",
    "updated_date": "2025-04-08 04:11:28 UTC"
  },
  {
    "arxiv_id": "2504.05646v1",
    "title": "Lattice: Learning to Efficiently Compress the Memory",
    "authors": [
      "Mahdi Karami",
      "Vahab Mirrokni"
    ],
    "abstract": "Attention mechanisms have revolutionized sequence learning but suffer from\nquadratic computational complexity. This paper introduces Lattice, a novel\nrecurrent neural network (RNN) mechanism that leverages the inherent low-rank\nstructure of K-V matrices to efficiently compress the cache into a fixed number\nof memory slots, achieving sub-quadratic complexity. We formulate this\ncompression as an online optimization problem and derive a dynamic memory\nupdate rule based on a single gradient descent step. The resulting recurrence\nfeatures a state- and input-dependent gating mechanism, offering an\ninterpretable memory update process. The core innovation is the orthogonal\nupdate: each memory slot is updated exclusively with information orthogonal to\nits current state hence incorporation of only novel, non-redundant data, which\nminimizes the interference with previously stored information. The experimental\nresults show that Lattice achieves the best perplexity compared to all\nbaselines across diverse context lengths, with performance improvement becoming\nmore pronounced as the context length increases.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05646v1",
    "published_date": "2025-04-08 03:48:43 UTC",
    "updated_date": "2025-04-08 03:48:43 UTC"
  },
  {
    "arxiv_id": "2504.05639v1",
    "title": "DBOT: Artificial Intelligence for Systematic Long-Term Investing",
    "authors": [
      "Vasant Dhar",
      "João Sedoc"
    ],
    "abstract": "Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "q-fin.PR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05639v1",
    "published_date": "2025-04-08 03:34:22 UTC",
    "updated_date": "2025-04-08 03:34:22 UTC"
  },
  {
    "arxiv_id": "2504.06312v1",
    "title": "DMol: A Schedule-Driven Diffusion Model for Highly Efficient and Versatile Molecule Generation",
    "authors": [
      "Peizhi Niu",
      "Yu-Hsiang Wang",
      "Vishal Rana",
      "Chetan Rupakheti",
      "Abhishek Pandey",
      "Olgica Milenkovic"
    ],
    "abstract": "We introduce a new graph diffusion model for small molecule generation,\n\\emph{DMol}, which outperforms the state-of-the-art DiGress model in terms of\nvalidity by roughly $1.5\\%$ across all benchmarking datasets while reducing the\nnumber of diffusion steps by at least $10$-fold, and the running time to\nroughly one half. The performance improvements are a result of a careful change\nin the objective function and a ``graph noise\" scheduling approach which, at\neach diffusion step, allows one to only change a subset of nodes of varying\nsize in the molecule graph. Another relevant property of the method is that it\ncan be easily combined with junction-tree-like graph representations that arise\nby compressing a collection of relevant ring structures into supernodes. Unlike\nclassical junction-tree techniques that involve VAEs and require complicated\nreconstruction steps, compressed DMol directly performs graph diffusion on a\ngraph that compresses only a carefully selected set of frequent carbon rings\ninto supernodes, which results in straightforward sample generation. This\ncompressed DMol method offers additional validity improvements over generic\nDMol of roughly $2\\%$, increases the novelty of the method, and further\nimproves the running time due to reductions in the graph size.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.06312v1",
    "published_date": "2025-04-08 03:31:21 UTC",
    "updated_date": "2025-04-08 03:31:21 UTC"
  },
  {
    "arxiv_id": "2504.05632v2",
    "title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning",
    "authors": [
      "Sanchit Kabra",
      "Akshita Jha",
      "Chandan K. Reddy"
    ],
    "abstract": "Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.05632v2",
    "published_date": "2025-04-08 03:21:51 UTC",
    "updated_date": "2025-04-09 03:05:13 UTC"
  },
  {
    "arxiv_id": "2504.05621v1",
    "title": "Continual Learning of Multiple Cognitive Functions with Brain-inspired Temporal Development Mechanism",
    "authors": [
      "Bing Han",
      "Feifei Zhao",
      "Yinqian Sun",
      "Wenxuan Pan",
      "Yi Zeng"
    ],
    "abstract": "Cognitive functions in current artificial intelligence networks are tied to\nthe exponential increase in network scale, whereas the human brain can\ncontinuously learn hundreds of cognitive functions with remarkably low energy\nconsumption. This advantage is in part due to the brain cross-regional temporal\ndevelopment mechanisms, where the progressive formation, reorganization, and\npruning of connections from basic to advanced regions, facilitate knowledge\ntransfer and prevent network redundancy. Inspired by these, we propose the\nContinual Learning of Multiple Cognitive Functions with Brain-inspired Temporal\nDevelopment Mechanism(TD-MCL), enabling cognitive enhancement from simple to\ncomplex in Perception-Motor-Interaction(PMI) multiple cognitive task scenarios.\nThe TD-MCL model proposes the sequential evolution of long-range connections\nbetween different cognitive modules to promote positive knowledge transfer,\nwhile using feedback-guided local connection inhibition and pruning to\neffectively eliminate redundancies in previous tasks, reducing energy\nconsumption while preserving acquired knowledge. Experiments show that the\nproposed method can achieve continual learning capabilities while reducing\nnetwork scale, without introducing regularization, replay, or freezing\nstrategies, and achieving superior accuracy on new tasks compared to direct\nlearning. The proposed method shows that the brain's developmental mechanisms\noffer a valuable reference for exploring biologically plausible, low-energy\nenhancements of general cognitive abilities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05621v1",
    "published_date": "2025-04-08 02:36:36 UTC",
    "updated_date": "2025-04-08 02:36:36 UTC"
  },
  {
    "arxiv_id": "2504.05618v1",
    "title": "Technical Report: Full Version of Analyzing and Optimizing Perturbation of DP-SGD Geometrically",
    "authors": [
      "Jiawei Duan",
      "Haibo Hu",
      "Qingqing Ye",
      "Xinyue Sun"
    ],
    "abstract": "Differential privacy (DP) has become a prevalent privacy model in a wide\nrange of machine learning tasks, especially after the debut of DP-SGD. However,\nDP-SGD, which directly perturbs gradients in the training iterations, fails to\nmitigate the negative impacts of noise on gradient direction. As a result,\nDP-SGD is often inefficient. Although various solutions (e.g., clipping to\nreduce the sensitivity of gradients and amplifying privacy bounds to save\nprivacy budgets) are proposed to trade privacy for model efficiency, the root\ncause of its inefficiency is yet unveiled.\n  In this work, we first generalize DP-SGD and theoretically derive the impact\nof DP noise on the training process. Our analysis reveals that, in terms of a\nperturbed gradient, only the noise on direction has eminent impact on the model\nefficiency while that on magnitude can be mitigated by optimization techniques,\ni.e., fine-tuning gradient clipping and learning rate. Besides, we confirm that\ntraditional DP introduces biased noise on the direction when adding unbiased\nnoise to the gradient itself. Overall, the perturbation of DP-SGD is actually\nsub-optimal from a geometric perspective. Motivated by this, we design a\ngeometric perturbation strategy GeoDP within the DP framework, which perturbs\nthe direction and the magnitude of a gradient, respectively. By directly\nreducing the noise on the direction, GeoDP mitigates the negative impact of DP\nnoise on model efficiency with the same DP guarantee. Extensive experiments on\ntwo public datasets (i.e., MNIST and CIFAR-10), one synthetic dataset and three\nprevalent models (i.e., Logistic Regression, CNN and ResNet) confirm the\neffectiveness and generality of our strategy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DB"
    ],
    "primary_category": "cs.LG",
    "comment": "This is the full version of our paper \"Analyzing and Optimizing\n  Perturbation of DP-SGD Geometrically\", which will appear in ICDE 2025 as a\n  regular research paper",
    "pdf_url": "http://arxiv.org/pdf/2504.05618v1",
    "published_date": "2025-04-08 02:26:10 UTC",
    "updated_date": "2025-04-08 02:26:10 UTC"
  },
  {
    "arxiv_id": "2504.05615v1",
    "title": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels",
    "authors": [
      "Seunghun Yu",
      "Jin-Hyun Ahn",
      "Joonhyuk Kang"
    ],
    "abstract": "Federated Learning (FL) is a powerful framework for privacy-preserving\ndistributed learning. It enables multiple clients to collaboratively train a\nglobal model without sharing raw data. However, handling noisy labels in FL\nremains a major challenge due to heterogeneous data distributions and\ncommunication constraints, which can severely degrade model performance. To\naddress this issue, we propose FedEFC, a novel method designed to tackle the\nimpact of noisy labels in FL. FedEFC mitigates this issue through two key\ntechniques: (1) prestopping, which prevents overfitting to mislabeled data by\ndynamically halting training at an optimal point, and (2) loss correction,\nwhich adjusts model updates to account for label noise. In particular, we\ndevelop an effective loss correction tailored to the unique challenges of FL,\nincluding data heterogeneity and decentralized training. Furthermore, we\nprovide a theoretical analysis, leveraging the composite proper loss property,\nto demonstrate that the FL objective function under noisy label distributions\ncan be aligned with the clean label distribution. Extensive experimental\nresults validate the effectiveness of our approach, showing that it\nconsistently outperforms existing FL techniques in mitigating the impact of\nnoisy labels, particularly under heterogeneous data settings (e.g., achieving\nup to 41.64% relative performance improvement over the existing loss correction\nmethod).",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.05615v1",
    "published_date": "2025-04-08 02:14:50 UTC",
    "updated_date": "2025-04-08 02:14:50 UTC"
  },
  {
    "arxiv_id": "2504.07139v1",
    "title": "Artificial Intelligence Index Report 2025",
    "authors": [
      "Nestor Maslej",
      "Loredana Fattorini",
      "Raymond Perrault",
      "Yolanda Gil",
      "Vanessa Parli",
      "Njenga Kariuki",
      "Emily Capstick",
      "Anka Reuel",
      "Erik Brynjolfsson",
      "John Etchemendy",
      "Katrina Ligett",
      "Terah Lyons",
      "James Manyika",
      "Juan Carlos Niebles",
      "Yoav Shoham",
      "Russell Wald",
      "Tobi Walsh",
      "Armin Hamrah",
      "Lapo Santarlasci",
      "Julia Betts Lotufo",
      "Alexandra Rome",
      "Andrew Shi",
      "Sukrut Oak"
    ],
    "abstract": "Welcome to the eighth edition of the AI Index report. The 2025 Index is our\nmost comprehensive to date and arrives at an important moment, as AI's\ninfluence across society, the economy, and global governance continues to\nintensify. New in this year's report are in-depth analyses of the evolving\nlandscape of AI hardware, novel estimates of inference costs, and new analyses\nof AI publication and patenting trends. We also introduce fresh data on\ncorporate adoption of responsible AI practices, along with expanded coverage of\nAI's growing role in science and medicine. Since its founding in 2017 as an\noffshoot of the One Hundred Year Study of Artificial Intelligence, the AI Index\nhas been committed to equipping policymakers, journalists, executives,\nresearchers, and the public with accurate, rigorously validated, and globally\nsourced data. Our mission has always been to help these stakeholders make\nbetter-informed decisions about the development and deployment of AI. In a\nworld where AI is discussed everywhere - from boardrooms to kitchen tables -\nthis mission has never been more essential. The AI Index continues to lead in\ntracking and interpreting the most critical trends shaping the field - from the\nshifting geopolitical landscape and the rapid evolution of underlying\ntechnologies, to AI's expanding role in business, policymaking, and public\nlife. Longitudinal tracking remains at the heart of our mission. In a domain\nadvancing at breakneck speed, the Index provides essential context - helping us\nunderstand where AI stands today, how it got here, and where it may be headed\nnext. Recognized globally as one of the most authoritative resources on\nartificial intelligence, the AI Index has been cited in major media outlets\nsuch as The New York Times, Bloomberg, and The Guardian; referenced in hundreds\nof academic papers; and used by policymakers and government agencies around the\nworld.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.07139v1",
    "published_date": "2025-04-08 02:01:37 UTC",
    "updated_date": "2025-04-08 02:01:37 UTC"
  },
  {
    "arxiv_id": "2504.05607v1",
    "title": "FactGuard: Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction",
    "authors": [
      "Qian-Wen Zhang",
      "Fang Li",
      "Jie Wang",
      "Lingfeng Qiao",
      "Yifei Yu",
      "Di Yin",
      "Xing Sun"
    ],
    "abstract": "Extractive reading comprehension systems are designed to locate the correct\nanswer to a question within a given text. However, a persistent challenge lies\nin ensuring these models maintain high accuracy in answering questions while\nreliably recognizing unanswerable queries. Despite significant advances in\nlarge language models (LLMs) for reading comprehension, this issue remains\ncritical, particularly as the length of supported contexts continues to expand.\nTo address this challenge, we propose an innovative data augmentation\nmethodology grounded in a multi-agent collaborative framework. Unlike\ntraditional methods, such as the costly human annotation process required for\ndatasets like SQuAD 2.0, our method autonomously generates evidence-based\nquestion-answer pairs and systematically constructs unanswerable questions.\nUsing this methodology, we developed the FactGuard-Bench dataset, which\ncomprises 25,220 examples of both answerable and unanswerable question\nscenarios, with context lengths ranging from 8K to 128K. Experimental\nevaluations conducted on seven popular LLMs reveal that even the most advanced\nmodels achieve only 61.79% overall accuracy. Furthermore, we emphasize the\nimportance of a model's ability to reason about unanswerable questions to avoid\ngenerating plausible but incorrect answers. By implementing efficient data\nselection and generation within the multi-agent collaborative framework, our\nmethod significantly reduces the traditionally high costs associated with\nmanual annotation and provides valuable insights for the training and\noptimization of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05607v1",
    "published_date": "2025-04-08 01:45:16 UTC",
    "updated_date": "2025-04-08 01:45:16 UTC"
  },
  {
    "arxiv_id": "2504.05591v1",
    "title": "Class Imbalance Correction for Improved Universal Lesion Detection and Tagging in CT",
    "authors": [
      "Peter D. Erickson",
      "Tejas Sudharshan Mathai",
      "Ronald M. Summers"
    ],
    "abstract": "Radiologists routinely detect and size lesions in CT to stage cancer and\nassess tumor burden. To potentially aid their efforts, multiple lesion\ndetection algorithms have been developed with a large public dataset called\nDeepLesion (32,735 lesions, 32,120 CT slices, 10,594 studies, 4,427 patients, 8\nbody part labels). However, this dataset contains missing measurements and\nlesion tags, and exhibits a severe imbalance in the number of lesions per label\ncategory. In this work, we utilize a limited subset of DeepLesion (6\\%, 1331\nlesions, 1309 slices) containing lesion annotations and body part label tags to\ntrain a VFNet model to detect lesions and tag them. We address the class\nimbalance by conducting three experiments: 1) Balancing data by the body part\nlabels, 2) Balancing data by the number of lesions per patient, and 3)\nBalancing data by the lesion size. In contrast to a randomly sampled\n(unbalanced) data subset, our results indicated that balancing the body part\nlabels always increased sensitivity for lesions >= 1cm for classes with low\ndata quantities (Bone: 80\\% vs. 46\\%, Kidney: 77\\% vs. 61\\%, Soft Tissue: 70\\%\nvs. 60\\%, Pelvis: 83\\% vs. 76\\%). Similar trends were seen for three other\nmodels tested (FasterRCNN, RetinaNet, FoveaBox). Balancing data by lesion size\nalso helped the VFNet model improve recalls for all classes in contrast to an\nunbalanced dataset. We also provide a structured reporting guideline for a\n``Lesions'' subsection to be entered into the ``Findings'' section of a\nradiology report. To our knowledge, we are the first to report the class\nimbalance in DeepLesion, and have taken data-driven steps to address it in the\ncontext of joint lesion detection and tagging.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "Published at MICCAI MILLAND Workshop 2022",
    "pdf_url": "http://arxiv.org/pdf/2504.05591v1",
    "published_date": "2025-04-08 00:58:26 UTC",
    "updated_date": "2025-04-08 00:58:26 UTC"
  },
  {
    "arxiv_id": "2504.05588v1",
    "title": "Multi-fidelity Reinforcement Learning Control for Complex Dynamical Systems",
    "authors": [
      "Luning Sun",
      "Xin-Yang Liu",
      "Siyan Zhao",
      "Aditya Grover",
      "Jian-Xun Wang",
      "Jayaraman J. Thiagarajan"
    ],
    "abstract": "Controlling instabilities in complex dynamical systems is challenging in\nscientific and engineering applications. Deep reinforcement learning (DRL) has\nseen promising results for applications in different scientific applications.\nThe many-query nature of control tasks requires multiple interactions with real\nenvironments of the underlying physics. However, it is usually sparse to\ncollect from the experiments or expensive to simulate for complex dynamics.\nAlternatively, controlling surrogate modeling could mitigate the computational\ncost issue. However, a fast and accurate learning-based model by offline\ntraining makes it very hard to get accurate pointwise dynamics when the\ndynamics are chaotic. To bridge this gap, the current work proposes a\nmulti-fidelity reinforcement learning (MFRL) framework that leverages\ndifferentiable hybrid models for control tasks, where a physics-based hybrid\nmodel is corrected by limited high-fidelity data. We also proposed a\nspectrum-based reward function for RL learning. The effect of the proposed\nframework is demonstrated on two complex dynamics in physics. The statistics of\nthe MFRL control result match that computed from many-query evaluations of the\nhigh-fidelity environments and outperform other SOTA baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05588v1",
    "published_date": "2025-04-08 00:50:15 UTC",
    "updated_date": "2025-04-08 00:50:15 UTC"
  },
  {
    "arxiv_id": "2504.05586v2",
    "title": "Finding Fantastic Experts in MoEs: A Unified Study for Expert Dropping Strategies and Observations",
    "authors": [
      "Ajay Jaiswal",
      "Jianyu Wang",
      "Yixiao Li",
      "Pingzhi Li",
      "Tianlong Chen",
      "Zhangyang Wang",
      "Chong Wang",
      "Ruoming Pang",
      "Xianzhi Du"
    ],
    "abstract": "Sparsely activated Mixture-of-Experts (SMoE) has shown promise in scaling up\nthe learning capacity of neural networks. However, vanilla SMoEs have issues\nsuch as expert redundancy and heavy memory requirements, making them\ninefficient and non-scalable, especially for resource-constrained scenarios.\nExpert-level sparsification of SMoEs involves pruning the least important\nexperts to address these limitations. In this work, we aim to address three\nquestions: (1) What is the best recipe to identify the least knowledgeable\nsubset of experts that can be dropped with minimal impact on performance? (2)\nHow should we perform expert dropping (one-shot or iterative), and what\ncorrection measures can we undertake to minimize its drastic impact on SMoE\nsubnetwork capabilities? (3) What capabilities of full-SMoEs are severely\nimpacted by the removal of the least dominant experts, and how can we recover\nthem? Firstly, we propose MoE Experts Compression Suite (MC-Suite), which is a\ncollection of some previously explored and multiple novel recipes to provide a\ncomprehensive benchmark for estimating expert importance from diverse\nperspectives, as well as unveil numerous valuable insights for SMoE experts.\nSecondly, unlike prior works with a one-shot expert pruning approach, we\nexplore the benefits of iterative pruning with the re-estimation of the\nMC-Suite criterion. Moreover, we introduce the benefits of task-agnostic\nfine-tuning as a correction mechanism during iterative expert dropping, which\nwe term MoE Lottery Subnetworks. Lastly, we present an experimentally validated\nconjecture that, during expert dropping, SMoEs' instruction-following\ncapabilities are predominantly hurt, which can be restored to a robust level\nsubject to external augmentation of instruction-following capabilities using\nk-shot examples and supervised fine-tuning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05586v2",
    "published_date": "2025-04-08 00:49:08 UTC",
    "updated_date": "2025-04-10 02:32:14 UTC"
  },
  {
    "arxiv_id": "2504.05585v2",
    "title": "TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning",
    "authors": [
      "Yuxuan Li",
      "Yicheng Gao",
      "Ning Yang",
      "Stephen Xia"
    ],
    "abstract": "Episodic tasks in Reinforcement Learning (RL) often pose challenges due to\nsparse reward signals and high-dimensional state spaces, which hinder efficient\nlearning. Additionally, these tasks often feature hidden \"trap states\" --\nirreversible failures that prevent task completion but do not provide explicit\nnegative rewards to guide agents away from repeated errors. To address these\nissues, we propose Time-Weighted Contrastive Reward Learning (TW-CRL), an\nInverse Reinforcement Learning (IRL) framework that leverages both successful\nand failed demonstrations. By incorporating temporal information, TW-CRL learns\na dense reward function that identifies critical states associated with success\nor failure. This approach not only enables agents to avoid trap states but also\nencourages meaningful exploration beyond simple imitation of expert\ntrajectories. Empirical evaluations on navigation tasks and robotic\nmanipulation benchmarks demonstrate that TW-CRL surpasses state-of-the-art\nmethods, achieving improved efficiency and robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05585v2",
    "published_date": "2025-04-08 00:48:29 UTC",
    "updated_date": "2025-05-22 00:37:44 UTC"
  },
  {
    "arxiv_id": "2504.16940v3",
    "title": "Better artificial intelligence does not mean better models of biology",
    "authors": [
      "Drew Linsley",
      "Pinyuan Feng",
      "Thomas Serre"
    ],
    "abstract": "Deep neural networks (DNNs) once showed increasing alignment with primate\nperception and neural responses as they improved on vision benchmarks, raising\nhopes that advances in AI would yield better models of biological vision.\nHowever, we show across three benchmarks that this alignment is now plateauing\n- and in some cases worsening - as DNNs scale to human or superhuman accuracy.\nThis divergence may reflect the adoption of visual strategies that differ from\nthose used by primates. These findings challenge the view that progress in\nartificial intelligence will naturally translate to neuroscience. We argue that\nvision science must chart its own course, developing algorithms grounded in\nbiological visual systems rather than optimizing for benchmarks based on\ninternet-scale datasets.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16940v3",
    "published_date": "2025-04-08 00:36:29 UTC",
    "updated_date": "2025-04-28 16:05:25 UTC"
  },
  {
    "arxiv_id": "2504.05576v1",
    "title": "SoundVista: Novel-View Ambient Sound Synthesis via Visual-Acoustic Binding",
    "authors": [
      "Mingfei Chen",
      "Israel D. Gebru",
      "Ishwarya Ananthabhotla",
      "Christian Richardt",
      "Dejan Markovic",
      "Jake Sandakly",
      "Steven Krenn",
      "Todd Keebler",
      "Eli Shlizerman",
      "Alexander Richard"
    ],
    "abstract": "We introduce SoundVista, a method to generate the ambient sound of an\narbitrary scene at novel viewpoints. Given a pre-acquired recording of the\nscene from sparsely distributed microphones, SoundVista can synthesize the\nsound of that scene from an unseen target viewpoint. The method learns the\nunderlying acoustic transfer function that relates the signals acquired at the\ndistributed microphones to the signal at the target viewpoint, using a limited\nnumber of known recordings. Unlike existing works, our method does not require\nconstraints or prior knowledge of sound source details. Moreover, our method\nefficiently adapts to diverse room layouts, reference microphone configurations\nand unseen environments. To enable this, we introduce a visual-acoustic binding\nmodule that learns visual embeddings linked with local acoustic properties from\npanoramic RGB and depth data. We first leverage these embeddings to optimize\nthe placement of reference microphones in any given scene. During synthesis, we\nleverage multiple embeddings extracted from reference locations to get adaptive\nweights for their contribution, conditioned on target viewpoint. We benchmark\nthe task on both publicly available data and real-world settings. We\ndemonstrate significant improvements over existing methods.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.SD",
    "comment": "Highlight Accepted to CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.05576v1",
    "published_date": "2025-04-08 00:22:16 UTC",
    "updated_date": "2025-04-08 00:22:16 UTC"
  },
  {
    "arxiv_id": "2504.05573v1",
    "title": "MicroNN: An On-device Disk-resident Updatable Vector Database",
    "authors": [
      "Jeffrey Pound",
      "Floris Chabert",
      "Arjun Bhushan",
      "Ankur Goswami",
      "Anil Pacaci",
      "Shihabur Rahman Chowdhury"
    ],
    "abstract": "Nearest neighbour search over dense vector collections has important\napplications in information retrieval, retrieval augmented generation (RAG),\nand content ranking. Performing efficient search over large vector collections\nis a well studied problem with many existing approaches and open source\nimplementations. However, most state-of-the-art systems are generally targeted\ntowards scenarios using large servers with an abundance of memory, static\nvector collections that are not updatable, and nearest neighbour search in\nisolation of other search criteria. We present Micro Nearest Neighbour\n(MicroNN), an embedded nearest-neighbour vector search engine designed for\nscalable similarity search in low-resource environments. MicroNN addresses the\nproblem of on-device vector search for real-world workloads containing updates\nand hybrid search queries that combine nearest neighbour search with structured\nattribute filters. In this scenario, memory is highly constrained and\ndisk-efficient index structures and algorithms are required, as well as support\nfor continuous inserts and deletes. MicroNN is an embeddable library that can\nscale to large vector collections with minimal resources. MicroNN is used in\nproduction and powers a wide range of vector search use-cases on-device.\nMicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with\n90% recall on publicly available million-scale vector benchmark while using ~10\nMB of memory.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05573v1",
    "published_date": "2025-04-08 00:05:58 UTC",
    "updated_date": "2025-04-08 00:05:58 UTC"
  },
  {
    "arxiv_id": "2504.05571v1",
    "title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions",
    "authors": [
      "Oded Ovadia",
      "Meni Brief",
      "Rachel Lemberg",
      "Eitam Sheetrit"
    ],
    "abstract": "While Large Language Models (LLMs) acquire vast knowledge during\npre-training, they often lack domain-specific, new, or niche information.\nContinual pre-training (CPT) attempts to address this gap but suffers from\ncatastrophic forgetting and inefficiencies in low-data regimes. We introduce\nKnowledge-Instruct, a novel approach to efficiently inject knowledge from\nlimited corpora through pure instruction-tuning. By generating\ninformation-dense synthetic instruction data, it effectively integrates new\nknowledge while preserving general reasoning and instruction-following\nabilities. Knowledge-Instruct demonstrates superior factual memorization,\nminimizes catastrophic forgetting, and remains scalable by leveraging synthetic\ndata from relatively small language models. Additionally, it enhances\ncontextual understanding, including complex multi-hop reasoning, facilitating\nintegration with retrieval systems. We validate its effectiveness across\ndiverse benchmarks, including Companies, a new dataset that we release to\nmeasure knowledge injection capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.05571v1",
    "published_date": "2025-04-08 00:00:36 UTC",
    "updated_date": "2025-04-08 00:00:36 UTC"
  }
]