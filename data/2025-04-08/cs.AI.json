{
  "date": "2025-04-08",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-08 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 论文百花齐放，大语言模型 (LLM) 持续渗透各个领域，从化学发现、物理模拟到金融咨询和超长上下文处理，同时研究者们也在深入探索 LLM 的推理、偏见、记忆机制以及与其他技术的融合；此外，计算机视觉、强化学习、联邦学习和理论基础方面也有不少新进展。值得关注的有将 LLM 微调重构为贝叶斯优化的 GOLLuM，能操作有限元分析软件的 LLM 智能体 FEABench，以及将 LLM 上下文扩展至 400 万 token 的高效训练方法。\n\n以下是值得关注的论文：\n\n---\n\n**1. GOLLuM: 高斯过程优化的 LLM -- 通过贝叶斯优化重构 LLM 微调 (GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization)**\n\n这篇论文提出了一种新颖的架构 GOLLuM，将 LLM 微调问题重新定义为通过深度核方法进行高斯过程 (GP) 边际似然优化。它引入了基于 LLM 的深度核，与 GP 联合优化，结合了 LLM 丰富的输入空间表示能力和 GP 的不确定性建模能力，以实现更高效的贝叶斯优化采样。在 Buchwald-Hartwig 反应优化任务中，该方法将高产率反应的发现率提高了近一倍。研究表明，联合优化隐式执行了对比学习，改善了嵌入空间结构和不确定性校准。\n\n**2. FEABench: 评估语言模型的多物理场推理能力 (FEABench: Evaluating Language Models on Multiphysics Reasoning Ability)**\n\n研究者们提出了 FEABench，一个用于评估大型语言模型 (LLM) 和 LLM 智能体使用有限元分析 (FEA) 软件（如 COMSOL）模拟和解决物理、数学及工程问题的基准。他们设计了一个评估方案，考察 LLM 理解自然语言问题描述并操作 FEA 软件计算答案的能力，并开发了一个能与软件 API 交互、检查输出并迭代改进方案的 LLM 智能体。最佳策略能生成 88% 可执行的 API 调用。这项工作旨在推动工程自动化，将 LLM 的推理能力与数值求解器的精度结合。\n\n**3. 从 128K 到 4M：超长上下文大语言模型的高效训练 (From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models)**\n\n这篇来自 NVIDIA 的研究介绍了一种高效的训练方法，可以将指令对齐的 LLM 的上下文窗口从 128K 扩展到惊人的 1M、2M 甚至 4M token。该方法利用高效的持续预训练策略扩展上下文窗口，并采用有效的指令微调来保持模型的指令遵循和推理能力。基于 Llama3.1-Instruct 构建的 UltraLong-8B 模型在多种长上下文基准上达到了 SOTA 水平，同时在标准短上下文基准上也保持了竞争力。研究还深入分析了关键设计选择，并发布了模型权重。\n\n**4. TxGemma: 用于治疗学的高效智能体 LLM (TxGemma: Efficient and Agentic LLMs for Therapeutics)**\n\nGoogle Health 推出了 TxGemma，一套专为治疗学开发设计的 LLM 套件（包含 2B、9B、27B 参数模型）。与任务特定模型不同，TxGemma 能综合来自小分子、蛋白质、核酸、疾病和细胞系等多种来源的信息，用于治疗属性预测、交互式推理和可解释性。在 66 项治疗开发任务中，TxGemma 在多数任务上优于或持平现有通用模型和专业模型。此外，还推出了基于 Gemini 2.5 的智能体系统 Agentic-Tx，在化学和生物学基准测试中表现出色。\n\n**5. SHIMI：用于可扩展智能体推理的语义分层内存索引 (SHIMI: A Semantic Hierarchical Memory Index for Scalable Agent Reasoning)**\n\n针对现有 RAG 和向量搜索在抽象、可扩展性和语义精度上的局限性（尤其在去中心化环境中），该研究提出了 SHIMI (Semantic Hierarchical Memory Index)。SHIMI 将知识建模为动态结构化的概念层次结构，允许智能体基于意义而非表面相似性检索信息。它支持从抽象意图到具体实体的自顶向下遍历，并为去中心化环境设计了轻量级同步协议（利用 Merkle-DAG、布隆过滤器和 CRDT 风格冲突解决）。实验证明了其在检索准确性、语义保真度和可扩展性方面的优势。\n\n**6. Leanabell-Prover: 形式化推理中的后训练扩展 (Leanabell-Prover: Posttraining Scaling in Formal Reasoning)**\n\n近期 LLM 在自动定理证明 (ATP) 方面取得进展，但尚未充分利用后训练扩展（如 OpenAI O1/O3 和 Deepseek R1 所展示的）。该研究探索了 ATP 的整个后训练过程，通过混合数据集（包含大量定理-证明对和模拟人类推理行为的数据）进行持续训练，并利用 Lean 4 编译器返回的结果进行强化学习。通过这种方式，成功改进了现有的形式化证明器（如 DeepSeek-Prover-v1.5 和 Goedel-Prover），在 MiniF2F 等基准上达到了 SOTA 性能。\n\n**7. DDT: 解耦扩散 Transformer (DDT: Decoupled Diffusion Transformer)**\n\n扩散 Transformer 在图像生成方面表现出色，但训练和推理成本高。本文指出，现有模型在每个去噪步骤中使用相同模块进行语义编码（低频）和细节解码（高频），存在优化冲突。为此，研究者提出了 DDT (Decoupled Diffusion Transformer)，采用解耦设计：一个专门的条件编码器用于语义提取，一个专门的速度解码器用于细节生成。实验表明，DDT 在 ImageNet 256x256 和 512x512 上均取得了 SOTA 的 FID 分数，且训练收敛速度更快。解耦架构还通过共享相邻步骤的自条件来加速推理。\n\n**8. Optuna vs Code Llama: LLM 是超参数调优的新范式吗？ (Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?)**\n\n这项工作探讨了使用大型语言模型 (LLM) 进行超参数优化 (HPO) 的可行性，特别是使用微调后的 Code Llama。通过 LoRA 进行参数高效微调，使 LLM 能够为不同的神经网络架构生成准确高效的超参数建议。与 Optuna 等传统方法相比，该方法在 RMSE 上取得了相当或更好的结果，同时显著减少了计算开销和调优时间，显示出 LLM 在 HPO 领域的潜力，尤其适用于资源受限的环境。\n\n**9. 启发式方法是蒸馏 MLP 进行图链接预测的好老师 (Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction)**\n\n链接预测是重要的图学习任务。将图神经网络 (GNN) 教师蒸馏到多层感知器 (MLP) 学生是一种有效降低计算成本的方法。本文研究了不同教师（标准 GNN、链接预测专用 GNN、启发式方法）对蒸馏效果的影响。令人惊讶的是，更强的教师不一定产生更强的学生，而较弱的启发式方法（如共同邻居）可以将 MLP 训练到接近 GNN 的性能，且训练成本大大降低。基于此，提出了 EHDM (Ensemble Heuristic-Distilled MLPs)，通过门控机制有效整合互补信号，在十个数据集上表现优于之前的 GNN-to-MLP 方法，且训练时间更短。\n\n**10. 通过推理引导微调减轻语言模型中的偏见 (Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning)**\n\n研究发现，LLM 的推理能力与其公平性（减少刻板印象）之间存在关联，推理能力更强的模型表现出更低的偏见。基于此，提出了 ReGiFT (Reasoning Guided Fine-Tuning) 方法，通过从高级推理模型中提取结构化推理轨迹，并将其注入到缺乏此类能力的模型中进行微调。该方法仅使用通用推理，无需特定于公平性的监督即可减轻偏见。实验表明，使用 ReGiFT 微调的模型不仅提高了公平性，甚至在公平性基准上优于提供推理轨迹的高级模型。\n\n**11. 知识指导：使用指令从有限数据中进行有效的持续预训练 (Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions)**\n\n针对 LLM 缺乏领域特定或新知识，以及持续预训练 (CPT) 在低数据量下效率低、易发生灾难性遗忘的问题，本文提出了 Knowledge-Instruct。该方法通过纯指令微调，利用生成的信息密集的合成指令数据，高效地注入新知识，同时保留通用推理和指令遵循能力。它在事实记忆方面表现优越，最大限度地减少了灾难性遗忘，并通过利用相对较小语言模型生成的合成数据保持了可扩展性。\n\n**12. MDK12-Bench: 用于评估多模态大语言模型推理能力的多学科基准 (MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in Multimodal Large Language Models)**\n\n现有 MLLM 推理基准存在数据量小、领域窄、知识分布不结构化等问题。本文提出了 MDK12-Bench，一个基于真实 K-12 考试题（涵盖数学、物理、化学、生物、地理、信息科学六个学科）的多学科基准，包含 14 万个推理实例，具有详细的知识点标注、答案解释、难度标签和跨年份划分。研究者还提出了动态评估框架以减轻数据污染。对 MLLM 的广泛实验揭示了当前模型在多模态推理方面的显著局限性。\n\n**13. Lattice: 学习高效压缩记忆 (Lattice: Learning to Efficiently Compress the Memory)**\n\n注意力机制计算复杂度高。本文提出 Lattice，一种新颖的循环神经网络 (RNN) 机制，利用 K-V 矩阵固有的低秩结构，将缓存高效压缩到固定数量的内存槽中，实现亚二次复杂度。压缩被建模为在线优化问题，并推导出基于梯度下降的动态内存更新规则。核心创新是正交更新，确保每个内存槽只更新与其当前状态正交的信息，从而最小化干扰。实验表明，Lattice 在不同上下文长度上均优于基线。\n\n---\n\n**其他简讯:**\n\n*   **联邦学习与域泛化:** (Paper 3) 提出了 `StyleDDG`，一种完全去中心化的域泛化算法，通过共享风格信息实现，并首次提供了基于风格的 DG 训练优化的数学分析框架和收敛性证明。 (Paper 72) 提出了 FedEFC，一种利用增强前向校正来处理联邦学习中标签噪声的方法，通过预停止和损失校正提高模型鲁棒性。\n*   **AI 智能体与人机交互:** (Paper 8) SkillFlow 框架允许 AI 智能体通过与环境或其他智能体通信来获取新技能，加速任务完成。 (Paper 54) 综述了人-AI 协作的研究现状，指出了对齐和充分利用 AI 能力的挑战，并提出了未来研究框架。 (Paper 25) 通过互动平台比较了 AI 影响者和美国公众对 AI 的恐惧与希望，发现观点存在差异。 (Paper 36) Agent Guide 提出了一种基于行为引导的智能体水印框架，用于追踪和问责。 (Paper 37) 探讨了生成式 AI 智能体作为个性化金融顾问的有效性，发现用户偏好和信任可能与建议质量脱钩。\n*   **计算机视觉应用:** (Paper 9) WoundAmbit 项目将 SOTA 语义分割模型应用于伤口护理，进行了基准测试和真实部署评估。 (Paper 22) MCAT 使用视觉查询在胎儿超声视频中定位标准解剖剪辑。 (Paper 34) Turin3D 是一个新的城市 LiDAR 点云语义分割数据集，并探索了半监督学习的应用。 (Paper 44) 提出了 HARDVS 2.0 数据集和 MMHCO-HAR 模型，用于基于 RGB-事件传感器的多模态人类活动识别。 (Paper 51) TMT 提出了一种用于跨域语义分割的区域自适应可迁移性估计方法。 (Paper 78) SoundVista 利用视觉-声学绑定，根据稀疏麦克风录音合成新视角的场景环境声。\n*   **模型安全与鲁棒性:** (Paper 43) 揭示了 Image Prompt Adapter (IP-Adapter) 可能被用于一种名为“劫持攻击”的新型越狱攻击。 (Paper 45) Parasite 提出了一种基于隐写术的扩散模型后门攻击框架。\n*   **特定领域应用:** (Paper 10) 提出了一个用于空间目标行为表征的自监督框架。 (Paper 11) 使用深度学习融合多模态传感数据，用于网联汽车的毫米波波束赋形。 (Paper 19) 提出了 UAHL 架构，用于车辆侧滑角估计的虚拟传感器，并关注不确定性量化。 (Paper 20) 探索使用窄谱照明和计算机视觉检测蜜蜂身上的瓦螨。 (Paper 29) 提出用 OWL DL 表示规范性法规以支持自动合规性检查。 (Paper 38) 探索了基于 AI 的视频美国手语词典的设计和用户体验。 (Paper 57) 对锂离子电池健康状态 (SoH) 预测的 AI 驱动预后方法进行了全面分析和验证。 (Paper 58) 探索使用 LLM 的联邦智能自动生成档案描述。 (Paper 60) HyperLLM 将 LLM 与双曲空间结合用于推荐系统，以更好地捕捉层次信息。 (Paper 63) kNN-SVC 改进了零样本歌声转换的鲁棒性。 (Paper 64) TARO 框架用于同步的视频到音频合成。 (Paper 74) 探讨了 CT 图像中通用病灶检测和标记的类别不平衡问题及校正方法。\n*   **基础理论与方法:** (Paper 5) 对元学习在自动算法选择和参数化 (ASP) 方面的研究进行了综述和实验评估。 (Paper 21) 提出了第一个具有可证明完备性保证的实时多智能体路径寻找 (MAPF) 方法 Real-Time LaCAM。 (Paper 23) 提出一种基于文本长度的置信度正则化方法用于掩码语言建模。 (Paper 24) 提出一种基于信息论的奖励分解方法，用于可泛化的 RLHF。 (Paper 31) CKGAN 使用特征核积分概率度量来训练 GAN。 (Paper 32) 探讨了数据复杂度差异作为公平性早期指标的可能性。 (Paper 33) PRIMEDrive-CoT 是一个用于驾驶场景中不确定性感知对象交互的预认知思维链框架。 (Paper 35) 提出了近似模型计数中系统化参数决策的方法。 (Paper 39) 结合句法分析和语义角色标注来增强预训练语言模型的共指消解能力。 (Paper 40) 提出了基于能量一致随机插值的物理感知生成模型用于湍流模拟。 (Paper 41) PathGPT 利用 LLM 进行个性化路径生成。 (Paper 42) 提出了动量增强的情景记忆来改善长尾 RL 环境中的学习。 (Paper 46) 提出了神经场的元持续学习问题和相应策略。 (Paper 47) 结合外部知识图谱和 LLM 生成更深入的后续问题。 (Paper 48) 综述了 LLM 在 3D 空间推理方面的研究。 (Paper 49) T3T 模型将视频流视为时间序列，用于 VideoQA。 (Paper 50) MDK12-Bench 是一个评估 MLLM 推理能力的多学科基准。 (Paper 52) SDA-Net 是一种轻量级多模块融合的韩文字符识别方法。 (Paper 53) TDE 是一种用于不规则采样时间序列的动态嵌入方法。 (Paper 55) DDT 是一种解耦的扩散 Transformer 模型。 (Paper 56) Rank-Then-Score 是一个基于 LLM 的自动作文评分框架。 (Paper 59) 证明了过参数化深度 ReLU 网络的泛化界与架构无关。 (Paper 61) STRIVE 是一种利用迭代改进来增强问题质量评估的方法。 (Paper 62) StayLTC 是一个用于医院住院时长预测的多模态框架。 (Paper 65) 评估了零样本和少样本 LLM 在 HR 面试转录本分析中的表现。 (Paper 66) Nes2Net 是一种用于语音反欺骗的轻量级嵌套架构。 (Paper 68) DBOT 是一个旨在模拟专家进行系统化长期投资的 AI 系统。 (Paper 69) ReGiFT 通过推理引导微调来减轻 LLM 的偏见。 (Paper 70) 提出了受脑启发的时序发展机制用于多认知功能持续学习。 (Paper 71) 从几何角度分析和优化了 DP-SGD 的扰动。 (Paper 73) FactGuard 利用多智能体系统生成可回答和不可回答问题，以增强长上下文 LLM 抽取能力。 (Paper 75) 提出了用于复杂动力系统控制的多保真度强化学习框架。 (Paper 76) 对 MoE 模型中的专家剪枝策略进行了统一研究。 (Paper 77) TW-CRL 是一种用于高效逆强化学习的时间加权对比奖励学习框架。 (Paper 79) MicroNN 是一个设备端、磁盘驻留、可更新的向量数据库。 (Paper 80) Knowledge-Instruct 使用指令从有限数据中进行有效的持续预训练。\n\n---\n\n希望这份快报能帮助你快速了解 arXiv 的最新动态！",
  "papers": [
    {
      "arxiv_id": "2504.06265v1",
      "title": "GOLLuM: Gaussian Process Optimized LLMs -- Reframing LLM Finetuning through Bayesian Optimization",
      "title_zh": "GOLLuM：高斯过程优化LLM——通过贝叶斯优化重新定义LLM微调\n",
      "authors": [
        "Bojana Ranković",
        "Philippe Schwaller"
      ],
      "abstract": "Large Language Models (LLMs) can encode complex relationships in their latent\nspaces, yet harnessing them for optimization under uncertainty remains\nchallenging. We address this gap with a novel architecture that reframes LLM\nfinetuning as Gaussian process (GP) marginal likelihood optimization via deep\nkernel methods. We introduce LLM-based deep kernels, jointly optimized with GPs\nto preserve the benefits of both - LLMs to provide a rich and flexible input\nspace for Bayesian optimization and - GPs to model this space with predictive\nuncertainty for more efficient sampling. Applied to Buchwald-Hartwig reaction\noptimization, our method nearly doubles the discovery rate of high-performing\nreactions compared to static LLM embeddings (from 24% to 43% coverage of the\ntop 5% reactions in just 50 optimization iterations). We also observe a 14%\nimprovement over domain-specific representations without requiring specialized\nfeatures. Extensive empirical evaluation across 19 benchmarks - ranging from\ngeneral chemistry to reaction and molecular property optimization -\ndemonstrates our method's robustness, generality, and consistent improvements\nacross: (1) tasks, (2) LLM architectures (encoder, decoder, encoder-decoder),\n(3) pretraining domains (chemistry-related or general-purpose) and (4)\nhyperparameter settings (tuned once on a single dataset). Finally, we explain\nthese improvements: joint LLM-GP optimization through marginal likelihood\nimplicitly performs contrastive learning, aligning representations to produce\n(1) better-structured embedding spaces, (2) improved uncertainty calibration,\nand (3) more efficient sampling - without requiring any external loss. This\nwork provides both practical advances in sample-efficient optimization and\ninsights into what makes effective Bayesian optimization.",
      "tldr_zh": "该论文提出了GOLLuM，一种新颖的架构，将LLM的微调重新定义为通过深度核方法进行高斯过程(GP)边际似然优化。GOLLuM引入了基于LLM的深度核，与GP联合优化，结合了LLM提供丰富灵活的输入空间和GP建模空间并进行预测不确定性的优点，从而实现更高效的采样。在Buchwald-Hartwig反应优化中，GOLLuM方法使高性能反应的发现率几乎翻倍。在包括化学、反应和分子性质优化在内的19个基准测试中，GOLLuM展示了其鲁棒性、通用性和持续改进。通过边际似然进行联合LLM-GP优化隐式地执行对比学习，从而产生更好的结构化嵌入空间、改进的不确定性校准和更高效的采样。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06265v1",
      "published_date": "2025-04-08 17:59:57 UTC",
      "updated_date": "2025-04-08 17:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:04:16.788828"
    },
    {
      "arxiv_id": "2504.06260v1",
      "title": "FEABench: Evaluating Language Models on Multiphysics Reasoning Ability",
      "title_zh": "FEABench：评估语言模型在多物理场推理能力上的表现\n",
      "authors": [
        "Nayantara Mudur",
        "Hao Cui",
        "Subhashini Venugopalan",
        "Paul Raccuglia",
        "Michael P. Brenner",
        "Peter Norgaard"
      ],
      "abstract": "Building precise simulations of the real world and invoking numerical solvers\nto answer quantitative problems is an essential requirement in engineering and\nscience. We present FEABench, a benchmark to evaluate the ability of large\nlanguage models (LLMs) and LLM agents to simulate and solve physics,\nmathematics and engineering problems using finite element analysis (FEA). We\nintroduce a comprehensive evaluation scheme to investigate the ability of LLMs\nto solve these problems end-to-end by reasoning over natural language problem\ndescriptions and operating COMSOL Multiphysics$^\\circledR$, an FEA software, to\ncompute the answers. We additionally design a language model agent equipped\nwith the ability to interact with the software through its Application\nProgramming Interface (API), examine its outputs and use tools to improve its\nsolutions over multiple iterations. Our best performing strategy generates\nexecutable API calls 88% of the time. LLMs that can successfully interact with\nand operate FEA software to solve problems such as those in our benchmark would\npush the frontiers of automation in engineering. Acquiring this capability\nwould augment LLMs' reasoning skills with the precision of numerical solvers\nand advance the development of autonomous systems that can tackle complex\nproblems in the real world. The code is available at\nhttps://github.com/google/feabench",
      "tldr_zh": "FEABench是一个用于评估大型语言模型(LLMs)在多物理场推理能力上的基准测试。该基准旨在考察LLMs模拟和解决物理、数学和工程问题的能力，通过有限元分析(FEA)并结合COMSOL Multiphysics软件。研究设计了一个综合评估方案，通过自然语言问题描述驱动LLMs操作FEA软件，端到端地解决问题。此外，还设计了一个语言模型Agent，使其能够通过API与软件交互，检查输出并迭代改进解决方案。最佳策略实现了88%的可执行API调用生成率。该研究旨在推动工程自动化前沿，将LLMs的推理能力与数值求解器的精度相结合，从而促进能够解决现实世界复杂问题的自主系统的发展。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "39 pages. Accepted at the NeurIPS 2024 Workshops on Mathematical\n  Reasoning and AI and Open-World Agents",
      "pdf_url": "http://arxiv.org/pdf/2504.06260v1",
      "published_date": "2025-04-08 17:59:39 UTC",
      "updated_date": "2025-04-08 17:59:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:04:28.539877"
    },
    {
      "arxiv_id": "2504.06235v1",
      "title": "Decentralized Federated Domain Generalization with Style Sharing: A Formal Modeling and Convergence Analysis",
      "title_zh": "基于风格共享的去中心化联邦领域泛化：形式化建模与收敛性分析\n",
      "authors": [
        "Shahryar Zehtabi",
        "Dong-Jun Han",
        "Seyyedali Hosseinalipour",
        "Christopher G. Brinton"
      ],
      "abstract": "Much of the federated learning (FL) literature focuses on settings where\nlocal dataset statistics remain the same between training and testing time.\nRecent advances in domain generalization (DG) aim to use data from source\n(training) domains to train a model that generalizes well to data from unseen\ntarget (testing) domains. In this paper, we are motivated by two major gaps in\nexisting work on FL and DG: (1) the lack of formal mathematical analysis of DG\nobjectives and training processes; and (2) DG research in FL being limited to\nthe conventional star-topology architecture. Addressing the second gap, we\ndevelop $\\textit{Decentralized Federated Domain Generalization with Style\nSharing}$ ($\\texttt{StyleDDG}$), a fully decentralized DG algorithm designed to\nallow devices in a peer-to-peer network to achieve DG based on sharing style\ninformation inferred from their datasets. Additionally, we fill the first gap\nby providing the first systematic approach to mathematically analyzing\nstyle-based DG training optimization. We cast existing centralized DG\nalgorithms within our framework, and employ their formalisms to model\n$\\texttt{StyleDDG}$. Based on this, we obtain analytical conditions under which\na sub-linear convergence rate of $\\texttt{StyleDDG}$ can be obtained. Through\nexperiments on two popular DG datasets, we demonstrate that $\\texttt{StyleDDG}$\ncan obtain significant improvements in accuracy across target domains with\nminimal added communication overhead compared to decentralized gradient methods\nthat do not employ style sharing.",
      "tldr_zh": "该论文提出了一种去中心化的联邦域泛化算法，名为$\\texttt{StyleDDG}$，旨在解决联邦学习中域泛化问题，并填补现有研究在数学分析和去中心化架构上的空白。$\\texttt{StyleDDG}$允许对等网络中的设备通过共享从数据集中推断出的风格信息来实现域泛化。论文对基于风格的DG训练优化进行了系统的数学分析，建立了$\\texttt{StyleDDG}$的 formal 模型，并获得了其亚线性收敛速度的分析条件。实验结果表明，与不采用风格共享的去中心化梯度方法相比，$\\texttt{StyleDDG}$在目标域上的准确率显著提高，且通信开销最小。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06235v1",
      "published_date": "2025-04-08 17:32:56 UTC",
      "updated_date": "2025-04-08 17:32:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:04:40.381158"
    },
    {
      "arxiv_id": "2504.06214v1",
      "title": "From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models",
      "title_zh": "从 128K 到 4M：超长上下文大型语言模型的高效训练\n",
      "authors": [
        "Chejian Xu",
        "Wei Ping",
        "Peng Xu",
        "Zihan Liu",
        "Boxin Wang",
        "Mohammad Shoeybi",
        "Bo Li",
        "Bryan Catanzaro"
      ],
      "abstract": "Long-context capabilities are essential for a wide range of applications,\nincluding document and video understanding, in-context learning, and\ninference-time scaling, all of which require models to process and reason over\nlong sequences of text and multimodal data. In this work, we introduce a\nefficient training recipe for building ultra-long context LLMs from aligned\ninstruct model, pushing the boundaries of context lengths from 128K to 1M, 2M,\nand 4M tokens. Our approach leverages efficient continued pretraining\nstrategies to extend the context window and employs effective instruction\ntuning to maintain the instruction-following and reasoning abilities. Our\nUltraLong-8B, built on Llama3.1-Instruct with our recipe, achieves\nstate-of-the-art performance across a diverse set of long-context benchmarks.\nImportantly, models trained with our approach maintain competitive performance\non standard benchmarks, demonstrating balanced improvements for both long and\nshort context tasks. We further provide an in-depth analysis of key design\nchoices, highlighting the impacts of scaling strategies and data composition.\nOur findings establish a robust framework for efficiently scaling context\nlengths while preserving general model capabilities. We release all model\nweights at: https://ultralong.github.io/.",
      "tldr_zh": "该论文提出了一种高效的训练方法，用于构建超长上下文的大语言模型(LLMs)，将上下文长度从128K扩展到1M、2M和4M tokens。该方法利用高效的持续预训练策略来扩展上下文窗口，并采用有效的指令微调来保持模型的指令跟随和推理能力。基于Llama3.1-Instruct构建的UltraLong-8B模型，在各种长上下文基准测试中取得了state-of-the-art的性能，同时在标准基准测试中保持了竞争力。研究还深入分析了关键设计选择，强调了缩放策略和数据组成的影响。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06214v1",
      "published_date": "2025-04-08 16:58:58 UTC",
      "updated_date": "2025-04-08 16:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:04:52.266578"
    },
    {
      "arxiv_id": "2504.06207v1",
      "title": "An experimental survey and Perspective View on Meta-Learning for Automated Algorithms Selection and Parametrization",
      "title_zh": "关于元学习在自动化算法选择和参数化中的应用：一项实验性调查和展望\n",
      "authors": [
        "Moncef Garouani"
      ],
      "abstract": "Considerable progress has been made in the recent literature studies to\ntackle the Algorithms Selection and Parametrization (ASP) problem, which is\ndiversified in multiple meta-learning setups. Yet there is a lack of surveys\nand comparative evaluations that critically analyze, summarize and assess the\nperformance of existing methods. In this paper, we provide an overview of the\nstate of the art in this continuously evolving field. The survey sheds light on\nthe motivational reasons for pursuing classifiers selection through\nmeta-learning. In this regard, Automated Machine Learning (AutoML) is usually\ntreated as an ASP problem under the umbrella of the democratization of machine\nlearning. Accordingly, AutoML makes machine learning techniques accessible to\ndomain scientists who are interested in applying advanced analytics but lack\nthe required expertise. It can ease the task of manually selecting ML\nalgorithms and tuning related hyperparameters. We comprehensively discuss the\ndifferent phases of classifiers selection based on a generic framework that is\nformed as an outcome of reviewing prior works. Subsequently, we propose a\nbenchmark knowledge base of 4 millions previously learned models and present\nextensive comparative evaluations of the prominent methods for classifiers\nselection based on 08 classification algorithms and 400 benchmark datasets. The\ncomparative study quantitatively assesses the performance of algorithms\nselection methods along while emphasizing the strengths and limitations of\nexisting studies.",
      "tldr_zh": "本文对元学习在自动算法选择和参数化(ASP)问题上的应用进行了实验性调研和展望。针对该领域缺乏系统性综述和对比评估的现状，本文概述了最新的研究进展，阐述了通过元学习进行分类器选择的动机，并指出自动机器学习(AutoML)通常被视为ASP问题，旨在降低机器学习的使用门槛。论文基于对先前工作的回顾，提出了一个通用的分类器选择框架，并在此基础上构建了一个包含400万个先前学习模型的基准知识库。通过对8种分类算法和400个基准数据集的广泛对比评估，论文定量评估了现有算法选择方法的性能，并强调了现有研究的优势和局限性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06207v1",
      "published_date": "2025-04-08 16:51:22 UTC",
      "updated_date": "2025-04-08 16:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:05:04.611115"
    },
    {
      "arxiv_id": "2504.06196v1",
      "title": "TxGemma: Efficient and Agentic LLMs for Therapeutics",
      "title_zh": "TxGemma：用于治疗学的高效且具有能动性的大语言模型\n",
      "authors": [
        "Eric Wang",
        "Samuel Schmidgall",
        "Paul F. Jaeger",
        "Fan Zhang",
        "Rory Pilgrim",
        "Yossi Matias",
        "Joelle Barral",
        "David Fleet",
        "Shekoofeh Azizi"
      ],
      "abstract": "Therapeutic development is a costly and high-risk endeavor that is often\nplagued by high failure rates. To address this, we introduce TxGemma, a suite\nof efficient, generalist large language models (LLMs) capable of therapeutic\nproperty prediction as well as interactive reasoning and explainability. Unlike\ntask-specific models, TxGemma synthesizes information from diverse sources,\nenabling broad application across the therapeutic development pipeline. The\nsuite includes 2B, 9B, and 27B parameter models, fine-tuned from Gemma-2 on a\ncomprehensive dataset of small molecules, proteins, nucleic acids, diseases,\nand cell lines. Across 66 therapeutic development tasks, TxGemma achieved\nsuperior or comparable performance to the state-of-the-art generalist model on\n64 (superior on 45), and against state-of-the-art specialist models on 50\n(superior on 26). Fine-tuning TxGemma models on therapeutic downstream tasks,\nsuch as clinical trial adverse event prediction, requires less training data\nthan fine-tuning base LLMs, making TxGemma suitable for data-limited\napplications. Beyond these predictive capabilities, TxGemma features\nconversational models that bridge the gap between general LLMs and specialized\nproperty predictors. These allow scientists to interact in natural language,\nprovide mechanistic reasoning for predictions based on molecular structure, and\nengage in scientific discussions. Building on this, we further introduce\nAgentic-Tx, a generalist therapeutic agentic system powered by Gemini 2.5 that\nreasons, acts, manages diverse workflows, and acquires external domain\nknowledge. Agentic-Tx surpasses prior leading models on the Humanity's Last\nExam benchmark (Chemistry & Biology) with 52.3% relative improvement over\no3-mini (high) and 26.7% over o3-mini (high) on GPQA (Chemistry) and excels\nwith improvements of 6.3% (ChemBench-Preference) and 2.4% (ChemBench-Mini) over\no3-mini (high).",
      "tldr_zh": "该研究提出了TxGemma，一套高效且通用的LLM，用于治疗药物开发。TxGemma模型家族（2B、9B和27B参数）基于Gemma-2，并在包含小分子、蛋白质、核酸、疾病和细胞系的大型数据集上进行微调，能够进行治疗性质预测、交互式推理和可解释性分析。在66项治疗开发任务中，TxGemma的性能优于或可与SOTA通用模型相媲美。研究进一步引入了Agentic-Tx，一个基于Gemini 2.5的通用治疗Agentic系统，它能够推理、行动、管理工作流程并获取外部领域知识，在Humanity's Last Exam和GPQA等基准测试中超越了先前的领先模型。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06196v1",
      "published_date": "2025-04-08 16:39:02 UTC",
      "updated_date": "2025-04-08 16:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:05:16.680551"
    },
    {
      "arxiv_id": "2504.06193v1",
      "title": "Heuristic Methods are Good Teachers to Distill MLPs for Graph Link Prediction",
      "title_zh": "启发式方法是指导 MLPs 进行图链接预测的优秀教师\n",
      "authors": [
        "Zongyue Qin",
        "Shichang Zhang",
        "Mingxuan Ju",
        "Tong Zhao",
        "Neil Shah",
        "Yizhou Sun"
      ],
      "abstract": "Link prediction is a crucial graph-learning task with applications including\ncitation prediction and product recommendation. Distilling Graph Neural\nNetworks (GNNs) teachers into Multi-Layer Perceptrons (MLPs) students has\nemerged as an effective approach to achieve strong performance and reducing\ncomputational cost by removing graph dependency. However, existing distillation\nmethods only use standard GNNs and overlook alternative teachers such as\nspecialized model for link prediction (GNN4LP) and heuristic methods (e.g.,\ncommon neighbors). This paper first explores the impact of different teachers\nin GNN-to-MLP distillation. Surprisingly, we find that stronger teachers do not\nalways produce stronger students: MLPs distilled from GNN4LP can underperform\nthose distilled from simpler GNNs, while weaker heuristic methods can teach\nMLPs to near-GNN performance with drastically reduced training costs. Building\non these insights, we propose Ensemble Heuristic-Distilled MLPs (EHDM), which\neliminates graph dependencies while effectively integrating complementary\nsignals via a gating mechanism. Experiments on ten datasets show an average\n7.93% improvement over previous GNN-to-MLP approaches with 1.95-3.32 times less\ntraining time, indicating EHDM is an efficient and effective link prediction\nmethod.",
      "tldr_zh": "该论文研究了图链接预测中，将图神经网络(GNNs)教师模型提炼成多层感知机(MLPs)学生模型的方法。研究发现，更强的教师模型（如GNN4LP）并不一定能产生更强的学生模型，而简单的启发式方法反而能以更低的训练成本使MLPs达到接近GNN的性能。基于此，论文提出了Ensemble Heuristic-Distilled MLPs (EHDM)模型，该模型通过门控机制有效整合互补信号，消除了图依赖性。实验结果表明，EHDM在十个数据集上相比之前的GNN-to-MLP方法平均提升了7.93%，训练时间减少了1.95-3.32倍，是一种高效的链接预测方法。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06193v1",
      "published_date": "2025-04-08 16:35:11 UTC",
      "updated_date": "2025-04-08 16:35:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:05:28.600205"
    },
    {
      "arxiv_id": "2504.06188v1",
      "title": "SkillFlow: Efficient Skill and Code Transfer Through Communication in Adapting AI Agents",
      "title_zh": "SkillFlow：通过通信在自适应 AI 智能体中实现高效技能和代码迁移\n",
      "authors": [
        "Pagkratios Tagkopoulos",
        "Fangzhou Li",
        "Ilias Tagkopoulos"
      ],
      "abstract": "AI agents are autonomous systems that can execute specific tasks based on\npredefined programming. Here, we present SkillFlow, a modular,\ntechnology-agnostic framework that allows agents to expand their functionality\nin an ad-hoc fashion by acquiring new skills from their environment or other\nagents. We present a theoretical model that examines under which conditions\nthis framework would be beneficial, and we then explore SkillFlow's ability to\naccelerate task completion and lead to lower cumulative costs in a real-world\napplication, namely scheduling agents for calendar events. We demonstrate that\nwithin a few iterations, SkillFlow leads to considerable (24.8%, p-value =\n$6.4\\times10^{-3}$) gains in time and cost, especially when the communication\ncost is high. Finally, we draw analogies from well-studied biological systems\nand compare this framework to that of lateral gene transfer, a significant\nprocess of adaptation and evolution in novel environments.",
      "tldr_zh": "SkillFlow是一个模块化、技术无关的框架，旨在使AI智能体能够通过从环境或其他智能体获取新技能来扩展其功能。该框架通过通信实现技能和代码的高效转移。理论模型分析了该框架的优势条件。在日历事件调度这一实际应用中，SkillFlow加速了任务完成并降低了累积成本。实验表明，在几次迭代后，SkillFlow在时间和成本方面取得了显著收益（24.8%），尤其是在通信成本较高时。该研究还将SkillFlow与生物系统中的横向基因转移进行了类比，认为其是适应新环境的重要过程。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06188v1",
      "published_date": "2025-04-08 16:33:24 UTC",
      "updated_date": "2025-04-08 16:33:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:05:40.275981"
    },
    {
      "arxiv_id": "2504.06185v1",
      "title": "WoundAmbit: Bridging State-of-the-Art Semantic Segmentation and Real-World Wound Care",
      "title_zh": "WoundAmbit：连接最先进的语义分割与真实世界的伤口护理\n",
      "authors": [
        "Vanessa Borst",
        "Timo Dittus",
        "Tassilo Dege",
        "Astrid Schmieder",
        "Samuel Kounev"
      ],
      "abstract": "Chronic wounds affect a large population, particularly the elderly and\ndiabetic patients, who often exhibit limited mobility and co-existing health\nconditions. Automated wound monitoring via mobile image capture can reduce\nin-person physician visits by enabling remote tracking of wound size. Semantic\nsegmentation is key to this process, yet wound segmentation remains\nunderrepresented in medical imaging research. To address this, we benchmark\nstate-of-the-art deep learning models from general-purpose vision, medical\nimaging, and top methods from public wound challenges. For fair comparison, we\nstandardize training, data augmentation, and evaluation, conducting\ncross-validationto minimize partitioning bias. We also assess real-world\ndeployment aspects, including generalization to an out-of-distribution wound\ndataset, computational efficiency, and interpretability. Additionally, we\npropose a reference object-based approach to convert AI-generated masks into\nclinically relevant wound size estimates, and evaluate this, along with mask\nquality, for the best models based on physician assessments. Overall, the\ntransformer-based TransNeXt showed the highest levels of generalizability.\nDespite variations in inference times, all models processed at least one image\nper second on the CPU, which is deemed adequate for the intended application.\nInterpretability analysis typically revealed prominent activations in wound\nregions, emphasizing focus on clinically relevant features. Expert evaluation\nshowed high mask approval for all analyzed models, with VWFormer and ConvNeXtS\nbackbone performing the best. Size retrieval accuracy was similar across\nmodels, and predictions closely matched expert annotations. Finally, we\ndemonstrate how our AI-driven wound size estimation framework, WoundAmbit, can\nbe integrated into a custom telehealth system. Our code will be made available\non GitHub upon publication.",
      "tldr_zh": "该研究针对慢性伤口患者的远程监测需求，对最先进的深度学习语义分割模型在伤口分割任务上进行了基准测试。研究比较了通用视觉、医学图像以及公开伤口挑战赛中的优秀方法，并标准化了训练、数据增强和评估流程。同时，评估了模型在泛化性、计算效率和可解释性等实际部署方面的性能。此外，论文提出了一种基于参考对象的方法，将AI生成的mask转换为临床相关的伤口大小估计。实验结果表明，基于Transformer的TransNeXt模型具有最高的泛化能力，而VWFormer和ConvNeXtS在专家评估中表现最佳。最终，研究展示了AI驱动的伤口大小估计框架WoundAmbit如何集成到远程医疗系统中。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Main paper: 17 pages; supplementary material: 16 pages; paper\n  submitted to the application track of the European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECML PKDD 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.06185v1",
      "published_date": "2025-04-08 16:25:59 UTC",
      "updated_date": "2025-04-08 16:25:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:05:52.676165"
    },
    {
      "arxiv_id": "2504.06176v1",
      "title": "A Self-Supervised Framework for Space Object Behaviour Characterisation",
      "title_zh": "一种用于空间物体行为特征分析的自监督框架\n",
      "authors": [
        "Ian Groves",
        "Andrew Campbell",
        "James Fernandes",
        "Diego Rodriguez",
        "Paul Murray",
        "Massimiliano Vasile",
        "Victoria Nockles"
      ],
      "abstract": "Foundation Models, pre-trained on large unlabelled datasets before\ntask-specific fine-tuning, are increasingly being applied to specialised\ndomains. Recent examples include ClimaX for climate and Clay for satellite\nEarth observation, but a Foundation Model for Space Object Behavioural Analysis\nhas not yet been developed. As orbital populations grow, automated methods for\ncharacterising space object behaviour are crucial for space safety. We present\na Space Safety and Sustainability Foundation Model focusing on space object\nbehavioural analysis using light curves (LCs). We implemented a\nPerceiver-Variational Autoencoder (VAE) architecture, pre-trained with\nself-supervised reconstruction and masked reconstruction on 227,000 LCs from\nthe MMT-9 observatory. The VAE enables anomaly detection, motion prediction,\nand LC generation. We fine-tuned the model for anomaly detection & motion\nprediction using two independent LC simulators (CASSANDRA and GRIAL\nrespectively), using CAD models of boxwing, Sentinel-3, SMOS, and Starlink\nplatforms. Our pre-trained model achieved a reconstruction error of 0.01%,\nidentifying potentially anomalous light curves through reconstruction\ndifficulty. After fine-tuning, the model scored 88% and 82% accuracy, with 0.90\nand 0.95 ROC AUC scores respectively in both anomaly detection and motion mode\nprediction (sun-pointing, spin, etc.). Analysis of high-confidence anomaly\npredictions on real data revealed distinct patterns including characteristic\nobject profiles and satellite glinting. Here, we demonstrate how\nself-supervised learning can simultaneously enable anomaly detection, motion\nprediction, and synthetic data generation from rich representations learned in\npre-training. Our work therefore supports space safety and sustainability\nthrough automated monitoring and simulation capabilities.",
      "tldr_zh": "该论文提出了一种自监督框架，用于空间物体行为特征分析，旨在解决日益增长的轨道物体数量带来的空间安全问题。该框架基于Perceiver-VAE架构，利用MMT-9天文台的227,000条光变曲线进行预训练，通过自监督重建和掩码重建学习空间物体的行为表征。该模型能够进行异常检测、运动预测和光变曲线生成。在CASSANDRA和GRIAL模拟器上进行微调后，该模型在异常检测和运动模式预测方面分别取得了88%和82%的准确率，以及0.90和0.95的ROC AUC评分。该研究表明，自监督学习能够同时实现异常检测、运动预测和合成数据生成，从而支持空间安全和可持续性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.space-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06176v1",
      "published_date": "2025-04-08 16:19:19 UTC",
      "updated_date": "2025-04-08 16:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:06:04.547412"
    },
    {
      "arxiv_id": "2504.06173v1",
      "title": "Multi-Modality Sensing in mmWave Beamforming for Connected Vehicles Using Deep Learning",
      "title_zh": "基于深度学习的毫米波波束成形中面向互联车辆的多模态感知",
      "authors": [
        "Muhammad Baqer Mollah",
        "Honggang Wang",
        "Mohammad Ataul Karim",
        "Hua Fang"
      ],
      "abstract": "Beamforming techniques are considered as essential parts to compensate severe\npath losses in millimeter-wave (mmWave) communications. In particular, these\ntechniques adopt large antenna arrays and formulate narrow beams to obtain\nsatisfactory received powers. However, performing accurate beam alignment over\nnarrow beams for efficient link configuration by traditional standard defined\nbeam selection approaches, which mainly rely on channel state information and\nbeam sweeping through exhaustive searching, imposes computational and\ncommunications overheads. And, such resulting overheads limit their potential\nuse in vehicle-to-infrastructure (V2I) and vehicle-to-vehicle (V2V)\ncommunications involving highly dynamic scenarios. In comparison, utilizing\nout-of-band contextual information, such as sensing data obtained from sensor\ndevices, provides a better alternative to reduce overheads. This paper presents\na deep learning-based solution for utilizing the multi-modality sensing data\nfor predicting the optimal beams having sufficient mmWave received powers so\nthat the best V2I and V2V line-of-sight links can be ensured proactively. The\nproposed solution has been tested on real-world measured mmWave sensing and\ncommunication data, and the results show that it can achieve up to 98.19%\naccuracies while predicting top-13 beams. Correspondingly, when compared to\nexisting been sweeping approach, the beam sweeping searching space and time\noverheads are greatly shortened roughly by 79.67% and 91.89%, respectively\nwhich confirm a promising solution for beamforming in mmWave enabled\ncommunications.",
      "tldr_zh": "该论文提出了一种基于深度学习的多模态感知方法，用于毫米波(mmWave)波束成形，旨在解决传统波束选择方法在高动态车联网(V2I/V2V)场景中计算和通信开销大的问题。该方法利用传感器获取的带外上下文信息，预测具有足够毫米波接收功率的最佳波束，从而主动确保最佳的V2I和V2V视距链路。实验结果表明，该方案在预测前13个最佳波束时，准确率高达98.19%，与现有的波束扫描方法相比，波束扫描搜索空间和时间开销分别缩短了约79.67%和91.89%，验证了其在毫米波通信波束成形中的应用潜力。\n",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.NI",
      "comment": "15 Pages",
      "pdf_url": "http://arxiv.org/pdf/2504.06173v1",
      "published_date": "2025-04-08 16:18:00 UTC",
      "updated_date": "2025-04-08 16:18:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:06:16.578126"
    },
    {
      "arxiv_id": "2504.06165v1",
      "title": "Real-Time Pitch/F0 Detection Using Spectrogram Images and Convolutional Neural Networks",
      "title_zh": "基于频谱图图像和卷积神经网络的实时音高/F0检测\n",
      "authors": [
        "Xufang Zhao",
        "Omer Tsimhoni"
      ],
      "abstract": "This paper presents a novel approach to detect F0 through Convolutional\nNeural Networks and image processing techniques to directly estimate pitch from\nspectrogram images. Our new approach demonstrates a very good detection\naccuracy; a total of 92% of predicted pitch contours have strong or moderate\ncorrelations to the true pitch contours. Furthermore, the experimental\ncomparison between our new approach and other state-of-the-art CNN methods\nreveals that our approach can enhance the detection rate by approximately 5%\nacross various Signal-to-Noise Ratio conditions.",
      "tldr_zh": "本文提出了一种新的方法，利用卷积神经网络(CNN)和图像处理技术，直接从声谱图图像中估计音高(F0)，从而实现实时音高检测。该方法表现出非常好的检测精度，92%的预测音高轮廓与真实的音高轮廓具有强或中等的相关性。与其它先进的CNN方法相比，该方法在各种信噪比(Signal-to-Noise Ratio)条件下，检测率提高了约5%。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06165v1",
      "published_date": "2025-04-08 16:01:25 UTC",
      "updated_date": "2025-04-08 16:01:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:06:28.218119"
    },
    {
      "arxiv_id": "2504.06160v2",
      "title": "Navigating the Rabbit Hole: Emergent Biases in LLM-Generated Attack Narratives Targeting Mental Health Groups",
      "title_zh": "误入歧途：LLM 生成的针对精神健康群体的攻击性叙事中涌现的偏见\n",
      "authors": [
        "Rijul Magu",
        "Arka Dutta",
        "Sean Kim",
        "Ashiqur R. KhudaBukhsh",
        "Munmun De Choudhury"
      ],
      "abstract": "Large Language Models (LLMs) have been shown to demonstrate imbalanced biases\nagainst certain groups. However, the study of unprovoked targeted attacks by\nLLMs towards at-risk populations remains underexplored. Our paper presents\nthree novel contributions: (1) the explicit evaluation of LLM-generated attacks\non highly vulnerable mental health groups; (2) a network-based framework to\nstudy the propagation of relative biases; and (3) an assessment of the relative\ndegree of stigmatization that emerges from these attacks. Our analysis of a\nrecently released large-scale bias audit dataset reveals that mental health\nentities occupy central positions within attack narrative networks, as revealed\nby a significantly higher mean centrality of closeness (p-value = 4.06e-10) and\ndense clustering (Gini coefficient = 0.7). Drawing from sociological\nfoundations of stigmatization theory, our stigmatization analysis indicates\nincreased labeling components for mental health disorder-related targets\nrelative to initial targets in generation chains. Taken together, these\ninsights shed light on the structural predilections of large language models to\nheighten harmful discourse and highlight the need for suitable approaches for\nmitigation.",
      "tldr_zh": "该研究揭示了大型语言模型(LLMs)在生成针对精神健康群体的攻击性叙事时，存在潜在的偏见。通过评估LLMs对弱势精神健康群体的攻击，并提出基于网络的框架来研究相对偏见的传播，以及评估攻击中出现的污名化程度，研究发现了三个主要贡献。分析表明，精神健康实体在攻击叙事网络中占据中心位置，且污名化分析显示，与生成链中的初始目标相比，与精神健康障碍相关的目标的标签成分有所增加。这些发现突显了LLMs在加剧有害言论方面的结构性倾向，并强调需要采取适当的缓解措施。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG",
        "cs.SI",
        "J.4; K.4.1; K.4.2"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06160v2",
      "published_date": "2025-04-08 15:56:57 UTC",
      "updated_date": "2025-04-09 04:24:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:06:40.484560"
    },
    {
      "arxiv_id": "2504.06143v1",
      "title": "ARLO: A Tailorable Approach for Transforming Natural Language Software Requirements into Architecture using LLMs",
      "title_zh": "ARLO：一种利用 LLM 将自然语言软件需求转化为架构的可定制方法\n",
      "authors": [
        "Tooraj Helmi"
      ],
      "abstract": "Software requirements expressed in natural language (NL) frequently suffer\nfrom verbosity, ambiguity, and inconsistency. This creates a range of\nchallenges, including selecting an appropriate architecture for a system and\nassessing different architectural alternatives. Relying on human expertise to\naccomplish the task of mapping NL requirements to architecture is\ntime-consuming and error-prone. This paper proposes ARLO, an approach that\nautomates this task by leveraging (1) a set of NL requirements for a system,\n(2) an existing standard that specifies architecturally relevant software\nquality attributes, and (3) a readily available Large Language Model (LLM).\nSpecifically, ARLO determines the subset of NL requirements for a given system\nthat is architecturally relevant and maps that subset to a tailorable matrix of\narchitectural choices. ARLO applies integer linear programming on the\narchitectural-choice matrix to determine the optimal architecture for the\ncurrent requirements. We demonstrate ARLO's efficacy using a set of real-world\nexamples. We highlight ARLO's ability (1) to trace the selected architectural\nchoices to the requirements and (2) to isolate NL requirements that exert a\nparticular influence on a system's architecture. This allows the\nidentification, comparative assessment, and exploration of alternative\narchitectural choices based on the requirements and constraints expressed\ntherein.",
      "tldr_zh": "该论文提出了一种名为ARLO的方法，利用大型语言模型(LLM)将自然语言(NL)表达的软件需求自动转化为系统架构。ARLO方法首先确定与架构相关的NL需求子集，并将其映射到一个可定制的架构选择矩阵。然后，通过整数线性规划在该矩阵上寻找最优架构。实验结果表明，ARLO能够有效地将需求追溯到所选的架构选择，并识别对系统架构具有特定影响的NL需求，从而支持对不同架构选择的评估和探索。该方法旨在解决自然语言需求中常见的冗余、模糊和不一致问题，并减少人工映射需求到架构的时间和错误。\n",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06143v1",
      "published_date": "2025-04-08 15:38:42 UTC",
      "updated_date": "2025-04-08 15:38:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:06:52.549882"
    },
    {
      "arxiv_id": "2504.06138v1",
      "title": "A Multimedia Analytics Model for the Foundation Model Era",
      "title_zh": "基础模型时代的多媒体分析模型\n",
      "authors": [
        "Marcel Worring",
        "Jan Zahálka",
        "Stef van den Elzen",
        "Maximilian Fischer",
        "Daniel Keim"
      ],
      "abstract": "The rapid advances in Foundation Models and agentic Artificial Intelligence\nare transforming multimedia analytics by enabling richer, more sophisticated\ninteractions between humans and analytical systems. Existing conceptual models\nfor visual and multimedia analytics, however, do not adequately capture the\ncomplexity introduced by these powerful AI paradigms. To bridge this gap, we\npropose a comprehensive multimedia analytics model specifically designed for\nthe foundation model era. Building upon established frameworks from visual\nanalytics, multimedia analytics, knowledge generation, analytic task\ndefinition, mixed-initiative guidance, and human-in-the-loop reinforcement\nlearning, our model emphasizes integrated human-AI teaming based on visual\nanalytics agents from both technical and conceptual perspectives. Central to\nthe model is a seamless, yet explicitly separable, interaction channel between\nexpert users and semi-autonomous analytical processes, ensuring continuous\nalignment between user intent and AI behavior. The model addresses practical\nchallenges in sensitive domains such as intelligence analysis, investigative\njournalism, and other fields handling complex, high-stakes data. We illustrate\nthrough detailed case studies how our model facilitates deeper understanding\nand targeted improvement of multimedia analytics solutions. By explicitly\ncapturing how expert users can optimally interact with and guide AI-powered\nmultimedia analytics systems, our conceptual framework sets a clear direction\nfor system design, comparison, and future research.",
      "tldr_zh": "本文提出了一个针对Foundation Model时代的多媒体分析模型，旨在弥合现有视觉和多媒体分析概念模型与新兴AI范式之间的差距。该模型基于视觉分析、多媒体分析、知识生成等框架，强调人机集成协作，特别是专家用户与半自主分析过程之间的无缝交互。通过显式分离的交互通道，确保用户意图与AI行为的持续对齐。该模型适用于情报分析、调查新闻等敏感领域，并通过案例研究展示了其如何促进对多媒体分析解决方案的深入理解和改进，为系统设计、比较和未来研究提供了清晰的方向。\n",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06138v1",
      "published_date": "2025-04-08 15:35:59 UTC",
      "updated_date": "2025-04-08 15:35:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:07:04.535477"
    },
    {
      "arxiv_id": "2504.06136v1",
      "title": "QGen Studio: An Adaptive Question-Answer Generation, Training and Evaluation Platform",
      "title_zh": "QGen Studio：一个自适应的问答生成、训练和评估平台\n",
      "authors": [
        "Movina Moses",
        "Mohab Elkaref",
        "James Barry",
        "Shinnosuke Tanaka",
        "Vishnudev Kuruvanthodi",
        "Nathan Herr",
        "Campbell D Watson",
        "Geeth De Mel"
      ],
      "abstract": "We present QGen Studio: an adaptive question-answer generation, training, and\nevaluation platform. QGen Studio enables users to leverage large language\nmodels (LLMs) to create custom question-answer datasets and fine-tune models on\nthis synthetic data. It features a dataset viewer and model explorer to\nstreamline this process. The dataset viewer provides key metrics and visualizes\nthe context from which the QA pairs are generated, offering insights into data\nquality. The model explorer supports model comparison, allowing users to\ncontrast the performance of their trained LLMs against other models, supporting\nperformance benchmarking and refinement. QGen Studio delivers an interactive,\nend-to-end solution for generating QA datasets and training scalable,\ndomain-adaptable models. The studio will be open-sourced soon, allowing users\nto deploy it locally.",
      "tldr_zh": "QGen Studio是一个自适应的问答生成、训练和评估平台。它利用大型语言模型(LLMs)创建定制的问答数据集，并在此合成数据上进行模型微调。该平台包含数据集查看器和模型浏览器，用于简化流程，提供数据质量的洞察，并支持模型性能的基准测试和改进。QGen Studio提供了一个交互式的端到端解决方案，用于生成问答数据集和训练可扩展的、领域自适应的模型，并将很快开源。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06136v1",
      "published_date": "2025-04-08 15:32:09 UTC",
      "updated_date": "2025-04-08 15:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:07:16.248988"
    },
    {
      "arxiv_id": "2504.06135v1",
      "title": "Decentralizing AI Memory: SHIMI, a Semantic Hierarchical Memory Index for Scalable Agent Reasoning",
      "title_zh": "去中心化 AI 记忆：SHIMI，一种用于可扩展智能体推理的语义分层记忆索引\n",
      "authors": [
        "Tooraj Helmi"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) and vector-based search have become\nfoundational tools for memory in AI systems, yet they struggle with\nabstraction, scalability, and semantic precision - especially in decentralized\nenvironments. We present SHIMI (Semantic Hierarchical Memory Index), a unified\narchitecture that models knowledge as a dynamically structured hierarchy of\nconcepts, enabling agents to retrieve information based on meaning rather than\nsurface similarity. SHIMI organizes memory into layered semantic nodes and\nsupports top-down traversal from abstract intent to specific entities, offering\nmore precise and explainable retrieval. Critically, SHIMI is natively designed\nfor decentralized ecosystems, where agents maintain local memory trees and\nsynchronize them asynchronously across networks. We introduce a lightweight\nsync protocol that leverages Merkle-DAG summaries, Bloom filters, and\nCRDT-style conflict resolution to enable partial synchronization with minimal\noverhead. Through benchmark experiments and use cases involving decentralized\nagent collaboration, we demonstrate SHIMI's advantages in retrieval accuracy,\nsemantic fidelity, and scalability - positioning it as a core infrastructure\nlayer for decentralized cognitive systems.",
      "tldr_zh": "该论文提出了语义分层记忆索引(SHIMI)，一种用于可扩展智能体推理的去中心化AI记忆架构。SHIMI将知识建模为动态分层概念结构，允许智能体基于语义而非表面相似性检索信息。SHIMI采用分层语义节点组织记忆，支持从抽象意图到特定实体的自顶向下遍历，实现更精确和可解释的检索。SHIMI原生设计用于去中心化生态系统，智能体维护本地记忆树并在网络中异步同步。通过Merkle-DAG摘要、Bloom过滤器和CRDT风格的冲突解决，实现轻量级同步协议。实验证明，SHIMI在检索准确性、语义保真度和可扩展性方面具有优势，可作为去中心化认知系统的核心基础设施层。\n",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06135v1",
      "published_date": "2025-04-08 15:31:00 UTC",
      "updated_date": "2025-04-08 15:31:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:07:28.626610"
    },
    {
      "arxiv_id": "2504.06122v2",
      "title": "Leanabell-Prover: Posttraining Scaling in Formal Reasoning",
      "title_zh": "Leanabell-Prover：形式推理中的后训练缩放\n",
      "authors": [
        "Jingyuan Zhang",
        "Qi Wang",
        "Xingguang Ji",
        "Yahui Liu",
        "Yang Yue",
        "Fuzheng Zhang",
        "Di Zhang",
        "Guorui Zhou",
        "Kun Gai"
      ],
      "abstract": "Recent advances in automated theorem proving (ATP) through LLMs have\nhighlighted the potential of formal reasoning with Lean 4 codes. However, ATP\nhas not yet be revolutionized by the recent posttraining scaling as\ndemonstrated by Open AI O1/O3 and Deepseek R1. In this work, we investigate the\nentire posttraining of ATP, aiming to align it with breakthroughs in reasoning\nmodels in natural languages. To begin, we continual train current ATP models\nwith a hybrid dataset, which consists of numerous statement-proof pairs, and\nadditional data aimed at incorporating cognitive behaviors that emulate human\nreasoning and hypothesis refinement. Next, we explore reinforcement learning\nwith the use of outcome reward returned by Lean 4 compiler. Through our\ndesigned continual training and reinforcement learning processes, we have\nsuccessfully improved existing formal provers, including both\nDeepSeek-Prover-v1.5 and Goedel-Prover, achieving state-of-the-art performance\nin the field of whole-proof generation. For example, we achieve a 59.8% pass\nrate (pass@32) on MiniF2F. This is an on-going project and we will\nprogressively update our findings, release our data and training details.",
      "tldr_zh": "本文介绍了Leanabell-Prover，旨在探索后训练扩展在形式推理中的应用，以期将LLM在自然语言推理模型上的突破引入自动化定理证明(ATP)领域。研究者通过混合数据集对现有ATP模型进行持续训练，该数据集包含语句-证明对以及模拟人类推理和假设细化的认知行为数据。此外，他们还探索了利用Lean 4编译器返回的结果奖励进行强化学习的方法。实验结果表明，通过设计的持续训练和强化学习过程，Leanabell-Prover成功地改进了DeepSeek-Prover-v1.5和Goedel-Prover等现有形式证明器，在完整证明生成方面达到了最先进的性能，例如在MiniF2F上实现了59.8%的pass@32通过率。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06122v2",
      "published_date": "2025-04-08 15:15:26 UTC",
      "updated_date": "2025-04-09 04:03:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:07:40.772605"
    },
    {
      "arxiv_id": "2504.06105v1",
      "title": "Uncertainty-Aware Hybrid Machine Learning in Virtual Sensors for Vehicle Sideslip Angle Estimation",
      "title_zh": "虚拟传感器中用于车辆侧滑角估计的、具有不确定性感知能力的混合机器学习方法\n",
      "authors": [
        "Abinav Kalyanasundaram",
        "Karthikeyan Chandra Sekaran",
        "Philipp Stauber",
        "Michael Lange",
        "Wolfgang Utschick",
        "Michael Botsch"
      ],
      "abstract": "Precise vehicle state estimation is crucial for safe and reliable autonomous\ndriving. The number of measurable states and their precision offered by the\nonboard vehicle sensor system are often constrained by cost. For instance,\nmeasuring critical quantities such as the Vehicle Sideslip Angle (VSA) poses\nsignificant commercial challenges using current optical sensors. This paper\naddresses these limitations by focusing on the development of high-performance\nvirtual sensors to enhance vehicle state estimation for active safety. The\nproposed Uncertainty-Aware Hybrid Learning (UAHL) architecture integrates a\nmachine learning model with vehicle motion models to estimate VSA directly from\nonboard sensor data. A key aspect of the UAHL architecture is its focus on\nuncertainty quantification for individual model estimates and hybrid fusion.\nThese mechanisms enable the dynamic weighting of uncertainty-aware predictions\nfrom machine learning and vehicle motion models to produce accurate and\nreliable hybrid VSA estimates. This work also presents a novel dataset named\nReal-world Vehicle State Estimation Dataset (ReV-StED), comprising synchronized\nmeasurements from advanced vehicle dynamic sensors. The experimental results\ndemonstrate the superior performance of the proposed method for VSA estimation,\nhighlighting UAHL as a promising architecture for advancing virtual sensors and\nenhancing active safety in autonomous vehicles.",
      "tldr_zh": "本文提出了一种不确定性感知混合学习(Uncertainty-Aware Hybrid Learning, UAHL)架构，用于车辆侧滑角(Vehicle Sideslip Angle, VSA)的虚拟传感器估计，旨在解决自动驾驶中车辆状态精确估计问题。该架构融合了机器学习模型与车辆运动模型，直接从车载传感器数据估计VSA。UAHL的关键在于对模型估计和混合融合的不确定性进行量化，从而动态地对来自机器学习和车辆运动模型的不确定性感知预测进行加权，生成准确可靠的混合VSA估计。此外，本文还发布了一个名为Real-world Vehicle State Estimation Dataset (ReV-StED)的新数据集。实验结果表明，该方法在VSA估计方面表现出色，证明UAHL架构在推进虚拟传感器和增强自动驾驶主动安全方面的潜力。\n",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted at the 2025 IEEE Intelligent Vehicles Symposium (IV)",
      "pdf_url": "http://arxiv.org/pdf/2504.06105v1",
      "published_date": "2025-04-08 14:49:58 UTC",
      "updated_date": "2025-04-08 14:49:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:07:52.721650"
    },
    {
      "arxiv_id": "2504.06099v1",
      "title": "Towards Varroa destructor mite detection using a narrow spectra illumination",
      "title_zh": "基于窄光谱照明的瓦螨检测方法研究\n",
      "authors": [
        "Samuel Bielik",
        "Simon Bilik"
      ],
      "abstract": "This paper focuses on the development and modification of a beehive\nmonitoring device and Varroa destructor detection on the bees with the help of\nhyperspectral imagery while utilizing a U-net, semantic segmentation\narchitecture, and conventional computer vision methods. The main objectives\nwere to collect a dataset of bees and mites, and propose the computer vision\nmodel which can achieve the detection between bees and mites.",
      "tldr_zh": "本文提出了一种利用窄光谱照明和高光谱图像技术检测蜜蜂身上瓦螨的方法。研究人员开发并改进了蜂箱监测设备，采集了蜜蜂和瓦螨的数据集。他们使用U-Net语义分割架构和传统计算机视觉方法，构建了一个能够区分蜜蜂和瓦螨的计算机视觉模型。该研究旨在为蜜蜂瓦螨的早期检测提供一种新的技术手段。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06099v1",
      "published_date": "2025-04-08 14:41:42 UTC",
      "updated_date": "2025-04-08 14:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:08:04.310137"
    },
    {
      "arxiv_id": "2504.06091v1",
      "title": "Real-Time LaCAM",
      "title_zh": "实时LaCAM\n",
      "authors": [
        "Runzhe Liang",
        "Rishi Veerapaneni",
        "Daniel Harabor",
        "Jiaoyang Li",
        "Maxim Likhachev"
      ],
      "abstract": "The vast majority of Multi-Agent Path Finding (MAPF) methods with\ncompleteness guarantees require planning full horizon paths. However, planning\nfull horizon paths can take too long and be impractical in real-world\napplications. Instead, real-time planning and execution, which only allows the\nplanner a finite amount of time before executing and replanning, is more\npractical for real world multi-agent systems. Several methods utilize real-time\nplanning schemes but none are provably complete, which leads to livelock or\ndeadlock. Our main contribution is to show the first Real-Time MAPF method with\nprovable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023)\nin an incremental fashion. Our results show how we can iteratively plan for\ncongested environments with a cutoff time of milliseconds while still\nmaintaining the same success rate as full horizon LaCAM. We also show how it\ncan be used with a single-step learned MAPF policy. The proposed Real-Time\nLaCAM also provides us with a general mechanism for using iterative constraints\nfor completeness in future real-time MAPF algorithms.",
      "tldr_zh": "本文提出了一种具有完备性保证的实时多智能体路径规划(MAPF)方法，称为Real-Time LaCAM。该方法基于LaCAM算法，通过增量式规划，在有限的时间内进行规划和执行，解决了传统MAPF方法规划完整路径耗时过长的问题。Real-Time LaCAM能够在毫秒级的截断时间内，在拥堵环境中进行迭代规划，并保持与完整LaCAM相同的成功率。此外，该方法还可以与单步学习的MAPF策略结合使用。Real-Time LaCAM为未来实时MAPF算法的完备性提供了一种通用的迭代约束机制。\n",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06091v1",
      "published_date": "2025-04-08 14:31:05 UTC",
      "updated_date": "2025-04-08 14:31:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:08:16.606110"
    },
    {
      "arxiv_id": "2504.06088v1",
      "title": "MCAT: Visual Query-Based Localization of Standard Anatomical Clips in Fetal Ultrasound Videos Using Multi-Tier Class-Aware Token Transformer",
      "title_zh": "MCAT：基于多层类别感知 Token Transformer 的胎儿超声视频中标准解剖切面的可视化查询定位\n",
      "authors": [
        "Divyanshu Mishra",
        "Pramit Saha",
        "He Zhao",
        "Netzahualcoyotl Hernandez-Cruz",
        "Olga Patey",
        "Aris Papageorghiou",
        "J. Alison Noble"
      ],
      "abstract": "Accurate standard plane acquisition in fetal ultrasound (US) videos is\ncrucial for fetal growth assessment, anomaly detection, and adherence to\nclinical guidelines. However, manually selecting standard frames is\ntime-consuming and prone to intra- and inter-sonographer variability. Existing\nmethods primarily rely on image-based approaches that capture standard frames\nand then classify the input frames across different anatomies. This ignores the\ndynamic nature of video acquisition and its interpretation. To address these\nchallenges, we introduce Multi-Tier Class-Aware Token Transformer (MCAT), a\nvisual query-based video clip localization (VQ-VCL) method, to assist\nsonographers by enabling them to capture a quick US sweep. By then providing a\nvisual query of the anatomy they wish to analyze, MCAT returns the video clip\ncontaining the standard frames for that anatomy, facilitating thorough\nscreening for potential anomalies. We evaluate MCAT on two ultrasound video\ndatasets and a natural image VQ-VCL dataset based on Ego4D. Our model\noutperforms state-of-the-art methods by 10% and 13% mIoU on the ultrasound\ndatasets and by 5.35% mIoU on the Ego4D dataset, using 96% fewer tokens. MCAT's\nefficiency and accuracy have significant potential implications for public\nhealth, especially in low- and middle-income countries (LMICs), where it may\nenhance prenatal care by streamlining standard plane acquisition, simplifying\nUS-based screening, diagnosis and allowing sonographers to examine more\npatients.",
      "tldr_zh": "该论文提出了一个基于视觉查询的视频片段定位(VQ-VCL)方法，名为多层类别感知Token Transformer (MCAT)，用于在胎儿超声视频中定位标准解剖切面。MCAT通过视觉查询的方式，允许超声医师快速扫描超声视频，并返回包含特定解剖结构标准切面的视频片段，从而辅助筛查潜在异常。实验结果表明，MCAT在两个超声视频数据集和一个自然图像VQ-VCL数据集Ego4D上，均优于现有技术，在超声数据集上mIoU分别提高了10%和13%，在Ego4D数据集上提高了5.35%，同时减少了96%的token使用。MCAT的高效率和准确性，尤其是在中低收入国家，具有提升产前护理水平的潜力。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.06088v1",
      "published_date": "2025-04-08 14:29:15 UTC",
      "updated_date": "2025-04-08 14:29:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:08:28.894707"
    },
    {
      "arxiv_id": "2504.06037v2",
      "title": "Confidence Regularized Masked Language Modeling using Text Length",
      "title_zh": "基于文本长度的置信度正则化掩码语言建模\n",
      "authors": [
        "Seunghyun Ji",
        "Soowon Lee"
      ],
      "abstract": "Masked language modeling is a widely used method for learning language\nrepresentations, where the model predicts a randomly masked word in each input.\nHowever, this approach typically considers only a single correct answer during\ntraining, ignoring the variety of plausible alternatives that humans might\nchoose. This issue becomes more pronounced when the input text is short, as the\npossible word distribution tends to have higher entropy, potentially causing\nthe model to become overconfident in its predictions. To mitigate this, we\npropose a novel confidence regularizer that adaptively adjusts the\nregularization strength based on the input length. Experiments on the GLUE and\nSQuAD benchmarks show that our method improves both accuracy and expected\ncalibration error",
      "tldr_zh": "这篇论文提出了一种基于文本长度的置信度正则化掩码语言建模方法，旨在解决传统掩码语言模型在训练时只考虑单一正确答案，忽略多种合理选择的问题，尤其是在短文本输入中，模型容易过度自信。该方法通过引入一个置信度正则化项，并根据输入长度自适应地调整正则化强度，从而缓解这一问题。在GLUE和SQuAD基准测试上的实验结果表明，该方法能够提高模型的准确率和期望校准误差(expected calibration error)。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.06037v2",
      "published_date": "2025-04-08 13:37:08 UTC",
      "updated_date": "2025-04-09 02:32:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:08:40.499372"
    },
    {
      "arxiv_id": "2504.06020v1",
      "title": "Information-Theoretic Reward Decomposition for Generalizable RLHF",
      "title_zh": "基于信息论的奖励分解，用于可泛化的RLHF",
      "authors": [
        "Liyuan Mao",
        "Haoran Xu",
        "Amy Zhang",
        "Weinan Zhang",
        "Chenjia Bai"
      ],
      "abstract": "A generalizable reward model is crucial in Reinforcement Learning from Human\nFeedback (RLHF) as it enables correctly evaluating unseen prompt-response\npairs. However, existing reward models lack this ability, as they are typically\ntrained by increasing the reward gap between chosen and rejected responses,\nwhile overlooking the prompts that the responses are conditioned on.\nConsequently, when the trained reward model is evaluated on prompt-response\npairs that lie outside the data distribution, neglecting the effect of prompts\nmay result in poor generalization of the reward model. To address this issue,\nwe decompose the reward value into two independent components: prompt-free\nreward and prompt-related reward. Prompt-free reward represents the evaluation\nthat is determined only by responses, while the prompt-related reward reflects\nthe reward that derives from both the prompt and the response. We extract these\ntwo components from an information-theoretic perspective, which requires no\nextra models. Subsequently, we propose a new reward learning algorithm by\nprioritizing data samples based on their prompt-free reward values. Through toy\nexamples, we demonstrate that the extracted prompt-free and prompt-related\nrewards effectively characterize two parts of the reward model. Further,\nstandard evaluations show that our method improves both the alignment\nperformance and the generalization capability of the reward model.",
      "tldr_zh": "这篇论文提出了一种信息论驱动的奖励分解方法，旨在提升基于人类反馈的强化学习(RLHF)中奖励模型的泛化能力。该方法将奖励值分解为与提示无关的奖励和与提示相关的奖励两个独立部分，分别代表仅由回复决定的评价以及由提示和回复共同决定的奖励。通过信息论视角提取这两个组成部分，无需额外的模型。此外，论文还提出了一种新的奖励学习算法，该算法基于与提示无关的奖励值来优先选择数据样本。实验结果表明，该方法能够有效提升奖励模型的对齐性能和泛化能力。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Work done during internships at Institute of Artificial Intelligence\n  (TeleAI), China Telecom",
      "pdf_url": "http://arxiv.org/pdf/2504.06020v1",
      "published_date": "2025-04-08 13:26:07 UTC",
      "updated_date": "2025-04-08 13:26:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:08:52.500090"
    },
    {
      "arxiv_id": "2504.06016v1",
      "title": "The Hall of AI Fears and Hopes: Comparing the Views of AI Influencers and those of Members of the U.S. Public Through an Interactive Platform",
      "title_zh": "人工智能恐惧与希望殿堂：通过交互式平台比较人工智能影响者与美国公众的观点\n",
      "authors": [
        "Gustavo Moreira",
        "Edyta Paulina Bogucka",
        "Marios Constantinides",
        "Daniele Quercia"
      ],
      "abstract": "AI development is shaped by academics and industry leaders - let us call them\n``influencers'' - but it is unclear how their views align with those of the\npublic. To address this gap, we developed an interactive platform that served\nas a data collection tool for exploring public views on AI, including their\nfears, hopes, and overall sense of hopefulness. We made the platform available\nto 330 participants representative of the U.S. population in terms of age, sex,\nethnicity, and political leaning, and compared their views with those of 100 AI\ninfluencers identified by Time magazine. The public fears AI getting out of\ncontrol, while influencers emphasize regulation, seemingly to deflect attention\nfrom their alleged focus on monetizing AI's potential. Interestingly, the views\nof AI influencers from underrepresented groups such as women and people of\ncolor often differ from the views of underrepresented groups in the public.",
      "tldr_zh": "该研究对比了美国公众和AI领域“影响者”（如学者和行业领袖）对AI的恐惧和期望。通过一个互动平台，研究收集了330名代表美国人口的参与者和100名《时代》杂志评选的AI影响者的观点。结果显示，公众更担心AI失控，而影响者则强调监管，似乎是为了转移对其关注AI潜在盈利的注意力。此外，来自弱势群体（如女性和有色人种）的AI影响者的观点，与公众中弱势群体的观点存在差异。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "I.2; K.4.1; K.4.2; K.4.3"
      ],
      "primary_category": "cs.HC",
      "comment": "27 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.06016v1",
      "published_date": "2025-04-08 13:21:31 UTC",
      "updated_date": "2025-04-08 13:21:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:09:04.399590"
    },
    {
      "arxiv_id": "2504.06006v1",
      "title": "Optuna vs Code Llama: Are LLMs a New Paradigm for Hyperparameter Tuning?",
      "title_zh": "Optuna 对比 Code Llama：大语言模型是超参数调优的新范式吗？\n",
      "authors": [
        "Roman Kochnev",
        "Arash Torabi Goodarzi",
        "Zofia Antonina Bentyn",
        "Dmitry Ignatov",
        "Radu Timofte"
      ],
      "abstract": "Optimal hyperparameter selection is critical for maximizing neural network\nperformance, especially as models grow in complexity. This work investigates\nthe viability of using large language models (LLMs) for hyperparameter\noptimization by employing a fine-tuned version of Code Llama. Through\nparameter-efficient fine-tuning using LoRA, we adapt the LLM to generate\naccurate and efficient hyperparameter recommendations tailored to diverse\nneural network architectures. Unlike traditional methods such as Optuna, which\nrely on exhaustive trials, the proposed approach achieves competitive or\nsuperior results in terms of Root Mean Square Error (RMSE) while significantly\nreducing computational overhead. Our approach highlights that LLM-based\noptimization not only matches state-of-the-art methods like Tree-structured\nParzen Estimators but also accelerates the tuning process. This positions LLMs\nas a promising alternative to conventional optimization techniques,\nparticularly for rapid experimentation. Furthermore, the ability to generate\nhyperparameters in a single inference step makes this method particularly\nwell-suited for resource-constrained environments such as edge devices and\nmobile applications, where computational efficiency is paramount. The results\nconfirm that LLMs, beyond their efficiency, offer substantial time savings and\ncomparable stability, underscoring their value in advancing machine learning\nworkflows. All generated hyperparameters are included in the LEMUR Neural\nNetwork (NN) Dataset, which is publicly available and serves as an open-source\nbenchmark for hyperparameter optimization research.",
      "tldr_zh": "该研究探讨了使用大型语言模型(LLMs)进行超参数优化的可行性，通过LoRA对Code Llama进行参数高效的微调，使其能为不同的神经网络架构生成准确高效的超参数推荐。与依赖大量试验的传统方法Optuna不同，该方法在均方根误差(RMSE)方面取得了有竞争力甚至更优越的结果，同时显著降低了计算开销。结果表明，基于LLM的优化不仅能与Tree-structured Parzen Estimators等先进方法相媲美，还能加速调优过程，使其成为传统优化技术的有前景的替代方案，尤其适用于资源受限的环境。所有生成的超参数都包含在LEMUR神经网络(NN)数据集中，该数据集是公开的超参数优化研究基准。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.06006v1",
      "published_date": "2025-04-08 13:15:47 UTC",
      "updated_date": "2025-04-08 13:15:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:09:16.831721"
    },
    {
      "arxiv_id": "2504.05995v1",
      "title": "NativQA Framework: Enabling LLMs with Native, Local, and Everyday Knowledge",
      "title_zh": "NativQA 框架：利用原生、本地和日常知识赋能大型语言模型",
      "authors": [
        "Firoj Alam",
        "Md Arid Hasan",
        "Sahinur Rahman Laskar",
        "Mucahid Kutlu",
        "Shammur Absar Chowdhury"
      ],
      "abstract": "The rapid advancement of large language models (LLMs) has raised concerns\nabout cultural bias, fairness, and their applicability in diverse linguistic\nand underrepresented regional contexts. To enhance and benchmark the\ncapabilities of LLMs, there is a need to develop large-scale resources focused\non multilingual, local, and cultural contexts. In this study, we propose a\nframework, NativQA, that can seamlessly construct large-scale, culturally and\nregionally aligned QA datasets in native languages. The framework utilizes\nuser-defined seed queries and leverages search engines to collect\nlocation-specific, everyday information. It has been evaluated across 39\nlocations in 24 countries and in 7 languages, ranging from extremely\nlow-resource to high-resource languages, which resulted over 300K Question\nAnswer (QA) pairs. The developed resources can be used for LLM benchmarking and\nfurther fine-tuning. The framework has been made publicly available for the\ncommunity (https://gitlab.com/nativqa/nativqa-framework).",
      "tldr_zh": "该研究提出了NativQA框架，旨在解决大型语言模型(LLMs)在文化偏见、公平性以及在不同语言和代表性不足的区域环境中的适用性问题。NativQA能够无缝构建大规模、文化和区域对齐的本地语言QA数据集。该框架利用用户定义的种子查询，并利用搜索引擎收集特定位置的日常信息。实验评估在24个国家的39个地点和7种语言（包括极低资源到高资源语言）中进行，产生了超过30万个问答(QA)对。开发的资源可用于LLM基准测试和进一步微调。该框架已公开提供给社区。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "F.2.2; I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "LLMs, Native, Multilingual, Language Diversity, Contextual\n  Understanding, Minority Languages, Culturally Informed, Foundation Models,\n  Large Language Models",
      "pdf_url": "http://arxiv.org/pdf/2504.05995v1",
      "published_date": "2025-04-08 13:01:51 UTC",
      "updated_date": "2025-04-08 13:01:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:09:28.589735"
    },
    {
      "arxiv_id": "2504.05956v1",
      "title": "Temporal Alignment-Free Video Matching for Few-shot Action Recognition",
      "title_zh": "无需时间对齐的视频匹配方法，用于小样本动作识别\n",
      "authors": [
        "SuBeen Lee",
        "WonJun Moon",
        "Hyun Seok Seong",
        "Jae-Pil Heo"
      ],
      "abstract": "Few-Shot Action Recognition (FSAR) aims to train a model with only a few\nlabeled video instances. A key challenge in FSAR is handling divergent\nnarrative trajectories for precise video matching. While the frame- and\ntuple-level alignment approaches have been promising, their methods heavily\nrely on pre-defined and length-dependent alignment units (e.g., frames or\ntuples), which limits flexibility for actions of varying lengths and speeds. In\nthis work, we introduce a novel TEmporal Alignment-free Matching (TEAM)\napproach, which eliminates the need for temporal units in action representation\nand brute-force alignment during matching. Specifically, TEAM represents each\nvideo with a fixed set of pattern tokens that capture globally discriminative\nclues within the video instance regardless of action length or speed, ensuring\nits flexibility. Furthermore, TEAM is inherently efficient, using token-wise\ncomparisons to measure similarity between videos, unlike existing methods that\nrely on pairwise comparisons for temporal alignment. Additionally, we propose\nan adaptation process that identifies and removes common information across\nclasses, establishing clear boundaries even between novel categories. Extensive\nexperiments demonstrate the effectiveness of TEAM. Codes are available at\ngithub.com/leesb7426/TEAM.",
      "tldr_zh": "这篇论文提出了一种新的时间对齐无关的视频匹配方法(TEAM)，用于解决小样本动作识别(FSAR)中不同叙事轨迹带来的挑战。TEAM通过一组固定数量的模式令牌(pattern tokens)来表示每个视频，从而捕捉视频中全局判别线索，无需预定义的时间单元，增强了对不同长度和速度动作的适应性。与依赖成对比较进行时间对齐的现有方法不同，TEAM通过令牌级别的比较来衡量视频之间的相似性，提高了效率。此外，论文还提出了一种自适应过程，用于识别和删除跨类别的共同信息，从而在新的类别之间建立清晰的边界。实验结果表明，TEAM在小样本动作识别任务中表现出色。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 7 figures, 6 tables, Accepted to CVPR 2025 as Oral\n  Presentation",
      "pdf_url": "http://arxiv.org/pdf/2504.05956v1",
      "published_date": "2025-04-08 12:11:11 UTC",
      "updated_date": "2025-04-08 12:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:09:40.877704"
    },
    {
      "arxiv_id": "2504.05951v1",
      "title": "Representing Normative Regulations in OWL DL for Automated Compliance Checking Supported by Text Annotation",
      "title_zh": "在 OWL DL 中表示规范性规章，以支持通过文本标注实现的自动化合规性检查\n",
      "authors": [
        "Ildar Baimuratov",
        "Denis Turygin"
      ],
      "abstract": "Compliance checking is the process of determining whether a regulated entity\nadheres to these regulations. Currently, compliance checking is predominantly\nmanual, requiring significant time and highly skilled experts, while still\nbeing prone to errors caused by the human factor. Various approaches have been\nexplored to automate compliance checking, however, representing regulations in\nOWL DL language which enables compliance checking through OWL reasoning has not\nbeen adopted. In this work, we propose an annotation schema and an algorithm\nthat transforms text annotations into machine-interpretable OWL DL code. The\nproposed approach is validated through a proof-of-concept implementation\napplied to examples from the building construction domain.",
      "tldr_zh": "本文提出了一种将规范性法规表示为OWL DL本体的方法，旨在实现自动化的合规性检查。目前合规性检查主要依赖人工，耗时且易出错。该研究提出了一种注释模式和算法，可以将文本注释转换为机器可解释的OWL DL代码，从而利用OWL推理进行合规性检查。通过在建筑施工领域的概念验证实施，验证了该方法的可行性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05951v1",
      "published_date": "2025-04-08 12:05:21 UTC",
      "updated_date": "2025-04-08 12:05:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:09:52.409422"
    },
    {
      "arxiv_id": "2504.05950v1",
      "title": "AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems",
      "title_zh": "AEGIS：基于人类注意力机制的智能车辆系统可解释性引导\n",
      "authors": [
        "Zhuoli Zhuang",
        "Cheng-You Lu",
        "Yu-Cheng Fred Chang",
        "Yu-Kai Wang",
        "Thomas Do",
        "Chin-Teng Lin"
      ],
      "abstract": "Improving decision-making capabilities in Autonomous Intelligent Vehicles\n(AIVs) has been a heated topic in recent years. Despite advancements, training\nmachines to capture regions of interest for comprehensive scene understanding,\nlike human perception and reasoning, remains a significant challenge. This\nstudy introduces a novel framework, Human Attention-based Explainable Guidance\nfor Intelligent Vehicle Systems (AEGIS). AEGIS utilizes human attention,\nconverted from eye-tracking, to guide reinforcement learning (RL) models to\nidentify critical regions of interest for decision-making. AEGIS uses a\npre-trained human attention model to guide RL models to identify critical\nregions of interest for decision-making. By collecting 1.2 million frames from\n20 participants across six scenarios, AEGIS pre-trains a model to predict human\nattention patterns.",
      "tldr_zh": "本文提出了一种名为AEGIS的框架，即基于人类注意力机制的可解释智能车辆系统指导方法。该框架利用眼动追踪数据转化而成的人类注意力，引导强化学习(RL)模型识别关键区域，从而进行决策。AEGIS通过收集来自20名参与者在六种场景下的120万帧数据，预训练了一个模型来预测人类注意力模式。该方法旨在提升自动驾驶智能车辆(AIVs)的决策能力，使其更接近人类的感知和推理方式。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05950v1",
      "published_date": "2025-04-08 12:04:52 UTC",
      "updated_date": "2025-04-08 12:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:10:04.503647"
    },
    {
      "arxiv_id": "2504.05945v1",
      "title": "CKGAN: Training Generative Adversarial Networks Using Characteristic Kernel Integral Probability Metrics",
      "title_zh": "CKGAN：使用特征核积分概率度量训练生成对抗网络\n",
      "authors": [
        "Kuntian Zhang",
        "Simin Yu",
        "Yaoshu Wang",
        "Makoto Onizuka",
        "Chuan Xiao"
      ],
      "abstract": "In this paper, we propose CKGAN, a novel generative adversarial network (GAN)\nvariant based on an integral probability metrics framework with characteristic\nkernel (CKIPM). CKIPM, as a distance between two probability distributions, is\ndesigned to optimize the lowerbound of the maximum mean discrepancy (MMD) in a\nreproducing kernel Hilbert space, and thus can be used to train GANs. CKGAN\nmitigates the notorious problem of mode collapse by mapping the generated\nimages back to random noise. To save the effort of selecting the kernel\nfunction manually, we propose a soft selection method to automatically learn a\ncharacteristic kernel function. The experimental evaluation conducted on a set\nof synthetic and real image benchmarks (MNIST, CelebA, etc.) demonstrates that\nCKGAN generally outperforms other MMD-based GANs. The results also show that at\nthe cost of moderately more training time, the automatically selected kernel\nfunction delivers very close performance to the best of manually fine-tuned one\non real image benchmarks and is able to improve the performances of other\nMMD-based GANs.",
      "tldr_zh": "本文提出了一种新的生成对抗网络(GAN)变体CKGAN，它基于特征核积分概率度量(CKIPM)框架。CKIPM作为两种概率分布之间的距离，旨在优化再生核希尔伯特空间中的最大平均差异(MMD)的下界，从而可用于训练GAN。CKGAN通过将生成的图像映射回随机噪声来缓解模式崩溃问题。为了节省手动选择核函数的精力，本文提出了一种软选择方法来自动学习特征核函数。在合成图像和真实图像基准(MNIST, CelebA等)上进行的实验评估表明，CKGAN通常优于其他基于MMD的GAN。结果还表明，以适度增加训练时间为代价，自动选择的核函数在真实图像基准上提供了与手动微调的最佳核函数非常接近的性能，并且能够提高其他基于MMD的GAN的性能。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Source codes are available at https://github.com/chuanxiao1983/CKGAN/",
      "pdf_url": "http://arxiv.org/pdf/2504.05945v1",
      "published_date": "2025-04-08 11:58:56 UTC",
      "updated_date": "2025-04-08 11:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:10:17.023571"
    },
    {
      "arxiv_id": "2504.05923v1",
      "title": "Uncovering Fairness through Data Complexity as an Early Indicator",
      "title_zh": "通过数据复杂度揭示公平性：一种早期指标\n",
      "authors": [
        "Juliett Suárez Ferreira",
        "Marija Slavkovik",
        "Jorge Casillas"
      ],
      "abstract": "Fairness constitutes a concern within machine learning (ML) applications.\nCurrently, there is no study on how disparities in classification complexity\nbetween privileged and unprivileged groups could influence the fairness of\nsolutions, which serves as a preliminary indicator of potential unfairness. In\nthis work, we investigate this gap, specifically, we focus on synthetic\ndatasets designed to capture a variety of biases ranging from historical bias\nto measurement and representational bias to evaluate how various complexity\nmetrics differences correlate with group fairness metrics. We then apply\nassociation rule mining to identify patterns that link disproportionate\ncomplexity differences between groups with fairness-related outcomes, offering\ndata-centric indicators to guide bias mitigation. Our findings are also\nvalidated by their application in real-world problems, providing evidence that\nquantifying group-wise classification complexity can uncover early indicators\nof potential fairness challenges. This investigation helps practitioners to\nproactively address bias in classification tasks.",
      "tldr_zh": "该研究探讨了特权群体和非特权群体之间分类复杂度的差异如何影响机器学习模型的公平性，并将其作为潜在不公平性的早期指标。通过在合成数据集上模拟多种偏差（包括历史偏差、测量偏差和表征偏差），研究人员评估了各种复杂度指标的差异与群体公平性指标之间的相关性。利用关联规则挖掘，他们识别出将群体间复杂度差异与公平性结果联系起来的模式，从而为偏差缓解提供数据中心化的指导。实验结果在真实世界问题中得到验证，表明量化群体分类复杂度可以揭示潜在公平性挑战的早期指标，帮助从业者主动解决分类任务中的偏差。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05923v1",
      "published_date": "2025-04-08 11:28:40 UTC",
      "updated_date": "2025-04-08 11:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:10:28.595332"
    },
    {
      "arxiv_id": "2504.05908v1",
      "title": "PRIMEDrive-CoT: A Precognitive Chain-of-Thought Framework for Uncertainty-Aware Object Interaction in Driving Scene Scenario",
      "title_zh": "PRIMEDrive-CoT：一种用于驾驶场景中不确定性感知对象交互的预认知链式思维框架\n",
      "authors": [
        "Sriram Mandalika",
        "Lalitha V",
        "Athira Nambiar"
      ],
      "abstract": "Driving scene understanding is a critical real-world problem that involves\ninterpreting and associating various elements of a driving environment, such as\nvehicles, pedestrians, and traffic signals. Despite advancements in autonomous\ndriving, traditional pipelines rely on deterministic models that fail to\ncapture the probabilistic nature and inherent uncertainty of real-world\ndriving. To address this, we propose PRIMEDrive-CoT, a novel uncertainty-aware\nmodel for object interaction and Chain-of-Thought (CoT) reasoning in driving\nscenarios. In particular, our approach combines LiDAR-based 3D object detection\nwith multi-view RGB references to ensure interpretable and reliable scene\nunderstanding. Uncertainty and risk assessment, along with object interactions,\nare modelled using Bayesian Graph Neural Networks (BGNNs) for probabilistic\nreasoning under ambiguous conditions. Interpretable decisions are facilitated\nthrough CoT reasoning, leveraging object dynamics and contextual cues, while\nGrad-CAM visualizations highlight attention regions. Extensive evaluations on\nthe DriveCoT dataset demonstrate that PRIMEDrive-CoT outperforms\nstate-of-the-art CoT and risk-aware models.",
      "tldr_zh": "PRIMEDrive-CoT 是一种新的不确定性感知模型，用于驾驶场景中的对象交互和链式思维 (Chain-of-Thought, CoT) 推理。该框架结合了基于 LiDAR 的 3D 对象检测和多视角 RGB 参考，以确保可解释和可靠的场景理解。利用贝叶斯图神经网络 (Bayesian Graph Neural Networks, BGNNs) 对不确定性和风险评估以及对象交互进行建模，从而在模糊条件下进行概率推理。通过 CoT 推理，利用对象动态和上下文线索来促进可解释的决策，同时 Grad-CAM 可视化突出显示注意力区域。在 DriveCoT 数据集上的大量评估表明，PRIMEDrive-CoT 的性能优于最先进的 CoT 和风险感知模型。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at The IEEE/CVF Conference on Computer Vision and Pattern\n  Recognition 2025 - CVPRW",
      "pdf_url": "http://arxiv.org/pdf/2504.05908v1",
      "published_date": "2025-04-08 11:06:02 UTC",
      "updated_date": "2025-04-08 11:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:10:40.697143"
    },
    {
      "arxiv_id": "2504.05882v1",
      "title": "Turin3D: Evaluating Adaptation Strategies under Label Scarcity in Urban LiDAR Segmentation with Semi-Supervised Techniques",
      "title_zh": "Turin3D：利用半监督技术评估城市激光雷达分割中标签稀缺情况下的自适应策略\n",
      "authors": [
        "Luca Barco",
        "Giacomo Blanco",
        "Gaetano Chiriaco",
        "Alessia Intini",
        "Luigi La Riccia",
        "Vittorio Scolamiero",
        "Piero Boccardo",
        "Paolo Garza",
        "Fabrizio Dominici"
      ],
      "abstract": "3D semantic segmentation plays a critical role in urban modelling, enabling\ndetailed understanding and mapping of city environments. In this paper, we\nintroduce Turin3D: a new aerial LiDAR dataset for point cloud semantic\nsegmentation covering an area of around 1.43 km2 in the city centre of Turin\nwith almost 70M points. We describe the data collection process and compare\nTurin3D with others previously proposed in the literature. We did not fully\nannotate the dataset due to the complexity and time-consuming nature of the\nprocess; however, a manual annotation process was performed on the validation\nand test sets, to enable a reliable evaluation of the proposed techniques. We\nfirst benchmark the performances of several point cloud semantic segmentation\nmodels, trained on the existing datasets, when tested on Turin3D, and then\nimprove their performances by applying a semi-supervised learning technique\nleveraging the unlabelled training set. The dataset will be publicly available\nto support research in outdoor point cloud segmentation, with particular\nrelevance for self-supervised and semi-supervised learning approaches given the\nabsence of ground truth annotations for the training set.",
      "tldr_zh": "该论文介绍了Turin3D，一个新的航空LiDAR数据集，用于城市点云语义分割，覆盖了都灵市中心约1.43平方公里的区域，包含近7000万个点。由于标注过程复杂耗时，该数据集并未完全标注，但对验证集和测试集进行了手动标注，以实现对所提出技术的可靠评估。论文首先评估了在现有数据集上训练的几种点云语义分割模型在Turin3D上的性能，然后通过应用利用未标记训练集的半监督学习技术来提高其性能。该数据集将公开提供，以支持户外点云分割的研究，特别是考虑到训练集缺乏ground truth标注，对自监督和半监督学习方法具有特殊意义。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPRW2025 - USM3D",
      "pdf_url": "http://arxiv.org/pdf/2504.05882v1",
      "published_date": "2025-04-08 10:17:14 UTC",
      "updated_date": "2025-04-08 10:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:10:52.906247"
    },
    {
      "arxiv_id": "2504.05874v1",
      "title": "Systematic Parameter Decision in Approximate Model Counting",
      "title_zh": "近似模型计数中的系统化参数决策\n",
      "authors": [
        "Jinping Lei",
        "Toru Takisaka",
        "Junqiang Peng",
        "Mingyu Xiao"
      ],
      "abstract": "This paper proposes a novel approach to determining the internal parameters\nof the hashing-based approximate model counting algorithm $\\mathsf{ApproxMC}$.\nIn this problem, the chosen parameter values must ensure that\n$\\mathsf{ApproxMC}$ is Probably Approximately Correct (PAC), while also making\nit as efficient as possible. The existing approach to this problem relies on\nheuristics; in this paper, we solve this problem by formulating it as an\noptimization problem that arises from generalizing $\\mathsf{ApproxMC}$'s\ncorrectness proof to arbitrary parameter values.\n  Our approach separates the concerns of algorithm soundness and optimality,\nallowing us to address the former without the need for repetitive case-by-case\nargumentation, while establishing a clear framework for the latter.\nFurthermore, after reduction, the resulting optimization problem takes on an\nexceptionally simple form, enabling the use of a basic search algorithm and\nproviding insight into how parameter values affect algorithm performance.\nExperimental results demonstrate that our optimized parameters improve the\nruntime performance of the latest $\\mathsf{ApproxMC}$ by a factor of 1.6 to\n2.4, depending on the error tolerance.",
      "tldr_zh": "本文提出了一种新方法，用于确定基于哈希的近似模型计数算法$\\mathsf{ApproxMC}$的内部参数。该方法将参数选择问题转化为一个优化问题，该问题源于将$\\mathsf{ApproxMC}$的正确性证明推广到任意参数值。这种方法分离了算法可靠性和最优性的考量，从而可以在不需要重复的逐个案例论证的情况下解决前者，同时为后者建立一个清晰的框架。实验结果表明，优化的参数将最新$\\mathsf{ApproxMC}$的运行时间性能提高了1.6到2.4倍，具体取决于误差容限。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05874v1",
      "published_date": "2025-04-08 09:58:41 UTC",
      "updated_date": "2025-04-08 09:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:11:04.588765"
    },
    {
      "arxiv_id": "2504.05871v1",
      "title": "Agent Guide: A Simple Agent Behavioral Watermarking Framework",
      "title_zh": "Agent Guide：一种简单的智能体行为水印框架\n",
      "authors": [
        "Kaibo Huang",
        "Zhongliang Yang",
        "Linna Zhou"
      ],
      "abstract": "The increasing deployment of intelligent agents in digital ecosystems, such\nas social media platforms, has raised significant concerns about traceability\nand accountability, particularly in cybersecurity and digital content\nprotection. Traditional large language model (LLM) watermarking techniques,\nwhich rely on token-level manipulations, are ill-suited for agents due to the\nchallenges of behavior tokenization and information loss during\nbehavior-to-action translation. To address these issues, we propose Agent\nGuide, a novel behavioral watermarking framework that embeds watermarks by\nguiding the agent's high-level decisions (behavior) through probability biases,\nwhile preserving the naturalness of specific executions (action). Our approach\ndecouples agent behavior into two levels, behavior (e.g., choosing to bookmark)\nand action (e.g., bookmarking with specific tags), and applies watermark-guided\nbiases to the behavior probability distribution. We employ a z-statistic-based\nstatistical analysis to detect the watermark, ensuring reliable extraction over\nmultiple rounds. Experiments in a social media scenario with diverse agent\nprofiles demonstrate that Agent Guide achieves effective watermark detection\nwith a low false positive rate. Our framework provides a practical and robust\nsolution for agent watermarking, with applications in identifying malicious\nagents and protecting proprietary agent systems.",
      "tldr_zh": "为了解决智能体在数字生态系统中可追溯性和问责制的问题，该论文提出了一种名为Agent Guide的新型行为水印框架。该框架通过概率偏差引导智能体的高级决策（行为）来嵌入水印，同时保持特定执行（动作）的自然性。Agent Guide将智能体行为解耦为行为层（例如选择添加书签）和动作层（例如使用特定标签添加书签），并将水印引导的偏差应用于行为概率分布。通过基于z统计的统计分析来检测水印，确保在多轮迭代中可靠提取。在社交媒体场景中的实验表明，Agent Guide能够有效检测水印，且误报率较低，为识别恶意智能体和保护专有智能体系统提供了实用且强大的解决方案。\n",
      "categories": [
        "cs.AI",
        "K.6.5"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05871v1",
      "published_date": "2025-04-08 09:54:49 UTC",
      "updated_date": "2025-04-08 09:54:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:11:16.875034"
    },
    {
      "arxiv_id": "2504.05862v1",
      "title": "Are Generative AI Agents Effective Personalized Financial Advisors?",
      "title_zh": "生成式 AI 智能体能成为有效的个性化财务顾问吗？\n",
      "authors": [
        "Takehiro Takayanagi",
        "Kiyoshi Izumi",
        "Javier Sanz-Cruzado",
        "Richard McCreadie",
        "Iadh Ounis"
      ],
      "abstract": "Large language model-based agents are becoming increasingly popular as a\nlow-cost mechanism to provide personalized, conversational advice, and have\ndemonstrated impressive capabilities in relatively simple scenarios, such as\nmovie recommendations. But how do these agents perform in complex high-stakes\ndomains, where domain expertise is essential and mistakes carry substantial\nrisk? This paper investigates the effectiveness of LLM-advisors in the finance\ndomain, focusing on three distinct challenges: (1) eliciting user preferences\nwhen users themselves may be unsure of their needs, (2) providing personalized\nguidance for diverse investment preferences, and (3) leveraging advisor\npersonality to build relationships and foster trust. Via a lab-based user study\nwith 64 participants, we show that LLM-advisors often match human advisor\nperformance when eliciting preferences, although they can struggle to resolve\nconflicting user needs. When providing personalized advice, the LLM was able to\npositively influence user behavior, but demonstrated clear failure modes. Our\nresults show that accurate preference elicitation is key, otherwise, the\nLLM-advisor has little impact, or can even direct the investor toward\nunsuitable assets. More worryingly, users appear insensitive to the quality of\nadvice being given, or worse these can have an inverse relationship. Indeed,\nusers reported a preference for and increased satisfaction as well as emotional\ntrust with LLMs adopting an extroverted persona, even though those agents\nprovided worse advice.",
      "tldr_zh": "该研究评估了基于大型语言模型(LLM)的智能体作为个性化金融顾问的有效性，重点关注三个挑战：用户偏好获取、个性化指导和利用顾问性格建立信任。通过一项包含64名参与者的实验，研究表明LLM顾问在获取用户偏好方面与人类顾问表现相当，但在解决冲突需求时存在困难。在提供个性化建议时，LLM能够积极影响用户行为，但也暴露出明显的失败模式。更令人担忧的是，用户对建议质量不敏感，甚至存在反向关系，即用户更喜欢外向性格的LLM，即使它们提供的建议更差。研究强调了准确获取用户偏好的重要性，否则LLM顾问的影响甚微，甚至可能引导投资者选择不合适的资产。\n",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IR",
        "q-fin.CP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05862v1",
      "published_date": "2025-04-08 09:41:03 UTC",
      "updated_date": "2025-04-08 09:41:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:11:28.958261"
    },
    {
      "arxiv_id": "2504.05857v1",
      "title": "Towards an AI-Driven Video-Based American Sign Language Dictionary: Exploring Design and Usage Experience with Learners",
      "title_zh": "迈向 AI 驱动的基于视频的美式手语词典：与学习者一起探索设计和使用体验\n",
      "authors": [
        "Saad Hassan",
        "Matyas Bohacek",
        "Chaelin Kim",
        "Denise Crochet"
      ],
      "abstract": "Searching for unfamiliar American Sign Language (ASL) signs is challenging\nfor learners because, unlike spoken languages, they cannot type a text-based\nquery to look up an unfamiliar sign. Advances in isolated sign recognition have\nenabled the creation of video-based dictionaries, allowing users to submit a\nvideo and receive a list of the closest matching signs. Previous HCI research\nusing Wizard-of-Oz prototypes has explored interface designs for ASL\ndictionaries. Building on these studies, we incorporate their design\nrecommendations and leverage state-of-the-art sign-recognition technology to\ndevelop an automated video-based dictionary. We also present findings from an\nobservational study with twelve novice ASL learners who used this dictionary\nduring video-comprehension and question-answering tasks. Our results address\nhuman-AI interaction challenges not covered in previous WoZ research, including\nrecording and resubmitting signs, unpredictable outputs, system latency, and\nprivacy concerns. These insights offer guidance for designing and deploying\nvideo-based ASL dictionary systems.",
      "tldr_zh": "本文旨在开发一个基于AI的视频美式手语(ASL)词典，以解决学习者难以查询不熟悉手语的问题。该词典允许用户上传视频，并返回最匹配的手语列表，利用了最新的孤立手语识别技术和前人研究的设计建议。通过对12名新手ASL学习者的观察性研究，揭示了人机交互中出现的新挑战，包括录制和重新提交手语、不可预测的输出、系统延迟和隐私问题。这些发现为视频ASL词典系统的设计和部署提供了指导。\n",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05857v1",
      "published_date": "2025-04-08 09:35:46 UTC",
      "updated_date": "2025-04-08 09:35:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:11:40.783591"
    },
    {
      "arxiv_id": "2504.05855v1",
      "title": "Enhancing Coreference Resolution with Pretrained Language Models: Bridging the Gap Between Syntax and Semantics",
      "title_zh": "利用预训练语言模型增强共指消解：弥合句法和语义之间的差距\n",
      "authors": [
        "Xingzu Liu",
        "Songhang deng",
        "Mingbang Wang",
        "Zhang Dong",
        "Le Dai",
        "Jiyuan Li",
        "Ruilin Nong"
      ],
      "abstract": "Large language models have made significant advancements in various natural\nlanguage processing tasks, including coreference resolution. However,\ntraditional methods often fall short in effectively distinguishing referential\nrelationships due to a lack of integration between syntactic and semantic\ninformation. This study introduces an innovative framework aimed at enhancing\ncoreference resolution by utilizing pretrained language models. Our approach\ncombines syntax parsing with semantic role labeling to accurately capture finer\ndistinctions in referential relationships. By employing state-of-the-art\npretrained models to gather contextual embeddings and applying an attention\nmechanism for fine-tuning, we improve the performance of coreference tasks.\nExperimental results across diverse datasets show that our method surpasses\nconventional coreference resolution systems, achieving notable accuracy in\ndisambiguating references. This development not only improves coreference\nresolution outcomes but also positively impacts other natural language\nprocessing tasks that depend on precise referential understanding.",
      "tldr_zh": "本研究提出了一种新颖的框架，旨在通过利用预训练语言模型来增强共指消解(coreference resolution)的效果。该方法结合了句法分析(syntax parsing)和语义角色标注(semantic role labeling)，以精确捕捉指代关系中的细微差别。通过使用先进的预训练模型来收集上下文嵌入(contextual embeddings)，并应用注意力机制进行微调，提高了共指消解任务的性能。在多个数据集上的实验结果表明，该方法优于传统的共指消解系统，在消除歧义方面取得了显著的准确性，并对其他依赖精确指代理解的自然语言处理任务产生积极影响。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "acl submission",
      "pdf_url": "http://arxiv.org/pdf/2504.05855v1",
      "published_date": "2025-04-08 09:33:09 UTC",
      "updated_date": "2025-04-08 09:33:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:11:52.732023"
    },
    {
      "arxiv_id": "2504.05852v1",
      "title": "Physics-aware generative models for turbulent fluid flows through energy-consistent stochastic interpolants",
      "title_zh": "基于能量守恒随机插值的湍流物理感知生成模型\n",
      "authors": [
        "Nikolaj T. Mücke",
        "Benjamin Sanderse"
      ],
      "abstract": "Generative models have demonstrated remarkable success in domains such as\ntext, image, and video synthesis. In this work, we explore the application of\ngenerative models to fluid dynamics, specifically for turbulence simulation,\nwhere classical numerical solvers are computationally expensive. We propose a\nnovel stochastic generative model based on stochastic interpolants, which\nenables probabilistic forecasting while incorporating physical constraints such\nas energy stability and divergence-freeness. Unlike conventional stochastic\ngenerative models, which are often agnostic to underlying physical laws, our\napproach embeds energy consistency by making the parameters of the stochastic\ninterpolant learnable coefficients. We evaluate our method on a benchmark\nturbulence problem - Kolmogorov flow - demonstrating superior accuracy and\nstability over state-of-the-art alternatives such as autoregressive conditional\ndiffusion models (ACDMs) and PDE-Refiner. Furthermore, we achieve stable\nresults for significantly longer roll-outs than standard stochastic\ninterpolants. Our results highlight the potential of physics-aware generative\nmodels in accelerating and enhancing turbulence simulations while preserving\nfundamental conservation properties.",
      "tldr_zh": "该论文提出了一种基于能量一致性随机插值(energy-consistent stochastic interpolants)的物理感知生成模型，用于模拟湍流。该模型通过将随机插值的参数设置为可学习的系数，从而嵌入能量守恒等物理约束。与传统的随机生成模型不同，该方法更注重底层物理规律。在Kolmogorov湍流问题上的评估表明，该模型比自回归条件扩散模型(ACDMs)和PDE-Refiner等现有方法具有更高的精度和稳定性，并且能够实现比标准随机插值更长的稳定模拟。研究结果突出了物理感知生成模型在加速和增强湍流模拟方面的潜力，同时保留了基本的守恒特性。\n",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.CE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05852v1",
      "published_date": "2025-04-08 09:29:01 UTC",
      "updated_date": "2025-04-08 09:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:12:04.821588"
    },
    {
      "arxiv_id": "2504.05846v1",
      "title": "PathGPT: Leveraging Large Language Models for Personalized Route Generation",
      "title_zh": "PathGPT：利用大型语言模型进行个性化路线生成\n",
      "authors": [
        "Steeve Cuthbert Marcelyn",
        "Yucen Gao",
        "Yuzhe Zhang",
        "Xiaofeng Gao",
        "Guihai Chen"
      ],
      "abstract": "The proliferation of GPS enabled devices has led to the accumulation of a\nsubstantial corpus of historical trajectory data. By leveraging these data for\ntraining machine learning models,researchers have devised novel data-driven\nmethodologies that address the personalized route recommendation (PRR) problem.\nIn contrast to conventional algorithms such as Dijkstra shortest path\nalgorithm,these novel algorithms possess the capacity to discern and learn\npatterns within the data,thereby facilitating the generation of more\npersonalized paths. However,once these models have been trained,their\napplication is constrained to the generation of routes that align with their\ntraining patterns. This limitation renders them less adaptable to novel\nscenarios and the deployment of multiple machine learning models might be\nnecessary to address new possible scenarios,which can be costly as each model\nmust be trained separately. Inspired by recent advances in the field of Large\nLanguage Models (LLMs),we leveraged their natural language understanding\ncapabilities to develop a unified model to solve the PRR problem while being\nseamlessly adaptable to new scenarios without additional training. To\naccomplish this,we combined the extensive knowledge LLMs acquired during\ntraining with further access to external hand-crafted context\ninformation,similar to RAG (Retrieved Augmented Generation) systems,to enhance\ntheir ability to generate paths according to user-defined requirements.\nExtensive experiments on different datasets show a considerable uplift in LLM\nperformance on the PRR problem.",
      "tldr_zh": "该论文提出了PathGPT，利用大型语言模型(LLMs)解决个性化路线生成(PRR)问题。与传统的Dijkstra算法和数据驱动的PRR模型不同，PathGPT利用LLMs的自然语言理解能力，结合检索增强生成(RAG)系统，将LLMs的预训练知识与外部手工设计的上下文信息相结合，从而根据用户需求生成路线。实验结果表明，PathGPT在不同数据集上显著提升了LLMs在PRR问题上的性能，无需额外训练即可适应新场景。\n",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05846v1",
      "published_date": "2025-04-08 09:25:21 UTC",
      "updated_date": "2025-04-08 09:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:12:16.688937"
    },
    {
      "arxiv_id": "2504.05840v1",
      "title": "Momentum Boosted Episodic Memory for Improving Learning in Long-Tailed RL Environments",
      "title_zh": "动量加速情景记忆，以改善长尾 RL 环境中的学习\n",
      "authors": [
        "Dolton Fernandes",
        "Pramod Kaushik",
        "Harsh Shukla",
        "Bapi Raju Surampudi"
      ],
      "abstract": "Traditional Reinforcement Learning (RL) algorithms assume the distribution of\nthe data to be uniform or mostly uniform. However, this is not the case with\nmost real-world applications like autonomous driving or in nature where animals\nroam. Some experiences are encountered frequently, and most of the remaining\nexperiences occur rarely; the resulting distribution is called Zipfian. Taking\ninspiration from the theory of complementary learning systems, an architecture\nfor learning from Zipfian distributions is proposed where important long tail\ntrajectories are discovered in an unsupervised manner. The proposal comprises\nan episodic memory buffer containing a prioritised memory module to ensure\nimportant rare trajectories are kept longer to address the Zipfian problem,\nwhich needs credit assignment to happen in a sample efficient manner. The\nexperiences are then reinstated from episodic memory and given weighted\nimportance forming the trajectory to be executed. Notably, the proposed\narchitecture is modular, can be incorporated in any RL architecture and yields\nimproved performance in multiple Zipfian tasks over traditional architectures.\nOur method outperforms IMPALA by a significant margin on all three tasks and\nall three evaluation metrics (Zipfian, Uniform, and Rare Accuracy) and also\ngives improvements on most Atari environments that are considered challenging",
      "tldr_zh": "该论文提出了一种动量增强的情节记忆方法，用于改善长尾强化学习环境中的学习效果。该方法受到互补学习系统理论的启发，通过一个包含优先级记忆模块的情节记忆缓冲区，以无监督的方式发现重要的长尾轨迹，解决Zipfian分布带来的问题。重要且稀有的轨迹会被更长时间地保留，从而实现样本高效的信用分配。从情节记忆中恢复的经验会被赋予权重，形成待执行的轨迹。该架构具有模块化特性，可以集成到任何RL架构中，并在多个Zipfian任务中优于传统架构，在Zipfian、均匀和稀有精度等指标上显著优于IMPALA，并在大多数具有挑战性的Atari环境中有所改进。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05840v1",
      "published_date": "2025-04-08 09:21:39 UTC",
      "updated_date": "2025-04-08 09:21:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:12:29.166171"
    },
    {
      "arxiv_id": "2504.05838v1",
      "title": "Mind the Trojan Horse: Image Prompt Adapter Enabling Scalable and Deceptive Jailbreaking",
      "title_zh": "提防特洛伊木马：图像提示适配器实现可扩展且具有欺骗性的越狱攻击\n",
      "authors": [
        "Junxi Chen",
        "Junhao Dong",
        "Xiaohua Xie"
      ],
      "abstract": "Recently, the Image Prompt Adapter (IP-Adapter) has been increasingly\nintegrated into text-to-image diffusion models (T2I-DMs) to improve\ncontrollability. However, in this paper, we reveal that T2I-DMs equipped with\nthe IP-Adapter (T2I-IP-DMs) enable a new jailbreak attack named the hijacking\nattack. We demonstrate that, by uploading imperceptible image-space adversarial\nexamples (AEs), the adversary can hijack massive benign users to jailbreak an\nImage Generation Service (IGS) driven by T2I-IP-DMs and mislead the public to\ndiscredit the service provider. Worse still, the IP-Adapter's dependency on\nopen-source image encoders reduces the knowledge required to craft AEs.\nExtensive experiments verify the technical feasibility of the hijacking attack.\nIn light of the revealed threat, we investigate several existing defenses and\nexplore combining the IP-Adapter with adversarially trained models to overcome\nexisting defenses' limitations. Our code is available at\nhttps://github.com/fhdnskfbeuv/attackIPA.",
      "tldr_zh": "该论文揭示了配备图像提示适配器(IP-Adapter)的文本到图像扩散模型(T2I-DMs)存在一种新型的越狱攻击，称为劫持攻击。攻击者通过上传难以察觉的图像空间对抗样本(AEs)，可以劫持大量良性用户来越狱由T2I-IP-DMs驱动的图像生成服务(IGS)，从而误导公众并损害服务提供商的声誉。由于IP-Adapter依赖于开源图像编码器，因此制作AEs所需的知识减少。实验验证了劫持攻击的可行性。研究人员还调查了几种现有的防御措施，并探索将IP-Adapter与对抗训练模型相结合，以克服现有防御措施的局限性。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2025 as Highlight",
      "pdf_url": "http://arxiv.org/pdf/2504.05838v1",
      "published_date": "2025-04-08 09:20:29 UTC",
      "updated_date": "2025-04-08 09:20:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:12:41.019265"
    },
    {
      "arxiv_id": "2504.05830v1",
      "title": "Human Activity Recognition using RGB-Event based Sensors: A Multi-modal Heat Conduction Model and A Benchmark Dataset",
      "title_zh": "基于 RGB-Event 传感器的行为识别：一种多模态热传导模型和一个基准数据集\n",
      "authors": [
        "Shiao Wang",
        "Xiao Wang",
        "Bo Jiang",
        "Lin Zhu",
        "Guoqi Li",
        "Yaowei Wang",
        "Yonghong Tian",
        "Jin Tang"
      ],
      "abstract": "Human Activity Recognition (HAR) primarily relied on traditional RGB cameras\nto achieve high-performance activity recognition. However, the challenging\nfactors in real-world scenarios, such as insufficient lighting and rapid\nmovements, inevitably degrade the performance of RGB cameras. To address these\nchallenges, biologically inspired event cameras offer a promising solution to\novercome the limitations of traditional RGB cameras. In this work, we rethink\nhuman activity recognition by combining the RGB and event cameras. The first\ncontribution is the proposed large-scale multi-modal RGB-Event human activity\nrecognition benchmark dataset, termed HARDVS 2.0, which bridges the dataset\ngaps. It contains 300 categories of everyday real-world actions with a total of\n107,646 paired videos covering various challenging scenarios. Inspired by the\nphysics-informed heat conduction model, we propose a novel multi-modal heat\nconduction operation framework for effective activity recognition, termed\nMMHCO-HAR. More in detail, given the RGB frames and event streams, we first\nextract the feature embeddings using a stem network. Then, multi-modal Heat\nConduction blocks are designed to fuse the dual features, the key module of\nwhich is the multi-modal Heat Conduction Operation layer. We integrate RGB and\nevent embeddings through a multi-modal DCT-IDCT layer while adaptively\nincorporating the thermal conductivity coefficient via FVEs into this module.\nAfter that, we propose an adaptive fusion module based on a policy routing\nstrategy for high-performance classification. Comprehensive experiments\ndemonstrate that our method consistently performs well, validating its\neffectiveness and robustness. The source code and benchmark dataset will be\nreleased on https://github.com/Event-AHU/HARDVS/tree/HARDVSv2",
      "tldr_zh": "该论文提出了一种基于RGB和事件相机的人体活动识别(HAR)方法，旨在解决传统RGB相机在光照不足和快速运动等场景下的性能瓶颈。主要贡献包括：1) 构建了一个大规模多模态RGB-Event HAR基准数据集HARDVS 2.0，包含300类日常活动和107,646个配对视频；2) 提出了一个新颖的多模态热传导操作框架MMHCO-HAR，该框架受物理信息热传导模型的启发，通过多模态DCT-IDCT层融合RGB和事件流特征，并自适应地结合热导率系数；3) 设计了一个基于策略路由的自适应融合模块，用于高性能分类。实验结果表明，该方法具有良好的性能和鲁棒性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Journal Extension of HARDVS (AAAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2504.05830v1",
      "published_date": "2025-04-08 09:14:24 UTC",
      "updated_date": "2025-04-08 09:14:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:12:52.902898"
    },
    {
      "arxiv_id": "2504.05815v1",
      "title": "Parasite: A Steganography-based Backdoor Attack Framework for Diffusion Models",
      "title_zh": "Parasite：一种基于隐写术的扩散模型后门攻击框架\n",
      "authors": [
        "Jiahao Chen",
        "Yu Pan",
        "Yi Du",
        "Chunkai Wu",
        "Lin Wang"
      ],
      "abstract": "Recently, the diffusion model has gained significant attention as one of the\nmost successful image generation models, which can generate high-quality images\nby iteratively sampling noise. However, recent studies have shown that\ndiffusion models are vulnerable to backdoor attacks, allowing attackers to\nenter input data containing triggers to activate the backdoor and generate\ntheir desired output. Existing backdoor attack methods primarily focused on\ntarget noise-to-image and text-to-image tasks, with limited work on backdoor\nattacks in image-to-image tasks. Furthermore, traditional backdoor attacks\noften rely on a single, conspicuous trigger to generate a fixed target image,\nlacking concealability and flexibility. To address these limitations, we\npropose a novel backdoor attack method called \"Parasite\" for image-to-image\ntasks in diffusion models, which not only is the first to leverage\nsteganography for triggers hiding, but also allows attackers to embed the\ntarget content as a backdoor trigger to achieve a more flexible attack.\n\"Parasite\" as a novel attack method effectively bypasses existing detection\nframeworks to execute backdoor attacks. In our experiments, \"Parasite\" achieved\na 0 percent backdoor detection rate against the mainstream defense frameworks.\nIn addition, in the ablation study, we discuss the influence of different\nhiding coefficients on the attack results. You can find our code at\nhttps://anonymous.4open.science/r/Parasite-1715/.",
      "tldr_zh": "该论文提出了一种名为“Parasite”的新型隐写术后门攻击框架，专门针对扩散模型的image-to-image任务。与依赖于单一、明显的触发器的传统后门攻击不同，Parasite利用隐写术隐藏触发器，并将目标内容嵌入其中，实现了更灵活的攻击方式。这种方法能够有效绕过现有的后门检测框架。实验结果表明，Parasite在主流防御框架下的后门检测率为0%。该研究是首个将隐写术应用于扩散模型后门攻击的工作，并探讨了不同隐藏系数对攻击结果的影响。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05815v1",
      "published_date": "2025-04-08 08:53:47 UTC",
      "updated_date": "2025-04-08 08:53:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:13:04.724597"
    },
    {
      "arxiv_id": "2504.05806v1",
      "title": "Meta-Continual Learning of Neural Fields",
      "title_zh": "神经场上的元持续学习\n",
      "authors": [
        "Seungyoon Woo",
        "Junhyeog Yun",
        "Gunhee Kim"
      ],
      "abstract": "Neural Fields (NF) have gained prominence as a versatile framework for\ncomplex data representation. This work unveils a new problem setting termed\n\\emph{Meta-Continual Learning of Neural Fields} (MCL-NF) and introduces a novel\nstrategy that employs a modular architecture combined with optimization-based\nmeta-learning. Focused on overcoming the limitations of existing methods for\ncontinual learning of neural fields, such as catastrophic forgetting and slow\nconvergence, our strategy achieves high-quality reconstruction with\nsignificantly improved learning speed. We further introduce Fisher Information\nMaximization loss for neural radiance fields (FIM-NeRF), which maximizes\ninformation gains at the sample level to enhance learning generalization, with\nproved convergence guarantee and generalization bound. We perform extensive\nevaluations across image, audio, video reconstruction, and view synthesis tasks\non six diverse datasets, demonstrating our method's superiority in\nreconstruction quality and speed over existing MCL and CL-NF approaches.\nNotably, our approach attains rapid adaptation of neural fields for city-scale\nNeRF rendering with reduced parameter requirement.",
      "tldr_zh": "该论文提出了“神经场元持续学习”(MCL-NF)这一新问题设定，并提出了一种结合模块化架构和基于优化的元学习的新策略。该策略旨在克服现有神经场持续学习方法（如灾难性遗忘和收敛速度慢）的局限性，从而以显著提高的学习速度实现高质量重建。此外，论文还引入了用于神经辐射场的Fisher信息最大化损失(FIM-NeRF)，该损失在样本层面最大化信息增益以增强学习泛化能力，并证明了其收敛保证和泛化界限。 在图像、音频、视频重建和视图合成任务的六个不同数据集上进行了广泛的评估，证明了该方法在重建质量和速度方面优于现有的MCL和CL-NF方法。 值得注意的是，该方法实现了城市级NeRF渲染的神经场快速适应，并减少了参数需求。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05806v1",
      "published_date": "2025-04-08 08:38:37 UTC",
      "updated_date": "2025-04-08 08:38:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:13:17.296410"
    },
    {
      "arxiv_id": "2504.05801v1",
      "title": "From Superficial to Deep: Integrating External Knowledge for Follow-up Question Generation Using Knowledge Graph and LLM",
      "title_zh": "从浅层到深层：结合知识图谱和LLM的外部知识用于生成后续问题\n",
      "authors": [
        "Jianyu Liu",
        "Yi Huang",
        "Sheng Bi",
        "Junlan Feng",
        "Guilin Qi"
      ],
      "abstract": "In a conversational system, dynamically generating follow-up questions based\non context can help users explore information and provide a better user\nexperience. Humans are usually able to ask questions that involve some general\nlife knowledge and demonstrate higher order cognitive skills. However, the\nquestions generated by existing methods are often limited to shallow contextual\nquestions that are uninspiring and have a large gap to the human level. In this\npaper, we propose a three-stage external knowledge-enhanced follow-up question\ngeneration method, which generates questions by identifying contextual topics,\nconstructing a knowledge graph (KG) online, and finally combining these with a\nlarge language model to generate the final question. The model generates\ninformation-rich and exploratory follow-up questions by introducing external\ncommon sense knowledge and performing a knowledge fusion operation. Experiments\nshow that compared to baseline models, our method generates questions that are\nmore informative and closer to human questioning levels while maintaining\ncontextual relevance.",
      "tldr_zh": "该论文提出了一种三阶段的外部知识增强的后续问题生成方法，旨在提升对话系统中后续问题的深度和信息量。该方法首先识别上下文主题，然后在线构建知识图谱(KG)，最后结合大型语言模型(LLM)生成最终问题。通过引入外部常识知识并进行知识融合，模型能够生成信息丰富且具有探索性的后续问题。实验结果表明，与基线模型相比，该方法生成的后续问题更具信息量，更接近人类提问水平，同时保持了上下文相关性。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Proceedings of the 31st International Conference on Computational\n  Linguistics",
      "pdf_url": "http://arxiv.org/pdf/2504.05801v1",
      "published_date": "2025-04-08 08:31:03 UTC",
      "updated_date": "2025-04-08 08:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:13:28.558611"
    },
    {
      "arxiv_id": "2504.05786v1",
      "title": "How to Enable LLM with 3D Capacity? A Survey of Spatial Reasoning in LLM",
      "title_zh": "如何赋予 LLM 三维能力？LLM 空间推理综述\n",
      "authors": [
        "Jirong Zha",
        "Yuxuan Fan",
        "Xiao Yang",
        "Chen Gao",
        "Xinlei Chen"
      ],
      "abstract": "3D spatial understanding is essential in real-world applications such as\nrobotics, autonomous vehicles, virtual reality, and medical imaging. Recently,\nLarge Language Models (LLMs), having demonstrated remarkable success across\nvarious domains, have been leveraged to enhance 3D understanding tasks, showing\npotential to surpass traditional computer vision methods. In this survey, we\npresent a comprehensive review of methods integrating LLMs with 3D spatial\nunderstanding. We propose a taxonomy that categorizes existing methods into\nthree branches: image-based methods deriving 3D understanding from 2D visual\ndata, point cloud-based methods working directly with 3D representations, and\nhybrid modality-based methods combining multiple data streams. We\nsystematically review representative methods along these categories, covering\ndata representations, architectural modifications, and training strategies that\nbridge textual and 3D modalities. Finally, we discuss current limitations,\nincluding dataset scarcity and computational challenges, while highlighting\npromising research directions in spatial perception, multi-modal fusion, and\nreal-world applications.",
      "tldr_zh": "本文综述了如何利用大型语言模型(LLMs)提升3D空间理解能力的方法。文章提出了一种分类体系，将现有方法分为三类：基于图像的方法（从2D视觉数据推导3D理解），基于点云的方法（直接处理3D表示），以及混合模态方法（结合多个数据流）。论文系统地回顾了这些类别中的代表性方法，涵盖了数据表示、架构修改和训练策略，旨在桥接文本和3D模态。最后，讨论了当前局限性，包括数据集稀缺和计算挑战，并强调了空间感知、多模态融合和实际应用中具有前景的研究方向。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05786v1",
      "published_date": "2025-04-08 08:11:39 UTC",
      "updated_date": "2025-04-08 08:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:13:40.847790"
    },
    {
      "arxiv_id": "2504.05783v1",
      "title": "Video Flow as Time Series: Discovering Temporal Consistency and Variability for VideoQA",
      "title_zh": "将视频流视为时间序列：探索 VideoQA 的时间一致性和可变性\n",
      "authors": [
        "Zijie Song",
        "Zhenzhen Hu",
        "Yixiao Ma",
        "Jia Li",
        "Richang Hong"
      ],
      "abstract": "Video Question Answering (VideoQA) is a complex video-language task that\ndemands a sophisticated understanding of both visual content and temporal\ndynamics. Traditional Transformer-style architectures, while effective in\nintegrating multimodal data, often simplify temporal dynamics through\npositional encoding and fail to capture non-linear interactions within video\nsequences. In this paper, we introduce the Temporal Trio Transformer (T3T), a\nnovel architecture that models time consistency and time variability. The T3T\nintegrates three key components: Temporal Smoothing (TS), Temporal Difference\n(TD), and Temporal Fusion (TF). The TS module employs Brownian Bridge for\ncapturing smooth, continuous temporal transitions, while the TD module\nidentifies and encodes significant temporal variations and abrupt changes\nwithin the video content. Subsequently, the TF module synthesizes these\ntemporal features with textual cues, facilitating a deeper contextual\nunderstanding and response accuracy. The efficacy of the T3T is demonstrated\nthrough extensive testing on multiple VideoQA benchmark datasets. Our results\nunderscore the importance of a nuanced approach to temporal modeling in\nimproving the accuracy and depth of video-based question answering.",
      "tldr_zh": "这篇论文提出了Temporal Trio Transformer (T3T)，一种用于VideoQA的新型架构，旨在更有效地建模视频中的时间一致性和时间变异性。T3T集成了三个关键组件：Temporal Smoothing (TS)利用布朗桥捕捉平滑的时间过渡；Temporal Difference (TD)识别并编码显著的时间变化；Temporal Fusion (TF)将这些时间特征与文本线索融合。实验结果表明，T3T在多个VideoQA基准数据集上表现出色，证明了细致的时间建模方法能够提高VideoQA的准确性和深度。该研究强调了在处理视频内容时，充分理解和利用时间动态的重要性。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05783v1",
      "published_date": "2025-04-08 08:08:03 UTC",
      "updated_date": "2025-04-08 08:08:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:13:52.842585"
    },
    {
      "arxiv_id": "2504.05782v1",
      "title": "MDK12-Bench: A Multi-Discipline Benchmark for Evaluating Reasoning in Multimodal Large Language Models",
      "title_zh": "MDK12-Bench：用于评估多模态大型语言模型推理能力的多学科基准测试",
      "authors": [
        "Pengfei Zhou",
        "Fanrui Zhang",
        "Xiaopeng Peng",
        "Zhaopan Xu",
        "Jiaxin Ai",
        "Yansheng Qiu",
        "Chuanhao Li",
        "Zhen Li",
        "Ming Li",
        "Yukang Feng",
        "Jianwen Sun",
        "Haoquan Zhang",
        "Zizhen Li",
        "Xiaofeng Mao",
        "Wangbo Zhao",
        "Kai Wang",
        "Xiaojun Chang",
        "Wenqi Shao",
        "Yang You",
        "Kaipeng Zhang"
      ],
      "abstract": "Multimodal reasoning, which integrates language and visual cues into problem\nsolving and decision making, is a fundamental aspect of human intelligence and\na crucial step toward artificial general intelligence. However, the evaluation\nof multimodal reasoning capabilities in Multimodal Large Language Models\n(MLLMs) remains inadequate. Most existing reasoning benchmarks are constrained\nby limited data size, narrow domain coverage, and unstructured knowledge\ndistribution. To close these gaps, we introduce MDK12-Bench, a\nmulti-disciplinary benchmark assessing the reasoning capabilities of MLLMs via\nreal-world K-12 examinations. Spanning six disciplines (math, physics,\nchemistry, biology, geography, and information science), our benchmark\ncomprises 140K reasoning instances across diverse difficulty levels from\nprimary school to 12th grade. It features 6,827 instance-level knowledge point\nannotations based on a well-organized knowledge structure, detailed answer\nexplanations, difficulty labels and cross-year partitions, providing a robust\nplatform for comprehensive evaluation. Additionally, we present a novel dynamic\nevaluation framework to mitigate data contamination issues by bootstrapping\nquestion forms, question types, and image styles during evaluation. Extensive\nexperiment on MDK12-Bench reveals the significant limitation of current MLLMs\nin multimodal reasoning. The findings on our benchmark provide insights into\nthe development of the next-generation models. Our data and codes are available\nat https://github.com/LanceZPF/MDK12.",
      "tldr_zh": "MDK12-Bench是一个多学科基准，旨在评估多模态大型语言模型(MLLMs)的推理能力，通过使用真实的K-12考试题，涵盖数学、物理、化学、生物、地理和信息科学六个学科，包含14万个推理实例。该基准具有实例级别的知识点标注、详细的答案解释和难度标签，并提出了动态评估框架以缓解数据污染问题。实验表明，现有的MLLMs在多模态推理方面存在显著局限性，该基准为下一代模型的发展提供了有价值的见解。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05782v1",
      "published_date": "2025-04-08 08:06:53 UTC",
      "updated_date": "2025-04-08 08:06:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:14:04.758640"
    },
    {
      "arxiv_id": "2504.05774v1",
      "title": "Transferable Mask Transformer: Cross-domain Semantic Segmentation with Region-adaptive Transferability Estimation",
      "title_zh": "可迁移掩码Transformer：基于区域自适应可迁移性估计的跨域语义分割\n",
      "authors": [
        "Enming Zhang",
        "Zhengyu Li",
        "Yanru Wu",
        "Jingge Wang",
        "Yang Tan",
        "Ruizhe Zhao",
        "Guan Wang",
        "Yang Li"
      ],
      "abstract": "Recent advances in Vision Transformers (ViTs) have set new benchmarks in\nsemantic segmentation. However, when adapting pretrained ViTs to new target\ndomains, significant performance degradation often occurs due to distribution\nshifts, resulting in suboptimal global attention. Since self-attention\nmechanisms are inherently data-driven, they may fail to effectively attend to\nkey objects when source and target domains exhibit differences in texture,\nscale, or object co-occurrence patterns. While global and patch-level domain\nadaptation methods provide partial solutions, region-level adaptation with\ndynamically shaped regions is crucial due to spatial heterogeneity in\ntransferability across different image areas. We present Transferable Mask\nTransformer (TMT), a novel region-level adaptation framework for semantic\nsegmentation that aligns cross-domain representations through spatial\ntransferability analysis. TMT consists of two key components: (1) An Adaptive\nCluster-based Transferability Estimator (ACTE) that dynamically segments images\ninto structurally and semantically coherent regions for localized\ntransferability assessment, and (2) A Transferable Masked Attention (TMA)\nmodule that integrates region-specific transferability maps into ViTs'\nattention mechanisms, prioritizing adaptation in regions with low\ntransferability and high semantic uncertainty. Comprehensive evaluations across\n20 cross-domain pairs demonstrate TMT's superiority, achieving an average 2%\nMIoU improvement over vanilla fine-tuning and a 1.28% increase compared to\nstate-of-the-art baselines. The source code will be publicly available.",
      "tldr_zh": "本文提出了一种名为Transferable Mask Transformer (TMT) 的区域级自适应框架，用于语义分割中的跨域迁移学习。TMT通过空间可迁移性分析对齐跨域表示，由两个关键组件构成：自适应聚类可迁移性估计器 (ACTE)，用于将图像动态分割成结构和语义连贯的区域，以进行局部可迁移性评估；可迁移掩码注意力 (TMA) 模块，将区域特定的可迁移性图集成到ViT的注意力机制中，优先适应低可迁移性和高语义不确定性的区域。在20个跨域对上的综合评估表明，TMT优于现有方法，平均MIoU比原始微调提高了2%，比最先进的基线提高了1.28%。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05774v1",
      "published_date": "2025-04-08 07:53:51 UTC",
      "updated_date": "2025-04-08 07:53:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:14:16.948367"
    },
    {
      "arxiv_id": "2504.05770v1",
      "title": "A Lightweight Multi-Module Fusion Approach for Korean Character Recognition",
      "title_zh": "一种用于韩文字符识别的轻量级多模块融合方法\n",
      "authors": [
        "Inho Jake Park",
        "Jaehoon Jay Jeong",
        "Ho-Sang Jo"
      ],
      "abstract": "Optical Character Recognition (OCR) is essential in applications such as\ndocument processing, license plate recognition, and intelligent surveillance.\nHowever, existing OCR models often underperform in real-world scenarios due to\nirregular text layouts, poor image quality, character variability, and high\ncomputational costs.\n  This paper introduces SDA-Net (Stroke-Sensitive Attention and Dynamic Context\nEncoding Network), a lightweight and efficient architecture designed for robust\nsingle-character recognition. SDA-Net incorporates: (1) a Dual Attention\nMechanism to enhance stroke-level and spatial feature extraction; (2) a Dynamic\nContext Encoding module that adaptively refines semantic information using a\nlearnable gating mechanism; (3) a U-Net-inspired Feature Fusion Strategy for\ncombining low-level and high-level features; and (4) a highly optimized\nlightweight backbone that reduces memory and computational demands.\n  Experimental results show that SDA-Net achieves state-of-the-art accuracy on\nchallenging OCR benchmarks, with significantly faster inference, making it\nwell-suited for deployment in real-time and edge-based OCR systems.",
      "tldr_zh": "本文提出了一种轻量级多模块融合方法SDA-Net (Stroke-Sensitive Attention and Dynamic Context Encoding Network)用于韩文字符识别。SDA-Net 包含：(1) 双重注意力机制，增强笔画级别和空间特征的提取；(2) 动态上下文编码模块，使用可学习的门控机制自适应地细化语义信息；(3) 受 U-Net 启发的特征融合策略，用于结合低级和高级特征；(4) 高度优化的轻量级骨干网络，减少内存和计算需求。实验结果表明，SDA-Net 在具有挑战性的 OCR 基准测试中实现了最先进的准确率，并且推理速度明显更快，非常适合部署在实时和基于边缘的 OCR 系统中。\n",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T07",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.05770v1",
      "published_date": "2025-04-08 07:50:19 UTC",
      "updated_date": "2025-04-08 07:50:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:14:28.944619"
    },
    {
      "arxiv_id": "2504.05768v1",
      "title": "Temporal Dynamic Embedding for Irregularly Sampled Time Series",
      "title_zh": "针对非规则采样时间序列的时间动态嵌入\n",
      "authors": [
        "Mincheol Kim",
        "Soo-Yong Shin"
      ],
      "abstract": "In several practical applications, particularly healthcare, clinical data of\neach patient is individually recorded in a database at irregular intervals as\nrequired. This causes a sparse and irregularly sampled time series, which makes\nit difficult to handle as a structured representation of the prerequisites of\nneural network models. We therefore propose temporal dynamic embedding (TDE),\nwhich enables neural network models to receive data that change the number of\nvariables over time. TDE regards each time series variable as an embedding\nvector evolving over time, instead of a conventional fixed structured\nrepresentation, which causes a critical missing problem. For each time step,\nTDE allows for the selective adoption and aggregation of only observed variable\nsubsets and represents the current status of patient based on current\nobservations. The experiment was conducted on three clinical datasets:\nPhysioNet 2012, MIMIC-III, and PhysioNet 2019. The TDE model performed\ncompetitively or better than the imputation-based baseline and several recent\nstate-of-the-art methods with reduced training runtime.",
      "tldr_zh": "本文提出了一种用于处理不规则采样时间序列的Temporal Dynamic Embedding (TDE)方法。TDE将每个时间序列变量视为随时间演变的嵌入向量，而非传统的固定结构表示，从而避免了数据缺失问题。在每个时间步，TDE选择性地采用和聚合观测到的变量子集，并基于当前观测结果表示患者的当前状态。在PhysioNet 2012、MIMIC-III和PhysioNet 2019三个临床数据集上的实验表明，TDE模型在降低训练时间的同时，性能与基于插补的基线方法和几种最新的state-of-the-art方法相比具有竞争力或更优。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05768v1",
      "published_date": "2025-04-08 07:49:22 UTC",
      "updated_date": "2025-04-08 07:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:14:40.848320"
    },
    {
      "arxiv_id": "2504.05755v2",
      "title": "Unraveling Human-AI Teaming: A Review and Outlook",
      "title_zh": "解开人机协作：回顾与展望\n",
      "authors": [
        "Bowen Lou",
        "Tian Lu",
        "T. S. Raghu",
        "Yingjie Zhang"
      ],
      "abstract": "Artificial Intelligence (AI) is advancing at an unprecedented pace, with\nclear potential to enhance decision-making and productivity. Yet, the\ncollaborative decision-making process between humans and AI remains\nunderdeveloped, often falling short of its transformative possibilities. This\npaper explores the evolution of AI agents from passive tools to active\ncollaborators in human-AI teams, emphasizing their ability to learn, adapt, and\noperate autonomously in complex environments. This paradigm shifts challenges\ntraditional team dynamics, requiring new interaction protocols, delegation\nstrategies, and responsibility distribution frameworks. Drawing on Team\nSituation Awareness (SA) theory, we identify two critical gaps in current\nhuman-AI teaming research: the difficulty of aligning AI agents with human\nvalues and objectives, and the underutilization of AI's capabilities as genuine\nteam members. Addressing these gaps, we propose a structured research outlook\ncentered on four key aspects of human-AI teaming: formulation, coordination,\nmaintenance, and training. Our framework highlights the importance of shared\nmental models, trust-building, conflict resolution, and skill adaptation for\neffective teaming. Furthermore, we discuss the unique challenges posed by\nvarying team compositions, goals, and complexities. This paper provides a\nfoundational agenda for future research and practical design of sustainable,\nhigh-performing human-AI teams.",
      "tldr_zh": "本文回顾了人机协作领域的发展，探讨了AI从被动工具到主动合作者的演变，以及由此带来的团队动态变化，包括新的交互协议、委派策略和责任分配框架。文章基于团队情境感知(Team Situation Awareness, SA)理论，指出了当前研究中的两个关键差距：AI与人类价值观和目标对齐的困难，以及AI作为真正团队成员的能力未被充分利用。针对这些差距，文章提出了一个结构化的研究展望，围绕人机协作的四个关键方面：制定(formulation)、协调(coordination)、维护(maintenance)和训练(training)。该研究为未来人机协作研究和实践设计提供了基础，强调了共享心智模型、信任建立、冲突解决和技能适应的重要性。\n",
      "categories": [
        "cs.HC",
        "cs.AI",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05755v2",
      "published_date": "2025-04-08 07:37:25 UTC",
      "updated_date": "2025-04-09 12:20:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:14:53.226015"
    },
    {
      "arxiv_id": "2504.05741v2",
      "title": "DDT: Decoupled Diffusion Transformer",
      "title_zh": "DDT：解耦扩散 Transformer\n",
      "authors": [
        "Shuai Wang",
        "Zhi Tian",
        "Weilin Huang",
        "Limin Wang"
      ],
      "abstract": "Diffusion transformers have demonstrated remarkable generation quality,\nalbeit requiring longer training iterations and numerous inference steps. In\neach denoising step, diffusion transformers encode the noisy inputs to extract\nthe lower-frequency semantic component and then decode the higher frequency\nwith identical modules. This scheme creates an inherent optimization dilemma:\nencoding low-frequency semantics necessitates reducing high-frequency\ncomponents, creating tension between semantic encoding and high-frequency\ndecoding. To resolve this challenge, we propose a new\n\\textbf{\\color{ddt}D}ecoupled \\textbf{\\color{ddt}D}iffusion\n\\textbf{\\color{ddt}T}ransformer~(\\textbf{\\color{ddt}DDT}), with a decoupled\ndesign of a dedicated condition encoder for semantic extraction alongside a\nspecialized velocity decoder. Our experiments reveal that a more substantial\nencoder yields performance improvements as model size increases. For ImageNet\n$256\\times256$, Our DDT-XL/2 achieves a new state-of-the-art performance of\n{1.31 FID}~(nearly $4\\times$ faster training convergence compared to previous\ndiffusion transformers). For ImageNet $512\\times512$, Our DDT-XL/2 achieves a\nnew state-of-the-art FID of 1.28. Additionally, as a beneficial by-product, our\ndecoupled architecture enhances inference speed by enabling the sharing\nself-condition between adjacent denoising steps. To minimize performance\ndegradation, we propose a novel statistical dynamic programming approach to\nidentify optimal sharing strategies.",
      "tldr_zh": "该论文提出了解耦扩散Transformer (DDT)，旨在解决传统扩散Transformer在训练迭代和推理步骤上耗时较长的问题。DDT通过解耦设计，使用专门的条件编码器提取低频语义信息，并使用专门的速度解码器处理高频信息，从而避免了语义编码和高频解码之间的固有矛盾。实验结果表明，DDT在ImageNet 256x256上实现了1.31 FID的新SOTA，训练收敛速度比之前的扩散Transformer快近4倍。在ImageNet 512x512上，DDT也实现了1.28 FID的新SOTA。此外，DDT的解耦架构还允许在相邻去噪步骤之间共享自条件，从而提高了推理速度，并通过一种新的统计动态规划方法来确定最佳共享策略。\n",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "sota on ImageNet256 and ImageNet512",
      "pdf_url": "http://arxiv.org/pdf/2504.05741v2",
      "published_date": "2025-04-08 07:17:45 UTC",
      "updated_date": "2025-04-09 04:23:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:15:05.110674"
    },
    {
      "arxiv_id": "2504.05736v1",
      "title": "Rank-Then-Score: Enhancing Large Language Models for Automated Essay Scoring",
      "title_zh": "先排序后评分：增强大型语言模型以实现自动作文评分\n",
      "authors": [
        "Yida Cai",
        "Kun Liang",
        "Sanwoo Lee",
        "Qinghan Wang",
        "Yunfang Wu"
      ],
      "abstract": "In recent years, large language models (LLMs) achieve remarkable success\nacross a variety of tasks. However, their potential in the domain of Automated\nEssay Scoring (AES) remains largely underexplored. Moreover, compared to\nEnglish data, the methods for Chinese AES is not well developed. In this paper,\nwe propose Rank-Then-Score (RTS), a fine-tuning framework based on large\nlanguage models to enhance their essay scoring capabilities. Specifically, we\nfine-tune the ranking model (Ranker) with feature-enriched data, and then feed\nthe output of the ranking model, in the form of a candidate score set, with the\nessay content into the scoring model (Scorer) to produce the final score.\nExperimental results on two benchmark datasets, HSK and ASAP, demonstrate that\nRTS consistently outperforms the direct prompting (Vanilla) method in terms of\naverage QWK across all LLMs and datasets, and achieves the best performance on\nChinese essay scoring using the HSK dataset.",
      "tldr_zh": "本文提出了一种名为Rank-Then-Score (RTS)的微调框架，旨在提升大型语言模型(LLMs)在自动作文评分(AES)方面的能力，尤其是在中文作文评分领域。RTS框架首先使用富含特征的数据微调排序模型(Ranker)，然后将Ranker的输出（候选分数集合）与作文内容一同输入到评分模型(Scorer)中，以生成最终分数。在HSK和ASAP两个基准数据集上的实验结果表明，RTS在所有LLM和数据集上的平均QWK指标上均优于直接prompting方法，并且在使用HSK数据集进行中文作文评分时取得了最佳性能。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05736v1",
      "published_date": "2025-04-08 07:10:51 UTC",
      "updated_date": "2025-04-08 07:10:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:15:17.015450"
    },
    {
      "arxiv_id": "2504.05728v1",
      "title": "AI-Driven Prognostics for State of Health Prediction in Li-ion Batteries: A Comprehensive Analysis with Validation",
      "title_zh": "AI驱动的锂离子电池健康状态预测：一项基于验证的综合分析\n",
      "authors": [
        "Tianqi Ding",
        "Dawei Xiang",
        "Tianyao Sun",
        "YiJiashum Qi",
        "Zunduo Zhao"
      ],
      "abstract": "This paper presents a comprehensive review of AI-driven prognostics for State\nof Health (SoH) prediction in lithium-ion batteries. We compare the\neffectiveness of various AI algorithms, including FFNN, LSTM, and BiLSTM,\nacross multiple datasets (CALCE, NASA, UDDS) and scenarios (e.g., varying\ntemperatures and driving conditions). Additionally, we analyze the factors\ninfluencing SoH fluctuations, such as temperature and charge-discharge rates,\nand validate our findings through simulations. The results demonstrate that\nBiLSTM achieves the highest accuracy, with an average RMSE reduction of 15%\ncompared to LSTM, highlighting its robustness in real-world applications.",
      "tldr_zh": "本文全面综述了人工智能驱动的锂离子电池健康状态(State of Health, SoH)预测方法。通过在CALCE、NASA和UDDS等多个数据集以及不同场景（如不同温度和驾驶条件）下比较FFNN、LSTM和BiLSTM等多种AI算法的有效性，分析了影响SoH波动的因素，如温度和充放电速率，并通过仿真验证了研究结果。实验表明，BiLSTM实现了最高的预测精度，与LSTM相比，平均RMSE降低了15%，突出了其在实际应用中的鲁棒性。\n",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 12 figures, Accepted by 2025 6th International Conference on\n  Electrical Technology and Automatic Control(ICETAC 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.05728v1",
      "published_date": "2025-04-08 06:58:39 UTC",
      "updated_date": "2025-04-08 06:58:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:15:28.793894"
    },
    {
      "arxiv_id": "2504.05711v1",
      "title": "Automated Archival Descriptions with Federated Intelligence of LLMs",
      "title_zh": "基于 LLM 联邦智能的自动化档案描述\n",
      "authors": [
        "Jinghua Groppe",
        "Andreas Marquet",
        "Annabel Walz",
        "Sven Groppe"
      ],
      "abstract": "Enforcing archival standards requires specialized expertise, and manually\ncreating metadata descriptions for archival materials is a tedious and\nerror-prone task. This work aims at exploring the potential of agentic AI and\nlarge language models (LLMs) in addressing the challenges of implementing a\nstandardized archival description process. To this end, we introduce an agentic\nAI-driven system for automated generation of high-quality metadata descriptions\nof archival materials. We develop a federated optimization approach that unites\nthe intelligence of multiple LLMs to construct optimal archival metadata. We\nalso suggest methods to overcome the challenges associated with using LLMs for\nconsistent metadata generation. To evaluate the feasibility and effectiveness\nof our techniques, we conducted extensive experiments using a real-world\ndataset of archival materials, which covers a variety of document types and\ndata formats. The evaluation results demonstrate the feasibility of our\ntechniques and highlight the superior performance of the federated optimization\napproach compared to single-model solutions in metadata quality and\nreliability.",
      "tldr_zh": "该研究提出了一种基于智能体AI和大型语言模型(LLMs)的自动化档案描述系统，旨在解决人工创建档案材料元数据描述的繁琐和易错问题。该系统采用联邦优化方法，整合多个LLM的智能，以构建最佳的档案元数据。同时，研究还提出了克服LLM在一致性元数据生成方面挑战的方法。通过在真实档案数据集上的大量实验，验证了该技术的可行性和有效性，结果表明联邦优化方法在元数据质量和可靠性方面优于单模型解决方案。\n",
      "categories": [
        "cs.AI",
        "cs.DL",
        "cs.IR",
        "cs.LG",
        "I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05711v1",
      "published_date": "2025-04-08 06:11:05 UTC",
      "updated_date": "2025-04-08 06:11:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:15:40.774525"
    },
    {
      "arxiv_id": "2504.05695v2",
      "title": "Architecture independent generalization bounds for overparametrized deep ReLU networks",
      "title_zh": "过参数化深度 ReLU 网络的架构独立泛化界限\n",
      "authors": [
        "Thomas Chen",
        "Chun-Kai Kevin Chien",
        "Patricia Muñoz Ewald",
        "Andrew G. Moore"
      ],
      "abstract": "We prove that overparametrized neural networks are able to generalize with a\ntest error that is independent of the level of overparametrization, and\nindependent of the Vapnik-Chervonenkis (VC) dimension. We prove explicit bounds\nthat only depend on the metric geometry of the test and training sets, on the\nregularity properties of the activation function, and on the operator norms of\nthe weights and norms of biases. For overparametrized deep ReLU networks with a\ntraining sample size bounded by the input space dimension, we explicitly\nconstruct zero loss minimizers without use of gradient descent, and prove that\nthe generalization error is independent of the network architecture.",
      "tldr_zh": "该论文证明了过参数化的神经网络能够泛化，且测试误差与过参数化的程度以及VC维无关。论文提出了显式的泛化边界，该边界仅依赖于测试集和训练集的度量几何、激活函数的正则性以及权重和偏置的算子范数。对于训练样本大小受输入空间维度限制的过参数化深度ReLU网络，论文显式地构造了零损失最小化器，无需使用梯度下降，并证明了泛化误差与网络架构无关。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP",
        "math.OC",
        "stat.ML",
        "57R70, 62M45"
      ],
      "primary_category": "cs.LG",
      "comment": "AMS Latex, 12 pages. Typos corrected",
      "pdf_url": "http://arxiv.org/pdf/2504.05695v2",
      "published_date": "2025-04-08 05:37:38 UTC",
      "updated_date": "2025-04-09 17:29:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:15:52.828180"
    },
    {
      "arxiv_id": "2504.05694v1",
      "title": "Large Language Models Enhanced Hyperbolic Space Recommender Systems",
      "title_zh": "大型语言模型增强的双曲空间推荐系统\n",
      "authors": [
        "Wentao Cheng",
        "Zhida Qin",
        "Zexue Wu",
        "Pengzhan Zhou",
        "Tianyu Huang"
      ],
      "abstract": "Large Language Models (LLMs) have attracted significant attention in\nrecommender systems for their excellent world knowledge capabilities. However,\nexisting methods that rely on Euclidean space struggle to capture the rich\nhierarchical information inherent in textual and semantic data, which is\nessential for capturing user preferences. The geometric properties of\nhyperbolic space offer a promising solution to address this issue.\nNevertheless, integrating LLMs-based methods with hyperbolic space to\neffectively extract and incorporate diverse hierarchical information is\nnon-trivial. To this end, we propose a model-agnostic framework, named\nHyperLLM, which extracts and integrates hierarchical information from both\nstructural and semantic perspectives. Structurally, HyperLLM uses LLMs to\ngenerate multi-level classification tags with hierarchical parent-child\nrelationships for each item. Then, tag-item and user-item interactions are\njointly learned and aligned through contrastive learning, thereby providing the\nmodel with clear hierarchical information. Semantically, HyperLLM introduces a\nnovel meta-optimized strategy to extract hierarchical information from semantic\nembeddings and bridge the gap between the semantic and collaborative spaces for\nseamless integration. Extensive experiments show that HyperLLM significantly\noutperforms recommender systems based on hyperbolic space and LLMs, achieving\nperformance improvements of over 40%. Furthermore, HyperLLM not only improves\nrecommender performance but also enhances training stability, highlighting the\ncritical role of hierarchical information in recommender systems.",
      "tldr_zh": "该论文提出了一个名为HyperLLM的、与模型无关的框架，旨在利用大型语言模型(LLMs)增强双曲空间推荐系统。HyperLLM从结构和语义两个角度提取和整合层级信息：在结构上，利用LLMs为每个物品生成具有层级父子关系的多层分类标签，并通过对比学习联合学习和对齐标签-物品和用户-物品交互；在语义上，引入一种新的元优化策略，从语义嵌入中提取层级信息，并弥合语义空间和协同空间之间的差距。实验结果表明，HyperLLM显著优于基于双曲空间和LLMs的推荐系统，性能提升超过40%，并提高了训练稳定性，强调了层级信息在推荐系统中的关键作用。\n",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05694v1",
      "published_date": "2025-04-08 05:35:38 UTC",
      "updated_date": "2025-04-08 05:35:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:16:05.070606"
    },
    {
      "arxiv_id": "2504.05693v1",
      "title": "STRIVE: A Think & Improve Approach with Iterative Refinement for Enhancing Question Quality Estimation",
      "title_zh": "STRIVE：一种通过迭代改进的思考与改进方法，用于提升问题质量评估\n",
      "authors": [
        "Aniket Deroy",
        "Subhankar Maity"
      ],
      "abstract": "Automatically assessing question quality is crucial for educators as it saves\ntime, ensures consistency, and provides immediate feedback for refining\nteaching materials. We propose a novel methodology called STRIVE (Structured\nThinking and Refinement with multiLLMs for Improving Verified Question\nEstimation) using a series of Large Language Models (LLMs) for automatic\nquestion evaluation. This approach aims to improve the accuracy and depth of\nquestion quality assessment, ultimately supporting diverse learners and\nenhancing educational practices. The method estimates question quality in an\nautomated manner by generating multiple evaluations based on the strengths and\nweaknesses of the provided question and then choosing the best solution\ngenerated by the LLM. Then the process is improved by iterative review and\nresponse with another LLM until the evaluation metric values converge. This\nsophisticated method of evaluating question quality improves the estimation of\nquestion quality by automating the task of question quality evaluation.\nCorrelation scores show that using this proposed method helps to improve\ncorrelation with human judgments compared to the baseline method. Error\nanalysis shows that metrics like relevance and appropriateness improve\nsignificantly relative to human judgments by using STRIVE.",
      "tldr_zh": "该论文提出了一种名为STRIVE的新方法，利用大型语言模型(LLMs)进行迭代改进，以提升问题质量评估的准确性和深度。STRIVE通过生成多个基于问题优缺点的评估，并选择LLM的最佳解决方案来实现问题质量的自动评估。该方法通过迭代审查和LLM的反馈进行改进，直到评估指标值收敛。实验结果表明，相比基线方法，STRIVE能显著提高与人类判断的相关性，尤其在相关性和适当性等指标上表现突出，从而提升问题质量评估的自动化水平。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "5 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05693v1",
      "published_date": "2025-04-08 05:34:38 UTC",
      "updated_date": "2025-04-08 05:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:16:16.979335"
    },
    {
      "arxiv_id": "2504.05691v1",
      "title": "StayLTC: A Cost-Effective Multimodal Framework for Hospital Length of Stay Forecasting",
      "title_zh": "StayLTC：一种用于预测住院时长的经济高效的多模态框架\n",
      "authors": [
        "Sudeshna Jana",
        "Manjira Sinha",
        "Tirthankar Dasgupta"
      ],
      "abstract": "Accurate prediction of Length of Stay (LOS) in hospitals is crucial for\nimproving healthcare services, resource management, and cost efficiency. This\npaper presents StayLTC, a multimodal deep learning framework developed to\nforecast real-time hospital LOS using Liquid Time-Constant Networks (LTCs).\nLTCs, with their continuous-time recurrent dynamics, are evaluated against\ntraditional models using structured data from Electronic Health Records (EHRs)\nand clinical notes. Our evaluation, conducted on the MIMIC-III dataset,\ndemonstrated that LTCs significantly outperform most of the other time series\nmodels, offering enhanced accuracy, robustness, and efficiency in resource\nutilization. Additionally, LTCs demonstrate a comparable performance in LOS\nprediction compared to time series large language models, while requiring\nsignificantly less computational power and memory, underscoring their potential\nto advance Natural Language Processing (NLP) tasks in healthcare.",
      "tldr_zh": "该论文提出了StayLTC，一个经济高效的多模态深度学习框架，用于预测住院时长(Length of Stay, LOS)。StayLTC利用Liquid Time-Constant Networks (LTCs)处理电子健康记录(Electronic Health Records, EHRs)和临床笔记中的结构化数据，进行实时LOS预测。在MIMIC-III数据集上的评估表明，LTCs显著优于其他时间序列模型，在准确性、鲁棒性和资源利用效率方面均有提升。此外，LTCs在LOS预测方面表现与时间序列大型语言模型相当，但计算能力和内存需求更低，突显了其在医疗保健领域自然语言处理(NLP)任务中的潜力。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05691v1",
      "published_date": "2025-04-08 05:27:53 UTC",
      "updated_date": "2025-04-08 05:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:16:29.002143"
    },
    {
      "arxiv_id": "2504.05686v1",
      "title": "kNN-SVC: Robust Zero-Shot Singing Voice Conversion with Additive Synthesis and Concatenation Smoothness Optimization",
      "title_zh": "kNN-SVC：基于加性合成与拼接平滑优化的鲁棒零样本歌声转换",
      "authors": [
        "Keren Shao",
        "Ke Chen",
        "Matthew Baas",
        "Shlomo Dubnov"
      ],
      "abstract": "Robustness is critical in zero-shot singing voice conversion (SVC). This\npaper introduces two novel methods to strengthen the robustness of the kNN-VC\nframework for SVC. First, kNN-VC's core representation, WavLM, lacks harmonic\nemphasis, resulting in dull sounds and ringing artifacts. To address this, we\nleverage the bijection between WavLM, pitch contours, and spectrograms to\nperform additive synthesis, integrating the resulting waveform into the model\nto mitigate these issues. Second, kNN-VC overlooks concatenative smoothness, a\nkey perceptual factor in SVC. To enhance smoothness, we propose a new distance\nmetric that filters out unsuitable kNN candidates and optimize the summing\nweights of the candidates during inference. Although our techniques are built\non the kNN-VC framework for implementation convenience, they are broadly\napplicable to general concatenative neural synthesis models. Experimental\nresults validate the effectiveness of these modifications in achieving robust\nSVC. Demo: http://knnsvc.com Code: https://github.com/SmoothKen/knn-svc",
      "tldr_zh": "该论文提出了一种鲁棒的零样本歌声转换(SVC)方法，称为kNN-SVC，旨在解决kNN-VC框架在SVC中鲁棒性不足的问题。首先，通过WavLM、音高轮廓和频谱图之间的双射关系，进行加法合成，将合成的波形集成到模型中，以增强谐波并减少伪影。其次，提出了一种新的距离度量，用于过滤不合适的kNN候选，并在推理过程中优化候选的加权和，从而提高拼接的平滑性。实验结果表明，这些改进有效地实现了鲁棒的SVC。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 6 figures, 1 table, Proceedings of the International\n  Conference on Acoustics, Speech, and Signal Processing, ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05686v1",
      "published_date": "2025-04-08 04:59:56 UTC",
      "updated_date": "2025-04-08 04:59:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:16:40.947698"
    },
    {
      "arxiv_id": "2504.05684v1",
      "title": "TARO: Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning for Synchronized Video-to-Audio Synthesis",
      "title_zh": "TARO：基于起始感知调节的时步自适应表征对齐，用于同步视频到音频合成\n",
      "authors": [
        "Tri Ton",
        "Ji Woo Hong",
        "Chang D. Yoo"
      ],
      "abstract": "This paper introduces Timestep-Adaptive Representation Alignment with\nOnset-Aware Conditioning (TARO), a novel framework for high-fidelity and\ntemporally coherent video-to-audio synthesis. Built upon flow-based\ntransformers, which offer stable training and continuous transformations for\nenhanced synchronization and audio quality, TARO introduces two key\ninnovations: (1) Timestep-Adaptive Representation Alignment (TRA), which\ndynamically aligns latent representations by adjusting alignment strength based\non the noise schedule, ensuring smooth evolution and improved fidelity, and (2)\nOnset-Aware Conditioning (OAC), which integrates onset cues that serve as sharp\nevent-driven markers of audio-relevant visual moments to enhance\nsynchronization with dynamic visual events. Extensive experiments on the\nVGGSound and Landscape datasets demonstrate that TARO outperforms prior\nmethods, achieving relatively 53\\% lower Frechet Distance (FD), 29% lower\nFrechet Audio Distance (FAD), and a 97.19% Alignment Accuracy, highlighting its\nsuperior audio quality and synchronization precision.",
      "tldr_zh": "本文提出了一个名为TARO的视频到音频合成框架，该框架通过时间步自适应表示对齐和起始感知调节(Timestep-Adaptive Representation Alignment with Onset-Aware Conditioning)来实现高保真和时间连贯性。TARO基于flow-based transformers，通过引入时间步自适应表示对齐(TRA)和起始感知调节(OAC)两个关键创新点，动态调整潜在表示的对齐强度，并整合起始线索作为音频相关视觉事件的标记，从而增强同步性。在VGGSound和Landscape数据集上的实验表明，TARO优于现有方法，在Frechet Distance (FD)和Frechet Audio Distance (FAD)等指标上均有显著提升，验证了其卓越的音频质量和同步精度。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.SD",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05684v1",
      "published_date": "2025-04-08 04:49:36 UTC",
      "updated_date": "2025-04-08 04:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:16:53.191340"
    },
    {
      "arxiv_id": "2504.05683v1",
      "title": "Towards Smarter Hiring: Are Zero-Shot and Few-Shot Pre-trained LLMs Ready for HR Spoken Interview Transcript Analysis?",
      "title_zh": "迈向更智能的招聘：零样本和小样本预训练LLM是否已为HR口语面试记录分析做好准备？\n",
      "authors": [
        "Subhankar Maity",
        "Aniket Deroy",
        "Sudeshna Sarkar"
      ],
      "abstract": "This research paper presents a comprehensive analysis of the performance of\nprominent pre-trained large language models (LLMs), including GPT-4 Turbo,\nGPT-3.5 Turbo, text-davinci-003, text-babbage-001, text-curie-001,\ntext-ada-001, llama-2-7b-chat, llama-2-13b-chat, and llama-2-70b-chat, in\ncomparison to expert human evaluators in providing scores, identifying errors,\nand offering feedback and improvement suggestions to candidates during mock HR\n(Human Resources) interviews. We introduce a dataset called HURIT (Human\nResource Interview Transcripts), which comprises 3,890 HR interview transcripts\nsourced from real-world HR interview scenarios. Our findings reveal that\npre-trained LLMs, particularly GPT-4 Turbo and GPT-3.5 Turbo, exhibit\ncommendable performance and are capable of producing evaluations comparable to\nthose of expert human evaluators. Although these LLMs demonstrate proficiency\nin providing scores comparable to human experts in terms of human evaluation\nmetrics, they frequently fail to identify errors and offer specific actionable\nadvice for candidate performance improvement in HR interviews. Our research\nsuggests that the current state-of-the-art pre-trained LLMs are not fully\nconducive for automatic deployment in an HR interview assessment. Instead, our\nfindings advocate for a human-in-the-loop approach, to incorporate manual\nchecks for inconsistencies and provisions for improving feedback quality as a\nmore suitable strategy.",
      "tldr_zh": "该研究对比了包括GPT-4 Turbo、GPT-3.5 Turbo和Llama-2等多个预训练大语言模型(LLMs)在模拟HR面试场景中，对候选人进行评分、识别错误以及提供反馈和改进建议的表现，并与人类专家评估员的表现进行对比。研究引入了一个包含3890个真实HR面试记录的数据集HURIT。结果表明，GPT-4 Turbo和GPT-3.5 Turbo等LLMs在评分方面表现出色，与人类专家相当。然而，这些LLMs在识别错误和提供具体可操作的改进建议方面表现不足。研究认为，目前最先进的预训练LLMs还不完全适用于HR面试评估的自动部署，建议采用人机协作的方式，进行人工检查和改进反馈质量。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "32 pages, 24 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05683v1",
      "published_date": "2025-04-08 04:46:10 UTC",
      "updated_date": "2025-04-08 04:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:17:05.397903"
    },
    {
      "arxiv_id": "2504.05657v1",
      "title": "Nes2Net: A Lightweight Nested Architecture for Foundation Model Driven Speech Anti-spoofing",
      "title_zh": "Nes2Net：一种用于基础模型驱动的语音反欺骗的轻量级嵌套架构\n",
      "authors": [
        "Tianchi Liu",
        "Duc-Tuan Truong",
        "Rohan Kumar Das",
        "Kong Aik Lee",
        "Haizhou Li"
      ],
      "abstract": "Speech foundation models have significantly advanced various speech-related\ntasks by providing exceptional representation capabilities. However, their\nhigh-dimensional output features often create a mismatch with downstream task\nmodels, which typically require lower-dimensional inputs. A common solution is\nto apply a dimensionality reduction (DR) layer, but this approach increases\nparameter overhead, computational costs, and risks losing valuable information.\nTo address these issues, we propose Nested Res2Net (Nes2Net), a lightweight\nback-end architecture designed to directly process high-dimensional features\nwithout DR layers. The nested structure enhances multi-scale feature\nextraction, improves feature interaction, and preserves high-dimensional\ninformation. We first validate Nes2Net on CtrSVDD, a singing voice deepfake\ndetection dataset, and report a 22% performance improvement and an 87% back-end\ncomputational cost reduction over the state-of-the-art baseline. Additionally,\nextensive testing across four diverse datasets: ASVspoof 2021, ASVspoof 5,\nPartialSpoof, and In-the-Wild, covering fully spoofed speech, adversarial\nattacks, partial spoofing, and real-world scenarios, consistently highlights\nNes2Net's superior robustness and generalization capabilities. The code package\nand pre-trained models are available at https://github.com/Liu-Tianchi/Nes2Net.",
      "tldr_zh": "该论文提出了一种轻量级的嵌套架构Nes2Net，用于解决语音反欺骗任务中，语音基础模型输出的高维特征与下游任务模型需求之间的不匹配问题。Nes2Net无需降维(DR)层即可直接处理高维特征，通过嵌套结构增强多尺度特征提取和特征交互，从而保留高维信息。实验结果表明，在CtrSVDD数据集上，Nes2Net相比现有最佳方法性能提升22%，计算成本降低87%。此外，在ASVspoof 2021、ASVspoof 5、PartialSpoof和In-the-Wild四个数据集上的广泛测试也验证了Nes2Net的鲁棒性和泛化能力。\n",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "This manuscript has been submitted for peer review",
      "pdf_url": "http://arxiv.org/pdf/2504.05657v1",
      "published_date": "2025-04-08 04:11:28 UTC",
      "updated_date": "2025-04-08 04:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:17:17.119319"
    },
    {
      "arxiv_id": "2504.05646v1",
      "title": "Lattice: Learning to Efficiently Compress the Memory",
      "title_zh": "Lattice：学习高效压缩记忆",
      "authors": [
        "Mahdi Karami",
        "Vahab Mirrokni"
      ],
      "abstract": "Attention mechanisms have revolutionized sequence learning but suffer from\nquadratic computational complexity. This paper introduces Lattice, a novel\nrecurrent neural network (RNN) mechanism that leverages the inherent low-rank\nstructure of K-V matrices to efficiently compress the cache into a fixed number\nof memory slots, achieving sub-quadratic complexity. We formulate this\ncompression as an online optimization problem and derive a dynamic memory\nupdate rule based on a single gradient descent step. The resulting recurrence\nfeatures a state- and input-dependent gating mechanism, offering an\ninterpretable memory update process. The core innovation is the orthogonal\nupdate: each memory slot is updated exclusively with information orthogonal to\nits current state hence incorporation of only novel, non-redundant data, which\nminimizes the interference with previously stored information. The experimental\nresults show that Lattice achieves the best perplexity compared to all\nbaselines across diverse context lengths, with performance improvement becoming\nmore pronounced as the context length increases.",
      "tldr_zh": "该论文提出了一种新的循环神经网络(RNN)机制Lattice，旨在通过利用K-V矩阵的低秩结构，将缓存有效压缩到固定数量的内存槽中，从而实现亚二次复杂度，解决Attention机制计算复杂度过高的问题。Lattice将压缩过程建模为在线优化问题，并推导出基于单步梯度下降的动态内存更新规则。其核心创新在于正交更新：每个内存槽仅使用与其当前状态正交的信息进行更新，从而最大限度地减少与先前存储信息的干扰。实验结果表明，在不同的上下文长度下，Lattice相比所有基线模型实现了最佳的困惑度，并且随着上下文长度的增加，性能提升更加明显。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05646v1",
      "published_date": "2025-04-08 03:48:43 UTC",
      "updated_date": "2025-04-08 03:48:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:17:29.138416"
    },
    {
      "arxiv_id": "2504.05639v1",
      "title": "DBOT: Artificial Intelligence for Systematic Long-Term Investing",
      "title_zh": "DBOT：用于系统性长期投资的人工智能\n",
      "authors": [
        "Vasant Dhar",
        "João Sedoc"
      ],
      "abstract": "Long-term investing was previously seen as requiring human judgment. With the\nadvent of generative artificial intelligence (AI) systems, automated systematic\nlong-term investing is now feasible. In this paper, we present DBOT, a system\nwhose goal is to reason about valuation like Aswath Damodaran, who is a unique\nexpert in the investment arena in terms of having published thousands of\nvaluations on companies in addition to his numerous writings on the topic,\nwhich provide ready training data for an AI system. DBOT can value any publicly\ntraded company. DBOT can also be back-tested, making its behavior and\nperformance amenable to scientific inquiry. We compare DBOT to its analytic\nparent, Damodaran, and highlight the research challenges involved in raising\nits current capability to that of Damodaran's. Finally, we examine the\nimplications of DBOT-like AI agents for the financial industry, especially how\nthey will impact the role of human analysts in valuation.",
      "tldr_zh": "本文介绍了DBOT，一个用于系统性长期投资的人工智能系统。DBOT旨在像Aswath Damodaran一样进行估值推理，Damodaran是投资领域的专家，发表了数千份公司估值报告和大量相关著作，为AI系统提供了现成的训练数据。DBOT能够对任何上市公司进行估值，并可进行回测，使其行为和表现能够进行科学研究。文章将DBOT与其分析“父辈”Damodaran进行了比较，并强调了将其当前能力提升到Damodaran水平所涉及的研究挑战。最后，文章探讨了类似DBOT的AI agent对金融行业的影响，特别是它们将如何影响人类分析师在估值中的作用。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "q-fin.PR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05639v1",
      "published_date": "2025-04-08 03:34:22 UTC",
      "updated_date": "2025-04-08 03:34:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:17:41.276609"
    },
    {
      "arxiv_id": "2504.05632v2",
      "title": "Reasoning Towards Fairness: Mitigating Bias in Language Models through Reasoning-Guided Fine-Tuning",
      "title_zh": "趋向公平的推理：通过推理引导的微调来缓解语言模型中的偏见\n",
      "authors": [
        "Sanchit Kabra",
        "Akshita Jha",
        "Chandan K. Reddy"
      ],
      "abstract": "Recent advances in large-scale generative language models have shown that\nreasoning capabilities can significantly improve model performance across a\nvariety of tasks. However, the impact of reasoning on a model's ability to\nmitigate stereotypical responses remains largely underexplored. In this work,\nwe investigate the crucial relationship between a model's reasoning ability and\nfairness, and ask whether improved reasoning capabilities can mitigate harmful\nstereotypical responses, especially those arising due to shallow or flawed\nreasoning. We conduct a comprehensive evaluation of multiple open-source LLMs,\nand find that larger models with stronger reasoning abilities exhibit\nsubstantially lower stereotypical bias on existing fairness benchmarks.\nBuilding on this insight, we introduce ReGiFT -- Reasoning Guided Fine-Tuning,\na novel approach that extracts structured reasoning traces from advanced\nreasoning models and infuses them into models that lack such capabilities. We\nuse only general-purpose reasoning and do not require any fairness-specific\nsupervision for bias mitigation. Notably, we see that models fine-tuned using\nReGiFT not only improve fairness relative to their non-reasoning counterparts\nbut also outperform advanced reasoning models on fairness benchmarks. We also\nanalyze how variations in the correctness of the reasoning traces and their\nlength influence model fairness and their overall performance. Our findings\nhighlight that enhancing reasoning capabilities is an effective,\nfairness-agnostic strategy for mitigating stereotypical bias caused by\nreasoning flaws.",
      "tldr_zh": "该研究探讨了语言模型的推理能力与公平性之间的关系，发现更强的推理能力可以显著降低刻板偏见。研究者提出了ReGiFT (Reasoning Guided Fine-Tuning)，一种新颖的微调方法，利用先进推理模型提取的结构化推理轨迹，注入到缺乏推理能力的模型中。实验结果表明，使用ReGiFT微调的模型不仅提高了公平性，甚至优于先进的推理模型。该研究强调，增强推理能力是一种有效的、与公平性无关的策略，可以减轻由推理缺陷引起的刻板偏见。\n",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.05632v2",
      "published_date": "2025-04-08 03:21:51 UTC",
      "updated_date": "2025-04-09 03:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:17:52.904806"
    },
    {
      "arxiv_id": "2504.05621v1",
      "title": "Continual Learning of Multiple Cognitive Functions with Brain-inspired Temporal Development Mechanism",
      "title_zh": "基于大脑启发式时间发展机制的多认知功能持续学习\n",
      "authors": [
        "Bing Han",
        "Feifei Zhao",
        "Yinqian Sun",
        "Wenxuan Pan",
        "Yi Zeng"
      ],
      "abstract": "Cognitive functions in current artificial intelligence networks are tied to\nthe exponential increase in network scale, whereas the human brain can\ncontinuously learn hundreds of cognitive functions with remarkably low energy\nconsumption. This advantage is in part due to the brain cross-regional temporal\ndevelopment mechanisms, where the progressive formation, reorganization, and\npruning of connections from basic to advanced regions, facilitate knowledge\ntransfer and prevent network redundancy. Inspired by these, we propose the\nContinual Learning of Multiple Cognitive Functions with Brain-inspired Temporal\nDevelopment Mechanism(TD-MCL), enabling cognitive enhancement from simple to\ncomplex in Perception-Motor-Interaction(PMI) multiple cognitive task scenarios.\nThe TD-MCL model proposes the sequential evolution of long-range connections\nbetween different cognitive modules to promote positive knowledge transfer,\nwhile using feedback-guided local connection inhibition and pruning to\neffectively eliminate redundancies in previous tasks, reducing energy\nconsumption while preserving acquired knowledge. Experiments show that the\nproposed method can achieve continual learning capabilities while reducing\nnetwork scale, without introducing regularization, replay, or freezing\nstrategies, and achieving superior accuracy on new tasks compared to direct\nlearning. The proposed method shows that the brain's developmental mechanisms\noffer a valuable reference for exploring biologically plausible, low-energy\nenhancements of general cognitive abilities.",
      "tldr_zh": "本文提出了一种受大脑启发的时序发展机制(TD-MCL)，用于持续学习多个认知功能。该方法模拟大脑跨区域的时序发展，通过顺序演化不同认知模块间的长程连接来促进正向知识迁移，同时利用反馈引导的局部连接抑制和剪枝来消除冗余，从而在降低能耗的同时保留已获得的知识。实验结果表明，TD-MCL在感知-运动-交互(PMI)多认知任务场景下，无需正则化、回放或冻结策略，即可实现持续学习能力并减小网络规模，且在新任务上取得了优于直接学习的精度。该研究表明大脑的发育机制为探索生物可信、低能耗的通用认知能力增强提供了一个有价值的参考。\n",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05621v1",
      "published_date": "2025-04-08 02:36:36 UTC",
      "updated_date": "2025-04-08 02:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:18:05.512944"
    },
    {
      "arxiv_id": "2504.05618v1",
      "title": "Technical Report: Full Version of Analyzing and Optimizing Perturbation of DP-SGD Geometrically",
      "title_zh": "技术报告：DP-SGD 几何扰动分析与优化的完整版本\n",
      "authors": [
        "Jiawei Duan",
        "Haibo Hu",
        "Qingqing Ye",
        "Xinyue Sun"
      ],
      "abstract": "Differential privacy (DP) has become a prevalent privacy model in a wide\nrange of machine learning tasks, especially after the debut of DP-SGD. However,\nDP-SGD, which directly perturbs gradients in the training iterations, fails to\nmitigate the negative impacts of noise on gradient direction. As a result,\nDP-SGD is often inefficient. Although various solutions (e.g., clipping to\nreduce the sensitivity of gradients and amplifying privacy bounds to save\nprivacy budgets) are proposed to trade privacy for model efficiency, the root\ncause of its inefficiency is yet unveiled.\n  In this work, we first generalize DP-SGD and theoretically derive the impact\nof DP noise on the training process. Our analysis reveals that, in terms of a\nperturbed gradient, only the noise on direction has eminent impact on the model\nefficiency while that on magnitude can be mitigated by optimization techniques,\ni.e., fine-tuning gradient clipping and learning rate. Besides, we confirm that\ntraditional DP introduces biased noise on the direction when adding unbiased\nnoise to the gradient itself. Overall, the perturbation of DP-SGD is actually\nsub-optimal from a geometric perspective. Motivated by this, we design a\ngeometric perturbation strategy GeoDP within the DP framework, which perturbs\nthe direction and the magnitude of a gradient, respectively. By directly\nreducing the noise on the direction, GeoDP mitigates the negative impact of DP\nnoise on model efficiency with the same DP guarantee. Extensive experiments on\ntwo public datasets (i.e., MNIST and CIFAR-10), one synthetic dataset and three\nprevalent models (i.e., Logistic Regression, CNN and ResNet) confirm the\neffectiveness and generality of our strategy.",
      "tldr_zh": "该技术报告深入分析了差分隐私随机梯度下降(DP-SGD)的扰动对模型训练效率的影响。研究表明，DP-SGD中噪声对梯度方向的影响是导致效率低下的主要原因，而对梯度的幅度影响可以通过优化技术缓解。传统的DP在梯度上添加无偏噪声时，实际上对方向引入了有偏噪声，从几何角度来看，DP-SGD的扰动并非最优。因此，研究提出了一种几何扰动策略GeoDP，分别扰动梯度的方向和幅度，从而在相同的DP保证下，降低噪声对方向的影响，提高模型效率。在MNIST、CIFAR-10等数据集以及Logistic Regression、CNN和ResNet等模型上的实验验证了GeoDP的有效性和通用性。\n",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "This is the full version of our paper \"Analyzing and Optimizing\n  Perturbation of DP-SGD Geometrically\", which will appear in ICDE 2025 as a\n  regular research paper",
      "pdf_url": "http://arxiv.org/pdf/2504.05618v1",
      "published_date": "2025-04-08 02:26:10 UTC",
      "updated_date": "2025-04-08 02:26:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:18:17.191869"
    },
    {
      "arxiv_id": "2504.05615v1",
      "title": "FedEFC: Federated Learning Using Enhanced Forward Correction Against Noisy Labels",
      "title_zh": "FedEFC：使用增强型前向校正对抗噪声标签的联邦学习\n",
      "authors": [
        "Seunghun Yu",
        "Jin-Hyun Ahn",
        "Joonhyuk Kang"
      ],
      "abstract": "Federated Learning (FL) is a powerful framework for privacy-preserving\ndistributed learning. It enables multiple clients to collaboratively train a\nglobal model without sharing raw data. However, handling noisy labels in FL\nremains a major challenge due to heterogeneous data distributions and\ncommunication constraints, which can severely degrade model performance. To\naddress this issue, we propose FedEFC, a novel method designed to tackle the\nimpact of noisy labels in FL. FedEFC mitigates this issue through two key\ntechniques: (1) prestopping, which prevents overfitting to mislabeled data by\ndynamically halting training at an optimal point, and (2) loss correction,\nwhich adjusts model updates to account for label noise. In particular, we\ndevelop an effective loss correction tailored to the unique challenges of FL,\nincluding data heterogeneity and decentralized training. Furthermore, we\nprovide a theoretical analysis, leveraging the composite proper loss property,\nto demonstrate that the FL objective function under noisy label distributions\ncan be aligned with the clean label distribution. Extensive experimental\nresults validate the effectiveness of our approach, showing that it\nconsistently outperforms existing FL techniques in mitigating the impact of\nnoisy labels, particularly under heterogeneous data settings (e.g., achieving\nup to 41.64% relative performance improvement over the existing loss correction\nmethod).",
      "tldr_zh": "本文提出了一种名为FedEFC的新型联邦学习方法，旨在解决联邦学习中噪声标签带来的挑战。FedEFC通过两种关键技术缓解噪声标签的影响：(1) prestopping，通过动态停止训练防止模型过度拟合错误标记的数据；(2) 损失校正，调整模型更新以纠正标签噪声。特别地，作者开发了一种针对联邦学习独特挑战（包括数据异构性和去中心化训练）的有效损失校正方法。理论分析表明，在噪声标签分布下，联邦学习目标函数可以与干净标签分布对齐。实验结果表明，FedEFC在减轻噪声标签的影响方面优于现有的联邦学习技术，尤其是在异构数据设置下，性能提升显著（相对于现有损失校正方法，性能提升高达41.64%）。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.05615v1",
      "published_date": "2025-04-08 02:14:50 UTC",
      "updated_date": "2025-04-08 02:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:18:29.329525"
    },
    {
      "arxiv_id": "2504.05607v1",
      "title": "FactGuard: Leveraging Multi-Agent Systems to Generate Answerable and Unanswerable Questions for Enhanced Long-Context LLM Extraction",
      "title_zh": "FactGuard：利用多智能体系统生成可回答和不可回答问题，以增强长文本 LLM 的抽取能力\n",
      "authors": [
        "Qian-Wen Zhang",
        "Fang Li",
        "Jie Wang",
        "Lingfeng Qiao",
        "Yifei Yu",
        "Di Yin",
        "Xing Sun"
      ],
      "abstract": "Extractive reading comprehension systems are designed to locate the correct\nanswer to a question within a given text. However, a persistent challenge lies\nin ensuring these models maintain high accuracy in answering questions while\nreliably recognizing unanswerable queries. Despite significant advances in\nlarge language models (LLMs) for reading comprehension, this issue remains\ncritical, particularly as the length of supported contexts continues to expand.\nTo address this challenge, we propose an innovative data augmentation\nmethodology grounded in a multi-agent collaborative framework. Unlike\ntraditional methods, such as the costly human annotation process required for\ndatasets like SQuAD 2.0, our method autonomously generates evidence-based\nquestion-answer pairs and systematically constructs unanswerable questions.\nUsing this methodology, we developed the FactGuard-Bench dataset, which\ncomprises 25,220 examples of both answerable and unanswerable question\nscenarios, with context lengths ranging from 8K to 128K. Experimental\nevaluations conducted on seven popular LLMs reveal that even the most advanced\nmodels achieve only 61.79% overall accuracy. Furthermore, we emphasize the\nimportance of a model's ability to reason about unanswerable questions to avoid\ngenerating plausible but incorrect answers. By implementing efficient data\nselection and generation within the multi-agent collaborative framework, our\nmethod significantly reduces the traditionally high costs associated with\nmanual annotation and provides valuable insights for the training and\noptimization of LLMs.",
      "tldr_zh": "该论文提出了一种基于多智能体协作框架的数据增强方法，用于生成可回答和不可回答的问题，以提升长文本LLM的抽取能力。该方法旨在解决抽取式阅读理解系统在高准确率回答问题和可靠识别不可回答问题方面的挑战。通过该方法构建了FactGuard-Bench数据集，包含25,220个可回答和不可回答问题，上下文长度从8K到128K不等。实验结果表明，即使是最先进的LLM在该数据集上的总体准确率也仅为61.79%。该研究强调了模型推理不可回答问题的能力的重要性，并证明了该方法能有效降低传统人工标注的高成本，为LLM的训练和优化提供有价值的见解。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05607v1",
      "published_date": "2025-04-08 01:45:16 UTC",
      "updated_date": "2025-04-08 01:45:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:18:41.364660"
    },
    {
      "arxiv_id": "2504.05591v1",
      "title": "Class Imbalance Correction for Improved Universal Lesion Detection and Tagging in CT",
      "title_zh": "类不平衡校正以改进 CT 中通用病灶检测和标记\n",
      "authors": [
        "Peter D. Erickson",
        "Tejas Sudharshan Mathai",
        "Ronald M. Summers"
      ],
      "abstract": "Radiologists routinely detect and size lesions in CT to stage cancer and\nassess tumor burden. To potentially aid their efforts, multiple lesion\ndetection algorithms have been developed with a large public dataset called\nDeepLesion (32,735 lesions, 32,120 CT slices, 10,594 studies, 4,427 patients, 8\nbody part labels). However, this dataset contains missing measurements and\nlesion tags, and exhibits a severe imbalance in the number of lesions per label\ncategory. In this work, we utilize a limited subset of DeepLesion (6\\%, 1331\nlesions, 1309 slices) containing lesion annotations and body part label tags to\ntrain a VFNet model to detect lesions and tag them. We address the class\nimbalance by conducting three experiments: 1) Balancing data by the body part\nlabels, 2) Balancing data by the number of lesions per patient, and 3)\nBalancing data by the lesion size. In contrast to a randomly sampled\n(unbalanced) data subset, our results indicated that balancing the body part\nlabels always increased sensitivity for lesions >= 1cm for classes with low\ndata quantities (Bone: 80\\% vs. 46\\%, Kidney: 77\\% vs. 61\\%, Soft Tissue: 70\\%\nvs. 60\\%, Pelvis: 83\\% vs. 76\\%). Similar trends were seen for three other\nmodels tested (FasterRCNN, RetinaNet, FoveaBox). Balancing data by lesion size\nalso helped the VFNet model improve recalls for all classes in contrast to an\nunbalanced dataset. We also provide a structured reporting guideline for a\n``Lesions'' subsection to be entered into the ``Findings'' section of a\nradiology report. To our knowledge, we are the first to report the class\nimbalance in DeepLesion, and have taken data-driven steps to address it in the\ncontext of joint lesion detection and tagging.",
      "tldr_zh": "该研究针对DeepLesion数据集中病灶检测和标记任务中存在的类别不平衡问题，提出了一系列数据平衡策略以提升模型性能。研究人员利用DeepLesion数据集的一个子集，训练VFNet模型进行病灶检测和标记，并通过以下三种方式平衡数据：按身体部位标签、按每位患者的病灶数量以及按病灶大小。实验结果表明，与随机抽样（不平衡）的数据子集相比，按身体部位标签平衡数据能显著提高低数据量类别（如骨骼、肾脏、软组织、盆腔）中大于等于1厘米病灶的敏感性。按病灶大小平衡数据也有助于VFNet模型提高所有类别的召回率。此外，该研究还提供了一个结构化的报告指南，用于放射报告的“发现”部分的“病灶”小节。该研究首次报告了DeepLesion中的类别不平衡问题，并采取了数据驱动的步骤来解决联合病灶检测和标记任务中的这一问题。\n",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Published at MICCAI MILLAND Workshop 2022",
      "pdf_url": "http://arxiv.org/pdf/2504.05591v1",
      "published_date": "2025-04-08 00:58:26 UTC",
      "updated_date": "2025-04-08 00:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:18:53.519835"
    },
    {
      "arxiv_id": "2504.05588v1",
      "title": "Multi-fidelity Reinforcement Learning Control for Complex Dynamical Systems",
      "title_zh": "复杂动态系统的多保真强化学习控制\n",
      "authors": [
        "Luning Sun",
        "Xin-Yang Liu",
        "Siyan Zhao",
        "Aditya Grover",
        "Jian-Xun Wang",
        "Jayaraman J. Thiagarajan"
      ],
      "abstract": "Controlling instabilities in complex dynamical systems is challenging in\nscientific and engineering applications. Deep reinforcement learning (DRL) has\nseen promising results for applications in different scientific applications.\nThe many-query nature of control tasks requires multiple interactions with real\nenvironments of the underlying physics. However, it is usually sparse to\ncollect from the experiments or expensive to simulate for complex dynamics.\nAlternatively, controlling surrogate modeling could mitigate the computational\ncost issue. However, a fast and accurate learning-based model by offline\ntraining makes it very hard to get accurate pointwise dynamics when the\ndynamics are chaotic. To bridge this gap, the current work proposes a\nmulti-fidelity reinforcement learning (MFRL) framework that leverages\ndifferentiable hybrid models for control tasks, where a physics-based hybrid\nmodel is corrected by limited high-fidelity data. We also proposed a\nspectrum-based reward function for RL learning. The effect of the proposed\nframework is demonstrated on two complex dynamics in physics. The statistics of\nthe MFRL control result match that computed from many-query evaluations of the\nhigh-fidelity environments and outperform other SOTA baselines.",
      "tldr_zh": "该论文提出了一种多精度强化学习(MFRL)框架，用于控制复杂动力系统中的不稳定性。该框架利用可微混合模型进行控制任务，其中基于物理的混合模型通过有限的高精度数据进行校正。同时，论文还提出了一种基于频谱的奖励函数用于强化学习。实验结果表明，在两个复杂的物理动力学系统中，MFRL的控制结果与高精度环境的多查询评估结果相匹配，并且优于其他最先进的基线方法。该方法旨在解决控制任务需要多次与真实环境交互，而复杂动力学系统的实验数据收集稀疏或模拟成本高昂的问题。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05588v1",
      "published_date": "2025-04-08 00:50:15 UTC",
      "updated_date": "2025-04-08 00:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:19:05.190222"
    },
    {
      "arxiv_id": "2504.05586v1",
      "title": "Finding Fantastic Experts in MoEs: A Unified Study for Expert Dropping Strategies and Observations",
      "title_zh": "在 MoE 中寻找卓越专家：专家丢弃策略和观察的统一研究\n",
      "authors": [
        "Ajay Jaiswal",
        "Jianyu Wang",
        "Yixiao Li",
        "Pingzhi Li",
        "Tianlong Chen",
        "Zhangyang Wang",
        "Chong Wang",
        "Ruoming Pang",
        "Xianzhi Du"
      ],
      "abstract": "Sparsely activated Mixture-of-Experts (SMoE) has shown promise in scaling up\nthe learning capacity of neural networks. However, vanilla SMoEs have issues\nsuch as expert redundancy and heavy memory requirements, making them\ninefficient and non-scalable, especially for resource-constrained scenarios.\nExpert-level sparsification of SMoEs involves pruning the least important\nexperts to address these limitations. In this work, we aim to address three\nquestions: (1) What is the best recipe to identify the least knowledgeable\nsubset of experts that can be dropped with minimal impact on performance? (2)\nHow should we perform expert dropping (one-shot or iterative), and what\ncorrection measures can we undertake to minimize its drastic impact on SMoE\nsubnetwork capabilities? (3) What capabilities of full-SMoEs are severely\nimpacted by the removal of the least dominant experts, and how can we recover\nthem? Firstly, we propose MoE Experts Compression Suite (MC-Suite), which is a\ncollection of some previously explored and multiple novel recipes to provide a\ncomprehensive benchmark for estimating expert importance from diverse\nperspectives, as well as unveil numerous valuable insights for SMoE experts.\nSecondly, unlike prior works with a one-shot expert pruning approach, we\nexplore the benefits of iterative pruning with the re-estimation of the\nMC-Suite criterion. Moreover, we introduce the benefits of task-agnostic\nfine-tuning as a correction mechanism during iterative expert dropping, which\nwe term MoE Lottery Subnetworks. Lastly, we present an experimentally validated\nconjecture that, during expert dropping, SMoEs' instruction-following\ncapabilities are predominantly hurt, which can be restored to a robust level\nsubject to external augmentation of instruction-following capabilities using\nk-shot examples and supervised fine-tuning.",
      "tldr_zh": "本文深入研究了稀疏激活的混合专家模型(SMoE)中专家丢弃策略，旨在解决SMoE的冗余和内存需求问题。研究提出了MoE Experts Compression Suite (MC-Suite)，一个包含多种专家重要性评估方法的综合基准，并揭示了SMoE专家的重要见解。与以往的一次性剪枝方法不同，本文探索了迭代剪枝的优势，并引入了任务无关的微调作为纠正机制，称为MoE Lottery Subnetworks。实验验证表明，专家丢弃主要影响SMoE的指令跟随能力，可以通过外部增强指令跟随能力（例如k-shot示例和监督微调）来恢复。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05586v1",
      "published_date": "2025-04-08 00:49:08 UTC",
      "updated_date": "2025-04-08 00:49:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:19:17.230903"
    },
    {
      "arxiv_id": "2504.05585v1",
      "title": "TW-CRL: Time-Weighted Contrastive Reward Learning for Efficient Inverse Reinforcement Learning",
      "title_zh": "TW-CRL：用于高效逆强化学习的时间加权对比奖励学习\n",
      "authors": [
        "Yuxuan Li",
        "Ning Yang",
        "Stephen Xia"
      ],
      "abstract": "Episodic tasks in Reinforcement Learning (RL) often pose challenges due to\nsparse reward signals and high-dimensional state spaces, which hinder efficient\nlearning. Additionally, these tasks often feature hidden \"trap states\" --\nirreversible failures that prevent task completion but do not provide explicit\nnegative rewards to guide agents away from repeated errors. To address these\nissues, we propose Time-Weighted Contrastive Reward Learning (TW-CRL), an\nInverse Reinforcement Learning (IRL) framework that leverages both successful\nand failed demonstrations. By incorporating temporal information, TW-CRL learns\na dense reward function that identifies critical states associated with success\nor failure. This approach not only enables agents to avoid trap states but also\nencourages meaningful exploration beyond simple imitation of expert\ntrajectories. Empirical evaluations on navigation tasks and robotic\nmanipulation benchmarks demonstrate that TW-CRL surpasses state-of-the-art\nmethods, achieving improved efficiency and robustness.",
      "tldr_zh": "该论文提出了时间加权对比奖励学习(TW-CRL)框架，用于解决强化学习中由于稀疏奖励和高维状态空间导致的学习效率低下问题，特别是针对存在“陷阱状态”的 episodic 任务。TW-CRL 是一种逆强化学习(IRL)方法，它利用成功和失败的演示数据，并结合时间信息学习稠密的奖励函数，从而识别与成功或失败相关的关键状态。通过这种方式，智能体能够避免“陷阱状态”，并进行更有意义的探索，超越简单的模仿学习。在导航任务和机器人操作基准测试上的实验结果表明，TW-CRL 优于现有方法，实现了更高的效率和鲁棒性。\n",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05585v1",
      "published_date": "2025-04-08 00:48:29 UTC",
      "updated_date": "2025-04-08 00:48:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:19:29.293412"
    },
    {
      "arxiv_id": "2504.05576v1",
      "title": "SoundVista: Novel-View Ambient Sound Synthesis via Visual-Acoustic Binding",
      "title_zh": "SoundVista：基于视觉-声学绑定的新视角环境声音合成\n",
      "authors": [
        "Mingfei Chen",
        "Israel D. Gebru",
        "Ishwarya Ananthabhotla",
        "Christian Richardt",
        "Dejan Markovic",
        "Jake Sandakly",
        "Steven Krenn",
        "Todd Keebler",
        "Eli Shlizerman",
        "Alexander Richard"
      ],
      "abstract": "We introduce SoundVista, a method to generate the ambient sound of an\narbitrary scene at novel viewpoints. Given a pre-acquired recording of the\nscene from sparsely distributed microphones, SoundVista can synthesize the\nsound of that scene from an unseen target viewpoint. The method learns the\nunderlying acoustic transfer function that relates the signals acquired at the\ndistributed microphones to the signal at the target viewpoint, using a limited\nnumber of known recordings. Unlike existing works, our method does not require\nconstraints or prior knowledge of sound source details. Moreover, our method\nefficiently adapts to diverse room layouts, reference microphone configurations\nand unseen environments. To enable this, we introduce a visual-acoustic binding\nmodule that learns visual embeddings linked with local acoustic properties from\npanoramic RGB and depth data. We first leverage these embeddings to optimize\nthe placement of reference microphones in any given scene. During synthesis, we\nleverage multiple embeddings extracted from reference locations to get adaptive\nweights for their contribution, conditioned on target viewpoint. We benchmark\nthe task on both publicly available data and real-world settings. We\ndemonstrate significant improvements over existing methods.",
      "tldr_zh": "SoundVista 是一种通过视觉-声学绑定生成任意场景新视角环境声音的方法。它利用预先获取的稀疏分布麦克风记录，合成目标视角的场景声音。该方法学习潜在的声学传递函数，将分布式麦克风信号与目标视角的信号关联起来，无需声源细节的约束或先验知识。SoundVista 引入视觉-声学绑定模块，从全景 RGB 和深度数据中学习与局部声学特性相关的视觉嵌入，从而适应不同的房间布局、参考麦克风配置和未见环境。该方法首先利用这些嵌入优化参考麦克风在任何给定场景中的位置，然后在合成过程中，根据目标视角，利用从参考位置提取的多个嵌入来获得自适应权重，从而确定它们的贡献。实验结果表明，SoundVista 在公开数据和真实世界环境中均优于现有方法。\n",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.SD",
      "comment": "Highlight Accepted to CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.05576v1",
      "published_date": "2025-04-08 00:22:16 UTC",
      "updated_date": "2025-04-08 00:22:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:19:41.478028"
    },
    {
      "arxiv_id": "2504.05573v1",
      "title": "MicroNN: An On-device Disk-resident Updatable Vector Database",
      "title_zh": "MicroNN：一种在设备上驻留于磁盘的可更新向量数据库\n",
      "authors": [
        "Jeffrey Pound",
        "Floris Chabert",
        "Arjun Bhushan",
        "Ankur Goswami",
        "Anil Pacaci",
        "Shihabur Rahman Chowdhury"
      ],
      "abstract": "Nearest neighbour search over dense vector collections has important\napplications in information retrieval, retrieval augmented generation (RAG),\nand content ranking. Performing efficient search over large vector collections\nis a well studied problem with many existing approaches and open source\nimplementations. However, most state-of-the-art systems are generally targeted\ntowards scenarios using large servers with an abundance of memory, static\nvector collections that are not updatable, and nearest neighbour search in\nisolation of other search criteria. We present Micro Nearest Neighbour\n(MicroNN), an embedded nearest-neighbour vector search engine designed for\nscalable similarity search in low-resource environments. MicroNN addresses the\nproblem of on-device vector search for real-world workloads containing updates\nand hybrid search queries that combine nearest neighbour search with structured\nattribute filters. In this scenario, memory is highly constrained and\ndisk-efficient index structures and algorithms are required, as well as support\nfor continuous inserts and deletes. MicroNN is an embeddable library that can\nscale to large vector collections with minimal resources. MicroNN is used in\nproduction and powers a wide range of vector search use-cases on-device.\nMicroNN takes less than 7 ms to retrieve the top-100 nearest neighbours with\n90% recall on publicly available million-scale vector benchmark while using ~10\nMB of memory.",
      "tldr_zh": "MicroNN是一个专为低资源环境设计的嵌入式近邻向量搜索引擎，旨在解决设备端向量搜索在实际工作负载中面临的挑战，如更新和混合搜索查询。它通过磁盘高效的索引结构和算法，支持连续的插入和删除操作，从而在内存高度受限的情况下实现大规模向量集合的相似性搜索。MicroNN在百万级向量基准测试中，仅使用约10MB内存，就能在7ms内检索到Top-100近邻，召回率高达90%。该引擎已在生产环境中使用，为各种设备端向量搜索用例提供支持。\n",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05573v1",
      "published_date": "2025-04-08 00:05:58 UTC",
      "updated_date": "2025-04-08 00:05:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:19:53.217880"
    },
    {
      "arxiv_id": "2504.05571v1",
      "title": "Knowledge-Instruct: Effective Continual Pre-training from Limited Data using Instructions",
      "title_zh": "Knowledge-Instruct：利用指令从有限数据中进行有效的持续预训练\n",
      "authors": [
        "Oded Ovadia",
        "Meni Brief",
        "Rachel Lemberg",
        "Eitam Sheetrit"
      ],
      "abstract": "While Large Language Models (LLMs) acquire vast knowledge during\npre-training, they often lack domain-specific, new, or niche information.\nContinual pre-training (CPT) attempts to address this gap but suffers from\ncatastrophic forgetting and inefficiencies in low-data regimes. We introduce\nKnowledge-Instruct, a novel approach to efficiently inject knowledge from\nlimited corpora through pure instruction-tuning. By generating\ninformation-dense synthetic instruction data, it effectively integrates new\nknowledge while preserving general reasoning and instruction-following\nabilities. Knowledge-Instruct demonstrates superior factual memorization,\nminimizes catastrophic forgetting, and remains scalable by leveraging synthetic\ndata from relatively small language models. Additionally, it enhances\ncontextual understanding, including complex multi-hop reasoning, facilitating\nintegration with retrieval systems. We validate its effectiveness across\ndiverse benchmarks, including Companies, a new dataset that we release to\nmeasure knowledge injection capabilities.",
      "tldr_zh": "该论文提出 Knowledge-Instruct，一种利用指令微调从有限数据中进行有效持续预训练的新方法。该方法通过生成信息密集的合成指令数据，有效地整合新知识，同时保留通用推理和指令遵循能力。Knowledge-Instruct 在事实记忆方面表现出色，最大限度地减少了灾难性遗忘，并且可以通过利用来自相对较小的语言模型的合成数据来实现扩展。此外，它还增强了上下文理解能力，包括复杂的多跳推理，从而促进与检索系统的集成。论文通过包括 Companies 在内的各种基准测试验证了其有效性，Companies 是一个用于衡量知识注入能力的新数据集。\n",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.05571v1",
      "published_date": "2025-04-08 00:00:36 UTC",
      "updated_date": "2025-04-08 00:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-04-10T02:20:05.198034"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 80,
  "processed_papers_count": 80,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-04-10T02:21:16.993014"
}