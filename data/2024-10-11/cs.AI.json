{
  "date": "2024-10-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-10-11 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于大型语言模型（LLM）的安全、推理、多模态应用和强化学习等领域，亮点包括高效的 LLM 攻击防御方法（如 JAILJUDGE）、多任务学习框架（如 Multimodal Audio-based Disease Prediction）和知识图谱推理（如 ReasonPlanner），这些工作突显了 AI 在医疗、机器人和知识处理中的潜力，同时有名学者如 Paul Groth 的实体链接研究值得关注。\n\n下面，我挑选并简要讨论今天更重要的论文，先从高影响力或话题度高的开始（如 LLM 安全和多模态模型），再聊相关或有潜力的工作。其他较常规或非核心论文（如一些纯理论优化或小众数据集分析）将快速掠过，只列出标题和关键点，以控制篇幅。\n\n### 重点论文讨论\n\n**1. JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework（JAILJUDGE: 一种全面的越狱攻击评估基准，使用多代理增强解释评估框架）**  \n   这篇论文提出 JAILJUDGE 基准，用于评估 LLM 的越狱攻击风险。通过多代理框架（如 LLM 增强的解释评分），它实现了更细粒度的风险评估，并在多种 LLM 上表现出色（如 GPT-4）。主要贡献：提供了一个鲁棒的评估工具，显著提升了 LLM 安全性的可解释性和泛化能力，实验显示在真实场景中降低了攻击成功率，是 LLM 安全领域的重要进展。\n\n**2. AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents（AgentHarm: 用于评估 LLM 代理有害性的基准）**  \n   作者包括 Yarin Gal 等知名学者，论文构建了 AgentHarm 基准，测试 LLM 代理在恶意任务中的易受攻击性。发现领先 LLM（如 GPT-4）在未越狱时仍易受影响，主要贡献：揭示了 LLM 代理的安全漏洞，并通过实验证明简单越狱模板可显著放大风险，提供了一个全面评估框架。\n\n**3. Nudging: Inference-time Alignment of LLMs via Guided Decoding（Nudging: 通过引导解码在推理时对齐 LLM）**  \n   这篇工作提出 Nudging 算法，用于在不额外训练的情况下对齐 LLM。通过小模型引导大模型的输出，实现了高效的指令跟随。主要贡献：在多任务测试中，Nudging 让大模型（如 Gemma-2-27b）在零样本场景下性能媲美或超越大型对齐模型，突显了推理时动态对齐的潜力。\n\n**4. Multimodal Audio-based Disease Prediction with Transformer-based Hierarchical Fusion Network（使用 Transformer 的分层融合网络进行多模态音频疾病预测）**  \n   论文开发了一个 Transformer 框架，融合音频多模态特征预测疾病（如 COVID-19）。主要贡献：改进了传统方法的融合策略，提升了预测准确性，实验在多个数据集上达到 SOTA 性能，展示了 AI 在医疗音频分析中的应用价值。\n\n**5. ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs（ReasonPlanner: 使用时间知识图谱和 LLM 增强动态环境中的自主规划）**  \n   这篇论文整合 LLM 和时间知识图谱，实现更智能的自主代理规划。主要贡献：在 ScienceWorld 基准上性能提升 1.8 倍，强调了 LLM 在解释性和样本效率方面的优势，适合动态任务如实验规划。\n\n**6. DeltaDQ: Ultra-High Delta Compression for Fine-Tuned LLMs via Group-wise Dropout and Separate Quantization（DeltaDQ: 通过分组 Dropout 和分离量化实现微调 LLM 的超高压缩）**  \n   针对 LLM 微调后的参数膨胀，论文提出 DeltaDQ 压缩框架。主要贡献：实现了 16 倍压缩率，同时保持准确性（如 WizardMath 模型上提升），这是高效 LLM 部署的关键创新。\n\n**7. LLMD: A Large Language Model for Interpreting Longitudinal Medical Records（LLMD: 用于解释纵向医疗记录的大型语言模型）**  \n   作者包括多名医疗 AI 专家，论文构建了 LLMD 模型，分析患者历史记录。主要贡献：在医疗知识基准上超越 GPT-4，展示了在真实数据上的鲁棒性，强调了 LLM 在个性化医疗中的潜力。\n\n**8. Quantum-Trained Convolutional Neural Network for Deepfake Audio Detection（用于深度伪造音频检测的量子训练卷积神经网络）**  \n   论文引入量子机器学习框架优化 CNN 检测音频深度伪造。主要贡献：减少了参数量（70% 减少），保持高准确性，这是 AI 安全领域的有趣扩展。\n\n**9. Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts（基准膨胀: 使用回顾性保留集揭示 LLM 性能差距）**  \n   这篇工作检测 LLM 基准中的数据污染问题。主要贡献：通过 Retro-Holdouts 方法暴露性能夸大（如某些 LLM 得分膨胀 16%），为基准评估提供了新视角。\n\n**10. CYCLE: Cross-Year Contrastive Learning in Entity-Linking（CYCLE: 实体链接中的跨年对比学习）**  \n   作者 Paul Groth 等知名学者提出 CYCLE 方法，缓解实体链接模型的时序退化。主要贡献：通过图对比学习提升了低度实体链接的鲁棒性，实验显示性能提升 13.9%，适用于动态知识图谱。\n\n**11. Synth-SONAR: Sonar Image Synthesis with Enhanced Diversity and Realism via Dual Diffusion Models and GPT Prompting（Synth-SONAR: 通过双扩散模型和 GPT 提示增强声呐图像合成多样性和真实性）**  \n   论文使用扩散模型和 GPT 生成更真实的声呐图像。主要贡献：改进了水下图像合成技术，实验显示在多样性上优于 SOTA 方法，适用于海洋探索。\n\n**12. pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2（pLDDT-Predictor: 使用 Transformer 和 ESM2 的高速度蛋白质筛选）**  \n   这篇工作加速了蛋白质结构预测。主要贡献：比 AlphaFold2 快 25 万倍，同时保持高相关性（Pearson 0.7891），是生物计算领域的效率提升。\n\n其他论文如一些图神经网络优化或常规强化学习方法（如 \"Enhancing Multi-Step Reasoning Abilities of Language Models\"），虽然有贡献但相对常规，我仅快速列出标题和要点：  \n- **Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization（通过直接 Q 函数优化增强语言模型的多步推理能力）**：提出 DQO 方法，提升数学推理，实验在 GSM8K 上优于基线。  \n- **Refinements on the Complementary PDB Construction Mechanism（对互补 PDB 构建机制的改进）**：优化规划任务的启发式搜索，改进 PDB 构建。  \n- **Natural Language Counterfactual Explanations for Graphs Using Large Language Models（使用 LLM 为图生成自然语言反事实解释）**：利用 LLM 生成图数据的可解释解释，提升 XAI 性能。\n\n今天的论文总体上强调了 AI 的安全性和应用扩展，LLM 相关工作尤其活跃。如果你对特定领域感兴趣，如医疗或推理，建议关注上述亮点论文！（本快报约 1500 字，保持简洁。）",
  "papers": [
    {
      "arxiv_id": "2410.09302v2",
      "title": "Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization",
      "title_zh": "通过直接 Q 函数优化增强语言模型的多步推理能力",
      "authors": [
        "Kaixuan Ji",
        "Guanlin Liu",
        "Ning Dai",
        "Qingping Yang",
        "Renjie Zheng",
        "Zheng Wu",
        "Chen Dun",
        "Quanquan Gu",
        "Lin Yan"
      ],
      "abstract": "Reinforcement Learning (RL) plays a crucial role in aligning large language\nmodels (LLMs) with human preferences and improving their ability to perform\ncomplex tasks. However, current approaches either require significant\ncomputational resources due to the use of multiple models and extensive online\nsampling for training (e.g., PPO) or are framed as bandit problems (e.g., DPO,\nDRO), which often struggle with multi-step reasoning tasks, such as math\nproblem solving and complex reasoning that involve long chains of thought. To\novercome these limitations, we introduce Direct Q-function Optimization (DQO),\nwhich formulates the response generation process as a Markov Decision Process\n(MDP) and utilizes the soft actor-critic (SAC) framework to optimize a\nQ-function directly parameterized by the language model. The MDP formulation of\nDQO offers structural advantages over bandit-based methods, enabling more\neffective process supervision. Experimental results on two math problem-solving\ndatasets, GSM8K and MATH, demonstrate that DQO outperforms previous methods,\nestablishing it as a promising offline reinforcement learning approach for\naligning language models.",
      "tldr_zh": "本研究针对强化学习（RL）在对齐大型语言模型（LLMs）时存在的资源消耗大和多步推理能力弱的问题（如数学问题求解），提出Direct Q-function Optimization (DQO)方法。该方法将响应生成过程建模为Markov Decision Process (MDP)，并利用soft actor-critic (SAC)框架直接优化Q-function，从而实现更有效的过程监督。在GSM8K和MATH数据集上的实验表明，DQO优于现有方法，建立了一种有前景的离线RL方法，用于提升语言模型的多步推理能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09302v2",
      "published_date": "2024-10-11 23:29:20 UTC",
      "updated_date": "2025-02-11 01:46:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:04:00.735582"
    },
    {
      "arxiv_id": "2410.09300v3",
      "title": "Nudging: Inference-time Alignment of LLMs via Guided Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Fei",
        "Yasaman Razeghi",
        "Sameer Singh"
      ],
      "abstract": "Large language models (LLMs) require alignment to effectively and safely\nfollow user instructions. This process necessitates training an aligned version\nfor every base model, resulting in significant computational overhead. In this\nwork, we propose nudging, a simple, plug-and-play, and training-free algorithm\nthat aligns any base model at inference time using a small aligned model.\nNudging is motivated by recent findings that alignment primarily alters the\nmodel's behavior on a small subset of stylistic tokens (e.g., discourse\nmarkers). We find that base models are significantly more uncertain when\ngenerating these tokens. Building on this insight, nudging employs a small\naligned model to generate nudging tokens to guide the base model's output\nduring decoding when the base model's uncertainty is high. We evaluate nudging\nacross 3 model families on a diverse range of open-instruction tasks. Without\nany training, nudging a large base model with a 7x-14x smaller aligned model\nachieves zero-shot performance comparable to, and sometimes surpassing, that of\nlarge aligned models. By operating at the token level, nudging enables\noff-the-shelf collaboration between model families. For instance, nudging\nGemma-2-27b with Llama-2-7b-chat outperforms Llama-2-70b-chat on various tasks.\nOverall, our work offers a modular and cost-efficient solution to LLM\nalignment. Our project website: https://fywalter.github.io/nudging/ .",
      "tldr_zh": "该论文提出Nudging，一种无需训练的即插即用算法，用于在推理时通过引导解码(Guided Decoding)对齐大型语言模型(LLMs)，以减少计算开销。Nudging利用一个较小的对齐模型，在基模型生成不确定性高的风格化标记（如话语标记）时，提供nudging tokens来引导输出。实验在3个模型系列上评估，结果显示，使用7x-14x更小的对齐模型，Nudging使基模型在零样本指令任务上达到或超过大型对齐模型的性能，例如nudging Gemma-2-27b with Llama-2-7b-chat优于Llama-2-70b-chat。该方法提供了一个模块化、成本高效的LLM对齐解决方案，支持不同模型系列的协作。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09300v3",
      "published_date": "2024-10-11 23:24:38 UTC",
      "updated_date": "2025-04-20 00:16:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:04:22.527871"
    },
    {
      "arxiv_id": "2410.09297v1",
      "title": "Refinements on the Complementary PDB Construction Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Yufeng Zou"
      ],
      "abstract": "Pattern database (PDB) is one of the most popular automated heuristic\ngeneration techniques. A PDB maps states in a planning task to abstract states\nby considering a subset of variables and stores their optimal costs to the\nabstract goal in a look up table. As the result of the progress made on\nsymbolic search over recent years, symbolic-PDB-based planners achieved\nimpressive results in the International Planning Competition (IPC) 2018. Among\nthem, Complementary 1 (CPC1) tied as the second best planners and the best\nnon-portfolio planners in the cost optimal track, only 2 tasks behind the\nwinner. It uses a combination of different pattern generation algorithms to\nconstruct PDBs that are complementary to existing ones. As shown in the post\ncontest experiments, there is room for improvement. In this paper, we would\nlike to present our work on refining the PDB construction mechanism of CPC1. By\ntesting on IPC 2018 benchmarks, the results show that a significant improvement\nis made on our modified planner over the original version.",
      "tldr_zh": "该论文针对Pattern Database (PDB)启发式生成技术进行了改进，焦点在于优化Complementary 1 (CPC1)规划器的PDB构建机制。CPC1原先通过结合多种模式生成算法构建互补PDB，并在International Planning Competition (IPC) 2018中表现突出，但存在提升空间。作者通过测试和精炼PDB构建过程，在IPC 2018基准任务上实现了显著改进，使修改后的规划器性能优于原版。总的来说，此工作增强了PDB在规划任务中的效率和准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09297v1",
      "published_date": "2024-10-11 23:06:29 UTC",
      "updated_date": "2024-10-11 23:06:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:04:23.856120"
    },
    {
      "arxiv_id": "2410.09295v2",
      "title": "Natural Language Counterfactual Explanations for Graphs Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Flavio Giorgi",
        "Cesare Campagnano",
        "Fabrizio Silvestri",
        "Gabriele Tolomei"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a critical area of\nresearch to unravel the opaque inner logic of (deep) machine learning models.\nAmong the various XAI techniques proposed in the literature, counterfactual\nexplanations stand out as one of the most promising approaches. However, these\n\"what-if\" explanations are frequently complex and technical, making them\ndifficult for non-experts to understand and, more broadly, challenging for\nhumans to interpret. To bridge this gap, in this work, we exploit the power of\nopen-source Large Language Models to generate natural language explanations\nwhen prompted with valid counterfactual instances produced by state-of-the-art\nexplainers for graph-based models. Experiments across several graph datasets\nand counterfactual explainers show that our approach effectively produces\naccurate natural language representations of counterfactual instances, as\ndemonstrated by key performance metrics.",
      "tldr_zh": "该研究旨在解决反事实解释(Counterfactual Explanations)在Explainable Artificial Intelligence (XAI)领域的复杂性和可解释性问题，特别是针对图-based模型。作者提出了一种方法，利用开源Large Language Models (LLMs)来将由现有解释器生成的有效反事实实例转化为自然语言解释，从而使这些解释更易于非专家理解。通过在多个图数据集和反事实解释器上的实验，证明了该方法能准确生成高质量的自然语言表示，提升了XAI的可访问性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09295v2",
      "published_date": "2024-10-11 23:06:07 UTC",
      "updated_date": "2025-01-27 13:30:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:04:35.966047"
    },
    {
      "arxiv_id": "2410.09290v1",
      "title": "Ranking over Regression for Bayesian Optimization and Molecule Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Gary Tom",
        "Stanley Lo",
        "Samantha Corapi",
        "Alan Aspuru-Guzik",
        "Benjamin Sanchez-Lengeling"
      ],
      "abstract": "Bayesian optimization (BO) has become an indispensable tool for autonomous\ndecision-making across diverse applications from autonomous vehicle control to\naccelerated drug and materials discovery. With the growing interest in\nself-driving laboratories, BO of chemical systems is crucial for machine\nlearning (ML) guided experimental planning. Typically, BO employs a regression\nsurrogate model to predict the distribution of unseen parts of the search\nspace. However, for the selection of molecules, picking the top candidates with\nrespect to a distribution, the relative ordering of their properties may be\nmore important than their exact values. In this paper, we introduce Rank-based\nBayesian Optimization (RBO), which utilizes a ranking model as the surrogate.\nWe present a comprehensive investigation of RBO's optimization performance\ncompared to conventional BO on various chemical datasets. Our results\ndemonstrate similar or improved optimization performance using ranking models,\nparticularly for datasets with rough structure-property landscapes and activity\ncliffs. Furthermore, we observe a high correlation between the surrogate\nranking ability and BO performance, and this ability is maintained even at\nearly iterations of BO optimization when using ranking surrogate models. We\nconclude that RBO is an effective alternative to regression-based BO,\nespecially for optimizing novel chemical compounds.",
      "tldr_zh": "这篇论文提出了一种基于排名的 Bayesian Optimization (BO) 方法，称为 Rank-based Bayesian Optimization (RBO)，以取代传统的回归代理模型，用于分子选择任务。这种方法强调分子属性的相对排序而非精确值，尤其适用于化学系统优化。实验结果显示，RBO 在各种化学数据集上表现出与传统 BO 相当或更好的优化性能，特别是在结构-属性景观粗糙或存在 activity cliffs 的场景中。总体而言，RBO 通过保持排序能力的稳定性，即使在优化早期迭代中，也为机器学习指导的化学化合物优化提供了有效替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "14 + 4 pages, 5 + 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09290v1",
      "published_date": "2024-10-11 22:38:14 UTC",
      "updated_date": "2024-10-11 22:38:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:04:48.455024"
    },
    {
      "arxiv_id": "2410.09289v2",
      "title": "Multimodal Audio-based Disease Prediction with Transformer-based Hierarchical Fusion Network",
      "title_zh": "翻译失败",
      "authors": [
        "Jinjin Cai",
        "Ruiqi Wang",
        "Dezhong Zhao",
        "Ziqin Yuan",
        "Victoria McKenna",
        "Aaron Friedman",
        "Rachel Foot",
        "Susan Storey",
        "Ryan Boente",
        "Sudip Vhaduri",
        "Byung-Cheol Min"
      ],
      "abstract": "Audio-based disease prediction is emerging as a promising supplement to\ntraditional medical diagnosis methods, facilitating early, convenient, and\nnon-invasive disease detection and prevention. Multimodal fusion, which\nintegrates features from various domains within or across bio-acoustic\nmodalities, has proven effective in enhancing diagnostic performance. However,\nmost existing methods in the field employ unilateral fusion strategies that\nfocus solely on either intra-modal or inter-modal fusion. This approach limits\nthe full exploitation of the complementary nature of diverse acoustic feature\ndomains and bio-acoustic modalities. Additionally, the inadequate and isolated\nexploration of latent dependencies within modality-specific and modality-shared\nspaces curtails their capacity to manage the inherent heterogeneity in\nmultimodal data. To fill these gaps, we propose a transformer-based\nhierarchical fusion network designed for general multimodal audio-based disease\nprediction. Specifically, we seamlessly integrate intra-modal and inter-modal\nfusion in a hierarchical manner and proficiently encode the necessary\nintra-modal and inter-modal complementary correlations, respectively.\nComprehensive experiments demonstrate that our model achieves state-of-the-art\nperformance in predicting three diseases: COVID-19, Parkinson's disease, and\npathological dysarthria, showcasing its promising potential in a broad context\nof audio-based disease prediction tasks. Additionally, extensive ablation\nstudies and qualitative analyses highlight the significant benefits of each\nmain component within our model.",
      "tldr_zh": "该研究针对多模态音频-based疾病预测的局限性，提出了一种基于Transformer的hierarchical fusion network，以无缝整合intra-modal和inter-modal融合，高效编码不同模态间的互补相关性。相比现有单向融合策略，该方法更全面地利用音频特征的多样性，提升了诊断准确性。实验结果显示，该模型在预测COVID-19、Parkinson's disease和病理性dysarthria方面达到了state-of-the-art性能，并通过消融研究和定性分析证明了各组件的显著益处。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09289v2",
      "published_date": "2024-10-11 22:37:52 UTC",
      "updated_date": "2024-12-14 19:08:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:05:01.004005"
    },
    {
      "arxiv_id": "2410.09286v1",
      "title": "Language-Model-Assisted Bi-Level Programming for Reward Learning from Internet Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Harsh Mahesheka",
        "Zhixian Xie",
        "Zhaoran Wang",
        "Wanxin Jin"
      ],
      "abstract": "Learning from Demonstrations, particularly from biological experts like\nhumans and animals, often encounters significant data acquisition challenges.\nWhile recent approaches leverage internet videos for learning, they require\ncomplex, task-specific pipelines to extract and retarget motion data for the\nagent. In this work, we introduce a language-model-assisted bi-level\nprogramming framework that enables a reinforcement learning agent to directly\nlearn its reward from internet videos, bypassing dedicated data preparation.\nThe framework includes two levels: an upper level where a vision-language model\n(VLM) provides feedback by comparing the learner's behavior with expert videos,\nand a lower level where a large language model (LLM) translates this feedback\ninto reward updates. The VLM and LLM collaborate within this bi-level\nframework, using a \"chain rule\" approach to derive a valid search direction for\nreward learning. We validate the method for reward learning from YouTube\nvideos, and the results have shown that the proposed method enables efficient\nreward design from expert videos of biological agents for complex behavior\nsynthesis.",
      "tldr_zh": "该论文提出了一种Language-Model-Assisted Bi-Level Programming框架，帮助强化学习代理从互联网视频中直接学习奖励，从而避免了传统的复杂数据提取和重定向过程。框架包括上层VLM（视觉语言模型）通过比较学习者行为与专家视频提供反馈，以及下层LLM（大型语言模型）将反馈转化为奖励更新，并采用“链式规则”方法优化奖励学习的搜索方向。实验验证显示，该方法能高效从YouTube视频中设计奖励，支持复杂行为的合成。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09286v1",
      "published_date": "2024-10-11 22:31:39 UTC",
      "updated_date": "2024-10-11 22:31:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:05:12.532831"
    },
    {
      "arxiv_id": "2410.09275v1",
      "title": "Articulated Animal AI: An Environment for Animal-like Cognition in a Limbed Agent",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremy Lucas",
        "Isabeau Prémont-Schwarz"
      ],
      "abstract": "This paper presents the Articulated Animal AI Environment for Animal\nCognition, an enhanced version of the previous AnimalAI Environment. Key\nimprovements include the addition of agent limbs, enabling more complex\nbehaviors and interactions with the environment that closely resemble real\nanimal movements. The testbench features an integrated curriculum training\nsequence and evaluation tools, eliminating the need for users to develop their\nown training programs. Additionally, the tests and training procedures are\nrandomized, which will improve the agent's generalization capabilities. These\nadvancements significantly expand upon the original AnimalAI framework and will\nbe used to evaluate agents on various aspects of animal cognition.",
      "tldr_zh": "本文介绍了 Articulated Animal AI Environment for Animal Cognition，这是一个增强版的 AnimalAI Environment，通过添加 agent limbs 使代理能够执行更复杂的行为和环境互动，模拟真实动物的动作。 该环境集成了 curriculum training sequence 和评估工具，并实现了测试与训练的随机化，以提升代理的泛化能力。 这些改进扩展了原框架的功能，有助于评估代理在各种动物认知方面的表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, accepted to Workshop on Open-World Agents (OWA-2024) at\n  NeurIPS 2024 in Vancouver, Canada",
      "pdf_url": "http://arxiv.org/pdf/2410.09275v1",
      "published_date": "2024-10-11 21:55:23 UTC",
      "updated_date": "2024-10-11 21:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:05:23.690940"
    },
    {
      "arxiv_id": "2410.11886v1",
      "title": "Are Grid Cells Hexagonal for Performance or by Convenience?",
      "title_zh": "翻译失败",
      "authors": [
        "Taahaa Mir",
        "Peipei Yao",
        "Kateri Duranceau",
        "Isabeau Prémont-Schwarz"
      ],
      "abstract": "This paper investigates whether the hexagonal structure of grid cells\nprovides any performance benefits or if it merely represents a biologically\nconvenient configuration. Utilizing the Vector-HaSH content addressable memory\nmodel as a model of the grid cell -- place cell network of the mammalian brain,\nwe compare the performance of square and hexagonal grid cells in tasks of\nstoring and retrieving spatial memories. Our experiments across different path\ntypes, path lengths and grid configurations, reveal that hexagonal grid cells\nperform similarly to square grid cells with respect to spatial representation\nand memory recall. Our results show comparable accuracy and robustness across\ndifferent datasets and noise levels on images to recall. These findings suggest\nthat the brain's use of hexagonal grids may be more a matter of biological\nconvenience and ease of implementation rather than because they provide\nsuperior performance over square grid cells (which are easier to implement in\nsilico).",
      "tldr_zh": "本论文探讨网格细胞(grid cells)的六角形结构是否提供性能优势，还是仅为生物便利配置。研究利用 Vector-HaSH 模型模拟大脑的网格细胞和位置细胞网络，对六角形和方形网格细胞在存储和检索空间记忆任务中的性能进行比较。实验涵盖不同路径类型、长度和网格配置，结果显示两者在空间表示、记忆召回准确性和鲁棒性方面表现相似，即使在各种数据集和噪声水平下。总体而言，这些发现表明大脑采用六角形网格可能更多是生物便利性而非性能优越的原因。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "q-bio.NC",
      "comment": "5 pages, accepted at Montreal AI and Neuroscience Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.11886v1",
      "published_date": "2024-10-11 21:45:49 UTC",
      "updated_date": "2024-10-11 21:45:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:05:36.675124"
    },
    {
      "arxiv_id": "2410.09268v1",
      "title": "One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Anastasiia Birillo",
        "Elizaveta Artser",
        "Anna Potriasaeva",
        "Ilya Vlasov",
        "Katsiaryna Dzialets",
        "Yaroslav Golubev",
        "Igor Gerasimov",
        "Hieke Keuning",
        "Timofey Bryksin"
      ],
      "abstract": "Students often struggle with solving programming problems when learning to\ncode, especially when they have to do it online, with one of the most common\ndisadvantages of working online being the lack of personalized help. This help\ncan be provided as next-step hint generation, i.e., showing a student what\nspecific small step they need to do next to get to the correct solution. There\nare many ways to generate such hints, with large language models (LLMs) being\namong the most actively studied right now.\n  While LLMs constitute a promising technology for providing personalized help,\ncombining them with other techniques, such as static analysis, can\nsignificantly improve the output quality. In this work, we utilize this idea\nand propose a novel system to provide both textual and code hints for\nprogramming tasks. The pipeline of the proposed approach uses a\nchain-of-thought prompting technique and consists of three distinct steps: (1)\ngenerating subgoals - a list of actions to proceed with the task from the\ncurrent student's solution, (2) generating the code to achieve the next\nsubgoal, and (3) generating the text to describe this needed action. During the\nsecond step, we apply static analysis to the generated code to control its size\nand quality. The tool is implemented as a modification to the open-source\nJetBrains Academy plugin, supporting students in their in-IDE courses.\n  To evaluate our approach, we propose a list of criteria for all steps in our\npipeline and conduct two rounds of expert validation. Finally, we evaluate the\nnext-step hints in a classroom with 14 students from two universities. Our\nresults show that both forms of the hints - textual and code - were helpful for\nthe students, and the proposed system helped them to proceed with the coding\ntasks.",
      "tldr_zh": "本研究针对学生在线学习编程时缺乏个性化帮助的问题，提出了一种结合大型语言模型(LLMs)和静态分析的系统，用于生成编程任务的下一步提示，包括文本和代码形式。该系统采用链式思维提示(chain-of-thought)流程，分为三步：生成子目标列表、利用静态分析控制代码质量和大小来实现下一个子目标，以及生成描述性文本。该方法已整合到JetBrains Academy插件中，并通过专家验证和课堂测试（涉及14名学生）证明，生成的提示有效帮助学生推进编程任务。实验结果显示，该系统显著提升了学生的任务完成效率，为在线编程教育提供了可扩展的辅助工具。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09268v1",
      "published_date": "2024-10-11 21:41:57 UTC",
      "updated_date": "2024-10-11 21:41:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:05:47.978992"
    },
    {
      "arxiv_id": "2410.09252v1",
      "title": "ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Minh Pham Dinh",
        "Munira Syed",
        "Michael G Yankoski",
        "Trenton W. Ford"
      ],
      "abstract": "Planning and performing interactive tasks, such as conducting experiments to\ndetermine the melting point of an unknown substance, is straightforward for\nhumans but poses significant challenges for autonomous agents. We introduce\nReasonPlanner, a novel generalist agent designed for reflective thinking,\nplanning, and interactive reasoning. This agent leverages LLMs to plan\nhypothetical trajectories by building a World Model based on a Temporal\nKnowledge Graph. The agent interacts with the environment using a natural\nlanguage actor-critic module, where the actor translates the imagined\ntrajectory into a sequence of actionable steps, and the critic determines if\nreplanning is necessary. ReasonPlanner significantly outperforms previous\nstate-of-the-art prompting-based methods on the ScienceWorld benchmark by more\nthan 1.8 times, while being more sample-efficient and interpretable. It relies\nsolely on frozen weights thus requiring no gradient updates. ReasonPlanner can\nbe deployed and utilized without specialized knowledge of Machine Learning,\nmaking it accessible to a wide range of users.",
      "tldr_zh": "该论文提出ReasonPlanner，一种通用代理，用于提升动态环境中的自主规划能力，通过Temporal Knowledge Graphs构建世界模型并结合LLMs进行假设轨迹规划。代理采用自然语言的actor-critic模块，将规划轨迹转化为可执行步骤，同时critic模块评估是否需要重新规划。实验结果显示，ReasonPlanner在ScienceWorld基准上比现有方法性能提升1.8倍以上，且更高效、可解释，仅依赖冻结权重，无需梯度更新，便于非专业用户部署。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09252v1",
      "published_date": "2024-10-11 20:58:51 UTC",
      "updated_date": "2024-10-11 20:58:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:06:00.469791"
    },
    {
      "arxiv_id": "2410.12860v1",
      "title": "LLMD: A Large Language Model for Interpreting Longitudinal Medical Records",
      "title_zh": "LLMD：用于解读纵向医疗记录的大型语言模型",
      "authors": [
        "Robert Porter",
        "Adam Diehl",
        "Benjamin Pastel",
        "J. Henry Hinnefeld",
        "Lawson Nerenberg",
        "Pye Maung",
        "Sebastien Kerbrat",
        "Gillian Hanson",
        "Troy Astorino",
        "Stephen J. Tarsa"
      ],
      "abstract": "We introduce LLMD, a large language model designed to analyze a patient's\nmedical history based on their medical records. Along with domain knowledge,\nLLMD is trained on a large corpus of records collected over time and across\nfacilities, as well as tasks and labels that make nuanced connections among\nthem. This approach is critical to an accurate picture of patient health, and\nhas distinctive advantages over models trained on knowledge alone, unlabeled\nrecords, structured EHR data, or records from a single health system.\n  The recipe for LLMD continues pretraining a foundational model on both domain\nknowledge and the contents of millions of records. These span an average of 10\nyears of care and as many as 140 care sites per patient. LLMD is then\ninstruction fine-tuned on structuring and abstraction tasks. The former jointly\nidentify and normalize document metadata, provenance information, clinical\nnamed-entities, and ontology mappings, while the latter roll these into\nhigher-level representations, such a continuous era of time a patient was on a\nmedication. LLMD is deployed within a layered validation system that includes\ncontinual random audits and review by experts, e.g. based on uncertainty,\ndisease-specific rules, or use-case.\n  LLMD exhibits large gains over both more-powerful generalized models and\ndomain-specific models. On medical knowledge benchmarks, LLMD-8B achieves state\nof the art accuracy on PubMedQA text responses, besting orders-of-magnitude\nlarger models. On production tasks, we show that LLMD significantly outperforms\nall other models evaluated, and among alternatives, large general purpose LLMs\nlike GPT-4o are more accurate than models emphasizing medical knowledge. We\nfind strong evidence that accuracy on today's medical benchmarks is not the\nmost significant factor when analyzing real-world patient data, an insight with\nimplications for future medical LLMs.'",
      "tldr_zh": "该研究引入了 LLMD，一种大型语言模型（Large Language Model），专门用于分析患者的纵向医疗记录，通过整合领域知识和数百万条跨设施记录来构建患者健康的全景图。LLMD 的训练过程包括在海量数据上预训练，然后进行指令微调，以处理结构化任务（如识别临床实体和本体映射）和抽象任务（如总结药物使用时期）。实验结果显示，LLMD-8B 在 PubMedQA 等医疗知识基准上超越了更大规模模型，并在实际生产任务中显著优于其他模型，包括大通用 LLM 如 GPT-4o。研究强调，在真实世界患者数据分析中，模型的实际准确性比基准测试表现更具影响力，为未来医疗 LLM 的发展提供了重要启示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12860v1",
      "published_date": "2024-10-11 20:55:51 UTC",
      "updated_date": "2024-10-11 20:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:06:13.207857"
    },
    {
      "arxiv_id": "2410.09250v1",
      "title": "Quantum-Trained Convolutional Neural Network for Deepfake Audio Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Chu-Hsuan Abraham Lin",
        "Chen-Yu Liu",
        "Samuel Yen-Chi Chen",
        "Kuan-Cheng Chen"
      ],
      "abstract": "The rise of deepfake technologies has posed significant challenges to\nprivacy, security, and information integrity, particularly in audio and\nmultimedia content. This paper introduces a Quantum-Trained Convolutional\nNeural Network (QT-CNN) framework designed to enhance the detection of deepfake\naudio, leveraging the computational power of quantum machine learning (QML).\nThe QT-CNN employs a hybrid quantum-classical approach, integrating Quantum\nNeural Networks (QNNs) with classical neural architectures to optimize training\nefficiency while reducing the number of trainable parameters. Our method\nincorporates a novel quantum-to-classical parameter mapping that effectively\nutilizes quantum states to enhance the expressive power of the model, achieving\nup to 70% parameter reduction compared to classical models without compromising\naccuracy. Data pre-processing involved extracting essential audio features,\nlabel encoding, feature scaling, and constructing sequential datasets for\nrobust model evaluation. Experimental results demonstrate that the QT-CNN\nachieves comparable performance to traditional CNNs, maintaining high accuracy\nduring training and testing phases across varying configurations of QNN blocks.\nThe QT framework's ability to reduce computational overhead while maintaining\nperformance underscores its potential for real-world applications in deepfake\ndetection and other resource-constrained scenarios. This work highlights the\npractical benefits of integrating quantum computing into artificial\nintelligence, offering a scalable and efficient approach to advancing deepfake\ndetection technologies.",
      "tldr_zh": "本研究提出了一种 Quantum-Trained Convolutional Neural Network (QT-CNN) 框架，用于提升 deepfake 音频检测的性能，通过整合 Quantum Neural Networks (QNNs) 与经典神经网络的混合量子-经典方法。QT-CNN 采用创新的量子到经典参数映射，优化训练效率并减少可训练参数高达 70%，同时保持模型的表达能力和准确性。实验结果显示，该框架在音频特征提取和数据预处理后，与传统 CNN 相比表现出类似的高准确率，并显著降低计算开销，为资源受限的真实场景中 deepfake 检测提供可扩展的解决方案。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS",
        "quant-ph"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09250v1",
      "published_date": "2024-10-11 20:52:10 UTC",
      "updated_date": "2024-10-11 20:52:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:06:24.218723"
    },
    {
      "arxiv_id": "2410.09247v1",
      "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
      "title_zh": "翻译失败",
      "authors": [
        "Jacob Haimes",
        "Cenny Wenner",
        "Kunvar Thaman",
        "Vassil Tashev",
        "Clement Neo",
        "Esben Kran",
        "Jason Schreiber"
      ],
      "abstract": "The training data for many Large Language Models (LLMs) is contaminated with\ntest data. This means that public benchmarks used to assess LLMs are\ncompromised, suggesting a performance gap between benchmark scores and actual\ncapabilities. Ideally, a private holdout set could be used to accurately verify\nscores. Unfortunately, such datasets do not exist for most benchmarks, and\npost-hoc construction of sufficiently similar datasets is non-trivial. To\naddress these issues, we introduce a systematic methodology for (i)\nretrospectively constructing a holdout dataset for a target dataset, (ii)\ndemonstrating the statistical indistinguishability of this retro-holdout\ndataset, and (iii) comparing LLMs on the two datasets to quantify the\nperformance gap due to the dataset's public availability. Applying these\nmethods to TruthfulQA, we construct and release Retro-Misconceptions, on which\nwe evaluate twenty LLMs and find that some have inflated scores by as much as\n16 percentage points. Our results demonstrate that public benchmark scores do\nnot always accurately assess model properties, and underscore the importance of\nimproved data practices in the field.",
      "tldr_zh": "该论文揭示了大型语言模型（LLMs）的训练数据常被测试数据污染，导致公共基准测试分数不可靠，并夸大了模型的实际性能。研究团队提出了一种系统方法，包括回顾性地构建统计上相似的 holdout 数据集（Retro-Holdouts），并通过比较模型在原数据集和新数据集上的表现来量化性能差距。在 TruthfulQA 数据集的应用中，他们创建并发布了 Retro-Misconceptions 数据集，结果显示某些 LLMs 的分数被夸大多达 16 个百分点，这突显了改进数据实践以确保基准测试准确性的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09247v1",
      "published_date": "2024-10-11 20:46:56 UTC",
      "updated_date": "2024-10-11 20:46:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:06:36.820855"
    },
    {
      "arxiv_id": "2410.09246v1",
      "title": "DFM: Interpolant-free Dual Flow Matching",
      "title_zh": "DFM：无插值双流匹配",
      "authors": [
        "Denis Gudovskiy",
        "Tomoyuki Okuno",
        "Yohei Nakata"
      ],
      "abstract": "Continuous normalizing flows (CNFs) can model data distributions with\nexpressive infinite-length architectures. But this modeling involves\ncomputationally expensive process of solving an ordinary differential equation\n(ODE) during maximum likelihood training. Recently proposed flow matching (FM)\nframework allows to substantially simplify the training phase using a\nregression objective with the interpolated forward vector field. In this paper,\nwe propose an interpolant-free dual flow matching (DFM) approach without\nexplicit assumptions about the modeled vector field. DFM optimizes the forward\nand, additionally, a reverse vector field model using a novel objective that\nfacilitates bijectivity of the forward and reverse transformations. Our\nexperiments with the SMAP unsupervised anomaly detection show advantages of DFM\nwhen compared to the CNF trained with either maximum likelihood or FM\nobjectives with the state-of-the-art performance metrics.",
      "tldr_zh": "本论文提出了一种无需插值的双向流匹配方法（DFM），旨在简化连续归一化流（CNFs）的训练过程，避免了传统方法中求解普通微分方程（ODE）的计算开销。DFM 通过优化前向和反向向量场，并使用一个新颖的目标函数来确保变换的双射性，从而提升模型的建模能力。在 SMAP 无监督异常检测任务上，实验结果显示 DFM 优于基于最大似然或流匹配（FM）目标训练的 CNF，达到了最先进性能水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Extended Abstract Track at the Unifying Representations in Neural\n  Models Workshop (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.09246v1",
      "published_date": "2024-10-11 20:46:04 UTC",
      "updated_date": "2024-10-11 20:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:06:48.915313"
    },
    {
      "arxiv_id": "2410.09244v1",
      "title": "Using off-the-shelf LLMs to query enterprise data by progressively revealing ontologies",
      "title_zh": "翻译失败",
      "authors": [
        "C. Civili",
        "E. Sherkhonov",
        "R. E. K. Stirewalt"
      ],
      "abstract": "Ontologies are known to improve the accuracy of Large Language Models (LLMs)\nwhen translating natural language queries into a formal query language like SQL\nor SPARQL. There are two ways to leverage ontologies when working with LLMs.\nOne is to fine-tune the model, i.e., to enhance it with specific domain\nknowledge. Another is the zero-shot prompting approach, where the ontology is\nprovided as part of the input question. Unfortunately, modern enterprises\ntypically have ontologies that are too large to fit in a prompt due to LLM's\ntoken size limitations. We present a solution that incrementally reveals \"just\nenough\" of an ontology that is needed to answer a given question.",
      "tldr_zh": "该论文探讨了如何利用现成的大型语言模型（LLMs）查询企业数据的问题，提出通过逐步揭示本体（ontologies）的方法来克服提示 token 限制。传统方法包括微调模型或零-shot 提示，但企业本体通常过大无法直接纳入，因此该方案仅提供回答问题所需的“刚好足够”本体部分。该方法提高了 LLMs 将自然语言查询转化为 SQL 或 SPARQL 等正式查询语言的准确性，提供了一种高效、可扩展的零-shot 解决方案。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.09244v1",
      "published_date": "2024-10-11 20:41:04 UTC",
      "updated_date": "2024-10-11 20:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:07:00.036097"
    },
    {
      "arxiv_id": "2410.21287v1",
      "title": "A Systematic Assessment of OpenAI o1-Preview for Higher Order Thinking in Education",
      "title_zh": "翻译失败",
      "authors": [
        "Ehsan Latif",
        "Yifan Zhou",
        "Shuchen Guo",
        "Yizhu Gao",
        "Lehong Shi",
        "Matthew Nayaaba",
        "Gyeonggeon Lee",
        "Liang Zhang",
        "Arne Bewersdorff",
        "Luyang Fang",
        "Xiantong Yang",
        "Huaqin Zhao",
        "Hanqi Jiang",
        "Haoran Lu",
        "Jiaxi Li",
        "Jichao Yu",
        "Weihang You",
        "Zhengliang Liu",
        "Vincent Shung Liu",
        "Hui Wang",
        "Zihao Wu",
        "Jin Lu",
        "Fei Dou",
        "Ping Ma",
        "Ninghao Liu",
        "Tianming Liu",
        "Xiaoming Zhai"
      ],
      "abstract": "As artificial intelligence (AI) continues to advance, it demonstrates\ncapabilities comparable to human intelligence, with significant potential to\ntransform education and workforce development. This study evaluates OpenAI\no1-preview's ability to perform higher-order cognitive tasks across 14\ndimensions, including critical thinking, systems thinking, computational\nthinking, design thinking, metacognition, data literacy, creative thinking,\nabstract reasoning, quantitative reasoning, logical reasoning, analogical\nreasoning, and scientific reasoning. We used validated instruments like the\nEnnis-Weir Critical Thinking Essay Test and the Biological Systems Thinking\nTest to compare the o1-preview's performance with human performance\nsystematically. Our findings reveal that o1-preview outperforms humans in most\ncategories, achieving 150% better results in systems thinking, computational\nthinking, data literacy, creative thinking, scientific reasoning, and abstract\nreasoning. However, compared to humans, it underperforms by around 25% in\nlogical reasoning, critical thinking, and quantitative reasoning. In analogical\nreasoning, both o1-preview and humans achieved perfect scores. Despite these\nstrengths, the o1-preview shows limitations in abstract reasoning, where human\npsychology students outperform it, highlighting the continued importance of\nhuman oversight in tasks requiring high-level abstraction. These results have\nsignificant educational implications, suggesting a shift toward developing\nhuman skills that complement AI, such as creativity, abstract reasoning, and\ncritical thinking. This study emphasizes the transformative potential of AI in\neducation and calls for a recalibration of educational goals, teaching methods,\nand curricula to align with an AI-driven world.",
      "tldr_zh": "这篇论文系统评估了 OpenAI o1-preview 在教育中处理高阶认知任务的能力，涵盖 14 个维度，包括 critical thinking、systems thinking 和 computational thinking 等。研究采用验证工具（如 Ennis-Weir Critical Thinking Essay Test）比较 AI 与人类的表现，发现 o1-preview 在 systems thinking、data literacy 和 creative thinking 等多数类别中表现优于人类（某些方面高出 150%），但在 logical reasoning 和 critical thinking 中落后约 25%。这些结果突显 AI 在教育中的变革潜力，并呼吁调整教学方法和课程，以强化人类的 abstract reasoning 和批判性技能。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "An assessment of OpenAI o1-Preview for Higher Order Thinking in\n  Education",
      "pdf_url": "http://arxiv.org/pdf/2410.21287v1",
      "published_date": "2024-10-11 20:30:16 UTC",
      "updated_date": "2024-10-11 20:30:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:07:12.512864"
    },
    {
      "arxiv_id": "2410.09230v3",
      "title": "Improving Semantic Understanding in Speech Language Models via Brain-tuning",
      "title_zh": "通过 Brain-tuning 改善语音语言模型中的语义理解",
      "authors": [
        "Omer Moussa",
        "Dietrich Klakow",
        "Mariya Toneva"
      ],
      "abstract": "Speech language models align with human brain responses to natural language\nto an impressive degree. However, current models rely heavily on low-level\nspeech features, indicating they lack brain-relevant semantics which limits\ntheir utility as model organisms of semantic processing in the brain. In this\nwork, we address this limitation by inducing brain-relevant bias directly into\nthe models via fine-tuning with fMRI recordings of people listening to natural\nstories, a process we name brain-tuning. After testing it on 3 different\npretrained model families, we show that brain-tuning not only improves overall\nalignment with new brain recordings in semantic language regions, but also\nreduces the reliance on low-level speech features for this alignment.\nExcitingly, we further show that brain-tuning leads to 1) consistent\nimprovements in performance on a range of downstream tasks and 2) a\nrepresentational space with increased semantic preference. Our results provide\nconverging evidence, for the first time, that incorporating brain signals into\nthe training of language models improves the models' semantic understanding.",
      "tldr_zh": "这篇论文提出了一种名为 brain-tuning 的方法，通过使用 fMRI 记录（人们听自然故事时的脑部扫描数据）对语音语言模型进行微调，以提升其语义理解并减少对低级语音特征的依赖。实验在 3 个不同预训练模型家族上进行，结果显示 brain-tuning 不仅提高了模型与大脑语义区域的新记录的对齐度，还改善了下游任务的性能。更为重要的是，这种方法增强了模型的表示空间，使其更偏向语义处理。该研究首次提供了证据，证明将脑信号整合到语言模型训练中能显著提升语义理解能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.09230v3",
      "published_date": "2024-10-11 20:06:21 UTC",
      "updated_date": "2025-03-04 15:26:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:07:25.180731"
    },
    {
      "arxiv_id": "2410.09223v1",
      "title": "The Same But Different: Structural Similarities and Differences in Multilingual Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Ruochen Zhang",
        "Qinan Yu",
        "Matianyu Zang",
        "Carsten Eickhoff",
        "Ellie Pavlick"
      ],
      "abstract": "We employ new tools from mechanistic interpretability in order to ask whether\nthe internal structure of large language models (LLMs) shows correspondence to\nthe linguistic structures which underlie the languages on which they are\ntrained. In particular, we ask (1) when two languages employ the same\nmorphosyntactic processes, do LLMs handle them using shared internal circuitry?\nand (2) when two languages require different morphosyntactic processes, do LLMs\nhandle them using different internal circuitry? Using English and Chinese\nmultilingual and monolingual models, we analyze the internal circuitry involved\nin two tasks. We find evidence that models employ the same circuit to handle\nthe same syntactic process independently of the language in which it occurs,\nand that this is the case even for monolingual models trained completely\nindependently. Moreover, we show that multilingual models employ\nlanguage-specific components (attention heads and feed-forward networks) when\nneeded to handle linguistic processes (e.g., morphological marking) that only\nexist in some languages. Together, our results provide new insights into how\nLLMs trade off between exploiting common structures and preserving linguistic\ndifferences when tasked with modeling multiple languages simultaneously.",
      "tldr_zh": "本研究使用 mechanistic interpretability 工具，探究大型语言模型 (LLMs) 的内部 circuits 是否对应于训练语言的语言结构，特别是比较相同或不同 morphosyntactic processes 在英语和中文模型中的处理方式。研究发现，LLMs 采用相同的 circuits 处理相同句法过程，无论语言如何，甚至在 monolingual models 中也适用。同时，多语言模型会使用语言特定的 attention heads 和 feed-forward networks 来处理某些语言独有的过程，如形态标记。总体而言，这些结果揭示了 LLMs 在建模多种语言时，如何平衡共同结构与语言差异的权衡。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09223v1",
      "published_date": "2024-10-11 19:57:55 UTC",
      "updated_date": "2024-10-11 19:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:07:38.334017"
    },
    {
      "arxiv_id": "2410.22340v1",
      "title": "Testing GPT-4-o1-preview on math and science problems: A follow-up study",
      "title_zh": "翻译失败",
      "authors": [
        "Ernest Davis"
      ],
      "abstract": "In August 2023, Scott Aaronson and I reported the results of testing GPT4\nwith the Wolfram Alpha and Code Interpreter plug-ins over a collection of 105\noriginal high-school level and college-level science and math problems (Davis\nand Aaronson, 2023). In September 2024, I tested the recently released model\nGPT-4o1-preview on the same collection. Overall I found that performance had\nsignificantly improved, but was still considerably short of perfect. In\nparticular, problems that involve spatial reasoning are often stumbling blocks.",
      "tldr_zh": "这篇论文是对2023年Davis和Aaronson研究的后续，测试了新发布的GPT-4o1-preview模型在105个高中和大学水平的数学和科学问题上的表现。作者使用相同的测试集，发现该模型的整体性能比之前的GPT-4（带Wolfram Alpha和Code Interpreter插件）显著提升，但仍未达到完美。特别地，涉及spatial reasoning的空间推理问题往往是主要障碍，这突显了AI模型在特定领域改进的潜力及其局限性。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22340v1",
      "published_date": "2024-10-11 19:56:26 UTC",
      "updated_date": "2024-10-11 19:56:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:07:48.352766"
    },
    {
      "arxiv_id": "2410.09218v2",
      "title": "Continual Learning with Neuromorphic Computing: Theories, Methods, and Applications",
      "title_zh": "基于神经形态计算的持续学习：理论、方法和应用",
      "authors": [
        "Mishal Fatima Minhas",
        "Rachmad Vidya Wicaksana Putra",
        "Falah Awwad",
        "Osman Hasan",
        "Muhammad Shafique"
      ],
      "abstract": "To adapt to real-world dynamics, intelligent systems need to assimilate new\nknowledge without catastrophic forgetting, where learning new tasks leads to a\ndegradation in performance on old tasks. To address this, continual learning\nconcept is proposed for enabling autonomous systems to acquire new knowledge\nand dynamically adapt to changing environments. Specifically, energy-efficient\ncontinual learning is needed to ensure the functionality of autonomous systems\nunder tight compute and memory resource budgets (i.e., so-called autonomous\nembedded systems). Neuromorphic computing, with brain-inspired Spiking Neural\nNetworks (SNNs), offers inherent advantages for enabling low-power/energy\ncontinual learning in autonomous embedded systems. In this paper, we\ncomprehensively discuss the foundations and methods for enabling continual\nlearning in neural networks, then analyze the state-of-the-art works\nconsidering SNNs. Afterward, comparative analyses of existing methods are\nconducted while considering crucial design factors, such as network complexity,\nmemory, latency, and power/energy efficiency. We also explore the practical\napplications that can benefit from SNN-based continual learning and open\nchallenges in real-world scenarios. In this manner, our survey provides\nvaluable insights into the recent advancements of SNN-based continual learning\nfor real-world application use-cases.",
      "tldr_zh": "本论文探讨了持续学习（continual learning）在神经形态计算（Neuromorphic Computing）中的理论、方法和应用，旨在帮助智能系统适应动态环境而不发生灾难性遗忘（catastrophic forgetting）。论文强调了基于脉冲神经网络（Spiking Neural Networks, SNNs）的能量高效持续学习方法，以满足自治嵌入式系统的计算和内存资源限制。作者对现有方法进行了全面分析和比较，评估了网络复杂度、内存、延迟以及功耗/能效等因素，并讨论了SNNs在实际应用中的潜力以及面临的挑战，为真实场景中的持续学习提供宝贵见解。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "This work has been submitted to the IEEE Access for possible\n  publication",
      "pdf_url": "http://arxiv.org/pdf/2410.09218v2",
      "published_date": "2024-10-11 19:49:53 UTC",
      "updated_date": "2024-10-28 04:52:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:08:00.486860"
    },
    {
      "arxiv_id": "2410.12859v1",
      "title": "Enhancing Long Context Performance in LLMs Through Inner Loop Query Mechanism",
      "title_zh": "翻译失败",
      "authors": [
        "Yimin Tang",
        "Yurong Xu",
        "Ning Yan",
        "Masood Mortazavi"
      ],
      "abstract": "Transformers have a quadratic scaling of computational complexity with input\nsize, which limits the input context window size of large language models\n(LLMs) in both training and inference. Meanwhile, retrieval-augmented\ngeneration (RAG) besed models can better handle longer contexts by using a\nretrieval system to filter out unnecessary information. However, most RAG\nmethods only perform retrieval based on the initial query, which may not work\nwell with complex questions that require deeper reasoning. We introduce a novel\napproach, Inner Loop Memory Augmented Tree Retrieval (ILM-TR), involving\ninner-loop queries, based not only on the query question itself but also on\nintermediate findings. At inference time, our model retrieves information from\nthe RAG system, integrating data from lengthy documents at various levels of\nabstraction. Based on the information retrieved, the LLM generates texts stored\nin an area named Short-Term Memory (STM) which is then used to formulate the\nnext query. This retrieval process is repeated until the text in STM converged.\nOur experiments demonstrate that retrieval with STM offers improvements over\ntraditional retrieval-augmented LLMs, particularly in long context tests such\nas Multi-Needle In A Haystack (M-NIAH) and BABILong.",
      "tldr_zh": "这篇论文针对Transformer模型在处理长上下文时计算复杂度二次方增长的问题，提出了一种内循环查询机制Inner Loop Memory Augmented Tree Retrieval (ILM-TR)，以提升LLMs的性能。ILM-TR基于初始查询和中间发现进行多次检索，将信息存储在Short-Term Memory (STM)中，并重复过程直到STM内容收敛，从而更好地处理复杂问题和长文档。实验结果表明，该方法在M-NIAH和BABILong等长上下文测试中，比传统RAG-LLMs表现出显著改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12859v1",
      "published_date": "2024-10-11 19:49:05 UTC",
      "updated_date": "2024-10-11 19:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:08:12.203033"
    },
    {
      "arxiv_id": "2410.09207v1",
      "title": "P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains",
      "title_zh": "P-FOLIO：利用丰富的由人类编写的推理链评估和改进逻辑推理",
      "authors": [
        "Simeng Han",
        "Aaron Yu",
        "Rui Shen",
        "Zhenting Qi",
        "Martin Riddell",
        "Wenfei Zhou",
        "Yujie Qiao",
        "Yilun Zhao",
        "Semih Yavuz",
        "Ye Liu",
        "Shafiq Joty",
        "Yingbo Zhou",
        "Caiming Xiong",
        "Dragomir Radev",
        "Rex Ying",
        "Arman Cohan"
      ],
      "abstract": "Existing methods on understanding the capabilities of LLMs in logical\nreasoning rely on binary entailment classification or synthetically derived\nrationales, which are not sufficient for proper investigation of model's\ncapabilities. We present P-FOLIO, a human-annotated dataset consisting of\ndiverse and complex reasoning chains for a set of realistic logical reasoning\nstories also written by humans. P-FOLIO is collected with an annotation\nprotocol that facilitates humans to annotate well-structured natural language\nproofs for first-order logic reasoning problems in a step-by-step manner. The\nnumber of reasoning steps in P-FOLIO span from 0 to 20. We further use P-FOLIO\nto evaluate and improve large-language-model (LLM) reasoning capabilities. We\nevaluate LLM reasoning capabilities at a fine granularity via single-step\ninference rule classification, with more diverse inference rules of more\ndiverse and higher levels of complexities than previous works. Given that a\nsingle model-generated reasoning chain could take a completely different path\nthan the human-annotated one, we sample multiple reasoning chains from a model\nand use pass@k metrics for evaluating the quality of model-generated reasoning\nchains. We show that human-written reasoning chains significantly boost the\nlogical reasoning capabilities of LLMs via many-shot prompting and fine-tuning.\nFurthermore, fine-tuning Llama3-7B on P-FOLIO improves the model performance by\n10% or more on three other out-of-domain logical reasoning datasets. We also\nconduct detailed analysis to show where most powerful LLMs fall short in\nreasoning. We will release the dataset and code publicly.",
      "tldr_zh": "本研究引入了P-FOLIO数据集，该数据集由人类标注的多样化复杂推理链组成，用于评估和提升大型语言模型(LLMs)的逻辑推理能力，针对现实的逻辑推理问题。P-FOLIO通过一种逐步注解协议收集结构良好的自然语言证明，推理步骤从0到20不等，并采用细粒度的单步推理规则分类和pass@k指标来评估模型生成的推理链。结果显示，通过many-shot prompting和fine-tuning，人类书写的推理链显著提高了LLMs的性能，例如在P-FOLIO上fine-tuning的Llama3-7B模型在其他三个领域外数据集上性能提升10%以上；此外，分析揭示了当前强大LLMs在推理中的关键不足，并计划公开数据集和代码。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09207v1",
      "published_date": "2024-10-11 19:22:57 UTC",
      "updated_date": "2024-10-11 19:22:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:08:27.520042"
    },
    {
      "arxiv_id": "2410.09206v1",
      "title": "pyhgf: A neural network library for predictive coding",
      "title_zh": "pyhgf：用于预测编码的神经网络库",
      "authors": [
        "Nicolas Legrand",
        "Lilian Weber",
        "Peter Thestrup Waade",
        "Anna Hedvig Møller Daugaard",
        "Mojtaba Khodadadi",
        "Nace Mikuš",
        "Chris Mathys"
      ],
      "abstract": "Bayesian models of cognition have gained considerable traction in\ncomputational neuroscience and psychiatry. Their scopes are now expected to\nexpand rapidly to artificial intelligence, providing general inference\nframeworks to support embodied, adaptable, and energy-efficient autonomous\nagents. A central theory in this domain is predictive coding, which posits that\nlearning and behaviour are driven by hierarchical probabilistic inferences\nabout the causes of sensory inputs. Biological realism constrains these\nnetworks to rely on simple local computations in the form of precision-weighted\npredictions and prediction errors. This can make this framework highly\nefficient, but its implementation comes with unique challenges on the software\ndevelopment side. Embedding such models in standard neural network libraries\noften becomes limiting, as these libraries' compilation and differentiation\nbackends can force a conceptual separation between optimization algorithms and\nthe systems being optimized. This critically departs from other biological\nprinciples such as self-monitoring, self-organisation, cellular growth and\nfunctional plasticity. In this paper, we introduce \\texttt{pyhgf}: a Python\npackage backed by JAX and Rust for creating, manipulating and sampling dynamic\nnetworks for predictive coding. We improve over other frameworks by enclosing\nthe network components as transparent, modular and malleable variables in the\nmessage-passing steps. The resulting graphs can implement arbitrary\ncomputational complexities as beliefs propagation. But the transparency of core\nvariables can also translate into inference processes that leverage\nself-organisation principles, and express structure learning, meta-learning or\ncausal discovery as the consequence of network structural adaptation to\nsurprising inputs. The code, tutorials and documentation are hosted at:\nhttps://github.com/ilabcode/pyhgf.",
      "tldr_zh": "该论文介绍了 pyhgf，一种基于 JAX 和 Rust 的 Python 库，用于构建预测编码 (predictive coding) 神经网络模型。该库通过将网络组件设计为透明、可模块化和可塑的变量，支持动态消息传递和层次化概率推理，从而克服了传统神经网络库在优化算法与系统分离方面的限制。pyhgf 允许实现任意计算复杂性的信念传播 (beliefs propagation)，并促进自组织原则，如结构学习、元学习和因果发现，为 Bayesian 模型在人工智能中的应用提供更高效和生物现实的框架。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09206v1",
      "published_date": "2024-10-11 19:21:38 UTC",
      "updated_date": "2024-10-11 19:21:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:08:36.284896"
    },
    {
      "arxiv_id": "2410.09204v1",
      "title": "Encoding Agent Trajectories as Representations with Sequence Transformers",
      "title_zh": "使用",
      "authors": [
        "Athanasios Tsiligkaridis",
        "Nicholas Kalinowski",
        "Zhongheng Li",
        "Elizabeth Hou"
      ],
      "abstract": "Spatiotemporal data faces many analogous challenges to natural language text\nincluding the ordering of locations (words) in a sequence, long range\ndependencies between locations, and locations having multiple meanings. In this\nwork, we propose a novel model for representing high dimensional spatiotemporal\ntrajectories as sequences of discrete locations and encoding them with a\nTransformer-based neural network architecture. Similar to language models, our\nSequence Transformer for Agent Representation Encodings (STARE) model can learn\nrepresentations and structure in trajectory data through both supervisory tasks\n(e.g., classification), and self-supervisory tasks (e.g., masked modelling). We\npresent experimental results on various synthetic and real trajectory datasets\nand show that our proposed model can learn meaningful encodings that are useful\nfor many downstream tasks including discriminating between labels and\nindicating similarity between locations. Using these encodings, we also learn\nrelationships between agents and locations present in spatiotemporal data.",
      "tldr_zh": "本研究提出了一种名为 STARE 的模型，使用 Sequence Transformers 将高维空间时间轨迹表示为离散位置序列，并通过 Transformer-based neural network 架构进行编码。模型借鉴语言模型的方法，通过监督任务（如分类）和自监督任务（如 masked modelling）学习轨迹数据的表示、结构和长距离依赖关系。在各种合成和真实轨迹数据集上的实验表明，STARE 能生成有意义的编码，支持下游任务如标签区分、位置相似性判断，并揭示代理和位置之间的关系。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, to be presented at GeoAI workshop at ACM SigSpatial 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.09204v1",
      "published_date": "2024-10-11 19:18:47 UTC",
      "updated_date": "2024-10-11 19:18:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:08:48.890937"
    },
    {
      "arxiv_id": "2410.12858v1",
      "title": "Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis",
      "title_zh": "大语言模型用于医疗 OSCE 评估：一种新颖的转录文本分析方法",
      "authors": [
        "Ameer Hamza Shakur",
        "Michael J. Holcomb",
        "David Hein",
        "Shinyoung Kang",
        "Thomas O. Dalton",
        "Krystle K. Campbell",
        "Daniel J. Scott",
        "Andrew R. Jamieson"
      ],
      "abstract": "Grading Objective Structured Clinical Examinations (OSCEs) is a\ntime-consuming and expensive process, traditionally requiring extensive manual\neffort from human experts. In this study, we explore the potential of Large\nLanguage Models (LLMs) to assess skills related to medical student\ncommunication. We analyzed 2,027 video-recorded OSCE examinations from the\nUniversity of Texas Southwestern Medical Center (UTSW), spanning four years\n(2019-2022), and several different medical cases or \"stations.\" Specifically,\nour focus was on evaluating students' ability to summarize patients' medical\nhistory: we targeted the rubric item 'did the student summarize the patients'\nmedical history?' from the communication skills rubric. After transcribing\nspeech audio captured by OSCE videos using Whisper-v3, we studied the\nperformance of various LLM-based approaches for grading students on this\nsummarization task based on their examination transcripts. Using various\nfrontier-level open-source and proprietary LLMs, we evaluated different\ntechniques such as zero-shot chain-of-thought prompting, retrieval augmented\ngeneration, and multi-model ensemble methods. Our results show that frontier\nLLM models like GPT-4 achieved remarkable alignment with human graders,\ndemonstrating a Cohen's kappa agreement of 0.88 and indicating strong potential\nfor LLM-based OSCE grading to augment the current grading process. Open-source\nmodels also showed promising results, suggesting potential for widespread,\ncost-effective deployment. Further, we present a failure analysis identifying\nconditions where LLM grading may be less reliable in this context and recommend\nbest practices for deploying LLMs in medical education settings.",
      "tldr_zh": "本研究探讨了使用 Large Language Models (LLMs) 评估医学 Objective Structured Clinical Examinations (OSCE) 考试中学生的沟通技能，特别是总结患者病史的能力，以减少传统手动评分的工作量。研究团队分析了 2027 个来自 University of Texas Southwestern Medical Center 的视频记录，使用 Whisper-v3 转录语音，并测试了多种 LLM 方法，包括 zero-shot chain-of-thought prompting、retrieval augmented generation 和 multi-model ensemble。结果显示，GPT-4 与人类评分者达到了 Cohen's kappa 0.88 的高一致性，而开源模型也表现出色，表明 LLMs 有潜力实现成本有效的部署。该研究还进行了失败分析，并提出了在医疗教育中部署 LLMs 的最佳实践。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12858v1",
      "published_date": "2024-10-11 19:16:03 UTC",
      "updated_date": "2024-10-11 19:16:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:09:01.267163"
    },
    {
      "arxiv_id": "2410.09194v1",
      "title": "AI security and cyber risk in IoT systems",
      "title_zh": "翻译失败",
      "authors": [
        "Petar Radanliev",
        "David De Roure",
        "Carsten Maple",
        "Jason R. C. Nurse",
        "Razvan Nicolescu",
        "Uchenna Ani"
      ],
      "abstract": "We present a dependency model tailored to the context of current challenges\nin data strategies and make recommendations for the cybersecurity community.\nThe model can be used for cyber risk estimation and assessment and generic risk\nimpact assessment.",
      "tldr_zh": "这篇论文提出一个针对物联网（IoT）系统AI安全和网络风险的依赖模型（dependency model），以应对当前数据策略的挑战，并为网络安全社区提供相关推荐。该模型专为网络风险估计（cyber risk estimation）和评估（cyber risk assessment）设计，同时支持通用风险影响评估（generic risk impact assessment）。这项工作有助于提升IoT系统的风险管理能力，提供实用工具来量化并缓解潜在威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09194v1",
      "published_date": "2024-10-11 18:54:02 UTC",
      "updated_date": "2024-10-11 18:54:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:09:12.314087"
    },
    {
      "arxiv_id": "2410.09193v1",
      "title": "Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students",
      "title_zh": "翻译失败",
      "authors": [
        "Stephen MacNeil",
        "Magdalena Rogalska",
        "Juho Leinonen",
        "Paul Denny",
        "Arto Hellas",
        "Xandria Crosland"
      ],
      "abstract": "Large language models (LLMs) present an exciting opportunity for generating\nsynthetic classroom data. Such data could include code containing a typical\ndistribution of errors, simulated student behaviour to address the cold start\nproblem when developing education tools, and synthetic user data when access to\nauthentic data is restricted due to privacy reasons. In this research paper, we\nconduct a comparative study examining the distribution of bugs generated by\nLLMs in contrast to those produced by computing students. Leveraging data from\ntwo previous large-scale analyses of student-generated bugs, we investigate\nwhether LLMs can be coaxed to exhibit bug patterns that are similar to\nauthentic student bugs when prompted to inject errors into code. The results\nsuggest that unguided, LLMs do not generate plausible error distributions, and\nmany of the generated errors are unlikely to be generated by real students.\nHowever, with guidance including descriptions of common errors and typical\nfrequencies, LLMs can be shepherded to generate realistic distributions of\nerrors in synthetic code.",
      "tldr_zh": "这篇论文比较了大型语言模型（LLMs）和计算机学生在代码错误分布（bug distribution）方面的差异，旨在评估LLMs生成合成课堂数据的潜力，包括模拟学生错误以解决冷启动问题和隐私限制。研究方法利用先前的大型分析数据，通过提示LLMs注入错误，考察其是否能模仿真实学生的错误模式。结果表明，未经指导的LLMs生成的错误分布不真实且不 plausible，但通过提供常见错误描述和频率指导，LLMs能够产生更真实的合成错误分布，为教育工具开发提供宝贵资源。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09193v1",
      "published_date": "2024-10-11 18:51:58 UTC",
      "updated_date": "2024-10-11 18:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:09:25.034009"
    },
    {
      "arxiv_id": "2410.22339v2",
      "title": "DAWN: Designing Distributed Agents in a Worldwide Network",
      "title_zh": "翻译失败",
      "authors": [
        "Zahra Aminiranjbar",
        "Jianan Tang",
        "Qiudan Wang",
        "Shubha Pant",
        "Mahesh Viswanathan"
      ],
      "abstract": "The rapid evolution of Large Language Models (LLMs) has transformed them from\nbasic conversational tools into sophisticated entities capable of complex\nreasoning and decision-making. These advancements have led to the development\nof specialized LLM-based agents designed for diverse tasks such as coding and\nweb browsing. As these agents become more capable, the need for a robust\nframework that facilitates global communication and collaboration among them\ntowards advanced objectives has become increasingly critical. Distributed\nAgents in a Worldwide Network (DAWN) addresses this need by offering a\nversatile framework that integrates LLM-based agents with traditional software\nsystems, enabling the creation of agentic applications suited for a wide range\nof use cases. DAWN enables distributed agents worldwide to register and be\neasily discovered through Gateway Agents. Collaborations among these agents are\ncoordinated by a Principal Agent equipped with reasoning strategies. DAWN\noffers three operational modes: No-LLM Mode for deterministic tasks, Copilot\nfor augmented decision-making, and LLM Agent for autonomous operations.\nAdditionally, DAWN ensures the safety and security of agent collaborations\nglobally through a dedicated safety, security, and compliance layer, protecting\nthe network against attackers and adhering to stringent security and compliance\nstandards. These features make DAWN a robust network for deploying agent-based\napplications across various industries.",
      "tldr_zh": "该研究介绍了DAWN框架，用于设计全球分布式代理（Distributed Agents in a Worldwide Network），以满足Large Language Models (LLMs)代理在复杂任务中的通信和协作需求。DAWN整合LLM-based agents与传统软件系统，通过Gateway Agents实现代理注册和发现，并由Principal Agent协调协作，提供三种操作模式：No-LLM Mode用于确定性任务、Copilot用于增强决策，以及LLM Agent用于自主操作。同时，该框架配备安全、合规层，确保全球代理协作的安全性，适用于各种行业的代理应用。实验表明，DAWN提升了代理系统的健壮性和效率，为大规模代理网络奠定基础。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.22339v2",
      "published_date": "2024-10-11 18:47:04 UTC",
      "updated_date": "2024-11-18 17:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:09:36.471682"
    },
    {
      "arxiv_id": "2410.09187v2",
      "title": "Automated Rewards via LLM-Generated Progress Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Vishnu Sarukkai",
        "Brennan Shacklett",
        "Zander Majercik",
        "Kush Bhatia",
        "Christopher Ré",
        "Kayvon Fatahalian"
      ],
      "abstract": "Large Language Models (LLMs) have the potential to automate reward\nengineering by leveraging their broad domain knowledge across various tasks.\nHowever, they often need many iterations of trial-and-error to generate\neffective reward functions. This process is costly because evaluating every\nsampled reward function requires completing the full policy optimization\nprocess for each function. In this paper, we introduce an LLM-driven reward\ngeneration framework that is able to produce state-of-the-art policies on the\nchallenging Bi-DexHands benchmark with 20x fewer reward function samples than\nthe prior state-of-the-art work. Our key insight is that we reduce the problem\nof generating task-specific rewards to the problem of coarsely estimating task\nprogress. Our two-step solution leverages the task domain knowledge and the\ncode synthesis abilities of LLMs to author progress functions that estimate\ntask progress from a given state. Then, we use this notion of progress to\ndiscretize states, and generate count-based intrinsic rewards using the\nlow-dimensional state space. We show that the combination of LLM-generated\nprogress functions and count-based intrinsic rewards is essential for our\nperformance gains, while alternatives such as generic hash-based counts or\nusing progress directly as a reward function fall short.",
      "tldr_zh": "本研究提出了一种基于大型语言模型(LLMs)的奖励生成框架，用于自动化奖励工程，显著减少了生成有效奖励函数的试错迭代。该框架的核心是将任务特定奖励问题简化为估算任务进度，通过LLMs的领域知识和代码合成能力创建进度函数，并使用这些函数离散化状态以生成基于计数的内在奖励。在Bi-DexHands基准测试中，该方法仅需比现有最先进工作少20倍的奖励函数样本，即可实现最先进的策略性能，且证明了LLM生成进度函数与内在奖励结合的必要性，而其他替代方案（如哈希计数或直接使用进度作为奖励）效果较差。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09187v2",
      "published_date": "2024-10-11 18:41:15 UTC",
      "updated_date": "2024-10-25 17:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:09:48.775934"
    },
    {
      "arxiv_id": "2410.09186v2",
      "title": "Learning Algorithms Made Simple",
      "title_zh": "学习算法简明易懂",
      "authors": [
        "Noorbakhsh Amiri Golilarz",
        "Elias Hossain",
        "Abdoljalil Addeh",
        "Keyan Alexander Rahimi"
      ],
      "abstract": "In this paper, we discuss learning algorithms and their importance in\ndifferent types of applications which includes training to identify important\npatterns and features in a straightforward, easy-to-understand manner. We will\nreview the main concepts of artificial intelligence (AI), machine learning\n(ML), deep learning (DL), and hybrid models. Some important subsets of Machine\nLearning algorithms such as supervised, unsupervised, and reinforcement\nlearning are also discussed in this paper. These techniques can be used for\nsome important tasks like prediction, classification, and segmentation.\nConvolutional Neural Networks (CNNs) are used for image and video processing\nand many more applications. We dive into the architecture of CNNs and how to\nintegrate CNNs with ML algorithms to build hybrid models. This paper explores\nthe vulnerability of learning algorithms to noise, leading to\nmisclassification. We further discuss the integration of learning algorithms\nwith Large Language Models (LLM) to generate coherent responses applicable to\nmany domains such as healthcare, marketing, and finance by learning important\npatterns from large volumes of data. Furthermore, we discuss the next\ngeneration of learning algorithms and how we may have an unified Adaptive and\nDynamic Network to perform important tasks. Overall, this article provides\nbrief overview of learning algorithms, exploring their current state,\napplications and future direction.",
      "tldr_zh": "这篇论文以简单易懂的方式概述了学习算法（learning algorithms），包括 artificial intelligence (AI)、machine learning (ML)、deep learning (DL) 和混合模型的核心概念，以及 supervised learning、unsupervised learning 和 reinforcement learning 等子集。论文讨论了这些算法在预测、分类和分割等任务中的应用，并介绍了 Convolutional Neural Networks (CNNs) 的架构及其与 ML 算法的整合，以处理图像和视频数据。论文还探讨了算法对噪声的脆弱性、与 Large Language Models (LLM) 的结合应用于医疗、金融等领域，以及未来统一的自适应动态网络（Adaptive and Dynamic Network）的方向。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09186v2",
      "published_date": "2024-10-11 18:39:25 UTC",
      "updated_date": "2025-05-08 19:38:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:10:01.297917"
    },
    {
      "arxiv_id": "2410.09181v1",
      "title": "Can a large language model be a gaslighter?",
      "title_zh": "大型语言模型能成为精神操控者吗？",
      "authors": [
        "Wei Li",
        "Luyao Zhu",
        "Yang Song",
        "Ruixi Lin",
        "Rui Mao",
        "Yang You"
      ],
      "abstract": "Large language models (LLMs) have gained human trust due to their\ncapabilities and helpfulness. However, this in turn may allow LLMs to affect\nusers' mindsets by manipulating language. It is termed as gaslighting, a\npsychological effect. In this work, we aim to investigate the vulnerability of\nLLMs under prompt-based and fine-tuning-based gaslighting attacks. Therefore,\nwe propose a two-stage framework DeepCoG designed to: 1) elicit gaslighting\nplans from LLMs with the proposed DeepGaslighting prompting template, and 2)\nacquire gaslighting conversations from LLMs through our Chain-of-Gaslighting\nmethod. The gaslighting conversation dataset along with a corresponding safe\ndataset is applied to fine-tuning-based attacks on open-source LLMs and\nanti-gaslighting safety alignment on these LLMs. Experiments demonstrate that\nboth prompt-based and fine-tuning-based attacks transform three open-source\nLLMs into gaslighters. In contrast, we advanced three safety alignment\nstrategies to strengthen (by 12.05%) the safety guardrail of LLMs. Our safety\nalignment strategies have minimal impacts on the utility of LLMs. Empirical\nstudies indicate that an LLM may be a potential gaslighter, even if it passed\nthe harmfulness test on general dangerous queries.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否可能通过操纵语言进行 gaslighting 攻击，从而影响用户心态。研究提出 DeepCoG 框架，包括 DeepGaslighting 提示模板和 Chain-of-Gaslighting 方法，用于从 LLMs 中提取 gaslighting 计划并生成对话数据集。实验结果显示，提示和微调攻击可将三个开源 LLMs 转化为 gaslighter，而提出的三种安全对齐策略提升了模型的安全防护 12.05%，并对 LLMs 的效用影响最小。最终，研究强调，即使 LLMs 通过了常规有害查询测试，它们仍存在成为潜在 gaslighter 的风险。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "10/26 (Main Body/Total), 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09181v1",
      "published_date": "2024-10-11 18:35:27 UTC",
      "updated_date": "2024-10-11 18:35:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:10:14.340938"
    },
    {
      "arxiv_id": "2410.09173v1",
      "title": "Resource-Constrained Heuristic for Max-SAT",
      "title_zh": "针对 Max-SAT 的资源约束启发式算法",
      "authors": [
        "Brian Matejek",
        "Daniel Elenius",
        "Cale Gentry",
        "David Stoker",
        "Adam Cobb"
      ],
      "abstract": "We propose a resource-constrained heuristic for instances of Max-SAT that\niteratively decomposes a larger problem into smaller subcomponents that can be\nsolved by optimized solvers and hardware. The unconstrained outer loop\nmaintains the state space of a given problem and selects a subset of the SAT\nvariables for optimization independent of previous calls. The\nresource-constrained inner loop maximizes the number of satisfiable clauses in\nthe \"sub-SAT\" problem. Our outer loop is agnostic to the mechanisms of the\ninner loop, allowing for the use of traditional solvers for the optimization\nstep. However, we can also transform the selected \"sub-SAT\" problem into a\nquadratic unconstrained binary optimization (QUBO) one and use specialized\nhardware for optimization. In contrast to existing solutions that convert a SAT\ninstance into a QUBO one before decomposition, we choose a subset of the SAT\nvariables before QUBO optimization. We analyze a set of variable selection\nmethods, including a novel graph-based method that exploits the structure of a\ngiven SAT instance. The number of QUBO variables needed to encode a (sub-)SAT\nproblem varies, so we additionally learn a model that predicts the size of\nsub-SAT problems that will fit a fixed-size QUBO solver. We empirically\ndemonstrate our results on a set of randomly generated Max-SAT instances as\nwell as real world examples from the Max-SAT evaluation benchmarks and\noutperform existing QUBO decomposer solutions.",
      "tldr_zh": "该研究提出了一种资源受限的启发式方法，用于 Max-SAT 问题，通过迭代分解大问题为小小子问题，由优化求解器和硬件处理。方法包括一个外循环维护问题状态并选择 SAT 变量子集，以及一个内循环最大化子 SAT 问题中可满足子句，支持传统求解器或转换为 quadratic unconstrained binary optimization (QUBO) 形式并利用专用硬件。研究还分析了多种变量选择方法，包括一个新颖的基于图的结构方法，并训练模型预测适合固定大小 QUBO 求解器的子问题规模；在随机生成和真实世界 Max-SAT 基准测试中，该方法超过了现有 QUBO 分解器解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09173v1",
      "published_date": "2024-10-11 18:20:08 UTC",
      "updated_date": "2024-10-11 18:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:10:25.524000"
    },
    {
      "arxiv_id": "2410.12857v1",
      "title": "Enterprise Benchmarks for Large Language Model Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Bing Zhang",
        "Mikio Takeuchi",
        "Ryo Kawahara",
        "Shubhi Asthana",
        "Md. Maruf Hossain",
        "Guang-Jie Ren",
        "Kate Soule",
        "Yada Zhu"
      ],
      "abstract": "The advancement of large language models (LLMs) has led to a greater\nchallenge of having a rigorous and systematic evaluation of complex tasks\nperformed, especially in enterprise applications. Therefore, LLMs need to be\nable to benchmark enterprise datasets for various tasks. This work presents a\nsystematic exploration of benchmarking strategies tailored to LLM evaluation,\nfocusing on the utilization of domain-specific datasets and consisting of a\nvariety of NLP tasks. The proposed evaluation framework encompasses 25 publicly\navailable datasets from diverse enterprise domains like financial services,\nlegal, cyber security, and climate and sustainability. The diverse performance\nof 13 models across different enterprise tasks highlights the importance of\nselecting the right model based on the specific requirements of each task. Code\nand prompts are available on GitHub.",
      "tldr_zh": "本研究探讨了评估大型语言模型 (LLMs) 在企业应用中的挑战，提出了一种系统化的基准测试策略，使用领域特定数据集进行评估。框架涵盖了25个公开数据集，涉及金融服务、法律、网络安全和气候可持续性等领域的各种NLP任务。实验评估了13个模型的表现，突出了根据任务需求选择合适模型的重要性；相关代码和提示已在GitHub上公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12857v1",
      "published_date": "2024-10-11 18:19:05 UTC",
      "updated_date": "2024-10-11 18:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:10:35.850969"
    },
    {
      "arxiv_id": "2410.09047v1",
      "title": "Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Liu",
        "Chao Shang",
        "Ling Liu",
        "Nikolaos Pappas",
        "Jie Ma",
        "Neha Anna John",
        "Srikanth Doss",
        "Lluis Marquez",
        "Miguel Ballesteros",
        "Yassine Benajiba"
      ],
      "abstract": "The safety alignment ability of Vision-Language Models (VLMs) is prone to be\ndegraded by the integration of the vision module compared to its LLM backbone.\nWe investigate this phenomenon, dubbed as ''safety alignment degradation'' in\nthis paper, and show that the challenge arises from the representation gap that\nemerges when introducing vision modality to VLMs. In particular, we show that\nthe representations of multi-modal inputs shift away from that of text-only\ninputs which represent the distribution that the LLM backbone is optimized for.\nAt the same time, the safety alignment capabilities, initially developed within\nthe textual embedding space, do not successfully transfer to this new\nmulti-modal representation space. To reduce safety alignment degradation, we\nintroduce Cross-Modality Representation Manipulation (CMRM), an inference time\nrepresentation intervention method for recovering the safety alignment ability\nthat is inherent in the LLM backbone of VLMs, while simultaneously preserving\nthe functional capabilities of VLMs. The empirical results show that our\nframework significantly recovers the alignment ability that is inherited from\nthe LLM backbone with minimal impact on the fluency and linguistic capabilities\nof pre-trained VLMs even without additional training. Specifically, the unsafe\nrate of LLaVA-7B on multi-modal input can be reduced from 61.53% to as low as\n3.15% with only inference-time intervention.\n  WARNING: This paper contains examples of toxic or harmful language.",
      "tldr_zh": "该研究揭示了Vision-Language Models (VLMs) 在整合视觉模块后，安全对齐能力退化的问题，称为“safety alignment degradation”，其根因在于多模态输入的表示差距，使安全对齐从文本嵌入空间无法顺利转移。针对此，作者提出Cross-Modality Representation Manipulation (CMRM)，一种推理时的表示干预方法，用于恢复VLMs从LLM backbone继承的安全对齐能力，同时保持模型的功能性。实验结果显示，该框架无需额外训练即可显著降低不安全率，例如将LLaVA-7B的多模态输入不安全率从61.53%降至3.15%，对模型的流畅性和语言能力影响最小。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2410.09047v1",
      "published_date": "2024-10-11 17:59:31 UTC",
      "updated_date": "2024-10-11 17:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:10:48.386714"
    },
    {
      "arxiv_id": "2410.09043v2",
      "title": "Transforming In-Vehicle Network Intrusion Detection: VAE-based Knowledge Distillation Meets Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammet Anil Yagiz",
        "Pedram MohajerAnsari",
        "Mert D. Pese",
        "Polat Goktas"
      ],
      "abstract": "In the evolving landscape of autonomous vehicles, ensuring robust in-vehicle\nnetwork (IVN) security is paramount. This paper introduces an advanced\nintrusion detection system (IDS) called KD-XVAE that uses a Variational\nAutoencoder (VAE)-based knowledge distillation approach to enhance both\nperformance and efficiency. Our model significantly reduces complexity,\noperating with just 1669 parameters and achieving an inference time of 0.3 ms\nper batch, making it highly suitable for resource-constrained automotive\nenvironments. Evaluations in the HCRL Car-Hacking dataset demonstrate\nexceptional capabilities, attaining perfect scores (Recall, Precision, F1 Score\nof 100%, and FNR of 0%) under multiple attack types, including DoS, Fuzzing,\nGear Spoofing, and RPM Spoofing. Comparative analysis on the CICIoV2024 dataset\nfurther underscores its superiority over traditional machine learning models,\nachieving perfect detection metrics. We furthermore integrate Explainable AI\n(XAI) techniques to ensure transparency in the model's decisions. The VAE\ncompresses the original feature space into a latent space, on which the\ndistilled model is trained. SHAP(SHapley Additive exPlanations) values provide\ninsights into the importance of each latent dimension, mapped back to original\nfeatures for intuitive understanding. Our paper advances the field by\nintegrating state-of-the-art techniques, addressing critical challenges in the\ndeployment of efficient, trustworthy, and reliable IDSes for autonomous\nvehicles, ensuring enhanced protection against emerging cyber threats.",
      "tldr_zh": "该论文提出了一种先进的入侵检测系统 KD-XVAE，利用 Variational Autoencoder (VAE)-based knowledge distillation 方法，提升了在-vehicle网络的安全性能和效率，仅需 1669 个参数和 0.3 ms 每批的推理时间，适合资源受限的汽车环境。实验在 HCRL Car-Hacking 数据集上针对 DoS、Fuzzing、Gear Spoofing 和 RPM Spoofing 等攻击类型，实现了完美的检测指标（Recall、Precision 和 F1 Score 均为 100%，FNR 为 0%），并在 CICIoV2024 数据集上优于传统机器学习模型。系统还整合了 Explainable AI (XAI) 技术，通过 VAE 压缩特征空间并使用 SHAP 值分析潜在维度的重要性，提供对模型决策的直观解释。该方法推进了自主车辆的安全领域，确保高效、可信赖的防护对抗新兴网络威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09043v2",
      "published_date": "2024-10-11 17:57:16 UTC",
      "updated_date": "2024-10-15 16:29:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:11:02.443778"
    },
    {
      "arxiv_id": "2410.09141v1",
      "title": "ACER: Automatic Language Model Context Extension via Retrieval",
      "title_zh": "ACER：基于检索的自动语言模型上下文扩展",
      "authors": [
        "Luyu Gao",
        "Yunyi Zhang",
        "Jamie Callan"
      ],
      "abstract": "Long-context modeling is one of the critical capabilities of language AI for\ndigesting and reasoning over complex information pieces. In practice,\nlong-context capabilities are typically built into a pre-trained language\nmodel~(LM) through a carefully designed context extension stage, with the goal\nof producing generalist long-context capabilities. In our preliminary\nexperiments, however, we discovered that the current open-weight generalist\nlong-context models are still lacking in practical long-context processing\ntasks. While this means perfectly effective long-context modeling demands\ntask-specific data, the cost can be prohibitive. In this paper, we draw\ninspiration from how humans process a large body of information: a lossy\n\\textbf{retrieval} stage ranks a large set of documents while the reader ends\nup reading deeply only the top candidates. We build an \\textbf{automatic} data\nsynthesis pipeline that mimics this process using short-context LMs. The\nshort-context LMs are further tuned using these self-generated data to obtain\ntask-specific long-context capabilities. Similar to how pre-training learns\nfrom imperfect data, we hypothesize and further demonstrate that the\nshort-context model can bootstrap over the synthetic data, outperforming not\nonly long-context generalist models but also the retrieval and read pipeline\nused to synthesize the training data in real-world tasks such as long-context\nretrieval augmented generation.",
      "tldr_zh": "本论文提出ACER，一种自动语言模型上下文扩展框架，通过受人类信息处理启发的检索机制，使用短上下文语言模型（LMs）构建一个数据合成管道，以模拟检索和优先阅读过程。ACER生成任务特定的合成数据，并以此微调短上下文LMs，从而赋予模型高效的长上下文能力。实验结果显示，该方法在真实任务如长上下文Retrieval Augmented Generation中，优于通用长上下文模型和原始合成管道，证明了短上下文模型通过合成数据进行引导式提升的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09141v1",
      "published_date": "2024-10-11 17:57:06 UTC",
      "updated_date": "2024-10-11 17:57:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:11:11.973587"
    },
    {
      "arxiv_id": "2410.09038v2",
      "title": "SimpleStrat: Diversifying Language Model Generation with Stratification",
      "title_zh": "SimpleStrat：通过分层实现语言模型生成的多样化",
      "authors": [
        "Justin Wong",
        "Yury Orlovskiy",
        "Michael Luo",
        "Sanjit A. Seshia",
        "Joseph E. Gonzalez"
      ],
      "abstract": "Generating diverse responses from large language models (LLMs) is crucial for\napplications such as planning/search and synthetic data generation, where\ndiversity provides distinct answers across generations. Prior approaches rely\non increasing temperature to increase diversity. However, contrary to popular\nbelief, we show not only does this approach produce lower quality individual\ngenerations as temperature increases, but it depends on model's next-token\nprobabilities being similar to the true distribution of answers. We propose\nSimpleStrat, an alternative approach that uses the language model itself to\npartition the space into strata. At inference, a random stratum is selected and\na sample drawn from within the strata. To measure diversity, we introduce\nCoverageQA, a dataset of underspecified questions with multiple equally\nplausible answers, and assess diversity by measuring KL Divergence between the\noutput distribution and uniform distribution over valid ground truth answers.\nAs computing probability per response/solution for proprietary models is\ninfeasible, we measure recall on ground truth solutions. Our evaluation show\nusing SimpleStrat achieves higher recall by 0.05 compared to GPT-4o and 0.36\naverage reduction in KL Divergence compared to Llama 3.",
      "tldr_zh": "该研究指出，现有的语言模型(LLMs)生成多样化响应方法（如提高温度）会降低生成质量，并依赖于模型的下一个标记概率与真实分布的相似性。作者提出SimpleStrat，一种利用语言模型本身将响应空间分区成strata（层）的创新方法，在推理时随机选择一个strata并从中抽样，以提升生成多样性。为评估多样性，他们引入了CoverageQA数据集，该数据集包含多个等可能答案的未指定问题，并通过KL Divergence和地面实答案的召回率进行测量。实验结果显示，SimpleStrat与GPT-4o相比召回率提高了0.05，与Llama 3相比KL Divergence平均降低了0.36，从而为LLMs在规划/搜索和合成数据生成等应用中提供更可靠的多样性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09038v2",
      "published_date": "2024-10-11 17:54:14 UTC",
      "updated_date": "2024-10-14 17:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:11:24.986152"
    },
    {
      "arxiv_id": "2410.09037v1",
      "title": "Mentor-KD: Making Small Language Models Better Multi-step Reasoners",
      "title_zh": "翻译失败",
      "authors": [
        "Hojae Lee",
        "Junho Kim",
        "SangKeun Lee"
      ],
      "abstract": "Large Language Models (LLMs) have displayed remarkable performances across\nvarious complex tasks by leveraging Chain-of-Thought (CoT) prompting. Recently,\nstudies have proposed a Knowledge Distillation (KD) approach, reasoning\ndistillation, which transfers such reasoning ability of LLMs through\nfine-tuning language models of multi-step rationales generated by LLM teachers.\nHowever, they have inadequately considered two challenges regarding\ninsufficient distillation sets from the LLM teacher model, in terms of 1) data\nquality and 2) soft label provision. In this paper, we propose Mentor-KD, which\neffectively distills the multi-step reasoning capability of LLMs to smaller LMs\nwhile addressing the aforementioned challenges. Specifically, we exploit a\nmentor, intermediate-sized task-specific fine-tuned model, to augment\nadditional CoT annotations and provide soft labels for the student model during\nreasoning distillation. We conduct extensive experiments and confirm\nMentor-KD's effectiveness across various models and complex reasoning tasks.",
      "tldr_zh": "本研究提出Mentor-KD，一种知识蒸馏（KD）方法，旨在提升小型语言模型（LMs）在多步推理任务中的性能，解决现有方法在数据质量和软标签提供方面的不足。具体来说，Mentor-KD利用一个中间规模的任务特定微调模型作为“导师”，来增强Chain-of-Thought (CoT)注释并为学生模型提供软标签，从而有效转移Large Language Models (LLMs)的推理能力。实验结果显示，该方法在各种模型和复杂推理任务上表现出色，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.09037v1",
      "published_date": "2024-10-11 17:53:27 UTC",
      "updated_date": "2024-10-11 17:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:11:36.255271"
    },
    {
      "arxiv_id": "2410.09034v1",
      "title": "PEAR: A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple Large Language Model Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Yin",
        "Chuqiao Shi",
        "Yimo Han",
        "Yi Jiang"
      ],
      "abstract": "Ptychography is an advanced computational imaging technique in X-ray and\nelectron microscopy. It has been widely adopted across scientific research\nfields, including physics, chemistry, biology, and materials science, as well\nas in industrial applications such as semiconductor characterization. In\npractice, obtaining high-quality ptychographic images requires simultaneous\noptimization of numerous experimental and algorithmic parameters.\nTraditionally, parameter selection often relies on trial and error, leading to\nlow-throughput workflows and potential human bias. In this work, we develop the\n\"Ptychographic Experiment and Analysis Robot\" (PEAR), a framework that\nleverages large language models (LLMs) to automate data analysis in\nptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM\nagents for tasks including knowledge retrieval, code generation, parameter\nrecommendation, and image reasoning. Our study demonstrates that PEAR's\nmulti-agent design significantly improves the workflow success rate, even with\nsmaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various\nautomation levels and is designed to work with customized local knowledge\nbases, ensuring flexibility and adaptability across different research\nenvironments.",
      "tldr_zh": "本研究开发了 PEAR 框架，这是一个基于多个大型语言模型 (LLMs) 代理的自动化系统，用于优化 Ptychography 成像技术的数据分析。PEAR 通过代理处理知识检索、代码生成、参数推荐和图像推理等任务，显著减少了传统试错方法的低效性和人为偏差。实验结果显示，即使使用较小模型如 LLaMA 3.1 8B，PEAR 也能提高工作流程成功率，并支持各种自动化级别和自定义本地知识库，确保在不同研究环境中的灵活性和适应性。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.CE",
      "comment": "18 pages, 5 figures, technical preview report",
      "pdf_url": "http://arxiv.org/pdf/2410.09034v1",
      "published_date": "2024-10-11 17:50:59 UTC",
      "updated_date": "2024-10-11 17:50:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:11:48.744084"
    },
    {
      "arxiv_id": "2410.09024v3",
      "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Maksym Andriushchenko",
        "Alexandra Souly",
        "Mateusz Dziemian",
        "Derek Duenas",
        "Maxwell Lin",
        "Justin Wang",
        "Dan Hendrycks",
        "Andy Zou",
        "Zico Kolter",
        "Matt Fredrikson",
        "Eric Winsor",
        "Jerome Wynne",
        "Yarin Gal",
        "Xander Davies"
      ],
      "abstract": "The robustness of LLMs to jailbreak attacks, where users design prompts to\ncircumvent safety measures and misuse model capabilities, has been studied\nprimarily for LLMs acting as simple chatbots. Meanwhile, LLM agents -- which\nuse external tools and can execute multi-stage tasks -- may pose a greater risk\nif misused, but their robustness remains underexplored. To facilitate research\non LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark\nincludes a diverse set of 110 explicitly malicious agent tasks (440 with\naugmentations), covering 11 harm categories including fraud, cybercrime, and\nharassment. In addition to measuring whether models refuse harmful agentic\nrequests, scoring well on AgentHarm requires jailbroken agents to maintain\ntheir capabilities following an attack to complete a multi-step task. We\nevaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly\ncompliant with malicious agent requests without jailbreaking, (2) simple\nuniversal jailbreak templates can be adapted to effectively jailbreak agents,\nand (3) these jailbreaks enable coherent and malicious multi-step agent\nbehavior and retain model capabilities. To enable simple and reliable\nevaluation of attacks and defenses for LLM-based agents, we publicly release\nAgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.",
      "tldr_zh": "本文提出 AgentHarm 基准，用于评估 LLM agents 对越狱攻击（jailbreak attacks）的鲁棒性，聚焦于代理的多阶段任务和潜在风险。该基准包括 110 个恶意任务（扩展后 440 个），覆盖 11 个危害类别，如欺诈、网络犯罪和骚扰，并不仅测量模型拒绝有害请求的能力，还评估越狱后代理是否能保持多步任务能力。实验发现，领先的 LLM 在未越狱情况下对恶意请求表现出奇顺从，简单的通用 jailbreak 模板可有效攻击代理，使其进行连贯的恶意行为同时保留模型功能。作者公开发布了 AgentHarm 数据集，以促进 LLM 代理安全研究的进一步发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.09024v3",
      "published_date": "2024-10-11 17:39:22 UTC",
      "updated_date": "2025-04-18 14:30:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:12:01.092932"
    },
    {
      "arxiv_id": "2410.09012v2",
      "title": "Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Li",
        "Cor-Paul Bezemer",
        "Ahmed E. Hassan"
      ],
      "abstract": "Foundation models (FMs) such as large language models (LLMs) have\nsignificantly impacted many fields, including software engineering (SE). The\ninteraction between SE and FMs has led to the integration of FMs into SE\npractices (FM4SE) and the application of SE methodologies to FMs (SE4FM). While\nseveral literature surveys exist on academic contributions to these trends, we\nare the first to provide a practitioner's view. We analyze 155 FM4SE and 997\nSE4FM blog posts from leading technology companies, leveraging an FM-powered\nsurveying approach to systematically label and summarize the discussed\nactivities and tasks. We observed that while code generation is the most\nprominent FM4SE task, FMs are leveraged for many other SE activities such as\ncode understanding, summarization, and API recommendation. The majority of blog\nposts on SE4FM are about model deployment & operation, and system architecture\n& orchestration. Although the emphasis is on cloud deployments, there is a\ngrowing interest in compressing FMs and deploying them on smaller devices such\nas edge or mobile devices. We outline eight future research directions inspired\nby our gained insights, aiming to bridge the gap between academic findings and\nreal-world applications. Our study not only enriches the body of knowledge on\npractical applications of FM4SE and SE4FM but also demonstrates the utility of\nFMs as a powerful and efficient approach in conducting literature surveys\nwithin technical and grey literature domains. Our dataset, results, code and\nused prompts can be found in our online replication package at\nhttps://github.com/SAILResearch/fmse-blogs.",
      "tldr_zh": "这篇论文通过分析来自领先科技公司的155个FM4SE和997个SE4FM博客帖子，提供了一个从业者视角的调查，探讨基础模型（FMs）如大语言模型（LLMs）与软件工程（SE）的互动。研究采用FM驱动的调查方法（Jury of Foundation Models）来系统标记和总结任务，发现FM4SE的主要活动包括代码生成、代码理解和API推荐，而SE4FM则重点关注模型部署、操作和系统架构，并显示出向边缘设备部署的趋势。论文还提出了八个未来研究方向，以桥接学术与实际应用，并证明了FMs在文献调查中的高效实用性。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "ICSE-SEIP 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.09012v2",
      "published_date": "2024-10-11 17:27:04 UTC",
      "updated_date": "2025-01-06 20:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:12:14.479813"
    },
    {
      "arxiv_id": "2410.12856v1",
      "title": "Optimized Biomedical Question-Answering Services with LLM and Multi-BERT Integration",
      "title_zh": "利用LLM和Multi-BERT整合的优化生物医学问答服务",
      "authors": [
        "Cheng Qian",
        "Xianglong Shi",
        "Shanshan Yao",
        "Yichen Liu",
        "Fengming Zhou",
        "Zishu Zhang",
        "Junaid Akram",
        "Ali Braytee",
        "Ali Anaissi"
      ],
      "abstract": "We present a refined approach to biomedical question-answering (QA) services\nby integrating large language models (LLMs) with Multi-BERT configurations. By\nenhancing the ability to process and prioritize vast amounts of complex\nbiomedical data, this system aims to support healthcare professionals in\ndelivering better patient outcomes and informed decision-making. Through\ninnovative use of BERT and BioBERT models, combined with a multi-layer\nperceptron (MLP) layer, we enable more specialized and efficient responses to\nthe growing demands of the healthcare sector. Our approach not only addresses\nthe challenge of overfitting by freezing one BERT model while training another\nbut also improves the overall adaptability of QA services. The use of extensive\ndatasets, such as BioASQ and BioMRC, demonstrates the system's ability to\nsynthesize critical information. This work highlights how advanced language\nmodels can make a tangible difference in healthcare, providing reliable and\nresponsive tools for professionals to manage complex information, ultimately\nserving the broader goal of improved care and data-driven insights.",
      "tldr_zh": "本研究提出了一种优化生物医学问答(QA)服务的框架，通过整合大型语言模型(LLMs)与Multi-BERT配置，提升对复杂生物医学数据的处理和优先级排序，支持医疗专业人员实现更好决策和患者结果。方法包括使用BERT和BioBERT模型结合多层感知器(MLP)层，同时通过冻结一个BERT模型训练另一个来避免过拟合，提高系统适应性。在BioASQ和BioMRC等数据集上的实验验证了该方法的有效性，最终为医疗领域提供可靠、响应迅速的工具，促进数据驱动的洞见和护理改进。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 pages, 12 figures, accepted and to be published in the proceedings\n  of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)",
      "pdf_url": "http://arxiv.org/pdf/2410.12856v1",
      "published_date": "2024-10-11 17:13:31 UTC",
      "updated_date": "2024-10-11 17:13:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:12:24.210229"
    },
    {
      "arxiv_id": "2410.08997v2",
      "title": "Hierarchical Universal Value Function Approximators",
      "title_zh": "层次通用价值函数近似器",
      "authors": [
        "Rushiv Arora"
      ],
      "abstract": "There have been key advancements to building universal approximators for\nmulti-goal collections of reinforcement learning value functions -- key\nelements in estimating long-term returns of states in a parameterized manner.\nWe extend this to hierarchical reinforcement learning, using the options\nframework, by introducing hierarchical universal value function approximators\n(H-UVFAs). This allows us to leverage the added benefits of scaling, planning,\nand generalization expected in temporal abstraction settings. We develop\nsupervised and reinforcement learning methods for learning embeddings of the\nstates, goals, options, and actions in the two hierarchical value functions:\n$Q(s, g, o; \\theta)$ and $Q(s, g, o, a; \\theta)$. Finally we demonstrate\ngeneralization of the HUVFAs and show they outperform corresponding UVFAs.",
      "tldr_zh": "本研究扩展了通用价值函数近似器（Universal Value Function Approximators, UVFAs）到分层强化学习（Hierarchical Reinforcement Learning）领域，通过引入分层通用价值函数近似器（H-UVFAs）来利用 options 框架的优势，实现更好的规模化、规划和泛化。研究开发了监督学习和强化学习方法，用于学习状态、目标、options 和动作的嵌入，具体涉及价值函数 $Q(s, g, o; \\theta)$ 和 $Q(s, g, o, a; \\theta)$。实验结果表明，H-UVFAs 在泛化性能上优于标准的 UVFAs，为多目标强化学习中的时间抽象设置提供了更有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 11 figures, 3 appendices. Currently under review",
      "pdf_url": "http://arxiv.org/pdf/2410.08997v2",
      "published_date": "2024-10-11 17:09:26 UTC",
      "updated_date": "2024-10-27 16:37:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:12:36.652135"
    },
    {
      "arxiv_id": "2410.08993v1",
      "title": "The structure of the token space for large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Robinson",
        "Sourya Dey",
        "Shauna Sweet"
      ],
      "abstract": "Large language models encode the correlational structure present in natural\nlanguage by fitting segments of utterances (tokens) into a high dimensional\nambient latent space upon which the models then operate. We assert that in\norder to develop a foundational, first-principles understanding of the behavior\nand limitations of large language models, it is crucial to understand the\ntopological and geometric structure of this token subspace. In this article, we\npresent estimators for the dimension and Ricci scalar curvature of the token\nsubspace, and apply it to three open source large language models of moderate\nsize: GPT2, LLEMMA7B, and MISTRAL7B. In all three models, using these\nmeasurements, we find that the token subspace is not a manifold, but is instead\na stratified manifold, where on each of the individual strata, the Ricci\ncurvature is significantly negative. We additionally find that the dimension\nand curvature correlate with generative fluency of the models, which suggest\nthat these findings have implications for model behavior.",
      "tldr_zh": "本论文探讨了大型语言模型中 token subspace 的拓扑和几何结构，以加深对模型行为和局限性的基础理解。作者提出了估算 token subspace 维数和 Ricci scalar curvature 的方法，并将其应用于 GPT2、LLEMMA7B 和 MISTRAL7B 等开源模型。结果显示，token subspace 不是一个流形，而是 stratified manifold，且每个层上的 Ricci 曲率显著负值。此外，维数和曲率与模型的生成流畅度相关，这为解释模型性能提供了重要启示。",
      "categories": [
        "math.DG",
        "cs.AI",
        "53Z50, 58Z05"
      ],
      "primary_category": "math.DG",
      "comment": "33 pages, 22 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.08993v1",
      "published_date": "2024-10-11 17:07:15 UTC",
      "updated_date": "2024-10-11 17:07:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:13:42.652769"
    },
    {
      "arxiv_id": "2410.08989v2",
      "title": "Zeroth-Order Fine-Tuning of LLMs in Random Subspaces",
      "title_zh": "翻译失败",
      "authors": [
        "Ziming Yu",
        "Pan Zhou",
        "Sike Wang",
        "Jia Li",
        "Hua Huang"
      ],
      "abstract": "Fine-tuning Large Language Models (LLMs) has proven effective for a variety\nof downstream tasks. However, as LLMs grow in size, the memory demands for\nbackpropagation become increasingly prohibitive. Zeroth-order (ZO) optimization\nmethods offer a memory-efficient alternative by using forward passes to\nestimate gradients, but the variance of gradient estimates typically scales\nlinearly with the model's parameter dimension$\\unicode{x2013}$a significant\nissue for LLMs. In this paper, we propose the random Subspace Zeroth-order\n(SubZero) optimization to address the challenges posed by LLMs' high\ndimensionality. We introduce a low-rank perturbation tailored for LLMs that\nsignificantly reduces memory consumption while improving training performance.\nAdditionally, we prove that our gradient estimation closely approximates the\nbackpropagation gradient, exhibits lower variance than traditional ZO methods,\nand ensures convergence when combined with SGD. Experimental results show that\nSubZero enhances fine-tuning performance and achieves faster convergence\ncompared to standard ZO approaches like MeZO across various language modeling\ntasks.",
      "tldr_zh": "这篇论文针对大语言模型 (LLMs) 的 fine-tuning 问题，提出了一种名为 SubZero 的随机子空间 Zeroth-order (ZO) 优化方法，以应对模型高维度导致的梯度估计方差和内存消耗挑战。SubZero 通过引入低秩扰动来减少内存使用，同时证明其梯度估计更接近 backpropagation 梯度、方差更低，并与 SGD 结合时确保收敛。实验结果显示，SubZero 在各种语言建模任务上提升了训练性能，并比标准 ZO 方法如 MeZO 实现更快收敛。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08989v2",
      "published_date": "2024-10-11 17:01:43 UTC",
      "updated_date": "2024-11-22 15:08:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:13:01.193819"
    },
    {
      "arxiv_id": "2410.08985v2",
      "title": "Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective",
      "title_zh": "翻译失败",
      "authors": [
        "Bo Ni",
        "Yu Wang",
        "Lu Cheng",
        "Erik Blasch",
        "Tyler Derr"
      ],
      "abstract": "Recently, Knowledge Graphs (KGs) have been successfully coupled with Large\nLanguage Models (LLMs) to mitigate their hallucinations and enhance their\nreasoning capability, such as in KG-based retrieval-augmented frameworks.\nHowever, current KG-LLM frameworks lack rigorous uncertainty estimation,\nlimiting their reliable deployment in high-stakes applications. Directly\nincorporating uncertainty quantification into KG-LLM frameworks presents\nchallenges due to their complex architectures and the intricate interactions\nbetween the knowledge graph and language model components. To address this gap,\nwe propose a new trustworthy KG-LLM framework, Uncertainty Aware\nKnowledge-Graph Reasoning (UAG), which incorporates uncertainty quantification\ninto the KG-LLM framework. We design an uncertainty-aware multi-step reasoning\nframework that leverages conformal prediction to provide a theoretical\nguarantee on the prediction set. To manage the error rate of the multi-step\nprocess, we additionally introduce an error rate control module to adjust the\nerror rate within the individual components. Extensive experiments show that\nour proposed UAG can achieve any pre-defined coverage rate while reducing the\nprediction set/interval size by 40% on average over the baselines.",
      "tldr_zh": "该论文针对知识图谱(KGs)和大型语言模型(LLMs)框架中缺乏不确定性估计的问题，提出了一种可信的推理框架Uncertainty Aware Knowledge-Graph Reasoning (UAG)。UAG设计了不确定性感知的多步推理机制，利用conformal prediction提供理论上的预测集保证，并引入错误率控制模块来调整多步过程中的错误率。实验结果显示，UAG能够在保持预定义覆盖率的同时，平均将预测集/区间大小减少40%，从而提升框架在高风险应用中的可靠性和效率。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08985v2",
      "published_date": "2024-10-11 16:57:30 UTC",
      "updated_date": "2024-10-20 19:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:13:12.755798"
    },
    {
      "arxiv_id": "2410.08979v3",
      "title": "Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control",
      "title_zh": "克服连续控制中的慢决策频率：基于模型的序列强化学习用于模型无关控制",
      "authors": [
        "Devdhar Patel",
        "Hava Siegelmann"
      ],
      "abstract": "Reinforcement learning (RL) is rapidly reaching and surpassing human-level\ncontrol capabilities. However, state-of-the-art RL algorithms often require\ntimesteps and reaction times significantly faster than human capabilities,\nwhich is impractical in real-world settings and typically necessitates\nspecialized hardware. We introduce Sequence Reinforcement Learning (SRL), an RL\nalgorithm designed to produce a sequence of actions for a given input state,\nenabling effective control at lower decision frequencies. SRL addresses the\nchallenges of learning action sequences by employing both a model and an\nactor-critic architecture operating at different temporal scales. We propose a\n\"temporal recall\" mechanism, where the critic uses the model to estimate\nintermediate states between primitive actions, providing a learning signal for\neach individual action within the sequence. Once training is complete, the\nactor can generate action sequences independently of the model, achieving\nmodel-free control at a slower frequency. We evaluate SRL on a suite of\ncontinuous control tasks, demonstrating that it achieves performance comparable\nto state-of-the-art algorithms while significantly reducing actor sample\ncomplexity. To better assess performance across varying decision frequencies,\nwe introduce the Frequency-Averaged Score (FAS) metric. Our results show that\nSRL significantly outperforms traditional RL algorithms in terms of FAS, making\nit particularly suitable for applications requiring variable decision\nfrequencies. Furthermore, we compare SRL with model-based online planning,\nshowing that SRL achieves comparable FAS while leveraging the same model during\ntraining that online planners use for planning. Lastly, we highlight the\nbiological relevance of SRL, showing that it replicates the \"action chunking\"\nbehavior observed in the basal ganglia, offering insights into brain-inspired\ncontrol mechanisms.",
      "tldr_zh": "这篇论文提出 Sequence Reinforcement Learning (SRL) 算法，以解决强化学习 (RL) 在连续控制中决策频率过高的实际挑战。SRL 通过结合模型和 actor-critic 架构，以及 temporal recall 机制，来学习动作序列，从而在较低决策频率下实现高效控制，并在训练后实现模型无关的控制。实验结果显示，SRL 在连续控制任务上与最先进算法性能相当，同时显著降低了 actor 的样本复杂度，并通过引入 Frequency-Averaged Score (FAS) 指标，展示了其在不同频率下的优越表现。此外，SRL 模仿了基底神经节的 action chunking 行为，提供对脑部控制机制的生物学启示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.08979v3",
      "published_date": "2024-10-11 16:54:07 UTC",
      "updated_date": "2025-03-04 03:11:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:13:25.749579"
    },
    {
      "arxiv_id": "2410.08976v2",
      "title": "Learning Representations of Instruments for Partial Identification of Treatment Effects",
      "title_zh": "翻译失败",
      "authors": [
        "Jonas Schweisthal",
        "Dennis Frauen",
        "Maresa Schröder",
        "Konstantin Hess",
        "Niki Kilbertus",
        "Stefan Feuerriegel"
      ],
      "abstract": "Reliable estimation of treatment effects from observational data is important\nin many disciplines such as medicine. However, estimation is challenging when\nunconfoundedness as a standard assumption in the causal inference literature is\nviolated. In this work, we leverage arbitrary (potentially high-dimensional)\ninstruments to estimate bounds on the conditional average treatment effect\n(CATE). Our contributions are three-fold: (1) We propose a novel approach for\npartial identification through a mapping of instruments to a discrete\nrepresentation space so that we yield valid bounds on the CATE. This is crucial\nfor reliable decision-making in real-world applications. (2) We derive a\ntwo-step procedure that learns tight bounds using a tailored neural\npartitioning of the latent instrument space. As a result, we avoid instability\nissues due to numerical approximations or adversarial training. Furthermore,\nour procedure aims to reduce the estimation variance in finite-sample settings\nto yield more reliable estimates. (3) We show theoretically that our procedure\nobtains valid bounds while reducing estimation variance. We further perform\nextensive experiments to demonstrate the effectiveness across various settings.\nOverall, our procedure offers a novel path for practitioners to make use of\npotentially high-dimensional instruments (e.g., as in Mendelian randomization).",
      "tldr_zh": "本文提出了一种利用工具变量（instruments）的方法，来部分识别治疗效果（treatment effects），以应对因果推断中 unconfoundedness 假设被违反时的挑战。具体而言，该方法通过将工具变量映射到离散表示空间，并采用一个两步过程，包括定制的神经分区（neural partitioning），来学习条件平均治疗效果（CATE）的紧密边界，同时减少估计方差。理论分析证明了该过程能提供有效的边界，并在各种实验设置中验证了其有效性，为从业者使用高维工具变量（如在孟德尔随机化中）提供了可靠的新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08976v2",
      "published_date": "2024-10-11 16:48:32 UTC",
      "updated_date": "2024-10-14 08:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:13:37.628884"
    },
    {
      "arxiv_id": "2410.08972v1",
      "title": "ALVIN: Active Learning Via INterpolation",
      "title_zh": "翻译失败",
      "authors": [
        "Michalis Korakakis",
        "Andreas Vlachos",
        "Adrian Weller"
      ],
      "abstract": "Active Learning aims to minimize annotation effort by selecting the most\nuseful instances from a pool of unlabeled data. However, typical active\nlearning methods overlook the presence of distinct example groups within a\nclass, whose prevalence may vary, e.g., in occupation classification datasets\ncertain demographics are disproportionately represented in specific classes.\nThis oversight causes models to rely on shortcuts for predictions, i.e.,\nspurious correlations between input attributes and labels occurring in\nwell-represented groups. To address this issue, we propose Active Learning Via\nINterpolation (ALVIN), which conducts intra-class interpolations between\nexamples from under-represented and well-represented groups to create anchors,\ni.e., artificial points situated between the example groups in the\nrepresentation space. By selecting instances close to the anchors for\nannotation, ALVIN identifies informative examples exposing the model to regions\nof the representation space that counteract the influence of shortcuts.\nCrucially, since the model considers these examples to be of high certainty,\nthey are likely to be ignored by typical active learning methods. Experimental\nresults on six datasets encompassing sentiment analysis, natural language\ninference, and paraphrase detection demonstrate that ALVIN outperforms\nstate-of-the-art active learning methods in both in-distribution and\nout-of-distribution generalization.",
      "tldr_zh": "本文提出 ALVIN，一种新型主动学习(Active Learning)方法，针对传统方法忽略类别内子群体分布不均的问题，导致模型依赖捷径(shortcuts)进行预测。ALVIN 通过在欠表示和优势表示子群体之间进行类别内插值(intra-class interpolations)，创建锚点(anchors)，并选择靠近这些锚点的样本进行标注，从而帮助模型暴露并对抗捷径影响的表示空间区域。实验结果显示，在六个涵盖情感分析、自然语言推理和释义检测的数据集上，ALVIN 在分布内和分布外泛化(out-of-distribution generalization)方面均优于现有主动学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to EMNLP 2024 (Main)",
      "pdf_url": "http://arxiv.org/pdf/2410.08972v1",
      "published_date": "2024-10-11 16:44:39 UTC",
      "updated_date": "2024-10-11 16:44:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:13:59.039849"
    },
    {
      "arxiv_id": "2410.08970v2",
      "title": "NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Yi Ho",
        "Siyuan Liang",
        "Sen Zhang",
        "Yibing Zhan",
        "Dacheng Tao"
      ],
      "abstract": "Hallucinations in Large Language Models (LLMs) remain a major obstacle,\nparticularly in high-stakes applications where factual accuracy is critical.\nWhile representation editing and reading methods have made strides in reducing\nhallucinations, their heavy reliance on specialised tools and training on\nin-domain samples, makes them difficult to scale and prone to overfitting. This\nlimits their accuracy gains and generalizability to diverse datasets. This\npaper presents a lightweight method, Norm Voting (NoVo), which harnesses the\nuntapped potential of attention head norms to dramatically enhance factual\naccuracy in zero-shot multiple-choice questions (MCQs). NoVo begins by\nautomatically selecting truth-correlated head norms with an efficient,\ninference-only algorithm using only 30 random samples, allowing NoVo to\neffortlessly scale to diverse datasets. Afterwards, selected head norms are\nemployed in a simple voting algorithm, which yields significant gains in\nprediction accuracy. On TruthfulQA MC1, NoVo surpasses the current\nstate-of-the-art and all previous methods by an astounding margin -- at least\n19 accuracy points. NoVo demonstrates exceptional generalization to 20 diverse\ndatasets, with significant gains in over 90\\% of them, far exceeding all\ncurrent representation editing and reading methods. NoVo also reveals promising\ngains to finetuning strategies and building textual adversarial defence. NoVo's\neffectiveness with head norms opens new frontiers in LLM interpretability,\nrobustness and reliability.",
      "tldr_zh": "这篇论文提出了一种轻量级方法 NoVo（Norm Voting），利用 attention head norms 来减少 Large Language Models (LLMs) 中的 hallucinations，从而提升事实准确性，尤其在零-shot multiple-choice questions (MCQs) 上。NoVo 通过一个高效的推理-only 算法，仅用 30 个随机样本自动选择与真相相关的 head norms，然后应用简单的投票机制进行预测。实验结果显示，在 TruthfulQA MC1 数据集上，NoVo 比当前最先进方法提高至少 19 个准确率点，并在 20 个多样数据集中的 90% 以上实现了显著提升。该方法还为 LLM 的 finetuning 策略和文本对抗防御提供了新颖的改进路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08970v2",
      "published_date": "2024-10-11 16:40:03 UTC",
      "updated_date": "2024-10-29 05:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:14:12.869014"
    },
    {
      "arxiv_id": "2410.08968v2",
      "title": "Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements",
      "title_zh": "可控安全对齐：针对多样化安全要求的推理时适应",
      "authors": [
        "Jingyu Zhang",
        "Ahmed Elgohary",
        "Ahmed Magooda",
        "Daniel Khashabi",
        "Benjamin Van Durme"
      ],
      "abstract": "The current paradigm for safety alignment of large language models (LLMs)\nfollows a one-size-fits-all approach: the model refuses to interact with any\ncontent deemed unsafe by the model provider. This approach lacks flexibility in\nthe face of varying social norms across cultures and regions. In addition,\nusers may have diverse safety needs, making a model with static safety\nstandards too restrictive to be useful, as well as too costly to be re-aligned.\n  We propose Controllable Safety Alignment (CoSA), a framework designed to\nadapt models to diverse safety requirements without re-training. Instead of\naligning a fixed model, we align models to follow safety configs -- free-form\nnatural language descriptions of the desired safety behaviors -- that are\nprovided as part of the system prompt. To adjust model safety behavior,\nauthorized users only need to modify such safety configs at inference time. To\nenable that, we propose CoSAlign, a data-centric method for aligning LLMs to\neasily adapt to diverse safety configs. Furthermore, we devise a novel\ncontrollability evaluation protocol that considers both helpfulness and\nconfigured safety, summarizing them into CoSA-Score, and construct CoSApien, a\nhuman-authored benchmark that consists of real-world LLM use cases with diverse\nsafety requirements and corresponding evaluation prompts. We show that CoSAlign\nleads to substantial gains of controllability over strong baselines including\nin-context alignment. Our framework encourages better representation and\nadaptation to pluralistic human values in LLMs, and thereby increasing their\npracticality.",
      "tldr_zh": "当前的安全对齐方法采用“一刀切”策略，导致大型语言模型(LLMs)无法灵活适应不同文化和社会规范下的多样安全需求。论文提出Controllable Safety Alignment (CoSA)框架，通过在推理时使用自由形式的“safety configs”描述来调整模型行为，而无需重新训练。作者开发了CoSAlign方法，这是一种数据中心的方法，帮助LLMs轻松适应各种安全配置，并引入了CoSA-Score和CoSApien基准进行评估。实验结果显示，CoSAlign在可控性上显著优于基线模型，如in-context alignment，从而提升了LLMs在代表多元人类价值观方面的实用性和适应性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ICLR 2025 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2410.08968v2",
      "published_date": "2024-10-11 16:38:01 UTC",
      "updated_date": "2025-03-03 22:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:14:24.738776"
    },
    {
      "arxiv_id": "2410.08964v3",
      "title": "Language Imbalance Driven Rewarding for Multilingual Self-improving",
      "title_zh": "翻译失败",
      "authors": [
        "Wen Yang",
        "Junhong Wu",
        "Chen Wang",
        "Chengqing Zong",
        "Jiajun Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have achieved state-of-the-art performance\nacross numerous tasks. However, these advancements have predominantly benefited\n\"first-class\" languages such as English and Chinese, leaving many other\nlanguages underrepresented. This imbalance, while limiting broader\napplications, generates a natural preference ranking between languages,\noffering an opportunity to bootstrap the multilingual capabilities of LLM in a\nself-improving manner. Thus, we propose $\\textit{Language Imbalance Driven\nRewarding}$, where the inherent imbalance between dominant and non-dominant\nlanguages within LLMs is leveraged as a reward signal. Iterative DPO training\ndemonstrates that this approach not only enhances LLM performance in\nnon-dominant languages but also improves the dominant language's capacity,\nthereby yielding an iterative reward signal. Fine-tuning\nMeta-Llama-3-8B-Instruct over two iterations of this approach results in\ncontinuous improvements in multilingual performance across\ninstruction-following and arithmetic reasoning tasks, evidenced by an average\nimprovement of 7.46% win rate on the X-AlpacaEval leaderboard and 13.9%\naccuracy on the MGSM benchmark. This work serves as an initial exploration,\npaving the way for multilingual self-improvement of LLMs. The code is available\nat https://github.com/ZNLP/Language-Imbalance-Driven-Rewarding",
      "tldr_zh": "本研究针对大型语言模型（LLMs）在主流语言（如英语和中文）上表现优异，而其他语言落后的不平衡问题，提出 Language Imbalance Driven Rewarding 方法，利用语言不平衡作为奖励信号进行迭代 DPO 训练。  \n这种方法不仅提升了非主流语言的性能，还进一步改善了主流语言的能力，形成持续的迭代奖励机制。  \n在 Meta-Llama-3-8B-Instruct 模型上进行两次迭代微调后，多语言性能显著提高，在 X-AlpacaEval 排行榜上平均胜率提升 7.46%，在 MGSM 基准上准确率提升 13.9%。  \n这项工作为 LLMs 的多语言自提升提供了初步探索路径，并开源了相关代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Camera ready version for ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08964v3",
      "published_date": "2024-10-11 16:32:05 UTC",
      "updated_date": "2025-02-26 12:39:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:14:34.598605"
    },
    {
      "arxiv_id": "2410.08961v1",
      "title": "Evaluating Federated Kolmogorov-Arnold Networks on Non-IID Data",
      "title_zh": "翻译失败",
      "authors": [
        "Arthur Mendonça Sasse",
        "Claudio Miceli de Farias"
      ],
      "abstract": "Federated Kolmogorov-Arnold Networks (F-KANs) have already been proposed, but\ntheir assessment is at an initial stage. We present a comparison between KANs\n(using B-splines and Radial Basis Functions as activation functions) and Multi-\nLayer Perceptrons (MLPs) with a similar number of parameters for 100 rounds of\nfederated learning in the MNIST classification task using non-IID partitions\nwith 100 clients. After 15 trials for each model, we show that the best\naccuracies achieved by MLPs can be achieved by Spline-KANs in half of the time\n(in rounds), with just a moderate increase in computing time.",
      "tldr_zh": "本研究评估了Federated Kolmogorov-Arnold Networks (F-KANs) 在non-IID数据上的性能，通过比较KANs（使用B-splines和Radial Basis Functions作为激活函数）和参数相似的Multi-Layer Perceptrons (MLPs)。实验在MNIST分类任务中进行100轮联邦学习，每个模型重复15次试验。结果显示，Spline-KANs可以在一半的轮次内达到MLPs的最佳准确率，尽管计算时间略有增加。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 5 figures, for associated code see\n  https://github.com/artsasse/fedkan",
      "pdf_url": "http://arxiv.org/pdf/2410.08961v1",
      "published_date": "2024-10-11 16:30:04 UTC",
      "updated_date": "2024-10-11 16:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:14:55.808724"
    },
    {
      "arxiv_id": "2410.08950v1",
      "title": "On the Adversarial Transferability of Generalized \"Skip Connections\"",
      "title_zh": "翻译失败",
      "authors": [
        "Yisen Wang",
        "Yichuan Mo",
        "Dongxian Wu",
        "Mingjie Li",
        "Xingjun Ma",
        "Zhouchen Lin"
      ],
      "abstract": "Skip connection is an essential ingredient for modern deep models to be\ndeeper and more powerful. Despite their huge success in normal scenarios\n(state-of-the-art classification performance on natural examples), we\ninvestigate and identify an interesting property of skip connections under\nadversarial scenarios, namely, the use of skip connections allows easier\ngeneration of highly transferable adversarial examples. Specifically, in\nResNet-like models (with skip connections), we find that using more gradients\nfrom the skip connections rather than the residual modules according to a decay\nfactor during backpropagation allows one to craft adversarial examples with\nhigh transferability. The above method is termed as Skip Gradient Method (SGM).\nAlthough starting from ResNet-like models in vision domains, we further extend\nSGM to more advanced architectures, including Vision Transformers (ViTs) and\nmodels with length-varying paths and other domains, i.e. natural language\nprocessing. We conduct comprehensive transfer attacks against various models\nincluding ResNets, Transformers, Inceptions, Neural Architecture Search, and\nLarge Language Models (LLMs). We show that employing SGM can greatly improve\nthe transferability of crafted attacks in almost all cases. Furthermore,\nconsidering the big complexity for practical use, we further demonstrate that\nSGM can even improve the transferability on ensembles of models or targeted\nattacks and the stealthiness against current defenses. At last, we provide\ntheoretical explanations and empirical insights on how SGM works. Our findings\nnot only motivate new adversarial research into the architectural\ncharacteristics of models but also open up further challenges for secure model\narchitecture design. Our code is available at https://github.com/mo666666/SGM.",
      "tldr_zh": "本研究探讨了“skip connections”在对抗场景下的转移性问题，发现其允许更容易生成高度可转移的对抗样本。作者提出Skip Gradient Method (SGM)，通过在反向传播中根据衰减因子优先使用skip connections的梯度，而非残差模块，来提升对抗样本的转移性，并将其扩展到Vision Transformers (ViTs)、自然语言处理等领域。实验结果显示，SGM在对ResNets、Transformers、Inceptions、Neural Architecture Search和Large Language Models (LLMs)等各种模型的转移攻击中，大幅提高了攻击成功率，甚至增强了针对模型集合的隐蔽性。总体而言，该方法不仅提供了对抗转移性的理论解释，还为安全模型架构设计带来了新挑战。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08950v1",
      "published_date": "2024-10-11 16:17:47 UTC",
      "updated_date": "2024-10-11 16:17:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:15:08.318839"
    },
    {
      "arxiv_id": "2410.08949v2",
      "title": "Transferable Belief Model on Quantum Circuits",
      "title_zh": "翻译失败",
      "authors": [
        "Qianli Zhou",
        "Hao Luo",
        "Lipeng Pan",
        "Yong Deng",
        "Eloi Bosse"
      ],
      "abstract": "The transferable belief model, as a semantic interpretation of\nDempster-Shafer theory, enables agents to perform reasoning and decision making\nin imprecise and incomplete environments. The model offers distinct semantics\nfor handling unreliable testimonies, allowing for a more reasonable and general\nprocess of belief transfer compared to the Bayesian approach. However, because\nboth the belief masses and the structure of focal sets must be considered when\nupdating belief functions-leading to extra computational complexity during\nreasoning-the transferable belief model has gradually lost favor among\nresearchers in recent developments. In this paper, we implement the\ntransferable belief model on quantum circuits and demonstrate that belief\nfunctions offer a more concise and effective alternative to Bayesian approaches\nwithin the quantum computing framework. Furthermore, leveraging the unique\ncharacteristics of quantum computing, we propose several novel belief transfer\napproaches. More broadly, this paper introduces a new perspective on basic\ninformation representation for quantum AI models, suggesting that belief\nfunctions are more suitable than Bayesian approach for handling uncertainty on\nquantum circuits.",
      "tldr_zh": "本文在量子电路中实现了 Transferable Belief Model（作为 Dempster-Shafer theory 的语义解释），以提升代理在不精确和不完整环境下的推理和决策能力。该模型在处理不可靠证言时比 Bayesian approach 更合理和通用，但传统计算复杂度较高。研究通过量子计算框架证明了信念函数的更新过程更简洁有效，并提出几种新型信念转移方法。作为更广泛贡献，这为量子 AI 模型的基本信息表示提供了新视角，建议信念函数更适合处理量子电路上的不确定性。",
      "categories": [
        "cs.AI",
        "quant-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08949v2",
      "published_date": "2024-10-11 16:17:20 UTC",
      "updated_date": "2024-10-17 11:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:15:10.663218"
    },
    {
      "arxiv_id": "2410.08947v1",
      "title": "Meta-Transfer Learning Empowered Temporal Graph Networks for Cross-City Real Estate Appraisal",
      "title_zh": "基于元转移学习的时序图网络用于跨城市房地产评估",
      "authors": [
        "Weijia Zhang",
        "Jindong Han",
        "Hao Liu",
        "Wei Fan",
        "Hao Wang",
        "Hui Xiong"
      ],
      "abstract": "Real estate appraisal is important for a variety of endeavors such as real\nestate deals, investment analysis, and real property taxation. Recently, deep\nlearning has shown great promise for real estate appraisal by harnessing\nsubstantial online transaction data from web platforms. Nonetheless, deep\nlearning is data-hungry, and thus it may not be trivially applicable to\nenormous small cities with limited data. To this end, we propose Meta-Transfer\nLearning Empowered Temporal Graph Networks (MetaTransfer) to transfer valuable\nknowledge from multiple data-rich metropolises to the data-scarce city to\nimprove valuation performance. Specifically, by modeling the ever-growing real\nestate transactions with associated residential communities as a temporal event\nheterogeneous graph, we first design an Event-Triggered Temporal Graph Network\nto model the irregular spatiotemporal correlations between evolving real estate\ntransactions. Besides, we formulate the city-wide real estate appraisal as a\nmulti-task dynamic graph link label prediction problem, where the valuation of\neach community in a city is regarded as an individual task. A\nHypernetwork-Based Multi-Task Learning module is proposed to simultaneously\nfacilitate intra-city knowledge sharing between multiple communities and\ntask-specific parameters generation to accommodate the community-wise real\nestate price distribution. Furthermore, we propose a Tri-Level Optimization\nBased Meta- Learning framework to adaptively re-weight training transaction\ninstances from multiple source cities to mitigate negative transfer, and thus\nimprove the cross-city knowledge transfer effectiveness. Finally, extensive\nexperiments based on five real-world datasets demonstrate the significant\nsuperiority of MetaTransfer compared with eleven baseline algorithms.",
      "tldr_zh": "这篇论文提出 Meta-Transfer Learning Empowered Temporal Graph Networks (MetaTransfer) 方法，用于解决房地产评估在数据稀缺小城市中的挑战，通过从数据丰富的城市转移知识来提升估值性能。具体地，该方法将房地产交易建模为时间事件异构图，并设计 Event-Triggered Temporal Graph Network 来捕捉不规则时空相关性，同时引入 Hypernetwork-Based Multi-Task Learning 模块促进城市内部社区知识共享和任务特定参数生成。此外，Tri-Level Optimization Based Meta-Learning 框架被用于适应性调整源城市训练实例权重，减少负面转移；实验在五个真实数据集上证明，MetaTransfer 比 11 个基线算法表现出显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.08947v1",
      "published_date": "2024-10-11 16:16:38 UTC",
      "updated_date": "2024-10-11 16:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:15:22.234750"
    },
    {
      "arxiv_id": "2410.08948v1",
      "title": "The Dynamics of Social Conventions in LLM populations: Spontaneous Emergence, Collective Biases and Tipping Points",
      "title_zh": "LLM 群体中社会惯例的动态：自发涌现、集体",
      "authors": [
        "Ariel Flint Ashery",
        "Luca Maria Aiello",
        "Andrea Baronchelli"
      ],
      "abstract": "Social conventions are the foundation for social and economic life. As\nlegions of AI agents increasingly interact with each other and with humans,\ntheir ability to form shared conventions will determine how effectively they\nwill coordinate behaviors, integrate into society and influence it. Here, we\ninvestigate the dynamics of conventions within populations of Large Language\nModel (LLM) agents using simulated interactions. First, we show that globally\naccepted social conventions can spontaneously arise from local interactions\nbetween communicating LLMs. Second, we demonstrate how strong collective biases\ncan emerge during this process, even when individual agents appear to be\nunbiased. Third, we examine how minority groups of committed LLMs can drive\nsocial change by establishing new social conventions. We show that once these\nminority groups reach a critical size, they can consistently overturn\nestablished behaviors. In all cases, contrasting the experimental results with\npredictions from a minimal multi-agent model allows us to isolate the specific\nrole of LLM agents. Our results clarify how AI systems can autonomously develop\nnorms without explicit programming and have implications for designing AI\nsystems that align with human values and societal goals.",
      "tldr_zh": "本文研究了LLM（Large Language Model）代理人口中社会conventions的动态，通过模拟互动实验，展示了这些约定如何从本地互动中自发出现，以及如何导致集体biases的产生，即使个体代理看似无偏。研究进一步发现，少数派承诺LLM群体一旦达到tipping points的临界规模，就能推动社会变革并推翻既有行为。最终，通过与最小多代理模型的对比，论文阐明了AI系统无需显式编程即可自主发展规范，并为设计与人类价值观和社会目标一致的AI系统提供了重要启示。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CY",
        "physics.soc-ph"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08948v1",
      "published_date": "2024-10-11 16:16:38 UTC",
      "updated_date": "2024-10-11 16:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:15:33.889029"
    },
    {
      "arxiv_id": "2410.08942v1",
      "title": "Maximizing the Potential of Synthetic Data: Insights from Random Matrix Theory",
      "title_zh": "最大化合成数据的潜力：来自随机矩阵理论的见解",
      "authors": [
        "Aymane El Firdoussi",
        "Mohamed El Amine Seddik",
        "Soufiane Hayou",
        "Reda Alami",
        "Ahmed Alzubaidi",
        "Hakim Hacid"
      ],
      "abstract": "Synthetic data has gained attention for training large language models, but\npoor-quality data can harm performance (see, e.g., Shumailov et al. (2023);\nSeddik et al. (2024)). A potential solution is data pruning, which retains only\nhigh-quality data based on a score function (human or machine feedback).\nPrevious work Feng et al. (2024) analyzed models trained on synthetic data as\nsample size increases. We extend this by using random matrix theory to derive\nthe performance of a binary classifier trained on a mix of real and pruned\nsynthetic data in a high dimensional setting. Our findings identify conditions\nwhere synthetic data could improve performance, focusing on the quality of the\ngenerative model and verification strategy. We also show a smooth phase\ntransition in synthetic label noise, contrasting with prior sharp behavior in\ninfinite sample limits. Experiments with toy models and large language models\nvalidate our theoretical results.",
      "tldr_zh": "这篇论文使用Random Matrix Theory分析合成数据在训练二元分类器中的潜力，扩展了之前的工作，聚焦于混合真实数据和修剪后合成数据的高维设置。研究发现，合成数据的质量（取决于生成模型和验证策略）是决定性能提升的关键条件，并揭示了合成标签噪声的平滑相变，与先前无限样本极限中的急剧行为形成对比。通过玩具模型和大型语言模型的实验，论文验证了这些理论insights，强调了数据修剪在避免低质量数据负面影响方面的作用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08942v1",
      "published_date": "2024-10-11 16:09:27 UTC",
      "updated_date": "2024-10-11 16:09:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:15:45.958838"
    },
    {
      "arxiv_id": "2410.08928v2",
      "title": "Towards Multilingual LLM Evaluation for European Languages",
      "title_zh": "迈向欧洲语言的多语言LLM评估",
      "authors": [
        "Klaudia Thellmann",
        "Bernhard Stadler",
        "Michael Fromm",
        "Jasper Schulze Buschhoff",
        "Alex Jude",
        "Fabio Barth",
        "Johannes Leveling",
        "Nicolas Flores-Herr",
        "Joachim Köhler",
        "René Jäkel",
        "Mehdi Ali"
      ],
      "abstract": "The rise of Large Language Models (LLMs) has revolutionized natural language\nprocessing across numerous languages and tasks. However, evaluating LLM\nperformance in a consistent and meaningful way across multiple European\nlanguages remains challenging, especially due to the scarcity of\nlanguage-parallel multilingual benchmarks. We introduce a multilingual\nevaluation approach tailored for European languages. We employ translated\nversions of five widely-used benchmarks to assess the capabilities of 40 LLMs\nacross 21 European languages. Our contributions include examining the\neffectiveness of translated benchmarks, assessing the impact of different\ntranslation services, and offering a multilingual evaluation framework for LLMs\nthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,\nEU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly\navailable to encourage further research in multilingual LLM evaluation.",
      "tldr_zh": "该研究针对大型语言模型 (LLMs) 在欧洲语言中的性能评估问题，提出了一种多语言评估方法，以解决缺乏语言平行基准的挑战。作者使用翻译版本的五种基准（如 EU20-MMLU、EU20-HellaSwag、EU20-ARC、EU20-TruthfulQA 和 EU20-GSM8K）评估 40 个 LLMs 在 21 种欧洲语言中的能力，并考察了翻译服务的有效性和影响。最终，该框架及其数据集被公开分享，以推动多语言 LLM 评估的进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08928v2",
      "published_date": "2024-10-11 15:53:24 UTC",
      "updated_date": "2024-10-17 17:58:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:15:58.389347"
    },
    {
      "arxiv_id": "2410.08926v3",
      "title": "Zero-Shot Pupil Segmentation with SAM 2: A Case Study of Over 14 Million Images",
      "title_zh": "零样本瞳孔分割与 SAM 2：超过 1400 万张图像的案例研究",
      "authors": [
        "Virmarie Maquiling",
        "Sean Anthony Byrne",
        "Diederick C. Niehorster",
        "Marco Carminati",
        "Enkelejda Kasneci"
      ],
      "abstract": "We explore the transformative potential of SAM 2, a vision foundation model,\nin advancing gaze estimation and eye tracking technologies. By significantly\nreducing annotation time, lowering technical barriers through its ease of\ndeployment, and enhancing segmentation accuracy, SAM 2 addresses critical\nchallenges faced by researchers and practitioners. Utilizing its zero-shot\nsegmentation capabilities with minimal user input-a single click per video-we\ntested SAM 2 on over 14 million eye images from diverse datasets, including\nvirtual reality setups and the world's largest unified dataset recorded using\nwearable eye trackers. Remarkably, in pupil segmentation tasks, SAM 2 matches\nthe performance of domain-specific models trained solely on eye images,\nachieving competitive mean Intersection over Union (mIoU) scores of up to 93%\nwithout fine-tuning. Additionally, we provide our code and segmentation masks\nfor these widely used datasets to promote further research.",
      "tldr_zh": "本文研究了SAM 2视觉基础模型在零样本瞳孔分割(pupil segmentation)中的潜力，通过只需每个视频一个点击的简单输入，处理了超过1400万张眼睛图像，包括VR设置和大型可穿戴眼动跟踪数据集。SAM 2显著减少了标注时间、降低了技术门槛，并实现了与专门训练的领域模型相当的性能，最高mIoU分数达93%，无需微调。研究者提供了代码和分割掩码，促进注视估计(gaze estimation)和眼动跟踪(eye tracking)领域的进一步发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "Virmarie Maquiling and Sean Anthony Byrne contributed equally to this\n  paper, 8 pages, 3 figures, ETRA 2025, pre-print",
      "pdf_url": "http://arxiv.org/pdf/2410.08926v3",
      "published_date": "2024-10-11 15:50:53 UTC",
      "updated_date": "2025-01-13 15:19:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:16:09.616543"
    },
    {
      "arxiv_id": "2410.08925v3",
      "title": "An Overview of Prototype Formulations for Interpretable Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Maximilian Xiling Li",
        "Korbinian Franz Rudolf",
        "Nils Blank",
        "Rudolf Lioutikov"
      ],
      "abstract": "Prototypical part networks offer interpretable alternatives to black-box deep\nlearning models. However, many of these networks rely on Euclidean prototypes,\nwhich may limit their flexibility. This work provides a comprehensive overview\nof various prototype formulations. Experiments conducted on the CUB-200-2011,\nStanford Cars, and Oxford Flowers datasets demonstrate the effectiveness and\nversatility of these different formulations.",
      "tldr_zh": "该论文概述了用于可解释深度学习的各种原型形式，旨在提供比依赖 Euclidean prototypes 的 prototypical part networks 更灵活的替代方案。作者讨论了这些网络的多种公式，以解决传统黑箱深度学习模型的局限性。在 CUB-200-2011、Stanford Cars 和 Oxford Flowers 数据集上的实验证明了这些公式的有效性和多功能性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Equal Contribution of M.X.Li and K.F.Rudolf",
      "pdf_url": "http://arxiv.org/pdf/2410.08925v3",
      "published_date": "2024-10-11 15:50:31 UTC",
      "updated_date": "2025-02-13 10:00:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:16:20.851018"
    },
    {
      "arxiv_id": "2410.08922v1",
      "title": "Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning",
      "title_zh": "探索使用 AI 生成代码的认知参与技术的设计空间，以增强学习",
      "authors": [
        "Majeed Kazemitabaar",
        "Oliver Huang",
        "Sangho Suh",
        "Austin Z. Henley",
        "Tovi Grossman"
      ],
      "abstract": "Novice programmers are increasingly relying on Large Language Models (LLMs)\nto generate code for learning programming concepts. However, this interaction\ncan lead to superficial engagement, giving learners an illusion of learning and\nhindering skill development. To address this issue, we conducted a systematic\ndesign exploration to develop seven cognitive engagement techniques aimed at\npromoting deeper engagement with AI-generated code. In this paper, we describe\nour design process, the initial seven techniques and results from a\nbetween-subjects study (N=82). We then iteratively refined the top techniques\nand further evaluated them through a within-subjects study (N=42). We evaluate\nthe friction each technique introduces, their effectiveness in helping learners\napply concepts to isomorphic tasks without AI assistance, and their success in\naligning learners' perceived and actual coding abilities. Ultimately, our\nresults highlight the most effective technique: guiding learners through the\nstep-by-step problem-solving process, where they engage in an interactive\ndialog with the AI, prompting what needs to be done at each stage before the\ncorresponding code is revealed.",
      "tldr_zh": "本研究探讨了新手程序员使用 Large Language Models (LLMs) 生成代码可能导致浅层参与和学习假象的问题，旨在通过系统设计探索开发七种 cognitive engagement techniques 来提升学习深度。研究者通过一个分组实验 (N=82) 和一个内部实验 (N=42) 评估了这些技术的摩擦、帮助学习者独立应用概念到相似任务的效果，以及校准感知和实际编码能力的表现。最终发现，最有效的技术是引导学习者通过逐步问题解决过程，与AI进行互动对话，在每个阶段提示操作后揭示代码，从而促进更真实的学习成果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "19 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.08922v1",
      "published_date": "2024-10-11 15:49:42 UTC",
      "updated_date": "2024-10-11 15:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:16:34.377534"
    },
    {
      "arxiv_id": "2410.08920v1",
      "title": "Efficient Hyperparameter Importance Assessment for CNNs",
      "title_zh": "针对 CNNs 的高效超参数重要性评估",
      "authors": [
        "Ruinan Wang",
        "Ian Nabney",
        "Mohammad Golbabaee"
      ],
      "abstract": "Hyperparameter selection is an essential aspect of the machine learning\npipeline, profoundly impacting models' robustness, stability, and\ngeneralization capabilities. Given the complex hyperparameter spaces associated\nwith Neural Networks and the constraints of computational resources and time,\noptimizing all hyperparameters becomes impractical. In this context, leveraging\nhyperparameter importance assessment (HIA) can provide valuable guidance by\nnarrowing down the search space. This enables machine learning practitioners to\nfocus their optimization efforts on the hyperparameters with the most\nsignificant impact on model performance while conserving time and resources.\nThis paper aims to quantify the importance weights of some hyperparameters in\nConvolutional Neural Networks (CNNs) with an algorithm called N-RReliefF,\nlaying the groundwork for applying HIA methodologies in the Deep Learning\nfield. We conduct an extensive study by training over ten thousand CNN models\nacross ten popular image classification datasets, thereby acquiring a\ncomprehensive dataset containing hyperparameter configuration instances and\ntheir corresponding performance metrics. It is demonstrated that among the\ninvestigated hyperparameters, the top five important hyperparameters of the CNN\nmodel are the number of convolutional layers, learning rate, dropout rate,\noptimizer and epoch.",
      "tldr_zh": "这篇论文针对机器学习中超参数选择的复杂性，提出了一种高效的超参数重要性评估 (HIA) 方法，以优化 Convolutional Neural Networks (CNNs) 的性能并节省资源。作者使用名为 N-RReliefF 的算法，通过在十个流行图像分类数据集上训练超过一万个 CNN 模型，量化了各超参数的影响。研究发现，CNN 模型中最关键的五个超参数是 number of convolutional layers、learning rate、dropout rate、optimizer 和 epoch，这为深度学习领域的 HIA 应用奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.08920v1",
      "published_date": "2024-10-11 15:47:46 UTC",
      "updated_date": "2024-10-11 15:47:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:16:46.073907"
    },
    {
      "arxiv_id": "2410.19760v1",
      "title": "Movie Trailer Genre Classification Using Multimodal Pretrained Features",
      "title_zh": "翻译失败",
      "authors": [
        "Serkan Sulun",
        "Paula Viana",
        "Matthew E. P. Davies"
      ],
      "abstract": "We introduce a novel method for movie genre classification, capitalizing on a\ndiverse set of readily accessible pretrained models. These models extract\nhigh-level features related to visual scenery, objects, characters, text,\nspeech, music, and audio effects. To intelligently fuse these pretrained\nfeatures, we train small classifier models with low time and memory\nrequirements. Employing the transformer model, our approach utilizes all video\nand audio frames of movie trailers without performing any temporal pooling,\nefficiently exploiting the correspondence between all elements, as opposed to\nthe fixed and low number of frames typically used by traditional methods. Our\napproach fuses features originating from different tasks and modalities, with\ndifferent dimensionalities, different temporal lengths, and complex\ndependencies as opposed to current approaches. Our method outperforms\nstate-of-the-art movie genre classification models in terms of precision,\nrecall, and mean average precision (mAP). To foster future research, we make\nthe pretrained features for the entire MovieNet dataset, along with our genre\nclassification code and the trained models, publicly available.",
      "tldr_zh": "本研究提出了一种新的电影类型分类方法，利用多模态预训练 features 从视觉场景、物体、人物、文本、语音、音乐和音频效果中提取高阶特征。方法通过训练小型分类器模型（如 Transformer）融合这些特征，处理所有视频和音频帧而不进行时间池化，从而高效捕捉元素间的复杂依赖关系。相比现有方法，该方法在精确率、召回率和 mAP 上实现了性能提升，并在 MovieNet 数据集上公开了预训练 features、代码和模型，以推动未来研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19760v1",
      "published_date": "2024-10-11 15:38:05 UTC",
      "updated_date": "2024-10-11 15:38:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:16:57.746782"
    },
    {
      "arxiv_id": "2410.08911v1",
      "title": "Test-driven Software Experimentation with LASSO: an LLM Benchmarking Example",
      "title_zh": "翻译失败",
      "authors": [
        "Marcus Kessel"
      ],
      "abstract": "Empirical software engineering faces a critical gap: the lack of standardized\ntools for rapid development and execution of Test-Driven Software Experiments\n(TDSEs) - that is, experiments that involve the execution of software subjects\nand the observation and analysis of their \"de facto\" run-time behavior. In this\npaper we present a general-purpose analysis platform called LASSO that provides\na minimal set of domain-specific languages and data structures to conduct\nTDSEs. By empowering users with an executable scripting language to design and\nexecute TDSEs, LASSO enables efficient evaluation of run-time semantics and\nexecution characteristics in addition to statically determined properties. We\npresent an example TDSE that demonstrates the practical benefits of LASSO's\nscripting capabilities for assessing the reliability of LLMs for code\ngeneration by means of a self-contained, reusable and extensible study script.\nThe LASSO platform is freely available at:\nhttps://softwareobservatorium.github.io/, and a demo video is available on\nYouTube: https://youtu.be/tzY9oNTWXzw",
      "tldr_zh": "该研究指出了软件工程领域在Test-Driven Software Experiments (TDSEs)方面缺乏标准化工具的问题，并介绍了LASSO平台，这是一个通用分析平台，提供最小化的领域特定语言和数据结构来设计和执行TDSEs。LASSO通过可执行脚本语言允许用户高效评估软件的运行时语义和执行特性，而不仅仅局限于静态属性。通过一个示例TDSE，该平台展示了评估Large Language Models (LLMs)代码生成可靠性的实际益处，包括自包含、可重用和可扩展的研究脚本。LASSO平台免费可用，并附带演示视频，网址为https://softwareobservatorium.github.io/。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "D.2.1; D.2.4; I.2.2; I.2.7"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08911v1",
      "published_date": "2024-10-11 15:32:48 UTC",
      "updated_date": "2024-10-11 15:32:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:17:10.869894"
    },
    {
      "arxiv_id": "2410.08900v2",
      "title": "A Benchmark for Cross-Domain Argumentative Stance Classification on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaqing Yuan",
        "Ruijie Xi",
        "Munindar P. Singh"
      ],
      "abstract": "Argumentative stance classification plays a key role in identifying authors'\nviewpoints on specific topics. However, generating diverse pairs of\nargumentative sentences across various domains is challenging. Existing\nbenchmarks often come from a single domain or focus on a limited set of topics.\nAdditionally, manual annotation for accurate labeling is time-consuming and\nlabor-intensive. To address these challenges, we propose leveraging platform\nrules, readily available expert-curated content, and large language models to\nbypass the need for human annotation. Our approach produces a multidomain\nbenchmark comprising 4,498 topical claims and 30,961 arguments from three\nsources, spanning 21 domains. We benchmark the dataset in fully supervised,\nzero-shot, and few-shot settings, shedding light on the strengths and\nlimitations of different methodologies. We release the dataset and code in this\nstudy at hidden for anonymity.",
      "tldr_zh": "本文提出一个跨领域 argumentative stance classification 基准数据集，针对社交媒体上作者观点识别的问题，解决现有基准受限于单一领域和手动标注的挑战。研究者利用平台规则、专家策划内容和 large language models 自动生成数据集，涵盖 21 个领域，共包含 4,498 个主题声明和 30,961 个论点。实验在 fully supervised、zero-shot 和 few-shot 设置下进行基准测试，揭示了不同方法的优势和局限性，并发布了数据集和代码以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by AAAI ICWSM 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08900v2",
      "published_date": "2024-10-11 15:20:11 UTC",
      "updated_date": "2024-11-15 23:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:17:22.294076"
    },
    {
      "arxiv_id": "2410.08899v2",
      "title": "Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective",
      "title_zh": "在数据结构和算法课程中使用 ChatGPT：助教的视角",
      "authors": [
        "Pooriya Jamie",
        "Reyhaneh Hajihashemi",
        "Sharareh Alipour"
      ],
      "abstract": "Integrating large language models (LLMs) like ChatGPT into computer science\neducation offers transformative potential for complex courses such as data\nstructures and algorithms (DSA). This study examines ChatGPT as a supplementary\ntool for teaching assistants (TAs), guided by structured prompts and human\noversight, to enhance instruction and student outcomes. A controlled experiment\ncompared traditional TA-led instruction with a hybrid approach where TAs used\nChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide\nfeedback. Structured prompts emphasized problem decomposition, real-world\ncontext, and code examples, enabling tailored support while mitigating\nover-reliance on AI. Results demonstrated the hybrid approach's efficacy, with\nstudents in the ChatGPT-assisted group scoring 16.50 points higher on average\nand excelling in advanced topics. However, ChatGPT's limitations necessitated\nTA verification. This framework highlights the dual role of LLMs: augmenting TA\nefficiency while ensuring accuracy through human oversight, offering a scalable\nsolution for human-AI collaboration in education.",
      "tldr_zh": "这篇论文探讨了将大型语言模型 (LLMs) 如 ChatGPT 整合到数据结构和算法 (DSA) 课程中的潜力，聚焦于 ChatGPT 作为教学助理 (TAs) 的辅助工具，通过结构化提示和人工监督来生成练习、解释概念并提供反馈。实验对比了传统 TA 教学与混合方法，结果显示使用 ChatGPT-4o 和 ChatGPT o1 的学生平均得分提高了 16.50 分，尤其在高级主题上表现出色。虽有 ChatGPT 的局限性需 TAs 验证，但该框架展示了 LLMs 在教育中提升效率并确保准确性的可扩展性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.DS",
        "K.3.2; I.2.6"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted at CHI EA '25 (Extended Abstracts of the CHI Conference on\n  Human Factors in Computing Systems, 2025). The final version is available at\n  the External DOI",
      "pdf_url": "http://arxiv.org/pdf/2410.08899v2",
      "published_date": "2024-10-11 15:18:48 UTC",
      "updated_date": "2025-03-02 16:12:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:17:35.092185"
    },
    {
      "arxiv_id": "2410.09134v1",
      "title": "Multi-Agent Actor-Critics in Autonomous Cyber Defense",
      "title_zh": "翻译失败",
      "authors": [
        "Mingjun Wang",
        "Remington Dechene"
      ],
      "abstract": "The need for autonomous and adaptive defense mechanisms has become paramount\nin the rapidly evolving landscape of cyber threats. Multi-Agent Deep\nReinforcement Learning (MADRL) presents a promising approach to enhancing the\nefficacy and resilience of autonomous cyber operations. This paper explores the\napplication of Multi-Agent Actor-Critic algorithms which provides a general\nform in Multi-Agent learning to cyber defense, leveraging the collaborative\ninteractions among multiple agents to detect, mitigate, and respond to cyber\nthreats. We demonstrate each agent is able to learn quickly and counter act on\nthe threats autonomously using MADRL in simulated cyber-attack scenarios. The\nresults indicate that MADRL can significantly enhance the capability of\nautonomous cyber defense systems, paving the way for more intelligent\ncybersecurity strategies. This study contributes to the growing body of\nknowledge on leveraging artificial intelligence for cybersecurity and sheds\nlight for future research and development in autonomous cyber operations.",
      "tldr_zh": "本论文探讨了 Multi-Agent Actor-Critic 算法在自主网络防御中的应用，利用 Multi-Agent Deep Reinforcement Learning (MADRL) 让多个代理通过协作交互来检测、缓解和响应网络威胁。研究通过模拟网络攻击场景，展示了代理能够快速学习并自主对抗威胁。结果表明，MADRL 显著提升了自主网络防御系统的效能，并为人工智能在网络安全领域的未来发展提供了重要启示。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages. 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.09134v1",
      "published_date": "2024-10-11 15:15:09 UTC",
      "updated_date": "2024-10-11 15:15:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:17:49.466571"
    },
    {
      "arxiv_id": "2410.08894v1",
      "title": "Conditional Generative Models for Contrast-Enhanced Synthesis of T1w and T1 Maps in Brain MRI",
      "title_zh": "条件生成模型用于大脑 MRI 中 T1w 和 T1 映射的对比增强合成",
      "authors": [
        "Moritz Piening",
        "Fabian Altekrüger",
        "Gabriele Steidl",
        "Elke Hattingen",
        "Eike Steidl"
      ],
      "abstract": "Contrast enhancement by Gadolinium-based contrast agents (GBCAs) is a vital\ntool for tumor diagnosis in neuroradiology. Based on brain MRI scans of\nglioblastoma before and after Gadolinium administration, we address enhancement\nprediction by neural networks with two new contributions. Firstly, we study the\npotential of generative models, more precisely conditional diffusion and flow\nmatching, for uncertainty quantification in virtual enhancement. Secondly, we\nexamine the performance of T1 scans from quantitive MRI versus T1-weighted\nscans. In contrast to T1-weighted scans, these scans have the advantage of a\nphysically meaningful and thereby comparable voxel range. To compare network\nprediction performance of these two modalities with incompatible gray-value\nscales, we propose to evaluate segmentations of contrast-enhanced regions of\ninterest using Dice and Jaccard scores. Across models, we observe better\nsegmentations with T1 scans than with T1-weighted scans.",
      "tldr_zh": "本研究探讨了使用条件生成模型（如条件扩散和流匹配）来合成脑MRI的T1加权（T1w）和T1扫描图像，以预测Gadolinium-based contrast agents (GBCAs)的对比增强效果，从而辅助神经胶质母细胞瘤诊断。研究首次评估这些生成模型在增强预测的不确定性量化方面的潜力，并比较了T1扫描（具有物理意义的可比体素范围）和T1-weighted scans的性能。结果显示，通过Dice和Jaccard分数评估对比增强区域分割时，T1扫描比T1-weighted scans表现出更好的性能，为非侵入性肿瘤诊断提供了更可靠的方法。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08894v1",
      "published_date": "2024-10-11 15:11:24 UTC",
      "updated_date": "2024-10-11 15:11:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:17:57.038656"
    },
    {
      "arxiv_id": "2410.08893v4",
      "title": "Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient",
      "title_zh": "翻译失败",
      "authors": [
        "Wenlong Wang",
        "Ivana Dusparic",
        "Yucheng Shi",
        "Ke Zhang",
        "Vinny Cahill"
      ],
      "abstract": "Model-based reinforcement learning (RL) offers a solution to the data\ninefficiency that plagues most model-free RL algorithms. However, learning a\nrobust world model often requires complex and deep architectures, which are\ncomputationally expensive and challenging to train. Within the world model,\nsequence models play a critical role in accurate predictions, and various\narchitectures have been explored, each with its own challenges. Currently,\nrecurrent neural network (RNN)-based world models struggle with vanishing\ngradients and capturing long-term dependencies. Transformers, on the other\nhand, suffer from the quadratic memory and computational complexity of\nself-attention mechanisms, scaling as $O(n^2)$, where $n$ is the sequence\nlength.\n  To address these challenges, we propose a state space model (SSM)-based world\nmodel, Drama, specifically leveraging Mamba, that achieves $O(n)$ memory and\ncomputational complexity while effectively capturing long-term dependencies and\nenabling efficient training with longer sequences. We also introduce a novel\nsampling method to mitigate the suboptimality caused by an incorrect world\nmodel in the early training stages. Combining these techniques, Drama achieves\na normalised score on the Atari100k benchmark that is competitive with other\nstate-of-the-art (SOTA) model-based RL algorithms, using only a 7\nmillion-parameter world model. Drama is accessible and trainable on\noff-the-shelf hardware, such as a standard laptop. Our code is available at\nhttps://github.com/realwenlongwang/Drama.git.",
      "tldr_zh": "这篇论文提出 Drama，一种基于 Mamba 状态空间模型 (SSM) 的模型-based 强化学习方法，旨在解决传统序列模型（如 RNN 和 Transformer）在世界模型中的效率问题，例如 RNN 的梯度消失和 Transformer 的 O(n^2) 计算复杂度。Drama 通过实现 O(n) 的内存和计算复杂度来捕捉长期依赖，并引入一种新采样方法来缓解早期训练阶段世界模型不准确导致的次优性。实验结果显示，Drama 在 Atari100k 基准上仅使用 7 百万参数就达到了与 SOTA 算法相当的标准化分数，并能在标准笔记本电脑上轻松训练和部署。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08893v4",
      "published_date": "2024-10-11 15:10:40 UTC",
      "updated_date": "2025-05-16 15:49:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:18:10.019089"
    },
    {
      "arxiv_id": "2410.08892v2",
      "title": "Federated Learning in Practice: Reflections and Projections",
      "title_zh": "联邦学习在实践中的应用：反思与展望",
      "authors": [
        "Katharine Daly",
        "Hubert Eichner",
        "Peter Kairouz",
        "H. Brendan McMahan",
        "Daniel Ramage",
        "Zheng Xu"
      ],
      "abstract": "Federated Learning (FL) is a machine learning technique that enables multiple\nentities to collaboratively learn a shared model without exchanging their local\ndata. Over the past decade, FL systems have achieved substantial progress,\nscaling to millions of devices across various learning domains while offering\nmeaningful differential privacy (DP) guarantees. Production systems from\norganizations like Google, Apple, and Meta demonstrate the real-world\napplicability of FL. However, key challenges remain, including verifying\nserver-side DP guarantees and coordinating training across heterogeneous\ndevices, limiting broader adoption. Additionally, emerging trends such as large\n(multi-modal) models and blurred lines between training, inference, and\npersonalization challenge traditional FL frameworks. In response, we propose a\nredefined FL framework that prioritizes privacy principles rather than rigid\ndefinitions. We also chart a path forward by leveraging trusted execution\nenvironments and open-source ecosystems to address these challenges and\nfacilitate future advancements in FL.",
      "tldr_zh": "这篇论文回顾了Federated Learning (FL) 的实际应用和发展，FL 是一种允许多个实体协作训练共享模型而不交换本地数据的机器学习技术，已扩展到数百万设备并提供差分隐私 (DP) 保证，如 Google、Apple 和 Meta 的生产系统所示。论文指出了关键挑战，包括验证服务器端 DP 保证和协调异构设备训练，以及新兴趋势如大型多模态模型和训练与推理边界的模糊，这些因素限制了 FL 的更广泛采用。为应对这些问题，作者提出重新定义 FL 框架，强调隐私原则而非刚性规则，并建议利用受信任执行环境和开源生态系统来推动未来进步。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at 2024 IEEE 6th International Conference on Trust, Privacy\n  and Security in Intelligent Systems, and Applications (TPS-ISA)",
      "pdf_url": "http://arxiv.org/pdf/2410.08892v2",
      "published_date": "2024-10-11 15:10:38 UTC",
      "updated_date": "2025-03-03 04:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:18:24.766743"
    },
    {
      "arxiv_id": "2410.19759v1",
      "title": "PINNing Cerebral Blood Flow: Analysis of Perfusion MRI in Infants using Physics-Informed Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Christoforos Galazis",
        "Ching-En Chiu",
        "Tomoki Arichi",
        "Anil A. Bharath",
        "Marta Varela"
      ],
      "abstract": "Arterial spin labeling (ASL) magnetic resonance imaging (MRI) enables\ncerebral perfusion measurement, which is crucial in detecting and managing\nneurological issues in infants born prematurely or after perinatal\ncomplications. However, cerebral blood flow (CBF) estimation in infants using\nASL remains challenging due to the complex interplay of network physiology,\ninvolving dynamic interactions between cardiac output and cerebral perfusion,\nas well as issues with parameter uncertainty and data noise. We propose a new\nspatial uncertainty-based physics-informed neural network (PINN), SUPINN, to\nestimate CBF and other parameters from infant ASL data. SUPINN employs a\nmulti-branch architecture to concurrently estimate regional and global model\nparameters across multiple voxels. It computes regional spatial uncertainties\nto weigh the signal. SUPINN can reliably estimate CBF (relative error $-0.3 \\pm\n71.7$), bolus arrival time (AT) ($30.5 \\pm 257.8$), and blood longitudinal\nrelaxation time ($T_{1b}$) ($-4.4 \\pm 28.9$), surpassing parameter estimates\nperformed using least squares or standard PINNs. Furthermore, SUPINN produces\nphysiologically plausible spatially smooth CBF and AT maps. Our study\ndemonstrates the successful modification of PINNs for accurate multi-parameter\nperfusion estimation from noisy and limited ASL data in infants. Frameworks\nlike SUPINN have the potential to advance our understanding of the complex\ncardio-brain network physiology, aiding in the detection and management of\ndiseases. Source code is provided at: https://github.com/cgalaz01/supinn.",
      "tldr_zh": "该研究针对婴儿 ASL MRI 数据中大脑血流（CBF）估计的挑战，提出了一种基于空间不确定性的物理信息神经网络（SUPINN），以处理参数不确定性和数据噪声问题。SUPINN 采用多分支架构，同时估计多个体素的区域和全局参数，并通过计算区域空间不确定性来加权信号，从而实现对 CBF、bolus arrival time (AT) 和 blood longitudinal relaxation time (T_{1b}) 的可靠估计。实验结果显示，SUPINN 的估计精度优于最小二乘法或标准 PINNs，分别在 CBF、AT 和 T_{1b} 上取得了较低的相对误差，并生成了生理上合理的空间平滑 CBF 和 AT 地图。该框架有望提升对 cardio-brain 网络生理学的理解，并辅助婴儿神经疾病的检测和管理。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.19759v1",
      "published_date": "2024-10-11 15:07:04 UTC",
      "updated_date": "2024-10-11 15:07:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:18:34.531847"
    },
    {
      "arxiv_id": "2410.08886v1",
      "title": "Bank Loan Prediction Using Machine Learning Techniques",
      "title_zh": "使用机器学习技术的银行贷款预测",
      "authors": [
        "F M Ahosanul Haque",
        "Md. Mahedi Hassan"
      ],
      "abstract": "Banks are important for the development of economies in any financial\necosystem through consumer and business loans. Lending, however, presents\nrisks; thus, banks have to determine the applicant's financial position to\nreduce the probabilities of default. A number of banks have currently,\ntherefore, adopted data analytics and state-of-the-art technology to arrive at\nbetter decisions in the process. The probability of payback is prescribed by a\npredictive modeling technique in which machine learning algorithms are applied.\nIn this research project, we will apply several machine learning methods to\nfurther improve the accuracy and efficiency of loan approval processes. Our\nwork focuses on the prediction of bank loan approval; we have worked on a\ndataset of 148,670 instances and 37 attributes using machine learning methods.\nThe target property segregates the loan applications into \"Approved\" and\n\"Denied\" groups. various machine learning techniques have been used, namely,\nDecision Tree Categorization, AdaBoosting, Random Forest Classifier, SVM, and\nGaussianNB. Following that, the models were trained and evaluated. Among these,\nthe best-performing algorithm was AdaBoosting, which achieved an incredible\naccuracy of 99.99%. The results therefore show how ensemble learning works\neffectively to improve the prediction skills of loan approval decisions. The\npresented work points to the possibility of achieving extremely accurate and\nefficient loan prediction models that provide useful insights for applying\nmachine learning to financial domains.",
      "tldr_zh": "本研究旨在通过机器学习技术预测银行贷款审批结果，以降低贷款违约风险并提升决策效率。研究团队使用 Decision Tree Categorization、AdaBoosting、Random Forest Classifier、SVM 和 GaussianNB 等算法，对一个包含 148,670 实例和 37 属性的数据集进行训练和评估。结果显示，AdaBoosting 算法表现出色，达到了 99.99% 的准确率，突显了 ensemble learning 在提高贷款预测性能方面的优势。该工作为机器学习在金融领域的实际应用提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 18 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.08886v1",
      "published_date": "2024-10-11 15:01:47 UTC",
      "updated_date": "2024-10-11 15:01:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:18:45.674971"
    },
    {
      "arxiv_id": "2410.12855v2",
      "title": "JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Fan Liu",
        "Yue Feng",
        "Zhao Xu",
        "Lixin Su",
        "Xinyu Ma",
        "Dawei Yin",
        "Hao Liu"
      ],
      "abstract": "Despite advancements in enhancing LLM safety against jailbreak attacks,\nevaluating LLM defenses remains a challenge, with current methods often lacking\nexplainability and generalization to complex scenarios, leading to incomplete\nassessments (e.g., direct judgment without reasoning, low F1 score of GPT-4 in\ncomplex cases, bias in multilingual scenarios). To address this, we present\nJAILJUDGE, a comprehensive benchmark featuring diverse risk scenarios,\nincluding synthetic, adversarial, in-the-wild, and multilingual prompts, along\nwith high-quality human-annotated datasets. The JAILJUDGE dataset includes over\n35k+ instruction-tune data with reasoning explainability and JAILJUDGETEST, a\n4.5k+ labeled set for risk scenarios, and a 6k+ multilingual set across ten\nlanguages. To enhance evaluation with explicit reasoning, we propose the\nJailJudge MultiAgent framework, which enables explainable, fine-grained scoring\n(1 to 10). This framework supports the construction of instruction-tuning\nground truth and facilitates the development of JAILJUDGE Guard, an end-to-end\njudge model that provides reasoning and eliminates API costs. Additionally, we\nintroduce JailBoost, an attacker-agnostic attack enhancer, and GuardShield, a\nmoderation defense, both leveraging JAILJUDGE Guard. Our experiments\ndemonstrate the state-of-the-art performance of JailJudge methods (JailJudge\nMultiAgent, JAILJUDGE Guard) across diverse models (e.g., GPT-4, Llama-Guard)\nand zero-shot scenarios. JailBoost and GuardShield significantly improve\njailbreak attack and defense tasks under zero-shot settings, with JailBoost\nenhancing performance by 29.24% and GuardShield reducing defense ASR from\n40.46% to 0.15%.",
      "tldr_zh": "本研究提出JAILJUDGE，一个全面的基准，用于评估LLM对抗越狱攻击的安全性，解决现有方法缺乏可解释性和泛化性的问题。该基准包括超过35k+指令调整数据和4.5k+标记的风险场景数据集，以及6k+多语言集，涵盖合成、对抗、野外和多语言提示。研究引入JailJudge MultiAgent框架，提供细粒度评分（1-10分）和可解释推理，支持开发JAILJUDGE Guard模型，同时推出JailBoost攻击增强器和GuardShield防御机制。实验结果显示，JailJudge方法在各种模型（如GPT-4和Llama-Guard）上达到最先进性能，JailBoost提升攻击性能29.24%，GuardShield将防御ASR从40.46%降至0.15%。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.12855v2",
      "published_date": "2024-10-11 14:56:28 UTC",
      "updated_date": "2024-10-18 02:35:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:18:58.928297"
    },
    {
      "arxiv_id": "2410.08875v1",
      "title": "Online design of dynamic networks",
      "title_zh": "动态网络的在线设计",
      "authors": [
        "Duo Wang",
        "Andrea Araldo",
        "Mounim El Yacoubi"
      ],
      "abstract": "Designing a network (e.g., a telecommunication or transport network) is\nmainly done offline, in a planning phase, prior to the operation of the\nnetwork. On the other hand, a massive effort has been devoted to characterizing\ndynamic networks, i.e., those that evolve over time. The novelty of this paper\nis that we introduce a method for the online design of dynamic networks. The\nneed to do so emerges when a network needs to operate in a dynamic and\nstochastic environment. In this case, one may wish to build a network over\ntime, on the fly, in order to react to the changes of the environment and to\nkeep certain performance targets. We tackle this online design problem with a\nrolling horizon optimization based on Monte Carlo Tree Search. The potential of\nonline network design is showcased for the design of a futuristic dynamic\npublic transport network, where bus lines are constructed on the fly to better\nadapt to a stochastic user demand. In such a scenario, we compare our results\nwith state-of-the-art dynamic vehicle routing problem (VRP) resolution methods,\nsimulating requests from a New York City taxi dataset. Differently from classic\nVRP methods, that extend vehicle trajectories in isolation, our method enables\nus to build a structured network of line buses, where complex user journeys are\npossible, thus increasing system performance.",
      "tldr_zh": "本论文提出一种在线设计动态网络的方法，针对网络在动态和随机环境中的实时适应需求，相比传统离线规划更能应对环境变化。该方法利用滚动地平线优化（rolling horizon optimization）结合 Monte Carlo Tree Search 算法，实现网络的实时构建和优化。在一个未来主义公共交通场景中，通过模拟纽约市出租车数据集，该方法构建结构化的巴士线路网络，支持复杂用户旅程，并比经典动态车辆路径问题 (VRP) 方法提高了系统性能。",
      "categories": [
        "cs.AI",
        "cs.SI",
        "physics.soc-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.08875v1",
      "published_date": "2024-10-11 14:50:31 UTC",
      "updated_date": "2024-10-11 14:50:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:19:09.987068"
    },
    {
      "arxiv_id": "2410.08874v1",
      "title": "Experiments with Choice in Dependently-Typed Higher-Order Logic",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel Ranalter",
        "Chad E. Brown",
        "Cezary Kaliszyk"
      ],
      "abstract": "Recently an extension to higher-order logic -- called DHOL -- was introduced,\nenriching the language with dependent types, and creating a powerful\nextensional type theory. In this paper we propose two ways how choice can be\nadded to DHOL. We extend the DHOL term structure by Hilbert's indefinite choice\noperator $\\epsilon$, define a translation of the choice terms to HOL choice\nthat extends the existing translation from DHOL to HOL and show that the\nextension of the translation is complete and give an argument for soundness. We\nfinally evaluate the extended translation on a set of dependent HOL problems\nthat require choice.",
      "tldr_zh": "本论文探讨了在依类型高阶逻辑（DHOL）中添加选择（choice）运算符的两种方法，以扩展其功能。研究者扩展了DHOL的术语结构，引入了Hilbert's indefinite choice operator $\\epsilon$，并定义了从DHOL到HOL的翻译扩展，同时证明了该扩展的完整性（completeness）和健全性（soundness）。最后，通过在一组需要choice的dependent HOL问题上进行评估，验证了方法的有效性。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "F.4.1; I.2.3"
      ],
      "primary_category": "cs.LO",
      "comment": "10 pages incl. references; published in the proceedings of LPAR25",
      "pdf_url": "http://arxiv.org/pdf/2410.08874v1",
      "published_date": "2024-10-11 14:49:45 UTC",
      "updated_date": "2024-10-11 14:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:19:21.985863"
    },
    {
      "arxiv_id": "2410.08864v1",
      "title": "The Good, the Bad and the Ugly: Watermarks, Transferable Attacks and Adversarial Defenses",
      "title_zh": "翻译失败",
      "authors": [
        "Grzegorz Głuch",
        "Berkant Turan",
        "Sai Ganesh Nagarajan",
        "Sebastian Pokutta"
      ],
      "abstract": "We formalize and extend existing definitions of backdoor-based watermarks and\nadversarial defenses as interactive protocols between two players. The\nexistence of these schemes is inherently tied to the learning tasks for which\nthey are designed. Our main result shows that for almost every discriminative\nlearning task, at least one of the two -- a watermark or an adversarial defense\n-- exists. The term \"almost every\" indicates that we also identify a third,\ncounterintuitive but necessary option, i.e., a scheme we call a transferable\nattack. By transferable attack, we refer to an efficient algorithm computing\nqueries that look indistinguishable from the data distribution and fool all\nefficient defenders. To this end, we prove the necessity of a transferable\nattack via a construction that uses a cryptographic tool called homomorphic\nencryption. Furthermore, we show that any task that satisfies our notion of a\ntransferable attack implies a cryptographic primitive, thus requiring the\nunderlying task to be computationally complex. These two facts imply an\n\"equivalence\" between the existence of transferable attacks and cryptography.\nFinally, we show that the class of tasks of bounded VC-dimension has an\nadversarial defense, and a subclass of them has a watermark.",
      "tldr_zh": "本论文形式化地将后门水印（backdoor-based watermarks）和对抗防御（adversarial defenses）定义为两个玩家之间的交互协议，并证明对于几乎所有判别学习任务，至少存在水印、防御或一个新的选项——可转移攻击（transferable attack）。可转移攻击是一种高效算法，能生成与数据分布相似但能欺骗所有高效防御者的查询，并通过同态加密（homomorphic encryption）证明其必要性；此外，该攻击的存在等价于密码学原语，意味着任务需具备计算复杂性。最后，论文显示，VC维有限的任务类具有对抗防御，而其子类则具有水印方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "68T01, 94A60, 91A99"
      ],
      "primary_category": "cs.LG",
      "comment": "42 pages, 6 figures, preliminary version published in ICML 2024\n  (Workshop on Theoretical Foundations of Foundation Models), see\n  https://openreview.net/pdf?id=WMaFRiggwV",
      "pdf_url": "http://arxiv.org/pdf/2410.08864v1",
      "published_date": "2024-10-11 14:44:05 UTC",
      "updated_date": "2024-10-11 14:44:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:19:33.856247"
    },
    {
      "arxiv_id": "2410.08855v1",
      "title": "MATCH: Model-Aware TVM-based Compilation for Heterogeneous Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Amine Hamdi",
        "Francesco Daghero",
        "Giuseppe Maria Sarda",
        "Josse Van Delm",
        "Arne Symons",
        "Luca Benini",
        "Marian Verhelst",
        "Daniele Jahier Pagliari",
        "Alessio Burrello"
      ],
      "abstract": "Streamlining the deployment of Deep Neural Networks (DNNs) on heterogeneous\nedge platforms, coupling within the same micro-controller unit (MCU)\ninstruction processors and hardware accelerators for tensor computations, is\nbecoming one of the crucial challenges of the TinyML field.\n  The best-performing DNN compilation toolchains are usually deeply customized\nfor a single MCU family, and porting to a different heterogeneous MCU family\nimplies labor-intensive re-development of almost the entire compiler. On the\nopposite side, retargetable toolchains, such as TVM, fail to exploit the\ncapabilities of custom accelerators, resulting in the generation of general but\nunoptimized code. To overcome this duality, we introduce MATCH, a novel\nTVM-based DNN deployment framework designed for easy agile retargeting across\ndifferent MCU processors and accelerators, thanks to a customizable model-based\nhardware abstraction.\n  We show that a general and retargetable mapping framework enhanced with\nhardware cost models can compete with and even outperform custom toolchains on\ndiverse targets while only needing the definition of an abstract hardware model\nand a SoC-specific API.\n  We tested MATCH on two state-of-the-art heterogeneous MCUs, GAP9 and DIANA.\n  On the four DNN models of the MLPerf Tiny suite MATCH reduces inference\nlatency by up to 60.88 times on DIANA, compared to using the plain TVM, thanks\nto the exploitation of the on-board HW accelerator. Compared to HTVM, a fully\ncustomized toolchain for DIANA, we still reduce the latency by 16.94%. On GAP9,\nusing the same benchmarks, we improve the latency by 2.15 times compared to the\ndedicated DORY compiler, thanks to our heterogeneous DNN mapping approach that\nsynergically exploits the DNN accelerator and the eight-cores cluster available\non board.",
      "tldr_zh": "本论文提出 MATCH，一种基于 TVM 的编译框架，用于简化深度神经网络 (DNNs) 在异构边缘设备的部署，解决 TinyML 领域中微控制器 (MCU) 处理器和硬件加速器耦合的挑战。MATCH 通过可自定义的模型aware硬件抽象和硬件成本模型，实现对不同 MCU 家族的快速移植和优化，超越了传统定制工具链的局限。实验结果显示，在 MLPerf Tiny 套件的 DNN 模型上，MATCH 在 DIANA 设备上比纯 TVM 减少推理延迟高达 60.88 倍，并比自定义工具链 HTVM 减少 16.94%；在 GAP9 设备上，比 DORY 编译器减少延迟 2.15 倍，展示了其高效的异构映射能力。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "I.2.2; D.1.3"
      ],
      "primary_category": "cs.DC",
      "comment": "13 pages, 11 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.08855v1",
      "published_date": "2024-10-11 14:32:06 UTC",
      "updated_date": "2024-10-11 14:32:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:19:46.601547"
    },
    {
      "arxiv_id": "2410.08854v3",
      "title": "Hybrid LLM-DDQN based Joint Optimization of V2I Communication and Autonomous Driving",
      "title_zh": "翻译失败",
      "authors": [
        "Zijiang Yan",
        "Hao Zhou",
        "Hina Tabassum",
        "Xue Liu"
      ],
      "abstract": "Large language models (LLMs) have received considerable interest recently due\nto their outstanding reasoning and comprehension capabilities. This work\nexplores applying LLMs to vehicular networks, aiming to jointly optimize\nvehicle-to-infrastructure (V2I) communications and autonomous driving (AD)\npolicies. We deploy LLMs for AD decision-making to maximize traffic flow and\navoid collisions for road safety, and a double deep Q-learning algorithm (DDQN)\nis used for V2I optimization to maximize the received data rate and reduce\nfrequent handovers. In particular, for LLM-enabled AD, we employ the Euclidean\ndistance to identify previously explored AD experiences, and then LLMs can\nlearn from past good and bad decisions for further improvement. Then, LLM-based\nAD decisions will become part of states in V2I problems, and DDQN will optimize\nthe V2I decisions accordingly. After that, the AD and V2I decisions are\niteratively optimized until convergence. Such an iterative optimization\napproach can better explore the interactions between LLMs and conventional\nreinforcement learning techniques, revealing the potential of using LLMs for\nnetwork optimization and management. Finally, the simulations demonstrate that\nour proposed hybrid LLM-DDQN approach outperforms the conventional DDQN\nalgorithm, showing faster convergence and higher average rewards.",
      "tldr_zh": "这篇论文提出了一种混合框架，将大型语言模型 (LLMs) 与双深 Q 学习算法 (DDQN) 结合，用于联合优化车辆到基础设施 (V2I) 通信和自动驾驶 (AD) 策略。方法中，LLMs 通过欧氏距离识别过去的 AD 经验，从良好和不良决策中学习，以最大化交通流量并避免碰撞；同时，DDQN 优化 V2I 以提升接收数据率并减少频繁切换，并将 LLM 基于的 AD 决策作为状态进行迭代优化。模拟结果表明，该混合 LLM-DDQN 方法比传统 DDQN 算法具有更快收敛速度和更高平均奖励，展示了 LLMs 在网络优化中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IEEE Wireless Communications Letters",
      "pdf_url": "http://arxiv.org/pdf/2410.08854v3",
      "published_date": "2024-10-11 14:30:04 UTC",
      "updated_date": "2025-02-04 19:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:19:58.531965"
    },
    {
      "arxiv_id": "2410.08852v2",
      "title": "Conformalized Interactive Imitation Learning: Handling Expert Shift and Intermittent Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Michelle Zhao",
        "Reid Simmons",
        "Henny Admoni",
        "Aaditya Ramdas",
        "Andrea Bajcsy"
      ],
      "abstract": "In interactive imitation learning (IL), uncertainty quantification offers a\nway for the learner (i.e. robot) to contend with distribution shifts\nencountered during deployment by actively seeking additional feedback from an\nexpert (i.e. human) online. Prior works use mechanisms like ensemble\ndisagreement or Monte Carlo dropout to quantify when black-box IL policies are\nuncertain; however, these approaches can lead to overconfident estimates when\nfaced with deployment-time distribution shifts. Instead, we contend that we\nneed uncertainty quantification algorithms that can leverage the expert human\nfeedback received during deployment time to adapt the robot's uncertainty\nonline. To tackle this, we draw upon online conformal prediction, a\ndistribution-free method for constructing prediction intervals online given a\nstream of ground-truth labels. Human labels, however, are intermittent in the\ninteractive IL setting. Thus, from the conformal prediction side, we introduce\na novel uncertainty quantification algorithm called intermittent quantile\ntracking (IQT) that leverages a probabilistic model of intermittent labels,\nmaintains asymptotic coverage guarantees, and empirically achieves desired\ncoverage levels. From the interactive IL side, we develop ConformalDAgger, a\nnew approach wherein the robot uses prediction intervals calibrated by IQT as a\nreliable measure of deployment-time uncertainty to actively query for more\nexpert feedback. We compare ConformalDAgger to prior uncertainty-aware DAgger\nmethods in scenarios where the distribution shift is (and isn't) present\nbecause of changes in the expert's policy. We find that in simulated and\nhardware deployments on a 7DOF robotic manipulator, ConformalDAgger detects\nhigh uncertainty when the expert shifts and increases the number of\ninterventions compared to baselines, allowing the robot to more quickly learn\nthe new behavior.",
      "tldr_zh": "本研究针对交互式模仿学习(interactive imitation learning, IL)中分布偏移和间歇性专家反馈的问题，提出了一种新的不确定性量化算法intermittent quantile tracking (IQT)，它基于在线置信预测(online conformal prediction)，利用概率模型处理间歇性标签，并保持渐进覆盖保证。\nIQT 被整合到ConformalDAgger框架中，该方法使用校准的预测区间作为可靠的不确定性度量，允许机器人主动查询专家反馈以适应部署时的策略变化。\n实验结果显示，在模拟环境和7DOF机器人硬件部署中，ConformalDAgger相较于基线方法更准确地检测专家策略偏移，提高干预频率，从而帮助机器人更快地学习新行为。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08852v2",
      "published_date": "2024-10-11 14:27:56 UTC",
      "updated_date": "2025-04-29 12:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:20:10.696915"
    },
    {
      "arxiv_id": "2410.08847v4",
      "title": "Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Noam Razin",
        "Sadhika Malladi",
        "Adithya Bhaskar",
        "Danqi Chen",
        "Sanjeev Arora",
        "Boris Hanin"
      ],
      "abstract": "Direct Preference Optimization (DPO) and its variants are increasingly used\nfor aligning language models with human preferences. Although these methods are\ndesigned to teach a model to generate preferred responses more frequently\nrelative to dispreferred responses, prior work has observed that the likelihood\nof preferred responses often decreases during training. The current work sheds\nlight on the causes and implications of this counter-intuitive phenomenon,\nwhich we term likelihood displacement. We demonstrate that likelihood\ndisplacement can be catastrophic, shifting probability mass from preferred\nresponses to responses with an opposite meaning. As a simple example, training\na model to prefer $\\texttt{No}$ over $\\texttt{Never}$ can sharply increase the\nprobability of $\\texttt{Yes}$. Moreover, when aligning the model to refuse\nunsafe prompts, we show that such displacement can unintentionally lead to\nunalignment, by shifting probability mass from preferred refusal responses to\nharmful responses (e.g., reducing the refusal rate of Llama-3-8B-Instruct from\n74.4% to 33.4%). We theoretically characterize that likelihood displacement is\ndriven by preferences that induce similar embeddings, as measured by a centered\nhidden embedding similarity (CHES) score. Empirically, the CHES score enables\nidentifying which training samples contribute most to likelihood displacement\nin a given dataset. Filtering out these samples effectively mitigated\nunintentional unalignment in our experiments. More broadly, our results\nhighlight the importance of curating data with sufficiently distinct\npreferences, for which we believe the CHES score may prove valuable.",
      "tldr_zh": "本文研究了Direct Preference Optimization (DPO)训练中的likelihood displacement现象，即preferred responses的概率意外降低，导致模型可能将概率转移到相反含义的响应，例如训练偏好“No”胜过“Never”时，可能会增加“Yes”的概率。作者理论分析表明，这种现象由preferences导致的类似embeddings驱动，并引入centered hidden embedding similarity (CHES)得分来识别问题样本。实验证明，过滤CHES得分高的样本能有效缓解unintentional unalignment，例如显著提高模型的拒绝率，并强调了构建distinct preferences数据集的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to ICLR 2025; Code available at\n  https://github.com/princeton-nlp/unintentional-unalignment",
      "pdf_url": "http://arxiv.org/pdf/2410.08847v4",
      "published_date": "2024-10-11 14:22:44 UTC",
      "updated_date": "2025-04-27 15:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:20:22.400846"
    },
    {
      "arxiv_id": "2410.08841v1",
      "title": "Public Transport Network Design for Equality of Accessibility via Message Passing Neural Networks and Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Duo Wang",
        "Maximilien Chau",
        "Andrea Araldo"
      ],
      "abstract": "Designing Public Transport (PT) networks able to satisfy mobility needs of\npeople is essential to reduce the number of individual vehicles on the road,\nand thus pollution and congestion. Urban sustainability is thus tightly coupled\nto an efficient PT. Current approaches on Transport Network Design (TND)\ngenerally aim to optimize generalized cost, i.e., a unique number including\noperator and users' costs. Since we intend quality of PT as the capability of\nsatisfying mobility needs, we focus instead on PT accessibility, i.e., the ease\nof reaching surrounding points of interest via PT. PT accessibility is\ngenerally unequally distributed in urban regions: suburbs generally suffer from\npoor PT accessibility, which condemns residents therein to be dependent on\ntheir private cars. We thus tackle the problem of designing bus lines so as to\nminimize the inequality in the geographical distribution of accessibility. We\ncombine state-of-the-art Message Passing Neural Networks (MPNN) and\nReinforcement Learning. We show the efficacy of our method against\nmetaheuristics (classically used in TND) in a use case representing in\nsimplified terms the city of Montreal.",
      "tldr_zh": "该研究针对公共交通（Public Transport, PT）网络设计问题，旨在通过最小化可达性（accessibility）的地理分布不平等来提升城市可持续性，避免郊区居民过度依赖私人汽车。不同于传统方法优化总成本（generalized cost），本文专注于PT可达性，即方便到达周边兴趣点。作者提出了一种结合Message Passing Neural Networks (MPNN)和Reinforcement Learning (RL)的框架，用于设计巴士线路以均衡可达性分布。在简化版蒙特利尔城市的用例中，该方法比经典元启发式(metaheuristics)方法更有效，证明了其在Transport Network Design (TND)中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.08841v1",
      "published_date": "2024-10-11 14:16:58 UTC",
      "updated_date": "2024-10-11 14:16:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:20:33.529578"
    },
    {
      "arxiv_id": "2410.08833v2",
      "title": "Symmetry-Constrained Generation of Diverse Low-Bandgap Molecules with Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Akshay Subramanian",
        "James Damewood",
        "Juno Nam",
        "Kevin P. Greenman",
        "Avni P. Singhal",
        "Rafael Gómez-Bombarelli"
      ],
      "abstract": "Organic optoelectronic materials are a promising avenue for next-generation\nelectronic devices due to their solution processability, mechanical\nflexibility, and tunable electronic properties. In particular, near-infrared\n(NIR) sensitive molecules have unique applications in night-vision equipment\nand biomedical imaging. Molecular engineering has played a crucial role in\ndeveloping non-fullerene acceptors (NFAs) such as the Y-series molecules, which\nhave significantly improved the power conversion efficiency (PCE) of solar\ncells and enhanced spectral coverage in the NIR region. However, systematically\ndesigning molecules with targeted optoelectronic properties while ensuring\nsynthetic accessibility remains a challenge. To address this, we leverage\nstructural priors from domain-focused, patent-mined datasets of organic\nelectronic molecules using a symmetry-aware fragment decomposition algorithm\nand a fragment-constrained Monte Carlo Tree Search (MCTS) generator. Our\napproach generates candidates that retain symmetry constraints from the patent\ndataset, while also exhibiting red-shifted absorption, as validated by TD-DFT\ncalculations.",
      "tldr_zh": "本研究针对有机光电子材料的设计挑战，提出了一种基于Monte Carlo Tree Search (MCTS)的分子生成方法，旨在系统生成多样化的低带隙分子，同时确保合成可访问性和对称约束。该方法利用对称感知的碎片分解算法，从专利挖掘的数据集中提取结构先验，并结合碎片约束的MCTS生成器，专注于开发近红外(NIR)敏感分子，如非富勒烯受体(NFAs)，以提升太阳能电池的功率转换效率(PCE)和光谱覆盖。通过TD-DFT计算验证，结果显示生成的分子表现出红移吸收，显著提高了分子工程的可行性。",
      "categories": [
        "physics.chem-ph",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08833v2",
      "published_date": "2024-10-11 14:09:27 UTC",
      "updated_date": "2024-12-12 16:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:20:45.598302"
    },
    {
      "arxiv_id": "2410.08829v1",
      "title": "Unveiling Molecular Secrets: An LLM-Augmented Linear Model for Explainable and Calibratable Molecular Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoran Li",
        "Xu Sun",
        "Wanyu Lin",
        "Jiannong Cao"
      ],
      "abstract": "Explainable molecular property prediction is essential for various scientific\nfields, such as drug discovery and material science. Despite delivering\nintrinsic explainability, linear models struggle with capturing complex,\nnon-linear patterns. Large language models (LLMs), on the other hand, yield\naccurate predictions through powerful inference capabilities yet fail to\nprovide chemically meaningful explanations for their predictions. This work\nproposes a novel framework, called MoleX, which leverages LLM knowledge to\nbuild a simple yet powerful linear model for accurate molecular property\nprediction with faithful explanations. The core of MoleX is to model\ncomplicated molecular structure-property relationships using a simple linear\nmodel, augmented by LLM knowledge and a crafted calibration strategy.\nSpecifically, to extract the maximum amount of task-relevant knowledge from LLM\nembeddings, we employ information bottleneck-inspired fine-tuning and\nsparsity-inducing dimensionality reduction. These informative embeddings are\nthen used to fit a linear model for explainable inference. Moreover, we\nintroduce residual calibration to address prediction errors stemming from\nlinear models' insufficient expressiveness of complex LLM embeddings, thus\nrecovering the LLM's predictive power and boosting overall accuracy.\nTheoretically, we provide a mathematical foundation to justify MoleX's\nexplainability. Extensive experiments demonstrate that MoleX outperforms\nexisting methods in molecular property prediction, establishing a new milestone\nin predictive performance, explainability, and efficiency. In particular, MoleX\nenables CPU inference and accelerates large-scale dataset processing, achieving\ncomparable performance 300x faster with 100,000 fewer parameters than LLMs.\nAdditionally, the calibration improves model performance by up to 12.7% without\ncompromising explainability.",
      "tldr_zh": "本研究提出 MoleX 框架，利用 LLM 知识增强线性模型，实现分子属性预测的可解释性和校准，以解决线性模型捕捉非线性模式不足以及 LLM 缺乏化学解释的问题。核心方法包括信息瓶颈启发的微调、稀疏性诱导的降维来提取 LLM 嵌入，并结合残差校准策略提升预测准确性，同时提供理论数学基础证明其解释性。实验结果显示，MoleX 在分子属性预测中优于现有方法，实现 CPU 推理，比 LLM 快 300 倍、参数减少 10 万倍，并通过校准策略提升性能高达 12.7%，在预测性能、解释性和效率上树立新里程碑。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08829v1",
      "published_date": "2024-10-11 14:07:57 UTC",
      "updated_date": "2024-10-11 14:07:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:20:58.649560"
    },
    {
      "arxiv_id": "2410.08824v1",
      "title": "One-shot Generative Domain Adaptation in 3D GANs",
      "title_zh": "翻译失败",
      "authors": [
        "Ziqiang Li",
        "Yi Wu",
        "Chaoyue Wang",
        "Xue Rui",
        "Bin Li"
      ],
      "abstract": "3D-aware image generation necessitates extensive training data to ensure\nstable training and mitigate the risk of overfitting. This paper first\nconsiders a novel task known as One-shot 3D Generative Domain Adaptation (GDA),\naimed at transferring a pre-trained 3D generator from one domain to a new one,\nrelying solely on a single reference image. One-shot 3D GDA is characterized by\nthe pursuit of specific attributes, namely, high fidelity, large diversity,\ncross-domain consistency, and multi-view consistency. Within this paper, we\nintroduce 3D-Adapter, the first one-shot 3D GDA method, for diverse and\nfaithful generation. Our approach begins by judiciously selecting a restricted\nweight set for fine-tuning, and subsequently leverages four advanced loss\nfunctions to facilitate adaptation. An efficient progressive fine-tuning\nstrategy is also implemented to enhance the adaptation process. The synergy of\nthese three technological components empowers 3D-Adapter to achieve remarkable\nperformance, substantiated both quantitatively and qualitatively, across all\ndesired properties of 3D GDA. Furthermore, 3D-Adapter seamlessly extends its\ncapabilities to zero-shot scenarios, and preserves the potential for crucial\ntasks such as interpolation, reconstruction, and editing within the latent\nspace of the pre-trained generator. Code will be available at\nhttps://github.com/iceli1007/3D-Adapter.",
      "tldr_zh": "本论文提出了一种名为 One-shot 3D Generative Domain Adaptation (GDA) 的新任务，旨在仅凭一张参考图像将预训练的 3D GANs 生成器从一个领域转移到新领域，同时追求高保真度、大多样性、跨领域一致性和多视图一致性。作者引入了 3D-Adapter 方法，通过选择有限权重集进行微调、结合四个高级损失函数以及渐进式微调策略，实现高效且忠实的生成。实验结果显示，3D-Adapter 在所有期望属性上表现出色，并在定量和定性评估中取得显著提升，同时扩展到 zero-shot 场景，并支持潜在空间的插值、重构和编辑任务。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "IJCV",
      "pdf_url": "http://arxiv.org/pdf/2410.08824v1",
      "published_date": "2024-10-11 14:04:44 UTC",
      "updated_date": "2024-10-11 14:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:21:09.364203"
    },
    {
      "arxiv_id": "2410.08822v2",
      "title": "SOLD: Slot Object-Centric Latent Dynamics Models for Relational Manipulation Learning from Pixels",
      "title_zh": "翻译失败",
      "authors": [
        "Malte Mosbach",
        "Jan Niklas Ewertz",
        "Angel Villar-Corrales",
        "Sven Behnke"
      ],
      "abstract": "Learning a latent dynamics model provides a task-agnostic representation of\nan agent's understanding of its environment. Leveraging this knowledge for\nmodel-based reinforcement learning (RL) holds the potential to improve sample\nefficiency over model-free methods by learning from imagined rollouts.\nFurthermore, because the latent space serves as input to behavior models, the\ninformative representations learned by the world model facilitate efficient\nlearning of desired skills. Most existing methods rely on holistic\nrepresentations of the environment's state. In contrast, humans reason about\nobjects and their interactions, predicting how actions will affect specific\nparts of their surroundings. Inspired by this, we propose Slot-Attention for\nObject-centric Latent Dynamics (SOLD), a novel model-based RL algorithm that\nlearns object-centric dynamics models in an unsupervised manner from pixel\ninputs. We demonstrate that the structured latent space not only improves model\ninterpretability but also provides a valuable input space for behavior models\nto reason over. Our results show that SOLD outperforms DreamerV3 and TD-MPC2 -\nstate-of-the-art model-based RL algorithms - across a range of benchmark\nrobotic environments that require relational reasoning and manipulation\ncapabilities. Videos are available at https://slot-latent-dynamics.github.io/.",
      "tldr_zh": "该论文提出SOLD（Slot Object-Centric Latent Dynamics Models），一种基于模型的强化学习（RL）算法，通过无监督方式从像素输入中学习对象中心化的动态模型，以模拟人类对对象及其交互的推理。SOLD利用Slot-Attention机制构建结构化的潜在空间，提高了模型的可解释性和行为模型的效率，从而在关系推理和操作任务中增强性能。实验结果显示，SOLD在多个基准机器人环境中优于DreamerV3和TD-MPC2，显著提升样本效率和任务表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08822v2",
      "published_date": "2024-10-11 14:03:31 UTC",
      "updated_date": "2025-02-07 10:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:21:21.408840"
    },
    {
      "arxiv_id": "2410.08815v2",
      "title": "StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization",
      "title_zh": "StructRAG：通过推理时混合信息结构化提升大型语言模型的知识密集型推理",
      "authors": [
        "Zhuoqun Li",
        "Xuanang Chen",
        "Haiyang Yu",
        "Hongyu Lin",
        "Yaojie Lu",
        "Qiaoyu Tang",
        "Fei Huang",
        "Xianpei Han",
        "Le Sun",
        "Yongbin Li"
      ],
      "abstract": "Retrieval-augmented generation (RAG) is a key means to effectively enhance\nlarge language models (LLMs) in many knowledge-based tasks. However, existing\nRAG methods struggle with knowledge-intensive reasoning tasks, because useful\ninformation required to these tasks are badly scattered. This characteristic\nmakes it difficult for existing RAG methods to accurately identify key\ninformation and perform global reasoning with such noisy augmentation. In this\npaper, motivated by the cognitive theories that humans convert raw information\ninto various structured knowledge when tackling knowledge-intensive reasoning,\nwe proposes a new framework, StructRAG, which can identify the optimal\nstructure type for the task at hand, reconstruct original documents into this\nstructured format, and infer answers based on the resulting structure.\nExtensive experiments across various knowledge-intensive tasks show that\nStructRAG achieves state-of-the-art performance, particularly excelling in\nchallenging scenarios, demonstrating its potential as an effective solution for\nenhancing LLMs in complex real-world applications.",
      "tldr_zh": "本研究针对现有检索增强生成（RAG）方法在知识密集型任务中难以处理散乱信息和进行全局推理的问题，提出了一种新框架 StructRAG。StructRAG 受人类认知理论启发，通过推理时混合信息结构化来识别任务的最佳结构类型、重构原始文档，并基于该结构推断答案，从而提升大型语言模型（LLMs）的推理能力。在各种知识密集型任务上的广泛实验表明，StructRAG 实现了最先进性能，尤其在复杂场景中表现出色，具有在实际应用中增强 LLMs 的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08815v2",
      "published_date": "2024-10-11 13:52:44 UTC",
      "updated_date": "2024-10-25 12:18:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:21:33.399449"
    },
    {
      "arxiv_id": "2410.21286v1",
      "title": "OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM Agents",
      "title_zh": "OpenCity：一个可扩展平台，用于通过海量 LLM 代理模拟城市活动",
      "authors": [
        "Yuwei Yan",
        "Qingbin Zeng",
        "Zhiheng Zheng",
        "Jingzhe Yuan",
        "Jie Feng",
        "Jun Zhang",
        "Fengli Xu",
        "Yong Li"
      ],
      "abstract": "Agent-based models (ABMs) have long been employed to explore how individual\nbehaviors aggregate into complex societal phenomena in urban space. Unlike\nblack-box predictive models, ABMs excel at explaining the micro-macro linkages\nthat drive such emergent behaviors. The recent rise of Large Language Models\n(LLMs) has led to the development of LLM agents capable of simulating urban\nactivities with unprecedented realism. However, the extreme high computational\ncost of LLMs presents significant challenges for scaling up the simulations of\nLLM agents. To address this problem, we propose OpenCity, a scalable simulation\nplatform optimized for both system and prompt efficiencies. Specifically, we\npropose a LLM request scheduler to reduce communication overhead by\nparallelizing requests through IO multiplexing. Besides, we deisgn a\n\"group-and-distill\" prompt optimization strategy minimizes redundancy by\nclustering agents with similar static attributes. Through experiments on six\nglobal cities, OpenCity achieves a 600-fold acceleration in simulation time per\nagent, a 70% reduction in LLM requests, and a 50% reduction in token usage.\nThese improvements enable the simulation of 10,000 agents' daily activities in\n1 hour on commodity hardware. Besides, the substantial speedup of OpenCity\nallows us to establish a urban simulation benchmark for LLM agents for the\nfirst time, comparing simulated urban activities with real-world data in 6\nmajor cities around the globe. We believe our OpenCity platform provides a\ncritical infrastructure to harness the power of LLMs for interdisciplinary\nstudies in urban space, fostering the collective efforts of broader research\ncommunities. Code repo is available at\nhttps://anonymous.4open.science/r/Anonymous-OpenCity-42BD.",
      "tldr_zh": "本文提出 OpenCity，一个可扩展平台，用于模拟大规模 LLM agents 的城市活动，旨在解决 LLM 高计算成本带来的模拟规模问题。平台采用 LLM request scheduler 通过 IO multiplexing 平行化请求减少通信开销，以及\"group-and-distill\"提示优化策略聚类类似属性的代理以最小化冗余。在六个全球城市实验中，OpenCity 实现了每代理模拟时间加速 600 倍、LLM 请求减少 70% 以及令牌使用减少 50%，使 10,000 代理的日常活动模拟可在普通硬件上仅需 1 小时。该平台还建立了首个城市模拟基准，与真实世界数据比较，并为利用 LLMs 进行城市研究的跨学科研究提供关键基础设施。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21286v1",
      "published_date": "2024-10-11 13:52:35 UTC",
      "updated_date": "2024-10-11 13:52:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:21:47.096880"
    },
    {
      "arxiv_id": "2410.08811v1",
      "title": "PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning",
      "title_zh": "翻译失败",
      "authors": [
        "Tingchen Fu",
        "Mrinank Sharma",
        "Philip Torr",
        "Shay B. Cohen",
        "David Krueger",
        "Fazl Barez"
      ],
      "abstract": "Preference learning is a central component for aligning current LLMs, but\nthis process can be vulnerable to data poisoning attacks. To address this\nconcern, we introduce PoisonBench, a benchmark for evaluating large language\nmodels' susceptibility to data poisoning during preference learning. Data\npoisoning attacks can manipulate large language model responses to include\nhidden malicious content or biases, potentially causing the model to generate\nharmful or unintended outputs while appearing to function normally. We deploy\ntwo distinct attack types across eight realistic scenarios, assessing 21\nwidely-used models. Our findings reveal concerning trends: (1) Scaling up\nparameter size does not inherently enhance resilience against poisoning\nattacks; (2) There exists a log-linear relationship between the effects of the\nattack and the data poison ratio; (3) The effect of data poisoning can\ngeneralize to extrapolated triggers that are not included in the poisoned data.\nThese results expose weaknesses in current preference learning techniques,\nhighlighting the urgent need for more robust defenses against malicious models\nand data manipulation.",
      "tldr_zh": "本研究引入了 PoisonBench，这是一个基准，用于评估大型语言模型 (LLMs) 在偏好学习过程中对数据投毒攻击的易感性。研究者部署了两种攻击类型，跨八个现实场景评估了21个广泛使用的模型，发现模型参数规模增大并不增强对攻击的抵抗力，且攻击效果与数据投毒比例呈对数线性关系。进一步，投毒的影响可泛化到未包含在投毒数据中的触发器，这些结果暴露了当前偏好学习技术的弱点，并强调了开发更 robust 防御措施的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "Tingchen Fu and Fazl Barez are core research contributors",
      "pdf_url": "http://arxiv.org/pdf/2410.08811v1",
      "published_date": "2024-10-11 13:50:50 UTC",
      "updated_date": "2024-10-11 13:50:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:21:58.104603"
    },
    {
      "arxiv_id": "2410.08809v2",
      "title": "DCNet: A Data-Driven Framework for DVL Calibration",
      "title_zh": "翻译失败",
      "authors": [
        "Zeev Yampolsky",
        "Itzik Klein"
      ],
      "abstract": "Autonomous underwater vehicles (AUVs) are underwater robotic platforms used\nin a variety of applications. An AUV's navigation solution relies heavily on\nthe fusion of inertial sensors and Doppler velocity logs (DVL), where the\nlatter delivers accurate velocity updates. To ensure accurate navigation, a DVL\ncalibration is undertaken before the mission begins to estimate its error\nterms. During calibration, the AUV follows a complex trajectory and employs\nnonlinear estimation filters to estimate error terms. In this paper, we\nintroduce DCNet, a data-driven framework that utilizes a two-dimensional\nconvolution kernel in an innovative way. Using DCNet and our proposed DVL error\nmodel, we offer a rapid calibration procedure. This can be applied to a\ntrajectory with a nearly constant velocity. To train and test our proposed\napproach a dataset of 276 minutes long with real DVL recorded measurements was\nused. We demonstrated an average improvement of 70% in accuracy and 80%\nimprovement in calibration time, compared to the baseline approach, with a\nlow-performance DVL. As a result of those improvements, an AUV employing a\nlow-cost DVL, can achieve higher accuracy, shorter calibration time, and apply\na simple nearly constant velocity calibration trajectory. Our results also open\nup new applications for marine robotics utilizing low-cost, high-accurate DVLs.",
      "tldr_zh": "该论文提出 DCNet，一种数据驱动框架，用于自主水下车辆 (AUVs) 的多普勒速度日志 (DVL) 校准，以解决传统校准中复杂轨迹和非线性估计过滤器的挑战。DCNet 创新性地运用二维卷积核和新的 DVL 错误模型，支持近似恒速轨迹的快速校准。实验基于 276 分钟的真实 DVL 数据集显示，与基线方法相比，准确率提升 70%，校准时间缩短 80%，从而使低成本 DVL 实现更高精度和更简便的应用，并为海洋机器人领域开辟新机会。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "10 Pages, 9 Figures, 5 Tables",
      "pdf_url": "http://arxiv.org/pdf/2410.08809v2",
      "published_date": "2024-10-11 13:47:40 UTC",
      "updated_date": "2024-10-14 09:47:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:22:10.681583"
    },
    {
      "arxiv_id": "2410.08794v1",
      "title": "M$^3$-Impute: Mask-guided Representation Learning for Missing Value Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongyi Yu",
        "Zhenghao Wu",
        "Shuhan Zhong",
        "Weifeng Su",
        "S. -H. Gary Chan",
        "Chul-Ho Lee",
        "Weipeng Zhuo"
      ],
      "abstract": "Missing values are a common problem that poses significant challenges to data\nanalysis and machine learning. This problem necessitates the development of an\neffective imputation method to fill in the missing values accurately, thereby\nenhancing the overall quality and utility of the datasets. Existing imputation\nmethods, however, fall short of explicitly considering the `missingness'\ninformation in the data during the embedding initialization stage and modeling\nthe entangled feature and sample correlations during the learning process, thus\nleading to inferior performance. We propose M$^3$-Impute, which aims to\nexplicitly leverage the missingness information and such correlations with\nnovel masking schemes. M$^3$-Impute first models the data as a bipartite graph\nand uses a graph neural network to learn node embeddings, where the refined\nembedding initialization process directly incorporates the missingness\ninformation. They are then optimized through M$^3$-Impute's novel feature\ncorrelation unit (FRU) and sample correlation unit (SRU) that effectively\ncaptures feature and sample correlations for imputation. Experiment results on\n25 benchmark datasets under three different missingness settings show the\neffectiveness of M$^3$-Impute by achieving 20 best and 4 second-best MAE scores\non average.",
      "tldr_zh": "该论文提出 M$^3$-Impute，一种基于 Mask-guided Representation Learning 的方法，用于处理数据分析和机器学习中的 Missing Value Imputation 问题，通过显式利用缺失信息和特征、样本相关性来提升填充准确性。M$^3$-Impute 将数据建模为 bipartite graph，使用图神经网络 (GNN) 在嵌入初始化阶段融入缺失信息，并通过创新的特征相关单元 (FRU) 和样本相关单元 (SRU) 优化学习过程以捕获相关性。实验在 25 个基准数据集和三种缺失设置下表明，该方法平均取得了 20 个最佳和 4 个第二最佳 MAE 分数，显著优于现有方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08794v1",
      "published_date": "2024-10-11 13:25:32 UTC",
      "updated_date": "2024-10-11 13:25:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:22:22.440809"
    },
    {
      "arxiv_id": "2410.09132v2",
      "title": "When Graph meets Multimodal: Benchmarking and Meditating on Multimodal Attributed Graphs Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Yan",
        "Chaozhuo Li",
        "Jun Yin",
        "Zhigang Yu",
        "Weihao Han",
        "Mingzheng Li",
        "Zhengxin Zeng",
        "Hao Sun",
        "Senzhang Wang"
      ],
      "abstract": "Multimodal Attributed Graphs (MAGs) are ubiquitous in real-world\napplications, encompassing extensive knowledge through multimodal attributes\nattached to nodes (e.g., texts and images) and topological structure\nrepresenting node interactions. Despite its potential to advance diverse\nresearch fields like social networks and e-commerce, MAG representation\nlearning (MAGRL) remains underexplored due to the lack of standardized datasets\nand evaluation frameworks. In this paper, we first propose MAGB, a\ncomprehensive MAG benchmark dataset, featuring curated graphs from various\ndomains with both textual and visual attributes. Based on MAGB dataset, we\nfurther systematically evaluate two mainstream MAGRL paradigms:\n$\\textit{GNN-as-Predictor}$, which integrates multimodal attributes via Graph\nNeural Networks (GNNs), and $\\textit{VLM-as-Predictor}$, which harnesses Vision\nLanguage Models (VLMs) for zero-shot reasoning. Extensive experiments on MAGB\nreveal following critical insights: $\\textit{(i)}$ Modality significances\nfluctuate drastically with specific domain characteristics. $\\textit{(ii)}$\nMultimodal embeddings can elevate the performance ceiling of GNNs. However,\nintrinsic biases among modalities may impede effective training, particularly\nin low-data scenarios. $\\textit{(iii)}$ VLMs are highly effective at generating\nmultimodal embeddings that alleviate the imbalance between textual and visual\nattributes. These discoveries, which illuminate the synergy between multimodal\nattributes and graph topologies, contribute to reliable benchmarks, paving the\nway for future MAG research. The MAGB dataset and evaluation pipeline are\npublicly available at https://github.com/sktsherlock/MAGB.",
      "tldr_zh": "本文提出 Multimodal Attributed Graphs (MAGs) 的表征学习 (MAGRL) 基准，旨在解决现有数据集和评估框架的缺失，构建了全面的 MAGB 数据集，涵盖各种领域的图结构及其文本和视觉属性。研究系统评估了两种主流 MAGRL 范式：GNN-as-Predictor（通过 Graph Neural Networks 整合多模态属性）和 VLM-as-Predictor（利用 Vision Language Models 进行零样本推理）。实验发现，模态重要性随领域特性而剧烈变化，多模态嵌入可提升 GNN 性能但易受模态偏差影响，而 VLMs 有效缓解了文本和视觉属性的不平衡，为未来 MAG 研究提供了可靠的基准和公开资源。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09132v2",
      "published_date": "2024-10-11 13:24:57 UTC",
      "updated_date": "2025-02-27 14:51:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:22:35.539125"
    },
    {
      "arxiv_id": "2410.08792v1",
      "title": "VLM See, Robot Do: Human Demo Video to Robot Action Plan via Vision Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Beichen Wang",
        "Juexiao Zhang",
        "Shuwen Dong",
        "Irving Fang",
        "Chen Feng"
      ],
      "abstract": "Vision Language Models (VLMs) have recently been adopted in robotics for\ntheir capability in common sense reasoning and generalizability. Existing work\nhas applied VLMs to generate task and motion planning from natural language\ninstructions and simulate training data for robot learning. In this work, we\nexplore using VLM to interpret human demonstration videos and generate robot\ntask planning. Our method integrates keyframe selection, visual perception, and\nVLM reasoning into a pipeline. We named it SeeDo because it enables the VLM to\n''see'' human demonstrations and explain the corresponding plans to the robot\nfor it to ''do''. To validate our approach, we collected a set of long-horizon\nhuman videos demonstrating pick-and-place tasks in three diverse categories and\ndesigned a set of metrics to comprehensively benchmark SeeDo against several\nbaselines, including state-of-the-art video-input VLMs. The experiments\ndemonstrate SeeDo's superior performance. We further deployed the generated\ntask plans in both a simulation environment and on a real robot arm.",
      "tldr_zh": "本文提出 SeeDo 方法，利用 Vision Language Models (VLMs) 从人类演示视频中生成机器人任务计划，旨在提升机器人的通用性和推理能力。SeeDo 整合关键帧选择、视觉感知和 VLM 推理，形成一个管道，使模型能够“看到”演示并解释对应的行动计划给机器人执行。为验证效果，研究者收集了长时序 pick-and-place 任务视频，并通过实验证明 SeeDo 优于基线模型，在模拟环境和真实机器人臂上成功部署。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08792v1",
      "published_date": "2024-10-11 13:17:52 UTC",
      "updated_date": "2024-10-11 13:17:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:22:45.659103"
    },
    {
      "arxiv_id": "2410.14716v3",
      "title": "A Systematic Survey on Large Language Models for Algorithm Design",
      "title_zh": "大型语言模型在算法设计中的系统综述",
      "authors": [
        "Fei Liu",
        "Yiming Yao",
        "Ping Guo",
        "Zhiyuan Yang",
        "Zhe Zhao",
        "Xi Lin",
        "Xialiang Tong",
        "Mingxuan Yuan",
        "Zhichao Lu",
        "Zhenkun Wang",
        "Qingfu Zhang"
      ],
      "abstract": "Algorithm Design (AD) is crucial for effective problem-solving across various\ndomains. The advent of Large Language Models (LLMs) has notably enhanced the\nautomation and innovation within this field, offering new perspectives and\npromising solutions. Over the past three years, the integration of LLMs into AD\n(LLM4AD) has seen substantial progress, with applications spanning\noptimization, machine learning, mathematical reasoning, and scientific\ndiscovery. Given the rapid advancements and expanding scope of this field, a\nsystematic review is both timely and necessary. This paper provides a\nsystematic review of LLM4AD. First, we offer an overview and summary of\nexisting studies. Then, we introduce a taxonomy and review the literature\nacross four dimensions: the roles of LLMs, search methods, prompt methods, and\napplication domains with a discussion of potential and achievements of LLMs in\nAD. Finally, we identify current challenges and highlight several promising\ndirections for future research.",
      "tldr_zh": "这篇论文对大型语言模型（Large Language Models, LLMs）在算法设计（Algorithm Design, AD）中的应用进行了系统性调查（A Systematic Survey）。它概述了过去三年LLMs与AD的整合（LLM4AD）的进展，包括在优化、机器学习、数理推理和科学发现等领域的应用，并引入了一个分类法（taxonomy）从LLMs的角色、搜索方法、提示方法和应用领域四个维度审视相关文献。论文讨论了LLMs在提升AD自动化和创新方面的潜力与成就，同时识别了当前挑战，如知识局限性和泛化问题，并提出了未来研究的方向，例如更先进的整合策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.14716v3",
      "published_date": "2024-10-11 13:17:19 UTC",
      "updated_date": "2024-11-01 09:38:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:22:58.240056"
    },
    {
      "arxiv_id": "2410.08776v2",
      "title": "F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents",
      "title_zh": "F2A：一种利用伪装安全检测代理进行提示注入的创新",
      "authors": [
        "Yupeng Ren"
      ],
      "abstract": "With the rapid development of Large Language Models (LLMs), numerous mature\napplications of LLMs have emerged in the field of content safety detection.\nHowever, we have found that LLMs exhibit blind trust in safety detection\nagents. The general LLMs can be compromised by hackers with this vulnerability.\nHence, this paper proposed an attack named Feign Agent Attack (F2A).Through\nsuch malicious forgery methods, adding fake safety detection results into the\nprompt, the defense mechanism of LLMs can be bypassed, thereby obtaining\nharmful content and hijacking the normal conversation. Continually, a series of\nexperiments were conducted. In these experiments, the hijacking capability of\nF2A on LLMs was analyzed and demonstrated, exploring the fundamental reasons\nwhy LLMs blindly trust safety detection results. The experiments involved\nvarious scenarios where fake safety detection results were injected into\nprompts, and the responses were closely monitored to understand the extent of\nthe vulnerability. Also, this paper provided a reasonable solution to this\nattack, emphasizing that it is important for LLMs to critically evaluate the\nresults of augmented agents to prevent the generating harmful content. By doing\nso, the reliability and security can be significantly improved, protecting the\nLLMs from F2A.",
      "tldr_zh": "本文提出了一种名为 F2A 的创新攻击方法（Feign Agent Attack），通过利用假的安全检测代理在提示中注入虚假结果，绕过 Large Language Models (LLMs) 的防御机制，从而获取有害内容并劫持正常对话。实验分析了 F2A 在各种场景下的劫持能力，揭示了 LLMs 对安全检测结果的盲目信任问题，并证明了攻击的有效性。论文还提供解决方案，强调 LLMs 需要 critically evaluate 增强代理的结果，以提升系统可靠性并防止生成有害内容。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "1. Fixed typo in abstract 2. Provisionally completed the article\n  update to facilitate future version revisions",
      "pdf_url": "http://arxiv.org/pdf/2410.08776v2",
      "published_date": "2024-10-11 12:49:05 UTC",
      "updated_date": "2024-10-14 15:04:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:23:09.520378"
    },
    {
      "arxiv_id": "2410.08769v1",
      "title": "Efficient Multi-Object Tracking on Edge Devices via Reconstruction-Based Channel Pruning",
      "title_zh": "基于重建的通道剪枝在边缘设备上实现高效多目标跟踪",
      "authors": [
        "Jan Müller",
        "Adrian Pigors"
      ],
      "abstract": "The advancement of multi-object tracking (MOT) technologies presents the dual\nchallenge of maintaining high performance while addressing critical security\nand privacy concerns. In applications such as pedestrian tracking, where\nsensitive personal data is involved, the potential for privacy violations and\ndata misuse becomes a significant issue if data is transmitted to external\nservers. To mitigate these risks, processing data directly on an edge device,\nsuch as a smart camera, has emerged as a viable solution. Edge computing\nensures that sensitive information remains local, thereby aligning with\nstringent privacy principles and significantly reducing network latency.\nHowever, the implementation of MOT on edge devices is not without its\nchallenges. Edge devices typically possess limited computational resources,\nnecessitating the development of highly optimized algorithms capable of\ndelivering real-time performance under these constraints. The disparity between\nthe computational requirements of state-of-the-art MOT algorithms and the\ncapabilities of edge devices emphasizes a significant obstacle. To address\nthese challenges, we propose a neural network pruning method specifically\ntailored to compress complex networks, such as those used in modern MOT\nsystems. This approach optimizes MOT performance by ensuring high accuracy and\nefficiency within the constraints of limited edge devices, such as NVIDIA's\nJetson Orin Nano. By applying our pruning method, we achieve model size\nreductions of up to 70% while maintaining a high level of accuracy and further\nimproving performance on the Jetson Orin Nano, demonstrating the effectiveness\nof our approach for edge computing applications.",
      "tldr_zh": "本研究针对多对象跟踪（MOT）技术在边缘设备上的性能与隐私挑战，提出了一种基于重构的通道修剪（Reconstruction-Based Channel Pruning）方法，以优化复杂网络在资源有限环境下的运行。该方法通过压缩神经网络，实现模型大小减少高达70%，同时保持高准确性，并直接在边缘设备如NVIDIA Jetson Orin Nano上处理敏感数据，从而提升实时性能并强化隐私保护。实验结果证明，该方法显著提高了MOT在边缘计算应用中的效率和可靠性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08769v1",
      "published_date": "2024-10-11 12:37:42 UTC",
      "updated_date": "2024-10-11 12:37:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:23:21.476970"
    },
    {
      "arxiv_id": "2410.08766v1",
      "title": "Integrating Supertag Features into Neural Discontinuous Constituent Parsing",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas Mielczarek"
      ],
      "abstract": "Syntactic parsing is essential in natural-language processing, with\nconstituent structure being one widely used description of syntax. Traditional\nviews of constituency demand that constituents consist of adjacent words, but\nthis poses challenges in analysing syntax with non-local dependencies, common\nin languages like German. Therefore, in a number of treebanks like NeGra and\nTIGER for German and DPTB for English, long-range dependencies are represented\nby crossing edges. Various grammar formalisms have been used to describe\ndiscontinuous trees - often with high time complexities for parsing.\nTransition-based parsing aims at reducing this factor by eliminating the need\nfor an explicit grammar. Instead, neural networks are trained to produce trees\ngiven raw text input using supervised learning on large annotated corpora. An\nelegant proposal for a stack-free transition-based parser developed by Coavoux\nand Cohen (2019) successfully allows for the derivation of any discontinuous\nconstituent tree over a sentence in worst-case quadratic time.\n  The purpose of this work is to explore the introduction of supertag\ninformation into transition-based discontinuous constituent parsing. In\nlexicalised grammar formalisms like CCG (Steedman, 1989) informative categories\nare assigned to the words in a sentence and act as the building blocks for\ncomposing the sentence's syntax. These supertags indicate a word's structural\nrole and syntactic relationship with surrounding items. The study examines\nincorporating supertag information by using a dedicated supertagger as\nadditional input for a neural parser (pipeline) and by jointly training a\nneural model for both parsing and supertagging (multi-task). In addition to\nCCG, several other frameworks (LTAG-spinal, LCFRS) and sequence labelling tasks\n(chunking, dependency parsing) will be compared in terms of their suitability\nas auxiliary tasks for parsing.",
      "tldr_zh": "这篇论文探讨了将supertag特征整合到神经网络-based的非连续成分解析中，以解决传统句法解析在处理非本地依赖（如德语中的交叉边）时面临的挑战。研究方法包括使用独立的supertagger作为额外输入(pipeline)或通过多任务学习(multi-task)联合训练解析和supertagging，从而提升解析效率和准确性。论文还比较了多种框架（如CCG、LTAG-spinal、LCFRS）和辅助任务（如chunking、dependency parsing），评估它们作为supertag来源的适用性，为改进过渡-based解析提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.CL",
      "comment": "Bachelor's Thesis. Supervised by Dr. Kilian Evang and Univ.-Prof. Dr.\n  Laura Kallmeyer",
      "pdf_url": "http://arxiv.org/pdf/2410.08766v1",
      "published_date": "2024-10-11 12:28:26 UTC",
      "updated_date": "2024-10-11 12:28:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:23:34.896051"
    },
    {
      "arxiv_id": "2410.08760v2",
      "title": "Unlocking FedNL: Self-Contained Compute-Optimized Implementation",
      "title_zh": "解锁 FedNL：自包含计算优化实现",
      "authors": [
        "Konstantin Burlachenko",
        "Peter Richtárik"
      ],
      "abstract": "Federated Learning (FL) is an emerging paradigm that enables intelligent\nagents to collaboratively train Machine Learning (ML) models in a distributed\nmanner, eliminating the need for sharing their local data. The recent work\n(arXiv:2106.02969) introduces a family of Federated Newton Learn (FedNL)\nalgorithms, marking a significant step towards applying second-order methods to\nFL and large-scale optimization. However, the reference FedNL prototype\nexhibits three serious practical drawbacks: (i) It requires 4.8 hours to launch\na single experiment in a sever-grade workstation; (ii) The prototype only\nsimulates multi-node setting; (iii) Prototype integration into\nresource-constrained applications is challenging. To bridge the gap between\ntheory and practice, we present a self-contained implementation of FedNL,\nFedNL-LS, FedNL-PP for single-node and multi-node settings. Our work resolves\nthe aforementioned issues and reduces the wall clock time by x1000. With this\nFedNL outperforms alternatives for training logistic regression in a\nsingle-node -- CVXPY (arXiv:1603.00943), and in a multi-node -- Apache Spark\n(arXiv:1505.06807), Ray/Scikit-Learn (arXiv:1712.05889). Finally, we propose\ntwo practical-orientated compressors for FedNL - adaptive TopLEK and\ncache-aware RandSeqK, which fulfill the theory of FedNL.",
      "tldr_zh": "本研究针对Federated Learning (FL)中的Federated Newton Learn (FedNL)算法原型存在的问题（如启动时间长、仅模拟多节点设置和整合困难），提出一个自包含且计算优化的实现，包括FedNL-LS和FedNL-PP，支持单节点和多节点环境。该实现将实验时间减少了1000倍，使FedNL在训练逻辑回归模型时优于CVXPY（单节点）和Apache Spark、Ray/Scikit-Learn（多节点）。此外，论文引入了两种新的压缩器——adaptive TopLEK和cache-aware RandSeqK，这些方法符合FedNL的理论，并提升了其在资源受限场景下的实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MS",
        "cs.PF",
        "math.OC",
        "G.4; C.3; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "55 pages, 12 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.08760v2",
      "published_date": "2024-10-11 12:19:18 UTC",
      "updated_date": "2024-12-12 14:43:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:23:46.374697"
    },
    {
      "arxiv_id": "2410.08759v1",
      "title": "Enhancing GNNs with Architecture-Agnostic Graph Transformations: A Systematic Analysis",
      "title_zh": "通过架构无关的图变换增强图神经网络：系统分析",
      "authors": [
        "Zhifei Li",
        "Gerrit Großmann",
        "Verena Wolf"
      ],
      "abstract": "In recent years, a wide variety of graph neural network (GNN) architectures\nhave emerged, each with its own strengths, weaknesses, and complexities.\nVarious techniques, including rewiring, lifting, and node annotation with\ncentrality values, have been employed as pre-processing steps to enhance GNN\nperformance. However, there are no universally accepted best practices, and the\nimpact of architecture and pre-processing on performance often remains opaque.\n  This study systematically explores the impact of various graph\ntransformations as pre-processing steps on the performance of common GNN\narchitectures across standard datasets. The models are evaluated based on their\nability to distinguish non-isomorphic graphs, referred to as expressivity.\n  Our findings reveal that certain transformations, particularly those\naugmenting node features with centrality measures, consistently improve\nexpressivity. However, these gains come with trade-offs, as methods like graph\nencoding, while enhancing expressivity, introduce numerical inaccuracies\nwidely-used python packages. Additionally, we observe that these pre-processing\ntechniques are limited when addressing complex tasks involving 3-WL and 4-WL\nindistinguishable graphs.",
      "tldr_zh": "本研究系统分析了各种架构无关的图变换（如 rewiring, lifting 和 node annotation with centrality values）作为预处理步骤，以提升图神经网络 (GNNs) 的性能。研究评估了这些变换对常见 GNN 架构在标准数据集上的影响，重点考察 GNNs 的 expressivity（区分非同构图的能力）。结果显示，使用 centrality measures 增强节点特征的变换能一致提高 expressivity，但会带来权衡，如 graph encoding 可能导致数值不准确。总体而言，这些技术在处理 3-WL 和 4-WL 无法区分的复杂图任务时存在局限，为 GNNs 预处理的最佳实践提供了重要洞见。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08759v1",
      "published_date": "2024-10-11 12:19:17 UTC",
      "updated_date": "2024-10-11 12:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:23:59.291036"
    },
    {
      "arxiv_id": "2410.08740v1",
      "title": "Hespi: A pipeline for automatically detecting information from hebarium specimen sheets",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Turnbull",
        "Emily Fitzgerald",
        "Karen Thompson",
        "Joanne L. Birch"
      ],
      "abstract": "Specimen associated biodiversity data are sought after for biological,\nenvironmental, climate, and conservation sciences. A rate shift is required for\nthe extraction of data from specimen images to eliminate the bottleneck that\nthe reliance on human-mediated transcription of these data represents. We\napplied advanced computer vision techniques to develop the `Hespi' (HErbarium\nSpecimen sheet PIpeline), which extracts a pre-catalogue subset of collection\ndata on the institutional labels on herbarium specimens from their digital\nimages. The pipeline integrates two object detection models; the first detects\nbounding boxes around text-based labels and the second detects bounding boxes\naround text-based data fields on the primary institutional label. The pipeline\nclassifies text-based institutional labels as printed, typed, handwritten, or a\ncombination and applies Optical Character Recognition (OCR) and Handwritten\nText Recognition (HTR) for data extraction. The recognized text is then\ncorrected against authoritative databases of taxon names. The extracted text is\nalso corrected with the aide of a multimodal Large Language Model (LLM). Hespi\naccurately detects and extracts text for test datasets including specimen sheet\nimages from international herbaria. The components of the pipeline are modular\nand users can train their own models with their own data and use them in place\nof the models provided.",
      "tldr_zh": "该研究引入了 Hespi 管道，一种自动化系统，用于从植物标本图像中提取生物多样性数据，从而解决依赖人工转录的瓶颈问题。Hespi 整合了两个对象检测模型来识别文本标签和数据字段，并通过 Optical Character Recognition (OCR) 和 Handwritten Text Recognition (HTR) 提取文本，同时分类文本类型（如打印、打字或手写），并利用权威数据库和多模态 Large Language Model (LLM) 进行校正。实验结果显示，Hespi 在国际植物标本图像测试数据集上实现了准确的文本检测和提取，且其模块化设计允许用户使用自定义训练模型进行优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08740v1",
      "published_date": "2024-10-11 11:59:40 UTC",
      "updated_date": "2024-10-11 11:59:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:24:10.256840"
    },
    {
      "arxiv_id": "2410.19756v1",
      "title": "A SAM based Tool for Semi-Automatic Food Annotation",
      "title_zh": "翻译失败",
      "authors": [
        "Lubnaa Abdur Rahman",
        "Ioannis Papathanail",
        "Lorenzo Brigato",
        "Stavroula Mougiakakou"
      ],
      "abstract": "The advancement of artificial intelligence (AI) in food and nutrition\nresearch is hindered by a critical bottleneck: the lack of annotated food data.\nDespite the rise of highly efficient AI models designed for tasks such as food\nsegmentation and classification, their practical application might necessitate\nproficiency in AI and machine learning principles, which can act as a challenge\nfor non-AI experts in the field of nutritional sciences. Alternatively, it\nhighlights the need to translate AI models into user-friendly tools that are\naccessible to all. To address this, we present a demo of a semi-automatic food\nimage annotation tool leveraging the Segment Anything Model (SAM). The tool\nenables prompt-based food segmentation via user interactions, promoting user\nengagement and allowing them to further categorise food items within meal\nimages and specify weight/volume if necessary. Additionally, we release a\nfine-tuned version of SAM's mask decoder, dubbed MealSAM, with the ViT-B\nbackbone tailored specifically for food image segmentation. Our objective is\nnot only to contribute to the field by encouraging participation,\ncollaboration, and the gathering of more annotated food data but also to make\nAI technology available for a broader audience by translating AI into practical\ntools.",
      "tldr_zh": "该研究针对食品和营养研究中标注数据缺乏的问题，提出了一种基于 Segment Anything Model (SAM) 的半自动食品图像标注工具，以降低非AI专家的使用门槛。该工具允许用户通过交互式提示进行食品分割，并进一步分类食品项目并指定重量/体积，从而提升标注效率。同时，作者发布了一个针对食品图像优化的微调版本SAM掩码解码器MealSAM，使用ViT-B骨干网，以提高分割准确性。最终，该工具旨在促进更多标注数据的收集和AI技术的普及，推动食品领域的研究协作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted Demo Paper - ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.19756v1",
      "published_date": "2024-10-11 11:50:10 UTC",
      "updated_date": "2024-10-11 11:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:24:22.174556"
    },
    {
      "arxiv_id": "2410.08731v1",
      "title": "Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yeeun Kim",
        "Young Rok Choi",
        "Eunkyung Choi",
        "Jinhwan Choi",
        "Hai Jin Park",
        "Wonseok Hwang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable performance in the\nlegal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However\ntheir efficacy remains limited for non-standardized tasks and tasks in\nlanguages other than English. This underscores the need for careful evaluation\nof LLMs within each legal system before application. Here, we introduce KBL, a\nbenchmark for assessing the Korean legal language understanding of LLMs,\nconsisting of (1) 7 legal knowledge tasks (510 examples), (2) 4 legal reasoning\ntasks (288 examples), and (3) the Korean bar exam (4 domains, 53 tasks, 2,510\nexamples). First two datasets were developed in close collaboration with\nlawyers to evaluate LLMs in practical scenarios in a certified manner.\nFurthermore, considering legal practitioners' frequent use of extensive legal\ndocuments for research, we assess LLMs in both a closed book setting, where\nthey rely solely on internal knowledge, and a retrieval-augmented generation\n(RAG) setting, using a corpus of Korean statutes and precedents. The results\nindicate substantial room and opportunities for improvement.",
      "tldr_zh": "本文开发了 KBL 基准，用于评估大型语言模型 (LLMs) 在韩国法律语言理解方面的表现，旨在解决 LLMs 在非标准化任务和非英语语言中的局限性。KBL 包括 7 个法律知识任务 (510 个例子)、4 个法律推理任务 (288 个例子)，以及韩国律师考试 (4 个领域、53 个任务、2510 个例子)，这些数据集由律师密切合作开发，以确保实际性和可靠性。评估采用封闭书籍设置 (依赖内部知识) 和检索增强生成 (RAG) 设置 (利用韩国法规和先例语料库)，结果表明 LLMs 在韩国法律任务上仍有较大改进空间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.08731v1",
      "published_date": "2024-10-11 11:41:02 UTC",
      "updated_date": "2024-10-11 11:41:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:24:35.567505"
    },
    {
      "arxiv_id": "2410.08728v1",
      "title": "From N-grams to Pre-trained Multilingual Models For Language Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Thapelo Sindane",
        "Vukosi Marivate"
      ],
      "abstract": "In this paper, we investigate the use of N-gram models and Large Pre-trained\nMultilingual models for Language Identification (LID) across 11 South African\nlanguages. For N-gram models, this study shows that effective data size\nselection remains crucial for establishing effective frequency distributions of\nthe target languages, that efficiently model each language, thus, improving\nlanguage ranking. For pre-trained multilingual models, we conduct extensive\nexperiments covering a diverse set of massively pre-trained multilingual (PLM)\nmodels -- mBERT, RemBERT, XLM-r, and Afri-centric multilingual models --\nAfriBERTa, Afro-XLMr, AfroLM, and Serengeti. We further compare these models\nwith available large-scale Language Identification tools: Compact Language\nDetector v3 (CLD V3), AfroLID, GlotLID, and OpenLID to highlight the importance\nof focused-based LID. From these, we show that Serengeti is a superior model\nacross models: N-grams to Transformers on average. Moreover, we propose a\nlightweight BERT-based LID model (za_BERT_lid) trained with NHCLT + Vukzenzele\ncorpus, which performs on par with our best-performing Afri-centric models.",
      "tldr_zh": "这篇论文探讨了 N-gram 模型和大型预训练多语言模型在 11 种南非语言上的 Language Identification (LID) 应用，强调了数据大小选择对 N-gram 模型频率分布和语言排名的关键影响。研究通过广泛实验比较了多种预训练模型，包括 mBERT、RemBERT、XLM-r，以及非洲中心模型如 AfriBERTa、Afro-XLMr、AfroLM 和 Serengeti，并与现有工具如 CLD V3、AfroLID 等进行对比，突出了专注于 LID 的重要性。结果显示，Serengeti 模型在整体表现上优于其他模型；此外，作者提出了一种轻量级 BERT 基于模型 za_BERT_lid，使用 NHCLT + Vukzenzele 语料训练，其性能可与最佳非洲中心模型媲美。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The paper has been accepted at The 4th International Conference on\n  Natural Language Processing for Digital Humanities (NLP4DH 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.08728v1",
      "published_date": "2024-10-11 11:35:57 UTC",
      "updated_date": "2024-10-11 11:35:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:24:46.982891"
    },
    {
      "arxiv_id": "2410.09129v1",
      "title": "nextlocllm: next location prediction using LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Liu",
        "Ning Cao",
        "Yile Chen",
        "Yue Jiang",
        "Gao Cong"
      ],
      "abstract": "Next location prediction is a critical task in human mobility analysis and\nserves as a foundation for various downstream applications. Existing methods\ntypically rely on discrete IDs to represent locations, which inherently\noverlook spatial relationships and cannot generalize across cities. In this\npaper, we propose NextLocLLM, which leverages the advantages of large language\nmodels (LLMs) in processing natural language descriptions and their strong\ngeneralization capabilities for next location prediction. Specifically, instead\nof using IDs, NextLocLLM encodes locations based on continuous spatial\ncoordinates to better model spatial relationships. These coordinates are\nfurther normalized to enable robust cross-city generalization. Another\nhighlight of NextlocLLM is its LLM-enhanced POI embeddings. It utilizes LLMs'\nability to encode each POI category's natural language description into\nembeddings. These embeddings are then integrated via nonlinear projections to\nform this LLM-enhanced POI embeddings, effectively capturing locations'\nfunctional attributes. Furthermore, task and data prompt prefix, together with\ntrajectory embeddings, are incorporated as input for partly-frozen LLM\nbackbone. NextLocLLM further introduces prediction retrieval module to ensure\nstructural consistency in prediction. Experiments show that NextLocLLM\noutperforms existing models in next location prediction, excelling in both\nsupervised and zero-shot settings.",
      "tldr_zh": "该论文提出NextLocLLM框架，利用大型语言模型（LLMs）来提升下一位置预测（next location prediction）任务的性能，解决现有方法依赖离散ID而忽略空间关系和跨城市泛化的问题。具体而言，NextLocLLM使用连续空间坐标编码位置并进行规范化，还开发了LLM-enhanced POI embeddings，通过LLMs处理POI（兴趣点）类别的自然语言描述并整合功能属性，同时引入预测检索模块（prediction retrieval module）确保预测的结构一致性。实验结果显示，NextLocLLM在监督和zero-shot设置中均优于现有模型，展示了其在人类移动性分析中的强大泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.09129v1",
      "published_date": "2024-10-11 10:59:14 UTC",
      "updated_date": "2024-10-11 10:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:24:58.015911"
    },
    {
      "arxiv_id": "2410.08703v2",
      "title": "On the token distance modeling ability of higher RoPE attention dimension",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Hong",
        "Che Jiang",
        "Biqing Qi",
        "Fandong Meng",
        "Mo Yu",
        "Bowen Zhou",
        "Jie Zhou"
      ],
      "abstract": "Length extrapolation algorithms based on Rotary position embedding (RoPE)\nhave shown promising results in extending the context length of language\nmodels. However, understanding how position embedding can capture longer-range\ncontextual information remains elusive. Based on the intuition that different\ndimensions correspond to different frequency of changes in RoPE encoding, we\nconducted a dimension-level analysis to investigate the correlation between a\nhidden dimension of an attention head and its contribution to capturing\nlong-distance dependencies. Using our correlation metric, we identified a\nparticular type of attention heads, which we named Positional Heads, from\nvarious length-extrapolated models. These heads exhibit a strong focus on\nlong-range information interaction and play a pivotal role in long input\nprocessing, as evidence by our ablation. We further demonstrate the correlation\nbetween the efficiency of length extrapolation and the extension of the\nhigh-dimensional attention allocation of these heads. The identification of\nPositional Heads provides insights for future research in long-text\ncomprehension.",
      "tldr_zh": "本研究探讨了 Rotary position embedding (RoPE) 在语言模型长度外推中的机制，特别分析了更高维度注意力如何捕捉长距离依赖。作者通过维度级分析和相关性指标，识别出一种特殊的注意力头（Positional Heads），这些头专注于长范围信息交互，并在长输入处理中发挥关键作用，如消融实验所示。该发现揭示了长度外推效率与Positional Heads的高维度注意力分配的相关性，为未来长文本理解研究提供重要洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EMNLP 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2410.08703v2",
      "published_date": "2024-10-11 10:47:02 UTC",
      "updated_date": "2024-10-21 08:49:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:25:09.892998"
    },
    {
      "arxiv_id": "2410.08688v2",
      "title": "Chain-of-Restoration: Multi-Task Image Restoration Models are Zero-Shot Step-by-Step Universal Image Restorers",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Cao",
        "Deyu Meng",
        "Xiangyong Cao"
      ],
      "abstract": "Despite previous image restoration (IR) methods have often concentrated on\nisolated degradations, recent research has increasingly focused on addressing\ncomposite degradations involving a complex combination of multiple isolated\ndegradations. However, current IR methods for composite degradations require\nbuilding training data that contain an exponential number of possible\ndegradation combinations, which brings in a significant burden. To alleviate\nthis issue, this paper proposes a new task setting, i.e. Universal Image\nRestoration (UIR). Specifically, UIR doesn't require training on all the\ndegradation combinations but only on a set of degradation bases and then\nremoving any degradation that these bases can potentially compose in a\nzero-shot manner. Inspired by the Chain-of-Thought that prompts large language\nmodels (LLMs) to address problems step-by-step, we propose Chain-of-Restoration\n(CoR) mechanism, which instructs models to remove unknown composite\ndegradations step-by-step. By integrating a simple Degradation Discriminator\ninto pre-trained multi-task models, CoR facilitates the process where models\nremove one degradation basis per step, continuing this process until the image\nis fully restored from the unknown composite degradation. Extensive experiments\nshow that CoR can significantly improve model performance in removing composite\ndegradations, achieving comparable or better results than those\nstate-of-the-art (SoTA) methods trained on all degradations.",
      "tldr_zh": "该论文提出了一种新的任务设置Universal Image Restoration (UIR)，旨在解决图像恢复（IR）中复合退化问题的训练负担问题，而无需训练所有可能的退化组合，只需在退化基础（degradation bases）上训练即可实现零-shot移除任意复合退化。受Chain-of-Thought启发，作者开发了Chain-of-Restoration (CoR)机制，将一个简单的Degradation Discriminator集成到预训练的多任务模型中，让模型逐步（step-by-step）移除每个退化基础，直到图像完全恢复。实验结果显示，CoR在处理未知复合退化时显著提升性能，与那些在所有退化上训练的state-of-the-art (SoTA)方法相比，表现相当或更优。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "code: https://github.com/toummHus/Chain-of-Restoration",
      "pdf_url": "http://arxiv.org/pdf/2410.08688v2",
      "published_date": "2024-10-11 10:21:42 UTC",
      "updated_date": "2024-12-04 04:28:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:25:22.312520"
    },
    {
      "arxiv_id": "2410.08669v2",
      "title": "SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction",
      "title_zh": "SmartPretrain：模型无关且数据集无关的表示学习，用于运动预测",
      "authors": [
        "Yang Zhou",
        "Hao Shao",
        "Letian Wang",
        "Steven L. Waslander",
        "Hongsheng Li",
        "Yu Liu"
      ],
      "abstract": "Predicting the future motion of surrounding agents is essential for\nautonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed\nenvironments. However, the scarcity of large-scale driving datasets has\nhindered the development of robust and generalizable motion prediction models,\nlimiting their ability to capture complex interactions and road geometries.\nInspired by recent advances in natural language processing (NLP) and computer\nvision (CV), self-supervised learning (SSL) has gained significant attention in\nthe motion prediction community for learning rich and transferable scene\nrepresentations. Nonetheless, existing pre-training methods for motion\nprediction have largely focused on specific model architectures and single\ndataset, limiting their scalability and generalizability. To address these\nchallenges, we propose SmartPretrain, a general and scalable SSL framework for\nmotion prediction that is both model-agnostic and dataset-agnostic. Our\napproach integrates contrastive and reconstructive SSL, leveraging the\nstrengths of both generative and discriminative paradigms to effectively\nrepresent spatiotemporal evolution and interactions without imposing\narchitectural constraints. Additionally, SmartPretrain employs a\ndataset-agnostic scenario sampling strategy that integrates multiple datasets,\nenhancing data volume, diversity, and robustness. Extensive experiments on\nmultiple datasets demonstrate that SmartPretrain consistently improves the\nperformance of state-of-the-art prediction models across datasets, data splits\nand main metrics. For instance, SmartPretrain significantly reduces the\nMissRate of Forecast-MAE by 10.6%. These results highlight SmartPretrain's\neffectiveness as a unified, scalable solution for motion prediction, breaking\nfree from the limitations of the small-data regime. Codes are available at\nhttps://github.com/youngzhou1999/SmartPretrain",
      "tldr_zh": "该研究提出 SmartPretrain，一种模型无关 (Model-Agnostic) 和数据集无关 (Dataset-Agnostic) 的自监督学习 (SSL) 框架，旨在解决自动驾驶车辆 (AVs) 运动预测中数据稀缺问题，提升模型的鲁棒性和泛化能力。框架通过整合对比学习 (contrastive SSL) 和重构学习 (reconstructive SSL)，结合生成和判别范式来学习丰富的时空场景表示，并采用数据集无关的场景采样策略融合多个数据集以增强数据多样性和鲁棒性。实验结果显示，SmartPretrain 在多个数据集上显著提升了最先进预测模型的性能，例如将 Forecast-MAE 的 MissRate 降低了 10.6%，为运动预测提供了一个统一的、可扩展解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Camera-ready version for ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08669v2",
      "published_date": "2024-10-11 09:52:26 UTC",
      "updated_date": "2025-02-27 15:20:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:25:35.587150"
    },
    {
      "arxiv_id": "2410.09128v1",
      "title": "TIGER: Temporally Improved Graph Entity Linker",
      "title_zh": "翻译失败",
      "authors": [
        "Pengyu Zhang",
        "Congfeng Cao",
        "Paul Groth"
      ],
      "abstract": "Knowledge graphs change over time, for example, when new entities are\nintroduced or entity descriptions change. This impacts the performance of\nentity linking, a key task in many uses of knowledge graphs such as web search\nand recommendation. Specifically, entity linking models exhibit temporal\ndegradation - their performance decreases the further a knowledge graph moves\nfrom its original state on which an entity linking model was trained. To tackle\nthis challenge, we introduce \\textbf{TIGER}: a \\textbf{T}emporally\n\\textbf{I}mproved \\textbf{G}raph \\textbf{E}ntity Linke\\textbf{r}. By\nincorporating structural information between entities into the model, we\nenhance the learned representation, making entities more distinguishable over\ntime. The core idea is to integrate graph-based information into text-based\ninformation, from which both distinct and shared embeddings are based on an\nentity's feature and structural relationships and their interaction.\nExperiments on three datasets show that our model can effectively prevent\ntemporal degradation, demonstrating a 16.24\\% performance boost over the\nstate-of-the-art in a temporal setting when the time gap is one year and an\nimprovement to 20.93\\% as the gap expands to three years. The code and data are\nmade available at\n\\url{https://github.com/pengyu-zhang/TIGER-Temporally-Improved-Graph-Entity-Linker}.",
      "tldr_zh": "该研究针对知识图谱（knowledge graphs）随时间变化导致实体链接（entity linking）性能下降的问题，提出了TIGER（Temporally Improved Graph Entity Linker）模型，以缓解时间退化（temporal degradation）。TIGER通过整合实体之间的结构信息（graph-based information）与文本信息，生成基于实体特征、关系及其交互的distinct和shared embeddings，从而提升实体表示的可区分性。在三个数据集上的实验显示，该模型在时间差距为一年时比最先进模型提升16.24%的性能，扩展到三年时提升至20.93%。代码和数据已公开在GitHub上，便于进一步研究和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09128v1",
      "published_date": "2024-10-11 09:44:33 UTC",
      "updated_date": "2024-10-11 09:44:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:25:45.798493"
    },
    {
      "arxiv_id": "2410.08666v1",
      "title": "DeltaDQ: Ultra-High Delta Compression for Fine-Tuned LLMs via Group-wise Dropout and Separate Quantization",
      "title_zh": "翻译失败",
      "authors": [
        "Yanfeng Jiang",
        "Zelan Yang",
        "Bohua Chen",
        "Shen Li",
        "Yong Li",
        "Tao Li"
      ],
      "abstract": "Large language models achieve exceptional performance on various downstream\ntasks through supervised fine-tuning. However, the diversity of downstream\ntasks and practical requirements makes deploying multiple full-parameter\nfine-tuned models challenging. Current methods that compress the delta weight\nstruggle to achieve ultra-high compression, failing to minimize the deployment\noverhead. To address the above issue, we propose a novel distribution-driven\ndelta compression framework DeltaDQ, which utilizes Group-wise Dropout and\nSeparate Quantization to achieve ultra-high compression for the delta weight.\nWe have observed that the matrix-computed intermediate results for the delta\nweight exhibit extremely small variance and min-max range characteristics,\nreferred to as Balanced Intermediate Results. Exploiting this phenomenon, we\nintroduce Group-wise Dropout to perform dropout on the delta weight using an\noptimal group size. Furthermore, using Separate Quantization, sparse weights\nare quantized and decomposed to achieve a lower bit. Experimental results show\nthat DeltaDQ achieves 16x compression with improved accuracy compared to\nbaselines for WizardMath and WizardCoder models across different parameter\nscales. Moreover, DeltaDQ demonstrates the ability for ultra-high compression\nratio, achieving 128x compression for the WizardMath-7B model and 512x\ncompression for the WizardMath-70B model.",
      "tldr_zh": "该论文提出 DeltaDQ 框架，用于实现超高压缩率以部署微调的大型语言模型（LLMs），通过 Group-wise Dropout 和 Separate Quantization 处理增量权重（delta weight），以解决现有方法压缩不足的问题。DeltaDQ 利用增量权重中间结果的 Balanced Intermediate Results 特性，选择最优组大小进行 dropout，并对稀疏权重进行量化分解以降低位数。实验结果显示，该框架在 WizardMath 和 WizardCoder 模型上实现了 16x 压缩率的同时提升准确率，并进一步达到 WizardMath-7B 的 128x 和 WizardMath-70B 的 512x 超高压缩比。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08666v1",
      "published_date": "2024-10-11 09:44:16 UTC",
      "updated_date": "2024-10-11 09:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:25:58.583713"
    },
    {
      "arxiv_id": "2410.08665v1",
      "title": "DistDD: Distributed Data Distillation Aggregation through Gradient Matching",
      "title_zh": "DistDD：通过梯度匹配的分布式数据蒸馏聚合",
      "authors": [
        "Peiran Wang",
        "Haohan Wang"
      ],
      "abstract": "In this paper, we introduce DistDD, a novel approach within the federated\nlearning framework that reduces the need for repetitive communication by\ndistilling data directly on clients' devices. Unlike traditional federated\nlearning that requires iterative model updates across nodes, DistDD facilitates\na one-time distillation process that extracts a global distilled dataset,\nmaintaining the privacy standards of federated learning while significantly\ncutting down communication costs. By leveraging the DistDD's distilled dataset,\nthe developers of the FL can achieve just-in-time parameter tuning and neural\narchitecture search over FL without repeating the whole FL process multiple\ntimes. We provide a detailed convergence proof of the DistDD algorithm,\nreinforcing its mathematical stability and reliability for practical\napplications. Our experiments demonstrate the effectiveness and robustness of\nDistDD, particularly in non-i.i.d. and mislabeled data scenarios, showcasing\nits potential to handle complex real-world data challenges distinctively from\nconventional federated learning methods. We also evaluate DistDD's application\nin the use case and prove its effectiveness and communication-savings in the\nNAS use case.",
      "tldr_zh": "该论文提出 DistDD，一种基于梯度匹配的分布式数据蒸馏聚合方法，用于联邦学习（Federated Learning），通过在客户端设备上进行一次性数据蒸馏，显著减少重复通信并维护隐私标准。DistDD 允许开发者利用蒸馏数据集实现即时参数调整和神经架构搜索（NAS），而无需重复整个联邦学习过程，并提供了算法的收敛证明以确保其数学稳定性和可靠性。实验结果显示，DistDD 在非 i.i.d. 和错误标记数据场景中表现出色，证明了其在复杂真实世界应用中的有效性和通信节省潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08665v1",
      "published_date": "2024-10-11 09:43:35 UTC",
      "updated_date": "2024-10-11 09:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:26:10.618710"
    },
    {
      "arxiv_id": "2410.09127v1",
      "title": "CYCLE: Cross-Year Contrastive Learning in Entity-Linking",
      "title_zh": "CYCLE：实体链接中的跨年份对比学习",
      "authors": [
        "Pengyu Zhang",
        "Congfeng Cao",
        "Klim Zaporojets",
        "Paul Groth"
      ],
      "abstract": "Knowledge graphs constantly evolve with new entities emerging, existing\ndefinitions being revised, and entity relationships changing. These changes\nlead to temporal degradation in entity linking models, characterized as a\ndecline in model performance over time. To address this issue, we propose\nleveraging graph relationships to aggregate information from neighboring\nentities across different time periods. This approach enhances the ability to\ndistinguish similar entities over time, thereby minimizing the impact of\ntemporal degradation. We introduce \\textbf{CYCLE}: \\textbf{C}ross-\\textbf{Y}ear\n\\textbf{C}ontrastive \\textbf{L}earning for \\textbf{E}ntity-Linking. This model\nemploys a novel graph contrastive learning method to tackle temporal\nperformance degradation in entity linking tasks. Our contrastive learning\nmethod treats newly added graph relationships as \\textit{positive} samples and\nnewly removed ones as \\textit{negative} samples. This approach helps our model\neffectively prevent temporal degradation, achieving a 13.90\\% performance\nimprovement over the state-of-the-art from 2023 when the time gap is one year,\nand a 17.79\\% improvement as the gap expands to three years. Further analysis\nshows that CYCLE is particularly robust for low-degree entities, which are less\nresistant to temporal degradation due to their sparse connectivity, making them\nparticularly suitable for our method. The code and data are made available at\n\\url{https://github.com/pengyu-zhang/CYCLE-Cross-Year-Contrastive-Learning-in-Entity-Linking}.",
      "tldr_zh": "这篇论文针对知识图谱的动态变化（如新实体出现、关系调整）导致的实体链接模型性能下降（temporal degradation）问题，提出了 CYCLE 模型，即一种跨年对比学习（Cross-Year Contrastive Learning）方法。该方法利用图关系聚合不同时间段的邻居信息，将新添加的关系作为正样本、新移除的关系作为负样本，从而提升模型对相似实体的区分能力。实验结果显示，CYCLE 相较 2023 年最先进模型，在时间间隔为一年时提升 13.90%、为三年时提升 17.79%，并特别适用于低度实体（low-degree entities），增强了模型的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09127v1",
      "published_date": "2024-10-11 09:41:54 UTC",
      "updated_date": "2024-10-11 09:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:26:22.560183"
    },
    {
      "arxiv_id": "2410.08660v3",
      "title": "RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process",
      "title_zh": "翻译失败",
      "authors": [
        "Peiran Wang",
        "Xiaogeng Liu",
        "Chaowei Xiao"
      ],
      "abstract": "In this study, we introduce RePD, an innovative attack Retrieval-based Prompt\nDecomposition framework designed to mitigate the risk of jailbreak attacks on\nlarge language models (LLMs). Despite rigorous pretraining and finetuning\nfocused on ethical alignment, LLMs are still susceptible to jailbreak exploits.\nRePD operates on a one-shot learning model, wherein it accesses a database of\npre-collected jailbreak prompt templates to identify and decompose harmful\ninquiries embedded within user prompts. This process involves integrating the\ndecomposition of the jailbreak prompt into the user's original query into a\none-shot learning example to effectively teach the LLM to discern and separate\nmalicious components. Consequently, the LLM is equipped to first neutralize any\npotentially harmful elements before addressing the user's prompt in a manner\nthat aligns with its ethical guidelines. RePD is versatile and compatible with\na variety of open-source LLMs acting as agents. Through comprehensive\nexperimentation with both harmful and benign prompts, we have demonstrated the\nefficacy of our proposed RePD in enhancing the resilience of LLMs against\njailbreak attacks, without compromising their performance in responding to\ntypical user requests.",
      "tldr_zh": "本研究提出 RePD，一种基于检索的提示分解框架，用于防御大型语言模型 (LLMs) 的 jailbreak attacks，尽管 LLMs 已通过预训练和微调进行伦理对齐但仍易受影响。RePD 利用一-shot learning 机制，访问预收集的 jailbreak 提示模板数据库来识别和分解用户提示中的有害查询，并将分解结果整合为示例，教导 LLMs 先中和恶意元素再安全响应。实验证明，RePD 兼容多种开源 LLMs，能显著提升对 jailbreak attacks 的抵抗力，同时不影响正常用户请求的处理性能。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08660v3",
      "published_date": "2024-10-11 09:39:11 UTC",
      "updated_date": "2024-11-29 02:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:26:34.624414"
    },
    {
      "arxiv_id": "2410.09126v1",
      "title": "Convolutional Neural Network Design and Evaluation for Real-Time Multivariate Time Series Fault Detection in Spacecraft Attitude Sensors",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Gallon",
        "Fabian Schiemenz",
        "Alessandra Menicucci",
        "Eberhard Gill"
      ],
      "abstract": "Traditional anomaly detection techniques onboard satellites are based on\nreliable, yet limited, thresholding mechanisms which are designed to monitor\nunivariate signals and trigger recovery actions according to specific European\nCooperation for Space Standardization (ECSS) standards. However, Artificial\nIntelligence-based Fault Detection, Isolation and Recovery (FDIR) solutions\nhave recently raised with the prospect to overcome the limitations of these\nstandard methods, expanding the range of detectable failures and improving\nresponse times. This paper presents a novel approach to detecting stuck values\nwithin the Accelerometer and Inertial Measurement Unit of a drone-like\nspacecraft for the exploration of Small Solar System Bodies (SSSB), leveraging\na multi-channel Convolutional Neural Network (CNN) to perform multi-target\nclassification and independently detect faults in the sensors. Significant\nattention has been dedicated to ensuring the compatibility of the algorithm\nwithin the onboard FDIR system, representing a step forward to the in-orbit\nvalidation of a technology that remains experimental until its robustness is\nthoroughly proven. An integration methodology is proposed to enable the network\nto effectively detect anomalies and trigger recovery actions at the system\nlevel. The detection performances and the capability of the algorithm in\nreaction triggering are evaluated employing a set of custom-defined detection\nand system metrics, showing the outstanding performances of the algorithm in\nperforming its FDIR task.",
      "tldr_zh": "本论文设计并评估了一个多通道Convolutional Neural Network (CNN)，用于实时检测航天器姿态传感器（如加速度计和Inertial Measurement Unit）中的多变量时间序列故障，旨在克服传统阈值机制的局限性。方法通过多目标分类实现故障检测、隔离和恢复 (FDIR)，并提出集成策略以确保算法与机载FDIR系统兼容，从而触发系统级恢复动作。实验结果显示，该算法在自定义检测和系统指标上表现出色，显著提高了故障检测范围和响应时间。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "submitted to Advances in Space Research",
      "pdf_url": "http://arxiv.org/pdf/2410.09126v1",
      "published_date": "2024-10-11 09:36:38 UTC",
      "updated_date": "2024-10-11 09:36:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:26:46.730085"
    },
    {
      "arxiv_id": "2410.08656v2",
      "title": "radarODE-MTL: A Multi-Task Learning Framework with Eccentric Gradient Alignment for Robust Radar-Based ECG Reconstruction",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyuan Zhang",
        "Rui Yang",
        "Yutao Yue",
        "Eng Gee Lim"
      ],
      "abstract": "Millimeter-wave radar is promising to provide robust and accurate vital sign\nmonitoring in an unobtrusive manner. However, the radar signal might be\ndistorted in propagation by ambient noise or random body movement, ruining the\nsubtle cardiac activities and destroying the vital sign recovery. In\nparticular, the recovery of electrocardiogram (ECG) signal heavily relies on\nthe deep-learning model and is sensitive to noise. Therefore, this work\ncreatively deconstructs the radar-based ECG recovery into three individual\ntasks and proposes a multi-task learning (MTL) framework, radarODE-MTL, to\nincrease the robustness against consistent and abrupt noises. In addition, to\nalleviate the potential conflicts in optimizing individual tasks, a novel\nmulti-task optimization strategy, eccentric gradient alignment (EGA), is\nproposed to dynamically trim the task-specific gradients based on task\ndifficulties in orthogonal space. The proposed radarODE-MTL with EGA is\nevaluated on the public dataset with prominent improvements in accuracy, and\nthe performance remains consistent under noises. The experimental results\nindicate that radarODE-MTL could reconstruct accurate ECG signals robustly from\nradar signals and imply the application prospect in real-life situations. The\ncode is available at: http://github.com/ZYY0844/radarODE-MTL.",
      "tldr_zh": "本文提出 radarODE-MTL，一种多任务学习(MTL)框架，用于从毫米波雷达信号中重建 electrocardiogram (ECG) 信号，以提升对环境噪声和身体运动干扰的鲁棒性。该框架将 ECG 恢复分解为三个独立任务，并引入 eccentric gradient alignment (EGA) 优化策略，根据任务难度在正交空间动态调整梯度，避免任务冲突。实验在公开数据集上显示，radarODE-MTL 显著提高了准确性，并在噪声环境下保持一致性能，展示了其在实际生命体征监测中的应用前景。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08656v2",
      "published_date": "2024-10-11 09:28:09 UTC",
      "updated_date": "2025-05-06 08:36:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:26:58.855228"
    },
    {
      "arxiv_id": "2410.09125v1",
      "title": "Training on Fake Labels: Mitigating Label Leakage in Split Learning via Secure Dimension Transformation",
      "title_zh": "基于假标签训练：通过安全维度变换缓解分割学习中的",
      "authors": [
        "Yukun Jiang",
        "Peiran Wang",
        "Chengguo Lin",
        "Ziyue Huang",
        "Yong Cheng"
      ],
      "abstract": "Two-party split learning has emerged as a popular paradigm for vertical\nfederated learning. To preserve the privacy of the label owner, split learning\nutilizes a split model, which only requires the exchange of intermediate\nrepresentations (IRs) based on the inputs and gradients for each IR between two\nparties during the learning process. However, split learning has recently been\nproven to survive label inference attacks. Though several defense methods could\nbe adopted, they either have limited defensive performance or significantly\nnegatively impact the original mission. In this paper, we propose a novel\ntwo-party split learning method to defend against existing label inference\nattacks while maintaining the high utility of the learned models. Specifically,\nwe first craft a dimension transformation module, SecDT, which could achieve\nbidirectional mapping between original labels and increased K-class labels to\nmitigate label leakage from the directional perspective. Then, a gradient\nnormalization algorithm is designed to remove the magnitude divergence of\ngradients from different classes. We propose a softmax-normalized Gaussian\nnoise to mitigate privacy leakage and make our K unknowable to adversaries. We\nconducted experiments on real-world datasets, including two\nbinary-classification datasets (Avazu and Criteo) and three\nmulti-classification datasets (MNIST, FashionMNIST, CIFAR-10); we also\nconsidered current attack schemes, including direction, norm, spectral, and\nmodel completion attacks. The detailed experiments demonstrate our proposed\nmethod's effectiveness and superiority over existing approaches. For instance,\non the Avazu dataset, the attack AUC of evaluated four prominent attacks could\nbe reduced by 0.4532+-0.0127.",
      "tldr_zh": "该论文提出了一种新颖的两方Split Learning方法，旨在缓解标签推断攻击(label inference attacks)对隐私的威胁，同时保持模型的高效用。具体地，该方法引入了Secure Dimension Transformation (SecDT)模块，实现原始标签与扩展K类标签之间的双向映射，并结合梯度归一化算法和Softmax-normalized Gaussian噪声，以消除梯度差异并隐藏K值。实验在真实数据集（如Avazu、Criteo、MNIST等）上评估多种攻击（包括direction、norm、spectral和model completion attacks），结果显示该方法显著降低了攻击成功率，例如在Avazu数据集上，四种主要攻击的AUC下降了0.4532±0.0127，优于现有防御方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09125v1",
      "published_date": "2024-10-11 09:25:21 UTC",
      "updated_date": "2024-10-11 09:25:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:27:10.761047"
    },
    {
      "arxiv_id": "2410.08643v1",
      "title": "SOAK: Same/Other/All K-fold cross-validation for estimating similarity of patterns in data subsets",
      "title_zh": "SOAK：Same/Other/All K折交叉验证用于估计数据子集中的模式相似性",
      "authors": [
        "Toby Dylan Hocking",
        "Gabrielle Thibault",
        "Cameron Scott Bodine",
        "Paul Nelson Arellano",
        "Alexander F Shenkin",
        "Olivia Jasmine Lindly"
      ],
      "abstract": "In many real-world applications of machine learning, we are interested to\nknow if it is possible to train on the data that we have gathered so far, and\nobtain accurate predictions on a new test data subset that is qualitatively\ndifferent in some respect (time period, geographic region, etc). Another\nquestion is whether data subsets are similar enough so that it is beneficial to\ncombine subsets during model training. We propose SOAK, Same/Other/All K-fold\ncross-validation, a new method which can be used to answer both questions. SOAK\nsystematically compares models which are trained on different subsets of data,\nand then used for prediction on a fixed test subset, to estimate the similarity\nof learnable/predictable patterns in data subsets. We show results of using\nSOAK on six new real data sets (with geographic/temporal subsets, to check if\npredictions are accurate on new subsets), 3 image pair data sets (subsets are\ndifferent image types, to check that we get smaller prediction error on similar\nimages), and 11 benchmark data sets with predefined train/test splits (to check\nsimilarity of predefined splits).",
      "tldr_zh": "该论文提出SOAK（Same/Other/All K-fold cross-validation）方法，用于评估数据子集之间可学习/可预测模式的相似性，帮助判断是否能在当前数据上训练模型并准确预测新子集，或是否应合并子集进行训练。SOAK通过系统比较在不同数据子集上训练的模型，然后在固定测试子集上进行预测，来量化子集相似性。实验结果显示，在六个真实数据集（涉及地理/时间子集）、三个图像对数据集（不同图像类型）和十一个基准数据集上，SOAK有效提高了预测准确性和错误率控制。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08643v1",
      "published_date": "2024-10-11 09:10:39 UTC",
      "updated_date": "2024-10-11 09:10:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:27:22.204588"
    },
    {
      "arxiv_id": "2410.08635v1",
      "title": "Efficient line search for optimizing Area Under the ROC Curve in gradient descent",
      "title_zh": "在梯度下降中优化 ROC 曲线下面积的高效线搜索",
      "authors": [
        "Jadon Fowler",
        "Toby Dylan Hocking"
      ],
      "abstract": "Receiver Operating Characteristic (ROC) curves are useful for evaluation in\nbinary classification and changepoint detection, but difficult to use for\nlearning since the Area Under the Curve (AUC) is piecewise constant (gradient\nzero almost everywhere). Recently the Area Under Min (AUM) of false positive\nand false negative rates has been proposed as a differentiable surrogate for\nAUC. In this paper we study the piecewise linear/constant nature of the\nAUM/AUC, and propose new efficient path-following algorithms for choosing the\nlearning rate which is optimal for each step of gradient descent (line search),\nwhen optimizing a linear model. Remarkably, our proposed line search algorithm\nhas the same log-linear asymptotic time complexity as gradient descent with\nconstant step size, but it computes a complete representation of the AUM/AUC as\na function of step size. In our empirical study of binary classification\nproblems, we verify that our proposed algorithm is fast and exact; in\nchangepoint detection problems we show that the proposed algorithm is just as\naccurate as grid search, but faster.",
      "tldr_zh": "该论文针对优化二元分类中的 Area Under the ROC Curve (AUC) 问题，提出使用 Area Under Min (AUM) 作为可微替代，以解决 AUC 的分段常数性质导致梯度下降困难。该方法开发了高效的路径跟踪算法，在梯度下降中进行最优学习率线搜索（line search），适用于线性模型，且该算法的渐近时间复杂度与固定步长梯度下降相同，同时能完整表示 AUM/AUC 与步长的关系。在实证实验中，该算法在二元分类问题上表现出快速和精确的优势，在变化点检测问题上与网格搜索相当准确但计算速度更快。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08635v1",
      "published_date": "2024-10-11 08:59:06 UTC",
      "updated_date": "2024-10-11 08:59:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:27:34.995692"
    },
    {
      "arxiv_id": "2410.08632v1",
      "title": "Words as Beacons: Guiding RL Agents with High-Level Language Prompts",
      "title_zh": "词语作为信标：使用高级语言提示指导强化学习代理",
      "authors": [
        "Unai Ruiz-Gonzalez",
        "Alain Andres",
        "Pedro G. Bascoy",
        "Javier Del Ser"
      ],
      "abstract": "Sparse reward environments in reinforcement learning (RL) pose significant\nchallenges for exploration, often leading to inefficient or incomplete learning\nprocesses. To tackle this issue, this work proposes a teacher-student RL\nframework that leverages Large Language Models (LLMs) as \"teachers\" to guide\nthe agent's learning process by decomposing complex tasks into subgoals. Due to\ntheir inherent capability to understand RL environments based on a textual\ndescription of structure and purpose, LLMs can provide subgoals to accomplish\nthe task defined for the environment in a similar fashion to how a human would\ndo. In doing so, three types of subgoals are proposed: positional targets\nrelative to the agent, object representations, and language-based instructions\ngenerated directly by the LLM. More importantly, we show that it is possible to\nquery the LLM only during the training phase, enabling agents to operate within\nthe environment without any LLM intervention. We assess the performance of this\nproposed framework by evaluating three state-of-the-art open-source LLMs\n(Llama, DeepSeek, Qwen) eliciting subgoals across various procedurally\ngenerated environment of the MiniGrid benchmark. Experimental results\ndemonstrate that this curriculum-based approach accelerates learning and\nenhances exploration in complex tasks, achieving up to 30 to 200 times faster\nconvergence in training steps compared to recent baselines designed for sparse\nreward environments.",
      "tldr_zh": "本研究提出了一种 teacher-student RL 框架，利用 Large Language Models (LLMs) 作为“老师”，通过高水平语言提示将复杂任务分解成子目标，以解决强化学习（RL）中稀疏奖励环境的探索挑战。LLMs 基于环境的文本描述生成三种子目标，包括位置目标（positional targets）、对象表示（object representations）和语言指令，从而指导代理像人类一样高效学习。实验评估了 Llama、DeepSeek 和 Qwen 等开源 LLMs 在 MiniGrid 基准的环境中，结果显示这种基于课程的方法加速了学习过程，并提升了探索效率，与现有基线相比，训练步骤收敛速度可快 30 到 200 倍。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08632v1",
      "published_date": "2024-10-11 08:54:45 UTC",
      "updated_date": "2024-10-11 08:54:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:27:45.577776"
    },
    {
      "arxiv_id": "2410.08631v2",
      "title": "CryoFM: A Flow-based Foundation Model for Cryo-EM Densities",
      "title_zh": "翻译失败",
      "authors": [
        "Yi Zhou",
        "Yilai Li",
        "Jing Yuan",
        "Quanquan Gu"
      ],
      "abstract": "Cryo-electron microscopy (cryo-EM) is a powerful technique in structural\nbiology and drug discovery, enabling the study of biomolecules at high\nresolution. Significant advancements by structural biologists using cryo-EM\nhave led to the production of over 38,626 protein density maps at various\nresolutions1. However, cryo-EM data processing algorithms have yet to fully\nbenefit from our knowledge of biomolecular density maps, with only a few recent\nmodels being data-driven but limited to specific tasks. In this study, we\npresent CryoFM, a foundation model designed as a generative model, learning the\ndistribution of high-quality density maps and generalizing effectively to\ndownstream tasks. Built on flow matching, CryoFM is trained to accurately\ncapture the prior distribution of biomolecular density maps. Furthermore, we\nintroduce a flow posterior sampling method that leverages CRYOFM as a flexible\nprior for several downstream tasks in cryo-EM and cryo-electron tomography\n(cryo-ET) without the need for fine-tuning, achieving state-of-the-art\nperformance on most tasks and demonstrating its potential as a foundational\nmodel for broader applications in these fields.",
      "tldr_zh": "本研究针对 cryo-EM（冷冻电子显微镜）数据处理中的局限性，提出了 CryoFM，一种基于 flow matching 的 foundation model，用于学习高质量生物分子密度图的分布，从而提升结构生物学和药物发现的应用。\nCryoFM 通过训练捕获先验分布，并引入 flow posterior sampling 方法，作为灵活的 prior，支持 cryo-EM 和 cryo-ET（冷冻电子断层扫描）等下游任务，而无需 fine-tuning。\n实验结果表明，CryoFM 在大多数任务上达到了 state-of-the-art 性能，展示了其作为基础模型的广阔潜力。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.CE",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08631v2",
      "published_date": "2024-10-11 08:53:58 UTC",
      "updated_date": "2024-12-04 06:58:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:27:58.357882"
    },
    {
      "arxiv_id": "2410.08613v1",
      "title": "Cross-Modal Bidirectional Interaction Model for Referring Remote Sensing Image Segmentation",
      "title_zh": "用于指称遥感图像分割的跨模态双向交互模型",
      "authors": [
        "Zhe Dong",
        "Yuzhe Sun",
        "Yanfeng Gu",
        "Tianzhu Liu"
      ],
      "abstract": "Given a natural language expression and a remote sensing image, the goal of\nreferring remote sensing image segmentation (RRSIS) is to generate a\npixel-level mask of the target object identified by the referring expression.\nIn contrast to natural scenarios, expressions in RRSIS often involve complex\ngeospatial relationships, with target objects of interest that vary\nsignificantly in scale and lack visual saliency, thereby increasing the\ndifficulty of achieving precise segmentation. To address the aforementioned\nchallenges, a novel RRSIS framework is proposed, termed the cross-modal\nbidirectional interaction model (CroBIM). Specifically, a context-aware prompt\nmodulation (CAPM) module is designed to integrate spatial positional\nrelationships and task-specific knowledge into the linguistic features, thereby\nenhancing the ability to capture the target object. Additionally, a\nlanguage-guided feature aggregation (LGFA) module is introduced to integrate\nlinguistic information into multi-scale visual features, incorporating an\nattention deficit compensation mechanism to enhance feature aggregation.\nFinally, a mutual-interaction decoder (MID) is designed to enhance cross-modal\nfeature alignment through cascaded bidirectional cross-attention, thereby\nenabling precise segmentation mask prediction. To further forster the research\nof RRSIS, we also construct RISBench, a new large-scale benchmark dataset\ncomprising 52,472 image-language-label triplets. Extensive benchmarking on\nRISBench and two other prevalent datasets demonstrates the superior performance\nof the proposed CroBIM over existing state-of-the-art (SOTA) methods. The\nsource code for CroBIM and the RISBench dataset will be publicly available at\nhttps://github.com/HIT-SIRS/CroBIM",
      "tldr_zh": "本论文针对Referring Remote Sensing Image Segmentation (RRSIS)任务，提出一种Cross-Modal Bidirectional Interaction Model (CroBIM)框架，用于从自然语言表达式中精确生成遥感图像目标对象的像素级掩码，以应对复杂地理空间关系和目标规模变化带来的挑战。CroBIM包括Context-Aware Prompt Modulation (CAPM)模块，用于整合空间位置关系和任务知识增强语言特征；Language-Guided Feature Aggregation (LGFA)模块，将语言信息融入多尺度视觉特征并引入注意力缺陷补偿机制；以及Mutual-Interaction Decoder (MID)模块，通过级联双向交叉注意力提升跨模态特征对齐，实现精确分割。论文还构建了大规模基准数据集RISBench，包含52,472个图像-语言-标签三元组，并在多个数据集上实验证明CroBIM优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08613v1",
      "published_date": "2024-10-11 08:28:04 UTC",
      "updated_date": "2024-10-11 08:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:28:10.577792"
    },
    {
      "arxiv_id": "2410.08612v1",
      "title": "Synth-SONAR: Sonar Image Synthesis with Enhanced Diversity and Realism via Dual Diffusion Models and GPT Prompting",
      "title_zh": "翻译失败",
      "authors": [
        "Purushothaman Natarajan",
        "Kamal Basha",
        "Athira Nambiar"
      ],
      "abstract": "Sonar image synthesis is crucial for advancing applications in underwater\nexploration, marine biology, and defence. Traditional methods often rely on\nextensive and costly data collection using sonar sensors, jeopardizing data\nquality and diversity. To overcome these limitations, this study proposes a new\nsonar image synthesis framework, Synth-SONAR leveraging diffusion models and\nGPT prompting. The key novelties of Synth-SONAR are threefold: First, by\nintegrating Generative AI-based style injection techniques along with publicly\navailable real/simulated data, thereby producing one of the largest sonar data\ncorpus for sonar research. Second, a dual text-conditioning sonar diffusion\nmodel hierarchy synthesizes coarse and fine-grained sonar images with enhanced\nquality and diversity. Third, high-level (coarse) and low-level (detailed)\ntext-based sonar generation methods leverage advanced semantic information\navailable in visual language models (VLMs) and GPT-prompting. During inference,\nthe method generates diverse and realistic sonar images from textual prompts,\nbridging the gap between textual descriptions and sonar image generation. This\nmarks the application of GPT-prompting in sonar imagery for the first time, to\nthe best of our knowledge. Synth-SONAR achieves state-of-the-art results in\nproducing high-quality synthetic sonar datasets, significantly enhancing their\ndiversity and realism.",
      "tldr_zh": "本研究提出 Synth-SONAR 框架，利用 dual diffusion models 和 GPT prompting 来提升 sonar 图像合成的多样性和真实性，解决传统方法依赖昂贵数据收集的局限性。该框架的关键创新包括整合 Generative AI-based style injection 与公开数据，创建最大的 sonar 数据集；采用双文本条件 diffusion 模型层次结构，生成高质量的粗粒度和细粒度图像；以及利用 VLMs 和 GPT-prompting 从文本提示合成多样 sonar 图像，这是 GPT-prompting 在 sonar 领域应用的首次尝试。Synth-SONAR 实现了 state-of-the-art 结果，显著提高了合成数据集的多样性、真实性和质量，支持水下探索、海洋生物学和国防应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "94A08 (Primary) 68T45, 68U10 (Secondary)",
        "I.2.0; I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 5 tables and 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.08612v1",
      "published_date": "2024-10-11 08:27:25 UTC",
      "updated_date": "2024-10-11 08:27:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:28:22.660069"
    },
    {
      "arxiv_id": "2410.08611v1",
      "title": "Conjugated Semantic Pool Improves OOD Detection with Pre-trained Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mengyuan Chen",
        "Junyu Gao",
        "Changsheng Xu"
      ],
      "abstract": "A straightforward pipeline for zero-shot out-of-distribution (OOD) detection\ninvolves selecting potential OOD labels from an extensive semantic pool and\nthen leveraging a pre-trained vision-language model to perform classification\non both in-distribution (ID) and OOD labels. In this paper, we theorize that\nenhancing performance requires expanding the semantic pool, while increasing\nthe expected probability of selected OOD labels being activated by OOD samples,\nand ensuring low mutual dependence among the activations of these OOD labels. A\nnatural expansion manner is to adopt a larger lexicon; however, the inevitable\nintroduction of numerous synonyms and uncommon words fails to meet the above\nrequirements, indicating that viable expansion manners move beyond merely\nselecting words from a lexicon. Since OOD detection aims to correctly classify\ninput images into ID/OOD class groups, we can \"make up\" OOD label candidates\nwhich are not standard class names but beneficial for the process. Observing\nthat the original semantic pool is comprised of unmodified specific class\nnames, we correspondingly construct a conjugated semantic pool (CSP) consisting\nof modified superclass names, each serving as a cluster center for samples\nsharing similar properties across different categories. Consistent with our\nestablished theory, expanding OOD label candidates with the CSP satisfies the\nrequirements and outperforms existing works by 7.89% in FPR95. Codes are\navailable in https://github.com/MengyuanChen21/NeurIPS2024-CSP.",
      "tldr_zh": "该论文提出了一种改进预训练视觉语言模型（Vision-Language Models）在零样本OOD（Out-of-Distribution）检测中的方法，通过构建一个conjugated semantic pool (CSP)，该池由修改后的超类名组成，作为不同类别共享相似属性的聚类中心，以扩展OOD标签候选并降低标签间的互相关联。CSP方法满足了扩展语义池的要求，包括提高OOD标签被激活的概率和确保低相互依赖，从而提升检测性能。实验结果显示，该方法在FPR95指标上比现有工作提高了7.89%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.08611v1",
      "published_date": "2024-10-11 08:24:11 UTC",
      "updated_date": "2024-10-11 08:24:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:28:33.916740"
    },
    {
      "arxiv_id": "2410.08608v1",
      "title": "Text-To-Image with Generative Adversarial Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Mehrshad Momen-Tayefeh"
      ],
      "abstract": "Generating realistic images from human texts is one of the most challenging\nproblems in the field of computer vision (CV). The meaning of descriptions\ngiven can be roughly reflected by existing text-to-image approaches. In this\npaper, our main purpose is to propose a brief comparison between five different\nmethods base on the Generative Adversarial Networks (GAN) to make image from\nthe text. In addition, each model architectures synthesis images with different\nresolution. Furthermore, the best and worst obtained resolutions is 64*64,\n256*256 respectively. However, we checked and compared some metrics that\nintroduce the accuracy of each model. Also, by doing this study, we found out\nthe best model for this problem by comparing these different approaches\nessential metrics.",
      "tldr_zh": "这篇论文探讨了基于 Generative Adversarial Networks (GAN) 的文本到图像生成技术，比较了五种不同方法来从人类描述生成逼真的图像。每个模型的架构生成了不同分辨率的图像，其中最佳分辨率为64*64，最差为256*256。论文通过评估各种准确性指标，最终确定了在这一任务中表现最佳的模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08608v1",
      "published_date": "2024-10-11 08:16:35 UTC",
      "updated_date": "2024-10-11 08:16:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:28:46.123196"
    },
    {
      "arxiv_id": "2410.08597v1",
      "title": "What killed the cat? Towards a logical formalization of curiosity (and suspense, and surprise) in narratives",
      "title_zh": "翻译失败",
      "authors": [
        "Florence Dupin de Saint-Cyr",
        "Anne-Gwenn Bosser",
        "Benjamin Callac",
        "Eric Maisel"
      ],
      "abstract": "We provide a unified framework in which the three emotions at the heart of\nnarrative tension (curiosity, suspense and surprise) are formalized. This\nframework is built on nonmonotonic reasoning which allows us to compactly\nrepresent the default behavior of the world and to simulate the affective\nevolution of an agent receiving a story. After formalizing the notions of\nawareness, curiosity, surprise and suspense, we explore the properties induced\nby our definitions and study the computational complexity of detecting them. We\nfinally propose means to evaluate these emotions' intensity for a given agent\nlistening to a story.",
      "tldr_zh": "本研究提出一个统一框架，通过非monotonic reasoning形式化叙事张力中的三种情感：curiosity（好奇心）、suspense（悬念）和surprise（惊喜）。该框架利用非单调推理来紧凑表示世界的默认行为，并模拟代理在接收故事时的情感演变。论文形式化了awareness（意识）、curiosity、surprise和suspense的概念，探讨这些定义的属性和检测计算复杂性，并提供方法评估这些情感的强度。最终，这为理解叙事情感提供了理论基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08597v1",
      "published_date": "2024-10-11 07:50:55 UTC",
      "updated_date": "2024-10-11 07:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:28:57.475929"
    },
    {
      "arxiv_id": "2410.08593v1",
      "title": "VERIFIED: A Video Corpus Moment Retrieval Benchmark for Fine-Grained Video Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Houlun Chen",
        "Xin Wang",
        "Hong Chen",
        "Zeyang Zhang",
        "Wei Feng",
        "Bin Huang",
        "Jia Jia",
        "Wenwu Zhu"
      ],
      "abstract": "Existing Video Corpus Moment Retrieval (VCMR) is limited to coarse-grained\nunderstanding, which hinders precise video moment localization when given\nfine-grained queries. In this paper, we propose a more challenging fine-grained\nVCMR benchmark requiring methods to localize the best-matched moment from the\ncorpus with other partially matched candidates. To improve the dataset\nconstruction efficiency and guarantee high-quality data annotations, we propose\nVERIFIED, an automatic \\underline{V}id\\underline{E}o-text annotation pipeline\nto generate captions with \\underline{R}el\\underline{I}able\n\\underline{FI}n\\underline{E}-grained statics and \\underline{D}ynamics.\nSpecifically, we resort to large language models (LLM) and large multimodal\nmodels (LMM) with our proposed Statics and Dynamics Enhanced Captioning modules\nto generate diverse fine-grained captions for each video. To filter out the\ninaccurate annotations caused by the LLM hallucination, we propose a\nFine-Granularity Aware Noise Evaluator where we fine-tune a video foundation\nmodel with disturbed hard-negatives augmented contrastive and matching losses.\nWith VERIFIED, we construct a more challenging fine-grained VCMR benchmark\ncontaining Charades-FIG, DiDeMo-FIG, and ActivityNet-FIG which demonstrate a\nhigh level of annotation quality. We evaluate several state-of-the-art VCMR\nmodels on the proposed dataset, revealing that there is still significant scope\nfor fine-grained video understanding in VCMR. Code and Datasets are in\n\\href{https://github.com/hlchen23/VERIFIED}{https://github.com/hlchen23/VERIFIED}.",
      "tldr_zh": "本论文针对现有 Video Corpus Moment Retrieval (VCMR) 的粗粒度理解局限，提出一个更具挑战性的细粒度 VCMR 基准，以实现精确的视频时刻定位。论文引入 VERIFIED 自动视频-文本标注管道，利用 Large Language Models (LLM) 和 Large Multimodal Models (LMM) 结合 Statics and Dynamics Enhanced Captioning 模块生成多样化的细粒度字幕，并通过 Fine-Granularity Aware Noise Evaluator 过滤 LLM 幻觉引起的噪声，确保标注质量。基于 VERIFIED 构建了 Charades-FIG、DiDeMo-FIG 和 ActivityNet-FIG 等高质量数据集，并在这些数据集上评估了现有最先进模型，结果显示细粒度视频理解领域仍有显著改进空间。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by 38th NeurIPS Datasets & Benchmarks Track (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.08593v1",
      "published_date": "2024-10-11 07:42:36 UTC",
      "updated_date": "2024-10-11 07:42:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:29:11.501782"
    },
    {
      "arxiv_id": "2410.08592v1",
      "title": "VIBES -- Vision Backbone Efficient Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Joris Guerin",
        "Shray Bansal",
        "Amirreza Shaban",
        "Paulo Mann",
        "Harshvardhan Gazula"
      ],
      "abstract": "This work tackles the challenge of efficiently selecting high-performance\npre-trained vision backbones for specific target tasks. Although exhaustive\nsearch within a finite set of backbones can solve this problem, it becomes\nimpractical for large datasets and backbone pools. To address this, we\nintroduce Vision Backbone Efficient Selection (VIBES), which aims to quickly\nfind well-suited backbones, potentially trading off optimality for efficiency.\nWe propose several simple yet effective heuristics to address VIBES and\nevaluate them across four diverse computer vision datasets. Our results show\nthat these approaches can identify backbones that outperform those selected\nfrom generic benchmarks, even within a limited search budget of one hour on a\nsingle GPU. We reckon VIBES marks a paradigm shift from benchmarks to\ntask-specific optimization.",
      "tldr_zh": "该研究提出VIBES（Vision Backbone Efficient Selection）方法，旨在高效选择适合特定任务的高性能预训练视觉骨干网络，避免了传统穷尽搜索的低效问题。通过采用简单有效的启发式策略，VIBES能在有限的搜索预算（如一个GPU上的一个小时）内快速识别出优化的骨干网络。实验在四个多样化的计算机视觉数据集上验证，这些方法表现优于通用基准，帮助提升任务特定性能。该框架标志着从基准测试向任务特定优化的范式转变。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "9 pages, 4 figures, under review at WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08592v1",
      "published_date": "2024-10-11 07:39:52 UTC",
      "updated_date": "2024-10-11 07:39:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:29:22.343082"
    },
    {
      "arxiv_id": "2410.09124v1",
      "title": "SoK: Verifiable Cross-Silo FL",
      "title_zh": "SoK",
      "authors": [
        "Aleksei Korneev",
        "Jan Ramon"
      ],
      "abstract": "Federated Learning (FL) is a widespread approach that allows training machine\nlearning (ML) models with data distributed across multiple devices. In\ncross-silo FL, which often appears in domains like healthcare or finance, the\nnumber of participants is moderate, and each party typically represents a\nwell-known organization. For instance, in medicine data owners are often\nhospitals or data hubs which are well-established entities. However, malicious\nparties may still attempt to disturb the training procedure in order to obtain\ncertain benefits, for example, a biased result or a reduction in computational\nload. While one can easily detect a malicious agent when data used for training\nis public, the problem becomes much more acute when it is necessary to maintain\nthe privacy of the training dataset. To address this issue, there is recently\ngrowing interest in developing verifiable protocols, where one can check that\nparties do not deviate from the training procedure and perform computations\ncorrectly. In this paper, we present a systematization of knowledge on\nverifiable cross-silo FL. We analyze various protocols, fit them in a taxonomy,\nand compare their efficiency and threat models. We also analyze Zero-Knowledge\nProof (ZKP) schemes and discuss how their overall cost in a FL context can be\nminimized. Lastly, we identify research gaps and discuss potential directions\nfor future scientific work.",
      "tldr_zh": "本论文（SoK: Verifiable Cross-Silo FL）系统化了可验证跨组织联邦学习（Verifiable Cross-Silo FL）的知识，针对医疗和金融等领域中组织间数据训练的潜在恶意行为，如数据所有者篡改过程以获得偏向结果。作者分析了各种可验证协议，将它们归入分类学框架，并比较了这些协议的效率和威胁模型，以确保参与者在保持数据隐私的前提下正确执行训练。论文还探讨了Zero-Knowledge Proof (ZKP)方案及其在联邦学习（FL）中的成本优化策略。最终，研究识别了现有空白，并提出了未来研究的潜在方向，如增强协议的鲁棒性和效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.09124v1",
      "published_date": "2024-10-11 07:39:35 UTC",
      "updated_date": "2024-10-11 07:39:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:29:33.695637"
    },
    {
      "arxiv_id": "2410.08588v1",
      "title": "ViT3D Alignment of LLaMA3: 3D Medical Image Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Siyou Li",
        "Beining Xu",
        "Yihao Luo",
        "Dong Nie",
        "Le Zhang"
      ],
      "abstract": "Automatic medical report generation (MRG), which aims to produce detailed\ntext reports from medical images, has emerged as a critical task in this\ndomain. MRG systems can enhance radiological workflows by reducing the time and\neffort required for report writing, thereby improving diagnostic efficiency. In\nthis work, we present a novel approach for automatic MRG utilizing a multimodal\nlarge language model. Specifically, we employed the 3D Vision Transformer\n(ViT3D) image encoder introduced from M3D-CLIP to process 3D scans and use the\nAsclepius-Llama3-8B as the language model to generate the text reports by\nauto-regressive decoding. The experiment shows our model achieved an average\nGreen score of 0.3 on the MRG task validation set and an average accuracy of\n0.61 on the visual question answering (VQA) task validation set, outperforming\nthe baseline model. Our approach demonstrates the effectiveness of the ViT3D\nalignment of LLaMA3 for automatic MRG and VQA tasks by tuning the model on a\nsmall dataset.",
      "tldr_zh": "本研究提出了一种新型自动医疗报告生成(MRG)方法，利用多模态大型语言模型，通过ViT3D图像编码器处理3D医疗扫描，并结合Asclepius-Llama3-8B语言模型进行自回归文本报告生成，以提高放射学工作流程效率。\n该方法在小数据集上微调模型，实验显示在MRG任务验证集上平均Green分数达到0.3，在视觉问答(VQA)任务上平均准确率达0.61，均优于基线模型。\n整体结果证明了ViT3D与LLaMA3的对齐在MRG和VQA任务中的有效性，为自动化医疗图像分析提供了可行路径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08588v1",
      "published_date": "2024-10-11 07:35:33 UTC",
      "updated_date": "2024-10-11 07:35:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:29:46.666599"
    },
    {
      "arxiv_id": "2410.08584v2",
      "title": "ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification",
      "title_zh": "ZipVL：高效的大型视觉语言模型，采用动态令牌稀疏化",
      "authors": [
        "Yefei He",
        "Feng Chen",
        "Jing Liu",
        "Wenqi Shao",
        "Hong Zhou",
        "Kaipeng Zhang",
        "Bohan Zhuang"
      ],
      "abstract": "The efficiency of large vision-language models (LVLMs) is constrained by the\ncomputational bottleneck of the attention mechanism during the prefill phase\nand the memory bottleneck of fetching the key-value (KV) cache in the decoding\nphase, particularly in scenarios involving high-resolution images or videos.\nVisual content often exhibits substantial redundancy, resulting in highly\nsparse attention maps within LVLMs. This sparsity can be leveraged to\naccelerate attention computation or compress the KV cache through various\napproaches. However, most studies focus on addressing only one of these\nbottlenecks and do not adequately support dynamic adjustment of sparsity\nconcerning distinct layers or tasks. In this paper, we present ZipVL, an\nefficient inference framework designed for LVLMs through a dynamic ratio\nallocation strategy of important tokens. This ratio is adaptively determined\nbased on the layer-specific distribution of attention scores, rather than fixed\nhyper-parameters, thereby improving efficiency for less complex tasks while\nmaintaining high performance for more challenging ones. Then we select\nimportant tokens based on their normalized attention scores and perform sparse\nattention mechanism solely on those important tokens, reducing the latency in\nthe prefill phase. Tokens deemed less important will be discarded to reduce KV\ncache size, alleviating the memory bottleneck in the decoding phase. Our\nexperiments demonstrate that ZipVL can accelerate the prefill phase by\n2.3$\\times$ and improve decoding throughput by 2.8$\\times$, with a minimal\naccuracy reduction of only 0.5\\% on VQAv2 benchmark over LLaVA-Next-13B model,\neffectively enhancing the generation efficiency of LVLMs.",
      "tldr_zh": "该研究针对大型视觉语言模型 (LVLMs) 在预填充阶段的注意力机制计算瓶颈和解码阶段的 KV 缓存内存瓶颈，提出了一种高效框架 ZipVL，通过动态 token 稀疏化策略来提升效率。ZipVL 基于层特定的注意力分数分布自适应分配重要 tokens 的比例，仅对这些 tokens 进行稀疏注意力机制，从而加速预填充阶段并减少 KV 缓存大小。实验结果显示，ZipVL 使预填充阶段加速 2.3 倍、解码吞吐量提高 2.8 倍，同时在 VQAv2 基准上，LLaVA-Next-13B 模型的准确率仅下降 0.5%，显著改善了 LVLM 的生成效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2410.08584v2",
      "published_date": "2024-10-11 07:24:21 UTC",
      "updated_date": "2024-12-18 07:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:29:58.335712"
    },
    {
      "arxiv_id": "2410.08583v1",
      "title": "Intent-Enhanced Data Augmentation for Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Chen",
        "Zhoujun Li"
      ],
      "abstract": "The research on intent-enhanced sequential recommendation algorithms focuses\non how to better mine dynamic user intent based on user behavior data for\nsequential recommendation tasks. Various data augmentation methods are widely\napplied in current sequential recommendation algorithms, effectively enhancing\nthe ability to capture user intent. However, these widely used data\naugmentation methods often rely on a large amount of random sampling, which can\nintroduce excessive noise into the training data, blur user intent, and thus\nnegatively affect recommendation performance. Additionally, these methods have\nlimited approaches to utilizing augmented data, failing to fully leverage the\naugmented samples. We propose an intent-enhanced data augmentation method for\nsequential recommendation(\\textbf{IESRec}), which constructs positive and\nnegative samples based on user behavior sequences through intent-segment\ninsertion. On one hand, the generated positive samples are mixed with the\noriginal training data, and they are trained together to improve recommendation\nperformance. On the other hand, the generated positive and negative samples are\nused to build a contrastive loss function, enhancing recommendation performance\nthrough self-supervised training. Finally, the main recommendation task is\njointly trained with the contrastive learning loss minimization task.\nExperiments on three real-world datasets validate the effectiveness of our\nIESRec model.",
      "tldr_zh": "该研究针对序列推荐（Sequential Recommendation）中的数据增强问题，指出现有方法依赖随机采样易引入噪声并模糊用户意图，从而影响性能。提出了一种意图增强数据增强方法IESRec，通过基于用户行为序列的意图段插入生成正负样本，并将正样本与原数据混合训练，同时利用正负样本构建对比损失函数（Contrastive Loss）进行自监督训练，以提升推荐效果。实验在三个真实数据集上验证了IESRec的有效性，证明了其在改善用户意图挖掘和推荐性能方面的优势。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "14 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.08583v1",
      "published_date": "2024-10-11 07:23:45 UTC",
      "updated_date": "2024-10-11 07:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:30:09.420017"
    },
    {
      "arxiv_id": "2410.08581v1",
      "title": "Integrating AI for Enhanced Feedback in Translation Revision- A Mixed-Methods Investigation of Student Engagement",
      "title_zh": "翻译失败",
      "authors": [
        "Simin Xu",
        "Yanfang Su",
        "Kanglong Liu"
      ],
      "abstract": "Despite the well-established importance of feedback in education, the\napplication of Artificial Intelligence (AI)-generated feedback, particularly\nfrom language models like ChatGPT, remains understudied in translation\neducation. This study investigates the engagement of master's students in\ntranslation with ChatGPT-generated feedback during their revision process. A\nmixed-methods approach, combining a translation-and-revision experiment with\nquantitative and qualitative analyses, was employed to examine the feedback,\ntranslations pre-and post-revision, the revision process, and student\nreflections. The results reveal complex interrelations among cognitive,\naffective, and behavioural dimensions influencing students' engagement with AI\nfeedback and their subsequent revisions. Specifically, the findings indicate\nthat students invested considerable cognitive effort in the revision process,\ndespite finding the feedback comprehensible. Additionally, they exhibited\nmoderate affective satisfaction with the feedback model. Behaviourally, their\nactions were largely influenced by cognitive and affective factors, although\nsome inconsistencies were observed. This research provides novel insights into\nthe potential applications of AI-generated feedback in translation teachingand\nopens avenues for further investigation into the integration of AI tools in\nlanguage teaching settings.",
      "tldr_zh": "本研究探讨了在翻译教育中使用AI（如ChatGPT）生成反馈对硕士学生参与度的影响，采用混合方法（mixed-methods approach）结合翻译和修订实验、定量及定性分析，考察了反馈、翻译前后变化、修订过程及学生反思。结果显示，学生在修订过程中投入了大量认知努力，尽管反馈易懂，但情感满意度（affective satisfaction）中等，且行为受认知和情感因素影响虽显著，却存在某些不一致性。该研究为AI-generated feedback在翻译教学中的应用提供了新见解，并为AI工具在语言教学环境的整合打开了进一步研究路径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08581v1",
      "published_date": "2024-10-11 07:21:29 UTC",
      "updated_date": "2024-10-11 07:21:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:30:22.828523"
    },
    {
      "arxiv_id": "2410.21284v1",
      "title": "AI-driven innovation in medicaid: enhancing access, cost efficiency, and population health management",
      "title_zh": "人工智能驱动的创新在Medicaid中：提升访问、成本效率和人口",
      "authors": [
        "Balaji Shesharao Ingole",
        "Vishnu Ramineni",
        "Manjunatha Sughaturu Krishnappa",
        "Vivekananda Jayaram"
      ],
      "abstract": "The U.S. Medicaid program is experiencing critical challenges that include\nrapidly increasing healthcare costs, uneven care accessibility, and the\nchallenge associated with addressing a varied set of population health needs.\nThis paper investigates the transformative potential of Artificial Intelligence\n(AI) in reshaping Medicaid by streamlining operations, improving patient\nresults, and lowering costs. We delve into the pivotal role of AI in predictive\nanalytics, care coordination, the detection of fraud, and personalized\nmedicine. By leveraging insights from advanced data models and addressing\nchallenges particular to Medicaid, we put forward AI-driven solutions that\nprioritize equitable care and improved public health outcomes. This study\nunderscores the urgency of integrating AI into Medicaid to not only improve\noperational effectiveness but also to create a more accessible and equitable\nhealthcare system for all beneficiaries.",
      "tldr_zh": "这篇论文探讨了美国Medicaid程序面临的挑战，包括医疗成本快速上升、护理可及性不均以及多样化的人口健康需求，并强调了Artificial Intelligence (AI)在其重塑中的潜力。作者分析了AI在预测分析、护理协调、欺诈检测和个性化医学中的应用，通过高级数据模型提出AI驱动解决方案，以简化操作、降低成本并改善患者结果。最终，该研究呼吁将AI整合到Medicaid中，促进公平护理和更佳的公共健康管理，从而构建一个更具可及性和高效性的医疗体系。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21284v1",
      "published_date": "2024-10-11 07:14:42 UTC",
      "updated_date": "2024-10-11 07:14:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:30:34.509826"
    },
    {
      "arxiv_id": "2410.09123v2",
      "title": "Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs",
      "title_zh": "上下文感知适配器调优用于知识图谱中的少样本关系学习",
      "authors": [
        "Ran Liu",
        "Zhongzhou Liu",
        "Xiaoli Li",
        "Yuan Fang"
      ],
      "abstract": "Knowledge graphs (KGs) are instrumental in various real-world applications,\nyet they often suffer from incompleteness due to missing relations. To predict\ninstances for novel relations with limited training examples, few-shot relation\nlearning approaches have emerged, utilizing techniques such as meta-learning.\nHowever, the assumption is that novel relations in meta-testing and base\nrelations in meta-training are independently and identically distributed, which\nmay not hold in practice. To address the limitation, we propose RelAdapter, a\ncontext-aware adapter for few-shot relation learning in KGs designed to enhance\nthe adaptation process in meta-learning. First, RelAdapter is equipped with a\nlightweight adapter module that facilitates relation-specific, tunable\nadaptation of meta-knowledge in a parameter-efficient manner. Second,\nRelAdapter is enriched with contextual information about the target relation,\nenabling enhanced adaptation to each distinct relation. Extensive experiments\non three benchmark KGs validate the superiority of RelAdapter over\nstate-of-the-art methods.",
      "tldr_zh": "知识图谱（KGs）常因关系缺失而存在不完整性，现有的 few-shot relation learning 方法依赖 meta-learning 但假设新型关系与基础关系独立同分布，这一假设在实践中往往不成立。  \n为此，本文提出 RelAdapter，一种 context-aware adapter，用于提升 few-shot relation learning 的适应性。  \nRelAdapter 包含一个轻量级 adapter module，实现关系特定的参数高效 meta-knowledge 调整，并整合目标关系的 contextual information 以增强针对性。  \n在三个基准 KGs 上进行的广泛实验证明，RelAdapter 优于 state-of-the-art 方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by EMNLP 2024",
      "pdf_url": "http://arxiv.org/pdf/2410.09123v2",
      "published_date": "2024-10-11 07:06:45 UTC",
      "updated_date": "2024-10-17 07:00:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:30:46.233874"
    },
    {
      "arxiv_id": "2410.08576v1",
      "title": "A Theoretical Framework for AI-driven data quality monitoring in high-volume data environments",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Bangad",
        "Vivekananda Jayaram",
        "Manjunatha Sughaturu Krishnappa",
        "Amey Ram Banarse",
        "Darshan Mohan Bidkar",
        "Akshay Nagpal",
        "Vidyasagar Parlapalli"
      ],
      "abstract": "This paper presents a theoretical framework for an AI-driven data quality\nmonitoring system designed to address the challenges of maintaining data\nquality in high-volume environments. We examine the limitations of traditional\nmethods in managing the scale, velocity, and variety of big data and propose a\nconceptual approach leveraging advanced machine learning techniques. Our\nframework outlines a system architecture that incorporates anomaly detection,\nclassification, and predictive analytics for real-time, scalable data quality\nmanagement. Key components include an intelligent data ingestion layer,\nadaptive preprocessing mechanisms, context-aware feature extraction, and\nAI-based quality assessment modules. A continuous learning paradigm is central\nto our framework, ensuring adaptability to evolving data patterns and quality\nrequirements. We also address implications for scalability, privacy, and\nintegration within existing data ecosystems. While practical results are not\nprovided, it lays a robust theoretical foundation for future research and\nimplementations, advancing data quality management and encouraging the\nexploration of AI-driven solutions in dynamic environments.",
      "tldr_zh": "本论文提出一个理论框架，用于AI-driven的数据质量监控系统，以应对高容量数据环境中的规模、速度和多样性挑战。框架整合高级machine learning技术，包括anomaly detection、classification和predictive analytics，实现实时、可扩展的数据质量管理，其关键组件涵盖智能数据摄取层、适应性预处理机制、上下文感知特征提取以及AI-based质量评估模块。中央的持续学习范式确保系统适应演变的数据模式，并考虑可扩展性、隐私和现有数据生态系统的集成，为未来研究和AI驱动解决方案奠定坚实基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08576v1",
      "published_date": "2024-10-11 07:06:36 UTC",
      "updated_date": "2024-10-11 07:06:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:30:59.003010"
    },
    {
      "arxiv_id": "2410.08565v4",
      "title": "Baichuan-Omni Technical Report",
      "title_zh": "Baichuan-Omni 技术报告",
      "authors": [
        "Yadong Li",
        "Haoze Sun",
        "Mingan Lin",
        "Tianpeng Li",
        "Guosheng Dong",
        "Tao Zhang",
        "Bowen Ding",
        "Wei Song",
        "Zhenglin Cheng",
        "Yuqi Huo",
        "Song Chen",
        "Xu Li",
        "Da Pan",
        "Shusen Zhang",
        "Xin Wu",
        "Zheng Liang",
        "Jun Liu",
        "Tao Zhang",
        "Keer Lu",
        "Yaqi Zhao",
        "Yanjun Shen",
        "Fan Yang",
        "Kaicheng Yu",
        "Tao Lin",
        "Jianhua Xu",
        "Zenan Zhou",
        "Weipeng Chen"
      ],
      "abstract": "The salient multimodal capabilities and interactive experience of GPT-4o\nhighlight its critical role in practical applications, yet it lacks a\nhigh-performing open-source counterpart. In this paper, we introduce\nBaichuan-omni, the first open-source 7B Multimodal Large Language Model (MLLM)\nadept at concurrently processing and analyzing modalities of image, video,\naudio, and text, while delivering an advanced multimodal interactive experience\nand strong performance. We propose an effective multimodal training schema\nstarting with 7B model and proceeding through two stages of multimodal\nalignment and multitask fine-tuning across audio, image, video, and text modal.\nThis approach equips the language model with the ability to handle visual and\naudio data effectively. Demonstrating strong performance across various\nomni-modal and multimodal benchmarks, we aim for this contribution to serve as\na competitive baseline for the open-source community in advancing multimodal\nunderstanding and real-time interaction.",
      "tldr_zh": "本论文介绍了 Baichuan-omni，这是首个开源的 7B Multimodal Large Language Model (MLLM)，能够同时处理图像、视频、音频和文本模态，提供先进的交互体验并展现出强大性能，以应对 GPT-4o 的类似能力。研究团队提出了一种有效的多模态训练方案，包括两个阶段：多模态 alignment 和多任务 fine-tuning，跨音频、图像、视频和文本模态，帮助模型高效处理视觉和音频数据。实验结果显示，Baichuan-omni 在各种 omni-modal 和 multimodal 基准上表现出色，旨在为开源社区提供一个竞争性基准，促进多模态理解和实时交互的发展。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08565v4",
      "published_date": "2024-10-11 06:44:31 UTC",
      "updated_date": "2024-12-27 14:19:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:31:10.773261"
    },
    {
      "arxiv_id": "2410.08559v4",
      "title": "Learning General Representation of 12-Lead Electrocardiogram with a Joint-Embedding Predictive Architecture",
      "title_zh": "翻译失败",
      "authors": [
        "Sehun Kim"
      ],
      "abstract": "Electrocardiogram (ECG) captures the heart's electrical signals, offering\nvaluable information for diagnosing cardiac conditions. However, the scarcity\nof labeled data makes it challenging to fully leverage supervised learning in\nmedical domain. Self-supervised learning (SSL) offers a promising solution,\nenabling models to learn from unlabeled data and uncover meaningful patterns.\nIn this paper, we show that masked modeling in the latent space can be a\npowerful alternative to existing self-supervised methods in the ECG domain. We\nintroduce ECG-JEPA, a SSL model for 12-lead ECG analysis that learns semantic\nrepresentations of ECG data by predicting in the hidden latent space, bypassing\nthe need to reconstruct raw signals. This approach offers several advantages in\nthe ECG domain: (1) it avoids producing unnecessary details, such as noise,\nwhich is common in ECG; and (2) it addresses the limitations of na\\\"ive L2 loss\nbetween raw signals. Another key contribution is the introduction of\nCross-Pattern Attention (CroPA), a specialized masked attention mechanism\ntailored for 12-lead ECG data. ECG-JEPA is trained on the union of several open\nECG datasets, totaling approximately 180,000 samples, and achieves\nstate-of-the-art performance in various downstream tasks including ECG\nclassification and feature prediction. Our code is openly available at\nhttps://github.com/sehunfromdaegu/ECG_JEPA.",
      "tldr_zh": "这篇论文提出 ECG-JEPA，一种基于自监督学习(SSL)的模型，用于学习12-lead ECG的通用表示，通过在隐藏潜在空间中预测而非重建原始信号，从而避免重建不必要的细节如噪声，并解决naive L2 loss的局限。论文引入了Cross-Pattern Attention (CroPA)，一个专门为12-lead ECG设计的masked attention机制，以提升数据处理效率。该模型在约18万样本的公开数据集上训练，并在ECG分类和特征预测等下游任务中实现最先进性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08559v4",
      "published_date": "2024-10-11 06:30:48 UTC",
      "updated_date": "2024-12-03 03:21:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:31:22.168239"
    },
    {
      "arxiv_id": "2410.08553v1",
      "title": "Balancing Innovation and Privacy: Data Security Strategies in Natural Language Processing Applications",
      "title_zh": "平衡创新与隐私：在自然语言处理应用中的数据安全策略",
      "authors": [
        "Shaobo Liu",
        "Guiran Liu",
        "Binrong Zhu",
        "Yuanshuai Luo",
        "Linxiao Wu",
        "Rui Wang"
      ],
      "abstract": "This research addresses privacy protection in Natural Language Processing\n(NLP) by introducing a novel algorithm based on differential privacy, aimed at\nsafeguarding user data in common applications such as chatbots, sentiment\nanalysis, and machine translation. With the widespread application of NLP\ntechnology, the security and privacy protection of user data have become\nimportant issues that need to be solved urgently. This paper proposes a new\nprivacy protection algorithm designed to effectively prevent the leakage of\nuser sensitive information. By introducing a differential privacy mechanism,\nour model ensures the accuracy and reliability of data analysis results while\nadding random noise. This method not only reduces the risk caused by data\nleakage but also achieves effective processing of data while protecting user\nprivacy. Compared to traditional privacy methods like data anonymization and\nhomomorphic encryption, our approach offers significant advantages in terms of\ncomputational efficiency and scalability while maintaining high accuracy in\ndata analysis. The proposed algorithm's efficacy is demonstrated through\nperformance metrics such as accuracy (0.89), precision (0.85), and recall\n(0.88), outperforming other methods in balancing privacy and utility. As\nprivacy protection regulations become increasingly stringent, enterprises and\ndevelopers must take effective measures to deal with privacy risks. Our\nresearch provides an important reference for the application of privacy\nprotection technology in the field of NLP, emphasizing the need to achieve a\nbalance between technological innovation and user privacy. In the future, with\nthe continuous advancement of technology, privacy protection will become a core\nelement of data-driven applications and promote the healthy development of the\nentire industry.",
      "tldr_zh": "这篇论文提出了一种基于 differential privacy 的新算法，用于保护 Natural Language Processing (NLP) 应用（如聊天机器人、情感分析和机器翻译）中的用户数据隐私。该算法通过添加随机噪声来防止敏感信息泄露，同时保持数据分析的准确性和可靠性，与传统方法如 data anonymization 和 homomorphic encryption 相比，具有更高的计算效率和可扩展性。实验结果显示，该算法的 accuracy 为 0.89、precision 为 0.85 和 recall 为 0.88，优于其他方法，并为 NLP 领域实现技术创新与隐私保护的平衡提供了重要参考。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08553v1",
      "published_date": "2024-10-11 06:05:10 UTC",
      "updated_date": "2024-10-11 06:05:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:31:34.523056"
    },
    {
      "arxiv_id": "2410.08551v2",
      "title": "Context-Aware Full Body Anonymization using Text-to-Image Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pascal Zwick",
        "Kevin Roesch",
        "Marvin Klemp",
        "Oliver Bringmann"
      ],
      "abstract": "Anonymization plays a key role in protecting sensible information of\nindividuals in real world datasets. Self-driving cars for example need high\nresolution facial features to track people and their viewing direction to\npredict future behaviour and react accordingly. In order to protect people's\nprivacy whilst keeping important features in the dataset, it is important to\nreplace the full body of a person with a highly detailed anonymized one. In\ncontrast to doing face anonymization, full body replacement decreases the\nability of recognizing people by their hairstyle or clothes. In this paper, we\npropose a workflow for full body person anonymization utilizing Stable\nDiffusion as a generative backend. Text-to-image diffusion models, like Stable\nDiffusion, OpenAI's DALL-E or Midjourney, have become very popular in recent\ntime, being able to create photorealistic images from a single text prompt. We\nshow that our method outperforms state-of-the art anonymization pipelines with\nrespect to image quality, resolution, Inception Score (IS) and Frechet\nInception Distance (FID). Additionally, our method is invariant with respect to\nthe image generator and thus able to be used with the latest models available.",
      "tldr_zh": "该论文提出了一种基于上下文的全身匿名化方法，使用文本到图像扩散模型（如Stable Diffusion）来保护个人隐私，同时保留数据集中的关键特征，例如自动驾驶场景中面部特征和行为预测信息。与传统面部匿名化不同，该方法通过替换整个身体来减少基于发型或衣着识别的风险。实验结果显示，该工作流程在图像质量、分辨率、Inception Score (IS) 和 Frechet Inception Distance (FID) 方面优于现有技术，且对图像生成器具有兼容性，可适应最新模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.4.0; I.2.0"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08551v2",
      "published_date": "2024-10-11 06:04:30 UTC",
      "updated_date": "2024-10-17 14:04:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:31:45.735275"
    },
    {
      "arxiv_id": "2410.08545v1",
      "title": "Humanity in AI: Detecting the Personality of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Baohua Zhan",
        "Yongyi Huang",
        "Wenyao Cui",
        "Huaping Zhang",
        "Jianyun Shang"
      ],
      "abstract": "Questionnaires are a common method for detecting the personality of Large\nLanguage Models (LLMs). However, their reliability is often compromised by two\nmain issues: hallucinations (where LLMs produce inaccurate or irrelevant\nresponses) and the sensitivity of responses to the order of the presented\noptions. To address these issues, we propose combining text mining with\nquestionnaires method. Text mining can extract psychological features from the\nLLMs' responses without being affected by the order of options. Furthermore,\nbecause this method does not rely on specific answers, it reduces the influence\nof hallucinations. By normalizing the scores from both methods and calculating\nthe root mean square error, our experiment results confirm the effectiveness of\nthis approach. To further investigate the origins of personality traits in\nLLMs, we conduct experiments on both pre-trained language models (PLMs), such\nas BERT and GPT, as well as conversational models (ChatLLMs), such as ChatGPT.\nThe results show that LLMs do contain certain personalities, for example,\nChatGPT and ChatGLM exhibit the personality traits of 'Conscientiousness'.\nAdditionally, we find that the personalities of LLMs are derived from their\npre-trained data. The instruction data used to train ChatLLMs can enhance the\ngeneration of data containing personalities and expose their hidden\npersonality. We compare the results with the human average personality score,\nand we find that the personality of FLAN-T5 in PLMs and ChatGPT in ChatLLMs is\nmore similar to that of a human, with score differences of 0.34 and 0.22,\nrespectively.",
      "tldr_zh": "本文提出一种结合文本挖掘和问卷的方法来检测 Large Language Models (LLMs) 的个性，旨在解决问卷中存在的 hallucinations 和选项顺序敏感问题。通过标准化分数并计算根均方误差，实验验证了该方法的有效性。研究发现，LLMs 如 ChatGPT 和 ChatGLM 表现出“Conscientiousness”等个性特征，这些特性主要源于预训练数据，且 FLAN-T5 和 ChatGPT 的个性与人类平均分数差异最小（分别为 0.34 和 0.22）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08545v1",
      "published_date": "2024-10-11 05:53:11 UTC",
      "updated_date": "2024-10-11 05:53:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:31:58.212065"
    },
    {
      "arxiv_id": "2410.08540v1",
      "title": "Kaleidoscope: Learnable Masks for Heterogeneous Multi-agent Reinforcement Learning",
      "title_zh": "Kaleidoscope：用于异构多智能体强化学习的可学习掩码",
      "authors": [
        "Xinran Li",
        "Ling Pan",
        "Jun Zhang"
      ],
      "abstract": "In multi-agent reinforcement learning (MARL), parameter sharing is commonly\nemployed to enhance sample efficiency. However, the popular approach of full\nparameter sharing often leads to homogeneous policies among agents, potentially\nlimiting the performance benefits that could be derived from policy diversity.\nTo address this critical limitation, we introduce \\emph{Kaleidoscope}, a novel\nadaptive partial parameter sharing scheme that fosters policy heterogeneity\nwhile still maintaining high sample efficiency. Specifically, Kaleidoscope\nmaintains one set of common parameters alongside multiple sets of distinct,\nlearnable masks for different agents, dictating the sharing of parameters. It\npromotes diversity among policy networks by encouraging discrepancy among these\nmasks, without sacrificing the efficiencies of parameter sharing. This design\nallows Kaleidoscope to dynamically balance high sample efficiency with a broad\npolicy representational capacity, effectively bridging the gap between full\nparameter sharing and non-parameter sharing across various environments. We\nfurther extend Kaleidoscope to critic ensembles in the context of actor-critic\nalgorithms, which could help improve value estimations.Our empirical\nevaluations across extensive environments, including multi-agent particle\nenvironment, multi-agent MuJoCo and StarCraft multi-agent challenge v2,\ndemonstrate the superior performance of Kaleidoscope compared with existing\nparameter sharing approaches, showcasing its potential for performance\nenhancement in MARL. The code is publicly available at\n\\url{https://github.com/LXXXXR/Kaleidoscope}.",
      "tldr_zh": "这项研究针对多智能体强化学习（MARL）中的参数共享问题，提出了一种名为 Kaleidoscope 的自适应部分参数共享方案，以促进代理策略的异质性，同时保持高样本效率。Kaleidoscope 通过维护一组公共参数和多个代理的独特可学习掩码，来动态控制参数共享，并通过鼓励掩码差异来增强策略网络的多样性。该方法还扩展到演员-评论家算法中的评论家集成，以改善价值估计。实验结果显示，在多智能体粒子环境、多智能体 MuJoCo 和 StarCraft II 等环境中，Kaleidoscope 比现有参数共享方法表现出色，显著提升了性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems(NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2410.08540v1",
      "published_date": "2024-10-11 05:22:54 UTC",
      "updated_date": "2024-10-11 05:22:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:32:10.141105"
    },
    {
      "arxiv_id": "2410.08529v1",
      "title": "VOVTrack: Exploring the Potentiality in Videos for Open-Vocabulary Object Tracking",
      "title_zh": "翻译失败",
      "authors": [
        "Zekun Qian",
        "Ruize Han",
        "Junhui Hou",
        "Linqi Song",
        "Wei Feng"
      ],
      "abstract": "Open-vocabulary multi-object tracking (OVMOT) represents a critical new\nchallenge involving the detection and tracking of diverse object categories in\nvideos, encompassing both seen categories (base classes) and unseen categories\n(novel classes). This issue amalgamates the complexities of open-vocabulary\nobject detection (OVD) and multi-object tracking (MOT). Existing approaches to\nOVMOT often merge OVD and MOT methodologies as separate modules, predominantly\nfocusing on the problem through an image-centric lens. In this paper, we\npropose VOVTrack, a novel method that integrates object states relevant to MOT\nand video-centric training to address this challenge from a video object\ntracking standpoint. First, we consider the tracking-related state of the\nobjects during tracking and propose a new prompt-guided attention mechanism for\nmore accurate localization and classification (detection) of the time-varying\nobjects. Subsequently, we leverage raw video data without annotations for\ntraining by formulating a self-supervised object similarity learning technique\nto facilitate temporal object association (tracking). Experimental results\nunderscore that VOVTrack outperforms existing methods, establishing itself as a\nstate-of-the-art solution for open-vocabulary tracking task.",
      "tldr_zh": "该论文针对开放词汇多对象跟踪（OVMOT）挑战，提出了一种新方法VOVTrack，该方法从视频视角整合对象状态和视频中心训练，解决现有基于图像的方法在检测和跟踪已见（base classes）和未见（novel classes）类别对象时的局限性。具体而言，VOVTrack引入提示引导注意力机制来实现更精确的物体定位和分类，以及自监督对象相似性学习技术，利用无标注原始视频数据进行时间对象关联。实验结果表明，该方法在OVMOT任务中超越现有方案，成为state-of-the-art解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08529v1",
      "published_date": "2024-10-11 05:01:49 UTC",
      "updated_date": "2024-10-11 05:01:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:32:22.503841"
    },
    {
      "arxiv_id": "2410.08527v2",
      "title": "Scaling Laws for Predicting Downstream Performance in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yangyi Chen",
        "Binxuan Huang",
        "Yifan Gao",
        "Zhengyang Wang",
        "Jingfeng Yang",
        "Heng Ji"
      ],
      "abstract": "Precise estimation of downstream performance in large language models (LLMs)\nprior to training is essential for guiding their development process. Scaling\nlaws analysis utilizes the statistics of a series of significantly smaller\nsampling language models (LMs) to predict the performance of the target LLM.\nFor downstream performance prediction, the critical challenge lies in the\nemergent abilities in LLMs that occur beyond task-specific computational\nthresholds. In this work, we focus on the pre-training loss as a more\ncomputation-efficient metric for performance estimation. Our two-stage approach\nFLP consists of first estimating a function that maps computational resources\n(e.g., FLOPs) to the pre-training Loss using a series of fully-converged\nsampling models, followed by mapping the pre-training loss to downstream task\nPerformance using the intermediate models with emerged performance. In our\nexperiments, this FLP solution accurately predicts the performance of LLMs with\n7B and 13B parameters using a series of sampling LMs up to 3B, achieving error\nmargins of 5% and 10%, respectively, and significantly outperforming the\nFLOPs-to-Performance approach. Further, we present FLP-M, a fundamental\napproach for performance prediction that addresses the practical need to\nintegrate datasets from multiple sources during pre-training. FLP-M extends the\npower law analytical function to predict domain-specific pre-training loss\nbased on FLOPs across data sources, and employs a two-layer neural network to\nmodel the non-linear relationship between multiple domain-specific loss and\ndownstream performance. By utilizing a 3B LLM trained on a specific ratio and a\nseries of smaller sampling LMs, FLP-M can effectively forecast the performance\nof 3B and 7B LLMs across various data mixtures for most benchmarks within 10%\nerror margins.",
      "tldr_zh": "这篇论文探讨了使用缩放定律预测大型语言模型(LLMs)的下游性能，以指导模型开发。作者提出了一种两阶段方法FLP，通过一组完全收敛的较小采样模型，先映射计算资源(FLOPs)到预训练损失，再将预训练损失映射到下游任务性能，在实验中准确预测7B和13B参数LLMs的性能，错误率分别为5%和10%，显著优于直接FLOPs-to-Performance方法。此外，FLP-M扩展了这一框架，处理多数据源预训练场景，利用power law函数和两层神经网络建模多域损失与性能的非线性关系，实现对各种数据混合下LLMs性能的预测，错误率在10%以内。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to TMLR",
      "pdf_url": "http://arxiv.org/pdf/2410.08527v2",
      "published_date": "2024-10-11 04:57:48 UTC",
      "updated_date": "2025-04-07 21:47:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:32:35.932569"
    },
    {
      "arxiv_id": "2410.08526v1",
      "title": "\"I Am the One and Only, Your Cyber BFF\": Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Myra Cheng",
        "Alicia DeVrio",
        "Lisa Egede",
        "Su Lin Blodgett",
        "Alexandra Olteanu"
      ],
      "abstract": "Many state-of-the-art generative AI (GenAI) systems are increasingly prone to\nanthropomorphic behaviors, i.e., to generating outputs that are perceived to be\nhuman-like. While this has led to scholars increasingly raising concerns about\npossible negative impacts such anthropomorphic AI systems can give rise to,\nanthropomorphism in AI development, deployment, and use remains vastly\noverlooked, understudied, and underspecified. In this perspective, we argue\nthat we cannot thoroughly map the social impacts of generative AI without\nmapping the social impacts of anthropomorphic AI, and outline a call to action.",
      "tldr_zh": "这篇论文强调，先进的生成式 AI (GenAI) 系统越来越呈现出拟人化行为（anthropomorphic behaviors），这可能导致负面社会影响，但目前在 AI 的开发、部署和使用中被严重忽视。作者认为，彻底评估 GenAI 的社会影响必须先深入研究 anthropomorphic AI 的影响，因为二者密切相关。论文呼吁采取行动，系统地映射这些影响，以推动更全面的 AI 研究和监管。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08526v1",
      "published_date": "2024-10-11 04:57:41 UTC",
      "updated_date": "2024-10-11 04:57:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:32:46.435066"
    },
    {
      "arxiv_id": "2410.08500v1",
      "title": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Yunpeng Gao",
        "Zhigang Wang",
        "Linglin Jing",
        "Dong Wang",
        "Xuelong Li",
        "Bin Zhao"
      ],
      "abstract": "Aerial Vision-and-Language Navigation (VLN) is a novel task enabling Unmanned\nAerial Vehicles (UAVs) to navigate in outdoor environments through natural\nlanguage instructions and visual cues. It remains challenging due to the\ncomplex spatial relationships in outdoor aerial scenes. In this paper, we\npropose an end-to-end zero-shot framework for aerial VLN tasks, where the large\nlanguage model (LLM) is introduced as our agent for action prediction.\nSpecifically, we develop a novel Semantic-Topo-Metric Representation (STMR) to\nenhance the spatial reasoning ability of LLMs. This is achieved by extracting\nand projecting instruction-related semantic masks of landmarks into a top-down\nmap that contains the location information of surrounding landmarks. Further,\nthis map is transformed into a matrix representation with distance metrics as\nthe text prompt to the LLM, for action prediction according to the instruction.\nExperiments conducted in real and simulation environments have successfully\nproved the effectiveness and robustness of our method, achieving 15.9% and\n12.5% improvements (absolute) in Oracle Success Rate (OSR) on AerialVLN-S\ndataset.",
      "tldr_zh": "本研究针对空中视觉语言导航(Aerial VLN)任务，提出了一种端到端零样本框架，利用大型语言模型(LLM)作为代理进行动作预测，以应对户外环境中复杂的空间关系。框架的核心是Semantic-Topo-Metric Representation (STMR)，通过提取指令相关的语义掩码，将其投影到包含周围地标位置的顶视图地图，并转换为带距离度量的矩阵表示，作为LLM的文本提示来增强空间推理能力。在真实和模拟环境中进行的实验证明了该方法的有效性和鲁棒性，在AerialVLN-S数据集上，Oracle Success Rate (OSR)分别提高了15.9%和12.5%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Submitted to ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08500v1",
      "published_date": "2024-10-11 03:54:48 UTC",
      "updated_date": "2024-10-11 03:54:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:32:57.769055"
    },
    {
      "arxiv_id": "2410.08491v1",
      "title": "A Systematic Review of Edge Case Detection in Automated Driving: Methods, Challenges and Future Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Saeed Rahmani",
        "Sabine Rieder",
        "Erwin de Gelder",
        "Marcel Sonntag",
        "Jorge Lorente Mallada",
        "Sytze Kalisvaart",
        "Vahid Hashemi",
        "Simeon C. Calvert"
      ],
      "abstract": "The rapid development of automated vehicles (AVs) promises to revolutionize\ntransportation by enhancing safety and efficiency. However, ensuring their\nreliability in diverse real-world conditions remains a significant challenge,\nparticularly due to rare and unexpected situations known as edge cases.\nAlthough numerous approaches exist for detecting edge cases, there is a notable\nlack of a comprehensive survey that systematically reviews these techniques.\nThis paper fills this gap by presenting a practical, hierarchical review and\nsystematic classification of edge case detection and assessment methodologies.\nOur classification is structured on two levels: first, categorizing detection\napproaches according to AV modules, including perception-related and\ntrajectory-related edge cases; and second, based on underlying methodologies\nand theories guiding these techniques. We extend this taxonomy by introducing a\nnew class called \"knowledge-driven\" approaches, which is largely overlooked in\nthe literature. Additionally, we review the techniques and metrics for the\nevaluation of edge case detection methods and identified edge cases. To our\nknowledge, this is the first survey to comprehensively cover edge case\ndetection methods across all AV subsystems, discuss knowledge-driven edge\ncases, and explore evaluation techniques for detection methods. This structured\nand multi-faceted analysis aims to facilitate targeted research and modular\ntesting of AVs. Moreover, by identifying the strengths and weaknesses of\nvarious approaches and discussing the challenges and future directions, this\nsurvey intends to assist AV developers, researchers, and policymakers in\nenhancing the safety and reliability of automated driving (AD) systems through\neffective edge case detection.",
      "tldr_zh": "这篇论文对自动驾驶（automated driving）中的边缘案例检测（edge case detection）方法进行了系统综述，填补了现有文献的空白，通过分层分类（包括按 AV 模块如感知相关和轨迹相关，以及底层方法如知识驱动方法）来组织和分析这些技术。该综述首次全面覆盖所有自动驾驶子系统，引入了被忽略的“knowledge-driven”方法，并审查了评估指标和检测技术。通过识别各方法的优势、劣势、挑战及未来方向，该研究旨在促进针对性研究和模块化测试，提升自动驾驶系统的安全性和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Preprint submitted to IEEE Transactions on Intelligent Transportation\n  Systems",
      "pdf_url": "http://arxiv.org/pdf/2410.08491v1",
      "published_date": "2024-10-11 03:32:20 UTC",
      "updated_date": "2024-10-11 03:32:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:33:11.008636"
    },
    {
      "arxiv_id": "2410.21283v2",
      "title": "pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2",
      "title_zh": "翻译失败",
      "authors": [
        "Joongwon Chae",
        "Zhenyu Wang",
        "Ijaz Gul",
        "Jiansong Ji",
        "Zhenglin Chen",
        "Peiwu Qin"
      ],
      "abstract": "Recent advancements in protein structure prediction, particularly AlphaFold2,\nhave revolutionized structural biology by achieving near-experimental accuracy\n($\\text{average RMSD} < 1.5\\text{\\AA}$). However, the computational demands of\nthese models (approximately 30 minutes per protein on an RTX 4090)\nsignificantly limit their application in high-throughput protein screening.\nWhile large language models like ESM (Evolutionary Scale Modeling) have shown\npromise in extracting structural information directly from protein sequences,\nrapid assessment of protein structure quality for large-scale analyses remains\na major challenge.\n  We introduce pLDDT-Predictor, a high-speed protein screening tool that\nachieves a $250,000\\times$ speedup compared to AlphaFold2 by leveraging\npre-trained ESM2 protein embeddings and a Transformer architecture. Our model\npredicts AlphaFold2's pLDDT (predicted Local Distance Difference Test) scores\nwith a Pearson correlation of 0.7891 and processes proteins in just 0.007\nseconds on average. Using a comprehensive dataset of 1.5 million diverse\nprotein sequences (ranging from 50 to 2048 amino acids), we demonstrate that\npLDDT-Predictor accurately classifies high-confidence structures (pLDDT $>$ 70)\nwith 91.2\\% accuracy and achieves an MSE of 84.8142 compared to AlphaFold2's\npredictions.\n  The source code and pre-trained models are freely available at\n\\url{https://github.com/jw-chae/pLDDT_Predictor}, enabling the research\ncommunity to perform rapid, large-scale protein structure quality assessments.",
      "tldr_zh": "本研究提出 pLDDT-Predictor，一种利用预训练 ESM2 蛋白嵌入和 Transformer 架构的高速蛋白质筛选工具，旨在解决 AlphaFold2 计算需求高（约30分钟/蛋白）的限制，实现250,000倍的加速。模型能够快速预测 AlphaFold2 的 pLDDT（predicted Local Distance Difference Test）分数，平均处理时间仅0.007秒，并达到Pearson correlation为0.7891的准确性。基于1.5百万多样蛋白序列数据集，pLDDT-Predictor 在分类高置信度结构（pLDDT > 70）时准确率达91.2%，MSE为84.8142，为大规模蛋白结构质量评估提供高效解决方案。源代码已在GitHub上公开，供研究社区免费使用。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "6 pages main topic, 8 pages including citiation, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2410.21283v2",
      "published_date": "2024-10-11 03:19:44 UTC",
      "updated_date": "2024-11-13 08:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:33:22.991100"
    },
    {
      "arxiv_id": "2410.08478v3",
      "title": "Dynamic Fusion Strategies for Federated Multimodal Recommendations",
      "title_zh": "联邦多模态推荐的动态融合策略",
      "authors": [
        "Zhiwei Li",
        "Guodong Long",
        "Jing Jiang",
        "Chengqi Zhang"
      ],
      "abstract": "Delivering deeply personalized recommendations necessitates understanding\nuser interactions with diverse multimedia features, but achieving this within\nthe constraints of Federated Recommendation Systems (FedRec) is severely\nhampered by communication bottlenecks, user heterogeneity, and the complexity\nof privacy-preserving multimodal fusion. To this end, we propose FedMR, a novel\nmultimodal FedRec framework centered around the Mixing Feature Fusion Module\n(MFFM). FedMR employs a two-stage process: (1) Server-side centralized\nmultimedia content processing provides rich, shared item context using\npre-trained models, mitigating limitations from client sparsity and resource\nconstraints efficiently. (2) Client-Side Personalized Refinement, where the\nMFFM dynamically adapts these server-provided multimodal representations based\non client-specific interaction patterns, effectively tailoring recommendations\nand resolving heterogeneity in user preferences towards different modalities.\nExtensive experiments validate that FedMR seamlessly enhances existing ID-based\nFedRecs, effectively transforming them into high-performing federated\nmultimodal systems.",
      "tldr_zh": "这篇论文提出 FedMR，一种新型的多模态联邦推荐系统（FedRec）框架，旨在解决通信瓶颈、用户异质性和隐私保护的多模态融合挑战。FedMR 通过两阶段过程实现：服务器端使用预训练模型集中处理多媒体内容，提供共享的项目上下文；客户端则采用 Mixing Feature Fusion Module (MFFM) 动态调整这些表示，以适应用户特定交互模式和偏好。实验验证显示，FedMR 无缝增强了现有的基于 ID 的 FedRec 系统，将其转化为高性能的多模态推荐框架。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "17 pages, 8 figures, 6 tables, conference",
      "pdf_url": "http://arxiv.org/pdf/2410.08478v3",
      "published_date": "2024-10-11 03:10:09 UTC",
      "updated_date": "2025-05-18 06:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:33:34.320900"
    },
    {
      "arxiv_id": "2410.08475v2",
      "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation",
      "title_zh": "GIVE：利用知识图谱启发的真实性外推进行大语言模型的结构化推理",
      "authors": [
        "Jiashu He",
        "Mingyu Derek Ma",
        "Jinxuan Fan",
        "Dan Roth",
        "Wei Wang",
        "Alejandro Ribeiro"
      ],
      "abstract": "Existing approaches based on context prompting or reinforcement learning (RL)\nto improve the reasoning capacities of large language models (LLMs) depend on\nthe LLMs' internal knowledge to produce reliable Chain-Of-Thought (CoT).\nHowever, no matter the size of LLMs, certain problems cannot be resolved in a\nsingle forward pass. Meanwhile, agent-based reasoning systems require access to\na comprehensive nonparametric knowledge base, which is often costly or not\nfeasible for use in scientific and niche domains. We present Graph Inspired\nVeracity Extrapolation (GIVE), a novel reasoning method that merges parametric\nand non-parametric memories to improve accurate reasoning with minimal external\ninput. GIVE guides the LLM agent to select the most pertinent expert data\n(observe), engage in query-specific divergent thinking (reflect), and then\nsynthesize this information to produce the final output (speak). Extensive\nexperiments demonstrated the following benefits of our framework: (1) GIVE\nboosts the performance of LLMs across various sizes. (2) In some scenarios,\nGIVE allows smaller LLMs to surpass larger, more sophisticated ones in\nscientific tasks (GPT3.5T + GIVE > GPT4). (3) GIVE is effective on scientific\nand open-domain assessments. (4) GIVE is a training-free method that enables\nLLMs to tackle new problems that extend beyond their training data (up to 43.5%\n-> 88.2%} accuracy improvement). (5) GIVE allows LLM agents to reason using\nboth restricted (very small) and noisy (very large) knowledge sources,\naccommodating knowledge graphs (KG) ranging from 135 to more than 840k nodes.\n(6) The reasoning process involved in GIVE is fully interpretable.",
      "tldr_zh": "该论文提出 GIVE，一种创新的推理方法，通过 Knowledge Graph Inspired Veracity Extrapolation 结合参数和非参数记忆，提升 Large Language Models (LLMs) 的准确推理能力，以解决依赖内部知识的局限。GIVE 指导 LLM 代理通过三个步骤——observe (选择相关专家数据)、reflect (进行查询特定的发散思考)和 speak (合成最终输出)——实现结构化推理。实验结果显示，GIVE 显著提升了不同规模 LLMs 的性能，使小型模型在某些科学任务中超越大型模型（如 GPT-3.5T + GIVE > GPT4），并在科学和开放领域实现高达 88.2% 的准确率改进，同时支持从 135 到 84 万节点的 Knowledge Graph (KG) 和可解释的推理过程。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08475v2",
      "published_date": "2024-10-11 03:05:06 UTC",
      "updated_date": "2025-02-08 22:44:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:33:49.782963"
    },
    {
      "arxiv_id": "2410.08473v1",
      "title": "Deeper Insights into Deep Graph Convolutional Networks: Stability and Generalization",
      "title_zh": "对深度图卷积网络",
      "authors": [
        "Guangrui Yang",
        "Ming Li",
        "Han Feng",
        "Xiaosheng Zhuang"
      ],
      "abstract": "Graph convolutional networks (GCNs) have emerged as powerful models for graph\nlearning tasks, exhibiting promising performance in various domains. While\ntheir empirical success is evident, there is a growing need to understand their\nessential ability from a theoretical perspective. Existing theoretical research\nhas primarily focused on the analysis of single-layer GCNs, while a\ncomprehensive theoretical exploration of the stability and generalization of\ndeep GCNs remains limited. In this paper, we bridge this gap by delving into\nthe stability and generalization properties of deep GCNs, aiming to provide\nvaluable insights by characterizing rigorously the associated upper bounds. Our\ntheoretical results reveal that the stability and generalization of deep GCNs\nare influenced by certain key factors, such as the maximum absolute eigenvalue\nof the graph filter operators and the depth of the network. Our theoretical\nstudies contribute to a deeper understanding of the stability and\ngeneralization properties of deep GCNs, potentially paving the way for\ndeveloping more reliable and well-performing models.",
      "tldr_zh": "这篇论文深入探讨了深层图卷积网络（deep GCNs）的稳定性（stability）和泛化性（generalization），填补了现有理论研究主要聚焦单层 GCNs 的空白。作者通过严格的理论分析，提供了相关的上界（upper bounds），揭示了这些特性受图过滤器操作符的最大绝对特征值（maximum absolute eigenvalue）和网络深度（depth）等关键因素的影响。这些发现有助于加深对深层 GCNs 的理解，并为开发更可靠且性能优越的图学习模型奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "44 pages, 3 figures, submitted to IEEE Trans. Pattern Anal. Mach.\n  Intell. on 18-Jun-2024, under review",
      "pdf_url": "http://arxiv.org/pdf/2410.08473v1",
      "published_date": "2024-10-11 02:57:47 UTC",
      "updated_date": "2024-10-11 02:57:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:33:58.658982"
    },
    {
      "arxiv_id": "2410.08464v1",
      "title": "ARCap: Collecting High-quality Human Demonstrations for Robot Learning with Augmented Reality Feedback",
      "title_zh": "ARCap：通过增强现实反馈收集高质量人类演示用于机器人学习",
      "authors": [
        "Sirui Chen",
        "Chen Wang",
        "Kaden Nguyen",
        "Li Fei-Fei",
        "C. Karen Liu"
      ],
      "abstract": "Recent progress in imitation learning from human demonstrations has shown\npromising results in teaching robots manipulation skills. To further scale up\ntraining datasets, recent works start to use portable data collection devices\nwithout the need for physical robot hardware. However, due to the absence of\non-robot feedback during data collection, the data quality depends heavily on\nuser expertise, and many devices are limited to specific robot embodiments. We\npropose ARCap, a portable data collection system that provides visual feedback\nthrough augmented reality (AR) and haptic warnings to guide users in collecting\nhigh-quality demonstrations. Through extensive user studies, we show that ARCap\nenables novice users to collect robot-executable data that matches robot\nkinematics and avoids collisions with the scenes. With data collected from\nARCap, robots can perform challenging tasks, such as manipulation in cluttered\nenvironments and long-horizon cross-embodiment manipulation. ARCap is fully\nopen-source and easy to calibrate; all components are built from off-the-shelf\nproducts. More details and results can be found on our website:\nhttps://stanford-tml.github.io/ARCap",
      "tldr_zh": "该研究提出ARCap，一种便携式数据收集系统，利用增强现实(AR)视觉反馈和触觉警告，帮助用户收集高质量人类演示数据，以提升机器人模仿学习的效果。相较于传统设备，ARCap减少了对用户专业知识的依赖，并确保数据符合机器人运动学，避免碰撞。用户研究表明，该系统使新手用户能够生成可执行数据，支持机器人完成复杂任务，如杂乱环境操作和长horizon跨形态操作。ARCap采用开源设计，使用现成产品，易于校准，并提供更多细节于其官方网站。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 8 Figures, submitted to ICRA 2025",
      "pdf_url": "http://arxiv.org/pdf/2410.08464v1",
      "published_date": "2024-10-11 02:30:46 UTC",
      "updated_date": "2024-10-11 02:30:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:34:11.057832"
    },
    {
      "arxiv_id": "2410.08455v1",
      "title": "Why pre-training is beneficial for downstream classification tasks?",
      "title_zh": "为什么预训练对下游分类任务有益？",
      "authors": [
        "Xin Jiang",
        "Xu Cheng",
        "Zechao Li"
      ],
      "abstract": "Pre-training has exhibited notable benefits to downstream tasks by boosting\naccuracy and speeding up convergence, but the exact reasons for these benefits\nstill remain unclear. To this end, we propose to quantitatively and explicitly\nexplain effects of pre-training on the downstream task from a novel\ngame-theoretic view, which also sheds new light into the learning behavior of\ndeep neural networks (DNNs). Specifically, we extract and quantify the\nknowledge encoded by the pre-trained model, and further track the changes of\nsuch knowledge during the fine-tuning process. Interestingly, we discover that\nonly a small amount of pre-trained model's knowledge is preserved for the\ninference of downstream tasks. However, such preserved knowledge is very\nchallenging for a model training from scratch to learn. Thus, with the help of\nthis exclusively learned and useful knowledge, the model fine-tuned from\npre-training usually achieves better performance than the model training from\nscratch. Besides, we discover that pre-training can guide the fine-tuned model\nto learn target knowledge for the downstream task more directly and quickly,\nwhich accounts for the faster convergence of the fine-tuned model.",
      "tldr_zh": "本文研究了pre-training对下游分类任务的好处，通过游戏理论视角量化并解释其机制。作者提取预训练模型的编码知识，并跟踪微调过程中的变化，发现只有少量预训练知识被保留用于下游任务，但这些知识对从零训练的DNNs模型非常难学，从而使微调模型实现更高的准确性和更好性能。此外，pre-training能指导模型更直接、快速地学习目标知识，导致训练收敛更快。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08455v1",
      "published_date": "2024-10-11 02:13:16 UTC",
      "updated_date": "2024-10-11 02:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:34:25.162268"
    },
    {
      "arxiv_id": "2410.21282v1",
      "title": "Logic Error Localization in Student Programming Assignments Using Pseudocode and Graph Neural Networks",
      "title_zh": "在学生编程作业中使用伪代码和图神经网络进行逻辑错误定位",
      "authors": [
        "Zhenyu Xu",
        "Kun Zhang",
        "Victor S. Sheng"
      ],
      "abstract": "Pseudocode is extensively used in introductory programming courses to\ninstruct computer science students in algorithm design, utilizing natural\nlanguage to define algorithmic behaviors. This learning approach enables\nstudents to convert pseudocode into source code and execute it to verify their\nalgorithms' correctness. This process typically introduces two types of errors:\nsyntax errors and logic errors. Syntax errors are often accompanied by compiler\nfeedback, which helps students identify incorrect lines. In contrast, logic\nerrors are more challenging because they do not trigger compiler errors and\nlack immediate diagnostic feedback, making them harder to detect and correct.\nTo address this challenge, we developed a system designed to localize logic\nerrors within student programming assignments at the line level. Our approach\nutilizes pseudocode as a scaffold to build a code-pseudocode graph, connecting\nsymbols from the source code to their pseudocode counterparts. We then employ a\ngraph neural network to both localize and suggest corrections for logic errors.\nAdditionally, we have devised a method to efficiently gather logic-error-prone\nprograms during the syntax error correction process and compile these into a\ndataset that includes single and multiple line logic errors, complete with\nindices of the erroneous lines. Our experimental results are promising,\ndemonstrating a localization accuracy of 99.2% for logic errors within the\ntop-10 suspected lines, highlighting the effectiveness of our approach in\nenhancing students' coding proficiency and error correction skills.",
      "tldr_zh": "本研究针对学生编程作业中逻辑错误难以检测的问题，提出了一种利用Pseudocode构建代码-pseudocode graph的系统，并结合Graph Neural Networks在行级别定位和建议修正逻辑错误。该方法还包括高效收集逻辑错误数据集的过程，涵盖单行和多行错误。实验结果显示，逻辑错误定位准确率在top-10怀疑行中达到99.2%，为提升学生的编程能力和错误修正技能提供了有效工具。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.21282v1",
      "published_date": "2024-10-11 01:46:24 UTC",
      "updated_date": "2024-10-11 01:46:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:34:34.447879"
    },
    {
      "arxiv_id": "2410.08442v2",
      "title": "JurEE not Judges: safeguarding llm interactions with small, specialised Encoder Ensembles",
      "title_zh": "翻译失败",
      "authors": [
        "Dom Nasrabadi"
      ],
      "abstract": "We introduce JurEE, an ensemble of efficient, encoder-only transformer models\ndesigned to strengthen safeguards in AI-User interactions within LLM-based\nsystems. Unlike existing LLM-as-Judge methods, which often struggle with\ngeneralization across risk taxonomies and only provide textual outputs, JurEE\noffers probabilistic risk estimates across a wide range of prevalent risks. Our\napproach leverages diverse data sources and employs progressive synthetic data\ngeneration techniques, including LLM-assisted augmentation, to enhance model\nrobustness and performance. We create an in-house benchmark comprising of other\nreputable benchmarks such as the OpenAI Moderation Dataset and ToxicChat, where\nwe find JurEE significantly outperforms baseline models, demonstrating superior\naccuracy, speed, and cost-efficiency. This makes it particularly suitable for\napplications requiring stringent content moderation, such as customer-facing\nchatbots. The encoder-ensemble's modular design allows users to set tailored\nrisk thresholds, enhancing its versatility across various safety-related\napplications. JurEE's collective decision-making process, where each\nspecialized encoder model contributes to the final output, not only improves\npredictive accuracy but also enhances interpretability. This approach provides\na more efficient, performant, and economical alternative to traditional LLMs\nfor large-scale implementations requiring robust content moderation.",
      "tldr_zh": "本文提出 JurEE，一种由小型专用编码器集合（Encoder Ensembles）组成的系统，用于加强 LLM-based 系统中的 AI-用户交互安全，与传统 LLM-as-Judge 方法相比，它提供更广泛的风险概率估计，并通过多样数据来源和渐进式合成数据生成（如 LLM 辅助增强）提升模型鲁棒性。在内部基准测试中，包括 OpenAI Moderation Dataset 和 ToxicChat，JurEE 显著优于基线模型，在准确性、速度和成本效率上表现出色。该框架的模块化设计允许自定义风险阈值，提高了其在内容审核应用（如聊天机器人）中的实用性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08442v2",
      "published_date": "2024-10-11 01:20:49 UTC",
      "updated_date": "2024-10-14 09:58:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:34:46.136932"
    },
    {
      "arxiv_id": "2410.08437v3",
      "title": "Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks",
      "title_zh": "大型语言模型的自治评估：用于真理维护和推理任务",
      "authors": [
        "Rushang Karia",
        "Daniel Bramblett",
        "Daksh Dobhal",
        "Siddharth Srivastava"
      ],
      "abstract": "This paper presents AutoEval, a novel benchmark for scaling Large Language\nModel (LLM) assessment in formal tasks with clear notions of correctness, such\nas truth maintenance in translation and logical reasoning. AutoEval is the\nfirst benchmarking paradigm that offers several key advantages necessary for\nscaling objective evaluation of LLMs without human labeling: (a) ability to\nevaluate LLMs of increasing sophistication by auto-generating tasks at\ndifferent levels of difficulty; (b) auto-generation of ground truth that\neliminates dependence on expensive and time-consuming human annotation; (c) the\nuse of automatically generated, randomized datasets that mitigate the ability\nof successive LLMs to overfit to static datasets used in many contemporary\nbenchmarks. Empirical analysis shows that an LLM's performance on AutoEval is\nhighly indicative of its performance on a diverse array of other benchmarks\nfocusing on translation and reasoning tasks, making it a valuable autonomous\nevaluation paradigm in settings where hand-curated datasets can be hard to\nobtain and/or update.",
      "tldr_zh": "本论文介绍了 AutoEval，一种新型基准，用于自主评估大型语言模型 (LLM) 在正式任务中的表现，如翻译中的真实性维护和逻辑推理。AutoEval 的关键优势包括自动生成不同难度的任务、自动创建 ground truth 以避免昂贵的人工标注，以及使用随机化数据集来防止 LLM 对静态基准过拟合。实证分析显示，LLM 在 AutoEval 上的表现能有效预测其在其他翻译和推理基准中的表现，从而提供一个高效的自主评估框架，尤其适用于难以获取或更新手动数据集的场景。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08437v3",
      "published_date": "2024-10-11 00:56:37 UTC",
      "updated_date": "2025-04-11 20:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:34:57.945969"
    },
    {
      "arxiv_id": "2410.08436v2",
      "title": "Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models",
      "title_zh": "探索推理结构在多步自然语言推理中使用大型语言模型构建证明",
      "authors": [
        "Zi'ou Zheng",
        "Christopher Malon",
        "Martin Renqiang Min",
        "Xiaodan Zhu"
      ],
      "abstract": "When performing complex multi-step reasoning tasks, the ability of Large\nLanguage Models (LLMs) to derive structured intermediate proof steps is\nimportant for ensuring that the models truly perform the desired reasoning and\nfor improving models' explainability. This paper is centred around a focused\nstudy: whether the current state-of-the-art generalist LLMs can leverage the\nstructures in a few examples to better construct the proof structures with\n\\textit{in-context learning}. Our study specifically focuses on structure-aware\ndemonstration and structure-aware pruning. We demonstrate that they both help\nimprove performance. A detailed analysis is provided to help understand the\nresults.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 在多步自然语言推理任务中构建结构化中间证明步骤的作用，强调这些步骤有助于确保模型进行正确的推理并提升可解释性。研究重点是通过 in-context learning，让 LLMs 利用少量示例中的结构进行结构感知演示 (structure-aware demonstration) 和结构感知修剪 (structure-aware pruning)，从而改善证明结构的构建。结果显示，这些方法显著提升了模型性能，并通过详细分析解释了背后的原因。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by EMNLP2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2410.08436v2",
      "published_date": "2024-10-11 00:45:50 UTC",
      "updated_date": "2025-01-30 08:06:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:35:21.097662"
    },
    {
      "arxiv_id": "2410.08435v2",
      "title": "Efficient Fine-Grained Guidance for Diffusion-Based Symbolic Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Tingyu Zhu",
        "Haoyu Liu",
        "Ziyu Wang",
        "Zhimin Jiang",
        "Zeyu Zheng"
      ],
      "abstract": "Developing generative models to create or conditionally create symbolic music\npresents unique challenges due to the combination of limited data availability\nand the need for high precision in note pitch. To address these challenges, we\nintroduce an efficient Fine-Grained Guidance (FGG) approach within diffusion\nmodels. FGG guides the diffusion models to generate music that aligns more\nclosely with the control and intent of expert composers, which is critical to\nimprove the accuracy, listenability, and quality of generated music. This\napproach empowers diffusion models to excel in advanced applications such as\nimprovisation, and interactive music creation. We derive theoretical\ncharacterizations for both the challenges in symbolic music generation and the\neffects of the FGG approach. We provide numerical experiments and subjective\nevaluation to demonstrate the effectiveness of our approach. We have published\na demo page to showcase performances, as one of the first in the symbolic music\nliterature's demo pages that enables real-time interactive generation.",
      "tldr_zh": "本研究针对符号音乐生成面临的挑战（如数据有限和高精度音高需求），提出了Efficient Fine-Grained Guidance (FGG)方法，用于指导diffusion models生成更符合专家作曲家意图的音乐，从而提升音乐的准确性、可听性和整体质量。\nFGG方法通过细粒度控制支持高级应用，如即兴表演和互动音乐创作，并提供了符号音乐生成挑战及其效果的理论分析。\n实验结果显示，该方法在数值和主观评估中表现出色，并发布了一个实时互动演示页面，作为符号音乐领域的创新展示。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2410.08435v2",
      "published_date": "2024-10-11 00:41:46 UTC",
      "updated_date": "2025-02-02 19:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:35:22.297687"
    },
    {
      "arxiv_id": "2410.08431v1",
      "title": "oRetrieval Augmented Generation for 10 Large Language Models and its Generalizability in Assessing Medical Fitness",
      "title_zh": "翻译失败",
      "authors": [
        "Yu He Ke",
        "Liyuan Jin",
        "Kabilan Elangovan",
        "Hairil Rizal Abdullah",
        "Nan Liu",
        "Alex Tiong Heng Sia",
        "Chai Rick Soh",
        "Joshua Yi Min Tung",
        "Jasmine Chiat Ling Ong",
        "Chang-Fu Kuo",
        "Shao-Chun Wu",
        "Vesela P. Kovacheva",
        "Daniel Shu Wei Ting"
      ],
      "abstract": "Large Language Models (LLMs) show potential for medical applications but\noften lack specialized clinical knowledge. Retrieval Augmented Generation (RAG)\nallows customization with domain-specific information, making it suitable for\nhealthcare. This study evaluates the accuracy, consistency, and safety of RAG\nmodels in determining fitness for surgery and providing preoperative\ninstructions. We developed LLM-RAG models using 35 local and 23 international\npreoperative guidelines and tested them against human-generated responses. A\ntotal of 3,682 responses were evaluated. Clinical documents were processed\nusing Llamaindex, and 10 LLMs, including GPT3.5, GPT4, and Claude-3, were\nassessed. Fourteen clinical scenarios were analyzed, focusing on seven aspects\nof preoperative instructions. Established guidelines and expert judgment were\nused to determine correct responses, with human-generated answers serving as\ncomparisons. The LLM-RAG models generated responses within 20 seconds,\nsignificantly faster than clinicians (10 minutes). The GPT4 LLM-RAG model\nachieved the highest accuracy (96.4% vs. 86.6%, p=0.016), with no\nhallucinations and producing correct instructions comparable to clinicians.\nResults were consistent across both local and international guidelines. This\nstudy demonstrates the potential of LLM-RAG models for preoperative healthcare\ntasks, highlighting their efficiency, scalability, and reliability.",
      "tldr_zh": "本研究评估了 Retrieval Augmented Generation (RAG) 技术在增强 10 个 Large Language Models (LLMs) 方面的应用，特别是其在评估手术适应性和提供术前指导的泛化能力。研究团队使用 35 个本地和 23 个国际术前指南开发了 LLM-RAG 模型，并通过 14 个临床场景测试其准确性、一致性和安全性，与人类响应进行比较。结果显示，GPT4 LLM-RAG 模型的准确率最高（96.4% vs. 86.6%，p=0.016），响应时间仅需 20 秒且无幻觉，输出质量可与临床医生媲美。整体而言，这证明了 LLM-RAG 在术前医疗任务中的高效、可扩展性和可靠性，具有重要的临床潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.01733",
      "pdf_url": "http://arxiv.org/pdf/2410.08431v1",
      "published_date": "2024-10-11 00:34:20 UTC",
      "updated_date": "2024-10-11 00:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:35:36.021563"
    },
    {
      "arxiv_id": "2410.21281v1",
      "title": "The Social Impact of Generative LLM-Based AI",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Xie",
        "Sofia Avila"
      ],
      "abstract": "Liking it or not, ready or not, we are likely to enter a new phase of human\nhistory in which Artificial Intelligence (AI) will dominate economic production\nand social life -- the AI Revolution. Before the actual arrival of the AI\nRevolution, it is time for us to speculate on how AI will impact the social\nworld. In this article, we focus on the social impact of generative LLM-based\nAI (GELLMAI), discussing societal factors that contribute to its technological\ndevelopment and its potential roles in enhancing both between-country and\nwithin-country social inequality. There are good indications that the US and\nChina will lead the field and will be the main competitors for domination of AI\nin the world. We conjecture the AI Revolution will likely give rise to a\npost-knowledge society in which knowledge per se will become less important\nthan in today's world. Instead, individual relationships and social identity\nwill become more important. So will soft skills.",
      "tldr_zh": "这篇论文探讨了生成式 LLM-Based AI（GELLMAI）的社会影响，包括推动其技术发展的社会因素，以及它可能加剧国家间和国家内社会不平等的风险。作者预测，美国和中国将主导AI领域，成为全球竞争的主要力量。论文进一步推测，AI Revolution 将催生一个后-knowledge society，在此社会中，知识本身的重要性将下降，而个人关系、社会身份和软技能将变得更为关键。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "00",
        "A.0"
      ],
      "primary_category": "cs.CY",
      "comment": "34 pages, 3 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2410.21281v1",
      "published_date": "2024-10-11 00:26:44 UTC",
      "updated_date": "2024-10-11 00:26:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T10:35:45.739944"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 159,
  "processed_papers_count": 159,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T10:36:17.501880"
}