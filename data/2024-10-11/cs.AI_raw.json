[
  {
    "arxiv_id": "2410.09302v2",
    "title": "Enhancing Multi-Step Reasoning Abilities of Language Models through Direct Q-Function Optimization",
    "authors": [
      "Kaixuan Ji",
      "Guanlin Liu",
      "Ning Dai",
      "Qingping Yang",
      "Renjie Zheng",
      "Zheng Wu",
      "Chen Dun",
      "Quanquan Gu",
      "Lin Yan"
    ],
    "abstract": "Reinforcement Learning (RL) plays a crucial role in aligning large language\nmodels (LLMs) with human preferences and improving their ability to perform\ncomplex tasks. However, current approaches either require significant\ncomputational resources due to the use of multiple models and extensive online\nsampling for training (e.g., PPO) or are framed as bandit problems (e.g., DPO,\nDRO), which often struggle with multi-step reasoning tasks, such as math\nproblem solving and complex reasoning that involve long chains of thought. To\novercome these limitations, we introduce Direct Q-function Optimization (DQO),\nwhich formulates the response generation process as a Markov Decision Process\n(MDP) and utilizes the soft actor-critic (SAC) framework to optimize a\nQ-function directly parameterized by the language model. The MDP formulation of\nDQO offers structural advantages over bandit-based methods, enabling more\neffective process supervision. Experimental results on two math problem-solving\ndatasets, GSM8K and MATH, demonstrate that DQO outperforms previous methods,\nestablishing it as a promising offline reinforcement learning approach for\naligning language models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09302v2",
    "published_date": "2024-10-11 23:29:20 UTC",
    "updated_date": "2025-02-11 01:46:35 UTC"
  },
  {
    "arxiv_id": "2410.09300v3",
    "title": "Nudging: Inference-time Alignment of LLMs via Guided Decoding",
    "authors": [
      "Yu Fei",
      "Yasaman Razeghi",
      "Sameer Singh"
    ],
    "abstract": "Large language models (LLMs) require alignment to effectively and safely\nfollow user instructions. This process necessitates training an aligned version\nfor every base model, resulting in significant computational overhead. In this\nwork, we propose nudging, a simple, plug-and-play, and training-free algorithm\nthat aligns any base model at inference time using a small aligned model.\nNudging is motivated by recent findings that alignment primarily alters the\nmodel's behavior on a small subset of stylistic tokens (e.g., discourse\nmarkers). We find that base models are significantly more uncertain when\ngenerating these tokens. Building on this insight, nudging employs a small\naligned model to generate nudging tokens to guide the base model's output\nduring decoding when the base model's uncertainty is high. We evaluate nudging\nacross 3 model families on a diverse range of open-instruction tasks. Without\nany training, nudging a large base model with a 7x-14x smaller aligned model\nachieves zero-shot performance comparable to, and sometimes surpassing, that of\nlarge aligned models. By operating at the token level, nudging enables\noff-the-shelf collaboration between model families. For instance, nudging\nGemma-2-27b with Llama-2-7b-chat outperforms Llama-2-70b-chat on various tasks.\nOverall, our work offers a modular and cost-efficient solution to LLM\nalignment. Our project website: https://fywalter.github.io/nudging/ .",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09300v3",
    "published_date": "2024-10-11 23:24:38 UTC",
    "updated_date": "2025-04-20 00:16:18 UTC"
  },
  {
    "arxiv_id": "2410.09297v1",
    "title": "Refinements on the Complementary PDB Construction Mechanism",
    "authors": [
      "Yufeng Zou"
    ],
    "abstract": "Pattern database (PDB) is one of the most popular automated heuristic\ngeneration techniques. A PDB maps states in a planning task to abstract states\nby considering a subset of variables and stores their optimal costs to the\nabstract goal in a look up table. As the result of the progress made on\nsymbolic search over recent years, symbolic-PDB-based planners achieved\nimpressive results in the International Planning Competition (IPC) 2018. Among\nthem, Complementary 1 (CPC1) tied as the second best planners and the best\nnon-portfolio planners in the cost optimal track, only 2 tasks behind the\nwinner. It uses a combination of different pattern generation algorithms to\nconstruct PDBs that are complementary to existing ones. As shown in the post\ncontest experiments, there is room for improvement. In this paper, we would\nlike to present our work on refining the PDB construction mechanism of CPC1. By\ntesting on IPC 2018 benchmarks, the results show that a significant improvement\nis made on our modified planner over the original version.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09297v1",
    "published_date": "2024-10-11 23:06:29 UTC",
    "updated_date": "2024-10-11 23:06:29 UTC"
  },
  {
    "arxiv_id": "2410.09295v2",
    "title": "Natural Language Counterfactual Explanations for Graphs Using Large Language Models",
    "authors": [
      "Flavio Giorgi",
      "Cesare Campagnano",
      "Fabrizio Silvestri",
      "Gabriele Tolomei"
    ],
    "abstract": "Explainable Artificial Intelligence (XAI) has emerged as a critical area of\nresearch to unravel the opaque inner logic of (deep) machine learning models.\nAmong the various XAI techniques proposed in the literature, counterfactual\nexplanations stand out as one of the most promising approaches. However, these\n\"what-if\" explanations are frequently complex and technical, making them\ndifficult for non-experts to understand and, more broadly, challenging for\nhumans to interpret. To bridge this gap, in this work, we exploit the power of\nopen-source Large Language Models to generate natural language explanations\nwhen prompted with valid counterfactual instances produced by state-of-the-art\nexplainers for graph-based models. Experiments across several graph datasets\nand counterfactual explainers show that our approach effectively produces\naccurate natural language representations of counterfactual instances, as\ndemonstrated by key performance metrics.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09295v2",
    "published_date": "2024-10-11 23:06:07 UTC",
    "updated_date": "2025-01-27 13:30:57 UTC"
  },
  {
    "arxiv_id": "2410.09290v1",
    "title": "Ranking over Regression for Bayesian Optimization and Molecule Selection",
    "authors": [
      "Gary Tom",
      "Stanley Lo",
      "Samantha Corapi",
      "Alan Aspuru-Guzik",
      "Benjamin Sanchez-Lengeling"
    ],
    "abstract": "Bayesian optimization (BO) has become an indispensable tool for autonomous\ndecision-making across diverse applications from autonomous vehicle control to\naccelerated drug and materials discovery. With the growing interest in\nself-driving laboratories, BO of chemical systems is crucial for machine\nlearning (ML) guided experimental planning. Typically, BO employs a regression\nsurrogate model to predict the distribution of unseen parts of the search\nspace. However, for the selection of molecules, picking the top candidates with\nrespect to a distribution, the relative ordering of their properties may be\nmore important than their exact values. In this paper, we introduce Rank-based\nBayesian Optimization (RBO), which utilizes a ranking model as the surrogate.\nWe present a comprehensive investigation of RBO's optimization performance\ncompared to conventional BO on various chemical datasets. Our results\ndemonstrate similar or improved optimization performance using ranking models,\nparticularly for datasets with rough structure-property landscapes and activity\ncliffs. Furthermore, we observe a high correlation between the surrogate\nranking ability and BO performance, and this ability is maintained even at\nearly iterations of BO optimization when using ranking surrogate models. We\nconclude that RBO is an effective alternative to regression-based BO,\nespecially for optimizing novel chemical compounds.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "14 + 4 pages, 5 + 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09290v1",
    "published_date": "2024-10-11 22:38:14 UTC",
    "updated_date": "2024-10-11 22:38:14 UTC"
  },
  {
    "arxiv_id": "2410.09289v2",
    "title": "Multimodal Audio-based Disease Prediction with Transformer-based Hierarchical Fusion Network",
    "authors": [
      "Jinjin Cai",
      "Ruiqi Wang",
      "Dezhong Zhao",
      "Ziqin Yuan",
      "Victoria McKenna",
      "Aaron Friedman",
      "Rachel Foot",
      "Susan Storey",
      "Ryan Boente",
      "Sudip Vhaduri",
      "Byung-Cheol Min"
    ],
    "abstract": "Audio-based disease prediction is emerging as a promising supplement to\ntraditional medical diagnosis methods, facilitating early, convenient, and\nnon-invasive disease detection and prevention. Multimodal fusion, which\nintegrates features from various domains within or across bio-acoustic\nmodalities, has proven effective in enhancing diagnostic performance. However,\nmost existing methods in the field employ unilateral fusion strategies that\nfocus solely on either intra-modal or inter-modal fusion. This approach limits\nthe full exploitation of the complementary nature of diverse acoustic feature\ndomains and bio-acoustic modalities. Additionally, the inadequate and isolated\nexploration of latent dependencies within modality-specific and modality-shared\nspaces curtails their capacity to manage the inherent heterogeneity in\nmultimodal data. To fill these gaps, we propose a transformer-based\nhierarchical fusion network designed for general multimodal audio-based disease\nprediction. Specifically, we seamlessly integrate intra-modal and inter-modal\nfusion in a hierarchical manner and proficiently encode the necessary\nintra-modal and inter-modal complementary correlations, respectively.\nComprehensive experiments demonstrate that our model achieves state-of-the-art\nperformance in predicting three diseases: COVID-19, Parkinson's disease, and\npathological dysarthria, showcasing its promising potential in a broad context\nof audio-based disease prediction tasks. Additionally, extensive ablation\nstudies and qualitative analyses highlight the significant benefits of each\nmain component within our model.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09289v2",
    "published_date": "2024-10-11 22:37:52 UTC",
    "updated_date": "2024-12-14 19:08:02 UTC"
  },
  {
    "arxiv_id": "2410.09286v1",
    "title": "Language-Model-Assisted Bi-Level Programming for Reward Learning from Internet Videos",
    "authors": [
      "Harsh Mahesheka",
      "Zhixian Xie",
      "Zhaoran Wang",
      "Wanxin Jin"
    ],
    "abstract": "Learning from Demonstrations, particularly from biological experts like\nhumans and animals, often encounters significant data acquisition challenges.\nWhile recent approaches leverage internet videos for learning, they require\ncomplex, task-specific pipelines to extract and retarget motion data for the\nagent. In this work, we introduce a language-model-assisted bi-level\nprogramming framework that enables a reinforcement learning agent to directly\nlearn its reward from internet videos, bypassing dedicated data preparation.\nThe framework includes two levels: an upper level where a vision-language model\n(VLM) provides feedback by comparing the learner's behavior with expert videos,\nand a lower level where a large language model (LLM) translates this feedback\ninto reward updates. The VLM and LLM collaborate within this bi-level\nframework, using a \"chain rule\" approach to derive a valid search direction for\nreward learning. We validate the method for reward learning from YouTube\nvideos, and the results have shown that the proposed method enables efficient\nreward design from expert videos of biological agents for complex behavior\nsynthesis.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09286v1",
    "published_date": "2024-10-11 22:31:39 UTC",
    "updated_date": "2024-10-11 22:31:39 UTC"
  },
  {
    "arxiv_id": "2410.09275v1",
    "title": "Articulated Animal AI: An Environment for Animal-like Cognition in a Limbed Agent",
    "authors": [
      "Jeremy Lucas",
      "Isabeau Prémont-Schwarz"
    ],
    "abstract": "This paper presents the Articulated Animal AI Environment for Animal\nCognition, an enhanced version of the previous AnimalAI Environment. Key\nimprovements include the addition of agent limbs, enabling more complex\nbehaviors and interactions with the environment that closely resemble real\nanimal movements. The testbench features an integrated curriculum training\nsequence and evaluation tools, eliminating the need for users to develop their\nown training programs. Additionally, the tests and training procedures are\nrandomized, which will improve the agent's generalization capabilities. These\nadvancements significantly expand upon the original AnimalAI framework and will\nbe used to evaluate agents on various aspects of animal cognition.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, accepted to Workshop on Open-World Agents (OWA-2024) at\n  NeurIPS 2024 in Vancouver, Canada",
    "pdf_url": "http://arxiv.org/pdf/2410.09275v1",
    "published_date": "2024-10-11 21:55:23 UTC",
    "updated_date": "2024-10-11 21:55:23 UTC"
  },
  {
    "arxiv_id": "2410.11886v1",
    "title": "Are Grid Cells Hexagonal for Performance or by Convenience?",
    "authors": [
      "Taahaa Mir",
      "Peipei Yao",
      "Kateri Duranceau",
      "Isabeau Prémont-Schwarz"
    ],
    "abstract": "This paper investigates whether the hexagonal structure of grid cells\nprovides any performance benefits or if it merely represents a biologically\nconvenient configuration. Utilizing the Vector-HaSH content addressable memory\nmodel as a model of the grid cell -- place cell network of the mammalian brain,\nwe compare the performance of square and hexagonal grid cells in tasks of\nstoring and retrieving spatial memories. Our experiments across different path\ntypes, path lengths and grid configurations, reveal that hexagonal grid cells\nperform similarly to square grid cells with respect to spatial representation\nand memory recall. Our results show comparable accuracy and robustness across\ndifferent datasets and noise levels on images to recall. These findings suggest\nthat the brain's use of hexagonal grids may be more a matter of biological\nconvenience and ease of implementation rather than because they provide\nsuperior performance over square grid cells (which are easier to implement in\nsilico).",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "q-bio.NC",
    "comment": "5 pages, accepted at Montreal AI and Neuroscience Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.11886v1",
    "published_date": "2024-10-11 21:45:49 UTC",
    "updated_date": "2024-10-11 21:45:49 UTC"
  },
  {
    "arxiv_id": "2410.09268v1",
    "title": "One Step at a Time: Combining LLMs and Static Analysis to Generate Next-Step Hints for Programming Tasks",
    "authors": [
      "Anastasiia Birillo",
      "Elizaveta Artser",
      "Anna Potriasaeva",
      "Ilya Vlasov",
      "Katsiaryna Dzialets",
      "Yaroslav Golubev",
      "Igor Gerasimov",
      "Hieke Keuning",
      "Timofey Bryksin"
    ],
    "abstract": "Students often struggle with solving programming problems when learning to\ncode, especially when they have to do it online, with one of the most common\ndisadvantages of working online being the lack of personalized help. This help\ncan be provided as next-step hint generation, i.e., showing a student what\nspecific small step they need to do next to get to the correct solution. There\nare many ways to generate such hints, with large language models (LLMs) being\namong the most actively studied right now.\n  While LLMs constitute a promising technology for providing personalized help,\ncombining them with other techniques, such as static analysis, can\nsignificantly improve the output quality. In this work, we utilize this idea\nand propose a novel system to provide both textual and code hints for\nprogramming tasks. The pipeline of the proposed approach uses a\nchain-of-thought prompting technique and consists of three distinct steps: (1)\ngenerating subgoals - a list of actions to proceed with the task from the\ncurrent student's solution, (2) generating the code to achieve the next\nsubgoal, and (3) generating the text to describe this needed action. During the\nsecond step, we apply static analysis to the generated code to control its size\nand quality. The tool is implemented as a modification to the open-source\nJetBrains Academy plugin, supporting students in their in-IDE courses.\n  To evaluate our approach, we propose a list of criteria for all steps in our\npipeline and conduct two rounds of expert validation. Finally, we evaluate the\nnext-step hints in a classroom with 14 students from two universities. Our\nresults show that both forms of the hints - textual and code - were helpful for\nthe students, and the proposed system helped them to proceed with the coding\ntasks.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09268v1",
    "published_date": "2024-10-11 21:41:57 UTC",
    "updated_date": "2024-10-11 21:41:57 UTC"
  },
  {
    "arxiv_id": "2410.09252v1",
    "title": "ReasonPlanner: Enhancing Autonomous Planning in Dynamic Environments with Temporal Knowledge Graphs and LLMs",
    "authors": [
      "Minh Pham Dinh",
      "Munira Syed",
      "Michael G Yankoski",
      "Trenton W. Ford"
    ],
    "abstract": "Planning and performing interactive tasks, such as conducting experiments to\ndetermine the melting point of an unknown substance, is straightforward for\nhumans but poses significant challenges for autonomous agents. We introduce\nReasonPlanner, a novel generalist agent designed for reflective thinking,\nplanning, and interactive reasoning. This agent leverages LLMs to plan\nhypothetical trajectories by building a World Model based on a Temporal\nKnowledge Graph. The agent interacts with the environment using a natural\nlanguage actor-critic module, where the actor translates the imagined\ntrajectory into a sequence of actionable steps, and the critic determines if\nreplanning is necessary. ReasonPlanner significantly outperforms previous\nstate-of-the-art prompting-based methods on the ScienceWorld benchmark by more\nthan 1.8 times, while being more sample-efficient and interpretable. It relies\nsolely on frozen weights thus requiring no gradient updates. ReasonPlanner can\nbe deployed and utilized without specialized knowledge of Machine Learning,\nmaking it accessible to a wide range of users.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09252v1",
    "published_date": "2024-10-11 20:58:51 UTC",
    "updated_date": "2024-10-11 20:58:51 UTC"
  },
  {
    "arxiv_id": "2410.12860v1",
    "title": "LLMD: A Large Language Model for Interpreting Longitudinal Medical Records",
    "authors": [
      "Robert Porter",
      "Adam Diehl",
      "Benjamin Pastel",
      "J. Henry Hinnefeld",
      "Lawson Nerenberg",
      "Pye Maung",
      "Sebastien Kerbrat",
      "Gillian Hanson",
      "Troy Astorino",
      "Stephen J. Tarsa"
    ],
    "abstract": "We introduce LLMD, a large language model designed to analyze a patient's\nmedical history based on their medical records. Along with domain knowledge,\nLLMD is trained on a large corpus of records collected over time and across\nfacilities, as well as tasks and labels that make nuanced connections among\nthem. This approach is critical to an accurate picture of patient health, and\nhas distinctive advantages over models trained on knowledge alone, unlabeled\nrecords, structured EHR data, or records from a single health system.\n  The recipe for LLMD continues pretraining a foundational model on both domain\nknowledge and the contents of millions of records. These span an average of 10\nyears of care and as many as 140 care sites per patient. LLMD is then\ninstruction fine-tuned on structuring and abstraction tasks. The former jointly\nidentify and normalize document metadata, provenance information, clinical\nnamed-entities, and ontology mappings, while the latter roll these into\nhigher-level representations, such a continuous era of time a patient was on a\nmedication. LLMD is deployed within a layered validation system that includes\ncontinual random audits and review by experts, e.g. based on uncertainty,\ndisease-specific rules, or use-case.\n  LLMD exhibits large gains over both more-powerful generalized models and\ndomain-specific models. On medical knowledge benchmarks, LLMD-8B achieves state\nof the art accuracy on PubMedQA text responses, besting orders-of-magnitude\nlarger models. On production tasks, we show that LLMD significantly outperforms\nall other models evaluated, and among alternatives, large general purpose LLMs\nlike GPT-4o are more accurate than models emphasizing medical knowledge. We\nfind strong evidence that accuracy on today's medical benchmarks is not the\nmost significant factor when analyzing real-world patient data, an insight with\nimplications for future medical LLMs.'",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12860v1",
    "published_date": "2024-10-11 20:55:51 UTC",
    "updated_date": "2024-10-11 20:55:51 UTC"
  },
  {
    "arxiv_id": "2410.09250v1",
    "title": "Quantum-Trained Convolutional Neural Network for Deepfake Audio Detection",
    "authors": [
      "Chu-Hsuan Abraham Lin",
      "Chen-Yu Liu",
      "Samuel Yen-Chi Chen",
      "Kuan-Cheng Chen"
    ],
    "abstract": "The rise of deepfake technologies has posed significant challenges to\nprivacy, security, and information integrity, particularly in audio and\nmultimedia content. This paper introduces a Quantum-Trained Convolutional\nNeural Network (QT-CNN) framework designed to enhance the detection of deepfake\naudio, leveraging the computational power of quantum machine learning (QML).\nThe QT-CNN employs a hybrid quantum-classical approach, integrating Quantum\nNeural Networks (QNNs) with classical neural architectures to optimize training\nefficiency while reducing the number of trainable parameters. Our method\nincorporates a novel quantum-to-classical parameter mapping that effectively\nutilizes quantum states to enhance the expressive power of the model, achieving\nup to 70% parameter reduction compared to classical models without compromising\naccuracy. Data pre-processing involved extracting essential audio features,\nlabel encoding, feature scaling, and constructing sequential datasets for\nrobust model evaluation. Experimental results demonstrate that the QT-CNN\nachieves comparable performance to traditional CNNs, maintaining high accuracy\nduring training and testing phases across varying configurations of QNN blocks.\nThe QT framework's ability to reduce computational overhead while maintaining\nperformance underscores its potential for real-world applications in deepfake\ndetection and other resource-constrained scenarios. This work highlights the\npractical benefits of integrating quantum computing into artificial\nintelligence, offering a scalable and efficient approach to advancing deepfake\ndetection technologies.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS",
      "quant-ph"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09250v1",
    "published_date": "2024-10-11 20:52:10 UTC",
    "updated_date": "2024-10-11 20:52:10 UTC"
  },
  {
    "arxiv_id": "2410.09247v1",
    "title": "Benchmark Inflation: Revealing LLM Performance Gaps Using Retro-Holdouts",
    "authors": [
      "Jacob Haimes",
      "Cenny Wenner",
      "Kunvar Thaman",
      "Vassil Tashev",
      "Clement Neo",
      "Esben Kran",
      "Jason Schreiber"
    ],
    "abstract": "The training data for many Large Language Models (LLMs) is contaminated with\ntest data. This means that public benchmarks used to assess LLMs are\ncompromised, suggesting a performance gap between benchmark scores and actual\ncapabilities. Ideally, a private holdout set could be used to accurately verify\nscores. Unfortunately, such datasets do not exist for most benchmarks, and\npost-hoc construction of sufficiently similar datasets is non-trivial. To\naddress these issues, we introduce a systematic methodology for (i)\nretrospectively constructing a holdout dataset for a target dataset, (ii)\ndemonstrating the statistical indistinguishability of this retro-holdout\ndataset, and (iii) comparing LLMs on the two datasets to quantify the\nperformance gap due to the dataset's public availability. Applying these\nmethods to TruthfulQA, we construct and release Retro-Misconceptions, on which\nwe evaluate twenty LLMs and find that some have inflated scores by as much as\n16 percentage points. Our results demonstrate that public benchmark scores do\nnot always accurately assess model properties, and underscore the importance of\nimproved data practices in the field.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09247v1",
    "published_date": "2024-10-11 20:46:56 UTC",
    "updated_date": "2024-10-11 20:46:56 UTC"
  },
  {
    "arxiv_id": "2410.09246v1",
    "title": "DFM: Interpolant-free Dual Flow Matching",
    "authors": [
      "Denis Gudovskiy",
      "Tomoyuki Okuno",
      "Yohei Nakata"
    ],
    "abstract": "Continuous normalizing flows (CNFs) can model data distributions with\nexpressive infinite-length architectures. But this modeling involves\ncomputationally expensive process of solving an ordinary differential equation\n(ODE) during maximum likelihood training. Recently proposed flow matching (FM)\nframework allows to substantially simplify the training phase using a\nregression objective with the interpolated forward vector field. In this paper,\nwe propose an interpolant-free dual flow matching (DFM) approach without\nexplicit assumptions about the modeled vector field. DFM optimizes the forward\nand, additionally, a reverse vector field model using a novel objective that\nfacilitates bijectivity of the forward and reverse transformations. Our\nexperiments with the SMAP unsupervised anomaly detection show advantages of DFM\nwhen compared to the CNF trained with either maximum likelihood or FM\nobjectives with the state-of-the-art performance metrics.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Extended Abstract Track at the Unifying Representations in Neural\n  Models Workshop (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.09246v1",
    "published_date": "2024-10-11 20:46:04 UTC",
    "updated_date": "2024-10-11 20:46:04 UTC"
  },
  {
    "arxiv_id": "2410.09244v1",
    "title": "Using off-the-shelf LLMs to query enterprise data by progressively revealing ontologies",
    "authors": [
      "C. Civili",
      "E. Sherkhonov",
      "R. E. K. Stirewalt"
    ],
    "abstract": "Ontologies are known to improve the accuracy of Large Language Models (LLMs)\nwhen translating natural language queries into a formal query language like SQL\nor SPARQL. There are two ways to leverage ontologies when working with LLMs.\nOne is to fine-tune the model, i.e., to enhance it with specific domain\nknowledge. Another is the zero-shot prompting approach, where the ontology is\nprovided as part of the input question. Unfortunately, modern enterprises\ntypically have ontologies that are too large to fit in a prompt due to LLM's\ntoken size limitations. We present a solution that incrementally reveals \"just\nenough\" of an ontology that is needed to answer a given question.",
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "primary_category": "cs.DB",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.09244v1",
    "published_date": "2024-10-11 20:41:04 UTC",
    "updated_date": "2024-10-11 20:41:04 UTC"
  },
  {
    "arxiv_id": "2410.21287v1",
    "title": "A Systematic Assessment of OpenAI o1-Preview for Higher Order Thinking in Education",
    "authors": [
      "Ehsan Latif",
      "Yifan Zhou",
      "Shuchen Guo",
      "Yizhu Gao",
      "Lehong Shi",
      "Matthew Nayaaba",
      "Gyeonggeon Lee",
      "Liang Zhang",
      "Arne Bewersdorff",
      "Luyang Fang",
      "Xiantong Yang",
      "Huaqin Zhao",
      "Hanqi Jiang",
      "Haoran Lu",
      "Jiaxi Li",
      "Jichao Yu",
      "Weihang You",
      "Zhengliang Liu",
      "Vincent Shung Liu",
      "Hui Wang",
      "Zihao Wu",
      "Jin Lu",
      "Fei Dou",
      "Ping Ma",
      "Ninghao Liu",
      "Tianming Liu",
      "Xiaoming Zhai"
    ],
    "abstract": "As artificial intelligence (AI) continues to advance, it demonstrates\ncapabilities comparable to human intelligence, with significant potential to\ntransform education and workforce development. This study evaluates OpenAI\no1-preview's ability to perform higher-order cognitive tasks across 14\ndimensions, including critical thinking, systems thinking, computational\nthinking, design thinking, metacognition, data literacy, creative thinking,\nabstract reasoning, quantitative reasoning, logical reasoning, analogical\nreasoning, and scientific reasoning. We used validated instruments like the\nEnnis-Weir Critical Thinking Essay Test and the Biological Systems Thinking\nTest to compare the o1-preview's performance with human performance\nsystematically. Our findings reveal that o1-preview outperforms humans in most\ncategories, achieving 150% better results in systems thinking, computational\nthinking, data literacy, creative thinking, scientific reasoning, and abstract\nreasoning. However, compared to humans, it underperforms by around 25% in\nlogical reasoning, critical thinking, and quantitative reasoning. In analogical\nreasoning, both o1-preview and humans achieved perfect scores. Despite these\nstrengths, the o1-preview shows limitations in abstract reasoning, where human\npsychology students outperform it, highlighting the continued importance of\nhuman oversight in tasks requiring high-level abstraction. These results have\nsignificant educational implications, suggesting a shift toward developing\nhuman skills that complement AI, such as creativity, abstract reasoning, and\ncritical thinking. This study emphasizes the transformative potential of AI in\neducation and calls for a recalibration of educational goals, teaching methods,\nand curricula to align with an AI-driven world.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "An assessment of OpenAI o1-Preview for Higher Order Thinking in\n  Education",
    "pdf_url": "http://arxiv.org/pdf/2410.21287v1",
    "published_date": "2024-10-11 20:30:16 UTC",
    "updated_date": "2024-10-11 20:30:16 UTC"
  },
  {
    "arxiv_id": "2410.09230v3",
    "title": "Improving Semantic Understanding in Speech Language Models via Brain-tuning",
    "authors": [
      "Omer Moussa",
      "Dietrich Klakow",
      "Mariya Toneva"
    ],
    "abstract": "Speech language models align with human brain responses to natural language\nto an impressive degree. However, current models rely heavily on low-level\nspeech features, indicating they lack brain-relevant semantics which limits\ntheir utility as model organisms of semantic processing in the brain. In this\nwork, we address this limitation by inducing brain-relevant bias directly into\nthe models via fine-tuning with fMRI recordings of people listening to natural\nstories, a process we name brain-tuning. After testing it on 3 different\npretrained model families, we show that brain-tuning not only improves overall\nalignment with new brain recordings in semantic language regions, but also\nreduces the reliance on low-level speech features for this alignment.\nExcitingly, we further show that brain-tuning leads to 1) consistent\nimprovements in performance on a range of downstream tasks and 2) a\nrepresentational space with increased semantic preference. Our results provide\nconverging evidence, for the first time, that incorporating brain signals into\nthe training of language models improves the models' semantic understanding.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.09230v3",
    "published_date": "2024-10-11 20:06:21 UTC",
    "updated_date": "2025-03-04 15:26:30 UTC"
  },
  {
    "arxiv_id": "2410.09223v1",
    "title": "The Same But Different: Structural Similarities and Differences in Multilingual Language Modeling",
    "authors": [
      "Ruochen Zhang",
      "Qinan Yu",
      "Matianyu Zang",
      "Carsten Eickhoff",
      "Ellie Pavlick"
    ],
    "abstract": "We employ new tools from mechanistic interpretability in order to ask whether\nthe internal structure of large language models (LLMs) shows correspondence to\nthe linguistic structures which underlie the languages on which they are\ntrained. In particular, we ask (1) when two languages employ the same\nmorphosyntactic processes, do LLMs handle them using shared internal circuitry?\nand (2) when two languages require different morphosyntactic processes, do LLMs\nhandle them using different internal circuitry? Using English and Chinese\nmultilingual and monolingual models, we analyze the internal circuitry involved\nin two tasks. We find evidence that models employ the same circuit to handle\nthe same syntactic process independently of the language in which it occurs,\nand that this is the case even for monolingual models trained completely\nindependently. Moreover, we show that multilingual models employ\nlanguage-specific components (attention heads and feed-forward networks) when\nneeded to handle linguistic processes (e.g., morphological marking) that only\nexist in some languages. Together, our results provide new insights into how\nLLMs trade off between exploiting common structures and preserving linguistic\ndifferences when tasked with modeling multiple languages simultaneously.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09223v1",
    "published_date": "2024-10-11 19:57:55 UTC",
    "updated_date": "2024-10-11 19:57:55 UTC"
  },
  {
    "arxiv_id": "2410.22340v1",
    "title": "Testing GPT-4-o1-preview on math and science problems: A follow-up study",
    "authors": [
      "Ernest Davis"
    ],
    "abstract": "In August 2023, Scott Aaronson and I reported the results of testing GPT4\nwith the Wolfram Alpha and Code Interpreter plug-ins over a collection of 105\noriginal high-school level and college-level science and math problems (Davis\nand Aaronson, 2023). In September 2024, I tested the recently released model\nGPT-4o1-preview on the same collection. Overall I found that performance had\nsignificantly improved, but was still considerably short of perfect. In\nparticular, problems that involve spatial reasoning are often stumbling blocks.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22340v1",
    "published_date": "2024-10-11 19:56:26 UTC",
    "updated_date": "2024-10-11 19:56:26 UTC"
  },
  {
    "arxiv_id": "2410.09218v2",
    "title": "Continual Learning with Neuromorphic Computing: Theories, Methods, and Applications",
    "authors": [
      "Mishal Fatima Minhas",
      "Rachmad Vidya Wicaksana Putra",
      "Falah Awwad",
      "Osman Hasan",
      "Muhammad Shafique"
    ],
    "abstract": "To adapt to real-world dynamics, intelligent systems need to assimilate new\nknowledge without catastrophic forgetting, where learning new tasks leads to a\ndegradation in performance on old tasks. To address this, continual learning\nconcept is proposed for enabling autonomous systems to acquire new knowledge\nand dynamically adapt to changing environments. Specifically, energy-efficient\ncontinual learning is needed to ensure the functionality of autonomous systems\nunder tight compute and memory resource budgets (i.e., so-called autonomous\nembedded systems). Neuromorphic computing, with brain-inspired Spiking Neural\nNetworks (SNNs), offers inherent advantages for enabling low-power/energy\ncontinual learning in autonomous embedded systems. In this paper, we\ncomprehensively discuss the foundations and methods for enabling continual\nlearning in neural networks, then analyze the state-of-the-art works\nconsidering SNNs. Afterward, comparative analyses of existing methods are\nconducted while considering crucial design factors, such as network complexity,\nmemory, latency, and power/energy efficiency. We also explore the practical\napplications that can benefit from SNN-based continual learning and open\nchallenges in real-world scenarios. In this manner, our survey provides\nvaluable insights into the recent advancements of SNN-based continual learning\nfor real-world application use-cases.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "This work has been submitted to the IEEE Access for possible\n  publication",
    "pdf_url": "http://arxiv.org/pdf/2410.09218v2",
    "published_date": "2024-10-11 19:49:53 UTC",
    "updated_date": "2024-10-28 04:52:01 UTC"
  },
  {
    "arxiv_id": "2410.12859v1",
    "title": "Enhancing Long Context Performance in LLMs Through Inner Loop Query Mechanism",
    "authors": [
      "Yimin Tang",
      "Yurong Xu",
      "Ning Yan",
      "Masood Mortazavi"
    ],
    "abstract": "Transformers have a quadratic scaling of computational complexity with input\nsize, which limits the input context window size of large language models\n(LLMs) in both training and inference. Meanwhile, retrieval-augmented\ngeneration (RAG) besed models can better handle longer contexts by using a\nretrieval system to filter out unnecessary information. However, most RAG\nmethods only perform retrieval based on the initial query, which may not work\nwell with complex questions that require deeper reasoning. We introduce a novel\napproach, Inner Loop Memory Augmented Tree Retrieval (ILM-TR), involving\ninner-loop queries, based not only on the query question itself but also on\nintermediate findings. At inference time, our model retrieves information from\nthe RAG system, integrating data from lengthy documents at various levels of\nabstraction. Based on the information retrieved, the LLM generates texts stored\nin an area named Short-Term Memory (STM) which is then used to formulate the\nnext query. This retrieval process is repeated until the text in STM converged.\nOur experiments demonstrate that retrieval with STM offers improvements over\ntraditional retrieval-augmented LLMs, particularly in long context tests such\nas Multi-Needle In A Haystack (M-NIAH) and BABILong.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12859v1",
    "published_date": "2024-10-11 19:49:05 UTC",
    "updated_date": "2024-10-11 19:49:05 UTC"
  },
  {
    "arxiv_id": "2410.09207v1",
    "title": "P-FOLIO: Evaluating and Improving Logical Reasoning with Abundant Human-Written Reasoning Chains",
    "authors": [
      "Simeng Han",
      "Aaron Yu",
      "Rui Shen",
      "Zhenting Qi",
      "Martin Riddell",
      "Wenfei Zhou",
      "Yujie Qiao",
      "Yilun Zhao",
      "Semih Yavuz",
      "Ye Liu",
      "Shafiq Joty",
      "Yingbo Zhou",
      "Caiming Xiong",
      "Dragomir Radev",
      "Rex Ying",
      "Arman Cohan"
    ],
    "abstract": "Existing methods on understanding the capabilities of LLMs in logical\nreasoning rely on binary entailment classification or synthetically derived\nrationales, which are not sufficient for proper investigation of model's\ncapabilities. We present P-FOLIO, a human-annotated dataset consisting of\ndiverse and complex reasoning chains for a set of realistic logical reasoning\nstories also written by humans. P-FOLIO is collected with an annotation\nprotocol that facilitates humans to annotate well-structured natural language\nproofs for first-order logic reasoning problems in a step-by-step manner. The\nnumber of reasoning steps in P-FOLIO span from 0 to 20. We further use P-FOLIO\nto evaluate and improve large-language-model (LLM) reasoning capabilities. We\nevaluate LLM reasoning capabilities at a fine granularity via single-step\ninference rule classification, with more diverse inference rules of more\ndiverse and higher levels of complexities than previous works. Given that a\nsingle model-generated reasoning chain could take a completely different path\nthan the human-annotated one, we sample multiple reasoning chains from a model\nand use pass@k metrics for evaluating the quality of model-generated reasoning\nchains. We show that human-written reasoning chains significantly boost the\nlogical reasoning capabilities of LLMs via many-shot prompting and fine-tuning.\nFurthermore, fine-tuning Llama3-7B on P-FOLIO improves the model performance by\n10% or more on three other out-of-domain logical reasoning datasets. We also\nconduct detailed analysis to show where most powerful LLMs fall short in\nreasoning. We will release the dataset and code publicly.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09207v1",
    "published_date": "2024-10-11 19:22:57 UTC",
    "updated_date": "2024-10-11 19:22:57 UTC"
  },
  {
    "arxiv_id": "2410.09206v1",
    "title": "pyhgf: A neural network library for predictive coding",
    "authors": [
      "Nicolas Legrand",
      "Lilian Weber",
      "Peter Thestrup Waade",
      "Anna Hedvig Møller Daugaard",
      "Mojtaba Khodadadi",
      "Nace Mikuš",
      "Chris Mathys"
    ],
    "abstract": "Bayesian models of cognition have gained considerable traction in\ncomputational neuroscience and psychiatry. Their scopes are now expected to\nexpand rapidly to artificial intelligence, providing general inference\nframeworks to support embodied, adaptable, and energy-efficient autonomous\nagents. A central theory in this domain is predictive coding, which posits that\nlearning and behaviour are driven by hierarchical probabilistic inferences\nabout the causes of sensory inputs. Biological realism constrains these\nnetworks to rely on simple local computations in the form of precision-weighted\npredictions and prediction errors. This can make this framework highly\nefficient, but its implementation comes with unique challenges on the software\ndevelopment side. Embedding such models in standard neural network libraries\noften becomes limiting, as these libraries' compilation and differentiation\nbackends can force a conceptual separation between optimization algorithms and\nthe systems being optimized. This critically departs from other biological\nprinciples such as self-monitoring, self-organisation, cellular growth and\nfunctional plasticity. In this paper, we introduce \\texttt{pyhgf}: a Python\npackage backed by JAX and Rust for creating, manipulating and sampling dynamic\nnetworks for predictive coding. We improve over other frameworks by enclosing\nthe network components as transparent, modular and malleable variables in the\nmessage-passing steps. The resulting graphs can implement arbitrary\ncomputational complexities as beliefs propagation. But the transparency of core\nvariables can also translate into inference processes that leverage\nself-organisation principles, and express structure learning, meta-learning or\ncausal discovery as the consequence of network structural adaptation to\nsurprising inputs. The code, tutorials and documentation are hosted at:\nhttps://github.com/ilabcode/pyhgf.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG",
      "q-bio.NC"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09206v1",
    "published_date": "2024-10-11 19:21:38 UTC",
    "updated_date": "2024-10-11 19:21:38 UTC"
  },
  {
    "arxiv_id": "2410.09204v1",
    "title": "Encoding Agent Trajectories as Representations with Sequence Transformers",
    "authors": [
      "Athanasios Tsiligkaridis",
      "Nicholas Kalinowski",
      "Zhongheng Li",
      "Elizabeth Hou"
    ],
    "abstract": "Spatiotemporal data faces many analogous challenges to natural language text\nincluding the ordering of locations (words) in a sequence, long range\ndependencies between locations, and locations having multiple meanings. In this\nwork, we propose a novel model for representing high dimensional spatiotemporal\ntrajectories as sequences of discrete locations and encoding them with a\nTransformer-based neural network architecture. Similar to language models, our\nSequence Transformer for Agent Representation Encodings (STARE) model can learn\nrepresentations and structure in trajectory data through both supervisory tasks\n(e.g., classification), and self-supervisory tasks (e.g., masked modelling). We\npresent experimental results on various synthetic and real trajectory datasets\nand show that our proposed model can learn meaningful encodings that are useful\nfor many downstream tasks including discriminating between labels and\nindicating similarity between locations. Using these encodings, we also learn\nrelationships between agents and locations present in spatiotemporal data.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, to be presented at GeoAI workshop at ACM SigSpatial 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.09204v1",
    "published_date": "2024-10-11 19:18:47 UTC",
    "updated_date": "2024-10-11 19:18:47 UTC"
  },
  {
    "arxiv_id": "2410.12858v1",
    "title": "Large Language Models for Medical OSCE Assessment: A Novel Approach to Transcript Analysis",
    "authors": [
      "Ameer Hamza Shakur",
      "Michael J. Holcomb",
      "David Hein",
      "Shinyoung Kang",
      "Thomas O. Dalton",
      "Krystle K. Campbell",
      "Daniel J. Scott",
      "Andrew R. Jamieson"
    ],
    "abstract": "Grading Objective Structured Clinical Examinations (OSCEs) is a\ntime-consuming and expensive process, traditionally requiring extensive manual\neffort from human experts. In this study, we explore the potential of Large\nLanguage Models (LLMs) to assess skills related to medical student\ncommunication. We analyzed 2,027 video-recorded OSCE examinations from the\nUniversity of Texas Southwestern Medical Center (UTSW), spanning four years\n(2019-2022), and several different medical cases or \"stations.\" Specifically,\nour focus was on evaluating students' ability to summarize patients' medical\nhistory: we targeted the rubric item 'did the student summarize the patients'\nmedical history?' from the communication skills rubric. After transcribing\nspeech audio captured by OSCE videos using Whisper-v3, we studied the\nperformance of various LLM-based approaches for grading students on this\nsummarization task based on their examination transcripts. Using various\nfrontier-level open-source and proprietary LLMs, we evaluated different\ntechniques such as zero-shot chain-of-thought prompting, retrieval augmented\ngeneration, and multi-model ensemble methods. Our results show that frontier\nLLM models like GPT-4 achieved remarkable alignment with human graders,\ndemonstrating a Cohen's kappa agreement of 0.88 and indicating strong potential\nfor LLM-based OSCE grading to augment the current grading process. Open-source\nmodels also showed promising results, suggesting potential for widespread,\ncost-effective deployment. Further, we present a failure analysis identifying\nconditions where LLM grading may be less reliable in this context and recommend\nbest practices for deploying LLMs in medical education settings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12858v1",
    "published_date": "2024-10-11 19:16:03 UTC",
    "updated_date": "2024-10-11 19:16:03 UTC"
  },
  {
    "arxiv_id": "2410.09194v1",
    "title": "AI security and cyber risk in IoT systems",
    "authors": [
      "Petar Radanliev",
      "David De Roure",
      "Carsten Maple",
      "Jason R. C. Nurse",
      "Razvan Nicolescu",
      "Uchenna Ani"
    ],
    "abstract": "We present a dependency model tailored to the context of current challenges\nin data strategies and make recommendations for the cybersecurity community.\nThe model can be used for cyber risk estimation and assessment and generic risk\nimpact assessment.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09194v1",
    "published_date": "2024-10-11 18:54:02 UTC",
    "updated_date": "2024-10-11 18:54:02 UTC"
  },
  {
    "arxiv_id": "2410.09193v1",
    "title": "Synthetic Students: A Comparative Study of Bug Distribution Between Large Language Models and Computing Students",
    "authors": [
      "Stephen MacNeil",
      "Magdalena Rogalska",
      "Juho Leinonen",
      "Paul Denny",
      "Arto Hellas",
      "Xandria Crosland"
    ],
    "abstract": "Large language models (LLMs) present an exciting opportunity for generating\nsynthetic classroom data. Such data could include code containing a typical\ndistribution of errors, simulated student behaviour to address the cold start\nproblem when developing education tools, and synthetic user data when access to\nauthentic data is restricted due to privacy reasons. In this research paper, we\nconduct a comparative study examining the distribution of bugs generated by\nLLMs in contrast to those produced by computing students. Leveraging data from\ntwo previous large-scale analyses of student-generated bugs, we investigate\nwhether LLMs can be coaxed to exhibit bug patterns that are similar to\nauthentic student bugs when prompted to inject errors into code. The results\nsuggest that unguided, LLMs do not generate plausible error distributions, and\nmany of the generated errors are unlikely to be generated by real students.\nHowever, with guidance including descriptions of common errors and typical\nfrequencies, LLMs can be shepherded to generate realistic distributions of\nerrors in synthetic code.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09193v1",
    "published_date": "2024-10-11 18:51:58 UTC",
    "updated_date": "2024-10-11 18:51:58 UTC"
  },
  {
    "arxiv_id": "2410.22339v2",
    "title": "DAWN: Designing Distributed Agents in a Worldwide Network",
    "authors": [
      "Zahra Aminiranjbar",
      "Jianan Tang",
      "Qiudan Wang",
      "Shubha Pant",
      "Mahesh Viswanathan"
    ],
    "abstract": "The rapid evolution of Large Language Models (LLMs) has transformed them from\nbasic conversational tools into sophisticated entities capable of complex\nreasoning and decision-making. These advancements have led to the development\nof specialized LLM-based agents designed for diverse tasks such as coding and\nweb browsing. As these agents become more capable, the need for a robust\nframework that facilitates global communication and collaboration among them\ntowards advanced objectives has become increasingly critical. Distributed\nAgents in a Worldwide Network (DAWN) addresses this need by offering a\nversatile framework that integrates LLM-based agents with traditional software\nsystems, enabling the creation of agentic applications suited for a wide range\nof use cases. DAWN enables distributed agents worldwide to register and be\neasily discovered through Gateway Agents. Collaborations among these agents are\ncoordinated by a Principal Agent equipped with reasoning strategies. DAWN\noffers three operational modes: No-LLM Mode for deterministic tasks, Copilot\nfor augmented decision-making, and LLM Agent for autonomous operations.\nAdditionally, DAWN ensures the safety and security of agent collaborations\nglobally through a dedicated safety, security, and compliance layer, protecting\nthe network against attackers and adhering to stringent security and compliance\nstandards. These features make DAWN a robust network for deploying agent-based\napplications across various industries.",
    "categories": [
      "cs.NI",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.NI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.22339v2",
    "published_date": "2024-10-11 18:47:04 UTC",
    "updated_date": "2024-11-18 17:30:47 UTC"
  },
  {
    "arxiv_id": "2410.09187v2",
    "title": "Automated Rewards via LLM-Generated Progress Functions",
    "authors": [
      "Vishnu Sarukkai",
      "Brennan Shacklett",
      "Zander Majercik",
      "Kush Bhatia",
      "Christopher Ré",
      "Kayvon Fatahalian"
    ],
    "abstract": "Large Language Models (LLMs) have the potential to automate reward\nengineering by leveraging their broad domain knowledge across various tasks.\nHowever, they often need many iterations of trial-and-error to generate\neffective reward functions. This process is costly because evaluating every\nsampled reward function requires completing the full policy optimization\nprocess for each function. In this paper, we introduce an LLM-driven reward\ngeneration framework that is able to produce state-of-the-art policies on the\nchallenging Bi-DexHands benchmark with 20x fewer reward function samples than\nthe prior state-of-the-art work. Our key insight is that we reduce the problem\nof generating task-specific rewards to the problem of coarsely estimating task\nprogress. Our two-step solution leverages the task domain knowledge and the\ncode synthesis abilities of LLMs to author progress functions that estimate\ntask progress from a given state. Then, we use this notion of progress to\ndiscretize states, and generate count-based intrinsic rewards using the\nlow-dimensional state space. We show that the combination of LLM-generated\nprogress functions and count-based intrinsic rewards is essential for our\nperformance gains, while alternatives such as generic hash-based counts or\nusing progress directly as a reward function fall short.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09187v2",
    "published_date": "2024-10-11 18:41:15 UTC",
    "updated_date": "2024-10-25 17:37:59 UTC"
  },
  {
    "arxiv_id": "2410.09186v2",
    "title": "Learning Algorithms Made Simple",
    "authors": [
      "Noorbakhsh Amiri Golilarz",
      "Elias Hossain",
      "Abdoljalil Addeh",
      "Keyan Alexander Rahimi"
    ],
    "abstract": "In this paper, we discuss learning algorithms and their importance in\ndifferent types of applications which includes training to identify important\npatterns and features in a straightforward, easy-to-understand manner. We will\nreview the main concepts of artificial intelligence (AI), machine learning\n(ML), deep learning (DL), and hybrid models. Some important subsets of Machine\nLearning algorithms such as supervised, unsupervised, and reinforcement\nlearning are also discussed in this paper. These techniques can be used for\nsome important tasks like prediction, classification, and segmentation.\nConvolutional Neural Networks (CNNs) are used for image and video processing\nand many more applications. We dive into the architecture of CNNs and how to\nintegrate CNNs with ML algorithms to build hybrid models. This paper explores\nthe vulnerability of learning algorithms to noise, leading to\nmisclassification. We further discuss the integration of learning algorithms\nwith Large Language Models (LLM) to generate coherent responses applicable to\nmany domains such as healthcare, marketing, and finance by learning important\npatterns from large volumes of data. Furthermore, we discuss the next\ngeneration of learning algorithms and how we may have an unified Adaptive and\nDynamic Network to perform important tasks. Overall, this article provides\nbrief overview of learning algorithms, exploring their current state,\napplications and future direction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09186v2",
    "published_date": "2024-10-11 18:39:25 UTC",
    "updated_date": "2025-05-08 19:38:13 UTC"
  },
  {
    "arxiv_id": "2410.09181v1",
    "title": "Can a large language model be a gaslighter?",
    "authors": [
      "Wei Li",
      "Luyao Zhu",
      "Yang Song",
      "Ruixi Lin",
      "Rui Mao",
      "Yang You"
    ],
    "abstract": "Large language models (LLMs) have gained human trust due to their\ncapabilities and helpfulness. However, this in turn may allow LLMs to affect\nusers' mindsets by manipulating language. It is termed as gaslighting, a\npsychological effect. In this work, we aim to investigate the vulnerability of\nLLMs under prompt-based and fine-tuning-based gaslighting attacks. Therefore,\nwe propose a two-stage framework DeepCoG designed to: 1) elicit gaslighting\nplans from LLMs with the proposed DeepGaslighting prompting template, and 2)\nacquire gaslighting conversations from LLMs through our Chain-of-Gaslighting\nmethod. The gaslighting conversation dataset along with a corresponding safe\ndataset is applied to fine-tuning-based attacks on open-source LLMs and\nanti-gaslighting safety alignment on these LLMs. Experiments demonstrate that\nboth prompt-based and fine-tuning-based attacks transform three open-source\nLLMs into gaslighters. In contrast, we advanced three safety alignment\nstrategies to strengthen (by 12.05%) the safety guardrail of LLMs. Our safety\nalignment strategies have minimal impacts on the utility of LLMs. Empirical\nstudies indicate that an LLM may be a potential gaslighter, even if it passed\nthe harmfulness test on general dangerous queries.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "10/26 (Main Body/Total), 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09181v1",
    "published_date": "2024-10-11 18:35:27 UTC",
    "updated_date": "2024-10-11 18:35:27 UTC"
  },
  {
    "arxiv_id": "2410.09173v1",
    "title": "Resource-Constrained Heuristic for Max-SAT",
    "authors": [
      "Brian Matejek",
      "Daniel Elenius",
      "Cale Gentry",
      "David Stoker",
      "Adam Cobb"
    ],
    "abstract": "We propose a resource-constrained heuristic for instances of Max-SAT that\niteratively decomposes a larger problem into smaller subcomponents that can be\nsolved by optimized solvers and hardware. The unconstrained outer loop\nmaintains the state space of a given problem and selects a subset of the SAT\nvariables for optimization independent of previous calls. The\nresource-constrained inner loop maximizes the number of satisfiable clauses in\nthe \"sub-SAT\" problem. Our outer loop is agnostic to the mechanisms of the\ninner loop, allowing for the use of traditional solvers for the optimization\nstep. However, we can also transform the selected \"sub-SAT\" problem into a\nquadratic unconstrained binary optimization (QUBO) one and use specialized\nhardware for optimization. In contrast to existing solutions that convert a SAT\ninstance into a QUBO one before decomposition, we choose a subset of the SAT\nvariables before QUBO optimization. We analyze a set of variable selection\nmethods, including a novel graph-based method that exploits the structure of a\ngiven SAT instance. The number of QUBO variables needed to encode a (sub-)SAT\nproblem varies, so we additionally learn a model that predicts the size of\nsub-SAT problems that will fit a fixed-size QUBO solver. We empirically\ndemonstrate our results on a set of randomly generated Max-SAT instances as\nwell as real world examples from the Max-SAT evaluation benchmarks and\noutperform existing QUBO decomposer solutions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09173v1",
    "published_date": "2024-10-11 18:20:08 UTC",
    "updated_date": "2024-10-11 18:20:08 UTC"
  },
  {
    "arxiv_id": "2410.12857v1",
    "title": "Enterprise Benchmarks for Large Language Model Evaluation",
    "authors": [
      "Bing Zhang",
      "Mikio Takeuchi",
      "Ryo Kawahara",
      "Shubhi Asthana",
      "Md. Maruf Hossain",
      "Guang-Jie Ren",
      "Kate Soule",
      "Yada Zhu"
    ],
    "abstract": "The advancement of large language models (LLMs) has led to a greater\nchallenge of having a rigorous and systematic evaluation of complex tasks\nperformed, especially in enterprise applications. Therefore, LLMs need to be\nable to benchmark enterprise datasets for various tasks. This work presents a\nsystematic exploration of benchmarking strategies tailored to LLM evaluation,\nfocusing on the utilization of domain-specific datasets and consisting of a\nvariety of NLP tasks. The proposed evaluation framework encompasses 25 publicly\navailable datasets from diverse enterprise domains like financial services,\nlegal, cyber security, and climate and sustainability. The diverse performance\nof 13 models across different enterprise tasks highlights the importance of\nselecting the right model based on the specific requirements of each task. Code\nand prompts are available on GitHub.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12857v1",
    "published_date": "2024-10-11 18:19:05 UTC",
    "updated_date": "2024-10-11 18:19:05 UTC"
  },
  {
    "arxiv_id": "2410.09047v1",
    "title": "Unraveling and Mitigating Safety Alignment Degradation of Vision-Language Models",
    "authors": [
      "Qin Liu",
      "Chao Shang",
      "Ling Liu",
      "Nikolaos Pappas",
      "Jie Ma",
      "Neha Anna John",
      "Srikanth Doss",
      "Lluis Marquez",
      "Miguel Ballesteros",
      "Yassine Benajiba"
    ],
    "abstract": "The safety alignment ability of Vision-Language Models (VLMs) is prone to be\ndegraded by the integration of the vision module compared to its LLM backbone.\nWe investigate this phenomenon, dubbed as ''safety alignment degradation'' in\nthis paper, and show that the challenge arises from the representation gap that\nemerges when introducing vision modality to VLMs. In particular, we show that\nthe representations of multi-modal inputs shift away from that of text-only\ninputs which represent the distribution that the LLM backbone is optimized for.\nAt the same time, the safety alignment capabilities, initially developed within\nthe textual embedding space, do not successfully transfer to this new\nmulti-modal representation space. To reduce safety alignment degradation, we\nintroduce Cross-Modality Representation Manipulation (CMRM), an inference time\nrepresentation intervention method for recovering the safety alignment ability\nthat is inherent in the LLM backbone of VLMs, while simultaneously preserving\nthe functional capabilities of VLMs. The empirical results show that our\nframework significantly recovers the alignment ability that is inherited from\nthe LLM backbone with minimal impact on the fluency and linguistic capabilities\nof pre-trained VLMs even without additional training. Specifically, the unsafe\nrate of LLaVA-7B on multi-modal input can be reduced from 61.53% to as low as\n3.15% with only inference-time intervention.\n  WARNING: This paper contains examples of toxic or harmful language.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2410.09047v1",
    "published_date": "2024-10-11 17:59:31 UTC",
    "updated_date": "2024-10-11 17:59:31 UTC"
  },
  {
    "arxiv_id": "2410.09043v2",
    "title": "Transforming In-Vehicle Network Intrusion Detection: VAE-based Knowledge Distillation Meets Explainable AI",
    "authors": [
      "Muhammet Anil Yagiz",
      "Pedram MohajerAnsari",
      "Mert D. Pese",
      "Polat Goktas"
    ],
    "abstract": "In the evolving landscape of autonomous vehicles, ensuring robust in-vehicle\nnetwork (IVN) security is paramount. This paper introduces an advanced\nintrusion detection system (IDS) called KD-XVAE that uses a Variational\nAutoencoder (VAE)-based knowledge distillation approach to enhance both\nperformance and efficiency. Our model significantly reduces complexity,\noperating with just 1669 parameters and achieving an inference time of 0.3 ms\nper batch, making it highly suitable for resource-constrained automotive\nenvironments. Evaluations in the HCRL Car-Hacking dataset demonstrate\nexceptional capabilities, attaining perfect scores (Recall, Precision, F1 Score\nof 100%, and FNR of 0%) under multiple attack types, including DoS, Fuzzing,\nGear Spoofing, and RPM Spoofing. Comparative analysis on the CICIoV2024 dataset\nfurther underscores its superiority over traditional machine learning models,\nachieving perfect detection metrics. We furthermore integrate Explainable AI\n(XAI) techniques to ensure transparency in the model's decisions. The VAE\ncompresses the original feature space into a latent space, on which the\ndistilled model is trained. SHAP(SHapley Additive exPlanations) values provide\ninsights into the importance of each latent dimension, mapped back to original\nfeatures for intuitive understanding. Our paper advances the field by\nintegrating state-of-the-art techniques, addressing critical challenges in the\ndeployment of efficient, trustworthy, and reliable IDSes for autonomous\nvehicles, ensuring enhanced protection against emerging cyber threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09043v2",
    "published_date": "2024-10-11 17:57:16 UTC",
    "updated_date": "2024-10-15 16:29:55 UTC"
  },
  {
    "arxiv_id": "2410.09141v1",
    "title": "ACER: Automatic Language Model Context Extension via Retrieval",
    "authors": [
      "Luyu Gao",
      "Yunyi Zhang",
      "Jamie Callan"
    ],
    "abstract": "Long-context modeling is one of the critical capabilities of language AI for\ndigesting and reasoning over complex information pieces. In practice,\nlong-context capabilities are typically built into a pre-trained language\nmodel~(LM) through a carefully designed context extension stage, with the goal\nof producing generalist long-context capabilities. In our preliminary\nexperiments, however, we discovered that the current open-weight generalist\nlong-context models are still lacking in practical long-context processing\ntasks. While this means perfectly effective long-context modeling demands\ntask-specific data, the cost can be prohibitive. In this paper, we draw\ninspiration from how humans process a large body of information: a lossy\n\\textbf{retrieval} stage ranks a large set of documents while the reader ends\nup reading deeply only the top candidates. We build an \\textbf{automatic} data\nsynthesis pipeline that mimics this process using short-context LMs. The\nshort-context LMs are further tuned using these self-generated data to obtain\ntask-specific long-context capabilities. Similar to how pre-training learns\nfrom imperfect data, we hypothesize and further demonstrate that the\nshort-context model can bootstrap over the synthetic data, outperforming not\nonly long-context generalist models but also the retrieval and read pipeline\nused to synthesize the training data in real-world tasks such as long-context\nretrieval augmented generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09141v1",
    "published_date": "2024-10-11 17:57:06 UTC",
    "updated_date": "2024-10-11 17:57:06 UTC"
  },
  {
    "arxiv_id": "2410.09038v2",
    "title": "SimpleStrat: Diversifying Language Model Generation with Stratification",
    "authors": [
      "Justin Wong",
      "Yury Orlovskiy",
      "Michael Luo",
      "Sanjit A. Seshia",
      "Joseph E. Gonzalez"
    ],
    "abstract": "Generating diverse responses from large language models (LLMs) is crucial for\napplications such as planning/search and synthetic data generation, where\ndiversity provides distinct answers across generations. Prior approaches rely\non increasing temperature to increase diversity. However, contrary to popular\nbelief, we show not only does this approach produce lower quality individual\ngenerations as temperature increases, but it depends on model's next-token\nprobabilities being similar to the true distribution of answers. We propose\nSimpleStrat, an alternative approach that uses the language model itself to\npartition the space into strata. At inference, a random stratum is selected and\na sample drawn from within the strata. To measure diversity, we introduce\nCoverageQA, a dataset of underspecified questions with multiple equally\nplausible answers, and assess diversity by measuring KL Divergence between the\noutput distribution and uniform distribution over valid ground truth answers.\nAs computing probability per response/solution for proprietary models is\ninfeasible, we measure recall on ground truth solutions. Our evaluation show\nusing SimpleStrat achieves higher recall by 0.05 compared to GPT-4o and 0.36\naverage reduction in KL Divergence compared to Llama 3.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09038v2",
    "published_date": "2024-10-11 17:54:14 UTC",
    "updated_date": "2024-10-14 17:32:26 UTC"
  },
  {
    "arxiv_id": "2410.09037v1",
    "title": "Mentor-KD: Making Small Language Models Better Multi-step Reasoners",
    "authors": [
      "Hojae Lee",
      "Junho Kim",
      "SangKeun Lee"
    ],
    "abstract": "Large Language Models (LLMs) have displayed remarkable performances across\nvarious complex tasks by leveraging Chain-of-Thought (CoT) prompting. Recently,\nstudies have proposed a Knowledge Distillation (KD) approach, reasoning\ndistillation, which transfers such reasoning ability of LLMs through\nfine-tuning language models of multi-step rationales generated by LLM teachers.\nHowever, they have inadequately considered two challenges regarding\ninsufficient distillation sets from the LLM teacher model, in terms of 1) data\nquality and 2) soft label provision. In this paper, we propose Mentor-KD, which\neffectively distills the multi-step reasoning capability of LLMs to smaller LMs\nwhile addressing the aforementioned challenges. Specifically, we exploit a\nmentor, intermediate-sized task-specific fine-tuned model, to augment\nadditional CoT annotations and provide soft labels for the student model during\nreasoning distillation. We conduct extensive experiments and confirm\nMentor-KD's effectiveness across various models and complex reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.09037v1",
    "published_date": "2024-10-11 17:53:27 UTC",
    "updated_date": "2024-10-11 17:53:27 UTC"
  },
  {
    "arxiv_id": "2410.09034v1",
    "title": "PEAR: A Robust and Flexible Automation Framework for Ptychography Enabled by Multiple Large Language Model Agents",
    "authors": [
      "Xiangyu Yin",
      "Chuqiao Shi",
      "Yimo Han",
      "Yi Jiang"
    ],
    "abstract": "Ptychography is an advanced computational imaging technique in X-ray and\nelectron microscopy. It has been widely adopted across scientific research\nfields, including physics, chemistry, biology, and materials science, as well\nas in industrial applications such as semiconductor characterization. In\npractice, obtaining high-quality ptychographic images requires simultaneous\noptimization of numerous experimental and algorithmic parameters.\nTraditionally, parameter selection often relies on trial and error, leading to\nlow-throughput workflows and potential human bias. In this work, we develop the\n\"Ptychographic Experiment and Analysis Robot\" (PEAR), a framework that\nleverages large language models (LLMs) to automate data analysis in\nptychography. To ensure high robustness and accuracy, PEAR employs multiple LLM\nagents for tasks including knowledge retrieval, code generation, parameter\nrecommendation, and image reasoning. Our study demonstrates that PEAR's\nmulti-agent design significantly improves the workflow success rate, even with\nsmaller open-weight models such as LLaMA 3.1 8B. PEAR also supports various\nautomation levels and is designed to work with customized local knowledge\nbases, ensuring flexibility and adaptability across different research\nenvironments.",
    "categories": [
      "cs.CE",
      "cs.AI",
      "cs.CL",
      "cs.MA"
    ],
    "primary_category": "cs.CE",
    "comment": "18 pages, 5 figures, technical preview report",
    "pdf_url": "http://arxiv.org/pdf/2410.09034v1",
    "published_date": "2024-10-11 17:50:59 UTC",
    "updated_date": "2024-10-11 17:50:59 UTC"
  },
  {
    "arxiv_id": "2410.09024v3",
    "title": "AgentHarm: A Benchmark for Measuring Harmfulness of LLM Agents",
    "authors": [
      "Maksym Andriushchenko",
      "Alexandra Souly",
      "Mateusz Dziemian",
      "Derek Duenas",
      "Maxwell Lin",
      "Justin Wang",
      "Dan Hendrycks",
      "Andy Zou",
      "Zico Kolter",
      "Matt Fredrikson",
      "Eric Winsor",
      "Jerome Wynne",
      "Yarin Gal",
      "Xander Davies"
    ],
    "abstract": "The robustness of LLMs to jailbreak attacks, where users design prompts to\ncircumvent safety measures and misuse model capabilities, has been studied\nprimarily for LLMs acting as simple chatbots. Meanwhile, LLM agents -- which\nuse external tools and can execute multi-stage tasks -- may pose a greater risk\nif misused, but their robustness remains underexplored. To facilitate research\non LLM agent misuse, we propose a new benchmark called AgentHarm. The benchmark\nincludes a diverse set of 110 explicitly malicious agent tasks (440 with\naugmentations), covering 11 harm categories including fraud, cybercrime, and\nharassment. In addition to measuring whether models refuse harmful agentic\nrequests, scoring well on AgentHarm requires jailbroken agents to maintain\ntheir capabilities following an attack to complete a multi-step task. We\nevaluate a range of leading LLMs, and find (1) leading LLMs are surprisingly\ncompliant with malicious agent requests without jailbreaking, (2) simple\nuniversal jailbreak templates can be adapted to effectively jailbreak agents,\nand (3) these jailbreaks enable coherent and malicious multi-step agent\nbehavior and retain model capabilities. To enable simple and reliable\nevaluation of attacks and defenses for LLM-based agents, we publicly release\nAgentHarm at https://huggingface.co/datasets/ai-safety-institute/AgentHarm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.09024v3",
    "published_date": "2024-10-11 17:39:22 UTC",
    "updated_date": "2025-04-18 14:30:31 UTC"
  },
  {
    "arxiv_id": "2410.09012v2",
    "title": "Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models",
    "authors": [
      "Hao Li",
      "Cor-Paul Bezemer",
      "Ahmed E. Hassan"
    ],
    "abstract": "Foundation models (FMs) such as large language models (LLMs) have\nsignificantly impacted many fields, including software engineering (SE). The\ninteraction between SE and FMs has led to the integration of FMs into SE\npractices (FM4SE) and the application of SE methodologies to FMs (SE4FM). While\nseveral literature surveys exist on academic contributions to these trends, we\nare the first to provide a practitioner's view. We analyze 155 FM4SE and 997\nSE4FM blog posts from leading technology companies, leveraging an FM-powered\nsurveying approach to systematically label and summarize the discussed\nactivities and tasks. We observed that while code generation is the most\nprominent FM4SE task, FMs are leveraged for many other SE activities such as\ncode understanding, summarization, and API recommendation. The majority of blog\nposts on SE4FM are about model deployment & operation, and system architecture\n& orchestration. Although the emphasis is on cloud deployments, there is a\ngrowing interest in compressing FMs and deploying them on smaller devices such\nas edge or mobile devices. We outline eight future research directions inspired\nby our gained insights, aiming to bridge the gap between academic findings and\nreal-world applications. Our study not only enriches the body of knowledge on\npractical applications of FM4SE and SE4FM but also demonstrates the utility of\nFMs as a powerful and efficient approach in conducting literature surveys\nwithin technical and grey literature domains. Our dataset, results, code and\nused prompts can be found in our online replication package at\nhttps://github.com/SAILResearch/fmse-blogs.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "ICSE-SEIP 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.09012v2",
    "published_date": "2024-10-11 17:27:04 UTC",
    "updated_date": "2025-01-06 20:49:13 UTC"
  },
  {
    "arxiv_id": "2410.12856v1",
    "title": "Optimized Biomedical Question-Answering Services with LLM and Multi-BERT Integration",
    "authors": [
      "Cheng Qian",
      "Xianglong Shi",
      "Shanshan Yao",
      "Yichen Liu",
      "Fengming Zhou",
      "Zishu Zhang",
      "Junaid Akram",
      "Ali Braytee",
      "Ali Anaissi"
    ],
    "abstract": "We present a refined approach to biomedical question-answering (QA) services\nby integrating large language models (LLMs) with Multi-BERT configurations. By\nenhancing the ability to process and prioritize vast amounts of complex\nbiomedical data, this system aims to support healthcare professionals in\ndelivering better patient outcomes and informed decision-making. Through\ninnovative use of BERT and BioBERT models, combined with a multi-layer\nperceptron (MLP) layer, we enable more specialized and efficient responses to\nthe growing demands of the healthcare sector. Our approach not only addresses\nthe challenge of overfitting by freezing one BERT model while training another\nbut also improves the overall adaptability of QA services. The use of extensive\ndatasets, such as BioASQ and BioMRC, demonstrates the system's ability to\nsynthesize critical information. This work highlights how advanced language\nmodels can make a tangible difference in healthcare, providing reliable and\nresponsive tools for professionals to manage complex information, ultimately\nserving the broader goal of improved care and data-driven insights.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 12 figures, accepted and to be published in the proceedings\n  of 2024 IEEE International Conference on Data Mining Workshops (ICDMW)",
    "pdf_url": "http://arxiv.org/pdf/2410.12856v1",
    "published_date": "2024-10-11 17:13:31 UTC",
    "updated_date": "2024-10-11 17:13:31 UTC"
  },
  {
    "arxiv_id": "2410.08997v2",
    "title": "Hierarchical Universal Value Function Approximators",
    "authors": [
      "Rushiv Arora"
    ],
    "abstract": "There have been key advancements to building universal approximators for\nmulti-goal collections of reinforcement learning value functions -- key\nelements in estimating long-term returns of states in a parameterized manner.\nWe extend this to hierarchical reinforcement learning, using the options\nframework, by introducing hierarchical universal value function approximators\n(H-UVFAs). This allows us to leverage the added benefits of scaling, planning,\nand generalization expected in temporal abstraction settings. We develop\nsupervised and reinforcement learning methods for learning embeddings of the\nstates, goals, options, and actions in the two hierarchical value functions:\n$Q(s, g, o; \\theta)$ and $Q(s, g, o, a; \\theta)$. Finally we demonstrate\ngeneralization of the HUVFAs and show they outperform corresponding UVFAs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 11 figures, 3 appendices. Currently under review",
    "pdf_url": "http://arxiv.org/pdf/2410.08997v2",
    "published_date": "2024-10-11 17:09:26 UTC",
    "updated_date": "2024-10-27 16:37:44 UTC"
  },
  {
    "arxiv_id": "2410.08993v1",
    "title": "The structure of the token space for large language models",
    "authors": [
      "Michael Robinson",
      "Sourya Dey",
      "Shauna Sweet"
    ],
    "abstract": "Large language models encode the correlational structure present in natural\nlanguage by fitting segments of utterances (tokens) into a high dimensional\nambient latent space upon which the models then operate. We assert that in\norder to develop a foundational, first-principles understanding of the behavior\nand limitations of large language models, it is crucial to understand the\ntopological and geometric structure of this token subspace. In this article, we\npresent estimators for the dimension and Ricci scalar curvature of the token\nsubspace, and apply it to three open source large language models of moderate\nsize: GPT2, LLEMMA7B, and MISTRAL7B. In all three models, using these\nmeasurements, we find that the token subspace is not a manifold, but is instead\na stratified manifold, where on each of the individual strata, the Ricci\ncurvature is significantly negative. We additionally find that the dimension\nand curvature correlate with generative fluency of the models, which suggest\nthat these findings have implications for model behavior.",
    "categories": [
      "math.DG",
      "cs.AI",
      "53Z50, 58Z05"
    ],
    "primary_category": "math.DG",
    "comment": "33 pages, 22 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.08993v1",
    "published_date": "2024-10-11 17:07:15 UTC",
    "updated_date": "2024-10-11 17:07:15 UTC"
  },
  {
    "arxiv_id": "2410.08989v2",
    "title": "Zeroth-Order Fine-Tuning of LLMs in Random Subspaces",
    "authors": [
      "Ziming Yu",
      "Pan Zhou",
      "Sike Wang",
      "Jia Li",
      "Hua Huang"
    ],
    "abstract": "Fine-tuning Large Language Models (LLMs) has proven effective for a variety\nof downstream tasks. However, as LLMs grow in size, the memory demands for\nbackpropagation become increasingly prohibitive. Zeroth-order (ZO) optimization\nmethods offer a memory-efficient alternative by using forward passes to\nestimate gradients, but the variance of gradient estimates typically scales\nlinearly with the model's parameter dimension$\\unicode{x2013}$a significant\nissue for LLMs. In this paper, we propose the random Subspace Zeroth-order\n(SubZero) optimization to address the challenges posed by LLMs' high\ndimensionality. We introduce a low-rank perturbation tailored for LLMs that\nsignificantly reduces memory consumption while improving training performance.\nAdditionally, we prove that our gradient estimation closely approximates the\nbackpropagation gradient, exhibits lower variance than traditional ZO methods,\nand ensures convergence when combined with SGD. Experimental results show that\nSubZero enhances fine-tuning performance and achieves faster convergence\ncompared to standard ZO approaches like MeZO across various language modeling\ntasks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08989v2",
    "published_date": "2024-10-11 17:01:43 UTC",
    "updated_date": "2024-11-22 15:08:59 UTC"
  },
  {
    "arxiv_id": "2410.08985v2",
    "title": "Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective",
    "authors": [
      "Bo Ni",
      "Yu Wang",
      "Lu Cheng",
      "Erik Blasch",
      "Tyler Derr"
    ],
    "abstract": "Recently, Knowledge Graphs (KGs) have been successfully coupled with Large\nLanguage Models (LLMs) to mitigate their hallucinations and enhance their\nreasoning capability, such as in KG-based retrieval-augmented frameworks.\nHowever, current KG-LLM frameworks lack rigorous uncertainty estimation,\nlimiting their reliable deployment in high-stakes applications. Directly\nincorporating uncertainty quantification into KG-LLM frameworks presents\nchallenges due to their complex architectures and the intricate interactions\nbetween the knowledge graph and language model components. To address this gap,\nwe propose a new trustworthy KG-LLM framework, Uncertainty Aware\nKnowledge-Graph Reasoning (UAG), which incorporates uncertainty quantification\ninto the KG-LLM framework. We design an uncertainty-aware multi-step reasoning\nframework that leverages conformal prediction to provide a theoretical\nguarantee on the prediction set. To manage the error rate of the multi-step\nprocess, we additionally introduce an error rate control module to adjust the\nerror rate within the individual components. Extensive experiments show that\nour proposed UAG can achieve any pre-defined coverage rate while reducing the\nprediction set/interval size by 40% on average over the baselines.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08985v2",
    "published_date": "2024-10-11 16:57:30 UTC",
    "updated_date": "2024-10-20 19:35:09 UTC"
  },
  {
    "arxiv_id": "2410.08979v3",
    "title": "Overcoming Slow Decision Frequencies in Continuous Control: Model-Based Sequence Reinforcement Learning for Model-Free Control",
    "authors": [
      "Devdhar Patel",
      "Hava Siegelmann"
    ],
    "abstract": "Reinforcement learning (RL) is rapidly reaching and surpassing human-level\ncontrol capabilities. However, state-of-the-art RL algorithms often require\ntimesteps and reaction times significantly faster than human capabilities,\nwhich is impractical in real-world settings and typically necessitates\nspecialized hardware. We introduce Sequence Reinforcement Learning (SRL), an RL\nalgorithm designed to produce a sequence of actions for a given input state,\nenabling effective control at lower decision frequencies. SRL addresses the\nchallenges of learning action sequences by employing both a model and an\nactor-critic architecture operating at different temporal scales. We propose a\n\"temporal recall\" mechanism, where the critic uses the model to estimate\nintermediate states between primitive actions, providing a learning signal for\neach individual action within the sequence. Once training is complete, the\nactor can generate action sequences independently of the model, achieving\nmodel-free control at a slower frequency. We evaluate SRL on a suite of\ncontinuous control tasks, demonstrating that it achieves performance comparable\nto state-of-the-art algorithms while significantly reducing actor sample\ncomplexity. To better assess performance across varying decision frequencies,\nwe introduce the Frequency-Averaged Score (FAS) metric. Our results show that\nSRL significantly outperforms traditional RL algorithms in terms of FAS, making\nit particularly suitable for applications requiring variable decision\nfrequencies. Furthermore, we compare SRL with model-based online planning,\nshowing that SRL achieves comparable FAS while leveraging the same model during\ntraining that online planners use for planning. Lastly, we highlight the\nbiological relevance of SRL, showing that it replicates the \"action chunking\"\nbehavior observed in the basal ganglia, offering insights into brain-inspired\ncontrol mechanisms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.08979v3",
    "published_date": "2024-10-11 16:54:07 UTC",
    "updated_date": "2025-03-04 03:11:25 UTC"
  },
  {
    "arxiv_id": "2410.08976v2",
    "title": "Learning Representations of Instruments for Partial Identification of Treatment Effects",
    "authors": [
      "Jonas Schweisthal",
      "Dennis Frauen",
      "Maresa Schröder",
      "Konstantin Hess",
      "Niki Kilbertus",
      "Stefan Feuerriegel"
    ],
    "abstract": "Reliable estimation of treatment effects from observational data is important\nin many disciplines such as medicine. However, estimation is challenging when\nunconfoundedness as a standard assumption in the causal inference literature is\nviolated. In this work, we leverage arbitrary (potentially high-dimensional)\ninstruments to estimate bounds on the conditional average treatment effect\n(CATE). Our contributions are three-fold: (1) We propose a novel approach for\npartial identification through a mapping of instruments to a discrete\nrepresentation space so that we yield valid bounds on the CATE. This is crucial\nfor reliable decision-making in real-world applications. (2) We derive a\ntwo-step procedure that learns tight bounds using a tailored neural\npartitioning of the latent instrument space. As a result, we avoid instability\nissues due to numerical approximations or adversarial training. Furthermore,\nour procedure aims to reduce the estimation variance in finite-sample settings\nto yield more reliable estimates. (3) We show theoretically that our procedure\nobtains valid bounds while reducing estimation variance. We further perform\nextensive experiments to demonstrate the effectiveness across various settings.\nOverall, our procedure offers a novel path for practitioners to make use of\npotentially high-dimensional instruments (e.g., as in Mendelian randomization).",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08976v2",
    "published_date": "2024-10-11 16:48:32 UTC",
    "updated_date": "2024-10-14 08:04:01 UTC"
  },
  {
    "arxiv_id": "2410.08972v1",
    "title": "ALVIN: Active Learning Via INterpolation",
    "authors": [
      "Michalis Korakakis",
      "Andreas Vlachos",
      "Adrian Weller"
    ],
    "abstract": "Active Learning aims to minimize annotation effort by selecting the most\nuseful instances from a pool of unlabeled data. However, typical active\nlearning methods overlook the presence of distinct example groups within a\nclass, whose prevalence may vary, e.g., in occupation classification datasets\ncertain demographics are disproportionately represented in specific classes.\nThis oversight causes models to rely on shortcuts for predictions, i.e.,\nspurious correlations between input attributes and labels occurring in\nwell-represented groups. To address this issue, we propose Active Learning Via\nINterpolation (ALVIN), which conducts intra-class interpolations between\nexamples from under-represented and well-represented groups to create anchors,\ni.e., artificial points situated between the example groups in the\nrepresentation space. By selecting instances close to the anchors for\nannotation, ALVIN identifies informative examples exposing the model to regions\nof the representation space that counteract the influence of shortcuts.\nCrucially, since the model considers these examples to be of high certainty,\nthey are likely to be ignored by typical active learning methods. Experimental\nresults on six datasets encompassing sentiment analysis, natural language\ninference, and paraphrase detection demonstrate that ALVIN outperforms\nstate-of-the-art active learning methods in both in-distribution and\nout-of-distribution generalization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to EMNLP 2024 (Main)",
    "pdf_url": "http://arxiv.org/pdf/2410.08972v1",
    "published_date": "2024-10-11 16:44:39 UTC",
    "updated_date": "2024-10-11 16:44:39 UTC"
  },
  {
    "arxiv_id": "2410.08970v2",
    "title": "NoVo: Norm Voting off Hallucinations with Attention Heads in Large Language Models",
    "authors": [
      "Zheng Yi Ho",
      "Siyuan Liang",
      "Sen Zhang",
      "Yibing Zhan",
      "Dacheng Tao"
    ],
    "abstract": "Hallucinations in Large Language Models (LLMs) remain a major obstacle,\nparticularly in high-stakes applications where factual accuracy is critical.\nWhile representation editing and reading methods have made strides in reducing\nhallucinations, their heavy reliance on specialised tools and training on\nin-domain samples, makes them difficult to scale and prone to overfitting. This\nlimits their accuracy gains and generalizability to diverse datasets. This\npaper presents a lightweight method, Norm Voting (NoVo), which harnesses the\nuntapped potential of attention head norms to dramatically enhance factual\naccuracy in zero-shot multiple-choice questions (MCQs). NoVo begins by\nautomatically selecting truth-correlated head norms with an efficient,\ninference-only algorithm using only 30 random samples, allowing NoVo to\neffortlessly scale to diverse datasets. Afterwards, selected head norms are\nemployed in a simple voting algorithm, which yields significant gains in\nprediction accuracy. On TruthfulQA MC1, NoVo surpasses the current\nstate-of-the-art and all previous methods by an astounding margin -- at least\n19 accuracy points. NoVo demonstrates exceptional generalization to 20 diverse\ndatasets, with significant gains in over 90\\% of them, far exceeding all\ncurrent representation editing and reading methods. NoVo also reveals promising\ngains to finetuning strategies and building textual adversarial defence. NoVo's\neffectiveness with head norms opens new frontiers in LLM interpretability,\nrobustness and reliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08970v2",
    "published_date": "2024-10-11 16:40:03 UTC",
    "updated_date": "2024-10-29 05:23:53 UTC"
  },
  {
    "arxiv_id": "2410.08968v2",
    "title": "Controllable Safety Alignment: Inference-Time Adaptation to Diverse Safety Requirements",
    "authors": [
      "Jingyu Zhang",
      "Ahmed Elgohary",
      "Ahmed Magooda",
      "Daniel Khashabi",
      "Benjamin Van Durme"
    ],
    "abstract": "The current paradigm for safety alignment of large language models (LLMs)\nfollows a one-size-fits-all approach: the model refuses to interact with any\ncontent deemed unsafe by the model provider. This approach lacks flexibility in\nthe face of varying social norms across cultures and regions. In addition,\nusers may have diverse safety needs, making a model with static safety\nstandards too restrictive to be useful, as well as too costly to be re-aligned.\n  We propose Controllable Safety Alignment (CoSA), a framework designed to\nadapt models to diverse safety requirements without re-training. Instead of\naligning a fixed model, we align models to follow safety configs -- free-form\nnatural language descriptions of the desired safety behaviors -- that are\nprovided as part of the system prompt. To adjust model safety behavior,\nauthorized users only need to modify such safety configs at inference time. To\nenable that, we propose CoSAlign, a data-centric method for aligning LLMs to\neasily adapt to diverse safety configs. Furthermore, we devise a novel\ncontrollability evaluation protocol that considers both helpfulness and\nconfigured safety, summarizing them into CoSA-Score, and construct CoSApien, a\nhuman-authored benchmark that consists of real-world LLM use cases with diverse\nsafety requirements and corresponding evaluation prompts. We show that CoSAlign\nleads to substantial gains of controllability over strong baselines including\nin-context alignment. Our framework encourages better representation and\nadaptation to pluralistic human values in LLMs, and thereby increasing their\npracticality.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "ICLR 2025 camera ready",
    "pdf_url": "http://arxiv.org/pdf/2410.08968v2",
    "published_date": "2024-10-11 16:38:01 UTC",
    "updated_date": "2025-03-03 22:10:04 UTC"
  },
  {
    "arxiv_id": "2410.08964v3",
    "title": "Language Imbalance Driven Rewarding for Multilingual Self-improving",
    "authors": [
      "Wen Yang",
      "Junhong Wu",
      "Chen Wang",
      "Chengqing Zong",
      "Jiajun Zhang"
    ],
    "abstract": "Large Language Models (LLMs) have achieved state-of-the-art performance\nacross numerous tasks. However, these advancements have predominantly benefited\n\"first-class\" languages such as English and Chinese, leaving many other\nlanguages underrepresented. This imbalance, while limiting broader\napplications, generates a natural preference ranking between languages,\noffering an opportunity to bootstrap the multilingual capabilities of LLM in a\nself-improving manner. Thus, we propose $\\textit{Language Imbalance Driven\nRewarding}$, where the inherent imbalance between dominant and non-dominant\nlanguages within LLMs is leveraged as a reward signal. Iterative DPO training\ndemonstrates that this approach not only enhances LLM performance in\nnon-dominant languages but also improves the dominant language's capacity,\nthereby yielding an iterative reward signal. Fine-tuning\nMeta-Llama-3-8B-Instruct over two iterations of this approach results in\ncontinuous improvements in multilingual performance across\ninstruction-following and arithmetic reasoning tasks, evidenced by an average\nimprovement of 7.46% win rate on the X-AlpacaEval leaderboard and 13.9%\naccuracy on the MGSM benchmark. This work serves as an initial exploration,\npaving the way for multilingual self-improvement of LLMs. The code is available\nat https://github.com/ZNLP/Language-Imbalance-Driven-Rewarding",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Camera ready version for ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08964v3",
    "published_date": "2024-10-11 16:32:05 UTC",
    "updated_date": "2025-02-26 12:39:40 UTC"
  },
  {
    "arxiv_id": "2410.08961v1",
    "title": "Evaluating Federated Kolmogorov-Arnold Networks on Non-IID Data",
    "authors": [
      "Arthur Mendonça Sasse",
      "Claudio Miceli de Farias"
    ],
    "abstract": "Federated Kolmogorov-Arnold Networks (F-KANs) have already been proposed, but\ntheir assessment is at an initial stage. We present a comparison between KANs\n(using B-splines and Radial Basis Functions as activation functions) and Multi-\nLayer Perceptrons (MLPs) with a similar number of parameters for 100 rounds of\nfederated learning in the MNIST classification task using non-IID partitions\nwith 100 clients. After 15 trials for each model, we show that the best\naccuracies achieved by MLPs can be achieved by Spline-KANs in half of the time\n(in rounds), with just a moderate increase in computing time.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 5 figures, for associated code see\n  https://github.com/artsasse/fedkan",
    "pdf_url": "http://arxiv.org/pdf/2410.08961v1",
    "published_date": "2024-10-11 16:30:04 UTC",
    "updated_date": "2024-10-11 16:30:04 UTC"
  },
  {
    "arxiv_id": "2410.08950v1",
    "title": "On the Adversarial Transferability of Generalized \"Skip Connections\"",
    "authors": [
      "Yisen Wang",
      "Yichuan Mo",
      "Dongxian Wu",
      "Mingjie Li",
      "Xingjun Ma",
      "Zhouchen Lin"
    ],
    "abstract": "Skip connection is an essential ingredient for modern deep models to be\ndeeper and more powerful. Despite their huge success in normal scenarios\n(state-of-the-art classification performance on natural examples), we\ninvestigate and identify an interesting property of skip connections under\nadversarial scenarios, namely, the use of skip connections allows easier\ngeneration of highly transferable adversarial examples. Specifically, in\nResNet-like models (with skip connections), we find that using more gradients\nfrom the skip connections rather than the residual modules according to a decay\nfactor during backpropagation allows one to craft adversarial examples with\nhigh transferability. The above method is termed as Skip Gradient Method (SGM).\nAlthough starting from ResNet-like models in vision domains, we further extend\nSGM to more advanced architectures, including Vision Transformers (ViTs) and\nmodels with length-varying paths and other domains, i.e. natural language\nprocessing. We conduct comprehensive transfer attacks against various models\nincluding ResNets, Transformers, Inceptions, Neural Architecture Search, and\nLarge Language Models (LLMs). We show that employing SGM can greatly improve\nthe transferability of crafted attacks in almost all cases. Furthermore,\nconsidering the big complexity for practical use, we further demonstrate that\nSGM can even improve the transferability on ensembles of models or targeted\nattacks and the stealthiness against current defenses. At last, we provide\ntheoretical explanations and empirical insights on how SGM works. Our findings\nnot only motivate new adversarial research into the architectural\ncharacteristics of models but also open up further challenges for secure model\narchitecture design. Our code is available at https://github.com/mo666666/SGM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08950v1",
    "published_date": "2024-10-11 16:17:47 UTC",
    "updated_date": "2024-10-11 16:17:47 UTC"
  },
  {
    "arxiv_id": "2410.08949v2",
    "title": "Transferable Belief Model on Quantum Circuits",
    "authors": [
      "Qianli Zhou",
      "Hao Luo",
      "Lipeng Pan",
      "Yong Deng",
      "Eloi Bosse"
    ],
    "abstract": "The transferable belief model, as a semantic interpretation of\nDempster-Shafer theory, enables agents to perform reasoning and decision making\nin imprecise and incomplete environments. The model offers distinct semantics\nfor handling unreliable testimonies, allowing for a more reasonable and general\nprocess of belief transfer compared to the Bayesian approach. However, because\nboth the belief masses and the structure of focal sets must be considered when\nupdating belief functions-leading to extra computational complexity during\nreasoning-the transferable belief model has gradually lost favor among\nresearchers in recent developments. In this paper, we implement the\ntransferable belief model on quantum circuits and demonstrate that belief\nfunctions offer a more concise and effective alternative to Bayesian approaches\nwithin the quantum computing framework. Furthermore, leveraging the unique\ncharacteristics of quantum computing, we propose several novel belief transfer\napproaches. More broadly, this paper introduces a new perspective on basic\ninformation representation for quantum AI models, suggesting that belief\nfunctions are more suitable than Bayesian approach for handling uncertainty on\nquantum circuits.",
    "categories": [
      "cs.AI",
      "quant-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08949v2",
    "published_date": "2024-10-11 16:17:20 UTC",
    "updated_date": "2024-10-17 11:52:24 UTC"
  },
  {
    "arxiv_id": "2410.08947v1",
    "title": "Meta-Transfer Learning Empowered Temporal Graph Networks for Cross-City Real Estate Appraisal",
    "authors": [
      "Weijia Zhang",
      "Jindong Han",
      "Hao Liu",
      "Wei Fan",
      "Hao Wang",
      "Hui Xiong"
    ],
    "abstract": "Real estate appraisal is important for a variety of endeavors such as real\nestate deals, investment analysis, and real property taxation. Recently, deep\nlearning has shown great promise for real estate appraisal by harnessing\nsubstantial online transaction data from web platforms. Nonetheless, deep\nlearning is data-hungry, and thus it may not be trivially applicable to\nenormous small cities with limited data. To this end, we propose Meta-Transfer\nLearning Empowered Temporal Graph Networks (MetaTransfer) to transfer valuable\nknowledge from multiple data-rich metropolises to the data-scarce city to\nimprove valuation performance. Specifically, by modeling the ever-growing real\nestate transactions with associated residential communities as a temporal event\nheterogeneous graph, we first design an Event-Triggered Temporal Graph Network\nto model the irregular spatiotemporal correlations between evolving real estate\ntransactions. Besides, we formulate the city-wide real estate appraisal as a\nmulti-task dynamic graph link label prediction problem, where the valuation of\neach community in a city is regarded as an individual task. A\nHypernetwork-Based Multi-Task Learning module is proposed to simultaneously\nfacilitate intra-city knowledge sharing between multiple communities and\ntask-specific parameters generation to accommodate the community-wise real\nestate price distribution. Furthermore, we propose a Tri-Level Optimization\nBased Meta- Learning framework to adaptively re-weight training transaction\ninstances from multiple source cities to mitigate negative transfer, and thus\nimprove the cross-city knowledge transfer effectiveness. Finally, extensive\nexperiments based on five real-world datasets demonstrate the significant\nsuperiority of MetaTransfer compared with eleven baseline algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.08947v1",
    "published_date": "2024-10-11 16:16:38 UTC",
    "updated_date": "2024-10-11 16:16:38 UTC"
  },
  {
    "arxiv_id": "2410.08948v1",
    "title": "The Dynamics of Social Conventions in LLM populations: Spontaneous Emergence, Collective Biases and Tipping Points",
    "authors": [
      "Ariel Flint Ashery",
      "Luca Maria Aiello",
      "Andrea Baronchelli"
    ],
    "abstract": "Social conventions are the foundation for social and economic life. As\nlegions of AI agents increasingly interact with each other and with humans,\ntheir ability to form shared conventions will determine how effectively they\nwill coordinate behaviors, integrate into society and influence it. Here, we\ninvestigate the dynamics of conventions within populations of Large Language\nModel (LLM) agents using simulated interactions. First, we show that globally\naccepted social conventions can spontaneously arise from local interactions\nbetween communicating LLMs. Second, we demonstrate how strong collective biases\ncan emerge during this process, even when individual agents appear to be\nunbiased. Third, we examine how minority groups of committed LLMs can drive\nsocial change by establishing new social conventions. We show that once these\nminority groups reach a critical size, they can consistently overturn\nestablished behaviors. In all cases, contrasting the experimental results with\npredictions from a minimal multi-agent model allows us to isolate the specific\nrole of LLM agents. Our results clarify how AI systems can autonomously develop\nnorms without explicit programming and have implications for designing AI\nsystems that align with human values and societal goals.",
    "categories": [
      "cs.MA",
      "cs.AI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08948v1",
    "published_date": "2024-10-11 16:16:38 UTC",
    "updated_date": "2024-10-11 16:16:38 UTC"
  },
  {
    "arxiv_id": "2410.08942v1",
    "title": "Maximizing the Potential of Synthetic Data: Insights from Random Matrix Theory",
    "authors": [
      "Aymane El Firdoussi",
      "Mohamed El Amine Seddik",
      "Soufiane Hayou",
      "Reda Alami",
      "Ahmed Alzubaidi",
      "Hakim Hacid"
    ],
    "abstract": "Synthetic data has gained attention for training large language models, but\npoor-quality data can harm performance (see, e.g., Shumailov et al. (2023);\nSeddik et al. (2024)). A potential solution is data pruning, which retains only\nhigh-quality data based on a score function (human or machine feedback).\nPrevious work Feng et al. (2024) analyzed models trained on synthetic data as\nsample size increases. We extend this by using random matrix theory to derive\nthe performance of a binary classifier trained on a mix of real and pruned\nsynthetic data in a high dimensional setting. Our findings identify conditions\nwhere synthetic data could improve performance, focusing on the quality of the\ngenerative model and verification strategy. We also show a smooth phase\ntransition in synthetic label noise, contrasting with prior sharp behavior in\ninfinite sample limits. Experiments with toy models and large language models\nvalidate our theoretical results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.ST",
      "stat.TH"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08942v1",
    "published_date": "2024-10-11 16:09:27 UTC",
    "updated_date": "2024-10-11 16:09:27 UTC"
  },
  {
    "arxiv_id": "2410.08928v2",
    "title": "Towards Multilingual LLM Evaluation for European Languages",
    "authors": [
      "Klaudia Thellmann",
      "Bernhard Stadler",
      "Michael Fromm",
      "Jasper Schulze Buschhoff",
      "Alex Jude",
      "Fabio Barth",
      "Johannes Leveling",
      "Nicolas Flores-Herr",
      "Joachim Köhler",
      "René Jäkel",
      "Mehdi Ali"
    ],
    "abstract": "The rise of Large Language Models (LLMs) has revolutionized natural language\nprocessing across numerous languages and tasks. However, evaluating LLM\nperformance in a consistent and meaningful way across multiple European\nlanguages remains challenging, especially due to the scarcity of\nlanguage-parallel multilingual benchmarks. We introduce a multilingual\nevaluation approach tailored for European languages. We employ translated\nversions of five widely-used benchmarks to assess the capabilities of 40 LLMs\nacross 21 European languages. Our contributions include examining the\neffectiveness of translated benchmarks, assessing the impact of different\ntranslation services, and offering a multilingual evaluation framework for LLMs\nthat includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC,\nEU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly\navailable to encourage further research in multilingual LLM evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08928v2",
    "published_date": "2024-10-11 15:53:24 UTC",
    "updated_date": "2024-10-17 17:58:53 UTC"
  },
  {
    "arxiv_id": "2410.08926v3",
    "title": "Zero-Shot Pupil Segmentation with SAM 2: A Case Study of Over 14 Million Images",
    "authors": [
      "Virmarie Maquiling",
      "Sean Anthony Byrne",
      "Diederick C. Niehorster",
      "Marco Carminati",
      "Enkelejda Kasneci"
    ],
    "abstract": "We explore the transformative potential of SAM 2, a vision foundation model,\nin advancing gaze estimation and eye tracking technologies. By significantly\nreducing annotation time, lowering technical barriers through its ease of\ndeployment, and enhancing segmentation accuracy, SAM 2 addresses critical\nchallenges faced by researchers and practitioners. Utilizing its zero-shot\nsegmentation capabilities with minimal user input-a single click per video-we\ntested SAM 2 on over 14 million eye images from diverse datasets, including\nvirtual reality setups and the world's largest unified dataset recorded using\nwearable eye trackers. Remarkably, in pupil segmentation tasks, SAM 2 matches\nthe performance of domain-specific models trained solely on eye images,\nachieving competitive mean Intersection over Union (mIoU) scores of up to 93%\nwithout fine-tuning. Additionally, we provide our code and segmentation masks\nfor these widely used datasets to promote further research.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "Virmarie Maquiling and Sean Anthony Byrne contributed equally to this\n  paper, 8 pages, 3 figures, ETRA 2025, pre-print",
    "pdf_url": "http://arxiv.org/pdf/2410.08926v3",
    "published_date": "2024-10-11 15:50:53 UTC",
    "updated_date": "2025-01-13 15:19:14 UTC"
  },
  {
    "arxiv_id": "2410.08925v3",
    "title": "An Overview of Prototype Formulations for Interpretable Deep Learning",
    "authors": [
      "Maximilian Xiling Li",
      "Korbinian Franz Rudolf",
      "Nils Blank",
      "Rudolf Lioutikov"
    ],
    "abstract": "Prototypical part networks offer interpretable alternatives to black-box deep\nlearning models. However, many of these networks rely on Euclidean prototypes,\nwhich may limit their flexibility. This work provides a comprehensive overview\nof various prototype formulations. Experiments conducted on the CUB-200-2011,\nStanford Cars, and Oxford Flowers datasets demonstrate the effectiveness and\nversatility of these different formulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Equal Contribution of M.X.Li and K.F.Rudolf",
    "pdf_url": "http://arxiv.org/pdf/2410.08925v3",
    "published_date": "2024-10-11 15:50:31 UTC",
    "updated_date": "2025-02-13 10:00:58 UTC"
  },
  {
    "arxiv_id": "2410.08922v1",
    "title": "Exploring the Design Space of Cognitive Engagement Techniques with AI-Generated Code for Enhanced Learning",
    "authors": [
      "Majeed Kazemitabaar",
      "Oliver Huang",
      "Sangho Suh",
      "Austin Z. Henley",
      "Tovi Grossman"
    ],
    "abstract": "Novice programmers are increasingly relying on Large Language Models (LLMs)\nto generate code for learning programming concepts. However, this interaction\ncan lead to superficial engagement, giving learners an illusion of learning and\nhindering skill development. To address this issue, we conducted a systematic\ndesign exploration to develop seven cognitive engagement techniques aimed at\npromoting deeper engagement with AI-generated code. In this paper, we describe\nour design process, the initial seven techniques and results from a\nbetween-subjects study (N=82). We then iteratively refined the top techniques\nand further evaluated them through a within-subjects study (N=42). We evaluate\nthe friction each technique introduces, their effectiveness in helping learners\napply concepts to isomorphic tasks without AI assistance, and their success in\naligning learners' perceived and actual coding abilities. Ultimately, our\nresults highlight the most effective technique: guiding learners through the\nstep-by-step problem-solving process, where they engage in an interactive\ndialog with the AI, prompting what needs to be done at each stage before the\ncorresponding code is revealed.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "19 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.08922v1",
    "published_date": "2024-10-11 15:49:42 UTC",
    "updated_date": "2024-10-11 15:49:42 UTC"
  },
  {
    "arxiv_id": "2410.08920v1",
    "title": "Efficient Hyperparameter Importance Assessment for CNNs",
    "authors": [
      "Ruinan Wang",
      "Ian Nabney",
      "Mohammad Golbabaee"
    ],
    "abstract": "Hyperparameter selection is an essential aspect of the machine learning\npipeline, profoundly impacting models' robustness, stability, and\ngeneralization capabilities. Given the complex hyperparameter spaces associated\nwith Neural Networks and the constraints of computational resources and time,\noptimizing all hyperparameters becomes impractical. In this context, leveraging\nhyperparameter importance assessment (HIA) can provide valuable guidance by\nnarrowing down the search space. This enables machine learning practitioners to\nfocus their optimization efforts on the hyperparameters with the most\nsignificant impact on model performance while conserving time and resources.\nThis paper aims to quantify the importance weights of some hyperparameters in\nConvolutional Neural Networks (CNNs) with an algorithm called N-RReliefF,\nlaying the groundwork for applying HIA methodologies in the Deep Learning\nfield. We conduct an extensive study by training over ten thousand CNN models\nacross ten popular image classification datasets, thereby acquiring a\ncomprehensive dataset containing hyperparameter configuration instances and\ntheir corresponding performance metrics. It is demonstrated that among the\ninvestigated hyperparameters, the top five important hyperparameters of the CNN\nmodel are the number of convolutional layers, learning rate, dropout rate,\noptimizer and epoch.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.08920v1",
    "published_date": "2024-10-11 15:47:46 UTC",
    "updated_date": "2024-10-11 15:47:46 UTC"
  },
  {
    "arxiv_id": "2410.19760v1",
    "title": "Movie Trailer Genre Classification Using Multimodal Pretrained Features",
    "authors": [
      "Serkan Sulun",
      "Paula Viana",
      "Matthew E. P. Davies"
    ],
    "abstract": "We introduce a novel method for movie genre classification, capitalizing on a\ndiverse set of readily accessible pretrained models. These models extract\nhigh-level features related to visual scenery, objects, characters, text,\nspeech, music, and audio effects. To intelligently fuse these pretrained\nfeatures, we train small classifier models with low time and memory\nrequirements. Employing the transformer model, our approach utilizes all video\nand audio frames of movie trailers without performing any temporal pooling,\nefficiently exploiting the correspondence between all elements, as opposed to\nthe fixed and low number of frames typically used by traditional methods. Our\napproach fuses features originating from different tasks and modalities, with\ndifferent dimensionalities, different temporal lengths, and complex\ndependencies as opposed to current approaches. Our method outperforms\nstate-of-the-art movie genre classification models in terms of precision,\nrecall, and mean average precision (mAP). To foster future research, we make\nthe pretrained features for the entire MovieNet dataset, along with our genre\nclassification code and the trained models, publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19760v1",
    "published_date": "2024-10-11 15:38:05 UTC",
    "updated_date": "2024-10-11 15:38:05 UTC"
  },
  {
    "arxiv_id": "2410.08911v1",
    "title": "Test-driven Software Experimentation with LASSO: an LLM Benchmarking Example",
    "authors": [
      "Marcus Kessel"
    ],
    "abstract": "Empirical software engineering faces a critical gap: the lack of standardized\ntools for rapid development and execution of Test-Driven Software Experiments\n(TDSEs) - that is, experiments that involve the execution of software subjects\nand the observation and analysis of their \"de facto\" run-time behavior. In this\npaper we present a general-purpose analysis platform called LASSO that provides\na minimal set of domain-specific languages and data structures to conduct\nTDSEs. By empowering users with an executable scripting language to design and\nexecute TDSEs, LASSO enables efficient evaluation of run-time semantics and\nexecution characteristics in addition to statically determined properties. We\npresent an example TDSE that demonstrates the practical benefits of LASSO's\nscripting capabilities for assessing the reliability of LLMs for code\ngeneration by means of a self-contained, reusable and extensible study script.\nThe LASSO platform is freely available at:\nhttps://softwareobservatorium.github.io/, and a demo video is available on\nYouTube: https://youtu.be/tzY9oNTWXzw",
    "categories": [
      "cs.SE",
      "cs.AI",
      "D.2.1; D.2.4; I.2.2; I.2.7"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08911v1",
    "published_date": "2024-10-11 15:32:48 UTC",
    "updated_date": "2024-10-11 15:32:48 UTC"
  },
  {
    "arxiv_id": "2410.08900v2",
    "title": "A Benchmark for Cross-Domain Argumentative Stance Classification on Social Media",
    "authors": [
      "Jiaqing Yuan",
      "Ruijie Xi",
      "Munindar P. Singh"
    ],
    "abstract": "Argumentative stance classification plays a key role in identifying authors'\nviewpoints on specific topics. However, generating diverse pairs of\nargumentative sentences across various domains is challenging. Existing\nbenchmarks often come from a single domain or focus on a limited set of topics.\nAdditionally, manual annotation for accurate labeling is time-consuming and\nlabor-intensive. To address these challenges, we propose leveraging platform\nrules, readily available expert-curated content, and large language models to\nbypass the need for human annotation. Our approach produces a multidomain\nbenchmark comprising 4,498 topical claims and 30,961 arguments from three\nsources, spanning 21 domains. We benchmark the dataset in fully supervised,\nzero-shot, and few-shot settings, shedding light on the strengths and\nlimitations of different methodologies. We release the dataset and code in this\nstudy at hidden for anonymity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by AAAI ICWSM 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08900v2",
    "published_date": "2024-10-11 15:20:11 UTC",
    "updated_date": "2024-11-15 23:18:53 UTC"
  },
  {
    "arxiv_id": "2410.08899v2",
    "title": "Utilizing ChatGPT in a Data Structures and Algorithms Course: A Teaching Assistant's Perspective",
    "authors": [
      "Pooriya Jamie",
      "Reyhaneh Hajihashemi",
      "Sharareh Alipour"
    ],
    "abstract": "Integrating large language models (LLMs) like ChatGPT into computer science\neducation offers transformative potential for complex courses such as data\nstructures and algorithms (DSA). This study examines ChatGPT as a supplementary\ntool for teaching assistants (TAs), guided by structured prompts and human\noversight, to enhance instruction and student outcomes. A controlled experiment\ncompared traditional TA-led instruction with a hybrid approach where TAs used\nChatGPT-4o and ChatGPT o1 to generate exercises, clarify concepts, and provide\nfeedback. Structured prompts emphasized problem decomposition, real-world\ncontext, and code examples, enabling tailored support while mitigating\nover-reliance on AI. Results demonstrated the hybrid approach's efficacy, with\nstudents in the ChatGPT-assisted group scoring 16.50 points higher on average\nand excelling in advanced topics. However, ChatGPT's limitations necessitated\nTA verification. This framework highlights the dual role of LLMs: augmenting TA\nefficiency while ensuring accuracy through human oversight, offering a scalable\nsolution for human-AI collaboration in education.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.DS",
      "K.3.2; I.2.6"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at CHI EA '25 (Extended Abstracts of the CHI Conference on\n  Human Factors in Computing Systems, 2025). The final version is available at\n  the External DOI",
    "pdf_url": "http://arxiv.org/pdf/2410.08899v2",
    "published_date": "2024-10-11 15:18:48 UTC",
    "updated_date": "2025-03-02 16:12:10 UTC"
  },
  {
    "arxiv_id": "2410.09134v1",
    "title": "Multi-Agent Actor-Critics in Autonomous Cyber Defense",
    "authors": [
      "Mingjun Wang",
      "Remington Dechene"
    ],
    "abstract": "The need for autonomous and adaptive defense mechanisms has become paramount\nin the rapidly evolving landscape of cyber threats. Multi-Agent Deep\nReinforcement Learning (MADRL) presents a promising approach to enhancing the\nefficacy and resilience of autonomous cyber operations. This paper explores the\napplication of Multi-Agent Actor-Critic algorithms which provides a general\nform in Multi-Agent learning to cyber defense, leveraging the collaborative\ninteractions among multiple agents to detect, mitigate, and respond to cyber\nthreats. We demonstrate each agent is able to learn quickly and counter act on\nthe threats autonomously using MADRL in simulated cyber-attack scenarios. The\nresults indicate that MADRL can significantly enhance the capability of\nautonomous cyber defense systems, paving the way for more intelligent\ncybersecurity strategies. This study contributes to the growing body of\nknowledge on leveraging artificial intelligence for cybersecurity and sheds\nlight for future research and development in autonomous cyber operations.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.CR",
    "comment": "6 pages. 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.09134v1",
    "published_date": "2024-10-11 15:15:09 UTC",
    "updated_date": "2024-10-11 15:15:09 UTC"
  },
  {
    "arxiv_id": "2410.08894v1",
    "title": "Conditional Generative Models for Contrast-Enhanced Synthesis of T1w and T1 Maps in Brain MRI",
    "authors": [
      "Moritz Piening",
      "Fabian Altekrüger",
      "Gabriele Steidl",
      "Elke Hattingen",
      "Eike Steidl"
    ],
    "abstract": "Contrast enhancement by Gadolinium-based contrast agents (GBCAs) is a vital\ntool for tumor diagnosis in neuroradiology. Based on brain MRI scans of\nglioblastoma before and after Gadolinium administration, we address enhancement\nprediction by neural networks with two new contributions. Firstly, we study the\npotential of generative models, more precisely conditional diffusion and flow\nmatching, for uncertainty quantification in virtual enhancement. Secondly, we\nexamine the performance of T1 scans from quantitive MRI versus T1-weighted\nscans. In contrast to T1-weighted scans, these scans have the advantage of a\nphysically meaningful and thereby comparable voxel range. To compare network\nprediction performance of these two modalities with incompatible gray-value\nscales, we propose to evaluate segmentations of contrast-enhanced regions of\ninterest using Dice and Jaccard scores. Across models, we observe better\nsegmentations with T1 scans than with T1-weighted scans.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08894v1",
    "published_date": "2024-10-11 15:11:24 UTC",
    "updated_date": "2024-10-11 15:11:24 UTC"
  },
  {
    "arxiv_id": "2410.08893v4",
    "title": "Drama: Mamba-Enabled Model-Based Reinforcement Learning Is Sample and Parameter Efficient",
    "authors": [
      "Wenlong Wang",
      "Ivana Dusparic",
      "Yucheng Shi",
      "Ke Zhang",
      "Vinny Cahill"
    ],
    "abstract": "Model-based reinforcement learning (RL) offers a solution to the data\ninefficiency that plagues most model-free RL algorithms. However, learning a\nrobust world model often requires complex and deep architectures, which are\ncomputationally expensive and challenging to train. Within the world model,\nsequence models play a critical role in accurate predictions, and various\narchitectures have been explored, each with its own challenges. Currently,\nrecurrent neural network (RNN)-based world models struggle with vanishing\ngradients and capturing long-term dependencies. Transformers, on the other\nhand, suffer from the quadratic memory and computational complexity of\nself-attention mechanisms, scaling as $O(n^2)$, where $n$ is the sequence\nlength.\n  To address these challenges, we propose a state space model (SSM)-based world\nmodel, Drama, specifically leveraging Mamba, that achieves $O(n)$ memory and\ncomputational complexity while effectively capturing long-term dependencies and\nenabling efficient training with longer sequences. We also introduce a novel\nsampling method to mitigate the suboptimality caused by an incorrect world\nmodel in the early training stages. Combining these techniques, Drama achieves\na normalised score on the Atari100k benchmark that is competitive with other\nstate-of-the-art (SOTA) model-based RL algorithms, using only a 7\nmillion-parameter world model. Drama is accessible and trainable on\noff-the-shelf hardware, such as a standard laptop. Our code is available at\nhttps://github.com/realwenlongwang/Drama.git.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Published as a conference paper at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08893v4",
    "published_date": "2024-10-11 15:10:40 UTC",
    "updated_date": "2025-05-16 15:49:48 UTC"
  },
  {
    "arxiv_id": "2410.08892v2",
    "title": "Federated Learning in Practice: Reflections and Projections",
    "authors": [
      "Katharine Daly",
      "Hubert Eichner",
      "Peter Kairouz",
      "H. Brendan McMahan",
      "Daniel Ramage",
      "Zheng Xu"
    ],
    "abstract": "Federated Learning (FL) is a machine learning technique that enables multiple\nentities to collaboratively learn a shared model without exchanging their local\ndata. Over the past decade, FL systems have achieved substantial progress,\nscaling to millions of devices across various learning domains while offering\nmeaningful differential privacy (DP) guarantees. Production systems from\norganizations like Google, Apple, and Meta demonstrate the real-world\napplicability of FL. However, key challenges remain, including verifying\nserver-side DP guarantees and coordinating training across heterogeneous\ndevices, limiting broader adoption. Additionally, emerging trends such as large\n(multi-modal) models and blurred lines between training, inference, and\npersonalization challenge traditional FL frameworks. In response, we propose a\nredefined FL framework that prioritizes privacy principles rather than rigid\ndefinitions. We also chart a path forward by leveraging trusted execution\nenvironments and open-source ecosystems to address these challenges and\nfacilitate future advancements in FL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at 2024 IEEE 6th International Conference on Trust, Privacy\n  and Security in Intelligent Systems, and Applications (TPS-ISA)",
    "pdf_url": "http://arxiv.org/pdf/2410.08892v2",
    "published_date": "2024-10-11 15:10:38 UTC",
    "updated_date": "2025-03-03 04:14:17 UTC"
  },
  {
    "arxiv_id": "2410.19759v1",
    "title": "PINNing Cerebral Blood Flow: Analysis of Perfusion MRI in Infants using Physics-Informed Neural Networks",
    "authors": [
      "Christoforos Galazis",
      "Ching-En Chiu",
      "Tomoki Arichi",
      "Anil A. Bharath",
      "Marta Varela"
    ],
    "abstract": "Arterial spin labeling (ASL) magnetic resonance imaging (MRI) enables\ncerebral perfusion measurement, which is crucial in detecting and managing\nneurological issues in infants born prematurely or after perinatal\ncomplications. However, cerebral blood flow (CBF) estimation in infants using\nASL remains challenging due to the complex interplay of network physiology,\ninvolving dynamic interactions between cardiac output and cerebral perfusion,\nas well as issues with parameter uncertainty and data noise. We propose a new\nspatial uncertainty-based physics-informed neural network (PINN), SUPINN, to\nestimate CBF and other parameters from infant ASL data. SUPINN employs a\nmulti-branch architecture to concurrently estimate regional and global model\nparameters across multiple voxels. It computes regional spatial uncertainties\nto weigh the signal. SUPINN can reliably estimate CBF (relative error $-0.3 \\pm\n71.7$), bolus arrival time (AT) ($30.5 \\pm 257.8$), and blood longitudinal\nrelaxation time ($T_{1b}$) ($-4.4 \\pm 28.9$), surpassing parameter estimates\nperformed using least squares or standard PINNs. Furthermore, SUPINN produces\nphysiologically plausible spatially smooth CBF and AT maps. Our study\ndemonstrates the successful modification of PINNs for accurate multi-parameter\nperfusion estimation from noisy and limited ASL data in infants. Frameworks\nlike SUPINN have the potential to advance our understanding of the complex\ncardio-brain network physiology, aiding in the detection and management of\ndiseases. Source code is provided at: https://github.com/cgalaz01/supinn.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.19759v1",
    "published_date": "2024-10-11 15:07:04 UTC",
    "updated_date": "2024-10-11 15:07:04 UTC"
  },
  {
    "arxiv_id": "2410.08886v1",
    "title": "Bank Loan Prediction Using Machine Learning Techniques",
    "authors": [
      "F M Ahosanul Haque",
      "Md. Mahedi Hassan"
    ],
    "abstract": "Banks are important for the development of economies in any financial\necosystem through consumer and business loans. Lending, however, presents\nrisks; thus, banks have to determine the applicant's financial position to\nreduce the probabilities of default. A number of banks have currently,\ntherefore, adopted data analytics and state-of-the-art technology to arrive at\nbetter decisions in the process. The probability of payback is prescribed by a\npredictive modeling technique in which machine learning algorithms are applied.\nIn this research project, we will apply several machine learning methods to\nfurther improve the accuracy and efficiency of loan approval processes. Our\nwork focuses on the prediction of bank loan approval; we have worked on a\ndataset of 148,670 instances and 37 attributes using machine learning methods.\nThe target property segregates the loan applications into \"Approved\" and\n\"Denied\" groups. various machine learning techniques have been used, namely,\nDecision Tree Categorization, AdaBoosting, Random Forest Classifier, SVM, and\nGaussianNB. Following that, the models were trained and evaluated. Among these,\nthe best-performing algorithm was AdaBoosting, which achieved an incredible\naccuracy of 99.99%. The results therefore show how ensemble learning works\neffectively to improve the prediction skills of loan approval decisions. The\npresented work points to the possibility of achieving extremely accurate and\nefficient loan prediction models that provide useful insights for applying\nmachine learning to financial domains.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 18 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.08886v1",
    "published_date": "2024-10-11 15:01:47 UTC",
    "updated_date": "2024-10-11 15:01:47 UTC"
  },
  {
    "arxiv_id": "2410.12855v2",
    "title": "JAILJUDGE: A Comprehensive Jailbreak Judge Benchmark with Multi-Agent Enhanced Explanation Evaluation Framework",
    "authors": [
      "Fan Liu",
      "Yue Feng",
      "Zhao Xu",
      "Lixin Su",
      "Xinyu Ma",
      "Dawei Yin",
      "Hao Liu"
    ],
    "abstract": "Despite advancements in enhancing LLM safety against jailbreak attacks,\nevaluating LLM defenses remains a challenge, with current methods often lacking\nexplainability and generalization to complex scenarios, leading to incomplete\nassessments (e.g., direct judgment without reasoning, low F1 score of GPT-4 in\ncomplex cases, bias in multilingual scenarios). To address this, we present\nJAILJUDGE, a comprehensive benchmark featuring diverse risk scenarios,\nincluding synthetic, adversarial, in-the-wild, and multilingual prompts, along\nwith high-quality human-annotated datasets. The JAILJUDGE dataset includes over\n35k+ instruction-tune data with reasoning explainability and JAILJUDGETEST, a\n4.5k+ labeled set for risk scenarios, and a 6k+ multilingual set across ten\nlanguages. To enhance evaluation with explicit reasoning, we propose the\nJailJudge MultiAgent framework, which enables explainable, fine-grained scoring\n(1 to 10). This framework supports the construction of instruction-tuning\nground truth and facilitates the development of JAILJUDGE Guard, an end-to-end\njudge model that provides reasoning and eliminates API costs. Additionally, we\nintroduce JailBoost, an attacker-agnostic attack enhancer, and GuardShield, a\nmoderation defense, both leveraging JAILJUDGE Guard. Our experiments\ndemonstrate the state-of-the-art performance of JailJudge methods (JailJudge\nMultiAgent, JAILJUDGE Guard) across diverse models (e.g., GPT-4, Llama-Guard)\nand zero-shot scenarios. JailBoost and GuardShield significantly improve\njailbreak attack and defense tasks under zero-shot settings, with JailBoost\nenhancing performance by 29.24% and GuardShield reducing defense ASR from\n40.46% to 0.15%.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.12855v2",
    "published_date": "2024-10-11 14:56:28 UTC",
    "updated_date": "2024-10-18 02:35:22 UTC"
  },
  {
    "arxiv_id": "2410.08875v1",
    "title": "Online design of dynamic networks",
    "authors": [
      "Duo Wang",
      "Andrea Araldo",
      "Mounim El Yacoubi"
    ],
    "abstract": "Designing a network (e.g., a telecommunication or transport network) is\nmainly done offline, in a planning phase, prior to the operation of the\nnetwork. On the other hand, a massive effort has been devoted to characterizing\ndynamic networks, i.e., those that evolve over time. The novelty of this paper\nis that we introduce a method for the online design of dynamic networks. The\nneed to do so emerges when a network needs to operate in a dynamic and\nstochastic environment. In this case, one may wish to build a network over\ntime, on the fly, in order to react to the changes of the environment and to\nkeep certain performance targets. We tackle this online design problem with a\nrolling horizon optimization based on Monte Carlo Tree Search. The potential of\nonline network design is showcased for the design of a futuristic dynamic\npublic transport network, where bus lines are constructed on the fly to better\nadapt to a stochastic user demand. In such a scenario, we compare our results\nwith state-of-the-art dynamic vehicle routing problem (VRP) resolution methods,\nsimulating requests from a New York City taxi dataset. Differently from classic\nVRP methods, that extend vehicle trajectories in isolation, our method enables\nus to build a structured network of line buses, where complex user journeys are\npossible, thus increasing system performance.",
    "categories": [
      "cs.AI",
      "cs.SI",
      "physics.soc-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.08875v1",
    "published_date": "2024-10-11 14:50:31 UTC",
    "updated_date": "2024-10-11 14:50:31 UTC"
  },
  {
    "arxiv_id": "2410.08874v1",
    "title": "Experiments with Choice in Dependently-Typed Higher-Order Logic",
    "authors": [
      "Daniel Ranalter",
      "Chad E. Brown",
      "Cezary Kaliszyk"
    ],
    "abstract": "Recently an extension to higher-order logic -- called DHOL -- was introduced,\nenriching the language with dependent types, and creating a powerful\nextensional type theory. In this paper we propose two ways how choice can be\nadded to DHOL. We extend the DHOL term structure by Hilbert's indefinite choice\noperator $\\epsilon$, define a translation of the choice terms to HOL choice\nthat extends the existing translation from DHOL to HOL and show that the\nextension of the translation is complete and give an argument for soundness. We\nfinally evaluate the extended translation on a set of dependent HOL problems\nthat require choice.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "F.4.1; I.2.3"
    ],
    "primary_category": "cs.LO",
    "comment": "10 pages incl. references; published in the proceedings of LPAR25",
    "pdf_url": "http://arxiv.org/pdf/2410.08874v1",
    "published_date": "2024-10-11 14:49:45 UTC",
    "updated_date": "2024-10-11 14:49:45 UTC"
  },
  {
    "arxiv_id": "2410.08864v1",
    "title": "The Good, the Bad and the Ugly: Watermarks, Transferable Attacks and Adversarial Defenses",
    "authors": [
      "Grzegorz Głuch",
      "Berkant Turan",
      "Sai Ganesh Nagarajan",
      "Sebastian Pokutta"
    ],
    "abstract": "We formalize and extend existing definitions of backdoor-based watermarks and\nadversarial defenses as interactive protocols between two players. The\nexistence of these schemes is inherently tied to the learning tasks for which\nthey are designed. Our main result shows that for almost every discriminative\nlearning task, at least one of the two -- a watermark or an adversarial defense\n-- exists. The term \"almost every\" indicates that we also identify a third,\ncounterintuitive but necessary option, i.e., a scheme we call a transferable\nattack. By transferable attack, we refer to an efficient algorithm computing\nqueries that look indistinguishable from the data distribution and fool all\nefficient defenders. To this end, we prove the necessity of a transferable\nattack via a construction that uses a cryptographic tool called homomorphic\nencryption. Furthermore, we show that any task that satisfies our notion of a\ntransferable attack implies a cryptographic primitive, thus requiring the\nunderlying task to be computationally complex. These two facts imply an\n\"equivalence\" between the existence of transferable attacks and cryptography.\nFinally, we show that the class of tasks of bounded VC-dimension has an\nadversarial defense, and a subclass of them has a watermark.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "68T01, 94A60, 91A99"
    ],
    "primary_category": "cs.LG",
    "comment": "42 pages, 6 figures, preliminary version published in ICML 2024\n  (Workshop on Theoretical Foundations of Foundation Models), see\n  https://openreview.net/pdf?id=WMaFRiggwV",
    "pdf_url": "http://arxiv.org/pdf/2410.08864v1",
    "published_date": "2024-10-11 14:44:05 UTC",
    "updated_date": "2024-10-11 14:44:05 UTC"
  },
  {
    "arxiv_id": "2410.08855v1",
    "title": "MATCH: Model-Aware TVM-based Compilation for Heterogeneous Edge Devices",
    "authors": [
      "Mohamed Amine Hamdi",
      "Francesco Daghero",
      "Giuseppe Maria Sarda",
      "Josse Van Delm",
      "Arne Symons",
      "Luca Benini",
      "Marian Verhelst",
      "Daniele Jahier Pagliari",
      "Alessio Burrello"
    ],
    "abstract": "Streamlining the deployment of Deep Neural Networks (DNNs) on heterogeneous\nedge platforms, coupling within the same micro-controller unit (MCU)\ninstruction processors and hardware accelerators for tensor computations, is\nbecoming one of the crucial challenges of the TinyML field.\n  The best-performing DNN compilation toolchains are usually deeply customized\nfor a single MCU family, and porting to a different heterogeneous MCU family\nimplies labor-intensive re-development of almost the entire compiler. On the\nopposite side, retargetable toolchains, such as TVM, fail to exploit the\ncapabilities of custom accelerators, resulting in the generation of general but\nunoptimized code. To overcome this duality, we introduce MATCH, a novel\nTVM-based DNN deployment framework designed for easy agile retargeting across\ndifferent MCU processors and accelerators, thanks to a customizable model-based\nhardware abstraction.\n  We show that a general and retargetable mapping framework enhanced with\nhardware cost models can compete with and even outperform custom toolchains on\ndiverse targets while only needing the definition of an abstract hardware model\nand a SoC-specific API.\n  We tested MATCH on two state-of-the-art heterogeneous MCUs, GAP9 and DIANA.\n  On the four DNN models of the MLPerf Tiny suite MATCH reduces inference\nlatency by up to 60.88 times on DIANA, compared to using the plain TVM, thanks\nto the exploitation of the on-board HW accelerator. Compared to HTVM, a fully\ncustomized toolchain for DIANA, we still reduce the latency by 16.94%. On GAP9,\nusing the same benchmarks, we improve the latency by 2.15 times compared to the\ndedicated DORY compiler, thanks to our heterogeneous DNN mapping approach that\nsynergically exploits the DNN accelerator and the eight-cores cluster available\non board.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "I.2.2; D.1.3"
    ],
    "primary_category": "cs.DC",
    "comment": "13 pages, 11 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.08855v1",
    "published_date": "2024-10-11 14:32:06 UTC",
    "updated_date": "2024-10-11 14:32:06 UTC"
  },
  {
    "arxiv_id": "2410.08854v3",
    "title": "Hybrid LLM-DDQN based Joint Optimization of V2I Communication and Autonomous Driving",
    "authors": [
      "Zijiang Yan",
      "Hao Zhou",
      "Hina Tabassum",
      "Xue Liu"
    ],
    "abstract": "Large language models (LLMs) have received considerable interest recently due\nto their outstanding reasoning and comprehension capabilities. This work\nexplores applying LLMs to vehicular networks, aiming to jointly optimize\nvehicle-to-infrastructure (V2I) communications and autonomous driving (AD)\npolicies. We deploy LLMs for AD decision-making to maximize traffic flow and\navoid collisions for road safety, and a double deep Q-learning algorithm (DDQN)\nis used for V2I optimization to maximize the received data rate and reduce\nfrequent handovers. In particular, for LLM-enabled AD, we employ the Euclidean\ndistance to identify previously explored AD experiences, and then LLMs can\nlearn from past good and bad decisions for further improvement. Then, LLM-based\nAD decisions will become part of states in V2I problems, and DDQN will optimize\nthe V2I decisions accordingly. After that, the AD and V2I decisions are\niteratively optimized until convergence. Such an iterative optimization\napproach can better explore the interactions between LLMs and conventional\nreinforcement learning techniques, revealing the potential of using LLMs for\nnetwork optimization and management. Finally, the simulations demonstrate that\nour proposed hybrid LLM-DDQN approach outperforms the conventional DDQN\nalgorithm, showing faster convergence and higher average rewards.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by IEEE Wireless Communications Letters",
    "pdf_url": "http://arxiv.org/pdf/2410.08854v3",
    "published_date": "2024-10-11 14:30:04 UTC",
    "updated_date": "2025-02-04 19:38:26 UTC"
  },
  {
    "arxiv_id": "2410.08852v2",
    "title": "Conformalized Interactive Imitation Learning: Handling Expert Shift and Intermittent Feedback",
    "authors": [
      "Michelle Zhao",
      "Reid Simmons",
      "Henny Admoni",
      "Aaditya Ramdas",
      "Andrea Bajcsy"
    ],
    "abstract": "In interactive imitation learning (IL), uncertainty quantification offers a\nway for the learner (i.e. robot) to contend with distribution shifts\nencountered during deployment by actively seeking additional feedback from an\nexpert (i.e. human) online. Prior works use mechanisms like ensemble\ndisagreement or Monte Carlo dropout to quantify when black-box IL policies are\nuncertain; however, these approaches can lead to overconfident estimates when\nfaced with deployment-time distribution shifts. Instead, we contend that we\nneed uncertainty quantification algorithms that can leverage the expert human\nfeedback received during deployment time to adapt the robot's uncertainty\nonline. To tackle this, we draw upon online conformal prediction, a\ndistribution-free method for constructing prediction intervals online given a\nstream of ground-truth labels. Human labels, however, are intermittent in the\ninteractive IL setting. Thus, from the conformal prediction side, we introduce\na novel uncertainty quantification algorithm called intermittent quantile\ntracking (IQT) that leverages a probabilistic model of intermittent labels,\nmaintains asymptotic coverage guarantees, and empirically achieves desired\ncoverage levels. From the interactive IL side, we develop ConformalDAgger, a\nnew approach wherein the robot uses prediction intervals calibrated by IQT as a\nreliable measure of deployment-time uncertainty to actively query for more\nexpert feedback. We compare ConformalDAgger to prior uncertainty-aware DAgger\nmethods in scenarios where the distribution shift is (and isn't) present\nbecause of changes in the expert's policy. We find that in simulated and\nhardware deployments on a 7DOF robotic manipulator, ConformalDAgger detects\nhigh uncertainty when the expert shifts and increases the number of\ninterventions compared to baselines, allowing the robot to more quickly learn\nthe new behavior.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08852v2",
    "published_date": "2024-10-11 14:27:56 UTC",
    "updated_date": "2025-04-29 12:17:52 UTC"
  },
  {
    "arxiv_id": "2410.08847v4",
    "title": "Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization",
    "authors": [
      "Noam Razin",
      "Sadhika Malladi",
      "Adithya Bhaskar",
      "Danqi Chen",
      "Sanjeev Arora",
      "Boris Hanin"
    ],
    "abstract": "Direct Preference Optimization (DPO) and its variants are increasingly used\nfor aligning language models with human preferences. Although these methods are\ndesigned to teach a model to generate preferred responses more frequently\nrelative to dispreferred responses, prior work has observed that the likelihood\nof preferred responses often decreases during training. The current work sheds\nlight on the causes and implications of this counter-intuitive phenomenon,\nwhich we term likelihood displacement. We demonstrate that likelihood\ndisplacement can be catastrophic, shifting probability mass from preferred\nresponses to responses with an opposite meaning. As a simple example, training\na model to prefer $\\texttt{No}$ over $\\texttt{Never}$ can sharply increase the\nprobability of $\\texttt{Yes}$. Moreover, when aligning the model to refuse\nunsafe prompts, we show that such displacement can unintentionally lead to\nunalignment, by shifting probability mass from preferred refusal responses to\nharmful responses (e.g., reducing the refusal rate of Llama-3-8B-Instruct from\n74.4% to 33.4%). We theoretically characterize that likelihood displacement is\ndriven by preferences that induce similar embeddings, as measured by a centered\nhidden embedding similarity (CHES) score. Empirically, the CHES score enables\nidentifying which training samples contribute most to likelihood displacement\nin a given dataset. Filtering out these samples effectively mitigated\nunintentional unalignment in our experiments. More broadly, our results\nhighlight the importance of curating data with sufficiently distinct\npreferences, for which we believe the CHES score may prove valuable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to ICLR 2025; Code available at\n  https://github.com/princeton-nlp/unintentional-unalignment",
    "pdf_url": "http://arxiv.org/pdf/2410.08847v4",
    "published_date": "2024-10-11 14:22:44 UTC",
    "updated_date": "2025-04-27 15:21:29 UTC"
  },
  {
    "arxiv_id": "2410.08841v1",
    "title": "Public Transport Network Design for Equality of Accessibility via Message Passing Neural Networks and Reinforcement Learning",
    "authors": [
      "Duo Wang",
      "Maximilien Chau",
      "Andrea Araldo"
    ],
    "abstract": "Designing Public Transport (PT) networks able to satisfy mobility needs of\npeople is essential to reduce the number of individual vehicles on the road,\nand thus pollution and congestion. Urban sustainability is thus tightly coupled\nto an efficient PT. Current approaches on Transport Network Design (TND)\ngenerally aim to optimize generalized cost, i.e., a unique number including\noperator and users' costs. Since we intend quality of PT as the capability of\nsatisfying mobility needs, we focus instead on PT accessibility, i.e., the ease\nof reaching surrounding points of interest via PT. PT accessibility is\ngenerally unequally distributed in urban regions: suburbs generally suffer from\npoor PT accessibility, which condemns residents therein to be dependent on\ntheir private cars. We thus tackle the problem of designing bus lines so as to\nminimize the inequality in the geographical distribution of accessibility. We\ncombine state-of-the-art Message Passing Neural Networks (MPNN) and\nReinforcement Learning. We show the efficacy of our method against\nmetaheuristics (classically used in TND) in a use case representing in\nsimplified terms the city of Montreal.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.08841v1",
    "published_date": "2024-10-11 14:16:58 UTC",
    "updated_date": "2024-10-11 14:16:58 UTC"
  },
  {
    "arxiv_id": "2410.08833v2",
    "title": "Symmetry-Constrained Generation of Diverse Low-Bandgap Molecules with Monte Carlo Tree Search",
    "authors": [
      "Akshay Subramanian",
      "James Damewood",
      "Juno Nam",
      "Kevin P. Greenman",
      "Avni P. Singhal",
      "Rafael Gómez-Bombarelli"
    ],
    "abstract": "Organic optoelectronic materials are a promising avenue for next-generation\nelectronic devices due to their solution processability, mechanical\nflexibility, and tunable electronic properties. In particular, near-infrared\n(NIR) sensitive molecules have unique applications in night-vision equipment\nand biomedical imaging. Molecular engineering has played a crucial role in\ndeveloping non-fullerene acceptors (NFAs) such as the Y-series molecules, which\nhave significantly improved the power conversion efficiency (PCE) of solar\ncells and enhanced spectral coverage in the NIR region. However, systematically\ndesigning molecules with targeted optoelectronic properties while ensuring\nsynthetic accessibility remains a challenge. To address this, we leverage\nstructural priors from domain-focused, patent-mined datasets of organic\nelectronic molecules using a symmetry-aware fragment decomposition algorithm\nand a fragment-constrained Monte Carlo Tree Search (MCTS) generator. Our\napproach generates candidates that retain symmetry constraints from the patent\ndataset, while also exhibiting red-shifted absorption, as validated by TD-DFT\ncalculations.",
    "categories": [
      "physics.chem-ph",
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08833v2",
    "published_date": "2024-10-11 14:09:27 UTC",
    "updated_date": "2024-12-12 16:22:24 UTC"
  },
  {
    "arxiv_id": "2410.08829v1",
    "title": "Unveiling Molecular Secrets: An LLM-Augmented Linear Model for Explainable and Calibratable Molecular Property Prediction",
    "authors": [
      "Zhuoran Li",
      "Xu Sun",
      "Wanyu Lin",
      "Jiannong Cao"
    ],
    "abstract": "Explainable molecular property prediction is essential for various scientific\nfields, such as drug discovery and material science. Despite delivering\nintrinsic explainability, linear models struggle with capturing complex,\nnon-linear patterns. Large language models (LLMs), on the other hand, yield\naccurate predictions through powerful inference capabilities yet fail to\nprovide chemically meaningful explanations for their predictions. This work\nproposes a novel framework, called MoleX, which leverages LLM knowledge to\nbuild a simple yet powerful linear model for accurate molecular property\nprediction with faithful explanations. The core of MoleX is to model\ncomplicated molecular structure-property relationships using a simple linear\nmodel, augmented by LLM knowledge and a crafted calibration strategy.\nSpecifically, to extract the maximum amount of task-relevant knowledge from LLM\nembeddings, we employ information bottleneck-inspired fine-tuning and\nsparsity-inducing dimensionality reduction. These informative embeddings are\nthen used to fit a linear model for explainable inference. Moreover, we\nintroduce residual calibration to address prediction errors stemming from\nlinear models' insufficient expressiveness of complex LLM embeddings, thus\nrecovering the LLM's predictive power and boosting overall accuracy.\nTheoretically, we provide a mathematical foundation to justify MoleX's\nexplainability. Extensive experiments demonstrate that MoleX outperforms\nexisting methods in molecular property prediction, establishing a new milestone\nin predictive performance, explainability, and efficiency. In particular, MoleX\nenables CPU inference and accelerates large-scale dataset processing, achieving\ncomparable performance 300x faster with 100,000 fewer parameters than LLMs.\nAdditionally, the calibration improves model performance by up to 12.7% without\ncompromising explainability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08829v1",
    "published_date": "2024-10-11 14:07:57 UTC",
    "updated_date": "2024-10-11 14:07:57 UTC"
  },
  {
    "arxiv_id": "2410.08824v1",
    "title": "One-shot Generative Domain Adaptation in 3D GANs",
    "authors": [
      "Ziqiang Li",
      "Yi Wu",
      "Chaoyue Wang",
      "Xue Rui",
      "Bin Li"
    ],
    "abstract": "3D-aware image generation necessitates extensive training data to ensure\nstable training and mitigate the risk of overfitting. This paper first\nconsiders a novel task known as One-shot 3D Generative Domain Adaptation (GDA),\naimed at transferring a pre-trained 3D generator from one domain to a new one,\nrelying solely on a single reference image. One-shot 3D GDA is characterized by\nthe pursuit of specific attributes, namely, high fidelity, large diversity,\ncross-domain consistency, and multi-view consistency. Within this paper, we\nintroduce 3D-Adapter, the first one-shot 3D GDA method, for diverse and\nfaithful generation. Our approach begins by judiciously selecting a restricted\nweight set for fine-tuning, and subsequently leverages four advanced loss\nfunctions to facilitate adaptation. An efficient progressive fine-tuning\nstrategy is also implemented to enhance the adaptation process. The synergy of\nthese three technological components empowers 3D-Adapter to achieve remarkable\nperformance, substantiated both quantitatively and qualitatively, across all\ndesired properties of 3D GDA. Furthermore, 3D-Adapter seamlessly extends its\ncapabilities to zero-shot scenarios, and preserves the potential for crucial\ntasks such as interpolation, reconstruction, and editing within the latent\nspace of the pre-trained generator. Code will be available at\nhttps://github.com/iceli1007/3D-Adapter.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "IJCV",
    "pdf_url": "http://arxiv.org/pdf/2410.08824v1",
    "published_date": "2024-10-11 14:04:44 UTC",
    "updated_date": "2024-10-11 14:04:44 UTC"
  },
  {
    "arxiv_id": "2410.08822v2",
    "title": "SOLD: Slot Object-Centric Latent Dynamics Models for Relational Manipulation Learning from Pixels",
    "authors": [
      "Malte Mosbach",
      "Jan Niklas Ewertz",
      "Angel Villar-Corrales",
      "Sven Behnke"
    ],
    "abstract": "Learning a latent dynamics model provides a task-agnostic representation of\nan agent's understanding of its environment. Leveraging this knowledge for\nmodel-based reinforcement learning (RL) holds the potential to improve sample\nefficiency over model-free methods by learning from imagined rollouts.\nFurthermore, because the latent space serves as input to behavior models, the\ninformative representations learned by the world model facilitate efficient\nlearning of desired skills. Most existing methods rely on holistic\nrepresentations of the environment's state. In contrast, humans reason about\nobjects and their interactions, predicting how actions will affect specific\nparts of their surroundings. Inspired by this, we propose Slot-Attention for\nObject-centric Latent Dynamics (SOLD), a novel model-based RL algorithm that\nlearns object-centric dynamics models in an unsupervised manner from pixel\ninputs. We demonstrate that the structured latent space not only improves model\ninterpretability but also provides a valuable input space for behavior models\nto reason over. Our results show that SOLD outperforms DreamerV3 and TD-MPC2 -\nstate-of-the-art model-based RL algorithms - across a range of benchmark\nrobotic environments that require relational reasoning and manipulation\ncapabilities. Videos are available at https://slot-latent-dynamics.github.io/.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08822v2",
    "published_date": "2024-10-11 14:03:31 UTC",
    "updated_date": "2025-02-07 10:52:37 UTC"
  },
  {
    "arxiv_id": "2410.08815v2",
    "title": "StructRAG: Boosting Knowledge Intensive Reasoning of LLMs via Inference-time Hybrid Information Structurization",
    "authors": [
      "Zhuoqun Li",
      "Xuanang Chen",
      "Haiyang Yu",
      "Hongyu Lin",
      "Yaojie Lu",
      "Qiaoyu Tang",
      "Fei Huang",
      "Xianpei Han",
      "Le Sun",
      "Yongbin Li"
    ],
    "abstract": "Retrieval-augmented generation (RAG) is a key means to effectively enhance\nlarge language models (LLMs) in many knowledge-based tasks. However, existing\nRAG methods struggle with knowledge-intensive reasoning tasks, because useful\ninformation required to these tasks are badly scattered. This characteristic\nmakes it difficult for existing RAG methods to accurately identify key\ninformation and perform global reasoning with such noisy augmentation. In this\npaper, motivated by the cognitive theories that humans convert raw information\ninto various structured knowledge when tackling knowledge-intensive reasoning,\nwe proposes a new framework, StructRAG, which can identify the optimal\nstructure type for the task at hand, reconstruct original documents into this\nstructured format, and infer answers based on the resulting structure.\nExtensive experiments across various knowledge-intensive tasks show that\nStructRAG achieves state-of-the-art performance, particularly excelling in\nchallenging scenarios, demonstrating its potential as an effective solution for\nenhancing LLMs in complex real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08815v2",
    "published_date": "2024-10-11 13:52:44 UTC",
    "updated_date": "2024-10-25 12:18:37 UTC"
  },
  {
    "arxiv_id": "2410.21286v1",
    "title": "OpenCity: A Scalable Platform to Simulate Urban Activities with Massive LLM Agents",
    "authors": [
      "Yuwei Yan",
      "Qingbin Zeng",
      "Zhiheng Zheng",
      "Jingzhe Yuan",
      "Jie Feng",
      "Jun Zhang",
      "Fengli Xu",
      "Yong Li"
    ],
    "abstract": "Agent-based models (ABMs) have long been employed to explore how individual\nbehaviors aggregate into complex societal phenomena in urban space. Unlike\nblack-box predictive models, ABMs excel at explaining the micro-macro linkages\nthat drive such emergent behaviors. The recent rise of Large Language Models\n(LLMs) has led to the development of LLM agents capable of simulating urban\nactivities with unprecedented realism. However, the extreme high computational\ncost of LLMs presents significant challenges for scaling up the simulations of\nLLM agents. To address this problem, we propose OpenCity, a scalable simulation\nplatform optimized for both system and prompt efficiencies. Specifically, we\npropose a LLM request scheduler to reduce communication overhead by\nparallelizing requests through IO multiplexing. Besides, we deisgn a\n\"group-and-distill\" prompt optimization strategy minimizes redundancy by\nclustering agents with similar static attributes. Through experiments on six\nglobal cities, OpenCity achieves a 600-fold acceleration in simulation time per\nagent, a 70% reduction in LLM requests, and a 50% reduction in token usage.\nThese improvements enable the simulation of 10,000 agents' daily activities in\n1 hour on commodity hardware. Besides, the substantial speedup of OpenCity\nallows us to establish a urban simulation benchmark for LLM agents for the\nfirst time, comparing simulated urban activities with real-world data in 6\nmajor cities around the globe. We believe our OpenCity platform provides a\ncritical infrastructure to harness the power of LLMs for interdisciplinary\nstudies in urban space, fostering the collective efforts of broader research\ncommunities. Code repo is available at\nhttps://anonymous.4open.science/r/Anonymous-OpenCity-42BD.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21286v1",
    "published_date": "2024-10-11 13:52:35 UTC",
    "updated_date": "2024-10-11 13:52:35 UTC"
  },
  {
    "arxiv_id": "2410.08811v1",
    "title": "PoisonBench: Assessing Large Language Model Vulnerability to Data Poisoning",
    "authors": [
      "Tingchen Fu",
      "Mrinank Sharma",
      "Philip Torr",
      "Shay B. Cohen",
      "David Krueger",
      "Fazl Barez"
    ],
    "abstract": "Preference learning is a central component for aligning current LLMs, but\nthis process can be vulnerable to data poisoning attacks. To address this\nconcern, we introduce PoisonBench, a benchmark for evaluating large language\nmodels' susceptibility to data poisoning during preference learning. Data\npoisoning attacks can manipulate large language model responses to include\nhidden malicious content or biases, potentially causing the model to generate\nharmful or unintended outputs while appearing to function normally. We deploy\ntwo distinct attack types across eight realistic scenarios, assessing 21\nwidely-used models. Our findings reveal concerning trends: (1) Scaling up\nparameter size does not inherently enhance resilience against poisoning\nattacks; (2) There exists a log-linear relationship between the effects of the\nattack and the data poison ratio; (3) The effect of data poisoning can\ngeneralize to extrapolated triggers that are not included in the poisoned data.\nThese results expose weaknesses in current preference learning techniques,\nhighlighting the urgent need for more robust defenses against malicious models\nand data manipulation.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "Tingchen Fu and Fazl Barez are core research contributors",
    "pdf_url": "http://arxiv.org/pdf/2410.08811v1",
    "published_date": "2024-10-11 13:50:50 UTC",
    "updated_date": "2024-10-11 13:50:50 UTC"
  },
  {
    "arxiv_id": "2410.08809v2",
    "title": "DCNet: A Data-Driven Framework for DVL Calibration",
    "authors": [
      "Zeev Yampolsky",
      "Itzik Klein"
    ],
    "abstract": "Autonomous underwater vehicles (AUVs) are underwater robotic platforms used\nin a variety of applications. An AUV's navigation solution relies heavily on\nthe fusion of inertial sensors and Doppler velocity logs (DVL), where the\nlatter delivers accurate velocity updates. To ensure accurate navigation, a DVL\ncalibration is undertaken before the mission begins to estimate its error\nterms. During calibration, the AUV follows a complex trajectory and employs\nnonlinear estimation filters to estimate error terms. In this paper, we\nintroduce DCNet, a data-driven framework that utilizes a two-dimensional\nconvolution kernel in an innovative way. Using DCNet and our proposed DVL error\nmodel, we offer a rapid calibration procedure. This can be applied to a\ntrajectory with a nearly constant velocity. To train and test our proposed\napproach a dataset of 276 minutes long with real DVL recorded measurements was\nused. We demonstrated an average improvement of 70% in accuracy and 80%\nimprovement in calibration time, compared to the baseline approach, with a\nlow-performance DVL. As a result of those improvements, an AUV employing a\nlow-cost DVL, can achieve higher accuracy, shorter calibration time, and apply\na simple nearly constant velocity calibration trajectory. Our results also open\nup new applications for marine robotics utilizing low-cost, high-accurate DVLs.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "10 Pages, 9 Figures, 5 Tables",
    "pdf_url": "http://arxiv.org/pdf/2410.08809v2",
    "published_date": "2024-10-11 13:47:40 UTC",
    "updated_date": "2024-10-14 09:47:10 UTC"
  },
  {
    "arxiv_id": "2410.08794v1",
    "title": "M$^3$-Impute: Mask-guided Representation Learning for Missing Value Imputation",
    "authors": [
      "Zhongyi Yu",
      "Zhenghao Wu",
      "Shuhan Zhong",
      "Weifeng Su",
      "S. -H. Gary Chan",
      "Chul-Ho Lee",
      "Weipeng Zhuo"
    ],
    "abstract": "Missing values are a common problem that poses significant challenges to data\nanalysis and machine learning. This problem necessitates the development of an\neffective imputation method to fill in the missing values accurately, thereby\nenhancing the overall quality and utility of the datasets. Existing imputation\nmethods, however, fall short of explicitly considering the `missingness'\ninformation in the data during the embedding initialization stage and modeling\nthe entangled feature and sample correlations during the learning process, thus\nleading to inferior performance. We propose M$^3$-Impute, which aims to\nexplicitly leverage the missingness information and such correlations with\nnovel masking schemes. M$^3$-Impute first models the data as a bipartite graph\nand uses a graph neural network to learn node embeddings, where the refined\nembedding initialization process directly incorporates the missingness\ninformation. They are then optimized through M$^3$-Impute's novel feature\ncorrelation unit (FRU) and sample correlation unit (SRU) that effectively\ncaptures feature and sample correlations for imputation. Experiment results on\n25 benchmark datasets under three different missingness settings show the\neffectiveness of M$^3$-Impute by achieving 20 best and 4 second-best MAE scores\non average.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08794v1",
    "published_date": "2024-10-11 13:25:32 UTC",
    "updated_date": "2024-10-11 13:25:32 UTC"
  },
  {
    "arxiv_id": "2410.09132v2",
    "title": "When Graph meets Multimodal: Benchmarking and Meditating on Multimodal Attributed Graphs Learning",
    "authors": [
      "Hao Yan",
      "Chaozhuo Li",
      "Jun Yin",
      "Zhigang Yu",
      "Weihao Han",
      "Mingzheng Li",
      "Zhengxin Zeng",
      "Hao Sun",
      "Senzhang Wang"
    ],
    "abstract": "Multimodal Attributed Graphs (MAGs) are ubiquitous in real-world\napplications, encompassing extensive knowledge through multimodal attributes\nattached to nodes (e.g., texts and images) and topological structure\nrepresenting node interactions. Despite its potential to advance diverse\nresearch fields like social networks and e-commerce, MAG representation\nlearning (MAGRL) remains underexplored due to the lack of standardized datasets\nand evaluation frameworks. In this paper, we first propose MAGB, a\ncomprehensive MAG benchmark dataset, featuring curated graphs from various\ndomains with both textual and visual attributes. Based on MAGB dataset, we\nfurther systematically evaluate two mainstream MAGRL paradigms:\n$\\textit{GNN-as-Predictor}$, which integrates multimodal attributes via Graph\nNeural Networks (GNNs), and $\\textit{VLM-as-Predictor}$, which harnesses Vision\nLanguage Models (VLMs) for zero-shot reasoning. Extensive experiments on MAGB\nreveal following critical insights: $\\textit{(i)}$ Modality significances\nfluctuate drastically with specific domain characteristics. $\\textit{(ii)}$\nMultimodal embeddings can elevate the performance ceiling of GNNs. However,\nintrinsic biases among modalities may impede effective training, particularly\nin low-data scenarios. $\\textit{(iii)}$ VLMs are highly effective at generating\nmultimodal embeddings that alleviate the imbalance between textual and visual\nattributes. These discoveries, which illuminate the synergy between multimodal\nattributes and graph topologies, contribute to reliable benchmarks, paving the\nway for future MAG research. The MAGB dataset and evaluation pipeline are\npublicly available at https://github.com/sktsherlock/MAGB.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09132v2",
    "published_date": "2024-10-11 13:24:57 UTC",
    "updated_date": "2025-02-27 14:51:24 UTC"
  },
  {
    "arxiv_id": "2410.08792v1",
    "title": "VLM See, Robot Do: Human Demo Video to Robot Action Plan via Vision Language Model",
    "authors": [
      "Beichen Wang",
      "Juexiao Zhang",
      "Shuwen Dong",
      "Irving Fang",
      "Chen Feng"
    ],
    "abstract": "Vision Language Models (VLMs) have recently been adopted in robotics for\ntheir capability in common sense reasoning and generalizability. Existing work\nhas applied VLMs to generate task and motion planning from natural language\ninstructions and simulate training data for robot learning. In this work, we\nexplore using VLM to interpret human demonstration videos and generate robot\ntask planning. Our method integrates keyframe selection, visual perception, and\nVLM reasoning into a pipeline. We named it SeeDo because it enables the VLM to\n''see'' human demonstrations and explain the corresponding plans to the robot\nfor it to ''do''. To validate our approach, we collected a set of long-horizon\nhuman videos demonstrating pick-and-place tasks in three diverse categories and\ndesigned a set of metrics to comprehensively benchmark SeeDo against several\nbaselines, including state-of-the-art video-input VLMs. The experiments\ndemonstrate SeeDo's superior performance. We further deployed the generated\ntask plans in both a simulation environment and on a real robot arm.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08792v1",
    "published_date": "2024-10-11 13:17:52 UTC",
    "updated_date": "2024-10-11 13:17:52 UTC"
  },
  {
    "arxiv_id": "2410.14716v3",
    "title": "A Systematic Survey on Large Language Models for Algorithm Design",
    "authors": [
      "Fei Liu",
      "Yiming Yao",
      "Ping Guo",
      "Zhiyuan Yang",
      "Zhe Zhao",
      "Xi Lin",
      "Xialiang Tong",
      "Mingxuan Yuan",
      "Zhichao Lu",
      "Zhenkun Wang",
      "Qingfu Zhang"
    ],
    "abstract": "Algorithm Design (AD) is crucial for effective problem-solving across various\ndomains. The advent of Large Language Models (LLMs) has notably enhanced the\nautomation and innovation within this field, offering new perspectives and\npromising solutions. Over the past three years, the integration of LLMs into AD\n(LLM4AD) has seen substantial progress, with applications spanning\noptimization, machine learning, mathematical reasoning, and scientific\ndiscovery. Given the rapid advancements and expanding scope of this field, a\nsystematic review is both timely and necessary. This paper provides a\nsystematic review of LLM4AD. First, we offer an overview and summary of\nexisting studies. Then, we introduce a taxonomy and review the literature\nacross four dimensions: the roles of LLMs, search methods, prompt methods, and\napplication domains with a discussion of potential and achievements of LLMs in\nAD. Finally, we identify current challenges and highlight several promising\ndirections for future research.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.14716v3",
    "published_date": "2024-10-11 13:17:19 UTC",
    "updated_date": "2024-11-01 09:38:59 UTC"
  },
  {
    "arxiv_id": "2410.08776v2",
    "title": "F2A: An Innovative Approach for Prompt Injection by Utilizing Feign Security Detection Agents",
    "authors": [
      "Yupeng Ren"
    ],
    "abstract": "With the rapid development of Large Language Models (LLMs), numerous mature\napplications of LLMs have emerged in the field of content safety detection.\nHowever, we have found that LLMs exhibit blind trust in safety detection\nagents. The general LLMs can be compromised by hackers with this vulnerability.\nHence, this paper proposed an attack named Feign Agent Attack (F2A).Through\nsuch malicious forgery methods, adding fake safety detection results into the\nprompt, the defense mechanism of LLMs can be bypassed, thereby obtaining\nharmful content and hijacking the normal conversation. Continually, a series of\nexperiments were conducted. In these experiments, the hijacking capability of\nF2A on LLMs was analyzed and demonstrated, exploring the fundamental reasons\nwhy LLMs blindly trust safety detection results. The experiments involved\nvarious scenarios where fake safety detection results were injected into\nprompts, and the responses were closely monitored to understand the extent of\nthe vulnerability. Also, this paper provided a reasonable solution to this\nattack, emphasizing that it is important for LLMs to critically evaluate the\nresults of augmented agents to prevent the generating harmful content. By doing\nso, the reliability and security can be significantly improved, protecting the\nLLMs from F2A.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "1. Fixed typo in abstract 2. Provisionally completed the article\n  update to facilitate future version revisions",
    "pdf_url": "http://arxiv.org/pdf/2410.08776v2",
    "published_date": "2024-10-11 12:49:05 UTC",
    "updated_date": "2024-10-14 15:04:51 UTC"
  },
  {
    "arxiv_id": "2410.08769v1",
    "title": "Efficient Multi-Object Tracking on Edge Devices via Reconstruction-Based Channel Pruning",
    "authors": [
      "Jan Müller",
      "Adrian Pigors"
    ],
    "abstract": "The advancement of multi-object tracking (MOT) technologies presents the dual\nchallenge of maintaining high performance while addressing critical security\nand privacy concerns. In applications such as pedestrian tracking, where\nsensitive personal data is involved, the potential for privacy violations and\ndata misuse becomes a significant issue if data is transmitted to external\nservers. To mitigate these risks, processing data directly on an edge device,\nsuch as a smart camera, has emerged as a viable solution. Edge computing\nensures that sensitive information remains local, thereby aligning with\nstringent privacy principles and significantly reducing network latency.\nHowever, the implementation of MOT on edge devices is not without its\nchallenges. Edge devices typically possess limited computational resources,\nnecessitating the development of highly optimized algorithms capable of\ndelivering real-time performance under these constraints. The disparity between\nthe computational requirements of state-of-the-art MOT algorithms and the\ncapabilities of edge devices emphasizes a significant obstacle. To address\nthese challenges, we propose a neural network pruning method specifically\ntailored to compress complex networks, such as those used in modern MOT\nsystems. This approach optimizes MOT performance by ensuring high accuracy and\nefficiency within the constraints of limited edge devices, such as NVIDIA's\nJetson Orin Nano. By applying our pruning method, we achieve model size\nreductions of up to 70% while maintaining a high level of accuracy and further\nimproving performance on the Jetson Orin Nano, demonstrating the effectiveness\nof our approach for edge computing applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08769v1",
    "published_date": "2024-10-11 12:37:42 UTC",
    "updated_date": "2024-10-11 12:37:42 UTC"
  },
  {
    "arxiv_id": "2410.08766v1",
    "title": "Integrating Supertag Features into Neural Discontinuous Constituent Parsing",
    "authors": [
      "Lukas Mielczarek"
    ],
    "abstract": "Syntactic parsing is essential in natural-language processing, with\nconstituent structure being one widely used description of syntax. Traditional\nviews of constituency demand that constituents consist of adjacent words, but\nthis poses challenges in analysing syntax with non-local dependencies, common\nin languages like German. Therefore, in a number of treebanks like NeGra and\nTIGER for German and DPTB for English, long-range dependencies are represented\nby crossing edges. Various grammar formalisms have been used to describe\ndiscontinuous trees - often with high time complexities for parsing.\nTransition-based parsing aims at reducing this factor by eliminating the need\nfor an explicit grammar. Instead, neural networks are trained to produce trees\ngiven raw text input using supervised learning on large annotated corpora. An\nelegant proposal for a stack-free transition-based parser developed by Coavoux\nand Cohen (2019) successfully allows for the derivation of any discontinuous\nconstituent tree over a sentence in worst-case quadratic time.\n  The purpose of this work is to explore the introduction of supertag\ninformation into transition-based discontinuous constituent parsing. In\nlexicalised grammar formalisms like CCG (Steedman, 1989) informative categories\nare assigned to the words in a sentence and act as the building blocks for\ncomposing the sentence's syntax. These supertags indicate a word's structural\nrole and syntactic relationship with surrounding items. The study examines\nincorporating supertag information by using a dedicated supertagger as\nadditional input for a neural parser (pipeline) and by jointly training a\nneural model for both parsing and supertagging (multi-task). In addition to\nCCG, several other frameworks (LTAG-spinal, LCFRS) and sequence labelling tasks\n(chunking, dependency parsing) will be compared in terms of their suitability\nas auxiliary tasks for parsing.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.FL"
    ],
    "primary_category": "cs.CL",
    "comment": "Bachelor's Thesis. Supervised by Dr. Kilian Evang and Univ.-Prof. Dr.\n  Laura Kallmeyer",
    "pdf_url": "http://arxiv.org/pdf/2410.08766v1",
    "published_date": "2024-10-11 12:28:26 UTC",
    "updated_date": "2024-10-11 12:28:26 UTC"
  },
  {
    "arxiv_id": "2410.08760v2",
    "title": "Unlocking FedNL: Self-Contained Compute-Optimized Implementation",
    "authors": [
      "Konstantin Burlachenko",
      "Peter Richtárik"
    ],
    "abstract": "Federated Learning (FL) is an emerging paradigm that enables intelligent\nagents to collaboratively train Machine Learning (ML) models in a distributed\nmanner, eliminating the need for sharing their local data. The recent work\n(arXiv:2106.02969) introduces a family of Federated Newton Learn (FedNL)\nalgorithms, marking a significant step towards applying second-order methods to\nFL and large-scale optimization. However, the reference FedNL prototype\nexhibits three serious practical drawbacks: (i) It requires 4.8 hours to launch\na single experiment in a sever-grade workstation; (ii) The prototype only\nsimulates multi-node setting; (iii) Prototype integration into\nresource-constrained applications is challenging. To bridge the gap between\ntheory and practice, we present a self-contained implementation of FedNL,\nFedNL-LS, FedNL-PP for single-node and multi-node settings. Our work resolves\nthe aforementioned issues and reduces the wall clock time by x1000. With this\nFedNL outperforms alternatives for training logistic regression in a\nsingle-node -- CVXPY (arXiv:1603.00943), and in a multi-node -- Apache Spark\n(arXiv:1505.06807), Ray/Scikit-Learn (arXiv:1712.05889). Finally, we propose\ntwo practical-orientated compressors for FedNL - adaptive TopLEK and\ncache-aware RandSeqK, which fulfill the theory of FedNL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MS",
      "cs.PF",
      "math.OC",
      "G.4; C.3; I.2.11"
    ],
    "primary_category": "cs.LG",
    "comment": "55 pages, 12 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.08760v2",
    "published_date": "2024-10-11 12:19:18 UTC",
    "updated_date": "2024-12-12 14:43:48 UTC"
  },
  {
    "arxiv_id": "2410.08759v1",
    "title": "Enhancing GNNs with Architecture-Agnostic Graph Transformations: A Systematic Analysis",
    "authors": [
      "Zhifei Li",
      "Gerrit Großmann",
      "Verena Wolf"
    ],
    "abstract": "In recent years, a wide variety of graph neural network (GNN) architectures\nhave emerged, each with its own strengths, weaknesses, and complexities.\nVarious techniques, including rewiring, lifting, and node annotation with\ncentrality values, have been employed as pre-processing steps to enhance GNN\nperformance. However, there are no universally accepted best practices, and the\nimpact of architecture and pre-processing on performance often remains opaque.\n  This study systematically explores the impact of various graph\ntransformations as pre-processing steps on the performance of common GNN\narchitectures across standard datasets. The models are evaluated based on their\nability to distinguish non-isomorphic graphs, referred to as expressivity.\n  Our findings reveal that certain transformations, particularly those\naugmenting node features with centrality measures, consistently improve\nexpressivity. However, these gains come with trade-offs, as methods like graph\nencoding, while enhancing expressivity, introduce numerical inaccuracies\nwidely-used python packages. Additionally, we observe that these pre-processing\ntechniques are limited when addressing complex tasks involving 3-WL and 4-WL\nindistinguishable graphs.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08759v1",
    "published_date": "2024-10-11 12:19:17 UTC",
    "updated_date": "2024-10-11 12:19:17 UTC"
  },
  {
    "arxiv_id": "2410.08740v1",
    "title": "Hespi: A pipeline for automatically detecting information from hebarium specimen sheets",
    "authors": [
      "Robert Turnbull",
      "Emily Fitzgerald",
      "Karen Thompson",
      "Joanne L. Birch"
    ],
    "abstract": "Specimen associated biodiversity data are sought after for biological,\nenvironmental, climate, and conservation sciences. A rate shift is required for\nthe extraction of data from specimen images to eliminate the bottleneck that\nthe reliance on human-mediated transcription of these data represents. We\napplied advanced computer vision techniques to develop the `Hespi' (HErbarium\nSpecimen sheet PIpeline), which extracts a pre-catalogue subset of collection\ndata on the institutional labels on herbarium specimens from their digital\nimages. The pipeline integrates two object detection models; the first detects\nbounding boxes around text-based labels and the second detects bounding boxes\naround text-based data fields on the primary institutional label. The pipeline\nclassifies text-based institutional labels as printed, typed, handwritten, or a\ncombination and applies Optical Character Recognition (OCR) and Handwritten\nText Recognition (HTR) for data extraction. The recognized text is then\ncorrected against authoritative databases of taxon names. The extracted text is\nalso corrected with the aide of a multimodal Large Language Model (LLM). Hespi\naccurately detects and extracts text for test datasets including specimen sheet\nimages from international herbaria. The components of the pipeline are modular\nand users can train their own models with their own data and use them in place\nof the models provided.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08740v1",
    "published_date": "2024-10-11 11:59:40 UTC",
    "updated_date": "2024-10-11 11:59:40 UTC"
  },
  {
    "arxiv_id": "2410.19756v1",
    "title": "A SAM based Tool for Semi-Automatic Food Annotation",
    "authors": [
      "Lubnaa Abdur Rahman",
      "Ioannis Papathanail",
      "Lorenzo Brigato",
      "Stavroula Mougiakakou"
    ],
    "abstract": "The advancement of artificial intelligence (AI) in food and nutrition\nresearch is hindered by a critical bottleneck: the lack of annotated food data.\nDespite the rise of highly efficient AI models designed for tasks such as food\nsegmentation and classification, their practical application might necessitate\nproficiency in AI and machine learning principles, which can act as a challenge\nfor non-AI experts in the field of nutritional sciences. Alternatively, it\nhighlights the need to translate AI models into user-friendly tools that are\naccessible to all. To address this, we present a demo of a semi-automatic food\nimage annotation tool leveraging the Segment Anything Model (SAM). The tool\nenables prompt-based food segmentation via user interactions, promoting user\nengagement and allowing them to further categorise food items within meal\nimages and specify weight/volume if necessary. Additionally, we release a\nfine-tuned version of SAM's mask decoder, dubbed MealSAM, with the ViT-B\nbackbone tailored specifically for food image segmentation. Our objective is\nnot only to contribute to the field by encouraging participation,\ncollaboration, and the gathering of more annotated food data but also to make\nAI technology available for a broader audience by translating AI into practical\ntools.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted Demo Paper - ECAI 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.19756v1",
    "published_date": "2024-10-11 11:50:10 UTC",
    "updated_date": "2024-10-11 11:50:10 UTC"
  },
  {
    "arxiv_id": "2410.08731v1",
    "title": "Developing a Pragmatic Benchmark for Assessing Korean Legal Language Understanding in Large Language Models",
    "authors": [
      "Yeeun Kim",
      "Young Rok Choi",
      "Eunkyung Choi",
      "Jinhwan Choi",
      "Hai Jin Park",
      "Wonseok Hwang"
    ],
    "abstract": "Large language models (LLMs) have demonstrated remarkable performance in the\nlegal domain, with GPT-4 even passing the Uniform Bar Exam in the U.S. However\ntheir efficacy remains limited for non-standardized tasks and tasks in\nlanguages other than English. This underscores the need for careful evaluation\nof LLMs within each legal system before application. Here, we introduce KBL, a\nbenchmark for assessing the Korean legal language understanding of LLMs,\nconsisting of (1) 7 legal knowledge tasks (510 examples), (2) 4 legal reasoning\ntasks (288 examples), and (3) the Korean bar exam (4 domains, 53 tasks, 2,510\nexamples). First two datasets were developed in close collaboration with\nlawyers to evaluate LLMs in practical scenarios in a certified manner.\nFurthermore, considering legal practitioners' frequent use of extensive legal\ndocuments for research, we assess LLMs in both a closed book setting, where\nthey rely solely on internal knowledge, and a retrieval-augmented generation\n(RAG) setting, using a corpus of Korean statutes and precedents. The results\nindicate substantial room and opportunities for improvement.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.08731v1",
    "published_date": "2024-10-11 11:41:02 UTC",
    "updated_date": "2024-10-11 11:41:02 UTC"
  },
  {
    "arxiv_id": "2410.08728v1",
    "title": "From N-grams to Pre-trained Multilingual Models For Language Identification",
    "authors": [
      "Thapelo Sindane",
      "Vukosi Marivate"
    ],
    "abstract": "In this paper, we investigate the use of N-gram models and Large Pre-trained\nMultilingual models for Language Identification (LID) across 11 South African\nlanguages. For N-gram models, this study shows that effective data size\nselection remains crucial for establishing effective frequency distributions of\nthe target languages, that efficiently model each language, thus, improving\nlanguage ranking. For pre-trained multilingual models, we conduct extensive\nexperiments covering a diverse set of massively pre-trained multilingual (PLM)\nmodels -- mBERT, RemBERT, XLM-r, and Afri-centric multilingual models --\nAfriBERTa, Afro-XLMr, AfroLM, and Serengeti. We further compare these models\nwith available large-scale Language Identification tools: Compact Language\nDetector v3 (CLD V3), AfroLID, GlotLID, and OpenLID to highlight the importance\nof focused-based LID. From these, we show that Serengeti is a superior model\nacross models: N-grams to Transformers on average. Moreover, we propose a\nlightweight BERT-based LID model (za_BERT_lid) trained with NHCLT + Vukzenzele\ncorpus, which performs on par with our best-performing Afri-centric models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The paper has been accepted at The 4th International Conference on\n  Natural Language Processing for Digital Humanities (NLP4DH 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.08728v1",
    "published_date": "2024-10-11 11:35:57 UTC",
    "updated_date": "2024-10-11 11:35:57 UTC"
  },
  {
    "arxiv_id": "2410.09129v1",
    "title": "nextlocllm: next location prediction using LLMs",
    "authors": [
      "Shuai Liu",
      "Ning Cao",
      "Yile Chen",
      "Yue Jiang",
      "Gao Cong"
    ],
    "abstract": "Next location prediction is a critical task in human mobility analysis and\nserves as a foundation for various downstream applications. Existing methods\ntypically rely on discrete IDs to represent locations, which inherently\noverlook spatial relationships and cannot generalize across cities. In this\npaper, we propose NextLocLLM, which leverages the advantages of large language\nmodels (LLMs) in processing natural language descriptions and their strong\ngeneralization capabilities for next location prediction. Specifically, instead\nof using IDs, NextLocLLM encodes locations based on continuous spatial\ncoordinates to better model spatial relationships. These coordinates are\nfurther normalized to enable robust cross-city generalization. Another\nhighlight of NextlocLLM is its LLM-enhanced POI embeddings. It utilizes LLMs'\nability to encode each POI category's natural language description into\nembeddings. These embeddings are then integrated via nonlinear projections to\nform this LLM-enhanced POI embeddings, effectively capturing locations'\nfunctional attributes. Furthermore, task and data prompt prefix, together with\ntrajectory embeddings, are incorporated as input for partly-frozen LLM\nbackbone. NextLocLLM further introduces prediction retrieval module to ensure\nstructural consistency in prediction. Experiments show that NextLocLLM\noutperforms existing models in next location prediction, excelling in both\nsupervised and zero-shot settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.09129v1",
    "published_date": "2024-10-11 10:59:14 UTC",
    "updated_date": "2024-10-11 10:59:14 UTC"
  },
  {
    "arxiv_id": "2410.08703v2",
    "title": "On the token distance modeling ability of higher RoPE attention dimension",
    "authors": [
      "Xiangyu Hong",
      "Che Jiang",
      "Biqing Qi",
      "Fandong Meng",
      "Mo Yu",
      "Bowen Zhou",
      "Jie Zhou"
    ],
    "abstract": "Length extrapolation algorithms based on Rotary position embedding (RoPE)\nhave shown promising results in extending the context length of language\nmodels. However, understanding how position embedding can capture longer-range\ncontextual information remains elusive. Based on the intuition that different\ndimensions correspond to different frequency of changes in RoPE encoding, we\nconducted a dimension-level analysis to investigate the correlation between a\nhidden dimension of an attention head and its contribution to capturing\nlong-distance dependencies. Using our correlation metric, we identified a\nparticular type of attention heads, which we named Positional Heads, from\nvarious length-extrapolated models. These heads exhibit a strong focus on\nlong-range information interaction and play a pivotal role in long input\nprocessing, as evidence by our ablation. We further demonstrate the correlation\nbetween the efficiency of length extrapolation and the extension of the\nhigh-dimensional attention allocation of these heads. The identification of\nPositional Heads provides insights for future research in long-text\ncomprehension.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to EMNLP 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2410.08703v2",
    "published_date": "2024-10-11 10:47:02 UTC",
    "updated_date": "2024-10-21 08:49:18 UTC"
  },
  {
    "arxiv_id": "2410.08688v2",
    "title": "Chain-of-Restoration: Multi-Task Image Restoration Models are Zero-Shot Step-by-Step Universal Image Restorers",
    "authors": [
      "Jin Cao",
      "Deyu Meng",
      "Xiangyong Cao"
    ],
    "abstract": "Despite previous image restoration (IR) methods have often concentrated on\nisolated degradations, recent research has increasingly focused on addressing\ncomposite degradations involving a complex combination of multiple isolated\ndegradations. However, current IR methods for composite degradations require\nbuilding training data that contain an exponential number of possible\ndegradation combinations, which brings in a significant burden. To alleviate\nthis issue, this paper proposes a new task setting, i.e. Universal Image\nRestoration (UIR). Specifically, UIR doesn't require training on all the\ndegradation combinations but only on a set of degradation bases and then\nremoving any degradation that these bases can potentially compose in a\nzero-shot manner. Inspired by the Chain-of-Thought that prompts large language\nmodels (LLMs) to address problems step-by-step, we propose Chain-of-Restoration\n(CoR) mechanism, which instructs models to remove unknown composite\ndegradations step-by-step. By integrating a simple Degradation Discriminator\ninto pre-trained multi-task models, CoR facilitates the process where models\nremove one degradation basis per step, continuing this process until the image\nis fully restored from the unknown composite degradation. Extensive experiments\nshow that CoR can significantly improve model performance in removing composite\ndegradations, achieving comparable or better results than those\nstate-of-the-art (SoTA) methods trained on all degradations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "code: https://github.com/toummHus/Chain-of-Restoration",
    "pdf_url": "http://arxiv.org/pdf/2410.08688v2",
    "published_date": "2024-10-11 10:21:42 UTC",
    "updated_date": "2024-12-04 04:28:41 UTC"
  },
  {
    "arxiv_id": "2410.08669v2",
    "title": "SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction",
    "authors": [
      "Yang Zhou",
      "Hao Shao",
      "Letian Wang",
      "Steven L. Waslander",
      "Hongsheng Li",
      "Yu Liu"
    ],
    "abstract": "Predicting the future motion of surrounding agents is essential for\nautonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed\nenvironments. However, the scarcity of large-scale driving datasets has\nhindered the development of robust and generalizable motion prediction models,\nlimiting their ability to capture complex interactions and road geometries.\nInspired by recent advances in natural language processing (NLP) and computer\nvision (CV), self-supervised learning (SSL) has gained significant attention in\nthe motion prediction community for learning rich and transferable scene\nrepresentations. Nonetheless, existing pre-training methods for motion\nprediction have largely focused on specific model architectures and single\ndataset, limiting their scalability and generalizability. To address these\nchallenges, we propose SmartPretrain, a general and scalable SSL framework for\nmotion prediction that is both model-agnostic and dataset-agnostic. Our\napproach integrates contrastive and reconstructive SSL, leveraging the\nstrengths of both generative and discriminative paradigms to effectively\nrepresent spatiotemporal evolution and interactions without imposing\narchitectural constraints. Additionally, SmartPretrain employs a\ndataset-agnostic scenario sampling strategy that integrates multiple datasets,\nenhancing data volume, diversity, and robustness. Extensive experiments on\nmultiple datasets demonstrate that SmartPretrain consistently improves the\nperformance of state-of-the-art prediction models across datasets, data splits\nand main metrics. For instance, SmartPretrain significantly reduces the\nMissRate of Forecast-MAE by 10.6%. These results highlight SmartPretrain's\neffectiveness as a unified, scalable solution for motion prediction, breaking\nfree from the limitations of the small-data regime. Codes are available at\nhttps://github.com/youngzhou1999/SmartPretrain",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "Camera-ready version for ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08669v2",
    "published_date": "2024-10-11 09:52:26 UTC",
    "updated_date": "2025-02-27 15:20:00 UTC"
  },
  {
    "arxiv_id": "2410.09128v1",
    "title": "TIGER: Temporally Improved Graph Entity Linker",
    "authors": [
      "Pengyu Zhang",
      "Congfeng Cao",
      "Paul Groth"
    ],
    "abstract": "Knowledge graphs change over time, for example, when new entities are\nintroduced or entity descriptions change. This impacts the performance of\nentity linking, a key task in many uses of knowledge graphs such as web search\nand recommendation. Specifically, entity linking models exhibit temporal\ndegradation - their performance decreases the further a knowledge graph moves\nfrom its original state on which an entity linking model was trained. To tackle\nthis challenge, we introduce \\textbf{TIGER}: a \\textbf{T}emporally\n\\textbf{I}mproved \\textbf{G}raph \\textbf{E}ntity Linke\\textbf{r}. By\nincorporating structural information between entities into the model, we\nenhance the learned representation, making entities more distinguishable over\ntime. The core idea is to integrate graph-based information into text-based\ninformation, from which both distinct and shared embeddings are based on an\nentity's feature and structural relationships and their interaction.\nExperiments on three datasets show that our model can effectively prevent\ntemporal degradation, demonstrating a 16.24\\% performance boost over the\nstate-of-the-art in a temporal setting when the time gap is one year and an\nimprovement to 20.93\\% as the gap expands to three years. The code and data are\nmade available at\n\\url{https://github.com/pengyu-zhang/TIGER-Temporally-Improved-Graph-Entity-Linker}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09128v1",
    "published_date": "2024-10-11 09:44:33 UTC",
    "updated_date": "2024-10-11 09:44:33 UTC"
  },
  {
    "arxiv_id": "2410.08666v1",
    "title": "DeltaDQ: Ultra-High Delta Compression for Fine-Tuned LLMs via Group-wise Dropout and Separate Quantization",
    "authors": [
      "Yanfeng Jiang",
      "Zelan Yang",
      "Bohua Chen",
      "Shen Li",
      "Yong Li",
      "Tao Li"
    ],
    "abstract": "Large language models achieve exceptional performance on various downstream\ntasks through supervised fine-tuning. However, the diversity of downstream\ntasks and practical requirements makes deploying multiple full-parameter\nfine-tuned models challenging. Current methods that compress the delta weight\nstruggle to achieve ultra-high compression, failing to minimize the deployment\noverhead. To address the above issue, we propose a novel distribution-driven\ndelta compression framework DeltaDQ, which utilizes Group-wise Dropout and\nSeparate Quantization to achieve ultra-high compression for the delta weight.\nWe have observed that the matrix-computed intermediate results for the delta\nweight exhibit extremely small variance and min-max range characteristics,\nreferred to as Balanced Intermediate Results. Exploiting this phenomenon, we\nintroduce Group-wise Dropout to perform dropout on the delta weight using an\noptimal group size. Furthermore, using Separate Quantization, sparse weights\nare quantized and decomposed to achieve a lower bit. Experimental results show\nthat DeltaDQ achieves 16x compression with improved accuracy compared to\nbaselines for WizardMath and WizardCoder models across different parameter\nscales. Moreover, DeltaDQ demonstrates the ability for ultra-high compression\nratio, achieving 128x compression for the WizardMath-7B model and 512x\ncompression for the WizardMath-70B model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08666v1",
    "published_date": "2024-10-11 09:44:16 UTC",
    "updated_date": "2024-10-11 09:44:16 UTC"
  },
  {
    "arxiv_id": "2410.08665v1",
    "title": "DistDD: Distributed Data Distillation Aggregation through Gradient Matching",
    "authors": [
      "Peiran Wang",
      "Haohan Wang"
    ],
    "abstract": "In this paper, we introduce DistDD, a novel approach within the federated\nlearning framework that reduces the need for repetitive communication by\ndistilling data directly on clients' devices. Unlike traditional federated\nlearning that requires iterative model updates across nodes, DistDD facilitates\na one-time distillation process that extracts a global distilled dataset,\nmaintaining the privacy standards of federated learning while significantly\ncutting down communication costs. By leveraging the DistDD's distilled dataset,\nthe developers of the FL can achieve just-in-time parameter tuning and neural\narchitecture search over FL without repeating the whole FL process multiple\ntimes. We provide a detailed convergence proof of the DistDD algorithm,\nreinforcing its mathematical stability and reliability for practical\napplications. Our experiments demonstrate the effectiveness and robustness of\nDistDD, particularly in non-i.i.d. and mislabeled data scenarios, showcasing\nits potential to handle complex real-world data challenges distinctively from\nconventional federated learning methods. We also evaluate DistDD's application\nin the use case and prove its effectiveness and communication-savings in the\nNAS use case.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08665v1",
    "published_date": "2024-10-11 09:43:35 UTC",
    "updated_date": "2024-10-11 09:43:35 UTC"
  },
  {
    "arxiv_id": "2410.09127v1",
    "title": "CYCLE: Cross-Year Contrastive Learning in Entity-Linking",
    "authors": [
      "Pengyu Zhang",
      "Congfeng Cao",
      "Klim Zaporojets",
      "Paul Groth"
    ],
    "abstract": "Knowledge graphs constantly evolve with new entities emerging, existing\ndefinitions being revised, and entity relationships changing. These changes\nlead to temporal degradation in entity linking models, characterized as a\ndecline in model performance over time. To address this issue, we propose\nleveraging graph relationships to aggregate information from neighboring\nentities across different time periods. This approach enhances the ability to\ndistinguish similar entities over time, thereby minimizing the impact of\ntemporal degradation. We introduce \\textbf{CYCLE}: \\textbf{C}ross-\\textbf{Y}ear\n\\textbf{C}ontrastive \\textbf{L}earning for \\textbf{E}ntity-Linking. This model\nemploys a novel graph contrastive learning method to tackle temporal\nperformance degradation in entity linking tasks. Our contrastive learning\nmethod treats newly added graph relationships as \\textit{positive} samples and\nnewly removed ones as \\textit{negative} samples. This approach helps our model\neffectively prevent temporal degradation, achieving a 13.90\\% performance\nimprovement over the state-of-the-art from 2023 when the time gap is one year,\nand a 17.79\\% improvement as the gap expands to three years. Further analysis\nshows that CYCLE is particularly robust for low-degree entities, which are less\nresistant to temporal degradation due to their sparse connectivity, making them\nparticularly suitable for our method. The code and data are made available at\n\\url{https://github.com/pengyu-zhang/CYCLE-Cross-Year-Contrastive-Learning-in-Entity-Linking}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09127v1",
    "published_date": "2024-10-11 09:41:54 UTC",
    "updated_date": "2024-10-11 09:41:54 UTC"
  },
  {
    "arxiv_id": "2410.08660v3",
    "title": "RePD: Defending Jailbreak Attack through a Retrieval-based Prompt Decomposition Process",
    "authors": [
      "Peiran Wang",
      "Xiaogeng Liu",
      "Chaowei Xiao"
    ],
    "abstract": "In this study, we introduce RePD, an innovative attack Retrieval-based Prompt\nDecomposition framework designed to mitigate the risk of jailbreak attacks on\nlarge language models (LLMs). Despite rigorous pretraining and finetuning\nfocused on ethical alignment, LLMs are still susceptible to jailbreak exploits.\nRePD operates on a one-shot learning model, wherein it accesses a database of\npre-collected jailbreak prompt templates to identify and decompose harmful\ninquiries embedded within user prompts. This process involves integrating the\ndecomposition of the jailbreak prompt into the user's original query into a\none-shot learning example to effectively teach the LLM to discern and separate\nmalicious components. Consequently, the LLM is equipped to first neutralize any\npotentially harmful elements before addressing the user's prompt in a manner\nthat aligns with its ethical guidelines. RePD is versatile and compatible with\na variety of open-source LLMs acting as agents. Through comprehensive\nexperimentation with both harmful and benign prompts, we have demonstrated the\nefficacy of our proposed RePD in enhancing the resilience of LLMs against\njailbreak attacks, without compromising their performance in responding to\ntypical user requests.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08660v3",
    "published_date": "2024-10-11 09:39:11 UTC",
    "updated_date": "2024-11-29 02:35:47 UTC"
  },
  {
    "arxiv_id": "2410.09126v1",
    "title": "Convolutional Neural Network Design and Evaluation for Real-Time Multivariate Time Series Fault Detection in Spacecraft Attitude Sensors",
    "authors": [
      "Riccardo Gallon",
      "Fabian Schiemenz",
      "Alessandra Menicucci",
      "Eberhard Gill"
    ],
    "abstract": "Traditional anomaly detection techniques onboard satellites are based on\nreliable, yet limited, thresholding mechanisms which are designed to monitor\nunivariate signals and trigger recovery actions according to specific European\nCooperation for Space Standardization (ECSS) standards. However, Artificial\nIntelligence-based Fault Detection, Isolation and Recovery (FDIR) solutions\nhave recently raised with the prospect to overcome the limitations of these\nstandard methods, expanding the range of detectable failures and improving\nresponse times. This paper presents a novel approach to detecting stuck values\nwithin the Accelerometer and Inertial Measurement Unit of a drone-like\nspacecraft for the exploration of Small Solar System Bodies (SSSB), leveraging\na multi-channel Convolutional Neural Network (CNN) to perform multi-target\nclassification and independently detect faults in the sensors. Significant\nattention has been dedicated to ensuring the compatibility of the algorithm\nwithin the onboard FDIR system, representing a step forward to the in-orbit\nvalidation of a technology that remains experimental until its robustness is\nthoroughly proven. An integration methodology is proposed to enable the network\nto effectively detect anomalies and trigger recovery actions at the system\nlevel. The detection performances and the capability of the algorithm in\nreaction triggering are evaluated employing a set of custom-defined detection\nand system metrics, showing the outstanding performances of the algorithm in\nperforming its FDIR task.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "submitted to Advances in Space Research",
    "pdf_url": "http://arxiv.org/pdf/2410.09126v1",
    "published_date": "2024-10-11 09:36:38 UTC",
    "updated_date": "2024-10-11 09:36:38 UTC"
  },
  {
    "arxiv_id": "2410.08656v2",
    "title": "radarODE-MTL: A Multi-Task Learning Framework with Eccentric Gradient Alignment for Robust Radar-Based ECG Reconstruction",
    "authors": [
      "Yuanyuan Zhang",
      "Rui Yang",
      "Yutao Yue",
      "Eng Gee Lim"
    ],
    "abstract": "Millimeter-wave radar is promising to provide robust and accurate vital sign\nmonitoring in an unobtrusive manner. However, the radar signal might be\ndistorted in propagation by ambient noise or random body movement, ruining the\nsubtle cardiac activities and destroying the vital sign recovery. In\nparticular, the recovery of electrocardiogram (ECG) signal heavily relies on\nthe deep-learning model and is sensitive to noise. Therefore, this work\ncreatively deconstructs the radar-based ECG recovery into three individual\ntasks and proposes a multi-task learning (MTL) framework, radarODE-MTL, to\nincrease the robustness against consistent and abrupt noises. In addition, to\nalleviate the potential conflicts in optimizing individual tasks, a novel\nmulti-task optimization strategy, eccentric gradient alignment (EGA), is\nproposed to dynamically trim the task-specific gradients based on task\ndifficulties in orthogonal space. The proposed radarODE-MTL with EGA is\nevaluated on the public dataset with prominent improvements in accuracy, and\nthe performance remains consistent under noises. The experimental results\nindicate that radarODE-MTL could reconstruct accurate ECG signals robustly from\nradar signals and imply the application prospect in real-life situations. The\ncode is available at: http://github.com/ZYY0844/radarODE-MTL.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08656v2",
    "published_date": "2024-10-11 09:28:09 UTC",
    "updated_date": "2025-05-06 08:36:57 UTC"
  },
  {
    "arxiv_id": "2410.09125v1",
    "title": "Training on Fake Labels: Mitigating Label Leakage in Split Learning via Secure Dimension Transformation",
    "authors": [
      "Yukun Jiang",
      "Peiran Wang",
      "Chengguo Lin",
      "Ziyue Huang",
      "Yong Cheng"
    ],
    "abstract": "Two-party split learning has emerged as a popular paradigm for vertical\nfederated learning. To preserve the privacy of the label owner, split learning\nutilizes a split model, which only requires the exchange of intermediate\nrepresentations (IRs) based on the inputs and gradients for each IR between two\nparties during the learning process. However, split learning has recently been\nproven to survive label inference attacks. Though several defense methods could\nbe adopted, they either have limited defensive performance or significantly\nnegatively impact the original mission. In this paper, we propose a novel\ntwo-party split learning method to defend against existing label inference\nattacks while maintaining the high utility of the learned models. Specifically,\nwe first craft a dimension transformation module, SecDT, which could achieve\nbidirectional mapping between original labels and increased K-class labels to\nmitigate label leakage from the directional perspective. Then, a gradient\nnormalization algorithm is designed to remove the magnitude divergence of\ngradients from different classes. We propose a softmax-normalized Gaussian\nnoise to mitigate privacy leakage and make our K unknowable to adversaries. We\nconducted experiments on real-world datasets, including two\nbinary-classification datasets (Avazu and Criteo) and three\nmulti-classification datasets (MNIST, FashionMNIST, CIFAR-10); we also\nconsidered current attack schemes, including direction, norm, spectral, and\nmodel completion attacks. The detailed experiments demonstrate our proposed\nmethod's effectiveness and superiority over existing approaches. For instance,\non the Avazu dataset, the attack AUC of evaluated four prominent attacks could\nbe reduced by 0.4532+-0.0127.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09125v1",
    "published_date": "2024-10-11 09:25:21 UTC",
    "updated_date": "2024-10-11 09:25:21 UTC"
  },
  {
    "arxiv_id": "2410.08643v1",
    "title": "SOAK: Same/Other/All K-fold cross-validation for estimating similarity of patterns in data subsets",
    "authors": [
      "Toby Dylan Hocking",
      "Gabrielle Thibault",
      "Cameron Scott Bodine",
      "Paul Nelson Arellano",
      "Alexander F Shenkin",
      "Olivia Jasmine Lindly"
    ],
    "abstract": "In many real-world applications of machine learning, we are interested to\nknow if it is possible to train on the data that we have gathered so far, and\nobtain accurate predictions on a new test data subset that is qualitatively\ndifferent in some respect (time period, geographic region, etc). Another\nquestion is whether data subsets are similar enough so that it is beneficial to\ncombine subsets during model training. We propose SOAK, Same/Other/All K-fold\ncross-validation, a new method which can be used to answer both questions. SOAK\nsystematically compares models which are trained on different subsets of data,\nand then used for prediction on a fixed test subset, to estimate the similarity\nof learnable/predictable patterns in data subsets. We show results of using\nSOAK on six new real data sets (with geographic/temporal subsets, to check if\npredictions are accurate on new subsets), 3 image pair data sets (subsets are\ndifferent image types, to check that we get smaller prediction error on similar\nimages), and 11 benchmark data sets with predefined train/test splits (to check\nsimilarity of predefined splits).",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08643v1",
    "published_date": "2024-10-11 09:10:39 UTC",
    "updated_date": "2024-10-11 09:10:39 UTC"
  },
  {
    "arxiv_id": "2410.08635v1",
    "title": "Efficient line search for optimizing Area Under the ROC Curve in gradient descent",
    "authors": [
      "Jadon Fowler",
      "Toby Dylan Hocking"
    ],
    "abstract": "Receiver Operating Characteristic (ROC) curves are useful for evaluation in\nbinary classification and changepoint detection, but difficult to use for\nlearning since the Area Under the Curve (AUC) is piecewise constant (gradient\nzero almost everywhere). Recently the Area Under Min (AUM) of false positive\nand false negative rates has been proposed as a differentiable surrogate for\nAUC. In this paper we study the piecewise linear/constant nature of the\nAUM/AUC, and propose new efficient path-following algorithms for choosing the\nlearning rate which is optimal for each step of gradient descent (line search),\nwhen optimizing a linear model. Remarkably, our proposed line search algorithm\nhas the same log-linear asymptotic time complexity as gradient descent with\nconstant step size, but it computes a complete representation of the AUM/AUC as\na function of step size. In our empirical study of binary classification\nproblems, we verify that our proposed algorithm is fast and exact; in\nchangepoint detection problems we show that the proposed algorithm is just as\naccurate as grid search, but faster.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08635v1",
    "published_date": "2024-10-11 08:59:06 UTC",
    "updated_date": "2024-10-11 08:59:06 UTC"
  },
  {
    "arxiv_id": "2410.08632v1",
    "title": "Words as Beacons: Guiding RL Agents with High-Level Language Prompts",
    "authors": [
      "Unai Ruiz-Gonzalez",
      "Alain Andres",
      "Pedro G. Bascoy",
      "Javier Del Ser"
    ],
    "abstract": "Sparse reward environments in reinforcement learning (RL) pose significant\nchallenges for exploration, often leading to inefficient or incomplete learning\nprocesses. To tackle this issue, this work proposes a teacher-student RL\nframework that leverages Large Language Models (LLMs) as \"teachers\" to guide\nthe agent's learning process by decomposing complex tasks into subgoals. Due to\ntheir inherent capability to understand RL environments based on a textual\ndescription of structure and purpose, LLMs can provide subgoals to accomplish\nthe task defined for the environment in a similar fashion to how a human would\ndo. In doing so, three types of subgoals are proposed: positional targets\nrelative to the agent, object representations, and language-based instructions\ngenerated directly by the LLM. More importantly, we show that it is possible to\nquery the LLM only during the training phase, enabling agents to operate within\nthe environment without any LLM intervention. We assess the performance of this\nproposed framework by evaluating three state-of-the-art open-source LLMs\n(Llama, DeepSeek, Qwen) eliciting subgoals across various procedurally\ngenerated environment of the MiniGrid benchmark. Experimental results\ndemonstrate that this curriculum-based approach accelerates learning and\nenhances exploration in complex tasks, achieving up to 30 to 200 times faster\nconvergence in training steps compared to recent baselines designed for sparse\nreward environments.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08632v1",
    "published_date": "2024-10-11 08:54:45 UTC",
    "updated_date": "2024-10-11 08:54:45 UTC"
  },
  {
    "arxiv_id": "2410.08631v2",
    "title": "CryoFM: A Flow-based Foundation Model for Cryo-EM Densities",
    "authors": [
      "Yi Zhou",
      "Yilai Li",
      "Jing Yuan",
      "Quanquan Gu"
    ],
    "abstract": "Cryo-electron microscopy (cryo-EM) is a powerful technique in structural\nbiology and drug discovery, enabling the study of biomolecules at high\nresolution. Significant advancements by structural biologists using cryo-EM\nhave led to the production of over 38,626 protein density maps at various\nresolutions1. However, cryo-EM data processing algorithms have yet to fully\nbenefit from our knowledge of biomolecular density maps, with only a few recent\nmodels being data-driven but limited to specific tasks. In this study, we\npresent CryoFM, a foundation model designed as a generative model, learning the\ndistribution of high-quality density maps and generalizing effectively to\ndownstream tasks. Built on flow matching, CryoFM is trained to accurately\ncapture the prior distribution of biomolecular density maps. Furthermore, we\nintroduce a flow posterior sampling method that leverages CRYOFM as a flexible\nprior for several downstream tasks in cryo-EM and cryo-electron tomography\n(cryo-ET) without the need for fine-tuning, achieving state-of-the-art\nperformance on most tasks and demonstrating its potential as a foundational\nmodel for broader applications in these fields.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.CE",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08631v2",
    "published_date": "2024-10-11 08:53:58 UTC",
    "updated_date": "2024-12-04 06:58:26 UTC"
  },
  {
    "arxiv_id": "2410.08613v1",
    "title": "Cross-Modal Bidirectional Interaction Model for Referring Remote Sensing Image Segmentation",
    "authors": [
      "Zhe Dong",
      "Yuzhe Sun",
      "Yanfeng Gu",
      "Tianzhu Liu"
    ],
    "abstract": "Given a natural language expression and a remote sensing image, the goal of\nreferring remote sensing image segmentation (RRSIS) is to generate a\npixel-level mask of the target object identified by the referring expression.\nIn contrast to natural scenarios, expressions in RRSIS often involve complex\ngeospatial relationships, with target objects of interest that vary\nsignificantly in scale and lack visual saliency, thereby increasing the\ndifficulty of achieving precise segmentation. To address the aforementioned\nchallenges, a novel RRSIS framework is proposed, termed the cross-modal\nbidirectional interaction model (CroBIM). Specifically, a context-aware prompt\nmodulation (CAPM) module is designed to integrate spatial positional\nrelationships and task-specific knowledge into the linguistic features, thereby\nenhancing the ability to capture the target object. Additionally, a\nlanguage-guided feature aggregation (LGFA) module is introduced to integrate\nlinguistic information into multi-scale visual features, incorporating an\nattention deficit compensation mechanism to enhance feature aggregation.\nFinally, a mutual-interaction decoder (MID) is designed to enhance cross-modal\nfeature alignment through cascaded bidirectional cross-attention, thereby\nenabling precise segmentation mask prediction. To further forster the research\nof RRSIS, we also construct RISBench, a new large-scale benchmark dataset\ncomprising 52,472 image-language-label triplets. Extensive benchmarking on\nRISBench and two other prevalent datasets demonstrates the superior performance\nof the proposed CroBIM over existing state-of-the-art (SOTA) methods. The\nsource code for CroBIM and the RISBench dataset will be publicly available at\nhttps://github.com/HIT-SIRS/CroBIM",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08613v1",
    "published_date": "2024-10-11 08:28:04 UTC",
    "updated_date": "2024-10-11 08:28:04 UTC"
  },
  {
    "arxiv_id": "2410.08612v1",
    "title": "Synth-SONAR: Sonar Image Synthesis with Enhanced Diversity and Realism via Dual Diffusion Models and GPT Prompting",
    "authors": [
      "Purushothaman Natarajan",
      "Kamal Basha",
      "Athira Nambiar"
    ],
    "abstract": "Sonar image synthesis is crucial for advancing applications in underwater\nexploration, marine biology, and defence. Traditional methods often rely on\nextensive and costly data collection using sonar sensors, jeopardizing data\nquality and diversity. To overcome these limitations, this study proposes a new\nsonar image synthesis framework, Synth-SONAR leveraging diffusion models and\nGPT prompting. The key novelties of Synth-SONAR are threefold: First, by\nintegrating Generative AI-based style injection techniques along with publicly\navailable real/simulated data, thereby producing one of the largest sonar data\ncorpus for sonar research. Second, a dual text-conditioning sonar diffusion\nmodel hierarchy synthesizes coarse and fine-grained sonar images with enhanced\nquality and diversity. Third, high-level (coarse) and low-level (detailed)\ntext-based sonar generation methods leverage advanced semantic information\navailable in visual language models (VLMs) and GPT-prompting. During inference,\nthe method generates diverse and realistic sonar images from textual prompts,\nbridging the gap between textual descriptions and sonar image generation. This\nmarks the application of GPT-prompting in sonar imagery for the first time, to\nthe best of our knowledge. Synth-SONAR achieves state-of-the-art results in\nproducing high-quality synthetic sonar datasets, significantly enhancing their\ndiversity and realism.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "94A08 (Primary) 68T45, 68U10 (Secondary)",
      "I.2.0; I.4.5"
    ],
    "primary_category": "cs.CV",
    "comment": "12 pages, 5 tables and 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.08612v1",
    "published_date": "2024-10-11 08:27:25 UTC",
    "updated_date": "2024-10-11 08:27:25 UTC"
  },
  {
    "arxiv_id": "2410.08611v1",
    "title": "Conjugated Semantic Pool Improves OOD Detection with Pre-trained Vision-Language Models",
    "authors": [
      "Mengyuan Chen",
      "Junyu Gao",
      "Changsheng Xu"
    ],
    "abstract": "A straightforward pipeline for zero-shot out-of-distribution (OOD) detection\ninvolves selecting potential OOD labels from an extensive semantic pool and\nthen leveraging a pre-trained vision-language model to perform classification\non both in-distribution (ID) and OOD labels. In this paper, we theorize that\nenhancing performance requires expanding the semantic pool, while increasing\nthe expected probability of selected OOD labels being activated by OOD samples,\nand ensuring low mutual dependence among the activations of these OOD labels. A\nnatural expansion manner is to adopt a larger lexicon; however, the inevitable\nintroduction of numerous synonyms and uncommon words fails to meet the above\nrequirements, indicating that viable expansion manners move beyond merely\nselecting words from a lexicon. Since OOD detection aims to correctly classify\ninput images into ID/OOD class groups, we can \"make up\" OOD label candidates\nwhich are not standard class names but beneficial for the process. Observing\nthat the original semantic pool is comprised of unmodified specific class\nnames, we correspondingly construct a conjugated semantic pool (CSP) consisting\nof modified superclass names, each serving as a cluster center for samples\nsharing similar properties across different categories. Consistent with our\nestablished theory, expanding OOD label candidates with the CSP satisfies the\nrequirements and outperforms existing works by 7.89% in FPR95. Codes are\navailable in https://github.com/MengyuanChen21/NeurIPS2024-CSP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "28 pages, accepted by NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.08611v1",
    "published_date": "2024-10-11 08:24:11 UTC",
    "updated_date": "2024-10-11 08:24:11 UTC"
  },
  {
    "arxiv_id": "2410.08608v1",
    "title": "Text-To-Image with Generative Adversarial Networks",
    "authors": [
      "Mehrshad Momen-Tayefeh"
    ],
    "abstract": "Generating realistic images from human texts is one of the most challenging\nproblems in the field of computer vision (CV). The meaning of descriptions\ngiven can be roughly reflected by existing text-to-image approaches. In this\npaper, our main purpose is to propose a brief comparison between five different\nmethods base on the Generative Adversarial Networks (GAN) to make image from\nthe text. In addition, each model architectures synthesis images with different\nresolution. Furthermore, the best and worst obtained resolutions is 64*64,\n256*256 respectively. However, we checked and compared some metrics that\nintroduce the accuracy of each model. Also, by doing this study, we found out\nthe best model for this problem by comparing these different approaches\nessential metrics.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08608v1",
    "published_date": "2024-10-11 08:16:35 UTC",
    "updated_date": "2024-10-11 08:16:35 UTC"
  },
  {
    "arxiv_id": "2410.08597v1",
    "title": "What killed the cat? Towards a logical formalization of curiosity (and suspense, and surprise) in narratives",
    "authors": [
      "Florence Dupin de Saint-Cyr",
      "Anne-Gwenn Bosser",
      "Benjamin Callac",
      "Eric Maisel"
    ],
    "abstract": "We provide a unified framework in which the three emotions at the heart of\nnarrative tension (curiosity, suspense and surprise) are formalized. This\nframework is built on nonmonotonic reasoning which allows us to compactly\nrepresent the default behavior of the world and to simulate the affective\nevolution of an agent receiving a story. After formalizing the notions of\nawareness, curiosity, surprise and suspense, we explore the properties induced\nby our definitions and study the computational complexity of detecting them. We\nfinally propose means to evaluate these emotions' intensity for a given agent\nlistening to a story.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08597v1",
    "published_date": "2024-10-11 07:50:55 UTC",
    "updated_date": "2024-10-11 07:50:55 UTC"
  },
  {
    "arxiv_id": "2410.08593v1",
    "title": "VERIFIED: A Video Corpus Moment Retrieval Benchmark for Fine-Grained Video Understanding",
    "authors": [
      "Houlun Chen",
      "Xin Wang",
      "Hong Chen",
      "Zeyang Zhang",
      "Wei Feng",
      "Bin Huang",
      "Jia Jia",
      "Wenwu Zhu"
    ],
    "abstract": "Existing Video Corpus Moment Retrieval (VCMR) is limited to coarse-grained\nunderstanding, which hinders precise video moment localization when given\nfine-grained queries. In this paper, we propose a more challenging fine-grained\nVCMR benchmark requiring methods to localize the best-matched moment from the\ncorpus with other partially matched candidates. To improve the dataset\nconstruction efficiency and guarantee high-quality data annotations, we propose\nVERIFIED, an automatic \\underline{V}id\\underline{E}o-text annotation pipeline\nto generate captions with \\underline{R}el\\underline{I}able\n\\underline{FI}n\\underline{E}-grained statics and \\underline{D}ynamics.\nSpecifically, we resort to large language models (LLM) and large multimodal\nmodels (LMM) with our proposed Statics and Dynamics Enhanced Captioning modules\nto generate diverse fine-grained captions for each video. To filter out the\ninaccurate annotations caused by the LLM hallucination, we propose a\nFine-Granularity Aware Noise Evaluator where we fine-tune a video foundation\nmodel with disturbed hard-negatives augmented contrastive and matching losses.\nWith VERIFIED, we construct a more challenging fine-grained VCMR benchmark\ncontaining Charades-FIG, DiDeMo-FIG, and ActivityNet-FIG which demonstrate a\nhigh level of annotation quality. We evaluate several state-of-the-art VCMR\nmodels on the proposed dataset, revealing that there is still significant scope\nfor fine-grained video understanding in VCMR. Code and Datasets are in\n\\href{https://github.com/hlchen23/VERIFIED}{https://github.com/hlchen23/VERIFIED}.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by 38th NeurIPS Datasets & Benchmarks Track (NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.08593v1",
    "published_date": "2024-10-11 07:42:36 UTC",
    "updated_date": "2024-10-11 07:42:36 UTC"
  },
  {
    "arxiv_id": "2410.08592v1",
    "title": "VIBES -- Vision Backbone Efficient Selection",
    "authors": [
      "Joris Guerin",
      "Shray Bansal",
      "Amirreza Shaban",
      "Paulo Mann",
      "Harshvardhan Gazula"
    ],
    "abstract": "This work tackles the challenge of efficiently selecting high-performance\npre-trained vision backbones for specific target tasks. Although exhaustive\nsearch within a finite set of backbones can solve this problem, it becomes\nimpractical for large datasets and backbone pools. To address this, we\nintroduce Vision Backbone Efficient Selection (VIBES), which aims to quickly\nfind well-suited backbones, potentially trading off optimality for efficiency.\nWe propose several simple yet effective heuristics to address VIBES and\nevaluate them across four diverse computer vision datasets. Our results show\nthat these approaches can identify backbones that outperform those selected\nfrom generic benchmarks, even within a limited search budget of one hour on a\nsingle GPU. We reckon VIBES marks a paradigm shift from benchmarks to\ntask-specific optimization.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "9 pages, 4 figures, under review at WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08592v1",
    "published_date": "2024-10-11 07:39:52 UTC",
    "updated_date": "2024-10-11 07:39:52 UTC"
  },
  {
    "arxiv_id": "2410.09124v1",
    "title": "SoK: Verifiable Cross-Silo FL",
    "authors": [
      "Aleksei Korneev",
      "Jan Ramon"
    ],
    "abstract": "Federated Learning (FL) is a widespread approach that allows training machine\nlearning (ML) models with data distributed across multiple devices. In\ncross-silo FL, which often appears in domains like healthcare or finance, the\nnumber of participants is moderate, and each party typically represents a\nwell-known organization. For instance, in medicine data owners are often\nhospitals or data hubs which are well-established entities. However, malicious\nparties may still attempt to disturb the training procedure in order to obtain\ncertain benefits, for example, a biased result or a reduction in computational\nload. While one can easily detect a malicious agent when data used for training\nis public, the problem becomes much more acute when it is necessary to maintain\nthe privacy of the training dataset. To address this issue, there is recently\ngrowing interest in developing verifiable protocols, where one can check that\nparties do not deviate from the training procedure and perform computations\ncorrectly. In this paper, we present a systematization of knowledge on\nverifiable cross-silo FL. We analyze various protocols, fit them in a taxonomy,\nand compare their efficiency and threat models. We also analyze Zero-Knowledge\nProof (ZKP) schemes and discuss how their overall cost in a FL context can be\nminimized. Lastly, we identify research gaps and discuss potential directions\nfor future scientific work.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.09124v1",
    "published_date": "2024-10-11 07:39:35 UTC",
    "updated_date": "2024-10-11 07:39:35 UTC"
  },
  {
    "arxiv_id": "2410.08588v1",
    "title": "ViT3D Alignment of LLaMA3: 3D Medical Image Report Generation",
    "authors": [
      "Siyou Li",
      "Beining Xu",
      "Yihao Luo",
      "Dong Nie",
      "Le Zhang"
    ],
    "abstract": "Automatic medical report generation (MRG), which aims to produce detailed\ntext reports from medical images, has emerged as a critical task in this\ndomain. MRG systems can enhance radiological workflows by reducing the time and\neffort required for report writing, thereby improving diagnostic efficiency. In\nthis work, we present a novel approach for automatic MRG utilizing a multimodal\nlarge language model. Specifically, we employed the 3D Vision Transformer\n(ViT3D) image encoder introduced from M3D-CLIP to process 3D scans and use the\nAsclepius-Llama3-8B as the language model to generate the text reports by\nauto-regressive decoding. The experiment shows our model achieved an average\nGreen score of 0.3 on the MRG task validation set and an average accuracy of\n0.61 on the visual question answering (VQA) task validation set, outperforming\nthe baseline model. Our approach demonstrates the effectiveness of the ViT3D\nalignment of LLaMA3 for automatic MRG and VQA tasks by tuning the model on a\nsmall dataset.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08588v1",
    "published_date": "2024-10-11 07:35:33 UTC",
    "updated_date": "2024-10-11 07:35:33 UTC"
  },
  {
    "arxiv_id": "2410.08584v2",
    "title": "ZipVL: Efficient Large Vision-Language Models with Dynamic Token Sparsification",
    "authors": [
      "Yefei He",
      "Feng Chen",
      "Jing Liu",
      "Wenqi Shao",
      "Hong Zhou",
      "Kaipeng Zhang",
      "Bohan Zhuang"
    ],
    "abstract": "The efficiency of large vision-language models (LVLMs) is constrained by the\ncomputational bottleneck of the attention mechanism during the prefill phase\nand the memory bottleneck of fetching the key-value (KV) cache in the decoding\nphase, particularly in scenarios involving high-resolution images or videos.\nVisual content often exhibits substantial redundancy, resulting in highly\nsparse attention maps within LVLMs. This sparsity can be leveraged to\naccelerate attention computation or compress the KV cache through various\napproaches. However, most studies focus on addressing only one of these\nbottlenecks and do not adequately support dynamic adjustment of sparsity\nconcerning distinct layers or tasks. In this paper, we present ZipVL, an\nefficient inference framework designed for LVLMs through a dynamic ratio\nallocation strategy of important tokens. This ratio is adaptively determined\nbased on the layer-specific distribution of attention scores, rather than fixed\nhyper-parameters, thereby improving efficiency for less complex tasks while\nmaintaining high performance for more challenging ones. Then we select\nimportant tokens based on their normalized attention scores and perform sparse\nattention mechanism solely on those important tokens, reducing the latency in\nthe prefill phase. Tokens deemed less important will be discarded to reduce KV\ncache size, alleviating the memory bottleneck in the decoding phase. Our\nexperiments demonstrate that ZipVL can accelerate the prefill phase by\n2.3$\\times$ and improve decoding throughput by 2.8$\\times$, with a minimal\naccuracy reduction of only 0.5\\% on VQAv2 benchmark over LLaVA-Next-13B model,\neffectively enhancing the generation efficiency of LVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2410.08584v2",
    "published_date": "2024-10-11 07:24:21 UTC",
    "updated_date": "2024-12-18 07:45:11 UTC"
  },
  {
    "arxiv_id": "2410.08583v1",
    "title": "Intent-Enhanced Data Augmentation for Sequential Recommendation",
    "authors": [
      "Shuai Chen",
      "Zhoujun Li"
    ],
    "abstract": "The research on intent-enhanced sequential recommendation algorithms focuses\non how to better mine dynamic user intent based on user behavior data for\nsequential recommendation tasks. Various data augmentation methods are widely\napplied in current sequential recommendation algorithms, effectively enhancing\nthe ability to capture user intent. However, these widely used data\naugmentation methods often rely on a large amount of random sampling, which can\nintroduce excessive noise into the training data, blur user intent, and thus\nnegatively affect recommendation performance. Additionally, these methods have\nlimited approaches to utilizing augmented data, failing to fully leverage the\naugmented samples. We propose an intent-enhanced data augmentation method for\nsequential recommendation(\\textbf{IESRec}), which constructs positive and\nnegative samples based on user behavior sequences through intent-segment\ninsertion. On one hand, the generated positive samples are mixed with the\noriginal training data, and they are trained together to improve recommendation\nperformance. On the other hand, the generated positive and negative samples are\nused to build a contrastive loss function, enhancing recommendation performance\nthrough self-supervised training. Finally, the main recommendation task is\njointly trained with the contrastive learning loss minimization task.\nExperiments on three real-world datasets validate the effectiveness of our\nIESRec model.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "14 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.08583v1",
    "published_date": "2024-10-11 07:23:45 UTC",
    "updated_date": "2024-10-11 07:23:45 UTC"
  },
  {
    "arxiv_id": "2410.08581v1",
    "title": "Integrating AI for Enhanced Feedback in Translation Revision- A Mixed-Methods Investigation of Student Engagement",
    "authors": [
      "Simin Xu",
      "Yanfang Su",
      "Kanglong Liu"
    ],
    "abstract": "Despite the well-established importance of feedback in education, the\napplication of Artificial Intelligence (AI)-generated feedback, particularly\nfrom language models like ChatGPT, remains understudied in translation\neducation. This study investigates the engagement of master's students in\ntranslation with ChatGPT-generated feedback during their revision process. A\nmixed-methods approach, combining a translation-and-revision experiment with\nquantitative and qualitative analyses, was employed to examine the feedback,\ntranslations pre-and post-revision, the revision process, and student\nreflections. The results reveal complex interrelations among cognitive,\naffective, and behavioural dimensions influencing students' engagement with AI\nfeedback and their subsequent revisions. Specifically, the findings indicate\nthat students invested considerable cognitive effort in the revision process,\ndespite finding the feedback comprehensible. Additionally, they exhibited\nmoderate affective satisfaction with the feedback model. Behaviourally, their\nactions were largely influenced by cognitive and affective factors, although\nsome inconsistencies were observed. This research provides novel insights into\nthe potential applications of AI-generated feedback in translation teachingand\nopens avenues for further investigation into the integration of AI tools in\nlanguage teaching settings.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08581v1",
    "published_date": "2024-10-11 07:21:29 UTC",
    "updated_date": "2024-10-11 07:21:29 UTC"
  },
  {
    "arxiv_id": "2410.21284v1",
    "title": "AI-driven innovation in medicaid: enhancing access, cost efficiency, and population health management",
    "authors": [
      "Balaji Shesharao Ingole",
      "Vishnu Ramineni",
      "Manjunatha Sughaturu Krishnappa",
      "Vivekananda Jayaram"
    ],
    "abstract": "The U.S. Medicaid program is experiencing critical challenges that include\nrapidly increasing healthcare costs, uneven care accessibility, and the\nchallenge associated with addressing a varied set of population health needs.\nThis paper investigates the transformative potential of Artificial Intelligence\n(AI) in reshaping Medicaid by streamlining operations, improving patient\nresults, and lowering costs. We delve into the pivotal role of AI in predictive\nanalytics, care coordination, the detection of fraud, and personalized\nmedicine. By leveraging insights from advanced data models and addressing\nchallenges particular to Medicaid, we put forward AI-driven solutions that\nprioritize equitable care and improved public health outcomes. This study\nunderscores the urgency of integrating AI into Medicaid to not only improve\noperational effectiveness but also to create a more accessible and equitable\nhealthcare system for all beneficiaries.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21284v1",
    "published_date": "2024-10-11 07:14:42 UTC",
    "updated_date": "2024-10-11 07:14:42 UTC"
  },
  {
    "arxiv_id": "2410.09123v2",
    "title": "Context-Aware Adapter Tuning for Few-Shot Relation Learning in Knowledge Graphs",
    "authors": [
      "Ran Liu",
      "Zhongzhou Liu",
      "Xiaoli Li",
      "Yuan Fang"
    ],
    "abstract": "Knowledge graphs (KGs) are instrumental in various real-world applications,\nyet they often suffer from incompleteness due to missing relations. To predict\ninstances for novel relations with limited training examples, few-shot relation\nlearning approaches have emerged, utilizing techniques such as meta-learning.\nHowever, the assumption is that novel relations in meta-testing and base\nrelations in meta-training are independently and identically distributed, which\nmay not hold in practice. To address the limitation, we propose RelAdapter, a\ncontext-aware adapter for few-shot relation learning in KGs designed to enhance\nthe adaptation process in meta-learning. First, RelAdapter is equipped with a\nlightweight adapter module that facilitates relation-specific, tunable\nadaptation of meta-knowledge in a parameter-efficient manner. Second,\nRelAdapter is enriched with contextual information about the target relation,\nenabling enhanced adaptation to each distinct relation. Extensive experiments\non three benchmark KGs validate the superiority of RelAdapter over\nstate-of-the-art methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by EMNLP 2024",
    "pdf_url": "http://arxiv.org/pdf/2410.09123v2",
    "published_date": "2024-10-11 07:06:45 UTC",
    "updated_date": "2024-10-17 07:00:29 UTC"
  },
  {
    "arxiv_id": "2410.08576v1",
    "title": "A Theoretical Framework for AI-driven data quality monitoring in high-volume data environments",
    "authors": [
      "Nikhil Bangad",
      "Vivekananda Jayaram",
      "Manjunatha Sughaturu Krishnappa",
      "Amey Ram Banarse",
      "Darshan Mohan Bidkar",
      "Akshay Nagpal",
      "Vidyasagar Parlapalli"
    ],
    "abstract": "This paper presents a theoretical framework for an AI-driven data quality\nmonitoring system designed to address the challenges of maintaining data\nquality in high-volume environments. We examine the limitations of traditional\nmethods in managing the scale, velocity, and variety of big data and propose a\nconceptual approach leveraging advanced machine learning techniques. Our\nframework outlines a system architecture that incorporates anomaly detection,\nclassification, and predictive analytics for real-time, scalable data quality\nmanagement. Key components include an intelligent data ingestion layer,\nadaptive preprocessing mechanisms, context-aware feature extraction, and\nAI-based quality assessment modules. A continuous learning paradigm is central\nto our framework, ensuring adaptability to evolving data patterns and quality\nrequirements. We also address implications for scalability, privacy, and\nintegration within existing data ecosystems. While practical results are not\nprovided, it lays a robust theoretical foundation for future research and\nimplementations, advancing data quality management and encouraging the\nexploration of AI-driven solutions in dynamic environments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08576v1",
    "published_date": "2024-10-11 07:06:36 UTC",
    "updated_date": "2024-10-11 07:06:36 UTC"
  },
  {
    "arxiv_id": "2410.08565v4",
    "title": "Baichuan-Omni Technical Report",
    "authors": [
      "Yadong Li",
      "Haoze Sun",
      "Mingan Lin",
      "Tianpeng Li",
      "Guosheng Dong",
      "Tao Zhang",
      "Bowen Ding",
      "Wei Song",
      "Zhenglin Cheng",
      "Yuqi Huo",
      "Song Chen",
      "Xu Li",
      "Da Pan",
      "Shusen Zhang",
      "Xin Wu",
      "Zheng Liang",
      "Jun Liu",
      "Tao Zhang",
      "Keer Lu",
      "Yaqi Zhao",
      "Yanjun Shen",
      "Fan Yang",
      "Kaicheng Yu",
      "Tao Lin",
      "Jianhua Xu",
      "Zenan Zhou",
      "Weipeng Chen"
    ],
    "abstract": "The salient multimodal capabilities and interactive experience of GPT-4o\nhighlight its critical role in practical applications, yet it lacks a\nhigh-performing open-source counterpart. In this paper, we introduce\nBaichuan-omni, the first open-source 7B Multimodal Large Language Model (MLLM)\nadept at concurrently processing and analyzing modalities of image, video,\naudio, and text, while delivering an advanced multimodal interactive experience\nand strong performance. We propose an effective multimodal training schema\nstarting with 7B model and proceeding through two stages of multimodal\nalignment and multitask fine-tuning across audio, image, video, and text modal.\nThis approach equips the language model with the ability to handle visual and\naudio data effectively. Demonstrating strong performance across various\nomni-modal and multimodal benchmarks, we aim for this contribution to serve as\na competitive baseline for the open-source community in advancing multimodal\nunderstanding and real-time interaction.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08565v4",
    "published_date": "2024-10-11 06:44:31 UTC",
    "updated_date": "2024-12-27 14:19:55 UTC"
  },
  {
    "arxiv_id": "2410.08559v4",
    "title": "Learning General Representation of 12-Lead Electrocardiogram with a Joint-Embedding Predictive Architecture",
    "authors": [
      "Sehun Kim"
    ],
    "abstract": "Electrocardiogram (ECG) captures the heart's electrical signals, offering\nvaluable information for diagnosing cardiac conditions. However, the scarcity\nof labeled data makes it challenging to fully leverage supervised learning in\nmedical domain. Self-supervised learning (SSL) offers a promising solution,\nenabling models to learn from unlabeled data and uncover meaningful patterns.\nIn this paper, we show that masked modeling in the latent space can be a\npowerful alternative to existing self-supervised methods in the ECG domain. We\nintroduce ECG-JEPA, a SSL model for 12-lead ECG analysis that learns semantic\nrepresentations of ECG data by predicting in the hidden latent space, bypassing\nthe need to reconstruct raw signals. This approach offers several advantages in\nthe ECG domain: (1) it avoids producing unnecessary details, such as noise,\nwhich is common in ECG; and (2) it addresses the limitations of na\\\"ive L2 loss\nbetween raw signals. Another key contribution is the introduction of\nCross-Pattern Attention (CroPA), a specialized masked attention mechanism\ntailored for 12-lead ECG data. ECG-JEPA is trained on the union of several open\nECG datasets, totaling approximately 180,000 samples, and achieves\nstate-of-the-art performance in various downstream tasks including ECG\nclassification and feature prediction. Our code is openly available at\nhttps://github.com/sehunfromdaegu/ECG_JEPA.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08559v4",
    "published_date": "2024-10-11 06:30:48 UTC",
    "updated_date": "2024-12-03 03:21:51 UTC"
  },
  {
    "arxiv_id": "2410.08553v1",
    "title": "Balancing Innovation and Privacy: Data Security Strategies in Natural Language Processing Applications",
    "authors": [
      "Shaobo Liu",
      "Guiran Liu",
      "Binrong Zhu",
      "Yuanshuai Luo",
      "Linxiao Wu",
      "Rui Wang"
    ],
    "abstract": "This research addresses privacy protection in Natural Language Processing\n(NLP) by introducing a novel algorithm based on differential privacy, aimed at\nsafeguarding user data in common applications such as chatbots, sentiment\nanalysis, and machine translation. With the widespread application of NLP\ntechnology, the security and privacy protection of user data have become\nimportant issues that need to be solved urgently. This paper proposes a new\nprivacy protection algorithm designed to effectively prevent the leakage of\nuser sensitive information. By introducing a differential privacy mechanism,\nour model ensures the accuracy and reliability of data analysis results while\nadding random noise. This method not only reduces the risk caused by data\nleakage but also achieves effective processing of data while protecting user\nprivacy. Compared to traditional privacy methods like data anonymization and\nhomomorphic encryption, our approach offers significant advantages in terms of\ncomputational efficiency and scalability while maintaining high accuracy in\ndata analysis. The proposed algorithm's efficacy is demonstrated through\nperformance metrics such as accuracy (0.89), precision (0.85), and recall\n(0.88), outperforming other methods in balancing privacy and utility. As\nprivacy protection regulations become increasingly stringent, enterprises and\ndevelopers must take effective measures to deal with privacy risks. Our\nresearch provides an important reference for the application of privacy\nprotection technology in the field of NLP, emphasizing the need to achieve a\nbalance between technological innovation and user privacy. In the future, with\nthe continuous advancement of technology, privacy protection will become a core\nelement of data-driven applications and promote the healthy development of the\nentire industry.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08553v1",
    "published_date": "2024-10-11 06:05:10 UTC",
    "updated_date": "2024-10-11 06:05:10 UTC"
  },
  {
    "arxiv_id": "2410.08551v2",
    "title": "Context-Aware Full Body Anonymization using Text-to-Image Diffusion Models",
    "authors": [
      "Pascal Zwick",
      "Kevin Roesch",
      "Marvin Klemp",
      "Oliver Bringmann"
    ],
    "abstract": "Anonymization plays a key role in protecting sensible information of\nindividuals in real world datasets. Self-driving cars for example need high\nresolution facial features to track people and their viewing direction to\npredict future behaviour and react accordingly. In order to protect people's\nprivacy whilst keeping important features in the dataset, it is important to\nreplace the full body of a person with a highly detailed anonymized one. In\ncontrast to doing face anonymization, full body replacement decreases the\nability of recognizing people by their hairstyle or clothes. In this paper, we\npropose a workflow for full body person anonymization utilizing Stable\nDiffusion as a generative backend. Text-to-image diffusion models, like Stable\nDiffusion, OpenAI's DALL-E or Midjourney, have become very popular in recent\ntime, being able to create photorealistic images from a single text prompt. We\nshow that our method outperforms state-of-the art anonymization pipelines with\nrespect to image quality, resolution, Inception Score (IS) and Frechet\nInception Distance (FID). Additionally, our method is invariant with respect to\nthe image generator and thus able to be used with the latest models available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.0; I.2.0"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08551v2",
    "published_date": "2024-10-11 06:04:30 UTC",
    "updated_date": "2024-10-17 14:04:01 UTC"
  },
  {
    "arxiv_id": "2410.08545v1",
    "title": "Humanity in AI: Detecting the Personality of Large Language Models",
    "authors": [
      "Baohua Zhan",
      "Yongyi Huang",
      "Wenyao Cui",
      "Huaping Zhang",
      "Jianyun Shang"
    ],
    "abstract": "Questionnaires are a common method for detecting the personality of Large\nLanguage Models (LLMs). However, their reliability is often compromised by two\nmain issues: hallucinations (where LLMs produce inaccurate or irrelevant\nresponses) and the sensitivity of responses to the order of the presented\noptions. To address these issues, we propose combining text mining with\nquestionnaires method. Text mining can extract psychological features from the\nLLMs' responses without being affected by the order of options. Furthermore,\nbecause this method does not rely on specific answers, it reduces the influence\nof hallucinations. By normalizing the scores from both methods and calculating\nthe root mean square error, our experiment results confirm the effectiveness of\nthis approach. To further investigate the origins of personality traits in\nLLMs, we conduct experiments on both pre-trained language models (PLMs), such\nas BERT and GPT, as well as conversational models (ChatLLMs), such as ChatGPT.\nThe results show that LLMs do contain certain personalities, for example,\nChatGPT and ChatGLM exhibit the personality traits of 'Conscientiousness'.\nAdditionally, we find that the personalities of LLMs are derived from their\npre-trained data. The instruction data used to train ChatLLMs can enhance the\ngeneration of data containing personalities and expose their hidden\npersonality. We compare the results with the human average personality score,\nand we find that the personality of FLAN-T5 in PLMs and ChatGPT in ChatLLMs is\nmore similar to that of a human, with score differences of 0.34 and 0.22,\nrespectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08545v1",
    "published_date": "2024-10-11 05:53:11 UTC",
    "updated_date": "2024-10-11 05:53:11 UTC"
  },
  {
    "arxiv_id": "2410.08540v1",
    "title": "Kaleidoscope: Learnable Masks for Heterogeneous Multi-agent Reinforcement Learning",
    "authors": [
      "Xinran Li",
      "Ling Pan",
      "Jun Zhang"
    ],
    "abstract": "In multi-agent reinforcement learning (MARL), parameter sharing is commonly\nemployed to enhance sample efficiency. However, the popular approach of full\nparameter sharing often leads to homogeneous policies among agents, potentially\nlimiting the performance benefits that could be derived from policy diversity.\nTo address this critical limitation, we introduce \\emph{Kaleidoscope}, a novel\nadaptive partial parameter sharing scheme that fosters policy heterogeneity\nwhile still maintaining high sample efficiency. Specifically, Kaleidoscope\nmaintains one set of common parameters alongside multiple sets of distinct,\nlearnable masks for different agents, dictating the sharing of parameters. It\npromotes diversity among policy networks by encouraging discrepancy among these\nmasks, without sacrificing the efficiencies of parameter sharing. This design\nallows Kaleidoscope to dynamically balance high sample efficiency with a broad\npolicy representational capacity, effectively bridging the gap between full\nparameter sharing and non-parameter sharing across various environments. We\nfurther extend Kaleidoscope to critic ensembles in the context of actor-critic\nalgorithms, which could help improve value estimations.Our empirical\nevaluations across extensive environments, including multi-agent particle\nenvironment, multi-agent MuJoCo and StarCraft multi-agent challenge v2,\ndemonstrate the superior performance of Kaleidoscope compared with existing\nparameter sharing approaches, showcasing its potential for performance\nenhancement in MARL. The code is publicly available at\n\\url{https://github.com/LXXXXR/Kaleidoscope}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the Thirty-Eighth Annual Conference on Neural Information\n  Processing Systems(NeurIPS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2410.08540v1",
    "published_date": "2024-10-11 05:22:54 UTC",
    "updated_date": "2024-10-11 05:22:54 UTC"
  },
  {
    "arxiv_id": "2410.08529v1",
    "title": "VOVTrack: Exploring the Potentiality in Videos for Open-Vocabulary Object Tracking",
    "authors": [
      "Zekun Qian",
      "Ruize Han",
      "Junhui Hou",
      "Linqi Song",
      "Wei Feng"
    ],
    "abstract": "Open-vocabulary multi-object tracking (OVMOT) represents a critical new\nchallenge involving the detection and tracking of diverse object categories in\nvideos, encompassing both seen categories (base classes) and unseen categories\n(novel classes). This issue amalgamates the complexities of open-vocabulary\nobject detection (OVD) and multi-object tracking (MOT). Existing approaches to\nOVMOT often merge OVD and MOT methodologies as separate modules, predominantly\nfocusing on the problem through an image-centric lens. In this paper, we\npropose VOVTrack, a novel method that integrates object states relevant to MOT\nand video-centric training to address this challenge from a video object\ntracking standpoint. First, we consider the tracking-related state of the\nobjects during tracking and propose a new prompt-guided attention mechanism for\nmore accurate localization and classification (detection) of the time-varying\nobjects. Subsequently, we leverage raw video data without annotations for\ntraining by formulating a self-supervised object similarity learning technique\nto facilitate temporal object association (tracking). Experimental results\nunderscore that VOVTrack outperforms existing methods, establishing itself as a\nstate-of-the-art solution for open-vocabulary tracking task.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08529v1",
    "published_date": "2024-10-11 05:01:49 UTC",
    "updated_date": "2024-10-11 05:01:49 UTC"
  },
  {
    "arxiv_id": "2410.08527v2",
    "title": "Scaling Laws for Predicting Downstream Performance in LLMs",
    "authors": [
      "Yangyi Chen",
      "Binxuan Huang",
      "Yifan Gao",
      "Zhengyang Wang",
      "Jingfeng Yang",
      "Heng Ji"
    ],
    "abstract": "Precise estimation of downstream performance in large language models (LLMs)\nprior to training is essential for guiding their development process. Scaling\nlaws analysis utilizes the statistics of a series of significantly smaller\nsampling language models (LMs) to predict the performance of the target LLM.\nFor downstream performance prediction, the critical challenge lies in the\nemergent abilities in LLMs that occur beyond task-specific computational\nthresholds. In this work, we focus on the pre-training loss as a more\ncomputation-efficient metric for performance estimation. Our two-stage approach\nFLP consists of first estimating a function that maps computational resources\n(e.g., FLOPs) to the pre-training Loss using a series of fully-converged\nsampling models, followed by mapping the pre-training loss to downstream task\nPerformance using the intermediate models with emerged performance. In our\nexperiments, this FLP solution accurately predicts the performance of LLMs with\n7B and 13B parameters using a series of sampling LMs up to 3B, achieving error\nmargins of 5% and 10%, respectively, and significantly outperforming the\nFLOPs-to-Performance approach. Further, we present FLP-M, a fundamental\napproach for performance prediction that addresses the practical need to\nintegrate datasets from multiple sources during pre-training. FLP-M extends the\npower law analytical function to predict domain-specific pre-training loss\nbased on FLOPs across data sources, and employs a two-layer neural network to\nmodel the non-linear relationship between multiple domain-specific loss and\ndownstream performance. By utilizing a 3B LLM trained on a specific ratio and a\nseries of smaller sampling LMs, FLP-M can effectively forecast the performance\nof 3B and 7B LLMs across various data mixtures for most benchmarks within 10%\nerror margins.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to TMLR",
    "pdf_url": "http://arxiv.org/pdf/2410.08527v2",
    "published_date": "2024-10-11 04:57:48 UTC",
    "updated_date": "2025-04-07 21:47:09 UTC"
  },
  {
    "arxiv_id": "2410.08526v1",
    "title": "\"I Am the One and Only, Your Cyber BFF\": Understanding the Impact of GenAI Requires Understanding the Impact of Anthropomorphic AI",
    "authors": [
      "Myra Cheng",
      "Alicia DeVrio",
      "Lisa Egede",
      "Su Lin Blodgett",
      "Alexandra Olteanu"
    ],
    "abstract": "Many state-of-the-art generative AI (GenAI) systems are increasingly prone to\nanthropomorphic behaviors, i.e., to generating outputs that are perceived to be\nhuman-like. While this has led to scholars increasingly raising concerns about\npossible negative impacts such anthropomorphic AI systems can give rise to,\nanthropomorphism in AI development, deployment, and use remains vastly\noverlooked, understudied, and underspecified. In this perspective, we argue\nthat we cannot thoroughly map the social impacts of generative AI without\nmapping the social impacts of anthropomorphic AI, and outline a call to action.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08526v1",
    "published_date": "2024-10-11 04:57:41 UTC",
    "updated_date": "2024-10-11 04:57:41 UTC"
  },
  {
    "arxiv_id": "2410.08500v1",
    "title": "Aerial Vision-and-Language Navigation via Semantic-Topo-Metric Representation Guided LLM Reasoning",
    "authors": [
      "Yunpeng Gao",
      "Zhigang Wang",
      "Linglin Jing",
      "Dong Wang",
      "Xuelong Li",
      "Bin Zhao"
    ],
    "abstract": "Aerial Vision-and-Language Navigation (VLN) is a novel task enabling Unmanned\nAerial Vehicles (UAVs) to navigate in outdoor environments through natural\nlanguage instructions and visual cues. It remains challenging due to the\ncomplex spatial relationships in outdoor aerial scenes. In this paper, we\npropose an end-to-end zero-shot framework for aerial VLN tasks, where the large\nlanguage model (LLM) is introduced as our agent for action prediction.\nSpecifically, we develop a novel Semantic-Topo-Metric Representation (STMR) to\nenhance the spatial reasoning ability of LLMs. This is achieved by extracting\nand projecting instruction-related semantic masks of landmarks into a top-down\nmap that contains the location information of surrounding landmarks. Further,\nthis map is transformed into a matrix representation with distance metrics as\nthe text prompt to the LLM, for action prediction according to the instruction.\nExperiments conducted in real and simulation environments have successfully\nproved the effectiveness and robustness of our method, achieving 15.9% and\n12.5% improvements (absolute) in Oracle Success Rate (OSR) on AerialVLN-S\ndataset.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Submitted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08500v1",
    "published_date": "2024-10-11 03:54:48 UTC",
    "updated_date": "2024-10-11 03:54:48 UTC"
  },
  {
    "arxiv_id": "2410.08491v1",
    "title": "A Systematic Review of Edge Case Detection in Automated Driving: Methods, Challenges and Future Directions",
    "authors": [
      "Saeed Rahmani",
      "Sabine Rieder",
      "Erwin de Gelder",
      "Marcel Sonntag",
      "Jorge Lorente Mallada",
      "Sytze Kalisvaart",
      "Vahid Hashemi",
      "Simeon C. Calvert"
    ],
    "abstract": "The rapid development of automated vehicles (AVs) promises to revolutionize\ntransportation by enhancing safety and efficiency. However, ensuring their\nreliability in diverse real-world conditions remains a significant challenge,\nparticularly due to rare and unexpected situations known as edge cases.\nAlthough numerous approaches exist for detecting edge cases, there is a notable\nlack of a comprehensive survey that systematically reviews these techniques.\nThis paper fills this gap by presenting a practical, hierarchical review and\nsystematic classification of edge case detection and assessment methodologies.\nOur classification is structured on two levels: first, categorizing detection\napproaches according to AV modules, including perception-related and\ntrajectory-related edge cases; and second, based on underlying methodologies\nand theories guiding these techniques. We extend this taxonomy by introducing a\nnew class called \"knowledge-driven\" approaches, which is largely overlooked in\nthe literature. Additionally, we review the techniques and metrics for the\nevaluation of edge case detection methods and identified edge cases. To our\nknowledge, this is the first survey to comprehensively cover edge case\ndetection methods across all AV subsystems, discuss knowledge-driven edge\ncases, and explore evaluation techniques for detection methods. This structured\nand multi-faceted analysis aims to facilitate targeted research and modular\ntesting of AVs. Moreover, by identifying the strengths and weaknesses of\nvarious approaches and discussing the challenges and future directions, this\nsurvey intends to assist AV developers, researchers, and policymakers in\nenhancing the safety and reliability of automated driving (AD) systems through\neffective edge case detection.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "Preprint submitted to IEEE Transactions on Intelligent Transportation\n  Systems",
    "pdf_url": "http://arxiv.org/pdf/2410.08491v1",
    "published_date": "2024-10-11 03:32:20 UTC",
    "updated_date": "2024-10-11 03:32:20 UTC"
  },
  {
    "arxiv_id": "2410.21283v2",
    "title": "pLDDT-Predictor: High-speed Protein Screening Using Transformer and ESM2",
    "authors": [
      "Joongwon Chae",
      "Zhenyu Wang",
      "Ijaz Gul",
      "Jiansong Ji",
      "Zhenglin Chen",
      "Peiwu Qin"
    ],
    "abstract": "Recent advancements in protein structure prediction, particularly AlphaFold2,\nhave revolutionized structural biology by achieving near-experimental accuracy\n($\\text{average RMSD} < 1.5\\text{\\AA}$). However, the computational demands of\nthese models (approximately 30 minutes per protein on an RTX 4090)\nsignificantly limit their application in high-throughput protein screening.\nWhile large language models like ESM (Evolutionary Scale Modeling) have shown\npromise in extracting structural information directly from protein sequences,\nrapid assessment of protein structure quality for large-scale analyses remains\na major challenge.\n  We introduce pLDDT-Predictor, a high-speed protein screening tool that\nachieves a $250,000\\times$ speedup compared to AlphaFold2 by leveraging\npre-trained ESM2 protein embeddings and a Transformer architecture. Our model\npredicts AlphaFold2's pLDDT (predicted Local Distance Difference Test) scores\nwith a Pearson correlation of 0.7891 and processes proteins in just 0.007\nseconds on average. Using a comprehensive dataset of 1.5 million diverse\nprotein sequences (ranging from 50 to 2048 amino acids), we demonstrate that\npLDDT-Predictor accurately classifies high-confidence structures (pLDDT $>$ 70)\nwith 91.2\\% accuracy and achieves an MSE of 84.8142 compared to AlphaFold2's\npredictions.\n  The source code and pre-trained models are freely available at\n\\url{https://github.com/jw-chae/pLDDT_Predictor}, enabling the research\ncommunity to perform rapid, large-scale protein structure quality assessments.",
    "categories": [
      "q-bio.BM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.BM",
    "comment": "6 pages main topic, 8 pages including citiation, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2410.21283v2",
    "published_date": "2024-10-11 03:19:44 UTC",
    "updated_date": "2024-11-13 08:33:17 UTC"
  },
  {
    "arxiv_id": "2410.08478v3",
    "title": "Dynamic Fusion Strategies for Federated Multimodal Recommendations",
    "authors": [
      "Zhiwei Li",
      "Guodong Long",
      "Jing Jiang",
      "Chengqi Zhang"
    ],
    "abstract": "Delivering deeply personalized recommendations necessitates understanding\nuser interactions with diverse multimedia features, but achieving this within\nthe constraints of Federated Recommendation Systems (FedRec) is severely\nhampered by communication bottlenecks, user heterogeneity, and the complexity\nof privacy-preserving multimodal fusion. To this end, we propose FedMR, a novel\nmultimodal FedRec framework centered around the Mixing Feature Fusion Module\n(MFFM). FedMR employs a two-stage process: (1) Server-side centralized\nmultimedia content processing provides rich, shared item context using\npre-trained models, mitigating limitations from client sparsity and resource\nconstraints efficiently. (2) Client-Side Personalized Refinement, where the\nMFFM dynamically adapts these server-provided multimodal representations based\non client-specific interaction patterns, effectively tailoring recommendations\nand resolving heterogeneity in user preferences towards different modalities.\nExtensive experiments validate that FedMR seamlessly enhances existing ID-based\nFedRecs, effectively transforming them into high-performing federated\nmultimodal systems.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "17 pages, 8 figures, 6 tables, conference",
    "pdf_url": "http://arxiv.org/pdf/2410.08478v3",
    "published_date": "2024-10-11 03:10:09 UTC",
    "updated_date": "2025-05-18 06:26:48 UTC"
  },
  {
    "arxiv_id": "2410.08475v2",
    "title": "GIVE: Structured Reasoning of Large Language Models with Knowledge Graph Inspired Veracity Extrapolation",
    "authors": [
      "Jiashu He",
      "Mingyu Derek Ma",
      "Jinxuan Fan",
      "Dan Roth",
      "Wei Wang",
      "Alejandro Ribeiro"
    ],
    "abstract": "Existing approaches based on context prompting or reinforcement learning (RL)\nto improve the reasoning capacities of large language models (LLMs) depend on\nthe LLMs' internal knowledge to produce reliable Chain-Of-Thought (CoT).\nHowever, no matter the size of LLMs, certain problems cannot be resolved in a\nsingle forward pass. Meanwhile, agent-based reasoning systems require access to\na comprehensive nonparametric knowledge base, which is often costly or not\nfeasible for use in scientific and niche domains. We present Graph Inspired\nVeracity Extrapolation (GIVE), a novel reasoning method that merges parametric\nand non-parametric memories to improve accurate reasoning with minimal external\ninput. GIVE guides the LLM agent to select the most pertinent expert data\n(observe), engage in query-specific divergent thinking (reflect), and then\nsynthesize this information to produce the final output (speak). Extensive\nexperiments demonstrated the following benefits of our framework: (1) GIVE\nboosts the performance of LLMs across various sizes. (2) In some scenarios,\nGIVE allows smaller LLMs to surpass larger, more sophisticated ones in\nscientific tasks (GPT3.5T + GIVE > GPT4). (3) GIVE is effective on scientific\nand open-domain assessments. (4) GIVE is a training-free method that enables\nLLMs to tackle new problems that extend beyond their training data (up to 43.5%\n-> 88.2%} accuracy improvement). (5) GIVE allows LLM agents to reason using\nboth restricted (very small) and noisy (very large) knowledge sources,\naccommodating knowledge graphs (KG) ranging from 135 to more than 840k nodes.\n(6) The reasoning process involved in GIVE is fully interpretable.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08475v2",
    "published_date": "2024-10-11 03:05:06 UTC",
    "updated_date": "2025-02-08 22:44:31 UTC"
  },
  {
    "arxiv_id": "2410.08473v1",
    "title": "Deeper Insights into Deep Graph Convolutional Networks: Stability and Generalization",
    "authors": [
      "Guangrui Yang",
      "Ming Li",
      "Han Feng",
      "Xiaosheng Zhuang"
    ],
    "abstract": "Graph convolutional networks (GCNs) have emerged as powerful models for graph\nlearning tasks, exhibiting promising performance in various domains. While\ntheir empirical success is evident, there is a growing need to understand their\nessential ability from a theoretical perspective. Existing theoretical research\nhas primarily focused on the analysis of single-layer GCNs, while a\ncomprehensive theoretical exploration of the stability and generalization of\ndeep GCNs remains limited. In this paper, we bridge this gap by delving into\nthe stability and generalization properties of deep GCNs, aiming to provide\nvaluable insights by characterizing rigorously the associated upper bounds. Our\ntheoretical results reveal that the stability and generalization of deep GCNs\nare influenced by certain key factors, such as the maximum absolute eigenvalue\nof the graph filter operators and the depth of the network. Our theoretical\nstudies contribute to a deeper understanding of the stability and\ngeneralization properties of deep GCNs, potentially paving the way for\ndeveloping more reliable and well-performing models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "44 pages, 3 figures, submitted to IEEE Trans. Pattern Anal. Mach.\n  Intell. on 18-Jun-2024, under review",
    "pdf_url": "http://arxiv.org/pdf/2410.08473v1",
    "published_date": "2024-10-11 02:57:47 UTC",
    "updated_date": "2024-10-11 02:57:47 UTC"
  },
  {
    "arxiv_id": "2410.08464v1",
    "title": "ARCap: Collecting High-quality Human Demonstrations for Robot Learning with Augmented Reality Feedback",
    "authors": [
      "Sirui Chen",
      "Chen Wang",
      "Kaden Nguyen",
      "Li Fei-Fei",
      "C. Karen Liu"
    ],
    "abstract": "Recent progress in imitation learning from human demonstrations has shown\npromising results in teaching robots manipulation skills. To further scale up\ntraining datasets, recent works start to use portable data collection devices\nwithout the need for physical robot hardware. However, due to the absence of\non-robot feedback during data collection, the data quality depends heavily on\nuser expertise, and many devices are limited to specific robot embodiments. We\npropose ARCap, a portable data collection system that provides visual feedback\nthrough augmented reality (AR) and haptic warnings to guide users in collecting\nhigh-quality demonstrations. Through extensive user studies, we show that ARCap\nenables novice users to collect robot-executable data that matches robot\nkinematics and avoids collisions with the scenes. With data collected from\nARCap, robots can perform challenging tasks, such as manipulation in cluttered\nenvironments and long-horizon cross-embodiment manipulation. ARCap is fully\nopen-source and easy to calibrate; all components are built from off-the-shelf\nproducts. More details and results can be found on our website:\nhttps://stanford-tml.github.io/ARCap",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 8 Figures, submitted to ICRA 2025",
    "pdf_url": "http://arxiv.org/pdf/2410.08464v1",
    "published_date": "2024-10-11 02:30:46 UTC",
    "updated_date": "2024-10-11 02:30:46 UTC"
  },
  {
    "arxiv_id": "2410.08455v1",
    "title": "Why pre-training is beneficial for downstream classification tasks?",
    "authors": [
      "Xin Jiang",
      "Xu Cheng",
      "Zechao Li"
    ],
    "abstract": "Pre-training has exhibited notable benefits to downstream tasks by boosting\naccuracy and speeding up convergence, but the exact reasons for these benefits\nstill remain unclear. To this end, we propose to quantitatively and explicitly\nexplain effects of pre-training on the downstream task from a novel\ngame-theoretic view, which also sheds new light into the learning behavior of\ndeep neural networks (DNNs). Specifically, we extract and quantify the\nknowledge encoded by the pre-trained model, and further track the changes of\nsuch knowledge during the fine-tuning process. Interestingly, we discover that\nonly a small amount of pre-trained model's knowledge is preserved for the\ninference of downstream tasks. However, such preserved knowledge is very\nchallenging for a model training from scratch to learn. Thus, with the help of\nthis exclusively learned and useful knowledge, the model fine-tuned from\npre-training usually achieves better performance than the model training from\nscratch. Besides, we discover that pre-training can guide the fine-tuned model\nto learn target knowledge for the downstream task more directly and quickly,\nwhich accounts for the faster convergence of the fine-tuned model.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08455v1",
    "published_date": "2024-10-11 02:13:16 UTC",
    "updated_date": "2024-10-11 02:13:16 UTC"
  },
  {
    "arxiv_id": "2410.21282v1",
    "title": "Logic Error Localization in Student Programming Assignments Using Pseudocode and Graph Neural Networks",
    "authors": [
      "Zhenyu Xu",
      "Kun Zhang",
      "Victor S. Sheng"
    ],
    "abstract": "Pseudocode is extensively used in introductory programming courses to\ninstruct computer science students in algorithm design, utilizing natural\nlanguage to define algorithmic behaviors. This learning approach enables\nstudents to convert pseudocode into source code and execute it to verify their\nalgorithms' correctness. This process typically introduces two types of errors:\nsyntax errors and logic errors. Syntax errors are often accompanied by compiler\nfeedback, which helps students identify incorrect lines. In contrast, logic\nerrors are more challenging because they do not trigger compiler errors and\nlack immediate diagnostic feedback, making them harder to detect and correct.\nTo address this challenge, we developed a system designed to localize logic\nerrors within student programming assignments at the line level. Our approach\nutilizes pseudocode as a scaffold to build a code-pseudocode graph, connecting\nsymbols from the source code to their pseudocode counterparts. We then employ a\ngraph neural network to both localize and suggest corrections for logic errors.\nAdditionally, we have devised a method to efficiently gather logic-error-prone\nprograms during the syntax error correction process and compile these into a\ndataset that includes single and multiple line logic errors, complete with\nindices of the erroneous lines. Our experimental results are promising,\ndemonstrating a localization accuracy of 99.2% for logic errors within the\ntop-10 suspected lines, highlighting the effectiveness of our approach in\nenhancing students' coding proficiency and error correction skills.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.21282v1",
    "published_date": "2024-10-11 01:46:24 UTC",
    "updated_date": "2024-10-11 01:46:24 UTC"
  },
  {
    "arxiv_id": "2410.08442v2",
    "title": "JurEE not Judges: safeguarding llm interactions with small, specialised Encoder Ensembles",
    "authors": [
      "Dom Nasrabadi"
    ],
    "abstract": "We introduce JurEE, an ensemble of efficient, encoder-only transformer models\ndesigned to strengthen safeguards in AI-User interactions within LLM-based\nsystems. Unlike existing LLM-as-Judge methods, which often struggle with\ngeneralization across risk taxonomies and only provide textual outputs, JurEE\noffers probabilistic risk estimates across a wide range of prevalent risks. Our\napproach leverages diverse data sources and employs progressive synthetic data\ngeneration techniques, including LLM-assisted augmentation, to enhance model\nrobustness and performance. We create an in-house benchmark comprising of other\nreputable benchmarks such as the OpenAI Moderation Dataset and ToxicChat, where\nwe find JurEE significantly outperforms baseline models, demonstrating superior\naccuracy, speed, and cost-efficiency. This makes it particularly suitable for\napplications requiring stringent content moderation, such as customer-facing\nchatbots. The encoder-ensemble's modular design allows users to set tailored\nrisk thresholds, enhancing its versatility across various safety-related\napplications. JurEE's collective decision-making process, where each\nspecialized encoder model contributes to the final output, not only improves\npredictive accuracy but also enhances interpretability. This approach provides\na more efficient, performant, and economical alternative to traditional LLMs\nfor large-scale implementations requiring robust content moderation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08442v2",
    "published_date": "2024-10-11 01:20:49 UTC",
    "updated_date": "2024-10-14 09:58:31 UTC"
  },
  {
    "arxiv_id": "2410.08437v3",
    "title": "Autonomous Evaluation of LLMs for Truth Maintenance and Reasoning Tasks",
    "authors": [
      "Rushang Karia",
      "Daniel Bramblett",
      "Daksh Dobhal",
      "Siddharth Srivastava"
    ],
    "abstract": "This paper presents AutoEval, a novel benchmark for scaling Large Language\nModel (LLM) assessment in formal tasks with clear notions of correctness, such\nas truth maintenance in translation and logical reasoning. AutoEval is the\nfirst benchmarking paradigm that offers several key advantages necessary for\nscaling objective evaluation of LLMs without human labeling: (a) ability to\nevaluate LLMs of increasing sophistication by auto-generating tasks at\ndifferent levels of difficulty; (b) auto-generation of ground truth that\neliminates dependence on expensive and time-consuming human annotation; (c) the\nuse of automatically generated, randomized datasets that mitigate the ability\nof successive LLMs to overfit to static datasets used in many contemporary\nbenchmarks. Empirical analysis shows that an LLM's performance on AutoEval is\nhighly indicative of its performance on a diverse array of other benchmarks\nfocusing on translation and reasoning tasks, making it a valuable autonomous\nevaluation paradigm in settings where hand-curated datasets can be hard to\nobtain and/or update.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08437v3",
    "published_date": "2024-10-11 00:56:37 UTC",
    "updated_date": "2025-04-11 20:44:16 UTC"
  },
  {
    "arxiv_id": "2410.08436v2",
    "title": "Exploring the Role of Reasoning Structures for Constructing Proofs in Multi-Step Natural Language Reasoning with Large Language Models",
    "authors": [
      "Zi'ou Zheng",
      "Christopher Malon",
      "Martin Renqiang Min",
      "Xiaodan Zhu"
    ],
    "abstract": "When performing complex multi-step reasoning tasks, the ability of Large\nLanguage Models (LLMs) to derive structured intermediate proof steps is\nimportant for ensuring that the models truly perform the desired reasoning and\nfor improving models' explainability. This paper is centred around a focused\nstudy: whether the current state-of-the-art generalist LLMs can leverage the\nstructures in a few examples to better construct the proof structures with\n\\textit{in-context learning}. Our study specifically focuses on structure-aware\ndemonstration and structure-aware pruning. We demonstrate that they both help\nimprove performance. A detailed analysis is provided to help understand the\nresults.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by EMNLP2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2410.08436v2",
    "published_date": "2024-10-11 00:45:50 UTC",
    "updated_date": "2025-01-30 08:06:33 UTC"
  },
  {
    "arxiv_id": "2410.08435v2",
    "title": "Efficient Fine-Grained Guidance for Diffusion-Based Symbolic Music Generation",
    "authors": [
      "Tingyu Zhu",
      "Haoyu Liu",
      "Ziyu Wang",
      "Zhimin Jiang",
      "Zeyu Zheng"
    ],
    "abstract": "Developing generative models to create or conditionally create symbolic music\npresents unique challenges due to the combination of limited data availability\nand the need for high precision in note pitch. To address these challenges, we\nintroduce an efficient Fine-Grained Guidance (FGG) approach within diffusion\nmodels. FGG guides the diffusion models to generate music that aligns more\nclosely with the control and intent of expert composers, which is critical to\nimprove the accuracy, listenability, and quality of generated music. This\napproach empowers diffusion models to excel in advanced applications such as\nimprovisation, and interactive music creation. We derive theoretical\ncharacterizations for both the challenges in symbolic music generation and the\neffects of the FGG approach. We provide numerical experiments and subjective\nevaluation to demonstrate the effectiveness of our approach. We have published\na demo page to showcase performances, as one of the first in the symbolic music\nliterature's demo pages that enables real-time interactive generation.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2410.08435v2",
    "published_date": "2024-10-11 00:41:46 UTC",
    "updated_date": "2025-02-02 19:01:07 UTC"
  },
  {
    "arxiv_id": "2410.08431v1",
    "title": "oRetrieval Augmented Generation for 10 Large Language Models and its Generalizability in Assessing Medical Fitness",
    "authors": [
      "Yu He Ke",
      "Liyuan Jin",
      "Kabilan Elangovan",
      "Hairil Rizal Abdullah",
      "Nan Liu",
      "Alex Tiong Heng Sia",
      "Chai Rick Soh",
      "Joshua Yi Min Tung",
      "Jasmine Chiat Ling Ong",
      "Chang-Fu Kuo",
      "Shao-Chun Wu",
      "Vesela P. Kovacheva",
      "Daniel Shu Wei Ting"
    ],
    "abstract": "Large Language Models (LLMs) show potential for medical applications but\noften lack specialized clinical knowledge. Retrieval Augmented Generation (RAG)\nallows customization with domain-specific information, making it suitable for\nhealthcare. This study evaluates the accuracy, consistency, and safety of RAG\nmodels in determining fitness for surgery and providing preoperative\ninstructions. We developed LLM-RAG models using 35 local and 23 international\npreoperative guidelines and tested them against human-generated responses. A\ntotal of 3,682 responses were evaluated. Clinical documents were processed\nusing Llamaindex, and 10 LLMs, including GPT3.5, GPT4, and Claude-3, were\nassessed. Fourteen clinical scenarios were analyzed, focusing on seven aspects\nof preoperative instructions. Established guidelines and expert judgment were\nused to determine correct responses, with human-generated answers serving as\ncomparisons. The LLM-RAG models generated responses within 20 seconds,\nsignificantly faster than clinicians (10 minutes). The GPT4 LLM-RAG model\nachieved the highest accuracy (96.4% vs. 86.6%, p=0.016), with no\nhallucinations and producing correct instructions comparable to clinicians.\nResults were consistent across both local and international guidelines. This\nstudy demonstrates the potential of LLM-RAG models for preoperative healthcare\ntasks, highlighting their efficiency, scalability, and reliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2402.01733",
    "pdf_url": "http://arxiv.org/pdf/2410.08431v1",
    "published_date": "2024-10-11 00:34:20 UTC",
    "updated_date": "2024-10-11 00:34:20 UTC"
  },
  {
    "arxiv_id": "2410.21281v1",
    "title": "The Social Impact of Generative LLM-Based AI",
    "authors": [
      "Yu Xie",
      "Sofia Avila"
    ],
    "abstract": "Liking it or not, ready or not, we are likely to enter a new phase of human\nhistory in which Artificial Intelligence (AI) will dominate economic production\nand social life -- the AI Revolution. Before the actual arrival of the AI\nRevolution, it is time for us to speculate on how AI will impact the social\nworld. In this article, we focus on the social impact of generative LLM-based\nAI (GELLMAI), discussing societal factors that contribute to its technological\ndevelopment and its potential roles in enhancing both between-country and\nwithin-country social inequality. There are good indications that the US and\nChina will lead the field and will be the main competitors for domination of AI\nin the world. We conjecture the AI Revolution will likely give rise to a\npost-knowledge society in which knowledge per se will become less important\nthan in today's world. Instead, individual relationships and social identity\nwill become more important. So will soft skills.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "00",
      "A.0"
    ],
    "primary_category": "cs.CY",
    "comment": "34 pages, 3 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2410.21281v1",
    "published_date": "2024-10-11 00:26:44 UTC",
    "updated_date": "2024-10-11 00:26:44 UTC"
  }
]