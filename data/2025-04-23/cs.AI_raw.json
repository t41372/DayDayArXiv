[
  {
    "arxiv_id": "2504.16929v1",
    "title": "I-Con: A Unifying Framework for Representation Learning",
    "authors": [
      "Shaden Alshammari",
      "John Hershey",
      "Axel Feldmann",
      "William T. Freeman",
      "Mark Hamilton"
    ],
    "abstract": "As the field of representation learning grows, there has been a proliferation\nof different loss functions to solve different classes of problems. We\nintroduce a single information-theoretic equation that generalizes a large\ncollection of modern loss functions in machine learning. In particular, we\nintroduce a framework that shows that several broad classes of machine learning\nmethods are precisely minimizing an integrated KL divergence between two\nconditional distributions: the supervisory and learned representations. This\nviewpoint exposes a hidden information geometry underlying clustering, spectral\nmethods, dimensionality reduction, contrastive learning, and supervised\nlearning. This framework enables the development of new loss functions by\ncombining successful techniques from across the literature. We not only present\na wide array of proofs, connecting over 23 different approaches, but we also\nleverage these theoretical results to create state-of-the-art unsupervised\nimage classifiers that achieve a +8% improvement over the prior\nstate-of-the-art on unsupervised classification on ImageNet-1K. We also\ndemonstrate that I-Con can be used to derive principled debiasing methods which\nimprove contrastive representation learners.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025; website: https://aka.ms/i-con . Proceedings of the\n  Thirteenth International Conference on Learning Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.16929v1",
    "published_date": "2025-04-23 17:59:01 UTC",
    "updated_date": "2025-04-23 17:59:01 UTC"
  },
  {
    "arxiv_id": "2504.16925v1",
    "title": "Latent Diffusion Planning for Imitation Learning",
    "authors": [
      "Amber Xie",
      "Oleh Rybkin",
      "Dorsa Sadigh",
      "Chelsea Finn"
    ],
    "abstract": "Recent progress in imitation learning has been enabled by policy\narchitectures that scale to complex visuomotor tasks, multimodal distributions,\nand large datasets. However, these methods often rely on learning from large\namount of expert demonstrations. To address these shortcomings, we propose\nLatent Diffusion Planning (LDP), a modular approach consisting of a planner\nwhich can leverage action-free demonstrations, and an inverse dynamics model\nwhich can leverage suboptimal data, that both operate over a learned latent\nspace. First, we learn a compact latent space through a variational\nautoencoder, enabling effective forecasting of future states in image-based\ndomains. Then, we train a planner and an inverse dynamics model with diffusion\nobjectives. By separating planning from action prediction, LDP can benefit from\nthe denser supervision signals of suboptimal and action-free data. On simulated\nvisual robotic manipulation tasks, LDP outperforms state-of-the-art imitation\nlearning approaches, as they cannot leverage such additional data.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16925v1",
    "published_date": "2025-04-23 17:53:34 UTC",
    "updated_date": "2025-04-23 17:53:34 UTC"
  },
  {
    "arxiv_id": "2504.16922v1",
    "title": "Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light",
    "authors": [
      "Ali Hassani",
      "Fengzhe Zhou",
      "Aditya Kane",
      "Jiannan Huang",
      "Chieh-Yun Chen",
      "Min Shi",
      "Steven Walton",
      "Markus Hoehnerbach",
      "Vijay Thakkar",
      "Michael Isaev",
      "Qinsheng Zhang",
      "Bing Xu",
      "Haicheng Wu",
      "Wen-mei Hwu",
      "Ming-Yu Liu",
      "Humphrey Shi"
    ],
    "abstract": "Many sparse attention mechanisms such as Neighborhood Attention have\ntypically failed to consistently deliver speedup over the self attention\nbaseline. This is largely due to the level of complexity in attention\ninfrastructure, and the rapid evolution of AI hardware architecture. At the\nsame time, many state-of-the-art foundational models, particularly in computer\nvision, are heavily bound by attention, and need reliable sparsity to escape\nthe O(n^2) complexity. In this paper, we study a class of promising sparse\nattention mechanisms that focus on locality, and aim to develop a better\nanalytical model of their performance improvements. We first introduce\nGeneralized Neighborhood Attention (GNA), which can describe sliding window,\nstrided sliding window, and blocked attention. We then consider possible design\nchoices in implementing these approaches, and create a simulator that can\nprovide much more realistic speedup upper bounds for any given setting.\nFinally, we implement GNA on top of a state-of-the-art fused multi-headed\nattention (FMHA) kernel designed for the NVIDIA Blackwell architecture in\nCUTLASS. Our implementation can fully realize the maximum speedup theoretically\npossible in many perfectly block-sparse cases, and achieves an effective\nutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA\nconfigurations into off-the-shelf generative models, such as Cosmos-7B,\nHunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end\nspeedup on B200 without any fine-tuning. We will open source our simulator and\nBlackwell kernels directly through the NATTEN project.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "https://github.com/SHI-Labs/NATTEN/",
    "pdf_url": "http://arxiv.org/pdf/2504.16922v1",
    "published_date": "2025-04-23 17:49:53 UTC",
    "updated_date": "2025-04-23 17:49:53 UTC"
  },
  {
    "arxiv_id": "2504.16918v1",
    "title": "OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents",
    "authors": [
      "Raghav Thind",
      "Youran Sun",
      "Ling Liang",
      "Haizhao Yang"
    ],
    "abstract": "Optimization plays a vital role in scientific research and practical\napplications, but formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce\n\\textbf{OptimAI}, a framework for solving \\underline{Optim}ization problems\ndescribed in natural language by leveraging LLM-powered \\underline{AI} agents,\nachieving superior performance over current state-of-the-art methods. Our\nframework is built upon four key roles: (1) a \\emph{formulator} that translates\nnatural language problem descriptions into precise mathematical formulations;\n(2) a \\emph{planner} that constructs a high-level solution strategy prior to\nexecution; and (3) a \\emph{coder} and a \\emph{code critic} capable of\ninteracting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, allowing us to conveniently explore the synergistic effect of\ncombining diverse models within a unified system. Our approach attains 88.1\\%\naccuracy on the NLP4LP dataset and 71.2\\% on the Optibench (non-linear w/o\ntable) subset, reducing error rates by 58\\% and 50\\% respectively over prior\nbest results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16918v1",
    "published_date": "2025-04-23 17:45:05 UTC",
    "updated_date": "2025-04-23 17:45:05 UTC"
  },
  {
    "arxiv_id": "2504.16913v1",
    "title": "Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM Behind AI-Generated Text",
    "authors": [
      "Shifali Agrahari",
      "Sanasam Ranbir Singh"
    ],
    "abstract": "In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "De-Factify 4: 4th Workshop on Multimodal Fact Checking and Hate\n  Speech Detection, co-located with AAAI 2025. Pennsylvania",
    "pdf_url": "http://arxiv.org/pdf/2504.16913v1",
    "published_date": "2025-04-23 17:39:49 UTC",
    "updated_date": "2025-04-23 17:39:49 UTC"
  },
  {
    "arxiv_id": "2504.16907v1",
    "title": "BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation",
    "authors": [
      "Ruotong Wang",
      "Mingli Zhu",
      "Jiarong Ou",
      "Rui Chen",
      "Xin Tao",
      "Pengfei Wan",
      "Baoyuan Wu"
    ],
    "abstract": "Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16907v1",
    "published_date": "2025-04-23 17:34:48 UTC",
    "updated_date": "2025-04-23 17:34:48 UTC"
  },
  {
    "arxiv_id": "2504.16902v1",
    "title": "Building A Secure Agentic AI Application Leveraging A2A Protocol",
    "authors": [
      "Idan Habler",
      "Ken Huang",
      "Vineeth Sai Narajala",
      "Prashant Kulkarni"
    ],
    "abstract": "As Agentic AI systems evolve from basic workflows to complex multi agent\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\nessential enablers. To foster secure adoption and ensure the reliability of\nthese complex interactions, understanding the secure implementation of A2A is\nessential. This paper addresses this goal by providing a comprehensive security\nanalysis centered on the A2A protocol. We examine its fundamental elements and\noperational dynamics, situating it within the framework of agent communication\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\nrisks, we apply proactive threat modeling to assess potential security issues\nin A2A deployments, focusing on aspects such as Agent Card management, task\nexecution integrity, and authentication methodologies.\n  Based on these insights, we recommend practical secure development\nmethodologies and architectural best practices designed to build resilient and\neffective A2A systems. Our analysis also explores how the synergy between A2A\nand the Model Context Protocol (MCP) can further enhance secure\ninteroperability. This paper equips developers and architects with the\nknowledge and practical guidance needed to confidently leverage the A2A\nprotocol for building robust and secure next generation agentic applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 4 figures, 1 table, Authors contributed equally to this\n  work",
    "pdf_url": "http://arxiv.org/pdf/2504.16902v1",
    "published_date": "2025-04-23 17:27:49 UTC",
    "updated_date": "2025-04-23 17:27:49 UTC"
  },
  {
    "arxiv_id": "2504.16891v1",
    "title": "AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset",
    "authors": [
      "Ivan Moshkov",
      "Darragh Hanley",
      "Ivan Sorokin",
      "Shubham Toshniwal",
      "Christof Henkel",
      "Benedikt Schifferer",
      "Wei Du",
      "Igor Gitman"
    ],
    "abstract": "This paper presents our winning submission to the AI Mathematical Olympiad -\nProgress Prize 2 (AIMO-2) competition. Our recipe for building state-of-the-art\nmathematical reasoning models relies on three key pillars. First, we create a\nlarge-scale dataset comprising 540K unique high-quality math problems,\nincluding olympiad-level problems, and their 3.2M long-reasoning solutions.\nSecond, we develop a novel method to integrate code execution with long\nreasoning models through iterative training, generation, and quality filtering,\nresulting in 1.7M high-quality Tool-Integrated Reasoning solutions. Third, we\ncreate a pipeline to train models to select the most promising solution from\nmany candidates. We show that such generative solution selection (GenSelect)\ncan significantly improve upon majority voting baseline. Combining these ideas,\nwe train a series of models that achieve state-of-the-art results on\nmathematical reasoning benchmarks. To facilitate further research, we release\nour code, models, and the complete OpenMathReasoning dataset under a\ncommercially permissive license.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Report of AIMO-2 winning submission",
    "pdf_url": "http://arxiv.org/pdf/2504.16891v1",
    "published_date": "2025-04-23 17:13:04 UTC",
    "updated_date": "2025-04-23 17:13:04 UTC"
  },
  {
    "arxiv_id": "2504.16837v1",
    "title": "Approximating Optimal Labelings for Temporal Connectivity",
    "authors": [
      "Daniele Carnevale",
      "Gianlorenzo D'Angelo",
      "Martin Olsen"
    ],
    "abstract": "In a temporal graph the edge set dynamically changes over time according to a\nset of time-labels associated with each edge that indicates at which time-steps\nthe edge is available. Two vertices are connected if there is a path connecting\nthem in which the edges are traversed in increasing order of their labels. We\nstudy the problem of scheduling the availability time of the edges of a\ntemporal graph in such a way that all pairs of vertices are connected within a\ngiven maximum allowed time $a$ and the overall number of labels is minimized.\n  The problem, known as \\emph{Minimum Aged Labeling} (MAL), has several\napplications in logistics, distribution scheduling, and information spreading\nin social networks, where carefully choosing the time-labels can significantly\nreduce infrastructure costs, fuel consumption, or greenhouse gases.\n  The problem MAL has previously been proved to be NP-complete on undirected\ngraphs and \\APX-hard on directed graphs. In this paper, we extend our knowledge\non the complexity and approximability of MAL in several directions. We first\nshow that the problem cannot be approximated within a factor better than\n$O(\\log n)$ when $a\\geq 2$, unless $\\text{P} = \\text{NP}$, and a factor better\nthan $2^{\\log ^{1-\\epsilon} n}$ when $a\\geq 3$, unless $\\text{NP}\\subseteq\n\\text{DTIME}(2^{\\text{polylog}(n)})$, where $n$ is the number of vertices in\nthe graph. Then we give a set of approximation algorithms that, under some\nconditions, almost match these lower bounds. In particular, we show that the\napproximation depends on a relation between $a$ and the diameter of the input\ngraph.\n  We further establish a connection with a foundational optimization problem on\nstatic graphs called \\emph{Diameter Constrained Spanning Subgraph} (DCSS) and\nshow that our hardness results also apply to DCSS.",
    "categories": [
      "cs.DS",
      "cs.AI"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16837v1",
    "published_date": "2025-04-23 16:00:33 UTC",
    "updated_date": "2025-04-23 16:00:33 UTC"
  },
  {
    "arxiv_id": "2504.16834v1",
    "title": "Improving Significant Wave Height Prediction Using Chronos Models",
    "authors": [
      "Yilin Zhai",
      "Hongyuan Shi",
      "Chao Zhan",
      "Qing Wang",
      "Zaijin You",
      "Nan Wang"
    ],
    "abstract": "Accurate wave height prediction is critical for maritime safety and coastal\nresilience, yet conventional physics-based models and traditional machine\nlearning methods face challenges in computational efficiency and nonlinear\ndynamics modeling. This study introduces Chronos, the first implementation of a\nlarge language model (LLM)-powered temporal architecture (Chronos) optimized\nfor wave forecasting. Through advanced temporal pattern recognition applied to\nhistorical wave data from three strategically chosen marine zones in the\nNorthwest Pacific basin, our framework achieves multimodal improvements: (1)\n14.3% reduction in training time with 2.5x faster inference speed compared to\nPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;\n(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)\nsustained predictive leadership in extended-range forecasts (1-120h); and (4)\ndemonstrated zero-shot capability maintaining median performance (rank 4/12)\nagainst specialized operational models. This LLM-enhanced temporal modeling\nparadigm establishes a new standard in wave prediction, offering both\ncomputationally efficient solutions and a transferable framework for complex\ngeophysical systems modeling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16834v1",
    "published_date": "2025-04-23 15:56:28 UTC",
    "updated_date": "2025-04-23 15:56:28 UTC"
  },
  {
    "arxiv_id": "2504.16828v1",
    "title": "Process Reward Models That Think",
    "authors": [
      "Muhammad Khalifa",
      "Rishabh Agarwal",
      "Lajanugen Logeswaran",
      "Jaekyeom Kim",
      "Hao Peng",
      "Moontae Lee",
      "Honglak Lee",
      "Lu Wang"
    ],
    "abstract": "Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16828v1",
    "published_date": "2025-04-23 15:44:54 UTC",
    "updated_date": "2025-04-23 15:44:54 UTC"
  },
  {
    "arxiv_id": "2504.16795v1",
    "title": "Random Long-Context Access for Mamba via Hardware-aligned Hierarchical Sparse Attention",
    "authors": [
      "Xiang Hu",
      "Jiaqi Leng",
      "Jun Zhao",
      "Kewei Tu",
      "Wei Wu"
    ],
    "abstract": "A key advantage of Recurrent Neural Networks (RNNs) over Transformers is\ntheir linear computational and space complexity enables faster training and\ninference for long sequences. However, RNNs are fundamentally unable to\nrandomly access historical context, and simply integrating attention mechanisms\nmay undermine their efficiency advantages. To overcome this limitation, we\npropose \\textbf{H}ierarchical \\textbf{S}parse \\textbf{A}ttention (HSA), a novel\nattention mechanism that enhances RNNs with long-range random access\nflexibility while preserving their merits in efficiency and length\ngeneralization. HSA divides inputs into chunks, selecting the top-$k$ chunks\nand hierarchically aggregates information. The core innovation lies in learning\ntoken-to-chunk relevance based on fine-grained token-level information inside\neach chunk. This approach enhances the precision of chunk selection across both\nin-domain and out-of-domain context lengths. To make HSA efficient, we further\nintroduce a hardware-aligned kernel design. By combining HSA with Mamba, we\nintroduce RAMba, which achieves perfect accuracy in passkey retrieval across 64\nmillion contexts despite pre-training on only 4K-length contexts, and\nsignificant improvements on various downstream tasks, with nearly constant\nmemory footprint. These results show RAMba's huge potential in long-context\nmodeling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.16795v1",
    "published_date": "2025-04-23 15:15:06 UTC",
    "updated_date": "2025-04-23 15:15:06 UTC"
  },
  {
    "arxiv_id": "2504.16791v1",
    "title": "Radiometer Calibration using Machine Learning",
    "authors": [
      "S. A. K. Leeney",
      "H. T. J. Bevins",
      "E. de Lera Acedo",
      "W. J. Handley",
      "C. Kirkham",
      "R. S. Patel",
      "J. Zhu",
      "D. Molnar",
      "J. Cumner",
      "D. Anstey",
      "K. Artuc",
      "G. Bernardi",
      "M. Bucher",
      "S. Carey",
      "J. Cavillot",
      "R. Chiello",
      "W. Croukamp",
      "D. I. L. de Villiers",
      "J. A. Ely",
      "A. Fialkov",
      "T. Gessey-Jones",
      "G. Kulkarni",
      "A. Magro",
      "P. D. Meerburg",
      "S. Mittal",
      "J. H. N. Pattison",
      "S. Pegwal",
      "C. M. Pieterse",
      "J. R. Pritchard",
      "E. Puchwein",
      "N. Razavi-Ghods",
      "I. L. V. Roque",
      "A. Saxena",
      "K. H. Scheutwinkel",
      "P. Scott",
      "E. Shen",
      "P. H. Sims",
      "M. Spinelli"
    ],
    "abstract": "Radiometers are crucial instruments in radio astronomy, forming the primary\ncomponent of nearly all radio telescopes. They measure the intensity of\nelectromagnetic radiation, converting this radiation into electrical signals. A\nradiometer's primary components are an antenna and a Low Noise Amplifier (LNA),\nwhich is the core of the ``receiver'' chain. Instrumental effects introduced by\nthe receiver are typically corrected or removed during calibration. However,\nimpedance mismatches between the antenna and receiver can introduce unwanted\nsignal reflections and distortions. Traditional calibration methods, such as\nDicke switching, alternate the receiver input between the antenna and a\nwell-characterised reference source to mitigate errors by comparison. Recent\nadvances in Machine Learning (ML) offer promising alternatives. Neural\nnetworks, which are trained using known signal sources, provide a powerful\nmeans to model and calibrate complex systems where traditional analytical\napproaches struggle. These methods are especially relevant for detecting the\nfaint sky-averaged 21-cm signal from atomic hydrogen at high redshifts. This is\none of the main challenges in observational Cosmology today. Here, for the\nfirst time, we introduce and test a machine learning-based calibration\nframework capable of achieving the precision required for radiometric\nexperiments aiming to detect the 21-cm line.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "Under peer review for publication in Nature Scientific Reports as\n  part of the Radio Astronomy collection",
    "pdf_url": "http://arxiv.org/pdf/2504.16791v1",
    "published_date": "2025-04-23 15:10:25 UTC",
    "updated_date": "2025-04-23 15:10:25 UTC"
  },
  {
    "arxiv_id": "2504.16788v1",
    "title": "Towards Explainable AI: Multi-Modal Transformer for Video-based Image Description Generation",
    "authors": [
      "Lakshita Agarwal",
      "Bindu Verma"
    ],
    "abstract": "Understanding and analyzing video actions are essential for producing\ninsightful and contextualized descriptions, especially for video-based\napplications like intelligent monitoring and autonomous systems. The proposed\nwork introduces a novel framework for generating natural language descriptions\nfrom video datasets by combining textual and visual modalities. The suggested\narchitecture makes use of ResNet50 to extract visual features from video frames\nthat are taken from the Microsoft Research Video Description Corpus (MSVD), and\nBerkeley DeepDrive eXplanation (BDD-X) datasets. The extracted visual\ncharacteristics are converted into patch embeddings and then run through an\nencoder-decoder model based on Generative Pre-trained Transformer-2 (GPT-2). In\norder to align textual and visual representations and guarantee high-quality\ndescription production, the system uses multi-head self-attention and\ncross-attention techniques. The model's efficacy is demonstrated by performance\nevaluation using BLEU (1-4), CIDEr, METEOR, and ROUGE-L. The suggested\nframework outperforms traditional methods with BLEU-4 scores of 0.755 (BDD-X)\nand 0.778 (MSVD), CIDEr scores of 1.235 (BDD-X) and 1.315 (MSVD), METEOR scores\nof 0.312 (BDD-X) and 0.329 (MSVD), and ROUGE-L scores of 0.782 (BDD-X) and\n0.795 (MSVD). By producing human-like, contextually relevant descriptions,\nstrengthening interpretability, and improving real-world applications, this\nresearch advances explainable AI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16788v1",
    "published_date": "2025-04-23 15:03:37 UTC",
    "updated_date": "2025-04-23 15:03:37 UTC"
  },
  {
    "arxiv_id": "2504.16787v1",
    "title": "Credible plan-driven RAG method for Multi-hop Question Answering",
    "authors": [
      "Ningning Zhang",
      "Chi Zhang",
      "Zhizhong Tan",
      "Xingxing Yang",
      "Weiping Deng",
      "Wenyong Wang"
    ],
    "abstract": "Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16787v1",
    "published_date": "2025-04-23 15:03:17 UTC",
    "updated_date": "2025-04-23 15:03:17 UTC"
  },
  {
    "arxiv_id": "2504.16778v1",
    "title": "Evaluation Framework for AI Systems in \"the Wild\"",
    "authors": [
      "Sarah Jabbour",
      "Trenton Chang",
      "Anindya Das Antar",
      "Joseph Peper",
      "Insu Jang",
      "Jiachen Liu",
      "Jae-Won Chung",
      "Shiqi He",
      "Michael Wellman",
      "Bryan Goodman",
      "Elizabeth Bondi-Kelly",
      "Kevin Samy",
      "Rada Mihalcea",
      "Mosharaf Chowhury",
      "David Jurgens",
      "Lu Wang"
    ],
    "abstract": "Generative AI (GenAI) models have become vital across industries, yet current\nevaluation methods have not adapted to their widespread use. Traditional\nevaluations often rely on benchmarks and fixed datasets, frequently failing to\nreflect real-world performance, which creates a gap between lab-tested outcomes\nand practical applications. This white paper proposes a comprehensive framework\nfor how we should evaluate real-world GenAI systems, emphasizing diverse,\nevolving inputs and holistic, dynamic, and ongoing assessment approaches. The\npaper offers guidance for practitioners on how to design evaluation methods\nthat accurately reflect real-time capabilities, and provides policymakers with\nrecommendations for crafting GenAI policies focused on societal impacts, rather\nthan fixed performance numbers or parameter sizes. We advocate for holistic\nframeworks that integrate performance, fairness, and ethics and the use of\ncontinuous, outcome-oriented methods that combine human and automated\nassessments while also being transparent to foster trust among stakeholders.\nImplementing these strategies ensures GenAI models are not only technically\nproficient but also ethically responsible and impactful.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.16778v1",
    "published_date": "2025-04-23 14:52:39 UTC",
    "updated_date": "2025-04-23 14:52:39 UTC"
  },
  {
    "arxiv_id": "2504.16768v1",
    "title": "How Effective are Generative Large Language Models in Performing Requirements Classification?",
    "authors": [
      "Waad Alhoshan",
      "Alessio Ferrari",
      "Liping Zhao"
    ],
    "abstract": "In recent years, transformer-based large language models (LLMs) have\nrevolutionised natural language processing (NLP), with generative models\nopening new possibilities for tasks that require context-aware text generation.\nRequirements engineering (RE) has also seen a surge in the experimentation of\nLLMs for different tasks, including trace-link detection, regulatory\ncompliance, and others. Requirements classification is a common task in RE.\nWhile non-generative LLMs like BERT have been successfully applied to this\ntask, there has been limited exploration of generative LLMs. This gap raises an\nimportant question: how well can generative LLMs, which produce context-aware\noutputs, perform in requirements classification? In this study, we explore the\neffectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing\nboth binary and multi-class requirements classification. We design an extensive\nexperimental study involving over 400 experiments across three widely used\ndatasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes\nthat while factors like prompt design and LLM architecture are universally\nimportant, others-such as dataset variations-have a more situational impact,\ndepending on the complexity of the classification task. This insight can guide\nfuture model development and deployment strategies, focusing on optimising\nprompt structures and aligning model architectures with task-specific needs for\nimproved performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16768v1",
    "published_date": "2025-04-23 14:41:11 UTC",
    "updated_date": "2025-04-23 14:41:11 UTC"
  },
  {
    "arxiv_id": "2504.16763v1",
    "title": "Noise-Tolerant Coreset-Based Class Incremental Continual Learning",
    "authors": [
      "Edison Mucllari",
      "Aswin Raghavan",
      "Zachary Alan Daniels"
    ],
    "abstract": "Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Work-in-Progress",
    "pdf_url": "http://arxiv.org/pdf/2504.16763v1",
    "published_date": "2025-04-23 14:34:20 UTC",
    "updated_date": "2025-04-23 14:34:20 UTC"
  },
  {
    "arxiv_id": "2504.16760v1",
    "title": "Lightweight Latent Verifiers for Efficient Meta-Generation Strategies",
    "authors": [
      "Bartosz Piotrowski",
      "Witold Drzewakowski",
      "Konrad Staniszewski",
      "Piotr Miłoś"
    ],
    "abstract": "Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16760v1",
    "published_date": "2025-04-23 14:33:20 UTC",
    "updated_date": "2025-04-23 14:33:20 UTC"
  },
  {
    "arxiv_id": "2504.16754v1",
    "title": "HEMA : A Hippocampus-Inspired Extended Memory Architecture for Long-Context AI Conversations",
    "authors": [
      "Kwangseob Ahn"
    ],
    "abstract": "Large language models (LLMs) struggle with maintaining coherence in extended\nconversations spanning hundreds of turns, despite performing well within their\ncontext windows. This paper introduces HEMA (Hippocampus-Inspired Extended\nMemory Architecture), a dual-memory system inspired by human cognitive\nprocesses. HEMA combines Compact Memory - a continuously updated one-sentence\nsummary preserving global narrative coherence, and Vector Memory - an episodic\nstore of chunk embeddings queried via cosine similarity. When integrated with a\n6B-parameter transformer, HEMA maintains coherent dialogues beyond 300 turns\nwhile keeping prompt length under 3,500 tokens. Experimental results show\nsubstantial improvements: factual recall accuracy increases from 41% to 87%,\nand human-rated coherence improves from 2.7 to 4.3 on a 5-point scale. With 10K\nindexed chunks, Vector Memory achieves P@5 >= 0.80 and R@50 >= 0.74, doubling\nthe area under the precision-recall curve compared to summarization-only\napproaches. Ablation studies reveal two key insights: semantic forgetting\nthrough age-weighted pruning reduces retrieval latency by 34% with minimal\nrecall loss, and a two-level summary hierarchy prevents cascade errors in\nultra-long conversations exceeding 1,000 turns. HEMA demonstrates that\ncombining verbatim recall with semantic continuity provides a practical\nsolution for privacy-aware conversational AI capable of month-long dialogues\nwithout model retraining.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16754v1",
    "published_date": "2025-04-23 14:27:12 UTC",
    "updated_date": "2025-04-23 14:27:12 UTC"
  },
  {
    "arxiv_id": "2504.16738v1",
    "title": "MOSAIC: A Skill-Centric Algorithmic Framework for Long-Horizon Manipulation Planning",
    "authors": [
      "Itamar Mishani",
      "Yorai Shaoul",
      "Maxim Likhachev"
    ],
    "abstract": "Planning long-horizon motions using a set of predefined skills is a key\nchallenge in robotics and AI. Addressing this challenge requires methods that\nsystematically explore skill combinations to uncover task-solving sequences,\nharness generic, easy-to-learn skills (e.g., pushing, grasping) to generalize\nacross unseen tasks, and bypass reliance on symbolic world representations that\ndemand extensive domain and task-specific knowledge. Despite significant\nprogress, these elements remain largely disjoint in existing approaches,\nleaving a critical gap in achieving robust, scalable solutions for complex,\nlong-horizon problems. In this work, we present MOSAIC, a skill-centric\nframework that unifies these elements by using the skills themselves to guide\nthe planning process. MOSAIC uses two families of skills: Generators compute\nexecutable trajectories and world configurations, and Connectors link these\nindependently generated skill trajectories by solving boundary value problems,\nenabling progress toward completing the overall task. By breaking away from the\nconventional paradigm of incrementally discovering skills from predefined start\nor goal states--a limitation that significantly restricts exploration--MOSAIC\nfocuses planning efforts on regions where skills are inherently effective. We\ndemonstrate the efficacy of MOSAIC in both simulated and real-world robotic\nmanipulation tasks, showcasing its ability to solve complex long-horizon\nplanning problems using a diverse set of skills incorporating generative\ndiffusion models, motion planning algorithms, and manipulation-specific models.\nVisit https://skill-mosaic.github.io for demonstrations and examples.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review. Project page: https://skill-mosaic.github.io",
    "pdf_url": "http://arxiv.org/pdf/2504.16738v1",
    "published_date": "2025-04-23 14:09:42 UTC",
    "updated_date": "2025-04-23 14:09:42 UTC"
  },
  {
    "arxiv_id": "2504.16736v1",
    "title": "A Survey of AI Agent Protocols",
    "authors": [
      "Yingxuan Yang",
      "Huacan Chai",
      "Yuanyi Song",
      "Siyuan Qi",
      "Muning Wen",
      "Ning Li",
      "Junwei Liao",
      "Haoyi Hu",
      "Jianghao Lin",
      "Gaowei Chang",
      "Weiwen Liu",
      "Ying Wen",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "abstract": "The rapid development of large language models (LLMs) has led to the\nwidespread deployment of LLM agents across diverse industries, including\ncustomer service, content generation, data analysis, and even healthcare.\nHowever, as more LLM agents are deployed, a major issue has emerged: there is\nno standard way for these agents to communicate with external tools or data\nsources. This lack of standardized protocols makes it difficult for agents to\nwork together or scale effectively, and it limits their ability to tackle\ncomplex, real-world tasks. A unified communication protocol for LLM agents\ncould change this. It would allow agents and tools to interact more smoothly,\nencourage collaboration, and triggering the formation of collective\nintelligence. In this paper, we provide a systematic overview of existing\ncommunication protocols for LLM agents. We classify them into four main\ncategories and make an analysis to help users and developers select the most\nsuitable protocols for specific applications. Additionally, we conduct a\ncomparative performance analysis of these protocols across key dimensions such\nas security, scalability, and latency. Finally, we explore future challenges,\nsuch as how protocols can adapt and survive in fast-evolving environments, and\nwhat qualities future protocols might need to support the next generation of\nLLM agent ecosystems. We expect this work to serve as a practical reference for\nboth researchers and engineers seeking to design, evaluate, or integrate robust\ncommunication infrastructures for intelligent agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16736v1",
    "published_date": "2025-04-23 14:07:26 UTC",
    "updated_date": "2025-04-23 14:07:26 UTC"
  },
  {
    "arxiv_id": "2504.16728v1",
    "title": "IRIS: Interactive Research Ideation System for Accelerating Scientific Discovery",
    "authors": [
      "Aniketh Garikaparthi",
      "Manasi Patwardhan",
      "Lovekesh Vig",
      "Arman Cohan"
    ],
    "abstract": "The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages main-text, 2 pages appendix",
    "pdf_url": "http://arxiv.org/pdf/2504.16728v1",
    "published_date": "2025-04-23 14:01:36 UTC",
    "updated_date": "2025-04-23 14:01:36 UTC"
  },
  {
    "arxiv_id": "2504.16727v2",
    "title": "V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations",
    "authors": [
      "Zhiyuan Fan",
      "Yumeng Wang",
      "Sandeep Polisetty",
      "Yi R. Fung"
    ],
    "abstract": "Large Vision Language Models (LVLMs) excel in various vision-language tasks.\nYet, their robustness to visual variations in position, scale, orientation, and\ncontext that objects in natural scenes inevitably exhibit due to changes in\nviewpoint and environment remains largely underexplored. To bridge this gap, we\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\ndataset generation and principled metrics for thorough robustness assessment.\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\nto visual variations, in which even advanced models that excel at complex\nvision-language tasks significantly underperform on simple tasks such as object\nrecognition. Interestingly, these models exhibit a distinct visual position\nbias that contradicts theories of effective receptive fields, and demonstrate a\nhuman-like visual acuity threshold. To identify the source of these\nvulnerabilities, we present a systematic framework for component-level\nanalysis, featuring a novel visualization approach for aligned visual features.\nResults show that these vulnerabilities stem from error accumulation in the\npipeline architecture and inadequate multimodal alignment. Complementary\nexperiments with synthetic data further demonstrate that these limitations are\nfundamentally architectural deficiencies, scoring the need for architectural\ninnovations in future LVLM designs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16727v2",
    "published_date": "2025-04-23 14:01:32 UTC",
    "updated_date": "2025-04-24 02:18:01 UTC"
  },
  {
    "arxiv_id": "2504.16723v1",
    "title": "Detecting and Understanding Hateful Contents in Memes Through Captioning and Visual Question-Answering",
    "authors": [
      "Ali Anaissi",
      "Junaid Akram",
      "Kunal Chaturvedi",
      "Ali Braytee"
    ],
    "abstract": "Memes are widely used for humor and cultural commentary, but they are\nincreasingly exploited to spread hateful content. Due to their multimodal\nnature, hateful memes often evade traditional text-only or image-only detection\nsystems, particularly when they employ subtle or coded references. To address\nthese challenges, we propose a multimodal hate detection framework that\nintegrates key components: OCR to extract embedded text, captioning to describe\nvisual content neutrally, sub-label classification for granular categorization\nof hateful content, RAG for contextually relevant retrieval, and VQA for\niterative analysis of symbolic and contextual cues. This enables the framework\nto uncover latent signals that simpler pipelines fail to detect. Experimental\nresults on the Facebook Hateful Memes dataset reveal that the proposed\nframework exceeds the performance of unimodal and conventional multimodal\nmodels in both accuracy and AUC-ROC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 2 figures, 2025 International Conference on Computational\n  Science",
    "pdf_url": "http://arxiv.org/pdf/2504.16723v1",
    "published_date": "2025-04-23 13:52:14 UTC",
    "updated_date": "2025-04-23 13:52:14 UTC"
  },
  {
    "arxiv_id": "2504.16722v1",
    "title": "PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum Learning",
    "authors": [
      "Yingjie Xi",
      "Jian Jun Zhang",
      "Xiaosong Yang"
    ],
    "abstract": "In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16722v1",
    "published_date": "2025-04-23 13:51:42 UTC",
    "updated_date": "2025-04-23 13:51:42 UTC"
  },
  {
    "arxiv_id": "2504.16680v1",
    "title": "Offline Robotic World Model: Learning Robotic Policies without a Physics Simulator",
    "authors": [
      "Chenhao Li",
      "Andreas Krause",
      "Marco Hutter"
    ],
    "abstract": "Reinforcement Learning (RL) has demonstrated impressive capabilities in\nrobotic control but remains challenging due to high sample complexity, safety\nconcerns, and the sim-to-real gap. While offline RL eliminates the need for\nrisky real-world exploration by learning from pre-collected data, it suffers\nfrom distributional shift, limiting policy generalization. Model-Based RL\n(MBRL) addresses this by leveraging predictive models for synthetic rollouts,\nyet existing approaches often lack robust uncertainty estimation, leading to\ncompounding errors in offline settings. We introduce Offline Robotic World\nModel (RWM-O), a model-based approach that explicitly estimates epistemic\nuncertainty to improve policy learning without reliance on a physics simulator.\nBy integrating these uncertainty estimates into policy optimization, our\napproach penalizes unreliable transitions, reducing overfitting to model errors\nand enhancing stability. Experimental results show that RWM-O improves\ngeneralization and safety, enabling policy learning purely from real-world data\nand advancing scalable, data-efficient RL for robotics.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16680v1",
    "published_date": "2025-04-23 12:58:15 UTC",
    "updated_date": "2025-04-23 12:58:15 UTC"
  },
  {
    "arxiv_id": "2504.16677v1",
    "title": "A Post-trainer's Guide to Multilingual Training Data: Uncovering Cross-lingual Transfer Dynamics",
    "authors": [
      "Luisa Shimabucoro",
      "Ahmet Ustun",
      "Marzieh Fadaee",
      "Sebastian Ruder"
    ],
    "abstract": "In order for large language models to be useful across the globe, they are\nfine-tuned to follow instructions on multilingual data. Despite the ubiquity of\nsuch post-training, a clear understanding of the dynamics that enable\ncross-lingual transfer remains elusive. This study examines cross-lingual\ntransfer (CLT) dynamics in realistic post-training settings. We study two model\nfamilies of up to 35B parameters in size trained on carefully controlled\nmixtures of multilingual data on three generative tasks with varying levels of\ncomplexity (summarization, instruction following, and mathematical reasoning)\nin both single-task and multi-task instruction tuning settings. Overall, we\nfind that the dynamics of cross-lingual transfer and multilingual performance\ncannot be explained by isolated variables, varying depending on the combination\nof post-training settings. Finally, we identify the conditions that lead to\neffective cross-lingual transfer in practice.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16677v1",
    "published_date": "2025-04-23 12:52:49 UTC",
    "updated_date": "2025-04-23 12:52:49 UTC"
  },
  {
    "arxiv_id": "2504.16667v1",
    "title": "Representation Learning via Non-Contrastive Mutual Information",
    "authors": [
      "Zhaohan Daniel Guo",
      "Bernardo Avila Pires",
      "Khimya Khetarpal",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "abstract": "Labeling data is often very time consuming and expensive, leaving us with a\nmajority of unlabeled data. Self-supervised representation learning methods\nsuch as SimCLR (Chen et al., 2020) or BYOL (Grill et al., 2020) have been very\nsuccessful at learning meaningful latent representations from unlabeled image\ndata, resulting in much more general and transferable representations for\ndownstream tasks. Broadly, self-supervised methods fall into two types: 1)\nContrastive methods, such as SimCLR; and 2) Non-Contrastive methods, such as\nBYOL. Contrastive methods are generally trying to maximize mutual information\nbetween related data points, so they need to compare every data point to every\nother data point, resulting in high variance, and thus requiring large batch\nsizes to work well. Non-contrastive methods like BYOL have much lower variance\nas they do not need to make pairwise comparisons, but are much trickier to\nimplement as they have the possibility of collapsing to a constant vector. In\nthis paper, we aim to develop a self-supervised objective that combines the\nstrength of both types. We start with a particular contrastive method called\nthe Spectral Contrastive Loss (HaoChen et al., 2021; Lu et al., 2024), and we\nconvert it into a more general non-contrastive form; this removes the pairwise\ncomparisons resulting in lower variance, but keeps the mutual information\nformulation of the contrastive method preventing collapse. We call our new\nobjective the Mutual Information Non-Contrastive (MINC) loss. We test MINC by\nlearning image representations on ImageNet (similar to SimCLR and BYOL) and\nshow that it consistently improves upon the Spectral Contrastive loss baseline.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML",
      "I.2.6; I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16667v1",
    "published_date": "2025-04-23 12:35:27 UTC",
    "updated_date": "2025-04-23 12:35:27 UTC"
  },
  {
    "arxiv_id": "2504.16651v1",
    "title": "MAYA: Addressing Inconsistencies in Generative Password Guessing through a Unified Benchmark",
    "authors": [
      "William Corrias",
      "Fabio De Gaspari",
      "Dorjan Hitaj",
      "Luigi V. Mancini"
    ],
    "abstract": "The rapid evolution of generative models has led to their integration across\nvarious fields, including password guessing, aiming to generate passwords that\nresemble human-created ones in complexity, structure, and patterns. Despite\ngenerative model's promise, inconsistencies in prior research and a lack of\nrigorous evaluation have hindered a comprehensive understanding of their true\npotential. In this paper, we introduce MAYA, a unified, customizable,\nplug-and-play password benchmarking framework. MAYA provides a standardized\napproach for evaluating generative password-guessing models through a rigorous\nset of advanced testing scenarios and a collection of eight real-life password\ndatasets. Using MAYA, we comprehensively evaluate six state-of-the-art\napproaches, which have been re-implemented and adapted to ensure\nstandardization, for a total of over 15,000 hours of computation. Our findings\nindicate that these models effectively capture different aspects of human\npassword distribution and exhibit strong generalization capabilities. However,\ntheir effectiveness varies significantly with long and complex passwords.\nThrough our evaluation, sequential models consistently outperform other\ngenerative architectures and traditional password-guessing tools, demonstrating\nunique capabilities in generating accurate and complex guesses. Moreover,\nmodels learn and generate different password distributions, enabling a\nmulti-model attack that outperforms the best individual model. By releasing\nMAYA, we aim to foster further research, providing the community with a new\ntool to consistently and reliably benchmark password-generation techniques. Our\nframework is publicly available at\nhttps://github.com/williamcorrias/MAYA-Password-Benchmarking",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16651v1",
    "published_date": "2025-04-23 12:16:59 UTC",
    "updated_date": "2025-04-23 12:16:59 UTC"
  },
  {
    "arxiv_id": "2504.16640v1",
    "title": "SSLR: A Semi-Supervised Learning Method for Isolated Sign Language Recognition",
    "authors": [
      "Hasan Algafri",
      "Hamzah Luqman",
      "Sarah Alyami",
      "Issam Laradji"
    ],
    "abstract": "Sign language is the primary communication language for people with disabling\nhearing loss. Sign language recognition (SLR) systems aim to recognize sign\ngestures and translate them into spoken language. One of the main challenges in\nSLR is the scarcity of annotated datasets. To address this issue, we propose a\nsemi-supervised learning (SSL) approach for SLR (SSLR), employing a\npseudo-label method to annotate unlabeled samples. The sign gestures are\nrepresented using pose information that encodes the signer's skeletal joint\npoints. This information is used as input for the Transformer backbone model\nutilized in the proposed approach. To demonstrate the learning capabilities of\nSSL across various labeled data sizes, several experiments were conducted using\ndifferent percentages of labeled data with varying numbers of classes. The\nperformance of the SSL approach was compared with a fully supervised\nlearning-based model on the WLASL-100 dataset. The obtained results of the SSL\nmodel outperformed the supervised learning-based model with less labeled data\nin many cases.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16640v1",
    "published_date": "2025-04-23 11:59:52 UTC",
    "updated_date": "2025-04-23 11:59:52 UTC"
  },
  {
    "arxiv_id": "2504.16635v1",
    "title": "Bridging Econometrics and AI: VaR Estimation via Reinforcement Learning and GARCH Models",
    "authors": [
      "Fredy Pokou",
      "Jules Sadefo Kamdem",
      "François Benhmad"
    ],
    "abstract": "In an environment of increasingly volatile financial markets, the accurate\nestimation of risk remains a major challenge. Traditional econometric models,\nsuch as GARCH and its variants, are based on assumptions that are often too\nrigid to adapt to the complexity of the current market dynamics. To overcome\nthese limitations, we propose a hybrid framework for Value-at-Risk (VaR)\nestimation, combining GARCH volatility models with deep reinforcement learning.\nOur approach incorporates directional market forecasting using the Double Deep\nQ-Network (DDQN) model, treating the task as an imbalanced classification\nproblem. This architecture enables the dynamic adjustment of risk-level\nforecasts according to market conditions. Empirical validation on daily\nEurostoxx 50 data covering periods of crisis and high volatility shows a\nsignificant improvement in the accuracy of VaR estimates, as well as a\nreduction in the number of breaches and also in capital requirements, while\nrespecting regulatory risk thresholds. The ability of the model to adjust risk\nlevels in real time reinforces its relevance to modern and proactive risk\nmanagement.",
    "categories": [
      "cs.AI",
      "q-fin.CP",
      "q-fin.RM",
      "q-fin.ST"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16635v1",
    "published_date": "2025-04-23 11:54:22 UTC",
    "updated_date": "2025-04-23 11:54:22 UTC"
  },
  {
    "arxiv_id": "2504.16622v1",
    "title": "Cognitive Silicon: An Architectural Blueprint for Post-Industrial Computing Systems",
    "authors": [
      "Christoforus Yoga Haryanto",
      "Emily Lomempow"
    ],
    "abstract": "Autonomous AI systems reveal foundational limitations in deterministic,\nhuman-authored computing architectures. This paper presents Cognitive Silicon:\na hypothetical full-stack architectural framework projected toward 2035,\nexploring a possible trajectory for cognitive computing system design. The\nproposed architecture would integrate symbolic scaffolding, governed memory,\nruntime moral coherence, and alignment-aware execution across\nsilicon-to-semantics layers. Our design grammar has emerged from dialectical\nco-design with LLMs under asymmetric epistemic conditions--creating structured\nfriction to expose blind spots and trade-offs. The envisioned framework would\nestablish mortality as a natural consequence of physical constraints,\nnon-copyable tacit knowledge, and non-cloneable identity keys as\ncognitive-embodiment primitives. Core tensions (trust/agency,\nscaffolding/emergence, execution/governance) would function as central\narchitectural pressures rather than edge cases. The architecture theoretically\nconverges with the Free Energy Principle, potentially offering a formal account\nof how cognitive systems could maintain identity through prediction error\nminimization across physical and computational boundaries. The resulting\nframework aims to deliver a morally tractable cognitive infrastructure that\ncould maintain human-alignment through irreversible hardware constraints and\nidentity-bound epistemic mechanisms resistant to replication or subversion.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Working Paper, 37 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.16622v1",
    "published_date": "2025-04-23 11:24:30 UTC",
    "updated_date": "2025-04-23 11:24:30 UTC"
  },
  {
    "arxiv_id": "2504.16604v1",
    "title": "Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories",
    "authors": [
      "Mareike Lisker",
      "Christina Gottschalk",
      "Helena Mihaljević"
    ],
    "abstract": "Counterspeech is a key strategy against harmful online content, but scaling\nexpert-driven efforts is challenging. Large Language Models (LLMs) present a\npotential solution, though their use in countering conspiracy theories is\nunder-researched. Unlike for hate speech, no datasets exist that pair\nconspiracy theory comments with expert-crafted counterspeech. We address this\ngap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively\napply counterspeech strategies derived from psychological research provided\nthrough structured prompts. Our results show that the models often generate\ngeneric, repetitive, or superficial results. Additionally, they\nover-acknowledge fear and frequently hallucinate facts, sources, or figures,\nmaking their prompt-based use in practical applications problematic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.16604v1",
    "published_date": "2025-04-23 10:32:45 UTC",
    "updated_date": "2025-04-23 10:32:45 UTC"
  },
  {
    "arxiv_id": "2504.16601v1",
    "title": "Comparing Large Language Models and Traditional Machine Translation Tools for Translating Medical Consultation Summaries: A Pilot Study",
    "authors": [
      "Andy Li",
      "Wei Zhou",
      "Rashina Hoda",
      "Chris Bain",
      "Peter Poon"
    ],
    "abstract": "This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 tables and 1 Figure",
    "pdf_url": "http://arxiv.org/pdf/2504.16601v1",
    "published_date": "2025-04-23 10:31:33 UTC",
    "updated_date": "2025-04-23 10:31:33 UTC"
  },
  {
    "arxiv_id": "2504.16584v1",
    "title": "Case Study: Fine-tuning Small Language Models for Accurate and Private CWE Detection in Python Code",
    "authors": [
      "Md. Azizul Hakim Bappy",
      "Hossen A Mustafa",
      "Prottoy Saha",
      "Rajinus Salehat"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and analyzing code for security vulnerabilities, such as Common\nWeakness Enumerations (CWEs). However, their reliance on cloud infrastructure\nand substantial computational requirements pose challenges for analyzing\nsensitive or proprietary codebases due to privacy concerns and inference costs.\nThis work explores the potential of Small Language Models (SLMs) as a viable\nalternative for accurate, on-premise vulnerability detection. We investigated\nwhether a 350-million parameter pre-trained code model (codegen-mono) could be\neffectively fine-tuned to detect the MITRE Top 25 CWEs specifically within\nPython code. To facilitate this, we developed a targeted dataset of 500\nexamples using a semi-supervised approach involving LLM-driven synthetic data\ngeneration coupled with meticulous human review. Initial tests confirmed that\nthe base codegen-mono model completely failed to identify CWEs in our samples.\nHowever, after applying instruction-following fine-tuning, the specialized SLM\nachieved remarkable performance on our test set, yielding approximately 99%\naccuracy, 98.08% precision, 100% recall, and a 99.04% F1-score. These results\nstrongly suggest that fine-tuned SLMs can serve as highly accurate and\nefficient tools for CWE detection, offering a practical and privacy-preserving\nsolution for integrating advanced security analysis directly into development\nworkflows.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 2 figures, 3 tables. Dataset available at\n  https://huggingface.co/datasets/floxihunter/synthetic_python_cwe. Model\n  available at https://huggingface.co/floxihunter/codegen-mono-CWEdetect.\n  Keywords: Small Language Models (SLMs), Vulnerability Detection, CWE,\n  Fine-tuning, Python Security, Privacy-Preserving Code Analysis",
    "pdf_url": "http://arxiv.org/pdf/2504.16584v1",
    "published_date": "2025-04-23 10:05:27 UTC",
    "updated_date": "2025-04-23 10:05:27 UTC"
  },
  {
    "arxiv_id": "2504.16576v1",
    "title": "MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation",
    "authors": [
      "Xu Guo",
      "Tong Zhang",
      "Fuyun Wang",
      "Xudong Wang",
      "Xiaoya Zhang",
      "Xin Liu",
      "Zhen Cui"
    ],
    "abstract": "The burgeoning presence of multimodal content-sharing platforms propels the\ndevelopment of personalized recommender systems. Previous works usually suffer\nfrom data sparsity and cold-start problems, and may fail to adequately explore\nsemantic user-product associations from multimodal data. To address these\nissues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL)\nframework for user recommendation. For a comprehensive information exploration\nfrom user-product relations, we construct two hypergraphs, i.e. a user-to-user\n(u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine shared\npreferences among users and intricate multimodal semantic resemblance among\nitems, respectively. This process yields denser second-order semantics that are\nfused with first-order user-item interaction as complementary to alleviate the\ndata sparsity issue. Then, we design a contrastive feature enhancement paradigm\nby applying synergistic contrastive learning. By maximizing/minimizing the\nmutual information between second-order (e.g. shared preference pattern for\nusers) and first-order (information of selected items for users) embeddings of\nthe same/different users and items, the feature distinguishability can be\neffectively enhanced. Compared with using sparse primary user-item interaction\nonly, our MMHCL obtains denser second-order hypergraphs and excavates more\nabundant shared attributes to explore the user-product associations, which to a\ncertain extent alleviates the problems of data sparsity and cold-start.\nExtensive experiments have comprehensively demonstrated the effectiveness of\nour method. Our code is publicly available at: https://github.com/Xu107/MMHCL.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "23 pages, 8 figures. This manuscript is currently under major\n  revision for ACM Transactions on Multimedia Computing, Communications, and\n  Applications (ACM TOMM)",
    "pdf_url": "http://arxiv.org/pdf/2504.16576v1",
    "published_date": "2025-04-23 09:58:54 UTC",
    "updated_date": "2025-04-23 09:58:54 UTC"
  },
  {
    "arxiv_id": "2504.16574v1",
    "title": "PIS: Linking Importance Sampling and Attention Mechanisms for Efficient Prompt Compression",
    "authors": [
      "Lizhe Chen",
      "Binjia Zhou",
      "Yuyao Ge",
      "Jiayi Chen",
      "Shiguang NI"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16574v1",
    "published_date": "2025-04-23 09:53:01 UTC",
    "updated_date": "2025-04-23 09:53:01 UTC"
  },
  {
    "arxiv_id": "2504.16573v1",
    "title": "PsyCounAssist: A Full-Cycle AI-Powered Psychological Counseling Assistant System",
    "authors": [
      "Xianghe Liu",
      "Jiaqi Xu",
      "Tao Sun"
    ],
    "abstract": "Psychological counseling is a highly personalized and dynamic process that\nrequires therapists to continuously monitor emotional changes, document session\ninsights, and maintain therapeutic continuity. In this paper, we introduce\nPsyCounAssist, a comprehensive AI-powered counseling assistant system\nspecifically designed to augment psychological counseling practices.\nPsyCounAssist integrates multimodal emotion recognition combining speech and\nphotoplethysmography (PPG) signals for accurate real-time affective analysis,\nautomated structured session reporting using large language models (LLMs), and\npersonalized AI-generated follow-up support. Deployed on Android-based tablet\ndevices, the system demonstrates practical applicability and flexibility in\nreal-world counseling scenarios. Experimental evaluation confirms the\nreliability of PPG-based emotional classification and highlights the system's\npotential for non-intrusive, privacy-aware emotional support. PsyCounAssist\nrepresents a novel approach to ethically and effectively integrating AI into\npsychological counseling workflows.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16573v1",
    "published_date": "2025-04-23 09:49:05 UTC",
    "updated_date": "2025-04-23 09:49:05 UTC"
  },
  {
    "arxiv_id": "2504.16562v1",
    "title": "A Vision for AI-Driven Adaptation of Dynamic AR Content to Users and Environments",
    "authors": [
      "Julian Rasch",
      "Florian Müller",
      "Francesco Chiossi"
    ],
    "abstract": "Augmented Reality (AR) is transforming the way we interact with virtual\ninformation in the physical world. By overlaying digital content in real-world\nenvironments, AR enables new forms of immersive and engaging experiences.\nHowever, existing AR systems often struggle to effectively manage the many\ninteractive possibilities that AR presents. This vision paper speculates on\nAI-driven approaches for adaptive AR content placement, dynamically adjusting\nto user movement and environmental changes. By leveraging machine learning\nmethods, such a system would intelligently manage content distribution between\nAR projections integrated into the external environment and fixed static\ncontent, enabling seamless UI layout and potentially reducing users' cognitive\nload. By exploring the possibilities of AI-driven dynamic AR content placement,\nwe aim to envision new opportunities for innovation and improvement in various\nindustries, from urban navigation and workplace productivity to immersive\nlearning and beyond. This paper outlines a vision for the development of more\nintuitive, engaging, and effective AI-powered AR experiences.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16562v1",
    "published_date": "2025-04-23 09:42:38 UTC",
    "updated_date": "2025-04-23 09:42:38 UTC"
  },
  {
    "arxiv_id": "2504.16548v1",
    "title": "Exploring human-SAV interaction using large language models: The impact of psychological ownership and anthropomorphism on user experience",
    "authors": [
      "Lirui Guo",
      "Michael G. Burke",
      "Wynita M. Griggs"
    ],
    "abstract": "There has been extensive prior work exploring how psychological factors such\nas anthropomorphism affect the adoption of shared autonomous vehicles (SAVs).\nHowever, limited research has been conducted on how prompt strategies in large\nlanguage model (LLM)-powered SAV User Interfaces (UIs) affect users'\nperceptions, experiences, and intentions to adopt such technology. In this\nwork, we investigate how conversational UIs powered by LLMs drive these\npsychological factors and psychological ownership, the sense of possession a\nuser may come to feel towards an entity or object they may not legally own. We\ndesigned four SAV UIs with varying levels of anthropomorphic characteristics\nand psychological ownership triggers. Quantitative measures of psychological\nownership, anthropomorphism, quality of service, disclosure tendency, sentiment\nof SAV responses, and overall acceptance were collected after participants\ninteracted with each SAV. Qualitative feedback was also gathered regarding the\nexperience of psychological ownership during the interactions. The results\nindicate that an SAV conversational UI designed to be more anthropomorphic and\nto induce psychological ownership improved users' perceptions of the SAV's\nhuman-like qualities and improved the sentiment of responses compared to a\ncontrol condition. These findings provide practical guidance for designing\nLLM-based conversational UIs that enhance user experience and adoption of SAVs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16548v1",
    "published_date": "2025-04-23 09:25:22 UTC",
    "updated_date": "2025-04-23 09:25:22 UTC"
  },
  {
    "arxiv_id": "2504.16537v1",
    "title": "Transformers for Complex Query Answering over Knowledge Hypergraphs",
    "authors": [
      "Hong Ting Tsang",
      "Zihao Wang",
      "Yangqiu Song"
    ],
    "abstract": "Complex Query Answering (CQA) has been extensively studied in recent years.\nIn order to model data that is closer to real-world distribution, knowledge\ngraphs with different modalities have been introduced. Triple KGs, as the\nclassic KGs composed of entities and relations of arity 2, have limited\nrepresentation of real-world facts. Real-world data is more sophisticated.\nWhile hyper-relational graphs have been introduced, there are limitations in\nrepresenting relationships of varying arity that contain entities with equal\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\nM-FB15k-HCQA. Each dataset contains various query types that include logical\noperations such as projection, negation, conjunction, and disjunction. In order\nto answer knowledge hypergraph (KHG) existential first-order queries, we\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\nprojection and a Logical Encoder for complex logical operations. Both encoders\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\nmethod over KHG and is able to generalize to out-of-distribution query types.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16537v1",
    "published_date": "2025-04-23 09:07:21 UTC",
    "updated_date": "2025-04-23 09:07:21 UTC"
  },
  {
    "arxiv_id": "2504.16516v1",
    "title": "Think Hierarchically, Act Dynamically: Hierarchical Multi-modal Fusion and Reasoning for Vision-and-Language Navigation",
    "authors": [
      "Junrong Yue",
      "Yifan Zhang",
      "Chuan Qin",
      "Bo Li",
      "Xiaomin Lie",
      "Xinlei Yu",
      "Wenxin Zhang",
      "Zhendong Zhao"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) aims to enable embodied agents to follow\nnatural language instructions and reach target locations in real-world\nenvironments. While prior methods often rely on either global scene\nrepresentations or object-level features, these approaches are insufficient for\ncapturing the complex interactions across modalities required for accurate\nnavigation. In this paper, we propose a Multi-level Fusion and Reasoning\nArchitecture (MFRA) to enhance the agent's ability to reason over visual\nobservations, language instructions and navigation history. Specifically, MFRA\nintroduces a hierarchical fusion mechanism that aggregates multi-level\nfeatures-ranging from low-level visual cues to high-level semantic\nconcepts-across multiple modalities. We further design a reasoning module that\nleverages fused representations to infer navigation actions through\ninstruction-guided attention and dynamic context integration. By selectively\ncapturing and combining relevant visual, linguistic, and temporal signals, MFRA\nimproves decision-making accuracy in complex navigation scenarios. Extensive\nexperiments on benchmark VLN datasets including REVERIE, R2R, and SOON\ndemonstrate that MFRA achieves superior performance compared to\nstate-of-the-art methods, validating the effectiveness of multi-level modal\nfusion for embodied navigation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 4 figures, Submitted to ACM MM 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16516v1",
    "published_date": "2025-04-23 08:41:27 UTC",
    "updated_date": "2025-04-23 08:41:27 UTC"
  },
  {
    "arxiv_id": "2504.16515v1",
    "title": "Federated Learning of Low-Rank One-Shot Image Detection Models in Edge Devices with Scalable Accuracy and Compute Complexity",
    "authors": [
      "Abdul Hannaan",
      "Zubair Shah",
      "Aiman Erbad",
      "Amr Mohamed",
      "Ali Safa"
    ],
    "abstract": "This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted for publication at IEEE IWCMC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16515v1",
    "published_date": "2025-04-23 08:40:44 UTC",
    "updated_date": "2025-04-23 08:40:44 UTC"
  },
  {
    "arxiv_id": "2504.16489v1",
    "title": "Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based Multi-Agent Debate",
    "authors": [
      "Senmao Qi",
      "Yifei Zou",
      "Peng Li",
      "Ziyi Lin",
      "Xiuzhen Cheng",
      "Dongxiao Yu"
    ],
    "abstract": "Multi-Agent Debate (MAD), leveraging collaborative interactions among Large\nLanguage Models (LLMs), aim to enhance reasoning capabilities in complex tasks.\nHowever, the security implications of their iterative dialogues and\nrole-playing characteristics, particularly susceptibility to jailbreak attacks\neliciting harmful content, remain critically underexplored. This paper\nsystematically investigates the jailbreak vulnerabilities of four prominent MAD\nframeworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo,\nand DeepSeek) without compromising internal agents. We introduce a novel\nstructured prompt-rewriting framework specifically designed to exploit MAD\ndynamics via narrative encapsulation, role-driven escalation, iterative\nrefinement, and rhetorical obfuscation. Our extensive experiments demonstrate\nthat MAD systems are inherently more vulnerable than single-agent setups.\nCrucially, our proposed attack methodology significantly amplifies this\nfragility, increasing average harmfulness from 28.14% to 80.34% and achieving\nattack success rates as high as 80% in certain scenarios. These findings reveal\nintrinsic vulnerabilities in MAD architectures and underscore the urgent need\nfor robust, specialized defenses prior to real-world deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "33 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16489v1",
    "published_date": "2025-04-23 08:01:50 UTC",
    "updated_date": "2025-04-23 08:01:50 UTC"
  },
  {
    "arxiv_id": "2504.16485v1",
    "title": "On Developers' Self-Declaration of AI-Generated Code: An Analysis of Practices",
    "authors": [
      "Syed Mohammad Kashif",
      "Peng Liang",
      "Amjed Tahir"
    ],
    "abstract": "AI code generation tools have gained significant popularity among developers,\nwho use them to assist in software development due to their capability to\ngenerate code. Existing studies mainly explored the quality, e.g., correctness\nand security, of AI-generated code, while in real-world software development,\nthe prerequisite is to distinguish AI-generated code from human-written code,\nwhich emphasizes the need to explicitly declare AI-generated code by\ndevelopers. To this end, this study intends to understand the ways developers\nuse to self-declare AI-generated code and explore the reasons why developers\nchoose to self-declare or not. We conducted a mixed-methods study consisting of\ntwo phases. In the first phase, we mined GitHub repositories and collected 613\ninstances of AI-generated code snippets. In the second phase, we conducted a\nfollow-up industrial survey, which received 111 valid responses. Our research\nrevealed the practices followed by developers to self-declare AI-generated\ncode. Most practitioners (76.6%) always or sometimes self-declare AI-generated\ncode. In contrast, other practitioners (23.4%) noted that they never\nself-declare AI-generated code. The reasons for self-declaring AI-generated\ncode include the need to track and monitor the code for future review and\ndebugging, and ethical considerations. The reasons for not self-declaring\nAI-generated code include extensive modifications to AI-generated code and the\ndevelopers' perception that self-declaration is an unnecessary activity. We\nfinally provided guidelines for practitioners to self-declare AI-generated\ncode, addressing ethical and code quality concerns.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "35 pages, 17 images, 8 tables, Manuscript submitted to a journal\n  (2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.16485v1",
    "published_date": "2025-04-23 07:52:39 UTC",
    "updated_date": "2025-04-23 07:52:39 UTC"
  },
  {
    "arxiv_id": "2504.16479v1",
    "title": "The Dance of Atoms-De Novo Protein Design with Diffusion Model",
    "authors": [
      "Yujie Qin",
      "Ming He",
      "Changyong Yu",
      "Ming Ni",
      "Xian Liu",
      "Xiaochen Bo"
    ],
    "abstract": "The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16479v1",
    "published_date": "2025-04-23 07:45:00 UTC",
    "updated_date": "2025-04-23 07:45:00 UTC"
  },
  {
    "arxiv_id": "2504.16472v1",
    "title": "Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges",
    "authors": [
      "Mark Harman",
      "Peter O'Hearn",
      "Shubho Sengupta"
    ],
    "abstract": "Despite decades of research and practice in automated software testing,\nseveral fundamental concepts remain ill-defined and under-explored, yet offer\nenormous potential real-world impact. We show that these concepts raise\nexciting new challenges in the context of Large Language Models for software\ntest generation. More specifically, we formally define and investigate the\nproperties of hardening and catching tests. A hardening test is one that seeks\nto protect against future regressions, while a catching test is one that\ncatches such a regression or a fault in new functionality introduced by a code\nchange. Hardening tests can be generated at any time and may become catching\ntests when a future regression is caught. We also define and motivate the\nCatching `Just-in-Time' (JiTTest) Challenge, in which tests are generated\n`just-in-time' to catch new faults before they land into production. We show\nthat any solution to Catching JiTTest generation can also be repurposed to\ncatch latent faults in legacy code. We enumerate possible outcomes for\nhardening and catching tests and JiTTests, and discuss open research problems,\ndeployment options, and initial results from our work on automated LLM-based\nhardening at Meta. This paper\\footnote{Author order is alphabetical. The\ncorresponding author is Mark Harman.} was written to accompany the keynote by\nthe authors at the ACM International Conference on the Foundations of Software\nEngineering (FSE) 2025.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "To Appear as keynote paper at FSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16472v1",
    "published_date": "2025-04-23 07:32:43 UTC",
    "updated_date": "2025-04-23 07:32:43 UTC"
  },
  {
    "arxiv_id": "2504.16464v1",
    "title": "ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance",
    "authors": [
      "Ying Li",
      "Xiaobao Wei",
      "Xiaowei Chi",
      "Yuming Li",
      "Zhongyu Zhao",
      "Hao Wang",
      "Ningning Ma",
      "Ming Lu",
      "Shanghang Zhang"
    ],
    "abstract": "While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16464v1",
    "published_date": "2025-04-23 07:23:41 UTC",
    "updated_date": "2025-04-23 07:23:41 UTC"
  },
  {
    "arxiv_id": "2504.16460v1",
    "title": "T-VEC: A Telecom-Specific Vectorization Model with Enhanced Semantic Understanding via Deep Triplet Loss Fine-Tuning",
    "authors": [
      "Vignesh Ethiraj",
      "Sidhanth Menon",
      "Divya Vijay"
    ],
    "abstract": "The specialized vocabulary and complex concepts of the telecommunications\nindustry present significant challenges for standard Natural Language\nProcessing models. Generic text embeddings often fail to capture\ntelecom-specific semantics, hindering downstream task performance. We introduce\nT-VEC (Telecom Vectorization Model), a novel embedding model tailored for the\ntelecom domain through deep fine-tuning. Developed by NetoAI, T-VEC is created\nby adapting the state-of-the-art gte-Qwen2-1.5B-instruct model using a triplet\nloss objective on a meticulously curated, large-scale dataset of\ntelecom-specific data. Crucially, this process involved substantial\nmodification of weights across 338 layers of the base model, ensuring deep\nintegration of domain knowledge, far exceeding superficial adaptation\ntechniques. We quantify this deep change via weight difference analysis. A key\ncontribution is the development and open-sourcing (MIT License) of the first\ndedicated telecom-specific tokenizer, enhancing the handling of industry\njargon. T-VEC achieves a leading average MTEB score (0.825) compared to\nestablished models and demonstrates vastly superior performance (0.9380 vs.\nless than 0.07) on our internal telecom-specific triplet evaluation benchmark,\nindicating an exceptional grasp of domain-specific nuances, visually confirmed\nby improved embedding separation. This work positions NetoAI at the forefront\nof telecom AI innovation, providing the community with a powerful, deeply\nadapted, open-source tool.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.CL",
    "comment": "Introduces T-VEC, a telecom-specific text embedding model. Fine-tuned\n  gte-Qwen2-1.5B-instruct on curated telecom data points. Includes the first\n  open-source telecom tokenizer. Model available at\n  https://huggingface.co/NetoAISolutions/T-VEC",
    "pdf_url": "http://arxiv.org/pdf/2504.16460v1",
    "published_date": "2025-04-23 07:10:37 UTC",
    "updated_date": "2025-04-23 07:10:37 UTC"
  },
  {
    "arxiv_id": "2504.16448v1",
    "title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records",
    "authors": [
      "Shuguang Zhao",
      "Qiangzhong Feng",
      "Zhiyang He",
      "Peipei Sun",
      "Yingying Wang",
      "Xiaodong Tao",
      "Xiaoliang Lu",
      "Mei Cheng",
      "Xinyue Wu",
      "Yanyan Wang",
      "Wei Liang"
    ],
    "abstract": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16448v1",
    "published_date": "2025-04-23 06:17:55 UTC",
    "updated_date": "2025-04-23 06:17:55 UTC"
  },
  {
    "arxiv_id": "2504.16438v1",
    "title": "Private Federated Learning using Preference-Optimized Synthetic Data",
    "authors": [
      "Charlie Hou",
      "Mei-Yu Wang",
      "Yige Zhu",
      "Daniel Lazar",
      "Giulia Fanti"
    ],
    "abstract": "In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Spotlight presentation at SynthData Workshop ICLR25",
    "pdf_url": "http://arxiv.org/pdf/2504.16438v1",
    "published_date": "2025-04-23 05:57:20 UTC",
    "updated_date": "2025-04-23 05:57:20 UTC"
  },
  {
    "arxiv_id": "2504.16432v1",
    "title": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network",
    "authors": [
      "Ziran Liang",
      "Rui An",
      "Wenqi Fan",
      "Yanghui Rao",
      "Yuxuan Liang"
    ],
    "abstract": "As time evolves, data within specific domains exhibit predictability that\nmotivates time series forecasting to predict future trends from historical\ndata. However, current deep forecasting methods can achieve promising\nperformance but generally lack interpretability, hindering trustworthiness and\npractical deployment in safety-critical applications such as auto-driving and\nhealthcare. In this paper, we propose a novel interpretable model, iTFKAN, for\ncredible time series forecasting. iTFKAN enables further exploration of model\ndecision rationales and underlying data patterns due to its interpretability\nachieved through model symbolization. Besides, iTFKAN develops two strategies,\nprior knowledge injection, and time-frequency synergy learning, to effectively\nguide model learning under complex intertwined time series data. Extensive\nexperimental results demonstrated that iTFKAN can achieve promising forecasting\nperformance while simultaneously possessing high interpretive capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16432v1",
    "published_date": "2025-04-23 05:34:49 UTC",
    "updated_date": "2025-04-23 05:34:49 UTC"
  },
  {
    "arxiv_id": "2504.16427v2",
    "title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark",
    "authors": [
      "Hanlei Zhang",
      "Zhuohang Li",
      "Yeshuang Zhu",
      "Hua Xu",
      "Peiwu Wang",
      "Haige Zhu",
      "Jie Zhou",
      "Jinchao Zhang"
    ],
    "abstract": "Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16427v2",
    "published_date": "2025-04-23 05:25:13 UTC",
    "updated_date": "2025-04-24 07:35:03 UTC"
  },
  {
    "arxiv_id": "2504.16420v1",
    "title": "A Survey of Foundation Model-Powered Recommender Systems: From Feature-Based, Generative to Agentic Paradigms",
    "authors": [
      "Chengkai Huang",
      "Hongtao Huang",
      "Tong Yu",
      "Kaige Xie",
      "Junda Wu",
      "Shuai Zhang",
      "Julian Mcauley",
      "Dietmar Jannach",
      "Lina Yao"
    ],
    "abstract": "Recommender systems (RS) have become essential in filtering information and\npersonalizing content for users. RS techniques have traditionally relied on\nmodeling interactions between users and items as well as the features of\ncontent using models specific to each task. The emergence of foundation models\n(FMs), large scale models trained on vast amounts of data such as GPT, LLaMA\nand CLIP, is reshaping the recommendation paradigm. This survey provides a\ncomprehensive overview of the Foundation Models for Recommender Systems\n(FM4RecSys), covering their integration in three paradigms: (1) Feature-Based\naugmentation of representations, (2) Generative recommendation approaches, and\n(3) Agentic interactive systems. We first review the data foundations of RS,\nfrom traditional explicit or implicit feedback to multimodal content sources.\nWe then introduce FMs and their capabilities for representation learning,\nnatural language understanding, and multi-modal reasoning in RS contexts. The\ncore of the survey discusses how FMs enhance RS under different paradigms.\nAfterward, we examine FM applications in various recommendation tasks. Through\nan analysis of recent research, we highlight key opportunities that have been\nrealized as well as challenges encountered. Finally, we outline open research\ndirections and technical challenges for next-generation FM4RecSys. This survey\nnot only reviews the state-of-the-art methods but also provides a critical\nanalysis of the trade-offs among the feature-based, the generative, and the\nagentic paradigms, outlining key open issues and future research directions.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16420v1",
    "published_date": "2025-04-23 05:02:51 UTC",
    "updated_date": "2025-04-23 05:02:51 UTC"
  },
  {
    "arxiv_id": "2504.16419v1",
    "title": "PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels",
    "authors": [
      "Qi Yang",
      "Weichen Bi",
      "Haiyang Shen",
      "Yaoqi Guo",
      "Yun Ma"
    ],
    "abstract": "Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16419v1",
    "published_date": "2025-04-23 05:01:25 UTC",
    "updated_date": "2025-04-23 05:01:25 UTC"
  },
  {
    "arxiv_id": "2504.16416v1",
    "title": "FeedQUAC: Quick Unobtrusive AI-Generated Commentary",
    "authors": [
      "Tao Long",
      "Kendra Wannamaker",
      "Jo Vermeulen",
      "George Fitzmaurice",
      "Justin Matejka"
    ],
    "abstract": "Design thrives on feedback. However, gathering constant feedback throughout\nthe design process can be labor-intensive and disruptive. We explore how AI can\nbridge this gap by providing effortless, ambient feedback. We introduce\nFeedQUAC, a design companion that delivers real-time AI-generated commentary\nfrom a variety of perspectives through different personas. A design probe study\nwith eight participants highlights how designers can leverage quick yet ambient\nAI feedback to enhance their creative workflows. Participants highlight\nbenefits such as convenience, playfulness, confidence boost, and inspiration\nfrom this lightweight feedback agent, while suggesting additional features,\nlike chat interaction and context curation. We discuss the role of AI feedback,\nits strengths and limitations, and how to integrate it into existing design\nworkflows while balancing user involvement. Our findings also suggest that\nambient interaction is a valuable consideration for both the design and\nevaluation of future creativity support systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "20 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16416v1",
    "published_date": "2025-04-23 04:48:00 UTC",
    "updated_date": "2025-04-23 04:48:00 UTC"
  },
  {
    "arxiv_id": "2504.16404v1",
    "title": "Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection",
    "authors": [
      "Md Fahimuzzman Sohan"
    ],
    "abstract": "Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16404v1",
    "published_date": "2025-04-23 04:17:41 UTC",
    "updated_date": "2025-04-23 04:17:41 UTC"
  },
  {
    "arxiv_id": "2504.16394v1",
    "title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs",
    "authors": [
      "Fahmida Liza Piya",
      "Rahmatollah Beheshti"
    ],
    "abstract": "Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16394v1",
    "published_date": "2025-04-23 03:42:46 UTC",
    "updated_date": "2025-04-23 03:42:46 UTC"
  },
  {
    "arxiv_id": "2504.16381v1",
    "title": "PINN-MEP: Continuous Neural Representations for Minimum-Energy Path Discovery in Molecular Systems",
    "authors": [
      "Magnus Petersen",
      "Roberto Covino"
    ],
    "abstract": "Characterizing conformational transitions in physical systems remains a\nfundamental challenge in the computational sciences. Traditional sampling\nmethods like molecular dynamics (MD) or MCMC often struggle with the\nhigh-dimensional nature of molecular systems and the high energy barriers of\ntransitions between stable states. While these transitions are rare events in\nsimulation timescales, they often represent the most biologically significant\nprocesses - for example, the conformational change of an ion channel protein\nfrom its closed to open state, which controls cellular ion flow and is crucial\nfor neural signaling. Such transitions in real systems may take milliseconds to\nseconds but could require months or years of continuous simulation to observe\neven once. We present a method that reformulates transition path generation as\na continuous optimization problem solved through physics-informed neural\nnetworks (PINNs) inspired by string methods for minimum-energy path (MEP)\ngeneration. By representing transition paths as implicit neural functions and\nleveraging automatic differentiation with differentiable molecular dynamics\nforce fields, our method enables the efficient discovery of physically\nrealistic transition pathways without requiring expensive path sampling. We\ndemonstrate our method's effectiveness on two proteins, including an explicitly\nhydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300\natoms.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16381v1",
    "published_date": "2025-04-23 03:02:29 UTC",
    "updated_date": "2025-04-23 03:02:29 UTC"
  },
  {
    "arxiv_id": "2504.16378v1",
    "title": "Cyberoception: Finding a Painlessly-Measurable New Sense in the Cyberworld Towards Emotion-Awareness in Computing",
    "authors": [
      "Tadashi Okoshi",
      "Zexiong Gao",
      "Tan Yi Zhen",
      "Takumi Karasawa",
      "Takeshi Miki",
      "Wataru Sasaki",
      "Rajesh K. Balan"
    ],
    "abstract": "In Affective computing, recognizing users' emotions accurately is the basis\nof affective human-computer interaction. Understanding users' interoception\ncontributes to a better understanding of individually different emotional\nabilities, which is essential for achieving inter-individually accurate emotion\nestimation. However, existing interoception measurement methods, such as the\nheart rate discrimination task, have several limitations, including their\ndependence on a well-controlled laboratory environment and precision apparatus,\nmaking monitoring users' interoception challenging. This study aims to\ndetermine other forms of data that can explain users' interoceptive or similar\nstates in their real-world lives and propose a novel hypothetical concept\n\"cyberoception,\" a new sense (1) which has properties similar to interoception\nin terms of the correlation with other emotion-related abilities, and (2) which\ncan be measured only by the sensors embedded inside commodity smartphone\ndevices in users' daily lives. Results from a 10-day-long in-lab/in-the-wild\nhybrid experiment reveal a specific cyberoception type \"Turn On\" (users'\nsubjective sensory perception about the frequency of turning-on behavior on\ntheir smartphones), significantly related to participants' emotional valence.\nWe anticipate that cyberoception to serve as a fundamental building block for\ndeveloping more \"emotion-aware\", user-friendly applications and services.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by ACM CHI2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16378v1",
    "published_date": "2025-04-23 02:56:55 UTC",
    "updated_date": "2025-04-23 02:56:55 UTC"
  },
  {
    "arxiv_id": "2504.16364v1",
    "title": "CLPSTNet: A Progressive Multi-Scale Convolutional Steganography Model Integrating Curriculum Learning",
    "authors": [
      "Fengchun Liu",
      "Tong Zhang",
      "Chunying Zhang"
    ],
    "abstract": "In recent years, a large number of works have introduced Convolutional Neural\nNetworks (CNNs) into image steganography, which transform traditional\nsteganography methods such as hand-crafted features and prior knowledge design\ninto steganography methods that neural networks autonomically learn information\nembedding. However, due to the inherent complexity of digital images, issues of\ninvisibility and security persist when using CNN models for information\nembedding. In this paper, we propose Curriculum Learning Progressive Steganophy\nNetwork (CLPSTNet). The network consists of multiple progressive multi-scale\nconvolutional modules that integrate Inception structures and dilated\nconvolutions. The module contains multiple branching pathways, starting from a\nsmaller convolutional kernel and dilatation rate, extracting the basic, local\nfeature information from the feature map, and gradually expanding to the\nconvolution with a larger convolutional kernel and dilatation rate for\nperceiving the feature information of a larger receptive field, so as to\nrealize the multi-scale feature extraction from shallow to deep, and from fine\nto coarse, allowing the shallow secret information features to be refined in\ndifferent fusion stages. The experimental results show that the proposed\nCLPSTNet not only has high PSNR , SSIM metrics and decoding accuracy on three\nlarge public datasets, ALASKA2, VOC2012 and ImageNet, but also the\nsteganographic images generated by CLPSTNet have low steganalysis scores.You\ncan find our code at\n\\href{https://github.com/chaos-boops/CLPSTNet}{https://github.com/chaos-boops/CLPSTNet}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16364v1",
    "published_date": "2025-04-23 02:34:25 UTC",
    "updated_date": "2025-04-23 02:34:25 UTC"
  },
  {
    "arxiv_id": "2504.16357v1",
    "title": "DP2FL: Dual Prompt Personalized Federated Learning in Foundation Models",
    "authors": [
      "Ying Chang",
      "Xiaohu Shi",
      "Xiaohui Zhao",
      "Zhaohuang Chen",
      "Deyin Ma"
    ],
    "abstract": "Personalized federated learning (PFL) has garnered significant attention for\nits ability to address heterogeneous client data distributions while preserving\ndata privacy. However, when local client data is limited, deep learning models\noften suffer from insufficient training, leading to suboptimal performance.\nFoundation models, such as CLIP (Contrastive Language-Image Pretraining),\nexhibit strong feature extraction capabilities and can alleviate this issue by\nfine-tuning on limited local data. Despite their potential, foundation models\nare rarely utilized in federated learning scenarios, and challenges related to\nintegrating new clients remain largely unresolved. To address these challenges,\nwe propose the Dual Prompt Personalized Federated Learning (DP2FL) framework,\nwhich introduces dual prompts and an adaptive aggregation strategy. DP2FL\ncombines global task awareness with local data-driven insights, enabling local\nmodels to achieve effective generalization while remaining adaptable to\nspecific data distributions. Moreover, DP2FL introduces a global model that\nenables prediction on new data sources and seamlessly integrates newly added\nclients without requiring retraining. Experimental results in highly\nheterogeneous environments validate the effectiveness of DP2FL's prompt design\nand aggregation strategy, underscoring the advantages of prediction on novel\ndata sources and demonstrating the seamless integration of new clients into the\nfederated learning framework.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16357v1",
    "published_date": "2025-04-23 02:13:56 UTC",
    "updated_date": "2025-04-23 02:13:56 UTC"
  },
  {
    "arxiv_id": "2504.16353v1",
    "title": "Transformer-Based Extraction of Statutory Definitions from the U.S. Code",
    "authors": [
      "Arpana Hosabettu",
      "Harsh Shah"
    ],
    "abstract": "Automatic extraction of definitions from legal texts is critical for\nenhancing the comprehension and clarity of complex legal corpora such as the\nUnited States Code (U.S.C.). We present an advanced NLP system leveraging\ntransformer-based architectures to automatically extract defined terms, their\ndefinitions, and their scope from the U.S.C. We address the challenges of\nautomatically identifying legal definitions, extracting defined terms, and\ndetermining their scope within this complex corpus of over 200,000 pages of\nfederal statutory law. Building upon previous feature-based machine learning\nmethods, our updated model employs domain-specific transformers (Legal-BERT)\nfine-tuned specifically for statutory texts, significantly improving extraction\naccuracy. Our work implements a multi-stage pipeline that combines document\nstructure analysis with state-of-the-art language models to process legal text\nfrom the XML version of the U.S. Code. Each paragraph is first classified using\na fine-tuned legal domain BERT model to determine if it contains a definition.\nOur system then aggregates related paragraphs into coherent definitional units\nand applies a combination of attention mechanisms and rule-based patterns to\nextract defined terms and their jurisdictional scope. The definition extraction\nsystem is evaluated on multiple titles of the U.S. Code containing thousands of\ndefinitions, demonstrating significant improvements over previous approaches.\nOur best model achieves 96.8% precision and 98.9% recall (98.2% F1-score),\nsubstantially outperforming traditional machine learning classifiers. This work\ncontributes to improving accessibility and understanding of legal information\nwhile establishing a foundation for downstream legal reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, to be published in IEEE AIIoT 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16353v1",
    "published_date": "2025-04-23 02:09:53 UTC",
    "updated_date": "2025-04-23 02:09:53 UTC"
  },
  {
    "arxiv_id": "2504.16352v1",
    "title": "Disentangling and Generating Modalities for Recommendation in Missing Modality Scenarios",
    "authors": [
      "Jiwan Kim",
      "Hongseok Kang",
      "Sein Kim",
      "Kibum Kim",
      "Chanyoung Park"
    ],
    "abstract": "Multi-modal recommender systems (MRSs) have achieved notable success in\nimproving personalization by leveraging diverse modalities such as images,\ntext, and audio. However, two key challenges remain insufficiently addressed:\n(1) Insufficient consideration of missing modality scenarios and (2) the\noverlooking of unique characteristics of modality features. These challenges\nresult in significant performance degradation in realistic situations where\nmodalities are missing. To address these issues, we propose Disentangling and\nGenerating Modality Recommender (DGMRec), a novel framework tailored for\nmissing modality scenarios. DGMRec disentangles modality features into general\nand specific modality features from an information-based perspective, enabling\nricher representations for recommendation. Building on this, it generates\nmissing modality features by integrating aligned features from other modalities\nand leveraging user modality preferences. Extensive experiments show that\nDGMRec consistently outperforms state-of-the-art MRSs in challenging scenarios,\nincluding missing modalities and new item settings as well as diverse missing\nratios and varying levels of missing modalities. Moreover, DGMRec's\ngeneration-based approach enables cross-modal retrieval, a task inapplicable\nfor existing MRSs, highlighting its adaptability and potential for real-world\napplications. Our code is available at https://github.com/ptkjw1997/DGMRec.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16352v1",
    "published_date": "2025-04-23 02:04:14 UTC",
    "updated_date": "2025-04-23 02:04:14 UTC"
  },
  {
    "arxiv_id": "2504.16350v1",
    "title": "QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate Optimization Algorithm Circuits",
    "authors": [
      "Ilya Tyagin",
      "Marwa H. Farag",
      "Kyle Sherbert",
      "Karunya Shirali",
      "Yuri Alexeev",
      "Ilya Safro"
    ],
    "abstract": "Quantum computing has the potential to improve our ability to solve certain\noptimization problems that are computationally difficult for classical\ncomputers, by offering new algorithmic approaches that may provide speedups\nunder specific conditions. In this work, we introduce QAOA-GPT, a generative\nframework that leverages Generative Pretrained Transformers (GPT) to directly\nsynthesize quantum circuits for solving quadratic unconstrained binary\noptimization problems, and demonstrate it on the MaxCut problem on graphs. To\ndiversify the training circuits and ensure their quality, we have generated a\nsynthetic dataset using the adaptive QAOA approach, a method that incrementally\nbuilds and optimizes problem-specific circuits. The experiments conducted on a\ncurated set of graph instances demonstrate that QAOA-GPT, generates high\nquality quantum circuits for new problem instances unseen in the training as\nwell as successfully parametrizes QAOA. Our results show that using QAOA-GPT to\ngenerate quantum circuits will significantly decrease both the computational\noverhead of classical QAOA and adaptive approaches that often use gradient\nevaluation to generate the circuit and the classical optimization of the\ncircuit parameters. Our work shows that generative AI could be a promising\navenue to generate compact quantum circuits in a scalable way.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16350v1",
    "published_date": "2025-04-23 02:00:36 UTC",
    "updated_date": "2025-04-23 02:00:36 UTC"
  },
  {
    "arxiv_id": "2504.16343v1",
    "title": "Mining Software Repositories for Expert Recommendation",
    "authors": [
      "Chad Marshall",
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "We propose an automated approach to bug assignment to developers in large\nopen-source software projects. This way, we assist human bug triagers who are\nin charge of finding the best developer with the right level of expertise in a\nparticular area to be assigned to a newly reported issue. Our approach is based\non the history of software development as documented in the issue tracking\nsystems. We deploy BERTopic and techniques from TopicMiner. Our approach works\nbased on the bug reports' features, such as the corresponding products and\ncomponents, as well as their priority and severity levels. We sort developers\nbased on their experience with specific combinations of new reports. The\nevaluation is performed using Top-k accuracy, and the results are compared with\nthe reported results in prior work, namely TopicMiner MTM, BUGZIE, Bug triaging\nvia deep Reinforcement Learning BT-RL, and LDA-SVM. The evaluation data come\nfrom various Eclipse and Mozilla projects, such as JDT, Firefox, and\nThunderbird.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16343v1",
    "published_date": "2025-04-23 01:41:08 UTC",
    "updated_date": "2025-04-23 01:41:08 UTC"
  }
]