[
  {
    "arxiv_id": "2505.05481v1",
    "title": "Structure & Quality: Conceptual and Formal Foundations for the Mind-Body Problem",
    "authors": [
      "Ryan Williams"
    ],
    "abstract": "This paper explores the hard problem of consciousness from a different\nperspective. Instead of drawing distinctions between the physical and the\nmental, an exploration of a more foundational relationship is examined: the\nrelationship between structure and quality.\n  Information-theoretic measures are developed to quantify the mutual\ndeterminability between structure and quality, including a novel Q-S space for\nanalyzing fidelity between the two domains. This novel space naturally points\ntoward a five-fold categorization of possible relationships between structural\nand qualitative properties, illustrating each through conceptual and formal\nmodels.\n  The ontological implications of each category are examined, shedding light on\ndebates around functionalism, emergentism, idealism, panpsychism, and neutral\nmonism.\n  This new line of inquiry has established a framework for deriving theoretical\nconstraints on qualitative systems undergoing evolution that is explored in my\ncompanion paper, Qualia & Natural Selection.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.05481v1",
    "published_date": "2025-04-23 23:49:40 UTC",
    "updated_date": "2025-04-23 23:49:40 UTC"
  },
  {
    "arxiv_id": "2504.17824v1",
    "title": "EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?",
    "authors": [
      "Yibin Wang",
      "Jiaxi Xie",
      "Lakshminarayanan Subramanian"
    ],
    "abstract": "The prevalence of Large Language Models (LLMs) is revolutionizing the process\nof writing code. General and code LLMs have shown impressive performance in\ngenerating standalone functions and code-completion tasks with one-shot\nqueries. However, the ability to solve comprehensive programming tasks with\nrecursive requests and bug fixes remains questionable. In this paper, we\npropose EduBot, an intelligent automated assistant system that combines\nconceptual knowledge teaching, end-to-end code development, personalized\nprogramming through recursive prompt-driven methods, and debugging with limited\nhuman interventions powered by LLMs. We show that EduBot can solve complicated\nprogramming tasks consisting of sub-tasks with increasing difficulties ranging\nfrom conceptual to coding questions by recursive automatic prompt-driven\nsystems without finetuning on LLMs themselves. To further evaluate EduBot's\nperformance, we design and conduct a benchmark suite consisting of 20 scenarios\nin algorithms, machine learning, and real-world problems. The result shows that\nEduBot can complete most scenarios in less than 20 minutes. Based on the\nbenchmark suites, we perform a comparative study to take different LLMs as the\nbackbone and to verify EduBot's compatibility and robustness across LLMs with\nvarying capabilities. We believe that EduBot is an exploratory approach to\nexplore the potential of pre-trained LLMs in multi-step reasoning and code\ngeneration for solving personalized assignments with knowledge learning and\ncode generation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Published at AAAI 2025 AI4EDU Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.17824v1",
    "published_date": "2025-04-23 23:25:13 UTC",
    "updated_date": "2025-04-23 23:25:13 UTC"
  },
  {
    "arxiv_id": "2504.17140v1",
    "title": "Scalable Permutation-Aware Modeling for Temporal Set Prediction",
    "authors": [
      "Ashish Ranjan",
      "Ayush Agarwal",
      "Shalin Barot",
      "Sushant Kumar"
    ],
    "abstract": "Temporal set prediction involves forecasting the elements that will appear in\nthe next set, given a sequence of prior sets, each containing a variable number\nof elements. Existing methods often rely on intricate architectures with\nsubstantial computational overhead, which hampers their scalability. In this\nwork, we introduce a novel and scalable framework that leverages\npermutation-equivariant and permutation-invariant transformations to\nefficiently model set dynamics. Our approach significantly reduces both\ntraining and inference time while maintaining competitive performance.\nExtensive experiments on multiple public benchmarks show that our method\nachieves results on par with or superior to state-of-the-art models across\nseveral evaluation metrics. These results underscore the effectiveness of our\nmodel in enabling efficient and scalable temporal set prediction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17140v1",
    "published_date": "2025-04-23 23:14:35 UTC",
    "updated_date": "2025-04-23 23:14:35 UTC"
  },
  {
    "arxiv_id": "2504.17137v1",
    "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation",
    "authors": [
      "Chanhee Park",
      "Hyeonseok Moon",
      "Chanjun Park",
      "Heuiseok Lim"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective\nmethod for enhancing the generative capabilities of Large Language Models\n(LLMs) through the incorporation of external knowledge. However, the evaluation\nof RAG systems remains a challenge, due to the intricate interplay between\nretrieval and generation components. This limitation has resulted in a scarcity\nof benchmarks that facilitate a detailed, component-specific assessment. In\nthis work, we present MIRAGE, a Question Answering dataset specifically\ndesigned for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped\nto a retrieval pool of 37,800 entries, enabling an efficient and precise\nevaluation of both retrieval and generation tasks. We also introduce novel\nevaluation metrics aimed at measuring RAG adaptability, encompassing dimensions\nsuch as noise vulnerability, context acceptability, context insensitivity, and\ncontext misinterpretation. Through comprehensive experiments across various\nretriever-LLM configurations, we provide new insights into the optimal\nalignment of model pairs and the nuanced dynamics within RAG systems. The\ndataset and evaluation code are publicly available, allowing for seamless\nintegration and customization in diverse research settings\\footnote{The MIRAGE\ncode and data are available at https://github.com/nlpai-lab/MIRAGE.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL2025 Findings",
    "pdf_url": "http://arxiv.org/pdf/2504.17137v1",
    "published_date": "2025-04-23 23:05:46 UTC",
    "updated_date": "2025-04-23 23:05:46 UTC"
  },
  {
    "arxiv_id": "2504.17823v1",
    "title": "The Cloud Weaving Model for AI development",
    "authors": [
      "Darcy Kim",
      "Aida Kalender",
      "Sennay Ghebreab",
      "Giovanni Sileno"
    ],
    "abstract": "While analysing challenges in pilot projects developing AI with marginalized\ncommunities, we found it difficult to express them within commonly used\nparadigms. We therefore constructed an alternative conceptual framework to\nground AI development in the social fabric -- the Cloud Weaving Model --\ninspired (amongst others) by indigenous knowledge, motifs from nature, and\nEastern traditions. This paper introduces and elaborates on the fundamental\nelements of the model (clouds, spiders, threads, spiderwebs, and weather) and\ntheir interpretation in an AI context. The framework is then applied to\ncomprehend patterns observed in co-creation pilots approaching marginalized\ncommunities, highlighting neglected yet relevant dimensions for responsible AI\ndevelopment.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CY",
    "comment": "presented at alt.CHI 2025, Yokohama",
    "pdf_url": "http://arxiv.org/pdf/2504.17823v1",
    "published_date": "2025-04-23 22:48:13 UTC",
    "updated_date": "2025-04-23 22:48:13 UTC"
  },
  {
    "arxiv_id": "2504.17129v1",
    "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference",
    "authors": [
      "Seyed Yousef Soltanian",
      "Wenlong Zhang"
    ],
    "abstract": "Human-robot interactions can be modeled as incomplete-information general-sum\ndynamic games since the objective functions of both agents are not explicitly\nknown to each other. However, solving for equilibrium policies for such games\npresents a major challenge, especially if the games involve nonlinear\nunderlying dynamics. To simplify the problem, existing work often assumes that\none agent is an expert with complete information about its peer, which can lead\nto biased estimates and failures in coordination. To address this challenge, we\npropose a nonlinear peer-aware cost estimation (N-PACE) algorithm for\ngeneral-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ)\napproximation of the nonlinear general-sum game, each agent explicitly models\nthe learning dynamics of its peer agent while inferring their objective\nfunctions, leading to unbiased fast learning in inferring the unknown objective\nfunction of the peer agent, which is critical for task completion and safety\nassurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent\ncommunication} in such multi-agent systems by explicitly modeling the peer's\nlearning dynamics.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.GT",
      "cs.RO",
      "cs.SY",
      "93C41, 49N70, 49N90, 91A27"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17129v1",
    "published_date": "2025-04-23 22:47:20 UTC",
    "updated_date": "2025-04-23 22:47:20 UTC"
  },
  {
    "arxiv_id": "2504.17124v1",
    "title": "Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy",
    "authors": [
      "Ming Du",
      "Mark Wolfman",
      "Chengjun Sun",
      "Shelly D. Kelly",
      "Mathew J. Cherukara"
    ],
    "abstract": "X-ray absorption near edge structure (XANES) spectroscopy is a powerful\ntechnique for characterizing the chemical state and symmetry of individual\nelements within materials, but requires collecting data at many energy points\nwhich can be time-consuming. While adaptive sampling methods exist for\nefficiently collecting spectroscopic data, they often lack domain-specific\nknowledge about XANES spectra structure. Here we demonstrate a\nknowledge-injected Bayesian optimization approach for adaptive XANES data\ncollection that incorporates understanding of spectral features like absorption\nedges and pre-edge peaks. We show this method accurately reconstructs the\nabsorption edge of XANES spectra using only 15-20% of the measurement points\ntypically needed for conventional sampling, while maintaining the ability to\ndetermine the x-ray energy of the sharp peak after absorption edge with errors\nless than 0.03 eV, the absorption edge with errors less than 0.1 eV; and\noverall root-mean-square errors less than 0.005 compared to compared to\ntraditionally sampled spectra. Our experiments on battery materials and\ncatalysts demonstrate the method's effectiveness for both static and dynamic\nXANES measurements, improving data collection efficiency and enabling better\ntime resolution for tracking chemical changes. This approach advances the\ndegree of automation in XANES experiments reducing the common errors of under-\nor over-sampling points in near the absorption edge and enabling dynamic\nexperiments that require high temporal resolution or limited measurement time.",
    "categories": [
      "physics.app-ph",
      "cs.AI",
      "cs.CE",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "physics.app-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17124v1",
    "published_date": "2025-04-23 22:32:42 UTC",
    "updated_date": "2025-04-23 22:32:42 UTC"
  },
  {
    "arxiv_id": "2504.17822v1",
    "title": "A multi-scale vision transformer-based multimodal GeoAI model for mapping Arctic permafrost thaw",
    "authors": [
      "Wenwen Li",
      "Chia-Yu Hsu",
      "Sizhe Wang",
      "Zhining Gu",
      "Yili Yang",
      "Brendan M. Rogers",
      "Anna Liljedahl"
    ],
    "abstract": "Retrogressive Thaw Slumps (RTS) in Arctic regions are distinct permafrost\nlandforms with significant environmental impacts. Mapping these RTS is crucial\nbecause their appearance serves as a clear indication of permafrost thaw.\nHowever, their small scale compared to other landform features, vague\nboundaries, and spatiotemporal variation pose significant challenges for\naccurate detection. In this paper, we employed a state-of-the-art deep learning\nmodel, the Cascade Mask R-CNN with a multi-scale vision transformer-based\nbackbone, to delineate RTS features across the Arctic. Two new strategies were\nintroduced to optimize multimodal learning and enhance the model's predictive\nperformance: (1) a feature-level, residual cross-modality attention fusion\nstrategy, which effectively integrates feature maps from multiple modalities to\ncapture complementary information and improve the model's ability to understand\ncomplex patterns and relationships within the data; (2) pre-trained unimodal\nlearning followed by multimodal fine-tuning to alleviate high computing demand\nwhile achieving strong model performance. Experimental results demonstrated\nthat our approach outperformed existing models adopting data-level fusion,\nfeature-level convolutional fusion, and various attention fusion strategies,\nproviding valuable insights into the efficient utilization of multimodal data\nfor RTS mapping. This research contributes to our understanding of permafrost\nlandforms and their environmental implications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17822v1",
    "published_date": "2025-04-23 22:18:10 UTC",
    "updated_date": "2025-04-23 22:18:10 UTC"
  },
  {
    "arxiv_id": "2504.17122v1",
    "title": "Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET",
    "authors": [
      "Kartikay Tehlan",
      "Thomas Wendler"
    ],
    "abstract": "Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables\nnon-invasive quantification of glucose metabolism through kinetic analysis,\noften modelled by the two-tissue compartment model (TCKM). However, voxel-wise\nkinetic parameter estimation using conventional methods is computationally\nintensive and limited by spatial resolution. Deep neural networks (DNNs) offer\nan alternative but require large training datasets and significant\ncomputational resources. To address these limitations, we propose a\nphysiological neural representation based on implicit neural representations\n(INRs) for personalized kinetic parameter estimation. INRs, which learn\ncontinuous functions, allow for efficient, high-resolution parametric imaging\nwith reduced data requirements. Our method also integrates anatomical priors\nfrom a 3D CT foundation model to enhance robustness and precision in kinetic\nmodelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset\nand compare it to state-of-the-art DNNs. Results demonstrate superior spatial\nresolution, lower mean-squared error, and improved anatomical consistency,\nparticularly in tumour and highly vascularized regions. Our findings highlight\nthe potential of INRs for personalized, data-efficient tracer kinetic\nmodelling, enabling applications in tumour characterization, segmentation, and\nprognostic assessment.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "The code is available at: https://github.com/tkartikay/PhysNRPET",
    "pdf_url": "http://arxiv.org/pdf/2504.17122v1",
    "published_date": "2025-04-23 22:12:04 UTC",
    "updated_date": "2025-04-23 22:12:04 UTC"
  },
  {
    "arxiv_id": "2504.17119v2",
    "title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey",
    "authors": [
      "Muskan Garg",
      "Shaina Raza",
      "Shebuti Rayana",
      "Xingyi Liu",
      "Sunghwan Sohn"
    ],
    "abstract": "Despite substantial progress in healthcare applications driven by large\nlanguage models (LLMs), growing concerns around data privacy, and limited\nresources; the small language models (SLMs) offer a scalable and clinically\nviable solution for efficient performance in resource-constrained environments\nfor next-generation healthcare informatics. Our comprehensive survey presents a\ntaxonomic framework to identify and categorize them for healthcare\nprofessionals and informaticians. The timeline of healthcare SLM contributions\nestablishes a foundational framework for analyzing models across three\ndimensions: NLP tasks, stakeholder roles, and the continuum of care. We present\na taxonomic framework to identify the architectural foundations for building\nmodels from scratch; adapting SLMs to clinical precision through prompting,\ninstruction fine-tuning, and reasoning; and accessibility and sustainability\nthrough compression techniques. Our primary objective is to offer a\ncomprehensive survey for healthcare professionals, introducing recent\ninnovations in model optimization and equipping them with curated resources to\nsupport future research and development in the field. Aiming to showcase the\ngroundbreaking advancements in SLMs for healthcare, we present a comprehensive\ncompilation of experimental results across widely studied NLP tasks in\nhealthcare to highlight the transformative potential of SLMs in healthcare. The\nupdated repository is available at Github",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages, 7 tables, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.17119v2",
    "published_date": "2025-04-23 22:02:25 UTC",
    "updated_date": "2025-04-25 13:42:19 UTC"
  },
  {
    "arxiv_id": "2504.17114v1",
    "title": "Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation",
    "authors": [
      "Valentin Langer",
      "Kartikay Tehlan",
      "Thomas Wendler"
    ],
    "abstract": "Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron\nemission tomography (PET) requires anatomically constrained modelling of\nimage-derived input functions (IDIFs). Traditionally, IDIFs are obtained from\nthe aorta, neglecting anatomical variations and complex vascular contributions.\nThis study proposes a multi-organ segmentation-based approach that integrates\nIDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using\nhigh-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we\nincorporate organ-specific blood supply sources to improve kinetic modelling.\nOur method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients,\nresulting in a mean squared error (MSE) reduction of $13.39\\%$ for the liver\nand $10.42\\%$ for the lungs. These initial results highlight the potential of\nmultiple IDIFs in improving anatomical modelling and fully leveraging dynamic\nPET imaging. This approach could facilitate the integration of tracer kinetic\nmodelling into clinical routine.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "physics.med-ph"
    ],
    "primary_category": "eess.IV",
    "comment": "The code is available under\n  https://github.com/tinolan/curve_fit_multi_idif",
    "pdf_url": "http://arxiv.org/pdf/2504.17114v1",
    "published_date": "2025-04-23 21:47:05 UTC",
    "updated_date": "2025-04-23 21:47:05 UTC"
  },
  {
    "arxiv_id": "2504.17087v1",
    "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments",
    "authors": [
      "Yuran Li",
      "Jama Hussein Mohamud",
      "Chongren Sun",
      "Di Wu",
      "Benoit Boulet"
    ],
    "abstract": "Large language models (LLMs) are being widely applied across various fields,\nbut as tasks become more complex, evaluating their responses is increasingly\nchallenging. Compared to human evaluators, the use of LLMs to support\nperformance evaluation offers a more efficient alternative. However, most\nstudies focus mainly on aligning LLMs' judgments with human preferences,\noverlooking the existence of biases and mistakes in human judgment.\nFurthermore, how to select suitable LLM judgments given multiple potential LLM\nresponses remains underexplored. To address these two aforementioned issues, we\npropose a three-stage meta-judge selection pipeline: 1) developing a\ncomprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM\nagents to score judgments, and 3) applying a threshold to filter out\nlow-scoring judgments. Compared to methods using a single LLM as both judge and\nmeta-judge, our pipeline introduces multi-agent collaboration and a more\ncomprehensive rubric. Experimental results on the JudgeBench dataset show about\n15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over\nthe single-agent baseline. Our work demonstrates the potential of LLMs as\nmeta-judges and lays the foundation for future research on constructing\npreference datasets for LLM-as-a-judge reinforcement learning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 5 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.17087v1",
    "published_date": "2025-04-23 20:32:12 UTC",
    "updated_date": "2025-04-23 20:32:12 UTC"
  },
  {
    "arxiv_id": "2504.17077v1",
    "title": "Physics-guided and fabrication-aware inverse design of photonic devices using diffusion models",
    "authors": [
      "Dongjin Seo",
      "Soobin Um",
      "Sangbin Lee",
      "Jong Chul Ye",
      "Haejun Chung"
    ],
    "abstract": "Designing free-form photonic devices is fundamentally challenging due to the\nvast number of possible geometries and the complex requirements of fabrication\nconstraints. Traditional inverse-design approaches--whether driven by human\nintuition, global optimization, or adjoint-based gradient methods--often\ninvolve intricate binarization and filtering steps, while recent deep learning\nstrategies demand prohibitively large numbers of simulations (10^5 to 10^6). To\novercome these limitations, we present AdjointDiffusion, a physics-guided\nframework that integrates adjoint sensitivity gradients into the sampling\nprocess of diffusion models. AdjointDiffusion begins by training a diffusion\nnetwork on a synthetic, fabrication-aware dataset of binary masks. During\ninference, we compute the adjoint gradient of a candidate structure and inject\nthis physics-based guidance at each denoising step, steering the generative\nprocess toward high figure-of-merit (FoM) solutions without additional\npost-processing. We demonstrate our method on two canonical photonic design\nproblems--a bent waveguide and a CMOS image sensor color router--and show that\nour method consistently outperforms state-of-the-art nonlinear optimizers (such\nas MMA and SLSQP) in both efficiency and manufacturability, while using orders\nof magnitude fewer simulations (approximately 2 x 10^2) than pure deep learning\napproaches (approximately 10^5 to 10^6). By eliminating complex binarization\nschedules and minimizing simulation overhead, AdjointDiffusion offers a\nstreamlined, simulation-efficient, and fabrication-aware pipeline for\nnext-generation photonic device design. Our open-source implementation is\navailable at https://github.com/dongjin-seo2020/AdjointDiffusion.",
    "categories": [
      "physics.optics",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "physics.optics",
    "comment": "25 pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2504.17077v1",
    "published_date": "2025-04-23 19:54:33 UTC",
    "updated_date": "2025-04-23 19:54:33 UTC"
  },
  {
    "arxiv_id": "2504.17070v1",
    "title": "Robo-Troj: Attacking LLM-based Task Planners",
    "authors": [
      "Mohaiminul Al Nahian",
      "Zainab Altaweel",
      "David Reitano",
      "Sabbir Ahmed",
      "Saumitra Lohokare",
      "Shiqi Zhang",
      "Adnan Siraj Rakin"
    ],
    "abstract": "Robots need task planning methods to achieve goals that require more than\nindividual actions. Recently, large language models (LLMs) have demonstrated\nimpressive performance in task planning. LLMs can generate a step-by-step\nsolution using a description of actions and the goal. Despite the successes in\nLLM-based task planning, there is limited research studying the security\naspects of those systems. In this paper, we develop Robo-Troj, the first\nmulti-trigger backdoor attack for LLM-based task planners, which is the main\ncontribution of this work. As a multi-trigger attack, Robo-Troj is trained to\naccommodate the diversity of robot application domains. For instance, one can\nuse unique trigger words, e.g., \"herical\", to activate a specific malicious\nbehavior, e.g., cutting hand on a kitchen robot. In addition, we develop an\noptimization method for selecting the trigger words that are most effective.\nThrough demonstrating the vulnerability of LLM-based planners, we aim to\npromote the development of secured robot systems.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17070v1",
    "published_date": "2025-04-23 19:39:16 UTC",
    "updated_date": "2025-04-23 19:39:16 UTC"
  },
  {
    "arxiv_id": "2504.17069v1",
    "title": "Distilling semantically aware orders for autoregressive image generation",
    "authors": [
      "Rishav Pramanik",
      "Antoine Poupon",
      "Juan A. Rodriguez",
      "Masih Aminbeidokhti",
      "David Vazquez",
      "Christopher Pal",
      "Zhaozheng Yin",
      "Marco Pedersoli"
    ],
    "abstract": "Autoregressive patch-based image generation has recently shown competitive\nresults in terms of image quality and scalability. It can also be easily\nintegrated and scaled within Vision-Language models. Nevertheless,\nautoregressive models require a defined order for patch generation. While a\nnatural order based on the dictation of the words makes sense for text\ngeneration, there is no inherent generation order that exists for image\ngeneration. Traditionally, a raster-scan order (from top-left to bottom-right)\nguides autoregressive image generation models. In this paper, we argue that\nthis order is suboptimal, as it fails to respect the causality of the image\ncontent: for instance, when conditioned on a visual description of a sunset, an\nautoregressive model may generate clouds before the sun, even though the color\nof clouds should depend on the color of the sun and not the inverse. In this\nwork, we show that first by training a model to generate patches in\nany-given-order, we can infer both the content and the location (order) of each\npatch during generation. Secondly, we use these extracted orders to finetune\nthe any-given-order model to produce better-quality images. Through our\nexperiments, we show on two datasets that this new generation method produces\nbetter images than the traditional raster-scan approach, with similar training\ncosts and no extra annotations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17069v1",
    "published_date": "2025-04-23 19:33:58 UTC",
    "updated_date": "2025-04-23 19:33:58 UTC"
  },
  {
    "arxiv_id": "2504.17058v3",
    "title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation",
    "authors": [
      "Rahul Vishwakarma",
      "Shrey Dharmendra Modi",
      "Vishwanath Seshagiri"
    ],
    "abstract": "The generation of high-quality synthetic data presents significant challenges\nin machine learning research, particularly regarding statistical fidelity and\nuncertainty quantification. Existing generative models produce compelling\nsynthetic samples but lack rigorous statistical guarantees about their relation\nto the underlying data distribution, limiting their applicability in critical\ndomains requiring robust error bounds. We address this fundamental limitation\nby presenting a novel framework that incorporates conformal prediction\nmethodologies into Generative Adversarial Networks (GANs). By integrating\nmultiple conformal prediction paradigms including Inductive Conformal\nPrediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction,\nand Venn-Abers Predictors, we establish distribution-free uncertainty\nquantification in generated samples. This approach, termed Conformalized GAN\n(cGAN), demonstrates enhanced calibration properties while maintaining the\ngenerative power of traditional GANs, producing synthetic data with provable\nstatistical guarantees. We provide rigorous mathematical proofs establishing\nfinite-sample validity guarantees and asymptotic efficiency properties,\nenabling the reliable application of synthetic data in high-stakes domains\nincluding healthcare, finance, and autonomous systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "6 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2504.17058v3",
    "published_date": "2025-04-23 19:07:44 UTC",
    "updated_date": "2025-05-11 20:31:29 UTC"
  },
  {
    "arxiv_id": "2505.00016v2",
    "title": "Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning",
    "authors": [
      "Josefa Lia Stoisser",
      "Marc Boubnovski Martell",
      "Julien Fauqueur"
    ],
    "abstract": "This work reframes the Text-to-SQL task as a pathway for teaching large\nlanguage models (LLMs) to reason over and manipulate tabular data--moving\nbeyond the traditional focus on query generation. We propose a two-stage\nframework that leverages SQL supervision to develop transferable table\nreasoning capabilities. First, we synthesize detailed chain-of-thought (CoT)\ntraces from real-world SQL queries, providing step-by-step, clause-level\nsupervision that teaches the model how to traverse, filter, and aggregate table\nfields. Second, we introduce a Group Relative Policy Optimization (GRPO)\nreinforcement learning objective that connects SQL execution accuracy to\ngeneralizable reasoning by encouraging steps that extend beyond task-specific\nsyntax and transfer across datasets. Empirically, our approach improves\nperformance on standard Text-to-SQL benchmarks and achieves substantial gains\non reasoning-intensive datasets such as BIRD and CRT-QA, demonstrating enhanced\ngeneralization and interpretability. Specifically, the distilled-quantized\nLLaMA model achieved a relative 33.9\\% increase in accuracy when trained on\nText-to-SQL tasks, while Qwen achieved a relative 14.5\\% increase. These\nresults suggest that SQL can serve not only as a target formalism but also as\nan effective scaffold for learning robust, transferable reasoning over\nstructured data.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2505.00016v2",
    "published_date": "2025-04-23 19:02:04 UTC",
    "updated_date": "2025-05-02 11:34:00 UTC"
  },
  {
    "arxiv_id": "2504.17044v1",
    "title": "Approaches to Responsible Governance of GenAI in Organizations",
    "authors": [
      "Dhari Gandhi",
      "Himanshu Joshi",
      "Lucas Hartman",
      "Shabnam Hassani"
    ],
    "abstract": "The rapid evolution of Generative AI (GenAI) has introduced unprecedented\nopportunities while presenting complex challenges around ethics,\naccountability, and societal impact. This paper draws on a literature review,\nestablished governance frameworks, and industry roundtable discussions to\nidentify core principles for integrating responsible GenAI governance into\ndiverse organizational structures. Our objective is to provide actionable\nrecommendations for a balanced, risk-based governance approach that enables\nboth innovation and oversight. Findings emphasize the need for adaptable risk\nassessment tools, continuous monitoring practices, and cross-sector\ncollaboration to establish trustworthy GenAI. These insights provide a\nstructured foundation and Responsible GenAI Guide (ResAI) for organizations to\nalign GenAI initiatives with ethical, legal, and operational best practices.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17044v1",
    "published_date": "2025-04-23 18:43:29 UTC",
    "updated_date": "2025-04-23 18:43:29 UTC"
  },
  {
    "arxiv_id": "2504.17040v2",
    "title": "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs",
    "authors": [
      "Zhenhailong Wang",
      "Senthil Purushwalkam",
      "Caiming Xiong",
      "Silvio Savarese",
      "Heng Ji",
      "Ran Xu"
    ],
    "abstract": "We present DyMU, an efficient, training-free framework that dynamically\nreduces the computational burden of vision-language models (VLMs) while\nmaintaining high task performance. Our approach comprises two key components.\nFirst, Dynamic Token Merging (DToMe) reduces the number of visual token\nembeddings by merging similar tokens based on image complexity, addressing the\ninherent inefficiency of fixed-length outputs in vision transformers. Second,\nVirtual Token Unmerging (VTU) simulates the expected token sequence for large\nlanguage models (LLMs) by efficiently reconstructing the attention dynamics of\na full sequence, thus preserving the downstream performance without additional\nfine-tuning. Unlike previous approaches, our method dynamically adapts token\ncompression to the content of the image and operates completely training-free,\nmaking it readily applicable to most state-of-the-art VLM architectures.\nExtensive experiments on image and video understanding tasks demonstrate that\nDyMU can reduce the average visual token count by 32%-85% while achieving\ncomparable performance to full-length models across diverse VLM architectures,\nincluding the recently popularized AnyRes-based visual encoders. Furthermore,\nthrough qualitative analyses, we demonstrate that DToMe effectively adapts\ntoken reduction based on image complexity and, unlike existing systems,\nprovides users more control over computational costs. Project page:\nhttps://mikewangwzhl.github.io/dymu/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17040v2",
    "published_date": "2025-04-23 18:38:18 UTC",
    "updated_date": "2025-05-10 22:42:28 UTC"
  },
  {
    "arxiv_id": "2504.17029v1",
    "title": "Fried Parameter Estimation from Single Wavefront Sensor Image with Artificial Neural Networks",
    "authors": [
      "Jeffrey Smith",
      "Taisei Fujii",
      "Jesse Cranney",
      "Charles Gretton"
    ],
    "abstract": "Atmospheric turbulence degrades the quality of astronomical observations in\nground-based telescopes, leading to distorted and blurry images. Adaptive\nOptics (AO) systems are designed to counteract these effects, using atmospheric\nmeasurements captured by a wavefront sensor to make real-time corrections to\nthe incoming wavefront. The Fried parameter, r0, characterises the strength of\natmospheric turbulence and is an essential control parameter for optimising the\nperformance of AO systems and more recently sky profiling for Free Space\nOptical (FSO) communication channels. In this paper, we develop a novel\ndata-driven approach, adapting machine learning methods from computer vision\nfor Fried parameter estimation from a single Shack-Hartmann or pyramid\nwavefront sensor image. Using these data-driven methods, we present a detailed\nsimulation-based evaluation of our approach using the open-source COMPASS AO\nsimulation tool to evaluate both the Shack-Hartmann and pyramid wavefront\nsensors. Our evaluation is over a range of guide star magnitudes, and realistic\nnoise, atmospheric and instrument conditions. Remarkably, we are able to\ndevelop a single network-based estimator that is accurate in both open and\nclosed-loop AO configurations. Our method accurately estimates the Fried\nparameter from a single WFS image directly from AO telemetry to a few\nmillimetres. Our approach is suitable for real time control, exhibiting 0.83ms\nr0 inference times on retail NVIDIA RTX 3090 GPU hardware, and thereby\ndemonstrating a compelling economic solution for use in real-time instrument\ncontrol.",
    "categories": [
      "astro-ph.IM",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17029v1",
    "published_date": "2025-04-23 18:16:07 UTC",
    "updated_date": "2025-04-23 18:16:07 UTC"
  },
  {
    "arxiv_id": "2504.17028v1",
    "title": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU",
    "authors": [
      "Iman Khadir",
      "Shane Stevenson",
      "Henry Li",
      "Kyle Krick",
      "Abram Burrows",
      "David Hall",
      "Stan Posey",
      "Samuel S. P. Shen"
    ],
    "abstract": "This paper demonstrates the feasibility of democratizing AI-driven global\nweather forecasting models among university research groups by leveraging\nGraphics Processing Units (GPUs) and freely available AI models, such as\nNVIDIA's FourCastNetv2. FourCastNetv2 is an NVIDIA's advanced neural network\nfor weather prediction and is trained on a 73-channel subset of the European\nCentre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset\nat single levels and different pressure levels. Although the training\nspecifications for FourCastNetv2 are not released to the public, the training\ndocumentation of the model's first generation, FourCastNet, is available to all\nusers. The training had 64 A100 GPUs and took 16 hours to complete. Although\nNVIDIA's models offer significant reductions in both time and cost compared to\ntraditional Numerical Weather Prediction (NWP), reproducing published\nforecasting results presents ongoing challenges for resource-constrained\nuniversity research groups with limited GPU availability. We demonstrate both\n(i) leveraging FourCastNetv2 to create predictions through the designated\napplication programming interface (API) and (ii) utilizing NVIDIA hardware to\ntrain the original FourCastNet model. Further, this paper demonstrates the\ncapabilities and limitations of NVIDIA A100's for resource-limited research\ngroups in universities. We also explore data management, training efficiency,\nand model validation, highlighting the advantages and challenges of using\nlimited high-performance computing resources. Consequently, this paper and its\ncorresponding GitHub materials may serve as an initial guide for other\nuniversity research groups and courses related to machine learning, climate\nscience, and data science to develop research and education programs on AI\nweather forecasting, and hence help democratize the AI NWP in the digital\neconomy.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.17028v1",
    "published_date": "2025-04-23 18:15:31 UTC",
    "updated_date": "2025-04-23 18:15:31 UTC"
  },
  {
    "arxiv_id": "2504.17023v1",
    "title": "What Makes for a Good Saliency Map? Comparing Strategies for Evaluating Saliency Maps in Explainable AI (XAI)",
    "authors": [
      "Felix Kares",
      "Timo Speith",
      "Hanwei Zhang",
      "Markus Langer"
    ],
    "abstract": "Saliency maps are a popular approach for explaining classifications of\n(convolutional) neural networks. However, it remains an open question as to how\nbest to evaluate salience maps, with three families of evaluation methods\ncommonly being used: subjective user measures, objective user measures, and\nmathematical metrics. We examine three of the most popular saliency map\napproaches (viz., LIME, Grad-CAM, and Guided Backpropagation) in a between\nsubject study (N=166) across these families of evaluation methods. We test 1)\nfor subjective measures, if the maps differ with respect to user trust and\nsatisfaction; 2) for objective measures, if the maps increase users' abilities\nand thus understanding of a model; 3) for mathematical metrics, which map\nachieves the best ratings across metrics; and 4) whether the mathematical\nmetrics can be associated with objective user measures. To our knowledge, our\nstudy is the first to compare several salience maps across all these evaluation\nmethods$-$with the finding that they do not agree in their assessment (i.e.,\nthere was no difference concerning trust and satisfaction, Grad-CAM improved\nusers' abilities best, and Guided Backpropagation had the most favorable\nmathematical metrics). Additionally, we show that some mathematical metrics\nwere associated with user understanding, although this relationship was often\ncounterintuitive. We discuss these findings in light of general debates\nconcerning the complementary use of user studies and mathematical metrics in\nthe evaluation of explainable AI (XAI) approaches.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "27 pages, 7 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.17023v1",
    "published_date": "2025-04-23 18:09:06 UTC",
    "updated_date": "2025-04-23 18:09:06 UTC"
  },
  {
    "arxiv_id": "2504.17020v2",
    "title": "Analyzing Value Functions of States in Parametric Markov Chains",
    "authors": [
      "Kasper Engelen",
      "Guillermo A. Pérez",
      "Shrisha Rao"
    ],
    "abstract": "Parametric Markov chains (pMC) are used to model probabilistic systems with\nunknown or partially known probabilities. Although (universal) pMC verification\nfor reachability properties is known to be coETR-complete, there have been\nefforts to approach it using potentially easier-to-check properties such as\nasking whether the pMC is monotonic in certain parameters. In this paper, we\nfirst reduce monotonicity to asking whether the reachability probability from a\ngiven state is never less than that of another given state. Recent results for\nthe latter property imply an efficient algorithm to collapse same-value\nequivalence classes, which in turn preserves verification results and\nmonotonicity. We implement our algorithm to collapse \"trivial\" equivalence\nclasses in the pMC and show empirical evidence for the following: First, the\ncollapse gives reductions in size for some existing benchmarks and significant\nreductions on some custom benchmarks; Second, the collapse speeds up existing\nalgorithms to check monotonicity and parameter lifting, and hence can be used\nas a fast pre-processing step in practice.",
    "categories": [
      "cs.LO",
      "cs.AI"
    ],
    "primary_category": "cs.LO",
    "comment": "Published as part of the book \"Principles of Verification: Cycling\n  the Probabilistic Landscape: Essays Dedicated to Joost-Pieter Katoen on the\n  Occasion of His 60th Birthday, Part II\"",
    "pdf_url": "http://arxiv.org/pdf/2504.17020v2",
    "published_date": "2025-04-23 18:06:41 UTC",
    "updated_date": "2025-04-26 05:49:22 UTC"
  },
  {
    "arxiv_id": "2504.17017v1",
    "title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification",
    "authors": [
      "Balaji Rao",
      "William Eiers",
      "Carlo Lipizzi"
    ],
    "abstract": "Formally verifying properties of software code has been a highly desirable\ntask, especially with the emergence of LLM-generated code. In the same vein,\nthey provide an interesting avenue for the exploration of formal verification\nand mechanistic interpretability. Since the introduction of code-specific\nmodels, despite their successes in generating code in Lean4 and Isabelle, the\ntask of generalized theorem proving still remains far from being fully solved\nand will be a benchmark for reasoning capability in LLMs. In this work, we\nintroduce a framework that generates whole proofs in a formal language to be\nused within systems that utilize the power of built-in tactics and\noff-the-shelf automated theorem provers. Our framework includes 3 components:\ngenerating natural language statements of the code to be verified, an LLM that\ngenerates formal proofs for the given statement, and a module employing\nheuristics for building the final proof. To train the LLM, we employ a 2-stage\nfine-tuning process, where we first use SFT-based training to enable the model\nto generate syntactically correct Isabelle code and then RL-based training that\nencourages the model to generate proofs verified by a theorem prover. We\nvalidate our framework using the miniF2F-test benchmark and the Isabelle proof\nassistant and design a use case to verify the correctness of the AWS S3 bucket\naccess policy code. We also curate a dataset based on the\nFVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.",
    "categories": [
      "cs.AI",
      "cs.FL",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to the Proceedings of the 19th Conference on Neurosymbolic\n  Learning and Reasoning (NeSy 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.17017v1",
    "published_date": "2025-04-23 18:04:38 UTC",
    "updated_date": "2025-04-23 18:04:38 UTC"
  },
  {
    "arxiv_id": "2504.17006v1",
    "title": "A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs",
    "authors": [
      "Jalal Arabneydi",
      "Saiful Islam",
      "Srijita Das",
      "Sai Krishna Gottipati",
      "William Duguay",
      "Cloderic Mars",
      "Matthew E. Taylor",
      "Matthew Guzdial",
      "Antoine Fagette",
      "Younes Zerouali"
    ],
    "abstract": "With the growing popularity of deep reinforcement learning (DRL),\nhuman-in-the-loop (HITL) approach has the potential to revolutionize the way we\napproach decision-making problems and create new opportunities for human-AI\ncollaboration. In this article, we introduce a novel multi-layered hierarchical\nHITL DRL algorithm that comprises three types of learning: self learning,\nimitation learning and transfer learning. In addition, we consider three forms\nof human inputs: reward, action and demonstration. Furthermore, we discuss main\nchallenges, trade-offs and advantages of HITL in solving complex problems and\nhow human information can be integrated in the AI solution systematically. To\nverify our technical results, we present a real-world unmanned aerial vehicles\n(UAV) problem wherein a number of enemy drones attack a restricted area. The\nobjective is to design a scalable HITL DRL algorithm for ally drones to\nneutralize the enemy drones before they reach the area. To this end, we first\nimplement our solution using an award-winning open-source HITL software called\nCogment. We then demonstrate several interesting results such as (a) HITL leads\nto faster training and higher performance, (b) advice acts as a guiding\ndirection for gradient methods and lowers variance, and (c) the amount of\nadvice should neither be too large nor too small to avoid over-training and\nunder-training. Finally, we illustrate the role of human-AI cooperation in\nsolving two real-world complex scenarios, i.e., overloaded and decoy attacks.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "This is a result of the collaboration by JACOBB, AMII(Alberta Machine\n  Intelligence Institute), Thales and AI Redefined (AIR) in 2021-2023",
    "pdf_url": "http://arxiv.org/pdf/2504.17006v1",
    "published_date": "2025-04-23 18:00:08 UTC",
    "updated_date": "2025-04-23 18:00:08 UTC"
  },
  {
    "arxiv_id": "2504.17004v1",
    "title": "(Im)possibility of Automated Hallucination Detection in Large Language Models",
    "authors": [
      "Amin Karbasi",
      "Omar Montasser",
      "John Sous",
      "Grigoris Velegkas"
    ],
    "abstract": "Is automated hallucination detection possible? In this work, we introduce a\ntheoretical framework to analyze the feasibility of automatically detecting\nhallucinations produced by large language models (LLMs). Inspired by the\nclassical Gold-Angluin framework for language identification and its recent\nadaptation to language generation by Kleinberg and Mullainathan, we investigate\nwhether an algorithm, trained on examples drawn from an unknown target language\n$K$ (selected from a countable collection) and given access to an LLM, can\nreliably determine whether the LLM's outputs are correct or constitute\nhallucinations.\n  First, we establish an equivalence between hallucination detection and the\nclassical task of language identification. We prove that any hallucination\ndetection method can be converted into a language identification method, and\nconversely, algorithms solving language identification can be adapted for\nhallucination detection. Given the inherent difficulty of language\nidentification, this implies that hallucination detection is fundamentally\nimpossible for most language collections if the detector is trained using only\ncorrect examples from the target language.\n  Second, we show that the use of expert-labeled feedback, i.e., training the\ndetector with both positive examples (correct statements) and negative examples\n(explicitly labeled incorrect statements), dramatically changes this\nconclusion. Under this enriched training regime, automated hallucination\ndetection becomes possible for all countable language collections.\n  These results highlight the essential role of expert-labeled examples in\ntraining hallucination detectors and provide theoretical support for\nfeedback-based methods, such as reinforcement learning with human feedback\n(RLHF), which have proven critical for reliable LLM deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.17004v1",
    "published_date": "2025-04-23 18:00:07 UTC",
    "updated_date": "2025-04-23 18:00:07 UTC"
  },
  {
    "arxiv_id": "2504.16929v1",
    "title": "I-Con: A Unifying Framework for Representation Learning",
    "authors": [
      "Shaden Alshammari",
      "John Hershey",
      "Axel Feldmann",
      "William T. Freeman",
      "Mark Hamilton"
    ],
    "abstract": "As the field of representation learning grows, there has been a proliferation\nof different loss functions to solve different classes of problems. We\nintroduce a single information-theoretic equation that generalizes a large\ncollection of modern loss functions in machine learning. In particular, we\nintroduce a framework that shows that several broad classes of machine learning\nmethods are precisely minimizing an integrated KL divergence between two\nconditional distributions: the supervisory and learned representations. This\nviewpoint exposes a hidden information geometry underlying clustering, spectral\nmethods, dimensionality reduction, contrastive learning, and supervised\nlearning. This framework enables the development of new loss functions by\ncombining successful techniques from across the literature. We not only present\na wide array of proofs, connecting over 23 different approaches, but we also\nleverage these theoretical results to create state-of-the-art unsupervised\nimage classifiers that achieve a +8% improvement over the prior\nstate-of-the-art on unsupervised classification on ImageNet-1K. We also\ndemonstrate that I-Con can be used to derive principled debiasing methods which\nimprove contrastive representation learners.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025; website: https://aka.ms/i-con . Proceedings of the\n  Thirteenth International Conference on Learning Representations (ICLR 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.16929v1",
    "published_date": "2025-04-23 17:59:01 UTC",
    "updated_date": "2025-04-23 17:59:01 UTC"
  },
  {
    "arxiv_id": "2504.16979v1",
    "title": "Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline",
    "authors": [
      "Masoud Tafavvoghi",
      "Lars Ailo Bongo",
      "André Berli Delgado",
      "Nikita Shvetsov",
      "Anders Sildnes",
      "Line Moi",
      "Lill-Tove Rasmussen Busund",
      "Kajsa Møllersen"
    ],
    "abstract": "In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs)\nassessment pipeline within QuPath, demonstrating the potential of easily\naccessible tools to perform complex tasks in a fully automatic fashion. First,\nwe trained a pixel classifier to segment tumor, tumor-associated stroma, and\nother tissue compartments in breast cancer H&E-stained whole-slide images (WSI)\nto isolate tumor-associated stroma for subsequent analysis. Next, we applied a\npre-trained StarDist deep learning model in QuPath for cell detection and used\nthe extracted cell features to train a binary classifier distinguishing TILs\nfrom other cells. To evaluate our TILs assessment pipeline, we calculated the\nTIL density in each WSI and categorized them as low, medium, or high TIL\nlevels. Our pipeline was evaluated against pathologist-assigned TIL scores,\nachieving a Cohen's kappa of 0.71 on the external test set, corroborating\nprevious research findings. These results confirm that existing software can\noffer a practical solution for the assessment of TILs in H&E-stained WSIs of\nbreast cancer.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "q-bio.QM",
    "comment": "16 Pages, 9 Figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.16979v1",
    "published_date": "2025-04-23 17:54:59 UTC",
    "updated_date": "2025-04-23 17:54:59 UTC"
  },
  {
    "arxiv_id": "2504.16925v1",
    "title": "Latent Diffusion Planning for Imitation Learning",
    "authors": [
      "Amber Xie",
      "Oleh Rybkin",
      "Dorsa Sadigh",
      "Chelsea Finn"
    ],
    "abstract": "Recent progress in imitation learning has been enabled by policy\narchitectures that scale to complex visuomotor tasks, multimodal distributions,\nand large datasets. However, these methods often rely on learning from large\namount of expert demonstrations. To address these shortcomings, we propose\nLatent Diffusion Planning (LDP), a modular approach consisting of a planner\nwhich can leverage action-free demonstrations, and an inverse dynamics model\nwhich can leverage suboptimal data, that both operate over a learned latent\nspace. First, we learn a compact latent space through a variational\nautoencoder, enabling effective forecasting of future states in image-based\ndomains. Then, we train a planner and an inverse dynamics model with diffusion\nobjectives. By separating planning from action prediction, LDP can benefit from\nthe denser supervision signals of suboptimal and action-free data. On simulated\nvisual robotic manipulation tasks, LDP outperforms state-of-the-art imitation\nlearning approaches, as they cannot leverage such additional data.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16925v1",
    "published_date": "2025-04-23 17:53:34 UTC",
    "updated_date": "2025-04-23 17:53:34 UTC"
  },
  {
    "arxiv_id": "2504.16922v1",
    "title": "Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light",
    "authors": [
      "Ali Hassani",
      "Fengzhe Zhou",
      "Aditya Kane",
      "Jiannan Huang",
      "Chieh-Yun Chen",
      "Min Shi",
      "Steven Walton",
      "Markus Hoehnerbach",
      "Vijay Thakkar",
      "Michael Isaev",
      "Qinsheng Zhang",
      "Bing Xu",
      "Haicheng Wu",
      "Wen-mei Hwu",
      "Ming-Yu Liu",
      "Humphrey Shi"
    ],
    "abstract": "Many sparse attention mechanisms such as Neighborhood Attention have\ntypically failed to consistently deliver speedup over the self attention\nbaseline. This is largely due to the level of complexity in attention\ninfrastructure, and the rapid evolution of AI hardware architecture. At the\nsame time, many state-of-the-art foundational models, particularly in computer\nvision, are heavily bound by attention, and need reliable sparsity to escape\nthe O(n^2) complexity. In this paper, we study a class of promising sparse\nattention mechanisms that focus on locality, and aim to develop a better\nanalytical model of their performance improvements. We first introduce\nGeneralized Neighborhood Attention (GNA), which can describe sliding window,\nstrided sliding window, and blocked attention. We then consider possible design\nchoices in implementing these approaches, and create a simulator that can\nprovide much more realistic speedup upper bounds for any given setting.\nFinally, we implement GNA on top of a state-of-the-art fused multi-headed\nattention (FMHA) kernel designed for the NVIDIA Blackwell architecture in\nCUTLASS. Our implementation can fully realize the maximum speedup theoretically\npossible in many perfectly block-sparse cases, and achieves an effective\nutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA\nconfigurations into off-the-shelf generative models, such as Cosmos-7B,\nHunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end\nspeedup on B200 without any fine-tuning. We will open source our simulator and\nBlackwell kernels directly through the NATTEN project.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "https://github.com/SHI-Labs/NATTEN/",
    "pdf_url": "http://arxiv.org/pdf/2504.16922v1",
    "published_date": "2025-04-23 17:49:53 UTC",
    "updated_date": "2025-04-23 17:49:53 UTC"
  },
  {
    "arxiv_id": "2504.16918v2",
    "title": "OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents",
    "authors": [
      "Raghav Thind",
      "Youran Sun",
      "Ling Liang",
      "Haizhao Yang"
    ],
    "abstract": "Optimization plays a vital role in scientific research and practical\napplications. However, formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce OptimAI,\na framework for solving Optimization problems described in natural language by\nleveraging LLM-powered AI agents, and achieve superior performance over current\nstate-of-the-art methods. Our framework is built upon the following key roles:\n(1) a formulator that translates natural language problem descriptions into\nprecise mathematical formulations; (2) a planner that constructs a high-level\nsolution strategy prior to execution; and (3) a coder and a code critic capable\nof interacting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, and our experiments confirm that combining diverse models leads\nto performance gains. Our approach attains 88.1% accuracy on the NLP4LP dataset\nand 82.3% on the Optibench dataset, reducing error rates by 58% and 52%,\nrespectively, over prior best results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16918v2",
    "published_date": "2025-04-23 17:45:05 UTC",
    "updated_date": "2025-05-17 03:40:22 UTC"
  },
  {
    "arxiv_id": "2504.16913v1",
    "title": "Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM Behind AI-Generated Text",
    "authors": [
      "Shifali Agrahari",
      "Sanasam Ranbir Singh"
    ],
    "abstract": "In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "De-Factify 4: 4th Workshop on Multimodal Fact Checking and Hate\n  Speech Detection, co-located with AAAI 2025. Pennsylvania",
    "pdf_url": "http://arxiv.org/pdf/2504.16913v1",
    "published_date": "2025-04-23 17:39:49 UTC",
    "updated_date": "2025-04-23 17:39:49 UTC"
  },
  {
    "arxiv_id": "2504.16907v1",
    "title": "BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation",
    "authors": [
      "Ruotong Wang",
      "Mingli Zhu",
      "Jiarong Ou",
      "Rui Chen",
      "Xin Tao",
      "Pengfei Wan",
      "Baoyuan Wu"
    ],
    "abstract": "Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16907v1",
    "published_date": "2025-04-23 17:34:48 UTC",
    "updated_date": "2025-04-23 17:34:48 UTC"
  },
  {
    "arxiv_id": "2504.16977v1",
    "title": "Tokenization Matters: Improving Zero-Shot NER for Indic Languages",
    "authors": [
      "Priyaranjan Pattnayak",
      "Hitesh Laxmichand Patel",
      "Amit Agarwal"
    ],
    "abstract": "Tokenization is a critical component of Natural Language Processing (NLP),\nespecially for low resource languages, where subword segmentation influences\nvocabulary structure and downstream task accuracy. Although Byte Pair Encoding\n(BPE) is a standard tokenization method in multilingual language models, its\nsuitability for Named Entity Recognition (NER) in low resource Indic languages\nremains underexplored due to its limitations in handling morphological\ncomplexity. In this work, we systematically compare BPE, SentencePiece, and\nCharacter Level tokenization strategies using IndicBERT for NER tasks in low\nresource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as\nextremely low resource Indic languages like Santali, Manipuri, and Sindhi. We\nassess both intrinsic linguistic properties tokenization efficiency, out of\nvocabulary (OOV) rates, and morphological preservation as well as extrinsic\ndownstream performance, including fine tuning and zero shot cross lingual\ntransfer.\n  Our experiments show that SentencePiece is a consistently better performing\napproach than BPE for NER in low resource Indic Languages, particularly in zero\nshot cross lingual settings, as it better preserves entity consistency. While\nBPE provides the most compact tokenization form, it is not capable of\ngeneralization because it misclassifies or even fails to recognize entity\nlabels when tested on unseen languages. In contrast, SentencePiece constitutes\na better linguistic structural preservation model, benefiting extremely low\nresource and morphologically rich Indic languages, such as Santali and\nManipuri, for superior entity recognition, as well as high generalization\nacross scripts, such as Sindhi, written in Arabic. The results point to\nSentencePiece as the more effective tokenization strategy for NER within\nmultilingual and low resource Indic NLP applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16977v1",
    "published_date": "2025-04-23 17:28:38 UTC",
    "updated_date": "2025-04-23 17:28:38 UTC"
  },
  {
    "arxiv_id": "2504.16902v2",
    "title": "Building A Secure Agentic AI Application Leveraging A2A Protocol",
    "authors": [
      "Idan Habler",
      "Ken Huang",
      "Vineeth Sai Narajala",
      "Prashant Kulkarni"
    ],
    "abstract": "As Agentic AI systems evolve from basic workflows to complex multi agent\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\nessential enablers. To foster secure adoption and ensure the reliability of\nthese complex interactions, understanding the secure implementation of A2A is\nessential. This paper addresses this goal by providing a comprehensive security\nanalysis centered on the A2A protocol. We examine its fundamental elements and\noperational dynamics, situating it within the framework of agent communication\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\nrisks, we apply proactive threat modeling to assess potential security issues\nin A2A deployments, focusing on aspects such as Agent Card management, task\nexecution integrity, and authentication methodologies.\n  Based on these insights, we recommend practical secure development\nmethodologies and architectural best practices designed to build resilient and\neffective A2A systems. Our analysis also explores how the synergy between A2A\nand the Model Context Protocol (MCP) can further enhance secure\ninteroperability. This paper equips developers and architects with the\nknowledge and practical guidance needed to confidently leverage the A2A\nprotocol for building robust and secure next generation agentic applications.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "13 pages, 4 figures, 1 table, Authors contributed equally to this\n  work, typos corrected, references added",
    "pdf_url": "http://arxiv.org/pdf/2504.16902v2",
    "published_date": "2025-04-23 17:27:49 UTC",
    "updated_date": "2025-05-02 18:28:07 UTC"
  },
  {
    "arxiv_id": "2504.16891v1",
    "title": "AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset",
    "authors": [
      "Ivan Moshkov",
      "Darragh Hanley",
      "Ivan Sorokin",
      "Shubham Toshniwal",
      "Christof Henkel",
      "Benedikt Schifferer",
      "Wei Du",
      "Igor Gitman"
    ],
    "abstract": "This paper presents our winning submission to the AI Mathematical Olympiad -\nProgress Prize 2 (AIMO-2) competition. Our recipe for building state-of-the-art\nmathematical reasoning models relies on three key pillars. First, we create a\nlarge-scale dataset comprising 540K unique high-quality math problems,\nincluding olympiad-level problems, and their 3.2M long-reasoning solutions.\nSecond, we develop a novel method to integrate code execution with long\nreasoning models through iterative training, generation, and quality filtering,\nresulting in 1.7M high-quality Tool-Integrated Reasoning solutions. Third, we\ncreate a pipeline to train models to select the most promising solution from\nmany candidates. We show that such generative solution selection (GenSelect)\ncan significantly improve upon majority voting baseline. Combining these ideas,\nwe train a series of models that achieve state-of-the-art results on\nmathematical reasoning benchmarks. To facilitate further research, we release\nour code, models, and the complete OpenMathReasoning dataset under a\ncommercially permissive license.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Report of AIMO-2 winning submission",
    "pdf_url": "http://arxiv.org/pdf/2504.16891v1",
    "published_date": "2025-04-23 17:13:04 UTC",
    "updated_date": "2025-04-23 17:13:04 UTC"
  },
  {
    "arxiv_id": "2504.16837v1",
    "title": "Approximating Optimal Labelings for Temporal Connectivity",
    "authors": [
      "Daniele Carnevale",
      "Gianlorenzo D'Angelo",
      "Martin Olsen"
    ],
    "abstract": "In a temporal graph the edge set dynamically changes over time according to a\nset of time-labels associated with each edge that indicates at which time-steps\nthe edge is available. Two vertices are connected if there is a path connecting\nthem in which the edges are traversed in increasing order of their labels. We\nstudy the problem of scheduling the availability time of the edges of a\ntemporal graph in such a way that all pairs of vertices are connected within a\ngiven maximum allowed time $a$ and the overall number of labels is minimized.\n  The problem, known as \\emph{Minimum Aged Labeling} (MAL), has several\napplications in logistics, distribution scheduling, and information spreading\nin social networks, where carefully choosing the time-labels can significantly\nreduce infrastructure costs, fuel consumption, or greenhouse gases.\n  The problem MAL has previously been proved to be NP-complete on undirected\ngraphs and \\APX-hard on directed graphs. In this paper, we extend our knowledge\non the complexity and approximability of MAL in several directions. We first\nshow that the problem cannot be approximated within a factor better than\n$O(\\log n)$ when $a\\geq 2$, unless $\\text{P} = \\text{NP}$, and a factor better\nthan $2^{\\log ^{1-\\epsilon} n}$ when $a\\geq 3$, unless $\\text{NP}\\subseteq\n\\text{DTIME}(2^{\\text{polylog}(n)})$, where $n$ is the number of vertices in\nthe graph. Then we give a set of approximation algorithms that, under some\nconditions, almost match these lower bounds. In particular, we show that the\napproximation depends on a relation between $a$ and the diameter of the input\ngraph.\n  We further establish a connection with a foundational optimization problem on\nstatic graphs called \\emph{Diameter Constrained Spanning Subgraph} (DCSS) and\nshow that our hardness results also apply to DCSS.",
    "categories": [
      "cs.DS",
      "cs.AI"
    ],
    "primary_category": "cs.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16837v1",
    "published_date": "2025-04-23 16:00:33 UTC",
    "updated_date": "2025-04-23 16:00:33 UTC"
  },
  {
    "arxiv_id": "2504.16834v2",
    "title": "Improving Significant Wave Height Prediction Using Chronos Models",
    "authors": [
      "Yilin Zhai",
      "Hongyuan Shi",
      "Chao Zhan",
      "Qing Wang",
      "Zaijin You",
      "Nan Wang"
    ],
    "abstract": "Accurate wave height prediction is critical for maritime safety and coastal\nresilience, yet conventional physics-based models and traditional machine\nlearning methods face challenges in computational efficiency and nonlinear\ndynamics modeling. This study introduces Chronos, the first implementation of a\nlarge language model (LLM)-powered temporal architecture (Chronos) optimized\nfor wave forecasting. Through advanced temporal pattern recognition applied to\nhistorical wave data from three strategically chosen marine zones in the\nNorthwest Pacific basin, our framework achieves multimodal improvements: (1)\n14.3% reduction in training time with 2.5x faster inference speed compared to\nPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;\n(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)\nsustained predictive leadership in extended-range forecasts (1-120h); and (4)\ndemonstrated zero-shot capability maintaining median performance (rank 4/12)\nagainst specialized operational models. This LLM-enhanced temporal modeling\nparadigm establishes a new standard in wave prediction, offering both\ncomputationally efficient solutions and a transferable framework for complex\ngeophysical systems modeling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "arXiv admin note: text overlap with arXiv:2403.07815 by other authors",
    "pdf_url": "http://arxiv.org/pdf/2504.16834v2",
    "published_date": "2025-04-23 15:56:28 UTC",
    "updated_date": "2025-04-25 08:51:09 UTC"
  },
  {
    "arxiv_id": "2504.16828v2",
    "title": "Process Reward Models That Think",
    "authors": [
      "Muhammad Khalifa",
      "Rishabh Agarwal",
      "Lajanugen Logeswaran",
      "Jaekyeom Kim",
      "Hao Peng",
      "Moontae Lee",
      "Honglak Lee",
      "Lu Wang"
    ],
    "abstract": "Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16828v2",
    "published_date": "2025-04-23 15:44:54 UTC",
    "updated_date": "2025-05-18 01:23:04 UTC"
  },
  {
    "arxiv_id": "2504.16972v1",
    "title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications",
    "authors": [
      "Hossein Ahmadi",
      "Sajjad Emdadi Mahdimahalleh",
      "Arman Farahat",
      "Banafsheh Saffari"
    ],
    "abstract": "The rapid growth of unlabeled time-series data in domains such as wireless\ncommunications, radar, biomedical engineering, and the Internet of Things (IoT)\nhas driven advancements in unsupervised learning. This review synthesizes\nrecent progress in applying autoencoders and vision transformers for\nunsupervised signal analysis, focusing on their architectures, applications,\nand emerging trends. We explore how these models enable feature extraction,\nanomaly detection, and classification across diverse signal types, including\nelectrocardiograms, radar waveforms, and IoT sensor data. The review highlights\nthe strengths of hybrid architectures and self-supervised learning, while\nidentifying challenges in interpretability, scalability, and domain\ngeneralization. By bridging methodological innovations and practical\napplications, this work offers a roadmap for developing robust, adaptive models\nfor signal intelligence.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16972v1",
    "published_date": "2025-04-23 15:19:12 UTC",
    "updated_date": "2025-04-23 15:19:12 UTC"
  },
  {
    "arxiv_id": "2504.16795v1",
    "title": "Random Long-Context Access for Mamba via Hardware-aligned Hierarchical Sparse Attention",
    "authors": [
      "Xiang Hu",
      "Jiaqi Leng",
      "Jun Zhao",
      "Kewei Tu",
      "Wei Wu"
    ],
    "abstract": "A key advantage of Recurrent Neural Networks (RNNs) over Transformers is\ntheir linear computational and space complexity enables faster training and\ninference for long sequences. However, RNNs are fundamentally unable to\nrandomly access historical context, and simply integrating attention mechanisms\nmay undermine their efficiency advantages. To overcome this limitation, we\npropose \\textbf{H}ierarchical \\textbf{S}parse \\textbf{A}ttention (HSA), a novel\nattention mechanism that enhances RNNs with long-range random access\nflexibility while preserving their merits in efficiency and length\ngeneralization. HSA divides inputs into chunks, selecting the top-$k$ chunks\nand hierarchically aggregates information. The core innovation lies in learning\ntoken-to-chunk relevance based on fine-grained token-level information inside\neach chunk. This approach enhances the precision of chunk selection across both\nin-domain and out-of-domain context lengths. To make HSA efficient, we further\nintroduce a hardware-aligned kernel design. By combining HSA with Mamba, we\nintroduce RAMba, which achieves perfect accuracy in passkey retrieval across 64\nmillion contexts despite pre-training on only 4K-length contexts, and\nsignificant improvements on various downstream tasks, with nearly constant\nmemory footprint. These results show RAMba's huge potential in long-context\nmodeling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.16795v1",
    "published_date": "2025-04-23 15:15:06 UTC",
    "updated_date": "2025-04-23 15:15:06 UTC"
  },
  {
    "arxiv_id": "2504.16791v1",
    "title": "Radiometer Calibration using Machine Learning",
    "authors": [
      "S. A. K. Leeney",
      "H. T. J. Bevins",
      "E. de Lera Acedo",
      "W. J. Handley",
      "C. Kirkham",
      "R. S. Patel",
      "J. Zhu",
      "D. Molnar",
      "J. Cumner",
      "D. Anstey",
      "K. Artuc",
      "G. Bernardi",
      "M. Bucher",
      "S. Carey",
      "J. Cavillot",
      "R. Chiello",
      "W. Croukamp",
      "D. I. L. de Villiers",
      "J. A. Ely",
      "A. Fialkov",
      "T. Gessey-Jones",
      "G. Kulkarni",
      "A. Magro",
      "P. D. Meerburg",
      "S. Mittal",
      "J. H. N. Pattison",
      "S. Pegwal",
      "C. M. Pieterse",
      "J. R. Pritchard",
      "E. Puchwein",
      "N. Razavi-Ghods",
      "I. L. V. Roque",
      "A. Saxena",
      "K. H. Scheutwinkel",
      "P. Scott",
      "E. Shen",
      "P. H. Sims",
      "M. Spinelli"
    ],
    "abstract": "Radiometers are crucial instruments in radio astronomy, forming the primary\ncomponent of nearly all radio telescopes. They measure the intensity of\nelectromagnetic radiation, converting this radiation into electrical signals. A\nradiometer's primary components are an antenna and a Low Noise Amplifier (LNA),\nwhich is the core of the ``receiver'' chain. Instrumental effects introduced by\nthe receiver are typically corrected or removed during calibration. However,\nimpedance mismatches between the antenna and receiver can introduce unwanted\nsignal reflections and distortions. Traditional calibration methods, such as\nDicke switching, alternate the receiver input between the antenna and a\nwell-characterised reference source to mitigate errors by comparison. Recent\nadvances in Machine Learning (ML) offer promising alternatives. Neural\nnetworks, which are trained using known signal sources, provide a powerful\nmeans to model and calibrate complex systems where traditional analytical\napproaches struggle. These methods are especially relevant for detecting the\nfaint sky-averaged 21-cm signal from atomic hydrogen at high redshifts. This is\none of the main challenges in observational Cosmology today. Here, for the\nfirst time, we introduce and test a machine learning-based calibration\nframework capable of achieving the precision required for radiometric\nexperiments aiming to detect the 21-cm line.",
    "categories": [
      "astro-ph.IM",
      "astro-ph.CO",
      "cs.AI"
    ],
    "primary_category": "astro-ph.IM",
    "comment": "Under peer review for publication in Nature Scientific Reports as\n  part of the Radio Astronomy collection",
    "pdf_url": "http://arxiv.org/pdf/2504.16791v1",
    "published_date": "2025-04-23 15:10:25 UTC",
    "updated_date": "2025-04-23 15:10:25 UTC"
  },
  {
    "arxiv_id": "2504.16788v1",
    "title": "Towards Explainable AI: Multi-Modal Transformer for Video-based Image Description Generation",
    "authors": [
      "Lakshita Agarwal",
      "Bindu Verma"
    ],
    "abstract": "Understanding and analyzing video actions are essential for producing\ninsightful and contextualized descriptions, especially for video-based\napplications like intelligent monitoring and autonomous systems. The proposed\nwork introduces a novel framework for generating natural language descriptions\nfrom video datasets by combining textual and visual modalities. The suggested\narchitecture makes use of ResNet50 to extract visual features from video frames\nthat are taken from the Microsoft Research Video Description Corpus (MSVD), and\nBerkeley DeepDrive eXplanation (BDD-X) datasets. The extracted visual\ncharacteristics are converted into patch embeddings and then run through an\nencoder-decoder model based on Generative Pre-trained Transformer-2 (GPT-2). In\norder to align textual and visual representations and guarantee high-quality\ndescription production, the system uses multi-head self-attention and\ncross-attention techniques. The model's efficacy is demonstrated by performance\nevaluation using BLEU (1-4), CIDEr, METEOR, and ROUGE-L. The suggested\nframework outperforms traditional methods with BLEU-4 scores of 0.755 (BDD-X)\nand 0.778 (MSVD), CIDEr scores of 1.235 (BDD-X) and 1.315 (MSVD), METEOR scores\nof 0.312 (BDD-X) and 0.329 (MSVD), and ROUGE-L scores of 0.782 (BDD-X) and\n0.795 (MSVD). By producing human-like, contextually relevant descriptions,\nstrengthening interpretability, and improving real-world applications, this\nresearch advances explainable AI.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16788v1",
    "published_date": "2025-04-23 15:03:37 UTC",
    "updated_date": "2025-04-23 15:03:37 UTC"
  },
  {
    "arxiv_id": "2504.16787v1",
    "title": "Credible plan-driven RAG method for Multi-hop Question Answering",
    "authors": [
      "Ningning Zhang",
      "Chi Zhang",
      "Zhizhong Tan",
      "Xingxing Yang",
      "Weiping Deng",
      "Wenyong Wang"
    ],
    "abstract": "Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16787v1",
    "published_date": "2025-04-23 15:03:17 UTC",
    "updated_date": "2025-04-23 15:03:17 UTC"
  },
  {
    "arxiv_id": "2504.16778v2",
    "title": "Evaluation Framework for AI Systems in \"the Wild\"",
    "authors": [
      "Sarah Jabbour",
      "Trenton Chang",
      "Anindya Das Antar",
      "Joseph Peper",
      "Insu Jang",
      "Jiachen Liu",
      "Jae-Won Chung",
      "Shiqi He",
      "Michael Wellman",
      "Bryan Goodman",
      "Elizabeth Bondi-Kelly",
      "Kevin Samy",
      "Rada Mihalcea",
      "Mosharaf Chowdhury",
      "David Jurgens",
      "Lu Wang"
    ],
    "abstract": "Generative AI (GenAI) models have become vital across industries, yet current\nevaluation methods have not adapted to their widespread use. Traditional\nevaluations often rely on benchmarks and fixed datasets, frequently failing to\nreflect real-world performance, which creates a gap between lab-tested outcomes\nand practical applications. This white paper proposes a comprehensive framework\nfor how we should evaluate real-world GenAI systems, emphasizing diverse,\nevolving inputs and holistic, dynamic, and ongoing assessment approaches. The\npaper offers guidance for practitioners on how to design evaluation methods\nthat accurately reflect real-time capabilities, and provides policymakers with\nrecommendations for crafting GenAI policies focused on societal impacts, rather\nthan fixed performance numbers or parameter sizes. We advocate for holistic\nframeworks that integrate performance, fairness, and ethics and the use of\ncontinuous, outcome-oriented methods that combine human and automated\nassessments while also being transparent to foster trust among stakeholders.\nImplementing these strategies ensures GenAI models are not only technically\nproficient but also ethically responsible and impactful.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "35 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.16778v2",
    "published_date": "2025-04-23 14:52:39 UTC",
    "updated_date": "2025-04-28 15:12:12 UTC"
  },
  {
    "arxiv_id": "2504.16768v1",
    "title": "How Effective are Generative Large Language Models in Performing Requirements Classification?",
    "authors": [
      "Waad Alhoshan",
      "Alessio Ferrari",
      "Liping Zhao"
    ],
    "abstract": "In recent years, transformer-based large language models (LLMs) have\nrevolutionised natural language processing (NLP), with generative models\nopening new possibilities for tasks that require context-aware text generation.\nRequirements engineering (RE) has also seen a surge in the experimentation of\nLLMs for different tasks, including trace-link detection, regulatory\ncompliance, and others. Requirements classification is a common task in RE.\nWhile non-generative LLMs like BERT have been successfully applied to this\ntask, there has been limited exploration of generative LLMs. This gap raises an\nimportant question: how well can generative LLMs, which produce context-aware\noutputs, perform in requirements classification? In this study, we explore the\neffectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing\nboth binary and multi-class requirements classification. We design an extensive\nexperimental study involving over 400 experiments across three widely used\ndatasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes\nthat while factors like prompt design and LLM architecture are universally\nimportant, others-such as dataset variations-have a more situational impact,\ndepending on the complexity of the classification task. This insight can guide\nfuture model development and deployment strategies, focusing on optimising\nprompt structures and aligning model architectures with task-specific needs for\nimproved performance.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16768v1",
    "published_date": "2025-04-23 14:41:11 UTC",
    "updated_date": "2025-04-23 14:41:11 UTC"
  },
  {
    "arxiv_id": "2504.16763v1",
    "title": "Noise-Tolerant Coreset-Based Class Incremental Continual Learning",
    "authors": [
      "Edison Mucllari",
      "Aswin Raghavan",
      "Zachary Alan Daniels"
    ],
    "abstract": "Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Work-in-Progress",
    "pdf_url": "http://arxiv.org/pdf/2504.16763v1",
    "published_date": "2025-04-23 14:34:20 UTC",
    "updated_date": "2025-04-23 14:34:20 UTC"
  },
  {
    "arxiv_id": "2504.16760v1",
    "title": "Lightweight Latent Verifiers for Efficient Meta-Generation Strategies",
    "authors": [
      "Bartosz Piotrowski",
      "Witold Drzewakowski",
      "Konrad Staniszewski",
      "Piotr Miłoś"
    ],
    "abstract": "Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16760v1",
    "published_date": "2025-04-23 14:33:20 UTC",
    "updated_date": "2025-04-23 14:33:20 UTC"
  },
  {
    "arxiv_id": "2504.16754v1",
    "title": "HEMA : A Hippocampus-Inspired Extended Memory Architecture for Long-Context AI Conversations",
    "authors": [
      "Kwangseob Ahn"
    ],
    "abstract": "Large language models (LLMs) struggle with maintaining coherence in extended\nconversations spanning hundreds of turns, despite performing well within their\ncontext windows. This paper introduces HEMA (Hippocampus-Inspired Extended\nMemory Architecture), a dual-memory system inspired by human cognitive\nprocesses. HEMA combines Compact Memory - a continuously updated one-sentence\nsummary preserving global narrative coherence, and Vector Memory - an episodic\nstore of chunk embeddings queried via cosine similarity. When integrated with a\n6B-parameter transformer, HEMA maintains coherent dialogues beyond 300 turns\nwhile keeping prompt length under 3,500 tokens. Experimental results show\nsubstantial improvements: factual recall accuracy increases from 41% to 87%,\nand human-rated coherence improves from 2.7 to 4.3 on a 5-point scale. With 10K\nindexed chunks, Vector Memory achieves P@5 >= 0.80 and R@50 >= 0.74, doubling\nthe area under the precision-recall curve compared to summarization-only\napproaches. Ablation studies reveal two key insights: semantic forgetting\nthrough age-weighted pruning reduces retrieval latency by 34% with minimal\nrecall loss, and a two-level summary hierarchy prevents cascade errors in\nultra-long conversations exceeding 1,000 turns. HEMA demonstrates that\ncombining verbatim recall with semantic continuity provides a practical\nsolution for privacy-aware conversational AI capable of month-long dialogues\nwithout model retraining.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16754v1",
    "published_date": "2025-04-23 14:27:12 UTC",
    "updated_date": "2025-04-23 14:27:12 UTC"
  },
  {
    "arxiv_id": "2504.16738v1",
    "title": "MOSAIC: A Skill-Centric Algorithmic Framework for Long-Horizon Manipulation Planning",
    "authors": [
      "Itamar Mishani",
      "Yorai Shaoul",
      "Maxim Likhachev"
    ],
    "abstract": "Planning long-horizon motions using a set of predefined skills is a key\nchallenge in robotics and AI. Addressing this challenge requires methods that\nsystematically explore skill combinations to uncover task-solving sequences,\nharness generic, easy-to-learn skills (e.g., pushing, grasping) to generalize\nacross unseen tasks, and bypass reliance on symbolic world representations that\ndemand extensive domain and task-specific knowledge. Despite significant\nprogress, these elements remain largely disjoint in existing approaches,\nleaving a critical gap in achieving robust, scalable solutions for complex,\nlong-horizon problems. In this work, we present MOSAIC, a skill-centric\nframework that unifies these elements by using the skills themselves to guide\nthe planning process. MOSAIC uses two families of skills: Generators compute\nexecutable trajectories and world configurations, and Connectors link these\nindependently generated skill trajectories by solving boundary value problems,\nenabling progress toward completing the overall task. By breaking away from the\nconventional paradigm of incrementally discovering skills from predefined start\nor goal states--a limitation that significantly restricts exploration--MOSAIC\nfocuses planning efforts on regions where skills are inherently effective. We\ndemonstrate the efficacy of MOSAIC in both simulated and real-world robotic\nmanipulation tasks, showcasing its ability to solve complex long-horizon\nplanning problems using a diverse set of skills incorporating generative\ndiffusion models, motion planning algorithms, and manipulation-specific models.\nVisit https://skill-mosaic.github.io for demonstrations and examples.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "Under review. Project page: https://skill-mosaic.github.io",
    "pdf_url": "http://arxiv.org/pdf/2504.16738v1",
    "published_date": "2025-04-23 14:09:42 UTC",
    "updated_date": "2025-04-23 14:09:42 UTC"
  },
  {
    "arxiv_id": "2504.16736v2",
    "title": "A Survey of AI Agent Protocols",
    "authors": [
      "Yingxuan Yang",
      "Huacan Chai",
      "Yuanyi Song",
      "Siyuan Qi",
      "Muning Wen",
      "Ning Li",
      "Junwei Liao",
      "Haoyi Hu",
      "Jianghao Lin",
      "Gaowei Chang",
      "Weiwen Liu",
      "Ying Wen",
      "Yong Yu",
      "Weinan Zhang"
    ],
    "abstract": "The rapid development of large language models (LLMs) has led to the\nwidespread deployment of LLM agents across diverse industries, including\ncustomer service, content generation, data analysis, and even healthcare.\nHowever, as more LLM agents are deployed, a major issue has emerged: there is\nno standard way for these agents to communicate with external tools or data\nsources. This lack of standardized protocols makes it difficult for agents to\nwork together or scale effectively, and it limits their ability to tackle\ncomplex, real-world tasks. A unified communication protocol for LLM agents\ncould change this. It would allow agents and tools to interact more smoothly,\nencourage collaboration, and triggering the formation of collective\nintelligence. In this paper, we provide the first comprehensive analysis of\nexisting agent protocols, proposing a systematic two-dimensional classification\nthat differentiates context-oriented versus inter-agent protocols and\ngeneral-purpose versus domain-specific protocols. Additionally, we conduct a\ncomparative performance analysis of these protocols across key dimensions such\nas security, scalability, and latency. Finally, we explore the future landscape\nof agent protocols by identifying critical research directions and\ncharacteristics necessary for next-generation protocols. These characteristics\ninclude adaptability, privacy preservation, and group-based interaction, as\nwell as trends toward layered architectures and collective intelligence\ninfrastructures. We expect this work to serve as a practical reference for both\nresearchers and engineers seeking to design, evaluate, or integrate robust\ncommunication infrastructures for intelligent agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16736v2",
    "published_date": "2025-04-23 14:07:26 UTC",
    "updated_date": "2025-04-26 15:16:11 UTC"
  },
  {
    "arxiv_id": "2504.16728v1",
    "title": "IRIS: Interactive Research Ideation System for Accelerating Scientific Discovery",
    "authors": [
      "Aniketh Garikaparthi",
      "Manasi Patwardhan",
      "Lovekesh Vig",
      "Arman Cohan"
    ],
    "abstract": "The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages main-text, 2 pages appendix",
    "pdf_url": "http://arxiv.org/pdf/2504.16728v1",
    "published_date": "2025-04-23 14:01:36 UTC",
    "updated_date": "2025-04-23 14:01:36 UTC"
  },
  {
    "arxiv_id": "2504.16727v2",
    "title": "V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations",
    "authors": [
      "Zhiyuan Fan",
      "Yumeng Wang",
      "Sandeep Polisetty",
      "Yi R. Fung"
    ],
    "abstract": "Large Vision Language Models (LVLMs) excel in various vision-language tasks.\nYet, their robustness to visual variations in position, scale, orientation, and\ncontext that objects in natural scenes inevitably exhibit due to changes in\nviewpoint and environment remains largely underexplored. To bridge this gap, we\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\ndataset generation and principled metrics for thorough robustness assessment.\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\nto visual variations, in which even advanced models that excel at complex\nvision-language tasks significantly underperform on simple tasks such as object\nrecognition. Interestingly, these models exhibit a distinct visual position\nbias that contradicts theories of effective receptive fields, and demonstrate a\nhuman-like visual acuity threshold. To identify the source of these\nvulnerabilities, we present a systematic framework for component-level\nanalysis, featuring a novel visualization approach for aligned visual features.\nResults show that these vulnerabilities stem from error accumulation in the\npipeline architecture and inadequate multimodal alignment. Complementary\nexperiments with synthetic data further demonstrate that these limitations are\nfundamentally architectural deficiencies, scoring the need for architectural\ninnovations in future LVLM designs.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16727v2",
    "published_date": "2025-04-23 14:01:32 UTC",
    "updated_date": "2025-04-24 02:18:01 UTC"
  },
  {
    "arxiv_id": "2504.21027v1",
    "title": "UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models",
    "authors": [
      "Yu Zheng",
      "Longyi Liu",
      "Yuming Lin",
      "Jie Feng",
      "Guozhen Zhang",
      "Depeng Jin",
      "Yong Li"
    ],
    "abstract": "The advent of Large Language Models (LLMs) holds promise for revolutionizing\nvarious fields traditionally dominated by human expertise. Urban planning, a\nprofessional discipline that fundamentally shapes our daily surroundings, is\none such field heavily relying on multifaceted domain knowledge and experience\nof human experts. The extent to which LLMs can assist human practitioners in\nurban planning remains largely unexplored. In this paper, we introduce a\ncomprehensive benchmark, UrbanPlanBench, tailored to evaluate the efficacy of\nLLMs in urban planning, which encompasses fundamental principles, professional\nknowledge, and management and regulations, aligning closely with the\nqualifications expected of human planners. Through extensive evaluation, we\nreveal a significant imbalance in the acquisition of planning knowledge among\nLLMs, with even the most proficient models falling short of meeting\nprofessional standards. For instance, we observe that 70% of LLMs achieve\nsubpar performance in understanding planning regulations compared to other\naspects. Besides the benchmark, we present the largest-ever supervised\nfine-tuning (SFT) dataset, UrbanPlanText, comprising over 30,000 instruction\npairs sourced from urban planning exams and textbooks. Our findings demonstrate\nthat fine-tuned models exhibit enhanced performance in memorization tests and\ncomprehension of urban planning knowledge, while there exists significant room\nfor improvement, particularly in tasks requiring domain-specific terminology\nand reasoning. By making our benchmark, dataset, and associated evaluation and\nfine-tuning toolsets publicly available at\nhttps://github.com/tsinghua-fib-lab/PlanBench, we aim to catalyze the\nintegration of LLMs into practical urban planning, fostering a symbiotic\ncollaboration between human expertise and machine intelligence.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21027v1",
    "published_date": "2025-04-23 13:53:59 UTC",
    "updated_date": "2025-04-23 13:53:59 UTC"
  },
  {
    "arxiv_id": "2504.16723v1",
    "title": "Detecting and Understanding Hateful Contents in Memes Through Captioning and Visual Question-Answering",
    "authors": [
      "Ali Anaissi",
      "Junaid Akram",
      "Kunal Chaturvedi",
      "Ali Braytee"
    ],
    "abstract": "Memes are widely used for humor and cultural commentary, but they are\nincreasingly exploited to spread hateful content. Due to their multimodal\nnature, hateful memes often evade traditional text-only or image-only detection\nsystems, particularly when they employ subtle or coded references. To address\nthese challenges, we propose a multimodal hate detection framework that\nintegrates key components: OCR to extract embedded text, captioning to describe\nvisual content neutrally, sub-label classification for granular categorization\nof hateful content, RAG for contextually relevant retrieval, and VQA for\niterative analysis of symbolic and contextual cues. This enables the framework\nto uncover latent signals that simpler pipelines fail to detect. Experimental\nresults on the Facebook Hateful Memes dataset reveal that the proposed\nframework exceeds the performance of unimodal and conventional multimodal\nmodels in both accuracy and AUC-ROC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 2 figures, 2025 International Conference on Computational\n  Science",
    "pdf_url": "http://arxiv.org/pdf/2504.16723v1",
    "published_date": "2025-04-23 13:52:14 UTC",
    "updated_date": "2025-04-23 13:52:14 UTC"
  },
  {
    "arxiv_id": "2504.16722v1",
    "title": "PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum Learning",
    "authors": [
      "Yingjie Xi",
      "Jian Jun Zhang",
      "Xiaosong Yang"
    ],
    "abstract": "In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16722v1",
    "published_date": "2025-04-23 13:51:42 UTC",
    "updated_date": "2025-04-23 13:51:42 UTC"
  },
  {
    "arxiv_id": "2504.16680v1",
    "title": "Offline Robotic World Model: Learning Robotic Policies without a Physics Simulator",
    "authors": [
      "Chenhao Li",
      "Andreas Krause",
      "Marco Hutter"
    ],
    "abstract": "Reinforcement Learning (RL) has demonstrated impressive capabilities in\nrobotic control but remains challenging due to high sample complexity, safety\nconcerns, and the sim-to-real gap. While offline RL eliminates the need for\nrisky real-world exploration by learning from pre-collected data, it suffers\nfrom distributional shift, limiting policy generalization. Model-Based RL\n(MBRL) addresses this by leveraging predictive models for synthetic rollouts,\nyet existing approaches often lack robust uncertainty estimation, leading to\ncompounding errors in offline settings. We introduce Offline Robotic World\nModel (RWM-O), a model-based approach that explicitly estimates epistemic\nuncertainty to improve policy learning without reliance on a physics simulator.\nBy integrating these uncertainty estimates into policy optimization, our\napproach penalizes unreliable transitions, reducing overfitting to model errors\nand enhancing stability. Experimental results show that RWM-O improves\ngeneralization and safety, enabling policy learning purely from real-world data\nand advancing scalable, data-efficient RL for robotics.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16680v1",
    "published_date": "2025-04-23 12:58:15 UTC",
    "updated_date": "2025-04-23 12:58:15 UTC"
  },
  {
    "arxiv_id": "2504.16677v1",
    "title": "A Post-trainer's Guide to Multilingual Training Data: Uncovering Cross-lingual Transfer Dynamics",
    "authors": [
      "Luisa Shimabucoro",
      "Ahmet Ustun",
      "Marzieh Fadaee",
      "Sebastian Ruder"
    ],
    "abstract": "In order for large language models to be useful across the globe, they are\nfine-tuned to follow instructions on multilingual data. Despite the ubiquity of\nsuch post-training, a clear understanding of the dynamics that enable\ncross-lingual transfer remains elusive. This study examines cross-lingual\ntransfer (CLT) dynamics in realistic post-training settings. We study two model\nfamilies of up to 35B parameters in size trained on carefully controlled\nmixtures of multilingual data on three generative tasks with varying levels of\ncomplexity (summarization, instruction following, and mathematical reasoning)\nin both single-task and multi-task instruction tuning settings. Overall, we\nfind that the dynamics of cross-lingual transfer and multilingual performance\ncannot be explained by isolated variables, varying depending on the combination\nof post-training settings. Finally, we identify the conditions that lead to\neffective cross-lingual transfer in practice.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16677v1",
    "published_date": "2025-04-23 12:52:49 UTC",
    "updated_date": "2025-04-23 12:52:49 UTC"
  },
  {
    "arxiv_id": "2504.16667v1",
    "title": "Representation Learning via Non-Contrastive Mutual Information",
    "authors": [
      "Zhaohan Daniel Guo",
      "Bernardo Avila Pires",
      "Khimya Khetarpal",
      "Dale Schuurmans",
      "Bo Dai"
    ],
    "abstract": "Labeling data is often very time consuming and expensive, leaving us with a\nmajority of unlabeled data. Self-supervised representation learning methods\nsuch as SimCLR (Chen et al., 2020) or BYOL (Grill et al., 2020) have been very\nsuccessful at learning meaningful latent representations from unlabeled image\ndata, resulting in much more general and transferable representations for\ndownstream tasks. Broadly, self-supervised methods fall into two types: 1)\nContrastive methods, such as SimCLR; and 2) Non-Contrastive methods, such as\nBYOL. Contrastive methods are generally trying to maximize mutual information\nbetween related data points, so they need to compare every data point to every\nother data point, resulting in high variance, and thus requiring large batch\nsizes to work well. Non-contrastive methods like BYOL have much lower variance\nas they do not need to make pairwise comparisons, but are much trickier to\nimplement as they have the possibility of collapsing to a constant vector. In\nthis paper, we aim to develop a self-supervised objective that combines the\nstrength of both types. We start with a particular contrastive method called\nthe Spectral Contrastive Loss (HaoChen et al., 2021; Lu et al., 2024), and we\nconvert it into a more general non-contrastive form; this removes the pairwise\ncomparisons resulting in lower variance, but keeps the mutual information\nformulation of the contrastive method preventing collapse. We call our new\nobjective the Mutual Information Non-Contrastive (MINC) loss. We test MINC by\nlearning image representations on ImageNet (similar to SimCLR and BYOL) and\nshow that it consistently improves upon the Spectral Contrastive loss baseline.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.ML",
      "I.2.6; I.2.10"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16667v1",
    "published_date": "2025-04-23 12:35:27 UTC",
    "updated_date": "2025-04-23 12:35:27 UTC"
  },
  {
    "arxiv_id": "2504.16968v2",
    "title": "BackSlash: Rate Constrained Optimized Training of Large Language Models",
    "authors": [
      "Jun Wu",
      "Jiangtao Wen",
      "Yuxing Han"
    ],
    "abstract": "The rapid advancement of large-language models (LLMs) has driven extensive\nresearch into parameter compression after training has been completed, yet\ncompression during the training phase remains largely unexplored. In this work,\nwe introduce Rate-Constrained Training (BackSlash), a novel training-time\ncompression approach based on rate-distortion optimization (RDO). BackSlash\nenables a flexible trade-off between model accuracy and complexity,\nsignificantly reducing parameter redundancy while preserving performance.\nExperiments in various architectures and tasks demonstrate that BackSlash can\nreduce memory usage by 60% - 90% without accuracy loss and provides significant\ncompression gain compared to compression after training. Moreover, BackSlash\nproves to be highly versatile: it enhances generalization with small Lagrange\nmultipliers, improves model robustness to pruning (maintaining accuracy even at\n80% pruning rates), and enables network simplification for accelerated\ninference on edge devices.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16968v2",
    "published_date": "2025-04-23 12:28:27 UTC",
    "updated_date": "2025-04-25 08:26:21 UTC"
  },
  {
    "arxiv_id": "2504.16651v1",
    "title": "MAYA: Addressing Inconsistencies in Generative Password Guessing through a Unified Benchmark",
    "authors": [
      "William Corrias",
      "Fabio De Gaspari",
      "Dorjan Hitaj",
      "Luigi V. Mancini"
    ],
    "abstract": "The rapid evolution of generative models has led to their integration across\nvarious fields, including password guessing, aiming to generate passwords that\nresemble human-created ones in complexity, structure, and patterns. Despite\ngenerative model's promise, inconsistencies in prior research and a lack of\nrigorous evaluation have hindered a comprehensive understanding of their true\npotential. In this paper, we introduce MAYA, a unified, customizable,\nplug-and-play password benchmarking framework. MAYA provides a standardized\napproach for evaluating generative password-guessing models through a rigorous\nset of advanced testing scenarios and a collection of eight real-life password\ndatasets. Using MAYA, we comprehensively evaluate six state-of-the-art\napproaches, which have been re-implemented and adapted to ensure\nstandardization, for a total of over 15,000 hours of computation. Our findings\nindicate that these models effectively capture different aspects of human\npassword distribution and exhibit strong generalization capabilities. However,\ntheir effectiveness varies significantly with long and complex passwords.\nThrough our evaluation, sequential models consistently outperform other\ngenerative architectures and traditional password-guessing tools, demonstrating\nunique capabilities in generating accurate and complex guesses. Moreover,\nmodels learn and generate different password distributions, enabling a\nmulti-model attack that outperforms the best individual model. By releasing\nMAYA, we aim to foster further research, providing the community with a new\ntool to consistently and reliably benchmark password-generation techniques. Our\nframework is publicly available at\nhttps://github.com/williamcorrias/MAYA-Password-Benchmarking",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16651v1",
    "published_date": "2025-04-23 12:16:59 UTC",
    "updated_date": "2025-04-23 12:16:59 UTC"
  },
  {
    "arxiv_id": "2504.16640v1",
    "title": "SSLR: A Semi-Supervised Learning Method for Isolated Sign Language Recognition",
    "authors": [
      "Hasan Algafri",
      "Hamzah Luqman",
      "Sarah Alyami",
      "Issam Laradji"
    ],
    "abstract": "Sign language is the primary communication language for people with disabling\nhearing loss. Sign language recognition (SLR) systems aim to recognize sign\ngestures and translate them into spoken language. One of the main challenges in\nSLR is the scarcity of annotated datasets. To address this issue, we propose a\nsemi-supervised learning (SSL) approach for SLR (SSLR), employing a\npseudo-label method to annotate unlabeled samples. The sign gestures are\nrepresented using pose information that encodes the signer's skeletal joint\npoints. This information is used as input for the Transformer backbone model\nutilized in the proposed approach. To demonstrate the learning capabilities of\nSSL across various labeled data sizes, several experiments were conducted using\ndifferent percentages of labeled data with varying numbers of classes. The\nperformance of the SSL approach was compared with a fully supervised\nlearning-based model on the WLASL-100 dataset. The obtained results of the SSL\nmodel outperformed the supervised learning-based model with less labeled data\nin many cases.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16640v1",
    "published_date": "2025-04-23 11:59:52 UTC",
    "updated_date": "2025-04-23 11:59:52 UTC"
  },
  {
    "arxiv_id": "2504.16635v1",
    "title": "Bridging Econometrics and AI: VaR Estimation via Reinforcement Learning and GARCH Models",
    "authors": [
      "Fredy Pokou",
      "Jules Sadefo Kamdem",
      "François Benhmad"
    ],
    "abstract": "In an environment of increasingly volatile financial markets, the accurate\nestimation of risk remains a major challenge. Traditional econometric models,\nsuch as GARCH and its variants, are based on assumptions that are often too\nrigid to adapt to the complexity of the current market dynamics. To overcome\nthese limitations, we propose a hybrid framework for Value-at-Risk (VaR)\nestimation, combining GARCH volatility models with deep reinforcement learning.\nOur approach incorporates directional market forecasting using the Double Deep\nQ-Network (DDQN) model, treating the task as an imbalanced classification\nproblem. This architecture enables the dynamic adjustment of risk-level\nforecasts according to market conditions. Empirical validation on daily\nEurostoxx 50 data covering periods of crisis and high volatility shows a\nsignificant improvement in the accuracy of VaR estimates, as well as a\nreduction in the number of breaches and also in capital requirements, while\nrespecting regulatory risk thresholds. The ability of the model to adjust risk\nlevels in real time reinforces its relevance to modern and proactive risk\nmanagement.",
    "categories": [
      "cs.AI",
      "q-fin.CP",
      "q-fin.RM",
      "q-fin.ST"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16635v1",
    "published_date": "2025-04-23 11:54:22 UTC",
    "updated_date": "2025-04-23 11:54:22 UTC"
  },
  {
    "arxiv_id": "2504.21026v1",
    "title": "Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models",
    "authors": [
      "Manish Pandey",
      "Nageshwar Prasad Yadav",
      "Mokshada Adduru",
      "Sawan Rai"
    ],
    "abstract": "With the growing presence of multilingual users on social media, detecting\nabusive language in code-mixed text has become increasingly challenging.\nCode-mixed communication, where users seamlessly switch between English and\ntheir native languages, poses difficulties for traditional abuse detection\nmodels, as offensive content may be context-dependent or obscured by linguistic\nblending. While abusive language detection has been extensively explored for\nhigh-resource languages like English and Hindi, low-resource languages such as\nTelugu and Nepali remain underrepresented, leaving gaps in effective\nmoderation. In this study, we introduce a novel, manually annotated dataset of\n2 thousand Telugu-English and 5 Nepali-English code-mixed comments, categorized\nas abusive and non-abusive, collected from various social media platforms. The\ndataset undergoes rigorous preprocessing before being evaluated across multiple\nMachine Learning (ML), Deep Learning (DL), and Large Language Models (LLMs). We\nexperimented with models including Logistic Regression, Random Forest, Support\nVector Machines (SVM), Neural Networks (NN), LSTM, CNN, and LLMs, optimizing\ntheir performance through hyperparameter tuning, and evaluate it using 10-fold\ncross-validation and statistical significance testing (t-test). Our findings\nprovide key insights into the challenges of detecting abusive language in\ncode-mixed settings and offer a comparative analysis of computational\napproaches. This study contributes to advancing NLP for low-resource languages\nby establishing benchmarks for abusive language detection in Telugu-English and\nNepali-English code-mixed text. The dataset and insights can aid in the\ndevelopment of more robust moderation strategies for multilingual social media\nenvironments.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.21026v1",
    "published_date": "2025-04-23 11:29:10 UTC",
    "updated_date": "2025-04-23 11:29:10 UTC"
  },
  {
    "arxiv_id": "2504.16622v1",
    "title": "Cognitive Silicon: An Architectural Blueprint for Post-Industrial Computing Systems",
    "authors": [
      "Christoforus Yoga Haryanto",
      "Emily Lomempow"
    ],
    "abstract": "Autonomous AI systems reveal foundational limitations in deterministic,\nhuman-authored computing architectures. This paper presents Cognitive Silicon:\na hypothetical full-stack architectural framework projected toward 2035,\nexploring a possible trajectory for cognitive computing system design. The\nproposed architecture would integrate symbolic scaffolding, governed memory,\nruntime moral coherence, and alignment-aware execution across\nsilicon-to-semantics layers. Our design grammar has emerged from dialectical\nco-design with LLMs under asymmetric epistemic conditions--creating structured\nfriction to expose blind spots and trade-offs. The envisioned framework would\nestablish mortality as a natural consequence of physical constraints,\nnon-copyable tacit knowledge, and non-cloneable identity keys as\ncognitive-embodiment primitives. Core tensions (trust/agency,\nscaffolding/emergence, execution/governance) would function as central\narchitectural pressures rather than edge cases. The architecture theoretically\nconverges with the Free Energy Principle, potentially offering a formal account\nof how cognitive systems could maintain identity through prediction error\nminimization across physical and computational boundaries. The resulting\nframework aims to deliver a morally tractable cognitive infrastructure that\ncould maintain human-alignment through irreversible hardware constraints and\nidentity-bound epistemic mechanisms resistant to replication or subversion.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Working Paper, 37 pages, 1 figure, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.16622v1",
    "published_date": "2025-04-23 11:24:30 UTC",
    "updated_date": "2025-04-23 11:24:30 UTC"
  },
  {
    "arxiv_id": "2504.16604v1",
    "title": "Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories",
    "authors": [
      "Mareike Lisker",
      "Christina Gottschalk",
      "Helena Mihaljević"
    ],
    "abstract": "Counterspeech is a key strategy against harmful online content, but scaling\nexpert-driven efforts is challenging. Large Language Models (LLMs) present a\npotential solution, though their use in countering conspiracy theories is\nunder-researched. Unlike for hate speech, no datasets exist that pair\nconspiracy theory comments with expert-crafted counterspeech. We address this\ngap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively\napply counterspeech strategies derived from psychological research provided\nthrough structured prompts. Our results show that the models often generate\ngeneric, repetitive, or superficial results. Additionally, they\nover-acknowledge fear and frequently hallucinate facts, sources, or figures,\nmaking their prompt-based use in practical applications problematic.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.16604v1",
    "published_date": "2025-04-23 10:32:45 UTC",
    "updated_date": "2025-04-23 10:32:45 UTC"
  },
  {
    "arxiv_id": "2504.16601v1",
    "title": "Comparing Large Language Models and Traditional Machine Translation Tools for Translating Medical Consultation Summaries: A Pilot Study",
    "authors": [
      "Andy Li",
      "Wei Zhou",
      "Rashina Hoda",
      "Chris Bain",
      "Peter Poon"
    ],
    "abstract": "This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 2 tables and 1 Figure",
    "pdf_url": "http://arxiv.org/pdf/2504.16601v1",
    "published_date": "2025-04-23 10:31:33 UTC",
    "updated_date": "2025-04-23 10:31:33 UTC"
  },
  {
    "arxiv_id": "2504.16584v1",
    "title": "Case Study: Fine-tuning Small Language Models for Accurate and Private CWE Detection in Python Code",
    "authors": [
      "Md. Azizul Hakim Bappy",
      "Hossen A Mustafa",
      "Prottoy Saha",
      "Rajinus Salehat"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and analyzing code for security vulnerabilities, such as Common\nWeakness Enumerations (CWEs). However, their reliance on cloud infrastructure\nand substantial computational requirements pose challenges for analyzing\nsensitive or proprietary codebases due to privacy concerns and inference costs.\nThis work explores the potential of Small Language Models (SLMs) as a viable\nalternative for accurate, on-premise vulnerability detection. We investigated\nwhether a 350-million parameter pre-trained code model (codegen-mono) could be\neffectively fine-tuned to detect the MITRE Top 25 CWEs specifically within\nPython code. To facilitate this, we developed a targeted dataset of 500\nexamples using a semi-supervised approach involving LLM-driven synthetic data\ngeneration coupled with meticulous human review. Initial tests confirmed that\nthe base codegen-mono model completely failed to identify CWEs in our samples.\nHowever, after applying instruction-following fine-tuning, the specialized SLM\nachieved remarkable performance on our test set, yielding approximately 99%\naccuracy, 98.08% precision, 100% recall, and a 99.04% F1-score. These results\nstrongly suggest that fine-tuned SLMs can serve as highly accurate and\nefficient tools for CWE detection, offering a practical and privacy-preserving\nsolution for integrating advanced security analysis directly into development\nworkflows.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "11 pages, 2 figures, 3 tables. Dataset available at\n  https://huggingface.co/datasets/floxihunter/synthetic_python_cwe. Model\n  available at https://huggingface.co/floxihunter/codegen-mono-CWEdetect.\n  Keywords: Small Language Models (SLMs), Vulnerability Detection, CWE,\n  Fine-tuning, Python Security, Privacy-Preserving Code Analysis",
    "pdf_url": "http://arxiv.org/pdf/2504.16584v1",
    "published_date": "2025-04-23 10:05:27 UTC",
    "updated_date": "2025-04-23 10:05:27 UTC"
  },
  {
    "arxiv_id": "2504.16576v1",
    "title": "MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation",
    "authors": [
      "Xu Guo",
      "Tong Zhang",
      "Fuyun Wang",
      "Xudong Wang",
      "Xiaoya Zhang",
      "Xin Liu",
      "Zhen Cui"
    ],
    "abstract": "The burgeoning presence of multimodal content-sharing platforms propels the\ndevelopment of personalized recommender systems. Previous works usually suffer\nfrom data sparsity and cold-start problems, and may fail to adequately explore\nsemantic user-product associations from multimodal data. To address these\nissues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL)\nframework for user recommendation. For a comprehensive information exploration\nfrom user-product relations, we construct two hypergraphs, i.e. a user-to-user\n(u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine shared\npreferences among users and intricate multimodal semantic resemblance among\nitems, respectively. This process yields denser second-order semantics that are\nfused with first-order user-item interaction as complementary to alleviate the\ndata sparsity issue. Then, we design a contrastive feature enhancement paradigm\nby applying synergistic contrastive learning. By maximizing/minimizing the\nmutual information between second-order (e.g. shared preference pattern for\nusers) and first-order (information of selected items for users) embeddings of\nthe same/different users and items, the feature distinguishability can be\neffectively enhanced. Compared with using sparse primary user-item interaction\nonly, our MMHCL obtains denser second-order hypergraphs and excavates more\nabundant shared attributes to explore the user-product associations, which to a\ncertain extent alleviates the problems of data sparsity and cold-start.\nExtensive experiments have comprehensively demonstrated the effectiveness of\nour method. Our code is publicly available at: https://github.com/Xu107/MMHCL.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "23 pages, 8 figures. This manuscript is currently under major\n  revision for ACM Transactions on Multimedia Computing, Communications, and\n  Applications (ACM TOMM)",
    "pdf_url": "http://arxiv.org/pdf/2504.16576v1",
    "published_date": "2025-04-23 09:58:54 UTC",
    "updated_date": "2025-04-23 09:58:54 UTC"
  },
  {
    "arxiv_id": "2504.16574v1",
    "title": "PIS: Linking Importance Sampling and Attention Mechanisms for Efficient Prompt Compression",
    "authors": [
      "Lizhe Chen",
      "Binjia Zhou",
      "Yuyao Ge",
      "Jiayi Chen",
      "Shiguang NI"
    ],
    "abstract": "Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16574v1",
    "published_date": "2025-04-23 09:53:01 UTC",
    "updated_date": "2025-04-23 09:53:01 UTC"
  },
  {
    "arxiv_id": "2504.16573v1",
    "title": "PsyCounAssist: A Full-Cycle AI-Powered Psychological Counseling Assistant System",
    "authors": [
      "Xianghe Liu",
      "Jiaqi Xu",
      "Tao Sun"
    ],
    "abstract": "Psychological counseling is a highly personalized and dynamic process that\nrequires therapists to continuously monitor emotional changes, document session\ninsights, and maintain therapeutic continuity. In this paper, we introduce\nPsyCounAssist, a comprehensive AI-powered counseling assistant system\nspecifically designed to augment psychological counseling practices.\nPsyCounAssist integrates multimodal emotion recognition combining speech and\nphotoplethysmography (PPG) signals for accurate real-time affective analysis,\nautomated structured session reporting using large language models (LLMs), and\npersonalized AI-generated follow-up support. Deployed on Android-based tablet\ndevices, the system demonstrates practical applicability and flexibility in\nreal-world counseling scenarios. Experimental evaluation confirms the\nreliability of PPG-based emotional classification and highlights the system's\npotential for non-intrusive, privacy-aware emotional support. PsyCounAssist\nrepresents a novel approach to ethically and effectively integrating AI into\npsychological counseling workflows.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16573v1",
    "published_date": "2025-04-23 09:49:05 UTC",
    "updated_date": "2025-04-23 09:49:05 UTC"
  },
  {
    "arxiv_id": "2504.16562v1",
    "title": "A Vision for AI-Driven Adaptation of Dynamic AR Content to Users and Environments",
    "authors": [
      "Julian Rasch",
      "Florian Müller",
      "Francesco Chiossi"
    ],
    "abstract": "Augmented Reality (AR) is transforming the way we interact with virtual\ninformation in the physical world. By overlaying digital content in real-world\nenvironments, AR enables new forms of immersive and engaging experiences.\nHowever, existing AR systems often struggle to effectively manage the many\ninteractive possibilities that AR presents. This vision paper speculates on\nAI-driven approaches for adaptive AR content placement, dynamically adjusting\nto user movement and environmental changes. By leveraging machine learning\nmethods, such a system would intelligently manage content distribution between\nAR projections integrated into the external environment and fixed static\ncontent, enabling seamless UI layout and potentially reducing users' cognitive\nload. By exploring the possibilities of AI-driven dynamic AR content placement,\nwe aim to envision new opportunities for innovation and improvement in various\nindustries, from urban navigation and workplace productivity to immersive\nlearning and beyond. This paper outlines a vision for the development of more\nintuitive, engaging, and effective AI-powered AR experiences.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16562v1",
    "published_date": "2025-04-23 09:42:38 UTC",
    "updated_date": "2025-04-23 09:42:38 UTC"
  },
  {
    "arxiv_id": "2504.16548v1",
    "title": "Exploring human-SAV interaction using large language models: The impact of psychological ownership and anthropomorphism on user experience",
    "authors": [
      "Lirui Guo",
      "Michael G. Burke",
      "Wynita M. Griggs"
    ],
    "abstract": "There has been extensive prior work exploring how psychological factors such\nas anthropomorphism affect the adoption of shared autonomous vehicles (SAVs).\nHowever, limited research has been conducted on how prompt strategies in large\nlanguage model (LLM)-powered SAV User Interfaces (UIs) affect users'\nperceptions, experiences, and intentions to adopt such technology. In this\nwork, we investigate how conversational UIs powered by LLMs drive these\npsychological factors and psychological ownership, the sense of possession a\nuser may come to feel towards an entity or object they may not legally own. We\ndesigned four SAV UIs with varying levels of anthropomorphic characteristics\nand psychological ownership triggers. Quantitative measures of psychological\nownership, anthropomorphism, quality of service, disclosure tendency, sentiment\nof SAV responses, and overall acceptance were collected after participants\ninteracted with each SAV. Qualitative feedback was also gathered regarding the\nexperience of psychological ownership during the interactions. The results\nindicate that an SAV conversational UI designed to be more anthropomorphic and\nto induce psychological ownership improved users' perceptions of the SAV's\nhuman-like qualities and improved the sentiment of responses compared to a\ncontrol condition. These findings provide practical guidance for designing\nLLM-based conversational UIs that enhance user experience and adoption of SAVs.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16548v1",
    "published_date": "2025-04-23 09:25:22 UTC",
    "updated_date": "2025-04-23 09:25:22 UTC"
  },
  {
    "arxiv_id": "2504.16537v1",
    "title": "Transformers for Complex Query Answering over Knowledge Hypergraphs",
    "authors": [
      "Hong Ting Tsang",
      "Zihao Wang",
      "Yangqiu Song"
    ],
    "abstract": "Complex Query Answering (CQA) has been extensively studied in recent years.\nIn order to model data that is closer to real-world distribution, knowledge\ngraphs with different modalities have been introduced. Triple KGs, as the\nclassic KGs composed of entities and relations of arity 2, have limited\nrepresentation of real-world facts. Real-world data is more sophisticated.\nWhile hyper-relational graphs have been introduced, there are limitations in\nrepresenting relationships of varying arity that contain entities with equal\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\nM-FB15k-HCQA. Each dataset contains various query types that include logical\noperations such as projection, negation, conjunction, and disjunction. In order\nto answer knowledge hypergraph (KHG) existential first-order queries, we\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\nprojection and a Logical Encoder for complex logical operations. Both encoders\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\nmethod over KHG and is able to generalize to out-of-distribution query types.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16537v1",
    "published_date": "2025-04-23 09:07:21 UTC",
    "updated_date": "2025-04-23 09:07:21 UTC"
  },
  {
    "arxiv_id": "2504.16516v2",
    "title": "Think Hierarchically, Act Dynamically: Hierarchical Multi-modal Fusion and Reasoning for Vision-and-Language Navigation",
    "authors": [
      "Junrong Yue",
      "Yifan Zhang",
      "Chuan Qin",
      "Bo Li",
      "Xiaomin Lie",
      "Xinlei Yu",
      "Wenxin Zhang",
      "Zhendong Zhao"
    ],
    "abstract": "Vision-and-Language Navigation (VLN) aims to enable embodied agents to follow\nnatural language instructions and reach target locations in real-world\nenvironments. While prior methods often rely on either global scene\nrepresentations or object-level features, these approaches are insufficient for\ncapturing the complex interactions across modalities required for accurate\nnavigation. In this paper, we propose a Multi-level Fusion and Reasoning\nArchitecture (MFRA) to enhance the agent's ability to reason over visual\nobservations, language instructions and navigation history. Specifically, MFRA\nintroduces a hierarchical fusion mechanism that aggregates multi-level\nfeatures-ranging from low-level visual cues to high-level semantic\nconcepts-across multiple modalities. We further design a reasoning module that\nleverages fused representations to infer navigation actions through\ninstruction-guided attention and dynamic context integration. By selectively\ncapturing and combining relevant visual, linguistic, and temporal signals, MFRA\nimproves decision-making accuracy in complex navigation scenarios. Extensive\nexperiments on benchmark VLN datasets including REVERIE, R2R, and SOON\ndemonstrate that MFRA achieves superior performance compared to\nstate-of-the-art methods, validating the effectiveness of multi-level modal\nfusion for embodied navigation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 4 figures, Submitted to ACM MM 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16516v2",
    "published_date": "2025-04-23 08:41:27 UTC",
    "updated_date": "2025-04-24 19:36:09 UTC"
  },
  {
    "arxiv_id": "2504.16515v1",
    "title": "Federated Learning of Low-Rank One-Shot Image Detection Models in Edge Devices with Scalable Accuracy and Compute Complexity",
    "authors": [
      "Abdul Hannaan",
      "Zubair Shah",
      "Aiman Erbad",
      "Amr Mohamed",
      "Ali Safa"
    ],
    "abstract": "This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "accepted for publication at IEEE IWCMC 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16515v1",
    "published_date": "2025-04-23 08:40:44 UTC",
    "updated_date": "2025-04-23 08:40:44 UTC"
  },
  {
    "arxiv_id": "2504.16489v1",
    "title": "Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based Multi-Agent Debate",
    "authors": [
      "Senmao Qi",
      "Yifei Zou",
      "Peng Li",
      "Ziyi Lin",
      "Xiuzhen Cheng",
      "Dongxiao Yu"
    ],
    "abstract": "Multi-Agent Debate (MAD), leveraging collaborative interactions among Large\nLanguage Models (LLMs), aim to enhance reasoning capabilities in complex tasks.\nHowever, the security implications of their iterative dialogues and\nrole-playing characteristics, particularly susceptibility to jailbreak attacks\neliciting harmful content, remain critically underexplored. This paper\nsystematically investigates the jailbreak vulnerabilities of four prominent MAD\nframeworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo,\nand DeepSeek) without compromising internal agents. We introduce a novel\nstructured prompt-rewriting framework specifically designed to exploit MAD\ndynamics via narrative encapsulation, role-driven escalation, iterative\nrefinement, and rhetorical obfuscation. Our extensive experiments demonstrate\nthat MAD systems are inherently more vulnerable than single-agent setups.\nCrucially, our proposed attack methodology significantly amplifies this\nfragility, increasing average harmfulness from 28.14% to 80.34% and achieving\nattack success rates as high as 80% in certain scenarios. These findings reveal\nintrinsic vulnerabilities in MAD architectures and underscore the urgent need\nfor robust, specialized defenses prior to real-world deployment.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "33 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16489v1",
    "published_date": "2025-04-23 08:01:50 UTC",
    "updated_date": "2025-04-23 08:01:50 UTC"
  },
  {
    "arxiv_id": "2504.16485v1",
    "title": "On Developers' Self-Declaration of AI-Generated Code: An Analysis of Practices",
    "authors": [
      "Syed Mohammad Kashif",
      "Peng Liang",
      "Amjed Tahir"
    ],
    "abstract": "AI code generation tools have gained significant popularity among developers,\nwho use them to assist in software development due to their capability to\ngenerate code. Existing studies mainly explored the quality, e.g., correctness\nand security, of AI-generated code, while in real-world software development,\nthe prerequisite is to distinguish AI-generated code from human-written code,\nwhich emphasizes the need to explicitly declare AI-generated code by\ndevelopers. To this end, this study intends to understand the ways developers\nuse to self-declare AI-generated code and explore the reasons why developers\nchoose to self-declare or not. We conducted a mixed-methods study consisting of\ntwo phases. In the first phase, we mined GitHub repositories and collected 613\ninstances of AI-generated code snippets. In the second phase, we conducted a\nfollow-up industrial survey, which received 111 valid responses. Our research\nrevealed the practices followed by developers to self-declare AI-generated\ncode. Most practitioners (76.6%) always or sometimes self-declare AI-generated\ncode. In contrast, other practitioners (23.4%) noted that they never\nself-declare AI-generated code. The reasons for self-declaring AI-generated\ncode include the need to track and monitor the code for future review and\ndebugging, and ethical considerations. The reasons for not self-declaring\nAI-generated code include extensive modifications to AI-generated code and the\ndevelopers' perception that self-declaration is an unnecessary activity. We\nfinally provided guidelines for practitioners to self-declare AI-generated\ncode, addressing ethical and code quality concerns.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "35 pages, 17 images, 8 tables, Manuscript submitted to a journal\n  (2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.16485v1",
    "published_date": "2025-04-23 07:52:39 UTC",
    "updated_date": "2025-04-23 07:52:39 UTC"
  },
  {
    "arxiv_id": "2504.16479v1",
    "title": "The Dance of Atoms-De Novo Protein Design with Diffusion Model",
    "authors": [
      "Yujie Qin",
      "Ming He",
      "Changyong Yu",
      "Ming Ni",
      "Xian Liu",
      "Xiaochen Bo"
    ],
    "abstract": "The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.",
    "categories": [
      "q-bio.BM",
      "cs.AI"
    ],
    "primary_category": "q-bio.BM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16479v1",
    "published_date": "2025-04-23 07:45:00 UTC",
    "updated_date": "2025-04-23 07:45:00 UTC"
  },
  {
    "arxiv_id": "2504.16472v2",
    "title": "Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges",
    "authors": [
      "Mark Harman",
      "Peter O'Hearn",
      "Shubho Sengupta"
    ],
    "abstract": "Despite decades of research and practice in automated software testing,\nseveral fundamental concepts remain ill-defined and under-explored, yet offer\nenormous potential real-world impact. We show that these concepts raise\nexciting new challenges in the context of Large Language Models for software\ntest generation. More specifically, we formally define and investigate the\nproperties of hardening and catching tests. A hardening test is one that seeks\nto protect against future regressions, while a catching test is one that\ncatches such a regression or a fault in new functionality introduced by a code\nchange. Hardening tests can be generated at any time and may become catching\ntests when a future regression is caught. We also define and motivate the\nCatching 'Just-in-Time' (JiTTest) Challenge, in which tests are generated\n'just-in-time' to catch new faults before they land into production. We show\nthat any solution to Catching JiTTest generation can also be repurposed to\ncatch latent faults in legacy code. We enumerate possible outcomes for\nhardening and catching tests and JiTTests, and discuss open research problems,\ndeployment options, and initial results from our work on automated LLM-based\nhardening at Meta. This paper was written to accompany the keynote by the\nauthors at the ACM International Conference on the Foundations of Software\nEngineering (FSE) 2025. Author order is alphabetical. The corresponding author\nis Mark Harman.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "To Appear as keynote paper at FSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16472v2",
    "published_date": "2025-04-23 07:32:43 UTC",
    "updated_date": "2025-05-14 10:55:20 UTC"
  },
  {
    "arxiv_id": "2504.16464v1",
    "title": "ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance",
    "authors": [
      "Ying Li",
      "Xiaobao Wei",
      "Xiaowei Chi",
      "Yuming Li",
      "Zhongyu Zhao",
      "Hao Wang",
      "Ningning Ma",
      "Ming Lu",
      "Shanghang Zhang"
    ],
    "abstract": "While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "9 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16464v1",
    "published_date": "2025-04-23 07:23:41 UTC",
    "updated_date": "2025-04-23 07:23:41 UTC"
  },
  {
    "arxiv_id": "2504.16460v1",
    "title": "T-VEC: A Telecom-Specific Vectorization Model with Enhanced Semantic Understanding via Deep Triplet Loss Fine-Tuning",
    "authors": [
      "Vignesh Ethiraj",
      "Sidhanth Menon",
      "Divya Vijay"
    ],
    "abstract": "The specialized vocabulary and complex concepts of the telecommunications\nindustry present significant challenges for standard Natural Language\nProcessing models. Generic text embeddings often fail to capture\ntelecom-specific semantics, hindering downstream task performance. We introduce\nT-VEC (Telecom Vectorization Model), a novel embedding model tailored for the\ntelecom domain through deep fine-tuning. Developed by NetoAI, T-VEC is created\nby adapting the state-of-the-art gte-Qwen2-1.5B-instruct model using a triplet\nloss objective on a meticulously curated, large-scale dataset of\ntelecom-specific data. Crucially, this process involved substantial\nmodification of weights across 338 layers of the base model, ensuring deep\nintegration of domain knowledge, far exceeding superficial adaptation\ntechniques. We quantify this deep change via weight difference analysis. A key\ncontribution is the development and open-sourcing (MIT License) of the first\ndedicated telecom-specific tokenizer, enhancing the handling of industry\njargon. T-VEC achieves a leading average MTEB score (0.825) compared to\nestablished models and demonstrates vastly superior performance (0.9380 vs.\nless than 0.07) on our internal telecom-specific triplet evaluation benchmark,\nindicating an exceptional grasp of domain-specific nuances, visually confirmed\nby improved embedding separation. This work positions NetoAI at the forefront\nof telecom AI innovation, providing the community with a powerful, deeply\nadapted, open-source tool.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50"
    ],
    "primary_category": "cs.CL",
    "comment": "Introduces T-VEC, a telecom-specific text embedding model. Fine-tuned\n  gte-Qwen2-1.5B-instruct on curated telecom data points. Includes the first\n  open-source telecom tokenizer. Model available at\n  https://huggingface.co/NetoAISolutions/T-VEC",
    "pdf_url": "http://arxiv.org/pdf/2504.16460v1",
    "published_date": "2025-04-23 07:10:37 UTC",
    "updated_date": "2025-04-23 07:10:37 UTC"
  },
  {
    "arxiv_id": "2504.16448v1",
    "title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records",
    "authors": [
      "Shuguang Zhao",
      "Qiangzhong Feng",
      "Zhiyang He",
      "Peipei Sun",
      "Yingying Wang",
      "Xiaodong Tao",
      "Xiaoliang Lu",
      "Mei Cheng",
      "Xinyue Wu",
      "Yanyan Wang",
      "Wei Liang"
    ],
    "abstract": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16448v1",
    "published_date": "2025-04-23 06:17:55 UTC",
    "updated_date": "2025-04-23 06:17:55 UTC"
  },
  {
    "arxiv_id": "2504.16438v1",
    "title": "Private Federated Learning using Preference-Optimized Synthetic Data",
    "authors": [
      "Charlie Hou",
      "Mei-Yu Wang",
      "Yige Zhu",
      "Daniel Lazar",
      "Giulia Fanti"
    ],
    "abstract": "In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Spotlight presentation at SynthData Workshop ICLR25",
    "pdf_url": "http://arxiv.org/pdf/2504.16438v1",
    "published_date": "2025-04-23 05:57:20 UTC",
    "updated_date": "2025-04-23 05:57:20 UTC"
  },
  {
    "arxiv_id": "2504.16432v1",
    "title": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network",
    "authors": [
      "Ziran Liang",
      "Rui An",
      "Wenqi Fan",
      "Yanghui Rao",
      "Yuxuan Liang"
    ],
    "abstract": "As time evolves, data within specific domains exhibit predictability that\nmotivates time series forecasting to predict future trends from historical\ndata. However, current deep forecasting methods can achieve promising\nperformance but generally lack interpretability, hindering trustworthiness and\npractical deployment in safety-critical applications such as auto-driving and\nhealthcare. In this paper, we propose a novel interpretable model, iTFKAN, for\ncredible time series forecasting. iTFKAN enables further exploration of model\ndecision rationales and underlying data patterns due to its interpretability\nachieved through model symbolization. Besides, iTFKAN develops two strategies,\nprior knowledge injection, and time-frequency synergy learning, to effectively\nguide model learning under complex intertwined time series data. Extensive\nexperimental results demonstrated that iTFKAN can achieve promising forecasting\nperformance while simultaneously possessing high interpretive capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16432v1",
    "published_date": "2025-04-23 05:34:49 UTC",
    "updated_date": "2025-04-23 05:34:49 UTC"
  },
  {
    "arxiv_id": "2504.16427v2",
    "title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark",
    "authors": [
      "Hanlei Zhang",
      "Zhuohang Li",
      "Yeshuang Zhu",
      "Hua Xu",
      "Peiwu Wang",
      "Haige Zhu",
      "Jie Zhou",
      "Jinchao Zhang"
    ],
    "abstract": "Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CL",
    "comment": "23 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16427v2",
    "published_date": "2025-04-23 05:25:13 UTC",
    "updated_date": "2025-04-24 07:35:03 UTC"
  },
  {
    "arxiv_id": "2504.16420v1",
    "title": "A Survey of Foundation Model-Powered Recommender Systems: From Feature-Based, Generative to Agentic Paradigms",
    "authors": [
      "Chengkai Huang",
      "Hongtao Huang",
      "Tong Yu",
      "Kaige Xie",
      "Junda Wu",
      "Shuai Zhang",
      "Julian Mcauley",
      "Dietmar Jannach",
      "Lina Yao"
    ],
    "abstract": "Recommender systems (RS) have become essential in filtering information and\npersonalizing content for users. RS techniques have traditionally relied on\nmodeling interactions between users and items as well as the features of\ncontent using models specific to each task. The emergence of foundation models\n(FMs), large scale models trained on vast amounts of data such as GPT, LLaMA\nand CLIP, is reshaping the recommendation paradigm. This survey provides a\ncomprehensive overview of the Foundation Models for Recommender Systems\n(FM4RecSys), covering their integration in three paradigms: (1) Feature-Based\naugmentation of representations, (2) Generative recommendation approaches, and\n(3) Agentic interactive systems. We first review the data foundations of RS,\nfrom traditional explicit or implicit feedback to multimodal content sources.\nWe then introduce FMs and their capabilities for representation learning,\nnatural language understanding, and multi-modal reasoning in RS contexts. The\ncore of the survey discusses how FMs enhance RS under different paradigms.\nAfterward, we examine FM applications in various recommendation tasks. Through\nan analysis of recent research, we highlight key opportunities that have been\nrealized as well as challenges encountered. Finally, we outline open research\ndirections and technical challenges for next-generation FM4RecSys. This survey\nnot only reviews the state-of-the-art methods but also provides a critical\nanalysis of the trade-offs among the feature-based, the generative, and the\nagentic paradigms, outlining key open issues and future research directions.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16420v1",
    "published_date": "2025-04-23 05:02:51 UTC",
    "updated_date": "2025-04-23 05:02:51 UTC"
  },
  {
    "arxiv_id": "2504.16419v2",
    "title": "PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels",
    "authors": [
      "Qi Yang",
      "Weichen Bi",
      "Haiyang Shen",
      "Yaoqi Guo",
      "Yun Ma"
    ],
    "abstract": "Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16419v2",
    "published_date": "2025-04-23 05:01:25 UTC",
    "updated_date": "2025-04-27 06:52:23 UTC"
  },
  {
    "arxiv_id": "2504.16416v1",
    "title": "FeedQUAC: Quick Unobtrusive AI-Generated Commentary",
    "authors": [
      "Tao Long",
      "Kendra Wannamaker",
      "Jo Vermeulen",
      "George Fitzmaurice",
      "Justin Matejka"
    ],
    "abstract": "Design thrives on feedback. However, gathering constant feedback throughout\nthe design process can be labor-intensive and disruptive. We explore how AI can\nbridge this gap by providing effortless, ambient feedback. We introduce\nFeedQUAC, a design companion that delivers real-time AI-generated commentary\nfrom a variety of perspectives through different personas. A design probe study\nwith eight participants highlights how designers can leverage quick yet ambient\nAI feedback to enhance their creative workflows. Participants highlight\nbenefits such as convenience, playfulness, confidence boost, and inspiration\nfrom this lightweight feedback agent, while suggesting additional features,\nlike chat interaction and context curation. We discuss the role of AI feedback,\nits strengths and limitations, and how to integrate it into existing design\nworkflows while balancing user involvement. Our findings also suggest that\nambient interaction is a valuable consideration for both the design and\nevaluation of future creativity support systems.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY",
      "cs.MM"
    ],
    "primary_category": "cs.HC",
    "comment": "20 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.16416v1",
    "published_date": "2025-04-23 04:48:00 UTC",
    "updated_date": "2025-04-23 04:48:00 UTC"
  },
  {
    "arxiv_id": "2504.16404v2",
    "title": "Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection",
    "authors": [
      "Md Fahimuzzman Sohan",
      "A. H. Abdul Hafez",
      "Raid Alzubi"
    ],
    "abstract": "Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG",
      "eess.IV"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16404v2",
    "published_date": "2025-04-23 04:17:41 UTC",
    "updated_date": "2025-05-13 02:22:55 UTC"
  },
  {
    "arxiv_id": "2504.16394v2",
    "title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs",
    "authors": [
      "Fahmida Liza Piya",
      "Rahmatollah Beheshti"
    ],
    "abstract": "Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16394v2",
    "published_date": "2025-04-23 03:42:46 UTC",
    "updated_date": "2025-05-12 14:57:14 UTC"
  },
  {
    "arxiv_id": "2504.16381v4",
    "title": "PINN-MEP: Continuous Neural Representations for Minimum-Energy Path Discovery in Molecular Systems",
    "authors": [
      "Magnus Petersen",
      "Roberto Covino"
    ],
    "abstract": "Characterizing conformational transitions in physical systems remains a\nfundamental challenge in the computational sciences. Traditional sampling\nmethods like molecular dynamics (MD) or MCMC often struggle with the\nhigh-dimensional nature of molecular systems and the high energy barriers of\ntransitions between stable states. While these transitions are rare events in\nsimulation timescales, they often represent the most biologically significant\nprocesses - for example, the conformational change of an ion channel protein\nfrom its closed to open state, which controls cellular ion flow and is crucial\nfor neural signaling. Such transitions in real systems may take milliseconds to\nseconds but could require months or years of continuous simulation to observe\neven once. We present a method that reformulates transition path generation as\na continuous optimization problem solved through physics-informed neural\nnetworks (PINNs) inspired by string methods for minimum-energy path (MEP)\ngeneration. By representing transition paths as implicit neural functions and\nleveraging automatic differentiation with differentiable molecular dynamics\nforce fields, our method enables the efficient discovery of physically\nrealistic transition pathways without requiring expensive path sampling. We\ndemonstrate our method's effectiveness on two proteins, including an explicitly\nhydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300\natoms.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "Update 08.05.2025: Added some intermediate steps in the derivation of\n  the loss to add clarity. Update 28.04.2025: Added citation and reference to\n  just-released work \"Action-Minimization Meets Generative Modeling: Efficient\n  Transition Path Sampling with the Onsager-Machlup Functional\" by Sanjeev Raja\n  et al. and added an appendix section clarifying some loss derivation steps",
    "pdf_url": "http://arxiv.org/pdf/2504.16381v4",
    "published_date": "2025-04-23 03:02:29 UTC",
    "updated_date": "2025-05-08 15:53:07 UTC"
  },
  {
    "arxiv_id": "2504.16378v1",
    "title": "Cyberoception: Finding a Painlessly-Measurable New Sense in the Cyberworld Towards Emotion-Awareness in Computing",
    "authors": [
      "Tadashi Okoshi",
      "Zexiong Gao",
      "Tan Yi Zhen",
      "Takumi Karasawa",
      "Takeshi Miki",
      "Wataru Sasaki",
      "Rajesh K. Balan"
    ],
    "abstract": "In Affective computing, recognizing users' emotions accurately is the basis\nof affective human-computer interaction. Understanding users' interoception\ncontributes to a better understanding of individually different emotional\nabilities, which is essential for achieving inter-individually accurate emotion\nestimation. However, existing interoception measurement methods, such as the\nheart rate discrimination task, have several limitations, including their\ndependence on a well-controlled laboratory environment and precision apparatus,\nmaking monitoring users' interoception challenging. This study aims to\ndetermine other forms of data that can explain users' interoceptive or similar\nstates in their real-world lives and propose a novel hypothetical concept\n\"cyberoception,\" a new sense (1) which has properties similar to interoception\nin terms of the correlation with other emotion-related abilities, and (2) which\ncan be measured only by the sensors embedded inside commodity smartphone\ndevices in users' daily lives. Results from a 10-day-long in-lab/in-the-wild\nhybrid experiment reveal a specific cyberoception type \"Turn On\" (users'\nsubjective sensory perception about the frequency of turning-on behavior on\ntheir smartphones), significantly related to participants' emotional valence.\nWe anticipate that cyberoception to serve as a fundamental building block for\ndeveloping more \"emotion-aware\", user-friendly applications and services.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted by ACM CHI2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16378v1",
    "published_date": "2025-04-23 02:56:55 UTC",
    "updated_date": "2025-04-23 02:56:55 UTC"
  },
  {
    "arxiv_id": "2504.16364v1",
    "title": "CLPSTNet: A Progressive Multi-Scale Convolutional Steganography Model Integrating Curriculum Learning",
    "authors": [
      "Fengchun Liu",
      "Tong Zhang",
      "Chunying Zhang"
    ],
    "abstract": "In recent years, a large number of works have introduced Convolutional Neural\nNetworks (CNNs) into image steganography, which transform traditional\nsteganography methods such as hand-crafted features and prior knowledge design\ninto steganography methods that neural networks autonomically learn information\nembedding. However, due to the inherent complexity of digital images, issues of\ninvisibility and security persist when using CNN models for information\nembedding. In this paper, we propose Curriculum Learning Progressive Steganophy\nNetwork (CLPSTNet). The network consists of multiple progressive multi-scale\nconvolutional modules that integrate Inception structures and dilated\nconvolutions. The module contains multiple branching pathways, starting from a\nsmaller convolutional kernel and dilatation rate, extracting the basic, local\nfeature information from the feature map, and gradually expanding to the\nconvolution with a larger convolutional kernel and dilatation rate for\nperceiving the feature information of a larger receptive field, so as to\nrealize the multi-scale feature extraction from shallow to deep, and from fine\nto coarse, allowing the shallow secret information features to be refined in\ndifferent fusion stages. The experimental results show that the proposed\nCLPSTNet not only has high PSNR , SSIM metrics and decoding accuracy on three\nlarge public datasets, ALASKA2, VOC2012 and ImageNet, but also the\nsteganographic images generated by CLPSTNet have low steganalysis scores.You\ncan find our code at\n\\href{https://github.com/chaos-boops/CLPSTNet}{https://github.com/chaos-boops/CLPSTNet}.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16364v1",
    "published_date": "2025-04-23 02:34:25 UTC",
    "updated_date": "2025-04-23 02:34:25 UTC"
  },
  {
    "arxiv_id": "2504.16357v1",
    "title": "DP2FL: Dual Prompt Personalized Federated Learning in Foundation Models",
    "authors": [
      "Ying Chang",
      "Xiaohu Shi",
      "Xiaohui Zhao",
      "Zhaohuang Chen",
      "Deyin Ma"
    ],
    "abstract": "Personalized federated learning (PFL) has garnered significant attention for\nits ability to address heterogeneous client data distributions while preserving\ndata privacy. However, when local client data is limited, deep learning models\noften suffer from insufficient training, leading to suboptimal performance.\nFoundation models, such as CLIP (Contrastive Language-Image Pretraining),\nexhibit strong feature extraction capabilities and can alleviate this issue by\nfine-tuning on limited local data. Despite their potential, foundation models\nare rarely utilized in federated learning scenarios, and challenges related to\nintegrating new clients remain largely unresolved. To address these challenges,\nwe propose the Dual Prompt Personalized Federated Learning (DP2FL) framework,\nwhich introduces dual prompts and an adaptive aggregation strategy. DP2FL\ncombines global task awareness with local data-driven insights, enabling local\nmodels to achieve effective generalization while remaining adaptable to\nspecific data distributions. Moreover, DP2FL introduces a global model that\nenables prediction on new data sources and seamlessly integrates newly added\nclients without requiring retraining. Experimental results in highly\nheterogeneous environments validate the effectiveness of DP2FL's prompt design\nand aggregation strategy, underscoring the advantages of prediction on novel\ndata sources and demonstrating the seamless integration of new clients into the\nfederated learning framework.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16357v1",
    "published_date": "2025-04-23 02:13:56 UTC",
    "updated_date": "2025-04-23 02:13:56 UTC"
  },
  {
    "arxiv_id": "2504.16353v1",
    "title": "Transformer-Based Extraction of Statutory Definitions from the U.S. Code",
    "authors": [
      "Arpana Hosabettu",
      "Harsh Shah"
    ],
    "abstract": "Automatic extraction of definitions from legal texts is critical for\nenhancing the comprehension and clarity of complex legal corpora such as the\nUnited States Code (U.S.C.). We present an advanced NLP system leveraging\ntransformer-based architectures to automatically extract defined terms, their\ndefinitions, and their scope from the U.S.C. We address the challenges of\nautomatically identifying legal definitions, extracting defined terms, and\ndetermining their scope within this complex corpus of over 200,000 pages of\nfederal statutory law. Building upon previous feature-based machine learning\nmethods, our updated model employs domain-specific transformers (Legal-BERT)\nfine-tuned specifically for statutory texts, significantly improving extraction\naccuracy. Our work implements a multi-stage pipeline that combines document\nstructure analysis with state-of-the-art language models to process legal text\nfrom the XML version of the U.S. Code. Each paragraph is first classified using\na fine-tuned legal domain BERT model to determine if it contains a definition.\nOur system then aggregates related paragraphs into coherent definitional units\nand applies a combination of attention mechanisms and rule-based patterns to\nextract defined terms and their jurisdictional scope. The definition extraction\nsystem is evaluated on multiple titles of the U.S. Code containing thousands of\ndefinitions, demonstrating significant improvements over previous approaches.\nOur best model achieves 96.8% precision and 98.9% recall (98.2% F1-score),\nsubstantially outperforming traditional machine learning classifiers. This work\ncontributes to improving accessibility and understanding of legal information\nwhile establishing a foundation for downstream legal reasoning tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "7 pages, to be published in IEEE AIIoT 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16353v1",
    "published_date": "2025-04-23 02:09:53 UTC",
    "updated_date": "2025-04-23 02:09:53 UTC"
  },
  {
    "arxiv_id": "2504.16352v1",
    "title": "Disentangling and Generating Modalities for Recommendation in Missing Modality Scenarios",
    "authors": [
      "Jiwan Kim",
      "Hongseok Kang",
      "Sein Kim",
      "Kibum Kim",
      "Chanyoung Park"
    ],
    "abstract": "Multi-modal recommender systems (MRSs) have achieved notable success in\nimproving personalization by leveraging diverse modalities such as images,\ntext, and audio. However, two key challenges remain insufficiently addressed:\n(1) Insufficient consideration of missing modality scenarios and (2) the\noverlooking of unique characteristics of modality features. These challenges\nresult in significant performance degradation in realistic situations where\nmodalities are missing. To address these issues, we propose Disentangling and\nGenerating Modality Recommender (DGMRec), a novel framework tailored for\nmissing modality scenarios. DGMRec disentangles modality features into general\nand specific modality features from an information-based perspective, enabling\nricher representations for recommendation. Building on this, it generates\nmissing modality features by integrating aligned features from other modalities\nand leveraging user modality preferences. Extensive experiments show that\nDGMRec consistently outperforms state-of-the-art MRSs in challenging scenarios,\nincluding missing modalities and new item settings as well as diverse missing\nratios and varying levels of missing modalities. Moreover, DGMRec's\ngeneration-based approach enables cross-modal retrieval, a task inapplicable\nfor existing MRSs, highlighting its adaptability and potential for real-world\napplications. Our code is available at https://github.com/ptkjw1997/DGMRec.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "SIGIR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16352v1",
    "published_date": "2025-04-23 02:04:14 UTC",
    "updated_date": "2025-04-23 02:04:14 UTC"
  },
  {
    "arxiv_id": "2504.16350v1",
    "title": "QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate Optimization Algorithm Circuits",
    "authors": [
      "Ilya Tyagin",
      "Marwa H. Farag",
      "Kyle Sherbert",
      "Karunya Shirali",
      "Yuri Alexeev",
      "Ilya Safro"
    ],
    "abstract": "Quantum computing has the potential to improve our ability to solve certain\noptimization problems that are computationally difficult for classical\ncomputers, by offering new algorithmic approaches that may provide speedups\nunder specific conditions. In this work, we introduce QAOA-GPT, a generative\nframework that leverages Generative Pretrained Transformers (GPT) to directly\nsynthesize quantum circuits for solving quadratic unconstrained binary\noptimization problems, and demonstrate it on the MaxCut problem on graphs. To\ndiversify the training circuits and ensure their quality, we have generated a\nsynthetic dataset using the adaptive QAOA approach, a method that incrementally\nbuilds and optimizes problem-specific circuits. The experiments conducted on a\ncurated set of graph instances demonstrate that QAOA-GPT, generates high\nquality quantum circuits for new problem instances unseen in the training as\nwell as successfully parametrizes QAOA. Our results show that using QAOA-GPT to\ngenerate quantum circuits will significantly decrease both the computational\noverhead of classical QAOA and adaptive approaches that often use gradient\nevaluation to generate the circuit and the classical optimization of the\ncircuit parameters. Our work shows that generative AI could be a promising\navenue to generate compact quantum circuits in a scalable way.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16350v1",
    "published_date": "2025-04-23 02:00:36 UTC",
    "updated_date": "2025-04-23 02:00:36 UTC"
  },
  {
    "arxiv_id": "2504.16343v1",
    "title": "Mining Software Repositories for Expert Recommendation",
    "authors": [
      "Chad Marshall",
      "Andrew Barovic",
      "Armin Moin"
    ],
    "abstract": "We propose an automated approach to bug assignment to developers in large\nopen-source software projects. This way, we assist human bug triagers who are\nin charge of finding the best developer with the right level of expertise in a\nparticular area to be assigned to a newly reported issue. Our approach is based\non the history of software development as documented in the issue tracking\nsystems. We deploy BERTopic and techniques from TopicMiner. Our approach works\nbased on the bug reports' features, such as the corresponding products and\ncomponents, as well as their priority and severity levels. We sort developers\nbased on their experience with specific combinations of new reports. The\nevaluation is performed using Top-k accuracy, and the results are compared with\nthe reported results in prior work, namely TopicMiner MTM, BUGZIE, Bug triaging\nvia deep Reinforcement Learning BT-RL, and LDA-SVM. The evaluation data come\nfrom various Eclipse and Mozilla projects, such as JDT, Firefox, and\nThunderbird.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.16343v1",
    "published_date": "2025-04-23 01:41:08 UTC",
    "updated_date": "2025-04-23 01:41:08 UTC"
  }
]