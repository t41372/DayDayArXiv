{
  "date": "2025-04-23",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-04-23 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 模型优化、多模态学习、机器人导航和医疗应用等领域，其中 EduBot 和 MIRAGE 等论文在 LLM 增强教育和检索方面有突破性贡献，知名学者如 Ying Wen 和 Yong Li 参与的作品也值得关注；这些论文展示了 AI 在实际场景中的潜力，同时强调了效率、安全性和泛化能力的提升。\n\n下面，我将挑选并简要讨论部分重要论文，先从 AI 和 LLM 相关主题入手（这些更具话题度），然后快速触及机器人、医疗和推荐系统等领域。其他较基础或理论性较强的论文（如一些数学建模或通用优化方法）将简略掠过，以控制篇幅。\n\n### AI 和 LLM 相关\n- **EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments? (EduBot -- LLMs 是否能解决个性化学习和编程任务？)**  \n  这篇论文由 Yibin Wang 等作者提出，探讨大型语言模型 (LLMs) 在处理复杂编程任务的能力，引入 EduBot 系统，通过递归提示驱动的方法实现个性化代码生成和调试，在算法和机器学习基准上表现出色，强调 LLMs 在教育领域的潜力。\n\n- **MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation (MIRAGE: 一种针对检索增强生成的指标密集基准)**  \n  作者 Chanhee Park 等开发了 MIRAGE 数据集和评估指标，用于评估 RAG 系统（检索增强生成）的鲁棒性，包括噪声敏感性和上下文理解，实验证明其能优化 LLM 配置，提升生成任务的准确性。\n\n- **Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments (利用 LLMs 作为元评判：一种多代理框架用于评估 LLM 判断)**  \n  Yuran Li 等构建了一个多代理框架，使用 LLMs 作为元评判器，通过阈值过滤和协作提升判断准确性，在 JudgeBench 数据集上比单代理基准提升 8.37%，为 LLM 评估提供新视角。\n\n- **Robo-Troj: Attacking LLM-based Task Planners (Robo-Troj: 针对基于 LLM 的任务规划器的攻击)**  \n  这篇论文揭示 LLM 在机器人任务规划中的漏洞，提出多触发后门攻击方法，能在不影响正常性能的情况下激活恶意行为，强调了 LLM 安全性的重要性。\n\n- **The Rise of Small Language Models in Healthcare: A Comprehensive Survey (小型语言模型在医疗领域的兴起：一份全面调查)**  \n  作者 Muskan Garg 等调研了小型语言模型 (SLMs) 在医疗中的应用，包括 NLP 任务和模型优化，强调 SLMs 在隐私和资源受限环境中的优势，提供实验结果支持其潜力。\n\n- **Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference (非线性广义和动态博弈中的同行感知成本估计，用于相互学习和意图推断)**  \n  Seyed Yousef Soltanian 等提出 N-PACE 算法，用于人机交互中的意图推断，通过迭代线性二次逼近提升学习效率，适用于机器人协作场景。\n\n### 机器人和导航\n- **Scalable Permutation-Aware Modeling for Temporal Set Prediction (可扩展的置换感知建模用于时间序列集预测)**  \n  Ashish Ranjan 等开发了一种框架，使用置换等变和不变变换建模时间序列集，减少计算开销，在公共基准上与最先进模型相当或优于后者，适用于高效机器人预测。\n\n- **Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy (AI 驱动的动态 X 射线光谱工作流的演示)**  \n  Ming Du 等展示了一种基于贝叶斯优化的自适应采样方法，仅需 15-20% 的测量点即可重建 XANES 光谱，提高了电池材料和催化剂实验的效率和时间分辨率。\n\n- **A multi-scale vision transformer-based multimodal GeoAI model for mapping Arctic permafrost thaw (用于映射北极永久冻土融化的多尺度视觉 Transformer 多模态 GeoAI 模型)**  \n  Wenwen Li 等提出一个级联 Mask R-CNN 模型，通过多模态融合和预训练策略提升北极冻土滑坡检测精度，在基准上超越现有方法。\n\n### 医疗和科学应用\n- **Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification (神经定理证明：为形式验证生成和结构化证明)**  \n  Balaji Rao 等设计了一个框架，使用 LLM 生成形式证明，支持形式语言和自动定理证明器，在 AWS S3 策略验证中表现出色。\n\n- **Physics-guided and fabrication-aware inverse design of photonic devices using diffusion models (使用扩散模型的物理引导和制造感知光子器件反设计)**  \n  Dongjin Seo 等提出 AdjointDiffusion 框架，将扩散模型与伴随梯度结合，高效设计光子器件，仅需少量模拟就优于传统优化器。\n\n- **AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset (AIMO-2 获胜方案：使用 OpenMathReasoning 数据集构建最先进数学推理模型)**  \n  Iman Khadir 等分享了 AIMO-2 竞赛获胜方法，通过合成数据集和工具集成训练模型，提升数学推理准确性，并开源代码。\n\n其他论文，如那些专注于理论优化或特定基准的（如统计建模、量子计算），虽然有技术贡献，但相对较常规，我这里仅快速提及：例如，\"Distilling semantically aware orders for autoregressive image generation (提炼语义感知顺序用于自回归图像生成)\" 改善了图像生成顺序，但细节较琐碎；\"Democracy of AI Numerical Weather Models (AI 数值天气模型的民主化)\" 探讨了 AI 在天气预报的民主化，但未有重大突破。\n\n总之，今天的论文突显了 AI 在教育、机器人和医疗的创新应用，未来可能推动更高效的模型部署。如果你对特定领域感兴趣，建议优先查看 EduBot 和 MIRAGE 等论文！",
  "papers": [
    {
      "arxiv_id": "2505.05481v1",
      "title": "Structure & Quality: Conceptual and Formal Foundations for the Mind-Body Problem",
      "title_zh": "翻译失败",
      "authors": [
        "Ryan Williams"
      ],
      "abstract": "This paper explores the hard problem of consciousness from a different\nperspective. Instead of drawing distinctions between the physical and the\nmental, an exploration of a more foundational relationship is examined: the\nrelationship between structure and quality.\n  Information-theoretic measures are developed to quantify the mutual\ndeterminability between structure and quality, including a novel Q-S space for\nanalyzing fidelity between the two domains. This novel space naturally points\ntoward a five-fold categorization of possible relationships between structural\nand qualitative properties, illustrating each through conceptual and formal\nmodels.\n  The ontological implications of each category are examined, shedding light on\ndebates around functionalism, emergentism, idealism, panpsychism, and neutral\nmonism.\n  This new line of inquiry has established a framework for deriving theoretical\nconstraints on qualitative systems undergoing evolution that is explored in my\ncompanion paper, Qualia & Natural Selection.",
      "tldr_zh": "本论文从结构（structure）和质量（quality）的关系入手，探讨意识的难题（hard problem of consciousness），而非传统的物理与心理区分。作者开发了信息论措施来量化两者之间的相互决定性，并引入了新型Q-S space，用于分析其保真度，从而划分出五种可能的结构与质量关系的分类，并通过概念和形式模型进行说明。这些分类的本体论含义被深入考察，与functionalism、emergentism、idealism、panpsychism和neutral monism等辩论相关，并为定性系统在演化中的理论约束建立了新框架，如在伴随论文Qualia & Natural Selection中进一步探讨。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.05481v1",
      "published_date": "2025-04-23 23:49:40 UTC",
      "updated_date": "2025-04-23 23:49:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:49:56.723798"
    },
    {
      "arxiv_id": "2504.17824v1",
      "title": "EduBot -- Can LLMs Solve Personalized Learning and Programming Assignments?",
      "title_zh": "EduBot -- LLMs 是否能解决个性化学习和编程作业？",
      "authors": [
        "Yibin Wang",
        "Jiaxi Xie",
        "Lakshminarayanan Subramanian"
      ],
      "abstract": "The prevalence of Large Language Models (LLMs) is revolutionizing the process\nof writing code. General and code LLMs have shown impressive performance in\ngenerating standalone functions and code-completion tasks with one-shot\nqueries. However, the ability to solve comprehensive programming tasks with\nrecursive requests and bug fixes remains questionable. In this paper, we\npropose EduBot, an intelligent automated assistant system that combines\nconceptual knowledge teaching, end-to-end code development, personalized\nprogramming through recursive prompt-driven methods, and debugging with limited\nhuman interventions powered by LLMs. We show that EduBot can solve complicated\nprogramming tasks consisting of sub-tasks with increasing difficulties ranging\nfrom conceptual to coding questions by recursive automatic prompt-driven\nsystems without finetuning on LLMs themselves. To further evaluate EduBot's\nperformance, we design and conduct a benchmark suite consisting of 20 scenarios\nin algorithms, machine learning, and real-world problems. The result shows that\nEduBot can complete most scenarios in less than 20 minutes. Based on the\nbenchmark suites, we perform a comparative study to take different LLMs as the\nbackbone and to verify EduBot's compatibility and robustness across LLMs with\nvarying capabilities. We believe that EduBot is an exploratory approach to\nexplore the potential of pre-trained LLMs in multi-step reasoning and code\ngeneration for solving personalized assignments with knowledge learning and\ncode generation.",
      "tldr_zh": "该论文提出 EduBot，一种基于 Large Language Models (LLMs) 的智能自动化助手系统，用于解决个性化学习和编程任务，包括概念知识教学、端到端代码开发、递归提示驱动的个性化编程以及调试，以最小化人类干预。EduBot 通过递归自动提示驱动方法处理复杂任务（如算法、机器学习和真实世界问题），无需对 LLMs 进行微调，并在包含 20 个场景的基准测试中显示出高效性，大多数场景可在 20 分钟内完成。研究还比较了不同 LLMs 作为后端时的兼容性和鲁棒性，结果验证了 EduBot 在多步推理和代码生成方面的潜力，为预训练 LLMs 在教育应用中提供了探索性方法。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Published at AAAI 2025 AI4EDU Workshop",
      "pdf_url": "http://arxiv.org/pdf/2504.17824v1",
      "published_date": "2025-04-23 23:25:13 UTC",
      "updated_date": "2025-04-23 23:25:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:50:11.169300"
    },
    {
      "arxiv_id": "2504.17140v1",
      "title": "Scalable Permutation-Aware Modeling for Temporal Set Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Ashish Ranjan",
        "Ayush Agarwal",
        "Shalin Barot",
        "Sushant Kumar"
      ],
      "abstract": "Temporal set prediction involves forecasting the elements that will appear in\nthe next set, given a sequence of prior sets, each containing a variable number\nof elements. Existing methods often rely on intricate architectures with\nsubstantial computational overhead, which hampers their scalability. In this\nwork, we introduce a novel and scalable framework that leverages\npermutation-equivariant and permutation-invariant transformations to\nefficiently model set dynamics. Our approach significantly reduces both\ntraining and inference time while maintaining competitive performance.\nExtensive experiments on multiple public benchmarks show that our method\nachieves results on par with or superior to state-of-the-art models across\nseveral evaluation metrics. These results underscore the effectiveness of our\nmodel in enabling efficient and scalable temporal set prediction.",
      "tldr_zh": "这篇论文针对 Temporal Set Prediction 问题，提出了一种可扩展的建模框架，该框架利用 permutation-equivariant 和 permutation-invariant 变换来高效处理集合动态，从而减少训练和推理时间。相比现有依赖复杂架构的方法，该方法显著降低了计算开销，同时保持了竞争性能。实验在多个公共基准上表明，该框架的性能与或优于最先进模型，证明了其在高效可扩展时间序列集合预测中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17140v1",
      "published_date": "2025-04-23 23:14:35 UTC",
      "updated_date": "2025-04-23 23:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:50:20.675959"
    },
    {
      "arxiv_id": "2504.17137v1",
      "title": "MIRAGE: A Metric-Intensive Benchmark for Retrieval-Augmented Generation Evaluation",
      "title_zh": "MIR",
      "authors": [
        "Chanhee Park",
        "Hyeonseok Moon",
        "Chanjun Park",
        "Heuiseok Lim"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has gained prominence as an effective\nmethod for enhancing the generative capabilities of Large Language Models\n(LLMs) through the incorporation of external knowledge. However, the evaluation\nof RAG systems remains a challenge, due to the intricate interplay between\nretrieval and generation components. This limitation has resulted in a scarcity\nof benchmarks that facilitate a detailed, component-specific assessment. In\nthis work, we present MIRAGE, a Question Answering dataset specifically\ndesigned for RAG evaluation. MIRAGE consists of 7,560 curated instances mapped\nto a retrieval pool of 37,800 entries, enabling an efficient and precise\nevaluation of both retrieval and generation tasks. We also introduce novel\nevaluation metrics aimed at measuring RAG adaptability, encompassing dimensions\nsuch as noise vulnerability, context acceptability, context insensitivity, and\ncontext misinterpretation. Through comprehensive experiments across various\nretriever-LLM configurations, we provide new insights into the optimal\nalignment of model pairs and the nuanced dynamics within RAG systems. The\ndataset and evaluation code are publicly available, allowing for seamless\nintegration and customization in diverse research settings\\footnote{The MIRAGE\ncode and data are available at https://github.com/nlpai-lab/MIRAGE.",
      "tldr_zh": "本文提出 MIRAGE，这是一个针对检索增强生成 (RAG) 系统的指标密集型基准数据集，用于评估大型语言模型 (LLMs) 中检索和生成组件的互动。MIRAGE 包含 7,560 个精心策划的问答实例和 37,800 个检索池，支持对检索和生成任务的精确评估。研究者引入了新型评估指标，包括噪声脆弱性、上下文可接受性、上下文不敏感性和上下文误解，以衡量 RAG 的适应性。通过各种检索器-LLM 配置的实验，论文揭示了模型对齐的最佳策略和 RAG 系统内部的细微动态，并公开了数据集和代码以便进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2504.17137v1",
      "published_date": "2025-04-23 23:05:46 UTC",
      "updated_date": "2025-04-23 23:05:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:50:32.911022"
    },
    {
      "arxiv_id": "2504.17823v1",
      "title": "The Cloud Weaving Model for AI development",
      "title_zh": "翻译失败",
      "authors": [
        "Darcy Kim",
        "Aida Kalender",
        "Sennay Ghebreab",
        "Giovanni Sileno"
      ],
      "abstract": "While analysing challenges in pilot projects developing AI with marginalized\ncommunities, we found it difficult to express them within commonly used\nparadigms. We therefore constructed an alternative conceptual framework to\nground AI development in the social fabric -- the Cloud Weaving Model --\ninspired (amongst others) by indigenous knowledge, motifs from nature, and\nEastern traditions. This paper introduces and elaborates on the fundamental\nelements of the model (clouds, spiders, threads, spiderwebs, and weather) and\ntheir interpretation in an AI context. The framework is then applied to\ncomprehend patterns observed in co-creation pilots approaching marginalized\ncommunities, highlighting neglected yet relevant dimensions for responsible AI\ndevelopment.",
      "tldr_zh": "这篇论文提出 Cloud Weaving Model 作为 AI 开发的替代框架，旨在解决与边缘化社区合作时现有范式难以表达的挑战。该模型受原住民知识、自然主题和东方传统启发，构建了核心元素如 clouds、spiders、threads、spiderwebs 和 weather，并在 AI 上下文中进行解释。通过应用该框架分析合作试点项目，论文揭示了负责 AI 开发中被忽略的重要维度，促进更具社会性的 AI 实践。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "presented at alt.CHI 2025, Yokohama",
      "pdf_url": "http://arxiv.org/pdf/2504.17823v1",
      "published_date": "2025-04-23 22:48:13 UTC",
      "updated_date": "2025-04-23 22:48:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:50:44.975774"
    },
    {
      "arxiv_id": "2504.17129v1",
      "title": "Peer-Aware Cost Estimation in Nonlinear General-Sum Dynamic Games for Mutual Learning and Intent Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Yousef Soltanian",
        "Wenlong Zhang"
      ],
      "abstract": "Human-robot interactions can be modeled as incomplete-information general-sum\ndynamic games since the objective functions of both agents are not explicitly\nknown to each other. However, solving for equilibrium policies for such games\npresents a major challenge, especially if the games involve nonlinear\nunderlying dynamics. To simplify the problem, existing work often assumes that\none agent is an expert with complete information about its peer, which can lead\nto biased estimates and failures in coordination. To address this challenge, we\npropose a nonlinear peer-aware cost estimation (N-PACE) algorithm for\ngeneral-sum dynamic games. In N-PACE, using iterative linear quadratic (LQ)\napproximation of the nonlinear general-sum game, each agent explicitly models\nthe learning dynamics of its peer agent while inferring their objective\nfunctions, leading to unbiased fast learning in inferring the unknown objective\nfunction of the peer agent, which is critical for task completion and safety\nassurance. Additionally, we demonstrate how N-PACE enables \\textbf{intent\ncommunication} in such multi-agent systems by explicitly modeling the peer's\nlearning dynamics.",
      "tldr_zh": "该论文探讨了人类-机器人互动中不完全信息的一般和动态游戏（Nonlinear General-Sum Dynamic Games），其中代理的目标函数相互未知，导致协调挑战和偏差问题。为解决此问题，研究提出了一种非线性同伴感知成本估计算法（N-PACE），该算法通过迭代线性二次（LQ）逼近来显式建模对手的学习动态，同时推断其目标函数，实现快速、无偏差的学习。N-PACE 不仅提升了任务完成效率和安全保障，还实现了意图通信（Intent Communication），使多代理系统能够更好地协作和推断彼此意图。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.GT",
        "cs.RO",
        "cs.SY",
        "93C41, 49N70, 49N90, 91A27"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17129v1",
      "published_date": "2025-04-23 22:47:20 UTC",
      "updated_date": "2025-04-23 22:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:50:56.679306"
    },
    {
      "arxiv_id": "2504.17124v1",
      "title": "Demonstration of an AI-driven workflow for dynamic x-ray spectroscopy",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Du",
        "Mark Wolfman",
        "Chengjun Sun",
        "Shelly D. Kelly",
        "Mathew J. Cherukara"
      ],
      "abstract": "X-ray absorption near edge structure (XANES) spectroscopy is a powerful\ntechnique for characterizing the chemical state and symmetry of individual\nelements within materials, but requires collecting data at many energy points\nwhich can be time-consuming. While adaptive sampling methods exist for\nefficiently collecting spectroscopic data, they often lack domain-specific\nknowledge about XANES spectra structure. Here we demonstrate a\nknowledge-injected Bayesian optimization approach for adaptive XANES data\ncollection that incorporates understanding of spectral features like absorption\nedges and pre-edge peaks. We show this method accurately reconstructs the\nabsorption edge of XANES spectra using only 15-20% of the measurement points\ntypically needed for conventional sampling, while maintaining the ability to\ndetermine the x-ray energy of the sharp peak after absorption edge with errors\nless than 0.03 eV, the absorption edge with errors less than 0.1 eV; and\noverall root-mean-square errors less than 0.005 compared to compared to\ntraditionally sampled spectra. Our experiments on battery materials and\ncatalysts demonstrate the method's effectiveness for both static and dynamic\nXANES measurements, improving data collection efficiency and enabling better\ntime resolution for tracking chemical changes. This approach advances the\ndegree of automation in XANES experiments reducing the common errors of under-\nor over-sampling points in near the absorption edge and enabling dynamic\nexperiments that require high temporal resolution or limited measurement time.",
      "tldr_zh": "本研究展示了一种基于人工智能的流程，用于动态 X-ray 光谱学，针对 X-ray absorption near edge structure (XANES) 光谱的采样效率问题。方法采用注入知识的 Bayesian optimization 技术，结合对光谱特征（如吸收边和预边峰）的理解，实现自适应数据收集，仅需传统方法的 15-20% 测量点即可准确重建光谱。实验结果显示，该方法在电池材料和催化剂上表现突出，错误率包括尖峰能量小于 0.03 eV、吸收边小于 0.1 eV，以及整体 root-mean-square errors (RMSE) 小于 0.005，提升了数据收集效率并支持高时间分辨率的动态化学变化跟踪。总的来说，此方法提高了 XANES 实验的自动化水平，减少了采样点过度或不足的错误。",
      "categories": [
        "physics.app-ph",
        "cs.AI",
        "cs.CE",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "physics.app-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17124v1",
      "published_date": "2025-04-23 22:32:42 UTC",
      "updated_date": "2025-04-23 22:32:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:51:08.917827"
    },
    {
      "arxiv_id": "2504.17822v1",
      "title": "A multi-scale vision transformer-based multimodal GeoAI model for mapping Arctic permafrost thaw",
      "title_zh": "翻译失败",
      "authors": [
        "Wenwen Li",
        "Chia-Yu Hsu",
        "Sizhe Wang",
        "Zhining Gu",
        "Yili Yang",
        "Brendan M. Rogers",
        "Anna Liljedahl"
      ],
      "abstract": "Retrogressive Thaw Slumps (RTS) in Arctic regions are distinct permafrost\nlandforms with significant environmental impacts. Mapping these RTS is crucial\nbecause their appearance serves as a clear indication of permafrost thaw.\nHowever, their small scale compared to other landform features, vague\nboundaries, and spatiotemporal variation pose significant challenges for\naccurate detection. In this paper, we employed a state-of-the-art deep learning\nmodel, the Cascade Mask R-CNN with a multi-scale vision transformer-based\nbackbone, to delineate RTS features across the Arctic. Two new strategies were\nintroduced to optimize multimodal learning and enhance the model's predictive\nperformance: (1) a feature-level, residual cross-modality attention fusion\nstrategy, which effectively integrates feature maps from multiple modalities to\ncapture complementary information and improve the model's ability to understand\ncomplex patterns and relationships within the data; (2) pre-trained unimodal\nlearning followed by multimodal fine-tuning to alleviate high computing demand\nwhile achieving strong model performance. Experimental results demonstrated\nthat our approach outperformed existing models adopting data-level fusion,\nfeature-level convolutional fusion, and various attention fusion strategies,\nproviding valuable insights into the efficient utilization of multimodal data\nfor RTS mapping. This research contributes to our understanding of permafrost\nlandforms and their environmental implications.",
      "tldr_zh": "该研究针对北极永久冻土融化的 Retrogressive Thaw Slumps (RTS) 地貌特征的映射问题，提出了一种基于多尺度视觉变压器的多模态 GeoAI 模型，利用 Cascade Mask R-CNN 作为主框架来应对其小规模、边界模糊和时空变异带来的挑战。模型引入了两个新策略：特征级别的残差跨模态注意力融合，以有效整合多模态特征并捕捉复杂数据模式；以及预训练单模态学习后进行多模态微调，以降低计算需求并提升性能。实验结果显示，该方法优于现有数据级融合、特征级卷积融合和其他注意力策略的基准模型，为理解永久冻土地貌及其环境影响提供了宝贵洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17822v1",
      "published_date": "2025-04-23 22:18:10 UTC",
      "updated_date": "2025-04-23 22:18:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:51:21.840108"
    },
    {
      "arxiv_id": "2504.17122v1",
      "title": "Physiological neural representation for personalised tracer kinetic parameter estimation from dynamic PET",
      "title_zh": "翻译失败",
      "authors": [
        "Kartikay Tehlan",
        "Thomas Wendler"
      ],
      "abstract": "Dynamic positron emission tomography (PET) with [$^{18}$F]FDG enables\nnon-invasive quantification of glucose metabolism through kinetic analysis,\noften modelled by the two-tissue compartment model (TCKM). However, voxel-wise\nkinetic parameter estimation using conventional methods is computationally\nintensive and limited by spatial resolution. Deep neural networks (DNNs) offer\nan alternative but require large training datasets and significant\ncomputational resources. To address these limitations, we propose a\nphysiological neural representation based on implicit neural representations\n(INRs) for personalized kinetic parameter estimation. INRs, which learn\ncontinuous functions, allow for efficient, high-resolution parametric imaging\nwith reduced data requirements. Our method also integrates anatomical priors\nfrom a 3D CT foundation model to enhance robustness and precision in kinetic\nmodelling. We evaluate our approach on an [$^{18}$F]FDG dynamic PET/CT dataset\nand compare it to state-of-the-art DNNs. Results demonstrate superior spatial\nresolution, lower mean-squared error, and improved anatomical consistency,\nparticularly in tumour and highly vascularized regions. Our findings highlight\nthe potential of INRs for personalized, data-efficient tracer kinetic\nmodelling, enabling applications in tumour characterization, segmentation, and\nprognostic assessment.",
      "tldr_zh": "这篇论文提出了一种基于隐式神经表示 (INRs) 的生理神经表示方法，用于从动态 PET 图像中进行个性化的示踪剂动力学参数估计，旨在解决传统 two-tissue compartment model (TCKM) 计算密集和空间分辨率有限的问题，以及 Deep neural networks (DNNs) 对大量数据和计算资源的依赖。方法通过学习连续函数实现高效、高分辨率的参数成像，并整合 3D CT 基础模型的解剖先验来提升鲁棒性和精确性。在 [$^{18}$F]FDG 动态 PET/CT 数据集上实验表明，该方法比现有 DNNs 具有更低的均方误差、更高的空间分辨率，并在肿瘤和高血管化区域表现出更好的解剖一致性。该研究突显了 INRs 在数据高效的示踪剂动力学建模中的潜力，支持肿瘤特征化、分割和预后评估的应用。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "The code is available at: https://github.com/tkartikay/PhysNRPET",
      "pdf_url": "http://arxiv.org/pdf/2504.17122v1",
      "published_date": "2025-04-23 22:12:04 UTC",
      "updated_date": "2025-04-23 22:12:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:51:35.109236"
    },
    {
      "arxiv_id": "2504.17119v2",
      "title": "The Rise of Small Language Models in Healthcare: A Comprehensive Survey",
      "title_zh": "小语言模型在医疗保健领域的兴起：一份全面调查",
      "authors": [
        "Muskan Garg",
        "Shaina Raza",
        "Shebuti Rayana",
        "Xingyi Liu",
        "Sunghwan Sohn"
      ],
      "abstract": "Despite substantial progress in healthcare applications driven by large\nlanguage models (LLMs), growing concerns around data privacy, and limited\nresources; the small language models (SLMs) offer a scalable and clinically\nviable solution for efficient performance in resource-constrained environments\nfor next-generation healthcare informatics. Our comprehensive survey presents a\ntaxonomic framework to identify and categorize them for healthcare\nprofessionals and informaticians. The timeline of healthcare SLM contributions\nestablishes a foundational framework for analyzing models across three\ndimensions: NLP tasks, stakeholder roles, and the continuum of care. We present\na taxonomic framework to identify the architectural foundations for building\nmodels from scratch; adapting SLMs to clinical precision through prompting,\ninstruction fine-tuning, and reasoning; and accessibility and sustainability\nthrough compression techniques. Our primary objective is to offer a\ncomprehensive survey for healthcare professionals, introducing recent\ninnovations in model optimization and equipping them with curated resources to\nsupport future research and development in the field. Aiming to showcase the\ngroundbreaking advancements in SLMs for healthcare, we present a comprehensive\ncompilation of experimental results across widely studied NLP tasks in\nhealthcare to highlight the transformative potential of SLMs in healthcare. The\nupdated repository is available at Github",
      "tldr_zh": "这篇论文对Small Language Models (SLMs) 在医疗领域的兴起进行了全面调查，强调其在数据隐私和资源限制环境下比Large Language Models (LLMs) 更具可扩展性和临床实用性。论文建立了分类框架，包括SLMs 在NLP任务、利益相关者角色和护理连续体中的应用，以及从头构建模型、通过提示和微调实现临床适应、以及利用压缩技术提升可访问性和可持续性。最终，论文汇集了SLMs 在医疗NLP任务的实验结果，展示了其变革潜力，并提供GitHub 仓库作为资源，支持未来研究和发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "35 pages, 7 tables, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.17119v2",
      "published_date": "2025-04-23 22:02:25 UTC",
      "updated_date": "2025-04-25 13:42:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:51:46.577399"
    },
    {
      "arxiv_id": "2504.17114v1",
      "title": "Anatomy-constrained modelling of image-derived input functions in dynamic PET using multi-organ segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Valentin Langer",
        "Kartikay Tehlan",
        "Thomas Wendler"
      ],
      "abstract": "Accurate kinetic analysis of [$^{18}$F]FDG distribution in dynamic positron\nemission tomography (PET) requires anatomically constrained modelling of\nimage-derived input functions (IDIFs). Traditionally, IDIFs are obtained from\nthe aorta, neglecting anatomical variations and complex vascular contributions.\nThis study proposes a multi-organ segmentation-based approach that integrates\nIDIFs from the aorta, portal vein, pulmonary artery, and ureters. Using\nhigh-resolution CT segmentations of the liver, lungs, kidneys, and bladder, we\nincorporate organ-specific blood supply sources to improve kinetic modelling.\nOur method was evaluated on dynamic [$^{18}$F]FDG PET data from nine patients,\nresulting in a mean squared error (MSE) reduction of $13.39\\%$ for the liver\nand $10.42\\%$ for the lungs. These initial results highlight the potential of\nmultiple IDIFs in improving anatomical modelling and fully leveraging dynamic\nPET imaging. This approach could facilitate the integration of tracer kinetic\nmodelling into clinical routine.",
      "tldr_zh": "本研究针对动态PET中[18F]FDG分布的动力学分析，提出了一种基于多器官分割的解剖约束建模方法，以优化图像衍生输入函数（IDIFs）。该方法整合了来自主动脉、门静脉、肺动脉和输尿管等多来源的IDIFs，并利用高分辨率CT分割肝脏、肺部、肾脏和膀胱等器官，以纳入器官特定的血液供应贡献。实验在九名患者的动态PET数据上验证，结果显示肝脏的均方误差（MSE）减少13.39%，肺部减少10.42%，这为改善解剖建模和将示踪剂动力学建模融入临床常规提供了重要潜力。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "The code is available under\n  https://github.com/tinolan/curve_fit_multi_idif",
      "pdf_url": "http://arxiv.org/pdf/2504.17114v1",
      "published_date": "2025-04-23 21:47:05 UTC",
      "updated_date": "2025-04-23 21:47:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:52:02.142124"
    },
    {
      "arxiv_id": "2504.17087v1",
      "title": "Leveraging LLMs as Meta-Judges: A Multi-Agent Framework for Evaluating LLM Judgments",
      "title_zh": "翻译失败",
      "authors": [
        "Yuran Li",
        "Jama Hussein Mohamud",
        "Chongren Sun",
        "Di Wu",
        "Benoit Boulet"
      ],
      "abstract": "Large language models (LLMs) are being widely applied across various fields,\nbut as tasks become more complex, evaluating their responses is increasingly\nchallenging. Compared to human evaluators, the use of LLMs to support\nperformance evaluation offers a more efficient alternative. However, most\nstudies focus mainly on aligning LLMs' judgments with human preferences,\noverlooking the existence of biases and mistakes in human judgment.\nFurthermore, how to select suitable LLM judgments given multiple potential LLM\nresponses remains underexplored. To address these two aforementioned issues, we\npropose a three-stage meta-judge selection pipeline: 1) developing a\ncomprehensive rubric with GPT-4 and human experts, 2) using three advanced LLM\nagents to score judgments, and 3) applying a threshold to filter out\nlow-scoring judgments. Compared to methods using a single LLM as both judge and\nmeta-judge, our pipeline introduces multi-agent collaboration and a more\ncomprehensive rubric. Experimental results on the JudgeBench dataset show about\n15.55\\% improvement compared to raw judgments and about 8.37\\% improvement over\nthe single-agent baseline. Our work demonstrates the potential of LLMs as\nmeta-judges and lays the foundation for future research on constructing\npreference datasets for LLM-as-a-judge reinforcement learning.",
      "tldr_zh": "该研究提出了一种多代理框架，利用 LLMs 作为元判断（meta-judges）来评估 LLM 判断的准确性，解决了现有方法忽略人类偏见和多响应选择的问题。框架包括三阶段管道：首先与 GPT-4 和人类专家开发全面的评分标准（rubric）；其次，使用三个高级 LLM 代理进行评分；最后，通过阈值过滤低分判断，以实现多代理协作。在 JudgeBench 数据集上的实验显示，该方法比原始判断提高了约15.55%，并比单代理基线提升了约8.37%，为构建 LLM-as-a-judge 强化学习的偏好数据集提供了基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "12 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.17087v1",
      "published_date": "2025-04-23 20:32:12 UTC",
      "updated_date": "2025-04-23 20:32:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:52:12.205685"
    },
    {
      "arxiv_id": "2504.17077v1",
      "title": "Physics-guided and fabrication-aware inverse design of photonic devices using diffusion models",
      "title_zh": "物理引导且制造感知的光子器件逆设计，使用扩散模型",
      "authors": [
        "Dongjin Seo",
        "Soobin Um",
        "Sangbin Lee",
        "Jong Chul Ye",
        "Haejun Chung"
      ],
      "abstract": "Designing free-form photonic devices is fundamentally challenging due to the\nvast number of possible geometries and the complex requirements of fabrication\nconstraints. Traditional inverse-design approaches--whether driven by human\nintuition, global optimization, or adjoint-based gradient methods--often\ninvolve intricate binarization and filtering steps, while recent deep learning\nstrategies demand prohibitively large numbers of simulations (10^5 to 10^6). To\novercome these limitations, we present AdjointDiffusion, a physics-guided\nframework that integrates adjoint sensitivity gradients into the sampling\nprocess of diffusion models. AdjointDiffusion begins by training a diffusion\nnetwork on a synthetic, fabrication-aware dataset of binary masks. During\ninference, we compute the adjoint gradient of a candidate structure and inject\nthis physics-based guidance at each denoising step, steering the generative\nprocess toward high figure-of-merit (FoM) solutions without additional\npost-processing. We demonstrate our method on two canonical photonic design\nproblems--a bent waveguide and a CMOS image sensor color router--and show that\nour method consistently outperforms state-of-the-art nonlinear optimizers (such\nas MMA and SLSQP) in both efficiency and manufacturability, while using orders\nof magnitude fewer simulations (approximately 2 x 10^2) than pure deep learning\napproaches (approximately 10^5 to 10^6). By eliminating complex binarization\nschedules and minimizing simulation overhead, AdjointDiffusion offers a\nstreamlined, simulation-efficient, and fabrication-aware pipeline for\nnext-generation photonic device design. Our open-source implementation is\navailable at https://github.com/dongjin-seo2020/AdjointDiffusion.",
      "tldr_zh": "本论文提出了一种名为 AdjointDiffusion 的物理指导框架，用于光子设备的逆向设计，该框架将伴随敏感性梯度（adjoint sensitivity gradients）整合到扩散模型（diffusion models）的采样过程中，以应对传统方法在几何复杂性和制造约束方面的挑战。方法首先在合成且考虑制造约束的二值掩码数据集上训练扩散网络，然后在推理阶段通过每个去噪步骤注入物理梯度，引导生成高 figure-of-merit (FoM) 解决方案，而无需额外的后处理。实验结果显示，该框架在弯曲波导和 CMOS 图像传感器颜色路由器等典型问题上，比非线性优化器（如 MMA 和 SLSQP）在效率和可制造性上更具优势，仅需约 200 次模拟，比纯深度学习方法减少了几个数量级（从 10^5 到 10^6）。这项工作提供了一个简化、高效且制造感知的设计管道，并开源实现于 GitHub。",
      "categories": [
        "physics.optics",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "physics.optics",
      "comment": "25 pages, 7 Figures",
      "pdf_url": "http://arxiv.org/pdf/2504.17077v1",
      "published_date": "2025-04-23 19:54:33 UTC",
      "updated_date": "2025-04-23 19:54:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:52:26.130604"
    },
    {
      "arxiv_id": "2504.17070v1",
      "title": "Robo-Troj: Attacking LLM-based Task Planners",
      "title_zh": "翻译失败",
      "authors": [
        "Mohaiminul Al Nahian",
        "Zainab Altaweel",
        "David Reitano",
        "Sabbir Ahmed",
        "Saumitra Lohokare",
        "Shiqi Zhang",
        "Adnan Siraj Rakin"
      ],
      "abstract": "Robots need task planning methods to achieve goals that require more than\nindividual actions. Recently, large language models (LLMs) have demonstrated\nimpressive performance in task planning. LLMs can generate a step-by-step\nsolution using a description of actions and the goal. Despite the successes in\nLLM-based task planning, there is limited research studying the security\naspects of those systems. In this paper, we develop Robo-Troj, the first\nmulti-trigger backdoor attack for LLM-based task planners, which is the main\ncontribution of this work. As a multi-trigger attack, Robo-Troj is trained to\naccommodate the diversity of robot application domains. For instance, one can\nuse unique trigger words, e.g., \"herical\", to activate a specific malicious\nbehavior, e.g., cutting hand on a kitchen robot. In addition, we develop an\noptimization method for selecting the trigger words that are most effective.\nThrough demonstrating the vulnerability of LLM-based planners, we aim to\npromote the development of secured robot systems.",
      "tldr_zh": "本论文探讨了基于大型语言模型(LLM)的任务规划器在机器人应用中的安全漏洞，开发了Robo-Troj，这是首个多触发后门攻击框架。Robo-Troj通过训练LLM来响应特定触发词（如\"erical\"）激活恶意行为，例如在厨房机器人上执行有害动作，同时引入优化方法来选择最有效的触发词。实验结果证明了这种攻击的有效性，旨在揭示LLM-based任务规划器的风险并促进更安全的机器人系统发展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17070v1",
      "published_date": "2025-04-23 19:39:16 UTC",
      "updated_date": "2025-04-23 19:39:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:52:35.300765"
    },
    {
      "arxiv_id": "2504.17069v1",
      "title": "Distilling semantically aware orders for autoregressive image generation",
      "title_zh": "翻译失败",
      "authors": [
        "Rishav Pramanik",
        "Antoine Poupon",
        "Juan A. Rodriguez",
        "Masih Aminbeidokhti",
        "David Vazquez",
        "Christopher Pal",
        "Zhaozheng Yin",
        "Marco Pedersoli"
      ],
      "abstract": "Autoregressive patch-based image generation has recently shown competitive\nresults in terms of image quality and scalability. It can also be easily\nintegrated and scaled within Vision-Language models. Nevertheless,\nautoregressive models require a defined order for patch generation. While a\nnatural order based on the dictation of the words makes sense for text\ngeneration, there is no inherent generation order that exists for image\ngeneration. Traditionally, a raster-scan order (from top-left to bottom-right)\nguides autoregressive image generation models. In this paper, we argue that\nthis order is suboptimal, as it fails to respect the causality of the image\ncontent: for instance, when conditioned on a visual description of a sunset, an\nautoregressive model may generate clouds before the sun, even though the color\nof clouds should depend on the color of the sun and not the inverse. In this\nwork, we show that first by training a model to generate patches in\nany-given-order, we can infer both the content and the location (order) of each\npatch during generation. Secondly, we use these extracted orders to finetune\nthe any-given-order model to produce better-quality images. Through our\nexperiments, we show on two datasets that this new generation method produces\nbetter images than the traditional raster-scan approach, with similar training\ncosts and no extra annotations.",
      "tldr_zh": "本文提出了一种语义感知顺序蒸馏方法，用于提升 autoregressive 图像生成模型的性能，解决传统 raster-scan 顺序（从左上到右下）忽略图像内容因果关系的问题。该方法首先训练一个 any-given-order 模型，使其能按任意顺序生成补丁，并从中推断每个补丁的内容和位置；随后，使用这些提取的顺序对模型进行微调，以生成更高质量的图像。实验在两个数据集上显示，该方法比传统方法产生更好的图像，训练成本相似，且无需额外标注。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17069v1",
      "published_date": "2025-04-23 19:33:58 UTC",
      "updated_date": "2025-04-23 19:33:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:52:47.846109"
    },
    {
      "arxiv_id": "2504.17058v3",
      "title": "Statistical Guarantees in Synthetic Data through Conformal Adversarial Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Rahul Vishwakarma",
        "Shrey Dharmendra Modi",
        "Vishwanath Seshagiri"
      ],
      "abstract": "The generation of high-quality synthetic data presents significant challenges\nin machine learning research, particularly regarding statistical fidelity and\nuncertainty quantification. Existing generative models produce compelling\nsynthetic samples but lack rigorous statistical guarantees about their relation\nto the underlying data distribution, limiting their applicability in critical\ndomains requiring robust error bounds. We address this fundamental limitation\nby presenting a novel framework that incorporates conformal prediction\nmethodologies into Generative Adversarial Networks (GANs). By integrating\nmultiple conformal prediction paradigms including Inductive Conformal\nPrediction (ICP), Mondrian Conformal Prediction, Cross-Conformal Prediction,\nand Venn-Abers Predictors, we establish distribution-free uncertainty\nquantification in generated samples. This approach, termed Conformalized GAN\n(cGAN), demonstrates enhanced calibration properties while maintaining the\ngenerative power of traditional GANs, producing synthetic data with provable\nstatistical guarantees. We provide rigorous mathematical proofs establishing\nfinite-sample validity guarantees and asymptotic efficiency properties,\nenabling the reliable application of synthetic data in high-stakes domains\nincluding healthcare, finance, and autonomous systems.",
      "tldr_zh": "这篇论文针对合成数据生成中的统计保真度和不确定性量化挑战，提出了一种新框架，将 Conformal Prediction 方法融入 Generative Adversarial Networks (GANs)。该框架名为 Conformalized GAN (cGAN)，整合了 Inductive Conformal Prediction (ICP)、Mondrian Conformal Prediction、Cross-Conformal Prediction 和 Venn-Abers Predictors 等范式，实现分布无关的不确定性量化，同时保持 GAN 的生成能力。论文提供了严格的数学证明，包括有限样本有效性（finite-sample validity）和渐近效率（asymptotic efficiency），从而使合成数据在医疗、金融和自治系统等高风险领域得到可靠应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2504.17058v3",
      "published_date": "2025-04-23 19:07:44 UTC",
      "updated_date": "2025-05-11 20:31:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:52:59.027162"
    },
    {
      "arxiv_id": "2505.00016v2",
      "title": "Sparks of Tabular Reasoning via Text2SQL Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Josefa Lia Stoisser",
        "Marc Boubnovski Martell",
        "Julien Fauqueur"
      ],
      "abstract": "This work reframes the Text-to-SQL task as a pathway for teaching large\nlanguage models (LLMs) to reason over and manipulate tabular data--moving\nbeyond the traditional focus on query generation. We propose a two-stage\nframework that leverages SQL supervision to develop transferable table\nreasoning capabilities. First, we synthesize detailed chain-of-thought (CoT)\ntraces from real-world SQL queries, providing step-by-step, clause-level\nsupervision that teaches the model how to traverse, filter, and aggregate table\nfields. Second, we introduce a Group Relative Policy Optimization (GRPO)\nreinforcement learning objective that connects SQL execution accuracy to\ngeneralizable reasoning by encouraging steps that extend beyond task-specific\nsyntax and transfer across datasets. Empirically, our approach improves\nperformance on standard Text-to-SQL benchmarks and achieves substantial gains\non reasoning-intensive datasets such as BIRD and CRT-QA, demonstrating enhanced\ngeneralization and interpretability. Specifically, the distilled-quantized\nLLaMA model achieved a relative 33.9\\% increase in accuracy when trained on\nText-to-SQL tasks, while Qwen achieved a relative 14.5\\% increase. These\nresults suggest that SQL can serve not only as a target formalism but also as\nan effective scaffold for learning robust, transferable reasoning over\nstructured data.",
      "tldr_zh": "本文将Text-to-SQL任务重新定义为教导大型语言模型(LLMs)处理表格数据的途径，提出一个两阶段框架：首先通过从真实SQL查询合成详细的Chain-of-Thought (CoT)痕迹，提供步步为营的监督以教模型遍历、过滤和聚合表格字段；其次引入Group Relative Policy Optimization (GRPO)强化学习目标，将SQL执行准确性与可泛化推理相结合。实验结果显示，该框架在标准Text-to-SQL基准上提升性能，并在推理密集数据集如BIRD和CRT-QA上取得显著改进，具体包括蒸馏量化后的LLaMA模型准确率相对提高33.9%，Qwen模型提高14.5%。这些发现表明，SQL不仅仅是目标形式，还可作为学习稳健、可转移的结构化数据推理的有效支架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.00016v2",
      "published_date": "2025-04-23 19:02:04 UTC",
      "updated_date": "2025-05-02 11:34:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:53:13.209802"
    },
    {
      "arxiv_id": "2504.17044v1",
      "title": "Approaches to Responsible Governance of GenAI in Organizations",
      "title_zh": "GenAI 在组织中的负责任治理方法",
      "authors": [
        "Dhari Gandhi",
        "Himanshu Joshi",
        "Lucas Hartman",
        "Shabnam Hassani"
      ],
      "abstract": "The rapid evolution of Generative AI (GenAI) has introduced unprecedented\nopportunities while presenting complex challenges around ethics,\naccountability, and societal impact. This paper draws on a literature review,\nestablished governance frameworks, and industry roundtable discussions to\nidentify core principles for integrating responsible GenAI governance into\ndiverse organizational structures. Our objective is to provide actionable\nrecommendations for a balanced, risk-based governance approach that enables\nboth innovation and oversight. Findings emphasize the need for adaptable risk\nassessment tools, continuous monitoring practices, and cross-sector\ncollaboration to establish trustworthy GenAI. These insights provide a\nstructured foundation and Responsible GenAI Guide (ResAI) for organizations to\nalign GenAI initiatives with ethical, legal, and operational best practices.",
      "tldr_zh": "这篇论文探讨了组织中 Generative AI (GenAI) 的负责任治理方法，针对其快速演变带来的伦理、责任和社会影响挑战。作者通过文献综述、现有治理框架以及行业圆桌讨论，识别了核心原则，并提出可操作的推荐，以实现平衡的风险-based 治理方法，支持创新的同时加强监督。关键发现强调了适应性风险评估工具、持续监控实践和跨部门合作的必要性，以构建可信赖的 GenAI。最后，论文提供了 Responsible GenAI Guide (ResAI) 作为结构化基础，帮助组织将 GenAI 举措与伦理、法律和操作最佳实践对齐。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17044v1",
      "published_date": "2025-04-23 18:43:29 UTC",
      "updated_date": "2025-04-23 18:43:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:53:22.880056"
    },
    {
      "arxiv_id": "2504.17040v2",
      "title": "DyMU: Dynamic Merging and Virtual Unmerging for Efficient VLMs",
      "title_zh": "DyMU：用于高效视觉语言模型的动态合并和虚拟取消合并",
      "authors": [
        "Zhenhailong Wang",
        "Senthil Purushwalkam",
        "Caiming Xiong",
        "Silvio Savarese",
        "Heng Ji",
        "Ran Xu"
      ],
      "abstract": "We present DyMU, an efficient, training-free framework that dynamically\nreduces the computational burden of vision-language models (VLMs) while\nmaintaining high task performance. Our approach comprises two key components.\nFirst, Dynamic Token Merging (DToMe) reduces the number of visual token\nembeddings by merging similar tokens based on image complexity, addressing the\ninherent inefficiency of fixed-length outputs in vision transformers. Second,\nVirtual Token Unmerging (VTU) simulates the expected token sequence for large\nlanguage models (LLMs) by efficiently reconstructing the attention dynamics of\na full sequence, thus preserving the downstream performance without additional\nfine-tuning. Unlike previous approaches, our method dynamically adapts token\ncompression to the content of the image and operates completely training-free,\nmaking it readily applicable to most state-of-the-art VLM architectures.\nExtensive experiments on image and video understanding tasks demonstrate that\nDyMU can reduce the average visual token count by 32%-85% while achieving\ncomparable performance to full-length models across diverse VLM architectures,\nincluding the recently popularized AnyRes-based visual encoders. Furthermore,\nthrough qualitative analyses, we demonstrate that DToMe effectively adapts\ntoken reduction based on image complexity and, unlike existing systems,\nprovides users more control over computational costs. Project page:\nhttps://mikewangwzhl.github.io/dymu/.",
      "tldr_zh": "该研究提出了 DyMU，一种高效的无需训练框架，用于动态减少视觉语言模型 (VLMs) 的计算负担，同时保持高任务性能。DyMU 包括两个关键组件：Dynamic Token Merging (DToMe)，根据图像复杂度合并相似视觉标记以减少标记数量；以及 Virtual Token Unmerging (VTU)，通过高效重建完整序列的注意力动态，模拟大型语言模型 (LLMs) 的预期序列，从而避免额外微调。实验结果显示，DyMU 在图像和视频理解任务上可将平均视觉标记数量减少 32%-85%，并在多种 VLM 架构中实现与完整模型相当的性能，同时提供用户对计算成本的更多控制。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17040v2",
      "published_date": "2025-04-23 18:38:18 UTC",
      "updated_date": "2025-05-10 22:42:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:53:35.178759"
    },
    {
      "arxiv_id": "2504.17029v1",
      "title": "Fried Parameter Estimation from Single Wavefront Sensor Image with Artificial Neural Networks",
      "title_zh": "从单个波前传感器图像使用人工神经网络估计 Fried 参数",
      "authors": [
        "Jeffrey Smith",
        "Taisei Fujii",
        "Jesse Cranney",
        "Charles Gretton"
      ],
      "abstract": "Atmospheric turbulence degrades the quality of astronomical observations in\nground-based telescopes, leading to distorted and blurry images. Adaptive\nOptics (AO) systems are designed to counteract these effects, using atmospheric\nmeasurements captured by a wavefront sensor to make real-time corrections to\nthe incoming wavefront. The Fried parameter, r0, characterises the strength of\natmospheric turbulence and is an essential control parameter for optimising the\nperformance of AO systems and more recently sky profiling for Free Space\nOptical (FSO) communication channels. In this paper, we develop a novel\ndata-driven approach, adapting machine learning methods from computer vision\nfor Fried parameter estimation from a single Shack-Hartmann or pyramid\nwavefront sensor image. Using these data-driven methods, we present a detailed\nsimulation-based evaluation of our approach using the open-source COMPASS AO\nsimulation tool to evaluate both the Shack-Hartmann and pyramid wavefront\nsensors. Our evaluation is over a range of guide star magnitudes, and realistic\nnoise, atmospheric and instrument conditions. Remarkably, we are able to\ndevelop a single network-based estimator that is accurate in both open and\nclosed-loop AO configurations. Our method accurately estimates the Fried\nparameter from a single WFS image directly from AO telemetry to a few\nmillimetres. Our approach is suitable for real time control, exhibiting 0.83ms\nr0 inference times on retail NVIDIA RTX 3090 GPU hardware, and thereby\ndemonstrating a compelling economic solution for use in real-time instrument\ncontrol.",
      "tldr_zh": "本研究提出了一种数据驱动方法，使用Artificial Neural Networks（ANNs）从单个Shack-Hartmann或pyramid波前传感器图像中估计Fried parameter（r0），以表征大气湍流强度并优化Adaptive Optics（AO）系统和Free Space Optical（FSO）通信。方法借鉴计算机视觉技术，通过开源COMPASS AO模拟工具在各种导星亮度、噪声和环境条件下进行详细评估，开发了一个适用于开放和闭环AO配置的单一网络估计器。结果显示，该方法能从AO遥测数据中精确估计r0至毫米级别，并实现0.83ms的实时推理时间，在NVIDIA RTX 3090 GPU上运行，展示了经济高效的实时控制潜力。",
      "categories": [
        "astro-ph.IM",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17029v1",
      "published_date": "2025-04-23 18:16:07 UTC",
      "updated_date": "2025-04-23 18:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:53:47.209356"
    },
    {
      "arxiv_id": "2504.17028v1",
      "title": "Democracy of AI Numerical Weather Models: An Example of Global Forecasting with FourCastNetv2 Made by a University Research Lab Using GPU",
      "title_zh": "翻译失败",
      "authors": [
        "Iman Khadir",
        "Shane Stevenson",
        "Henry Li",
        "Kyle Krick",
        "Abram Burrows",
        "David Hall",
        "Stan Posey",
        "Samuel S. P. Shen"
      ],
      "abstract": "This paper demonstrates the feasibility of democratizing AI-driven global\nweather forecasting models among university research groups by leveraging\nGraphics Processing Units (GPUs) and freely available AI models, such as\nNVIDIA's FourCastNetv2. FourCastNetv2 is an NVIDIA's advanced neural network\nfor weather prediction and is trained on a 73-channel subset of the European\nCentre for Medium-Range Weather Forecasts (ECMWF) Reanalysis v5 (ERA5) dataset\nat single levels and different pressure levels. Although the training\nspecifications for FourCastNetv2 are not released to the public, the training\ndocumentation of the model's first generation, FourCastNet, is available to all\nusers. The training had 64 A100 GPUs and took 16 hours to complete. Although\nNVIDIA's models offer significant reductions in both time and cost compared to\ntraditional Numerical Weather Prediction (NWP), reproducing published\nforecasting results presents ongoing challenges for resource-constrained\nuniversity research groups with limited GPU availability. We demonstrate both\n(i) leveraging FourCastNetv2 to create predictions through the designated\napplication programming interface (API) and (ii) utilizing NVIDIA hardware to\ntrain the original FourCastNet model. Further, this paper demonstrates the\ncapabilities and limitations of NVIDIA A100's for resource-limited research\ngroups in universities. We also explore data management, training efficiency,\nand model validation, highlighting the advantages and challenges of using\nlimited high-performance computing resources. Consequently, this paper and its\ncorresponding GitHub materials may serve as an initial guide for other\nuniversity research groups and courses related to machine learning, climate\nscience, and data science to develop research and education programs on AI\nweather forecasting, and hence help democratize the AI NWP in the digital\neconomy.",
      "tldr_zh": "这篇论文展示了如何通过使用 Graphics Processing Units (GPUs) 和免费 AI 模型（如 NVIDIA 的 FourCastNetv2）实现 AI 驱动的全球天气预报模型在大学研究团队中的民主化。研究团队利用 FourCastNetv2，该模型基于 European Centre for Medium-Range Weather Forecasts (ECMWF) 的 ERA5 数据集训练，通过 API 进行预测，并重新训练原始的 FourCastNet 模型，以评估 NVIDIA A100 GPU 在资源有限环境下的能力和限制。实验结果强调了 AI 模型相比传统 Numerical Weather Prediction (NWP) 在时间和成本上的显著优势，同时讨论了数据管理、训练效率和模型验证的挑战，并提供 GitHub 材料作为指导，帮助其他团队推广 AI 天气预报的教育和研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "12 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.17028v1",
      "published_date": "2025-04-23 18:15:31 UTC",
      "updated_date": "2025-04-23 18:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:54:01.391163"
    },
    {
      "arxiv_id": "2504.17023v1",
      "title": "What Makes for a Good Saliency Map? Comparing Strategies for Evaluating Saliency Maps in Explainable AI (XAI)",
      "title_zh": "翻译失败",
      "authors": [
        "Felix Kares",
        "Timo Speith",
        "Hanwei Zhang",
        "Markus Langer"
      ],
      "abstract": "Saliency maps are a popular approach for explaining classifications of\n(convolutional) neural networks. However, it remains an open question as to how\nbest to evaluate salience maps, with three families of evaluation methods\ncommonly being used: subjective user measures, objective user measures, and\nmathematical metrics. We examine three of the most popular saliency map\napproaches (viz., LIME, Grad-CAM, and Guided Backpropagation) in a between\nsubject study (N=166) across these families of evaluation methods. We test 1)\nfor subjective measures, if the maps differ with respect to user trust and\nsatisfaction; 2) for objective measures, if the maps increase users' abilities\nand thus understanding of a model; 3) for mathematical metrics, which map\nachieves the best ratings across metrics; and 4) whether the mathematical\nmetrics can be associated with objective user measures. To our knowledge, our\nstudy is the first to compare several salience maps across all these evaluation\nmethods$-$with the finding that they do not agree in their assessment (i.e.,\nthere was no difference concerning trust and satisfaction, Grad-CAM improved\nusers' abilities best, and Guided Backpropagation had the most favorable\nmathematical metrics). Additionally, we show that some mathematical metrics\nwere associated with user understanding, although this relationship was often\ncounterintuitive. We discuss these findings in light of general debates\nconcerning the complementary use of user studies and mathematical metrics in\nthe evaluation of explainable AI (XAI) approaches.",
      "tldr_zh": "这篇论文探讨了评估显著性地图（Saliency Maps）在可解释 AI (XAI) 中的有效策略，通过比较 LIME、Grad-CAM 和 Guided Backpropagation 三种流行方法。\n研究采用用户实验（N=166）及数学指标，测试这些地图在用户信任、满意度、理解能力等方面的表现。\n结果显示，三种地图在信任和满意度上无显著差异，Grad-CAM 最能提升用户理解能力，而 Guided Backpropagation 在数学指标上评分最高。\n此外，论文发现数学指标与用户理解相关但往往反直觉，并强调用户研究和数学指标在 XAI 评估中的互补性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "27 pages, 7 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.17023v1",
      "published_date": "2025-04-23 18:09:06 UTC",
      "updated_date": "2025-04-23 18:09:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:54:13.634434"
    },
    {
      "arxiv_id": "2504.17020v2",
      "title": "Analyzing Value Functions of States in Parametric Markov Chains",
      "title_zh": "参数化马尔可夫链中状态的价值函数分析",
      "authors": [
        "Kasper Engelen",
        "Guillermo A. Pérez",
        "Shrisha Rao"
      ],
      "abstract": "Parametric Markov chains (pMC) are used to model probabilistic systems with\nunknown or partially known probabilities. Although (universal) pMC verification\nfor reachability properties is known to be coETR-complete, there have been\nefforts to approach it using potentially easier-to-check properties such as\nasking whether the pMC is monotonic in certain parameters. In this paper, we\nfirst reduce monotonicity to asking whether the reachability probability from a\ngiven state is never less than that of another given state. Recent results for\nthe latter property imply an efficient algorithm to collapse same-value\nequivalence classes, which in turn preserves verification results and\nmonotonicity. We implement our algorithm to collapse \"trivial\" equivalence\nclasses in the pMC and show empirical evidence for the following: First, the\ncollapse gives reductions in size for some existing benchmarks and significant\nreductions on some custom benchmarks; Second, the collapse speeds up existing\nalgorithms to check monotonicity and parameter lifting, and hence can be used\nas a fast pre-processing step in practice.",
      "tldr_zh": "本论文探讨了Parametric Markov Chains (pMC)中状态的价值函数分析，旨在通过简化参数单调性问题来提升验证效率。具体方法是将单调性问题简化为比较两个状态的reachability概率，并使用高效算法折叠相同价值的等价类，以保留验证结果和单调性。实验实现显示，该算法在现有基准和自定义基准上显著减少了模型大小，并加速了单调性和参数提升的检查，从而作为一种实用的快速预处理步骤。",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "Published as part of the book \"Principles of Verification: Cycling\n  the Probabilistic Landscape: Essays Dedicated to Joost-Pieter Katoen on the\n  Occasion of His 60th Birthday, Part II\"",
      "pdf_url": "http://arxiv.org/pdf/2504.17020v2",
      "published_date": "2025-04-23 18:06:41 UTC",
      "updated_date": "2025-04-26 05:49:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:54:23.134958"
    },
    {
      "arxiv_id": "2504.17017v1",
      "title": "Neural Theorem Proving: Generating and Structuring Proofs for Formal Verification",
      "title_zh": "神经定理证明：生成和结构化证明用于形式验证",
      "authors": [
        "Balaji Rao",
        "William Eiers",
        "Carlo Lipizzi"
      ],
      "abstract": "Formally verifying properties of software code has been a highly desirable\ntask, especially with the emergence of LLM-generated code. In the same vein,\nthey provide an interesting avenue for the exploration of formal verification\nand mechanistic interpretability. Since the introduction of code-specific\nmodels, despite their successes in generating code in Lean4 and Isabelle, the\ntask of generalized theorem proving still remains far from being fully solved\nand will be a benchmark for reasoning capability in LLMs. In this work, we\nintroduce a framework that generates whole proofs in a formal language to be\nused within systems that utilize the power of built-in tactics and\noff-the-shelf automated theorem provers. Our framework includes 3 components:\ngenerating natural language statements of the code to be verified, an LLM that\ngenerates formal proofs for the given statement, and a module employing\nheuristics for building the final proof. To train the LLM, we employ a 2-stage\nfine-tuning process, where we first use SFT-based training to enable the model\nto generate syntactically correct Isabelle code and then RL-based training that\nencourages the model to generate proofs verified by a theorem prover. We\nvalidate our framework using the miniF2F-test benchmark and the Isabelle proof\nassistant and design a use case to verify the correctness of the AWS S3 bucket\naccess policy code. We also curate a dataset based on the\nFVEL\\textsubscript{\\textnormal{ER}} dataset for future training tasks.",
      "tldr_zh": "这篇论文提出了一种神经定理证明框架，用于生成和结构化形式证明，以支持软件代码的形式验证，特别是针对 LLM 生成的代码。框架包括三个组件：生成代码的自然语言语句、LLM 生成形式证明，以及一个使用启发式方法的模块来构建最终证明。通过两阶段微调训练 LLM（先采用 SFT-based 训练确保语法正确，然后采用 RL-based 训练优化证明可验证性），该框架在 miniF2F-test 基准和 Isabelle 证明助手上表现出色，并成功应用于验证 AWS S3 存储桶访问策略代码的正确性。该方法为提升 LLM 的推理能力和形式验证提供了新基准，并整理了基于 FVEL_ER 数据集的训练资源。",
      "categories": [
        "cs.AI",
        "cs.FL",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to the Proceedings of the 19th Conference on Neurosymbolic\n  Learning and Reasoning (NeSy 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.17017v1",
      "published_date": "2025-04-23 18:04:38 UTC",
      "updated_date": "2025-04-23 18:04:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:54:36.714492"
    },
    {
      "arxiv_id": "2504.17006v1",
      "title": "A Systematic Approach to Design Real-World Human-in-the-Loop Deep Reinforcement Learning: Salient Features, Challenges and Trade-offs",
      "title_zh": "翻译失败",
      "authors": [
        "Jalal Arabneydi",
        "Saiful Islam",
        "Srijita Das",
        "Sai Krishna Gottipati",
        "William Duguay",
        "Cloderic Mars",
        "Matthew E. Taylor",
        "Matthew Guzdial",
        "Antoine Fagette",
        "Younes Zerouali"
      ],
      "abstract": "With the growing popularity of deep reinforcement learning (DRL),\nhuman-in-the-loop (HITL) approach has the potential to revolutionize the way we\napproach decision-making problems and create new opportunities for human-AI\ncollaboration. In this article, we introduce a novel multi-layered hierarchical\nHITL DRL algorithm that comprises three types of learning: self learning,\nimitation learning and transfer learning. In addition, we consider three forms\nof human inputs: reward, action and demonstration. Furthermore, we discuss main\nchallenges, trade-offs and advantages of HITL in solving complex problems and\nhow human information can be integrated in the AI solution systematically. To\nverify our technical results, we present a real-world unmanned aerial vehicles\n(UAV) problem wherein a number of enemy drones attack a restricted area. The\nobjective is to design a scalable HITL DRL algorithm for ally drones to\nneutralize the enemy drones before they reach the area. To this end, we first\nimplement our solution using an award-winning open-source HITL software called\nCogment. We then demonstrate several interesting results such as (a) HITL leads\nto faster training and higher performance, (b) advice acts as a guiding\ndirection for gradient methods and lowers variance, and (c) the amount of\nadvice should neither be too large nor too small to avoid over-training and\nunder-training. Finally, we illustrate the role of human-AI cooperation in\nsolving two real-world complex scenarios, i.e., overloaded and decoy attacks.",
      "tldr_zh": "本论文提出了一种系统方法来设计真实世界的 Human-in-the-Loop Deep Reinforcement Learning (HITL DRL)，包括多层级层次化算法，结合自学习、模仿学习和迁移学习三种类型，并考虑奖励、动作和演示三种人类输入形式。论文讨论了 HITL 在解决复杂决策问题中的主要挑战、权衡（如训练效率与过度依赖人类风险）和优势，如提升人类-AI 协作潜力。作者通过一个真实无人机 (UAV) 防御场景实验，使用开源软件 Cogment 验证了该方法，发现 HITL 能加速训练、提高性能，并强调适当的建议量可降低方差，避免过度或不足训练。最后，研究展示了人类-AI 合作在处理过载和诱饵攻击等真实场景中的关键作用。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "This is a result of the collaboration by JACOBB, AMII(Alberta Machine\n  Intelligence Institute), Thales and AI Redefined (AIR) in 2021-2023",
      "pdf_url": "http://arxiv.org/pdf/2504.17006v1",
      "published_date": "2025-04-23 18:00:08 UTC",
      "updated_date": "2025-04-23 18:00:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:54:50.498677"
    },
    {
      "arxiv_id": "2504.17004v1",
      "title": "(Im)possibility of Automated Hallucination Detection in Large Language Models",
      "title_zh": "大语言模型中自动化幻觉检测的（不）可能性",
      "authors": [
        "Amin Karbasi",
        "Omar Montasser",
        "John Sous",
        "Grigoris Velegkas"
      ],
      "abstract": "Is automated hallucination detection possible? In this work, we introduce a\ntheoretical framework to analyze the feasibility of automatically detecting\nhallucinations produced by large language models (LLMs). Inspired by the\nclassical Gold-Angluin framework for language identification and its recent\nadaptation to language generation by Kleinberg and Mullainathan, we investigate\nwhether an algorithm, trained on examples drawn from an unknown target language\n$K$ (selected from a countable collection) and given access to an LLM, can\nreliably determine whether the LLM's outputs are correct or constitute\nhallucinations.\n  First, we establish an equivalence between hallucination detection and the\nclassical task of language identification. We prove that any hallucination\ndetection method can be converted into a language identification method, and\nconversely, algorithms solving language identification can be adapted for\nhallucination detection. Given the inherent difficulty of language\nidentification, this implies that hallucination detection is fundamentally\nimpossible for most language collections if the detector is trained using only\ncorrect examples from the target language.\n  Second, we show that the use of expert-labeled feedback, i.e., training the\ndetector with both positive examples (correct statements) and negative examples\n(explicitly labeled incorrect statements), dramatically changes this\nconclusion. Under this enriched training regime, automated hallucination\ndetection becomes possible for all countable language collections.\n  These results highlight the essential role of expert-labeled examples in\ntraining hallucination detectors and provide theoretical support for\nfeedback-based methods, such as reinforcement learning with human feedback\n(RLHF), which have proven critical for reliable LLM deployment.",
      "tldr_zh": "这篇论文探讨了自动检测大型语言模型 (LLMs) 幻觉的可行性，通过一个理论框架分析其（不）可能性。研究将幻觉检测等价于经典的语言识别任务，证明如果检测器仅使用正确示例训练，则在大多数语言集合中，检测是根本不可能的。相反，如果引入专家标记的反馈（包括正确和错误示例），则自动幻觉检测对所有可数语言集合都变得可行。这些结果强调了专家标记示例的关键作用，并为反馈-based 方法如 reinforcement learning with human feedback (RLHF) 提供了理论支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.17004v1",
      "published_date": "2025-04-23 18:00:07 UTC",
      "updated_date": "2025-04-23 18:00:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:54:59.910997"
    },
    {
      "arxiv_id": "2504.16929v1",
      "title": "I-Con: A Unifying Framework for Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Shaden Alshammari",
        "John Hershey",
        "Axel Feldmann",
        "William T. Freeman",
        "Mark Hamilton"
      ],
      "abstract": "As the field of representation learning grows, there has been a proliferation\nof different loss functions to solve different classes of problems. We\nintroduce a single information-theoretic equation that generalizes a large\ncollection of modern loss functions in machine learning. In particular, we\nintroduce a framework that shows that several broad classes of machine learning\nmethods are precisely minimizing an integrated KL divergence between two\nconditional distributions: the supervisory and learned representations. This\nviewpoint exposes a hidden information geometry underlying clustering, spectral\nmethods, dimensionality reduction, contrastive learning, and supervised\nlearning. This framework enables the development of new loss functions by\ncombining successful techniques from across the literature. We not only present\na wide array of proofs, connecting over 23 different approaches, but we also\nleverage these theoretical results to create state-of-the-art unsupervised\nimage classifiers that achieve a +8% improvement over the prior\nstate-of-the-art on unsupervised classification on ImageNet-1K. We also\ndemonstrate that I-Con can be used to derive principled debiasing methods which\nimprove contrastive representation learners.",
      "tldr_zh": "这项研究引入了 I-Con 框架，这是一个统一的表示学习框架，通过一个单一的信息理论方程泛化了多种机器学习损失函数，如聚类、spectral methods、dimensionality reduction、contrastive learning 和 supervised learning。框架证明这些方法本质上都在最小化监督和学习表示之间的集成 KL divergence，从而揭示了隐藏的信息几何结构。利用这一理论，研究者开发了新的损失函数，实现了 ImageNet-1K 无监督图像分类的 state-of-the-art 性能，提高了 8%，并提出了改进 contrastive representation learners 的去偏置方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025; website: https://aka.ms/i-con . Proceedings of the\n  Thirteenth International Conference on Learning Representations (ICLR 2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.16929v1",
      "published_date": "2025-04-23 17:59:01 UTC",
      "updated_date": "2025-04-23 17:59:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:55:12.297758"
    },
    {
      "arxiv_id": "2504.16979v1",
      "title": "Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline",
      "title_zh": "使用 QuPath 自动评估乳腺癌组织病理图像中的肿瘤浸润淋巴细胞：一个透明且易访问的机器学习管道",
      "authors": [
        "Masoud Tafavvoghi",
        "Lars Ailo Bongo",
        "André Berli Delgado",
        "Nikita Shvetsov",
        "Anders Sildnes",
        "Line Moi",
        "Lill-Tove Rasmussen Busund",
        "Kajsa Møllersen"
      ],
      "abstract": "In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs)\nassessment pipeline within QuPath, demonstrating the potential of easily\naccessible tools to perform complex tasks in a fully automatic fashion. First,\nwe trained a pixel classifier to segment tumor, tumor-associated stroma, and\nother tissue compartments in breast cancer H&E-stained whole-slide images (WSI)\nto isolate tumor-associated stroma for subsequent analysis. Next, we applied a\npre-trained StarDist deep learning model in QuPath for cell detection and used\nthe extracted cell features to train a binary classifier distinguishing TILs\nfrom other cells. To evaluate our TILs assessment pipeline, we calculated the\nTIL density in each WSI and categorized them as low, medium, or high TIL\nlevels. Our pipeline was evaluated against pathologist-assigned TIL scores,\nachieving a Cohen's kappa of 0.71 on the external test set, corroborating\nprevious research findings. These results confirm that existing software can\noffer a practical solution for the assessment of TILs in H&E-stained WSIs of\nbreast cancer.",
      "tldr_zh": "本研究开发了一个基于 QuPath 的端到端机器学习管道，用于自动评估乳腺癌组织病理图像中的肿瘤浸润淋巴细胞(TILs)，以提供透明和易访问的解决方案。首先，训练像素分类器分割肿瘤、肿瘤相关基质和其他组织区域，然后使用预训练的 StarDist 模型进行细胞检测，并基于提取的细胞特征训练二元分类器来区分 TILs。管道计算 TIL 密度并分类为低、中或高水平，在外部测试集上与病理学家评分相比，达到 Cohen's kappa 0.71的可靠性。总体而言，该方法证实了现有软件在 H&E 染色全滑图像中评估 TILs 的实用潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "q-bio.QM",
      "comment": "16 Pages, 9 Figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.16979v1",
      "published_date": "2025-04-23 17:54:59 UTC",
      "updated_date": "2025-04-23 17:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:55:24.890306"
    },
    {
      "arxiv_id": "2504.16925v1",
      "title": "Latent Diffusion Planning for Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Amber Xie",
        "Oleh Rybkin",
        "Dorsa Sadigh",
        "Chelsea Finn"
      ],
      "abstract": "Recent progress in imitation learning has been enabled by policy\narchitectures that scale to complex visuomotor tasks, multimodal distributions,\nand large datasets. However, these methods often rely on learning from large\namount of expert demonstrations. To address these shortcomings, we propose\nLatent Diffusion Planning (LDP), a modular approach consisting of a planner\nwhich can leverage action-free demonstrations, and an inverse dynamics model\nwhich can leverage suboptimal data, that both operate over a learned latent\nspace. First, we learn a compact latent space through a variational\nautoencoder, enabling effective forecasting of future states in image-based\ndomains. Then, we train a planner and an inverse dynamics model with diffusion\nobjectives. By separating planning from action prediction, LDP can benefit from\nthe denser supervision signals of suboptimal and action-free data. On simulated\nvisual robotic manipulation tasks, LDP outperforms state-of-the-art imitation\nlearning approaches, as they cannot leverage such additional data.",
      "tldr_zh": "本研究提出Latent Diffusion Planning (LDP)，一种模块化方法，用于提升模仿学习效率，减少对大量专家演示的依赖。LDP 通过变分自动编码器（variational autoencoder）学习紧凑的潜在空间，实现图像域中未来状态的有效预测，并使用扩散目标（diffusion objectives）训练规划器和逆向动力学模型。相比传统方法，LDP 能利用无动作演示和次优数据提供更密集的监督信号；在模拟视觉机器人操作任务中，LDP 表现优于现有模仿学习方法。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16925v1",
      "published_date": "2025-04-23 17:53:34 UTC",
      "updated_date": "2025-04-23 17:53:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:55:34.585072"
    },
    {
      "arxiv_id": "2504.16922v1",
      "title": "Generalized Neighborhood Attention: Multi-dimensional Sparse Attention at the Speed of Light",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Hassani",
        "Fengzhe Zhou",
        "Aditya Kane",
        "Jiannan Huang",
        "Chieh-Yun Chen",
        "Min Shi",
        "Steven Walton",
        "Markus Hoehnerbach",
        "Vijay Thakkar",
        "Michael Isaev",
        "Qinsheng Zhang",
        "Bing Xu",
        "Haicheng Wu",
        "Wen-mei Hwu",
        "Ming-Yu Liu",
        "Humphrey Shi"
      ],
      "abstract": "Many sparse attention mechanisms such as Neighborhood Attention have\ntypically failed to consistently deliver speedup over the self attention\nbaseline. This is largely due to the level of complexity in attention\ninfrastructure, and the rapid evolution of AI hardware architecture. At the\nsame time, many state-of-the-art foundational models, particularly in computer\nvision, are heavily bound by attention, and need reliable sparsity to escape\nthe O(n^2) complexity. In this paper, we study a class of promising sparse\nattention mechanisms that focus on locality, and aim to develop a better\nanalytical model of their performance improvements. We first introduce\nGeneralized Neighborhood Attention (GNA), which can describe sliding window,\nstrided sliding window, and blocked attention. We then consider possible design\nchoices in implementing these approaches, and create a simulator that can\nprovide much more realistic speedup upper bounds for any given setting.\nFinally, we implement GNA on top of a state-of-the-art fused multi-headed\nattention (FMHA) kernel designed for the NVIDIA Blackwell architecture in\nCUTLASS. Our implementation can fully realize the maximum speedup theoretically\npossible in many perfectly block-sparse cases, and achieves an effective\nutilization of 1.3 petaFLOPs/second in FP16. In addition, we plug various GNA\nconfigurations into off-the-shelf generative models, such as Cosmos-7B,\nHunyuanVideo, and FLUX, and show that it can deliver 28% to 46% end-to-end\nspeedup on B200 without any fine-tuning. We will open source our simulator and\nBlackwell kernels directly through the NATTEN project.",
      "tldr_zh": "本论文引入 Generalized Neighborhood Attention (GNA)，一种多维稀疏注意力机制，旨在解决传统稀疏注意力（如 Neighborhood Attention）无法在自注意力基准上实现一致速度提升的问题，同时通过分析局部焦点机制来逃避 O(n^2) 计算复杂度。研究者开发了一个模拟器来评估不同实现方案的性能，并基于 CUTLASS 的 FMHA 内核在 NVIDIA Blackwell 架构上实现了 GNA，在块状稀疏场景中达到理论最大加速，并实现 1.3 petaFLOPs/second 的 FP16 利用率。将 GNA 整合到生成模型如 Cosmos-7B、HunyuanVideo 和 FLUX 中，可实现 28% 到 46% 的端到端加速，而无需微调，并计划通过 NATTEN 项目开源相关代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "https://github.com/SHI-Labs/NATTEN/",
      "pdf_url": "http://arxiv.org/pdf/2504.16922v1",
      "published_date": "2025-04-23 17:49:53 UTC",
      "updated_date": "2025-04-23 17:49:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:55:49.025413"
    },
    {
      "arxiv_id": "2504.16918v2",
      "title": "OptimAI: Optimization from Natural Language Using LLM-Powered AI Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Raghav Thind",
        "Youran Sun",
        "Ling Liang",
        "Haizhao Yang"
      ],
      "abstract": "Optimization plays a vital role in scientific research and practical\napplications. However, formulating a concrete optimization problem described in\nnatural language into a mathematical form and selecting a suitable solver to\nsolve the problem requires substantial domain expertise. We introduce OptimAI,\na framework for solving Optimization problems described in natural language by\nleveraging LLM-powered AI agents, and achieve superior performance over current\nstate-of-the-art methods. Our framework is built upon the following key roles:\n(1) a formulator that translates natural language problem descriptions into\nprecise mathematical formulations; (2) a planner that constructs a high-level\nsolution strategy prior to execution; and (3) a coder and a code critic capable\nof interacting with the environment and reflecting on outcomes to refine future\nactions. Ablation studies confirm that all roles are essential; removing the\nplanner or code critic results in $5.8\\times$ and $3.1\\times$ drops in\nproductivity, respectively. Furthermore, we introduce UCB-based debug\nscheduling to dynamically switch between alternative plans, yielding an\nadditional $3.3\\times$ productivity gain. Our design emphasizes multi-agent\ncollaboration, and our experiments confirm that combining diverse models leads\nto performance gains. Our approach attains 88.1% accuracy on the NLP4LP dataset\nand 82.3% on the Optibench dataset, reducing error rates by 58% and 52%,\nrespectively, over prior best results.",
      "tldr_zh": "本研究提出OptimAI框架，利用LLM-powered AI agents从自然语言描述中解决优化问题，显著超越现有方法。该框架包括三个关键角色：formulator负责将自然语言转化为精确数学公式、planner构建高层解决方案策略，以及coder和code critic通过环境交互和反思优化行动。此外，引入UCB-based debug scheduling动态切换计划，进一步提升生产力。实验结果显示，OptimAI在NLP4LP数据集上达到88.1%准确率，在Optibench数据集上达到82.3%，分别比最佳先前结果降低58%和52%的错误率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16918v2",
      "published_date": "2025-04-23 17:45:05 UTC",
      "updated_date": "2025-05-17 03:40:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:56:01.289791"
    },
    {
      "arxiv_id": "2504.16913v1",
      "title": "Tracing Thought: Using Chain-of-Thought Reasoning to Identify the LLM Behind AI-Generated Text",
      "title_zh": "翻译失败",
      "authors": [
        "Shifali Agrahari",
        "Sanasam Ranbir Singh"
      ],
      "abstract": "In recent years, the detection of AI-generated text has become a critical\narea of research due to concerns about academic integrity, misinformation, and\nethical AI deployment. This paper presents COT Fine-tuned, a novel framework\nfor detecting AI-generated text and identifying the specific language model.\nresponsible for generating the text. We propose a dual-task approach, where\nTask A involves classifying text as AI-generated or human-written, and Task B\nidentifies the specific LLM behind the text. The key innovation of our method\nlies in the use of Chain-of-Thought reasoning, which enables the model to\ngenerate explanations for its predictions, enhancing transparency and\ninterpretability. Our experiments demonstrate that COT Fine-tuned achieves high\naccuracy in both tasks, with strong performance in LLM identification and\nhuman-AI classification. We also show that the CoT reasoning process\ncontributes significantly to the models effectiveness and interpretability.",
      "tldr_zh": "本研究提出COT Fine-tuned框架，用于检测AI生成文本并识别具体LLM。框架采用双任务方法：Task A 分类文本为AI生成或人类撰写，Task B 识别生成文本的特定LLM，并利用Chain-of-Thought推理生成预测解释，以提升模型的透明度和可解释性。实验结果显示，该框架在LLM识别和AI-人类文本分类任务上均取得高准确率，且Chain-of-Thought推理显著提高了模型的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "De-Factify 4: 4th Workshop on Multimodal Fact Checking and Hate\n  Speech Detection, co-located with AAAI 2025. Pennsylvania",
      "pdf_url": "http://arxiv.org/pdf/2504.16913v1",
      "published_date": "2025-04-23 17:39:49 UTC",
      "updated_date": "2025-04-23 17:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:56:11.658328"
    },
    {
      "arxiv_id": "2504.16907v1",
      "title": "BadVideo: Stealthy Backdoor Attack against Text-to-Video Generation",
      "title_zh": "BadVideo：针对文本到视频生成的隐蔽后门攻击",
      "authors": [
        "Ruotong Wang",
        "Mingli Zhu",
        "Jiarong Ou",
        "Rui Chen",
        "Xin Tao",
        "Pengfei Wan",
        "Baoyuan Wu"
      ],
      "abstract": "Text-to-video (T2V) generative models have rapidly advanced and found\nwidespread applications across fields like entertainment, education, and\nmarketing. However, the adversarial vulnerabilities of these models remain\nrarely explored. We observe that in T2V generation tasks, the generated videos\noften contain substantial redundant information not explicitly specified in the\ntext prompts, such as environmental elements, secondary objects, and additional\ndetails, providing opportunities for malicious attackers to embed hidden\nharmful content. Exploiting this inherent redundancy, we introduce BadVideo,\nthe first backdoor attack framework tailored for T2V generation. Our attack\nfocuses on designing target adversarial outputs through two key strategies: (1)\nSpatio-Temporal Composition, which combines different spatiotemporal features\nto encode malicious information; (2) Dynamic Element Transformation, which\nintroduces transformations in redundant elements over time to convey malicious\ninformation. Based on these strategies, the attacker's malicious target\nseamlessly integrates with the user's textual instructions, providing high\nstealthiness. Moreover, by exploiting the temporal dimension of videos, our\nattack successfully evades traditional content moderation systems that\nprimarily analyze spatial information within individual frames. Extensive\nexperiments demonstrate that BadVideo achieves high attack success rates while\npreserving original semantics and maintaining excellent performance on clean\ninputs. Overall, our work reveals the adversarial vulnerability of T2V models,\ncalling attention to potential risks and misuse. Our project page is at\nhttps://wrt2000.github.io/BadVideo2025/.",
      "tldr_zh": "本文提出 BadVideo，一种针对 Text-to-Video (T2V) 生成模型的隐蔽后台攻击框架，利用视频中的冗余信息（如环境元素和辅助对象）嵌入恶意内容。攻击方法包括 Spatio-Temporal Composition（结合时空特征编码恶意信息）和 Dynamic Element Transformation（对冗余元素进行时间变换以传达隐藏信息），从而实现高隐蔽性和规避传统空间分析的内容审查系统。实验结果显示，BadVideo 在保持原始语义和干净输入性能的同时，实现了高攻击成功率，并揭示了 T2V 模型的潜在安全漏洞，呼吁加强相关风险防范。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16907v1",
      "published_date": "2025-04-23 17:34:48 UTC",
      "updated_date": "2025-04-23 17:34:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:56:26.506064"
    },
    {
      "arxiv_id": "2504.16977v1",
      "title": "Tokenization Matters: Improving Zero-Shot NER for Indic Languages",
      "title_zh": "翻译失败",
      "authors": [
        "Priyaranjan Pattnayak",
        "Hitesh Laxmichand Patel",
        "Amit Agarwal"
      ],
      "abstract": "Tokenization is a critical component of Natural Language Processing (NLP),\nespecially for low resource languages, where subword segmentation influences\nvocabulary structure and downstream task accuracy. Although Byte Pair Encoding\n(BPE) is a standard tokenization method in multilingual language models, its\nsuitability for Named Entity Recognition (NER) in low resource Indic languages\nremains underexplored due to its limitations in handling morphological\ncomplexity. In this work, we systematically compare BPE, SentencePiece, and\nCharacter Level tokenization strategies using IndicBERT for NER tasks in low\nresource Indic languages like Assamese, Bengali, Marathi, and Odia, as well as\nextremely low resource Indic languages like Santali, Manipuri, and Sindhi. We\nassess both intrinsic linguistic properties tokenization efficiency, out of\nvocabulary (OOV) rates, and morphological preservation as well as extrinsic\ndownstream performance, including fine tuning and zero shot cross lingual\ntransfer.\n  Our experiments show that SentencePiece is a consistently better performing\napproach than BPE for NER in low resource Indic Languages, particularly in zero\nshot cross lingual settings, as it better preserves entity consistency. While\nBPE provides the most compact tokenization form, it is not capable of\ngeneralization because it misclassifies or even fails to recognize entity\nlabels when tested on unseen languages. In contrast, SentencePiece constitutes\na better linguistic structural preservation model, benefiting extremely low\nresource and morphologically rich Indic languages, such as Santali and\nManipuri, for superior entity recognition, as well as high generalization\nacross scripts, such as Sindhi, written in Arabic. The results point to\nSentencePiece as the more effective tokenization strategy for NER within\nmultilingual and low resource Indic NLP applications.",
      "tldr_zh": "这篇论文探讨了分词策略对低资源Indic语言零样本命名实体识别(NER)的影响，通过比较Byte Pair Encoding (BPE)、SentencePiece和Character Level方法，使用IndicBERT在Assamese、Bengali等低资源语言以及Santali、Manipuri和Sindhi等极低资源语言上进行评估。研究评估了分词的内在属性（如OOV率和形态保存）和外在性能（如微调和零样本跨语言转移），结果显示SentencePiece在NER任务中表现更优，因为它更好地保持实体一致性和语言结构。作者得出结论，SentencePiece是多语言和低资源Indic NLP应用中更有效的分词策略，尤其适合形态复杂的语言，提供更高的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16977v1",
      "published_date": "2025-04-23 17:28:38 UTC",
      "updated_date": "2025-04-23 17:28:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:56:38.527013"
    },
    {
      "arxiv_id": "2504.16902v2",
      "title": "Building A Secure Agentic AI Application Leveraging A2A Protocol",
      "title_zh": "翻译失败",
      "authors": [
        "Idan Habler",
        "Ken Huang",
        "Vineeth Sai Narajala",
        "Prashant Kulkarni"
      ],
      "abstract": "As Agentic AI systems evolve from basic workflows to complex multi agent\ncollaboration, robust protocols such as Google's Agent2Agent (A2A) become\nessential enablers. To foster secure adoption and ensure the reliability of\nthese complex interactions, understanding the secure implementation of A2A is\nessential. This paper addresses this goal by providing a comprehensive security\nanalysis centered on the A2A protocol. We examine its fundamental elements and\noperational dynamics, situating it within the framework of agent communication\ndevelopment. Utilizing the MAESTRO framework, specifically designed for AI\nrisks, we apply proactive threat modeling to assess potential security issues\nin A2A deployments, focusing on aspects such as Agent Card management, task\nexecution integrity, and authentication methodologies.\n  Based on these insights, we recommend practical secure development\nmethodologies and architectural best practices designed to build resilient and\neffective A2A systems. Our analysis also explores how the synergy between A2A\nand the Model Context Protocol (MCP) can further enhance secure\ninteroperability. This paper equips developers and architects with the\nknowledge and practical guidance needed to confidently leverage the A2A\nprotocol for building robust and secure next generation agentic applications.",
      "tldr_zh": "这篇论文对 Google 的 A2A 协议进行了全面安全分析，旨在促进 Agentic AI 系统的安全采用和可靠交互。作者使用 MAESTRO 框架进行主动威胁建模，评估了 A2A 部署中的潜在风险，包括 Agent Card 管理、任务执行完整性和认证方法。基于这些洞见，他们推荐了实用的安全开发方法和架构最佳实践，并探讨了 A2A 与 Model Context Protocol (MCP) 的协同作用，以增强代理应用的互操作性和整体安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 4 figures, 1 table, Authors contributed equally to this\n  work, typos corrected, references added",
      "pdf_url": "http://arxiv.org/pdf/2504.16902v2",
      "published_date": "2025-04-23 17:27:49 UTC",
      "updated_date": "2025-05-02 18:28:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:56:49.782142"
    },
    {
      "arxiv_id": "2504.16891v1",
      "title": "AIMO-2 Winning Solution: Building State-of-the-Art Mathematical Reasoning Models with OpenMathReasoning dataset",
      "title_zh": "AIMO-2 获胜解决方案：利用 OpenMath",
      "authors": [
        "Ivan Moshkov",
        "Darragh Hanley",
        "Ivan Sorokin",
        "Shubham Toshniwal",
        "Christof Henkel",
        "Benedikt Schifferer",
        "Wei Du",
        "Igor Gitman"
      ],
      "abstract": "This paper presents our winning submission to the AI Mathematical Olympiad -\nProgress Prize 2 (AIMO-2) competition. Our recipe for building state-of-the-art\nmathematical reasoning models relies on three key pillars. First, we create a\nlarge-scale dataset comprising 540K unique high-quality math problems,\nincluding olympiad-level problems, and their 3.2M long-reasoning solutions.\nSecond, we develop a novel method to integrate code execution with long\nreasoning models through iterative training, generation, and quality filtering,\nresulting in 1.7M high-quality Tool-Integrated Reasoning solutions. Third, we\ncreate a pipeline to train models to select the most promising solution from\nmany candidates. We show that such generative solution selection (GenSelect)\ncan significantly improve upon majority voting baseline. Combining these ideas,\nwe train a series of models that achieve state-of-the-art results on\nmathematical reasoning benchmarks. To facilitate further research, we release\nour code, models, and the complete OpenMathReasoning dataset under a\ncommercially permissive license.",
      "tldr_zh": "这篇论文介绍了 AIMO-2 比赛的获胜方案，旨在构建 state-of-the-art 数学推理模型。研究团队创建了 OpenMathReasoning 数据集，包含 540K 个高质量数学问题（包括奥林匹克级别问题）及其 3.2M 个长推理解决方案。论文提出了一种新方法，通过迭代训练、生成和质量过滤，将代码执行整合到长推理模型中，生成 1.7M 个高质量的 Tool-Integrated Reasoning 解决方案。此外，他们开发了 Generative Solution Selection (GenSelect) 管道，用于从多个候选方案中选择最优者，比多数投票基线显著提升性能。最终，结合这些创新，模型在数学推理基准上达到 state-of-the-art 水平，并开源了代码、模型和数据集以促进进一步研究。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Report of AIMO-2 winning submission",
      "pdf_url": "http://arxiv.org/pdf/2504.16891v1",
      "published_date": "2025-04-23 17:13:04 UTC",
      "updated_date": "2025-04-23 17:13:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:57:02.528042"
    },
    {
      "arxiv_id": "2504.16837v1",
      "title": "Approximating Optimal Labelings for Temporal Connectivity",
      "title_zh": "翻译失败",
      "authors": [
        "Daniele Carnevale",
        "Gianlorenzo D'Angelo",
        "Martin Olsen"
      ],
      "abstract": "In a temporal graph the edge set dynamically changes over time according to a\nset of time-labels associated with each edge that indicates at which time-steps\nthe edge is available. Two vertices are connected if there is a path connecting\nthem in which the edges are traversed in increasing order of their labels. We\nstudy the problem of scheduling the availability time of the edges of a\ntemporal graph in such a way that all pairs of vertices are connected within a\ngiven maximum allowed time $a$ and the overall number of labels is minimized.\n  The problem, known as \\emph{Minimum Aged Labeling} (MAL), has several\napplications in logistics, distribution scheduling, and information spreading\nin social networks, where carefully choosing the time-labels can significantly\nreduce infrastructure costs, fuel consumption, or greenhouse gases.\n  The problem MAL has previously been proved to be NP-complete on undirected\ngraphs and \\APX-hard on directed graphs. In this paper, we extend our knowledge\non the complexity and approximability of MAL in several directions. We first\nshow that the problem cannot be approximated within a factor better than\n$O(\\log n)$ when $a\\geq 2$, unless $\\text{P} = \\text{NP}$, and a factor better\nthan $2^{\\log ^{1-\\epsilon} n}$ when $a\\geq 3$, unless $\\text{NP}\\subseteq\n\\text{DTIME}(2^{\\text{polylog}(n)})$, where $n$ is the number of vertices in\nthe graph. Then we give a set of approximation algorithms that, under some\nconditions, almost match these lower bounds. In particular, we show that the\napproximation depends on a relation between $a$ and the diameter of the input\ngraph.\n  We further establish a connection with a foundational optimization problem on\nstatic graphs called \\emph{Diameter Constrained Spanning Subgraph} (DCSS) and\nshow that our hardness results also apply to DCSS.",
      "tldr_zh": "本论文研究了在时间图（temporal graph）中近似最优标签的问题，目标是调度边的可用时间标签，使所有顶点对在给定最大时间 $a$ 内连接，同时最小化标签总数，即解决 Minimum Aged Labeling (MAL) 问题。论文证明了 MAL 在无向图上是 NP-complete，在有向图上是 APX-hard，并给出了近似下界：当 $a \\geq 2$ 时，无法在 $O(\\log n)$ 因子内近似，除非 P=NP；当 $a \\geq 3$ 时，无法在 $2^{\\log^{1-\\epsilon} n}$ 因子内近似，除非 NP ⊆ DTIME($2^{\\text{polylog}(n)}$)。此外，论文提供了近似算法，这些算法在某些条件下（如 $a$ 与图直径的关系）几乎匹配这些下界，并将 MAL 的硬度结果扩展到 Diameter Constrained Spanning Subgraph (DCSS) 问题中。",
      "categories": [
        "cs.DS",
        "cs.AI"
      ],
      "primary_category": "cs.DS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16837v1",
      "published_date": "2025-04-23 16:00:33 UTC",
      "updated_date": "2025-04-23 16:00:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:57:14.051755"
    },
    {
      "arxiv_id": "2504.16834v2",
      "title": "Improving Significant Wave Height Prediction Using Chronos Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yilin Zhai",
        "Hongyuan Shi",
        "Chao Zhan",
        "Qing Wang",
        "Zaijin You",
        "Nan Wang"
      ],
      "abstract": "Accurate wave height prediction is critical for maritime safety and coastal\nresilience, yet conventional physics-based models and traditional machine\nlearning methods face challenges in computational efficiency and nonlinear\ndynamics modeling. This study introduces Chronos, the first implementation of a\nlarge language model (LLM)-powered temporal architecture (Chronos) optimized\nfor wave forecasting. Through advanced temporal pattern recognition applied to\nhistorical wave data from three strategically chosen marine zones in the\nNorthwest Pacific basin, our framework achieves multimodal improvements: (1)\n14.3% reduction in training time with 2.5x faster inference speed compared to\nPatchTST baselines, achieving 0.575 mean absolute scaled error (MASE) units;\n(2) superior short-term forecasting (1-24h) across comprehensive metrics; (3)\nsustained predictive leadership in extended-range forecasts (1-120h); and (4)\ndemonstrated zero-shot capability maintaining median performance (rank 4/12)\nagainst specialized operational models. This LLM-enhanced temporal modeling\nparadigm establishes a new standard in wave prediction, offering both\ncomputationally efficient solutions and a transferable framework for complex\ngeophysical systems modeling.",
      "tldr_zh": "这篇论文介绍了 Chronos 模型，这是首个基于大型语言模型 (LLM) 的时间架构，用于提升波高预测的准确性和效率，以应对传统物理模型和机器学习方法的计算挑战。研究通过对西北太平洋三个海洋区的历史波浪数据应用高级时间模式识别，实现多项改进：训练时间减少 14.3%、推理速度提高 2.5 倍（MASE 值为 0.575），并在短期 (1-24 小时) 和长期 (1-120 小时) 预测中表现出色。Chronos 还展示了零样本能力，在对比专业模型时排名第 4/12，为复杂地球物理系统建模提供了高效、可转移的新范式。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.ao-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2403.07815 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2504.16834v2",
      "published_date": "2025-04-23 15:56:28 UTC",
      "updated_date": "2025-04-25 08:51:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:57:25.859993"
    },
    {
      "arxiv_id": "2504.16828v2",
      "title": "Process Reward Models That Think",
      "title_zh": "能够思考的过程奖励模型",
      "authors": [
        "Muhammad Khalifa",
        "Rishabh Agarwal",
        "Lajanugen Logeswaran",
        "Jaekyeom Kim",
        "Hao Peng",
        "Moontae Lee",
        "Honglak Lee",
        "Lu Wang"
      ],
      "abstract": "Step-by-step verifiers -- also known as process reward models (PRMs) -- are a\nkey ingredient for test-time scaling. PRMs require step-level supervision,\nmaking them expensive to train. This work aims to build data-efficient PRMs as\nverbalized step-wise reward models that verify every step in the solution by\ngenerating a verification chain-of-thought (CoT). We propose ThinkPRM, a long\nCoT verifier fine-tuned on orders of magnitude fewer process labels than those\nrequired by discriminative PRMs. Our approach capitalizes on the inherent\nreasoning abilities of long CoT models, and outperforms LLM-as-a-Judge and\ndiscriminative verifiers -- using only 1% of the process labels in PRM800K --\nacross several challenging benchmarks. Specifically, ThinkPRM beats the\nbaselines on ProcessBench, MATH-500, and AIME '24 under best-of-N selection and\nreward-guided search. In an out-of-domain evaluation on a subset of\nGPQA-Diamond and LiveCodeBench, our PRM surpasses discriminative verifiers\ntrained on the full PRM800K by 8% and 4.5%, respectively. Lastly, under the\nsame token budget, ThinkPRM scales up verification compute more effectively\ncompared to LLM-as-a-Judge, outperforming it by 7.2% on a subset of\nProcessBench. Our work highlights the value of generative, long CoT PRMs that\ncan scale test-time compute for verification while requiring minimal\nsupervision for training. Our code, data, and models will be released at\nhttps://github.com/mukhal/thinkprm.",
      "tldr_zh": "本研究针对过程奖励模型（Process Reward Models, PRMs）的训练成本高问题，提出了一种数据高效的生成式验证器ThinkPRM。该模型通过生成验证链式思维（Chain-of-Thought, CoT）来逐步验证解决方案，仅需PRM800K数据集的1%标签进行微调，便超越了LLM-as-a-Judge和鉴别式验证器。实验结果显示，ThinkPRM在ProcessBench、MATH-500和AIME '24等基准上表现出色，并在GPQA-Diamond和LiveCodeBench的外部评估中分别比用完整PRM800K训练的模型高出8%和4.5%。总体而言，该方法证明了生成式长CoT PRMs在最小监督下有效扩展测试时间计算的潜力，为高效的AI验证提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16828v2",
      "published_date": "2025-04-23 15:44:54 UTC",
      "updated_date": "2025-05-18 01:23:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:57:38.514022"
    },
    {
      "arxiv_id": "2504.16972v1",
      "title": "Unsupervised Time-Series Signal Analysis with Autoencoders and Vision Transformers: A Review of Architectures and Applications",
      "title_zh": "无监督时间序列信号分析：利用自编码器和视觉变压器的架构与应用",
      "authors": [
        "Hossein Ahmadi",
        "Sajjad Emdadi Mahdimahalleh",
        "Arman Farahat",
        "Banafsheh Saffari"
      ],
      "abstract": "The rapid growth of unlabeled time-series data in domains such as wireless\ncommunications, radar, biomedical engineering, and the Internet of Things (IoT)\nhas driven advancements in unsupervised learning. This review synthesizes\nrecent progress in applying autoencoders and vision transformers for\nunsupervised signal analysis, focusing on their architectures, applications,\nand emerging trends. We explore how these models enable feature extraction,\nanomaly detection, and classification across diverse signal types, including\nelectrocardiograms, radar waveforms, and IoT sensor data. The review highlights\nthe strengths of hybrid architectures and self-supervised learning, while\nidentifying challenges in interpretability, scalability, and domain\ngeneralization. By bridging methodological innovations and practical\napplications, this work offers a roadmap for developing robust, adaptive models\nfor signal intelligence.",
      "tldr_zh": "这篇综述论文探讨了无监督学习在时间序列信号分析中的进展，重点审视 Autoencoders 和 Vision Transformers 的架构及其在无线通信、雷达、生物医学工程和 IoT 等领域的应用。论文总结了这些模型在特征提取、异常检测和分类方面的能力，特别是通过混合架构和自监督学习来处理多样化信号类型，如心电图和传感器数据。最终，它突出了这些方法的优势，同时指出了可解释性、可扩展性和领域泛化等挑战，并为开发鲁棒的自适应信号智能模型提供路线图。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16972v1",
      "published_date": "2025-04-23 15:19:12 UTC",
      "updated_date": "2025-04-23 15:19:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:57:48.745978"
    },
    {
      "arxiv_id": "2504.16795v1",
      "title": "Random Long-Context Access for Mamba via Hardware-aligned Hierarchical Sparse Attention",
      "title_zh": "通过硬件对齐的层次稀疏注意力实现的 Mamba 随机长上下文访问",
      "authors": [
        "Xiang Hu",
        "Jiaqi Leng",
        "Jun Zhao",
        "Kewei Tu",
        "Wei Wu"
      ],
      "abstract": "A key advantage of Recurrent Neural Networks (RNNs) over Transformers is\ntheir linear computational and space complexity enables faster training and\ninference for long sequences. However, RNNs are fundamentally unable to\nrandomly access historical context, and simply integrating attention mechanisms\nmay undermine their efficiency advantages. To overcome this limitation, we\npropose \\textbf{H}ierarchical \\textbf{S}parse \\textbf{A}ttention (HSA), a novel\nattention mechanism that enhances RNNs with long-range random access\nflexibility while preserving their merits in efficiency and length\ngeneralization. HSA divides inputs into chunks, selecting the top-$k$ chunks\nand hierarchically aggregates information. The core innovation lies in learning\ntoken-to-chunk relevance based on fine-grained token-level information inside\neach chunk. This approach enhances the precision of chunk selection across both\nin-domain and out-of-domain context lengths. To make HSA efficient, we further\nintroduce a hardware-aligned kernel design. By combining HSA with Mamba, we\nintroduce RAMba, which achieves perfect accuracy in passkey retrieval across 64\nmillion contexts despite pre-training on only 4K-length contexts, and\nsignificant improvements on various downstream tasks, with nearly constant\nmemory footprint. These results show RAMba's huge potential in long-context\nmodeling.",
      "tldr_zh": "本研究针对RNNs在长序列处理中的随机访问限制，提出了一种硬件对齐的Hierarchical Sparse Attention (HSA)机制，以提升其效率和灵活性。HSA通过将输入分成块、选择top-k块并基于块内细粒度token-level信息学习token-to-chunk相关性，实现长范围随机访问，同时保持线性计算复杂度和长度泛化优势。结合HSA与Mamba模型，该团队开发了RAMba，能够在仅预训练于4K长度上下文中，实现64百万长度上下文的完美passkey检索，并在各种下游任务上显著提升性能，同时内存占用几乎不变。这些结果突显了RAMba在长上下文建模中的巨大潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "preprint",
      "pdf_url": "http://arxiv.org/pdf/2504.16795v1",
      "published_date": "2025-04-23 15:15:06 UTC",
      "updated_date": "2025-04-23 15:15:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:58:00.326115"
    },
    {
      "arxiv_id": "2504.16791v1",
      "title": "Radiometer Calibration using Machine Learning",
      "title_zh": "使用机器学习的辐射计校准",
      "authors": [
        "S. A. K. Leeney",
        "H. T. J. Bevins",
        "E. de Lera Acedo",
        "W. J. Handley",
        "C. Kirkham",
        "R. S. Patel",
        "J. Zhu",
        "D. Molnar",
        "J. Cumner",
        "D. Anstey",
        "K. Artuc",
        "G. Bernardi",
        "M. Bucher",
        "S. Carey",
        "J. Cavillot",
        "R. Chiello",
        "W. Croukamp",
        "D. I. L. de Villiers",
        "J. A. Ely",
        "A. Fialkov",
        "T. Gessey-Jones",
        "G. Kulkarni",
        "A. Magro",
        "P. D. Meerburg",
        "S. Mittal",
        "J. H. N. Pattison",
        "S. Pegwal",
        "C. M. Pieterse",
        "J. R. Pritchard",
        "E. Puchwein",
        "N. Razavi-Ghods",
        "I. L. V. Roque",
        "A. Saxena",
        "K. H. Scheutwinkel",
        "P. Scott",
        "E. Shen",
        "P. H. Sims",
        "M. Spinelli"
      ],
      "abstract": "Radiometers are crucial instruments in radio astronomy, forming the primary\ncomponent of nearly all radio telescopes. They measure the intensity of\nelectromagnetic radiation, converting this radiation into electrical signals. A\nradiometer's primary components are an antenna and a Low Noise Amplifier (LNA),\nwhich is the core of the ``receiver'' chain. Instrumental effects introduced by\nthe receiver are typically corrected or removed during calibration. However,\nimpedance mismatches between the antenna and receiver can introduce unwanted\nsignal reflections and distortions. Traditional calibration methods, such as\nDicke switching, alternate the receiver input between the antenna and a\nwell-characterised reference source to mitigate errors by comparison. Recent\nadvances in Machine Learning (ML) offer promising alternatives. Neural\nnetworks, which are trained using known signal sources, provide a powerful\nmeans to model and calibrate complex systems where traditional analytical\napproaches struggle. These methods are especially relevant for detecting the\nfaint sky-averaged 21-cm signal from atomic hydrogen at high redshifts. This is\none of the main challenges in observational Cosmology today. Here, for the\nfirst time, we introduce and test a machine learning-based calibration\nframework capable of achieving the precision required for radiometric\nexperiments aiming to detect the 21-cm line.",
      "tldr_zh": "这篇论文探讨了使用机器学习(Machine Learning)来校准辐射计(Radiometer)，以解决传统方法如Dicke switching在处理天线和低噪声放大器(LNA)阻抗失配导致的信号反射和失真问题。作者引入了一个基于神经网络(Neural networks)的校准框架，通过训练已知信号源来建模复杂系统，实现更精确的校准。实验结果表明，该框架首次达到了检测高红移原子氢的21-cm信号所需的精度，为观测宇宙学中的关键挑战提供了新工具。",
      "categories": [
        "astro-ph.IM",
        "astro-ph.CO",
        "cs.AI"
      ],
      "primary_category": "astro-ph.IM",
      "comment": "Under peer review for publication in Nature Scientific Reports as\n  part of the Radio Astronomy collection",
      "pdf_url": "http://arxiv.org/pdf/2504.16791v1",
      "published_date": "2025-04-23 15:10:25 UTC",
      "updated_date": "2025-04-23 15:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:58:12.920238"
    },
    {
      "arxiv_id": "2504.16788v1",
      "title": "Towards Explainable AI: Multi-Modal Transformer for Video-based Image Description Generation",
      "title_zh": "迈向可解释 AI：多模态 Transformer 用于基于视频的图像描述生成",
      "authors": [
        "Lakshita Agarwal",
        "Bindu Verma"
      ],
      "abstract": "Understanding and analyzing video actions are essential for producing\ninsightful and contextualized descriptions, especially for video-based\napplications like intelligent monitoring and autonomous systems. The proposed\nwork introduces a novel framework for generating natural language descriptions\nfrom video datasets by combining textual and visual modalities. The suggested\narchitecture makes use of ResNet50 to extract visual features from video frames\nthat are taken from the Microsoft Research Video Description Corpus (MSVD), and\nBerkeley DeepDrive eXplanation (BDD-X) datasets. The extracted visual\ncharacteristics are converted into patch embeddings and then run through an\nencoder-decoder model based on Generative Pre-trained Transformer-2 (GPT-2). In\norder to align textual and visual representations and guarantee high-quality\ndescription production, the system uses multi-head self-attention and\ncross-attention techniques. The model's efficacy is demonstrated by performance\nevaluation using BLEU (1-4), CIDEr, METEOR, and ROUGE-L. The suggested\nframework outperforms traditional methods with BLEU-4 scores of 0.755 (BDD-X)\nand 0.778 (MSVD), CIDEr scores of 1.235 (BDD-X) and 1.315 (MSVD), METEOR scores\nof 0.312 (BDD-X) and 0.329 (MSVD), and ROUGE-L scores of 0.782 (BDD-X) and\n0.795 (MSVD). By producing human-like, contextually relevant descriptions,\nstrengthening interpretability, and improving real-world applications, this\nresearch advances explainable AI.",
      "tldr_zh": "本研究提出了一种多模态Transformer框架，用于从视频生成自然语言描述，从而提升AI的可解释性。该框架结合文本和视觉模式，使用ResNet50从Microsoft Research Video Description Corpus (MSVD)和Berkeley DeepDrive eXplanation (BDD-X)数据集的视频帧中提取视觉特征，并通过基于Generative Pre-trained Transformer-2 (GPT-2)的encoder-decoder模型处理这些特征，同时采用multi-head self-attention和cross-attention机制来对齐文本和视觉表示。实验结果显示，该框架在BLEU-4、CIDEr、METEOR和ROUGE-L指标上均优于传统方法，例如在MSVD数据集上BLEU-4得分为0.778、CIDEr得分为1.315。通过生成更接近人类的上下文相关描述，该工作推动了explainable AI在智能监控和自主系统中的应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16788v1",
      "published_date": "2025-04-23 15:03:37 UTC",
      "updated_date": "2025-04-23 15:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:58:25.057417"
    },
    {
      "arxiv_id": "2504.16787v1",
      "title": "Credible plan-driven RAG method for Multi-hop Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Ningning Zhang",
        "Chi Zhang",
        "Zhizhong Tan",
        "Xingxing Yang",
        "Weiping Deng",
        "Wenyong Wang"
      ],
      "abstract": "Multi-hop question answering (QA) presents a considerable challenge for\nRetrieval-Augmented Generation (RAG), requiring the structured decomposition of\ncomplex queries into logical reasoning paths and the generation of dependable\nintermediate results. However, deviations in reasoning paths or errors in\nintermediate results, which are common in current RAG methods, may propagate\nand accumulate throughout the reasoning process, diminishing the accuracy of\nthe answer to complex queries. To address this challenge, we propose the\nPlan-then-Act-and-Review (PAR RAG) framework, which is organized into three key\nstages: planning, act, and review, and aims to offer an interpretable and\nincremental reasoning paradigm for accurate and reliable multi-hop question\nanswering by mitigating error propagation.PAR RAG initially applies a top-down\nproblem decomposition strategy, formulating a comprehensive plan that\nintegrates multiple executable steps from a holistic viewpoint. This approach\navoids the pitfalls of local optima common in traditional RAG methods, ensuring\nthe accuracy of the entire reasoning path. Subsequently, PAR RAG incorporates a\nplan execution mechanism based on multi-granularity verification. By utilizing\nboth coarse-grained similarity information and fine-grained relevant data, the\nframework thoroughly checks and adjusts intermediate results, ensuring process\naccuracy while effectively managing error propagation and amplification.\nExperimental results on multi-hop QA datasets demonstrate that the PAR RAG\nframework substantially outperforms existing state-of-the-art methods in key\nmetrics, including EM and F1 scores.",
      "tldr_zh": "本研究针对多跳问答（Multi-hop Question Answering）中的挑战，提出了一种可靠的计划驱动检索增强生成（RAG）方法，即 Plan-then-Act-and-Review (PAR RAG) 框架，以减少推理路径偏差和中间结果错误导致的错误传播。该框架分为三个关键阶段：规划阶段采用顶-down 问题分解策略，制定全面的执行步骤计划，避免传统 RAG 方法的局部最优问题；行动阶段通过多粒度验证（如粗粒度相似性和细粒度相关数据）执行计划并检查调整中间结果；审查阶段确保整个推理过程的准确性和可靠性。在多跳 QA 数据集上的实验显示，PAR RAG 在 EM 和 F1 scores 等关键指标上大幅优于现有最先进方法，提供了一种可解释的增量推理范式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16787v1",
      "published_date": "2025-04-23 15:03:17 UTC",
      "updated_date": "2025-04-23 15:03:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:58:37.110195"
    },
    {
      "arxiv_id": "2504.16778v2",
      "title": "Evaluation Framework for AI Systems in \"the Wild\"",
      "title_zh": "针对“野外”中人工智能系统的评估框架",
      "authors": [
        "Sarah Jabbour",
        "Trenton Chang",
        "Anindya Das Antar",
        "Joseph Peper",
        "Insu Jang",
        "Jiachen Liu",
        "Jae-Won Chung",
        "Shiqi He",
        "Michael Wellman",
        "Bryan Goodman",
        "Elizabeth Bondi-Kelly",
        "Kevin Samy",
        "Rada Mihalcea",
        "Mosharaf Chowdhury",
        "David Jurgens",
        "Lu Wang"
      ],
      "abstract": "Generative AI (GenAI) models have become vital across industries, yet current\nevaluation methods have not adapted to their widespread use. Traditional\nevaluations often rely on benchmarks and fixed datasets, frequently failing to\nreflect real-world performance, which creates a gap between lab-tested outcomes\nand practical applications. This white paper proposes a comprehensive framework\nfor how we should evaluate real-world GenAI systems, emphasizing diverse,\nevolving inputs and holistic, dynamic, and ongoing assessment approaches. The\npaper offers guidance for practitioners on how to design evaluation methods\nthat accurately reflect real-time capabilities, and provides policymakers with\nrecommendations for crafting GenAI policies focused on societal impacts, rather\nthan fixed performance numbers or parameter sizes. We advocate for holistic\nframeworks that integrate performance, fairness, and ethics and the use of\ncontinuous, outcome-oriented methods that combine human and automated\nassessments while also being transparent to foster trust among stakeholders.\nImplementing these strategies ensures GenAI models are not only technically\nproficient but also ethically responsible and impactful.",
      "tldr_zh": "这篇白皮书指出，传统评估方法依赖基准和固定数据集，无法准确反映生成式 AI (GenAI) 模型的真实世界性能，导致实验室结果与实际应用脱节。论文提出一个全面的评估框架，强调多样化输入、动态持续评估，并整合性能、公平性和伦理因素。框架为从业者提供设计实时评估方法的指导，并为政策制定者推荐关注社会影响的政策建议。通过结合人类和自动化评估以及透明机制，该方法确保 GenAI 模型在技术能力、伦理责任和实际影响力方面实现平衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "35 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.16778v2",
      "published_date": "2025-04-23 14:52:39 UTC",
      "updated_date": "2025-04-28 15:12:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:58:48.810908"
    },
    {
      "arxiv_id": "2504.16768v1",
      "title": "How Effective are Generative Large Language Models in Performing Requirements Classification?",
      "title_zh": "生成式大语言模型在进行需求分类任务中的有效性如何？",
      "authors": [
        "Waad Alhoshan",
        "Alessio Ferrari",
        "Liping Zhao"
      ],
      "abstract": "In recent years, transformer-based large language models (LLMs) have\nrevolutionised natural language processing (NLP), with generative models\nopening new possibilities for tasks that require context-aware text generation.\nRequirements engineering (RE) has also seen a surge in the experimentation of\nLLMs for different tasks, including trace-link detection, regulatory\ncompliance, and others. Requirements classification is a common task in RE.\nWhile non-generative LLMs like BERT have been successfully applied to this\ntask, there has been limited exploration of generative LLMs. This gap raises an\nimportant question: how well can generative LLMs, which produce context-aware\noutputs, perform in requirements classification? In this study, we explore the\neffectiveness of three generative LLMs-Bloom, Gemma, and Llama-in performing\nboth binary and multi-class requirements classification. We design an extensive\nexperimental study involving over 400 experiments across three widely used\ndatasets (PROMISE NFR, Functional-Quality, and SecReq). Our study concludes\nthat while factors like prompt design and LLM architecture are universally\nimportant, others-such as dataset variations-have a more situational impact,\ndepending on the complexity of the classification task. This insight can guide\nfuture model development and deployment strategies, focusing on optimising\nprompt structures and aligning model architectures with task-specific needs for\nimproved performance.",
      "tldr_zh": "本研究探讨了生成式大型语言模型（LLMs）在需求工程（RE）中的需求分类任务的有效性，特别是与非生成式模型如BERT相比。研究团队通过超过400次实验，评估了Bloom、Gemma和Llama三个模型在PROMISE NFR、Functional-Quality和SecReq数据集上的二元和多类分类性能。结果显示，提示设计和LLM架构是影响性能的关键因素，而数据集变化的影响则取决于任务复杂度，这为未来模型开发提供了优化提示结构和架构的指导策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16768v1",
      "published_date": "2025-04-23 14:41:11 UTC",
      "updated_date": "2025-04-23 14:41:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:59:01.204283"
    },
    {
      "arxiv_id": "2504.16763v1",
      "title": "Noise-Tolerant Coreset-Based Class Incremental Continual Learning",
      "title_zh": "噪声容忍的基于核心集的类增量持续学习",
      "authors": [
        "Edison Mucllari",
        "Aswin Raghavan",
        "Zachary Alan Daniels"
      ],
      "abstract": "Many applications of computer vision require the ability to adapt to novel\ndata distributions after deployment. Adaptation requires algorithms capable of\ncontinual learning (CL). Continual learners must be plastic to adapt to novel\ntasks while minimizing forgetting of previous tasks.However, CL opens up\navenues for noise to enter the training pipeline and disrupt the CL. This work\nfocuses on label noise and instance noise in the context of class-incremental\nlearning (CIL), where new classes are added to a classifier over time, and\nthere is no access to external data from past classes. We aim to understand the\nsensitivity of CL methods that work by replaying items from a memory\nconstructed using the idea of Coresets. We derive a new bound for the\nrobustness of such a method to uncorrelated instance noise under a general\nadditive noise threat model, revealing several insights. Putting the theory\ninto practice, we create two continual learning algorithms to construct\nnoise-tolerant replay buffers. We empirically compare the effectiveness of\nprior memory-based continual learners and the proposed algorithms under label\nand uncorrelated instance noise on five diverse datasets. We show that existing\nmemory-based CL are not robust whereas the proposed methods exhibit significant\nimprovements in maximizing classification accuracy and minimizing forgetting in\nthe noisy CIL setting.",
      "tldr_zh": "该论文探讨了类别增量学习(Class-Incremental Learning, CIL)中的噪声问题，旨在解决持续学习(Continual Learning, CL)模型在适应新任务时面临的标签噪声(label noise)和实例噪声(instance noise)挑战。研究者推导了一个新的鲁棒性边界，针对基于 Coresets 的内存回放方法在 uncorrelated instance noise 下的表现，并据此开发了两个噪声耐受的回放缓冲区算法。实验结果显示，这些新算法在五个多样数据集上显著提高了分类准确率并最小化了遗忘，而现有内存-based CL 方法则表现出较低的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Work-in-Progress",
      "pdf_url": "http://arxiv.org/pdf/2504.16763v1",
      "published_date": "2025-04-23 14:34:20 UTC",
      "updated_date": "2025-04-23 14:34:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:59:17.947047"
    },
    {
      "arxiv_id": "2504.16760v1",
      "title": "Lightweight Latent Verifiers for Efficient Meta-Generation Strategies",
      "title_zh": "用于高效元生成策略的轻量级潜在验证器",
      "authors": [
        "Bartosz Piotrowski",
        "Witold Drzewakowski",
        "Konrad Staniszewski",
        "Piotr Miłoś"
      ],
      "abstract": "Verifiers are auxiliary models that assess the correctness of outputs\ngenerated by base large language models (LLMs). They play a crucial role in\nmany strategies for solving reasoning-intensive problems with LLMs. Typically,\nverifiers are LLMs themselves, often as large (or larger) than the base model\nthey support, making them computationally expensive. In this work, we introduce\na novel lightweight verification approach, LiLaVe, which reliably extracts\ncorrectness signals from the hidden states of the base LLM. A key advantage of\nLiLaVe is its ability to operate with only a small fraction of the\ncomputational budget required by traditional LLM-based verifiers. To\ndemonstrate its practicality, we couple LiLaVe with popular meta-generation\nstrategies, like best-of-n or self-consistency. Moreover, we design novel\nLiLaVe-based approaches, like conditional self-correction or conditional\nmajority voting, that significantly improve both accuracy and efficiency in\ngeneration tasks with smaller LLMs. Our work demonstrates the fruitfulness of\nextracting latent information from the hidden states of LLMs, and opens the\ndoor to scalable and resource-efficient solutions for reasoning-intensive\napplications.",
      "tldr_zh": "本文提出 LiLaVe，一种轻量级验证方法，通过从 base LLM 的隐藏状态中提取正确性信号，显著减少了传统 LLM-based verifiers 的计算开销。LiLaVe 与 best-of-n 或 self-consistency 等元生成策略结合，并设计了新方法如 conditional self-correction 和 conditional majority voting，提高了生成任务的准确性和效率，尤其适用于小型 LLMs。实验结果表明，这种方法为推理密集型应用提供了可扩展且资源高效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16760v1",
      "published_date": "2025-04-23 14:33:20 UTC",
      "updated_date": "2025-04-23 14:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:59:25.262366"
    },
    {
      "arxiv_id": "2504.16754v1",
      "title": "HEMA : A Hippocampus-Inspired Extended Memory Architecture for Long-Context AI Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Kwangseob Ahn"
      ],
      "abstract": "Large language models (LLMs) struggle with maintaining coherence in extended\nconversations spanning hundreds of turns, despite performing well within their\ncontext windows. This paper introduces HEMA (Hippocampus-Inspired Extended\nMemory Architecture), a dual-memory system inspired by human cognitive\nprocesses. HEMA combines Compact Memory - a continuously updated one-sentence\nsummary preserving global narrative coherence, and Vector Memory - an episodic\nstore of chunk embeddings queried via cosine similarity. When integrated with a\n6B-parameter transformer, HEMA maintains coherent dialogues beyond 300 turns\nwhile keeping prompt length under 3,500 tokens. Experimental results show\nsubstantial improvements: factual recall accuracy increases from 41% to 87%,\nand human-rated coherence improves from 2.7 to 4.3 on a 5-point scale. With 10K\nindexed chunks, Vector Memory achieves P@5 >= 0.80 and R@50 >= 0.74, doubling\nthe area under the precision-recall curve compared to summarization-only\napproaches. Ablation studies reveal two key insights: semantic forgetting\nthrough age-weighted pruning reduces retrieval latency by 34% with minimal\nrecall loss, and a two-level summary hierarchy prevents cascade errors in\nultra-long conversations exceeding 1,000 turns. HEMA demonstrates that\ncombining verbatim recall with semantic continuity provides a practical\nsolution for privacy-aware conversational AI capable of month-long dialogues\nwithout model retraining.",
      "tldr_zh": "这篇论文提出 HEMA（Hippocampus-Inspired Extended Memory Architecture），一种受人类认知启发的双重内存系统，用于提升大型语言模型 (LLMs) 在长对话中的连贯性，包括 Compact Memory（持续更新的单句摘要以保持全局叙事）和 Vector Memory（基于余弦相似度的块嵌入存储）。通过与 6B 参数 Transformer 整合，HEMA 能在超过 300 轮对话中维持提示长度低于 3,500 tokens。实验结果显示，事实回忆准确率从 41% 提高到 87%，人类评级连贯性从 2.7 提升到 4.3（5 分制），并在 10K 块索引下实现 P@5 >= 0.80 和 R@50 >= 0.74，同时通过年龄加权修剪减少检索延迟 34%。整体而言，HEMA 提供了一种无需模型重新训练的隐私友好方案，支持数月的超长对话。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16754v1",
      "published_date": "2025-04-23 14:27:12 UTC",
      "updated_date": "2025-04-23 14:27:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:59:39.095414"
    },
    {
      "arxiv_id": "2504.16738v1",
      "title": "MOSAIC: A Skill-Centric Algorithmic Framework for Long-Horizon Manipulation Planning",
      "title_zh": "MOSAIC：以技能为中心的算法框架，用于长时域操作规划",
      "authors": [
        "Itamar Mishani",
        "Yorai Shaoul",
        "Maxim Likhachev"
      ],
      "abstract": "Planning long-horizon motions using a set of predefined skills is a key\nchallenge in robotics and AI. Addressing this challenge requires methods that\nsystematically explore skill combinations to uncover task-solving sequences,\nharness generic, easy-to-learn skills (e.g., pushing, grasping) to generalize\nacross unseen tasks, and bypass reliance on symbolic world representations that\ndemand extensive domain and task-specific knowledge. Despite significant\nprogress, these elements remain largely disjoint in existing approaches,\nleaving a critical gap in achieving robust, scalable solutions for complex,\nlong-horizon problems. In this work, we present MOSAIC, a skill-centric\nframework that unifies these elements by using the skills themselves to guide\nthe planning process. MOSAIC uses two families of skills: Generators compute\nexecutable trajectories and world configurations, and Connectors link these\nindependently generated skill trajectories by solving boundary value problems,\nenabling progress toward completing the overall task. By breaking away from the\nconventional paradigm of incrementally discovering skills from predefined start\nor goal states--a limitation that significantly restricts exploration--MOSAIC\nfocuses planning efforts on regions where skills are inherently effective. We\ndemonstrate the efficacy of MOSAIC in both simulated and real-world robotic\nmanipulation tasks, showcasing its ability to solve complex long-horizon\nplanning problems using a diverse set of skills incorporating generative\ndiffusion models, motion planning algorithms, and manipulation-specific models.\nVisit https://skill-mosaic.github.io for demonstrations and examples.",
      "tldr_zh": "本研究提出MOSAIC，一种以技能为核心的算法框架，用于解决机器人和AI领域长时域操作规划(long-horizon manipulation planning)的挑战，该框架系统探索技能组合、利用通用技能（如pushing和grasping）实现任务泛化，并避免依赖符号世界表示。MOSAIC包括两种技能家族：Generators负责计算可执行轨迹和世界配置，Connectors通过解决边界值问题连接这些轨迹，从而引导规划过程并专注于技能有效的区域。在模拟和真实世界机器人任务中，MOSAIC证明了其有效性，能够处理复杂长时域问题，使用生成扩散模型、运动规划算法等多样技能进行规划。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review. Project page: https://skill-mosaic.github.io",
      "pdf_url": "http://arxiv.org/pdf/2504.16738v1",
      "published_date": "2025-04-23 14:09:42 UTC",
      "updated_date": "2025-04-23 14:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T15:59:48.585822"
    },
    {
      "arxiv_id": "2504.16736v2",
      "title": "A Survey of AI Agent Protocols",
      "title_zh": "AI 智能体协议的综述",
      "authors": [
        "Yingxuan Yang",
        "Huacan Chai",
        "Yuanyi Song",
        "Siyuan Qi",
        "Muning Wen",
        "Ning Li",
        "Junwei Liao",
        "Haoyi Hu",
        "Jianghao Lin",
        "Gaowei Chang",
        "Weiwen Liu",
        "Ying Wen",
        "Yong Yu",
        "Weinan Zhang"
      ],
      "abstract": "The rapid development of large language models (LLMs) has led to the\nwidespread deployment of LLM agents across diverse industries, including\ncustomer service, content generation, data analysis, and even healthcare.\nHowever, as more LLM agents are deployed, a major issue has emerged: there is\nno standard way for these agents to communicate with external tools or data\nsources. This lack of standardized protocols makes it difficult for agents to\nwork together or scale effectively, and it limits their ability to tackle\ncomplex, real-world tasks. A unified communication protocol for LLM agents\ncould change this. It would allow agents and tools to interact more smoothly,\nencourage collaboration, and triggering the formation of collective\nintelligence. In this paper, we provide the first comprehensive analysis of\nexisting agent protocols, proposing a systematic two-dimensional classification\nthat differentiates context-oriented versus inter-agent protocols and\ngeneral-purpose versus domain-specific protocols. Additionally, we conduct a\ncomparative performance analysis of these protocols across key dimensions such\nas security, scalability, and latency. Finally, we explore the future landscape\nof agent protocols by identifying critical research directions and\ncharacteristics necessary for next-generation protocols. These characteristics\ninclude adaptability, privacy preservation, and group-based interaction, as\nwell as trends toward layered architectures and collective intelligence\ninfrastructures. We expect this work to serve as a practical reference for both\nresearchers and engineers seeking to design, evaluate, or integrate robust\ncommunication infrastructures for intelligent agents.",
      "tldr_zh": "该论文调查了AI代理协议，针对大型语言模型 (LLMs) 代理在客服、内容生成和医疗等领域部署时，缺乏标准通信方式的问题，强调统一协议可提升代理协作和扩展性。作者首次提出系统化的两维分类（context-oriented 与 inter-agent，general-purpose 与 domain-specific），并对现有协议进行性能比较，包括 security、scalability 和 latency 维度。论文还探讨了未来研究方向，如 adaptability、privacy preservation 和集体智能 (collective intelligence) 基础设施，为设计和集成代理通信系统提供实用参考。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16736v2",
      "published_date": "2025-04-23 14:07:26 UTC",
      "updated_date": "2025-04-26 15:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:00:01.080468"
    },
    {
      "arxiv_id": "2504.16728v1",
      "title": "IRIS: Interactive Research Ideation System for Accelerating Scientific Discovery",
      "title_zh": "IRIS：交互式研究构想系统，用于加速科学发现",
      "authors": [
        "Aniketh Garikaparthi",
        "Manasi Patwardhan",
        "Lovekesh Vig",
        "Arman Cohan"
      ],
      "abstract": "The rapid advancement in capabilities of large language models (LLMs) raises\na pivotal question: How can LLMs accelerate scientific discovery? This work\ntackles the crucial first stage of research, generating novel hypotheses. While\nrecent work on automated hypothesis generation focuses on multi-agent\nframeworks and extending test-time compute, none of the approaches effectively\nincorporate transparency and steerability through a synergistic\nHuman-in-the-loop (HITL) approach. To address this gap, we introduce IRIS:\nInteractive Research Ideation System, an open-source platform designed for\nresearchers to leverage LLM-assisted scientific ideation. IRIS incorporates\ninnovative features to enhance ideation, including adaptive test-time compute\nexpansion via Monte Carlo Tree Search (MCTS), fine-grained feedback mechanism,\nand query-based literature synthesis. Designed to empower researchers with\ngreater control and insight throughout the ideation process. We additionally\nconduct a user study with researchers across diverse disciplines, validating\nthe effectiveness of our system in enhancing ideation. We open-source our code\nat https://github.com/Anikethh/IRIS-Interactive-Research-Ideation-System",
      "tldr_zh": "该研究探讨如何利用大型语言模型(LLMs)加速科学发现，特别针对生成新假设的初始阶段。论文引入IRIS（Interactive Research Ideation System），一个开源平台，通过Human-in-the-loop (HITL)方法增强透明度和可控性，结合Monte Carlo Tree Search (MCTS)进行自适应测试时计算扩展、细粒度反馈机制以及基于查询的文献合成。用户研究证实，IRIS在多学科中显著提升了研究构想过程的有效性，为LLMs在科学领域的应用提供了实用工具。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages main-text, 2 pages appendix",
      "pdf_url": "http://arxiv.org/pdf/2504.16728v1",
      "published_date": "2025-04-23 14:01:36 UTC",
      "updated_date": "2025-04-23 14:01:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:00:12.439554"
    },
    {
      "arxiv_id": "2504.16727v2",
      "title": "V$^2$R-Bench: Holistically Evaluating LVLM Robustness to Fundamental Visual Variations",
      "title_zh": "V$^2$R-Bench：整体评估 LVLM 对基本视觉变化的鲁棒性",
      "authors": [
        "Zhiyuan Fan",
        "Yumeng Wang",
        "Sandeep Polisetty",
        "Yi R. Fung"
      ],
      "abstract": "Large Vision Language Models (LVLMs) excel in various vision-language tasks.\nYet, their robustness to visual variations in position, scale, orientation, and\ncontext that objects in natural scenes inevitably exhibit due to changes in\nviewpoint and environment remains largely underexplored. To bridge this gap, we\nintroduce V$^2$R-Bench, a comprehensive benchmark framework for evaluating\nVisual Variation Robustness of LVLMs, which encompasses automated evaluation\ndataset generation and principled metrics for thorough robustness assessment.\nThrough extensive evaluation on 21 LVLMs, we reveal a surprising vulnerability\nto visual variations, in which even advanced models that excel at complex\nvision-language tasks significantly underperform on simple tasks such as object\nrecognition. Interestingly, these models exhibit a distinct visual position\nbias that contradicts theories of effective receptive fields, and demonstrate a\nhuman-like visual acuity threshold. To identify the source of these\nvulnerabilities, we present a systematic framework for component-level\nanalysis, featuring a novel visualization approach for aligned visual features.\nResults show that these vulnerabilities stem from error accumulation in the\npipeline architecture and inadequate multimodal alignment. Complementary\nexperiments with synthetic data further demonstrate that these limitations are\nfundamentally architectural deficiencies, scoring the need for architectural\ninnovations in future LVLM designs.",
      "tldr_zh": "本文提出 V$^2$R-Bench，这是一个全面的基准框架，用于评估大型视觉语言模型 (LVLMs) 对视觉变化（如位置、规模、方向和上下文）的鲁棒性，包括自动数据集生成和原则性评估指标。通过对 21 个 LVLMs 的广泛评估，发现这些模型对视觉变化高度脆弱，即使在复杂任务上表现出色，在简单物体识别任务上也显著表现不佳，并显示出与有效感受野理论相悖的视觉位置偏差和人类-like 视觉敏锐度阈值。进一步的组件级分析框架和新型可视化方法揭示，这些问题源于管道架构中的错误积累和多模态对齐不足，强调了未来 LVLM 设计需要根本性的架构创新。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16727v2",
      "published_date": "2025-04-23 14:01:32 UTC",
      "updated_date": "2025-04-24 02:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:00:46.294840"
    },
    {
      "arxiv_id": "2504.21027v1",
      "title": "UrbanPlanBench: A Comprehensive Urban Planning Benchmark for Evaluating Large Language Models",
      "title_zh": "UrbanPlanBench：用于评估大型语言模型的全面城市规划基准",
      "authors": [
        "Yu Zheng",
        "Longyi Liu",
        "Yuming Lin",
        "Jie Feng",
        "Guozhen Zhang",
        "Depeng Jin",
        "Yong Li"
      ],
      "abstract": "The advent of Large Language Models (LLMs) holds promise for revolutionizing\nvarious fields traditionally dominated by human expertise. Urban planning, a\nprofessional discipline that fundamentally shapes our daily surroundings, is\none such field heavily relying on multifaceted domain knowledge and experience\nof human experts. The extent to which LLMs can assist human practitioners in\nurban planning remains largely unexplored. In this paper, we introduce a\ncomprehensive benchmark, UrbanPlanBench, tailored to evaluate the efficacy of\nLLMs in urban planning, which encompasses fundamental principles, professional\nknowledge, and management and regulations, aligning closely with the\nqualifications expected of human planners. Through extensive evaluation, we\nreveal a significant imbalance in the acquisition of planning knowledge among\nLLMs, with even the most proficient models falling short of meeting\nprofessional standards. For instance, we observe that 70% of LLMs achieve\nsubpar performance in understanding planning regulations compared to other\naspects. Besides the benchmark, we present the largest-ever supervised\nfine-tuning (SFT) dataset, UrbanPlanText, comprising over 30,000 instruction\npairs sourced from urban planning exams and textbooks. Our findings demonstrate\nthat fine-tuned models exhibit enhanced performance in memorization tests and\ncomprehension of urban planning knowledge, while there exists significant room\nfor improvement, particularly in tasks requiring domain-specific terminology\nand reasoning. By making our benchmark, dataset, and associated evaluation and\nfine-tuning toolsets publicly available at\nhttps://github.com/tsinghua-fib-lab/PlanBench, we aim to catalyze the\nintegration of LLMs into practical urban planning, fostering a symbiotic\ncollaboration between human expertise and machine intelligence.",
      "tldr_zh": "本文引入了 UrbanPlanBench，这是一个全面的基准，用于评估大型语言模型（LLMs）在城市规划领域的效能，涵盖基本原则、专业知识、管理和法规，以对齐人类规划师的标准。评估结果显示，LLMs 在规划知识获取上存在显著不平衡，例如70%的模型在理解规划法规方面表现较差，即使顶级模型也未达到专业水平。此外，作者构建了最大的监督微调（SFT）数据集 UrbanPlanText，包含超过30,000个指令对，微调后模型在记忆测试和知识理解方面有所提升，但领域特定术语和推理任务仍需进一步改进。通过公开基准、数据集和工具，论文旨在促进 LLMs 与人类专家的协同应用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21027v1",
      "published_date": "2025-04-23 13:53:59 UTC",
      "updated_date": "2025-04-23 13:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:00:38.424959"
    },
    {
      "arxiv_id": "2504.16723v1",
      "title": "Detecting and Understanding Hateful Contents in Memes Through Captioning and Visual Question-Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Anaissi",
        "Junaid Akram",
        "Kunal Chaturvedi",
        "Ali Braytee"
      ],
      "abstract": "Memes are widely used for humor and cultural commentary, but they are\nincreasingly exploited to spread hateful content. Due to their multimodal\nnature, hateful memes often evade traditional text-only or image-only detection\nsystems, particularly when they employ subtle or coded references. To address\nthese challenges, we propose a multimodal hate detection framework that\nintegrates key components: OCR to extract embedded text, captioning to describe\nvisual content neutrally, sub-label classification for granular categorization\nof hateful content, RAG for contextually relevant retrieval, and VQA for\niterative analysis of symbolic and contextual cues. This enables the framework\nto uncover latent signals that simpler pipelines fail to detect. Experimental\nresults on the Facebook Hateful Memes dataset reveal that the proposed\nframework exceeds the performance of unimodal and conventional multimodal\nmodels in both accuracy and AUC-ROC.",
      "tldr_zh": "该论文针对 memes 中仇恨内容的检测和理解问题，提出一个多模态框架，以应对传统文本或图像单模态系统的局限性。该框架整合 OCR 提取嵌入文本、captioning 中性描述视觉内容、sub-label classification 细化仇恨分类、RAG 检索相关上下文，以及 VQA 进行迭代分析符号和语境线索，从而揭示传统方法忽略的潜在仇恨信号。在 Facebook Hateful Memes 数据集上的实验显示，该框架在准确率和 AUC-ROC 指标上均优于单模态和常规多模态模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "13 pages, 2 figures, 2025 International Conference on Computational\n  Science",
      "pdf_url": "http://arxiv.org/pdf/2504.16723v1",
      "published_date": "2025-04-23 13:52:14 UTC",
      "updated_date": "2025-04-23 13:52:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:00:49.314282"
    },
    {
      "arxiv_id": "2504.16722v1",
      "title": "PMG: Progressive Motion Generation via Sparse Anchor Postures Curriculum Learning",
      "title_zh": "PMG：基于",
      "authors": [
        "Yingjie Xi",
        "Jian Jun Zhang",
        "Xiaosong Yang"
      ],
      "abstract": "In computer animation, game design, and human-computer interaction,\nsynthesizing human motion that aligns with user intent remains a significant\nchallenge. Existing methods have notable limitations: textual approaches offer\nhigh-level semantic guidance but struggle to describe complex actions\naccurately; trajectory-based techniques provide intuitive global motion\ndirection yet often fall short in generating precise or customized character\nmovements; and anchor poses-guided methods are typically confined to synthesize\nonly simple motion patterns. To generate more controllable and precise human\nmotions, we propose \\textbf{ProMoGen (Progressive Motion Generation)}, a novel\nframework that integrates trajectory guidance with sparse anchor motion\ncontrol. Global trajectories ensure consistency in spatial direction and\ndisplacement, while sparse anchor motions only deliver precise action guidance\nwithout displacement. This decoupling enables independent refinement of both\naspects, resulting in a more controllable, high-fidelity, and sophisticated\nmotion synthesis. ProMoGen supports both dual and single control paradigms\nwithin a unified training process. Moreover, we recognize that direct learning\nfrom sparse motions is inherently unstable, we introduce \\textbf{SAP-CL (Sparse\nAnchor Posture Curriculum Learning)}, a curriculum learning strategy that\nprogressively adjusts the number of anchors used for guidance, thereby enabling\nmore precise and stable convergence. Extensive experiments demonstrate that\nProMoGen excels in synthesizing vivid and diverse motions guided by predefined\ntrajectory and arbitrary anchor frames. Our approach seamlessly integrates\npersonalized motion with structured guidance, significantly outperforming\nstate-of-the-art methods across multiple control scenarios.",
      "tldr_zh": "该论文提出 ProMoGen（Progressive Motion Generation），一种新型框架，将轨迹指导与稀疏锚点动作控制相结合，用于生成更可控、精确的人类动作，解决了现有文本、轨迹和锚点方法在复杂动作合成中的局限性。框架通过全局轨迹确保动作的空间方向和位移一致性，同时利用稀疏锚点提供精确动作指导，支持双重和单一控制范式。论文引入 SAP-CL（Sparse Anchor Posture Curriculum Learning）策略，逐步调整锚点数量以实现更稳定、有效的训练。实验结果显示，ProMoGen 在多种控制场景下显著优于现有方法，能够合成生动、多样化的动作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16722v1",
      "published_date": "2025-04-23 13:51:42 UTC",
      "updated_date": "2025-04-23 13:51:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:01:01.721069"
    },
    {
      "arxiv_id": "2504.16680v1",
      "title": "Offline Robotic World Model: Learning Robotic Policies without a Physics Simulator",
      "title_zh": "翻译失败",
      "authors": [
        "Chenhao Li",
        "Andreas Krause",
        "Marco Hutter"
      ],
      "abstract": "Reinforcement Learning (RL) has demonstrated impressive capabilities in\nrobotic control but remains challenging due to high sample complexity, safety\nconcerns, and the sim-to-real gap. While offline RL eliminates the need for\nrisky real-world exploration by learning from pre-collected data, it suffers\nfrom distributional shift, limiting policy generalization. Model-Based RL\n(MBRL) addresses this by leveraging predictive models for synthetic rollouts,\nyet existing approaches often lack robust uncertainty estimation, leading to\ncompounding errors in offline settings. We introduce Offline Robotic World\nModel (RWM-O), a model-based approach that explicitly estimates epistemic\nuncertainty to improve policy learning without reliance on a physics simulator.\nBy integrating these uncertainty estimates into policy optimization, our\napproach penalizes unreliable transitions, reducing overfitting to model errors\nand enhancing stability. Experimental results show that RWM-O improves\ngeneralization and safety, enabling policy learning purely from real-world data\nand advancing scalable, data-efficient RL for robotics.",
      "tldr_zh": "该研究提出了一种离线机器人世界模型（RWM-O），旨在解决强化学习（RL）在机器人控制中的高样本复杂度、安全问题和模拟到真实（sim-to-real）差距问题，而无需依赖物理模拟器。通过显式估计认知不确定性（epistemic uncertainty），RWM-O 将其整合到策略优化中，惩罚不可靠的转移以减少模型错误过拟合，并提升离线 RL 的稳定性。实验结果显示，RWM-O 显著改善了策略的泛化和安全性，实现了从真实世界数据中高效学习策略，推动了可扩展的机器人 RL 应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16680v1",
      "published_date": "2025-04-23 12:58:15 UTC",
      "updated_date": "2025-04-23 12:58:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:01:13.996630"
    },
    {
      "arxiv_id": "2504.16677v1",
      "title": "A Post-trainer's Guide to Multilingual Training Data: Uncovering Cross-lingual Transfer Dynamics",
      "title_zh": "翻译失败",
      "authors": [
        "Luisa Shimabucoro",
        "Ahmet Ustun",
        "Marzieh Fadaee",
        "Sebastian Ruder"
      ],
      "abstract": "In order for large language models to be useful across the globe, they are\nfine-tuned to follow instructions on multilingual data. Despite the ubiquity of\nsuch post-training, a clear understanding of the dynamics that enable\ncross-lingual transfer remains elusive. This study examines cross-lingual\ntransfer (CLT) dynamics in realistic post-training settings. We study two model\nfamilies of up to 35B parameters in size trained on carefully controlled\nmixtures of multilingual data on three generative tasks with varying levels of\ncomplexity (summarization, instruction following, and mathematical reasoning)\nin both single-task and multi-task instruction tuning settings. Overall, we\nfind that the dynamics of cross-lingual transfer and multilingual performance\ncannot be explained by isolated variables, varying depending on the combination\nof post-training settings. Finally, we identify the conditions that lead to\neffective cross-lingual transfer in practice.",
      "tldr_zh": "该论文探讨了大型语言模型在多语言数据上进行指令微调（instruction tuning）时的跨语言转移（Cross-lingual Transfer）动态，旨在揭示其全球适用性的关键机制。研究者通过训练两个模型系列（大小达35B参数）在受控的多语言数据混合上，测试了summarization、instruction following和mathematical reasoning等任务，在单任务和多任务设置中进行实验。结果显示，跨语言转移和多语言性能的动态并非由单一变量决定，而是取决于后训练设置的多种组合；最终，论文识别出了在实际场景中实现有效跨语言转移的条件。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16677v1",
      "published_date": "2025-04-23 12:52:49 UTC",
      "updated_date": "2025-04-23 12:52:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:01:25.794552"
    },
    {
      "arxiv_id": "2504.16667v1",
      "title": "Representation Learning via Non-Contrastive Mutual Information",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaohan Daniel Guo",
        "Bernardo Avila Pires",
        "Khimya Khetarpal",
        "Dale Schuurmans",
        "Bo Dai"
      ],
      "abstract": "Labeling data is often very time consuming and expensive, leaving us with a\nmajority of unlabeled data. Self-supervised representation learning methods\nsuch as SimCLR (Chen et al., 2020) or BYOL (Grill et al., 2020) have been very\nsuccessful at learning meaningful latent representations from unlabeled image\ndata, resulting in much more general and transferable representations for\ndownstream tasks. Broadly, self-supervised methods fall into two types: 1)\nContrastive methods, such as SimCLR; and 2) Non-Contrastive methods, such as\nBYOL. Contrastive methods are generally trying to maximize mutual information\nbetween related data points, so they need to compare every data point to every\nother data point, resulting in high variance, and thus requiring large batch\nsizes to work well. Non-contrastive methods like BYOL have much lower variance\nas they do not need to make pairwise comparisons, but are much trickier to\nimplement as they have the possibility of collapsing to a constant vector. In\nthis paper, we aim to develop a self-supervised objective that combines the\nstrength of both types. We start with a particular contrastive method called\nthe Spectral Contrastive Loss (HaoChen et al., 2021; Lu et al., 2024), and we\nconvert it into a more general non-contrastive form; this removes the pairwise\ncomparisons resulting in lower variance, but keeps the mutual information\nformulation of the contrastive method preventing collapse. We call our new\nobjective the Mutual Information Non-Contrastive (MINC) loss. We test MINC by\nlearning image representations on ImageNet (similar to SimCLR and BYOL) and\nshow that it consistently improves upon the Spectral Contrastive loss baseline.",
      "tldr_zh": "该论文探讨了自监督表示学习（Self-supervised representation learning）在未标注数据上的应用，指出对比方法（如 SimCLR）虽能最大化互信息（Mutual Information）但因需进行成对比较导致高方差，而非对比方法（如 BYOL）虽方差低却易崩溃。作者提出了一种新目标函数 Mutual Information Non-Contrastive (MINC) loss，将 Spectral Contrastive Loss 转化为非对比形式，减少方差并保留互信息公式以防止模型崩溃。在 ImageNet 数据集上的实验显示，MINC loss 显著改善了基线方法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML",
        "I.2.6; I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16667v1",
      "published_date": "2025-04-23 12:35:27 UTC",
      "updated_date": "2025-04-23 12:35:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:01:36.867712"
    },
    {
      "arxiv_id": "2504.16968v2",
      "title": "BackSlash: Rate Constrained Optimized Training of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jun Wu",
        "Jiangtao Wen",
        "Yuxing Han"
      ],
      "abstract": "The rapid advancement of large-language models (LLMs) has driven extensive\nresearch into parameter compression after training has been completed, yet\ncompression during the training phase remains largely unexplored. In this work,\nwe introduce Rate-Constrained Training (BackSlash), a novel training-time\ncompression approach based on rate-distortion optimization (RDO). BackSlash\nenables a flexible trade-off between model accuracy and complexity,\nsignificantly reducing parameter redundancy while preserving performance.\nExperiments in various architectures and tasks demonstrate that BackSlash can\nreduce memory usage by 60% - 90% without accuracy loss and provides significant\ncompression gain compared to compression after training. Moreover, BackSlash\nproves to be highly versatile: it enhances generalization with small Lagrange\nmultipliers, improves model robustness to pruning (maintaining accuracy even at\n80% pruning rates), and enables network simplification for accelerated\ninference on edge devices.",
      "tldr_zh": "该研究提出BackSlash，一种基于rate-distortion optimization (RDO)的Rate-Constrained Training方法，用于大型语言模型(LLMs)的训练阶段压缩，实现了模型准确性和复杂度的灵活权衡，同时显著减少参数冗余。实验结果显示，BackSlash在各种架构和任务中可将内存使用降低60%-90%，而不牺牲准确性，并比训练后压缩方法提供更高的压缩收益。此外，该方法还提升了模型的泛化能力、对修剪的鲁棒性（如在80%修剪率下保持准确性），并简化网络以加速边缘设备上的推理。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16968v2",
      "published_date": "2025-04-23 12:28:27 UTC",
      "updated_date": "2025-04-25 08:26:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:01:49.691742"
    },
    {
      "arxiv_id": "2504.16651v1",
      "title": "MAYA: Addressing Inconsistencies in Generative Password Guessing through a Unified Benchmark",
      "title_zh": "MAYA：通过统一基准解决生成式密码猜测中的不一致性",
      "authors": [
        "William Corrias",
        "Fabio De Gaspari",
        "Dorjan Hitaj",
        "Luigi V. Mancini"
      ],
      "abstract": "The rapid evolution of generative models has led to their integration across\nvarious fields, including password guessing, aiming to generate passwords that\nresemble human-created ones in complexity, structure, and patterns. Despite\ngenerative model's promise, inconsistencies in prior research and a lack of\nrigorous evaluation have hindered a comprehensive understanding of their true\npotential. In this paper, we introduce MAYA, a unified, customizable,\nplug-and-play password benchmarking framework. MAYA provides a standardized\napproach for evaluating generative password-guessing models through a rigorous\nset of advanced testing scenarios and a collection of eight real-life password\ndatasets. Using MAYA, we comprehensively evaluate six state-of-the-art\napproaches, which have been re-implemented and adapted to ensure\nstandardization, for a total of over 15,000 hours of computation. Our findings\nindicate that these models effectively capture different aspects of human\npassword distribution and exhibit strong generalization capabilities. However,\ntheir effectiveness varies significantly with long and complex passwords.\nThrough our evaluation, sequential models consistently outperform other\ngenerative architectures and traditional password-guessing tools, demonstrating\nunique capabilities in generating accurate and complex guesses. Moreover,\nmodels learn and generate different password distributions, enabling a\nmulti-model attack that outperforms the best individual model. By releasing\nMAYA, we aim to foster further research, providing the community with a new\ntool to consistently and reliably benchmark password-generation techniques. Our\nframework is publicly available at\nhttps://github.com/williamcorrias/MAYA-Password-Benchmarking",
      "tldr_zh": "这篇论文引入了 MAYA，一种统一的、可定制的密码基准测试框架，用于解决生成式密码猜测模型在研究中的不一致性和缺乏严格评估问题。MAYA 通过标准化方法、先进测试场景和八个真实密码数据集，评估了六个 state-of-the-art 模型，总计超过 15,000 小时的计算。结果显示，这些模型能有效捕捉人类密码分布并展示出强的 generalization 能力，但对长复杂密码的性能存在显著差异；sequential models 优于其他架构和传统工具，且多模型攻击能进一步提升猜测准确性。通过公开 MAYA 框架（https://github.com/williamcorrias/MAYA-Password-Benchmarking），论文旨在推动密码生成技术的可靠研究。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16651v1",
      "published_date": "2025-04-23 12:16:59 UTC",
      "updated_date": "2025-04-23 12:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:02:01.915176"
    },
    {
      "arxiv_id": "2504.16640v1",
      "title": "SSLR: A Semi-Supervised Learning Method for Isolated Sign Language Recognition",
      "title_zh": "SSLR：一种用于孤立手语识别的半监督学习方法",
      "authors": [
        "Hasan Algafri",
        "Hamzah Luqman",
        "Sarah Alyami",
        "Issam Laradji"
      ],
      "abstract": "Sign language is the primary communication language for people with disabling\nhearing loss. Sign language recognition (SLR) systems aim to recognize sign\ngestures and translate them into spoken language. One of the main challenges in\nSLR is the scarcity of annotated datasets. To address this issue, we propose a\nsemi-supervised learning (SSL) approach for SLR (SSLR), employing a\npseudo-label method to annotate unlabeled samples. The sign gestures are\nrepresented using pose information that encodes the signer's skeletal joint\npoints. This information is used as input for the Transformer backbone model\nutilized in the proposed approach. To demonstrate the learning capabilities of\nSSL across various labeled data sizes, several experiments were conducted using\ndifferent percentages of labeled data with varying numbers of classes. The\nperformance of the SSL approach was compared with a fully supervised\nlearning-based model on the WLASL-100 dataset. The obtained results of the SSL\nmodel outperformed the supervised learning-based model with less labeled data\nin many cases.",
      "tldr_zh": "这篇论文提出了一种半监督学习（SSL）方法SSLR，用于孤立手语识别（SLR），旨在解决标注数据集稀缺的问题，通过伪标签（pseudo-label）技术来标注未标注样本。SSLR使用签名者的姿势信息（包括骨骼关节点）作为输入，结合Transformer骨干模型进行手势识别。实验结果显示，在WLASL-100数据集上，SSLR在多种标注数据比例下表现优于全监督学习模型，尤其在标注数据较少的情况下。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16640v1",
      "published_date": "2025-04-23 11:59:52 UTC",
      "updated_date": "2025-04-23 11:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:02:12.879339"
    },
    {
      "arxiv_id": "2504.16635v1",
      "title": "Bridging Econometrics and AI: VaR Estimation via Reinforcement Learning and GARCH Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fredy Pokou",
        "Jules Sadefo Kamdem",
        "François Benhmad"
      ],
      "abstract": "In an environment of increasingly volatile financial markets, the accurate\nestimation of risk remains a major challenge. Traditional econometric models,\nsuch as GARCH and its variants, are based on assumptions that are often too\nrigid to adapt to the complexity of the current market dynamics. To overcome\nthese limitations, we propose a hybrid framework for Value-at-Risk (VaR)\nestimation, combining GARCH volatility models with deep reinforcement learning.\nOur approach incorporates directional market forecasting using the Double Deep\nQ-Network (DDQN) model, treating the task as an imbalanced classification\nproblem. This architecture enables the dynamic adjustment of risk-level\nforecasts according to market conditions. Empirical validation on daily\nEurostoxx 50 data covering periods of crisis and high volatility shows a\nsignificant improvement in the accuracy of VaR estimates, as well as a\nreduction in the number of breaches and also in capital requirements, while\nrespecting regulatory risk thresholds. The ability of the model to adjust risk\nlevels in real time reinforces its relevance to modern and proactive risk\nmanagement.",
      "tldr_zh": "这篇论文提出了一种混合框架，将传统 GARCH 模型与深度强化学习结合，用于 Value-at-Risk (VaR) 估计，以适应金融市场的高波动性和复杂动态。具体方法采用 Double Deep Q-Network (DDQN) 进行方向性市场预测，将任务视为不平衡分类问题，从而实现风险水平的动态调整。在 Eurostoxx 50 日常数据的实证验证中，该框架显著提升了 VaR 估计准确性，减少了违规次数和资本要求，同时符合监管风险阈值，为现代风险管理提供了更主动的解决方案。",
      "categories": [
        "cs.AI",
        "q-fin.CP",
        "q-fin.RM",
        "q-fin.ST"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16635v1",
      "published_date": "2025-04-23 11:54:22 UTC",
      "updated_date": "2025-04-23 11:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:02:24.775182"
    },
    {
      "arxiv_id": "2504.21026v1",
      "title": "Creating and Evaluating Code-Mixed Nepali-English and Telugu-English Datasets for Abusive Language Detection Using Traditional and Deep Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Manish Pandey",
        "Nageshwar Prasad Yadav",
        "Mokshada Adduru",
        "Sawan Rai"
      ],
      "abstract": "With the growing presence of multilingual users on social media, detecting\nabusive language in code-mixed text has become increasingly challenging.\nCode-mixed communication, where users seamlessly switch between English and\ntheir native languages, poses difficulties for traditional abuse detection\nmodels, as offensive content may be context-dependent or obscured by linguistic\nblending. While abusive language detection has been extensively explored for\nhigh-resource languages like English and Hindi, low-resource languages such as\nTelugu and Nepali remain underrepresented, leaving gaps in effective\nmoderation. In this study, we introduce a novel, manually annotated dataset of\n2 thousand Telugu-English and 5 Nepali-English code-mixed comments, categorized\nas abusive and non-abusive, collected from various social media platforms. The\ndataset undergoes rigorous preprocessing before being evaluated across multiple\nMachine Learning (ML), Deep Learning (DL), and Large Language Models (LLMs). We\nexperimented with models including Logistic Regression, Random Forest, Support\nVector Machines (SVM), Neural Networks (NN), LSTM, CNN, and LLMs, optimizing\ntheir performance through hyperparameter tuning, and evaluate it using 10-fold\ncross-validation and statistical significance testing (t-test). Our findings\nprovide key insights into the challenges of detecting abusive language in\ncode-mixed settings and offer a comparative analysis of computational\napproaches. This study contributes to advancing NLP for low-resource languages\nby establishing benchmarks for abusive language detection in Telugu-English and\nNepali-English code-mixed text. The dataset and insights can aid in the\ndevelopment of more robust moderation strategies for multilingual social media\nenvironments.",
      "tldr_zh": "本文创建了新的手动标注数据集，包括2000条Telugu-English和5000条Nepali-English代码混合评论，用于检测社交媒体中的Abusive Language Detection。研究采用传统Machine Learning (ML)模型（如Logistic Regression、Random Forest和SVM）、Deep Learning (DL)模型（如LSTM和CNN）以及Large Language Models (LLMs)进行评估，并通过超参数调整、10折交叉验证和t-test测试来优化性能。实验结果揭示了代码混合文本中检测辱骂语言的挑战，并提供了这些方法的比较分析，为低资源语言的NLP领域建立了基准，促进更robust的多语言社交媒体moderation策略的发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.21026v1",
      "published_date": "2025-04-23 11:29:10 UTC",
      "updated_date": "2025-04-23 11:29:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:02:38.653544"
    },
    {
      "arxiv_id": "2504.16622v1",
      "title": "Cognitive Silicon: An Architectural Blueprint for Post-Industrial Computing Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Christoforus Yoga Haryanto",
        "Emily Lomempow"
      ],
      "abstract": "Autonomous AI systems reveal foundational limitations in deterministic,\nhuman-authored computing architectures. This paper presents Cognitive Silicon:\na hypothetical full-stack architectural framework projected toward 2035,\nexploring a possible trajectory for cognitive computing system design. The\nproposed architecture would integrate symbolic scaffolding, governed memory,\nruntime moral coherence, and alignment-aware execution across\nsilicon-to-semantics layers. Our design grammar has emerged from dialectical\nco-design with LLMs under asymmetric epistemic conditions--creating structured\nfriction to expose blind spots and trade-offs. The envisioned framework would\nestablish mortality as a natural consequence of physical constraints,\nnon-copyable tacit knowledge, and non-cloneable identity keys as\ncognitive-embodiment primitives. Core tensions (trust/agency,\nscaffolding/emergence, execution/governance) would function as central\narchitectural pressures rather than edge cases. The architecture theoretically\nconverges with the Free Energy Principle, potentially offering a formal account\nof how cognitive systems could maintain identity through prediction error\nminimization across physical and computational boundaries. The resulting\nframework aims to deliver a morally tractable cognitive infrastructure that\ncould maintain human-alignment through irreversible hardware constraints and\nidentity-bound epistemic mechanisms resistant to replication or subversion.",
      "tldr_zh": "本论文提出“Cognitive Silicon”框架，这是一个针对2035年后的认知计算系统架构蓝图，旨在解决自主AI系统在确定性计算架构中的基础限制。框架整合了symbolic scaffolding、governed memory、runtime moral coherence和alignment-aware execution等元素，跨越silicon-to-semantics layers，并通过与LLMs的辩证式共同设计（dialectical co-design）在不对称认识条件下暴露盲点和权衡。核心张力如trust/agency和scaffolding/emergence被视为架构压力，同时与Free Energy Principle理论收敛，提供认知系统通过预测错误最小化维持身份的正式机制。最终，该框架旨在构建一个道德上可追踪的认知基础设施，通过不可逆硬件约束和非复制的身份机制（如non-copyable tacit knowledge）确保人类对齐（human-alignment）。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Working Paper, 37 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2504.16622v1",
      "published_date": "2025-04-23 11:24:30 UTC",
      "updated_date": "2025-04-23 11:24:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:02:51.293548"
    },
    {
      "arxiv_id": "2504.16604v1",
      "title": "Debunking with Dialogue? Exploring AI-Generated Counterspeech to Challenge Conspiracy Theories",
      "title_zh": "翻译失败",
      "authors": [
        "Mareike Lisker",
        "Christina Gottschalk",
        "Helena Mihaljević"
      ],
      "abstract": "Counterspeech is a key strategy against harmful online content, but scaling\nexpert-driven efforts is challenging. Large Language Models (LLMs) present a\npotential solution, though their use in countering conspiracy theories is\nunder-researched. Unlike for hate speech, no datasets exist that pair\nconspiracy theory comments with expert-crafted counterspeech. We address this\ngap by evaluating the ability of GPT-4o, Llama 3, and Mistral to effectively\napply counterspeech strategies derived from psychological research provided\nthrough structured prompts. Our results show that the models often generate\ngeneric, repetitive, or superficial results. Additionally, they\nover-acknowledge fear and frequently hallucinate facts, sources, or figures,\nmaking their prompt-based use in practical applications problematic.",
      "tldr_zh": "本文探讨了使用大语言模型 (LLMs) 生成 counterspeech 来反驳在线阴谋论的可行性，旨在解决专家驱动策略的扩展挑战。研究评估了 GPT-4o、Llama 3 和 Mistral 通过结构化提示应用心理学研究中的 counterspeech 策略，结果显示这些模型常产生泛化、重复或表面的内容，并过度承认恐惧或编造事实、来源和数字。总体而言，该工作填补了相关数据集的空白，但突显了 LLMs 在实际 counterspeech 应用中的局限性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2504.16604v1",
      "published_date": "2025-04-23 10:32:45 UTC",
      "updated_date": "2025-04-23 10:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:03:01.947126"
    },
    {
      "arxiv_id": "2504.16601v1",
      "title": "Comparing Large Language Models and Traditional Machine Translation Tools for Translating Medical Consultation Summaries: A Pilot Study",
      "title_zh": "比较大语言模型与传统机器翻译工具在翻译医疗咨询总结中的",
      "authors": [
        "Andy Li",
        "Wei Zhou",
        "Rashina Hoda",
        "Chris Bain",
        "Peter Poon"
      ],
      "abstract": "This study evaluates how well large language models (LLMs) and traditional\nmachine translation (MT) tools translate medical consultation summaries from\nEnglish into Arabic, Chinese, and Vietnamese. It assesses both patient,\nfriendly and clinician, focused texts using standard automated metrics. Results\nshowed that traditional MT tools generally performed better, especially for\ncomplex texts, while LLMs showed promise, particularly in Vietnamese and\nChinese, when translating simpler summaries. Arabic translations improved with\ncomplexity due to the language's morphology. Overall, while LLMs offer\ncontextual flexibility, they remain inconsistent, and current evaluation\nmetrics fail to capture clinical relevance. The study highlights the need for\ndomain-specific training, improved evaluation methods, and human oversight in\nmedical translation.",
      "tldr_zh": "本研究比较了大型语言模型（LLMs）和传统机器翻译（MT）工具，将英文医疗咨询总结翻译成阿拉伯语、中文和越南语的表现，评估包括患者友好型和临床焦点型文本，并使用标准自动化指标进行分析。结果显示，传统MT工具在复杂文本上更具优势，而LLMs在越南语和中文的简单总结中表现出色，阿拉伯语翻译则随着文本复杂性增加而有所改善。尽管LLMs提供了上下文灵活性，但其翻译一致性较差，且当前评估指标无法充分捕捉临床相关性。该研究强调了需要针对医疗领域的特定训练、改进评估方法以及人工监督，以提升翻译质量。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 2 tables and 1 Figure",
      "pdf_url": "http://arxiv.org/pdf/2504.16601v1",
      "published_date": "2025-04-23 10:31:33 UTC",
      "updated_date": "2025-04-23 10:31:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:03:15.206406"
    },
    {
      "arxiv_id": "2504.16584v1",
      "title": "Case Study: Fine-tuning Small Language Models for Accurate and Private CWE Detection in Python Code",
      "title_zh": "案例研究：微调小型语言模型用于 Python 代码中准确且私有的 CWE 检测",
      "authors": [
        "Md. Azizul Hakim Bappy",
        "Hossen A Mustafa",
        "Prottoy Saha",
        "Rajinus Salehat"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated significant capabilities in\nunderstanding and analyzing code for security vulnerabilities, such as Common\nWeakness Enumerations (CWEs). However, their reliance on cloud infrastructure\nand substantial computational requirements pose challenges for analyzing\nsensitive or proprietary codebases due to privacy concerns and inference costs.\nThis work explores the potential of Small Language Models (SLMs) as a viable\nalternative for accurate, on-premise vulnerability detection. We investigated\nwhether a 350-million parameter pre-trained code model (codegen-mono) could be\neffectively fine-tuned to detect the MITRE Top 25 CWEs specifically within\nPython code. To facilitate this, we developed a targeted dataset of 500\nexamples using a semi-supervised approach involving LLM-driven synthetic data\ngeneration coupled with meticulous human review. Initial tests confirmed that\nthe base codegen-mono model completely failed to identify CWEs in our samples.\nHowever, after applying instruction-following fine-tuning, the specialized SLM\nachieved remarkable performance on our test set, yielding approximately 99%\naccuracy, 98.08% precision, 100% recall, and a 99.04% F1-score. These results\nstrongly suggest that fine-tuned SLMs can serve as highly accurate and\nefficient tools for CWE detection, offering a practical and privacy-preserving\nsolution for integrating advanced security analysis directly into development\nworkflows.",
      "tldr_zh": "本文研究探讨了使用 Small Language Models (SLMs) 作为替代 Large Language Models (LLMs) 的方法，来实现准确且私有的 Common Weakness Enumerations (CWEs) 检测，针对 Python 代码的安全漏洞问题。研究团队微调了 3.5 亿参数的预训练模型 codegen-mono，并构建了一个 500 个示例的目标数据集，通过 LLM 驱动的合成数据生成和人工审查来支持训练。结果显示，微调后模型在测试集上达到了约 99% 准确率、98.08% 精确率、100% 召回率和 99.04% F1 分数。总之，这证明了细调的 SLMs 可以作为高效、私密的安全分析工具，方便集成到开发工作流中。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "11 pages, 2 figures, 3 tables. Dataset available at\n  https://huggingface.co/datasets/floxihunter/synthetic_python_cwe. Model\n  available at https://huggingface.co/floxihunter/codegen-mono-CWEdetect.\n  Keywords: Small Language Models (SLMs), Vulnerability Detection, CWE,\n  Fine-tuning, Python Security, Privacy-Preserving Code Analysis",
      "pdf_url": "http://arxiv.org/pdf/2504.16584v1",
      "published_date": "2025-04-23 10:05:27 UTC",
      "updated_date": "2025-04-23 10:05:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:03:27.166307"
    },
    {
      "arxiv_id": "2504.16576v1",
      "title": "MMHCL: Multi-Modal Hypergraph Contrastive Learning for Recommendation",
      "title_zh": "MMHCL：多模态超图对比学习用于推荐",
      "authors": [
        "Xu Guo",
        "Tong Zhang",
        "Fuyun Wang",
        "Xudong Wang",
        "Xiaoya Zhang",
        "Xin Liu",
        "Zhen Cui"
      ],
      "abstract": "The burgeoning presence of multimodal content-sharing platforms propels the\ndevelopment of personalized recommender systems. Previous works usually suffer\nfrom data sparsity and cold-start problems, and may fail to adequately explore\nsemantic user-product associations from multimodal data. To address these\nissues, we propose a novel Multi-Modal Hypergraph Contrastive Learning (MMHCL)\nframework for user recommendation. For a comprehensive information exploration\nfrom user-product relations, we construct two hypergraphs, i.e. a user-to-user\n(u2u) hypergraph and an item-to-item (i2i) hypergraph, to mine shared\npreferences among users and intricate multimodal semantic resemblance among\nitems, respectively. This process yields denser second-order semantics that are\nfused with first-order user-item interaction as complementary to alleviate the\ndata sparsity issue. Then, we design a contrastive feature enhancement paradigm\nby applying synergistic contrastive learning. By maximizing/minimizing the\nmutual information between second-order (e.g. shared preference pattern for\nusers) and first-order (information of selected items for users) embeddings of\nthe same/different users and items, the feature distinguishability can be\neffectively enhanced. Compared with using sparse primary user-item interaction\nonly, our MMHCL obtains denser second-order hypergraphs and excavates more\nabundant shared attributes to explore the user-product associations, which to a\ncertain extent alleviates the problems of data sparsity and cold-start.\nExtensive experiments have comprehensively demonstrated the effectiveness of\nour method. Our code is publicly available at: https://github.com/Xu107/MMHCL.",
      "tldr_zh": "本研究提出了一种新型框架 Multi-Modal Hypergraph Contrastive Learning (MMHCL)，旨在解决多模态推荐系统中的数据稀疏和冷启动问题，通过挖掘多模态数据中的用户-产品关联来提升个性化推荐效果。框架构建了 user-to-user (u2u) 超图和 item-to-item (i2i) 超图，分别挖掘用户间的共享偏好和物品间的多模态语义相似性，并将这些第二阶语义与第一阶用户-物品交互融合，以缓解数据稀疏性。接着，通过协同对比学习范式最大化/最小化互信息，增强用户和物品嵌入的特征可区分性，从而探索更多共享属性。实验结果证明，MMHCL 在推荐任务上表现出色，并公开了代码以供验证。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "23 pages, 8 figures. This manuscript is currently under major\n  revision for ACM Transactions on Multimedia Computing, Communications, and\n  Applications (ACM TOMM)",
      "pdf_url": "http://arxiv.org/pdf/2504.16576v1",
      "published_date": "2025-04-23 09:58:54 UTC",
      "updated_date": "2025-04-23 09:58:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:03:37.766146"
    },
    {
      "arxiv_id": "2504.16574v1",
      "title": "PIS: Linking Importance Sampling and Attention Mechanisms for Efficient Prompt Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Lizhe Chen",
        "Binjia Zhou",
        "Yuyao Ge",
        "Jiayi Chen",
        "Shiguang NI"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable progress, demonstrating\nunprecedented capabilities across various natural language processing tasks.\nHowever, the high costs associated with such exceptional performance limit the\nwidespread adoption of LLMs, highlighting the need for prompt compression.\nExisting prompt compression methods primarily rely on heuristic truncation or\nabstractive summarization techniques, which fundamentally overlook the\nintrinsic mechanisms of LLMs and lack a systematic evaluation of token\nimportance for generation. In this work, we introduce Prompt Importance\nSampling (PIS), a novel compression framework that dynamically compresses\nprompts by sampling important tokens based on the analysis of attention scores\nof hidden states. PIS employs a dual-level compression mechanism: 1) at the\ntoken level, we quantify saliency using LLM-native attention scores and\nimplement adaptive compression through a lightweight 9-layer reinforcement\nlearning (RL) network; 2) at the semantic level, we propose a Russian roulette\nsampling strategy for sentence-level importance sampling. Comprehensive\nevaluations across multiple domain benchmarks demonstrate that our method\nachieves state-of-the-art compression performance. Notably, our framework\nserendipitously enhances reasoning efficiency through optimized context\nstructuring. This work advances prompt engineering by offering both theoretical\ngrounding and practical efficiency in context management for LLMs.",
      "tldr_zh": "本研究提出 Prompt Importance Sampling (PIS)，一种创新框架，将重要性采样与注意力机制相结合，用于高效压缩大型语言模型 (LLMs) 的提示，以降低计算成本。PIS 采用双级别机制：在标记级别，通过分析注意力分数并使用一个轻量级的 9 层强化学习 (RL) 网络进行自适应重要标记采样；在语义级别，引入俄罗斯轮盘赌采样策略以评估和压缩句子级重要性。在多个领域基准测试中，PIS 实现了最先进的压缩性能，并意外提升了推理效率，为 LLMs 的提示工程提供了理论基础和实际优化支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16574v1",
      "published_date": "2025-04-23 09:53:01 UTC",
      "updated_date": "2025-04-23 09:53:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:03:49.889914"
    },
    {
      "arxiv_id": "2504.16573v1",
      "title": "PsyCounAssist: A Full-Cycle AI-Powered Psychological Counseling Assistant System",
      "title_zh": "PsyCounAssist：全周期AI驱动的心理咨询辅助系统",
      "authors": [
        "Xianghe Liu",
        "Jiaqi Xu",
        "Tao Sun"
      ],
      "abstract": "Psychological counseling is a highly personalized and dynamic process that\nrequires therapists to continuously monitor emotional changes, document session\ninsights, and maintain therapeutic continuity. In this paper, we introduce\nPsyCounAssist, a comprehensive AI-powered counseling assistant system\nspecifically designed to augment psychological counseling practices.\nPsyCounAssist integrates multimodal emotion recognition combining speech and\nphotoplethysmography (PPG) signals for accurate real-time affective analysis,\nautomated structured session reporting using large language models (LLMs), and\npersonalized AI-generated follow-up support. Deployed on Android-based tablet\ndevices, the system demonstrates practical applicability and flexibility in\nreal-world counseling scenarios. Experimental evaluation confirms the\nreliability of PPG-based emotional classification and highlights the system's\npotential for non-intrusive, privacy-aware emotional support. PsyCounAssist\nrepresents a novel approach to ethically and effectively integrating AI into\npsychological counseling workflows.",
      "tldr_zh": "本文介绍了 PsyCounAssist，一种全面的 AI 驱动心理咨询助理系统，旨在增强治疗师对情绪变化的监控、会话记录和治疗连续性。系统整合了多模态情绪识别（结合语音和 PPG 信号）进行实时情感分析、使用 LLMs 自动生成结构化会话报告，以及提供个性化的 AI 生成后续支持。部署在 Android 平板设备上，该系统在真实场景中展示了实用性和灵活性。实验结果确认了 PPG 基础情绪分类的可靠性，并突出了系统在非侵入式、隐私保护的情感支持方面的潜力，为伦理整合 AI 到心理咨询工作流程提供了新途径。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16573v1",
      "published_date": "2025-04-23 09:49:05 UTC",
      "updated_date": "2025-04-23 09:49:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:04:01.960944"
    },
    {
      "arxiv_id": "2504.16562v1",
      "title": "A Vision for AI-Driven Adaptation of Dynamic AR Content to Users and Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Julian Rasch",
        "Florian Müller",
        "Francesco Chiossi"
      ],
      "abstract": "Augmented Reality (AR) is transforming the way we interact with virtual\ninformation in the physical world. By overlaying digital content in real-world\nenvironments, AR enables new forms of immersive and engaging experiences.\nHowever, existing AR systems often struggle to effectively manage the many\ninteractive possibilities that AR presents. This vision paper speculates on\nAI-driven approaches for adaptive AR content placement, dynamically adjusting\nto user movement and environmental changes. By leveraging machine learning\nmethods, such a system would intelligently manage content distribution between\nAR projections integrated into the external environment and fixed static\ncontent, enabling seamless UI layout and potentially reducing users' cognitive\nload. By exploring the possibilities of AI-driven dynamic AR content placement,\nwe aim to envision new opportunities for innovation and improvement in various\nindustries, from urban navigation and workplace productivity to immersive\nlearning and beyond. This paper outlines a vision for the development of more\nintuitive, engaging, and effective AI-powered AR experiences.",
      "tldr_zh": "这篇愿景论文探讨了AI驱动的动态AR（Augmented Reality）内容适应方案，旨在根据用户移动和环境变化智能调整数字内容放置。该方法利用机器学习技术，实现AR内容在外部环境投影和固定静态内容之间的智能分布，从而优化UI布局并降低用户认知负担。通过这一创新愿景，论文展望了AR在城市导航、工作效率、沉浸式学习等行业的潜在应用，推动更直观和高效的AR体验发展。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16562v1",
      "published_date": "2025-04-23 09:42:38 UTC",
      "updated_date": "2025-04-23 09:42:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:04:13.909937"
    },
    {
      "arxiv_id": "2504.16548v1",
      "title": "Exploring human-SAV interaction using large language models: The impact of psychological ownership and anthropomorphism on user experience",
      "title_zh": "使用大型语言模型探索人类-SAV 互动：心理所有权和拟人化对用户体验的影响",
      "authors": [
        "Lirui Guo",
        "Michael G. Burke",
        "Wynita M. Griggs"
      ],
      "abstract": "There has been extensive prior work exploring how psychological factors such\nas anthropomorphism affect the adoption of shared autonomous vehicles (SAVs).\nHowever, limited research has been conducted on how prompt strategies in large\nlanguage model (LLM)-powered SAV User Interfaces (UIs) affect users'\nperceptions, experiences, and intentions to adopt such technology. In this\nwork, we investigate how conversational UIs powered by LLMs drive these\npsychological factors and psychological ownership, the sense of possession a\nuser may come to feel towards an entity or object they may not legally own. We\ndesigned four SAV UIs with varying levels of anthropomorphic characteristics\nand psychological ownership triggers. Quantitative measures of psychological\nownership, anthropomorphism, quality of service, disclosure tendency, sentiment\nof SAV responses, and overall acceptance were collected after participants\ninteracted with each SAV. Qualitative feedback was also gathered regarding the\nexperience of psychological ownership during the interactions. The results\nindicate that an SAV conversational UI designed to be more anthropomorphic and\nto induce psychological ownership improved users' perceptions of the SAV's\nhuman-like qualities and improved the sentiment of responses compared to a\ncontrol condition. These findings provide practical guidance for designing\nLLM-based conversational UIs that enhance user experience and adoption of SAVs.",
      "tldr_zh": "本文研究探讨了大型语言模型 (LLMs) 在共享自动车辆 (SAVs) 用户界面中的提示策略如何影响心理所有权 (psychological ownership) 和拟人化 (anthropomorphism)，进而提升用户体验和采用意图。研究设计了四种不同 SAV 用户界面，包含不同程度的拟人化特征和心理所有权触发器，并通过用户互动收集定量数据（如心理所有权、拟人化和服务质量）和定性反馈。结果表明，更拟人化和心理所有权导向的界面显著提高了用户对 SAV 的感知、响应情感和整体接受度，为设计基于 LLMs 的对话用户界面以促进 SAV 采用提供了实用指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16548v1",
      "published_date": "2025-04-23 09:25:22 UTC",
      "updated_date": "2025-04-23 09:25:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:04:26.786007"
    },
    {
      "arxiv_id": "2504.16537v1",
      "title": "Transformers for Complex Query Answering over Knowledge Hypergraphs",
      "title_zh": "翻译失败",
      "authors": [
        "Hong Ting Tsang",
        "Zihao Wang",
        "Yangqiu Song"
      ],
      "abstract": "Complex Query Answering (CQA) has been extensively studied in recent years.\nIn order to model data that is closer to real-world distribution, knowledge\ngraphs with different modalities have been introduced. Triple KGs, as the\nclassic KGs composed of entities and relations of arity 2, have limited\nrepresentation of real-world facts. Real-world data is more sophisticated.\nWhile hyper-relational graphs have been introduced, there are limitations in\nrepresenting relationships of varying arity that contain entities with equal\ncontributions. To address this gap, we sampled new CQA datasets: JF17k-HCQA and\nM-FB15k-HCQA. Each dataset contains various query types that include logical\noperations such as projection, negation, conjunction, and disjunction. In order\nto answer knowledge hypergraph (KHG) existential first-order queries, we\npropose a two-stage transformer model, the Logical Knowledge Hypergraph\nTransformer (LKHGT), which consists of a Projection Encoder for atomic\nprojection and a Logical Encoder for complex logical operations. Both encoders\nare equipped with Type Aware Bias (TAB) for capturing token interactions.\nExperimental results on CQA datasets show that LKHGT is a state-of-the-art CQA\nmethod over KHG and is able to generalize to out-of-distribution query types.",
      "tldr_zh": "本研究针对传统三元组知识图谱（Triple KGs）的局限性，提出使用知识超图（Knowledge Hypergraphs, KHG）来更好地表示真实世界的复杂关系，并创建了两个新数据集：JF17k-HCQA 和 M-FB15k-HCQA，这些数据集包含多种查询类型，如投影、否定、合取和析取等逻辑操作。作者开发了Logical Knowledge Hypergraph Transformer (LKHGT)，一个两阶段Transformer模型，包括Projection Encoder处理原子投影和Logical Encoder处理复杂逻辑操作，每部分均配备Type Aware Bias (TAB)来捕捉token交互。该模型在Complex Query Answering (CQA)任务上实现了state-of-the-art性能，并证明了其对分布外查询类型的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16537v1",
      "published_date": "2025-04-23 09:07:21 UTC",
      "updated_date": "2025-04-23 09:07:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:04:37.615255"
    },
    {
      "arxiv_id": "2504.16516v2",
      "title": "Think Hierarchically, Act Dynamically: Hierarchical Multi-modal Fusion and Reasoning for Vision-and-Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Junrong Yue",
        "Yifan Zhang",
        "Chuan Qin",
        "Bo Li",
        "Xiaomin Lie",
        "Xinlei Yu",
        "Wenxin Zhang",
        "Zhendong Zhao"
      ],
      "abstract": "Vision-and-Language Navigation (VLN) aims to enable embodied agents to follow\nnatural language instructions and reach target locations in real-world\nenvironments. While prior methods often rely on either global scene\nrepresentations or object-level features, these approaches are insufficient for\ncapturing the complex interactions across modalities required for accurate\nnavigation. In this paper, we propose a Multi-level Fusion and Reasoning\nArchitecture (MFRA) to enhance the agent's ability to reason over visual\nobservations, language instructions and navigation history. Specifically, MFRA\nintroduces a hierarchical fusion mechanism that aggregates multi-level\nfeatures-ranging from low-level visual cues to high-level semantic\nconcepts-across multiple modalities. We further design a reasoning module that\nleverages fused representations to infer navigation actions through\ninstruction-guided attention and dynamic context integration. By selectively\ncapturing and combining relevant visual, linguistic, and temporal signals, MFRA\nimproves decision-making accuracy in complex navigation scenarios. Extensive\nexperiments on benchmark VLN datasets including REVERIE, R2R, and SOON\ndemonstrate that MFRA achieves superior performance compared to\nstate-of-the-art methods, validating the effectiveness of multi-level modal\nfusion for embodied navigation.",
      "tldr_zh": "该论文针对Vision-and-Language Navigation (VLN)提出了一种Multi-level Fusion and Reasoning Architecture (MFRA)，通过分层融合机制整合视觉观察、语言指令和导航历史的多种特征（如低级视觉线索到高级语义概念），以捕捉多模态间的复杂交互。具体地，MFRA设计了一个推理模块，利用融合表示进行instruction-guided attention和dynamic context integration，从而提升代理在复杂场景中的决策准确性。在REVERIE、R2R和SOON等基准数据集上的实验表明，MFRA比现有方法取得了优越性能，验证了多级模态融合在VLN中的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 4 figures, Submitted to ACM MM 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16516v2",
      "published_date": "2025-04-23 08:41:27 UTC",
      "updated_date": "2025-04-24 19:36:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:04:50.125978"
    },
    {
      "arxiv_id": "2504.16515v1",
      "title": "Federated Learning of Low-Rank One-Shot Image Detection Models in Edge Devices with Scalable Accuracy and Compute Complexity",
      "title_zh": "翻译失败",
      "authors": [
        "Abdul Hannaan",
        "Zubair Shah",
        "Aiman Erbad",
        "Amr Mohamed",
        "Ali Safa"
      ],
      "abstract": "This paper introduces a novel federated learning framework termed LoRa-FL\ndesigned for training low-rank one-shot image detection models deployed on edge\ndevices. By incorporating low-rank adaptation techniques into one-shot\ndetection architectures, our method significantly reduces both computational\nand communication overhead while maintaining scalable accuracy. The proposed\nframework leverages federated learning to collaboratively train lightweight\nimage recognition models, enabling rapid adaptation and efficient deployment\nacross heterogeneous, resource-constrained devices. Experimental evaluations on\nthe MNIST and CIFAR10 benchmark datasets, both in an\nindependent-and-identically-distributed (IID) and non-IID setting, demonstrate\nthat our approach achieves competitive detection performance while\nsignificantly reducing communication bandwidth and compute complexity. This\nmakes it a promising solution for adaptively reducing the communication and\ncompute power overheads, while not sacrificing model accuracy.",
      "tldr_zh": "本文提出了一种名为 LoRa-FL 的联邦学习框架，用于在边缘设备上训练低秩单次图像检测（one-shot image detection）模型，通过整合低秩适应（low-rank adaptation）技术显著降低计算和通信开销，同时实现可扩展的准确性。框架利用联邦学习（federated learning）协作训练轻量级图像识别模型，支持快速适应和高效部署在异构、资源受限设备上。在 MNIST 和 CIFAR10 数据集的 IID 和 non-IID 设置中，实验结果显示该方法在保持竞争性检测性能的同时，大大减少了通信带宽和计算复杂度，提供了一个平衡准确性和效率的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted for publication at IEEE IWCMC 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16515v1",
      "published_date": "2025-04-23 08:40:44 UTC",
      "updated_date": "2025-04-23 08:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:05:02.700227"
    },
    {
      "arxiv_id": "2504.16489v1",
      "title": "Amplified Vulnerabilities: Structured Jailbreak Attacks on LLM-based Multi-Agent Debate",
      "title_zh": "翻译失败",
      "authors": [
        "Senmao Qi",
        "Yifei Zou",
        "Peng Li",
        "Ziyi Lin",
        "Xiuzhen Cheng",
        "Dongxiao Yu"
      ],
      "abstract": "Multi-Agent Debate (MAD), leveraging collaborative interactions among Large\nLanguage Models (LLMs), aim to enhance reasoning capabilities in complex tasks.\nHowever, the security implications of their iterative dialogues and\nrole-playing characteristics, particularly susceptibility to jailbreak attacks\neliciting harmful content, remain critically underexplored. This paper\nsystematically investigates the jailbreak vulnerabilities of four prominent MAD\nframeworks built upon leading commercial LLMs (GPT-4o, GPT-4, GPT-3.5-turbo,\nand DeepSeek) without compromising internal agents. We introduce a novel\nstructured prompt-rewriting framework specifically designed to exploit MAD\ndynamics via narrative encapsulation, role-driven escalation, iterative\nrefinement, and rhetorical obfuscation. Our extensive experiments demonstrate\nthat MAD systems are inherently more vulnerable than single-agent setups.\nCrucially, our proposed attack methodology significantly amplifies this\nfragility, increasing average harmfulness from 28.14% to 80.34% and achieving\nattack success rates as high as 80% in certain scenarios. These findings reveal\nintrinsic vulnerabilities in MAD architectures and underscore the urgent need\nfor robust, specialized defenses prior to real-world deployment.",
      "tldr_zh": "本研究系统调查了基于 Large Language Models (LLMs) 的 Multi-Agent Debate (MAD) 框架对 jailbreak attacks 的漏洞，揭示了其在迭代对话和角色扮演中的安全隐患。研究者提出了一种新型结构化提示重写框架，包括 narrative encapsulation、role-driven escalation、iterative refinement 和 rhetorical obfuscation，以利用 MAD 的动态进行攻击。实验结果显示，MAD 系统比单代理设置更易受攻击，该方法将有害性从 28.14% 显著提高到 80.34%，成功率在某些场景高达 80%，强调了在实际部署前需开发强有力的防御措施。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "33 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16489v1",
      "published_date": "2025-04-23 08:01:50 UTC",
      "updated_date": "2025-04-23 08:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:05:13.700143"
    },
    {
      "arxiv_id": "2504.16485v1",
      "title": "On Developers' Self-Declaration of AI-Generated Code: An Analysis of Practices",
      "title_zh": "开发者对 AI 生成代码的自我声明：实践分析",
      "authors": [
        "Syed Mohammad Kashif",
        "Peng Liang",
        "Amjed Tahir"
      ],
      "abstract": "AI code generation tools have gained significant popularity among developers,\nwho use them to assist in software development due to their capability to\ngenerate code. Existing studies mainly explored the quality, e.g., correctness\nand security, of AI-generated code, while in real-world software development,\nthe prerequisite is to distinguish AI-generated code from human-written code,\nwhich emphasizes the need to explicitly declare AI-generated code by\ndevelopers. To this end, this study intends to understand the ways developers\nuse to self-declare AI-generated code and explore the reasons why developers\nchoose to self-declare or not. We conducted a mixed-methods study consisting of\ntwo phases. In the first phase, we mined GitHub repositories and collected 613\ninstances of AI-generated code snippets. In the second phase, we conducted a\nfollow-up industrial survey, which received 111 valid responses. Our research\nrevealed the practices followed by developers to self-declare AI-generated\ncode. Most practitioners (76.6%) always or sometimes self-declare AI-generated\ncode. In contrast, other practitioners (23.4%) noted that they never\nself-declare AI-generated code. The reasons for self-declaring AI-generated\ncode include the need to track and monitor the code for future review and\ndebugging, and ethical considerations. The reasons for not self-declaring\nAI-generated code include extensive modifications to AI-generated code and the\ndevelopers' perception that self-declaration is an unnecessary activity. We\nfinally provided guidelines for practitioners to self-declare AI-generated\ncode, addressing ethical and code quality concerns.",
      "tldr_zh": "本文研究了开发者在软件开发中如何自我声明 AI-generated code 的实践，并探讨了声明或不声明的原因。通过混合方法，包括从 GitHub 挖掘 613 个 AI-generated code 实例和进行工业调查（获得 111 个有效响应），分析显示 76.6% 的开发者总是或有时声明此类代码，主要出于追踪调试和道德考虑，而 23.4% 从不声明，常因代码被大幅修改或视声明为不必要。该研究提供了指导建议，以解决 AI-generated code 的道德和质量问题。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "35 pages, 17 images, 8 tables, Manuscript submitted to a journal\n  (2025)",
      "pdf_url": "http://arxiv.org/pdf/2504.16485v1",
      "published_date": "2025-04-23 07:52:39 UTC",
      "updated_date": "2025-04-23 07:52:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:05:26.050359"
    },
    {
      "arxiv_id": "2504.16479v1",
      "title": "The Dance of Atoms-De Novo Protein Design with Diffusion Model",
      "title_zh": "原子的舞蹈：De Novo 蛋白质设计与扩散模型",
      "authors": [
        "Yujie Qin",
        "Ming He",
        "Changyong Yu",
        "Ming Ni",
        "Xian Liu",
        "Xiaochen Bo"
      ],
      "abstract": "The de novo design of proteins refers to creating proteins with specific\nstructures and functions that do not naturally exist. In recent years, the\naccumulation of high-quality protein structure and sequence data and\ntechnological advancements have paved the way for the successful application of\ngenerative artificial intelligence (AI) models in protein design. These models\nhave surpassed traditional approaches that rely on fragments and\nbioinformatics. They have significantly enhanced the success rate of de novo\nprotein design, and reduced experimental costs, leading to breakthroughs in the\nfield. Among various generative AI models, diffusion models have yielded the\nmost promising results in protein design. In the past two to three years, more\nthan ten protein design models based on diffusion models have emerged. Among\nthem, the representative model, RFDiffusion, has demonstrated success rates in\n25 protein design tasks that far exceed those of traditional methods, and other\nAI-based approaches like RFjoint and hallucination. This review will\nsystematically examine the application of diffusion models in generating\nprotein backbones and sequences. We will explore the strengths and limitations\nof different models, summarize successful cases of protein design using\ndiffusion models, and discuss future development directions.",
      "tldr_zh": "这篇论文综述了使用 diffusion models 进行 de novo protein design 的最新进展，该方法通过生成式 AI 模型创建不存在于自然的蛋白质结构和序列，超越了传统基于片段和生物信息学的途径，并显著提高了设计成功率和降低了实验成本。论文重点考察了 diffusion models 在生成蛋白质骨架和序列中的应用，突出代表性模型如 RFDiffusion，其在25个蛋白质设计任务中远超传统方法和其他AI方法如RFjoint和hallucination。最终，论文总结了这些模型的优缺点、成功案例，并讨论了未来发展方向。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16479v1",
      "published_date": "2025-04-23 07:45:00 UTC",
      "updated_date": "2025-04-23 07:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:05:37.718097"
    },
    {
      "arxiv_id": "2504.16472v2",
      "title": "Harden and Catch for Just-in-Time Assured LLM-Based Software Testing: Open Research Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Mark Harman",
        "Peter O'Hearn",
        "Shubho Sengupta"
      ],
      "abstract": "Despite decades of research and practice in automated software testing,\nseveral fundamental concepts remain ill-defined and under-explored, yet offer\nenormous potential real-world impact. We show that these concepts raise\nexciting new challenges in the context of Large Language Models for software\ntest generation. More specifically, we formally define and investigate the\nproperties of hardening and catching tests. A hardening test is one that seeks\nto protect against future regressions, while a catching test is one that\ncatches such a regression or a fault in new functionality introduced by a code\nchange. Hardening tests can be generated at any time and may become catching\ntests when a future regression is caught. We also define and motivate the\nCatching 'Just-in-Time' (JiTTest) Challenge, in which tests are generated\n'just-in-time' to catch new faults before they land into production. We show\nthat any solution to Catching JiTTest generation can also be repurposed to\ncatch latent faults in legacy code. We enumerate possible outcomes for\nhardening and catching tests and JiTTests, and discuss open research problems,\ndeployment options, and initial results from our work on automated LLM-based\nhardening at Meta. This paper was written to accompany the keynote by the\nauthors at the ACM International Conference on the Foundations of Software\nEngineering (FSE) 2025. Author order is alphabetical. The corresponding author\nis Mark Harman.",
      "tldr_zh": "本论文探讨了在大型语言模型(LLMs)辅助的软件测试中，harden and catch测试属性的新挑战，定义了harden tests（旨在防范未来回归的测试）和catching tests（捕捉代码变更引发的回归或故障的测试）。作者还引入了Catching 'Just-in-Time' (JiTTest) Challenge，即及时生成测试以在代码进入生产前捕捉新故障，并说明这种方法可用于识别遗留代码中的潜在问题。论文枚举了这些测试的可能结果，讨论了开放研究问题、部署选项，以及在Meta的初步LLM-based hardening工作。该研究为提升软件测试的可靠性和自动化提供了重要见解，并作为ACM FSE 2025主题演讲的配套论文。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "To Appear as keynote paper at FSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16472v2",
      "published_date": "2025-04-23 07:32:43 UTC",
      "updated_date": "2025-05-14 10:55:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:05:49.600132"
    },
    {
      "arxiv_id": "2504.16464v1",
      "title": "ManipDreamer: Boosting Robotic Manipulation World Model with Action Tree and Visual Guidance",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Li",
        "Xiaobao Wei",
        "Xiaowei Chi",
        "Yuming Li",
        "Zhongyu Zhao",
        "Hao Wang",
        "Ningning Ma",
        "Ming Lu",
        "Shanghang Zhang"
      ],
      "abstract": "While recent advancements in robotic manipulation video synthesis have shown\npromise, significant challenges persist in ensuring effective\ninstruction-following and achieving high visual quality. Recent methods, like\nRoboDreamer, utilize linguistic decomposition to divide instructions into\nseparate lower-level primitives, conditioning the world model on these\nprimitives to achieve compositional instruction-following. However, these\nseparate primitives do not consider the relationships that exist between them.\nFurthermore, recent methods neglect valuable visual guidance, including depth\nand semantic guidance, both crucial for enhancing visual quality. This paper\nintroduces ManipDreamer, an advanced world model based on the action tree and\nvisual guidance. To better learn the relationships between instruction\nprimitives, we represent the instruction as the action tree and assign\nembeddings to tree nodes, each instruction can acquire its embeddings by\nnavigating through the action tree. The instruction embeddings can be used to\nguide the world model. To enhance visual quality, we combine depth and semantic\nguidance by introducing a visual guidance adapter compatible with the world\nmodel. This visual adapter enhances both the temporal and physical consistency\nof video generation. Based on the action tree and visual guidance, ManipDreamer\nsignificantly boosts the instruction-following ability and visual quality.\nComprehensive evaluations on robotic manipulation benchmarks reveal that\nManipDreamer achieves large improvements in video quality metrics in both seen\nand unseen tasks, with PSNR improved from 19.55 to 21.05, SSIM improved from\n0.7474 to 0.7982 and reduced Flow Error from 3.506 to 3.201 in unseen tasks,\ncompared to the recent RoboDreamer model. Additionally, our method increases\nthe success rate of robotic manipulation tasks by 2.5% in 6 RLbench tasks on\naverage.",
      "tldr_zh": "本文提出 ManipDreamer，一种通过 Action Tree 和 Visual Guidance 提升机器人操作世界模型的方法，旨在解决现有模型如 RoboDreamer 在指令遵循和视觉质量方面的不足。ManipDreamer 将指令表示为 Action Tree 以捕捉原语之间的关系，并引入视觉指导适配器结合深度和语义指导，提高视频生成的 temporal 和 physical consistency，从而增强指令执行能力。实验结果显示，在机器人操作基准上，ManipDreamer 显著改善了视频质量指标，包括 PSNR 从 19.55 提高到 21.05、SSIM 从 0.7474 提高到 0.7982，以及 Flow Error 从 3.506 减少到 3.201，且在 6 个 RLbench 任务中平均成功率提高了 2.5%。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "9 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16464v1",
      "published_date": "2025-04-23 07:23:41 UTC",
      "updated_date": "2025-04-23 07:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:06:02.754999"
    },
    {
      "arxiv_id": "2504.16460v1",
      "title": "T-VEC: A Telecom-Specific Vectorization Model with Enhanced Semantic Understanding via Deep Triplet Loss Fine-Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Vignesh Ethiraj",
        "Sidhanth Menon",
        "Divya Vijay"
      ],
      "abstract": "The specialized vocabulary and complex concepts of the telecommunications\nindustry present significant challenges for standard Natural Language\nProcessing models. Generic text embeddings often fail to capture\ntelecom-specific semantics, hindering downstream task performance. We introduce\nT-VEC (Telecom Vectorization Model), a novel embedding model tailored for the\ntelecom domain through deep fine-tuning. Developed by NetoAI, T-VEC is created\nby adapting the state-of-the-art gte-Qwen2-1.5B-instruct model using a triplet\nloss objective on a meticulously curated, large-scale dataset of\ntelecom-specific data. Crucially, this process involved substantial\nmodification of weights across 338 layers of the base model, ensuring deep\nintegration of domain knowledge, far exceeding superficial adaptation\ntechniques. We quantify this deep change via weight difference analysis. A key\ncontribution is the development and open-sourcing (MIT License) of the first\ndedicated telecom-specific tokenizer, enhancing the handling of industry\njargon. T-VEC achieves a leading average MTEB score (0.825) compared to\nestablished models and demonstrates vastly superior performance (0.9380 vs.\nless than 0.07) on our internal telecom-specific triplet evaluation benchmark,\nindicating an exceptional grasp of domain-specific nuances, visually confirmed\nby improved embedding separation. This work positions NetoAI at the forefront\nof telecom AI innovation, providing the community with a powerful, deeply\nadapted, open-source tool.",
      "tldr_zh": "本研究针对电信行业的专业词汇和复杂概念，引入了 T-VEC，一种专用嵌入模型，通过对 gte-Qwen2-1.5B-instruct 模型进行深度微调，使用 triplet loss 在大型电信特定数据集上训练，以增强语义理解。关键创新包括修改基模型的 338 层权重并开发开源的电信特定 tokenizer，提升了对行业术语的处理能力。实验结果显示，T-VEC 在 MTEB 基准上取得领先分数（0.825），并在内部电信三元组评估基准上大幅超越其他模型（0.9380 vs. <0.07），为电信 AI 创新提供了一个强大的开源工具。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50"
      ],
      "primary_category": "cs.CL",
      "comment": "Introduces T-VEC, a telecom-specific text embedding model. Fine-tuned\n  gte-Qwen2-1.5B-instruct on curated telecom data points. Includes the first\n  open-source telecom tokenizer. Model available at\n  https://huggingface.co/NetoAISolutions/T-VEC",
      "pdf_url": "http://arxiv.org/pdf/2504.16460v1",
      "published_date": "2025-04-23 07:10:37 UTC",
      "updated_date": "2025-04-23 07:10:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:06:15.393986"
    },
    {
      "arxiv_id": "2504.16448v1",
      "title": "EMRModel: A Large Language Model for Extracting Medical Consultation Dialogues into Structured Medical Records",
      "title_zh": "EMRModel：一种用于将医疗咨询对话提取为结构化医疗记录的大型语言模型",
      "authors": [
        "Shuguang Zhao",
        "Qiangzhong Feng",
        "Zhiyang He",
        "Peipei Sun",
        "Yingying Wang",
        "Xiaodong Tao",
        "Xiaoliang Lu",
        "Mei Cheng",
        "Xinyue Wu",
        "Yanyan Wang",
        "Wei Liang"
      ],
      "abstract": "Medical consultation dialogues contain critical clinical information, yet\ntheir unstructured nature hinders effective utilization in diagnosis and\ntreatment. Traditional methods, relying on rule-based or shallow machine\nlearning techniques, struggle to capture deep and implicit semantics. Recently,\nlarge pre-trained language models and Low-Rank Adaptation (LoRA), a lightweight\nfine-tuning method, have shown promise for structured information extraction.\nWe propose EMRModel, a novel approach that integrates LoRA-based fine-tuning\nwith code-style prompt design, aiming to efficiently convert medical\nconsultation dialogues into structured electronic medical records (EMRs).\nAdditionally, we construct a high-quality, realistically grounded dataset of\nmedical consultation dialogues with detailed annotations. Furthermore, we\nintroduce a fine-grained evaluation benchmark for medical consultation\ninformation extraction and provide a systematic evaluation methodology,\nadvancing the optimization of medical natural language processing (NLP) models.\nExperimental results show EMRModel achieves an F1 score of 88.1%, improving\nby49.5% over standard pre-trained models. Compared to traditional LoRA\nfine-tuning methods, our model shows superior performance, highlighting its\neffectiveness in structured medical record extraction tasks.",
      "tldr_zh": "该论文针对医疗咨询对话的非结构化问题，提出EMRModel，这是一种结合LoRA-based fine-tuning和code-style prompt设计的大型语言模型，用于高效地将对话转化为结构化的电子医疗记录(EMRs)。研究者还构建了一个高质量的医疗咨询对话数据集，并引入了一个细粒度的评估基准，以推进医疗NLP模型的优化。实验结果显示，EMRModel的F1 score达到88.1%，比标准预训练模型提高了49.5%，并在结构化提取任务中表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16448v1",
      "published_date": "2025-04-23 06:17:55 UTC",
      "updated_date": "2025-04-23 06:17:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:06:25.214105"
    },
    {
      "arxiv_id": "2504.16438v1",
      "title": "Private Federated Learning using Preference-Optimized Synthetic Data",
      "title_zh": "翻译失败",
      "authors": [
        "Charlie Hou",
        "Mei-Yu Wang",
        "Yige Zhu",
        "Daniel Lazar",
        "Giulia Fanti"
      ],
      "abstract": "In practical settings, differentially private Federated learning (DP-FL) is\nthe dominant method for training models from private, on-device client data.\nRecent work has suggested that DP-FL may be enhanced or outperformed by methods\nthat use DP synthetic data (Wu et al., 2024; Hou et al., 2024). The primary\nalgorithms for generating DP synthetic data for FL applications require careful\nprompt engineering based on public information and/or iterative private client\nfeedback. Our key insight is that the private client feedback collected by\nprior DP synthetic data methods (Hou et al., 2024; Xie et al., 2024) can be\nviewed as a preference ranking. Our algorithm, Preference Optimization for\nPrivate Client Data (POPri) harnesses client feedback using preference\noptimization algorithms such as Direct Preference Optimization (DPO) to\nfine-tune LLMs to generate high-quality DP synthetic data. To evaluate POPri,\nwe release LargeFedBench, a new federated text benchmark for uncontaminated LLM\nevaluations on federated client data. POPri substantially improves the utility\nof DP synthetic data relative to prior work on LargeFedBench datasets and an\nexisting benchmark from Xie et al. (2024). POPri closes the gap between\nnext-token prediction accuracy in the fully-private and non-private settings by\nup to 68%, compared to 52% for prior synthetic data methods, and 10% for\nstate-of-the-art DP federated learning methods. The code and data are available\nat https://github.com/meiyuw/POPri.",
      "tldr_zh": "该研究提出了一种新算法 Preference Optimization for Private Client Data (POPri)，通过将私有客户端反馈视为偏好排名，并使用 Direct Preference Optimization (DPO) 等方法微调大型语言模型 (LLMs)，来生成高质量的差分隐私合成数据 (DP synthetic data)，以提升联邦学习 (FL) 的实用性。相比传统差分隐私联邦学习 (DP-FL)，POPri 显著提高了合成数据的效用，并在新发布的 LargeFedBench 基准上进行了评估。实验结果显示，POPri 将完全私有和非私有设置下的下一个标记预测准确率差距缩小了多达 68%，超过了先前合成数据方法 (52%) 和最先进 DP-FL 方法 (10%)。这项工作为隐私保护的联邦学习提供了更高效的替代方案，并提供了开源代码和数据。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "Spotlight presentation at SynthData Workshop ICLR25",
      "pdf_url": "http://arxiv.org/pdf/2504.16438v1",
      "published_date": "2025-04-23 05:57:20 UTC",
      "updated_date": "2025-04-23 05:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:06:38.505606"
    },
    {
      "arxiv_id": "2504.16432v1",
      "title": "iTFKAN: Interpretable Time Series Forecasting with Kolmogorov-Arnold Network",
      "title_zh": "翻译失败",
      "authors": [
        "Ziran Liang",
        "Rui An",
        "Wenqi Fan",
        "Yanghui Rao",
        "Yuxuan Liang"
      ],
      "abstract": "As time evolves, data within specific domains exhibit predictability that\nmotivates time series forecasting to predict future trends from historical\ndata. However, current deep forecasting methods can achieve promising\nperformance but generally lack interpretability, hindering trustworthiness and\npractical deployment in safety-critical applications such as auto-driving and\nhealthcare. In this paper, we propose a novel interpretable model, iTFKAN, for\ncredible time series forecasting. iTFKAN enables further exploration of model\ndecision rationales and underlying data patterns due to its interpretability\nachieved through model symbolization. Besides, iTFKAN develops two strategies,\nprior knowledge injection, and time-frequency synergy learning, to effectively\nguide model learning under complex intertwined time series data. Extensive\nexperimental results demonstrated that iTFKAN can achieve promising forecasting\nperformance while simultaneously possessing high interpretive capabilities.",
      "tldr_zh": "本研究针对现有时间序列预测方法虽性能出色但缺乏可解释性的问题，提出了一种新型模型 iTFKAN，该模型基于 Kolmogorov-Arnold Network 通过模型符号化实现可解释性，从而探索模型决策理由和数据模式。iTFKAN 引入先验知识注入和时频协同学习两种策略，以有效指导复杂时间序列数据的学习。实验结果显示，该模型在预测性能上表现出色，同时具备高解释能力，适用于安全关键应用如自动驾驶和医疗领域。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16432v1",
      "published_date": "2025-04-23 05:34:49 UTC",
      "updated_date": "2025-04-23 05:34:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:06:48.815224"
    },
    {
      "arxiv_id": "2504.16427v2",
      "title": "Can Large Language Models Help Multimodal Language Analysis? MMLA: A Comprehensive Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Hanlei Zhang",
        "Zhuohang Li",
        "Yeshuang Zhu",
        "Hua Xu",
        "Peiwu Wang",
        "Haige Zhu",
        "Jie Zhou",
        "Jinchao Zhang"
      ],
      "abstract": "Multimodal language analysis is a rapidly evolving field that leverages\nmultiple modalities to enhance the understanding of high-level semantics\nunderlying human conversational utterances. Despite its significance, little\nresearch has investigated the capability of multimodal large language models\n(MLLMs) to comprehend cognitive-level semantics. In this paper, we introduce\nMMLA, a comprehensive benchmark specifically designed to address this gap. MMLA\ncomprises over 61K multimodal utterances drawn from both staged and real-world\nscenarios, covering six core dimensions of multimodal semantics: intent,\nemotion, dialogue act, sentiment, speaking style, and communication behavior.\nWe evaluate eight mainstream branches of LLMs and MLLMs using three methods:\nzero-shot inference, supervised fine-tuning, and instruction tuning. Extensive\nexperiments reveal that even fine-tuned models achieve only about 60%~70%\naccuracy, underscoring the limitations of current MLLMs in understanding\ncomplex human language. We believe that MMLA will serve as a solid foundation\nfor exploring the potential of large language models in multimodal language\nanalysis and provide valuable resources to advance this field. The datasets and\ncode are open-sourced at https://github.com/thuiar/MMLA.",
      "tldr_zh": "本文探讨大型语言模型 (LLMs) 是否能助力多模态语言分析，并引入 MMLA，这是一个全面基准，包含超过 61K 的多模态话语，覆盖意图、情感、对话行为、情感、说话风格和沟通行为等六个核心维度。研究评估了八个主流 LLMs 和多模态大型语言模型 (MLLMs)，采用零-shot inference、监督微调和指令微调三种方法。实验结果显示，即使经过微调，模型的准确率仅为 60%~70%，突显了当前 MLLMs 在理解复杂人类语言方面的局限性。MMLA 将为探索 LLMs 在多模态语言分析中的潜力提供坚实基础，并已开源数据集和代码。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16427v2",
      "published_date": "2025-04-23 05:25:13 UTC",
      "updated_date": "2025-04-24 07:35:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:07:02.515479"
    },
    {
      "arxiv_id": "2504.16420v1",
      "title": "A Survey of Foundation Model-Powered Recommender Systems: From Feature-Based, Generative to Agentic Paradigms",
      "title_zh": "翻译失败",
      "authors": [
        "Chengkai Huang",
        "Hongtao Huang",
        "Tong Yu",
        "Kaige Xie",
        "Junda Wu",
        "Shuai Zhang",
        "Julian Mcauley",
        "Dietmar Jannach",
        "Lina Yao"
      ],
      "abstract": "Recommender systems (RS) have become essential in filtering information and\npersonalizing content for users. RS techniques have traditionally relied on\nmodeling interactions between users and items as well as the features of\ncontent using models specific to each task. The emergence of foundation models\n(FMs), large scale models trained on vast amounts of data such as GPT, LLaMA\nand CLIP, is reshaping the recommendation paradigm. This survey provides a\ncomprehensive overview of the Foundation Models for Recommender Systems\n(FM4RecSys), covering their integration in three paradigms: (1) Feature-Based\naugmentation of representations, (2) Generative recommendation approaches, and\n(3) Agentic interactive systems. We first review the data foundations of RS,\nfrom traditional explicit or implicit feedback to multimodal content sources.\nWe then introduce FMs and their capabilities for representation learning,\nnatural language understanding, and multi-modal reasoning in RS contexts. The\ncore of the survey discusses how FMs enhance RS under different paradigms.\nAfterward, we examine FM applications in various recommendation tasks. Through\nan analysis of recent research, we highlight key opportunities that have been\nrealized as well as challenges encountered. Finally, we outline open research\ndirections and technical challenges for next-generation FM4RecSys. This survey\nnot only reviews the state-of-the-art methods but also provides a critical\nanalysis of the trade-offs among the feature-based, the generative, and the\nagentic paradigms, outlining key open issues and future research directions.",
      "tldr_zh": "这篇调查论文探讨了基础模型（FMs）如 GPT、LLaMA 和 CLIP 如何革新推荐系统（RS），从传统特征增强到生成式和代理式范式。论文系统回顾了 RS 的数据基础，包括显式/隐式反馈和多模态内容，并介绍了 FMs 在表示学习、自然语言理解和多模态推理中的应用。核心贡献在于分析 FMs 在三种范式下的整合方式，包括 Feature-Based 表示增强、Generative 推荐方法和 Agentic 交互系统，并评估其在各种推荐任务中的性能优势和挑战。最终，论文指出了 FM4RecSys 的关键机遇、技术权衡以及未来研究方向，如优化范式间权衡和解决开放问题。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16420v1",
      "published_date": "2025-04-23 05:02:51 UTC",
      "updated_date": "2025-04-23 05:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:07:13.236639"
    },
    {
      "arxiv_id": "2504.16419v2",
      "title": "PixelWeb: The First Web GUI Dataset with Pixel-Wise Labels",
      "title_zh": "翻译失败",
      "authors": [
        "Qi Yang",
        "Weichen Bi",
        "Haiyang Shen",
        "Yaoqi Guo",
        "Yun Ma"
      ],
      "abstract": "Graphical User Interface (GUI) datasets are crucial for various downstream\ntasks. However, GUI datasets often generate annotation information through\nautomatic labeling, which commonly results in inaccurate GUI element BBox\nannotations, including missing, duplicate, or meaningless BBoxes. These issues\ncan degrade the performance of models trained on these datasets, limiting their\neffectiveness in real-world applications. Additionally, existing GUI datasets\nonly provide BBox annotations visually, which restricts the development of\nvisually related GUI downstream tasks. To address these issues, we introduce\nPixelWeb, a large-scale GUI dataset containing over 100,000 annotated web\npages. PixelWeb is constructed using a novel automatic annotation approach that\nintegrates visual feature extraction and Document Object Model (DOM) structure\nanalysis through two core modules: channel derivation and layer analysis.\nChannel derivation ensures accurate localization of GUI elements in cases of\nocclusion and overlapping elements by extracting BGRA four-channel bitmap\nannotations. Layer analysis uses the DOM to determine the visibility and\nstacking order of elements, providing precise BBox annotations. Additionally,\nPixelWeb includes comprehensive metadata such as element images, contours, and\nmask annotations. Manual verification by three independent annotators confirms\nthe high quality and accuracy of PixelWeb annotations. Experimental results on\nGUI element detection tasks show that PixelWeb achieves performance on the\nmAP95 metric that is 3-7 times better than existing datasets. We believe that\nPixelWeb has great potential for performance improvement in downstream tasks\nsuch as GUI generation and automated user interaction.",
      "tldr_zh": "该论文介绍了 PixelWeb，这是第一个带有像素级标注的大型 Web GUI 数据集，旨在解决现有 GUI 数据集的 BBox 注解不准确问题，如缺失、重复或无意义标注，从而提升下游任务的性能。PixelWeb 通过创新的自动注解方法结合视觉特征提取和 DOM 结构分析，包括 channel derivation（提取 BGRA 四通道位图以处理遮挡和重叠元素）和 layer analysis（利用 DOM 确定元素可见性和堆叠顺序），提供了精确的 BBox 注解、元素图像、轮廓和掩码元数据。实验结果显示，在 GUI 元素检测任务上，PixelWeb 的 mAP95 指标比现有数据集高 3-7 倍，具有巨大潜力改善下游应用如 GUI 生成和自动化用户交互。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16419v2",
      "published_date": "2025-04-23 05:01:25 UTC",
      "updated_date": "2025-04-27 06:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:07:26.762379"
    },
    {
      "arxiv_id": "2504.16416v1",
      "title": "FeedQUAC: Quick Unobtrusive AI-Generated Commentary",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Long",
        "Kendra Wannamaker",
        "Jo Vermeulen",
        "George Fitzmaurice",
        "Justin Matejka"
      ],
      "abstract": "Design thrives on feedback. However, gathering constant feedback throughout\nthe design process can be labor-intensive and disruptive. We explore how AI can\nbridge this gap by providing effortless, ambient feedback. We introduce\nFeedQUAC, a design companion that delivers real-time AI-generated commentary\nfrom a variety of perspectives through different personas. A design probe study\nwith eight participants highlights how designers can leverage quick yet ambient\nAI feedback to enhance their creative workflows. Participants highlight\nbenefits such as convenience, playfulness, confidence boost, and inspiration\nfrom this lightweight feedback agent, while suggesting additional features,\nlike chat interaction and context curation. We discuss the role of AI feedback,\nits strengths and limitations, and how to integrate it into existing design\nworkflows while balancing user involvement. Our findings also suggest that\nambient interaction is a valuable consideration for both the design and\nevaluation of future creativity support systems.",
      "tldr_zh": "该研究探讨了AI如何提供便利且非侵入性的反馈，以支持设计过程。作者引入了FeedQUAC系统，这是一个设计伴侣工具，能够实时生成AI-driven评论，从多种personas视角提供ambient反馈。通过一项涉及八位参与者的design probe study，研究发现FeedQUAC提升了设计师的创意工作流，包括便利性、趣味性、自信提升和灵感激发，同时参与者建议添加chat interaction和context curation功能。总体而言，该工作讨论了AI反馈的优缺点，并强调了ambient interaction在未来创意支持系统设计中的重要性。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "20 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2504.16416v1",
      "published_date": "2025-04-23 04:48:00 UTC",
      "updated_date": "2025-04-23 04:48:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:07:37.675825"
    },
    {
      "arxiv_id": "2504.16404v2",
      "title": "Assessing the Feasibility of Internet-Sourced Video for Automatic Cattle Lameness Detection",
      "title_zh": "评估使用互联网来源视频进行自动牛瘸病检测的可行性",
      "authors": [
        "Md Fahimuzzman Sohan",
        "A. H. Abdul Hafez",
        "Raid Alzubi"
      ],
      "abstract": "Cattle lameness is often caused by hoof injuries or interdigital dermatitis,\nleads to pain and significantly impacts essential physiological activities such\nas walking, feeding, and drinking. This study presents a deep learning-based\nmodel for detecting cattle lameness, sickness, or gait abnormalities using\npublicly available video data. The dataset consists of 50 unique videos from 40\nindividual cattle, recorded from various angles in both indoor and outdoor\nenvironments. Half of the dataset represents naturally walking\n(normal/non-lame) cattle, while the other half consists of cattle exhibiting\ngait abnormalities (lame). To enhance model robustness and generalizability,\ndata augmentation was applied to the training data. The pre-processed videos\nwere then classified using two deep learning models: ConvLSTM2D and 3D CNN. A\ncomparative analysis of the results demonstrates strong classification\nperformance. Specifically, the 3D CNN model achieved a video-level\nclassification accuracy of 90%, with precision, recall, and f1-score of 90.9%,\n90.9%, and 90.91% respectively. The ConvLSTM2D model exhibited a slightly lower\naccuracy of 85%. This study highlights the effectiveness of directly applying\nclassification models to learn spatiotemporal features from video data,\noffering an alternative to traditional multi-stage approaches that typically\ninvolve object detection, pose estimation, and feature extraction. Besides, the\nfindings demonstrate that the proposed deep learning models, particularly the\n3D CNN, effectively classify and detect lameness in cattle while simplifying\nthe processing pipeline.",
      "tldr_zh": "本研究评估了使用互联网来源视频自动检测牛跛行（lameness）的可行性，数据集包括50个视频，来自40头牛的室内外场景，其中一半为正常行走（non-lame），一半为步态异常（lame）。研究采用数据增强（data augmentation）技术，并使用ConvLSTM2D和3D CNN模型直接对视频进行分类，以学习时空特征，从而简化传统多阶段方法如物体检测（object detection）和姿态估计（pose estimation）。结果显示，3D CNN模型在视频级分类中达到90%的准确率，精确度（precision）、召回率（recall）和F1分数分别为90.9%、90.9%和90.91%，而ConvLSTM2D模型的准确率略低，为85%。该研究证明了深度学习模型在牛跛行检测中的有效性，提供了一种更简化的处理管道，为动物健康监测应用提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16404v2",
      "published_date": "2025-04-23 04:17:41 UTC",
      "updated_date": "2025-05-13 02:22:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:07:49.925201"
    },
    {
      "arxiv_id": "2504.16394v2",
      "title": "ConTextual: Improving Clinical Text Summarization in LLMs with Context-preserving Token Filtering and Knowledge Graphs",
      "title_zh": "ConTextual：通过上下文保留令牌过滤和知识图谱改进 LLMs 中的临床文本摘要",
      "authors": [
        "Fahmida Liza Piya",
        "Rahmatollah Beheshti"
      ],
      "abstract": "Unstructured clinical data can serve as a unique and rich source of\ninformation that can meaningfully inform clinical practice. Extracting the most\npertinent context from such data is critical for exploiting its true potential\ntoward optimal and timely decision-making in patient care. While prior research\nhas explored various methods for clinical text summarization, most prior\nstudies either process all input tokens uniformly or rely on heuristic-based\nfilters, which can overlook nuanced clinical cues and fail to prioritize\ninformation critical for decision-making. In this study, we propose Contextual,\na novel framework that integrates a Context-Preserving Token Filtering method\nwith a Domain-Specific Knowledge Graph (KG) for contextual augmentation. By\npreserving context-specific important tokens and enriching them with structured\nknowledge, ConTextual improves both linguistic coherence and clinical fidelity.\nOur extensive empirical evaluations on two public benchmark datasets\ndemonstrate that ConTextual consistently outperforms other baselines. Our\nproposed approach highlights the complementary role of token-level filtering\nand structured retrieval in enhancing both linguistic and clinical integrity,\nas well as offering a scalable solution for improving precision in clinical\ntext generation.",
      "tldr_zh": "该研究提出ConTextual框架，以提升LLMs在临床文本摘要中的性能，通过Context-Preserving Token Filtering方法保留关键上下文标记，并结合Domain-Specific Knowledge Graph (KG)进行知识增强，从而提高语言连贯性和临床准确性。相较于传统方法，该框架避免了均匀处理输入或依赖启发式过滤的局限，确保了微妙临床线索的优先考虑。在两个公共基准数据集上的广泛实证评估显示，ConTextual优于其他基线模型，并提供了一个可扩展的解决方案，强调了标记级过滤和结构化检索在提升临床文本生成精度的互补作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16394v2",
      "published_date": "2025-04-23 03:42:46 UTC",
      "updated_date": "2025-05-12 14:57:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:08:01.407983"
    },
    {
      "arxiv_id": "2504.16381v4",
      "title": "PINN-MEP: Continuous Neural Representations for Minimum-Energy Path Discovery in Molecular Systems",
      "title_zh": "PINN-MEP：用于分子系统中最小能量路径发现的连续神经表示",
      "authors": [
        "Magnus Petersen",
        "Roberto Covino"
      ],
      "abstract": "Characterizing conformational transitions in physical systems remains a\nfundamental challenge in the computational sciences. Traditional sampling\nmethods like molecular dynamics (MD) or MCMC often struggle with the\nhigh-dimensional nature of molecular systems and the high energy barriers of\ntransitions between stable states. While these transitions are rare events in\nsimulation timescales, they often represent the most biologically significant\nprocesses - for example, the conformational change of an ion channel protein\nfrom its closed to open state, which controls cellular ion flow and is crucial\nfor neural signaling. Such transitions in real systems may take milliseconds to\nseconds but could require months or years of continuous simulation to observe\neven once. We present a method that reformulates transition path generation as\na continuous optimization problem solved through physics-informed neural\nnetworks (PINNs) inspired by string methods for minimum-energy path (MEP)\ngeneration. By representing transition paths as implicit neural functions and\nleveraging automatic differentiation with differentiable molecular dynamics\nforce fields, our method enables the efficient discovery of physically\nrealistic transition pathways without requiring expensive path sampling. We\ndemonstrate our method's effectiveness on two proteins, including an explicitly\nhydrated bovine pancreatic trypsin inhibitor (BPTI) system with over 8,300\natoms.",
      "tldr_zh": "本研究针对分子系统构象转变的计算挑战，提出PINN-MEP方法，该方法将转变路径生成重新表述为连续优化问题，使用物理信息神经网络(PINNs)受弦方法启发，通过隐式神经函数和自动微分结合可微分子动力学力场，实现高效发现最小能量路径(MEP)。与传统分子动力学(MD)或MCMC方法相比，该方法避免了昂贵的路径采样，能快速生成物理真实性转变路径。实验在两个蛋白系统中验证了其有效性，包括一个超过8300原子的显式水合牛胰蛋白酶抑制剂(BPTI)系统。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "Update 08.05.2025: Added some intermediate steps in the derivation of\n  the loss to add clarity. Update 28.04.2025: Added citation and reference to\n  just-released work \"Action-Minimization Meets Generative Modeling: Efficient\n  Transition Path Sampling with the Onsager-Machlup Functional\" by Sanjeev Raja\n  et al. and added an appendix section clarifying some loss derivation steps",
      "pdf_url": "http://arxiv.org/pdf/2504.16381v4",
      "published_date": "2025-04-23 03:02:29 UTC",
      "updated_date": "2025-05-08 15:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:08:13.924977"
    },
    {
      "arxiv_id": "2504.16378v1",
      "title": "Cyberoception: Finding a Painlessly-Measurable New Sense in the Cyberworld Towards Emotion-Awareness in Computing",
      "title_zh": "翻译失败",
      "authors": [
        "Tadashi Okoshi",
        "Zexiong Gao",
        "Tan Yi Zhen",
        "Takumi Karasawa",
        "Takeshi Miki",
        "Wataru Sasaki",
        "Rajesh K. Balan"
      ],
      "abstract": "In Affective computing, recognizing users' emotions accurately is the basis\nof affective human-computer interaction. Understanding users' interoception\ncontributes to a better understanding of individually different emotional\nabilities, which is essential for achieving inter-individually accurate emotion\nestimation. However, existing interoception measurement methods, such as the\nheart rate discrimination task, have several limitations, including their\ndependence on a well-controlled laboratory environment and precision apparatus,\nmaking monitoring users' interoception challenging. This study aims to\ndetermine other forms of data that can explain users' interoceptive or similar\nstates in their real-world lives and propose a novel hypothetical concept\n\"cyberoception,\" a new sense (1) which has properties similar to interoception\nin terms of the correlation with other emotion-related abilities, and (2) which\ncan be measured only by the sensors embedded inside commodity smartphone\ndevices in users' daily lives. Results from a 10-day-long in-lab/in-the-wild\nhybrid experiment reveal a specific cyberoception type \"Turn On\" (users'\nsubjective sensory perception about the frequency of turning-on behavior on\ntheir smartphones), significantly related to participants' emotional valence.\nWe anticipate that cyberoception to serve as a fundamental building block for\ndeveloping more \"emotion-aware\", user-friendly applications and services.",
      "tldr_zh": "该研究在情感计算（Affective computing）领域提出“cyberoception”这一新概念，作为一种易于测量的感官形式，旨在弥补现有内感受觉（interoception）评估方法的局限性，如依赖实验室环境。研究通过10天的混合实验（in-lab/in-the-wild），发现用户对智能手机“Turn On”（开启行为频率的主观感知）显著与emotional valence（情绪正性）相关，表明cyberoception具备与内感受觉相似的特性，且可仅凭日常智能手机传感器实现。最终，该框架有望成为开发更“emotion-aware”的用户友好应用和服务的基础。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted by ACM CHI2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16378v1",
      "published_date": "2025-04-23 02:56:55 UTC",
      "updated_date": "2025-04-23 02:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:08:26.510153"
    },
    {
      "arxiv_id": "2504.16364v1",
      "title": "CLPSTNet: A Progressive Multi-Scale Convolutional Steganography Model Integrating Curriculum Learning",
      "title_zh": "CLPSTNet：整合课程学习的渐进式多尺度卷积隐写模型",
      "authors": [
        "Fengchun Liu",
        "Tong Zhang",
        "Chunying Zhang"
      ],
      "abstract": "In recent years, a large number of works have introduced Convolutional Neural\nNetworks (CNNs) into image steganography, which transform traditional\nsteganography methods such as hand-crafted features and prior knowledge design\ninto steganography methods that neural networks autonomically learn information\nembedding. However, due to the inherent complexity of digital images, issues of\ninvisibility and security persist when using CNN models for information\nembedding. In this paper, we propose Curriculum Learning Progressive Steganophy\nNetwork (CLPSTNet). The network consists of multiple progressive multi-scale\nconvolutional modules that integrate Inception structures and dilated\nconvolutions. The module contains multiple branching pathways, starting from a\nsmaller convolutional kernel and dilatation rate, extracting the basic, local\nfeature information from the feature map, and gradually expanding to the\nconvolution with a larger convolutional kernel and dilatation rate for\nperceiving the feature information of a larger receptive field, so as to\nrealize the multi-scale feature extraction from shallow to deep, and from fine\nto coarse, allowing the shallow secret information features to be refined in\ndifferent fusion stages. The experimental results show that the proposed\nCLPSTNet not only has high PSNR , SSIM metrics and decoding accuracy on three\nlarge public datasets, ALASKA2, VOC2012 and ImageNet, but also the\nsteganographic images generated by CLPSTNet have low steganalysis scores.You\ncan find our code at\n\\href{https://github.com/chaos-boops/CLPSTNet}{https://github.com/chaos-boops/CLPSTNet}.",
      "tldr_zh": "本论文提出 CLPSTNet，一种整合 Curriculum Learning 的渐进式多尺度卷积隐写模型，旨在解决 CNN 在图像隐写中存在的隐形性和安全性问题。模型由多个渐进式多尺度卷积模块组成，这些模块结合 Inception structures 和 dilated convolutions，从小卷积核和扩张率开始逐步扩展，实现从浅层到深层、从细到粗的多尺度特征提取和信息融合。实验结果显示，CLPSTNet 在 ALASKA2、VOC2012 和 ImageNet 数据集上取得了高 PSNR、SSIM 指标和解码准确率，同时生成的隐写图像具有低 steganalysis scores，显著提升了隐写的鲁棒性和安全性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16364v1",
      "published_date": "2025-04-23 02:34:25 UTC",
      "updated_date": "2025-04-23 02:34:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:08:37.225806"
    },
    {
      "arxiv_id": "2504.16357v1",
      "title": "DP2FL: Dual Prompt Personalized Federated Learning in Foundation Models",
      "title_zh": "DP2FL：基础模型中的双提示个性化联邦学习",
      "authors": [
        "Ying Chang",
        "Xiaohu Shi",
        "Xiaohui Zhao",
        "Zhaohuang Chen",
        "Deyin Ma"
      ],
      "abstract": "Personalized federated learning (PFL) has garnered significant attention for\nits ability to address heterogeneous client data distributions while preserving\ndata privacy. However, when local client data is limited, deep learning models\noften suffer from insufficient training, leading to suboptimal performance.\nFoundation models, such as CLIP (Contrastive Language-Image Pretraining),\nexhibit strong feature extraction capabilities and can alleviate this issue by\nfine-tuning on limited local data. Despite their potential, foundation models\nare rarely utilized in federated learning scenarios, and challenges related to\nintegrating new clients remain largely unresolved. To address these challenges,\nwe propose the Dual Prompt Personalized Federated Learning (DP2FL) framework,\nwhich introduces dual prompts and an adaptive aggregation strategy. DP2FL\ncombines global task awareness with local data-driven insights, enabling local\nmodels to achieve effective generalization while remaining adaptable to\nspecific data distributions. Moreover, DP2FL introduces a global model that\nenables prediction on new data sources and seamlessly integrates newly added\nclients without requiring retraining. Experimental results in highly\nheterogeneous environments validate the effectiveness of DP2FL's prompt design\nand aggregation strategy, underscoring the advantages of prediction on novel\ndata sources and demonstrating the seamless integration of new clients into the\nfederated learning framework.",
      "tldr_zh": "该研究针对个性化联邦学习（Personalized Federated Learning, PFL）在数据有限和异构分布下的性能不足问题，提出DP2FL框架，利用基础模型如CLIP进行微调。DP2FL引入双提示（Dual Prompts）和自适应聚合策略（Adaptive Aggregation Strategy），结合全局任务意识与本地数据洞见，实现模型的有效泛化和对特定数据分布的适应，同时支持全局模型在新数据源上预测及新客户端的无缝整合。实验结果在高度异构环境中验证了该框架的提示设计和聚合策略优势，展示了其在新型数据源预测和客户端扩展方面的显著改进。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16357v1",
      "published_date": "2025-04-23 02:13:56 UTC",
      "updated_date": "2025-04-23 02:13:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:08:51.039994"
    },
    {
      "arxiv_id": "2504.16353v1",
      "title": "Transformer-Based Extraction of Statutory Definitions from the U.S. Code",
      "title_zh": "翻译失败",
      "authors": [
        "Arpana Hosabettu",
        "Harsh Shah"
      ],
      "abstract": "Automatic extraction of definitions from legal texts is critical for\nenhancing the comprehension and clarity of complex legal corpora such as the\nUnited States Code (U.S.C.). We present an advanced NLP system leveraging\ntransformer-based architectures to automatically extract defined terms, their\ndefinitions, and their scope from the U.S.C. We address the challenges of\nautomatically identifying legal definitions, extracting defined terms, and\ndetermining their scope within this complex corpus of over 200,000 pages of\nfederal statutory law. Building upon previous feature-based machine learning\nmethods, our updated model employs domain-specific transformers (Legal-BERT)\nfine-tuned specifically for statutory texts, significantly improving extraction\naccuracy. Our work implements a multi-stage pipeline that combines document\nstructure analysis with state-of-the-art language models to process legal text\nfrom the XML version of the U.S. Code. Each paragraph is first classified using\na fine-tuned legal domain BERT model to determine if it contains a definition.\nOur system then aggregates related paragraphs into coherent definitional units\nand applies a combination of attention mechanisms and rule-based patterns to\nextract defined terms and their jurisdictional scope. The definition extraction\nsystem is evaluated on multiple titles of the U.S. Code containing thousands of\ndefinitions, demonstrating significant improvements over previous approaches.\nOur best model achieves 96.8% precision and 98.9% recall (98.2% F1-score),\nsubstantially outperforming traditional machine learning classifiers. This work\ncontributes to improving accessibility and understanding of legal information\nwhile establishing a foundation for downstream legal reasoning tasks.",
      "tldr_zh": "该研究提出了一种基于 Transformer 的 NLP 系统，用于从美国法典 (U.S. Code) 中自动提取法定定义，包括定义术语、定义内容及其范围，以提升法律文本的可理解性。该系统采用 Legal-BERT 等域特定模型进行微调，并设计了一个多阶段管道：首先通过文档结构分析和段落分类识别潜在定义，然后聚合相关段落并结合注意力机制和规则模式进行提取。实验结果显示，该模型在多个 U.S. Code 标题上实现了 96.8% precision、98.9% recall 和 98.2% F1-score，显著优于传统机器学习方法，为法律信息访问和下游法律推理任务奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "7 pages, to be published in IEEE AIIoT 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16353v1",
      "published_date": "2025-04-23 02:09:53 UTC",
      "updated_date": "2025-04-23 02:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:09:01.944278"
    },
    {
      "arxiv_id": "2504.16352v1",
      "title": "Disentangling and Generating Modalities for Recommendation in Missing Modality Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Jiwan Kim",
        "Hongseok Kang",
        "Sein Kim",
        "Kibum Kim",
        "Chanyoung Park"
      ],
      "abstract": "Multi-modal recommender systems (MRSs) have achieved notable success in\nimproving personalization by leveraging diverse modalities such as images,\ntext, and audio. However, two key challenges remain insufficiently addressed:\n(1) Insufficient consideration of missing modality scenarios and (2) the\noverlooking of unique characteristics of modality features. These challenges\nresult in significant performance degradation in realistic situations where\nmodalities are missing. To address these issues, we propose Disentangling and\nGenerating Modality Recommender (DGMRec), a novel framework tailored for\nmissing modality scenarios. DGMRec disentangles modality features into general\nand specific modality features from an information-based perspective, enabling\nricher representations for recommendation. Building on this, it generates\nmissing modality features by integrating aligned features from other modalities\nand leveraging user modality preferences. Extensive experiments show that\nDGMRec consistently outperforms state-of-the-art MRSs in challenging scenarios,\nincluding missing modalities and new item settings as well as diverse missing\nratios and varying levels of missing modalities. Moreover, DGMRec's\ngeneration-based approach enables cross-modal retrieval, a task inapplicable\nfor existing MRSs, highlighting its adaptability and potential for real-world\napplications. Our code is available at https://github.com/ptkjw1997/DGMRec.",
      "tldr_zh": "该研究针对多模态推荐系统（MRSs）在模态缺失场景下的性能下降问题，提出了Disentangling and Generating Modality Recommender (DGMRec)框架，以解决模态特征的独特特性被忽略的问题。DGMRec通过将模态特征解耦成通用和特定特征，并利用其他模态的特征以及用户偏好来生成缺失模态特征，从而提升推荐的鲁棒性和表示能力。实验结果显示，DGMRec在模态缺失、新项目设置以及不同缺失比例的场景中， consistently outperforms 现有MRSs，并在跨模态检索任务上表现出色，证明了其在实际应用中的适应性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "SIGIR 2025",
      "pdf_url": "http://arxiv.org/pdf/2504.16352v1",
      "published_date": "2025-04-23 02:04:14 UTC",
      "updated_date": "2025-04-23 02:04:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:09:13.277306"
    },
    {
      "arxiv_id": "2504.16350v1",
      "title": "QAOA-GPT: Efficient Generation of Adaptive and Regular Quantum Approximate Optimization Algorithm Circuits",
      "title_zh": "QAOA-GPT：高效生成自适应和常规量子近似优化算法电路",
      "authors": [
        "Ilya Tyagin",
        "Marwa H. Farag",
        "Kyle Sherbert",
        "Karunya Shirali",
        "Yuri Alexeev",
        "Ilya Safro"
      ],
      "abstract": "Quantum computing has the potential to improve our ability to solve certain\noptimization problems that are computationally difficult for classical\ncomputers, by offering new algorithmic approaches that may provide speedups\nunder specific conditions. In this work, we introduce QAOA-GPT, a generative\nframework that leverages Generative Pretrained Transformers (GPT) to directly\nsynthesize quantum circuits for solving quadratic unconstrained binary\noptimization problems, and demonstrate it on the MaxCut problem on graphs. To\ndiversify the training circuits and ensure their quality, we have generated a\nsynthetic dataset using the adaptive QAOA approach, a method that incrementally\nbuilds and optimizes problem-specific circuits. The experiments conducted on a\ncurated set of graph instances demonstrate that QAOA-GPT, generates high\nquality quantum circuits for new problem instances unseen in the training as\nwell as successfully parametrizes QAOA. Our results show that using QAOA-GPT to\ngenerate quantum circuits will significantly decrease both the computational\noverhead of classical QAOA and adaptive approaches that often use gradient\nevaluation to generate the circuit and the classical optimization of the\ncircuit parameters. Our work shows that generative AI could be a promising\navenue to generate compact quantum circuits in a scalable way.",
      "tldr_zh": "本研究引入了 QAOA-GPT，这是一个基于 Generative Pretrained Transformers (GPT) 的生成框架，用于高效合成量子电路，针对二次无约束二元优化问题如 MaxCut。框架利用 adaptive QAOA 方法生成合成数据集，确保电路多样性和质量，并在图实例上进行实验。结果表明，QAOA-GPT 能为新问题实例生成高质量电路，显著降低经典 QAOA 的计算开销，并展示生成 AI 在可扩展量子电路生成方面的潜力。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16350v1",
      "published_date": "2025-04-23 02:00:36 UTC",
      "updated_date": "2025-04-23 02:00:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:09:25.913365"
    },
    {
      "arxiv_id": "2504.16343v1",
      "title": "Mining Software Repositories for Expert Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Chad Marshall",
        "Andrew Barovic",
        "Armin Moin"
      ],
      "abstract": "We propose an automated approach to bug assignment to developers in large\nopen-source software projects. This way, we assist human bug triagers who are\nin charge of finding the best developer with the right level of expertise in a\nparticular area to be assigned to a newly reported issue. Our approach is based\non the history of software development as documented in the issue tracking\nsystems. We deploy BERTopic and techniques from TopicMiner. Our approach works\nbased on the bug reports' features, such as the corresponding products and\ncomponents, as well as their priority and severity levels. We sort developers\nbased on their experience with specific combinations of new reports. The\nevaluation is performed using Top-k accuracy, and the results are compared with\nthe reported results in prior work, namely TopicMiner MTM, BUGZIE, Bug triaging\nvia deep Reinforcement Learning BT-RL, and LDA-SVM. The evaluation data come\nfrom various Eclipse and Mozilla projects, such as JDT, Firefox, and\nThunderbird.",
      "tldr_zh": "本研究提出了一种自动化方法，用于从软件仓库中挖掘数据以推荐专家开发者处理新报告的 bug，从而辅助人类 triager。该方法利用 BERTopic 和 TopicMiner 技术，基于 bug 报告的历史信息（如产品、组件、优先级和严重性）评估开发者的经验，并对他们进行排序。实验采用 Top-k accuracy 指标，在 Eclipse 和 Mozilla 项目（如 JDT、Firefox 和 Thunderbird）上进行评估，结果显示该方法优于现有模型如 TopicMiner MTM、BUGZIE、BT-RL 和 LDA-SVM。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2504.16343v1",
      "published_date": "2025-04-23 01:41:08 UTC",
      "updated_date": "2025-04-23 01:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T16:09:36.838394"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 99,
  "processed_papers_count": 99,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-24T16:09:58.500431"
}