[
  {
    "arxiv_id": "2405.19575v1",
    "title": "A Deep Convolutional Neural Network-based Model for Aspect and Polarity Classification in Hausa Movie Reviews",
    "authors": [
      "Umar Ibrahim",
      "Abubakar Yakubu Zandam",
      "Fatima Muhammad Adam",
      "Aminu Musa"
    ],
    "abstract": "Aspect-based Sentiment Analysis (ABSA) is crucial for understanding sentiment\nnuances in text, especially across diverse languages and cultures. This paper\nintroduces a novel Deep Convolutional Neural Network (CNN)-based model tailored\nfor aspect and polarity classification in Hausa movie reviews, an\nunderrepresented language in sentiment analysis research. A comprehensive Hausa\nABSA dataset is created, filling a significant gap in resource availability.\nThe dataset, preprocessed using sci-kit-learn for TF-IDF transformation,\nincludes manually annotated aspect-level feature ontology words and sentiment\npolarity assignments. The proposed model combines CNNs with attention\nmechanisms for aspect-word prediction, leveraging contextual information and\nsentiment polarities. With 91% accuracy on aspect term extraction and 92% on\nsentiment polarity classification, the model outperforms traditional machine\nmodels, offering insights into specific aspects and sentiments. This study\nadvances ABSA research, particularly in underrepresented languages, with\nimplications for cross-cultural linguistic research.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in the proceedings of ICCAIT 2023",
    "pdf_url": "http://arxiv.org/pdf/2405.19575v1",
    "published_date": "2024-05-29 23:45:42 UTC",
    "updated_date": "2024-05-29 23:45:42 UTC"
  },
  {
    "arxiv_id": "2405.19567v2",
    "title": "Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding",
    "authors": [
      "Shenghuan Sun",
      "Alexander Schubert",
      "Gregory M. Goldgof",
      "Zhiqing Sun",
      "Thomas Hartvigsen",
      "Atul J. Butte",
      "Ahmed Alaa"
    ],
    "abstract": "Vision-Language Models (VLM) can support clinicians by analyzing medical\nimages and engaging in natural language interactions to assist in diagnostic\nand treatment tasks. However, VLMs often exhibit \"hallucinogenic\" behavior,\ngenerating textual outputs not grounded in contextual multimodal information.\nThis challenge is particularly pronounced in the medical domain, where we do\nnot only require VLM outputs to be accurate in single interactions but also to\nbe consistent with clinical reasoning and diagnostic pathways throughout\nmulti-turn conversations. For this purpose, we propose a new alignment\nalgorithm that uses symbolic representations of clinical reasoning to ground\nVLMs in medical knowledge. These representations are utilized to (i) generate\nGPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM\nconversations with demonstrations of clinical reasoning, and (ii) create an\nautomatic reward function that evaluates the clinical validity of VLM\ngenerations throughout clinician-VLM interactions. Our algorithm eliminates the\nneed for human involvement in training data generation or reward model\nconstruction, reducing costs compared to standard reinforcement learning with\nhuman feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a\nconversational VLM finetuned for analyzing bone marrow pathology slides,\ndemonstrating strong performance in multi-turn medical conversations.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Code available at: https://github.com/AlaaLab/Dr-LLaVA",
    "pdf_url": "http://arxiv.org/pdf/2405.19567v2",
    "published_date": "2024-05-29 23:19:28 UTC",
    "updated_date": "2024-10-10 07:47:21 UTC"
  },
  {
    "arxiv_id": "2406.00062v1",
    "title": "Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study",
    "authors": [
      "David Pissarra",
      "Isabel Curioso",
      "João Alveira",
      "Duarte Pereira",
      "Bruno Ribeiro",
      "Tomás Souper",
      "Vasco Gomes",
      "André V. Carreiro",
      "Vitor Rolla"
    ],
    "abstract": "Automated clinical text anonymization has the potential to unlock the\nwidespread sharing of textual health data for secondary usage while assuring\npatient privacy and safety. Despite the proposal of many complex and\ntheoretically successful anonymization solutions in literature, these\ntechniques remain flawed. As such, clinical institutions are still reluctant to\napply them for open access to their data. Recent advances in developing Large\nLanguage Models (LLMs) pose a promising opportunity to further the field, given\ntheir capability to perform various tasks. This paper proposes six new\nevaluation metrics tailored to the challenges of generative anonymization with\nLLMs. Moreover, we present a comparative study of LLM-based methods, testing\nthem against two baseline techniques. Our results establish LLM-based models as\na reliable alternative to common approaches, paving the way toward trustworthy\nanonymization of clinical text.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR",
      "cs.LG",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00062v1",
    "published_date": "2024-05-29 23:07:58 UTC",
    "updated_date": "2024-05-29 23:07:58 UTC"
  },
  {
    "arxiv_id": "2405.19561v1",
    "title": "Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models",
    "authors": [
      "Venkat Venkatasubramanian",
      "Arijit Chakraborty"
    ],
    "abstract": "The startling success of ChatGPT and other large language models (LLMs) using\ntransformer-based generative neural network architecture in applications such\nas natural language processing and image synthesis has many researchers excited\nabout potential opportunities in process systems engineering (PSE). The almost\nhuman-like performance of LLMs in these areas is indeed very impressive,\nsurprising, and a major breakthrough. Their capabilities are very useful in\ncertain tasks, such as writing first drafts of documents, code writing\nassistance, text summarization, etc. However, their success is limited in\nhighly scientific domains as they cannot yet reason, plan, or explain due to\ntheir lack of in-depth domain knowledge. This is a problem in domains such as\nchemical engineering as they are governed by fundamental laws of physics and\nchemistry (and biology), constitutive relations, and highly technical knowledge\nabout materials, processes, and systems. Although purely data-driven machine\nlearning has its immediate uses, the long-term success of AI in scientific and\nengineering domains would depend on developing hybrid AI systems that use first\nprinciples and technical knowledge effectively. We call these hybrid AI systems\nLarge Knowledge Models (LKMs), as they will not be limited to only NLP-based\ntechniques or NLP-like applications. In this paper, we discuss the challenges\nand opportunities in developing such systems in chemical engineering.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "I.2.0; I.2.7"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19561v1",
    "published_date": "2024-05-29 23:06:54 UTC",
    "updated_date": "2024-05-29 23:06:54 UTC"
  },
  {
    "arxiv_id": "2406.00061v1",
    "title": "STAT: Shrinking Transformers After Training",
    "authors": [
      "Megan Flynn",
      "Alexander Wang",
      "Dean Edward Alvarez",
      "Christopher De Sa",
      "Anil Damle"
    ],
    "abstract": "We present STAT: a simple algorithm to prune transformer models without any\nfine-tuning. STAT eliminates both attention heads and neurons from the network,\nwhile preserving accuracy by calculating a correction to the weights of the\nnext layer. Each layer block in the network is compressed using a series of\nprincipled matrix factorizations that preserve the network structure. Our\nentire algorithm takes minutes to compress BERT, and less than three hours to\ncompress models with 7B parameters using a single GPU. Using only several\nhundred data examples, STAT preserves the output of the network and improves\nupon existing gradient-free pruning methods. It is even competitive with\nmethods that include significant fine-tuning. We demonstrate our method on both\nencoder and decoder architectures, including BERT, DistilBERT, and Llama-2\nusing benchmarks such as GLUE, Squad, WikiText2.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.00061v1",
    "published_date": "2024-05-29 22:59:11 UTC",
    "updated_date": "2024-05-29 22:59:11 UTC"
  },
  {
    "arxiv_id": "2405.19544v3",
    "title": "One-Shot Safety Alignment for Large Language Models via Optimal Dualization",
    "authors": [
      "Xinmeng Huang",
      "Shuo Li",
      "Edgar Dobriban",
      "Osbert Bastani",
      "Hamed Hassani",
      "Dongsheng Ding"
    ],
    "abstract": "The growing safety concerns surrounding large language models raise an urgent\nneed to align them with diverse human preferences to simultaneously enhance\ntheir helpfulness and safety. A promising approach is to enforce safety\nconstraints through Reinforcement Learning from Human Feedback (RLHF). For such\nconstrained RLHF, typical Lagrangian-based primal-dual policy optimization\nmethods are computationally expensive and often unstable. This paper presents a\nperspective of dualization that reduces constrained alignment to an equivalent\nunconstrained alignment problem. We do so by pre-optimizing a smooth and convex\ndual function that has a closed form. This shortcut eliminates the need for\ncumbersome primal-dual policy iterations, greatly reducing the computational\nburden and improving training stability. Our strategy leads to two practical\nalgorithms in model-based and preference-based settings (MoCAN and PeCAN,\nrespectively). A broad range of experiments demonstrate the effectiveness and\nmerits of our algorithms.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, 6 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.19544v3",
    "published_date": "2024-05-29 22:12:52 UTC",
    "updated_date": "2024-11-22 05:55:58 UTC"
  },
  {
    "arxiv_id": "2405.19538v2",
    "title": "CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats",
    "authors": [
      "Pierre Chambon",
      "Jean-Benoit Delbrouck",
      "Thomas Sounack",
      "Shih-Cheng Huang",
      "Zhihong Chen",
      "Maya Varma",
      "Steven QH Truong",
      "Chu The Chuong",
      "Curtis P. Langlotz"
    ],
    "abstract": "Since the release of the original CheXpert paper five years ago, CheXpert has\nbecome one of the most widely used and cited clinical AI datasets. The\nemergence of vision language models has sparked an increase in demands for\nsharing reports linked to CheXpert images, along with a growing interest among\nAI fairness researchers in obtaining demographic data. To address this,\nCheXpert Plus serves as a new collection of radiology data sources, made\npublicly available to enhance the scaling, performance, robustness, and\nfairness of models for all subsequent machine learning tasks in the field of\nradiology. CheXpert Plus is the largest text dataset publicly released in\nradiology, with a total of 36 million text tokens, including 13 million\nimpression tokens. To the best of our knowledge, it represents the largest text\nde-identification effort in radiology, with almost 1 million PHI spans\nanonymized. It is only the second time that a large-scale English paired\ndataset has been released in radiology, thereby enabling, for the first time,\ncross-institution training at scale. All reports are paired with high-quality\nimages in DICOM format, along with numerous image and patient metadata covering\nvarious clinical and socio-economic groups, as well as many pathology labels\nand RadGraph annotations. We hope this dataset will boost research for AI\nmodels that can further assist radiologists and help improve medical care. Data\nis available at the following URL:\nhttps://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1\nModels are available at the following URL:\nhttps://github.com/Stanford-AIMI/chexpert-plus",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "13 pages Updated title",
    "pdf_url": "http://arxiv.org/pdf/2405.19538v2",
    "published_date": "2024-05-29 21:48:56 UTC",
    "updated_date": "2024-06-03 19:14:12 UTC"
  },
  {
    "arxiv_id": "2405.19534v4",
    "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
    "authors": [
      "Angelica Chen",
      "Sadhika Malladi",
      "Lily H. Zhang",
      "Xinyi Chen",
      "Qiuyi Zhang",
      "Rajesh Ranganath",
      "Kyunghyun Cho"
    ],
    "abstract": "Preference learning algorithms (e.g., RLHF and DPO) are frequently used to\nsteer LLMs to produce generations that are more preferred by humans, but our\nunderstanding of their inner workings is still limited. In this work, we study\nthe conventional wisdom that preference learning trains models to assign higher\nlikelihoods to more preferred outputs than less preferred outputs, measured via\nranking accuracy. Surprisingly, we find that most state-of-the-art\npreference-tuned models achieve a ranking accuracy of less than 60% on common\npreference datasets. We furthermore derive the idealized ranking accuracy that\na preference-tuned LLM would achieve if it optimized the DPO or RLHF objective\nperfectly. We demonstrate that existing models exhibit a significant alignment\ngap -- i.e., a gap between the observed and idealized ranking accuracies. We\nattribute this discrepancy to the DPO objective, which is empirically and\ntheoretically ill-suited to fix even mild ranking errors in the reference\nmodel, and derive a simple and efficient formula for quantifying the difficulty\nof learning a given preference datapoint. Finally, we demonstrate that ranking\naccuracy strongly correlates with the empirically popular win rate metric when\nthe model is close to the reference model used in the objective, shedding\nfurther light on the differences between on-policy (e.g., RLHF) and off-policy\n(e.g., DPO) preference learning algorithms.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "NeurIPS 2024 camera-ready",
    "pdf_url": "http://arxiv.org/pdf/2405.19534v4",
    "published_date": "2024-05-29 21:29:44 UTC",
    "updated_date": "2024-10-31 14:32:28 UTC"
  },
  {
    "arxiv_id": "2405.19524v1",
    "title": "AI Risk Management Should Incorporate Both Safety and Security",
    "authors": [
      "Xiangyu Qi",
      "Yangsibo Huang",
      "Yi Zeng",
      "Edoardo Debenedetti",
      "Jonas Geiping",
      "Luxi He",
      "Kaixuan Huang",
      "Udari Madhushani",
      "Vikash Sehwag",
      "Weijia Shi",
      "Boyi Wei",
      "Tinghao Xie",
      "Danqi Chen",
      "Pin-Yu Chen",
      "Jeffrey Ding",
      "Ruoxi Jia",
      "Jiaqi Ma",
      "Arvind Narayanan",
      "Weijie J Su",
      "Mengdi Wang",
      "Chaowei Xiao",
      "Bo Li",
      "Dawn Song",
      "Peter Henderson",
      "Prateek Mittal"
    ],
    "abstract": "The exposure of security vulnerabilities in safety-aligned language models,\ne.g., susceptibility to adversarial attacks, has shed light on the intricate\ninterplay between AI safety and AI security. Although the two disciplines now\ncome together under the overarching goal of AI risk management, they have\nhistorically evolved separately, giving rise to differing perspectives.\nTherefore, in this paper, we advocate that stakeholders in AI risk management\nshould be aware of the nuances, synergies, and interplay between safety and\nsecurity, and unambiguously take into account the perspectives of both\ndisciplines in order to devise mostly effective and holistic risk mitigation\napproaches. Unfortunately, this vision is often obfuscated, as the definitions\nof the basic concepts of \"safety\" and \"security\" themselves are often\ninconsistent and lack consensus across communities. With AI risk management\nbeing increasingly cross-disciplinary, this issue is particularly salient. In\nlight of this conceptual challenge, we introduce a unified reference framework\nto clarify the differences and interplay between AI safety and AI security,\naiming to facilitate a shared understanding and effective collaboration across\ncommunities.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19524v1",
    "published_date": "2024-05-29 21:00:47 UTC",
    "updated_date": "2024-05-29 21:00:47 UTC"
  },
  {
    "arxiv_id": "2405.19522v1",
    "title": "Artificial Intelligence Index Report 2024",
    "authors": [
      "Nestor Maslej",
      "Loredana Fattorini",
      "Raymond Perrault",
      "Vanessa Parli",
      "Anka Reuel",
      "Erik Brynjolfsson",
      "John Etchemendy",
      "Katrina Ligett",
      "Terah Lyons",
      "James Manyika",
      "Juan Carlos Niebles",
      "Yoav Shoham",
      "Russell Wald",
      "Jack Clark"
    ],
    "abstract": "The 2024 Index is our most comprehensive to date and arrives at an important\nmoment when AI's influence on society has never been more pronounced. This\nyear, we have broadened our scope to more extensively cover essential trends\nsuch as technical advancements in AI, public perceptions of the technology, and\nthe geopolitical dynamics surrounding its development. Featuring more original\ndata than ever before, this edition introduces new estimates on AI training\ncosts, detailed analyses of the responsible AI landscape, and an entirely new\nchapter dedicated to AI's impact on science and medicine. The AI Index report\ntracks, collates, distills, and visualizes data related to artificial\nintelligence (AI). Our mission is to provide unbiased, rigorously vetted,\nbroadly sourced data in order for policymakers, researchers, executives,\njournalists, and the general public to develop a more thorough and nuanced\nunderstanding of the complex field of AI. The AI Index is recognized globally\nas one of the most credible and authoritative sources for data and insights on\nartificial intelligence. Previous editions have been cited in major newspapers,\nincluding the The New York Times, Bloomberg, and The Guardian, have amassed\nhundreds of academic citations, and been referenced by high-level policymakers\nin the United States, the United Kingdom, and the European Union, among other\nplaces. This year's edition surpasses all previous ones in size, scale, and\nscope, reflecting the growing significance that AI is coming to hold in all of\nour lives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19522v1",
    "published_date": "2024-05-29 20:59:57 UTC",
    "updated_date": "2024-05-29 20:59:57 UTC"
  },
  {
    "arxiv_id": "2405.19519v2",
    "title": "Two-Layer Retrieval-Augmented Generation Framework for Low-Resource Medical Question Answering Using Reddit Data: Proof-of-Concept Study",
    "authors": [
      "Sudeshna Das",
      "Yao Ge",
      "Yuting Guo",
      "Swati Rajwal",
      "JaMor Hairston",
      "Jeanne Powell",
      "Drew Walker",
      "Snigdha Peddireddy",
      "Sahithi Lakamana",
      "Selen Bozkurt",
      "Matthew Reyna",
      "Reza Sameni",
      "Yunyu Xiao",
      "Sangmi Kim",
      "Rasheeta Chandler",
      "Natalie Hernandez",
      "Danielle Mowery",
      "Rachel Wightman",
      "Jennifer Love",
      "Anthony Spadaro",
      "Jeanmarie Perrone",
      "Abeed Sarker"
    ],
    "abstract": "The increasing use of social media to share lived and living experiences of\nsubstance use presents a unique opportunity to obtain information on side\neffects, use patterns, and opinions on novel psychoactive substances. However,\ndue to the large volume of data, obtaining useful insights through natural\nlanguage processing technologies such as large language models is challenging.\nThis paper aims to develop a retrieval-augmented generation (RAG) architecture\nfor medical question answering pertaining to clinicians' queries on emerging\nissues associated with health-related topics, using user-generated medical\ninformation on social media. We proposed a two-layer RAG framework for\nquery-focused answer generation and evaluated a proof of concept for the\nframework in the context of query-focused summary generation from social media\nforums, focusing on emerging drug-related information. Our modular framework\ngenerates individual summaries followed by an aggregated summary to answer\nmedical queries from large amounts of user-generated social media data in an\nefficient manner. We compared the performance of a quantized large language\nmodel (Nous-Hermes-2-7B-DPO), deployable in low-resource settings, with GPT-4.\nFor this proof-of-concept study, we used user-generated data from Reddit to\nanswer clinicians' questions on the use of xylazine and ketamine. Our framework\nachieves comparable median scores in terms of relevance, length, hallucination,\ncoverage, and coherence when evaluated using GPT-4 and Nous-Hermes-2-7B-DPO,\nevaluated for 20 queries with 76 samples. There was no statistically\nsignificant difference between the two for coverage, coherence, relevance,\nlength, and hallucination. A statistically significant difference was noted for\nthe Coleman-Liau Index. Our RAG framework can effectively answer medical\nquestions about targeted topics and can be deployed in resource-constrained\nsettings.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Published in JMIR: https://www.jmir.org/2025/1/e66220",
    "pdf_url": "http://arxiv.org/pdf/2405.19519v2",
    "published_date": "2024-05-29 20:56:52 UTC",
    "updated_date": "2025-01-07 16:13:50 UTC"
  },
  {
    "arxiv_id": "2405.19501v1",
    "title": "MDS-ViTNet: Improving saliency prediction for Eye-Tracking with Vision Transformer",
    "authors": [
      "Polezhaev Ignat",
      "Goncharenko Igor",
      "Iurina Natalya"
    ],
    "abstract": "In this paper, we present a novel methodology we call MDS-ViTNet (Multi\nDecoder Saliency by Vision Transformer Network) for enhancing visual saliency\nprediction or eye-tracking. This approach holds significant potential for\ndiverse fields, including marketing, medicine, robotics, and retail. We propose\na network architecture that leverages the Vision Transformer, moving beyond the\nconventional ImageNet backbone. The framework adopts an encoder-decoder\nstructure, with the encoder utilizing a Swin transformer to efficiently embed\nmost important features. This process involves a Transfer Learning method,\nwherein layers from the Vision Transformer are converted by the Encoder\nTransformer and seamlessly integrated into a CNN Decoder. This methodology\nensures minimal information loss from the original input image. The decoder\nemploys a multi-decoding technique, utilizing dual decoders to generate two\ndistinct attention maps. These maps are subsequently combined into a singular\noutput via an additional CNN model. Our trained model MDS-ViTNet achieves\nstate-of-the-art results across several benchmarks. Committed to fostering\nfurther collaboration, we intend to make our code, models, and datasets\naccessible to the public.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19501v1",
    "published_date": "2024-05-29 20:28:04 UTC",
    "updated_date": "2024-05-29 20:28:04 UTC"
  },
  {
    "arxiv_id": "2405.19498v1",
    "title": "Machine Psychology: Integrating Operant Conditioning with the Non-Axiomatic Reasoning System for Advancing Artificial General Intelligence Research",
    "authors": [
      "Robert Johansson"
    ],
    "abstract": "This paper introduces an interdisciplinary framework called Machine\nPsychology, which merges principles from operant learning psychology with a\nspecific Artificial Intelligence model, the Non-Axiomatic Reasoning System\n(NARS), to enhance Artificial General Intelligence (AGI) research. The core\npremise of this framework is that adaptation is crucial to both biological and\nartificial intelligence and can be understood through operant conditioning\nprinciples. The study assesses this approach via three operant learning tasks\nusing OpenNARS for Applications (ONA): simple discrimination, changing\ncontingencies, and conditional discrimination tasks.\n  In the simple discrimination task, NARS demonstrated rapid learning,\nachieving perfect accuracy during both training and testing phases. The\nchanging contingencies task showcased NARS's adaptability, as it successfully\nadjusted its behavior when task conditions were reversed. In the conditional\ndiscrimination task, NARS handled complex learning scenarios effectively,\nachieving high accuracy by forming and utilizing intricate hypotheses based on\nconditional cues.\n  These findings support the application of operant conditioning as a framework\nfor creating adaptive AGI systems. NARS's ability to operate under conditions\nof insufficient knowledge and resources, coupled with its sensorimotor\nreasoning capabilities, establishes it as a robust model for AGI. The Machine\nPsychology framework, by incorporating elements of natural intelligence such as\ncontinuous learning and goal-driven behavior, offers a scalable and flexible\napproach for real-world applications. Future research should investigate using\nenhanced NARS systems, more advanced tasks, and applying this framework to\ndiverse, complex challenges to further progress the development of human-level\nAI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19498v1",
    "published_date": "2024-05-29 20:23:57 UTC",
    "updated_date": "2024-05-29 20:23:57 UTC"
  },
  {
    "arxiv_id": "2405.19495v1",
    "title": "Qiskit Code Assistant: Training LLMs for generating Quantum Computing Code",
    "authors": [
      "Nicolas Dupuis",
      "Luca Buratti",
      "Sanjay Vishwakarma",
      "Aitana Viudes Forrat",
      "David Kremer",
      "Ismael Faro",
      "Ruchir Puri",
      "Juan Cruz-Benito"
    ],
    "abstract": "Code Large Language Models (Code LLMs) have emerged as powerful tools,\nrevolutionizing the software development landscape by automating the coding\nprocess and reducing time and effort required to build applications. This paper\nfocuses on training Code LLMs to specialize in the field of quantum computing.\nWe begin by discussing the unique needs of quantum computing programming, which\ndiffer significantly from classical programming approaches or languages. A Code\nLLM specializing in quantum computing requires a foundational understanding of\nquantum computing and quantum information theory. However, the scarcity of\navailable quantum code examples and the rapidly evolving field, which\nnecessitates continuous dataset updates, present significant challenges.\nMoreover, we discuss our work on training Code LLMs to produce high-quality\nquantum code using the Qiskit library. This work includes an examination of the\nvarious aspects of the LLMs used for training and the specific training\nconditions, as well as the results obtained with our current models. To\nevaluate our models, we have developed a custom benchmark, similar to\nHumanEval, which includes a set of tests specifically designed for the field of\nquantum computing programming using Qiskit. Our findings indicate that our\nmodel outperforms existing state-of-the-art models in quantum computing tasks.\nWe also provide examples of code suggestions, comparing our model to other\nrelevant code LLMs. Finally, we introduce a discussion on the potential\nbenefits of Code LLMs for quantum computing computational scientists,\nresearchers, and practitioners. We also explore various features and future\nwork that could be relevant in this context.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19495v1",
    "published_date": "2024-05-29 20:21:00 UTC",
    "updated_date": "2024-05-29 20:21:00 UTC"
  },
  {
    "arxiv_id": "2405.19479v1",
    "title": "Participation in the age of foundation models",
    "authors": [
      "Harini Suresh",
      "Emily Tseng",
      "Meg Young",
      "Mary L. Gray",
      "Emma Pierson",
      "Karen Levy"
    ],
    "abstract": "Growing interest and investment in the capabilities of foundation models has\npositioned such systems to impact a wide array of public services. Alongside\nthese opportunities is the risk that these systems reify existing power\nimbalances and cause disproportionate harm to marginalized communities.\nParticipatory approaches hold promise to instead lend agency and\ndecision-making power to marginalized stakeholders. But existing approaches in\nparticipatory AI/ML are typically deeply grounded in context - how do we apply\nthese approaches to foundation models, which are, by design, disconnected from\ncontext? Our paper interrogates this question.\n  First, we examine existing attempts at incorporating participation into\nfoundation models. We highlight the tension between participation and scale,\ndemonstrating that it is intractable for impacted communities to meaningfully\nshape a foundation model that is intended to be universally applicable. In\nresponse, we develop a blueprint for participatory foundation models that\nidentifies more local, application-oriented opportunities for meaningful\nparticipation. In addition to the \"foundation\" layer, our framework proposes\nthe \"subfloor'' layer, in which stakeholders develop shared technical\ninfrastructure, norms and governance for a grounded domain, and the \"surface''\nlayer, in which affected communities shape the use of a foundation model for a\nspecific downstream task. The intermediate \"subfloor'' layer scopes the range\nof potential harms to consider, and affords communities more concrete avenues\nfor deliberation and intervention. At the same time, it avoids duplicative\neffort by scaling input across relevant use cases. Through three case studies\nin clinical care, financial services, and journalism, we illustrate how this\nmulti-layer model can create more meaningful opportunities for participation\nthan solely intervening at the foundation layer.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "13 pages, 2 figures. Appeared at FAccT '24",
    "pdf_url": "http://arxiv.org/pdf/2405.19479v1",
    "published_date": "2024-05-29 19:53:23 UTC",
    "updated_date": "2024-05-29 19:53:23 UTC"
  },
  {
    "arxiv_id": "2405.19471v1",
    "title": "The Data Minimization Principle in Machine Learning",
    "authors": [
      "Prakhar Ganesh",
      "Cuong Tran",
      "Reza Shokri",
      "Ferdinando Fioretto"
    ],
    "abstract": "The principle of data minimization aims to reduce the amount of data\ncollected, processed or retained to minimize the potential for misuse,\nunauthorized access, or data breaches. Rooted in privacy-by-design principles,\ndata minimization has been endorsed by various global data protection\nregulations. However, its practical implementation remains a challenge due to\nthe lack of a rigorous formulation. This paper addresses this gap and\nintroduces an optimization framework for data minimization based on its legal\ndefinitions. It then adapts several optimization algorithms to perform data\nminimization and conducts a comprehensive evaluation in terms of their\ncompliance with minimization objectives as well as their impact on user\nprivacy. Our analysis underscores the mismatch between the privacy expectations\nof data minimization and the actual privacy benefits, emphasizing the need for\napproaches that account for multiple facets of real-world privacy risks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19471v1",
    "published_date": "2024-05-29 19:40:27 UTC",
    "updated_date": "2024-05-29 19:40:27 UTC"
  },
  {
    "arxiv_id": "2405.19464v2",
    "title": "Leveraging Generative AI for Urban Digital Twins: A Scoping Review on the Autonomous Generation of Urban Data, Scenarios, Designs, and 3D City Models for Smart City Advancement",
    "authors": [
      "Haowen Xu",
      "Femi Omitaomu",
      "Soheil Sabri",
      "Sisi Zlatanova",
      "Xiao Li",
      "Yongze Song"
    ],
    "abstract": "The digital transformation of modern cities by integrating advanced\ninformation, communication, and computing technologies has marked the epoch of\ndata-driven smart city applications for efficient and sustainable urban\nmanagement. Despite their effectiveness, these applications often rely on\nmassive amounts of high-dimensional and multi-domain data for monitoring and\ncharacterizing different urban sub-systems, presenting challenges in\napplication areas that are limited by data quality and availability, as well as\ncostly efforts for generating urban scenarios and design alternatives. As an\nemerging research area in deep learning, Generative Artificial Intelligence\n(AI) models have demonstrated their unique values in data and code generation.\nThis survey paper aims to explore the innovative integration of generative AI\ntechniques and urban digital twins to address challenges in the realm of smart\ncities in various urban sectors, such as transportation and mobility\nmanagement, energy system operations, building and infrastructure management,\nand urban design. The survey starts with the introduction of popular generative\nAI models with their application areas, followed by a structured review of the\nexisting urban science applications that leverage the autonomous capability of\nthe generative AI techniques to facilitate (a) data augmentation for promoting\nurban monitoring and predictive analytics, (b) synthetic data and scenario\ngeneration, (c) automated 3D city modeling, and (d) generative urban design and\noptimization. Based on the review, this survey discusses potential\nopportunities and technical strategies that integrate generative AI models into\nthe next-generation urban digital twins for more reliable, scalable, and\nautomated management of smart cities.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19464v2",
    "published_date": "2024-05-29 19:23:07 UTC",
    "updated_date": "2024-08-06 18:32:39 UTC"
  },
  {
    "arxiv_id": "2405.19458v4",
    "title": "MemControl: Mitigating Memorization in Diffusion Models via Automated Parameter Selection",
    "authors": [
      "Raman Dutt",
      "Ondrej Bohdal",
      "Pedro Sanchez",
      "Sotirios A. Tsaftaris",
      "Timothy Hospedales"
    ],
    "abstract": "Diffusion models excel in generating images that closely resemble their\ntraining data but are also susceptible to data memorization, raising privacy,\nethical, and legal concerns, particularly in sensitive domains such as medical\nimaging. We hypothesize that this memorization stems from the\noverparameterization of deep models and propose that regularizing model\ncapacity during fine-tuning can mitigate this issue. Firstly, we empirically\nshow that regulating the model capacity via Parameter-efficient fine-tuning\n(PEFT) mitigates memorization to some extent, however, it further requires the\nidentification of the exact parameter subsets to be fine-tuned for high-quality\ngeneration. To identify these subsets, we introduce a bi-level optimization\nframework, MemControl, that automates parameter selection using memorization\nand generation quality metrics as rewards during fine-tuning. The parameter\nsubsets discovered through MemControl achieve a superior tradeoff between\ngeneration quality and memorization. For the task of medical image generation,\nour approach outperforms existing state-of-the-art memorization mitigation\nstrategies by fine-tuning as few as 0.019% of model parameters. Moreover, we\ndemonstrate that the discovered parameter subsets are transferable to\nnon-medical domains. Our framework is scalable to large datasets, agnostic to\nreward functions, and can be integrated with existing approaches for further\nmemorization mitigation. To the best of our knowledge, this is the first study\nto empirically evaluate memorization in medical images and propose a targeted\nyet universal mitigation strategy. The code is available at\nhttps://github.com/Raman1121/Diffusion_Memorization_HPO.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted into WACV 2025 (Applications Track)",
    "pdf_url": "http://arxiv.org/pdf/2405.19458v4",
    "published_date": "2024-05-29 19:12:08 UTC",
    "updated_date": "2025-02-11 12:41:08 UTC"
  },
  {
    "arxiv_id": "2405.19456v2",
    "title": "SSFF: Investigating LLM Predictive Capabilities for Startup Success through a Multi-Agent Framework with Enhanced Explainability and Performance",
    "authors": [
      "Xisen Wang",
      "Yigit Ihlamur",
      "Fuat Alican"
    ],
    "abstract": "LLM based agents have recently demonstrated strong potential in automating\ncomplex tasks, yet accurately predicting startup success remains an open\nchallenge with few benchmarks and tailored frameworks. To address these\nlimitations, we propose the Startup Success Forecasting Framework, an\nautonomous system that emulates the reasoning of venture capital analysts\nthrough a multi agent collaboration model. Our framework integrates traditional\nmachine learning methods such as random forests and neural networks within a\nretrieval augmented generation framework composed of three interconnected\nmodules: a prediction block, an analysis block, and an external knowledge\nblock. We evaluate our framework and identify three main findings. First, by\nleveraging founder segmentation, startups led by L5 founders are 3.79 times\nmore likely to succeed than those led by L1 founders. Second, baseline large\nlanguage models consistently overpredict startup success and struggle under\nrealistic class imbalances largely due to overreliance on founder claims.\nThird, our framework significantly enhances prediction accuracy, yielding a\n108.3 percent relative improvement over GPT 4o mini and a 30.8 percent relative\nimprovement over GPT 4o. These results demonstrate the value of a multi agent\napproach combined with discriminative machine learning in mitigating the\nlimitations of standard large language model based prediction methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "For relevant code:\n  https://github.com/Xisen-Wang/Startup-Success-Forecasting-Framework",
    "pdf_url": "http://arxiv.org/pdf/2405.19456v2",
    "published_date": "2024-05-29 19:07:42 UTC",
    "updated_date": "2025-04-19 17:18:29 UTC"
  },
  {
    "arxiv_id": "2405.19453v1",
    "title": "Optimizing Split Points for Error-Resilient SplitFed Learning",
    "authors": [
      "Chamani Shiranthika",
      "Parvaneh Saeedi",
      "Ivan V. Bajić"
    ],
    "abstract": "Recent advancements in decentralized learning, such as Federated Learning\n(FL), Split Learning (SL), and Split Federated Learning (SplitFed), have\nexpanded the potentials of machine learning. SplitFed aims to minimize the\ncomputational burden on individual clients in FL and parallelize SL while\nmaintaining privacy. This study investigates the resilience of SplitFed to\npacket loss at model split points. It explores various parameter aggregation\nstrategies of SplitFed by examining the impact of splitting the model at\ndifferent points-either shallow split or deep split-on the final global model\nperformance. The experiments, conducted on a human embryo image segmentation\ntask, reveal a statistically significant advantage of a deeper split point.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for poster presentation at the Women in Computer Vision\n  (WiCV) workshop in CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19453v1",
    "published_date": "2024-05-29 19:03:27 UTC",
    "updated_date": "2024-05-29 19:03:27 UTC"
  },
  {
    "arxiv_id": "2405.19444v1",
    "title": "MathChat: Benchmarking Mathematical Reasoning and Instruction Following in Multi-Turn Interactions",
    "authors": [
      "Zhenwen Liang",
      "Dian Yu",
      "Wenhao Yu",
      "Wenlin Yao",
      "Zhihan Zhang",
      "Xiangliang Zhang",
      "Dong Yu"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nmathematical problem solving, particularly in single turn question answering\nformats. However, real world scenarios often involve mathematical question\nanswering that requires multi turn or interactive information exchanges, and\nthe performance of LLMs on these tasks is still underexplored. This paper\nintroduces MathChat, a comprehensive benchmark specifically designed to\nevaluate LLMs across a broader spectrum of mathematical tasks. These tasks are\nstructured to assess the models' abilities in multiturn interactions and open\nended generation. We evaluate the performance of various SOTA LLMs on the\nMathChat benchmark, and we observe that while these models excel in single turn\nquestion answering, they significantly underperform in more complex scenarios\nthat require sustained reasoning and dialogue understanding. To address the\nabove limitations of existing LLMs when faced with multiturn and open ended\ntasks, we develop MathChat sync, a synthetic dialogue based math dataset for\nLLM finetuning, focusing on improving models' interaction and instruction\nfollowing capabilities in conversations. Experimental results emphasize the\nneed for training LLMs with diverse, conversational instruction tuning datasets\nlike MathChatsync. We believe this work outlines one promising direction for\nimproving the multiturn mathematical reasoning abilities of LLMs, thus pushing\nforward the development of LLMs that are more adept at interactive mathematical\nproblem solving and real world applications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19444v1",
    "published_date": "2024-05-29 18:45:55 UTC",
    "updated_date": "2024-05-29 18:45:55 UTC"
  },
  {
    "arxiv_id": "2405.19423v1",
    "title": "Evaluating Vision-Language Models on Bistable Images",
    "authors": [
      "Artemis Panagopoulou",
      "Coby Melkin",
      "Chris Callison-Burch"
    ],
    "abstract": "Bistable images, also known as ambiguous or reversible images, present visual\nstimuli that can be seen in two distinct interpretations, though not\nsimultaneously by the observer. In this study, we conduct the most extensive\nexamination of vision-language models using bistable images to date. We\nmanually gathered a dataset of 29 bistable images, along with their associated\nlabels, and subjected them to 116 different manipulations in brightness, tint,\nand rotation. We evaluated twelve different models in both classification and\ngenerative tasks across six model architectures. Our findings reveal that, with\nthe exception of models from the Idefics family and LLaVA1.5-13b, there is a\npronounced preference for one interpretation over another among the models, and\nminimal variance under image manipulations, with few exceptions on image\nrotations. Additionally, we compared the model preferences with humans, noting\nthat the models do not exhibit the same continuity biases as humans and often\ndiverge from human initial interpretations. We also investigated the influence\nof variations in prompts and the use of synonymous labels, discovering that\nthese factors significantly affect model interpretations more than image\nmanipulations showing a higher influence of the language priors on bistable\nimage interpretations compared to image-text training data. All code and data\nis open sourced.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19423v1",
    "published_date": "2024-05-29 18:04:59 UTC",
    "updated_date": "2024-05-29 18:04:59 UTC"
  },
  {
    "arxiv_id": "2405.19420v3",
    "title": "Learning Human-Aligned Representations with Contrastive Learning and Generative Similarity",
    "authors": [
      "Raja Marjieh",
      "Sreejan Kumar",
      "Declan Campbell",
      "Liyi Zhang",
      "Gianluca Bencomo",
      "Jake Snell",
      "Thomas L. Griffiths"
    ],
    "abstract": "Humans rely on effective representations to learn from few examples and\nabstract useful information from sensory data. Inducing such representations in\nmachine learning models has been shown to improve their performance on various\nbenchmarks such as few-shot learning and robustness. However, finding effective\ntraining procedures to achieve that goal can be challenging as psychologically\nrich training data such as human similarity judgments are expensive to scale,\nand Bayesian models of human inductive biases are often intractable for\ncomplex, realistic domains. Here, we address this challenge by leveraging a\nBayesian notion of generative similarity whereby two data points are considered\nsimilar if they are likely to have been sampled from the same distribution.\nThis measure can be applied to complex generative processes, including\nprobabilistic programs. We incorporate generative similarity into a contrastive\nlearning objective to enable learning of embeddings that express human\ncognitive representations. We demonstrate the utility of our approach by\nshowing that it can be used to capture human-like representations of shape\nregularity, abstract Euclidean geometric concepts, and semantic hierarchies for\nnatural images.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19420v3",
    "published_date": "2024-05-29 18:01:58 UTC",
    "updated_date": "2025-01-31 16:19:24 UTC"
  },
  {
    "arxiv_id": "2405.19413v1",
    "title": "VisTA-SR: Improving the Accuracy and Resolution of Low-Cost Thermal Imaging Cameras for Agriculture",
    "authors": [
      "Heesup Yun",
      "Sassoum Lo",
      "Christine H. Diepenbrock",
      "Brian N. Bailey",
      "J. Mason Earles"
    ],
    "abstract": "Thermal cameras are an important tool for agricultural research because they\nallow for non-invasive measurement of plant temperature, which relates to\nimportant photochemical, hydraulic, and agronomic traits. Utilizing low-cost\nthermal cameras can lower the barrier to introducing thermal imaging in\nagricultural research and production. This paper presents an approach to\nimprove the temperature accuracy and image quality of low-cost thermal imaging\ncameras for agricultural applications. Leveraging advancements in computer\nvision techniques, particularly deep learning networks, we propose a method,\ncalled $\\textbf{VisTA-SR}$ ($\\textbf{Vis}$ual \\& $\\textbf{T}$hermal\n$\\textbf{A}$lignment and $\\textbf{S}$uper-$\\textbf{R}$esolution Enhancement)\nthat combines RGB and thermal images to enhance the capabilities of\nlow-resolution thermal cameras. The research includes calibration and\nvalidation of temperature measurements, acquisition of paired image datasets,\nand the development of a deep learning network tailored for agricultural\nthermal imaging. Our study addresses the challenges of image enhancement in the\nagricultural domain and explores the potential of low-cost thermal cameras to\nreplace high-resolution industrial cameras. Experimental results demonstrate\nthe effectiveness of our approach in enhancing temperature accuracy and image\nsharpness, paving the way for more accessible and efficient thermal imaging\nsolutions in agriculture.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19413v1",
    "published_date": "2024-05-29 18:00:20 UTC",
    "updated_date": "2024-05-29 18:00:20 UTC"
  },
  {
    "arxiv_id": "2405.19334v2",
    "title": "LLMs Meet Multimodal Generation and Editing: A Survey",
    "authors": [
      "Yingqing He",
      "Zhaoyang Liu",
      "Jingye Chen",
      "Zeyue Tian",
      "Hongyu Liu",
      "Xiaowei Chi",
      "Runtao Liu",
      "Ruibin Yuan",
      "Yazhou Xing",
      "Wenhai Wang",
      "Jifeng Dai",
      "Yong Zhang",
      "Wei Xue",
      "Qifeng Liu",
      "Yike Guo",
      "Qifeng Chen"
    ],
    "abstract": "With the recent advancement in large language models (LLMs), there is a\ngrowing interest in combining LLMs with multimodal learning. Previous surveys\nof multimodal large language models (MLLMs) mainly focus on multimodal\nunderstanding. This survey elaborates on multimodal generation and editing\nacross various domains, comprising image, video, 3D, and audio. Specifically,\nwe summarize the notable advancements with milestone works in these fields and\ncategorize these studies into LLM-based and CLIP/T5-based methods. Then, we\nsummarize the various roles of LLMs in multimodal generation and exhaustively\ninvestigate the critical technical components behind these methods and the\nmultimodal datasets utilized in these studies. Additionally, we dig into\ntool-augmented multimodal agents that can leverage existing generative models\nfor human-computer interaction. Lastly, we discuss the advancements in the\ngenerative AI safety field, investigate emerging applications, and discuss\nfuture prospects. Our work provides a systematic and insightful overview of\nmultimodal generation and processing, which is expected to advance the\ndevelopment of Artificial Intelligence for Generative Content (AIGC) and world\nmodels. A curated list of all related papers can be found at\nhttps://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM",
      "cs.SD"
    ],
    "primary_category": "cs.AI",
    "comment": "52 Pages with 16 Figures, 12 Tables, and 545 References. GitHub\n  Repository at:\n  https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",
    "pdf_url": "http://arxiv.org/pdf/2405.19334v2",
    "published_date": "2024-05-29 17:59:20 UTC",
    "updated_date": "2024-06-09 11:34:12 UTC"
  },
  {
    "arxiv_id": "2405.19332v3",
    "title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment",
    "authors": [
      "Shenao Zhang",
      "Donghan Yu",
      "Hiteshi Sharma",
      "Han Zhong",
      "Zhihan Liu",
      "Ziyi Yang",
      "Shuohang Wang",
      "Hany Hassan",
      "Zhaoran Wang"
    ],
    "abstract": "Preference optimization, particularly through Reinforcement Learning from\nHuman Feedback (RLHF), has achieved significant success in aligning Large\nLanguage Models (LLMs) to adhere to human intentions. Unlike offline alignment\nwith a fixed dataset, online feedback collection from humans or AI on model\ngenerations typically leads to more capable reward models and better-aligned\nLLMs through an iterative process. However, achieving a globally accurate\nreward model requires systematic exploration to generate diverse responses that\nspan the vast space of natural language. Random sampling from standard\nreward-maximizing LLMs alone is insufficient to fulfill this requirement. To\naddress this issue, we propose a bilevel objective optimistically biased\ntowards potentially high-reward responses to actively explore\nout-of-distribution regions. By solving the inner-level problem with the\nreparameterized reward function, the resulting algorithm, named Self-Exploring\nLanguage Models (SELM), eliminates the need for a separate RM and iteratively\nupdates the LLM with a straightforward objective. Compared to Direct Preference\nOptimization (DPO), the SELM objective reduces indiscriminate favor of unseen\nextrapolations and enhances exploration efficiency. Our experimental results\ndemonstrate that when fine-tuned on Zephyr-7B-SFT and Llama-3-8B-Instruct\nmodels, SELM significantly boosts the performance on instruction-following\nbenchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard\nacademic benchmarks in different settings. Our code and models are available at\nhttps://github.com/shenao-zhang/SELM.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19332v3",
    "published_date": "2024-05-29 17:59:07 UTC",
    "updated_date": "2024-11-05 07:21:18 UTC"
  },
  {
    "arxiv_id": "2405.19331v2",
    "title": "NPGA: Neural Parametric Gaussian Avatars",
    "authors": [
      "Simon Giebenhain",
      "Tobias Kirschstein",
      "Martin Rünz",
      "Lourdes Agapito",
      "Matthias Nießner"
    ],
    "abstract": "The creation of high-fidelity, digital versions of human heads is an\nimportant stepping stone in the process of further integrating virtual\ncomponents into our everyday lives. Constructing such avatars is a challenging\nresearch problem, due to a high demand for photo-realism and real-time\nrendering performance. In this work, we propose Neural Parametric Gaussian\nAvatars (NPGA), a data-driven approach to create high-fidelity, controllable\navatars from multi-view video recordings. We build our method around 3D\nGaussian splatting for its highly efficient rendering and to inherit the\ntopological flexibility of point clouds. In contrast to previous work, we\ncondition our avatars' dynamics on the rich expression space of neural\nparametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we\ndistill the backward deformation field of our underlying NPHM into forward\ndeformations which are compatible with rasterization-based rendering. All\nremaining fine-scale, expression-dependent details are learned from the\nmulti-view videos. For increased representational capacity of our avatars, we\npropose per-Gaussian latent features that condition each primitives dynamic\nbehavior. To regularize this increased dynamic expressivity, we propose\nLaplacian terms on the latent features and predicted dynamics. We evaluate our\nmethod on the public NeRSemble dataset, demonstrating that NPGA significantly\noutperforms the previous state-of-the-art avatars on the self-reenactment task\nby 2.6 PSNR. Furthermore, we demonstrate accurate animation capabilities from\nreal-world monocular videos.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project Page: see https://simongiebenhain.github.io/NPGA/ ; Youtube\n  Video: see https://youtu.be/t0S0OK7WnA4",
    "pdf_url": "http://arxiv.org/pdf/2405.19331v2",
    "published_date": "2024-05-29 17:58:09 UTC",
    "updated_date": "2024-09-13 17:41:21 UTC"
  },
  {
    "arxiv_id": "2405.19327v4",
    "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series",
    "authors": [
      "Ge Zhang",
      "Scott Qu",
      "Jiaheng Liu",
      "Chenchen Zhang",
      "Chenghua Lin",
      "Chou Leuang Yu",
      "Danny Pan",
      "Esther Cheng",
      "Jie Liu",
      "Qunshu Lin",
      "Raven Yuan",
      "Tuney Zheng",
      "Wei Pang",
      "Xinrun Du",
      "Yiming Liang",
      "Yinghao Ma",
      "Yizhi Li",
      "Ziyang Ma",
      "Bill Lin",
      "Emmanouil Benetos",
      "Huan Yang",
      "Junting Zhou",
      "Kaijing Ma",
      "Minghao Liu",
      "Morry Niu",
      "Noah Wang",
      "Quehry Que",
      "Ruibo Liu",
      "Sine Liu",
      "Shawn Guo",
      "Soren Gao",
      "Wangchunshu Zhou",
      "Xinyue Zhang",
      "Yizhi Zhou",
      "Yubo Wang",
      "Yuelin Bai",
      "Yuhan Zhang",
      "Yuxiang Zhang",
      "Zenith Wang",
      "Zhenzhu Yang",
      "Zijian Zhao",
      "Jiajun Zhang",
      "Wanli Ouyang",
      "Wenhao Huang",
      "Wenhu Chen"
    ],
    "abstract": "Large Language Models (LLMs) have made great strides in recent years to\nachieve unprecedented performance across different tasks. However, due to\ncommercial interest, the most competitive models like GPT, Gemini, and Claude\nhave been gated behind proprietary interfaces without disclosing the training\ndetails. Recently, many institutions have open-sourced several strong LLMs like\nLLaMA-3, comparable to existing closed-source LLMs. However, only the model's\nweights are provided with most details (e.g., intermediate checkpoints,\npre-training corpus, and training code, etc.) being undisclosed. To improve the\ntransparency of LLMs, the research community has formed to open-source truly\nopen LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training\ncorpus and training code) are being provided. These models have greatly\nadvanced the scientific study of these large models including their strengths,\nweaknesses, biases and risks. However, we observe that the existing truly open\nLLMs on reasoning, knowledge, and coding tasks are still inferior to existing\nstate-of-the-art LLMs with similar model sizes. To this end, we open-source\nMAP-Neo, a highly capable and transparent bilingual language model with 7B\nparameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the\nfirst fully open-sourced bilingual LLM with comparable performance compared to\nexisting state-of-the-art LLMs. Moreover, we open-source all details to\nreproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning\npipeline, checkpoints, and well-optimized training/evaluation framework are\nprovided. Finally, we hope our MAP-Neo will enhance and strengthen the open\nresearch community and inspire more innovations and creativities to facilitate\nthe further improvements of LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "https://map-neo.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.19327v4",
    "published_date": "2024-05-29 17:57:16 UTC",
    "updated_date": "2024-07-10 16:55:47 UTC"
  },
  {
    "arxiv_id": "2405.19323v2",
    "title": "Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys",
    "authors": [
      "Mingmeng Geng",
      "Sihong He",
      "Roberto Trotta"
    ],
    "abstract": "Can large language models (LLMs) simulate social surveys? To answer this\nquestion, we conducted millions of simulations in which LLMs were asked to\nanswer subjective questions. A comparison of different LLM responses with the\nEuropean Social Survey (ESS) data suggests that the effect of prompts on bias\nand variability is fundamental, highlighting major cultural, age, and gender\nbiases. We further discussed statistical methods for measuring the difference\nbetween LLM answers and survey data and proposed a novel measure inspired by\nJaccard similarity, as LLM-generated responses are likely to have a smaller\nvariance. Our experiments also reveal that it is important to analyze the\nrobustness and variability of prompts before using LLMs to simulate social\nsurveys, as their imitation abilities are approximate at best.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.19323v2",
    "published_date": "2024-05-29 17:54:22 UTC",
    "updated_date": "2024-10-21 17:05:15 UTC"
  },
  {
    "arxiv_id": "2405.19320v4",
    "title": "Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF",
    "authors": [
      "Shicong Cen",
      "Jincheng Mei",
      "Katayoon Goshvadi",
      "Hanjun Dai",
      "Tong Yang",
      "Sherry Yang",
      "Dale Schuurmans",
      "Yuejie Chi",
      "Bo Dai"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has demonstrated great\npromise in aligning large language models (LLMs) with human preference.\nDepending on the availability of preference data, both online and offline RLHF\nare active areas of investigation. A key bottleneck is understanding how to\nincorporate uncertainty estimation in the reward function learned from the\npreference data for RLHF, regardless of how the preference data is collected.\nWhile the principles of optimism or pessimism under uncertainty are\nwell-established in standard reinforcement learning (RL), a\npractically-implementable and theoretically-grounded form amenable to large\nlanguage models is not yet available, as standard techniques for constructing\nconfidence intervals become intractable under arbitrary policy\nparameterizations.\n  In this paper, we introduce a unified approach to online and offline RLHF --\nvalue-incentivized preference optimization (VPO) -- which regularizes the\nmaximum-likelihood estimate of the reward function with the corresponding value\nfunction, modulated by a $\\textit{sign}$ to indicate whether the optimism or\npessimism is chosen. VPO also directly optimizes the policy with implicit\nreward modeling, and therefore shares a simpler RLHF pipeline similar to direct\npreference optimization. Theoretical guarantees of VPO are provided for both\nonline and offline settings, matching the rates of their standard RL\ncounterparts. Moreover, experiments on text summarization and dialog verify the\npracticality and effectiveness of VPO.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.19320v4",
    "published_date": "2024-05-29 17:51:42 UTC",
    "updated_date": "2025-02-19 00:51:58 UTC"
  },
  {
    "arxiv_id": "2406.18563v1",
    "title": "Interdisciplinary Expertise to Advance Equitable Explainable AI",
    "authors": [
      "Chloe R. Bennett",
      "Heather Cole-Lewis",
      "Stephanie Farquhar",
      "Naama Haamel",
      "Boris Babenko",
      "Oran Lang",
      "Mat Fleck",
      "Ilana Traynis",
      "Charles Lau",
      "Ivor Horn",
      "Courtney Lyles"
    ],
    "abstract": "The field of artificial intelligence (AI) is rapidly influencing health and\nhealthcare, but bias and poor performance persists for populations who face\nwidespread structural oppression. Previous work has clearly outlined the need\nfor more rigorous attention to data representativeness and model performance to\nadvance equity and reduce bias. However, there is an opportunity to also\nimprove the explainability of AI by leveraging best practices of social\nepidemiology and health equity to help us develop hypotheses for associations\nfound. In this paper, we focus on explainable AI (XAI) and describe a framework\nfor interdisciplinary expert panel review to discuss and critically assess AI\nmodel explanations from multiple perspectives and identify areas of bias and\ndirections for future research. We emphasize the importance of the\ninterdisciplinary expert panel to produce more accurate, equitable\ninterpretations which are historically and contextually informed.\nInterdisciplinary panel discussions can help reduce bias, identify potential\nconfounders, and identify opportunities for additional research where there are\ngaps in the literature. In turn, these insights can suggest opportunities for\nAI model improvement.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.18563v1",
    "published_date": "2024-05-29 17:45:38 UTC",
    "updated_date": "2024-05-29 17:45:38 UTC"
  },
  {
    "arxiv_id": "2405.19317v4",
    "title": "Generalized Neyman Allocation for Locally Minimax Optimal Best-Arm Identification",
    "authors": [
      "Masahiro Kato"
    ],
    "abstract": "This study investigates an asymptotically locally minimax optimal algorithm\nfor fixed-budget best-arm identification (BAI). We propose the Generalized\nNeyman Allocation (GNA) algorithm and demonstrate that its worst-case upper\nbound on the probability of misidentifying the best arm aligns with the\nworst-case lower bound under the small-gap regime, where the gap between the\nexpected outcomes of the best and suboptimal arms is small. Our lower and upper\nbounds are tight, matching exactly including constant terms within the\nsmall-gap regime. The GNA algorithm generalizes the Neyman allocation for\ntwo-armed bandits (Neyman, 1934; Kaufmann et al., 2016) and refines existing\nBAI algorithms, such as those proposed by Glynn & Juneja (2004). By proposing\nan asymptotically minimax optimal algorithm, we address the longstanding open\nissue in BAI (Kaufmann, 2020) and treatment choice (Kasy & Sautmann, 202) by\nrestricting a class of distributions to the small-gap regimes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "econ.EM",
      "stat.ME",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19317v4",
    "published_date": "2024-05-29 17:43:13 UTC",
    "updated_date": "2025-02-02 18:50:55 UTC"
  },
  {
    "arxiv_id": "2405.19313v2",
    "title": "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice",
    "authors": [
      "Jian-Qiao Zhu",
      "Haijiang Yan",
      "Thomas L. Griffiths"
    ],
    "abstract": "The observed similarities in the behavior of humans and Large Language Models\n(LLMs) have prompted researchers to consider the potential of using LLMs as\nmodels of human cognition. However, several significant challenges must be\naddressed before LLMs can be legitimately regarded as cognitive models. For\ninstance, LLMs are trained on far more data than humans typically encounter,\nand may have been directly trained on human data in specific cognitive tasks or\naligned with human preferences. Consequently, the origins of these behavioral\nsimilarities are not well understood. In this paper, we propose a novel way to\nenhance the utility of LLMs as cognitive models. This approach involves (i)\nleveraging computationally equivalent tasks that both an LLM and a rational\nagent need to master for solving a cognitive problem and (ii) examining the\nspecific task distributions required for an LLM to exhibit human-like\nbehaviors. We apply this approach to decision-making -- specifically risky and\nintertemporal choice -- where the key computationally equivalent task is the\narithmetic of expected value calculations. We show that an LLM pretrained on an\necologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts\nhuman behavior better than many traditional cognitive models. Pretraining LLMs\non ecologically valid arithmetic datasets is sufficient to produce a strong\ncorrespondence between these models and human decision-making. Our results also\nsuggest that LLMs used as cognitive models should be carefully investigated via\nablation studies of the pretraining data.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "econ.GN",
      "q-fin.EC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19313v2",
    "published_date": "2024-05-29 17:37:14 UTC",
    "updated_date": "2025-05-06 01:26:28 UTC"
  },
  {
    "arxiv_id": "2405.19300v3",
    "title": "Measuring and Mitigating Bias for Tabular Datasets with Multiple Protected Attributes",
    "authors": [
      "Manh Khoi Duong",
      "Stefan Conrad"
    ],
    "abstract": "Motivated by the recital (67) of the current corrigendum of the AI Act in the\nEuropean Union, we propose and present measures and mitigation strategies for\ndiscrimination in tabular datasets. We specifically focus on datasets that\ncontain multiple protected attributes, such as nationality, age, and sex. This\nmakes measuring and mitigating bias more challenging, as many existing methods\nare designed for a single protected attribute. This paper comes with a twofold\ncontribution: Firstly, new discrimination measures are introduced. These\nmeasures are categorized in our framework along with existing ones, guiding\nresearchers and practitioners in choosing the right measure to assess the\nfairness of the underlying dataset. Secondly, a novel application of an\nexisting bias mitigation method, FairDo, is presented. We show that this\nstrategy can mitigate any type of discrimination, including intersectional\ndiscrimination, by transforming the dataset. By conducting experiments on\nreal-world datasets (Adult, Bank, COMPAS), we demonstrate that de-biasing\ndatasets with multiple protected attributes is possible. All transformed\ndatasets show a reduction in discrimination, on average by 28%. Further, these\ndatasets do not compromise any of the tested machine learning models'\nperformances significantly compared to the original datasets. Conclusively,\nthis study demonstrates the effectiveness of the mitigation strategy used and\ncontributes to the ongoing discussion on the implementation of the European\nUnion's AI Act.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submission accepted in AEQUITAS'24 (co-located with ECAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.19300v3",
    "published_date": "2024-05-29 17:27:08 UTC",
    "updated_date": "2024-10-01 17:39:02 UTC"
  },
  {
    "arxiv_id": "2405.19296v2",
    "title": "Neural Isometries: Taming Transformations for Equivariant ML",
    "authors": [
      "Thomas W. Mitchel",
      "Michael Taylor",
      "Vincent Sitzmann"
    ],
    "abstract": "Real-world geometry and 3D vision tasks are replete with challenging\nsymmetries that defy tractable analytical expression. In this paper, we\nintroduce Neural Isometries, an autoencoder framework which learns to map the\nobservation space to a general-purpose latent space wherein encodings are\nrelated by isometries whenever their corresponding observations are\ngeometrically related in world space. Specifically, we regularize the latent\nspace such that maps between encodings preserve a learned inner product and\ncommute with a learned functional operator, in the same manner as rigid-body\ntransformations commute with the Laplacian. This approach forms an effective\nbackbone for self-supervised representation learning, and we demonstrate that a\nsimple off-the-shelf equivariant network operating in the pre-trained latent\nspace can achieve results on par with meticulously-engineered, handcrafted\nnetworks designed to handle complex, nonlinear symmetries. Furthermore,\nisometric maps capture information about the respective transformations in\nworld space, and we show that this allows us to regress camera poses directly\nfrom the coefficients of the maps between encodings of adjacent views of a\nscene.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19296v2",
    "published_date": "2024-05-29 17:24:25 UTC",
    "updated_date": "2024-10-29 23:55:17 UTC"
  },
  {
    "arxiv_id": "2405.19284v1",
    "title": "Optimizing Foundation Model Inference on a Many-tiny-core Open-source RISC-V Platform",
    "authors": [
      "Viviane Potocnik",
      "Luca Colagrande",
      "Tim Fischer",
      "Luca Bertaccini",
      "Daniele Jahier Pagliari",
      "Alessio Burrello",
      "Luca Benini"
    ],
    "abstract": "Transformer-based foundation models have become crucial for various domains,\nmost notably natural language processing (NLP) or computer vision (CV). These\nmodels are predominantly deployed on high-performance GPUs or hardwired\naccelerators with highly customized, proprietary instruction sets. Until now,\nlimited attention has been given to RISC-V-based general-purpose platforms. In\nour work, we present the first end-to-end inference results of transformer\nmodels on an open-source many-tiny-core RISC-V platform implementing\ndistributed Softmax primitives and leveraging ISA extensions for SIMD\nfloating-point operand streaming and instruction repetition, as well as\nspecialized DMA engines to minimize costly main memory accesses and to tolerate\ntheir latency. We focus on two foundational transformer topologies,\nencoder-only and decoder-only models. For encoder-only models, we demonstrate a\nspeedup of up to 12.8x between the most optimized implementation and the\nbaseline version. We reach over 79% FPU utilization and 294 GFLOPS/W,\noutperforming State-of-the-Art (SoA) accelerators by more than 2x utilizing the\nHW platform while achieving comparable throughput per computational unit. For\ndecoder-only topologies, we achieve 16.1x speedup in the Non-Autoregressive\n(NAR) mode and up to 35.6x speedup in the Autoregressive (AR) mode compared to\nthe baseline implementation. Compared to the best SoA dedicated accelerator, we\nachieve 2.04x higher FPU utilization.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR",
      "C.4; C.3; I.2"
    ],
    "primary_category": "cs.DC",
    "comment": "14 pages, 10 figures, 4 tables, IEEE Transactions on Circuits and\n  Systems for Artificial Intelligence",
    "pdf_url": "http://arxiv.org/pdf/2405.19284v1",
    "published_date": "2024-05-29 17:16:59 UTC",
    "updated_date": "2024-05-29 17:16:59 UTC"
  },
  {
    "arxiv_id": "2405.19262v3",
    "title": "Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models",
    "authors": [
      "Zhanhui Zhou",
      "Zhixuan Liu",
      "Jie Liu",
      "Zhichen Dong",
      "Chao Yang",
      "Yu Qiao"
    ],
    "abstract": "Large language models are usually fine-tuned to align with human preferences.\nHowever, fine-tuning a large language model can be challenging. In this work,\nwe introduce $\\textit{weak-to-strong search}$, framing the alignment of a large\nlanguage model as a test-time greedy search to maximize the log-probability\ndifference between small tuned and untuned models while sampling from the\nfrozen large model. This method serves both as (1) a compute-efficient model\nup-scaling strategy that avoids directly tuning the large model and as (2) an\ninstance of weak-to-strong generalization that enhances a strong model with\nweak test-time guidance. Empirically, we demonstrate the flexibility of\nweak-to-strong search across different tasks. In controlled-sentiment\ngeneration and summarization, we use tuned and untuned $\\texttt{gpt2}$s to\nimprove the alignment of large models without additional training. Crucially,\nin a more difficult instruction-following benchmark, AlpacaEval 2.0, we show\nthat reusing off-the-shelf small models (e.g., $\\texttt{zephyr-7b-beta}$ and\nits untuned version) can improve the length-controlled win rates of both\nwhite-box and black-box large models against $\\texttt{gpt-4-turbo}$ (e.g.,\n$34.4\\% \\rightarrow 37.9\\%$ for $\\texttt{Llama-3-70B-Instruct}$ and $16.0\\%\n\\rightarrow 20.1\\%$ for $\\texttt{gpt-3.5-turbo-instruct}$), despite the small\nmodels' low win rates $\\approx 10.0\\%$.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19262v3",
    "published_date": "2024-05-29 16:55:32 UTC",
    "updated_date": "2024-11-19 13:27:30 UTC"
  },
  {
    "arxiv_id": "2405.19261v2",
    "title": "Faster Cascades via Speculative Decoding",
    "authors": [
      "Harikrishna Narasimhan",
      "Wittawat Jitkrittum",
      "Ankit Singh Rawat",
      "Seungyeon Kim",
      "Neha Gupta",
      "Aditya Krishna Menon",
      "Sanjiv Kumar"
    ],
    "abstract": "Cascades and speculative decoding are two common approaches to improving\nlanguage models' inference efficiency. Both approaches involve interleaving\nmodels of different sizes, but via fundamentally distinct mechanisms: cascades\nemploy a deferral rule that invokes the larger model only for \"hard\" inputs,\nwhile speculative decoding uses speculative execution to primarily invoke the\nlarger model in parallel verification mode. These mechanisms offer different\nbenefits: empirically, cascades offer better cost-quality trade-offs, often\neven outperforming the large model, while theoretically, speculative decoding\noffers a guarantee of quality-neutrality. In this paper, we leverage the best\nof both these approaches by designing new speculative cascading techniques that\nimplement their deferral rule through speculative execution. We characterize\nthe optimal deferral rule for our speculative cascades, and employ a plug-in\napproximation to the optimal rule. Experiments with Gemma and T5 models on a\nrange of language benchmarks show that our approach yields better cost quality\ntrade-offs than cascading and speculative decoding baselines.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19261v2",
    "published_date": "2024-05-29 16:55:08 UTC",
    "updated_date": "2024-10-21 18:12:44 UTC"
  },
  {
    "arxiv_id": "2405.19255v3",
    "title": "Towards Next-Generation Urban Decision Support Systems through AI-Powered Construction of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation",
    "authors": [
      "Jose Tupayachi",
      "Haowen Xu",
      "Olufemi A. Omitaomu",
      "Mustafa Can Camur",
      "Aliza Sharmin",
      "Xueping Li"
    ],
    "abstract": "The incorporation of Artificial Intelligence (AI) models into various\noptimization systems is on the rise. Yet, addressing complex urban and\nenvironmental management problems normally requires in-depth domain science and\ninformatics expertise. This expertise is essential for deriving data and\nsimulation-driven for informed decision support. In this context, we\ninvestigate the potential of leveraging the pre-trained Large Language Models\n(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated\nworkflow that encompasses natural language processing, methontology-based\nprompt tuning, and transformers. This workflow automates the creation of\nscenario-based ontology using existing research articles and technical manuals\nof urban datasets and simulations. The outcomes of our methodology are\nknowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).\nThese facilitate the development of urban decision support systems by enhancing\nthe data and metadata modeling, the integration of complex datasets, the\ncoupling of multi-domain simulation models, and the formulation of\ndecision-making metrics and workflow. The feasibility of our methodology is\nevaluated through a comparative analysis that juxtaposes our AI-generated\nontology with the well-known Pizza Ontology employed in tutorials for popular\nontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of\noptimizing the complex urban system of multi-modal freight transportation by\ngenerating anthologies of various domain data and simulations to support\ninformed decision-making.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19255v3",
    "published_date": "2024-05-29 16:40:31 UTC",
    "updated_date": "2024-09-06 20:04:22 UTC"
  },
  {
    "arxiv_id": "2405.19250v1",
    "title": "Kotlin ML Pack: Technical Report",
    "authors": [
      "Sergey Titov",
      "Mikhail Evtikhiev",
      "Anton Shapkin",
      "Oleg Smirnov",
      "Sergei Boytsov",
      "Sergei Boytsov",
      "Dariia Karaeva",
      "Maksim Sheptyakov",
      "Mikhail Arkhipov",
      "Timofey Bryksin",
      "Egor Bogomolov"
    ],
    "abstract": "In this technical report, we present three novel datasets of Kotlin code:\nKStack, KStack-clean, and KExercises. We also describe the results of\nfine-tuning CodeLlama and DeepSeek models on this data. Additionally, we\npresent a version of the HumanEval benchmark rewritten by human experts into\nKotlin - both the solutions and the tests. Our results demonstrate that small,\nhigh-quality datasets (KStack-clean and KExercises) can significantly improve\nmodel performance on code generation tasks, achieving up to a 16-point increase\nin pass rate on the HumanEval benchmark. Lastly, we discuss potential future\nwork in the field of improving language modeling for Kotlin, including the use\nof static analysis tools in the learning process and the introduction of more\nintricate and realistic benchmarks.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19250v1",
    "published_date": "2024-05-29 16:33:50 UTC",
    "updated_date": "2024-05-29 16:33:50 UTC"
  },
  {
    "arxiv_id": "2405.19243v1",
    "title": "Challenge-Device-Synthesis: A multi-disciplinary approach for the development of social innovation competences for students of Artificial Intelligence",
    "authors": [
      "Matías Bilkis",
      "Joan Moya Kohler",
      "Fernando Vilariño"
    ],
    "abstract": "The advent of Artificial Intelligence is expected to imply profound changes\nin the short-term. It is therefore imperative for Academia, and particularly\nfor the Computer Science scope, to develop cross-disciplinary tools that bond\nAI developments to their social dimension. To this aim, we introduce the\nChallenge-Device-Synthesis methodology (CDS), in which a specific challenge is\npresented to the students of AI, who are required to develop a device as a\nsolution for the challenge. The device becomes the object of study for the\ndifferent dimensions of social transformation, and the conclusions addressed by\nthe students during the discussion around the device are presented in a\nsynthesis piece in the shape of a 10-page scientific paper. The latter is\nevaluated taking into account both the depth of analysis and the level to which\nit genuinely reflects the social transformations associated with the proposed\nAI-based device. We provide data obtained during the pilot for the\nimplementation phase of CDS within the subject of Social Innovation, a 6-ECTS\nsubject from the 6th semester of the Degree of Artificial Intelligence,\nUAB-Barcelona. We provide details on temporalisation, task distribution,\nmethodological tools used and assessment delivery procedure, as well as\nqualitative analysis of the results obtained.",
    "categories": [
      "cs.AI",
      "physics.ed-ph"
    ],
    "primary_category": "cs.AI",
    "comment": "accepted as contribution for EDULEARN24 - 16th annual International\n  Conference on Education and New Learning Technologies",
    "pdf_url": "http://arxiv.org/pdf/2405.19243v1",
    "published_date": "2024-05-29 16:24:38 UTC",
    "updated_date": "2024-05-29 16:24:38 UTC"
  },
  {
    "arxiv_id": "2405.19238v2",
    "title": "Human-Aware Belief Revision: A Cognitively Inspired Framework for Explanation-Guided Revision of Human Models",
    "authors": [
      "Stylianos Loukas Vasileiou",
      "William Yeoh"
    ],
    "abstract": "Traditional belief revision frameworks often rely on the principle of\nminimalism, which advocates minimal changes to existing beliefs. However,\nresearch in human cognition suggests that people are inherently driven to seek\nexplanations for inconsistencies, thereby striving for explanatory\nunderstanding rather than minimal changes when revising beliefs. Traditional\nframeworks often fail to account for these cognitive patterns, relying instead\non formal principles that may not reflect actual human reasoning. To address\nthis gap, we introduce Human-Aware Belief Revision, a cognitively-inspired\nframework for modeling human belief revision dynamics, where given a human\nmodel and an explanation for an explanandum, revises the model in a non-minimal\nway that aligns with human cognition. Finally, we conduct two human-subject\nstudies to empirically evaluate our framework under real-world scenarios. Our\nfindings support our hypotheses and provide insights into the strategies people\nemploy when resolving inconsistencies, offering some guidance for developing\nmore effective human-aware AI systems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19238v2",
    "published_date": "2024-05-29 16:20:51 UTC",
    "updated_date": "2024-08-22 14:17:58 UTC"
  },
  {
    "arxiv_id": "2405.19237v1",
    "title": "ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning",
    "authors": [
      "Ruchika Chavhan",
      "Da Li",
      "Timothy Hospedales"
    ],
    "abstract": "While large-scale text-to-image diffusion models have demonstrated impressive\nimage-generation capabilities, there are significant concerns about their\npotential misuse for generating unsafe content, violating copyright, and\nperpetuating societal biases. Recently, the text-to-image generation community\nhas begun addressing these concerns by editing or unlearning undesired concepts\nfrom pre-trained models. However, these methods often involve data-intensive\nand inefficient fine-tuning or utilize various forms of token remapping,\nrendering them susceptible to adversarial jailbreaks. In this paper, we present\na simple and effective training-free approach, ConceptPrune, wherein we first\nidentify critical regions within pre-trained models responsible for generating\nundesirable concepts, thereby facilitating straightforward concept unlearning\nvia weight pruning. Experiments across a range of concepts including artistic\nstyles, nudity, object erasure, and gender debiasing demonstrate that target\nconcepts can be efficiently erased by pruning a tiny fraction, approximately\n0.12% of total weights, enabling multi-concept erasure and robustness against\nvarious white-box and black-box adversarial attacks.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19237v1",
    "published_date": "2024-05-29 16:19:37 UTC",
    "updated_date": "2024-05-29 16:19:37 UTC"
  },
  {
    "arxiv_id": "2405.19236v1",
    "title": "Exploring the impact of traffic signal control and connected and automated vehicles on intersections safety: A deep reinforcement learning approach",
    "authors": [
      "Amir Hossein Karbasi",
      "Hao Yang",
      "Saiedeh Razavi"
    ],
    "abstract": "In transportation networks, intersections pose significant risks of\ncollisions due to conflicting movements of vehicles approaching from different\ndirections. To address this issue, various tools can exert influence on traffic\nsafety both directly and indirectly. This study focuses on investigating the\nimpact of adaptive signal control and connected and automated vehicles (CAVs)\non intersection safety using a deep reinforcement learning approach. The\nobjective is to assess the individual and combined effects of CAVs and adaptive\ntraffic signal control on traffic safety, considering rear-end and crossing\nconflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals\nand driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses\nTime To Collision (TTC) metric to evaluate safety. The findings demonstrate a\nsignificant reduction in rear-end and crossing conflicts through the combined\nimplementation of CAVs and DQNs-based traffic signal control. Additionally, the\nlong-term positive effects of CAVs on safety are similar to the short-term\neffects of combined CAVs and DQNs-based traffic signal control. Overall, the\nstudy emphasizes the potential benefits of integrating CAVs and adaptive\ntraffic signal control approaches in order to enhance traffic safety. The\nfindings of this study could provide valuable insights for city officials and\ntransportation authorities in developing effective strategies to improve safety\nat signalized intersections.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "TRB 103nd Annual Meeting",
    "pdf_url": "http://arxiv.org/pdf/2405.19236v1",
    "published_date": "2024-05-29 16:17:19 UTC",
    "updated_date": "2024-05-29 16:17:19 UTC"
  },
  {
    "arxiv_id": "2405.19229v1",
    "title": "On Generating Monolithic and Model Reconciling Explanations in Probabilistic Scenarios",
    "authors": [
      "Stylianos Loukas Vasileiou",
      "William Yeoh",
      "Alessandro Previti",
      "Tran Cao Son"
    ],
    "abstract": "Explanation generation frameworks aim to make AI systems' decisions\ntransparent and understandable to human users. However, generating explanations\nin uncertain environments characterized by incomplete information and\nprobabilistic models remains a significant challenge. In this paper, we propose\na novel framework for generating probabilistic monolithic explanations and\nmodel reconciling explanations. Monolithic explanations provide self-contained\nreasons for an explanandum without considering the agent receiving the\nexplanation, while model reconciling explanations account for the knowledge of\nthe agent receiving the explanation. For monolithic explanations, our approach\nintegrates uncertainty by utilizing probabilistic logic to increase the\nprobability of the explanandum. For model reconciling explanations, we propose\na framework that extends the logic-based variant of the model reconciliation\nproblem to account for probabilistic human models, where the goal is to find\nexplanations that increase the probability of the explanandum while minimizing\nconflicts between the explanation and the probabilistic human model. We\nintroduce explanatory gain and explanatory power as quantitative metrics to\nassess the quality of these explanations. Further, we present algorithms that\nexploit the duality between minimal correction sets and minimal unsatisfiable\nsets to efficiently compute both types of explanations in probabilistic\ncontexts. Extensive experimental evaluations on various benchmarks demonstrate\nthe effectiveness and scalability of our approach in generating explanations\nunder uncertainty.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19229v1",
    "published_date": "2024-05-29 16:07:31 UTC",
    "updated_date": "2024-05-29 16:07:31 UTC"
  },
  {
    "arxiv_id": "2405.19220v5",
    "title": "WRDScore: New Metric for Evaluation of Natural Language Generation Models",
    "authors": [
      "Ravil Mussabayev"
    ],
    "abstract": "Evaluating natural language generation models, particularly for method name\nprediction, poses significant challenges. A robust metric must account for the\nversatility of method naming, considering both semantic and syntactic\nvariations. Traditional overlap-based metrics, such as ROUGE, fail to capture\nthese nuances. Existing embedding-based metrics often suffer from imbalanced\nprecision and recall, lack normalized scores, or make unrealistic assumptions\nabout sequences. To address these limitations, we leverage the theory of\noptimal transport and construct WRDScore, a novel metric that strikes a balance\nbetween simplicity and effectiveness. In the WRDScore framework, we define\nprecision as the maximum degree to which the predicted sequence's tokens are\nincluded in the reference sequence, token by token. Recall is calculated as the\ntotal cost of the optimal transport plan that maps the reference sequence to\nthe predicted one. Finally, WRDScore is computed as the harmonic mean of\nprecision and recall, balancing these two complementary metrics. Our metric is\nlightweight, normalized, and precision-recall-oriented, avoiding unrealistic\nassumptions while aligning well with human judgments. Experiments on a\nhuman-curated dataset confirm the superiority of WRDScore over other available\ntext metrics.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to IEEE Xplore",
    "pdf_url": "http://arxiv.org/pdf/2405.19220v5",
    "published_date": "2024-05-29 16:00:46 UTC",
    "updated_date": "2024-08-13 13:32:07 UTC"
  },
  {
    "arxiv_id": "2405.19213v2",
    "title": "EdgeSight: Enabling Modeless and Cost-Efficient Inference at the Edge",
    "authors": [
      "ChonLam Lao",
      "Jiaqi Gao",
      "Ganesh Ananthanarayanan",
      "Aditya Akella",
      "Minlan Yu"
    ],
    "abstract": "Traditional ML inference is evolving toward modeless inference, which\nabstracts the complexity of model selection from users, allowing the system to\nautomatically choose the most appropriate model for each request based on\naccuracy and resource requirements. While prior studies have focused on\nmodeless inference within data centers, this paper tackles the pressing need\nfor cost-efficient modeless inference at the edge -- particularly within its\nunique constraints of limited device memory, volatile network conditions, and\nrestricted power consumption.\n  To overcome these challenges, we propose EdgeSight, a system that provides\ncost-efficient EdgeSight serving for diverse DNNs at the edge. EdgeSight\nemploys an edge-data center (edge-DC) architecture, utilizing confidence\nscaling to reduce the number of model options while meeting diverse accuracy\nrequirements. Additionally, it supports lossy inference in volatile network\nenvironments. Our experimental results show that EdgeSight outperforms existing\nsystems by up to 1.6x in P99 latency for modeless services. Furthermore, our\nFPGA prototype demonstrates similar performance at certain accuracy levels,\nwith a power consumption reduction of up to 3.34x.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.NI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "12 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.19213v2",
    "published_date": "2024-05-29 15:56:33 UTC",
    "updated_date": "2025-01-15 04:17:38 UTC"
  },
  {
    "arxiv_id": "2405.19212v3",
    "title": "Partial Information Decomposition for Data Interpretability and Feature Selection",
    "authors": [
      "Charles Westphal",
      "Stephen Hailes",
      "Mirco Musolesi"
    ],
    "abstract": "In this paper, we introduce Partial Information Decomposition of Features\n(PIDF), a new paradigm for simultaneous data interpretability and feature\nselection. Contrary to traditional methods that assign a single importance\nvalue, our approach is based on three metrics per feature: the mutual\ninformation shared with the target variable, the feature's contribution to\nsynergistic information, and the amount of this information that is redundant.\nIn particular, we develop a novel procedure based on these three metrics, which\nreveals not only how features are correlated with the target but also the\nadditional and overlapping information provided by considering them in\ncombination with other features. We extensively evaluate PIDF using both\nsynthetic and real-world data, demonstrating its potential applications and\neffectiveness, by considering case studies from genetics and neuroscience.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19212v3",
    "published_date": "2024-05-29 15:54:03 UTC",
    "updated_date": "2024-11-18 16:22:41 UTC"
  },
  {
    "arxiv_id": "2405.19210v1",
    "title": "Gradient Guided Hypotheses: A unified solution to enable machine learning models on scarce and noisy data regimes",
    "authors": [
      "Paulo Neves",
      "Joerg K. Wegner",
      "Philippe Schwaller"
    ],
    "abstract": "Ensuring high-quality data is paramount for maximizing the performance of\nmachine learning models and business intelligence systems. However, challenges\nin data quality, including noise in data capture, missing records, limited data\nproduction, and confounding variables, significantly constrain the potential\nperformance of these systems. In this study, we propose an\narchitecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to\naddress these challenges. GGH analyses gradients from hypotheses as a proxy of\ndistinct and possibly contradictory patterns in the data. This framework\nentails an additional step in machine learning training, where gradients can be\nincluded or excluded from backpropagation. In this manner, missing and noisy\ndata are addressed through a unified solution that perceives both challenges as\nfacets of the same overarching issue: the propagation of erroneous information.\nExperimental validation of GGH is conducted using real-world open-source\ndatasets, where records with missing rates of up to 98.5% are simulated.\nComparative analysis with state-of-the-art imputation methods demonstrates a\nsubstantial improvement in model performance achieved by GGH. Specifically in\nvery high scarcity regimes, GGH was found to be the only viable solution.\nAdditionally, GGH's noise detection capabilities are showcased by introducing\nsimulated noise into the datasets and observing enhanced model performance\nafter filtering out the noisy data. This study presents GGH as a promising\nsolution for improving data quality and model performance in various\napplications.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19210v1",
    "published_date": "2024-05-29 15:51:40 UTC",
    "updated_date": "2024-05-29 15:51:40 UTC"
  },
  {
    "arxiv_id": "2406.11870v1",
    "title": "Sisteme Hibride de Invatare Automata si Aplicatii",
    "authors": [
      "Eduard Hogea",
      "Darian Onchis"
    ],
    "abstract": "In this paper, a deep neural network approach and a neuro-symbolic one are\nproposed for classification and regression. The neuro-symbolic predictive\nmodels based on Logic Tensor Networks are capable of discriminating and in the\nsame time of explaining the characterization of bad connections, called alerts\nor attacks, and of normal connections. The proposed hybrid systems incorporate\nboth the ability of deep neural networks to improve on their own through\nexperience and the interpretability of the results provided by symbolic\nartificial intelligence approach. To justify the need for shifting towards\nhybrid systems, explanation, implementation, and comparison of the dense neural\nnetwork and the neuro-symbolic network is performed in detail. For the\ncomparison to be relevant, the same datasets were used in training and the\nmetrics resulted have been compared. A review of the resulted metrics shows\nthat while both methods have similar precision in their predictive models, with\nLogic Tensor Networks being also possible to have interactive accuracy and\ndeductive reasoning over data. Other advantages and disadvantages such as\noverfitting mitigation and scalability issues are also further discussed.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "in Romanian language",
    "pdf_url": "http://arxiv.org/pdf/2406.11870v1",
    "published_date": "2024-05-29 15:50:34 UTC",
    "updated_date": "2024-05-29 15:50:34 UTC"
  },
  {
    "arxiv_id": "2405.19209v3",
    "title": "VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos",
    "authors": [
      "Ziyang Wang",
      "Shoubin Yu",
      "Elias Stengel-Eskin",
      "Jaehong Yoon",
      "Feng Cheng",
      "Gedas Bertasius",
      "Mohit Bansal"
    ],
    "abstract": "Long-form video understanding is complicated by the high redundancy of video\ndata and the abundance of query-irrelevant information. To tackle these\nchallenges, we propose VideoTree, a training-free framework which builds a\nquery-adaptive and hierarchical video representation for LLM reasoning over\nlong-form videos. First, VideoTree extracts query-relevant information from the\ninput video through an iterative process, progressively refining the selection\nof keyframes based on their relevance to the query. Furthermore, VideoTree\nleverages the inherent hierarchical structure of long video data, which is\noften overlooked by existing LLM-based methods. Specifically, we incorporate\nmulti-granularity information into a tree-based representation, allowing\nVideoTree to extract query-relevant details from long videos in a\ncoarse-to-fine manner. This enables the model to effectively handle a wide\nrange of video queries with varying levels of detail. Finally, VideoTree\naggregates the hierarchical query-relevant information within the tree\nstructure and feeds it into an LLM reasoning model to answer the query. Our\nexperiments show that our method improves both reasoning accuracy and\nefficiency. Specifically, VideoTree outperforms existing training-free\napproaches on EgoSchema and NExT-QA with less inference time, achieving 61.1%\nand 75.6% accuracy on the test set without additional video-specific training.\nMoreover, on the long split of Video-MME (average 44 minutes), VideoTree\nachieves better performance than GPT-4V and many other MLLMs that were\nextensively trained on video data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025; First three authors contributed equally; Project page:\n  https://videotree2024.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2405.19209v3",
    "published_date": "2024-05-29 15:49:09 UTC",
    "updated_date": "2025-03-14 13:57:16 UTC"
  },
  {
    "arxiv_id": "2405.19207v1",
    "title": "A Multi-Source Retrieval Question Answering Framework Based on RAG",
    "authors": [
      "Ridong Wu",
      "Shuhong Chen",
      "Xiangbiao Su",
      "Yuankai Zhu",
      "Yifei Liao",
      "Jianming Wu"
    ],
    "abstract": "With the rapid development of large-scale language models,\nRetrieval-Augmented Generation (RAG) has been widely adopted. However, existing\nRAG paradigms are inevitably influenced by erroneous retrieval information,\nthereby reducing the reliability and correctness of generated results.\nTherefore, to improve the relevance of retrieval information, this study\nproposes a method that replaces traditional retrievers with GPT-3.5, leveraging\nits vast corpus knowledge to generate retrieval information. We also propose a\nweb retrieval based method to implement fine-grained knowledge retrieval,\nUtilizing the powerful reasoning capability of GPT-3.5 to realize semantic\npartitioning of problem.In order to mitigate the illusion of GPT retrieval and\nreduce noise in Web retrieval,we proposes a multi-source retrieval framework,\nnamed MSRAG, which combines GPT retrieval with web retrieval. Experiments on\nmultiple knowledge-intensive QA datasets demonstrate that the proposed\nframework in this study performs better than existing RAG framework in\nenhancing the overall efficiency and accuracy of QA systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "4 pages,3 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.19207v1",
    "published_date": "2024-05-29 15:47:57 UTC",
    "updated_date": "2024-05-29 15:47:57 UTC"
  },
  {
    "arxiv_id": "2405.19202v4",
    "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey",
    "authors": [
      "Renato M. Silva",
      "Gregório F. Azevedo",
      "Matheus V. V. Berto",
      "Jean R. Rocha",
      "Eduardo C. Fidelis",
      "Matheus V. Nogueira",
      "Pedro H. Lisboa",
      "Tiago A. Almeida"
    ],
    "abstract": "Traffic incidents involving vulnerable road users (VRUs) constitute a\nsignificant proportion of global road accidents. Advances in traffic\ncommunication ecosystems, coupled with sophisticated signal processing and\nmachine learning techniques, have facilitated the utilization of data from\ndiverse sensors. Despite these advancements and the availability of extensive\ndatasets, substantial progress is required to mitigate traffic casualties. This\npaper provides a comprehensive survey of state-of-the-art technologies and\nmethodologies to enhance the safety of VRUs. The study delves into the\ncommunication networks between vehicles and VRUs, emphasizing the integration\nof advanced sensors and the availability of relevant datasets. It explores\npreprocessing techniques and data fusion methods to enhance sensor data\nquality. Furthermore, our study assesses critical simulation environments\nessential for developing and testing VRU safety systems. Our research also\nhighlights recent advances in VRU detection and classification algorithms,\naddressing challenges such as variable environmental conditions. Additionally,\nwe cover cutting-edge research in predicting VRU intentions and behaviors,\nwhich is crucial for proactive collision avoidance strategies. Through this\nsurvey, we aim to provide a comprehensive understanding of the current\nlandscape of VRU safety technologies, identifying areas of progress and areas\nneeding further research and development.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "57 pages, 18 tables, 8 figures, citing 339 (up-to-date) papers,\n  preprint submitted to Expert Systems with Applications (Elsevier)",
    "pdf_url": "http://arxiv.org/pdf/2405.19202v4",
    "published_date": "2024-05-29 15:42:10 UTC",
    "updated_date": "2024-11-05 19:24:50 UTC"
  },
  {
    "arxiv_id": "2405.19201v2",
    "title": "Going beyond Compositions, DDPMs Can Produce Zero-Shot Interpolations",
    "authors": [
      "Justin Deschenaux",
      "Igor Krawczuk",
      "Grigorios Chrysos",
      "Volkan Cevher"
    ],
    "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable\ncapabilities in image generation, with studies suggesting that they can\ngeneralize by composing latent factors learned from the training data. In this\nwork, we go further and study DDPMs trained on strictly separate subsets of the\ndata distribution with large gaps on the support of the latent factors. We show\nthat such a model can effectively generate images in the unexplored,\nintermediate regions of the distribution. For instance, when trained on clearly\nsmiling and non-smiling faces, we demonstrate a sampling procedure which can\ngenerate slightly smiling faces without reference images (zero-shot\ninterpolation). We replicate these findings for other attributes as well as\nother datasets. Our code is available at\nhttps://github.com/jdeschena/ddpm-zero-shot-interpolation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19201v2",
    "published_date": "2024-05-29 15:41:53 UTC",
    "updated_date": "2024-07-10 14:42:18 UTC"
  },
  {
    "arxiv_id": "2405.19184v1",
    "title": "Promoting Two-sided Fairness in Dynamic Vehicle Routing Problem",
    "authors": [
      "Yufan Kang",
      "Rongsheng Zhang",
      "Wei Shao",
      "Flora D. Salim",
      "Jeffrey Chan"
    ],
    "abstract": "Dynamic Vehicle Routing Problem (DVRP), is an extension of the classic\nVehicle Routing Problem (VRP), which is a fundamental problem in logistics and\ntransportation. Typically, DVRPs involve two stakeholders: service providers\nthat deliver services to customers and customers who raise requests from\ndifferent locations. Many real-world applications can be formulated as DVRP\nsuch as ridesharing and non-compliance capture. Apart from original objectives\nlike optimising total utility or efficiency, DVRP should also consider fairness\nfor all parties. Unfairness can induce service providers and customers to give\nup on the systems, leading to negative financial and social impacts. However,\nmost existing DVRP-related applications focus on improving fairness from a\nsingle side, and there have been few works considering two-sided fairness and\nutility optimisation concurrently. To this end, we propose a novel framework, a\nTwo-sided Fairness-aware Genetic Algorithm (named 2FairGA), which expands the\ngenetic algorithm from the original objective solely focusing on utility to\nmulti-objectives that incorporate two-sided fairness. Subsequently, the impact\nof injecting two fairness definitions into the utility-focused model and the\ncorrelation between any pair of the three objectives are explored. Extensive\nexperiments demonstrate the superiority of our proposed framework compared to\nthe state-of-the-art.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19184v1",
    "published_date": "2024-05-29 15:24:28 UTC",
    "updated_date": "2024-05-29 15:24:28 UTC"
  },
  {
    "arxiv_id": "2405.19176v1",
    "title": "The ethical situation of DALL-E 2",
    "authors": [
      "Eduard Hogea",
      "Josem Rocafortf"
    ],
    "abstract": "A hot topic of Artificial Intelligence right now is image generation from\nprompts. DALL-E 2 is one of the biggest names in this domain, as it allows\npeople to create images from simple text inputs, to even more complicated ones.\nThe company that made this possible, OpenAI, has assured everyone that visited\ntheir website that their mission is to ensure that artificial general\nintelligence benefits all humanity. A noble idea in our opinion, that also\nstood as the motive behind us choosing this subject. This paper analyzes the\nethical implications of an AI image generative system, with an emphasis on how\nsociety is responding to it, how it probably will and how it should if all the\nright measures are taken.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19176v1",
    "published_date": "2024-05-29 15:18:13 UTC",
    "updated_date": "2024-05-29 15:18:13 UTC"
  },
  {
    "arxiv_id": "2405.19166v1",
    "title": "Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity",
    "authors": [
      "Benjamin Shih",
      "Ahmad Peyvan",
      "Zhongqiang Zhang",
      "George Em Karniadakis"
    ],
    "abstract": "Neural operator learning models have emerged as very effective surrogates in\ndata-driven methods for partial differential equations (PDEs) across different\napplications from computational science and engineering. Such operator learning\nmodels not only predict particular instances of a physical or biological system\nin real-time but also forecast classes of solutions corresponding to a\ndistribution of initial and boundary conditions or forcing terms. % DeepONet is\nthe first neural operator model and has been tested extensively for a broad\nclass of solutions, including Riemann problems. Transformers have not been used\nin that capacity, and specifically, they have not been tested for solutions of\nPDEs with low regularity. %\n  In this work, we first establish the theoretical groundwork that transformers\npossess the universal approximation property as operator learning models.\n  We then apply transformers to forecast solutions of diverse dynamical systems\nwith solutions of finite regularity for a plurality of initial conditions and\nforcing terms. In particular, we consider three examples: the Izhikevich neuron\nmodel, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and\nthe one-dimensional Euler equation Riemann problem. For the latter problem, we\nalso compare with variants of DeepONet, and we find that transformers\noutperform DeepONet in accuracy but they are computationally more expensive.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19166v1",
    "published_date": "2024-05-29 15:10:24 UTC",
    "updated_date": "2024-05-29 15:10:24 UTC"
  },
  {
    "arxiv_id": "2405.19164v1",
    "title": "Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery",
    "authors": [
      "Sounak Lahiri",
      "Sumit Pai",
      "Tim Weninger",
      "Sanmitra Bhattacharya"
    ],
    "abstract": "Electronic Discovery (eDiscovery) involves identifying relevant documents\nfrom a vast collection based on legal production requests. The integration of\nartificial intelligence (AI) and natural language processing (NLP) has\ntransformed this process, helping document review and enhance efficiency and\ncost-effectiveness. Although traditional approaches like BM25 or fine-tuned\npre-trained models are common in eDiscovery, they face performance,\ncomputational, and interpretability challenges. In contrast, Large Language\nModel (LLM)-based methods prioritize interpretability but sacrifice performance\nand throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid\napproach that combines the strengths of two worlds: a heterogeneous graph-based\nmethod for accurate document relevance prediction and subsequent LLM-driven\napproach for reasoning. Graph representational learning generates embeddings\nand predicts links, ranking the corpus for a given request, and the LLMs\nprovide reasoning for document relevance. Our approach handles datasets with\nbalanced and imbalanced distributions, outperforming baselines in F1-score,\nprecision, and recall by an average of 12%, 3%, and 16%, respectively. In an\nenterprise context, our approach drastically reduces document review costs by\n99.9% compared to manual processes and by 95% compared to LLM-based\nclassification methods",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 2 tables, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.19164v1",
    "published_date": "2024-05-29 15:08:55 UTC",
    "updated_date": "2024-05-29 15:08:55 UTC"
  },
  {
    "arxiv_id": "2405.19162v1",
    "title": "Does learning the right latent variables necessarily improve in-context learning?",
    "authors": [
      "Sarthak Mittal",
      "Eric Elmoznino",
      "Leo Gagnon",
      "Sangnie Bhardwaj",
      "Dhanya Sridhar",
      "Guillaume Lajoie"
    ],
    "abstract": "Large autoregressive models like Transformers can solve tasks through\nin-context learning (ICL) without learning new weights, suggesting avenues for\nefficiently solving new tasks. For many tasks, e.g., linear regression, the\ndata factorizes: examples are independent given a task latent that generates\nthe data, e.g., linear coefficients. While an optimal predictor leverages this\nfactorization by inferring task latents, it is unclear if Transformers\nimplicitly do so or if they instead exploit heuristics and statistical\nshortcuts enabled by attention layers. Both scenarios have inspired active\nongoing work. In this paper, we systematically investigate the effect of\nexplicitly inferring task latents. We minimally modify the Transformer\narchitecture with a bottleneck designed to prevent shortcuts in favor of more\nstructured solutions, and then compare performance against standard\nTransformers across various ICL tasks. Contrary to intuition and some recent\nworks, we find little discernible difference between the two; biasing towards\ntask-relevant latent variables does not lead to better out-of-distribution\nperformance, in general. Curiously, we find that while the bottleneck\neffectively learns to extract latent task variables from context, downstream\nprocessing struggles to utilize them for robust prediction. Our study\nhighlights the intrinsic limitations of Transformers in achieving structured\nICL solutions that generalize, and shows that while inferring the right latents\naids interpretability, it is not sufficient to alleviate this problem.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19162v1",
    "published_date": "2024-05-29 15:06:10 UTC",
    "updated_date": "2024-05-29 15:06:10 UTC"
  },
  {
    "arxiv_id": "2405.19153v2",
    "title": "A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning",
    "authors": [
      "Arthur Juliani",
      "Jordan T. Ash"
    ],
    "abstract": "Continual learning with deep neural networks presents challenges distinct\nfrom both the fixed-dataset and convex continual learning regimes. One such\nchallenge is plasticity loss, wherein a neural network trained in an online\nfashion displays a degraded ability to fit new tasks. This problem has been\nextensively studied in both supervised learning and off-policy reinforcement\nlearning (RL), where a number of remedies have been proposed. Still, plasticity\nloss has received less attention in the on-policy deep RL setting. Here we\nperform an extensive set of experiments examining plasticity loss and a variety\nof mitigation methods in on-policy deep RL. We demonstrate that plasticity loss\nis pervasive under domain shift in this regime, and that a number of methods\ndeveloped to resolve it in other settings fail, sometimes even performing worse\nthan applying no intervention at all. In contrast, we find that a class of\n``regenerative'' methods are able to consistently mitigate plasticity loss in a\nvariety of contexts, including in gridworld tasks and more challenging\nenvironments like Montezuma's Revenge and ProcGen.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19153v2",
    "published_date": "2024-05-29 14:59:49 UTC",
    "updated_date": "2024-11-01 16:47:59 UTC"
  },
  {
    "arxiv_id": "2405.19149v2",
    "title": "CaLa: Complementary Association Learning for Augmenting Composed Image Retrieval",
    "authors": [
      "Xintong Jiang",
      "Yaxiong Wang",
      "Mengjian Li",
      "Yujiao Wu",
      "Bingwen Hu",
      "Xueming Qian"
    ],
    "abstract": "Composed Image Retrieval (CIR) involves searching for target images based on\nan image-text pair query. While current methods treat this as a query-target\nmatching problem, we argue that CIR triplets contain additional associations\nbeyond this primary relation. In our paper, we identify two new relations\nwithin triplets, treating each triplet as a graph node. Firstly, we introduce\nthe concept of text-bridged image alignment, where the query text serves as a\nbridge between the query image and the target image. We propose a hinge-based\ncross-attention mechanism to incorporate this relation into network learning.\nSecondly, we explore complementary text reasoning, considering CIR as a form of\ncross-modal retrieval where two images compose to reason about complementary\ntext. To integrate these perspectives effectively, we design a twin\nattention-based compositor. By combining these complementary associations with\nthe explicit query pair-target image relation, we establish a comprehensive set\nof constraints for CIR. Our framework, CaLa (Complementary Association Learning\nfor Augmenting Composed Image Retrieval), leverages these insights. We evaluate\nCaLa on CIRR and FashionIQ benchmarks with multiple backbones, demonstrating\nits superiority in composed image retrieval.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "To appear at SIGIR 2024. arXiv admin note: text overlap with\n  arXiv:2309.02169",
    "pdf_url": "http://arxiv.org/pdf/2405.19149v2",
    "published_date": "2024-05-29 14:52:10 UTC",
    "updated_date": "2024-05-30 13:26:43 UTC"
  },
  {
    "arxiv_id": "2405.19139v1",
    "title": "DGRC: An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension",
    "authors": [
      "Runfeng Lin",
      "Dacheng Xu",
      "Huijiang Wang",
      "Zebiao Chen",
      "Yating Wang",
      "Shouqiang Liu"
    ],
    "abstract": "When evaluating a learner's knowledge proficiency, the multiple-choice\nquestion is an efficient and widely used format in standardized tests.\nNevertheless, generating these questions, particularly plausible distractors\n(incorrect options), poses a considerable challenge. Generally, the distractor\ngeneration can be classified into cloze-style distractor generation (CDG) and\nnatural questions distractor generation (NQDG). In contrast to the CDG,\nutilizing pre-trained language models (PLMs) for NQDG presents three primary\nchallenges: (1) PLMs are typically trained to generate ``correct'' content,\nlike answers, while rarely trained to generate ``plausible\" content, like\ndistractors; (2) PLMs often struggle to produce content that aligns well with\nspecific knowledge and the style of exams; (3) NQDG necessitates the model to\nproduce longer, context-sensitive, and question-relevant distractors. In this\nstudy, we introduce a fine-tuning framework named DGRC for NQDG in Chinese\nmulti-choice reading comprehension from authentic examinations. DGRC comprises\nthree major components: hard chain-of-thought, multi-task learning, and\ngeneration mask patterns. The experiment results demonstrate that DGRC\nsignificantly enhances generation performance, achieving a more than 2.5-fold\nimprovement in BLEU scores.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19139v1",
    "published_date": "2024-05-29 14:47:01 UTC",
    "updated_date": "2024-05-29 14:47:01 UTC"
  },
  {
    "arxiv_id": "2405.19132v1",
    "title": "Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT",
    "authors": [
      "Andreas Scholl",
      "Daniel Schiffner",
      "Natalie Kiesler"
    ],
    "abstract": "Large Language Models (LLMs) have taken the world by storm, and students are\nassumed to use related tools at a great scale. In this research paper we aim to\ngain an understanding of how introductory programming students chat with LLMs\nand related tools, e.g., ChatGPT-3.5. To address this goal, computing students\nat a large German university were motivated to solve programming exercises with\nthe assistance of ChatGPT as part of their weekly introductory course\nexercises. Then students (n=213) submitted their chat protocols (with 2335\nprompts in sum) as data basis for this analysis. The data was analyzed w.r.t.\nthe prompts, frequencies, the chats' progress, contents, and other use pattern,\nwhich revealed a great variety of interactions, both potentially supportive and\nconcerning. Learning about students' interactions with ChatGPT will help inform\nand align teaching practices and instructions for future introductory\nprogramming courses in higher education.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at DELFI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19132v1",
    "published_date": "2024-05-29 14:38:32 UTC",
    "updated_date": "2024-05-29 14:38:32 UTC"
  },
  {
    "arxiv_id": "2405.19121v2",
    "title": "Spatio-Spectral Graph Neural Networks",
    "authors": [
      "Simon Geisler",
      "Arthur Kosmala",
      "Daniel Herbst",
      "Stephan Günnemann"
    ],
    "abstract": "Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for\nlearning on graph-structured data. However, key limitations of l-step MPGNNs\nare that their \"receptive field\" is typically limited to the l-hop neighborhood\nof a node and that information exchange between distant nodes is limited by\nover-squashing. Motivated by these limitations, we propose Spatio-Spectral\nGraph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural\nNetworks (GNNs) that synergistically combines spatially and spectrally\nparametrized graph filters. Parameterizing filters partially in the frequency\ndomain enables global yet efficient information propagation. We show that\nS$^2$GNNs vanquish over-squashing and yield strictly tighter\napproximation-theoretic error bounds than MPGNNs. Further, rethinking graph\nconvolutions at a fundamental level unlocks new design spaces. For example,\nS$^2$GNNs allow for free positional encodings that make them strictly more\nexpressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain\ngeneral-purpose S$^2$GNNs, we propose spectrally parametrized filters for\ndirected graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and\ngraph rewirings, e.g., on the peptide long-range benchmark tasks, and are\ncompetitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs\nscale to millions of nodes.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "46 pages, 27 figures, 12 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.19121v2",
    "published_date": "2024-05-29 14:28:08 UTC",
    "updated_date": "2024-06-02 18:03:44 UTC"
  },
  {
    "arxiv_id": "2405.19107v1",
    "title": "Offline Regularised Reinforcement Learning for Large Language Models Alignment",
    "authors": [
      "Pierre Harvey Richemond",
      "Yunhao Tang",
      "Daniel Guo",
      "Daniele Calandriello",
      "Mohammad Gheshlaghi Azar",
      "Rafael Rafailov",
      "Bernardo Avila Pires",
      "Eugene Tarassov",
      "Lucas Spangher",
      "Will Ellsworth",
      "Aliaksei Severyn",
      "Jonathan Mallinson",
      "Lior Shani",
      "Gil Shamir",
      "Rishabh Joshi",
      "Tianqi Liu",
      "Remi Munos",
      "Bilal Piot"
    ],
    "abstract": "The dominant framework for alignment of large language models (LLM), whether\nthrough reinforcement learning from human feedback or direct preference\noptimisation, is to learn from preference data. This involves building datasets\nwhere each element is a quadruplet composed of a prompt, two independent\nresponses (completions of the prompt) and a human preference between the two\nindependent responses, yielding a preferred and a dis-preferred response. Such\ndata is typically scarce and expensive to collect. On the other hand,\n\\emph{single-trajectory} datasets where each element is a triplet composed of a\nprompt, a response and a human feedback is naturally more abundant. The\ncanonical element of such datasets is for instance an LLM's response to a\nuser's prompt followed by a user's feedback such as a thumbs-up/down.\nConsequently, in this work, we propose DRO, or \\emph{Direct Reward\nOptimisation}, as a framework and associated algorithms that do not require\npairwise preferences. DRO uses a simple mean-squared objective that can be\nimplemented in various ways. We validate our findings empirically, using T5\nencoder-decoder language models, and show DRO's performance over selected\nbaselines such as Kahneman-Tversky Optimization (KTO). Thus, we confirm that\nDRO is a simple and empirically compelling method for single-trajectory policy\noptimisation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19107v1",
    "published_date": "2024-05-29 14:11:29 UTC",
    "updated_date": "2024-05-29 14:11:29 UTC"
  },
  {
    "arxiv_id": "2405.19098v1",
    "title": "Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior",
    "authors": [
      "Shuyu Cheng",
      "Yibo Miao",
      "Yinpeng Dong",
      "Xiao Yang",
      "Xiao-Shan Gao",
      "Jun Zhu"
    ],
    "abstract": "This paper studies the challenging black-box adversarial attack that aims to\ngenerate adversarial examples against a black-box model by only using output\nfeedback of the model to input queries. Some previous methods improve the query\nefficiency by incorporating the gradient of a surrogate white-box model into\nquery-based attacks due to the adversarial transferability. However, the\nlocalized gradient is not informative enough, making these methods still\nquery-intensive. In this paper, we propose a Prior-guided Bayesian Optimization\n(P-BO) algorithm that leverages the surrogate model as a global function prior\nin black-box adversarial attacks. As the surrogate model contains rich prior\ninformation of the black-box one, P-BO models the attack objective with a\nGaussian process whose mean function is initialized as the surrogate model's\nloss. Our theoretical analysis on the regret bound indicates that the\nperformance of P-BO may be affected by a bad prior. Therefore, we further\npropose an adaptive integration strategy to automatically adjust a coefficient\non the function prior by minimizing the regret bound. Extensive experiments on\nimage classifiers and large vision-language models demonstrate the superiority\nof the proposed algorithm in reducing queries and improving attack success\nrates compared with the state-of-the-art black-box attacks. Code is available\nat https://github.com/yibo-miao/PBO-Attack.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19098v1",
    "published_date": "2024-05-29 14:05:16 UTC",
    "updated_date": "2024-05-29 14:05:16 UTC"
  },
  {
    "arxiv_id": "2405.19094v1",
    "title": "Faithful Chart Summarization with ChaTS-Pi",
    "authors": [
      "Syrine Krichene",
      "Francesco Piccinno",
      "Fangyu Liu",
      "Julian Martin Eisenschlos"
    ],
    "abstract": "Chart-to-summary generation can help explore data, communicate insights, and\nhelp the visually impaired people. Multi-modal generative models have been used\nto produce fluent summaries, but they can suffer from factual and perceptual\nerrors. In this work we present CHATS-CRITIC, a reference-free chart\nsummarization metric for scoring faithfulness. CHATS-CRITIC is composed of an\nimage-to-text model to recover the table from a chart, and a tabular entailment\nmodel applied to score the summary sentence by sentence. We find that\nCHATS-CRITIC evaluates the summary quality according to human ratings better\nthan reference-based metrics, either learned or n-gram based, and can be\nfurther used to fix candidate summaries by removing not supported sentences. We\nthen introduce CHATS-PI, a chart-to-summary pipeline that leverages\nCHATS-CRITIC during inference to fix and rank sampled candidates from any\nchart-summarization model. We evaluate CHATS-PI and CHATS-CRITIC using human\nraters, establishing state-of-the-art results on two popular chart-to-summary\ndatasets.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "To be published in the proceedings of the 2024 Annual Meeting of the\n  Association for Computational Linguistics",
    "pdf_url": "http://arxiv.org/pdf/2405.19094v1",
    "published_date": "2024-05-29 13:55:06 UTC",
    "updated_date": "2024-05-29 13:55:06 UTC"
  },
  {
    "arxiv_id": "2405.19085v1",
    "title": "Patch-enhanced Mask Encoder Prompt Image Generation",
    "authors": [
      "Shusong Xu",
      "Peiye Liu"
    ],
    "abstract": "Artificial Intelligence Generated Content(AIGC), known for its superior\nvisual results, represents a promising mitigation method for high-cost\nadvertising applications. Numerous approaches have been developed to manipulate\ngenerated content under different conditions. However, a crucial limitation\nlies in the accurate description of products in advertising applications.\nApplying previous methods directly may lead to considerable distortion and\ndeformation of advertised products, primarily due to oversimplified content\ncontrol conditions. Hence, in this work, we propose a patch-enhanced mask\nencoder approach to ensure accurate product descriptions while preserving\ndiverse backgrounds. Our approach consists of three components Patch Flexible\nVisibility, Mask Encoder Prompt Adapter and an image Foundation Model. Patch\nFlexible Visibility is used for generating a more reasonable background image.\nMask Encoder Prompt Adapter enables region-controlled fusion. We also conduct\nan analysis of the structure and operational mechanisms of the Generation\nModule. Experimental results show our method can achieve the highest visual\nresults and FID scores compared with other methods.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19085v1",
    "published_date": "2024-05-29 13:47:32 UTC",
    "updated_date": "2024-05-29 13:47:32 UTC"
  },
  {
    "arxiv_id": "2405.19080v1",
    "title": "OMPO: A Unified Framework for RL under Policy and Dynamics Shifts",
    "authors": [
      "Yu Luo",
      "Tianying Ji",
      "Fuchun Sun",
      "Jianwei Zhang",
      "Huazhe Xu",
      "Xianyuan Zhan"
    ],
    "abstract": "Training reinforcement learning policies using environment interaction data\ncollected from varying policies or dynamics presents a fundamental challenge.\nExisting works often overlook the distribution discrepancies induced by policy\nor dynamics shifts, or rely on specialized algorithms with task priors, thus\noften resulting in suboptimal policy performances and high learning variances.\nIn this paper, we identify a unified strategy for online RL policy learning\nunder diverse settings of policy and dynamics shifts: transition occupancy\nmatching. In light of this, we introduce a surrogate policy learning objective\nby considering the transition occupancy discrepancies and then cast it into a\ntractable min-max optimization problem through dual reformulation. Our method,\ndubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized\nactor-critic structure equipped with a distribution discriminator and a\nsmall-size local buffer. We conduct extensive experiments based on the OpenAI\nGym, Meta-World, and Panda Robots environments, encompassing policy shifts\nunder stationary and nonstationary dynamics, as well as domain adaption. The\nresults demonstrate that OMPO outperforms the specialized baselines from\ndifferent categories in all settings. We also find that OMPO exhibits\nparticularly strong performance when combined with domain randomization,\nhighlighting its potential in RL-based robotics applications",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19080v1",
    "published_date": "2024-05-29 13:36:36 UTC",
    "updated_date": "2024-05-29 13:36:36 UTC"
  },
  {
    "arxiv_id": "2405.19074v1",
    "title": "Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning",
    "authors": [
      "Dipam Goswami",
      "Albin Soutif--Cormerais",
      "Yuyang Liu",
      "Sandesh Kamath",
      "Bartłomiej Twardowski",
      "Joost van de Weijer"
    ],
    "abstract": "Continual learning methods are known to suffer from catastrophic forgetting,\na phenomenon that is particularly hard to counter for methods that do not store\nexemplars of previous tasks. Therefore, to reduce potential drift in the\nfeature extractor, existing exemplar-free methods are typically evaluated in\nsettings where the first task is significantly larger than subsequent tasks.\nTheir performance drops drastically in more challenging settings starting with\na smaller first task. To address this problem of feature drift estimation for\nexemplar-free methods, we propose to adversarially perturb the current samples\nsuch that their embeddings are close to the old class prototypes in the old\nmodel embedding space. We then estimate the drift in the embedding space from\nthe old to the new model using the perturbed images and compensate the\nprototypes accordingly. We exploit the fact that adversarial samples are\ntransferable from the old to the new feature space in a continual learning\nsetting. The generation of these images is simple and computationally cheap. We\ndemonstrate in our experiments that the proposed approach better tracks the\nmovement of prototypes in embedding space and outperforms existing methods on\nseveral standard continual learning benchmarks as well as on fine-grained\ndatasets. Code is available at https://github.com/dipamgoswami/ADC.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19074v1",
    "published_date": "2024-05-29 13:31:42 UTC",
    "updated_date": "2024-05-29 13:31:42 UTC"
  },
  {
    "arxiv_id": "2405.19062v1",
    "title": "SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs",
    "authors": [
      "Lanting Fang",
      "Yulian Yang",
      "Kai Wang",
      "Shanshan Feng",
      "Kaiyu Feng",
      "Jie Gui",
      "Shuliang Wang",
      "Yew-Soon Ong"
    ],
    "abstract": "While dynamic graph neural networks have shown promise in various\napplications, explaining their predictions on continuous-time dynamic graphs\n(CTDGs) is difficult. This paper investigates a new research task:\nself-interpretable GNNs for CTDGs. We aim to predict future links within the\ndynamic graph while simultaneously providing causal explanations for these\npredictions. There are two key challenges: (1) capturing the underlying\nstructural and temporal information that remains consistent across both\nindependent and identically distributed (IID) and out-of-distribution (OOD)\ndata, and (2) efficiently generating high-quality link prediction results and\nexplanations. To tackle these challenges, we propose a novel causal inference\nmodel, namely the Independent and Confounded Causal Model (ICCM). ICCM is then\nintegrated into a deep learning architecture that considers both effectiveness\nand efficiency. Extensive experiments demonstrate that our proposed model\nsignificantly outperforms existing methods across link prediction accuracy,\nexplanation quality, and robustness to shortcut features. Our code and datasets\nare anonymously released at https://github.com/2024SIG/SIG.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.19062v1",
    "published_date": "2024-05-29 13:09:33 UTC",
    "updated_date": "2024-05-29 13:09:33 UTC"
  },
  {
    "arxiv_id": "2405.19053v1",
    "title": "Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of Electric Vehicle Charging Stations",
    "authors": [
      "Zongbao Zhang",
      "Jiao Hao",
      "Wenmeng Zhao",
      "Yan Liu",
      "Yaohui Huang",
      "Xinhang Luo"
    ],
    "abstract": "The rapid expansion of electric vehicles (EVs) has rendered the load\nforecasting of electric vehicle charging stations (EVCS) increasingly critical.\nThe primary challenge in achieving precise load forecasting for EVCS lies in\naccounting for the nonlinear of charging behaviors, the spatial interactions\namong different stations, and the intricate temporal variations in usage\npatterns. To address these challenges, we propose a Multiscale Spatio-Temporal\nEnhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM\nincorporates a multiscale graph neural network to discern hierarchical\nnonlinear temporal dependencies across various time scales. Besides, it also\nintegrates a recurrent learning component and a residual fusion mechanism,\nenhancing its capability to accurately capture spatial and temporal variations\nin charging patterns. The effectiveness of the proposed MSTEM has been\nvalidated through comparative analysis with six baseline models using three\nevaluation metrics. The case studies utilize real-world datasets for both fast\nand slow charging loads at EVCS in Perth, UK. The experimental results\ndemonstrate the superiority of MSTEM in short-term continuous load forecasting\nfor EVCS.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "5 pages, 1 figure, AEEES 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19053v1",
    "published_date": "2024-05-29 12:54:22 UTC",
    "updated_date": "2024-05-29 12:54:22 UTC"
  },
  {
    "arxiv_id": "2405.19047v2",
    "title": "Statistical Context Detection for Deep Lifelong Reinforcement Learning",
    "authors": [
      "Jeffery Dick",
      "Saptarshi Nath",
      "Christos Peridis",
      "Eseoghene Benjamin",
      "Soheil Kolouri",
      "Andrea Soltoggio"
    ],
    "abstract": "Context detection involves labeling segments of an online stream of data as\nbelonging to different tasks. Task labels are used in lifelong learning\nalgorithms to perform consolidation or other procedures that prevent\ncatastrophic forgetting. Inferring task labels from online experiences remains\na challenging problem. Most approaches assume finite and low-dimension\nobservation spaces or a preliminary training phase during which task labels are\nlearned. Moreover, changes in the transition or reward functions can be\ndetected only in combination with a policy, and therefore are more difficult to\ndetect than changes in the input distribution. This paper presents an approach\nto learning both policies and labels in an online deep reinforcement learning\nsetting. The key idea is to use distance metrics, obtained via optimal\ntransport methods, i.e., Wasserstein distance, on suitable latent action-reward\nspaces to measure distances between sets of data points from past and current\nstreams. Such distances can then be used for statistical tests based on an\nadapted Kolmogorov-Smirnov calculation to assign labels to sequences of\nexperiences. A rollback procedure is introduced to learn multiple policies by\nensuring that only the appropriate data is used to train the corresponding\npolicy. The combination of task detection and policy deployment allows for the\noptimization of lifelong reinforcement learning agents without an oracle that\nprovides task labels. The approach is tested using two benchmarks and the\nresults show promising performance when compared with related context detection\nalgorithms. The results suggest that optimal transport statistical methods\nprovide an explainable and justifiable procedure for online context detection\nand reward optimization in lifelong reinforcement learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages excluding references and bibliography. Accepted at CoLLAs\n  2024",
    "pdf_url": "http://arxiv.org/pdf/2405.19047v2",
    "published_date": "2024-05-29 12:44:41 UTC",
    "updated_date": "2024-09-03 09:25:46 UTC"
  },
  {
    "arxiv_id": "2405.19033v1",
    "title": "CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation in Ultra-Lightweight and One-Shot Graph Classification on Edge",
    "authors": [
      "Yuxi Han",
      "Jihe Wang",
      "Danghui Wang"
    ],
    "abstract": "Graph Neural Networks (GNNs) are computationally demanding and inefficient\nwhen applied to graph classification tasks in resource-constrained edge\nscenarios due to their inherent process, involving multiple rounds of forward\nand backward propagation. As a lightweight alternative, Hyper-Dimensional\nComputing (HDC), which leverages high-dimensional vectors for data encoding and\nprocessing, offers a more efficient solution by addressing computational\nbottleneck. However, current HDC methods primarily focus on static graphs and\nneglect to effectively capture node attributes and structural information,\nwhich leads to poor accuracy. In this work, we propose CiliaGraph, an enhanced\nexpressive yet ultra-lightweight HDC model for graph classification. This model\nintroduces a novel node encoding strategy that preserves relative distance\nisomorphism for accurate node connection representation. In addition, node\ndistances are utilized as edge weights for information aggregation, and the\nencoded node attributes and structural information are concatenated to obtain a\ncomprehensive graph representation. Furthermore, we explore the relationship\nbetween orthogonality and dimensionality to reduce the dimensions, thereby\nfurther enhancing computational efficiency. Compared to the SOTA GNNs,\nextensive experiments show that CiliaGraph reduces memory usage and accelerates\ntraining speed by an average of 292 times(up to 2341 times) and 103 times(up to\n313 times) respectively while maintaining comparable accuracy.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19033v1",
    "published_date": "2024-05-29 12:22:59 UTC",
    "updated_date": "2024-05-29 12:22:59 UTC"
  },
  {
    "arxiv_id": "2405.19032v1",
    "title": "Large Language Models for Code Summarization",
    "authors": [
      "Balázs Szalontai",
      "Gergő Szalay",
      "Tamás Márton",
      "Anna Sike",
      "Balázs Pintér",
      "Tibor Gregorics"
    ],
    "abstract": "Recently, there has been increasing activity in using deep learning for\nsoftware engineering, including tasks like code generation and summarization.\nIn particular, the most recent coding Large Language Models seem to perform\nwell on these problems. In this technical report, we aim to review how these\nmodels perform in code explanation/summarization, while also investigating\ntheir code generation capabilities (based on natural language descriptions).",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.PL",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "technical report with 11 pages, 1 figure, 10 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.19032v1",
    "published_date": "2024-05-29 12:18:51 UTC",
    "updated_date": "2024-05-29 12:18:51 UTC"
  },
  {
    "arxiv_id": "2405.19029v1",
    "title": "Convex neural network synthesis for robustness in the 1-norm",
    "authors": [
      "Ross Drummond",
      "Chris Guiver",
      "Matthew C. Turner"
    ],
    "abstract": "With neural networks being used to control safety-critical systems, they\nincreasingly have to be both accurate (in the sense of matching inputs to\noutputs) and robust. However, these two properties are often at odds with each\nother and a trade-off has to be navigated. To address this issue, this paper\nproposes a method to generate an approximation of a neural network which is\ncertifiably more robust. Crucially, the method is fully convex and posed as a\nsemi-definite programme. An application to robustifying model predictive\ncontrol is used to demonstrate the results. The aim of this work is to\nintroduce a method to navigate the neural network robustness/accuracy\ntrade-off.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19029v1",
    "published_date": "2024-05-29 12:17:09 UTC",
    "updated_date": "2024-05-29 12:17:09 UTC"
  },
  {
    "arxiv_id": "2405.19026v2",
    "title": "DiveR-CT: Diversity-enhanced Red Teaming Large Language Model Assistants with Relaxing Constraints",
    "authors": [
      "Andrew Zhao",
      "Quentin Xu",
      "Matthieu Lin",
      "Shenzhi Wang",
      "Yong-jin Liu",
      "Zilong Zheng",
      "Gao Huang"
    ],
    "abstract": "Recent advances in large language model assistants have made them\nindispensable, raising significant concerns over managing their safety.\nAutomated red teaming offers a promising alternative to the labor-intensive and\nerror-prone manual probing for vulnerabilities, providing more consistent and\nscalable safety evaluations. However, existing approaches often compromise\ndiversity by focusing on maximizing attack success rate. Additionally, methods\nthat decrease the cosine similarity from historical embeddings with semantic\ndiversity rewards lead to novelty stagnation as history grows. To address these\nissues, we introduce DiveR-CT, which relaxes conventional constraints on the\nobjective and semantic reward, granting greater freedom for the policy to\nenhance diversity. Our experiments demonstrate DiveR-CT's marked superiority\nover baselines by 1) generating data that perform better in various diversity\nmetrics across different attack success rate levels, 2) better-enhancing\nresiliency in blue team models through safety tuning based on collected data,\n3) allowing dynamic control of objective weights for reliable and controllable\nattack success rates, and 4) reducing susceptibility to reward\noveroptimization. Overall, our method provides an effective and efficient\napproach to LLM red teaming, accelerating real-world deployment.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by the 39th Annual AAAI Conference on Artificial\n  Intelligence (AAAI-25)",
    "pdf_url": "http://arxiv.org/pdf/2405.19026v2",
    "published_date": "2024-05-29 12:12:09 UTC",
    "updated_date": "2024-12-20 07:37:32 UTC"
  },
  {
    "arxiv_id": "2405.19024v3",
    "title": "Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory",
    "authors": [
      "Mustafa Mert Çelikok",
      "Frans A. Oliehoek",
      "Jan-Willem van de Meent"
    ],
    "abstract": "We consider inverse reinforcement learning problems with concave utilities.\nConcave Utility Reinforcement Learning (CURL) is a generalisation of the\nstandard RL objective, which employs a concave function of the state occupancy\nmeasure, rather than a linear function. CURL has garnered recent attention for\nits ability to represent instances of many important applications including the\nstandard RL such as imitation learning, pure exploration, constrained MDPs,\noffline RL, human-regularized RL, and others. Inverse reinforcement learning is\na powerful paradigm that focuses on recovering an unknown reward function that\ncan rationalize the observed behaviour of an agent. There has been recent\ntheoretical advances in inverse RL where the problem is formulated as\nidentifying the set of feasible reward functions. However, inverse RL for CURL\nproblems has not been considered previously. In this paper we show that most of\nthe standard IRL results do not apply to CURL in general, since CURL\ninvalidates the classical Bellman equations. This calls for a new theoretical\nframework for the inverse CURL problem. Using a recent equivalence result\nbetween CURL and Mean-field Games, we propose a new definition for the feasible\nrewards for I-CURL by proving that this problem is equivalent to an inverse\ngame theory problem in a subclass of mean-field games. We outline future\ndirections and applications in human--AI collaboration enabled by our results.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT",
      "cs.MA"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19024v3",
    "published_date": "2024-05-29 12:07:17 UTC",
    "updated_date": "2024-08-01 22:45:45 UTC"
  },
  {
    "arxiv_id": "2405.19012v1",
    "title": "Implicit Neural Image Field for Biological Microscopy Image Compression",
    "authors": [
      "Gaole Dai",
      "Cheng-Ching Tseng",
      "Qingpo Wuwu",
      "Rongyu Zhang",
      "Shaokang Wang",
      "Ming Lu",
      "Tiejun Huang",
      "Yu Zhou",
      "Ali Ata Tuz",
      "Matthias Gunzer",
      "Jianxu Chen",
      "Shanghang Zhang"
    ],
    "abstract": "The rapid pace of innovation in biological microscopy imaging has led to\nlarge images, putting pressure on data storage and impeding efficient sharing,\nmanagement, and visualization. This necessitates the development of efficient\ncompression solutions. Traditional CODEC methods struggle to adapt to the\ndiverse bioimaging data and often suffer from sub-optimal compression. In this\nstudy, we propose an adaptive compression workflow based on Implicit Neural\nRepresentation (INR). This approach permits application-specific compression\nobjectives, capable of compressing images of any shape and arbitrary pixel-wise\ndecompression. We demonstrated on a wide range of microscopy images from real\napplications that our workflow not only achieved high, controllable compression\nratios (e.g., 512x) but also preserved detailed information critical for\ndownstream analysis.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.19012v1",
    "published_date": "2024-05-29 11:51:33 UTC",
    "updated_date": "2024-05-29 11:51:33 UTC"
  },
  {
    "arxiv_id": "2405.19010v1",
    "title": "Evaluating the External and Parametric Knowledge Fusion of Large Language Models",
    "authors": [
      "Hao Zhang",
      "Yuyang Zhang",
      "Xiaoguang Li",
      "Wenxuan Shi",
      "Haonan Xu",
      "Huanshuo Liu",
      "Yasheng Wang",
      "Lifeng Shang",
      "Qun Liu",
      "Yong Liu",
      "Ruiming Tang"
    ],
    "abstract": "Integrating external knowledge into large language models (LLMs) presents a\npromising solution to overcome the limitations imposed by their antiquated and\nstatic parametric memory. Prior studies, however, have tended to over-reliance\non external knowledge, underestimating the valuable contributions of an LLMs'\nintrinsic parametric knowledge. The efficacy of LLMs in blending external and\nparametric knowledge remains largely unexplored, especially in cases where\nexternal knowledge is incomplete and necessitates supplementation by their\nparametric knowledge. We propose to deconstruct knowledge fusion into four\ndistinct scenarios, offering the first thorough investigation of LLM behavior\nacross each. We develop a systematic pipeline for data construction and\nknowledge infusion to simulate these fusion scenarios, facilitating a series of\ncontrolled experiments. Our investigation reveals that enhancing parametric\nknowledge within LLMs can significantly bolster their capability for knowledge\nintegration. Nonetheless, we identify persistent challenges in memorizing and\neliciting parametric knowledge, and determining parametric knowledge\nboundaries. Our findings aim to steer future explorations on harmonizing\nexternal and parametric knowledge within LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "15 pages, 3 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.19010v1",
    "published_date": "2024-05-29 11:48:27 UTC",
    "updated_date": "2024-05-29 11:48:27 UTC"
  },
  {
    "arxiv_id": "2405.18999v2",
    "title": "Continuously Optimizing Radar Placement with Model Predictive Path Integrals",
    "authors": [
      "Michael Potter",
      "Shuo Tang",
      "Paul Ghanem",
      "Milica Stojanovic",
      "Pau Closas",
      "Murat Akcakaya",
      "Ben Wright",
      "Marius Necsoiu",
      "Deniz Erdogmus",
      "Michael Everett",
      "Tales Imbiriba"
    ],
    "abstract": "Continuously optimizing sensor placement is essential for precise target\nlocalization in various military and civilian applications. While information\ntheory has shown promise in optimizing sensor placement, many studies\noversimplify sensor measurement models or neglect dynamic constraints of mobile\nsensors. To address these challenges, we employ a range measurement model that\nincorporates radar parameters and radar-target distance, coupled with Model\nPredictive Path Integral (MPPI) control to manage complex environmental\nobstacles and dynamic constraints. We compare the proposed approach against\nstationary radars or simplified range measurement models based on the root mean\nsquared error (RMSE) of the Cubature Kalman Filter (CKF) estimator for the\ntargets' state. Additionally, we visualize the evolving geometry of radars and\ntargets over time, highlighting areas of highest measurement information gain,\ndemonstrating the strengths of the approach. The proposed strategy outperforms\nstationary radars and simplified range measurement models in target\nlocalization, achieving a 38-74% reduction in mean RMSE and a 33-79% reduction\nin the upper tail of the 90% Highest Density Interval (HDI) over 500 Monte Carl\n(MC) trials across all time steps.\n  Code will be made publicly available upon acceptance.",
    "categories": [
      "stat.AP",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "stat.AP",
    "comment": "Submitted to IEEE Aerospace and Electronic Systems",
    "pdf_url": "http://arxiv.org/pdf/2405.18999v2",
    "published_date": "2024-05-29 11:25:53 UTC",
    "updated_date": "2024-05-30 01:44:38 UTC"
  },
  {
    "arxiv_id": "2405.18984v1",
    "title": "Optimizing Vehicular Networks with Variational Quantum Circuits-based Reinforcement Learning",
    "authors": [
      "Zijiang Yan",
      "Ramsundar Tanikella",
      "Hina Tabassum"
    ],
    "abstract": "In vehicular networks (VNets), ensuring both road safety and dependable\nnetwork connectivity is of utmost importance. Achieving this necessitates the\ncreation of resilient and efficient decision-making policies that prioritize\nmultiple objectives. In this paper, we develop a Variational Quantum Circuit\n(VQC)-based multi-objective reinforcement learning (MORL) framework to\ncharacterize efficient network selection and autonomous driving policies in a\nvehicular network (VNet). Numerical results showcase notable enhancements in\nboth convergence rates and rewards when compared to conventional deep-Q\nnetworks (DQNs), validating the efficacy of the VQC-MORL solution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted By INFOCOM 2024 Poster - 2024 IEEE International Conference\n  on Computer Communications",
    "pdf_url": "http://arxiv.org/pdf/2405.18984v1",
    "published_date": "2024-05-29 10:57:25 UTC",
    "updated_date": "2024-05-29 10:57:25 UTC"
  },
  {
    "arxiv_id": "2405.18968v1",
    "title": "UniIF: Unified Molecule Inverse Folding",
    "authors": [
      "Zhangyang Gao",
      "Jue Wang",
      "Cheng Tan",
      "Lirong Wu",
      "Yufei Huang",
      "Siyuan Li",
      "Zhirui Ye",
      "Stan Z. Li"
    ],
    "abstract": "Molecule inverse folding has been a long-standing challenge in chemistry and\nbiology, with the potential to revolutionize drug discovery and material\nscience. Despite specified models have been proposed for different small- or\nmacro-molecules, few have attempted to unify the learning process, resulting in\nredundant efforts. Complementary to recent advancements in molecular structure\nprediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified\nmodel UniIF for the inverse folding of all molecules. We do such unification in\ntwo levels: 1) Data-Level: We propose a unified block graph data form for all\nmolecules, including the local frame building and geometric feature\ninitialization. 2) Model-Level: We introduce a geometric block attention\nnetwork, comprising a geometric interaction, interactive attention and virtual\nlong-term dependency modules, to capture the 3D interactions of all molecules.\nThrough comprehensive evaluations across various tasks such as protein design,\nRNA design, and material design, we demonstrate that our proposed method\nsurpasses state-of-the-art methods on all tasks. UniIF offers a versatile and\neffective solution for general molecule inverse folding.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18968v1",
    "published_date": "2024-05-29 10:26:16 UTC",
    "updated_date": "2024-05-29 10:26:16 UTC"
  },
  {
    "arxiv_id": "2406.02579v1",
    "title": "An Open-Source Framework for Efficient Numerically-Tailored Computations",
    "authors": [
      "Louis Ledoux",
      "Marc Casas"
    ],
    "abstract": "We present a versatile open-source framework designed to facilitate\nefficient, numerically-tailored Matrix-Matrix Multiplications (MMMs). The\nframework offers two primary contributions: first, a fine-tuned, automated\npipeline for arithmetic datapath generation, enabling highly customizable\nsystolic MMM kernels; second, seamless integration of the generated kernels\ninto user code, irrespective of the programming language employed, without\nnecessitating modifications.\n  The framework demonstrates a systematic enhancement in accuracy per energy\ncost across diverse High Performance Computing (HPC) workloads displaying a\nvariety of numerical requirements, such as Artificial Intelligence (AI)\ninference and Sea Surface Height (SSH) computation. For AI inference, we\nconsider a set of state-of-the-art neural network models, namely ResNet18,\nResNet34, ResNet50, DenseNet121, DenseNet161, DenseNet169, and VGG11, in\nconjunction with two datasets, two computer formats, and 27 distinct\nintermediate arithmetic datapaths. Our approach consistently reduces energy\nconsumption across all cases, with a notable example being the reduction by\nfactors of $3.3\\times$ for IEEE754-32 and $1.4\\times$ for Bfloat16 during\nImageNet inference with ResNet50. This is accomplished while maintaining\naccuracies of $82.3\\%$ and $86\\%$, comparable to those achieved with\nconventional Floating-Point Units (FPUs). In the context of SSH computation,\nour method achieves fully-reproducible results using double-precision words,\nsurpassing the accuracy of conventional double- and quad-precision arithmetic\nin FPUs. Our approach enhances SSH computation accuracy by a minimum of\n$5\\times$ and $27\\times$ compared to IEEE754-64 and IEEE754-128, respectively,\nresulting in $5.6\\times$ and $15.1\\times$ improvements in accuracy per power\ncost.",
    "categories": [
      "cs.MS",
      "cs.AI",
      "cs.AR",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "cs.MS",
    "comment": "6 pages, open-source",
    "pdf_url": "http://arxiv.org/pdf/2406.02579v1",
    "published_date": "2024-05-29 10:10:53 UTC",
    "updated_date": "2024-05-29 10:10:53 UTC"
  },
  {
    "arxiv_id": "2405.18952v2",
    "title": "Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets",
    "authors": [
      "Peter Devine"
    ],
    "abstract": "Training Large Language Models (LLMs) with Reinforcement Learning from AI\nFeedback (RLAIF) aligns model outputs more closely with human preferences. This\ninvolves an evaluator model ranking multiple candidate responses to user\nprompts. However, the rankings from popular evaluator models such as GPT-4 can\nbe inconsistent. We propose the Repeat Ranking method - where we evaluate the\nsame responses multiple times and train only on those responses which are\nconsistently ranked. Using 2,714 prompts in 62 languages, we generated\nresponses from 7 top multilingual LLMs and had GPT-4 rank them five times each.\nEvaluating on MT-Bench chat benchmarks in six languages, our method\noutperformed the standard practice of training on all available prompts. Our\nwork highlights the quality versus quantity trade-off in RLAIF dataset\ngeneration and offers a stackable strategy for enhancing dataset and thus model\nquality.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18952v2",
    "published_date": "2024-05-29 10:08:31 UTC",
    "updated_date": "2024-06-01 02:18:06 UTC"
  },
  {
    "arxiv_id": "2405.18942v3",
    "title": "Verifiably Robust Conformal Prediction",
    "authors": [
      "Linus Jeary",
      "Tom Kuipers",
      "Mehran Hosseini",
      "Nicola Paoletti"
    ],
    "abstract": "Conformal Prediction (CP) is a popular uncertainty quantification method that\nprovides distribution-free, statistically valid prediction sets, assuming that\ntraining and test data are exchangeable. In such a case, CP's prediction sets\nare guaranteed to cover the (unknown) true test output with a user-specified\nprobability. Nevertheless, this guarantee is violated when the data is\nsubjected to adversarial attacks, which often result in a significant loss of\ncoverage. Recently, several approaches have been put forward to recover CP\nguarantees in this setting. These approaches leverage variations of randomised\nsmoothing to produce conservative sets which account for the effect of the\nadversarial perturbations. They are, however, limited in that they only support\n$\\ell^2$-bounded perturbations and classification tasks. This paper introduces\nVRCP (Verifiably Robust Conformal Prediction), a new framework that leverages\nrecent neural network verification methods to recover coverage guarantees under\nadversarial attacks. Our VRCP method is the first to support perturbations\nbounded by arbitrary norms including $\\ell^1$, $\\ell^2$, and $\\ell^\\infty$, as\nwell as regression tasks. We evaluate and compare our approach on image\nclassification tasks (CIFAR10, CIFAR100, and TinyImageNet) and regression tasks\nfor deep reinforcement learning environments. In every case, VRCP achieves\nabove nominal coverage and yields significantly more efficient and informative\nprediction regions than the SotA.",
    "categories": [
      "cs.LO",
      "cs.AI",
      "cs.LG",
      "68T37 (Primary) 68T27 (Secondary)",
      "G.3; I.2.4; F.4.1"
    ],
    "primary_category": "cs.LO",
    "comment": "Accepted at NeurIPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18942v3",
    "published_date": "2024-05-29 09:50:43 UTC",
    "updated_date": "2024-11-16 17:51:33 UTC"
  },
  {
    "arxiv_id": "2405.18931v1",
    "title": "EntProp: High Entropy Propagation for Improving Accuracy and Robustness",
    "authors": [
      "Shohei Enomoto"
    ],
    "abstract": "Deep neural networks (DNNs) struggle to generalize to out-of-distribution\ndomains that are different from those in training despite their impressive\nperformance. In practical applications, it is important for DNNs to have both\nhigh standard accuracy and robustness against out-of-distribution domains. One\ntechnique that achieves both of these improvements is disentangled learning\nwith mixture distribution via auxiliary batch normalization layers (ABNs). This\ntechnique treats clean and transformed samples as different domains, allowing a\nDNN to learn better features from mixed domains. However, if we distinguish the\ndomains of the samples based on entropy, we find that some transformed samples\nare drawn from the same domain as clean samples, and these samples are not\ncompletely different domains. To generate samples drawn from a completely\ndifferent domain than clean samples, we hypothesize that transforming clean\nhigh-entropy samples to further increase the entropy generates\nout-of-distribution samples that are much further away from the in-distribution\ndomain. On the basis of the hypothesis, we propose high entropy\npropagation~(EntProp), which feeds high-entropy samples to the network that\nuses ABNs. We introduce two techniques, data augmentation and free adversarial\ntraining, that increase entropy and bring the sample further away from the\nin-distribution domain. These techniques do not require additional training\ncosts. Our experimental results show that EntProp achieves higher standard\naccuracy and robustness with a lower training cost than the baseline methods.\nIn particular, EntProp is highly effective at training on small datasets.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted to UAI2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18931v1",
    "published_date": "2024-05-29 09:36:20 UTC",
    "updated_date": "2024-05-29 09:36:20 UTC"
  },
  {
    "arxiv_id": "2405.18929v2",
    "title": "Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled Data",
    "authors": [
      "Hiroshi Takahashi",
      "Tomoharu Iwata",
      "Atsutoshi Kumagai",
      "Yuuki Yamanaka"
    ],
    "abstract": "Semi-supervised anomaly detection, which aims to improve the anomaly\ndetection performance by using a small amount of labeled anomaly data in\naddition to unlabeled data, has attracted attention. Existing semi-supervised\napproaches assume that most unlabeled data are normal, and train anomaly\ndetectors by minimizing the anomaly scores for the unlabeled data while\nmaximizing those for the labeled anomaly data. However, in practice, the\nunlabeled data are often contaminated with anomalies. This weakens the effect\nof maximizing the anomaly scores for anomalies, and prevents us from improving\nthe detection performance. To solve this problem, we propose the deep\npositive-unlabeled anomaly detection framework, which integrates\npositive-unlabeled learning with deep anomaly detection models such as\nautoencoders and deep support vector data descriptions. Our approach enables\nthe approximation of anomaly scores for normal data using the unlabeled data\nand the labeled anomaly data. Therefore, without labeled normal data, our\napproach can train anomaly detectors by minimizing the anomaly scores for\nnormal data while maximizing those for the labeled anomaly data. Experiments on\nvarious datasets show that our approach achieves better detection performance\nthan existing approaches.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Under revirew. Code is available at\n  https://github.com/takahashihiroshi/pusvdd",
    "pdf_url": "http://arxiv.org/pdf/2405.18929v2",
    "published_date": "2024-05-29 09:34:47 UTC",
    "updated_date": "2025-02-08 10:03:37 UTC"
  },
  {
    "arxiv_id": "2405.18917v2",
    "title": "Causal Action Influence Aware Counterfactual Data Augmentation",
    "authors": [
      "Núria Armengol Urpí",
      "Marco Bagatella",
      "Marin Vlastelica",
      "Georg Martius"
    ],
    "abstract": "Offline data are both valuable and practical resources for teaching robots\ncomplex behaviors. Ideally, learning agents should not be constrained by the\nscarcity of available demonstrations, but rather generalize beyond the training\ndistribution. However, the complexity of real-world scenarios typically\nrequires huge amounts of data to prevent neural network policies from picking\nup on spurious correlations and learning non-causal relationships. We propose\nCAIAC, a data augmentation method that can create feasible synthetic\ntransitions from a fixed dataset without having access to online environment\ninteractions. By utilizing principled methods for quantifying causal influence,\nwe are able to perform counterfactual reasoning by swapping\n$\\it{action}$-unaffected parts of the state-space between independent\ntrajectories in the dataset. We empirically show that this leads to a\nsubstantial increase in robustness of offline learning algorithms against\ndistributional shift.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in 41st International Conference on Machine Learning (ICML\n  2024)",
    "pdf_url": "http://arxiv.org/pdf/2405.18917v2",
    "published_date": "2024-05-29 09:19:50 UTC",
    "updated_date": "2024-12-12 10:39:06 UTC"
  },
  {
    "arxiv_id": "2405.18915v2",
    "title": "Towards Better Chain-of-Thought: A Reflection on Effectiveness and Faithfulness",
    "authors": [
      "Jiachun Li",
      "Pengfei Cao",
      "Yubo Chen",
      "Jiexin Xu",
      "Huaijun Li",
      "Xiaojian Jiang",
      "Kang Liu",
      "Jun Zhao"
    ],
    "abstract": "Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "18 pages, under review",
    "pdf_url": "http://arxiv.org/pdf/2405.18915v2",
    "published_date": "2024-05-29 09:17:46 UTC",
    "updated_date": "2025-03-03 13:25:36 UTC"
  },
  {
    "arxiv_id": "2405.18910v1",
    "title": "Predicting Parking Availability in Singapore with Cross-Domain Data: A New Dataset and A Data-Driven Approach",
    "authors": [
      "Huaiwu Zhang",
      "Yutong Xia",
      "Siru Zhong",
      "Kun Wang",
      "Zekun Tong",
      "Qingsong Wen",
      "Roger Zimmermann",
      "Yuxuan Liang"
    ],
    "abstract": "The increasing number of vehicles highlights the need for efficient parking\nspace management. Predicting real-time Parking Availability (PA) can help\nmitigate traffic congestion and the corresponding social problems, which is a\npressing issue in densely populated cities like Singapore. In this study, we\naim to collectively predict future PA across Singapore with complex factors\nfrom various domains. The contributions in this paper are listed as follows:\n(1) A New Dataset: We introduce the \\texttt{SINPA} dataset, containing a year's\nworth of PA data from 1,687 parking lots in Singapore, enriched with various\nspatial and temporal factors. (2) A Data-Driven Approach: We present DeepPA, a\nnovel deep-learning framework, to collectively and efficiently predict future\nPA across thousands of parking lots. (3) Extensive Experiments and Deployment:\nDeepPA demonstrates a 9.2% reduction in prediction error for up to 3-hour\nforecasts compared to existing advanced models. Furthermore, we implement\nDeepPA in a practical web-based platform to provide real-time PA predictions to\naid drivers and inform urban planning for the governors in Singapore. We\nrelease the dataset and source code at https://github.com/yoshall/SINPA.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IJCAI 2024 (Multi-Year Track On AI And Social Good with\n  ~20% acceptance rate)",
    "pdf_url": "http://arxiv.org/pdf/2405.18910v1",
    "published_date": "2024-05-29 09:11:51 UTC",
    "updated_date": "2024-05-29 09:11:51 UTC"
  },
  {
    "arxiv_id": "2406.16899v2",
    "title": "Prompting or Fine-tuning? Exploring Large Language Models for Causal Graph Validation",
    "authors": [
      "Yuni Susanti",
      "Nina Holsmoelle"
    ],
    "abstract": "This study explores the capability of Large Language Models (LLMs) to\nevaluate causality in causal graphs generated by conventional statistical\ncausal discovery methods-a task traditionally reliant on manual assessment by\nhuman subject matter experts. To bridge this gap in causality assessment, LLMs\nare employed to evaluate the causal relationships by determining whether a\ncausal connection between variable pairs can be inferred from textual context.\nOur study compares two approaches: (1) prompting-based method for zero-shot and\nfew-shot causal inference and, (2) fine-tuning language models for the causal\nrelation prediction task. While prompt-based LLMs have demonstrated versatility\nacross various NLP tasks, our experiments on biomedical and general-domain\ndatasets show that fine-tuned models consistently outperform them, achieving up\nto a 20.5-point improvement in F1 score-even when using smaller-parameter\nlanguage models. These findings provide valuable insights into the strengths\nand limitations of both approaches for causal graph evaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.16899v2",
    "published_date": "2024-05-29 09:06:18 UTC",
    "updated_date": "2025-04-09 04:44:48 UTC"
  },
  {
    "arxiv_id": "2405.18902v2",
    "title": "A Causal Framework for Evaluating Deferring Systems",
    "authors": [
      "Filippo Palomba",
      "Andrea Pugnana",
      "José Manuel Alvarez",
      "Salvatore Ruggieri"
    ],
    "abstract": "Deferring systems extend supervised Machine Learning (ML) models with the\npossibility to defer predictions to human experts. However, evaluating the\nimpact of a deferring strategy on system accuracy is still an overlooked area.\nThis paper fills this gap by evaluating deferring systems through a causal\nlens. We link the potential outcomes framework for causal inference with\ndeferring systems, which allows to identify the causal impact of the deferring\nstrategy on predictive accuracy. We distinguish two scenarios. In the first\none, we have access to both the human and ML model predictions for the deferred\ninstances. Here, we can identify the individual causal effects for deferred\ninstances and the aggregates of them. In the second one, only human predictions\nare available for the deferred instances. Here, we can resort to regression\ndiscontinuity designs to estimate a local causal effect. We evaluate our\napproach on synthetic and real datasets for seven deferring systems from the\nliterature.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.18902v2",
    "published_date": "2024-05-29 09:03:44 UTC",
    "updated_date": "2025-04-07 08:54:30 UTC"
  },
  {
    "arxiv_id": "2405.18894v1",
    "title": "Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural Networks Using One Bayesian Test Vector",
    "authors": [
      "Soyed Tuhin Ahmed",
      "Mehdi Tahoori"
    ],
    "abstract": "The performance of deep learning algorithms such as neural networks (NNs) has\nincreased tremendously recently, and they can achieve state-of-the-art\nperformance in many domains. However, due to memory and computation resource\nconstraints, implementing NNs on edge devices is a challenging task. Therefore,\nhardware accelerators such as computation-in-memory (CIM) with memristive\ndevices have been developed to accelerate the most common operations, i.e.,\nmatrix-vector multiplication. However, due to inherent device properties,\nexternal environmental factors such as temperature, and an immature fabrication\nprocess, memristors suffer from various non-idealities, including defects and\nvariations occurring during manufacturing and runtime. Consequently, there is a\nlack of complete confidence in the predictions made by the model. To improve\nconfidence in NN predictions made by hardware accelerators in the presence of\ndevice non-idealities, in this paper, we propose a Bayesian test vector\ngeneration framework that can estimate the model uncertainty of NNs implemented\non memristor-based CIM hardware. Compared to the conventional point estimate\ntest vector generation method, our method is more generalizable across\ndifferent model dimensions and requires storing only one test Bayesian vector\nin the hardware. Our method is evaluated on different model dimensions, tasks,\nfault rates, and variation noise to show that it can consistently achieve\n$100\\%$ coverage with only $0.024$ MB of memory overhead.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18894v1",
    "published_date": "2024-05-29 08:53:16 UTC",
    "updated_date": "2024-05-29 08:53:16 UTC"
  },
  {
    "arxiv_id": "2405.18889v1",
    "title": "On Perception of Prevalence of Cheating and Usage of Generative AI",
    "authors": [
      "Roman Denkin"
    ],
    "abstract": "This report investigates the perceptions of teaching staff on the prevalence\nof student cheating and the impact of Generative AI on academic integrity. Data\nwas collected via an anonymous survey of teachers at the Department of\nInformation Technology at Uppsala University and analyzed alongside\ninstitutional statistics on cheating investigations from 2004 to 2023. The\nresults indicate that while teachers generally do not view cheating as highly\nprevalent, there is a strong belief that its incidence is increasing,\npotentially due to the accessibility of Generative AI. Most teachers do not\nequate AI usage with cheating but acknowledge its widespread use among\nstudents. Furthermore, teachers' perceptions align with objective data on\ncheating trends, highlighting their awareness of the evolving landscape of\nacademic dishonesty.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18889v1",
    "published_date": "2024-05-29 08:46:00 UTC",
    "updated_date": "2024-05-29 08:46:00 UTC"
  },
  {
    "arxiv_id": "2405.18886v2",
    "title": "Compressing Large Language Models using Low Rank and Low Precision Decomposition",
    "authors": [
      "Rajarshi Saha",
      "Naomi Sagan",
      "Varun Srivastava",
      "Andrea J. Goldsmith",
      "Mert Pilanci"
    ],
    "abstract": "The prohibitive sizes of Large Language Models (LLMs) today make it difficult\nto deploy them on memory-constrained edge devices. This work introduces $\\rm\nCALDERA$ -- a new post-training LLM compression algorithm that harnesses the\ninherent low-rank structure of a weight matrix $\\mathbf{W}$ by approximating it\nvia a low-rank, low-precision decomposition as $\\mathbf{W} \\approx \\mathbf{Q} +\n\\mathbf{L}\\mathbf{R}$. Here, $\\mathbf{L}$ and $\\mathbf{R}$ are low rank\nfactors, and the entries of $\\mathbf{Q}$, $\\mathbf{L}$ and $\\mathbf{R}$ are\nquantized. The model is compressed by substituting each layer with its\n$\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ decomposition, and the zero-shot\nperformance of the compressed model is evaluated. Additionally, $\\mathbf{L}$\nand $\\mathbf{R}$ are readily amenable to low-rank adaptation, consequently\nenhancing the zero-shot performance. $\\rm CALDERA$ obtains this decomposition\nby formulating it as an optimization problem\n$\\min_{\\mathbf{Q},\\mathbf{L},\\mathbf{R}}\\lVert(\\mathbf{Q} +\n\\mathbf{L}\\mathbf{R} - \\mathbf{W})\\mathbf{X}^\\top\\rVert_{\\rm F}^2$, where\n$\\mathbf{X}$ is the calibration data, and $\\mathbf{Q}, \\mathbf{L}, \\mathbf{R}$\nare constrained to be representable using low-precision formats. Theoretical\nupper bounds on the approximation error of $\\rm CALDERA$ are established using\na rank-constrained regression framework, and the tradeoff between compression\nratio and model performance is studied by analyzing the impact of target rank\nand quantization bit budget. Results illustrate that compressing LlaMa-$2$\n$7$B/$13B$/$70$B and LlaMa-$3$ $8$B models using $\\rm CALDERA$ outperforms\nexisting post-training LLM compression techniques in the regime of less than\n$2.5$ bits per parameter. The implementation is available at:\nhttps://github.com/pilancilab/caldera.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to The 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024). [31 pages, 10 figures, 9 tables]",
    "pdf_url": "http://arxiv.org/pdf/2405.18886v2",
    "published_date": "2024-05-29 08:42:30 UTC",
    "updated_date": "2024-11-03 20:25:29 UTC"
  },
  {
    "arxiv_id": "2405.18881v3",
    "title": "Inference-Time Alignment of Diffusion Models with Direct Noise Optimization",
    "authors": [
      "Zhiwei Tang",
      "Jiangweizhi Peng",
      "Jiasheng Tang",
      "Mingyi Hong",
      "Fan Wang",
      "Tsung-Hui Chang"
    ],
    "abstract": "In this work, we focus on the alignment problem of diffusion models with a\ncontinuous reward function, which represents specific objectives for downstream\ntasks, such as increasing darkness or improving the aesthetics of images. The\ncentral goal of the alignment problem is to adjust the distribution learned by\ndiffusion models such that the generated samples maximize the target reward\nfunction. We propose a novel alignment approach, named Direct Noise\nOptimization (DNO), that optimizes the injected noise during the sampling\nprocess of diffusion models. By design, DNO operates at inference-time, and\nthus is tuning-free and prompt-agnostic, with the alignment occurring in an\nonline fashion during generation. We rigorously study the theoretical\nproperties of DNO and also propose variants to deal with non-differentiable\nreward functions. Furthermore, we identify that naive implementation of DNO\noccasionally suffers from the out-of-distribution reward hacking problem, where\noptimized samples have high rewards but are no longer in the support of the\npretrained distribution. To remedy this issue, we leverage classical\nhigh-dimensional statistics theory to an effective probability regularization\ntechnique. We conduct extensive experiments on several important reward\nfunctions and demonstrate that the proposed DNO approach can achieve\nstate-of-the-art reward scores within a reasonable time budget for generation.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18881v3",
    "published_date": "2024-05-29 08:39:39 UTC",
    "updated_date": "2024-10-02 05:22:07 UTC"
  },
  {
    "arxiv_id": "2405.18877v2",
    "title": "Continuous Product Graph Neural Networks",
    "authors": [
      "Aref Einizade",
      "Fragkiskos D. Malliaros",
      "Jhony H. Giraldo"
    ],
    "abstract": "Processing multidomain data defined on multiple graphs holds significant\npotential in various practical applications in computer science. However,\ncurrent methods are mostly limited to discrete graph filtering operations.\nTensorial partial differential equations on graphs (TPDEGs) provide a\nprincipled framework for modeling structured data across multiple interacting\ngraphs, addressing the limitations of the existing discrete methodologies. In\nthis paper, we introduce Continuous Product Graph Neural Networks (CITRUS) that\nemerge as a natural solution to the TPDEG. CITRUS leverages the separability of\ncontinuous heat kernels from Cartesian graph products to efficiently implement\ngraph spectral decomposition. We conduct thorough theoretical analyses of the\nstability and over-smoothing properties of CITRUS in response to\ndomain-specific graph perturbations and graph spectra effects on the\nperformance. We evaluate CITRUS on well-known traffic and weather\nspatiotemporal forecasting datasets, demonstrating superior performance over\nexisting approaches. The implementation codes are available at\nhttps://github.com/ArefEinizade2/CITRUS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18877v2",
    "published_date": "2024-05-29 08:36:09 UTC",
    "updated_date": "2024-10-30 15:25:38 UTC"
  },
  {
    "arxiv_id": "2405.18875v1",
    "title": "Counterfactual Metarules for Local and Global Recourse",
    "authors": [
      "Tom Bewley",
      "Salim I. Amoukou",
      "Saumitra Mishra",
      "Daniele Magazzeni",
      "Manuela Veloso"
    ],
    "abstract": "We introduce T-CREx, a novel model-agnostic method for local and global\ncounterfactual explanation (CE), which summarises recourse options for both\nindividuals and groups in the form of human-readable rules. It leverages\ntree-based surrogate models to learn the counterfactual rules, alongside\n'metarules' denoting their regions of optimality, providing both a global\nanalysis of model behaviour and diverse recourse options for users. Experiments\nindicate that T-CREx achieves superior aggregate performance over existing\nrule-based baselines on a range of CE desiderata, while being orders of\nmagnitude faster to run.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18875v1",
    "published_date": "2024-05-29 08:35:17 UTC",
    "updated_date": "2024-05-29 08:35:17 UTC"
  },
  {
    "arxiv_id": "2405.18870v2",
    "title": "LLMs achieve adult human performance on higher-order theory of mind tasks",
    "authors": [
      "Winnie Street",
      "John Oliver Siy",
      "Geoff Keeling",
      "Adrien Baranes",
      "Benjamin Barnett",
      "Michael McKibben",
      "Tatenda Kanyere",
      "Alison Lentz",
      "Blaise Aguera y Arcas",
      "Robin I. M. Dunbar"
    ],
    "abstract": "This paper examines the extent to which large language models (LLMs) have\ndeveloped higher-order theory of mind (ToM); the human ability to reason about\nmultiple mental and emotional states in a recursive manner (e.g. I think that\nyou believe that she knows). This paper builds on prior work by introducing a\nhandwritten test suite -- Multi-Order Theory of Mind Q&A -- and using it to\ncompare the performance of five LLMs to a newly gathered adult human benchmark.\nWe find that GPT-4 and Flan-PaLM reach adult-level and near adult-level\nperformance on ToM tasks overall, and that GPT-4 exceeds adult performance on\n6th order inferences. Our results suggest that there is an interplay between\nmodel size and finetuning for the realisation of ToM abilities, and that the\nbest-performing LLMs have developed a generalised capacity for ToM. Given the\nrole that higher-order ToM plays in a wide range of cooperative and competitive\nhuman behaviours, these findings have significant implications for user-facing\nLLM applications.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC",
      "I.2.7; H.1.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18870v2",
    "published_date": "2024-05-29 08:31:16 UTC",
    "updated_date": "2024-05-31 12:45:50 UTC"
  },
  {
    "arxiv_id": "2405.18867v1",
    "title": "Topological Perspectives on Optimal Multimodal Embedding Spaces",
    "authors": [
      "Abdul Aziz A. B",
      "A. B Abdul Rahim"
    ],
    "abstract": "Recent strides in multimodal model development have ignited a paradigm shift\nin the realm of text-to-image generation. Among these advancements, CLIP stands\nout as a remarkable achievement which is a sophisticated autoencoder adept at\nencoding both textual and visual information within a unified latent space.\nThis paper delves into a comparative analysis between CLIP and its recent\ncounterpart, CLOOB. To unravel the intricate distinctions within the embedding\nspaces crafted by these models, we employ topological data analysis. Our\napproach encompasses a comprehensive examination of the modality gap drivers,\nthe clustering structures existing across both high and low dimensions, and the\npivotal role that dimension collapse plays in shaping their respective\nembedding spaces. Empirical experiments substantiate the implications of our\nanalyses on downstream performance across various contextual scenarios. Through\nthis investigation, we aim to shed light on the nuanced intricacies that\nunderlie the comparative efficacy of CLIP and CLOOB, offering insights into\ntheir respective strengths and weaknesses, and providing a foundation for\nfurther refinement and advancement in multimodal model research.",
    "categories": [
      "cs.AI",
      "68T05"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 17 figures, 2 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.18867v1",
    "published_date": "2024-05-29 08:28:23 UTC",
    "updated_date": "2024-05-29 08:28:23 UTC"
  },
  {
    "arxiv_id": "2405.18852v1",
    "title": "LetsMap: Unsupervised Representation Learning for Semantic BEV Mapping",
    "authors": [
      "Nikhil Gosala",
      "Kürsat Petek",
      "B Ravi Kiran",
      "Senthil Yogamani",
      "Paulo Drews-Jr",
      "Wolfram Burgard",
      "Abhinav Valada"
    ],
    "abstract": "Semantic Bird's Eye View (BEV) maps offer a rich representation with strong\nocclusion reasoning for various decision making tasks in autonomous driving.\nHowever, most BEV mapping approaches employ a fully supervised learning\nparadigm that relies on large amounts of human-annotated BEV ground truth data.\nIn this work, we address this limitation by proposing the first unsupervised\nrepresentation learning approach to generate semantic BEV maps from a monocular\nfrontal view (FV) image in a label-efficient manner. Our approach pretrains the\nnetwork to independently reason about scene geometry and scene semantics using\ntwo disjoint neural pathways in an unsupervised manner and then finetunes it\nfor the task of semantic BEV mapping using only a small fraction of labels in\nthe BEV. We achieve label-free pretraining by exploiting spatial and temporal\nconsistency of FV images to learn scene geometry while relying on a novel\ntemporal masked autoencoder formulation to encode the scene representation.\nExtensive evaluations on the KITTI-360 and nuScenes datasets demonstrate that\nour approach performs on par with the existing state-of-the-art approaches\nwhile using only 1% of BEV labels and no additional labeled data.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.CV",
    "comment": "23 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18852v1",
    "published_date": "2024-05-29 08:03:36 UTC",
    "updated_date": "2024-05-29 08:03:36 UTC"
  },
  {
    "arxiv_id": "2405.18848v2",
    "title": "Anomaly Detection by Context Contrasting",
    "authors": [
      "Alain Ryser",
      "Thomas M. Sutter",
      "Alexander Marx",
      "Julia E. Vogt"
    ],
    "abstract": "Anomaly detection focuses on identifying samples that deviate from the norm.\nWhen working with high-dimensional data such as images, a crucial requirement\nfor detecting anomalous patterns is learning lower-dimensional representations\nthat capture concepts of normality. Recent advances in self-supervised learning\nhave shown great promise in this regard. However, many successful\nself-supervised anomaly detection methods assume prior knowledge about\nanomalies to create synthetic outliers during training. Yet, in real-world\napplications, we often do not know what to expect from unseen data, and we can\nsolely leverage knowledge about normal data. In this work, we propose Con$_2$,\nwhich learns representations through context augmentations that allow us to\nobserve samples from two distinct perspectives while keeping the invariances of\nnormal data. Con$_2$ learns rich representations of context-augmented samples\nby clustering them according to their context while simultaneously aligning\ntheir positions across clusters. At test time, representations of anomalies\nthat do not adhere to the invariances of normal data then deviate from their\nrespective context cluster. Learning representations in such a way thus allows\nus to detect anomalies without making assumptions about anomalous data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18848v2",
    "published_date": "2024-05-29 07:59:06 UTC",
    "updated_date": "2024-10-14 08:48:34 UTC"
  },
  {
    "arxiv_id": "2405.18845v1",
    "title": "Simulation, Modelling and Classification of Wiki Contributors: Spotting The Good, The Bad, and The Ugly",
    "authors": [
      "Silvia García Méndez",
      "Fátima Leal",
      "Benedita Malheiro",
      "Juan Carlos Burguillo Rial",
      "Bruno Veloso",
      "Adriana E. Chis",
      "Horacio González Vélez"
    ],
    "abstract": "Data crowdsourcing is a data acquisition process where groups of voluntary\ncontributors feed platforms with highly relevant data ranging from news,\ncomments, and media to knowledge and classifications. It typically processes\nuser-generated data streams to provide and refine popular services such as\nwikis, collaborative maps, e-commerce sites, and social networks. Nevertheless,\nthis modus operandi raises severe concerns regarding ill-intentioned data\nmanipulation in adversarial environments. This paper presents a simulation,\nmodelling, and classification approach to automatically identify human and\nnon-human (bots) as well as benign and malign contributors by using data\nfabrication to balance classes within experimental data sets, data stream\nmodelling to build and update contributor profiles and, finally, autonomic data\nstream classification. By employing WikiVoyage - a free worldwide wiki travel\nguide open to contribution from the general public - as a testbed, our approach\nproves to significantly boost the confidence and quality of the classifier by\nusing a class-balanced data stream, comprising both real and synthetic data.\nOur empirical results show that the proposed method distinguishes between\nbenign and malign bots as well as human contributors with a classification\naccuracy of up to 92 %.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18845v1",
    "published_date": "2024-05-29 07:56:08 UTC",
    "updated_date": "2024-05-29 07:56:08 UTC"
  },
  {
    "arxiv_id": "2405.18843v2",
    "title": "Data-driven Machinery Fault Diagnosis: A Comprehensive Review",
    "authors": [
      "Dhiraj Neupane",
      "Mohamed Reda Bouadjenek",
      "Richard Dazeley",
      "Sunil Aryal"
    ],
    "abstract": "In this era of advanced manufacturing, it's now more crucial than ever to\ndiagnose machine faults as early as possible to guarantee their safe and\nefficient operation. With the massive surge in industrial big data and\nadvancement in sensing and computational technologies, data-driven Machinery\nFault Diagnosis (MFD) solutions based on machine/deep learning approaches have\nbeen used ubiquitously in manufacturing. Timely and accurately identifying\nfaulty machine signals is vital in industrial applications for which many\nrelevant solutions have been proposed and are reviewed in many articles.\nDespite the availability of numerous solutions and reviews on MFD, existing\nworks often lack several aspects. Most of the available literature has limited\napplicability in a wide range of manufacturing settings due to their\nconcentration on a particular type of equipment or method of analysis.\nAdditionally, discussions regarding the challenges associated with implementing\ndata-driven approaches, such as dealing with noisy data, selecting appropriate\nfeatures, and adapting models to accommodate new or unforeseen faults, are\noften superficial or completely overlooked. Thus, this survey provides a\ncomprehensive review of the articles using different types of machine learning\napproaches for the detection and diagnosis of various types of machinery\nfaults, highlights their strengths and limitations, provides a review of the\nmethods used for condition-based analyses, comprehensively discusses the\navailable machinery fault datasets, introduces future researchers to the\npossible challenges they have to encounter while using these approaches for MFD\nand recommends the probable solutions to mitigate those problems. The future\nresearch prospects are also pointed out for a better understanding of the\nfield. We believe this article will help researchers and contribute to the\nfurther development of the field.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in Neurocomputing",
    "pdf_url": "http://arxiv.org/pdf/2405.18843v2",
    "published_date": "2024-05-29 07:50:47 UTC",
    "updated_date": "2025-02-24 02:35:21 UTC"
  },
  {
    "arxiv_id": "2405.18832v1",
    "title": "MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models",
    "authors": [
      "Taehyun Kim",
      "Kwanseok Choi",
      "Youngmock Cho",
      "Jaehoon Cho",
      "Hyuk-Jae Lee",
      "Jaewoong Sim"
    ],
    "abstract": "Mixture-of-Experts (MoE) large language models (LLM) have memory requirements\nthat often exceed the GPU memory capacity, requiring costly parameter movement\nfrom secondary memories to the GPU for expert computation. In this work, we\npresent Mixture of Near-Data Experts (MoNDE), a near-data computing solution\nthat efficiently enables MoE LLM inference. MoNDE reduces the volume of MoE\nparameter movement by transferring only the $\\textit{hot}$ experts to the GPU,\nwhile computing the remaining $\\textit{cold}$ experts inside the host memory\ndevice. By replacing the transfers of massive expert parameters with the ones\nof small activations, MoNDE enables far more communication-efficient MoE\ninference, thereby resulting in substantial speedups over the existing\nparameter offloading frameworks for both encoder and decoder operations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to DAC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18832v1",
    "published_date": "2024-05-29 07:23:29 UTC",
    "updated_date": "2024-05-29 07:23:29 UTC"
  },
  {
    "arxiv_id": "2405.18823v1",
    "title": "Why Reinforcement Learning in Energy Systems Needs Explanations",
    "authors": [
      "Hallah Shahid Butt",
      "Benjamin Schäfer"
    ],
    "abstract": "With economic development, the complexity of infrastructure has increased\ndrastically. Similarly, with the shift from fossil fuels to renewable sources\nof energy, there is a dire need for such systems that not only predict and\nforecast with accuracy but also help in understanding the process of\npredictions. Artificial intelligence and machine learning techniques have\nhelped in finding out wellperforming solutions to different problems in the\nenergy sector. However, the usage of state-of-the-art techniques like\nreinforcement learning is not surprisingly convincing. This paper discusses the\napplication of reinforcement techniques in energy systems and how explanations\nof these models can be helpful",
    "categories": [
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18823v1",
    "published_date": "2024-05-29 07:09:00 UTC",
    "updated_date": "2024-05-29 07:09:00 UTC"
  },
  {
    "arxiv_id": "2405.18820v1",
    "title": "Diffeomorphic interpolation for efficient persistence-based topological optimization",
    "authors": [
      "Mathieu Carriere",
      "Marc Theveneau",
      "Théo Lacombe"
    ],
    "abstract": "Topological Data Analysis (TDA) provides a pipeline to extract quantitative\ntopological descriptors from structured objects. This enables the definition of\ntopological loss functions, which assert to what extent a given object exhibits\nsome topological properties. These losses can then be used to perform\ntopological optimizationvia gradient descent routines. While theoretically\nsounded, topological optimization faces an important challenge: gradients tend\nto be extremely sparse, in the sense that the loss function typically depends\non only very few coordinates of the input object, yielding dramatically slow\noptimization schemes in practice.Focusing on the central case of topological\noptimization for point clouds, we propose in this work to overcome this\nlimitation using diffeomorphic interpolation, turning sparse gradients into\nsmooth vector fields defined on the whole space, with quantifiable Lipschitz\nconstants. In particular, we show that our approach combines efficiently with\nsubsampling techniques routinely used in TDA, as the diffeomorphism derived\nfrom the gradient computed on a subsample can be used to update the coordinates\nof the full input object, allowing us to perform topological optimization on\npoint clouds at an unprecedented scale. Finally, we also showcase the relevance\nof our approach for black-box autoencoder (AE) regularization, where we aim at\nenforcing topological priors on the latent spaces associated to fixed,\npre-trained, black-box AE models, and where we show thatlearning a\ndiffeomorphic flow can be done once and then re-applied to new data in linear\ntime (while vanilla topological optimization has to be re-run from scratch).\nMoreover, reverting the flow allows us to generate data by sampling the\ntopologically-optimized latent space directly, yielding better interpretability\nof the model.",
    "categories": [
      "cs.AI",
      "cs.CG",
      "math.OC"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18820v1",
    "published_date": "2024-05-29 07:00:28 UTC",
    "updated_date": "2024-05-29 07:00:28 UTC"
  },
  {
    "arxiv_id": "2405.18810v1",
    "title": "UniPTS: A Unified Framework for Proficient Post-Training Sparsity",
    "authors": [
      "Jingjing Xie",
      "Yuxin Zhang",
      "Mingbao Lin",
      "Zhihang Lin",
      "Liujuan Cao",
      "Rongrong Ji"
    ],
    "abstract": "Post-training Sparsity (PTS) is a recently emerged avenue that chases\nefficient network sparsity with limited data in need. Existing PTS methods,\nhowever, undergo significant performance degradation compared with traditional\nmethods that retrain the sparse networks via the whole dataset, especially at\nhigh sparsity ratios. In this paper, we attempt to reconcile this disparity by\ntransposing three cardinal factors that profoundly alter the performance of\nconventional sparsity into the context of PTS. Our endeavors particularly\ncomprise (1) A base-decayed sparsity objective that promotes efficient\nknowledge transferring from dense network to the sparse counterpart. (2) A\nreducing-regrowing search algorithm designed to ascertain the optimal sparsity\ndistribution while circumventing overfitting to the small calibration set in\nPTS. (3) The employment of dynamic sparse training predicated on the preceding\naspects, aimed at comprehensively optimizing the sparsity structure while\nensuring training stability. Our proposed framework, termed UniPTS, is\nvalidated to be much superior to existing PTS methods across extensive\nbenchmarks. As an illustration, it amplifies the performance of POT, a recently\nproposed recipe, from 3.9% to 68.6% when pruning ResNet-50 at 90% sparsity\nratio on ImageNet. We release the code of our paper at\nhttps://github.com/xjjxmu/UniPTS.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18810v1",
    "published_date": "2024-05-29 06:53:18 UTC",
    "updated_date": "2024-05-29 06:53:18 UTC"
  },
  {
    "arxiv_id": "2405.18802v2",
    "title": "Enhancing Security and Privacy in Federated Learning using Low-Dimensional Update Representation and Proximity-Based Defense",
    "authors": [
      "Wenjie Li",
      "Kai Fan",
      "Jingyuan Zhang",
      "Hui Li",
      "Wei Yang Bryan Lim",
      "Qiang Yang"
    ],
    "abstract": "Federated Learning (FL) is a promising privacy-preserving machine learning\nparadigm that allows data owners to collaboratively train models while keeping\ntheir data localized. Despite its potential, FL faces challenges related to the\ntrustworthiness of both clients and servers, particularly against curious or\nmalicious adversaries. In this paper, we introduce a novel framework named\n\\underline{F}ederated \\underline{L}earning with Low-Dimensional\n\\underline{U}pdate \\underline{R}epresentation and \\underline{P}roximity-Based\ndefense (FLURP), designed to address privacy preservation and resistance to\nByzantine attacks in distributed learning environments. FLURP employs\n$\\mathsf{LinfSample}$ method, enabling clients to compute the $l_{\\infty}$ norm\nacross sliding windows of updates, resulting in a Low-Dimensional Update\nRepresentation (LUR). Calculating the shared distance matrix among LURs, rather\nthan updates, significantly reduces the overhead of Secure Multi-Party\nComputation (SMPC) by three orders of magnitude while effectively\ndistinguishing between benign and poisoned updates. Additionally, FLURP\nintegrates a privacy-preserving proximity-based defense mechanism utilizing\noptimized SMPC protocols to minimize communication rounds. Our experiments\ndemonstrate FLURP's effectiveness in countering Byzantine adversaries with low\ncommunication and runtime overhead. FLURP offers a scalable framework for\nsecure and reliable FL in distributed environments, facilitating its\napplication in scenarios requiring robust data management and security.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.18802v2",
    "published_date": "2024-05-29 06:46:10 UTC",
    "updated_date": "2025-02-11 06:00:39 UTC"
  },
  {
    "arxiv_id": "2405.18792v1",
    "title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies",
    "authors": [
      "Haanvid Lee",
      "Tri Wahyu Guntara",
      "Jongmin Lee",
      "Yung-Kyun Noh",
      "Kee-Eung Kim"
    ],
    "abstract": "We consider off-policy evaluation (OPE) of deterministic target policies for\nreinforcement learning (RL) in environments with continuous action spaces.\nWhile it is common to use importance sampling for OPE, it suffers from high\nvariance when the behavior policy deviates significantly from the target\npolicy. In order to address this issue, some recent works on OPE proposed\nin-sample learning with importance resampling. Yet, these approaches are not\napplicable to deterministic target policies for continuous action spaces. To\naddress this limitation, we propose to relax the deterministic target policy\nusing a kernel and learn the kernel metrics that minimize the overall mean\nsquared error of the estimated temporal difference update vector of an action\nvalue function, where the action value function is used for policy evaluation.\nWe derive the bias and variance of the estimation error due to this relaxation\nand provide analytic solutions for the optimal kernel metric. In empirical\nstudies using various test domains, we show that the OPE with in-sample\nlearning using the kernel with optimized metric achieves significantly improved\naccuracy than other baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "23 pages, 2 figures, Accepted at ICLR 2024 (spotlight)",
    "pdf_url": "http://arxiv.org/pdf/2405.18792v1",
    "published_date": "2024-05-29 06:17:33 UTC",
    "updated_date": "2024-05-29 06:17:33 UTC"
  },
  {
    "arxiv_id": "2405.18780v3",
    "title": "Certifying Counterfactual Bias in LLMs",
    "authors": [
      "Isha Chaudhary",
      "Qian Hu",
      "Manoj Kumar",
      "Morteza Ziyadi",
      "Rahul Gupta",
      "Gagandeep Singh"
    ],
    "abstract": "Large Language Models (LLMs) can produce biased responses that can cause\nrepresentational harms. However, conventional studies are insufficient to\nthoroughly evaluate biases across LLM responses for different demographic\ngroups (a.k.a. counterfactual bias), as they do not scale to large number of\ninputs and do not provide guarantees. Therefore, we propose the first\nframework, LLMCert-B that certifies LLMs for counterfactual bias on\ndistributions of prompts. A certificate consists of high-confidence bounds on\nthe probability of unbiased LLM responses for any set of counterfactual prompts\n- prompts differing by demographic groups, sampled from a distribution. We\nillustrate counterfactual bias certification for distributions of\ncounterfactual prompts created by applying prefixes sampled from prefix\ndistributions, to a given set of prompts. We consider prefix distributions\nconsisting random token sequences, mixtures of manual jailbreaks, and\nperturbations of jailbreaks in LLM's embedding space. We generate non-trivial\ncertificates for SOTA LLMs, exposing their vulnerabilities over distributions\nof prompts generated from computationally inexpensive prefix distributions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Published at ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2405.18780v3",
    "published_date": "2024-05-29 05:39:37 UTC",
    "updated_date": "2025-04-21 23:20:28 UTC"
  },
  {
    "arxiv_id": "2405.18770v2",
    "title": "Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships",
    "authors": [
      "Futa Waseda",
      "Antonio Tejero-de-Pablos",
      "Isao Echizen"
    ],
    "abstract": "Pre-trained vision-language (VL) models are highly vulnerable to adversarial\nattacks. However, existing defense methods primarily focus on image\nclassification, overlooking two key aspects of VL tasks: multimodal attacks,\nwhere both image and text can be perturbed, and the one-to-many relationship of\nimages and texts, where a single image can correspond to multiple textual\ndescriptions and vice versa (1:N and N:1). This work is the first to explore\ndefense strategies against multimodal attacks in VL tasks, whereas prior VL\ndefense methods focus on vision robustness. We propose multimodal adversarial\ntraining (MAT), which incorporates adversarial perturbations in both image and\ntext modalities during training, significantly outperforming existing unimodal\ndefenses. Furthermore, we discover that MAT is limited by deterministic\none-to-one (1:1) image-text pairs in VL training data. To address this, we\nconduct a comprehensive study on leveraging one-to-many relationships to\nenhance robustness, investigating diverse augmentation techniques. Our analysis\nshows that, for a more effective defense, augmented image-text pairs should be\nwell-aligned, diverse, yet avoid distribution shift -- conditions overlooked by\nprior research. Our experiments show that MAT can effectively be applied to\ndifferent VL models and tasks to improve adversarial robustness, outperforming\nprevious efforts. Our code will be made public upon acceptance.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CV",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2405.18770v2",
    "published_date": "2024-05-29 05:20:02 UTC",
    "updated_date": "2025-03-18 14:32:07 UTC"
  },
  {
    "arxiv_id": "2405.18762v2",
    "title": "Inpaint Biases: A Pathway to Accurate and Unbiased Image Generation",
    "authors": [
      "Jiyoon Myung",
      "Jihyeon Park"
    ],
    "abstract": "This paper examines the limitations of advanced text-to-image models in\naccurately rendering unconventional concepts which are scarcely represented or\nabsent in their training datasets. We identify how these limitations not only\nconfine the creative potential of these models but also pose risks of\nreinforcing stereotypes. To address these challenges, we introduce the Inpaint\nBiases framework, which employs user-defined masks and inpainting techniques to\nenhance the accuracy of image generation, particularly for novel or\ninaccurately rendered objects. Through experimental validation, we demonstrate\nhow this framework significantly improves the fidelity of generated images to\nthe user's intent, thereby expanding the models' creative capabilities and\nmitigating the risk of perpetuating biases. Our study contributes to the\nadvancement of text-to-image models as unbiased, versatile tools for creative\nexpression.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Paper accepted in CVPRW 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18762v2",
    "published_date": "2024-05-29 05:04:07 UTC",
    "updated_date": "2024-05-30 10:58:56 UTC"
  },
  {
    "arxiv_id": "2405.18758v1",
    "title": "Learning to Continually Learn with the Bayesian Principle",
    "authors": [
      "Soochan Lee",
      "Hyeonseong Jeon",
      "Jaehyeon Son",
      "Gunhee Kim"
    ],
    "abstract": "In the present era of deep learning, continual learning research is mainly\nfocused on mitigating forgetting when training a neural network with stochastic\ngradient descent on a non-stationary stream of data. On the other hand, in the\nmore classical literature of statistical machine learning, many models have\nsequential Bayesian update rules that yield the same learning outcome as the\nbatch training, i.e., they are completely immune to catastrophic forgetting.\nHowever, they are often overly simple to model complex real-world data. In this\nwork, we adopt the meta-learning paradigm to combine the strong\nrepresentational power of neural networks and simple statistical models'\nrobustness to forgetting. In our novel meta-continual learning framework,\ncontinual learning takes place only in statistical models via ideal sequential\nBayesian update rules, while neural networks are meta-learned to bridge the raw\ndata and the statistical models. Since the neural networks remain fixed during\ncontinual learning, they are protected from catastrophic forgetting. This\napproach not only achieves significantly improved performance but also exhibits\nexcellent scalability. Since our approach is domain-agnostic and\nmodel-agnostic, it can be applied to a wide range of problems and easily\nintegrated with existing model architectures.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18758v1",
    "published_date": "2024-05-29 04:53:31 UTC",
    "updated_date": "2024-05-29 04:53:31 UTC"
  },
  {
    "arxiv_id": "2405.18756v1",
    "title": "Provable Contrastive Continual Learning",
    "authors": [
      "Yichen Wen",
      "Zhiquan Tan",
      "Kaipeng Zheng",
      "Chuanlong Xie",
      "Weiran Huang"
    ],
    "abstract": "Continual learning requires learning incremental tasks with dynamic data\ndistributions. So far, it has been observed that employing a combination of\ncontrastive loss and distillation loss for training in continual learning\nyields strong performance. To the best of our knowledge, however, this\ncontrastive continual learning framework lacks convincing theoretical\nexplanations. In this work, we fill this gap by establishing theoretical\nperformance guarantees, which reveal how the performance of the model is\nbounded by training losses of previous tasks in the contrastive continual\nlearning framework. Our theoretical explanations further support the idea that\npre-training can benefit continual learning. Inspired by our theoretical\nanalysis of these guarantees, we propose a novel contrastive continual learning\nalgorithm called CILA, which uses adaptive distillation coefficients for\ndifferent tasks. These distillation coefficients are easily computed by the\nratio between average distillation losses and average contrastive losses from\nprevious tasks. Our method shows great improvement on standard benchmarks and\nachieves new state-of-the-art performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "stat.AP",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18756v1",
    "published_date": "2024-05-29 04:48:11 UTC",
    "updated_date": "2024-05-29 04:48:11 UTC"
  },
  {
    "arxiv_id": "2405.18753v2",
    "title": "Confronting the Reproducibility Crisis: A Case Study of Challenges in Cybersecurity AI",
    "authors": [
      "Richard H. Moulton",
      "Gary A. McCully",
      "John D. Hastings"
    ],
    "abstract": "In the rapidly evolving field of cybersecurity, ensuring the reproducibility\nof AI-driven research is critical to maintaining the reliability and integrity\nof security systems. This paper addresses the reproducibility crisis within the\ndomain of adversarial robustness -- a key area in AI-based cybersecurity that\nfocuses on defending deep neural networks against malicious perturbations.\nThrough a detailed case study, we attempt to validate results from prior work\non certified robustness using the VeriGauge toolkit, revealing significant\nchallenges due to software and hardware incompatibilities, version conflicts,\nand obsolescence. Our findings underscore the urgent need for standardized\nmethodologies, containerization, and comprehensive documentation to ensure the\nreproducibility of AI models deployed in critical cybersecurity applications.\nBy tackling these reproducibility challenges, we aim to contribute to the\nbroader discourse on securing AI systems against advanced persistent threats,\nenhancing network and IoT security, and protecting critical infrastructure.\nThis work advocates for a concerted effort within the research community to\nprioritize reproducibility, thereby strengthening the foundation upon which\nfuture cybersecurity advancements are built.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "I.2.0; D.4.6; K.6.5; I.5.1"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, 0 figures, 2 tables, updated to incorporate feedback and\n  improvements",
    "pdf_url": "http://arxiv.org/pdf/2405.18753v2",
    "published_date": "2024-05-29 04:37:19 UTC",
    "updated_date": "2024-08-16 03:29:18 UTC"
  },
  {
    "arxiv_id": "2405.18751v2",
    "title": "On the Limits of Multi-modal Meta-Learning with Auxiliary Task Modulation Using Conditional Batch Normalization",
    "authors": [
      "Jordi Armengol-Estapé",
      "Vincent Michalski",
      "Ramnath Kumar",
      "Pierre-Luc St-Charles",
      "Doina Precup",
      "Samira Ebrahimi Kahou"
    ],
    "abstract": "Few-shot learning aims to learn representations that can tackle novel tasks\ngiven a small number of examples. Recent studies show that cross-modal learning\ncan improve representations for few-shot classification. More specifically,\nlanguage is a rich modality that can be used to guide visual learning. In this\nwork, we experiment with a multi-modal architecture for few-shot learning that\nconsists of three components: a classifier, an auxiliary network, and a bridge\nnetwork. While the classifier performs the main classification task, the\nauxiliary network learns to predict language representations from the same\ninput, and the bridge network transforms high-level features of the auxiliary\nnetwork into modulation parameters for layers of the few-shot classifier using\nconditional batch normalization. The bridge should encourage a form of\nlightweight semantic alignment between language and vision which could be\nuseful for the classifier. However, after evaluating the proposed approach on\ntwo popular few-shot classification benchmarks we find that a) the improvements\ndo not reproduce across benchmarks, and b) when they do, the improvements are\ndue to the additional compute and parameters introduced by the bridge network.\nWe contribute insights and recommendations for future work in multi-modal\nmeta-learning, especially when using language representations.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18751v2",
    "published_date": "2024-05-29 04:29:12 UTC",
    "updated_date": "2024-05-30 14:13:05 UTC"
  },
  {
    "arxiv_id": "2405.18742v1",
    "title": "Musical Phrase Segmentation via Grammatical Induction",
    "authors": [
      "Reed Perkins",
      "Dan Ventura"
    ],
    "abstract": "We outline a solution to the challenge of musical phrase segmentation that\nuses grammatical induction algorithms, a class of algorithms which infer a\ncontext-free grammar from an input sequence. We analyze the performance of five\ngrammatical induction algorithms on three datasets using various musical\nviewpoint combinations. Our experiments show that the LONGESTFIRST algorithm\nachieves the best F1 scores across all three datasets and that input encodings\nthat include the duration viewpoint result in the best performance.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of a paper appearing in the proceedings of IJCAI\n  2024 that includes additional material in an appendix. Please cite the IJCAI\n  version",
    "pdf_url": "http://arxiv.org/pdf/2405.18742v1",
    "published_date": "2024-05-29 04:04:36 UTC",
    "updated_date": "2024-05-29 04:04:36 UTC"
  },
  {
    "arxiv_id": "2405.18741v2",
    "title": "Genshin: General Shield for Natural Language Processing with Large Language Models",
    "authors": [
      "Xiao Peng",
      "Tao Liu",
      "Ying Wang"
    ],
    "abstract": "Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been\ntrending recently, demonstrating considerable advancement and generalizability\npower in countless domains. However, LLMs create an even bigger black box\nexacerbating opacity, with interpretability limited to few approaches. The\nuncertainty and opacity embedded in LLMs' nature restrict their application in\nhigh-stakes domains like financial fraud, phishing, etc. Current approaches\nmainly rely on traditional textual classification with posterior interpretable\nalgorithms, suffering from attackers who may create versatile adversarial\nsamples to break the system's defense, forcing users to make trade-offs between\nefficiency and robustness. To address this issue, we propose a novel cascading\nframework called Genshin (General Shield for Natural Language Processing with\nLarge Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike\nmost applications of LLMs that try to transform text into something new or\nstructural, Genshin uses LLMs to recover text to its original state. Genshin\naims to combine the generalizability of the LLM, the discrimination of the\nmedian model, and the interpretability of the simple model. Our experiments on\nthe task of sentimental analysis and spam detection have shown fatal flaws of\nthe current median models and exhilarating results on LLMs' recovery ability,\ndemonstrating that Genshin is both effective and efficient. In our ablation\nstudy, we unearth several intriguing observations. Utilizing the LLM defender,\na tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal\nmask rate results in the 3rd paradigm of NLP. Additionally, when employing the\nLLM as a potential adversarial tool, attackers are capable of executing\neffective attacks that are nearly semantically lossless.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18741v2",
    "published_date": "2024-05-29 04:04:05 UTC",
    "updated_date": "2024-06-03 08:35:07 UTC"
  },
  {
    "arxiv_id": "2405.18733v1",
    "title": "Efficient Learning in Chinese Checkers: Comparing Parameter Sharing in Multi-Agent Reinforcement Learning",
    "authors": [
      "Noah Adhikari",
      "Allen Gu"
    ],
    "abstract": "We show that multi-agent reinforcement learning (MARL) with full parameter\nsharing outperforms independent and partially shared architectures in the\ncompetitive perfect-information homogenous game of Chinese Checkers. To run our\nexperiments, we develop a new MARL environment: variable-size, six-player\nChinese Checkers. This custom environment was developed in PettingZoo and\nsupports all traditional rules of the game including chaining jumps. This is,\nto the best of our knowledge, the first implementation of Chinese Checkers that\nremains faithful to the true game.\n  Chinese Checkers is difficult to learn due to its large branching factor and\npotentially infinite horizons. We borrow the concept of branching actions\n(submoves) from complex action spaces in other RL domains, where a submove may\nnot end a player's turn immediately. This drastically reduces the\ndimensionality of the action space. Our observation space is inspired by\nAlphaGo with many binary game boards stacked in a 3D array to encode\ninformation.\n  The PettingZoo environment, training and evaluation logic, and analysis\nscripts can be found on\n\\href{https://github.com/noahadhikari/pettingzoo-chinese-checkers}{Github}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18733v1",
    "published_date": "2024-05-29 03:27:30 UTC",
    "updated_date": "2024-05-29 03:27:30 UTC"
  },
  {
    "arxiv_id": "2405.18732v3",
    "title": "Gemini & Physical World: Large Language Models Can Estimate the Intensity of Earthquake Shaking from Multi-Modal Social Media Posts",
    "authors": [
      "S. Mostafa Mousavi",
      "Marc Stogaitis",
      "Tajinder Gadh",
      "Richard M Allen",
      "Alexei Barski",
      "Robert Bosch",
      "Patrick Robertson",
      "Nivetha Thiruverahan",
      "Youngmin Cho",
      "Aman Raj"
    ],
    "abstract": "This paper presents a novel approach to extract scientifically valuable\ninformation about Earth's physical phenomena from unconventional sources, such\nas multi-modal social media posts. Employing a state-of-the-art large language\nmodel (LLM), Gemini 1.5 Pro (Reid et al. 2024), we estimate earthquake ground\nshaking intensity from these unstructured posts. The model's output, in the\nform of Modified Mercalli Intensity (MMI) values, aligns well with independent\nobservational data. Furthermore, our results suggest that LLMs, trained on vast\ninternet data, may have developed a unique understanding of physical phenomena.\nSpecifically, Google's Gemini models demonstrate a simplified understanding of\nthe general relationship between earthquake magnitude, distance, and MMI\nintensity, accurately describing observational data even though it's not\nidentical to established models. These findings raise intriguing questions\nabout the extent to which Gemini's training has led to a broader understanding\nof the physical world and its phenomena. The ability of Generative AI models\nlike Gemini to generate results consistent with established scientific\nknowledge highlights their potential to augment our understanding of complex\nphysical phenomena like earthquakes. The flexible and effective approach\nproposed in this study holds immense potential for enriching our understanding\nof the impact of physical phenomena and improving resilience during natural\ndisasters. This research is a significant step toward harnessing the power of\nsocial media and AI for natural disaster mitigation, opening new avenues for\nunderstanding the emerging capabilities of Generative AI and LLMs for\nscientific applications.",
    "categories": [
      "physics.geo-ph",
      "cs.AI",
      "cs.LG",
      "physics.app-ph"
    ],
    "primary_category": "physics.geo-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18732v3",
    "published_date": "2024-05-29 03:23:34 UTC",
    "updated_date": "2024-06-14 17:12:17 UTC"
  },
  {
    "arxiv_id": "2405.18731v4",
    "title": "VBIM-Net: Variational Born Iterative Network for Inverse Scattering Problems",
    "authors": [
      "Ziqing Xing",
      "Zhaoyang Zhang",
      "Zirui Chen",
      "Yusong Wang",
      "Haoran Ma",
      "Zhun Wei"
    ],
    "abstract": "Recently, studies have shown the potential of integrating field-type\niterative methods with deep learning (DL) techniques in solving inverse\nscattering problems (ISPs). In this article, we propose a novel Variational\nBorn Iterative Network, namely, VBIM-Net, to solve the full-wave ISPs with\nsignificantly improved structural rationality and inversion quality. The\nproposed VBIM-Net emulates the alternating updates of the total electric field\nand the contrast in the variational Born iterative method (VBIM) by multiple\nlayers of subnetworks. We embed the analytical calculation of the contrast\nvariation into each subnetwork, converting the scattered field residual into an\napproximate contrast variation and then enhancing it by a U-Net, thus avoiding\nthe requirement of matched measurement dimension and grid resolution as in\nexisting approaches. The total field and contrast of each layer's output is\nsupervised in the loss function of VBIM-Net, imposing soft physical constraints\non the variables in the subnetworks, which benefits the model's performance. In\naddition, we design a training scheme with extra noise to enhance the model's\nstability. Extensive numerical results on synthetic and experimental data both\nverify the inversion quality, generalization ability, and robustness of the\nproposed VBIM-Net. This work may provide some new inspiration for the design of\nefficient field-type DL schemes.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "physics.comp-ph"
    ],
    "primary_category": "eess.SP",
    "comment": "This article has been published in IEEE Transactions on Geoscience\n  and Remote Sensing",
    "pdf_url": "http://arxiv.org/pdf/2405.18731v4",
    "published_date": "2024-05-29 03:21:09 UTC",
    "updated_date": "2025-02-02 13:24:06 UTC"
  },
  {
    "arxiv_id": "2405.18729v1",
    "title": "Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning",
    "authors": [
      "Tianle Zhang",
      "Jiayi Guan",
      "Lin Zhao",
      "Yihang Li",
      "Dongjiang Li",
      "Zecui Zeng",
      "Lei Sun",
      "Yue Chen",
      "Xuelong Wei",
      "Lusong Li",
      "Xiaodong He"
    ],
    "abstract": "Offline reinforcement learning (RL) aims to learn optimal policies from\npreviously collected datasets. Recently, due to their powerful representational\ncapabilities, diffusion models have shown significant potential as policy\nmodels for offline RL issues. However, previous offline RL algorithms based on\ndiffusion policies generally adopt weighted regression to improve the policy.\nThis approach optimizes the policy only using the collected actions and is\nsensitive to Q-values, which limits the potential for further performance\nenhancement. To this end, we propose a novel preferred-action-optimized\ndiffusion policy for offline RL. In particular, an expressive conditional\ndiffusion model is utilized to represent the diverse distribution of a behavior\npolicy. Meanwhile, based on the diffusion model, preferred actions within the\nsame behavior distribution are automatically generated through the critic\nfunction. Moreover, an anti-noise preference optimization is designed to\nachieve policy improvement by using the preferred actions, which can adapt to\nnoise-preferred actions for stable training. Extensive experiments demonstrate\nthat the proposed method provides competitive or superior performance compared\nto previous state-of-the-art offline RL methods, particularly in sparse reward\ntasks such as Kitchen and AntMaze. Additionally, we empirically prove the\neffectiveness of anti-noise preference optimization.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18729v1",
    "published_date": "2024-05-29 03:19:59 UTC",
    "updated_date": "2024-05-29 03:19:59 UTC"
  },
  {
    "arxiv_id": "2405.18727v2",
    "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control",
    "authors": [
      "Huanshuo Liu",
      "Hao Zhang",
      "Zhijiang Guo",
      "Jing Wang",
      "Kuicai Dong",
      "Xiangyang Li",
      "Yi Quan Lee",
      "Cong Zhang",
      "Yong Liu"
    ],
    "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution for\nmitigating hallucinations of large language models (LLMs) with retrieved\nexternal knowledge. Adaptive RAG enhances this approach by enabling dynamic\nretrieval during generation, activating retrieval only when the query exceeds\nLLM's internal knowledge. Existing methods primarily focus on detecting LLM's\nconfidence via statistical uncertainty. Instead, we present the first attempts\nto solve adaptive RAG from a representation perspective and develop an inherent\ncontrol-based framework, termed \\name. Specifically, we extract the features\nthat represent the honesty and confidence directions of LLM and adopt them to\ncontrol LLM behavior and guide retrieval timing decisions. We also design a\nsimple yet effective query formulation strategy to support adaptive retrieval.\nExperiments show that \\name is superior to existing adaptive RAG methods on a\ndiverse set of tasks, the honesty steering can effectively make LLMs more\nhonest and confidence monitoring is a promising indicator of retrieval\ntrigger.Our code is available at \\url{https://github.com/HSLiu-Initial/CtrlA}.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "29 pages, 10 figures, 11 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.18727v2",
    "published_date": "2024-05-29 03:17:16 UTC",
    "updated_date": "2024-10-03 20:09:31 UTC"
  },
  {
    "arxiv_id": "2405.18724v2",
    "title": "Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction",
    "authors": [
      "Linjia Kang",
      "Songhua Zhou",
      "Shuyan Fang",
      "Shichao Liu"
    ],
    "abstract": "Accurate prediction of molecular properties is crucial in drug discovery.\nTraditional methods often overlook that real-world molecules typically exhibit\nmultiple property labels with complex correlations. To this end, we propose a\nnovel framework, HiPM, which stands for hierarchical prompted molecular\nrepresentation learning framework. HiPM leverages task-aware prompts to enhance\nthe differential expression of tasks in molecular representations and mitigate\nnegative transfer caused by conflicts in individual task information. Our\nframework comprises two core components: the Molecular Representation Encoder\n(MRE) and the Task-Aware Prompter (TAP). MRE employs a hierarchical\nmessage-passing network architecture to capture molecular features at both the\natom and motif levels. Meanwhile, TAP utilizes agglomerative hierarchical\nclustering algorithm to construct a prompt tree that reflects task affinity and\ndistinctiveness, enabling the model to consider multi-granular correlation\ninformation among tasks, thereby effectively handling the complexity of\nmulti-label property prediction. Extensive experiments demonstrate that HiPM\nachieves state-of-the-art performance across various multi-label datasets,\noffering a novel perspective on multi-label molecular representation learning.",
    "categories": [
      "q-bio.QM",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-bio.QM",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18724v2",
    "published_date": "2024-05-29 03:10:21 UTC",
    "updated_date": "2024-08-11 07:02:54 UTC"
  },
  {
    "arxiv_id": "2405.18723v3",
    "title": "Conformal Depression Prediction",
    "authors": [
      "Yonghong Li",
      "Xiuzhuang Zhou"
    ],
    "abstract": "While existing depression prediction methods based on deep learning show\npromise, their practical application is hindered by the lack of\ntrustworthiness, as these deep models are often deployed as black box models,\nleaving us uncertain on the confidence of their predictions. For high-risk\nclinical applications like depression prediction, uncertainty quantification is\nessential in decision-making. In this paper, we introduce conformal depression\nprediction (CDP), a depression prediction method with uncertainty\nquantification based on conformal prediction (CP), giving valid confidence\nintervals with theoretical coverage guarantees for the model predictions. CDP\nis a plug-and-play module that requires neither model retraining nor an\nassumption about the depression data distribution. As CDP provides only an\naverage coverage guarantee across all inputs rather than per-input performance\nguarantee, we further propose CDP-ACC, an improved conformal prediction with\napproximate conditional coverage. CDP-ACC firstly estimates the prediction\ndistribution through neighborhood relaxation, and then introduces a conformal\nscore function by constructing nested sequences, so as to provide a tighter\nprediction interval adaptive to specific input. We empirically demonstrate the\napplication of CDP in uncertainty-aware facial depression prediction, as well\nas the effectiveness and superiority of CDP-ACC on the AVEC 2013 and AVEC 2014\ndatasets. Our code is publicly available at https://github.com/PushineLee/CDP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18723v3",
    "published_date": "2024-05-29 03:08:30 UTC",
    "updated_date": "2024-08-27 07:31:44 UTC"
  },
  {
    "arxiv_id": "2405.18721v2",
    "title": "Correctable Landmark Discovery via Large Models for Vision-Language Navigation",
    "authors": [
      "Bingqian Lin",
      "Yunshuang Nie",
      "Ziming Wei",
      "Yi Zhu",
      "Hang Xu",
      "Shikui Ma",
      "Jianzhuang Liu",
      "Xiaodan Liang"
    ],
    "abstract": "Vision-Language Navigation (VLN) requires the agent to follow language\ninstructions to reach a target position. A key factor for successful navigation\nis to align the landmarks implied in the instruction with diverse visual\nobservations. However, previous VLN agents fail to perform accurate modality\nalignment especially in unexplored scenes, since they learn from limited\nnavigation data and lack sufficient open-world alignment knowledge. In this\nwork, we propose a new VLN paradigm, called COrrectable LaNdmark DiScOvery via\nLarge ModEls (CONSOLE). In CONSOLE, we cast VLN as an open-world sequential\nlandmark discovery problem, by introducing a novel correctable landmark\ndiscovery scheme based on two large models ChatGPT and CLIP. Specifically, we\nuse ChatGPT to provide rich open-world landmark cooccurrence commonsense, and\nconduct CLIP-driven landmark discovery based on these commonsense priors. To\nmitigate the noise in the priors due to the lack of visual constraints, we\nintroduce a learnable cooccurrence scoring module, which corrects the\nimportance of each cooccurrence according to actual observations for accurate\nlandmark discovery. We further design an observation enhancement strategy for\nan elegant combination of our framework with different VLN agents, where we\nutilize the corrected landmark features to obtain enhanced observation features\nfor action decision. Extensive experimental results on multiple popular VLN\nbenchmarks (R2R, REVERIE, R4R, RxR) show the significant superiority of CONSOLE\nover strong baselines. Especially, our CONSOLE establishes the new\nstate-of-the-art results on R2R and R4R in unseen scenarios. Code is available\nat https://github.com/expectorlin/CONSOLE.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by TPAMI 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.18721v2",
    "published_date": "2024-05-29 03:05:59 UTC",
    "updated_date": "2024-06-05 09:59:21 UTC"
  },
  {
    "arxiv_id": "2405.18719v2",
    "title": "Contextual Position Encoding: Learning to Count What's Important",
    "authors": [
      "Olga Golovneva",
      "Tianlu Wang",
      "Jason Weston",
      "Sainbayar Sukhbaatar"
    ],
    "abstract": "The attention mechanism is a critical component of Large Language Models\n(LLMs) that allows tokens in a sequence to interact with each other, but is\norder-invariant. Incorporating position encoding (PE) makes it possible to\naddress by position, such as attending to the i-th token. However, current PE\nmethods use token counts to derive position, and thus cannot generalize to\nhigher levels of abstraction, such as attending to the i-th sentence. In this\npaper, we propose a new position encoding method, Contextual Position Encoding\n(CoPE), that allows positions to be conditioned on context by incrementing\nposition only on certain tokens determined by the model. This allows more\ngeneral position addressing such as attending to the $i$-th particular word,\nnoun, or sentence. We show that CoPE can solve the selective copy, counting and\nFlip-Flop tasks where popular position embeddings fail, and improves perplexity\non language modeling and coding tasks.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18719v2",
    "published_date": "2024-05-29 02:57:15 UTC",
    "updated_date": "2024-05-30 17:51:53 UTC"
  },
  {
    "arxiv_id": "2405.18711v2",
    "title": "Calibrating Reasoning in Language Models with Internal Consistency",
    "authors": [
      "Zhihui Xie",
      "Jizhou Guo",
      "Tong Yu",
      "Shuai Li"
    ],
    "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nvarious reasoning tasks, aided by techniques like chain-of-thought prompting\nthat elicits verbalized reasoning. However, LLMs often generate text with\nobvious mistakes and contradictions, raising doubts about their ability to\nrobustly process and utilize generated rationales. In this work, we investigate\nreasoning in LLMs through the lens of internal representations, focusing on how\nthese representations are influenced by generated rationales. Our preliminary\nanalysis reveals that while generated rationales improve answer accuracy,\ninconsistencies emerge between the model's internal representations in middle\nlayers and those in final layers, potentially undermining the reliability of\ntheir reasoning processes. To address this, we propose internal consistency as\na measure of the model's confidence by examining the agreement of latent\npredictions decoded from intermediate layers. Extensive empirical studies\nacross different models and datasets demonstrate that internal consistency\neffectively distinguishes between correct and incorrect reasoning paths.\nMotivated by this, we propose a new approach to calibrate reasoning by\nup-weighting reasoning paths with high internal consistency, resulting in a\nsignificant boost in reasoning performance. Further analysis uncovers distinct\npatterns in attention and feed-forward modules across layers, providing\ninsights into the emergence of internal inconsistency. In summary, our results\ndemonstrate the potential of using internal representations for self-evaluation\nof LLMs. Our code is available at github.com/zhxieml/internal-consistency.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "NeurIPS 2024 camera ready",
    "pdf_url": "http://arxiv.org/pdf/2405.18711v2",
    "published_date": "2024-05-29 02:44:12 UTC",
    "updated_date": "2024-12-05 04:01:28 UTC"
  },
  {
    "arxiv_id": "2405.18710v2",
    "title": "To FP8 and Back Again: Quantifying Reduced Precision Effects on LLM Training Stability",
    "authors": [
      "Joonhyung Lee",
      "Jeongin Bae",
      "Byeongwook Kim",
      "Se Jung Kwon",
      "Dongsoo Lee"
    ],
    "abstract": "The massive computational costs associated with large language model (LLM)\npretraining have spurred great interest in reduced-precision floating-point\nrepresentations to accelerate the process. As a result, the BrainFloat16 (BF16)\nprecision has become the de facto standard for LLM training, with hardware\nsupport included in recent generations of accelerators. This trend has gone\neven further in the latest processors, where FP8 has recently been introduced.\nHowever, prior experience with FP16, which was found to be less stable than\nBF16, raises concerns as to whether FP8, with even fewer bits than FP16, can be\na cost-effective option for LLM training. We argue that reduced-precision\ntraining schemes must have similar training stability and hyperparameter\nsensitivities to their higher-precision counterparts in order to be\ncost-effective. However, we find that currently available methods for FP8\ntraining are not robust enough to allow their use as economical replacements.\nThis prompts us to investigate the stability of reduced-precision LLM training\nin terms of robustness across random seeds, learning rates, and datasets. To\nthis end, we propose new evaluation techniques and a new metric for quantifying\nloss landscape sharpness in autoregressive language models. By simulating\nincremental bit reductions in floating-point representations, we analyze the\nrelationship between representational power and training stability with the\nintent of aiding future research into the field.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18710v2",
    "published_date": "2024-05-29 02:42:23 UTC",
    "updated_date": "2025-03-25 11:11:03 UTC"
  },
  {
    "arxiv_id": "2405.18708v1",
    "title": "Cognitive Evolutionary Learning to Select Feature Interactions for Recommender Systems",
    "authors": [
      "Runlong Yu",
      "Qixiang Shao",
      "Qi Liu",
      "Huan Liu",
      "Enhong Chen"
    ],
    "abstract": "Feature interaction selection is a fundamental problem in commercial\nrecommender systems. Most approaches equally enumerate all features and\ninteractions by the same pre-defined operation under expert guidance. Their\nrecommendation is unsatisfactory sometimes due to the following issues:\n(1)~They cannot ensure the learning abilities of models because their\narchitectures are poorly adaptable to tasks and data; (2)~Useless features and\ninteractions can bring unnecessary noise and complicate the training process.\nIn this paper, we aim to adaptively evolve the model to select appropriate\noperations, features, and interactions under task guidance. Inspired by the\nevolution and functioning of natural organisms, we propose a novel\n\\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive\nability refers to a property of organisms that allows them to react and survive\nin diverse environments. It consists of three stages, i.e., DNA search, genome\nsearch, and model functioning. Specifically, if we regard the relationship\nbetween models and tasks as the relationship between organisms and natural\nenvironments, interactions of feature pairs can be analogous to double-stranded\nDNA, of which relevant features and interactions can be analogous to genomes.\nAlong this line, we diagnose the fitness of the model on operations, features,\nand interactions to simulate the survival rates of organisms for natural\nselection. We show that CELL can adaptively evolve into different models for\ndifferent tasks and data, which enables practitioners to access off-the-shelf\nmodels. Extensive experiments on four real-world datasets demonstrate that CELL\nsignificantly outperforms state-of-the-art baselines. Also, we conduct\nsynthetic experiments to ascertain that CELL can consistently discover the\npre-defined interaction patterns for feature pairs.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18708v1",
    "published_date": "2024-05-29 02:35:23 UTC",
    "updated_date": "2024-05-29 02:35:23 UTC"
  },
  {
    "arxiv_id": "2405.18707v1",
    "title": "Adaptive and Parallel Split Federated Learning in Vehicular Edge Computing",
    "authors": [
      "Xianke Qiang",
      "Zheng Chang",
      "Yun Hu",
      "Lei Liu",
      "Timo Hamalainen"
    ],
    "abstract": "Vehicular edge intelligence (VEI) is a promising paradigm for enabling future\nintelligent transportation systems by accommodating artificial intelligence\n(AI) at the vehicular edge computing (VEC) system. Federated learning (FL)\nstands as one of the fundamental technologies facilitating collaborative model\ntraining locally and aggregation, while safeguarding the privacy of vehicle\ndata in VEI. However, traditional FL faces challenges in adapting to vehicle\nheterogeneity, training large models on resource-constrained vehicles, and\nremaining susceptible to model weight privacy leakage. Meanwhile, split\nlearning (SL) is proposed as a promising collaborative learning framework which\ncan mitigate the risk of model wights leakage, and release the training\nworkload on vehicles. SL sequentially trains a model between a vehicle and an\nedge cloud (EC) by dividing the entire model into a vehicle-side model and an\nEC-side model at a given cut layer. In this work, we combine the advantages of\nSL and FL to develop an Adaptive Split Federated Learning scheme for Vehicular\nEdge Computing (ASFV). The ASFV scheme adaptively splits the model and\nparallelizes the training process, taking into account mobile vehicle selection\nand resource allocation. Our extensive simulations, conducted on\nnon-independent and identically distributed data, demonstrate that the proposed\nASFV solution significantly reduces training latency compared to existing\nbenchmarks, while adapting to network dynamics and vehicles' mobility.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18707v1",
    "published_date": "2024-05-29 02:34:38 UTC",
    "updated_date": "2024-05-29 02:34:38 UTC"
  },
  {
    "arxiv_id": "2405.18698v1",
    "title": "Spectral-Risk Safe Reinforcement Learning with Convergence Guarantees",
    "authors": [
      "Dohyeong Kim",
      "Taehyun Cho",
      "Seungyub Han",
      "Hojun Chung",
      "Kyungjae Lee",
      "Songhwai Oh"
    ],
    "abstract": "The field of risk-constrained reinforcement learning (RCRL) has been\ndeveloped to effectively reduce the likelihood of worst-case scenarios by\nexplicitly handling risk-measure-based constraints. However, the nonlinearity\nof risk measures makes it challenging to achieve convergence and optimality. To\novercome the difficulties posed by the nonlinearity, we propose a spectral risk\nmeasure-constrained RL algorithm, spectral-risk-constrained policy optimization\n(SRCPO), a bilevel optimization approach that utilizes the duality of spectral\nrisk measures. In the bilevel optimization structure, the outer problem\ninvolves optimizing dual variables derived from the risk measures, while the\ninner problem involves finding an optimal policy given these dual variables.\nThe proposed method, to the best of our knowledge, is the first to guarantee\nconvergence to an optimum in the tabular setting. Furthermore, the proposed\nmethod has been evaluated on continuous control tasks and showed the best\nperformance among other RCRL algorithms satisfying the constraints.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.18698v1",
    "published_date": "2024-05-29 02:17:25 UTC",
    "updated_date": "2024-05-29 02:17:25 UTC"
  },
  {
    "arxiv_id": "2405.18693v1",
    "title": "DeepHGNN: Study of Graph Neural Network based Forecasting Methods for Hierarchically Related Multivariate Time Series",
    "authors": [
      "Abishek Sriramulu",
      "Nicolas Fourrier",
      "Christoph Bergmeir"
    ],
    "abstract": "Graph Neural Networks (GNN) have gained significant traction in the\nforecasting domain, especially for their capacity to simultaneously account for\nintra-series temporal correlations and inter-series relationships. This paper\nintroduces a novel Hierarchical GNN (DeepHGNN) framework, explicitly designed\nfor forecasting in complex hierarchical structures. The uniqueness of DeepHGNN\nlies in its innovative graph-based hierarchical interpolation and an end-to-end\nreconciliation mechanism. This approach ensures forecast accuracy and coherence\nacross various hierarchical levels while sharing signals across them,\naddressing a key challenge in hierarchical forecasting. A critical insight in\nhierarchical time series is the variance in forecastability across levels, with\nupper levels typically presenting more predictable components. DeepHGNN\ncapitalizes on this insight by pooling and leveraging knowledge from all\nhierarchy levels, thereby enhancing the overall forecast accuracy. Our\ncomprehensive evaluation set against several state-of-the-art models confirm\nthe superior performance of DeepHGNN. This research not only demonstrates\nDeepHGNN's effectiveness in achieving significantly improved forecast accuracy\nbut also contributes to the understanding of graph-based methods in\nhierarchical time series forecasting.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18693v1",
    "published_date": "2024-05-29 02:06:17 UTC",
    "updated_date": "2024-05-29 02:06:17 UTC"
  },
  {
    "arxiv_id": "2405.18688v1",
    "title": "Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation",
    "authors": [
      "Fengshuo Bai",
      "Rui Zhao",
      "Hongming Zhang",
      "Sijia Cui",
      "Ying Wen",
      "Yaodong Yang",
      "Bo Xu",
      "Lei Han"
    ],
    "abstract": "Preference-based reinforcement learning (PbRL) has shown impressive\ncapabilities in training agents without reward engineering. However, a notable\nlimitation of PbRL is its dependency on substantial human feedback. This\ndependency stems from the learning loop, which entails accurate reward learning\ncompounded with value/policy learning, necessitating a considerable number of\nsamples. To boost the learning loop, we propose SEER, an efficient PbRL method\nthat integrates label smoothing and policy regularization techniques. Label\nsmoothing reduces overfitting of the reward model by smoothing human preference\nlabels. Additionally, we bootstrap a conservative estimate $\\widehat{Q}$ using\nwell-supported state-action pairs from the current replay memory to mitigate\noverestimation bias and utilize it for policy learning regularization. Our\nexperimental results across a variety of complex tasks, both in online and\noffline settings, demonstrate that our approach improves feedback efficiency,\noutperforming state-of-the-art methods by a large margin. Ablation studies\nfurther reveal that SEER achieves a more accurate Q-function compared to prior\nwork.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18688v1",
    "published_date": "2024-05-29 01:49:20 UTC",
    "updated_date": "2024-05-29 01:49:20 UTC"
  },
  {
    "arxiv_id": "2405.18682v2",
    "title": "Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension",
    "authors": [
      "Shubham Vatsal",
      "Ayush Singh"
    ],
    "abstract": "Large language models (LLMs) have shown remarkable performance on many tasks\nin different domains. However, their performance in closed-book biomedical\nmachine reading comprehension (MRC) has not been evaluated in depth. In this\nwork, we evaluate GPT on four closed-book biomedical MRC benchmarks. We\nexperiment with different conventional prompting techniques as well as\nintroduce our own novel prompting method. To solve some of the retrieval\nproblems inherent to LLMs, we propose a prompting strategy named Implicit\nRetrieval Augmented Generation (RAG) that alleviates the need for using vector\ndatabases to retrieve important chunks in traditional RAG setups. Moreover, we\nreport qualitative assessments on the natural language generation outputs from\nour approach. The results show that our new prompting technique is able to get\nthe best performance in two out of four datasets and ranks second in rest of\nthem. Experiments show that modern-day LLMs like GPT even in a zero-shot\nsetting can outperform supervised models, leading to new state-of-the-art\n(SoTA) results on two of the benchmarks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18682v2",
    "published_date": "2024-05-29 01:12:53 UTC",
    "updated_date": "2024-10-25 16:57:43 UTC"
  },
  {
    "arxiv_id": "2405.18681v2",
    "title": "A random-key GRASP for combinatorial optimization",
    "authors": [
      "Antonio A. Chaves",
      "Mauricio G. C. Resende",
      "Ricardo M. A. Silva"
    ],
    "abstract": "This paper proposes a problem-independent GRASP metaheuristic using the\nrandom-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search\nprocedure) is a metaheuristic for combinatorial optimization that repeatedly\napplies a semi-greedy construction procedure followed by a local search\nprocedure. The best solution found over all iterations is returned as the\nsolution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for\ncontinuous optimization in the unit hypercube. A random-key optimizer (RKO)\nuses a vector of random keys to encode a solution to a combinatorial\noptimization problem. It uses a decoder to evaluate a solution encoded by the\nvector of random keys. A random-key GRASP is a C-GRASP where points in the unit\nhypercube are evaluated employing a decoder. We describe random key GRASP\nconsisting of a problem-independent component and a problem-dependent decoder.\nAs a proof of concept, the random-key GRASP is tested on five NP-hard\ncombinatorial optimization problems: traveling salesman problem, tree of hubs\nlocation problem, Steiner triple covering problem, node capacitated graph\npartitioning problem, and job sequencing and tool switching problem.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "math.OC",
      "90-02, 90B40, 90C27",
      "G.1.6; G.2.1; I.2.8"
    ],
    "primary_category": "cs.NE",
    "comment": "24 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2405.18681v2",
    "published_date": "2024-05-29 01:07:38 UTC",
    "updated_date": "2024-05-30 13:06:27 UTC"
  },
  {
    "arxiv_id": "2405.18669v2",
    "title": "Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities",
    "authors": [
      "Vicky Zayats",
      "Peter Chen",
      "Melissa Ferrari",
      "Dirk Padfield"
    ],
    "abstract": "Integrating multiple generative foundation models, especially those trained\non different modalities, into something greater than the sum of its parts poses\nsignificant challenges. Two key hurdles are the availability of aligned data\n(concepts that contain similar meaning but is expressed differently in\ndifferent modalities), and effectively leveraging unimodal representations in\ncross-domain generative tasks, without compromising their original unimodal\ncapabilities.\n  We propose Zipper, a multi-tower decoder architecture that addresses these\nconcerns by using cross-attention to flexibly compose multimodal generative\nmodels from independently pre-trained unimodal decoders. In our experiments\nfusing speech and text modalities, we show the proposed architecture performs\nvery competitively in scenarios with limited aligned text-speech data. We also\nshowcase the flexibility of our model to selectively maintain unimodal (e.g.,\ntext-to-text generation) generation performance by freezing the corresponding\nmodal tower (e.g. text). In cross-modal tasks such as automatic speech\nrecognition (ASR) where the output modality is text, we show that freezing the\ntext backbone results in negligible performance degradation. In cross-modal\ntasks such as text-to-speech generation (TTS) where the output modality is\nspeech, we show that using a pre-trained speech backbone results in superior\nperformance to the baseline.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "eess.AS"
    ],
    "primary_category": "cs.LG",
    "comment": "Under review at NeurIPS",
    "pdf_url": "http://arxiv.org/pdf/2405.18669v2",
    "published_date": "2024-05-29 00:23:55 UTC",
    "updated_date": "2024-05-31 15:42:53 UTC"
  },
  {
    "arxiv_id": "2405.18664v2",
    "title": "Fast Explanations via Policy Gradient-Optimized Explainer",
    "authors": [
      "Deng Pan",
      "Nuno Moniz",
      "Nitesh Chawla"
    ],
    "abstract": "The challenge of delivering efficient explanations is a critical barrier that\nprevents the adoption of model explanations in real-world applications.\nExisting approaches often depend on extensive model queries for sample-level\nexplanations or rely on expert's knowledge of specific model structures that\ntrade general applicability for efficiency. To address these limitations, this\npaper introduces a novel framework Fast Explanation (FEX) that represents\nattribution-based explanations via probability distributions, which are\noptimized by leveraging the policy gradient method. The proposed framework\noffers a robust, scalable solution for real-time, large-scale model\nexplanations, bridging the gap between efficiency and applicability. We\nvalidate our framework on image and text classification tasks and the\nexperiments demonstrate that our method reduces inference time by over 97% and\nmemory usage by 70% compared to traditional model-agnostic approaches while\nmaintaining high-quality explanations and broad applicability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.18664v2",
    "published_date": "2024-05-29 00:01:40 UTC",
    "updated_date": "2025-01-27 20:01:55 UTC"
  }
]