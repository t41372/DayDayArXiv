{
  "date": "2024-05-29",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-29 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的安全性、对齐和优化、医疗应用、量子计算以及持续学习等领域，强调了 LLM 在偏见缓解和鲁棒性提升上的突破（如 Dr-LLaVA 和 STAT），以及知名学者（如 Venkat Venkatasubramanian 和 Yoav Shoham）参与的综合报告（如 Artificial Intelligence Index Report 2024），这些工作展示了 AI 在实际应用中的潜力。\n\n以下是今日论文的精选摘要，我优先选取了重要、话题度和有影响力的文章，并将相关主题归类讨论。对于其他次要论文，我会简要掠过，只列标题和核心贡献。每个摘要保留核心学术术语，并清晰描述主要贡献和发现。\n\n### LLM 对齐和安全\n- **Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding**（英文原标题：\"Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding\"）  \n  这篇论文提出了一种视觉语言模型（VLM）对齐算法，使用符号临床推理来减少幻觉（hallucinations），并生成大规模 GPT-4 指导数据。主要贡献是通过自动奖励函数提升 VLM 在多轮医疗对话中的性能，应用于骨髓病理学图像分析，显著提高了模型的临床有效性和一致性。\n\n- **Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models**（英文原标题：\"Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models\"）  \n  作者 Venkat Venkatasubramanian 等讨论了 LLM 在科学领域（如化学工程）的局限性，提出 Large Knowledge Models（LKM）框架。主要发现是 LKM 通过整合第一原理和领域知识，能更好地处理推理和规划，适用于复杂科学任务。\n\n- **Preference Learning Algorithms Do Not Learn Preference Rankings**（英文原标题：\"Preference Learning Algorithms Do Not Learn Preference Rankings\"）  \n  这篇工作揭示了偏好学习算法（如 RLHF 和 DPO）在 LLM 对齐中的不足，主要发现是这些算法在排名准确性上存在差距，并提出量化方法分析参考模型的影响，为更可靠的 LLM 偏好优化提供洞见。\n\n- **AI Risk Management Should Incorporate Both Safety and Security**（英文原标题：\"AI Risk Management Should Incorporate Both Safety and Security\"）  \n  作者包括 Yoav Shoham 等知名学者，强调 AI 风险管理需整合安全性和安全性。主要贡献是提出统一框架，分析二者间的互补关系，帮助制定更全面的风险缓解策略。\n\n- **One-Shot Safety Alignment for Large Language Models via Optimal Dualization**（英文原标题：\"One-Shot Safety Alignment for Large Language Models via Optimal Dualization\"）  \n  这篇论文简化了 LLM 的安全对齐过程，通过最优二元化方法消除 RLHF 的计算负担。主要发现是新算法 MoCAN 和 PeCAN 能在单步优化中提升模型的安全性和稳定性。\n\n其他 LLM 相关论文如 **STAT: Shrinking Transformers After Training**（英文原标题：\"STAT: Shrinking Transformers After Training\"），贡献是无微调剪枝 Transformer 模型，提升效率；这些工作快速掠过，因为它们更侧重技术细节而非新范式。\n\n### 医疗 AI 应用\n- **CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats**（英文原标题：\"CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats\"）  \n  这篇论文扩展了 CheXpert 数据集，添加了文本报告和患者人口统计信息。主要贡献是发布最大规模的放射学文本数据集，支持 AI 模型的公平性和鲁棒性提升。\n\n- **Two-Layer Retrieval-Augmented Generation Framework for Low-Resource Medical Question Answering Using Reddit Data**（英文原标题：\"Two-Layer Retrieval-Augmented Generation Framework for Low-Resource Medical Question Answering Using Reddit Data\"）  \n  作者使用 Reddit 数据构建双层检索增强框架（RAG），主要发现是该框架在低资源设置下能高效回答医疗查询，如药物相关问题，性能与 GPT-4 相当。\n\n其他医疗论文如 **Unlocking the Potential of Large Language Models for Clinical Text Anonymization**（英文原标题：\"Unlocking the Potential of Large Language Models for Clinical Text Anonymization\"），贡献是提出新指标评估 LLM 在临床文本匿名化中的可靠性；这些次要工作快速掠过。\n\n### 量子计算和图神经网络\n- **Qiskit Code Assistant: Training LLMs for generating Quantum Computing Code**（英文原标题：\"Qiskit Code Assistant: Training LLMs for generating Quantum Computing Code\"）  \n  这篇论文训练 LLM 生成量子代码，主要贡献是使用 Qiskit 库优化代码生成，并在量子编程基准上超越现有模型。\n\n- **MDS-ViTNet: Improving saliency prediction for Eye-Tracking with Vision Transformer**（英文原标题：\"MDS-ViTNet: Improving saliency prediction for Eye-Tracking with Vision Transformer\"）  \n  论文提出 Vision Transformer 网络改善眼动追踪的显著性预测，主要发现是多解码器结构提升了预测准确性，适用于营销和医学领域。\n\n其他量子或图相关论文如 **Machine Psychology: Integrating Operant Conditioning with the Non-Axiomatic Reasoning System**（英文原标题：\"Machine Psychology: Integrating Operant Conditioning with the Non-Axiomatic Reasoning System\"），贡献是整合心理学原理提升 AGI 适应性；这些文章影响力较小，故从简。\n\n### 其他重要主题\n- **Artificial Intelligence Index Report 2024**（英文原标题：\"Artificial Intelligence Index Report 2024\"）  \n  作者包括 Yoav Shoham 和 James Manyika，这份报告是年度 AI 概述，主要发现是 AI 技术进步、公众感知和地缘政治影响的详尽分析，提供可信数据支持政策制定。\n\n- **Participation in the age of foundation models**（英文原标题：\"Participation in the age of foundation models\"）  \n  这篇论文讨论基础模型时代的人类参与，主要贡献是提出多层框架（subfloor 和 surface 层），提升 AI 在医疗和金融等领域的公平性。\n\n其他论文如 **Efficient Black-box Adversarial Attacks via Bayesian Optimization**（英文原标题：\"Efficient Black-box Adversarial Attacks via Bayesian Optimization\"），贡献是优化黑盒攻击效率；或 **Learning Human-Aligned Representations with Contrastive Learning**（英文原标题：\"Learning Human-Aligned Representations with Contrastive Learning\"），发现对比学习能捕捉人类认知表示；这些工作虽有价值，但非核心，故快速掠过。\n\n总之，今天的 arXiv 论文突出了 AI 模型的可靠性和应用潜力，但也提醒我们持续关注偏见和安全问题。重点文章如 Dr-LLaVA 和 AI Index Report 值得追踪，期待它们在实际领域的落地。更多论文细节可查阅 arXiv 页面！",
  "papers": [
    {
      "arxiv_id": "2405.19575v1",
      "title": "A Deep Convolutional Neural Network-based Model for Aspect and Polarity Classification in Hausa Movie Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Umar Ibrahim",
        "Abubakar Yakubu Zandam",
        "Fatima Muhammad Adam",
        "Aminu Musa"
      ],
      "abstract": "Aspect-based Sentiment Analysis (ABSA) is crucial for understanding sentiment\nnuances in text, especially across diverse languages and cultures. This paper\nintroduces a novel Deep Convolutional Neural Network (CNN)-based model tailored\nfor aspect and polarity classification in Hausa movie reviews, an\nunderrepresented language in sentiment analysis research. A comprehensive Hausa\nABSA dataset is created, filling a significant gap in resource availability.\nThe dataset, preprocessed using sci-kit-learn for TF-IDF transformation,\nincludes manually annotated aspect-level feature ontology words and sentiment\npolarity assignments. The proposed model combines CNNs with attention\nmechanisms for aspect-word prediction, leveraging contextual information and\nsentiment polarities. With 91% accuracy on aspect term extraction and 92% on\nsentiment polarity classification, the model outperforms traditional machine\nmodels, offering insights into specific aspects and sentiments. This study\nadvances ABSA research, particularly in underrepresented languages, with\nimplications for cross-cultural linguistic research.",
      "tldr_zh": "这篇论文提出了一种基于 Deep Convolutional Neural Network (CNN) 的模型，用于在 Hausa 电影评论中进行 Aspect and Polarity Classification，从而提升 Aspect-based Sentiment Analysis (ABSA) 在低资源语言中的应用。研究团队创建了一个新的 Hausa ABSA 数据集，包括手动标注的方面级特征本体词和情感极性，并使用 TF-IDF 预处理结合 attention mechanisms 来捕捉上下文信息。模型在方面术语提取上达到 91% 准确率，在情感极性分类上达到 92%，优于传统机器模型。该研究为跨文化语言研究提供了重要见解，推动了 ABSA 在 underrepresented languages 中的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in the proceedings of ICCAIT 2023",
      "pdf_url": "http://arxiv.org/pdf/2405.19575v1",
      "published_date": "2024-05-29 23:45:42 UTC",
      "updated_date": "2024-05-29 23:45:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:23:05.846454"
    },
    {
      "arxiv_id": "2405.19567v2",
      "title": "Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding",
      "title_zh": "Dr-LLaVA：利用符号临床基础的视觉指令微调",
      "authors": [
        "Shenghuan Sun",
        "Alexander Schubert",
        "Gregory M. Goldgof",
        "Zhiqing Sun",
        "Thomas Hartvigsen",
        "Atul J. Butte",
        "Ahmed Alaa"
      ],
      "abstract": "Vision-Language Models (VLM) can support clinicians by analyzing medical\nimages and engaging in natural language interactions to assist in diagnostic\nand treatment tasks. However, VLMs often exhibit \"hallucinogenic\" behavior,\ngenerating textual outputs not grounded in contextual multimodal information.\nThis challenge is particularly pronounced in the medical domain, where we do\nnot only require VLM outputs to be accurate in single interactions but also to\nbe consistent with clinical reasoning and diagnostic pathways throughout\nmulti-turn conversations. For this purpose, we propose a new alignment\nalgorithm that uses symbolic representations of clinical reasoning to ground\nVLMs in medical knowledge. These representations are utilized to (i) generate\nGPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM\nconversations with demonstrations of clinical reasoning, and (ii) create an\nautomatic reward function that evaluates the clinical validity of VLM\ngenerations throughout clinician-VLM interactions. Our algorithm eliminates the\nneed for human involvement in training data generation or reward model\nconstruction, reducing costs compared to standard reinforcement learning with\nhuman feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a\nconversational VLM finetuned for analyzing bone marrow pathology slides,\ndemonstrating strong performance in multi-turn medical conversations.",
      "tldr_zh": "该研究针对视觉语言模型（VLMs）在医疗领域的幻觉问题和多轮对话一致性挑战，提出了一种新的对齐算法，使用符号临床推理（symbolic clinical grounding）来强化VLMs与医疗知识的关联。该算法通过GPT-4引导生成大规模视觉指令调整数据，模拟临床医生-VLM对话，并创建自动奖励函数（automatic reward function）评估生成内容的临床有效性，从而无需人工参与，相比标准强化学习与人类反馈（RLHF）显著降低了成本。最终，研究开发了Dr-LLaVA，一种针对骨髓病理学幻灯片分析的对话式VLMs，在多轮医疗对话中表现出色。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Code available at: https://github.com/AlaaLab/Dr-LLaVA",
      "pdf_url": "http://arxiv.org/pdf/2405.19567v2",
      "published_date": "2024-05-29 23:19:28 UTC",
      "updated_date": "2024-10-10 07:47:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:23:16.952759"
    },
    {
      "arxiv_id": "2406.00062v1",
      "title": "Unlocking the Potential of Large Language Models for Clinical Text Anonymization: A Comparative Study",
      "title_zh": "释放大语言模型在临床文本匿名化中的潜力：一项比较研究",
      "authors": [
        "David Pissarra",
        "Isabel Curioso",
        "João Alveira",
        "Duarte Pereira",
        "Bruno Ribeiro",
        "Tomás Souper",
        "Vasco Gomes",
        "André V. Carreiro",
        "Vitor Rolla"
      ],
      "abstract": "Automated clinical text anonymization has the potential to unlock the\nwidespread sharing of textual health data for secondary usage while assuring\npatient privacy and safety. Despite the proposal of many complex and\ntheoretically successful anonymization solutions in literature, these\ntechniques remain flawed. As such, clinical institutions are still reluctant to\napply them for open access to their data. Recent advances in developing Large\nLanguage Models (LLMs) pose a promising opportunity to further the field, given\ntheir capability to perform various tasks. This paper proposes six new\nevaluation metrics tailored to the challenges of generative anonymization with\nLLMs. Moreover, we present a comparative study of LLM-based methods, testing\nthem against two baseline techniques. Our results establish LLM-based models as\na reliable alternative to common approaches, paving the way toward trustworthy\nanonymization of clinical text.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在临床文本匿名化中的潜力，通过比较研究评估其作为可靠替代方案的效能。论文针对LLMs的生成式匿名化挑战，提出六个新的评估指标，以解决现有技术的缺陷，如隐私保护不足和机构采用犹豫。研究将LLMs-based方法与两个基线技术比较，结果显示前者显著提升了匿名化的可信度，为临床数据的安全共享铺平道路。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00062v1",
      "published_date": "2024-05-29 23:07:58 UTC",
      "updated_date": "2024-05-29 23:07:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:23:36.370827"
    },
    {
      "arxiv_id": "2405.19561v1",
      "title": "Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models",
      "title_zh": "翻译失败",
      "authors": [
        "Venkat Venkatasubramanian",
        "Arijit Chakraborty"
      ],
      "abstract": "The startling success of ChatGPT and other large language models (LLMs) using\ntransformer-based generative neural network architecture in applications such\nas natural language processing and image synthesis has many researchers excited\nabout potential opportunities in process systems engineering (PSE). The almost\nhuman-like performance of LLMs in these areas is indeed very impressive,\nsurprising, and a major breakthrough. Their capabilities are very useful in\ncertain tasks, such as writing first drafts of documents, code writing\nassistance, text summarization, etc. However, their success is limited in\nhighly scientific domains as they cannot yet reason, plan, or explain due to\ntheir lack of in-depth domain knowledge. This is a problem in domains such as\nchemical engineering as they are governed by fundamental laws of physics and\nchemistry (and biology), constitutive relations, and highly technical knowledge\nabout materials, processes, and systems. Although purely data-driven machine\nlearning has its immediate uses, the long-term success of AI in scientific and\nengineering domains would depend on developing hybrid AI systems that use first\nprinciples and technical knowledge effectively. We call these hybrid AI systems\nLarge Knowledge Models (LKMs), as they will not be limited to only NLP-based\ntechniques or NLP-like applications. In this paper, we discuss the challenges\nand opportunities in developing such systems in chemical engineering.",
      "tldr_zh": "这篇论文讨论了大型语言模型（Large Language Models, LLMs）如 ChatGPT 在自然语言处理（NLP）和图像合成中的惊人成功，但强调了它们在科学领域如化学工程中的局限性，因为缺乏深度领域知识、推理和规划能力。作者提出发展混合 AI 系统，即大型知识模型（Large Knowledge Models, LKMs），这些系统结合第一原理、物理化学定律和技术知识，以提升 AI 在工程领域的性能。论文重点分析了在化学工程中构建 LKMs 的挑战和机会，为未来 AI 应用提供更可靠和可解释的框架。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "I.2.0; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19561v1",
      "published_date": "2024-05-29 23:06:54 UTC",
      "updated_date": "2024-05-29 23:06:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:23:38.354429"
    },
    {
      "arxiv_id": "2406.00061v1",
      "title": "STAT: Shrinking Transformers After Training",
      "title_zh": "翻译失败",
      "authors": [
        "Megan Flynn",
        "Alexander Wang",
        "Dean Edward Alvarez",
        "Christopher De Sa",
        "Anil Damle"
      ],
      "abstract": "We present STAT: a simple algorithm to prune transformer models without any\nfine-tuning. STAT eliminates both attention heads and neurons from the network,\nwhile preserving accuracy by calculating a correction to the weights of the\nnext layer. Each layer block in the network is compressed using a series of\nprincipled matrix factorizations that preserve the network structure. Our\nentire algorithm takes minutes to compress BERT, and less than three hours to\ncompress models with 7B parameters using a single GPU. Using only several\nhundred data examples, STAT preserves the output of the network and improves\nupon existing gradient-free pruning methods. It is even competitive with\nmethods that include significant fine-tuning. We demonstrate our method on both\nencoder and decoder architectures, including BERT, DistilBERT, and Llama-2\nusing benchmarks such as GLUE, Squad, WikiText2.",
      "tldr_zh": "本文提出STAT算法，一种无需微调即可修剪Transformer模型的方法，通过消除注意力头和神经元，同时使用矩阵分解和权重校正来保持网络准确性。算法高效，仅需几分钟压缩BERT模型，或不到三小时处理7B参数模型，使用单个GPU和几百个数据示例即可实现。实验结果显示，STAT在BERT、DistilBERT和Llama-2等架构上，使用GLUE、SQuAD和WikiText2基准，优于无梯度修剪方法，甚至与需微调的方法竞争。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00061v1",
      "published_date": "2024-05-29 22:59:11 UTC",
      "updated_date": "2024-05-29 22:59:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:23:51.049204"
    },
    {
      "arxiv_id": "2405.19544v3",
      "title": "One-Shot Safety Alignment for Large Language Models via Optimal Dualization",
      "title_zh": "翻译失败",
      "authors": [
        "Xinmeng Huang",
        "Shuo Li",
        "Edgar Dobriban",
        "Osbert Bastani",
        "Hamed Hassani",
        "Dongsheng Ding"
      ],
      "abstract": "The growing safety concerns surrounding large language models raise an urgent\nneed to align them with diverse human preferences to simultaneously enhance\ntheir helpfulness and safety. A promising approach is to enforce safety\nconstraints through Reinforcement Learning from Human Feedback (RLHF). For such\nconstrained RLHF, typical Lagrangian-based primal-dual policy optimization\nmethods are computationally expensive and often unstable. This paper presents a\nperspective of dualization that reduces constrained alignment to an equivalent\nunconstrained alignment problem. We do so by pre-optimizing a smooth and convex\ndual function that has a closed form. This shortcut eliminates the need for\ncumbersome primal-dual policy iterations, greatly reducing the computational\nburden and improving training stability. Our strategy leads to two practical\nalgorithms in model-based and preference-based settings (MoCAN and PeCAN,\nrespectively). A broad range of experiments demonstrate the effectiveness and\nmerits of our algorithms.",
      "tldr_zh": "该研究针对大型语言模型（Large Language Models）的安全对齐问题，提出了一种基于 Optimal Dualization 的单次（One-Shot）方法，将约束强化学习从人类反馈（RLHF）转化为等价的无约束对齐问题，通过预优化平滑凸双重函数来减少计算负担并提升训练稳定性。该方法消除了传统的拉格朗日-based primal-dual 政策迭代的需求，开发了两个实用算法：MoCAN（模型-based）和 PeCAN（偏好-based）。实验结果显示，这些算法在广泛场景中表现出色，有效提高了模型的安全性和帮助性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 6 figures, 8 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.19544v3",
      "published_date": "2024-05-29 22:12:52 UTC",
      "updated_date": "2024-11-22 05:55:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:24:02.915043"
    },
    {
      "arxiv_id": "2405.19538v2",
      "title": "CheXpert Plus: Augmenting a Large Chest X-ray Dataset with Text Radiology Reports, Patient Demographics and Additional Image Formats",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Chambon",
        "Jean-Benoit Delbrouck",
        "Thomas Sounack",
        "Shih-Cheng Huang",
        "Zhihong Chen",
        "Maya Varma",
        "Steven QH Truong",
        "Chu The Chuong",
        "Curtis P. Langlotz"
      ],
      "abstract": "Since the release of the original CheXpert paper five years ago, CheXpert has\nbecome one of the most widely used and cited clinical AI datasets. The\nemergence of vision language models has sparked an increase in demands for\nsharing reports linked to CheXpert images, along with a growing interest among\nAI fairness researchers in obtaining demographic data. To address this,\nCheXpert Plus serves as a new collection of radiology data sources, made\npublicly available to enhance the scaling, performance, robustness, and\nfairness of models for all subsequent machine learning tasks in the field of\nradiology. CheXpert Plus is the largest text dataset publicly released in\nradiology, with a total of 36 million text tokens, including 13 million\nimpression tokens. To the best of our knowledge, it represents the largest text\nde-identification effort in radiology, with almost 1 million PHI spans\nanonymized. It is only the second time that a large-scale English paired\ndataset has been released in radiology, thereby enabling, for the first time,\ncross-institution training at scale. All reports are paired with high-quality\nimages in DICOM format, along with numerous image and patient metadata covering\nvarious clinical and socio-economic groups, as well as many pathology labels\nand RadGraph annotations. We hope this dataset will boost research for AI\nmodels that can further assist radiologists and help improve medical care. Data\nis available at the following URL:\nhttps://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1\nModels are available at the following URL:\nhttps://github.com/Stanford-AIMI/chexpert-plus",
      "tldr_zh": "本研究推出了 CheXpert Plus，这是一个扩展的胸部 X-ray 数据集，添加了文本放射学报告、患者人口统计数据以及额外的图像格式，以提升放射学领域机器学习任务的规模、性能、鲁棒性和公平性。该数据集是放射学中最大的公开文本数据集，包含 3600 万文本标记（包括 1300 万印象标记），并进行了大规模的 PHI 去标识化，匿名化近 100 万跨度，支持首次大规模跨机构训练。CheXpert Plus 配对高品质 DICOM 格式图像、各种图像和患者元数据、病理标签以及 RadGraph 注释，有望助力 AI 模型辅助放射科医生并改善医疗护理。数据和模型可通过指定 URL 获得。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages Updated title",
      "pdf_url": "http://arxiv.org/pdf/2405.19538v2",
      "published_date": "2024-05-29 21:48:56 UTC",
      "updated_date": "2024-06-03 19:14:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:24:18.312227"
    },
    {
      "arxiv_id": "2405.19534v4",
      "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
      "title_zh": "偏好学习算法不学习偏好排名",
      "authors": [
        "Angelica Chen",
        "Sadhika Malladi",
        "Lily H. Zhang",
        "Xinyi Chen",
        "Qiuyi Zhang",
        "Rajesh Ranganath",
        "Kyunghyun Cho"
      ],
      "abstract": "Preference learning algorithms (e.g., RLHF and DPO) are frequently used to\nsteer LLMs to produce generations that are more preferred by humans, but our\nunderstanding of their inner workings is still limited. In this work, we study\nthe conventional wisdom that preference learning trains models to assign higher\nlikelihoods to more preferred outputs than less preferred outputs, measured via\nranking accuracy. Surprisingly, we find that most state-of-the-art\npreference-tuned models achieve a ranking accuracy of less than 60% on common\npreference datasets. We furthermore derive the idealized ranking accuracy that\na preference-tuned LLM would achieve if it optimized the DPO or RLHF objective\nperfectly. We demonstrate that existing models exhibit a significant alignment\ngap -- i.e., a gap between the observed and idealized ranking accuracies. We\nattribute this discrepancy to the DPO objective, which is empirically and\ntheoretically ill-suited to fix even mild ranking errors in the reference\nmodel, and derive a simple and efficient formula for quantifying the difficulty\nof learning a given preference datapoint. Finally, we demonstrate that ranking\naccuracy strongly correlates with the empirically popular win rate metric when\nthe model is close to the reference model used in the objective, shedding\nfurther light on the differences between on-policy (e.g., RLHF) and off-policy\n(e.g., DPO) preference learning algorithms.",
      "tldr_zh": "这篇论文研究了偏好学习算法（如 RLHF 和 DPO）在训练大型语言模型（LLMs）时是否能有效学习偏好排名，发现大多数最先进的模型在常见数据集上的排名准确率不足60%，挑战了传统认知。作者推导了理想化的排名准确率，并揭示了实际模型与理论最优模型之间的“alignment gap”，将问题归因于DPO目标的局限性，该目标难以修复参考模型中的轻微排名错误。论文还提供了一个简单公式来量化学习特定偏好数据点的难度，并证明排名准确率与胜率指标高度相关，尤其当模型接近参考模型时。最终，这为理解on-policy（如RLHF）和off-policy（如DPO）算法的差异提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024 camera-ready",
      "pdf_url": "http://arxiv.org/pdf/2405.19534v4",
      "published_date": "2024-05-29 21:29:44 UTC",
      "updated_date": "2024-10-31 14:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:24:28.282689"
    },
    {
      "arxiv_id": "2405.19524v1",
      "title": "AI Risk Management Should Incorporate Both Safety and Security",
      "title_zh": "翻译失败",
      "authors": [
        "Xiangyu Qi",
        "Yangsibo Huang",
        "Yi Zeng",
        "Edoardo Debenedetti",
        "Jonas Geiping",
        "Luxi He",
        "Kaixuan Huang",
        "Udari Madhushani",
        "Vikash Sehwag",
        "Weijia Shi",
        "Boyi Wei",
        "Tinghao Xie",
        "Danqi Chen",
        "Pin-Yu Chen",
        "Jeffrey Ding",
        "Ruoxi Jia",
        "Jiaqi Ma",
        "Arvind Narayanan",
        "Weijie J Su",
        "Mengdi Wang",
        "Chaowei Xiao",
        "Bo Li",
        "Dawn Song",
        "Peter Henderson",
        "Prateek Mittal"
      ],
      "abstract": "The exposure of security vulnerabilities in safety-aligned language models,\ne.g., susceptibility to adversarial attacks, has shed light on the intricate\ninterplay between AI safety and AI security. Although the two disciplines now\ncome together under the overarching goal of AI risk management, they have\nhistorically evolved separately, giving rise to differing perspectives.\nTherefore, in this paper, we advocate that stakeholders in AI risk management\nshould be aware of the nuances, synergies, and interplay between safety and\nsecurity, and unambiguously take into account the perspectives of both\ndisciplines in order to devise mostly effective and holistic risk mitigation\napproaches. Unfortunately, this vision is often obfuscated, as the definitions\nof the basic concepts of \"safety\" and \"security\" themselves are often\ninconsistent and lack consensus across communities. With AI risk management\nbeing increasingly cross-disciplinary, this issue is particularly salient. In\nlight of this conceptual challenge, we introduce a unified reference framework\nto clarify the differences and interplay between AI safety and AI security,\naiming to facilitate a shared understanding and effective collaboration across\ncommunities.",
      "tldr_zh": "该论文强调，AI风险管理应同时纳入AI safety（AI安全）和AI security（AI安全），因为两者在防范如对抗攻击等风险中存在复杂互动，但历史发展独立导致定义不一致。作者主张，利益相关者需认识到两者的细微差异、协同作用，并在风险缓解策略中全面考虑这些视角，以实现更有效的整体管理。为解决概念挑战，论文提出一个统一的参考框架，旨在澄清AI safety与AI security的差异和互动，促进跨社区的共享理解和合作。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19524v1",
      "published_date": "2024-05-29 21:00:47 UTC",
      "updated_date": "2024-05-29 21:00:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:24:38.785905"
    },
    {
      "arxiv_id": "2405.19522v1",
      "title": "Artificial Intelligence Index Report 2024",
      "title_zh": "人工智能指数报告 2024",
      "authors": [
        "Nestor Maslej",
        "Loredana Fattorini",
        "Raymond Perrault",
        "Vanessa Parli",
        "Anka Reuel",
        "Erik Brynjolfsson",
        "John Etchemendy",
        "Katrina Ligett",
        "Terah Lyons",
        "James Manyika",
        "Juan Carlos Niebles",
        "Yoav Shoham",
        "Russell Wald",
        "Jack Clark"
      ],
      "abstract": "The 2024 Index is our most comprehensive to date and arrives at an important\nmoment when AI's influence on society has never been more pronounced. This\nyear, we have broadened our scope to more extensively cover essential trends\nsuch as technical advancements in AI, public perceptions of the technology, and\nthe geopolitical dynamics surrounding its development. Featuring more original\ndata than ever before, this edition introduces new estimates on AI training\ncosts, detailed analyses of the responsible AI landscape, and an entirely new\nchapter dedicated to AI's impact on science and medicine. The AI Index report\ntracks, collates, distills, and visualizes data related to artificial\nintelligence (AI). Our mission is to provide unbiased, rigorously vetted,\nbroadly sourced data in order for policymakers, researchers, executives,\njournalists, and the general public to develop a more thorough and nuanced\nunderstanding of the complex field of AI. The AI Index is recognized globally\nas one of the most credible and authoritative sources for data and insights on\nartificial intelligence. Previous editions have been cited in major newspapers,\nincluding the The New York Times, Bloomberg, and The Guardian, have amassed\nhundreds of academic citations, and been referenced by high-level policymakers\nin the United States, the United Kingdom, and the European Union, among other\nplaces. This year's edition surpasses all previous ones in size, scale, and\nscope, reflecting the growing significance that AI is coming to hold in all of\nour lives.",
      "tldr_zh": "2024年Artificial Intelligence Index报告是迄今为止最全面的版本，涵盖AI的技术进步、公众认知以及地缘政治动态等关键趋势。该报告引入了更多原创数据，包括AI训练成本的估计、负责任AI的详细分析，以及一个全新章节探讨AI对科学和医学的影响。报告通过跟踪、整理和可视化广泛来源的数据，提供无偏见且严格审查的洞见，帮助政策制定者、研究人员和公众更深入地理解AI领域。作为全球权威来源，该报告已被媒体和高层决策者广泛引用，反映了AI在社会中日益重要的作用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19522v1",
      "published_date": "2024-05-29 20:59:57 UTC",
      "updated_date": "2024-05-29 20:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:24:50.353931"
    },
    {
      "arxiv_id": "2405.19519v2",
      "title": "Two-Layer Retrieval-Augmented Generation Framework for Low-Resource Medical Question Answering Using Reddit Data: Proof-of-Concept Study",
      "title_zh": "两层检索增强",
      "authors": [
        "Sudeshna Das",
        "Yao Ge",
        "Yuting Guo",
        "Swati Rajwal",
        "JaMor Hairston",
        "Jeanne Powell",
        "Drew Walker",
        "Snigdha Peddireddy",
        "Sahithi Lakamana",
        "Selen Bozkurt",
        "Matthew Reyna",
        "Reza Sameni",
        "Yunyu Xiao",
        "Sangmi Kim",
        "Rasheeta Chandler",
        "Natalie Hernandez",
        "Danielle Mowery",
        "Rachel Wightman",
        "Jennifer Love",
        "Anthony Spadaro",
        "Jeanmarie Perrone",
        "Abeed Sarker"
      ],
      "abstract": "The increasing use of social media to share lived and living experiences of\nsubstance use presents a unique opportunity to obtain information on side\neffects, use patterns, and opinions on novel psychoactive substances. However,\ndue to the large volume of data, obtaining useful insights through natural\nlanguage processing technologies such as large language models is challenging.\nThis paper aims to develop a retrieval-augmented generation (RAG) architecture\nfor medical question answering pertaining to clinicians' queries on emerging\nissues associated with health-related topics, using user-generated medical\ninformation on social media. We proposed a two-layer RAG framework for\nquery-focused answer generation and evaluated a proof of concept for the\nframework in the context of query-focused summary generation from social media\nforums, focusing on emerging drug-related information. Our modular framework\ngenerates individual summaries followed by an aggregated summary to answer\nmedical queries from large amounts of user-generated social media data in an\nefficient manner. We compared the performance of a quantized large language\nmodel (Nous-Hermes-2-7B-DPO), deployable in low-resource settings, with GPT-4.\nFor this proof-of-concept study, we used user-generated data from Reddit to\nanswer clinicians' questions on the use of xylazine and ketamine. Our framework\nachieves comparable median scores in terms of relevance, length, hallucination,\ncoverage, and coherence when evaluated using GPT-4 and Nous-Hermes-2-7B-DPO,\nevaluated for 20 queries with 76 samples. There was no statistically\nsignificant difference between the two for coverage, coherence, relevance,\nlength, and hallucination. A statistically significant difference was noted for\nthe Coleman-Liau Index. Our RAG framework can effectively answer medical\nquestions about targeted topics and can be deployed in resource-constrained\nsettings.",
      "tldr_zh": "本研究提出一个两层 Retrieval-Augmented Generation (RAG) 框架，用于从 Reddit 用户生成数据中回答低资源医疗问答问题，针对临床医生关于新兴药物（如 xylazine 和 ketamine）相关查询的证明概念研究。\n框架通过生成个体摘要并聚合总结，实现高效查询焦点答案生成，并使用量化大型语言模型（Nous-Hermes-2-7B-DPO）在资源受限环境中部署，与 GPT-4 进行性能比较。\n实验结果显示，该框架在相关性、长度、幻觉、覆盖率和连贯性方面与 GPT-4 相当，没有统计显著差异，仅在 Coleman-Liau Index 上有所不同。\n总体而言，该框架证明了其在处理社交媒体数据以回答医疗问题方面的有效性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Published in JMIR: https://www.jmir.org/2025/1/e66220",
      "pdf_url": "http://arxiv.org/pdf/2405.19519v2",
      "published_date": "2024-05-29 20:56:52 UTC",
      "updated_date": "2025-01-07 16:13:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:25:06.022688"
    },
    {
      "arxiv_id": "2405.19501v1",
      "title": "MDS-ViTNet: Improving saliency prediction for Eye-Tracking with Vision Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Polezhaev Ignat",
        "Goncharenko Igor",
        "Iurina Natalya"
      ],
      "abstract": "In this paper, we present a novel methodology we call MDS-ViTNet (Multi\nDecoder Saliency by Vision Transformer Network) for enhancing visual saliency\nprediction or eye-tracking. This approach holds significant potential for\ndiverse fields, including marketing, medicine, robotics, and retail. We propose\na network architecture that leverages the Vision Transformer, moving beyond the\nconventional ImageNet backbone. The framework adopts an encoder-decoder\nstructure, with the encoder utilizing a Swin transformer to efficiently embed\nmost important features. This process involves a Transfer Learning method,\nwherein layers from the Vision Transformer are converted by the Encoder\nTransformer and seamlessly integrated into a CNN Decoder. This methodology\nensures minimal information loss from the original input image. The decoder\nemploys a multi-decoding technique, utilizing dual decoders to generate two\ndistinct attention maps. These maps are subsequently combined into a singular\noutput via an additional CNN model. Our trained model MDS-ViTNet achieves\nstate-of-the-art results across several benchmarks. Committed to fostering\nfurther collaboration, we intend to make our code, models, and datasets\naccessible to the public.",
      "tldr_zh": "本研究提出了一种名为 MDS-ViTNet 的新方法，用于提升视觉显著性预测和眼动追踪，适用于营销、医学、机器人和零售等领域。该框架采用 Vision Transformer 作为核心，结合 Swin transformer 编码器通过 Transfer Learning 提取关键特征，并使用多解码器(multi-decoding)技术生成并合并两个注意力图，以最小化信息损失。实验结果显示，MDS-ViTNet 在多个基准上达到了 state-of-the-art 性能，并计划公开代码、模型和数据集以促进进一步合作。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19501v1",
      "published_date": "2024-05-29 20:28:04 UTC",
      "updated_date": "2024-05-29 20:28:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:25:15.204091"
    },
    {
      "arxiv_id": "2405.19498v1",
      "title": "Machine Psychology: Integrating Operant Conditioning with the Non-Axiomatic Reasoning System for Advancing Artificial General Intelligence Research",
      "title_zh": "翻译失败",
      "authors": [
        "Robert Johansson"
      ],
      "abstract": "This paper introduces an interdisciplinary framework called Machine\nPsychology, which merges principles from operant learning psychology with a\nspecific Artificial Intelligence model, the Non-Axiomatic Reasoning System\n(NARS), to enhance Artificial General Intelligence (AGI) research. The core\npremise of this framework is that adaptation is crucial to both biological and\nartificial intelligence and can be understood through operant conditioning\nprinciples. The study assesses this approach via three operant learning tasks\nusing OpenNARS for Applications (ONA): simple discrimination, changing\ncontingencies, and conditional discrimination tasks.\n  In the simple discrimination task, NARS demonstrated rapid learning,\nachieving perfect accuracy during both training and testing phases. The\nchanging contingencies task showcased NARS's adaptability, as it successfully\nadjusted its behavior when task conditions were reversed. In the conditional\ndiscrimination task, NARS handled complex learning scenarios effectively,\nachieving high accuracy by forming and utilizing intricate hypotheses based on\nconditional cues.\n  These findings support the application of operant conditioning as a framework\nfor creating adaptive AGI systems. NARS's ability to operate under conditions\nof insufficient knowledge and resources, coupled with its sensorimotor\nreasoning capabilities, establishes it as a robust model for AGI. The Machine\nPsychology framework, by incorporating elements of natural intelligence such as\ncontinuous learning and goal-driven behavior, offers a scalable and flexible\napproach for real-world applications. Future research should investigate using\nenhanced NARS systems, more advanced tasks, and applying this framework to\ndiverse, complex challenges to further progress the development of human-level\nAI.",
      "tldr_zh": "本文提出 Machine Psychology 框架，将 operant conditioning 原则与 Non-Axiomatic Reasoning System (NARS) 整合，旨在提升 Artificial General Intelligence (AGI) 研究的核心适应性。研究通过在 OpenNARS for Applications (ONA) 上评估三个任务——simple discrimination、changing contingencies 和 conditional discrimination——证明了 NARS 的快速学习能力、行为调整灵活性和处理复杂场景的效能。实验结果显示，该框架有助于构建适应性 AGI 系统，并在资源有限条件下表现出色，为未来扩展到更高级任务和实际应用奠定基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19498v1",
      "published_date": "2024-05-29 20:23:57 UTC",
      "updated_date": "2024-05-29 20:23:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:25:27.862009"
    },
    {
      "arxiv_id": "2405.19495v1",
      "title": "Qiskit Code Assistant: Training LLMs for generating Quantum Computing Code",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolas Dupuis",
        "Luca Buratti",
        "Sanjay Vishwakarma",
        "Aitana Viudes Forrat",
        "David Kremer",
        "Ismael Faro",
        "Ruchir Puri",
        "Juan Cruz-Benito"
      ],
      "abstract": "Code Large Language Models (Code LLMs) have emerged as powerful tools,\nrevolutionizing the software development landscape by automating the coding\nprocess and reducing time and effort required to build applications. This paper\nfocuses on training Code LLMs to specialize in the field of quantum computing.\nWe begin by discussing the unique needs of quantum computing programming, which\ndiffer significantly from classical programming approaches or languages. A Code\nLLM specializing in quantum computing requires a foundational understanding of\nquantum computing and quantum information theory. However, the scarcity of\navailable quantum code examples and the rapidly evolving field, which\nnecessitates continuous dataset updates, present significant challenges.\nMoreover, we discuss our work on training Code LLMs to produce high-quality\nquantum code using the Qiskit library. This work includes an examination of the\nvarious aspects of the LLMs used for training and the specific training\nconditions, as well as the results obtained with our current models. To\nevaluate our models, we have developed a custom benchmark, similar to\nHumanEval, which includes a set of tests specifically designed for the field of\nquantum computing programming using Qiskit. Our findings indicate that our\nmodel outperforms existing state-of-the-art models in quantum computing tasks.\nWe also provide examples of code suggestions, comparing our model to other\nrelevant code LLMs. Finally, we introduce a discussion on the potential\nbenefits of Code LLMs for quantum computing computational scientists,\nresearchers, and practitioners. We also explore various features and future\nwork that could be relevant in this context.",
      "tldr_zh": "该论文介绍了Qiskit Code Assistant，一种针对量子计算代码生成的Code LLMs训练方法，以应对量子编程的独特需求，如量子计算和量子信息理论的基础知识。研究者讨论了训练过程，包括处理数据集稀缺和领域快速演变的挑战，并使用Qiskit库进行模型优化，同时开发了一个类似于HumanEval的自定义基准进行评估。结果显示，该模型在量子计算任务中优于现有状态-of-the-art模型，并提供了代码建议示例，探讨了其对量子计算科学家的潜在益处及未来扩展方向。",
      "categories": [
        "quant-ph",
        "cs.AI"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19495v1",
      "published_date": "2024-05-29 20:21:00 UTC",
      "updated_date": "2024-05-29 20:21:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:25:39.411823"
    },
    {
      "arxiv_id": "2405.19479v1",
      "title": "Participation in the age of foundation models",
      "title_zh": "基础模型时代的参与",
      "authors": [
        "Harini Suresh",
        "Emily Tseng",
        "Meg Young",
        "Mary L. Gray",
        "Emma Pierson",
        "Karen Levy"
      ],
      "abstract": "Growing interest and investment in the capabilities of foundation models has\npositioned such systems to impact a wide array of public services. Alongside\nthese opportunities is the risk that these systems reify existing power\nimbalances and cause disproportionate harm to marginalized communities.\nParticipatory approaches hold promise to instead lend agency and\ndecision-making power to marginalized stakeholders. But existing approaches in\nparticipatory AI/ML are typically deeply grounded in context - how do we apply\nthese approaches to foundation models, which are, by design, disconnected from\ncontext? Our paper interrogates this question.\n  First, we examine existing attempts at incorporating participation into\nfoundation models. We highlight the tension between participation and scale,\ndemonstrating that it is intractable for impacted communities to meaningfully\nshape a foundation model that is intended to be universally applicable. In\nresponse, we develop a blueprint for participatory foundation models that\nidentifies more local, application-oriented opportunities for meaningful\nparticipation. In addition to the \"foundation\" layer, our framework proposes\nthe \"subfloor'' layer, in which stakeholders develop shared technical\ninfrastructure, norms and governance for a grounded domain, and the \"surface''\nlayer, in which affected communities shape the use of a foundation model for a\nspecific downstream task. The intermediate \"subfloor'' layer scopes the range\nof potential harms to consider, and affords communities more concrete avenues\nfor deliberation and intervention. At the same time, it avoids duplicative\neffort by scaling input across relevant use cases. Through three case studies\nin clinical care, financial services, and journalism, we illustrate how this\nmulti-layer model can create more meaningful opportunities for participation\nthan solely intervening at the foundation layer.",
      "tldr_zh": "这篇论文探讨了基础模型（foundation models）在公共服务中的应用可能加剧权力不平衡和对边缘化社区的伤害，并提出参与式方法（participatory approaches）作为解决方案，以赋予这些社区决策权。论文分析了现有参与式AI/ML方法的局限性，特别是基础模型脱离上下文的特性，导致大规模参与不可行，并开发了一个多层蓝图：包括“foundation”层的基础模型、“subfloor”层（开发共享技术基础设施、规范和治理以覆盖特定领域），以及“surface”层（受影响社区针对下游任务定制模型）。通过临床护理、金融服务和新闻业的三个案例研究，展示了这一框架如何缩小潜在危害、提升参与效率，并避免重复努力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages, 2 figures. Appeared at FAccT '24",
      "pdf_url": "http://arxiv.org/pdf/2405.19479v1",
      "published_date": "2024-05-29 19:53:23 UTC",
      "updated_date": "2024-05-29 19:53:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:25:52.538994"
    },
    {
      "arxiv_id": "2405.19471v1",
      "title": "The Data Minimization Principle in Machine Learning",
      "title_zh": "机器学习中的数据最小化原则",
      "authors": [
        "Prakhar Ganesh",
        "Cuong Tran",
        "Reza Shokri",
        "Ferdinando Fioretto"
      ],
      "abstract": "The principle of data minimization aims to reduce the amount of data\ncollected, processed or retained to minimize the potential for misuse,\nunauthorized access, or data breaches. Rooted in privacy-by-design principles,\ndata minimization has been endorsed by various global data protection\nregulations. However, its practical implementation remains a challenge due to\nthe lack of a rigorous formulation. This paper addresses this gap and\nintroduces an optimization framework for data minimization based on its legal\ndefinitions. It then adapts several optimization algorithms to perform data\nminimization and conducts a comprehensive evaluation in terms of their\ncompliance with minimization objectives as well as their impact on user\nprivacy. Our analysis underscores the mismatch between the privacy expectations\nof data minimization and the actual privacy benefits, emphasizing the need for\napproaches that account for multiple facets of real-world privacy risks.",
      "tldr_zh": "这篇论文探讨了数据最小化（data minimization）原则在机器学习中的应用，该原则旨在通过减少收集、处理或保留的数据量来降低误用、未授权访问或数据泄露的风险，并根植于privacy-by-design原则。该研究填补了该原则缺乏严格制定框架的空白，引入了一个基于法律定义的optimization framework，并适应多种优化算法来实现数据最小化。论文通过全面评估这些算法的合规性及其对用户隐私的影响，发现实际隐私益处与期望值不匹配，并强调需要考虑多方面真实世界隐私风险的综合方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19471v1",
      "published_date": "2024-05-29 19:40:27 UTC",
      "updated_date": "2024-05-29 19:40:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:26:03.915023"
    },
    {
      "arxiv_id": "2405.19464v2",
      "title": "Leveraging Generative AI for Urban Digital Twins: A Scoping Review on the Autonomous Generation of Urban Data, Scenarios, Designs, and 3D City Models for Smart City Advancement",
      "title_zh": "翻译失败",
      "authors": [
        "Haowen Xu",
        "Femi Omitaomu",
        "Soheil Sabri",
        "Sisi Zlatanova",
        "Xiao Li",
        "Yongze Song"
      ],
      "abstract": "The digital transformation of modern cities by integrating advanced\ninformation, communication, and computing technologies has marked the epoch of\ndata-driven smart city applications for efficient and sustainable urban\nmanagement. Despite their effectiveness, these applications often rely on\nmassive amounts of high-dimensional and multi-domain data for monitoring and\ncharacterizing different urban sub-systems, presenting challenges in\napplication areas that are limited by data quality and availability, as well as\ncostly efforts for generating urban scenarios and design alternatives. As an\nemerging research area in deep learning, Generative Artificial Intelligence\n(AI) models have demonstrated their unique values in data and code generation.\nThis survey paper aims to explore the innovative integration of generative AI\ntechniques and urban digital twins to address challenges in the realm of smart\ncities in various urban sectors, such as transportation and mobility\nmanagement, energy system operations, building and infrastructure management,\nand urban design. The survey starts with the introduction of popular generative\nAI models with their application areas, followed by a structured review of the\nexisting urban science applications that leverage the autonomous capability of\nthe generative AI techniques to facilitate (a) data augmentation for promoting\nurban monitoring and predictive analytics, (b) synthetic data and scenario\ngeneration, (c) automated 3D city modeling, and (d) generative urban design and\noptimization. Based on the review, this survey discusses potential\nopportunities and technical strategies that integrate generative AI models into\nthe next-generation urban digital twins for more reliable, scalable, and\nautomated management of smart cities.",
      "tldr_zh": "这篇综述论文探讨了如何利用Generative AI 技术增强Urban Digital Twins，以自动生成城市数据、场景、设计和3D City Models，从而解决智能城市中数据质量和可用性的挑战。论文首先介绍了流行Generative AI 模型及其应用领域，然后通过结构化回顾，分析了这些技术在交通、能源、建筑等领域中的作用，包括数据增强、合成数据生成、自动3D城市建模以及生成式城市设计优化。最终，论文讨论了将Generative AI 整合到下一代Urban Digital Twins中的潜在机会和技术策略，以实现更可靠、可扩展的智能城市管理。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19464v2",
      "published_date": "2024-05-29 19:23:07 UTC",
      "updated_date": "2024-08-06 18:32:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:26:16.429697"
    },
    {
      "arxiv_id": "2405.19458v4",
      "title": "MemControl: Mitigating Memorization in Diffusion Models via Automated Parameter Selection",
      "title_zh": "MemControl：通过自动参数选择缓解扩散模型中的记忆化",
      "authors": [
        "Raman Dutt",
        "Ondrej Bohdal",
        "Pedro Sanchez",
        "Sotirios A. Tsaftaris",
        "Timothy Hospedales"
      ],
      "abstract": "Diffusion models excel in generating images that closely resemble their\ntraining data but are also susceptible to data memorization, raising privacy,\nethical, and legal concerns, particularly in sensitive domains such as medical\nimaging. We hypothesize that this memorization stems from the\noverparameterization of deep models and propose that regularizing model\ncapacity during fine-tuning can mitigate this issue. Firstly, we empirically\nshow that regulating the model capacity via Parameter-efficient fine-tuning\n(PEFT) mitigates memorization to some extent, however, it further requires the\nidentification of the exact parameter subsets to be fine-tuned for high-quality\ngeneration. To identify these subsets, we introduce a bi-level optimization\nframework, MemControl, that automates parameter selection using memorization\nand generation quality metrics as rewards during fine-tuning. The parameter\nsubsets discovered through MemControl achieve a superior tradeoff between\ngeneration quality and memorization. For the task of medical image generation,\nour approach outperforms existing state-of-the-art memorization mitigation\nstrategies by fine-tuning as few as 0.019% of model parameters. Moreover, we\ndemonstrate that the discovered parameter subsets are transferable to\nnon-medical domains. Our framework is scalable to large datasets, agnostic to\nreward functions, and can be integrated with existing approaches for further\nmemorization mitigation. To the best of our knowledge, this is the first study\nto empirically evaluate memorization in medical images and propose a targeted\nyet universal mitigation strategy. The code is available at\nhttps://github.com/Raman1121/Diffusion_Memorization_HPO.",
      "tldr_zh": "该研究针对扩散模型（Diffusion models）在图像生成中存在的记忆化问题（如数据隐私风险），假设这是由模型过度参数化（overparameterization）引起的，并提出通过调节模型容量来缓解。作者引入MemControl框架，一个双层优化（bi-level optimization）方法，利用记忆化和生成质量指标作为奖励，自动选择参数子集进行参数高效微调（PEFT），从而实现生成质量与记忆化之间的优异权衡。在医疗图像生成任务中，该方法仅微调0.019%的参数就超过了现有最先进策略，且发现的参数子集可转移到非医疗领域，框架还具备可扩展性和通用性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted into WACV 2025 (Applications Track)",
      "pdf_url": "http://arxiv.org/pdf/2405.19458v4",
      "published_date": "2024-05-29 19:12:08 UTC",
      "updated_date": "2025-02-11 12:41:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:26:28.909841"
    },
    {
      "arxiv_id": "2405.19456v2",
      "title": "SSFF: Investigating LLM Predictive Capabilities for Startup Success through a Multi-Agent Framework with Enhanced Explainability and Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Xisen Wang",
        "Yigit Ihlamur",
        "Fuat Alican"
      ],
      "abstract": "LLM based agents have recently demonstrated strong potential in automating\ncomplex tasks, yet accurately predicting startup success remains an open\nchallenge with few benchmarks and tailored frameworks. To address these\nlimitations, we propose the Startup Success Forecasting Framework, an\nautonomous system that emulates the reasoning of venture capital analysts\nthrough a multi agent collaboration model. Our framework integrates traditional\nmachine learning methods such as random forests and neural networks within a\nretrieval augmented generation framework composed of three interconnected\nmodules: a prediction block, an analysis block, and an external knowledge\nblock. We evaluate our framework and identify three main findings. First, by\nleveraging founder segmentation, startups led by L5 founders are 3.79 times\nmore likely to succeed than those led by L1 founders. Second, baseline large\nlanguage models consistently overpredict startup success and struggle under\nrealistic class imbalances largely due to overreliance on founder claims.\nThird, our framework significantly enhances prediction accuracy, yielding a\n108.3 percent relative improvement over GPT 4o mini and a 30.8 percent relative\nimprovement over GPT 4o. These results demonstrate the value of a multi agent\napproach combined with discriminative machine learning in mitigating the\nlimitations of standard large language model based prediction methods.",
      "tldr_zh": "本研究提出SSFF框架，通过多智能体协作模拟风险投资分析师的推理，整合随机森林和神经网络等传统机器学习方法于一个检索增强生成系统，包括预测块、分析块和外部知识块，以提升LLM在初创公司成功预测中的准确性和可解释性。研究发现，通过创始人分段，L5级创始人的初创公司成功概率是L1级创始人的3.79倍，而基线LLM模型往往过度预测成功并在类别不平衡下表现不佳，主要由于过度依赖创始人的声明。SSFF框架显著提高了预测性能，比GPT-4o mini提升108.3%，比GPT-4o提升30.8%，证明了多智能体方法结合判别机器学习的价值。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "For relevant code:\n  https://github.com/Xisen-Wang/Startup-Success-Forecasting-Framework",
      "pdf_url": "http://arxiv.org/pdf/2405.19456v2",
      "published_date": "2024-05-29 19:07:42 UTC",
      "updated_date": "2025-04-19 17:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:26:39.007472"
    },
    {
      "arxiv_id": "2405.19453v1",
      "title": "Optimizing Split Points for Error-Resilient SplitFed Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Chamani Shiranthika",
        "Parvaneh Saeedi",
        "Ivan V. Bajić"
      ],
      "abstract": "Recent advancements in decentralized learning, such as Federated Learning\n(FL), Split Learning (SL), and Split Federated Learning (SplitFed), have\nexpanded the potentials of machine learning. SplitFed aims to minimize the\ncomputational burden on individual clients in FL and parallelize SL while\nmaintaining privacy. This study investigates the resilience of SplitFed to\npacket loss at model split points. It explores various parameter aggregation\nstrategies of SplitFed by examining the impact of splitting the model at\ndifferent points-either shallow split or deep split-on the final global model\nperformance. The experiments, conducted on a human embryo image segmentation\ntask, reveal a statistically significant advantage of a deeper split point.",
      "tldr_zh": "这篇论文针对 SplitFed Learning 的鲁棒性问题，优化了模型分割点以应对分组丢失带来的错误影响。研究者比较了浅层和深层分割点对参数聚合策略的影响，通过在人类胚胎图像分割任务上的实验证明，深层分割点显著提高了全局模型性能。总体而言，该工作为提升 Federated Learning 和 Split Learning 的错误恢复能力提供了重要指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for poster presentation at the Women in Computer Vision\n  (WiCV) workshop in CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19453v1",
      "published_date": "2024-05-29 19:03:27 UTC",
      "updated_date": "2024-05-29 19:03:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:26:50.841482"
    },
    {
      "arxiv_id": "2405.19444v1",
      "title": "MathChat: Benchmarking Mathematical Reasoning and Instruction Following in Multi-Turn Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenwen Liang",
        "Dian Yu",
        "Wenhao Yu",
        "Wenlin Yao",
        "Zhihan Zhang",
        "Xiangliang Zhang",
        "Dong Yu"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nmathematical problem solving, particularly in single turn question answering\nformats. However, real world scenarios often involve mathematical question\nanswering that requires multi turn or interactive information exchanges, and\nthe performance of LLMs on these tasks is still underexplored. This paper\nintroduces MathChat, a comprehensive benchmark specifically designed to\nevaluate LLMs across a broader spectrum of mathematical tasks. These tasks are\nstructured to assess the models' abilities in multiturn interactions and open\nended generation. We evaluate the performance of various SOTA LLMs on the\nMathChat benchmark, and we observe that while these models excel in single turn\nquestion answering, they significantly underperform in more complex scenarios\nthat require sustained reasoning and dialogue understanding. To address the\nabove limitations of existing LLMs when faced with multiturn and open ended\ntasks, we develop MathChat sync, a synthetic dialogue based math dataset for\nLLM finetuning, focusing on improving models' interaction and instruction\nfollowing capabilities in conversations. Experimental results emphasize the\nneed for training LLMs with diverse, conversational instruction tuning datasets\nlike MathChatsync. We believe this work outlines one promising direction for\nimproving the multiturn mathematical reasoning abilities of LLMs, thus pushing\nforward the development of LLMs that are more adept at interactive mathematical\nproblem solving and real world applications.",
      "tldr_zh": "本研究引入了MathChat基准，用于评估大型语言模型(LLMs)在多轮互动中的数学推理和指令遵循能力，发现这些模型虽在单轮问答中表现出色，但多轮任务中因持续推理和对话理解不足而表现欠佳。MathChat涵盖多种数学任务，包括多轮互动和开放生成，以全面测试LLMs的性能。针对这一局限，研究团队开发了MathChat sync，这是一个合成对话数据集，用于微调LLMs，提高其在对话中的互动和指令遵循能力。实验结果强调，使用多样化对话指令调优数据集是提升LLMs多轮数学推理能力的有效方向，从而推动其在实际交互式问题解决中的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19444v1",
      "published_date": "2024-05-29 18:45:55 UTC",
      "updated_date": "2024-05-29 18:45:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:27:03.204442"
    },
    {
      "arxiv_id": "2405.19423v1",
      "title": "Evaluating Vision-Language Models on Bistable Images",
      "title_zh": "翻译失败",
      "authors": [
        "Artemis Panagopoulou",
        "Coby Melkin",
        "Chris Callison-Burch"
      ],
      "abstract": "Bistable images, also known as ambiguous or reversible images, present visual\nstimuli that can be seen in two distinct interpretations, though not\nsimultaneously by the observer. In this study, we conduct the most extensive\nexamination of vision-language models using bistable images to date. We\nmanually gathered a dataset of 29 bistable images, along with their associated\nlabels, and subjected them to 116 different manipulations in brightness, tint,\nand rotation. We evaluated twelve different models in both classification and\ngenerative tasks across six model architectures. Our findings reveal that, with\nthe exception of models from the Idefics family and LLaVA1.5-13b, there is a\npronounced preference for one interpretation over another among the models, and\nminimal variance under image manipulations, with few exceptions on image\nrotations. Additionally, we compared the model preferences with humans, noting\nthat the models do not exhibit the same continuity biases as humans and often\ndiverge from human initial interpretations. We also investigated the influence\nof variations in prompts and the use of synonymous labels, discovering that\nthese factors significantly affect model interpretations more than image\nmanipulations showing a higher influence of the language priors on bistable\nimage interpretations compared to image-text training data. All code and data\nis open sourced.",
      "tldr_zh": "本研究评估了视觉语言模型（Vision-Language Models）在双稳图像（Bistable Images）上的表现，这些图像可被解释为两种不同方式。研究者收集了29张双稳图像及其标签，并进行了116种亮度、色调和旋转操作，测试了12个模型（涵盖6种架构）在分类和生成任务中的表现。结果显示，除Idefics家族和LLaVA1.5-13b模型外，大多数模型更偏向一种解释，且对图像操作变化（如旋转）不敏感。相比人类，模型缺乏连续性偏见，且初始解释往往与人类不同；此外，提示变化和同义标签对模型解释的影响远大于图像操作，突显了语言先验的更大作用。该研究开源了所有代码和数据，为模型在模糊视觉任务中的局限性提供了重要洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19423v1",
      "published_date": "2024-05-29 18:04:59 UTC",
      "updated_date": "2024-05-29 18:04:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:27:16.827998"
    },
    {
      "arxiv_id": "2405.19420v3",
      "title": "Learning Human-Aligned Representations with Contrastive Learning and Generative Similarity",
      "title_zh": "翻译失败",
      "authors": [
        "Raja Marjieh",
        "Sreejan Kumar",
        "Declan Campbell",
        "Liyi Zhang",
        "Gianluca Bencomo",
        "Jake Snell",
        "Thomas L. Griffiths"
      ],
      "abstract": "Humans rely on effective representations to learn from few examples and\nabstract useful information from sensory data. Inducing such representations in\nmachine learning models has been shown to improve their performance on various\nbenchmarks such as few-shot learning and robustness. However, finding effective\ntraining procedures to achieve that goal can be challenging as psychologically\nrich training data such as human similarity judgments are expensive to scale,\nand Bayesian models of human inductive biases are often intractable for\ncomplex, realistic domains. Here, we address this challenge by leveraging a\nBayesian notion of generative similarity whereby two data points are considered\nsimilar if they are likely to have been sampled from the same distribution.\nThis measure can be applied to complex generative processes, including\nprobabilistic programs. We incorporate generative similarity into a contrastive\nlearning objective to enable learning of embeddings that express human\ncognitive representations. We demonstrate the utility of our approach by\nshowing that it can be used to capture human-like representations of shape\nregularity, abstract Euclidean geometric concepts, and semantic hierarchies for\nnatural images.",
      "tldr_zh": "本文提出了一种利用对比学习（contrastive learning）和生成相似性（generative similarity）的方法，来学习与人类认知对齐的表示，从而提升机器学习模型在少样本学习和鲁棒性方面的性能。方法通过贝叶斯框架定义生成相似性，即判断两个数据点是否可能来自同一分布，并将其整合到对比学习目标中，以克服获取人类相似性判断等心理丰富训练数据的难题。实验结果表明，该方法成功捕捉了人类-like 表示，包括形状规则、抽象欧几里得几何概念以及自然图像的语义层次。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19420v3",
      "published_date": "2024-05-29 18:01:58 UTC",
      "updated_date": "2025-01-31 16:19:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:27:28.414702"
    },
    {
      "arxiv_id": "2405.19413v1",
      "title": "VisTA-SR: Improving the Accuracy and Resolution of Low-Cost Thermal Imaging Cameras for Agriculture",
      "title_zh": "VisTA-SR：改善低成本热成像摄像机的准确性和分辨率，用于农业",
      "authors": [
        "Heesup Yun",
        "Sassoum Lo",
        "Christine H. Diepenbrock",
        "Brian N. Bailey",
        "J. Mason Earles"
      ],
      "abstract": "Thermal cameras are an important tool for agricultural research because they\nallow for non-invasive measurement of plant temperature, which relates to\nimportant photochemical, hydraulic, and agronomic traits. Utilizing low-cost\nthermal cameras can lower the barrier to introducing thermal imaging in\nagricultural research and production. This paper presents an approach to\nimprove the temperature accuracy and image quality of low-cost thermal imaging\ncameras for agricultural applications. Leveraging advancements in computer\nvision techniques, particularly deep learning networks, we propose a method,\ncalled $\\textbf{VisTA-SR}$ ($\\textbf{Vis}$ual \\& $\\textbf{T}$hermal\n$\\textbf{A}$lignment and $\\textbf{S}$uper-$\\textbf{R}$esolution Enhancement)\nthat combines RGB and thermal images to enhance the capabilities of\nlow-resolution thermal cameras. The research includes calibration and\nvalidation of temperature measurements, acquisition of paired image datasets,\nand the development of a deep learning network tailored for agricultural\nthermal imaging. Our study addresses the challenges of image enhancement in the\nagricultural domain and explores the potential of low-cost thermal cameras to\nreplace high-resolution industrial cameras. Experimental results demonstrate\nthe effectiveness of our approach in enhancing temperature accuracy and image\nsharpness, paving the way for more accessible and efficient thermal imaging\nsolutions in agriculture.",
      "tldr_zh": "这篇论文提出了 VisTA-SR 方法，利用 RGB 和热成像相结合的深度学习网络，提升低成本热成像相机的温度准确性和图像质量，以应用于农业研究。VisTA-SR 通过温度测量校准、获取配对图像数据集以及开发针对农业领域的专属网络，解决了图像增强的挑战，并探讨了低成本相机取代高分辨率工业相机的潜力。实验结果显示，该方法显著提高了温度精确度和图像清晰度，为农业提供更经济高效的非侵入式热成像解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19413v1",
      "published_date": "2024-05-29 18:00:20 UTC",
      "updated_date": "2024-05-29 18:00:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:27:40.251969"
    },
    {
      "arxiv_id": "2405.19334v2",
      "title": "LLMs Meet Multimodal Generation and Editing: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Yingqing He",
        "Zhaoyang Liu",
        "Jingye Chen",
        "Zeyue Tian",
        "Hongyu Liu",
        "Xiaowei Chi",
        "Runtao Liu",
        "Ruibin Yuan",
        "Yazhou Xing",
        "Wenhai Wang",
        "Jifeng Dai",
        "Yong Zhang",
        "Wei Xue",
        "Qifeng Liu",
        "Yike Guo",
        "Qifeng Chen"
      ],
      "abstract": "With the recent advancement in large language models (LLMs), there is a\ngrowing interest in combining LLMs with multimodal learning. Previous surveys\nof multimodal large language models (MLLMs) mainly focus on multimodal\nunderstanding. This survey elaborates on multimodal generation and editing\nacross various domains, comprising image, video, 3D, and audio. Specifically,\nwe summarize the notable advancements with milestone works in these fields and\ncategorize these studies into LLM-based and CLIP/T5-based methods. Then, we\nsummarize the various roles of LLMs in multimodal generation and exhaustively\ninvestigate the critical technical components behind these methods and the\nmultimodal datasets utilized in these studies. Additionally, we dig into\ntool-augmented multimodal agents that can leverage existing generative models\nfor human-computer interaction. Lastly, we discuss the advancements in the\ngenerative AI safety field, investigate emerging applications, and discuss\nfuture prospects. Our work provides a systematic and insightful overview of\nmultimodal generation and processing, which is expected to advance the\ndevelopment of Artificial Intelligence for Generative Content (AIGC) and world\nmodels. A curated list of all related papers can be found at\nhttps://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",
      "tldr_zh": "这篇调查综述了大型语言模型(LLMs)在多模态生成和编辑中的应用，涵盖图像、视频、3D和音频等领域，将相关研究分类为LLM-based和CLIP/T5-based方法，并总结了LLMs的关键角色、技术组件以及使用的多模态数据集。该调查深入探讨了工具增强的多模态代理、生成AI安全问题、以及新兴应用和未来前景，提供了一个系统性概述，以推动生成内容人工智能(AIGC)和世界模型的发展。相关论文列表可通过GitHub链接获取。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM",
        "cs.SD"
      ],
      "primary_category": "cs.AI",
      "comment": "52 Pages with 16 Figures, 12 Tables, and 545 References. GitHub\n  Repository at:\n  https://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",
      "pdf_url": "http://arxiv.org/pdf/2405.19334v2",
      "published_date": "2024-05-29 17:59:20 UTC",
      "updated_date": "2024-06-09 11:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:27:52.443971"
    },
    {
      "arxiv_id": "2405.19332v3",
      "title": "Self-Exploring Language Models: Active Preference Elicitation for Online Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Shenao Zhang",
        "Donghan Yu",
        "Hiteshi Sharma",
        "Han Zhong",
        "Zhihan Liu",
        "Ziyi Yang",
        "Shuohang Wang",
        "Hany Hassan",
        "Zhaoran Wang"
      ],
      "abstract": "Preference optimization, particularly through Reinforcement Learning from\nHuman Feedback (RLHF), has achieved significant success in aligning Large\nLanguage Models (LLMs) to adhere to human intentions. Unlike offline alignment\nwith a fixed dataset, online feedback collection from humans or AI on model\ngenerations typically leads to more capable reward models and better-aligned\nLLMs through an iterative process. However, achieving a globally accurate\nreward model requires systematic exploration to generate diverse responses that\nspan the vast space of natural language. Random sampling from standard\nreward-maximizing LLMs alone is insufficient to fulfill this requirement. To\naddress this issue, we propose a bilevel objective optimistically biased\ntowards potentially high-reward responses to actively explore\nout-of-distribution regions. By solving the inner-level problem with the\nreparameterized reward function, the resulting algorithm, named Self-Exploring\nLanguage Models (SELM), eliminates the need for a separate RM and iteratively\nupdates the LLM with a straightforward objective. Compared to Direct Preference\nOptimization (DPO), the SELM objective reduces indiscriminate favor of unseen\nextrapolations and enhances exploration efficiency. Our experimental results\ndemonstrate that when fine-tuned on Zephyr-7B-SFT and Llama-3-8B-Instruct\nmodels, SELM significantly boosts the performance on instruction-following\nbenchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard\nacademic benchmarks in different settings. Our code and models are available at\nhttps://github.com/shenao-zhang/SELM.",
      "tldr_zh": "该研究提出Self-Exploring Language Models (SELM)，一种主动偏好elicitation方法，用于在线对齐Large Language Models (LLMs)，以解决传统RLHF (Reinforcement Learning from Human Feedback)中随机采样不足的问题。SELM采用双层目标（bilevel objective），通过乐观偏向潜在高奖励响应来系统探索分布外区域，并直接迭代更新LLMs，而无需单独的奖励模型（RM）。与Direct Preference Optimization (DPO)相比，SELM减少了对未见外推的盲目偏好，并提升探索效率。实验结果显示，在Zephyr-7B-SFT和Llama-3-8B-Instruct模型上微调后，SELM显著提高了指令遵循基准如MT-Bench和AlpacaEval 2.0的性能，以及其他学术基准的表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19332v3",
      "published_date": "2024-05-29 17:59:07 UTC",
      "updated_date": "2024-11-05 07:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:28:04.351274"
    },
    {
      "arxiv_id": "2405.19331v2",
      "title": "NPGA: Neural Parametric Gaussian Avatars",
      "title_zh": "NPGA: 神经参数高斯头像",
      "authors": [
        "Simon Giebenhain",
        "Tobias Kirschstein",
        "Martin Rünz",
        "Lourdes Agapito",
        "Matthias Nießner"
      ],
      "abstract": "The creation of high-fidelity, digital versions of human heads is an\nimportant stepping stone in the process of further integrating virtual\ncomponents into our everyday lives. Constructing such avatars is a challenging\nresearch problem, due to a high demand for photo-realism and real-time\nrendering performance. In this work, we propose Neural Parametric Gaussian\nAvatars (NPGA), a data-driven approach to create high-fidelity, controllable\navatars from multi-view video recordings. We build our method around 3D\nGaussian splatting for its highly efficient rendering and to inherit the\ntopological flexibility of point clouds. In contrast to previous work, we\ncondition our avatars' dynamics on the rich expression space of neural\nparametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we\ndistill the backward deformation field of our underlying NPHM into forward\ndeformations which are compatible with rasterization-based rendering. All\nremaining fine-scale, expression-dependent details are learned from the\nmulti-view videos. For increased representational capacity of our avatars, we\npropose per-Gaussian latent features that condition each primitives dynamic\nbehavior. To regularize this increased dynamic expressivity, we propose\nLaplacian terms on the latent features and predicted dynamics. We evaluate our\nmethod on the public NeRSemble dataset, demonstrating that NPGA significantly\noutperforms the previous state-of-the-art avatars on the self-reenactment task\nby 2.6 PSNR. Furthermore, we demonstrate accurate animation capabilities from\nreal-world monocular videos.",
      "tldr_zh": "本研究提出了一种数据驱动的方法，名为 Neural Parametric Gaussian Avatars (NPGA)，用于从多视图视频创建高保真、可控的人头头像，旨在实现照片级真实性和实时渲染性能。NPGA 以 3D Gaussian splatting 为基础，结合 Neural Parametric Head Models (NPHM) 的丰富表情空间，将后向变形场蒸馏成前向变形，并通过 per-Gaussian latent features 学习细微动态细节，同时使用 Laplacian terms 对这些特征和动态进行正则化。实验结果显示，NPGA 在 NeRSemble 数据集上的自重演任务中比现有最先进方法提高 2.6 PSNR，并支持从真实世界单目视频进行准确动画。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: see https://simongiebenhain.github.io/NPGA/ ; Youtube\n  Video: see https://youtu.be/t0S0OK7WnA4",
      "pdf_url": "http://arxiv.org/pdf/2405.19331v2",
      "published_date": "2024-05-29 17:58:09 UTC",
      "updated_date": "2024-09-13 17:41:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:28:16.743048"
    },
    {
      "arxiv_id": "2405.19327v4",
      "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series",
      "title_zh": "MAP-Neo：高性能且透明的双语大型语言模型系列",
      "authors": [
        "Ge Zhang",
        "Scott Qu",
        "Jiaheng Liu",
        "Chenchen Zhang",
        "Chenghua Lin",
        "Chou Leuang Yu",
        "Danny Pan",
        "Esther Cheng",
        "Jie Liu",
        "Qunshu Lin",
        "Raven Yuan",
        "Tuney Zheng",
        "Wei Pang",
        "Xinrun Du",
        "Yiming Liang",
        "Yinghao Ma",
        "Yizhi Li",
        "Ziyang Ma",
        "Bill Lin",
        "Emmanouil Benetos",
        "Huan Yang",
        "Junting Zhou",
        "Kaijing Ma",
        "Minghao Liu",
        "Morry Niu",
        "Noah Wang",
        "Quehry Que",
        "Ruibo Liu",
        "Sine Liu",
        "Shawn Guo",
        "Soren Gao",
        "Wangchunshu Zhou",
        "Xinyue Zhang",
        "Yizhi Zhou",
        "Yubo Wang",
        "Yuelin Bai",
        "Yuhan Zhang",
        "Yuxiang Zhang",
        "Zenith Wang",
        "Zhenzhu Yang",
        "Zijian Zhao",
        "Jiajun Zhang",
        "Wanli Ouyang",
        "Wenhao Huang",
        "Wenhu Chen"
      ],
      "abstract": "Large Language Models (LLMs) have made great strides in recent years to\nachieve unprecedented performance across different tasks. However, due to\ncommercial interest, the most competitive models like GPT, Gemini, and Claude\nhave been gated behind proprietary interfaces without disclosing the training\ndetails. Recently, many institutions have open-sourced several strong LLMs like\nLLaMA-3, comparable to existing closed-source LLMs. However, only the model's\nweights are provided with most details (e.g., intermediate checkpoints,\npre-training corpus, and training code, etc.) being undisclosed. To improve the\ntransparency of LLMs, the research community has formed to open-source truly\nopen LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training\ncorpus and training code) are being provided. These models have greatly\nadvanced the scientific study of these large models including their strengths,\nweaknesses, biases and risks. However, we observe that the existing truly open\nLLMs on reasoning, knowledge, and coding tasks are still inferior to existing\nstate-of-the-art LLMs with similar model sizes. To this end, we open-source\nMAP-Neo, a highly capable and transparent bilingual language model with 7B\nparameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the\nfirst fully open-sourced bilingual LLM with comparable performance compared to\nexisting state-of-the-art LLMs. Moreover, we open-source all details to\nreproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning\npipeline, checkpoints, and well-optimized training/evaluation framework are\nprovided. Finally, we hope our MAP-Neo will enhance and strengthen the open\nresearch community and inspire more innovations and creativities to facilitate\nthe further improvements of LLMs.",
      "tldr_zh": "该论文开源了MAP-Neo，这是一个7B参数的高性能透明双语Large Language Model (LLM)，旨在解决现有LLMs透明度不足的问题。MAP-Neo从零开始训练于4.5T高质量token上，并在推理、知识和编码任务上与类似规模的SOTA LLMs性能相当。论文提供了完整的开源细节，包括预训练语料、数据清理管道、检查点以及优化训练/评估框架，以促进开源社区的创新和发展。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "https://map-neo.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.19327v4",
      "published_date": "2024-05-29 17:57:16 UTC",
      "updated_date": "2024-07-10 16:55:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:28:28.972911"
    },
    {
      "arxiv_id": "2405.19323v2",
      "title": "Are Large Language Models Chameleons? An Attempt to Simulate Social Surveys",
      "title_zh": "翻译失败",
      "authors": [
        "Mingmeng Geng",
        "Sihong He",
        "Roberto Trotta"
      ],
      "abstract": "Can large language models (LLMs) simulate social surveys? To answer this\nquestion, we conducted millions of simulations in which LLMs were asked to\nanswer subjective questions. A comparison of different LLM responses with the\nEuropean Social Survey (ESS) data suggests that the effect of prompts on bias\nand variability is fundamental, highlighting major cultural, age, and gender\nbiases. We further discussed statistical methods for measuring the difference\nbetween LLM answers and survey data and proposed a novel measure inspired by\nJaccard similarity, as LLM-generated responses are likely to have a smaller\nvariance. Our experiments also reveal that it is important to analyze the\nrobustness and variability of prompts before using LLMs to simulate social\nsurveys, as their imitation abilities are approximate at best.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 是否能模拟社会调查，通过进行数百万次模拟，让 LLMs 回答主观问题并与欧洲社会调查 (ESS) 数据比较。研究发现，提示词对 LLMs 的偏差和变异性影响巨大，导致显著的文化、年龄和性别偏差，且 LLMs 生成的响应变异性较小。作者提出了一个新统计措施，受 Jaccard 相似性启发，用于衡量 LLM 答案与真实调查数据的差异，并强调在应用 LLMs 模拟调查前需分析提示词的稳健性和变异性，因为其模仿能力仅为近似。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "17 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.19323v2",
      "published_date": "2024-05-29 17:54:22 UTC",
      "updated_date": "2024-10-21 17:05:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:28:40.820056"
    },
    {
      "arxiv_id": "2405.19320v4",
      "title": "Value-Incentivized Preference Optimization: A Unified Approach to Online and Offline RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Shicong Cen",
        "Jincheng Mei",
        "Katayoon Goshvadi",
        "Hanjun Dai",
        "Tong Yang",
        "Sherry Yang",
        "Dale Schuurmans",
        "Yuejie Chi",
        "Bo Dai"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has demonstrated great\npromise in aligning large language models (LLMs) with human preference.\nDepending on the availability of preference data, both online and offline RLHF\nare active areas of investigation. A key bottleneck is understanding how to\nincorporate uncertainty estimation in the reward function learned from the\npreference data for RLHF, regardless of how the preference data is collected.\nWhile the principles of optimism or pessimism under uncertainty are\nwell-established in standard reinforcement learning (RL), a\npractically-implementable and theoretically-grounded form amenable to large\nlanguage models is not yet available, as standard techniques for constructing\nconfidence intervals become intractable under arbitrary policy\nparameterizations.\n  In this paper, we introduce a unified approach to online and offline RLHF --\nvalue-incentivized preference optimization (VPO) -- which regularizes the\nmaximum-likelihood estimate of the reward function with the corresponding value\nfunction, modulated by a $\\textit{sign}$ to indicate whether the optimism or\npessimism is chosen. VPO also directly optimizes the policy with implicit\nreward modeling, and therefore shares a simpler RLHF pipeline similar to direct\npreference optimization. Theoretical guarantees of VPO are provided for both\nonline and offline settings, matching the rates of their standard RL\ncounterparts. Moreover, experiments on text summarization and dialog verify the\npracticality and effectiveness of VPO.",
      "tldr_zh": "该论文提出了一种统一方法——Value-Incentivized Preference Optimization (VPO)，用于处理在线和离线 Reinforcement Learning from Human Feedback (RLHF)，以更好地将大型语言模型 (LLMs) 调整为符合人类偏好。VPO 通过价值函数调节奖励函数的极大似然估计，并根据乐观或悲观策略添加正则化，同时直接优化策略而非显式建模奖励，从而简化了 RLHF 流程。理论分析显示，VPO 在在线和离线设置中达到了与标准 RL 相当的保证率；实验在文本摘要和对话任务上验证了其有效性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.19320v4",
      "published_date": "2024-05-29 17:51:42 UTC",
      "updated_date": "2025-02-19 00:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:29:01.180722"
    },
    {
      "arxiv_id": "2406.18563v1",
      "title": "Interdisciplinary Expertise to Advance Equitable Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Chloe R. Bennett",
        "Heather Cole-Lewis",
        "Stephanie Farquhar",
        "Naama Haamel",
        "Boris Babenko",
        "Oran Lang",
        "Mat Fleck",
        "Ilana Traynis",
        "Charles Lau",
        "Ivor Horn",
        "Courtney Lyles"
      ],
      "abstract": "The field of artificial intelligence (AI) is rapidly influencing health and\nhealthcare, but bias and poor performance persists for populations who face\nwidespread structural oppression. Previous work has clearly outlined the need\nfor more rigorous attention to data representativeness and model performance to\nadvance equity and reduce bias. However, there is an opportunity to also\nimprove the explainability of AI by leveraging best practices of social\nepidemiology and health equity to help us develop hypotheses for associations\nfound. In this paper, we focus on explainable AI (XAI) and describe a framework\nfor interdisciplinary expert panel review to discuss and critically assess AI\nmodel explanations from multiple perspectives and identify areas of bias and\ndirections for future research. We emphasize the importance of the\ninterdisciplinary expert panel to produce more accurate, equitable\ninterpretations which are historically and contextually informed.\nInterdisciplinary panel discussions can help reduce bias, identify potential\nconfounders, and identify opportunities for additional research where there are\ngaps in the literature. In turn, these insights can suggest opportunities for\nAI model improvement.",
      "tldr_zh": "这篇论文探讨了人工智能（AI）在健康领域存在的偏见问题，强调需要通过数据代表性和模型性能的优化来促进公平和可解释性（Explainable AI, XAI）。作者提出一个框架，利用跨学科专家小组从多个视角审查 AI 模型解释，结合社会流行病学和健康公平的最佳实践，以识别偏见、潜在混杂因素和研究空白。最终，这种方法有助于生成更准确、基于历史和语境的解释，并为改进 AI 模型提供宝贵见解，从而推动更公平的 AI 应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.18563v1",
      "published_date": "2024-05-29 17:45:38 UTC",
      "updated_date": "2024-05-29 17:45:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:29:14.077859"
    },
    {
      "arxiv_id": "2405.19317v4",
      "title": "Generalized Neyman Allocation for Locally Minimax Optimal Best-Arm Identification",
      "title_zh": "翻译失败",
      "authors": [
        "Masahiro Kato"
      ],
      "abstract": "This study investigates an asymptotically locally minimax optimal algorithm\nfor fixed-budget best-arm identification (BAI). We propose the Generalized\nNeyman Allocation (GNA) algorithm and demonstrate that its worst-case upper\nbound on the probability of misidentifying the best arm aligns with the\nworst-case lower bound under the small-gap regime, where the gap between the\nexpected outcomes of the best and suboptimal arms is small. Our lower and upper\nbounds are tight, matching exactly including constant terms within the\nsmall-gap regime. The GNA algorithm generalizes the Neyman allocation for\ntwo-armed bandits (Neyman, 1934; Kaufmann et al., 2016) and refines existing\nBAI algorithms, such as those proposed by Glynn & Juneja (2004). By proposing\nan asymptotically minimax optimal algorithm, we address the longstanding open\nissue in BAI (Kaufmann, 2020) and treatment choice (Kasy & Sautmann, 202) by\nrestricting a class of distributions to the small-gap regimes.",
      "tldr_zh": "这篇论文提出了 Generalized Neyman Allocation (GNA) 算法，用于固定预算的最佳手臂识别 (BAI)，旨在实现局部最小最大最优性能。GNA 算法推广了 Neyman allocation 的概念，并在小-gap regime 下证明了其最坏情况错误概率的上界与下界精确匹配，包括常数项，从而比现有算法如 Glynn & Juneja (2004) 的方法更精确。最终，该研究解决了 BAI 和治疗选择中的长期开放问题，为小差距场景下的决策优化提供了理论基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "econ.EM",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19317v4",
      "published_date": "2024-05-29 17:43:13 UTC",
      "updated_date": "2025-02-02 18:50:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:29:25.467451"
    },
    {
      "arxiv_id": "2405.19313v2",
      "title": "Language Models Trained to do Arithmetic Predict Human Risky and Intertemporal Choice",
      "title_zh": "训练进行算术运算的语言模型预测人类的风险决策和跨期选择",
      "authors": [
        "Jian-Qiao Zhu",
        "Haijiang Yan",
        "Thomas L. Griffiths"
      ],
      "abstract": "The observed similarities in the behavior of humans and Large Language Models\n(LLMs) have prompted researchers to consider the potential of using LLMs as\nmodels of human cognition. However, several significant challenges must be\naddressed before LLMs can be legitimately regarded as cognitive models. For\ninstance, LLMs are trained on far more data than humans typically encounter,\nand may have been directly trained on human data in specific cognitive tasks or\naligned with human preferences. Consequently, the origins of these behavioral\nsimilarities are not well understood. In this paper, we propose a novel way to\nenhance the utility of LLMs as cognitive models. This approach involves (i)\nleveraging computationally equivalent tasks that both an LLM and a rational\nagent need to master for solving a cognitive problem and (ii) examining the\nspecific task distributions required for an LLM to exhibit human-like\nbehaviors. We apply this approach to decision-making -- specifically risky and\nintertemporal choice -- where the key computationally equivalent task is the\narithmetic of expected value calculations. We show that an LLM pretrained on an\necologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts\nhuman behavior better than many traditional cognitive models. Pretraining LLMs\non ecologically valid arithmetic datasets is sufficient to produce a strong\ncorrespondence between these models and human decision-making. Our results also\nsuggest that LLMs used as cognitive models should be carefully investigated via\nablation studies of the pretraining data.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）作为人类认知模型的可能性，提出一种新方法：通过利用计算等价任务（如预期价值计算的算术），并分析LLMs需要哪些任务分布来模仿人类行为。研究者开发了Arithmetic-GPT，将LLMs预训练于生态有效的算术数据集，应用于风险选择和跨期决策领域。结果显示，Arithmetic-GPT比许多传统认知模型更准确地预测人类行为，证明了预训练数据的重要性，并建议通过删除研究（ablation studies）来进一步验证LLMs的认知建模效用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "econ.GN",
        "q-fin.EC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19313v2",
      "published_date": "2024-05-29 17:37:14 UTC",
      "updated_date": "2025-05-06 01:26:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:29:37.934759"
    },
    {
      "arxiv_id": "2405.19300v3",
      "title": "Measuring and Mitigating Bias for Tabular Datasets with Multiple Protected Attributes",
      "title_zh": "测量与缓解具有多个受",
      "authors": [
        "Manh Khoi Duong",
        "Stefan Conrad"
      ],
      "abstract": "Motivated by the recital (67) of the current corrigendum of the AI Act in the\nEuropean Union, we propose and present measures and mitigation strategies for\ndiscrimination in tabular datasets. We specifically focus on datasets that\ncontain multiple protected attributes, such as nationality, age, and sex. This\nmakes measuring and mitigating bias more challenging, as many existing methods\nare designed for a single protected attribute. This paper comes with a twofold\ncontribution: Firstly, new discrimination measures are introduced. These\nmeasures are categorized in our framework along with existing ones, guiding\nresearchers and practitioners in choosing the right measure to assess the\nfairness of the underlying dataset. Secondly, a novel application of an\nexisting bias mitigation method, FairDo, is presented. We show that this\nstrategy can mitigate any type of discrimination, including intersectional\ndiscrimination, by transforming the dataset. By conducting experiments on\nreal-world datasets (Adult, Bank, COMPAS), we demonstrate that de-biasing\ndatasets with multiple protected attributes is possible. All transformed\ndatasets show a reduction in discrimination, on average by 28%. Further, these\ndatasets do not compromise any of the tested machine learning models'\nperformances significantly compared to the original datasets. Conclusively,\nthis study demonstrates the effectiveness of the mitigation strategy used and\ncontributes to the ongoing discussion on the implementation of the European\nUnion's AI Act.",
      "tldr_zh": "本研究受欧盟 AI Act 启发，提出测量和缓解表格数据集偏见的方法，特别针对包含多个保护 attributes（如国籍、年龄和性别）的复杂数据集。论文的主要贡献包括：引入新的歧视测量指标，并将其与现有指标分类到一个框架中，以指导研究者选择合适的公平性评估工具；以及创新应用现有的偏见缓解方法 FairDo，通过数据集转换来减轻包括交叉歧视在内的各种歧视。实验在真实数据集（Adult、Bank、COMPAS）上进行，结果显示经处理的数据集平均减少28%的歧视，同时未显著影响机器学习模型的性能。该工作证明了缓解策略的有效性，并为欧盟 AI Act 的实施提供实际贡献。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submission accepted in AEQUITAS'24 (co-located with ECAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.19300v3",
      "published_date": "2024-05-29 17:27:08 UTC",
      "updated_date": "2024-10-01 17:39:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:29:50.349784"
    },
    {
      "arxiv_id": "2405.19296v2",
      "title": "Neural Isometries: Taming Transformations for Equivariant ML",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas W. Mitchel",
        "Michael Taylor",
        "Vincent Sitzmann"
      ],
      "abstract": "Real-world geometry and 3D vision tasks are replete with challenging\nsymmetries that defy tractable analytical expression. In this paper, we\nintroduce Neural Isometries, an autoencoder framework which learns to map the\nobservation space to a general-purpose latent space wherein encodings are\nrelated by isometries whenever their corresponding observations are\ngeometrically related in world space. Specifically, we regularize the latent\nspace such that maps between encodings preserve a learned inner product and\ncommute with a learned functional operator, in the same manner as rigid-body\ntransformations commute with the Laplacian. This approach forms an effective\nbackbone for self-supervised representation learning, and we demonstrate that a\nsimple off-the-shelf equivariant network operating in the pre-trained latent\nspace can achieve results on par with meticulously-engineered, handcrafted\nnetworks designed to handle complex, nonlinear symmetries. Furthermore,\nisometric maps capture information about the respective transformations in\nworld space, and we show that this allows us to regress camera poses directly\nfrom the coefficients of the maps between encodings of adjacent views of a\nscene.",
      "tldr_zh": "本研究提出Neural Isometries，一种autoencoder框架，用于处理真实世界几何和3D视觉任务中的复杂对称性。该框架将观察空间映射到通用潜在空间(latent space)，通过正规化编码间的等距映射(isometries)来确保映射保留学习的内积和函数算子，从而模拟刚体变换与Laplacian的交换特性。实验结果显示，该方法支持有效的自监督表示学习，一种简单的现成equivariant network在预训练潜在空间中可与专门设计处理非线性对称性的网络匹敌，并能从编码映射系数直接回归相机位姿(camera poses)。这为处理挑战性变换的机器学习提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19296v2",
      "published_date": "2024-05-29 17:24:25 UTC",
      "updated_date": "2024-10-29 23:55:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:30:11.840023"
    },
    {
      "arxiv_id": "2405.19284v1",
      "title": "Optimizing Foundation Model Inference on a Many-tiny-core Open-source RISC-V Platform",
      "title_zh": "翻译失败",
      "authors": [
        "Viviane Potocnik",
        "Luca Colagrande",
        "Tim Fischer",
        "Luca Bertaccini",
        "Daniele Jahier Pagliari",
        "Alessio Burrello",
        "Luca Benini"
      ],
      "abstract": "Transformer-based foundation models have become crucial for various domains,\nmost notably natural language processing (NLP) or computer vision (CV). These\nmodels are predominantly deployed on high-performance GPUs or hardwired\naccelerators with highly customized, proprietary instruction sets. Until now,\nlimited attention has been given to RISC-V-based general-purpose platforms. In\nour work, we present the first end-to-end inference results of transformer\nmodels on an open-source many-tiny-core RISC-V platform implementing\ndistributed Softmax primitives and leveraging ISA extensions for SIMD\nfloating-point operand streaming and instruction repetition, as well as\nspecialized DMA engines to minimize costly main memory accesses and to tolerate\ntheir latency. We focus on two foundational transformer topologies,\nencoder-only and decoder-only models. For encoder-only models, we demonstrate a\nspeedup of up to 12.8x between the most optimized implementation and the\nbaseline version. We reach over 79% FPU utilization and 294 GFLOPS/W,\noutperforming State-of-the-Art (SoA) accelerators by more than 2x utilizing the\nHW platform while achieving comparable throughput per computational unit. For\ndecoder-only topologies, we achieve 16.1x speedup in the Non-Autoregressive\n(NAR) mode and up to 35.6x speedup in the Autoregressive (AR) mode compared to\nthe baseline implementation. Compared to the best SoA dedicated accelerator, we\nachieve 2.04x higher FPU utilization.",
      "tldr_zh": "这篇论文优化了 Transformer 基础模型在开源 RISC-V 平台的推理过程，针对编码器-only 和解码器-only 模型，首次实现了端到端推理结果。研究通过分布式 Softmax 基元、SIMD 浮点操作流和指令重复的 ISA 扩展，以及专门的 DMA 引擎，减少了主内存访问延迟并提高了 FPU 利用率。实验结果显示，对于编码器-only 模型，实现了高达 12.8x 的加速、79% FPU 利用率和 294 GFLOPS/W 的能效，比 State-of-the-Art (SoA) 加速器高出 2x；对于解码器-only 模型，在 Non-Autoregressive (NAR) 模式下加速 16.1x，在 Autoregressive (AR) 模式下加速 35.6x，并提升 FPU 利用率 2.04x。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR",
        "C.4; C.3; I.2"
      ],
      "primary_category": "cs.DC",
      "comment": "14 pages, 10 figures, 4 tables, IEEE Transactions on Circuits and\n  Systems for Artificial Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2405.19284v1",
      "published_date": "2024-05-29 17:16:59 UTC",
      "updated_date": "2024-05-29 17:16:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:30:17.105801"
    },
    {
      "arxiv_id": "2405.19262v3",
      "title": "Weak-to-Strong Search: Align Large Language Models via Searching over Small Language Models",
      "title_zh": "弱到强搜索：通过在小型语言模型上搜索来对齐大型语言模型",
      "authors": [
        "Zhanhui Zhou",
        "Zhixuan Liu",
        "Jie Liu",
        "Zhichen Dong",
        "Chao Yang",
        "Yu Qiao"
      ],
      "abstract": "Large language models are usually fine-tuned to align with human preferences.\nHowever, fine-tuning a large language model can be challenging. In this work,\nwe introduce $\\textit{weak-to-strong search}$, framing the alignment of a large\nlanguage model as a test-time greedy search to maximize the log-probability\ndifference between small tuned and untuned models while sampling from the\nfrozen large model. This method serves both as (1) a compute-efficient model\nup-scaling strategy that avoids directly tuning the large model and as (2) an\ninstance of weak-to-strong generalization that enhances a strong model with\nweak test-time guidance. Empirically, we demonstrate the flexibility of\nweak-to-strong search across different tasks. In controlled-sentiment\ngeneration and summarization, we use tuned and untuned $\\texttt{gpt2}$s to\nimprove the alignment of large models without additional training. Crucially,\nin a more difficult instruction-following benchmark, AlpacaEval 2.0, we show\nthat reusing off-the-shelf small models (e.g., $\\texttt{zephyr-7b-beta}$ and\nits untuned version) can improve the length-controlled win rates of both\nwhite-box and black-box large models against $\\texttt{gpt-4-turbo}$ (e.g.,\n$34.4\\% \\rightarrow 37.9\\%$ for $\\texttt{Llama-3-70B-Instruct}$ and $16.0\\%\n\\rightarrow 20.1\\%$ for $\\texttt{gpt-3.5-turbo-instruct}$), despite the small\nmodels' low win rates $\\approx 10.0\\%$.",
      "tldr_zh": "本研究提出 weak-to-strong search 方法，通过测试时的贪婪搜索在小型语言模型上最大化 log-probability 差异，从而对齐大型语言模型（Large Language Models），避免直接微调大型模型，同时实现弱到强泛化。实验显示，该方法在受控情感生成和总结任务中使用调优及未调优的 gpt2 模型即可提升大型模型的对齐效果，而无需额外训练。在 AlpacaEval 2.0 指令遵循基准上，重用现成的小型模型（如 zephyr-7b-beta）使 Llama-3-70B-Instruct 的胜率从 34.4% 提高到 37.9%，gpt-3.5-turbo-instruct 从 16.0% 提高到 20.1%，尽管小型模型的胜率仅约 10%。这为计算高效的模型升级提供了新策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19262v3",
      "published_date": "2024-05-29 16:55:32 UTC",
      "updated_date": "2024-11-19 13:27:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:30:28.143755"
    },
    {
      "arxiv_id": "2405.19261v2",
      "title": "Faster Cascades via Speculative Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Harikrishna Narasimhan",
        "Wittawat Jitkrittum",
        "Ankit Singh Rawat",
        "Seungyeon Kim",
        "Neha Gupta",
        "Aditya Krishna Menon",
        "Sanjiv Kumar"
      ],
      "abstract": "Cascades and speculative decoding are two common approaches to improving\nlanguage models' inference efficiency. Both approaches involve interleaving\nmodels of different sizes, but via fundamentally distinct mechanisms: cascades\nemploy a deferral rule that invokes the larger model only for \"hard\" inputs,\nwhile speculative decoding uses speculative execution to primarily invoke the\nlarger model in parallel verification mode. These mechanisms offer different\nbenefits: empirically, cascades offer better cost-quality trade-offs, often\neven outperforming the large model, while theoretically, speculative decoding\noffers a guarantee of quality-neutrality. In this paper, we leverage the best\nof both these approaches by designing new speculative cascading techniques that\nimplement their deferral rule through speculative execution. We characterize\nthe optimal deferral rule for our speculative cascades, and employ a plug-in\napproximation to the optimal rule. Experiments with Gemma and T5 models on a\nrange of language benchmarks show that our approach yields better cost quality\ntrade-offs than cascading and speculative decoding baselines.",
      "tldr_zh": "本研究探讨了提升语言模型推理效率的两种方法——Cascades 和 Speculative Decoding，前者通过 deferral rule 只在“hard”输入时调用更大模型，提供更好的成本-质量权衡；后者则利用推测执行确保质量中性。论文提出了一种新的 Speculative Cascading 技术，将 Cascades 的 deferral rule 与 Speculative Decoding 的并行验证机制结合，并通过表征最优 deferral rule 和 plug-in 近似来实现优化。实验在 Gemma 和 T5 模型上进行，显示该方法在各种语言基准测试中比传统基线提供了更优的成本-质量权衡。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19261v2",
      "published_date": "2024-05-29 16:55:08 UTC",
      "updated_date": "2024-10-21 18:12:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:30:37.666559"
    },
    {
      "arxiv_id": "2405.19255v3",
      "title": "Towards Next-Generation Urban Decision Support Systems through AI-Powered Construction of Scientific Ontology using Large Language Models -- A Case in Optimizing Intermodal Freight Transportation",
      "title_zh": "翻译失败",
      "authors": [
        "Jose Tupayachi",
        "Haowen Xu",
        "Olufemi A. Omitaomu",
        "Mustafa Can Camur",
        "Aliza Sharmin",
        "Xueping Li"
      ],
      "abstract": "The incorporation of Artificial Intelligence (AI) models into various\noptimization systems is on the rise. Yet, addressing complex urban and\nenvironmental management problems normally requires in-depth domain science and\ninformatics expertise. This expertise is essential for deriving data and\nsimulation-driven for informed decision support. In this context, we\ninvestigate the potential of leveraging the pre-trained Large Language Models\n(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated\nworkflow that encompasses natural language processing, methontology-based\nprompt tuning, and transformers. This workflow automates the creation of\nscenario-based ontology using existing research articles and technical manuals\nof urban datasets and simulations. The outcomes of our methodology are\nknowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).\nThese facilitate the development of urban decision support systems by enhancing\nthe data and metadata modeling, the integration of complex datasets, the\ncoupling of multi-domain simulation models, and the formulation of\ndecision-making metrics and workflow. The feasibility of our methodology is\nevaluated through a comparative analysis that juxtaposes our AI-generated\nontology with the well-known Pizza Ontology employed in tutorials for popular\nontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of\noptimizing the complex urban system of multi-modal freight transportation by\ngenerating anthologies of various domain data and simulations to support\ninformed decision-making.",
      "tldr_zh": "本研究探讨了利用大型语言模型（LLMs）如ChatGPT API构建科学本体，以提升下一代城市决策支持系统（Urban Decision Support Systems）。他们提出一个集成工作流，包括自然语言处理（NLP）、基于Methontology的提示调整和Transformers，来自动化从现有研究文章和技术手册中生成场景化本体，从而创建知识图谱（如OWL、RDF、SPARQL）。结果显示，该方法提高了数据建模、多数据集整合和多领域模拟模型耦合的能力，并在优化多模式货运运输（Intermodal Freight Transportation）的真实案例中验证了其可行性，通过与Pizza Ontology的比较证明了AI生成的本体有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19255v3",
      "published_date": "2024-05-29 16:40:31 UTC",
      "updated_date": "2024-09-06 20:04:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:30:50.689884"
    },
    {
      "arxiv_id": "2405.19250v1",
      "title": "Kotlin ML Pack: Technical Report",
      "title_zh": "翻译失败",
      "authors": [
        "Sergey Titov",
        "Mikhail Evtikhiev",
        "Anton Shapkin",
        "Oleg Smirnov",
        "Sergei Boytsov",
        "Sergei Boytsov",
        "Dariia Karaeva",
        "Maksim Sheptyakov",
        "Mikhail Arkhipov",
        "Timofey Bryksin",
        "Egor Bogomolov"
      ],
      "abstract": "In this technical report, we present three novel datasets of Kotlin code:\nKStack, KStack-clean, and KExercises. We also describe the results of\nfine-tuning CodeLlama and DeepSeek models on this data. Additionally, we\npresent a version of the HumanEval benchmark rewritten by human experts into\nKotlin - both the solutions and the tests. Our results demonstrate that small,\nhigh-quality datasets (KStack-clean and KExercises) can significantly improve\nmodel performance on code generation tasks, achieving up to a 16-point increase\nin pass rate on the HumanEval benchmark. Lastly, we discuss potential future\nwork in the field of improving language modeling for Kotlin, including the use\nof static analysis tools in the learning process and the introduction of more\nintricate and realistic benchmarks.",
      "tldr_zh": "本技术报告介绍了三个新的Kotlin代码数据集：KStack、KStack-clean和KExercises，并描述了在这些数据集上细调CodeLlama和DeepSeek模型的结果。该报告还提供了一个由专家重写的Kotlin版本的HumanEval基准，包括解决方案和测试。结果显示，使用小型高品质数据集（如KStack-clean和KExercises）能显著提升模型在代码生成任务上的性能，使HumanEval基准的通过率提高多达16分。最后，讨论了未来工作，包括整合静态分析工具和开发更复杂基准以改进Kotlin语言建模。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19250v1",
      "published_date": "2024-05-29 16:33:50 UTC",
      "updated_date": "2024-05-29 16:33:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:31:01.530639"
    },
    {
      "arxiv_id": "2405.19243v1",
      "title": "Challenge-Device-Synthesis: A multi-disciplinary approach for the development of social innovation competences for students of Artificial Intelligence",
      "title_zh": "Challenge-Device-Synthesis：一种多学科方法，用于发展人工智能学生社会创新能力",
      "authors": [
        "Matías Bilkis",
        "Joan Moya Kohler",
        "Fernando Vilariño"
      ],
      "abstract": "The advent of Artificial Intelligence is expected to imply profound changes\nin the short-term. It is therefore imperative for Academia, and particularly\nfor the Computer Science scope, to develop cross-disciplinary tools that bond\nAI developments to their social dimension. To this aim, we introduce the\nChallenge-Device-Synthesis methodology (CDS), in which a specific challenge is\npresented to the students of AI, who are required to develop a device as a\nsolution for the challenge. The device becomes the object of study for the\ndifferent dimensions of social transformation, and the conclusions addressed by\nthe students during the discussion around the device are presented in a\nsynthesis piece in the shape of a 10-page scientific paper. The latter is\nevaluated taking into account both the depth of analysis and the level to which\nit genuinely reflects the social transformations associated with the proposed\nAI-based device. We provide data obtained during the pilot for the\nimplementation phase of CDS within the subject of Social Innovation, a 6-ECTS\nsubject from the 6th semester of the Degree of Artificial Intelligence,\nUAB-Barcelona. We provide details on temporalisation, task distribution,\nmethodological tools used and assessment delivery procedure, as well as\nqualitative analysis of the results obtained.",
      "tldr_zh": "本研究引入了Challenge-Device-Synthesis (CDS)方法，一种多学科教学框架，旨在帮助人工智能 (AI) 学生发展社会创新能力，通过将AI技术与社会维度相结合。CDS要求学生针对特定挑战开发AI-based设备，然后分析其在社会转型中的影响，并以一篇10页科学论文的形式总结讨论和结论。论文提供了在UAB-Barcelona人工智能学位课程中试点实施的数据，包括时间安排、任务分配、评估工具和定性分析结果，展示了该方法在提升学生跨学科分析深度方面的有效性。",
      "categories": [
        "cs.AI",
        "physics.ed-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted as contribution for EDULEARN24 - 16th annual International\n  Conference on Education and New Learning Technologies",
      "pdf_url": "http://arxiv.org/pdf/2405.19243v1",
      "published_date": "2024-05-29 16:24:38 UTC",
      "updated_date": "2024-05-29 16:24:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:31:16.498676"
    },
    {
      "arxiv_id": "2405.19238v2",
      "title": "Human-Aware Belief Revision: A Cognitively Inspired Framework for Explanation-Guided Revision of Human Models",
      "title_zh": "翻译失败",
      "authors": [
        "Stylianos Loukas Vasileiou",
        "William Yeoh"
      ],
      "abstract": "Traditional belief revision frameworks often rely on the principle of\nminimalism, which advocates minimal changes to existing beliefs. However,\nresearch in human cognition suggests that people are inherently driven to seek\nexplanations for inconsistencies, thereby striving for explanatory\nunderstanding rather than minimal changes when revising beliefs. Traditional\nframeworks often fail to account for these cognitive patterns, relying instead\non formal principles that may not reflect actual human reasoning. To address\nthis gap, we introduce Human-Aware Belief Revision, a cognitively-inspired\nframework for modeling human belief revision dynamics, where given a human\nmodel and an explanation for an explanandum, revises the model in a non-minimal\nway that aligns with human cognition. Finally, we conduct two human-subject\nstudies to empirically evaluate our framework under real-world scenarios. Our\nfindings support our hypotheses and provide insights into the strategies people\nemploy when resolving inconsistencies, offering some guidance for developing\nmore effective human-aware AI systems.",
      "tldr_zh": "本研究指出，传统信念 revision 框架依赖最小主义原则，但这与人类认知模式不符，因为人们更倾向于通过寻求解释来解决不一致性，而不是进行最小变化。针对这一问题，作者提出 Human-Aware Belief Revision，这是一个认知灵感框架，能够基于给定的人类模型和解释，进行非最小修正以更好地模拟人类推理过程。研究通过两个人类主题实验验证了框架的有效性，结果支持了假设，并为开发更有效的 human-aware AI 系统提供了宝贵指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19238v2",
      "published_date": "2024-05-29 16:20:51 UTC",
      "updated_date": "2024-08-22 14:17:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:31:29.555139"
    },
    {
      "arxiv_id": "2405.19237v1",
      "title": "ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron Pruning",
      "title_zh": "翻译失败",
      "authors": [
        "Ruchika Chavhan",
        "Da Li",
        "Timothy Hospedales"
      ],
      "abstract": "While large-scale text-to-image diffusion models have demonstrated impressive\nimage-generation capabilities, there are significant concerns about their\npotential misuse for generating unsafe content, violating copyright, and\nperpetuating societal biases. Recently, the text-to-image generation community\nhas begun addressing these concerns by editing or unlearning undesired concepts\nfrom pre-trained models. However, these methods often involve data-intensive\nand inefficient fine-tuning or utilize various forms of token remapping,\nrendering them susceptible to adversarial jailbreaks. In this paper, we present\na simple and effective training-free approach, ConceptPrune, wherein we first\nidentify critical regions within pre-trained models responsible for generating\nundesirable concepts, thereby facilitating straightforward concept unlearning\nvia weight pruning. Experiments across a range of concepts including artistic\nstyles, nudity, object erasure, and gender debiasing demonstrate that target\nconcepts can be efficiently erased by pruning a tiny fraction, approximately\n0.12% of total weights, enabling multi-concept erasure and robustness against\nvarious white-box and black-box adversarial attacks.",
      "tldr_zh": "该研究针对大型文本到图像扩散模型可能生成不安全内容、侵犯版权或强化社会偏见的问题，提出了一种简单有效的无训练方法：ConceptPrune。方法通过识别预训练模型中负责不期望概念的关键区域，并通过权重修剪（weight pruning）来删除这些概念，仅需修剪约0.12%的总权重即可实现高效概念编辑。实验在艺术风格、裸露、对象删除和性别去偏见等概念上验证了其效果，支持多概念删除，并展示了对白盒和黑盒对抗攻击（adversarial attacks）的鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19237v1",
      "published_date": "2024-05-29 16:19:37 UTC",
      "updated_date": "2024-05-29 16:19:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:31:37.585851"
    },
    {
      "arxiv_id": "2405.19236v1",
      "title": "Exploring the impact of traffic signal control and connected and automated vehicles on intersections safety: A deep reinforcement learning approach",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Hossein Karbasi",
        "Hao Yang",
        "Saiedeh Razavi"
      ],
      "abstract": "In transportation networks, intersections pose significant risks of\ncollisions due to conflicting movements of vehicles approaching from different\ndirections. To address this issue, various tools can exert influence on traffic\nsafety both directly and indirectly. This study focuses on investigating the\nimpact of adaptive signal control and connected and automated vehicles (CAVs)\non intersection safety using a deep reinforcement learning approach. The\nobjective is to assess the individual and combined effects of CAVs and adaptive\ntraffic signal control on traffic safety, considering rear-end and crossing\nconflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals\nand driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses\nTime To Collision (TTC) metric to evaluate safety. The findings demonstrate a\nsignificant reduction in rear-end and crossing conflicts through the combined\nimplementation of CAVs and DQNs-based traffic signal control. Additionally, the\nlong-term positive effects of CAVs on safety are similar to the short-term\neffects of combined CAVs and DQNs-based traffic signal control. Overall, the\nstudy emphasizes the potential benefits of integrating CAVs and adaptive\ntraffic signal control approaches in order to enhance traffic safety. The\nfindings of this study could provide valuable insights for city officials and\ntransportation authorities in developing effective strategies to improve safety\nat signalized intersections.",
      "tldr_zh": "本研究探讨了自适应信号控制和连接自动车辆(CAVs)对交叉路口安全的个体及组合影响，使用Deep Q Network (DQN)来调节交通信号和车辆行为，并以Time To Collision (TTC)指标评估后端及交叉冲突。结果表明，CAVs与DQN-based信号控制的结合显著减少了冲突，CAVs的长期安全效果类似于短期内结合信号控制的效果。该研究强调了整合CAVs和自适应信号控制的潜力，为城市官员和交通当局制定安全策略提供宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "TRB 103nd Annual Meeting",
      "pdf_url": "http://arxiv.org/pdf/2405.19236v1",
      "published_date": "2024-05-29 16:17:19 UTC",
      "updated_date": "2024-05-29 16:17:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:31:50.427098"
    },
    {
      "arxiv_id": "2405.19229v1",
      "title": "On Generating Monolithic and Model Reconciling Explanations in Probabilistic Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Stylianos Loukas Vasileiou",
        "William Yeoh",
        "Alessandro Previti",
        "Tran Cao Son"
      ],
      "abstract": "Explanation generation frameworks aim to make AI systems' decisions\ntransparent and understandable to human users. However, generating explanations\nin uncertain environments characterized by incomplete information and\nprobabilistic models remains a significant challenge. In this paper, we propose\na novel framework for generating probabilistic monolithic explanations and\nmodel reconciling explanations. Monolithic explanations provide self-contained\nreasons for an explanandum without considering the agent receiving the\nexplanation, while model reconciling explanations account for the knowledge of\nthe agent receiving the explanation. For monolithic explanations, our approach\nintegrates uncertainty by utilizing probabilistic logic to increase the\nprobability of the explanandum. For model reconciling explanations, we propose\na framework that extends the logic-based variant of the model reconciliation\nproblem to account for probabilistic human models, where the goal is to find\nexplanations that increase the probability of the explanandum while minimizing\nconflicts between the explanation and the probabilistic human model. We\nintroduce explanatory gain and explanatory power as quantitative metrics to\nassess the quality of these explanations. Further, we present algorithms that\nexploit the duality between minimal correction sets and minimal unsatisfiable\nsets to efficiently compute both types of explanations in probabilistic\ncontexts. Extensive experimental evaluations on various benchmarks demonstrate\nthe effectiveness and scalability of our approach in generating explanations\nunder uncertainty.",
      "tldr_zh": "本研究提出一个新框架，用于在概率场景中生成单体(monolithic)解释和模型协调(model reconciling)解释，以提升AI决策的透明度。单体解释通过概率逻辑整合不确定性，提供自包含的理由来增加explanandum的概率；模型协调解释则扩展逻辑-based模型协调问题，考虑接收者的概率人类模型，同时最小化冲突。研究引入了explanatory gain和explanatory power作为评估指标，并开发算法利用minimal correction sets和minimal unsatisfiable sets的二元性来高效计算这些解释。实验在多个基准上证明了该框架的有效性和可扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19229v1",
      "published_date": "2024-05-29 16:07:31 UTC",
      "updated_date": "2024-05-29 16:07:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:32:02.151388"
    },
    {
      "arxiv_id": "2405.19220v5",
      "title": "WRDScore: New Metric for Evaluation of Natural Language Generation Models",
      "title_zh": "WRDScore：用于评估自然语言生成模型的新指标",
      "authors": [
        "Ravil Mussabayev"
      ],
      "abstract": "Evaluating natural language generation models, particularly for method name\nprediction, poses significant challenges. A robust metric must account for the\nversatility of method naming, considering both semantic and syntactic\nvariations. Traditional overlap-based metrics, such as ROUGE, fail to capture\nthese nuances. Existing embedding-based metrics often suffer from imbalanced\nprecision and recall, lack normalized scores, or make unrealistic assumptions\nabout sequences. To address these limitations, we leverage the theory of\noptimal transport and construct WRDScore, a novel metric that strikes a balance\nbetween simplicity and effectiveness. In the WRDScore framework, we define\nprecision as the maximum degree to which the predicted sequence's tokens are\nincluded in the reference sequence, token by token. Recall is calculated as the\ntotal cost of the optimal transport plan that maps the reference sequence to\nthe predicted one. Finally, WRDScore is computed as the harmonic mean of\nprecision and recall, balancing these two complementary metrics. Our metric is\nlightweight, normalized, and precision-recall-oriented, avoiding unrealistic\nassumptions while aligning well with human judgments. Experiments on a\nhuman-curated dataset confirm the superiority of WRDScore over other available\ntext metrics.",
      "tldr_zh": "该论文提出WRDScore，一种新型指标，用于评估自然语言生成模型，特别是方法名称预测任务，以解决传统指标如ROUGE无法捕捉语义和句法变化的问题。WRDScore基于optimal transport理论，将precision定义为预测序列tokens在参考序列中的最大包含度，并将recall计算为映射参考序列到预测序列的最优传输计划的总成本，然后取二者的harmonic mean。实验结果显示，WRDScore在人类策划的数据集上优于现有指标，提供轻量级、归一化的评估方式，与人类判断高度一致。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IEEE Xplore",
      "pdf_url": "http://arxiv.org/pdf/2405.19220v5",
      "published_date": "2024-05-29 16:00:46 UTC",
      "updated_date": "2024-08-13 13:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:32:13.726429"
    },
    {
      "arxiv_id": "2405.19213v2",
      "title": "EdgeSight: Enabling Modeless and Cost-Efficient Inference at the Edge",
      "title_zh": "翻译失败",
      "authors": [
        "ChonLam Lao",
        "Jiaqi Gao",
        "Ganesh Ananthanarayanan",
        "Aditya Akella",
        "Minlan Yu"
      ],
      "abstract": "Traditional ML inference is evolving toward modeless inference, which\nabstracts the complexity of model selection from users, allowing the system to\nautomatically choose the most appropriate model for each request based on\naccuracy and resource requirements. While prior studies have focused on\nmodeless inference within data centers, this paper tackles the pressing need\nfor cost-efficient modeless inference at the edge -- particularly within its\nunique constraints of limited device memory, volatile network conditions, and\nrestricted power consumption.\n  To overcome these challenges, we propose EdgeSight, a system that provides\ncost-efficient EdgeSight serving for diverse DNNs at the edge. EdgeSight\nemploys an edge-data center (edge-DC) architecture, utilizing confidence\nscaling to reduce the number of model options while meeting diverse accuracy\nrequirements. Additionally, it supports lossy inference in volatile network\nenvironments. Our experimental results show that EdgeSight outperforms existing\nsystems by up to 1.6x in P99 latency for modeless services. Furthermore, our\nFPGA prototype demonstrates similar performance at certain accuracy levels,\nwith a power consumption reduction of up to 3.34x.",
      "tldr_zh": "这篇论文探讨了无模型推理（modeless inference）在边缘环境的挑战，包括设备内存有限、网络波动和功耗限制，旨在实现成本高效的 ML 推理。作者提出 EdgeSight 系统，使用 edge-DC 架构和置信度缩放（confidence scaling）来减少模型选项，同时支持有损推理（lossy inference）以适应多样化准确性需求。实验结果显示，EdgeSight 比现有系统将 P99 延迟降低高达 1.6 倍，且其 FPGA 原型在特定准确性水平下实现了功耗减少高达 3.34 倍，为边缘 DNNs 服务提供了高效解决方案。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.NI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.19213v2",
      "published_date": "2024-05-29 15:56:33 UTC",
      "updated_date": "2025-01-15 04:17:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:32:25.913997"
    },
    {
      "arxiv_id": "2405.19212v3",
      "title": "Partial Information Decomposition for Data Interpretability and Feature Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Charles Westphal",
        "Stephen Hailes",
        "Mirco Musolesi"
      ],
      "abstract": "In this paper, we introduce Partial Information Decomposition of Features\n(PIDF), a new paradigm for simultaneous data interpretability and feature\nselection. Contrary to traditional methods that assign a single importance\nvalue, our approach is based on three metrics per feature: the mutual\ninformation shared with the target variable, the feature's contribution to\nsynergistic information, and the amount of this information that is redundant.\nIn particular, we develop a novel procedure based on these three metrics, which\nreveals not only how features are correlated with the target but also the\nadditional and overlapping information provided by considering them in\ncombination with other features. We extensively evaluate PIDF using both\nsynthetic and real-world data, demonstrating its potential applications and\neffectiveness, by considering case studies from genetics and neuroscience.",
      "tldr_zh": "本研究引入了 Partial Information Decomposition of Features (PIDF)，一种新范式，用于同时提升数据可解释性和特征选择，与传统方法不同，它为每个特征提供三个指标：与目标变量的 mutual information、特征对 synergistic information 的贡献，以及 redundant information。PIDF 通过这些指标开发了一种新程序，不仅揭示特征与目标的相关性，还分析特征组合时提供的额外和重叠信息。在合成和真实数据（如遗传学和神经科学案例）上的广泛评估中，PIDF 展示了其有效性和实际应用潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19212v3",
      "published_date": "2024-05-29 15:54:03 UTC",
      "updated_date": "2024-11-18 16:22:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:32:37.182071"
    },
    {
      "arxiv_id": "2405.19210v1",
      "title": "Gradient Guided Hypotheses: A unified solution to enable machine learning models on scarce and noisy data regimes",
      "title_zh": "Gradient Guided Hypotheses：一种统一的解决方案，用于在数据稀缺和噪声数据环境中启用机器学习模型",
      "authors": [
        "Paulo Neves",
        "Joerg K. Wegner",
        "Philippe Schwaller"
      ],
      "abstract": "Ensuring high-quality data is paramount for maximizing the performance of\nmachine learning models and business intelligence systems. However, challenges\nin data quality, including noise in data capture, missing records, limited data\nproduction, and confounding variables, significantly constrain the potential\nperformance of these systems. In this study, we propose an\narchitecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to\naddress these challenges. GGH analyses gradients from hypotheses as a proxy of\ndistinct and possibly contradictory patterns in the data. This framework\nentails an additional step in machine learning training, where gradients can be\nincluded or excluded from backpropagation. In this manner, missing and noisy\ndata are addressed through a unified solution that perceives both challenges as\nfacets of the same overarching issue: the propagation of erroneous information.\nExperimental validation of GGH is conducted using real-world open-source\ndatasets, where records with missing rates of up to 98.5% are simulated.\nComparative analysis with state-of-the-art imputation methods demonstrates a\nsubstantial improvement in model performance achieved by GGH. Specifically in\nvery high scarcity regimes, GGH was found to be the only viable solution.\nAdditionally, GGH's noise detection capabilities are showcased by introducing\nsimulated noise into the datasets and observing enhanced model performance\nafter filtering out the noisy data. This study presents GGH as a promising\nsolution for improving data quality and model performance in various\napplications.",
      "tldr_zh": "本文提出 Gradient Guided Hypotheses (GGH)，一个架构无关的算法，旨在统一解决机器学习模型在数据稀缺和噪声环境下的性能挑战，通过分析假设的 gradients 作为数据模式代理，并在训练过程中选择性包括或排除 gradients 用于 backpropagation。GGH 将缺失记录和噪声视为错误信息传播的同一问题，提供了一个简化的处理框架。实验结果显示，在真实开源数据集上模拟高达98.5%缺失率时，GGH 相较于现有填充方法显著提升模型性能，并在引入噪声后通过过滤实现进一步优化，从而为实际应用中改善数据质量和模型可靠性提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19210v1",
      "published_date": "2024-05-29 15:51:40 UTC",
      "updated_date": "2024-05-29 15:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:32:51.977099"
    },
    {
      "arxiv_id": "2406.11870v1",
      "title": "Sisteme Hibride de Invatare Automata si Aplicatii",
      "title_zh": "翻译失败",
      "authors": [
        "Eduard Hogea",
        "Darian Onchis"
      ],
      "abstract": "In this paper, a deep neural network approach and a neuro-symbolic one are\nproposed for classification and regression. The neuro-symbolic predictive\nmodels based on Logic Tensor Networks are capable of discriminating and in the\nsame time of explaining the characterization of bad connections, called alerts\nor attacks, and of normal connections. The proposed hybrid systems incorporate\nboth the ability of deep neural networks to improve on their own through\nexperience and the interpretability of the results provided by symbolic\nartificial intelligence approach. To justify the need for shifting towards\nhybrid systems, explanation, implementation, and comparison of the dense neural\nnetwork and the neuro-symbolic network is performed in detail. For the\ncomparison to be relevant, the same datasets were used in training and the\nmetrics resulted have been compared. A review of the resulted metrics shows\nthat while both methods have similar precision in their predictive models, with\nLogic Tensor Networks being also possible to have interactive accuracy and\ndeductive reasoning over data. Other advantages and disadvantages such as\noverfitting mitigation and scalability issues are also further discussed.",
      "tldr_zh": "这篇论文提出了一种深度神经网络方法和基于 Logic Tensor Networks 的神经符号方法，用于分类和回归任务，这些方法能够区分不良连接（如警报或攻击）与正常连接，同时提供结果的可解释性。论文通过详细比较密集神经网络和神经符号网络，使用相同数据集进行训练，显示两者在预测精确性上相似，但神经符号方法额外支持交互准确性和演绎推理。最终，论文讨论了混合系统的优势，如缓解过度拟合，以及潜在缺点如可扩展性问题，强调了转向混合系统的必要性。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "in Romanian language",
      "pdf_url": "http://arxiv.org/pdf/2406.11870v1",
      "published_date": "2024-05-29 15:50:34 UTC",
      "updated_date": "2024-05-29 15:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:33:02.756704"
    },
    {
      "arxiv_id": "2405.19209v3",
      "title": "VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on Long Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Wang",
        "Shoubin Yu",
        "Elias Stengel-Eskin",
        "Jaehong Yoon",
        "Feng Cheng",
        "Gedas Bertasius",
        "Mohit Bansal"
      ],
      "abstract": "Long-form video understanding is complicated by the high redundancy of video\ndata and the abundance of query-irrelevant information. To tackle these\nchallenges, we propose VideoTree, a training-free framework which builds a\nquery-adaptive and hierarchical video representation for LLM reasoning over\nlong-form videos. First, VideoTree extracts query-relevant information from the\ninput video through an iterative process, progressively refining the selection\nof keyframes based on their relevance to the query. Furthermore, VideoTree\nleverages the inherent hierarchical structure of long video data, which is\noften overlooked by existing LLM-based methods. Specifically, we incorporate\nmulti-granularity information into a tree-based representation, allowing\nVideoTree to extract query-relevant details from long videos in a\ncoarse-to-fine manner. This enables the model to effectively handle a wide\nrange of video queries with varying levels of detail. Finally, VideoTree\naggregates the hierarchical query-relevant information within the tree\nstructure and feeds it into an LLM reasoning model to answer the query. Our\nexperiments show that our method improves both reasoning accuracy and\nefficiency. Specifically, VideoTree outperforms existing training-free\napproaches on EgoSchema and NExT-QA with less inference time, achieving 61.1%\nand 75.6% accuracy on the test set without additional video-specific training.\nMoreover, on the long split of Video-MME (average 44 minutes), VideoTree\nachieves better performance than GPT-4V and many other MLLMs that were\nextensively trained on video data.",
      "tldr_zh": "该研究提出 VideoTree，一种无需训练的框架，用于处理长视频理解中的数据冗余和无关信息问题，通过迭代提取查询相关关键帧并构建层次化树状表示，实现从粗到细的视频信息提取。VideoTree 利用多粒度信息整合到树结构中，然后输入 LLM 进行推理，从而提高查询响应的准确性和效率。在实验中，该方法在 EgoSchema 和 NExT-QA 数据集上分别达到 61.1% 和 75.6% 的准确率，优于现有无训练方法，且在 Video-MME 长视频任务上超越 GPT-4V 等模型，同时减少了推理时间。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025; First three authors contributed equally; Project page:\n  https://videotree2024.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2405.19209v3",
      "published_date": "2024-05-29 15:49:09 UTC",
      "updated_date": "2025-03-14 13:57:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:33:14.398315"
    },
    {
      "arxiv_id": "2405.19207v1",
      "title": "A Multi-Source Retrieval Question Answering Framework Based on RAG",
      "title_zh": "一种基于 RAG 的",
      "authors": [
        "Ridong Wu",
        "Shuhong Chen",
        "Xiangbiao Su",
        "Yuankai Zhu",
        "Yifei Liao",
        "Jianming Wu"
      ],
      "abstract": "With the rapid development of large-scale language models,\nRetrieval-Augmented Generation (RAG) has been widely adopted. However, existing\nRAG paradigms are inevitably influenced by erroneous retrieval information,\nthereby reducing the reliability and correctness of generated results.\nTherefore, to improve the relevance of retrieval information, this study\nproposes a method that replaces traditional retrievers with GPT-3.5, leveraging\nits vast corpus knowledge to generate retrieval information. We also propose a\nweb retrieval based method to implement fine-grained knowledge retrieval,\nUtilizing the powerful reasoning capability of GPT-3.5 to realize semantic\npartitioning of problem.In order to mitigate the illusion of GPT retrieval and\nreduce noise in Web retrieval,we proposes a multi-source retrieval framework,\nnamed MSRAG, which combines GPT retrieval with web retrieval. Experiments on\nmultiple knowledge-intensive QA datasets demonstrate that the proposed\nframework in this study performs better than existing RAG framework in\nenhancing the overall efficiency and accuracy of QA systems.",
      "tldr_zh": "本研究针对现有 Retrieval-Augmented Generation (RAG) 框架易受错误检索信息影响的问题，提出了一种多源检索问答框架 MSRAG。该框架使用 GPT-3.5 替换传统检索器，利用其知识库生成检索信息，并结合网络检索实现细粒度知识检索和语义分区，以减少幻觉和噪音。实验结果显示，MSRAG 在多个知识密集型 Question Answering (QA) 数据集上，比现有 RAG 框架显著提高了系统的整体效率和准确性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "4 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.19207v1",
      "published_date": "2024-05-29 15:47:57 UTC",
      "updated_date": "2024-05-29 15:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:33:27.008298"
    },
    {
      "arxiv_id": "2405.19202v4",
      "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive Survey",
      "title_zh": "脆弱道路使用者检测与安全增强：全面综述",
      "authors": [
        "Renato M. Silva",
        "Gregório F. Azevedo",
        "Matheus V. V. Berto",
        "Jean R. Rocha",
        "Eduardo C. Fidelis",
        "Matheus V. Nogueira",
        "Pedro H. Lisboa",
        "Tiago A. Almeida"
      ],
      "abstract": "Traffic incidents involving vulnerable road users (VRUs) constitute a\nsignificant proportion of global road accidents. Advances in traffic\ncommunication ecosystems, coupled with sophisticated signal processing and\nmachine learning techniques, have facilitated the utilization of data from\ndiverse sensors. Despite these advancements and the availability of extensive\ndatasets, substantial progress is required to mitigate traffic casualties. This\npaper provides a comprehensive survey of state-of-the-art technologies and\nmethodologies to enhance the safety of VRUs. The study delves into the\ncommunication networks between vehicles and VRUs, emphasizing the integration\nof advanced sensors and the availability of relevant datasets. It explores\npreprocessing techniques and data fusion methods to enhance sensor data\nquality. Furthermore, our study assesses critical simulation environments\nessential for developing and testing VRU safety systems. Our research also\nhighlights recent advances in VRU detection and classification algorithms,\naddressing challenges such as variable environmental conditions. Additionally,\nwe cover cutting-edge research in predicting VRU intentions and behaviors,\nwhich is crucial for proactive collision avoidance strategies. Through this\nsurvey, we aim to provide a comprehensive understanding of the current\nlandscape of VRU safety technologies, identifying areas of progress and areas\nneeding further research and development.",
      "tldr_zh": "这篇论文对脆弱道路使用者（VRUs，如行人或骑行者）的检测和安全增强进行了全面调查，旨在减少全球交通事故中的伤亡。论文探讨了车辆与VRUs的通信网络、先进传感器的数据融合和预处理方法，以及关键模拟环境，以支持系统开发和测试。同时，它回顾了最新的VRU检测、分类算法和意图预测技术，处理了可变环境条件带来的挑战，并强调了这些进展在主动碰撞避免策略中的作用。最终，该研究识别了当前技术景观的进展与不足，指出未来需要更多研究来提升VRU安全。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "57 pages, 18 tables, 8 figures, citing 339 (up-to-date) papers,\n  preprint submitted to Expert Systems with Applications (Elsevier)",
      "pdf_url": "http://arxiv.org/pdf/2405.19202v4",
      "published_date": "2024-05-29 15:42:10 UTC",
      "updated_date": "2024-11-05 19:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:33:39.704215"
    },
    {
      "arxiv_id": "2405.19201v2",
      "title": "Going beyond Compositions, DDPMs Can Produce Zero-Shot Interpolations",
      "title_zh": "翻译失败",
      "authors": [
        "Justin Deschenaux",
        "Igor Krawczuk",
        "Grigorios Chrysos",
        "Volkan Cevher"
      ],
      "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable\ncapabilities in image generation, with studies suggesting that they can\ngeneralize by composing latent factors learned from the training data. In this\nwork, we go further and study DDPMs trained on strictly separate subsets of the\ndata distribution with large gaps on the support of the latent factors. We show\nthat such a model can effectively generate images in the unexplored,\nintermediate regions of the distribution. For instance, when trained on clearly\nsmiling and non-smiling faces, we demonstrate a sampling procedure which can\ngenerate slightly smiling faces without reference images (zero-shot\ninterpolation). We replicate these findings for other attributes as well as\nother datasets. Our code is available at\nhttps://github.com/jdeschena/ddpm-zero-shot-interpolation.",
      "tldr_zh": "本研究扩展了Denoising Diffusion Probabilistic Models (DDPMs)的能力，证明它们不仅能组合训练数据中的潜在因素，还能在严格分离的数据子集上训练后生成未探索的中间区域图像。作者开发了一种采样过程，实现zero-shot interpolation，例如使用微笑和非微笑脸部图像训练后，直接生成轻微微笑的脸部图像，而无需参考样本。该方法在多种属性和数据集上得到验证，代码可从GitHub获取，这为DDPMs的泛化应用提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19201v2",
      "published_date": "2024-05-29 15:41:53 UTC",
      "updated_date": "2024-07-10 14:42:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:33:51.182147"
    },
    {
      "arxiv_id": "2405.19184v1",
      "title": "Promoting Two-sided Fairness in Dynamic Vehicle Routing Problem",
      "title_zh": "在动态车辆路径问题中促进双向公平",
      "authors": [
        "Yufan Kang",
        "Rongsheng Zhang",
        "Wei Shao",
        "Flora D. Salim",
        "Jeffrey Chan"
      ],
      "abstract": "Dynamic Vehicle Routing Problem (DVRP), is an extension of the classic\nVehicle Routing Problem (VRP), which is a fundamental problem in logistics and\ntransportation. Typically, DVRPs involve two stakeholders: service providers\nthat deliver services to customers and customers who raise requests from\ndifferent locations. Many real-world applications can be formulated as DVRP\nsuch as ridesharing and non-compliance capture. Apart from original objectives\nlike optimising total utility or efficiency, DVRP should also consider fairness\nfor all parties. Unfairness can induce service providers and customers to give\nup on the systems, leading to negative financial and social impacts. However,\nmost existing DVRP-related applications focus on improving fairness from a\nsingle side, and there have been few works considering two-sided fairness and\nutility optimisation concurrently. To this end, we propose a novel framework, a\nTwo-sided Fairness-aware Genetic Algorithm (named 2FairGA), which expands the\ngenetic algorithm from the original objective solely focusing on utility to\nmulti-objectives that incorporate two-sided fairness. Subsequently, the impact\nof injecting two fairness definitions into the utility-focused model and the\ncorrelation between any pair of the three objectives are explored. Extensive\nexperiments demonstrate the superiority of our proposed framework compared to\nthe state-of-the-art.",
      "tldr_zh": "本研究针对 Dynamic Vehicle Routing Problem (DVRP) 的双边公平问题，提出一种新框架 Two-sided Fairness-aware Genetic Algorithm (2FairGA)，将传统遗传算法从单一效用优化扩展到多目标优化，包括服务提供者和客户的双边公平。\n该框架探讨了注入公平定义对模型的影响，以及效用与公平目标之间的相关性。\n实验结果显示，2FairGA 比现有最先进方法表现出色，能够有效缓解不公平带来的负面影响，提升物流系统的整体性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19184v1",
      "published_date": "2024-05-29 15:24:28 UTC",
      "updated_date": "2024-05-29 15:24:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:34:14.086214"
    },
    {
      "arxiv_id": "2405.19176v1",
      "title": "The ethical situation of DALL-E 2",
      "title_zh": "DALL-E 2 的伦理状况",
      "authors": [
        "Eduard Hogea",
        "Josem Rocafortf"
      ],
      "abstract": "A hot topic of Artificial Intelligence right now is image generation from\nprompts. DALL-E 2 is one of the biggest names in this domain, as it allows\npeople to create images from simple text inputs, to even more complicated ones.\nThe company that made this possible, OpenAI, has assured everyone that visited\ntheir website that their mission is to ensure that artificial general\nintelligence benefits all humanity. A noble idea in our opinion, that also\nstood as the motive behind us choosing this subject. This paper analyzes the\nethical implications of an AI image generative system, with an emphasis on how\nsociety is responding to it, how it probably will and how it should if all the\nright measures are taken.",
      "tldr_zh": "本论文探讨了DALL-E 2作为AI图像生成系统的伦理状况，聚焦于从简单文本提示生成图像的技术及其社会影响。作者强调OpenAI的使命，即确保人工智能（Artificial Intelligence）造福全人类，并以此作为分析基础。论文分析了当前社会对DALL-E 2的反应、潜在未来响应，以及如果采取适当措施（如加强监管和伦理指导）应有的理想应对方式。总的来说，该研究为AI图像生成领域的伦理决策提供了宝贵见解。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19176v1",
      "published_date": "2024-05-29 15:18:13 UTC",
      "updated_date": "2024-05-29 15:18:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:34:14.344963"
    },
    {
      "arxiv_id": "2405.19166v1",
      "title": "Transformers as Neural Operators for Solutions of Differential Equations with Finite Regularity",
      "title_zh": "Transformers 作为神经算子用于有限正则性微分",
      "authors": [
        "Benjamin Shih",
        "Ahmad Peyvan",
        "Zhongqiang Zhang",
        "George Em Karniadakis"
      ],
      "abstract": "Neural operator learning models have emerged as very effective surrogates in\ndata-driven methods for partial differential equations (PDEs) across different\napplications from computational science and engineering. Such operator learning\nmodels not only predict particular instances of a physical or biological system\nin real-time but also forecast classes of solutions corresponding to a\ndistribution of initial and boundary conditions or forcing terms. % DeepONet is\nthe first neural operator model and has been tested extensively for a broad\nclass of solutions, including Riemann problems. Transformers have not been used\nin that capacity, and specifically, they have not been tested for solutions of\nPDEs with low regularity. %\n  In this work, we first establish the theoretical groundwork that transformers\npossess the universal approximation property as operator learning models.\n  We then apply transformers to forecast solutions of diverse dynamical systems\nwith solutions of finite regularity for a plurality of initial conditions and\nforcing terms. In particular, we consider three examples: the Izhikevich neuron\nmodel, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and\nthe one-dimensional Euler equation Riemann problem. For the latter problem, we\nalso compare with variants of DeepONet, and we find that transformers\noutperform DeepONet in accuracy but they are computationally more expensive.",
      "tldr_zh": "本研究证明了 Transformers 作为神经算子学习模型的通用逼近性质，能够有效求解有限正则性的偏微分方程 (PDEs) 解决方案。作者将 Transformers 应用于多种动态系统，包括 Izhikevich 神经元模型、tempered 分数阶 Leaky Integrate-and-Fire (LIF) 模型，以及一维 Euler 方程 Riemann 问题，以预测不同初始条件和强制项下的解决方案。相比 DeepONet，Transformers 在准确性上表现出色，但计算开销更大，为数据驱动的 PDEs 模拟提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19166v1",
      "published_date": "2024-05-29 15:10:24 UTC",
      "updated_date": "2024-05-29 15:10:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:34:28.057082"
    },
    {
      "arxiv_id": "2405.19164v1",
      "title": "Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in eDiscovery",
      "title_zh": "从诉讼中学习：图和 LLMs 用于电子发现",
      "authors": [
        "Sounak Lahiri",
        "Sumit Pai",
        "Tim Weninger",
        "Sanmitra Bhattacharya"
      ],
      "abstract": "Electronic Discovery (eDiscovery) involves identifying relevant documents\nfrom a vast collection based on legal production requests. The integration of\nartificial intelligence (AI) and natural language processing (NLP) has\ntransformed this process, helping document review and enhance efficiency and\ncost-effectiveness. Although traditional approaches like BM25 or fine-tuned\npre-trained models are common in eDiscovery, they face performance,\ncomputational, and interpretability challenges. In contrast, Large Language\nModel (LLM)-based methods prioritize interpretability but sacrifice performance\nand throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid\napproach that combines the strengths of two worlds: a heterogeneous graph-based\nmethod for accurate document relevance prediction and subsequent LLM-driven\napproach for reasoning. Graph representational learning generates embeddings\nand predicts links, ranking the corpus for a given request, and the LLMs\nprovide reasoning for document relevance. Our approach handles datasets with\nbalanced and imbalanced distributions, outperforming baselines in F1-score,\nprecision, and recall by an average of 12%, 3%, and 16%, respectively. In an\nenterprise context, our approach drastically reduces document review costs by\n99.9% compared to manual processes and by 95% compared to LLM-based\nclassification methods",
      "tldr_zh": "这篇论文针对电子发现(eDiscovery)中的文档检索问题，提出了一种混合框架DISCOG，结合异构图表示学习(heterogeneous graph-based method)用于准确预测文档相关性，以及后续LLM驱动方法进行推理，从而解决传统方法如BM25的性能和可解释性挑战。DISCOG通过生成嵌入、预测链接并排名语料库，能够处理平衡和不平衡数据集，在F1-score、precision和recall上分别平均比基线提升12%、3%和16%。在企业环境中，该框架将文档审查成本比手动过程降低99.9%，比纯LLM分类方法降低95%，显著提高了效率和成本效益。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 2 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.19164v1",
      "published_date": "2024-05-29 15:08:55 UTC",
      "updated_date": "2024-05-29 15:08:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:34:40.195850"
    },
    {
      "arxiv_id": "2405.19162v1",
      "title": "Does learning the right latent variables necessarily improve in-context learning?",
      "title_zh": "学习正确的潜在变量是否必然改善上下文学习？",
      "authors": [
        "Sarthak Mittal",
        "Eric Elmoznino",
        "Leo Gagnon",
        "Sangnie Bhardwaj",
        "Dhanya Sridhar",
        "Guillaume Lajoie"
      ],
      "abstract": "Large autoregressive models like Transformers can solve tasks through\nin-context learning (ICL) without learning new weights, suggesting avenues for\nefficiently solving new tasks. For many tasks, e.g., linear regression, the\ndata factorizes: examples are independent given a task latent that generates\nthe data, e.g., linear coefficients. While an optimal predictor leverages this\nfactorization by inferring task latents, it is unclear if Transformers\nimplicitly do so or if they instead exploit heuristics and statistical\nshortcuts enabled by attention layers. Both scenarios have inspired active\nongoing work. In this paper, we systematically investigate the effect of\nexplicitly inferring task latents. We minimally modify the Transformer\narchitecture with a bottleneck designed to prevent shortcuts in favor of more\nstructured solutions, and then compare performance against standard\nTransformers across various ICL tasks. Contrary to intuition and some recent\nworks, we find little discernible difference between the two; biasing towards\ntask-relevant latent variables does not lead to better out-of-distribution\nperformance, in general. Curiously, we find that while the bottleneck\neffectively learns to extract latent task variables from context, downstream\nprocessing struggles to utilize them for robust prediction. Our study\nhighlights the intrinsic limitations of Transformers in achieving structured\nICL solutions that generalize, and shows that while inferring the right latents\naids interpretability, it is not sufficient to alleviate this problem.",
      "tldr_zh": "该研究探讨了在 in-context learning (ICL) 中，学习正确的潜在变量（latent variables）是否能改善模型性能。作者通过最小化修改 Transformer 架构，添加一个瓶颈机制来防止统计捷径，强迫模型更结构化地推断任务潜在变量，并与标准 Transformer 在各种 ICL 任务上进行比较。结果显示，这种偏向任务相关潜在变量的修改并未显著提升 out-of-distribution 性能。论文强调，虽然瓶颈机制能有效提取潜在变量，但下游处理无法充分利用它们，导致 Transformer 在实现鲁棒的结构化 ICL 解决方案上存在固有限制。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19162v1",
      "published_date": "2024-05-29 15:06:10 UTC",
      "updated_date": "2024-05-29 15:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:34:52.185586"
    },
    {
      "arxiv_id": "2405.19153v2",
      "title": "A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning",
      "title_zh": "在线策略深度强化学习中的可塑性损失研究",
      "authors": [
        "Arthur Juliani",
        "Jordan T. Ash"
      ],
      "abstract": "Continual learning with deep neural networks presents challenges distinct\nfrom both the fixed-dataset and convex continual learning regimes. One such\nchallenge is plasticity loss, wherein a neural network trained in an online\nfashion displays a degraded ability to fit new tasks. This problem has been\nextensively studied in both supervised learning and off-policy reinforcement\nlearning (RL), where a number of remedies have been proposed. Still, plasticity\nloss has received less attention in the on-policy deep RL setting. Here we\nperform an extensive set of experiments examining plasticity loss and a variety\nof mitigation methods in on-policy deep RL. We demonstrate that plasticity loss\nis pervasive under domain shift in this regime, and that a number of methods\ndeveloped to resolve it in other settings fail, sometimes even performing worse\nthan applying no intervention at all. In contrast, we find that a class of\n``regenerative'' methods are able to consistently mitigate plasticity loss in a\nvariety of contexts, including in gridworld tasks and more challenging\nenvironments like Montezuma's Revenge and ProcGen.",
      "tldr_zh": "本研究探讨了在线策略深度强化学习（on-policy deep RL）中的塑性损失（plasticity loss）问题，即神经网络在在线训练中对新任务适应能力下降的现象。研究者通过一系列实验，测试了多种缓解方法，发现塑性损失在领域转移（domain shift）下普遍存在，且许多方法不仅无效，有时甚至比不干预更差。相比之下，一类“regenerative”方法在网格世界任务以及复杂环境如Montezuma's Revenge和ProcGen中，能够一致地缓解塑性损失，为持续学习提供潜在解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19153v2",
      "published_date": "2024-05-29 14:59:49 UTC",
      "updated_date": "2024-11-01 16:47:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:35:03.491414"
    },
    {
      "arxiv_id": "2405.19149v2",
      "title": "CaLa: Complementary Association Learning for Augmenting Composed Image Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Xintong Jiang",
        "Yaxiong Wang",
        "Mengjian Li",
        "Yujiao Wu",
        "Bingwen Hu",
        "Xueming Qian"
      ],
      "abstract": "Composed Image Retrieval (CIR) involves searching for target images based on\nan image-text pair query. While current methods treat this as a query-target\nmatching problem, we argue that CIR triplets contain additional associations\nbeyond this primary relation. In our paper, we identify two new relations\nwithin triplets, treating each triplet as a graph node. Firstly, we introduce\nthe concept of text-bridged image alignment, where the query text serves as a\nbridge between the query image and the target image. We propose a hinge-based\ncross-attention mechanism to incorporate this relation into network learning.\nSecondly, we explore complementary text reasoning, considering CIR as a form of\ncross-modal retrieval where two images compose to reason about complementary\ntext. To integrate these perspectives effectively, we design a twin\nattention-based compositor. By combining these complementary associations with\nthe explicit query pair-target image relation, we establish a comprehensive set\nof constraints for CIR. Our framework, CaLa (Complementary Association Learning\nfor Augmenting Composed Image Retrieval), leverages these insights. We evaluate\nCaLa on CIRR and FashionIQ benchmarks with multiple backbones, demonstrating\nits superiority in composed image retrieval.",
      "tldr_zh": "该论文提出了一种名为 CaLa 的框架，用于增强 Composed Image Retrieval (CIR)，即基于图像-文本对查询目标图像的方法。作者识别出 CIR 三元组中额外的关联，包括 text-bridged image alignment（使用 hinge-based cross-attention 机制将查询文本作为桥梁连接查询图像和目标图像）和 complementary text reasoning（将两个图像组合进行跨模态互补文本推理，并采用 twin attention-based compositor）。通过整合这些关联与传统的查询-目标匹配关系，CaLa 建立了全面的约束机制。实验在 CIRR 和 FashionIQ 基准上证明，该框架在多种骨干网络下显著提升了 CIR 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "To appear at SIGIR 2024. arXiv admin note: text overlap with\n  arXiv:2309.02169",
      "pdf_url": "http://arxiv.org/pdf/2405.19149v2",
      "published_date": "2024-05-29 14:52:10 UTC",
      "updated_date": "2024-05-30 13:26:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:35:16.332013"
    },
    {
      "arxiv_id": "2405.19139v1",
      "title": "DGRC: An Effective Fine-tuning Framework for Distractor Generation in Chinese Multi-choice Reading Comprehension",
      "title_zh": "翻译失败",
      "authors": [
        "Runfeng Lin",
        "Dacheng Xu",
        "Huijiang Wang",
        "Zebiao Chen",
        "Yating Wang",
        "Shouqiang Liu"
      ],
      "abstract": "When evaluating a learner's knowledge proficiency, the multiple-choice\nquestion is an efficient and widely used format in standardized tests.\nNevertheless, generating these questions, particularly plausible distractors\n(incorrect options), poses a considerable challenge. Generally, the distractor\ngeneration can be classified into cloze-style distractor generation (CDG) and\nnatural questions distractor generation (NQDG). In contrast to the CDG,\nutilizing pre-trained language models (PLMs) for NQDG presents three primary\nchallenges: (1) PLMs are typically trained to generate ``correct'' content,\nlike answers, while rarely trained to generate ``plausible\" content, like\ndistractors; (2) PLMs often struggle to produce content that aligns well with\nspecific knowledge and the style of exams; (3) NQDG necessitates the model to\nproduce longer, context-sensitive, and question-relevant distractors. In this\nstudy, we introduce a fine-tuning framework named DGRC for NQDG in Chinese\nmulti-choice reading comprehension from authentic examinations. DGRC comprises\nthree major components: hard chain-of-thought, multi-task learning, and\ngeneration mask patterns. The experiment results demonstrate that DGRC\nsignificantly enhances generation performance, achieving a more than 2.5-fold\nimprovement in BLEU scores.",
      "tldr_zh": "这篇论文针对中文多选阅读理解中的干扰项（distractors）生成问题，提出了一种有效的微调框架DGRC，以解决预训练语言模型（PLMs）在生成“plausible”内容时的挑战，包括内容对齐、知识相关性和上下文敏感性。DGRC框架主要包括hard chain-of-thought推理、多任务学习和generation mask patterns三大组件，通过这些机制提升了干扰项的生成质量。实验结果显示，DGRC在中文多选阅读理解任务上显著提高了性能，BLEU分数提升超过2.5倍。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19139v1",
      "published_date": "2024-05-29 14:47:01 UTC",
      "updated_date": "2024-05-29 14:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:35:28.451946"
    },
    {
      "arxiv_id": "2405.19132v1",
      "title": "Analyzing Chat Protocols of Novice Programmers Solving Introductory Programming Tasks with ChatGPT",
      "title_zh": "分析新手程序员使用 ChatGPT 解决入门级编程任务的聊天协议",
      "authors": [
        "Andreas Scholl",
        "Daniel Schiffner",
        "Natalie Kiesler"
      ],
      "abstract": "Large Language Models (LLMs) have taken the world by storm, and students are\nassumed to use related tools at a great scale. In this research paper we aim to\ngain an understanding of how introductory programming students chat with LLMs\nand related tools, e.g., ChatGPT-3.5. To address this goal, computing students\nat a large German university were motivated to solve programming exercises with\nthe assistance of ChatGPT as part of their weekly introductory course\nexercises. Then students (n=213) submitted their chat protocols (with 2335\nprompts in sum) as data basis for this analysis. The data was analyzed w.r.t.\nthe prompts, frequencies, the chats' progress, contents, and other use pattern,\nwhich revealed a great variety of interactions, both potentially supportive and\nconcerning. Learning about students' interactions with ChatGPT will help inform\nand align teaching practices and instructions for future introductory\nprogramming courses in higher education.",
      "tldr_zh": "本文研究了初级编程学生使用大型语言模型(LLMs)如 ChatGPT-3.5 解决入门编程任务的聊天协议，以了解他们的互动模式。研究方法涉及让 213 名德国大学计算学生在课程中辅助完成编程练习，并收集分析他们的 2335 个提示，包括频率、聊天进展、内容和其他使用模式。结果揭示了多样化的互动，既有潜在支持性方面（如辅助学习），也有令人担忧的问题（如依赖性），从而为优化高等教育入门编程课程的教学实践提供指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at DELFI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19132v1",
      "published_date": "2024-05-29 14:38:32 UTC",
      "updated_date": "2024-05-29 14:38:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:35:39.847048"
    },
    {
      "arxiv_id": "2405.19121v2",
      "title": "Spatio-Spectral Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Geisler",
        "Arthur Kosmala",
        "Daniel Herbst",
        "Stephan Günnemann"
      ],
      "abstract": "Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for\nlearning on graph-structured data. However, key limitations of l-step MPGNNs\nare that their \"receptive field\" is typically limited to the l-hop neighborhood\nof a node and that information exchange between distant nodes is limited by\nover-squashing. Motivated by these limitations, we propose Spatio-Spectral\nGraph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural\nNetworks (GNNs) that synergistically combines spatially and spectrally\nparametrized graph filters. Parameterizing filters partially in the frequency\ndomain enables global yet efficient information propagation. We show that\nS$^2$GNNs vanquish over-squashing and yield strictly tighter\napproximation-theoretic error bounds than MPGNNs. Further, rethinking graph\nconvolutions at a fundamental level unlocks new design spaces. For example,\nS$^2$GNNs allow for free positional encodings that make them strictly more\nexpressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain\ngeneral-purpose S$^2$GNNs, we propose spectrally parametrized filters for\ndirected graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and\ngraph rewirings, e.g., on the peptide long-range benchmark tasks, and are\ncompetitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs\nscale to millions of nodes.",
      "tldr_zh": "本研究针对Spatial Message Passing Graph Neural Networks (MPGNNs) 的局限性，如节点“接收域”受限于 l-hop 邻居和信息过压缩（over-squashing），提出Spatio-Spectral Graph Neural Networks (S$^2$GNNs），一种结合空间和谱参数化图过滤器的全新图神经网络范式。S$^2$GNNs 通过在频率域部分参数化过滤器，实现高效的全局信息传播，并提供比MPGNNs更紧的近似理论误差界限，同时支持免费的位置编码，使其表达力超过1-Weisfeiler-Lehman (WL) 测试。实验结果显示，S$^2$GNNs在肽长距离基准任务上优于MPGNNs、图变换器和图重连，并与序列建模的先进模型竞争，同时在40 GB GPU上可扩展到数百万节点。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "46 pages, 27 figures, 12 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.19121v2",
      "published_date": "2024-05-29 14:28:08 UTC",
      "updated_date": "2024-06-02 18:03:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:36:03.341214"
    },
    {
      "arxiv_id": "2405.19107v1",
      "title": "Offline Regularised Reinforcement Learning for Large Language Models Alignment",
      "title_zh": "离线正则化强化学习用于",
      "authors": [
        "Pierre Harvey Richemond",
        "Yunhao Tang",
        "Daniel Guo",
        "Daniele Calandriello",
        "Mohammad Gheshlaghi Azar",
        "Rafael Rafailov",
        "Bernardo Avila Pires",
        "Eugene Tarassov",
        "Lucas Spangher",
        "Will Ellsworth",
        "Aliaksei Severyn",
        "Jonathan Mallinson",
        "Lior Shani",
        "Gil Shamir",
        "Rishabh Joshi",
        "Tianqi Liu",
        "Remi Munos",
        "Bilal Piot"
      ],
      "abstract": "The dominant framework for alignment of large language models (LLM), whether\nthrough reinforcement learning from human feedback or direct preference\noptimisation, is to learn from preference data. This involves building datasets\nwhere each element is a quadruplet composed of a prompt, two independent\nresponses (completions of the prompt) and a human preference between the two\nindependent responses, yielding a preferred and a dis-preferred response. Such\ndata is typically scarce and expensive to collect. On the other hand,\n\\emph{single-trajectory} datasets where each element is a triplet composed of a\nprompt, a response and a human feedback is naturally more abundant. The\ncanonical element of such datasets is for instance an LLM's response to a\nuser's prompt followed by a user's feedback such as a thumbs-up/down.\nConsequently, in this work, we propose DRO, or \\emph{Direct Reward\nOptimisation}, as a framework and associated algorithms that do not require\npairwise preferences. DRO uses a simple mean-squared objective that can be\nimplemented in various ways. We validate our findings empirically, using T5\nencoder-decoder language models, and show DRO's performance over selected\nbaselines such as Kahneman-Tversky Optimization (KTO). Thus, we confirm that\nDRO is a simple and empirically compelling method for single-trajectory policy\noptimisation.",
      "tldr_zh": "这篇论文针对大型语言模型（LLM）的对齐问题，提出了一种新的框架：Direct Reward Optimisation (DRO)，它利用单轨迹数据集（包括提示、响应和人类反馈）而非稀缺的配对偏好数据进行优化。DRO 采用简单的均方误差目标，能够以多种方式实现，避免了传统方法如 Reinforcement Learning from Human Feedback (RLHF) 或 Direct Preference Optimisation (DPO) 的数据收集难题。在使用 T5 编码器-解码器模型的实验中，DRO 比基线如 Kahneman-Tversky Optimization (KTO) 表现出色，证明了其作为单轨迹策略优化的简单且实证有效的方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19107v1",
      "published_date": "2024-05-29 14:11:29 UTC",
      "updated_date": "2024-05-29 14:11:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:36:07.169757"
    },
    {
      "arxiv_id": "2405.19098v1",
      "title": "Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided by a Function Prior",
      "title_zh": "翻译失败",
      "authors": [
        "Shuyu Cheng",
        "Yibo Miao",
        "Yinpeng Dong",
        "Xiao Yang",
        "Xiao-Shan Gao",
        "Jun Zhu"
      ],
      "abstract": "This paper studies the challenging black-box adversarial attack that aims to\ngenerate adversarial examples against a black-box model by only using output\nfeedback of the model to input queries. Some previous methods improve the query\nefficiency by incorporating the gradient of a surrogate white-box model into\nquery-based attacks due to the adversarial transferability. However, the\nlocalized gradient is not informative enough, making these methods still\nquery-intensive. In this paper, we propose a Prior-guided Bayesian Optimization\n(P-BO) algorithm that leverages the surrogate model as a global function prior\nin black-box adversarial attacks. As the surrogate model contains rich prior\ninformation of the black-box one, P-BO models the attack objective with a\nGaussian process whose mean function is initialized as the surrogate model's\nloss. Our theoretical analysis on the regret bound indicates that the\nperformance of P-BO may be affected by a bad prior. Therefore, we further\npropose an adaptive integration strategy to automatically adjust a coefficient\non the function prior by minimizing the regret bound. Extensive experiments on\nimage classifiers and large vision-language models demonstrate the superiority\nof the proposed algorithm in reducing queries and improving attack success\nrates compared with the state-of-the-art black-box attacks. Code is available\nat https://github.com/yibo-miao/PBO-Attack.",
      "tldr_zh": "这篇论文提出了一种Prior-guided Bayesian Optimization (P-BO)算法，用于提升黑盒对抗攻击的效率，仅通过模型输出反馈生成对抗样本。P-BO利用代理白盒模型作为全局函数先验，将其损失初始化为高斯过程的均值函数，并通过自适应策略调整先验系数以最小化遗憾界。实验结果显示，该算法在图像分类器和大型视觉语言模型上显著减少查询次数并提高攻击成功率，优于现有黑盒攻击方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19098v1",
      "published_date": "2024-05-29 14:05:16 UTC",
      "updated_date": "2024-05-29 14:05:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:36:16.033856"
    },
    {
      "arxiv_id": "2405.19094v1",
      "title": "Faithful Chart Summarization with ChaTS-Pi",
      "title_zh": "翻译失败",
      "authors": [
        "Syrine Krichene",
        "Francesco Piccinno",
        "Fangyu Liu",
        "Julian Martin Eisenschlos"
      ],
      "abstract": "Chart-to-summary generation can help explore data, communicate insights, and\nhelp the visually impaired people. Multi-modal generative models have been used\nto produce fluent summaries, but they can suffer from factual and perceptual\nerrors. In this work we present CHATS-CRITIC, a reference-free chart\nsummarization metric for scoring faithfulness. CHATS-CRITIC is composed of an\nimage-to-text model to recover the table from a chart, and a tabular entailment\nmodel applied to score the summary sentence by sentence. We find that\nCHATS-CRITIC evaluates the summary quality according to human ratings better\nthan reference-based metrics, either learned or n-gram based, and can be\nfurther used to fix candidate summaries by removing not supported sentences. We\nthen introduce CHATS-PI, a chart-to-summary pipeline that leverages\nCHATS-CRITIC during inference to fix and rank sampled candidates from any\nchart-summarization model. We evaluate CHATS-PI and CHATS-CRITIC using human\nraters, establishing state-of-the-art results on two popular chart-to-summary\ndatasets.",
      "tldr_zh": "本研究针对图表摘要生成中的事实和感知错误问题，提出了一种无参考评估指标 CHATS-CRITIC，它结合图像到文本模型恢复图表中的表格，并使用表格蕴涵模型逐句评分摘要的忠实度。CHATS-CRITIC 比传统基于参考的指标更符合人类评估标准，并可用于修复摘要，通过移除不支持的句子。基于此，研究引入 CHATS-PI 管道，利用 CHATS-CRITIC 在推理过程中修复和排名来自任何图表摘要模型的候选摘要。实验结果显示，CHATS-PI 在两个流行图表摘要数据集上达到了最先进的状态。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To be published in the proceedings of the 2024 Annual Meeting of the\n  Association for Computational Linguistics",
      "pdf_url": "http://arxiv.org/pdf/2405.19094v1",
      "published_date": "2024-05-29 13:55:06 UTC",
      "updated_date": "2024-05-29 13:55:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:36:28.255578"
    },
    {
      "arxiv_id": "2405.19085v1",
      "title": "Patch-enhanced Mask Encoder Prompt Image Generation",
      "title_zh": "补丁增强掩码编码器提示图像生成",
      "authors": [
        "Shusong Xu",
        "Peiye Liu"
      ],
      "abstract": "Artificial Intelligence Generated Content(AIGC), known for its superior\nvisual results, represents a promising mitigation method for high-cost\nadvertising applications. Numerous approaches have been developed to manipulate\ngenerated content under different conditions. However, a crucial limitation\nlies in the accurate description of products in advertising applications.\nApplying previous methods directly may lead to considerable distortion and\ndeformation of advertised products, primarily due to oversimplified content\ncontrol conditions. Hence, in this work, we propose a patch-enhanced mask\nencoder approach to ensure accurate product descriptions while preserving\ndiverse backgrounds. Our approach consists of three components Patch Flexible\nVisibility, Mask Encoder Prompt Adapter and an image Foundation Model. Patch\nFlexible Visibility is used for generating a more reasonable background image.\nMask Encoder Prompt Adapter enables region-controlled fusion. We also conduct\nan analysis of the structure and operational mechanisms of the Generation\nModule. Experimental results show our method can achieve the highest visual\nresults and FID scores compared with other methods.",
      "tldr_zh": "这篇论文针对人工智能生成内容（AIGC）在广告应用中的产品描述问题，提出了一种patch-enhanced mask encoder方法，以确保产品准确性同时保留背景多样性。该方法包括三个关键组件：Patch Flexible Visibility用于生成更合理的背景图像、Mask Encoder Prompt Adapter实现区域控制的融合，以及一个图像基础模型（image Foundation Model）。此外，论文分析了生成模块的结构和机制。实验结果表明，该方法在视觉效果和FID scores上优于其他方法，实现了更高的生成质量。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19085v1",
      "published_date": "2024-05-29 13:47:32 UTC",
      "updated_date": "2024-05-29 13:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:36:39.547798"
    },
    {
      "arxiv_id": "2405.19080v1",
      "title": "OMPO: A Unified Framework for RL under Policy and Dynamics Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Luo",
        "Tianying Ji",
        "Fuchun Sun",
        "Jianwei Zhang",
        "Huazhe Xu",
        "Xianyuan Zhan"
      ],
      "abstract": "Training reinforcement learning policies using environment interaction data\ncollected from varying policies or dynamics presents a fundamental challenge.\nExisting works often overlook the distribution discrepancies induced by policy\nor dynamics shifts, or rely on specialized algorithms with task priors, thus\noften resulting in suboptimal policy performances and high learning variances.\nIn this paper, we identify a unified strategy for online RL policy learning\nunder diverse settings of policy and dynamics shifts: transition occupancy\nmatching. In light of this, we introduce a surrogate policy learning objective\nby considering the transition occupancy discrepancies and then cast it into a\ntractable min-max optimization problem through dual reformulation. Our method,\ndubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized\nactor-critic structure equipped with a distribution discriminator and a\nsmall-size local buffer. We conduct extensive experiments based on the OpenAI\nGym, Meta-World, and Panda Robots environments, encompassing policy shifts\nunder stationary and nonstationary dynamics, as well as domain adaption. The\nresults demonstrate that OMPO outperforms the specialized baselines from\ndifferent categories in all settings. We also find that OMPO exhibits\nparticularly strong performance when combined with domain randomization,\nhighlighting its potential in RL-based robotics applications",
      "tldr_zh": "这篇论文提出 OMPO，一种统一的框架，用于强化学习（RL）中处理政策和动态变化（policy and dynamics shifts）所带来的分布差异问题。OMPO 通过过渡占用匹配（transition occupancy matching）策略，引入一个代理策略学习目标，并将其转化为可处理的 min-max 优化问题，结合 actor-critic 结构、分布鉴别器和小型本地缓冲区来优化策略学习。实验在 OpenAI Gym、Meta-World 和 Panda Robots 等环境中验证了 OMPO 在政策变化和领域适应场景下的优越性能，比专门基线方法提高了表现，尤其在与领域随机化结合时，展示了其在 RL 基础机器人应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19080v1",
      "published_date": "2024-05-29 13:36:36 UTC",
      "updated_date": "2024-05-29 13:36:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:36:53.175506"
    },
    {
      "arxiv_id": "2405.19074v1",
      "title": "Resurrecting Old Classes with New Data for Exemplar-Free Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dipam Goswami",
        "Albin Soutif--Cormerais",
        "Yuyang Liu",
        "Sandesh Kamath",
        "Bartłomiej Twardowski",
        "Joost van de Weijer"
      ],
      "abstract": "Continual learning methods are known to suffer from catastrophic forgetting,\na phenomenon that is particularly hard to counter for methods that do not store\nexemplars of previous tasks. Therefore, to reduce potential drift in the\nfeature extractor, existing exemplar-free methods are typically evaluated in\nsettings where the first task is significantly larger than subsequent tasks.\nTheir performance drops drastically in more challenging settings starting with\na smaller first task. To address this problem of feature drift estimation for\nexemplar-free methods, we propose to adversarially perturb the current samples\nsuch that their embeddings are close to the old class prototypes in the old\nmodel embedding space. We then estimate the drift in the embedding space from\nthe old to the new model using the perturbed images and compensate the\nprototypes accordingly. We exploit the fact that adversarial samples are\ntransferable from the old to the new feature space in a continual learning\nsetting. The generation of these images is simple and computationally cheap. We\ndemonstrate in our experiments that the proposed approach better tracks the\nmovement of prototypes in embedding space and outperforms existing methods on\nseveral standard continual learning benchmarks as well as on fine-grained\ndatasets. Code is available at https://github.com/dipamgoswami/ADC.",
      "tldr_zh": "该论文针对无样本持续学习（Exemplar-Free Continual Learning）中的灾难性遗忘（Catastrophic Forgetting）问题，提出了一种新方法，通过对当前样本进行对抗性扰动（Adversarially Perturb），使它们的嵌入（Embeddings）接近旧类原型（Old Class Prototypes）。该方法利用扰动图像估计嵌入空间的特征漂移（Feature Drift），并相应补偿原型，从而更好地跟踪原型在空间中的移动。实验结果表明，该方法在多个标准持续学习基准和细粒度数据集上优于现有方法，提供开源代码以便复现。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19074v1",
      "published_date": "2024-05-29 13:31:42 UTC",
      "updated_date": "2024-05-29 13:31:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:37:04.667029"
    },
    {
      "arxiv_id": "2405.19062v1",
      "title": "SIG: Efficient Self-Interpretable Graph Neural Network for Continuous-time Dynamic Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Lanting Fang",
        "Yulian Yang",
        "Kai Wang",
        "Shanshan Feng",
        "Kaiyu Feng",
        "Jie Gui",
        "Shuliang Wang",
        "Yew-Soon Ong"
      ],
      "abstract": "While dynamic graph neural networks have shown promise in various\napplications, explaining their predictions on continuous-time dynamic graphs\n(CTDGs) is difficult. This paper investigates a new research task:\nself-interpretable GNNs for CTDGs. We aim to predict future links within the\ndynamic graph while simultaneously providing causal explanations for these\npredictions. There are two key challenges: (1) capturing the underlying\nstructural and temporal information that remains consistent across both\nindependent and identically distributed (IID) and out-of-distribution (OOD)\ndata, and (2) efficiently generating high-quality link prediction results and\nexplanations. To tackle these challenges, we propose a novel causal inference\nmodel, namely the Independent and Confounded Causal Model (ICCM). ICCM is then\nintegrated into a deep learning architecture that considers both effectiveness\nand efficiency. Extensive experiments demonstrate that our proposed model\nsignificantly outperforms existing methods across link prediction accuracy,\nexplanation quality, and robustness to shortcut features. Our code and datasets\nare anonymously released at https://github.com/2024SIG/SIG.",
      "tldr_zh": "这篇论文探讨了在连续时间动态图(CTDGs)上构建自解释图神经网络(GNNs)的挑战，提出一个新任务：预测未来链接的同时提供因果解释。作者引入了Independent and Confounded Causal Model (ICCM)模型，并将其整合到一个高效的深度学习架构中，以捕捉结构和时间信息并处理IID和OOD数据。实验结果表明，该模型在链接预测准确性、解释质量以及对捷径特征的鲁棒性上显著优于现有方法，并公开了代码和数据集。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.19062v1",
      "published_date": "2024-05-29 13:09:33 UTC",
      "updated_date": "2024-05-29 13:09:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:37:17.536664"
    },
    {
      "arxiv_id": "2405.19053v1",
      "title": "Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of Electric Vehicle Charging Stations",
      "title_zh": "翻译失败",
      "authors": [
        "Zongbao Zhang",
        "Jiao Hao",
        "Wenmeng Zhao",
        "Yan Liu",
        "Yaohui Huang",
        "Xinhang Luo"
      ],
      "abstract": "The rapid expansion of electric vehicles (EVs) has rendered the load\nforecasting of electric vehicle charging stations (EVCS) increasingly critical.\nThe primary challenge in achieving precise load forecasting for EVCS lies in\naccounting for the nonlinear of charging behaviors, the spatial interactions\namong different stations, and the intricate temporal variations in usage\npatterns. To address these challenges, we propose a Multiscale Spatio-Temporal\nEnhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM\nincorporates a multiscale graph neural network to discern hierarchical\nnonlinear temporal dependencies across various time scales. Besides, it also\nintegrates a recurrent learning component and a residual fusion mechanism,\nenhancing its capability to accurately capture spatial and temporal variations\nin charging patterns. The effectiveness of the proposed MSTEM has been\nvalidated through comparative analysis with six baseline models using three\nevaluation metrics. The case studies utilize real-world datasets for both fast\nand slow charging loads at EVCS in Perth, UK. The experimental results\ndemonstrate the superiority of MSTEM in short-term continuous load forecasting\nfor EVCS.",
      "tldr_zh": "随着电动汽车（EVs）的快速扩张，电动汽车充电站（EVCS）的负载预测面临充电行为非线性、站点间空间互动以及复杂时间变化的挑战。为解决这些问题，本文提出Multiscale Spatio-Temporal Enhanced Model (MSTEM)，该模型整合多尺度图神经网络、循环学习组件和残差融合机制，以准确捕捉不同时间尺度的层次非线性依赖和空间变异。实验通过与六种基线模型的比较，使用真实珀斯数据集验证了MSTEM在EVCS短期连续负载预测中的优越性能，展示了其在精确性和有效性方面的显著提升。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "5 pages, 1 figure, AEEES 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19053v1",
      "published_date": "2024-05-29 12:54:22 UTC",
      "updated_date": "2024-05-29 12:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:37:30.121887"
    },
    {
      "arxiv_id": "2405.19047v2",
      "title": "Statistical Context Detection for Deep Lifelong Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jeffery Dick",
        "Saptarshi Nath",
        "Christos Peridis",
        "Eseoghene Benjamin",
        "Soheil Kolouri",
        "Andrea Soltoggio"
      ],
      "abstract": "Context detection involves labeling segments of an online stream of data as\nbelonging to different tasks. Task labels are used in lifelong learning\nalgorithms to perform consolidation or other procedures that prevent\ncatastrophic forgetting. Inferring task labels from online experiences remains\na challenging problem. Most approaches assume finite and low-dimension\nobservation spaces or a preliminary training phase during which task labels are\nlearned. Moreover, changes in the transition or reward functions can be\ndetected only in combination with a policy, and therefore are more difficult to\ndetect than changes in the input distribution. This paper presents an approach\nto learning both policies and labels in an online deep reinforcement learning\nsetting. The key idea is to use distance metrics, obtained via optimal\ntransport methods, i.e., Wasserstein distance, on suitable latent action-reward\nspaces to measure distances between sets of data points from past and current\nstreams. Such distances can then be used for statistical tests based on an\nadapted Kolmogorov-Smirnov calculation to assign labels to sequences of\nexperiences. A rollback procedure is introduced to learn multiple policies by\nensuring that only the appropriate data is used to train the corresponding\npolicy. The combination of task detection and policy deployment allows for the\noptimization of lifelong reinforcement learning agents without an oracle that\nprovides task labels. The approach is tested using two benchmarks and the\nresults show promising performance when compared with related context detection\nalgorithms. The results suggest that optimal transport statistical methods\nprovide an explainable and justifiable procedure for online context detection\nand reward optimization in lifelong reinforcement learning.",
      "tldr_zh": "本研究针对深度终身强化学习中的上下文检测问题，提出了一种在线方法，用于同时学习策略和任务标签，以防止灾难性遗忘。该方法的核心在于利用最优传输技术（如Wasserstein distance）在潜在行动-奖励空间中测量数据点之间的距离，并通过适配的Kolmogorov-Smirnov统计测试为经验序列分配标签。引入rollback程序确保仅使用相关数据训练多个策略，从而在没有预言机提供任务标签的情况下优化终身强化学习代理。在两个基准测试中，该方法表现出色，与相关算法相比性能提升明显，并证明了最优传输统计方法的解释性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages excluding references and bibliography. Accepted at CoLLAs\n  2024",
      "pdf_url": "http://arxiv.org/pdf/2405.19047v2",
      "published_date": "2024-05-29 12:44:41 UTC",
      "updated_date": "2024-09-03 09:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:37:41.206647"
    },
    {
      "arxiv_id": "2405.19033v1",
      "title": "CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation in Ultra-Lightweight and One-Shot Graph Classification on Edge",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxi Han",
        "Jihe Wang",
        "Danghui Wang"
      ],
      "abstract": "Graph Neural Networks (GNNs) are computationally demanding and inefficient\nwhen applied to graph classification tasks in resource-constrained edge\nscenarios due to their inherent process, involving multiple rounds of forward\nand backward propagation. As a lightweight alternative, Hyper-Dimensional\nComputing (HDC), which leverages high-dimensional vectors for data encoding and\nprocessing, offers a more efficient solution by addressing computational\nbottleneck. However, current HDC methods primarily focus on static graphs and\nneglect to effectively capture node attributes and structural information,\nwhich leads to poor accuracy. In this work, we propose CiliaGraph, an enhanced\nexpressive yet ultra-lightweight HDC model for graph classification. This model\nintroduces a novel node encoding strategy that preserves relative distance\nisomorphism for accurate node connection representation. In addition, node\ndistances are utilized as edge weights for information aggregation, and the\nencoded node attributes and structural information are concatenated to obtain a\ncomprehensive graph representation. Furthermore, we explore the relationship\nbetween orthogonality and dimensionality to reduce the dimensions, thereby\nfurther enhancing computational efficiency. Compared to the SOTA GNNs,\nextensive experiments show that CiliaGraph reduces memory usage and accelerates\ntraining speed by an average of 292 times(up to 2341 times) and 103 times(up to\n313 times) respectively while maintaining comparable accuracy.",
      "tldr_zh": "该论文提出 CiliaGraph，一种增强表达性的超轻量级 Hyper-Dimensional Computing (HDC) 模型，用于边缘设备上的图分类任务，以解决 Graph Neural Networks (GNNs) 的计算密集问题。CiliaGraph 引入新型节点编码策略，保留相对距离同构（relative distance isomorphism）来准确表示节点连接，并利用节点距离作为边权重进行信息聚合，同时将编码后的节点属性和结构信息整合以生成全面的图表示。论文还探索正交性和维度的关系来减少维度，进一步提升计算效率。实验结果显示，与最先进 GNNs 相比，CiliaGraph 平均减少内存使用 292 倍（最高 2341 倍）、加速训练速度 103 倍（最高 313 倍），同时保持可比的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19033v1",
      "published_date": "2024-05-29 12:22:59 UTC",
      "updated_date": "2024-05-29 12:22:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:37:55.042741"
    },
    {
      "arxiv_id": "2405.19032v1",
      "title": "Large Language Models for Code Summarization",
      "title_zh": "大型语言模型用于代码总结",
      "authors": [
        "Balázs Szalontai",
        "Gergő Szalay",
        "Tamás Márton",
        "Anna Sike",
        "Balázs Pintér",
        "Tibor Gregorics"
      ],
      "abstract": "Recently, there has been increasing activity in using deep learning for\nsoftware engineering, including tasks like code generation and summarization.\nIn particular, the most recent coding Large Language Models seem to perform\nwell on these problems. In this technical report, we aim to review how these\nmodels perform in code explanation/summarization, while also investigating\ntheir code generation capabilities (based on natural language descriptions).",
      "tldr_zh": "这篇技术报告探讨了大型语言模型（Large Language Models）在代码总结方面的应用，审查了这些模型在代码解释和总结任务上的表现。报告同时调查了模型基于自然语言描述的代码生成能力。研究发现，最新的大型语言模型在这些软件工程任务中表现出色，为深度学习在编程领域的潜力提供了初步见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "technical report with 11 pages, 1 figure, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.19032v1",
      "published_date": "2024-05-29 12:18:51 UTC",
      "updated_date": "2024-05-29 12:18:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:38:04.491874"
    },
    {
      "arxiv_id": "2405.19029v1",
      "title": "Convex neural network synthesis for robustness in the 1-norm",
      "title_zh": "凸神经网络合成以实现1-范数中的鲁棒性",
      "authors": [
        "Ross Drummond",
        "Chris Guiver",
        "Matthew C. Turner"
      ],
      "abstract": "With neural networks being used to control safety-critical systems, they\nincreasingly have to be both accurate (in the sense of matching inputs to\noutputs) and robust. However, these two properties are often at odds with each\nother and a trade-off has to be navigated. To address this issue, this paper\nproposes a method to generate an approximation of a neural network which is\ncertifiably more robust. Crucially, the method is fully convex and posed as a\nsemi-definite programme. An application to robustifying model predictive\ncontrol is used to demonstrate the results. The aim of this work is to\nintroduce a method to navigate the neural network robustness/accuracy\ntrade-off.",
      "tldr_zh": "本论文针对神经网络在安全关键系统中需要平衡准确性和鲁棒性的问题，提出了一种在1-norm中提升鲁棒性的凸合成方法。方法通过完全凸的semi-definite programme生成神经网络的鲁棒近似，确保其鲁棒性得到证明。该方法应用于robustifying model predictive control，展示了如何有效导航神经网络的鲁棒性/准确性权衡。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19029v1",
      "published_date": "2024-05-29 12:17:09 UTC",
      "updated_date": "2024-05-29 12:17:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:38:18.474909"
    },
    {
      "arxiv_id": "2405.19026v2",
      "title": "DiveR-CT: Diversity-enhanced Red Teaming Large Language Model Assistants with Relaxing Constraints",
      "title_zh": "DiveR-CT：通过放松约束增强多样性的红队测试大语言模型助手",
      "authors": [
        "Andrew Zhao",
        "Quentin Xu",
        "Matthieu Lin",
        "Shenzhi Wang",
        "Yong-jin Liu",
        "Zilong Zheng",
        "Gao Huang"
      ],
      "abstract": "Recent advances in large language model assistants have made them\nindispensable, raising significant concerns over managing their safety.\nAutomated red teaming offers a promising alternative to the labor-intensive and\nerror-prone manual probing for vulnerabilities, providing more consistent and\nscalable safety evaluations. However, existing approaches often compromise\ndiversity by focusing on maximizing attack success rate. Additionally, methods\nthat decrease the cosine similarity from historical embeddings with semantic\ndiversity rewards lead to novelty stagnation as history grows. To address these\nissues, we introduce DiveR-CT, which relaxes conventional constraints on the\nobjective and semantic reward, granting greater freedom for the policy to\nenhance diversity. Our experiments demonstrate DiveR-CT's marked superiority\nover baselines by 1) generating data that perform better in various diversity\nmetrics across different attack success rate levels, 2) better-enhancing\nresiliency in blue team models through safety tuning based on collected data,\n3) allowing dynamic control of objective weights for reliable and controllable\nattack success rates, and 4) reducing susceptibility to reward\noveroptimization. Overall, our method provides an effective and efficient\napproach to LLM red teaming, accelerating real-world deployment.",
      "tldr_zh": "这篇论文引入了 DiveR-CT，一种通过放松对目标和语义奖励约束的红队方法，旨在提升 Large Language Model (LLM) 助手的多样性测试，从而解决现有方法在追求攻击成功率时忽略多样性的问题。DiveR-CT 通过生成在各种多样性指标上表现更优的数据，帮助提升蓝队模型的安全性，并支持动态控制攻击成功率以避免奖励过优化。实验结果表明，该方法显著优于基线，并在实际部署中提供更有效且可控的 LLM 红队测试方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by the 39th Annual AAAI Conference on Artificial\n  Intelligence (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2405.19026v2",
      "published_date": "2024-05-29 12:12:09 UTC",
      "updated_date": "2024-12-20 07:37:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:38:30.157238"
    },
    {
      "arxiv_id": "2405.19024v3",
      "title": "Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Mustafa Mert Çelikok",
        "Frans A. Oliehoek",
        "Jan-Willem van de Meent"
      ],
      "abstract": "We consider inverse reinforcement learning problems with concave utilities.\nConcave Utility Reinforcement Learning (CURL) is a generalisation of the\nstandard RL objective, which employs a concave function of the state occupancy\nmeasure, rather than a linear function. CURL has garnered recent attention for\nits ability to represent instances of many important applications including the\nstandard RL such as imitation learning, pure exploration, constrained MDPs,\noffline RL, human-regularized RL, and others. Inverse reinforcement learning is\na powerful paradigm that focuses on recovering an unknown reward function that\ncan rationalize the observed behaviour of an agent. There has been recent\ntheoretical advances in inverse RL where the problem is formulated as\nidentifying the set of feasible reward functions. However, inverse RL for CURL\nproblems has not been considered previously. In this paper we show that most of\nthe standard IRL results do not apply to CURL in general, since CURL\ninvalidates the classical Bellman equations. This calls for a new theoretical\nframework for the inverse CURL problem. Using a recent equivalence result\nbetween CURL and Mean-field Games, we propose a new definition for the feasible\nrewards for I-CURL by proving that this problem is equivalent to an inverse\ngame theory problem in a subclass of mean-field games. We outline future\ndirections and applications in human--AI collaboration enabled by our results.",
      "tldr_zh": "该论文探讨了凹函数效用强化学习（CURL）的逆强化学习（Inverse RL）问题，指出CURL作为标准RL的泛化，无法应用经典Bellman方程，导致标准IRL结果失效。\n作者证明了逆CURL问题等价于逆游戏理论问题，通过CURL与Mean-field Games的等价性，定义了可行奖励函数的集合。\n这一新框架为模仿学习、人类正则化RL等应用提供了理论基础，并开启了人类-AI协作的未来方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19024v3",
      "published_date": "2024-05-29 12:07:17 UTC",
      "updated_date": "2024-08-01 22:45:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:38:41.193916"
    },
    {
      "arxiv_id": "2405.19012v1",
      "title": "Implicit Neural Image Field for Biological Microscopy Image Compression",
      "title_zh": "隐式神经图像场",
      "authors": [
        "Gaole Dai",
        "Cheng-Ching Tseng",
        "Qingpo Wuwu",
        "Rongyu Zhang",
        "Shaokang Wang",
        "Ming Lu",
        "Tiejun Huang",
        "Yu Zhou",
        "Ali Ata Tuz",
        "Matthias Gunzer",
        "Jianxu Chen",
        "Shanghang Zhang"
      ],
      "abstract": "The rapid pace of innovation in biological microscopy imaging has led to\nlarge images, putting pressure on data storage and impeding efficient sharing,\nmanagement, and visualization. This necessitates the development of efficient\ncompression solutions. Traditional CODEC methods struggle to adapt to the\ndiverse bioimaging data and often suffer from sub-optimal compression. In this\nstudy, we propose an adaptive compression workflow based on Implicit Neural\nRepresentation (INR). This approach permits application-specific compression\nobjectives, capable of compressing images of any shape and arbitrary pixel-wise\ndecompression. We demonstrated on a wide range of microscopy images from real\napplications that our workflow not only achieved high, controllable compression\nratios (e.g., 512x) but also preserved detailed information critical for\ndownstream analysis.",
      "tldr_zh": "本研究针对生物显微镜图像的快速增长导致的存储和共享难题，提出了一种基于Implicit Neural Representation (INR)的自适应压缩工作流，以克服传统压缩方法在多样化生物图像数据上的不足。 该工作流支持应用特定的压缩目标，能够处理任意形状的图像并实现任意像素级的解压缩。 在广泛的真实显微镜图像测试中，该方法实现了高可控压缩比（如512x），同时保留了关键细节，有助于下游分析的应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.19012v1",
      "published_date": "2024-05-29 11:51:33 UTC",
      "updated_date": "2024-05-29 11:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:38:53.997575"
    },
    {
      "arxiv_id": "2405.19010v1",
      "title": "Evaluating the External and Parametric Knowledge Fusion of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hao Zhang",
        "Yuyang Zhang",
        "Xiaoguang Li",
        "Wenxuan Shi",
        "Haonan Xu",
        "Huanshuo Liu",
        "Yasheng Wang",
        "Lifeng Shang",
        "Qun Liu",
        "Yong Liu",
        "Ruiming Tang"
      ],
      "abstract": "Integrating external knowledge into large language models (LLMs) presents a\npromising solution to overcome the limitations imposed by their antiquated and\nstatic parametric memory. Prior studies, however, have tended to over-reliance\non external knowledge, underestimating the valuable contributions of an LLMs'\nintrinsic parametric knowledge. The efficacy of LLMs in blending external and\nparametric knowledge remains largely unexplored, especially in cases where\nexternal knowledge is incomplete and necessitates supplementation by their\nparametric knowledge. We propose to deconstruct knowledge fusion into four\ndistinct scenarios, offering the first thorough investigation of LLM behavior\nacross each. We develop a systematic pipeline for data construction and\nknowledge infusion to simulate these fusion scenarios, facilitating a series of\ncontrolled experiments. Our investigation reveals that enhancing parametric\nknowledge within LLMs can significantly bolster their capability for knowledge\nintegration. Nonetheless, we identify persistent challenges in memorizing and\neliciting parametric knowledge, and determining parametric knowledge\nboundaries. Our findings aim to steer future explorations on harmonizing\nexternal and parametric knowledge within LLMs.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）中外部知识和参数知识的融合，旨在解决LLMs因过时参数记忆而依赖外部知识的局限性。作者将知识融合分解为四个场景，并开发了一个系统化的数据构建和知识注入管道，以模拟这些场景并进行控制实验。结果表明，增强参数知识能显著提升LLMs的知识整合能力，但仍面临记忆、提取参数知识以及确定知识边界的挑战。该研究为未来在LLMs中协调外部和参数知识提供了重要指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.19010v1",
      "published_date": "2024-05-29 11:48:27 UTC",
      "updated_date": "2024-05-29 11:48:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:39:05.563173"
    },
    {
      "arxiv_id": "2405.18999v2",
      "title": "Continuously Optimizing Radar Placement with Model Predictive Path Integrals",
      "title_zh": "基于模型预测路径积分的雷达放置连续优化",
      "authors": [
        "Michael Potter",
        "Shuo Tang",
        "Paul Ghanem",
        "Milica Stojanovic",
        "Pau Closas",
        "Murat Akcakaya",
        "Ben Wright",
        "Marius Necsoiu",
        "Deniz Erdogmus",
        "Michael Everett",
        "Tales Imbiriba"
      ],
      "abstract": "Continuously optimizing sensor placement is essential for precise target\nlocalization in various military and civilian applications. While information\ntheory has shown promise in optimizing sensor placement, many studies\noversimplify sensor measurement models or neglect dynamic constraints of mobile\nsensors. To address these challenges, we employ a range measurement model that\nincorporates radar parameters and radar-target distance, coupled with Model\nPredictive Path Integral (MPPI) control to manage complex environmental\nobstacles and dynamic constraints. We compare the proposed approach against\nstationary radars or simplified range measurement models based on the root mean\nsquared error (RMSE) of the Cubature Kalman Filter (CKF) estimator for the\ntargets' state. Additionally, we visualize the evolving geometry of radars and\ntargets over time, highlighting areas of highest measurement information gain,\ndemonstrating the strengths of the approach. The proposed strategy outperforms\nstationary radars and simplified range measurement models in target\nlocalization, achieving a 38-74% reduction in mean RMSE and a 33-79% reduction\nin the upper tail of the 90% Highest Density Interval (HDI) over 500 Monte Carl\n(MC) trials across all time steps.\n  Code will be made publicly available upon acceptance.",
      "tldr_zh": "该研究提出了一种持续优化雷达放置的方法，结合了基于雷达参数和雷达-目标距离的范围测量模型，以及 Model Predictive Path Integral (MPPI) 控制，以处理复杂环境障碍和动态约束。相比静态雷达或简化测量模型，该方法使用 Cubature Kalman Filter (CKF) 估计算法评估目标状态的根均方误差 (RMSE)，并通过可视化展示了雷达与目标的动态几何变化。实验结果显示，该策略在500次Monte Carlo (MC) 试验中，将目标定位的均值 RMSE 降低了38-74%，并将90% Highest Density Interval (HDI) 的上尾部降低了33-79%。这为精确目标定位应用提供了显著改进。",
      "categories": [
        "stat.AP",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "stat.AP",
      "comment": "Submitted to IEEE Aerospace and Electronic Systems",
      "pdf_url": "http://arxiv.org/pdf/2405.18999v2",
      "published_date": "2024-05-29 11:25:53 UTC",
      "updated_date": "2024-05-30 01:44:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:39:18.160273"
    },
    {
      "arxiv_id": "2405.18984v1",
      "title": "Optimizing Vehicular Networks with Variational Quantum Circuits-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zijiang Yan",
        "Ramsundar Tanikella",
        "Hina Tabassum"
      ],
      "abstract": "In vehicular networks (VNets), ensuring both road safety and dependable\nnetwork connectivity is of utmost importance. Achieving this necessitates the\ncreation of resilient and efficient decision-making policies that prioritize\nmultiple objectives. In this paper, we develop a Variational Quantum Circuit\n(VQC)-based multi-objective reinforcement learning (MORL) framework to\ncharacterize efficient network selection and autonomous driving policies in a\nvehicular network (VNet). Numerical results showcase notable enhancements in\nboth convergence rates and rewards when compared to conventional deep-Q\nnetworks (DQNs), validating the efficacy of the VQC-MORL solution.",
      "tldr_zh": "该论文提出了一种基于 Variational Quantum Circuits (VQC) 的多目标强化学习 (MORL) 框架，用于优化车辆网络 (VNets)，以实现道路安全和可靠网络连接的决策策略。该框架通过 VQC 增强 MORL 的效率，针对网络选择和自动驾驶政策进行建模。实验结果显示，与传统的 Deep-Q Networks (DQNs) 相比，该方法在收敛速度和奖励方面取得了显著提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted By INFOCOM 2024 Poster - 2024 IEEE International Conference\n  on Computer Communications",
      "pdf_url": "http://arxiv.org/pdf/2405.18984v1",
      "published_date": "2024-05-29 10:57:25 UTC",
      "updated_date": "2024-05-29 10:57:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:39:29.397817"
    },
    {
      "arxiv_id": "2405.18968v1",
      "title": "UniIF: Unified Molecule Inverse Folding",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangyang Gao",
        "Jue Wang",
        "Cheng Tan",
        "Lirong Wu",
        "Yufei Huang",
        "Siyuan Li",
        "Zhirui Ye",
        "Stan Z. Li"
      ],
      "abstract": "Molecule inverse folding has been a long-standing challenge in chemistry and\nbiology, with the potential to revolutionize drug discovery and material\nscience. Despite specified models have been proposed for different small- or\nmacro-molecules, few have attempted to unify the learning process, resulting in\nredundant efforts. Complementary to recent advancements in molecular structure\nprediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified\nmodel UniIF for the inverse folding of all molecules. We do such unification in\ntwo levels: 1) Data-Level: We propose a unified block graph data form for all\nmolecules, including the local frame building and geometric feature\ninitialization. 2) Model-Level: We introduce a geometric block attention\nnetwork, comprising a geometric interaction, interactive attention and virtual\nlong-term dependency modules, to capture the 3D interactions of all molecules.\nThrough comprehensive evaluations across various tasks such as protein design,\nRNA design, and material design, we demonstrate that our proposed method\nsurpasses state-of-the-art methods on all tasks. UniIF offers a versatile and\neffective solution for general molecule inverse folding.",
      "tldr_zh": "本研究提出UniIF，一种统一的分子逆折叠模型，旨在解决分子逆折叠在化学和生物学中的挑战，并革新药物发现和材料科学。该模型在数据级上采用统一的块图数据形式，包括局部框架构建和几何特征初始化；在模型级上引入几何块注意力网络，包含几何交互、交互注意力模块和虚拟长期依赖模块，以捕捉所有分子的3D交互。UniIF基于RoseTTAFold All-Atom和AlphaFold3等进展，在蛋白质设计、RNA设计和材料设计等任务上超越了现有最先进方法。总体而言，该方法提供了一个通用的、有效的分子逆折叠解决方案。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18968v1",
      "published_date": "2024-05-29 10:26:16 UTC",
      "updated_date": "2024-05-29 10:26:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:39:41.867685"
    },
    {
      "arxiv_id": "2406.02579v1",
      "title": "An Open-Source Framework for Efficient Numerically-Tailored Computations",
      "title_zh": "一个高效数值定制计算的开源框架",
      "authors": [
        "Louis Ledoux",
        "Marc Casas"
      ],
      "abstract": "We present a versatile open-source framework designed to facilitate\nefficient, numerically-tailored Matrix-Matrix Multiplications (MMMs). The\nframework offers two primary contributions: first, a fine-tuned, automated\npipeline for arithmetic datapath generation, enabling highly customizable\nsystolic MMM kernels; second, seamless integration of the generated kernels\ninto user code, irrespective of the programming language employed, without\nnecessitating modifications.\n  The framework demonstrates a systematic enhancement in accuracy per energy\ncost across diverse High Performance Computing (HPC) workloads displaying a\nvariety of numerical requirements, such as Artificial Intelligence (AI)\ninference and Sea Surface Height (SSH) computation. For AI inference, we\nconsider a set of state-of-the-art neural network models, namely ResNet18,\nResNet34, ResNet50, DenseNet121, DenseNet161, DenseNet169, and VGG11, in\nconjunction with two datasets, two computer formats, and 27 distinct\nintermediate arithmetic datapaths. Our approach consistently reduces energy\nconsumption across all cases, with a notable example being the reduction by\nfactors of $3.3\\times$ for IEEE754-32 and $1.4\\times$ for Bfloat16 during\nImageNet inference with ResNet50. This is accomplished while maintaining\naccuracies of $82.3\\%$ and $86\\%$, comparable to those achieved with\nconventional Floating-Point Units (FPUs). In the context of SSH computation,\nour method achieves fully-reproducible results using double-precision words,\nsurpassing the accuracy of conventional double- and quad-precision arithmetic\nin FPUs. Our approach enhances SSH computation accuracy by a minimum of\n$5\\times$ and $27\\times$ compared to IEEE754-64 and IEEE754-128, respectively,\nresulting in $5.6\\times$ and $15.1\\times$ improvements in accuracy per power\ncost.",
      "tldr_zh": "本研究提出了一种通用的开源框架，用于高效的、针对数字优化的矩阵-矩阵乘法 (MMMs)。框架的主要贡献包括：一个微调的自动化管道，用于生成高度可定制的 systolic MMM kernels，以及将这些 kernels 无缝集成到用户代码中，而不依赖编程语言或需修改代码。该框架在 High Performance Computing (HPC) 工作负载中展示了系统性的改进，例如在 Artificial Intelligence (AI) 推理中，使用 ResNet50 等模型进行 ImageNet 推理时，能量消耗分别降低了 3.3 倍（IEEE754-32）和 1.4 倍（Bfloat16），同时保持了与 Floating-Point Units (FPUs) 相当的准确率（分别为 82.3% 和 86%）。在 Sea Surface Height (SSH) 计算中，该方法使用双精度词实现了完全可重现的结果，准确性至少比 IEEE754-64 和 IEEE754-128 提高了 5 倍和 27 倍，并提升了 5.6 倍和 15.1 倍的准确性每功率成本。",
      "categories": [
        "cs.MS",
        "cs.AI",
        "cs.AR",
        "cs.LG",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.MS",
      "comment": "6 pages, open-source",
      "pdf_url": "http://arxiv.org/pdf/2406.02579v1",
      "published_date": "2024-05-29 10:10:53 UTC",
      "updated_date": "2024-05-29 10:10:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:39:55.934535"
    },
    {
      "arxiv_id": "2405.18952v2",
      "title": "Are You Sure? Rank Them Again: Repeated Ranking For Better Preference Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Devine"
      ],
      "abstract": "Training Large Language Models (LLMs) with Reinforcement Learning from AI\nFeedback (RLAIF) aligns model outputs more closely with human preferences. This\ninvolves an evaluator model ranking multiple candidate responses to user\nprompts. However, the rankings from popular evaluator models such as GPT-4 can\nbe inconsistent. We propose the Repeat Ranking method - where we evaluate the\nsame responses multiple times and train only on those responses which are\nconsistently ranked. Using 2,714 prompts in 62 languages, we generated\nresponses from 7 top multilingual LLMs and had GPT-4 rank them five times each.\nEvaluating on MT-Bench chat benchmarks in six languages, our method\noutperformed the standard practice of training on all available prompts. Our\nwork highlights the quality versus quantity trade-off in RLAIF dataset\ngeneration and offers a stackable strategy for enhancing dataset and thus model\nquality.",
      "tldr_zh": "该论文提出Repeat Ranking方法，通过多次评估相同响应并仅训练那些排名一致的响应，来提升RLAIF（Reinforcement Learning from AI Feedback）中偏好数据集的质量，以解决评估器模型如GPT-4的不一致性问题。研究使用2,714个提示覆盖62种语言，从7个顶级多语言LLMs生成响应，并让GPT-4对每个响应进行五次排名。实验结果显示，该方法在六种语言的MT-Bench聊天基准上优于标准训练方式，突出了数据集生成中质量优先于数量的权衡，并提供了一种可叠加策略来提升模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18952v2",
      "published_date": "2024-05-29 10:08:31 UTC",
      "updated_date": "2024-06-01 02:18:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:40:06.674483"
    },
    {
      "arxiv_id": "2405.18942v3",
      "title": "Verifiably Robust Conformal Prediction",
      "title_zh": "可验证鲁棒保形预测",
      "authors": [
        "Linus Jeary",
        "Tom Kuipers",
        "Mehran Hosseini",
        "Nicola Paoletti"
      ],
      "abstract": "Conformal Prediction (CP) is a popular uncertainty quantification method that\nprovides distribution-free, statistically valid prediction sets, assuming that\ntraining and test data are exchangeable. In such a case, CP's prediction sets\nare guaranteed to cover the (unknown) true test output with a user-specified\nprobability. Nevertheless, this guarantee is violated when the data is\nsubjected to adversarial attacks, which often result in a significant loss of\ncoverage. Recently, several approaches have been put forward to recover CP\nguarantees in this setting. These approaches leverage variations of randomised\nsmoothing to produce conservative sets which account for the effect of the\nadversarial perturbations. They are, however, limited in that they only support\n$\\ell^2$-bounded perturbations and classification tasks. This paper introduces\nVRCP (Verifiably Robust Conformal Prediction), a new framework that leverages\nrecent neural network verification methods to recover coverage guarantees under\nadversarial attacks. Our VRCP method is the first to support perturbations\nbounded by arbitrary norms including $\\ell^1$, $\\ell^2$, and $\\ell^\\infty$, as\nwell as regression tasks. We evaluate and compare our approach on image\nclassification tasks (CIFAR10, CIFAR100, and TinyImageNet) and regression tasks\nfor deep reinforcement learning environments. In every case, VRCP achieves\nabove nominal coverage and yields significantly more efficient and informative\nprediction regions than the SotA.",
      "tldr_zh": "本文提出Verifiably Robust Conformal Prediction (VRCP)，一个新框架，用于在对抗攻击下恢复Conformal Prediction (CP)的覆盖保证，解决CP在数据交换性假设失效时的局限性。VRCP利用神经网络验证方法，支持任意范数边界扰动（如ℓ¹、ℓ²和ℓ∞），并扩展到回归任务，超越现有基于randomised smoothing的方法。实验结果显示，在CIFAR10、CIFAR100和TinyImageNet图像分类任务以及深度强化学习回归任务上，VRCP实现了高于名义覆盖率的性能，并提供了更高效、信息丰富的预测区域。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG",
        "68T37 (Primary) 68T27 (Secondary)",
        "G.3; I.2.4; F.4.1"
      ],
      "primary_category": "cs.LO",
      "comment": "Accepted at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18942v3",
      "published_date": "2024-05-29 09:50:43 UTC",
      "updated_date": "2024-11-16 17:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:40:20.405926"
    },
    {
      "arxiv_id": "2405.18931v1",
      "title": "EntProp: High Entropy Propagation for Improving Accuracy and Robustness",
      "title_zh": "EntProp：高熵传播用于提高准确性和鲁棒性",
      "authors": [
        "Shohei Enomoto"
      ],
      "abstract": "Deep neural networks (DNNs) struggle to generalize to out-of-distribution\ndomains that are different from those in training despite their impressive\nperformance. In practical applications, it is important for DNNs to have both\nhigh standard accuracy and robustness against out-of-distribution domains. One\ntechnique that achieves both of these improvements is disentangled learning\nwith mixture distribution via auxiliary batch normalization layers (ABNs). This\ntechnique treats clean and transformed samples as different domains, allowing a\nDNN to learn better features from mixed domains. However, if we distinguish the\ndomains of the samples based on entropy, we find that some transformed samples\nare drawn from the same domain as clean samples, and these samples are not\ncompletely different domains. To generate samples drawn from a completely\ndifferent domain than clean samples, we hypothesize that transforming clean\nhigh-entropy samples to further increase the entropy generates\nout-of-distribution samples that are much further away from the in-distribution\ndomain. On the basis of the hypothesis, we propose high entropy\npropagation~(EntProp), which feeds high-entropy samples to the network that\nuses ABNs. We introduce two techniques, data augmentation and free adversarial\ntraining, that increase entropy and bring the sample further away from the\nin-distribution domain. These techniques do not require additional training\ncosts. Our experimental results show that EntProp achieves higher standard\naccuracy and robustness with a lower training cost than the baseline methods.\nIn particular, EntProp is highly effective at training on small datasets.",
      "tldr_zh": "该论文针对深度神经网络 (DNNs) 在处理分布外域时的泛化问题，提出了一种高熵传播方法 EntProp，以提升标准准确性和鲁棒性。EntProp 基于辅助批标准化层 (ABNs) 的混合分布学习，假设通过进一步增加高熵样本的熵（如使用数据增强和免费对抗训练）可以生成更远离分布内的样本，从而改善特征学习。该方法无需额外训练成本，实验结果显示 EntProp 比基线方法在小数据集上实现了更高的准确性和鲁棒性表现。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted to UAI2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18931v1",
      "published_date": "2024-05-29 09:36:20 UTC",
      "updated_date": "2024-05-29 09:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:40:29.775169"
    },
    {
      "arxiv_id": "2405.18929v2",
      "title": "Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled Data",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroshi Takahashi",
        "Tomoharu Iwata",
        "Atsutoshi Kumagai",
        "Yuuki Yamanaka"
      ],
      "abstract": "Semi-supervised anomaly detection, which aims to improve the anomaly\ndetection performance by using a small amount of labeled anomaly data in\naddition to unlabeled data, has attracted attention. Existing semi-supervised\napproaches assume that most unlabeled data are normal, and train anomaly\ndetectors by minimizing the anomaly scores for the unlabeled data while\nmaximizing those for the labeled anomaly data. However, in practice, the\nunlabeled data are often contaminated with anomalies. This weakens the effect\nof maximizing the anomaly scores for anomalies, and prevents us from improving\nthe detection performance. To solve this problem, we propose the deep\npositive-unlabeled anomaly detection framework, which integrates\npositive-unlabeled learning with deep anomaly detection models such as\nautoencoders and deep support vector data descriptions. Our approach enables\nthe approximation of anomaly scores for normal data using the unlabeled data\nand the labeled anomaly data. Therefore, without labeled normal data, our\napproach can train anomaly detectors by minimizing the anomaly scores for\nnormal data while maximizing those for the labeled anomaly data. Experiments on\nvarious datasets show that our approach achieves better detection performance\nthan existing approaches.",
      "tldr_zh": "该研究针对半监督异常检测（semi-supervised anomaly detection）中的问题，提出了一种处理污染未标记数据的深度正-未标记异常检测框架（deep positive-unlabeled anomaly detection）。该框架将正-未标记学习（positive-unlabeled learning）与深度异常检测模型（如 autoencoders 和 deep support vector data descriptions）整合，使用未标记数据和标记异常数据来近似正常数据的异常分数，从而在没有标记正常数据的情况下优化检测器。实验结果显示，该方法在各种数据集上比现有方法实现了更好的检测性能。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Under revirew. Code is available at\n  https://github.com/takahashihiroshi/pusvdd",
      "pdf_url": "http://arxiv.org/pdf/2405.18929v2",
      "published_date": "2024-05-29 09:34:47 UTC",
      "updated_date": "2025-02-08 10:03:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:40:42.554783"
    },
    {
      "arxiv_id": "2405.18917v2",
      "title": "Causal Action Influence Aware Counterfactual Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Núria Armengol Urpí",
        "Marco Bagatella",
        "Marin Vlastelica",
        "Georg Martius"
      ],
      "abstract": "Offline data are both valuable and practical resources for teaching robots\ncomplex behaviors. Ideally, learning agents should not be constrained by the\nscarcity of available demonstrations, but rather generalize beyond the training\ndistribution. However, the complexity of real-world scenarios typically\nrequires huge amounts of data to prevent neural network policies from picking\nup on spurious correlations and learning non-causal relationships. We propose\nCAIAC, a data augmentation method that can create feasible synthetic\ntransitions from a fixed dataset without having access to online environment\ninteractions. By utilizing principled methods for quantifying causal influence,\nwe are able to perform counterfactual reasoning by swapping\n$\\it{action}$-unaffected parts of the state-space between independent\ntrajectories in the dataset. We empirically show that this leads to a\nsubstantial increase in robustness of offline learning algorithms against\ndistributional shift.",
      "tldr_zh": "该论文提出CAIAC，一种基于因果行动影响（causal action influence）的逆事实数据增强（counterfactual data augmentation）方法，用于从固定数据集生成可行合成转移，而无需在线环境交互。CAIAC通过量化因果影响，在数据集的独立轨迹之间交换不受行动影响的状态空间部分，从而实现逆事实推理，提升算法的泛化能力。实验结果显示，该方法显著提高了离线学习算法对分布偏移（distributional shift）的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted in 41st International Conference on Machine Learning (ICML\n  2024)",
      "pdf_url": "http://arxiv.org/pdf/2405.18917v2",
      "published_date": "2024-05-29 09:19:50 UTC",
      "updated_date": "2024-12-12 10:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:40:53.112261"
    },
    {
      "arxiv_id": "2405.18915v2",
      "title": "Towards Better Chain-of-Thought: A Reflection on Effectiveness and Faithfulness",
      "title_zh": "向着更好的链式思维：对有效性和忠实性的反思",
      "authors": [
        "Jiachun Li",
        "Pengfei Cao",
        "Yubo Chen",
        "Jiexin Xu",
        "Huaijun Li",
        "Xiaojian Jiang",
        "Kang Liu",
        "Jun Zhao"
      ],
      "abstract": "Chain-of-thought (CoT) prompting demonstrates varying performance under\ndifferent reasoning tasks. Previous work attempts to evaluate it but falls\nshort in providing an in-depth analysis of patterns that influence the CoT. In\nthis paper, we study the CoT performance from the perspective of effectiveness\nand faithfulness. For the former, we identify key factors that influence CoT\neffectiveness on performance improvement, including problem difficulty,\ninformation gain, and information flow. For the latter, we interpret the\nunfaithful CoT issue by conducting a joint analysis of the information\ninteraction among the question, CoT, and answer. The result demonstrates that,\nwhen the LLM predicts answers, it can recall correct information missing in the\nCoT from the question, leading to the problem. Finally, we propose a novel\nalgorithm to mitigate this issue, in which we recall extra information from the\nquestion to enhance the CoT generation and evaluate CoTs based on their\ninformation gain. Extensive experiments demonstrate that our approach enhances\nboth the faithfulness and effectiveness of CoT.",
      "tldr_zh": "这篇论文分析了 Chain-of-Thought (CoT) 提示在不同推理任务中的表现，从有效性(effectiveness)和忠实性(faithfulness)两个角度进行深入探讨。研究识别出影响 CoT 有效性的关键因素，包括问题难度(problem difficulty)、information gain 和 information flow，并通过信息互动分析揭示了 CoT 不忠实问题，即大型语言模型(LLM)在预测答案时可能从问题中回忆缺失信息。作者提出了一种新算法，通过从问题中提取额外信息增强 CoT 生成并基于 information gain 进行评估，实验结果显示该方法显著提高了 CoT 的忠实性和整体有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages, under review",
      "pdf_url": "http://arxiv.org/pdf/2405.18915v2",
      "published_date": "2024-05-29 09:17:46 UTC",
      "updated_date": "2025-03-03 13:25:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:41:07.390736"
    },
    {
      "arxiv_id": "2405.18910v1",
      "title": "Predicting Parking Availability in Singapore with Cross-Domain Data: A New Dataset and A Data-Driven Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Huaiwu Zhang",
        "Yutong Xia",
        "Siru Zhong",
        "Kun Wang",
        "Zekun Tong",
        "Qingsong Wen",
        "Roger Zimmermann",
        "Yuxuan Liang"
      ],
      "abstract": "The increasing number of vehicles highlights the need for efficient parking\nspace management. Predicting real-time Parking Availability (PA) can help\nmitigate traffic congestion and the corresponding social problems, which is a\npressing issue in densely populated cities like Singapore. In this study, we\naim to collectively predict future PA across Singapore with complex factors\nfrom various domains. The contributions in this paper are listed as follows:\n(1) A New Dataset: We introduce the \\texttt{SINPA} dataset, containing a year's\nworth of PA data from 1,687 parking lots in Singapore, enriched with various\nspatial and temporal factors. (2) A Data-Driven Approach: We present DeepPA, a\nnovel deep-learning framework, to collectively and efficiently predict future\nPA across thousands of parking lots. (3) Extensive Experiments and Deployment:\nDeepPA demonstrates a 9.2% reduction in prediction error for up to 3-hour\nforecasts compared to existing advanced models. Furthermore, we implement\nDeepPA in a practical web-based platform to provide real-time PA predictions to\naid drivers and inform urban planning for the governors in Singapore. We\nrelease the dataset and source code at https://github.com/yoshall/SINPA.",
      "tldr_zh": "这篇论文针对新加坡日益严重的停车位可用性（Parking Availability, PA）预测问题，提出了一种利用跨领域数据的数据驱动方法。主要贡献包括：引入了新的SINPA数据集，包含1,687个停车场的1年时空数据；以及开发了DeepPA框架，一个基于deep-learning的模型，用于高效集体预测数千个停车位的未来PA。实验结果显示，DeepPA在长达3小时的预测中比现有先进模型减少9.2%的错误，并已部署在web-based平台上，以辅助驾驶员和城市规划。作者还开源了数据集和代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IJCAI 2024 (Multi-Year Track On AI And Social Good with\n  ~20% acceptance rate)",
      "pdf_url": "http://arxiv.org/pdf/2405.18910v1",
      "published_date": "2024-05-29 09:11:51 UTC",
      "updated_date": "2024-05-29 09:11:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:41:20.272936"
    },
    {
      "arxiv_id": "2406.16899v2",
      "title": "Prompting or Fine-tuning? Exploring Large Language Models for Causal Graph Validation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuni Susanti",
        "Nina Holsmoelle"
      ],
      "abstract": "This study explores the capability of Large Language Models (LLMs) to\nevaluate causality in causal graphs generated by conventional statistical\ncausal discovery methods-a task traditionally reliant on manual assessment by\nhuman subject matter experts. To bridge this gap in causality assessment, LLMs\nare employed to evaluate the causal relationships by determining whether a\ncausal connection between variable pairs can be inferred from textual context.\nOur study compares two approaches: (1) prompting-based method for zero-shot and\nfew-shot causal inference and, (2) fine-tuning language models for the causal\nrelation prediction task. While prompt-based LLMs have demonstrated versatility\nacross various NLP tasks, our experiments on biomedical and general-domain\ndatasets show that fine-tuned models consistently outperform them, achieving up\nto a 20.5-point improvement in F1 score-even when using smaller-parameter\nlanguage models. These findings provide valuable insights into the strengths\nand limitations of both approaches for causal graph evaluation.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在评估由统计因果发现方法生成的因果图方面的能力，旨在取代传统的人工评估，通过从文本上下文中推断变量对之间的因果关系。研究比较了两种方法：基于提示的零样本和少样本因果推理，以及针对因果关系预测任务的微调(fine-tuning)方法。实验结果显示，在生物医学和通用领域数据集上，微调模型的表现优于基于提示的方法，提高F1分数高达20.5点，即使使用较小参数的语言模型。该研究为因果图评估提供了重要见解，突显了微调方法的优势和局限性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.16899v2",
      "published_date": "2024-05-29 09:06:18 UTC",
      "updated_date": "2025-04-09 04:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:41:33.553709"
    },
    {
      "arxiv_id": "2405.18902v2",
      "title": "A Causal Framework for Evaluating Deferring Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Palomba",
        "Andrea Pugnana",
        "José Manuel Alvarez",
        "Salvatore Ruggieri"
      ],
      "abstract": "Deferring systems extend supervised Machine Learning (ML) models with the\npossibility to defer predictions to human experts. However, evaluating the\nimpact of a deferring strategy on system accuracy is still an overlooked area.\nThis paper fills this gap by evaluating deferring systems through a causal\nlens. We link the potential outcomes framework for causal inference with\ndeferring systems, which allows to identify the causal impact of the deferring\nstrategy on predictive accuracy. We distinguish two scenarios. In the first\none, we have access to both the human and ML model predictions for the deferred\ninstances. Here, we can identify the individual causal effects for deferred\ninstances and the aggregates of them. In the second one, only human predictions\nare available for the deferred instances. Here, we can resort to regression\ndiscontinuity designs to estimate a local causal effect. We evaluate our\napproach on synthetic and real datasets for seven deferring systems from the\nliterature.",
      "tldr_zh": "这篇论文提出一个因果框架（Causal Framework），用于评估 deferring systems，这些系统允许监督机器学习（ML）模型将预测推迟给人类专家，以提升整体准确性。论文通过将潜在结果框架（potential outcomes framework）与 deferring systems 相结合，识别 deferring 策略对预测准确性的因果影响，并区分两种场景：在第一种场景中，可计算 deferred 实例的个体和聚合因果效应；在第二种场景中，使用回归不连续设计（regression discontinuity designs）估计局部因果效应。最终，研究在合成和真实数据集上评估了七个文献中的 deferring systems，填补了这一领域的评估空白。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at AISTATS 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.18902v2",
      "published_date": "2024-05-29 09:03:44 UTC",
      "updated_date": "2025-04-07 08:54:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:41:44.557179"
    },
    {
      "arxiv_id": "2405.18894v1",
      "title": "Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural Networks Using One Bayesian Test Vector",
      "title_zh": "翻译失败",
      "authors": [
        "Soyed Tuhin Ahmed",
        "Mehdi Tahoori"
      ],
      "abstract": "The performance of deep learning algorithms such as neural networks (NNs) has\nincreased tremendously recently, and they can achieve state-of-the-art\nperformance in many domains. However, due to memory and computation resource\nconstraints, implementing NNs on edge devices is a challenging task. Therefore,\nhardware accelerators such as computation-in-memory (CIM) with memristive\ndevices have been developed to accelerate the most common operations, i.e.,\nmatrix-vector multiplication. However, due to inherent device properties,\nexternal environmental factors such as temperature, and an immature fabrication\nprocess, memristors suffer from various non-idealities, including defects and\nvariations occurring during manufacturing and runtime. Consequently, there is a\nlack of complete confidence in the predictions made by the model. To improve\nconfidence in NN predictions made by hardware accelerators in the presence of\ndevice non-idealities, in this paper, we propose a Bayesian test vector\ngeneration framework that can estimate the model uncertainty of NNs implemented\non memristor-based CIM hardware. Compared to the conventional point estimate\ntest vector generation method, our method is more generalizable across\ndifferent model dimensions and requires storing only one test Bayesian vector\nin the hardware. Our method is evaluated on different model dimensions, tasks,\nfault rates, and variation noise to show that it can consistently achieve\n$100\\%$ coverage with only $0.024$ MB of memory overhead.",
      "tldr_zh": "该论文针对忆阻器-based 计算即内存 (CIM) 硬件上实现的深度神经网络 (NNs) 的不确定性问题，提出了一种 Few-Shot 测试方法，使用一个 Bayesian 测试向量来估计模型不确定性。该方法通过 Bayesian 测试向量生成框架，解决了传统点估计方法的局限性，提高了在不同模型维度和任务中的泛化能力，仅需存储一个测试向量。实验结果显示，该框架在各种故障率和变异噪声条件下实现了100%覆盖率，同时仅带来0.024 MB的内存开销，为硬件加速器中的可靠NN预测提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.ET"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18894v1",
      "published_date": "2024-05-29 08:53:16 UTC",
      "updated_date": "2024-05-29 08:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:41:55.381094"
    },
    {
      "arxiv_id": "2405.18889v1",
      "title": "On Perception of Prevalence of Cheating and Usage of Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Denkin"
      ],
      "abstract": "This report investigates the perceptions of teaching staff on the prevalence\nof student cheating and the impact of Generative AI on academic integrity. Data\nwas collected via an anonymous survey of teachers at the Department of\nInformation Technology at Uppsala University and analyzed alongside\ninstitutional statistics on cheating investigations from 2004 to 2023. The\nresults indicate that while teachers generally do not view cheating as highly\nprevalent, there is a strong belief that its incidence is increasing,\npotentially due to the accessibility of Generative AI. Most teachers do not\nequate AI usage with cheating but acknowledge its widespread use among\nstudents. Furthermore, teachers' perceptions align with objective data on\ncheating trends, highlighting their awareness of the evolving landscape of\nacademic dishonesty.",
      "tldr_zh": "本研究探讨了教师对学生作弊盛行程度的感知以及生成式 AI（Generative AI）对学术诚信的影响。研究通过对Uppsala University信息技术系教师的匿名调查和2004-2023年机构作弊调查数据的分析发现，虽然教师不认为作弊高度盛行，但他们相信其incidence正在增加，可能与Generative AI的易用性有关。大多数教师不将AI使用等同于cheating，但承认学生广泛使用AI，且教师的感知与客观作弊趋势数据一致。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18889v1",
      "published_date": "2024-05-29 08:46:00 UTC",
      "updated_date": "2024-05-29 08:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:42:07.746827"
    },
    {
      "arxiv_id": "2405.18886v2",
      "title": "Compressing Large Language Models using Low Rank and Low Precision Decomposition",
      "title_zh": "翻译失败",
      "authors": [
        "Rajarshi Saha",
        "Naomi Sagan",
        "Varun Srivastava",
        "Andrea J. Goldsmith",
        "Mert Pilanci"
      ],
      "abstract": "The prohibitive sizes of Large Language Models (LLMs) today make it difficult\nto deploy them on memory-constrained edge devices. This work introduces $\\rm\nCALDERA$ -- a new post-training LLM compression algorithm that harnesses the\ninherent low-rank structure of a weight matrix $\\mathbf{W}$ by approximating it\nvia a low-rank, low-precision decomposition as $\\mathbf{W} \\approx \\mathbf{Q} +\n\\mathbf{L}\\mathbf{R}$. Here, $\\mathbf{L}$ and $\\mathbf{R}$ are low rank\nfactors, and the entries of $\\mathbf{Q}$, $\\mathbf{L}$ and $\\mathbf{R}$ are\nquantized. The model is compressed by substituting each layer with its\n$\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ decomposition, and the zero-shot\nperformance of the compressed model is evaluated. Additionally, $\\mathbf{L}$\nand $\\mathbf{R}$ are readily amenable to low-rank adaptation, consequently\nenhancing the zero-shot performance. $\\rm CALDERA$ obtains this decomposition\nby formulating it as an optimization problem\n$\\min_{\\mathbf{Q},\\mathbf{L},\\mathbf{R}}\\lVert(\\mathbf{Q} +\n\\mathbf{L}\\mathbf{R} - \\mathbf{W})\\mathbf{X}^\\top\\rVert_{\\rm F}^2$, where\n$\\mathbf{X}$ is the calibration data, and $\\mathbf{Q}, \\mathbf{L}, \\mathbf{R}$\nare constrained to be representable using low-precision formats. Theoretical\nupper bounds on the approximation error of $\\rm CALDERA$ are established using\na rank-constrained regression framework, and the tradeoff between compression\nratio and model performance is studied by analyzing the impact of target rank\nand quantization bit budget. Results illustrate that compressing LlaMa-$2$\n$7$B/$13B$/$70$B and LlaMa-$3$ $8$B models using $\\rm CALDERA$ outperforms\nexisting post-training LLM compression techniques in the regime of less than\n$2.5$ bits per parameter. The implementation is available at:\nhttps://github.com/pilancilab/caldera.",
      "tldr_zh": "这篇论文提出了 CALDERA，一种后训练压缩 Large Language Models (LLMs) 的算法，通过低秩和低精度分解将权重矩阵 W 近似为 Q + L R 的形式，其中 L 和 R 是低秩因子，而 Q、L 和 R 的条目被量化，以实现高效模型压缩。算法通过优化问题最小化 (Q + L R - W) X^T 的 Frobenius 范数，并对因子施加低精度约束，同时建立了理论上界来分析压缩率与性能的权衡。实验结果显示，CALDERA 在压缩 LlaMa-2 (7B/13B/70B) 和 LlaMa-3 (8B) 模型时，在每参数少于 2.5 位的条件下，零样本性能优于现有后训练压缩技术。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to The 38th Conference on Neural Information Processing\n  Systems (NeurIPS 2024). [31 pages, 10 figures, 9 tables]",
      "pdf_url": "http://arxiv.org/pdf/2405.18886v2",
      "published_date": "2024-05-29 08:42:30 UTC",
      "updated_date": "2024-11-03 20:25:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:42:22.102588"
    },
    {
      "arxiv_id": "2405.18881v3",
      "title": "Inference-Time Alignment of Diffusion Models with Direct Noise Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiwei Tang",
        "Jiangweizhi Peng",
        "Jiasheng Tang",
        "Mingyi Hong",
        "Fan Wang",
        "Tsung-Hui Chang"
      ],
      "abstract": "In this work, we focus on the alignment problem of diffusion models with a\ncontinuous reward function, which represents specific objectives for downstream\ntasks, such as increasing darkness or improving the aesthetics of images. The\ncentral goal of the alignment problem is to adjust the distribution learned by\ndiffusion models such that the generated samples maximize the target reward\nfunction. We propose a novel alignment approach, named Direct Noise\nOptimization (DNO), that optimizes the injected noise during the sampling\nprocess of diffusion models. By design, DNO operates at inference-time, and\nthus is tuning-free and prompt-agnostic, with the alignment occurring in an\nonline fashion during generation. We rigorously study the theoretical\nproperties of DNO and also propose variants to deal with non-differentiable\nreward functions. Furthermore, we identify that naive implementation of DNO\noccasionally suffers from the out-of-distribution reward hacking problem, where\noptimized samples have high rewards but are no longer in the support of the\npretrained distribution. To remedy this issue, we leverage classical\nhigh-dimensional statistics theory to an effective probability regularization\ntechnique. We conduct extensive experiments on several important reward\nfunctions and demonstrate that the proposed DNO approach can achieve\nstate-of-the-art reward scores within a reasonable time budget for generation.",
      "tldr_zh": "本研究针对扩散模型（diffusion models）的对齐问题，提出了一种Direct Noise Optimization (DNO)方法，该方法通过优化采样过程中的注入噪声，使生成的样本最大化连续奖励函数（continuous reward function），以适应下游任务如提升图像美学或黑暗度。DNO在推理时（inference-time）运行，无需模型调优（tuning-free）且不依赖提示（prompt-agnostic），并通过理论分析和变体设计处理非可微奖励函数，同时引入概率正则化技术来避免out-of-distribution reward hacking问题。实验结果显示，DNO在多种重要奖励函数上实现了最先进的奖励分数，并在合理的生成时间内表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18881v3",
      "published_date": "2024-05-29 08:39:39 UTC",
      "updated_date": "2024-10-02 05:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:42:32.208314"
    },
    {
      "arxiv_id": "2405.18877v2",
      "title": "Continuous Product Graph Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Aref Einizade",
        "Fragkiskos D. Malliaros",
        "Jhony H. Giraldo"
      ],
      "abstract": "Processing multidomain data defined on multiple graphs holds significant\npotential in various practical applications in computer science. However,\ncurrent methods are mostly limited to discrete graph filtering operations.\nTensorial partial differential equations on graphs (TPDEGs) provide a\nprincipled framework for modeling structured data across multiple interacting\ngraphs, addressing the limitations of the existing discrete methodologies. In\nthis paper, we introduce Continuous Product Graph Neural Networks (CITRUS) that\nemerge as a natural solution to the TPDEG. CITRUS leverages the separability of\ncontinuous heat kernels from Cartesian graph products to efficiently implement\ngraph spectral decomposition. We conduct thorough theoretical analyses of the\nstability and over-smoothing properties of CITRUS in response to\ndomain-specific graph perturbations and graph spectra effects on the\nperformance. We evaluate CITRUS on well-known traffic and weather\nspatiotemporal forecasting datasets, demonstrating superior performance over\nexisting approaches. The implementation codes are available at\nhttps://github.com/ArefEinizade2/CITRUS.",
      "tldr_zh": "本论文提出 Continuous Product Graph Neural Networks (CITRUS)，一种基于 Tensorial partial differential equations on graphs (TPDEGs) 的框架，用于处理多域数据在多个交互图上的问题，从而克服现有离散图过滤方法的局限性。\nCITRUS 通过利用连续热核（continuous heat kernels）的可分离性，实现高效的图谱分解（graph spectral decomposition），并对模型的稳定性（stability）和过度平滑（over-smoothing）属性进行了理论分析。\n实验结果显示，CITRUS 在交通和天气时空预测数据集上优于现有方法，证明了其在实际应用中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "20 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.18877v2",
      "published_date": "2024-05-29 08:36:09 UTC",
      "updated_date": "2024-10-30 15:25:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:42:47.333200"
    },
    {
      "arxiv_id": "2405.18875v1",
      "title": "Counterfactual Metarules for Local and Global Recourse",
      "title_zh": "翻译失败",
      "authors": [
        "Tom Bewley",
        "Salim I. Amoukou",
        "Saumitra Mishra",
        "Daniele Magazzeni",
        "Manuela Veloso"
      ],
      "abstract": "We introduce T-CREx, a novel model-agnostic method for local and global\ncounterfactual explanation (CE), which summarises recourse options for both\nindividuals and groups in the form of human-readable rules. It leverages\ntree-based surrogate models to learn the counterfactual rules, alongside\n'metarules' denoting their regions of optimality, providing both a global\nanalysis of model behaviour and diverse recourse options for users. Experiments\nindicate that T-CREx achieves superior aggregate performance over existing\nrule-based baselines on a range of CE desiderata, while being orders of\nmagnitude faster to run.",
      "tldr_zh": "该论文引入了T-CREx，一种新型的模型无关方法，用于本地和全局反事实解释（counterfactual explanation, CE），通过人类可读规则总结个人和群体的补救选项（recourse options）。该方法利用基于树的代理模型（tree-based surrogate models）学习反事实规则，并生成“metarules”来表示这些规则的最优区域，从而提供对模型行为的全局分析和多样化的补救选择。实验结果显示，T-CREx 在各种CE标准上比现有基于规则的基准性能更优，并提高了几个数量级的运行速度。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18875v1",
      "published_date": "2024-05-29 08:35:17 UTC",
      "updated_date": "2024-05-29 08:35:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:42:55.426860"
    },
    {
      "arxiv_id": "2405.18870v2",
      "title": "LLMs achieve adult human performance on higher-order theory of mind tasks",
      "title_zh": "大型语言模型在高阶心智理论任务上达到成人人类表现水平",
      "authors": [
        "Winnie Street",
        "John Oliver Siy",
        "Geoff Keeling",
        "Adrien Baranes",
        "Benjamin Barnett",
        "Michael McKibben",
        "Tatenda Kanyere",
        "Alison Lentz",
        "Blaise Aguera y Arcas",
        "Robin I. M. Dunbar"
      ],
      "abstract": "This paper examines the extent to which large language models (LLMs) have\ndeveloped higher-order theory of mind (ToM); the human ability to reason about\nmultiple mental and emotional states in a recursive manner (e.g. I think that\nyou believe that she knows). This paper builds on prior work by introducing a\nhandwritten test suite -- Multi-Order Theory of Mind Q&A -- and using it to\ncompare the performance of five LLMs to a newly gathered adult human benchmark.\nWe find that GPT-4 and Flan-PaLM reach adult-level and near adult-level\nperformance on ToM tasks overall, and that GPT-4 exceeds adult performance on\n6th order inferences. Our results suggest that there is an interplay between\nmodel size and finetuning for the realisation of ToM abilities, and that the\nbest-performing LLMs have developed a generalised capacity for ToM. Given the\nrole that higher-order ToM plays in a wide range of cooperative and competitive\nhuman behaviours, these findings have significant implications for user-facing\nLLM applications.",
      "tldr_zh": "这篇论文评估了大型语言模型（LLMs）在更高阶理论-of-mind（ToM）任务上的表现，发现 GPT-4 和 Flan-PaLM 整体达到了成人人类水平，甚至 GPT-4 在 6th order inferences 上超过了成人表现。研究引入了手写的 Multi-Order Theory of Mind Q&A 测试套件，并将其与新收集的成人基准进行比较。结果表明，模型大小和 finetuning 之间存在互动，促成了 LLMs 的 ToM 能力发展。鉴于更高阶 ToM 在人类合作和竞争行为中的关键作用，这些发现对用户面对的 LLM 应用具有重要启示。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "I.2.7; H.1.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18870v2",
      "published_date": "2024-05-29 08:31:16 UTC",
      "updated_date": "2024-05-31 12:45:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:43:09.358828"
    },
    {
      "arxiv_id": "2405.18867v1",
      "title": "Topological Perspectives on Optimal Multimodal Embedding Spaces",
      "title_zh": "拓扑视角下的最优多模态嵌入空间",
      "authors": [
        "Abdul Aziz A. B",
        "A. B Abdul Rahim"
      ],
      "abstract": "Recent strides in multimodal model development have ignited a paradigm shift\nin the realm of text-to-image generation. Among these advancements, CLIP stands\nout as a remarkable achievement which is a sophisticated autoencoder adept at\nencoding both textual and visual information within a unified latent space.\nThis paper delves into a comparative analysis between CLIP and its recent\ncounterpart, CLOOB. To unravel the intricate distinctions within the embedding\nspaces crafted by these models, we employ topological data analysis. Our\napproach encompasses a comprehensive examination of the modality gap drivers,\nthe clustering structures existing across both high and low dimensions, and the\npivotal role that dimension collapse plays in shaping their respective\nembedding spaces. Empirical experiments substantiate the implications of our\nanalyses on downstream performance across various contextual scenarios. Through\nthis investigation, we aim to shed light on the nuanced intricacies that\nunderlie the comparative efficacy of CLIP and CLOOB, offering insights into\ntheir respective strengths and weaknesses, and providing a foundation for\nfurther refinement and advancement in multimodal model research.",
      "tldr_zh": "这篇论文使用 Topological Data Analysis 来比较多模态模型 CLIP 和 CLOOB 的嵌入空间差异。研究者分析了模态间隙驱动因素、高低维聚类结构以及维度坍缩对嵌入空间的影响，并通过实证实验验证这些差异如何影响下游任务性能。最终，该工作揭示了 CLIP 和 CLOOB 的优缺点，为多模态模型的优化和未来研究提供重要基础。",
      "categories": [
        "cs.AI",
        "68T05"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 17 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.18867v1",
      "published_date": "2024-05-29 08:28:23 UTC",
      "updated_date": "2024-05-29 08:28:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:43:21.045752"
    },
    {
      "arxiv_id": "2405.18852v1",
      "title": "LetsMap: Unsupervised Representation Learning for Semantic BEV Mapping",
      "title_zh": "翻译失败",
      "authors": [
        "Nikhil Gosala",
        "Kürsat Petek",
        "B Ravi Kiran",
        "Senthil Yogamani",
        "Paulo Drews-Jr",
        "Wolfram Burgard",
        "Abhinav Valada"
      ],
      "abstract": "Semantic Bird's Eye View (BEV) maps offer a rich representation with strong\nocclusion reasoning for various decision making tasks in autonomous driving.\nHowever, most BEV mapping approaches employ a fully supervised learning\nparadigm that relies on large amounts of human-annotated BEV ground truth data.\nIn this work, we address this limitation by proposing the first unsupervised\nrepresentation learning approach to generate semantic BEV maps from a monocular\nfrontal view (FV) image in a label-efficient manner. Our approach pretrains the\nnetwork to independently reason about scene geometry and scene semantics using\ntwo disjoint neural pathways in an unsupervised manner and then finetunes it\nfor the task of semantic BEV mapping using only a small fraction of labels in\nthe BEV. We achieve label-free pretraining by exploiting spatial and temporal\nconsistency of FV images to learn scene geometry while relying on a novel\ntemporal masked autoencoder formulation to encode the scene representation.\nExtensive evaluations on the KITTI-360 and nuScenes datasets demonstrate that\nour approach performs on par with the existing state-of-the-art approaches\nwhile using only 1% of BEV labels and no additional labeled data.",
      "tldr_zh": "本文提出 Let'sMap，一种无监督表示学习方法，用于从单目正面视图 (FV) 图像生成语义 Bird's Eye View (BEV) 地图，旨在减少对标注数据的依赖。方法通过两个独立的神经路径，无监督预训练网络来学习场景几何（利用空间和时间一致性）和场景语义（采用新型 temporal masked autoencoder 公式），然后仅使用 1% 的 BEV 标签进行微调。在 KITTI-360 和 nuScenes 数据集上的实验显示，该方法性能与现有最先进方法相当，同时无需额外标注数据。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.18852v1",
      "published_date": "2024-05-29 08:03:36 UTC",
      "updated_date": "2024-05-29 08:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:43:34.348095"
    },
    {
      "arxiv_id": "2405.18848v2",
      "title": "Anomaly Detection by Context Contrasting",
      "title_zh": "基于上下文对比的异常检测",
      "authors": [
        "Alain Ryser",
        "Thomas M. Sutter",
        "Alexander Marx",
        "Julia E. Vogt"
      ],
      "abstract": "Anomaly detection focuses on identifying samples that deviate from the norm.\nWhen working with high-dimensional data such as images, a crucial requirement\nfor detecting anomalous patterns is learning lower-dimensional representations\nthat capture concepts of normality. Recent advances in self-supervised learning\nhave shown great promise in this regard. However, many successful\nself-supervised anomaly detection methods assume prior knowledge about\nanomalies to create synthetic outliers during training. Yet, in real-world\napplications, we often do not know what to expect from unseen data, and we can\nsolely leverage knowledge about normal data. In this work, we propose Con$_2$,\nwhich learns representations through context augmentations that allow us to\nobserve samples from two distinct perspectives while keeping the invariances of\nnormal data. Con$_2$ learns rich representations of context-augmented samples\nby clustering them according to their context while simultaneously aligning\ntheir positions across clusters. At test time, representations of anomalies\nthat do not adhere to the invariances of normal data then deviate from their\nrespective context cluster. Learning representations in such a way thus allows\nus to detect anomalies without making assumptions about anomalous data.",
      "tldr_zh": "本论文提出了一种名为 Con$_2$ 的异常检测方法，针对高维数据如图像，通过上下文增强学习正常数据的低维表示，而不依赖于异常数据的先验知识。Con$_2$ 通过对增强样本进行聚类并同时对齐它们在聚类间的位子，保持正常数据的不变性，从而学习丰富的表示。在测试时，不符合正常数据不变性的异常样本会偏离其上下文聚类，实现无假设的异常检测。实验表明，这种自监督学习方法在真实世界应用中具有显著潜力。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18848v2",
      "published_date": "2024-05-29 07:59:06 UTC",
      "updated_date": "2024-10-14 08:48:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:43:46.827066"
    },
    {
      "arxiv_id": "2405.18845v1",
      "title": "Simulation, Modelling and Classification of Wiki Contributors: Spotting The Good, The Bad, and The Ugly",
      "title_zh": "翻译失败",
      "authors": [
        "Silvia García Méndez",
        "Fátima Leal",
        "Benedita Malheiro",
        "Juan Carlos Burguillo Rial",
        "Bruno Veloso",
        "Adriana E. Chis",
        "Horacio González Vélez"
      ],
      "abstract": "Data crowdsourcing is a data acquisition process where groups of voluntary\ncontributors feed platforms with highly relevant data ranging from news,\ncomments, and media to knowledge and classifications. It typically processes\nuser-generated data streams to provide and refine popular services such as\nwikis, collaborative maps, e-commerce sites, and social networks. Nevertheless,\nthis modus operandi raises severe concerns regarding ill-intentioned data\nmanipulation in adversarial environments. This paper presents a simulation,\nmodelling, and classification approach to automatically identify human and\nnon-human (bots) as well as benign and malign contributors by using data\nfabrication to balance classes within experimental data sets, data stream\nmodelling to build and update contributor profiles and, finally, autonomic data\nstream classification. By employing WikiVoyage - a free worldwide wiki travel\nguide open to contribution from the general public - as a testbed, our approach\nproves to significantly boost the confidence and quality of the classifier by\nusing a class-balanced data stream, comprising both real and synthetic data.\nOur empirical results show that the proposed method distinguishes between\nbenign and malign bots as well as human contributors with a classification\naccuracy of up to 92 %.",
      "tldr_zh": "这篇论文针对数据众包（data crowdsourcing）中的恶意数据操纵问题，提出了一种模拟、建模和分类方法，以自动识别人类和非人类（bots）贡献者，并区分良性和恶性贡献者。方法包括使用data fabrication平衡实验数据集、data stream modelling构建和更新贡献者配置文件，以及autonomic data stream classification进行动态分类。实验在WikiVoyage平台上进行，结果显示该方法在包含真实和合成数据的平衡数据流中，实现了高达92%的分类准确率，从而显著提升了贡献者识别的置信度和质量。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18845v1",
      "published_date": "2024-05-29 07:56:08 UTC",
      "updated_date": "2024-05-29 07:56:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:43:58.172837"
    },
    {
      "arxiv_id": "2405.18843v2",
      "title": "Data-driven Machinery Fault Diagnosis: A Comprehensive Review",
      "title_zh": "数据驱动的机械故障诊断：一个全面综述",
      "authors": [
        "Dhiraj Neupane",
        "Mohamed Reda Bouadjenek",
        "Richard Dazeley",
        "Sunil Aryal"
      ],
      "abstract": "In this era of advanced manufacturing, it's now more crucial than ever to\ndiagnose machine faults as early as possible to guarantee their safe and\nefficient operation. With the massive surge in industrial big data and\nadvancement in sensing and computational technologies, data-driven Machinery\nFault Diagnosis (MFD) solutions based on machine/deep learning approaches have\nbeen used ubiquitously in manufacturing. Timely and accurately identifying\nfaulty machine signals is vital in industrial applications for which many\nrelevant solutions have been proposed and are reviewed in many articles.\nDespite the availability of numerous solutions and reviews on MFD, existing\nworks often lack several aspects. Most of the available literature has limited\napplicability in a wide range of manufacturing settings due to their\nconcentration on a particular type of equipment or method of analysis.\nAdditionally, discussions regarding the challenges associated with implementing\ndata-driven approaches, such as dealing with noisy data, selecting appropriate\nfeatures, and adapting models to accommodate new or unforeseen faults, are\noften superficial or completely overlooked. Thus, this survey provides a\ncomprehensive review of the articles using different types of machine learning\napproaches for the detection and diagnosis of various types of machinery\nfaults, highlights their strengths and limitations, provides a review of the\nmethods used for condition-based analyses, comprehensively discusses the\navailable machinery fault datasets, introduces future researchers to the\npossible challenges they have to encounter while using these approaches for MFD\nand recommends the probable solutions to mitigate those problems. The future\nresearch prospects are also pointed out for a better understanding of the\nfield. We believe this article will help researchers and contribute to the\nfurther development of the field.",
      "tldr_zh": "这篇论文对数据驱动的 Machinery Fault Diagnosis (MFD) 进行了全面回顾，强调了在先进制造时代使用机器/深度学习方法早期检测机器故障的重要性，以确保设备的安全和高效运行。论文分析了各种机器学习方法在检测和诊断不同类型机械故障中的优势、局限性，并讨论了条件-based 分析方法以及可用的数据集，同时指出了实施挑战，如处理噪声数据、特征选择和适应新故障的策略。最终，它提出了潜在解决方案和未来研究方向，以推动该领域的发展。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in Neurocomputing",
      "pdf_url": "http://arxiv.org/pdf/2405.18843v2",
      "published_date": "2024-05-29 07:50:47 UTC",
      "updated_date": "2025-02-24 02:35:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:44:10.142066"
    },
    {
      "arxiv_id": "2405.18832v1",
      "title": "MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models",
      "title_zh": "翻译失败",
      "authors": [
        "Taehyun Kim",
        "Kwanseok Choi",
        "Youngmock Cho",
        "Jaehoon Cho",
        "Hyuk-Jae Lee",
        "Jaewoong Sim"
      ],
      "abstract": "Mixture-of-Experts (MoE) large language models (LLM) have memory requirements\nthat often exceed the GPU memory capacity, requiring costly parameter movement\nfrom secondary memories to the GPU for expert computation. In this work, we\npresent Mixture of Near-Data Experts (MoNDE), a near-data computing solution\nthat efficiently enables MoE LLM inference. MoNDE reduces the volume of MoE\nparameter movement by transferring only the $\\textit{hot}$ experts to the GPU,\nwhile computing the remaining $\\textit{cold}$ experts inside the host memory\ndevice. By replacing the transfers of massive expert parameters with the ones\nof small activations, MoNDE enables far more communication-efficient MoE\ninference, thereby resulting in substantial speedups over the existing\nparameter offloading frameworks for both encoder and decoder operations.",
      "tldr_zh": "该论文提出MoNDE（Mixture of Near-Data Experts），一种针对大规模稀疏模型的near-data computing解决方案，用于解决Mixture-of-Experts (MoE)大型语言模型(LLM)的内存限制问题。MoNDE通过仅将hot experts转移到GPU，而在主机内存中计算cold experts，从而减少参数传输量，取而代之以小激活传输。实验结果显示，MoNDE显著提升了MoE LLM推理的通信效率，在encoder和decoder操作上比现有参数卸载框架实现更快的速度。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to DAC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18832v1",
      "published_date": "2024-05-29 07:23:29 UTC",
      "updated_date": "2024-05-29 07:23:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:44:21.512947"
    },
    {
      "arxiv_id": "2405.18823v1",
      "title": "Why Reinforcement Learning in Energy Systems Needs Explanations",
      "title_zh": "为什么能源系统中强化学习需要解释",
      "authors": [
        "Hallah Shahid Butt",
        "Benjamin Schäfer"
      ],
      "abstract": "With economic development, the complexity of infrastructure has increased\ndrastically. Similarly, with the shift from fossil fuels to renewable sources\nof energy, there is a dire need for such systems that not only predict and\nforecast with accuracy but also help in understanding the process of\npredictions. Artificial intelligence and machine learning techniques have\nhelped in finding out wellperforming solutions to different problems in the\nenergy sector. However, the usage of state-of-the-art techniques like\nreinforcement learning is not surprisingly convincing. This paper discusses the\napplication of reinforcement techniques in energy systems and how explanations\nof these models can be helpful",
      "tldr_zh": "本论文讨论了强化学习（Reinforcement Learning）在能源系统中的应用背景，随着经济发展和从化石燃料向可再生能源的转型，能源基础设施日益复杂，需要准确预测并理解预测过程。现有AI和机器学习技术已在能源领域取得进展，但强化学习的应用仍面临说服力不足的问题，主要由于缺乏可解释性。论文强调，通过提供模型解释，可以帮助理解预测机制，从而提升强化学习在能源系统中的可靠性和实际价值。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18823v1",
      "published_date": "2024-05-29 07:09:00 UTC",
      "updated_date": "2024-05-29 07:09:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:44:34.009081"
    },
    {
      "arxiv_id": "2405.18820v1",
      "title": "Diffeomorphic interpolation for efficient persistence-based topological optimization",
      "title_zh": "微分同胚插值用于高效",
      "authors": [
        "Mathieu Carriere",
        "Marc Theveneau",
        "Théo Lacombe"
      ],
      "abstract": "Topological Data Analysis (TDA) provides a pipeline to extract quantitative\ntopological descriptors from structured objects. This enables the definition of\ntopological loss functions, which assert to what extent a given object exhibits\nsome topological properties. These losses can then be used to perform\ntopological optimizationvia gradient descent routines. While theoretically\nsounded, topological optimization faces an important challenge: gradients tend\nto be extremely sparse, in the sense that the loss function typically depends\non only very few coordinates of the input object, yielding dramatically slow\noptimization schemes in practice.Focusing on the central case of topological\noptimization for point clouds, we propose in this work to overcome this\nlimitation using diffeomorphic interpolation, turning sparse gradients into\nsmooth vector fields defined on the whole space, with quantifiable Lipschitz\nconstants. In particular, we show that our approach combines efficiently with\nsubsampling techniques routinely used in TDA, as the diffeomorphism derived\nfrom the gradient computed on a subsample can be used to update the coordinates\nof the full input object, allowing us to perform topological optimization on\npoint clouds at an unprecedented scale. Finally, we also showcase the relevance\nof our approach for black-box autoencoder (AE) regularization, where we aim at\nenforcing topological priors on the latent spaces associated to fixed,\npre-trained, black-box AE models, and where we show thatlearning a\ndiffeomorphic flow can be done once and then re-applied to new data in linear\ntime (while vanilla topological optimization has to be re-run from scratch).\nMoreover, reverting the flow allows us to generate data by sampling the\ntopologically-optimized latent space directly, yielding better interpretability\nof the model.",
      "tldr_zh": "该论文提出了一种基于微分同胚插值(diffeomorphic interpolation)的技术，用于提升基于持久性(persistence-based)的拓扑优化效率，解决拓扑数据分析(TDA)中梯度稀疏导致的优化缓慢问题。方法通过将稀疏梯度转化为平滑向量场，并结合子采样技术，使点云优化能够在更大规模上进行，同时量化Lipschitz常数以确保稳定性。在黑箱自编码器(AE)正则化应用中，该方法强制拓扑先验，允许一次性学习微分同胚流并线性时间应用于新数据，还能逆转流生成数据，从而提高模型的可解释性和实用性。",
      "categories": [
        "cs.AI",
        "cs.CG",
        "math.OC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18820v1",
      "published_date": "2024-05-29 07:00:28 UTC",
      "updated_date": "2024-05-29 07:00:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:44:57.302826"
    },
    {
      "arxiv_id": "2405.18810v1",
      "title": "UniPTS: A Unified Framework for Proficient Post-Training Sparsity",
      "title_zh": "翻译失败",
      "authors": [
        "Jingjing Xie",
        "Yuxin Zhang",
        "Mingbao Lin",
        "Zhihang Lin",
        "Liujuan Cao",
        "Rongrong Ji"
      ],
      "abstract": "Post-training Sparsity (PTS) is a recently emerged avenue that chases\nefficient network sparsity with limited data in need. Existing PTS methods,\nhowever, undergo significant performance degradation compared with traditional\nmethods that retrain the sparse networks via the whole dataset, especially at\nhigh sparsity ratios. In this paper, we attempt to reconcile this disparity by\ntransposing three cardinal factors that profoundly alter the performance of\nconventional sparsity into the context of PTS. Our endeavors particularly\ncomprise (1) A base-decayed sparsity objective that promotes efficient\nknowledge transferring from dense network to the sparse counterpart. (2) A\nreducing-regrowing search algorithm designed to ascertain the optimal sparsity\ndistribution while circumventing overfitting to the small calibration set in\nPTS. (3) The employment of dynamic sparse training predicated on the preceding\naspects, aimed at comprehensively optimizing the sparsity structure while\nensuring training stability. Our proposed framework, termed UniPTS, is\nvalidated to be much superior to existing PTS methods across extensive\nbenchmarks. As an illustration, it amplifies the performance of POT, a recently\nproposed recipe, from 3.9% to 68.6% when pruning ResNet-50 at 90% sparsity\nratio on ImageNet. We release the code of our paper at\nhttps://github.com/xjjxmu/UniPTS.",
      "tldr_zh": "本论文提出UniPTS，一种统一的Post-Training Sparsity (PTS)框架，旨在解决现有PTS方法在高稀疏率下性能显著下降的问题，通过有限数据实现高效网络稀疏化。UniPTS的关键创新包括base-decayed稀疏目标促进密集网络到稀疏网络的知识转移、reducing-regrowing搜索算法优化稀疏分布并避免小校准集过拟合，以及基于这些的动态稀疏训练以稳定结构优化。实验验证显示，UniPTS在ImageNet等基准上大幅超越现有方法，例如将ResNet-50在90%稀疏率下的性能从3.9%提升至68.6%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18810v1",
      "published_date": "2024-05-29 06:53:18 UTC",
      "updated_date": "2024-05-29 06:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:44:59.348858"
    },
    {
      "arxiv_id": "2405.18802v2",
      "title": "Enhancing Security and Privacy in Federated Learning using Low-Dimensional Update Representation and Proximity-Based Defense",
      "title_zh": "使用低维更新表示和基于邻近性防御增强联邦学习中的安全性和隐私",
      "authors": [
        "Wenjie Li",
        "Kai Fan",
        "Jingyuan Zhang",
        "Hui Li",
        "Wei Yang Bryan Lim",
        "Qiang Yang"
      ],
      "abstract": "Federated Learning (FL) is a promising privacy-preserving machine learning\nparadigm that allows data owners to collaboratively train models while keeping\ntheir data localized. Despite its potential, FL faces challenges related to the\ntrustworthiness of both clients and servers, particularly against curious or\nmalicious adversaries. In this paper, we introduce a novel framework named\n\\underline{F}ederated \\underline{L}earning with Low-Dimensional\n\\underline{U}pdate \\underline{R}epresentation and \\underline{P}roximity-Based\ndefense (FLURP), designed to address privacy preservation and resistance to\nByzantine attacks in distributed learning environments. FLURP employs\n$\\mathsf{LinfSample}$ method, enabling clients to compute the $l_{\\infty}$ norm\nacross sliding windows of updates, resulting in a Low-Dimensional Update\nRepresentation (LUR). Calculating the shared distance matrix among LURs, rather\nthan updates, significantly reduces the overhead of Secure Multi-Party\nComputation (SMPC) by three orders of magnitude while effectively\ndistinguishing between benign and poisoned updates. Additionally, FLURP\nintegrates a privacy-preserving proximity-based defense mechanism utilizing\noptimized SMPC protocols to minimize communication rounds. Our experiments\ndemonstrate FLURP's effectiveness in countering Byzantine adversaries with low\ncommunication and runtime overhead. FLURP offers a scalable framework for\nsecure and reliable FL in distributed environments, facilitating its\napplication in scenarios requiring robust data management and security.",
      "tldr_zh": "该研究针对联邦学习(Federated Learning, FL)中存在的隐私泄露和拜占庭攻击(Byzantine attacks)问题，提出了一种名为 FLURP 的新框架，以提升安全性和隐私保护。FLURP 采用 $\\mathsf{LinfSample}$ 方法计算更新滑动窗口的 $l_{\\infty}$ 范数，生成低维更新表示(Low-Dimensional Update Representation, LUR)，并通过计算 LUR 的共享距离矩阵来显著减少安全多方计算(Secure Multi-Party Computation, SMPC)的开销，降低三个数量级。框架还整合了基于邻近度的隐私保护防御机制，使用优化的 SMPC 协议最小化通信轮次。实验结果显示，FLURP 有效对抗恶意对手，同时保持低通信和运行时开销，为分布式环境中的安全 FL 应用提供了可扩展的解决方案。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.18802v2",
      "published_date": "2024-05-29 06:46:10 UTC",
      "updated_date": "2025-02-11 06:00:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:45:11.711256"
    },
    {
      "arxiv_id": "2405.18792v1",
      "title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of Deterministic RL Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Haanvid Lee",
        "Tri Wahyu Guntara",
        "Jongmin Lee",
        "Yung-Kyun Noh",
        "Kee-Eung Kim"
      ],
      "abstract": "We consider off-policy evaluation (OPE) of deterministic target policies for\nreinforcement learning (RL) in environments with continuous action spaces.\nWhile it is common to use importance sampling for OPE, it suffers from high\nvariance when the behavior policy deviates significantly from the target\npolicy. In order to address this issue, some recent works on OPE proposed\nin-sample learning with importance resampling. Yet, these approaches are not\napplicable to deterministic target policies for continuous action spaces. To\naddress this limitation, we propose to relax the deterministic target policy\nusing a kernel and learn the kernel metrics that minimize the overall mean\nsquared error of the estimated temporal difference update vector of an action\nvalue function, where the action value function is used for policy evaluation.\nWe derive the bias and variance of the estimation error due to this relaxation\nand provide analytic solutions for the optimal kernel metric. In empirical\nstudies using various test domains, we show that the OPE with in-sample\nlearning using the kernel with optimized metric achieves significantly improved\naccuracy than other baselines.",
      "tldr_zh": "该研究针对强化学习（RL）中确定性目标策略的离策略评估（OPE），特别是在连续动作空间下，解决了传统重要性采样（importance sampling）的高方差问题。作者提出了一种核度量学习（kernel metric learning）方法，通过使用核（kernel）放松确定性目标策略，并优化核度量以最小化行动价值函数的时间差更新向量的均方误差（mean squared error）。他们推导了该放松导致的估计误差的偏差和方差，并提供了最优核度量的解析解。在各种测试域的实证实验中，该方法比其他基线显著提高了OPE的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23 pages, 2 figures, Accepted at ICLR 2024 (spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2405.18792v1",
      "published_date": "2024-05-29 06:17:33 UTC",
      "updated_date": "2024-05-29 06:17:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:45:24.760148"
    },
    {
      "arxiv_id": "2405.18780v3",
      "title": "Certifying Counterfactual Bias in LLMs",
      "title_zh": "LLMs 中反事实偏差的认证",
      "authors": [
        "Isha Chaudhary",
        "Qian Hu",
        "Manoj Kumar",
        "Morteza Ziyadi",
        "Rahul Gupta",
        "Gagandeep Singh"
      ],
      "abstract": "Large Language Models (LLMs) can produce biased responses that can cause\nrepresentational harms. However, conventional studies are insufficient to\nthoroughly evaluate biases across LLM responses for different demographic\ngroups (a.k.a. counterfactual bias), as they do not scale to large number of\ninputs and do not provide guarantees. Therefore, we propose the first\nframework, LLMCert-B that certifies LLMs for counterfactual bias on\ndistributions of prompts. A certificate consists of high-confidence bounds on\nthe probability of unbiased LLM responses for any set of counterfactual prompts\n- prompts differing by demographic groups, sampled from a distribution. We\nillustrate counterfactual bias certification for distributions of\ncounterfactual prompts created by applying prefixes sampled from prefix\ndistributions, to a given set of prompts. We consider prefix distributions\nconsisting random token sequences, mixtures of manual jailbreaks, and\nperturbations of jailbreaks in LLM's embedding space. We generate non-trivial\ncertificates for SOTA LLMs, exposing their vulnerabilities over distributions\nof prompts generated from computationally inexpensive prefix distributions.",
      "tldr_zh": "这篇论文提出了 LLMCert-B 框架，这是第一个用于在提示分布上认证大型语言模型 (LLMs) 的反事实偏见 (counterfactual bias) 方法，以解决传统评估无法处理大规模输入和提供保证的问题。框架通过为任何一组反事实提示（prompts differing by demographic groups）生成高置信度边界，量化 LLMs 无偏响应的概率，并利用前缀分布（如随机 token 序列、手动 jailbreaks 的混合和嵌入空间扰动）来创建这些提示分布。实验结果显示，SOTA LLMs 在基于计算上廉价的前缀分布生成的提示上暴露了脆弱性，并生成了非平凡证书，为评估和缓解模型偏见提供了可靠工具。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.18780v3",
      "published_date": "2024-05-29 05:39:37 UTC",
      "updated_date": "2025-04-21 23:20:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:45:40.366500"
    },
    {
      "arxiv_id": "2405.18770v2",
      "title": "Multimodal Adversarial Defense for Vision-Language Models by Leveraging One-To-Many Relationships",
      "title_zh": "翻译失败",
      "authors": [
        "Futa Waseda",
        "Antonio Tejero-de-Pablos",
        "Isao Echizen"
      ],
      "abstract": "Pre-trained vision-language (VL) models are highly vulnerable to adversarial\nattacks. However, existing defense methods primarily focus on image\nclassification, overlooking two key aspects of VL tasks: multimodal attacks,\nwhere both image and text can be perturbed, and the one-to-many relationship of\nimages and texts, where a single image can correspond to multiple textual\ndescriptions and vice versa (1:N and N:1). This work is the first to explore\ndefense strategies against multimodal attacks in VL tasks, whereas prior VL\ndefense methods focus on vision robustness. We propose multimodal adversarial\ntraining (MAT), which incorporates adversarial perturbations in both image and\ntext modalities during training, significantly outperforming existing unimodal\ndefenses. Furthermore, we discover that MAT is limited by deterministic\none-to-one (1:1) image-text pairs in VL training data. To address this, we\nconduct a comprehensive study on leveraging one-to-many relationships to\nenhance robustness, investigating diverse augmentation techniques. Our analysis\nshows that, for a more effective defense, augmented image-text pairs should be\nwell-aligned, diverse, yet avoid distribution shift -- conditions overlooked by\nprior research. Our experiments show that MAT can effectively be applied to\ndifferent VL models and tasks to improve adversarial robustness, outperforming\nprevious efforts. Our code will be made public upon acceptance.",
      "tldr_zh": "该研究探讨了视觉语言模型（Vision-Language Models）对多模态攻击的脆弱性，首次提出针对图像和文本同时扰动的防御策略，强调了图像与文本的一对多关系（One-To-Many Relationships）。他们开发了多模态对抗训练（MAT），在训练过程中对图像和文本模态添加对抗扰动，显著优于现有的单模态防御方法。论文通过全面分析发现，增强的图像-文本对需保持良好对齐、多样化且避免分布偏移，以提升鲁棒性。实验结果显示，MAT 可应用于不同 VL 模型和任务，提高对抗鲁棒性，并超越先前努力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CV",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2405.18770v2",
      "published_date": "2024-05-29 05:20:02 UTC",
      "updated_date": "2025-03-18 14:32:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:45:49.111745"
    },
    {
      "arxiv_id": "2405.18762v2",
      "title": "Inpaint Biases: A Pathway to Accurate and Unbiased Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jiyoon Myung",
        "Jihyeon Park"
      ],
      "abstract": "This paper examines the limitations of advanced text-to-image models in\naccurately rendering unconventional concepts which are scarcely represented or\nabsent in their training datasets. We identify how these limitations not only\nconfine the creative potential of these models but also pose risks of\nreinforcing stereotypes. To address these challenges, we introduce the Inpaint\nBiases framework, which employs user-defined masks and inpainting techniques to\nenhance the accuracy of image generation, particularly for novel or\ninaccurately rendered objects. Through experimental validation, we demonstrate\nhow this framework significantly improves the fidelity of generated images to\nthe user's intent, thereby expanding the models' creative capabilities and\nmitigating the risk of perpetuating biases. Our study contributes to the\nadvancement of text-to-image models as unbiased, versatile tools for creative\nexpression.",
      "tldr_zh": "这篇论文探讨了文本到图像模型在渲染训练数据中稀少或缺失的概念时的局限性，这些问题不仅限制了模型的创造潜力，还可能强化刻板印象。为了解决这些挑战，作者提出了Inpaint Biases框架，该框架通过用户定义的masks和inpainting技术来提升图像生成的准确性，尤其针对新颖或不准确的对象。实验结果表明，该框架显著提高了生成图像与用户意图的契合度，扩展了模型的创造能力并降低了偏见风险，从而推动文本到图像模型向无偏见、多功能工具的演进。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted in CVPRW 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18762v2",
      "published_date": "2024-05-29 05:04:07 UTC",
      "updated_date": "2024-05-30 10:58:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:46:03.421211"
    },
    {
      "arxiv_id": "2405.18758v1",
      "title": "Learning to Continually Learn with the Bayesian Principle",
      "title_zh": "翻译失败",
      "authors": [
        "Soochan Lee",
        "Hyeonseong Jeon",
        "Jaehyeon Son",
        "Gunhee Kim"
      ],
      "abstract": "In the present era of deep learning, continual learning research is mainly\nfocused on mitigating forgetting when training a neural network with stochastic\ngradient descent on a non-stationary stream of data. On the other hand, in the\nmore classical literature of statistical machine learning, many models have\nsequential Bayesian update rules that yield the same learning outcome as the\nbatch training, i.e., they are completely immune to catastrophic forgetting.\nHowever, they are often overly simple to model complex real-world data. In this\nwork, we adopt the meta-learning paradigm to combine the strong\nrepresentational power of neural networks and simple statistical models'\nrobustness to forgetting. In our novel meta-continual learning framework,\ncontinual learning takes place only in statistical models via ideal sequential\nBayesian update rules, while neural networks are meta-learned to bridge the raw\ndata and the statistical models. Since the neural networks remain fixed during\ncontinual learning, they are protected from catastrophic forgetting. This\napproach not only achieves significantly improved performance but also exhibits\nexcellent scalability. Since our approach is domain-agnostic and\nmodel-agnostic, it can be applied to a wide range of problems and easily\nintegrated with existing model architectures.",
      "tldr_zh": "本研究探讨了持续学习（continual learning）中的遗忘问题，指出深度学习模型在非平稳数据流上训练时易受灾难性遗忘（catastrophic forgetting）影响，而经典统计模型则通过顺序 Bayesian 更新规则实现无遗忘学习。论文提出了一种新型 meta-continual learning 框架，其中统计模型负责持续学习并采用理想的 Bayesian 更新规则，神经网络则通过 meta-learning 桥接原始数据和统计模型，从而保持神经网络固定避免遗忘。该方法显著提升了学习性能，具有优秀的可扩展性，并适用于各种领域和模型架构，便于与现有系统集成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18758v1",
      "published_date": "2024-05-29 04:53:31 UTC",
      "updated_date": "2024-05-29 04:53:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:46:12.060042"
    },
    {
      "arxiv_id": "2405.18756v1",
      "title": "Provable Contrastive Continual Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yichen Wen",
        "Zhiquan Tan",
        "Kaipeng Zheng",
        "Chuanlong Xie",
        "Weiran Huang"
      ],
      "abstract": "Continual learning requires learning incremental tasks with dynamic data\ndistributions. So far, it has been observed that employing a combination of\ncontrastive loss and distillation loss for training in continual learning\nyields strong performance. To the best of our knowledge, however, this\ncontrastive continual learning framework lacks convincing theoretical\nexplanations. In this work, we fill this gap by establishing theoretical\nperformance guarantees, which reveal how the performance of the model is\nbounded by training losses of previous tasks in the contrastive continual\nlearning framework. Our theoretical explanations further support the idea that\npre-training can benefit continual learning. Inspired by our theoretical\nanalysis of these guarantees, we propose a novel contrastive continual learning\nalgorithm called CILA, which uses adaptive distillation coefficients for\ndifferent tasks. These distillation coefficients are easily computed by the\nratio between average distillation losses and average contrastive losses from\nprevious tasks. Our method shows great improvement on standard benchmarks and\nachieves new state-of-the-art performance.",
      "tldr_zh": "该论文探讨了持续学习（continual learning）中处理动态数据分布的问题，证明了结合对比损失（contrastive loss）和蒸馏损失（distillation loss）的训练框架能实现强性能，并首次提供了理论性能保证，解释模型表现如何受之前任务训练损失的影响。研究还通过理论分析支持预训练对持续学习的好处，并提出新算法 CILA，使用自适应蒸馏系数（adaptive distillation coefficients）来根据之前任务的损失比率动态调整系数。在标准基准测试中，CILA 显著提升了性能，达到了新的 state-of-the-art 水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.AP",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18756v1",
      "published_date": "2024-05-29 04:48:11 UTC",
      "updated_date": "2024-05-29 04:48:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:46:27.541819"
    },
    {
      "arxiv_id": "2405.18753v2",
      "title": "Confronting the Reproducibility Crisis: A Case Study of Challenges in Cybersecurity AI",
      "title_zh": "翻译失败",
      "authors": [
        "Richard H. Moulton",
        "Gary A. McCully",
        "John D. Hastings"
      ],
      "abstract": "In the rapidly evolving field of cybersecurity, ensuring the reproducibility\nof AI-driven research is critical to maintaining the reliability and integrity\nof security systems. This paper addresses the reproducibility crisis within the\ndomain of adversarial robustness -- a key area in AI-based cybersecurity that\nfocuses on defending deep neural networks against malicious perturbations.\nThrough a detailed case study, we attempt to validate results from prior work\non certified robustness using the VeriGauge toolkit, revealing significant\nchallenges due to software and hardware incompatibilities, version conflicts,\nand obsolescence. Our findings underscore the urgent need for standardized\nmethodologies, containerization, and comprehensive documentation to ensure the\nreproducibility of AI models deployed in critical cybersecurity applications.\nBy tackling these reproducibility challenges, we aim to contribute to the\nbroader discourse on securing AI systems against advanced persistent threats,\nenhancing network and IoT security, and protecting critical infrastructure.\nThis work advocates for a concerted effort within the research community to\nprioritize reproducibility, thereby strengthening the foundation upon which\nfuture cybersecurity advancements are built.",
      "tldr_zh": "这篇论文探讨了网络安全 AI 领域中的可复现性危机，特别是针对对抗鲁棒性(adversarial robustness)的挑战，通过一个案例研究使用 VeriGauge 工具验证先前的工作结果。研究发现，软件和硬件不兼容、版本冲突以及过时问题(obolescence)严重阻碍了实验的复现。论文呼吁采用标准化方法ologies、容器化(containerization)和全面文档(comprehensive documentation)，以提升 AI 模型在关键网络安全应用中的可靠性和完整性，从而为强化网络安全和防护先进持续威胁奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "I.2.0; D.4.6; K.6.5; I.5.1"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 0 figures, 2 tables, updated to incorporate feedback and\n  improvements",
      "pdf_url": "http://arxiv.org/pdf/2405.18753v2",
      "published_date": "2024-05-29 04:37:19 UTC",
      "updated_date": "2024-08-16 03:29:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:46:46.359144"
    },
    {
      "arxiv_id": "2405.18751v2",
      "title": "On the Limits of Multi-modal Meta-Learning with Auxiliary Task Modulation Using Conditional Batch Normalization",
      "title_zh": "翻译失败",
      "authors": [
        "Jordi Armengol-Estapé",
        "Vincent Michalski",
        "Ramnath Kumar",
        "Pierre-Luc St-Charles",
        "Doina Precup",
        "Samira Ebrahimi Kahou"
      ],
      "abstract": "Few-shot learning aims to learn representations that can tackle novel tasks\ngiven a small number of examples. Recent studies show that cross-modal learning\ncan improve representations for few-shot classification. More specifically,\nlanguage is a rich modality that can be used to guide visual learning. In this\nwork, we experiment with a multi-modal architecture for few-shot learning that\nconsists of three components: a classifier, an auxiliary network, and a bridge\nnetwork. While the classifier performs the main classification task, the\nauxiliary network learns to predict language representations from the same\ninput, and the bridge network transforms high-level features of the auxiliary\nnetwork into modulation parameters for layers of the few-shot classifier using\nconditional batch normalization. The bridge should encourage a form of\nlightweight semantic alignment between language and vision which could be\nuseful for the classifier. However, after evaluating the proposed approach on\ntwo popular few-shot classification benchmarks we find that a) the improvements\ndo not reproduce across benchmarks, and b) when they do, the improvements are\ndue to the additional compute and parameters introduced by the bridge network.\nWe contribute insights and recommendations for future work in multi-modal\nmeta-learning, especially when using language representations.",
      "tldr_zh": "本研究探讨了多模态元学习（multi-modal meta-learning）的局限性，特别使用辅助任务调制和 conditional batch normalization 来提升 few-shot learning 中的视觉学习。具体方法包括一个多模态架构：分类器处理主要任务，辅助网络预测语言表示，桥网络则通过 conditional batch normalization 将这些表示转化为分类器的调制参数，以实现轻量级语义对齐。实验结果显示，这种方法在两个 few-shot classification 基准上改进不稳定，且当有提升时，主要源于桥网络引入的额外计算和参数。该论文提供了对未来多模态元学习的见解和推荐，尤其在利用语言表示时。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18751v2",
      "published_date": "2024-05-29 04:29:12 UTC",
      "updated_date": "2024-05-30 14:13:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:46:48.815078"
    },
    {
      "arxiv_id": "2405.18742v1",
      "title": "Musical Phrase Segmentation via Grammatical Induction",
      "title_zh": "翻译失败",
      "authors": [
        "Reed Perkins",
        "Dan Ventura"
      ],
      "abstract": "We outline a solution to the challenge of musical phrase segmentation that\nuses grammatical induction algorithms, a class of algorithms which infer a\ncontext-free grammar from an input sequence. We analyze the performance of five\ngrammatical induction algorithms on three datasets using various musical\nviewpoint combinations. Our experiments show that the LONGESTFIRST algorithm\nachieves the best F1 scores across all three datasets and that input encodings\nthat include the duration viewpoint result in the best performance.",
      "tldr_zh": "这篇论文提出了一种通过语法归纳算法（grammatical induction algorithms）来实现音乐短语分割（musical phrase segmentation）的方法，这些算法从输入序列中推断上下文无关文法（context-free grammar）。\n研究者评估了五个语法归纳算法在三个数据集上的性能，并测试了各种音乐视点（musical viewpoint）组合。\n结果表明，LONGESTFIRST 算法在所有数据集上取得了最佳的 F1 scores，而包含持续时间视点（duration viewpoint）的输入编码显著提升了整体表现。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of a paper appearing in the proceedings of IJCAI\n  2024 that includes additional material in an appendix. Please cite the IJCAI\n  version",
      "pdf_url": "http://arxiv.org/pdf/2405.18742v1",
      "published_date": "2024-05-29 04:04:36 UTC",
      "updated_date": "2024-05-29 04:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:47:03.836883"
    },
    {
      "arxiv_id": "2405.18741v2",
      "title": "Genshin: General Shield for Natural Language Processing with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiao Peng",
        "Tao Liu",
        "Ying Wang"
      ],
      "abstract": "Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been\ntrending recently, demonstrating considerable advancement and generalizability\npower in countless domains. However, LLMs create an even bigger black box\nexacerbating opacity, with interpretability limited to few approaches. The\nuncertainty and opacity embedded in LLMs' nature restrict their application in\nhigh-stakes domains like financial fraud, phishing, etc. Current approaches\nmainly rely on traditional textual classification with posterior interpretable\nalgorithms, suffering from attackers who may create versatile adversarial\nsamples to break the system's defense, forcing users to make trade-offs between\nefficiency and robustness. To address this issue, we propose a novel cascading\nframework called Genshin (General Shield for Natural Language Processing with\nLarge Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike\nmost applications of LLMs that try to transform text into something new or\nstructural, Genshin uses LLMs to recover text to its original state. Genshin\naims to combine the generalizability of the LLM, the discrimination of the\nmedian model, and the interpretability of the simple model. Our experiments on\nthe task of sentimental analysis and spam detection have shown fatal flaws of\nthe current median models and exhilarating results on LLMs' recovery ability,\ndemonstrating that Genshin is both effective and efficient. In our ablation\nstudy, we unearth several intriguing observations. Utilizing the LLM defender,\na tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal\nmask rate results in the 3rd paradigm of NLP. Additionally, when employing the\nLLM as a potential adversarial tool, attackers are capable of executing\neffective attacks that are nearly semantically lossless.",
      "tldr_zh": "该研究提出了一种名为Genshin的通用防御框架，用于提升Large Language Models (LLMs)在自然语言处理中的鲁棒性，针对LLMs的不透明性和不确定性问题，这些问题限制了其在高风险领域如金融欺诈的应用。Genshin采用LLMs作为一次性防御插件，通过将文本恢复到原始状态，结合LLMs的泛化能力、中间模型的辨别能力和简单模型的可解释性，来抵御对抗样本攻击。在情感分析和垃圾邮件检测任务的实验中，Genshin展示了显著的恢复能力和效率优势，并通过消融研究揭示了LLMs在防御和潜在攻击中的双重作用，包括重现BERT的15%最优掩码率结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18741v2",
      "published_date": "2024-05-29 04:04:05 UTC",
      "updated_date": "2024-06-03 08:35:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:47:13.440141"
    },
    {
      "arxiv_id": "2405.18733v1",
      "title": "Efficient Learning in Chinese Checkers: Comparing Parameter Sharing in Multi-Agent Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Noah Adhikari",
        "Allen Gu"
      ],
      "abstract": "We show that multi-agent reinforcement learning (MARL) with full parameter\nsharing outperforms independent and partially shared architectures in the\ncompetitive perfect-information homogenous game of Chinese Checkers. To run our\nexperiments, we develop a new MARL environment: variable-size, six-player\nChinese Checkers. This custom environment was developed in PettingZoo and\nsupports all traditional rules of the game including chaining jumps. This is,\nto the best of our knowledge, the first implementation of Chinese Checkers that\nremains faithful to the true game.\n  Chinese Checkers is difficult to learn due to its large branching factor and\npotentially infinite horizons. We borrow the concept of branching actions\n(submoves) from complex action spaces in other RL domains, where a submove may\nnot end a player's turn immediately. This drastically reduces the\ndimensionality of the action space. Our observation space is inspired by\nAlphaGo with many binary game boards stacked in a 3D array to encode\ninformation.\n  The PettingZoo environment, training and evaluation logic, and analysis\nscripts can be found on\n\\href{https://github.com/noahadhikari/pettingzoo-chinese-checkers}{Github}.",
      "tldr_zh": "本研究比较了多智能体强化学习(MARL)中不同参数共享策略在中国跳棋游戏中的性能，发现完全参数共享架构在竞争性完美信息同质游戏中优于独立和部分共享架构。研究者开发了一个新的可变大小、六玩家中国跳棋环境，使用PettingZoo实现，并支持所有传统规则，包括连锁跳跃，这是首个忠实于真实游戏的实现。为应对游戏的大分支因子和潜在无限视野，论文引入分支动作(submoves)来减少行动空间维度，并采用类似AlphaGo的观察空间设计，通过堆叠二进制游戏板编码信息。实验结果和相关代码可在GitHub上获取。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18733v1",
      "published_date": "2024-05-29 03:27:30 UTC",
      "updated_date": "2024-05-29 03:27:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:47:29.275293"
    },
    {
      "arxiv_id": "2405.18732v3",
      "title": "Gemini & Physical World: Large Language Models Can Estimate the Intensity of Earthquake Shaking from Multi-Modal Social Media Posts",
      "title_zh": "翻译失败",
      "authors": [
        "S. Mostafa Mousavi",
        "Marc Stogaitis",
        "Tajinder Gadh",
        "Richard M Allen",
        "Alexei Barski",
        "Robert Bosch",
        "Patrick Robertson",
        "Nivetha Thiruverahan",
        "Youngmin Cho",
        "Aman Raj"
      ],
      "abstract": "This paper presents a novel approach to extract scientifically valuable\ninformation about Earth's physical phenomena from unconventional sources, such\nas multi-modal social media posts. Employing a state-of-the-art large language\nmodel (LLM), Gemini 1.5 Pro (Reid et al. 2024), we estimate earthquake ground\nshaking intensity from these unstructured posts. The model's output, in the\nform of Modified Mercalli Intensity (MMI) values, aligns well with independent\nobservational data. Furthermore, our results suggest that LLMs, trained on vast\ninternet data, may have developed a unique understanding of physical phenomena.\nSpecifically, Google's Gemini models demonstrate a simplified understanding of\nthe general relationship between earthquake magnitude, distance, and MMI\nintensity, accurately describing observational data even though it's not\nidentical to established models. These findings raise intriguing questions\nabout the extent to which Gemini's training has led to a broader understanding\nof the physical world and its phenomena. The ability of Generative AI models\nlike Gemini to generate results consistent with established scientific\nknowledge highlights their potential to augment our understanding of complex\nphysical phenomena like earthquakes. The flexible and effective approach\nproposed in this study holds immense potential for enriching our understanding\nof the impact of physical phenomena and improving resilience during natural\ndisasters. This research is a significant step toward harnessing the power of\nsocial media and AI for natural disaster mitigation, opening new avenues for\nunderstanding the emerging capabilities of Generative AI and LLMs for\nscientific applications.",
      "tldr_zh": "本研究提出了一种创新方法，使用大型语言模型（Large Language Models, LLMs）如 Gemini 1.5 Pro，从多模态社交媒体帖子中估计地震震动的 Modified Mercalli Intensity (MMI) 值。结果显示，该模型的输出与独立观测数据高度一致，表明 LLMs 在训练过程中可能发展出对地震震级、距离与 MMI 关系的简化理解。研究揭示了 Generative AI 在处理物理现象方面的潜力，为提升自然灾害缓解策略提供了新途径，并强调了社交媒体和 AI 在科学应用中的重要作用。",
      "categories": [
        "physics.geo-ph",
        "cs.AI",
        "cs.LG",
        "physics.app-ph"
      ],
      "primary_category": "physics.geo-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18732v3",
      "published_date": "2024-05-29 03:23:34 UTC",
      "updated_date": "2024-06-14 17:12:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:47:47.231868"
    },
    {
      "arxiv_id": "2405.18731v4",
      "title": "VBIM-Net: Variational Born Iterative Network for Inverse Scattering Problems",
      "title_zh": "VBIM-Net：变分 Born 迭代网络用于逆散射问题",
      "authors": [
        "Ziqing Xing",
        "Zhaoyang Zhang",
        "Zirui Chen",
        "Yusong Wang",
        "Haoran Ma",
        "Zhun Wei"
      ],
      "abstract": "Recently, studies have shown the potential of integrating field-type\niterative methods with deep learning (DL) techniques in solving inverse\nscattering problems (ISPs). In this article, we propose a novel Variational\nBorn Iterative Network, namely, VBIM-Net, to solve the full-wave ISPs with\nsignificantly improved structural rationality and inversion quality. The\nproposed VBIM-Net emulates the alternating updates of the total electric field\nand the contrast in the variational Born iterative method (VBIM) by multiple\nlayers of subnetworks. We embed the analytical calculation of the contrast\nvariation into each subnetwork, converting the scattered field residual into an\napproximate contrast variation and then enhancing it by a U-Net, thus avoiding\nthe requirement of matched measurement dimension and grid resolution as in\nexisting approaches. The total field and contrast of each layer's output is\nsupervised in the loss function of VBIM-Net, imposing soft physical constraints\non the variables in the subnetworks, which benefits the model's performance. In\naddition, we design a training scheme with extra noise to enhance the model's\nstability. Extensive numerical results on synthetic and experimental data both\nverify the inversion quality, generalization ability, and robustness of the\nproposed VBIM-Net. This work may provide some new inspiration for the design of\nefficient field-type DL schemes.",
      "tldr_zh": "本研究提出了一种新型网络 VBIM-Net，用于解决反散射问题（ISPs），它将变分 Born 迭代方法（VBIM）与深度学习（DL）技术相结合，提高了结构合理性和反演质量。VBIM-Net 通过多个子网络模拟总电场和对比度的交替更新，并在每个子网络中嵌入对比度变动的分析计算，并利用 U-Net 增强散射场残差，从而避免了现有方法对测量维度和网格分辨率的需求。损失函数中对总场和对比度进行监督，并采用带额外噪声的训练方案，以施加软物理约束并提升模型稳定性；实验结果显示，VBIM-Net 在合成和实验数据上表现出色，具有优秀的反演质量、泛化能力和鲁棒性，为设计高效的场型 DL 方案提供了新灵感。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "eess.SP",
      "comment": "This article has been published in IEEE Transactions on Geoscience\n  and Remote Sensing",
      "pdf_url": "http://arxiv.org/pdf/2405.18731v4",
      "published_date": "2024-05-29 03:21:09 UTC",
      "updated_date": "2025-02-02 13:24:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:47:50.732050"
    },
    {
      "arxiv_id": "2405.18729v1",
      "title": "Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Tianle Zhang",
        "Jiayi Guan",
        "Lin Zhao",
        "Yihang Li",
        "Dongjiang Li",
        "Zecui Zeng",
        "Lei Sun",
        "Yue Chen",
        "Xuelong Wei",
        "Lusong Li",
        "Xiaodong He"
      ],
      "abstract": "Offline reinforcement learning (RL) aims to learn optimal policies from\npreviously collected datasets. Recently, due to their powerful representational\ncapabilities, diffusion models have shown significant potential as policy\nmodels for offline RL issues. However, previous offline RL algorithms based on\ndiffusion policies generally adopt weighted regression to improve the policy.\nThis approach optimizes the policy only using the collected actions and is\nsensitive to Q-values, which limits the potential for further performance\nenhancement. To this end, we propose a novel preferred-action-optimized\ndiffusion policy for offline RL. In particular, an expressive conditional\ndiffusion model is utilized to represent the diverse distribution of a behavior\npolicy. Meanwhile, based on the diffusion model, preferred actions within the\nsame behavior distribution are automatically generated through the critic\nfunction. Moreover, an anti-noise preference optimization is designed to\nachieve policy improvement by using the preferred actions, which can adapt to\nnoise-preferred actions for stable training. Extensive experiments demonstrate\nthat the proposed method provides competitive or superior performance compared\nto previous state-of-the-art offline RL methods, particularly in sparse reward\ntasks such as Kitchen and AntMaze. Additionally, we empirically prove the\neffectiveness of anti-noise preference optimization.",
      "tldr_zh": "本文提出了一种名为Preferred-Action-Optimized Diffusion Policies的离线强化学习(Offline RL)方法，以解决现有基于扩散模型(Diffusion Models)策略的局限性，如仅使用收集动作并对Q-values敏感的问题。 该方法利用条件扩散模型表示行为策略的多样分布，通过批评函数(Critic Function)自动生成分布内的首选动作，并设计抗噪声首选优化(Anti-Noise Preference Optimization)来实现策略改进，确保训练稳定性。 实验显示，该方法在稀疏奖励任务（如Kitchen和AntMaze）上比现有最先进离线RL算法表现更优或相当，并证明了抗噪声优化的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18729v1",
      "published_date": "2024-05-29 03:19:59 UTC",
      "updated_date": "2024-05-29 03:19:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:48:03.184793"
    },
    {
      "arxiv_id": "2405.18727v2",
      "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Inherent Control",
      "title_zh": "CtrlA：基于内在控制的适应性检索增强生成",
      "authors": [
        "Huanshuo Liu",
        "Hao Zhang",
        "Zhijiang Guo",
        "Jing Wang",
        "Kuicai Dong",
        "Xiangyang Li",
        "Yi Quan Lee",
        "Cong Zhang",
        "Yong Liu"
      ],
      "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution for\nmitigating hallucinations of large language models (LLMs) with retrieved\nexternal knowledge. Adaptive RAG enhances this approach by enabling dynamic\nretrieval during generation, activating retrieval only when the query exceeds\nLLM's internal knowledge. Existing methods primarily focus on detecting LLM's\nconfidence via statistical uncertainty. Instead, we present the first attempts\nto solve adaptive RAG from a representation perspective and develop an inherent\ncontrol-based framework, termed \\name. Specifically, we extract the features\nthat represent the honesty and confidence directions of LLM and adopt them to\ncontrol LLM behavior and guide retrieval timing decisions. We also design a\nsimple yet effective query formulation strategy to support adaptive retrieval.\nExperiments show that \\name is superior to existing adaptive RAG methods on a\ndiverse set of tasks, the honesty steering can effectively make LLMs more\nhonest and confidence monitoring is a promising indicator of retrieval\ntrigger.Our code is available at \\url{https://github.com/HSLiu-Initial/CtrlA}.",
      "tldr_zh": "该论文提出CtrlA框架，一种基于内在控制的Adaptive Retrieval-Augmented Generation (RAG)方法，用于动态决定何时检索外部知识以减少大型语言模型 (LLMs) 的幻觉。不同于现有方法依赖统计不确定性，CtrlA从表示视角提取LLMs的诚实和信心特征，用于控制模型行为和指导检索时机，并设计了一个简单的查询制定策略。实验结果显示，CtrlA在多种任务上优于现有Adaptive RAG方法，诚实导向显著提升LLMs的诚实性，而信心监控作为检索触发指标表现出色。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "29 pages, 10 figures, 11 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.18727v2",
      "published_date": "2024-05-29 03:17:16 UTC",
      "updated_date": "2024-10-03 20:09:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:48:13.467950"
    },
    {
      "arxiv_id": "2405.18724v2",
      "title": "Adapting Differential Molecular Representation with Hierarchical Prompts for Multi-label Property Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Linjia Kang",
        "Songhua Zhou",
        "Shuyan Fang",
        "Shichao Liu"
      ],
      "abstract": "Accurate prediction of molecular properties is crucial in drug discovery.\nTraditional methods often overlook that real-world molecules typically exhibit\nmultiple property labels with complex correlations. To this end, we propose a\nnovel framework, HiPM, which stands for hierarchical prompted molecular\nrepresentation learning framework. HiPM leverages task-aware prompts to enhance\nthe differential expression of tasks in molecular representations and mitigate\nnegative transfer caused by conflicts in individual task information. Our\nframework comprises two core components: the Molecular Representation Encoder\n(MRE) and the Task-Aware Prompter (TAP). MRE employs a hierarchical\nmessage-passing network architecture to capture molecular features at both the\natom and motif levels. Meanwhile, TAP utilizes agglomerative hierarchical\nclustering algorithm to construct a prompt tree that reflects task affinity and\ndistinctiveness, enabling the model to consider multi-granular correlation\ninformation among tasks, thereby effectively handling the complexity of\nmulti-label property prediction. Extensive experiments demonstrate that HiPM\nachieves state-of-the-art performance across various multi-label datasets,\noffering a novel perspective on multi-label molecular representation learning.",
      "tldr_zh": "该研究针对分子属性的多标签预测问题，提出了一种新框架 HiPM（Hierarchical Prompted Molecular Representation Learning Framework），以解决传统方法忽略多标签复杂相关性的局限性。HiPM 包括两个核心组件：Molecular Representation Encoder (MRE)，采用分层消息传递网络捕捉原子和基序级别的分子特征；以及 Task-Aware Prompter (TAP)，通过凝聚层次聚类算法构建提示树，增强任务感知提示并减轻负面转移。实验结果显示，HiPM 在多种多标签分子数据集上实现了最先进性能，为多标签分子表示学习提供了新视角。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18724v2",
      "published_date": "2024-05-29 03:10:21 UTC",
      "updated_date": "2024-08-11 07:02:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:48:25.862221"
    },
    {
      "arxiv_id": "2405.18723v3",
      "title": "Conformal Depression Prediction",
      "title_zh": "保形抑郁预测",
      "authors": [
        "Yonghong Li",
        "Xiuzhuang Zhou"
      ],
      "abstract": "While existing depression prediction methods based on deep learning show\npromise, their practical application is hindered by the lack of\ntrustworthiness, as these deep models are often deployed as black box models,\nleaving us uncertain on the confidence of their predictions. For high-risk\nclinical applications like depression prediction, uncertainty quantification is\nessential in decision-making. In this paper, we introduce conformal depression\nprediction (CDP), a depression prediction method with uncertainty\nquantification based on conformal prediction (CP), giving valid confidence\nintervals with theoretical coverage guarantees for the model predictions. CDP\nis a plug-and-play module that requires neither model retraining nor an\nassumption about the depression data distribution. As CDP provides only an\naverage coverage guarantee across all inputs rather than per-input performance\nguarantee, we further propose CDP-ACC, an improved conformal prediction with\napproximate conditional coverage. CDP-ACC firstly estimates the prediction\ndistribution through neighborhood relaxation, and then introduces a conformal\nscore function by constructing nested sequences, so as to provide a tighter\nprediction interval adaptive to specific input. We empirically demonstrate the\napplication of CDP in uncertainty-aware facial depression prediction, as well\nas the effectiveness and superiority of CDP-ACC on the AVEC 2013 and AVEC 2014\ndatasets. Our code is publicly available at https://github.com/PushineLee/CDP.",
      "tldr_zh": "本研究针对现有深度学习抑郁预测方法的黑盒问题，提出 Conformal Depression Prediction (CDP)，这是一种基于 Conformal Prediction (CP) 的不确定性量化方法，能够为模型预测提供理论上保证的置信区间，且作为即插即用模块，无需模型重新训练或数据分布假设。CDP 仅提供平均覆盖保证，为提升针对特定输入的性能，作者进一步开发了 CDP-ACC，通过邻域松弛估计预测分布并构建嵌套序列的共形分数函数，实现更精确的自适应预测区间。在 AVEC 2013 和 AVEC 2014 数据集上的实验验证了 CDP 在不确定性感知的面部抑郁预测中的有效性，以及 CDP-ACC 的优越表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18723v3",
      "published_date": "2024-05-29 03:08:30 UTC",
      "updated_date": "2024-08-27 07:31:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:48:38.432959"
    },
    {
      "arxiv_id": "2405.18721v2",
      "title": "Correctable Landmark Discovery via Large Models for Vision-Language Navigation",
      "title_zh": "翻译失败",
      "authors": [
        "Bingqian Lin",
        "Yunshuang Nie",
        "Ziming Wei",
        "Yi Zhu",
        "Hang Xu",
        "Shikui Ma",
        "Jianzhuang Liu",
        "Xiaodan Liang"
      ],
      "abstract": "Vision-Language Navigation (VLN) requires the agent to follow language\ninstructions to reach a target position. A key factor for successful navigation\nis to align the landmarks implied in the instruction with diverse visual\nobservations. However, previous VLN agents fail to perform accurate modality\nalignment especially in unexplored scenes, since they learn from limited\nnavigation data and lack sufficient open-world alignment knowledge. In this\nwork, we propose a new VLN paradigm, called COrrectable LaNdmark DiScOvery via\nLarge ModEls (CONSOLE). In CONSOLE, we cast VLN as an open-world sequential\nlandmark discovery problem, by introducing a novel correctable landmark\ndiscovery scheme based on two large models ChatGPT and CLIP. Specifically, we\nuse ChatGPT to provide rich open-world landmark cooccurrence commonsense, and\nconduct CLIP-driven landmark discovery based on these commonsense priors. To\nmitigate the noise in the priors due to the lack of visual constraints, we\nintroduce a learnable cooccurrence scoring module, which corrects the\nimportance of each cooccurrence according to actual observations for accurate\nlandmark discovery. We further design an observation enhancement strategy for\nan elegant combination of our framework with different VLN agents, where we\nutilize the corrected landmark features to obtain enhanced observation features\nfor action decision. Extensive experimental results on multiple popular VLN\nbenchmarks (R2R, REVERIE, R4R, RxR) show the significant superiority of CONSOLE\nover strong baselines. Especially, our CONSOLE establishes the new\nstate-of-the-art results on R2R and R4R in unseen scenarios. Code is available\nat https://github.com/expectorlin/CONSOLE.",
      "tldr_zh": "本研究针对Vision-Language Navigation (VLN)中标志物与视觉观察的对齐问题，提出了一种新范式CONSOLE（Correctable Landmark Discovery via Large Models），将VLN转化为开放世界的顺序标志物发现任务。CONSOLE利用ChatGPT提供丰富的标志物共现常识，并结合CLIP驱动的发现机制，再通过可学习的共现评分模块根据实际观察纠正噪声，以实现准确的标志物识别和观察增强策略。实验结果显示，CONSOLE在多个VLN基准（如R2R、REVERIE、R4R和RxR）上显著优于基线，尤其在未见场景中，在R2R和R4R上建立了新的最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by TPAMI 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.18721v2",
      "published_date": "2024-05-29 03:05:59 UTC",
      "updated_date": "2024-06-05 09:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:48:50.447803"
    },
    {
      "arxiv_id": "2405.18719v2",
      "title": "Contextual Position Encoding: Learning to Count What's Important",
      "title_zh": "翻译失败",
      "authors": [
        "Olga Golovneva",
        "Tianlu Wang",
        "Jason Weston",
        "Sainbayar Sukhbaatar"
      ],
      "abstract": "The attention mechanism is a critical component of Large Language Models\n(LLMs) that allows tokens in a sequence to interact with each other, but is\norder-invariant. Incorporating position encoding (PE) makes it possible to\naddress by position, such as attending to the i-th token. However, current PE\nmethods use token counts to derive position, and thus cannot generalize to\nhigher levels of abstraction, such as attending to the i-th sentence. In this\npaper, we propose a new position encoding method, Contextual Position Encoding\n(CoPE), that allows positions to be conditioned on context by incrementing\nposition only on certain tokens determined by the model. This allows more\ngeneral position addressing such as attending to the $i$-th particular word,\nnoun, or sentence. We show that CoPE can solve the selective copy, counting and\nFlip-Flop tasks where popular position embeddings fail, and improves perplexity\non language modeling and coding tasks.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）的注意力机制（attention mechanism）提出了一种新方法：Contextual Position Encoding (CoPE)，它通过基于上下文的条件来递增位置编码，仅在模型确定的特定令牌上计数，从而实现更抽象的位置寻址，如关注第 i 个单词、名词或句子。相比传统位置编码（PE），CoPE 能够成功处理 selective copy、counting 和 Flip-Flop 任务，这些任务是现有方法无法解决的。实验结果显示，CoPE 改善了语言建模和编码任务的 perplexity，提升了模型的泛化能力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18719v2",
      "published_date": "2024-05-29 02:57:15 UTC",
      "updated_date": "2024-05-30 17:51:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:49:03.059104"
    },
    {
      "arxiv_id": "2405.18711v2",
      "title": "Calibrating Reasoning in Language Models with Internal Consistency",
      "title_zh": "翻译失败",
      "authors": [
        "Zhihui Xie",
        "Jizhou Guo",
        "Tong Yu",
        "Shuai Li"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nvarious reasoning tasks, aided by techniques like chain-of-thought prompting\nthat elicits verbalized reasoning. However, LLMs often generate text with\nobvious mistakes and contradictions, raising doubts about their ability to\nrobustly process and utilize generated rationales. In this work, we investigate\nreasoning in LLMs through the lens of internal representations, focusing on how\nthese representations are influenced by generated rationales. Our preliminary\nanalysis reveals that while generated rationales improve answer accuracy,\ninconsistencies emerge between the model's internal representations in middle\nlayers and those in final layers, potentially undermining the reliability of\ntheir reasoning processes. To address this, we propose internal consistency as\na measure of the model's confidence by examining the agreement of latent\npredictions decoded from intermediate layers. Extensive empirical studies\nacross different models and datasets demonstrate that internal consistency\neffectively distinguishes between correct and incorrect reasoning paths.\nMotivated by this, we propose a new approach to calibrate reasoning by\nup-weighting reasoning paths with high internal consistency, resulting in a\nsignificant boost in reasoning performance. Further analysis uncovers distinct\npatterns in attention and feed-forward modules across layers, providing\ninsights into the emergence of internal inconsistency. In summary, our results\ndemonstrate the potential of using internal representations for self-evaluation\nof LLMs. Our code is available at github.com/zhxieml/internal-consistency.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在推理任务中的问题，如生成错误和矛盾，尽管 chain-of-thought prompting 等技术已提升其性能。作者通过分析模型内部表示，发现生成的推理虽提高答案准确性，但中间层和最终层的表示存在不一致性。针对此，他们提出 internal consistency 作为模型自信度的衡量指标，即评估中间层潜在预测的一致性，并通过实验证明其能有效区分正确与错误的推理路径。最终，作者开发了一种新方法，通过加权高 internal consistency 的推理路径来校准模型，显著提升推理性能，并揭示了注意力模块和前馈模块在不同层中的模式，为 LLMs 的自评估提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 camera ready",
      "pdf_url": "http://arxiv.org/pdf/2405.18711v2",
      "published_date": "2024-05-29 02:44:12 UTC",
      "updated_date": "2024-12-05 04:01:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:49:13.968611"
    },
    {
      "arxiv_id": "2405.18710v2",
      "title": "To FP8 and Back Again: Quantifying Reduced Precision Effects on LLM Training Stability",
      "title_zh": "翻译失败",
      "authors": [
        "Joonhyung Lee",
        "Jeongin Bae",
        "Byeongwook Kim",
        "Se Jung Kwon",
        "Dongsoo Lee"
      ],
      "abstract": "The massive computational costs associated with large language model (LLM)\npretraining have spurred great interest in reduced-precision floating-point\nrepresentations to accelerate the process. As a result, the BrainFloat16 (BF16)\nprecision has become the de facto standard for LLM training, with hardware\nsupport included in recent generations of accelerators. This trend has gone\neven further in the latest processors, where FP8 has recently been introduced.\nHowever, prior experience with FP16, which was found to be less stable than\nBF16, raises concerns as to whether FP8, with even fewer bits than FP16, can be\na cost-effective option for LLM training. We argue that reduced-precision\ntraining schemes must have similar training stability and hyperparameter\nsensitivities to their higher-precision counterparts in order to be\ncost-effective. However, we find that currently available methods for FP8\ntraining are not robust enough to allow their use as economical replacements.\nThis prompts us to investigate the stability of reduced-precision LLM training\nin terms of robustness across random seeds, learning rates, and datasets. To\nthis end, we propose new evaluation techniques and a new metric for quantifying\nloss landscape sharpness in autoregressive language models. By simulating\nincremental bit reductions in floating-point representations, we analyze the\nrelationship between representational power and training stability with the\nintent of aiding future research into the field.",
      "tldr_zh": "该论文探讨了使用低精度浮点表示（如FP8）加速大型语言模型（LLM）预训练的稳定性和经济性问题，指出当前FP8训练方法不如BF16稳健，可能导致训练不稳定和超参数敏感性增加。作者通过模拟浮点位数的渐进减少，评估了训练的鲁棒性，包括随机种子、学习率和数据集的影响，并提出新的评估技术和一个量化损失景观锐度的指标。研究发现，低精度方案需在稳定性和表现上与高精度相当才能实用，为未来FP8优化提供指导。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18710v2",
      "published_date": "2024-05-29 02:42:23 UTC",
      "updated_date": "2025-03-25 11:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:49:29.659884"
    },
    {
      "arxiv_id": "2405.18708v1",
      "title": "Cognitive Evolutionary Learning to Select Feature Interactions for Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Runlong Yu",
        "Qixiang Shao",
        "Qi Liu",
        "Huan Liu",
        "Enhong Chen"
      ],
      "abstract": "Feature interaction selection is a fundamental problem in commercial\nrecommender systems. Most approaches equally enumerate all features and\ninteractions by the same pre-defined operation under expert guidance. Their\nrecommendation is unsatisfactory sometimes due to the following issues:\n(1)~They cannot ensure the learning abilities of models because their\narchitectures are poorly adaptable to tasks and data; (2)~Useless features and\ninteractions can bring unnecessary noise and complicate the training process.\nIn this paper, we aim to adaptively evolve the model to select appropriate\noperations, features, and interactions under task guidance. Inspired by the\nevolution and functioning of natural organisms, we propose a novel\n\\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive\nability refers to a property of organisms that allows them to react and survive\nin diverse environments. It consists of three stages, i.e., DNA search, genome\nsearch, and model functioning. Specifically, if we regard the relationship\nbetween models and tasks as the relationship between organisms and natural\nenvironments, interactions of feature pairs can be analogous to double-stranded\nDNA, of which relevant features and interactions can be analogous to genomes.\nAlong this line, we diagnose the fitness of the model on operations, features,\nand interactions to simulate the survival rates of organisms for natural\nselection. We show that CELL can adaptively evolve into different models for\ndifferent tasks and data, which enables practitioners to access off-the-shelf\nmodels. Extensive experiments on four real-world datasets demonstrate that CELL\nsignificantly outperforms state-of-the-art baselines. Also, we conduct\nsynthetic experiments to ascertain that CELL can consistently discover the\npre-defined interaction patterns for feature pairs.",
      "tldr_zh": "本研究针对推荐系统中特征交互选择的难题，提出了一种名为 Cognitive Evolutionary Learning (CELL) 的框架，以解决现有方法在模型适应性和噪声干扰方面的不足。CELL 框架受自然生物进化启发，包括 DNA search、genome search 和 model functioning 三个阶段，通过模拟生物适应环境的机制来动态选择合适的操作、特征和交互，从而使模型根据任务和数据自适应进化。实验结果显示，CELL 在四个真实数据集上显著优于现有基线模型，并在合成实验中成功发现预定义的特征交互模式，为推荐系统的优化提供了高效的现成解决方案。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18708v1",
      "published_date": "2024-05-29 02:35:23 UTC",
      "updated_date": "2024-05-29 02:35:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:49:38.284789"
    },
    {
      "arxiv_id": "2405.18707v1",
      "title": "Adaptive and Parallel Split Federated Learning in Vehicular Edge Computing",
      "title_zh": "车辆边缘计算中的适应性和并行分割联邦学习",
      "authors": [
        "Xianke Qiang",
        "Zheng Chang",
        "Yun Hu",
        "Lei Liu",
        "Timo Hamalainen"
      ],
      "abstract": "Vehicular edge intelligence (VEI) is a promising paradigm for enabling future\nintelligent transportation systems by accommodating artificial intelligence\n(AI) at the vehicular edge computing (VEC) system. Federated learning (FL)\nstands as one of the fundamental technologies facilitating collaborative model\ntraining locally and aggregation, while safeguarding the privacy of vehicle\ndata in VEI. However, traditional FL faces challenges in adapting to vehicle\nheterogeneity, training large models on resource-constrained vehicles, and\nremaining susceptible to model weight privacy leakage. Meanwhile, split\nlearning (SL) is proposed as a promising collaborative learning framework which\ncan mitigate the risk of model wights leakage, and release the training\nworkload on vehicles. SL sequentially trains a model between a vehicle and an\nedge cloud (EC) by dividing the entire model into a vehicle-side model and an\nEC-side model at a given cut layer. In this work, we combine the advantages of\nSL and FL to develop an Adaptive Split Federated Learning scheme for Vehicular\nEdge Computing (ASFV). The ASFV scheme adaptively splits the model and\nparallelizes the training process, taking into account mobile vehicle selection\nand resource allocation. Our extensive simulations, conducted on\nnon-independent and identically distributed data, demonstrate that the proposed\nASFV solution significantly reduces training latency compared to existing\nbenchmarks, while adapting to network dynamics and vehicles' mobility.",
      "tldr_zh": "本研究针对车辆边缘计算 (VEC) 中的联邦学习 (FL) 挑战，如车辆异质性、资源限制和模型权重隐私泄露，提出了一种自适应并行 Split Federated Learning 方案 (ASFV)。ASFV 结合 Split Learning (SL) 的优势，通过适应性分割模型、在车辆和边缘云之间并行训练，并优化车辆选择和资源分配，实现高效协作学习。实验结果表明，该方案在非独立同分布数据上显著降低了训练延迟，并能适应网络动态和车辆移动，为智能交通系统的隐私保护和高效AI应用提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18707v1",
      "published_date": "2024-05-29 02:34:38 UTC",
      "updated_date": "2024-05-29 02:34:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:49:51.607789"
    },
    {
      "arxiv_id": "2405.18698v1",
      "title": "Spectral-Risk Safe Reinforcement Learning with Convergence Guarantees",
      "title_zh": "翻译失败",
      "authors": [
        "Dohyeong Kim",
        "Taehyun Cho",
        "Seungyub Han",
        "Hojun Chung",
        "Kyungjae Lee",
        "Songhwai Oh"
      ],
      "abstract": "The field of risk-constrained reinforcement learning (RCRL) has been\ndeveloped to effectively reduce the likelihood of worst-case scenarios by\nexplicitly handling risk-measure-based constraints. However, the nonlinearity\nof risk measures makes it challenging to achieve convergence and optimality. To\novercome the difficulties posed by the nonlinearity, we propose a spectral risk\nmeasure-constrained RL algorithm, spectral-risk-constrained policy optimization\n(SRCPO), a bilevel optimization approach that utilizes the duality of spectral\nrisk measures. In the bilevel optimization structure, the outer problem\ninvolves optimizing dual variables derived from the risk measures, while the\ninner problem involves finding an optimal policy given these dual variables.\nThe proposed method, to the best of our knowledge, is the first to guarantee\nconvergence to an optimum in the tabular setting. Furthermore, the proposed\nmethod has been evaluated on continuous control tasks and showed the best\nperformance among other RCRL algorithms satisfying the constraints.",
      "tldr_zh": "该论文针对风险约束强化学习(RCRL)中风险测度的非线性问题，提出了一种新的算法spectral-risk-constrained policy optimization (SRCPO)，这是一种双层优化方法，利用spectral risk measures的二元性来优化双变量和策略。外层优化处理风险相关的双变量，而内层则求解给定双变量下的最优策略，从而保证在表格设置中收敛到最优解。到目前为止，这是首个提供这种收敛保证的RCRL方法。实验在连续控制任务中表明，SRCPO的表现优于其他算法，同时满足约束条件。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.18698v1",
      "published_date": "2024-05-29 02:17:25 UTC",
      "updated_date": "2024-05-29 02:17:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:50:02.324685"
    },
    {
      "arxiv_id": "2405.18693v1",
      "title": "DeepHGNN: Study of Graph Neural Network based Forecasting Methods for Hierarchically Related Multivariate Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Abishek Sriramulu",
        "Nicolas Fourrier",
        "Christoph Bergmeir"
      ],
      "abstract": "Graph Neural Networks (GNN) have gained significant traction in the\nforecasting domain, especially for their capacity to simultaneously account for\nintra-series temporal correlations and inter-series relationships. This paper\nintroduces a novel Hierarchical GNN (DeepHGNN) framework, explicitly designed\nfor forecasting in complex hierarchical structures. The uniqueness of DeepHGNN\nlies in its innovative graph-based hierarchical interpolation and an end-to-end\nreconciliation mechanism. This approach ensures forecast accuracy and coherence\nacross various hierarchical levels while sharing signals across them,\naddressing a key challenge in hierarchical forecasting. A critical insight in\nhierarchical time series is the variance in forecastability across levels, with\nupper levels typically presenting more predictable components. DeepHGNN\ncapitalizes on this insight by pooling and leveraging knowledge from all\nhierarchy levels, thereby enhancing the overall forecast accuracy. Our\ncomprehensive evaluation set against several state-of-the-art models confirm\nthe superior performance of DeepHGNN. This research not only demonstrates\nDeepHGNN's effectiveness in achieving significantly improved forecast accuracy\nbut also contributes to the understanding of graph-based methods in\nhierarchical time series forecasting.",
      "tldr_zh": "本研究提出了一种基于图神经网络（GNN）的DeepHGNN框架，用于预测层次相关多变量时间序列。该框架创新性地引入图-based 层次插值和端到端协调机制，确保预测在不同层次间的准确性和一致性，同时通过共享信号解决层次预测的挑战。DeepHGNN利用不同层次的可预测性差异（如上层更易预测），从所有层次汇集知识以提升整体预测准确性。实验结果显示，DeepHGNN在多项指标上优于现有模型，并为图-based 方法在层次时间序列预测中的应用提供了新见解。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18693v1",
      "published_date": "2024-05-29 02:06:17 UTC",
      "updated_date": "2024-05-29 02:06:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:50:17.890859"
    },
    {
      "arxiv_id": "2405.18688v1",
      "title": "Efficient Preference-based Reinforcement Learning via Aligned Experience Estimation",
      "title_zh": "翻译失败",
      "authors": [
        "Fengshuo Bai",
        "Rui Zhao",
        "Hongming Zhang",
        "Sijia Cui",
        "Ying Wen",
        "Yaodong Yang",
        "Bo Xu",
        "Lei Han"
      ],
      "abstract": "Preference-based reinforcement learning (PbRL) has shown impressive\ncapabilities in training agents without reward engineering. However, a notable\nlimitation of PbRL is its dependency on substantial human feedback. This\ndependency stems from the learning loop, which entails accurate reward learning\ncompounded with value/policy learning, necessitating a considerable number of\nsamples. To boost the learning loop, we propose SEER, an efficient PbRL method\nthat integrates label smoothing and policy regularization techniques. Label\nsmoothing reduces overfitting of the reward model by smoothing human preference\nlabels. Additionally, we bootstrap a conservative estimate $\\widehat{Q}$ using\nwell-supported state-action pairs from the current replay memory to mitigate\noverestimation bias and utilize it for policy learning regularization. Our\nexperimental results across a variety of complex tasks, both in online and\noffline settings, demonstrate that our approach improves feedback efficiency,\noutperforming state-of-the-art methods by a large margin. Ablation studies\nfurther reveal that SEER achieves a more accurate Q-function compared to prior\nwork.",
      "tldr_zh": "该研究针对 Preference-based Reinforcement Learning (PbRL) 的高人类反馈依赖问题，提出了一种高效方法 SEER，通过 label smoothing 减少奖励模型的过拟合，并利用保守估计 \\(\\widehat{Q}\\) 来自当前回放内存的可靠状态-动作对，以缓解过估计偏差并正则化策略学习。实验结果显示，SEER 在在线和离线复杂任务中显著提高了反馈效率，比现有最先进方法表现出色。消融研究进一步证明，SEER 实现了更准确的 Q-function，提升了 PbRL 的整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18688v1",
      "published_date": "2024-05-29 01:49:20 UTC",
      "updated_date": "2024-05-29 01:49:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:50:25.110669"
    },
    {
      "arxiv_id": "2405.18682v2",
      "title": "Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical Machine Reading Comprehension",
      "title_zh": "GPT 是否能重新定义医学理解？在生物医学机器阅读理解上评估 GPT",
      "authors": [
        "Shubham Vatsal",
        "Ayush Singh"
      ],
      "abstract": "Large language models (LLMs) have shown remarkable performance on many tasks\nin different domains. However, their performance in closed-book biomedical\nmachine reading comprehension (MRC) has not been evaluated in depth. In this\nwork, we evaluate GPT on four closed-book biomedical MRC benchmarks. We\nexperiment with different conventional prompting techniques as well as\nintroduce our own novel prompting method. To solve some of the retrieval\nproblems inherent to LLMs, we propose a prompting strategy named Implicit\nRetrieval Augmented Generation (RAG) that alleviates the need for using vector\ndatabases to retrieve important chunks in traditional RAG setups. Moreover, we\nreport qualitative assessments on the natural language generation outputs from\nour approach. The results show that our new prompting technique is able to get\nthe best performance in two out of four datasets and ranks second in rest of\nthem. Experiments show that modern-day LLMs like GPT even in a zero-shot\nsetting can outperform supervised models, leading to new state-of-the-art\n(SoTA) results on two of the benchmarks.",
      "tldr_zh": "本论文评估了大型语言模型 (LLMs) 如 GPT 在封闭式生物医学机器阅读理解 (MRC) 任务上的性能，涵盖四个基准数据集。研究引入了一种新颖的提示策略——Implicit Retrieval Augmented Generation (RAG)，它无需传统向量数据库即可解决 LLMs 的检索问题，并通过定性评估分析生成输出。该方法在两个数据集上取得最佳表现，在其余数据集上排名第二；此外，在零-shot 设置下，GPT 超过了监督模型，实现了两个基准的新 state-of-the-art (SoTA) 结果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18682v2",
      "published_date": "2024-05-29 01:12:53 UTC",
      "updated_date": "2024-10-25 16:57:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:50:37.956767"
    },
    {
      "arxiv_id": "2405.18681v2",
      "title": "A random-key GRASP for combinatorial optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Antonio A. Chaves",
        "Mauricio G. C. Resende",
        "Ricardo M. A. Silva"
      ],
      "abstract": "This paper proposes a problem-independent GRASP metaheuristic using the\nrandom-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search\nprocedure) is a metaheuristic for combinatorial optimization that repeatedly\napplies a semi-greedy construction procedure followed by a local search\nprocedure. The best solution found over all iterations is returned as the\nsolution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for\ncontinuous optimization in the unit hypercube. A random-key optimizer (RKO)\nuses a vector of random keys to encode a solution to a combinatorial\noptimization problem. It uses a decoder to evaluate a solution encoded by the\nvector of random keys. A random-key GRASP is a C-GRASP where points in the unit\nhypercube are evaluated employing a decoder. We describe random key GRASP\nconsisting of a problem-independent component and a problem-dependent decoder.\nAs a proof of concept, the random-key GRASP is tested on five NP-hard\ncombinatorial optimization problems: traveling salesman problem, tree of hubs\nlocation problem, Steiner triple covering problem, node capacitated graph\npartitioning problem, and job sequencing and tool switching problem.",
      "tldr_zh": "本论文提出了一种基于 random-key optimizer (RKO) 范式的 GRASP metaheuristic，名为 random-key GRASP，用于解决组合优化问题。该方法将传统 GRASP（包括半贪婪构造和局部搜索过程）扩展到连续优化框架中，通过随机键向量编码解决方案并使用解码器进行评估，从而实现问题无关的通用组件。实验作为概念证明，在五个 NP-hard 问题上进行了测试，包括 traveling salesman problem、tree of hubs location problem、Steiner triple covering problem、node capacitated graph partitioning problem 和 job sequencing and tool switching problem，展示了其有效性。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "math.OC",
        "90-02, 90B40, 90C27",
        "G.1.6; G.2.1; I.2.8"
      ],
      "primary_category": "cs.NE",
      "comment": "24 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.18681v2",
      "published_date": "2024-05-29 01:07:38 UTC",
      "updated_date": "2024-05-30 13:06:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:50:50.110841"
    },
    {
      "arxiv_id": "2405.18669v2",
      "title": "Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities",
      "title_zh": "翻译失败",
      "authors": [
        "Vicky Zayats",
        "Peter Chen",
        "Melissa Ferrari",
        "Dirk Padfield"
      ],
      "abstract": "Integrating multiple generative foundation models, especially those trained\non different modalities, into something greater than the sum of its parts poses\nsignificant challenges. Two key hurdles are the availability of aligned data\n(concepts that contain similar meaning but is expressed differently in\ndifferent modalities), and effectively leveraging unimodal representations in\ncross-domain generative tasks, without compromising their original unimodal\ncapabilities.\n  We propose Zipper, a multi-tower decoder architecture that addresses these\nconcerns by using cross-attention to flexibly compose multimodal generative\nmodels from independently pre-trained unimodal decoders. In our experiments\nfusing speech and text modalities, we show the proposed architecture performs\nvery competitively in scenarios with limited aligned text-speech data. We also\nshowcase the flexibility of our model to selectively maintain unimodal (e.g.,\ntext-to-text generation) generation performance by freezing the corresponding\nmodal tower (e.g. text). In cross-modal tasks such as automatic speech\nrecognition (ASR) where the output modality is text, we show that freezing the\ntext backbone results in negligible performance degradation. In cross-modal\ntasks such as text-to-speech generation (TTS) where the output modality is\nspeech, we show that using a pre-trained speech backbone results in superior\nperformance to the baseline.",
      "tldr_zh": "该论文提出 Zipper，一种多塔解码器(multi-tower decoder)架构，通过 cross-attention 机制灵活组合独立预训练的单模态解码器，以解决多模态生成模型整合的挑战，如对齐数据不足和保持单模态能力。Zipper 在语音和文本模态融合实验中，在有限对齐数据场景下表现出色，并允许通过冻结特定模态塔（如文本塔）来维持单模态生成性能，例如文本到文本任务。实验结果显示，在跨模态任务如自动语音识别(ASR)中，冻结文本主干导致性能几乎无损，而在文本到语音生成(TTS)中，使用预训练语音主干比基线模型性能更优。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "eess.AS"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review at NeurIPS",
      "pdf_url": "http://arxiv.org/pdf/2405.18669v2",
      "published_date": "2024-05-29 00:23:55 UTC",
      "updated_date": "2024-05-31 15:42:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:51:03.769655"
    },
    {
      "arxiv_id": "2405.18664v2",
      "title": "Fast Explanations via Policy Gradient-Optimized Explainer",
      "title_zh": "翻译失败",
      "authors": [
        "Deng Pan",
        "Nuno Moniz",
        "Nitesh Chawla"
      ],
      "abstract": "The challenge of delivering efficient explanations is a critical barrier that\nprevents the adoption of model explanations in real-world applications.\nExisting approaches often depend on extensive model queries for sample-level\nexplanations or rely on expert's knowledge of specific model structures that\ntrade general applicability for efficiency. To address these limitations, this\npaper introduces a novel framework Fast Explanation (FEX) that represents\nattribution-based explanations via probability distributions, which are\noptimized by leveraging the policy gradient method. The proposed framework\noffers a robust, scalable solution for real-time, large-scale model\nexplanations, bridging the gap between efficiency and applicability. We\nvalidate our framework on image and text classification tasks and the\nexperiments demonstrate that our method reduces inference time by over 97% and\nmemory usage by 70% compared to traditional model-agnostic approaches while\nmaintaining high-quality explanations and broad applicability.",
      "tldr_zh": "该论文针对模型解释的效率挑战，提出了一种新框架Fast Explanation (FEX)，通过概率分布表示归因-based解释，并利用policy gradient方法进行优化，以实现实时、大规模模型解释。FEX框架解决了现有方法依赖大量查询或专家知识的局限性，提供了一个鲁棒且可扩展的解决方案。实验在图像和文本分类任务上验证，该方法将推理时间减少97%、内存使用减少70%，同时保持高品质解释和广泛适用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.18664v2",
      "published_date": "2024-05-29 00:01:40 UTC",
      "updated_date": "2025-01-27 20:01:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T13:51:13.255180"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 140,
  "processed_papers_count": 140,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T13:51:50.723306"
}