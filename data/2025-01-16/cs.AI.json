{
  "date": "2025-01-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-16 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 更新了 71 篇论文，主要聚焦 AI 和大型语言模型（LLM）的创新应用，包括强化学习、视觉模型扩展、责任 AI 和医疗诊断等领域。其中，令人印象深刻的文章包括第 16 篇关于 LLM 推理的综述（作者包括 Yong Li），它系统回顾了强化学习在 LLM 上的应用；第 43 篇责任 AI 调查，强调隐私保护和公平性；以及第 7 篇视觉标记器扩展研究，展示了高效的模型优化。接下来，我将挑选重点论文逐一简要讨论，先聊 AI 和 LLM 相关的高话题度文章，再快速概述其他领域。\n\n**第 16 篇：Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models（迈向大型推理模型：大型语言模型强化推理的调查）**  \n这篇综述性论文由 Yong Li 等作者主导，探讨了强化学习在 LLM 中的应用，主要贡献是通过自动数据构建和测试时扩展，提升 LLM 的推理能力，发现训练时和测试时缩放相结合可创建更强大的“大型推理模型”，如 OpenAI o1 系列，强调了 AI 推理的未来方向。\n\n**第 43 篇：A Survey on Responsible LLMs: Inherent Risk, Malicious Use, and Mitigation Strategy（责任大型语言模型调查：固有风险、恶意使用及缓解策略）**  \n论文系统审视了 LLM 的风险，如隐私泄露和有毒内容生成，主要发现是通过四个阶段（预训练、微调、提示和后处理）优化缓解策略，包括公平性提升和毒性消除，提供了全面框架以提升 LLM 的可信度。\n\n**第 29 篇：Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment（超越奖励黑客：大型语言模型对齐的因果奖励）**  \n这篇论文提出因果奖励模型来优化 LLM 对齐，主要贡献是减少偏差（如长度偏差），通过实验验证了在合成和真实数据集上的鲁棒性，发现这种方法能提升 LLM 的公平性和可靠性。\n\n**第 57 篇：OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking（OmniThink：通过思考扩展机器写作的知识边界）**  \n作者包括 Huajun Chen，论文引入 OmniThink 框架模拟人类迭代思考，主要发现是通过检索增强生成改进机器写作的深度和原创性，实验证明它能生成更知识密集的文章，同时保持连贯性。\n\n**第 7 篇：Learnings from Scaling Visual Tokenizers for Reconstruction and Generation（从扩展视觉标记器中获得的经验教训）**  \n论文探索视觉标记器的扩展，主要贡献是提出 ViTok 架构，使用 Vision Transformer 优化重建和生成任务，发现扩展解码器比编码器更有效，并在 ImageNet 和 UCF-101 上实现高效性能。\n\n**第 4 篇：Bridging Language Barriers in Healthcare: A Study on Arabic LLMs（桥接医疗领域的语言障碍：阿拉伯 LLM 的研究）**  \n这篇医疗 AI 论文发现，简单翻译数据不足以提升 LLM 在临床任务上的表现，主要贡献是优化语言混合比例和预训练方法，提高多语种医疗 AI 的包容性。\n\n**第 3 篇：CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation（CrossModalityDiffusion：使用统一中间表示的多模态新视图合成）**  \n论文提出 CrossModalityDiffusion 框架，用于地理空间图像的多模态合成，主要发现是通过体积渲染和扩散模型生成准确的新视图，在 ShapeNet 数据集上验证了其有效性。\n\n其他论文中，快速提一下一些有潜力的领域：  \n- **第 9 篇：KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports（KU AIGEN ICL EDI@BC8 Track 3：推进畸形体格检查报告的表型命名实体识别和标准化）**  \n  主要贡献是使用数据增强改善医疗文本实体识别，提升了 EHR 处理的准确性。  \n- **第 18 篇：Incorporating Quantum Advantage in Quantum Circuit Generation through Genetic Programming（通过遗传编程在量子电路生成中整合量子优势）**  \n  提出新方法优化量子电路设计，发现它能加速收敛并生成高效电路。  \n- **第 33 篇：IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients（IFRA：基于机器学习的卒中患者仪器化跌倒风险评估量表）**  \n  开发了 IFRA 工具，用于评估卒中患者的跌倒风险，主要发现是通过机器学习提升预测精度。  \n\n剩余论文多为技术性较强的专题，如强化学习框架（第 6、24 篇）和图像分类（第 5、11 篇），但它们相对常规，我就不详细展开了。今天 arXiv 的更新突显了 AI 领域的快速演进，感兴趣的读者可关注 LLM 推理和责任 AI 的前沿进展！",
  "papers": [
    {
      "arxiv_id": "2501.09878v1",
      "title": "ASTRA: A Scene-aware TRAnsformer-based model for trajectory prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Izzeddin Teeti",
        "Aniket Thomas",
        "Munish Monga",
        "Sachin Kumar",
        "Uddeshya Singh",
        "Andrew Bradley",
        "Biplab Banerjee",
        "Fabio Cuzzolin"
      ],
      "abstract": "We present ASTRA (A} Scene-aware TRAnsformer-based model for trajectory\nprediction), a light-weight pedestrian trajectory forecasting model that\nintegrates the scene context, spatial dynamics, social inter-agent interactions\nand temporal progressions for precise forecasting. We utilised a U-Net-based\nfeature extractor, via its latent vector representation, to capture scene\nrepresentations and a graph-aware transformer encoder for capturing social\ninteractions. These components are integrated to learn an agent-scene aware\nembedding, enabling the model to learn spatial dynamics and forecast the future\ntrajectory of pedestrians. The model is designed to produce both deterministic\nand stochastic outcomes, with the stochastic predictions being generated by\nincorporating a Conditional Variational Auto-Encoder (CVAE). ASTRA also\nproposes a simple yet effective weighted penalty loss function, which helps to\nyield predictions that outperform a wide array of state-of-the-art\ndeterministic and generative models. ASTRA demonstrates an average improvement\nof 27%/10% in deterministic/stochastic settings on the ETH-UCY dataset, and 26%\nimprovement on the PIE dataset, respectively, along with seven times fewer\nparameters than the existing state-of-the-art model (see Figure 1).\nAdditionally, the model's versatility allows it to generalize across different\nperspectives, such as Bird's Eye View (BEV) and Ego-Vehicle View (EVV).",
      "tldr_zh": "本研究提出 ASTRA，一种基于 Transformer 的轻量级行人轨迹预测模型，它整合了场景上下文、空间动态、社会交互和时间进展，以实现精确的轨迹预测。模型采用 U-Net-based 特征提取器捕捉场景表示，并结合 graph-aware transformer encoder 处理社会交互，生成 agent-scene aware embedding，同时通过 Conditional Variational Auto-Encoder (CVAE) 实现确定性和随机预测，并引入加权惩罚损失函数优化输出。实验结果显示，ASTRA 在 ETH-UCY 数据集上确定性/随机设置改善了27%/10%，在 PIE 数据集上改善了26%，且参数比现有最先进模型少七倍，并能在 Bird's Eye View (BEV) 和 Ego-Vehicle View (EVV) 等不同视角上实现泛化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09878v1",
      "published_date": "2025-01-16 23:28:30 UTC",
      "updated_date": "2025-01-16 23:28:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:03:44.341924"
    },
    {
      "arxiv_id": "2501.09858v1",
      "title": "From Explainability to Interpretability: Interpretable Policies in Reinforcement Learning Via Model Explanation",
      "title_zh": "翻译失败",
      "authors": [
        "Peilang Li",
        "Umer Siddique",
        "Yongcan Cao"
      ],
      "abstract": "Deep reinforcement learning (RL) has shown remarkable success in complex\ndomains, however, the inherent black box nature of deep neural network policies\nraises significant challenges in understanding and trusting the decision-making\nprocesses. While existing explainable RL methods provide local insights, they\nfail to deliver a global understanding of the model, particularly in\nhigh-stakes applications. To overcome this limitation, we propose a novel\nmodel-agnostic approach that bridges the gap between explainability and\ninterpretability by leveraging Shapley values to transform complex deep RL\npolicies into transparent representations. The proposed approach offers two key\ncontributions: a novel approach employing Shapley values to policy\ninterpretation beyond local explanations and a general framework applicable to\noff-policy and on-policy algorithms. We evaluate our approach with three\nexisting deep RL algorithms and validate its performance in two classic control\nenvironments. The results demonstrate that our approach not only preserves the\noriginal models' performance but also generates more stable interpretable\npolicies.",
      "tldr_zh": "本论文探讨了深度强化学习（RL）的黑盒问题，提出了一种模型无关的方法，利用 Shapley values 将复杂的深度 RL 策略转化为透明表示，从而从 explainability 转向 interpretability。\n主要贡献包括：一种超越局部解释的策略解释方法，以及一个适用于 off-policy 和 on-policy 算法的通用框架。\n在三个现有深度 RL 算法和两个经典控制环境中进行评估，结果表明该方法不仅保持了原模型的性能，还生成了更稳定的可解释策略。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to Deployable AI (DAI) Workshop at the Thirty-Ninth AAAI\n  Conference on Artificial Intelligence (AAAI-25)",
      "pdf_url": "http://arxiv.org/pdf/2501.09858v1",
      "published_date": "2025-01-16 22:11:03 UTC",
      "updated_date": "2025-01-16 22:11:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:03:54.387921"
    },
    {
      "arxiv_id": "2501.09838v1",
      "title": "CrossModalityDiffusion: Multi-Modal Novel View Synthesis with Unified Intermediate Representation",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Berian",
        "Daniel Brignac",
        "JhihYang Wu",
        "Natnael Daba",
        "Abhijit Mahalanobis"
      ],
      "abstract": "Geospatial imaging leverages data from diverse sensing modalities-such as EO,\nSAR, and LiDAR, ranging from ground-level drones to satellite views. These\nheterogeneous inputs offer significant opportunities for scene understanding\nbut present challenges in interpreting geometry accurately, particularly in the\nabsence of precise ground truth data. To address this, we propose\nCrossModalityDiffusion, a modular framework designed to generate images across\ndifferent modalities and viewpoints without prior knowledge of scene geometry.\nCrossModalityDiffusion employs modality-specific encoders that take multiple\ninput images and produce geometry-aware feature volumes that encode scene\nstructure relative to their input camera positions. The space where the feature\nvolumes are placed acts as a common ground for unifying input modalities. These\nfeature volumes are overlapped and rendered into feature images from novel\nperspectives using volumetric rendering techniques. The rendered feature images\nare used as conditioning inputs for a modality-specific diffusion model,\nenabling the synthesis of novel images for the desired output modality. In this\npaper, we show that jointly training different modules ensures consistent\ngeometric understanding across all modalities within the framework. We validate\nCrossModalityDiffusion's capabilities on the synthetic ShapeNet cars dataset,\ndemonstrating its effectiveness in generating accurate and consistent novel\nviews across multiple imaging modalities and perspectives.",
      "tldr_zh": "这篇论文提出了CrossModalityDiffusion框架，用于处理多模态地理空间成像（如EO、SAR和LiDAR），旨在在缺乏精确地面真实数据的情况下，实现不同模态和视角下的新型视图图像合成。该框架采用模态特定的编码器生成几何感知的特征体，这些特征体在统一中间表示空间中重叠，并通过volumetric rendering技术渲染成特征图像，然后作为条件输入给diffusion model以合成目标模态图像。联合训练确保了框架内所有模态的一致几何理解。在ShapeNet cars合成数据集上的实验验证了该方法的有效性，实现了准确且一致的跨模态新型视图生成。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in the 2025 WACV workshop GeoCV",
      "pdf_url": "http://arxiv.org/pdf/2501.09838v1",
      "published_date": "2025-01-16 20:56:32 UTC",
      "updated_date": "2025-01-16 20:56:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:04:07.581742"
    },
    {
      "arxiv_id": "2501.09825v1",
      "title": "Bridging Language Barriers in Healthcare: A Study on Arabic LLMs",
      "title_zh": "桥接医疗保健领域的",
      "authors": [
        "Nada Saadi",
        "Tathagata Raha",
        "Clément Christophe",
        "Marco AF Pimentel",
        "Ronnie Rajan",
        "Praveen K Kanithi"
      ],
      "abstract": "This paper investigates the challenges of developing large language models\n(LLMs) proficient in both multilingual understanding and medical knowledge. We\ndemonstrate that simply translating medical data does not guarantee strong\nperformance on clinical tasks in the target language. Our experiments reveal\nthat the optimal language mix in training data varies significantly across\ndifferent medical tasks. We find that larger models with carefully calibrated\nlanguage ratios achieve superior performance on native-language clinical tasks.\nFurthermore, our results suggest that relying solely on fine-tuning may not be\nthe most effective approach for incorporating new language knowledge into LLMs.\nInstead, data and computationally intensive pretraining methods may still be\nnecessary to achieve optimal performance in multilingual medical settings.\nThese findings provide valuable guidance for building effective and inclusive\nmedical AI systems for diverse linguistic communities.",
      "tldr_zh": "本研究探讨了开发在多语言理解和医疗知识方面熟练的 LLMs 的挑战，发现简单翻译医疗数据无法确保目标语言临床任务的良好性能。实验显示，训练数据中的最佳语言比例因不同医疗任务而异，而更大模型通过仔细校准的语言混合能在母语临床任务上取得优越表现。作者建议，依赖仅微调可能不足以融入新语言知识，数据和计算密集的预训练方法更适合多语言医疗场景，并为构建包容性医疗 AI 系统提供了宝贵指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09825v1",
      "published_date": "2025-01-16 20:24:56 UTC",
      "updated_date": "2025-01-16 20:24:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:04:17.832852"
    },
    {
      "arxiv_id": "2501.09817v1",
      "title": "Generalized Single-Image-Based Morphing Attack Detection Using Deep Representations from Vision Transformer",
      "title_zh": "基于 Vision Transformer 深度表示的泛化单",
      "authors": [
        "Haoyu Zhang",
        "Raghavendra Ramachandra",
        "Kiran Raja",
        "Christoph Busch"
      ],
      "abstract": "Face morphing attacks have posed severe threats to Face Recognition Systems\n(FRS), which are operated in border control and passport issuance use cases.\nCorrespondingly, morphing attack detection algorithms (MAD) are needed to\ndefend against such attacks. MAD approaches must be robust enough to handle\nunknown attacks in an open-set scenario where attacks can originate from\nvarious morphing generation algorithms, post-processing and the diversity of\nprinters/scanners. The problem of generalization is further pronounced when the\ndetection has to be made on a single suspected image. In this paper, we propose\na generalized single-image-based MAD (S-MAD) algorithm by learning the encoding\nfrom Vision Transformer (ViT) architecture. Compared to CNN-based\narchitectures, ViT model has the advantage on integrating local and global\ninformation and hence can be suitable to detect the morphing traces widely\ndistributed among the face region. Extensive experiments are carried out on\nface morphing datasets generated using publicly available FRGC face datasets.\nSeveral state-of-the-art (SOTA) MAD algorithms, including representative ones\nthat have been publicly evaluated, have been selected and benchmarked with our\nViT-based approach. Obtained results demonstrate the improved detection\nperformance of the proposed S-MAD method on inter-dataset testing (when\ndifferent data is used for training and testing) and comparable performance on\nintra-dataset testing (when the same data is used for training and testing)\nexperimental protocol.",
      "tldr_zh": "该论文针对面部变形攻击对Face Recognition Systems (FRS)的威胁，提出了一种基于Vision Transformer (ViT)的通用单图像变形攻击检测算法(S-MAD)。该算法通过ViT架构学习深度表示，利用其整合局部和全局信息的优势，来检测广泛分布的面部变形痕迹，从而提升对未知攻击的鲁棒性。实验结果显示，与现有SOTA方法相比，该S-MAD在跨数据集测试中表现出显著性能改进，而在同一数据集测试中保持可比性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09817v1",
      "published_date": "2025-01-16 20:09:19 UTC",
      "updated_date": "2025-01-16 20:09:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:04:30.231895"
    },
    {
      "arxiv_id": "2501.09804v1",
      "title": "Enhancing Generalization in Chain of Thought Reasoning for Smaller Models",
      "title_zh": "翻译失败",
      "authors": [
        "Maxwell J. Yin",
        "Dingyi Jiang",
        "Yongbing Chen",
        "Boyu Wang",
        "Charles Ling"
      ],
      "abstract": "Chain-of-Thought (CoT) reasoning in smaller language models is a challenging\nnatural language process problem yet highly desirable in many real-life\napplications. Existing CoT knowledge distillation methods often suffer from\noverly conservative memorization in smaller LLMs, leading to low generalization\nconfidence. As fully preserving the CoT ability of teacher model is impossible,\nwe hypothesize that adversarial CoT fine-tuning is crucial for developing\nsmaller LLM with robust CoT generalization. To this end, we propose\n\\textit{PRompt-Assisted Domain-Adversarial fine-tuning} (PRADA), a principled\nfine-tuning framework that integrates diverse CoT domains. Specifically, PRADA\npioneers two CoT improvements in smaller LLM: (1) Recovering the\ndomain-invariant feature insight which typically lost during distillation with\ndomain adversarial fine-tuning; (2) Enhancing the domain adaptability of CoT\nprompt engineering by employing domain-adversarial approaches. We theoretically\ndemonstrate the effectiveness of our approach and empirically show that it\nsignificantly outperforms the state of the arts in a wide range of tasks.\nMoreover, our empirical findings reveal that the smaller LLM, when leveraging\nPRADA, aligns closely with domain knowledge, thereby improving the\nexplainability of our approach.",
      "tldr_zh": "本文针对较小语言模型在Chain-of-Thought (CoT)推理中的泛化能力不足问题，提出PRompt-Assisted Domain-Adversarial fine-tuning (PRADA)框架，通过域对抗微调恢复域不变特征并增强CoT提示工程的域适应性。PRADA整合多种CoT领域，理论上证明了其有效性，并在广泛任务中实证上显著优于现有知识蒸馏方法。实验结果显示，使用PRADA的较小LLM更接近域知识，提高了模型的可解释性和泛化性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09804v1",
      "published_date": "2025-01-16 19:23:11 UTC",
      "updated_date": "2025-01-16 19:23:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:04:42.761761"
    },
    {
      "arxiv_id": "2501.09755v1",
      "title": "Learnings from Scaling Visual Tokenizers for Reconstruction and Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Philippe Hansen-Estruch",
        "David Yan",
        "Ching-Yao Chung",
        "Orr Zohar",
        "Jialiang Wang",
        "Tingbo Hou",
        "Tao Xu",
        "Sriram Vishwanath",
        "Peter Vajda",
        "Xinlei Chen"
      ],
      "abstract": "Visual tokenization via auto-encoding empowers state-of-the-art image and\nvideo generative models by compressing pixels into a latent space. Although\nscaling Transformer-based generators has been central to recent advances, the\ntokenizer component itself is rarely scaled, leaving open questions about how\nauto-encoder design choices influence both its objective of reconstruction and\ndownstream generative performance. Our work aims to conduct an exploration of\nscaling in auto-encoders to fill in this blank. To facilitate this exploration,\nwe replace the typical convolutional backbone with an enhanced Vision\nTransformer architecture for Tokenization (ViTok). We train ViTok on\nlarge-scale image and video datasets far exceeding ImageNet-1K, removing data\nconstraints on tokenizer scaling. We first study how scaling the auto-encoder\nbottleneck affects both reconstruction and generation -- and find that while it\nis highly correlated with reconstruction, its relationship with generation is\nmore complex. We next explored the effect of separately scaling the\nauto-encoders' encoder and decoder on reconstruction and generation\nperformance. Crucially, we find that scaling the encoder yields minimal gains\nfor either reconstruction or generation, while scaling the decoder boosts\nreconstruction but the benefits for generation are mixed. Building on our\nexploration, we design ViTok as a lightweight auto-encoder that achieves\ncompetitive performance with state-of-the-art auto-encoders on ImageNet-1K and\nCOCO reconstruction tasks (256p and 512p) while outperforming existing\nauto-encoders on 16-frame 128p video reconstruction for UCF-101, all with 2-5x\nfewer FLOPs. When integrated with Diffusion Transformers, ViTok demonstrates\ncompetitive performance on image generation for ImageNet-1K and sets new\nstate-of-the-art benchmarks for class-conditional video generation on UCF-101.",
      "tldr_zh": "本研究探讨了扩展视觉标记器（Visual Tokenizers）对图像和视频重建（Reconstruction）和生成（Generation）的影響，特别关注自动编码器（auto-encoders）的设计选择。作者引入了增强型 Vision Transformer 架构 ViTok 作为标记器骨干网，并在远超 ImageNet-1K 的数据集上进行训练，发现扩展 auto-encoder 的瓶颈高度相关于重建，但与生成的关系更复杂，而扩展编码器收益有限，扩展解码器则显著提升重建性能。最终，ViTok 作为轻量级模型，在 ImageNet-1K 和 UCF-101 等重建任务上以 2-5 倍更少的 FLOPs 实现与 SOTA 竞争的表现，并在与 Diffusion Transformers 结合的生成任务中设置了新的基准。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10; I.4.2; I.4.5"
      ],
      "primary_category": "cs.CV",
      "comment": "28 pages, 25 figures, 7 Tables",
      "pdf_url": "http://arxiv.org/pdf/2501.09755v1",
      "published_date": "2025-01-16 18:59:04 UTC",
      "updated_date": "2025-01-16 18:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:04:55.344310"
    },
    {
      "arxiv_id": "2501.09751v2",
      "title": "OmniThink: Expanding Knowledge Boundaries in Machine Writing through Thinking",
      "title_zh": "OmniThink：通过思考扩展机器写作中的知识边界",
      "authors": [
        "Zekun Xi",
        "Wenbiao Yin",
        "Jizhan Fang",
        "Jialong Wu",
        "Runnan Fang",
        "Ningyu Zhang",
        "Jiang Yong",
        "Pengjun Xie",
        "Fei Huang",
        "Huajun Chen"
      ],
      "abstract": "Machine writing with large language models often relies on\nretrieval-augmented generation. However, these approaches remain confined\nwithin the boundaries of the model's predefined scope, limiting the generation\nof content with rich information. Specifically, vanilla-retrieved information\ntends to lack depth, novelty, and suffers from redundancy, which negatively\nimpacts the quality of generated articles, leading to shallow, unoriginal, and\nrepetitive outputs. To address these issues, we propose OmniThink, a\nslow-thinking machine writing framework that emulates the human-like process of\niterative expansion and reflection. The core idea behind OmniThink is to\nsimulate the cognitive behavior of learners as they slowly deepen their\nknowledge of the topics. Experimental results demonstrate that OmniThink\nimproves the knowledge density of generated articles without compromising\nmetrics such as coherence and depth. Human evaluations and expert feedback\nfurther highlight the potential of OmniThink to address real-world challenges\nin the generation of long-form articles.",
      "tldr_zh": "本文研究发现，现有的机器写作依赖于retrieval-augmented generation，但受限于模型预定义范围，导致生成的文章缺乏深度、新颖性并出现冗余问题。针对这些不足，作者提出OmniThink框架，该框架模拟人类慢思考过程，通过迭代扩展和反思来加深主题知识的认知行为。实验结果显示，OmniThink显著提高了生成文章的知识密度，同时保持了连贯性和深度，且人类评估及专家反馈证实了其在处理长文章实际挑战方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Code is available at https://github.com/zjunlp/OmniThink",
      "pdf_url": "http://arxiv.org/pdf/2501.09751v2",
      "published_date": "2025-01-16 18:58:06 UTC",
      "updated_date": "2025-02-20 15:05:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:05:06.761164"
    },
    {
      "arxiv_id": "2501.09744v1",
      "title": "KU AIGEN ICL EDI@BC8 Track 3: Advancing Phenotype Named Entity Recognition and Normalization for Dysmorphology Physical Examination Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Hajung Kim",
        "Chanhwi Kim",
        "Jiwoong Sohn",
        "Tim Beck",
        "Marek Rei",
        "Sunkyu Kim",
        "T Ian Simpson",
        "Joram M Posma",
        "Antoine Lain",
        "Mujeen Sung",
        "Jaewoo Kang"
      ],
      "abstract": "The objective of BioCreative8 Track 3 is to extract phenotypic key medical\nfindings embedded within EHR texts and subsequently normalize these findings to\ntheir Human Phenotype Ontology (HPO) terms. However, the presence of diverse\nsurface forms in phenotypic findings makes it challenging to accurately\nnormalize them to the correct HPO terms. To address this challenge, we explored\nvarious models for named entity recognition and implemented data augmentation\ntechniques such as synonym marginalization to enhance the normalization step.\nOur pipeline resulted in an exact extraction and normalization F1 score 2.6\\%\nhigher than the mean score of all submissions received in response to the\nchallenge. Furthermore, in terms of the normalization F1 score, our approach\nsurpassed the average performance by 1.9\\%. These findings contribute to the\nadvancement of automated medical data extraction and normalization techniques,\nshowcasing potential pathways for future research and application in the\nbiomedical domain.",
      "tldr_zh": "本研究针对BioCreative8 Track 3挑战，旨在从畸形体格检查报告的EHR文本中提取表型关键医疗发现，并将其标准化到Human Phenotype Ontology (HPO)术语，以应对表型发现多样表面形式带来的困难。研究团队探索了多种命名实体识别(NER)模型，并采用数据增强技术如同义词边缘化来提升标准化步骤的准确性。结果显示，该管道在精确提取和标准化F1分数上比所有提交平均值高2.6%，在标准化F1分数上高1.9%，从而推进了自动化医疗数据提取和标准化技术的应用，为生物医学领域未来研究提供了新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This article is part of the Proceedings of the BioCreative VIII\n  Challenge and Workshop: Curation and Evaluation in the era of Generative\n  Models",
      "pdf_url": "http://arxiv.org/pdf/2501.09744v1",
      "published_date": "2025-01-16 18:53:32 UTC",
      "updated_date": "2025-01-16 18:53:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:07:12.087399"
    },
    {
      "arxiv_id": "2501.09725v1",
      "title": "Parallel multi-objective metaheuristics for smart communications in vehicular networks",
      "title_zh": "翻译失败",
      "authors": [
        "Jamal Toutouh",
        "Enrique Alba"
      ],
      "abstract": "This article analyzes the use of two parallel multi-objective soft computing\nalgorithms to automatically search for high-quality settings of the Ad hoc On\nDemand Vector routing protocol for vehicular networks. These methods are based\non an evolutionary algorithm and on a swarm intelligence approach. The\nexperimental analysis demonstrates that the configurations computed by our\noptimization algorithms outperform other state-of-the-art optimized ones. In\nturn, the computational efficiency achieved by all the parallel versions is\ngreater than 87 %. Therefore, the line of work presented in this article\nrepresents an efficient framework to improve vehicular communications.",
      "tldr_zh": "本文提出两种并行多-objective metaheuristics 算法（基于 evolutionary algorithm 和 swarm intelligence），用于自动优化 Ad hoc On Demand Vector (AODV) 路由协议在车载网络中的设置，以提升智能通信性能。实验分析表明，这些算法生成的配置优于现有最先进优化方案，同时所有并行版本的计算效率均超过87%。该研究框架为改善车载网络通信提供了高效且可靠的方法。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09725v1",
      "published_date": "2025-01-16 18:16:34 UTC",
      "updated_date": "2025-01-16 18:16:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:05:30.958614"
    },
    {
      "arxiv_id": "2501.09720v3",
      "title": "A Simple Aerial Detection Baseline of Multimodal Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Qingyun Li",
        "Yushi Chen",
        "Xinya Shu",
        "Dong Chen",
        "Xin He",
        "Yi Yu",
        "Xue Yang"
      ],
      "abstract": "The multimodal language models (MLMs) based on generative pre-trained\nTransformer are considered powerful candidates for unifying various domains and\ntasks. MLMs developed for remote sensing (RS) have demonstrated outstanding\nperformance in multiple tasks, such as visual question answering and visual\ngrounding. In addition to visual grounding that detects specific objects\ncorresponded to given instruction, aerial detection, which detects all objects\nof multiple categories, is also a valuable and challenging task for RS\nfoundation models. However, aerial detection has not been explored by existing\nRS MLMs because the autoregressive prediction mechanism of MLMs differs\nsignificantly from the detection outputs. In this paper, we present a simple\nbaseline for applying MLMs to aerial detection for the first time, named\nLMMRotate. Specifically, we first introduce a normalization method to transform\ndetection outputs into textual outputs to be compatible with the MLM framework.\nThen, we propose a evaluation method, which ensures a fair comparison between\nMLMs and conventional object detection models. We construct the baseline by\nfine-tuning open-source general-purpose MLMs and achieve impressive detection\nperformance comparable to conventional detector. We hope that this baseline\nwill serve as a reference for future MLM development, enabling more\ncomprehensive capabilities for understanding RS images. Code is available at\nhttps://github.com/Li-Qingyun/mllm-mmrotate.",
      "tldr_zh": "这篇论文首次探索多模态语言模型 (MLMs) 在航空检测任务中的应用，提出一个简单基线 LMMRotate，以解决 MLMs 的自回归预测机制与检测输出不兼容的问题。具体方法包括引入一种归一化技术将检测输出转化为文本格式，并设计公平的评估方法与传统物体检测模型进行比较。通过微调开源的通用 MLMs，该基线在遥感 (RS) 图像检测任务中实现了与常规检测器相当的性能，为未来 MLM 开发提供全面参考。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "4 pages, 1 table, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09720v3",
      "published_date": "2025-01-16 18:09:22 UTC",
      "updated_date": "2025-01-31 21:29:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:07:23.363010"
    },
    {
      "arxiv_id": "2501.09709v1",
      "title": "CyberMentor: AI Powered Learning Tool Platform to Address Diverse Student Needs in Cybersecurity Education",
      "title_zh": "CyberMentor：AI 驱动的学习工具平台，用于解决网络安全教育中多样化的学生需求",
      "authors": [
        "Tianyu Wang",
        "Nianjun Zhou",
        "Zhixiong Chen"
      ],
      "abstract": "Many non-traditional students in cybersecurity programs often lack access to\nadvice from peers, family members and professors, which can hinder their\neducational experiences. Additionally, these students may not fully benefit\nfrom various LLM-powered AI assistants due to issues like content relevance,\nlocality of advice, minimum expertise, and timing. This paper addresses these\nchallenges by introducing an application designed to provide comprehensive\nsupport by answering questions related to knowledge, skills, and career\npreparation advice tailored to the needs of these students. We developed a\nlearning tool platform, CyberMentor, to address the diverse needs and pain\npoints of students majoring in cybersecurity. Powered by agentic workflow and\nGenerative Large Language Models (LLMs), the platform leverages\nRetrieval-Augmented Generation (RAG) for accurate and contextually relevant\ninformation retrieval to achieve accessibility and personalization. We\ndemonstrated its value in addressing knowledge requirements for cybersecurity\neducation and for career marketability, in tackling skill requirements for\nanalytical and programming assignments, and in delivering real time on demand\nlearning support. Using three use scenarios, we showcased CyberMentor in\nfacilitating knowledge acquisition and career preparation and providing\nseamless skill-based guidance and support. We also employed the LangChain\nprompt-based evaluation methodology to evaluate the platform's impact,\nconfirming its strong performance in helpfulness, correctness, and\ncompleteness. These results underscore the system's ability to support students\nin developing practical cybersecurity skills while improving equity and\nsustainability within higher education. Furthermore, CyberMentor's open-source\ndesign allows for adaptation across other disciplines, fostering educational\ninnovation and broadening its potential impact.",
      "tldr_zh": "这篇论文介绍了 CyberMentor，一种基于 AI 的学习工具平台，针对网络安全教育中非传统学生的需求（如缺乏建议和内容相关性问题）提供个性化的知识、技能和职业准备支持。平台采用 agentic workflow、Generative LLMs 和 RAG（Retrieval-Augmented Generation）技术，实现准确的上下文相关信息检索和实时学习辅助。实验通过三个使用场景和 LangChain 提示评估方法验证了 CyberMentor 在帮助性、正确性和完整性方面的出色表现，并强调其开源设计可扩展到其他学科，促进教育公平和创新。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "K.3.2; I.2.1"
      ],
      "primary_category": "cs.CY",
      "comment": "11 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09709v1",
      "published_date": "2025-01-16 18:00:06 UTC",
      "updated_date": "2025-01-16 18:00:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:07:35.731051"
    },
    {
      "arxiv_id": "2501.09707v1",
      "title": "The Goofus & Gallant Story Corpus for Practical Value Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Md Sultan Al Nahian",
        "Tasmia Tasrin",
        "Spencer Frazier",
        "Mark Riedl",
        "Brent Harrison"
      ],
      "abstract": "Values or principles are key elements of human society that influence people\nto behave and function according to an accepted standard set of social rules to\nmaintain social order. As AI systems are becoming ubiquitous in human society,\nit is a major concern that they could violate these norms or values and\npotentially cause harm. Thus, to prevent intentional or unintentional harm, AI\nsystems are expected to take actions that align with these principles. Training\nsystems to exhibit this type of behavior is difficult and often requires a\nspecialized dataset. This work presents a multi-modal dataset illustrating\nnormative and non-normative behavior in real-life situations described through\nnatural language and artistic images. This training set contains curated sets\nof images that are designed to teach young children about social principles. We\nargue that this is an ideal dataset to use for training socially normative\nagents given this fact.",
      "tldr_zh": "该论文提出了Goofus & Gallant Story Corpus，这是一个多模态数据集，旨在促进AI系统的实际价值对齐(Value Alignment)，帮助AI遵守社会规范并避免潜在危害。数据集通过自然语言描述和艺术图像展示真实情境中的规范和非规范行为，这些内容源自专门设计用于教育儿童的社会原则。作者认为，该数据集特别适合训练社会规范代理(socially normative agents)，从而提升AI在社会中的行为可靠性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by International Conference on Machine Learning and\n  Applications (ICMLA) 2024. Main Conference, Long Paper",
      "pdf_url": "http://arxiv.org/pdf/2501.09707v1",
      "published_date": "2025-01-16 17:58:58 UTC",
      "updated_date": "2025-01-16 17:58:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:07:46.157869"
    },
    {
      "arxiv_id": "2501.09705v1",
      "title": "Practical Continual Forgetting for Pre-trained Vision Models",
      "title_zh": "预训练视觉模型的实用持续遗忘方法",
      "authors": [
        "Hongbo Zhao",
        "Fei Zhu",
        "Bolin Ni",
        "Feng Zhu",
        "Gaofeng Meng",
        "Zhaoxiang Zhang"
      ],
      "abstract": "For privacy and security concerns, the need to erase unwanted information\nfrom pre-trained vision models is becoming evident nowadays. In real-world\nscenarios, erasure requests originate at any time from both users and model\nowners, and these requests usually form a sequence. Therefore, under such a\nsetting, selective information is expected to be continuously removed from a\npre-trained model while maintaining the rest. We define this problem as\ncontinual forgetting and identify three key challenges. (i) For unwanted\nknowledge, efficient and effective deleting is crucial. (ii) For remaining\nknowledge, the impact brought by the forgetting procedure should be minimal.\n(iii) In real-world scenarios, the training samples may be scarce or partially\nmissing during the process of forgetting. To address them, we first propose\nGroup Sparse LoRA (GS-LoRA). Specifically, towards (i), we introduce LoRA\nmodules to fine-tune the FFN layers in Transformer blocks for each forgetting\ntask independently, and towards (ii), a simple group sparse regularization is\nadopted, enabling automatic selection of specific LoRA groups and zeroing out\nthe others. To further extend GS-LoRA to more practical scenarios, we\nincorporate prototype information as additional supervision and introduce a\nmore practical approach, GS-LoRA++. For each forgotten class, we move the\nlogits away from its original prototype. For the remaining classes, we pull the\nlogits closer to their respective prototypes. We conduct extensive experiments\non face recognition, object detection and image classification and demonstrate\nthat our method manages to forget specific classes with minimal impact on other\nclasses. Codes have been released on https://github.com/bjzhb666/GS-LoRA.",
      "tldr_zh": "该论文针对隐私和安全需求，提出了一种实用的连续忘记方法，用于从预训练视觉模型中删除特定信息，同时最小化对剩余知识的影响。核心方法包括 Group Sparse LoRA (GS-LoRA)，通过在 Transformer 块的 FFN 层中应用 LoRA 模块进行独立任务微调，并采用组稀疏正则化自动选择和零化无关 LoRA 组，以高效处理忘记任务。进一步扩展为 GS-LoRA++，利用原型信息作为监督，将忘记类别的 logits 远离其原型，同时拉近剩余类别的 logits 到各自原型。实验在面部识别、物体检测和图像分类任务上证明，该方法能有效忘记指定类别的知识，而对其他类别的性能影响最小，并已在 GitHub 上开源代码。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09705v1",
      "published_date": "2025-01-16 17:57:53 UTC",
      "updated_date": "2025-01-16 17:57:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:07:58.992973"
    },
    {
      "arxiv_id": "2501.09700v1",
      "title": "Cueless EEG imagined speech for subject identification: dataset and benchmarks",
      "title_zh": "无提示脑电图想象言语用于主体识别：数据集和基准",
      "authors": [
        "Ali Derakhshesh",
        "Zahra Dehghanian",
        "Reza Ebrahimpour",
        "Hamid R. Rabiee"
      ],
      "abstract": "Electroencephalogram (EEG) signals have emerged as a promising modality for\nbiometric identification. While previous studies have explored the use of\nimagined speech with semantically meaningful words for subject identification,\nmost have relied on additional visual or auditory cues. In this study, we\nintroduce a cueless EEG-based imagined speech paradigm, where subjects imagine\nthe pronunciation of semantically meaningful words without any external cues.\nThis innovative approach addresses the limitations of prior methods by\nrequiring subjects to select and imagine words from a predefined list\nnaturally. The dataset comprises over 4,350 trials from 11 subjects across five\nsessions. We assess a variety of classification methods, including traditional\nmachine learning techniques such as Support Vector Machines (SVM) and XGBoost,\nas well as time-series foundation models and deep learning architectures\nspecifically designed for EEG classification, such as EEG Conformer and Shallow\nConvNet. A session-based hold-out validation strategy was employed to ensure\nreliable evaluation and prevent data leakage. Our results demonstrate\noutstanding classification accuracy, reaching 97.93%. These findings highlight\nthe potential of cueless EEG paradigms for secure and reliable subject\nidentification in real-world applications, such as brain-computer interfaces\n(BCIs).",
      "tldr_zh": "本文提出了一种无提示（cueless）EEG 想象言语范式，用于生物识别中的主体识别，subjects 无需外部视觉或听觉提示，从预定义列表中自行选择并想象语义有意义的单词，从而克服了传统方法的局限。研究构建了一个包含 11 个 subjects、超过 4,350 个 trials 和五个 sessions 的数据集，并评估了多种分类方法，包括传统机器学习如 Support Vector Machines (SVM) 和 XGBoost，以及深度学习模型如 EEG Conformer 和 Shallow ConvNet。采用基于 sessions 的 hold-out 验证策略，实验结果显示分类准确率高达 97.93%，突显了该范式在脑机接口 (BCI) 等真实世界应用中的安全性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09700v1",
      "published_date": "2025-01-16 17:54:56 UTC",
      "updated_date": "2025-01-16 17:54:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:08:12.194838"
    },
    {
      "arxiv_id": "2501.09686v3",
      "title": "Towards Large Reasoning Models: A Survey of Reinforced Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fengli Xu",
        "Qianyue Hao",
        "Zefang Zong",
        "Jingwei Wang",
        "Yunke Zhang",
        "Jingyi Wang",
        "Xiaochong Lan",
        "Jiahui Gong",
        "Tianjian Ouyang",
        "Fanjin Meng",
        "Chenyang Shao",
        "Yuwei Yan",
        "Qinglong Yang",
        "Yiwen Song",
        "Sijian Ren",
        "Xinyuan Hu",
        "Yu Li",
        "Jie Feng",
        "Chen Gao",
        "Yong Li"
      ],
      "abstract": "Language has long been conceived as an essential tool for human reasoning.\nThe breakthrough of Large Language Models (LLMs) has sparked significant\nresearch interest in leveraging these models to tackle complex reasoning tasks.\nResearchers have moved beyond simple autoregressive token generation by\nintroducing the concept of \"thought\" -- a sequence of tokens representing\nintermediate steps in the reasoning process. This innovative paradigm enables\nLLMs' to mimic complex human reasoning processes, such as tree search and\nreflective thinking. Recently, an emerging trend of learning to reason has\napplied reinforcement learning (RL) to train LLMs to master reasoning\nprocesses. This approach enables the automatic generation of high-quality\nreasoning trajectories through trial-and-error search algorithms, significantly\nexpanding LLMs' reasoning capacity by providing substantially more training\ndata. Furthermore, recent studies demonstrate that encouraging LLMs to \"think\"\nwith more tokens during test-time inference can further significantly boost\nreasoning accuracy. Therefore, the train-time and test-time scaling combined to\nshow a new research frontier -- a path toward Large Reasoning Model. The\nintroduction of OpenAI's o1 series marks a significant milestone in this\nresearch direction. In this survey, we present a comprehensive review of recent\nprogress in LLM reasoning. We begin by introducing the foundational background\nof LLMs and then explore the key technical components driving the development\nof large reasoning models, with a focus on automated data construction,\nlearning-to-reason techniques, and test-time scaling. We also analyze popular\nopen-source projects at building large reasoning models, and conclude with open\nchallenges and future research directions.",
      "tldr_zh": "这篇调查论文探讨了利用大型语言模型 (LLMs) 进行强化推理的最新进展，旨在推动向大型推理模型发展的方向。论文强调通过引入“thought”序列（如树搜索和反思性思考）以及强化学习 (RL) 技术，自动生成高质量推理轨迹，从而扩展 LLMs 的推理能力，并在测试时通过生成更多 token 显著提升准确性。研究回顾了关键组件，包括自动化数据构建、学习推理方法和测试时缩放，并分析了开源项目，同时指出了未来挑战，如 OpenAI o1 系列的里程碑意义。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09686v3",
      "published_date": "2025-01-16 17:37:58 UTC",
      "updated_date": "2025-01-23 08:44:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:08:23.628984"
    },
    {
      "arxiv_id": "2501.09685v2",
      "title": "Inference-Time Alignment in Diffusion Models with Reward-Guided Generation: Tutorial and Review",
      "title_zh": "扩散模型中基于奖励引导生成的推理时对齐：教程和综述",
      "authors": [
        "Masatoshi Uehara",
        "Yulai Zhao",
        "Chenyu Wang",
        "Xiner Li",
        "Aviv Regev",
        "Sergey Levine",
        "Tommaso Biancalani"
      ],
      "abstract": "This tutorial provides an in-depth guide on inference-time guidance and\nalignment methods for optimizing downstream reward functions in diffusion\nmodels. While diffusion models are renowned for their generative modeling\ncapabilities, practical applications in fields such as biology often require\nsample generation that maximizes specific metrics (e.g., stability, affinity in\nproteins, closeness to target structures). In these scenarios, diffusion models\ncan be adapted not only to generate realistic samples but also to explicitly\nmaximize desired measures at inference time without fine-tuning. This tutorial\nexplores the foundational aspects of such inference-time algorithms. We review\nthese methods from a unified perspective, demonstrating that current techniques\n-- such as Sequential Monte Carlo (SMC)-based guidance, value-based sampling,\nand classifier guidance -- aim to approximate soft optimal denoising processes\n(a.k.a. policies in RL) that combine pre-trained denoising processes with value\nfunctions serving as look-ahead functions that predict from intermediate states\nto terminal rewards. Within this framework, we present several novel algorithms\nnot yet covered in the literature. Furthermore, we discuss (1) fine-tuning\nmethods combined with inference-time techniques, (2) inference-time algorithms\nbased on search algorithms such as Monte Carlo tree search, which have received\nlimited attention in current research, and (3) connections between\ninference-time algorithms in language models and diffusion models. The code of\nthis tutorial on protein design is available at\nhttps://github.com/masa-ue/AlignInversePro",
      "tldr_zh": "这篇教程和综述探讨了扩散模型(diffusion models)中基于奖励引导生成(reward-guided generation)的推理时对齐(inference-time alignment)方法，用于优化下游奖励函数，如在生物学中最大化蛋白的稳定性或亲和力。该文从统一视角审视现有技术，包括Sequential Monte Carlo (SMC)-based guidance、value-based sampling和classifier guidance，这些方法通过结合预训练去噪过程和价值函数来近似软最优去噪过程(a.k.a. policies in RL)。论文引入了几个新算法，并讨论了与微调结合、基于搜索算法如Monte Carlo tree search的推理时方法，以及与语言模型的连接，为实际应用如蛋白设计提供了实用指导，代码见https://github.com/masa-ue/AlignInversePro。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.QM",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "We plan to add more content and codes. Please let us know if there\n  are any comments or missing citations",
      "pdf_url": "http://arxiv.org/pdf/2501.09685v2",
      "published_date": "2025-01-16 17:37:35 UTC",
      "updated_date": "2025-01-20 22:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:08:36.424114"
    },
    {
      "arxiv_id": "2501.09682v1",
      "title": "Incorporating Quantum Advantage in Quantum Circuit Generation through Genetic Programming",
      "title_zh": "通过遗传编程在量子电路生成中整合量子优势",
      "authors": [
        "Christoph Stein",
        "Michael Färber"
      ],
      "abstract": "Designing efficient quantum circuits that leverage quantum advantage compared\nto classical computing has become increasingly critical. Genetic algorithms\nhave shown potential in generating such circuits through artificial evolution.\nHowever, integrating quantum advantage into the fitness function of these\nalgorithms remains unexplored. In this paper, we aim to enhance the efficiency\nof quantum circuit design by proposing two novel approaches for incorporating\nquantum advantage metrics into the fitness function of genetic algorithms.1 We\nevaluate our approaches based on the Bernstein-Vazirani Problem and the\nUnstructured Database Search Problem as test cases. The results demonstrate\nthat our approaches not only improve the convergence speed of the genetic\nalgorithm but also produce circuits comparable to expert-designed solutions.\nOur findings suggest that automated quantum circuit design using genetic\nalgorithms that incorporate a measure of quantum advantage is a promising\napproach to accelerating the development of quantum algorithms.",
      "tldr_zh": "本文提出两种新方法，将量子优势(Quantum Advantage)指标融入遗传算法(Genetic Algorithms)的适应度函数，以提升量子电路设计效率。研究以Bernstein-Vazirani Problem和Unstructured Database Search Problem作为测试案例，实验结果显示这些方法显著提高了算法的收敛速度，并生成与专家设计方案相当的电路。这些发现表明，结合量子优势的自动化量子电路设计有望加速量子算法的开发。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "cs.ET",
        "cs.NE"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09682v1",
      "published_date": "2025-01-16 17:34:34 UTC",
      "updated_date": "2025-01-16 17:34:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:08:47.050772"
    },
    {
      "arxiv_id": "2501.09674v1",
      "title": "Authenticated Delegation and Authorized AI Agents",
      "title_zh": "认证委托和授权AI代理",
      "authors": [
        "Tobin South",
        "Samuele Marro",
        "Thomas Hardjono",
        "Robert Mahari",
        "Cedric Deslandes Whitney",
        "Dazza Greenwood",
        "Alan Chan",
        "Alex Pentland"
      ],
      "abstract": "The rapid deployment of autonomous AI agents creates urgent challenges around\nauthorization, accountability, and access control in digital spaces. New\nstandards are needed to know whom AI agents act on behalf of and guide their\nuse appropriately, protecting online spaces while unlocking the value of task\ndelegation to autonomous agents. We introduce a novel framework for\nauthenticated, authorized, and auditable delegation of authority to AI agents,\nwhere human users can securely delegate and restrict the permissions and scope\nof agents while maintaining clear chains of accountability. This framework\nbuilds on existing identification and access management protocols, extending\nOAuth 2.0 and OpenID Connect with agent-specific credentials and metadata,\nmaintaining compatibility with established authentication and web\ninfrastructure. Further, we propose a framework for translating flexible,\nnatural language permissions into auditable access control configurations,\nenabling robust scoping of AI agent capabilities across diverse interaction\nmodalities. Taken together, this practical approach facilitates immediate\ndeployment of AI agents while addressing key security and accountability\nconcerns, working toward ensuring agentic AI systems perform only appropriate\nactions and providing a tool for digital service providers to enable AI agent\ninteractions without risking harm from scalable interaction.",
      "tldr_zh": "本论文针对AI代理的授权、问责制和访问控制挑战，提出一个新型框架，支持认证、授权和可审计的权限委托。框架基于现有协议如OAuth 2.0和OpenID Connect，扩展了代理特定的凭证和元数据，并引入将自然语言权限转化为可审计访问控制配置的方法。用户可以通过此框架安全地委托和限制AI代理的权限，同时维护清晰的责任链。该框架促进AI代理的即时部署，提升安全性，确保代理仅执行适当行动并减少潜在风险。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.NI",
        "68M01, 68T01, 68U35, 94A60, 68P20"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09674v1",
      "published_date": "2025-01-16 17:11:21 UTC",
      "updated_date": "2025-01-16 17:11:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:08:59.306960"
    },
    {
      "arxiv_id": "2501.10476v1",
      "title": "Revisiting Rogers' Paradox in the Context of Human-AI Interaction",
      "title_zh": "在人类-AI 交互的背景下重新审视 Rogers 悖论",
      "authors": [
        "Katherine M. Collins",
        "Umang Bhatt",
        "Ilia Sucholutsky"
      ],
      "abstract": "Humans learn about the world, and how to act in the world, in many ways: from\nindividually conducting experiments to observing and reproducing others'\nbehavior. Different learning strategies come with different costs and\nlikelihoods of successfully learning more about the world. The choice that any\none individual makes of how to learn can have an impact on the collective\nunderstanding of a whole population if people learn from each other. Alan\nRogers developed simulations of a population of agents to study these network\nphenomena where agents could individually or socially learn amidst a dynamic,\nuncertain world and uncovered a confusing result: the availability of cheap\nsocial learning yielded no benefit to population fitness over individual\nlearning. This paradox spawned decades of work trying to understand and uncover\nfactors that foster the relative benefit of social learning that centuries of\nhuman behavior suggest exists. What happens in such network models now that\nhumans can socially learn from AI systems that are themselves socially learning\nfrom us? We revisit Rogers' Paradox in the context of human-AI interaction to\nprobe a simplified network of humans and AI systems learning together about an\nuncertain world. We propose and examine the impact of several learning\nstrategies on the quality of the equilibrium of a society's 'collective world\nmodel'. We consider strategies that can be undertaken by various stakeholders\ninvolved in a single human-AI interaction: human, AI model builder, and society\nor regulators around the interaction. We then consider possible negative\nfeedback loops that may arise from humans learning socially from AI: that\nlearning from the AI may impact our own ability to learn about the world. We\nclose with open directions into studying networks of human and AI systems that\ncan be explored in enriched versions of our simulation framework.",
      "tldr_zh": "本研究重新审视 Rogers' Paradox，在人类-AI 交互的背景下探讨社会学习与个体学习的相对益处。作者通过模拟框架建模一个包含人类和 AI 系统的学习网络，考察不同学习策略（如个体实验、社会观察和 AI 辅助学习）对社会“集体世界模型”平衡的影响。结果显示，人类从 AI 学习可能导致负面反馈循环，削弱个体学习能力，并强调了人类、AI 模型构建者和监管者等利益相关者的策略选择。最终，该工作提出未来扩展模拟框架，以深入研究人类-AI 网络的动态演化。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2501.10476v1",
      "published_date": "2025-01-16 17:09:57 UTC",
      "updated_date": "2025-01-16 17:09:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:09:11.096028"
    },
    {
      "arxiv_id": "2501.09672v2",
      "title": "Robin: a Suite of Multi-Scale Vision-Language Models and the CHIRP Evaluation Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Alexis Roger",
        "Prateek Humane",
        "Daniel Z. Kaplan",
        "Kshitij Gupta",
        "Qi Sun",
        "George Adamopoulos",
        "Jonathan Siu Chi Lim",
        "Quentin Anthony",
        "Edwin Fennell",
        "Irina Rish"
      ],
      "abstract": "The proliferation of Vision-Language Models (VLMs) in the past several years\ncalls for rigorous and comprehensive evaluation methods and benchmarks. This\nwork analyzes existing VLM evaluation techniques, including automated metrics,\nAI-based assessments, and human evaluations across diverse tasks. We first\nintroduce Robin - a novel suite of VLMs that we built by combining Large\nLanguage Models (LLMs) and Vision Encoders (VEs) at multiple scales, and use\nRobin to identify shortcomings of current evaluation approaches across scales.\nNext, to overcome the identified limitations, we introduce CHIRP - a new long\nform response benchmark we developed for more robust and complete VLM\nevaluation. We provide open access to the Robin training code, model suite, and\nCHIRP benchmark to promote reproducibility and advance VLM research.",
      "tldr_zh": "本文分析了现有视觉语言模型(VLM)评估技术，包括自动化指标、AI评估和人类评估，并通过构建Robin套件——一个结合多规模Large Language Models (LLMs)和Vision Encoders (VEs)的VLM框架——来识别这些方法的不足。针对这些问题，研究者引入了CHIRP基准，这是一个新的长形式响应评估标准，用于更稳健和全面的VLM评估。论文还公开了Robin的训练代码、模型套件和CHIRP基准，以促进研究的可重复性和VLM领域的进展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09672v2",
      "published_date": "2025-01-16 17:08:12 UTC",
      "updated_date": "2025-01-21 01:04:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:09:23.337003"
    },
    {
      "arxiv_id": "2501.09653v1",
      "title": "The Heap: A Contamination-Free Multilingual Code Dataset for Evaluating Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jonathan Katzy",
        "Razvan Mihai Popescu",
        "Arie van Deursen",
        "Maliheh Izadi"
      ],
      "abstract": "The recent rise in the popularity of large language models has spurred the\ndevelopment of extensive code datasets needed to train them. This has left\nlimited code available for collection and use in the downstream investigation\nof specific behaviors, or evaluation of large language models without suffering\nfrom data contamination. To address this problem, we release The Heap, a large\nmultilingual dataset covering 57 programming languages that has been\ndeduplicated with respect to other open datasets of code, enabling researchers\nto conduct fair evaluations of large language models without significant data\ncleaning overhead.",
      "tldr_zh": "这篇论文介绍了 The Heap，这是一个免受数据污染的多语言代码数据集，旨在解决大型语言模型（Large Language Models）评估中代码数据短缺的问题。数据集覆盖 57 种编程语言，并已与其它公开代码数据集进行去重处理，确保研究人员能轻松收集和使用。The Heap 的发布有助于进行公平的模型行为评估，而无需进行大量数据清洗，从而提升评估效率和可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Pre-Print. Accepted to FORGE 2025 Dataset Track",
      "pdf_url": "http://arxiv.org/pdf/2501.09653v1",
      "published_date": "2025-01-16 16:48:41 UTC",
      "updated_date": "2025-01-16 16:48:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:09:34.641615"
    },
    {
      "arxiv_id": "2501.09649v1",
      "title": "Monte Carlo Tree Search with Velocity Obstacles for safe and efficient motion planning in dynamic environments",
      "title_zh": "蒙特卡洛树搜索结合速度",
      "authors": [
        "Lorenzo Bonanni",
        "Daniele Meli",
        "Alberto Castellini",
        "Alessandro Farinelli"
      ],
      "abstract": "Online motion planning is a challenging problem for intelligent robots moving\nin dense environments with dynamic obstacles, e.g., crowds. In this work, we\npropose a novel approach for optimal and safe online motion planning with\nminimal information about dynamic obstacles. Specifically, our approach\nrequires only the current position of the obstacles and their maximum speed,\nbut it does not need any information about their exact trajectories or dynamic\nmodel. The proposed methodology combines Monte Carlo Tree Search (MCTS), for\nonline optimal planning via model simulations, with Velocity Obstacles (VO),\nfor obstacle avoidance. We perform experiments in a cluttered simulated\nenvironment with walls, and up to 40 dynamic obstacles moving with random\nvelocities and directions. With an ablation study, we show the key contribution\nof VO in scaling up the efficiency of MCTS, selecting the safest and most\nrewarding actions in the tree of simulations. Moreover, we show the superiority\nof our methodology with respect to state-of-the-art planners, including\nNon-linear Model Predictive Control (NMPC), in terms of improved collision\nrate, computational and task performance.",
      "tldr_zh": "本研究提出了一种结合Monte Carlo Tree Search (MCTS)与Velocity Obstacles (VO)的在线运动规划方法，旨在帮助智能机器人在动态环境（如拥挤人群）中实现安全、高效的路径规划，仅需障碍物的当前位置和最大速度信息，而非精确轨迹或动态模型。MCTS用于通过模型模拟进行在线最优规划，VO则负责障碍物避免，确保选择最安全且回报最高的行动。实验在杂乱模拟环境中进行，涉及墙壁和多达40个随机移动障碍物，结果显示该方法相较于Non-linear Model Predictive Control (NMPC)基准，显著降低了碰撞率，并提升了计算和任务性能，证明了其在扩展MCTS效率方面的关键贡献。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09649v1",
      "published_date": "2025-01-16 16:45:08 UTC",
      "updated_date": "2025-01-16 16:45:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:09:47.251296"
    },
    {
      "arxiv_id": "2501.09646v1",
      "title": "NS-Gym: Open-Source Simulation Environments and Benchmarks for Non-Stationary Markov Decision Processes",
      "title_zh": "NS-Gym：开源模拟环境和基准测试，用于非平稳马尔可夫决策过程",
      "authors": [
        "Nathaniel S. Keplinger",
        "Baiting Luo",
        "Iliyas Bektas",
        "Yunuo Zhang",
        "Kyle Hollins Wray",
        "Aron Laszka",
        "Abhishek Dubey",
        "Ayan Mukhopadhyay"
      ],
      "abstract": "In many real-world applications, agents must make sequential decisions in\nenvironments where conditions are subject to change due to various exogenous\nfactors. These non-stationary environments pose significant challenges to\ntraditional decision-making models, which typically assume stationary dynamics.\nNon-stationary Markov decision processes (NS-MDPs) offer a framework to model\nand solve decision problems under such changing conditions. However, the lack\nof standardized benchmarks and simulation tools has hindered systematic\nevaluation and advance in this field. We present NS-Gym, the first simulation\ntoolkit designed explicitly for NS-MDPs, integrated within the popular\nGymnasium framework. In NS-Gym, we segregate the evolution of the environmental\nparameters that characterize non-stationarity from the agent's decision-making\nmodule, allowing for modular and flexible adaptations to dynamic environments.\nWe review prior work in this domain and present a toolkit encapsulating key\nproblem characteristics and types in NS-MDPs. This toolkit is the first effort\nto develop a set of standardized interfaces and benchmark problems to enable\nconsistent and reproducible evaluation of algorithms under non-stationary\nconditions. We also benchmark six algorithmic approaches from prior work on\nNS-MDPs using NS-Gym. Our vision is that NS-Gym will enable researchers to\nassess the adaptability and robustness of their decision-making algorithms to\nnon-stationary conditions.",
      "tldr_zh": "该研究引入了 NS-Gym，这是一个开源模拟环境和基准工具，专门针对 Non-Stationary Markov Decision Processes (NS-MDPs)，以解决传统决策模型在动态环境中的局限性。NS-Gym 整合到 Gymnasium 框架中，通过分离环境参数的演变与代理的决策模块，实现模块化和灵活的适应。论文回顾了相关工作，提供标准化接口和基准问题，并对六个现有算法进行了基准测试，旨在帮助研究者评估算法在非平稳条件下的适应性和鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09646v1",
      "published_date": "2025-01-16 16:38:33 UTC",
      "updated_date": "2025-01-16 16:38:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:10:00.353580"
    },
    {
      "arxiv_id": "2501.09645v1",
      "title": "CarMem: Enhancing Long-Term Memory in LLM Voice Assistants through Category-Bounding",
      "title_zh": "CarMem：通过类别界定增强大型语言模型语音助手中的长期记忆",
      "authors": [
        "Johannes Kirmayr",
        "Lukas Stappen",
        "Phillip Schneider",
        "Florian Matthes",
        "Elisabeth André"
      ],
      "abstract": "In today's assistant landscape, personalisation enhances interactions,\nfosters long-term relationships, and deepens engagement. However, many systems\nstruggle with retaining user preferences, leading to repetitive user requests\nand disengagement. Furthermore, the unregulated and opaque extraction of user\npreferences in industry applications raises significant concerns about privacy\nand trust, especially in regions with stringent regulations like Europe. In\nresponse to these challenges, we propose a long-term memory system for voice\nassistants, structured around predefined categories. This approach leverages\nLarge Language Models to efficiently extract, store, and retrieve preferences\nwithin these categories, ensuring both personalisation and transparency. We\nalso introduce a synthetic multi-turn, multi-session conversation dataset\n(CarMem), grounded in real industry data, tailored to an in-car voice assistant\nsetting. Benchmarked on the dataset, our system achieves an F1-score of .78 to\n.95 in preference extraction, depending on category granularity. Our\nmaintenance strategy reduces redundant preferences by 95% and contradictory\nones by 92%, while the accuracy of optimal retrieval is at .87. Collectively,\nthe results demonstrate the system's suitability for industrial applications.",
      "tldr_zh": "该研究针对语音助手在保留用户偏好方面的问题（如重复请求和隐私担忧），提出CarMem系统，通过Category-Bounding方法利用Large Language Models (LLMs)来高效提取、存储和检索基于预定义类别的用户偏好，确保个人化和透明度。同时，引入了CarMem合成数据集，该数据集基于真实行业数据，模拟多轮、多会话的汽车语音助手场景。在基准测试中，系统在偏好提取上达到F1-score 0.78至0.95，维护策略减少了95%的冗余偏好和92%的矛盾偏好，检索准确率达0.87，证明其适用于工业应用。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for presentation at the International Conference on\n  Computational Linguistics (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.09645v1",
      "published_date": "2025-01-16 16:37:33 UTC",
      "updated_date": "2025-01-16 16:37:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:10:11.451954"
    },
    {
      "arxiv_id": "2501.09640v2",
      "title": "Electronic Health Records: Towards Digital Twins in Healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammet Alkan",
        "Hester Huijsdens",
        "Yola Jones",
        "Fani Deligianni"
      ],
      "abstract": "The pivotal shift from traditional paper-based records to sophisticated\nElectronic Health Records (EHR), enabled systematic collection and analysis of\npatient data through descriptive statistics, providing insight into patterns\nand trends across patient populations. This evolution continued toward\npredictive analytics, allowing healthcare providers to anticipate patient\noutcomes and potential complications before they occur. This progression from\nbasic digital record-keeping to sophisticated predictive modelling and digital\ntwins reflects healthcare's broader evolution toward more integrated,\npatient-centred approaches that combine data-driven insights with personalized\ncare delivery. This chapter explores the evolution and significance of\nhealthcare information systems, beginning with an examination of the\nimplementation of EHR in the UK and the USA. It provides a comprehensive\noverview of the International Classification of Diseases (ICD) system, tracing\nits development from ICD-9 to ICD-10. Central to this discussion is the\nMIMIC-III database, a landmark achievement in healthcare data sharing and\narguably the most comprehensive critical care database freely available to\nresearchers worldwide. MIMIC-III has democratized access to high-quality\nhealthcare data, enabling unprecedented opportunities for research and\nanalysis. The chapter examines its structure, clinical outcome analysis\ncapabilities, and practical applications through case studies, with a\nparticular focus on mortality and length of stay metrics, vital signs\nextraction, and ICD coding. Through detailed entity-relationship diagrams and\npractical examples, the text illustrates MIMIC's complex data structure and\ndemonstrates how different querying approaches can lead to subtly different\nresults, emphasizing the critical importance of understanding the database's\narchitecture for accurate data extraction.",
      "tldr_zh": "这篇论文探讨了电子健康记录(EHR)从传统纸质记录向数字孪生的演变，强调其通过描述性统计和预测分析实现患者数据系统化收集，从而支持个性化医疗和预见性干预。论文审查了EHR在英国和美国的实施历程、International Classification of Diseases (ICD)系统从ICD-9到ICD-10的发展，以及MIMIC-III数据库作为关键资源的作用，该数据库促进了医疗数据共享和研究。作者通过案例研究展示了MIMIC-III在分析临床结果（如死亡率和住院时间）、提取生命体征数据以及ICD编码方面的实际应用，并强调理解数据库结构对于准确数据查询的重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Added acknowledgements for the corresponding author",
      "pdf_url": "http://arxiv.org/pdf/2501.09640v2",
      "published_date": "2025-01-16 16:30:02 UTC",
      "updated_date": "2025-02-17 10:59:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:10:23.536614"
    },
    {
      "arxiv_id": "2501.09632v2",
      "title": "Platform-Aware Mission Planning",
      "title_zh": "平台感知任务规划",
      "authors": [
        "Stefan Panjkovic",
        "Alessandro Cimatti",
        "Andrea Micheli",
        "Stefano Tonetta"
      ],
      "abstract": "Planning for autonomous systems typically requires reasoning with models at\ndifferent levels of abstraction, and the harmonization of two competing sets of\nobjectives: high-level mission goals that refer to an interaction of the system\nwith the external environment, and low-level platform constraints that aim to\npreserve the integrity and the correct interaction of the subsystems. The\ncomplicated interplay between these two models makes it very hard to reason on\nthe system as a whole, especially when the objective is to find plans with\nrobustness guarantees, considering the non-deterministic behavior of the lower\nlayers of the system.\n  In this paper, we introduce the problem of Platform-Aware Mission Planning\n(PAMP), addressing it in the setting of temporal durative actions. The PAMP\nproblem differs from standard temporal planning for its exists-forall nature:\nthe high-level plan dealing with mission goals is required to satisfy safety\nand executability constraints, for all the possible non-deterministic\nexecutions of the low-level model of the platform and the environment. We\npropose two approaches for solving PAMP. The first baseline approach\namalgamates the mission and platform levels, while the second is based on an\nabstraction-refinement loop that leverages the combination of a planner and a\nverification engine. We prove the soundness and completeness of the proposed\napproaches and validate them experimentally, demonstrating the importance of\nheterogeneous modeling and the superiority of the technique based on\nabstraction-refinement.",
      "tldr_zh": "这篇论文引入了Platform-Aware Mission Planning (PAMP)问题，针对自主系统的规划，协调高层任务目标与低层平台约束，确保计划在非确定性环境中的鲁棒性。PAMP 采用 temporal durative actions 的框架，要求高层计划在所有可能的低层执行中满足安全和可执行性约束。作者提出了两种方法：一种是合并高层和低层模型，另一种基于 abstraction-refinement 循环结合规划器和验证引擎；实验结果证明了后者的优越性，并验证了异构建模的重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09632v2",
      "published_date": "2025-01-16 16:20:37 UTC",
      "updated_date": "2025-05-20 06:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:10:35.379805"
    },
    {
      "arxiv_id": "2501.09628v2",
      "title": "Artificial Intelligence-Driven Clinical Decision Support Systems",
      "title_zh": "人工智能驱动的临床决策支持系统",
      "authors": [
        "Muhammet Alkan",
        "Idris Zakariyya",
        "Samuel Leighton",
        "Kaushik Bhargav Sivangi",
        "Christos Anagnostopoulos",
        "Fani Deligianni"
      ],
      "abstract": "As artificial intelligence (AI) becomes increasingly embedded in healthcare\ndelivery, this chapter explores the critical aspects of developing reliable and\nethical Clinical Decision Support Systems (CDSS). Beginning with the\nfundamental transition from traditional statistical models to sophisticated\nmachine learning approaches, this work examines rigorous validation strategies\nand performance assessment methods, including the crucial role of model\ncalibration and decision curve analysis. The chapter emphasizes that creating\ntrustworthy AI systems in healthcare requires more than just technical\naccuracy; it demands careful consideration of fairness, explainability, and\nprivacy. The challenge of ensuring equitable healthcare delivery through AI is\nstressed, discussing methods to identify and mitigate bias in clinical\npredictive models. The chapter then delves into explainability as a cornerstone\nof human-centered CDSS. This focus reflects the understanding that healthcare\nprofessionals must not only trust AI recommendations but also comprehend their\nunderlying reasoning. The discussion advances in an analysis of privacy\nvulnerabilities in medical AI systems, from data leakage in deep learning\nmodels to sophisticated attacks against model explanations. The text explores\nprivacy-preservation strategies such as differential privacy and federated\nlearning, while acknowledging the inherent trade-offs between privacy\nprotection and model performance. This progression, from technical validation\nto ethical considerations, reflects the multifaceted challenges of developing\nAI systems that can be seamlessly and reliably integrated into daily clinical\npractice while maintaining the highest standards of patient care and data\nprotection.",
      "tldr_zh": "这篇论文探讨了人工智能 (AI) 在医疗领域的应用，重点开发可靠且伦理的临床决策支持系统 (CDSS)，从传统统计模型转向先进的机器学习方法，并强调了严格的验证策略如模型校准和决策曲线分析。论文强调构建可信赖 AI 系统需兼顾公平性、解释性和隐私，包括识别并缓解临床预测模型中的偏见，以及采用差分隐私和联邦学习等策略来防范数据泄露。最终，它突出了在日常临床实践中整合 AI 的多方面挑战，以确保公平医疗和患者数据保护。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Added acknowledgements for the corresponding author, updated Figure\n  4, 5 & 6",
      "pdf_url": "http://arxiv.org/pdf/2501.09628v2",
      "published_date": "2025-01-16 16:17:39 UTC",
      "updated_date": "2025-02-17 11:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:10:47.395115"
    },
    {
      "arxiv_id": "2501.09620v1",
      "title": "Beyond Reward Hacking: Causal Rewards for Large Language Model Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Chaoqi Wang",
        "Zhuokai Zhao",
        "Yibo Jiang",
        "Zhaorun Chen",
        "Chen Zhu",
        "Yuxin Chen",
        "Jiayi Liu",
        "Lizhu Zhang",
        "Xiangjun Fan",
        "Hao Ma",
        "Sinong Wang"
      ],
      "abstract": "Recent advances in large language models (LLMs) have demonstrated significant\nprogress in performing complex tasks. While Reinforcement Learning from Human\nFeedback (RLHF) has been effective in aligning LLMs with human preferences, it\nis susceptible to spurious correlations in reward modeling. Consequently, it\noften introduces biases-such as length bias, sycophancy, conceptual bias, and\ndiscrimination that hinder the model's ability to capture true causal\nrelationships. To address this, we propose a novel causal reward modeling\napproach that integrates causal inference to mitigate these spurious\ncorrelations. Our method enforces counterfactual invariance, ensuring reward\npredictions remain consistent when irrelevant variables are altered. Through\nexperiments on both synthetic and real-world datasets, we show that our\napproach mitigates various types of spurious correlations effectively,\nresulting in more reliable and fair alignment of LLMs with human preferences.\nAs a drop-in enhancement to the existing RLHF workflow, our causal reward\nmodeling provides a practical way to improve the trustworthiness and fairness\nof LLM finetuning.",
      "tldr_zh": "该论文指出，现有的 Reinforcement Learning from Human Feedback (RLHF) 在对齐大型语言模型 (LLMs) 时易受虚假相关影响，导致偏见如长度偏见 (length bias)、奉承 (sycophancy)、概念偏见 (conceptual bias) 和歧视问题。作者提出了一种新型因果奖励建模 (causal reward modeling) 方法，整合因果推理并强制反事实不变性 (counterfactual invariance)，确保奖励预测在无关变量改变时保持一致，从而缓解这些虚假相关。实验在合成和真实数据集上验证了该方法的有效性，提高了 LLMs 与人类偏好的可靠和公平对齐，并作为 RLHF 工作流的即插即用增强，提供更可信的模型微调方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09620v1",
      "published_date": "2025-01-16 16:00:37 UTC",
      "updated_date": "2025-01-16 16:00:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:11:00.480577"
    },
    {
      "arxiv_id": "2501.09608v1",
      "title": "Metric Learning with Progressive Self-Distillation for Audio-Visual Embedding Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Donghuo Zeng",
        "Kazushi Ikeda"
      ],
      "abstract": "Metric learning projects samples into an embedded space, where similarities\nand dissimilarities are quantified based on their learned representations.\nHowever, existing methods often rely on label-guided representation learning,\nwhere representations of different modalities, such as audio and visual data,\nare aligned based on annotated labels. This approach tends to underutilize\nlatent complex features and potential relationships inherent in the\ndistributions of audio and visual data that are not directly tied to the\nlabels, resulting in suboptimal performance in audio-visual embedding learning.\nTo address this issue, we propose a novel architecture that integrates\ncross-modal triplet loss with progressive self-distillation. Our method\nenhances representation learning by leveraging inherent distributions and\ndynamically refining soft audio-visual alignments -- probabilistic alignments\nbetween audio and visual data that capture the inherent relationships beyond\nexplicit labels. Specifically, the model distills audio-visual\ndistribution-based knowledge from annotated labels in a subset of each batch.\nThis self-distilled knowledge is used t",
      "tldr_zh": "该论文指出，现有的 metric learning 方法在音频-视觉嵌入学习中过度依赖标签引导，导致未充分利用音频和视觉数据分布中的潜在复杂特征和关系，从而影响性能。\n为此，研究提出一种新架构，结合跨模态三元组损失和 progressive self-distillation，通过动态细化软音频-视觉对齐（probabilistic alignments），来捕捉超出标签的内在分布知识。\n这种方法从批次子集的带标签数据中蒸馏知识，并逐步增强表示学习，最终有望提升音频-视觉嵌入学习的整体效果。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.IR",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 3 figures, 2 tables. Accepted by ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.09608v1",
      "published_date": "2025-01-16 15:32:41 UTC",
      "updated_date": "2025-01-16 15:32:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:11:11.946842"
    },
    {
      "arxiv_id": "2501.09605v1",
      "title": "Managed-Retention Memory: A New Class of Memory for the AI Era",
      "title_zh": "翻译失败",
      "authors": [
        "Sergey Legtchenko",
        "Ioan Stefanovici",
        "Richard Black",
        "Antony Rowstron",
        "Junyi Liu",
        "Paolo Costa",
        "Burcu Canakci",
        "Dushyanth Narayanan",
        "Xingbo Wu"
      ],
      "abstract": "AI clusters today are one of the major uses of High Bandwidth Memory (HBM).\nHowever, HBM is suboptimal for AI workloads for several reasons. Analysis shows\nHBM is overprovisioned on write performance, but underprovisioned on density\nand read bandwidth, and also has significant energy per bit overheads. It is\nalso expensive, with lower yield than DRAM due to manufacturing complexity. We\npropose a new memory class: Managed-Retention Memory (MRM), which is more\noptimized to store key data structures for AI inference workloads. We believe\nthat MRM may finally provide a path to viability for technologies that were\noriginally proposed to support Storage Class Memory (SCM). These technologies\ntraditionally offered long-term persistence (10+ years) but provided poor IO\nperformance and/or endurance. MRM makes different trade-offs, and by\nunderstanding the workload IO patterns, MRM foregoes long-term data retention\nand write performance for better potential performance on the metrics important\nfor these workloads.",
      "tldr_zh": "该论文分析了High Bandwidth Memory (HBM)在AI集群中的不足，包括写入性能过度配置、密度和读取带宽不足，以及较高的能源消耗和成本。作者提出了一种新内存类Managed-Retention Memory (MRM)，专门优化用于AI推理工作负载的关键数据结构存储，通过理解工作负载IO模式，牺牲长期数据保留和写入性能，以提升密度、读取带宽等重要指标。MRM可能为原本用于Storage Class Memory (SCM)的技术提供可行性路径，从而更好地适应AI时代的需求。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.ET"
      ],
      "primary_category": "cs.AR",
      "comment": "8 pages (5 content + 3 refs); 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.09605v1",
      "published_date": "2025-01-16 15:25:44 UTC",
      "updated_date": "2025-01-16 15:25:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:11:23.473844"
    },
    {
      "arxiv_id": "2501.09597v1",
      "title": "Reducing the Sensitivity of Neural Physics Simulators to Mesh Topology via Pretraining",
      "title_zh": "通过预训练减少神经物理模拟器对网格拓扑的敏感性",
      "authors": [
        "Nathan Vaska",
        "Justin Goodwin",
        "Robin Walters",
        "Rajmonda S. Caceres"
      ],
      "abstract": "Meshes are used to represent complex objects in high fidelity physics\nsimulators across a variety of domains, such as radar sensing and aerodynamics.\nThere is growing interest in using neural networks to accelerate physics\nsimulations, and also a growing body of work on applying neural networks\ndirectly to irregular mesh data. Since multiple mesh topologies can represent\nthe same object, mesh augmentation is typically required to handle topological\nvariation when training neural networks. Due to the sensitivity of physics\nsimulators to small changes in mesh shape, it is challenging to use these\naugmentations when training neural network-based physics simulators. In this\nwork, we show that variations in mesh topology can significantly reduce the\nperformance of neural network simulators. We evaluate whether pretraining can\nbe used to address this issue, and find that employing an established\nautoencoder pretraining technique with graph embedding models reduces the\nsensitivity of neural network simulators to variations in mesh topology.\nFinally, we highlight future research directions that may further reduce neural\nsimulator sensitivity to mesh topology.",
      "tldr_zh": "这篇论文探讨了神经物理模拟器（Neural Physics Simulators）对网格拓扑（Mesh Topology）变化的敏感性问题，因为不同拓扑可能表示同一物体，但会导致模拟性能显著下降。作者通过采用自动编码器（Autoencoder）预训练技术结合图嵌入模型（Graph Embedding Models），来减少这种敏感性，并在训练过程中处理网格增强的挑战。实验结果表明，该预训练方法有效提升了模拟器的鲁棒性。论文还提出了未来研究方向，以进一步优化神经模拟器对拓扑变化的适应性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.6; I.2.10"
      ],
      "primary_category": "cs.LG",
      "comment": "5 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09597v1",
      "published_date": "2025-01-16 15:21:18 UTC",
      "updated_date": "2025-01-16 15:21:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:11:36.097976"
    },
    {
      "arxiv_id": "2501.09595v1",
      "title": "IFRA: a machine learning-based Instrumented Fall Risk Assessment Scale derived from Instrumented Timed Up and Go test in stroke patients",
      "title_zh": "翻译失败",
      "authors": [
        "Simone Macciò",
        "Alessandro Carfì",
        "Alessio Capitanelli",
        "Peppino Tropea",
        "Massimo Corbo",
        "Fulvio Mastrogiovanni",
        "Michela Picardi"
      ],
      "abstract": "Effective fall risk assessment is critical for post-stroke patients. The\npresent study proposes a novel, data-informed fall risk assessment method based\non the instrumented Timed Up and Go (ITUG) test data, bringing in many mobility\nmeasures that traditional clinical scales fail to capture. IFRA, which stands\nfor Instrumented Fall Risk Assessment, has been developed using a two-step\nprocess: first, features with the highest predictive power among those\ncollected in a ITUG test have been identified using machine learning\ntechniques; then, a strategy is proposed to stratify patients into low, medium,\nor high-risk strata. The dataset used in our analysis consists of 142\nparticipants, out of which 93 were used for training (15 synthetically\ngenerated), 17 for validation and 32 to test the resulting IFRA scale (22\nnon-fallers and 10 fallers). Features considered in the IFRA scale include gait\nspeed, vertical acceleration during sit-to-walk transition, and turning angular\nvelocity, which align well with established literature on the risk of fall in\nneurological patients. In a comparison with traditional clinical scales such as\nthe traditional Timed Up & Go and the Mini-BESTest, IFRA demonstrates\ncompetitive performance, being the only scale to correctly assign more than\nhalf of the fallers to the high-risk stratum (Fischer's Exact test p = 0.004).\nDespite the dataset's limited size, this is the first proof-of-concept study to\npave the way for future evidence regarding the use of IFRA tool for continuous\npatient monitoring and fall prevention both in clinical stroke rehabilitation\nand at home post-discharge.",
      "tldr_zh": "本文提出 IFRA，一种基于 machine learning 的 Instrumented Fall Risk Assessment 量表，利用 Instrumented Timed Up and Go (ITUG) 测试数据评估中风患者的跌倒风险，通过两步过程识别高预测力特征（如步行速度、坐到走过渡的垂直加速度和转弯角速度），并将患者分层为低、中或高风险。研究使用 142 名参与者的数据集进行训练、验证和测试，结果显示 IFRA 比传统临床量表如 Timed Up & Go 和 Mini-BESTest 更具竞争力，能正确将超过一半的跌倒者归为高风险群组（Fischer's Exact test p = 0.004）。这项概念验证研究为中风患者的临床康复和家庭监测提供新工具，促进持续跌倒预防。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.LG",
      "comment": "26 pages, 2 figures, submitted for review dec 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.09595v1",
      "published_date": "2025-01-16 15:20:22 UTC",
      "updated_date": "2025-01-16 15:20:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:21:50.091904"
    },
    {
      "arxiv_id": "2501.09571v1",
      "title": "MatrixNet: Learning over symmetry groups using learned group representations",
      "title_zh": "翻译失败",
      "authors": [
        "Lucas Laird",
        "Circe Hsu",
        "Asilata Bapat",
        "Robin Walters"
      ],
      "abstract": "Group theory has been used in machine learning to provide a theoretically\ngrounded approach for incorporating known symmetry transformations in tasks\nfrom robotics to protein modeling. In these applications, equivariant neural\nnetworks use known symmetry groups with predefined representations to learn\nover geometric input data. We propose MatrixNet, a neural network architecture\nthat learns matrix representations of group element inputs instead of using\npredefined representations. MatrixNet achieves higher sample efficiency and\ngeneralization over several standard baselines in prediction tasks over the\nseveral finite groups and the Artin braid group. We also show that MatrixNet\nrespects group relations allowing generalization to group elements of greater\nword length than in the training set.",
      "tldr_zh": "论文提出了 MatrixNet，一种新型神经网络架构，用于在群论（group theory）基础上学习对称群的矩阵表示，而不是依赖预定义的表示，从而提升机器学习任务中的对称性处理。MatrixNet 通过学习群元素表示，在几个有限群和 Artin braid group 的预测任务中，比标准基线模型实现了更高的样本效率和泛化能力。该方法还能够尊重群关系，实现对训练集外更长词长（word length）的群元素的泛化。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.RT"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.09571v1",
      "published_date": "2025-01-16 14:45:12 UTC",
      "updated_date": "2025-01-16 14:45:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:11:58.676421"
    },
    {
      "arxiv_id": "2501.09555v3",
      "title": "Text-driven Adaptation of Foundation Models for Few-shot Surgical Workflow Analysis",
      "title_zh": "文本驱动的基础模型适应用于少样本手术工作流分析",
      "authors": [
        "Tingxuan Chen",
        "Kun Yuan",
        "Vinkle Srivastav",
        "Nassir Navab",
        "Nicolas Padoy"
      ],
      "abstract": "Purpose: Surgical workflow analysis is crucial for improving surgical\nefficiency and safety. However, previous studies rely heavily on large-scale\nannotated datasets, posing challenges in cost, scalability, and reliance on\nexpert annotations. To address this, we propose Surg-FTDA (Few-shot Text-driven\nAdaptation), designed to handle various surgical workflow analysis tasks with\nminimal paired image-label data.\n  Methods: Our approach has two key components. First, Few-shot selection-based\nmodality alignment selects a small subset of images and aligns their embeddings\nwith text embeddings from the downstream task, bridging the modality gap.\nSecond, Text-driven adaptation leverages only text data to train a decoder,\neliminating the need for paired image-text data. This decoder is then applied\nto aligned image embeddings, enabling image-related tasks without explicit\nimage-text pairs.\n  Results: We evaluate our approach to generative tasks (image captioning) and\ndiscriminative tasks (triplet recognition and phase recognition). Results show\nthat Surg-FTDA outperforms baselines and generalizes well across downstream\ntasks.\n  Conclusion: We propose a text-driven adaptation approach that mitigates the\nmodality gap and handles multiple downstream tasks in surgical workflow\nanalysis, with minimal reliance on large annotated datasets. The code and\ndataset will be released in https://github.com/CAMMA-public/Surg-FTDA",
      "tldr_zh": "本文提出 Surg-FTDA 方法，用于少样本手术工作流程分析，通过文本驱动适应减少对大型标注数据集的依赖，仅需最少的图像-标签对数据。方法包括 Few-shot selection-based modality alignment 来选择少量图像并对齐其嵌入与文本嵌入，以及 Text-driven adaptation 来仅用文本数据训练解码器，从而实现图像相关任务。实验结果显示，Surg-FTDA 在图像 captioning、triplet recognition 和 phase recognition 等任务上优于基线模型，并表现出良好的泛化性。该框架为高效、可扩展的手术智能分析提供了新途径，相关代码和数据集将在 GitHub 上发布。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09555v3",
      "published_date": "2025-01-16 14:18:06 UTC",
      "updated_date": "2025-03-03 13:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:12:13.885566"
    },
    {
      "arxiv_id": "2501.09534v1",
      "title": "AI in Support of Diversity and Inclusion",
      "title_zh": "翻译失败",
      "authors": [
        "Çiçek Güven",
        "Afra Alishahi",
        "Henry Brighton",
        "Gonzalo Nápoles",
        "Juan Sebastian Olier",
        "Marie Šafář",
        "Eric Postma",
        "Dimitar Shterionov",
        "Mirella De Sisto",
        "Eva Vanmassenhove"
      ],
      "abstract": "In this paper, we elaborate on how AI can support diversity and inclusion and\nexemplify research projects conducted in that direction. We start by looking at\nthe challenges and progress in making large language models (LLMs) more\ntransparent, inclusive, and aware of social biases. Even though LLMs like\nChatGPT have impressive abilities, they struggle to understand different\ncultural contexts and engage in meaningful, human like conversations. A key\nissue is that biases in language processing, especially in machine translation,\ncan reinforce inequality. Tackling these biases requires a multidisciplinary\napproach to ensure AI promotes diversity, fairness, and inclusion. We also\nhighlight AI's role in identifying biased content in media, which is important\nfor improving representation. By detecting unequal portrayals of social groups,\nAI can help challenge stereotypes and create more inclusive technologies.\nTransparent AI algorithms, which clearly explain their decisions, are essential\nfor building trust and reducing bias in AI systems. We also stress AI systems\nneed diverse and inclusive training data. Projects like the Child Growth\nMonitor show how using a wide range of data can help address real world\nproblems like malnutrition and poverty. We present a project that demonstrates\nhow AI can be applied to monitor the role of search engines in spreading\ndisinformation about the LGBTQ+ community. Moreover, we discuss the SignON\nproject as an example of how technology can bridge communication gaps between\nhearing and deaf people, emphasizing the importance of collaboration and mutual\ntrust in developing inclusive AI. Overall, with this paper, we advocate for AI\nsystems that are not only effective but also socially responsible, promoting\nfair and inclusive interactions between humans and machines.",
      "tldr_zh": "本论文探讨了 AI 如何支持多样性和包容性，重点分析大型语言模型（LLMs）如 ChatGPT 在处理文化上下文和社会偏见方面的挑战，并提出多学科方法来减少语言处理中的偏见，确保 AI 促进公平和包容。论文强调透明 AI 算法、识别媒体中的偏见内容以及使用多样化训练数据的必要性，通过项目如 Child Growth Monitor 和 SignON 示范 AI 在解决营养问题、防范对 LGBTQ+ 社区的错误信息以及桥接听障沟通方面的实际应用。最终，作者倡导开发社会责任强的 AI 系统，以构建信任并推动人类与机器的包容互动。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09534v1",
      "published_date": "2025-01-16 13:36:24 UTC",
      "updated_date": "2025-01-16 13:36:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:12:23.406515"
    },
    {
      "arxiv_id": "2501.09525v2",
      "title": "Class Incremental Fault Diagnosis under Limited Fault Data via Supervised Contrastive Knowledge Distillation",
      "title_zh": "翻译失败",
      "authors": [
        "Hanrong Zhang",
        "Yifei Yao",
        "Zixuan Wang",
        "Jiayuan Su",
        "Mengxuan Li",
        "Peng Peng",
        "Hongwei Wang"
      ],
      "abstract": "Class-incremental fault diagnosis requires a model to adapt to new fault\nclasses while retaining previous knowledge. However, limited research exists\nfor imbalanced and long-tailed data. Extracting discriminative features from\nfew-shot fault data is challenging, and adding new fault classes often demands\ncostly model retraining. Moreover, incremental training of existing methods\nrisks catastrophic forgetting, and severe class imbalance can bias the model's\ndecisions toward normal classes. To tackle these issues, we introduce a\nSupervised Contrastive knowledge distiLlation for class Incremental Fault\nDiagnosis (SCLIFD) framework proposing supervised contrastive knowledge\ndistillation for improved representation learning capability and less\nforgetting, a novel prioritized exemplar selection method for sample replay to\nalleviate catastrophic forgetting, and the Random Forest Classifier to address\nthe class imbalance. Extensive experimentation on simulated and real-world\nindustrial datasets across various imbalance ratios demonstrates the\nsuperiority of SCLIFD over existing approaches. Our code can be found at\nhttps://github.com/Zhang-Henry/SCLIFD_TII.",
      "tldr_zh": "该研究针对类增量故障诊断问题，提出了一种名为 SCLIFD 的框架，以应对有限故障数据、数据不平衡和灾难性遗忘等挑战。框架通过 Supervised Contrastive knowledge distillation 技术提升表示学习能力并减少遗忘，结合新型优先级样本选择方法进行样本重放，以及 Random Forest Classifier 来处理类不平衡。实验在模拟和真实工业数据集上证明，SCLIFD 在各种不平衡比率下优于现有方法，提供更有效的故障诊断解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09525v2",
      "published_date": "2025-01-16 13:20:29 UTC",
      "updated_date": "2025-01-19 10:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:12:35.519737"
    },
    {
      "arxiv_id": "2501.09481v2",
      "title": "MonoSOWA: Scalable monocular 3D Object detector Without human Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Jan Skvrna",
        "Lukas Neumann"
      ],
      "abstract": "Inferring object 3D position and orientation from a single RGB camera is a\nfoundational task in computer vision with many important applications.\nTraditionally, 3D object detection methods are trained in a fully-supervised\nsetup, requiring LiDAR and vast amounts of human annotations, which are\nlaborious, costly, and do not scale well with the ever-increasing amounts of\ndata being captured.\n  We present a novel method to train a 3D object detector from a single RGB\ncamera without domain-specific human annotations, making orders of magnitude\nmore data available for training. The method uses newly proposed Local Object\nMotion Model to disentangle object movement source between subsequent frames,\nis approximately 700 times faster than previous work and compensates camera\nfocal length differences to aggregate multiple datasets.\n  The method is evaluated on three public datasets, where despite using no\nhuman labels, it outperforms prior work by a significant margin. It also shows\nits versatility as a pre-training tool for fully-supervised training and shows\nthat combining pseudo-labels from multiple datasets can achieve comparable\naccuracy to using human labels from a single dataset. The source code and model\nwill be published soon.",
      "tldr_zh": "这篇论文提出了 MonoSOWA，一种无需人工标注的可扩展单目 RGB 3D 物体检测器，旨在从单一相机推断物体的 3D 位置和方向，从而解决传统方法依赖 LiDAR 和大量标注的局限性。核心创新是引入 Local Object Motion Model 来区分物体在连续帧中的运动来源，该方法比先前工作快约 700 倍，并能补偿相机焦距差异以聚合多个数据集。实验在三个公共数据集上显示，尽管不使用人类标签，MonoSOWA 的性能显著优于现有方法；此外，它还可用作全监督训练的预训练工具，并证明结合多个数据集的伪标签可媲美单一数据集的人工标注准确性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09481v2",
      "published_date": "2025-01-16 11:35:22 UTC",
      "updated_date": "2025-03-10 12:27:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:12:48.593033"
    },
    {
      "arxiv_id": "2501.09469v1",
      "title": "Predicting Air Temperature from Volumetric Urban Morphology with Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Berk Kıvılcım",
        "Patrick Erik Bradley"
      ],
      "abstract": "In this study, we firstly introduce a method that converts CityGML data into\nvoxels which works efficiently and fast in high resolution for large scale\ndatasets such as cities but by sacrificing some building details to overcome\nthe limitations of previous voxelization methodologies that have been\ncomputationally intensive and inefficient at transforming large-scale urban\nareas into voxel representations for high resolution. Those voxelized 3D city\ndata from multiple cities and corresponding air temperature data are used to\ndevelop a machine learning model. Before the model training, Gaussian blurring\nis implemented on input data to consider spatial relationships, as a result the\ncorrelation rate between air temperature and volumetric building morphology is\nalso increased after the Gaussian blurring. After the model training, the\nprediction results are not just evaluated with Mean Square Error (MSE) but some\nimage similarity metrics such as Structural Similarity Index Measure (SSIM) and\nLearned Perceptual Image Patch Similarity (LPIPS) that are able to detect and\nconsider spatial relations during the evaluation process. This trained model is\ncapable of predicting the spatial distribution of air temperature by using\nbuilding volume information of corresponding pixel as input. By doing so, this\nresearch aims to assist urban planners in incorporating environmental\nparameters into their planning strategies, thereby facilitating more\nsustainable and inhabitable urban environments.",
      "tldr_zh": "本研究提出了一种高效方法，将 CityGML 数据转换为体素 (voxels)，以快速处理大规模城市数据集，同时牺牲部分建筑细节来克服传统体素化方法的计算密集问题。研究利用这些体素化 3D 城市数据和空气温度数据，通过 Gaussian blurring 处理输入以增强空间关系相关性，并训练机器学习模型来预测空气温度的空间分布。模型评估采用 Mean Square Error (MSE)、Structural Similarity Index Measure (SSIM) 和 Learned Perceptual Image Patch Similarity (LPIPS) 等指标，显示了显著的预测准确性。该方法旨在辅助城市规划者整合环境参数，促进更可持续的城市环境。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "30 pages, 8 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.09469v1",
      "published_date": "2025-01-16 11:10:38 UTC",
      "updated_date": "2025-01-16 11:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:12:59.622707"
    },
    {
      "arxiv_id": "2501.09465v1",
      "title": "RE-POSE: Synergizing Reinforcement Learning-Based Partitioning and Offloading for Edge Object Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Jianrui Shi",
        "Yong Zhao",
        "Zeyang Cui",
        "Xiaoming Shen",
        "Minhang Zeng",
        "Xiaojie Liu"
      ],
      "abstract": "Object detection plays a crucial role in smart video analysis, with\napplications ranging from autonomous driving and security to smart cities.\nHowever, achieving real-time object detection on edge devices presents\nsignificant challenges due to their limited computational resources and the\nhigh demands of deep neural network (DNN)-based detection models, particularly\nwhen processing high-resolution video. Conventional strategies, such as input\ndown-sampling and network up-scaling, often compromise detection accuracy for\nfaster performance or lead to higher inference latency. To address these\nissues, this paper introduces RE-POSE, a Reinforcement Learning (RL)-Driven\nPartitioning and Edge Offloading framework designed to optimize the\naccuracy-latency trade-off in resource-constrained edge environments. Our\napproach features an RL-Based Dynamic Clustering Algorithm (RL-DCA) that\npartitions video frames into non-uniform blocks based on object distribution\nand the computational characteristics of DNNs. Furthermore, a parallel edge\noffloading scheme is implemented to distribute these blocks across multiple\nedge servers for concurrent processing. Experimental evaluations show that\nRE-POSE significantly enhances detection accuracy and reduces inference\nlatency, surpassing existing methods.",
      "tldr_zh": "本文提出 RE-POSE 框架，通过强化学习（RL）驱动的分区和边缘卸载技术，优化边缘设备上对象检测的准确性与延迟权衡，以应对资源受限环境下的高分辨率视频处理挑战。具体而言，该框架采用 RL-Based Dynamic Clustering Algorithm (RL-DCA) 根据对象分布和 Deep Neural Network (DNN) 计算特性，将视频帧分区成非均匀块，并通过并行边缘卸载方案将这些块分配到多个边缘服务器上进行并发处理。实验评估表明，RE-POSE 显著提升了检测准确率并降低了推理延迟，超过了现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09465v1",
      "published_date": "2025-01-16 10:56:45 UTC",
      "updated_date": "2025-01-16 10:56:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:13:11.729984"
    },
    {
      "arxiv_id": "2501.09775v2",
      "title": "Multiple Choice Questions: Reasoning Makes Large Language Models (LLMs) More Self-Confident Even When They Are Wrong",
      "title_zh": "多项选择题：推理使大型语言模型 (LLMs) 即使在错误时也更自信",
      "authors": [
        "Tairan Fu",
        "Javier Conde",
        "Gonzalo Martínez",
        "María Grandury",
        "Pedro Reviriego"
      ],
      "abstract": "One of the most widely used methods to evaluate LLMs are Multiple Choice\nQuestion (MCQ) tests. MCQ benchmarks enable the testing of LLM knowledge on\nalmost any topic at scale as the results can be processed automatically. To\nhelp the LLM answer, a few examples called few shots can be included in the\nprompt. Moreover, the LLM can be asked to answer the question directly with the\nselected option or to first provide the reasoning and then the selected answer,\nwhich is known as chain of thought. In addition to checking whether the\nselected answer is correct, the evaluation can look at the LLM-estimated\nprobability of its response as an indication of the confidence of the LLM in\nthe response. In this paper, we study how the LLM confidence in its answer\ndepends on whether the model has been asked to answer directly or to provide\nthe reasoning before answering. The results of the evaluation of questions on a\nwide range of topics in seven different models show that LLMs are more\nconfident in their answers when they provide reasoning before the answer. This\noccurs regardless of whether the selected answer is correct. Our hypothesis is\nthat this behavior is due to the reasoning that modifies the probability of the\nselected answer, as the LLM predicts the answer based on the input question and\nthe reasoning that supports the selection made. Therefore, LLM estimated\nprobabilities seem to have intrinsic limitations that should be understood in\norder to use them in evaluation procedures. Interestingly, the same behavior\nhas been observed in humans, for whom explaining an answer increases confidence\nin its correctness.",
      "tldr_zh": "本文研究了在多选题 (MCQs) 测试中，要求 Large Language Models (LLMs) 先提供推理（Chain of Thought）再回答问题时，其自信度的变化。实验结果显示，无论答案正确与否，LLMs 在提供推理后会表现出更高的自信度，这可能是因为推理过程修改了答案的概率估计。作者分析了 LLMs 概率估计的内在局限性，并建议在评估中使用时需谨慎理解。该现象与人类行为类似，即解释答案会增强对正确性的信心。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09775v2",
      "published_date": "2025-01-16 10:27:51 UTC",
      "updated_date": "2025-01-24 22:03:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:22:00.942529"
    },
    {
      "arxiv_id": "2501.09444v2",
      "title": "Solving the Unsolvable: Translating Case Law in Hong Kong",
      "title_zh": "翻译失败",
      "authors": [
        "King-kui Sin",
        "Xi Xuan",
        "Chunyu Kit",
        "Clara Ho-yan Chan",
        "Honic Ho-kin Ip"
      ],
      "abstract": "This paper addresses the challenges translating case law under Hong Kong's\nbilingual legal system. It highlights the initial success of translating all\nwritten statutes into Chinese before the 1997 handover, a task mandated by the\nBasic Law. The effort involved significant collaboration among legal,\nlinguistic, and translation experts, resulting in a comprehensive and\nculturally appropriate bilingual legal system. However, translating case law\nremains a significant challenge due to the sheer volume and continuous growth\nof judicial decisions. The paper critiques the governments and judiciarys\nsporadic and uncoordinated efforts to translate case law, contrasting it with\nthe thorough approach previously taken for statute translation. Although the\ngovernment acknowledges the importance of legal bilingualism, it lacks a\nsustainable strategy for translating case law. The Judiciarys position that\ntranslating all judgments is unnecessary, unrealistic, and not cost-effectiveis\nanalyzed and critiqued for its impact on legal transparency and public trust. A\nproposed solution involves leveraging machine translation technology through a\nhuman-machine interactive translation platform, which undergoes two major\ntransitions. Initially based on a neural model, the platform transitions to\nusing a large language model for improved translation accuracy. Furthermore, it\nevolves from a single-agent system to a multi-agent system, incorporating\nTranslator, Annotator, and Proofreader agents. This multi-agent approach,\nsupported by a grant, aims to facilitate efficient, high-quality translation of\njudicial judgments by integrating advanced artificial intelligence and\ncontinuous feedback mechanisms, thus better meeting the needs of a bilingual\nlegal system.",
      "tldr_zh": "这篇论文探讨了香港双语法律系统下翻译判例法的挑战，突显出尽管成文法在1997年移交前已成功翻译，但判例法的翻译因数量庞大和持续增长而面临重大障碍。论文批评政府和司法机构的零散努力缺乏可持续策略，并质疑司法机构认为翻译所有判决“不必要、不现实且不划算”的立场，这可能影响法律透明度和公众信任。为解决这一问题，论文提出利用machine translation技术，通过一个人类-机器互动翻译平台，该平台从基于neural model的单代理系统演进到使用large language model的多-agent system，incorporating Translator, Annotator, and Proofreader agents，以提升翻译效率和准确性，最终支持高效的双语法律体系。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09444v2",
      "published_date": "2025-01-16 10:17:58 UTC",
      "updated_date": "2025-01-18 13:32:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:22:13.987729"
    },
    {
      "arxiv_id": "2501.09431v1",
      "title": "A Survey on Responsible LLMs: Inherent Risk, Malicious Use, and Mitigation Strategy",
      "title_zh": "翻译失败",
      "authors": [
        "Huandong Wang",
        "Wenjie Fu",
        "Yingzhou Tang",
        "Zhilong Chen",
        "Yuxi Huang",
        "Jinghua Piao",
        "Chen Gao",
        "Fengli Xu",
        "Tao Jiang",
        "Yong Li"
      ],
      "abstract": "While large language models (LLMs) present significant potential for\nsupporting numerous real-world applications and delivering positive social\nimpacts, they still face significant challenges in terms of the inherent risk\nof privacy leakage, hallucinated outputs, and value misalignment, and can be\nmaliciously used for generating toxic content and unethical purposes after been\njailbroken. Therefore, in this survey, we present a comprehensive review of\nrecent advancements aimed at mitigating these issues, organized across the four\nphases of LLM development and usage: data collecting and pre-training,\nfine-tuning and alignment, prompting and reasoning, and post-processing and\nauditing. We elaborate on the recent advances for enhancing the performance of\nLLMs in terms of privacy protection, hallucination reduction, value alignment,\ntoxicity elimination, and jailbreak defenses. In contrast to previous surveys\nthat focus on a single dimension of responsible LLMs, this survey presents a\nunified framework that encompasses these diverse dimensions, providing a\ncomprehensive view of enhancing LLMs to better serve real-world applications.",
      "tldr_zh": "这篇调查论文探讨了大型语言模型(LLMs)的责任问题，包括固有风险（如privacy leakage、hallucinated outputs和value misalignment）以及恶意使用（如生成toxic content和越狱攻击）。论文组织了LLMs开发和使用的四个阶段——数据收集和预训练、fine-tuning和alignment、prompting和reasoning、后处理和auditing——并回顾了相关缓解策略的最新进展，如privacy protection、hallucination reduction、value alignment、toxicity elimination和jailbreak defenses。相比以往专注于单一维度的调查，该研究提供了一个统一的框架，综合这些方面，以提升LLMs在真实应用中的可靠性和安全性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09431v1",
      "published_date": "2025-01-16 09:59:45 UTC",
      "updated_date": "2025-01-16 09:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:22:25.780918"
    },
    {
      "arxiv_id": "2501.09429v1",
      "title": "ADAGE: A generic two-layer framework for adaptive agent based modelling",
      "title_zh": "ADAGE：一个通用的双层框架，用于自适应代理建模",
      "authors": [
        "Benjamin Patrick Evans",
        "Sihan Zeng",
        "Sumitra Ganesh",
        "Leo Ardon"
      ],
      "abstract": "Agent-based models (ABMs) are valuable for modelling complex, potentially\nout-of-equilibria scenarios. However, ABMs have long suffered from the Lucas\ncritique, stating that agent behaviour should adapt to environmental changes.\nFurthermore, the environment itself often adapts to these behavioural changes,\ncreating a complex bi-level adaptation problem. Recent progress integrating\nmulti-agent reinforcement learning into ABMs introduces adaptive agent\nbehaviour, beginning to address the first part of this critique, however, the\napproaches are still relatively ad hoc, lacking a general formulation, and\nfurthermore, do not tackle the second aspect of simultaneously adapting\nenvironmental level characteristics in addition to the agent behaviours. In\nthis work, we develop a generic two-layer framework for ADaptive AGEnt based\nmodelling (ADAGE) for addressing these problems. This framework formalises the\nbi-level problem as a Stackelberg game with conditional behavioural policies,\nproviding a consolidated framework for adaptive agent-based modelling based on\nsolving a coupled set of non-linear equations. We demonstrate how this generic\napproach encapsulates several common (previously viewed as distinct) ABM tasks,\nsuch as policy design, calibration, scenario generation, and robust behavioural\nlearning under one unified framework. We provide example simulations on\nmultiple complex economic and financial environments, showing the strength of\nthe novel framework under these canonical settings, addressing long-standing\ncritiques of traditional ABMs.",
      "tldr_zh": "本研究针对Agent-based models (ABMs) 面临的Lucas critique问题，即代理行为需适应环境变化，而环境也可能随之调整，提出一个通用的双层框架ADAGE。ADAGE将这一双层适应问题形式化为Stackelberg game，使用条件行为策略并通过解决耦合的非线性方程来实现统一的建模框架。该框架整合了多代理强化学习，涵盖了政策设计、校准、场景生成和鲁棒行为学习等常见ABM任务。在经济和金融环境中进行的模拟实验证明，ADAGE框架显著提升了模型的适应性和有效性，解决了传统ABMs的长期批评。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "econ.GN",
        "q-fin.CP",
        "q-fin.EC"
      ],
      "primary_category": "cs.MA",
      "comment": "Accepted at the 2025 International Conference on Autonomous Agents\n  and Multiagent Systems (AAMAS)",
      "pdf_url": "http://arxiv.org/pdf/2501.09429v1",
      "published_date": "2025-01-16 09:58:24 UTC",
      "updated_date": "2025-01-16 09:58:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:22:36.728801"
    },
    {
      "arxiv_id": "2501.09420v1",
      "title": "Dynamic Neural Style Transfer for Artistic Image Generation using VGG19",
      "title_zh": "动态神经风格转移用于艺术图像生成，使用 VGG19",
      "authors": [
        "Kapil Kashyap",
        "Mehak Garg",
        "Sean Fargose",
        "Sindhu Nair"
      ],
      "abstract": "Throughout history, humans have created remarkable works of art, but\nartificial intelligence has only recently started to make strides in generating\nvisually compelling art. Breakthroughs in the past few years have focused on\nusing convolutional neural networks (CNNs) to separate and manipulate the\ncontent and style of images, applying texture synthesis techniques.\nNevertheless, a number of current techniques continue to encounter obstacles,\nincluding lengthy processing times, restricted choices of style images, and the\ninability to modify the weight ratio of styles. We proposed a neural style\ntransfer system that can add various artistic styles to a desired image to\naddress these constraints allowing flexible adjustments to style weight ratios\nand reducing processing time. The system uses the VGG19 model for feature\nextraction, ensuring high-quality, flexible stylization without compromising\ncontent integrity.",
      "tldr_zh": "本研究针对现有神经风格转移技术的问题，如处理时间长、风格图像选择有限以及无法灵活调整风格权重比例，提出了一种动态神经风格转移系统，用于艺术图像生成。系统利用 VGG19 模型进行特征提取，能够将各种艺术风格应用到目标图像，同时支持实时调整风格权重比例。实验结果显示，该方法显著减少了处理时间，同时保持了图像内容完整性，提高了生成艺术的视觉质量和灵活性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09420v1",
      "published_date": "2025-01-16 09:47:18 UTC",
      "updated_date": "2025-01-16 09:47:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:22:48.694245"
    },
    {
      "arxiv_id": "2501.09410v1",
      "title": "MoE$^2$: Optimizing Collaborative Inference for Edge Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lyudong Jin",
        "Yanning Zhang",
        "Yanhan Li",
        "Shurong Wang",
        "Howard H. Yang",
        "Jian Wu",
        "Meng Zhang"
      ],
      "abstract": "Large language models (LLMs) have demonstrated remarkable capabilities across\na wide range of natural language processing tasks. Exploiting the heterogeneous\ncapabilities of edge LLMs is crucial for diverse emerging applications, as it\nenables greater cost-effectiveness and reduced latency. In this work, we\nintroduce \\textit{Mixture-of-Edge-Experts (MoE$^2$)}, a novel collaborative\ninference framework for edge LLMs. We formulate the joint gating and expert\nselection problem to optimize inference performance under energy and latency\nconstraints. Unlike conventional MoE problems, LLM expert selection is\nsignificantly more challenging due to the combinatorial nature and the\nheterogeneity of edge LLMs across various attributes. To this end, we propose a\ntwo-level expert selection mechanism through which we uncover an\noptimality-preserving property of gating parameters across expert selections.\nThis property enables the decomposition of the training and selection\nprocesses, significantly reducing complexity. Furthermore, we leverage the\nobjective's monotonicity and design a discrete monotonic optimization algorithm\nfor optimal expert selection. We implement edge servers with NVIDIA Jetson AGX\nOrins and NVIDIA RTX 4090 GPUs, and perform extensive experiments. Our results\nvalidate that performance improvements of various LLM models and show that our\nMoE$^2$ method can achieve optimal trade-offs among different delay and energy\nbudgets, and outperforms baselines under various system resource constraints.",
      "tldr_zh": "本论文引入了Mixture-of-Edge-Experts (MoE²)，一个新型协作推理框架，旨在优化边缘大语言模型(LLMs)的性能，以实现更高的成本效益和更低的延迟。\nMoE² 通过制定联合门控和专家选择问题，并采用两级专家选择机制以及离散单调优化算法，解决了专家选择的组合性和异质性挑战，从而简化了训练和选择过程。\n实验在NVIDIA Jetson AGX Orins和NVIDIA RTX 4090 GPUs上进行，结果显示MoE²在各种延迟和能量预算下显著提升了LLMs的性能，并优于基线方法。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "Submitted to IEEE/ACM Transactions on Networking",
      "pdf_url": "http://arxiv.org/pdf/2501.09410v1",
      "published_date": "2025-01-16 09:36:32 UTC",
      "updated_date": "2025-01-16 09:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:23:01.771967"
    },
    {
      "arxiv_id": "2502.00022v1",
      "title": "A Dynamic and High-Precision Method for Scenario-Based HRA Synthetic Data Collection in Multi-Agent Collaborative Environments Driven by LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Xingyu Xiao",
        "Peng Chen",
        "Qianqian Jia",
        "Jiejuan Tong",
        "Jingang Liang",
        "Haitao Wang"
      ],
      "abstract": "HRA (Human Reliability Analysis) data is crucial for advancing HRA\nmethodologies. however, existing data collection methods lack the necessary\ngranularity, and most approaches fail to capture dynamic features.\nAdditionally, many methods require expert knowledge as input, making them\ntime-consuming and labor-intensive. To address these challenges, we propose a\nnew paradigm for the automated collection of HRA data. Our approach focuses on\nkey indicators behind human error, specifically measuring workload in\ncollaborative settings. This study introduces a novel, scenario-driven method\nfor workload estimation, leveraging fine-tuned large language models (LLMs). By\ntraining LLMs on real-world operational data from high-temperature gas-cooled\nreactors (HTGRs), we simulate human behavior and cognitive load in real time\nacross various collaborative scenarios. The method dynamically adapts to\nchanges in operator workload, providing more accurate, flexible, and scalable\nworkload estimates. The results demonstrate that the proposed WELLA (Workload\nEstimation with LLMs and Agents) outperforms existing commercial LLM-based\nmethods in terms of prediction accuracy.",
      "tldr_zh": "该论文针对HRA（Human Reliability Analysis）数据收集的不足，如缺乏粒度、无法捕捉动态特征以及依赖专家知识的问题，提出了一种动态高精度的场景驱动方法。方法利用微调的大型语言模型（LLMs）基于高温气冷反应堆（HTGRs）的真实数据，模拟人类行为和认知负载，并在多代理协作环境中实时估计工作负载。引入WELLA（Workload Estimation with LLMs and Agents）框架，该框架能动态适应变化，提供更准确且可扩展的估计，结果显示其预测准确性优于现有商业LLM方法。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.00022v1",
      "published_date": "2025-01-16 09:23:48 UTC",
      "updated_date": "2025-01-16 09:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:23:13.635704"
    },
    {
      "arxiv_id": "2501.09395v1",
      "title": "ELM-DeepONets: Backpropagation-Free Training of Deep Operator Networks via Extreme Learning Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Hwijae Son"
      ],
      "abstract": "Deep Operator Networks (DeepONets) are among the most prominent frameworks\nfor operator learning, grounded in the universal approximation theorem for\noperators. However, training DeepONets typically requires significant\ncomputational resources. To address this limitation, we propose ELM-DeepONets,\nan Extreme Learning Machine (ELM) framework for DeepONets that leverages the\nbackpropagation-free nature of ELM. By reformulating DeepONet training as a\nleast-squares problem for newly introduced parameters, the ELM-DeepONet\napproach significantly reduces training complexity. Validation on benchmark\nproblems, including nonlinear ODEs and PDEs, demonstrates that the proposed\nmethod not only achieves superior accuracy but also drastically reduces\ncomputational costs. This work offers a scalable and efficient alternative for\noperator learning in scientific computing.",
      "tldr_zh": "该研究提出ELM-DeepONets框架，利用Extreme Learning Machines (ELM)的backpropagation-free特性来训练Deep Operator Networks (DeepONets)，以解决传统训练所需的大量计算资源问题。通过将DeepONet训练重构为最小二乘问题，显著降低了训练复杂度。实验在非线性ODEs和PDEs等基准问题上验证，该方法不仅实现了更高的准确性，还大幅减少了计算成本，为科学计算中的操作符学习提供了可扩展、高效的替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09395v1",
      "published_date": "2025-01-16 09:06:43 UTC",
      "updated_date": "2025-01-16 09:06:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:23:24.896113"
    },
    {
      "arxiv_id": "2501.09394v1",
      "title": "Quantum-Enhanced Transformers for Robust Acoustic Scene Classification in IoT Environments",
      "title_zh": "量子增强Transformer",
      "authors": [
        "Minh K. Quan",
        "Mayuri Wijayasundara",
        "Sujeeva Setunge",
        "Pubudu N. Pathirana"
      ],
      "abstract": "The proliferation of Internet of Things (IoT) devices equipped with acoustic\nsensors necessitates robust acoustic scene classification (ASC) capabilities,\neven in noisy and data-limited environments. Traditional machine learning\nmethods often struggle to generalize effectively under such conditions. To\naddress this, we introduce Q-ASC, a novel Quantum-Inspired Acoustic Scene\nClassifier that leverages the power of quantum-inspired transformers. By\nintegrating quantum concepts like superposition and entanglement, Q-ASC\nachieves superior feature learning and enhanced noise resilience compared to\nclassical models. Furthermore, we introduce a Quantum Variational Autoencoder\n(QVAE) based data augmentation technique to mitigate the challenge of limited\nlabeled data in IoT deployments. Extensive evaluations on the Tampere\nUniversity of Technology (TUT) Acoustic Scenes 2016 benchmark dataset\ndemonstrate that Q-ASC achieves remarkable accuracy between 68.3% and 88.5%\nunder challenging conditions, outperforming state-of-the-art methods by over 5%\nin the best case. This research paves the way for deploying intelligent\nacoustic sensing in IoT networks, with potential applications in smart homes,\nindustrial monitoring, and environmental surveillance, even in adverse acoustic\nenvironments.",
      "tldr_zh": "该论文针对IoT环境中嘈杂和数据有限条件下声学场景分类（Acoustic Scene Classification, ASC）的挑战，提出了一种新型量子灵感分类器Q-ASC，利用量子概念如superposition和entanglement增强Transformer模型的特征学习和噪声抵抗力。论文还引入了Quantum Variational Autoencoder (QVAE)基于数据增强技术，以缓解标签数据不足的问题。实验结果显示，在TUT Acoustic Scenes 2016基准数据集上，Q-ASC在挑战条件下实现了68.3%至88.5%的准确率，比现有方法高出超过5%。这项研究为IoT网络中的智能声学感知铺平道路，适用于智能家居、工业监测和环境监控等领域。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.LG",
        "cs.PF",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09394v1",
      "published_date": "2025-01-16 09:06:10 UTC",
      "updated_date": "2025-01-16 09:06:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:23:38.872945"
    },
    {
      "arxiv_id": "2501.09368v3",
      "title": "Aligning Instruction Tuning with Pre-training",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Liang",
        "Tianyu Zheng",
        "Xinrun Du",
        "Ge Zhang",
        "Jiaheng Liu",
        "Xingwei Qu",
        "Wenqiang Zu",
        "Xingrun Xing",
        "Chujie Zheng",
        "Lei Ma",
        "Wenhu Chen",
        "Guoyin Wang",
        "Zhaoxiang Zhang",
        "Wenhao Huang",
        "Xiang Yue",
        "Jiajun Zhang"
      ],
      "abstract": "Instruction tuning enhances large language models (LLMs) to follow human\ninstructions across diverse tasks, relying on high-quality datasets to guide\nbehavior. However, these datasets, whether manually curated or synthetically\ngenerated, are often narrowly focused and misaligned with the broad\ndistributions captured during pre-training, limiting LLM generalization and\neffective use of pre-trained knowledge. We propose Aligning Instruction Tuning\nwith Pre-training (AITP), a method that bridges this gap by identifying\ncoverage shortfalls in instruction-tuning datasets and rewriting\nunderrepresented pre-training data into high-quality instruction-response\npairs. This approach enriches dataset diversity while preserving task-specific\nobjectives. Evaluations on three fully open LLMs across eight benchmarks\ndemonstrate consistent performance improvements with AITP. Ablations highlight\nthe benefits of adaptive data selection, controlled rewriting, and balanced\nintegration, emphasizing the importance of aligning instruction tuning with\npre-training distributions to unlock the full potential of LLMs.",
      "tldr_zh": "本研究针对指令微调（Instruction Tuning）中数据集狭隘问题提出 Aligning Instruction Tuning with Pre-training (AITP) 方法，以桥接指令调优与预训练（Pre-training）分布的差距。AITP 通过识别指令调优数据集中的覆盖不足，并将 underrepresented 的预训练数据改写为高质量的指令-响应对，从而丰富数据集多样性，同时保持任务特定目标。实验在三个开源大型语言模型（LLMs）上评估八个基准测试，结果显示性能一致提升；消融实验进一步证明了自适应数据选择、控制改写和平衡集成的关键作用，强调了这种对齐策略在释放 LLMs 潜力的重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:hep-ph/9811436 by other\n  authors",
      "pdf_url": "http://arxiv.org/pdf/2501.09368v3",
      "published_date": "2025-01-16 08:27:40 UTC",
      "updated_date": "2025-01-20 14:05:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:23:48.706733"
    },
    {
      "arxiv_id": "2501.09355v1",
      "title": "YETI (YET to Intervene) Proactive Interventions by Multimodal AI Agents in Augmented Reality Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Saptarashmi Bandyopadhyay",
        "Vikas Bahirwani",
        "Lavisha Aggarwal",
        "Bhanu Guda",
        "Lin Li",
        "Andrea Colaco"
      ],
      "abstract": "Multimodal AI Agents are AI models that have the capability of interactively\nand cooperatively assisting human users to solve day-to-day tasks. Augmented\nReality (AR) head worn devices can uniquely improve the user experience of\nsolving procedural day-to-day tasks by providing egocentric multimodal (audio\nand video) observational capabilities to AI Agents. Such AR capabilities can\nhelp AI Agents see and listen to actions that users take which can relate to\nmultimodal capabilities of human users. Existing AI Agents, either Large\nLanguage Models (LLMs) or Multimodal Vision-Language Models (VLMs) are reactive\nin nature, which means that models cannot take an action without reading or\nlistening to the human user's prompts. Proactivity of AI Agents on the other\nhand can help the human user detect and correct any mistakes in agent observed\ntasks, encourage users when they do tasks correctly or simply engage in\nconversation with the user - akin to a human teaching or assisting a user. Our\nproposed YET to Intervene (YETI) multimodal agent focuses on the research\nquestion of identifying circumstances that may require the agent to intervene\nproactively. This allows the agent to understand when it can intervene in a\nconversation with human users that can help the user correct mistakes on tasks,\nlike cooking, using AR. Our YETI Agent learns scene understanding signals based\non interpretable notions of Structural Similarity (SSIM) on consecutive video\nframes. We also define the alignment signal which the AI Agent can learn to\nidentify if the video frames corresponding to the user's actions on the task\nare consistent with expected actions. These signals are used by our AI Agent to\ndetermine when it should proactively intervene. We compare our results on the\ninstances of proactive intervention in the HoloAssist multimodal benchmark for\nan expert agent guiding a user to complete procedural tasks.",
      "tldr_zh": "该论文提出YETI（YET to Intervene）系统，这是一个多模态AI代理，用于在Augmented Reality (AR)任务中实现主动干预，帮助用户检测错误、提供鼓励或参与对话。YETI代理通过Structural Similarity (SSIM)分析连续视频帧的场景理解信号，并定义alignment signal来检查用户动作是否符合预期，从而决定干预时机。与传统的反应式Large Language Models (LLMs)或Multimodal Vision-Language Models (VLMs)不同，该系统在HoloAssist多模态基准上评估显示出显著的主动干预效果，提升了用户任务体验。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.ET",
        "cs.MA",
        "I.2; I.2.10; I.2.11; I.2.1; I.2.7; I.4.8; I.4.9"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2501.09355v1",
      "published_date": "2025-01-16 08:06:02 UTC",
      "updated_date": "2025-01-16 08:06:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:24:01.837276"
    },
    {
      "arxiv_id": "2501.09354v1",
      "title": "Style4Rec: Enhancing Transformer-based E-commerce Recommendation Systems with Style and Shopping Cart Information",
      "title_zh": "Style4Rec：利用风格和购物车信息增强基于 Transformer 的电子商务推荐系统",
      "authors": [
        "Berke Ugurlu",
        "Ming-Yi Hong",
        "Che Lin"
      ],
      "abstract": "Understanding users' product preferences is essential to the efficacy of a\nrecommendation system. Precision marketing leverages users' historical data to\ndiscern these preferences and recommends products that align with them.\nHowever, recent browsing and purchase records might better reflect current\npurchasing inclinations. Transformer-based recommendation systems have made\nstrides in sequential recommendation tasks, but they often fall short in\nutilizing product image style information and shopping cart data effectively.\nIn light of this, we propose Style4Rec, a transformer-based e-commerce\nrecommendation system that harnesses style and shopping cart information to\nenhance existing transformer-based sequential product recommendation systems.\nStyle4Rec represents a significant step forward in personalized e-commerce\nrecommendations, outperforming benchmarks across various evaluation metrics.\nStyle4Rec resulted in notable improvements: HR@5 increased from 0.681 to 0.735,\nNDCG@5 increased from 0.594 to 0.674, and MRR@5 increased from 0.559 to 0.654.\nWe tested our model using an e-commerce dataset from our partnering company and\nfound that it exceeded established transformer-based sequential recommendation\nbenchmarks across various evaluation metrics. Thus, Style4Rec presents a\nsignificant step forward in personalized e-commerce recommendation systems.",
      "tldr_zh": "该研究提出Style4Rec，一种基于Transformer的电商推荐系统，通过整合产品图像风格信息和购物车数据，改善了对用户当前偏好的捕捉。相比传统Transformer-based系统，Style4Rec在序列推荐任务中更有效地利用这些额外信息。实验结果显示，在电商数据集上，Style4Rec显著提升了性能：HR@5从0.681增加到0.735，NDCG@5从0.594增加到0.674，MRR@5从0.559增加到0.654，从而为个性化电商推荐提供了重要进展。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "9 pages, 6 images, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.09354v1",
      "published_date": "2025-01-16 08:05:39 UTC",
      "updated_date": "2025-01-16 08:05:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:24:13.082971"
    },
    {
      "arxiv_id": "2501.09345v3",
      "title": "Rational Tuning of LLM Cascades via Probabilistic Modeling",
      "title_zh": "通过概率建模的 LLM 级联理性调优",
      "authors": [
        "Michael J. Zellinger",
        "Matt Thomson"
      ],
      "abstract": "Understanding the reliability of large language models (LLMs) has recently\ngarnered significant attention. Given LLMs' propensity to hallucinate, as well\nas their high sensitivity to prompt design, it is already challenging to\npredict the performance of an individual LLM. However, the problem becomes more\ncomplex for compound LLM systems such as cascades, where in addition to each\nmodel's standalone performance, we must understand how the error rates of\ndifferent models interact. In this paper, we present a probabilistic model for\nthe joint performance distribution of a sequence of LLMs, which enables a\nframework for rationally tuning the confidence thresholds of a LLM cascade\nusing continuous optimization. Compared to selecting confidence thresholds\nusing grid search, our parametric Markov-copula model significantly improves\nruntime scaling with respect to the length of the cascade and the desired\nresolution of the cost-error curve, turning them from intractable into\nlow-order polynomial. In addition, the optimal thresholds computed using our\ncontinuous optimization-based algorithm increasingly outperform those found via\ngrid search as cascade length grows, improving the area under the cost-error\ncurve by 1.9% on average for cascades consisting of at least three models.\nOverall, our Markov-copula model provides a rational basis for tuning LLM\ncascade performance and points to the potential of probabilistic methods in\nanalyzing LLM systems.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）的可靠性问题，提出了一种基于概率建模的方法来优化LLM级联系统（cascades）。论文引入parametric Markov-copula模型，以描述序列LLMs的联合性能分布，并通过连续优化框架合理调整置信度阈值（confidence thresholds），从而避免了传统网格搜索（grid search）的低效。实验结果显示，该方法显著改善了运行时间扩展性，并在大长度级联中提升了成本-错误曲线下的面积（area under the cost-error curve），平均提高1.9%。总体上，该模型为LLM系统的理性调优提供了坚实基础，并突显了概率方法在分析LLM系统中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09345v3",
      "published_date": "2025-01-16 07:58:33 UTC",
      "updated_date": "2025-03-05 19:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:24:25.336974"
    },
    {
      "arxiv_id": "2501.09333v2",
      "title": "Prompt-CAM: Making Vision Transformers Interpretable for Fine-Grained Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Arpita Chowdhury",
        "Dipanjyoti Paul",
        "Zheda Mai",
        "Jianyang Gu",
        "Ziheng Zhang",
        "Kazi Sajeed Mehrab",
        "Elizabeth G. Campolongo",
        "Daniel Rubenstein",
        "Charles V. Stewart",
        "Anuj Karpatne",
        "Tanya Berger-Wolf",
        "Yu Su",
        "Wei-Lun Chao"
      ],
      "abstract": "We present a simple approach to make pre-trained Vision Transformers (ViTs)\ninterpretable for fine-grained analysis, aiming to identify and localize the\ntraits that distinguish visually similar categories, such as bird species.\nPre-trained ViTs, such as DINO, have demonstrated remarkable capabilities in\nextracting localized, discriminative features. However, saliency maps like\nGrad-CAM often fail to identify these traits, producing blurred, coarse\nheatmaps that highlight entire objects instead. We propose a novel approach,\nPrompt Class Attention Map (Prompt-CAM), to address this limitation. Prompt-CAM\nlearns class-specific prompts for a pre-trained ViT and uses the corresponding\noutputs for classification. To correctly classify an image, the true-class\nprompt must attend to unique image patches not present in other classes' images\n(i.e., traits). As a result, the true class's multi-head attention maps reveal\ntraits and their locations. Implementation-wise, Prompt-CAM is almost a ``free\nlunch,'' requiring only a modification to the prediction head of Visual Prompt\nTuning (VPT). This makes Prompt-CAM easy to train and apply, in stark contrast\nto other interpretable methods that require designing specific models and\ntraining processes. Extensive empirical studies on a dozen datasets from\nvarious domains (e.g., birds, fishes, insects, fungi, flowers, food, and cars)\nvalidate the superior interpretation capability of Prompt-CAM. The source code\nand demo are available at https://github.com/Imageomics/Prompt_CAM.",
      "tldr_zh": "本研究提出 Prompt-CAM，一种简单方法，使预训练的 Vision Transformers (ViTs) 在细粒度分析中更具可解释性，旨在识别和定位视觉相似类别（如鸟类物种）的独特特征。Prompt-CAM 通过学习类别特定的提示，并利用多头注意力地图（multi-head attention maps）来关注图像中独有的补丁，从而生成精确的热力图，解决传统方法如 Grad-CAM 产生的模糊热图问题。该方法只需修改 Visual Prompt Tuning (VPT) 的预测头，训练和应用极为便捷，并在十多个数据集（如鸟类、鱼类等）上验证了其 superior interpretation capability。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by CVPR 2025 Main Conference",
      "pdf_url": "http://arxiv.org/pdf/2501.09333v2",
      "published_date": "2025-01-16 07:07:41 UTC",
      "updated_date": "2025-04-07 18:03:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:24:38.836106"
    },
    {
      "arxiv_id": "2501.09328v2",
      "title": "Neural Honeytrace: A Robust Plug-and-Play Watermarking Framework against Model Extraction Attacks",
      "title_zh": "翻译失败",
      "authors": [
        "Yixiao Xu",
        "Binxing Fang",
        "Rui Wang",
        "Yinghai Zhou",
        "Shouling Ji",
        "Yuan Liu",
        "Mohan Li",
        "Zhihong Tian"
      ],
      "abstract": "Developing high-performance deep learning models is resource-intensive,\nleading model owners to utilize Machine Learning as a Service (MLaaS) platforms\ninstead of publicly releasing their models. However, malicious users may\nexploit query interfaces to execute model extraction attacks, reconstructing\nthe target model's functionality locally. While prior research has investigated\ntriggerable watermarking techniques for asserting ownership, existing methods\nface significant challenges: (1) most approaches require additional training,\nresulting in high overhead and limited flexibility, and (2) they often fail to\naccount for advanced attackers, leaving them vulnerable to adaptive attacks.\n  In this paper, we propose Neural Honeytrace, a robust plug-and-play\nwatermarking framework against model extraction attacks. We first formulate a\nwatermark transmission model from an information-theoretic perspective,\nproviding an interpretable account of the principles and limitations of\nexisting triggerable watermarking. Guided by the model, we further introduce:\n(1) a similarity-based training-free watermarking method for plug-and-play and\nflexible watermarking, and (2) a distribution-based multi-step watermark\ninformation transmission strategy for robust watermarking. Comprehensive\nexperiments on four datasets demonstrate that Neural Honeytrace outperforms\nprevious methods in efficiency and resisting adaptive attacks. Neural\nHoneytrace reduces the average number of samples required for a worst-case\nt-Test-based copyright claim from $12,000$ to $200$ with zero training cost.",
      "tldr_zh": "该研究提出Neural Honeytrace，一种鲁棒的plug-and-play水印框架，用于对抗模型提取attacks。框架从信息论视角制定水mark传输模型，引入基于相似度的无训练水印方法和基于分布的多步水印信息传输策略，从而实现高效且灵活的模型保护。实验在四个数据集上显示，Neural Honeytrace在抵抗自适应attacks方面优于现有方法，将worst-case t-Test-based版权声明所需的样本数从12,000减少到200，且无需额外训练。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09328v2",
      "published_date": "2025-01-16 06:59:20 UTC",
      "updated_date": "2025-01-17 06:50:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:24:48.958776"
    },
    {
      "arxiv_id": "2501.09327v2",
      "title": "On Learning Informative Trajectory Embeddings for Imitation, Classification and Regression",
      "title_zh": "翻译失败",
      "authors": [
        "Zichang Ge",
        "Changyu Chen",
        "Arunesh Sinha",
        "Pradeep Varakantham"
      ],
      "abstract": "In real-world sequential decision making tasks like autonomous driving,\nrobotics, and healthcare, learning from observed state-action trajectories is\ncritical for tasks like imitation, classification, and clustering. For example,\nself-driving cars must replicate human driving behaviors, while robots and\nhealthcare systems benefit from modeling decision sequences, whether or not\nthey come from expert data. Existing trajectory encoding methods often focus on\nspecific tasks or rely on reward signals, limiting their ability to generalize\nacross domains and tasks. Inspired by the success of embedding models like CLIP\nand BERT in static domains, we propose a novel method for embedding\nstate-action trajectories into a latent space that captures the skills and\ncompetencies in the dynamic underlying decision-making processes. This method\noperates without the need for reward labels, enabling better generalization\nacross diverse domains and tasks. Our contributions are threefold: (1) We\nintroduce a trajectory embedding approach that captures multiple abilities from\nstate-action data. (2) The learned embeddings exhibit strong representational\npower across downstream tasks, including imitation, classification, clustering,\nand regression. (3) The embeddings demonstrate unique properties, such as\ncontrolling agent behaviors in IQ-Learn and an additive structure in the latent\nspace. Experimental results confirm that our method outperforms traditional\napproaches, offering more flexible and powerful trajectory representations for\nvarious applications. Our code is available at\nhttps://github.com/Erasmo1015/vte.",
      "tldr_zh": "本论文提出了一种新型轨迹嵌入方法，用于从状态-动作轨迹中学习信息丰富的表示，支持模仿、分类和回归等任务。该方法受 CLIP 和 BERT 启发，将轨迹嵌入潜在空间以捕捉动态决策过程中的技能和能力，而无需依赖奖励信号，从而提升了跨领域泛化性。主要贡献包括：引入一种能从状态-动作数据中提取多重能力的嵌入框架；嵌入在下游任务如模仿、分类、聚类和回归中表现出强表示力，并展示独特属性如在 IQ-Learn 中控制代理行为和潜在空间的加法结构；实验结果表明，该方法优于传统方法，为实际应用如自动驾驶和机器人提供了更灵活的轨迹表示。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.09327v2",
      "published_date": "2025-01-16 06:52:58 UTC",
      "updated_date": "2025-01-17 18:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:25:02.145056"
    },
    {
      "arxiv_id": "2501.09316v1",
      "title": "SOP-Agent: Empower General Purpose AI Agent with Domain-Specific SOPs",
      "title_zh": "翻译失败",
      "authors": [
        "Anbang Ye",
        "Qianran Ma",
        "Jia Chen",
        "Muqi Li",
        "Tong Li",
        "Fujiao Liu",
        "Siqi Mai",
        "Meichen Lu",
        "Haitao Bao",
        "Yang You"
      ],
      "abstract": "Despite significant advancements in general-purpose AI agents, several\nchallenges still hinder their practical application in real-world scenarios.\nFirst, the limited planning capabilities of Large Language Models (LLM)\nrestrict AI agents from effectively solving complex tasks that require\nlong-horizon planning. Second, general-purpose AI agents struggle to\nefficiently utilize domain-specific knowledge and human expertise. In this\npaper, we introduce the Standard Operational Procedure-guided Agent\n(SOP-agent), a novel framework for constructing domain-specific agents through\npseudocode-style Standard Operational Procedures (SOPs) written in natural\nlanguage. Formally, we represent a SOP as a decision graph, which is traversed\nto guide the agent in completing tasks specified by the SOP. We conduct\nextensive experiments across tasks in multiple domains, including\ndecision-making, search and reasoning, code generation, data cleaning, and\ngrounded customer service. The SOP-agent demonstrates excellent versatility,\nachieving performance superior to general-purpose agent frameworks and\ncomparable to domain-specific agent systems. Additionally, we introduce the\nGrounded Customer Service Benchmark, the first benchmark designed to evaluate\nthe grounded decision-making capabilities of AI agents in customer service\nscenarios based on SOPs.",
      "tldr_zh": "这篇论文针对通用 AI 代理在复杂任务规划和领域知识利用方面的挑战，提出了 SOP-agent 框架，该框架使用自然语言的伪代码式 Standard Operational Procedures (SOPs) 表示为 decision graph，以指导代理高效完成任务。实验涵盖决策、搜索和推理、代码生成、数据清理以及客户服务等领域，结果显示 SOP-agent 的性能优于通用代理框架，并与领域特定系统相当。此外，论文引入了 Grounded Customer Service Benchmark，这是首个基于 SOPs 的基准，用于评估 AI 代理在客户服务场景中的决策能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "35 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.09316v1",
      "published_date": "2025-01-16 06:14:58 UTC",
      "updated_date": "2025-01-16 06:14:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:25:13.388931"
    },
    {
      "arxiv_id": "2501.09311v1",
      "title": "Shape-Based Single Object Classification Using Ensemble Method Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Nur Shazwani Kamarudin",
        "Mokhairi Makhtar",
        "Syadiah Nor Wan Shamsuddin",
        "Syed Abdullah Fadzli"
      ],
      "abstract": "Nowadays, more and more images are available. Annotation and retrieval of the\nimages pose classification problems, where each class is defined as the group\nof database images labelled with a common semantic label. Various systems have\nbeen proposed for content-based retrieval, as well as for image classification\nand indexing. In this paper, a hierarchical classification framework has been\nproposed for bridging the semantic gap effectively and achieving multi-category\nimage classification. A well known pre-processing and post-processing method\nwas used and applied to three problems; image segmentation, object\nidentification and image classification. The method was applied to classify\nsingle object images from Amazon and Google datasets. The classification was\ntested for four different classifiers; BayesNetwork (BN), Random Forest (RF),\nBagging and Vote. The estimated classification accuracies ranged from 20% to\n99% (using 10-fold cross validation). The Bagging classifier presents the best\nperformance, followed by the Random Forest classifier.",
      "tldr_zh": "该论文提出一个基于形状的分层分类框架，用于桥接语义鸿沟并实现单对象图像的多类别分类，方法包括图像分割、对象识别和图像分类的预处理与后处理。研究在 Amazon 和 Google 数据集上测试了四种分类器：BayesNetwork (BN)、Random Forest (RF)、Bagging 和 Vote。实验结果显示，Bagging 分类器表现最佳，准确率最高可达 99%，整体准确率范围为 20% 到 99%（使用 10-fold cross validation）。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09311v1",
      "published_date": "2025-01-16 05:58:32 UTC",
      "updated_date": "2025-01-16 05:58:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:25:25.181933"
    },
    {
      "arxiv_id": "2501.09310v1",
      "title": "A Study of In-Context-Learning-Based Text-to-SQL Errors",
      "title_zh": "翻译失败",
      "authors": [
        "Jiawei Shen",
        "Chengcheng Wan",
        "Ruoyi Qiao",
        "Jiazhen Zou",
        "Hang Xu",
        "Yuchen Shao",
        "Yueling Zhang",
        "Weikai Miao",
        "Geguang Pu"
      ],
      "abstract": "Large language models (LLMs) have been adopted to perform text-to-SQL tasks,\nutilizing their in-context learning (ICL) capability to translate natural\nlanguage questions into structured query language (SQL). However, such a\ntechnique faces correctness problems and requires efficient repairing\nsolutions. In this paper, we conduct the first comprehensive study of\ntext-to-SQL errors. Our study covers four representative ICL-based techniques,\nfive basic repairing methods, two benchmarks, and two LLM settings. We find\nthat text-to-SQL errors are widespread and summarize 29 error types of 7\ncategories. We also find that existing repairing attempts have limited\ncorrectness improvement at the cost of high computational overhead with many\nmis-repairs. Based on the findings, we propose MapleRepair, a novel text-to-SQL\nerror detection and repairing framework. The evaluation demonstrates that\nMapleRepair outperforms existing solutions by repairing 13.8% more queries with\nneglectable mis-repairs and 67.4% less overhead.",
      "tldr_zh": "本研究对基于 In-Context Learning (ICL) 的 Text-to-SQL 任务中大型语言模型 (LLMs) 的错误进行了首次全面分析，涵盖四种代表性 ICL 技术、五种基本修复方法、两个基准和两个 LLM 设置。研究发现这些错误广泛存在，并总结了29种错误类型，分为7类，同时指出现有修复方法的效果有限，伴随高计算开销和大量误修复。基于这些发现，作者提出了一种新型框架MapleRepair，用于检测和修复Text-to-SQL错误，并在评估中表现出色，修复了13.8%更多的查询，几乎无误修复，并减少了67.4%的开销。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09310v1",
      "published_date": "2025-01-16 05:54:59 UTC",
      "updated_date": "2025-01-16 05:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:25:37.903774"
    },
    {
      "arxiv_id": "2501.09309v1",
      "title": "Understanding Mental Health Content on Social Media and Its Effect Towards Suicidal Ideation",
      "title_zh": "理解社交媒体上的心理健康内容及其对自杀意念的影响",
      "authors": [
        "Mohaiminul Islam Bhuiyan",
        "Nur Shazwani Kamarudin",
        "Nur Hafieza Ismail"
      ],
      "abstract": "This review underscores the critical need for effective strategies to\nidentify and support individuals with suicidal ideation, exploiting\ntechnological innovations in ML and DL to further suicide prevention efforts.\nThe study details the application of these technologies in analyzing vast\namounts of unstructured social media data to detect linguistic patterns,\nkeywords, phrases, tones, and contextual cues associated with suicidal\nthoughts. It explores various ML and DL models like SVMs, CNNs, LSTM, neural\nnetworks, and their effectiveness in interpreting complex data patterns and\nemotional nuances within text data. The review discusses the potential of these\ntechnologies to serve as a life-saving tool by identifying at-risk individuals\nthrough their digital traces. Furthermore, it evaluates the real-world\neffectiveness, limitations, and ethical considerations of employing these\ntechnologies for suicide prevention, stressing the importance of responsible\ndevelopment and usage. The study aims to fill critical knowledge gaps by\nanalyzing recent studies, methodologies, tools, and techniques in this field.\nIt highlights the importance of synthesizing current literature to inform\npractical tools and suicide prevention efforts, guiding innovation in reliable,\nethical systems for early intervention. This research synthesis evaluates the\nintersection of technology and mental health, advocating for the ethical and\nresponsible application of ML, DL, and NLP to offer life-saving potential\nworldwide while addressing challenges like generalizability, biases, privacy,\nand the need for further research to ensure these technologies do not\nexacerbate existing inequities and harms.",
      "tldr_zh": "本综述探讨了社交媒体上心理健康内容的分析及其对自杀意念的影响，强调利用机器学习(ML)和深度学习(DL)技术来识别和支持高风险个体。研究详细说明了这些技术在处理海量非结构化社交媒体数据时，通过检测语言模式、关键词、语气和上下文线索（如使用SVMs、CNNs、LSTM和神经网络）来识别自杀相关信号，从而作为预防工具。论文评估了这些方法的实际效果、局限性（如泛化性问题、偏见和隐私风险）以及伦理考虑，呼吁负责任的应用以填补知识空白，并指导可靠的早期干预系统的发展。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09309v1",
      "published_date": "2025-01-16 05:46:27 UTC",
      "updated_date": "2025-01-16 05:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:25:48.995113"
    },
    {
      "arxiv_id": "2501.09292v3",
      "title": "To Retrieve or Not to Retrieve? Uncertainty Detection for Dynamic Retrieval Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaustubh D. Dhole"
      ],
      "abstract": "Retrieval-Augmented Generation equips large language models with the\ncapability to retrieve external knowledge, thereby mitigating hallucinations by\nincorporating information beyond the model's intrinsic abilities. However, most\nprior works have focused on invoking retrieval deterministically, which makes\nit unsuitable for tasks such as long-form question answering. Instead,\ndynamically performing retrieval by invoking it only when the underlying LLM\nlacks the required knowledge can be more efficient. In this context, we delve\ndeeper into the question, \"To Retrieve or Not to Retrieve?\" by exploring\nmultiple uncertainty detection methods. We evaluate these methods for the task\nof long-form question answering, employing dynamic retrieval, and present our\ncomparisons. Our findings suggest that uncertainty detection metrics, such as\nDegree Matrix Jaccard and Eccentricity, can reduce the number of retrieval\ncalls by almost half, with only a slight reduction in question-answering\naccuracy.",
      "tldr_zh": "这篇论文探讨了在 Retrieval-Augmented Generation (RAG) 中使用不确定性检测方法来动态决定是否进行检索，从而提高大型语言模型 (LLMs) 的效率并减少幻觉。作者评估了多种不确定性检测指标，如 Degree Matrix Jaccard 和 Eccentricity，应用于长形式问答任务中。结果表明，这些方法可以将检索调用减少近一半，同时仅略微降低问答准确性，为更智能的知识增强生成提供了实用策略。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "I.2.7; H.3.3; I.5.5"
      ],
      "primary_category": "cs.CL",
      "comment": "1st workshop of \"Quantify Uncertainty and Hallucination in Foundation\n  Models: The Next Frontier in Reliable AI\" at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.09292v3",
      "published_date": "2025-01-16 04:56:33 UTC",
      "updated_date": "2025-03-18 16:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:26:01.428737"
    },
    {
      "arxiv_id": "2501.09291v2",
      "title": "LAVCap: LLM-based Audio-Visual Captioning using Optimal Transport",
      "title_zh": "翻译失败",
      "authors": [
        "Kyeongha Rho",
        "Hyeongkeun Lee",
        "Valentio Iverson",
        "Joon Son Chung"
      ],
      "abstract": "Automated audio captioning is a task that generates textual descriptions for\naudio content, and recent studies have explored using visual information to\nenhance captioning quality. However, current methods often fail to effectively\nfuse audio and visual data, missing important semantic cues from each modality.\nTo address this, we introduce LAVCap, a large language model (LLM)-based\naudio-visual captioning framework that effectively integrates visual\ninformation with audio to improve audio captioning performance. LAVCap employs\nan optimal transport-based alignment loss to bridge the modality gap between\naudio and visual features, enabling more effective semantic extraction.\nAdditionally, we propose an optimal transport attention module that enhances\naudio-visual fusion using an optimal transport assignment map. Combined with\nthe optimal training strategy, experimental results demonstrate that each\ncomponent of our framework is effective. LAVCap outperforms existing\nstate-of-the-art methods on the AudioCaps dataset, without relying on large\ndatasets or post-processing. Code is available at\nhttps://github.com/NAVER-INTEL-Co-Lab/gaudi-lavcap.",
      "tldr_zh": "这篇论文提出了 LAVCap，一种基于 LLM（Large Language Model）的音频-视觉字幕框架，旨在通过有效融合音频和视觉信息来提升音频内容的文本描述质量。框架采用 Optimal Transport-based alignment loss 来桥接音频和视觉模态间的语义差距，并引入 Optimal Transport attention module 增强融合效果，同时结合最优训练策略。实验结果显示，LAVCap 在 AudioCaps 数据集上优于现有最先进方法，且无需依赖大型数据集或后处理。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.MM",
      "comment": "5 pages, 2 figures; Accepted to ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.09291v2",
      "published_date": "2025-01-16 04:53:29 UTC",
      "updated_date": "2025-03-15 12:38:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:26:12.982721"
    },
    {
      "arxiv_id": "2501.09284v2",
      "title": "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Giyeong Oh",
        "Saejin Kim",
        "Woohyun Cho",
        "Sangkyu Lee",
        "Jiwan Chung",
        "Dokyung Song",
        "Youngjae Yu"
      ],
      "abstract": "Recently, LoRA and its variants have become the de facto strategy for\ntraining and sharing task-specific versions of large pretrained models, thanks\nto their efficiency and simplicity. However, the issue of copyright protection\nfor LoRA weights, especially through watermark-based techniques, remains\nunderexplored. To address this gap, we propose SEAL (SEcure wAtermarking on\nLoRA weights), the universal whitebox watermarking for LoRA. SEAL embeds a\nsecret, non-trainable matrix between trainable LoRA weights, serving as a\npassport to claim ownership. SEAL then entangles the passport with the LoRA\nweights through training, without extra loss for entanglement, and distributes\nthe finetuned weights after hiding the passport. When applying SEAL, we\nobserved no performance degradation across commonsense reasoning,\ntextual/visual instruction tuning, and text-to-image synthesis tasks. We\ndemonstrate that SEAL is robust against a variety of known attacks: removal,\nobfuscation, and ambiguity attacks.",
      "tldr_zh": "该研究提出SEAL，一种针对Low-Rank Adaptation (LoRA)权重的通用白-box水marks方法，以解决LoRA模型版权保护问题。SEAL通过在可训练LoRA权重之间嵌入一个秘密的、非可训练矩阵（作为“护照”），并通过训练过程使矩阵与权重纠缠，而无需额外损失函数，从而实现隐蔽水印。实验结果显示，SEAL在常识推理、文本/视觉指令调整和文本到图像合成任务中无性能下降，并对移除、混淆和歧义攻击表现出强鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "Author name corrected",
      "pdf_url": "http://arxiv.org/pdf/2501.09284v2",
      "published_date": "2025-01-16 04:17:56 UTC",
      "updated_date": "2025-01-17 04:59:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:26:25.265131"
    },
    {
      "arxiv_id": "2501.09279v1",
      "title": "Text Semantics to Flexible Design: A Residential Layout Generation Method Based on Stable Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zijin Qiu",
        "Jiepeng Liu",
        "Yi Xia",
        "Hongtuo Qi",
        "Pengkun Liu"
      ],
      "abstract": "Flexibility in the AI-based residential layout design remains a significant\nchallenge, as traditional methods like rule-based heuristics and graph-based\ngeneration often lack flexibility and require substantial design knowledge from\nusers. To address these limitations, we propose a cross-modal design approach\nbased on the Stable Diffusion model for generating flexible residential\nlayouts. The method offers multiple input types for learning objectives,\nallowing users to specify both boundaries and layouts. It incorporates natural\nlanguage as design constraints and introduces ControlNet to enable stable\nlayout generation through two distinct pathways. We also present a scheme that\nencapsulates design expertise within a knowledge graph and translates it into\nnatural language, providing an interpretable representation of design\nknowledge. This comprehensibility and diversity of input options enable\nprofessionals and non-professionals to directly express design requirements,\nenhancing flexibility and controllability. Finally, experiments verify the\nflexibility of the proposed methods under multimodal constraints better than\nstate-of-the-art models, even when specific semantic information about room\nareas or connections is incomplete.",
      "tldr_zh": "该论文提出了一种基于 Stable Diffusion 模型的跨模态设计方法，用于生成灵活的住宅布局，以克服传统 rule-based heuristics 和 graph-based generation 的局限性。该方法支持多种输入类型（如边界和布局），利用自然语言作为设计约束，并引入 ControlNet 通过两个路径实现稳定的布局生成，同时通过 knowledge graph 封装设计知识并转化为可解释的自然语言表达。实验结果表明，该方法在多模态约束下比现有最先进模型更具灵活性，即使缺少房间面积或连接等特定语义信息。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09279v1",
      "published_date": "2025-01-16 03:57:38 UTC",
      "updated_date": "2025-01-16 03:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:26:37.902827"
    },
    {
      "arxiv_id": "2501.09274v2",
      "title": "Large Language Model is Secretly a Protein Sequence Optimizer",
      "title_zh": "翻译失败",
      "authors": [
        "Yinkai Wang",
        "Jiaxing He",
        "Yuanqi Du",
        "Xiaohui Chen",
        "Jianan Canal Li",
        "Li-Ping Liu",
        "Xiaolin Xu",
        "Soha Hassoun"
      ],
      "abstract": "We consider the protein sequence engineering problem, which aims to find\nprotein sequences with high fitness levels, starting from a given wild-type\nsequence. Directed evolution has been a dominating paradigm in this field which\nhas an iterative process to generate variants and select via experimental\nfeedback. We demonstrate large language models (LLMs), despite being trained on\nmassive texts, are secretly protein sequence optimizers. With a directed\nevolutionary method, LLM can perform protein engineering through Pareto and\nexperiment-budget constrained optimization, demonstrating success on both\nsynthetic and experimental fitness landscapes.",
      "tldr_zh": "本研究揭示大型语言模型(LLMs)可以作为蛋白质序列优化器，通过定向进化方法从给定野生型序列出发，寻找高适应性水平的变体。作者将LLMs应用于Pareto优化和实验预算约束的蛋白质工程流程，成功处理了合成和实验适应性景观。实验结果证明了LLMs在蛋白质序列优化中的有效性，为传统定向进化范式提供了新颖替代方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2501.09274v2",
      "published_date": "2025-01-16 03:44:16 UTC",
      "updated_date": "2025-01-17 15:22:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:26:48.785825"
    },
    {
      "arxiv_id": "2501.09265v1",
      "title": "Perspective Transition of Large Language Models for Solving Subjective Tasks",
      "title_zh": "大型语言模型的视角转换用于解决主观任务",
      "authors": [
        "Xiaolong Wang",
        "Yuanchi Zhang",
        "Ziyue Wang",
        "Yuzhuang Xu",
        "Fuwen Luo",
        "Yile Wang",
        "Peng Li",
        "Yang Liu"
      ],
      "abstract": "Large language models (LLMs) have revolutionized the field of natural\nlanguage processing, enabling remarkable progress in various tasks. Different\nfrom objective tasks such as commonsense reasoning and arithmetic\nquestion-answering, the performance of LLMs on subjective tasks is still\nlimited, where the perspective on the specific problem plays crucial roles for\nbetter interpreting the context and giving proper response. For example, in\ncertain scenarios, LLMs may perform better when answering from an expert role\nperspective, potentially eliciting their relevant domain knowledge. In\ncontrast, in some scenarios, LLMs may provide more accurate responses when\nanswering from a third-person standpoint, enabling a more comprehensive\nunderstanding of the problem and potentially mitigating inherent biases. In\nthis paper, we propose Reasoning through Perspective Transition (RPT), a method\nbased on in-context learning that enables LLMs to dynamically select among\ndirect, role, and third-person perspectives for the best way to solve\ncorresponding subjective problem. Through extensive experiments on totally 12\nsubjective tasks by using both closed-source and open-source LLMs including\nGPT-4, GPT-3.5, Llama-3, and Qwen-2, our method outperforms widely used single\nfixed perspective based methods such as chain-of-thought prompting and expert\nprompting, highlights the intricate ways that LLMs can adapt their perspectives\nto provide nuanced and contextually appropriate responses for different\nproblems.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在主观任务上的性能限制，强调视角 (perspective) 的选择对上下文解读和响应质量的影响。论文提出 Reasoning through Perspective Transition (RPT) 方法，基于 in-context learning 动态选择直接、角色或第三人称视角，以优化主观问题的解决。实验在 12 个主观任务上使用 GPT-4、GPT-3.5、Llama-3 和 Qwen-2 等模型表明，RPT 优于 chain-of-thought prompting 和 expert prompting 等固定视角方法，突显了 LLMs 通过视角转换提供更细致和上下文适配响应的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09265v1",
      "published_date": "2025-01-16 03:30:47 UTC",
      "updated_date": "2025-01-16 03:30:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:27:01.291903"
    },
    {
      "arxiv_id": "2501.09254v1",
      "title": "Clone-Robust AI Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Ariel D. Procaccia",
        "Benjamin Schiffer",
        "Shirley Zhang"
      ],
      "abstract": "A key challenge in training Large Language Models (LLMs) is properly aligning\nthem with human preferences. Reinforcement Learning with Human Feedback (RLHF)\nuses pairwise comparisons from human annotators to train reward functions and\nhas emerged as a popular alignment method. However, input datasets in RLHF are\nnot necessarily balanced in the types of questions and answers that are\nincluded. Therefore, we want RLHF algorithms to perform well even when the set\nof alternatives is not uniformly distributed. Drawing on insights from social\nchoice theory, we introduce robustness to approximate clones, a desirable\nproperty of RLHF algorithms which requires that adding near-duplicate\nalternatives does not significantly change the learned reward function. We\nfirst demonstrate that the standard RLHF algorithm based on regularized maximum\nlikelihood estimation (MLE) fails to satisfy this property. We then propose the\nweighted MLE, a new RLHF algorithm that modifies the standard regularized MLE\nby weighting alternatives based on their similarity to other alternatives. This\nnew algorithm guarantees robustness to approximate clones while preserving\ndesirable theoretical properties.",
      "tldr_zh": "本研究针对训练 Large Language Models (LLMs) 时，Reinforcement Learning with Human Feedback (RLHF) 方法因数据集不平衡而导致性能不佳的问题，借鉴 social choice theory 引入了 robustness to approximate clones 的概念，即添加近似重复备选方案不会显著改变学到的奖励函数。标准 RLHF 算法基于 regularized maximum likelihood estimation (MLE) 无法满足这一属性，因此作者提出 weighted MLE 算法，通过基于备选方案相似性的权重调整来提升鲁棒性。该新算法不仅保证了 robustness to approximate clones，还保留了原有理论属性，从而提高了 RLHF 在不均匀分布数据集上的适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09254v1",
      "published_date": "2025-01-16 02:43:44 UTC",
      "updated_date": "2025-01-16 02:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:27:13.954808"
    },
    {
      "arxiv_id": "2501.09239v1",
      "title": "AI-based Identity Fraud Detection: A Systematic Review",
      "title_zh": "翻译失败",
      "authors": [
        "Chuo Jun Zhang",
        "Asif Q. Gill",
        "Bo Liu",
        "Memoona J. Anwar"
      ],
      "abstract": "With the rapid development of digital services, a large volume of personally\nidentifiable information (PII) is stored online and is subject to cyberattacks\nsuch as Identity fraud. Most recently, the use of Artificial Intelligence (AI)\nenabled deep fake technologies has significantly increased the complexity of\nidentity fraud. Fraudsters may use these technologies to create highly\nsophisticated counterfeit personal identification documents, photos and videos.\nThese advancements in the identity fraud landscape pose challenges for identity\nfraud detection and society at large. There is a pressing need to review and\nunderstand identity fraud detection methods, their limitations and potential\nsolutions. This research aims to address this important need by using the\nwell-known systematic literature review method. This paper reviewed a selected\nset of 43 papers across 4 major academic literature databases. In particular,\nthe review results highlight the two types of identity fraud prevention and\ndetection methods, in-depth and open challenges. The results were also\nconsolidated into a taxonomy of AI-based identity fraud detection and\nprevention methods including key insights and trends. Overall, this paper\nprovides a foundational knowledge base to researchers and practitioners for\nfurther research and development in this important area of digital identity\nfraud.",
      "tldr_zh": "本文对 AI-based 身份欺诈检测进行了系统文献综述，重点探讨数字服务快速发展导致的个人信息泄露问题，以及 AI 启用深度伪造技术如何加剧欺诈的复杂性。研究审阅了 43 篇论文，来自 4 个主要学术数据库，突出了身份欺诈预防和检测的两种方法（in-depth 和 open challenges），并构建了一个 AI-based 身份欺诈检测和预防方法的分类学。结果总结了关键洞见和趋势，为研究者和从业者提供基础知识库，支持未来在数字身份安全领域的进一步研究和发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09239v1",
      "published_date": "2025-01-16 01:52:30 UTC",
      "updated_date": "2025-01-16 01:52:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:27:25.744009"
    },
    {
      "arxiv_id": "2501.09223v1",
      "title": "Foundations of Large Language Models",
      "title_zh": "大型语言模型的基础",
      "authors": [
        "Tong Xiao",
        "Jingbo Zhu"
      ],
      "abstract": "This is a book about large language models. As indicated by the title, it\nprimarily focuses on foundational concepts rather than comprehensive coverage\nof all cutting-edge technologies. The book is structured into four main\nchapters, each exploring a key area: pre-training, generative models, prompting\ntechniques, and alignment methods. It is intended for college students,\nprofessionals, and practitioners in natural language processing and related\nfields, and can serve as a reference for anyone interested in large language\nmodels.",
      "tldr_zh": "这本书探讨了大型语言模型（Large Language Models）的基礎概念，重点关注预训练（pre-training）、生成模型（generative models）、提示技术（prompting techniques）和对齐方法（alignment methods）等关键领域，而非全面覆盖前沿技术。书中结构分为四个主要章节，旨在为读者提供系统的理论基础。适合自然语言处理领域的大学生、专业人士和从业者作为参考资料。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09223v1",
      "published_date": "2025-01-16 01:03:56 UTC",
      "updated_date": "2025-01-16 01:03:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:27:36.945044"
    },
    {
      "arxiv_id": "2501.09218v1",
      "title": "Interpretable Droplet Digital PCR Assay for Trustworthy Molecular Diagnostics",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanyuan Wei",
        "Yucheng Wu",
        "Fuyang Qu",
        "Yao Mu",
        "Yi-Ping Ho",
        "Ho-Pui Ho",
        "Wu Yuan",
        "Mingkun Xu"
      ],
      "abstract": "Accurate molecular quantification is essential for advancing research and\ndiagnostics in fields such as infectious diseases, cancer biology, and genetic\ndisorders. Droplet digital PCR (ddPCR) has emerged as a gold standard for\nachieving absolute quantification. While computational ddPCR technologies have\nadvanced significantly, achieving automatic interpretation and consistent\nadaptability across diverse operational environments remains a challenge. To\naddress these limitations, we introduce the intelligent interpretable droplet\ndigital PCR (I2ddPCR) assay, a comprehensive framework integrating front-end\npredictive models (for droplet segmentation and classification) with GPT-4o\nmultimodal large language model (MLLM, for context-aware explanations and\nrecommendations) to automate and enhance ddPCR image analysis. This approach\nsurpasses the state-of-the-art models, affording 99.05% accuracy in processing\ncomplex ddPCR images containing over 300 droplets per image with varying\nsignal-to-noise ratios (SNRs). By combining specialized neural networks and\nlarge language models, the I2ddPCR assay offers a robust and adaptable solution\nfor absolute molecular quantification, achieving a sensitivity capable of\ndetecting low-abundance targets as low as 90.32 copies/{\\mu}L. Furthermore, it\nimproves model's transparency through detailed explanation and troubleshooting\nguidance, empowering users to make informed decisions. This innovative\nframework has the potential to benefit molecular diagnostics, disease research,\nand clinical applications, especially in resource-constrained settings.",
      "tldr_zh": "本论文提出 I2ddPCR 框架，用于提升 Droplet Digital PCR (ddPCR) 的自动解释和适应性，解决分子定量在复杂环境中的挑战。框架整合前端预测模型（如神经网络）用于液滴分割和分类，以及 GPT-4o 多模态大语言模型提供上下文感知解释和推荐，实现对复杂 ddPCR 图像的精确分析。实验结果显示，该方法在处理包含超过 300 个液滴的图像时达到 99.05% 准确率，并能检测低丰度目标低至 90.32 copies/μL，同时通过详细解释提升模型透明度和用户决策能力。通过这一创新框架，论文为分子诊断、疾病研究和资源有限的临床应用提供可靠、可信赖的解决方案。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.09218v1",
      "published_date": "2025-01-16 00:33:17 UTC",
      "updated_date": "2025-01-16 00:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:27:50.058135"
    },
    {
      "arxiv_id": "2501.09217v1",
      "title": "Adaptive Law-Based Transformation (ALT): A Lightweight Feature Representation for Time Series Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Marcell T. Kurbucz",
        "Balázs Hajós",
        "Balázs P. Halmos",
        "Vince Á. Molnár",
        "Antal Jakovác"
      ],
      "abstract": "Time series classification (TSC) is fundamental in numerous domains,\nincluding finance, healthcare, and environmental monitoring. However,\ntraditional TSC methods often struggle with the inherent complexity and\nvariability of time series data. Building on our previous work with the linear\nlaw-based transformation (LLT) - which improved classification accuracy by\ntransforming the feature space based on key data patterns - we introduce\nadaptive law-based transformation (ALT). ALT enhances LLT by incorporating\nvariable-length shifted time windows, enabling it to capture distinguishing\npatterns of various lengths and thereby handle complex time series more\neffectively. By mapping features into a linearly separable space, ALT provides\na fast, robust, and transparent solution that achieves state-of-the-art\nperformance with only a few hyperparameters.",
      "tldr_zh": "该论文针对时间序列分类 (TSC) 的复杂性和可变性问题，提出了Adaptive Law-Based Transformation (ALT) 作为一种轻量级特征表示方法。ALT 在先前Linear Law-Based Transformation (LLT) 的基础上，引入可变长度的时间窗口，以捕获不同长度的区分模式，从而更有效地处理复杂时间序列数据。通过将特征映射到线性可分空间，ALT 仅需少量超参数，便实现了快速、鲁棒且透明的解决方案，并在性能上达到了最先进水平。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML",
        "62H30, 68T10, 62M10",
        "I.5; I.2.0; G.3"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 1 figure, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.09217v1",
      "published_date": "2025-01-16 00:33:01 UTC",
      "updated_date": "2025-01-16 00:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T00:28:00.979248"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 71,
  "processed_papers_count": 71,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T00:28:18.056568"
}