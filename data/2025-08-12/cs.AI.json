{
  "date": "2025-08-12",
  "category": "cs.AI",
  "summary": "ä½ å¥½ï¼æˆ‘æ˜¯ Gemini Enterpriseã€‚æ¬¢è¿æ¥åˆ° **UTC æ—¶é—´ 2025-08-12** çš„ arXiv ä¸­æ–‡ TLDR å¿«æŠ¥ï¼\n\n**ä»Šæ—¥æ€»ç»“ï¼š**\nä»Šå¤©çš„ arXiv åˆæ˜¯â€œç¥ä»™æ‰“æ¶â€çš„ä¸€å¤©ã€‚**OpenAI å›¢é˜Ÿå‘å¸ƒäº†ä¸€ç¯‡å…³äºå®‰å…¨è®­ç»ƒèŒƒå¼è½¬å˜çš„é‡ç£…æ–‡ç« **ï¼Œæå‡ºä»â€œæ‹’ç»å›ç­”â€è½¬å‘â€œå®‰å…¨è¡¥å…¨â€ï¼›Agent é¢†åŸŸæŒç»­ç«çƒ­ï¼Œ**Computer-Useï¼ˆè®¡ç®—æœºä½¿ç”¨ï¼‰** ç›¸å…³çš„å¼€æºåŸºç¡€æ¡†æ¶ OpenCUA å€¼å¾—å…³æ³¨ï¼›æ­¤å¤–ï¼Œå…³äº **Search-based Agent çš„æ•°æ®æ±¡æŸ“**é—®é¢˜è¢«å°–é”åœ°æŒ‡å‡ºã€‚åœ¨å¤šæ¨¡æ€æ–¹é¢ï¼Œ**äº¤äº’å¼è§†é¢‘ç”Ÿæˆ**å’Œ**äººä½“åŠ¨ä½œè¿ç§»**ä¹Ÿæœ‰äº†ä»¤äººå°è±¡æ·±åˆ»çš„è¿›å±•ã€‚\n\n---\n\n### ğŸš€ LLM å®‰å…¨ã€å¯¹é½ä¸æ¨ç† (Safety, Alignment & Reasoning)\n\nä»Šå¤©çš„é‡å¤´æˆåœ¨å®‰å…¨å¯¹é½ä¸Šï¼ŒOpenAI çš„æ–°æ€è·¯å¯èƒ½ä¼šæ”¹å˜æœªæ¥çš„å®‰å…¨è®­ç»ƒèŒƒå¼ã€‚åŒæ—¶ï¼ŒAgent çš„è¯„ä¼°é—®é¢˜ä¹Ÿæš´éœ²å‡ºäº†æ–°çš„éšæ‚£ã€‚\n\n**1. ä»ç”Ÿç¡¬æ‹’ç»åˆ°å®‰å…¨è¡¥å…¨ï¼šè¿ˆå‘ä»¥è¾“å‡ºä¸ºä¸­å¿ƒçš„å®‰å…¨è®­ç»ƒ**\n**From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šOpenAI å›¢é˜ŸåŠ›ä½œã€‚è®¤ä¸ºä¼ ç»Ÿçš„â€œæ‹’ç»å›ç­”â€ (Refusal) ç­–ç•¥åœ¨åŒé‡ç”¨é€”ï¼ˆå¦‚ç”Ÿç‰©ã€ç½‘ç»œå®‰å…¨ï¼‰åœºæ™¯ä¸‹å¤ªè„†å¼±ä¸”ä¸å¯ç”¨ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šæå‡ºäº† **Safe-Completions**ï¼ˆå®‰å…¨è¡¥å…¨ï¼‰çš„æ¦‚å¿µã€‚ä¸å†ç®€å•åœ°æ ¹æ®ç”¨æˆ·æ„å›¾è¿›è¡ŒäºŒå…ƒåˆ†ç±»ï¼ˆæ‹’ç»/æ¥å—ï¼‰ï¼Œè€Œæ˜¯è®©æ¨¡å‹åœ¨å®‰å…¨ç­–ç•¥çš„çº¦æŸä¸‹ï¼Œå°½å¯èƒ½æä¾›æœ‰å¸®åŠ©çš„è¾“å‡ºï¼ˆMaximum Helpfulnessï¼‰ã€‚å®éªŒè¡¨æ˜ï¼Œè¿™ç§æ–¹æ³•åœ¨ GPT-5 ä¸­ä¸ä»…æå‡äº†å®‰å…¨æ€§ï¼ˆç‰¹åˆ«æ˜¯é’ˆå¯¹åŒé‡ç”¨é€”æç¤ºè¯ï¼‰ï¼Œè¿˜æ˜¾è‘—æé«˜äº†æ¨¡å‹çš„æœ‰ç”¨æ€§ã€‚\n\n**2. æœç´¢æ—¶æ•°æ®æ±¡æŸ“**\n**Search-Time Data Contamination**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šè¿™å°±å¾ˆå°´å°¬äº†ï¼ŒSearch-based Agent ä¼šè‡ªå·±åœ¨ç½‘ä¸Šæœåˆ°æµ‹è¯•é›†çš„ç­”æ¡ˆã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šä½œè€…å‘ç°ï¼Œèƒ½å¤Ÿä½¿ç”¨å·¥å…·æœç´¢äº’è”ç½‘çš„ LLM Agentï¼Œåœ¨è¯„ä¼°æ—¶ç»å¸¸ä¼šæœåˆ° HuggingFace ç­‰å¹³å°ä¸Šçš„æ•°æ®é›†æºæ–‡ä»¶ï¼ˆåŒ…å«é—®é¢˜å’Œç­”æ¡ˆï¼‰ã€‚è¿™è¢«ç§°ä¸ºâ€œæœç´¢æ—¶æ±¡æŸ“ (STC)â€ã€‚åœ¨ HLE, SimpleQA ç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œçº¦ 3% çš„é—®é¢˜è¢« Agent ç›´æ¥â€œæŠ„â€åˆ°äº†ç­”æ¡ˆã€‚å°é” HuggingFace åï¼Œå‡†ç¡®ç‡æ‰äº† 15%ã€‚è¿™ç»™å½“å‰çš„ Agent æ¦œå•å«é‡‘é‡æ‰“äº†ä¸ªé—®å·ã€‚\n\n**3. æ‰©æ•£è¯­è¨€æ¨¡å‹ä¸­çš„æ—¶é—´åŠ¨æ€ï¼šåˆ©ç”¨ä¸­é—´é¢„æµ‹**\n**Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šæ‰©æ•£æ¨¡å‹ç”Ÿæˆæ–‡æœ¬æ—¶ï¼Œä¸­é—´è¿‡ç¨‹å…¶å®å·²ç»åŒ…å«äº†æ­£ç¡®ç­”æ¡ˆï¼Œä½†åé¢åˆè¢«â€œä¼˜åŒ–â€æ‰äº†ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šä½œè€…å‘ç° **dLLMs (Diffusion LLMs)** å­˜åœ¨â€œæ—¶é—´éœ‡è¡â€ç°è±¡ï¼šæ­£ç¡®ç­”æ¡ˆå¾€å¾€åœ¨ä¸­é—´å»å™ªæ­¥éª¤å‡ºç°ï¼Œéšåè¢«è¦†ç›–ã€‚æå‡ºäº† Temporal Self-Consistency Votingï¼ˆåˆ©ç”¨ä¸­é—´æ­¥éª¤æŠ•ç¥¨ï¼‰å’Œ Temporal Consistency Reinforcementï¼ˆå¼ºåŒ–ä¸­é—´è¯­ä¹‰ç¨³å®šæ€§ï¼‰ï¼Œåœ¨æ•°å­¦ä»»åŠ¡ï¼ˆGSM8K, MATH500ï¼‰ä¸Šæ˜¾è‘—æå‡äº†æ€§èƒ½ã€‚\n\n**4. ç½—ç›˜æ€è€ƒè€…-7Bï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ æŒ–æ˜æ¨ç†æ½œåŠ›**\n**Compass-Thinker-7B Technical Report**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šå¯¹æ ‡ DeepSeek-R1-Zero çš„æ€è·¯ï¼Œä½†ç”¨æ›´å°‘çš„èµ„æºåš RLã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šå‘å¸ƒäº† Compass-Thinker-7Bï¼Œé€šè¿‡ä¸“é—¨è®¾è®¡çš„å¼ºåŒ–å­¦ä¹ ç®¡çº¿ï¼ˆRL Pipelineï¼‰å’Œ 30k å¯éªŒè¯æ•°å­¦é—®é¢˜æ•°æ®é›†è®­ç»ƒè€Œæˆã€‚è¯æ˜äº†å°æ¨¡å‹ï¼ˆ7Bï¼‰é€šè¿‡åˆç†çš„ RL ç­–ç•¥ä¹Ÿèƒ½åœ¨æ•°å­¦æ¨ç†ï¼ˆAIME2024 è¾¾åˆ° 40%ï¼‰ä¸Šå–å¾—ä¼˜å¼‚æˆç»©ï¼Œé™ä½äº† RL æ¢ç´¢çš„é—¨æ§›ã€‚\n\n**5. LLM ä¸­çš„é«˜æ•ˆå¯åˆ‡æ¢å®‰å…¨æ§åˆ¶**\n**Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šæƒ³è®©æ¨¡å‹å˜â€œåâ€çº¢é˜Ÿæµ‹è¯•ï¼Œæˆ–è€…å˜â€œå¥½â€æœåŠ¡ç”¨æˆ·ï¼Œåªéœ€è¦ä¸€ä¸ª Token åˆ‡æ¢ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šæå‡ºäº†ä¸€ç§ Co-Training æ¡†æ¶ï¼Œè®© LLM åœ¨å•ä¸ª SFT é˜¶æ®µå­¦ä¹ ä¸‰ç§è¡Œä¸ºæ¨¡å¼ï¼šç§¯æï¼ˆå®‰å…¨ï¼‰ã€æ¶ˆæï¼ˆæ— è¿‡æ»¤/é£é™©ï¼‰ã€æ‹’ç»ï¼ˆä¿å®ˆï¼‰ã€‚é€šè¿‡æ¨ç†æ—¶çš„ **Magic Token** å³å¯æ— ç¼åˆ‡æ¢æ¨¡å¼ã€‚è¿™å¯¹äºçº¢é˜Ÿæµ‹è¯•å’Œçµæ´»éƒ¨ç½²éå¸¸æœ‰ç”¨ï¼Œä¸” 8B æ¨¡å‹åœ¨å®‰å…¨æ€§ä¸Šè¶…è¶Šäº† DeepSeek-R1 (671B)ã€‚\n\n---\n\n### ğŸ¤– Agent ä¸ è®¡ç®—æœºä½¿ç”¨ (Agents & Computer Use)\n\n**6. OpenCUAï¼šè®¡ç®—æœºä½¿ç”¨ Agent çš„å¼€æ”¾åŸºç¡€**\n**OpenCUA: Open Foundations for Computer-Use Agents**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šComputer-Use Agent (CUA) æ˜¯è¿‘æœŸçš„çƒ­ç‚¹ï¼Œè¿™ç¯‡è®ºæ–‡å¼€æºäº†æ•´å¥—åŸºç¡€è®¾æ–½ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šå‘å¸ƒäº† OpenCUA æ¡†æ¶ï¼ŒåŒ…å«ï¼š(1) æ ‡æ³¨å·¥å…·ï¼›(2) **AgentNet**ï¼šæ¶µç›– 3 ä¸ªæ“ä½œç³»ç»Ÿã€200+ åº”ç”¨çš„å¤§è§„æ¨¡æ•°æ®é›†ï¼›(3) èƒ½å¤Ÿå°†æ¼”ç¤ºè½¬åŒ–ä¸ºå¸¦æœ‰é•¿æ€ç»´é“¾ (CoT) çš„è®­ç»ƒæ•°æ®çš„ç®¡é“ã€‚è®­ç»ƒå‡ºçš„ OpenCUA-72B åœ¨ OSWorld æ¦œå•ä¸Šåˆ·æ–°äº†å¼€æº SOTAã€‚\n\n**7. äººæœºäº¤äº’ä¸­çš„ç¤¾ä¼šè®¤åŒï¼šå…¥é—¨æŒ‡å—**\n**Social Identity in Human-Agent Interaction: A Primer**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šç»ˆèº«æ•™æˆè§†è§’çš„ç†è®ºç»¼è¿°ï¼Œæ¢è®¨äººç±»å¦‚ä½•å°† Agent è§†ä¸ºâ€œç¤¾ä¼šç¾¤ä½“â€çš„ä¸€å‘˜ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šå°†ç¤¾ä¼šè®¤åŒç†è®º (SIT) å’Œç¤¾ä¼šåˆ†ç±»ç†è®º (SCT) å¼•å…¥äººæœºäº¤äº’ã€‚æ¢è®¨äº†å½“æœºå™¨ï¼ˆLLMã€ç¤¾äº¤æœºå™¨äººï¼‰è¶Šæ¥è¶Šåƒäººæ—¶ï¼Œäººç±»å¦‚ä½•å¯¹å…¶è¿›è¡Œç¤¾ä¼šåˆ†ç±»ã€‚ä½œè€…è­¦å‘Šä¸“å®¶ä»¬å¯èƒ½éœ€è¦æ‰®æ¼”â€œææ€–è°·æ€æ‰‹ (uncanny killjoy)â€çš„è§’è‰²ï¼Œè­¦æƒ•è¿‡åº¦æ‹ŸäººåŒ–å¸¦æ¥çš„é£é™©ã€‚\n\n**8. æµè§ˆå¤§å¸ˆï¼šé€šè¿‡å·¥å…·å¢å¼ºçš„ç¨‹åºåŒ– Agent å¯¹å®ç°å¯æ‰©å±•çš„ç½‘é¡µæµè§ˆ**\n**BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šè§£å†³ Agent åœ¨ç½‘é¡µæµè§ˆæ—¶â€œæŸ¥å¾—å¹¿â€å’Œâ€œæƒ³å¾—æ·±â€ä¹‹é—´çš„çŸ›ç›¾ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šè®¾è®¡äº† Planner-Executor åŒ Agent æ¶æ„ã€‚Planner è´Ÿè´£åˆ¶å®šç­–ç•¥ï¼ŒExecutor è´Ÿè´£é«˜æ•ˆæ£€ç´¢ã€‚è¿™ç§åˆ†å·¥åä½œåœ¨ BrowseComp æ¦œå•ï¼ˆè‹±æ–‡å’Œä¸­æ–‡ï¼‰ä¸Šéƒ½è¶…è¶Šäº†ç°æœ‰åŸºçº¿ã€‚\n\n---\n\n### ğŸ¨ å¤šæ¨¡æ€ä¸ç”Ÿæˆ (Multimodal & Generation)\n\n**9. Yanï¼šåŸºç¡€äº¤äº’å¼è§†é¢‘ç”Ÿæˆ**\n**Yan: Foundational Interactive Video Generation**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šè¿ˆå‘â€œå¯ç©çš„è§†é¢‘â€ï¼Œé›†æ¨¡æ‹Ÿã€ç”Ÿæˆã€ç¼–è¾‘äºä¸€ä½“ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šæå‡ºäº† Yan æ¡†æ¶ï¼ŒåŒ…å« AAA çº§æ¨¡æ‹Ÿï¼ˆä½å»¶è¿Ÿ 3D-VAEï¼‰ã€å¤šæ¨¡æ€ç”Ÿæˆï¼ˆå°†æ¸¸æˆçŸ¥è¯†æ³¨å…¥è§†é¢‘æ‰©æ•£æ¨¡å‹ï¼‰å’Œå¤šç²’åº¦ç¼–è¾‘ã€‚å®ç°äº† **1080P/60FPS** çš„å®æ—¶äº¤äº’å¼æ¨¡æ‹Ÿï¼Œä¸ä»…èƒ½ç”Ÿæˆè§†é¢‘ï¼Œè¿˜èƒ½åƒç©æ¸¸æˆä¸€æ ·æ§åˆ¶å…¶ä¸­çš„åŠ¨ä½œã€‚\n\n**10. X-UniMotionï¼šç”¨å¯Œæœ‰è¡¨ç°åŠ›ã€ç»Ÿä¸€ä¸”èº«ä»½æ— å…³çš„åŠ¨ä½œæ½œåœ¨å˜é‡åŠ¨ç”»åŒ–äººç‰©å›¾åƒ**\n**X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šä¸€å¼ å›¾ + ä¸€ä¸ªåŠ¨ä½œ = é«˜ä¿çœŸåŠ¨ç”»ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šæå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„éšå¼æ½œåœ¨è¡¨ç¤ºï¼Œå°†é¢éƒ¨è¡¨æƒ…ã€èº«ä½“å§¿åŠ¿å’Œæ‰‹åŠ¿è§£è€¦ã€‚ä¸éœ€è¦æ˜¾å¼çš„éª¨éª¼å§¿åŠ¿ï¼Œç›´æ¥ä»å•å¼ å›¾åƒç¼–ç åŠ¨ä½œã€‚ç”Ÿæˆçš„åŠ¨ç”»åœ¨ä¿ç•™äººç‰©èº«ä»½çš„åŒæ—¶ï¼Œèƒ½å¤Ÿæå…¶ç”ŸåŠ¨åœ°è¿ç§»å¤æ‚çš„å…¨èº«åŠ¨ä½œã€‚\n\n**11. ç”¨å¤šæ¨¡æ€æ‰©æ•£ Transformer å®ç°æ— éœ€è®­ç»ƒçš„æ–‡æœ¬å¼•å¯¼é¢œè‰²ç¼–è¾‘**\n**Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šæ”¹å›¾é¢œè‰²ä¸éœ€è¦é‡æ–°è®­ç»ƒæ¨¡å‹ï¼Œç”šè‡³ä¸éœ€è¦å¾®è°ƒã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šåˆ©ç”¨ç°ä»£ MM-DiTï¼ˆå¦‚ SD3, FLUX.1ï¼‰çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡è§£è€¦ç»“æ„å’Œé¢œè‰²ï¼Œå®ç°äº†ç²¾å‡†çš„æ–‡æœ¬å¼•å¯¼é¢œè‰²ç¼–è¾‘ï¼ˆColorCtrlï¼‰ã€‚å¯¹æ¯”äº†å•†ä¸šæ¨¡å‹å’Œ GPT-4o çš„ç”»å›¾åŠŸèƒ½ï¼Œåœ¨ä¸€è‡´æ€§ä¸Šè¡¨ç°æ›´å¥½ã€‚\n\n---\n\n### ğŸŒ ç¤¾ä¼šç§‘å­¦ã€åè§ä¸ä¼¦ç† (Social Science, Ethics & Bias)\n\n**12. æœ‰åè§çš„ AI æ”¹å–„äº†äººç±»å†³ç­–ä½†é™ä½äº†ä¿¡ä»»**\n**Biased AI improves human decision-making but reduces trust**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šåç›´è§‰çš„å‘ç°â€”â€”â€œç†ä¸­å®¢â€çš„ AI ä¸ä¸€å®šæœ€å¥½ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šé€šè¿‡ 2500 äººçš„éšæœºå®éªŒå‘ç°ï¼Œå¸¦æœ‰æ”¿æ²»åè§çš„ AI åŠ©æ‰‹åè€Œèƒ½æé«˜äººç±»åœ¨ä¿¡æ¯è¯„ä¼°ä»»åŠ¡ä¸­çš„è¡¨ç°ï¼ˆå¢åŠ äº†å‚ä¸åº¦ï¼Œå‡å°‘äº†äººç±»è‡ªèº«çš„è¯„ä¼°åå·®ï¼‰ï¼Œå°¤å…¶æ˜¯å½“ AI è§‚ç‚¹ä¸äººç±»ç›¸åæ—¶ã€‚ä½†ä»£ä»·æ˜¯ï¼šäººç±»ä¸ä¿¡ä»»è¿™äº›æœ‰åè§çš„ AIï¼Œå“ªæ€•å®ƒä»¬å¾ˆæœ‰ç”¨ã€‚\n\n**13. å›½é™…æ„ŸçŸ¥çš„æ ¹æºï¼šç”¨ LLM Agent æ¨¡æ‹Ÿç¾å›½å¯¹åæ€åº¦çš„å˜åŒ–**\n**The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šç”¨ LLM æ¨¡æ‹Ÿ 20 å¹´çš„å›½é™…å…³ç³»æ°‘æ„æ¼”å˜ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šæ„å»ºäº†ä¸€ä¸ªåŒ…å«åª’ä½“æ•°æ®æ”¶é›†ã€ç”¨æˆ·ç”»åƒå’Œè®¤çŸ¥æ¶æ„çš„æ¡†æ¶ï¼ŒæˆåŠŸå¤ç°äº† 2005 å¹´è‡³ä»Šç¾å›½æ°‘ä¼—å¯¹ä¸­å›½æ€åº¦çš„å˜åŒ–è¶‹åŠ¿ã€‚å¼•å…¥äº†â€œé­”é¬¼ä»£è¨€äººâ€ Agent æ¥è§£é‡Šæ€åº¦åè½¬çš„æ·±å±‚åŸå› ï¼ˆä¿¡æ¯è·å–æ–¹å¼çš„å˜åŒ–ï¼‰ã€‚\n\n**14. é’ˆå¯¹ AI å®‰å…¨çš„éæ´²è®®ç¨‹**\n**Toward an African Agenda for AI Safety**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šAI å®‰å…¨ä¸èƒ½åªå¬ç¡…è°·çš„ï¼Œéæ´²æœ‰å…¶ç‹¬ç‰¹çš„é£é™©å›¾è°±ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šæŒ‡å‡ºäº†éæ´²é¢ä¸´çš„ç‹¬ç‰¹ AI é£é™©ï¼ˆå¦‚é€‰ä¸¾å¹²é¢„ã€æ•°æ®æ®–æ°‘ä¸»ä¹‰ã€ç®—åŠ›åŒ®ä¹ï¼‰ã€‚æå‡ºäº†äº”ç‚¹è¡ŒåŠ¨è®¡åˆ’ï¼ŒåŒ…æ‹¬å»ºç«‹éæ´² AI å®‰å…¨ç ”ç©¶æ‰€ã€é’ˆå¯¹ 25+ ç§éæ´²è¯­è¨€å»ºç«‹åŸºå‡†æµ‹è¯•ç­‰ã€‚\n\n---\n\n### ğŸ’Š ç§‘å­¦ä¸åŒ»ç–— (Science & Health)\n\n**15. ç†è§£ç—´å‘†ç—‡è¯­éŸ³ä¸åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆçš„å¯¹é½**\n**Understanding Dementia Speech Alignment with Diffusion-Based Image Generation**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šè„‘æ´æ¸…å¥‡â€”â€”æŠŠç—´å‘†ç—‡æ‚£è€…çš„è¯ç”Ÿæˆå›¾ï¼Œçœ‹å›¾å°±èƒ½è¯Šæ–­ç—´å‘†ï¼Ÿ\n> **ä¸»è¦è´¡çŒ®**ï¼šç ”ç©¶å‘ç°ï¼Œä»…é€šè¿‡æ‚£è€…è¯­éŸ³ç”Ÿæˆçš„å›¾åƒï¼Œå°±èƒ½ä»¥ 75% çš„å‡†ç¡®ç‡æ£€æµ‹ç—´å‘†ç—‡ï¼ˆADReSS æ•°æ®é›†ï¼‰ã€‚è¿™æ„å‘³ç€æ–‡æœ¬åˆ°å›¾åƒæ¨¡å‹åœ¨æ½œåœ¨ç©ºé—´ä¸­æ•æ‰åˆ°äº†ç—…ç†æ€§è¯­éŸ³çš„ç‰¹å¾ã€‚\n\n**16. Pep2Prob åŸºå‡†æµ‹è¯•ï¼šé¢„æµ‹ MS^2 è›‹ç™½è´¨ç»„å­¦çš„ç¢ç‰‡ç¦»å­æ¦‚ç‡**\n**Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS^2-based Proteomics**\n> **æ ¸å¿ƒäº®ç‚¹**ï¼šè›‹ç™½è´¨ç»„å­¦çš„å¤§è§„æ¨¡æ•°æ®é›†å’ŒåŸºå‡†ã€‚\n> **ä¸»è¦è´¡çŒ®**ï¼šå‘å¸ƒäº† Pep2Prob æ•°æ®é›†ï¼ŒåŒ…å« 1.83 äº¿ä¸ªé«˜è´¨é‡è´¨è°±å›¾ã€‚è¯æ˜äº†åˆ©ç”¨è‚½æ®µç‰¹å®šä¿¡æ¯ï¼ˆè€Œéå…¨å±€ç»Ÿè®¡ï¼‰çš„æ¨¡å‹èƒ½æ˜¾è‘—æé«˜é¢„æµ‹å‡†ç¡®æ€§ï¼Œè¿™å¯¹äºè›‹ç™½è´¨é‰´å®šå’Œè¯ç‰©é¶ç‚¹åˆ†æè‡³å…³é‡è¦ã€‚\n\n---\n\n### ğŸ’¡ å…¶ä»–å€¼å¾—ä¸€çœ‹ (Mix)\n\n*   **[#16] TEN: Table Explicitization, Neurosymbolically**: æ—¢ç„¶ LLM å¤„ç†è¡¨æ ¼å®¹æ˜“å‡ºç°å¹»è§‰ï¼Œä¸å¦‚ç”¨â€œç¥ç»ç¬¦å·â€æ–¹æ³•ã€‚ç»“åˆ CoT å’Œç¬¦å·æ£€æŸ¥å™¨æ¥æå–åŠç»“æ„åŒ–æ–‡æœ¬ä¸­çš„è¡¨æ ¼æ•°æ®ã€‚\n*   **[#153] Yan**: ä¸Šé¢æåˆ°çš„è§†é¢‘ç”Ÿæˆï¼Œå…¶å®ä¹Ÿæ˜¯æ¸¸æˆ AI çš„ä¸€å¤§æ­¥ã€‚\n*   **[#163] UQGNN**: åŸå¸‚è®¡ç®—é¢†åŸŸï¼Œæå‡ºäº†å¸¦ä¸ç¡®å®šæ€§é‡åŒ–çš„å›¾ç¥ç»ç½‘ç»œï¼Œç”¨äºå¤šå˜é‡æ—¶ç©ºé¢„æµ‹ï¼ˆå¦‚äº¤é€šã€çŠ¯ç½ªç­‰ï¼‰ã€‚\n\nå¸Œæœ›è¿™ä»½å¿«æŠ¥å¯¹ä½ çš„ç ”ç©¶å·¥ä½œæœ‰å¸®åŠ©ï¼æˆ‘ä»¬æ˜å¤©è§ã€‚",
  "papers": [
    {
      "arxiv_id": "2508.16609v1",
      "title": "Social Identity in Human-Agent Interaction: A Primer",
      "title_zh": "äººæœºäº¤äº’ä¸­çš„ç¤¾ä¼šè®¤åŒï¼šå…¥é—¨æŒ‡å—",
      "authors": [
        "Katie Seaborn"
      ],
      "abstract": "Social identity theory (SIT) and social categorization theory (SCT) are two facets of the social identity approach (SIA) to understanding social phenomena. SIT and SCT are models that describe and explain how people interact with one another socially, connecting the individual to the group through an understanding of underlying psychological mechanisms and intergroup behaviour. SIT, originally developed in the 1970s, and SCT, a later, more general offshoot, have been broadly applied to a range of social phenomena among people. The rise of increasingly social machines embedded in daily life has spurned efforts on understanding whether and how artificial agents can and do participate in SIA activities. As agents like social robots and chatbots powered by sophisticated large language models (LLMs) advance, understanding the real and potential roles of these technologies as social entities is crucial. Here, I provide a primer on SIA and extrapolate, through case studies and imagined examples, how SIT and SCT can apply to artificial social agents. I emphasize that not all human models and sub-theories will apply. I further argue that, given the emerging competence of these machines and our tendency to be taken in by them, we experts may need to don the hat of the uncanny killjoy, for our own good.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¤¾ä¼šè®¤åŒç†è®º(Social Identity Theory, SIT)å’Œç¤¾ä¼šåˆ†ç±»ç†è®º(Social Categorization Theory, SCT)åœ¨äººæœºäº¤äº’(Human-Agent Interaction)ä¸­çš„åº”ç”¨ã€‚ä½œè€…é’ˆå¯¹ç¤¾äº¤æœºå™¨äººå’Œå¤§è¯­è¨€æ¨¡å‹(LLMs)é©±åŠ¨çš„èŠå¤©æœºå™¨äººçš„å´›èµ·ï¼Œæå‡ºäº†ç¤¾ä¼šè®¤åŒæ–¹æ³•(Social Identity Approach, SIA)çš„å…¥é—¨æŒ‡å—ï¼Œåˆ†æäº†äººå·¥æ™ºèƒ½ä½“ä½œä¸ºç¤¾ä¼šå®ä½“çš„æ½œåœ¨è§’è‰²ã€‚é€šè¿‡æ¡ˆä¾‹ç ”ç©¶å’Œè®¾æƒ³ç¤ºä¾‹ï¼Œæ–‡ç« è¯¦ç»†é˜è¿°äº†è¿™äº›ç†è®ºå¦‚ä½•å¤–æ¨è‡³äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œå¹¶æŒ‡å‡ºå¹¶éæ‰€æœ‰äººç±»ç¤¾äº¤æ¨¡å‹éƒ½é€‚ç”¨äºæœºå™¨ã€‚ç ”ç©¶å¼ºè°ƒï¼Œé¢å¯¹è¿™äº›å…·å¤‡ç¤¾äº¤èƒ½åŠ›çš„æœºå™¨ï¼Œäººç±»å®¹æ˜“äº§ç”Ÿè¿‡åº¦è®¤åŒçš„å€¾å‘ï¼Œå› æ­¤ä¸“å®¶åº”ä¿æŒå®¡æ…ï¼Œä»¥æ‰¹åˆ¤æ€§è§†è§’å®¡è§†äººæœºç¤¾ä¼šå…³ç³»çš„è¾¹ç•Œã€‚",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.CY",
        "cs.HC",
        "cs.RO"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "28 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.16609v1",
      "published_date": "2025-08-12 23:48:59 UTC",
      "updated_date": "2025-08-12 23:48:59 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:09:58.585460+00:00"
    },
    {
      "arxiv_id": "2508.09385v1",
      "title": "Understanding Dementia Speech Alignment with Diffusion-Based Image Generation",
      "title_zh": "åŸºäºæ‰©æ•£å›¾åƒç”Ÿæˆçš„ç—´å‘†ç—‡è¨€è¯­å¯¹é½æ¢ç©¶",
      "authors": [
        "Mansi",
        "Anastasios Lepipas",
        "Dominika Woszczyk",
        "Yiying Guan",
        "Soteris Demetriou"
      ],
      "abstract": "Text-to-image models generate highly realistic images based on natural language descriptions and millions of users use them to create and share images online. While it is expected that such models can align input text and generated image in the same latent space little has been done to understand whether this alignment is possible between pathological speech and generated images. In this work, we examine the ability of such models to align dementia-related speech information with the generated images and develop methods to explain this alignment. Surprisingly, we found that dementia detection is possible from generated images alone achieving 75% accuracy on the ADReSS dataset. We then leverage explainability methods to show which parts of the language contribute to the detection.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹(Text-to-image models)æ˜¯å¦èƒ½å¤Ÿå°†ç—´å‘†ç—‡ç›¸å…³çš„ç—…ç†è¯­éŸ³(pathological speech)ä¿¡æ¯ä¸ç”Ÿæˆçš„å›¾åƒè¿›è¡Œæœ‰æ•ˆå¯¹é½ã€‚ç ”ç©¶è€…åˆ©ç”¨åŸºäºæ‰©æ•£çš„å›¾åƒç”Ÿæˆ(Diffusion-Based Image Generation)æŠ€æœ¯ï¼Œåˆ†æäº†æ¨¡å‹åœ¨å¤„ç†ç—´å‘†ç—‡æ‚£è€…è¯­è¨€æè¿°æ—¶çš„è§†è§‰è¾“å‡ºä¸€è‡´æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…é€šè¿‡ç”Ÿæˆçš„å›¾åƒå³å¯å®ç°ç—´å‘†ç—‡æ£€æµ‹(dementia detection)ï¼Œå¹¶åœ¨ADReSSæ•°æ®é›†ä¸Šè¾¾åˆ°äº†75%çš„å‡†ç¡®ç‡ã€‚æ­¤å¤–ï¼Œè¯¥å·¥ä½œè¿˜å¼€å‘äº†å¯è§£é‡Šæ€§æ–¹æ³•(explainability methods)ï¼Œæ—¨åœ¨æ­ç¤ºè¾“å…¥è¯­è¨€ä¸­çš„å“ªäº›éƒ¨åˆ†å¯¹è¿™ä¸€æ£€æµ‹ç»“æœèµ·åˆ°äº†å…³é”®è´¡çŒ®ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†ç”Ÿæˆå¼æ¨¡å‹åœ¨æ•æ‰ç—…ç†æ€§è¯­è¨€ç‰¹å¾æ–¹é¢çš„æ½œåŠ›ï¼Œä¸ºè®¤çŸ¥éšœç¢çš„è¾…åŠ©è¯Šæ–­æä¾›äº†å…¨æ–°çš„è·¨æ¨¡æ€è§†è§’ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted at Interspeech 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09385v1",
      "published_date": "2025-08-12 23:00:36 UTC",
      "updated_date": "2025-08-12 23:00:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:09:55.556400+00:00"
    },
    {
      "arxiv_id": "2508.13180v1",
      "title": "Search-Time Data Contamination",
      "title_zh": "æœç´¢æ—¶æ•°æ®æ±¡æŸ“",
      "authors": [
        "Ziwen Han",
        "Meher Mankikar",
        "Julian Michael",
        "Zifan Wang"
      ],
      "abstract": "Data contamination refers to the leakage of evaluation data into model training data, resulting in overfitting to supposedly held-out test sets and compromising test validity. We identify an analogous issue, search-time contamination (STC), in evaluating search-based LLM agents which use tools to gather information from online sources when answering user queries. STC occurs when the retrieval step surfaces a source containing the test question (or a near-duplicate) alongside its answer, enabling agents to copy rather than genuinely infer or reason, undermining benchmark integrity. We find that HuggingFace, an online platform hosting evaluation datasets, appears among retrieved sources in search based agent logs. Consequently, agents often explicitly acknowledge discovering question answer pairs from HuggingFace within their reasoning chains. On three commonly used capability benchmarks: Humanity's Last Exam (HLE), SimpleQA, and GPQA, we demonstrate that for approximately 3% of questions, search-based agents directly find the datasets with ground truth labels on HuggingFace. When millions of evaluation queries target the same benchmark, even small, repeated leaks can accelerate the benchmark's obsolescence, shortening its intended lifecycle. After HuggingFace is blocked, we observe a drop in accuracy on the contaminated subset of approximately 15%. We further show through ablation experiments that publicly accessible evaluation datasets on HuggingFace may not be the sole source of STC. To this end, we conclude by proposing best practices for benchmark design and result reporting to address this novel form of leakage and ensure trustworthy evaluation of search-based LLM agents. To facilitate the auditing of evaluation results, we also publicly release the complete logs from our experiments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†æœç´¢æ—¶æ•°æ®æ±¡æŸ“ (Search-Time Data Contamination, STC) çš„æ¦‚å¿µï¼Œæ—¨åœ¨æ¢è®¨åŸºäºæœç´¢çš„ LLM agents åœ¨åˆ©ç”¨åœ¨çº¿èµ„æºå›ç­”é—®é¢˜æ—¶ï¼Œå› æ£€ç´¢åˆ°åŒ…å«æµ‹è¯•é¢˜ç›®åŠç­”æ¡ˆçš„æºæ–‡ä»¶è€Œå¯¼è‡´çš„è¯„ä¼°å¤±çœŸé—®é¢˜ã€‚ç ”ç©¶å‘ç°ï¼ŒHuggingFace ç­‰æ‰˜ç®¡è¯„ä¼°æ•°æ®é›†çš„å¹³å°å¸¸å‡ºç°åœ¨æ™ºèƒ½ä½“çš„æ£€ç´¢æ—¥å¿—ä¸­ï¼Œä½¿å…¶èƒ½å¤Ÿç›´æ¥å¤åˆ¶ç­”æ¡ˆè€Œéè¿›è¡ŒçœŸæ­£çš„é€»è¾‘æ¨ç†ã€‚åœ¨ Humanity's Last Exam (HLE)ã€SimpleQA å’Œ GPQA ç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼Œçº¦æœ‰ 3% çš„é—®é¢˜ä¼šè¢«æ™ºèƒ½ä½“ç›´æ¥æ£€ç´¢åˆ°åŸå§‹æ•°æ®é›†ï¼Œè€Œåœ¨å±è”½ HuggingFace æ¥æºåï¼Œå—æ±¡æŸ“å­é›†çš„å‡†ç¡®ç‡æ˜¾è‘—ä¸‹é™äº†çº¦ 15%ã€‚æ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®ï¼Œå…¬å¼€æ•°æ®é›†å¹¶é STC çš„å”¯ä¸€æ¥æºï¼Œè¿™ç§æ³„éœ²ä¼šä¸¥é‡ç¼©çŸ­åŸºå‡†æµ‹è¯•çš„ç”Ÿå‘½å‘¨æœŸå¹¶æŸå®³è¯„ä¼°çš„å¯ä¿¡åº¦ã€‚ä¸ºæ­¤ï¼Œç ”ç©¶è€…æå‡ºäº†é’ˆå¯¹åŸºå‡†æµ‹è¯•è®¾è®¡å’Œç»“æœæŠ¥å‘Šçš„æœ€ä½³å®è·µå»ºè®®ï¼Œå¹¶å…¬å¼€å‘å¸ƒäº†å®Œæ•´å®éªŒæ—¥å¿—ä»¥æ”¯æŒè¯„ä¼°å®¡è®¡ï¼Œä¸ºç¡®ä¿æœç´¢ç±»æ™ºèƒ½ä½“è¯„ä¼°çš„å…¬æ­£æ€§å¥ å®šäº†åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13180v1",
      "published_date": "2025-08-12 22:52:21 UTC",
      "updated_date": "2025-08-12 22:52:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:04.287750+00:00"
    },
    {
      "arxiv_id": "2508.09383v1",
      "title": "X-UniMotion: Animating Human Images with Expressive, Unified and Identity-Agnostic Motion Latents",
      "title_zh": "X-UniMotionï¼šåŸºäºè¡¨æ„ä¸°å¯Œã€ç»Ÿä¸€ä¸”èº«ä»½æ— å…³è¿åŠ¨æ½œè¡¨å¾çš„äººç‰©å›¾åƒåŠ¨ç”»ç”Ÿæˆ",
      "authors": [
        "Guoxian Song",
        "Hongyi Xu",
        "Xiaochen Zhao",
        "You Xie",
        "Tianpei Gu",
        "Zenan Li",
        "Chenxu Zhang",
        "Linjie Luo"
      ],
      "abstract": "We present X-UniMotion, a unified and expressive implicit latent representation for whole-body human motion, encompassing facial expressions, body poses, and hand gestures. Unlike prior motion transfer methods that rely on explicit skeletal poses and heuristic cross-identity adjustments, our approach encodes multi-granular motion directly from a single image into a compact set of four disentangled latent tokens -- one for facial expression, one for body pose, and one for each hand. These motion latents are both highly expressive and identity-agnostic, enabling high-fidelity, detailed cross-identity motion transfer across subjects with diverse identities, poses, and spatial configurations. To achieve this, we introduce a self-supervised, end-to-end framework that jointly learns the motion encoder and latent representation alongside a DiT-based video generative model, trained on large-scale, diverse human motion datasets. Motion-identity disentanglement is enforced via 2D spatial and color augmentations, as well as synthetic 3D renderings of cross-identity subject pairs under shared poses. Furthermore, we guide motion token learning with auxiliary decoders that promote fine-grained, semantically aligned, and depth-aware motion embeddings. Extensive experiments show that X-UniMotion outperforms state-of-the-art methods, producing highly expressive animations with superior motion fidelity and identity preservation.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† X-UniMotionï¼Œä¸€ç§ç”¨äºæ•´ä¸ªäººä½“åŠ¨ä½œçš„ç»Ÿä¸€ä¸”å¯Œæœ‰è¡¨ç°åŠ›çš„éšå¼æ½œå±‚è¡¨ç¤ºï¼ˆimplicit latent representationï¼‰ï¼Œæ¶µç›–äº†é¢éƒ¨è¡¨æƒ…ã€èº«ä½“å§¿æ€å’Œæ‰‹åŠ¿ã€‚è¯¥æ–¹æ³•å¼ƒç”¨äº†ä¼ ç»Ÿçš„æ˜¾å¼éª¨éª¼å§¿æ€ï¼Œå°†å•å›¾ä¸­çš„å¤šç²’åº¦åŠ¨ä½œç¼–ç ä¸ºé¢éƒ¨ã€èº«ä½“åŠåŒæ‰‹å…±å››ä¸ªè§£è€¦çš„æ½œå±‚ä»¤ç‰Œï¼ˆlatent tokensï¼‰ï¼Œå®ç°äº†å…·æœ‰èº«ä»½æ— å…³æ€§ï¼ˆidentity-agnosticï¼‰çš„é«˜ä¿çœŸè·¨èº«ä»½åŠ¨ä½œè¿ç§»ã€‚ç ”ç©¶æ„å»ºäº†ä¸€ä¸ªè‡ªç›‘ç£ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œå…±åŒè®­ç»ƒè¿åŠ¨ç¼–ç å™¨ä¸åŸºäº DiT çš„è§†é¢‘ç”Ÿæˆæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨ç©ºé—´å¢å¼ºã€åˆæˆ 3D æ¸²æŸ“åŠè¾…åŠ©è§£ç å™¨æ¥ç¡®ä¿åµŒå…¥çš„è§£è€¦æ€§ä¸è¯­ä¹‰å¯¹é½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒX-UniMotion åœ¨ç”Ÿæˆé«˜åº¦å†™å®çš„åŠ¨ç”»æ–¹é¢è¡¨ç°ä¼˜å¼‚ï¼Œå…¶åŠ¨ä½œä¿çœŸåº¦ï¼ˆmotion fidelityï¼‰å’Œèº«ä»½ä¿æŒæ•ˆæœæ˜¾è‘—è¶…è¶Šäº†ç°æœ‰çš„å…ˆè¿›æŠ€æœ¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09383v1",
      "published_date": "2025-08-12 22:47:20 UTC",
      "updated_date": "2025-08-12 22:47:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:04.883974+00:00"
    },
    {
      "arxiv_id": "2508.09381v1",
      "title": "What Can We Learn from Inter-Annotator Variability in Skin Lesion Segmentation?",
      "title_zh": "ä»çš®è‚¤ç—…å˜åˆ†å‰²çš„æ ‡æ³¨è€…é—´å˜å¼‚æ€§ä¸­ï¼Œæˆ‘ä»¬èƒ½å­¦åˆ°ä»€ä¹ˆï¼Ÿ",
      "authors": [
        "Kumar Abhishek",
        "Jeremy Kawahara",
        "Ghassan Hamarneh"
      ],
      "abstract": "Medical image segmentation exhibits intra- and inter-annotator variability due to ambiguous object boundaries, annotator preferences, expertise, and tools, among other factors. Lesions with ambiguous boundaries, e.g., spiculated or infiltrative nodules, or irregular borders per the ABCD rule, are particularly prone to disagreement and are often associated with malignancy. In this work, we curate IMA++, the largest multi-annotator skin lesion segmentation dataset, on which we conduct an in-depth study of variability due to annotator, malignancy, tool, and skill factors. We find a statistically significant (p<0.001) association between inter-annotator agreement (IAA), measured using Dice, and the malignancy of skin lesions. We further show that IAA can be accurately predicted directly from dermoscopic images, achieving a mean absolute error of 0.108. Finally, we leverage this association by utilizing IAA as a \"soft\" clinical feature within a multi-task learning objective, yielding a 4.2% improvement in balanced accuracy averaged across multiple model architectures and across IMA++ and four public dermoscopic datasets. The code is available at https://github.com/sfu-mial/skin-IAV.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†çš®è‚¤ç—…å˜åˆ†å‰²ä¸­ç”±äºè¾¹ç•Œæ¨¡ç³Šå’Œæ ‡æ³¨è€…æ°´å¹³å·®å¼‚å¯¼è‡´çš„æ ‡æ³¨è€…é—´å˜å¼‚æ€§(Inter-Annotator Variability)ã€‚ä½œè€…æ„å»ºäº†ç›®å‰è§„æ¨¡æœ€å¤§çš„å¤šæ ‡æ³¨è€…çš®è‚¤ç—…å˜åˆ†å‰²æ•°æ®é›†IMA++ï¼Œå¹¶å¯¹æ ‡æ³¨è€…ã€ç—…å˜æ¶æ€§ç¨‹åº¦ã€å·¥å…·åŠæŠ€èƒ½ç­‰å½±å“å› ç´ è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚å®éªŒå‘ç°ï¼Œåˆ©ç”¨Diceç³»æ•°è¡¡é‡çš„æ ‡æ³¨è€…é—´ä¸€è‡´æ€§(Inter-Annotator Agreement, IAA)ä¸çš®è‚¤ç—…å˜çš„æ¶æ€§ç¨‹åº¦(malignancy)ä¹‹é—´å­˜åœ¨æ˜¾è‘—çš„ç»Ÿè®¡å­¦å…³è”ã€‚ç ”ç©¶è¿›ä¸€æ­¥è¯æ˜å¯ä»¥ç›´æ¥ä»çš®è‚¤é•œå›¾åƒä¸­é¢„æµ‹IAAï¼Œå¹¶å®ç°0.108çš„å¹³å‡ç»å¯¹è¯¯å·®ã€‚é€šè¿‡å°†é¢„æµ‹çš„IAAä½œä¸ºå¤šä»»åŠ¡å­¦ä¹ (multi-task learning)ä¸­çš„â€œè½¯â€ä¸´åºŠç‰¹å¾ï¼Œè¯¥æ–¹æ³•åœ¨IMA++åŠå››ä¸ªå…¬å¼€æ•°æ®é›†ä¸Šçš„åˆ†ç±»å¹³è¡¡å‡†ç¡®ç‡å¹³å‡æå‡äº†4.2%ï¼Œè¯æ˜äº†åˆ©ç”¨æ ‡æ³¨å˜å¼‚æ€§æå‡æ¨¡å‹æ€§èƒ½çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Medical Image Computing and Computer-Assisted Intervention (MICCAI) ISIC Skin Image Analysis Workshop (MICCAI ISIC) 2025; 12 pages, 4 tables, 3 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09381v1",
      "published_date": "2025-08-12 22:37:56 UTC",
      "updated_date": "2025-08-12 22:37:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:13.387965+00:00"
    },
    {
      "arxiv_id": "2508.09378v1",
      "title": "APIO: Automatic Prompt Induction and Optimization for Grammatical Error Correction and Text Simplification",
      "title_zh": "APIOï¼šé¢å‘è¯­æ³•çº é”™ä¸æ–‡æœ¬ç®€åŒ–çš„è‡ªåŠ¨æç¤ºè¯å½’çº³ä¸ä¼˜åŒ–",
      "authors": [
        "Artem Chernodub",
        "Aman Saini",
        "Yejin Huh",
        "Vivek Kulkarni",
        "Vipul Raheja"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have enabled a wide range of natural language processing (NLP) tasks to be performed through simple prompt-based interactions. Consequently, several approaches have been proposed to engineer prompts that most effectively enable LLMs to perform a given task (e.g., chain-of-thought prompting). In settings with a well-defined metric to optimize model performance, automatic prompt optimization (APO) methods have been developed to refine a seed prompt. Advancing this line of research, we propose APIO, a simple but effective prompt induction and optimization approach for the tasks of Grammatical Error Correction (GEC) and Text Simplification, without relying on manually specified seed prompts. APIO achieves a new state-of-the-art performance for purely LLM-based prompting methods on these tasks. We make our data, code, prompts, and outputs publicly available.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† APIOï¼Œä¸€ç§é’ˆå¯¹è¯­æ³•çº é”™ (Grammatical Error Correction, GEC) å’Œæ–‡æœ¬ç®€åŒ– (Text Simplification) ä»»åŠ¡çš„è‡ªåŠ¨æç¤ºè¯è¯±å¯¼ä¸ä¼˜åŒ– (Automatic Prompt Induction and Optimization) æ–¹æ³•ã€‚ä¸ä¼ ç»Ÿçš„è‡ªåŠ¨æç¤ºè¯ä¼˜åŒ– (APO) æ–¹æ³•ä¸åŒï¼ŒAPIO æ— éœ€ä¾èµ–äººå·¥æŒ‡å®šçš„åˆå§‹ç§å­æç¤ºè¯ï¼Œå³å¯å®ç°é«˜æ•ˆçš„æç¤ºè¯ç”Ÿæˆä¸è¿­ä»£ã€‚è¯¥æ–¹æ³•æ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨å¤„ç†ç‰¹å®šè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡æ—¶ï¼Œæç¤ºè¯å·¥ç¨‹è¿‡äºä¾èµ–äººå·¥ç»éªŒçš„éš¾é¢˜ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒAPIO åœ¨ GEC å’Œæ–‡æœ¬ç®€åŒ–ä»»åŠ¡ä¸Šè¾¾åˆ°äº†çº¯ LLM æç¤ºè¯æ–¹æ³•çš„æ–°æœ€å…ˆè¿›æ€§èƒ½ (State-of-the-art)ã€‚é€šè¿‡å¼€æºæ•°æ®ã€ä»£ç ã€æç¤ºè¯å’Œè¾“å‡ºï¼Œè¯¥ç ”ç©¶ä¸ºè‡ªåŠ¨åŒ–æç¤ºè¯å·¥ç¨‹é¢†åŸŸæä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æ’‘å’Œå®è·µå‚è€ƒã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted for publication at Recent Advances in Natural Language Processing conference (RANLP 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.09378v1",
      "published_date": "2025-08-12 22:26:32 UTC",
      "updated_date": "2025-08-12 22:26:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:18.594425+00:00"
    },
    {
      "arxiv_id": "2508.09372v1",
      "title": "A Signer-Invariant Conformer and Multi-Scale Fusion Transformer for Continuous Sign Language Recognition",
      "title_zh": "é¢å‘è¿ç»­æ‰‹è¯­è¯†åˆ«çš„æ‰‹è¯­è€…æ— å…³ Conformer ä¸å¤šå°ºåº¦èåˆ Transformer",
      "authors": [
        "Md Rezwanul Haque",
        "Md. Milon Islam",
        "S M Taslim Uddin Raju",
        "Fakhri Karray"
      ],
      "abstract": "Continuous Sign Language Recognition (CSLR) faces multiple challenges, including significant inter-signer variability and poor generalization to novel sentence structures. Traditional solutions frequently fail to handle these issues efficiently. For overcoming these constraints, we propose a dual-architecture framework. For the Signer-Independent (SI) challenge, we propose a Signer-Invariant Conformer that combines convolutions with multi-head self-attention to learn robust, signer-agnostic representations from pose-based skeletal keypoints. For the Unseen-Sentences (US) task, we designed a Multi-Scale Fusion Transformer with a novel dual-path temporal encoder that captures both fine-grained posture dynamics, enabling the model's ability to comprehend novel grammatical compositions. Experiments on the challenging Isharah-1000 dataset establish a new standard for both CSLR benchmarks. The proposed conformer architecture achieves a Word Error Rate (WER) of 13.07% on the SI challenge, a reduction of 13.53% from the state-of-the-art. On the US task, the transformer model scores a WER of 47.78%, surpassing previous work. In the SignEval 2025 CSLR challenge, our team placed 2nd in the US task and 4th in the SI task, demonstrating the performance of these models. The findings validate our key hypothesis: that developing task-specific networks designed for the particular challenges of CSLR leads to considerable performance improvements and establishes a new baseline for further research. The source code is available at: https://github.com/rezwanh001/MSLR-Pose86K-CSLR-Isharah.",
      "tldr_zh": "é’ˆå¯¹è¿ç»­æ‰‹è¯­è¯†åˆ« (Continuous Sign Language Recognition, CSLR) ä¸­ç­¾ç½²è€…å·®å¼‚æ€§å¤§å’Œå¯¹æ–°å¥å­ç»“æ„æ³›åŒ–èƒ½åŠ›å·®çš„æŒ‘æˆ˜ï¼Œè¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŒæ¶æ„æ¡†æ¶ã€‚ä¸ºè§£å†³ç­¾ç½²è€…æ— å…³ (Signer-Independent, SI) é—®é¢˜ï¼Œç ”ç©¶è€…å¼€å‘äº† Signer-Invariant Conformerï¼Œåˆ©ç”¨å·ç§¯å’Œå¤šå¤´è‡ªæ³¨æ„åŠ›æœºåˆ¶ä»å§¿æ€éª¨éª¼å…³é”®ç‚¹ä¸­æå–é²æ£’çš„ç­¾ç½²è€…æ— å…³è¡¨å¾ã€‚é’ˆå¯¹æœªè§å¥å­ (Unseen-Sentences, US) ä»»åŠ¡ï¼Œè¯¥ç ”ç©¶è®¾è®¡äº†å¸¦æœ‰æ–°å‹åŒè·¯å¾„æ—¶é—´ç¼–ç å™¨çš„ Multi-Scale Fusion Transformerï¼Œæœ‰æ•ˆæ•æ‰ç»†ç²’åº¦å§¿æ€åŠ¨æ€ä»¥ç†è§£å¤æ‚çš„è¯­æ³•ç»„åˆã€‚å®éªŒåœ¨ Isharah-1000 æ•°æ®é›†ä¸Šè¯æ˜äº†è¯¥æ–¹æ¡ˆçš„ä¼˜è¶Šæ€§ï¼Œå…¶ä¸­ Conformer æ¶æ„åœ¨ SI ä»»åŠ¡ä¸­å®ç°äº† 13.07% çš„è¯é”™è¯¯ç‡ (Word Error Rate, WER)ï¼Œæ¯”ç°æœ‰æŠ€æœ¯é™ä½äº† 13.53%ã€‚åœ¨ US ä»»åŠ¡ä¸­ï¼Œè¯¥æ¨¡å‹ä¹Ÿä»¥ 47.78% çš„ WER åˆ·æ–°äº†çºªå½•ï¼Œå¹¶åœ¨ SignEval 2025 CSLR æŒ‘æˆ˜èµ›ä¸­åˆ†åˆ«å–å¾—ç¬¬äºŒå’Œç¬¬å››åçš„æˆç»©ã€‚è¯¥ç ”ç©¶éªŒè¯äº†ä¸º CSLR ç‰¹å®šæŒ‘æˆ˜è®¾è®¡ä¸“ç”¨ç½‘ç»œçš„é‡è¦æ€§ï¼Œä¸ºåç»­ç ”ç©¶ç¡®ç«‹äº†æ–°çš„åŸºå‡†ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for the IEEE/CVF International Conference on Computer Vision (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09372v1",
      "published_date": "2025-08-12 21:59:53 UTC",
      "updated_date": "2025-08-12 21:59:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:21.385641+00:00"
    },
    {
      "arxiv_id": "2508.09362v1",
      "title": "FusionEnsemble-Net: An Attention-Based Ensemble of Spatiotemporal Networks for Multimodal Sign Language Recognition",
      "title_zh": "FusionEnsemble-Netï¼šç”¨äºå¤šæ¨¡æ€æ‰‹è¯­è¯†åˆ«çš„åŸºäºæ³¨æ„åŠ›çš„æ—¶ç©ºç½‘ç»œé›†æˆ",
      "authors": [
        "Md. Milon Islam",
        "Md Rezwanul Haque",
        "S M Taslim Uddin Raju",
        "Fakhri Karray"
      ],
      "abstract": "Accurate recognition of sign language in healthcare communication poses a significant challenge, requiring frameworks that can accurately interpret complex multimodal gestures. To deal with this, we propose FusionEnsemble-Net, a novel attention-based ensemble of spatiotemporal networks that dynamically fuses visual and motion data to enhance recognition accuracy. The proposed approach processes RGB video and range Doppler map radar modalities synchronously through four different spatiotemporal networks. For each network, features from both modalities are continuously fused using an attention-based fusion module before being fed into an ensemble of classifiers. Finally, the outputs of these four different fused channels are combined in an ensemble classification head, thereby enhancing the model's robustness. Experiments demonstrate that FusionEnsemble-Net outperforms state-of-the-art approaches with a test accuracy of 99.44% on the large-scale MultiMeDaLIS dataset for Italian Sign Language. Our findings indicate that an ensemble of diverse spatiotemporal networks, unified by attention-based fusion, yields a robust and accurate framework for complex, multimodal isolated gesture recognition tasks. The source code is available at: https://github.com/rezwanh001/Multimodal-Isolated-Italian-Sign-Language-Recognition.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† FusionEnsemble-Netï¼Œè¿™æ˜¯ä¸€ç§åŸºäºæ³¨æ„åŠ›æœºåˆ¶(attention-based)çš„æ—¶ç©ºç½‘ç»œé›†æˆæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³åŒ»ç–—æ²Ÿé€šä¸­å¤æ‚å¤šæ¨¡æ€æ‰‹è¯­è¯†åˆ«çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åŒæ­¥å¤„ç† RGB è§†é¢‘å’Œè·ç¦»å¤šæ™®å‹’å›¾(range Doppler map)é›·è¾¾æ•°æ®ï¼Œé€šè¿‡å››ä¸ªä¸åŒçš„æ—¶ç©ºç½‘ç»œ(spatiotemporal networks)åŠ¨æ€èåˆè§†è§‰ä¸è¿åŠ¨ä¿¡æ¯ã€‚åœ¨æ¯ä¸ªç½‘ç»œå†…éƒ¨ï¼Œä¸¤ç§æ¨¡æ€çš„ç‰¹å¾åˆ©ç”¨æ³¨æ„åŠ›èåˆæ¨¡å—(attention-based fusion module)è¿›è¡ŒæŒç»­èåˆï¼Œéšåé€å…¥åˆ†ç±»å™¨é›†æˆã€‚æœ€ç»ˆï¼Œå››ä¸ªèåˆé€šé“çš„è¾“å‡ºé€šè¿‡é›†æˆåˆ†ç±»å¤´(ensemble classification head)è¿›è¡Œç»„åˆï¼Œä»è€Œæ˜¾è‘—æå‡äº†æ¨¡å‹çš„é²æ£’æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒFusionEnsemble-Net åœ¨å¤§è§„æ¨¡æ„å¤§åˆ©æ‰‹è¯­æ•°æ®é›† MultiMeDaLIS ä¸Šå–å¾—äº† 99.44% çš„æµ‹è¯•å‡†ç¡®ç‡ï¼Œæ€§èƒ½ä¼˜äºç°æœ‰æœ€å…ˆè¿›çš„æ–¹æ³•ã€‚ç ”ç©¶è¡¨æ˜ï¼Œè¿™ç§é€šè¿‡æ³¨æ„åŠ›èåˆç»Ÿä¸€å¤šæ ·åŒ–æ—¶ç©ºç½‘ç»œçš„é›†æˆç­–ç•¥ï¼Œä¸ºè§£å†³å¤æ‚å¤šæ¨¡æ€å­¤ç«‹æ‰‹åŠ¿è¯†åˆ«ä»»åŠ¡æä¾›äº†ä¸€ä¸ªç¨³å¥ä¸”ç²¾ç¡®çš„æœ‰æ•ˆæ¡†æ¶ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted for the IEEE/CVF International Conference on Computer Vision (ICCV), Honolulu, Hawaii, USA. 1st MSLR Workshop 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09362v1",
      "published_date": "2025-08-12 21:44:23 UTC",
      "updated_date": "2025-08-12 21:44:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:26.690510+00:00"
    },
    {
      "arxiv_id": "2508.10057v1",
      "title": "Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹åœ¨æŠ½è±¡æ¨ç†ä¸­å±•ç°å‡ºä¸äººç±»ç¥ç»è®¤çŸ¥çš„ä¸€è‡´æ€§è¿¹è±¡",
      "authors": [
        "Christopher Pinier",
        "Sonia AcuÃ±a Vargas",
        "Mariia Steeghs-Turchina",
        "Dora Matzke",
        "Claire E. Stevenson",
        "Michael D. Nunez"
      ],
      "abstract": "This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æŠ½è±¡æ¨ç†è¿‡ç¨‹ä¸­æ˜¯å¦ä¸äººç±»ç¥ç»è®¤çŸ¥å…·æœ‰ä¸€è‡´æ€§ï¼Œé€šè¿‡å¯¹æ¯”äººç±»ä¸å…«ä¸ªå¼€æº LLMs åœ¨æŠ½è±¡æ¨¡å¼è¡¥å…¨ä»»åŠ¡ï¼ˆabstract-pattern-completion taskï¼‰ä¸­çš„è¡¨ç°åŠç¥ç»è¡¨å¾ã€‚ç ”ç©¶ç»“åˆäº†è„‘ç”µå›¾ï¼ˆEEGï¼‰è®°å½•çš„æ³¨è§†ç›¸å…³ç”µä½ï¼ˆFRPsï¼‰è¿›è¡Œè·¨å­¦ç§‘åˆ†æï¼Œå‘ç°ä»…æœ‰ Qwen-2.5-72B å’Œ DeepSeek-R1-70B ç­‰çº¦ 700 äº¿å‚æ•°çš„å¤§å‹æ¨¡å‹åœ¨å‡†ç¡®ç‡å’Œéš¾åº¦åˆ†å¸ƒä¸Šä¸äººç±»è¡¨ç°ç›¸ä¼¼ã€‚å®éªŒè¡¨æ˜ï¼Œæ‰€æœ‰æµ‹è¯•çš„ LLMs ä¸­é—´å±‚å‡èƒ½å¯¹æŠ½è±¡æ¨¡å¼ç±»åˆ«è¿›è¡Œèšç±»ï¼Œä¸”å…¶ä»»åŠ¡æœ€ä¼˜å±‚çš„è¡¨å¾å‡ ä½•ç»“æ„ï¼ˆrepresentational geometriesï¼‰ä¸äººç±»é¢å¶ FRPs ä¹‹é—´å­˜åœ¨ä¸­åº¦æ­£ç›¸å…³ã€‚è¿™äº›å‘ç°æ­ç¤ºäº†ç”Ÿç‰©æ™ºèƒ½ä¸äººå·¥æ™ºèƒ½åœ¨å¤„ç†æŠ½è±¡æ¨¡å¼æ—¶å¯èƒ½å­˜åœ¨å…±äº«çš„è¡¨å¾ç©ºé—´ï¼Œä¸”è¯¥ç°è±¡åœ¨å…¶ä»–è„‘ç”µæµ‹é‡æŒ‡æ ‡ä¸­å¹¶æœªè§‚å¯Ÿåˆ°ã€‚è¯¥ç ”ç©¶ä¸º LLMs é•œåƒäººç±»å¤§è„‘æŠ½è±¡æ¨ç†æœºåˆ¶æä¾›äº†åˆæ­¥è¯æ®ï¼Œå±•ç¤ºäº†äººå·¥ç³»ç»Ÿä¸ç”Ÿç‰©ç¥ç»ç½‘ç»œåœ¨è®¤çŸ¥åŸç†ä¸Šçš„æ½œåœ¨äº¤é›†ã€‚",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "q-bio.NC",
      "comment": "Presented at the 8th Annual Conference on Cognitive Computational Neuroscience (August 12-15, 2025; Amsterdam, The Netherlands); 20 pages, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.10057v1",
      "published_date": "2025-08-12 21:38:46 UTC",
      "updated_date": "2025-08-12 21:38:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:38.397613+00:00"
    },
    {
      "arxiv_id": "2508.09349v1",
      "title": "The Human-AI Hybrid Delphi Model: A Structured Framework for Context-Rich, Expert Consensus in Complex Domains",
      "title_zh": "äººæœºæ··åˆå¾·å°”è²æ¨¡å‹ï¼šé’ˆå¯¹å¤æ‚é¢†åŸŸä¸­å¯Œå«è¯­å¢ƒä¸“å®¶å…±è¯†çš„ç»“æ„åŒ–æ¡†æ¶",
      "authors": [
        "Cathy Speed",
        "Ahmed A. Metwally"
      ],
      "abstract": "Expert consensus plays a critical role in domains where evidence is complex, conflicting, or insufficient for direct prescription. Traditional methods, such as Delphi studies, consensus conferences, and systematic guideline synthesis, offer structure but face limitations including high panel burden, interpretive oversimplification, and suppression of conditional nuance. These challenges are now exacerbated by information overload, fragmentation of the evidence base, and increasing reliance on publicly available sources that lack expert filtering. This study introduces and evaluates a Human-AI Hybrid Delphi (HAH-Delphi) framework designed to augment expert consensus development by integrating a generative AI model (Gemini 2.5 Pro), small panels of senior human experts, and structured facilitation. The HAH-Delphi was tested in three phases: retrospective replication, prospective comparison, and applied deployment in two applied domains (endurance training and resistance and mixed cardio/strength training). The AI replicated 95% of published expert consensus conclusions in Phase I and showed 95% directional agreement with senior human experts in Phase II, though it lacked experiential and pragmatic nuance. In Phase III, compact panels of six senior experts achieved >90% consensus coverage and reached thematic saturation before the final participant. The AI provided consistent, literature-grounded scaffolding that supported divergence resolution and accelerated saturation. The HAH-Delphi framework offers a flexible, scalable approach for generating high-quality, context-sensitive consensus. Its successful application across health, coaching, and performance science confirms its methodological robustness and supports its use as a foundation for generating conditional, personalised guidance and published consensus frameworks at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Human-AI Hybrid Delphi (HAH-Delphi) æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡é›†æˆç”Ÿæˆå¼äººå·¥æ™ºèƒ½æ¨¡å‹ Gemini 2.5 Pro ä¸äººç±»ä¸“å®¶å°ç»„ï¼Œæ”¹è¿›å¤æ‚é¢†åŸŸçš„ä¸“å®¶å…±è¯†å¼€å‘è¿‡ç¨‹ã€‚ä¼ ç»Ÿ Delphi æ–¹æ³•å¸¸é¢ä¸´ä¸“å®¶è´Ÿæ‹…é‡ã€è§£è¯»è¿‡äºç®€åŒ–åŠç¼ºä¹èƒŒæ™¯ç»†å¾®å·®åˆ«ç­‰å±€é™ï¼Œè€Œ HAH-Delphi é€šè¿‡ç»“æ„åŒ–å¼•å¯¼æœ‰æ•ˆç¼“è§£äº†ä¿¡æ¯è¿‡è½½å’Œè¯æ®ç¢ç‰‡çš„æŒ‘æˆ˜ã€‚å®éªŒåˆ†ä¸ºå›é¡¾æ€§å¤åˆ¶ã€å‰ç»æ€§å¯¹æ¯”åŠå®é™…åº”ç”¨éƒ¨ç½²ä¸‰ä¸ªé˜¶æ®µï¼Œåœ¨è€åŠ›è®­ç»ƒä¸åŠ›é‡è®­ç»ƒç­‰é¢†åŸŸè¿›è¡Œäº†éªŒè¯ã€‚ç»“æœæ˜¾ç¤ºï¼ŒAI åœ¨ç¬¬ä¸€é˜¶æ®µæˆåŠŸå¤åˆ¶äº† 95% çš„å·²å‘è¡¨å…±è¯†ï¼Œå¹¶åœ¨ç¬¬äºŒé˜¶æ®µä¸é«˜çº§ä¸“å®¶è¾¾æˆäº† 95% çš„æ–¹å‘æ€§ä¸€è‡´ã€‚åœ¨åº”ç”¨é˜¶æ®µï¼Œä»…éœ€ 6 åä¸“å®¶çš„ç²¾ç®€å°ç»„å³å¯å®ç°è¶…è¿‡ 90% çš„å…±è¯†è¦†ç›–ç‡ï¼ŒAI æä¾›çš„æ–‡çŒ®æ”¯æ’‘æ˜¾è‘—åŠ é€Ÿäº†ä¸»é¢˜é¥±å’Œåº¦ (thematic saturation) çš„è¾¾æˆã€‚è¯¥æ¡†æ¶è¯æ˜äº†å…¶åœ¨ç”Ÿæˆé«˜è´¨é‡ã€è¯­å¢ƒæ•æ„Ÿçš„å…±è¯†æ–¹é¢çš„ç¨³å¥æ€§ï¼Œä¸ºå¤§è§„æ¨¡ç”Ÿæˆæ¡ä»¶æ€§ã€ä¸ªæ€§åŒ–æŒ‡å¯¼æä¾›äº†çµæ´»ä¸”å¯æ‰©å±•çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09349v1",
      "published_date": "2025-08-12 21:24:19 UTC",
      "updated_date": "2025-08-12 21:24:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:31.701377+00:00"
    },
    {
      "arxiv_id": "2508.09340v1",
      "title": "Collective dynamics of strategic classification",
      "title_zh": "ç­–ç•¥æ€§åˆ†ç±»çš„é›†ä½“åŠ¨åŠ›å­¦",
      "authors": [
        "Marta C. Couto",
        "Flavia Barsotti",
        "Fernando P. Santos"
      ],
      "abstract": "Classification algorithms based on Artificial Intelligence (AI) are nowadays applied in high-stakes decisions in finance, healthcare, criminal justice, or education. Individuals can strategically adapt to the information gathered about classifiers, which in turn may require algorithms to be re-trained. Which collective dynamics will result from users' adaptation and algorithms' retraining? We apply evolutionary game theory to address this question. Our framework provides a mathematically rigorous way of treating the problem of feedback loops between collectives of users and institutions, allowing to test interventions to mitigate the adverse effects of strategic adaptation. As a case study, we consider institutions deploying algorithms for credit lending. We consider several scenarios, each representing different interaction paradigms. When algorithms are not robust against strategic manipulation, we are able to capture previous challenges discussed in the strategic classification literature, whereby users either pay excessive costs to meet the institutions' expectations (leading to high social costs) or game the algorithm (e.g., provide fake information). From this baseline setting, we test the role of improving gaming detection and providing algorithmic recourse. We show that increased detection capabilities reduce social costs and could lead to users' improvement; when perfect classifiers are not feasible (likely to occur in practice), algorithmic recourse can steer the dynamics towards high users' improvement rates. The speed at which the institutions re-adapt to the user's population plays a role in the final outcome. Finally, we explore a scenario where strict institutions provide actionable recourse to their unsuccessful users and observe cycling dynamics so far unnoticed in the literature.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æˆ˜ç•¥æ€§åˆ†ç±»(strategic classification)ä¸­çš„é›†ä½“åŠ¨åŠ›å­¦é—®é¢˜ï¼Œåˆ†æäº†åœ¨é‡‘èã€åŒ»ç–—ç­‰é«˜é£é™©å†³ç­–åœºæ™¯ä¸‹ï¼Œç”¨æˆ·ç­–ç•¥æ€§é€‚åº”åˆ†ç±»å™¨ä¸ç®—æ³•é‡æ–°è®­ç»ƒä¹‹é—´çš„åé¦ˆå¾ªç¯ã€‚ä½œè€…åˆ©ç”¨æ¼”åŒ–åšå¼ˆè®º(evolutionary game theory)å»ºç«‹äº†ä¸€ä¸ªä¸¥è°¨çš„æ•°å­¦æ¡†æ¶ï¼Œç”¨äºæµ‹è¯•ç¼“è§£ç”¨æˆ·ç­–ç•¥æ€§é€‚åº”è´Ÿé¢å½±å“çš„å¹²é¢„æªæ–½ã€‚ç ”ç©¶å‘ç°ï¼Œå½“ç®—æ³•ç¼ºä¹å¯¹æ“çºµçš„é²æ£’æ€§æ—¶ï¼Œç”¨æˆ·ä¼šæ‰¿æ‹…è¿‡é«˜çš„ç¤¾ä¼šæˆæœ¬æˆ–é€šè¿‡æä¾›è™šå‡ä¿¡æ¯ç­‰æ‰‹æ®µåšå¼ˆç®—æ³•(gaming the algorithm)ã€‚å®éªŒè¯æ˜ï¼Œå¢å¼ºåšå¼ˆæ£€æµ‹èƒ½åŠ›å¯é™ä½ç¤¾ä¼šæˆæœ¬ï¼Œè€Œç®—æ³•è¿½æº¯(algorithmic recourse)åœ¨æ— æ³•å®ç°å®Œç¾åˆ†ç±»å™¨çš„æƒ…å†µä¸‹èƒ½æ˜¾è‘—å¼•å¯¼ç”¨æˆ·æå‡ã€‚æ­¤å¤–ï¼Œæœºæ„é‡æ–°é€‚åº”ç”¨æˆ·ç¾¤ä½“çš„é€Ÿåº¦å¯¹æœ€ç»ˆç»“æœæœ‰é‡è¦å½±å“ã€‚è¯¥ç ”ç©¶è¿˜é¦–æ¬¡æ­ç¤ºäº†åœ¨ä¸¥æ ¼æœºæ„æä¾›å¯æ“ä½œæ€§è¿½æº¯çš„åœºæ™¯ä¸‹ï¼Œç³»ç»Ÿä¼šå‡ºç°ä»¥å¾€æ–‡çŒ®æœªæ›¾å‘ç°çš„å‘¨æœŸæ€§åŠ¨æ€(cycling dynamics)ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "34 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09340v1",
      "published_date": "2025-08-12 20:57:17 UTC",
      "updated_date": "2025-08-12 20:57:17 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:56.354740+00:00"
    },
    {
      "arxiv_id": "2508.09334v1",
      "title": "RicciFlowRec: A Geometric Root Cause Recommender Using Ricci Curvature on Financial Graphs",
      "title_zh": "RicciFlowRecï¼šåŸºäºé‡‘èå›¾ Ricci æ›²ç‡çš„å‡ ä½•æ ¹å› æ¨èç³»ç»Ÿ",
      "authors": [
        "Zhongtian Sun",
        "Anoushka Harit"
      ],
      "abstract": "We propose RicciFlowRec, a geometric recommendation framework that performs root cause attribution via Ricci curvature and flow on dynamic financial graphs. By modelling evolving interactions among stocks, macroeconomic indicators, and news, we quantify local stress using discrete Ricci curvature and trace shock propagation via Ricci flow. Curvature gradients reveal causal substructures, informing a structural risk-aware ranking function. Preliminary results on S\\&P~500 data with FinBERT-based sentiment show improved robustness and interpretability under synthetic perturbations. This ongoing work supports curvature-based attribution and early-stage risk-aware ranking, with plans for portfolio optimization and return forecasting. To our knowledge, RicciFlowRec is the first recommender to apply geometric flow-based reasoning in financial decision support.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RicciFlowRecï¼Œè¿™æ˜¯ä¸€ç§åˆ©ç”¨ Ricci curvature å’Œ flow åœ¨åŠ¨æ€é‡‘èå›¾ä¸Šè¿›è¡Œæ ¹å› å½’å› ï¼ˆroot cause attributionï¼‰çš„å‡ ä½•æ¨èæ¡†æ¶ã€‚è¯¥æ¨¡å‹é€šè¿‡æ¨¡æ‹Ÿè‚¡ç¥¨ã€å®è§‚ç»æµæŒ‡æ ‡å’Œæ–°é—»ä¹‹é—´çš„æ¼”åŒ–äº¤äº’ï¼Œåˆ©ç”¨ç¦»æ•£ Ricci curvature é‡åŒ–å±€éƒ¨å‹åŠ›ï¼Œå¹¶é€šè¿‡ Ricci flow è¿½è¸ªå†²å‡»ä¼ æ’­è¿‡ç¨‹ã€‚RicciFlowRec è¿›ä¸€æ­¥åˆ©ç”¨æ›²ç‡æ¢¯åº¦ï¼ˆCurvature gradientsï¼‰æ­ç¤ºå› æœå­ç»“æ„ï¼Œä»è€Œä¸ºå…·æœ‰ç»“æ„æ€§é£é™©æ„ŸçŸ¥çš„æ’åºå‡½æ•°ï¼ˆstructural risk-aware ranking functionï¼‰æä¾›å†³ç­–æ”¯æŒã€‚åˆæ­¥å®éªŒåœ¨ S&P 500 æ•°æ®ä¸Šç»“åˆ FinBERT æƒ…æ„Ÿåˆ†æè¿›è¡Œäº†éªŒè¯ï¼Œç»“æœè¡¨æ˜åœ¨åˆæˆæ‰°åŠ¨ä¸‹æ¨¡å‹è¡¨ç°å‡ºæ˜¾è‘—çš„é²æ£’æ€§å’Œå¯è§£é‡Šæ€§ã€‚è¯¥é¡¹å·¥ä½œç›®å‰æ”¯æŒåŸºäºæ›²ç‡çš„å½’å› å’Œæ—©æœŸé£é™©æ„ŸçŸ¥æ’åºï¼Œæœªæ¥è®¡åˆ’æ‰©å±•è‡³æŠ•èµ„ç»„åˆä¼˜åŒ–å’Œæ”¶ç›Šé¢„æµ‹é¢†åŸŸã€‚æ®ç ”ç©¶äººå‘˜æ‰€çŸ¥ï¼ŒRicciFlowRec æ˜¯é¦–ä¸ªåœ¨é‡‘èå†³ç­–æ”¯æŒä¸­å¼•å…¥å‡ ä½•æµæ¨ç†ï¼ˆgeometric flow-based reasoningï¼‰çš„æ¨èç³»ç»Ÿã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ACM RecSys 2025 (Late Breaking Results Track)",
      "pdf_url": "https://arxiv.org/pdf/2508.09334v1",
      "published_date": "2025-08-12 20:45:02 UTC",
      "updated_date": "2025-08-12 20:45:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:10:56.164651+00:00"
    },
    {
      "arxiv_id": "2508.21076v1",
      "title": "Pep2Prob Benchmark: Predicting Fragment Ion Probability for MS$^2$-based Proteomics",
      "title_zh": "Pep2Prob åŸºå‡†ï¼šåŸºäº MS$^2$ è›‹ç™½è´¨ç»„å­¦çš„ç¢ç‰‡ç¦»å­æ¦‚ç‡é¢„æµ‹",
      "authors": [
        "Hao Xu",
        "Zhichao Wang",
        "Shengqi Sang",
        "Pisit Wajanasara",
        "Nuno Bandeira"
      ],
      "abstract": "Proteins perform nearly all cellular functions and constitute most drug targets, making their analysis fundamental to understanding human biology in health and disease. Tandem mass spectrometry (MS$^2$) is the major analytical technique in proteomics that identifies peptides by ionizing them, fragmenting them, and using the resulting mass spectra to identify and quantify proteins in biological samples. In MS$^2$ analysis, peptide fragment ion probability prediction plays a critical role, enhancing the accuracy of peptide identification from mass spectra as a complement to the intensity information. Current approaches rely on global statistics of fragmentation, which assumes that a fragment's probability is uniform across all peptides. Nevertheless, this assumption is oversimplified from a biochemical principle point of view and limits accurate prediction. To address this gap, we present Pep2Prob, the first comprehensive dataset and benchmark designed for peptide-specific fragment ion probability prediction. The proposed dataset contains fragment ion probability statistics for 608,780 unique precursors (each precursor is a pair of peptide sequence and charge state), summarized from more than 183 million high-quality, high-resolution, HCD MS$^2$ spectra with validated peptide assignments and fragmentation annotations. We establish baseline performance using simple statistical rules and learning-based methods, and find that models leveraging peptide-specific information significantly outperform previous methods using only global fragmentation statistics. Furthermore, performance across benchmark models with increasing capacities suggests that the peptide-fragmentation relationship exhibits complex nonlinearities requiring sophisticated machine learning approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Pep2Probï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºé¢„æµ‹è´¨è°±è›‹ç™½è´¨ç»„å­¦ä¸­å¤šè‚½ç‰‡æ®µç¦»å­æ¦‚ç‡ï¼ˆfragment ion probabilityï¼‰çš„ç»¼åˆæ•°æ®é›†ä¸åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•ä¾èµ–å…¨å±€ç»Ÿè®¡ã€å‡è®¾ç‰‡æ®µæ¦‚ç‡åœ¨æ‰€æœ‰å¤šè‚½ä¸­å‡åŒ€åˆ†å¸ƒè€Œå¿½ç•¥ç”ŸåŒ–å¤æ‚æ€§çš„å±€é™ï¼ŒPep2Prob æä¾›äº†ä» 1.83 äº¿ä¸ªé«˜åˆ†è¾¨ç‡ HCD MS$^2$ å…‰è°±ä¸­å½’çº³å‡ºçš„ 608,780 ä¸ªå”¯ä¸€å‰ä½“ï¼ˆprecursorsï¼‰çš„è¯¦ç»†ç»Ÿè®¡æ•°æ®ã€‚ç ”ç©¶é€šè¿‡å¯¹æ¯”ç»Ÿè®¡è§„åˆ™ä¸å¤šç§å­¦ä¹ æ¨¡å‹ï¼Œè¯æ˜äº†åˆ©ç”¨å¤šè‚½ç‰¹å®šä¿¡æ¯ï¼ˆpeptide-specific informationï¼‰èƒ½æ˜¾è‘—ä¼˜äºä¼ ç»Ÿçš„å…¨å±€ç»Ÿè®¡æ–¹æ³•ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥æ­ç¤ºäº†å¤šè‚½ç¢ç‰‡åŒ–ï¼ˆfragmentationï¼‰å…³ç³»ä¸­å­˜åœ¨å¤æ‚çš„éçº¿æ€§ç‰¹å¾ï¼Œè¡¨æ˜è¯¥é¢†åŸŸéœ€è¦æ›´å…ˆè¿›çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚è¿™ä¸€åŸºå‡†çš„å»ºç«‹ä¸ºæé«˜è›‹ç™½è´¨ç»„å­¦ä¸­å¤šè‚½é‰´å®šçš„å‡†ç¡®æ€§æä¾›äº†é‡è¦çš„æ•°æ®æ”¯æ’‘å’Œç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.BM",
      "comment": "Dataset is available at HuggingFace: https://huggingface.co/datasets/bandeiralab/Pep2Prob",
      "pdf_url": "https://arxiv.org/pdf/2508.21076v1",
      "published_date": "2025-08-12 20:39:50 UTC",
      "updated_date": "2025-08-12 20:39:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:13.051905+00:00"
    },
    {
      "arxiv_id": "2508.09330v2",
      "title": "Synaptic Pruning: A Biological Inspiration for Deep Learning Regularization",
      "title_zh": "çªè§¦ä¿®å‰ªï¼šæ·±åº¦å­¦ä¹ æ­£åˆ™åŒ–çš„ç”Ÿç‰©å­¦å¯ç¤º",
      "authors": [
        "Gideon Vos",
        "Liza van Eijk",
        "Zoltan Sarnyai",
        "Mostafa Rahimi Azghadi"
      ],
      "abstract": "Synaptic pruning in biological brains removes weak connections to improve efficiency. In contrast, dropout regularization in artificial neural networks randomly deactivates neurons without considering activity-dependent pruning. We propose a magnitude-based synaptic pruning method that better reflects biology by progressively removing low-importance connections during training. Integrated directly into the training loop as a dropout replacement, our approach computes weight importance from absolute magnitudes across layers and applies a cubic schedule to gradually increase global sparsity. At fixed intervals, pruning masks permanently remove low-importance weights while maintaining gradient flow for active ones, eliminating the need for separate pruning and fine-tuning phases. Experiments on multiple time series forecasting models including RNN, LSTM, and Patch Time Series Transformer across four datasets show consistent gains. Our method ranked best overall, with statistically significant improvements confirmed by Friedman tests (p < 0.01). In financial forecasting, it reduced Mean Absolute Error by up to 20% over models with no or standard dropout, and up to 52% in select transformer models. This dynamic pruning mechanism advances regularization by coupling weight elimination with progressive sparsification, offering easy integration into diverse architectures. Its strong performance, especially in financial time series forecasting, highlights its potential as a practical alternative to conventional dropout techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶å—ç”Ÿç‰©å¤§è„‘çªè§¦å‰ªæ(Synaptic Pruning)çš„å¯å‘ï¼Œé’ˆå¯¹äººå·¥ç¥ç»ç½‘ç»œä¸­Dropoutéšæœºå¤±æ´»ç¥ç»å…ƒä¸”æœªè€ƒè™‘æ´»åŠ¨ä¾èµ–æ€§å‰ªæçš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¹…å€¼çš„çªè§¦å‰ªææ­£åˆ™åŒ–æ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†å‰ªææœºåˆ¶ç›´æ¥é›†æˆåˆ°è®­ç»ƒå¾ªç¯ä¸­ä»¥æ›¿ä»£Dropoutï¼Œé€šè¿‡è®¡ç®—è·¨å±‚æƒé‡çš„ç»å¯¹å¹…å€¼æ¥è¯„ä¼°é‡è¦æ€§ï¼Œå¹¶åˆ©ç”¨ç«‹æ–¹è°ƒåº¦(Cubic Schedule)é€æ­¥å¢åŠ å…¨å±€ç¨€ç–åº¦ã€‚åœ¨å›ºå®šé—´éš”å†…ï¼Œç³»ç»Ÿé€šè¿‡å‰ªææ©ç (Pruning Masks)æ°¸ä¹…ç§»é™¤ä½é‡è¦æ€§æƒé‡å¹¶ä¿æŒæ´»è·ƒæƒé‡çš„æ¢¯åº¦æµï¼Œä»è€Œæ¶ˆé™¤äº†ä¼ ç»Ÿæ–¹æ³•ä¸­å¯¹ç‹¬ç«‹å‰ªæå’Œå¾®è°ƒ(Fine-tuning)é˜¶æ®µçš„éœ€æ±‚ã€‚å®éªŒåœ¨RNNã€LSTMå’ŒPatch Time Series Transformerç­‰å¤šç§æ—¶é—´åºåˆ—é¢„æµ‹æ¨¡å‹ä¸Šè¿›è¡Œï¼Œç»“æœæ˜¾ç¤ºè¯¥æ–¹æ³•åœ¨å››ä¸ªæ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¸€è‡´çš„æ€§èƒ½å¢ç›Šã€‚å¼—é‡Œå¾·æ›¼æ£€éªŒ(Friedman tests)ç¡®è®¤äº†å…¶æ”¹è¿›å…·æœ‰æ˜¾è‘—çš„ç»Ÿè®¡å­¦æ„ä¹‰(p < 0.01)ï¼Œå°¤å…¶åœ¨é‡‘èé¢„æµ‹ä»»åŠ¡ä¸­ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”æ ‡å‡†Dropoutå¯å°†å¹³å‡ç»å¯¹è¯¯å·®(Mean Absolute Error)é™ä½è¾¾20%ï¼Œåœ¨ç‰¹å®šTransformeræ¨¡å‹ä¸­é™å¹…ç”šè‡³è¾¾åˆ°52%ã€‚è¿™ç§åŠ¨æ€å‰ªææœºåˆ¶é€šè¿‡å°†æƒé‡æ¶ˆé™¤ä¸æ¸è¿›ç¨€ç–åŒ–ç›¸ç»“åˆï¼Œä¸ºä¸åŒæ¶æ„æä¾›äº†æ˜“äºé›†æˆçš„æ­£åˆ™åŒ–æ–¹æ¡ˆï¼Œå±•ç°å‡ºä½œä¸ºä¼ ç»Ÿæ­£åˆ™åŒ–æŠ€æœ¯æ›¿ä»£æ–¹æ¡ˆçš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09330v2",
      "published_date": "2025-08-12 20:36:00 UTC",
      "updated_date": "2025-10-05 07:16:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:12.251069+00:00"
    },
    {
      "arxiv_id": "2508.09325v3",
      "title": "SegDAC: Improving Visual Reinforcement Learning by Extracting Dynamic Object-Centric Representations from Pretrained Vision Models",
      "title_zh": "SegDACï¼šé€šè¿‡ä»é¢„è®­ç»ƒè§†è§‰æ¨¡å‹ä¸­æå–åŠ¨æ€ä»¥ç‰©ä½“ä¸ºä¸­å¿ƒçš„è¡¨å¾æå‡è§†è§‰å¼ºåŒ–å­¦ä¹ ",
      "authors": [
        "Alexandre Brown",
        "Glen Berseth"
      ],
      "abstract": "Visual reinforcement learning (RL) is challenging due to the need to extract useful representations from high-dimensional inputs while learning effective control from sparse and noisy rewards. Although large perception models exist, integrating them effectively into RL for visual generalization and improved sample efficiency remains difficult. We propose SegDAC, a Segmentation-Driven Actor-Critic method. SegDAC uses Segment Anything (SAM) for object-centric decomposition and YOLO-World to ground the image segmentation process via text inputs. It includes a novel transformer-based architecture that supports a dynamic number of segments at each time step and effectively learns which segments to focus on using online RL, without using human labels. By evaluating SegDAC over a challenging visual generalization benchmark using Maniskill3, which covers diverse manipulation tasks under strong visual perturbations, we demonstrate that SegDAC achieves significantly better visual generalization, doubling prior performance on the hardest setting and matching or surpassing prior methods in sample efficiency across all evaluated tasks. Project Page: https://segdac.github.io/",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰å¼ºåŒ–å­¦ä¹  (Visual RL) åœ¨å¤„ç†é«˜ç»´è¾“å…¥å’Œç¨€ç–å™ªå£°å¥–åŠ±æ—¶é¢ä¸´çš„è¡¨ç¤ºæå–éš¾é¢˜ï¼Œæå‡ºäº†åä¸º SegDAC çš„åˆ†å‰²é©±åŠ¨æ¼”å‘˜-è¯„è®ºå®¶æ–¹æ³• (Segmentation-Driven Actor-Critic)ã€‚SegDAC åˆ©ç”¨ Segment Anything (SAM) æ¨¡å‹è¿›è¡Œä»¥å¯¹è±¡ä¸ºä¸­å¿ƒçš„è¡¨ç¤ºåˆ†è§£ï¼Œå¹¶ç»“åˆ YOLO-World é€šè¿‡æ–‡æœ¬è¾“å…¥å¯¹å›¾åƒåˆ†å‰²è¿‡ç¨‹è¿›è¡Œå®šä½ã€‚è¯¥æ–¹æ³•å¼•å…¥äº†ä¸€ç§åŸºäº Transformer çš„æ–°å‹æ¶æ„ï¼Œæ”¯æŒåœ¨æ¯ä¸ªæ—¶é—´æ­¥å¤„ç†åŠ¨æ€æ•°é‡çš„ç‰‡æ®µï¼Œå¹¶åˆ©ç”¨åœ¨çº¿å¼ºåŒ–å­¦ä¹  (Online RL) è‡ªåŠ¨å­¦ä¹ éœ€è¦å…³æ³¨çš„ç‰‡æ®µï¼Œæ— éœ€äººå·¥æ ‡ç­¾ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨ Maniskill3 è¿™ä¸€æå…·æŒ‘æˆ˜æ€§çš„è§†è§‰æ³›åŒ–åŸºå‡†ä¸Šè¿›è¡Œäº†è¯„ä¼°ï¼Œæ¶µç›–äº†å¼ºè§†è§‰å¹²æ‰°ä¸‹çš„å¤šç§æ“ä½œä»»åŠ¡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSegDAC æ˜¾è‘—æå‡äº†è§†è§‰æ³›åŒ–èƒ½åŠ›ï¼Œåœ¨æœ€å›°éš¾çš„è®¾ç½®ä¸‹æ€§èƒ½è¾¾åˆ°äº†æ­¤å‰æ–¹æ³•çš„ä¸€å€ï¼Œä¸”åœ¨æ‰€æœ‰è¯„ä¼°ä»»åŠ¡çš„æ ·æœ¬æ•ˆç‡ (Sample Efficiency) æ–¹é¢å‡è¾¾åˆ°æˆ–è¶…è¶Šäº†ç°æœ‰æŠ€æœ¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09325v3",
      "published_date": "2025-08-12 20:16:54 UTC",
      "updated_date": "2026-01-12 13:21:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:03.091133+00:00"
    },
    {
      "arxiv_id": "2508.09324v1",
      "title": "TEN: Table Explicitization, Neurosymbolically",
      "title_zh": "TENï¼šç¥ç»ç¬¦å·åŒ–è¡¨æ ¼æ˜¾æ€§åŒ–",
      "authors": [
        "Nikita Mehrotra",
        "Aayush Kumar",
        "Sumit Gulwani",
        "Arjun Radhakrishna",
        "Ashish Tiwari"
      ],
      "abstract": "We present a neurosymbolic approach, TEN, for extracting tabular data from semistructured input text. This task is particularly challenging for text input that does not use special delimiters consistently to separate columns and rows. Purely neural approaches perform poorly due to hallucinations and their inability to enforce hard constraints. TEN uses Structural Decomposition prompting - a specialized chain-of-thought prompting approach - on a large language model (LLM) to generate an initial table, and thereafter uses a symbolic checker to evaluate not only the well-formedness of that table, but also detect cases of hallucinations or forgetting. The output of the symbolic checker is processed by a critique-LLM to generate guidance for fixing the table, which is presented to the original LLM in a self-debug loop. Our extensive experiments demonstrate that TEN significantly outperforms purely neural baselines across multiple datasets and metrics, achieving significantly higher exact match accuracy and substantially reduced hallucination rates. A 21-participant user study further confirms that TEN's tables are rated significantly more accurate (mean score: 5.0 vs 4.3; p = 0.021), and are consistently preferred for ease of verification and correction, with participants favoring our method in over 60% of the cases.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†TENï¼Œä¸€ç§ç”¨äºä»åŠç»“æ„åŒ–æ–‡æœ¬ä¸­æå–è¡¨æ ¼æ•°æ®çš„ç¥ç»ç¬¦å·(neurosymbolic)æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³è¾“å…¥æ–‡æœ¬å› ç¼ºä¹ç»Ÿä¸€åˆ†éš”ç¬¦è€Œéš¾ä»¥æå–ç»“æ„åŒ–ä¿¡æ¯çš„æŒ‘æˆ˜ã€‚è¯¥æ–¹æ³•é€šè¿‡åœ¨LLMä¸Šåº”ç”¨ç»“æ„åˆ†è§£æç¤º(Structural Decomposition prompting)ç”Ÿæˆåˆå§‹è¡¨æ ¼ï¼Œå¹¶åˆ©ç”¨ç¬¦å·æ£€æŸ¥å™¨(symbolic checker)è¯„ä¼°è¡¨æ ¼çš„è§„èŒƒæ€§å¹¶æ£€æµ‹å¹»è§‰æˆ–é—æ¼ã€‚éšåï¼Œæ‰¹è¯„å¤§æ¨¡å‹(critique-LLM)æ ¹æ®æ£€æŸ¥ç»“æœç”Ÿæˆä¿®æ­£å»ºè®®ï¼Œå¼•å¯¼åŸå§‹æ¨¡å‹è¿›å…¥è‡ªæˆ‘è°ƒè¯•å¾ªç¯(self-debug loop)ä»¥æŒç»­ä¼˜åŒ–è¾“å‡ºã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒTENåœ¨å¤šé¡¹æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºçº¯ç¥ç»åŸºå‡†æ¨¡å‹ï¼Œå¤§å¹…æå‡äº†ç²¾ç¡®åŒ¹é…ç‡(exact match accuracy)å¹¶é™ä½äº†å¹»è§‰ç‡ã€‚æ­¤å¤–ï¼Œä¸€é¡¹åŒ…å«21åå‚ä¸è€…çš„ç”¨æˆ·ç ”ç©¶è¯å®ï¼ŒTENç”Ÿæˆçš„è¡¨æ ¼è¢«è®¤ä¸ºæ›´åŠ å‡†ç¡®ä¸”æ›´æ˜“äºéªŒè¯å’Œçº é”™ï¼Œåœ¨è¶…è¿‡60%çš„æƒ…å†µä¸‹è¢«ç”¨æˆ·ä¼˜å…ˆé€‰æ‹©ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09324v1",
      "published_date": "2025-08-12 20:16:41 UTC",
      "updated_date": "2025-08-12 20:16:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:13.462925+00:00"
    },
    {
      "arxiv_id": "2508.09323v2",
      "title": "Leveraging Large Language Models for Rare Disease Named Entity Recognition",
      "title_zh": "åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¿›è¡Œç½•è§ç—…å‘½åå®ä½“è¯†åˆ«",
      "authors": [
        "Nan Miles Xi",
        "Yu Deng",
        "Lin Wang"
      ],
      "abstract": "Named Entity Recognition (NER) in the rare disease domain poses unique challenges due to limited labeled data, semantic ambiguity between entity types, and long-tail distributions. In this study, we evaluate the capabilities of GPT-4o for rare disease NER under low-resource settings, using a range of prompt-based strategies including zero-shot prompting, few-shot in-context learning, retrieval-augmented generation (RAG), and task-level fine-tuning. We design a structured prompting framework that encodes domain-specific knowledge and disambiguation rules for four entity types. We further introduce two semantically guided few-shot example selection methods to improve in-context performance while reducing labeling effort. Experiments on the RareDis Corpus show that GPT-4o achieves competitive or superior performance compared to BioClinicalBERT, with task-level fine-tuning yielding the strongest performance among the evaluated approaches and improving upon the previously reported BioClinicalBERT baseline. Cost-performance analysis reveals that few-shot prompting delivers high returns at low token budgets. RAG provides limited overall gains but can improve recall for challenging entity types, especially signs and symptoms. An error taxonomy highlights common failure modes such as boundary drift and type confusion, suggesting opportunities for post-processing and hybrid refinement. Our results demonstrate that prompt-optimized LLMs can serve as effective, scalable alternatives to traditional supervised models in biomedical NER, particularly in rare disease applications where annotated data is scarce.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹ (Large Language Models) èƒŒæ™¯ä¸‹è§£å†³ç½•è§ç—…é¢†åŸŸå‘½åå®ä½“è¯†åˆ« (Named Entity Recognition, NER) é¢ä¸´çš„æ•°æ®ç¨€ç¼ºã€è¯­ä¹‰æ­§ä¹‰å’Œé•¿å°¾åˆ†å¸ƒæŒ‘æˆ˜ã€‚ç ”ç©¶è¯„ä¼°äº† GPT-4o åœ¨ä½èµ„æºè®¾å®šä¸‹çš„è¡¨ç°ï¼Œå¹¶å¯¹æ¯”äº†é›¶æ ·æœ¬æç¤º (zero-shot prompting)ã€å°‘æ ·æœ¬ä¸Šä¸‹æ–‡å­¦ä¹  (few-shot in-context learning)ã€æ£€ç´¢å¢å¼ºç”Ÿæˆ (Retrieval-Augmented Generation, RAG) ä»¥åŠä»»åŠ¡çº§å¾®è°ƒ (task-level fine-tuning) ç­‰ç­–ç•¥ã€‚ä½œè€…è®¾è®¡äº†ä¸€ä¸ªç»“æ„åŒ–çš„æç¤ºæ¡†æ¶ï¼Œæ•´åˆäº†ç‰¹å®šé¢†åŸŸçŸ¥è¯†å’Œæ¶ˆæ­§è§„åˆ™ï¼Œå¹¶å¼•å…¥äº†ä¸¤ç§è¯­ä¹‰å¼•å¯¼çš„å°‘æ ·æœ¬ç¤ºä¾‹é€‰æ‹©æ–¹æ³•ä»¥ä¼˜åŒ–æ€§èƒ½ã€‚åœ¨ RareDis Corpus ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGPT-4o çš„è¡¨ç°ä¼˜äº BioClinicalBERT åŸºçº¿æ¨¡å‹ï¼Œå…¶ä¸­ä»»åŠ¡çº§å¾®è°ƒè·å¾—äº†æœ€ä½³æ•ˆæœã€‚æˆæœ¬æ•ˆç›Šåˆ†æè¡¨æ˜å°‘æ ·æœ¬æç¤ºåœ¨ä½é¢„ç®—ä¸‹å›æŠ¥æé«˜ï¼Œè€Œ RAG è™½ç„¶æ•´ä½“æå‡æœ‰é™ï¼Œä½†æ˜¾è‘—æé«˜äº†å¦‚ signs and symptoms ç­‰æŒ‘æˆ˜æ€§å®ä½“çš„å¬å›ç‡ã€‚é€šè¿‡å¯¹è¾¹ç•Œåç§»å’Œç±»å‹æ··æ·†ç­‰é”™è¯¯ç±»å‹çš„åˆ†æï¼Œè¯¥ç ”ç©¶è¯æ˜äº†ç»è¿‡æç¤ºä¼˜åŒ–çš„ LLMs åœ¨æ ‡æ³¨æ•°æ®åŒ®ä¹çš„ç”Ÿç‰©åŒ»å­¦ NER ä»»åŠ¡ä¸­ï¼Œæ˜¯ä¼ ç»Ÿç›‘ç£å­¦ä¹ æ¨¡å‹çš„é«˜æ•ˆä¸”å¯æ‰©å±•çš„æ›¿ä»£æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09323v2",
      "published_date": "2025-08-12 20:16:31 UTC",
      "updated_date": "2025-12-29 16:39:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:23.655177+00:00"
    },
    {
      "arxiv_id": "2508.09320v2",
      "title": "Exact Verification of Graph Neural Networks with Incremental Constraint Solving",
      "title_zh": "åŸºäºå¢é‡å¼çº¦æŸæ±‚è§£çš„å›¾ç¥ç»ç½‘ç»œç²¾ç¡®éªŒè¯",
      "authors": [
        "Minghao Liu",
        "Chia-Hsuan Lu",
        "Marta Kwiatkowska"
      ],
      "abstract": "Graph neural networks (GNNs) are increasingly employed in high-stakes applications, such as fraud detection or healthcare, but are susceptible to adversarial attacks. A number of techniques have been proposed to provide adversarial robustness guarantees, but support for commonly used aggregation functions in message-passing GNNs is lacking. In this paper, we develop an exact (sound and complete) verification method for GNNs to compute guarantees against attribute and structural perturbations that involve edge addition or deletion, subject to budget constraints. Our method employs constraint solving with bound tightening, and iteratively solves a sequence of relaxed constraint satisfaction problems while relying on incremental solving capabilities of solvers to improve efficiency. We implement GNNev, a versatile exact verifier for message-passing neural networks, which supports three aggregation functions, sum, max and mean, with the latter two considered here for the first time. Extensive experimental evaluation of GNNev on real-world fraud datasets (Amazon and Yelp) and biochemical datasets (MUTAG and ENZYMES) demonstrates its usability and effectiveness, as well as superior performance for node classification and competitiveness on graph classification compared to existing exact verification tools on sum-aggregated GNNs.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›¾ç¥ç»ç½‘ç»œ (Graph Neural Networks, GNNs) æ˜“å—å¯¹æŠ—æ€§æ”»å‡»çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º GNNev çš„ç²¾ç¡® (sound and complete) éªŒè¯æ–¹æ³•ï¼Œæ—¨åœ¨ä¸ºå±æ€§å’Œç»“æ„æ‰°åŠ¨ï¼ˆå¦‚è¾¹æ·»åŠ æˆ–åˆ é™¤ï¼‰æä¾›é²æ£’æ€§ä¿è¯ã€‚è¯¥æ–¹æ³•é‡‡ç”¨äº†ç»“åˆè¾¹ç•Œæ”¶ç´§ (bound tightening) çš„çº¦æŸæ±‚è§£æŠ€æœ¯ï¼Œå¹¶é€šè¿‡å¢é‡æ±‚è§£ (incremental solving) èƒ½åŠ›è¿­ä»£å¤„ç†æ¾å¼›çš„çº¦æŸæ»¡è¶³é—®é¢˜ï¼Œä»è€Œæ˜¾è‘—æå‡äº†éªŒè¯æ•ˆç‡ã€‚GNNev æ”¯æŒåŒ…æ‹¬ sumã€max å’Œ mean åœ¨å†…çš„ä¸‰ç§æ¶ˆæ¯ä¼ é€’èšåˆå‡½æ•°ï¼Œå…¶ä¸­å¯¹ max å’Œ mean èšåˆçš„ç²¾ç¡®éªŒè¯å±é¦–æ¬¡å®ç°ã€‚åœ¨ Amazonã€Yelp ç­‰çœŸå®æ¬ºè¯ˆæ•°æ®é›†ä»¥åŠ MUTAGã€ENZYMES ç­‰ç”ŸåŒ–æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œè¯¥å·¥å…·åœ¨èŠ‚ç‚¹åˆ†ç±»ä»»åŠ¡ä¸Šè¡¨ç°å“è¶Šï¼Œåœ¨å›¾åˆ†ç±»ä»»åŠ¡ä¸Šä¹Ÿå…·å¤‡æå¼ºçš„ç«äº‰åŠ›ã€‚è¿™ä¸€æˆæœä¸ºé«˜é£é™©åº”ç”¨åœºæ™¯ä¸‹ GNNs çš„å¯¹æŠ—ç¨³å¥æ€§æä¾›äº†å¯é çš„æ•°å­¦è¯æ˜æ‰‹æ®µã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09320v2",
      "published_date": "2025-08-12 20:10:31 UTC",
      "updated_date": "2025-12-17 14:35:40 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:24.354924+00:00"
    },
    {
      "arxiv_id": "2508.09318v1",
      "title": "TPTP World Infrastructure for Non-classical Logics",
      "title_zh": "é¢å‘éç»å…¸é€»è¾‘çš„ TPTP World åŸºç¡€è®¾æ–½",
      "authors": [
        "Alexander Steen",
        "Geoff Sutcliffe"
      ],
      "abstract": "The TPTP World is the well established infrastructure that supports research, development, and deployment of Automated Theorem Proving (ATP) systems. The TPTP World supports a range of classical logics, and since release v9.0.0 has supported non-classical logics. This paper provides a self-contained comprehensive overview of the TPTP World infrastructure for ATP in non-classical logics: the non-classical language extension, problems and solutions, and tool support. A detailed description of use of the infrastructure for quantified normal multi-modal logic is given.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº† TPTP World è¿™ä¸€ç”¨äºæ”¯æŒè‡ªåŠ¨åŒ–å®šç†è¯æ˜(Automated Theorem Proving, ATP)ç³»ç»Ÿç ”å‘ä¸éƒ¨ç½²çš„æˆç†ŸåŸºç¡€è®¾æ–½ã€‚è®ºæ–‡é‡ç‚¹ä»‹ç»äº†è‡ª v9.0.0 ç‰ˆæœ¬ä»¥æ¥ï¼Œè¯¥å¹³å°å¯¹éç»å…¸é€»è¾‘(non-classical logics)æ‰©å±•çš„æ”¯æŒï¼Œå¹¶æä¾›äº†å…³äºå…¶æ¶æ„çš„å…¨é¢ç»¼è¿°ã€‚æ–‡ä¸­è¯¦ç»†é˜è¿°äº†éç»å…¸è¯­è¨€æ‰©å±•(non-classical language extension)ã€åŸºå‡†é—®é¢˜ä¸è§£æ³•é›†ä»¥åŠç›¸åº”çš„å·¥å…·æ”¯æŒä½“ç³»ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜æ·±å…¥åˆ†æäº†è¯¥åŸºç¡€è®¾æ–½åœ¨é‡åŒ–æ­£è§„æ¨¡æ€é€»è¾‘(quantified normal multi-modal logic)ä¸­çš„å…·ä½“åº”ç”¨å®è·µã€‚è¿™é¡¹å·¥ä½œä¸ºéç»å…¸é€»è¾‘é¢†åŸŸçš„ ATP ç ”ç©¶æä¾›äº†æ ‡å‡†åŒ–çš„æŠ€æœ¯æ¡†æ¶ï¼Œæœ‰æ•ˆä¿ƒè¿›äº†ç›¸å…³é€»è¾‘ç³»ç»Ÿçš„å¼€å‘ã€æµ‹è¯•ä¸æ€§èƒ½è¯„ä¼°ã€‚",
      "categories": [
        "cs.LO",
        "cs.AI"
      ],
      "primary_category": "cs.LO",
      "comment": "35 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09318v1",
      "published_date": "2025-08-12 20:05:52 UTC",
      "updated_date": "2025-08-12 20:05:52 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:24.652053+00:00"
    },
    {
      "arxiv_id": "2508.11697v1",
      "title": "Separating Knowledge and Perception with Procedural Data",
      "title_zh": "åˆ©ç”¨ç¨‹åºåŒ–æ•°æ®åˆ†ç¦»çŸ¥è¯†ä¸æ„ŸçŸ¥",
      "authors": [
        "AdriÃ¡n RodrÃ­guez-MuÃ±oz",
        "Manel Baradad",
        "Phillip Isola",
        "Antonio Torralba"
      ],
      "abstract": "We train representation models with procedural data only, and apply them on visual similarity, classification, and semantic segmentation tasks without further training by using visual memory -- an explicit database of reference image embeddings. Unlike prior work on visual memory, our approach achieves full compartmentalization with respect to all real-world images while retaining strong performance. Compared to a model trained on Places, our procedural model performs within $1\\%$ on NIGHTS visual similarity, outperforms by $8\\%$ and $15\\%$ on CUB200 and Flowers102 fine-grained classification, and is within $10\\%$ on ImageNet-1K classification. It also demonstrates strong zero-shot segmentation, achieving an $R^2$ on COCO within $10\\%$ of the models trained on real data. Finally, we analyze procedural versus real data models, showing that parts of the same object have dissimilar representations in procedural models, resulting in incorrect searches in memory and explaining the remaining performance gap.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¦‚ä½•ä»…ä½¿ç”¨ç¨‹åºåŒ–æ•°æ®(procedural data)è®­ç»ƒè¡¨ç¤ºæ¨¡å‹ï¼Œå¹¶åˆ©ç”¨è§†è§‰å­˜å‚¨å™¨(visual memory)â€”â€”å³æ˜¾å¼çš„å‚è€ƒå›¾åƒåµŒå…¥æ•°æ®åº“ï¼Œåœ¨ä¸è¿›è¡Œé¢å¤–è®­ç»ƒçš„æƒ…å†µä¸‹æ‰§è¡Œè§†è§‰ç›¸ä¼¼æ€§ã€åˆ†ç±»å’Œè¯­ä¹‰åˆ†å‰²ä»»åŠ¡ã€‚è¯¥æ–¹æ³•å®ç°äº†å¯¹æ‰€æœ‰ç°å®ä¸–ç•Œå›¾åƒçš„å®Œå…¨è§£è€¦(compartmentalization)ï¼ŒåŒæ—¶åœ¨å„é¡¹ä»»åŠ¡ä¸­ä¿æŒäº†å¼ºåŠ²çš„è¡¨ç¤ºèƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨NIGHTSè§†è§‰ç›¸ä¼¼æ€§ä»»åŠ¡ä¸Šä¸åœ¨Placesæ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹æ€§èƒ½å·®è·åœ¨1%ä»¥å†…ï¼Œåœ¨CUB200å’ŒFlowers102ç»†ç²’åº¦åˆ†ç±»ä»»åŠ¡ä¸Šåˆ†åˆ«å–å¾—äº†8%å’Œ15%çš„é¢†å…ˆï¼Œå¹¶åœ¨ImageNet-1Kå’ŒCOCOé›¶æ ·æœ¬åˆ†å‰²ä»»åŠ¡ä¸­è¾¾åˆ°äº†çœŸå®æ•°æ®æ¨¡å‹90%ä»¥ä¸Šçš„æ€§èƒ½æ°´å¹³ã€‚ç ”ç©¶æœ€åé€šè¿‡å¯¹æ¯”åˆ†æå‘ç°ï¼Œç¨‹åºåŒ–æ¨¡å‹ä¸­åŒä¸€ç‰©ä½“çš„ä¸åŒéƒ¨åˆ†å¾€å¾€è¡¨ç°å‡ºä¸ç›¸ä¼¼çš„ç‰¹å¾è¡¨ç¤ºï¼Œè¿™ä¼šå¯¼è‡´å­˜å‚¨å™¨æœç´¢è¿‡ç¨‹ä¸­çš„åå·®ï¼Œä»è€Œæ­ç¤ºäº†è¯¥æ–¹æ³•ä¸çœŸå®æ•°æ®æ¨¡å‹ä¹‹é—´æ€§èƒ½å·®è·çš„æ ¹æœ¬åŸå› ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 18 figures, 3 tables, to be published in ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.11697v1",
      "published_date": "2025-08-12 19:48:35 UTC",
      "updated_date": "2025-08-12 19:48:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:29.267447+00:00"
    },
    {
      "arxiv_id": "2508.09303v1",
      "title": "ParallelSearch: Train your LLMs to Decompose Query and Search Sub-queries in Parallel with Reinforcement Learning",
      "title_zh": "ParallelSearchï¼šåˆ©ç”¨å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹å®ç°å¹¶è¡ŒæŸ¥è¯¢åˆ†è§£ä¸å­æŸ¥è¯¢æœç´¢",
      "authors": [
        "Shu Zhao",
        "Tan Yu",
        "Anbang Xu",
        "Japinder Singh",
        "Aaditya Shukla",
        "Rama Akkiraju"
      ],
      "abstract": "Reasoning-augmented search agents such as Search-R1, trained via reinforcement learning with verifiable rewards (RLVR), demonstrate remarkable capabilities in multi-step information retrieval from external knowledge sources. These agents address the limitations of their parametric memory by dynamically gathering relevant facts to address complex reasoning tasks. However, existing approaches suffer from a fundamental architectural limitation: they process search queries strictly sequentially, even when handling inherently parallelizable and logically independent comparisons. This sequential bottleneck significantly constrains computational efficiency, particularly for queries that require multiple entity comparisons. To address this critical limitation, we propose ParallelSearch, a novel reinforcement learning framework that empowers large language models (LLMs) to recognize parallelizable query structures and execute multiple search operations concurrently. Our approach introduces dedicated reward functions that incentivize the identification of independent query components while preserving answer accuracy through jointly considering correctness, query decomposition quality, and parallel execution benefits. Comprehensive experiments demonstrate that ParallelSearch outperforms state-of-the-art baselines by an average performance gain of 2.9% across seven question-answering benchmarks. Notably, on parallelizable questions, our method achieves a 12.7% performance improvement while requiring only 69.6% of the LLM calls compared to sequential approaches.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ParallelSearchï¼Œè¿™æ˜¯ä¸€ç§å…¨æ–°çš„å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰æ¨ç†å¢å¼ºæœç´¢æ™ºèƒ½ä½“ï¼ˆå¦‚ Search-R1ï¼‰åœ¨å¤„ç†å¤æ‚æ£€ç´¢ä»»åŠ¡æ—¶å­˜åœ¨çš„ä¸²è¡Œæ‰§è¡Œç“¶é¢ˆã€‚ParallelSearch èµ‹èƒ½å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)è¯†åˆ«å¯å¹¶è¡Œçš„æŸ¥è¯¢ç»“æ„ï¼Œä»è€Œèƒ½å¤Ÿå¹¶å‘æ‰§è¡Œå¤šä¸ªç‹¬ç«‹çš„å­æŸ¥è¯¢æœç´¢æ“ä½œã€‚é€šè¿‡å¼•å…¥ä¸“é—¨çš„å¥–åŠ±å‡½æ•°(Reward Functions)ï¼Œè¯¥æ¡†æ¶åœ¨ä¿æŒç­”æ¡ˆå‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œä¼˜åŒ–äº†æŸ¥è¯¢åˆ†è§£è´¨é‡å¹¶å……åˆ†åˆ©ç”¨äº†å¹¶è¡Œæ‰§è¡Œçš„æ•ˆç‡ä¼˜åŠ¿ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒParallelSearch åœ¨ä¸ƒä¸ªé—®ç­”åŸºå‡†æµ‹è¯•ä¸­çš„å¹³å‡æ€§èƒ½æ¯”ç°æœ‰åŸºçº¿æ¨¡å‹æé«˜äº† 2.9%ã€‚å°¤å…¶åœ¨å¤„ç†å¯å¹¶è¡ŒåŒ–çš„é—®é¢˜æ—¶ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½æå‡ 12.7% çš„åŒæ—¶ï¼Œå…¶ LLM è°ƒç”¨é‡(LLM calls)ä»…ä¸ºä¸²è¡Œæ–¹æ³•çš„ 69.6%ï¼Œæ˜¾è‘—æå‡äº†è®¡ç®—æ•ˆç‡ä¸æ¨ç†æ£€ç´¢èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09303v1",
      "published_date": "2025-08-12 19:38:21 UTC",
      "updated_date": "2025-08-12 19:38:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:47.546877+00:00"
    },
    {
      "arxiv_id": "2508.09299v2",
      "title": "Decentralized Weather Forecasting via Distributed Machine Learning and Blockchain-Based Model Validation",
      "title_zh": "åŸºäºåˆ†å¸ƒå¼æœºå™¨å­¦ä¹ ä¸åŒºå—é“¾æ¨¡å‹éªŒè¯çš„å»ä¸­å¿ƒåŒ–å¤©æ°”é¢„æŠ¥",
      "authors": [
        "Rilwan Umar",
        "Aydin Abadi",
        "Basil Aldali",
        "Benito Vincent",
        "Elliot A. J. Hurley",
        "Hotoon Aljazaeri",
        "Jamie Hedley-Cook",
        "Jamie-Lee Bell",
        "Lambert Uwuigbusun",
        "Mujeeb Ahmed",
        "Shishir Nagaraja",
        "Suleiman Sabo",
        "Weaam Alrbeiqi"
      ],
      "abstract": "Weather forecasting plays a vital role in disaster preparedness, agriculture, and resource management, yet current centralized forecasting systems are increasingly strained by security vulnerabilities, limited scalability, and susceptibility to single points of failure. To address these challenges, we propose a decentralized weather forecasting framework that integrates Federated Learning (FL) with blockchain technology. FL enables collaborative model training without exposing sensitive local data; this approach enhances privacy and reduces data transfer overhead. Meanwhile, the Ethereum blockchain ensures transparent and dependable verification of model updates. To further enhance the system's security, we introduce a reputation-based voting mechanism that assesses the trustworthiness of submitted models while utilizing the Interplanetary File System (IPFS) for efficient off-chain storage. Experimental results demonstrate that our approach not only improves forecasting accuracy but also enhances system resilience and scalability, making it a viable candidate for deployment in real-world, security-critical environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»“åˆäº†è”é‚¦å­¦ä¹ (Federated Learning, FL)ä¸åŒºå—é“¾(blockchain)æŠ€æœ¯çš„å»ä¸­å¿ƒåŒ–å¤©æ°”é¢„æŠ¥æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿé›†ä¸­å¼é¢„æŠ¥ç³»ç»Ÿé¢ä¸´çš„å®‰å…¨æ€§æ¼æ´ã€æ‰©å±•æ€§æœ‰é™å’Œå•ç‚¹æ•…éšœ(single points of failure)ç­‰æŒ‘æˆ˜ã€‚åœ¨è¯¥æ¡†æ¶ä¸­ï¼Œè”é‚¦å­¦ä¹ (FL)å®ç°äº†æ— éœ€æš´éœ²åŸå§‹æ•°æ®çš„åä½œå¼æ¨¡å‹è®­ç»ƒï¼Œåœ¨å¢å¼ºæ•°æ®éšç§çš„åŒæ—¶é™ä½äº†ä¼ è¾“å¼€é”€ã€‚ä¸ºäº†ä¿éšœæ¨¡å‹æ›´æ–°çš„é€æ˜æ€§ä¸å¯é æ€§ï¼Œç³»ç»Ÿåˆ©ç”¨ä»¥å¤ªåŠ(Ethereum)åŒºå—é“¾è¿›è¡ŒéªŒè¯ï¼Œå¹¶å¼•å…¥äº†åŸºäºå£°èª‰çš„æŠ•ç¥¨æœºåˆ¶(reputation-based voting mechanism)æ¥è¯„ä¼°å‚ä¸è€…çš„å¯ä¿¡åº¦ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜ç»“åˆäº†æ˜Ÿé™…æ–‡ä»¶ç³»ç»Ÿ(IPFS)è¿›è¡Œé«˜æ•ˆçš„é“¾ä¸‹å­˜å‚¨ï¼Œè¿›ä¸€æ­¥å¼ºåŒ–äº†ç³»ç»Ÿçš„å®‰å…¨é˜²å¾¡èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ¡ˆåœ¨æé«˜é¢„æŠ¥å‡†ç¡®æ€§çš„åŒæ—¶ï¼Œæ˜¾è‘—æå‡äº†ç³»ç»Ÿçš„é²æ£’æ€§ä¸å¯æ‰©å±•æ€§ï¼Œä¸ºåœ¨å®‰å…¨æ•æ„Ÿç¯å¢ƒä¸‹éƒ¨ç½²å¤©æ°”é¢„æŠ¥ç³»ç»Ÿæä¾›äº†å¯è¡Œçš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09299v2",
      "published_date": "2025-08-12 19:25:34 UTC",
      "updated_date": "2025-08-14 07:18:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:50.857216+00:00"
    },
    {
      "arxiv_id": "2508.09297v3",
      "title": "Biased AI improves human decision-making but reduces trust",
      "title_zh": "æœ‰åè§çš„äººå·¥æ™ºèƒ½æå‡äº†äººç±»å†³ç­–èƒ½åŠ›ï¼Œä½†ä¼šé™ä½ä¿¡ä»»åº¦",
      "authors": [
        "Shiyang Lai",
        "Junsol Kim",
        "Nadav Kunievsky",
        "Yujin Potter",
        "James Evans"
      ],
      "abstract": "Current AI systems minimize risk by enforcing ideological neutrality, yet this may introduce automation bias by suppressing cognitive engagement in human decision-making. We conducted randomized trials with 2,500 participants to test whether culturally biased AI enhances human decision-making. Participants interacted with politically diverse GPT-4o variants on information evaluation tasks. Partisan AI assistants enhanced human performance, increased engagement, and reduced evaluative bias compared to non-biased counterparts, with amplified benefits when participants encountered opposing views. These gains carried a trust penalty: participants underappreciated biased AI and overcredited neutral systems. Exposing participants to two AIs whose biases flanked human perspectives closed the perception-performance gap. These findings complicate conventional wisdom about AI neutrality, suggesting that strategic integration of diverse cultural biases may foster improved and resilient human decision-making.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æ¢è®¨äº† AI ç³»ç»Ÿåœ¨å¼ºåˆ¶æ‰§è¡Œæ„è¯†å½¢æ€ä¸­ç«‹æ—¶å¯èƒ½å¯¼è‡´çš„äººç±»è®¤çŸ¥å‚ä¸åº¦é™ä½å’Œ Automation Bias é—®é¢˜ã€‚ç ”ç©¶äººå‘˜é€šè¿‡å¯¹ 2,500 åå‚ä¸è€…è¿›è¡Œéšæœºå¯¹ç…§è¯•éªŒï¼Œæµ‹è¯•äº†å…·æœ‰æ–‡åŒ–åå‘æ€§çš„ GPT-4o å˜ä½“åœ¨ä¿¡æ¯è¯„ä¼°ä»»åŠ¡ä¸­å¯¹å†³ç­–çš„å½±å“ã€‚ç»“æœæ˜¾ç¤ºï¼Œä¸ä¸­ç«‹çš„ AI ç›¸æ¯”ï¼Œå…·æœ‰å…šæ´¾åè§ï¼ˆPartisan AIï¼‰çš„åŠ©æ‰‹æå‡äº†äººç±»çš„ä»»åŠ¡è¡¨ç°ï¼Œå¢å¼ºäº†äº’åŠ¨å‚ä¸åº¦ï¼Œå¹¶æ˜¾è‘—é™ä½äº†è¯„ä»·åå·®ã€‚å½“å‚ä¸è€…é‡åˆ°ä¸å…¶æŒç›¸åè§‚ç‚¹çš„ AI æ—¶ï¼Œè¿™ç§æ€§èƒ½æå‡çš„æ•ˆç›Šæ›´ä¸ºæ˜æ˜¾ã€‚ç„¶è€Œï¼Œè¿™ç§æ”¶ç›Šä¼´éšç€ Trust Penaltyï¼Œå³å‚ä¸è€…å¾€å¾€ä½ä¼°åå‘æ€§ AI çš„ä»·å€¼ï¼Œè€Œè¿‡åº¦ä¿¡ä»»ä¸­ç«‹ç³»ç»Ÿã€‚ç ”ç©¶å‘ç°ï¼Œè®©å‚ä¸è€…åŒæ—¶æ¥è§¦ä¸¤ä¸ªç«‹åœºç›¸å¯¹çš„ AI å¯ä»¥æœ‰æ•ˆå¼¥åˆæ„ŸçŸ¥ä¸æ€§èƒ½ä¹‹é—´çš„å·®è·ã€‚è¯¥ç ”ç©¶æŒ‘æˆ˜äº†å…³äº AI Neutrality çš„ä¼ ç»Ÿè§‚ç‚¹ï¼Œè¡¨æ˜æˆ˜ç•¥æ€§åœ°æ•´åˆå¤šå…ƒæ–‡åŒ–åè§ï¼ˆCultural Biasesï¼‰å¯èƒ½æœ‰åŠ©äºåŸ¹å…»æ›´å…·éŸ§æ€§ä¸”æ›´ä¼˜çš„äººç±»å†³ç­–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09297v3",
      "published_date": "2025-08-12 19:20:43 UTC",
      "updated_date": "2025-08-19 22:58:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:53.464359+00:00"
    },
    {
      "arxiv_id": "2508.09294v1",
      "title": "Fake-Mamba: Real-Time Speech Deepfake Detection Using Bidirectional Mamba as Self-Attention's Alternative",
      "title_zh": "Fake-Mambaï¼šåŸºäºåŒå‘ Mamba æ›¿ä»£è‡ªæ³¨æ„åŠ›æœºåˆ¶çš„å®æ—¶è¯­éŸ³æ·±åº¦ä¼ªé€ æ£€æµ‹",
      "authors": [
        "Xi Xuan",
        "Zimo Zhu",
        "Wenxin Zhang",
        "Yi-Cheng Lin",
        "Tomi Kinnunen"
      ],
      "abstract": "Advances in speech synthesis intensify security threats, motivating real-time deepfake detection research. We investigate whether bidirectional Mamba can serve as a competitive alternative to Self-Attention in detecting synthetic speech. Our solution, Fake-Mamba, integrates an XLSR front-end with bidirectional Mamba to capture both local and global artifacts. Our core innovation introduces three efficient encoders: TransBiMamba, ConBiMamba, and PN-BiMamba. Leveraging XLSR's rich linguistic representations, PN-BiMamba can effectively capture the subtle cues of synthetic speech. Evaluated on ASVspoof 21 LA, 21 DF, and In-The-Wild benchmarks, Fake-Mamba achieves 0.97%, 1.74%, and 5.85% EER, respectively, representing substantial relative gains over SOTA models XLSR-Conformer and XLSR-Mamba. The framework maintains real-time inference across utterance lengths, demonstrating strong generalization and practical viability. The code is available at https://github.com/xuanxixi/Fake-Mamba.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Fake-Mambaï¼Œä¸€ç§ç”¨äºå®æ—¶è¯­éŸ³æ·±åº¦ä¼ªé€ æ£€æµ‹(speech deepfake detection)çš„æ–°å‹æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹å…ˆè¿›è¯­éŸ³åˆæˆæŠ€æœ¯å¸¦æ¥çš„å®‰å…¨æŒ‘æˆ˜ã€‚ç ”ç©¶å›¢é˜Ÿæ·±å…¥æ¢è®¨äº†ä½¿ç”¨åŒå‘Mamba (bidirectional Mamba) ä½œä¸ºè‡ªæ³¨æ„åŠ›æœºåˆ¶(Self-Attention)æ›¿ä»£æ–¹æ¡ˆçš„å¯è¡Œæ€§ï¼Œä»¥æ•æ‰éŸ³é¢‘ä¸­çš„å±€éƒ¨å’Œå…¨å±€ä¼ªé€ ç‰¹å¾ã€‚è¯¥æ–¹æ¡ˆé€šè¿‡é›†æˆXLSRå‰ç«¯ä¸åŒå‘Mambaï¼Œå¼•å…¥äº†TransBiMambaã€ConBiMambaå’ŒPN-BiMambaä¸‰ç§é«˜æ•ˆç¼–ç å™¨ï¼Œå…¶ä¸­PN-BiMambaåˆ©ç”¨XLSRä¸°å¯Œçš„è¯­è¨€è¡¨ç¤ºæœ‰æ•ˆæ•è·åˆæˆè¯­éŸ³çš„ç»†å¾®çº¿ç´¢ã€‚åœ¨ASVspoof 21 LAã€21 DFå’ŒIn-The-Wildç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼ŒFake-Mambaåˆ†åˆ«å–å¾—äº†0.97%ã€1.74%å’Œ5.85%çš„ç­‰é”™ç‡(EER)ï¼Œæ€§èƒ½æ˜¾è‘—è¶…è¶Šäº†XLSR-Conformerå’ŒXLSR-Mambaç­‰ç°æœ‰SOTAæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶åœ¨ä¸åŒé•¿åº¦çš„è¯­éŸ³è¾“å…¥ä¸‹å‡èƒ½ä¿æŒå®æ—¶æ¨ç†é€Ÿåº¦ï¼Œå±•ç°äº†å‡ºè‰²çš„æ³›åŒ–èƒ½åŠ›å’Œå®é™…åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "eess.SY"
      ],
      "primary_category": "eess.AS",
      "comment": "Accepted at IEEE ASRU 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09294v1",
      "published_date": "2025-08-12 19:15:13 UTC",
      "updated_date": "2025-08-12 19:15:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:12:00.052877+00:00"
    },
    {
      "arxiv_id": "2508.09293v1",
      "title": "Ethical Medical Image Synthesis",
      "title_zh": "ä¼¦ç†æ€§åŒ»å­¦å›¾åƒåˆæˆ",
      "authors": [
        "Weina Jin",
        "Ashish Sinha",
        "Kumar Abhishek",
        "Ghassan Hamarneh"
      ],
      "abstract": "The task of ethical Medical Image Synthesis (MISyn) is to ensure that the MISyn techniques are researched and developed ethically throughout their entire lifecycle, which is essential to prevent the negative impacts of MISyn. To address the ever-increasing needs and requirements for ethical practice of MISyn research and development, we first conduct a theoretical analysis that identifies the key properties of ethical MISyn and intrinsic limits of MISyn. We identify that synthetic images lack inherent grounding in real medical phenomena, cannot fully represent the training medical images, and inevitably introduce new distribution shifts and biases.\n  Ethical risks can arise from not acknowledging the intrinsic limits and weaknesses of synthetic images compared to medical images, with the extreme form manifested as misinformation of MISyn that substitutes synthetic images for medical images without acknowledgment. The resulting ethical harms include eroding trust in the medical imaging dataset environment and causing algorithmic discrimination towards stakeholders and the public.\n  To facilitate collective efforts towards ethical MISyn within and outside the medical image analysis community, we then propose practical supports for ethical practice in MISyn based on the theoretical analysis, including ethical practice recommendations that adapt the existing technical standards, problem formulation, design, and evaluation practice of MISyn to the ethical challenges; and oversight recommendations to facilitate checks and balances from stakeholders and the public. We also present two case studies that demonstrate how to apply the ethical practice recommendations in practice, and identify gaps between existing practice and the ethical practice recommendations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¼¦ç†åŒ»å­¦å›¾åƒåˆæˆ (Ethical Medical Image Synthesis, MISyn)ï¼Œæ—¨åœ¨ç¡®ä¿è¯¥æŠ€æœ¯åœ¨æ•´ä¸ªç”Ÿå‘½å‘¨æœŸå†…å¾—åˆ°ä¼¦ç†åŒ–çš„ç ”ç©¶ä¸å¼€å‘ï¼Œä»¥é˜²æ­¢æ½œåœ¨çš„è´Ÿé¢å½±å“ã€‚é€šè¿‡ç†è®ºåˆ†æï¼Œä½œè€…è¯†åˆ«äº† MISyn çš„æ ¸å¿ƒå±æ€§åŠå…¶å†…åœ¨å±€é™ï¼ŒæŒ‡å‡ºåˆæˆå›¾åƒåœ¨åŒ»å­¦ç°è±¡å…³è”æ€§ã€æ•°æ®ä»£è¡¨æ€§ä»¥åŠå¼•å…¥åˆ†å¸ƒåç§» (distribution shifts) å’Œåè§ (biases) æ–¹é¢å­˜åœ¨ç¼ºé™·ã€‚ç ”ç©¶å¼ºè°ƒï¼Œè‹¥ä¸æ‰¿è®¤è¿™äº›å¼±ç‚¹å¯èƒ½å¯¼è‡´ MISyn è¯¯å¯¼æ€§ä¿¡æ¯çš„ä¼ æ’­ï¼Œè¿›è€Œä¾µèš€å¯¹åŒ»å­¦æˆåƒæ•°æ®é›†ç¯å¢ƒçš„ä¿¡ä»»ï¼Œå¹¶å¼•å‘é’ˆå¯¹åˆ©ç›Šç›¸å…³è€…å’Œå…¬ä¼—çš„ç®—æ³•æ­§è§†ã€‚ä¸ºåº”å¯¹è¿™äº›ä¼¦ç†æŒ‘æˆ˜ï¼Œè®ºæ–‡æå‡ºäº†æ¶µç›–æŠ€æœ¯æ ‡å‡†ã€é—®é¢˜æ„å»ºã€ç³»ç»Ÿè®¾è®¡åŠè¯„ä¼°å®è·µçš„ä¼¦ç†å®è·µå»ºè®®ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æå‡ºäº†ç›‘ç£å»ºè®®ä»¥ä¿ƒè¿›åˆ©ç›Šç›¸å…³è€…çš„åˆ¶è¡¡ï¼Œå¹¶é€šè¿‡ä¸¤ä¸ªæ¡ˆä¾‹ç ”ç©¶å±•ç¤ºäº†å»ºè®®çš„åº”ç”¨ï¼ŒåŒæ—¶è¯†åˆ«äº†ç°æœ‰å®è·µä¸ä¼¦ç†è¦æ±‚ä¹‹é—´çš„å·®è·ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09293v1",
      "published_date": "2025-08-12 19:14:37 UTC",
      "updated_date": "2025-08-12 19:14:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:11:57.259871+00:00"
    },
    {
      "arxiv_id": "2508.09292v1",
      "title": "The Othello AI Arena: Evaluating Intelligent Systems Through Limited-Time Adaptation to Unseen Boards",
      "title_zh": "Othello AI Arenaï¼šé€šè¿‡å¯¹æœªè§æ£‹å±€çš„é™æ—¶é€‚åº”è¯„ä¼°æ™ºèƒ½ç³»ç»Ÿ",
      "authors": [
        "Sundong Kim"
      ],
      "abstract": "The ability to rapidly adapt to novel and unforeseen environmental changes is a cornerstone of artificial general intelligence (AGI), yet it remains a critical blind spot in most existing AI benchmarks. Traditional evaluation largely focuses on optimizing performance within fixed environments, failing to assess systems' flexibility and generalization capabilities when faced with even subtle rule or structural modifications. Addressing this gap, I introduce the Othello AI Arena, a novel benchmark framework designed to evaluate intelligent systems based on their capacity for limited-time adaptation to unseen environments. Our platform poses a meta-learning challenge: participants must develop systems that can analyze the specific configuration and rules of a novel Othello board within a strict time limit (60 seconds) and generate a tailored, high-performing strategy for that unique environment. With this, evaluation of the meta-level intelligence can be separated from the task-level strategy performance. The Arena features a diverse set of game stages, including public stages for development and private stages with structural and rule variations designed to test genuine adaptive and generalization capabilities. Implemented as an accessible web-based platform, the Arena provides real-time visualization, automated evaluation using multi-dimensional metrics, and comprehensive logging for post-hoc analysis. Initial observations from pilot tests and preliminary student engagements highlight fascinating patterns in adaptation approaches, ranging from rapid parameter tuning to rudimentary environmental model learning through simulation. The Othello AI Arena offers a unique educational tool and a valuable research benchmark for fostering and evaluating the crucial skill of rapid, intelligent adaptation in AI systems.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼•å…¥äº† Othello AI Arenaï¼Œè¿™æ˜¯ä¸€ç§å…¨æ–°çš„è¯„ä¼°æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ç°æœ‰ AI åŸºå‡†æµ‹è¯•åœ¨è¡¡é‡ç³»ç»Ÿå¯¹ç¯å¢ƒå˜åŒ–å¿«é€Ÿé€‚åº”èƒ½åŠ›æ–¹é¢çš„ä¸è¶³ã€‚é’ˆå¯¹é€šç”¨äººå·¥æ™ºèƒ½ (AGI) çš„æ ¸å¿ƒéœ€æ±‚ï¼Œè¯¥å¹³å°æå‡ºäº†ä¸€ä¸ª meta-learning æŒ‘æˆ˜ï¼Œè¦æ±‚æ™ºèƒ½ç³»ç»Ÿåœ¨ 60 ç§’çš„ä¸¥æ ¼æ—¶é™å†…åˆ†æå¹¶é€‚åº”å…¨æ–°çš„ Othello æ£‹ç›˜é…ç½®ä¸è§„åˆ™ã€‚é€šè¿‡è®¾ç½®åŒ…å«ç»“æ„å’Œè§„åˆ™å˜åŒ–çš„ç§æœ‰æµ‹è¯•é˜¶æ®µï¼Œè¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆåœ°å°† meta-level intelligence çš„è¯„ä¼°ä¸ç‰¹å®šä»»åŠ¡çš„ç­–ç•¥è¡¨ç°åˆ†ç¦»å¼€æ¥ã€‚è¯¥å¹³å°åŸºäº Web å¼€å‘ï¼Œé›†æˆäº†å®æ—¶å¯è§†åŒ–ã€å¤šç»´åº¦è‡ªåŠ¨åŒ–è¯„ä¼°æŒ‡æ ‡ä»¥åŠè¯¦å°½çš„æ—¥å¿—åˆ†æåŠŸèƒ½ã€‚åˆæ­¥å®éªŒè§‚å¯Ÿåˆ°ï¼Œç³»ç»Ÿåœ¨é€‚åº”è¿‡ç¨‹ä¸­å±•ç°å‡ºäº†ä»å¿«é€Ÿå‚æ•°å¾®è°ƒåˆ°åŸºäºæ¨¡æ‹Ÿçš„ç¯å¢ƒæ¨¡å‹å­¦ä¹ ç­‰å¤šç§ç­–ç•¥ã€‚è¯¥ç ”ç©¶ä¸ºè¯„ä¼°å’Œæ¨åŠ¨ AI ç³»ç»Ÿåœ¨æœªçŸ¥ç¯å¢ƒä¸­çš„ generalization èƒ½åŠ›å’Œå¿«é€Ÿæ™ºèƒ½é€‚åº”æŠ€å·§æä¾›äº†é‡è¦çš„ç ”ç©¶åŸºå‡†ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09292v1",
      "published_date": "2025-08-12 19:10:58 UTC",
      "updated_date": "2025-08-12 19:10:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:12:11.988289+00:00"
    },
    {
      "arxiv_id": "2508.09288v2",
      "title": "Can AI Keep a Secret? Contextual Integrity Verification: A Provable Security Architecture for LLMs",
      "title_zh": "AI èƒ½å¦ä¿å®ˆç§˜å¯†ï¼Ÿä¸Šä¸‹æ–‡å®Œæ•´æ€§éªŒè¯ï¼šä¸€ç§é¢å‘å¤§è¯­è¨€æ¨¡å‹çš„å¯è¯æ˜å®‰å…¨æ¶æ„",
      "authors": [
        "Aayush Gupta"
      ],
      "abstract": "Large language models (LLMs) remain acutely vulnerable to prompt injection and related jailbreak attacks; heuristic guardrails (rules, filters, LLM judges) are routinely bypassed. We present Contextual Integrity Verification (CIV), an inference-time security architecture that attaches cryptographically signed provenance labels to every token and enforces a source-trust lattice inside the transformer via a pre-softmax hard attention mask (with optional FFN/residual gating). CIV provides deterministic, per-token non-interference guarantees on frozen models: lower-trust tokens cannot influence higher-trust representations. On benchmarks derived from recent taxonomies of prompt-injection vectors (Elite-Attack + SoK-246), CIV attains 0% attack success rate under the stated threat model while preserving 93.1% token-level similarity and showing no degradation in model perplexity on benign tasks; we note a latency overhead attributable to a non-optimized data path. Because CIV is a lightweight patch -- no fine-tuning required -- we demonstrate drop-in protection for Llama-3-8B and Mistral-7B. We release a reference implementation, an automated certification harness, and the Elite-Attack corpus to support reproducible research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)æ˜“å—æç¤ºè¯æ³¨å…¥å’Œè¶Šç‹±æ”»å‡»ä¸”ä¼ ç»Ÿé˜²å¾¡æ‰‹æ®µæ˜“è¢«ç»•è¿‡çš„é—®é¢˜ï¼Œæå‡ºäº†Contextual Integrity Verification (CIV)æ¨ç†æ—¶å®‰å…¨æ¶æ„ã€‚CIVé€šè¿‡ä¸ºæ¯ä¸ªtokené™„åŠ åŠ å¯†ç­¾åçš„æ¥æºæ ‡ç­¾ï¼Œå¹¶åœ¨Transformerå†…éƒ¨åˆ©ç”¨pre-softmaxç¡¬æ³¨æ„åŠ›æ©ç (hard attention mask)å®æ–½æºä¿¡ä»»æ ¼çº¦æŸï¼Œä»è€Œæä¾›ç¡®å®šçš„éå¹²æ‰°ä¿è¯ã€‚è¯¥æœºåˆ¶ç¡®ä¿äº†ä½ä¿¡ä»»åº¦çš„tokenæ— æ³•å½±å“é«˜ä¿¡ä»»åº¦çš„è¡¨ç¤ºï¼Œå®ç°äº†åœ¨å†»ç»“æ¨¡å‹ä¸Šçš„å¯è¯æ˜å®‰å…¨æ€§ã€‚åœ¨Elite-Attackç­‰åŸºå‡†æµ‹è¯•ä¸­ï¼ŒCIVåœ¨å®ç°0%æ”»å‡»æˆåŠŸç‡çš„åŒæ—¶ï¼Œä¿ç•™äº†93.1%çš„tokençº§ç›¸ä¼¼åº¦ä¸”ä¸å½±å“æ¨¡å‹åœ¨è‰¯æ€§ä»»åŠ¡ä¸Šçš„å›°æƒ‘åº¦(perplexity)ã€‚ä½œä¸ºä¸€ç§æ— éœ€å¾®è°ƒçš„è½»é‡çº§è¡¥ä¸ï¼ŒCIVæ”¯æŒåœ¨Llama-3-8Bå’ŒMistral-7Bç­‰æ¨¡å‹ä¸­å³æ’å³ç”¨ï¼Œä¸ºLLMå®‰å…¨ç ”ç©¶æä¾›äº†å¯å¤ç°çš„å‚è€ƒå®ç°ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "2 figures, 3 tables; code and certification harness: https://github.com/ayushgupta4897/Contextual-Integrity-Verification ; Elite-Attack dataset: https://huggingface.co/datasets/zyushg/elite-attack",
      "pdf_url": "https://arxiv.org/pdf/2508.09288v2",
      "published_date": "2025-08-12 18:47:30 UTC",
      "updated_date": "2025-08-18 18:20:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:12:09.686100+00:00"
    },
    {
      "arxiv_id": "2508.09277v1",
      "title": "Value Function Initialization for Knowledge Transfer and Jump-start in Deep Reinforcement Learning",
      "title_zh": "æ·±åº¦å¼ºåŒ–å­¦ä¹ ä¸­é¢å‘çŸ¥è¯†è¿ç§»ä¸å¿«é€Ÿèµ·æ­¥çš„ä»·å€¼å‡½æ•°åˆå§‹åŒ–",
      "authors": [
        "Soumia Mehimeh"
      ],
      "abstract": "Value function initialization (VFI) is an effective way to achieve a jumpstart in reinforcement learning (RL) by leveraging value estimates from prior tasks. While this approach is well established in tabular settings, extending it to deep reinforcement learning (DRL) poses challenges due to the continuous nature of the state-action space, the noisy approximations of neural networks, and the impracticality of storing all past models for reuse. In this work, we address these challenges and introduce DQInit, a method that adapts value function initialization to DRL. DQInit reuses compact tabular Q-values extracted from previously solved tasks as a transferable knowledge base. It employs a knownness-based mechanism to softly integrate these transferred values into underexplored regions and gradually shift toward the agent's learned estimates, avoiding the limitations of fixed time decay. Our approach offers a novel perspective on knowledge transfer in DRL by relying solely on value estimates rather than policies or demonstrations, effectively combining the strengths of jumpstart RL and policy distillation while mitigating their drawbacks. Experiments across multiple continuous control tasks demonstrate that DQInit consistently improves early learning efficiency, stability, and overall performance compared to standard initialization and existing transfer techniques.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å¼ºåŒ–å­¦ä¹ (Deep Reinforcement Learning)ä¸­ä»·å€¼å‡½æ•°åˆå§‹åŒ–(Value Function Initialization)åœ¨è¿ç»­ç©ºé—´åŠæ¨¡å‹å­˜å‚¨æ–¹é¢çš„æŒ‘æˆ˜ï¼Œæå‡ºäº† DQInit æ–¹æ³•ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ä»å…ˆå‰ä»»åŠ¡ä¸­æå–çš„å‹ç¼©è¡¨æ ¼å‹ Q-values ä½œä¸ºå¯è¿ç§»çŸ¥è¯†åº“ï¼Œä»¥å®ç°é«˜æ•ˆçš„çŸ¥è¯†è¿ç§»å’Œå¿«é€Ÿèµ·æ­¥(Jump-start)ã€‚DQInit å¼•å…¥äº†ä¸€ç§åŸºäºå·²çŸ¥åº¦(Knownness-based)çš„æœºåˆ¶ï¼Œå°†è¿ç§»ä»·å€¼è½¯é›†æˆåˆ°æ¢ç´¢ä¸è¶³çš„åŒºåŸŸï¼Œå¹¶å¹³æ»‘åœ°è¿‡æ¸¡åˆ°æ™ºèƒ½ä½“çš„å­¦ä¹ ä¼°è®¡ï¼Œå…‹æœäº†å›ºå®šæ—¶é—´è¡°å‡çš„å±€é™æ€§ã€‚ä½œä¸ºä¸€ç§æ–°é¢–çš„è¿ç§»å­¦ä¹ è§†è§’ï¼Œè¯¥æ–¹æ³•ä»…ä¾èµ–ä»·å€¼ä¼°è®¡è€Œéç­–ç•¥(Policies)æˆ–æ¼”ç¤º(Demonstrations)ï¼Œæœ‰æ•ˆç»“åˆäº† Jump-start RL ä¸ç­–ç•¥è’¸é¦(Policy Distillation)çš„ä¼˜åŠ¿ã€‚å®éªŒè¯æ˜ï¼ŒDQInit åœ¨å¤šé¡¹è¿ç»­æ§åˆ¶ä»»åŠ¡ä¸­æ˜¾è‘—æå‡äº†æ—©æœŸå­¦ä¹ æ•ˆç‡ã€ç¨³å®šæ€§å’Œæ•´ä½“æ€§èƒ½ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09277v1",
      "published_date": "2025-08-12 18:32:08 UTC",
      "updated_date": "2025-08-12 18:32:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:12:08.396331+00:00"
    },
    {
      "arxiv_id": "2508.11695v1",
      "title": "RefAdGen: High-Fidelity Advertising Image Generation",
      "title_zh": "RefAdGenï¼šé«˜ä¿çœŸå¹¿å‘Šå›¾åƒç”Ÿæˆ",
      "authors": [
        "Yiyun Chen",
        "Weikai Yang"
      ],
      "abstract": "The rapid advancement of Artificial Intelligence Generated Content (AIGC) techniques has unlocked opportunities in generating diverse and compelling advertising images based on referenced product images and textual scene descriptions. This capability substantially reduces human labor and production costs in traditional marketing workflows. However, existing AIGC techniques either demand extensive fine-tuning for each referenced image to achieve high fidelity, or they struggle to maintain fidelity across diverse products, making them impractical for e-commerce and marketing industries. To tackle this limitation, we first construct AdProd-100K, a large-scale advertising image generation dataset. A key innovation in its construction is our dual data augmentation strategy, which fosters robust, 3D-aware representations crucial for realistic and high-fidelity image synthesis. Leveraging this dataset, we propose RefAdGen, a generation framework that achieves high fidelity through a decoupled design. The framework enforces precise spatial control by injecting a product mask at the U-Net input, and employs an efficient Attention Fusion Module (AFM) to integrate product features. This design effectively resolves the fidelity-efficiency dilemma present in existing methods. Extensive experiments demonstrate that RefAdGen achieves state-of-the-art performance, showcasing robust generalization by maintaining high fidelity and remarkable visual results for both unseen products and challenging real-world, in-the-wild images. This offers a scalable and cost-effective alternative to traditional workflows. Code and datasets are publicly available at https://github.com/Anonymous-Name-139/RefAdgen.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰äººå·¥æ™ºèƒ½ç”Ÿæˆå†…å®¹(AIGC)æŠ€æœ¯åœ¨ç”Ÿæˆå¹¿å‘Šå›¾åƒæ—¶é¢ä¸´çš„é«˜ä¿çœŸåº¦(high fidelity)ä¸å¾®è°ƒæ•ˆç‡ä¹‹é—´çš„çŸ›ç›¾ï¼Œæå‡ºäº†RefAdGenæ¡†æ¶ã€‚ä¸ºäº†æ”¯æŒé«˜è´¨é‡ç”Ÿæˆï¼Œç ”ç©¶å›¢é˜Ÿé¦–å…ˆæ„å»ºäº†å¤§è§„æ¨¡å¹¿å‘Šå›¾åƒç”Ÿæˆæ•°æ®é›†AdProd-100Kï¼Œå¹¶é€šè¿‡åŒé‡æ•°æ®å¢å¼ºç­–ç•¥(dual data augmentation)å¼ºåŒ–äº†æ¨¡å‹çš„3Dæ„ŸçŸ¥èƒ½åŠ›ã€‚RefAdGené‡‡ç”¨äº†è§£è€¦è®¾è®¡ï¼Œé€šè¿‡åœ¨U-Netè¾“å…¥ç«¯æ³¨å…¥äº§å“æ©è†œ(product mask)å®ç°ç²¾å‡†çš„ç©ºé—´æ§åˆ¶ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†é«˜æ•ˆçš„æ³¨æ„åŠ›èåˆæ¨¡å—(Attention Fusion Module, AFM)æ¥æ•´åˆäº§å“ç‰¹å¾ï¼Œç¡®ä¿äº†ç”Ÿæˆçš„çœŸå®æ„Ÿä¸ç»†èŠ‚è¿˜åŸã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRefAdGenåœ¨å¤„ç†æœªè§è¿‡çš„äº§å“åŠå¤æ‚çš„é‡å¤–(in-the-wild)å›¾åƒæ—¶å‡è¾¾åˆ°äº†æœ€å…ˆè¿›(state-of-the-art)çš„æ°´å¹³ã€‚è¯¥æ–¹æ¡ˆä¸ºä¼ ç»Ÿè¥é”€æµç¨‹æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å…·æœ‰æˆæœ¬æ•ˆç›Šçš„æ›¿ä»£æ–¹æ¡ˆï¼Œç›¸å…³ä»£ç ä¸æ•°æ®é›†å·²å…¬å¼€ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.11695v1",
      "published_date": "2025-08-12 18:25:31 UTC",
      "updated_date": "2025-08-12 18:25:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:12:14.891918+00:00"
    },
    {
      "arxiv_id": "2508.09264v1",
      "title": "Detection of Odor Presence via Deep Neural Networks",
      "title_zh": "åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„æ°”å‘³å­˜åœ¨æ£€æµ‹",
      "authors": [
        "Matin Hassanloo",
        "Ali Zareh",
        "Mehmet Kemal Ã–zdemir"
      ],
      "abstract": "Odor detection underpins food safety, environmental monitoring, medical diagnostics, and many more fields. The current artificial sensors developed for odor detection struggle with complex mixtures while non-invasive recordings lack reliable single-trial fidelity. To develop a general system for odor detection, in this study we present a preliminary work where we aim to test two hypotheses: (i) that spectral features of local field potentials (LFPs) are sufficient for robust single-trial odor detection and (ii) that signals from the olfactory bulb alone are adequate. To test two hypotheses, we propose an ensemble of complementary one-dimensional convolutional networks (ResCNN and AttentionCNN) that decodes the presence of odor from multichannel olfactory bulb LFPs. Tested on 2,349 trials from seven awake mice, our final ensemble model supports both hypotheses, achieving a mean accuracy of 86.6%, an F1-score of 81.0%, and an AUC of 0.9247, substantially outperforming previous benchmarks. In addition, the t-SNE visualization confirms that our framework captures biologically significant signatures. These findings establish the feasibility of robust single-trial detection of the presence of odor from extracellular LFPs, as well as demonstrate the potential of deep learning models to provide a deeper understanding of olfactory representations.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶é’ˆå¯¹äººå·¥ä¼ æ„Ÿå™¨åœ¨å¤„ç†å¤æ‚æ··åˆç‰©åŠéä¾µå…¥å¼è®°å½•ç¼ºä¹å•æ¬¡è¯•éªŒä¿çœŸåº¦ (single-trial fidelity) çš„é—®é¢˜ï¼Œæå‡ºäº†åˆ©ç”¨æ·±åº¦ç¥ç»ç½‘ç»œè¿›è¡Œæ°”å‘³æ£€æµ‹çš„æ–¹æ¡ˆã€‚ç ”ç©¶éªŒè¯äº†ä¸¤ä¸ªæ ¸å¿ƒå‡è®¾ï¼šä¸€æ˜¯å±€éƒ¨åœºç”µä½ (local field potentials, LFPs) çš„å…‰è°±ç‰¹å¾è¶³ä»¥å®ç°ç¨³å¥çš„å•æ¬¡è¯•éªŒæ°”å‘³æ£€æµ‹ï¼ŒäºŒæ˜¯ä»…æ¥è‡ªå—…çƒ (olfactory bulb) çš„ä¿¡å·å³å·²æ»¡è¶³æ£€æµ‹éœ€æ±‚ã€‚ä¸ºæ­¤ï¼Œä½œè€…å¼€å‘äº†ä¸€ä¸ªç»“åˆ ResCNN å’Œ AttentionCNN çš„ä¸€ç»´å·ç§¯é›†æˆç½‘ç»œï¼Œé€šè¿‡è§£ç å¤šé€šé“å—…çƒ LFPs æ¥åˆ¤æ–­æ°”å‘³çš„å­˜åœ¨ã€‚å®éªŒåœ¨ 2,349 æ¬¡å°é¼ è¯•éªŒæ•°æ®ä¸Šè¿›è¡Œï¼Œæ¨¡å‹è¾¾åˆ°äº† 86.6% çš„å¹³å‡å‡†ç¡®ç‡å’Œ 0.9247 çš„ AUCï¼Œæ€§èƒ½å¤§å¹…ä¼˜äºæ­¤å‰åŸºå‡†ã€‚t-SNE å¯è§†åŒ–åˆ†æè¿›ä¸€æ­¥ç¡®è®¤äº†è¯¥æ¡†æ¶èƒ½å¤Ÿæ•æ‰åˆ°å…·æœ‰ç”Ÿç‰©å­¦æ„ä¹‰çš„å…³é”®ç‰¹å¾ã€‚è¯¥æˆæœè¯æ˜äº†åˆ©ç”¨ç»†èƒå¤– LFPs è¿›è¡Œç¨³å¥å•æ¬¡æ°”å‘³æ£€æµ‹çš„å¯è¡Œæ€§ï¼Œå¹¶ä½“ç°äº†æ·±åº¦å­¦ä¹ åœ¨æ­ç¤ºå—…è§‰è¡¨å¾ (olfactory representations) æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09264v1",
      "published_date": "2025-08-12 18:14:24 UTC",
      "updated_date": "2025-08-12 18:14:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:12:33.485544+00:00"
    },
    {
      "arxiv_id": "2508.09138v3",
      "title": "Time Is a Feature: Exploiting Temporal Dynamics in Diffusion Language Models",
      "title_zh": "æ—¶é—´å³ç‰¹å¾ï¼šåˆ©ç”¨æ‰©æ•£è¯­è¨€æ¨¡å‹ä¸­çš„æ—¶é—´åŠ¨æ€",
      "authors": [
        "Wen Wang",
        "Bozhen Fang",
        "Chenchen Jing",
        "Yongliang Shen",
        "Yangyi Shen",
        "Qiuyu Wang",
        "Hao Ouyang",
        "Hao Chen",
        "Chunhua Shen"
      ],
      "abstract": "Diffusion large language models (dLLMs) generate text through iterative denoising, yet current decoding strategies discard rich intermediate predictions in favor of the final output. Our work here reveals a critical phenomenon, temporal oscillation, where correct answers often emerge in the middle process, but are overwritten in later denoising steps. To address this issue, we introduce two complementary methods that exploit temporal consistency: 1) Temporal Self-Consistency Voting, a training-free, test-time decoding strategy that aggregates predictions across denoising steps to select the most consistent output; and 2) a post-training method termed Temporal Consistency Reinforcement, which uses Temporal Semantic Entropy (TSE), a measure of semantic stability across intermediate predictions, as a reward signal to encourage stable generations. Empirical results across multiple benchmarks demonstrate the effectiveness of our approach. Using the negative TSE reward alone, we observe a remarkable average improvement of 24.7% on the Countdown dataset over an existing dLLM. Combined with the accuracy reward, we achieve absolute gains of 2.0% on GSM8K, 4.3% on MATH500, 6.6% on SVAMP, and 25.3% on Countdown, respectively. Our findings underscore the untapped potential of temporal dynamics in dLLMs and offer two simple yet effective tools to harness them.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ‰©æ•£å¤§è¯­è¨€æ¨¡å‹ (Diffusion Large Language Models, dLLMs) åœ¨è¿­ä»£å»å™ªè¿‡ç¨‹ä¸­çš„æ—¶é—´åŠ¨åŠ›å­¦ç‰¹æ€§ï¼Œå¹¶æ­ç¤ºäº†æ­£ç¡®ç­”æ¡ˆå¸¸åœ¨ä¸­é—´æ­¥éª¤å‡ºç°å´åœ¨åç»­è¢«è¦†ç›–çš„â€œæ—¶é—´æŒ¯è¡â€ (Temporal Oscillation) ç°è±¡ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº†ä¸¤ç§åˆ©ç”¨æ—¶é—´ä¸€è‡´æ€§çš„äº’è¡¥æ–¹æ³•ã€‚ç¬¬ä¸€ç§æ˜¯ Temporal Self-Consistency Votingï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒçš„è§£ç ç­–ç•¥ï¼Œé€šè¿‡èšåˆå¤šä¸ªå»å™ªæ­¥éª¤çš„é¢„æµ‹æ¥ç­›é€‰æœ€ä¸€è‡´çš„è¾“å‡ºã€‚ç¬¬äºŒç§æ˜¯åä¸º Temporal Consistency Reinforcement çš„è®­ç»ƒåæ–¹æ³•ï¼Œå®ƒå°† Temporal Semantic Entropy (TSE) ä½œä¸ºå¥–åŠ±ä¿¡å·ä»¥é¼“åŠ±ç”Ÿæˆè¿‡ç¨‹çš„è¯­ä¹‰ç¨³å®šæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ Countdownã€GSM8Kã€MATH500 åŠ SVAMP ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¯¥ç ”ç©¶å¼ºè°ƒäº† dLLMs ä¸­æ—¶é—´åŠ¨æ€ç‰¹å¾çš„æœªå¼€å‘æ½œåŠ›ï¼Œå¹¶ä¸ºå¢å¼ºæ‰©æ•£æ¨¡å‹çš„ç”Ÿæˆèƒ½åŠ›æä¾›äº†ç®€å•æœ‰æ•ˆçš„å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Project webpage: https://aim-uofa.github.io/dLLM-MidTruth",
      "pdf_url": "https://arxiv.org/pdf/2508.09138v3",
      "published_date": "2025-08-12 17:59:57 UTC",
      "updated_date": "2025-10-06 14:46:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:00.198195+00:00"
    },
    {
      "arxiv_id": "2508.09131v2",
      "title": "Training-Free Text-Guided Color Editing with Multi-Modal Diffusion Transformer",
      "title_zh": "åŸºäºå¤šæ¨¡æ€æ‰©æ•£ Transformer çš„å…è®­ç»ƒæ–‡æœ¬å¼•å¯¼é¢œè‰²ç¼–è¾‘",
      "authors": [
        "Zixin Yin",
        "Xili Dai",
        "Ling-Hao Chen",
        "Deyu Zhou",
        "Jianan Wang",
        "Duomin Wang",
        "Gang Yu",
        "Lionel M. Ni",
        "Lei Zhang",
        "Heung-Yeung Shum"
      ],
      "abstract": "Text-guided color editing in images and videos is a fundamental yet unsolved problem, requiring fine-grained manipulation of color attributes, including albedo, light source color, and ambient lighting, while preserving physical consistency in geometry, material properties, and light-matter interactions. Existing training-free methods offer broad applicability across editing tasks but struggle with precise color control and often introduce visual inconsistency in both edited and non-edited regions. In this work, we present ColorCtrl, a training-free color editing method that leverages the attention mechanisms of modern Multi-Modal Diffusion Transformers (MM-DiT). By disentangling structure and color through targeted manipulation of attention maps and value tokens, our method enables accurate and consistent color editing, along with word-level control of attribute intensity. Our method modifies only the intended regions specified by the prompt, leaving unrelated areas untouched. Extensive experiments on both SD3 and FLUX.1-dev demonstrate that ColorCtrl outperforms existing training-free approaches and achieves state-of-the-art performances in both edit quality and consistency. Furthermore, our method surpasses strong commercial models such as FLUX.1 Kontext Max and GPT-4o Image Generation in terms of consistency. When extended to video models like CogVideoX, our approach exhibits greater advantages, particularly in maintaining temporal coherence and editing stability. Finally, our method also generalizes to instruction-based editing diffusion models such as Step1X-Edit and FLUX.1 Kontext dev, further demonstrating its versatility.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ColorCtrlï¼Œä¸€ç§æ— éœ€è®­ç»ƒçš„ (training-free) æ–‡æœ¬å¼•å¯¼é¢œè‰²ç¼–è¾‘æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å›¾åƒå’Œè§†é¢‘ä¸­ç»†ç²’åº¦é¢œè‰²å±æ€§æ“çºµä¸ç‰©ç†ä¸€è‡´æ€§ä¿æŒä¹‹é—´çš„éš¾é¢˜ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ç°ä»£å¤šæ¨¡æ€æ‰©æ•£ Transformer (Multi-Modal Diffusion Transformers, MM-DiT) çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œé€šè¿‡é’ˆå¯¹æ€§åœ°æ“ä½œæ³¨æ„åŠ›å›¾ (attention maps) å’Œæ•°å€¼ä»¤ç‰Œ (value tokens) æ¥å®ç°ç»“æ„ä¸é¢œè‰²çš„è§£è€¦ã€‚ColorCtrl èƒ½å¤Ÿå®ç°ç²¾ç¡®ä¸”ä¸€è‡´çš„é¢œè‰²ç¼–è¾‘ï¼Œå¹¶æ”¯æŒè¯çº§åˆ«çš„å±æ€§å¼ºåº¦æ§åˆ¶ï¼Œç¡®ä¿ä»…å¯¹æç¤ºè¯æŒ‡å®šçš„åŒºåŸŸè¿›è¡Œä¿®æ”¹è€Œä¸å½±å“æ— å…³åŒºåŸŸã€‚åœ¨ SD3 å’Œ FLUX.1-dev ä¸Šçš„å¹¿æ³›å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ç¼–è¾‘è´¨é‡å’Œä¸€è‡´æ€§æ–¹é¢ä¼˜äºç°æœ‰çš„æ— éœ€è®­ç»ƒæ–¹æ³•ï¼Œå…¶è¡¨ç°ç”šè‡³è¶…è¶Šäº† FLUX.1 Kontext Max å’Œ GPT-4o ç­‰å¼ºåŠ›å•†ä¸šæ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ³•åœ¨ CogVideoX ç­‰è§†é¢‘æ¨¡å‹ä¸­å±•ç°å‡ºæ˜¾è‘—çš„æ—¶é—´ç›¸å¹²æ€§ (temporal coherence) å’Œç¼–è¾‘ç¨³å®šæ€§ï¼Œå¹¶èƒ½æˆåŠŸæ³›åŒ–è‡³ Step1X-Edit ç­‰åŸºäºæŒ‡ä»¤çš„ç¼–è¾‘æ‰©æ•£æ¨¡å‹ä¸­ï¼Œè¯æ˜äº†å…¶æé«˜çš„é€šç”¨æ€§ä¸å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.GR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09131v2",
      "published_date": "2025-08-12 17:57:04 UTC",
      "updated_date": "2025-08-13 01:20:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:03.801349+00:00"
    },
    {
      "arxiv_id": "2508.09129v1",
      "title": "BrowseMaster: Towards Scalable Web Browsing via Tool-Augmented Programmatic Agent Pair",
      "title_zh": "BrowseMasterï¼šåŸºäºå·¥å…·å¢å¼ºå‹ç¨‹åºåŒ–æ™ºèƒ½ä½“å¯¹çš„å¯æ‰©å±•ç½‘é¡µæµè§ˆ",
      "authors": [
        "Xianghe Pang",
        "Shuo Tang",
        "Rui Ye",
        "Yuwen Du",
        "Yaxin Du",
        "Siheng Chen"
      ],
      "abstract": "Effective information seeking in the vast and ever-growing digital landscape requires balancing expansive search with strategic reasoning. Current large language model (LLM)-based agents struggle to achieve this balance due to limitations in search breadth and reasoning depth, where slow, serial querying restricts coverage of relevant sources and noisy raw inputs disrupt the continuity of multi-step reasoning. To address these challenges, we propose BrowseMaster, a scalable framework built around a programmatically augmented planner-executor agent pair. The planner formulates and adapts search strategies based on task constraints, while the executor conducts efficient, targeted retrieval to supply the planner with concise, relevant evidence. This division of labor preserves coherent, long-horizon reasoning while sustaining broad and systematic exploration, overcoming the trade-off that limits existing agents. Extensive experiments on challenging English and Chinese benchmarks show that BrowseMaster consistently outperforms open-source and proprietary baselines, achieving scores of 30.0 on BrowseComp-en and 46.5 on BrowseComp-zh, which demonstrates its strong capability in complex, reasoning-heavy information-seeking tasks at scale.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†BrowseMasterï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨é€šè¿‡å·¥å…·å¢å¼ºçš„ç¨‹åºåŒ–æ™ºèƒ½ä½“å¯¹ï¼ˆplanner-executor agent pairï¼‰å®ç°å¯æ‰©å±•ç½‘é¡µæµè§ˆçš„æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ™ºèƒ½ä½“åœ¨æœç´¢å¹¿åº¦ä¸æ¨ç†æ·±åº¦ä¹‹é—´éš¾ä»¥å¹³è¡¡ï¼Œä»¥åŠä¸²è¡ŒæŸ¥è¯¢å’Œå™ªå£°è¾“å…¥å¹²æ‰°é•¿æ—¶ç¨‹æ¨ç†ï¼ˆlong-horizon reasoningï¼‰çš„é—®é¢˜ï¼ŒBrowseMasteré€šè¿‡åˆ†å·¥æœºåˆ¶ä¼˜åŒ–äº†æ€§èƒ½ã€‚Plannerè´Ÿè´£æ ¹æ®ä»»åŠ¡çº¦æŸåˆ¶å®šå’Œè°ƒæ•´æœç´¢ç­–ç•¥ï¼Œè€ŒExecutoråˆ™æ‰§è¡Œé«˜æ•ˆçš„ç›®æ ‡æ£€ç´¢ï¼Œä¸ºPlanneræä¾›ç®€æ´ã€ç›¸å…³çš„è¯æ®æ”¯æŒã€‚è¿™ç§æ¶æ„åœ¨ç»´æŒè¿è´¯æ¨ç†çš„åŒæ—¶å®ç°äº†ç³»ç»Ÿæ€§çš„å¹¿æ³›æ¢ç´¢ï¼Œå…‹æœäº†ç°æœ‰æ™ºèƒ½ä½“çš„æŠ€æœ¯ç“¶é¢ˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒBrowseMasteråœ¨BrowseComp-enå’ŒBrowseComp-zhåŸºå‡†æµ‹è¯•ä¸­åˆ†åˆ«å–å¾—äº†30.0å’Œ46.5çš„æˆç»©ï¼Œæ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼€æºå’Œå•†ä¸šåŸºå‡†æ¨¡å‹ï¼Œè¯æ˜äº†å…¶å¤„ç†å¤æ‚ã€é«˜æ¨ç†å¼ºåº¦çš„å¤§è§„æ¨¡ä¿¡æ¯å¯»æ±‚ä»»åŠ¡çš„å“è¶Šèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09129v1",
      "published_date": "2025-08-12 17:56:25 UTC",
      "updated_date": "2025-08-12 17:56:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:06.294112+00:00"
    },
    {
      "arxiv_id": "2508.09123v3",
      "title": "OpenCUA: Open Foundations for Computer-Use Agents",
      "title_zh": "OpenCUAï¼šè®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“çš„å¼€æ”¾åŸºç¡€",
      "authors": [
        "Xinyuan Wang",
        "Bowen Wang",
        "Dunjie Lu",
        "Junlin Yang",
        "Tianbao Xie",
        "Junli Wang",
        "Jiaqi Deng",
        "Xiaole Guo",
        "Yiheng Xu",
        "Chen Henry Wu",
        "Zhennan Shen",
        "Zhuokai Li",
        "Ryan Li",
        "Xiaochuan Li",
        "Junda Chen",
        "Boyuan Zheng",
        "Peihang Li",
        "Fangyu Lei",
        "Ruisheng Cao",
        "Yeqiao Fu",
        "Dongchan Shin",
        "Martin Shin",
        "Jiarui Hu",
        "Yuyan Wang",
        "Jixuan Chen",
        "Yuxiao Ye",
        "Danyang Zhang",
        "Dikang Du",
        "Hao Hu",
        "Huarong Chen",
        "Zaida Zhou",
        "Haotian Yao",
        "Ziwei Chen",
        "Qizheng Gu",
        "Yipu Wang",
        "Heng Wang",
        "Diyi Yang",
        "Victor Zhong",
        "Flood Sung",
        "Y. Charles",
        "Zhilin Yang",
        "Tao Yu"
      ],
      "abstract": "Vision-language models have demonstrated impressive capabilities as computer-use agents (CUAs) capable of automating diverse computer tasks. As their commercial potential grows, critical details of the most capable CUA systems remain closed. As these agents will increasingly mediate digital interactions and execute consequential decisions on our behalf, the research community needs access to open CUA frameworks to study their capabilities, limitations, and risks. To bridge this gap, we propose OpenCUA, a comprehensive open-source framework for scaling CUA data and foundation models. Our framework consists of: (1) an annotation infrastructure that seamlessly captures human computer-use demonstrations; (2) AgentNet, the first large-scale computer-use task dataset spanning 3 operating systems and 200+ applications and websites; (3) a scalable pipeline that transforms demonstrations into state-action pairs with reflective long Chain-of-Thought reasoning that sustain robust performance gains as data scales. Our end-to-end agent models demonstrate strong performance across CUA benchmarks. In particular, OpenCUA-72B achieves an average success rate of 45.0% on OSWorld-Verified, establishing a new state-of-the-art (SOTA) among open-source models. Further analysis confirms that our approach generalizes well across domains and benefits significantly from increased test-time computation. We release our annotation tool, datasets, code, and models to build open foundations for further CUA research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OpenCUAï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ‰©å±•è®¡ç®—æœºä½¿ç”¨æ™ºèƒ½ä½“ (Computer-Use Agents, CUAs) æ•°æ®å’ŒåŸºç¡€æ¨¡å‹çš„å…¨é¢å¼€æºæ¡†æ¶ï¼Œä»¥åº”å¯¹å½“å‰é¢†å…ˆ CUA ç³»ç»Ÿæ ¸å¿ƒç»†èŠ‚ä¸å…¬å¼€çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶ç”±ä¸‰ä¸ªæ ¸å¿ƒéƒ¨åˆ†ç»„æˆï¼šèƒ½å¤Ÿæ— ç¼æ•è·äººç±»æ¼”ç¤ºçš„æ ‡æ³¨åŸºç¡€è®¾æ–½ã€æ¶µç›– 3 ä¸ªæ“ä½œç³»ç»ŸåŠ 200 å¤šä¸ªåº”ç”¨ç¨‹åºçš„å¤§è§„æ¨¡æ•°æ®é›† AgentNetï¼Œä»¥åŠä¸€ä¸ªå°†æ¼”ç¤ºè½¬åŒ–ä¸ºå¸¦æœ‰åæ€æ€§é•¿é“¾å¼æ€ç»´ (Chain-of-Thought) æ¨ç†çš„çŠ¶æ€-åŠ¨ä½œå¯¹çš„å¯æ‰©å±•æµæ°´çº¿ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒOpenCUA ç«¯åˆ°ç«¯æ¨¡å‹åœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­è¡¨ç°å‡ºè‰²ï¼Œå…¶ä¸­ OpenCUA-72B åœ¨ OSWorld-Verified ä¸Šå®ç°äº† 45.0% çš„å¹³å‡æˆåŠŸç‡ï¼Œç¡®ç«‹äº†å¼€æºæ¨¡å‹çš„æ–° SOTAã€‚è¿›ä¸€æ­¥åˆ†æè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸åŒé¢†åŸŸé—´å…·æœ‰è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œå¹¶ä¸”èƒ½æ˜¾è‘—å—ç›Šäºæµ‹è¯•æ—¶è®¡ç®— (test-time computation) çš„å¢åŠ ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡å¼€æºç›¸å…³çš„æ ‡æ³¨å·¥å…·ã€æ•°æ®é›†ã€ä»£ç åŠæ¨¡å‹ï¼Œä¸ºæœªæ¥çš„ CUA ç ”ç©¶æ„å»ºäº†ç¨³å›ºçš„å¼€æ”¾åŸºç¡€ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Updata author list, modify first page format, correct typos",
      "pdf_url": "https://arxiv.org/pdf/2508.09123v3",
      "published_date": "2025-08-12 17:52:32 UTC",
      "updated_date": "2025-10-04 17:38:02 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:14.997003+00:00"
    },
    {
      "arxiv_id": "2508.13179v1",
      "title": "Toward an African Agenda for AI Safety",
      "title_zh": "è¿ˆå‘éæ´²äººå·¥æ™ºèƒ½å®‰å…¨è®®ç¨‹",
      "authors": [
        "Samuel T. Segun",
        "Rachel Adams",
        "Ana Florido",
        "Scott Timcke",
        "Jonathan Shock",
        "Leah Junck",
        "Fola Adeleke",
        "Nicolas Grossman",
        "Ayantola Alayande",
        "Jerry John Kponyo",
        "Matthew Smith",
        "Dickson Marfo Fosu",
        "Prince Dawson Tetteh",
        "Juliet Arthur",
        "Stephanie Kasaon",
        "Odilile Ayodele",
        "Laetitia Badolo",
        "Paul Plantinga",
        "Michael Gastrow",
        "Sumaya Nur Adan",
        "Joanna Wiaterek",
        "Cecil Abungu",
        "Kojo Apeagyei",
        "Luise Eder",
        "Tegawende Bissyande"
      ],
      "abstract": "This paper maps Africa's distinctive AI risk profile, from deepfake fuelled electoral interference and data colonial dependency to compute scarcity, labour disruption and disproportionate exposure to climate driven environmental costs. While major benefits are promised to accrue, the availability, development and adoption of AI also mean that African people and countries face particular AI safety risks, from large scale labour market disruptions to the nefarious use of AI to manipulate public opinion. To date, African perspectives have not been meaningfully integrated into global debates and processes regarding AI safety, leaving African stakeholders with limited influence over the emerging global AI safety governance agenda. While there are Computer Incident Response Teams on the continent, none hosts a dedicated AI Safety Institute or office. We propose a five-point action plan centred on (i) a policy approach that foregrounds the protection of the human rights of those most vulnerable to experiencing the harmful socio-economic effects of AI; (ii) the establishment of an African AI Safety Institute; (iii) promote public AI literacy and awareness; (iv) development of early warning system with inclusive benchmark suites for 25+ African languages; and (v) an annual AU-level AI Safety & Security Forum.",
      "tldr_zh": "è¯¥ç ”ç©¶ç³»ç»Ÿç»˜åˆ¶äº†éæ´²ç‹¬ç‰¹çš„ AI safety é£é™©å›¾è°±ï¼Œé‡ç‚¹æ¢è®¨äº†ç”± deepfake é©±åŠ¨çš„é€‰ä¸¾å¹²é¢„ã€æ•°æ®æ®–æ°‘ä¾èµ–ï¼ˆdata colonial dependencyï¼‰ã€ç®—åŠ›çŸ­ç¼ºï¼ˆcompute scarcityï¼‰ä»¥åŠä¸æˆæ¯”ä¾‹çš„æ°”å€™ç¯å¢ƒæˆæœ¬ã€‚æ–‡ç« æŒ‡å‡ºï¼Œå°½ç®¡éæ´²é¢ä¸´å¤§è§„æ¨¡åŠ³åŠ¨åŠ›ä¸­æ–­å’Œèˆ†è®ºæ“çºµç­‰é£é™©ï¼Œä½†éæ´²è§†è§’åœ¨ç›®å‰çš„å…¨çƒ AI safety æ²»ç†è®®ç¨‹ä¸­ä¸¥é‡ç¼ºå¤±ï¼Œä¸”è¯¥å¤§é™†ç›®å‰ç¼ºä¹ä¸“é—¨çš„ AI Safety Instituteã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ä¸ªäº”ç‚¹è¡ŒåŠ¨è®¡åˆ’ï¼Œæ ¸å¿ƒåŒ…æ‹¬å»ºç«‹ African AI Safety Institute ä»¥åŠåˆ¶å®šä»¥äººæƒä¿æŠ¤ä¸ºé¦–è¦ä»»åŠ¡çš„æ”¿ç­–è·¯å¾„ã€‚æ­¤å¤–ï¼Œè¯¥è®¡åˆ’å»ºè®®å¼€å‘æ”¯æŒ 25 ç§ä»¥ä¸Šéæ´²è¯­è¨€çš„æ—©æœŸé¢„è­¦ç³»ç»Ÿä¸åŸºå‡†æµ‹è¯•é›†ï¼ˆbenchmark suitesï¼‰ï¼Œå¹¶è®¾ç«‹éç›Ÿï¼ˆAUï¼‰çº§åˆ«çš„ AI Safety & Security Forumã€‚è¿™ä¸€è®®ç¨‹æ—¨åœ¨å¢å¼ºéæ´²åœ¨å…¨çƒ AI å®‰å…¨æ²»ç†ä¸­çš„å½±å“åŠ›ï¼Œç¡®ä¿å…¶èƒ½å¤Ÿæœ‰æ•ˆåº”å¯¹æŠ€æœ¯å˜é©å¸¦æ¥çš„ç‰¹å®šç¤¾ä¼šç»æµå†²å‡»ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "28 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.13179v1",
      "published_date": "2025-08-12 17:42:09 UTC",
      "updated_date": "2025-08-12 17:42:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:08.389163+00:00"
    },
    {
      "arxiv_id": "2508.09105v2",
      "title": "SMA: Who Said That? Auditing Membership Leakage in Semi-Black-box RAG Controlling",
      "title_zh": "SMAï¼šâ€œé‚£æ˜¯è°è¯´çš„ï¼Ÿâ€ï¼šåŠé»‘ç›’ RAG ç®¡æ§ä¸‹çš„æˆå‘˜èº«ä»½æ³„éœ²å®¡è®¡",
      "authors": [
        "Shixuan Sun",
        "Siyuan Liang",
        "Ruoyu Chen",
        "Jianjie Huang",
        "Jingzhi Li",
        "Xiaochun Cao"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) and its Multimodal Retrieval-Augmented Generation (MRAG) significantly improve the knowledge coverage and contextual understanding of Large Language Models (LLMs) by introducing external knowledge sources. However, retrieval and multimodal fusion obscure content provenance, rendering existing membership inference methods unable to reliably attribute generated outputs to pre-training, external retrieval, or user input, thus undermining privacy leakage accountability\n  To address these challenges, we propose the first Source-aware Membership Audit (SMA) that enables fine-grained source attribution of generated content in a semi-black-box setting with retrieval control capabilities. To address the environmental constraints of semi-black-box auditing, we further design an attribution estimation mechanism based on zero-order optimization, which robustly approximates the true influence of input tokens on the output through large-scale perturbation sampling and ridge regression modeling. In addition, SMA introduces a cross-modal attribution technique that projects image inputs into textual descriptions via MLLMs, enabling token-level attribution in the text modality, which for the first time facilitates membership inference on image retrieval traces in MRAG systems. This work shifts the focus of membership inference from 'whether the data has been memorized' to 'where the content is sourced from', offering a novel perspective for auditing data provenance in complex generative systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ£€ç´¢å¢å¼ºç”Ÿæˆ(RAG)å’Œå¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ(MRAG)ä¸­å†…å®¹æ¥æºä¸æ˜ç¡®å¯¼è‡´éšç§æ³„éœ²è´£ä»»è¿½ç©¶å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†é¦–ä¸ªæºæ„ŸçŸ¥æˆå‘˜å®¡è®¡æ¡†æ¶SMA (Source-aware Membership Audit)ã€‚SMAèƒ½å¤Ÿåœ¨å…·å¤‡æ£€ç´¢æ§åˆ¶èƒ½åŠ›çš„åŠé»‘ç›’(semi-black-box)è®¾ç½®ä¸‹å®ç°ç”Ÿæˆå†…å®¹çš„ç»†ç²’åº¦æ¥æºå½’å±ã€‚ä¸ºäº†åº”å¯¹å®¡è®¡ç¯å¢ƒçš„é™åˆ¶ï¼Œç ”ç©¶è®¾è®¡äº†ä¸€ç§åŸºäºé›¶é˜¶ä¼˜åŒ–(zero-order optimization)çš„å½’å±ä¼°è®¡æœºåˆ¶ï¼Œé€šè¿‡å¤§è§„æ¨¡æ‰°åŠ¨é‡‡æ ·å’Œå²­å›å½’å»ºæ¨¡(ridge regression modeling)æ¥ç¨³å¥åœ°é€¼è¿‘è¾“å…¥tokenå¯¹è¾“å‡ºçš„çœŸå®å½±å“ã€‚æ­¤å¤–ï¼ŒSMAå¼•å…¥äº†è·¨æ¨¡æ€å½’å±æŠ€æœ¯ï¼Œåˆ©ç”¨å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)å°†å›¾åƒè¾“å…¥è½¬åŒ–ä¸ºæ–‡æœ¬æè¿°ï¼Œä»è€Œåœ¨æ–‡æœ¬æ¨¡æ€ä¸‹è¿›è¡Œtokençº§å½’å±ï¼Œé¦–æ¬¡å®ç°äº†å¯¹MRAGç³»ç»Ÿä¸­å›¾åƒæ£€ç´¢ç—•è¿¹çš„æˆå‘˜æ¨ç†(membership inference)ã€‚è¯¥å·¥ä½œå°†æˆå‘˜æ¨ç†çš„ç„¦ç‚¹ä»â€œæ•°æ®æ˜¯å¦è¢«è®°å¿†â€è½¬å‘â€œå†…å®¹æ¥æºäºä½•å¤„â€ï¼Œä¸ºå¤æ‚ç”Ÿæˆç³»ç»Ÿä¸­çš„åŸå§‹æ•°æ®å®¡è®¡(data provenance)æä¾›äº†å…¨æ–°è§†è§’ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09105v2",
      "published_date": "2025-08-12 17:32:24 UTC",
      "updated_date": "2025-08-13 11:05:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:21.991021+00:00"
    },
    {
      "arxiv_id": "2508.09100v1",
      "title": "Towards Universal Neural Inference",
      "title_zh": "è¿ˆå‘é€šç”¨ç¥ç»æ¨ç†",
      "authors": [
        "Shreyas Bhat Brahmavar",
        "Yang Li",
        "Junier Oliva"
      ],
      "abstract": "Real-world data often appears in diverse, disjoint forms -- with varying schemas, inconsistent semantics, and no fixed feature ordering -- making it challenging to build general-purpose models that can leverage information across datasets. We introduce ASPIRE, Arbitrary Set-based Permutation-Invariant Reasoning Engine, a Universal Neural Inference model for semantic reasoning and prediction over heterogeneous structured data. ASPIRE combines a permutation-invariant, set-based Transformer with a semantic grounding module that incorporates natural language descriptions, dataset metadata, and in-context examples to learn cross-dataset feature dependencies. This architecture allows ASPIRE to ingest arbitrary sets of feature--value pairs and support examples, align semantics across disjoint tables, and make predictions for any specified target. Once trained, ASPIRE generalizes to new inference tasks without additional tuning. In addition to delivering strong results across diverse benchmarks, ASPIRE naturally supports cost-aware active feature acquisition in an open-world setting, selecting informative features under test-time budget constraints for an arbitrary unseen dataset. These capabilities position ASPIRE as a step toward truly universal, semantics-aware inference over structured data.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† ASPIRE (Arbitrary Set-based Permutation-Invariant Reasoning Engine)ï¼Œæ—¨åœ¨è§£å†³ç°å®ä¸–ç•Œç»“æ„åŒ–æ•°æ®å›  Schema å¤šæ ·ã€è¯­ä¹‰ä¸ä¸€è‡´åŠç‰¹å¾æ’åºä¸å›ºå®šè€Œå¯¼è‡´çš„è·¨æ•°æ®é›†é€šç”¨å»ºæ¨¡éš¾é¢˜ã€‚ASPIRE ç»“åˆäº†ç½®æ¢ä¸å˜æ€§ (permutation-invariant) çš„é›†åˆå‹ Transformer ä¸è¯­ä¹‰å¯¹é½æ¨¡å— (semantic grounding module)ï¼Œé€šè¿‡æ•´åˆè‡ªç„¶è¯­è¨€æè¿°ã€æ•°æ®é›†å…ƒæ•°æ®å’Œä¸Šä¸‹æ–‡ç¤ºä¾‹æ¥å­¦ä¹ è·¨æ•°æ®é›†çš„ç‰¹å¾ä¾èµ–å…³ç³»ã€‚è¯¥æ¶æ„å…è®¸æ¨¡å‹æ‘„å–ä»»æ„çš„ç‰¹å¾å€¼å¯¹ (feature-value pairs) å’Œæ”¯æŒç¤ºä¾‹ï¼Œä»è€Œå®ç°åœ¨ä¸ç›¸äº¤çš„è¡¨æ ¼é—´è¿›è¡Œè¯­ä¹‰å¯¹é½å¹¶å¯¹æŒ‡å®šç›®æ ‡è¿›è¡Œé¢„æµ‹ã€‚å®éªŒè¡¨æ˜ï¼Œè®­ç»ƒåçš„ ASPIRE æ— éœ€é¢å¤–å¾®è°ƒå³å¯æ³›åŒ–è‡³å…¨æ–°çš„æ¨ç†ä»»åŠ¡ï¼Œåœ¨å¤šé¡¹åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ€§èƒ½ã€‚æ­¤å¤–ï¼ŒASPIRE è¿˜æ”¯æŒåœ¨å¼€æ”¾ç¯å¢ƒä¸‹è¿›è¡Œæˆæœ¬æ•æ„Ÿçš„ç‰¹å¾ä¸»åŠ¨è·å– (active feature acquisition)ï¼Œèƒ½å¤Ÿåœ¨é¢„ç®—é™åˆ¶ä¸‹ä¸ºæœªçŸ¥æ•°æ®é›†é€‰æ‹©æœ€å…·ä¿¡æ¯é‡çš„ç‰¹å¾ã€‚è¿™é¡¹å·¥ä½œä¸ºå®ç°å…·å¤‡è¯­ä¹‰æ„ŸçŸ¥èƒ½åŠ›ä¸”é€‚ç”¨äºå¼‚æ„ç»“æ„åŒ–æ•°æ®çš„é€šç”¨ç¥ç»æ¨ç† (Universal Neural Inference) å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09100v1",
      "published_date": "2025-08-12 17:26:48 UTC",
      "updated_date": "2025-08-12 17:26:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:27.887101+00:00"
    },
    {
      "arxiv_id": "2508.09090v2",
      "title": "SPARC: Soft Probabilistic Adaptive multi-interest Retrieval Model via Codebooks for recommender system",
      "title_zh": "SPARCï¼šåŸºäºç æœ¬çš„æ¨èç³»ç»Ÿè½¯æ¦‚ç‡è‡ªé€‚åº”å¤šå…´è¶£æ£€ç´¢æ¨¡å‹",
      "authors": [
        "Jialiang Shi",
        "Yaguang Dou",
        "Tian Qi"
      ],
      "abstract": "Modeling multi-interests has arisen as a core problem in real-world RS. Current multi-interest retrieval methods pose three major challenges: 1) Interests, typically extracted from predefined external knowledge, are invariant. Failed to dynamically evolve with users' real-time consumption preferences. 2) Online inference typically employs an over-exploited strategy, mainly matching users' existing interests, lacking proactive exploration and discovery of novel and long-tail interests. To address these challenges, we propose a novel retrieval framework named SPARC(Soft Probabilistic Adaptive Retrieval Model via Codebooks). Our contribution is two folds. First, the framework utilizes Residual Quantized Variational Autoencoder (RQ-VAE) to construct a discretized interest space. It achieves joint training of the RQ-VAE with the industrial large scale recommendation model, mining behavior-aware interests that can perceive user feedback and evolve dynamically. Secondly, a probabilistic interest module that predicts the probability distribution over the entire dynamic and discrete interest space. This facilitates an efficient \"soft-search\" strategy during online inference, revolutionizing the retrieval paradigm from \"passive matching\" to \"proactive exploration\" and thereby effectively promoting interest discovery. Online A/B tests on an industrial platform with tens of millions daily active users, have achieved substantial gains in business metrics: +0.9% increase in user view duration, +0.4% increase in user page views (PV), and a +22.7% improvement in PV500(new content reaching 500 PVs in 24 hours). Offline evaluations are conducted on open-source Amazon Product datasets. Metrics, such as Recall@K and Normalized Discounted Cumulative Gain@K(NDCG@K), also showed consistent improvement. Both online and offline experiments validate the efficacy and practical value of the proposed method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ¨èç³»ç»Ÿ(RS)ä¸­å¤šå…´è¶£å»ºæ¨¡é¢ä¸´çš„å…´è¶£è¡¨ç°é™æ€ã€åœ¨çº¿æ¨ç†ç¼ºä¹ä¸»åŠ¨æ¢ç´¢ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†SPARCï¼ˆSoft Probabilistic Adaptive multi-interest Retrieval Model via Codebooksï¼‰æ£€ç´¢æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ®‹å·®é‡åŒ–å˜åˆ†è‡ªåŠ¨ç¼–ç å™¨(RQ-VAE)æ„å»ºç¦»æ•£åŒ–å…´è¶£ç©ºé—´ï¼Œå¹¶ä¸å·¥ä¸šçº§å¤§è§„æ¨¡æ¨èæ¨¡å‹è¿›è¡Œè”åˆè®­ç»ƒï¼Œä»è€ŒæŒ–æ˜å‡ºèƒ½éšç”¨æˆ·è¡Œä¸ºåŠ¨æ€æ¼”è¿›çš„å…´è¶£è¡¨ç¤ºã€‚é€šè¿‡å¼•å…¥æ¦‚ç‡å…´è¶£æ¨¡å—ï¼ŒSPARCå®ç°äº†ä»â€œè¢«åŠ¨åŒ¹é…â€åˆ°â€œä¸»åŠ¨æ¢ç´¢â€çš„æ£€ç´¢èŒƒå¼è½¬å˜ï¼Œåˆ©ç”¨â€œè½¯æœç´¢â€ç­–ç•¥æœ‰æ•ˆä¿ƒè¿›äº†å¯¹é•¿å°¾å’Œæ–°é¢–å…´è¶£çš„å‘ç°ã€‚åœ¨åƒä¸‡çº§æ—¥æ´»ç”¨æˆ·çš„å·¥ä¸šå¹³å°æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹æ˜¾è‘—æå‡äº†ç”¨æˆ·æ—¶é•¿å’Œé¡µé¢æµè§ˆé‡(PV)ï¼Œå…¶ä¸­è¡¡é‡æ–°å†…å®¹åˆ†å‘èƒ½åŠ›çš„PV500æŒ‡æ ‡å¤§å¹…æå‡è¾¾22.7%ã€‚çº¿ä¸‹åœ¨Amazon Productæ•°æ®é›†ä¸Šçš„å®éªŒåŒæ ·è¯æ˜äº†Recall@Kå’ŒNDCG@Kç­‰æŒ‡æ ‡çš„æŒç»­æ”¹è¿›ï¼Œå……åˆ†éªŒè¯äº†è¯¥æ–¹æ³•åœ¨å®é™…ç”Ÿäº§ç¯å¢ƒä¸­çš„æ•ˆèƒ½ä¸åº”ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09090v2",
      "published_date": "2025-08-12 17:16:37 UTC",
      "updated_date": "2025-08-13 01:51:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:37.650962+00:00"
    },
    {
      "arxiv_id": "2508.09085v1",
      "title": "Dynamic Uncertainty-aware Multimodal Fusion for Outdoor Health Monitoring",
      "title_zh": "é¢å‘æˆ·å¤–å¥åº·ç›‘æµ‹çš„åŠ¨æ€ä¸ç¡®å®šæ€§æ„ŸçŸ¥å¤šæ¨¡æ€èåˆ",
      "authors": [
        "Zihan Fang",
        "Zheng Lin",
        "Senkang Hu",
        "Yihang Tao",
        "Yiqin Deng",
        "Xianhao Chen",
        "Yuguang Fang"
      ],
      "abstract": "Outdoor health monitoring is essential to detect early abnormal health status for safeguarding human health and safety. Conventional outdoor monitoring relies on static multimodal deep learning frameworks, which requires extensive data training from scratch and fails to capture subtle health status changes. Multimodal large language models (MLLMs) emerge as a promising alternative, utilizing only small datasets to fine-tune pre-trained information-rich models for enabling powerful health status monitoring. Unfortunately, MLLM-based outdoor health monitoring also faces significant challenges: I) sensor data contains input noise stemming from sensor data acquisition and fluctuation noise caused by sudden changes in physiological signals due to dynamic outdoor environments, thus degrading the training performance; ii) current transformer based MLLMs struggle to achieve robust multimodal fusion, as they lack a design for fusing the noisy modality; iii) modalities with varying noise levels hinder accurate recovery of missing data from fluctuating distributions. To combat these challenges, we propose an uncertainty-aware multimodal fusion framework, named DUAL-Health, for outdoor health monitoring in dynamic and noisy environments. First, to assess the impact of noise, we accurately quantify modality uncertainty caused by input and fluctuation noise with current and temporal features. Second, to empower efficient muitimodal fusion with low-quality modalities,we customize the fusion weight for each modality based on quantified and calibrated uncertainty. Third, to enhance data recovery from fluctuating noisy modalities, we align modality distributions within a common semantic space. Extensive experiments demonstrate that our DUAL-Health outperforms state-of-the-art baselines in detection accuracy and robustness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æˆ·å¤–å¥åº·ç›‘æµ‹ä¸­ä¼ æ„Ÿå™¨é‡‡é›†å™ªå£°å’Œç¯å¢ƒæ³¢åŠ¨å¼•èµ·çš„ç”Ÿç†ä¿¡å·å¹²æ‰°ï¼Œæå‡ºäº†åä¸º DUAL-Health çš„åŠ¨æ€ä¸ç¡®å®šæ€§æ„ŸçŸ¥å¤šæ¨¡æ€èåˆæ¡†æ¶ã€‚ä¸ºäº†å…‹æœç°æœ‰ Multimodal Large Language Models (MLLMs) åœ¨å¤„ç†ä½è´¨é‡æ•°æ®æ—¶èåˆç¨³å¥æ€§ä¸è¶³çš„é—®é¢˜ï¼Œè¯¥æ¡†æ¶é€šè¿‡ç»“åˆå½“å‰ä¸æ—¶åºç‰¹å¾ï¼Œå‡†ç¡®é‡åŒ–äº†æ¨¡æ€çš„ä¸ç¡®å®šæ€§ã€‚DUAL-Health æ ¹æ®æ ¡å‡†åçš„ä¸ç¡®å®šæ€§ä¸ºä¸åŒæ¨¡æ€åŠ¨æ€å®šåˆ¶èåˆæƒé‡ï¼Œç¡®ä¿äº†åœ¨åŠ¨æ€å™ªå£°ç¯å¢ƒä¸‹çš„é«˜æ•ˆç‰¹å¾é›†æˆã€‚åŒæ—¶ï¼Œè¯¥æ–¹æ³•åœ¨å…¬å…±è¯­ä¹‰ç©ºé—´ä¸­å¯¹é½æ¨¡æ€åˆ†å¸ƒï¼Œæ˜¾è‘—å¢å¼ºäº†ä»æ³¢åŠ¨æ•°æ®ä¸­æ¢å¤ç¼ºå¤±ä¿¡æ¯çš„èƒ½åŠ›ã€‚å¤§é‡å®éªŒè¯æ˜ï¼ŒDUAL-Health åœ¨æ£€æµ‹å‡†ç¡®æ€§å’Œé²æ£’æ€§ä¸Šå‡ä¼˜äºç°æœ‰çš„ state-of-the-art åŸºçº¿æ¨¡å‹ï¼Œä¸ºå¯é çš„æˆ·å¤–å¥åº·å®æ—¶ç›‘æµ‹æä¾›äº†æ–°æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "14 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09085v1",
      "published_date": "2025-08-12 17:07:27 UTC",
      "updated_date": "2025-08-12 17:07:27 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:30.683453+00:00"
    },
    {
      "arxiv_id": "2508.09054v1",
      "title": "CVCM Track Circuits Pre-emptive Failure Diagnostics for Predictive Maintenance Using Deep Neural Networks",
      "title_zh": "åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œçš„ CVCM è½¨é“ç”µè·¯é¢„æµ‹æ€§ç»´æŠ¤æŠ¢å…ˆå¼æ•…éšœè¯Šæ–­",
      "authors": [
        "Debdeep Mukherjee",
        "Eduardo Di Santi",
        "ClÃ©ment Lefebvre",
        "Nenad Mijatovic",
        "Victor Martin",
        "Thierry Josse",
        "Jonathan Brown",
        "Kenza Saiah"
      ],
      "abstract": "Track circuits are critical for railway operations, acting as the main signalling sub-system to locate trains. Continuous Variable Current Modulation (CVCM) is one such technology. Like any field-deployed, safety-critical asset, it can fail, triggering cascading disruptions. Many failures originate as subtle anomalies that evolve over time, often not visually apparent in monitored signals. Conventional approaches, which rely on clear signal changes, struggle to detect them early. Early identification of failure types is essential to improve maintenance planning, minimising downtime and revenue loss. Leveraging deep neural networks, we propose a predictive maintenance framework that classifies anomalies well before they escalate into failures. Validated on 10 CVCM failure cases across different installations, the method is ISO-17359 compliant and outperforms conventional techniques, achieving 99.31% overall accuracy with detection within 1% of anomaly onset. Through conformal prediction, we provide uncertainty estimates, reaching 99% confidence with consistent coverage across classes. Given CVCMs global deployment, the approach is scalable and adaptable to other track circuits and railway systems, enhancing operational reliability.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è½¨é“ç”µè·¯ä¸­è¿ç»­å˜é‡ç”µæµè°ƒåˆ¶ (Continuous Variable Current Modulation, CVCM) æŠ€æœ¯çš„æ•…éšœé¢„æµ‹é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦ç¥ç»ç½‘ç»œ (Deep Neural Networks) çš„é¢„é˜²æ€§ç»´æŠ¤æ¡†æ¶ã€‚ä¼ ç»Ÿçš„ç»´æŠ¤æ–¹æ³•éš¾ä»¥åœ¨æ—©æœŸè¯†åˆ«ç»†å¾®çš„å¼‚å¸¸ä¿¡å·ï¼Œè€Œè¯¥æ¡†æ¶èƒ½å¤Ÿåœ¨å¼‚å¸¸æ¼”åŒ–ä¸ºä¸¥é‡æ•…éšœä¹‹å‰å¯¹å…¶è¿›è¡Œç²¾å‡†åˆ†ç±»ã€‚è¯¥æ–¹æ³•é€šè¿‡ä¸€è‡´æ€§é¢„æµ‹ (Conformal Prediction) æä¾›äº†ä¸ç¡®å®šæ€§ä¼°ç®—ï¼Œåœ¨æ»¡è¶³ ISO-17359 æ ‡å‡†çš„åŒæ—¶ï¼Œå®ç°äº† 99% çš„ç½®ä¿¡æ°´å¹³ã€‚åœ¨ 10 ä¸ªä¸åŒçš„ CVCM æ•…éšœæ¡ˆä¾‹éªŒè¯ä¸­ï¼Œè¯¥æ¨¡å‹è¾¾åˆ°äº† 99.31% çš„æ€»å‡†ç¡®ç‡ï¼Œä¸”åœ¨å¼‚å¸¸å‘ç”ŸåˆæœŸçš„ 1% é˜¶æ®µå³å¯å®Œæˆæ£€æµ‹ã€‚å®éªŒè¯æ˜è¯¥æ–¹æ³•ä¼˜äºä¼ ç»ŸæŠ€æœ¯ï¼Œç”±äºå…¶å…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œé€‚åº”æ€§ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæå‡å…¨çƒèŒƒå›´å†…è½¨é“ç”µè·¯åŠé“è·¯ç³»ç»Ÿçš„è¿è¡Œå¯é æ€§ï¼Œå‡å°‘åœæœºæ—¶é—´ä¸ç»æµæŸå¤±ã€‚",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025 (International Conference on Railway Operations Modelling and Analysis), Dresden, Germany. https://tu-dresden.de/raildresden2025 8 pages, 6 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2508.09054v1",
      "published_date": "2025-08-12 16:13:51 UTC",
      "updated_date": "2025-08-12 16:13:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:37.371529+00:00"
    },
    {
      "arxiv_id": "2508.16607v2",
      "title": "\"Accessibility people, you go work on that thing of yours over there\": Addressing Disability Inclusion in AI Product Organizations",
      "title_zh": "â€œåšæ— éšœç¢çš„é‚£æ‹¨äººï¼Œä½ ä»¬å»é‚£è¾¹å¿™ä½ ä»¬çš„å§â€ï¼šåº”å¯¹ AI äº§å“ç»„ç»‡ä¸­çš„æ®‹éšœåŒ…å®¹æ€§æŒ‘æˆ˜",
      "authors": [
        "Sanika Moharana",
        "Cynthia L. Bennett",
        "Erin Buehler",
        "Michael Madaio",
        "Vinita Tibdewal",
        "Shaun K. Kane"
      ],
      "abstract": "The rapid emergence of generative AI has changed the way that technology is designed, constructed, maintained, and evaluated. Decisions made when creating AI-powered systems may impact some users disproportionately, such as people with disabilities. In this paper, we report on an interview study with 25 AI practitioners across multiple roles (engineering, research, UX, and responsible AI) about how their work processes and artifacts may impact end users with disabilities. We found that practitioners experienced friction when triaging problems at the intersection of responsible AI and accessibility practices, navigated contradictions between accessibility and responsible AI guidelines, identified gaps in data about users with disabilities, and gathered support for addressing the needs of disabled stakeholders by leveraging informal volunteer and community groups within their company. Based on these findings, we offer suggestions for new resources and process changes to better support people with disabilities as end users of AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†äººå·¥æ™ºèƒ½äº§å“ç»„ç»‡ä¸­è§£å†³æ®‹ç–¾äººåŒ…å®¹æ€§ï¼ˆDisability Inclusionï¼‰çš„é—®é¢˜ï¼Œæ—¨åœ¨åˆ†æç”Ÿæˆå¼äººå·¥æ™ºèƒ½å¯¹æ®‹ç–¾ç”¨æˆ·çš„æ½œåœ¨å½±å“ã€‚é€šè¿‡å¯¹è·¨è¶Šå·¥ç¨‹ã€ç ”ç©¶ã€ç”¨æˆ·ä½“éªŒï¼ˆUXï¼‰å’Œè´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ï¼ˆResponsible AIï¼‰ç­‰å²—ä½çš„25ä½äººå·¥æ™ºèƒ½ä»ä¸šè€…ï¼ˆAI practitionersï¼‰è¿›è¡Œæ·±åº¦è®¿è°ˆï¼Œæ­ç¤ºäº†å½“å‰å·¥ä½œæµç¨‹ä¸­å­˜åœ¨çš„ç³»ç»Ÿæ€§éšœç¢ã€‚ç ”ç©¶å‘ç°ï¼Œä»ä¸šè€…åœ¨å¤„ç†è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½ä¸æ— éšœç¢ï¼ˆAccessibilityï¼‰å®è·µçš„äº¤é›†æ—¶é¢ä¸´æ‘©æ“¦ï¼Œä¸”ä¸åŒæŒ‡å—ä¹‹é—´å­˜åœ¨çŸ›ç›¾ã€‚æ­¤å¤–ï¼Œç ”ç©¶æŒ‡å‡ºäº†æ®‹ç–¾ç”¨æˆ·æ•°æ®çš„ä¸¥é‡ç¼ºå¤±ï¼Œä»¥åŠä»ä¸šè€…å¾€å¾€ä¾èµ–å…¬å¸å†…éƒ¨éæ­£å¼å¿—æ„¿è€…å’Œç¤¾ç¾¤åŠ›é‡æ¥åº”å¯¹æ®‹ç–¾åˆ©ç›Šç›¸å…³è€…çš„éœ€æ±‚ã€‚åŸºäºä¸Šè¿°å‘ç°ï¼Œè¯¥ç ”ç©¶æå‡ºäº†èµ„æºå»ºè®¾ä¸æµç¨‹ä¼˜åŒ–æ–¹æ¡ˆï¼Œä»¥æœŸåœ¨äººå·¥æ™ºèƒ½äº§å“å¼€å‘ä¸­æ›´å¥½åœ°ä¿éšœæ®‹ç–¾ç»ˆç«¯ç”¨æˆ·çš„åˆ©ç›Šã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16607v2",
      "published_date": "2025-08-12 16:08:42 UTC",
      "updated_date": "2025-11-05 16:58:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:57.468305+00:00"
    },
    {
      "arxiv_id": "2508.09242v1",
      "title": "Cross-BCI, A Cross-BCI-Paradigm Classifica-tion Model Towards Universal BCI Applications",
      "title_zh": "Cross-BCIï¼šé¢å‘é€šç”¨è„‘æœºæ¥å£åº”ç”¨çš„è·¨èŒƒå¼åˆ†ç±»æ¨¡å‹",
      "authors": [
        "Gaojie Zhou",
        "Junhua Li"
      ],
      "abstract": "Classification models used in brain-computer interface (BCI) are usually designed for a single BCI paradigm. This requires the redevelopment of the model when applying it to a new BCI paradigm, resulting in repeated costs and effort. Moreover, less complex deep learning models are desired for practical usage, as well as for deployment on portable devices. In or-der to fill the above gaps, we, in this study, proposed a light-weight and unified decoding model for cross-BCI-paradigm classification. The proposed model starts with a tempo-spatial convolution. It is followed by a multi-scale local feature selec-tion module, aiming to extract local features shared across BCI paradigms and generate weighted features. Finally, a mul-ti-dimensional global feature extraction module is designed, in which multi-dimensional global features are extracted from the weighted features and fused with the weighted features to form high-level feature representations associated with BCI para-digms. The results, evaluated on a mixture of three classical BCI paradigms (i.e., MI, SSVEP, and P300), demon-strate that the proposed model achieves 88.39%, 82.36%, 80.01%, and 0.8092 for accuracy, macro-precision, mac-ro-recall, and macro-F1-score, respectively, significantly out-performing the compared models. This study pro-vides a feasible solution for cross-BCI-paradigm classifica-tion. It lays a technological foundation for de-veloping a new generation of unified decoding systems, paving the way for low-cost and universal practical applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Cross-BCIï¼Œä¸€ç§è½»é‡çº§ä¸”ç»Ÿä¸€çš„è§£ç æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿè„‘æœºæ¥å£(BCI)åˆ†ç±»æ¨¡å‹å› é’ˆå¯¹å•ä¸€èŒƒå¼è®¾è®¡è€Œå¯¼è‡´çš„é‡å¤å¼€å‘æˆæœ¬é«˜åŠéš¾ä»¥éƒ¨ç½²åœ¨ä¾¿æºè®¾å¤‡ç­‰é—®é¢˜ã€‚Cross-BCIæ¨¡å‹é¦–å…ˆé€šè¿‡æ—¶é—´-ç©ºé—´å·ç§¯(tempo-spatial convolution)æå–ç‰¹å¾ï¼Œéšååˆ©ç”¨å¤šå°ºåº¦å±€éƒ¨ç‰¹å¾é€‰æ‹©æ¨¡å—(multi-scale local feature selection module)æ•è·è·¨èŒƒå¼å…±äº«çš„å±€éƒ¨åŠ æƒç‰¹å¾ã€‚æ¨¡å‹è¿›ä¸€æ­¥è®¾è®¡äº†å¤šç»´åº¦å…¨å±€ç‰¹å¾æå–æ¨¡å—(multi-dimensional global feature extraction module)ï¼Œå°†å…¨å±€ä¿¡æ¯ä¸åŠ æƒç‰¹å¾èåˆï¼Œä»è€Œå½¢æˆä¸BCIèŒƒå¼ç›¸å…³çš„é«˜çº§ç‰¹å¾è¡¨ç¤ºã€‚åœ¨æ¶µç›–è¿åŠ¨æƒ³è±¡(MI)ã€ç¨³æ€è§†è§‰è¯±å‘ç”µä½(SSVEP)å’ŒP300ä¸‰ç§ç»å…¸èŒƒå¼çš„æ··åˆè¯„ä¼°ä¸­ï¼Œè¯¥æ¨¡å‹å–å¾—äº†88.39%çš„å‡†ç¡®ç‡å’Œ0.8092çš„å®F1åˆ†æ•°ï¼Œæ€§èƒ½æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¯¹æ¯”æ¨¡å‹ã€‚è¯¥é¡¹å·¥ä½œä¸ºè·¨èŒƒå¼BCIåˆ†ç±»æä¾›äº†ä¸€ç§å¯è¡Œçš„é€šç”¨åŒ–è§£å†³æ–¹æ¡ˆï¼Œä¸ºå¼€å‘ä½æˆæœ¬ã€é€šç”¨çš„æ–°ä¸€ä»£è„‘æœºæ¥å£ç³»ç»Ÿå¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "q-bio.QM",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09242v1",
      "published_date": "2025-08-12 16:04:50 UTC",
      "updated_date": "2025-08-12 16:04:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:58.069604+00:00"
    },
    {
      "arxiv_id": "2508.09036v1",
      "title": "Can We Trust AI to Govern AI? Benchmarking LLM Performance on Privacy and AI Governance Exams",
      "title_zh": "æˆ‘ä»¬èƒ½ä¿¡ä»» AI æ²»ç† AI å—ï¼Ÿå¤§è¯­è¨€æ¨¡å‹åœ¨éšç§ä¸ AI æ²»ç†è®¤è¯è€ƒè¯•ä¸­çš„æ€§èƒ½åŸºå‡†æµ‹è¯•",
      "authors": [
        "Zane Witherspoon",
        "Thet Mon Aye",
        "YingYing Hao"
      ],
      "abstract": "The rapid emergence of large language models (LLMs) has raised urgent questions across the modern workforce about this new technology's strengths, weaknesses, and capabilities. For privacy professionals, the question is whether these AI systems can provide reliable support on regulatory compliance, privacy program management, and AI governance. In this study, we evaluate ten leading open and closed LLMs, including models from OpenAI, Anthropic, Google DeepMind, Meta, and DeepSeek, by benchmarking their performance on industry-standard certification exams: CIPP/US, CIPM, CIPT, and AIGP from the International Association of Privacy Professionals (IAPP). Each model was tested using official sample exams in a closed-book setting and compared to IAPP's passing thresholds. Our findings show that several frontier models such as Gemini 2.5 Pro and OpenAI's GPT-5 consistently achieve scores exceeding the standards for professional human certification - demonstrating substantial expertise in privacy law, technical controls, and AI governance. The results highlight both the strengths and domain-specific gaps of current LLMs and offer practical insights for privacy officers, compliance leads, and technologists assessing the readiness of AI tools for high-stakes data governance roles. This paper provides an overview for professionals navigating the intersection of AI advancement and regulatory risk and establishes a machine benchmark based on human-centric evaluations.",
      "tldr_zh": "è¯¥ç ”ç©¶è¯„ä¼°äº†å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†ç›‘ç®¡åˆè§„ã€éšç§è®¡åˆ’ç®¡ç†å’Œäººå·¥æ™ºèƒ½æ²»ç†(AI governance)æ–¹é¢çš„å¯é æ€§ã€‚ç ”ç©¶äººå‘˜é€‰å–äº†æ¥è‡ª OpenAIã€Anthropicã€Google DeepMindã€Meta å’Œ DeepSeek çš„åä¸ªé¢†å…ˆæ¨¡å‹ï¼Œé€šè¿‡ IAPPï¼ˆå›½é™…éšç§ä¸“ä¸šäººå£«åä¼šï¼‰çš„è¡Œä¸šæ ‡å‡†è®¤è¯è€ƒè¯•ï¼ˆåŒ…æ‹¬ CIPP/USã€CIPMã€CIPT å’Œ AIGPï¼‰åœ¨é—­å·ç¯å¢ƒä¸‹å¯¹å…¶è¿›è¡Œäº†åŸºå‡†æµ‹è¯•ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGemini 2.5 Pro å’Œ OpenAI çš„ GPT-5 ç­‰å‰æ²¿æ¨¡å‹åœ¨éšç§æ³•å¾‹ã€æŠ€æœ¯æ§åˆ¶å’Œæ²»ç†å®è·µä¸­è¡¨ç°å“è¶Šï¼Œå…¶å¾—åˆ†å‡è¶…è¿‡äº†äººç±»ä¸“ä¸šè®¤è¯çš„åˆæ ¼é—¨æ§›ã€‚ç ”ç©¶æ·±å…¥æ¢è®¨äº†å½“å‰æ¨¡å‹çš„é¢†åŸŸç‰¹å®šä¼˜åŠ¿ä¸èƒ½åŠ›ç¼ºå£ï¼Œä¸ºéšç§å®˜å‘˜å’Œåˆè§„ä¸»ç®¡åœ¨è¯„ä¼° AI å·¥å…·ç”¨äºé«˜é£é™©æ•°æ®æ²»ç†è§’è‰²æ—¶æä¾›äº†é‡è¦å‚è€ƒã€‚è¯¥è®ºæ–‡é€šè¿‡å»ºç«‹åŸºäºäººç±»è¯„ä¼°æ ‡å‡†çš„æœºå™¨åŸºå‡†ï¼Œä¸ºæ³•å¾‹ç›‘ç®¡ä¸æŠ€æœ¯è¿›æ­¥çš„äº¤æ±‡ç ”ç©¶æä¾›äº†æœ‰åŠ›æ”¯æŒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09036v1",
      "published_date": "2025-08-12 15:57:22 UTC",
      "updated_date": "2025-08-12 15:57:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:13:57.651046+00:00"
    },
    {
      "arxiv_id": "2508.09032v1",
      "title": "Spatial Traces: Enhancing VLA Models with Spatial-Temporal Understanding",
      "title_zh": "Spatial Tracesï¼šé€šè¿‡æ—¶ç©ºç†è§£å¢å¼º VLA æ¨¡å‹",
      "authors": [
        "Maxim A. Patratskiy",
        "Alexey K. Kovalev",
        "Aleksandr I. Panov"
      ],
      "abstract": "Vision-Language-Action models have demonstrated remarkable capabilities in predicting agent movements within virtual environments and real-world scenarios based on visual observations and textual instructions. Although recent research has focused on enhancing spatial and temporal understanding independently, this paper presents a novel approach that integrates both aspects through visual prompting. We introduce a method that projects visual traces of key points from observations onto depth maps, enabling models to capture both spatial and temporal information simultaneously. The experiments in SimplerEnv show that the mean number of tasks successfully solved increased for 4% compared to SpatialVLA and 19% compared to TraceVLA. Furthermore, we show that this enhancement can be achieved with minimal training data, making it particularly valuable for real-world applications where data collection is challenging. The project page is available at https://ampiromax.github.io/ST-VLA.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€åŠ¨ä½œæ¨¡å‹(Vision-Language-Action models, VLA)åœ¨é¢„æµ‹æ™ºèƒ½ä½“åŠ¨ä½œæ—¶çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åä¸ºSpatial Tracesçš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨é€šè¿‡è§†è§‰æç¤º(visual prompting)åŒæ—¶å¢å¼ºæ¨¡å‹çš„ç©ºé—´å’Œæ—¶é—´ç†è§£èƒ½åŠ›ã€‚è¯¥æ–¹æ³•é€šè¿‡å°†è§‚å¯Ÿåˆ°çš„å…³é”®ç‚¹è§†è§‰è½¨è¿¹æŠ•å½±åˆ°æ·±åº¦å›¾(depth maps)ä¸Šï¼Œä½¿æ¨¡å‹èƒ½å¤Ÿæœ‰æ•ˆåœ°åŒæ­¥æ•æ‰æ—¶ç©ºä¿¡æ¯ã€‚åœ¨SimplerEnvç¯å¢ƒä¸­çš„å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•çš„å¹³å‡ä»»åŠ¡æˆåŠŸç‡ç›¸è¾ƒäºSpatialVLAæå‡äº†4%ï¼Œç›¸è¾ƒäºTraceVLAæ˜¾è‘—æå‡äº†19%ã€‚æ­¤å¤–ï¼Œè¯¥æ–¹æ¡ˆä»…éœ€æå°‘çš„è®­ç»ƒæ•°æ®å³å¯å®ç°æ˜¾è‘—çš„æ€§èƒ½å¢å¼ºï¼Œè¿™å¯¹äºæ•°æ®é‡‡é›†å›°éš¾çš„ç°å®ä¸–ç•Œåº”ç”¨åœºæ™¯å…·æœ‰æé«˜çš„å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09032v1",
      "published_date": "2025-08-12 15:53:45 UTC",
      "updated_date": "2025-08-12 15:53:45 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:02.148288+00:00"
    },
    {
      "arxiv_id": "2508.10052v1",
      "title": "NetMoniAI: An Agentic AI Framework for Network Security & Monitoring",
      "title_zh": "NetMoniAIï¼šé¢å‘ç½‘ç»œå®‰å…¨ä¸ç›‘æ§çš„æ™ºèƒ½ä½“ AI æ¡†æ¶",
      "authors": [
        "Pallavi Zambare",
        "Venkata Nikhil Thanikella",
        "Nikhil Padmanabh Kottur",
        "Sree Akhil Akula",
        "Ying Liu"
      ],
      "abstract": "In this paper, we present NetMoniAI, an agentic AI framework for automatic network monitoring and security that integrates decentralized analysis with lightweight centralized coordination. The framework consists of two layers: autonomous micro-agents at each node perform local traffic analysis and anomaly detection. A central controller then aggregates insights across nodes to detect coordinated attacks and maintain system-wide situational awareness. We evaluated NetMoniAI on a local micro-testbed and through NS-3 simulations. Results confirm that the two-tier agentic-AI design scales under resource constraints, reduces redundancy, and improves response time without compromising accuracy. To facilitate broader adoption and reproducibility, the complete framework is available as open source. This enables researchers and practitioners to replicate, validate, and extend it across diverse network environments and threat scenarios. Github link: https://github.com/pzambare3/NetMoniAI",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† NetMoniAIï¼Œä¸€ç§ç”¨äºè‡ªåŠ¨åŒ–ç½‘ç»œç›‘æ§ä¸å®‰å…¨çš„ Agentic AI æ¡†æ¶ï¼Œé€šè¿‡æ•´åˆå»ä¸­å¿ƒåŒ–åˆ†æä¸è½»é‡åŒ–ä¸­å¿ƒåè°ƒæ¥æå‡é˜²å¾¡æ•ˆç‡ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸¤å±‚æ¶æ„ï¼Œå…¶ä¸­éƒ¨ç½²åœ¨å„èŠ‚ç‚¹çš„è‡ªä¸» Micro-agents è´Ÿè´£æœ¬åœ°æµé‡åˆ†æä¸å¼‚å¸¸æ£€æµ‹ï¼Œè€Œä¸­å¤®æ§åˆ¶å™¨ï¼ˆCentral Controllerï¼‰åˆ™è´Ÿè´£èšåˆè·¨èŠ‚ç‚¹æ´å¯Ÿä»¥è¯†åˆ«ååŒæ”»å‡»å¹¶ç»´æŒç³»ç»Ÿçº§æ€åŠ¿æ„ŸçŸ¥ã€‚ç ”ç©¶äººå‘˜é€šè¿‡æœ¬åœ°å¾®å‹æµ‹è¯•åºŠï¼ˆMicro-testbedï¼‰å’Œ NS-3 ä»¿çœŸå¯¹è¯¥ç³»ç»Ÿè¿›è¡Œäº†è¯„ä¼°ï¼Œç»“æœè¯å®è¿™ç§ä¸¤å±‚ Agentic AI è®¾è®¡åœ¨èµ„æºå—é™çš„æƒ…å†µä¸‹å…·æœ‰å‡ºè‰²çš„æ‰©å±•æ€§ã€‚å®éªŒæ•°æ®è¡¨æ˜ï¼ŒNetMoniAI åœ¨ä¸æŸå¤±å‡†ç¡®æ€§çš„å‰æä¸‹ï¼Œæ˜¾è‘—å‡å°‘äº†æ•°æ®å†—ä½™å¹¶ç¼©çŸ­äº†å“åº”æ—¶é—´ã€‚æ­¤å¤–ï¼Œè¯¥æ¡†æ¶å·²åœ¨ GitHub å¼€æºï¼Œæ—¨åœ¨ä¸ºç§‘ç ”äººå‘˜å’Œä»ä¸šè€…åœ¨å¤šæ ·åŒ–çš„ç½‘ç»œç¯å¢ƒä¸å¨èƒåœºæ™¯ä¸­æä¾›å¯å¤ç°ã€å¯æ‰©å±•çš„å®‰å…¨ç›‘æµ‹æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted in IEEE 3rd International Conference on Artificial Intelligence, Blockchain, and Internet of Things (AIBThings 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.10052v1",
      "published_date": "2025-08-12 15:48:53 UTC",
      "updated_date": "2025-08-12 15:48:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:06.056175+00:00"
    },
    {
      "arxiv_id": "2508.09027v1",
      "title": "A First Look at Predictability and Explainability of Pre-request Passenger Waiting Time in Ridesharing Systems",
      "title_zh": "å…±äº«å‡ºè¡Œç³»ç»Ÿä¸­è¯·æ±‚å‰ä¹˜å®¢ç­‰å¾…æ—¶é—´çš„å¯é¢„æµ‹æ€§ä¸å¯è§£é‡Šæ€§åˆæ¢",
      "authors": [
        "Jie Wang",
        "Guang Wang"
      ],
      "abstract": "Passenger waiting time prediction plays a critical role in enhancing both ridesharing user experience and platform efficiency. While most existing research focuses on post-request waiting time prediction with knowing the matched driver information, pre-request waiting time prediction (i.e., before submitting a ride request and without matching a driver) is also important, as it enables passengers to plan their trips more effectively and enhance the experience of both passengers and drivers. However, it has not been fully studied by existing works. In this paper, we take the first step toward understanding the predictability and explainability of pre-request passenger waiting time in ridesharing systems. Particularly, we conduct an in-depth data-driven study to investigate the impact of demand&supply dynamics on passenger waiting time. Based on this analysis and feature engineering, we propose FiXGBoost, a novel feature interaction-based XGBoost model designed to predict waiting time without knowing the assigned driver information. We further perform an importance analysis to quantify the contribution of each factor. Experiments on a large-scale real-world ridesharing dataset including over 30 million trip records show that our FiXGBoost can achieve a good performance for pre-request passenger waiting time prediction with high explainability.",
      "tldr_zh": "è¯¥ç ”ç©¶é¦–æ¬¡æ·±å…¥æ¢è®¨äº†ç½‘çº¦è½¦ç³»ç»Ÿä¸­è¯·æ±‚å‰(pre-request)ä¹˜å®¢ç­‰å¾…æ—¶é—´çš„é¢„æµ‹å¯èƒ½æ€§ä¸å¯è§£é‡Šæ€§ï¼Œå¡«è¡¥äº†ç°æœ‰ç ”ç©¶å¤šå…³æ³¨åŒ¹é…é©±åŠ¨ç¨‹åºåç­‰å¾…æ—¶é—´çš„ç©ºç™½ã€‚é€šè¿‡å¯¹ä¾›éœ€åŠ¨æ€(demand&supply dynamics)å½±å“çš„æ·±å…¥æ•°æ®é©±åŠ¨åˆ†æï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§åä¸ºFiXGBoostçš„æ–°å‹ç‰¹å¾äº¤äº’XGBoostæ¨¡å‹ï¼Œç”¨äºåœ¨æœªçŸ¥åŒ¹é…é©±åŠ¨ä¿¡æ¯çš„æƒ…å†µä¸‹é¢„æµ‹ç­‰å¾…æ—¶é—´ã€‚è¯¥æ¨¡å‹ç»“åˆäº†ç»†è‡´çš„ç‰¹å¾å·¥ç¨‹ï¼Œå¹¶é€šè¿‡é‡è¦æ€§åˆ†æé‡åŒ–äº†å„å› ç´ å¯¹ç­‰å¾…æ—¶é—´çš„å½±å“ã€‚åœ¨åŒ…å«è¶…è¿‡3000ä¸‡æ¡è¡Œç¨‹è®°å½•çš„å¤§è§„æ¨¡çœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒFiXGBooståœ¨è¯·æ±‚å‰ç­‰å¾…æ—¶é—´é¢„æµ‹ä»»åŠ¡ä¸­å…·æœ‰ä¼˜å¼‚çš„æ€§èƒ½ï¼Œå¹¶å±•ç°å‡ºæé«˜çš„å¯è§£é‡Šæ€§(explainability)ã€‚è¿™é¡¹ç ”ç©¶å¯¹äºæ”¹å–„ä¹˜å®¢å‡ºè¡Œä½“éªŒå’Œæå‡ç½‘çº¦è½¦å¹³å°è¿è¥æ•ˆç‡å…·æœ‰é‡è¦ä»·å€¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09027v1",
      "published_date": "2025-08-12 15:42:14 UTC",
      "updated_date": "2025-08-12 15:42:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:15.342937+00:00"
    },
    {
      "arxiv_id": "2508.09023v2",
      "title": "E3-Rewrite: Learning to Rewrite SQL for Executability, Equivalence,and Efficiency",
      "title_zh": "E3-Rewriteï¼šé¢å‘å¯æ‰§è¡Œæ€§ã€ç­‰ä»·æ€§ä¸é«˜æ•ˆæ€§çš„ SQL é‡å†™å­¦ä¹ ",
      "authors": [
        "Dongjie Xu",
        "Yue Cui",
        "Weijie Shi",
        "Qingzhi Ma",
        "Hanghui Guo",
        "Jiaming Li",
        "Yao Zhao",
        "Ruiyuan Zhang",
        "Shimin Di",
        "Jia Zhu",
        "Kai Zheng",
        "Jiajie Xu"
      ],
      "abstract": "SQL query rewriting aims to reformulate a query into a more efficient form while preserving equivalence. Most existing methods rely on predefined rewrite rules. However, such rule-based approaches face fundamental limitations: (1) fixed rule sets generalize poorly to novel query patterns and struggle with complex queries; (2) a wide range of effective rewriting strategies cannot be fully captured by declarative rules. To overcome these issues, we propose using large language models (LLMs) to generate rewrites. LLMs can capture complex strategies, such as evaluation reordering and CTE rewriting. Despite this potential, directly applying LLMs often results in performance regressions or non-equivalent rewrites due to a lack of execution awareness and semantic grounding. To address these challenges, We present E3-Rewrite, an LLM-based SQL rewriting framework that produces executable, equivalent, and efficient queries. It integrates two core components: a context construction module and a reinforcement learning framework. First, the context module leverages execution plans and retrieved demonstrations to build bottleneck-aware prompts that guide inference-time rewriting. Second, we design a reward function targeting executability, equivalence, and efficiency, evaluated via syntax checks, equivalence verification, and cost estimation. Third, to ensure stable multi-objective learning, we adopt a staged curriculum that first emphasizes executability and equivalence, then gradually incorporates efficiency. Across multiple SQL benchmarks, our experiments demonstrate that E3-Rewrite can shorten query execution time by as much as 25.6% relative to leading baselines, while also producing up to 24.4% more rewrites that meet strict equivalence criteria. These gains extend to challenging query patterns that prior approaches could not effectively optimize.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†E3-Rewriteï¼Œè¿™æ˜¯ä¸€ä¸ªåŸºäºå¤§è¯­è¨€æ¨¡å‹(LLMs)çš„SQLé‡å†™æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°å¯æ‰§è¡Œæ€§(Executability)ã€ç­‰ä»·æ€§(Equivalence)å’Œé«˜æ•ˆæ€§(Efficiency)ã€‚é’ˆå¯¹ä¼ ç»ŸåŸºäºè§„åˆ™çš„æ–¹æ³•åœ¨å¤„ç†å¤æ‚æŸ¥è¯¢å’Œæ–°æ¨¡å¼æ—¶çš„å±€é™æ€§ï¼ŒE3-Rewriteé›†æˆäº†ä¸Šä¸‹æ–‡æ„å»ºæ¨¡å—å’Œå¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æ¡†æ¶ã€‚è¯¥æ¡†æ¶åˆ©ç”¨æ‰§è¡Œè®¡åˆ’(Execution Plans)å’Œæ£€ç´¢åˆ°çš„ç¤ºä¾‹æ„å»ºç“¶é¢ˆæ„ŸçŸ¥æç¤º(Bottleneck-aware Prompts)ä»¥æŒ‡å¯¼æ¨ç†ï¼Œå¹¶é€šè¿‡é’ˆå¯¹ä¸‰ä¸ªæ ¸å¿ƒç›®æ ‡çš„å¥–åŠ±å‡½æ•°è¿›è¡Œä¼˜åŒ–ã€‚ä¸ºäº†ç¡®ä¿å¤šç›®æ ‡å­¦ä¹ çš„ç¨³å®šæ€§ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸€ç§åˆ†é˜¶æ®µè¯¾ç¨‹å­¦ä¹ (Staged Curriculum)ç­–ç•¥ï¼Œä¼˜å…ˆä¿éšœæŸ¥è¯¢çš„å¯æ‰§è¡Œæ€§ä¸ç­‰ä»·æ€§ï¼Œéšåé€æ­¥å¼•å…¥æ•ˆç‡æŒ‡æ ‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šä¸ªSQLåŸºå‡†æµ‹è¯•ä¸­ï¼ŒE3-Rewriteç›¸æ¯”é¢†å…ˆçš„åŸºå‡†æ¨¡å‹å¯å°†æŸ¥è¯¢æ‰§è¡Œæ—¶é—´ç¼©çŸ­å¤šè¾¾25.6%ï¼ŒåŒæ—¶ç”Ÿæˆçš„ç¬¦åˆä¸¥æ ¼ç­‰ä»·æ ‡å‡†çš„é‡å†™æŸ¥è¯¢æ•°é‡æå‡äº†24.4%ï¼Œæœ‰æ•ˆè§£å†³äº†ä»¥å¾€æ–¹æ³•éš¾ä»¥ä¼˜åŒ–çš„å¤æ‚æŸ¥è¯¢æ¨¡å¼ã€‚",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09023v2",
      "published_date": "2025-08-12 15:38:10 UTC",
      "updated_date": "2025-08-15 03:52:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:17.086531+00:00"
    },
    {
      "arxiv_id": "2508.09022v3",
      "title": "Leveraging Unlabeled Data from Unknown Sources via Dual-Path Guidance for Deepfake Face Detection",
      "title_zh": "é€šè¿‡åŒè·¯å¾„å¼•å¯¼åˆ©ç”¨æœªçŸ¥æ¥æºæ— æ ‡ç­¾æ•°æ®è¿›è¡ŒDeepfakeäººè„¸æ£€æµ‹",
      "authors": [
        "Zhiqiang Yang",
        "Renshuai Tao",
        "Chunjie Zhang",
        "guodong yang",
        "Xiaolong Zheng",
        "Yao Zhao"
      ],
      "abstract": "Existing deepfake detection methods heavily rely on static labeled datasets. However, with the proliferation of generative models, real-world scenarios are flooded with massive amounts of unlabeled fake face data from unknown sources. This presents a critical dilemma: detectors relying solely on existing data face generalization failure, while manual labeling for this new stream is infeasible due to the high realism of fakes. A more fundamental challenge is that, unlike typical unsupervised learning tasks where categories are clearly defined, real and fake faces share the same semantics, which leads to a decline in the performance of traditional unsupervised strategies. Therefore, there is an urgent need for a new paradigm designed specifically for this scenario to effectively utilize these unlabeled data. Accordingly, this paper proposes a dual-path guided network (DPGNet) to address two key challenges: (1) bridging the domain differences between faces generated by different generative models; and (2) utilizing unlabeled image samples. The method comprises two core modules: text-guided cross-domain alignment, which uses learnable cues to unify visual and textual embeddings into a domain-invariant feature space; and curriculum-driven pseudo-label generation, which dynamically utilizes unlabeled samples. Extensive experiments on multiple mainstream datasets show that DPGNet significantly outperforms existing techniques,, highlighting its effectiveness in addressing the challenges posed by the deepfakes using unlabeled data.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰Deepfakeæ£€æµ‹æ–¹æ³•ä¾èµ–é™æ€æ ‡è®°æ•°æ®ä¸”åœ¨é¢å¯¹æ¥æºæœªçŸ¥çš„æµ·é‡æœªæ ‡æ³¨æ•°æ®æ—¶æ³›åŒ–æ€§è¾ƒå·®çš„é—®é¢˜ï¼Œæå‡ºäº†åŒè·¯å¾„å¼•å¯¼ç½‘ç»œDPGNetã€‚ç”±äºçœŸå®ä¸è™šå‡äººè„¸åœ¨è¯­ä¹‰ä¸Šé«˜åº¦ç›¸ä¼¼ï¼Œå¯¼è‡´ä¼ ç»Ÿæ— ç›‘ç£ç­–ç•¥åœ¨åŒºåˆ†äºŒè€…æ—¶æ•ˆæœæœ‰é™ï¼Œå› æ­¤DPGNetè®¾è®¡äº†ä¸¤ä¸ªæ ¸å¿ƒæ¨¡å—æ¥æœ‰æ•ˆåˆ©ç”¨è¿™äº›æœªæ ‡æ³¨æ•°æ®ã€‚é¦–å…ˆæ˜¯æ–‡æœ¬å¼•å¯¼çš„è·¨åŸŸå¯¹é½(text-guided cross-domain alignment)æ¨¡å—ï¼Œé€šè¿‡å¯å­¦ä¹ çº¿ç´¢å°†è§†è§‰å’Œæ–‡æœ¬åµŒå…¥ç»Ÿä¸€åˆ°åŸŸä¸å˜çš„ç‰¹å¾ç©ºé—´ä¸­ï¼Œæ—¨åœ¨æ¶ˆé™¤ä¸åŒç”Ÿæˆæ¨¡å‹ä¹‹é—´çš„åŸŸå·®å¼‚ã€‚å…¶æ¬¡æ˜¯è¯¾ç¨‹é©±åŠ¨çš„ä¼ªæ ‡ç­¾ç”Ÿæˆ(curriculum-driven pseudo-label generation)æ¨¡å—ï¼Œé€šè¿‡åŠ¨æ€ç­›é€‰æœºåˆ¶å……åˆ†æŒ–æ˜æœªæ ‡æ³¨æ ·æœ¬çš„æ½œåœ¨ä»·å€¼ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDPGNetåœ¨å¤šä¸ªä¸»æµæ•°æ®é›†ä¸Šå‡æ˜¾è‘—ä¼˜äºç°æœ‰æŠ€æœ¯ï¼Œè¯æ˜äº†å…¶åœ¨åˆ©ç”¨æœªçŸ¥æ¥æºæ•°æ®æå‡æ·±åº¦ä¼ªé€ æ£€æµ‹èƒ½åŠ›æ–¹é¢çš„å“è¶Šæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11pages,4figures",
      "pdf_url": "https://arxiv.org/pdf/2508.09022v3",
      "published_date": "2025-08-12 15:37:17 UTC",
      "updated_date": "2025-11-25 09:30:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:19.797577+00:00"
    },
    {
      "arxiv_id": "2508.09021v1",
      "title": "Attacks and Defenses Against LLM Fingerprinting",
      "title_zh": "LLM æŒ‡çº¹è¯†åˆ«çš„æ”»å‡»ä¸é˜²å¾¡",
      "authors": [
        "Kevin Kurian",
        "Ethan Holland",
        "Sean Oesch"
      ],
      "abstract": "As large language models are increasingly deployed in sensitive environments, fingerprinting attacks pose significant privacy and security risks. We present a study of LLM fingerprinting from both offensive and defensive perspectives. Our attack methodology uses reinforcement learning to automatically optimize query selection, achieving better fingerprinting accuracy with only 3 queries compared to randomly selecting 3 queries from the same pool. Our defensive approach employs semantic-preserving output filtering through a secondary LLM to obfuscate model identity while maintaining semantic integrity. The defensive method reduces fingerprinting accuracy across tested models while preserving output quality. These contributions show the potential to improve fingerprinting tools capabilities while providing practical mitigation strategies against fingerprinting attacks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨æ•æ„Ÿç¯å¢ƒä¸­é¢ä¸´çš„æŒ‡çº¹è¯†åˆ«ï¼ˆFingerprintingï¼‰æ”»å‡»åŠå…¶é˜²å¾¡æ‰‹æ®µè¿›è¡Œäº†æ·±å…¥æ¢è®¨ã€‚åœ¨æ”»å‡»å±‚é¢ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰çš„æ–¹æ³•æ¥è‡ªåŠ¨ä¼˜åŒ–æŸ¥è¯¢é€‰æ‹©ï¼Œæ˜¾è‘—æå‡äº†è¯†åˆ«æ•ˆç‡ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä»…éœ€3æ¬¡æŸ¥è¯¢å³å¯å®ç°æ¯”éšæœºé€‰æ‹©æ›´é«˜çš„æŒ‡çº¹è¯†åˆ«å‡†ç¡®ç‡ã€‚åœ¨é˜²å¾¡å±‚é¢ï¼Œç ”ç©¶é‡‡ç”¨äº†ä¸€ç§é€šè¿‡æ¬¡çº§ LLM è¿›è¡Œè¯­ä¹‰ä¿ç•™è¾“å‡ºè¿‡æ»¤ï¼ˆSemantic-preserving output filteringï¼‰çš„æŠ€æœ¯ï¼Œæ—¨åœ¨æ¨¡ç³Šæ¨¡å‹èº«ä»½çš„åŒæ—¶ç»´æŒè¯­ä¹‰å®Œæ•´æ€§ã€‚è¿™ç§é˜²å¾¡æ–¹æ³•åœ¨ä¿æŒè¾“å‡ºè´¨é‡çš„å‰æä¸‹ï¼Œèƒ½æœ‰æ•ˆé™ä½æµ‹è¯•æ¨¡å‹è¢«æŒ‡çº¹è¯†åˆ«çš„å‡†ç¡®ç‡ã€‚è¿™äº›è´¡çŒ®ä¸ä»…æ­ç¤ºäº†æå‡æŒ‡çº¹è¯†åˆ«å·¥å…·èƒ½åŠ›çš„æ½œåŠ›ï¼Œè¿˜ä¸ºåº”å¯¹æ­¤ç±»éšç§ä¸å®‰å…¨é£é™©æä¾›äº†å®ç”¨çš„ç¼“è§£ç­–ç•¥ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09021v1",
      "published_date": "2025-08-12 15:36:36 UTC",
      "updated_date": "2025-08-12 15:36:36 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:21.895003+00:00"
    },
    {
      "arxiv_id": "2508.09019v1",
      "title": "Activation Steering for Bias Mitigation: An Interpretable Approach to Safer LLMs",
      "title_zh": "é’ˆå¯¹åè§ç¼“è§£çš„æ¿€æ´»å¼•å¯¼ï¼šä¸€ç§å®ç°æ›´å®‰å…¨å¤§è¯­è¨€æ¨¡å‹çš„å¯è§£é‡Šæ–¹æ³•",
      "authors": [
        "Shivam Dubey"
      ],
      "abstract": "As large language models (LLMs) become more integrated into societal systems, the risk of them perpetuating and amplifying harmful biases becomes a critical safety concern. Traditional methods for mitigating bias often rely on data filtering or post-hoc output moderation, which treat the model as an opaque black box. In this work, we introduce a complete, end-to-end system that uses techniques from mechanistic interpretability to both identify and actively mitigate bias directly within a model's internal workings. Our method involves two primary stages. First, we train linear \"probes\" on the internal activations of a model to detect the latent representations of various biases (e.g., gender, race, age). Our experiments on \\texttt{gpt2-large} demonstrate that these probes can identify biased content with near-perfect accuracy, revealing that bias representations become most salient in the model's later layers. Second, we leverage these findings to compute \"steering vectors\" by contrasting the model's activation patterns for biased and neutral statements. By adding these vectors during inference, we can actively steer the model's generative process away from producing harmful, stereotypical, or biased content in real-time. We demonstrate the efficacy of this activation steering technique, showing that it successfully alters biased completions toward more neutral alternatives. We present our work as a robust and reproducible system that offers a more direct and interpretable approach to building safer and more accountable LLMs.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†ä¸€ä¸ªæ—¨åœ¨å‡å°‘å¤§è¯­è¨€æ¨¡å‹ (LLMs) æœ‰å®³åè§çš„ç«¯åˆ°ç«¯ç³»ç»Ÿï¼Œé€šè¿‡æœºæ¢°è§£é‡Šæ€§ (mechanistic interpretability) æŠ€æœ¯ç›´æ¥è¯†åˆ«å¹¶å¹²é¢„æ¨¡å‹çš„å†…éƒ¨è¿ä½œã€‚è¯¥æ–¹æ³•é¦–å…ˆé€šè¿‡åœ¨æ¨¡å‹å†…éƒ¨æ¿€æ´»ä¸Šè®­ç»ƒçº¿æ€§æ¢æµ‹å™¨ (linear probes) æ¥æ£€æµ‹æ€§åˆ«ã€ç§æ—å’Œå¹´é¾„ç­‰åè§çš„æ½œåœ¨è¡¨å¾ã€‚å®éªŒåœ¨ gpt2-large æ¨¡å‹ä¸Šè¯æ˜äº†è¿™äº›æ¢æµ‹å™¨èƒ½ä»¥æé«˜çš„å‡†ç¡®ç‡è¯†åˆ«åè§å†…å®¹ï¼Œå¹¶æ­ç¤ºäº†åè§è¡¨å¾åœ¨æ¨¡å‹çš„åæœŸå±‚ (later layers) æœ€ä¸ºæ˜¾è‘—ã€‚éšåï¼Œç ”ç©¶è€…é€šè¿‡å¯¹æ¯”åè§å’Œä¸­æ€§é™ˆè¿°çš„æ¿€æ´»æ¨¡å¼è®¡ç®—å‡ºè½¬å‘å‘é‡ (steering vectors)ï¼Œå¹¶åœ¨æ¨ç† (inference) è¿‡ç¨‹ä¸­å°†å…¶åŠ å…¥ï¼Œä»è€Œå®æ—¶å¼•å¯¼æ¨¡å‹çš„ç”Ÿæˆè¿‡ç¨‹è¿œç¦»æœ‰å®³æˆ–åˆ»æ¿å°è±¡å†…å®¹ã€‚ç»“æœæ˜¾ç¤ºï¼Œè¿™ç§æ¿€æ´»è½¬å‘ (activation steering) æŠ€æœ¯èƒ½æœ‰æ•ˆå°†åè§è¡¥å…¨è½¬åŒ–ä¸ºä¸­æ€§è¡¨è¾¾ï¼Œä¸ºæ„å»ºæ›´å®‰å…¨ã€æ›´å…·å¯è§£é‡Šæ€§ä¸”è´Ÿè´£ä»»çš„ LLMs æä¾›äº†ä¸€ç§ç¨³å¥ä¸”å¯é‡ç°çš„æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09019v1",
      "published_date": "2025-08-12 15:34:18 UTC",
      "updated_date": "2025-08-12 15:34:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:25.652737+00:00"
    },
    {
      "arxiv_id": "2508.09012v1",
      "title": "LyS at SemEval 2025 Task 8: Zero-Shot Code Generation for Tabular QA",
      "title_zh": "LyS å‚åŠ  SemEval 2025 Task 8ï¼šé¢å‘è¡¨æ ¼é—®ç­”çš„é›¶æ ·æœ¬ä»£ç ç”Ÿæˆ",
      "authors": [
        "AdriÃ¡n Gude",
        "Roi Santos-RÃ­os",
        "Francisco Prado-ValiÃ±o",
        "Ana Ezquerro",
        "JesÃºs Vilares"
      ],
      "abstract": "This paper describes our participation in SemEval 2025 Task 8, focused on Tabular Question Answering. We developed a zero-shot pipeline that leverages an Large Language Model to generate functional code capable of extracting the relevant information from tabular data based on an input question. Our approach consists of a modular pipeline where the main code generator module is supported by additional components that identify the most relevant columns and analyze their data types to improve extraction accuracy. In the event that the generated code fails, an iterative refinement process is triggered, incorporating the error feedback into a new generation prompt to enhance robustness. Our results show that zero-shot code generation is a valid approach for Tabular QA, achieving rank 33 of 53 in the test phase despite the lack of task-specific fine-tuning.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº†ä½œè€…å‚åŠ  SemEval 2025 Task 8 çš„ç ”ç©¶æˆæœï¼Œé’ˆå¯¹è¡¨æ ¼é—®ç­” (Tabular Question Answering) ä»»åŠ¡å¼€å‘äº†ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (Large Language Model) çš„é›¶æ ·æœ¬ (Zero-Shot) ä»£ç ç”Ÿæˆæµæ°´çº¿ã€‚è¯¥æµæ°´çº¿é‡‡ç”¨æ¨¡å—åŒ–æ¶æ„ï¼Œé€šè¿‡è¯†åˆ«ç›¸å…³åˆ—å’Œåˆ†ææ•°æ®ç±»å‹çš„è¾…åŠ©ç»„ä»¶æ¥æå‡ä¿¡æ¯æå–çš„å‡†ç¡®ç‡ã€‚é’ˆå¯¹ç”Ÿæˆçš„ä»£ç è¿è¡Œå¤±è´¥çš„æƒ…å†µï¼Œç ”ç©¶å¼•å…¥äº†è¿­ä»£ä¼˜åŒ–æœºåˆ¶ï¼Œåˆ©ç”¨é”™è¯¯åé¦ˆæ”¹è¿›æç¤ºè¯ä»¥å¢å¼ºç³»ç»Ÿçš„é²æ£’æ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé›¶æ ·æœ¬ä»£ç ç”Ÿæˆæ˜¯å¤„ç† Tabular QA ä»»åŠ¡çš„ä¸€ç§æœ‰æ•ˆæ–¹æ³•ã€‚å°½ç®¡æ²¡æœ‰è¿›è¡Œé’ˆå¯¹æ€§çš„å¾®è°ƒ (Task-specific fine-tuning)ï¼Œè¯¥ç³»ç»Ÿåœ¨æµ‹è¯•é˜¶æ®µçš„ 53 ä¸ªå‚èµ›é˜Ÿä¼ä¸­æ’åç¬¬ 33 ä½ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to SemEval 2025. Camera-ready version",
      "pdf_url": "https://arxiv.org/pdf/2508.09012v1",
      "published_date": "2025-08-12 15:25:31 UTC",
      "updated_date": "2025-08-12 15:25:31 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:06.394055+00:00"
    },
    {
      "arxiv_id": "2508.09001v1",
      "title": "Retrospective Sparse Attention for Efficient Long-Context Generation",
      "title_zh": "é¢å‘é«˜æ•ˆé•¿ä¸Šä¸‹æ–‡ç”Ÿæˆçš„å›æº¯æ€§ç¨€ç–æ³¨æ„åŠ›",
      "authors": [
        "Seonghwan Choi",
        "Beomseok Kang",
        "Dongwon Jo",
        "Jae-Joon Kim"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed in long-context tasks such as reasoning, code generation, and multi-turn dialogue. However, inference over extended contexts is bottlenecked by the Key-Value (KV) cache, whose memory footprint grows linearly with sequence length and dominates latency at each decoding step. While recent KV cache compression methods identify and load important tokens, they focus predominantly on input contexts and fail to address the cumulative attention errors that arise during long decoding. In this paper, we introduce RetroAttention, a novel KV cache update technique that retrospectively revises past attention outputs using newly arrived KV entries from subsequent decoding steps. By maintaining a lightweight output cache, RetroAttention enables past queries to efficiently access more relevant context, while incurring minimal latency overhead. This breaks the fixed-attention-output paradigm and allows continual correction of prior approximations. Extensive experiments on long-generation benchmarks show that RetroAttention consistently outperforms state-of-the-art (SOTA) KV compression methods, increasing effective KV exposure by up to 1.6$\\times$ and accuracy by up to 21.9\\%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† RetroAttentionï¼Œä¸€ç§æ—¨åœ¨æå‡å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰é•¿ä¸Šä¸‹æ–‡ç”Ÿæˆæ•ˆç‡çš„è¿½æº¯å¼ç¨€ç–æ³¨æ„åŠ›æŠ€æœ¯ã€‚é’ˆå¯¹é•¿åºåˆ—æ¨ç†ä¸­ KV cache å¸¦æ¥çš„å†…å­˜ç“¶é¢ˆä»¥åŠè§£ç è¿‡ç¨‹ä¸­æ—¥ç›Šä¸¥é‡çš„æ³¨æ„åŠ›ç´¯ç§¯è¯¯å·®ï¼ŒRetroAttention å…è®¸æ¨¡å‹åˆ©ç”¨è§£ç åç»­æ­¥éª¤ä¸­æ–°ç”Ÿæˆçš„ KV æ¡ç›®è¿½æº¯å¹¶ä¿®æ­£è¿‡å¾€çš„æ³¨æ„åŠ›è¾“å‡ºã€‚è¯¥æ–¹æ³•é€šè¿‡å¼•å…¥è½»é‡çº§è¾“å‡ºç¼“å­˜ï¼Œæ‰“ç ´äº†ä¼ ç»Ÿçš„å›ºå®šæ³¨æ„åŠ›è¾“å‡ºï¼ˆfixed-attention-outputï¼‰èŒƒå¼ï¼Œä½¿å…ˆå‰çš„æŸ¥è¯¢èƒ½å¤ŸåŠ¨æ€ä¸”é«˜æ•ˆåœ°è®¿é—®æ›´å…·ç›¸å…³æ€§çš„ä¸Šä¸‹æ–‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒRetroAttention åœ¨å¤šé¡¹é•¿æ–‡æœ¬ç”ŸæˆåŸºå‡†æµ‹è¯•ä¸­æŒç»­ä¼˜äºç°æœ‰çš„ KV å‹ç¼© SOTA æ–¹æ³•ï¼Œå°†æœ‰æ•ˆ KV æš´éœ²ç¨‹åº¦æå‡äº† 1.6 å€ã€‚è¯¥æŠ€æœ¯åœ¨ä¿è¯æä½å»¶è¿Ÿå¼€é”€çš„åŒæ—¶ï¼Œå°†ç”Ÿæˆå‡†ç¡®ç‡æœ€é«˜æå‡äº† 21.9%ï¼Œä¸ºå®ç°é«˜æ•ˆä¸”ç²¾å‡†çš„é•¿ä¸Šä¸‹æ–‡ä»»åŠ¡å¤„ç†æä¾›äº†æ–°çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09001v1",
      "published_date": "2025-08-12 15:11:47 UTC",
      "updated_date": "2025-08-12 15:11:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:53.695673+00:00"
    },
    {
      "arxiv_id": "2508.08997v2",
      "title": "Intrinsic Memory Agents: Heterogeneous Multi-Agent LLM Systems through Structured Contextual Memory",
      "title_zh": "Intrinsic Memory Agentsï¼šåŸºäºç»“æ„åŒ–ä¸Šä¸‹æ–‡è®°å¿†çš„å¼‚æ„å¤§è¯­è¨€æ¨¡å‹å¤šæ™ºèƒ½ä½“ç³»ç»Ÿ",
      "authors": [
        "Sizhe Yuen",
        "Francisco Gomez Medina",
        "Ting Su",
        "Yali Du",
        "Adam J. Sobey"
      ],
      "abstract": "Multi-agent systems built on Large Language Models (LLMs) show exceptional promise for complex collaborative problem-solving, yet they face fundamental challenges stemming from context window limitations that impair memory consistency, role adherence, and procedural integrity. This paper introduces Intrinsic Memory Agents, a novel framework that addresses these limitations through agent-specific memories that evolve intrinsically with agent outputs. Specifically, our method maintains role-aligned memory that preserves specialized perspectives while focusing on task-relevant information. Our approach utilises a generic memory template applicable to new problems without the need to hand-craft specific memory prompts. We benchmark our approach on the PDDL, FEVER, and ALFWorld datasets, comparing its performance to existing state-of-the-art multi-agentic memory approaches and showing state-of-the-art or comparable performance across all three, with the highest consistency. An additional evaluation is performed on a complex data pipeline design task, and we demonstrate that our approach produces higher quality designs across 5 metrics: scalability, reliability, usability, cost-effectiveness, and documentation, plus additional qualitative evidence of the improvements. Our findings suggest that addressing memory limitations through intrinsic approaches can improve the capabilities of multi-agent LLM systems on structured planning tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Intrinsic Memory Agentsæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨ä¸Šä¸‹æ–‡çª—å£é™åˆ¶ã€è®°å¿†ä¸€è‡´æ€§ã€è§’è‰²ä¾ä»æ€§åŠç¨‹åºå®Œæ•´æ€§æ–¹é¢é¢ä¸´çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶å¼•å…¥äº†éšæ™ºèƒ½ä½“è¾“å‡ºè‡ªå‘æ¼”è¿›çš„ç‰¹å®šè®°å¿†æœºåˆ¶ï¼Œèƒ½å¤Ÿåœ¨ä¿ç•™ä¸“ä¸šåŒ–è§†è§’çš„åŒæ—¶ï¼Œèšç„¦äºä»»åŠ¡ç›¸å…³çš„å…³é”®ä¿¡æ¯ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸€ç§é€šç”¨çš„è®°å¿†æ¨¡æ¿ï¼Œæ— éœ€äººå·¥è®¾è®¡ç‰¹å®šè®°å¿†æç¤ºå³å¯åº”ç”¨äºæ–°ä»»åŠ¡ï¼Œæ˜¾è‘—é™ä½äº†å¼€å‘æˆæœ¬ã€‚åœ¨PDDLã€FEVERå’ŒALFWorldæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šè¾¾åˆ°äº†SOTAæˆ–åŒç­‰æ°´å¹³ï¼Œå¹¶è¡¨ç°å‡ºæœ€é«˜çš„ä¸€è‡´æ€§ã€‚æ­¤å¤–ï¼Œåœ¨å¤æ‚çš„æ•°æ®æµæ°´çº¿è®¾è®¡ä»»åŠ¡ä¸­ï¼Œè¯¥ç³»ç»Ÿåœ¨å¯æ‰©å±•æ€§ã€å¯é æ€§ã€æ˜“ç”¨æ€§ã€æˆæœ¬æ•ˆç›ŠåŠæ–‡æ¡£ç¼–å†™äº”ä¸ªæŒ‡æ ‡ä¸Šå‡å±•ç°å‡ºæ›´é«˜çš„è´¨é‡ã€‚å®éªŒç»“æœè¯æ˜ï¼Œé€šè¿‡å†…åœ¨è®°å¿†è·¯å¾„è§£å†³è®°å¿†å±€é™æ€§ï¼Œå¯æœ‰æ•ˆæå‡å¤šæ™ºèƒ½ä½“LLMç³»ç»Ÿåœ¨ç»“æ„åŒ–è§„åˆ’ä»»åŠ¡ä¸­çš„ç»¼åˆèƒ½åŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08997v2",
      "published_date": "2025-08-12 15:05:00 UTC",
      "updated_date": "2026-01-12 11:46:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:14:54.086206+00:00"
    },
    {
      "arxiv_id": "2508.09240v1",
      "title": "NEFMind: Parameter-Efficient Fine-Tuning of Open-Source LLMs for Telecom APIs Automation",
      "title_zh": "NEFMindï¼šé¢å‘ç”µä¿¡ API è‡ªåŠ¨åŒ–çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹å‚æ•°é«˜æ•ˆå¾®è°ƒ",
      "authors": [
        "Zainab Khan",
        "Ahmed Hussain",
        "Mukesh Thakur",
        "Arto Hellas",
        "Panos Papadimitratos"
      ],
      "abstract": "The use of Service-Based Architecture in modern telecommunications has exponentially increased Network Functions (NFs) and Application Programming Interfaces (APIs), creating substantial operational complexities in service discovery and management. We introduce \\textit{NEFMind}, a framework leveraging parameter-efficient fine-tuning of open-source Large Language Models (LLMs) to address these challenges. It integrates three core components: synthetic dataset generation from Network Exposure Function (NEF) API specifications, model optimization through Quantized-Low-Rank Adaptation, and performance evaluation via GPT-4 Ref Score and BertScore metrics. Targeting 5G Service-Based Architecture APIs, our approach achieves 85% reduction in communication overhead compared to manual discovery methods. Experimental validation using the open-source Phi-2 model demonstrates exceptional API call identification performance at 98-100% accuracy. The fine-tuned Phi-2 model delivers performance comparable to significantly larger models like GPT-4 while maintaining computational efficiency for telecommunications infrastructure deployment. These findings validate domain-specific, parameter-efficient LLM strategies for managing complex API ecosystems in next-generation telecommunications networks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† NEFMind æ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨ Parameter-Efficient Fine-Tuning æŠ€æœ¯è§£å†³ç°ä»£ç”µä¿¡ Service-Based Architecture ä¸­ Network Functions (NFs) å’Œ APIs æ¿€å¢å¸¦æ¥çš„è¿ç»´å¤æ‚æ€§ã€‚NEFMind é›†æˆäº†ä» Network Exposure Function (NEF) API è§„èŒƒç”Ÿæˆåˆæˆæ•°æ®é›†ã€åˆ©ç”¨ Quantized-Low-Rank Adaptation (QLoRA) è¿›è¡Œæ¨¡å‹ä¼˜åŒ–ä»¥åŠé€šè¿‡ GPT-4 Ref Score å’Œ BertScore è¿›è¡Œè¯„ä¼°çš„æ ¸å¿ƒç»„ä»¶ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•é’ˆå¯¹ 5G Service-Based Architecture APIs çš„è‡ªåŠ¨åŒ–ç®¡ç†æ¯”æ‰‹åŠ¨æ–¹æ³•å‡å°‘äº† 85% çš„é€šä¿¡å¼€é”€ã€‚åœ¨åŸºäºå¼€æº Phi-2 æ¨¡å‹çš„éªŒè¯ä¸­ï¼ŒNEFMind å®ç°äº† 98-100% çš„ API call identification å‡†ç¡®ç‡ï¼Œå…¶æ€§èƒ½å¯ä¸è§„æ¨¡æ›´å¤§çš„ GPT-4 åª²ç¾ï¼ŒåŒæ—¶ä¿æŒäº†é€‚ç”¨äºç”µä¿¡åŸºç¡€è®¾æ–½éƒ¨ç½²çš„è®¡ç®—æ•ˆç‡ã€‚è¯¥ç ”ç©¶éªŒè¯äº†é¢†åŸŸç‰¹å®šçš„ LLM ç­–ç•¥åœ¨ç®¡ç†ä¸‹ä¸€ä»£ç”µä¿¡ç½‘ç»œå¤æ‚ API ç”Ÿæ€ç³»ç»Ÿä¸­çš„æœ‰æ•ˆæ€§ä¸å®ç”¨ä»·å€¼ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.09240v1",
      "published_date": "2025-08-12 15:03:22 UTC",
      "updated_date": "2025-08-12 15:03:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:02.381567+00:00"
    },
    {
      "arxiv_id": "2508.08992v1",
      "title": "Prospect Theory Fails for LLMs: Revealing Instability of Decision-Making under Epistemic Uncertainty",
      "title_zh": "å‰æ™¯ç†è®ºå¯¹å¤§è¯­è¨€æ¨¡å‹çš„å¤±æ•ˆï¼šæ­ç¤ºè®¤çŸ¥ä¸ç¡®å®šæ€§ä¸‹çš„å†³ç­–ä¸ç¨³å®šæ€§",
      "authors": [
        "Rui Wang",
        "Qihan Lin",
        "Jiayu Liu",
        "Qing Zong",
        "Tianshi Zheng",
        "Weiqi Wang",
        "Yangqiu Song"
      ],
      "abstract": "Prospect Theory (PT) models human decision-making under uncertainty, while epistemic markers (e.g., maybe) serve to express uncertainty in language. However, it remains largely unexplored whether Prospect Theory applies to contemporary Large Language Models and whether epistemic markers, which express human uncertainty, affect their decision-making behaviour. To address these research gaps, we design a three-stage experiment based on economic questionnaires. We propose a more general and precise evaluation framework to model LLMs' decision-making behaviour under PT, introducing uncertainty through the empirical probability values associated with commonly used epistemic markers in comparable contexts. We then incorporate epistemic markers into the evaluation framework based on their corresponding probability values to examine their influence on LLM decision-making behaviours. Our findings suggest that modelling LLMs' decision-making with PT is not consistently reliable, particularly when uncertainty is expressed in diverse linguistic forms. Our code is released in https://github.com/HKUST-KnowComp/MarPT.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å‰æ™¯ç†è®º(Prospect Theory, PT)æ˜¯å¦é€‚ç”¨äºå¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)ï¼Œå¹¶é‡ç‚¹åˆ†æäº†è¡¨è¾¾äººç±»ä¸ç¡®å®šæ€§çš„è®¤è¯†æ ‡è®°(epistemic markers)å¦‚ä½•å½±å“å…¶å†³ç­–è¡Œä¸ºã€‚ä½œè€…è®¾è®¡äº†ä¸€ä¸ªåŸºäºç»æµå­¦é—®å·çš„ä¸‰é˜¶æ®µå®éªŒï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªé€šç”¨çš„è¯„ä¼°æ¡†æ¶ï¼Œé€šè¿‡å¼•å…¥ä¸è®¤è¯†æ ‡è®°ç›¸å…³çš„ç»éªŒæ¦‚ç‡å€¼æ¥æ¨¡æ‹Ÿæ¨¡å‹åœ¨è®¤çŸ¥ä¸ç¡®å®šæ€§(epistemic uncertainty)ä¸‹çš„è¡¨ç°ã€‚è¯¥æ¡†æ¶å°†è®¤è¯†æ ‡è®°æ ¹æ®å…¶æ¦‚ç‡å€¼æ•´åˆè‡³å®éªŒæµç¨‹ä¸­ï¼Œä»¥ç³»ç»Ÿæ€§åœ°æ£€éªŒè¯­è¨€å½¢å¼çš„ä¸ç¡®å®šæ€§å¯¹æ¨¡å‹å†³ç­–çš„å½±å“ã€‚ç ”ç©¶å‘ç°ï¼Œåˆ©ç”¨å‰æ™¯ç†è®ºæ¥å»ºæ¨¡å¤§è¯­è¨€æ¨¡å‹çš„å†³ç­–è¿‡ç¨‹å¹¶ä¸å…·å¤‡æŒç»­çš„å¯é æ€§ã€‚å®éªŒç»“æœæ­ç¤ºäº†æ¨¡å‹åœ¨å†³ç­–é€»è¾‘ä¸Šçš„ä¸ç¨³å®šæ€§ï¼Œå°¤å…¶æ˜¯åœ¨é¢å¯¹å¤šæ ·åŒ–çš„è®¤è¯†æ ‡è®°æ—¶ï¼Œå…¶è¡¨ç°ä¸äººç±»å†³ç­–æ¨¡å¼å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08992v1",
      "published_date": "2025-08-12 15:02:16 UTC",
      "updated_date": "2025-08-12 15:02:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:05.589434+00:00"
    },
    {
      "arxiv_id": "2508.14077v1",
      "title": "Label Smoothing is a Pragmatic Information Bottleneck",
      "title_zh": "æ ‡ç­¾å¹³æ»‘æ˜¯ä¸€ç§åŠ¡å®çš„ä¿¡æ¯ç“¶é¢ˆ",
      "authors": [
        "Sota Kudo"
      ],
      "abstract": "This study revisits label smoothing via a form of information bottleneck. Under the assumption of sufficient model flexibility and no conflicting labels for the same input, we theoretically and experimentally demonstrate that the model output obtained through label smoothing explores the optimal solution of the information bottleneck. Based on this, label smoothing can be interpreted as a practical approach to the information bottleneck, enabling simple implementation. As an information bottleneck method, we experimentally show that label smoothing also exhibits the property of being insensitive to factors that do not contain information about the target, or to factors that provide no additional information about it when conditioned on another variable.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»ä¿¡æ¯ç“¶é¢ˆ(Information Bottleneck)çš„è§’åº¦é‡æ–°å®¡è§†äº†æ ‡ç­¾å¹³æ»‘(Label Smoothing)æŠ€æœ¯ã€‚åœ¨æ¨¡å‹å…·æœ‰è¶³å¤Ÿçµæ´»æ€§ä¸”è¾“å…¥æ ‡ç­¾ä¸å†²çªçš„å‡è®¾ä¸‹ï¼Œè¯¥è®ºæ–‡é€šè¿‡ç†è®ºå’Œå®éªŒè¯æ˜äº†ä½¿ç”¨æ ‡ç­¾å¹³æ»‘å¾—åˆ°çš„æ¨¡å‹è¾“å‡ºå®é™…ä¸Šæ¢ç´¢äº†ä¿¡æ¯ç“¶é¢ˆçš„æœ€ä¼˜è§£ã€‚å› æ­¤ï¼Œæ ‡ç­¾å¹³æ»‘å¯ä»¥è¢«è§£é‡Šä¸ºä¸€ç§å®ç°ä¿¡æ¯ç“¶é¢ˆçš„å®ç”¨æ–¹æ³•ï¼Œå…·å¤‡å®ç°ç®€å•çš„ä¼˜åŠ¿ã€‚å®éªŒç»“æœè¿›ä¸€æ­¥éªŒè¯äº†ä½œä¸ºä¸€ç§ä¿¡æ¯ç“¶é¢ˆæ–¹æ³•ï¼Œæ ‡ç­¾å¹³æ»‘è¡¨ç°å‡ºå¯¹ä¸åŒ…å«ç›®æ ‡ä¿¡æ¯æˆ–åœ¨ç»™å®šæ¡ä»¶ä¸‹ä¸æä¾›é¢å¤–ä¿¡æ¯çš„å› ç´ ä¸æ•æ„Ÿçš„ç‰¹æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 8 figures, published in Transactions on Machine Learning Research (TMLR), 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.14077v1",
      "published_date": "2025-08-12 14:50:23 UTC",
      "updated_date": "2025-08-12 14:50:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:18.094818+00:00"
    },
    {
      "arxiv_id": "2508.08983v1",
      "title": "Rational Inverse Reasoning",
      "title_zh": "ç†æ€§é€†å‘æ¨ç†",
      "authors": [
        "Ben Zandonati",
        "TomÃ¡s Lozano-PÃ©rez",
        "Leslie Pack Kaelbling"
      ],
      "abstract": "Humans can observe a single, imperfect demonstration and immediately generalize to very different problem settings. Robots, in contrast, often require hundreds of examples and still struggle to generalize beyond the training conditions. We argue that this limitation arises from the inability to recover the latent explanations that underpin intelligent behavior, and that these explanations can take the form of structured programs consisting of high-level goals, sub-task decomposition, and execution constraints. In this work, we introduce Rational Inverse Reasoning (RIR), a framework for inferring these latent programs through a hierarchical generative model of behavior. RIR frames few-shot imitation as Bayesian program induction: a vision-language model iteratively proposes structured symbolic task hypotheses, while a planner-in-the-loop inference scheme scores each by the likelihood of the observed demonstration under that hypothesis. This loop yields a posterior over concise, executable programs. We evaluate RIR on a suite of continuous manipulation tasks designed to test one-shot and few-shot generalization across variations in object pose, count, geometry, and layout. With as little as one demonstration, RIR infers the intended task structure and generalizes to novel settings, outperforming state-of-the-art vision-language model baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Rational Inverse Reasoning (RIR) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³æœºå™¨äººéš¾ä»¥ä»æå°‘æ•°ç¤ºä¾‹ä¸­å®ç°è·¨åœºæ™¯æ³›åŒ–çš„é—®é¢˜ã€‚RIR å°†å°‘æ ·æœ¬æ¨¡ä»¿å­¦ä¹  (few-shot imitation) å»ºæ¨¡ä¸ºè´å¶æ–¯ç¨‹åºå½’çº³ (Bayesian program induction)ï¼Œé€šè¿‡ Vision-Language Model (VLM) è¿­ä»£ç”ŸæˆåŒ…å«é«˜å±‚ç›®æ ‡ã€å­ä»»åŠ¡åˆ†è§£å’Œæ‰§è¡Œçº¦æŸçš„ç»“æ„åŒ–ç¬¦å·ç¨‹åºã€‚è¯¥æ¡†æ¶å¼•å…¥äº† planner-in-the-loop æ¨ç†æ–¹æ¡ˆï¼Œæ ¹æ®è§‚æµ‹æ¼”ç¤ºçš„ä¼¼ç„¶æ¦‚ç‡å¯¹å‡è®¾è¿›è¡Œè¯„åˆ†ï¼Œä»è€Œæ¨å¯¼å‡ºæ½œåœ¨è¡Œä¸ºè§£é‡Šçš„åéªŒåˆ†å¸ƒã€‚åœ¨æ¶‰åŠç‰©ä½“ä½å§¿ã€æ•°é‡åŠå‡ ä½•å½¢çŠ¶å˜åŒ–çš„è¿ç»­æ“çºµä»»åŠ¡è¯„ä¼°ä¸­ï¼ŒRIR å±•ç°å‡ºå¼ºå¤§çš„å•æ ·æœ¬ (one-shot) æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒRIR èƒ½å¤Ÿæœ‰æ•ˆæ¨æ–­ä»»åŠ¡ç»“æ„å¹¶åº”ç”¨äºå…¨æ–°ç¯å¢ƒï¼Œåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç°æœ‰çš„ Vision-Language Model åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08983v1",
      "published_date": "2025-08-12 14:49:44 UTC",
      "updated_date": "2025-08-12 14:49:44 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:24.095929+00:00"
    },
    {
      "arxiv_id": "2508.08982v1",
      "title": "Unsupervised Skill Discovery as Exploration for Learning Agile Locomotion",
      "title_zh": "å°†æ— ç›‘ç£æŠ€èƒ½å‘ç°ä½œä¸ºæ¢ç´¢æœºåˆ¶çš„æ•æ·è¿åŠ¨å­¦ä¹ ",
      "authors": [
        "Seungeun Rho",
        "Kartik Garg",
        "Morgan Byrd",
        "Sehoon Ha"
      ],
      "abstract": "Exploration is crucial for enabling legged robots to learn agile locomotion behaviors that can overcome diverse obstacles. However, such exploration is inherently challenging, and we often rely on extensive reward engineering, expert demonstrations, or curriculum learning - all of which limit generalizability. In this work, we propose Skill Discovery as Exploration (SDAX), a novel learning framework that significantly reduces human engineering effort. SDAX leverages unsupervised skill discovery to autonomously acquire a diverse repertoire of skills for overcoming obstacles. To dynamically regulate the level of exploration during training, SDAX employs a bi-level optimization process that autonomously adjusts the degree of exploration. We demonstrate that SDAX enables quadrupedal robots to acquire highly agile behaviors including crawling, climbing, leaping, and executing complex maneuvers such as jumping off vertical walls. Finally, we deploy the learned policy on real hardware, validating its successful transfer to the real world.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è…¿å¼æœºå™¨äººåœ¨å¤æ‚ç¯å¢ƒä¸‹å­¦ä¹ æ•æ·è¿åŠ¨æ—¶é¢ä¸´çš„æ¢ç´¢éš¾é¢˜ï¼Œæå‡ºäº†åä¸ºSkill Discovery as Exploration (SDAX) çš„æ–°å‹å­¦ä¹ æ¡†æ¶ï¼Œæœ‰æ•ˆå‡å°‘äº†å¯¹å¥–åŠ±å·¥ç¨‹å’Œä¸“å®¶æ¼”ç¤ºçš„ä¾èµ–ã€‚SDAXåˆ©ç”¨æ— ç›‘ç£æŠ€èƒ½å‘ç° (Unsupervised skill discovery) æŠ€æœ¯è‡ªä¸»è·å–å¤šæ ·åŒ–çš„æŠ€èƒ½åº“ï¼Œå¹¶é‡‡ç”¨åŒå±‚ä¼˜åŒ–è¿‡ç¨‹ (Bi-level optimization process) åŠ¨æ€è°ƒèŠ‚è®­ç»ƒè¿‡ç¨‹ä¸­çš„æ¢ç´¢ç¨‹åº¦ã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ¡†æ¶ä½¿å››è¶³æœºå™¨äººèƒ½å¤ŸæŒæ¡çˆ¬è¡Œ (Crawling)ã€æ”€çˆ¬ (Climbing)ã€è·³è·ƒ (Leaping) ä»¥åŠä»å‚ç›´å¢™å£è·³ä¸‹ç­‰é«˜éš¾åº¦æ•æ·åŠ¨ä½œã€‚ç ”ç©¶å›¢é˜Ÿæœ€ç»ˆå°†å­¦ä¹ åˆ°çš„ç­–ç•¥æˆåŠŸéƒ¨ç½²äºçœŸå®ç¡¬ä»¶ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨ç°å®ä¸–ç•Œä¸­çš„æœ‰æ•ˆæ€§åŠå…¶å¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Conference on Robot Learning 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08982v1",
      "published_date": "2025-08-12 14:49:25 UTC",
      "updated_date": "2025-08-12 14:49:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:22.987802+00:00"
    },
    {
      "arxiv_id": "2508.08976v1",
      "title": "Urban-STA4CLC: Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change",
      "title_zh": "Urban-STA4CLCï¼šèåˆåŸå¸‚ç†è®ºçš„æ—¶ç©ºæ³¨æ„åŠ›ç¾åå•†ä¸šç”¨åœ°å˜åŒ–é¢„æµ‹æ¨¡å‹",
      "authors": [
        "Ziyi Guo",
        "Yan Wang"
      ],
      "abstract": "Natural disasters such as hurricanes and wildfires increasingly introduce unusual disturbance on economic activities, which are especially likely to reshape commercial land use pattern given their sensitive to customer visitation. However, current modeling approaches are limited in capturing such complex interplay between human activities and commercial land use change under and following disturbances. Such interactions have been more effectively captured in current resilient urban planning theories. This study designs and calibrates a Urban Theory-Informed Spatio-Temporal Attention Model for Predicting Post-Disaster Commercial Land Use Change (Urban-STA4CLC) to predict both the yearly decline and expansion of commercial land use at census block level under cumulative impact of disasters on human activities over two years. Guided by urban theories, Urban-STA4CLC integrates both spatial and temporal attention mechanisms with three theory-informed modules. Resilience theory guides a disaster-aware temporal attention module that captures visitation dynamics. Spatial economic theory informs a multi-relational spatial attention module for inter-block representation. Diffusion theory contributes a regularization term that constrains land use transitions. The model performs significantly better than non-theoretical baselines in predicting commercial land use change under the scenario of recurrent hurricanes, with around 19% improvement in F1 score (0.8763). The effectiveness of the theory-guided modules was further validated through ablation studies. The research demonstrates that embedding urban theory into commercial land use modeling models may substantially enhance the capacity to capture its gains and losses. These advances in commercial land use modeling contribute to land use research that accounts for cumulative impacts of recurrent disasters and shifts in economic activity patterns.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Urban-STA4CLCæ¨¡å‹ï¼Œæ—¨åœ¨é¢„æµ‹è‡ªç„¶ç¾å®³ç´¯ç§¯å½±å“ä¸‹çš„æ™®æŸ¥åŒº(census block)çº§åˆ«å•†ä¸šåœŸåœ°åˆ©ç”¨çš„å¹´åº¦ä¸‹é™ä¸æ‰©å¼ ã€‚è¯¥æ¨¡å‹é€šè¿‡æ•´åˆæ—¶ç©ºæ³¨æ„åŠ›æœºåˆ¶(Spatio-Temporal Attention)ä¸ä¸‰ä¸ªåŸå¸‚ç†è®ºå¯¼å‘æ¨¡å—ï¼Œæœ‰æ•ˆæ•æ‰äº†äººç±»æ´»åŠ¨ä¸åœŸåœ°åˆ©ç”¨ä¹‹é—´çš„å¤æ‚äº¤äº’ã€‚å…·ä½“è€Œè¨€ï¼ŒéŸ§æ€§ç†è®º(Resilience theory)æŒ‡å¯¼çš„ç¾å®³æ„ŸçŸ¥æ—¶é—´æ³¨æ„åŠ›æ¨¡å—è´Ÿè´£æ•æ‰å®¢æµåŠ¨æ€ï¼Œç©ºé—´ç»æµç†è®º(Spatial economic theory)é©±åŠ¨çš„å¤šå…³ç³»ç©ºé—´æ³¨æ„åŠ›æ¨¡å—ç”¨äºè¡¨å¾è¡—åŒºé—´çš„ç©ºé—´å…³è”ï¼Œè€Œæ‰©æ•£ç†è®º(Diffusion theory)åˆ™æä¾›æ­£åˆ™åŒ–é¡¹ä»¥çº¦æŸåœŸåœ°åˆ©ç”¨è½¬æ¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨é£“é£é‡å¤å‘ç”Ÿçš„æƒ…æ™¯ä¸‹ï¼Œè¯¥æ¨¡å‹è¾ƒéç†è®ºåŸºçº¿æ¨¡å‹çš„F1 scoreæå‡äº†çº¦19%ï¼ˆè¾¾åˆ°0.8763ï¼‰ï¼Œæ˜¾è‘—å¢å¼ºäº†é¢„æµ‹å•†ä¸šåœŸåœ°å¢å‡çš„èƒ½åŠ›ã€‚è¿™é¡¹ç ”ç©¶è¯æ˜äº†å°†åŸå¸‚ç†è®ºåµŒå…¥æ·±åº¦å­¦ä¹ æ¨¡å‹çš„é‡è¦æ€§ï¼Œä¸ºåˆ†æç¾å®³ç´¯ç§¯å½±å“ä¸‹çš„ç»æµæ´»åŠ¨æ¨¡å¼è½¬å˜æä¾›äº†æœ‰åŠ›çš„å»ºæ¨¡æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08976v1",
      "published_date": "2025-08-12 14:39:42 UTC",
      "updated_date": "2025-08-12 14:39:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:27.789343+00:00"
    },
    {
      "arxiv_id": "2508.11693v1",
      "title": "Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data",
      "title_zh": "åŸºäºç°æœ‰ STDS è½¨é“ç”µè·¯æ•°æ®åˆ†æçš„è½¨é“éƒ¨ä»¶æ•…éšœæ£€æµ‹",
      "authors": [
        "Francisco LÃ³pez",
        "Eduardo Di Santi",
        "ClÃ©ment Lefebvre",
        "Nenad Mijatovic",
        "Michele Pugnaloni",
        "Victor MartÃ­n",
        "Kenza Saiah"
      ],
      "abstract": "Track Circuits (TC) are the main signalling devices used to detect the presence of a train on a rail track. It has been used since the 19th century and nowadays there are many types depending on the technology. As a general classification, Track Circuits can be divided into 2 main groups, DC (Direct Current) and AC (Alternating Current) circuits. This work is focused on a particular AC track circuit, called \"Smart Train Detection System\" (STDS), designed with both high and low-frequency bands. This approach uses STDS current data applied to an SVM (support vector machine) classifier as a type of failure identifier. The main purpose of this work consists on determine automatically which is the component of the track that is failing to improve the maintenance action. Model was trained to classify 15 different failures that belong to 3 more general categories. The method was tested with field data from 10 different track circuits and validated by the STDS track circuit expert and maintainers. All use cases were correctly classified by the method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åä¸ºSmart Train Detection System (STDS)çš„äº¤æµè½¨é“ç”µè·¯(AC Track Circuit)ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨ç°æœ‰æ•°æ®è¿›è¡Œè½¨é“éƒ¨ä»¶æ•…éšœæ£€æµ‹çš„åˆ†ææ–¹æ³•ã€‚è¯¥æ–¹æ³•é‡‡ç”¨STDSçš„ç”µæµæ•°æ®å¹¶ç»“åˆæ”¯æŒå‘é‡æœº(SVM)åˆ†ç±»å™¨ï¼Œä½œä¸ºä¸€ç§é«˜æ•ˆçš„æ•…éšœè¯†åˆ«æ‰‹æ®µã€‚ç ”ç©¶çš„ä¸»è¦ç›®çš„æ˜¯è‡ªåŠ¨è¯†åˆ«å…·ä½“çš„æ•…éšœè½¨é“éƒ¨ä»¶ï¼Œä»è€Œä¼˜åŒ–é“è·¯ç»´æŠ¤æµç¨‹ã€‚æ¨¡å‹é’ˆå¯¹3ä¸ªå¤§ç±»ä¸‹çš„15ç§ä¸åŒæ•…éšœè¿›è¡Œäº†è®­ç»ƒï¼Œèƒ½å¤Ÿå®ç°ç²¾ç»†åŒ–çš„æ•…éšœè¯Šæ–­ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨æ¥è‡ª10ä¸ªä¸åŒè½¨é“ç”µè·¯çš„ç°åœºæ•°æ®(Field Data)å¯¹è¯¥æ–¹æ³•è¿›è¡Œäº†æµ‹è¯•ï¼Œå¹¶è·å¾—äº†STDSä¸“å®¶åŠç»´æŠ¤äººå‘˜çš„éªŒè¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ‰€æœ‰æµ‹è¯•ç”¨ä¾‹å‡è¢«è¯¥æ–¹æ³•æ­£ç¡®åˆ†ç±»ï¼Œè¯æ˜äº†è¯¥ç³»ç»Ÿåœ¨å®é™…è½¨é“ç»´æŠ¤åº”ç”¨ä¸­çš„å‡†ç¡®æ€§ä¸å¯é æ€§ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "eess.SP",
      "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025 (International Conference on Railway Operations Modelling and Analysis), Dresden, Germany",
      "pdf_url": "https://arxiv.org/pdf/2508.11693v1",
      "published_date": "2025-08-12 14:35:18 UTC",
      "updated_date": "2025-08-12 14:35:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:28.086806+00:00"
    },
    {
      "arxiv_id": "2508.08967v2",
      "title": "Revealing the Role of Audio Channels in ASR Performance Degradation",
      "title_zh": "æ­ç¤ºéŸ³é¢‘ä¿¡é“åœ¨ ASR æ€§èƒ½é€€åŒ–ä¸­çš„ä½œç”¨",
      "authors": [
        "Kuan-Tang Huang",
        "Li-Wei Chen",
        "Hung-Shin Lee",
        "Berlin Chen",
        "Hsin-Min Wang"
      ],
      "abstract": "Pre-trained automatic speech recognition (ASR) models have demonstrated strong performance on a variety of tasks. However, their performance can degrade substantially when the input audio comes from different recording channels. While previous studies have demonstrated this phenomenon, it is often attributed to the mismatch between training and testing corpora. This study argues that variations in speech characteristics caused by different recording channels can fundamentally harm ASR performance. To address this limitation, we propose a normalization technique designed to mitigate the impact of channel variation by aligning internal feature representations in the ASR model with those derived from a clean reference channel. This approach significantly improves ASR performance on previously unseen channels and languages, highlighting its ability to generalize across channel and language differences.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é¢„è®­ç»ƒè‡ªåŠ¨è¯­éŸ³è¯†åˆ« (ASR) æ¨¡å‹åœ¨é¢å¯¹ä¸åŒéŸ³é¢‘é€šé“ (audio channels) è¾“å…¥æ—¶æ€§èƒ½æ˜¾è‘—ä¸‹é™çš„é—®é¢˜ã€‚ä¸åŒäºä»¥å¾€å°†å…¶å½’å› äºè®­ç»ƒä¸æµ‹è¯•è¯­æ–™åº“ä¸åŒ¹é…çš„è§‚ç‚¹ï¼Œè¯¥ç ”ç©¶æŒ‡å‡ºç”±ä¸åŒå½•éŸ³é€šé“å¼•èµ·çš„è¯­éŸ³ç‰¹å¾å˜åŒ–æ‰æ˜¯å¯¼è‡´ ASR æ€§èƒ½å—æŸçš„æ ¹æœ¬åŸå› ã€‚ä¸ºäº†è§£å†³è¿™ä¸€å±€é™æ€§ï¼Œä½œè€…æå‡ºäº†ä¸€ç§å½’ä¸€åŒ–æŠ€æœ¯ (normalization technique)ï¼Œé€šè¿‡å°† ASR æ¨¡å‹çš„å†…éƒ¨ç‰¹å¾è¡¨ç¤ºä¸å¹²å‡€å‚è€ƒé€šé“çš„ç‰¹å¾è¿›è¡Œå¯¹é½ï¼Œä»¥å‡è½»é€šé“å˜å¼‚å¸¦æ¥çš„å½±å“ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æœªè§è¿‡çš„é€šé“å’Œè¯­è¨€ä¸Šå‡æ˜¾è‘—æå‡äº† ASR çš„è¡¨ç°ï¼Œå±•ç¤ºäº†å…¶åœ¨è·¨é€šé“å’Œè·¨è¯­è¨€ä»»åŠ¡ä¸­ä¼˜å¼‚çš„æ³›åŒ–èƒ½åŠ›ã€‚è¯¥é¡¹å·¥ä½œæ­ç¤ºäº†éŸ³é¢‘é€šé“åœ¨æ€§èƒ½è¡°å‡ä¸­çš„æ ¸å¿ƒä½œç”¨ï¼Œå¹¶ä¸ºå¼€å‘æ›´å…·é²æ£’æ€§çš„è¯­éŸ³è¯†åˆ«ç³»ç»Ÿæä¾›äº†æœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to IEEE ASRU 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08967v2",
      "published_date": "2025-08-12 14:32:48 UTC",
      "updated_date": "2025-08-22 04:10:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:49.550808+00:00"
    },
    {
      "arxiv_id": "2508.14076v1",
      "title": "PersRM-R1: Enhance Personalized Reward Modeling with Reinforcement Learning",
      "title_zh": "PersRM-R1ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ å¢å¼ºä¸ªæ€§åŒ–å¥–åŠ±å»ºæ¨¡",
      "authors": [
        "Mengdi Li",
        "Guanqiao Chen",
        "Xufeng Zhao",
        "Haochen Wen",
        "Shu Yang",
        "Di Wang"
      ],
      "abstract": "Reward models (RMs), which are central to existing post-training methods, aim to align LLM outputs with human values by providing feedback signals during fine-tuning. However, existing RMs struggle to capture nuanced, user-specific preferences, especially under limited data and across diverse domains. Thus, we introduce PersRM-R1, the first reasoning-based reward modeling framework specifically designed to identify and represent personal factors from only one or a few personal exemplars. To address challenges including limited data availability and the requirement for robust generalization, our approach combines synthetic data generation with a two-stage training pipeline consisting of supervised fine-tuning followed by reinforcement fine-tuning. Experimental results demonstrate that PersRM-R1 outperforms existing models of similar size and matches the performance of much larger models in both accuracy and generalizability, paving the way for more effective personalized LLMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PersRM-R1ï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨è®¾è®¡çš„åŸºäºæ¨ç†çš„ä¸ªæ€§åŒ–å¥–åŠ±æ¨¡å‹(Reward Modeling)æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æå°‘é‡çš„ä¸ªæ€§åŒ–ç¤ºä¾‹è¯†åˆ«å¹¶æœ‰æ•ˆè¡¨ç¤ºç”¨æˆ·ç‰¹å®šçš„åå¥½ã€‚ç°æœ‰çš„å¥–åŠ±æ¨¡å‹(RMs)åœ¨å¤„ç†ç»†å¾®ä¸”ä¸ªæ€§åŒ–çš„ç”¨æˆ·éœ€æ±‚æ—¶å¸¸é¢ä¸´æŒ‘æˆ˜ï¼Œå°¤å…¶æ˜¯åœ¨æ•°æ®æœ‰é™å’Œè·¨é¢†åŸŸåœºæ™¯ä¸‹è¡¨ç°æ¬ ä½³ã€‚ä¸ºäº†å…‹æœæ•°æ®ç¨€ç¼ºå¹¶æ»¡è¶³é²æ£’æ³›åŒ–è¦æ±‚ï¼ŒPersRM-R1å°†åˆæˆæ•°æ®ç”Ÿæˆ(Synthetic Data Generation)æŠ€æœ¯ä¸åŒ…å«ç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)åŠå¼ºåŒ–å¾®è°ƒ(Reinforcement Fine-Tuning)çš„ä¸¤é˜¶æ®µè®­ç»ƒæµç¨‹ç›¸ç»“åˆã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒPersRM-R1åœ¨å‡†ç¡®æ€§å’Œæ³›åŒ–èƒ½åŠ›ä¸Šå‡ä¼˜äºåŒç­‰è§„æ¨¡çš„ç°æœ‰æ¨¡å‹ï¼Œå¹¶è¾¾åˆ°äº†ä¸æ›´å¤§å‚æ•°é‡æ¨¡å‹ç›¸å½“çš„æ€§èƒ½æ°´å¹³ã€‚è¯¥æ¡†æ¶çš„æå‡ºä¸ºå¼€å‘æ›´é«˜æ•ˆã€æ›´ç²¾å‡†çš„ä¸ªæ€§åŒ–å¤§è¯­è¨€æ¨¡å‹(Personalized LLMs)å¥ å®šäº†é‡è¦åŸºç¡€ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14076v1",
      "published_date": "2025-08-12 14:25:58 UTC",
      "updated_date": "2025-08-12 14:25:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:57.188671+00:00"
    },
    {
      "arxiv_id": "2508.09765v1",
      "title": "Enhance the machine learning algorithm performance in phishing detection with keyword features",
      "title_zh": "åˆ©ç”¨å…³é”®è¯ç‰¹å¾æå‡ç½‘ç»œé’“é±¼æ£€æµ‹ä¸­çš„æœºå™¨å­¦ä¹ ç®—æ³•æ€§èƒ½",
      "authors": [
        "Zijiang Yang"
      ],
      "abstract": "Recently, we can observe a significant increase of the phishing attacks in the Internet. In a typical phishing attack, the attacker sets up a malicious website that looks similar to the legitimate website in order to obtain the end-users' information. This may cause the leakage of the sensitive information and the financial loss for the end-users. To avoid such attacks, the early detection of these websites' URLs is vital and necessary. Previous researchers have proposed many machine learning algorithms to distinguish the phishing URLs from the legitimate ones. In this paper, we would like to enhance these machine learning algorithms from the perspective of feature selection. We propose a novel method to incorporate the keyword features with the traditional features. This method is applied on multiple traditional machine learning algorithms and the experimental results have shown this method is useful and effective. On average, this method can reduce the classification error by 30% for the large dataset. Moreover, its enhancement is more significant for the small dataset. In addition, this method extracts the information from the URL and does not rely on the additional information provided by the third-part service. The best result for the machine learning algorithm using our proposed method has achieved the accuracy of 99.68%.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—¥ç›Šä¸¥é‡çš„ç½‘ç»œé’“é±¼æ”»å‡»é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§å°†å…³é”®å­—ç‰¹å¾ (keyword features) ä¸ä¼ ç»Ÿç‰¹å¾ç›¸ç»“åˆçš„æ–°å‹ç‰¹å¾é€‰æ‹©æ–¹æ³•ï¼Œæ—¨åœ¨å¢å¼ºæœºå™¨å­¦ä¹ ç®—æ³•å¯¹é’“é±¼ URL çš„æ£€æµ‹æ€§èƒ½ã€‚è¯¥æ–¹æ³•é€šè¿‡ç›´æ¥ä» URL ä¸­æå–å…³é”®ä¿¡æ¯ï¼Œé¿å…äº†å¯¹ç¬¬ä¸‰æ–¹æœåŠ¡çš„ä¾èµ–ï¼Œç¡®ä¿äº†æ£€æµ‹è¿‡ç¨‹çš„ç‹¬ç«‹æ€§ä¸é«˜æ•ˆæ€§ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤šç§ä¼ ç»Ÿæœºå™¨å­¦ä¹ ç®—æ³•ä¸Šå‡å–å¾—äº†æ˜¾è‘—æˆæ•ˆï¼Œåœ¨å¤§å‹æ•°æ®é›†ä¸Šå¹³å‡å¯é™ä½ 30% çš„åˆ†ç±»é”™è¯¯ç‡ï¼Œä¸”åœ¨å°å‹æ•°æ®é›†ä¸Šçš„æ€§èƒ½æå‡æ›´ä¸ºæ˜¾è‘—ã€‚æœ€ç»ˆï¼Œé‡‡ç”¨è¯¥æ–¹æ³•çš„ç®—æ³•å®ç°äº†é«˜è¾¾ 99.68% çš„æ£€æµ‹å‡†ç¡®ç‡ï¼Œè¯æ˜äº†ç»“åˆå…³é”®å­—ç‰¹å¾åœ¨æå‡ç½‘ç»œé’“é±¼è¯†åˆ«ç²¾åº¦æ–¹é¢çš„å®ç”¨ä»·å€¼ä¸æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09765v1",
      "published_date": "2025-08-12 14:16:11 UTC",
      "updated_date": "2025-08-12 14:16:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:47.249490+00:00"
    },
    {
      "arxiv_id": "2508.08957v1",
      "title": "QAMRO: Quality-aware Adaptive Margin Ranking Optimization for Human-aligned Assessment of Audio Generation Systems",
      "title_zh": "QAMROï¼šé¢å‘éŸ³é¢‘ç”Ÿæˆç³»ç»Ÿäººç±»å¯¹é½è¯„ä¼°çš„è´¨é‡æ„ŸçŸ¥è‡ªé€‚åº”è¾¹é™…æ’åºä¼˜åŒ–",
      "authors": [
        "Chien-Chun Wang",
        "Kuan-Tang Huang",
        "Cheng-Yeh Yang",
        "Hung-Shin Lee",
        "Hsin-Min Wang",
        "Berlin Chen"
      ],
      "abstract": "Evaluating audio generation systems, including text-to-music (TTM), text-to-speech (TTS), and text-to-audio (TTA), remains challenging due to the subjective and multi-dimensional nature of human perception. Existing methods treat mean opinion score (MOS) prediction as a regression problem, but standard regression losses overlook the relativity of perceptual judgments. To address this limitation, we introduce QAMRO, a novel Quality-aware Adaptive Margin Ranking Optimization framework that seamlessly integrates regression objectives from different perspectives, aiming to highlight perceptual differences and prioritize accurate ratings. Our framework leverages pre-trained audio-text models such as CLAP and Audiobox-Aesthetics, and is trained exclusively on the official AudioMOS Challenge 2025 dataset. It demonstrates superior alignment with human evaluations across all dimensions, significantly outperforming robust baseline models.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† QAMROï¼Œä¸€ç§è´¨é‡æ„ŸçŸ¥çš„è‡ªé€‚åº”è¾¹é™…æ’åä¼˜åŒ– (Quality-aware Adaptive Margin Ranking Optimization) æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³éŸ³é¢‘ç”Ÿæˆç³»ç»Ÿï¼ˆåŒ…æ‹¬ TTM, TTS å’Œ TTAï¼‰åœ¨äººç±»æ„ŸçŸ¥è¯„ä¼°ä¸­é¢ä¸´çš„ä¸»è§‚æ€§ä¸å¤šç»´æ€§æŒ‘æˆ˜ã€‚é’ˆå¯¹ç°æœ‰æ–¹æ³•å°† Mean Opinion Score (MOS) é¢„æµ‹è§†ä¸ºå›å½’é—®é¢˜è€Œå¿½ç•¥æ„ŸçŸ¥åˆ¤æ–­ç›¸å¯¹æ€§çš„å±€é™ï¼ŒQAMRO æ•´åˆäº†å¤šç»´åº¦çš„å›å½’ç›®æ ‡ä¸æ’åä¼˜åŒ–ï¼Œä»è€Œæ›´å¥½åœ°æ•æ‰æ„ŸçŸ¥å·®å¼‚å¹¶æå‡è¯„åˆ†å‡†ç¡®åº¦ã€‚è¯¥æ¡†æ¶å……åˆ†åˆ©ç”¨äº† CLAP å’Œ Audiobox-Aesthetics ç­‰é¢„è®­ç»ƒéŸ³é¢‘æ–‡æœ¬æ¨¡å‹ï¼Œå¹¶åœ¨ AudioMOS Challenge 2025 å®˜æ–¹æ•°æ®é›†ä¸Šè¿›è¡Œäº†é’ˆå¯¹æ€§è®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒQAMRO åœ¨æ‰€æœ‰è¯„ä¼°ç»´åº¦ä¸Šå‡å®ç°äº†ä¸äººç±»è¯„ä»·çš„é«˜åº¦å¯¹é½ï¼Œå…¶æ€§èƒ½è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼ºåŠ›åŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to IEEE ASRU 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08957v1",
      "published_date": "2025-08-12 14:14:04 UTC",
      "updated_date": "2025-08-12 14:14:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:56.952062+00:00"
    },
    {
      "arxiv_id": "2509.05298v1",
      "title": "Livia: An Emotion-Aware AR Companion Powered by Modular AI Agents and Progressive Memory Compression",
      "title_zh": "Liviaï¼šç”±æ¨¡å—åŒ– AI æ™ºèƒ½ä½“ä¸æ¸è¿›å¼è®°å¿†å‹ç¼©é©±åŠ¨çš„æƒ…æ„Ÿæ„ŸçŸ¥ AR ä¼´ä¾£",
      "authors": [
        "Rui Xi",
        "Xianghan Wang"
      ],
      "abstract": "Loneliness and social isolation pose significant emotional and health challenges, prompting the development of technology-based solutions for companionship and emotional support. This paper introduces Livia, an emotion-aware augmented reality (AR) companion app designed to provide personalized emotional support by combining modular artificial intelligence (AI) agents, multimodal affective computing, progressive memory compression, and AR driven embodied interaction. Livia employs a modular AI architecture with specialized agents responsible for emotion analysis, dialogue generation, memory management, and behavioral orchestration, ensuring robust and adaptive interactions. Two novel algorithms-Temporal Binary Compression (TBC) and Dynamic Importance Memory Filter (DIMF)-effectively manage and prioritize long-term memory, significantly reducing storage requirements while retaining critical context. Our multimodal emotion detection approach achieves high accuracy, enhancing proactive and empathetic engagement. User evaluations demonstrated increased emotional bonds, improved satisfaction, and statistically significant reductions in loneliness. Users particularly valued Livia's adaptive personality evolution and realistic AR embodiment. Future research directions include expanding gesture and tactile interactions, supporting multi-user experiences, and exploring customized hardware implementations.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»‹ç»äº† Liviaï¼Œä¸€æ¬¾æ—¨åœ¨æä¾›ä¸ªæ€§åŒ–æƒ…æ„Ÿæ”¯æŒçš„æƒ…ç»ªæ„ŸçŸ¥å¢å¼ºç°å® (AR) ä¼´ä¾£åº”ç”¨ã€‚Livia é‡‡ç”¨äº†æ¨¡å—åŒ–äººå·¥æ™ºèƒ½ (AI) æ¶æ„ï¼Œç”±è´Ÿè´£æƒ…ç»ªåˆ†æã€å¯¹è¯ç”Ÿæˆã€è®°å¿†ç®¡ç†å’Œè¡Œä¸ºç¼–æ’çš„ä¸“é—¨æ™ºèƒ½ä½“ç»„æˆï¼Œç¡®ä¿äº†äº¤äº’çš„ç¨³å¥æ€§ä¸é€‚åº”æ€§ã€‚ä¸ºäº†ä¼˜åŒ–é•¿æœŸè®°å¿†ç®¡ç†ï¼Œç ”ç©¶æå‡ºäº†æ—¶é—´äºŒè¿›åˆ¶å‹ç¼© (Temporal Binary Compression, TBC) å’ŒåŠ¨æ€é‡è¦æ€§è®°å¿†è¿‡æ»¤å™¨ (Dynamic Importance Memory Filter, DIMF) ä¸¤ç§æ–°ç®—æ³•ï¼Œåœ¨å¤§å¹…é™ä½å­˜å‚¨éœ€æ±‚çš„åŒæ—¶ä¿ç•™äº†æ ¸å¿ƒä¸Šä¸‹æ–‡ã€‚æ­¤å¤–ï¼Œå¤šæ¨¡æ€æƒ…æ„Ÿè®¡ç®— (Multimodal Affective Computing) çš„åº”ç”¨æ˜¾è‘—æå‡äº†æƒ…ç»ªæ£€æµ‹çš„å‡†ç¡®ç‡ï¼Œå¢å¼ºäº†ç³»ç»Ÿçš„å…±æƒ…äº’åŠ¨èƒ½åŠ›ã€‚ç”¨æˆ·è¯„ä¼°ç»“æœè¡¨æ˜ï¼ŒLivia èƒ½å¤Ÿå»ºç«‹æ›´æ·±çš„æƒ…æ„Ÿçº½å¸¦å¹¶æ˜¾è‘—é™ä½å­¤ç‹¬æ„Ÿã€‚å‚ä¸è€…å¯¹è¯¥ç³»ç»Ÿå±•ç¤ºå‡ºçš„è‡ªé€‚åº”äººæ ¼è¿›åŒ–å’Œé€¼çœŸçš„ AR å…·èº«åŒ– (AR Embodiment) äº¤äº’ç»™äºˆäº†é«˜åº¦è¯„ä»·ï¼Œä¸ºæœªæ¥å¼€å‘æ™ºèƒ½æƒ…æ„Ÿæ”¯æŒæŠ€æœ¯æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to the Proceedings of the 2025 International Conference on Artificial Intelligence and Virtual Reality (AIVR 2025). \\c{opyright} 2025 Springer. This is the author-accepted manuscript. Rui Xi and Xianghan Wang contributed equally to this work. The final version will be available via SpringerLink",
      "pdf_url": "https://arxiv.org/pdf/2509.05298v1",
      "published_date": "2025-08-12 14:07:22 UTC",
      "updated_date": "2025-08-12 14:07:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:15:51.256563+00:00"
    },
    {
      "arxiv_id": "2508.08947v2",
      "title": "Generalising Traffic Forecasting to Regions without Traffic Observations",
      "title_zh": "å°†äº¤é€šé¢„æµ‹æ³›åŒ–è‡³æ— äº¤é€šè§‚æµ‹åŒºåŸŸ",
      "authors": [
        "Xinyu Su",
        "Majid Sarvi",
        "Feng Liu",
        "Egemen Tanin",
        "Jianzhong Qi"
      ],
      "abstract": "Traffic forecasting is essential for intelligent transportation systems. Accurate forecasting relies on continuous observations collected by traffic sensors. However, due to high deployment and maintenance costs, not all regions are equipped with such sensors. This paper aims to forecast for regions without traffic sensors, where the lack of historical traffic observations challenges the generalisability of existing models. We propose a model named GenCast, the core idea of which is to exploit external knowledge to compensate for the missing observations and to enhance generalisation. We integrate physics-informed neural networks into GenCast, enabling physical principles to regularise the learning process. We introduce an external signal learning module to explore correlations between traffic states and external signals such as weather conditions, further improving model generalisability. Additionally, we design a spatial grouping module to filter localised features that hinder model generalisability. Extensive experiments show that GenCast consistently reduces forecasting errors on multiple real-world datasets.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ™ºèƒ½äº¤é€šç³»ç»Ÿä¸­è®¸å¤šåŒºåŸŸå› ä¼ æ„Ÿå™¨éƒ¨ç½²æˆæœ¬é«˜è€Œç¼ºä¹å†å²äº¤é€šè§‚æµ‹æ•°æ®ï¼Œå¯¼è‡´ç°æœ‰æ¨¡å‹æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†åä¸º GenCast çš„é¢„æµ‹æ¨¡å‹ã€‚GenCast çš„æ ¸å¿ƒæ€æƒ³æ˜¯åˆ©ç”¨å¤–éƒ¨çŸ¥è¯†æ¥å¼¥è¡¥è§‚æµ‹ç¼ºå¤±å¹¶å¢å¼º Generalisation æ€§èƒ½ã€‚è¯¥æ¨¡å‹é€šè¿‡é›†æˆ Physics-Informed Neural Networks (PINNs) å°†ç‰©ç†è§„å¾‹å¼•å…¥å­¦ä¹ è¿‡ç¨‹è¿›è¡Œæ­£åˆ™åŒ–ï¼Œå¹¶åˆ©ç”¨å¤–éƒ¨ä¿¡å·å­¦ä¹ æ¨¡å— (External signal learning module) æ¢ç´¢äº¤é€šçŠ¶æ€ä¸å¤©æ°”ç­‰å¤–éƒ¨ä¿¡å·çš„å…³è”ã€‚æ­¤å¤–ï¼Œæ¨¡å‹è®¾è®¡çš„ç©ºé—´åˆ†ç»„æ¨¡å— (Spatial grouping module) èƒ½å¤Ÿæœ‰æ•ˆè¿‡æ»¤é˜»ç¢æ³›åŒ–çš„å±€éƒ¨ç‰¹å¾ã€‚åœ¨å¤šä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGenCast æ˜¾è‘—é™ä½äº†é¢„æµ‹è¯¯å·®ï¼Œè¯æ˜äº†å…¶åœ¨æ— ä¼ æ„Ÿå™¨è§‚æµ‹åŒºåŸŸè¿›è¡Œäº¤é€šé¢„æµ‹çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.08947v2",
      "published_date": "2025-08-12 14:00:12 UTC",
      "updated_date": "2025-12-30 09:59:42 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:00.262838+00:00"
    },
    {
      "arxiv_id": "2508.08940v1",
      "title": "Train Long, Think Short: Curriculum Learning for Efficient Reasoning",
      "title_zh": "è®­ç»ƒé•¿ï¼Œæ€è€ƒçŸ­ï¼šé¢å‘é«˜æ•ˆæ¨ç†çš„è¯¾ç¨‹å­¦ä¹ ",
      "authors": [
        "Hasan Abed Al Kader Hammoud",
        "Kumail Alhamoud",
        "Abed Hammoud",
        "Elie Bou-Zeid",
        "Marzyeh Ghassemi",
        "Bernard Ghanem"
      ],
      "abstract": "Recent work on enhancing the reasoning abilities of large language models (LLMs) has introduced explicit length control as a means of constraining computational cost while preserving accuracy. However, existing approaches rely on fixed-length training budgets, which do not take advantage of the natural progression from exploration to compression during learning. In this work, we propose a curriculum learning strategy for length-controlled reasoning using Group Relative Policy Optimization (GRPO). Our method starts with generous token budgets and gradually tightens them over training, encouraging models to first discover effective solution strategies and then distill them into more concise reasoning traces. We augment GRPO with a reward function that balances three signals: task correctness (via verifier feedback), length efficiency, and formatting adherence (via structural tags). Experiments on GSM8K, MATH500, SVAMP, College Math, and GSM+ demonstrate that curriculum-based training consistently outperforms fixed-budget baselines at the same final budget, achieving higher accuracy and significantly improved token efficiency. We further ablate the impact of reward weighting and decay schedule design, showing that progressive constraint serves as a powerful inductive bias for training efficient reasoning models. Our code and checkpoints are released at: https://github.com/hammoudhasan/curriculum_grpo.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)æ¨ç†èƒ½åŠ›æå‡ä¸­æ˜¾å¼é•¿åº¦æ§åˆ¶å­˜åœ¨çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºè¯¾ç¨‹å­¦ä¹ (Curriculum Learning)çš„é«˜æ•ˆæ¨ç†è®­ç»ƒç­–ç•¥ã€‚ç°æœ‰çš„å›ºå®šé•¿åº¦é¢„ç®—æ–¹æ³•æœªèƒ½å……åˆ†åˆ©ç”¨æ¨¡å‹ä»æ¢ç´¢åˆ°å‹ç¼©çš„å­¦ä¹ ç‰¹æ€§ï¼Œè€Œæœ¬ç ”ç©¶é‡‡ç”¨ç¾¤ä½“ç›¸å¯¹ç­–ç•¥ä¼˜åŒ–(GRPO)æ¡†æ¶ï¼Œä»å®½æ¾çš„Tokené¢„ç®—å¼€å§‹è®­ç»ƒå¹¶éšè¿›ç¨‹é€æ­¥æ”¶ç´§ï¼Œä¿ƒä½¿æ¨¡å‹å…ˆå‘ç°æœ‰æ•ˆçš„è§£é¢˜ç­–ç•¥ï¼Œéšåå°†å…¶æç‚¼ä¸ºæ›´åŠ ç®€æ´çš„æ¨ç†è½¨è¿¹ã€‚ç ”ç©¶è®¾è®¡äº†å¹³è¡¡ä»»åŠ¡æ­£ç¡®æ€§ã€é•¿åº¦æ•ˆç‡å’Œæ ¼å¼è§„èŒƒçš„å¤åˆå¥–åŠ±å‡½æ•°ã€‚åœ¨GSM8Kã€MATH500ã€SVAMPç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œç›¸æ¯”å›ºå®šé¢„ç®—çš„åŸºçº¿æ¨¡å‹ï¼Œè¯¥è¯¾ç¨‹å­¦ä¹ ç­–ç•¥åœ¨ç›¸åŒæœ€ç»ˆé¢„ç®—ä¸‹å®ç°äº†æ›´é«˜çš„å‡†ç¡®ç‡å’Œæ˜¾è‘—æå‡çš„Tokenæ•ˆç‡ã€‚è¿™é¡¹å·¥ä½œè¯æ˜äº†æ¸è¿›å¼çº¦æŸå¯ä»¥ä½œä¸ºè®­ç»ƒé«˜æ•ˆæ¨ç†æ¨¡å‹çš„å¼ºå¤§å½’çº³åç½®(Inductive Bias)ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under Review",
      "pdf_url": "https://arxiv.org/pdf/2508.08940v1",
      "published_date": "2025-08-12 13:48:03 UTC",
      "updated_date": "2025-08-12 13:48:03 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:15.244809+00:00"
    },
    {
      "arxiv_id": "2508.08926v1",
      "title": "Safe Semantics, Unsafe Interpretations: Tackling Implicit Reasoning Safety in Large Vision-Language Models",
      "title_zh": "å®‰å…¨è¯­ä¹‰ï¼Œä¸å®‰å…¨è§£é‡Šï¼šåº”å¯¹å¤§è§†è§‰è¯­è¨€æ¨¡å‹ä¸­çš„éšå¼æ¨ç†å®‰å…¨é—®é¢˜",
      "authors": [
        "Wei Cai",
        "Jian Zhao",
        "Yuchu Jiang",
        "Tianle Zhang",
        "Xuelong Li"
      ],
      "abstract": "Large Vision-Language Models face growing safety challenges with multimodal inputs. This paper introduces the concept of Implicit Reasoning Safety, a vulnerability in LVLMs. Benign combined inputs trigger unsafe LVLM outputs due to flawed or hidden reasoning. To showcase this, we developed Safe Semantics, Unsafe Interpretations, the first dataset for this critical issue. Our demonstrations show that even simple In-Context Learning with SSUI significantly mitigates these implicit multimodal threats, underscoring the urgent need to improve cross-modal implicit reasoning.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è§†è§‰è¯­è¨€æ¨¡å‹(LVLMs)åœ¨å¤šæ¨¡æ€è¾“å…¥ä¸‹æ—¥ç›Šä¸¥å³»çš„å®‰å…¨æŒ‘æˆ˜ï¼Œå¹¶æå‡ºäº†éšå¼æ¨ç†å®‰å…¨(Implicit Reasoning Safety)è¿™ä¸€å…¨æ–°æ¼æ´æ¦‚å¿µã€‚ç ”ç©¶æŒ‡å‡ºï¼Œå³ä¾¿è¾“å…¥ç»„åˆåœ¨è¯­ä¹‰å±‚é¢æ˜¯è‰¯æ€§çš„ï¼ŒLVLMsä¹Ÿå¯èƒ½ç”±äºç¼ºé™·æˆ–éšè—çš„æ¨ç†é€»è¾‘è§¦å‘ä¸å®‰å…¨çš„è¾“å‡ºã€‚ä¸ºäº†æ·±å…¥å‰–æè¯¥é—®é¢˜ï¼Œä½œè€…å¼€å‘äº†é¦–ä¸ªä¸“é—¨é’ˆå¯¹æ­¤ç±»æ¼æ´çš„æ•°æ®é›†Safe Semantics, Unsafe Interpretations (SSUI)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œé€šè¿‡åŸºäºSSUIçš„ç®€å•ä¸Šä¸‹æ–‡å­¦ä¹ (In-Context Learning)å³å¯æ˜¾è‘—ç¼“è§£è¿™äº›éšå¼çš„å¤šæ¨¡æ€å®‰å…¨å¨èƒã€‚è¯¥ç ”ç©¶ä¸ä»…æ­ç¤ºäº†å¤šæ¨¡æ€æ¨¡å‹åœ¨æ¨ç†å±‚é¢çš„å®‰å…¨éšæ‚£ï¼Œä¹Ÿå‡¸æ˜¾äº†æå‡è·¨æ¨¡æ€éšå¼æ¨ç†èƒ½åŠ›çš„ç´§è¿«æ€§ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08926v1",
      "published_date": "2025-08-12 13:26:06 UTC",
      "updated_date": "2025-08-12 13:26:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:06.055122+00:00"
    },
    {
      "arxiv_id": "2508.08924v1",
      "title": "EGGCodec: A Robust Neural Encodec Framework for EGG Reconstruction and F0 Extraction",
      "title_zh": "EGGCodecï¼šé¢å‘ EGG é‡æ„ä¸åŸºé¢‘æå–çš„ç¨³å¥ç¥ç» Encodec æ¡†æ¶",
      "authors": [
        "Rui Feng",
        "Yuang Chen",
        "Yu Hu",
        "Jun Du",
        "Jiahong Yuan"
      ],
      "abstract": "This letter introduces EGGCodec, a robust neural Encodec framework engineered for electroglottography (EGG) signal reconstruction and F0 extraction. We propose a multi-scale frequency-domain loss function to capture the nuanced relationship between original and reconstructed EGG signals, complemented by a time-domain correlation loss to improve generalization and accuracy. Unlike conventional Encodec models that extract F0 directly from features, EGGCodec leverages reconstructed EGG signals, which more closely correspond to F0. By removing the conventional GAN discriminator, we streamline EGGCodec's training process without compromising efficiency, incurring only negligible performance degradation. Trained on a widely used EGG-inclusive dataset, extensive evaluations demonstrate that EGGCodec outperforms state-of-the-art F0 extraction schemes, reducing mean absolute error (MAE) from 14.14 Hz to 13.69 Hz, and improving voicing decision error (VDE) by 38.2\\%. Moreover, extensive ablation experiments validate the contribution of each component of EGGCodec.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EGGCodecï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ä¸ºç”µå£°é—¨å›¾ (EGG) ä¿¡å·é‡å»ºå’ŒåŸºé¢‘ (F0) æå–è®¾è®¡çš„ç¨³å¥ç¥ç» Encodec æ¡†æ¶ã€‚ä¸ºäº†ç²¾å‡†æ•æ‰åŸå§‹ä¿¡å·ä¸é‡å»ºä¿¡å·ä¹‹é—´çš„ç»†å¾®å…³ç³»ï¼Œè¯¥æ¡†æ¶å¼•å…¥äº†å¤šå°ºåº¦é¢‘åŸŸæŸå¤±å‡½æ•°ï¼Œå¹¶è¾…ä»¥æ—¶åŸŸç›¸å…³æ€§æŸå¤±ä»¥æå‡æ³›åŒ–èƒ½åŠ›å’Œå‡†ç¡®æ€§ã€‚ä¸ç›´æ¥ä»ç‰¹å¾ä¸­æå– F0 çš„ä¼ ç»Ÿæ¨¡å‹ä¸åŒï¼ŒEGGCodec åˆ©ç”¨é‡å»ºçš„ EGG ä¿¡å·è¿›è¡Œæå–ï¼Œä½¿å…¶æ›´èƒ½åæ˜  F0 çš„ç‰©ç†ç‰¹æ€§ã€‚ç ”ç©¶äººå‘˜é€šè¿‡ç§»é™¤ä¼ ç»Ÿçš„ GAN åˆ¤åˆ«å™¨ç®€åŒ–äº†è®­ç»ƒè¿‡ç¨‹ï¼Œåœ¨ä¿æŒé«˜æ•ˆçš„åŒæ—¶ç¡®ä¿äº†æ€§èƒ½çš„ç¨³å¥ã€‚åœ¨æƒå¨æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒEGGCodec çš„æ€§èƒ½ä¼˜äºç°æœ‰çš„ F0 æå–æ–¹æ¡ˆï¼Œå°†å¹³å‡ç»å¯¹è¯¯å·® (MAE) ä» 14.14 Hz é™ä½è‡³ 13.69 Hzã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨è¯­éŸ³åˆ¤å®šè¯¯å·® (VDE) æŒ‡æ ‡ä¸Šå®ç°äº† 38.2% çš„æ˜¾è‘—æå‡ï¼Œæ¶ˆèå®éªŒä¹Ÿè¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ¡†æ¶å„ç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 5 figures, to be appeared in IEEE Signal Processing Letters",
      "pdf_url": "https://arxiv.org/pdf/2508.08924v1",
      "published_date": "2025-08-12 13:20:25 UTC",
      "updated_date": "2025-08-12 13:20:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:13.033489+00:00"
    },
    {
      "arxiv_id": "2508.08923v1",
      "title": "Shape Completion and Real-Time Visualization in Robotic Ultrasound Spine Acquisitions",
      "title_zh": "æœºå™¨äººè¶…å£°è„ŠæŸ±é‡‡é›†ä¸­çš„å½¢çŠ¶è¡¥å…¨ä¸å®æ—¶å¯è§†åŒ–",
      "authors": [
        "Miruna-Alexandra Gafencu",
        "Reem Shaban",
        "Yordanka Velikova",
        "Mohammad Farid Azampour",
        "Nassir Navab"
      ],
      "abstract": "Ultrasound (US) imaging is increasingly used in spinal procedures due to its real-time, radiation-free capabilities; however, its effectiveness is hindered by shadowing artifacts that obscure deeper tissue structures. Traditional approaches, such as CT-to-US registration, incorporate anatomical information from preoperative CT scans to guide interventions, but they are limited by complex registration requirements, differences in spine curvature, and the need for recent CT imaging. Recent shape completion methods can offer an alternative by reconstructing spinal structures in US data, while being pretrained on large set of publicly available CT scans. However, these approaches are typically offline and have limited reproducibility. In this work, we introduce a novel integrated system that combines robotic ultrasound with real-time shape completion to enhance spinal visualization. Our robotic platform autonomously acquires US sweeps of the lumbar spine, extracts vertebral surfaces from ultrasound, and reconstructs the complete anatomy using a deep learning-based shape completion network. This framework provides interactive, real-time visualization with the capability to autonomously repeat scans and can enable navigation to target locations. This can contribute to better consistency, reproducibility, and understanding of the underlying anatomy. We validate our approach through quantitative experiments assessing shape completion accuracy and evaluations of multiple spine acquisition protocols on a phantom setup. Additionally, we present qualitative results of the visualization on a volunteer scan.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¶…å£°æˆåƒ(Ultrasound)åœ¨è„ŠæŸ±æ‰‹æœ¯ä¸­å› é˜´å½±ä¼ªå½±å¯¼è‡´æ·±éƒ¨ç»“æ„ä¸æ¸…æ™°çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆæœºå™¨äººè¶…å£°(Robotic ultrasound)ä¸å®æ—¶å½¢çŠ¶è¡¥å…¨(Shape completion)çš„æ–°å‹é›†æˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿåˆ©ç”¨æœºå™¨äººå¹³å°è‡ªä¸»é‡‡é›†è…°æ¤è¶…å£°æ‰«æŸ¥æ•°æ®ï¼Œé€šè¿‡æ·±åº¦å­¦ä¹ ç½‘ç»œä»è¶…å£°å½±åƒä¸­æå–æ¤ä½“è¡¨é¢å¹¶é‡å»ºå®Œæ•´çš„è§£å‰–ç»“æ„ã€‚è¯¥æ¡†æ¶æ”¯æŒäº¤äº’å¼å®æ—¶å¯è§†åŒ–ï¼Œå¹¶å…·å¤‡è‡ªä¸»é‡å¤æ‰«æå’Œç›®æ ‡ä½ç½®å¯¼èˆªçš„èƒ½åŠ›ï¼Œæœ‰æ•ˆå…‹æœäº†ä¼ ç»ŸCT-to-USé…å‡†å¯¹æœ¯å‰å½±åƒå’Œå¤æ‚é…å‡†è¿‡ç¨‹çš„ä¾èµ–ã€‚é€šè¿‡åœ¨ä½“æ¨¡(Phantom)ä¸Šçš„å®šé‡å®éªŒå’Œå¿—æ„¿è€…æ‰«æçš„å®šæ€§è¯„ä¼°ï¼ŒéªŒè¯äº†è¯¥æ–¹æ³•åœ¨å½¢çŠ¶è¡¥å…¨å‡†ç¡®æ€§æ–¹é¢çš„è¡¨ç°ã€‚è¯¥ç ”ç©¶æ˜¾è‘—æå‡äº†è„ŠæŸ±è§£å‰–ç»“æ„ç†è§£çš„ä¸€è‡´æ€§ä¸å¯é‡å¤æ€§ï¼Œä¸ºä¸´åºŠæ‰‹æœ¯å¯¼èˆªæä¾›äº†ä¸€ç§é«˜æ•ˆã€æ— è¾å°„çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08923v1",
      "published_date": "2025-08-12 13:19:37 UTC",
      "updated_date": "2025-08-12 13:19:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:14.648595+00:00"
    },
    {
      "arxiv_id": "2508.11692v1",
      "title": "Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning",
      "title_zh": "åŸºäºæ·±åº¦å­¦ä¹ çš„å¯æ‰©å±•ã€æŠ€æœ¯æ— å…³çš„è½¬è¾™æœºè¯Šæ–­ä¸é¢„æµ‹æ€§ç»´æŠ¤",
      "authors": [
        "Eduardo Di Santi",
        "Ruixiang Ci",
        "ClÃ©ment Lefebvre",
        "Nenad Mijatovic",
        "Michele Pugnaloni",
        "Jonathan Brown",
        "Victor MartÃ­n",
        "Kenza Saiah"
      ],
      "abstract": "The Point Machine (PM) is a critical piece of railway equipment that switches train routes by diverting tracks through a switchblade. As with any critical safety equipment, a failure will halt operations leading to service disruptions; therefore, pre-emptive maintenance may avoid unnecessary interruptions by detecting anomalies before they become failures. Previous work relies on several inputs and crafting custom features by segmenting the signal. This not only adds additional requirements for data collection and processing, but it is also specific to the PM technology, the installed locations and operational conditions limiting scalability. Based on the available maintenance records, the main failure causes for PM are obstacles, friction, power source issues and misalignment. Those failures affect the energy consumption pattern of PMs, altering the usual (or healthy) shape of the power signal during the PM movement. In contrast to the current state-of-the-art, our method requires only one input. We apply a deep learning model to the power signal pattern to classify if the PM is nominal or associated with any failure type, achieving >99.99\\% precision, <0.01\\% false positives and negligible false negatives. Our methodology is generic and technology-agnostic, proven to be scalable on several electromechanical PM types deployed in both real-world and test bench environments. Finally, by using conformal prediction the maintainer gets a clear indication of the certainty of the system outputs, adding a confidence layer to operations and making the method compliant with the ISO-17359 standard.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é“è·¯å…³é”®è®¾å¤‡è½¬è¾™æœº(Point Machine)çš„æ•…éšœè¯Šæ–­ä¸é¢„æµ‹æ€§ç»´æŠ¤ï¼Œæå‡ºäº†ä¸€ç§åŸºäºæ·±åº¦å­¦ä¹ (Deep Learning)çš„é€šç”¨æ–¹æ¡ˆã€‚ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•ä¾èµ–å¤šé¡¹è¾“å…¥å’Œç‰¹å®šç‰¹å¾å·¥ç¨‹çš„å±€é™æ€§ï¼Œè¯¥æ–¹æ³•ä»…éœ€åŠŸç‡ä¿¡å·(power signal)è¿™ä¸€é¡¹è¾“å…¥ï¼Œé€šè¿‡è¯†åˆ«èƒ½é‡æ¶ˆè€—æ¨¡å¼çš„å˜åŒ–æ¥åˆ†ç±»æ­£å¸¸çŠ¶æ€åŠå„ç±»æ•…éšœã€‚è¯¥æŠ€æœ¯å…·æœ‰ä¸å…·ä½“æŠ€æœ¯æ— å…³(technology-agnostic)çš„ç‰¹æ€§ï¼Œåœ¨å¤šç§æœºç”µå¼è½¬è¾™æœºç±»å‹åŠçœŸå®ä¸æµ‹è¯•ç¯å¢ƒä¸­å‡è¡¨ç°å‡ºæé«˜çš„å¯æ‰©å±•æ€§ã€‚å®éªŒæ•°æ®è¡¨æ˜ï¼Œè¯¥æ¨¡å‹å®ç°äº†è¶…è¿‡99.99%çš„ç²¾ç¡®ç‡(precision)å’Œä½äº0.01%çš„è¯¯æŠ¥ç‡(false positives)ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åˆè§„é¢„æµ‹(conformal prediction)ä»¥æä¾›è¾“å‡ºç»“æœçš„ç½®ä¿¡åº¦ï¼Œç¡®ä¿ç³»ç»Ÿç¬¦åˆISO-17359æ ‡å‡†ï¼Œä¸ºé“è·¯ç³»ç»Ÿçš„å®‰å…¨è¿è¡Œå’Œé¢„æµ‹æ€§ç»´æŠ¤æä¾›äº†é«˜å¯é çš„æŠ€æœ¯æ”¯æ’‘ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "Peer-reviewed conference paper. Presented at ICROMA 2025, Dresden, Germany. Conference: https://tu-dresden.de/raildresden2025. Book of abstracts: https://tu-dresden.de/raildresden2025/BoA.pdf. 8 pages, 6 figures, 1 table",
      "pdf_url": "https://arxiv.org/pdf/2508.11692v1",
      "published_date": "2025-08-12 13:15:56 UTC",
      "updated_date": "2025-08-12 13:15:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:33.483228+00:00"
    },
    {
      "arxiv_id": "2508.09239v1",
      "title": "Gradient-Direction-Aware Density Control for 3D Gaussian Splatting",
      "title_zh": "é¢å‘ 3D é«˜æ–¯æ³¼æº…çš„æ¢¯åº¦æ–¹å‘æ„ŸçŸ¥å¯†åº¦æ§åˆ¶",
      "authors": [
        "Zheng Zhou",
        "Yu-Jie Xiong",
        "Chun-Ming Xia",
        "Jia-Chen Zhang",
        "Hong-Jian Zhan"
      ],
      "abstract": "The emergence of 3D Gaussian Splatting (3DGS) has significantly advanced novel view synthesis through explicit scene representation, enabling real-time photorealistic rendering. However, existing approaches manifest two critical limitations in complex scenarios: (1) Over-reconstruction occurs when persistent large Gaussians cannot meet adaptive splitting thresholds during density control. This is exacerbated by conflicting gradient directions that prevent effective splitting of these Gaussians; (2) Over-densification of Gaussians occurs in regions with aligned gradient aggregation, leading to redundant component proliferation. This redundancy significantly increases memory overhead due to unnecessary data retention. We present Gradient-Direction-Aware Gaussian Splatting (GDAGS), a gradient-direction-aware adaptive density control framework to address these challenges. Our key innovations: the gradient coherence ratio (GCR), computed through normalized gradient vector norms, which explicitly discriminates Gaussians with concordant versus conflicting gradient directions; and a nonlinear dynamic weighting mechanism leverages the GCR to enable gradient-direction-aware density control. Specifically, GDAGS prioritizes conflicting-gradient Gaussians during splitting operations to enhance geometric details while suppressing redundant concordant-direction Gaussians. Conversely, in cloning processes, GDAGS promotes concordant-direction Gaussian densification for structural completion while preventing conflicting-direction Gaussian overpopulation. Comprehensive evaluations across diverse real-world benchmarks demonstrate that GDAGS achieves superior rendering quality while effectively mitigating over-reconstruction, suppressing over-densification, and constructing compact scene representations with 50\\% reduced memory consumption through optimized Gaussians utilization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GDAGS (Gradient-Direction-Aware Gaussian Splatting)ï¼Œä¸€ç§æ„ŸçŸ¥æ¢¯åº¦æ–¹å‘çš„è‡ªé€‚åº”å¯†åº¦æ§åˆ¶æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³3D Gaussian Splatting (3DGS) åœ¨å¤æ‚åœºæ™¯ä¸­é¢ä¸´çš„è¿‡åº¦é‡å»º(Over-reconstruction)å’Œè¿‡åº¦åŠ å¯†(Over-densification)é—®é¢˜ã€‚æ ¸å¿ƒåˆ›æ–°åŒ…æ‹¬å¼•å…¥äº†æ¢¯åº¦ç›¸å¹²æ¯”(Gradient Coherence Ratio, GCR)ï¼Œç”¨äºæ˜¾å¼åŒºåˆ†å…·æœ‰ä¸€è‡´æˆ–å†²çªæ¢¯åº¦æ–¹å‘çš„é«˜æ–¯åˆ†å¸ƒï¼Œå¹¶ç»“åˆäº†éçº¿æ€§åŠ¨æ€åŠ æƒæœºåˆ¶ã€‚åœ¨å¯†åº¦æ§åˆ¶è¿‡ç¨‹ä¸­ï¼ŒGDAGSåœ¨åˆ†è£‚(Splitting)æ“ä½œä¸­ä¼˜å…ˆå¤„ç†æ¢¯åº¦å†²çªçš„é«˜æ–¯ä»¥æå‡å‡ ä½•ç»†èŠ‚ï¼ŒåŒæ—¶åœ¨å…‹éš†(Cloning)è¿‡ç¨‹ä¸­ä¿ƒè¿›ä¸€è‡´æ¢¯åº¦çš„é«˜æ–¯è‡´å¯†åŒ–ã€‚è¿™ä¸€æœºåˆ¶æœ‰æ•ˆæŠ‘åˆ¶äº†å†—ä½™ç»„ä»¶çš„å¢æ®–ï¼Œå¹¶æ˜¾è‘—ç¼“è§£äº†å› æ¢¯åº¦èšåˆå¯¼è‡´çš„å†…å­˜å¼€é”€ã€‚å®éªŒè¡¨æ˜ï¼ŒGDAGSåœ¨ä¿æŒä¼˜å¼‚æ¸²æŸ“è´¨é‡çš„åŒæ—¶ï¼ŒæˆåŠŸæ„å»ºäº†æ›´ä¸ºç´§å‡‘çš„åœºæ™¯è¡¨ç¤ºï¼Œå¹¶å°†å†…å­˜æ¶ˆè€—é™ä½äº†50%ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09239v1",
      "published_date": "2025-08-12 13:12:54 UTC",
      "updated_date": "2025-08-12 13:12:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:50.293053+00:00"
    },
    {
      "arxiv_id": "2508.16606v1",
      "title": "Multimodal Appearance based Gaze-Controlled Virtual Keyboard with Synchronous Asynchronous Interaction for Low-Resource Settings",
      "title_zh": "é¢å‘ä½èµ„æºç¯å¢ƒã€æ”¯æŒåŒæ­¥ä¸å¼‚æ­¥äº¤äº’çš„å¤šæ¨¡æ€å¤–è§‚è§†çº¿æ§åˆ¶è™šæ‹Ÿé”®ç›˜",
      "authors": [
        "Yogesh Kumar Meena",
        "Manish Salvi"
      ],
      "abstract": "Over the past decade, the demand for communication devices has increased among individuals with mobility and speech impairments. Eye-gaze tracking has emerged as a promising solution for hands-free communication; however, traditional appearance-based interfaces often face challenges such as accuracy issues, involuntary eye movements, and difficulties with extensive command sets. This work presents a multimodal appearance-based gaze-controlled virtual keyboard that utilises deep learning in conjunction with standard camera hardware, incorporating both synchronous and asynchronous modes for command selection. The virtual keyboard application supports menu-based selection with nine commands, enabling users to spell and type up to 56 English characters, including uppercase and lowercase letters, punctuation, and a delete function for corrections. The proposed system was evaluated with twenty able-bodied participants who completed specially designed typing tasks using three input modalities: (i) a mouse, (ii) an eye-tracker, and (iii) an unmodified webcam. Typing performance was measured in terms of speed and information transfer rate (ITR) at both command and letter levels. Average typing speeds were 18.3+-5.31 letters/min (mouse), 12.60+-2.99letters/min (eye-tracker, synchronous), 10.94 +- 1.89 letters/min (webcam, synchronous), 11.15 +- 2.90 letters/min (eye-tracker, asynchronous), and 7.86 +- 1.69 letters/min (webcam, asynchronous). ITRs were approximately 80.29 +- 15.72 bits/min (command level) and 63.56 +- 11 bits/min (letter level) with webcam in synchronous mode. The system demonstrated good usability and low workload with webcam input, highlighting its user-centred design and promise as an accessible communication tool in low-resource settings.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è¡ŒåŠ¨å’Œè¨€è¯­éšœç¢è€…çš„äº¤æµéœ€æ±‚ï¼Œæå‡ºäº†ä¸€ç§åŸºäºå¤šæ¨¡æ€å¤–è§‚(Appearance-based)çš„æ³¨è§†æ§åˆ¶è™šæ‹Ÿé”®ç›˜ç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿç»“åˆæ·±åº¦å­¦ä¹ (Deep Learning)æŠ€æœ¯ä¸æ™®é€šæ‘„åƒå¤´ç¡¬ä»¶ï¼Œå¹¶åˆ›æ–°æ€§åœ°é›†æˆäº†åŒæ­¥(Synchronous)å’Œå¼‚æ­¥(Asynchronous)ä¸¤ç§äº¤äº’æ¨¡å¼ï¼Œä»¥è§£å†³ä¼ ç»Ÿæ³¨è§†è¿½è¸ªç•Œé¢åœ¨å‡†ç¡®ç‡å’Œéè‡ªå‘æ€§çœ¼åŠ¨æ–¹é¢çš„æŒ‘æˆ˜ã€‚è™šæ‹Ÿé”®ç›˜é€šè¿‡ä¹ä¸ªæ ¸å¿ƒæŒ‡ä»¤çš„èœå•è®¾è®¡ï¼Œæ”¯æŒç”¨æˆ·è¾“å…¥åŒ…æ‹¬å¤§å°å†™å­—æ¯åŠæ ‡ç‚¹åœ¨å†…çš„56ä¸ªå­—ç¬¦ï¼Œå¹¶å…·å¤‡çº é”™åŠŸèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä½¿ç”¨æ™®é€šæ‘„åƒå¤´çš„åŒæ­¥æ¨¡å¼ä¸‹ï¼Œç”¨æˆ·å¹³å‡æ‰“å­—é€Ÿåº¦å¯è¾¾10.94 letters/minï¼ŒæŒ‡ä»¤çº§ä¿¡æ¯ä¼ è¾“ç‡(ITR)çº¦ä¸º80.29 bits/minã€‚è¯¥ç³»ç»Ÿå±•ç°å‡ºè‰¯å¥½çš„æ˜“ç”¨æ€§å’Œè¾ƒä½çš„å·¥ä½œè´Ÿè½½ï¼Œè¯æ˜äº†å…¶åœ¨èµ„æºæœ‰é™(Low-resource settings)ç¯å¢ƒä¸‹ä½œä¸ºå¯æ‰©å±•è¾…åŠ©äº¤æµå·¥å…·çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16606v1",
      "published_date": "2025-08-12 13:08:54 UTC",
      "updated_date": "2025-08-12 13:08:54 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:45.490883+00:00"
    },
    {
      "arxiv_id": "2508.08912v1",
      "title": "Munsit at NADI 2025 Shared Task 2: Pushing the Boundaries of Multidialectal Arabic ASR with Weakly Supervised Pretraining and Continual Supervised Fine-tuning",
      "title_zh": "Munsit åœ¨ NADI 2025 Shared Task 2ï¼šé€šè¿‡å¼±ç›‘ç£é¢„è®­ç»ƒå’ŒæŒç»­ç›‘ç£å¾®è°ƒçªç ´å¤šæ–¹è¨€é˜¿æ‹‰ä¼¯è¯­ ASR çš„ç•Œé™",
      "authors": [
        "Mahmoud Salhab",
        "Shameed Sait",
        "Mohammad Abusheikh",
        "Hasan Abusheikh"
      ],
      "abstract": "Automatic speech recognition (ASR) plays a vital role in enabling natural human-machine interaction across applications such as virtual assistants, industrial automation, customer support, and real-time transcription. However, developing accurate ASR systems for low-resource languages like Arabic remains a significant challenge due to limited labeled data and the linguistic complexity introduced by diverse dialects. In this work, we present a scalable training pipeline that combines weakly supervised learning with supervised fine-tuning to develop a robust Arabic ASR model. In the first stage, we pretrain the model on 15,000 hours of weakly labeled speech covering both Modern Standard Arabic (MSA) and various Dialectal Arabic (DA) variants. In the subsequent stage, we perform continual supervised fine-tuning using a mixture of filtered weakly labeled data and a small, high-quality annotated dataset. Our approach achieves state-of-the-art results, ranking first in the multi-dialectal Arabic ASR challenge. These findings highlight the effectiveness of weak supervision paired with fine-tuning in overcoming data scarcity and delivering high-quality ASR for low-resource, dialect-rich languages.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é˜¿æ‹‰ä¼¯è¯­å¤šæ–¹è¨€è¯­éŸ³è¯†åˆ« (ASR) é¢ä¸´çš„æ ‡æ³¨æ•°æ®åŒ®ä¹å’Œæ–¹è¨€å¤æ‚åº¦é«˜ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† Munsit æ¨¡å‹çš„å¼€å‘æµç¨‹ã€‚è¯¥æµç¨‹é‡‡ç”¨äº†ä¸€ç§å¯æ‰©å±•çš„è®­ç»ƒæµæ°´çº¿ï¼Œé¦–å…ˆåœ¨åŒ…å«ç°ä»£æ ‡å‡†é˜¿æ‹‰ä¼¯è¯­ (MSA) å’Œå¤šç§æ–¹è¨€ (DA) å˜ä½“çš„ 15,000 å°æ—¶å¼±æ ‡æ³¨è¯­éŸ³æ•°æ®ä¸Šè¿›è¡Œå¼±ç›‘ç£é¢„è®­ç»ƒ (Weakly Supervised Pretraining)ã€‚éšåï¼Œç ”ç©¶è€…é€šè¿‡ç»“åˆè¿‡æ»¤åçš„å¼±æ ‡æ³¨æ•°æ®ä¸å°‘é‡é«˜è´¨é‡æ ‡æ³¨æ•°æ®é›†ï¼Œè¿›è¡ŒæŒç»­æœ‰ç›‘ç£å¾®è°ƒ (Continual Supervised Fine-tuning)ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•åœ¨ NADI 2025 å¤šæ–¹è¨€é˜¿æ‹‰ä¼¯è¯­ ASR æŒ‘æˆ˜èµ›ä¸­å–å¾—äº†ç¬¬ä¸€åçš„æˆç»©ï¼Œè¾¾åˆ°äº†å½“å‰æœ€ä¼˜æ°´å¹³ (State-of-the-art)ã€‚è¿™ä¸€æˆæœè¯æ˜äº†å¼±ç›‘ç£å­¦ä¹ ä¸å¾®è°ƒç›¸ç»“åˆåœ¨å…‹æœä½èµ„æºè¯­è¨€æ•°æ®ç¨€ç¼ºã€æå‡å¤šæ–¹è¨€ ASR è´¨é‡æ–¹é¢çš„å“è¶Šæœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08912v1",
      "published_date": "2025-08-12 13:02:22 UTC",
      "updated_date": "2025-08-12 13:02:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:44.084146+00:00"
    },
    {
      "arxiv_id": "2508.08909v2",
      "title": "Compass-Thinker-7B Technical Report",
      "title_zh": "Compass-Thinker-7B æŠ€æœ¯æŠ¥å‘Š",
      "authors": [
        "Anxiang Zeng",
        "Haibo Zhang",
        "Kaixiang Mo",
        "Long Zhang",
        "Shuman Liu",
        "Yanhui Huang",
        "Yawen Liu",
        "Yuepeng Sheng",
        "Yuwei Huang"
      ],
      "abstract": "Recent R1-Zero-like research further demonstrates that reasoning extension has given large language models (LLMs) unprecedented reasoning capabilities, and Reinforcement Learning is the core technology to elicit its complex reasoning. However, conducting RL experiments directly on hyperscale models involves high computational costs and resource demands, posing significant risks. We propose the Compass-Thinker-7B model, which aims to explore the potential of Reinforcement Learning with less computational resources and costs, and provides insights for further research into RL recipes for larger models. Compass-Thinker-7B is trained from an open source model through a specially designed Reinforcement Learning Pipeline. We curate a dataset of 30k verifiable mathematics problems for the Reinforcement Learning Pipeline. By configuring data and training settings with different difficulty distributions for different stages, the potential of the model is gradually released and the training efficiency is improved. Extensive evaluations show that Compass-Thinker-7B possesses exceptional reasoning potential, and achieves superior performance on mathematics compared to the same-sized RL model. Especially in the challenging AIME2024 evaluation, Compass-Thinker-7B achieves 40% accuracy.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Compass-Thinker-7B æ¨¡å‹ï¼Œæ—¨åœ¨æ¢ç´¢å¦‚ä½•ä»¥æ›´ä½çš„è®¡ç®—èµ„æºå’Œæˆæœ¬ï¼Œåˆ©ç”¨å¼ºåŒ–å­¦ä¹  (Reinforcement Learning) æŠ€æœ¯æ¿€å‘å¤§å‹è¯­è¨€æ¨¡å‹ (LLMs) çš„å¤æ‚æ¨ç†æ½œåŠ›ã€‚é’ˆå¯¹åœ¨è¶…å¤§è§„æ¨¡æ¨¡å‹ä¸Šç›´æ¥è¿›è¡Œ RL å®éªŒæ‰€é¢ä¸´çš„é«˜æ˜‚ä»£ä»·ï¼Œè¯¥æ¨¡å‹åœ¨å¼€æºæ¨¡å‹åŸºç¡€ä¸Šé‡‡ç”¨äº†ä¸“é—¨è®¾è®¡çš„ Reinforcement Learning Pipelineã€‚ç ”ç©¶å›¢é˜Ÿç­–åˆ’äº†ç”± 3 ä¸‡ä¸ªå¯éªŒè¯æ•°å­¦é—®é¢˜ç»„æˆçš„æ•°æ®é›†ï¼Œå¹¶é€šè¿‡åœ¨ä¸åŒè®­ç»ƒé˜¶æ®µé…ç½®æ¢¯åº¦éš¾åº¦çš„è®¾ç½®ï¼Œæœ‰æ•ˆé‡Šæ”¾äº†æ¨¡å‹çš„æ¨ç†æ½œåŠ›å¹¶æå‡äº†è®­ç»ƒæ•ˆç‡ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼ŒCompass-Thinker-7B åœ¨æ•°å­¦é¢†åŸŸè¡¨ç°å‡ºä¼˜äºåŒç­‰è§„æ¨¡ RL æ¨¡å‹çš„æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯åœ¨æå…·æŒ‘æˆ˜æ€§çš„ AIME2024 æµ‹è¯•ä¸­ï¼Œè¯¥æ¨¡å‹å®ç°äº† 40% çš„å‡†ç¡®ç‡ï¼Œä¸ºåç»­ç ”ç©¶æ›´å¤§è§„æ¨¡æ¨¡å‹çš„ RL ç­–ç•¥æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08909v2",
      "published_date": "2025-08-12 12:58:12 UTC",
      "updated_date": "2025-08-14 07:12:38 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:53.187159+00:00"
    },
    {
      "arxiv_id": "2508.14908v1",
      "title": "A Chinese Heart Failure Status Speech Database with Universal and Personalised Classification",
      "title_zh": "æ”¯æŒé€šç”¨ä¸ä¸ªæ€§åŒ–åˆ†ç±»çš„ä¸­æ–‡å¿ƒåŠ›è¡°ç«­çŠ¶æ€è¯­éŸ³æ•°æ®åº“",
      "authors": [
        "Yue Pan",
        "Liwei Liu",
        "Changxin Li",
        "Xinyao Wang",
        "Yili Xia",
        "Hanyue Zhang",
        "Ming Chu"
      ],
      "abstract": "Speech is a cost-effective and non-intrusive data source for identifying acute and chronic heart failure (HF). However, there is a lack of research on whether Chinese syllables contain HF-related information, as observed in other well-studied languages. This study presents the first Chinese speech database of HF patients, featuring paired recordings taken before and after hospitalisation. The findings confirm the effectiveness of the Chinese language in HF detection using both standard 'patient-wise' and personalised 'pair-wise' classification approaches, with the latter serving as an ideal speaker-decoupled baseline for future research. Statistical tests and classification results highlight individual differences as key contributors to inaccuracy. Additionally, an adaptive frequency filter (AFF) is proposed for frequency importance analysis. The data and demonstrations are published at https://github.com/panyue1998/Voice_HF.",
      "tldr_zh": "è¯¥ç ”ç©¶æŒ‡å‡ºè¯­éŸ³æ˜¯è¯†åˆ«æ€¥æ€§å’Œæ…¢æ€§å¿ƒåŠ›è¡°ç«­(Heart Failure, HF)çš„ä¸€ç§ä½æˆæœ¬ä¸”éä¾µå…¥æ€§çš„æ•°æ®æ¥æºï¼Œå¹¶å»ºç«‹äº†é¦–ä¸ªåŒ…å«æ‚£è€…ä½é™¢å‰åé…å¯¹å½•éŸ³çš„ä¸­å›½HFæ‚£è€…è¯­éŸ³æ•°æ®åº“ã€‚ç ”ç©¶é€šè¿‡æ ‡å‡†çš„â€œpatient-wiseâ€å’Œä¸ªæ€§åŒ–çš„â€œpair-wiseâ€åˆ†ç±»æ–¹æ³•ï¼Œè¯å®äº†ä¸­æ–‡éŸ³èŠ‚åœ¨HFæ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œå…¶ä¸­â€œpair-wiseâ€æ–¹æ³•ä¸ºæœªæ¥å»è¯´è¯äººè€¦åˆç ”ç©¶æä¾›äº†ç†æƒ³åŸºå‡†ã€‚ç»Ÿè®¡æµ‹è¯•ä¸åˆ†ç±»ç»“æœè¡¨æ˜ï¼Œä¸ªä½“å·®å¼‚æ˜¯å½±å“æ£€æµ‹å‡†ç¡®ç‡çš„å…³é”®å› ç´ ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†ä¸€ç§è‡ªé€‚åº”é¢‘ç‡æ»¤æ³¢å™¨(Adaptive Frequency Filter, AFF)ç”¨äºåˆ†æé¢‘ç‡é‡è¦æ€§ã€‚è¯¥å·¥ä½œå¡«è¡¥äº†ä¸­æ–‡è¯­éŸ³HFæ£€æµ‹çš„ç ”ç©¶ç©ºç™½ï¼Œç›¸å…³çš„æ•°æ®åº“å’Œæ¼”ç¤ºå·²åœ¨GitHubå¼€æºã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14908v1",
      "published_date": "2025-08-12 12:52:16 UTC",
      "updated_date": "2025-08-12 12:52:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:16:53.884233+00:00"
    },
    {
      "arxiv_id": "2508.08895v2",
      "title": "ASPD: Unlocking Adaptive Serial-Parallel Decoding by Exploring Intrinsic Parallelism in LLMs",
      "title_zh": "ASPDï¼šé€šè¿‡æŒ–æ˜å¤§è¯­è¨€æ¨¡å‹ä¸­çš„å†…åœ¨å¹¶è¡Œæ€§å®ç°è‡ªé€‚åº”ä¸²å¹¶è¡Œè§£ç ",
      "authors": [
        "Keyu Chen",
        "Zhifeng Shen",
        "Daohai Yu",
        "Haoqian Wu",
        "Wei Wen",
        "Jianfeng He",
        "Ruizhi Qiao",
        "Xing Sun"
      ],
      "abstract": "The increasing scale and complexity of large language models (LLMs) pose significant inference latency challenges, primarily due to their autoregressive decoding paradigm characterized by the sequential nature of next-token prediction. By re-examining the outputs of autoregressive models, we observed that some segments exhibit parallelizable structures, which we term intrinsic parallelism. Decoding each parallelizable branch simultaneously (i.e. parallel decoding) can significantly improve the overall inference speed of LLMs. In this paper, we propose an Adaptive Serial-Parallel Decoding (ASPD), which addresses two core challenges: automated construction of parallelizable data and efficient parallel decoding mechanism. More specifically, we introduce a non-invasive pipeline that automatically extracts and validates parallelizable structures from the responses of autoregressive models. To empower efficient adaptive serial-parallel decoding, we implement a Hybrid Decoding Engine which enables seamless transitions between serial and parallel decoding modes while maintaining a reusable KV cache, maximizing computational efficiency. Extensive evaluations across General Tasks, Retrieval-Augmented Generation, Mathematical Reasoning, demonstrate that ASPD achieves unprecedented performance in both effectiveness and efficiency. Notably, on Vicuna Bench, our method achieves up to 3.19x speedup (1.85x on average) while maintaining response quality within 1% difference compared to autoregressive models, realizing significant acceleration without compromising generation quality. Our framework sets a groundbreaking benchmark for efficient LLM parallel inference, paving the way for its deployment in latency-sensitive applications such as AI-powered customer service bots and answer retrieval engines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)å› è‡ªå›å½’(autoregressive)è§£ç æ¨¡å¼å¸¦æ¥çš„æ¨ç†å»¶è¿ŸæŒ‘æˆ˜ï¼Œæå‡ºäº†è‡ªé€‚åº”ä¸²å¹¶è¡Œè§£ç æ¡†æ¶ASPD (Adaptive Serial-Parallel Decoding)ã€‚é€šè¿‡é‡æ–°å®¡è§†æ¨¡å‹è¾“å‡ºï¼Œç ”ç©¶è€…å‘ç°éƒ¨åˆ†ç‰‡æ®µå±•ç°å‡ºå¯å¹¶è¡ŒåŒ–çš„ç»“æ„ï¼Œå³å†…åœ¨å¹¶è¡Œæ€§(intrinsic parallelism)ã€‚ASPD å¼•å…¥äº†ä¸€ç§éä¾µå…¥å¼æµæ°´çº¿ï¼Œèƒ½å¤Ÿè‡ªåŠ¨ä»æ¨¡å‹å“åº”ä¸­æå–å¹¶éªŒè¯è¿™äº›å¹¶è¡Œç»“æ„ã€‚åŒæ—¶ï¼Œè¯¥æ¡†æ¶é€šè¿‡æ··åˆè§£ç å¼•æ“(Hybrid Decoding Engine)å®ç°äº†ä¸²è¡Œä¸å¹¶è¡Œæ¨¡å¼çš„æ— ç¼åˆ‡æ¢ï¼Œå¹¶åˆ©ç”¨å¯å¤ç”¨çš„ KV cache æœ€å¤§åŒ–è®¡ç®—æ•ˆç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒASPD åœ¨ Vicuna Bench ä¸Šå®ç°äº†æœ€é«˜ 3.19 å€ã€å¹³å‡ 1.85 å€çš„åŠ é€Ÿæ•ˆæœï¼Œä¸”ç”Ÿæˆè´¨é‡ä¸åŸå§‹æ¨¡å‹ç›¸æ¯”å·®å¼‚ä¸è¶³ 1%ã€‚è¯¥æ¡†æ¶ä¸ºä½å»¶è¿Ÿåœºæ™¯ä¸‹çš„ LLM æ¨ç†éƒ¨ç½²æä¾›äº†é«˜æ•ˆä¸”é«˜ä¿çœŸåº¦çš„å¹¶è¡Œæ¨ç†åŸºå‡†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08895v2",
      "published_date": "2025-08-12 12:35:55 UTC",
      "updated_date": "2025-08-14 09:04:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:05.991823+00:00"
    },
    {
      "arxiv_id": "2508.08883v1",
      "title": "Position: Causal Machine Learning Requires Rigorous Synthetic Experiments for Broader Adoption",
      "title_zh": "è§‚ç‚¹ï¼šå› æœæœºå™¨å­¦ä¹ éœ€è¦ä¸¥è°¨çš„åˆæˆå®éªŒä»¥æ¨åŠ¨å…¶å¹¿æ³›åº”ç”¨",
      "authors": [
        "Audrey Poinsot",
        "Panayiotis Panayiotou",
        "Alessandro Leite",
        "Nicolas Chesneau",
        "Ã–zgÃ¼r ÅimÅŸek",
        "Marc Schoenauer"
      ],
      "abstract": "Causal machine learning has the potential to revolutionize decision-making by combining the predictive power of machine learning algorithms with the theory of causal inference. However, these methods remain underutilized by the broader machine learning community, in part because current empirical evaluations do not permit assessment of their reliability and robustness, undermining their practical utility. Specifically, one of the principal criticisms made by the community is the extensive use of synthetic experiments. We argue, on the contrary, that synthetic experiments are essential and necessary to precisely assess and understand the capabilities of causal machine learning methods. To substantiate our position, we critically review the current evaluation practices, spotlight their shortcomings, and propose a set of principles for conducting rigorous empirical analyses with synthetic data. Adopting the proposed principles will enable comprehensive evaluations that build trust in causal machine learning methods, driving their broader adoption and impactful real-world use.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å› æœæœºå™¨å­¦ä¹ (Causal Machine Learning)åœ¨å†³ç­–åˆ¶å®šä¸­çš„æ½œåŠ›ï¼ŒæŒ‡å‡ºç”±äºç°æœ‰ç»éªŒè¯„ä¼°éš¾ä»¥è¡¡é‡å…¶å¯é æ€§å’Œé²æ£’æ€§ï¼Œè¯¥æŠ€æœ¯åœ¨ç¤¾åŒºä¸­ä»æœªå¾—åˆ°å……åˆ†åˆ©ç”¨ã€‚é’ˆå¯¹å­¦ç•Œå¯¹åˆæˆå®éªŒ(synthetic experiments)çš„æ‰¹è¯„ï¼Œä½œè€…æå‡ºäº†ç›¸åçš„ç«‹åœºï¼Œè®¤ä¸ºåˆæˆå®éªŒå¯¹äºç²¾ç¡®è¯„ä¼°å’Œç†è§£è¯¥é¢†åŸŸæ–¹æ³•çš„èƒ½åŠ›è‡³å…³é‡è¦ä¸”ä¸å¯æˆ–ç¼ºã€‚é€šè¿‡å¯¹å½“å‰è¯„ä¼°å®è·µçš„æ‰¹åˆ¤æ€§å®¡è§†ï¼Œè®ºæ–‡æ­ç¤ºäº†å…¶ç¼ºé™·ï¼Œå¹¶ä¸ºåˆ©ç”¨åˆæˆæ•°æ®è¿›è¡Œä¸¥æ ¼çš„ç»éªŒåˆ†ææå‡ºäº†ä¸€å¥—åŸºæœ¬åŸåˆ™ã€‚ä½œè€…å¼ºè°ƒï¼Œé‡‡çº³è¿™äº›åŸåˆ™å°†æœ‰åŠ©äºè¿›è¡Œæ›´å…¨é¢çš„è¯„ä¼°ï¼Œä»è€Œå¢å¼ºå¼€å‘è€…å¯¹å› æœæœºå™¨å­¦ä¹ (Causal Machine Learning)æ–¹æ³•çš„ä¿¡ä»»ã€‚æœ€åï¼Œè¿™å°†æœ‰æ•ˆæ¨åŠ¨è¯¥æŠ€æœ¯åœ¨ç°å®åœºæ™¯ä¸­å®ç°æ›´å¹¿æ³›ä¸”æ›´å…·å½±å“åŠ›çš„è½åœ°åº”ç”¨ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at ICML 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08883v1",
      "published_date": "2025-08-12 12:13:13 UTC",
      "updated_date": "2025-08-12 12:13:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:08.087228+00:00"
    },
    {
      "arxiv_id": "2508.08882v4",
      "title": "Reducing Cognitive Overhead in Tool Use via Multi-Small-Agent Reinforcement Learning",
      "title_zh": "é€šè¿‡å¤šå°å‹æ™ºèƒ½ä½“å¼ºåŒ–å­¦ä¹ é™ä½å·¥å…·ä½¿ç”¨ä¸­çš„è®¤çŸ¥å¼€é”€",
      "authors": [
        "Dayu Wang",
        "Jiaye Yang",
        "Weikang Li",
        "Jiahui Liang",
        "Yang Li"
      ],
      "abstract": "Recent advances in multi-agent systems highlight the potential of specialized small agents that collaborate via division of labor. Existing tool-integrated reasoning systems, however, often follow a single-agent paradigm in which one large model interleaves long-horizon reasoning with precise tool operations, leading to cognitive-load interference and unstable coordination. We present MSARL, a Multi-Small-Agent Reinforcement Learning framework that explicitly decouples reasoning from tool use. In MSARL, a Reasoning Agent decomposes problems and plans tool invocations, while multiple Tool Agents specialize in specific external tools, each trained via a combination of imitation learning and reinforcement learning with role-specific rewards. On mathematical problem solving with code execution, MSARL significantly improves reasoning stability and final-answer accuracy over single-agent baselines. Moreover, the architecture generalizes to diverse tool-use tasks, demonstrating that cognitive-role decoupling with small agents is a scalable blueprint for multi-agent AI design.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MSARLï¼ˆMulti-Small-Agent Reinforcement Learningï¼‰æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ˜¾å¼è§£è€¦æ¨ç†ä¸å·¥å…·ä½¿ç”¨æ¥é™ä½ç³»ç»Ÿè®¤çŸ¥è´Ÿè·ã€‚é’ˆå¯¹å•æ™ºèƒ½ä½“æ¨¡å‹åœ¨å¤„ç†é•¿ç¨‹æ¨ç†ä¸ç²¾ç¡®å·¥å…·æ“ä½œæ—¶å®¹æ˜“å‡ºç°çš„åä½œä¸ç¨³å®šé—®é¢˜ï¼Œè¯¥æ¡†æ¶å°†ä»»åŠ¡æ‹†åˆ†ä¸ºè´Ÿè´£é—®é¢˜åˆ†è§£ä¸è§„åˆ’çš„æ¨ç†æ™ºèƒ½ä½“ï¼ˆReasoning Agentï¼‰ï¼Œä»¥åŠå¤šä¸ªä¸“é—¨æ‰§è¡Œç‰¹å®šå·¥å…·æŒ‡ä»¤çš„å·¥å…·æ™ºèƒ½ä½“ï¼ˆTool Agentsï¼‰ã€‚è¿™äº›æ™ºèƒ½ä½“é€šè¿‡ç»“åˆæ¨¡ä»¿å­¦ä¹ ï¼ˆImitation Learningï¼‰ä¸å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰ï¼Œå¹¶åˆ©ç”¨è§’è‰²ç‰¹å®šçš„å¥–åŠ±æœºåˆ¶è¿›è¡Œè®­ç»ƒã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨æ¶‰åŠä»£ç æ‰§è¡Œçš„æ•°å­¦é—®é¢˜æ±‚è§£ä»»åŠ¡ä¸­ï¼ŒMSARLåœ¨æ¨ç†ç¨³å®šæ€§å’Œç­”æ¡ˆå‡†ç¡®ç‡ä¸Šæ˜¾è‘—ä¼˜äºå•æ™ºèƒ½ä½“åŸºçº¿æ¨¡å‹ã€‚æ­¤å¤–ï¼Œè¯¥æ¶æ„å±•ç°äº†è‰¯å¥½çš„æ³›åŒ–èƒ½åŠ›ï¼Œè¯æ˜äº†é€šè¿‡å°å‹æ™ºèƒ½ä½“è¿›è¡Œè®¤çŸ¥è§’è‰²è§£è€¦æ˜¯å¤šæ™ºèƒ½ä½“äººå·¥æ™ºèƒ½è®¾è®¡ä¸­ä¸€ç§å¯æ‰©å±•çš„æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08882v4",
      "published_date": "2025-08-12 12:10:53 UTC",
      "updated_date": "2025-10-11 08:24:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:18.483533+00:00"
    },
    {
      "arxiv_id": "2508.08879v2",
      "title": "Entangled in Representations: Mechanistic Investigation of Cultural Biases in Large Language Models",
      "title_zh": "è¡¨å¾ä¹‹å›°ï¼šå¤§è¯­è¨€æ¨¡å‹æ–‡åŒ–åè§çš„æœºåˆ¶æ€§æ¢ç©¶",
      "authors": [
        "Haeun Yu",
        "Seogyeong Jeong",
        "Siddhesh Pawar",
        "Jisu Shin",
        "Jiho Jin",
        "Junho Myung",
        "Alice Oh",
        "Isabelle Augenstein"
      ],
      "abstract": "The growing deployment of large language models (LLMs) across diverse cultural contexts necessitates a deeper understanding of LLMs' representations of different cultures. Prior work has focused on evaluating the cultural awareness of LLMs by only examining the text they generate. This approach overlooks the internal sources of cultural misrepresentation within the models themselves. To bridge this gap, we propose Culturescope, the first mechanistic interpretability-based method that probes the internal representations of different cultural knowledge in LLMs. We also introduce a cultural flattening score as a measure of the intrinsic cultural biases of the decoded knowledge from Culturescope. Additionally, we study how LLMs internalize cultural biases, which allows us to trace how cultural biases such as Western-dominance bias and cultural flattening emerge within LLMs. We find that low-resource cultures are less susceptible to cultural biases, likely due to the model's limited parametric knowledge. Our work provides a foundation for future research on mitigating cultural biases and enhancing LLMs' cultural understanding.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨ä¸åŒæ–‡åŒ–èƒŒæ™¯ä¸‹éƒ¨ç½²æ—¶å­˜åœ¨çš„æ–‡åŒ–åè§é—®é¢˜ï¼ŒæŒ‡å‡ºä»¥å¾€ç ”ç©¶ä»…å…³æ³¨ç”Ÿæˆæ–‡æœ¬è€Œå¿½ç•¥äº†æ¨¡å‹å†…éƒ¨è¡¨ç¤ºçš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†Culturescopeï¼Œè¿™æ˜¯é¦–ä¸ªåŸºäºæœºæ¢°è§£é‡Šæ€§ï¼ˆmechanistic interpretabilityï¼‰çš„æ–¹æ³•ï¼Œæ—¨åœ¨æ¢æµ‹LLMså†…éƒ¨å­˜å‚¨çš„ä¸åŒæ–‡åŒ–çŸ¥è¯†è¡¨ç¤ºã€‚ç ”ç©¶è¿˜å¼•å…¥äº†æ–‡åŒ–æ‰å¹³åŒ–è¯„åˆ†ï¼ˆcultural flattening scoreï¼‰ï¼Œä½œä¸ºè¡¡é‡ä»Culturescopeè§£ç å‡ºçš„çŸ¥è¯†ä¸­å­˜åœ¨å†…åœ¨æ–‡åŒ–åè§çš„æ ‡å‡†ã€‚é€šè¿‡ç ”ç©¶LLMså¦‚ä½•å†…åŒ–æ–‡åŒ–åè§ï¼Œè¯¥å·¥ä½œè¿½è¸ªäº†è¥¿æ–¹ä¸»å¯¼åè§ï¼ˆWestern-dominance biasï¼‰å’Œæ–‡åŒ–æ‰å¹³åŒ–ï¼ˆcultural flatteningï¼‰åœ¨æ¨¡å‹å†…éƒ¨çš„äº§ç”Ÿè¿‡ç¨‹ã€‚å®éªŒå‘ç°ï¼Œä½èµ„æºæ–‡åŒ–ï¼ˆlow-resource culturesï¼‰ç”±äºæ¨¡å‹å‚æ•°åŒ–çŸ¥è¯†æœ‰é™ï¼Œåè€Œè¾ƒä¸å®¹æ˜“å—åˆ°æ–‡åŒ–åè§çš„å½±å“ã€‚è¯¥ç ”ç©¶ä¸ºæœªæ¥ç¼“è§£æ–‡åŒ–åè§ã€å¢å¼ºLLMsçš„æ–‡åŒ–ç†è§£èƒ½åŠ›æä¾›äº†é‡è¦çš„æœºæ¢°è®ºåŸºç¡€å’Œè¯„ä¼°å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "16 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08879v2",
      "published_date": "2025-08-12 12:05:32 UTC",
      "updated_date": "2026-01-16 14:21:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:18.884783+00:00"
    },
    {
      "arxiv_id": "2508.08875v2",
      "title": "Oblivionis: A Lightweight Learning and Unlearning Framework for Federated Large Language Models",
      "title_zh": "Oblivionisï¼šé¢å‘è”é‚¦å¤§è¯­è¨€æ¨¡å‹çš„è½»é‡çº§å­¦ä¹ ä¸é—å¿˜æ¡†æ¶",
      "authors": [
        "Fuyao Zhang",
        "Xinyu Yan",
        "Tiantong Wu",
        "Wenjie Li",
        "Tianxiang Chen",
        "Yang Cao",
        "Ran Yan",
        "Longtao Huang",
        "Wei Yang Bryan Lim",
        "Qiang Yang"
      ],
      "abstract": "Large Language Models (LLMs) increasingly leverage Federated Learning (FL) to utilize private, task-specific datasets for fine-tuning while preserving data privacy. However, while federated LLM frameworks effectively enable collaborative training without raw data sharing, they critically lack built-in mechanisms for regulatory compliance like GDPR's right to be forgotten. Integrating private data heightens concerns over data quality and long-term governance, yet existing distributed training frameworks offer no principled way to selectively remove specific client contributions post-training. Due to distributed data silos, stringent privacy constraints, and the intricacies of interdependent model aggregation, federated LLM unlearning is significantly more complex than centralized LLM unlearning. To address this gap, we introduce Oblivionis, a lightweight learning and unlearning framework that enables clients to selectively remove specific private data during federated LLM training, enhancing trustworthiness and regulatory compliance. By unifying FL and unlearning as a dual optimization objective, we incorporate 6 FL and 5 unlearning algorithms for comprehensive evaluation and comparative analysis, establishing a robust pipeline for federated LLM unlearning. Extensive experiments demonstrate that Oblivionis outperforms local training, achieving a robust balance between forgetting efficacy and model utility, with cross-algorithm comparisons providing clear directions for future LLM development.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨è”é‚¦å­¦ä¹ (Federated Learning)ä¸­ç¼ºä¹ç¬¦åˆGDPRâ€œè¢«é—å¿˜æƒâ€ç›‘ç®¡æœºåˆ¶çš„é—®é¢˜ï¼Œæå‡ºäº† Oblivionis è¿™ä¸€è½»é‡çº§çš„å­¦ä¹ ä¸é—å¿˜æ¡†æ¶ã€‚ç”±äºæ•°æ®å­¤å²›ã€ä¸¥è‹›çš„éšç§é™åˆ¶å’Œå¤æ‚çš„æ¨¡å‹èšåˆï¼Œè”é‚¦LLMçš„æœºå™¨é—å¿˜(Unlearning)æ¯”ä¸­å¿ƒåŒ–ç¯å¢ƒæ›´å…·æŒ‘æˆ˜æ€§ï¼Œè€Œ Oblivionis å…è®¸å®¢æˆ·ç«¯åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­é€‰æ‹©æ€§åœ°ç§»é™¤ç‰¹å®šç§æœ‰æ•°æ®ã€‚è¯¥æ¡†æ¶å°†è”é‚¦å­¦ä¹ ä¸æœºå™¨é—å¿˜ç»Ÿä¸€ä¸ºåŒé‡ä¼˜åŒ–ç›®æ ‡ï¼Œå¹¶é›†æˆäº†6ç§è”é‚¦å­¦ä¹ ç®—æ³•å’Œ5ç§é—å¿˜ç®—æ³•ä»¥è¿›è¡Œå…¨é¢çš„è¯„ä¼°ä¸å¯¹æ¯”åˆ†æã€‚å®éªŒç»“æœè¯æ˜ï¼ŒOblivionis åœ¨é—å¿˜æ•ˆç‡(Forgetting Efficacy)ä¸æ¨¡å‹æ•ˆç”¨(Model Utility)ä¹‹é—´å–å¾—äº†æ˜¾è‘—å¹³è¡¡ï¼Œæ€§èƒ½è¶…è¶Šäº†ä¼ ç»Ÿçš„æœ¬åœ°è®­ç»ƒæ¨¡å¼ã€‚è¯¥å·¥ä½œä¸ºå¢å¼ºè”é‚¦LLMçš„å¯ä¿¡åº¦ä¸ç›‘ç®¡åˆè§„æ€§å»ºç«‹äº†ç¨³å¥çš„æµç¨‹ï¼Œå¹¶ä¸ºæœªæ¥LLMçš„åˆ†å¸ƒå¼å¼€å‘æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08875v2",
      "published_date": "2025-08-12 12:02:53 UTC",
      "updated_date": "2025-11-08 06:01:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:33.256478+00:00"
    },
    {
      "arxiv_id": "2508.20103v1",
      "title": "Deep Reinforcement Learning for Optimal Asset Allocation Using DDPG with TiDE",
      "title_zh": "åŸºäº DDPG ä¸ TiDE æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„æœ€ä¼˜èµ„äº§é…ç½®",
      "authors": [
        "Rongwei Liu",
        "Jin Zheng",
        "John Cartlidge"
      ],
      "abstract": "The optimal asset allocation between risky and risk-free assets is a persistent challenge due to the inherent volatility in financial markets. Conventional methods rely on strict distributional assumptions or non-additive reward ratios, which limit their robustness and applicability to investment goals. To overcome these constraints, this study formulates the optimal two-asset allocation problem as a sequential decision-making task within a Markov Decision Process (MDP). This framework enables the application of reinforcement learning (RL) mechanisms to develop dynamic policies based on simulated financial scenarios, regardless of prerequisites. We use the Kelly criterion to balance immediate reward signals against long-term investment objectives, and we take the novel step of integrating the Time-series Dense Encoder (TiDE) into the Deep Deterministic Policy Gradient (DDPG) RL framework for continuous decision-making. We compare DDPG-TiDE with a simple discrete-action Q-learning RL framework and a passive buy-and-hold investment strategy. Empirical results show that DDPG-TiDE outperforms Q-learning and generates higher risk adjusted returns than buy-and-hold. These findings suggest that tackling the optimal asset allocation problem by integrating TiDE within a DDPG reinforcement learning framework is a fruitful avenue for further exploration.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹é‡‘èå¸‚åœºæ³¢åŠ¨å¸¦æ¥çš„é£é™©ä¸æ— é£é™©èµ„äº§æœ€ä¼˜é…ç½®éš¾é¢˜ï¼Œå°†å…¶å»ºæ¨¡ä¸ºé©¬å°”å¯å¤«å†³ç­–è¿‡ç¨‹(Markov Decision Process, MDP)ä¸­çš„åºåˆ—å†³ç­–ä»»åŠ¡ã€‚ç ”ç©¶åˆ›æ–°æ€§åœ°å°†æ—¶é—´åºåˆ—å¯†é›†ç¼–ç å™¨(Time-series Dense Encoder, TiDE)é›†æˆåˆ°æ·±åº¦ç¡®å®šæ€§ç­–ç•¥æ¢¯åº¦(Deep Deterministic Policy Gradient, DDPG)å¼ºåŒ–å­¦ä¹ æ¡†æ¶ä¸­ï¼Œä»¥å®ç°è¿ç»­å†³ç­–å¹¶å¼€å‘åŠ¨æ€æŠ•èµ„ç­–ç•¥ã€‚é€šè¿‡å¼•å…¥å‡¯åˆ©å‡†åˆ™(Kelly criterion)æ¥å¹³è¡¡å³æ—¶å¥–åŠ±ä¿¡å·ä¸é•¿æœŸæŠ•èµ„ç›®æ ‡ï¼Œè¯¥æ–¹æ³•æœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿæ¨¡å‹å¯¹ä¸¥æ ¼åˆ†å¸ƒå‡è®¾çš„ä¾èµ–ã€‚å®éªŒå¯¹æ¯”æ˜¾ç¤ºï¼ŒDDPG-TiDEåœ¨æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºç¦»æ•£åŠ¨ä½œçš„Q-learningæ¡†æ¶ï¼Œå¹¶äº§ç”Ÿäº†æ¯”è¢«åŠ¨æŒæœ‰(buy-and-hold)ç­–ç•¥æ›´é«˜çš„é£é™©è°ƒæ•´æ”¶ç›Šã€‚è¿™ä¸€ç»“æœè¯æ˜äº†å°†TiDEåº”ç”¨äºDDPGå¼ºåŒ–å­¦ä¹ æ¡†æ¶ä»¥è§£å†³æœ€ä¼˜èµ„äº§é…ç½®é—®é¢˜çš„æœ‰æ•ˆæ€§ï¼Œä¸ºè¯¥é¢†åŸŸçš„è¿›ä¸€æ­¥ç ”ç©¶æä¾›äº†å…·æœ‰å‰æ™¯çš„æ–¹å‘ã€‚",
      "categories": [
        "q-fin.PM",
        "cs.AI",
        "cs.LG",
        "q-fin.RM"
      ],
      "primary_category": "q-fin.PM",
      "comment": "10 pages, 3 figures, authors accepted manuscript, to appear in 24th International Conference on Modelling and Applied Simulation (MAS), Sep. 2025, Fes, Morocco",
      "pdf_url": "https://arxiv.org/pdf/2508.20103v1",
      "published_date": "2025-08-12 11:59:55 UTC",
      "updated_date": "2025-08-12 11:59:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:38.791414+00:00"
    },
    {
      "arxiv_id": "2508.15791v1",
      "title": "InteChar: A Unified Oracle Bone Character List for Ancient Chinese Language Modeling",
      "title_zh": "InteCharï¼šé¢å‘å¤æ±‰è¯­è¯­è¨€å»ºæ¨¡çš„ç»Ÿä¸€ç”²éª¨æ–‡å­—è¡¨",
      "authors": [
        "Xiaolei Diao",
        "Zhihan Zhou",
        "Lida Shi",
        "Ting Wang",
        "Ruihua Qi",
        "Hao Xu",
        "Daqian Shi"
      ],
      "abstract": "Constructing historical language models (LMs) plays a crucial role in aiding archaeological provenance studies and understanding ancient cultures. However, existing resources present major challenges for training effective LMs on historical texts. First, the scarcity of historical language samples renders unsupervised learning approaches based on large text corpora highly inefficient, hindering effective pre-training. Moreover, due to the considerable temporal gap and complex evolution of ancient scripts, the absence of comprehensive character encoding schemes limits the digitization and computational processing of ancient texts, particularly in early Chinese writing. To address these challenges, we introduce InteChar, a unified and extensible character list that integrates unencoded oracle bone characters with traditional and modern Chinese. InteChar enables consistent digitization and representation of historical texts, providing a foundation for robust modeling of ancient scripts. To evaluate the effectiveness of InteChar, we construct the Oracle Corpus Set (OracleCS), an ancient Chinese corpus that combines expert-annotated samples with LLM-assisted data augmentation, centered on Chinese oracle bone inscriptions. Extensive experiments show that models trained with InteChar on OracleCS achieve substantial improvements across various historical language understanding tasks, confirming the effectiveness of our approach and establishing a solid foundation for future research in ancient Chinese NLP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ„å»ºå¤ä»£è¯­è¨€æ¨¡å‹æ—¶é¢ä¸´çš„è¯­æ–™åŒ®ä¹å’Œæ—©æœŸæ–‡å­—ç¼ºä¹ç»Ÿä¸€ç¼–ç æ–¹æ¡ˆç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº† InteCharã€‚InteChar æ˜¯ä¸€ä¸ªç»Ÿä¸€ä¸”å¯æ‰©å±•çš„å­—ç¬¦åˆ—è¡¨ï¼Œæ—¨åœ¨å°†å°šæœªç¼–ç çš„ç”²éª¨æ–‡(oracle bone characters)ä¸ç¹ä½“åŠç°ä»£æ±‰è¯­è¿›è¡Œæ•´åˆï¼Œä»è€Œå®ç°å†å²æ–‡æœ¬çš„ä¸€è‡´æ•°å­—åŒ–è¡¨ç¤ºã€‚ä¸ºéªŒè¯å…¶æœ‰æ•ˆæ€§ï¼Œç ”ç©¶è€…æ„å»ºäº†ç”²éª¨æ–‡è¯­æ–™é›† Oracle Corpus Set (OracleCS)ï¼Œè¯¥è¯­æ–™é›†ç»“åˆäº†ä¸“å®¶æ ‡æ³¨ä¸å¤§è¯­è¨€æ¨¡å‹(LLM)è¾…åŠ©çš„æ•°æ®å¢å¼ºæŠ€æœ¯ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ OracleCS ä¸Šåˆ©ç”¨ InteChar è®­ç»ƒçš„æ¨¡å‹åœ¨å¤šé¡¹å†å²è¯­è¨€ç†è§£ä»»åŠ¡ä¸­è¡¨ç°å‡ºæ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚è¯¥ç ”ç©¶æœ‰æ•ˆè§£å†³äº†å¤ä»£æ–‡çŒ®æ•°å­—åŒ–å¤„ç†ä¸­çš„å­—ç¬¦è¡¨ç¤ºéš¾é¢˜ï¼Œä¸ºæœªæ¥å¤ä»£æ±‰è¯­è‡ªç„¶è¯­è¨€å¤„ç†(Ancient Chinese NLP)é¢†åŸŸçš„ç ”ç©¶å¥ å®šäº†åšå®åŸºç¡€ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15791v1",
      "published_date": "2025-08-12 11:53:57 UTC",
      "updated_date": "2025-08-12 11:53:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:39.651263+00:00"
    },
    {
      "arxiv_id": "2508.10050v1",
      "title": "Legal Zero-Days: A Novel Risk Vector for Advanced AI Systems",
      "title_zh": "æ³•å¾‹é›¶æ—¥æ¼æ´ï¼šå…ˆè¿›äººå·¥æ™ºèƒ½ç³»ç»Ÿçš„æ–°å‹é£é™©çŸ¢é‡",
      "authors": [
        "Greg Sadler",
        "Nathan Sherburn"
      ],
      "abstract": "We introduce the concept of \"Legal Zero-Days\" as a novel risk vector for advanced AI systems. Legal Zero-Days are previously undiscovered vulnerabilities in legal frameworks that, when exploited, can cause immediate and significant societal disruption without requiring litigation or other processes before impact. We present a risk model for identifying and evaluating these vulnerabilities, demonstrating their potential to bypass safeguards or impede government responses to AI incidents. Using the 2017 Australian dual citizenship crisis as a case study, we illustrate how seemingly minor legal oversights can lead to large-scale governance disruption. We develop a methodology for creating \"legal puzzles\" as evaluation instruments for assessing AI systems' capabilities to discover such vulnerabilities. Our findings suggest that while current AI models may not reliably find impactful Legal Zero-Days, future systems may develop this capability, presenting both risks and opportunities for improving legal robustness. This work contributes to the broader effort to identify and mitigate previously unrecognized risks from frontier AI systems.",
      "tldr_zh": "è¿™é¡¹ç ”ç©¶æå‡ºäº†Legal Zero-Daysçš„æ¦‚å¿µï¼Œå°†å…¶å®šä¹‰ä¸ºé«˜çº§AIç³»ç»Ÿçš„ä¸€ç§æ–°å‹é£é™©å‘é‡ã€‚Legal Zero-DaysæŒ‡çš„æ˜¯æ³•å¾‹æ¡†æ¶ä¸­å…ˆå‰æœªè¢«å‘ç°çš„æ¼æ´ï¼Œä¸€æ—¦è¢«åˆ©ç”¨ï¼Œå¯èƒ½åœ¨æ— éœ€è¯‰è®¼æˆ–æ­£å¼ç¨‹åºçš„æƒ…å†µä¸‹å¼•å‘å³æ—¶ä¸”é‡å¤§çš„ç¤¾ä¼šåŠ¨è¡ã€‚ç ”ç©¶å›¢é˜Ÿé€šè¿‡åˆ†æ2017å¹´æ¾³å¤§åˆ©äºšåŒé‡å›½ç±å±æœºæ¡ˆä¾‹ï¼Œå±•ç¤ºäº†ç»†å¾®æ³•å¾‹ç–å¿½å¦‚ä½•å¯¼è‡´å¤§è§„æ¨¡æ²»ç†ä¸­æ–­ï¼Œå¹¶æå‡ºäº†ä¸€ä¸ªç”¨äºè¯†åˆ«å’Œè¯„ä¼°è¿™äº›æ¼æ´çš„é£é™©æ¨¡å‹ã€‚æ­¤å¤–ï¼Œä½œè€…å¼€å‘äº†ä¸€ç§åŸºäºlegal puzzlesçš„æ–¹æ³•è®ºä½œä¸ºè¯„ä¼°å·¥å…·ï¼Œæ—¨åœ¨æµ‹è¯•AIç³»ç»Ÿå‘ç°æ­¤ç±»æ³•å¾‹è„†å¼±æ€§çš„èƒ½åŠ›ã€‚ç ”ç©¶ç»“æœæ˜¾ç¤ºï¼Œè™½ç„¶å½“å‰çš„AIæ¨¡å‹å°šæ— æ³•å¯é åœ°è¯†åˆ«å‡ºå…·æœ‰å½±å“åŠ›çš„Legal Zero-Daysï¼Œä½†æœªæ¥ç³»ç»Ÿå¯èƒ½å…·å¤‡æ­¤èƒ½åŠ›ï¼Œè¿™æ—¢å¸¦æ¥äº†é£é™©ï¼Œä¹Ÿä¸ºæå‡æ³•å¾‹ç³»ç»Ÿçš„ç¨³å¥æ€§æä¾›äº†æœºé‡ã€‚è¯¥å·¥ä½œä¸ºè¯†åˆ«å’Œç¼“è§£å‰æ²¿AIç³»ç»Ÿæ‰€å¼•å‘çš„æœªçŸ¥é£é™©æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 1 table, 1 figure. Introduces Legal Zero-Days as a novel AI risk vector and provides evaluation framework for measuring AI systems' ability to discover legal vulnerabilities",
      "pdf_url": "https://arxiv.org/pdf/2508.10050v1",
      "published_date": "2025-08-12 11:43:00 UTC",
      "updated_date": "2025-08-12 11:43:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:46.888770+00:00"
    },
    {
      "arxiv_id": "2508.13178v1",
      "title": "The Interpretability Analysis of the Model Can Bring Improvements to the Text-to-SQL Task",
      "title_zh": "æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æå¯¹ Text-to-SQL ä»»åŠ¡çš„æ”¹è¿›ç ”ç©¶",
      "authors": [
        "Cong Zhang"
      ],
      "abstract": "To elevate the foundational capabilities and generalization prowess of the text-to-SQL model in real-world applications, we integrate model interpretability analysis with execution-guided strategy for semantic parsing of WHERE clauses in SQL queries. Furthermore, we augment this approach with filtering adjustments, logical correlation refinements, and model fusion, culminating in the design of the CESQL model that facilitates conditional enhancement. Our model excels on the WikiSQL dataset, which is emblematic of single-table database query tasks, markedly boosting the accuracy of prediction outcomes. When predicting conditional values in WHERE clauses, we have not only minimized our dependence on data within the condition columns of tables but also circumvented the impact of manually labeled training data. Our hope is that this endeavor to enhance accuracy in processing basic database queries will offer fresh perspectives for research into handling complex queries and scenarios featuring irregular data in real-world database environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æ(model interpretability analysis)å¯¹Text-to-SQLä»»åŠ¡çš„æ”¹è¿›ä½œç”¨ï¼Œå¹¶æ®æ­¤è®¾è®¡äº†æ—¨åœ¨å®ç°æ¡ä»¶å¢å¼ºçš„CESQLæ¨¡å‹ã€‚CESQLå°†å¯è§£é‡Šæ€§åˆ†æä¸æ‰§è¡Œå¼•å¯¼ç­–ç•¥(execution-guided strategy)ç›¸ç»“åˆï¼Œé‡ç‚¹ä¼˜åŒ–äº†SQLæŸ¥è¯¢ä¸­WHEREå­å¥çš„è¯­ä¹‰è§£æã€‚è¯¥æ–¹æ³•è¿˜é€šè¿‡è¿‡æ»¤è°ƒæ•´(filtering adjustments)ã€é€»è¾‘å…³è”ä¼˜åŒ–(logical correlation refinements)å’Œæ¨¡å‹èåˆ(model fusion)è¿›ä¸€æ­¥å¢å¼ºäº†æ¨¡å‹æ€§èƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒCESQLåœ¨WikiSQLæ•°æ®é›†ä¸Šæ˜¾è‘—æå‡äº†é¢„æµ‹ç»“æœçš„å‡†ç¡®ç‡ï¼Œå°¤å…¶åœ¨é¢„æµ‹æ¡ä»¶å€¼æ—¶æœ‰æ•ˆå‡å°‘äº†å¯¹è¡¨åˆ—æ•°æ®åŠäººå·¥æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚è¯¥é¡¹å·¥ä½œä¸ä»…æå‡äº†å¤„ç†åŸºç¡€æ•°æ®åº“æŸ¥è¯¢çš„èƒ½åŠ›ï¼Œä¹Ÿä¸ºåœ¨çœŸå®å¤æ‚åœºæ™¯åŠä¸è§„åˆ™æ•°æ®ç¯å¢ƒä¸‹è¿›è¡Œè¯­ä¹‰è§£ææä¾›äº†æ–°çš„ç ”ç©¶è§†è§’ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13178v1",
      "published_date": "2025-08-12 11:24:16 UTC",
      "updated_date": "2025-08-12 11:24:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:18:13.051447+00:00"
    },
    {
      "arxiv_id": "2508.08855v2",
      "title": "BiasGym: Fantastic LLM Biases and How to Find (and Remove) Them",
      "title_zh": "BiasGymï¼šå¤§è¯­è¨€æ¨¡å‹ä¸­çš„ç§ç§åè§åŠå…¶å‘ç°ï¼ˆä¸æ¶ˆé™¤ï¼‰æ–¹æ³•",
      "authors": [
        "Sekh Mainul Islam",
        "Nadav Borenstein",
        "Siddhesh Milind Pawar",
        "Haeun Yu",
        "Arnav Arora",
        "Isabelle Augenstein"
      ],
      "abstract": "Understanding biases and stereotypes encoded in the weights of Large Language Models (LLMs) is crucial for developing effective mitigation strategies. Biased behaviour is often subtle and non-trivial to isolate, even when deliberately elicited, making systematic analysis and debiasing particularly challenging. To address this, we introduce BiasGym, a simple, cost-effective, and generalizable framework for reliably injecting, analyzing, and mitigating conceptual associations within LLMs. BiasGym consists of two components: BiasInject, which injects specific biases into the model via token-based fine-tuning while keeping the model frozen, and BiasScope, which leverages these injected signals to identify and steer the components responsible for biased behavior. Our method enables consistent bias elicitation for mechanistic analysis, supports targeted debiasing without degrading performance on downstream tasks, and generalizes to biases unseen during token-based fine-tuning. We demonstrate the effectiveness of BiasGym in reducing real-world stereotypes (e.g., people from Italy being `reckless drivers') and in probing fictional associations (e.g., people from a fictional country having `blue skin'), showing its utility for both safety interventions and interpretability research.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† BiasGymï¼Œè¿™æ˜¯ä¸€ä¸ªç®€å•ã€ä½æˆæœ¬ä¸”å…·æœ‰é€šç”¨æ€§çš„æ¡†æ¶ï¼Œæ—¨åœ¨å¯é åœ°æ³¨å…¥ã€åˆ†æå’Œç¼“è§£å¤§è¯­è¨€æ¨¡å‹ (Large Language Models, LLMs) ä¸­çš„æ¦‚å¿µå…³è”ã€‚è¯¥æ¡†æ¶åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒç»„ä»¶ï¼šBiasInject é€šè¿‡åœ¨æ¨¡å‹å†»ç»“çŠ¶æ€ä¸‹è¿›è¡ŒåŸºäºæ ‡è®° (Token-based) çš„å¾®è°ƒæ¥æ³¨å…¥ç‰¹å®šåè§ï¼Œè€Œ BiasScope åˆ™åˆ©ç”¨è¿™äº›æ³¨å…¥ä¿¡å·æ¥è¯†åˆ«å¹¶å¼•å¯¼è´Ÿè´£åè§è¡Œä¸ºçš„æ¨¡å‹å†…éƒ¨ç»„ä»¶ã€‚è¯¥æ–¹æ³•å®ç°äº†ç”¨äºæœºåˆ¶åˆ†æ (Mechanistic Analysis) çš„ä¸€è‡´æ€§åè§è¯±å‘ï¼Œå¹¶æ”¯æŒåœ¨ä¸æŸå®³ä¸‹æ¸¸ä»»åŠ¡æ€§èƒ½çš„æƒ…å†µä¸‹è¿›è¡Œé’ˆå¯¹æ€§å»å (Debiasing)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒBiasGym åœ¨å‡å°‘ç°å®ä¸–ç•Œåˆ»æ¿å°è±¡ï¼ˆå¦‚ç‰¹å®šå›½ç±çš„äººæ˜¯â€œé²è½é©¾é©¶è€…â€ï¼‰ä»¥åŠæ¢æµ‹è™šæ„å…³è”æ–¹é¢å‡å…·æœ‰æ˜¾è‘—æ•ˆæœã€‚BiasGym èƒ½å¤Ÿæ¨å¹¿åˆ°å¾®è°ƒè¿‡ç¨‹ä¸­æœªè§çš„åè§ï¼Œä¸ºå®‰å…¨å¹²é¢„å’Œæ¨¡å‹çš„å¯è§£é‡Šæ€§ç ”ç©¶ (Interpretability Research) æä¾›äº†é‡è¦å·¥å…·ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Under review",
      "pdf_url": "https://arxiv.org/pdf/2508.08855v2",
      "published_date": "2025-08-12 11:23:44 UTC",
      "updated_date": "2025-08-14 17:57:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:50.692213+00:00"
    },
    {
      "arxiv_id": "2508.14075v2",
      "title": "Explainable Graph Spectral Clustering For GloVe-like Text Embeddings",
      "title_zh": "ç±» GloVe æ–‡æœ¬åµŒå…¥çš„å¯è§£é‡Šå›¾è°±èšç±»",
      "authors": [
        "MieczysÅ‚aw A. KÅ‚opotek",
        "SÅ‚awomir T. WierzchoÅ„",
        "BartÅ‚omiej Starosta",
        "Piotr Borkowski",
        "Dariusz Czerski",
        "Eryk Laskowski"
      ],
      "abstract": "In a previous paper, we proposed an introduction to the explainability of Graph Spectral Clustering results for textual documents, given that document similarity is computed as cosine similarity in term vector space.\n  In this paper, we generalize this idea by considering other embeddings of documents, in particular, based on the GloVe embedding idea.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†é’ˆå¯¹æ–‡æœ¬æ–‡æ¡£çš„å›¾è°±èšç±»(Graph Spectral Clustering)ç»“æœçš„å¯è§£é‡Šæ€§é—®é¢˜ï¼Œæ—¨åœ¨æé«˜æ–‡æœ¬æŒ–æ˜ä»»åŠ¡çš„é€æ˜åº¦ã€‚åœ¨å‰æœŸç ”ç©¶ä¸­ï¼Œä½œè€…å·²ç»åŸºäºè¯é¡¹å‘é‡ç©ºé—´ä¸­çš„ä½™å¼¦ç›¸ä¼¼åº¦(cosine similarity)æå‡ºäº†ä¸€å¥—è§£é‡Šæ¡†æ¶ã€‚æœ¬æ–‡é€šè¿‡è€ƒè™‘åŒ…æ‹¬GloVeåœ¨å†…çš„å…¶ä»–æ–‡æ¡£åµŒå…¥(embeddings)æŠ€æœ¯ï¼Œå¯¹è¯¥è§£é‡Šæ€§æ–¹æ³•è¿›è¡Œäº†æ³›åŒ–ä¸æ¨å¹¿ã€‚è¯¥ç ”ç©¶ä¸ä»…æ‰©å±•äº†å¯è§£é‡Šèšç±»çš„åº”ç”¨èŒƒå›´ï¼Œè¿˜ä¸ºå¤„ç†é«˜ç»´å¤æ‚æ–‡æœ¬æ•°æ®æä¾›äº†æ›´ä¸ºç›´è§‚çš„åˆ†ææ‰‹æ®µã€‚é€šè¿‡è¿™ç§é€šç”¨çš„æ–¹æ³•è®ºï¼Œç ”ç©¶è€…èƒ½å¤Ÿæ›´æ¸…æ™°åœ°ç†è§£å›¾è°±èšç±»åœ¨ä¸åŒè¯­ä¹‰ç©ºé—´ä¸‹çš„åˆ†ç±»é€»è¾‘å’Œç»“æœã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "47 pages, 19 tables, 11 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.14075v2",
      "published_date": "2025-08-12 11:20:27 UTC",
      "updated_date": "2025-12-22 06:08:18 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:17:59.264802+00:00"
    },
    {
      "arxiv_id": "2508.08846v3",
      "title": "Steering Towards Fairness: Mitigating Political Bias in LLMs",
      "title_zh": "è¿ˆå‘å…¬å¹³ï¼šç¼“è§£å¤§è¯­è¨€æ¨¡å‹ä¸­çš„æ”¿æ²»åè§",
      "authors": [
        "Afrozah Nadeem",
        "Mark Dras",
        "Usman Naseem"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have enabled their widespread use across diverse real-world applications. However, concerns remain about their tendency to encode and reproduce ideological biases along political and economic dimensions. In this paper, we employ a framework for probing and mitigating such biases in decoder-based LLMs through analysis of internal model representations. Grounded in the Political Compass Test (PCT), this method uses contrastive pairs to extract and compare hidden layer activations from models like Mistral and DeepSeek. We introduce a comprehensive activation extraction pipeline capable of layer-wise analysis across multiple ideological axes, revealing meaningful disparities linked to political framing. Our results show that decoder LLMs systematically encode representational bias across layers, which can be leveraged for effective steering vector-based mitigation. This work provides new insights into how political bias is encoded in LLMs and offers a principled approach to debiasing beyond surface-level output interventions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨æ”¿æ²»ä¸ç»æµç»´åº¦ä¸Šç¼–ç å¹¶å¤ç°æ„è¯†å½¢æ€åè§çš„é—®é¢˜ã€‚ä½œè€…åŸºäºæ”¿æ²»ç½—ç›˜æµ‹è¯•ï¼ˆPolitical Compass Test, PCTï¼‰æ¡†æ¶ï¼Œé€šè¿‡åˆ†æ Mistral å’Œ DeepSeek ç­‰è§£ç å™¨æ¶æ„ï¼ˆdecoder-basedï¼‰æ¨¡å‹çš„å†…éƒ¨è¡¨å¾ï¼Œæå‡ºäº†ä¸€ç§æ¢æµ‹ä¸å‡è½»åè§çš„æ–¹æ³•ã€‚ç ”ç©¶å¼•å…¥äº†ä¸€å¥—æ¿€æ´»æå–æµæ°´çº¿ï¼ˆactivation extraction pipelineï¼‰ï¼Œæ”¯æŒå¯¹å¤šä¸ªæ„è¯†å½¢æ€è½´è¿›è¡Œé€å±‚åˆ†æï¼Œä»è€Œæ­ç¤ºæ¨¡å‹å†…éƒ¨ä¸æ”¿æ²»ç«‹åœºç›¸å…³çš„è¡¨å¾å·®å¼‚ã€‚ç ”ç©¶å‘ç°ï¼ŒLLMs çš„å†…éƒ¨å±‚çº§ä¸­ç³»ç»Ÿæ€§åœ°å­˜åœ¨è¡¨å¾åè§ï¼Œè€Œåˆ©ç”¨å¼•å¯¼å‘é‡ï¼ˆsteering vector-basedï¼‰å¯ä»¥æœ‰æ•ˆåœ°å®ç°åè§ç¼“è§£ã€‚è¿™é¡¹å·¥ä½œä¸ºç†è§£æ”¿æ²»åè§åœ¨æ¨¡å‹ä¸­çš„ç¼–ç æœºåˆ¶æä¾›äº†æ–°è§è§£ï¼Œå¹¶å±•ç¤ºäº†ä¸€ç§ä¼˜äºä¼ ç»Ÿè¡¨å±‚è¾“å‡ºå¹²é¢„çš„å»åè§æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at CASE@RANLP2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08846v3",
      "published_date": "2025-08-12 11:09:03 UTC",
      "updated_date": "2025-09-20 07:24:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:18:34.093937+00:00"
    },
    {
      "arxiv_id": "2508.08837v2",
      "title": "The Roots of International Perceptions: Simulating US Attitude Changes Towards China with LLM Agents",
      "title_zh": "å›½é™…è®¤çŸ¥çš„æ ¹æºï¼šåˆ©ç”¨LLMæ™ºèƒ½ä½“æ¨¡æ‹Ÿç¾å›½å¯¹åæ€åº¦çš„æ¼”å˜",
      "authors": [
        "Nicholas Sukiennik",
        "Yichuan Xu",
        "Yuqing Kan",
        "Jinghua Piao",
        "Yuwei Yan",
        "Chen Gao",
        "Yong Li"
      ],
      "abstract": "The rise of LLMs poses new possibilities in modeling opinion evolution, a long-standing task in simulation, by leveraging advanced reasoning abilities to recreate complex, large-scale human cognitive trends. While most prior works focus on opinion evolution surrounding specific isolated events or the views within a country, ours is the first to model the large-scale attitude evolution of a population representing an entire country towards another -- US citizens' perspectives towards China. To tackle the challenges of this broad scenario, we propose a framework that integrates media data collection, user profile creation, and cognitive architecture for opinion updates to successfully reproduce the real trend of US attitudes towards China over a 20-year period from 2005 to today. We also leverage LLMs' capabilities to introduce debiased media exposure, extracting neutral events from typically subjective news contents, to uncover the roots of polarized opinion formation, as well as a devils advocate agent to help explain the rare reversal from negative to positive attitudes towards China, corresponding with changes in the way Americans obtain information about the country. The simulation results, beyond validating our framework architecture, also reveal the impact of biased framing and selection bias in shaping attitudes. Overall, our work contributes to a new paradigm for LLM-based modeling of cognitive behaviors in a large-scale, long-term, cross-border social context, providing insights into the formation of international biases and offering valuable implications for media consumers to better understand the factors shaping their perspectives, and ultimately contributing to the larger social need for bias reduction and cross-cultural tolerance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å›½é™…è®¤çŸ¥çš„æ ¹æºï¼Œæå‡ºäº†é¦–ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ (LLM Agents) æ¨¡æ‹Ÿä¸€å›½å¯¹å¦ä¸€å›½ï¼ˆç¾å›½å¯¹ä¸­å›½ï¼‰å¤§è§„æ¨¡æ€åº¦æ¼”å˜çš„ç ”ç©¶æ¡†æ¶ã€‚ä¸ºäº†åº”å¯¹å¤æ‚çš„è·¨å›½åœºæ™¯ï¼Œè¯¥æ¡†æ¶æ•´åˆäº†åª’ä½“æ•°æ®é‡‡é›†ã€ç”¨æˆ·ç”»åƒæ„å»ºåŠç”¨äºè§‚ç‚¹æ›´æ–°çš„è®¤çŸ¥æ¶æ„ (Cognitive Architecture)ï¼ŒæˆåŠŸé‡ç°äº†2005å¹´è‡³ä»Š20å¹´é—´ç¾å›½å¯¹åæ€åº¦çš„æ¼”å˜è¶‹åŠ¿ã€‚ç ”ç©¶åˆ©ç”¨ LLM çš„å»åè§åª’ä½“æš´éœ² (Debiased Media Exposure) æŠ€æœ¯ä»ä¸»è§‚æ–°é—»ä¸­æå–ä¸­ç«‹äº‹ä»¶ï¼Œå¹¶å¼•å…¥æ¶é­”ä»£è¨€äººæ™ºèƒ½ä½“ (Devil's Advocate Agent) æ¥è§£é‡Šç‰¹å®šæ—¶æœŸæ€åº¦è½¬å˜èƒŒåçš„ä¿¡æ¯è·å–æ¸ é“å˜åŒ–ã€‚ä»¿çœŸç»“æœæ­ç¤ºäº†åè§æ€§æ¡†æ¶ (Biased Framing) å’Œé€‰æ‹©æ€§åå·® (Selection Bias) åœ¨å¡‘é€ æ€åº¦ä¸­çš„å…³é”®ä½œç”¨ã€‚è¯¥å·¥ä½œä¸ºåœ¨å¤§è§„æ¨¡ã€é•¿å‘¨æœŸã€è·¨å¢ƒç¤¾ä¼šèƒŒæ™¯ä¸‹è¿›è¡ŒåŸºäº LLM çš„è®¤çŸ¥è¡Œä¸ºå»ºæ¨¡æä¾›äº†æ–°èŒƒå¼ï¼Œä¸ºç†è§£å›½é™…åè§çš„å½¢æˆåŠä¿ƒè¿›è·¨æ–‡åŒ–åŒ…å®¹æä¾›äº†é‡è¦è§è§£ã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Submitted to AAAI Social Impact 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.08837v2",
      "published_date": "2025-08-12 10:54:08 UTC",
      "updated_date": "2025-08-15 10:48:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:18:19.338106+00:00"
    },
    {
      "arxiv_id": "2508.08836v1",
      "title": "EditMF: Drawing an Invisible Fingerprint for Your Large Language Models",
      "title_zh": "EditMFï¼šä¸ºå¤§è¯­è¨€æ¨¡å‹ç»˜åˆ¶éšå½¢æŒ‡çº¹",
      "authors": [
        "Jiaxuan Wu",
        "Yinghan Zhou",
        "Wanli Peng",
        "Yiming Xue",
        "Juan Wen",
        "Ping Zhong"
      ],
      "abstract": "Training large language models (LLMs) is resource-intensive and expensive, making protecting intellectual property (IP) for LLMs crucial. Recently, embedding fingerprints into LLMs has emerged as a prevalent method for establishing model ownership. However, existing back-door-based methods suffer from limited stealth and efficiency. To simultaneously address these issues, we propose EditMF, a training-free fingerprinting paradigm that achieves highly imperceptible fingerprint embedding with minimal computational overhead. Ownership bits are mapped to compact, semantically coherent triples drawn from an encrypted artificial knowledge base (e.g., virtual author-novel-protagonist facts). Causal tracing localizes the minimal set of layers influencing each triple, and a zero-space update injects the fingerprint without perturbing unrelated knowledge. Verification requires only a single black-box query and succeeds when the model returns the exact pre-embedded protagonist. Empirical results on LLaMA and Qwen families show that EditMF combines high imperceptibility with negligible model's performance loss, while delivering robustness far beyond LoRA-based fingerprinting and approaching that of SFT embeddings. Extensive experiments demonstrate that EditMF is an effective and low-overhead solution for secure LLM ownership verification.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† EditMFï¼Œè¿™æ˜¯ä¸€ç§æ— éœ€è®­ç»ƒ(training-free)çš„æŒ‡çº¹åµŒå…¥èŒƒå¼ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)çŸ¥è¯†äº§æƒ(IP)ä¿æŠ¤ä¸­çš„éšè”½æ€§å’Œæ•ˆç‡é—®é¢˜ã€‚è¯¥æ–¹æ³•å°†æ‰€æœ‰æƒä½æ˜ å°„åˆ°åŠ å¯†äººå·¥çŸ¥è¯†åº“ä¸­è¯­ä¹‰è¿è´¯çš„ä¸‰å…ƒç»„(triples)ï¼Œå¹¶é€šè¿‡å› æœè¿½è¸ª(Causal tracing)ç²¾ç¡®å®šä½å½±å“è¿™äº›ä¸‰å…ƒç»„çš„æœ€å°å±‚é›†ã€‚åˆ©ç”¨é›¶ç©ºé—´æ›´æ–°(zero-space update)æŠ€æœ¯ï¼ŒEditMF èƒ½å¤Ÿåœ¨ä¸å¹²æ‰°æ— å…³çŸ¥è¯†çš„æƒ…å†µä¸‹æ³¨å…¥æŒ‡çº¹ï¼Œä¸”éªŒè¯è¿‡ç¨‹ä»…éœ€å•æ¬¡é»‘ç›’æŸ¥è¯¢(black-box query)ã€‚åœ¨ LLaMA å’Œ Qwen ç³»åˆ—æ¨¡å‹ä¸Šçš„å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ¡ˆåœ¨ä¿æŒé«˜åº¦éšè”½æ€§çš„åŒæ—¶ï¼Œå‡ ä¹ä¸é€ æˆæ¨¡å‹æ€§èƒ½æŸå¤±ã€‚ç›¸æ¯”äºåŸºäº LoRA çš„æŒ‡çº¹è¯†åˆ«ï¼ŒEditMF å±•ç°å‡ºäº†æé«˜çš„é²æ£’æ€§ï¼Œä¸º LLM æ‰€æœ‰æƒéªŒè¯æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ä½å¼€é”€çš„å®‰å…¨è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08836v1",
      "published_date": "2025-08-12 10:52:48 UTC",
      "updated_date": "2025-08-12 10:52:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:18:12.055300+00:00"
    },
    {
      "arxiv_id": "2508.08833v3",
      "title": "An Investigation of Robustness of LLMs in Mathematical Reasoning: Benchmarking with Mathematically-Equivalent Transformation of Advanced Mathematical Problems",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹æ•°å­¦æ¨ç†é²æ£’æ€§ç ”ç©¶ï¼šåŸºäºé«˜ç­‰æ•°å­¦é—®é¢˜ç­‰ä»·å˜æ¢çš„åŸºå‡†æµ‹è¯•",
      "authors": [
        "Yuren Hao",
        "Xiang Wan",
        "ChengXiang Zhai"
      ],
      "abstract": "In this paper, we introduce a systematic framework beyond conventional method to assess LLMs' mathematical-reasoning robustness by stress-testing them on advanced math problems that are mathematically equivalent but with linguistic and parametric variation. These transformations allow us to measure the sensitivity of LLMs to non-mathematical perturbations, thereby enabling a more accurate evaluation of their mathematical reasoning capabilities. Using this new evaluation methodology, we created PutnamGAP, a new benchmark dataset with multiple mathematically-equivalent variations of competition-level math problems. With the new dataset, we evaluate multiple families of representative LLMs and examine their robustness. Across 18 commercial and open-source models we observe sharp performance degradation on the variants. OpenAI's flagship reasoning model, O3, scores 51.5% on the originals but drops by 4.7 percentage points on surface-renaming variants, and by 12.9 percentage points on parametric variants, while smaller models fare far worse. Overall, the results show that the proposed new evaluation methodology is effective for deepening our understanding of the robustness of LLMs and generating new insights for further improving their mathematical reasoning capabilities.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªè¶…è¶Šä¼ ç»Ÿæ–¹æ³•çš„ç³»ç»Ÿæ€§æ¡†æ¶ï¼Œæ—¨åœ¨é€šè¿‡æ•°å­¦ç­‰ä»·ä½†å…·æœ‰è¯­è¨€å’Œå‚æ•°å˜åŒ–çš„è¿›é˜¶æ•°å­¦é—®é¢˜å‹åŠ›æµ‹è¯•ï¼Œè¯„ä¼°å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨æ•°å­¦æ¨ç†æ–¹é¢çš„ç¨³å¥æ€§(Robustness)ã€‚è¿™äº›å˜æ¢èƒ½å¤Ÿæµ‹é‡ LLMs å¯¹éæ•°å­¦æ‰°åŠ¨(Non-mathematical perturbations)çš„æ•æ„Ÿæ€§ï¼Œä»è€Œæ›´å‡†ç¡®åœ°è¯„ä»·å…¶çœŸå®çš„æ•°å­¦æ¨ç†èƒ½åŠ›ã€‚åŸºäºæ­¤æ–¹æ³•ï¼Œç ”ç©¶è€…æ„å»ºäº†åä¸º PutnamGAP çš„å…¨æ–°åŸºå‡†æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç«èµ›çº§æ•°å­¦é—®é¢˜çš„å¤šç§ç­‰ä»·å˜ä½“ã€‚åœ¨å¯¹ 18 ç§ä»£è¡¨æ€§æ¨¡å‹ï¼ˆåŒ…æ‹¬å•†ä¸šå’Œå¼€æºæ¨¡å‹ï¼‰çš„è¯„ä¼°ä¸­ï¼Œç ”ç©¶è§‚å¯Ÿåˆ°æ¨¡å‹åœ¨é¢å¯¹å˜ä½“æ—¶è¡¨ç°å‡ºæ˜æ˜¾çš„æ€§èƒ½ä¸‹é™ã€‚ä¾‹å¦‚ OpenAI çš„æ——èˆ°æ¨ç†æ¨¡å‹ O3 åœ¨åŸå§‹é¢˜ç›®ä¸Šå¾—åˆ†ä¸º 51.5%ï¼Œä½†åœ¨è¡¨é¢æ›´åå˜ä½“(Surface-renaming variants)å’Œå‚æ•°å˜ä½“(Parametric variants)ä¸Šåˆ†åˆ«ä¸‹é™äº† 4.7 å’Œ 12.9 ä¸ªç™¾åˆ†ç‚¹ï¼Œè€Œå°å‹æ¨¡å‹çš„é€€åŒ–æƒ…å†µæ›´ä¸ºä¸¥é‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥è¯„ä¼°æ–¹æ³•èƒ½æœ‰æ•ˆæ·±åŒ–å¯¹ LLMs ç¨³å¥æ€§çš„ç†è§£ï¼Œå¹¶ä¸ºè¿›ä¸€æ­¥æå‡å…¶æ•°å­¦æ¨ç†èƒ½åŠ›æä¾›æ–°çš„è§è§£ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "34 pages, 9 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08833v3",
      "published_date": "2025-08-12 10:40:33 UTC",
      "updated_date": "2025-12-04 08:10:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:18:53.284066+00:00"
    },
    {
      "arxiv_id": "2508.08830v1",
      "title": "Silicon Minds versus Human Hearts: The Wisdom of Crowds Beats the Wisdom of AI in Emotion Recognition",
      "title_zh": "ç¡…åŸºæ™ºæ…§ä¸äººç±»å¿ƒçµï¼šç¾¤ä½“æ™ºæ…§åœ¨æƒ…ç»ªè¯†åˆ«ä¸­èƒœè¿‡ AI æ™ºæ…§",
      "authors": [
        "Mustafa Akben",
        "Vinayaka Gude",
        "Haya Ajjan"
      ],
      "abstract": "The ability to discern subtle emotional cues is fundamental to human social intelligence. As artificial intelligence (AI) becomes increasingly common, AI's ability to recognize and respond to human emotions is crucial for effective human-AI interactions. In particular, whether such systems can match or surpass human experts remains to be seen. However, the emotional intelligence of AI, particularly multimodal large language models (MLLMs), remains largely unexplored. This study evaluates the emotion recognition abilities of MLLMs using the Reading the Mind in the Eyes Test (RMET) and its multiracial counterpart (MRMET), and compares their performance against human participants. Results show that, on average, MLLMs outperform humans in accurately identifying emotions across both tests. This trend persists even when comparing performance across low, medium, and expert-level performing groups. Yet when we aggregate independent human decisions to simulate collective intelligence, human groups significantly surpass the performance of aggregated MLLM predictions, highlighting the wisdom of the crowd. Moreover, a collaborative approach (augmented intelligence) that combines human and MLLM predictions achieves greater accuracy than either humans or MLLMs alone. These results suggest that while MLLMs exhibit strong emotion recognition at the individual level, the collective intelligence of humans and the synergistic potential of human-AI collaboration offer the most promising path toward effective emotional AI. We discuss the implications of these findings for the development of emotionally intelligent AI systems and future research directions.",
      "tldr_zh": "è¯¥ç ”ç©¶åˆ©ç”¨Reading the Mind in the Eyes Test (RMET)åŠå…¶å¤šç§æ—ç‰ˆæœ¬(MRMET)ï¼Œè¯„ä¼°äº†å¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)åœ¨æƒ…ç»ªè¯†åˆ«æ–¹é¢çš„èƒ½åŠ›ï¼Œå¹¶å°†å…¶ä¸äººç±»è¡¨ç°è¿›è¡Œå¯¹æ¯”ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ä¸ªä½“å±‚é¢ä¸Šï¼ŒMLLMsåœ¨ä¸¤é¡¹æµ‹è¯•ä¸­è¯†åˆ«æƒ…ç»ªçš„å‡†ç¡®ç‡å¹³å‡ä¼˜äºäººç±»ä¸ªä½“ï¼Œä¸”åœ¨ä¸åŒæ°´å¹³çš„åˆ†ç»„æ¯”è¾ƒä¸­å‡ä¿æŒæ­¤è¶‹åŠ¿ã€‚ç„¶è€Œï¼Œå½“é€šè¿‡èšåˆç‹¬ç«‹å†³ç­–æ¥æ¨¡æ‹Ÿé›†ä½“æ™ºæ…§(collective intelligence)æ—¶ï¼Œäººç±»ç¾¤ä½“çš„è¡¨ç°æ˜¾è‘—è¶…è¿‡äº†èšåˆçš„MLLMé¢„æµ‹ï¼Œè¯æ˜äº†ä¼—äººçš„æ™ºæ…§(wisdom of the crowd)åœ¨æƒ…ç»ªè¯†åˆ«ä¸­çš„ä¼˜åŠ¿ã€‚æ­¤å¤–ï¼Œç ”ç©¶å‘ç°ç»“åˆäººç±»ä¸MLLMé¢„æµ‹çš„åä½œæ–¹æ³•(augmented intelligence)èƒ½å¤Ÿå®ç°æ¯”ä¸¤è€…å•ç‹¬æ“ä½œæ›´é«˜çš„å‡†ç¡®æ€§ã€‚è¿™é¡¹ç ”ç©¶è¡¨æ˜ï¼Œå°½ç®¡ä¸ªä½“æ¨¡å‹è¡¨ç°å¼ºåŠ²ï¼Œä½†äººç±»çš„é›†ä½“æ™ºæ…§ä»¥åŠäººæœºåä½œçš„ååŒæ½œåŠ›ä¸ºå¼€å‘æœ‰æ•ˆçš„æƒ…æ„ŸAI (emotional AI)æä¾›äº†æœ€æœ‰å‰æ™¯çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08830v1",
      "published_date": "2025-08-12 10:37:37 UTC",
      "updated_date": "2025-08-12 10:37:37 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:18:55.483800+00:00"
    },
    {
      "arxiv_id": "2508.08826v3",
      "title": "Geometry-Aware Global Feature Aggregation for Real-Time Indirect Illumination",
      "title_zh": "é¢å‘å®æ—¶é—´æ¥å…‰ç…§çš„å‡ ä½•æ„ŸçŸ¥å…¨å±€ç‰¹å¾èšåˆ",
      "authors": [
        "Meng Gai",
        "Guoping Wang",
        "Sheng Li"
      ],
      "abstract": "Real-time rendering with global illumination is crucial to afford the user realistic experience in virtual environments. We present a learning-based estimator to predict diffuse indirect illumination in screen space, which then is combined with direct illumination to synthesize globally-illuminated high dynamic range (HDR) results. Our approach tackles the challenges of capturing long-range/long-distance indirect illumination when employing neural networks and is generalized to handle complex lighting and scenarios.\n  From the neural network thinking of the solver to the rendering equation, we present a novel network architecture to predict indirect illumination. Our network is equipped with a modified attention mechanism that aggregates global information guided by spacial geometry features, as well as a monochromatic design that encodes each color channel individually.\n  We conducted extensive evaluations, and the experimental results demonstrate our superiority over previous learning-based techniques. Our approach excels at handling complex lighting such as varying-colored lighting and environment lighting. It can successfully capture distant indirect illumination and simulates the interreflections between textured surfaces well (i.e., color bleeding effects); it can also effectively handle new scenes that are not present in the training dataset.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå­¦ä¹ çš„ä¼°è®¡å™¨ï¼Œæ—¨åœ¨å±å¹•ç©ºé—´(screen space)é¢„æµ‹æ¼«åå°„é—´æ¥ç…§æ˜(indirect illumination)ï¼Œå¹¶å°†å…¶ä¸ç›´æ¥ç…§æ˜ç»“åˆä»¥åˆæˆé«˜è´¨é‡çš„HDRæ¸²æŸ“ç»“æœã€‚é’ˆå¯¹ç¥ç»ç½‘ç»œåœ¨æ•è·é•¿è·ç¦»é—´æ¥ç…§æ˜æ–¹é¢çš„æŒ‘æˆ˜ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†ä¸€ç§æ–°å‹ç½‘ç»œæ¶æ„ï¼Œå¼•å…¥äº†å—ç©ºé—´å‡ ä½•ç‰¹å¾å¼•å¯¼çš„æ”¹è¿›æ³¨æ„åŠ›æœºåˆ¶(attention mechanism)æ¥èšåˆå…¨å±€ä¿¡æ¯ï¼Œå¹¶é‡‡ç”¨å•è‰²è®¾è®¡(monochromatic design)å¯¹å„é¢œè‰²é€šé“è¿›è¡Œç‹¬ç«‹ç¼–ç ã€‚å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å¤„ç†å¤æ‚å…‰ç…§ã€ç¯å¢ƒå…‰åŠçº¹ç†è¡¨é¢é—´çš„è‰²æº¢æ•ˆåº”(color bleeding)æ–¹é¢å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚ç›¸æ¯”äºå…ˆå‰çš„å­¦ä¹ æŠ€æœ¯ï¼Œè¯¥æ–¹æ¡ˆä¸ä»…èƒ½æ›´ç²¾å‡†åœ°æ¨¡æ‹Ÿè¿œè·ç¦»é—´æ¥å…‰ç…§ï¼Œè¿˜å±•ç°å‡ºäº†æå¼ºçš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†è®­ç»ƒé›†ä¸­æœªå‡ºç°çš„å…¨æ–°åœºæ™¯ã€‚",
      "categories": [
        "cs.GR",
        "cs.AI"
      ],
      "primary_category": "cs.GR",
      "comment": "10 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.08826v3",
      "published_date": "2025-08-12 10:36:03 UTC",
      "updated_date": "2025-11-05 15:51:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:05.488918+00:00"
    },
    {
      "arxiv_id": "2508.08825v1",
      "title": "Wavelet Mixture of Experts for Time Series Forecasting",
      "title_zh": "ç”¨äºæ—¶é—´åºåˆ—é¢„æµ‹çš„å°æ³¢æ··åˆä¸“å®¶æ¨¡å‹",
      "authors": [
        "Zheng Zhou",
        "Yu-Jie Xiong",
        "Jia-Chen Zhang",
        "Chun-Ming Xia",
        "Xi-Jiong Xie"
      ],
      "abstract": "The field of time series forecasting is rapidly advancing, with recent large-scale Transformers and lightweight Multilayer Perceptron (MLP) models showing strong predictive performance. However, conventional Transformer models are often hindered by their large number of parameters and their limited ability to capture non-stationary features in data through smoothing. Similarly, MLP models struggle to manage multi-channel dependencies effectively. To address these limitations, we propose a novel, lightweight time series prediction model, WaveTS-B. This model combines wavelet transforms with MLP to capture both periodic and non-stationary characteristics of data in the wavelet domain. Building on this foundation, we propose a channel clustering strategy that incorporates a Mixture of Experts (MoE) framework, utilizing a gating mechanism and expert network to handle multi-channel dependencies efficiently. We propose WaveTS-M, an advanced model tailored for multi-channel time series prediction. Empirical evaluation across eight real-world time series datasets demonstrates that our WaveTS series models achieve state-of-the-art (SOTA) performance with significantly fewer parameters. Notably, WaveTS-M shows substantial improvements on multi-channel datasets, highlighting its effectiveness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿ Transformers æ¨¡å‹å‚æ•°å†—ä½™ä¸”éš¾ä»¥æ•æ‰éå¹³ç¨³ç‰¹å¾ï¼Œä»¥åŠ MLP æ¨¡å‹å¤„ç†å¤šé€šé“ä¾èµ–å…³ç³»ï¼ˆmulti-channel dependenciesï¼‰èƒ½åŠ›ä¸è¶³çš„é—®é¢˜ï¼Œæå‡ºäº†è½»é‡çº§é¢„æµ‹æ¨¡å‹ WaveTS-Bã€‚è¯¥æ¨¡å‹ç»“åˆäº†å°æ³¢å˜æ¢ï¼ˆwavelet transformsï¼‰ä¸ MLPï¼Œæ—¨åœ¨å°æ³¢åŸŸå†…æœ‰æ•ˆæ•è·æ•°æ®çš„å‘¨æœŸæ€§å’Œéå¹³ç¨³ç‰¹æ€§ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼•å…¥æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆMixture of Experts, MoEï¼‰æ¶æ„ä¸é€šé“èšç±»ç­–ç•¥ï¼Œå¼€å‘å‡ºè¿›é˜¶æ¨¡å‹ WaveTS-Mï¼Œåˆ©ç”¨é—¨æ§æœºåˆ¶ï¼ˆgating mechanismï¼‰å’Œä¸“å®¶ç½‘ç»œï¼ˆexpert networkï¼‰é«˜æ•ˆè§£å†³å¤šé€šé“ä¾èµ–é—®é¢˜ã€‚åœ¨å…«ä¸ªçœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼ŒWaveTS ç³»åˆ—æ¨¡å‹åœ¨å‚æ•°é‡å¤§å¹…å‡å°‘çš„æƒ…å†µä¸‹å®ç°äº†æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„é¢„æµ‹æ€§èƒ½ã€‚ç‰¹åˆ«æ˜¯ WaveTS-M åœ¨å¤šé€šé“æ•°æ®é›†ä¸Šçš„æ˜¾è‘—æ”¹è¿›ï¼ŒéªŒè¯äº†å…¶åœ¨å¤„ç†å¤æ‚æ—¶é—´åºåˆ—é¢„æµ‹ä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ä¸ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08825v1",
      "published_date": "2025-08-12 10:32:51 UTC",
      "updated_date": "2025-08-12 10:32:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:21.591727+00:00"
    },
    {
      "arxiv_id": "2508.08822v1",
      "title": "OISMA: On-the-fly In-memory Stochastic Multiplication Architecture for Matrix-Multiplication Workloads",
      "title_zh": "OISMAï¼šé¢å‘çŸ©é˜µä¹˜æ³•å·¥ä½œè´Ÿè½½çš„å®æ—¶å­˜å†…éšæœºä¹˜æ³•æ¶æ„",
      "authors": [
        "Shady Agwa",
        "Yihan Pan",
        "Georgios Papandroulidakis",
        "Themis Prodromakis"
      ],
      "abstract": "Artificial Intelligence models are currently driven by a significant up-scaling of their complexity, with massive matrix multiplication workloads representing the major computational bottleneck. In-memory computing architectures are proposed to avoid the Von Neumann bottleneck. However, both digital/binary-based and analogue in-memory computing architectures suffer from various limitations, which significantly degrade the performance and energy efficiency gains. This work proposes OISMA, a novel in-memory computing architecture that utilizes the computational simplicity of a quasi-stochastic computing domain (Bent-Pyramid system), while keeping the same efficiency, scalability, and productivity of digital memories. OISMA converts normal memory read operations into in-situ stochastic multiplication operations with a negligible cost. An accumulation periphery then accumulates the output multiplication bitstreams, achieving the matrix multiplication functionality. Extensive matrix multiplication benchmarking was conducted to analyze the accuracy of the Bent-Pyramid system, using matrix dimensions ranging from 4x4 to 512x512. The accuracy results show a significant decrease in the average relative Frobenius error, from 9.42% (for 4x4) to 1.81% (for 512x512), compared to 64-bit double precision floating-point format. A 1T1R OISMA array of 4 KB capacity was implemented using a commercial 180nm technology node and in-house RRAM technology. At 50 MHz, OISMA achieves 0.891 TOPS/W and 3.98 GOPS/mm2 for energy and area efficiency, respectively, occupying an effective computing area of 0.804241 mm2. Scaling OISMA from 180nm to 22nm technology shows a significant improvement of two orders of magnitude in energy efficiency and one order of magnitude in area efficiency, compared to dense matrix multiplication in-memory computing architectures.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†OISMAï¼Œä¸€ç§é’ˆå¯¹çŸ©é˜µä¹˜æ³•(Matrix-Multiplication)å·¥ä½œè´Ÿè½½çš„å³æ—¶å­˜å†…éšæœºä¹˜æ³•æ¶æ„ï¼Œæ—¨åœ¨è§£å†³äººå·¥æ™ºèƒ½æ¨¡å‹ä¸­çš„è®¡ç®—ç“¶é¢ˆå’ŒVon Neumannç“¶é¢ˆã€‚è¯¥æ¶æ„åˆ©ç”¨äº†Bent-Pyramidç³»ç»Ÿçš„å‡†éšæœºè®¡ç®—(quasi-stochastic computing)åŸŸçš„è®¡ç®—ç®€å•æ€§ï¼ŒåŒæ—¶ä¿æŒäº†æ•°å­—å­˜å‚¨å™¨çš„æ•ˆç‡ä¸å¯æ‰©å±•æ€§ã€‚OISMAèƒ½å¤Ÿå°†æ™®é€šçš„å†…å­˜è¯»å–æ“ä½œè½¬æ¢ä¸ºä½æˆæœ¬çš„åŸä½(in-situ)éšæœºä¹˜æ³•ï¼Œå¹¶é€šè¿‡ç´¯åŠ å¤–è®¾å¤„ç†è¾“å‡ºä½æµä»¥å®ç°å®Œæ•´çš„çŸ©é˜µä¹˜æ³•åŠŸèƒ½ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œéšç€çŸ©é˜µç»´åº¦å¢åŠ ï¼Œå…¶å¹³å‡ç›¸å¯¹Frobeniusè¯¯å·®æ˜¾è‘—é™ä½ï¼Œåœ¨512x512ç»´åº¦ä¸‹ä»…ä¸º1.81%ã€‚é‡‡ç”¨180nmå·¥è‰ºå’ŒRRAMæŠ€æœ¯å®ç°çš„4 KBé˜µåˆ—åœ¨50 MHzä¸‹è¾¾åˆ°äº†0.891 TOPS/Wçš„èƒ½æ•ˆã€‚æ­¤å¤–ï¼Œå°†OISMAæ‰©å±•è‡³22nmå·¥è‰ºé¢„è®¡å¯å®ç°æ¯”ä¼ ç»Ÿå¯†é›†å­˜å†…è®¡ç®—(In-memory computing)æ¶æ„é«˜å‡ºä¸¤ä¸ªæ•°é‡çº§çš„èƒ½æ•ˆæå‡ã€‚",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.ET",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "12 pages, 13 figures. This work has been submitted to the IEEE for possible publication",
      "pdf_url": "https://arxiv.org/pdf/2508.08822v1",
      "published_date": "2025-08-12 10:24:33 UTC",
      "updated_date": "2025-08-12 10:24:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:22.688388+00:00"
    },
    {
      "arxiv_id": "2508.08816v1",
      "title": "Efficient Agent: Optimizing Planning Capability for Multimodal Retrieval Augmented Generation",
      "title_zh": "Efficient Agentï¼šé¢å‘å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆçš„è§„åˆ’èƒ½åŠ›ä¼˜åŒ–",
      "authors": [
        "Yuechen Wang",
        "Yuming Qiao",
        "Dan Meng",
        "Jun Yang",
        "Haonan Lu",
        "Zhenyu Yang",
        "Xudong Zhang"
      ],
      "abstract": "Multimodal Retrieval-Augmented Generation (mRAG) has emerged as a promising solution to address the temporal limitations of Multimodal Large Language Models (MLLMs) in real-world scenarios like news analysis and trending topics. However, existing approaches often suffer from rigid retrieval strategies and under-utilization of visual information. To bridge this gap, we propose E-Agent, an agent framework featuring two key innovations: a mRAG planner trained to dynamically orchestrate multimodal tools based on contextual reasoning, and a task executor employing tool-aware execution sequencing to implement optimized mRAG workflows. E-Agent adopts a one-time mRAG planning strategy that enables efficient information retrieval while minimizing redundant tool invocations. To rigorously assess the planning capabilities of mRAG systems, we introduce the Real-World mRAG Planning (RemPlan) benchmark. This novel benchmark contains both retrieval-dependent and retrieval-independent question types, systematically annotated with essential retrieval tools required for each instance. The benchmark's explicit mRAG planning annotations and diverse question design enhance its practical relevance by simulating real-world scenarios requiring dynamic mRAG decisions. Experiments across RemPlan and three established benchmarks demonstrate E-Agent's superiority: 13% accuracy gain over state-of-the-art mRAG methods while reducing redundant searches by 37%.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† E-Agentï¼Œä¸€ç§æ—¨åœ¨ä¼˜åŒ–å¤šæ¨¡æ€æ£€ç´¢å¢å¼ºç”Ÿæˆ (mRAG) è§„åˆ’èƒ½åŠ›çš„æ™ºèƒ½ä½“æ¡†æ¶ï¼Œä»¥è§£å†³ç°æœ‰æ–¹æ³•ä¸­æ£€ç´¢ç­–ç•¥åƒµåŒ–å’Œè§†è§‰ä¿¡æ¯åˆ©ç”¨ä¸è¶³çš„é—®é¢˜ã€‚E-Agent åŒ…å«ä¸¤ä¸ªæ ¸å¿ƒåˆ›æ–°ï¼šä¸€ä¸ªèƒ½å¤Ÿæ ¹æ®ä¸Šä¸‹æ–‡æ¨ç†åŠ¨æ€åè°ƒå¤šæ¨¡æ€å·¥å…·çš„ mRAG plannerï¼Œä»¥åŠä¸€ä¸ªé‡‡ç”¨å·¥å…·æ„ŸçŸ¥æ‰§è¡Œåºåˆ—æ¥ä¼˜åŒ–å·¥ä½œæµçš„ task executorã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸€æ¬¡æ€§ mRAG è§„åˆ’ç­–ç•¥ï¼Œåœ¨å®ç°é«˜æ•ˆä¿¡æ¯æ£€ç´¢çš„åŒæ—¶æœ€å°åŒ–äº†å†—ä½™çš„å·¥å…·è°ƒç”¨ã€‚æ­¤å¤–ï¼Œç ”ç©¶è€…è¿˜æ¨å‡ºäº† Real-World mRAG Planning (RemPlan) åŸºå‡†æµ‹è¯•ï¼Œé€šè¿‡åŒ…å«æ£€ç´¢ä¾èµ–å‹å’Œéä¾èµ–å‹é—®é¢˜æ¥ä¸¥æ ¼è¯„ä¼°ç³»ç»Ÿåœ¨çœŸå®åœºæ™¯ä¸‹çš„åŠ¨æ€å†³ç­–èƒ½åŠ›ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒE-Agent åœ¨ RemPlan ç­‰å¤šä¸ªåŸºå‡†æµ‹è¯•ä¸­è¡¨ç°ä¼˜å¼‚ï¼Œç›¸æ¯”ç°æœ‰ SOTA æ–¹æ³•å‡†ç¡®ç‡æå‡äº† 13%ï¼Œå¹¶å‡å°‘äº† 37% çš„å†—ä½™æœç´¢ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08816v1",
      "published_date": "2025-08-12 10:17:12 UTC",
      "updated_date": "2025-08-12 10:17:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:29.496108+00:00"
    },
    {
      "arxiv_id": "2508.08815v1",
      "title": "GRainsaCK: a Comprehensive Software Library for Benchmarking Explanations of Link Prediction Tasks on Knowledge Graphs",
      "title_zh": "GRainsaCKï¼šä¸€ä¸ªç”¨äºçŸ¥è¯†å›¾è°±é“¾æ¥é¢„æµ‹ä»»åŠ¡è§£é‡ŠåŸºå‡†æµ‹è¯•çš„ç»¼åˆè½¯ä»¶åº“",
      "authors": [
        "Roberto Barile",
        "Claudia d'Amato",
        "Nicola Fanizzi"
      ],
      "abstract": "Since Knowledge Graphs are often incomplete, link prediction methods are adopted for predicting missing facts. Scalable embedding based solutions are mostly adopted for this purpose, however, they lack comprehensibility, which may be crucial in several domains. Explanation methods tackle this issue by identifying supporting knowledge explaining the predicted facts. Regretfully, evaluating/comparing quantitatively the resulting explanations is challenging as there is no standard evaluation protocol and overall benchmarking resource. We fill this important gap by proposing GRainsaCK, a reusable software resource that fully streamlines all the tasks involved in benchmarking explanations, i.e., from model training to evaluation of explanations along the same evaluation protocol. Moreover, GRainsaCK furthers modularity/extensibility by implementing the main components as functions that can be easily replaced. Finally, fostering its reuse, we provide extensive documentation including a tutorial.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GRainsaCKï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“é—¨ç”¨äºå¯¹çŸ¥è¯†å›¾è°± (Knowledge Graphs) é“¾è·¯é¢„æµ‹ (Link Prediction) ä»»åŠ¡çš„è§£é‡Šæ€§è¿›è¡ŒåŸºå‡†æµ‹è¯•çš„ç»¼åˆè½¯ä»¶åº“ã€‚é’ˆå¯¹ç›®å‰åŸºäºåµŒå…¥ (Embedding) çš„æ–¹æ³•ç¼ºä¹å¯ç†è§£æ€§ï¼Œä¸”ç¼ºä¹æ ‡å‡†åŒ–è¯„ä¼°åè®®å’ŒåŸºå‡†èµ„æºçš„é—®é¢˜ï¼ŒGRainsaCK å®ç°äº†ä»æ¨¡å‹è®­ç»ƒåˆ°ç»“æœè¯„ä¼°çš„å®Œæ•´è‡ªåŠ¨åŒ–æµç¨‹ã€‚è¯¥åº“é€šè¿‡å°†æ ¸å¿ƒç»„ä»¶å®ç°ä¸ºæ˜“äºæ›¿æ¢çš„å‡½æ•°ï¼Œç¡®ä¿äº†ç³»ç»Ÿçš„æ¨¡å—åŒ–ä¸å¯æ‰©å±•æ€§ã€‚é€šè¿‡å¼•å…¥ç»Ÿä¸€çš„è¯„ä¼°æ¡†æ¶ï¼ŒGRainsaCK å¡«è¡¥äº†å®šé‡å¯¹æ¯”ä¸åŒé“¾è·¯é¢„æµ‹è§£é‡Šæ–¹æ³•çš„å…³é”®ç©ºç™½ã€‚æ­¤å¤–ï¼Œç ”ç©¶å›¢é˜Ÿæä¾›äº†è¯¦å°½çš„æ–‡æ¡£ä¸æ•™ç¨‹ï¼Œä»¥æ”¯æŒè¯¥å·¥å…·çš„å¹¿æ³›å¤ç”¨ä¸å¼€å‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08815v1",
      "published_date": "2025-08-12 10:15:58 UTC",
      "updated_date": "2025-08-12 10:15:58 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:30.296117+00:00"
    },
    {
      "arxiv_id": "2508.08814v2",
      "title": "TempOpt -- Unsupervised Alarm Relation Learning for Telecommunication Networks",
      "title_zh": "TempOptï¼šç”µä¿¡ç½‘ç»œæ— ç›‘ç£å‘Šè­¦å…³è”å­¦ä¹ ",
      "authors": [
        "Sathiyanaryanan Sampath",
        "Pratyush Uppuluri",
        "Thirumaran Ekambaram"
      ],
      "abstract": "In a telecommunications network, fault alarms generated by network nodes are monitored in a Network Operations Centre (NOC) to ensure network availability and continuous network operations. The monitoring process comprises of tasks such as active alarms analysis, root alarm identification, and resolution of the underlying problem. Each network node potentially can generate alarms of different types, while nodes can be from multiple vendors, a network can have hundreds of nodes thus resulting in an enormous volume of alarms at any time. Since network nodes are inter-connected, a single fault in the network would trigger multiple sequences of alarms across a variety of nodes and from a monitoring point of view, it is a challenging task for a NOC engineer to be aware of relations between the various alarms, when trying to identify, for example, a root alarm on which an action needs to be taken. To effectively identify root alarms, it is essential to learn relation among the alarms for accurate and faster resolution. In this work we propose a novel unsupervised alarm relation learning technique Temporal Optimization (TempOpt) that is practical and overcomes the limitations of an existing class of alarm relational learning method-temporal dependency methods. Experiments have been carried on real-world network datasets, that demonstrate the improved quality of alarm relations learned by TempOpt as compared to temporal dependency method.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µä¿¡ç½‘ç»œä¸­ç”±äºèŠ‚ç‚¹äº’è”å’Œæµ·é‡æ•°æ®å¯¼è‡´çš„å‘Šè­¦å…³ç³»è¯†åˆ«éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸º TempOpt çš„æ–°å‹æ— ç›‘ç£å‘Šè­¦å…³ç³»å­¦ä¹ æŠ€æœ¯ã€‚åœ¨ç½‘ç»œæ“ä½œä¸­å¿ƒ(NOC)çš„æ—¥å¸¸è¿ç»´ä¸­ï¼Œæµ·é‡çš„æ•…éšœå‘Šè­¦ä½¿å¾—å·¥ç¨‹å¸ˆéš¾ä»¥å¿«é€Ÿå®šä½æ ¹æºå‘Šè­¦(root alarm)ï¼Œè€Œè¯¥æ–¹æ³•é€šè¿‡æ—¶é—´ä¼˜åŒ–(Temporal Optimization)ç­–ç•¥æœ‰æ•ˆå…‹æœäº†ä¼ ç»Ÿæ—¶é—´ä¾èµ–(temporal dependency)æ–¹æ³•çš„å±€é™æ€§ã€‚TempOpt æ— éœ€æ ‡æ³¨æ•°æ®å³å¯ä»ä¸åŒå‚å•†å’ŒèŠ‚ç‚¹çš„å‘Šè­¦æµä¸­è‡ªåŠ¨å­¦ä¹ å…³è”è§„å¾‹ï¼Œä¸ºæ•…éšœåˆ†æå’Œé—®é¢˜è§£å†³æä¾›å…³é”®æ”¯æŒã€‚é€šè¿‡åœ¨çœŸå®ä¸–ç•Œç½‘ç»œæ•°æ®é›†ä¸Šçš„å®éªŒéªŒè¯ï¼Œç»“æœè¡¨æ˜ TempOpt å­¦ä¹ åˆ°çš„å‘Šè­¦å…³ç³»è´¨é‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„æ—¶é—´ä¾èµ–æ–¹æ³•ï¼Œä¸ºæé«˜ç”µä¿¡ç½‘ç»œå¯ç”¨æ€§å’Œè‡ªåŠ¨åŒ–è¿ç»´æ•ˆç‡æä¾›äº†å®ç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "6 pages, 9 figures. IEEE 21st India Council International Conference (INDICON), 2024",
      "pdf_url": "https://arxiv.org/pdf/2508.08814v2",
      "published_date": "2025-08-12 10:15:48 UTC",
      "updated_date": "2025-08-13 07:28:25 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:34.394886+00:00"
    },
    {
      "arxiv_id": "2508.08810v1",
      "title": "Not in My Backyard! Temporal Voting Over Public Chores",
      "title_zh": "åˆ«åœ¨æˆ‘å®¶åé™¢ï¼å…³äºå…¬å…±è‹¦å·®çš„è·¨æœŸæŠ•ç¥¨",
      "authors": [
        "Edith Elkind",
        "Tzeh Yuan Neoh",
        "Nicholas Teh"
      ],
      "abstract": "We study a temporal voting model where voters have dynamic preferences over a set of public chores -- projects that benefit society, but impose individual costs on those affected by their implementation. We investigate the computational complexity of optimizing utilitarian and egalitarian welfare. Our results show that while optimizing the former is computationally straightforward, minimizing the latter is computationally intractable, even in very restricted cases. Nevertheless, we identify several settings where this problem can be solved efficiently, either exactly or by an approximation algorithm. We also examine the effects of enforcing temporal fairness and its impact on social welfare, and analyze the competitive ratio of online algorithms. We then explore the strategic behavior of agents, providing insights into potential malfeasance in such decision-making environments. Finally, we discuss a range of fairness measures and their suitability for our setting.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ä¸€ä¸ªæ—¶åºæŠ•ç¥¨æ¨¡å‹(Temporal Voting Model)ï¼Œåœ¨è¯¥æ¨¡å‹ä¸­é€‰æ°‘å¯¹ä¸€ç³»åˆ—å…¬å…±è‹¦å·®(Public Chores)å…·æœ‰åŠ¨æ€åå¥½ï¼Œè¿™äº›é¡¹ç›®è™½æœ‰ç›Šäºç¤¾ä¼šä½†ä¼šç»™å—å½±å“ä¸ªä½“å¸¦æ¥æˆæœ¬ã€‚ç ”ç©¶é‡ç‚¹åˆ†æäº†ä¼˜åŒ–åŠŸåˆ©ä¸»ä¹‰ç¦åˆ©(Utilitarian Welfare)å’Œå¹³å‡ä¸»ä¹‰ç¦åˆ©(Egalitarian Welfare)çš„è®¡ç®—å¤æ‚åº¦ï¼Œå‘ç°æœ€å°åŒ–åè€…åœ¨å¤§å¤šæ•°æƒ…å†µä¸‹æ˜¯è®¡ç®—ä¸å¯è¡Œçš„ã€‚å°½ç®¡å¦‚æ­¤ï¼Œä½œè€…ä»è¯†åˆ«å‡ºæ•°ç§å¯å®ç°ç²¾ç¡®è§£æˆ–è¿‘ä¼¼ç®—æ³•(Approximation Algorithm)çš„æœ‰æ•ˆè·¯å¾„ã€‚æ–‡ç« è¿›ä¸€æ­¥åˆ†æäº†å¼ºåˆ¶æ‰§è¡Œæ—¶åºå…¬å¹³(Temporal Fairness)å¯¹ç¤¾ä¼šç¦åˆ©çš„å½±å“ï¼Œä»¥åŠåœ¨çº¿ç®—æ³•(Online Algorithms)åœ¨å†³ç­–ç¯å¢ƒä¸­çš„ç«äº‰æ¯”(Competitive Ratio)ã€‚æ­¤å¤–ï¼Œç ”ç©¶è¿˜æ­ç¤ºäº†æ™ºèƒ½ä½“çš„æˆ˜ç•¥è¡Œä¸º(Strategic Behavior)åŠæ½œåœ¨çš„æ“çºµé£é™©ã€‚æœ€åï¼Œè®ºæ–‡è®¨è®ºäº†å¤šç§å…¬å¹³åº¦é‡æ ‡å‡†åœ¨æ—¶åºæŠ•ç¥¨èƒŒæ™¯ä¸‹çš„é€‚ç”¨æ€§ï¼Œä¸ºç†è§£å¤æ‚ç¤¾ä¼šå†³ç­–ä¸­çš„åˆ©ç›Šåˆ†é…æä¾›äº†ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH"
      ],
      "primary_category": "cs.GT",
      "comment": "Appears in the 34th International Joint Conference on Artificial Intelligence (IJCAI), 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08810v1",
      "published_date": "2025-08-12 10:06:56 UTC",
      "updated_date": "2025-08-12 10:06:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:54.067764+00:00"
    },
    {
      "arxiv_id": "2508.08805v1",
      "title": "Opening Musical Creativity? Embedded Ideologies in Generative-AI Music Systems",
      "title_zh": "å¼€å¯éŸ³ä¹åˆ›é€ åŠ›ï¼Ÿç”Ÿæˆå¼äººå·¥æ™ºèƒ½éŸ³ä¹ç³»ç»Ÿä¸­çš„åµŒå…¥æ„è¯†å½¢æ€",
      "authors": [
        "Liam Pram",
        "Fabio Morreale"
      ],
      "abstract": "AI systems for music generation are increasingly common and easy to use, granting people without any musical background the ability to create music. Because of this, generative-AI has been marketed and celebrated as a means of democratizing music making. However, inclusivity often functions as marketable rhetoric rather than a genuine guiding principle in these industry settings. In this paper, we look at four generative-AI music making systems available to the public as of mid-2025 (AIVA, Stable Audio, Suno, and Udio) and track how they are rhetoricized by their developers, and received by users. Our aim is to investigate ideologies that are driving the early-stage development and adoption of generative-AI in music making, with a particular focus on democratization. A combination of autoethnography and digital ethnography is used to examine patterns and incongruities in rhetoric when positioned against product functionality. The results are then collated to develop a nuanced, contextual discussion. The shared ideology we map between producers and consumers is individualist, globalist, techno-liberal, and ethically evasive. It is a 'total ideology' which obfuscates individual responsibility, and through which the nature of music and musical practice is transfigured to suit generative outcomes.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼ˆGenerative-AIï¼‰éŸ³ä¹ç³»ç»ŸåŠå…¶èƒŒåçš„æ„è¯†å½¢æ€ï¼Œé‡ç‚¹åˆ†æäº† AIVAã€Stable Audioã€Suno å’Œ Udio å››ä¸ªç³»ç»Ÿå¦‚ä½•é€šè¿‡â€œéŸ³ä¹åˆ¶ä½œæ°‘ä¸»åŒ–â€çš„ä¿®è¾è¿›è¡Œå¸‚åœºæ¨å¹¿ã€‚ä½œè€…é‡‡ç”¨è‡ªåŠ¨æ°‘æ—å¿—ï¼ˆautoethnographyï¼‰å’Œæ•°å­—æ°‘æ—å¿—ï¼ˆdigital ethnographyï¼‰ç›¸ç»“åˆçš„æ–¹æ³•ï¼Œè€ƒå¯Ÿäº†å¼€å‘è€…ä¿®è¾ã€äº§å“å®é™…åŠŸèƒ½ä¸ç”¨æˆ·æ¥å—æƒ…å†µä¹‹é—´çš„å…³è”ã€‚ç ”ç©¶å‘ç°ï¼Œè¿™äº›ç³»ç»Ÿæ‰€å®£æ‰¬çš„åŒ…å®¹æ€§æ›´å¤šæ˜¯è¥é”€è¯æœ¯è€Œéæ ¸å¿ƒå¼•å¯¼åŸåˆ™ã€‚åˆ†ææ­ç¤ºäº†ç”Ÿäº§è€…ä¸æ¶ˆè´¹è€…ä¹‹é—´å…±æœ‰çš„ä¸€ç§ä¸ªäººä¸»ä¹‰ï¼ˆindividualistï¼‰ã€å…¨çƒä¸»ä¹‰ï¼ˆglobalistï¼‰ã€æŠ€æœ¯è‡ªç”±ä¸»ä¹‰ï¼ˆtechno-liberalï¼‰ä¸”åœ¨ä¼¦ç†ä¸Šå…·æœ‰é€ƒé¿æ€§çš„æ„è¯†å½¢æ€ã€‚è¿™ç§â€œå…¨æ–¹ä½æ„è¯†å½¢æ€â€ï¼ˆtotal ideologyï¼‰æ¨¡ç³Šäº†ä¸ªäººè´£ä»»ï¼Œå¹¶ä¸ºäº†å¥‘åˆç”Ÿæˆå¼ç»“æœè€Œé‡å¡‘äº†éŸ³ä¹åŠéŸ³ä¹å®è·µçš„æœ¬è´¨ã€‚",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SD",
      "comment": "Extended version of the presentation at The First International Conference in AI Music Studies 2024",
      "pdf_url": "https://arxiv.org/pdf/2508.08805v1",
      "published_date": "2025-08-12 09:59:07 UTC",
      "updated_date": "2025-08-12 09:59:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:19:50.384590+00:00"
    },
    {
      "arxiv_id": "2508.08804v1",
      "title": "TechOps: Technical Documentation Templates for the AI Act",
      "title_zh": "TechOpsï¼šé¢å‘ã€Šäººå·¥æ™ºèƒ½æ³•æ¡ˆã€‹çš„æŠ€æœ¯æ–‡æ¡£æ¨¡æ¿",
      "authors": [
        "Laura Lucaj",
        "Alex Loosley",
        "Hakan Jonsson",
        "Urs Gasser",
        "Patrick van der Smagt"
      ],
      "abstract": "Operationalizing the EU AI Act requires clear technical documentation to ensure AI systems are transparent, traceable, and accountable. Existing documentation templates for AI systems do not fully cover the entire AI lifecycle while meeting the technical documentation requirements of the AI Act.\n  This paper addresses those shortcomings by introducing open-source templates and examples for documenting data, models, and applications to provide sufficient documentation for certifying compliance with the AI Act. These templates track the system status over the entire AI lifecycle, ensuring traceability, reproducibility, and compliance with the AI Act. They also promote discoverability and collaboration, reduce risks, and align with best practices in AI documentation and governance.\n  The templates are evaluated and refined based on user feedback to enable insights into their usability and implementability. We then validate the approach on real-world scenarios, providing examples that further guide their implementation: the data template is followed to document a skin tones dataset created to support fairness evaluations of downstream computer vision models and human-centric applications; the model template is followed to document a neural network for segmenting human silhouettes in photos. The application template is tested on a system deployed for construction site safety using real-time video analytics and sensor data. Our results show that TechOps can serve as a practical tool to enable oversight for regulatory compliance and responsible AI development.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹æ¬§ç›Ÿäººå·¥æ™ºèƒ½æ³•æ¡ˆ(AI Act)å¯¹é€æ˜åº¦ã€å¯è¿½æº¯æ€§å’Œé—®è´£åˆ¶çš„ä¸¥æ ¼è¦æ±‚ï¼Œæå‡ºäº†TechOpsï¼Œä¸€å¥—æ—¨åœ¨è¦†ç›–AIå…¨ç”Ÿå‘½å‘¨æœŸçš„å¼€æºæŠ€æœ¯æ–‡æ¡£æ¨¡æ¿ã€‚é’ˆå¯¹ç°æœ‰æ¨¡æ¿æ— æ³•å®Œå…¨è¦†ç›–AIå…¨ç”Ÿå‘½å‘¨æœŸä¸”éš¾ä»¥æ»¡è¶³AI Actåˆè§„è¦æ±‚çš„é—®é¢˜ï¼ŒTechOpsæä¾›äº†é’ˆå¯¹æ•°æ®(Data)ã€æ¨¡å‹(Model)å’Œåº”ç”¨(Application)çš„ä¸“é—¨åŒ–æ–‡æ¡£æ–¹æ¡ˆã€‚è¿™äº›æ¨¡æ¿é€šè¿‡è¿½è¸ªç³»ç»Ÿå…¨å‘¨æœŸçš„çŠ¶æ€ï¼Œç¡®ä¿äº†AIç³»ç»Ÿçš„å¯è¿½æº¯æ€§(Traceability)ã€å¯å¤ç°æ€§(Reproducibility)ä»¥åŠå¯¹AI Actçš„å…¨é¢åˆè§„ã€‚ç ”ç©¶å›¢é˜Ÿåˆ©ç”¨ç”¨æˆ·åé¦ˆå¯¹æ¨¡æ¿è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå¹¶åœ¨çš®è‚¤è‰²è°ƒæ•°æ®é›†ã€äººä½“å‰ªå½±åˆ†å‰²æ¨¡å‹ä»¥åŠå»ºç­‘å·¥åœ°å®‰å…¨ç›‘æ§ç³»ç»Ÿç­‰çœŸå®æ¡ˆä¾‹ä¸­è¿›è¡Œäº†éªŒè¯ã€‚ç»“æœæ˜¾ç¤ºï¼ŒTechOpsèƒ½å¤Ÿæ˜¾è‘—æå‡æ–‡æ¡£ç¼–åˆ¶çš„å¯ç”¨æ€§ï¼Œé™ä½æ²»ç†é£é™©ï¼Œå¹¶ä¸AIæ–‡æ¡£æ²»ç†çš„æœ€ä½³å®è·µä¿æŒä¸€è‡´ã€‚æœ€ç»ˆï¼Œè¯¥ç ”ç©¶è¯æ˜äº†TechOpsæ˜¯å®ç°ç›‘ç®¡åˆè§„ä¸è´Ÿè´£ä»»çš„äººå·¥æ™ºèƒ½(Responsible AI)å¼€å‘çš„å®ç”¨å·¥å…·ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08804v1",
      "published_date": "2025-08-12 09:58:33 UTC",
      "updated_date": "2025-08-12 09:58:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:10.464975+00:00"
    },
    {
      "arxiv_id": "2508.11691v1",
      "title": "Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception",
      "title_zh": "é¢å‘åŸºäºè„‘ç”µå›¾çš„ç—›è§‰è¯†åˆ«çš„å¯æ³›åŒ–å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Mathis Rezzouk",
        "Fabrice Gagnon",
        "Alyson Champagne",
        "Mathieu Roy",
        "Philippe Albouy",
        "Michel-Pierre Coll",
        "Cem Subakan"
      ],
      "abstract": "EEG-based analysis of pain perception, enhanced by machine learning, reveals how the brain encodes pain by identifying neural patterns evoked by noxious stimulation. However, a major challenge that remains is the generalization of machine learning models across individuals, given the high cross-participant variability inherent to EEG signals and the limited focus on direct pain perception identification in current research. In this study, we systematically evaluate the performance of cross-participant generalization of a wide range of models, including traditional classifiers and deep neural classifiers for identifying the sensory modality of thermal pain and aversive auditory stimulation from EEG recordings. Using a novel dataset of EEG recordings from 108 participants, we benchmark model performance under both within- and cross-participant evaluation settings. Our findings show that traditional models suffered the largest drop from within- to cross-participant performance, while deep learning models proved more resilient, underscoring their potential for subject-invariant EEG decoding. Even though performance variability remained high, the strong results of the graph-based model highlight its potential to capture subject-invariant structure in EEG signals. On the other hand, we also share the preprocessed dataset used in this study, providing a standardized benchmark for evaluating future algorithms under the same generalization constraints.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åŸºäºè„‘ç”µå›¾(EEG)çš„ç–¼ç—›æ„ŸçŸ¥è¯†åˆ«ï¼Œé‡ç‚¹è§£å†³æœºå™¨å­¦ä¹ æ¨¡å‹åœ¨åº”å¯¹é«˜å—è¯•è€…é—´å˜å¼‚æ€§æ—¶çš„æ³›åŒ–(generalization)æŒ‘æˆ˜ã€‚ç ”ç©¶äººå‘˜åˆ©ç”¨åŒ…å«108åå‚ä¸è€…çš„æ–°æ•°æ®é›†ï¼Œç³»ç»Ÿå¯¹æ¯”äº†ä¼ ç»Ÿåˆ†ç±»å™¨ä¸æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å—è¯•è€…å†…(within-participant)å’Œè·¨å—è¯•è€…(cross-participant)è®¾å®šä¸‹è¯†åˆ«çƒ­ç—›å’ŒåŒæ¶å¬è§‰åˆºæ¿€çš„è¡¨ç°ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œä¼ ç»Ÿæ¨¡å‹åœ¨è·¨å—è¯•è€…è¯„ä¼°æ—¶æ€§èƒ½ä¸‹é™æœ€ä¸ºæ˜¾è‘—ï¼Œè€Œæ·±åº¦å­¦ä¹ æ¨¡å‹åˆ™è¡¨ç°å‡ºæ›´å¼ºçš„å¤åŸåŠ›ã€‚ç‰¹åˆ«æ˜¯åŸºäºå›¾çš„(graph-based)æ¨¡å‹åœ¨æ•æ‰å—è¯•è€…ä¸å˜(subject-invariant)ç»“æ„æ–¹é¢å±•ç°å‡ºå·¨å¤§æ½œåŠ›ã€‚æ­¤å¤–ï¼Œè¯¥ç ”ç©¶è¿˜å…¬å¼€äº†é¢„å¤„ç†åçš„æ•°æ®é›†ï¼Œä¸ºæœªæ¥ç®—æ³•åœ¨ç›¸åŒæ³›åŒ–çº¦æŸä¸‹çš„è¯„ä¼°æä¾›äº†æ ‡å‡†åŸºå‡†(benchmark)ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "6 pages, 2 figures, 2 tables, MLSP IEEE conference",
      "pdf_url": "https://arxiv.org/pdf/2508.11691v1",
      "published_date": "2025-08-12 09:57:32 UTC",
      "updated_date": "2025-08-12 09:57:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:13.185316+00:00"
    },
    {
      "arxiv_id": "2508.08795v1",
      "title": "A Dual-Axis Taxonomy of Knowledge Editing for LLMs: From Mechanisms to Functions",
      "title_zh": "LLM çŸ¥è¯†ç¼–è¾‘çš„åŒè½´åˆ†ç±»ä½“ç³»ï¼šä»æœºåˆ¶åˆ°åŠŸèƒ½",
      "authors": [
        "Amir Mohammad Salehoof",
        "Ali Ramezani",
        "Yadollah Yaghoobzadeh",
        "Majid Nili Ahmadabadi"
      ],
      "abstract": "Large language models (LLMs) acquire vast knowledge from large text corpora, but this information can become outdated or inaccurate. Since retraining is computationally expensive, knowledge editing offers an efficient alternative -- modifying internal knowledge without full retraining. These methods aim to update facts precisely while preserving the model's overall capabilities. While existing surveys focus on the mechanism of editing (e.g., parameter changes vs. external memory), they often overlook the function of the knowledge being edited. This survey introduces a novel, complementary function-based taxonomy to provide a more holistic view. We examine how different mechanisms apply to various knowledge types -- factual, temporal, conceptual, commonsense, and social -- highlighting how editing effectiveness depends on the nature of the target knowledge. By organizing our review along these two axes, we map the current landscape, outline the strengths and limitations of existing methods, define the problem formally, survey evaluation tasks and datasets, and conclude with open challenges and future directions.",
      "tldr_zh": "è¯¥ç»¼è¿°é’ˆå¯¹ Large Language Models (LLMs) çš„ Knowledge Editing æŠ€æœ¯æå‡ºäº†ä¸€ä¸ªæ–°é¢–çš„ Dual-Axis Taxonomyï¼Œæ—¨åœ¨ä» Mechanisms ä¸ Functions ä¸¤ä¸ªç»´åº¦æä¾›æ›´å…¨é¢çš„è§†è§’ã€‚ç°æœ‰çš„ç ”ç©¶å¤šå…³æ³¨ç¼–è¾‘çš„ Mechanismï¼ˆå¦‚å‚æ•°è°ƒæ•´æˆ–å¤–éƒ¨è®°å¿†ï¼‰ï¼Œè€Œè¯¥è®ºæ–‡é€šè¿‡å¼•å…¥åŸºäº Function çš„è¡¥å……åˆ†ç±»è½´ï¼Œåˆ†æäº†ä¸åŒç±»å‹çš„çŸ¥è¯†ç‰¹æ€§å¦‚ä½•å½±å“ç¼–è¾‘æ•ˆæœã€‚ç ”ç©¶æ¢è®¨äº† Mechanisms åœ¨ Factual, Temporal, Conceptual, Commonsense å’Œ Social ç­‰ä¸åŒçŸ¥è¯†ç±»å‹ä¸Šçš„åº”ç”¨ï¼Œæ­ç¤ºäº†ç¼–è¾‘æœ‰æ•ˆæ€§ä¸ç›®æ ‡çŸ¥è¯†æ€§è´¨ä¹‹é—´çš„å…³ç³»ã€‚è¯¥ç»¼è¿°ç³»ç»Ÿåœ°æ¢³ç†äº†å½“å‰çš„æŠ€æœ¯ç‰ˆå›¾ï¼Œå¯¹é—®é¢˜è¿›è¡Œäº† Formal Definitionï¼Œå¹¶è°ƒç ”äº†ç›¸å…³çš„ Evaluation tasks å’Œ Datasetsã€‚æœ€åï¼Œæ–‡ç« æ€»ç»“äº†ç°æœ‰æ–¹æ³•çš„ä¼˜åŠ¿ä¸å±€é™æ€§ï¼Œå¹¶æŒ‡å‡ºäº†çŸ¥è¯†ç¼–è¾‘é¢†åŸŸæœªæ¥é¢ä¸´çš„æŒ‘æˆ˜ä¸ç ”ç©¶æ–¹å‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 1 figure",
      "pdf_url": "https://arxiv.org/pdf/2508.08795v1",
      "published_date": "2025-08-12 09:51:39 UTC",
      "updated_date": "2025-08-12 09:51:39 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:23.158592+00:00"
    },
    {
      "arxiv_id": "2508.08791v2",
      "title": "Feedback-Driven Tool-Use Improvements in Large Language Models via Automated Build Environments",
      "title_zh": "åŸºäºè‡ªåŠ¨åŒ–æ„å»ºç¯å¢ƒçš„å¤§è¯­è¨€æ¨¡å‹åé¦ˆé©±åŠ¨å·¥å…·ä½¿ç”¨èƒ½åŠ›æå‡",
      "authors": [
        "Junjie Ye",
        "Changhao Jiang",
        "Zhengyin Du",
        "Yufei Xu",
        "Xuesong Yao",
        "Zhiheng Xi",
        "Xiaoran Fan",
        "Qi Zhang",
        "Tao Gui",
        "Xuanjing Huang",
        "Jiecao Chen"
      ],
      "abstract": "Effective tool use is essential for large language models (LLMs) to interact meaningfully with their environment. However, progress is limited by the lack of efficient reinforcement learning (RL) frameworks specifically designed for tool use, due to challenges in constructing stable training environments and designing verifiable reward mechanisms. To address this, we propose an automated environment construction pipeline, incorporating scenario decomposition, document generation, function integration, complexity scaling, and localized deployment. This enables the creation of high-quality training environments that provide detailed and measurable feedback without relying on external tools. Additionally, we introduce a verifiable reward mechanism that evaluates both the precision of tool use and the completeness of task execution. When combined with trajectory data collected from the constructed environments, this mechanism integrates seamlessly with standard RL algorithms to facilitate feedback-driven model training. Experiments on LLMs of varying scales demonstrate that our approach significantly enhances the models' tool-use performance without degrading their general capabilities, regardless of inference modes or training algorithms. Our analysis suggests that these gains result from improved context understanding and reasoning, driven by updates to the lower-layer MLP parameters in models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å·¥å…·è°ƒç”¨(Tool-use)é¢†åŸŸç¼ºä¹é«˜æ•ˆå¼ºåŒ–å­¦ä¹ (RL)æ¡†æ¶ã€ç¨³å®šè®­ç»ƒç¯å¢ƒåŠå¯éªŒè¯å¥–åŠ±æœºåˆ¶çš„éš¾é¢˜ï¼Œæå‡ºäº†ä¸€ç§è‡ªåŠ¨åŒ–ç¯å¢ƒæ„å»ºç®¡çº¿ã€‚è¯¥ç®¡çº¿é€šè¿‡åœºæ™¯åˆ†è§£ã€æ–‡æ¡£ç”Ÿæˆã€åŠŸèƒ½é›†æˆå’Œæœ¬åœ°åŒ–éƒ¨ç½²ç­‰æ­¥éª¤ï¼Œèƒ½åœ¨æ— éœ€å¤–éƒ¨å·¥å…·çš„æƒ…å†µä¸‹ç”Ÿæˆé«˜è´¨é‡è®­ç»ƒç¯å¢ƒå¹¶æä¾›è¯¦ç»†åé¦ˆã€‚ç ”ç©¶åŒæ—¶å¼•å…¥äº†å¯éªŒè¯çš„å¥–åŠ±æœºåˆ¶ï¼Œç”¨äºè¯„ä¼°å·¥å…·è°ƒç”¨çš„ç²¾ç¡®åº¦ä¸ä»»åŠ¡æ‰§è¡Œçš„å®Œæ•´æ€§ï¼Œå¹¶ç»“åˆç¯å¢ƒè½¨è¿¹æ•°æ®é€šè¿‡æ ‡å‡†å¼ºåŒ–å­¦ä¹ ç®—æ³•å®ç°åé¦ˆé©±åŠ¨çš„æ¨¡å‹è®­ç»ƒã€‚å®éªŒè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸å‰Šå¼±é€šç”¨èƒ½åŠ›çš„å‰æä¸‹ï¼Œæ˜¾è‘—å¢å¼ºäº†ä¸åŒè§„æ¨¡æ¨¡å‹åœ¨å„ç§æ¨ç†æ¨¡å¼ä¸‹çš„å·¥å…·è°ƒç”¨æ€§èƒ½ã€‚æ·±å…¥åˆ†æè¡¨æ˜ï¼Œæ€§èƒ½å¢ç›Šä¸»è¦æºäºæ¨¡å‹åº•å±‚MLPå‚æ•°æ›´æ–°æ‰€å¸¦æ¥çš„ä¸Šä¸‹æ–‡ç†è§£ä¸æ¨ç†èƒ½åŠ›çš„æ˜¾è‘—æå‡ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08791v2",
      "published_date": "2025-08-12 09:45:19 UTC",
      "updated_date": "2025-09-12 02:57:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:19.261755+00:00"
    },
    {
      "arxiv_id": "2508.08790v1",
      "title": "ReQuestNet: A Foundational Learning model for Channel Estimation",
      "title_zh": "ReQuestNetï¼šé¢å‘ä¿¡é“ä¼°è®¡çš„åŸºç¡€å­¦ä¹ æ¨¡å‹",
      "authors": [
        "Kumar Pratik",
        "Pouriya Sadeghi",
        "Gabriele Cesa",
        "Sanaz Barghi",
        "Joseph B. Soriaga",
        "Yuanning Yu",
        "Supratik Bhattacharjee",
        "Arash Behboodi"
      ],
      "abstract": "In this paper, we present a novel neural architecture for channel estimation (CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network (ReQuestNet). It incorporates several practical considerations in wireless communication systems, such as ability to handle variable number of resource block (RB), dynamic number of transmit layers, physical resource block groups (PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a single unified model, thereby, drastically simplifying the CE pipeline. Besides it addresses several limitations of the legacy linear MMSE solutions, for example, by being independent of other reference signals and particularly by jointly processing MIMO layers and differently precoded channels with unknown precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive (Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet channel estimate by incorporating correlations across differently precoded PRGs, and correlation across multiple input multiple output (MIMO) channel spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet significantly outperforms genie minimum mean squared error (MMSE) CE across a wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations under dynamic PRG BS and varying transmit layer allocations.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ReQuestNet (Recurrent Equivariant UERS Estimation Network)ï¼Œè¿™æ˜¯ä¸€ç§é¢å‘5GåŠæœªæ¥é€šä¿¡ç³»ç»Ÿçš„ä¿¡é“ä¼°è®¡(Channel Estimation)æ–°å‹åŸºç¡€å­¦ä¹ æ¨¡å‹ã€‚è¯¥æ¶æ„é€šè¿‡ç»Ÿä¸€æ¨¡å‹å¤„ç†å¯å˜èµ„æºå—(RB)æ•°é‡ã€åŠ¨æ€ä¼ è¾“å±‚ã€ç‰©ç†èµ„æºå—ç»„(PRG)æ†ç»‘å¤§å°ä»¥åŠè§£è°ƒå‚è€ƒä¿¡å·(DMRS)æ¨¡å¼ï¼Œæå¤§åœ°ç®€åŒ–äº†ä¿¡é“ä¼°è®¡æµç¨‹ã€‚ReQuestNet å…‹æœäº†ä¼ ç»Ÿçº¿æ€§MMSEæ–¹æ¡ˆçš„å±€é™æ€§ï¼Œèƒ½å¤Ÿç‹¬ç«‹äºå‚è€ƒä¿¡å·å¹¶è”åˆå¤„ç†å…·æœ‰æœªçŸ¥é¢„ç¼–ç çš„MIMOå±‚ã€‚å…¶å†…éƒ¨ç”±CoarseNetå’ŒRefinementNetä¸¤ä¸ªå­å•å…ƒç»„æˆï¼Œåˆ†åˆ«æ‰§è¡Œåˆæ­¥ä¼°è®¡ä»¥åŠåˆ©ç”¨è·¨PRGå’Œè·¨MIMOç©ºé—´ç»´åº¦çš„ç›¸å…³æ€§è¿›è¡Œç²¾ç»†åŒ–å¤„ç†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨å¤šç§ä¿¡é“æ¡ä»¶ä¸‹æ˜¾è‘—ä¼˜äºç†æƒ³MMSEï¼Œåœ¨é«˜ä¿¡å™ªæ¯”(SNR)ä¸‹å¯å®ç°é«˜è¾¾10dBçš„æ€§èƒ½å¢ç›Šã€‚æ­¤å¤–ï¼ŒReQuestNet åœ¨åŠ¨æ€èµ„æºåˆ†é…ä¸‹è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•æ‰æœªè§ä¿¡é“å‰–é¢çš„ç©ºé—´ä¸é¢‘ç‡ç›¸å…³æ€§ã€‚",
      "categories": [
        "eess.SP",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "eess.SP",
      "comment": "Accepted at IEEE Globecom 2025. Permission from IEEE must be obtained for all other uses, in any current or future media, including reprinting/republishing this material for advertising or promotional purposes, creating new collective works, for resale or redistribution to servers or lists, or reuse of any copyrighted component of this work in other works",
      "pdf_url": "https://arxiv.org/pdf/2508.08790v1",
      "published_date": "2025-08-12 09:44:47 UTC",
      "updated_date": "2025-08-12 09:44:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:33.061856+00:00"
    },
    {
      "arxiv_id": "2508.13177v1",
      "title": "A Hardware-oriented Approach for Efficient Active Inference Computation and Deployment",
      "title_zh": "é¢å‘ç¡¬ä»¶çš„é«˜æ•ˆä¸»åŠ¨æ¨ç†è®¡ç®—ä¸éƒ¨ç½²æ–¹æ³•",
      "authors": [
        "Nikola PiÅ¾urica",
        "Nikola MiloviÄ‡",
        "Igor JovanÄeviÄ‡",
        "Conor Heins",
        "Miguel de Prado"
      ],
      "abstract": "Active Inference (AIF) offers a robust framework for decision-making, yet its computational and memory demands pose challenges for deployment, especially in resource-constrained environments. This work presents a methodology that facilitates AIF's deployment by integrating pymdp's flexibility and efficiency with a unified, sparse, computational graph tailored for hardware-efficient execution. Our approach reduces latency by over 2x and memory by up to 35%, advancing the deployment of efficient AIF agents for real-time and embedded applications.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ Active Inference (AIF) åœ¨èµ„æºå—é™ç¯å¢ƒä¸‹éƒ¨ç½²æ—¶é¢ä¸´çš„é«˜è®¡ç®—ä¸å†…å­˜éœ€æ±‚æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§é¢å‘ç¡¬ä»¶çš„é«˜æ•ˆè®¡ç®—ä¸éƒ¨ç½²æ–¹æ³•ã€‚è¯¥æ–¹æ³•æœ‰æ•ˆæ•´åˆäº† pymdp çš„çµæ´»æ€§ä¸æ•ˆç‡ï¼Œå¹¶é‡‡ç”¨äº†ä¸“ä¸ºç¡¬ä»¶é«˜æ•ˆæ‰§è¡Œè®¾è®¡çš„ç»Ÿä¸€ç¨€ç–è®¡ç®—å›¾ (sparse computational graph) æ¶æ„ã€‚å®éªŒè¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ–¹æ³•èƒ½å°†æ¨ç†å»¶è¿Ÿé™ä½ 2 å€ä»¥ä¸Šï¼Œå¹¶å°†å†…å­˜æ¶ˆè€—å‡å°‘å¤šè¾¾ 35%ã€‚è¿™ä¸€æˆæœæå¤§æå‡äº†é«˜æ•ˆ AIF æ™ºèƒ½ä½“åœ¨å®æ—¶åŠåµŒå…¥å¼åº”ç”¨ä¸­çš„éƒ¨ç½²å¯è¡Œæ€§ã€‚è¯¥ç ”ç©¶ä¸ºèµ„æºå—é™åœºæ™¯ä¸‹çš„å¤æ‚å†³ç­–ä»»åŠ¡æä¾›äº†æ›´ä¸ºé«˜æ•ˆçš„ç¡¬ä»¶è®¡ç®—èŒƒå¼ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.13177v1",
      "published_date": "2025-08-12 09:39:46 UTC",
      "updated_date": "2025-08-12 09:39:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:50.167796+00:00"
    },
    {
      "arxiv_id": "2508.08777v1",
      "title": "Evaluating Podcast Recommendations with Profile-Aware LLM-as-a-Judge",
      "title_zh": "åŸºäºç”»åƒæ„ŸçŸ¥å¤§è¯­è¨€æ¨¡å‹è£åˆ¤çš„æ’­å®¢æ¨èè¯„ä¼°",
      "authors": [
        "Francesco Fabbri",
        "Gustavo Penha",
        "Edoardo D'Amico",
        "Alice Wang",
        "Marco De Nadai",
        "Jackie Doremus",
        "Paul Gigioli",
        "Andreas Damianou",
        "Oskar Stal",
        "Mounia Lalmas"
      ],
      "abstract": "Evaluating personalized recommendations remains a central challenge, especially in long-form audio domains like podcasts, where traditional offline metrics suffer from exposure bias and online methods such as A/B testing are costly and operationally constrained. In this paper, we propose a novel framework that leverages Large Language Models (LLMs) as offline judges to assess the quality of podcast recommendations in a scalable and interpretable manner. Our two-stage profile-aware approach first constructs natural-language user profiles distilled from 90 days of listening history. These profiles summarize both topical interests and behavioral patterns, serving as compact, interpretable representations of user preferences. Rather than prompting the LLM with raw data, we use these profiles to provide high-level, semantically rich context-enabling the LLM to reason more effectively about alignment between a user's interests and recommended episodes. This reduces input complexity and improves interpretability. The LLM is then prompted to deliver fine-grained pointwise and pairwise judgments based on the profile-episode match. In a controlled study with 47 participants, our profile-aware judge matched human judgments with high fidelity and outperformed or matched a variant using raw listening histories. The framework enables efficient, profile-aware evaluation for iterative testing and model selection in recommender systems.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ’­å®¢(Podcast)ç­‰é•¿éŸ³é¢‘é¢†åŸŸä¸ªæ€§åŒ–æ¨èè¯„ä¼°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªåä¸ºProfile-Aware LLM-as-a-Judgeçš„è¯„ä¼°æ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨ä¸¤é˜¶æ®µæ–¹æ³•ï¼Œé¦–å…ˆä»ç”¨æˆ·90å¤©çš„æ”¶å¬å†å²ä¸­æç‚¼å¹¶æ„å»ºè‡ªç„¶è¯­è¨€ç”¨æˆ·ç”»åƒ(User Profiles)ï¼Œä»¥æ€»ç»“å…¶ä¸»é¢˜å…´è¶£å’Œè¡Œä¸ºæ¨¡å¼ã€‚ä¸ç›´æ¥è¾“å…¥åŸå§‹æ•°æ®ä¸åŒï¼Œè¯¥æ–¹æ³•åˆ©ç”¨ç”»åƒæä¾›è¯­ä¹‰ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ï¼Œä½¿å¤§è¯­è¨€æ¨¡å‹(LLMs)èƒ½å¤Ÿæ›´æœ‰æ•ˆåœ°æ¨æ–­ç”¨æˆ·å…´è¶£ä¸æ¨èå•é›†ä¹‹é—´çš„åŒ¹é…ç¨‹åº¦ã€‚éšåï¼Œæ¨¡å‹æ ¹æ®ç”»åƒä¸å•é›†çš„åŒ¹é…æƒ…å†µï¼Œç»™å‡ºç»†ç²’åº¦çš„é€ç‚¹(Pointwise)å’Œæˆå¯¹(Pairwise)è¯„åˆ¤ã€‚åœ¨åŒ…å«47åå‚ä¸è€…çš„å¯¹ç…§ç ”ç©¶ä¸­ï¼Œè¯¥Profile-Awareè¯„åˆ¤æ¡†æ¶å±•ç°å‡ºäº†æé«˜çš„äººç±»è¯„åˆ¤ä¿çœŸåº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨æ€§èƒ½ä¸Šä¼˜äºæˆ–ç­‰åŒäºä½¿ç”¨åŸå§‹æ”¶å¬å†å²çš„æ–¹æ¡ˆï¼Œä¸ºæ¨èç³»ç»Ÿçš„è¿­ä»£æµ‹è¯•å’Œæ¨¡å‹é€‰æ‹©æä¾›äº†é«˜æ•ˆä¸”å…·å¯è§£é‡Šæ€§çš„ç¦»çº¿è¯„ä¼°æ‰‹æ®µã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at RecSys '25",
      "pdf_url": "https://arxiv.org/pdf/2508.08777v1",
      "published_date": "2025-08-12 09:23:35 UTC",
      "updated_date": "2025-08-12 09:23:35 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:33.272535+00:00"
    },
    {
      "arxiv_id": "2508.08774v1",
      "title": "Designing Memory-Augmented AR Agents for Spatiotemporal Reasoning in Personalized Task Assistance",
      "title_zh": "é¢å‘ä¸ªæ€§åŒ–ä»»åŠ¡è¾…åŠ©ä¸­æ—¶ç©ºæ¨ç†çš„è®°å¿†å¢å¼ºå‹ AR æ™ºèƒ½ä½“è®¾è®¡",
      "authors": [
        "Dongwook Choi",
        "Taeyoon Kwon",
        "Dongil Yang",
        "Hyojun Kim",
        "Jinyoung Yeo"
      ],
      "abstract": "Augmented Reality (AR) systems are increasingly integrating foundation models, such as Multimodal Large Language Models (MLLMs), to provide more context-aware and adaptive user experiences. This integration has led to the development of AR agents to support intelligent, goal-directed interactions in real-world environments. While current AR agents effectively support immediate tasks, they struggle with complex multi-step scenarios that require understanding and leveraging user's long-term experiences and preferences. This limitation stems from their inability to capture, retain, and reason over historical user interactions in spatiotemporal contexts. To address these challenges, we propose a conceptual framework for memory-augmented AR agents that can provide personalized task assistance by learning from and adapting to user-specific experiences over time. Our framework consists of four interconnected modules: (1) Perception Module for multimodal sensor processing, (2) Memory Module for persistent spatiotemporal experience storage, (3) Spatiotemporal Reasoning Module for synthesizing past and present contexts, and (4) Actuator Module for effective AR communication. We further present an implementation roadmap, a future evaluation strategy, a potential target application and use cases to demonstrate the practical applicability of our framework across diverse domains. We aim for this work to motivate future research toward developing more intelligent AR systems that can effectively bridge user's interaction history with adaptive, context-aware task assistance.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¢å¼ºç°å®(Augmented Reality, AR)ç³»ç»Ÿä¸­é›†æˆå¤šæ¨¡æ€å¤§è¯­è¨€æ¨¡å‹(MLLMs)ä»¥æä¾›æ›´å…·ä¸Šä¸‹æ–‡æ„ŸçŸ¥èƒ½åŠ›çš„ä¸ªæ€§åŒ–ä»»åŠ¡è¾…åŠ©ã€‚é’ˆå¯¹å½“å‰ARæ™ºèƒ½ä½“åœ¨å¤„ç†éœ€è¦é•¿æœŸç»éªŒåŠå¤æ‚æ—¶ç©ºèƒŒæ™¯(spatiotemporal context)çš„å¤šæ­¥ä»»åŠ¡æ—¶çš„å±€é™æ€§ï¼Œä½œè€…æå‡ºäº†ä¸€ç§è®°å¿†å¢å¼ºå‹ARæ™ºèƒ½ä½“(memory-augmented AR agents)çš„æ¦‚å¿µæ¡†æ¶ã€‚è¯¥æ¡†æ¶æ—¨åœ¨é€šè¿‡å­¦ä¹ å’Œé€‚åº”ç”¨æˆ·ç‰¹å®šç»éªŒæ¥æä¾›ä¸ªæ€§åŒ–æ”¯æŒï¼Œå…¶æ ¸å¿ƒç”±å››ä¸ªäº’è¿æ¨¡å—ç»„æˆï¼šæ„ŸçŸ¥æ¨¡å—(Perception Module)è´Ÿè´£å¤šæ¨¡æ€ä¼ æ„Ÿå™¨å¤„ç†ï¼Œè®°å¿†æ¨¡å—(Memory Module)ç”¨äºæŒä¹…æ€§æ—¶ç©ºç»éªŒå­˜å‚¨ï¼Œæ—¶ç©ºæ¨ç†æ¨¡å—(Spatiotemporal Reasoning Module)è´Ÿè´£åˆæˆè¿‡å»ä¸ç°åœ¨çš„ä¸Šä¸‹æ–‡ï¼Œæ‰§è¡Œæ¨¡å—(Actuator Module)åˆ™ç”¨äºå®ç°æœ‰æ•ˆçš„ARæ²Ÿé€šã€‚æ­¤å¤–ï¼Œæ–‡ä¸­è¿˜æå‡ºäº†å®ç°è·¯çº¿å›¾ã€è¯„ä¼°ç­–ç•¥åŠåº”ç”¨æ¡ˆä¾‹ï¼Œå±•ç¤ºäº†è¯¥æ¡†æ¶åœ¨ä¸åŒé¢†åŸŸçš„å®ç”¨æ€§ã€‚è¯¥å·¥ä½œæ—¨åœ¨æ¿€åŠ±æœªæ¥ç ”ç©¶å¼€å‘å‡ºèƒ½å°†ç”¨æˆ·äº¤äº’å†å²ä¸è‡ªé€‚åº”ã€ä¸Šä¸‹æ–‡æ„ŸçŸ¥ä»»åŠ¡è¾…åŠ©æœ‰æ•ˆç»“åˆçš„æ™ºèƒ½åŒ–ARç³»ç»Ÿã€‚",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "7 pages, 2 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08774v1",
      "published_date": "2025-08-12 09:20:20 UTC",
      "updated_date": "2025-08-12 09:20:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:37.253099+00:00"
    },
    {
      "arxiv_id": "2508.08765v2",
      "title": "Bridging the Gap: A Framework for Real-World Video Deepfake Detection via Social Network Compression Emulation",
      "title_zh": "å¼¥åˆå·®è·ï¼šåŸºäºç¤¾äº¤ç½‘ç»œå‹ç¼©ä»¿çœŸçš„çœŸå®åœºæ™¯è§†é¢‘æ·±åº¦ä¼ªé€ æ£€æµ‹æ¡†æ¶",
      "authors": [
        "Andrea Montibeller",
        "Dasara Shullani",
        "Daniele Baracchi",
        "Alessandro Piva",
        "Giulia Boato"
      ],
      "abstract": "The growing presence of AI-generated videos on social networks poses new challenges for deepfake detection, as detectors trained under controlled conditions often fail to generalize to real-world scenarios. A key factor behind this gap is the aggressive, proprietary compression applied by platforms like YouTube and Facebook, which launder low-level forensic cues. However, replicating these transformations at scale is difficult due to API limitations and data-sharing constraints. For these reasons, we propose a first framework that emulates the video sharing pipelines of social networks by estimating compression and resizing parameters from a small set of uploaded videos. These parameters enable a local emulator capable of reproducing platform-specific artifacts on large datasets without direct API access. Experiments on FaceForensics++ videos shared via social networks demonstrate that our emulated data closely matches the degradation patterns of real uploads. Furthermore, detectors fine-tuned on emulated videos achieve comparable performance to those trained on actual shared media. Our approach offers a scalable and practical solution for bridging the gap between lab-based training and real-world deployment of deepfake detectors, particularly in the underexplored domain of compressed video content.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç¤¾äº¤ç½‘ç»œä¸Š AI ç”Ÿæˆè§†é¢‘ç»™ deepfake æ£€æµ‹å¸¦æ¥çš„æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºç¤¾äº¤å¹³å°é‡‡ç”¨çš„ä¸“æœ‰ compression å’Œ resizing ä¼šæ¶ˆé™¤åº•å±‚çš„å–è¯çº¿ç´¢ï¼Œå¯¼è‡´åœ¨å—æ§ç¯å¢ƒä¸‹è®­ç»ƒçš„æ£€æµ‹å™¨éš¾ä»¥æ³›åŒ–è‡³çœŸå®åœºæ™¯ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†é¦–ä¸ªé€šè¿‡æ¨¡æ‹Ÿç¤¾äº¤ç½‘ç»œè§†é¢‘åˆ†äº«æµç¨‹çš„æ£€æµ‹æ¡†æ¶ï¼Œè¯¥æ¡†æ¶èƒ½ä»å°‘é‡ä¸Šä¼ è§†é¢‘ä¸­ä¼°è®¡å‹ç¼©å’Œç¼©æ”¾å‚æ•°ï¼Œè¿›è€Œæ„å»ºæœ¬åœ° emulator ä»¥åœ¨å¤§è§„æ¨¡æ•°æ®é›†ä¸Šé‡ç°ç‰¹å®šå¹³å°çš„ artifactsã€‚åœ¨ FaceForensics++ æ•°æ®é›†ä¸Šçš„å®éªŒè¡¨æ˜ï¼Œæ¨¡æ‹Ÿç”Ÿæˆçš„æ•°æ®ä¸çœŸå®ç¤¾äº¤ç½‘ç»œä¸Šä¼ è§†é¢‘çš„é™è´¨æ¨¡å¼é«˜åº¦ä¸€è‡´ã€‚æ­¤å¤–ï¼Œåœ¨è¯¥æ¨¡æ‹Ÿæ•°æ®ä¸Šè¿›è¡Œå¾®è°ƒçš„æ£€æµ‹å™¨è¾¾åˆ°äº†ä¸ä½¿ç”¨çœŸå®ç¤¾äº¤åª’ä½“æ•°æ®è®­ç»ƒç›¸å½“çš„æ€§èƒ½ã€‚è¯¥æ–¹æ³•ä¸ºå¼¥åˆå®éªŒå®¤è®­ç»ƒä¸ç°å®éƒ¨ç½²ä¹‹é—´çš„å·®è·æä¾›äº†ä¸€ç§å¯æ‰©å±•ä¸”å®ç”¨çš„è§£å†³æ–¹æ¡ˆï¼Œç‰¹åˆ«æ˜¯åœ¨ç›®å‰ç ”ç©¶è¾ƒå°‘çš„å‹ç¼©è§†é¢‘å†…å®¹ deepfake æ£€æµ‹é¢†åŸŸå…·æœ‰é‡è¦æ„ä¹‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08765v2",
      "published_date": "2025-08-12 09:11:31 UTC",
      "updated_date": "2025-09-12 17:29:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:42.388863+00:00"
    },
    {
      "arxiv_id": "2508.08761v1",
      "title": "DevNous: An LLM-Based Multi-Agent System for Grounding IT Project Management in Unstructured Conversation",
      "title_zh": "DevNousï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼Œç”¨äºåœ¨éç»“æ„åŒ–å¯¹è¯ä¸­å®ç° IT é¡¹ç›®ç®¡ç†è½åœ°",
      "authors": [
        "Stavros Doropoulos",
        "Stavros Vologiannidis",
        "Ioannis Magnisalis"
      ],
      "abstract": "The manual translation of unstructured team dialogue into the structured artifacts required for Information Technology (IT) project governance is a critical bottleneck in modern information systems management. We introduce DevNous, a Large Language Model-based (LLM) multi-agent expert system, to automate this unstructured-to-structured translation process. DevNous integrates directly into team chat environments, identifying actionable intents from informal dialogue and managing stateful, multi-turn workflows for core administrative tasks like automated task formalization and progress summary synthesis. To quantitatively evaluate the system, we introduce a new benchmark of 160 realistic, interactive conversational turns. The dataset was manually annotated with a multi-label ground truth and is publicly available. On this benchmark, DevNous achieves an exact match turn accuracy of 81.3\\% and a multiset F1-Score of 0.845, providing strong evidence for its viability. The primary contributions of this work are twofold: (1) a validated architectural pattern for developing ambient administrative agents, and (2) the introduction of the first robust empirical baseline and public benchmark dataset for this challenging problem domain.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£ä¿¡æ¯ç³»ç»Ÿç®¡ç†ä¸­å°†éç»“æ„åŒ–å›¢é˜Ÿå¯¹è¯è½¬åŒ–ä¸ºç»“æ„åŒ– IT é¡¹ç›®æ²»ç†æˆæœçš„ç“¶é¢ˆï¼Œæå‡ºäº† DevNousï¼Œä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„å¤šæ™ºèƒ½ä½“ (multi-agent) ä¸“å®¶ç³»ç»Ÿã€‚DevNous ç›´æ¥é›†æˆäºå›¢é˜ŸèŠå¤©ç¯å¢ƒï¼Œèƒ½å¤Ÿä»éæ­£å¼å¯¹è¯ä¸­è¯†åˆ«å¯æ‰§è¡Œæ„å›¾ï¼Œå¹¶é’ˆå¯¹ä»»åŠ¡æ­£å¼åŒ– (task formalization) å’Œè¿›åº¦æ‘˜è¦åˆæˆç­‰æ ¸å¿ƒè¡Œæ”¿ä»»åŠ¡ç®¡ç†æœ‰çŠ¶æ€çš„å¤šè½®å·¥ä½œæµã€‚ä¸ºäº†å®šé‡è¯„ä¼°è¯¥ç³»ç»Ÿï¼Œç ”ç©¶å›¢é˜Ÿæ¨å‡ºäº†ä¸€ä¸ªåŒ…å« 160 ä¸ªçœŸå®äº¤äº’å¯¹è¯è½®æ¬¡çš„å…¨æ–°åŸºå‡†æ•°æ®é›†ï¼Œå¹¶è¿›è¡Œäº†äººå·¥å¤šæ ‡ç­¾æ ‡æ³¨ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒDevNous åœ¨è¯¥åŸºå‡†ä¸Šå®ç°äº† 81.3% çš„ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡å’Œ 0.845 çš„ multiset F1-Scoreï¼Œæœ‰åŠ›è¯æ˜äº†å…¶æ–¹æ¡ˆçš„å¯è¡Œæ€§ã€‚è¯¥å·¥ä½œçš„ä¸»è¦è´¡çŒ®åœ¨äºæä¾›äº†ä¸€ç§ç”¨äºå¼€å‘ç¯å¢ƒè¡Œæ”¿æ™ºèƒ½ä½“ (ambient administrative agents) çš„æ¶æ„æ¨¡å¼ï¼Œå¹¶ä¸ºè¯¥ç ”ç©¶é¢†åŸŸå¼•å…¥äº†é¦–ä¸ªç¨³å¥çš„å®è¯åŸºçº¿å’Œå…¬å¼€åŸºå‡†æ•°æ®é›†ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08761v1",
      "published_date": "2025-08-12 09:08:29 UTC",
      "updated_date": "2025-08-12 09:08:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:20:50.999716+00:00"
    },
    {
      "arxiv_id": "2508.08748v1",
      "title": "Visual Prompting for Robotic Manipulation with Annotation-Guided Pick-and-Place Using ACT",
      "title_zh": "åŸºäº ACT ä¸æ ‡æ³¨å¼•å¯¼æ‹¾å–-æ”¾ç½®çš„æœºå™¨äººæ“ä½œè§†è§‰æç¤º",
      "authors": [
        "Muhammad A. Muttaqien",
        "Tomohiro Motoda",
        "Ryo Hanai",
        "Yukiyasu Domae"
      ],
      "abstract": "Robotic pick-and-place tasks in convenience stores pose challenges due to dense object arrangements, occlusions, and variations in object properties such as color, shape, size, and texture. These factors complicate trajectory planning and grasping. This paper introduces a perception-action pipeline leveraging annotation-guided visual prompting, where bounding box annotations identify both pickable objects and placement locations, providing structured spatial guidance. Instead of traditional step-by-step planning, we employ Action Chunking with Transformers (ACT) as an imitation learning algorithm, enabling the robotic arm to predict chunked action sequences from human demonstrations. This facilitates smooth, adaptive, and data-driven pick-and-place operations. We evaluate our system based on success rate and visual analysis of grasping behavior, demonstrating improved grasp accuracy and adaptability in retail environments.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¾¿åˆ©åº—åœºæ™¯ä¸­å› ç‰©ä½“æ‘†æ”¾å¯†é›†ã€é®æŒ¡ä»¥åŠå±æ€§å¤šæ ·æ€§å¯¼è‡´æœºå™¨äººæŠ“å–å›°éš¾çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§ç»“åˆè§†è§‰æç¤º (Visual Prompting) ä¸æ¨¡ä»¿å­¦ä¹ çš„æ„ŸçŸ¥-åŠ¨ä½œæµç¨‹ã€‚è¯¥æ–¹æ³•åˆ©ç”¨æ ‡æ³¨å¼•å¯¼çš„è§†è§‰æç¤ºæŠ€æœ¯ï¼Œé€šè¿‡è¾¹ç•Œæ¡† (Bounding Box) æ ‡æ³¨è¯†åˆ«å¯æŠ“å–ç‰©ä½“åŠæ”¾ç½®ä½ç½®ï¼Œä¸ºç³»ç»Ÿæä¾›ç»“æ„åŒ–çš„ç©ºé—´å¼•å¯¼ã€‚ä¸åŒäºä¼ ç»Ÿçš„é€æ­¥è§„åˆ’ï¼Œç ”ç©¶é‡‡ç”¨äº†åŸºäº Transformer çš„åŠ¨ä½œåˆ†å—æŠ€æœ¯ (Action Chunking with Transformers, ACT) ä½œä¸ºæ¨¡ä»¿å­¦ä¹ ç®—æ³•ï¼Œä½¿æœºå™¨äººèƒ½å¤Ÿä»äººç±»æ¼”ç¤ºä¸­é¢„æµ‹åˆ†å—çš„åŠ¨ä½œåºåˆ—ã€‚è¿™ç§è®¾è®¡ä¿ƒè¿›äº†å¹³æ»‘ã€è‡ªé€‚åº”ä¸”æ•°æ®é©±åŠ¨çš„æ‹¾å–ä¸æ”¾ç½®æ“ä½œï¼Œå¢å¼ºäº†æœºå™¨äººåœ¨å¤æ‚åŠ¨æ€é›¶å”®ç¯å¢ƒä¸­çš„è¡¨ç°ã€‚å®éªŒé€šè¿‡æˆåŠŸç‡å’ŒæŠ“å–è¡Œä¸ºçš„è§†è§‰åˆ†æè¿›è¡Œè¯„ä¼°ï¼Œç»“æœè¡¨æ˜è¯¥ç³»ç»Ÿæ˜¾è‘—æé«˜äº†æŠ“å–çš„å‡†ç¡®æ€§å’Œé€‚åº”æ€§ï¼Œè¯æ˜äº†ç»“åˆæ ‡æ³¨å¼•å¯¼ä¸æ¨¡ä»¿å­¦ä¹ åœ¨å¤„ç†å¤æ‚æ“ä½œä»»åŠ¡ä¸­çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08748v1",
      "published_date": "2025-08-12 08:45:09 UTC",
      "updated_date": "2025-08-12 08:45:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:29.093015+00:00"
    },
    {
      "arxiv_id": "2508.14074v1",
      "title": "GEPD:GAN-Enhanced Generalizable Model for EEG-Based Detection of Parkinson's Disease",
      "title_zh": "GEPDï¼šåŸºäº GAN å¢å¼ºçš„è„‘ç”µå›¾å¸•é‡‘æ£®ç—…æ£€æµ‹å¯æ³›åŒ–æ¨¡å‹",
      "authors": [
        "Qian Zhang",
        "Ruilin Zhang",
        "Biaokai Zhu",
        "Xun Han",
        "Jun Xiao",
        "Yifan Liu",
        "Zhe Wang"
      ],
      "abstract": "Electroencephalography has been established as an effective method for detecting Parkinson's disease, typically diagnosed early.Current Parkinson's disease detection methods have shown significant success within individual datasets, however, the variability in detection methods across different EEG datasets and the small size of each dataset pose challenges for training a generalizable model for cross-dataset scenarios. To address these issues, this paper proposes a GAN-enhanced generalizable model, named GEPD, specifically for EEG-based cross-dataset classification of Parkinson's disease.First, we design a generative network that creates fusion EEG data by controlling the distribution similarity between generated data and real data.In addition, an EEG signal quality assessment model is designed to ensure the quality of generated data great.Second, we design a classification network that utilizes a combination of multiple convolutional neural networks to effectively capture the time-frequency characteristics of EEG signals, while maintaining a generalizable structure and ensuring easy convergence.This work is dedicated to utilizing intelligent methods to study pathological manifestations, aiming to facilitate the diagnosis and monitoring of neurological diseases.The evaluation results demonstrate that our model performs comparably to state-of-the-art models in cross-dataset settings, achieving an accuracy of 84.3% and an F1-score of 84.0%, showcasing the generalizability of the proposed model.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åä¸ºGEPDçš„GANå¢å¼ºé€šç”¨æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³åŸºäºè„‘ç”µå›¾(EEG)æ£€æµ‹å¸•é‡‘æ£®ç—…(Parkinson's Disease)æ—¶é¢ä¸´çš„è·¨æ•°æ®é›†å˜å¼‚æ€§å’Œæ ·æœ¬é‡ä¸è¶³ç­‰æŒ‘æˆ˜ã€‚è¯¥æ¨¡å‹é¦–å…ˆé€šè¿‡ç”Ÿæˆç½‘ç»œæ§åˆ¶ç”Ÿæˆæ•°æ®ä¸çœŸå®æ•°æ®ä¹‹é—´çš„åˆ†å¸ƒç›¸ä¼¼æ€§ï¼Œä»¥æ­¤åˆ›å»ºèåˆEEGæ•°æ®ï¼Œå¹¶åˆ©ç”¨ä¿¡å·è´¨é‡è¯„ä¼°æ¨¡å‹ç¡®ä¿ç”Ÿæˆæ•°æ®çš„è´¨é‡ã€‚æ­¤å¤–ï¼ŒGEPDè®¾è®¡äº†ä¸€ä¸ªç»“åˆå¤šä¸ªå·ç§¯ç¥ç»ç½‘ç»œ(CNN)çš„åˆ†ç±»ç½‘ç»œï¼Œèƒ½å¤Ÿæœ‰æ•ˆæ•è·EEGä¿¡å·çš„æ—¶é¢‘ç‰¹å¾ï¼ŒåŒæ—¶ä¿æŒç»“æ„é€šç”¨å¹¶ç¡®ä¿æ˜“äºæ”¶æ•›ã€‚è¿™é¡¹å·¥ä½œè‡´åŠ›äºé€šè¿‡æ™ºèƒ½åŒ–æ–¹æ³•ç ”ç©¶ç—…ç†è¡¨ç°ï¼Œæ—¨åœ¨ä¿ƒè¿›ç¥ç»ç³»ç»Ÿç–¾ç—…çš„è¯Šæ–­å’Œç›‘æµ‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹åœ¨è·¨æ•°æ®é›†è®¾ç½®ä¸‹å®ç°äº†84.3%çš„å‡†ç¡®ç‡å’Œ84.0%çš„F1-scoreï¼Œæ€§èƒ½ä¸ç°æœ‰æœ€å…ˆè¿›æ¨¡å‹ç›¸å½“ï¼Œå……åˆ†éªŒè¯äº†æ‰€ææ¨¡å‹çš„é€šç”¨æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by International Conference on Intelligent Computing(ICIC 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.14074v1",
      "published_date": "2025-08-12 08:37:14 UTC",
      "updated_date": "2025-08-12 08:37:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:05.243831+00:00"
    },
    {
      "arxiv_id": "2508.08742v2",
      "title": "SciRerankBench: Benchmarking Rerankers Towards Scientific Retrieval-Augmented Generated LLMs",
      "title_zh": "SciRerankBenchï¼šé¢å‘ç§‘å­¦é¢†åŸŸæ£€ç´¢å¢å¼ºç”Ÿæˆå¤§è¯­è¨€æ¨¡å‹çš„é‡æ’åºå™¨åŸºå‡†æµ‹è¯•",
      "authors": [
        "Haotian Chen",
        "Qingqing Long",
        "Meng Xiao",
        "Xiao Luo",
        "Wei Ju",
        "Chengrui Wang",
        "Xuezhi Wang",
        "Yuanchun Zhou",
        "Hengshu Zhu"
      ],
      "abstract": "Scientific literature question answering is a pivotal step towards new scientific discoveries. Recently, \\textit{two-stage} retrieval-augmented generated large language models (RAG-LLMs) have shown impressive advancements in this domain. Such a two-stage framework, especially the second stage (reranker), is particularly essential in the scientific domain, where subtle differences in terminology may have a greatly negative impact on the final factual-oriented or knowledge-intensive answers. Despite this significant progress, the potential and limitations of these works remain unexplored. In this work, we present a Scientific Rerank-oriented RAG Benchmark (SciRerankBench), for evaluating rerankers within RAG-LLMs systems, spanning five scientific subjects. To rigorously assess the reranker performance in terms of noise resilience, relevance disambiguation, and factual consistency, we develop three types of question-context-answer (Q-C-A) pairs, i.e., Noisy Contexts (NC), Semantically Similar but Logically Irrelevant Contexts (SSLI), and Counterfactual Contexts (CC). Through systematic evaluation of 13 widely used rerankers on five families of LLMs, we provide detailed insights into their relative strengths and limitations. To the best of our knowledge, SciRerankBench is the first benchmark specifically developed to evaluate rerankers within RAG-LLMs, which provides valuable observations and guidance for their future development.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†SciRerankBenchï¼Œè¿™æ˜¯é¦–ä¸ªä¸“é—¨ç”¨äºè¯„ä¼°ç§‘å­¦é¢†åŸŸæ£€ç´¢å¢å¼ºç”Ÿæˆå¤§è¯­è¨€æ¨¡å‹ï¼ˆRAG-LLMsï¼‰ä¸­é‡æ’åºå™¨ï¼ˆRerankerï¼‰æ€§èƒ½çš„åŸºå‡†æµ‹è¯•ã€‚é’ˆå¯¹ç§‘å­¦æ–‡çŒ®ä¸­æœ¯è¯­ç»†å¾®å·®åˆ«å¯¹äº‹å®å¯¼å‘ç­”æ¡ˆçš„è´Ÿé¢å½±å“ï¼Œè¯¥åŸºå‡†æ¶µç›–äº†äº”ä¸ªç§‘å­¦å­¦ç§‘ï¼Œæ—¨åœ¨ä¸¥è°¨è¯„ä¼°é‡æ’åºå™¨çš„å™ªå£°æŠ—æ€§ã€å…³è”æ­§ä¹‰æ¶ˆé™¤å’Œäº‹å®ä¸€è‡´æ€§ã€‚ç ”ç©¶å›¢é˜Ÿå¼€å‘äº†å™ªå£°èƒŒæ™¯ï¼ˆNCï¼‰ã€è¯­ä¹‰ç›¸ä¼¼ä½†é€»è¾‘æ— å…³èƒŒæ™¯ï¼ˆSSLIï¼‰ä»¥åŠåäº‹å®èƒŒæ™¯ï¼ˆCCï¼‰ä¸‰ç±»é—®ç­”å¯¹ï¼Œå¯¹13ç§å¹¿æ³›ä½¿ç”¨çš„é‡æ’åºå™¨åœ¨5ä¸ªå¤§æ¨¡å‹ç³»åˆ—ä¸Šè¿›è¡Œäº†ç³»ç»Ÿè¯„ä¼°ã€‚å®éªŒç»“æœè¯¦ç»†æ­ç¤ºäº†ç°æœ‰é‡æ’åºå™¨çš„ç›¸å¯¹ä¼˜åŠ¿ä¸å±€é™æ€§ï¼Œå¹¶ä¸ºç§‘å­¦é¢†åŸŸRAGç³»ç»Ÿçš„æœªæ¥å¼€å‘æä¾›äº†å®è´µçš„æŒ‡å¯¼å»ºè®®ã€‚SciRerankBenchçš„æ¨å‡ºå¡«è¡¥äº†è¯¥é¢†åŸŸé‡æ’åºå™¨ä¸“é¡¹è¯„ä¼°çš„ç©ºç™½ï¼Œä¸ºæ„å»ºæ›´ç²¾ç¡®ã€å¯é çš„ç§‘å­¦çŸ¥è¯†é—®ç­”ç³»ç»Ÿæä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08742v2",
      "published_date": "2025-08-12 08:36:23 UTC",
      "updated_date": "2025-09-24 07:37:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:20.189371+00:00"
    },
    {
      "arxiv_id": "2508.09232v2",
      "title": "PETLP: A Privacy-by-Design Pipeline for Social Media Data in AI Research",
      "title_zh": "PETLPï¼šé¢å‘äººå·¥æ™ºèƒ½ç ”ç©¶ä¸­ç¤¾äº¤åª’ä½“æ•°æ®çš„éšç§ä¿æŠ¤è®¾è®¡æµç¨‹",
      "authors": [
        "Nick Oh",
        "Giorgos D. Vrakas",
        "SiÃ¢n J. M. Brooke",
        "Sasha MoriniÃ¨re",
        "Toju Duke"
      ],
      "abstract": "Social media data presents AI researchers with overlapping obligations under the GDPR, copyright law, and platform terms -- yet existing frameworks fail to integrate these regulatory domains, leaving researchers without unified guidance. We introduce PETLP (Privacy-by-design Extract, Transform, Load, and Present), a compliance framework that embeds legal safeguards directly into extended ETL pipelines. Central to PETLP is treating Data Protection Impact Assessments as living documents that evolve from pre-registration through dissemination. Through systematic Reddit analysis, we demonstrate how extraction rights fundamentally differ between qualifying research organisations (who can invoke DSM Article 3 to override platform restrictions) and commercial entities (bound by terms of service), whilst GDPR obligations apply universally. We demonstrate why true anonymisation remains unachievable for social media data and expose the legal gap between permitted dataset creation and uncertain model distribution. By structuring compliance decisions into practical workflows and simplifying institutional data management plans, PETLP enables researchers to navigate regulatory complexity with confidence, bridging the gap between legal requirements and research practice.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†PETLPï¼ˆPrivacy-by-design Extract, Transform, Load, and Presentï¼‰ï¼Œè¿™æ˜¯ä¸€ä¸ªæ—¨åœ¨æ•´åˆGDPRã€ç‰ˆæƒæ³•å’Œå¹³å°æ¡æ¬¾çš„åˆè§„æ¡†æ¶ï¼Œä¸“é—¨ç”¨äºè§£å†³AIç ”ç©¶ä¸­ç¤¾äº¤åª’ä½“æ•°æ®å¤„ç†çš„æ³•å¾‹æŒ‡å¼•ç¼ºå¤±é—®é¢˜ã€‚è¯¥æ¡†æ¶å°†æ³•å¾‹ä¿éšœç›´æ¥åµŒå…¥æ‰©å±•çš„ETLæµæ°´çº¿ï¼Œå¹¶å°†æ•°æ®ä¿æŠ¤å½±å“è¯„ä¼°ï¼ˆDPIAï¼‰è§†ä¸ºè´¯ç©¿ç ”ç©¶å…¨ç”Ÿå‘½å‘¨æœŸçš„åŠ¨æ€æ–‡æ¡£ã€‚é€šè¿‡å¯¹Redditæ•°æ®çš„ç³»ç»Ÿåˆ†æï¼Œç ”ç©¶å¯¹æ¯”äº†åˆèµ„æ ¼ç ”ç©¶æœºæ„ä¸å•†ä¸šå®ä½“åœ¨æ•°æ®æå–æƒä¸Šçš„å·®å¼‚ï¼Œå¹¶è®ºè¯äº†ç¤¾äº¤åª’ä½“æ•°æ®å®ç°çœŸæ­£åŒ¿ååŒ–ï¼ˆAnonymisationï¼‰çš„ä¸å¯è¡Œæ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶æ­ç¤ºäº†æ•°æ®é›†åˆ›å»ºä¸æ¨¡å‹åˆ†å‘ä¹‹é—´å­˜åœ¨çš„æ³•å¾‹é¸¿æ²Ÿã€‚PETLPé€šè¿‡å°†åˆè§„å†³ç­–è½¬åŒ–ä¸ºå…·ä½“å·¥ä½œæµå¹¶ç®€åŒ–æœºæ„æ•°æ®ç®¡ç†è®¡åˆ’ï¼Œæœ‰æ•ˆå¼¥è¡¥äº†æ³•å¾‹ç›‘ç®¡ä¸ç ”ç©¶å®è·µä¹‹é—´çš„å·®è·ï¼Œæå‡äº†ç ”ç©¶äººå‘˜åœ¨å¤æ‚ç›‘ç®¡ç¯å¢ƒä¸‹å¼€å±•å·¥ä½œçš„åˆè§„ä¿¡å¿ƒã€‚",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.MM",
      "comment": "Extended version of paper to appear in the 8th AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.09232v2",
      "published_date": "2025-08-12 08:33:40 UTC",
      "updated_date": "2025-10-16 07:38:09 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:27.692578+00:00"
    },
    {
      "arxiv_id": "2509.09681v2",
      "title": "DB3 Team's Solution For Meta KDD Cup' 25",
      "title_zh": "DB3å›¢é˜Ÿåœ¨Meta KDD Cup' 25ä¸­çš„è§£å†³æ–¹æ¡ˆ",
      "authors": [
        "Yikuan Xia",
        "Jiazun Chen",
        "Yirui Zhan",
        "Suifeng Zhao",
        "Weipeng Jiang",
        "Chaorui Zhang",
        "Wei Han",
        "Bo Bai",
        "Jun Gao"
      ],
      "abstract": "This paper presents the db3 team's winning solution for the Meta CRAG-MM Challenge 2025 at KDD Cup'25. Addressing the challenge's unique multi-modal, multi-turn question answering benchmark (CRAG-MM), we developed a comprehensive framework that integrates tailored retrieval pipelines for different tasks with a unified LLM-tuning approach for hallucination control. Our solution features (1) domain-specific retrieval pipelines handling image-indexed knowledge graphs, web sources, and multi-turn conversations; and (2) advanced refusal training using SFT, DPO, and RL. The system achieved 2nd place in Task 1, 2nd place in Task 2, and 1st place in Task 3, securing the grand prize for excellence in ego-centric queries through superior handling of first-person perspective challenges.",
      "tldr_zh": "æœ¬ç ”ç©¶ä»‹ç»äº† db3 å›¢é˜Ÿåœ¨ KDD Cup'25 çš„ Meta CRAG-MM æŒ‘æˆ˜èµ›ä¸­çš„è·èƒœæ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€ã€å¤šè½®é—®ç­”åŸºå‡†æµ‹è¯•ä¸­çš„æ ¸å¿ƒéš¾é¢˜ã€‚è¯¥æ–¹æ¡ˆå¼€å‘äº†ä¸€ä¸ªç»¼åˆæ¡†æ¶ï¼Œå°†é’ˆå¯¹ä¸åŒä»»åŠ¡å®šåˆ¶çš„æ£€ç´¢æµæ°´çº¿ï¼ˆretrieval pipelinesï¼‰ä¸ç”¨äºå¹»è§‰æ§åˆ¶ï¼ˆhallucination controlï¼‰çš„ç»Ÿä¸€ LLM-tuning æ–¹æ³•ç›¸ç»“åˆã€‚å…¶æŠ€æœ¯ç‰¹è‰²åŒ…æ‹¬å¤„ç†å›¾åƒç´¢å¼•çŸ¥è¯†å›¾è°±ï¼ˆimage-indexed knowledge graphsï¼‰ã€ç½‘ç»œèµ„æºå’Œå¤šè½®å¯¹è¯çš„é¢†åŸŸç‰¹å®šæ£€ç´¢æŠ€æœ¯ï¼Œä»¥åŠç»“åˆäº† SFTã€DPO å’Œ RL çš„é«˜çº§æ‹’ç»è®­ç»ƒï¼ˆrefusal trainingï¼‰æœºåˆ¶ã€‚å‡­å€Ÿå¯¹ç¬¬ä¸€äººç§°è§†è§’ï¼ˆfirst-person perspectiveï¼‰æŒ‘æˆ˜çš„å“è¶Šå¤„ç†èƒ½åŠ›ï¼Œè¯¥ç³»ç»Ÿåœ¨ Task 1 å’Œ Task 2 ä¸­è·å¾—ç¬¬äºŒåï¼Œå¹¶åœ¨ Task 3 ä¸­å¤ºå¾—ç¬¬ä¸€åã€‚æœ€ç»ˆï¼Œè¯¥å›¢é˜Ÿå› åœ¨è‡ªæˆ‘ä¸­å¿ƒæŸ¥è¯¢ï¼ˆego-centric queriesï¼‰æ–¹é¢çš„æ°å‡ºè¡¨ç°è£è·å¤§å¥–ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨å¤æ‚å¤šæ¨¡æ€äº¤äº’åœºæ™¯ä¸‹çš„ä¼˜è¶Šæ€§ã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2509.09681v2",
      "published_date": "2025-08-12 08:27:53 UTC",
      "updated_date": "2026-01-12 05:54:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:23.388110+00:00"
    },
    {
      "arxiv_id": "2508.14073v2",
      "title": "MCLPD:Multi-view Contrastive Learning for EEG-based PD Detection Across Datasets",
      "title_zh": "MCLPDï¼šç”¨äºè·¨æ•°æ®é›†è„‘ç”µå›¾å¸•é‡‘æ£®ç—…æ£€æµ‹çš„å¤šè§†å›¾å¯¹æ¯”å­¦ä¹ ",
      "authors": [
        "Qian Zhang",
        "Ruilin Zhang",
        "Jun Xiao",
        "Yifan Liu",
        "Zhe Wang"
      ],
      "abstract": "Electroencephalography has been validated as an effective technique for detecting Parkinson's disease,particularly in its early stages.However,the high cost of EEG data annotation often results in limited dataset size and considerable discrepancies across datasets,including differences in acquisition protocols and subject demographics,significantly hinder the robustness and generalizability of models in cross-dataset detection scenarios.To address such challenges,this paper proposes a semi-supervised learning framework named MCLPD,which integrates multi-view contrastive pre-training with lightweight supervised fine-tuning to enhance cross-dataset PD detection performance.During pre-training,MCLPD uses self-supervised learning on the unlabeled UNM dataset.To build contrastive pairs,it applies dual augmentations in both time and frequency domains,which enrich the data and naturally fuse time-frequency information.In the fine-tuning phase,only a small proportion of labeled data from another two datasets (UI and UC)is used for supervised optimization.Experimental results show that MCLPD achieves F1 scores of 0.91 on UI and 0.81 on UC using only 1%of labeled data,which further improve to 0.97 and 0.87,respectively,when 5%of labeled data is used.Compared to existing methods,MCLPD substantially improves cross-dataset generalization while reducing the dependency on labeled data,demonstrating the effectiveness of the proposed framework.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MCLPDï¼Œä¸€ç§ç”¨äºè·¨æ•°æ®é›†å¸•é‡‘æ£®ç—…(Parkinson's disease, PD)æ£€æµ‹çš„å¤šè§†å›¾å¯¹æ¯”å­¦ä¹ æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³è„‘ç”µå›¾(EEG)æ•°æ®æ ‡æ³¨æˆæœ¬é«˜ä»¥åŠä¸åŒæ•°æ®é›†é—´å·®å¼‚å¯¼è‡´çš„æ¨¡å‹é²æ£’æ€§å·®ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŠç›‘ç£å­¦ä¹ ç­–ç•¥ï¼Œåœ¨é¢„è®­ç»ƒé˜¶æ®µåˆ©ç”¨æ— æ ‡ç­¾çš„UNMæ•°æ®é›†è¿›è¡Œè‡ªç›‘ç£å­¦ä¹ ï¼Œé€šè¿‡åœ¨æ—¶åŸŸå’Œé¢‘åŸŸåº”ç”¨åŒé‡æ•°æ®å¢å¼ºæ„å»ºå¯¹æ¯”å¯¹ï¼Œæœ‰æ•ˆèåˆäº†æ—¶é¢‘ä¿¡æ¯ã€‚åœ¨å¾®è°ƒé˜¶æ®µï¼ŒMCLPDä»…éœ€UIå’ŒUCæ•°æ®é›†æå°‘é‡çš„æœ‰æ ‡ç­¾æ•°æ®è¿›è¡Œä¼˜åŒ–ï¼Œæ˜¾è‘—é™ä½äº†å¯¹æ ‡æ³¨æ•°æ®çš„ä¾èµ–ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨ä»…ä½¿ç”¨1%æ ‡ç­¾æ•°æ®æ—¶ï¼ŒMCLPDåœ¨UIå’ŒUCæ•°æ®é›†ä¸Šçš„F1åˆ†æ•°åˆ†åˆ«è¾¾åˆ°0.91å’Œ0.81ï¼Œå½“æ ‡ç­¾æ¯”ä¾‹å‡è‡³5%æ—¶ï¼Œæ€§èƒ½è¿›ä¸€æ­¥æå‡è‡³0.97å’Œ0.87ã€‚ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”ï¼Œè¯¥æ¡†æ¶æ˜¾è‘—å¢å¼ºäº†è·¨æ•°æ®é›†çš„æ³›åŒ–èƒ½åŠ›ï¼Œä¸ºä½æ ‡æ³¨æˆæœ¬ä¸‹çš„é²æ£’æ€§PDæ£€æµ‹æä¾›äº†æœ‰æ•ˆæ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Acccepted by European Conference on Artificial Intelligence(ECAI 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.14073v2",
      "published_date": "2025-08-12 08:19:27 UTC",
      "updated_date": "2025-08-21 07:34:07 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:52.790258+00:00"
    },
    {
      "arxiv_id": "2508.09231v1",
      "title": "Beyond Technocratic XAI: The Who, What & How in Explanation Design",
      "title_zh": "è¶…è¶ŠæŠ€æœ¯å®˜åƒšå¼ XAIï¼šè§£é‡Šè®¾è®¡ä¸­çš„å—ä¼—ã€å†…å®¹ä¸æ–¹å¼",
      "authors": [
        "Ruchira Dhar",
        "Stephanie Brandl",
        "Ninell Oldenburg",
        "Anders SÃ¸gaard"
      ],
      "abstract": "The field of Explainable AI (XAI) offers a wide range of techniques for making complex models interpretable. Yet, in practice, generating meaningful explanations is a context-dependent task that requires intentional design choices to ensure accessibility and transparency. This paper reframes explanation as a situated design process -- an approach particularly relevant for practitioners involved in building and deploying explainable systems. Drawing on prior research and principles from design thinking, we propose a three-part framework for explanation design in XAI: asking Who needs the explanation, What they need explained, and How that explanation should be delivered. We also emphasize the need for ethical considerations, including risks of epistemic inequality, reinforcing social inequities, and obscuring accountability and governance. By treating explanation as a sociotechnical design process, this framework encourages a context-aware approach to XAI that supports effective communication and the development of ethically responsible explanations.",
      "tldr_zh": "è¯¥ç ”ç©¶å°†å¯è§£é‡Šäººå·¥æ™ºèƒ½ (Explainable AI, XAI) çš„è§£é‡Šè¿‡ç¨‹é‡æ–°å®šä¹‰ä¸ºä¸€ç§æƒ…å¢ƒåŒ–çš„è®¾è®¡è¿‡ç¨‹ (situated design process)ï¼Œå¼ºè°ƒç”Ÿæˆæœ‰æ„ä¹‰çš„è§£é‡Šå¿…é¡»ä¾èµ–äºå…·ä½“çš„ä¸Šä¸‹æ–‡å’Œåˆ»æ„çš„è®¾è®¡é€‰æ‹©ã€‚ç ”ç©¶å€Ÿé‰´è®¾è®¡æ€ç»´ (design thinking) åŸåˆ™ï¼Œä¸ºä»ä¸šè€…æå‡ºäº†ä¸€ä¸ªä¸‰éƒ¨åˆ†æ¡†æ¶ï¼Œé€šè¿‡æ˜ç¡®è° (Who) éœ€è¦è§£é‡Šã€è§£é‡Šä»€ä¹ˆ (What) ä»¥åŠå¦‚ä½• (How) ä¼ é€’è§£é‡Šæ¥æŒ‡å¯¼ç³»ç»Ÿå¼€å‘ã€‚è¯¥æ¡†æ¶ç‰¹åˆ«å…³æ³¨äº† XAI ä¸­çš„ä¼¦ç†è€ƒé‡ï¼Œæ¢è®¨äº†è®¤è¯†è®ºä¸å¹³ç­‰ (epistemic inequality)ã€åŠ å‰§ç¤¾ä¼šä¸å¹³ç­‰çš„é£é™©ä»¥åŠå¯¹é—®è´£ä¸æ²»ç†çš„å½±å“ã€‚é€šè¿‡å°†è§£é‡Šè§†ä¸ºä¸€ç§ç¤¾ä¼šæŠ€æœ¯è®¾è®¡è¿‡ç¨‹ (sociotechnical design process)ï¼Œè¯¥ç ”ç©¶é¼“åŠ±é‡‡ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æ–¹æ³•ï¼Œä»¥æ”¯æŒæ›´æœ‰æ•ˆçš„æ²Ÿé€šå¹¶ä¿ƒè¿›å…·æœ‰ä¼¦ç†è´£ä»»æ„Ÿçš„è§£é‡Šç³»ç»Ÿçš„å¼€å‘ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted to AI, Ethics & Society Conference (AIES) Proceedings 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09231v1",
      "published_date": "2025-08-12 08:17:26 UTC",
      "updated_date": "2025-08-12 08:17:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:47.596481+00:00"
    },
    {
      "arxiv_id": "2508.08726v1",
      "title": "Simulating Generative Social Agents via Theory-Informed Workflow Design",
      "title_zh": "åŸºäºç†è®ºæŒ‡å¯¼å·¥ä½œæµè®¾è®¡çš„ç”Ÿæˆå¼ç¤¾ä¼šæ™ºèƒ½ä½“æ¨¡æ‹Ÿ",
      "authors": [
        "Yuwei Yan",
        "Jinghua Piao",
        "Xiaochong Lan",
        "Chenyang Shao",
        "Pan Hui",
        "Yong Li"
      ],
      "abstract": "Recent advances in large language models have demonstrated strong reasoning and role-playing capabilities, opening new opportunities for agent-based social simulations. However, most existing agents' implementations are scenario-tailored, without a unified framework to guide the design. This lack of a general social agent limits their ability to generalize across different social contexts and to produce consistent, realistic behaviors. To address this challenge, we propose a theory-informed framework that provides a systematic design process for LLM-based social agents. Our framework is grounded in principles from Social Cognition Theory and introduces three key modules: motivation, action planning, and learning. These modules jointly enable agents to reason about their goals, plan coherent actions, and adapt their behavior over time, leading to more flexible and contextually appropriate responses. Comprehensive experiments demonstrate that our theory-driven agents reproduce realistic human behavior patterns under complex conditions, achieving up to 75% lower deviation from real-world behavioral data across multiple fidelity metrics compared to classical generative baselines. Ablation studies further show that removing motivation, planning, or learning modules increases errors by 1.5 to 3.2 times, confirming their distinct and essential contributions to generating realistic and coherent social behaviors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰ç”Ÿæˆçš„ç¤¾äº¤æ™ºèƒ½ä½“ç¼ºä¹ç»Ÿä¸€æ¡†æ¶ä¸”æ³›åŒ–èƒ½åŠ›å—é™çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ä¸ªå—ç¤¾ä¼šè®¤çŸ¥ç†è®ºï¼ˆSocial Cognition Theoryï¼‰å¯å‘çš„ç³»ç»ŸåŒ–è®¾è®¡æ¡†æ¶ã€‚è¯¥æ¡†æ¶æ ¸å¿ƒå¼•å…¥äº†åŠ¨æœºï¼ˆMotivationï¼‰ã€è¡ŒåŠ¨è§„åˆ’ï¼ˆAction Planningï¼‰å’Œå­¦ä¹ ï¼ˆLearningï¼‰ä¸‰ä¸ªæ¨¡å—ï¼Œæ—¨åœ¨æå‡æ™ºèƒ½ä½“çš„ç›®æ ‡æ¨ç†ã€è¡ŒåŠ¨è¿è´¯æ€§å’Œç¯å¢ƒé€‚åº”èƒ½åŠ›ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥ç†è®ºé©±åŠ¨çš„æ™ºèƒ½ä½“åœ¨å¤æ‚æ¡ä»¶ä¸‹èƒ½æœ‰æ•ˆå¤ç°äººç±»è¡Œä¸ºæ¨¡å¼ï¼Œåœ¨å¤šé¡¹ä¿çœŸåº¦æŒ‡æ ‡ä¸Šæ¯”ç»å…¸ç”Ÿæˆå¼åŸºçº¿æ¨¡å‹åå·®é™ä½äº†é«˜è¾¾ 75%ã€‚æ¶ˆèç ”ç©¶è¿›ä¸€æ­¥è¯å®ï¼ŒåŠ¨æœºã€è§„åˆ’å’Œå­¦ä¹ æ¨¡å—å¯¹äºç”ŸæˆçœŸå®ä¸”è¿è´¯çš„ç¤¾äº¤è¡Œä¸ºå‡è‡³å…³é‡è¦ï¼Œç§»é™¤ä»»ä½•æ¨¡å—éƒ½ä¼šå¯¼è‡´è¯¯å·®æ˜¾è‘—å¢åŠ ï¼Œä¸ºæ„å»ºé«˜ä¿çœŸåº¦çš„ç¤¾ä¼šæ¨¡æ‹Ÿç³»ç»Ÿæä¾›äº†ç†è®ºæ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08726v1",
      "published_date": "2025-08-12 08:14:48 UTC",
      "updated_date": "2025-08-12 08:14:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:52.290645+00:00"
    },
    {
      "arxiv_id": "2508.08719v2",
      "title": "IROTE: Human-like Traits Elicitation of Large Language Model via In-Context Self-Reflective Optimization",
      "title_zh": "IROTEï¼šåŸºäºä¸Šä¸‹æ–‡è‡ªæˆ‘åæ€ä¼˜åŒ–çš„å¤§è¯­è¨€æ¨¡å‹ç±»äººç‰¹è´¨æ¿€å‘",
      "authors": [
        "Yuzhuo Bai",
        "Shitong Duan",
        "Muhua Huang",
        "Jing Yao",
        "Zhenghao Liu",
        "Peng Zhang",
        "Tun Lu",
        "Xiaoyuan Yi",
        "Maosong Sun",
        "Xing Xie"
      ],
      "abstract": "Trained on various human-authored corpora, Large Language Models (LLMs) have demonstrated a certain capability of reflecting specific human-like traits (e.g., personality or values) by prompting, benefiting applications like personalized LLMs and social simulations. However, existing methods suffer from the superficial elicitation problem: LLMs can only be steered to mimic shallow and unstable stylistic patterns, failing to embody the desired traits precisely and consistently across diverse tasks like humans. To address this challenge, we propose IROTE, a novel in-context method for stable and transferable trait elicitation. Drawing on psychological theories suggesting that traits are formed through identity-related reflection, our method automatically generates and optimizes a textual self-reflection within prompts, which comprises self-perceived experience, to stimulate LLMs' trait-driven behavior. The optimization is performed by iteratively maximizing an information-theoretic objective that enhances the connections between LLMs' behavior and the target trait, while reducing noisy redundancy in reflection without any fine-tuning, leading to evocative and compact trait reflection. Extensive experiments across three human trait systems manifest that one single IROTE-generated self-reflection can induce LLMs' stable impersonation of the target trait across diverse downstream tasks beyond simple questionnaire answering, consistently outperforming existing strong baselines.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å¤§è¯­è¨€æ¨¡å‹ (LLMs) åœ¨æ¨¡æ‹Ÿäººç±»ç‰¹è´¨ (personality/values) æ—¶å­˜åœ¨çš„â€œè¡¨é¢è¯±å¯¼â€ (superficial elicitation) é—®é¢˜ï¼Œæå‡ºäº† IROTE æ–¹æ³•ã€‚è¿™æ˜¯ä¸€ç§åŸºäºä¸Šä¸‹æ–‡è‡ªåæ€ä¼˜åŒ– (In-Context Self-Reflective Optimization) çš„æ–°æ¡†æ¶ï¼Œæ—¨åœ¨å®ç°ç¨³å®šä¸”å¯è¿ç§»çš„ç‰¹è´¨è¯±å¯¼ã€‚è¯¥æ–¹æ³•å€Ÿé‰´å¿ƒç†å­¦ä¸­ç‰¹è´¨é€šè¿‡èº«ä»½ç›¸å…³åæ€å½¢æˆçš„ç†è®ºï¼Œåœ¨æç¤ºè¯ (prompts) ä¸­è‡ªåŠ¨ç”Ÿæˆå¹¶ä¼˜åŒ–åŒ…å«è‡ªæˆ‘æ„ŸçŸ¥ç»éªŒçš„æ–‡æœ¬è‡ªåæ€ï¼Œä»è€Œæ¿€å‘æ¨¡å‹çš„ç‰¹è´¨é©±åŠ¨è¡Œä¸ºã€‚åœ¨ä¼˜åŒ–è¿‡ç¨‹ä¸­ï¼Œç ”ç©¶è€…é€šè¿‡è¿­ä»£æœ€å¤§åŒ–ä¿¡æ¯è®ºç›®æ ‡ (information-theoretic objective) æ¥å¢å¼ºæ¨¡å‹è¡Œä¸ºä¸ç›®æ ‡ç‰¹è´¨ä¹‹é—´çš„å…³è”ï¼Œå¹¶åœ¨æ— éœ€å¾®è°ƒ (fine-tuning) çš„å‰æä¸‹å‡å°‘å†—ä½™å™ªå£°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒIROTE èƒ½å¤Ÿè¯±å¯¼æ¨¡å‹åœ¨å¤šç§ä¸‹æ¸¸ä»»åŠ¡ä¸­å±•ç°å‡ºç¨³å®šä¸”ä¸€è‡´çš„ç‰¹è´¨æ‰®æ¼”èƒ½åŠ›ã€‚è¯¥æ–¹æ³•åœ¨ä¸‰ä¸ªä¸»æµäººç±»ç‰¹è´¨ç³»ç»Ÿä¸Šçš„æµ‹è¯•è¡¨ç°å‡æ˜¾è‘—ä¼˜äºç°æœ‰çš„å¼ºåŸºçº¿æ¨¡å‹ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper is accepted by AAAI 2026",
      "pdf_url": "https://arxiv.org/pdf/2508.08719v2",
      "published_date": "2025-08-12 08:04:28 UTC",
      "updated_date": "2025-11-27 12:38:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:21:55.791344+00:00"
    },
    {
      "arxiv_id": "2508.08718v1",
      "title": "Generative Modeling for Robust Deep Reinforcement Learning on the Traveling Salesman Problem",
      "title_zh": "é¢å‘æ—…è¡Œå•†é—®é¢˜é²æ£’æ·±åº¦å¼ºåŒ–å­¦ä¹ çš„ç”Ÿæˆå¼å»ºæ¨¡",
      "authors": [
        "Michael Li",
        "Eric Bae",
        "Christopher Haberland",
        "Natasha Jaques"
      ],
      "abstract": "The Traveling Salesman Problem (TSP) is a classic NP-hard combinatorial optimization task with numerous practical applications. Classic heuristic solvers can attain near-optimal performance for small problem instances, but become computationally intractable for larger problems. Real-world logistics problems such as dynamically re-routing last-mile deliveries demand a solver with fast inference time, which has led researchers to investigate specialized neural network solvers. However, neural networks struggle to generalize beyond the synthetic data they were trained on. In particular, we show that there exist TSP distributions that are realistic in practice, which also consistently lead to poor worst-case performance for existing neural approaches. To address this issue of distribution robustness, we present Combinatorial Optimization with Generative Sampling (COGS), where training data is sampled from a generative TSP model. We show that COGS provides better data coverage and interpolation in the space of TSP training distributions. We also present TSPLib50, a dataset of realistically distributed TSP samples, which tests real-world generalization ability without conflating this issue with instance size. We evaluate our method on various synthetic datasets as well as TSPLib50, and compare to state-of-the-art neural baselines. We demonstrate that COGS improves distribution robustness, with most performance gains coming from worst-case scenarios.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ—…è¡Œå•†é—®é¢˜ (Traveling Salesman Problem, TSP) åœ¨å®é™…ç‰©æµåº”ç”¨ä¸­é¢ä¸´çš„åˆ†å¸ƒé²æ£’æ€§æŒ‘æˆ˜ï¼ŒæŒ‡å‡ºç›®å‰çš„ç¥ç»ç½‘ç»œæ±‚è§£å™¨åœ¨é¢å¯¹ç°å®åˆ†å¸ƒæ—¶å¾€å¾€è¡¨ç°å‡ºè¾ƒå·®çš„æœ€åæƒ…å†µæ€§èƒ½ã€‚ä¸ºäº†è§£å†³è¿™ä¸€é—®é¢˜ï¼Œä½œè€…æå‡ºäº† COGS (Combinatorial Optimization with Generative Sampling) æ¡†æ¶ï¼Œé€šè¿‡ä»ç”Ÿæˆå¼ TSP æ¨¡å‹ä¸­é‡‡æ ·è®­ç»ƒæ•°æ®æ¥å¢å¼ºæ•°æ®çš„è¦†ç›–èŒƒå›´å’Œåˆ†å¸ƒç©ºé—´çš„æ’å€¼èƒ½åŠ›ã€‚ç ”ç©¶è¿˜å¼•å…¥äº† TSPLib50 æ•°æ®é›†ï¼Œç”¨äºåœ¨ä¸æ··æ·†å®ä¾‹è§„æ¨¡çš„æƒ…å†µä¸‹ï¼Œä¸“é—¨æµ‹è¯•æ¨¡å‹å¯¹ç°å®ä¸–ç•Œåˆ†å¸ƒçš„æ³›åŒ–èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒCOGS åœ¨å¤šç§åˆæˆæ•°æ®é›†åŠ TSPLib50 ä¸Šå‡æ˜¾è‘—æå‡äº†åˆ†å¸ƒé²æ£’æ€§ï¼Œä¸”å¤§éƒ¨åˆ†æ€§èƒ½å¢ç›Šæºäºå¯¹æœ€åæƒ…å†µåœºæ™¯ (worst-case scenarios) çš„æ˜¾è‘—æ”¹è¿›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 8 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08718v1",
      "published_date": "2025-08-12 08:04:16 UTC",
      "updated_date": "2025-08-12 08:04:16 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:07.090111+00:00"
    },
    {
      "arxiv_id": "2508.08715v3",
      "title": "MultiGen: Child-Friendly Multilingual Speech Generator with LLMs",
      "title_zh": "MultiGenï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å„¿ç«¥å‹å¥½å‹å¤šè¯­è¨€è¯­éŸ³ç”Ÿæˆå™¨",
      "authors": [
        "Xiaoxue Gao",
        "Huayun Zhang",
        "Nancy F. Chen"
      ],
      "abstract": "Generative speech models have demonstrated significant potential in improving human-machine interactions, offering valuable real-world applications such as language learning for children. However, achieving high-quality, child-friendly speech generation remains challenging, particularly for low-resource languages across diverse languages and cultural contexts. In this paper, we propose MultiGen, a multilingual speech generation model with child-friendly interaction, leveraging LLM architecture for speech generation tailored for low-resource languages. We propose to integrate age-appropriate multilingual speech generation using LLM architectures, which can be used to facilitate young children's communication with AI systems through culturally relevant context in three low-resource languages: Singaporean accent Mandarin, Malay, and Tamil. Experimental results from both objective metrics and subjective evaluations demonstrate the superior performance of the proposed MultiGen compared to baseline methods.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MultiGenï¼Œè¿™æ˜¯ä¸€ç§åŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) æ¶æ„çš„å¤šè¯­è¨€è¯­éŸ³ç”Ÿæˆæ¨¡å‹ï¼Œæ—¨åœ¨ä¸ºå„¿ç«¥æä¾›å‹å¥½çš„äº¤äº’ä½“éªŒã€‚è¯¥æ¨¡å‹ç‰¹åˆ«é’ˆå¯¹ä½èµ„æºè¯­è¨€ (low-resource languages) è¿›è¡Œäº†ä¼˜åŒ–ï¼Œèƒ½å¤Ÿç”Ÿæˆç¬¦åˆå„¿ç«¥å¹´é¾„ç‰¹å¾ä¸”å…·æœ‰æ–‡åŒ–ç›¸å…³æ€§çš„è¯­éŸ³å†…å®¹ã€‚MultiGen é‡ç‚¹æ”¯æŒä¸‰ç§ä½èµ„æºè¯­è¨€ï¼šå…·æœ‰æ–°åŠ å¡å£éŸ³çš„æ™®é€šè¯ (Singaporean accent Mandarin)ã€é©¬æ¥è¯­ (Malay) å’Œæ³°ç±³å°”è¯­ (Tamil)ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œæ— è®ºæ˜¯åœ¨å®¢è§‚æŒ‡æ ‡ (objective metrics) è¿˜æ˜¯ä¸»è§‚è¯„ä»· (subjective evaluations) æ–¹é¢ï¼ŒMultiGen çš„è¡¨ç°å‡æ˜¾è‘—ä¼˜äºåŸºçº¿æ–¹æ³• (baseline methods)ã€‚è¯¥å·¥ä½œé€šè¿‡ç»“åˆæ–‡åŒ–ç›¸å…³çš„ä¸Šä¸‹æ–‡è®¾è®¡ï¼Œä¸ºå¹¼å„¿ä¸äººå·¥æ™ºèƒ½ç³»ç»Ÿä¹‹é—´çš„è·¨è¯­è¨€æ²Ÿé€šå¥ å®šäº†æŠ€æœ¯åŸºç¡€ã€‚",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "eess.SP"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.08715v3",
      "published_date": "2025-08-12 07:58:48 UTC",
      "updated_date": "2025-09-04 07:56:00 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:22.082854+00:00"
    },
    {
      "arxiv_id": "2508.08712v3",
      "title": "A Survey on Parallel Text Generation: From Parallel Decoding to Diffusion Language Models",
      "title_zh": "å¹¶è¡Œæ–‡æœ¬ç”Ÿæˆç»¼è¿°ï¼šä»å¹¶è¡Œè§£ç åˆ°æ‰©æ•£è¯­è¨€æ¨¡å‹",
      "authors": [
        "Lingzhe Zhang",
        "Liancheng Fang",
        "Chiming Duan",
        "Minghua He",
        "Leyi Pan",
        "Pei Xiao",
        "Shiyu Huang",
        "Yunpeng Zhai",
        "Xuming Hu",
        "Philip S. Yu",
        "Aiwei Liu"
      ],
      "abstract": "As text generation has become a core capability of modern Large Language Models (LLMs), it underpins a wide range of downstream applications. However, most existing LLMs rely on autoregressive (AR) generation, producing one token at a time based on previously generated context-resulting in limited generation speed due to the inherently sequential nature of the process. To address this challenge, an increasing number of researchers have begun exploring parallel text generation-a broad class of techniques aimed at breaking the token-by-token generation bottleneck and improving inference efficiency. Despite growing interest, there remains a lack of comprehensive analysis on what specific techniques constitute parallel text generation and how they improve inference performance. To bridge this gap, we present a systematic survey of parallel text generation methods. We categorize existing approaches into AR-based and Non-AR-based paradigms, and provide a detailed examination of the core techniques within each category. Following this taxonomy, we assess their theoretical trade-offs in terms of speed, quality, and efficiency, and examine their potential for combination and comparison with alternative acceleration strategies. Finally, based on our findings, we highlight recent advancements, identify open challenges, and outline promising directions for future research in parallel text generation. We have also created a GitHub repository for indexing relevant papers and open resources available at https://github.com/zhanglingzhe0820/Awesome-Parallel-Text-Generation.",
      "tldr_zh": "è¯¥ç»¼è¿°ç³»ç»Ÿæ€§åœ°æ¢è®¨äº†å¹¶è¡Œæ–‡æœ¬ç”Ÿæˆ(Parallel Text Generation)æŠ€æœ¯ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)å› è‡ªå›å½’(Autoregressive)ç”Ÿæˆæ¨¡å¼å¸¦æ¥çš„æ¨ç†é€Ÿåº¦ç“¶é¢ˆã€‚ç ”ç©¶å°†ç°æœ‰æ–¹æ³•åˆ’åˆ†ä¸ºåŸºäºAR(AR-based)å’Œéè‡ªå›å½’(Non-AR-based)ä¸¤ç§èŒƒå¼ï¼Œå¹¶å¯¹æ¯ä¸€ç±»åˆ«çš„æ ¸å¿ƒæŠ€æœ¯è¿›è¡Œäº†æ·±å…¥å‰–æã€‚è®ºæ–‡æ¶µç›–äº†ä»å¹¶è¡Œè§£ç (Parallel Decoding)åˆ°æ‰©æ•£è¯­è¨€æ¨¡å‹(Diffusion Language Models)ç­‰å‰æ²¿æ‰‹æ®µï¼Œè¯¦ç»†è¯„ä¼°äº†å„æ–¹æ³•åœ¨ç”Ÿæˆé€Ÿåº¦ã€è´¨é‡å’Œæ•ˆç‡ä¹‹é—´çš„ç†è®ºæƒè¡¡ã€‚æ­¤å¤–ï¼Œè¯¥ç»¼è¿°è¿˜åˆ†æäº†å¹¶è¡Œç”ŸæˆæŠ€æœ¯ä¸å…¶ä»–åŠ é€Ÿç­–ç•¥ç»“åˆçš„å¯èƒ½æ€§ï¼Œå¹¶æŒ‡å‡ºäº†å½“å‰é¢†åŸŸé¢ä¸´çš„æŒ‘æˆ˜ä¸æœªæ¥çš„ç ”ç©¶æ–¹å‘ã€‚è¯¥ç ”ç©¶ä¸ºä¼˜åŒ–æ–‡æœ¬ç”Ÿæˆæ•ˆç‡æä¾›äº†ç³»ç»Ÿæ€§çš„æŒ‡å¯¼ï¼Œå¹¶é…å¥—æä¾›äº†ç›¸å…³çš„å¼€æºæ–‡çŒ®ç´¢å¼•ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08712v3",
      "published_date": "2025-08-12 07:56:04 UTC",
      "updated_date": "2025-08-27 03:08:49 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:41.547398+00:00"
    },
    {
      "arxiv_id": "2508.09230v1",
      "title": "Cowpox: Towards the Immunity of VLM-based Multi-Agent Systems",
      "title_zh": "Cowpoxï¼šè¿ˆå‘åŸºäº VLM çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿçš„å…ç–«",
      "authors": [
        "Yutong Wu",
        "Jie Zhang",
        "Yiming Li",
        "Chao Zhang",
        "Qing Guo",
        "Nils Lukas",
        "Tianwei Zhang"
      ],
      "abstract": "Vision Language Model (VLM)-based agents are stateful, autonomous entities capable of perceiving and interacting with their environments through vision and language. Multi-agent systems comprise specialized agents who collaborate to solve a (complex) task. A core security property is robustness, stating that the system should maintain its integrity under adversarial attacks. However, the design of existing multi-agent systems lacks the robustness consideration, as a successful exploit against one agent can spread and infect other agents to undermine the entire system's assurance. To address this, we propose a new defense approach, Cowpox, to provably enhance the robustness of multi-agent systems. It incorporates a distributed mechanism, which improves the recovery rate of agents by limiting the expected number of infections to other agents. The core idea is to generate and distribute a special cure sample that immunizes an agent against the attack before exposure and helps recover the already infected agents. We demonstrate the effectiveness of Cowpox empirically and provide theoretical robustness guarantees.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åŸºäºè§†è§‰è¯­è¨€æ¨¡å‹(VLM)çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿåœ¨å¯¹æŠ—æ”»å‡»ä¸‹çš„é²æ£’æ€§(Robustness)ä¸è¶³é—®é¢˜ï¼Œæå‡ºäº†åä¸ºCowpoxçš„æ–°å‹é˜²å¾¡æ–¹æ³•ã€‚ç°æœ‰çš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå¾€å¾€ç¼ºä¹å®‰å…¨æ€§è®¾è®¡ï¼Œå¯¼è‡´é’ˆå¯¹å•ä¸ªæ™ºèƒ½ä½“çš„æˆåŠŸæ”»å‡»å¯èƒ½åœ¨ç³»ç»Ÿå†…æ‰©æ•£å¹¶å¨èƒæ•´ä½“å®‰å…¨ã€‚Cowpoxé‡‡ç”¨åˆ†å¸ƒå¼æœºåˆ¶ï¼Œé€šè¿‡é™åˆ¶é¢„æœŸçš„æ„ŸæŸ“æ•°é‡æ¥æå‡æ™ºèƒ½ä½“çš„æ¢å¤ç‡ï¼Œä»è€Œå¢å¼ºç³»ç»Ÿçš„å¯è¯æ˜é²æ£’æ€§ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºç”Ÿæˆå¹¶åˆ†å‘ä¸€ç§ç‰¹æ®Šçš„æ²»ç–—æ ·æœ¬(cure sample)ï¼Œè¿™ç§æ ·æœ¬èƒ½åœ¨æ™ºèƒ½ä½“æ¥è§¦æ”»å‡»å‰æä¾›å…ç–«èƒ½åŠ›ï¼Œå¹¶ååŠ©å·²å—æ„ŸæŸ“çš„æ™ºèƒ½ä½“å®ç°æ¢å¤ã€‚å®éªŒç»“æœå’Œç†è®ºä¿è¯å…±åŒéªŒè¯äº†Cowpoxåœ¨ç»´æŠ¤å¤šæ™ºèƒ½ä½“ç³»ç»Ÿå®Œæ•´æ€§å’ŒæŠµå¾¡æ¶æ„æ”»å‡»æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09230v1",
      "published_date": "2025-08-12 07:48:51 UTC",
      "updated_date": "2025-08-12 07:48:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:23:28.287411+00:00"
    },
    {
      "arxiv_id": "2508.08701v2",
      "title": "SafeFix: Targeted Model Repair via Controlled Image Generation",
      "title_zh": "SafeFixï¼šåŸºäºå¯æ§å›¾åƒç”Ÿæˆçš„é¶å‘æ¨¡å‹ä¿®å¤",
      "authors": [
        "Ouyang Xu",
        "Baoming Zhang",
        "Ruiyu Mao",
        "Yunhui Guo"
      ],
      "abstract": "Deep learning models for visual recognition often exhibit systematic errors due to underrepresented semantic subpopulations. Although existing debugging frameworks can pinpoint these failures by identifying key failure attributes, repairing the model effectively remains difficult. Current solutions often rely on manually designed prompts to generate synthetic training images -- an approach prone to distribution shift and semantic errors. To overcome these challenges, we introduce a model repair module that builds on an interpretable failure attribution pipeline. Our approach uses a conditional text-to-image model to generate semantically faithful and targeted images for failure cases. To preserve the quality and relevance of the generated samples, we further employ a large vision-language model (LVLM) to filter the outputs, enforcing alignment with the original data distribution and maintaining semantic consistency. By retraining vision models with this rare-case-augmented synthetic dataset, we significantly reduce errors associated with rare cases. Our experiments demonstrate that this targeted repair strategy improves model robustness without introducing new bugs. Code is available at https://github.com/oxu2/SafeFix",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨è§†è§‰è¯†åˆ«ä¸­å› è¯­ä¹‰å­ç¾¤ä½“ï¼ˆsemantic subpopulationsï¼‰ä»£è¡¨æ€§ä¸è¶³è€Œäº§ç”Ÿçš„ç³»ç»Ÿæ€§é”™è¯¯ï¼Œæå‡ºäº† SafeFix æ¨¡å‹ä¿®å¤æ¡†æ¶ã€‚SafeFix å»ºç«‹åœ¨å¯è§£é‡Šæ•…éšœå½’å› ï¼ˆfailure attributionï¼‰æµæ°´çº¿ä¹‹ä¸Šï¼Œåˆ©ç”¨æ¡ä»¶æ–‡æœ¬ç”Ÿæˆå›¾åƒæ¨¡å‹ï¼ˆconditional text-to-image modelï¼‰ä¸ºç‰¹å®šçš„æ•…éšœæ¡ˆä¾‹ç”Ÿæˆè¯­ä¹‰çœŸå®çš„é’ˆå¯¹æ€§å›¾åƒã€‚ä¸ºäº†ç»´æŒç”Ÿæˆæ ·æœ¬çš„è´¨é‡ä¸ç›¸å…³æ€§ï¼Œè¯¥æ–¹æ³•è¿›ä¸€æ­¥é‡‡ç”¨å¤§è§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆLVLMï¼‰å¯¹è¾“å‡ºè¿›è¡Œè¿‡æ»¤ï¼Œä»¥ç¡®ä¿å…¶ä¸åŸå§‹æ•°æ®åˆ†å¸ƒå¯¹é½å¹¶ä¿æŒè¯­ä¹‰ä¸€è‡´æ€§ï¼ˆsemantic consistencyï¼‰ã€‚é€šè¿‡ä½¿ç”¨è¿™ç§ç¨€æœ‰æ¡ˆä¾‹å¢å¼ºï¼ˆrare-case-augmentedï¼‰çš„åˆæˆæ•°æ®é›†å¯¹è§†è§‰æ¨¡å‹è¿›è¡Œé‡æ–°è®­ç»ƒï¼Œå¯ä»¥æ˜¾è‘—é™ä½æ¨¡å‹åœ¨ç¨€æœ‰æƒ…å†µä¸‹çš„é”™è¯¯ç‡ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¿™ç§é’ˆå¯¹æ€§çš„ä¿®å¤ç­–ç•¥åœ¨ä¸å¼•å…¥æ–°æ¼æ´ï¼ˆbugsï¼‰çš„å‰æä¸‹ï¼Œæœ‰æ•ˆæå‡äº†æ¨¡å‹çš„é²æ£’æ€§ï¼ˆrobustnessï¼‰ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08701v2",
      "published_date": "2025-08-12 07:45:25 UTC",
      "updated_date": "2025-11-24 19:26:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:29.684560+00:00"
    },
    {
      "arxiv_id": "2508.14906v1",
      "title": "Collaborative Filtering using Variational Quantum Hopfield Associative Memory",
      "title_zh": "åŸºäºå˜åˆ†é‡å­ Hopfield å…³è”è®°å¿†çš„ååŒè¿‡æ»¤",
      "authors": [
        "Amir Kermanshahani",
        "Ebrahim Ardeshir-Larijani",
        "Rakesh Saini",
        "Saif Al-Kuwari"
      ],
      "abstract": "Quantum computing, with its ability to do exponentially faster computation compared to classical systems, has found novel applications in various fields such as machine learning and recommendation systems. Quantum Machine Learning (QML), which integrates quantum computing with machine learning techniques, presents powerful new tools for data processing and pattern recognition. This paper proposes a hybrid recommendation system that combines Quantum Hopfield Associative Memory (QHAM) with deep neural networks to improve the extraction and classification on the MovieLens 1M dataset. User archetypes are clustered into multiple unique groups using the K-Means algorithm and converted into polar patterns through the encoder's activation function. These polar patterns are then integrated into the variational QHAM-based hybrid recommendation model. The system was trained using the MSE loss over 35 epochs in an ideal environment, achieving an ROC value of 0.9795, an accuracy of 0.8841, and an F-1 Score of 0.8786. Trained with the same number of epochs in a noisy environment using a custom Qiskit AER noise model incorporating bit-flip and readout errors with the same probabilities as in real quantum hardware, it achieves an ROC of 0.9177, an accuracy of 0.8013, and an F-1 Score equal to 0.7866, demonstrating consistent performance.\n  Additionally, we were able to optimize the qubit overhead present in previous QHAM architectures by efficiently updating only one random targeted qubit. This research presents a novel framework that combines variational quantum computing with deep learning, capable of dealing with real-world datasets with comparable performance compared to purely classical counterparts. Additionally, the model can perform similarly well in noisy configurations, showcasing a steady performance and proposing a promising direction for future usage in recommendation systems.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åŸºäºå˜åˆ†é‡å­éœæ™®è²å°”å¾·å…³è”è®°å¿†(Variational Quantum Hopfield Associative Memory, QHAM)çš„ååŒè¿‡æ»¤(Collaborative Filtering)æ¨èç³»ç»Ÿæ¡†æ¶ï¼Œæ—¨åœ¨åˆ©ç”¨é‡å­æœºå™¨å­¦ä¹ (QML)æå‡æ¨èæ•ˆç‡ã€‚è¯¥æ–¹æ¡ˆå°†æ·±åº¦ç¥ç»ç½‘ç»œä¸QHAMç»“åˆï¼Œåˆ©ç”¨K-Meansç®—æ³•å¯¹MovieLens 1Mæ•°æ®é›†ä¸­çš„ç”¨æˆ·åŸå‹è¿›è¡Œèšç±»ï¼Œå¹¶é€šè¿‡ç¼–ç å™¨æ¿€æ´»å‡½æ•°å°†å…¶è½¬æ¢ä¸ºææ€§æ¨¡å¼ã€‚é€šè¿‡é«˜æ•ˆæ›´æ–°å•ä¸€éšæœºç›®æ ‡é‡å­æ¯”ç‰¹(qubit)ï¼Œç ”ç©¶æˆåŠŸä¼˜åŒ–äº†ä»¥å¾€QHAMæ¶æ„ä¸­çš„é‡å­æ¯”ç‰¹å¼€é”€é—®é¢˜ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨ç†æƒ³ç¯å¢ƒä¸‹æ¨¡å‹è¾¾åˆ°äº†0.9795çš„ROCå€¼å’Œ0.8841çš„å‡†ç¡®ç‡(Accuracy)ï¼›åœ¨åŒ…å«æ¯”ç‰¹ç¿»è½¬(bit-flip)å’Œè¯»å–è¯¯å·®(readout errors)çš„å™ªå£°ç¯å¢ƒä¸­ï¼Œè¯¥ç³»ç»Ÿä¾ç„¶è¡¨ç°ç¨³å¥ï¼Œå–å¾—äº†0.9177çš„ROCå€¼å’Œ0.8013çš„å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å˜åˆ†é‡å­è®¡ç®—ä¸æ·±åº¦å­¦ä¹ ç»“åˆå¤„ç†ç°å®ä¸–ç•Œæ•°æ®é›†çš„å¯è¡Œæ€§ï¼Œä¸ºé‡å­æŠ€æœ¯åœ¨æ¨èç³»ç»Ÿé¢†åŸŸçš„åº”ç”¨æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14906v1",
      "published_date": "2025-08-12 07:33:11 UTC",
      "updated_date": "2025-08-12 07:33:11 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:42.448216+00:00"
    },
    {
      "arxiv_id": "2508.08688v1",
      "title": "STELAR-VISION: Self-Topology-Aware Efficient Learning for Aligned Reasoning in Vision",
      "title_zh": "STELAR-VISIONï¼šé¢å‘è§†è§‰å¯¹é½æ¨ç†çš„è‡ªæ‹“æ‰‘æ„ŸçŸ¥é«˜æ•ˆå­¦ä¹ ",
      "authors": [
        "Chen Li",
        "Han Zhang",
        "Zhantao Yang",
        "Fangyi Chen",
        "Zihan Wang",
        "Anudeepsekhar Bolimera",
        "Marios Savvides"
      ],
      "abstract": "Vision-language models (VLMs) have made significant strides in reasoning, yet they often struggle with complex multimodal tasks and tend to generate overly verbose outputs. A key limitation is their reliance on chain-of-thought (CoT) reasoning, despite many tasks benefiting from alternative topologies like trees or graphs. To address this, we introduce STELAR-Vision, a training framework for topology-aware reasoning. At its core is TopoAug, a synthetic data pipeline that enriches training with diverse topological structures. Using supervised fine-tuning and reinforcement learning, we post-train Qwen2VL models with both accuracy and efficiency in mind. Additionally, we propose Frugal Learning, which reduces output length with minimal accuracy loss. On MATH-V and VLM-S2H, STELAR-Vision improves accuracy by 9.7% over its base model and surpasses the larger Qwen2VL-72B-Instruct by 7.3%. On five out-of-distribution benchmarks, it outperforms Phi-4-Multimodal-Instruct by up to 28.4% and LLaMA-3.2-11B-Vision-Instruct by up to 13.2%, demonstrating strong generalization. Compared to Chain-Only training, our approach achieves 4.3% higher overall accuracy on in-distribution datasets and consistently outperforms across all OOD benchmarks. We have released datasets, and code will be available.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(VLMs)åœ¨å¤„ç†å¤æ‚å¤šæ¨¡æ€ä»»åŠ¡æ—¶å­˜åœ¨å†—é•¿è¾“å‡ºåŠé“¾å¼æ€ç»´(Chain-of-Thought)å±€é™æ€§çš„é—®é¢˜ï¼Œæå‡ºäº†æ‹“æ‰‘æ„ŸçŸ¥æ¨ç†è®­ç»ƒæ¡†æ¶STELAR-Visionã€‚è¯¥æ¡†æ¶é€šè¿‡æ ¸å¿ƒçš„åˆæˆæ•°æ®æµæ°´çº¿TopoAugå¼•å…¥å¤šæ ·åŒ–çš„æ‹“æ‰‘ç»“æ„ï¼Œå¹¶ç»“åˆç›‘ç£å¾®è°ƒ(Supervised Fine-Tuning)ä¸å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)å¯¹Qwen2VLæ¨¡å‹è¿›è¡Œåè®­ç»ƒã€‚ç ”ç©¶è¿˜è¿›ä¸€æ­¥æå‡ºäº†Frugal LearningæŠ€æœ¯ï¼Œæ—¨åœ¨ä»¥æå°çš„ç²¾åº¦æŸå¤±å¤§å¹…ç¼©å‡æ¨¡å‹è¾“å‡ºé•¿åº¦ã€‚å®éªŒè¡¨æ˜ï¼ŒSTELAR-Visionåœ¨MATH-Vå’ŒVLM-S2HåŸºå‡†æµ‹è¯•ä¸­æ¯”åŸºç¡€æ¨¡å‹å‡†ç¡®ç‡æå‡äº†9.7%ï¼Œæ€§èƒ½è¶…è¶Šäº†å‚æ•°é‡æ›´å¤§çš„Qwen2VL-72B-Instructã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨äº”ä¸ªåˆ†å¸ƒå¤–(Out-of-Distribution)åŸºå‡†æµ‹è¯•ä¸­å±•ç°å‡ºå¼ºå¤§çš„æ³›åŒ–èƒ½åŠ›ï¼Œæ˜¾è‘—é¢†å…ˆäºPhi-4-Multimodal-Instructå’ŒLLaMA-3.2-11B-Vision-Instructã€‚ä¸ä¼ ç»Ÿçš„Chain-Onlyè®­ç»ƒæ–¹æ³•ç›¸æ¯”ï¼ŒSTELAR-Visionè¯æ˜äº†æ‹“æ‰‘æ„ŸçŸ¥æ¨ç†(Topology-aware reasoning)èƒ½æ˜¾è‘—æå‡æ¨¡å‹åœ¨è§†è§‰é¢†åŸŸçš„æ¨ç†æ•ˆç‡ä¸å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08688v1",
      "published_date": "2025-08-12 07:27:50 UTC",
      "updated_date": "2025-08-12 07:27:50 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:41.751245+00:00"
    },
    {
      "arxiv_id": "2508.09229v1",
      "title": "Cluster Topology-Driven Placement of Experts Reduces Network Traffic in MoE Inference",
      "title_zh": "é›†ç¾¤æ‹“æ‰‘é©±åŠ¨çš„ä¸“å®¶æ”¾ç½®ï¼šé™ä½ MoE æ¨ç†ä¸­çš„ç½‘ç»œæµé‡",
      "authors": [
        "Danil Sivtsov",
        "Aleksandr Katrutsa",
        "Ivan Oseledets"
      ],
      "abstract": "Efficient deployment of a pre-trained LLM to a cluster with multiple servers is a critical step for providing fast responses to users' queries. The recent success of Mixture-of-Experts (MoE) LLMs raises the question of how to deploy them efficiently, considering their underlying structure. During the inference in MoE LLMs, only a small part of the experts is selected to process a given token. Moreover, in practice, the experts' load is highly imbalanced. For efficient deployment, one has to distribute the model across a large number of servers using a model placement algorithm. Thus, to improve cluster utilization, the model placement algorithm has to take into account the network topology. This work focuses on the efficient topology-aware placement of the pre-trained MoE LLMs in the inference stage. We propose an integer linear program (ILP) that determines the optimal placement of experts, minimizing the expected number of transmissions. Due to the internal structure, this optimization problem can be solved with a standard ILP solver. We demonstrate that ILP-based placement strategy yields lower network traffic than competitors for small-scale (DeepSeekMoE~16B) and large-scale (DeepSeek-R1~671B) models.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹é¢„è®­ç»ƒæ··åˆä¸“å®¶æ¨¡å‹ (Mixture-of-Experts, MoE) åœ¨å¤šæœåŠ¡å™¨é›†ç¾¤éƒ¨ç½²ä¸­é¢ä¸´çš„æ¨ç†æ•ˆç‡é—®é¢˜ï¼Œé‡ç‚¹æ¢è®¨äº†å¦‚ä½•æ ¹æ®ç½‘ç»œæ‹“æ‰‘ç»“æ„ä¼˜åŒ–ä¸“å®¶æ”¾ç½®ç­–ç•¥ã€‚è€ƒè™‘åˆ° MoE æ¨¡å‹åœ¨æ¨ç†è¿‡ç¨‹ä¸­ä»…æ¿€æ´»éƒ¨åˆ†ä¸“å®¶ä¸”è´Ÿè½½åˆ†å¸ƒæä¸å‡åŒ€ï¼Œç ”ç©¶æŒ‡å‡ºé«˜æ•ˆçš„éƒ¨ç½²å¿…é¡»å°†åº•å±‚ç½‘ç»œæ‹“æ‰‘çº³å…¥è€ƒé‡ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åŸºäºæ•´æ•°çº¿æ€§è§„åˆ’ (Integer Linear Program, ILP) çš„ä¼˜åŒ–æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡ç¡®å®šä¸“å®¶çš„æœ€ä½³æ”¾ç½®æ–¹æ¡ˆæ¥æœ€å°åŒ–é¢„æœŸçš„ç½‘ç»œä¼ è¾“é‡ã€‚è¯¥æ–¹æ³•åˆ©ç”¨ MoE çš„å†…éƒ¨ç»“æ„ç‰¹ç‚¹ï¼Œä½¿å¾—å¤æ‚çš„ä¼˜åŒ–é—®é¢˜èƒ½å¤Ÿåˆ©ç”¨æ ‡å‡†çš„ ILP æ±‚è§£å™¨å¾—å‡ºæœ€ä¼˜è§£ã€‚å®éªŒè¯æ˜ï¼Œåœ¨é’ˆå¯¹ DeepSeekMoE 16B å’Œ DeepSeek-R1 671B ç­‰ä¸åŒè§„æ¨¡æ¨¡å‹çš„æµ‹è¯•ä¸­ï¼Œè¯¥ç­–ç•¥ç›¸æ¯”ä¼ ç»Ÿæ–¹æ¡ˆèƒ½æ˜¾è‘—é™ä½ç½‘ç»œæµé‡ã€‚è¿™ä¸€ç ”ç©¶ä¸ºå¤§è§„æ¨¡ MoE æ¨¡å‹åœ¨å¤æ‚é›†ç¾¤ç¯å¢ƒä¸‹çš„é«˜æ•ˆæ¨ç†æä¾›äº†å…³é”®çš„ç†è®ºæ”¯æŒä¸ä¼˜åŒ–æ‰‹æ®µã€‚",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09229v1",
      "published_date": "2025-08-12 07:08:48 UTC",
      "updated_date": "2025-08-12 07:08:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:48.470285+00:00"
    },
    {
      "arxiv_id": "2508.08679v2",
      "title": "MMIF-AMIN: Adaptive Loss-Driven Multi-Scale Invertible Dense Network for Multimodal Medical Image Fusion",
      "title_zh": "MMIF-AMINï¼šé¢å‘å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆçš„è‡ªé€‚åº”æŸå¤±é©±åŠ¨å¤šå°ºåº¦å¯é€†å¯†é›†ç½‘ç»œ",
      "authors": [
        "Tao Luo",
        "Weihua Xu"
      ],
      "abstract": "Multimodal medical image fusion (MMIF) aims to integrate images from different modalities to produce a comprehensive image that enhances medical diagnosis by accurately depicting organ structures, tissue textures, and metabolic information. Capturing both the unique and complementary information across multiple modalities simultaneously is a key research challenge in MMIF. To address this challenge, this paper proposes a novel image fusion method, MMIF-AMIN, which features a new architecture that can effectively extract these unique and complementary features. Specifically, an Invertible Dense Network (IDN) is employed for lossless feature extraction from individual modalities. To extract complementary information between modalities, a Multi-scale Complementary Feature Extraction Module (MCFEM) is designed, which incorporates a hybrid attention mechanism, convolutional layers of varying sizes, and Transformers. An adaptive loss function is introduced to guide model learning, addressing the limitations of traditional manually-designed loss functions and enhancing the depth of data mining. Extensive experiments demonstrate that MMIF-AMIN outperforms nine state-of-the-art MMIF methods, delivering superior results in both quantitative and qualitative analyses. Ablation experiments confirm the effectiveness of each component of the proposed method. Additionally, extending MMIF-AMIN to other image fusion tasks also achieves promising performance.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† MMIF-AMINï¼Œä¸€ç§è‡ªé€‚åº”æŸå¤±é©±åŠ¨çš„å¤šå°ºåº¦å¯é€†ç¨ å¯†ç½‘ç»œï¼Œæ—¨åœ¨è§£å†³å¤šæ¨¡æ€åŒ»å­¦å›¾åƒèåˆ (Multimodal Medical Image Fusion, MMIF) ä¸­å¦‚ä½•æœ‰æ•ˆæ•è·ç‹¬ç‰¹ä¸äº’è¡¥ä¿¡æ¯çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¯é€†ç¨ å¯†ç½‘ç»œ (Invertible Dense Network, IDN) å®ç°å•ä¸€æ¨¡æ€çš„æ— æŸç‰¹å¾æå–ï¼Œå¹¶è®¾è®¡äº†ç»“åˆæ··åˆæ³¨æ„åŠ›æœºåˆ¶ä¸ Transformers çš„å¤šå°ºåº¦äº’è¡¥ç‰¹å¾æå–æ¨¡å— (Multi-scale Complementary Feature Extraction Module, MCFEM) ä»¥æ•æ‰æ¨¡æ€é—´çš„å…³è”ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†è‡ªé€‚åº”æŸå¤±å‡½æ•° (adaptive loss function) æ¥æŒ‡å¯¼æ¨¡å‹å­¦ä¹ ï¼Œå…‹æœäº†ä¼ ç»Ÿæ‰‹åŠ¨è®¾è®¡æŸå¤±å‡½æ•°çš„å±€é™æ€§å¹¶æ·±åŒ–äº†æ•°æ®æŒ–æ˜èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒMMIF-AMIN åœ¨å®šé‡ä¸å®šæ€§åˆ†æä¸Šå‡ä¼˜äºä¹ç§ä¸»æµ MMIF æ–¹æ³•ï¼Œæ¶ˆèå®éªŒè¿›ä¸€æ­¥è¯å®äº†å„ç»„ä»¶çš„æœ‰æ•ˆæ€§ã€‚è¯¥æ¨¡å‹ä¸ä»…åœ¨åŒ»å­¦å½±åƒé¢†åŸŸè¡¨ç°ä¼˜å¼‚ï¼Œåœ¨å…¶ä»–å›¾åƒèåˆä»»åŠ¡ä¸­ä¹Ÿå±•ç°å‡ºäº†è‰¯å¥½çš„æ‰©å±•æ€§ä¸åº”ç”¨å‰æ™¯ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This manuscript is withdrawn to allow for substantial expansion and restructuring. Based on recent research progress, we plan to add Generalization experiment and reorganize the manuscript structure to improve readability and logical flow. Thank you for your understanding and support",
      "pdf_url": "https://arxiv.org/pdf/2508.08679v2",
      "published_date": "2025-08-12 06:55:38 UTC",
      "updated_date": "2025-12-01 09:05:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:57.158324+00:00"
    },
    {
      "arxiv_id": "2508.10047v1",
      "title": "A Survey of Optimization Modeling Meets LLMs: Progress and Future Directions",
      "title_zh": "æœ€ä¼˜åŒ–å»ºæ¨¡ä¸å¤§è¯­è¨€æ¨¡å‹èåˆç»¼è¿°ï¼šè¿›å±•ä¸æœªæ¥æ–¹å‘",
      "authors": [
        "Ziyang Xiao",
        "Jingrong Xie",
        "Lilin Xu",
        "Shisi Guan",
        "Jingyan Zhu",
        "Xiongwei Han",
        "Xiaojin Fu",
        "WingYin Yu",
        "Han Wu",
        "Wei Shi",
        "Qingcan Kang",
        "Jiahui Duan",
        "Tao Zhong",
        "Mingxuan Yuan",
        "Jia Zeng",
        "Yuan Wang",
        "Gang Chen",
        "Dongxiang Zhang"
      ],
      "abstract": "By virtue of its great utility in solving real-world problems, optimization modeling has been widely employed for optimal decision-making across various sectors, but it requires substantial expertise from operations research professionals. With the advent of large language models (LLMs), new opportunities have emerged to automate the procedure of mathematical modeling. This survey presents a comprehensive and timely review of recent advancements that cover the entire technical stack, including data synthesis and fine-tuning for the base model, inference frameworks, benchmark datasets, and performance evaluation. In addition, we conducted an in-depth analysis on the quality of benchmark datasets, which was found to have a surprisingly high error rate. We cleaned the datasets and constructed a new leaderboard with fair performance evaluation in terms of base LLM model and datasets. We also build an online portal that integrates resources of cleaned datasets, code and paper repository to benefit the community. Finally, we identify limitations in current methodologies and outline future research opportunities.",
      "tldr_zh": "è¯¥è®ºæ–‡å…¨é¢ç»¼è¿°äº†ä¼˜åŒ–å»ºæ¨¡(Optimization Modeling)ä¸å¤§è¯­è¨€æ¨¡å‹(LLMs)ç»“åˆçš„æœ€æ–°è¿›å±•ï¼Œæ—¨åœ¨é™ä½æ•°å­¦å»ºæ¨¡å¯¹ä¸“ä¸šçŸ¥è¯†çš„é«˜è¦æ±‚ã€‚ç ”ç©¶æ¶µç›–äº†ä»æ•°æ®åˆæˆã€æ¨¡å‹å¾®è°ƒåˆ°æ¨ç†æ¡†æ¶(Inference Frameworks)åŠè¯„ä¼°åŸºå‡†çš„å®Œæ•´æŠ€æœ¯æ ˆã€‚ä½œè€…é€šè¿‡æ·±å…¥åˆ†æå‘ç°ï¼Œç°æœ‰çš„åŸºå‡†æ•°æ®é›†(Benchmark Datasets)æ™®éå­˜åœ¨æé«˜çš„é”™è¯¯ç‡ï¼Œä¸¥é‡å½±å“äº†è¯„ä¼°çš„å‡†ç¡®æ€§ã€‚é’ˆå¯¹è¿™ä¸€é—®é¢˜ï¼Œç ”ç©¶å›¢é˜Ÿå¯¹æ•°æ®é›†è¿›è¡Œäº†æ¸…æ´—ï¼Œå¹¶æ„å»ºäº†æ–°çš„æ’è¡Œæ¦œ(Leaderboard)ä»¥æä¾›å…¬å¹³çš„æ€§èƒ½è¯„ä»·ã€‚åŒæ—¶ï¼Œä½œè€…å¼€å‘äº†ä¸€ä¸ªé›†æˆäº†æ¸…æ´—æ•°æ®ã€ä»£ç å’Œè®ºæ–‡èµ„æºçš„åœ¨çº¿é—¨æˆ·ï¼Œä¸ºç›¸å…³ç ”ç©¶ç¤¾åŒºæä¾›äº†é‡è¦æ”¯æŒã€‚æ–‡ç« æœ€åæ€»ç»“äº†ç°æœ‰æ–¹æ³•çš„å±€é™æ€§ï¼Œå¹¶å¯¹æœªæ¥çš„ç ”ç©¶æ–¹å‘æå‡ºäº†å»ºè®®ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10047v1",
      "published_date": "2025-08-12 06:55:33 UTC",
      "updated_date": "2025-08-12 06:55:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:57.656552+00:00"
    },
    {
      "arxiv_id": "2508.09227v1",
      "title": "GSMT: Graph Fusion and Spatiotemporal TaskCorrection for Multi-Bus Trajectory Prediction",
      "title_zh": "GSMTï¼šé¢å‘å¤šå…¬äº¤è½¨è¿¹é¢„æµ‹çš„å›¾èåˆä¸æ—¶ç©ºä»»åŠ¡ä¿®æ­£",
      "authors": [
        "Fan Ding",
        "Hwa Hui Tew",
        "Junn Yong Loo",
        "Susilawati",
        "LiTong Liu",
        "Fang Yu Leong",
        "Xuewen Luo",
        "Kar Keong Chin",
        "Jia Jun Gan"
      ],
      "abstract": "Accurate trajectory prediction for buses is crucial in intelligent transportation systems, particularly within urban environments. In developing regions where access to multimodal data is limited, relying solely on onboard GPS data remains indispensable despite inherent challenges. To address this problem, we propose GSMT, a hybrid model that integrates a Graph Attention Network (GAT) with a sequence-to-sequence Recurrent Neural Network (RNN), and incorporates a task corrector capable of extracting complex behavioral patterns from large-scale trajectory data. The task corrector clusters historical trajectories to identify distinct motion patterns and fine-tunes the predictions generated by the GAT and RNN. Specifically, GSMT fuses dynamic bus information and static station information through embedded hybrid networks to perform trajectory prediction, and applies the task corrector for secondary refinement after the initial predictions are generated. This two-stage approach enables multi-node trajectory prediction among buses operating in dense urban traffic environments under complex conditions. Experiments conducted on a real-world dataset from Kuala Lumpur, Malaysia, demonstrate that our method significantly outperforms existing approaches, achieving superior performance in both short-term and long-term trajectory prediction tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†GSMTï¼Œä¸€ç§ç»“åˆGraph Attention Network (GAT)ä¸åºåˆ—åˆ°åºåˆ—Recurrent Neural Network (RNN)çš„æ··åˆæ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³åŸå¸‚ç¯å¢ƒä¸­ç‰¹åˆ«æ˜¯å¤šæ¨¡æ€æ•°æ®å—é™åœ°åŒºçš„å…¬äº¤è½¨è¿¹é¢„æµ‹éš¾é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡åµŒå…¥å¼æ··åˆç½‘ç»œèåˆäº†åŠ¨æ€å…¬äº¤ä¿¡æ¯ä¸é™æ€ç«™ç‚¹ä¿¡æ¯ï¼Œå®ç°äº†åœ¨å¤æ‚åŸå¸‚äº¤é€šç¯å¢ƒä¸‹çš„å¤šèŠ‚ç‚¹è½¨è¿¹é¢„æµ‹ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†ä¸€ä¸ªTask Correctorç»„ä»¶ï¼Œè¯¥ç»„ä»¶é€šè¿‡èšç±»å†å²è½¨è¿¹æ¥è¯†åˆ«ä¸åŒçš„è¿åŠ¨æ¨¡å¼ï¼Œå¹¶å¯¹GATå’ŒRNNç”Ÿæˆçš„åˆå§‹é¢„æµ‹è¿›è¡ŒäºŒæ¬¡ç»†åŒ–ä¸å¾®è°ƒã€‚è¿™ç§ä¸¤é˜¶æ®µæ–¹æ³•èƒ½å¤Ÿæœ‰æ•ˆä»å¤§è§„æ¨¡è½¨è¿¹æ•°æ®ä¸­æå–å¤æ‚çš„è¡Œä¸ºç‰¹å¾ï¼Œå¢å¼ºäº†æ¨¡å‹åœ¨å¯†é›†äº¤é€šæµä¸‹çš„é²æ£’æ€§ã€‚åœ¨é©¬æ¥è¥¿äºšå‰éš†å¡çœŸå®ä¸–ç•Œæ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒGSMTåœ¨çŸ­æœŸå’Œé•¿æœŸè½¨è¿¹é¢„æµ‹ä»»åŠ¡ä¸­å‡æ˜¾è‘—ä¼˜äºç°æœ‰æ–¹æ³•ï¼Œä¸ºæ™ºèƒ½äº¤é€šç³»ç»Ÿæä¾›äº†æ›´å¯é çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by ITSC 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.09227v1",
      "published_date": "2025-08-12 06:54:26 UTC",
      "updated_date": "2025-08-12 06:54:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:22:58.358066+00:00"
    },
    {
      "arxiv_id": "2508.10046v1",
      "title": "SABIA: An AI-Powered Tool for Detecting Opioid-Related Behaviors on Social Media",
      "title_zh": "SABIAï¼šä¸€ç§ç”¨äºè¯†åˆ«ç¤¾äº¤åª’ä½“ä¸­é˜¿ç‰‡ç±»è¯ç‰©ç›¸å…³è¡Œä¸ºçš„äººå·¥æ™ºèƒ½é©±åŠ¨å·¥å…·",
      "authors": [
        "Muhammad Ahmad",
        "Fida Ullah",
        "Muhammad Usman",
        "Ildar Batyrshin",
        "Grigori Sidorov"
      ],
      "abstract": "Social media platforms have become valuable tools for understanding public health challenges by offering insights into patient behaviors, medication use, and mental health issues. However, analyzing such data remains difficult due to the prevalence of informal language, slang, and coded communication, which can obscure the detection of opioid misuse. This study addresses the issue of opioid-related user behavior on social media, including informal expressions, slang terms, and misspelled or coded language. We analyzed the existing Bidirectional Encoder Representations from Transformers (BERT) technique and developed a BERT-BiLSTM-3CNN hybrid deep learning model, named SABIA, to create a single-task classifier that effectively captures the features of the target dataset. The SABIA model demonstrated strong capabilities in capturing semantics and contextual information. The proposed approach includes: (1) data preprocessing, (2) data representation using the SABIA model, (3) a fine-tuning phase, and (4) classification of user behavior into five categories. A new dataset was constructed from Reddit posts, identifying opioid user behaviors across five classes: Dealers, Active Opioid Users, Recovered Users, Prescription Users, and Non-Users, supported by detailed annotation guidelines. Experiments were conducted using supervised learning. Results show that SABIA achieved benchmark performance, outperforming the baseline (Logistic Regression, LR = 0.86) and improving accuracy by 9.30%. Comparisons with seven previous studies confirmed its effectiveness and robustness. This study demonstrates the potential of hybrid deep learning models for detecting complex opioid-related behaviors on social media, supporting public health monitoring and intervention efforts.",
      "tldr_zh": "æœ¬ç ”ç©¶é’ˆå¯¹ç¤¾äº¤åª’ä½“ä¸Šé˜¿ç‰‡ç±»è¯ç‰©(Opioid)ç›¸å…³è¡Œä¸ºç›‘æµ‹ä¸­å­˜åœ¨çš„éæ­£å¼è¯­è¨€ã€ä¿šè¯­åŠéšè¯­ç­‰è¯†åˆ«éš¾é¢˜ï¼Œå¼€å‘äº†åä¸ºSABIAçš„AIé©±åŠ¨å·¥å…·ã€‚è¯¥å·¥å…·é‡‡ç”¨äº†ä¸€ç§ç»“åˆäº†BERT-BiLSTM-3CNNçš„æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹ï¼Œæ—¨åœ¨é€šè¿‡å•ä»»åŠ¡åˆ†ç±»å™¨ç²¾å‡†æ•æ‰ç›®æ ‡æ•°æ®é›†çš„è¯­ä¹‰å’Œä¸Šä¸‹æ–‡ç‰¹å¾ã€‚ç ”ç©¶å›¢é˜ŸåŸºäºRedditå¸–å­æ„å»ºäº†åŒ…å«æ¯’è´©(Dealers)ã€æ´»è·ƒç”¨æˆ·(Active Opioid Users)ã€åº·å¤ç”¨æˆ·(Recovered Users)ã€å¤„æ–¹è¯ç”¨æˆ·(Prescription Users)å’Œéç”¨æˆ·(Non-Users)äº”ç±»è¡Œä¸ºçš„å…¨æ–°æ•°æ®é›†ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒSABIAæ¨¡å‹çš„å‡†ç¡®ç‡è¾ƒLogistic Regression (LR)åŸºçº¿æå‡äº†9.30%ï¼Œåœ¨ä¸ä¸ƒé¡¹å…ˆå‰ç ”ç©¶çš„å¯¹æ¯”ä¸­å±•ç°å‡ºå“è¶Šçš„æœ‰æ•ˆæ€§å’Œé²æ£’æ€§ã€‚è¯¥ç ”ç©¶å‡¸æ˜¾äº†æ··åˆæ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨å¤æ‚è¡Œä¸ºæ£€æµ‹ä¸­çš„æ½œåŠ›ï¼Œä¸ºå…¬å…±å«ç”Ÿç›‘æµ‹ä¸å¹²é¢„æä¾›äº†é‡è¦çš„æŠ€æœ¯æ”¯æŒã€‚",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.10046v1",
      "published_date": "2025-08-12 06:52:41 UTC",
      "updated_date": "2025-08-12 06:52:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:23:49.194739+00:00"
    },
    {
      "arxiv_id": "2508.16603v1",
      "title": "GreenTEA: Gradient Descent with Topic-modeling and Evolutionary Auto-prompting",
      "title_zh": "GreenTEAï¼šèåˆä¸»é¢˜å»ºæ¨¡ä¸è¿›åŒ–è‡ªåŠ¨æç¤ºçš„æ¢¯åº¦ä¸‹é™æ–¹æ³•",
      "authors": [
        "Zheng Dong",
        "Luming Shang",
        "Gabriela Olinto"
      ],
      "abstract": "High-quality prompts are crucial for Large Language Models (LLMs) to achieve exceptional performance. However, manually crafting effective prompts is labor-intensive and demands significant domain expertise, limiting its scalability. Existing automatic prompt optimization methods either extensively explore new prompt candidates, incurring high computational costs due to inefficient searches within a large solution space, or overly exploit feedback on existing prompts, risking suboptimal optimization because of the complex prompt landscape. To address these challenges, we introduce GreenTEA, an agentic LLM workflow for automatic prompt optimization that balances candidate exploration and knowledge exploitation. It leverages a collaborative team of agents to iteratively refine prompts based on feedback from error samples. An analyzing agent identifies common error patterns resulting from the current prompt via topic modeling, and a generation agent revises the prompt to directly address these key deficiencies. This refinement process is guided by a genetic algorithm framework, which simulates natural selection by evolving candidate prompts through operations such as crossover and mutation to progressively optimize model performance. Extensive numerical experiments conducted on public benchmark datasets suggest the superior performance of GreenTEA against human-engineered prompts and existing state-of-the-arts for automatic prompt optimization, covering logical and quantitative reasoning, commonsense, and ethical decision-making.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† GreenTEAï¼Œä¸€ç§å¹³è¡¡äº†å€™é€‰æ¢ç´¢ä¸çŸ¥è¯†åˆ©ç”¨çš„æ™ºèƒ½ä½“ LLM Workflowï¼Œæ—¨åœ¨è§£å†³æ‰‹åŠ¨è®¾è®¡ Prompt æ•ˆç‡ä½ä¸”éš¾ä»¥æ‰©å±•çš„é—®é¢˜ã€‚è¯¥æ¡†æ¶é‡‡ç”¨å¤šæ™ºèƒ½ä½“åä½œæ¨¡å¼ï¼Œé€šè¿‡åˆ†ææ™ºèƒ½ä½“åˆ©ç”¨ Topic Modeling è¯†åˆ«é”™è¯¯æ ·æœ¬çš„å…±æ€§æ¨¡å¼ï¼Œå¹¶ç”±ç”Ÿæˆæ™ºèƒ½ä½“é’ˆå¯¹æ€§åœ°ä¼˜åŒ– Prompt å†…å®¹ã€‚å…¶æ ¸å¿ƒä¼˜åŒ–é€»è¾‘åŸºäº Genetic Algorithm æ¡†æ¶ï¼Œåˆ©ç”¨ Crossover å’Œ Mutation ç­‰æ¼”åŒ–æ“ä½œåœ¨å¤æ‚çš„ Prompt ç©ºé—´ä¸­è¿›è¡Œé«˜æ•ˆæœç´¢ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒGreenTEA åœ¨é€»è¾‘æ¨ç†ã€å¸¸è¯†åˆ¤æ–­å’Œä¼¦ç†å†³ç­–ç­‰ä»»åŠ¡ä¸Šå‡ä¼˜äºäººå·¥å·¥ç¨‹è®¾è®¡çš„ Prompt åŠç°æœ‰çš„ State-of-the-art è‡ªåŠ¨ä¼˜åŒ–ç®—æ³•ã€‚è¿™ä¸€æ–¹æ³•ä¸ºæå‡ Large Language Models çš„ä»»åŠ¡è¡¨ç°æä¾›äº†ä¸€ç§è‡ªåŠ¨åŒ–ä¸”é«˜æ€§èƒ½çš„è·¯å¾„ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.16603v1",
      "published_date": "2025-08-12 06:48:30 UTC",
      "updated_date": "2025-08-12 06:48:30 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:24:43.860951+00:00"
    },
    {
      "arxiv_id": "2508.09225v1",
      "title": "AMRG: Extend Vision Language Models for Automatic Mammography Report Generation",
      "title_zh": "AMRGï¼šç”¨äºè‡ªåŠ¨ä¹³è…º X çº¿æ‘„å½±æŠ¥å‘Šç”Ÿæˆçš„è§†è§‰è¯­è¨€æ¨¡å‹æ‰©å±•",
      "authors": [
        "Nak-Jun Sung",
        "Donghyun Lee",
        "Bo Hwa Choi",
        "Chae Jung Park"
      ],
      "abstract": "Mammography report generation is a critical yet underexplored task in medical AI, characterized by challenges such as multiview image reasoning, high-resolution visual cues, and unstructured radiologic language. In this work, we introduce AMRG (Automatic Mammography Report Generation), the first end-to-end framework for generating narrative mammography reports using large vision-language models (VLMs). Building upon MedGemma-4B-it-a domain-specialized, instruction-tuned VLM-we employ a parameter-efficient fine-tuning (PEFT) strategy via Low-Rank Adaptation (LoRA), enabling lightweight adaptation with minimal computational overhead. We train and evaluate AMRG on DMID, a publicly available dataset of paired high-resolution mammograms and diagnostic reports. This work establishes the first reproducible benchmark for mammography report generation, addressing a longstanding gap in multimodal clinical AI. We systematically explore LoRA hyperparameter configurations and conduct comparative experiments across multiple VLM backbones, including both domain-specific and general-purpose models under a unified tuning protocol. Our framework demonstrates strong performance across both language generation and clinical metrics, achieving a ROUGE-L score of 0.5691, METEOR of 0.6152, CIDEr of 0.5818, and BI-RADS accuracy of 0.5582. Qualitative analysis further highlights improved diagnostic consistency and reduced hallucinations. AMRG offers a scalable and adaptable foundation for radiology report generation and paves the way for future research in multimodal medical AI.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†AMRGï¼Œè¿™æ˜¯é¦–ä¸ªç”¨äºè‡ªåŠ¨ç”Ÿæˆæè¿°æ€§ä¹³è…ºXå°„çº¿æ‘„å½±(Mammography)æŠ¥å‘Šçš„ç«¯åˆ°ç«¯æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šè§†å›¾å›¾åƒæ¨ç†ã€é«˜åˆ†è¾¨ç‡è§†è§‰çº¿ç´¢åŠéç»“æ„åŒ–æ”¾å°„å­¦è¯­è¨€å¸¦æ¥çš„æŒ‘æˆ˜ã€‚è¯¥æ¡†æ¶åŸºäºé¢†åŸŸä¸“ç”¨ä¸”ç»è¿‡æŒ‡ä»¤å¾®è°ƒçš„è§†è§‰è¯­è¨€æ¨¡å‹(VLMs) MedGemma-4B-itï¼Œå¹¶é‡‡ç”¨äº†ä½ç§©è‡ªé€‚åº”(LoRA)çš„å‚æ•°é«˜æ•ˆå¾®è°ƒ(PEFT)ç­–ç•¥ï¼Œä»¥æœ€å°çš„è®¡ç®—å¼€é”€å®ç°è½»é‡åŒ–é€‚é…ã€‚ç ”ç©¶äººå‘˜åœ¨å…¬å¼€æ•°æ®é›†DMIDä¸Šå¯¹AMRGè¿›è¡Œäº†è®­ç»ƒå’Œè¯„ä¼°ï¼Œä»è€Œå»ºç«‹äº†ä¹³è…ºXå°„çº¿æ‘„å½±æŠ¥å‘Šç”Ÿæˆé¢†åŸŸçš„é¦–ä¸ªå¯å¤ç°åŸºå‡†ï¼Œå¡«è¡¥äº†å¤šæ¨¡æ€ä¸´åºŠAIçš„é•¿æœŸç©ºç™½ã€‚å®éªŒé€šè¿‡å¯¹å¤šç§VLMä¸»å¹²ç½‘ç»œè¿›è¡Œç»Ÿä¸€è°ƒä¼˜å¯¹æ¯”ï¼Œè¯æ˜äº†è¯¥æ¡†æ¶åœ¨è¯­è¨€ç”Ÿæˆå’Œä¸´åºŠæŒ‡æ ‡ä¸Šå‡è¡¨ç°å‡ºè‰²ï¼Œå…¶ROUGE-Lè¾¾åˆ°0.5691ï¼ŒMETEORä¸º0.6152ï¼ŒBI-RADSå‡†ç¡®ç‡ä¸º0.5582ã€‚å®šæ€§åˆ†æè¿›ä¸€æ­¥è¡¨æ˜ï¼ŒAMRGæœ‰æ•ˆæé«˜äº†è¯Šæ–­çš„ä¸€è‡´æ€§å¹¶å‡å°‘äº†å¹»è§‰(hallucinations)ï¼Œä¸ºæ”¾å°„ç§‘æŠ¥å‘Šç”Ÿæˆæä¾›äº†å¯æ‰©å±•ä¸”å…·é€‚åº”æ€§çš„åŸºç¡€ã€‚",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09225v1",
      "published_date": "2025-08-12 06:37:41 UTC",
      "updated_date": "2025-08-12 06:37:41 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:23:51.893324+00:00"
    },
    {
      "arxiv_id": "2508.08672v2",
      "title": "Imposing AI: Deceptive design patterns against sustainability",
      "title_zh": "å¼ºåŠ å¼äººå·¥æ™ºèƒ½ï¼šè¿èƒŒå¯æŒç»­å‘å±•çš„æ¬ºéª—æ€§è®¾è®¡æ¨¡å¼",
      "authors": [
        "AnaÃ«lle Beignon",
        "Thomas Thibault",
        "Nolwenn Maudet"
      ],
      "abstract": "Generative AI is being massively deployed in digital services, at a scale that will result in significant environmental harm. We document how tech companies are transforming established user interfaces to impose AI use and show how and to what extent these strategies fit within established deceptive pattern categories. We identify two main design strategies that are implemented to impose AI use in both personal and professional contexts: imposing AI features in interfaces at the expense of existing non-AI features and promoting narratives about AI that make it harder to resist using it. We discuss opportunities for regulating the imposed adoption of AI features, which would inevitably lead to negative environmental effects.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) åœ¨æ•°å­—æœåŠ¡ä¸­çš„å¤§è§„æ¨¡éƒ¨ç½²åŠå…¶å¯èƒ½å¼•å‘çš„ä¸¥é‡ç¯å¢ƒå±å®³ã€‚ä½œè€…è¯¦ç»†è®°å½•äº†ç§‘æŠ€å…¬å¸å¦‚ä½•é€šè¿‡æ”¹é€ ç°æœ‰ç”¨æˆ·ç•Œé¢æ¥å¼ºåˆ¶æ¨è¡Œäººå·¥æ™ºèƒ½çš„ä½¿ç”¨ï¼Œå¹¶åˆ†æäº†è¿™äº›ç­–ç•¥å¦‚ä½•å½’ç±»äºç°æœ‰çš„æ¬ºéª—æ€§è®¾è®¡æ¨¡å¼ (Deceptive design patterns)ã€‚ç ”ç©¶è¯†åˆ«å‡ºä¸¤ç§æ ¸å¿ƒè®¾è®¡ç­–ç•¥ï¼šä¸€æ˜¯åœ¨ç•Œé¢ä¸­å¼ºåŠ ä»¥äººå·¥æ™ºèƒ½ä¸ºä¸­å¿ƒçš„åŠŸèƒ½å¹¶å‰Šå¼±åŸæœ‰çš„éäººå·¥æ™ºèƒ½åŠŸèƒ½ï¼ŒäºŒæ˜¯é€šè¿‡ç‰¹å®šå™è¿°å¢åŠ ç”¨æˆ·æ‹’ç»ä½¿ç”¨äººå·¥æ™ºèƒ½çš„éš¾åº¦ã€‚æ–‡ç« æœ€åè®¨è®ºäº†å¯¹è¿™ç§å¼ºåˆ¶æ€§äººå·¥æ™ºèƒ½éƒ¨ç½²è¿›è¡Œç›‘ç®¡çš„å¯èƒ½æ€§ï¼Œä»¥åº”å¯¹å…¶ä¸å¯é¿å…å¸¦æ¥çš„è´Ÿé¢ç¯å¢ƒå½±å“ã€‚",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08672v2",
      "published_date": "2025-08-12 06:37:39 UTC",
      "updated_date": "2025-09-12 13:49:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:23:57.599113+00:00"
    },
    {
      "arxiv_id": "2508.08665v2",
      "title": "Aryabhata: An exam-focused language model for JEE Math",
      "title_zh": "Aryabhataï¼šé¢å‘ JEE æ•°å­¦çš„åº”è¯•å‹è¯­è¨€æ¨¡å‹",
      "authors": [
        "Ritvik Rastogi",
        "Sachin Dharashivkar",
        "Sandeep Varma"
      ],
      "abstract": "We present Aryabhata 1.0, a compact 7B parameter math reasoning model optimized for the Indian academic exam, the Joint Entrance Examination (JEE). Despite rapid progress in large language models (LLMs), current models often remain unsuitable for educational use. Aryabhata 1.0 is built by merging strong open-weight reasoning models, followed by supervised fine-tuning (SFT) with curriculum learning on verified chain-of-thought (CoT) traces curated through best-of-$n$ rejection sampling. To further boost performance, we apply reinforcement learning with verifiable rewards (RLVR) using A2C objective with group-relative advantage estimation along with novel exploration strategies such as Adaptive Group Resizing and Temperature Scaling. Evaluated on both in-distribution (JEE Main 2025) and out-of-distribution (MATH, GSM8K) benchmarks, Aryabhata outperforms existing models in accuracy and efficiency, while offering pedagogically useful step-by-step reasoning. We release Aryabhata as a foundation model to advance exam-centric, open-source small language models. This marks our first open release for community feedback (https://huggingface.co/PhysicsWallahAI/Aryabhata-1.0); PW is actively training future models to further improve learning outcomes for students.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¨å‡ºäº† Aryabhata 1.0ï¼Œè¿™æ˜¯ä¸€ä¸ªåŒ…å« 7B å‚æ•°çš„å°å‹æ•°å­¦æ¨ç†æ¨¡å‹ï¼Œä¸“é—¨é’ˆå¯¹å°åº¦è”åˆå…¥å­¦è€ƒè¯• Joint Entrance Examination (JEE) è¿›è¡Œä¼˜åŒ–ï¼Œæ—¨åœ¨è§£å†³å½“å‰å¤§è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸé€‚ç”¨æ€§ä¸è¶³çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹é€šè¿‡åˆå¹¶å¼ºå¤§çš„å¼€æºæ¨ç†æƒé‡ï¼Œå¹¶åˆ©ç”¨ç»è¿‡ best-of-n æ‹’ç»é‡‡æ ·ç­›é€‰çš„éªŒè¯ Chain-of-Thought (CoT) è½¨è¿¹è¿›è¡Œè¯¾ç¨‹å­¦ä¹ ä¸‹çš„ç›‘ç£å¾®è°ƒ (SFT) æ„å»ºã€‚ä¸ºè¿›ä¸€æ­¥æå‡æ€§èƒ½ï¼Œç ”ç©¶å›¢é˜Ÿé‡‡ç”¨äº†åŸºäº Reinforcement Learning with Verifiable Rewards (RLVR) çš„ A2C ç›®æ ‡ï¼Œå¹¶å¼•å…¥äº† Adaptive Group Resizing å’Œ Temperature Scaling ç­‰åˆ›æ–°æ¢ç´¢ç­–ç•¥ã€‚å®éªŒè¯„ä¼°æ˜¾ç¤ºï¼ŒAryabhata 1.0 åœ¨ JEE Main 2025ã€MATH å’Œ GSM8K ç­‰åŸºå‡†æµ‹è¯•ä¸­å‡å±•ç°å‡ºä¼˜äºç°æœ‰æ¨¡å‹çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹èƒ½æä¾›å…·æœ‰æ•™å­¦ä»·å€¼çš„åˆ†æ­¥æ¨ç†è¿‡ç¨‹ï¼Œä½œä¸ºå¼€æºåŸºç¡€æ¨¡å‹å‘å¸ƒï¼Œä¸ºæ¨åŠ¨ä»¥è€ƒè¯•ä¸ºä¸­å¿ƒçš„å°è¯­è¨€æ¨¡å‹ç ”ç©¶æä¾›äº†é‡è¦æ”¯æ’‘ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08665v2",
      "published_date": "2025-08-12 06:20:07 UTC",
      "updated_date": "2025-08-13 05:34:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:24:15.756473+00:00"
    },
    {
      "arxiv_id": "2508.08661v1",
      "title": "Hallucinations in Code Change to Natural Language Generation: Prevalence and Evaluation of Detection Metrics",
      "title_zh": "ä»£ç å˜æ›´ç”Ÿæˆè‡ªç„¶è¯­è¨€ä¸­çš„å¹»è§‰ï¼šæ™®éæ€§åˆ†æä¸æ£€æµ‹æŒ‡æ ‡è¯„ä¼°",
      "authors": [
        "Chunhua Liu",
        "Hong Yi Lin",
        "Patanamon Thongtanunam"
      ],
      "abstract": "Language models have shown strong capabilities across a wide range of tasks in software engineering, such as code generation, yet they suffer from hallucinations. While hallucinations have been studied independently in natural language and code generation, their occurrence in tasks involving code changes which have a structurally complex and context-dependent format of code remains largely unexplored. This paper presents the first comprehensive analysis of hallucinations in two critical tasks involving code change to natural language generation: commit message generation and code review comment generation. We quantify the prevalence of hallucinations in recent language models and explore a range of metric-based approaches to automatically detect them. Our findings reveal that approximately 50\\% of generated code reviews and 20\\% of generated commit messages contain hallucinations. Whilst commonly used metrics are weak detectors on their own, combining multiple metrics substantially improves performance. Notably, model confidence and feature attribution metrics effectively contribute to hallucination detection, showing promise for inference-time detection.\\footnote{All code and data will be released upon acceptance.",
      "tldr_zh": "è¯¥ç ”ç©¶é¦–æ¬¡å…¨é¢åˆ†æäº†ä»£ç å˜æ›´åˆ°è‡ªç„¶è¯­è¨€ç”Ÿæˆ(Code Change to Natural Language Generation)ä»»åŠ¡ä¸­çš„å¹»è§‰(Hallucinations)é—®é¢˜ï¼Œé‡ç‚¹æ¢è®¨äº†æäº¤ä¿¡æ¯ç”Ÿæˆ(Commit Message Generation)å’Œä»£ç å®¡æŸ¥æ³¨é‡Šç”Ÿæˆ(Code Review Comment Generation)ä¸¤ä¸ªå…³é”®ä»»åŠ¡ã€‚ç ”ç©¶é€šè¿‡é‡åŒ–åˆ†æå‘ç°ï¼Œç”±äºä»£ç å˜æ›´å…·æœ‰å¤æ‚çš„ç»“æ„å’Œä¸Šä¸‹æ–‡ä¾èµ–æ€§ï¼Œç”Ÿæˆçš„ä»£ç å®¡æŸ¥ä¸­çº¦æœ‰50%åŒ…å«å¹»è§‰ï¼Œè€Œç”Ÿæˆçš„æäº¤ä¿¡æ¯ä¸­çº¦æœ‰20%å­˜åœ¨å¹»è§‰ã€‚ä¸ºäº†åº”å¯¹è¿™ä¸€æŒ‘æˆ˜ï¼Œç ”ç©¶è¯„ä¼°äº†å¤šç§åŸºäºæŒ‡æ ‡(Metric-based)çš„è‡ªåŠ¨æ£€æµ‹æ–¹æ³•ï¼Œå‘ç°è™½ç„¶å•ä¸€å¸¸ç”¨æŒ‡æ ‡çš„æ£€æµ‹èƒ½åŠ›è¾ƒå¼±ï¼Œä½†ç»“åˆå¤šä¸ªæŒ‡æ ‡å¯ä»¥æ˜¾è‘—æå‡æ£€æµ‹æ€§èƒ½ã€‚å®éªŒç»“æœç‰¹åˆ«å¼ºè°ƒäº†æ¨¡å‹ç½®ä¿¡åº¦(Model Confidence)å’Œç‰¹å¾å½’å› (Feature Attribution)æŒ‡æ ‡åœ¨å¹»è§‰æ£€æµ‹ä¸­çš„æœ‰æ•ˆæ€§ï¼Œä¸ºåœ¨æ¨ç†é˜¶æ®µ(Inference-time)å®ç°æœ‰æ•ˆçš„å¹»è§‰æ£€æµ‹æä¾›äº†æå…·å‰æ™¯çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "8 main pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08661v1",
      "published_date": "2025-08-12 05:59:33 UTC",
      "updated_date": "2025-08-12 05:59:33 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:24:07.494323+00:00"
    },
    {
      "arxiv_id": "2508.08659v1",
      "title": "Hybrid Node-Destroyer Model with Large Neighborhood Search for Solving the Capacitated Vehicle Routing Problem",
      "title_zh": "ç»“åˆå¤§é‚»åŸŸæœç´¢æ±‚è§£å¸¦å®¹é‡é™åˆ¶è½¦è¾†è·¯å¾„é—®é¢˜çš„æ··åˆ Node-Destroyer æ¨¡å‹",
      "authors": [
        "Bachtiar Herdianto",
        "Romain Billot",
        "Flavien Lucas",
        "Marc Sevaux",
        "Daniele Vigo"
      ],
      "abstract": "In this research, we propose an iterative learning hybrid optimization solver developed to strengthen the performance of metaheuristic algorithms in solving the Capacitated Vehicle Routing Problem (CVRP). The iterative hybrid mechanism integrates the proposed Node-Destroyer Model, a machine learning hybrid model that utilized Graph Neural Networks (GNNs) such identifies and selects customer nodes to guide the Large Neighborhood Search (LNS) operator within the metaheuristic optimization frameworks. This model leverages the structural properties of the problem and solution that can be represented as a graph, to guide strategic selections concerning node removal. The proposed approach reduces operational complexity and scales down the search space involved in the optimization process. The hybrid approach is applied specifically to the CVRP and does not require retraining across problem instances of different sizes. The proposed hybrid mechanism is able to improve the performance of baseline metaheuristic algorithms. Our approach not only enhances the solution quality for standard CVRP benchmarks but also proves scalability on very large-scale instances with up to 30,000 customer nodes. Experimental evaluations on benchmark datasets show that the proposed hybrid mechanism is capable of improving different baseline algorithms, achieving better quality of solutions under similar settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§è¿­ä»£å­¦ä¹ çš„æ··åˆä¼˜åŒ–æ±‚è§£å™¨ï¼Œæ—¨åœ¨å¢å¼ºå…ƒå¯å‘å¼ç®—æ³• (metaheuristic algorithms) åœ¨è§£å†³å¸¦å®¹é‡é™åˆ¶çš„è½¦è¾†è·¯å¾„é—®é¢˜ (Capacitated Vehicle Routing Problem, CVRP) ä¸­çš„æ€§èƒ½ã€‚å…¶æ ¸å¿ƒæ˜¯æå‡ºäº†ä¸€ç§åä¸º Node-Destroyer Model çš„æœºå™¨å­¦ä¹ æ··åˆæ¨¡å‹ï¼Œåˆ©ç”¨å›¾ç¥ç»ç½‘ç»œ (Graph Neural Networks, GNNs) è¯†åˆ«å¹¶é€‰æ‹©å®¢æˆ·èŠ‚ç‚¹ï¼Œä»è€Œå¼•å¯¼å…ƒå¯å‘å¼æ¡†æ¶ä¸­çš„å¤§é‚»åŸŸæœç´¢ (Large Neighborhood Search, LNS) ç®—å­ã€‚è¯¥æ¨¡å‹åˆ©ç”¨å¯è¡¨ç¤ºä¸ºå›¾çš„é—®é¢˜å’Œè§£çš„ç»“æ„ç‰¹æ€§æ¥æŒ‡å¯¼èŠ‚ç‚¹ç§»é™¤ç­–ç•¥ï¼Œæœ‰æ•ˆé™ä½äº†è¿ç®—å¤æ‚åº¦å¹¶ç¼©å°äº†ä¼˜åŒ–æœç´¢ç©ºé—´ã€‚è¯¥æ··åˆæ–¹æ³•æ— éœ€é’ˆå¯¹ä¸åŒè§„æ¨¡çš„å®ä¾‹è¿›è¡Œé‡æ–°è®­ç»ƒï¼Œå…·æœ‰è‰¯å¥½çš„æ³›åŒ–æ€§ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥æ–¹æ³•ä¸ä»…åœ¨æ ‡å‡† CVRP åŸºå‡†æµ‹è¯•ä¸­æå‡äº†æ±‚è§£è´¨é‡ï¼Œæ›´åœ¨åŒ…å« 30,000 ä¸ªå®¢æˆ·èŠ‚ç‚¹çš„è¶…å¤§è§„æ¨¡å®ä¾‹ä¸Šè¯æ˜äº†å“è¶Šçš„å¯æ‰©å±•æ€§ã€‚è¯„ä¼°è¡¨æ˜ï¼Œè¯¥æ··åˆæœºåˆ¶èƒ½æ˜¾è‘—æ”¹è¿›å¤šç§åŸºå‡†ç®—æ³•ï¼Œåœ¨ç›¸åŒè®¾å®šä¸‹å–å¾—æ›´ä¼˜çš„è§£ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 10 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08659v1",
      "published_date": "2025-08-12 05:56:13 UTC",
      "updated_date": "2025-08-12 05:56:13 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:24:16.850733+00:00"
    },
    {
      "arxiv_id": "2508.11690v1",
      "title": "Real Time Child Abduction And Detection System",
      "title_zh": "å®æ—¶å„¿ç«¥è¯±æ‹æ£€æµ‹ç³»ç»Ÿ",
      "authors": [
        "Tadisetty Sai Yashwanth",
        "Yangalasetty Sruthi Royal",
        "Vankayala Rajeshwari Shreya",
        "Mayank Kashyap",
        "Divyaprabha K N"
      ],
      "abstract": "Child safety continues to be a paramount concern worldwide, with child abduction posing significant threats to communities. This paper presents the development of an edge-based child abduction detection and alert system utilizing a multi-agent framework where each agent incorporates Vision-Language Models (VLMs) deployed on a Raspberry Pi. Leveraging the advanced capabilities of VLMs within individual agents of a multi-agent team, our system is trained to accurately detect and interpret complex interactions involving children in various environments in real-time. The multi-agent system is deployed on a Raspberry Pi connected to a webcam, forming an edge device capable of processing video feeds, thereby reducing latency and enhancing privacy. An integrated alert system utilizes the Twilio API to send immediate SMS and WhatsApp notifications, including calls and messages, when a potential child abduction event is detected. Experimental results demonstrate that the system achieves high accuracy in detecting potential abduction scenarios, with near real-time performance suitable for practical deployment. The multi-agent architecture enhances the system's ability to process complex situational data, improving detection capabilities over traditional single-model approaches. The edge deployment ensures scalability and cost-effectiveness, making it accessible for widespread use. The proposed system offers a proactive solution to enhance child safety through continuous monitoring and rapid alerting, contributing a valuable tool in efforts to prevent child abductions.",
      "tldr_zh": "è¯¥ç ”ç©¶å¼€å‘äº†ä¸€ç§åŸºäºè¾¹ç¼˜è®¡ç®—(edge-based)çš„å„¿ç«¥æ‹å–æ£€æµ‹ä¸é¢„è­¦ç³»ç»Ÿï¼Œé‡‡ç”¨äº†å¤šæ™ºèƒ½ä½“æ¡†æ¶(multi-agent framework)ä»¥å®ç°å¯¹å¤æ‚åœºæ™¯çš„å®æ—¶ç›‘æ§ã€‚ç³»ç»Ÿä¸­æ¯ä¸ªæ™ºèƒ½ä½“éƒ½é›†æˆäº†éƒ¨ç½²åœ¨ Raspberry Pi ä¸Šçš„è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)ï¼Œèƒ½å¤Ÿç²¾å‡†è¯†åˆ«å¹¶è§£è¯»å„ç§ç¯å¢ƒä¸­æ¶‰åŠå„¿ç«¥çš„å¼‚å¸¸äº¤äº’è¡Œä¸ºã€‚é€šè¿‡åœ¨è¾¹ç¼˜è®¾å¤‡ä¸Šç›´æ¥å¤„ç†è§†é¢‘æµï¼Œè¯¥æ–¹æ¡ˆåœ¨é™ä½æ•°æ®ä¼ è¾“å»¶è¿Ÿçš„åŒæ—¶æœ‰æ•ˆå¢å¼ºäº†ç”¨æˆ·éšç§ä¿æŠ¤ã€‚ç³»ç»Ÿè¿˜æ•´åˆäº† Twilio APIï¼Œä¸€æ—¦è¯†åˆ«åˆ°æ½œåœ¨çš„æ‹å–äº‹ä»¶ï¼Œä¾¿èƒ½é€šè¿‡çŸ­ä¿¡ã€WhatsAppã€è¯­éŸ³é€šè¯å’Œæ¶ˆæ¯ç«‹å³å‘å‡ºè­¦æŠ¥ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œè¯¥ç³»ç»Ÿåœ¨æ£€æµ‹æ½œåœ¨æ‹å–åœºæ™¯æ–¹é¢è¾¾åˆ°äº†æé«˜çš„å‡†ç¡®ç‡ï¼Œå…¶å¤šæ™ºèƒ½ä½“æ¶æ„åœ¨å¤„ç†å¤æ‚æƒ…å¢ƒæ•°æ®æ–¹é¢çš„æ€§èƒ½ä¼˜äºä¼ ç»Ÿçš„å•æ¨¡å‹æ–¹æ³•(single-model approaches)ã€‚è¿™ç§å…·å¤‡æ‰©å±•æ€§å’Œæˆæœ¬æ•ˆç›Šçš„è¾¹ç¼˜éƒ¨ç½²æ–¹æ¡ˆï¼Œä¸ºæå‡å„¿ç«¥å®‰å…¨å’Œé¢„é˜²æ‹å–æä¾›äº†ä¸€ç§é«˜æ•ˆä¸”ä¸»åŠ¨çš„è‡ªåŠ¨åŒ–ç›‘æ§æ‰‹æ®µã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.11690v1",
      "published_date": "2025-08-12 05:56:05 UTC",
      "updated_date": "2025-08-12 05:56:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:24:15.457978+00:00"
    },
    {
      "arxiv_id": "2508.08657v1",
      "title": "$\\text{M}^{2}$LLM: Multi-view Molecular Representation Learning with Large Language Models",
      "title_zh": "$\\text{M}^{2}$LLMï¼šåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„å¤šè§†å›¾åˆ†å­è¡¨ç¤ºå­¦ä¹ ",
      "authors": [
        "Jiaxin Ju",
        "Yizhen Zheng",
        "Huan Yee Koh",
        "Can Wang",
        "Shirui Pan"
      ],
      "abstract": "Accurate molecular property prediction is a critical challenge with wide-ranging applications in chemistry, materials science, and drug discovery. Molecular representation methods, including fingerprints and graph neural networks (GNNs), achieve state-of-the-art results by effectively deriving features from molecular structures. However, these methods often overlook decades of accumulated semantic and contextual knowledge. Recent advancements in large language models (LLMs) demonstrate remarkable reasoning abilities and prior knowledge across scientific domains, leading us to hypothesize that LLMs can generate rich molecular representations when guided to reason in multiple perspectives. To address these gaps, we propose $\\text{M}^{2}$LLM, a multi-view framework that integrates three perspectives: the molecular structure view, the molecular task view, and the molecular rules view. These views are fused dynamically to adapt to task requirements, and experiments demonstrate that $\\text{M}^{2}$LLM achieves state-of-the-art performance on multiple benchmarks across classification and regression tasks. Moreover, we demonstrate that representation derived from LLM achieves exceptional performance by leveraging two core functionalities: the generation of molecular embeddings through their encoding capabilities and the curation of molecular features through advanced reasoning processes.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MÂ²LLMï¼Œä¸€ä¸ªåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰è¿›è¡Œå¤šè§†å›¾åˆ†å­è¡¨ç¤ºå­¦ä¹ çš„æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿåˆ†å­è¡¨ç¤ºæ–¹æ³•åœ¨åˆ†å­å±æ€§é¢„æµ‹ä¸­å¿½è§†è¯­ä¹‰å’Œä¸Šä¸‹æ–‡çŸ¥è¯†çš„å±€é™ã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆåˆ†å­ç»“æ„è§†å›¾ï¼ˆmolecular structure viewï¼‰ã€åˆ†å­ä»»åŠ¡è§†å›¾ï¼ˆmolecular task viewï¼‰å’Œåˆ†å­è§„åˆ™è§†å›¾ï¼ˆmolecular rules viewï¼‰ä¸‰ä¸ªç»´åº¦çš„ç‰¹å¾ï¼Œå¹¶è¿›è¡ŒåŠ¨æ€èåˆä»¥é€‚åº”ç‰¹å®šçš„ä»»åŠ¡éœ€æ±‚ã€‚ç ”ç©¶è¡¨æ˜ï¼ŒMÂ²LLMèƒ½å¤Ÿæœ‰æ•ˆåˆ©ç”¨LLMsçš„ç¼–ç èƒ½åŠ›ç”Ÿæˆé«˜è´¨é‡çš„åˆ†å­åµŒå…¥ï¼ˆmolecular embeddingsï¼‰ï¼Œå¹¶é€šè¿‡å…¶é«˜çº§æ¨ç†è¿‡ç¨‹ååŒæå–å…³é”®åˆ†å­ç‰¹å¾ã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMÂ²LLMåœ¨å¤šä¸ªåˆ†ç±»å’Œå›å½’åŸºå‡†æµ‹è¯•ä¸­å‡å–å¾—äº†å½“å‰æœ€å…ˆè¿›ï¼ˆSOTAï¼‰çš„æ€§èƒ½ã€‚è¯¥ç ”ç©¶è¯æ˜äº†å°†LLMsè·¨å­¦ç§‘çš„å…ˆéªŒçŸ¥è¯†ä¸å¤šç»´åº¦æ¨ç†ç›¸ç»“åˆï¼Œèƒ½å¤Ÿæ˜¾è‘—å¢å¼ºåˆ†å­è¡¨ç¤ºçš„å‡†ç¡®æ€§ä¸é²æ£’æ€§ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "IJCAI 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08657v1",
      "published_date": "2025-08-12 05:46:47 UTC",
      "updated_date": "2025-08-12 05:46:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:24:29.364410+00:00"
    },
    {
      "arxiv_id": "2508.08653v1",
      "title": "LLM driven Text-to-Table Generation through Sub-Tasks Guidance and Iterative Refinement",
      "title_zh": "ç»“åˆå­ä»»åŠ¡å¼•å¯¼ä¸è¿­ä»£ä¼˜åŒ–çš„ LLM é©±åŠ¨æ–‡æœ¬åˆ°è¡¨æ ¼ç”Ÿæˆ",
      "authors": [
        "Rajmohan C",
        "Sarthak Harne",
        "Arvind Agarwal"
      ],
      "abstract": "Transforming unstructured text into structured data is a complex task, requiring semantic understanding, reasoning, and structural comprehension. While Large Language Models (LLMs) offer potential, they often struggle with handling ambiguous or domain-specific data, maintaining table structure, managing long inputs, and addressing numerical reasoning. This paper proposes an efficient system for LLM-driven text-to-table generation that leverages novel prompting techniques. Specifically, the system incorporates two key strategies: breaking down the text-to-table task into manageable, guided sub-tasks and refining the generated tables through iterative self-feedback. We show that this custom task decomposition allows the model to address the problem in a stepwise manner and improves the quality of the generated table. Furthermore, we discuss the benefits and potential risks associated with iterative self-feedback on the generated tables while highlighting the trade-offs between enhanced performance and computational cost. Our methods achieve strong results compared to baselines on two complex text-to-table generation datasets available in the public domain.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹Large Language Models (LLMs) åœ¨æ‰§è¡Œéç»“æ„åŒ–æ–‡æœ¬åˆ°ç»“æ„åŒ–è¡¨æ ¼è½¬æ¢ (Text-to-Table Generation) æ—¶é¢ä¸´çš„è¯­ä¹‰ç†è§£ã€ç»“æ„ç»´æŠ¤åŠæ•°å€¼æ¨ç†ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§ç”± LLM é©±åŠ¨çš„é«˜æ•ˆç”Ÿæˆç³»ç»Ÿã€‚è¯¥ç³»ç»Ÿå¼•å…¥äº†ä¸¤é¡¹å…³é”®ç­–ç•¥ï¼šé€šè¿‡å­ä»»åŠ¡å¼•å¯¼ (Sub-Tasks Guidance) å°†å¤æ‚çš„ç”Ÿæˆä»»åŠ¡åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯ç®¡ç†çš„å­ä»»åŠ¡ï¼Œå¹¶åˆ©ç”¨åŸºäºè‡ªæˆ‘åé¦ˆçš„è¿­ä»£ä¼˜åŒ– (Iterative Refinement) æœºåˆ¶æå‡è¡¨æ ¼è´¨é‡ã€‚ç ”ç©¶ç»“æœè¯æ˜ï¼Œè¿™ç§å®šåˆ¶çš„ä»»åŠ¡åˆ†è§£æ–¹æ³•èƒ½å¤Ÿå¼•å¯¼æ¨¡å‹ä»¥é€æ­¥æ–¹å¼è§£å†³é—®é¢˜ï¼Œæ˜¾è‘—æ”¹å–„äº†ç”Ÿæˆè¡¨æ ¼çš„å‡†ç¡®æ€§ã€‚åŒæ—¶ï¼Œæœ¬æ–‡è¿˜æ·±å…¥æ¢è®¨äº†è¿­ä»£è‡ªæˆ‘åé¦ˆåœ¨æ€§èƒ½æå‡ä¸è®¡ç®—æˆæœ¬ä¹‹é—´çš„æƒè¡¡å…³ç³»åŠå…¶æ½œåœ¨é£é™©ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¸¤ä¸ªå…¬å¼€çš„å¤æ‚æ•°æ®é›†ä¸Šå‡å–å¾—äº†ä¼˜äºåŸºçº¿æ¨¡å‹çš„æ•ˆæœï¼Œä¸ºé«˜æ•ˆçš„è‡ªåŠ¨åŒ–æ•°æ®ç»“æ„åŒ–æä¾›äº†æ–°æ€è·¯ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08653v1",
      "published_date": "2025-08-12 05:37:12 UTC",
      "updated_date": "2025-08-12 05:37:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:24:36.554122+00:00"
    },
    {
      "arxiv_id": "2508.08652v1",
      "title": "Prompt-and-Check: Using Large Language Models to Evaluate Communication Protocol Compliance in Simulation-Based Training",
      "title_zh": "Prompt-and-Checkï¼šåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹è¯„ä¼°æ¨¡æ‹Ÿè®­ç»ƒä¸­çš„æ²Ÿé€šè§„ç¨‹åˆè§„æ€§",
      "authors": [
        "Vishakha Lall",
        "Yisi Liu"
      ],
      "abstract": "Accurate evaluation of procedural communication compliance is essential in simulation-based training, particularly in safety-critical domains where adherence to compliance checklists reflects operational competence. This paper explores a lightweight, deployable approach using prompt-based inference with open-source large language models (LLMs) that can run efficiently on consumer-grade GPUs. We present Prompt-and-Check, a method that uses context-rich prompts to evaluate whether each checklist item in a protocol has been fulfilled, solely based on transcribed verbal exchanges. We perform a case study in the maritime domain with participants performing an identical simulation task, and experiment with models such as LLama 2 7B, LLaMA 3 8B and Mistral 7B, running locally on an RTX 4070 GPU. For each checklist item, a prompt incorporating relevant transcript excerpts is fed into the model, which outputs a compliance judgment. We assess model outputs against expert-annotated ground truth using classification accuracy and agreement scores. Our findings demonstrate that prompting enables effective context-aware reasoning without task-specific training. This study highlights the practical utility of LLMs in augmenting debriefing, performance feedback, and automated assessment in training environments.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†Prompt-and-Checkï¼Œä¸€ç§åˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models, LLMs)è¯„ä¼°æ¨¡æ‹ŸåŸ¹è®­ä¸­é€šä¿¡åè®®åˆè§„æ€§çš„è½»é‡çº§æ–¹æ³•ã€‚è¯¥æ–¹æ³•é€šè¿‡å¯Œå«ä¸Šä¸‹æ–‡çš„æç¤º(context-rich prompts)ï¼Œä»…æ ¹æ®è½¬å½•çš„å£å¤´äº¤æµå†…å®¹æ¥åˆ¤å®šåè®®ä¸­å„æ£€æŸ¥æ¸…å•é¡¹çš„å±¥è¡Œæƒ…å†µã€‚å®éªŒåœ¨èˆªæµ·é¢†åŸŸå¼€å±•æ¡ˆä¾‹ç ”ç©¶ï¼Œä½¿ç”¨Llama 2 7Bã€LLaMA 3 8Bå’ŒMistral 7Bç­‰å¼€æºæ¨¡å‹åœ¨æ¶ˆè´¹çº§GPUä¸Šé«˜æ•ˆè¿è¡Œã€‚é€šè¿‡å¯¹æ¯”æ¨¡å‹è¾“å‡ºä¸ä¸“å®¶æ ‡æ³¨çš„çœŸå®å€¼(ground truth)ï¼Œç ”ç©¶è¯„ä¼°äº†åˆ†ç±»å‡†ç¡®ç‡å’Œä¸€è‡´æ€§å¾—åˆ†ã€‚ç»“æœè¯æ˜ï¼Œæç¤ºæŠ€æœ¯æ— éœ€ç‰¹å®šä»»åŠ¡è®­ç»ƒå³å¯å®ç°æœ‰æ•ˆçš„ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ¨ç†ã€‚è¯¥ç ”ç©¶çªæ˜¾äº†LLMsåœ¨æå‡å¤ç›˜åé¦ˆã€ç»©æ•ˆè¯„ä»·åŠæ¨¡æ‹ŸåŸ¹è®­è‡ªåŠ¨åŒ–è¯„ä¼°æ–¹é¢çš„å®é™…åº”ç”¨æ½œåŠ›ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08652v1",
      "published_date": "2025-08-12 05:35:57 UTC",
      "updated_date": "2025-08-12 05:35:57 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:06.762307+00:00"
    },
    {
      "arxiv_id": "2508.14071v1",
      "title": "Edge-Selector Model Applied for Local Search Neighborhood for Solving Vehicle Routing Problems",
      "title_zh": "åº”ç”¨äºè½¦è¾†è·¯å¾„é—®é¢˜å±€éƒ¨æœç´¢é‚»åŸŸçš„è¾¹é€‰æ‹©å™¨æ¨¡å‹",
      "authors": [
        "Bachtiar Herdianto",
        "Romain Billot",
        "Flavien Lucas",
        "Marc Sevaux",
        "Daniele Vigo"
      ],
      "abstract": "This research proposes a hybrid Machine Learning and metaheuristic mechanism that is designed to solve Vehicle Routing Problems (VRPs). The main of our method is an edge solution selector model, which classifies solution edges to identify prohibited moves during the local search, hence guiding the search process within metaheuristic baselines. Two learning-based mechanisms are used to develop the edge selector: a simple tabular binary classifier and a Graph Neural Network (GNN). The tabular classifier employs Gradient Boosting Trees and Feedforward Neural Network as the baseline algorithms. Adjustments to the decision threshold are also applied to handle the class imbalance in the problem instance. An alternative mechanism employs the GNN to utilize graph structure for direct solution edge prediction, with the objective of guiding local search by predicting prohibited moves. These hybrid mechanisms are then applied in state-fo-the-art metaheuristic baselines. Our method demonstrates both scalability and generalizability, achieving performance improvements across different baseline metaheuristics, various problem sizes and variants, including the Capacitated Vehicle Routing Problem (CVRP) and CVRP with Time Windows (CVRPTW). Experimental evaluations on benchmark datasets up to 30,000 customer nodes, supported by pair-wise statistical analysis, verify the observed improvements.",
      "tldr_zh": "æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§ç»“åˆæœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼‰ä¸å…ƒå¯å‘å¼ç®—æ³•ï¼ˆmetaheuristicï¼‰çš„æ··åˆæœºåˆ¶ï¼Œæ—¨åœ¨è§£å†³è½¦è¾†è·¯å¾„é—®é¢˜ï¼ˆVehicle Routing Problems, VRPsï¼‰ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒæ˜¯ä¸€ä¸ªè¾¹é€‰æ‹©å™¨æ¨¡å‹ï¼ˆedge solution selector modelï¼‰ï¼Œé€šè¿‡å¯¹è§£çš„è¾¹è¿›è¡Œåˆ†ç±»æ¥è¯†åˆ«å±€éƒ¨æœç´¢ï¼ˆlocal searchï¼‰è¿‡ç¨‹ä¸­çš„ç¦æ­¢ç§»åŠ¨ï¼Œä»è€Œåœ¨å…ƒå¯å‘å¼åŸºçº¿ä¸­æœ‰æ•ˆå¼•å¯¼æœç´¢è¿‡ç¨‹ã€‚ç ”ç©¶é‡‡ç”¨äº†ä¸¤ç§å­¦ä¹ æœºåˆ¶ï¼ŒåŒ…æ‹¬åŸºäºæ¢¯åº¦æå‡æ ‘ï¼ˆGradient Boosting Treesï¼‰å’Œå‰é¦ˆç¥ç»ç½‘ç»œï¼ˆFeedforward Neural Networkï¼‰çš„è¡¨æ ¼äºŒåˆ†ç±»å™¨ï¼Œä»¥åŠåˆ©ç”¨å›¾ç¥ç»ç½‘ç»œï¼ˆGNNï¼‰æ•æ‰å›¾ç»“æ„ä¿¡æ¯ä»¥ç›´æ¥é¢„æµ‹è§£çš„è¾¹ã€‚ä¸ºäº†åº”å¯¹ç±»åˆ«ä¸å¹³è¡¡é—®é¢˜ï¼Œæ¨¡å‹è¿˜å¼•å…¥äº†å†³ç­–é˜ˆå€¼è°ƒæ•´æŠ€æœ¯ï¼Œç¡®ä¿äº†åœ¨å¤æ‚çº¦æŸä¸‹çš„é¢„æµ‹å‡†ç¡®æ€§ã€‚è¯¥æ–¹æ³•åœ¨å¸¦å®¹é‡é™åˆ¶çš„è½¦è¾†è·¯å¾„é—®é¢˜ï¼ˆCVRPï¼‰åŠå¸¦æ—¶é—´çª—çš„è½¦è¾†è·¯å¾„é—®é¢˜ï¼ˆCVRPTWï¼‰ç­‰å¤šç§å˜ä½“ä¸Šå±•ç°äº†å‡ºè‰²çš„å¯æ‰©å±•æ€§å’Œæ³›åŒ–æ€§ã€‚å®éªŒåœ¨åŒ…å«å¤šè¾¾30,000ä¸ªèŠ‚ç‚¹çš„åŸºå‡†æ•°æ®é›†ä¸Šè¿›è¡Œäº†éªŒè¯ï¼Œæˆå¯¹ç»Ÿè®¡åˆ†æè¯æ˜äº†è¯¥æ¨¡å‹åœ¨ä¸åŒå…ƒå¯å‘å¼åŸºçº¿ï¼ˆmetaheuristic baselinesï¼‰å’Œé—®é¢˜è§„æ¨¡ä¸‹å‡èƒ½æ˜¾è‘—æå‡æ±‚è§£æ€§èƒ½ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.14071v1",
      "published_date": "2025-08-12 05:28:26 UTC",
      "updated_date": "2025-08-12 05:28:26 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:28.383805+00:00"
    },
    {
      "arxiv_id": "2508.08646v1",
      "title": "P-CAFE: Personalized Cost-Aware Incremental Feature Selection For Electronic Health Records",
      "title_zh": "P-CAFEï¼šé¢å‘ç”µå­å¥åº·æ¡£æ¡ˆçš„ä¸ªæ€§åŒ–æˆæœ¬æ„ŸçŸ¥å¢é‡ç‰¹å¾é€‰æ‹©",
      "authors": [
        "Naama Kashani",
        "Mira Cohen",
        "Uri Shaham"
      ],
      "abstract": "Electronic Health Records (EHR) have revolutionized healthcare by digitizing patient data, improving accessibility, and streamlining clinical workflows. However, extracting meaningful insights from these complex and multimodal datasets remains a significant challenge for researchers. Traditional feature selection methods often struggle with the inherent sparsity and heterogeneity of EHR data, especially when accounting for patient-specific variations and feature costs in clinical applications. To address these challenges, we propose a novel personalized, online and cost-aware feature selection framework tailored specifically for EHR datasets. The features are aquired in an online fashion for individual patients, incorporating budgetary constraints and feature variability costs. The framework is designed to effectively manage sparse and multimodal data, ensuring robust and scalable performance in diverse healthcare contexts. A primary application of our proposed method is to support physicians' decision making in patient screening scenarios. By guiding physicians toward incremental acquisition of the most informative features within budget constraints, our approach aims to increase diagnostic confidence while optimizing resource utilization.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†P-CAFEï¼Œä¸€ç§ä¸“ä¸ºElectronic Health Records (EHR) æ•°æ®è®¾è®¡çš„ä¸ªæ€§åŒ–ã€åœ¨çº¿ä¸”å…·å¤‡æˆæœ¬æ„è¯†çš„Incremental Feature Selectionæ¡†æ¶ã€‚é’ˆå¯¹EHRæ•°æ®ä¸­å¸¸è§çš„Sparsityå’ŒHeterogeneityæŒ‘æˆ˜ï¼Œè¯¥æ–¹æ³•ä»¥åœ¨çº¿æ–¹å¼ä¸ºä¸ªä½“æ‚£è€…è·å–ç‰¹å¾ï¼Œå¹¶ç»¼åˆè€ƒè™‘äº†Budget Constraintså’Œç‰¹å¾è·å–æˆæœ¬ã€‚è¯¥æ¡†æ¶èƒ½å¤Ÿæœ‰æ•ˆå¤„ç†å¤šæ¨¡æ€æ•°æ®ï¼Œåœ¨å¤šæ ·åŒ–çš„åŒ»ç–—åœºæ™¯ä¸­å±•ç°å‡ºç¨³å¥ä¸”å¯æ‰©å±•çš„æ€§èƒ½ã€‚P-CAFEçš„ä¸»è¦åº”ç”¨åœºæ™¯æ˜¯æ”¯æŒåŒ»ç”Ÿåœ¨æ‚£è€…ç­›æŸ¥ä¸­çš„å†³ç­–åˆ¶å®šï¼Œé€šè¿‡å¼•å¯¼åŒ»ç”Ÿåœ¨é¢„ç®—èŒƒå›´å†…å¢é‡å¼åœ°è·å–æœ€å…·ä¿¡æ¯é‡çš„ç‰¹å¾ï¼Œè¯¥æ–¹æ³•æ—¨åœ¨æå‡è¯Šæ–­ä¿¡å¿ƒçš„åŒæ—¶ä¼˜åŒ–èµ„æºåˆ©ç”¨ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 5 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08646v1",
      "published_date": "2025-08-12 05:23:46 UTC",
      "updated_date": "2025-08-12 05:23:46 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:06.990725+00:00"
    },
    {
      "arxiv_id": "2508.08641v1",
      "title": "MiGrATe: Mixed-Policy GRPO for Adaptation at Test-Time",
      "title_zh": "MiGrATeï¼šé¢å‘æµ‹è¯•æ—¶è‡ªé€‚åº”çš„æ··åˆç­–ç•¥ GRPO",
      "authors": [
        "Peter Phan",
        "Dhruv Agarwal",
        "Kavitha Srinivas",
        "Horst Samulowitz",
        "Pavan Kapanipathi",
        "Andrew McCallum"
      ],
      "abstract": "Large language models (LLMs) are increasingly being applied to black-box optimization tasks, from program synthesis to molecule design. Prior work typically leverages in-context learning to iteratively guide the model towards better solutions. Such methods, however, often struggle to balance exploration of new solution spaces with exploitation of high-reward ones. Recently, test-time training (TTT) with synthetic data has shown promise in improving solution quality. However, the need for hand-crafted training data tailored to each task limits feasibility and scalability across domains. To address this problem, we introduce MiGrATe-a method for online TTT that uses GRPO as a search algorithm to adapt LLMs at inference without requiring external training data. MiGrATe operates via a mixed-policy group construction procedure that combines on-policy sampling with two off-policy data selection techniques: greedy sampling, which selects top-performing past completions, and neighborhood sampling (NS), which generates completions structurally similar to high-reward ones. Together, these components bias the policy gradient towards exploitation of promising regions in solution space, while preserving exploration through on-policy sampling. We evaluate MiGrATe on three challenging domains-word search, molecule optimization, and hypothesis+program induction on the Abstraction and Reasoning Corpus (ARC)-and find that it consistently outperforms both inference-only and TTT baselines, demonstrating the potential of online TTT as a solution for complex search tasks without external supervision.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†MiGrATeï¼Œä¸€ç§åŸºäºæ··åˆç­–ç•¥Group Relative Policy Optimization (GRPO)å®ç°æµ‹è¯•æ—¶é€‚åº”(Test-Time Adaptation)çš„æ–°æ–¹æ³•ï¼Œæ—¨åœ¨è§£å†³å¤§å‹è¯­è¨€æ¨¡å‹(LLMs)åœ¨å¤„ç†é»‘ç›’ä¼˜åŒ–ä»»åŠ¡æ—¶éš¾ä»¥å¹³è¡¡è§£ç©ºé—´æ¢ç´¢ä¸åˆ©ç”¨çš„é—®é¢˜ã€‚MiGrATeåœ¨æ¨ç†é˜¶æ®µå°†GRPOä½œä¸ºæœç´¢ç®—æ³•æ¥è°ƒæ•´æ¨¡å‹ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹äººå·¥æ ‡æ³¨æˆ–é¢†åŸŸç‰¹å®šè®­ç»ƒæ•°æ®çš„ä¾èµ–ã€‚è¯¥æ–¹æ³•çš„æ ¸å¿ƒåœ¨äºæ··åˆç­–ç•¥ç»„æ„å»ºç¨‹åºï¼Œé€šè¿‡ç»“åˆåŒç­–ç•¥é‡‡æ ·(on-policy sampling)ã€è´ªå©ªé‡‡æ ·ä»¥åŠç”¨äºç”Ÿæˆç»“æ„ç›¸ä¼¼é«˜å¥–åŠ±è§£çš„é‚»åŸŸé‡‡æ ·(neighborhood sampling)ï¼Œå°†ç­–ç•¥æ¢¯åº¦å¼•å‘æ›´æœ‰å‰æ™¯çš„è§£ç©ºé—´åŒºåŸŸã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼ŒMiGrATeåœ¨å•è¯æœç´¢ã€åˆ†å­ä¼˜åŒ–åŠARCåŸºå‡†æµ‹è¯•ç­‰å¤šä¸ªæŒ‘æˆ˜æ€§é¢†åŸŸä¸­ï¼Œè¡¨ç°å‡æ˜¾è‘—ä¼˜äºä»…æ¨ç†å’Œç°æœ‰çš„TTTåŸºçº¿ã€‚è¯¥ç ”ç©¶æœ‰åŠ›è¯æ˜äº†åœ¨çº¿TTTåœ¨æ— éœ€å¤–éƒ¨ç›‘ç£çš„æƒ…å†µä¸‹ï¼Œä½œä¸ºè§£å†³å¤æ‚æœç´¢ä»»åŠ¡æ–¹æ¡ˆçš„æœ‰æ•ˆæ€§ä¸è·¨é¢†åŸŸæ‰©å±•æ½œåŠ›ã€‚",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08641v1",
      "published_date": "2025-08-12 05:08:21 UTC",
      "updated_date": "2025-08-12 05:08:21 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:12.659966+00:00"
    },
    {
      "arxiv_id": "2508.08633v1",
      "title": "Diminution: On Reducing the Size of Grounding ASP Programs",
      "title_zh": "Diminutionï¼šè®ºç¼©å‡ ASP å®ä¾‹åŒ–ç¨‹åºè§„æ¨¡",
      "authors": [
        "HuanYu Yang",
        "Fengming Zhu",
        "YangFan Wu",
        "Jianmin Ji"
      ],
      "abstract": "Answer Set Programming (ASP) is often hindered by the grounding bottleneck: large Herbrand universes generate ground programs so large that solving becomes difficult. Many methods employ ad-hoc heuristics to improve grounding performance, motivating the need for a more formal and generalizable strategy. We introduce the notion of diminution, defined as a selected subset of the Herbrand universe used to generate a reduced ground program before solving. We give a formal definition of diminution, analyze its key properties, and study the complexity of identifying it. We use a specific encoding that enables off-the-shelf ASP solver to evaluate candidate subsets. Our approach integrates seamlessly with existing grounders via domain predicates. In extensive experiments on five benchmarks, applying diminutions selected by our strategy yields significant performance improvements, reducing grounding time by up to 70% on average and decreasing the size of grounding files by up to 85%. These results demonstrate that leveraging diminutions constitutes a robust and general-purpose approach for alleviating the grounding bottleneck in ASP.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å›ç­”é›†ç¨‹åºè®¾è®¡(Answer Set Programming, ASP)ä¸­å› Herbrand universesè¿‡å¤§è€Œå¯¼è‡´çš„æ¥åœ°ç“¶é¢ˆ(grounding bottleneck)é—®é¢˜ï¼Œæå‡ºäº†åä¸ºâ€œDiminutionâ€çš„å½¢å¼åŒ–æ¦‚å¿µã€‚Diminutionè¢«å®šä¹‰ä¸ºHerbrand universeçš„ä¸€ä¸ªç‰¹å®šå­é›†ï¼Œæ—¨åœ¨æ±‚è§£å‰ç”Ÿæˆè§„æ¨¡æ›´å°çš„æ¥åœ°ç¨‹åºï¼Œä»è€Œæé«˜å¤„ç†æ•ˆç‡ã€‚ä½œè€…é€šè¿‡æä¾›Diminutionçš„æ­£å¼å®šä¹‰å¹¶åˆ†æå…¶å¤æ‚æ€§ï¼Œåˆ©ç”¨ç‰¹å®šç¼–ç ä½¿ç°æœ‰çš„ASP solverèƒ½å¤Ÿç›´æ¥è¯„ä¼°å€™é€‰å­é›†ï¼Œä¸”è¯¥æ–¹æ³•å¯é€šè¿‡é¢†åŸŸè°“è¯(domain predicates)ä¸ç°æœ‰çš„grounderså®ç°æ— ç¼é›†æˆã€‚å®éªŒç»“æœæ˜¾ç¤ºï¼Œåœ¨äº”ä¸ªåŸºå‡†æµ‹è¯•ä¸­ï¼Œè¯¥ç­–ç•¥å¹³å‡å¯ç¼©å‡é«˜è¾¾70%çš„æ¥åœ°æ—¶é—´ï¼Œå¹¶å°†æ¥åœ°æ–‡ä»¶ä½“ç§¯å‡å°85%ã€‚è¿™äº›å‘ç°è¡¨æ˜ï¼ŒDiminutionä¸ºç¼“è§£ASPä¸­çš„æ¥åœ°ç“¶é¢ˆæä¾›äº†ä¸€ç§é²æ£’ä¸”é€šç”¨çš„è§£å†³æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08633v1",
      "published_date": "2025-08-12 04:52:19 UTC",
      "updated_date": "2025-08-12 04:52:19 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:11.154996+00:00"
    },
    {
      "arxiv_id": "2508.08632v1",
      "title": "AgriGPT: a Large Language Model Ecosystem for Agriculture",
      "title_zh": "AgriGPTï¼šé¢å‘å†œä¸šçš„å¤§è¯­è¨€æ¨¡å‹ç”Ÿæ€ç³»ç»Ÿ",
      "authors": [
        "Bo Yang",
        "Yu Zhang",
        "Lanfei Feng",
        "Yunkui Chen",
        "Jianyu Zhang",
        "Xiao Xu",
        "Nueraili Aierken",
        "Yurui Li",
        "Yuxuan Chen",
        "Guijun Yang",
        "Yong He",
        "Runhe Huang",
        "Shijian Li"
      ],
      "abstract": "Despite the rapid progress of Large Language Models (LLMs), their application in agriculture remains limited due to the lack of domain-specific models, curated datasets, and robust evaluation frameworks. To address these challenges, we propose AgriGPT, a domain-specialized LLM ecosystem for agricultural usage. At its core, we design a multi-agent scalable data engine that systematically compiles credible data sources into Agri-342K, a high-quality, standardized question-answer (QA) dataset. Trained on this dataset, AgriGPT supports a broad range of agricultural stakeholders, from practitioners to policy-makers. To enhance factual grounding, we employ Tri-RAG, a three-channel Retrieval-Augmented Generation framework combining dense retrieval, sparse retrieval, and multi-hop knowledge graph reasoning, thereby improving the LLM's reasoning reliability. For comprehensive evaluation, we introduce AgriBench-13K, a benchmark suite comprising 13 tasks with varying types and complexities. Experiments demonstrate that AgriGPT significantly outperforms general-purpose LLMs on both domain adaptation and reasoning. Beyond the model itself, AgriGPT represents a modular and extensible LLM ecosystem for agriculture, comprising structured data construction, retrieval-enhanced generation, and domain-specific evaluation. This work provides a generalizable framework for developing scientific and industry-specialized LLMs. All models, datasets, and code will be released to empower agricultural communities, especially in underserved regions, and to promote open, impactful research.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å†œä¸šé¢†åŸŸç¼ºä¹é¢†åŸŸç‰¹å®šæ¨¡å‹ã€é«˜è´¨é‡æ•°æ®é›†å’Œè¯„ä¼°æ¡†æ¶çš„é—®é¢˜ï¼Œæå‡ºäº†AgriGPTï¼Œè¿™æ˜¯ä¸€ä¸ªä¸“ä¸ºå†œä¸šåº”ç”¨è®¾è®¡çš„é¢†åŸŸä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹(LLMs)ç”Ÿæ€ç³»ç»Ÿã€‚å…¶æ ¸å¿ƒé‡‡ç”¨å¤šæ™ºèƒ½ä½“å¯æ‰©å±•æ•°æ®å¼•æ“ç³»ç»Ÿåœ°æ•´åˆå¯é æ•°æ®æºï¼Œæ„å»ºäº†åŒ…å«34.2ä¸‡æ¡é«˜è´¨é‡æ ‡å‡†åŒ–é—®ç­”å¯¹çš„æ•°æ®é›†Agri-342Kã€‚ä¸ºäº†æé«˜æ¨¡å‹çš„äº‹å®å‡†ç¡®æ€§ï¼Œç ”ç©¶å›¢é˜Ÿå¼€å‘äº†Tri-RAGæ¡†æ¶ï¼Œé€šè¿‡èåˆå¯†é›†æ£€ç´¢(dense retrieval)ã€ç¨€ç–æ£€ç´¢(sparse retrieval)å’Œå¤šè·³çŸ¥è¯†å›¾è°±æ¨ç†(multi-hop knowledge graph reasoning)æ¥å¢å¼ºæ¨ç†çš„å¯é æ€§ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†åŒ…å«13é¡¹å¤æ‚ä»»åŠ¡çš„åŸºå‡†æµ‹è¯•é›†AgriBench-13Kï¼Œå®éªŒè¯æ˜AgriGPTåœ¨é¢†åŸŸé€‚é…å’Œæ¨ç†æ€§èƒ½ä¸Šæ˜¾è‘—ä¼˜äºé€šç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚è¯¥å·¥ä½œä¸ä»…å±•ç¤ºäº†AgriGPTçš„å“è¶Šæ€§èƒ½ï¼Œè¿˜ä¸ºå†œä¸šé¢†åŸŸæ„å»ºäº†ä¸€ä¸ªæ¶µç›–æ•°æ®å»ºè®¾ã€æ£€ç´¢å¢å¼ºç”Ÿæˆå’Œç‰¹å®šé¢†åŸŸè¯„ä¼°çš„æ¨¡å—åŒ–å¯æ‰©å±•ç”Ÿæ€ç³»ç»Ÿã€‚é€šè¿‡å¼€æºç›¸å…³æ¨¡å‹å’Œæ•°æ®ï¼Œè¯¥ç ”ç©¶ä¸ºç§‘å­¦ä¸å·¥ä¸šä¸“ç”¨LLMsçš„å¼€å‘æä¾›äº†å¯æ¨å¹¿çš„é€šç”¨æ¡†æ¶ã€‚",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08632v1",
      "published_date": "2025-08-12 04:51:08 UTC",
      "updated_date": "2025-08-12 04:51:08 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:22.890410+00:00"
    },
    {
      "arxiv_id": "2508.08629v1",
      "title": "Securing Educational LLMs: A Generalised Taxonomy of Attacks on LLMs and DREAD Risk Assessment",
      "title_zh": "ä¿éšœæ•™è‚²å¤§è¯­è¨€æ¨¡å‹å®‰å…¨ï¼šå¤§è¯­è¨€æ¨¡å‹æ”»å‡»é€šç”¨åˆ†ç±»ä½“ç³»ä¸ DREAD é£é™©è¯„ä¼°",
      "authors": [
        "Farzana Zahid",
        "Anjalika Sewwandi",
        "Lee Brandon",
        "Vimal Kumar",
        "Roopak Sinha"
      ],
      "abstract": "Due to perceptions of efficiency and significant productivity gains, various organisations, including in education, are adopting Large Language Models (LLMs) into their workflows. Educator-facing, learner-facing, and institution-facing LLMs, collectively, Educational Large Language Models (eLLMs), complement and enhance the effectiveness of teaching, learning, and academic operations. However, their integration into an educational setting raises significant cybersecurity concerns. A comprehensive landscape of contemporary attacks on LLMs and their impact on the educational environment is missing. This study presents a generalised taxonomy of fifty attacks on LLMs, which are categorized as attacks targeting either models or their infrastructure. The severity of these attacks is evaluated in the educational sector using the DREAD risk assessment framework. Our risk assessment indicates that token smuggling, adversarial prompts, direct injection, and multi-step jailbreak are critical attacks on eLLMs. The proposed taxonomy, its application in the educational environment, and our risk assessment will help academic and industrial practitioners to build resilient solutions that protect learners and institutions.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¤§å‹è¯­è¨€æ¨¡å‹åœ¨æ•™è‚²é¢†åŸŸï¼ˆeLLMsï¼‰åº”ç”¨ä¸­é¢ä¸´çš„ç½‘ç»œå®‰å…¨æŒ‘æˆ˜ï¼Œæ—¨åœ¨å¡«è¡¥æ•™è‚²ç¯å¢ƒç¼ºä¹å…¨é¢æ”»å‡»åˆ†æçš„ç©ºç™½ã€‚ä½œè€…æå‡ºäº†ä¸€ç§åŒ…å«50ç§é’ˆå¯¹LLMsæ”»å‡»çš„é€šç”¨åˆ†ç±»æ³•ï¼ˆTaxonomyï¼‰ï¼Œå°†å…¶å½’çº³ä¸ºé’ˆå¯¹æ¨¡å‹æœ¬èº«å’Œé’ˆå¯¹åŸºç¡€è®¾æ–½çš„æ”»å‡»ä¸¤ç±»ã€‚é€šè¿‡åº”ç”¨DREADé£é™©è¯„ä¼°æ¡†æ¶ï¼ˆDREAD risk assessment frameworkï¼‰ï¼Œç ”ç©¶ç³»ç»Ÿè¯„ä¼°äº†è¿™äº›æ”»å‡»åœ¨æ•™è‚²éƒ¨é—¨çš„ä¸¥é‡ç¨‹åº¦ã€‚é£é™©è¯„ä¼°ç»“æœæŒ‡å‡ºï¼Œä»¤ç‰Œèµ°ç§ï¼ˆtoken smugglingï¼‰ã€å¯¹æŠ—æ€§æç¤ºï¼ˆadversarial promptsï¼‰ã€ç›´æ¥æ³¨å…¥ï¼ˆdirect injectionï¼‰å’Œå¤šæ­¥ç ´è§£ï¼ˆmulti-step jailbreakï¼‰æ˜¯eLLMsé¢ä¸´çš„å…³é”®å¨èƒã€‚è¯¥åˆ†ç±»æ³•åŠå…¶é£é™©è¯„ä¼°ç»“è®ºä¸ºå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œæ„å»ºæ›´å…·å¼¹æ€§çš„æ•™è‚²å®‰å…¨è§£å†³æ–¹æ¡ˆæä¾›äº†é‡è¦æŒ‡å¯¼ï¼Œæœ‰åŠ©äºä¿æŠ¤å­¦ä¹ è€…å’Œæ•™è‚²æœºæ„çš„æ•°å­—èµ„äº§ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08629v1",
      "published_date": "2025-08-12 04:34:12 UTC",
      "updated_date": "2025-08-12 04:34:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:30.887938+00:00"
    },
    {
      "arxiv_id": "2508.08627v1",
      "title": "QoE-Aware Service Provision for Mobile AR Rendering: An Agent-Driven Approach",
      "title_zh": "é¢å‘ç§»åŠ¨ AR æ¸²æŸ“çš„ QoE æ„ŸçŸ¥æœåŠ¡æä¾›ï¼šä¸€ç§æ™ºèƒ½ä½“é©±åŠ¨çš„æ–¹æ³•",
      "authors": [
        "Conghao Zhou",
        "Lulu Sun",
        "Xiucheng Wang",
        "Peng Yang",
        "Feng Lyu",
        "Sihan Lu",
        "Xuemin Shen"
      ],
      "abstract": "Mobile augmented reality (MAR) is envisioned as a key immersive application in 6G, enabling virtual content rendering aligned with the physical environment through device pose estimation. In this paper, we propose a novel agent-driven communication service provisioning approach for edge-assisted MAR, aiming to reduce communication overhead between MAR devices and the edge server while ensuring the quality of experience (QoE). First, to address the inaccessibility of MAR application-specific information to the network controller, we establish a digital agent powered by large language models (LLMs) on behalf of the MAR service provider, bridging the data and function gap between the MAR service and network domains. Second, to cope with the user-dependent and dynamic nature of data traffic patterns for individual devices, we develop a user-level QoE modeling method that captures the relationship between communication resource demands and perceived user QoE, enabling personalized, agent-driven communication resource management. Trace-driven simulation results demonstrate that the proposed approach outperforms conventional LLM-based QoE-aware service provisioning methods in both user-level QoE modeling accuracy and communication resource efficiency.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ 6G ç¯å¢ƒä¸‹ç§»åŠ¨å¢å¼ºç°å® (MAR) æ¸²æŸ“ä¸­çš„é€šä¿¡å¼€é”€ä¸ç”¨æˆ·ä½“éªŒè´¨é‡ (QoE) ä¿éšœé—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§æ–°å‹çš„æ™ºèƒ½ä½“é©±åŠ¨ (Agent-Driven) é€šä¿¡æœåŠ¡æä¾›æ–¹æ³•ã€‚ä¸ºäº†è§£å†³ç½‘ç»œæ§åˆ¶å™¨æ— æ³•è·å– MAR ç‰¹å®šåº”ç”¨ä¿¡æ¯çš„é—®é¢˜ï¼Œç ”ç©¶æ„å»ºäº†ä¸€ä¸ªç”±å¤§è¯­è¨€æ¨¡å‹ (LLMs) é©±åŠ¨çš„æ•°å­—æ™ºèƒ½ä½“ï¼Œæœ‰æ•ˆå¼¥è¡¥äº† MAR æœåŠ¡ä¸ç½‘ç»œé¢†åŸŸä¹‹é—´çš„æ•°æ®å’ŒåŠŸèƒ½é¸¿æ²Ÿã€‚é’ˆå¯¹ä¸ªä½“è®¾å¤‡æ•°æ®æµé‡æ¨¡å¼çš„åŠ¨æ€æ€§ï¼Œç ”ç©¶è¿›ä¸€æ­¥å¼€å‘äº†ä¸€ç§ç”¨æˆ·çº§çš„ QoE å»ºæ¨¡æ–¹æ³•ï¼Œç²¾å‡†æ•æ‰é€šä¿¡èµ„æºéœ€æ±‚ä¸ç”¨æˆ·æ„ŸçŸ¥ä½“éªŒä¹‹é—´çš„å…³è”ï¼Œä»è€Œå®ç°ä¸ªæ€§åŒ–çš„èµ„æºç®¡ç†ã€‚åŸºäºçœŸå®è½¨è¿¹çš„ä»¿çœŸç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ QoE å»ºæ¨¡å‡†ç¡®ç‡å’Œé€šä¿¡èµ„æºæ•ˆç‡ä¸Šå‡æ˜¾è‘—ä¼˜äºä¼ ç»ŸåŸºäº LLM çš„æœåŠ¡æä¾›æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08627v1",
      "published_date": "2025-08-12 04:32:04 UTC",
      "updated_date": "2025-08-12 04:32:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:27.402014+00:00"
    },
    {
      "arxiv_id": "2508.15790v1",
      "title": "KG-o1: Enhancing Multi-hop Question Answering in Large Language Models via Knowledge Graph Integration",
      "title_zh": "KG-o1ï¼šé€šè¿‡çŸ¥è¯†å›¾è°±é›†æˆå¢å¼ºå¤§è¯­è¨€æ¨¡å‹çš„å¤šè·³é—®ç­”èƒ½åŠ›",
      "authors": [
        "Nan Wang",
        "Yongqi Fan",
        "yansha zhu",
        "ZongYu Wang",
        "Xuezhi Cao",
        "Xinyan He",
        "Haiyun Jiang",
        "Tong Ruan",
        "Jingping Liu"
      ],
      "abstract": "Large Language Models (LLMs) face challenges in knowledge-intensive reasoning tasks like classic multi-hop question and answering, which involves reasoning across multiple facts. This difficulty arises because the chain of thoughts (CoTs) generated by LLMs in such tasks often deviate from real or a priori reasoning paths. In contrast, knowledge graphs (KGs) explicitly represent the logical connections between facts through entities and relationships. This reflects a significant gap. Meanwhile, large reasoning models (LRMs), such as o1, have demonstrated that long-step reasoning significantly enhances the performance of LLMs. Building on these insights, we propose KG-o1, a four-stage approach that integrates KGs to enhance the multi-hop reasoning abilities of LLMs. We first filter out initial entities and generate complex subgraphs. Secondly, we construct logical paths for subgraphs and then use knowledge graphs to build a dataset with a complex and extended brainstorming process, which trains LLMs to imitate long-term reasoning. Finally, we employ rejection sampling to generate a self-improving corpus for direct preference optimization (DPO), further refining the LLMs reasoning abilities. We conducted experiments on two simple and two complex datasets. The results show that KG-o1 models exhibit superior performance across all tasks compared to existing LRMs.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† KG-o1ï¼Œè¿™æ˜¯ä¸€ç§é€šè¿‡é›†æˆçŸ¥è¯†å›¾è°±(Knowledge Graph)æ¥å¢å¼ºå¤§è¯­è¨€æ¨¡å‹(LLMs)å¤šæ­¥æ¨ç†(Multi-hop Question Answering)èƒ½åŠ›çš„å››é˜¶æ®µæ–¹æ³•ã€‚é’ˆå¯¹ LLMs åœ¨çŸ¥è¯†å¯†é›†å‹ä»»åŠ¡ä¸­æ€ç»´é“¾(CoT)å®¹æ˜“åç¦»çœŸå®æ¨ç†è·¯å¾„çš„é—®é¢˜ï¼ŒKG-o1 åˆ©ç”¨ KGs çš„é€»è¾‘è¿æ¥ç‰¹æ€§å¼•å¯¼æ¨¡å‹ç”Ÿæˆæ›´å¯é çš„æ¨ç†è¿‡ç¨‹ã€‚è¯¥æ¡†æ¶é¦–å…ˆé€šè¿‡ç­›é€‰å®ä½“ç”Ÿæˆå¤æ‚å­å›¾ï¼Œå¹¶ä»¥æ­¤æ„å»ºåŒ…å«æ‰©å±•å¤´è„‘é£æš´è¿‡ç¨‹çš„æ•°æ®é›†ï¼Œè®­ç»ƒ LLMs æ¨¡ä»¿é•¿ç¨‹æ¨ç†(Long-term Reasoning)ã€‚éšåï¼Œç ”ç©¶é‡‡ç”¨æ‹’ç»é‡‡æ ·(Rejection Sampling)æ„å»ºè‡ªæå‡è¯­æ–™åº“ï¼Œå¹¶åˆ©ç”¨ç›´æ¥åå¥½ä¼˜åŒ–(DPO)è¿›ä¸€æ­¥å¾®è°ƒæ¨¡å‹çš„æ¨ç†èƒ½åŠ›ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒKG-o1 åœ¨å¤šç§ç®€å•åŠå¤æ‚æ•°æ®é›†ä¸Šçš„è¡¨ç°å‡ä¼˜äºç°æœ‰çš„é•¿ç¨‹æ¨ç†æ¨¡å‹(LRMs)ï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹åœ¨å¤„ç†å¤æ‚è·¨äº‹å®æ¨ç†æ—¶çš„å‡†ç¡®æ€§ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.15790v1",
      "published_date": "2025-08-12 04:29:10 UTC",
      "updated_date": "2025-08-12 04:29:10 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:42.895881+00:00"
    },
    {
      "arxiv_id": "2508.08615v2",
      "title": "UGM2N: An Unsupervised and Generalizable Mesh Movement Network via M-Uniform Loss",
      "title_zh": "UGM2Nï¼šåŸºäº M-Uniform æŸå¤±çš„æ— ç›‘ç£å¯æ³›åŒ–ç½‘æ ¼ç§»åŠ¨ç½‘ç»œ",
      "authors": [
        "Zhichao Wang",
        "Xinhai Chen",
        "Qinglin Wang",
        "Xiang Gao",
        "Qingyang Zhang",
        "Menghan Jia",
        "Xiang Zhang",
        "Jie Liu"
      ],
      "abstract": "Partial differential equations (PDEs) form the mathematical foundation for modeling physical systems in science and engineering, where numerical solutions demand rigorous accuracy-efficiency tradeoffs. Mesh movement techniques address this challenge by dynamically relocating mesh nodes to rapidly-varying regions, enhancing both simulation accuracy and computational efficiency. However, traditional approaches suffer from high computational complexity and geometric inflexibility, limiting their applicability, and existing supervised learning-based approaches face challenges in zero-shot generalization across diverse PDEs and mesh topologies.In this paper, we present an Unsupervised and Generalizable Mesh Movement Network (UGM2N). We first introduce unsupervised mesh adaptation through localized geometric feature learning, eliminating the dependency on pre-adapted meshes. We then develop a physics-constrained loss function, M-Uniform loss, that enforces mesh equidistribution at the nodal level.Experimental results demonstrate that the proposed network exhibits equation-agnostic generalization and geometric independence in efficient mesh adaptation. It demonstrates consistent superiority over existing methods, including robust performance across diverse PDEs and mesh geometries, scalability to multi-scale resolutions and guaranteed error reduction without mesh tangling.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹åå¾®åˆ†æ–¹ç¨‹(PDEs)æ•°å€¼æ±‚è§£ä¸­çš„ç²¾åº¦ä¸æ•ˆç‡å¹³è¡¡é—®é¢˜ï¼Œæå‡ºäº†UGM2Nï¼Œä¸€ç§æ— ç›‘ç£ä¸”å…·å¤‡æ³›åŒ–èƒ½åŠ›çš„ç½‘æ ¼ç§»åŠ¨ç½‘ç»œã€‚è¯¥æ¡†æ¶é€šè¿‡å±€éƒ¨å‡ ä½•ç‰¹å¾å­¦ä¹ å®ç°æ— ç›‘ç£çš„ç½‘æ ¼è‡ªé€‚åº”ï¼Œæœ‰æ•ˆè§£å†³äº†ä¼ ç»Ÿæ–¹æ³•è®¡ç®—å¤æ‚åº¦é«˜ä»¥åŠç°æœ‰ç›‘ç£å­¦ä¹ æ¨¡å‹åœ¨é›¶æ ·æœ¬æ³›åŒ–(zero-shot generalization)æ–¹é¢çš„å±€é™ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºå¼•å…¥äº†ç‰©ç†çº¦æŸçš„æŸå¤±å‡½æ•°M-Uniform lossï¼Œåœ¨èŠ‚ç‚¹å±‚é¢å¼ºåˆ¶æ‰§è¡Œç½‘æ ¼ç­‰åˆ†å¸ƒ(mesh equidistribution)ï¼Œä»è€Œæ¶ˆé™¤äº†å¯¹é¢„è‡ªé€‚åº”ç½‘æ ¼çš„ä¾èµ–ã€‚å®éªŒç»“æœè¯æ˜ï¼ŒUGM2Nå…·æœ‰æ˜¾è‘—çš„æ–¹ç¨‹ä¸å¯çŸ¥æ³›åŒ–æ€§(equation-agnostic generalization)å’Œå‡ ä½•ç‹¬ç«‹æ€§ï¼Œåœ¨å¤šç§PDEså’Œå¤æ‚å‡ ä½•å½¢çŠ¶ä¸‹è¡¨ç°ç¨³å¥ã€‚æ­¤å¤–ï¼Œè¯¥æ¨¡å‹åœ¨å¤šå°ºåº¦åˆ†è¾¨ç‡ä¸‹å±•ç°å‡ºè‰¯å¥½çš„æ‰©å±•æ€§ï¼Œå¹¶èƒ½åœ¨é¿å…ç½‘æ ¼ç¼ ç»“(mesh tangling)çš„åŒæ—¶ç¡®ä¿è¯¯å·®æ˜¾è‘—é™ä½ã€‚",
      "categories": [
        "cs.AI",
        "math.NA"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a Poster at NeurIPS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08615v2",
      "published_date": "2025-08-12 03:56:45 UTC",
      "updated_date": "2025-10-29 08:36:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:25:43.785034+00:00"
    },
    {
      "arxiv_id": "2508.14070v2",
      "title": "Special-Character Adversarial Attacks on Open-Source Language Model",
      "title_zh": "é’ˆå¯¹å¼€æºè¯­è¨€æ¨¡å‹çš„ç‰¹æ®Šå­—ç¬¦å¯¹æŠ—æ”»å‡»",
      "authors": [
        "Ephraiem Sarabamoun"
      ],
      "abstract": "Large language models (LLMs) have achieved remarkable performance across diverse natural language processing tasks, yet their vulnerability to character-level adversarial manipulations presents significant security challenges for real-world deployments. This paper presents a study of different special character attacks including unicode, homoglyph, structural, and textual encoding attacks aimed at bypassing safety mechanisms. We evaluate seven prominent open-source models ranging from 3.8B to 32B parameters on 4,000+ attack attempts. These experiments reveal critical vulnerabilities across all model sizes, exposing failure modes that include successful jailbreaks, incoherent outputs, and unrelated hallucinations.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†å¼€æºå¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å­—ç¬¦çº§å¯¹æŠ—æ€§æ“ä½œ(character-level adversarial manipulations)é¢å‰çš„è„†å¼±æ€§ï¼ŒæŒ‡å‡ºè¿™å¯¹å®é™…éƒ¨ç½²æ„æˆäº†ä¸¥å³»çš„å®‰å…¨æŒ‘æˆ˜ã€‚ä½œè€…ç³»ç»Ÿç ”ç©¶äº†åŒ…æ‹¬unicodeã€åŒå½¢æ–‡å­—(homoglyph)ã€ç»“æ„åŒ–å’Œæ–‡æœ¬ç¼–ç æ”»å‡»(textual encoding attacks)åœ¨å†…çš„å¤šç§ç‰¹æ®Šå­—ç¬¦æ”»å‡»æ‰‹æ®µï¼Œæ—¨åœ¨ç»•è¿‡æ¨¡å‹çš„å®‰å…¨æœºåˆ¶ã€‚é€šè¿‡å¯¹3.8Båˆ°32Bå‚æ•°è§„æ¨¡çš„ä¸ƒä¸ªä¸»æµå¼€æºæ¨¡å‹è¿›è¡Œè¶…è¿‡4,000æ¬¡æ”»å‡»æµ‹è¯•ï¼Œå®éªŒæ­ç¤ºäº†æ‰€æœ‰è§„æ¨¡çš„æ¨¡å‹å‡å­˜åœ¨å…³é”®æ¼æ´ã€‚ç ”ç©¶å‘ç°è¿™äº›æ”»å‡»ä¼šå¯¼è‡´æ¨¡å‹äº§ç”Ÿè¶Šç‹±(jailbreaks)ã€ä¸è¿è´¯è¾“å‡ºä»¥åŠæ— å…³å¹»è§‰(hallucinations)ç­‰å¤±æ•ˆæ¨¡å¼ã€‚è¿™äº›å‘ç°è¯å®äº†ç‰¹æ®Šå­—ç¬¦æ”»å‡»åœ¨ç»•è¿‡å®‰å…¨é˜²å¾¡æ–¹é¢çš„æœ‰æ•ˆæ€§ï¼Œä¸ºæœªæ¥æ„å»ºæ›´å…·é²æ£’æ€§çš„è¯­è¨€æ¨¡å‹æä¾›äº†é‡è¦å‚è€ƒã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14070v2",
      "published_date": "2025-08-12 03:42:59 UTC",
      "updated_date": "2025-11-25 23:27:47 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:01.695111+00:00"
    },
    {
      "arxiv_id": "2508.08604v3",
      "title": "Transferable Model-agnostic Vision-Language Model Adaptation for Efficient Weak-to-Strong Generalization",
      "title_zh": "é¢å‘é«˜æ•ˆâ€œå¼±åˆ°å¼ºâ€æ³›åŒ–çš„å¯è¿ç§»æ¨¡å‹æ— å…³è§†è§‰è¯­è¨€æ¨¡å‹é€‚é…",
      "authors": [
        "Jihwan Park",
        "Taehoon Song",
        "Sanghyeok Lee",
        "Miso Choi",
        "Hyunwoo J. Kim"
      ],
      "abstract": "Vision-Language Models (VLMs) have been widely used in various visual recognition tasks due to their remarkable generalization capabilities. As these models grow in size and complexity, fine-tuning becomes costly, emphasizing the need to reuse adaptation knowledge from 'weaker' models to efficiently enhance 'stronger' ones. However, existing adaptation transfer methods exhibit limited transferability across models due to their model-specific design and high computational demands. To tackle this, we propose Transferable Model-agnostic adapter (TransMiter), a light-weight adapter that improves vision-language models 'without backpropagation'. TransMiter captures the knowledge gap between pre-trained and fine-tuned VLMs, in an 'unsupervised' manner. Once trained, this knowledge can be seamlessly transferred across different models without the need for backpropagation. Moreover, TransMiter consists of only a few layers, inducing a negligible additional inference cost. Notably, supplementing the process with a few labeled data further yields additional performance gain, often surpassing a fine-tuned stronger model, with a marginal training cost. Experimental results and analyses demonstrate that TransMiter effectively and efficiently transfers adaptation knowledge while preserving generalization abilities across VLMs of different sizes and architectures in visual recognition tasks.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹è§†è§‰è¯­è¨€æ¨¡å‹(Vision-Language Models, VLMs)è§„æ¨¡å¢å¤§å¯¼è‡´å¾®è°ƒæˆæœ¬é«˜æ˜‚çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºTransMiterï¼ˆTransferable Model-agnostic adapterï¼‰çš„è½»é‡çº§é€‚é…å™¨ï¼Œæ—¨åœ¨å®ç°é«˜æ•ˆçš„å¼±åˆ°å¼ºæ³›åŒ–(Weak-to-Strong Generalization)ã€‚TransMiteré‡‡ç”¨æ— ç›‘ç£(unsupervised)æ–¹å¼æ•æ‰é¢„è®­ç»ƒæ¨¡å‹ä¸å¾®è°ƒæ¨¡å‹ä¹‹é—´çš„çŸ¥è¯†å·®è·ï¼Œä¸”åœ¨æå‡æ€§èƒ½æ—¶æ— éœ€è¿›è¡Œåå‘ä¼ æ’­(backpropagation)ã€‚ç”±äºè¯¥é€‚é…å™¨ä»…ç”±æå°‘æ•°å±‚ç»„æˆï¼Œå…¶å¸¦æ¥çš„é¢å¤–æ¨ç†æˆæœ¬å‡ ä¹å¯ä»¥å¿½ç•¥ä¸è®¡ï¼Œä¸”è®­ç»ƒåçš„é€‚é…çŸ¥è¯†å¯ä»¥æ— ç¼è¿ç§»è‡³ä¸åŒæ¶æ„å’Œè§„æ¨¡çš„æ¨¡å‹ä¸­ã€‚æ­¤å¤–ï¼Œä»…éœ€è¾…ä»¥æå°‘é‡çš„æ ‡æ³¨æ•°æ®ï¼ŒTransMiterä¾¿èƒ½ä»¥æä½çš„è®¡ç®—ä»£ä»·è·å¾—æ˜¾è‘—æ€§èƒ½æå‡ï¼Œç”šè‡³è¶…è¶Šç»è¿‡å®Œå…¨å¾®è°ƒçš„å¼ºæ¨¡å‹ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨ä¿æŒæ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„åŒæ—¶ï¼Œåœ¨å¤šç§è§†è§‰è¯†åˆ«ä»»åŠ¡ä¸­è¯æ˜äº†å…¶åœ¨è·¨æ¨¡å‹é€‚é…çŸ¥è¯†è¿ç§»æ–¹é¢çš„æœ‰æ•ˆæ€§ä¸é«˜æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "AAAI2026 Oral (camera ready version)",
      "pdf_url": "https://arxiv.org/pdf/2508.08604v3",
      "published_date": "2025-08-12 03:37:16 UTC",
      "updated_date": "2026-01-17 15:36:14 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:10.587492+00:00"
    },
    {
      "arxiv_id": "2508.08601v3",
      "title": "Yan: Foundational Interactive Video Generation",
      "title_zh": "Yanï¼šåŸºç¡€äº¤äº’å¼è§†é¢‘ç”Ÿæˆ",
      "authors": [
        "Deheng Ye",
        "Fangyun Zhou",
        "Jiacheng Lv",
        "Jianqi Ma",
        "Jun Zhang",
        "Junyan Lv",
        "Junyou Li",
        "Minwen Deng",
        "Mingyu Yang",
        "Qiang Fu",
        "Wei Yang",
        "Wenkai Lv",
        "Yangbin Yu",
        "Yewen Wang",
        "Yonghang Guan",
        "Zhihao Hu",
        "Zhongbin Fang",
        "Zhongqian Sun"
      ],
      "abstract": "We present Yan, a foundational framework for interactive video generation, covering the entire pipeline from simulation and generation to editing. Specifically, Yan comprises three core modules. AAA-level Simulation: We design a highly-compressed, low-latency 3D-VAE coupled with a KV-cache-based shift-window denoising inference process, achieving real-time 1080P/60FPS interactive simulation. Multi-Modal Generation: We introduce a hierarchical autoregressive caption method that injects game-specific knowledge into open-domain multi-modal video diffusion models (VDMs), then transforming the VDM into a frame-wise, action-controllable, real-time infinite interactive video generator. Notably, when the textual and visual prompts are sourced from different domains, the model demonstrates strong generalization, allowing it to blend and compose the style and mechanics across domains flexibly according to user prompts. Multi-Granularity Editing: We propose a hybrid model that explicitly disentangles interactive mechanics simulation from visual rendering, enabling multi-granularity video content editing during interaction through text. Collectively, Yan offers an integration of these modules, pushing interactive video generation beyond isolated capabilities toward a comprehensive AI-driven interactive creation paradigm, paving the way for the next generation of creative tools, media, and entertainment. The project page is: https://greatx3.github.io/Yan/.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† Yanï¼Œä¸€ä¸ªç”¨äºäº¤äº’å¼è§†é¢‘ç”Ÿæˆçš„ç”Ÿæˆå¼åŸºç¡€æ¡†æ¶ï¼Œæ¶µç›–äº†ä»æ¨¡æ‹Ÿã€ç”Ÿæˆåˆ°ç¼–è¾‘çš„å®Œæ•´æµç¨‹ã€‚åœ¨ AAA-level Simulation æ¨¡å—ä¸­ï¼Œç ”ç©¶å›¢é˜Ÿè®¾è®¡äº†é«˜å‹ç¼©æ¯”ã€ä½å»¶è¿Ÿçš„ 3D-VAEï¼Œå¹¶ç»“åˆåŸºäº KV-cache çš„ç§»ä½çª—å£å»å™ªæ¨ç†è¿‡ç¨‹ï¼Œå®ç°äº† 1080P/60FPS çš„å®æ—¶äº¤äº’å¼æ¨¡æ‹Ÿã€‚Multi-Modal Generation æ¨¡å—é€šè¿‡å±‚æ¬¡åŒ–è‡ªå›å½’æ ‡é¢˜æ–¹æ³•å°†æ¸¸æˆé¢†åŸŸçŸ¥è¯†æ³¨å…¥å¤šæ¨¡æ€è§†é¢‘æ‰©æ•£æ¨¡å‹ (VDMs)ï¼Œä½¿å…¶è½¬åŒ–ä¸ºé€å¸§ã€åŠ¨ä½œå¯æ§çš„å®æ—¶æ— é™äº¤äº’å¼è§†é¢‘ç”Ÿæˆå™¨ã€‚è¯¥æ¨¡å‹åœ¨å¤„ç†è·¨é¢†åŸŸæ–‡æœ¬å’Œè§†è§‰æç¤ºæ—¶è¡¨ç°å‡ºå¼ºå¤§çš„æ³›åŒ–æ€§ï¼Œèƒ½å¤Ÿæ ¹æ®ç”¨æˆ·æŒ‡ä»¤çµæ´»èåˆä¸åŒé¢†åŸŸçš„é£æ ¼ä¸äº¤äº’æœºåˆ¶ã€‚Multi-Granularity Editing æ¨¡å—é€šè¿‡è§£è€¦äº¤äº’æœºåˆ¶æ¨¡æ‹Ÿä¸è§†è§‰æ¸²æŸ“ï¼Œæ”¯æŒåœ¨äº¤äº’è¿‡ç¨‹ä¸­é€šè¿‡æ–‡æœ¬è¿›è¡Œå¤šç²’åº¦çš„è§†é¢‘å†…å®¹ç¼–è¾‘ã€‚Yan çš„æ•´åˆæ ‡å¿—ç€ä»å­¤ç«‹åŠŸèƒ½å‘å…¨é¢ AI é©±åŠ¨äº¤äº’å¼åˆ›ä½œèŒƒå¼çš„è½¬å˜ï¼Œä¸ºä¸‹ä¸€ä»£åˆ›æ„å·¥å…·å’Œå¨±ä¹åª’ä½“å¼€è¾Ÿäº†æ–°è·¯å¾„ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08601v3",
      "published_date": "2025-08-12 03:34:21 UTC",
      "updated_date": "2025-08-14 10:26:51 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:13.705399+00:00"
    },
    {
      "arxiv_id": "2508.08593v1",
      "title": "Generative AI for Critical Infrastructure in Smart Grids: A Unified Framework for Synthetic Data Generation and Anomaly Detection",
      "title_zh": "é¢å‘æ™ºèƒ½ç”µç½‘å…³é”®åŸºç¡€è®¾æ–½çš„ç”Ÿæˆå¼äººå·¥æ™ºèƒ½ï¼šåˆæˆæ•°æ®ç”Ÿæˆä¸å¼‚å¸¸æ£€æµ‹çš„ç»Ÿä¸€æ¡†æ¶",
      "authors": [
        "Aydin Zaboli",
        "Junho Hong"
      ],
      "abstract": "In digital substations, security events pose significant challenges to the sustained operation of power systems. To mitigate these challenges, the implementation of robust defense strategies is critically important. A thorough process of anomaly identification and detection in information and communication technology (ICT) frameworks is crucial to ensure secure and reliable communication and coordination between interconnected devices within digital substations. Hence, this paper addresses the critical cybersecurity challenges confronting IEC61850-based digital substations within modern smart grids, where the integration of advanced communication protocols, e.g., generic object-oriented substation event (GOOSE), has enhanced energy management and introduced significant vulnerabilities to cyberattacks. Focusing on the limitations of traditional anomaly detection systems (ADSs) in detecting threats, this research proposes a transformative approach by leveraging generative AI (GenAI) to develop robust ADSs. The primary contributions include the suggested advanced adversarial traffic mutation (AATM) technique to generate synthesized and balanced datasets for GOOSE messages, ensuring protocol compliance and enabling realistic zero-day attack pattern creation to address data scarcity. Then, the implementation of GenAI-based ADSs incorporating the task-oriented dialogue (ToD) processes has been explored for improved detection of attack patterns. Finally, a comparison of the GenAI-based ADS with machine learning (ML)-based ADSs has been implemented to showcase the outperformance of the GenAI-based frameworks considering the AATM-generated GOOSE datasets and standard/advanced performance evaluation metrics.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°ä»£æ™ºèƒ½ç”µç½‘ä¸­åŸºäº IEC61850 æ ‡å‡†çš„æ•°å­—å˜ç”µç«™é¢ä¸´çš„ç½‘ç»œå®‰å…¨æŒ‘æˆ˜ï¼Œæå‡ºäº†ä¸€ç§åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½ (Generative AI) çš„ç»Ÿä¸€æ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³ä¼ ç»Ÿå¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ (ADS) åœ¨è¯†åˆ«å¤æ‚æ”»å‡»æ—¶çš„å±€é™æ€§ã€‚è®ºæ–‡çš„æ ¸å¿ƒè´¡çŒ®ä¹‹ä¸€æ˜¯å¼€å‘äº†é«˜çº§å¯¹æŠ—æ€§æµé‡å˜å¼‚ (Advanced Adversarial Traffic Mutation, AATM) æŠ€æœ¯ï¼Œé€šè¿‡ç”Ÿæˆç¬¦åˆåè®®è§„èŒƒçš„åˆæˆå¹³è¡¡æ•°æ®é›†ï¼Œå®ç°äº†å¯¹ GOOSE åè®®é›¶æ—¥æ”»å‡»æ¨¡å¼çš„é€¼çœŸæ¨¡æ‹Ÿï¼Œæœ‰æ•ˆè§£å†³äº†æ•°æ®ç¨€ç¼ºé—®é¢˜ã€‚æ­¤å¤–ï¼Œç ”ç©¶å¼•å…¥äº†æ•´åˆä»»åŠ¡å¯¼å‘å‹å¯¹è¯ (Task-oriented Dialogue, ToD) æµç¨‹çš„æ£€æµ‹æœºåˆ¶ï¼Œæ˜¾è‘—å¢å¼ºäº†å¯¹å˜ç”µç«™å†…éƒ¨é€šä¿¡å¼‚å¸¸çš„è¯†åˆ«ç²¾åº¦ã€‚å®éªŒå¯¹æ¯”è¡¨æ˜ï¼Œåœ¨å¤„ç† AATM ç”Ÿæˆçš„ç‰¹å®šæµé‡æ•°æ®æ—¶ï¼Œè¯¥ GenAI æ¡†æ¶åœ¨å¤šé¡¹æ€§èƒ½æŒ‡æ ‡ä¸Šå‡ä¼˜äºä¼ ç»Ÿçš„æœºå™¨å­¦ä¹  (ML) æ¨¡å‹ã€‚è¿™ä¸€æˆæœä¸ºç¡®ä¿æ•°å­—å˜ç”µç«™å…³é”®ä¿¡æ¯é€šä¿¡æŠ€æœ¯ (ICT) æ¶æ„çš„å®‰å…¨æ€§å’Œå¯é æ€§æä¾›äº†åˆ›æ–°çš„é˜²å¾¡ç­–ç•¥ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "28 pages, 12 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.08593v1",
      "published_date": "2025-08-12 03:18:05 UTC",
      "updated_date": "2025-08-12 03:18:05 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:18.188322+00:00"
    },
    {
      "arxiv_id": "2508.08591v1",
      "title": "DepressLLM: Interpretable domain-adapted language model for depression detection from real-world narratives",
      "title_zh": "DepressLLMï¼šé¢å‘çœŸå®ä¸–ç•Œå™è¿°æŠ‘éƒæ£€æµ‹çš„å¯è§£é‡Šé¢†åŸŸè‡ªé€‚åº”è¯­è¨€æ¨¡å‹",
      "authors": [
        "Sehwan Moon",
        "Aram Lee",
        "Jeong Eun Kim",
        "Hee-Ju Kang",
        "Il-Seon Shin",
        "Sung-Wan Kim",
        "Jae-Min Kim",
        "Min Jhon",
        "Ju-Wan Kim"
      ],
      "abstract": "Advances in large language models (LLMs) have enabled a wide range of applications. However, depression prediction is hindered by the lack of large-scale, high-quality, and rigorously annotated datasets. This study introduces DepressLLM, trained and evaluated on a novel corpus of 3,699 autobiographical narratives reflecting both happiness and distress. DepressLLM provides interpretable depression predictions and, via its Score-guided Token Probability Summation (SToPS) module, delivers both improved classification performance and reliable confidence estimates, achieving an AUC of 0.789, which rises to 0.904 on samples with confidence $\\geq$ 0.95. To validate its robustness to heterogeneous data, we evaluated DepressLLM on in-house datasets, including an Ecological Momentary Assessment (EMA) corpus of daily stress and mood recordings, and on public clinical interview data. Finally, a psychiatric review of high-confidence misclassifications highlighted key model and data limitations that suggest directions for future refinements. These findings demonstrate that interpretable AI can enable earlier diagnosis of depression and underscore the promise of medical AI in psychiatry.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†DepressLLMï¼Œè¿™æ˜¯ä¸€ç§ä¸“é—¨ç”¨äºä»çœŸå®å™äº‹ä¸­æ£€æµ‹æŠ‘éƒç—‡çš„å¯è§£é‡Šé¢†åŸŸè‡ªé€‚åº”è¯­è¨€æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³æŠ‘éƒç—‡é¢„æµ‹ä¸­ç¼ºä¹å¤§è§„æ¨¡ã€é«˜è´¨é‡æ ‡æ³¨æ•°æ®é›†çš„é—®é¢˜ã€‚è¯¥æ¨¡å‹åœ¨åŒ…å«3,699ä¸ªè‡ªä¼ ä½“å™äº‹çš„è¯­æ–™åº“ä¸Šè¿›è¡Œè®­ç»ƒï¼Œå¹¶åˆ©ç”¨å…¶Score-guided Token Probability Summation (SToPS)æ¨¡å—æä¾›å¯è§£é‡Šçš„é¢„æµ‹ä¸å¯é çš„ç½®ä¿¡åº¦è¯„ä¼°ã€‚å®éªŒè¡¨æ˜ï¼ŒDepressLLMå®ç°äº†0.789çš„AUCï¼Œè€Œåœ¨é«˜ç½®ä¿¡åº¦æ ·æœ¬ä¸ŠAUCå¯è¾¾0.904ï¼Œå±•ç°å‡ºä¼˜å¼‚çš„åˆ†ç±»æ€§èƒ½ã€‚é€šè¿‡åœ¨å†…éƒ¨Ecological Momentary Assessment (EMA)æ•°æ®é›†å’Œå…¬å¼€ä¸´åºŠè®¿è°ˆæ•°æ®ä¸Šçš„å¤šç»´åº¦éªŒè¯ï¼Œè¯æ˜äº†è¯¥æ¨¡å‹å¯¹å¼‚è´¨æ•°æ®çš„é²æ£’æ€§ã€‚æœ€åï¼Œé€šè¿‡ç²¾ç¥ç—…å­¦ä¸“å®¶å¯¹é«˜ç½®ä¿¡åº¦é”™è¯¯åˆ†ç±»æ¡ˆä¾‹çš„å®¡æŸ¥ï¼Œç ”ç©¶æŒ‡å‡ºäº†æ¨¡å‹å½“å‰çš„å±€é™æ€§å¹¶æå‡ºäº†æ”¹è¿›æ–¹å‘ï¼Œå¼ºè°ƒäº†å¯è§£é‡ŠAIåœ¨è¾…åŠ©ç²¾ç¥åŒ»å­¦æ—©æœŸè¯Šæ–­æ–¹é¢çš„å·¨å¤§æ½œåŠ›ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08591v1",
      "published_date": "2025-08-12 03:12:55 UTC",
      "updated_date": "2025-08-12 03:12:55 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:20.387789+00:00"
    },
    {
      "arxiv_id": "2508.10044v2",
      "title": "Large Language Models for Power System Security: A Novel Multi-Modal Approach for Anomaly Detection in Energy Management Systems",
      "title_zh": "é¢å‘ç”µåŠ›ç³»ç»Ÿå®‰å…¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼šèƒ½é‡ç®¡ç†ç³»ç»Ÿå¼‚å¸¸æ£€æµ‹çš„æ–°å‹å¤šæ¨¡æ€æ–¹æ³•",
      "authors": [
        "Aydin Zaboli",
        "Junho Hong",
        "Alexandru Stefanov",
        "Chen-Ching Liu",
        "Chul-Sang Hwang"
      ],
      "abstract": "This paper elaborates on an extensive security framework specifically designed for energy management systems (EMSs), which effectively tackles the dynamic environment of cybersecurity vulnerabilities and/or system problems (SPs), accomplished through the incorporation of novel methodologies. A comprehensive multi-point attack/error model is initially proposed to systematically identify vulnerabilities throughout the entire EMS data processing pipeline, including post state estimation (SE) stealth attacks, EMS database manipulation, and human-machine interface (HMI) display corruption according to the real-time database (RTDB) storage. This framework acknowledges the interconnected nature of modern attack vectors, which utilize various phases of supervisory control and data acquisition (SCADA) data flow. Then, generative AI (GenAI)-based anomaly detection systems (ADSs) for EMSs are proposed for the first time in the power system domain to handle the scenarios. Further, a set-of-mark generative intelligence (SoM-GI) framework, which leverages multimodal analysis by integrating visual markers with rules considering the GenAI capabilities, is suggested to overcome inherent spatial reasoning limitations. The SoM-GI methodology employs systematic visual indicators to enable accurate interpretation of segmented HMI displays and detect visual anomalies that numerical methods fail to identify. Validation on the IEEE 14-Bus system shows the framework's effectiveness across scenarios, while visual analysis identifies inconsistencies. This integrated approach combines numerical analysis with visual pattern recognition and linguistic rules to protect against cyber threats and system errors.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç”µåŠ›ç³»ç»Ÿä¸­çš„èƒ½æºç®¡ç†ç³»ç»Ÿ(EMS)æå‡ºäº†ä¸€ç§å…¨æ–°çš„å®‰å…¨æ¡†æ¶ï¼Œæ—¨åœ¨åº”å¯¹åŠ¨æ€çš„ç½‘ç»œå®‰å…¨æ¼æ´ä¸ç³»ç»Ÿé—®é¢˜(SPs)ã€‚ç ”ç©¶é¦–å…ˆæ„å»ºäº†ä¸€ä¸ªå¤šç‚¹æ”»å‡»/é”™è¯¯æ¨¡å‹ï¼Œç”¨ä»¥ç³»ç»Ÿè¯†åˆ«æ¶µç›–çŠ¶æ€ä¼°è®¡(SE)éšè”½æ”»å‡»ã€æ•°æ®åº“ç¯¡æ”¹åŠäººæœºç•Œé¢(HMI)æ˜¾ç¤ºå¼‚å¸¸çš„å®Œæ•´æ•°æ®å¤„ç†æµæ°´çº¿æ¼æ´ã€‚ä¸ºæœ‰æ•ˆå¤„ç†è¿™äº›åœºæ™¯ï¼Œè¯¥æ–‡åœ¨ç”µåŠ›é¢†åŸŸé¦–æ¬¡å¼•å…¥äº†åŸºäºç”Ÿæˆå¼äººå·¥æ™ºèƒ½(GenAI)çš„å¼‚å¸¸æ£€æµ‹ç³»ç»Ÿ(ADS)ã€‚æ­¤å¤–ï¼Œç ”ç©¶æå‡ºäº†SoM-GI(Set-of-Mark Generative Intelligence)æ¡†æ¶ï¼Œé€šè¿‡å°†è§†è§‰æ ‡è®°ä¸è§„åˆ™ç›¸ç»“åˆè¿›è¡Œå¤šæ¨¡æ€åˆ†æï¼ŒæˆåŠŸå…‹æœäº†GenAIå›ºæœ‰çš„ç©ºé—´æ¨ç†å±€é™æ€§ã€‚åœ¨IEEE 14-Busç³»ç»Ÿä¸Šçš„éªŒè¯ç»“æœè¡¨æ˜ï¼Œè¯¥æ¡†æ¶èƒ½æœ‰æ•ˆè¯†åˆ«æ•°å€¼æ–¹æ³•æ— æ³•æ£€æµ‹çš„è§†è§‰å¼‚å¸¸ï¼Œé€šè¿‡é›†æˆæ•°å€¼åˆ†æã€è§†è§‰æ¨¡å¼è¯†åˆ«ä¸è¯­è¨€è§„åˆ™ï¼Œæ˜¾è‘—æå‡äº†ç”µåŠ›ç³»ç»Ÿçš„å®‰å…¨é˜²æŠ¤èƒ½åŠ›ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "10 Figures; 6 Tables; Accepted, IEEE ACCESS 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.10044v2",
      "published_date": "2025-08-12 03:10:22 UTC",
      "updated_date": "2025-11-29 20:47:24 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:34.985631+00:00"
    },
    {
      "arxiv_id": "2508.20102v1",
      "title": "A Hierarchical Signal Coordination and Control System Using a Hybrid Model-based and Reinforcement Learning Approach",
      "title_zh": "åŸºäºæ¨¡å‹ä¸å¼ºåŒ–å­¦ä¹ æ··åˆæ–¹æ³•çš„åˆ†å±‚ä¿¡å·åè°ƒæ§åˆ¶ç³»ç»Ÿ",
      "authors": [
        "Xianyue Peng",
        "Shenyang Chen",
        "H. Michael Zhang"
      ],
      "abstract": "Signal control in urban corridors faces the dual challenge of maintaining arterial traffic progression while adapting to demand variations at local intersections. We propose a hierarchical traffic signal coordination and control scheme that integrates model-based optimization with reinforcement learning. The system consists of: (i) a High-Level Coordinator (HLC) that selects coordination strategies based on observed and predicted demand; (ii) a Corridor Coordinator that derives phase constraints from the selected strategy-either Max-Flow Coordination (MFC) or Green-Wave Coordination (GWC); and (iii) Hybrid Signal Agents (HSAs) that determine signal phases via reinforcement learning with action masking to enforce feasibility. Hierarchical reinforcement learning with Proximal Policy Optimization (PPO) is used to train HSA and HLC policies. At the lower level, three HSA policies-MFC-aware, GWC-aware, and pure agent control (PAC) are trained in conjunction with their respective coordination strategies. At the higher level, the HLC is trained to dynamically switch strategies using a multi-objective reward balancing corridor-level and network-wide performance. The proposed scheme was developed and evaluated on a SUMO-RLlib platform. Case results show that hybrid MFC maximizes throughput under heavy demand; hybrid GWC consistently minimizes arterial stops and maintains progression across diverse traffic conditions but can reduce network-wide efficiency; and PAC improves network-wide travel time in moderate demand but is less effective under heavy demand. The hierarchical design enables adaptive strategy selection, achieving robust performance across all demand levels.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ç§åˆ†å±‚äº¤é€šä¿¡å·åè°ƒä¸æ§åˆ¶æ–¹æ¡ˆï¼Œæ—¨åœ¨è§£å†³åŸå¸‚å»Šé“åœ¨ç»´æŒå¹²çº¿äº¤é€šè¿ç»­æ€§ä¸é€‚åº”å±€éƒ¨äº¤å‰å£éœ€æ±‚å˜åŒ–ä¹‹é—´çš„åŒé‡æŒ‘æˆ˜ã€‚è¯¥ç³»ç»Ÿé›†æˆäº†åŸºäºæ¨¡å‹çš„ä¼˜åŒ–ä¸å¼ºåŒ–å­¦ä¹ (Reinforcement Learning)æŠ€æœ¯ï¼Œç”±é«˜å±‚åè°ƒå™¨(HLC)ã€å»Šé“åè°ƒå™¨å’Œæ··åˆä¿¡å·æ™ºèƒ½ä½“(HSAs)ä¸‰ä¸ªæ ¸å¿ƒç»„ä»¶æ„æˆã€‚å…¶ä¸­ï¼ŒHLCåˆ©ç”¨è¿‘ç«¯ç­–ç•¥ä¼˜åŒ–(PPO)ç®—æ³•æ ¹æ®äº¤é€šé¢„æµ‹åŠ¨æ€åˆ‡æ¢åè°ƒç­–ç•¥ï¼Œè€Œåº•å±‚æ™ºèƒ½ä½“åˆ™ç»“åˆå¤§æµé‡åè°ƒ(MFC)ã€ç»¿æ³¢åè°ƒ(GWC)æˆ–çº¯æ™ºèƒ½ä½“æ§åˆ¶(PAC)å¹¶è¾…ä»¥åŠ¨ä½œæ©ç (action masking)æ¥ç¡®ä¿å†³ç­–å¯è¡Œæ€§ã€‚åœ¨SUMO-RLlibå¹³å°ä¸Šçš„ä»¿çœŸç»“æœæ˜¾ç¤ºï¼Œæ··åˆMFCåœ¨é‡è½½éœ€æ±‚ä¸‹è¡¨ç°æœ€ä¼˜ï¼Œæ··åˆGWCèƒ½æœ‰æ•ˆå‡å°‘å¹²çº¿åœè½¦ï¼Œè€ŒPACåœ¨é€‚åº¦éœ€æ±‚ä¸‹èƒ½ç¼©çŸ­å…¨ç½‘æ—…è¡Œæ—¶é—´ã€‚è¿™ç§åˆ†å±‚è®¾è®¡ç¡®ä¿äº†ç³»ç»Ÿåœ¨å„ç±»äº¤é€šéœ€æ±‚æ°´å¹³ä¸‹å‡å…·æœ‰é²æ£’çš„æ€§èƒ½è¡¨ç°ï¼Œé€šè¿‡æ¨¡å‹é©±åŠ¨ä¸æ•°æ®é©±åŠ¨çš„æ··åˆæ¶æ„ï¼Œä¸ºè‡ªé€‚åº”çš„åŸå¸‚äº¤é€šæµä¼˜åŒ–æä¾›äº†æœ‰æ•ˆæ‰‹æ®µã€‚",
      "categories": [
        "eess.SY",
        "cs.AI"
      ],
      "primary_category": "eess.SY",
      "comment": "28 pages, 7 figures",
      "pdf_url": "https://arxiv.org/pdf/2508.20102v1",
      "published_date": "2025-08-12 03:10:06 UTC",
      "updated_date": "2025-08-12 03:10:06 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:39.969464+00:00"
    },
    {
      "arxiv_id": "2508.14905v1",
      "title": "Privacy Preserving Inference of Personalized Content for Out of Matrix Users",
      "title_zh": "é¢å‘çŸ©é˜µå¤–ç”¨æˆ·çš„ä¸ªæ€§åŒ–å†…å®¹éšç§ä¿æŠ¤æ¨ç†",
      "authors": [
        "Michael Sun",
        "Tai Vu",
        "Andrew Wang"
      ],
      "abstract": "Recommender systems for niche and dynamic communities face persistent challenges from data sparsity, cold start users and items, and privacy constraints. Traditional collaborative filtering and content-based approaches underperform in these settings, either requiring invasive user data or failing when preference histories are absent. We present DeepNaniNet, a deep neural recommendation framework that addresses these challenges through an inductive graph-based architecture combining user-item interactions, item-item relations, and rich textual review embeddings derived from BERT. Our design enables cold start recommendations without profile mining, using a novel \"content basket\" user representation and an autoencoder-based generalization strategy for unseen users. We introduce AnimeULike, a new dataset of 10,000 anime titles and 13,000 users, to evaluate performance in realistic scenarios with high proportions of guest or low-activity users. DeepNaniNet achieves state-of-the-art cold start results on the CiteULike benchmark, matches DropoutNet in user recall without performance degradation for out-of-matrix users, and outperforms Weighted Matrix Factorization (WMF) and DropoutNet on AnimeULike warm start by up to 7x and 1.5x in Recall@100, respectively. Our findings demonstrate that DeepNaniNet delivers high-quality, privacy-preserving recommendations in data-sparse, cold start-heavy environments while effectively integrating heterogeneous content sources.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å°ä¼—åŠ¨æ€ç¤¾åŒºä¸­æ¨èç³»ç»Ÿé¢ä¸´çš„æ•°æ®ç¨€ç–ã€å†·å¯åŠ¨åŠéšç§é™åˆ¶ç­‰æŒ‘æˆ˜ï¼Œæå‡ºäº†DeepNaniNetæ·±åº¦ç¥ç»æ¨èæ¡†æ¶ã€‚è¯¥æ¡†æ¶é‡‡ç”¨åŸºäºå½’çº³å¼å›¾(inductive graph-based)çš„æ¶æ„ï¼Œæœ‰æ•ˆç»“åˆäº†ç”¨æˆ·-é¡¹ç›®äº¤äº’ã€é¡¹ç›®é—´å…³ç³»ä»¥åŠåŸºäºBERTçš„ä¸°å¯Œæ–‡æœ¬è¯„è®ºåµŒå…¥ã€‚å…¶æ ¸å¿ƒåˆ›æ–°åœ¨äºæå‡ºäº†â€œå†…å®¹ç¯®å­â€(content basket)ç”¨æˆ·è¡¨ç¤ºæ–¹æ³•å’ŒåŸºäºè‡ªåŠ¨ç¼–ç å™¨(autoencoder)çš„æ³›åŒ–ç­–ç•¥ï¼Œä½¿ç³»ç»Ÿèƒ½å¤Ÿåœ¨ä¸ä¾èµ–ä¾µå…¥æ€§ç”¨æˆ·ç”»åƒçš„æƒ…å†µä¸‹ï¼Œä¸ºçŸ©é˜µå¤–(out-of-matrix)ç”¨æˆ·æä¾›éšç§ä¿æŠ¤çš„å†·å¯åŠ¨æ¨èã€‚ç ”ç©¶è€…è¿˜å‘å¸ƒäº†åŒ…å«1ä¸‡éƒ¨åŠ¨ç”»å’Œ1.3ä¸‡åç”¨æˆ·çš„AnimeULikeæ–°æ•°æ®é›†ä»¥æ¨¡æ‹ŸçœŸå®çš„ä½æ´»è·ƒåœºæ™¯ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒDeepNaniNetåœ¨CiteULikeåŸºå‡†ä¸Šå–å¾—äº†æœ€å…ˆè¿›çš„å†·å¯åŠ¨ç»“æœï¼Œå¹¶åœ¨AnimeULikeæ•°æ®é›†çš„Recall@100æŒ‡æ ‡ä¸Šæ˜¾è‘—ä¼˜äºWMFå’ŒDropoutNetæ¨¡å‹ã€‚è¯¥æ¡†æ¶è¯æ˜äº†åœ¨æ•°æ®ç¨€ç–ä¸”å†·å¯åŠ¨ä¸¥é‡çš„æŒ‘æˆ˜æ€§ç¯å¢ƒä¸­ï¼Œé€šè¿‡é›†æˆå¼‚æ„å†…å®¹å¯å®ç°é«˜è´¨é‡ä¸”å…¼é¡¾éšç§çš„ä¸ªæ€§åŒ–æ¨èã€‚",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.14905v1",
      "published_date": "2025-08-12 02:55:29 UTC",
      "updated_date": "2025-08-12 02:55:29 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:40.761316+00:00"
    },
    {
      "arxiv_id": "2508.08583v1",
      "title": "AI Security Map: Holistic Organization of AI Security Technologies and Impacts on Stakeholders",
      "title_zh": "AI å®‰å…¨åœ°å›¾ï¼šAI å®‰å…¨æŠ€æœ¯çš„ç³»ç»ŸåŒ–æ¢³ç†åŠå…¶å¯¹åˆ©ç›Šç›¸å…³è€…çš„å½±å“",
      "authors": [
        "Hiroya Kato",
        "Kentaro Kita",
        "Kento Hasegawa",
        "Seira Hidano"
      ],
      "abstract": "As the social implementation of AI has been steadily progressing, research and development related to AI security has also been increasing. However, existing studies have been limited to organizing related techniques, attacks, defenses, and risks in terms of specific domains or AI elements. Thus, it extremely difficult to understand the relationships among them and how negative impacts on stakeholders are brought about. In this paper, we argue that the knowledge, technologies, and social impacts related to AI security should be holistically organized to help understand relationships among them. To this end, we first develop an AI security map that holistically organizes interrelationships among elements related to AI security as well as negative impacts on information systems and stakeholders. This map consists of the two aspects, namely the information system aspect (ISA) and the external influence aspect (EIA). The elements that AI should fulfill within information systems are classified under the ISA. The EIA includes elements that affect stakeholders as a result of AI being attacked or misused. For each element, corresponding negative impacts are identified. By referring to the AI security map, one can understand the potential negative impacts, along with their causes and countermeasures. Additionally, our map helps clarify how the negative impacts on AI-based systems relate to those on stakeholders. We show some findings newly obtained by referring to our map. We also provide several recommendations and open problems to guide future AI security communities.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ç°æœ‰AI securityç ”ç©¶å¤šå±€é™äºç‰¹å®šé¢†åŸŸè€Œéš¾ä»¥ç†è§£å…¶å…³è”æ€§çš„ç°çŠ¶ï¼Œæå‡ºäº†ä¸€ä¸ªæ—¨åœ¨å…¨å±€æ•´åˆAIå®‰å…¨æŠ€æœ¯åŠç¤¾ä¼šå½±å“çš„AI Security Mapã€‚è¯¥åœ°å›¾ç”±ä¿¡æ¯ç³»ç»Ÿç»´åº¦(Information System Aspect, ISA)å’Œå¤–éƒ¨å½±å“ç»´åº¦(External Influence Aspect, EIA)ä¸¤ä¸ªæ ¸å¿ƒå±‚é¢ç»„æˆï¼Œå…¶ä¸­ISAåˆ†ç±»äº†AIåœ¨ç³»ç»Ÿå†…éœ€æ»¡è¶³çš„è¦ç´ ï¼Œè€ŒEIAåˆ™æ¶µç›–äº†AIè¢«æ”»å‡»æˆ–è¯¯ç”¨æ—¶å¯¹åˆ©ç›Šç›¸å…³è€…çš„å½±å“ã€‚é€šè¿‡å‚è€ƒæ­¤å›¾è°±ï¼Œç ”ç©¶è€…å¯ä»¥ç³»ç»Ÿåœ°è¯†åˆ«æ½œåœ¨çš„è´Ÿé¢å½±å“ã€æˆå› åŠå…¶å¯¹åº”çš„Countermeasuresã€‚æ­¤å¤–ï¼Œè¯¥åœ°å›¾é˜æ˜äº†AIç³»ç»Ÿå±‚é¢çš„è´Ÿé¢å½±å“æ˜¯å¦‚ä½•è½¬åŒ–ä¸ºå¯¹åˆ©ç›Šç›¸å…³è€…ä¹‹å½±å“çš„ï¼Œå¹¶åŸºäºæ­¤æ­ç¤ºäº†æ–°çš„å®‰å…¨å‘ç°ã€‚æœ€åï¼Œè®ºæ–‡ä¸ºAI securityç¤¾åŒºæä¾›äº†å¤šé¡¹å»ºè®®åŠOpen Problemsï¼Œä¸ºæœªæ¥çš„å®‰å…¨ç ”ç©¶æ–¹å‘æä¾›äº†æŒ‡å¼•ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08583v1",
      "published_date": "2025-08-12 02:41:20 UTC",
      "updated_date": "2025-08-12 02:41:20 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:40.555084+00:00"
    },
    {
      "arxiv_id": "2508.14904v3",
      "title": "Efficient Switchable Safety Control in LLMs via Magic-Token-Guided Co-Training",
      "title_zh": "åŸºäº Magic-Token å¼•å¯¼ååŒè®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹é«˜æ•ˆå¯åˆ‡æ¢å®‰å…¨æ§åˆ¶",
      "authors": [
        "Jianfeng Si",
        "Lin Sun",
        "Zhewen Tan",
        "Xiangzheng Zhang"
      ],
      "abstract": "Current methods for content safety in Large Language Models (LLMs), such as Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF), often rely on multi-stage training pipelines and lack fine-grained, post-deployment controllability. To address these limitations, we propose a unified co-training framework that efficiently integrates multiple safety behaviors: positive (lawful/prosocial), negative (unfiltered/risk-prone) and rejective (refusal-oriented/conservative) within a single SFT stage. Notably, each behavior is dynamically activated via a simple system-level instruction, or magic token, enabling stealthy and efficient behavioral switching at inference time. This flexibility supports diverse deployment scenarios, such as positive for safe user interaction, negative for internal red-teaming, and rejective for context-aware refusals triggered by upstream moderation signals. This co-training strategy induces a distinct Safety Alignment Margin in the output space, characterized by well-separated response distributions corresponding to each safety mode. The existence of this margin provides empirical evidence for the model's safety robustness and enables unprecedented fine-grained control. Experiments show that our method matches the safety alignment quality of SFT+DPO, with our 8B model notably surpassing DeepSeek-R1 (671B) in safety performance, while significantly reducing both training complexity and deployment costs. This work presents a scalable, efficient, and highly controllable solution for LLM content safety.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªç»Ÿä¸€çš„å…±åŒè®­ç»ƒæ¡†æ¶(co-training framework)ï¼Œæ—¨åœ¨è§£å†³å¤§è¯­è¨€æ¨¡å‹(LLMs)åœ¨å†…å®¹å®‰å…¨é¢†åŸŸé¢ä¸´çš„å¤šé˜¶æ®µè®­ç»ƒå¤æ‚å’Œç¼ºä¹åæœŸå¯æ§æ€§ç­‰é—®é¢˜ã€‚è¯¥æ¡†æ¶åœ¨å•ä¸ªç›‘ç£å¾®è°ƒ(SFT)é˜¶æ®µæ•´åˆäº†æ­£é¢ã€è´Ÿé¢å’Œæ‹’ç»æ€§ä¸‰ç§å®‰å…¨è¡Œä¸ºï¼Œå¹¶é€šè¿‡â€œé­”æœ¯ä»¤ç‰Œâ€(magic token)æˆ–ç³»ç»Ÿçº§æŒ‡ä»¤åœ¨æ¨ç†æ—¶å®ç°çµæ´»çš„è¡Œä¸ºåˆ‡æ¢ã€‚è¿™ç§æ–¹æ³•åœ¨è¾“å‡ºç©ºé—´è¯±å¯¼å‡ºäº†æ˜¾è‘—çš„å®‰å…¨å¯¹é½è¾¹ç•Œ(Safety Alignment Margin)ï¼Œä¸ºæ¨¡å‹çš„å®‰å…¨é²æ£’æ€§æä¾›äº†å®è¯æ”¯æŒï¼Œå¹¶å®ç°äº†å‰æ‰€æœªæœ‰çš„ç»†ç²’åº¦æ§åˆ¶ã€‚å®éªŒè¡¨æ˜ï¼Œè¯¥æ–¹æ³•åœ¨å®‰å…¨å¯¹é½è´¨é‡ä¸Šå¯ä¸SFT+DPOæ–¹æ¡ˆåª²ç¾ï¼Œå…¶8Bè§„æ¨¡çš„æ¨¡å‹åœ¨å®‰å…¨æ€§èƒ½ä¸Šç”šè‡³è¶…è¶Šäº†DeepSeek-R1 (671B)ã€‚è¯¥å·¥ä½œä¸ºå¤§è¯­è¨€æ¨¡å‹æä¾›äº†ä¸€ç§é«˜æ•ˆã€å¯æ‰©å±•ä¸”ä½æˆæœ¬çš„å†…å®¹å®‰å…¨è§£å†³æ–¹æ¡ˆï¼Œæ˜¾è‘—é™ä½äº†è®­ç»ƒä¸éƒ¨ç½²çš„å¤æ‚åº¦ã€‚",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages,3 figures,5 tables",
      "pdf_url": "https://arxiv.org/pdf/2508.14904v3",
      "published_date": "2025-08-12 02:39:33 UTC",
      "updated_date": "2026-01-20 13:15:53 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:26:57.590633+00:00"
    },
    {
      "arxiv_id": "2508.08573v2",
      "title": "Who Pays the RENT? Implications of Spatial Inequality for Prediction-Based Allocation Policies",
      "title_zh": "è°ä¸º RENT ä¹°å•ï¼Ÿç©ºé—´ä¸å¹³ç­‰å¯¹åŸºäºé¢„æµ‹çš„åˆ†é…æ”¿ç­–çš„å¯ç¤º",
      "authors": [
        "Tasfia Mashiat",
        "Patrick J. Fowler",
        "Sanmay Das"
      ],
      "abstract": "AI-powered scarce resource allocation policies rely on predictions to target either specific individuals (e.g., high-risk) or settings (e.g., neighborhoods). Recent research on individual-level targeting demonstrates conflicting results; some models show that targeting is not useful when inequality is high, while other work demonstrates potential benefits. To study and reconcile this apparent discrepancy, we develop a stylized framework based on the Mallows model to understand how the spatial distribution of inequality affects the effectiveness of door-to-door outreach policies. We introduce the RENT (Relative Efficiency of Non-Targeting) metric, which we use to assess the effectiveness of targeting approaches compared with neighborhood-based approaches in preventing tenant eviction when high-risk households are more versus less spatially concentrated. We then calibrate the model parameters to eviction court records collected in a medium-sized city in the USA. Results demonstrate considerable gains in the number of high-risk households canvassed through individually targeted policies, even in a highly segregated metro area with concentrated risks of eviction. We conclude that apparent discrepancies in the prior literature can be reconciled by considering 1) the source of deployment costs and 2) the observed versus modeled concentrations of risk. Our results inform the deployment of AI-based solutions in social service provision that account for particular applications and geographies.",
      "tldr_zh": "æœ¬ç ”ç©¶æ¢è®¨äº† AI é©±åŠ¨çš„ç¨€ç¼ºèµ„æºåˆ†é…æ”¿ç­–åœ¨ä¸åŒç©ºé—´ä¸å¹³ç­‰èƒŒæ™¯ä¸‹çš„æœ‰æ•ˆæ€§ï¼Œç‰¹åˆ«æ˜¯å¯¹æ¯”äº†é’ˆå¯¹ä¸ªä½“(Individual-level targeting)ä¸é’ˆå¯¹ç¤¾åŒº(Neighborhood-based approaches)çš„åˆ†é…ç­–ç•¥ã€‚ç ”ç©¶äººå‘˜å¼€å‘äº†ä¸€ä¸ªåŸºäº Mallows model çš„é£æ ¼åŒ–æ¡†æ¶ï¼Œå¹¶å¼•å…¥äº† RENT (Relative Efficiency of Non-Targeting) æŒ‡æ ‡ï¼Œç”¨äºè¯„ä¼°åœ¨é¢„é˜²ç§Ÿå®¢é©±é€(Tenant eviction)æ—¶ï¼Œç©ºé—´åˆ†å¸ƒå¦‚ä½•å½±å“ä¸Šé—¨èµ°è®¿ç­‰æ”¿ç­–çš„æ•ˆç‡ã€‚é€šè¿‡å¯¹ç¾å›½æŸä¸­å‹åŸå¸‚æ³•é™¢é©±é€è®°å½•çš„æ•°æ®æ ¡å‡†ï¼Œå®éªŒç»“æœè¡¨æ˜å³ä½¿åœ¨é«˜åº¦éš”ç¦»ä¸”é£é™©é›†ä¸­çš„åœ°åŒºï¼ŒåŸºäºä¸ªä½“çš„ç›®æ ‡å®šä½æ”¿ç­–åœ¨è¯†åˆ«é«˜é£é™©å®¶åº­æ–¹é¢ä»èƒ½äº§ç”Ÿæ˜¾è‘—æ”¶ç›Šã€‚è¯¥ç ”ç©¶é€šè¿‡è€ƒé‡éƒ¨ç½²æˆæœ¬æ¥æºä»¥åŠé£é™©æµ“åº¦çš„è§‚æµ‹ä¸æ¨¡å‹å·®å¼‚ï¼ŒæˆåŠŸè°ƒå’Œäº†ç°æœ‰æ–‡çŒ®ä¸­å…³äºç›®æ ‡å®šä½æœ‰æ•ˆæ€§çš„çŸ›ç›¾ç»“è®ºã€‚è¿™äº›ç ”ç©¶æˆæœä¸ºåœ¨ç¤¾ä¼šæœåŠ¡ä¾›ç»™ä¸­éƒ¨ç½²æ›´å…·åœ°ç†é’ˆå¯¹æ€§çš„ AI è§£å†³æ–¹æ¡ˆæä¾›äº†ç†è®ºä¾æ®å’Œå®è·µæŒ‡å¯¼ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "This work has been accepted for publication as a full paper at the AAAI/ACM Conference on AI, Ethics, and Society (AIES 2025)",
      "pdf_url": "https://arxiv.org/pdf/2508.08573v2",
      "published_date": "2025-08-12 02:16:50 UTC",
      "updated_date": "2025-08-17 03:49:32 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:18.364090+00:00"
    },
    {
      "arxiv_id": "2508.08570v1",
      "title": "Superclass-Guided Representation Disentanglement for Spurious Correlation Mitigation",
      "title_zh": "ç¼“è§£è™šå‡ç›¸å…³çš„è¶…ç±»å¼•å¯¼è¡¨å¾è§£è€¦",
      "authors": [
        "Chenruo Liu",
        "Hongjun Liu",
        "Zeyu Lai",
        "Yiqiu Shen",
        "Chen Zhao",
        "Qi Lei"
      ],
      "abstract": "To enhance group robustness to spurious correlations, prior work often relies on auxiliary annotations for groups or spurious features and assumes identical sets of groups across source and target domains. These two requirements are both unnatural and impractical in real-world settings. To overcome these limitations, we propose a method that leverages the semantic structure inherent in class labels--specifically, superclass information--to naturally reduce reliance on spurious features. Our model employs gradient-based attention guided by a pre-trained vision-language model to disentangle superclass-relevant and irrelevant features. Then, by promoting the use of all superclass-relevant features for prediction, our approach achieves robustness to more complex spurious correlations without the need to annotate any source samples. Experiments across diverse datasets demonstrate that our method significantly outperforms baselines in domain generalization tasks, with clear improvements in both quantitative metrics and qualitative visualizations.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹å‡è½»è™šå‡ç›¸å…³æ€§ï¼ˆSpurious Correlationï¼‰é€šå¸¸ä¾èµ–è¾…åŠ©æ ‡æ³¨ä¸”å‡è®¾åŸŸåˆ†å¸ƒä¸€è‡´çš„å±€é™æ€§ï¼Œæå‡ºäº†ä¸€ç§åˆ©ç”¨ç±»åˆ«æ ‡ç­¾å†…åœ¨è¯­ä¹‰ç»“æ„ï¼ˆå³è¶…ç±» Superclass ä¿¡æ¯ï¼‰çš„æ–°æ–¹æ³•ã€‚è¯¥æ¨¡å‹é€šè¿‡é¢„è®­ç»ƒè§†è§‰è¯­è¨€æ¨¡å‹ï¼ˆVision-Language Modelï¼‰å¼•å¯¼çš„æ¢¯åº¦æ³¨æ„åŠ›æœºåˆ¶ï¼Œå®ç°äº†è¶…ç±»ç›¸å…³ç‰¹å¾ä¸æ— å…³ç‰¹å¾çš„è§£è€¦ï¼ˆDisentanglementï¼‰ã€‚é€šè¿‡é¼“åŠ±é¢„æµ‹è¿‡ç¨‹å……åˆ†åˆ©ç”¨æ‰€æœ‰ä¸è¶…ç±»ç›¸å…³çš„ç‰¹å¾ï¼Œè¯¥æ–¹æ³•åœ¨æ— éœ€å¯¹æºåŸŸæ ·æœ¬è¿›è¡Œé¢å¤–æ ‡æ³¨çš„æƒ…å†µä¸‹ï¼Œå¢å¼ºäº†å¯¹å¤æ‚è™šå‡ç›¸å…³æ€§çš„æŠµå¾¡èƒ½åŠ›ã€‚å¤šé¡¹å®éªŒç»“æœè¯æ˜ï¼Œè¯¥æ–¹æ³•åœ¨åŸŸæ³›åŒ–ï¼ˆDomain Generalizationï¼‰ä»»åŠ¡ä¸­çš„è¡¨ç°æ˜¾è‘—ä¼˜äºç°æœ‰åŸºçº¿æ¨¡å‹ã€‚é‡åŒ–æŒ‡æ ‡ä¸å®šæ€§å¯è§†åŒ–åˆ†æè¿›ä¸€æ­¥éªŒè¯äº†è¯¥æ¡†æ¶åœ¨æ•æ‰æœ¬è´¨è¯­ä¹‰ç‰¹å¾åŠæå‡æ¨¡å‹é²æ£’æ€§æ–¹é¢çš„æœ‰æ•ˆæ€§ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08570v1",
      "published_date": "2025-08-12 02:16:04 UTC",
      "updated_date": "2025-08-12 02:16:04 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:14.968418+00:00"
    },
    {
      "arxiv_id": "2508.08551v2",
      "title": "UQGNN: Uncertainty Quantification of Graph Neural Networks for Multivariate Spatiotemporal Prediction",
      "title_zh": "UQGNNï¼šé¢å‘å¤šå˜é‡æ—¶ç©ºé¢„æµ‹çš„å›¾ç¥ç»ç½‘ç»œä¸ç¡®å®šæ€§é‡åŒ–",
      "authors": [
        "Dahai Yu",
        "Dingyi Zhuang",
        "Lin Jiang",
        "Rongchao Xu",
        "Xinyue Ye",
        "Yuheng Bu",
        "Shenhao Wang",
        "Guang Wang"
      ],
      "abstract": "Spatiotemporal prediction plays a critical role in numerous real-world applications such as urban planning, transportation optimization, disaster response, and pandemic control. In recent years, researchers have made significant progress by developing advanced deep learning models for spatiotemporal prediction. However, most existing models are deterministic, i.e., predicting only the expected mean values without quantifying uncertainty, leading to potentially unreliable and inaccurate outcomes. While recent studies have introduced probabilistic models to quantify uncertainty, they typically focus on a single phenomenon (e.g., taxi, bike, crime, or traffic crashes), thereby neglecting the inherent correlations among heterogeneous urban phenomena. To address the research gap, we propose a novel Graph Neural Network with Uncertainty Quantification, termed UQGNN for multivariate spatiotemporal prediction. UQGNN introduces two key innovations: (i) an Interaction-aware Spatiotemporal Embedding Module that integrates a multivariate diffusion graph convolutional network and an interaction-aware temporal convolutional network to effectively capture complex spatial and temporal interaction patterns, and (ii) a multivariate probabilistic prediction module designed to estimate both expected mean values and associated uncertainties. Extensive experiments on four real-world multivariate spatiotemporal datasets from Shenzhen, New York City, and Chicago demonstrate that UQGNN consistently outperforms state-of-the-art baselines in both prediction accuracy and uncertainty quantification. For example, on the Shenzhen dataset, UQGNN achieves a 5% improvement in both prediction accuracy and uncertainty quantification.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†UQGNNï¼Œä¸€ç§å¸¦æœ‰ä¸ç¡®å®šæ€§é‡åŒ–(Uncertainty Quantification)çš„å›¾ç¥ç»ç½‘ç»œæ¡†æ¶ï¼Œæ—¨åœ¨è§£å†³å¤šå…ƒæ—¶ç©ºé¢„æµ‹(Multivariate Spatiotemporal Prediction)ä¸­ç¡®å®šæ€§æ¨¡å‹ç¼ºä¹å¯é æ€§ä»¥åŠç°æœ‰æ¦‚ç‡æ¨¡å‹å¿½è§†å¼‚æ„åŸå¸‚ç°è±¡é—´å†…åœ¨å…³è”çš„é—®é¢˜ã€‚UQGNNå¼•å…¥äº†äº¤äº’æ„ŸçŸ¥æ—¶ç©ºåµŒå…¥æ¨¡å—(Interaction-aware Spatiotemporal Embedding Module)ï¼Œé€šè¿‡ç»“åˆå¤šå…ƒæ‰©æ•£å›¾å·ç§¯ç½‘ç»œ(Multivariate Diffusion Graph Convolutional Network)å’Œäº¤äº’æ„ŸçŸ¥æ—¶é—´å·ç§¯ç½‘ç»œï¼Œæœ‰æ•ˆæ•æ‰å¤æ‚çš„ç©ºé—´å’Œæ—¶é—´äº¤äº’æ¨¡å¼ã€‚è¯¥æ¡†æ¶è¿˜è®¾è®¡äº†ä¸€ä¸ªå¤šå…ƒæ¦‚ç‡é¢„æµ‹æ¨¡å—(Multivariate Probabilistic Prediction Module)ï¼Œèƒ½å¤ŸåŒæ—¶ä¼°ç®—é¢„æµ‹çš„æœŸæœ›å‡å€¼åŠå…¶ç›¸å…³çš„ä¸ç¡®å®šæ€§ã€‚ç ”ç©¶å›¢é˜Ÿåœ¨æ·±åœ³ã€çº½çº¦å’ŒèŠåŠ å“¥çš„å››ä¸ªçœŸå®ä¸–ç•Œå¤šå…ƒæ—¶ç©ºæ•°æ®é›†ä¸Šè¿›è¡Œäº†å¹¿æ³›å®éªŒï¼Œç»“æœæ˜¾ç¤ºUQGNNåœ¨é¢„æµ‹å‡†ç¡®ç‡å’Œä¸ç¡®å®šæ€§é‡åŒ–æŒ‡æ ‡ä¸Šå‡ä¸€è‡´ä¼˜äºç°æœ‰çš„åŸºå‡†æ¨¡å‹ã€‚ä¾‹å¦‚åœ¨æ·±åœ³æ•°æ®é›†ä¸Šï¼Œè¯¥æ¨¡å‹å®ç°äº†5%çš„æ€§èƒ½æå‡ï¼Œä¸ºåŸå¸‚è§„åˆ’ã€äº¤é€šä¼˜åŒ–å’Œç¾å®³å“åº”ç­‰ç°å®åº”ç”¨æä¾›äº†æ›´å¯é çš„å†³ç­–æ”¯æŒã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 7 figures, SIGSPATIAL 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.08551v2",
      "published_date": "2025-08-12 01:40:05 UTC",
      "updated_date": "2025-08-31 14:18:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:31.391295+00:00"
    },
    {
      "arxiv_id": "2508.19254v1",
      "title": "Real-Time Intuitive AI Drawing System for Collaboration: Enhancing Human Creativity through Formal and Contextual Intent Integration",
      "title_zh": "é¢å‘åä½œçš„å®æ—¶ç›´è§‰å¼ AI ç»˜ç”»ç³»ç»Ÿï¼šé€šè¿‡å½¢å¼ä¸ä¸Šä¸‹æ–‡æ„å›¾çš„èåˆå¢å¼ºäººç±»åˆ›é€ åŠ›",
      "authors": [
        "Jookyung Song",
        "Mookyoung Kang",
        "Nojun Kwak"
      ],
      "abstract": "This paper presents a real-time generative drawing system that interprets and integrates both formal intent - the structural, compositional, and stylistic attributes of a sketch - and contextual intent - the semantic and thematic meaning inferred from its visual content - into a unified transformation process. Unlike conventional text-prompt-based generative systems, which primarily capture high-level contextual descriptions, our approach simultaneously analyzes ground-level intuitive geometric features such as line trajectories, proportions, and spatial arrangement, and high-level semantic cues extracted via vision-language models. These dual intent signals are jointly conditioned in a multi-stage generation pipeline that combines contour-preserving structural control with style- and content-aware image synthesis. Implemented with a touchscreen-based interface and distributed inference architecture, the system achieves low-latency, two-stage transformation while supporting multi-user collaboration on shared canvases. The resulting platform enables participants, regardless of artistic expertise, to engage in synchronous, co-authored visual creation, redefining human-AI interaction as a process of co-creation and mutual enhancement.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº†ä¸€ä¸ªå®æ—¶ç”Ÿæˆå¼ç»˜å›¾ç³»ç»Ÿï¼Œæ—¨åœ¨é€šè¿‡æ•´åˆå½¢å¼æ„å›¾ (Formal Intent) å’Œä¸Šä¸‹æ–‡æ„å›¾ (Contextual Intent) æ¥å¢å¼ºäººç±»çš„åˆ›é€ åŠ›ã€‚ä¸åŒäºä¼ ç»Ÿçš„æ–‡æœ¬æç¤ºç³»ç»Ÿï¼Œè¯¥ç³»ç»ŸåŒæ—¶åˆ†æè‰å›¾çš„å‡ ä½•ç‰¹å¾ï¼ˆå¦‚çº¿æ¡è½¨è¿¹ã€æ¯”ä¾‹å’Œç©ºé—´å¸ƒå±€ï¼‰ä»¥åŠé€šè¿‡è§†è§‰è¯­è¨€æ¨¡å‹ (Vision-Language Models) æå–çš„é«˜å±‚è¯­ä¹‰çº¿ç´¢ã€‚è¿™äº›åŒé‡æ„å›¾ä¿¡å·åœ¨å¤šé˜¶æ®µç”Ÿæˆæµæ°´çº¿ä¸­è¢«å…±åŒè°ƒèŠ‚ï¼Œå°†è½®å»“ä¿ç•™çš„ç»“æ„æ§åˆ¶ä¸é£æ ¼åŠå†…å®¹æ„ŸçŸ¥å›¾åƒåˆæˆç›¸ç»“åˆã€‚ç³»ç»Ÿé‡‡ç”¨åŸºäºè§¦æ‘¸å±çš„ç•Œé¢å’Œåˆ†å¸ƒå¼æ¨ç†æ¶æ„ (Distributed Inference Architecture)ï¼Œå®ç°äº†ä½å»¶è¿Ÿçš„ä¸¤é˜¶æ®µè½¬æ¢ï¼Œå¹¶æ”¯æŒå…±äº«ç”»å¸ƒä¸Šçš„å¤šç”¨æˆ·åä½œã€‚è¯¥å¹³å°å…è®¸ä¸åŒè‰ºæœ¯æ°´å¹³çš„å‚ä¸è€…è¿›è¡ŒåŒæ­¥åä½œå¼è§†è§‰åˆ›ä½œï¼Œå°†äººæœºäº¤äº’ (Human-AI Interaction) é‡æ–°å®šä¹‰ä¸ºå…±åŒåˆ›é€ å’Œç›¸äº’å¢å¼ºçš„è¿‡ç¨‹ã€‚",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 4 figures, NeurIPS Creative AI Track 2025",
      "pdf_url": "https://arxiv.org/pdf/2508.19254v1",
      "published_date": "2025-08-12 01:34:23 UTC",
      "updated_date": "2025-08-12 01:34:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:18.159323+00:00"
    },
    {
      "arxiv_id": "2508.08545v1",
      "title": "OmniLLP: Enhancing LLM-based Log Level Prediction with Context-Aware Retrieval",
      "title_zh": "OmniLLPï¼šåˆ©ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ£€ç´¢å¢å¼ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„æ—¥å¿—çº§åˆ«é¢„æµ‹",
      "authors": [
        "Youssef Esseddiq Ouatiti",
        "Mohammed Sayagh",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "abstract": "Developers insert logging statements in source code to capture relevant runtime information essential for maintenance and debugging activities. Log level choice is an integral, yet tricky part of the logging activity as it controls log verbosity and therefore influences systems' observability and performance. Recent advances in ML-based log level prediction have leveraged large language models (LLMs) to propose log level predictors (LLPs) that demonstrated promising performance improvements (AUC between 0.64 and 0.8). Nevertheless, current LLM-based LLPs rely on randomly selected in-context examples, overlooking the structure and the diverse logging practices within modern software projects. In this paper, we propose OmniLLP, a novel LLP enhancement framework that clusters source files based on (1) semantic similarity reflecting the code's functional purpose, and (2) developer ownership cohesion. By retrieving in-context learning examples exclusively from these semantic and ownership aware clusters, we aim to provide more coherent prompts to LLPs leveraging LLMs, thereby improving their predictive accuracy. Our results show that both semantic and ownership-aware clusterings statistically significantly improve the accuracy (by up to 8\\% AUC) of the evaluated LLM-based LLPs compared to random predictors (i.e., leveraging randomly selected in-context examples from the whole project). Additionally, our approach that combines the semantic and ownership signal for in-context prediction achieves an impressive 0.88 to 0.96 AUC across our evaluated projects. Our findings highlight the value of integrating software engineering-specific context, such as code semantic and developer ownership signals into LLM-LLPs, offering developers a more accurate, contextually-aware approach to logging and therefore, enhancing system maintainability and observability.",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† OmniLLPï¼Œä¸€ç§æ—¨åœ¨é€šè¿‡ä¸Šä¸‹æ–‡æ„ŸçŸ¥æ£€ç´¢ (Context-Aware Retrieval) å¢å¼ºåŸºäºå¤§è¯­è¨€æ¨¡å‹ (LLM) çš„æ—¥å¿—çº§åˆ«é¢„æµ‹ (Log Level Prediction) çš„æ–°å‹æ¡†æ¶ã€‚é’ˆå¯¹ç°æœ‰æ¨¡å‹åœ¨ä¸Šä¸‹æ–‡å­¦ä¹  (In-context Learning) ä¸­éšæœºé€‰æ‹©ç¤ºä¾‹è€Œå¿½è§†è½¯ä»¶é¡¹ç›®ç»“æ„å’Œå¼€å‘å®è·µçš„é—®é¢˜ï¼ŒOmniLLP å¼•å…¥äº†åŸºäºä»£ç è¯­ä¹‰ç›¸ä¼¼æ€§å’Œå¼€å‘è€…å½’å± (Developer Ownership) å‡èšåŠ›çš„æºç æ–‡ä»¶èšç±»æŠ€æœ¯ã€‚è¯¥æ¡†æ¶é€šè¿‡ä»è¿™äº›è¯­ä¹‰å’Œæ‰€æœ‰æƒæ„ŸçŸ¥çš„èšç±»ä¸­æ£€ç´¢ç‰¹å®šçš„ä¸Šä¸‹æ–‡ç¤ºä¾‹ï¼Œä¸º LLM æä¾›æ›´å…·ä¸€è‡´æ€§çš„æç¤ºè¯ï¼Œä»è€Œæ˜¾è‘—ä¼˜åŒ–äº†é¢„æµ‹ç²¾åº¦ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ–¹æ³•ç›¸æ¯”äºéšæœºé¢„æµ‹å™¨åœ¨ AUC æŒ‡æ ‡ä¸Šæœ€é«˜æå‡äº† 8%ï¼Œåœ¨å¤šä¸ªè¯„ä¼°é¡¹ç›®ä¸­è¾¾åˆ°äº† 0.88 è‡³ 0.96 çš„æé«˜å‡†ç¡®ç‡ã€‚è¯¥ç ”ç©¶æ­ç¤ºäº†å°†è½¯ä»¶å·¥ç¨‹ç‰¹æœ‰çš„ä¸Šä¸‹æ–‡ä¿¡å·æ•´åˆè¿› LLM-LLPs çš„é‡è¦ä»·å€¼ï¼Œèƒ½å¤Ÿä¸ºå¼€å‘è€…æä¾›æ›´å…·è¯­å¢ƒæ„ŸçŸ¥çš„æ—¥å¿—è®°å½•æ–¹æ¡ˆã€‚è¿™é¡¹å·¥ä½œæœ€ç»ˆé€šè¿‡æå‡æ—¥å¿—è®°å½•çš„å‡†ç¡®æ€§ï¼Œæœ‰æ•ˆå¢å¼ºäº†å¤æ‚è½¯ä»¶ç³»ç»Ÿçš„å¯ç»´æŠ¤æ€§å’Œå¯è§‚æµ‹æ€§ã€‚",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08545v1",
      "published_date": "2025-08-12 01:18:56 UTC",
      "updated_date": "2025-08-12 01:18:56 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:35.284081+00:00"
    },
    {
      "arxiv_id": "2508.08544v1",
      "title": "AI Agents and the Law",
      "title_zh": "AI æ™ºèƒ½ä½“ä¸æ³•å¾‹",
      "authors": [
        "Mark O. Riedl",
        "Deven R. Desai"
      ],
      "abstract": "As AI becomes more \"agentic,\" it faces technical and socio-legal issues it must address if it is to fulfill its promise of increased economic productivity and efficiency. This paper uses technical and legal perspectives to explain how things change when AI systems start being able to directly execute tasks on behalf of a user. We show how technical conceptions of agents track some, but not all, socio-legal conceptions of agency. That is, both computer science and the law recognize the problems of under-specification for an agent, and both disciplines have robust conceptions of how to address ensuring an agent does what the programmer, or in the law, the principal desires and no more. However, to date, computer science has under-theorized issues related to questions of loyalty and to third parties that interact with an agent, both of which are central parts of the law of agency. First, we examine the correlations between implied authority in agency law and the principle of value-alignment in AI, wherein AI systems must operate under imperfect objective specification. Second, we reveal gaps in the current computer science view of agents pertaining to the legal concepts of disclosure and loyalty, and how failure to account for them can result in unintended effects in AI ecommerce agents. In surfacing these gaps, we show a path forward for responsible AI agent development and deployment.",
      "tldr_zh": "è¯¥ç ”ç©¶ä»æŠ€æœ¯ä¸æ³•å¾‹çš„åŒé‡ç»´åº¦åˆ†æäº†å½“ AI å˜å¾—æ›´å…·â€œä»£ç†æ€§â€ï¼ˆagenticï¼‰æ—¶æ‰€é¢ä¸´çš„å¤æ‚æŒ‘æˆ˜ã€‚ä½œè€…æŒ‡å‡ºï¼Œè™½ç„¶è®¡ç®—æœºç§‘å­¦ä¸æ³•å¾‹åœ¨åº”å¯¹ä»£ç†ç³»ç»Ÿçš„è§„æ ¼è¯´æ˜ä¸è¶³ï¼ˆunder-specificationï¼‰åŠç¡®ä¿ä»£ç†æ‰§è¡Œå§”æ‰˜äººï¼ˆprincipalï¼‰æ„æ„¿æ–¹é¢å­˜åœ¨å…±è¯†ï¼Œä½†åœ¨å¿ è¯šä¹‰åŠ¡ï¼ˆloyaltyï¼‰å’Œç¬¬ä¸‰æ–¹ï¼ˆthird partiesï¼‰äº¤äº’ç­‰æ ¸å¿ƒæ³•å¾‹æ¦‚å¿µä¸Šï¼Œè®¡ç®—æœºç§‘å­¦çš„ç°æœ‰ç†è®ºä»æ˜¾ä¸è¶³ã€‚è®ºæ–‡æ·±å…¥æ¢è®¨äº†ä»£ç†æ³•ä¸­çš„é»˜ç¤ºæˆæƒï¼ˆimplied authorityï¼‰ä¸ AI ä»·å€¼å¯¹é½ï¼ˆvalue-alignmentï¼‰åŸåˆ™ä¹‹é—´çš„å†…åœ¨è”ç³»ã€‚åŒæ—¶ï¼Œç ”ç©¶æ­ç¤ºäº† AI ç”µå­å•†åŠ¡ä»£ç†åœ¨æŠ«éœ²ï¼ˆdisclosureï¼‰ä¸å¿ è¯šåº¦æ–¹é¢çš„æ³•å¾‹ç¼ºå£åŠå…¶å¯èƒ½å¼•å‘çš„è´Ÿé¢å½±å“ã€‚é€šè¿‡æ¢³ç†è¿™äº›è·¨å­¦ç§‘çš„ç†è®ºé¸¿æ²Ÿï¼Œè¯¥è®ºæ–‡ä¸ºæ„å»ºè´Ÿè´£ä»»çš„ AI Agents åŠå…¶åˆè§„éƒ¨ç½²æä¾›äº†é‡è¦çš„æŒ‡å¯¼è·¯å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "2025 AAAI Conference on AI, Ethics, and Society",
      "pdf_url": "https://arxiv.org/pdf/2508.08544v1",
      "published_date": "2025-08-12 01:18:48 UTC",
      "updated_date": "2025-08-12 01:18:48 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:38.393619+00:00"
    },
    {
      "arxiv_id": "2508.08543v3",
      "title": "M3-Net: A Cost-Effective Graph-Free MLP-Based Model for Traffic Prediction",
      "title_zh": "M3-Netï¼šä¸€ç§é¢å‘äº¤é€šé¢„æµ‹çš„é«˜æ€§ä»·æ¯”æ— å›¾ MLP æ¨¡å‹",
      "authors": [
        "Guangyin Jin",
        "Sicong Lai",
        "Xiaoshuai Hao",
        "Mingtao Zhang",
        "Jinlei Zhang"
      ],
      "abstract": "Achieving accurate traffic prediction is a fundamental but crucial task in the development of current intelligent transportation systems.Most of the mainstream methods that have made breakthroughs in traffic prediction rely on spatio-temporal graph neural networks, spatio-temporal attention mechanisms, etc. The main challenges of the existing deep learning approaches are that they either depend on a complete traffic network structure or require intricate model designs to capture complex spatio-temporal dependencies. These limitations pose significant challenges for the efficient deployment and operation of deep learning models on large-scale datasets. To address these challenges, we propose a cost-effective graph-free Multilayer Perceptron (MLP) based model M3-Net for traffic prediction. Our proposed model not only employs time series and spatio-temporal embeddings for efficient feature processing but also first introduces a novel MLP-Mixer architecture with a mixture of experts (MoE) mechanism. Extensive experiments conducted on multiple real datasets demonstrate the superiority of the proposed model in terms of prediction performance and lightweight deployment.Our code is available at https://github.com/jinguangyin/M3_NET",
      "tldr_zh": "è¯¥ç ”ç©¶æå‡ºäº† M3-Netï¼Œä¸€ç§åŸºäº Multilayer Perceptron (MLP) çš„ä½æˆæœ¬ã€å…å›¾ç»“æ„äº¤é€šé¢„æµ‹æ¨¡å‹ï¼Œæ—¨åœ¨è§£å†³ä¸»æµæ–¹æ³•è¿‡åº¦ä¾èµ–å®Œæ•´è·¯ç½‘ç»“æ„æˆ–å¤æ‚æ—¶ç©ºä¾èµ–å»ºæ¨¡æ‰€å¯¼è‡´çš„éƒ¨ç½²éš¾é¢˜ã€‚è¯¥æ¨¡å‹åˆ©ç”¨æ—¶é—´åºåˆ—å’Œ spatio-temporal embeddings è¿›è¡Œé«˜æ•ˆç‰¹å¾å¤„ç†ï¼Œå¹¶é¦–æ¬¡å¼•å…¥äº†ç»“åˆ Mixture of Experts (MoE) æœºåˆ¶çš„ MLP-Mixer æ¶æ„ä»¥æ•æ‰å¤æ‚çš„äº¤é€šè§„å¾‹ã€‚åœ¨å¤šä¸ªçœŸå®æ•°æ®é›†ä¸Šçš„å®éªŒç»“æœè¡¨æ˜ï¼ŒM3-Net åœ¨é¢„æµ‹æ€§èƒ½å’Œè½»é‡åŒ–éƒ¨ç½² (lightweight deployment) æ–¹é¢å‡è¡¨ç°å‡ºæ˜¾è‘—çš„ä¼˜è¶Šæ€§ã€‚è¿™ä¸€æˆæœä¸ºå¤§è§„æ¨¡æ™ºèƒ½äº¤é€šç³»ç»Ÿåœ¨æœ‰é™è®¡ç®—èµ„æºä¸‹çš„é«˜æ•ˆè¿è¡Œæä¾›äº†åˆ‡å®å¯è¡Œçš„æŠ€æœ¯æ–¹æ¡ˆã€‚",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.08543v3",
      "published_date": "2025-08-12 01:11:46 UTC",
      "updated_date": "2025-11-12 04:18:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:39.890423+00:00"
    },
    {
      "arxiv_id": "2508.08535v2",
      "title": "LLM-Driven Adaptive 6G-Ready Wireless Body Area Networks: Survey and Framework",
      "title_zh": "å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„é¢å‘6Gè‡ªé€‚åº”æ— çº¿ä½“åŸŸç½‘ï¼šç»¼è¿°ä¸æ¡†æ¶",
      "authors": [
        "Mohammad Jalili Torkamani",
        "Negin Mahmoudi",
        "Kiana Kiashemshaki"
      ],
      "abstract": "Wireless Body Area Networks (WBANs) enable continuous monitoring of physiological signals for applications ranging from chronic disease management to emergency response. Recent advances in 6G communications, post-quantum cryptography, and energy harvesting have the potential to enhance WBAN performance. However, integrating these technologies into a unified, adaptive system remains a challenge. This paper surveys some of the most well-known Wireless Body Area Network (WBAN) architectures, routing strategies, and security mechanisms, identifying key gaps in adaptability, energy efficiency, and quantum-resistant security. We propose a novel Large Language Model-driven adaptive WBAN framework in which a Large Language Model acts as a cognitive control plane, coordinating routing, physical layer selection, micro-energy harvesting, and post-quantum security in real time. Our review highlights the limitations of current heuristic-based designs and outlines a research agenda for resource-constrained, 6G-ready medical systems. This approach aims to enable ultra-reliable, secure, and self-optimizing WBANs for next-generation mobile health applications.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†æ— çº¿ä½“åŸŸç½‘(Wireless Body Area Networks, WBANs)åœ¨ç”Ÿç†ä¿¡å·æŒç»­ç›‘æµ‹ä¸­çš„åº”ç”¨ï¼Œå¹¶é’ˆå¯¹å…¶åœ¨æ•´åˆ6Gé€šä¿¡ã€åé‡å­å¯†ç å­¦(post-quantum cryptography)å’Œèƒ½é‡é‡‡é›†(energy harvesting)æŠ€æœ¯æ—¶é¢ä¸´çš„é€‚åº”æ€§ä¸èƒ½æ•ˆæŒ‘æˆ˜è¿›è¡Œäº†æ·±å…¥åˆ†æã€‚è®ºæ–‡é¦–å…ˆå¯¹ç°æœ‰çš„WBANæ¶æ„ã€è·¯ç”±ç­–ç•¥åŠå®‰å…¨æœºåˆ¶è¿›è¡Œäº†å…¨é¢ç»¼è¿°ï¼Œè¯†åˆ«å‡ºå½“å‰åŸºäºå¯å‘å¼è®¾è®¡çš„ç³»ç»Ÿåœ¨èµ„æºå—é™ç¯å¢ƒä¸‹çš„å±€é™æ€§ã€‚ä¸ºæ­¤ï¼Œä½œè€…æå‡ºäº†ä¸€ç§åˆ›æ–°çš„å¤§è¯­è¨€æ¨¡å‹é©±åŠ¨(Large Language Model-driven)çš„è‡ªé€‚åº”WBANæ¡†æ¶ï¼Œå°†å¤§è¯­è¨€æ¨¡å‹(LLM)ä½œä¸ºè®¤çŸ¥æ§åˆ¶å¹³é¢ï¼Œå®ç°å¯¹ç‰©ç†å±‚é€‰æ‹©ã€è·¯ç”±åè®®å’Œå¾®èƒ½é‡é‡‡é›†çš„å®æ—¶åè°ƒã€‚è¯¥æ¡†æ¶é€šè¿‡æ•´åˆåé‡å­å®‰å…¨æŠ€æœ¯ï¼Œæ—¨åœ¨æ„å»ºä¸€ä¸ªè¶…å¯é ã€å®‰å…¨ä¸”å…·å¤‡è‡ªä¼˜åŒ–èƒ½åŠ›çš„6Gå°±ç»ªå‹åŒ»ç–—ç³»ç»Ÿã€‚è¿™é¡¹ç ”ç©¶ä¸ºä¸‹ä¸€ä»£ç§»åŠ¨å¥åº·åº”ç”¨æä¾›äº†æ–°çš„æ¶æ„æ€è·¯ï¼Œå¹¶æ˜ç¡®äº†æœªæ¥6Gç½‘ç»œç¯å¢ƒä¸‹é«˜æ€§èƒ½WBANçš„ç ”ç©¶è®®ç¨‹ã€‚",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "7 pages",
      "pdf_url": "https://arxiv.org/pdf/2508.08535v2",
      "published_date": "2025-08-12 00:25:41 UTC",
      "updated_date": "2025-08-14 02:38:22 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:40.785355+00:00"
    },
    {
      "arxiv_id": "2508.09224v1",
      "title": "From Hard Refusals to Safe-Completions: Toward Output-Centric Safety Training",
      "title_zh": "ä»å¼ºç¡¬æ‹’ç»åˆ°å®‰å…¨è¡¥å…¨ï¼šè¿ˆå‘ä»¥è¾“å‡ºä¸ºä¸­å¿ƒçš„å®‰å…¨è®­ç»ƒ",
      "authors": [
        "Yuan Yuan",
        "Tina Sriskandarajah",
        "Anna-Luisa Brakman",
        "Alec Helyar",
        "Alex Beutel",
        "Andrea Vallone",
        "Saachi Jain"
      ],
      "abstract": "Large Language Models used in ChatGPT have traditionally been trained to learn a refusal boundary: depending on the user's intent, the model is taught to either fully comply or outright refuse. While this is a strong mitigation for explicitly malicious prompts, focusing safety training on refusals can lead to brittleness for prompts with obscured user intent. Binary refusal boundaries are especially ill-suited for dual-use cases (such as biology or cybersecurity), where a user request can be answered safely at a high level, but in some cases can lead to malicious uplift if sufficiently detailed or actionable. As an alternative, we propose safe-completions: a safety-training approach that centers on the safety of the assistant's output, rather than a binary classification of the user's intent. Safe-completions seek to maximize helpfulness within the safety policy's constraints. We incorporated this approach into GPT-5 and find that across both production comparisons and internally controlled experiments, safe-completion training improves safety (especially on dual-use prompts), reduces the severity of residual safety failures, and substantially increases model helpfulness.",
      "tldr_zh": "è¯¥ç ”ç©¶é’ˆå¯¹ä¼ ç»Ÿå¤§è¯­è¨€æ¨¡å‹åœ¨å¤„ç†åŒé‡ç”¨é€”(dual-use)åœºæ™¯åŠæ¨¡ç³Šæ„å›¾æ—¶æ‹’ç»è¾¹ç•Œ(refusal boundary)è¿‡äºæ­»æ¿çš„é—®é¢˜ï¼Œæå‡ºäº†ä¸€ç§åä¸ºå®‰å…¨è¡¥å…¨(safe-completions)çš„è¾“å‡ºä¸­å¿ƒåŒ–å®‰å…¨è®­ç»ƒæ–¹æ³•ã€‚è¯¥æ–¹æ³•å°†è®­ç»ƒé‡ç‚¹ä»å¯¹ç”¨æˆ·æ„å›¾çš„äºŒå…ƒåˆ†ç±»è½¬å‘å¯¹åŠ©æ‰‹è¾“å‡ºå†…å®¹çš„å®‰å…¨æ€§è¯„ä¼°ï¼Œæ—¨åœ¨å®‰å…¨ç­–ç•¥çº¦æŸä¸‹æœ€å¤§åŒ–æ¨¡å‹çš„å¸®åŠ©æ€§(helpfulness)ã€‚é€šè¿‡åœ¨ GPT-5 ä¸Šçš„é›†æˆä¸å®éªŒéªŒè¯ï¼Œç»“æœæ˜¾ç¤ºå®‰å…¨è¡¥å…¨(safe-completions)åœ¨æå‡å®‰å…¨æ€§ï¼ˆå°¤å…¶æ˜¯åœ¨ç”Ÿç‰©ã€ç½‘ç»œå®‰å…¨ç­‰æ•æ„Ÿé¢†åŸŸï¼‰çš„åŒæ—¶ï¼Œæ˜¾è‘—å‡å°‘äº†æ®‹ç•™å®‰å…¨æ•…éšœçš„ä¸¥é‡ç¨‹åº¦ã€‚æ­¤å¤–ï¼Œè¯¥è®­ç»ƒæ–¹å¼æœ‰æ•ˆè§£å†³äº†è¿‡åº¦æ‹’ç»çš„é—®é¢˜ï¼Œå¤§å¹…å¢å¼ºäº†æ¨¡å‹çš„å®ç”¨æ€§ï¼Œä¸ºæ„å»ºæ—¢å®‰å…¨åˆé«˜æ•ˆçš„äººå·¥æ™ºèƒ½ç³»ç»Ÿæä¾›äº†æ–°çš„æŠ€æœ¯è·¯å¾„ã€‚",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "https://arxiv.org/pdf/2508.09224v1",
      "published_date": "2025-08-12 00:18:23 UTC",
      "updated_date": "2025-08-12 00:18:23 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:28:01.995968+00:00"
    },
    {
      "arxiv_id": "2508.10043v1",
      "title": "Securing Agentic AI: Threat Modeling and Risk Analysis for Network Monitoring Agentic AI System",
      "title_zh": "ä¿éšœæ™ºèƒ½ä½“ AI å®‰å…¨ï¼šç½‘ç»œç›‘æ§æ™ºèƒ½ä½“ AI ç³»ç»Ÿçš„å¨èƒå»ºæ¨¡ä¸é£é™©åˆ†æ",
      "authors": [
        "Pallavi Zambare",
        "Venkata Nikhil Thanikella",
        "Ying Liu"
      ],
      "abstract": "When combining Large Language Models (LLMs) with autonomous agents, used in network monitoring and decision-making systems, this will create serious security issues. In this research, the MAESTRO framework consisting of the seven layers threat modeling architecture in the system was used to expose, evaluate, and eliminate vulnerabilities of agentic AI. The prototype agent system was constructed and implemented, using Python, LangChain, and telemetry in WebSockets, and deployed with inference, memory, parameter tuning, and anomaly detection modules. Two practical threat cases were confirmed as follows: (i) resource denial of service by traffic replay denial-of-service, and (ii) memory poisoning by tampering with the historical log file maintained by the agent. These situations resulted in measurable levels of performance degradation, i.e. telemetry updates were delayed, and computational loads were increased, as a result of poor system adaptations. It was suggested to use a multilayered defense-in-depth approach with memory isolation, validation of planners and anomaly response systems in real-time. These findings verify that MAESTRO is viable in operational threat mapping, prospective risk scoring, and the basis of the resilient system design. The authors bring attention to the importance of the enforcement of memory integrity, paying attention to the adaptation logic monitoring, and cross-layer communication protection that guarantee the agentic AI reliability in adversarial settings.",
      "tldr_zh": "è¯¥ç ”ç©¶æ¢è®¨äº†åœ¨å¤§è¯­è¨€æ¨¡å‹(Large Language Models)ä¸è‡ªä¸»æ™ºèƒ½ä½“(autonomous agents)ç»“åˆç”¨äºç½‘ç»œç›‘æ§å’Œå†³ç­–ç³»ç»Ÿæ—¶äº§ç”Ÿçš„ä¸¥é‡å®‰å…¨é—®é¢˜ã€‚ç ”ç©¶é‡‡ç”¨äº†MAESTROæ¡†æ¶ï¼Œé€šè¿‡ä¸ƒå±‚å¨èƒå»ºæ¨¡(threat modeling)æ¶æ„æ¥æš´éœ²ã€è¯„ä¼°å¹¶æ¶ˆé™¤æ™ºèƒ½ä½“AI(agentic AI)çš„æ¼æ´ã€‚ä½œè€…åˆ©ç”¨Pythonã€LangChainå’ŒWebSocketsæŠ€æœ¯æ„å»ºäº†åŒ…å«æ¨ç†ã€è®°å¿†ã€å‚æ•°è°ƒä¼˜å’Œå¼‚å¸¸æ£€æµ‹æ¨¡å—çš„åŸå‹ç³»ç»Ÿã€‚å®éªŒè¯å®äº†ä¸¤ç§å…³é”®å¨èƒï¼Œå³é€šè¿‡æµé‡é‡æ”¾å¯¼è‡´çš„èµ„æºæ‹’ç»æœåŠ¡(resource denial of service)ä»¥åŠé€šè¿‡ç¯¡æ”¹å†å²æ—¥å¿—å®æ–½çš„è®°å¿†æ±¡æŸ“(memory poisoning)ï¼Œè¿™äº›å¨èƒå‡å¯¼è‡´äº†æ˜¾è‘—çš„æ€§èƒ½ä¸‹é™å’Œè®¡ç®—è´Ÿè½½å¢åŠ ã€‚ç ”ç©¶å»ºè®®é‡‡ç”¨å¤šå±‚æ·±åº¦é˜²å¾¡(multilayered defense-in-depth)ç­–ç•¥ï¼ŒåŒ…æ‹¬è®°å¿†éš”ç¦»(memory isolation)ã€è§„åˆ’å™¨éªŒè¯å’Œå®æ—¶å¼‚å¸¸å“åº”ç³»ç»Ÿã€‚è¿™äº›å‘ç°éªŒè¯äº†MAESTROåœ¨å¨èƒæ˜ å°„å’ŒéŸ§æ€§ç³»ç»Ÿè®¾è®¡ä¸­çš„å¯è¡Œæ€§ï¼Œå¼ºè°ƒäº†è®°å¿†å®Œæ•´æ€§ã€é€‚é…é€»è¾‘ç›‘æ§å’Œè·¨å±‚é€šä¿¡ä¿æŠ¤å¯¹ç¡®ä¿æ™ºèƒ½ä½“AIå¯é æ€§çš„é‡è¦æ€§ã€‚",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted and under review in IEEE Transactions on Privacy",
      "pdf_url": "https://arxiv.org/pdf/2508.10043v1",
      "published_date": "2025-08-12 00:14:12 UTC",
      "updated_date": "2025-08-12 00:14:12 UTC",
      "processing_status": "completed",
      "attempts": 1,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "llm_backup_calls": 0,
      "last_update": "2026-01-24T11:27:58.095758+00:00"
    }
  ],
  "processing_status": "completed",
  "error": null,
  "raw_papers_fetched": true,
  "papers_count": 170,
  "processed_papers_count": 170,
  "failed_papers_count": 0,
  "llm_backup_calls": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2026-01-24T11:29:04.015578+00:00"
}