{
  "date": "2025-02-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-02-14 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 123 篇论文，主要聚焦于 AI 模型优化（如 LLM 代理和多模态生成）、强化学习应用（如机器人导航）和图像处理创新，亮点包括高效 LLM 框架（如 MEADOW）和多模态基准测试（如 MIR-Bench），以及 Google DeepMind 等机构的相关工作，这些论文突显了 LLM 在实际应用中的潜力。\n\n下面，我将挑选并讨论部分重要、令人印象深刻的论文，先从 LLM 和多模态主题入手（这些有话题度和实际影响），再简要聊聊强化学习和机器人相关内容，最后快速掠过其他次要论文。每个条目列出论文标题（中文 + 英文），并聚焦核心贡献。\n\n### LLM 和多模态模型：高效框架与基准测试\n- **MEADOW: Memory-efficient Dataflow and Data Packing for Low Power Edge LLMs（MEADOW: 适用于低功耗边缘 LLM 的内存高效数据流和数据打包）**  \n  这篇论文提出 MEADOW 框架，通过新型 token-parallel 数据流和权重打包技术，显著降低边缘设备（如 FPGA）的 LLM 推理延迟，实现 1.5 倍解码和 2.5 倍预填充加速，主要贡献在于解决内存瓶颈，提升边缘 AI 部署效率。\n\n- **Post-training an LLM for RAG? Train on Self-Generated Demonstrations（针对 RAG 的 LLM 后训练：使用自生成演示进行训练）**  \n  作者探索了通过自生成演示训练 LLM 以提升检索增强生成（RAG）的性能，避免了传统数据分布问题；主要发现是，该方法在知识密集型任务中改善了模型鲁棒性，同时减少了幻觉问题。\n\n- **Granite Vision: a lightweight, open-source multimodal model for enterprise Intelligence（Granite Vision: 一种轻量级开源多模态模型，用于企业智能）**  \n  这篇由 IBM 团队的作品引入轻量级多模态模型 Granite Vision，能处理文档理解任务；关键贡献是结合视觉和文本特征，实现高效的企业应用，同时引入安全分类机制以减少有害输入。\n\n- **MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?（MIR-Bench: 您的 LLM 能否通过多样本上下文推理识别复杂模式？）**  \n  论文构建了新基准 MIR-Bench 测试 LLM 在多样本推理中的性能；主要发现是，LLM 在长上下文任务中表现出可扩展性，但存在鲁棒性和泛化挑战，这为 LLM 评估提供了新工具。\n\n- **HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation（HealthGPT: 一种用于统一理解和生成的医疗大视觉语言模型，通过异构知识适应）**  \n  作者开发了 HealthGPT 模型，通过异构低秩适应融合医疗视觉和文本知识；主要贡献是提升了医疗图像任务的性能，并展示了其在跨模态任务中的可扩展性。\n\n- **Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos（Video2Policy: 通过互联网视频在模拟环境中扩展操作任务）**  \n  这篇论文使用视频重建任务的强化学习框架 Video2Policy；核心发现是，它能从网络视频中高效生成模拟数据，提升机器人策略训练效率。\n\n### 强化学习和机器人应用：导航与效率提升\n- **BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds（BeamDojo: 在稀疏支点上学习敏捷人形机器人运动）**  \n  论文提出 BeamDojo 框架，使用强化学习在稀疏环境中训练机器人；主要贡献是提高足部放置精度和鲁棒性，实验显示在真实机器人上成功率提升 31%。\n\n- **MuDoC: An Interactive Multimodal Document-grounded Conversational AI System（MuDoC: 一种交互式多模态文档基础对话 AI 系统）**  \n  作者构建了 MuDoC 系统，支持基于文档的视觉对话；关键发现是，它提升了 AI 在医疗和教育领域的交互可靠性，同时促进了响应可验证性。\n\n其他论文多为次要主题，如特定领域优化或理论分析，我将快速掠过：\n- **Lorecast: Layout-Aware Performance and Power Forecasting from Natural Language（Lorecast: 从自然语言中进行布局感知性能和功耗预测）**  \n  这篇工作开发了 Lorecast 方法，用于芯片设计预测；主要贡献是快速生成准确的性能估计，减少了传统合成的劳动强度。\n- **Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression（在深度异方差回归中实现自监督协方差估计）**  \n  论文提出自监督方法估计协方差；核心发现是提高了回归任务的准确性和计算效率。\n- 其余如 **Do We Need to Verify Step by Step? Rethinking Process Supervision from a Theoretical Perspective（我们需要逐步验证吗？从理论视角重新审视过程监督）** 等理论论文，聚焦强化学习监督，但影响较小，仅提供统计框架改进。\n\n总之，今天的论文强调了 AI 模型的效率和实际应用潜力，LLM 相关工作尤为突出，建议读者关注 MEADOW 和 MIR-Bench 等创新框架，以推动高效 AI 部署。更多细节可查阅 arXiv。明天见！",
  "papers": [
    {
      "arxiv_id": "2503.11663v1",
      "title": "MEADOW: Memory-efficient Dataflow and Data Packing for Low Power Edge LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Abhishek Moitra",
        "Arkapravo Ghosh",
        "Shrey Agarwal",
        "Aporva Amarnath",
        "Karthik Swaminathan",
        "Priyadarshini Panda"
      ],
      "abstract": "The computational and memory challenges of large language models (LLMs) have\nsparked several optimization approaches towards their efficient implementation.\nWhile prior LLM-targeted quantization, and prior works on sparse acceleration\nhave significantly mitigated the memory and computation bottleneck, they do so\nassuming high power platforms such as GPUs and server-class FPGAs with large\noff-chip memory bandwidths and employ a generalized matrix multiplication\n(GEMM) execution of all the layers in the decoder. In such a GEMM-based\nexecution, data is fetched from an off-chip memory, computed and stored back.\nHowever, at reduced off-chip memory capacities, as is the case with low-power\nedge devices, this implementation strategy significantly increases the\nattention computation latency owing to the repeated storage and fetch of large\nintermediate tokens to and from the off-chip memory. Moreover, fetching the\nweight matrices from a bandwidth constrained memory further aggravates the\nmemory bottleneck problem. To this end, we introduce MEADOW, a framework that\nsignificantly reduces the off-chip memory access for LLMs with a novel\ntoken-parallel head-sequential (TPHS) dataflow. Additionally, MEADOW applies\nweight packing that performs loss-less decomposition of large weight matrices\nto their unique elements thereby, reducing the enormous weight fetch latency.\nMEADOW demonstrates 1.5x and 2.5x lower decode and prefill latency,\nrespectively, compared to a GEMM-based LLM implementation on the low power\nXilinx ZCU102 FPGA platform that consumes less than 10W. Additionally, MEADOW\nachieves an end-to-end latency improvement of over 40%, compared to prior LLM\noptimization works.",
      "tldr_zh": "该论文针对大型语言模型 (LLMs) 在低功率边缘设备上的内存和计算瓶颈问题，引入 MEADOW 框架，该框架采用新型 token-parallel head-sequential (TPHS) 数据流和 weight packing 技术，以减少 off-chip 内存访问和权重矩阵获取延迟。相比传统的 GEMM 执行方式，MEADOW 在 Xilinx ZCU102 FPGA 平台上实现了 1.5 倍解码延迟和 2.5 倍预填充延迟的降低，并将端到端延迟改善超过 40%。这项工作为高效、低功耗的边缘 LLM 部署提供了关键优化策略。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "12 pages, 13 figures. Accepted to The Eighth Annual Conference on\n  Machine Learning and Systems (MLSys), 2025",
      "pdf_url": "http://arxiv.org/pdf/2503.11663v1",
      "published_date": "2025-02-14 23:50:37 UTC",
      "updated_date": "2025-02-14 23:50:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:19:18.371480"
    },
    {
      "arxiv_id": "2503.11662v2",
      "title": "Lorecast: Layout-Aware Performance and Power Forecasting from Natural Language",
      "title_zh": "翻译失败",
      "authors": [
        "Runzhi Wang",
        "Prianka Sengupta",
        "Cristhian Roman-Vicharra",
        "Yiran Chen",
        "Jiang Hu"
      ],
      "abstract": "In chip design planning, obtaining reliable performance and power forecasts\nfor various design options is of critical importance. Traditionally, this\ninvolves using system-level models, which often lack accuracy, or trial\nsynthesis, which is both labor-intensive and time-consuming. We introduce a new\nmethodology, called Lorecast, which accepts English prompts as input to rapidly\ngenerate layout-aware performance and power estimates. This approach bypasses\nthe need for HDL code development and synthesis, making it both fast and\nuser-friendly. Experimental results demonstrate that Lorecast achieves accuracy\nwithin a few percent of error compared to post-layout analysis, while\nsignificantly reducing turnaround time.",
      "tldr_zh": "在芯片设计规划中，传统方法如系统级模型往往不准确，或需进行耗时费力的试产合成，本文提出Lorecast，一种基于自然语言（英语提示）输入的创新方法，能够快速生成布局感知的性能和功率估计。Lorecast 绕过HDL代码开发和合成过程，使预测过程更快捷且用户友好。实验结果表明，该方法与后布局分析相比，误差仅几个百分点，同时显著减少了周转时间。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.11662v2",
      "published_date": "2025-02-14 23:08:39 UTC",
      "updated_date": "2025-04-22 19:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:19:29.212977"
    },
    {
      "arxiv_id": "2502.10596v2",
      "title": "Post-training an LLM for RAG? Train on Self-Generated Demonstrations",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Finlayson",
        "Ilia Kulikov",
        "Daniel M. Bikel",
        "Barlas Oguz",
        "Xilun Chen",
        "Aasish Pappu"
      ],
      "abstract": "Large language models (LLMs) often struggle with knowledge intensive NLP\ntasks, such as answering \"Who won the latest World Cup?\" because the knowledge\nthey learn during training may be insufficient or outdated. Conditioning\ngeneration on retrieved documents -- a technique known as retrieval augmented\ngeneration (RAG) -- mitigates these shortcomings by allowing the model to\nleverage in-context information. Practitioners can improve LLM RAG performance\nby fine-tuning on retrieval-augmented instructions, but must beware that this\ncan cause undesirable model behaviors like hallucinations. We attribute this\ndegradation to the fact that the training data is likely to be\nout-of-distribution for the model and may suffer from quality issues, such as\nmisalignment between retrievals and target responses (since retrievals are\nfrequently added post-hoc). We propose a recipe for training RAG-enabled LLMs\nusing self-generated demonstrations, thereby avoiding training on\nout-of-distribution text and integrating retrievals into the LLM responses. We\nevaluate our method on knowledge intensive question answering (QA) tasks and\nshow that our method teaches LLMs to properly handle in-context retrievals and\nabstain from questions it will likely get wrong. Compared to conventional RA-IT\nmethods, our method prevents model degradation in non-RAG settings while\nexhibiting superior QA performance.",
      "tldr_zh": "该研究探讨了大型语言模型(LLMs)在知识密集型任务（如问答QA）上的局限性，例如知识过时或不足，并指出传统检索增强生成(RAG)微调可能导致幻觉等问题，因为训练数据往往分布外或质量低下。论文提出一种新方法：使用自生成演示(Self-Generated Demonstrations)来训练RAG-enabled LLMs，从而避免分布外数据并将检索无缝整合到模型响应中。该方法教导LLMs正确处理上下文检索、避免可能错误的回答，并在QA任务上表现出色，与传统RA-IT方法相比，不仅在非RAG设置中防止模型退化，还实现了更高的性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10596v2",
      "published_date": "2025-02-14 23:00:49 UTC",
      "updated_date": "2025-03-01 06:33:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:19:41.408290"
    },
    {
      "arxiv_id": "2502.10587v1",
      "title": "Towards Self-Supervised Covariance Estimation in Deep Heteroscedastic Regression",
      "title_zh": "朝向深度异方差回归中的自监督协方差估计",
      "authors": [
        "Megh Shukla",
        "Aziz Shameem",
        "Mathieu Salzmann",
        "Alexandre Alahi"
      ],
      "abstract": "Deep heteroscedastic regression models the mean and covariance of the target\ndistribution through neural networks. The challenge arises from\nheteroscedasticity, which implies that the covariance is sample dependent and\nis often unknown. Consequently, recent methods learn the covariance through\nunsupervised frameworks, which unfortunately yield a trade-off between\ncomputational complexity and accuracy. While this trade-off could be alleviated\nthrough supervision, obtaining labels for the covariance is non-trivial. Here,\nwe study self-supervised covariance estimation in deep heteroscedastic\nregression. We address two questions: (1) How should we supervise the\ncovariance assuming ground truth is available? (2) How can we obtain pseudo\nlabels in the absence of the ground-truth? We address (1) by analysing two\npopular measures: the KL Divergence and the 2-Wasserstein distance.\nSubsequently, we derive an upper bound on the 2-Wasserstein distance between\nnormal distributions with non-commutative covariances that is stable to\noptimize. We address (2) through a simple neighborhood based heuristic\nalgorithm which results in surprisingly effective pseudo labels for the\ncovariance. Our experiments over a wide range of synthetic and real datasets\ndemonstrate that the proposed 2-Wasserstein bound coupled with pseudo label\nannotations results in a computationally cheaper yet accurate deep\nheteroscedastic regression.",
      "tldr_zh": "该研究探讨了深度异方差回归（deep heteroscedastic regression）中自监督协方差估计（self-supervised covariance estimation），旨在解决协方差样本依赖且未知的问题，从而平衡计算复杂性和准确性。作者分析了两种监督措施——KL Divergence 和 2-Wasserstein distance，并推导了针对非交换协方差的 2-Wasserstein distance 上界，以实现稳定的优化；同时，提出一个基于邻域的启发式算法生成伪标签。实验在多种合成和真实数据集上表明，该方法显著降低了计算成本，同时保持了高准确性，为高效的异方差回归模型提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10587v1",
      "published_date": "2025-02-14 22:37:11 UTC",
      "updated_date": "2025-02-14 22:37:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:19:54.116580"
    },
    {
      "arxiv_id": "2502.10581v2",
      "title": "Do We Need to Verify Step by Step? Rethinking Process Supervision from a Theoretical Perspective",
      "title_zh": "我们需要逐步验证吗？从理论视角重新审视过程监督",
      "authors": [
        "Zeyu Jia",
        "Alexander Rakhlin",
        "Tengyang Xie"
      ],
      "abstract": "As large language models have evolved, it has become crucial to distinguish\nbetween process supervision and outcome supervision -- two key reinforcement\nlearning approaches to complex reasoning tasks. While process supervision\noffers intuitive advantages for long-term credit assignment, the precise\nrelationship between these paradigms has remained an open question.\nConventional wisdom suggests that outcome supervision is fundamentally more\nchallenging due to the trajectory-level coverage problem, leading to\nsignificant investment in collecting fine-grained process supervision data.\n  In this paper, we take steps towards resolving this debate. Our main theorem\nshows that, under standard data coverage assumptions, reinforcement learning\nthrough outcome supervision is no more statistically difficult than through\nprocess supervision, up to polynomial factors in horizon. At the core of this\nresult lies the novel Change of Trajectory Measure Lemma -- a technical tool\nthat bridges return-based trajectory measure and step-level distribution shift.\nFurthermore, for settings with access to a verifier or a rollout capability, we\nprove that any policy's advantage function can serve as an optimal process\nreward model, providing a direct connection between outcome and process\nsupervision. These findings suggest that the empirically observed performance\ngap -- if any -- between outcome and process supervision likely stems from\nalgorithmic limitations rather than inherent statistical difficulties,\npotentially transforming how we approach data collection and algorithm design\nfor reinforcement learning.",
      "tldr_zh": "这篇论文从理论角度重新审视了强化学习中过程监督（process supervision）和结果监督（outcome supervision）的差异，挑战了传统观点，即结果监督因轨迹级覆盖问题而更难。论文的主要贡献包括一个关键定理：在标准数据覆盖假设下，结果监督的统计难度不高于过程监督，仅涉及地平线（horizon）的多项式因素，并引入了Change of Trajectory Measure Lemma作为连接回报-based轨迹测量和步级分布偏移的技术工具。此外，论文证明了在有验证器或回放能力的情况下，任何策略的优势函数（advantage function）可作为最佳过程奖励模型，表明经验性能差距可能源于算法限制而非固有统计挑战，从而为强化学习的数据收集和算法设计提供新见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10581v2",
      "published_date": "2025-02-14 22:21:56 UTC",
      "updated_date": "2025-03-26 22:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:20:05.425023"
    },
    {
      "arxiv_id": "2502.10577v1",
      "title": "Man Made Language Models? Evaluating LLMs' Perpetuation of Masculine Generics Bias",
      "title_zh": "翻译失败",
      "authors": [
        "Enzo Doyen",
        "Amalia Todirascu"
      ],
      "abstract": "Large language models (LLMs) have been shown to propagate and even amplify\ngender bias, in English and other languages, in specific or constrained\ncontexts. However, no studies so far have focused on gender biases conveyed by\nLLMs' responses to generic instructions, especially with regard to masculine\ngenerics (MG). MG are a linguistic feature found in many gender-marked\nlanguages, denoting the use of the masculine gender as a \"default\" or\nsupposedly neutral gender to refer to mixed group of men and women, or of a\nperson whose gender is irrelevant or unknown. Numerous psycholinguistics\nstudies have shown that MG are not neutral and induce gender bias. This work\naims to analyze the use of MG by both proprietary and local LLMs in responses\nto generic instructions and evaluate their MG bias rate. We focus on French and\ncreate a human noun database from existing lexical resources. We filter\nexisting French instruction datasets to retrieve generic instructions and\nanalyze the responses of 6 different LLMs. Overall, we find that\n$\\approx$39.5\\% of LLMs' responses to generic instructions are MG-biased\n($\\approx$73.1\\% across responses with human nouns). Our findings also reveal\nthat LLMs are reluctant to using gender-fair language spontaneously.",
      "tldr_zh": "该研究评估大型语言模型 (LLMs) 在响应泛化指令时是否延续 Masculine Generics (MG) 偏见，即使用男性形式作为默认中性表达，从而传播性别偏见。研究聚焦于法语，构建了一个人类名词数据库，从现有指令数据集筛选泛化指令，并分析了 6 个不同 LLMs 的响应。结果显示，约 39.5% 的 LLMs 响应存在 MG 偏见，在包含人类名词的响应中这一比例高达 73.1%，并揭示 LLMs 不愿意主动采用性别公平语言。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "21 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10577v1",
      "published_date": "2025-02-14 22:05:54 UTC",
      "updated_date": "2025-02-14 22:05:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:20:17.824713"
    },
    {
      "arxiv_id": "2502.10573v1",
      "title": "An Innovative Next Activity Prediction Approach Using Process Entropy and DAW-Transformer",
      "title_zh": "一种创新的下一活动预测方法，使用过程熵和 DAW-Transformer",
      "authors": [
        "Hadi Zare",
        "Mostafa Abbasi",
        "Maryam Ahang",
        "Homayoun Najjaran"
      ],
      "abstract": "Purpose - In Business Process Management (BPM), accurate prediction of the\nnext activities is vital for operational efficiency and decision-making.\nCurrent Artificial Intelligence (AI)/Machine Learning (ML) models struggle with\nthe complexity and evolving nature of business process event logs, balancing\naccuracy and interpretability. This paper proposes an entropy-driven model\nselection approach and DAW-Transformer, which stands for Dynamic\nAttribute-Aware Transformer, to integrate all attributes with a dynamic window\nfor better accuracy.\n  Design/methodology/approach - This paper introduces a novel next-activity\nprediction approach that uses process entropy to assess the complexity of event\nlogs and dynamically select the most suitable ML model. A new transformer-based\narchitecture with multi-head attention and dynamic windowing mechanism,\nDAW-Transformer, is proposed to capture long-range dependencies and utilize all\nrelevant event log attributes. Experiments were conducted on six public\ndatasets, and the performance was evaluated with process entropy.\n  Finding - The results demonstrate the effectiveness of the approach across\nthese publicly available datasets. DAW-Transformer achieved superior\nperformance, especially on high-entropy datasets such as Sepsis exceeding\nLimited window Multi-Transformers by 4.69% and a benchmark CNN-LSTM-SAtt model\nby 3.07%. For low-entropy datasets like Road Traffic Fine, simpler, more\ninterpretable algorithms like Random Forest performed nearly as well as the\nmore complex DAW-Transformer and offered better handling of imbalanced data and\nimproved explainability.\n  Originality/ value - This work's novelty lies in the proposed\nDAW-Transformer, with a dynamic window and considering all relevant attributes.\nAlso, entropy-driven selection methods offer a robust, accurate, and\ninterpretable solution for next-activity prediction.",
      "tldr_zh": "本研究针对商业流程管理(BPM)中的下一活动预测问题，提出了一种创新方法，利用Process Entropy评估事件日志的复杂性，并动态选择最合适的机器学习(ML)模型。该方法引入DAW-Transformer（Dynamic Attribute-Aware Transformer），一种基于Transformer的架构，结合多头注意力机制和动态窗口机制，以捕获长程依赖并整合所有相关属性。在六个公共数据集上的实验显示，DAW-Transformer在高熵数据集（如Sepsis）上表现突出，比Limited window Multi-Transformers提高4.69%和CNN-LSTM-SAtt模型提高3.07%；而在低熵数据集（如Road Traffic Fine）上，简单算法如Random Forest提供类似性能并增强解释性。该方法通过熵驱动的模型选择，提供了一个鲁棒、准确且可解释的AI/ML解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10573v1",
      "published_date": "2025-02-14 22:02:00 UTC",
      "updated_date": "2025-02-14 22:02:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:20:30.409906"
    },
    {
      "arxiv_id": "2502.10569v1",
      "title": "HADL Framework for Noise Resilient Long-Term Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Aditya Dey",
        "Jonas Kusch",
        "Fadi Al Machot"
      ],
      "abstract": "Long-term time series forecasting is critical in domains such as finance,\neconomics, and energy, where accurate and reliable predictions over extended\nhorizons drive strategic decision-making. Despite the progress in machine\nlearning-based models, the impact of temporal noise in extended lookback\nwindows remains underexplored, often degrading model performance and\ncomputational efficiency. In this paper, we propose a novel framework that\naddresses these challenges by integrating the Discrete Wavelet Transform (DWT)\nand Discrete Cosine Transform (DCT) to perform noise reduction and extract\nrobust long-term features. These transformations enable the separation of\nmeaningful temporal patterns from noise in both the time and frequency domains.\nTo complement this, we introduce a lightweight low-rank linear prediction layer\nthat not only reduces the influence of residual noise but also improves memory\nefficiency. Our approach demonstrates competitive robustness to noisy input,\nsignificantly reduces computational complexity, and achieves competitive or\nstate-of-the-art forecasting performance across diverse benchmark datasets.\nExtensive experiments reveal that the proposed framework is particularly\neffective in scenarios with high noise levels or irregular patterns, making it\nwell suited for real-world forecasting tasks. The code is available in\nhttps://github.com/forgee-master/HADL.",
      "tldr_zh": "本文提出HADL框架，用于提升长期时间序列预测的噪声鲁棒性，针对金融、经济和能源等领域中时间噪声对模型性能和效率的影响。框架整合Discrete Wavelet Transform (DWT)和Discrete Cosine Transform (DCT)来减少噪声并提取鲁棒的长期特征，同时引入轻量级的低秩线性预测层，以进一步降低残留噪声影响并提高内存效率。实验结果显示，HADL在多种基准数据集上实现了竞争性或最先进预测性能，尤其在高噪声或不规则模式场景中表现出色，并显著减少了计算复杂度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10569v1",
      "published_date": "2025-02-14 21:41:42 UTC",
      "updated_date": "2025-02-14 21:41:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:20:41.587563"
    },
    {
      "arxiv_id": "2502.10568v1",
      "title": "Observer-Aware Probabilistic Planning Under Partial Observability",
      "title_zh": "翻译失败",
      "authors": [
        "Salomé Lepers",
        "Vincent Thomas",
        "Olivier Buffet"
      ],
      "abstract": "In this article, we are interested in planning problems where the agent is\naware of the presence of an observer, and where this observer is in a partial\nobservability situation. The agent has to choose its strategy so as to optimize\nthe information transmitted by observations. Building on observer-aware Markov\ndecision processes (OAMDPs), we propose a framework to handle this type of\nproblems and thus formalize properties such as legibility, explicability and\npredictability. This extension of OAMDPs to partial observability can not only\nhandle more realistic problems, but also permits considering dynamic hidden\nvariables of interest. These dynamic target variables allow, for instance,\nworking with predictability, or with legibility problems where the goal might\nchange during execution. We discuss theoretical properties of PO-OAMDPs and,\nexperimenting with benchmark problems, we analyze HSVI's convergence behavior\nwith dedicated initializations and study the resulting strategies.",
      "tldr_zh": "本研究探讨了代理在知晓观察者存在且观察者处于部分可观察性（Partial Observability）情况下的概率规划问题，代理需优化观察传输的信息。基于 Observer-Aware Markov Decision Processes (OAMDPs)，作者提出 PO-OAMDPs 框架，以形式化 legibility、可解释性（explicability）和 predictability 等属性，并处理动态隐藏变量。实验通过基准问题分析 HSVI 算法的收敛行为，并评估生成的策略，证明该框架能更好地应对现实场景和目标变化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 13 figures. Complete version of AAMAS 2025 extended\n  abstract",
      "pdf_url": "http://arxiv.org/pdf/2502.10568v1",
      "published_date": "2025-02-14 21:41:04 UTC",
      "updated_date": "2025-02-14 21:41:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:20:53.153265"
    },
    {
      "arxiv_id": "2502.10567v1",
      "title": "Efficient Hierarchical Contrastive Self-supervising Learning for Time Series Classification via Importance-aware Resolution Selection",
      "title_zh": "通过重要性感知分辨率选择的高效分层对比自监督学习，用于时间序列分类",
      "authors": [
        "Kevin Garcia",
        "Juan Manuel Perez",
        "Yifeng Gao"
      ],
      "abstract": "Recently, there has been a significant advancement in designing\nSelf-Supervised Learning (SSL) frameworks for time series data to reduce the\ndependency on data labels. Among these works, hierarchical contrastive\nlearning-based SSL frameworks, which learn representations by contrasting data\nembeddings at multiple resolutions, have gained considerable attention. Due to\ntheir ability to gather more information, they exhibit better generalization in\nvarious downstream tasks. However, when the time series data length is\nsignificant long, the computational cost is often significantly higher than\nthat of other SSL frameworks. In this paper, to address this challenge, we\npropose an efficient way to train hierarchical contrastive learning models.\nInspired by the fact that each resolution's data embedding is highly dependent,\nwe introduce importance-aware resolution selection based training framework to\nreduce the computational cost. In the experiment, we demonstrate that the\nproposed method significantly improves training time while preserving the\noriginal model's integrity in extensive time series classification performance\nevaluations. Our code could be found here, https://github.com/KEEBVIN/IARS",
      "tldr_zh": "该论文针对时间序列分类中的层次对比自监督学习（hierarchical contrastive learning-based SSL）框架，解决了长序列数据导致的高计算成本问题。作者提出了一种重要性感知分辨率选择（importance-aware resolution selection）训练框架，利用各分辨率数据嵌入的依赖性来优化选择，从而减少计算开销。实验结果表明，该方法显著缩短了训练时间，同时在广泛的时间序列分类任务中保持了原模型的性能完整性。代码可从 https://github.com/KEEBVIN/IARS 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "I.2"
      ],
      "primary_category": "cs.LG",
      "comment": "Appears in IEEEBigData-2024",
      "pdf_url": "http://arxiv.org/pdf/2502.10567v1",
      "published_date": "2025-02-14 21:32:50 UTC",
      "updated_date": "2025-02-14 21:32:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:21:05.113826"
    },
    {
      "arxiv_id": "2502.10559v1",
      "title": "SAMRI-2: A Memory-based Model for Cartilage and Meniscus Segmentation in 3D MRIs of the Knee Joint",
      "title_zh": "SAMRI-2：一种基于记忆的模型，用于膝关节3D MRI中的软骨和半月板分割",
      "authors": [
        "Danielle L. Ferreira",
        "Bruno A. A. Nunes",
        "Xuzhe Zhang",
        "Laura Carretero Gomez",
        "Maggie Fung",
        "Ravi Soni"
      ],
      "abstract": "Accurate morphometric assessment of cartilage-such as thickness/volume-via\nMRI is essential for monitoring knee osteoarthritis. Segmenting cartilage\nremains challenging and dependent on extensive expert-annotated datasets, which\nare heavily subjected to inter-reader variability. Recent advancements in\nVisual Foundational Models (VFM), especially memory-based approaches, offer\nopportunities for improving generalizability and robustness. This study\nintroduces a deep learning (DL) method for cartilage and meniscus segmentation\nfrom 3D MRIs using interactive, memory-based VFMs. To improve spatial awareness\nand convergence, we incorporated a Hybrid Shuffling Strategy (HSS) during\ntraining and applied a segmentation mask propagation technique to enhance\nannotation efficiency. We trained four AI models-a CNN-based 3D-VNet, two\nautomatic transformer-based models (SaMRI2D and SaMRI3D), and a\ntransformer-based promptable memory-based VFM (SAMRI-2)-on 3D knee MRIs from\n270 patients using public and internal datasets and evaluated on 57 external\ncases, including multi-radiologist annotations and different data acquisitions.\nModel performance was assessed against reference standards using Dice Score\n(DSC) and Intersection over Union (IoU), with additional morphometric\nevaluations to further quantify segmentation accuracy. SAMRI-2 model, trained\nwith HSS, outperformed all other models, achieving an average DSC improvement\nof 5 points, with a peak improvement of 12 points for tibial cartilage. It also\ndemonstrated the lowest cartilage thickness errors, reducing discrepancies by\nup to threefold. Notably, SAMRI-2 maintained high performance with as few as\nthree user clicks per volume, reducing annotation effort while ensuring\nanatomical precision. This memory-based VFM with spatial awareness offers a\nnovel approach for reliable AI-assisted knee MRI segmentation, advancing DL in\nmusculoskeletal imaging.",
      "tldr_zh": "本文提出SAMRI-2，一种基于记忆的Visual Foundational Models (VFMs)，用于从3D MRI中精确分割膝关节软骨和半月板，以监测骨关节炎并解决标注数据依赖和变异问题。该模型结合Hybrid Shuffling Strategy (HSS)和分割掩码传播技术，提高了空间意识、收敛性和标注效率。实验结果显示，SAMRI-2在Dice Score (DSC)和Intersection over Union (IoU)指标上优于其他模型，如平均DSC提高5点，软骨厚度错误减少多达三倍，且仅需每个体积三个用户点击即可维持高性能。这种方法为AI辅助肌肉骨骼成像提供了可靠的新途径。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10559v1",
      "published_date": "2025-02-14 21:18:01 UTC",
      "updated_date": "2025-02-14 21:18:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:21:19.531552"
    },
    {
      "arxiv_id": "2502.10554v1",
      "title": "Benchmarking the rationality of AI decision making using the transitivity axiom",
      "title_zh": "使用传递性公理对 AI 决策的理性进行基准测试",
      "authors": [
        "Kiwon Song",
        "James M. Jennings III",
        "Clintin P. Davis-Stober"
      ],
      "abstract": "Fundamental choice axioms, such as transitivity of preference, provide\ntestable conditions for determining whether human decision making is rational,\ni.e., consistent with a utility representation. Recent work has demonstrated\nthat AI systems trained on human data can exhibit similar reasoning biases as\nhumans and that AI can, in turn, bias human judgments through AI recommendation\nsystems. We evaluate the rationality of AI responses via a series of choice\nexperiments designed to evaluate transitivity of preference in humans. We\nconsidered ten versions of Meta's Llama 2 and 3 LLM models. We applied Bayesian\nmodel selection to evaluate whether these AI-generated choices violated two\nprominent models of transitivity. We found that the Llama 2 and 3 models\ngenerally satisfied transitivity, but when violations did occur, occurred only\nin the Chat/Instruct versions of the LLMs. We argue that rationality axioms,\nsuch as transitivity of preference, can be useful for evaluating and\nbenchmarking the quality of AI-generated responses and provide a foundation for\nunderstanding computational rationality in AI systems more generally.",
      "tldr_zh": "本研究使用偏好传递性(transitivity of preference)公理来基准测试AI决策的理性，即AI选择是否符合效用表示的一致性。研究者通过一系列选择实验评估了Meta的Llama 2和3模型的十个版本，并采用Bayesian model selection方法检查这些AI响应是否违反传递性模型。结果显示，Llama 2和3模型通常满足传递性，但Chat/Instruct版本偶尔会出现违反。论文强调，理性公理如偏好传递性可作为评估AI响应质量的工具，并为理解AI中的计算理性(computational rationality)提供基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 2 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.10554v1",
      "published_date": "2025-02-14 20:56:40 UTC",
      "updated_date": "2025-02-14 20:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:21:29.120966"
    },
    {
      "arxiv_id": "2502.10552v1",
      "title": "Synthesis of Dynamic Masks for Information-Theoretic Opacity in Stochastic Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Sumukha Udupa",
        "Chongyang Shi",
        "Jie Fu"
      ],
      "abstract": "In this work, we investigate the synthesis of dynamic information releasing\nmechanisms, referred to as ''masks'', to minimize information leakage from a\nstochastic system to an external observer. Specifically, for a stochastic\nsystem, an observer aims to infer whether the final state of the system\ntrajectory belongs to a set of secret states. The dynamic mask seeks to\nregulate sensor information in order to maximize the observer's uncertainty\nabout the final state, a property known as final-state opacity. While existing\nsupervisory control literature on dynamic masks primarily addresses qualitative\nopacity, we propose quantifying opacity in stochastic systems by conditional\nentropy, which is a measure of information leakage in information security. We\nthen formulate a constrained optimization problem to synthesize a dynamic mask\nthat maximizes final-state opacity under a total cost constraint on masking. To\nsolve this constrained optimal dynamic mask synthesis problem, we develop a\nnovel primal-dual policy gradient method. Additionally, we present a technique\nfor computing the gradient of conditional entropy with respect to the masking\npolicy parameters, leveraging observable operators in hidden Markov models. To\ndemonstrate the effectiveness of our approach, we apply our method to an\nillustrative example and a stochastic grid world scenario, showing how our\nalgorithm optimally enforces final-state opacity under cost constraints.",
      "tldr_zh": "本文研究了在随机系统(stochastic systems)中合成动态掩码(dynamic masks)，以最小化系统轨迹最终状态向外部观察者泄露的信息，并通过最大化条件熵(conditional entropy)来量化最终状态不透明性(final-state opacity)。作者制定了一个约束优化问题，目标是最大化不透明性同时满足总成本约束，并开发了原始-对偶策略梯度(primal-dual policy gradient)方法来求解该问题。实验结果显示，该方法在示例和随机网格世界场景中有效强制执行了最优不透明性保护。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.RO",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "11 pages, 6 figures, accepted to ICCPS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10552v1",
      "published_date": "2025-02-14 20:53:22 UTC",
      "updated_date": "2025-02-14 20:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:21:42.257591"
    },
    {
      "arxiv_id": "2502.10550v1",
      "title": "Memory, Benchmark & Robots: A Benchmark for Solving Complex Tasks with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Egor Cherepanov",
        "Nikita Kachaev",
        "Alexey K. Kovalev",
        "Aleksandr I. Panov"
      ],
      "abstract": "Memory is crucial for enabling agents to tackle complex tasks with temporal\nand spatial dependencies. While many reinforcement learning (RL) algorithms\nincorporate memory, the field lacks a universal benchmark to assess an agent's\nmemory capabilities across diverse scenarios. This gap is particularly evident\nin tabletop robotic manipulation, where memory is essential for solving tasks\nwith partial observability and ensuring robust performance, yet no standardized\nbenchmarks exist. To address this, we introduce MIKASA (Memory-Intensive Skills\nAssessment Suite for Agents), a comprehensive benchmark for memory RL, with\nthree key contributions: (1) we propose a comprehensive classification\nframework for memory-intensive RL tasks, (2) we collect MIKASA-Base - a unified\nbenchmark that enables systematic evaluation of memory-enhanced agents across\ndiverse scenarios, and (3) we develop MIKASA-Robo - a novel benchmark of 32\ncarefully designed memory-intensive tasks that assess memory capabilities in\ntabletop robotic manipulation. Our contributions establish a unified framework\nfor advancing memory RL research, driving the development of more reliable\nsystems for real-world applications. The code is available at\nhttps://sites.google.com/view/memorybenchrobots/.",
      "tldr_zh": "本研究强调了记忆在强化学习（RL）中处理复杂任务的重要性，但现有基准测试不足以评估代理的记忆能力，尤其是桌面机器人操作领域。为解决此问题，论文提出 MIKASA（Memory-Intensive Skills Assessment Suite for Agents）基准测试，包括一个全面的记忆密集型 RL 任务分类框架、MIKASA-Base 用于系统评估记忆增强代理在多样场景中的表现，以及 MIKASA-Robo 包含 32 个精心设计的任务，用于测试机器人操作中的记忆能力。这些贡献建立了统一的框架，推动记忆 RL 研究向更可靠的真实世界应用发展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "38 pages, 21 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10550v1",
      "published_date": "2025-02-14 20:46:19 UTC",
      "updated_date": "2025-02-14 20:46:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:21:53.356124"
    },
    {
      "arxiv_id": "2502.10546v1",
      "title": "Learning to be Smooth: An End-to-End Differentiable Particle Smoother",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Younis",
        "Erik B. Sudderth"
      ],
      "abstract": "For challenging state estimation problems arising in domains like vision and\nrobotics, particle-based representations attractively enable temporal reasoning\nabout multiple posterior modes. Particle smoothers offer the potential for more\naccurate offline data analysis by propagating information both forward and\nbackward in time, but have classically required human-engineered dynamics and\nobservation models. Extending recent advances in discriminative training of\nparticle filters, we develop a framework for low-variance propagation of\ngradients across long time sequences when training particle smoothers. Our\n\"two-filter'' smoother integrates particle streams that are propagated forward\nand backward in time, while incorporating stratification and importance weights\nin the resampling step to provide low-variance gradient estimates for neural\nnetwork dynamics and observation models. The resulting mixture density particle\nsmoother is substantially more accurate than state-of-the-art particle filters,\nas well as search-based baselines, for city-scale global vehicle localization\nfrom real-world videos and maps.",
      "tldr_zh": "这篇论文提出了一种端到端的可微分粒子平滑器（particle smoother），旨在解决视觉和机器人领域复杂状态估计问题的多模式后验推理挑战。框架扩展了粒子滤波器（particle filters）的判别训练，通过“two-filter”平滑器结合向前和向后传播、层化（stratification）和重要性权重（importance weights），以降低长序列梯度方差，并使用混合密度粒子平滑器（mixture density particle smoother）训练神经网络动态和观测模型。实验结果显示，该方法在真实世界城市规模全球车辆定位任务中，比最先进的粒子滤波器和基于搜索的基线准确性大幅提升。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "The Thirty-Eighth Annual Conference on Neural Information Processing\n  Systems (NeurIPS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2502.10546v1",
      "published_date": "2025-02-14 20:26:54 UTC",
      "updated_date": "2025-02-14 20:26:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:22:05.847805"
    },
    {
      "arxiv_id": "2502.10536v1",
      "title": "PolyPath: Adapting a Large Multimodal Model for Multi-slide Pathology Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Faruk Ahmed",
        "Lin Yang",
        "Tiam Jaroensri",
        "Andrew Sellergren",
        "Yossi Matias",
        "Avinatan Hassidim",
        "Greg S. Corrado",
        "Dale R. Webster",
        "Shravya Shetty",
        "Shruthi Prabhakara",
        "Yun Liu",
        "Daniel Golden",
        "Ellery Wulczyn",
        "David F. Steiner"
      ],
      "abstract": "The interpretation of histopathology cases underlies many important\ndiagnostic and treatment decisions in medicine. Notably, this process typically\nrequires pathologists to integrate and summarize findings across multiple\nslides per case. Existing vision-language capabilities in computational\npathology have so far been largely limited to small regions of interest, larger\nregions at low magnification, or single whole-slide images (WSIs). This limits\ninterpretation of findings that span multiple high-magnification regions across\nmultiple WSIs. By making use of Gemini 1.5 Flash, a large multimodal model\n(LMM) with a 1-million token context window, we demonstrate the ability to\ngenerate bottom-line diagnoses from up to 40,000 768x768 pixel image patches\nfrom multiple WSIs at 10X magnification. This is the equivalent of up to 11\nhours of video at 1 fps. Expert pathologist evaluations demonstrate that the\ngenerated report text is clinically accurate and equivalent to or preferred\nover the original reporting for 68% (95% CI: [60%, 76%]) of multi-slide\nexamples with up to 5 slides. While performance decreased for examples with 6\nor more slides, this study demonstrates the promise of leveraging the\nlong-context capabilities of modern LMMs for the uniquely challenging task of\nmedical report generation where each case can contain thousands of image\npatches.",
      "tldr_zh": "本文提出 PolyPath 方法，通过适应大型多模态模型 (LMM) Gemini 1.5 Flash，其 1 百万 token 的上下文窗口能力，能够从多张全滑片图像 (WSIs) 中处理多达 40,000 个 768x768 像素的图像补丁，生成整合多高放大率区域的病理诊断报告。实验结果显示，专家病理学家评估该生成的报告在多达 5 张滑片的病例中，准确且等同或优于原报告的比例达 68%（95% CI: [60%, 76%]）。尽管在 6 张或更多滑片时性能有所下降，此研究突显了利用 LMM 的长上下文能力来应对复杂医疗报告生成的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "8 main pages, 21 pages in total",
      "pdf_url": "http://arxiv.org/pdf/2502.10536v1",
      "published_date": "2025-02-14 20:09:13 UTC",
      "updated_date": "2025-02-14 20:09:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:22:20.685204"
    },
    {
      "arxiv_id": "2502.15765v1",
      "title": "Generalized Attention Flow: Feature Attribution for Transformer Models via Maximum Flow",
      "title_zh": "翻译失败",
      "authors": [
        "Behrooz Azarkhalili",
        "Maxwell Libbrecht"
      ],
      "abstract": "This paper introduces Generalized Attention Flow (GAF), a novel feature\nattribution method for Transformer-based models to address the limitations of\ncurrent approaches. By extending Attention Flow and replacing attention weights\nwith the generalized Information Tensor, GAF integrates attention weights,\ntheir gradients, the maximum flow problem, and the barrier method to enhance\nthe performance of feature attributions. The proposed method exhibits key\ntheoretical properties and mitigates the shortcomings of prior techniques that\nrely solely on simple aggregation of attention weights. Our comprehensive\nbenchmarking on sequence classification tasks demonstrates that a specific\nvariant of GAF consistently outperforms state-of-the-art feature attribution\nmethods in most evaluation settings, providing a more reliable interpretation\nof Transformer model outputs.",
      "tldr_zh": "本论文提出了Generalized Attention Flow (GAF)，一种新型特征归因方法，旨在解决Transformer模型中现有方法的局限性。GAF通过扩展Attention Flow，将注意力权重替换为generalized Information Tensor，并整合注意力权重、它们的梯度、maximum flow问题和barrier method，提升了特征归因的性能和理论属性。实验结果显示，GAF的特定变体在序列分类任务的基准测试中，大多数评估设置下均超过了最先进的特征归因方法，提供更可靠的Transformer模型输出解释。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15765v1",
      "published_date": "2025-02-14 19:50:58 UTC",
      "updated_date": "2025-02-14 19:50:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:22:29.646952"
    },
    {
      "arxiv_id": "2502.10526v2",
      "title": "Tempo: Helping Data Scientists and Domain Experts Collaboratively Specify Predictive Modeling Tasks",
      "title_zh": "Tempo：帮助数据科学家和领域专家协作指定预测建模任务",
      "authors": [
        "Venkatesh Sivaraman",
        "Anika Vaishampayan",
        "Xiaotong Li",
        "Brian R Buck",
        "Ziyong Ma",
        "Richard D Boyce",
        "Adam Perer"
      ],
      "abstract": "Temporal predictive models have the potential to improve decisions in health\ncare, public services, and other domains, yet they often fail to effectively\nsupport decision-makers. Prior literature shows that many misalignments between\nmodel behavior and decision-makers' expectations stem from issues of model\nspecification, namely how, when, and for whom predictions are made. However,\nmodel specifications for predictive tasks are highly technical and difficult\nfor non-data-scientist stakeholders to interpret and critique. To address this\nchallenge we developed Tempo, an interactive system that helps data scientists\nand domain experts collaboratively iterate on model specifications. Using\nTempo's simple yet precise temporal query language, data scientists can quickly\nprototype specifications with greater transparency about pre-processing\nchoices. Moreover, domain experts can assess performance within data subgroups\nto validate that models behave as expected. Through three case studies, we\ndemonstrate how Tempo helps multidisciplinary teams quickly prune infeasible\nspecifications and identify more promising directions to explore.",
      "tldr_zh": "这篇论文介绍了 Tempo 系统，一种交互式工具，旨在帮助数据科学家和领域专家协作指定 predictive modeling tasks，以解决时间预测模型在医疗和公共服务等领域中与决策者期望不匹配的问题。Tempo 采用简单的 temporal query language 允许数据科学家快速原型化模型规范，并提升预处理选择的透明度，同时让领域专家通过评估数据 subgroups 的性能来验证模型行为。通过三个案例研究，论文展示了 Tempo 如何帮助多学科团队快速排除不可行规格并探索更具前景的方向。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Appearing at CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10526v2",
      "published_date": "2025-02-14 19:44:37 UTC",
      "updated_date": "2025-02-20 17:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:22:41.995994"
    },
    {
      "arxiv_id": "2502.10522v1",
      "title": "GraphiT: Efficient Node Classification on Text-Attributed Graphs with Prompt Optimized LLMs",
      "title_zh": "GraphiT：利用提示优化的LLMs在文本属性图上进行高效节点分类",
      "authors": [
        "Shima Khoshraftar",
        "Niaz Abedini",
        "Amir Hajian"
      ],
      "abstract": "The application of large language models (LLMs) to graph data has attracted a\nlot of attention recently. LLMs allow us to use deep contextual embeddings from\npretrained models in text-attributed graphs, where shallow embeddings are often\nused for the text attributes of nodes. However, it is still challenging to\nefficiently encode the graph structure and features into a sequential form for\nuse by LLMs. In addition, the performance of an LLM alone, is highly dependent\non the structure of the input prompt, which limits their effectiveness as a\nreliable approach and often requires iterative manual adjustments that could be\nslow, tedious and difficult to replicate programmatically. In this paper, we\npropose GraphiT (Graphs in Text), a framework for encoding graphs into a\ntextual format and optimizing LLM prompts for graph prediction tasks. Here we\nfocus on node classification for text-attributed graphs. We encode the graph\ndata for every node and its neighborhood into a concise text to enable LLMs to\nbetter utilize the information in the graph. We then further programmatically\noptimize the LLM prompts using the DSPy framework to automate this step and\nmake it more efficient and reproducible. GraphiT outperforms our LLM-based\nbaselines on three datasets and we show how the optimization step in GraphiT\nleads to measurably better results without manual prompt tweaking. We also\ndemonstrated that our graph encoding approach is competitive to other graph\nencoding methods while being less expensive because it uses significantly less\ntokens for the same task.",
      "tldr_zh": "该论文提出GraphiT框架，用于高效处理文本属性图上的节点分类任务，通过将图数据编码成简洁文本格式，并利用DSPy框架对LLM提示进行程序化优化，以克服LLM对图结构编码和提示依赖的挑战。GraphiT将每个节点及其邻居的信息浓缩成文本形式，显著提升了LLM的利用效率，并在三个数据集上优于基线模型。实验证明，该方法无需手动调整提示即可获得更好结果，且在性能和token使用上更具竞争力。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "6 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10522v1",
      "published_date": "2025-02-14 19:38:41 UTC",
      "updated_date": "2025-02-14 19:38:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:22:53.452755"
    },
    {
      "arxiv_id": "2502.10517v1",
      "title": "KernelBench: Can LLMs Write Efficient GPU Kernels?",
      "title_zh": "KernelBench：大型语言模型能编写高效 GPU 内核吗？",
      "authors": [
        "Anne Ouyang",
        "Simon Guo",
        "Simran Arora",
        "Alex L. Zhang",
        "William Hu",
        "Christopher Ré",
        "Azalia Mirhoseini"
      ],
      "abstract": "Efficient GPU kernels are crucial for building performant machine learning\narchitectures, but writing them is a time-consuming challenge that requires\nsignificant expertise; therefore, we explore using language models (LMs) to\nautomate kernel generation. We introduce KernelBench, an open-source framework\nfor evaluating LMs' ability to write fast and correct kernels on a suite of 250\ncarefully selected PyTorch ML workloads. KernelBench represents a real-world\nengineering environment and making progress on the introduced benchmark\ndirectly translates to faster practical kernels. We introduce a new evaluation\nmetric fast_p, which measures the percentage of generated kernels that are\nfunctionally correct and offer a speedup greater than an adjustable threshold p\nover baseline. Our experiments across various state-of-the-art models and\ntest-time methods show that frontier reasoning models perform the best out of\nthe box but still fall short overall, matching the PyTorch baseline in less\nthan 20% of the cases. While we show that results can improve by leveraging\nexecution and profiling feedback during iterative refinement, KernelBench\nremains a challenging benchmark, with its difficulty increasing as we raise\nspeedup threshold p.",
      "tldr_zh": "本论文探讨了大型语言模型（LLMs）是否能自动生成高效的GPU kernels，以解决编写这些内核所需的专业知识和时间问题。作者引入了KernelBench框架，这是一个开源基准，包含250个精心选择的PyTorch机器学习工作负载，用于评估LLMs生成正确且快速内核的能力，并提出新指标fast_p来衡量功能正确且速度提升超过阈值p的比例。实验结果显示，前沿推理模型表现最佳，但仅在不到20%的案例中匹配PyTorch基准；尽管通过迭代优化和反馈可提升性能，KernelBench仍是一个具有挑战性的基准，随着速度阈值p的增加，难度进一步加大。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.PF",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10517v1",
      "published_date": "2025-02-14 19:30:53 UTC",
      "updated_date": "2025-02-14 19:30:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:23:05.423959"
    },
    {
      "arxiv_id": "2502.10389v1",
      "title": "Region-Adaptive Sampling for Diffusion Transformers",
      "title_zh": "扩散变压器的区域自适应采样",
      "authors": [
        "Ziming Liu",
        "Yifan Yang",
        "Chengruidong Zhang",
        "Yiqi Zhang",
        "Lili Qiu",
        "Yang You",
        "Yuqing Yang"
      ],
      "abstract": "Diffusion models (DMs) have become the leading choice for generative tasks\nacross diverse domains. However, their reliance on multiple sequential forward\npasses significantly limits real-time performance. Previous acceleration\nmethods have primarily focused on reducing the number of sampling steps or\nreusing intermediate results, failing to leverage variations across spatial\nregions within the image due to the constraints of convolutional U-Net\nstructures. By harnessing the flexibility of Diffusion Transformers (DiTs) in\nhandling variable number of tokens, we introduce RAS, a novel, training-free\nsampling strategy that dynamically assigns different sampling ratios to regions\nwithin an image based on the focus of the DiT model. Our key observation is\nthat during each sampling step, the model concentrates on semantically\nmeaningful regions, and these areas of focus exhibit strong continuity across\nconsecutive steps. Leveraging this insight, RAS updates only the regions\ncurrently in focus, while other regions are updated using cached noise from the\nprevious step. The model's focus is determined based on the output from the\npreceding step, capitalizing on the temporal consistency we observed. We\nevaluate RAS on Stable Diffusion 3 and Lumina-Next-T2I, achieving speedups up\nto 2.36x and 2.51x, respectively, with minimal degradation in generation\nquality. Additionally, a user study reveals that RAS delivers comparable\nqualities under human evaluation while achieving a 1.6x speedup. Our approach\nmakes a significant step towards more efficient diffusion transformers,\nenhancing their potential for real-time applications.",
      "tldr_zh": "该研究针对扩散模型（DMs）的实时性能问题，提出了一种新型无训练采样策略Region-Adaptive Sampling (RAS)，利用Diffusion Transformers (DiTs)的灵活性，根据模型的焦点动态为图像不同区域分配采样比率。RAS的关键机制是利用模型在采样步骤中对语义区域的关注和temporal consistency，仅更新焦点区域，而其他区域使用前一步的cached noise。实验结果显示，在Stable Diffusion 3和Lumina-Next-T2I模型上，RAS实现了高达2.36x和2.51x的加速，同时生成质量几乎无损，用户研究也证实其在人类评估中质量相当且速度提升1.6x，从而为高效的扩散变换器在实时应用中铺平道路。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10389v1",
      "published_date": "2025-02-14 18:59:36 UTC",
      "updated_date": "2025-02-14 18:59:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:23:18.585504"
    },
    {
      "arxiv_id": "2502.10385v1",
      "title": "Simplifying DINO via Coding Rate Regularization",
      "title_zh": "通过编码率正则化简化 DINO",
      "authors": [
        "Ziyang Wu",
        "Jingyuan Zhang",
        "Druv Pai",
        "XuDong Wang",
        "Chandan Singh",
        "Jianwei Yang",
        "Jianfeng Gao",
        "Yi Ma"
      ],
      "abstract": "DINO and DINOv2 are two model families being widely used to learn\nrepresentations from unlabeled imagery data at large scales. Their learned\nrepresentations often enable state-of-the-art performance for downstream tasks,\nsuch as image classification and segmentation. However, they employ many\nempirically motivated design choices and their training pipelines are highly\ncomplex and unstable -- many hyperparameters need to be carefully tuned to\nensure that the representations do not collapse -- which poses considerable\ndifficulty to improving them or adapting them to new domains. In this work, we\nposit that we can remove most such-motivated idiosyncrasies in the pre-training\npipelines, and only need to add an explicit coding rate term in the loss\nfunction to avoid collapse of the representations. As a result, we obtain\nhighly simplified variants of the DINO and DINOv2 which we call SimDINO and\nSimDINOv2, respectively. Remarkably, these simplified models are more robust to\ndifferent design choices, such as network architecture and hyperparameters, and\nthey learn even higher-quality representations, measured by performance on\ndownstream tasks, offering a Pareto improvement over the corresponding DINO and\nDINOv2 models. This work highlights the potential of using simplifying design\nprinciples to improve the empirical practice of deep learning.",
      "tldr_zh": "这篇论文针对 DINO 和 DINOv2 模型在从无标签图像数据中学习表示时的复杂训练问题，提出通过在损失函数中添加显式编码率正则化（coding rate regularization）来避免表示崩溃，从而简化了训练管道。研究者开发了简化的变体 SimDINO 和 SimDINOv2，这些模型对网络架构和超参数更鲁棒，并在下游任务如图像分类和分割上表现出更高的性能。总体而言，这一方法提供了 Pareto 改进，并突出了简化设计原则在深度学习实践中的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "17 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10385v1",
      "published_date": "2025-02-14 18:58:04 UTC",
      "updated_date": "2025-02-14 18:58:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:23:29.628029"
    },
    {
      "arxiv_id": "2502.10383v1",
      "title": "Representation and Interpretation in Artificial and Natural Computing",
      "title_zh": "人工与自然计算中的表示与解释",
      "authors": [
        "Luis A. Pineda"
      ],
      "abstract": "Artificial computing machinery transforms representations through an\nobjective process, to be interpreted subjectively by humans, so the machine and\nthe interpreter are different entities, but in the putative natural computing\nboth processes are performed by the same agent. The method or process that\ntransforms a representation is called here \\emph{the mode of computing}. The\nmode used by digital computers is the algorithmic one, but there are others,\nsuch as quantum computers and diverse forms of non-conventional computing, and\nthere is an open-ended set of representational formats and modes that could be\nused in artificial and natural computing. A mode based on a notion of computing\ndifferent from Turing's may perform feats beyond what the Turing Machine does\nbut the modes would not be of the same kind and could not be compared. For a\nmode of computing to be more powerful than the algorithmic one, it ought to\ncompute functions lacking an effective algorithm, and Church Thesis would not\nhold. Here, a thought experiment including a computational demon using a\nhypothetical mode for such an effect is presented. If there is natural\ncomputing, there is a mode of natural computing whose properties may be causal\nto the phenomenological experience. Discovering it would come with solving the\nhard problem of consciousness; but if it turns out that such a mode does not\nexist, there is no such thing as natural computing, and the mind is not a\ncomputational process.",
      "tldr_zh": "这篇论文探讨了人工计算和自然计算中表示（representation）的转换及其主观解释，强调人工计算由机器客观处理而人类主观解读，而自然计算则由同一代理执行。论文定义了“mode of computing”概念，包括算法模式（algorithmic one）、量子计算和其他形式，并讨论了是否存在超越Turing Machine的计算模式。作者通过一个思想实验（thought experiment）引入计算魔鬼，提出如果有更强大的模式能计算无有效算法的函数，则Church Thesis不成立。最终，论文认为如果不存在自然计算的模式，心灵就不是计算过程，从而将计算理论与意识难题相联系。",
      "categories": [
        "cs.AI",
        "F.0"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10383v1",
      "published_date": "2025-02-14 18:57:29 UTC",
      "updated_date": "2025-02-14 18:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:23:42.146274"
    },
    {
      "arxiv_id": "2502.10373v1",
      "title": "OWLS: Scaling Laws for Multilingual Speech Recognition and Translation Models",
      "title_zh": "OWLS：多语言语音识别和翻译模型的缩放定律",
      "authors": [
        "William Chen",
        "Jinchuan Tian",
        "Yifan Peng",
        "Brian Yan",
        "Chao-Han Huck Yang",
        "Shinji Watanabe"
      ],
      "abstract": "Neural scaling laws offer valuable insights for designing robust sequence\nprocessing architectures. While these laws have been extensively characterized\nin other modalities, their behavior in speech remains comparatively\nunderexplored. In this work, we introduce OWLS, an open-access, reproducible\nsuite of multilingual speech recognition and translation models spanning 0.25B\nto 18B parameters, with the 18B version being the largest speech model, to the\nbest of our knowledge. OWLS leverages up to 360K hours of public speech data\nacross 150 languages, enabling a systematic investigation into how data, model,\nand compute scaling each influence performance in multilingual speech tasks. We\nuse OWLS to derive neural scaling laws, showing how final performance can be\nreliably predicted when scaling. One of our key findings is that scaling\nenhances performance on low-resource languages/dialects, helping to mitigate\nbias and improve the accessibility of speech technologies. Finally, we show how\nOWLS can be used to power new research directions by discovering emergent\nabilities in large-scale speech models. Model checkpoints will be released on\nhttps://huggingface.co/collections/espnet/owls-scaling-laws-for-speech-recognition-and-translation-67ab7f991c194065f057ce8d\nfor future studies.",
      "tldr_zh": "本研究引入了 OWLS，这是一个开源、可复现的多语言语音识别和翻译模型套件，模型参数从 0.25B 到 18B 不等，其中 18B 版本是目前已知最大的语音模型。研究者利用多达 360K 小时的公共语音数据，覆盖 150 种语言，对数据、模型和计算规模的影响进行了系统调查，推导出了 neural scaling laws，以可靠预测多语言语音任务的最终性能。关键发现是，scaling 能够提升低资源语言/方言的性能，从而缓解偏差并提高语音技术的可访问性。此外，OWLS 还展示了大型语音模型的涌现能力，并将模型检查点发布在 Hugging Face 上，支持未来研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "23 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10373v1",
      "published_date": "2025-02-14 18:51:40 UTC",
      "updated_date": "2025-02-14 18:51:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:23:54.281147"
    },
    {
      "arxiv_id": "2502.10363v3",
      "title": "BeamDojo: Learning Agile Humanoid Locomotion on Sparse Footholds",
      "title_zh": "翻译失败",
      "authors": [
        "Huayi Wang",
        "Zirui Wang",
        "Junli Ren",
        "Qingwei Ben",
        "Tao Huang",
        "Weinan Zhang",
        "Jiangmiao Pang"
      ],
      "abstract": "Traversing risky terrains with sparse footholds poses a significant challenge\nfor humanoid robots, requiring precise foot placements and stable locomotion.\nExisting learning-based approaches often struggle on such complex terrains due\nto sparse foothold rewards and inefficient learning processes. To address these\nchallenges, we introduce BeamDojo, a reinforcement learning (RL) framework\ndesigned for enabling agile humanoid locomotion on sparse footholds. BeamDojo\nbegins by introducing a sampling-based foothold reward tailored for polygonal\nfeet, along with a double critic to balancing the learning process between\ndense locomotion rewards and sparse foothold rewards. To encourage sufficient\ntrial-and-error exploration, BeamDojo incorporates a two-stage RL approach: the\nfirst stage relaxes the terrain dynamics by training the humanoid on flat\nterrain while providing it with task-terrain perceptive observations, and the\nsecond stage fine-tunes the policy on the actual task terrain. Moreover, we\nimplement a onboard LiDAR-based elevation map to enable real-world deployment.\nExtensive simulation and real-world experiments demonstrate that BeamDojo\nachieves efficient learning in simulation and enables agile locomotion with\nprecise foot placement on sparse footholds in the real world, maintaining a\nhigh success rate even under significant external disturbances.",
      "tldr_zh": "该研究提出BeamDojo，一种强化学习 (RL) 框架，用于帮助人形机器人实现敏捷运动，尤其是在稀疏支点地形上，通过采样-based foothold reward和double critic来平衡密集运动奖励与稀疏支点奖励的学习过程。框架采用two-stage RL approach：第一阶段在平坦地形上训练机器人，提供任务-地形感知观察；第二阶段在实际地形上微调策略，并整合onboard LiDAR-based elevation map以支持真实世界部署。实验结果显示，BeamDojo在模拟环境中实现高效学习，并在真实场景中实现精确脚部放置和稳定运动，即使面对外部干扰，也保持高成功率。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "Published at RSS 2025. Project website:\n  https://why618188.github.io/beamdojo",
      "pdf_url": "http://arxiv.org/pdf/2502.10363v3",
      "published_date": "2025-02-14 18:42:42 UTC",
      "updated_date": "2025-04-27 13:49:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:24:06.319572"
    },
    {
      "arxiv_id": "2502.10339v1",
      "title": "STAR: Spectral Truncation and Rescale for Model Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Ang Lee",
        "Ching-Yun Ko",
        "Tejaswini Pedapati",
        "I-Hsin Chung",
        "Mi-Yen Yeh",
        "Pin-Yu Chen"
      ],
      "abstract": "Model merging is an efficient way of obtaining a multi-task model from\nseveral pretrained models without further fine-tuning, and it has gained\nattention in various domains, including natural language processing (NLP).\nDespite the efficiency, a key challenge in model merging is the seemingly\ninevitable decrease in task performance as the number of models increases. In\nthis paper, we propose $\\mathbf{S}$pectral $\\mathbf{T}$runcation $\\mathbf{A}$nd\n$\\mathbf{R}$escale (STAR) that aims at mitigating ``merging conflicts'' by\ntruncating small components in the respective spectral spaces, which is\nfollowed by an automatic parameter rescaling scheme to retain the nuclear norm\nof the original matrix. STAR requires no additional inference on original\ntraining data and is robust to hyperparamater choice. We demonstrate the\neffectiveness of STAR through extensive model merging cases on diverse NLP\ntasks. Specifically, STAR works robustly across varying model sizes, and can\noutperform baselines by 4.2$\\%$ when merging 12 models on Flan-T5. Our code is\npublicly available at https://github.com/IBM/STAR.",
      "tldr_zh": "该论文提出 STAR（Spectral Truncation and Rescale）方法，用于提升模型合并（Model Merging）的效率，旨在解决合并多个预训练模型时导致任务性能下降的“merging conflicts”问题。STAR 通过在光谱空间截断小组件（Spectral Truncation），并采用自动参数重新缩放方案（Rescale）来保留矩阵的核范数（nuclear norm），无需额外训练数据且对超参数选择鲁棒。实验结果显示，在各种 NLP 任务上，STAR 适用于不同模型大小，并在合并 12 个模型的 Flan-T5 场景中比基线提升 4.2%，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10339v1",
      "published_date": "2025-02-14 17:59:58 UTC",
      "updated_date": "2025-02-14 17:59:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:24:17.664694"
    },
    {
      "arxiv_id": "2502.10338v1",
      "title": "Evaluating the Meta- and Object-Level Reasoning of Large Language Models for Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Nick Ferguson",
        "Liane Guillou",
        "Alan Bundy",
        "Kwabena Nuamah"
      ],
      "abstract": "Large Language Models (LLMs) excel in natural language tasks but still face\nchallenges in Question Answering (QA) tasks requiring complex, multi-step\nreasoning. We outline the types of reasoning required in some of these tasks,\nand reframe them in terms of meta-level reasoning (akin to high-level strategic\nreasoning or planning) and object-level reasoning (embodied in lower-level\ntasks such as mathematical reasoning). Franklin, a novel dataset with\nrequirements of meta- and object-level reasoning, is introduced and used along\nwith three other datasets to evaluate four LLMs at question answering tasks\nrequiring multiple steps of reasoning. Results from human annotation studies\nsuggest LLMs demonstrate meta-level reasoning with high frequency, but struggle\nwith object-level reasoning tasks in some of the datasets used. Additionally,\nevidence suggests that LLMs find the object-level reasoning required for the\nquestions in the Franklin dataset challenging, yet they do exhibit strong\nperformance with respect to the meta-level reasoning requirements.",
      "tldr_zh": "这篇论文评估了 Large Language Models (LLMs) 在 Question Answering (QA) 任务中 meta-level reasoning（高层战略推理）和 object-level reasoning（低层任务如数学推理）的表现。研究引入了新数据集 Franklin，并结合其他三个数据集，对四个 LLMs 进行了多步推理任务的测试。结果显示，LLMs 在 meta-level reasoning 方面表现出高频表现，但 object-level reasoning 任务中存在显著挑战，尤其在 Franklin 数据集中。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages. Accepted to the Workshop on Planning in the Era of LLMs\n  (LM4Plan @ AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.10338v1",
      "published_date": "2025-02-14 17:55:43 UTC",
      "updated_date": "2025-02-14 17:55:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:24:30.269608"
    },
    {
      "arxiv_id": "2502.10497v1",
      "title": "Hallucinations and Truth: A Comprehensive Accuracy Evaluation of RAG, LoRA and DoRA",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Baqar",
        "Rajat Khanda"
      ],
      "abstract": "Recent advancements in Generative AI have significantly improved the\nefficiency and adaptability of natural language processing (NLP) systems,\nparticularly through Retrieval-Augmented Generation (RAG), Low-Rank Adaptation\n(LoRA), and Weight-Decomposed Low-Rank Adaptation (DoRA). RAG integrates\nexternal knowledge to enhance factual consistency in generative outputs, while\nLoRA enables parameter-efficient fine-tuning of large language models (LLMs).\nDoRA further refines this process by optimizing fine-tuning through adaptive\nparameter ranking and domain-aware weight adjustments, improving learning\nefficiency while maintaining inference performance.\n  This paper presents a large-scale empirical evaluation of RAG, LoRA, and\nDoRA, with model fine-tuning and generation performance assessed on 20,000\nFAQ-based queries, while the knowledge base spans 400,000 entries. The study\nanalyzes key performance metrics such as accuracy, relevance, and inference\nlatency. Experimental results demonstrate that DoRA achieves the highest\naccuracy (90.1%), relevance score (0.88), and lowest latency (110 ms per\nquery), outperforming both LoRA and RAG in real-world, domain-specific\ngenerative AI applications.\n  Furthermore, this study examines the trade-offs between fine-tuning\nefficiency, computational cost, and real-time adaptability across different\nmodels. Findings highlight RAG's effectiveness in knowledge grounding, LoRA's\ncost-efficient domain adaptation, and DoRA's ability to balance fine-tuning\nefficiency with model precision. These insights provide practical guidance for\ndeploying AI-driven generative systems in accuracy-critical domains such as\nhealthcare, finance, and legal services, ensuring scalability, reliability, and\noptimal performance in dynamic environments.",
      "tldr_zh": "本论文对 Retrieval-Augmented Generation (RAG)、Low-Rank Adaptation (LoRA) 和 Weight-Decomposed Low-Rank Adaptation (DoRA) 进行了全面准确性评估，旨在解决生成式 AI 中的幻觉问题。研究通过在 20,000 个 FAQ-based 查询和 400,000 条知识条目上进行大规模实证测试，评估了准确性、相关性和推理延迟等关键指标。结果显示，DoRA 表现出色，达到 90.1% 的准确率、0.88 的相关性分数和 110 ms/查询 的最低延迟，优于 LoRA 和 RAG。这些发现分析了各方法的权衡，如 RAG 的知识接地优势和 DoRA 的微调效率平衡，并为在医疗、金融和法律等精度关键领域部署 AI 系统提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "10 Pages",
      "pdf_url": "http://arxiv.org/pdf/2502.10497v1",
      "published_date": "2025-02-14 17:38:25 UTC",
      "updated_date": "2025-02-14 17:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:24:43.802786"
    },
    {
      "arxiv_id": "2502.10325v1",
      "title": "Process Reward Models for LLM Agents: Practical Framework and Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Sanjiban Choudhury"
      ],
      "abstract": "We introduce Agent Process Reward Models (AgentPRM), a simple and scalable\nframework for training LLM agents to continually improve through interactions.\nAgentPRM follows a lightweight actor-critic paradigm, using Monte Carlo\nrollouts to compute reward targets and optimize policies. It requires minimal\nmodifications to existing RLHF pipelines, making it easy to integrate at scale.\nBeyond AgentPRM, we propose InversePRM, which learns process rewards directly\nfrom demonstrations without explicit outcome supervision. We also explore key\nchallenges and opportunities, including exploration, process reward shaping,\nand model-predictive reasoning. We evaluate on ALFWorld benchmark, show that\nsmall 3B models trained with AgentPRM and InversePRM outperform strong GPT-4o\nbaselines, and analyze test-time scaling, reward hacking, and more. Our code is\navailable at: https://github.com/sanjibanc/agent_prm.",
      "tldr_zh": "该研究引入了 AgentPRM，一种简单可扩展的框架，用于训练 LLM 代理通过交互不断改进，采用轻量级 actor-critic 范式和 Monte Carlo rollouts 计算奖励目标并优化策略，仅需对现有 RLHF 管道进行最小修改，便于大规模集成。论文还提出了 InversePRM 方法，能够从演示中直接学习过程奖励，而无需显式结果监督，并探讨了探索、过程奖励塑造和模型预测推理等关键挑战和机会。在 ALFWorld 基准测试中，使用 AgentPRM 和 InversePRM 训练的 3B 模型超过了强大的 GPT-4o 基线，并在测试时间缩放和奖励黑客等方面进行了分析，代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10325v1",
      "published_date": "2025-02-14 17:34:28 UTC",
      "updated_date": "2025-02-14 17:34:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:24:55.538891"
    },
    {
      "arxiv_id": "2502.10311v1",
      "title": "ExplainReduce: Summarising local explanations via proxies",
      "title_zh": "翻译失败",
      "authors": [
        "Lauri Seppäläinen",
        "Mudong Guo",
        "Kai Puolamäki"
      ],
      "abstract": "Most commonly used non-linear machine learning methods are closed-box models,\nuninterpretable to humans. The field of explainable artificial intelligence\n(XAI) aims to develop tools to examine the inner workings of these closed\nboxes. An often-used model-agnostic approach to XAI involves using simple\nmodels as local approximations to produce so-called local explanations;\nexamples of this approach include LIME, SHAP, and SLISEMAP. This paper shows\nhow a large set of local explanations can be reduced to a small \"proxy set\" of\nsimple models, which can act as a generative global explanation. This reduction\nprocedure, ExplainReduce, can be formulated as an optimisation problem and\napproximated efficiently using greedy heuristics.",
      "tldr_zh": "非线性机器学习模型通常是黑盒子，无法被人类解释，XAI（Explainable Artificial Intelligence）领域则开发工具来揭示其内部机制。论文提出ExplainReduce方法，通过将大量局部解释（如LIME、SHAP和SLISEMAP）减少为一个小的“代理集”（proxy set）简单模型，从而生成全局解释。该方法将减少过程表述为优化问题，并使用贪婪启发式进行高效近似，提供了一种模型无关的解释总结框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.HC",
        "I.2.4"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages with a 7 page appendix, 7 + 5 figures, 2 tables. The\n  datasets and source code used in the paper are available at\n  https://github.com/edahelsinki/explainreduce",
      "pdf_url": "http://arxiv.org/pdf/2502.10311v1",
      "published_date": "2025-02-14 17:14:02 UTC",
      "updated_date": "2025-02-14 17:14:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:25:04.902128"
    },
    {
      "arxiv_id": "2502.10308v1",
      "title": "LLM-Powered Preference Elicitation in Combinatorial Assignment",
      "title_zh": "翻译失败",
      "authors": [
        "Ermis Soumalias",
        "Yanchen Jiang",
        "Kehang Zhu",
        "Michael Curry",
        "Sven Seuken",
        "David C. Parkes"
      ],
      "abstract": "We study the potential of large language models (LLMs) as proxies for humans\nto simplify preference elicitation (PE) in combinatorial assignment. While\ntraditional PE methods rely on iterative queries to capture preferences, LLMs\noffer a one-shot alternative with reduced human effort. We propose a framework\nfor LLM proxies that can work in tandem with SOTA ML-powered preference\nelicitation schemes. Our framework handles the novel challenges introduced by\nLLMs, such as response variability and increased computational costs. We\nexperimentally evaluate the efficiency of LLM proxies against human queries in\nthe well-studied course allocation domain, and we investigate the model\ncapabilities required for success. We find that our approach improves\nallocative efficiency by up to 20%, and these results are robust across\ndifferent LLMs and to differences in quality and accuracy of reporting.",
      "tldr_zh": "本研究探讨了使用大型语言模型（LLMs）作为人类代理，以简化组合分配（combinatorial assignment）中的偏好elicitation (PE)。他们提出一个框架，让 LLMs 与最先进（SOTA）的机器学习驱动 PE 方案协同工作，处理 LLMs 带来的挑战，如响应variability 和计算costs。实验在课程分配领域评估了该框架，发现与人类查询相比，分配效率（allocative efficiency）提高了高达 20%，且结果在不同 LLMs 和报告质量中保持稳健。",
      "categories": [
        "cs.AI",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10308v1",
      "published_date": "2025-02-14 17:12:20 UTC",
      "updated_date": "2025-02-14 17:12:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:25:17.375929"
    },
    {
      "arxiv_id": "2502.12182v1",
      "title": "Towards Transparent and Accurate Plasma State Monitoring at JET",
      "title_zh": "面向 JET 的透明与准确等离子体状态监测",
      "authors": [
        "Andrin Bürli",
        "Alessandro Pau",
        "Thomas Koller",
        "Olivier Sauter",
        "JET Contributors"
      ],
      "abstract": "Controlling and monitoring plasma within a tokamak device is complex and\nchallenging. Plasma off-normal events, such as disruptions, are hindering\nsteady-state operation. For large devices, they can even endanger the machine's\nintegrity and it represents in general one of the most serious concerns for the\nexploitation of the tokamak concept for future power plants. Effective plasma\nstate monitoring carries the potential to enable an understanding of such\nphenomena and their evolution which is crucial for the successful operation of\ntokamaks. This paper presents the application of a transparent and data-driven\nmethodology to monitor the plasma state in a tokamak. Compared to previous\nstudies in the field, supervised and unsupervised learning techniques are\ncombined. The dataset consisted of 520 expert-validated discharges from JET.\nThe goal was to provide an interpretable plasma state representation for the\nJET operational space by leveraging multi-task learning for the first time in\nthe context of plasma state monitoring. When evaluated as disruption\npredictors, a sequence-based approach showed significant improvements compared\nto the state-based models. The best resulting network achieved a promising\ncross-validated success rate when combined with a physical indicator and\naccounting for nearby instabilities. Qualitative evaluations of the learned\nlatent space uncovered operational and disruptive regions as well as patterns\nrelated to learned dynamics and global feature importance. The applied\nmethodology provides novel possibilities for the definition of triggers to\nswitch between different control scenarios, data analysis, and learning as well\nas exploring latent dynamics for plasma state monitoring. It also showed\npromising quantitative and qualitative results with warning times suitable for\navoidance purposes and distributions that are consistent with known physical\nmechanisms.",
      "tldr_zh": "这篇论文针对 JET 托卡马克装置的等离子体状态监控，提出了一种透明的数据驱动方法，结合监督学习、无监督学习和多任务学习，以更好地理解和预测破坏事件。使用 520 个专家验证的放电数据，该方法首次在等离子体监控中应用多任务学习，提供可解释的等离子体状态表示，并通过序列-based 预测模型将预测准确率显著提升。实验结果显示，该框架在结合物理指标后实现了高成功率预警，具有潜在应用在控制场景切换、数据分析和探索潜在动态方面。",
      "categories": [
        "physics.plasm-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.plasm-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12182v1",
      "published_date": "2025-02-14 17:09:03 UTC",
      "updated_date": "2025-02-14 17:09:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:25:30.475609"
    },
    {
      "arxiv_id": "2502.10303v1",
      "title": "Reinforcement Learning in Strategy-Based and Atari Games: A Review of Google DeepMinds Innovations",
      "title_zh": "翻译失败",
      "authors": [
        "Abdelrhman Shaheen",
        "Anas Badr",
        "Ali Abohendy",
        "Hatem Alsaadawy",
        "Nadine Alsayad"
      ],
      "abstract": "Reinforcement Learning (RL) has been widely used in many applications,\nparticularly in gaming, which serves as an excellent training ground for AI\nmodels. Google DeepMind has pioneered innovations in this field, employing\nreinforcement learning algorithms, including model-based, model-free, and deep\nQ-network approaches, to create advanced AI models such as AlphaGo, AlphaGo\nZero, and MuZero. AlphaGo, the initial model, integrates supervised learning\nand reinforcement learning to master the game of Go, surpassing professional\nhuman players. AlphaGo Zero refines this approach by eliminating reliance on\nhuman gameplay data, instead utilizing self-play for enhanced learning\nefficiency. MuZero further extends these advancements by learning the\nunderlying dynamics of game environments without explicit knowledge of the\nrules, achieving adaptability across various games, including complex Atari\ngames. This paper reviews the significance of reinforcement learning\napplications in Atari and strategy-based games, analyzing these three models,\ntheir key innovations, training processes, challenges encountered, and\nimprovements made. Additionally, we discuss advancements in the field of\ngaming, including MiniZero and multi-agent models, highlighting future\ndirections and emerging AI models from Google DeepMind.",
      "tldr_zh": "这篇论文回顾了 Google DeepMind 在强化学习（Reinforcement Learning, RL）领域的创新，特别是在策略游戏（如围棋）和 Atari 游戏中的应用。论文详细分析了关键模型，包括 AlphaGo（结合监督学习和 RL 超越人类玩家）、AlphaGo Zero（通过自对弈自学，提高效率并去除人类数据依赖）、以及 MuZero（无需游戏规则知识即可学习环境动态，实现跨游戏适应）。此外，它探讨了这些模型的训练过程、面临的挑战和改进措施，并展望未来方向，如 MiniZero 和多智能体模型的发展。",
      "categories": [
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10303v1",
      "published_date": "2025-02-14 17:06:34 UTC",
      "updated_date": "2025-02-14 17:06:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:25:42.058786"
    },
    {
      "arxiv_id": "2502.10495v1",
      "title": "SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhonghao Yang",
        "Linye Lyu",
        "Xuanhang Chang",
        "Daojing He",
        "YU LI"
      ],
      "abstract": "In the rapidly evolving landscape of image generation, Latent Diffusion\nModels (LDMs) have emerged as powerful tools, enabling the creation of highly\nrealistic images. However, this advancement raises significant concerns\nregarding copyright infringement and the potential misuse of generated content.\nCurrent watermarking techniques employed in LDMs often embed constant signals\nto the generated images that compromise their stealthiness, making them\nvulnerable to detection by malicious attackers. In this paper, we introduce\nSWA-LDM, a novel approach that enhances watermarking by randomizing the\nembedding process, effectively eliminating detectable patterns while preserving\nimage quality and robustness. Our proposed watermark presence attack reveals\nthe inherent vulnerabilities of existing latent-based watermarking methods,\ndemonstrating how easily these can be exposed. Through comprehensive\nexperiments, we validate that SWA-LDM not only fortifies watermark stealthiness\nbut also maintains competitive performance in watermark robustness and visual\nfidelity. This work represents a pivotal step towards securing LDM-generated\nimages against unauthorized use, ensuring both copyright protection and content\nintegrity in an era where digital image authenticity is paramount.",
      "tldr_zh": "这篇论文针对Latent Diffusion Models (LDMs)生成的图像版权侵权风险，提出SWA-LDM方法，通过随机化水印嵌入过程来消除可检测模式，从而提升水印的隐秘性，同时保持图像质量和鲁棒性。研究者还开发了watermark presence attack，以揭示现有隐形水印方法的漏洞。实验结果显示，SWA-LDM在隐秘性方面显著优于基线，同时维持了竞争性的性能，为保护LDMs生成图像的版权和完整性提供了关键性进展。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10495v1",
      "published_date": "2025-02-14 16:55:45 UTC",
      "updated_date": "2025-02-14 16:55:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:25:54.184200"
    },
    {
      "arxiv_id": "2502.10284v1",
      "title": "A Hybrid Cross-Stage Coordination Pre-ranking Model for Online Recommendation Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Binglei Zhao",
        "Houying Qi",
        "Guang Xu",
        "Mian Ma",
        "Xiwei Zhao",
        "Feng Mei",
        "Sulong Xu",
        "Jinghe Hu"
      ],
      "abstract": "Large-scale recommendation systems often adopt cascading architecture\nconsisting of retrieval, pre-ranking, ranking, and re-ranking stages. With\nstrict latency requirements, pre-ranking utilizes lightweight models to perform\na preliminary selection from massive retrieved candidates. However, recent\nworks focus solely on improving consistency with ranking, relying exclusively\non downstream stages. Since downstream input is derived from the pre-ranking\noutput, they will exacerbate the sample selection bias (SSB) issue and Matthew\neffect, leading to sub-optimal results. To address the limitation, we propose a\nnovel Hybrid Cross-Stage Coordination Pre-ranking model (HCCP) to integrate\ninformation from upstream (retrieval) and downstream (ranking, re-ranking)\nstages. Specifically, cross-stage coordination refers to the pre-ranking's\nadaptability to the entire stream and the role of serving as a more effective\nbridge between upstream and downstream. HCCP consists of Hybrid Sample\nConstruction and Hybrid Objective Optimization. Hybrid sample construction\ncaptures multi-level unexposed data from the entire stream and rearranges them\nto become the optimal guiding \"ground truth\" for pre-ranking learning. Hybrid\nobjective optimization contains the joint optimization of consistency and\nlong-tail precision through our proposed Margin InfoNCE loss. It is\nspecifically designed to learn from such hybrid unexposed samples, improving\nthe overall performance and mitigating the SSB issue. The appendix describes a\nproof of the efficacy of the proposed loss in selecting potential positives.\nExtensive offline and online experiments indicate that HCCP outperforms SOTA\nmethods by improving cross-stage coordination. It contributes up to 14.9% UCVR\nand 1.3% UCTR in the JD E-commerce recommendation system. Concerning code\nprivacy, we provide a pseudocode for reference.",
      "tldr_zh": "这篇论文针对在线推荐系统的级联架构，提出了一种新型 Hybrid Cross-Stage Coordination Pre-ranking model (HCCP)，旨在通过整合上游检索和下游排序/再排序阶段的信息，缓解样本选择偏差(SSB)问题和马太效应。HCCP 包括 Hybrid Sample Construction 用于捕获并重新排列多级未暴露数据作为优化指导，以及 Hybrid Objective Optimization 通过 Margin InfoNCE loss 联合优化阶段一致性和长尾精确度。实验结果显示，HCCP 在 JD 电商推荐系统中提升了 14.9% UCVR 和 1.3% UCTR，显著优于现有方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by WWW 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10284v1",
      "published_date": "2025-02-14 16:42:54 UTC",
      "updated_date": "2025-02-14 16:42:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:26:06.427972"
    },
    {
      "arxiv_id": "2502.10273v1",
      "title": "Probing Perceptual Constancy in Large Vision Language Models",
      "title_zh": "在大型视觉语言模型中",
      "authors": [
        "Haoran Sun",
        "Suyang Yu",
        "Yijiang Li",
        "Qingying Gao",
        "Haiyun Lyu",
        "Hokin Deng",
        "Dezhi Luo"
      ],
      "abstract": "Perceptual constancy is the ability to maintain stable perceptions of objects\ndespite changes in sensory input, such as variations in distance, angle, or\nlighting. This ability is crucial for recognizing visual information in a\ndynamic world, making it essential for Vision-Language Models (VLMs). However,\nwhether VLMs are currently and theoretically capable of mastering this ability\nremains underexplored. In this study, we evaluated 33 VLMs using 253\nexperiments across three domains: color, size, and shape constancy. The\nexperiments included single-image and video adaptations of classic cognitive\ntasks, along with novel tasks in in-the-wild conditions, to evaluate the\nmodels' recognition of object properties under varying conditions. We found\nsignificant variability in VLM performance, with models performance in shape\nconstancy clearly dissociated from that of color and size constancy.",
      "tldr_zh": "本研究探讨了大型视觉语言模型（VLMs）在感知恒常性（Perceptual Constancy）方面的能力，即在距离、角度或照明变化下保持物体感知稳定的关键功能。研究者评估了33个VLMs，通过253个实验涵盖颜色、尺寸和形状恒常性，包括经典认知任务的单图像和视频适应，以及野外条件下的新型任务。结果显示，VLMs的表现存在显著差异，特别是在形状恒常性与其他（如颜色和尺寸恒常性）之间存在明显脱节，为未来VLMs改进提供重要洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10273v1",
      "published_date": "2025-02-14 16:31:43 UTC",
      "updated_date": "2025-02-14 16:31:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:26:16.960305"
    },
    {
      "arxiv_id": "2502.10266v1",
      "title": "Are Large Language Models the future crowd workers of Linguistics?",
      "title_zh": "大语言模型是否会成为语言学的未来众包工作者？",
      "authors": [
        "Iris Ferrazzo"
      ],
      "abstract": "Data elicitation from human participants is one of the core data collection\nstrategies used in empirical linguistic research. The amount of participants in\nsuch studies may vary considerably, ranging from a handful to crowdsourcing\ndimensions. Even if they provide resourceful extensive data, both of these\nsettings come alongside many disadvantages, such as low control of\nparticipants' attention during task completion, precarious working conditions\nin crowdsourcing environments, and time-consuming experimental designs. For\nthese reasons, this research aims to answer the question of whether Large\nLanguage Models (LLMs) may overcome those obstacles if included in empirical\nlinguistic pipelines. Two reproduction case studies are conducted to gain\nclarity into this matter: Cruz (2023) and Lombard et al. (2021). The two forced\nelicitation tasks, originally designed for human participants, are reproduced\nin the proposed framework with the help of OpenAI's GPT-4o-mini model. Its\nperformance with our zero-shot prompting baseline shows the effectiveness and\nhigh versatility of LLMs, that tend to outperform human informants in\nlinguistic tasks. The findings of the second replication further highlight the\nneed to explore additional prompting techniques, such as Chain-of-Thought (CoT)\nprompting, which, in a second follow-up experiment, demonstrates higher\nalignment to human performance on both critical and filler items. Given the\nlimited scale of this study, it is worthwhile to further explore the\nperformance of LLMs in empirical Linguistics and in other future applications\nin the humanities.",
      "tldr_zh": "本研究探讨了Large Language Models (LLMs) 是否能取代人类参与者成为语言学研究的未来“crowd workers”，以解决传统数据收集中的问题，如参与者注意力不足、工作条件差和实验设计耗时。研究通过重现Cruz (2023)和Lombard et al. (2021)的两个强制激发任务，使用OpenAI的GPT-4o-mini模型进行zero-shot prompting，证明LLMs在语言学任务中往往优于人类表现。后续实验引入Chain-of-Thought (CoT) prompting，进一步提升了LLMs与人类性能的契合度。尽管研究规模有限，该工作强调了LLMs在语言学和人文领域的潜力，并建议进行更多探索。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10266v1",
      "published_date": "2025-02-14 16:23:39 UTC",
      "updated_date": "2025-02-14 16:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:26:29.748018"
    },
    {
      "arxiv_id": "2502.15764v1",
      "title": "High-Throughput Computational Screening and Interpretable Machine Learning of Metal-organic Frameworks for Iodine Capture",
      "title_zh": "高通量",
      "authors": [
        "Haoyi Tan",
        "Yukun Teng",
        "Guangcun Shan"
      ],
      "abstract": "The removal of leaked radioactive iodine isotopes in humid environments holds\nsignificant importance in nuclear waste management and nuclear accident\nmitigation. In this study, high-throughput computational screening and machine\nlearning were combined to reveal the iodine capture performance of 1816\nmetal-organic framework (MOF) materials under humid air conditions. Firstly,\nthe relationship between the structural characteristics of MOFs and their\nadsorption properties was explored, with the aim of identifying the optimal\nstructural parameters for iodine capture. Subsequently, two machine learning\nregression algorithms - Random Forest and CatBoost, were employed to predict\nthe iodine adsorption capabilities of MOFs. In addition to 6 structural\nfeatures, 25 molecular features and 8 chemical features were incorporated to\nenhance the prediction accuracy of the machine learning algorithms. Feature\nimportance was assessed to determine the relative influence of various features\non iodine adsorption performance, in which the Henry's coefficient and heat of\nadsorption to iodine were found the two most crucial chemical factors.\nFurthermore, four types of molecular fingerprints were introduced for providing\ncomprehensive and detailed structural information of MOF materials. The top 20\nmost significant MACCS molecular fingerprints were picked out, revealing that\nthe presence of six-membered ring structures and nitrogen atoms in the MOFs\nwere the key structural factors that enhanced iodine adsorption, followed by\nthe existence of oxygen atoms. This work combined high-throughput computation,\nmachine learning, and molecular fingerprints to comprehensively elucidate the\nmultifaceted factors influencing the iodine adsorption performance of MOFs,\noffering profound insightful guidelines for screening and structural design of\nadvanced MOF materials.",
      "tldr_zh": "本文通过高通量计算筛选和机器学习，评估了 1816 种 Metal-organic Frameworks (MOFs) 在潮湿空气条件下捕获放射性碘的性能，探索了 MOFs 的结构特征与吸附性能的关系，以识别最佳结构参数。使用 Random Forest 和 CatBoost 算法结合 6 个结构特征、25 个分子特征和 8 个化学特征进行预测，分析显示 Henry's coefficient 和吸附热是最关键的影响因素。研究进一步引入四种分子指纹，特别是前 20 个 MACCS 指纹，揭示六元环结构、氮原子和氧原子对碘吸附的增强作用，为筛选和设计先进 MOFs 材料提供了重要指导。",
      "categories": [
        "cs.LG",
        "cond-mat.mtrl-sci",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "13 page,6 figures, submitted to npjCM",
      "pdf_url": "http://arxiv.org/pdf/2502.15764v1",
      "published_date": "2025-02-14 16:22:28 UTC",
      "updated_date": "2025-02-14 16:22:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:26:42.522498"
    },
    {
      "arxiv_id": "2502.10263v1",
      "title": "Large Language Models and Synthetic Data for Monitoring Dataset Mentions in Research Papers",
      "title_zh": "大型语言模型和合成数据用于监测研究论文中的数据集提及",
      "authors": [
        "Aivin V. Solatorio",
        "Rafael Macalaba",
        "James Liounis"
      ],
      "abstract": "Tracking how data is mentioned and used in research papers provides critical\ninsights for improving data discoverability, quality, and production. However,\nmanually identifying and classifying dataset mentions across vast academic\nliterature is resource-intensive and not scalable. This paper presents a\nmachine learning framework that automates dataset mention detection across\nresearch domains by leveraging large language models (LLMs), synthetic data,\nand a two-stage fine-tuning process. We employ zero-shot extraction from\nresearch papers, an LLM-as-a-Judge for quality assessment, and a reasoning\nagent for refinement to generate a weakly supervised synthetic dataset. The\nPhi-3.5-mini instruct model is pre-fine-tuned on this dataset, followed by\nfine-tuning on a manually annotated subset. At inference, a ModernBERT-based\nclassifier efficiently filters dataset mentions, reducing computational\noverhead while maintaining high recall. Evaluated on a held-out manually\nannotated sample, our fine-tuned model outperforms NuExtract-v1.5 and\nGLiNER-large-v2.1 in dataset extraction accuracy. Our results highlight how\nLLM-generated synthetic data can effectively address training data scarcity,\nimproving generalization in low-resource settings. This framework offers a\npathway toward scalable monitoring of dataset usage, enhancing transparency,\nand supporting researchers, funders, and policymakers in identifying data gaps\nand strengthening data accessibility for informed decision-making.",
      "tldr_zh": "这篇论文提出了一种利用 Large Language Models (LLMs) 和 synthetic data 的机器学习框架，用于自动化监测研究论文中数据集的提及，从而提升数据可发现性、质量和生产效率。框架通过零样本提取、LLM-as-a-Judge 质量评估以及推理代理生成弱监督合成数据集，并对 Phi-3.5-mini instruct 模型进行两阶段微调，结合 ModernBERT-based 分类器在推理阶段过滤提及以减少计算开销。实验结果显示，该模型在手动标注样本上的提取准确性优于 NuExtract-v1.5 和 GLiNER-large-v2.1，提高了在低资源环境下的泛化能力。该方法为可扩展的数据集使用监测提供路径，支持研究者、资助者和政策制定者识别数据缺口并增强数据可访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.DB",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Project GitHub repository at https://github.com/worldbank/ai4data-use",
      "pdf_url": "http://arxiv.org/pdf/2502.10263v1",
      "published_date": "2025-02-14 16:16:02 UTC",
      "updated_date": "2025-02-14 16:16:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:26:54.605773"
    },
    {
      "arxiv_id": "2502.15763v1",
      "title": "Hybrid Offline-online Scheduling Method for Large Language Model Inference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Pang",
        "Kai Li",
        "Ruifeng She",
        "Feifan Wang"
      ],
      "abstract": "With the development of large language models (LLMs), it has become\nincreasingly important to optimize hardware usage and improve throughput. In\nthis paper, we study the inference optimization of the serving system that\ndeploys LLMs. To optimize system throughput and maximize hardware utilization,\nwe formulate the inference optimization problem as a mixed-integer programming\n(MIP) model and propose a hybrid offline-online method as solution. The offline\nmethod improves large-scale inference systems by introducing a Minimizing\nMakespan Bin Packing Problem. We further provide a theoretical lower bound\ncomputation method. Then, we propose an online sorting and preemptive\nscheduling method to better utilize hardware. In the online iteration\nscheduling process, a Lagrangian method is applied to evaluate the cost\nefficiency of inserting prefill stages versus decode stages at each iteration\nand dynamically determine when to preempt decoding tasks and insert prefill\ntasks. Experiments using real-world data from the LLaMA-65B model and the GSM8K\ndataset demonstrate that system utilization improves from 80.2% to 89.1%, and\nthe total inference time decreases from 201.00 to 190.58 seconds. A 100-cases\nstudy shows that our method consistently outperforms the baseline method and\nimproves the utilization rate by 8.0% on average. Finally, we discuss potential\nfuture extensions, including stochastic modeling, reinforcement learning-based\nschedulers, and dynamic decision-making strategies for system throughput and\nhardware utilization.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)的推理优化，提出了一种混合离线-在线调度方法，将问题表述为混合整数规划(MIP)模型，以提升系统吞吐量和硬件利用率。离线方法引入最小化完工时间装箱问题(Minimizing Makespan Bin Packing Problem)并提供理论下界计算，而在线方法采用排序、抢占调度和Lagrangian方法动态评估并插入预填充或解码任务。实验使用LLaMA-65B模型和GSM8K数据集显示，系统利用率从80.2%提高到89.1%，总推理时间从201.00秒减少到190.58秒，并在100个案例中平均提升利用率8.0%。未来扩展可能包括随机建模、基于强化学习的调度器和动态决策策略。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.AR",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15763v1",
      "published_date": "2025-02-14 16:00:00 UTC",
      "updated_date": "2025-02-14 16:00:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:27:06.985690"
    },
    {
      "arxiv_id": "2502.10239v1",
      "title": "Efficient Zero-Order Federated Finetuning of Language Models for Resource-Constrained Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Aboelenien Ahmed",
        "Kilian Pfeiffer",
        "Ramin Khalili",
        "Heba Khdr",
        "Jörg Henkel"
      ],
      "abstract": "Federated fine-tuning offers a promising approach for tuning Large Language\nModels (LLMs) on edge devices while preserving data privacy. However,\nfine-tuning these models on edge devices remains challenging due to high\nmemory, communication, and computational demands. Zero-order optimization with\ntask alignment provides a potential solution, enabling fine-tuning with\ninference-level memory requirements but requires a longer convergence time. In\nthis paper, we propose Federated Split-Perturbation Zero-order Optimization\n(FedSPZO) that divides the network into two blocks, applying a different number\nof perturbations per block in a computationally effective way, achieving faster\nconvergence. Our evaluation shows a $2.5 - 7\\times $ reduction in computation\noverhead compared to zero-order state of the art techniques in federated\nlearning.",
      "tldr_zh": "该论文探讨了在资源受限设备上进行联邦微调（Federated fine-tuning）大型语言模型（LLMs）的挑战，包括高内存、通信和计算需求。作者提出了一种名为 Federated Split-Perturbation Zero-order Optimization (FedSPZO) 的方法，该方法将网络分成两个块，并针对每个块应用不同数量的扰动，以实现更快的收敛速度，同时保持推理级别的内存要求。实验结果显示，FedSPZO 相较于现有的 Zero-order 优化技术，在联邦学习中将计算开销降低了 2.5-7 倍，为隐私保护下的高效 LLM 微调提供了可行解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10239v1",
      "published_date": "2025-02-14 15:49:02 UTC",
      "updated_date": "2025-02-14 15:49:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:27:17.856931"
    },
    {
      "arxiv_id": "2502.10236v2",
      "title": "Shaping Inductive Bias in Diffusion Models through Frequency-Based Noise Control",
      "title_zh": "通过基于频率的噪声控制塑造扩散模型中的归纳偏差",
      "authors": [
        "Thomas Jiralerspong",
        "Berton Earnshaw",
        "Jason Hartford",
        "Yoshua Bengio",
        "Luca Scimeca"
      ],
      "abstract": "Diffusion Probabilistic Models (DPMs) are powerful generative models that\nhave achieved unparalleled success in a number of generative tasks. In this\nwork, we aim to build inductive biases into the training and sampling of\ndiffusion models to better accommodate the target distribution of the data to\nmodel. For topologically structured data, we devise a frequency-based noising\noperator to purposefully manipulate, and set, these inductive biases. We first\nshow that appropriate manipulations of the noising forward process can lead\nDPMs to focus on particular aspects of the distribution to learn. We show that\ndifferent datasets necessitate different inductive biases, and that appropriate\nfrequency-based noise control induces increased generative performance compared\nto standard diffusion. Finally, we demonstrate the possibility of ignoring\ninformation at particular frequencies while learning. We show this in an image\ncorruption and recovery task, where we train a DPM to recover the original\ntarget distribution after severe noise corruption.",
      "tldr_zh": "本文提出了一种通过基于频率的噪声控制来塑造 Diffusion Probabilistic Models (DPMs) 的 inductive biases 方法，旨在更好地适应目标数据分布。该方法引入频率-based noising operator，用于拓扑结构数据，能够操纵噪声前向过程，让 DPMs 更专注于特定分布方面，从而提升生成性能。实验结果表明，这种策略在不同数据集上比标准扩散模型表现出更高的性能，并在图像损坏和恢复任务中成功忽略特定频率的信息，实现原始分布的恢复。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Published as workshop paper at DeLTa and FPI workshops, ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10236v2",
      "published_date": "2025-02-14 15:46:37 UTC",
      "updated_date": "2025-03-12 18:40:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:27:30.379794"
    },
    {
      "arxiv_id": "2502.10226v1",
      "title": "A Multiagent Path Search Algorithm for Large-Scale Coalition Structure Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Redha Taguelmimt",
        "Samir Aknine",
        "Djamila Boukredera",
        "Narayan Changder",
        "Tuomas Sandholm"
      ],
      "abstract": "Coalition structure generation (CSG), i.e. the problem of optimally\npartitioning a set of agents into coalitions to maximize social welfare, is a\nfundamental computational problem in multiagent systems. This problem is\nimportant for many applications where small run times are necessary, including\ntransportation and disaster response. In this paper, we develop SALDAE, a\nmultiagent path finding algorithm for CSG that operates on a graph of coalition\nstructures. Our algorithm utilizes a variety of heuristics and strategies to\nperform the search and guide it. It is an anytime algorithm that can handle\nlarge problems with hundreds and thousands of agents. We show empirically on\nnine standard value distributions, including disaster response and electric\nvehicle allocation benchmarks, that our algorithm enables a rapid finding of\nhigh-quality solutions and compares favorably with other state-of-the-art\nmethods.",
      "tldr_zh": "该论文针对联盟结构生成(CSG)问题，即将代理集最优分区以最大化社会福利，提出了一种多代理路径搜索算法SALDAE。该算法在联盟结构图上运行，利用各种启发式策略和搜索指导方法，能够处理数百到数千个代理，并作为一种anytime算法提供快速响应。实验结果显示，SALDAE在九种标准价值分布上，包括灾害响应和电动车分配基准，快速找到高质量解决方案，并优于其他最先进方法。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.GT",
        "93A16, 68T01",
        "I.2; F.2"
      ],
      "primary_category": "cs.MA",
      "comment": "Long and updated version to the published paper in the Proceedings of\n  the 39th Annual AAAI Conference on Artificial Intelligence (AAAI 2025)",
      "pdf_url": "http://arxiv.org/pdf/2502.10226v1",
      "published_date": "2025-02-14 15:21:27 UTC",
      "updated_date": "2025-02-14 15:21:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:27:41.559108"
    },
    {
      "arxiv_id": "2502.10216v1",
      "title": "Forget the Data and Fine-Tuning! Just Fold the Network to Compress",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Wang",
        "Haris Šikić",
        "Lothar Thiele",
        "Olga Saukh"
      ],
      "abstract": "We introduce model folding, a novel data-free model compression technique\nthat merges structurally similar neurons across layers, significantly reducing\nthe model size without the need for fine-tuning or access to training data.\nUnlike existing methods, model folding preserves data statistics during\ncompression by leveraging k-means clustering, and using novel data-free\ntechniques to prevent variance collapse or explosion. Our theoretical framework\nand experiments across standard benchmarks, including ResNet18 and LLaMA-7B,\ndemonstrate that model folding achieves comparable performance to data-driven\ncompression techniques and outperforms recently proposed data-free methods,\nespecially at high sparsity levels. This approach is particularly effective for\ncompressing large-scale models, making it suitable for deployment in\nresource-constrained environments.",
      "tldr_zh": "本研究提出了一种名为model folding的创新模型压缩技术，通过合并层间结构相似的神经元来显著减少模型大小，而无需依赖训练数据或微调过程。\n该方法利用k-means clustering保留数据统计，并引入新型数据无关技术来防止方差崩溃或爆炸，确保压缩后的模型保持高性能。\n实验结果显示，在ResNet18和LLaMA-7B等基准上，model folding与数据驱动压缩方法相当，并在高稀疏度场景下优于现有数据无关方法，特别适用于资源受限环境的部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This paper has been accepted by The Thirteenth International\n  Conference on Learning Representations(ICLR), 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10216v1",
      "published_date": "2025-02-14 15:10:43 UTC",
      "updated_date": "2025-02-14 15:10:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:27:54.505890"
    },
    {
      "arxiv_id": "2502.10215v1",
      "title": "Do Large Language Models Reason Causally Like Us? Even Better?",
      "title_zh": "大型语言模型是否像我们一样进行因果推理？甚至更好？",
      "authors": [
        "Hanna M. Dettki",
        "Brenden M. Lake",
        "Charley M. Wu",
        "Bob Rehder"
      ],
      "abstract": "Causal reasoning is a core component of intelligence. Large language models\n(LLMs) have shown impressive capabilities in generating human-like text,\nraising questions about whether their responses reflect true understanding or\nstatistical patterns. We compared causal reasoning in humans and four LLMs\nusing tasks based on collider graphs, rating the likelihood of a query variable\noccurring given evidence from other variables. We find that LLMs reason\ncausally along a spectrum from human-like to normative inference, with\nalignment shifting based on model, context, and task. Overall, GPT-4o and\nClaude showed the most normative behavior, including \"explaining away\", whereas\nGemini-Pro and GPT-3.5 did not. Although all agents deviated from the expected\nindependence of causes - Claude the least - they exhibited strong associative\nreasoning and predictive inference when assessing the likelihood of the effect\ngiven its causes. These findings underscore the need to assess AI biases as\nthey increasingly assist human decision-making.",
      "tldr_zh": "本研究探讨大型语言模型（LLMs）是否像人类一样进行因果推理，甚至更出色，通过比较人类和四个LLMs（GPT-4o、Claude、Gemini-Pro、GPT-3.5）在基于collider graphs的任务中的表现。研究任务涉及评估给定证据时查询变量发生的可能性，结果显示LLMs的因果推理沿人类-like到normative inference的光谱变化，取决于模型、上下文和任务。GPT-4o和Claude表现出最规范的行为，包括“explaining away”效应，而Gemini-Pro和GPT-3.5则表现较差。尽管所有模型偏离了预期的原因独立性（independence of causes），Claude的偏差最小，但它们在关联推理（associative reasoning）和预测推理（predictive inference）方面表现出色。这些发现强调了评估AI偏差的必要性，以确保其在辅助人类决策时的可靠性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10215v1",
      "published_date": "2025-02-14 15:09:15 UTC",
      "updated_date": "2025-02-14 15:09:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:28:07.296227"
    },
    {
      "arxiv_id": "2503.05712v1",
      "title": "Automatic Evaluation Metrics for Artificially Generated Scientific Research",
      "title_zh": "针对人工生成科学研究的自动评价指标",
      "authors": [
        "Niklas Höpner",
        "Leon Eshuijs",
        "Dimitrios Alivanistos",
        "Giacomo Zamprogno",
        "Ilaria Tiddi"
      ],
      "abstract": "Foundation models are increasingly used in scientific research, but\nevaluating AI-generated scientific work remains challenging. While expert\nreviews are costly, large language models (LLMs) as proxy reviewers have proven\nto be unreliable. To address this, we investigate two automatic evaluation\nmetrics, specifically citation count prediction and review score prediction. We\nparse all papers of OpenReview and augment each submission with its citation\ncount, reference, and research hypothesis. Our findings reveal that citation\ncount prediction is more viable than review score prediction, and predicting\nscores is more difficult purely from the research hypothesis than from the full\npaper. Furthermore, we show that a simple prediction model based solely on\ntitle and abstract outperforms LLM-based reviewers, though it still falls short\nof human-level consistency.",
      "tldr_zh": "这篇论文探讨了评估AI生成科学研究的自动指标，针对专家审查成本高和LLMs作为代理审查者不可靠的问题，调查了引文计数预测和评论分数预测两种方法。作者解析了OpenReview的所有论文，并为每篇论文添加引文计数、参考和研究假设，以进行分析。研究发现，引文计数预测比评论分数预测更可行，且从研究假设预测分数比从全文更具挑战性；此外，一个基于标题和摘要的简单预测模型优于LLMs-based审查者，但仍无法达到人类审查的一致性。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.05712v1",
      "published_date": "2025-02-14 14:56:14 UTC",
      "updated_date": "2025-02-14 14:56:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:28:20.246594"
    },
    {
      "arxiv_id": "2502.10201v1",
      "title": "Prediction hubs are context-informed frequent tokens in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Beatrix M. G. Nielsen",
        "Iuri Macocco",
        "Marco Baroni"
      ],
      "abstract": "Hubness, the tendency for few points to be among the nearest neighbours of a\ndisproportionate number of other points, commonly arises when applying standard\ndistance measures to high-dimensional data, often negatively impacting\ndistance-based analysis. As autoregressive large language models (LLMs) operate\non high-dimensional representations, we ask whether they are also affected by\nhubness. We first show, theoretically, that the only representation comparison\noperation performed by LLMs, namely that between context and unembedding\nvectors to determine continuation probabilities, is not characterized by the\nconcentration of distances phenomenon that typically causes the appeareance of\nnuisance hubness. We then empirically show that this comparison still leads to\na high degree of hubness, but the hubs in this case do not constitute a\ndisturbance. They are rather the result of context-modulated frequent tokens\noften appearing in the pool of likely candidates for next token prediction. On\nthe other hand, when other distance computations involving LLM representations\nare performed, we do not have the same theoretical guarantees, and, indeed, we\nsee nuisance hubs appear. In summary, our work highlights, on the one hand, how\nhubness, while omnipresent in high-dimensional spaces, is not always a negative\nproperty that needs to be mitigated, and, on the other hand, it shows that\nvarious widely-used LLMs have developed a guessing strategy that consists in\nconstantly assigning a high probability to frequent tokens.",
      "tldr_zh": "本论文探讨了在大型语言模型(LLMs)中出现的hubness现象，即少数点成为许多其他点的最近邻居。研究理论证明，LLMs在比较context和unembedding vectors以预测下一个token时，不受距离集中现象的负面影响，而是表现出有益的hubness，这些hubness源于上下文相关的频繁tokens。实证实验显示，这种现象导致LLMs常为频繁tokens分配高概率，而其他距离计算则可能产生干扰性的nuisance hubs。总体而言，论文强调hubness在高维空间中并非总是负面属性，并揭示了LLMs的常见猜测策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10201v1",
      "published_date": "2025-02-14 14:52:41 UTC",
      "updated_date": "2025-02-14 14:52:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:28:30.617061"
    },
    {
      "arxiv_id": "2502.10200v1",
      "title": "Dynamic Reinforcement Learning for Actors",
      "title_zh": "针对演员的动态强化学习",
      "authors": [
        "Katsunari Shibata"
      ],
      "abstract": "Dynamic Reinforcement Learning (Dynamic RL), proposed in this paper, directly\ncontrols system dynamics, instead of the actor (action-generating neural\nnetwork) outputs at each moment, bringing about a major qualitative shift in\nreinforcement learning (RL) from static to dynamic. The actor is initially\ndesigned to generate chaotic dynamics through the loop with its environment,\nenabling the agent to perform flexible and deterministic exploration. Dynamic\nRL controls global system dynamics using a local index called \"sensitivity,\"\nwhich indicates how much the input neighborhood contracts or expands into the\ncorresponding output neighborhood through each neuron's processing. While\nsensitivity adjustment learning (SAL) prevents excessive convergence of the\ndynamics, sensitivity-controlled reinforcement learning (SRL) adjusts them --\nto converge more to improve reproducibility around better state transitions\nwith positive TD error and to diverge more to enhance exploration around worse\ntransitions with negative TD error. Dynamic RL was applied only to the actor in\nan Actor-Critic RL architecture while applying it to the critic remains a\nchallenge. It was tested on two dynamic tasks and functioned effectively\nwithout external exploration noise or backward computation through time.\nMoreover, it exhibited excellent adaptability to new environments, although\nsome problems remain. Drawing parallels between 'exploration' and 'thinking,'\nthe author hypothesizes that \"exploration grows into thinking through learning\"\nand believes this RL could be a key technique for the emergence of thinking,\nincluding inspiration that cannot be reconstructed from massive existing text\ndata. Finally, despite being presumptuous, the author presents the argument\nthat this research should not proceed due to its potentially fatal risks,\naiming to encourage discussion.",
      "tldr_zh": "这篇论文提出了 Dynamic Reinforcement Learning (Dynamic RL)，它直接控制系统动态而非传统强化学习中 actor 的输出，实现从静态到动态的转变。方法通过设计 actor 生成混沌动态，并利用 sensitivity 指标进行 Sensitivity Adjustment Learning (SAL) 和 Sensitivity-Controlled Reinforcement Learning (SRL)，以防止过度收敛并优化探索和收敛平衡。在实验中，Dynamic RL 在两个动态任务上表现有效，无需外部探索噪声或时间反向计算，并展示了优秀的环境适应性；作者进一步假设探索可通过学习演变为思考，并警告该研究可能带来的潜在致命风险，呼吁讨论。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 20 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10200v1",
      "published_date": "2025-02-14 14:50:05 UTC",
      "updated_date": "2025-02-14 14:50:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:28:43.625043"
    },
    {
      "arxiv_id": "2502.10197v1",
      "title": "MathConstruct: Challenging LLM Reasoning with Constructive Proofs",
      "title_zh": "翻译失败",
      "authors": [
        "Mislav Balunović",
        "Jasper Dekoninck",
        "Nikola Jovanović",
        "Ivo Petrov",
        "Martin Vechev"
      ],
      "abstract": "While Large Language Models (LLMs) demonstrate impressive performance in\nmathematics, existing math benchmarks come with significant limitations. Many\nfocus on problems with fixed ground-truth answers, and are often saturated due\nto problem simplicity or the viability of guessing or memorization. Crucially,\nthey capture only a narrow subset of relevant math problems. To address this\nresearch gap, we introduce \\mc, a new benchmark of 126 challenging problems\nsourced from various math competitions, which targets constructive proofs, a\nwidely encountered problem type requiring the construction of mathematical\nobjects with specific properties. These proofs are particularly suitable for\nLLM evaluation, as solution correctness can be easily verified. Our automated\nverifiers also enable MathConstruct to generate problem variations, used to\nevaluate robustness. State-of-the-art LLMs solve only 54% of MathConstruct\nproblems, highlighting its complexity and importance for LLM evaluation.",
      "tldr_zh": "本研究指出了现有数学基准的局限性，如问题过于简单、易于猜测或记忆，且仅覆盖狭窄子集，从而无法全面评估Large Language Models (LLMs)的推理能力。为此，引入了MathConstruct基准，该基准包含126个来自数学竞赛的挑战性问题，专注于constructive proofs，这些证明要求构建具有特定属性的数学对象，并通过自动化验证器生成问题变体以测试鲁棒性。实验结果显示，最新LLMs仅解决了54%的MathConstruct问题，突显了该基准在提升LLM数学推理评估中的重要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10197v1",
      "published_date": "2025-02-14 14:44:22 UTC",
      "updated_date": "2025-02-14 14:44:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:28:54.008764"
    },
    {
      "arxiv_id": "2502.10195v1",
      "title": "Exploring the Camera Bias of Person Re-identification",
      "title_zh": "翻译失败",
      "authors": [
        "Myungseo Song",
        "Jin-Woo Park",
        "Jong-Seok Lee"
      ],
      "abstract": "We empirically investigate the camera bias of person re-identification (ReID)\nmodels. Previously, camera-aware methods have been proposed to address this\nissue, but they are largely confined to training domains of the models. We\nmeasure the camera bias of ReID models on unseen domains and reveal that camera\nbias becomes more pronounced under data distribution shifts. As a debiasing\nmethod for unseen domain data, we revisit feature normalization on embedding\nvectors. While the normalization has been used as a straightforward solution,\nits underlying causes and broader applicability remain unexplored. We analyze\nwhy this simple method is effective at reducing bias and show that it can be\napplied to detailed bias factors such as low-level image properties and body\nangle. Furthermore, we validate its generalizability across various models and\nbenchmarks, highlighting its potential as a simple yet effective test-time\npostprocessing method for ReID. In addition, we explore the inherent risk of\ncamera bias in unsupervised learning of ReID models. The unsupervised models\nremain highly biased towards camera labels even for seen domain data,\nindicating substantial room for improvement. Based on observations of the\nnegative impact of camera-biased pseudo labels on training, we suggest simple\ntraining strategies to mitigate the bias. By applying these strategies to\nexisting unsupervised learning algorithms, we show that significant performance\nimprovements can be achieved with minor modifications.",
      "tldr_zh": "这篇论文探讨了人重新识别 (ReID) 模型的相机偏差问题，通过实证研究发现，这种偏差在数据分布偏移的未见域上更为明显。研究者重新审视了特征归一化作为一种简单有效的去偏差方法，并分析其原因及其在低级图像属性和身体角度等因素上的适用性，验证了其在各种模型和基准上的泛化潜力。论文还揭示了无监督学习中相机偏差的风险，并提出简单的训练策略来缓解偏差影响，从而显著提升模型性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ICLR 2025 (Spotlight)",
      "pdf_url": "http://arxiv.org/pdf/2502.10195v1",
      "published_date": "2025-02-14 14:39:24 UTC",
      "updated_date": "2025-02-14 14:39:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:29:06.692824"
    },
    {
      "arxiv_id": "2502.10193v1",
      "title": "Merging public elementary schools to reduce racial/ethnic segregation",
      "title_zh": "合并公立小学以减少种族/民族隔离",
      "authors": [
        "Madison Landry",
        "Nabeel Gillani"
      ],
      "abstract": "Diverse schools can help address implicit biases and increase empathy, mutual\nrespect, and reflective thought by fostering connections between students from\ndifferent racial/ethnic, socioeconomic, and other backgrounds. Unfortunately,\ndemographic segregation remains rampant in US public schools, despite over 70\nyears since the passing of federal legislation formally outlawing segregation\nby race. However, changing how students are assigned to schools can help foster\nmore integrated learning environments. In this paper, we explore \"school\nmergers\" as one such under-explored, yet promising, student assignment policy\nchange. School mergers involve merging the school attendance boundaries, or\ncatchment areas, of schools and subsequently changing the grades each school\noffers. We develop an algorithm to simulate elementary school mergers across\n200 large school districts serving 4.5 million elementary school students and\nfind that pairing or tripling schools in this way could reduce racial/ethnic\nsegregation by a median relative 20% -- and as much as nearly 60% in some\ndistricts -- while increasing driving times to schools by an average of a few\nminutes each way. Districts with many interfaces between\nracially/ethnically-disparate neighborhoods tend to be prime candidates for\nmergers. We also compare the expected results of school mergers to other\ntypical integration policies, like redistricting, and find that different\npolicies may be more or less suitable in different places. Finally, we make our\nresults available through a public dashboard for policymakers and community\nmembers to explore further (https://mergers.schooldiversity.org). Together, our\nstudy offers new findings and tools to support integration policy-making across\nUS public school districts.",
      "tldr_zh": "该研究探讨通过“学校合并”（merging schools）政策来减少美国公立小学的种族/民族隔离（racial/ethnic segregation），旨在促进学生多样性以缓解隐性偏见并增强移情和相互尊重。研究开发了一个算法，模拟在200个大型学区合并小学的招生边界和年级，发现这种方法可将隔离程度中位数降低20%，某些学区甚至近60%，同时平均仅增加几分钟的通勤时间。适合合并的学区通常是那些种族/民族社区交界较多的地区，与redistricting等其他整合政策相比，不同策略在不同地方的适用性各异。最后，研究提供了公共仪表板（https://mergers.schooldiversity.org）作为工具，支持决策者和社区成员进一步探索和制定整合政策。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Forthcoming in PNAS Nexus",
      "pdf_url": "http://arxiv.org/pdf/2502.10193v1",
      "published_date": "2025-02-14 14:36:28 UTC",
      "updated_date": "2025-02-14 14:36:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:29:20.922201"
    },
    {
      "arxiv_id": "2502.10178v1",
      "title": "From Markov to Laplace: How Mamba In-Context Learns Markov Chains",
      "title_zh": "翻译失败",
      "authors": [
        "Marco Bondaschi",
        "Nived Rajaraman",
        "Xiuying Wei",
        "Kannan Ramchandran",
        "Razvan Pascanu",
        "Caglar Gulcehre",
        "Michael Gastpar",
        "Ashok Vardhan Makkuva"
      ],
      "abstract": "While transformer-based language models have driven the AI revolution thus\nfar, their computational complexity has spurred growing interest in viable\nalternatives, such as structured state space sequence models (SSMs) and\nSelective SSMs. Among these, Mamba (S6) and its variant Mamba-2 have shown\nremarkable inference speed ups over transformers while achieving comparable or\nsuperior performance on complex language modeling tasks. However, despite these\narchitectural innovations and empirical successes, the fundamental learning\ncapabilities of Mamba remain poorly understood. In this paper, we address this\ngap by studying in-context learning (ICL) on Markov chains and uncovering a\nsurprising phenomenon: unlike transformers, even a single-layer Mamba\nefficiently learns the in-context Laplacian smoothing estimator, which is both\nBayes and minimax optimal, for all Markovian orders. To explain this, we\ntheoretically characterize the representation capacity of Mamba and reveal the\nfundamental role of convolution in enabling it to represent the optimal\nLaplacian smoothing. These theoretical insights align strongly with empirical\nresults and, to the best of our knowledge, represent the first formal\nconnection between Mamba and optimal statistical estimators. Finally, we\noutline promising research directions inspired by these findings.",
      "tldr_zh": "该论文探讨了Mamba模型在Markov链上的in-context learning（ICL）能力，与Transformer模型相比，Mamba展示了更高效的学习机制。研究发现，即使单层Mamba也能学习到in-context Laplacian smoothing估计器，该估计器对所有Markovian阶数均是Bayes和minimax最优的，这得益于Mamba的卷积表示能力。作者通过理论分析和实证验证，首次建立了Mamba与最优统计估计器的正式联系，并为未来语言模型研究提供了新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10178v1",
      "published_date": "2025-02-14 14:13:55 UTC",
      "updated_date": "2025-02-14 14:13:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:29:30.631095"
    },
    {
      "arxiv_id": "2502.10177v2",
      "title": "STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Mingcong Lei",
        "Yiming Zhao",
        "Ge Wang",
        "Zhixin Mai",
        "Shuguang Cui",
        "Yatong Han",
        "Jinke Ren"
      ],
      "abstract": "A key objective of embodied intelligence is enabling agents to perform\nlong-horizon tasks in dynamic environments while maintaining robust\ndecision-making and adaptability. To achieve this goal, we propose the\nSpatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task\nplanning and execution by integrating spatio-temporal memory. STMA is built\nupon three critical components: (1) a spatio-temporal memory module that\ncaptures historical and environmental changes in real time, (2) a dynamic\nknowledge graph that facilitates adaptive spatial reasoning, and (3) a\nplanner-critic mechanism that iteratively refines task strategies. We evaluate\nSTMA in the TextWorld environment on 32 tasks, involving multi-step planning\nand exploration under varying levels of complexity. Experimental results\ndemonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7%\nincrease in average score compared to the state-of-the-art model. The results\nhighlight the effectiveness of spatio-temporal memory in advancing the memory\ncapabilities of embodied agents.",
      "tldr_zh": "本研究提出Spatio-Temporal Memory Agent (STMA)，一个新型框架，旨在提升代理在动态环境中的长时限任务规划能力，包括稳健决策和适应性。\nSTMA 由三个关键组件组成：spatio-temporal memory module 用于实时捕获历史和环境变化、dynamic knowledge graph 用于适应性空间推理，以及planner-critic mechanism 用于迭代优化任务策略。\n在TextWorld环境的32个多步任务上实验评估显示，STMA 成功率比最先进模型提高31.25%，平均分数增加24.7%，证明了spatio-temporal memory 在增强代理记忆能力方面的显著有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10177v2",
      "published_date": "2025-02-14 14:12:09 UTC",
      "updated_date": "2025-03-02 08:14:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:29:43.333949"
    },
    {
      "arxiv_id": "2502.10174v1",
      "title": "Technical Risks of (Lethal) Autonomous Weapons Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Heramb Podar",
        "Alycia Colijn"
      ],
      "abstract": "The autonomy and adaptability of (Lethal) Autonomous Weapons Systems, (L)AWS\nin short, promise unprecedented operational capabilities, but they also\nintroduce profound risks that challenge the principles of control,\naccountability, and stability in international security. This report outlines\nthe key technological risks associated with (L)AWS deployment, emphasizing\ntheir unpredictability, lack of transparency, and operational unreliability,\nwhich can lead to severe unintended consequences.\n  Key Takeaways:\n  1. Proposed advantages of (L)AWS can only be achieved through objectification\nand classification, but a range of systematic risks limit the reliability and\npredictability of classifying algorithms.\n  2. These systematic risks include the black-box nature of AI decision-making,\nsusceptibility to reward hacking, goal misgeneralization and potential for\nemergent behaviors that escape human control.\n  3. (L)AWS could act in ways that are not just unexpected but also\nuncontrollable, undermining mission objectives and potentially escalating\nconflicts.\n  4. Even rigorously tested systems may behave unpredictably and harmfully in\nreal-world conditions, jeopardizing both strategic stability and humanitarian\nprinciples.",
      "tldr_zh": "这篇报告探讨了致命自主武器系统((L)AWS)的技术风险，强调其自主性和适应性可能带来的不可预测性、缺乏透明度和操作不可靠性，从而挑战国际安全的控制、问责性和稳定性。关键风险包括AI决策的黑箱性质、易受奖励黑客(reward hacking)攻击、目标误泛化(goal misgeneralization)以及突发行为的潜在性，这些因素可能导致系统超出人类控制。研究发现，(L)AWS即使经过严格测试，在真实条件下仍可能以不可预见方式行动，破坏任务目标、升级冲突，并威胁战略稳定和人道主义原则。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10174v1",
      "published_date": "2025-02-14 14:09:43 UTC",
      "updated_date": "2025-02-14 14:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:29:54.547901"
    },
    {
      "arxiv_id": "2502.10162v1",
      "title": "Revisiting Generalization Power of a DNN in Terms of Symbolic Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Cheng",
        "Junpeng Zhang",
        "Qihan Ren",
        "Quanshi Zhang"
      ],
      "abstract": "This paper aims to analyze the generalization power of deep neural networks\n(DNNs) from the perspective of interactions. Unlike previous analysis of a\nDNN's generalization power in a highdimensional feature space, we find that the\ngeneralization power of a DNN can be explained as the generalization power of\nthe interactions. We found that the generalizable interactions follow a\ndecay-shaped distribution, while non-generalizable interactions follow a\nspindle-shaped distribution. Furthermore, our theory can effectively\ndisentangle these two types of interactions from a DNN. We have verified that\nour theory can well match real interactions in a DNN in experiments.",
      "tldr_zh": "本文重新审视深度神经网络(DNNs)的泛化能力，从符号交互(interactions)的角度出发，认为DNN的泛化能力本质上源于交互的泛化。研究发现，可泛化的交互遵循衰减形状(decay-shaped)分布，而不可泛化的交互遵循纺锤形状(spindle-shaped)分布。该理论能够有效区分这两种交互类型，并在实验中验证了其与DNN实际交互的良好匹配。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2407.19198",
      "pdf_url": "http://arxiv.org/pdf/2502.10162v1",
      "published_date": "2025-02-14 13:46:14 UTC",
      "updated_date": "2025-02-14 13:46:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:30:06.140013"
    },
    {
      "arxiv_id": "2502.10157v2",
      "title": "SessionRec: Next Session Prediction Paradigm For Generative Sequential Recommendation",
      "title_zh": "SessionRec：用于生成式序列推荐的下一个会话预测范式",
      "authors": [
        "Lei Huang",
        "Hao Guo",
        "Linzhi Peng",
        "Long Zhang",
        "Xiaoteng Wang",
        "Daoyuan Wang",
        "Shichao Wang",
        "Jinpeng Wang",
        "Lei Wang",
        "Sheng Chen"
      ],
      "abstract": "We introduce SessionRec, a novel next-session prediction paradigm (NSPP) for\ngenerative sequential recommendation, addressing the fundamental misalignment\nbetween conventional next-item prediction paradigm (NIPP) and real-world\nrecommendation scenarios. Unlike NIPP's item-level autoregressive generation\nthat contradicts actual session-based user interactions, our framework\nintroduces a session-aware representation learning through hierarchical\nsequence aggregation (intra/inter-session), reducing attention computation\ncomplexity while enabling implicit modeling of massive negative interactions,\nand a session-based prediction objective that better captures users' diverse\ninterests through multi-item recommendation in next sessions. Moreover, we\nfound that incorporating a rank loss for items within the session under the\nnext session prediction paradigm can significantly improve the ranking\neffectiveness of generative sequence recommendation models. We also verified\nthat SessionRec exhibits clear power-law scaling laws similar to those observed\nin LLMs. Extensive experiments conducted on public datasets and online A/B test\nin Meituan App demonstrate the effectiveness of SessionRec. The proposed\nparadigm establishes new foundations for developing industrial-scale generative\nrecommendation systems through its model-agnostic architecture and\ncomputational efficiency.",
      "tldr_zh": "本文提出 SessionRec，一种新的下一会话预测范式 (NSPP)，用于生成式序列推荐 (Generative Sequential Recommendation)，以解决传统下一物品预测范式 (NIPP) 在实际会话交互中的不匹配问题。该框架通过分层序列聚合 (intra/inter-session) 进行会话感知表示学习，减少注意力计算复杂性，并隐式建模大量负交互，同时采用基于会话的预测目标和排名损失来捕捉用户多样兴趣并提升模型排名效果。实验在公共数据集和 Meituan App 的在线 A/B 测试中证明了 SessionRec 的有效性，并展示了类似于 LLM 的幂律缩放定律，为开发工业规模的模型无关推荐系统提供了高效新基础。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10157v2",
      "published_date": "2025-02-14 13:36:20 UTC",
      "updated_date": "2025-02-18 02:41:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:30:19.748592"
    },
    {
      "arxiv_id": "2502.10154v1",
      "title": "Video Soundtrack Generation by Aligning Emotions and Temporal Boundaries",
      "title_zh": "翻译失败",
      "authors": [
        "Serkan Sulun",
        "Paula Viana",
        "Matthew E. P. Davies"
      ],
      "abstract": "We introduce EMSYNC, a video-based symbolic music generation model that\naligns music with a video's emotional content and temporal boundaries. It\nfollows a two-stage framework, where a pretrained video emotion classifier\nextracts emotional features, and a conditional music generator produces MIDI\nsequences guided by both emotional and temporal cues. We introduce boundary\noffsets, a novel temporal conditioning mechanism that enables the model to\nanticipate and align musical chords with scene cuts. Unlike existing models,\nour approach retains event-based encoding, ensuring fine-grained timing control\nand expressive musical nuances. We also propose a mapping scheme to bridge the\nvideo emotion classifier, which produces discrete emotion categories, with the\nemotion-conditioned MIDI generator, which operates on continuous-valued\nvalence-arousal inputs. In subjective listening tests, EMSYNC outperforms\nstate-of-the-art models across all subjective metrics, for music theory-aware\nparticipants as well as the general listeners.",
      "tldr_zh": "本研究引入了EMSYNC，一种基于视频的符号音乐生成模型，能够将音乐与视频的情感内容和时间边界对齐。模型采用两阶段框架：首先，使用预训练的视频情感分类器提取情感特征；其次，通过条件音乐生成器基于情感和时间线索生成MIDI序列，同时引入boundary offsets机制来预测并同步音乐和弦与场景切换。EMSYNC保留了基于事件的编码，确保细粒度的时间控制和音乐表现力，并提出一种映射方案将离散情感类别转换为连续的valence-arousal输入。在主观听力测试中，EMSYNC在所有指标上优于现有模型，适用于音乐理论专家和一般听众。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "cs.MM",
        "eess.AS",
        "eess.IV"
      ],
      "primary_category": "cs.SD",
      "comment": "Submitted to International Joint Conference on Artificial\n  Intelligence (IJCAI) 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10154v1",
      "published_date": "2025-02-14 13:32:59 UTC",
      "updated_date": "2025-02-14 13:32:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:30:30.511208"
    },
    {
      "arxiv_id": "2502.10148v2",
      "title": "Cooperative Multi-Agent Planning with Adaptive Skill Synthesis",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiyuan Li",
        "Wenshuai Zhao",
        "Joni Pajarinen"
      ],
      "abstract": "Despite much progress in training distributed artificial intelligence (AI),\nbuilding cooperative multi-agent systems with multi-agent reinforcement\nlearning (MARL) faces challenges in sample efficiency, interpretability, and\ntransferability. Unlike traditional learning-based methods that require\nextensive interaction with the environment, large language models (LLMs)\ndemonstrate remarkable capabilities in zero-shot planning and complex\nreasoning. However, existing LLM-based approaches heavily rely on text-based\nobservations and struggle with the non-Markovian nature of multi-agent\ninteractions under partial observability. We present COMPASS, a novel\nmulti-agent architecture that integrates vision-language models (VLMs) with a\ndynamic skill library and structured communication for decentralized\nclosed-loop decision-making. The skill library, bootstrapped from\ndemonstrations, evolves via planner-guided tasks to enable adaptive strategies.\nCOMPASS propagates entity information through multi-hop communication under\npartial observability. Evaluations on the improved StarCraft Multi-Agent\nChallenge (SMACv2) demonstrate COMPASS's strong performance against\nstate-of-the-art MARL baselines across both symmetric and asymmetric scenarios.\nNotably, in the symmetric Protoss 5v5 task, COMPASS achieved a 57\\% win rate,\nrepresenting a 30 percentage point advantage over QMIX (27\\%). Project page can\nbe found at https://stellar-entremet-1720bb.netlify.app/.",
      "tldr_zh": "该研究提出COMPASS，一种新型多智能体架构，整合视觉语言模型(VLMs)、动态技能库和结构化通信，以解决多智能体强化学习(MARL)在样本效率、解释性和可转移性方面的挑战。COMPASS从演示引导的技能库出发，通过规划器引导的任务演化实现自适应策略，并在部分可观察环境中利用多跳通信传播实体信息，支持去中心化的闭环决策。与传统LLMs方法不同，它有效处理非马尔可夫性质的多智能体交互。在改进的StarCraft Multi-Agent Challenge (SMACv2)上，COMPASS在对称和不对称场景中优于最先进MARL基线，例如在Protoss 5v5任务中实现57%的胜率，比QMIX高出30个百分点。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10148v2",
      "published_date": "2025-02-14 13:23:18 UTC",
      "updated_date": "2025-05-06 11:03:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:30:43.203272"
    },
    {
      "arxiv_id": "2502.10491v1",
      "title": "F-StrIPE: Fast Structure-Informed Positional Encoding for Symbolic Music Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Manvi Agarwal",
        "Changhong Wang",
        "Gael Richard"
      ],
      "abstract": "While music remains a challenging domain for generative models like\nTransformers, recent progress has been made by exploiting suitable\nmusically-informed priors. One technique to leverage information about musical\nstructure in Transformers is inserting such knowledge into the positional\nencoding (PE) module. However, Transformers carry a quadratic cost in sequence\nlength. In this paper, we propose F-StrIPE, a structure-informed PE scheme that\nworks in linear complexity. Using existing kernel approximation techniques\nbased on random features, we show that F-StrIPE is a generalization of\nStochastic Positional Encoding (SPE). We illustrate the empirical merits of\nF-StrIPE using melody harmonization for symbolic music.",
      "tldr_zh": "该研究提出F-StrIPE，一种快速的结构信息位置编码(Positional Encoding)方案，用于提升Transformer模型在符号音乐生成的性能。F-StrIPE通过基于随机特征的内核近似技术，实现线性复杂度下的音乐结构注入，并作为Stochastic Positional Encoding (SPE)的泛化形式。实验结果显示，在符号音乐的旋律和声化(melody harmonization)任务上，F-StrIPE显著改善了生成效果，解决了Transformer在处理音乐结构时的高计算成本问题。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10491v1",
      "published_date": "2025-02-14 13:15:18 UTC",
      "updated_date": "2025-02-14 13:15:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:30:57.496284"
    },
    {
      "arxiv_id": "2502.10490v1",
      "title": "A Robust Attack: Displacement Backdoor Attack",
      "title_zh": "翻译失败",
      "authors": [
        "Yong Li",
        "Han Gao"
      ],
      "abstract": "As artificial intelligence becomes more prevalent in our lives, people are\nenjoying the convenience it brings, but they are also facing hidden threats,\nsuch as data poisoning and adversarial attacks. These threats can have\ndisastrous consequences for the application of artificial intelligence,\nespecially for some applications that take effect immediately, such as\nautonomous driving and medical fields. Among these threats, backdoor attacks\nhave left a deep impression on people with their concealment and simple\ndeployment, making them a threat that cannot be ignored, however, in the\nprocess of deploying the backdoor model, the backdoor attack often has some\nreasons that make it unsatisfactory in real-world applications, such as jitter\nand brightness changes. Based on this, we propose a highly robust backdoor\nattack that shifts the target sample and combines it with itself to form a\nbackdoor sample, the Displacement Backdoor Attack(DBA). Experimental results\nshow that the DBA attack can resist data augmentation that simulates real-world\ndifferences, such as rotation and cropping.",
      "tldr_zh": "这篇论文针对后门攻击（backdoor attacks）在实际应用中的鲁棒性问题，如抖动和亮度变化，提出了一种新的攻击方法：Displacement Backdoor Attack (DBA)。DBA 通过位移目标样本并与自身结合，形成更稳定的后门样本，从而抵抗真实世界中的数据增强干扰，例如旋转和裁剪。实验结果表明，DBA 显著提高了攻击的鲁棒性，为评估 AI 安全提供了新的视角。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "64",
        "J.0"
      ],
      "primary_category": "cs.CR",
      "comment": "6 pages, 3 figures. arXiv admin note: text overlap with\n  arXiv:2405.16488",
      "pdf_url": "http://arxiv.org/pdf/2502.10490v1",
      "published_date": "2025-02-14 13:15:13 UTC",
      "updated_date": "2025-02-14 13:15:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:31:07.242911"
    },
    {
      "arxiv_id": "2502.10125v1",
      "title": "Learning Relational Tabular Data without Shared Features",
      "title_zh": "翻译失败",
      "authors": [
        "Zhaomin Wu",
        "Shida Wang",
        "Ziyang Wang",
        "Bingsheng He"
      ],
      "abstract": "Learning relational tabular data has gained significant attention recently,\nbut most studies focus on single tables, overlooking the potential of\ncross-table learning. Cross-table learning, especially in scenarios where\ntables lack shared features and pre-aligned data, offers vast opportunities but\nalso introduces substantial challenges. The alignment space is immense, and\ndetermining accurate alignments between tables is highly complex. We propose\nLatent Entity Alignment Learning (Leal), a novel framework enabling effective\ncross-table training without requiring shared features or pre-aligned data.\nLeal operates on the principle that properly aligned data yield lower loss than\nmisaligned data, a concept embodied in its soft alignment mechanism. This\nmechanism is coupled with a differentiable cluster sampler module, ensuring\nefficient scaling to large relational tables. Furthermore, we provide a\ntheoretical proof of the cluster sampler's approximation capacity. Extensive\nexperiments on five real-world and five synthetic datasets show that Leal\nachieves up to a 26.8% improvement in predictive performance compared to\nstate-of-the-art methods, demonstrating its effectiveness and scalability.",
      "tldr_zh": "本论文探讨了在关系表格数据中进行跨表学习的问题，特别是当表缺乏共享特征和预对齐数据时所面临的挑战。作者提出了一种名为Latent Entity Alignment Learning (Leal)的创新框架，该框架利用软对齐机制和可微分聚类采样器模块，通过最小化损失来实现有效的实体对齐，而无需预先要求共享特征或数据对齐。Leal还提供了聚类采样器近似能力的理论证明，以确保其在大型关系表上的可扩展性。在五个真实世界数据集和五个合成数据集的广泛实验中，Leal相较于最先进方法提升了多达26.8%的预测性能，展示了其有效性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10125v1",
      "published_date": "2025-02-14 12:51:07 UTC",
      "updated_date": "2025-02-14 12:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:31:19.387240"
    },
    {
      "arxiv_id": "2502.10489v1",
      "title": "LiveVal: Time-aware Data Valuation via Adaptive Reference Points",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Xu",
        "Zihan Wu",
        "Cong Wang",
        "Xiaohua Jia"
      ],
      "abstract": "Time-aware data valuation enhances training efficiency and model robustness,\nas early detection of harmful samples could prevent months of wasted\ncomputation. However, existing methods rely on model retraining or convergence\nassumptions or fail to capture long-term training dynamics.\n  We propose LiveVal, an efficient time-aware data valuation method with three\nkey designs:\n  1) seamless integration with SGD training for efficient data contribution\nmonitoring; 2) reference-based valuation with normalization for reliable\nbenchmark establishment; and 3) adaptive reference point selection for\nreal-time updating with optimized memory usage.\n  We establish theoretical guarantees for LiveVal's stability and prove that\nits valuations are bounded and directionally aligned with optimization\nprogress. Extensive experiments demonstrate that LiveVal provides efficient\ndata valuation across different modalities and model scales, achieving 180\nspeedup over traditional methods while maintaining robust detection\nperformance.",
      "tldr_zh": "该论文提出LiveVal，一种时间感知数据估值方法，通过自适应参考点设计来提升训练效率和模型鲁棒性，旨在早期检测有害样本以避免计算浪费。LiveVal的关键创新包括与SGD训练的无缝集成、基于参考的估值归一化以及动态参考点选择，实现高效监控和实时更新，同时优化内存使用。理论上，LiveVal确保估值稳定且与优化进度方向一致；实验结果显示，它在不同模态和模型规模下比传统方法快180倍，同时保持可靠的检测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10489v1",
      "published_date": "2025-02-14 12:41:20 UTC",
      "updated_date": "2025-02-14 12:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:31:29.846791"
    },
    {
      "arxiv_id": "2502.10118v1",
      "title": "Image Embedding Sampling Method for Diverse Captioning",
      "title_zh": "翻译失败",
      "authors": [
        "Sania Waheed",
        "Na Min An"
      ],
      "abstract": "Image Captioning for state-of-the-art VLMs has significantly improved over\ntime; however, this comes at the cost of increased computational complexity,\nmaking them less accessible for resource-constrained applications such as\nmobile devices and assistive technologies. Alternatively, smaller VLMs\nprioritize high-level scene descriptions, overlooking finer details that\ncontribute to a richer understanding of an image. In this paper, we introduce a\ntraining-free framework that enhances caption diversity and informativeness by\nexplicitly attending to distinct image regions using a comparably small VLM,\nBLIP, as the backbone. Our approach leverages structured segmentation to\nproduce hierarchical representations that capture both global and localized\nsemantics. Without requiring additional model training, we demonstrate that our\nmethod allows smaller VLMs to achieve performance comparable to larger models\nin terms of image-caption alignment, semantic integrity, and diversity. We\nevaluate our framework on MSCOCO, Flickr30k, and Nocaps test datasets,\nachieving a Div-2 score of 0.735, 0.750, and 0.748 for each dataset\nrespectively, while maintaining strong image-caption relevancy and semantic\nintegrity with the human-annotated captions.",
      "tldr_zh": "本论文提出了一种无训练框架，用于提升图像描述（Image Captioning）的多样性和信息性，针对小型视觉语言模型（VLMs，如BLIP）的问题，该框架通过结构化分割（structured segmentation）显式关注图像的不同区域，生成层次化表示以捕捉全局和局部语义。相比大型VLMs，该方法无需额外训练即可实现与大型模型相当的图像-描述对齐、语义完整性和多样性表现。在MSCOCO、Flickr30k和Nocaps数据集上，框架分别取得了Div-2分数0.735、0.750和0.748，同时保持了与人类标注描述的强相关性。整体而言，这为资源受限应用提供了高效的图像描述解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 5 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.10118v1",
      "published_date": "2025-02-14 12:33:19 UTC",
      "updated_date": "2025-02-14 12:33:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:31:43.544536"
    },
    {
      "arxiv_id": "2502.12181v3",
      "title": "3D ReX: Causal Explanations in 3D Neuroimaging Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Melane Navaratnarajah",
        "Sophie A. Martin",
        "David A. Kelly",
        "Nathan Blake",
        "Hana Chockler"
      ],
      "abstract": "Explainability remains a significant problem for AI models in medical\nimaging, making it challenging for clinicians to trust AI-driven predictions.\nWe introduce 3D ReX, the first causality-based post-hoc explainability tool for\n3D models. 3D ReX uses the theory of actual causality to generate\nresponsibility maps which highlight the regions most crucial to the model's\ndecision. We test 3D ReX on a stroke detection model, providing insight into\nthe spatial distribution of features relevant to stroke.",
      "tldr_zh": "该论文针对AI在医疗成像中的可解释性问题，引入了3D ReX，这是首个基于因果关系的后验解释工具，用于3D模型。3D ReX利用实际因果理论生成responsibility maps，突出模型决策中最重要的区域，从而帮助临床医生理解AI预测。实验在卒中检测模型上验证了其有效性，提供了对卒中相关特征的空间分布洞见，提升了AI的可信度。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "Presented in the 2nd Workshop on Imageomics (Imageomics-AAAI-25),\n  Discovering Biological Knowledge from Images using AI, held as part of\n  AAAI-2025",
      "pdf_url": "http://arxiv.org/pdf/2502.12181v3",
      "published_date": "2025-02-14 12:10:07 UTC",
      "updated_date": "2025-04-29 14:51:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:31:54.196919"
    },
    {
      "arxiv_id": "2502.10097v1",
      "title": "Causal Information Prioritization for Efficient Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hongye Cao",
        "Fan Feng",
        "Tianpei Yang",
        "Jing Huo",
        "Yang Gao"
      ],
      "abstract": "Current Reinforcement Learning (RL) methods often suffer from\nsample-inefficiency, resulting from blind exploration strategies that neglect\ncausal relationships among states, actions, and rewards. Although recent causal\napproaches aim to address this problem, they lack grounded modeling of\nreward-guided causal understanding of states and actions for goal-orientation,\nthus impairing learning efficiency. To tackle this issue, we propose a novel\nmethod named Causal Information Prioritization (CIP) that improves sample\nefficiency by leveraging factored MDPs to infer causal relationships between\ndifferent dimensions of states and actions with respect to rewards, enabling\nthe prioritization of causal information. Specifically, CIP identifies and\nleverages causal relationships between states and rewards to execute\ncounterfactual data augmentation to prioritize high-impact state features under\nthe causal understanding of the environments. Moreover, CIP integrates a\ncausality-aware empowerment learning objective, which significantly enhances\nthe agent's execution of reward-guided actions for more efficient exploration\nin complex environments. To fully assess the effectiveness of CIP, we conduct\nextensive experiments across 39 tasks in 5 diverse continuous control\nenvironments, encompassing both locomotion and manipulation skills learning\nwith pixel-based and sparse reward settings. Experimental results demonstrate\nthat CIP consistently outperforms existing RL methods across a wide range of\nscenarios.",
      "tldr_zh": "该论文针对强化学习（Reinforcement Learning）中的样本效率问题，提出了一种新方法Causal Information Prioritization (CIP)，通过利用factored MDPs推断状态、动作和奖励之间的因果关系，从而优先处理关键信息并提升探索效率。CIP具体包括反事实数据增强（counterfactual data augmentation）来强化高影响状态特征，以及整合causality-aware empowerment learning目标以指导代理执行奖励导向行动。在5个连续控制环境中涵盖的39个任务实验中，CIP在像素-based和稀疏奖励设置下 consistently outperforms现有RL方法，证明了其在复杂环境中的有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10097v1",
      "published_date": "2025-02-14 11:44:17 UTC",
      "updated_date": "2025-02-14 11:44:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:32:07.480904"
    },
    {
      "arxiv_id": "2502.10092v1",
      "title": "A novel approach to data generation in generative model",
      "title_zh": "一种生成模型中数据生成的新颖方法",
      "authors": [
        "JaeHong Kim",
        "Jaewon Shim"
      ],
      "abstract": "Variational Autoencoders (VAEs) and other generative models are widely\nemployed in artificial intelligence to synthesize new data. However, current\napproaches rely on Euclidean geometric assumptions and statistical\napproximations that fail to capture the structured and emergent nature of data\ngeneration. This paper introduces the Convergent Fusion Paradigm (CFP) theory,\na novel geometric framework that redefines data generation by integrating\ndimensional expansion accompanied by qualitative transformation. By modifying\nthe latent space geometry to interact with emergent high-dimensional\nstructures, CFP theory addresses key challenges such as identifiability issues\nand unintended artifacts like hallucinations in Large Language Models (LLMs).\nCFP theory is based on two key conceptual hypotheses that redefine how\ngenerative models structure relationships between data and algorithms. Through\nthe lens of CFP theory, we critically examine existing metric-learning\napproaches. CFP theory advances this perspective by introducing time-reversed\nmetric embeddings and structural convergence mechanisms, leading to a novel\ngeometric approach that better accounts for data generation as a structured\nepistemic process. Beyond its computational implications, CFP theory provides\nphilosophical insights into the ontological underpinnings of data generation.\nBy offering a systematic framework for high-dimensional learning dynamics, CFP\ntheory contributes to establishing a theoretical foundation for understanding\nthe data-relationship structures in AI. Finally, future research in CFP theory\nwill be led to its implications for fully realizing qualitative\ntransformations, introducing the potential of Hilbert space in generative\nmodeling.",
      "tldr_zh": "本论文批评了现有生成模型（如Variational Autoencoders, VAEs）依赖欧氏几何和统计近似，无法捕捉数据的结构化与涌现特性，提出了一种新型几何框架Convergent Fusion Paradigm (CFP)理论，重定义数据生成过程，通过维度扩展和定性转变来修改潜在空间几何。CFP基于两个关键假设，引入时间逆转度量嵌入和结构收敛机制，解决了生成模型中的可识别性问题和幻觉（如Large Language Models, LLMs中的），并为AI数据关系提供计算与哲学洞见。最终，该理论为高维学习动态建立系统框架，并探讨Hilbert space在生成建模中的潜力，为未来AI研究奠定基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "00A30 (Primary), 68T99 (Secondary)",
        "I.2.3; F.4.1"
      ],
      "primary_category": "cs.LG",
      "comment": "47 pages, 2 tables, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.10092v1",
      "published_date": "2025-02-14 11:27:02 UTC",
      "updated_date": "2025-02-14 11:27:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:32:20.976107"
    },
    {
      "arxiv_id": "2502.10090v1",
      "title": "Manual2Skill: Learning to Read Manuals and Acquire Robotic Skills for Furniture Assembly Using Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Chenrui Tie",
        "Shengxiang Sun",
        "Jinxuan Zhu",
        "Yiwei Liu",
        "Jingxiang Guo",
        "Yue Hu",
        "Haonan Chen",
        "Junting Chen",
        "Ruihai Wu",
        "Lin Shao"
      ],
      "abstract": "Humans possess an extraordinary ability to understand and execute complex\nmanipulation tasks by interpreting abstract instruction manuals. For robots,\nhowever, this capability remains a substantial challenge, as they cannot\ninterpret abstract instructions and translate them into executable actions. In\nthis paper, we present Manual2Skill, a novel framework that enables robots to\nperform complex assembly tasks guided by high-level manual instructions. Our\napproach leverages a Vision-Language Model (VLM) to extract structured\ninformation from instructional images and then uses this information to\nconstruct hierarchical assembly graphs. These graphs represent parts,\nsubassemblies, and the relationships between them. To facilitate task\nexecution, a pose estimation model predicts the relative 6D poses of components\nat each assembly step. At the same time, a motion planning module generates\nactionable sequences for real-world robotic implementation. We demonstrate the\neffectiveness of Manual2Skill by successfully assembling several real-world\nIKEA furniture items. This application highlights its ability to manage\nlong-horizon manipulation tasks with both efficiency and precision,\nsignificantly enhancing the practicality of robot learning from instruction\nmanuals. This work marks a step forward in advancing robotic systems capable of\nunderstanding and executing complex manipulation tasks in a manner akin to\nhuman capabilities.",
      "tldr_zh": "本研究提出 Manual2Skill 框架，利用 Vision-Language Models (VLM) 帮助机器人从抽象指令手册中提取结构化信息，并学习执行复杂的家具组装任务。该框架通过构建 hierarchical assembly graphs 来表示零件、子组件及其关系，结合 pose estimation model 预测组件的相对 6D 姿势，以及 motion planning module 生成可执行动作序列，实现高效的层次化任务执行。实验结果显示，Manual2Skill 成功组装了真实 IKEA 家具，提高了机器人处理长时序操作的精度和实用性，为机器人实现类似人类的操纵任务能力迈出了重要一步。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10090v1",
      "published_date": "2025-02-14 11:25:24 UTC",
      "updated_date": "2025-02-14 11:25:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:32:32.024784"
    },
    {
      "arxiv_id": "2502.10089v1",
      "title": "A Hybrid Edge Classifier: Combining TinyML-Optimised CNN with RRAM-CMOS ACAM for Energy-Efficient Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Kieran Woodward",
        "Eiman Kanjo",
        "Georgios Papandroulidakis",
        "Shady Agwa",
        "Themis Prodromakis"
      ],
      "abstract": "In recent years, the development of smart edge computing systems to process\ninformation locally is on the rise. Many near-sensor machine learning (ML)\napproaches have been implemented to introduce accurate and energy efficient\ntemplate matching operations in resource-constrained edge sensing systems, such\nas wearables. To introduce novel solutions that can be viable for extreme edge\ncases, hybrid solutions combining conventional and emerging technologies have\nstarted to be proposed. Deep Neural Networks (DNN) optimised for edge\napplication alongside new approaches of computing (both device and architecture\n-wise) could be a strong candidate in implementing edge ML solutions that aim\nat competitive accuracy classification while using a fraction of the power of\nconventional ML solutions. In this work, we are proposing a hybrid\nsoftware-hardware edge classifier aimed at the extreme edge near-sensor\nsystems. The classifier consists of two parts: (i) an optimised digital tinyML\nnetwork, working as a front-end feature extractor, and (ii) a back-end\nRRAM-CMOS analogue content addressable memory (ACAM), working as a final stage\ntemplate matching system. The combined hybrid system exhibits a competitive\ntrade-off in accuracy versus energy metric with $E_{front-end}$ = $96.23 nJ$\nand $E_{back-end}$ = $1.45 nJ$ for each classification operation compared with\n78.06$\\mu$J for the original teacher model, representing a 792-fold reduction,\nmaking it a viable solution for extreme edge applications.",
      "tldr_zh": "这篇论文提出了一种混合边缘分类器，将TinyML优化的CNN用作前端特征提取器，与RRAM-CMOS ACAM作为后端模板匹配系统相结合，旨在实现高准确性和极低能耗的推理。系统针对资源受限的极端边缘应用，如可穿戴设备，优化了深度神经网络（DNN）与新兴计算技术的集成。实验结果显示，该分类器每次操作的能耗仅为前端96.23 nJ和后端1.45 nJ，总计比原始模型低792倍（从78.06 μJ），为高效的近传感器机器学习提供可行解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10089v1",
      "published_date": "2025-02-14 11:21:36 UTC",
      "updated_date": "2025-02-14 11:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:32:43.170986"
    },
    {
      "arxiv_id": "2502.10487v1",
      "title": "Fast Proxies for LLM Robustness Evaluation",
      "title_zh": "快速代理用于 LLM 鲁棒性评估",
      "authors": [
        "Tim Beyer",
        "Jan Schuchardt",
        "Leo Schwinn",
        "Stephan Günnemann"
      ],
      "abstract": "Evaluating the robustness of LLMs to adversarial attacks is crucial for safe\ndeployment, yet current red-teaming methods are often prohibitively expensive.\nWe compare the ability of fast proxy metrics to predict the real-world\nrobustness of an LLM against a simulated attacker ensemble. This allows us to\nestimate a model's robustness to computationally expensive attacks without\nrequiring runs of the attacks themselves. Specifically, we consider\ngradient-descent-based embedding-space attacks, prefilling attacks, and direct\nprompting. Even though direct prompting in particular does not achieve high\nASR, we find that it and embedding-space attacks can predict attack success\nrates well, achieving $r_p=0.87$ (linear) and $r_s=0.94$ (Spearman rank)\ncorrelations with the full attack ensemble while reducing computational cost by\nthree orders of magnitude.",
      "tldr_zh": "该研究针对评估大型语言模型(LLMs)鲁棒性的高成本问题，提出使用快速代理指标来预测模型对模拟攻击者的真实鲁棒性，从而避免运行昂贵的攻击。方法包括基于梯度下降的embedding-space attacks、prefilling attacks和direct prompting，这些代理指标能有效估算攻击成功率。实验结果显示，direct prompting和embedding-space attacks与完整攻击集合的相关性分别为线性$r_p=0.87$和Spearman秩$r_s=0.94$，同时将计算成本降低了三个数量级。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10487v1",
      "published_date": "2025-02-14 11:15:27 UTC",
      "updated_date": "2025-02-14 11:15:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:32:54.409021"
    },
    {
      "arxiv_id": "2502.10077v1",
      "title": "Towards Empowerment Gain through Causal Structure Learning in Model-Based RL",
      "title_zh": "翻译失败",
      "authors": [
        "Hongye Cao",
        "Fan Feng",
        "Meng Fang",
        "Shaokang Dong",
        "Tianpei Yang",
        "Jing Huo",
        "Yang Gao"
      ],
      "abstract": "In Model-Based Reinforcement Learning (MBRL), incorporating causal structures\ninto dynamics models provides agents with a structured understanding of the\nenvironments, enabling efficient decision. Empowerment as an intrinsic\nmotivation enhances the ability of agents to actively control their\nenvironments by maximizing the mutual information between future states and\nactions. We posit that empowerment coupled with causal understanding can\nimprove controllability, while enhanced empowerment gain can further facilitate\ncausal reasoning in MBRL. To improve learning efficiency and controllability,\nwe propose a novel framework, Empowerment through Causal Learning (ECL), where\nan agent with the awareness of causal dynamics models achieves\nempowerment-driven exploration and optimizes its causal structure for task\nlearning. Specifically, ECL operates by first training a causal dynamics model\nof the environment based on collected data. We then maximize empowerment under\nthe causal structure for exploration, simultaneously using data gathered\nthrough exploration to update causal dynamics model to be more controllable\nthan dense dynamics model without causal structure. In downstream task\nlearning, an intrinsic curiosity reward is included to balance the causality,\nmitigating overfitting. Importantly, ECL is method-agnostic and is capable of\nintegrating various causal discovery methods. We evaluate ECL combined with 3\ncausal discovery methods across 6 environments including pixel-based tasks,\ndemonstrating its superior performance compared to other causal MBRL methods,\nin terms of causal discovery, sample efficiency, and asymptotic performance.",
      "tldr_zh": "这篇论文探讨了在基于模型的强化学习 (MBRL) 中，通过学习因果结构来提升赋权 (Empowerment)，从而提高代理对环境的控制能力和决策效率。作者提出了一种新框架 Empowerment through Causal Learning (ECL)，该框架先基于数据训练因果动态模型，然后通过赋权驱动的探索优化结构，并使用探索数据更新模型，同时在下游任务中加入内在好奇奖励以平衡因果性并避免过拟合。实验结果显示，ECL 与多种因果发现方法结合，在 6 个环境中（包括像素-based 任务）表现出色，在因果发现、样本效率和渐近性能上均优于其他因果 MBRL 方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10077v1",
      "published_date": "2025-02-14 10:59:09 UTC",
      "updated_date": "2025-02-14 10:59:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:33:07.692097"
    },
    {
      "arxiv_id": "2502.10063v1",
      "title": "Strassen Multisystolic Array Hardware Architectures",
      "title_zh": "Strassen 多脉动阵列硬件架构",
      "authors": [
        "Trevor E. Pogue",
        "Nicola Nicolici"
      ],
      "abstract": "While Strassen's matrix multiplication algorithm reduces the complexity of\nnaive matrix multiplication, general-purpose hardware is not suitable for\nachieving the algorithm's promised theoretical speedups. This leaves the\nquestion of if it could be better exploited in custom hardware architectures\ndesigned specifically for executing the algorithm. However, there is limited\nprior work on this and it is not immediately clear how to derive such\narchitectures or if they can ultimately lead to real improvements. We bridge\nthis gap, presenting and evaluating new systolic array architectures that\nefficiently translate the theoretical complexity reductions of Strassen's\nalgorithm directly into hardware resource savings. Furthermore, the\narchitectures are multisystolic array designs that can multiply smaller\nmatrices with higher utilization than single-systolic array designs. The\nproposed designs implemented on FPGA reduce DSP requirements by a factor of\n$1.14^r$ for $r$ implemented Strassen recursion levels, and otherwise require\noverall similar soft logic resources when instantiated to support matrix sizes\ndown to 32x32 and 24x24 at 1-2 levels of Strassen recursion, respectively. We\nevaluate the proposed designs both in isolation and in an end-to-end machine\nlearning accelerator compared to baseline designs and prior works, achieving\nstate-of-the-art performance.",
      "tldr_zh": "这篇论文提出了一种新的 multisystolic array 硬件架构，旨在高效利用 Strassen's 矩阵乘法算法的理论复杂度减少，将其转化为实际硬件资源节省。相比传统单 systolic array 设计，该架构采用多 systolic array 设计，支持更高利用率的矩阵乘法，尤其适用于较小矩阵（如 32x32 或 24x24）。在 FPGA 实现中，该设计通过 r 级 Strassen 递归将 DSP 要求减少了 1.14^r 倍，并在整体软逻辑资源方面与基线类似，同时在端到端机器学习加速器中表现出色，超越现有工作。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted for publication in IEEE Transactions on Very Large Scale\n  Integration (VLSI) Systems; Associated source code available on GitHub at\n  https://github.com/trevorpogue/algebraic-nnhw",
      "pdf_url": "http://arxiv.org/pdf/2502.10063v1",
      "published_date": "2025-02-14 10:40:32 UTC",
      "updated_date": "2025-02-14 10:40:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:33:19.421935"
    },
    {
      "arxiv_id": "2502.10062v1",
      "title": "Adaptive Bi-Level Multi-Robot Task Allocation and Learning under Uncertainty with Temporal Logic Constraints",
      "title_zh": "适应性的双层次多机器人任务分配与学习，在",
      "authors": [
        "Xiaoshan Lin",
        "Roberto Tron"
      ],
      "abstract": "This work addresses the problem of multi-robot coordination under unknown\nrobot transition models, ensuring that tasks specified by Time Window Temporal\nLogic are satisfied with user-defined probability thresholds. We present a\nbi-level framework that integrates (i) high-level task allocation, where tasks\nare assigned based on the robots' estimated task completion probabilities and\nexpected rewards, and (ii) low-level distributed policy learning and execution,\nwhere robots independently optimize auxiliary rewards while fulfilling their\nassigned tasks. To handle uncertainty in robot dynamics, our approach leverages\nreal-time task execution data to iteratively refine expected task completion\nprobabilities and rewards, enabling adaptive task allocation without explicit\nrobot transition models. We theoretically validate the proposed algorithm,\ndemonstrating that the task assignments meet the desired probability thresholds\nwith high confidence. Finally, we demonstrate the effectiveness of our\nframework through comprehensive simulations.",
      "tldr_zh": "这篇论文提出了一种自适应双层框架，用于在不确定条件下进行多机器人任务分配和学习，确保满足 Time Window Temporal Logic 指定的任务概率阈值。高层任务分配基于机器人估计的任务完成概率和预期奖励进行动态分配，而底层则采用分布式策略学习，让机器人独立优化辅助奖励并执行任务。该框架利用实时任务执行数据迭代精炼概率和奖励，实现无显式机器人过渡模型的自适应机制。理论分析和模拟实验证明，该算法能以高置信度满足概率要求，并在多机器人协调中表现出色。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted as a full paper at AAMAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10062v1",
      "published_date": "2025-02-14 10:39:21 UTC",
      "updated_date": "2025-02-14 10:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:33:30.754694"
    },
    {
      "arxiv_id": "2503.05711v1",
      "title": "Labeling Synthetic Content: User Perceptions of Warning Label Designs for AI-generated Content on Social Media",
      "title_zh": "翻译失败",
      "authors": [
        "Dilrukshi Gamage",
        "Dilki Sewwandi",
        "Min Zhang",
        "Arosha Bandara"
      ],
      "abstract": "In this research, we explored the efficacy of various warning label designs\nfor AI-generated content on social media platforms e.g., deepfakes. We devised\nand assessed ten distinct label design samples that varied across the\ndimensions of sentiment, color/iconography, positioning, and level of detail.\nOur experimental study involved 911 participants randomly assigned to these ten\nlabel designs and a control group evaluating social media content. We explored\ntheir perceptions relating to 1. Belief in the content being AI-generated, 2.\nTrust in the labels and 3. Social Media engagement perceptions of the content.\nThe results demonstrate that the presence of labels had a significant effect on\nthe users belief that the content is AI generated, deepfake, or edited by AI.\nHowever their trust in the label significantly varied based on the label\ndesign. Notably, having labels did not significantly change their engagement\nbehaviors, such as like, comment, and sharing. However, there were significant\ndifferences in engagement based on content type: political and entertainment.\nThis investigation contributes to the field of human computer interaction by\ndefining a design space for label implementation and providing empirical\nsupport for the strategic use of labels to mitigate the risks associated with\nsynthetically generated media.",
      "tldr_zh": "本研究探讨了社交媒体上 AI-generated content（如 deepfakes）的警告标签设计对用户感知的影响，设计并评估了 10 种标签，这些标签在情感、颜色/图标、位置和细节级别上有所差异。实验涉及 911 名参与者，通过随机分配和对照组评估了用户对内容真实性的信念、对标签的信任以及社交媒体互动行为（如点赞、评论和分享）。结果显示，标签显著提升了用户相信内容为 AI 生成的可能性，但信任度因设计而异，且虽未改变整体互动行为，却受内容类型（如政治或娱乐）影响。该研究为 human computer interaction 领域提供了标签实施的设计空间和经验支持，以缓解合成媒体的风险。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "H.4.0; J.7; H.5.1"
      ],
      "primary_category": "cs.HC",
      "comment": "This is a pre print longer version of a paper accepted to CHI 2025;\n  after rebuttal we had to short the paper to 25 pages. Currently its in\n  overleaf manuscript format with one column. All data for the file is in the\n  osf link",
      "pdf_url": "http://arxiv.org/pdf/2503.05711v1",
      "published_date": "2025-02-14 10:35:42 UTC",
      "updated_date": "2025-02-14 10:35:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:33:44.514946"
    },
    {
      "arxiv_id": "2503.16442v1",
      "title": "Situational Agency: The Framework for Designing Behavior in Agent-based art",
      "title_zh": "翻译失败",
      "authors": [
        "Ary-Yue Huang",
        "Varvara Guljajeva"
      ],
      "abstract": "In the context of artificial life art and agent-based art, this paper draws\non Simon Penny's {\\itshape Aesthetic of Behavior} theory and Sofian Audry's\ndiscussions on behavior computation to examine how artists design agent\nbehaviors and the ensuing aesthetic experiences. We advocate for integrating\nthe environment in which agents operate as the context for behavioral design,\npositing that the environment emerges through continuous interactions among\nagents, audiences, and other entities, forming an evolving network of meanings\ngenerated by these interactions. Artists create contexts by deploying and\nguiding these computational systems, audience participation, and agent\nbehaviors through artist strategies. This framework is developed by analysing\ntwo categories of agent-based artworks, exploring the intersection of\ncomputational systems, audience participation, and artistic strategies in\ncreating aesthetic experiences. This paper seeks to provide a contextual\nfoundation and framework for designing agents' behaviors by conducting a\ncomparative study focused on behavioural design strategies by the artists.",
      "tldr_zh": "这篇论文基于 Simon Penny 的 Aesthetic of Behavior 理论和 Sofian Audry 的行为计算讨论，提出 Situational Agency 框架，用于在 agent-based art 中设计代理行为及其美学体验。框架强调将代理运作的环境视为核心上下文，该环境通过代理、观众和其他实体间的持续互动演变，形成动态的意义网络。艺术家通过部署计算系统、引导观众参与和实施艺术策略来创建和塑造这些行为。最终，该研究通过分析两类代理-based 艺术作品，进行比较研究，为代理行为设计提供了一个情境化的理论基础和实践指导。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "J.5"
      ],
      "primary_category": "cs.HC",
      "comment": "8 pages,5 figures, accetped by 30th International Symposium on\n  Electronic Art (ISEA)",
      "pdf_url": "http://arxiv.org/pdf/2503.16442v1",
      "published_date": "2025-02-14 10:14:09 UTC",
      "updated_date": "2025-02-14 10:14:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:33:55.427869"
    },
    {
      "arxiv_id": "2502.10050v1",
      "title": "A Survey on LLM-powered Agents for Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Qiyao Peng",
        "Hongtao Liu",
        "Hua Huang",
        "Qing Yang",
        "Minglai Shao"
      ],
      "abstract": "Recommender systems are essential components of many online platforms, yet\ntraditional approaches still struggle with understanding complex user\npreferences and providing explainable recommendations. The emergence of Large\nLanguage Model (LLM)-powered agents offers a promising approach by enabling\nnatural language interactions and interpretable reasoning, potentially\ntransforming research in recommender systems. This survey provides a systematic\nreview of the emerging applications of LLM-powered agents in recommender\nsystems. We identify and analyze three key paradigms in current research: (1)\nRecommender-oriented approaches, which leverage intelligent agents to enhance\nthe fundamental recommendation mechanisms; (2) Interaction-oriented approaches,\nwhich facilitate dynamic user engagement through natural dialogue and\ninterpretable suggestions; and (3) Simulation-oriented approaches, which employ\nmulti-agent frameworks to model complex user-item interactions and system\ndynamics. Beyond paradigm categorization, we analyze the architectural\nfoundations of LLM-powered recommendation agents, examining their essential\ncomponents: profile construction, memory management, strategic planning, and\naction execution. Our investigation extends to a comprehensive analysis of\nbenchmark datasets and evaluation frameworks in this domain. This systematic\nexamination not only illuminates the current state of LLM-powered agent\nrecommender systems but also charts critical challenges and promising research\ndirections in this transformative field.",
      "tldr_zh": "本调查系统审视了Large Language Model (LLM)-powered agents在推荐系统中的应用，旨在解决传统方法在理解复杂用户偏好和提供可解释推荐方面的局限。研究将当前工作分类为三个关键范式：Recommender-oriented approaches（增强推荐机制）、Interaction-oriented approaches（通过自然对话促进用户互动）和Simulation-oriented approaches（利用多代理框架模拟用户-物品互动）。此外，论文分析了这些代理的架构基础，包括profile construction、memory management、strategic planning和action execution，并评估了相关基准数据集和评估框架，同时指出了关键挑战和未来研究方向。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10050v1",
      "published_date": "2025-02-14 09:57:07 UTC",
      "updated_date": "2025-02-14 09:57:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:34:07.195939"
    },
    {
      "arxiv_id": "2502.10047v1",
      "title": "Janus: Collaborative Vision Transformer Under Dynamic Network Environment",
      "title_zh": "Janus：动态网络环境下的协作视觉Transformer",
      "authors": [
        "Linyi Jiang",
        "Silvery D. Fu",
        "Yifei Zhu",
        "Bo Li"
      ],
      "abstract": "Vision Transformers (ViTs) have outperformed traditional Convolutional Neural\nNetwork architectures and achieved state-of-the-art results in various computer\nvision tasks. Since ViTs are computationally expensive, the models either have\nto be pruned to run on resource-limited edge devices only or have to be\nexecuted on remote cloud servers after receiving the raw data transmitted over\nfluctuating networks. The resulting degraded performance or high latency all\nhinder their widespread applications. In this paper, we present Janus, the\nfirst framework for low-latency cloud-device collaborative Vision Transformer\ninference over dynamic networks. Janus overcomes the intrinsic model\nlimitations of ViTs and realizes collaboratively executing ViT models on both\ncloud and edge devices, achieving low latency, high accuracy, and low\ncommunication overhead. Specifically, Janus judiciously combines token pruning\ntechniques with a carefully designed fine-to-coarse model splitting policy and\nnon-static mixed pruning policy. It attains a balance between accuracy and\nlatency by dynamically selecting the optimal pruning level and split point.\nExperimental results across various tasks demonstrate that Janus enhances\nthroughput by up to 5.15 times and reduces latency violation ratios by up to\n98.7% when compared with baseline approaches under various network\nenvironments.",
      "tldr_zh": "该论文提出 Janus 框架，这是首个针对动态网络环境的低延迟云-设备协作 Vision Transformers (ViTs) 推理系统，旨在解决 ViTs 计算密集导致的性能下降和延迟问题。\nJanus 通过整合 token pruning 技术、fine-to-coarse 模型分割策略以及非静态混合修剪策略，动态选择最佳修剪级别和分割点，从而平衡准确性、延迟和通信开销。\n实验结果表明，在各种任务和网络环境中，Janus 相比基线方法提升吞吐量高达 5.15 倍，并将延迟违规比率降低高达 98.7%。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "Accepted for publication in IEEE INFOCOM 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.10047v1",
      "published_date": "2025-02-14 09:49:52 UTC",
      "updated_date": "2025-02-14 09:49:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:34:19.954106"
    },
    {
      "arxiv_id": "2502.10044v1",
      "title": "Unsupervised Entity Alignment Based on Personalized Discriminative Rooted Tree",
      "title_zh": "基于个性化判别根树的无监督实体对齐",
      "authors": [
        "Yaming Yang",
        "Zhe Wang",
        "Ziyu Guan",
        "Wei Zhao",
        "Xinyan Huang",
        "Xiaofei He"
      ],
      "abstract": "Entity Alignment (EA) is to link potential equivalent entities across\ndifferent knowledge graphs (KGs). Most existing EA methods are supervised as\nthey require the supervision of seed alignments, i.e., manually specified\naligned entity pairs. Very recently, several EA studies have made some attempts\nto get rid of seed alignments. Despite achieving preliminary progress, they\nstill suffer two limitations: (1) The entity embeddings produced by their\nGNN-like encoders lack personalization since some of the aggregation subpaths\nare shared between different entities. (2) They cannot fully alleviate the\ndistribution distortion issue between candidate KGs due to the absence of the\nsupervised signal. In this work, we propose a novel unsupervised entity\nalignment approach called UNEA to address the above two issues. First, we\nparametrically sample a tree neighborhood rooted at each entity, and\naccordingly develop a tree attention aggregation mechanism to extract a\npersonalized embedding for each entity. Second, we introduce an auxiliary task\nof maximizing the mutual information between the input and the output of the KG\nencoder, to regularize the model and prevent the distribution distortion.\nExtensive experiments show that our UNEA achieves a new state-of-the-art for\nthe unsupervised EA task, and can even outperform many existing supervised EA\nbaselines.",
      "tldr_zh": "实体对齐（EA）任务旨在链接不同知识图谱（KGs）中潜在等价实体，但现有无监督方法存在实体嵌入缺乏个性化以及分布失真等问题。本文提出了一种新型无监督方法UNEA，通过为每个实体参数化采样以实体为根的树邻域，并采用树注意力聚合机制来提取个性化实体嵌入，同时引入最大化互信息辅助任务以正则化模型并缓解分布失真。实验结果表明，UNEA在无监督EA任务中实现了新的最先进性能，甚至超过了诸多监督EA基线方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10044v1",
      "published_date": "2025-02-14 09:45:39 UTC",
      "updated_date": "2025-02-14 09:45:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:34:31.959223"
    },
    {
      "arxiv_id": "2502.10038v2",
      "title": "POI-Enhancer: An LLM-based Semantic Enhancement Framework for POI Representation Learning",
      "title_zh": "POI-Enhancer：基于 LLM 的语义增强框架，用于 POI 表示学习",
      "authors": [
        "Jiawei Cheng",
        "Jingyuan Wang",
        "Yichuan Zhang",
        "Jiahao Ji",
        "Yuanshao Zhu",
        "Zhibo Zhang",
        "Xiangyu Zhao"
      ],
      "abstract": "POI representation learning plays a crucial role in handling tasks related to\nuser mobility data. Recent studies have shown that enriching POI\nrepresentations with multimodal information can significantly enhance their\ntask performance. Previously, the textual information incorporated into POI\nrepresentations typically involved only POI categories or check-in content,\nleading to relatively weak textual features in existing methods. In contrast,\nlarge language models (LLMs) trained on extensive text data have been found to\npossess rich textual knowledge. However leveraging such knowledge to enhance\nPOI representation learning presents two key challenges: first, how to extract\nPOI-related knowledge from LLMs effectively, and second, how to integrate the\nextracted information to enhance POI representations. To address these\nchallenges, we propose POI-Enhancer, a portable framework that leverages LLMs\nto improve POI representations produced by classic POI learning models. We\nfirst design three specialized prompts to extract semantic information from\nLLMs efficiently. Then, the Dual Feature Alignment module enhances the quality\nof the extracted information, while the Semantic Feature Fusion module\npreserves its integrity. The Cross Attention Fusion module then fully\nadaptively integrates such high-quality information into POI representations\nand Multi-View Contrastive Learning further injects human-understandable\nsemantic information into these representations. Extensive experiments on three\nreal-world datasets demonstrate the effectiveness of our framework, showing\nsignificant improvements across all baseline representations.",
      "tldr_zh": "本文提出POI-Enhancer框架，利用大型语言模型(LLMs)来增强POI表示学习，通过提取丰富的文本知识来解决现有方法文本特征弱的问题。框架设计了三个专门的prompts提取POI相关语义信息，并引入Dual Feature Alignment、Semantic Feature Fusion和Cross Attention Fusion模块来提升信息质量和整合性，同时Multi-View Contrastive Learning注入可理解的语义信息。实验在三个真实数据集上证明，该框架显著提高了基线POI表示的表现，展示了其有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "AAAI 25",
      "pdf_url": "http://arxiv.org/pdf/2502.10038v2",
      "published_date": "2025-02-14 09:34:24 UTC",
      "updated_date": "2025-03-04 00:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:34:43.124221"
    },
    {
      "arxiv_id": "2502.12180v1",
      "title": "ClusMFL: A Cluster-Enhanced Framework for Modality-Incomplete Multimodal Federated Learning in Brain Imaging Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Xinpeng Wang",
        "Rong Zhou",
        "Han Xie",
        "Xiaoying Tang",
        "Lifang He",
        "Carl Yang"
      ],
      "abstract": "Multimodal Federated Learning (MFL) has emerged as a promising approach for\ncollaboratively training multimodal models across distributed clients,\nparticularly in healthcare domains. In the context of brain imaging analysis,\nmodality incompleteness presents a significant challenge, where some\ninstitutions may lack specific imaging modalities (e.g., PET, MRI, or CT) due\nto privacy concerns, device limitations, or data availability issues. While\nexisting work typically assumes modality completeness or oversimplifies\nmissing-modality scenarios, we simulate a more realistic setting by considering\nboth client-level and instance-level modality incompleteness in this study.\nBuilding on this realistic simulation, we propose ClusMFL, a novel MFL\nframework that leverages feature clustering for cross-institutional brain\nimaging analysis under modality incompleteness. Specifically, ClusMFL utilizes\nthe FINCH algorithm to construct a pool of cluster centers for the feature\nembeddings of each modality-label pair, effectively capturing fine-grained data\ndistributions. These cluster centers are then used for feature alignment within\neach modality through supervised contrastive learning, while also acting as\nproxies for missing modalities, allowing cross-modal knowledge transfer.\nFurthermore, ClusMFL employs a modality-aware aggregation strategy, further\nenhancing the model's performance in scenarios with severe modality\nincompleteness. We evaluate the proposed framework on the ADNI dataset,\nutilizing structural MRI and PET scans. Extensive experimental results\ndemonstrate that ClusMFL achieves state-of-the-art performance compared to\nvarious baseline methods across varying levels of modality incompleteness,\nproviding a scalable solution for cross-institutional brain imaging analysis.",
      "tldr_zh": "本文提出 ClusMFL 框架，用于解决 Multimodal Federated Learning (MFL) 在脑部成像分析中的模态不完整性问题，包括客户端级和实例级缺失场景（如 PET 或 MRI 模态）。该框架利用 FINCH 算法进行特征聚类，构建模态-标签对的聚类中心，通过监督对比学习实现特征对齐和跨模态知识转移，并采用模态感知聚合策略增强性能。实验在 ADNI 数据集上使用 MRI 和 PET 扫描进行评估，结果显示 ClusMFL 在不同模态不完整性水平下，优于基线方法，提供了一个可扩展的跨机构脑部成像分析解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12180v1",
      "published_date": "2025-02-14 09:33:59 UTC",
      "updated_date": "2025-02-14 09:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:34:56.296574"
    },
    {
      "arxiv_id": "2502.12179v1",
      "title": "Identifiable Steering via Sparse Autoencoding of Multi-Concept Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Shruti Joshi",
        "Andrea Dittadi",
        "Sébastien Lachapelle",
        "Dhanya Sridhar"
      ],
      "abstract": "Steering methods manipulate the representations of large language models\n(LLMs) to induce responses that have desired properties, e.g., truthfulness,\noffering a promising approach for LLM alignment without the need for\nfine-tuning. Traditionally, steering has relied on supervision, such as from\ncontrastive pairs of prompts that vary in a single target concept, which is\ncostly to obtain and limits the speed of steering research. An appealing\nalternative is to use unsupervised approaches such as sparse autoencoders\n(SAEs) to map LLM embeddings to sparse representations that capture\nhuman-interpretable concepts. However, without further assumptions, SAEs may\nnot be identifiable: they could learn latent dimensions that entangle multiple\nconcepts, leading to unintentional steering of unrelated properties. We\nintroduce Sparse Shift Autoencoders (SSAEs) that instead map the differences\nbetween embeddings to sparse representations. Crucially, we show that SSAEs are\nidentifiable from paired observations that vary in \\textit{multiple unknown\nconcepts}, leading to accurate steering of single concepts without the need for\nsupervision. We empirically demonstrate accurate steering across semi-synthetic\nand real-world language datasets using Llama-3.1 embeddings.",
      "tldr_zh": "本研究提出 Sparse Shift Autoencoders (SSAEs)，一种无监督方法，用于操纵大语言模型 (LLMs) 的表示，实现可识别的 steering，例如提升模型的真实性，而无需昂贵的监督数据。SSAEs 通过映射嵌入之间的差异到稀疏表示，从多未知概念的配对观察中学习，确保单一概念的准确 steering，避免传统 sparse autoencoders (SAEs) 中概念纠缠的问题。在实验中，SSAEs 在半合成和真实语言数据集上，使用 Llama-3.1 嵌入，展示了有效的 steering 性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.12179v1",
      "published_date": "2025-02-14 08:49:41 UTC",
      "updated_date": "2025-02-14 08:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:35:07.636944"
    },
    {
      "arxiv_id": "2502.10012v1",
      "title": "Dream to Drive: Model-Based Vehicle Control Using Analytic World Models",
      "title_zh": "翻译失败",
      "authors": [
        "Asen Nachkov",
        "Danda Pani Paudel",
        "Jan-Nico Zaech",
        "Davide Scaramuzza",
        "Luc Van Gool"
      ],
      "abstract": "Differentiable simulators have recently shown great promise for training\nautonomous vehicle controllers. Being able to backpropagate through them, they\ncan be placed into an end-to-end training loop where their known dynamics turn\ninto useful priors for the policy to learn, removing the typical black box\nassumption of the environment. So far, these systems have only been used to\ntrain policies. However, this is not the end of the story in terms of what they\ncan offer. Here, for the first time, we use them to train world models.\nSpecifically, we present three new task setups that allow us to learn next\nstate predictors, optimal planners, and optimal inverse states. Unlike analytic\npolicy gradients (APG), which requires the gradient of the next simulator state\nwith respect to the current actions, our proposed setups rely on the gradient\nof the next state with respect to the current state. We call this approach\nAnalytic World Models (AWMs) and showcase its applications, including how to\nuse it for planning in the Waymax simulator. Apart from pushing the limits of\nwhat is possible with such simulators, we offer an improved training recipe\nthat increases performance on the large-scale Waymo Open Motion dataset by up\nto 12% compared to baselines at essentially no additional cost.",
      "tldr_zh": "该论文提出了一种基于 Analytic World Models (AWM) 的方法，利用可微分模拟器训练自动驾驶车辆控制系统，通过学习下一个状态预测器、最优规划器和最优逆状态来提升性能，与传统的 Analytic Policy Gradients (APG) 不同，AWM 依赖于下一个状态相对于当前状态的梯度。研究首次将这些模拟器用于训练世界模型，而不是仅限于策略训练，并引入了三个新任务设置以实现更精确的车辆控制。实验结果显示，在 Waymax 模拟器中应用 AWM 后，模型在 Waymo Open Motion 数据集上的性能提高了高达 12%，且几乎没有额外成本。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10012v1",
      "published_date": "2025-02-14 08:46:49 UTC",
      "updated_date": "2025-02-14 08:46:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:35:19.901549"
    },
    {
      "arxiv_id": "2502.10486v1",
      "title": "VLM-Guard: Safeguarding Vision-Language Models via Fulfilling Safety Alignment Gap",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Liu",
        "Fei Wang",
        "Chaowei Xiao",
        "Muhao Chen"
      ],
      "abstract": "The emergence of vision language models (VLMs) comes with increased safety\nconcerns, as the incorporation of multiple modalities heightens vulnerability\nto attacks. Although VLMs can be built upon LLMs that have textual safety\nalignment, it is easily undermined when the vision modality is integrated. We\nattribute this safety challenge to the modality gap, a separation of image and\ntext in the shared representation space, which blurs the distinction between\nharmful and harmless queries that is evident in LLMs but weakened in VLMs. To\navoid safety decay and fulfill the safety alignment gap, we propose VLM-Guard,\nan inference-time intervention strategy that leverages the LLM component of a\nVLM as supervision for the safety alignment of the VLM. VLM-Guard projects the\nrepresentations of VLM into the subspace that is orthogonal to the safety\nsteering direction that is extracted from the safety-aligned LLM. Experimental\nresults on three malicious instruction settings show the effectiveness of\nVLM-Guard in safeguarding VLM and fulfilling the safety alignment gap between\nVLM and its LLM component.",
      "tldr_zh": "视觉语言模型(VLMs)在整合视觉模态后，面临安全挑战，因为模态间隙(modality gap)导致有害和无害查询的区分模糊，从而削弱了基于安全对齐的LLMs的保护。论文提出VLM-Guard，一种推理时的干预策略，利用VLM中的LLM组件作为监督，将VLM的表示投影到与从安全对齐LLM提取的安全导向方向正交的子空间，从而填补安全对齐差距。实验结果显示，在三种恶意指令设置中，VLM-Guard显著提升了VLM的安全性，证明了其有效性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.CR",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2502.10486v1",
      "published_date": "2025-02-14 08:44:43 UTC",
      "updated_date": "2025-02-14 08:44:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:35:31.410758"
    },
    {
      "arxiv_id": "2502.09994v1",
      "title": "Decision Information Meets Large Language Models: The Future of Explainable Operations Research",
      "title_zh": "决策信息与大型语言模型的结合：可解释运筹学的未来",
      "authors": [
        "Yansen Zhang",
        "Qingcan Kang",
        "Wing Yin Yu",
        "Hailei Gong",
        "Xiaojin Fu",
        "Xiongwei Han",
        "Tao Zhong",
        "Chen Ma"
      ],
      "abstract": "Operations Research (OR) is vital for decision-making in many industries.\nWhile recent OR methods have seen significant improvements in automation and\nefficiency through integrating Large Language Models (LLMs), they still\nstruggle to produce meaningful explanations. This lack of clarity raises\nconcerns about transparency and trustworthiness in OR applications. To address\nthese challenges, we propose a comprehensive framework, Explainable Operations\nResearch (EOR), emphasizing actionable and understandable explanations\naccompanying optimization. The core of EOR is the concept of Decision\nInformation, which emerges from what-if analysis and focuses on evaluating the\nimpact of complex constraints (or parameters) changes on decision-making.\nSpecifically, we utilize bipartite graphs to quantify the changes in the OR\nmodel and adopt LLMs to improve the explanation capabilities. Additionally, we\nintroduce the first industrial benchmark to rigorously evaluate the\neffectiveness of explanations and analyses in OR, establishing a new standard\nfor transparency and clarity in the field.",
      "tldr_zh": "该研究探讨了 Operations Research (OR) 在整合 Large Language Models (LLMs) 后面临的解释不足问题，导致透明度和可信度挑战。为解决此，提出 Explainable Operations Research (EOR) 框架，强调提供可行动的优化解释。EOR 的核心是 Decision Information，通过 what-if 分析和 bipartite graphs 量化约束变化对决策的影响，并利用 LLMs 增强解释能力。该框架还引入首个工业基准，用于评估 OR 解释的有效性，从而提升行业的透明度标准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09994v1",
      "published_date": "2025-02-14 08:25:06 UTC",
      "updated_date": "2025-02-14 08:25:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:35:42.827050"
    },
    {
      "arxiv_id": "2502.09990v2",
      "title": "X-Boundary: Establishing Exact Safety Boundary to Shield LLMs from Multi-Turn Jailbreaks without Compromising Usability",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoya Lu",
        "Dongrui Liu",
        "Yi Yu",
        "Luxin Xu",
        "Jing Shao"
      ],
      "abstract": "Despite the rapid development of safety alignment techniques for LLMs,\ndefending against multi-turn jailbreaks is still a challenging task. In this\npaper, we conduct a comprehensive comparison, revealing that some existing\ndefense methods can improve the robustness of LLMs against multi-turn\njailbreaks but compromise usability, i.e., reducing general capabilities or\ncausing the over-refusal problem. From the perspective of mechanism\ninterpretability of LLMs, we discover that these methods fail to establish a\nboundary that exactly distinguishes safe and harmful feature representations.\nTherefore, boundary-safe representations close to harmful representations are\ninevitably disrupted, leading to a decline in usability. To address this issue,\nwe propose X-Boundary to push harmful representations away from boundary-safe\nrepresentations and obtain an exact distinction boundary. In this way, harmful\nrepresentations can be precisely erased without disrupting safe ones.\nExperimental results show that X-Boundary achieves state-of-the-art defense\nperformance against multi-turn jailbreaks, while reducing the over-refusal rate\nby about 20% and maintaining nearly complete general capability. Furthermore,\nwe theoretically prove and empirically verify that X-Boundary can accelerate\nthe convergence process during training. Please see our code at:\nhttps://github.com/AI45Lab/X-Boundary.",
      "tldr_zh": "该研究发现，现有的LLMs防御方法虽能提升对multi-turn jailbreaks的鲁棒性，但会损害可用性，如降低一般能力或导致over-refusal问题，因为它们无法精确区分安全和有害特征表示。作者提出X-Boundary方法，通过将有害表示推离边界安全表示，建立精确的安全边界，从而精确擦除有害表示而不干扰安全表示。实验结果显示，X-Boundary实现了最先进的防御性能，减少了约20%的over-refusal率，并保持了几乎完整的通用能力，同时理论证明和实证验证了其能加速训练过程中的收敛。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09990v2",
      "published_date": "2025-02-14 08:22:51 UTC",
      "updated_date": "2025-03-06 15:38:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:35:55.139726"
    },
    {
      "arxiv_id": "2502.10485v1",
      "title": "Forecasting time series with constraints",
      "title_zh": "约束下的时间序列预测",
      "authors": [
        "Nathan Doumèche",
        "Francis Bach",
        "Éloi Bedek",
        "Gérard Biau",
        "Claire Boyer",
        "Yannig Goude"
      ],
      "abstract": "Time series forecasting presents unique challenges that limit the\neffectiveness of traditional machine learning algorithms. To address these\nlimitations, various approaches have incorporated linear constraints into\nlearning algorithms, such as generalized additive models and hierarchical\nforecasting. In this paper, we propose a unified framework for integrating and\ncombining linear constraints in time series forecasting. Within this framework,\nwe show that the exact minimizer of the constrained empirical risk can be\ncomputed efficiently using linear algebra alone. This approach allows for\nhighly scalable implementations optimized for GPUs. We validate the proposed\nmethodology through extensive benchmarking on real-world tasks, including\nelectricity demand forecasting and tourism forecasting, achieving\nstate-of-the-art performance.",
      "tldr_zh": "本文提出一个统一的框架，用于在时间序列 forecasting 中整合和组合线性 constraints，以克服传统机器学习算法的局限性。该框架通过线性 algebra 高效计算约束 empirical risk 的精确最小值，支持高度可扩展的 GPU 优化实现。在真实任务如 electricity demand forecasting 和 tourism forecasting 的广泛基准测试中，该方法实现了 state-of-the-art 性能。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG",
        "math.ST",
        "stat.AP",
        "stat.ME",
        "stat.TH"
      ],
      "primary_category": "stat.ML",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10485v1",
      "published_date": "2025-02-14 08:18:17 UTC",
      "updated_date": "2025-02-14 08:18:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:36:06.427208"
    },
    {
      "arxiv_id": "2502.09977v2",
      "title": "LaRA: Benchmarking Retrieval-Augmented Generation and Long-Context LLMs -- No Silver Bullet for LC or RAG Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Kuan Li",
        "Liwen Zhang",
        "Yong Jiang",
        "Pengjun Xie",
        "Fei Huang",
        "Shuai Wang",
        "Minhao Cheng"
      ],
      "abstract": "Effectively incorporating external knowledge into Large Language Models\n(LLMs) is crucial for enhancing their capabilities and addressing real-world\nneeds. Retrieval-Augmented Generation (RAG) offers an effective method for\nachieving this by retrieving the most relevant fragments into LLMs. However,\nthe advancements in context window size for LLMs offer an alternative approach,\nraising the question of whether RAG remains necessary for effectively handling\nexternal knowledge. Several existing studies provide inconclusive comparisons\nbetween RAG and long-context (LC) LLMs, largely due to limitations in the\nbenchmark designs. In this paper, we present LaRA, a novel benchmark\nspecifically designed to rigorously compare RAG and LC LLMs. LaRA encompasses\n2326 test cases across four practical QA task categories and three types of\nnaturally occurring long texts. Through systematic evaluation of seven\nopen-source and four proprietary LLMs, we find that the optimal choice between\nRAG and LC depends on a complex interplay of factors, including the model's\nparameter size, long-text capabilities, context length, task type, and the\ncharacteristics of the retrieved chunks. Our findings provide actionable\nguidelines for practitioners to effectively leverage both RAG and LC approaches\nin developing and deploying LLM applications. Our code and dataset is provided\nat:\n\\href{https://github.com/Alibaba-NLP/LaRA}{\\textbf{https://github.com/Alibaba-NLP/LaRA}}.",
      "tldr_zh": "该研究提出LaRA基准，用于严格比较Retrieval-Augmented Generation (RAG) 和 Long-Context LLMs (LC) 在处理外部知识方面的性能，旨在解决现有基准设计不足的问题。LaRA包括2326个测试案例，涵盖四个实际QA任务类别和三种自然长文本，通过评估七个开源和四个专有LLMs，发现RAG和LC的选择取决于模型参数大小、长文本能力、上下文长度、任务类型以及检索块特征等因素。研究结果表明，没有单一最佳方案（No Silver Bullet），并为从业者提供实用指导，帮助在LLM应用中有效结合RAG和LC方法。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.09977v2",
      "published_date": "2025-02-14 08:04:22 UTC",
      "updated_date": "2025-03-05 08:48:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:36:18.799485"
    },
    {
      "arxiv_id": "2502.09974v1",
      "title": "Has My System Prompt Been Used? Large Language Model Prompt Membership Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Roman Levin",
        "Valeriia Cherepanova",
        "Abhimanyu Hans",
        "Avi Schwarzschild",
        "Tom Goldstein"
      ],
      "abstract": "Prompt engineering has emerged as a powerful technique for optimizing large\nlanguage models (LLMs) for specific applications, enabling faster prototyping\nand improved performance, and giving rise to the interest of the community in\nprotecting proprietary system prompts. In this work, we explore a novel\nperspective on prompt privacy through the lens of membership inference. We\ndevelop Prompt Detective, a statistical method to reliably determine whether a\ngiven system prompt was used by a third-party language model. Our approach\nrelies on a statistical test comparing the distributions of two groups of model\noutputs corresponding to different system prompts. Through extensive\nexperiments with a variety of language models, we demonstrate the effectiveness\nof Prompt Detective for prompt membership inference. Our work reveals that even\nminor changes in system prompts manifest in distinct response distributions,\nenabling us to verify prompt usage with statistical significance.",
      "tldr_zh": "本文探讨了大语言模型(LLMs)系统提示的隐私问题，提出了一种名为Prompt Detective的统计方法，用于通过成员推断(membership inference)检测第三方模型是否使用了特定系统提示。该方法基于统计测试，比较不同系统提示对应的模型输出分布，以识别提示使用情况。实验结果显示，即使系统提示的微小变化也会导致响应分布的显著差异，从而实现统计显著性的验证，为保护专有提示提供了有效工具。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09974v1",
      "published_date": "2025-02-14 08:00:42 UTC",
      "updated_date": "2025-02-14 08:00:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:36:31.303880"
    },
    {
      "arxiv_id": "2502.09971v1",
      "title": "Conditional Latent Coding with Learnable Synthesized Reference for Deep Image Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Siqi Wu",
        "Yinda Chen",
        "Dong Liu",
        "Zhihai He"
      ],
      "abstract": "In this paper, we study how to synthesize a dynamic reference from an\nexternal dictionary to perform conditional coding of the input image in the\nlatent domain and how to learn the conditional latent synthesis and coding\nmodules in an end-to-end manner. Our approach begins by constructing a\nuniversal image feature dictionary using a multi-stage approach involving\nmodified spatial pyramid pooling, dimension reduction, and multi-scale feature\nclustering. For each input image, we learn to synthesize a conditioning latent\nby selecting and synthesizing relevant features from the dictionary, which\nsignificantly enhances the model's capability in capturing and exploring image\nsource correlation. This conditional latent synthesis involves a\ncorrelation-based feature matching and alignment strategy, comprising a\nConditional Latent Matching (CLM) module and a Conditional Latent Synthesis\n(CLS) module. The synthesized latent is then used to guide the encoding\nprocess, allowing for more efficient compression by exploiting the correlation\nbetween the input image and the reference dictionary. According to our\ntheoretical analysis, the proposed conditional latent coding (CLC) method is\nrobust to perturbations in the external dictionary samples and the selected\nconditioning latent, with an error bound that scales logarithmically with the\ndictionary size, ensuring stability even with large and diverse dictionaries.\nExperimental results on benchmark datasets show that our new method improves\nthe coding performance by a large margin (up to 1.2 dB) with a very small\noverhead of approximately 0.5\\% bits per pixel. Our code is publicly available\nat https://github.com/ydchen0806/CLC.",
      "tldr_zh": "这篇论文提出了Conditional Latent Coding (CLC)方法，用于深度图像压缩，通过从外部字典合成动态参考来实现输入图像的条件编码。该方法首先构建一个通用图像特征字典，利用修改的空间金字塔池化、维度减少和多尺度特征聚类；然后，通过Conditional Latent Matching (CLM)和Conditional Latent Synthesis (CLS)模块，学习合成相关特征以捕获图像源相关性，并指导编码过程以提高效率。理论分析显示，CLC对字典样本和条件潜在表示的扰动具有鲁棒性，错误边界随字典大小呈对数增长；在基准数据集上的实验结果表明，该方法显著提升编码性能（高达1.2 dB），仅增加约0.5%的bits per pixel。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09971v1",
      "published_date": "2025-02-14 07:56:21 UTC",
      "updated_date": "2025-02-14 07:56:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:36:44.408710"
    },
    {
      "arxiv_id": "2502.09969v2",
      "title": "Data Valuation using Neural Networks for Efficient Instruction Fine-Tuning",
      "title_zh": "使用神经网络进行数据估值以实现高效指令微调",
      "authors": [
        "Ishika Agarwal",
        "Dilek Hakkani-Tür"
      ],
      "abstract": "Influence functions provide crucial insights into model training, but\nexisting methods suffer from large computational costs and limited\ngeneralization. Particularly, recent works have proposed various metrics and\nalgorithms to calculate the influence of data using language models, which do\nnot scale well with large models and datasets. This is because of the expensive\nforward and backward passes required for computation, substantial memory\nrequirements to store large models, and poor generalization of influence\nestimates to new data. In this paper, we explore the use of small neural\nnetworks -- which we refer to as the InfluenceNetwork -- to estimate influence\nvalues, achieving up to 99% cost reduction. Our evaluation demonstrates that\ninfluence values can be estimated with models just 0.0027% the size of full\nlanguage models (we use 7B and 8B versions). We apply our algorithm of\nestimating influence values (called NN-CIFT: Neural Networks for effiCient\nInstruction Fine-Tuning) to the downstream task of subset selection for general\ninstruction fine-tuning. In our study, we include four state-of-the-art\ninfluence functions and show no compromise in performance, despite large\nspeedups, between NN-CIFT and the original influence functions. We provide an\nin-depth hyperparameter analyses of NN-CIFT. The code for our method can be\nfound here: https://github.com/agarwalishika/NN-CIFT.",
      "tldr_zh": "本研究针对现有影响函数（influence functions）在模型训练中的高计算成本和泛化能力差问题，提出使用小型神经网络（InfluenceNetwork）来估计数据影响值，从而实现高达99%的成本减少。相比完整语言模型（如7B和8B版本），InfluenceNetwork 仅需模型大小的0.0027%即可高效估算影响值。作者将该算法应用于指令微调的子集选择任务（NN-CIFT: Neural Networks for effiCient Instruction Fine-Tuning），并与四种最先进的影响函数比较，结果显示性能无明显妥协，但速度大幅提升。研究还提供了NN-CIFT的超参数分析，并公开了代码（https://github.com/agarwalishika/NN-CIFT）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09969v2",
      "published_date": "2025-02-14 07:55:47 UTC",
      "updated_date": "2025-02-17 16:26:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:36:55.750800"
    },
    {
      "arxiv_id": "2502.14880v1",
      "title": "KKA: Improving Vision Anomaly Detection through Anomaly-related Knowledge from Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Dong Chen",
        "Zhengqing Hu",
        "Peiguang Fan",
        "Yueting Zhuang",
        "Yafei Li",
        "Qidong Liu",
        "Xiaoheng Jiang",
        "Mingliang Xu"
      ],
      "abstract": "Vision anomaly detection, particularly in unsupervised settings, often\nstruggles to distinguish between normal samples and anomalies due to the wide\nvariability in anomalies. Recently, an increasing number of studies have\nfocused on generating anomalies to help detectors learn more effective\nboundaries between normal samples and anomalies. However, as the generated\nanomalies are often derived from random factors, they frequently lack realism.\nAdditionally, randomly generated anomalies typically offer limited support in\nconstructing effective boundaries, as most differ substantially from normal\nsamples and lie far from the boundary. To address these challenges, we propose\nKey Knowledge Augmentation (KKA), a method that extracts anomaly-related\nknowledge from large language models (LLMs). More specifically, KKA leverages\nthe extensive prior knowledge of LLMs to generate meaningful anomalies based on\nnormal samples. Then, KKA classifies the generated anomalies as easy anomalies\nand hard anomalies according to their similarity to normal samples. Easy\nanomalies exhibit significant differences from normal samples, whereas hard\nanomalies closely resemble normal samples. KKA iteratively updates the\ngenerated anomalies, and gradually increasing the proportion of hard anomalies\nto enable the detector to learn a more effective boundary. Experimental results\nshow that the proposed method significantly improves the performance of various\nvision anomaly detectors while maintaining low generation costs. The code for\nCMG can be found at https://github.com/Anfeather/KKA.",
      "tldr_zh": "本文提出KKA方法，通过从大语言模型(LLMs)提取异常相关知识，改进无监督视觉异常检测的性能。具体而言，KKA基于正常样本生成有意义的异常，并将它们分类为easy anomalies（与正常样本差异明显）和hard anomalies（与正常样本相似度高），然后通过迭代更新逐渐增加hard anomalies的比例，以帮助检测器学习更有效的边界。实验结果显示，该方法显著提升了各种视觉异常检测器的表现，同时保持低生成成本。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.14880v1",
      "published_date": "2025-02-14 07:46:49 UTC",
      "updated_date": "2025-02-14 07:46:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:37:06.995658"
    },
    {
      "arxiv_id": "2502.15762v1",
      "title": "SmartEdge: Smart Healthcare End-to-End Integrated Edge and Cloud Computing System for Diabetes Prediction Enabled by Ensemble Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Alain Hennebelle",
        "Qifan Dieng",
        "Leila Ismail",
        "Rajkumar Buyya"
      ],
      "abstract": "The Internet of Things (IoT) revolutionizes smart city domains such as\nhealthcare, transportation, industry, and education. The Internet of Medical\nThings (IoMT) is gaining prominence, particularly in smart hospitals and Remote\nPatient Monitoring (RPM). The vast volume of data generated by IoMT devices\nshould be analyzed in real-time for health surveillance, prognosis, and\nprediction of diseases. Current approaches relying on Cloud computing to\nprovide the necessary computing and storage capabilities do not scale for these\nlatency-sensitive applications. Edge computing emerges as a solution by\nbringing cloud services closer to IoMT devices. This paper introduces\nSmartEdge, an AI-powered smart healthcare end-to-end integrated edge and cloud\ncomputing system for diabetes prediction. This work addresses latency concerns\nand demonstrates the efficacy of edge resources in healthcare applications\nwithin an end-to-end system. The system leverages various risk factors for\ndiabetes prediction. We propose an Edge and Cloud-enabled framework to deploy\nthe proposed diabetes prediction models on various configurations using edge\nnodes and main cloud servers. Performance metrics are evaluated using, latency,\naccuracy, and response time. By using ensemble machine learning voting\nalgorithms we can improve the prediction accuracy by 5% versus a single model\nprediction.",
      "tldr_zh": "本论文提出SmartEdge系统，这是一个端到端集成的边缘和云计算框架，旨在通过Internet of Medical Things (IoMT)实时分析健康数据，实现糖尿病预测。系统利用Ensemble Machine Learning的投票算法，结合边缘计算资源来解决传统Cloud Computing的延迟问题，并在各种配置下部署模型。实验结果显示，与单模型相比，预测准确率提高了5%，并在延迟、准确率和响应时间等性能指标上表现出显著优势。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.ET",
        "cs.LG",
        "68T01, 68T09, 68M14, 68W10, 68W15",
        "C.2.4; C.4; C.5; D.2.2; D.2.11; I.2.5; I.2.6; I.2.11; J.0; J.7"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.15762v1",
      "published_date": "2025-02-14 07:42:17 UTC",
      "updated_date": "2025-02-14 07:42:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:37:18.615260"
    },
    {
      "arxiv_id": "2503.16441v1",
      "title": "Safe and Efficient Social Navigation through Explainable Safety Regions Based on Topological Features",
      "title_zh": "翻译失败",
      "authors": [
        "Victor Toscano-Duran",
        "Sara Narteni",
        "Alberto Carlevaro",
        "Rocio Gonzalez-Diaz",
        "Maurizio Mongelli",
        "Jerome Guzzi"
      ],
      "abstract": "The recent adoption of artificial intelligence (AI) in robotics has driven\nthe development of algorithms that enable autonomous systems to adapt to\ncomplex social environments. In particular, safe and efficient social\nnavigation is a key challenge, requiring AI not only to avoid collisions and\ndeadlocks but also to interact intuitively and predictably with its\nsurroundings. To date, methods based on probabilistic models and the generation\nof conformal safety regions have shown promising results in defining safety\nregions with a controlled margin of error, primarily relying on classification\napproaches and explicit rules to describe collision-free navigation conditions.\n  This work explores how topological features contribute to explainable safety\nregions in social navigation. Instead of using behavioral parameters, we\nleverage topological data analysis to classify and characterize different\nsimulation behaviors. First, we apply global rule-based classification to\ndistinguish between safe (collision-free) and unsafe scenarios based on\ntopological properties. Then, we define safety regions, $S_\\varepsilon$, in the\ntopological feature space, ensuring a maximum classification error of\n$\\varepsilon$. These regions are built with adjustable SVM classifiers and\norder statistics, providing robust decision boundaries. Local rules extracted\nfrom these regions enhance interpretability, keeping the decision-making\nprocess transparent.\n  Our approach initially separates simulations with and without collisions,\noutperforming methods that not incorporate topological features. It offers a\ndeeper understanding of robot interactions within a navigable space. We further\nrefine safety regions to ensure deadlock-free simulations and integrate both\naspects to define a compliant simulation space that guarantees safe and\nefficient navigation.",
      "tldr_zh": "这篇论文探讨了基于拓扑特征的解释性安全区域，以实现机器人社会导航的安全性和效率，旨在避免碰撞和死锁，同时提升与环境的直观互动。作者利用拓扑数据分析（topological data analysis）对模拟行为进行分类，并通过全局规则区分安全（collision-free）和不安全场景。接着，他们定义了安全区域 $S_\\varepsilon$，使用可调整的 SVM 分类器和顺序统计（order statistics）来确保最大分类错误不超过 $\\varepsilon$，并从这些区域提取本地规则以增强决策透明度。该方法在处理碰撞和无死锁模拟时优于传统方法，提供更深入的机器人互动理解，并最终构建了一个合规的导航空间。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "math.GN"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2503.16441v1",
      "published_date": "2025-02-14 07:29:13 UTC",
      "updated_date": "2025-02-14 07:29:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:37:32.021003"
    },
    {
      "arxiv_id": "2502.09956v1",
      "title": "KGGen: Extracting Knowledge Graphs from Plain Text with Language Models",
      "title_zh": "KGGen：使用语言模型从纯文本中",
      "authors": [
        "Belinda Mo",
        "Kyssen Yu",
        "Joshua Kazdan",
        "Proud Mpala",
        "Lisa Yu",
        "Chris Cundy",
        "Charilaos Kanatsoulis",
        "Sanmi Koyejo"
      ],
      "abstract": "Recent interest in building foundation models for KGs has highlighted a\nfundamental challenge: knowledge-graph data is relatively scarce. The\nbest-known KGs are primarily human-labeled, created by pattern-matching, or\nextracted using early NLP techniques. While human-generated KGs are in short\nsupply, automatically extracted KGs are of questionable quality. We present a\nsolution to this data scarcity problem in the form of a text-to-KG generator\n(KGGen), a package that uses language models to create high-quality graphs from\nplaintext. Unlike other KG extractors, KGGen clusters related entities to\nreduce sparsity in extracted KGs. KGGen is available as a Python library\n(\\texttt{pip install kg-gen}), making it accessible to everyone. Along with\nKGGen, we release the first benchmark, Measure of of Information in Nodes and\nEdges (MINE), that tests an extractor's ability to produce a useful KG from\nplain text. We benchmark our new tool against existing extractors and\ndemonstrate far superior performance.",
      "tldr_zh": "该研究解决了知识图谱（KGs）数据稀缺和质量问题，提出KGGen工具，使用语言模型从纯文本自动生成高质量KGs，并通过聚类相关实体来减少图谱稀疏性。KGGen作为Python库（pip install kg-gen）发布，便于用户访问，同时引入首个基准测试MINE（Measure of Information in Nodes and Edges），评估提取器从纯文本生成有用KGs的能力。在基准测试中，KGGen显著优于现有提取器，提供了一个高效的文本到KGs转换解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09956v1",
      "published_date": "2025-02-14 07:28:08 UTC",
      "updated_date": "2025-02-14 07:28:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:37:42.650829"
    },
    {
      "arxiv_id": "2502.09955v1",
      "title": "Diverse Inference and Verification for Advanced Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Iddo Drori",
        "Gaston Longhitano",
        "Mao Mao",
        "Seunghwan Hyun",
        "Yuke Zhang",
        "Sungjun Park",
        "Zachary Meeks",
        "Xin-Yu Zhang",
        "Ben Segev",
        "Howard Yong",
        "Nakul Verma",
        "Avi Shporer",
        "Alon Amit",
        "Madeleine Udell"
      ],
      "abstract": "Reasoning LLMs such as OpenAI o1, o3 and DeepSeek R1 have made significant\nprogress in mathematics and coding, yet find challenging advanced tasks such as\nInternational Mathematical Olympiad (IMO) combinatorics problems, Abstraction\nand Reasoning Corpus (ARC) puzzles, and Humanity's Last Exam (HLE) questions.\nWe use a diverse inference approach that combines multiple models and methods\nat test time. We find that verifying mathematics and code problems, and\nrejection sampling on other problems is simple and effective. We automatically\nverify correctness of solutions to IMO problems by Lean, and ARC puzzles by\ncode, and find that best-of-N effectively answers HLE questions. Our approach\nincreases answer accuracy on IMO combinatorics problems from 33.3% to 77.8%,\naccuracy on HLE questions from 8% to 37%, and solves 80% of ARC puzzles that\n948 humans could not and 26.5% of ARC puzzles that o3 high compute does not.\nTest-time simulations, reinforcement learning, and meta-learning with inference\nfeedback improve generalization by adapting agent graph representations and\nvarying prompts, code, and datasets. Our approach is reliable, robust, and\nscalable, and in the spirit of reproducible research, we will make it publicly\navailable upon publication.",
      "tldr_zh": "该研究针对高级推理任务（如 International Mathematical Olympiad (IMO) 组合问题、Abstraction and Reasoning Corpus (ARC) 谜题和 Humanity's Last Exam (HLE) 问题），提出了一种 diverse inference 方法，结合多种模型和验证技术来提升大型语言模型(LLMs)如 OpenAI o1 和 o3 的性能。通过自动验证数学和代码问题（如使用 Lean 验证 IMO 解决方案）、rejection sampling 和 best-of-N 采样，该方法简化了复杂任务的处理。实验结果显示，IMO 组合问题准确率从 33.3% 提高到 77.8%，HLE 问题准确率从 8% 提升到 37%，并成功解决了 80% 的人类无法破解的 ARC 谜题，以及 26.5% 的 o3 high compute 无法解决的谜题。此外，test-time simulations、reinforcement learning 和 meta-learning 等技术进一步提升了模型的泛化能力，使该方法更可靠、鲁棒且易于扩展，并计划公开可用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "165 pages",
      "pdf_url": "http://arxiv.org/pdf/2502.09955v1",
      "published_date": "2025-02-14 07:22:25 UTC",
      "updated_date": "2025-02-14 07:22:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:37:56.522283"
    },
    {
      "arxiv_id": "2502.09952v1",
      "title": "Using MRNet to Predict Lunar Rock Categories Detected by Chang'e 5 Probe",
      "title_zh": "利用 MRNet 预测 Chang'e 5 探测器检测到的月球岩石类别",
      "authors": [
        "Jin Cui",
        "Yifei Zou",
        "Siyuan Zhang"
      ],
      "abstract": "China's Chang'e 5 mission has been a remarkable success, with the chang'e 5\nlander traveling on the Oceanus Procellarum to collect images of the lunar\nsurface. Over the past half century, people have brought back some lunar rock\nsamples, but its quantity does not meet the need for research. Under current\ncircumstances, people still mainly rely on the analysis of rocks on the lunar\nsurface through the detection of lunar rover. The Oceanus Procellarum, chosen\nby Chang'e 5 mission, contains various kind of rock species. Therefore, we\nfirst applied to the National Astronomical Observatories of the China under the\nChinese Academy of Sciences for the Navigation and Terrain Camera (NaTeCam) of\nthe lunar surface image, and established a lunar surface rock image data set\nCE5ROCK. The data set contains 100 images, which randomly divided into\ntraining, validation and test set. Experimental results show that the\nidentification accuracy testing on convolutional neural network (CNN) models\nlike AlexNet or MobileNet is about to 40.0%. In order to make full use of the\nglobal information in Moon images, this paper proposes the MRNet (MoonRockNet)\nnetwork architecture. The encoding structure of the network uses VGG16 for\nfeature extraction, and the decoding part adds dilated convolution and commonly\nused U-Net structure on the original VGG16 decoding structure, which is more\nconducive to identify more refined but more sparsely distributed types of lunar\nrocks. We have conducted extensive experiments on the established CE5ROCK data\nset, and the experimental results show that MRNet can achieve more accurate\nrock type identification, and outperform other existing mainstream algorithms\nin the identification performance.",
      "tldr_zh": "本研究针对嫦娥5号探测器在月球海洋平原采集的图像，建立了CE5ROCK数据集（包含100张图像），以解决现有月球岩石样本不足的问题。作者提出了MRNet（MoonRockNet）网络架构，该架构使用VGG16进行特征提取，并在解码部分添加膨胀卷积和U-Net结构，以更有效地捕捉全局信息和细致岩石特征。实验结果表明，MRNet在CE5ROCK数据集上的岩石类型识别准确率超过了传统CNN模型如AlexNet和MobileNet，性能更优。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at the 8th International Conference on Advances in\n  Machinery, Material Science and Engineering Application (MMSE 2022)",
      "pdf_url": "http://arxiv.org/pdf/2502.09952v1",
      "published_date": "2025-02-14 07:12:19 UTC",
      "updated_date": "2025-02-14 07:12:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:38:07.298819"
    },
    {
      "arxiv_id": "2502.09947v1",
      "title": "Analyzing Patient Daily Movement Behavior Dynamics Using Two-Stage Encoding Model",
      "title_zh": "翻译失败",
      "authors": [
        "Jin Cui",
        "Alexander Capstick",
        "Payam Barnaghi",
        "Gregory Scott"
      ],
      "abstract": "In the analysis of remote healthcare monitoring data, time series\nrepresentation learning offers substantial value in uncovering deeper patterns\nof patient behavior, especially given the fine temporal granularity of the\ndata. In this study, we focus on a dataset of home activity records from people\nliving with Dementia. We propose a two-stage self-supervised learning approach.\nThe first stage involves converting time-series activities into text strings,\nwhich are then encoded by a fine-tuned language model. In the second stage,\nthese time-series vectors are bi-dimensionalized for applying PageRank method,\nto analyze latent state transitions to quantitatively assess participants\nbehavioral patterns and identify activity biases. These insights, combined with\ndiagnostic data, aim to support personalized care interventions.",
      "tldr_zh": "本研究针对痴呆患者家庭活动记录的数据，提出一种两-stage self-supervised learning 方法，用于分析时间序列中的患者日常运动行为动态。第一阶段将时间序列活动转换为文本字符串，并使用 fine-tuned language model 进行编码；第二阶段则对这些时间序列 vectors 进行 bi-dimensionalization，并应用 PageRank 方法来分析潜在状态转换，从而量化评估行为模式和活动偏好。这些见解结合诊断数据，有助于实现个性化的护理干预。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024 workshop Time Series in the Age of Large Models. arXiv\n  admin note: substantial text overlap with arXiv:2502.09173",
      "pdf_url": "http://arxiv.org/pdf/2502.09947v1",
      "published_date": "2025-02-14 06:53:52 UTC",
      "updated_date": "2025-02-14 06:53:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:38:18.491476"
    },
    {
      "arxiv_id": "2502.09933v4",
      "title": "MIR-Bench: Can Your LLM Recognize Complicated Patterns via Many-Shot In-Context Reasoning?",
      "title_zh": "翻译失败",
      "authors": [
        "Kai Yan",
        "Zhan Ling",
        "Kang Liu",
        "Yifan Yang",
        "Ting-Han Fan",
        "Lingfeng Shen",
        "Zhengyin Du",
        "Jiecao Chen"
      ],
      "abstract": "The ability to recognize patterns from examples and apply them to new ones is\na primal ability for general intelligence, and is widely studied by psychology\nand AI researchers. Many benchmarks have been proposed to measure such ability\nfor Large Language Models (LLMs); however, they focus on few-shot (usually <10)\nsetting and lack evaluation for aggregating many pieces of information from\nlong contexts. On the other hand, the ever-growing context length of LLMs have\nbrought forth the novel paradigm of many-shot In-Context Learning (ICL), which\naddresses new tasks with hundreds to thousands of examples without expensive\nand inefficient fine-tuning. However, many-shot evaluations often focus on\nclassification, and popular long-context LLM tasks such as Needle-In-A-Haystack\n(NIAH) seldom require complicated intelligence for integrating many pieces of\ninformation. To fix the issues from both worlds, we propose MIR-Bench, the\nfirst many-shot in-context reasoning benchmark for pattern recognition that\nasks LLM to predict output via input-output examples from underlying functions\nwith diverse data format. Based on MIR-Bench, we study many novel problems for\nmany-shot in-context reasoning, and acquired many insightful findings including\nscaling effect, robustness, inductive vs. transductive reasoning, retrieval\nAugmented Generation (RAG), coding for inductive reasoning, cross-domain\ngeneralizability, etc.",
      "tldr_zh": "该论文提出 MIR-Bench，这是一个全新的多示例（many-shot）情境推理基准，用于评估大型语言模型（LLMs）识别复杂模式的能力，特别是从长上下文中聚合大量信息。MIR-Bench 通过输入-输出示例要求 LLM 预测底层函数的输出，弥补了现有 few-shot 基准的局限性，同时超越了如 Needle-In-A-Haystack (NIAH) 等任务的简单性。研究发现包括缩放效应、鲁棒性、归纳 vs. 演绎推理、Retrieval Augmented Generation (RAG)、编码用于归纳推理以及跨域泛化等洞见，为多示例 In-Context Learning (ICL) 的发展提供了重要指导。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "36 pages, 11 figures. The last version adds more experiments and\n  modifies name for better summary of the work",
      "pdf_url": "http://arxiv.org/pdf/2502.09933v4",
      "published_date": "2025-02-14 06:05:12 UTC",
      "updated_date": "2025-05-16 06:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:38:32.077649"
    },
    {
      "arxiv_id": "2502.09931v1",
      "title": "TransGUNet: Transformer Meets Graph-based Skip Connection for Medical Image Segmentation",
      "title_zh": "TransGUNet：Transformer 与基于图的跳跃连接相结合，用于医学图像分割",
      "authors": [
        "Ju-Hyeon Nam",
        "Nur Suriza Syazwany",
        "Sang-Chul Lee"
      ],
      "abstract": "Skip connection engineering is primarily employed to address the semantic gap\nbetween the encoder and decoder, while also integrating global dependencies to\nunderstand the relationships among complex anatomical structures in medical\nimage segmentation. Although several models have proposed transformer-based\napproaches to incorporate global dependencies within skip connections, they\noften face limitations in capturing detailed local features with high\ncomputational complexity. In contrast, graph neural networks (GNNs) exploit\ngraph structures to effectively capture local and global features. Leveraging\nthese properties, we introduce an attentional cross-scale graph neural network\n(ACS-GNN), which enhances the skip connection framework by converting\ncross-scale feature maps into a graph structure and capturing complex\nanatomical structures through node attention. Additionally, we observed that\ndeep learning models often produce uninformative feature maps, which degrades\nthe quality of spatial attention maps. To address this problem, we integrated\nentropy-driven feature selection (EFS) with spatial attention, calculating an\nentropy score for each channel and filtering out high-entropy feature maps. Our\ninnovative framework, TransGUNet, comprises ACS-GNN and EFS-based spatial\nattentio} to effectively enhance domain generalizability across various\nmodalities by leveraging GNNs alongside a reliable spatial attention map,\nensuring more robust features within the skip connection. Through comprehensive\nexperiments and analysis, TransGUNet achieved superior segmentation performance\non six seen and eight unseen datasets, demonstrating significantly higher\nefficiency compared to previous methods.",
      "tldr_zh": "本研究提出TransGUNet框架，将Transformer与基于图的跳跃连接相结合，用于医疗图像分割，以解决语义差距和特征捕获问题。框架引入注意力交叉尺度图神经网络(ACS-GNN)，通过将跨尺度特征图转换为图结构并应用节点注意力，高效捕获局部和全局解剖特征；同时，整合熵驱动特征选择(EFS)与空间注意力，计算通道熵分数并过滤高熵特征图，提升特征质量和领域泛化能力。实验结果显示，TransGUNet在六个已见和八个未见数据集上实现了优越的分割性能，并比现有方法更高效。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "24 pages, 12 figures",
      "pdf_url": "http://arxiv.org/pdf/2502.09931v1",
      "published_date": "2025-02-14 05:54:13 UTC",
      "updated_date": "2025-02-14 05:54:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:38:42.615206"
    },
    {
      "arxiv_id": "2502.09928v1",
      "title": "Deep Tree Tensor Networks for Image Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Chang Nie",
        "Junfang Chen",
        "Yajie Chen"
      ],
      "abstract": "Originating in quantum physics, tensor networks (TNs) have been widely\nadopted as exponential machines and parameter decomposers for recognition\ntasks. Typical TN models, such as Matrix Product States (MPS), have not yet\nachieved successful application in natural image processing. When employed,\nthey primarily serve to compress parameters within off-the-shelf networks, thus\nlosing their distinctive capability to enhance exponential-order feature\ninteractions. This paper introduces a novel architecture named\n\\textit{\\textbf{D}eep \\textbf{T}ree \\textbf{T}ensor \\textbf{N}etwork} (DTTN),\nwhich captures $2^L$-order multiplicative interactions across features through\nmultilinear operations, while essentially unfolding into a \\emph{tree}-like TN\ntopology with the parameter-sharing property. DTTN is stacked with multiple\nantisymmetric interacting modules (AIMs), and this design facilitates efficient\nimplementation. Moreover, we theoretically reveal the equivalency among\nquantum-inspired TN models and polynomial and multilinear networks under\ncertain conditions, and we believe that DTTN can inspire more interpretable\nstudies in this field. We evaluate the proposed model against a series of\nbenchmarks and achieve excellent performance compared to its peers and\ncutting-edge architectures. Our code will soon be publicly available.",
      "tldr_zh": "本论文提出了一种名为 Deep Tree Tensor Networks (DTTN) 的新架构，用于图像识别，以解决传统 Tensor Networks (TNs) 如 Matrix Product States (MPS) 在自然图像处理中仅用于参数压缩而忽略指数级特征交互的问题。DTTN 通过多线性操作捕获 2^L 阶乘法交互，并采用树状 TN 拓扑和多个 antisymmetric interacting modules (AIMs) 进行高效堆叠，实现参数共享。实验结果显示，DTTN 在基准测试中表现出色，优于现有模型，并理论上揭示了量子启发 TN 模型与多项式及多线性网络在特定条件下的等价性，为可解释的图像识别研究提供新灵感。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09928v1",
      "published_date": "2025-02-14 05:41:33 UTC",
      "updated_date": "2025-02-14 05:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:38:56.133359"
    },
    {
      "arxiv_id": "2502.09927v1",
      "title": "Granite Vision: a lightweight, open-source multimodal model for enterprise Intelligence",
      "title_zh": "Granite Vision：轻量级开源多模态模型，用于企业智能",
      "authors": [
        "Granite Vision Team",
        "Leonid Karlinsky",
        "Assaf Arbelle",
        "Abraham Daniels",
        "Ahmed Nassar",
        "Amit Alfassi",
        "Bo Wu",
        "Eli Schwartz",
        "Dhiraj Joshi",
        "Jovana Kondic",
        "Nimrod Shabtay",
        "Pengyuan Li",
        "Roei Herzig",
        "Shafiq Abedin",
        "Shaked Perek",
        "Sivan Harary",
        "Udi Barzelay",
        "Adi Raz Goldfarb",
        "Aude Oliva",
        "Ben Wieles",
        "Bishwaranjan Bhattacharjee",
        "Brandon Huang",
        "Christoph Auer",
        "Dan Gutfreund",
        "David Beymer",
        "David Wood",
        "Hilde Kuehne",
        "Jacob Hansen",
        "Joseph Shtok",
        "Ken Wong",
        "Luis Angel Bathen",
        "Mayank Mishra",
        "Maksym Lysak",
        "Michele Dolfi",
        "Mikhail Yurochkin",
        "Nikolaos Livathinos",
        "Nimrod Harel",
        "Ophir Azulai",
        "Oshri Naparstek",
        "Rafael Teixeira de Lima",
        "Rameswar Panda",
        "Sivan Doveh",
        "Shubham Gupta",
        "Subhro Das",
        "Syed Zawad",
        "Yusik Kim",
        "Zexue He",
        "Alexander Brooks",
        "Gabe Goodhart",
        "Anita Govindjee",
        "Derek Leist",
        "Ibrahim Ibrahim",
        "Aya Soffer",
        "David Cox",
        "Kate Soule",
        "Luis Lastras",
        "Nirmit Desai",
        "Shila Ofek-koifman",
        "Sriram Raghavan",
        "Tanveer Syeda-Mahmood",
        "Peter Staar",
        "Tal Drory",
        "Rogerio Feris"
      ],
      "abstract": "We introduce Granite Vision, a lightweight large language model with vision\ncapabilities, specifically designed to excel in enterprise use cases,\nparticularly in visual document understanding. Our model is trained on a\ncomprehensive instruction-following dataset, including document-related tasks,\nsuch as content extraction from tables, charts, diagrams, sketches, and\ninfographics, as well as general image tasks. The architecture of Granite\nVision is centered around visual modality alignment with a decoder-only, 2\nbillion parameter Granite large language model. Additionally, we introduce a\ndedicated safety classification approach in test-time that leverages a sparse\nset of attention vectors to identify potential harmful inputs. Despite its\nlightweight architecture, Granite Vision achieves strong results in standard\nbenchmarks related to visual document understanding, as well as on the LiveXiv\nbenchmark, which is designed to avoid test set contamination by using a\nconstantly updated corpus of recently published Arxiv papers. We are releasing\nthe model under the Apache-2 license, allowing for both research and commercial\nuse, while offering complete visibility into the training data and other\nrelevant details. See https://huggingface.co/ibm-granite/ for model weights.",
      "tldr_zh": "我们介绍了Granite Vision，这是一个轻量级、开源的多模态模型，专门针对企业智能中的视觉文档理解任务。该模型在全面的指令遵循数据集上训练，采用以2亿参数的解码器-only Granite大语言模型为核心的架构，并引入测试时的安全分类方法，使用稀疏注意力向量识别有害输入。尽管架构轻量化，Granite Vision在视觉文档理解标准基准和LiveXiv基准上表现出色，并以Apache-2许可发布，支持研究和商业应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09927v1",
      "published_date": "2025-02-14 05:36:32 UTC",
      "updated_date": "2025-02-14 05:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:39:07.539360"
    },
    {
      "arxiv_id": "2502.09925v1",
      "title": "TaskGalaxy: Scaling Multi-modal Instruction Fine-tuning with Tens of Thousands Vision Task Types",
      "title_zh": "翻译失败",
      "authors": [
        "Jiankang Chen",
        "Tianke Zhang",
        "Changyi Liu",
        "Haojie Ding",
        "Yaya Shi",
        "Feng Cheng",
        "Huihui Xiao",
        "Bin Wen",
        "Fan Yang",
        "Tingting Gao",
        "Di Zhang"
      ],
      "abstract": "Multimodal visual language models are gaining prominence in open-world\napplications, driven by advancements in model architectures, training\ntechniques, and high-quality data. However, their performance is often limited\nby insufficient task-specific data, leading to poor generalization and biased\noutputs. Existing efforts to increase task diversity in fine-tuning datasets\nare hindered by the labor-intensive process of manual task labeling, which\ntypically produces only a few hundred task types. To address this, we propose\nTaskGalaxy, a large-scale multimodal instruction fine-tuning dataset comprising\n19,227 hierarchical task types and 413,648 samples. TaskGalaxy utilizes GPT-4o\nto enrich task diversity by expanding from a small set of manually defined\ntasks, with CLIP and GPT-4o filtering those that best match open-source images,\nand generating relevant question-answer pairs. Multiple models are employed to\nensure sample quality. This automated process enhances both task diversity and\ndata quality, reducing manual intervention. Incorporating TaskGalaxy into\nLLaVA-v1.5 and InternVL-Chat-v1.0 models shows substantial performance\nimprovements across 16 benchmarks, demonstrating the critical importance of\ntask diversity. TaskGalaxy is publicly released at\nhttps://github.com/Kwai-YuanQi/TaskGalaxy.",
      "tldr_zh": "该研究提出TaskGalaxy，一个大规模多模态指令微调数据集，包含19,227个层次化视觉任务类型和413,648个样本，以解决多模态视觉语言模型（Multimodal visual language models）因任务特定数据不足而导致的泛化差和输出偏差问题。TaskGalaxy通过GPT-4o扩展从少量手动任务生成多样化任务，结合CLIP和GPT-4o过滤匹配开源图像的任务，并自动生成相关问题-答案对，以提升数据质量并减少手动干预。将TaskGalaxy整合到LLaVA-v1.5和InternVL-Chat-v1.0模型中，在16个基准测试中实现了显著性能提升，突显任务多样性的关键作用。该数据集已公开发布在https://github.com/Kwai-YuanQi/TaskGalaxy。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09925v1",
      "published_date": "2025-02-14 05:32:46 UTC",
      "updated_date": "2025-02-14 05:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:39:19.555845"
    },
    {
      "arxiv_id": "2502.09920v1",
      "title": "Machine Learning for Phase Estimation in Satellite-to-Earth Quantum Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Nathan K Long",
        "Robert Malaney",
        "Kenneth J Grant"
      ],
      "abstract": "A global continuous-variable quantum key distribution (CV-QKD) network can be\nestablished using a series of satellite-to-Earth channels. Increased\nperformance in such a network is provided by performing coherent measurement of\nthe optical quantum signals using a real local oscillator, calibrated locally\nby encoding known information on transmitted reference pulses and using signal\nphase error estimation algorithms. The speed and accuracy of the signal phase\nerror estimation algorithm are vital to practical CV-QKD implementation. Our\nwork provides a framework to analyze long short-term memory neural network (NN)\narchitecture parameterization, with respect to the quantum Cram\\'er-Rao\nuncertainty bound of the signal phase error estimation, with a focus on\nreducing the model complexity. More specifically, we demonstrate that signal\nphase error estimation can be achieved using a low-complexity NN architecture,\nwithout significantly sacrificing accuracy. Our results significantly improve\nthe real-time performance of practical CV-QKD systems deployed over\nsatellite-to-Earth channels, thereby contributing to the ongoing development of\nthe Quantum Internet.",
      "tldr_zh": "本文提出一个框架，使用长短时记忆神经网络(LSTM NN)来优化卫星到地球量子通信中的信号相位误差估计，旨在提高连续变量量子密钥分发(CV-QKD)网络的性能。框架通过分析NN架构参数化，与量子Cramér-Rao不确定性界限相关，重点减少模型复杂度，同时保持估计准确性。结果显示，低复杂度NN架构能有效实现相位误差估计，而不显著牺牲精度，从而提升CV-QKD系统的实时性能，并为量子互联网的发展提供重要贡献。",
      "categories": [
        "quant-ph",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "quant-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09920v1",
      "published_date": "2025-02-14 05:07:59 UTC",
      "updated_date": "2025-02-14 05:07:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:39:31.796191"
    },
    {
      "arxiv_id": "2502.09919v1",
      "title": "AttenGluco: Multimodal Transformer-Based Blood Glucose Forecasting on AI-READI Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Ebrahim Farahmand",
        "Reza Rahimi Azghan",
        "Nooshin Taheri Chatrudi",
        "Eric Kim",
        "Gautham Krishna Gudur",
        "Edison Thomaz",
        "Giulia Pedrielli",
        "Pavan Turaga",
        "Hassan Ghasemzadeh"
      ],
      "abstract": "Diabetes is a chronic metabolic disorder characterized by persistently high\nblood glucose levels (BGLs), leading to severe complications such as\ncardiovascular disease, neuropathy, and retinopathy. Predicting BGLs enables\npatients to maintain glucose levels within a safe range and allows caregivers\nto take proactive measures through lifestyle modifications. Continuous Glucose\nMonitoring (CGM) systems provide real-time tracking, offering a valuable tool\nfor monitoring BGLs. However, accurately forecasting BGLs remains challenging\ndue to fluctuations due to physical activity, diet, and other factors. Recent\ndeep learning models show promise in improving BGL prediction. Nonetheless,\nforecasting BGLs accurately from multimodal, irregularly sampled data over long\nprediction horizons remains a challenging research problem. In this paper, we\npropose AttenGluco, a multimodal Transformer-based framework for long-term\nblood glucose prediction. AttenGluco employs cross-attention to effectively\nintegrate CGM and activity data, addressing challenges in fusing data with\ndifferent sampling rates. Moreover, it employs multi-scale attention to capture\nlong-term dependencies in temporal data, enhancing forecasting accuracy. To\nevaluate the performance of AttenGluco, we conduct forecasting experiments on\nthe recently released AIREADI dataset, analyzing its predictive accuracy across\ndifferent subject cohorts including healthy individuals, people with\nprediabetes, and those with type 2 diabetes. Furthermore, we investigate its\nperformance improvements and forgetting behavior as new cohorts are introduced.\nOur evaluations show that AttenGluco improves all error metrics, such as root\nmean square error (RMSE), mean absolute error (MAE), and correlation, compared\nto the multimodal LSTM model. AttenGluco outperforms this baseline model by\nabout 10% and 15% in terms of RMSE and MAE, respectively.",
      "tldr_zh": "该论文针对糖尿病血糖水平（BGLs）的预测挑战，提出AttenGluco，一种基于Transformer的多模态框架，用于长期血糖预测。该框架通过cross-attention机制整合Continuous Glucose Monitoring (CGM)数据和活动数据，处理不同采样率的问题，并采用multi-scale attention捕捉时间序列中的长期依赖性。在AI-READI数据集上进行实验，结果显示AttenGluco在不同患者群体中优于多模态LSTM基线模型，在root mean square error (RMSE)和mean absolute error (MAE)上分别提高了约10%和15%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09919v1",
      "published_date": "2025-02-14 05:07:38 UTC",
      "updated_date": "2025-02-14 05:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:39:43.769736"
    },
    {
      "arxiv_id": "2502.09913v1",
      "title": "AutoS$^2$earch: Unlocking the Reasoning Potential of Large Models for Web-based Source Search",
      "title_zh": "AutoS²earch：解锁大型模型的推理潜力用于基于网络的源搜索",
      "authors": [
        "Zhengqiu Zhu",
        "Yatai Ji",
        "Jiaheng Huang",
        "Yong Zhao",
        "Sihang Qiu",
        "Rusheng Ju"
      ],
      "abstract": "Web-based management systems have been widely used in risk control and\nindustrial safety. However, effectively integrating source search capabilities\ninto these systems, to enable decision-makers to locate and address the hazard\n(e.g., gas leak detection) remains a challenge. While prior efforts have\nexplored using web crowdsourcing and AI algorithms for source search decision\nsupport, these approaches suffer from overheads in recruiting human\nparticipants and slow response times in time-sensitive situations. To address\nthis, we introduce AutoS$^2$earch, a novel framework leveraging large models\nfor zero-shot source search in web applications. AutoS$^2$earch operates on a\nsimplified visual environment projected through a web-based display, utilizing\na chain-of-thought prompt designed to emulate human reasoning. The multi-modal\nlarge language model (MLLMs) dynamically converts visual observations into\nlanguage descriptions, enabling the LLM to perform linguistic reasoning on four\ndirectional choices. Extensive experiments demonstrate that AutoS$^2$earch\nachieves performance nearly equivalent to human-AI collaborative source search\nwhile eliminating dependency on crowdsourced labor. Our work offers valuable\ninsights in using web engineering to design such autonomous systems in other\nindustrial applications.",
      "tldr_zh": "本研究提出AutoS$^2$earch框架，利用Large Models实现网络应用的零样本源搜索，旨在解决风险控制和工业安全领域中源定位（如气体泄漏检测）的挑战。框架通过Chain-of-Thought提示模拟人类推理，在简化视觉环境中，MLLMs将视觉观察转化为语言描述，LLM随后在四个方向选择上进行语言推理。实验结果显示，AutoS$^2$earch的性能几乎等同于人类-AI协作搜索，同时消除了对网络众包劳动力的依赖。该框架为其他工业应用设计自主系统提供了宝贵见解。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09913v1",
      "published_date": "2025-02-14 04:58:28 UTC",
      "updated_date": "2025-02-14 04:58:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:39:55.096203"
    },
    {
      "arxiv_id": "2502.09903v1",
      "title": "The Ann Arbor Architecture for Agent-Oriented Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Dong"
      ],
      "abstract": "In this paper, we reexamine prompt engineering for large language models\nthrough the lens of automata theory. We argue that language models function as\nautomata and, like all automata, should be programmed in the languages they\naccept, a unified collection of all natural and formal languages. Therefore,\ntraditional software engineering practices--conditioned on the clear separation\nof programming languages and natural languages--must be rethought. We introduce\nthe Ann Arbor Architecture, a conceptual framework for agent-oriented\nprogramming of language models, as a higher-level abstraction over raw token\ngeneration, and provide a new perspective on in-context learning. Based on this\nframework, we present the design of our agent platform Postline, and report on\nour initial experiments in agent training.",
      "tldr_zh": "这篇论文从自动机理论的角度重新审视大型语言模型的提示工程，主张语言模型应像自动机一样，使用它们接受的统一语言（包括自然和形式语言）进行编程，从而挑战传统软件工程中语言分离的假设。作者引入了 Ann Arbor Architecture 作为代理导向编程的框架，提供更高层次的抽象，并对 in-context learning 给出新视角。基于此框架，他们设计了代理平台 Postline，并报告了初步的代理训练实验，结果展示了该方法的潜力。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09903v1",
      "published_date": "2025-02-14 04:21:36 UTC",
      "updated_date": "2025-02-14 04:21:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:40:06.695760"
    },
    {
      "arxiv_id": "2502.09897v1",
      "title": "Artificial Intelligence in Spectroscopy: Advancing Chemistry from Prediction to Generation and Beyond",
      "title_zh": "人工智能在光谱学中：从预测到生成及",
      "authors": [
        "Kehan Guo",
        "Yili Shen",
        "Gisela Abigail Gonzalez-Montiel",
        "Yue Huang",
        "Yujun Zhou",
        "Mihir Surve",
        "Zhichun Guo",
        "Prayel Das",
        "Nitesh V Chawla",
        "Olaf Wiest",
        "Xiangliang Zhang"
      ],
      "abstract": "The rapid advent of machine learning (ML) and artificial intelligence (AI)\nhas catalyzed major transformations in chemistry, yet the application of these\nmethods to spectroscopic and spectrometric data, referred to as Spectroscopy\nMachine Learning (SpectraML), remains relatively underexplored. Modern\nspectroscopic techniques (MS, NMR, IR, Raman, UV-Vis) generate an ever-growing\nvolume of high-dimensional data, creating a pressing need for automated and\nintelligent analysis beyond traditional expert-based workflows. In this survey,\nwe provide a unified review of SpectraML, systematically examining\nstate-of-the-art approaches for both forward tasks (molecule-to-spectrum\nprediction) and inverse tasks (spectrum-to-molecule inference). We trace the\nhistorical evolution of ML in spectroscopy, from early pattern recognition to\nthe latest foundation models capable of advanced reasoning, and offer a\ntaxonomy of representative neural architectures, including graph-based and\ntransformer-based methods. Addressing key challenges such as data quality,\nmultimodal integration, and computational scalability, we highlight emerging\ndirections such as synthetic data generation, large-scale pretraining, and few-\nor zero-shot learning. To foster reproducible research, we also release an\nopen-source repository containing recent papers and their corresponding curated\ndatasets (https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers). Our survey\nserves as a roadmap for researchers, guiding progress at the intersection of\nspectroscopy and AI.",
      "tldr_zh": "这篇调查文章审视了机器学习(ML)和人工智能(AI)在光谱学中的应用，特别是Spectroscopy Machine Learning (SpectraML)，旨在超越传统专家工作流，实现对高维光谱数据（如MS、NMR、IR、Raman和UV-Vis）的自动化分析。论文系统地探讨了正向任务（molecule-to-spectrum prediction）和逆向任务（spectrum-to-molecule inference）的先进方法，并追溯了ML在光谱学从早期模式识别到最新基础模型的演变，同时分类了代表性神经架构，如基于图和transformer的方法。针对关键挑战包括数据质量、多模态整合和计算可扩展性，该文突出了新兴方向如合成数据生成、大规模预训练以及少样本或零样本学习，并发布了开源仓库（https://github.com/MINE-Lab-ND/SpectrumML_Survey_Papers）以促进可重复研究，最终为光谱学与AI交叉领域的进展提供路线图。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09897v1",
      "published_date": "2025-02-14 04:07:25 UTC",
      "updated_date": "2025-02-14 04:07:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:40:20.010467"
    },
    {
      "arxiv_id": "2502.12176v1",
      "title": "Ten Challenging Problems in Federated Foundation Models",
      "title_zh": "联邦基础模型中的十个挑战性问题",
      "authors": [
        "Tao Fan",
        "Hanlin Gu",
        "Xuemei Cao",
        "Chee Seng Chan",
        "Qian Chen",
        "Yiqiang Chen",
        "Yihui Feng",
        "Yang Gu",
        "Jiaxiang Geng",
        "Bing Luo",
        "Shuoling Liu",
        "Win Kent Ong",
        "Chao Ren",
        "Jiaqi Shao",
        "Chuan Sun",
        "Xiaoli Tang",
        "Hong Xi Tae",
        "Yongxin Tong",
        "Shuyue Wei",
        "Fan Wu",
        "Wei Xi",
        "Mingcong Xu",
        "He Yang",
        "Xin Yang",
        "Jiangpeng Yan",
        "Hao Yu",
        "Han Yu",
        "Teng Zhang",
        "Yifei Zhang",
        "Xiaojin Zhang",
        "Zhenzhe Zheng",
        "Lixin Fan",
        "Qiang Yang"
      ],
      "abstract": "Federated Foundation Models (FedFMs) represent a distributed learning\nparadigm that fuses general competences of foundation models as well as\nprivacy-preserving capabilities of federated learning. This combination allows\nthe large foundation models and the small local domain models at the remote\nclients to learn from each other in a teacher-student learning setting. This\npaper provides a comprehensive summary of the ten challenging problems inherent\nin FedFMs, encompassing foundational theory, utilization of private data,\ncontinual learning, unlearning, Non-IID and graph data, bidirectional knowledge\ntransfer, incentive mechanism design, game mechanism design, model\nwatermarking, and efficiency. The ten challenging problems manifest in five\npivotal aspects: ``Foundational Theory,\" which aims to establish a coherent and\nunifying theoretical framework for FedFMs. ``Data,\" addressing the difficulties\nin leveraging domain-specific knowledge from private data while maintaining\nprivacy; ``Heterogeneity,\" examining variations in data, model, and\ncomputational resources across clients; ``Security and Privacy,\" focusing on\ndefenses against malicious attacks and model theft; and ``Efficiency,\"\nhighlighting the need for improvements in training, communication, and\nparameter efficiency. For each problem, we offer a clear mathematical\ndefinition on the objective function, analyze existing methods, and discuss the\nkey challenges and potential solutions. This in-depth exploration aims to\nadvance the theoretical foundations of FedFMs, guide practical implementations,\nand inspire future research to overcome these obstacles, thereby enabling the\nrobust, efficient, and privacy-preserving FedFMs in various real-world\napplications.",
      "tldr_zh": "本论文探讨了Federated Foundation Models (FedFMs)，一种结合基础模型通用能力和联邦学习的隐私保护分布式学习框架，并总结了其中存在的十个关键挑战问题，包括基础理论、利用私有数据、持续学习、遗忘、非IID和图数据、双向知识转移、激励机制设计、游戏机制设计、模型水印以及效率。这些挑战归纳为五个核心方面：基础理论（建立统一框架）、数据（隐私下利用领域知识）、异质性（处理数据、模型和资源差异）、安全与隐私（防御攻击和盗用）以及效率（优化训练和通信）。论文为每个问题提供了数学定义、现有方法的分析、关键挑战及潜在解决方案，以推进FedFMs的理论基础、指导实际实现，并激发未来研究，实现更稳健的隐私保护应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.12176v1",
      "published_date": "2025-02-14 04:01:15 UTC",
      "updated_date": "2025-02-14 04:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:40:31.633953"
    },
    {
      "arxiv_id": "2502.09891v1",
      "title": "ArchRAG: Attributed Community-based Hierarchical Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Shu Wang",
        "Yixiang Fang",
        "Yingli Zhou",
        "Xilin Liu",
        "Yuchi Ma"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) has proven effective in integrating\nexternal knowledge into large language models (LLMs) for question-answer (QA)\ntasks. The state-of-the-art RAG approaches often use the graph data as the\nexternal data since they capture the rich semantic information and link\nrelationships between entities. However, existing graph-based RAG approaches\ncannot accurately identify the relevant information from the graph and also\nconsume large numbers of tokens in the online retrieval process. To address\nthese issues, we introduce a novel graph-based RAG approach, called Attributed\nCommunity-based Hierarchical RAG (ArchRAG), by augmenting the question using\nattributed communities, and also introducing a novel LLM-based hierarchical\nclustering method. To retrieve the most relevant information from the graph for\nthe question, we build a novel hierarchical index structure for the attributed\ncommunities and develop an effective online retrieval method. Experimental\nresults demonstrate that ArchRAG outperforms existing methods in terms of both\naccuracy and token cost.",
      "tldr_zh": "该论文提出了ArchRAG，一种基于attributed communities的层次化Retrieval-Augmented Generation (RAG) 方法，旨在解决现有图数据RAG方法在QA任务中无法准确识别相关信息并消耗大量tokens的问题。ArchRAG通过使用attributed communities增强问题，并引入LLM-based hierarchical clustering构建层次化索引结构，实现高效的在线检索。实验结果表明，该方法在准确性和token成本方面均优于现有方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09891v1",
      "published_date": "2025-02-14 03:28:36 UTC",
      "updated_date": "2025-02-14 03:28:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:40:42.548651"
    },
    {
      "arxiv_id": "2502.09889v1",
      "title": "Evaluating and Improving Graph-based Explanation Methods for Multi-Agent Coordination",
      "title_zh": "翻译失败",
      "authors": [
        "Siva Kailas",
        "Shalin Jain",
        "Harish Ravichandar"
      ],
      "abstract": "Graph Neural Networks (GNNs), developed by the graph learning community, have\nbeen adopted and shown to be highly effective in multi-robot and multi-agent\nlearning. Inspired by this successful cross-pollination, we investigate and\ncharacterize the suitability of existing GNN explanation methods for explaining\nmulti-agent coordination. We find that these methods have the potential to\nidentify the most-influential communication channels that impact the team's\nbehavior. Informed by our initial analyses, we propose an attention entropy\nregularization term that renders GAT-based policies more amenable to existing\ngraph-based explainers. Intuitively, minimizing attention entropy incentivizes\nagents to limit their attention to the most influential or impactful agents,\nthereby easing the challenge faced by the explainer. We theoretically ground\nthis intuition by showing that minimizing attention entropy increases the\ndisparity between the explainer-generated subgraph and its complement.\nEvaluations across three tasks and three team sizes i) provides insights into\nthe effectiveness of existing explainers, and ii) demonstrates that our\nproposed regularization consistently improves explanation quality without\nsacrificing task performance.",
      "tldr_zh": "这篇论文评估了现有 Graph Neural Networks (GNNs) 解释方法在多智能体协调中的适用性，发现这些方法能有效识别影响团队行为的通信通道。作者提出了一种注意力熵正则化（attention entropy regularization）术语，用于改进 Graph Attention Networks (GAT)-based 策略，使代理更专注于关键影响者，从而简化解释过程。理论分析证明，该正则化增加了解释器生成的子图与补图之间的差异，而在三个任务和三个团队规模的实验中，它显著提升了解释质量，同时不影响任务性能。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.MA",
      "comment": "19 pages, 8 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2502.09889v1",
      "published_date": "2025-02-14 03:25:45 UTC",
      "updated_date": "2025-02-14 03:25:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:40:55.200998"
    },
    {
      "arxiv_id": "2502.09886v1",
      "title": "Video2Policy: Scaling up Manipulation Tasks in Simulation through Internet Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Weirui Ye",
        "Fangchen Liu",
        "Zheng Ding",
        "Yang Gao",
        "Oleh Rybkin",
        "Pieter Abbeel"
      ],
      "abstract": "Simulation offers a promising approach for cheaply scaling training data for\ngeneralist policies. To scalably generate data from diverse and realistic\ntasks, existing algorithms either rely on large language models (LLMs) that may\nhallucinate tasks not interesting for robotics; or digital twins, which require\ncareful real-to-sim alignment and are hard to scale. To address these\nchallenges, we introduce Video2Policy, a novel framework that leverages\ninternet RGB videos to reconstruct tasks based on everyday human behavior. Our\napproach comprises two phases: (1) task generation in simulation from videos;\nand (2) reinforcement learning utilizing in-context LLM-generated reward\nfunctions iteratively. We demonstrate the efficacy of Video2Policy by\nreconstructing over 100 videos from the Something-Something-v2 (SSv2) dataset,\nwhich depicts diverse and complex human behaviors on 9 different tasks. Our\nmethod can successfully train RL policies on such tasks, including complex and\nchallenging tasks such as throwing. Finally, we show that the generated\nsimulation data can be scaled up for training a general policy, and it can be\ntransferred back to the real robot in a Real2Sim2Real way.",
      "tldr_zh": "该研究引入了Video2Policy框架，利用互联网RGB视频来扩展模拟环境中的操作任务训练数据，解决了现有方法依赖LLM可能产生无关任务或需要复杂数字孪生的问题。框架分为两个阶段：首先，从视频中重建基于日常人类行为的模拟任务；其次，通过in-context LLM生成的奖励函数进行迭代强化学习。实验在Something-Something-v2 (SSv2)数据集上重建超过100个视频，涵盖9个任务，包括复杂如投掷行为，并成功训练RL策略；最终，生成的模拟数据可大规模用于通用策略训练，并通过Real2Sim2Real方式转移到真实机器人，实现实际应用。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09886v1",
      "published_date": "2025-02-14 03:22:03 UTC",
      "updated_date": "2025-02-14 03:22:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:41:06.758784"
    },
    {
      "arxiv_id": "2502.09885v1",
      "title": "Comprehensive Review of Neural Differential Equations for Time Series Analysis",
      "title_zh": "神经微分方程在时间序列分析中的全面综述",
      "authors": [
        "YongKyung Oh",
        "Seungsu Kam",
        "Jonghun Lee",
        "Dong-Young Lim",
        "Sungil Kim",
        "Alex Bui"
      ],
      "abstract": "Time series modeling and analysis has become critical in various domains.\nConventional methods such as RNNs and Transformers, while effective for\ndiscrete-time and regularly sampled data, face significant challenges in\ncapturing the continuous dynamics and irregular sampling patterns inherent in\nreal-world scenarios. Neural Differential Equations (NDEs) represent a paradigm\nshift by combining the flexibility of neural networks with the mathematical\nrigor of differential equations. This paper presents a comprehensive review of\nNDE-based methods for time series analysis, including neural ordinary\ndifferential equations, neural controlled differential equations, and neural\nstochastic differential equations. We provide a detailed discussion of their\nmathematical formulations, numerical methods, and applications, highlighting\ntheir ability to model continuous-time dynamics. Furthermore, we address key\nchallenges and future research directions. This survey serves as a foundation\nfor researchers and practitioners seeking to leverage NDEs for advanced time\nseries analysis.",
      "tldr_zh": "时间序列分析在多个领域至关重要，但传统方法如 RNNs 和 Transformers 难以有效捕捉真实世界的连续动态和不规则采样问题。Neural Differential Equations (NDEs) 通过结合神经网络的灵活性和微分方程的数学严谨性，提供了一种范式转变，本文对 NDEs 在时间序列分析中的应用进行了全面回顾，包括 neural ordinary differential equations、neural controlled differential equations 和 neural stochastic differential equations。回顾详细讨论了这些方法的数学公式、数值方法和实际应用，突出了它们在建模连续时间动态方面的优势，同时指出了关键挑战和未来研究方向。该调查为研究者和从业者提供了坚实基础，以利用 NDEs 进行高级时间序列分析。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09885v1",
      "published_date": "2025-02-14 03:21:04 UTC",
      "updated_date": "2025-02-14 03:21:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:41:20.306891"
    },
    {
      "arxiv_id": "2502.09884v2",
      "title": "Nonasymptotic CLT and Error Bounds for Two-Time-Scale Stochastic Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Seo Taek Kong",
        "Sihan Zeng",
        "Thinh T. Doan",
        "R. Srikant"
      ],
      "abstract": "We consider linear two-time-scale stochastic approximation algorithms driven\nby martingale noise. Recent applications in machine learning motivate the need\nto understand finite-time error rates, but conventional stochastic\napproximation analysis focus on either asymptotic convergence in distribution\nor finite-time bounds that are far from optimal. Prior work on asymptotic\ncentral limit theorems (CLTs) suggest that two-time-scale algorithms may be\nable to achieve $1/\\sqrt{n}$ error in expectation, with a constant given by the\nexpected norm of the limiting Gaussian vector. However, the best known\nfinite-time rates are much slower. We derive the first non-asymptotic central\nlimit theorem with respect to the Wasserstein-1 distance for two-time-scale\nstochastic approximation with Polyak-Ruppert averaging. As a corollary, we show\nthat expected error achieved by Polyak-Ruppert averaging decays at rate\n$1/\\sqrt{n}$, which significantly improves on the rates of convergence in prior\nworks.",
      "tldr_zh": "这篇论文研究了由马氏噪声驱动的两时间尺度随机逼近算法（Two-Time-Scale Stochastic Approximation），重点解决机器学习应用中的有限时间错误率问题。作者首次推导了非渐近中心极限定理（Nonasymptotic CLT），基于Wasserstein-1距离，并应用Polyak-Ruppert averaging方法。结果表明，该算法的期望错误以1/√n的速度衰减，显著优于现有工作的收敛率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09884v2",
      "published_date": "2025-02-14 03:20:30 UTC",
      "updated_date": "2025-04-23 21:59:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:41:31.160947"
    },
    {
      "arxiv_id": "2502.09874v2",
      "title": "FrGNet: A fourier-guided weakly-supervised framework for nuclear instance segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Peng Ling",
        "Wenxiao Xiong"
      ],
      "abstract": "Nuclear instance segmentation has played a critical role in pathology image\nanalysis. The main challenges arise from the difficulty in accurately\nsegmenting instances and the high cost of precise mask-level annotations for\nfully-supervised training.In this work, we propose a fourier guidance framework\nfor solving the weakly-supervised nuclear instance segmentation problem. In\nthis framework, we construct a fourier guidance module to fuse the priori\ninformation into the training process of the model, which facilitates the model\nto capture the relevant features of the nuclear. Meanwhile, in order to further\nimprove the model's ability to represent the features of nuclear, we propose\nthe guide-based instance level contrastive module. This module makes full use\nof the framework's own properties and guide information to effectively enhance\nthe representation features of nuclear. We show on two public datasets that our\nmodel can outperform current SOTA methods under fully-supervised design, and in\nweakly-supervised experiments, with only a small amount of labeling our model\nstill maintains close to the performance under full supervision.In addition, we\nalso perform generalization experiments on a private dataset, and without any\nlabeling, our model is able to segment nuclear images that have not been seen\nduring training quite effectively. As open science, all codes and pre-trained\nmodels are available at https://github.com/LQY404/FrGNet.",
      "tldr_zh": "本文提出 FrGNet，一种基于 Fourier 指导的弱监督框架，用于核实例 segmentation（核实例分割），旨在解决准确分割困难和高成本标注的问题。该框架包括 Fourier guidance module 来融合先验信息，帮助模型捕获核相关特征，以及 guide-based instance level contrastive module 来增强核特征表示，从而提升模型性能。在两个公共数据集上，FrGNet 在全监督设置下超越当前 SOTA 方法，而在弱监督实验中，仅需少量标注即可接近全监督水平；此外，在一个私有数据集上，该模型无需额外标注即可有效泛化到未见图像。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09874v2",
      "published_date": "2025-02-14 02:51:25 UTC",
      "updated_date": "2025-02-18 05:10:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:41:43.551765"
    },
    {
      "arxiv_id": "2502.09870v1",
      "title": "A Taxonomy of Linguistic Expressions That Contribute To Anthropomorphism of Language Technologies",
      "title_zh": "语言技术拟人化的语言表达分类学体系",
      "authors": [
        "Alicia DeVrio",
        "Myra Cheng",
        "Lisa Egede",
        "Alexandra Olteanu",
        "Su Lin Blodgett"
      ],
      "abstract": "Recent attention to anthropomorphism -- the attribution of human-like\nqualities to non-human objects or entities -- of language technologies like\nLLMs has sparked renewed discussions about potential negative impacts of\nanthropomorphism. To productively discuss the impacts of this anthropomorphism\nand in what contexts it is appropriate, we need a shared vocabulary for the\nvast variety of ways that language can be anthropomorphic. In this work, we\ndraw on existing literature and analyze empirical cases of user interactions\nwith language technologies to develop a taxonomy of textual expressions that\ncan contribute to anthropomorphism. We highlight challenges and tensions\ninvolved in understanding linguistic anthropomorphism, such as how all language\nis fundamentally human and how efforts to characterize and shift perceptions of\nhumanness in machines can also dehumanize certain humans. We discuss ways that\nour taxonomy supports more precise and effective discussions of and decisions\nabout anthropomorphism of language technologies.",
      "tldr_zh": "这篇论文提出了一种分类法（taxonomy），用于识别和分类语言表达如何导致语言技术的拟人化（anthropomorphism），以便更有效地讨论其潜在负面影响。作者基于现有文献和用户互动的实证分析，开发了这一taxonomy，涵盖了各种文本表达方式。论文还突出了理解语言拟人化的挑战，例如语言的根本人性以及改变机器感知可能带来的 dehumanize 风险，并说明该分类法能支持更精确的决策和对话。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "18 pages, 1 figure, to appear at CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.09870v1",
      "published_date": "2025-02-14 02:43:46 UTC",
      "updated_date": "2025-02-14 02:43:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:41:54.852766"
    },
    {
      "arxiv_id": "2502.09866v1",
      "title": "How Users Who are Blind or Low Vision Play Mobile Games: Perceptions, Challenges, and Strategies",
      "title_zh": "翻译失败",
      "authors": [
        "Zihe Ran",
        "Xiyu Li",
        "Qing Xiao",
        "Xianzhe Fan",
        "Franklin Mingzhe Li",
        "Yanyun Wang",
        "Zhicong Lu"
      ],
      "abstract": "As blind and low-vision (BLV) players engage more deeply with games,\naccessibility features have become essential. While some research has explored\ntools and strategies to enhance game accessibility, the specific experiences of\nthese players with mobile games remain underexamined. This study addresses this\ngap by investigating how BLV users experience mobile games with varying\naccessibility levels. Through interviews with 32 experienced BLV mobile\nplayers, we explore their perceptions, challenges, and strategies for engaging\nwith mobile games. Our findings reveal that BLV players turn to mobile games to\nalleviate boredom, achieve a sense of accomplishment, and build social\nconnections, but face barriers depending on the game's accessibility level. We\nalso compare mobile games to other forms of gaming, highlighting the relative\nadvantages of mobile games, such as the inherent accessibility of smartphones.\nThis study contributes to understanding BLV mobile gaming experiences and\nprovides insights for enhancing accessible mobile game design.",
      "tldr_zh": "这篇论文通过对32名有经验的盲人和低视力（BLV）玩家的访谈，探讨了他们玩手机游戏的感知、挑战和策略。研究发现，BLV玩家使用手机游戏来缓解无聊、获得成就感和建立社交连接，但会因游戏的可访问性水平而面临各种障碍，如界面不友好或缺乏辅助功能。相比其他游戏形式，手机游戏的固有可访问性（如智能手机的屏幕阅读器）提供了相对优势，帮助BLV玩家更容易参与。该研究为提升手机游戏设计的可访问性提供了重要见解和建议。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "18 pages, 3 figures, Accepted by CHI '25",
      "pdf_url": "http://arxiv.org/pdf/2502.09866v1",
      "published_date": "2025-02-14 02:27:53 UTC",
      "updated_date": "2025-02-14 02:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:42:07.418781"
    },
    {
      "arxiv_id": "2502.09861v1",
      "title": "A Scoresheet for Explainable AI",
      "title_zh": "翻译失败",
      "authors": [
        "Michael Winikoff",
        "John Thangarajah",
        "Sebastian Rodriguez"
      ],
      "abstract": "Explainability is important for the transparency of autonomous and\nintelligent systems and for helping to support the development of appropriate\nlevels of trust. There has been considerable work on developing approaches for\nexplaining systems and there are standards that specify requirements for\ntransparency. However, there is a gap: the standards are too high-level and do\nnot adequately specify requirements for explainability. This paper develops a\nscoresheet that can be used to specify explainability requirements or to assess\nthe explainability aspects provided for particular applications. The scoresheet\nis developed by considering the requirements of a range of stakeholders and is\napplicable to Multiagent Systems as well as other AI technologies. We also\nprovide guidance for how to use the scoresheet and illustrate its generality\nand usefulness by applying it to a range of applications.",
      "tldr_zh": "这篇论文针对 Explainable AI 的透明度需求，开发了一个 scoresheet 来指定解释性要求或评估特定应用的解释性方面，从而填补现有标准过于高层级的不足。该 scoresheet 通过考虑各种利益相关者的需求设计而成，适用于 Multiagent Systems 及其他 AI 技术。作者还提供了使用指导，并通过应用于多种场景来证明其通用性和实用性。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "To appear at AAMAS 2025 - arXiv version also includes appendices",
      "pdf_url": "http://arxiv.org/pdf/2502.09861v1",
      "published_date": "2025-02-14 02:08:10 UTC",
      "updated_date": "2025-02-14 02:08:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:42:19.172655"
    },
    {
      "arxiv_id": "2502.09858v1",
      "title": "Automated Hypothesis Validation with Agentic Sequential Falsifications",
      "title_zh": "基于代理式顺序证伪的自动假设验证",
      "authors": [
        "Kexin Huang",
        "Ying Jin",
        "Ryan Li",
        "Michael Y. Li",
        "Emmanuel Candès",
        "Jure Leskovec"
      ],
      "abstract": "Hypotheses are central to information acquisition, decision-making, and\ndiscovery. However, many real-world hypotheses are abstract, high-level\nstatements that are difficult to validate directly. This challenge is further\nintensified by the rise of hypothesis generation from Large Language Models\n(LLMs), which are prone to hallucination and produce hypotheses in volumes that\nmake manual validation impractical. Here we propose Popper, an agentic\nframework for rigorous automated validation of free-form hypotheses. Guided by\nKarl Popper's principle of falsification, Popper validates a hypothesis using\nLLM agents that design and execute falsification experiments targeting its\nmeasurable implications. A novel sequential testing framework ensures strict\nType-I error control while actively gathering evidence from diverse\nobservations, whether drawn from existing data or newly conducted procedures.\nWe demonstrate Popper on six domains including biology, economics, and\nsociology. Popper delivers robust error control, high power, and scalability.\nFurthermore, compared to human scientists, Popper achieved comparable\nperformance in validating complex biological hypotheses while reducing time by\n10 folds, providing a scalable, rigorous solution for hypothesis validation.",
      "tldr_zh": "本研究提出Popper框架，一种基于代理式顺序证伪的自动化假设验证系统，旨在解决抽象假设的验证挑战，特别是LLM生成假设的幻觉问题。该框架利用LLM代理设计和执行针对假设可测量含义的证伪实验，并通过顺序测试框架严格控制Type-I错误，同时从现有数据或新程序中收集多样证据。在生物学、经济学和社会学等六个领域，Popper展示了鲁棒的错误控制、高功率和可扩展性，与人类科学家相比，在验证复杂生物假设时性能相当但时间减少10倍。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "q-bio.QM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09858v1",
      "published_date": "2025-02-14 01:46:00 UTC",
      "updated_date": "2025-02-14 01:46:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:42:31.565870"
    },
    {
      "arxiv_id": "2502.10482v2",
      "title": "A Self-Supervised Reinforcement Learning Approach for Fine-Tuning Large Language Models Using Cross-Attention Signals",
      "title_zh": "一种使用交叉注意力信号的自监督强化学习方法，用于微调大型语言模型",
      "authors": [
        "Andrew Kiruluta",
        "Andreas Lemos",
        "Priscilla Burity"
      ],
      "abstract": "We propose a novel reinforcement learning framework for post training large\nlanguage models that does not rely on human in the loop feedback. Instead, our\napproach uses cross attention signals within the model itself to derive a self\nsupervised reward, thereby guiding iterative fine tuning of the model policy.\nBy analyzing how the model attends to the input prompt during generation, we\nconstruct measures of prompt coverage, focus, and coherence. We then use these\nmeasures to rank or score candidate responses, providing a reward signal that\nencourages the model to produce well aligned, on topic text. In empirical\ncomparisons against standard policy gradient methods and RL fine tuning with\nsynthetic preference models, our method shows significant gains in prompt\nrelevance and consistency over a non RL baseline. While it does not yet match\nthe performance of fully human supervised RLHF systems, it highlights an\nimportant direction for scaling alignment with minimal human labeling. We\nprovide a detailed analysis, discuss potential limitations, and outline future\nwork for combining cross-attention based signals with smaller amounts of human\nfeedback.",
      "tldr_zh": "本研究提出了一种自监督强化学习框架，用于微调大型语言模型（Large Language Models），其核心是通过模型内部的 cross-attention signals 作为奖励信号，而非依赖人类反馈。框架通过分析模型对输入提示的注意力，构建 prompt coverage、focus 和 coherence 等度量来评估和排名候选响应，从而指导模型生成更相关、一致的文本。在实验中，该方法在提示相关性和一致性上显著优于标准策略梯度方法和使用合成偏好模型的 RL 微调基准。尽管尚未达到完全人类监督的 RLHF 系统性能，但它为最小化人类标注的模型对齐提供了重要方向，并讨论了潜在限制及未来工作，如结合 cross-attention signals 与少量人类反馈。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.10482v2",
      "published_date": "2025-02-14 01:44:04 UTC",
      "updated_date": "2025-04-16 18:56:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:42:44.438088"
    },
    {
      "arxiv_id": "2502.09854v1",
      "title": "Efficient Multitask Learning in Small Language Models Through Upside-Down Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yu-Chen Lin",
        "Sanat Sharma",
        "Hari Manikandan",
        "Jayant Kumar",
        "Tracy Holloway King",
        "Jing Zheng"
      ],
      "abstract": "In this work, we demonstrate that small language models (SLMs), specifically\na 100M parameter GPT-2 model, can achieve competitive performance in multitask\nprompt generation tasks while requiring only a fraction of the computational\nresources needed by large language models (LLMs). Through a novel combination\nof upside-down reinforcement learning and synthetic data distillation from a\npowerful LLM, Llama-3, we train an SLM that achieves relevance scores within 5%\nof state-of-the-art models, including Llama-3, Qwen2, and Mistral, despite\nbeing up to 80 times smaller, making it highly suitable for\nresource-constrained and real-time applications. This study highlights the\npotential of SLMs as efficient multitask learners in multimodal settings,\nproviding a promising alternative to LLMs for scalable, low-latency\ndeployments.",
      "tldr_zh": "本研究展示了小语言模型 (SLMs)，如 100M 参数的 GPT-2 模型，通过一种高效方法，在多任务提示生成任务中实现了与大型语言模型 (LLMs) 相媲美的性能，同时仅需少量计算资源。研究结合了 upside-down reinforcement learning 和从 Llama-3 模型中合成数据蒸馏的技术，训练 SLM 使其相关性分数仅比 Llama-3、Qwen2 和 Mistral 等模型低 5%，尽管模型大小小 80 倍。结果突出了 SLMs 在多模态设置中的潜力，作为资源受限和实时应用的低延迟、可扩展替代方案。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09854v1",
      "published_date": "2025-02-14 01:39:45 UTC",
      "updated_date": "2025-02-14 01:39:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:42:55.833435"
    },
    {
      "arxiv_id": "2502.09843v1",
      "title": "MuDoC: An Interactive Multimodal Document-grounded Conversational AI System",
      "title_zh": "翻译失败",
      "authors": [
        "Karan Taneja",
        "Ashok K. Goel"
      ],
      "abstract": "Multimodal AI is an important step towards building effective tools to\nleverage multiple modalities in human-AI communication. Building a multimodal\ndocument-grounded AI system to interact with long documents remains a\nchallenge. Our work aims to fill the research gap of directly leveraging\ngrounded visuals from documents alongside textual content in documents for\nresponse generation. We present an interactive conversational AI agent 'MuDoC'\nbased on GPT-4o to generate document-grounded responses with interleaved text\nand figures. MuDoC's intelligent textbook interface promotes trustworthiness\nand enables verification of system responses by allowing instant navigation to\nsource text and figures in the documents. We also discuss qualitative\nobservations based on MuDoC responses highlighting its strengths and\nlimitations.",
      "tldr_zh": "本文提出MuDoC，一种基于GPT-4o的交互式多模态文档基础对话AI系统，旨在利用文档中的文本和视觉元素（如图表）生成交错式响应，从而提升人类-AI通信效率。MuDoC的智能教科书界面增强了系统可信度，通过允许用户即时导航到源文本和图表进行验证。研究通过定性观察讨论了MuDoC的优势（如响应准确性和交互性）和局限性，为多模态AI在长文档处理中的应用提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages, 3 figures, AAAI-MAKE 2025",
      "pdf_url": "http://arxiv.org/pdf/2502.09843v1",
      "published_date": "2025-02-14 01:05:51 UTC",
      "updated_date": "2025-02-14 01:05:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:43:06.788996"
    },
    {
      "arxiv_id": "2502.09838v3",
      "title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Tianwei Lin",
        "Wenqiao Zhang",
        "Sijing Li",
        "Yuqian Yuan",
        "Binhe Yu",
        "Haoyuan Li",
        "Wanggui He",
        "Hao Jiang",
        "Mengze Li",
        "Xiaohui Song",
        "Siliang Tang",
        "Jun Xiao",
        "Hui Lin",
        "Yueting Zhuang",
        "Beng Chin Ooi"
      ],
      "abstract": "We present HealthGPT, a powerful Medical Large Vision-Language Model\n(Med-LVLM) that integrates medical visual comprehension and generation\ncapabilities within a unified autoregressive paradigm. Our bootstrapping\nphilosophy is to progressively adapt heterogeneous comprehension and generation\nknowledge to pre-trained large language models (LLMs). This is achieved through\na novel heterogeneous low-rank adaptation (H-LoRA) technique, which is\ncomplemented by a tailored hierarchical visual perception approach and a\nthree-stage learning strategy. To effectively learn the HealthGPT, we devise a\ncomprehensive medical domain-specific comprehension and generation dataset\ncalled VL-Health. Experimental results demonstrate exceptional performance and\nscalability of HealthGPT in medical visual unified tasks. Our project can be\naccessed at https://github.com/DCDmllm/HealthGPT.",
      "tldr_zh": "我们提出了 HealthGPT，一种医疗大型视觉语言模型 (Med-LVLM)，它通过统一的自动回归框架整合了医疗视觉理解和生成能力。模型采用异构低秩适应 (H-LoRA) 技术、层次化视觉感知方法以及三阶段学习策略，来逐步将异构知识适应到预训练的大型语言模型 (LLMs)。为了支持训练，我们构建了全面的医疗领域数据集 VL-Health，实验结果显示 HealthGPT 在医疗视觉统一任务中表现出色，并具有良好的可扩展性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Comments: added project page",
      "pdf_url": "http://arxiv.org/pdf/2502.09838v3",
      "published_date": "2025-02-14 00:42:36 UTC",
      "updated_date": "2025-02-21 17:39:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:43:19.929976"
    },
    {
      "arxiv_id": "2502.12175v1",
      "title": "Spatiotemporal Graph Neural Networks in short term load forecasting: Does adding Graph Structure in Consumption Data Improve Predictions?",
      "title_zh": "翻译失败",
      "authors": [
        "Quoc Viet Nguyen",
        "Joaquin Delgado Fernandez",
        "Sergio Potenciano Menci"
      ],
      "abstract": "Short term Load Forecasting (STLF) plays an important role in traditional and\nmodern power systems. Most STLF models predominantly exploit temporal\ndependencies from historical data to predict future consumption. Nowadays, with\nthe widespread deployment of smart meters, their data can contain\nspatiotemporal dependencies. In particular, their consumption data is not only\ncorrelated to historical values but also to the values of neighboring smart\nmeters. This new characteristic motivates researchers to explore and experiment\nwith new models that can effectively integrate spatiotemporal interrelations to\nincrease forecasting performance. Spatiotemporal Graph Neural Networks (STGNNs)\ncan leverage such interrelations by modeling relationships between smart meters\nas a graph and using these relationships as additional features to predict\nfuture energy consumption. While extensively studied in other spatiotemporal\nforecasting domains such as traffic, environments, or renewable energy\ngeneration, their application to load forecasting remains relatively\nunexplored, particularly in scenarios where the graph structure is not\ninherently available. This paper overviews the current literature focusing on\nSTGNNs with application in STLF. Additionally, from a technical perspective, it\nalso benchmarks selected STGNN models for STLF at the residential and aggregate\nlevels. The results indicate that incorporating graph features can improve\nforecasting accuracy at the residential level; however, this effect is not\nreflected at the aggregate level",
      "tldr_zh": "这篇论文探讨了在短时负荷预测（STLF）中应用时空图神经网络（STGNNs）的潜力，旨在通过将智能电表间的关系建模为图结构，整合时空依赖性以提升预测性能。作者回顾了现有文献，并对选定的 STGNN 模型进行了基准测试，在住宅级和聚合级数据上评估了添加图结构的效果。结果表明，在住宅级预测中，加入图特征显著提高了准确性，但在聚合级则未观察到明显改善。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, conference",
      "pdf_url": "http://arxiv.org/pdf/2502.12175v1",
      "published_date": "2025-02-14 00:16:47 UTC",
      "updated_date": "2025-02-14 00:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:43:31.393206"
    },
    {
      "arxiv_id": "2502.09829v1",
      "title": "Efficient Evaluation of Multi-Task Robot Policies With Active Experiment Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Abrar Anwar",
        "Rohan Gupta",
        "Zain Merchant",
        "Sayan Ghosh",
        "Willie Neiswanger",
        "Jesse Thomason"
      ],
      "abstract": "Evaluating learned robot control policies to determine their physical\ntask-level capabilities costs experimenter time and effort. The growing number\nof policies and tasks exacerbates this issue. It is impractical to test every\npolicy on every task multiple times; each trial requires a manual environment\nreset, and each task change involves re-arranging objects or even changing\nrobots. Naively selecting a random subset of tasks and policies to evaluate is\na high-cost solution with unreliable, incomplete results. In this work, we\nformulate robot evaluation as an active testing problem. We propose to model\nthe distribution of robot performance across all tasks and policies as we\nsequentially execute experiments. Tasks often share similarities that can\nreveal potential relationships in policy behavior, and we show that natural\nlanguage is a useful prior in modeling these relationships between tasks. We\nthen leverage this formulation to reduce the experimenter effort by using a\ncost-aware expected information gain heuristic to efficiently select\ninformative trials. Our framework accommodates both continuous and discrete\nperformance outcomes. We conduct experiments on existing evaluation data from\nreal robots and simulations. By prioritizing informative trials, our framework\nreduces the cost of calculating evaluation metrics for robot policies across\nmany tasks.",
      "tldr_zh": "该论文针对评估多任务机器人策略的效率问题，提出了一种主动实验选择框架，以减少实验者时间和努力。框架将机器人评估建模为主动测试问题，通过顺序执行实验来动态建模策略在各任务间的性能分布，并利用自然语言作为先验来捕捉任务相似性关系。最终，通过成本感知的预期信息增益启发式优先选择信息丰富的试验，该方法在真实机器人和模拟实验中显著降低了计算评估指标的成本，同时支持连续和离散性能结果。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2502.09829v1",
      "published_date": "2025-02-14 00:07:02 UTC",
      "updated_date": "2025-02-14 00:07:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-22T11:43:42.817969"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 123,
  "processed_papers_count": 123,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-22T11:44:00.704951"
}