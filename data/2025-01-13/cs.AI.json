{
  "date": "2025-01-13",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-01-13 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦 AI 模型优化、多模态生成、医疗应用和强化学习等领域，亮点包括 LLM 在文化对齐和心理健康诊断中的创新应用，以及多名知名学者（如 Javier Del Ser、Daniel Molina 和 Peter Stone）参与的论文，这些工作突显了 AI 在实际场景中的潜力，并强调了伦理和效率问题。\n\n### 重点论文亮点\n我挑选了其中最具话题度和影响力的论文，先从 AI 伦理、LLM 应用和医疗领域入手，这些论文可能引发广泛讨论。接下来，快速掠过其他次要主题的论文，以控制篇幅。\n\n#### AI 伦理与 LLM 应用\n- **Rethinking AI Cultural Alignment（重新思考 AI 文化对齐）**  \n  作者：Michal Bravansky 等。这篇论文挑战了传统的一维文化嵌入方法，提出 AI 文化对齐应是双向过程，通过人类互动框架查询相关文化值。核心贡献：使用 GPT-4o 案例证明互动框架能提升 AI 适应性，这对 LLM 在多文化环境中的部署有重要启示，可能推动更公平的 AI 系统。\n\n- **Large Language Models for Interpretable Mental Health Diagnosis（用于可解释心理健康诊断的大型语言模型）**  \n  作者：Brian Hyeongseok Kim 等（已接受 AAAI 2025 工作坊）。论文提出结合 LLM 和约束逻辑编程的临床决策支持系统，生成可检查的逻辑程序以诊断心理健康问题。核心发现：LLM 生成的程序需专家审查以确保准确性，避免伦理风险，这为 AI 在医疗中的可解释性提供了实用框架。\n\n- **The Paradox of Success in Evolutionary and Bioinspired Optimization（进化与生物启发优化中的成功悖论）**  \n  作者：Daniel Molina 等（知名学者 Javier Del Ser 和 Francisco Herrera 参与）。这篇综述分析了进化算法的不足，如过度拟合和缺乏理论基础，并提供改进指南。核心贡献：强调实验严谨性和创新路径，对 AI 优化领域有指导意义，值得关注其方法论影响。\n\n这些论文共同探讨了 AI 的文化和伦理挑战，LLM 的双向对齐和可解释性尤其突出，可能会激发更多跨文化 AI 研究。\n\n#### 医疗与多模态 AI\n- **CDS: Data Synthesis Method Guided by Cognitive Diagnosis Theory（基于认知诊断理论的数据合成方法）**  \n  作者：Haokun Zhao 等。论文引入认知诊断理论指导 LLM 数据合成，针对模型弱点生成高质量数据。核心发现：在多个基准上提升了模型性能（如代码生成提高 6.00%），这为医疗和教育中的 AI 训练提供高效数据增强策略。\n\n- **RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment（通过视觉-语言概念对齐提升放射学报告生成）**  \n  作者：Difei Gu 等。论文融合视觉语言模型和 LLM 生成更准确的放射报告。核心贡献：使用对齐机制提升报告质量（GREEN 分数 0.678），减少幻觉问题，对临床影像分析有实际应用价值。\n\n- **From Screens to Scenes: A Survey of Embodied AI in Healthcare（从屏幕到场景：医疗中具身 AI 的调查）**  \n  作者：Yihao Liu 等。这篇综述概述了具身 AI 在医疗中的应用，如临床干预和生物医学研究。核心发现：强调安全和模拟到现实的桥梁，对 AI 医疗系统设计提供路线图，作者团队背景强劲。\n\n这些医疗 AI 论文突出了多模态融合的潜力，特别是在影像和报告生成上，可能加速 AI 在临床中的落地。\n\n#### 强化学习与生成模型\n- **Performance Optimization of Ratings-Based Reinforcement Learning（基于评级的强化学习的性能优化）**  \n  作者：Evelyn Rose 等（已接受 AAAI 2025）。论文探索优化超参数以提升评级强化学习性能。核心贡献：提供超参数选择指南，帮助在无奖励环境中学习策略，对机器人决策有启发。\n\n- **BlobGEN-Vid: Compositional Text-to-Video Generation with Blob Video Representations（使用 Blob 视频表示的组合文本到视频生成）**  \n  作者：Weixi Feng 等。论文提出基于 Blob 表示的视频扩散模型，提升文本到视频的控制性。核心发现：在基准上实现零样本生成和布局控制，甚至超越专有模型，这对多模态生成有突破性影响。\n\n快速掠过其他论文：今天还有一些论文如 **WebWalker: Benchmarking LLMs in Web Traversal（评估 LLM 在网页遍历中的基准）** 和 **TiEBe: Tracking Language Model Recall of Notable Worldwide Events Through Time（追踪语言模型对全球事件记忆的基准）**，它们评估 LLM 在网络和事件追踪中的鲁棒性，但主题较窄，仅提供基准改进。其他如进化优化或数据增强论文（如 **Dataset Distillation via Committee Voting**），虽有技术贡献，但影响力有限，仅列出标题不深究。\n\n总之，今天的 arXiv 更新强调 AI 的实用性和伦理，LLM 相关工作尤其值得跟踪。如果您对特定领域感兴趣，建议查看这些论文的完整摘要！",
  "papers": [
    {
      "arxiv_id": "2501.07755v1",
      "title": "Performance Optimization of Ratings-Based Reinforcement Learning",
      "title_zh": "基于评级的强化学习的性能优化",
      "authors": [
        "Evelyn Rose",
        "Devin White",
        "Mingkang Wu",
        "Vernon Lawhern",
        "Nicholas R. Waytowich",
        "Yongcan Cao"
      ],
      "abstract": "This paper explores multiple optimization methods to improve the performance\nof rating-based reinforcement learning (RbRL). RbRL, a method based on the idea\nof human ratings, has been developed to infer reward functions in reward-free\nenvironments for the subsequent policy learning via standard reinforcement\nlearning, which requires the availability of reward functions. Specifically,\nRbRL minimizes the cross entropy loss that quantifies the differences between\nhuman ratings and estimated ratings derived from the inferred reward. Hence, a\nlow loss means a high degree of consistency between human ratings and estimated\nratings. Despite its simple form, RbRL has various hyperparameters and can be\nsensitive to various factors. Therefore, it is critical to provide\ncomprehensive experiments to understand the impact of various hyperparameters\non the performance of RbRL. This paper is a work in progress, providing users\nsome general guidelines on how to select hyperparameters in RbRL.",
      "tldr_zh": "该论文探讨了优化基于人类评级的强化学习方法（Ratings-Based Reinforcement Learning, RbRL）的多种策略。RbRL 通过最小化交叉熵损失来推断奖励函数，从而在无奖励环境中实现后续策略学习，确保人类评分与估计评分之间的高度一致性。研究通过全面实验分析了各种超参数对 RbRL 性能的影响，并为用户提供了选择超参数的一般指导准则。该工作仍在进行中，旨在提升 RbRL 的实用性和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Collaborative AI and Modeling of Humans Bridge\n  Program at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07755v1",
      "published_date": "2025-01-13 23:56:24 UTC",
      "updated_date": "2025-01-13 23:56:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:54:37.814566"
    },
    {
      "arxiv_id": "2501.07751v2",
      "title": "Rethinking AI Cultural Alignment",
      "title_zh": "反思 AI 文化对齐",
      "authors": [
        "Michal Bravansky",
        "Filip Trhlik",
        "Fazl Barez"
      ],
      "abstract": "As general-purpose artificial intelligence (AI) systems become increasingly\nintegrated with diverse human communities, cultural alignment has emerged as a\ncrucial element in their deployment. Most existing approaches treat cultural\nalignment as one-directional, embedding predefined cultural values from\nstandardized surveys and repositories into AI systems. To challenge this\nperspective, we highlight research showing that humans' cultural values must be\nunderstood within the context of specific AI systems. We then use a GPT-4o case\nstudy to demonstrate that AI systems' cultural alignment depends on how humans\nstructure their interactions with the system. Drawing on these findings, we\nargue that cultural alignment should be reframed as a bidirectional process:\nrather than merely imposing standardized values on AIs, we should query the\nhuman cultural values most relevant to each AI-based system and align it to\nthese values through interaction frameworks shaped by human users.",
      "tldr_zh": "本文重新审视AI文化对齐的重要性，指出现有方法将文化对齐视为单向过程，仅将预定义的文化价值观（如从标准化调查中获取）嵌入AI系统，这忽略了人类价值观在具体AI上下文中的动态性。通过GPT-4o的案例研究，论文证明AI的文化对齐取决于人类如何构建与系统的互动框架。最终，作者主张将文化对齐框架化为双向过程，即查询与特定AI系统相关的人类价值观，并通过用户设计的互动框架来实现更有效的对齐。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07751v2",
      "published_date": "2025-01-13 23:42:37 UTC",
      "updated_date": "2025-03-07 21:15:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:54:50.005116"
    },
    {
      "arxiv_id": "2502.05181v1",
      "title": "Enhancing Team Diversity with Generative AI: A Novel Project Management Framework",
      "title_zh": "使用生成式 AI 增强团队多样",
      "authors": [
        "Johnny Chan",
        "Yuming Li"
      ],
      "abstract": "This research-in-progress paper presents a new project management framework\nthat utilises GenAI technology. The framework is designed to address the common\nchallenge of uniform team compositions in academic and research project teams,\nparticularly in universities and research institutions. It does so by\nintegrating sociologically identified patterns of successful team member\npersonalities and roles, using GenAI agents to fill gaps in team dynamics. This\napproach adds an additional layer of analysis to conventional project\nmanagement processes by evaluating team members' personalities and roles and\nemploying GenAI agents, fine-tuned on personality datasets, to fill specific\nteam roles. Our initial experiments have shown improvements in the model's\nability to understand and process personality traits, suggesting the potential\neffectiveness of GenAI teammates in real-world project settings. This paper\naims to explore the practical application of AI in enhancing team diversity and\nproject management",
      "tldr_zh": "该研究提出了一种新型项目管理框架，利用 Generative AI (GenAI) 技术来提升团队多样性，针对学术和研究项目团队中成员组成单一的问题。该框架整合社会学中成功的团队成员个性和角色模式，通过评估团队成员的个性特征并使用在个性数据集上微调的 GenAI 代理来填充特定角色，从而增强团队动态。初步实验显示，GenAI 代理在理解和处理个性特征方面表现出色，表明其在实际项目环境中的潜在有效性。该框架旨在探索 AI 在改善团队多样性和优化项目管理过程中的实际应用。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "A published version can be found from here -\n  https://www.computer.org/csdl/proceedings-article/compsac/2024/769600b648/1ZIUInSDC0w",
      "pdf_url": "http://arxiv.org/pdf/2502.05181v1",
      "published_date": "2025-01-13 21:39:06 UTC",
      "updated_date": "2025-01-13 21:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:57:02.108124"
    },
    {
      "arxiv_id": "2501.07674v2",
      "title": "CDS: Data Synthesis Method Guided by Cognitive Diagnosis Theory",
      "title_zh": "CDS：基于认知诊断理论的数据合成方法",
      "authors": [
        "Haokun Zhao",
        "Jinyi Han",
        "Jiaqing Liang",
        "Yanghua Xiao"
      ],
      "abstract": "Large Language Models (LLMs) have achieved significant advancements, but the\nincreasing complexity of tasks and higher performance demands highlight the\nneed for continuous improvement. Some approaches utilize synthetic data\ngenerated by advanced LLMs based on evaluation results to train models.\nHowever, conventional evaluation methods fail to provide detailed, fine-grained\nprofiles of LLMs, limiting their guidance for data synthesis. In this paper, we\nintroduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a\ndiagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine\nevaluation results and characterize model profiles at the knowledge component\nlevel. Based on these diagnostics, we propose two diagnosis-synthesis\nstrategies for weakness-targeted data synthesis. Additionally, we present an\nenhanced data augmentation and selection pipeline to improve the quality and\ndiversity of synthesized data. Our experiments with several open-source models\nshow significant improvements across multiple benchmarks, achieving up to 6.00%\nimprovement in code generation, 13.10% in mathematical reasoning, and 5.43% in\nacademic exams. Code and data are available on GitHub.",
      "tldr_zh": "本论文提出了一种基于认知诊断理论(Cognitive Diagnosis Theory, CDT)的CDS方法，用于指导大型语言模型(Large Language Models, LLMs)的合成数据生成，以解决传统评估方法无法提供细粒度模型配置文件的局限性。CDS通过借鉴CDT进行诊断性评估，从知识组件层面识别模型弱点，并提出两种针对性合成策略，同时引入增强的数据增强和选择管道来提升数据质量和多样性。实验结果显示，该方法显著改善了开源模型的表现，在代码生成、数学推理和学术考试等基准上分别提升了6.00%、13.10%和5.43%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07674v2",
      "published_date": "2025-01-13 20:13:59 UTC",
      "updated_date": "2025-03-05 18:39:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:55:14.398837"
    },
    {
      "arxiv_id": "2501.07653v2",
      "title": "Large Language Models for Interpretable Mental Health Diagnosis",
      "title_zh": "翻译失败",
      "authors": [
        "Brian Hyeongseok Kim",
        "Chao Wang"
      ],
      "abstract": "We propose a clinical decision support system (CDSS) for mental health\ndiagnosis that combines the strengths of large language models (LLMs) and\nconstraint logic programming (CLP). Having a CDSS is important because of the\nhigh complexity of diagnostic manuals used by mental health professionals and\nthe danger of diagnostic errors. Our CDSS is a software tool that uses an LLM\nto translate diagnostic manuals to a logic program and solves the program using\nan off-the-shelf CLP engine to query a patient's diagnosis based on the encoded\nrules and provided data. By giving domain experts the opportunity to inspect\nthe LLM-generated logic program, and making modifications when needed, our CDSS\nensures that the diagnosis is not only accurate but also interpretable. We\nexperimentally compare it with two baseline approaches of using LLMs:\ndiagnosing patients using the LLM-only approach, and using the LLM-generated\nlogic program but without expert inspection. The results show that, while LLMs\nare extremely useful in generating candidate logic programs, these programs\nstill require expert inspection and modification to guarantee faithfulness to\nthe official diagnostic manuals. Additionally, ethical concerns arise from the\ndirect use of patient data in LLMs, underscoring the need for a safer hybrid\napproach like our proposed method.",
      "tldr_zh": "该研究提出了一种结合大型语言模型（LLMs）和约束逻辑编程（CLP）的临床决策支持系统（CDSS），旨在提升精神健康诊断的可解释性和准确性，以应对诊断手册复杂性和错误风险。该系统利用LLMs将诊断手册转化为逻辑程序，并通过CLP引擎结合患者数据进行诊断查询，同时允许领域专家审查和修改程序以确保忠实于官方标准。实验结果显示，与纯LLMs诊断或无专家检查的基线相比，这种混合方法显著提高了诊断准确性，但强调了直接使用患者数据在LLMs中可能引发的伦理问题，从而突显了安全混合方法的必要性。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at AAAI 2025 Workshop on Large Language Models and\n  Generative AI for Health (GenAI4Health)",
      "pdf_url": "http://arxiv.org/pdf/2501.07653v2",
      "published_date": "2025-01-13 19:26:09 UTC",
      "updated_date": "2025-02-21 17:32:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:55:26.164796"
    },
    {
      "arxiv_id": "2501.07647v1",
      "title": "BlobGEN-Vid: Compositional Text-to-Video Generation with Blob Video Representations",
      "title_zh": "BlobGEN-Vid：基于",
      "authors": [
        "Weixi Feng",
        "Chao Liu",
        "Sifei Liu",
        "William Yang Wang",
        "Arash Vahdat",
        "Weili Nie"
      ],
      "abstract": "Existing video generation models struggle to follow complex text prompts and\nsynthesize multiple objects, raising the need for additional grounding input\nfor improved controllability. In this work, we propose to decompose videos into\nvisual primitives - blob video representation, a general representation for\ncontrollable video generation. Based on blob conditions, we develop a\nblob-grounded video diffusion model named BlobGEN-Vid that allows users to\ncontrol object motions and fine-grained object appearance. In particular, we\nintroduce a masked 3D attention module that effectively improves regional\nconsistency across frames. In addition, we introduce a learnable module to\ninterpolate text embeddings so that users can control semantics in specific\nframes and obtain smooth object transitions. We show that our framework is\nmodel-agnostic and build BlobGEN-Vid based on both U-Net and DiT-based video\ndiffusion models. Extensive experimental results show that BlobGEN-Vid achieves\nsuperior zero-shot video generation ability and state-of-the-art layout\ncontrollability on multiple benchmarks. When combined with an LLM for layout\nplanning, our framework even outperforms proprietary text-to-video generators\nin terms of compositional accuracy.",
      "tldr_zh": "该研究针对现有视频生成模型在处理复杂文本提示和合成多个对象时的局限性，提出了一种基于 blob video representation 的可控视频生成框架。BlobGEN-Vid 模型利用 blob 条件来控制对象运动和细粒度外观，并引入 masked 3D attention module 以提升帧间区域一致性，以及一个可学习的文本嵌入插值模块来实现特定帧语义控制和平滑过渡。该框架模型无关，可应用于 U-Net 和 DiT-based video diffusion models 的基础上；实验结果显示，BlobGEN-Vid 在多个基准上实现了优越的零样本视频生成能力和最先进的布局可控性，甚至在结合 LLM 进行布局规划时，超过了专有文本到视频生成器的组合准确性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://blobgen-vid2.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2501.07647v1",
      "published_date": "2025-01-13 19:17:06 UTC",
      "updated_date": "2025-01-13 19:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:55:39.452997"
    },
    {
      "arxiv_id": "2501.07639v1",
      "title": "SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Fabien Bernier",
        "Jun Cao",
        "Maxime Cordy",
        "Salah Ghamizi"
      ],
      "abstract": "Efficiently solving Optimal Power Flow (OPF) problems in power systems is\ncrucial for operational planning and grid management. There is a growing need\nfor scalable algorithms capable of handling the increasing variability,\nconstraints, and uncertainties in modern power networks while providing\naccurate and fast solutions. To address this, machine learning techniques,\nparticularly Graph Neural Networks (GNNs) have emerged as promising approaches.\nThis letter introduces SafePowerGraph-LLM, the first framework explicitly\ndesigned for solving OPF problems using Large Language Models (LLM)s. The\nproposed approach combines graph and tabular representations of power grids to\neffectively query LLMs, capturing the complex relationships and constraints in\npower systems. A new implementation of in-context learning and fine-tuning\nprotocols for LLMs is introduced, tailored specifically for the OPF problem.\nSafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.\nOur study reveals the impact of LLM architecture, size, and fine-tuning and\ndemonstrates our framework's ability to handle realistic grid components and\nconstraints.",
      "tldr_zh": "这篇论文引入了 SafePowerGraph-LLM 框架，这是首个专门使用 Large Language Models (LLMs) 来解决 Optimal Power Flow (OPF) 问题的创新方法，以应对现代电力系统的变异性、约束和不确定性。框架通过结合电力网格的图表示和表格表示来查询 LLMs，并引入定制的 in-context learning 和 fine-tuning 协议，以捕捉复杂的电网关系和约束。实验结果显示，SafePowerGraph-LLM 在使用现成 LLMs 时表现出可靠性能，并揭示了 LLM 架构、大小和 fine-tuning 对性能的影响，使其能够有效处理真实电网组件和约束。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07639v1",
      "published_date": "2025-01-13 19:01:58 UTC",
      "updated_date": "2025-01-13 19:01:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:55:51.570947"
    },
    {
      "arxiv_id": "2501.07575v1",
      "title": "Dataset Distillation via Committee Voting",
      "title_zh": "基于委员会投票的数据集蒸馏",
      "authors": [
        "Jiacheng Cui",
        "Zhaoyi Li",
        "Xiaochen Ma",
        "Xinyue Bi",
        "Yaxin Luo",
        "Zhiqiang Shen"
      ],
      "abstract": "Dataset distillation aims to synthesize a smaller, representative dataset\nthat preserves the essential properties of the original data, enabling\nefficient model training with reduced computational resources. Prior work has\nprimarily focused on improving the alignment or matching process between\noriginal and synthetic data, or on enhancing the efficiency of distilling large\ndatasets. In this work, we introduce ${\\bf C}$ommittee ${\\bf V}$oting for ${\\bf\nD}$ataset ${\\bf D}$istillation (CV-DD), a novel and orthogonal approach that\nleverages the collective wisdom of multiple models or experts to create\nhigh-quality distilled datasets. We start by showing how to establish a strong\nbaseline that already achieves state-of-the-art accuracy through leveraging\nrecent advancements and thoughtful adjustments in model design and optimization\nprocesses. By integrating distributions and predictions from a committee of\nmodels while generating high-quality soft labels, our method captures a wider\nspectrum of data features, reduces model-specific biases and the adverse\neffects of distribution shifts, leading to significant improvements in\ngeneralization. This voting-based strategy not only promotes diversity and\nrobustness within the distilled dataset but also significantly reduces\noverfitting, resulting in improved performance on post-eval tasks. Extensive\nexperiments across various datasets and IPCs (images per class) demonstrate\nthat Committee Voting leads to more reliable and adaptable distilled data\ncompared to single/multi-model distillation methods, demonstrating its\npotential for efficient and accurate dataset distillation. Code is available\nat: https://github.com/Jiacheng8/CV-DD.",
      "tldr_zh": "这篇论文提出了 Committee Voting for Dataset Distillation (CV-DD)，一种新颖的方法，利用多个模型的集体智慧来合成高质量的蒸馏数据集，从而保留原始数据的关键特性并减少训练资源。CV-DD 通过整合模型的分布和预测生成软标签，捕捉更多数据特征、降低模型偏差和分布偏移，提升数据集的泛化能力和鲁棒性，同时减少过拟合。实验在多种数据集和 IPCs 上表明，CV-DD 比传统单模型或多模型方法提高了性能和准确率，展示了其在高效数据集蒸馏中的潜力。代码已在 GitHub 上开源。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code at: https://github.com/Jiacheng8/CV-DD",
      "pdf_url": "http://arxiv.org/pdf/2501.07575v1",
      "published_date": "2025-01-13 18:59:48 UTC",
      "updated_date": "2025-01-13 18:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:57:56.677138"
    },
    {
      "arxiv_id": "2501.07574v1",
      "title": "UnCommon Objects in 3D",
      "title_zh": "翻译失败",
      "authors": [
        "Xingchen Liu",
        "Piyush Tayal",
        "Jianyuan Wang",
        "Jesus Zarzar",
        "Tom Monnier",
        "Konstantinos Tertikas",
        "Jiali Duan",
        "Antoine Toisoul",
        "Jason Y. Zhang",
        "Natalia Neverova",
        "Andrea Vedaldi",
        "Roman Shapovalov",
        "David Novotny"
      ],
      "abstract": "We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for\n3D deep learning and 3D generative AI. uCO3D is the largest publicly-available\ncollection of high-resolution videos of objects with 3D annotations that\nensures full-360$^{\\circ}$ coverage. uCO3D is significantly more diverse than\nMVImgNet and CO3Dv2, covering more than 1,000 object categories. It is also of\nhigher quality, due to extensive quality checks of both the collected videos\nand the 3D annotations. Similar to analogous datasets, uCO3D contains\nannotations for 3D camera poses, depth maps and sparse point clouds. In\naddition, each object is equipped with a caption and a 3D Gaussian Splat\nreconstruction. We train several large 3D models on MVImgNet, CO3Dv2, and uCO3D\nand obtain superior results using the latter, showing that uCO3D is better for\nlearning applications.",
      "tldr_zh": "我们引入了 uCO3D，这是一个新的对象中心数据集，用于 3D 深度学习和 3D 生成 AI，它是最大的公开可用高分辨率视频集合，涵盖超过 1000 个对象类别并确保 360° 覆盖。相比 MVImgNet 和 CO3Dv2，uCO3D 具有更高的质量，通过严格的质量检查，并提供 3D 相机位姿、深度图、稀疏点云、标题和 3D Gaussian Splat 重建等注释。实验结果显示，在 uCO3D 上训练的模型表现出 superior 性能，证明其在学习应用中的优势。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07574v1",
      "published_date": "2025-01-13 18:59:20 UTC",
      "updated_date": "2025-01-13 18:59:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:56:15.384157"
    },
    {
      "arxiv_id": "2501.07572v2",
      "title": "WebWalker: Benchmarking LLMs in Web Traversal",
      "title_zh": "WebWalker：大语言模型在网络遍历中的基准测试",
      "authors": [
        "Jialong Wu",
        "Wenbiao Yin",
        "Yong Jiang",
        "Zhenglin Wang",
        "Zekun Xi",
        "Runnan Fang",
        "Linhai Zhang",
        "Yulan He",
        "Deyu Zhou",
        "Pengjun Xie",
        "Fei Huang"
      ],
      "abstract": "Retrieval-augmented generation (RAG) demonstrates remarkable performance\nacross tasks in open-domain question-answering. However, traditional search\nengines may retrieve shallow content, limiting the ability of LLMs to handle\ncomplex, multi-layered information. To address it, we introduce WebWalkerQA, a\nbenchmark designed to assess the ability of LLMs to perform web traversal. It\nevaluates the capacity of LLMs to traverse a website's subpages to extract\nhigh-quality data systematically. We propose WebWalker, which is a multi-agent\nframework that mimics human-like web navigation through an explore-critic\nparadigm. Extensive experimental results show that WebWalkerQA is challenging\nand demonstrates the effectiveness of RAG combined with WebWalker, through the\nhorizontal and vertical integration in real-world scenarios.",
      "tldr_zh": "本文提出 WebWalkerQA 基准，用于评估大型语言模型 (LLMs) 在网页遍历中的能力，解决传统检索增强生成 (RAG) 可能只检索浅层内容，从而限制处理复杂多层信息的局限性。WebWalker 是一个多智能体框架，通过 explore-critic 范式模仿人类网页导航，帮助系统遍历网站子页面并系统提取高质量数据。实验结果显示，WebWalkerQA 具有高度挑战性，且 RAG 与 WebWalker 的结合在真实场景中实现了有效的横向和纵向整合。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07572v2",
      "published_date": "2025-01-13 18:58:07 UTC",
      "updated_date": "2025-01-14 15:06:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:56:26.833113"
    },
    {
      "arxiv_id": "2501.07531v1",
      "title": "Evaluating Agent-based Program Repair at Google",
      "title_zh": "在 Google 评估基于代理的程序修复",
      "authors": [
        "Pat Rondon",
        "Renyao Wei",
        "José Cambronero",
        "Jürgen Cito",
        "Aaron Sun",
        "Siddhant Sanyam",
        "Michele Tufano",
        "Satish Chandra"
      ],
      "abstract": "Agent-based program repair offers to automatically resolve complex bugs\nend-to-end by combining the planning, tool use, and code generation abilities\nof modern LLMs. Recent work has explored the use of agent-based repair\napproaches on the popular open-source SWE-Bench, a collection of bugs from\nhighly-rated GitHub Python projects. In addition, various agentic approaches\nsuch as SWE-Agent have been proposed to solve bugs in this benchmark. This\npaper explores the viability of using an agentic approach to address bugs in an\nenterprise context. To investigate this, we curate an evaluation set of 178\nbugs drawn from Google's issue tracking system. This dataset spans both\nhuman-reported (78) and machine-reported bugs (100).\n  To establish a repair performance baseline on this benchmark, we implement\nPasserine, an agent similar in spirit to SWE-Agent that can work within\nGoogle's development environment. We show that with 20 trajectory samples and\nGemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e.,\nplausible) for 73% of machine-reported and 25.6% of human-reported bugs in our\nevaluation set. After manual examination, we found that 43% of machine-reported\nbugs and 17.9% of human-reported bugs have at least one patch that is\nsemantically equivalent to the ground-truth patch.\n  These results establish a baseline on an industrially relevant benchmark,\nwhich as we show, contains bugs drawn from a different distribution -- in terms\nof language diversity, size, and spread of changes, etc. -- compared to those\nin the popular SWE-Bench dataset.",
      "tldr_zh": "这篇论文评估了agent-based program repair在Google企业环境中的可行性，通过创建一个包含178个bug的数据集（包括78个人为报告和100个机器报告的bug）。他们实现了Passerine代理，类似于SWE-Agent，利用Gemini 1.5 Pro和20个轨迹样本，成功为73%的机器报告bug和25.6%的人为报告bug生成可通过测试的补丁。进一步手动检查发现，43%的机器报告bug和17.9%的人为报告bug有语义等价的补丁，这些结果为工业相关基准建立了性能基线，并强调了该数据集在语言多样性、代码规模和变化分布等方面与SWE-Bench的差异。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07531v1",
      "published_date": "2025-01-13 18:09:25 UTC",
      "updated_date": "2025-01-13 18:09:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:58:10.022960"
    },
    {
      "arxiv_id": "2501.07525v1",
      "title": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment",
      "title_zh": "RadAlign：通过视觉-语言概念对齐推进放射学报告生成",
      "authors": [
        "Difei Gu",
        "Yunhe Gao",
        "Yang Zhou",
        "Mu Zhou",
        "Dimitris Metaxas"
      ],
      "abstract": "Automated chest radiographs interpretation requires both accurate disease\nclassification and detailed radiology report generation, presenting a\nsignificant challenge in the clinical workflow. Current approaches either focus\non classification accuracy at the expense of interpretability or generate\ndetailed but potentially unreliable reports through image captioning\ntechniques. In this study, we present RadAlign, a novel framework that combines\nthe predictive accuracy of vision-language models (VLMs) with the reasoning\ncapabilities of large language models (LLMs). Inspired by the radiologist's\nworkflow, RadAlign first employs a specialized VLM to align visual features\nwith key medical concepts, achieving superior disease classification with an\naverage AUC of 0.885 across multiple diseases. These recognized medical\nconditions, represented as text-based concepts in the aligned visual-language\nspace, are then used to prompt LLM-based report generation. Enhanced by a\nretrieval-augmented generation mechanism that grounds outputs in similar\nhistorical cases, RadAlign delivers superior report quality with a GREEN score\nof 0.678, outperforming state-of-the-art methods' 0.634. Our framework\nmaintains strong clinical interpretability while reducing hallucinations,\nadvancing automated medical imaging and report analysis through integrated\npredictive and generative AI. Code is available at\nhttps://github.com/difeigu/RadAlign.",
      "tldr_zh": "该研究提出RadAlign框架，旨在提升胸部X光片解释的疾病分类准确性和放射学报告生成质量，通过结合视觉语言模型(VLM)和大型语言模型(LLM)来解决现有方法的局限性。RadAlign首先使用VLM对视觉特征与关键医疗概念对齐，实现平均AUC 0.885的出色分类性能，然后通过这些概念提示LLM生成报告，并采用检索增强生成(RAG)机制基于类似历史病例进行增强。实验结果显示，RadAlign的报告质量达到GREEN score 0.678，优于现有方法的0.634，同时提高了临床可解释性和减少了幻觉，为自动化医疗成像分析提供了先进解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07525v1",
      "published_date": "2025-01-13 17:55:32 UTC",
      "updated_date": "2025-01-13 17:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:58:20.110938"
    },
    {
      "arxiv_id": "2501.07523v2",
      "title": "Parallel Key-Value Cache Fusion for Position Invariant RAG",
      "title_zh": "翻译失败",
      "authors": [
        "Philhoon Oh",
        "Jinwoo Shin",
        "James Thorne"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) underscore the necessity\nof Retrieval Augmented Generation (RAG) to leverage external information.\nHowever, LLMs are sensitive to the position of relevant information within\ncontexts and tend to generate incorrect responses when such information is\nplaced in the middle, known as `Lost in the Middle' phenomenon. In this paper,\nwe introduce a framework that generates consistent outputs for decoder-only\nmodels, irrespective of the input context order. Experimental results for three\nopen domain question answering tasks demonstrate position invariance, where the\nmodel is not sensitive to input context order, and superior robustness to\nirrelevent passages compared to prevailing approaches for RAG pipelines.",
      "tldr_zh": "本论文针对大型语言模型（LLMs）在检索增强生成（RAG）中的“Lost in the Middle”现象提出了一种Parallel Key-Value Cache Fusion框架，该框架使解码器-only模型的输出与输入上下文顺序无关，从而提升了模型的鲁棒性。该方法通过融合关键-值缓存来实现位置不变性，确保相关信息无论放置在哪里都能被正确处理。实验结果显示，在三个开放领域问答任务上，该框架比现有RAG方法更鲁棒，并显著减少了对无关段落的敏感性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "5 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07523v2",
      "published_date": "2025-01-13 17:50:30 UTC",
      "updated_date": "2025-01-23 06:48:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:58:31.537270"
    },
    {
      "arxiv_id": "2501.07515v1",
      "title": "The Paradox of Success in Evolutionary and Bioinspired Optimization: Revisiting Critical Issues, Key Studies, and Methodological Pathways",
      "title_zh": "进化优化和生物启发优化中的成功悖论：重新审视关键问题、关键研究和方法路径",
      "authors": [
        "Daniel Molina",
        "Javier Del Ser",
        "Javier Poyatos",
        "Francisco Herrera"
      ],
      "abstract": "Evolutionary and bioinspired computation are crucial for efficiently\naddressing complex optimization problems across diverse application domains. By\nmimicking processes observed in nature, like evolution itself, these algorithms\noffer innovative solutions beyond the reach of traditional optimization\nmethods. They excel at finding near-optimal solutions in large, complex search\nspaces, making them invaluable in numerous fields. However, both areas are\nplagued by challenges at their core, including inadequate benchmarking,\nproblem-specific overfitting, insufficient theoretical grounding, and\nsuperfluous proposals justified only by their biological metaphor. This\noverview recapitulates and analyzes in depth the criticisms concerning the lack\nof innovation and rigor in experimental studies within the field. To this end,\nwe examine the judgmental positions of the existing literature in an informed\nattempt to guide the research community toward directions of solid contribution\nand advancement in these areas. We summarize guidelines for the design of\nevolutionary and bioinspired optimizers, the development of experimental\ncomparisons, and the derivation of novel proposals that take a step further in\nthe field. We provide a brief note on automating the process of creating these\nalgorithms, which may help align metaheuristic optimization research with its\nprimary objective (solving real-world problems), provided that our identified\npathways are followed. Our conclusions underscore the need for a sustained push\ntowards innovation and the enforcement of methodological rigor in prospective\nstudies to fully realize the potential of these advanced computational\ntechniques.",
      "tldr_zh": "这篇论文审视了进化计算(evolutionary computation)和生物启发优化(bioinspired optimization)领域的成功悖论，强调这些算法在处理复杂优化问题时虽能模仿自然过程并提供创新解决方案，但面临挑战如不充分的基准测试(benchmarking)、问题特定过拟合(overfitting)、理论基础不足以及仅基于生物隐喻的冗余提案。作者通过分析现有文献的批评，总结了设计优化器、进行实验比较以及提出新方案的指导原则，以引导研究社区实现更可靠的贡献。论文还简要讨论了自动化算法创建的过程，旨在帮助这些领域更好地解决真实世界问题，前提是遵循严格的方法论路径。最终，结论呼吁持续推动创新和方法论严谨性，以充分发挥这些高级计算技术的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "I.2.8; I.2"
      ],
      "primary_category": "cs.NE",
      "comment": "38 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2501.07515v1",
      "published_date": "2025-01-13 17:37:37 UTC",
      "updated_date": "2025-01-13 17:37:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:58:44.445484"
    },
    {
      "arxiv_id": "2501.07507v1",
      "title": "Inductive Learning of Robot Task Knowledge from Raw Data and Online Expert Feedback",
      "title_zh": "从原始数据和在线专家反馈中归纳学习机器人任务知识",
      "authors": [
        "Daniele Meli",
        "Paolo Fiorini"
      ],
      "abstract": "The increasing level of autonomy of robots poses challenges of trust and\nsocial acceptance, especially in human-robot interaction scenarios. This\nrequires an interpretable implementation of robotic cognitive capabilities,\npossibly based on formal methods as logics for the definition of task\nspecifications. However, prior knowledge is often unavailable in complex\nrealistic scenarios.\n  In this paper, we propose an offline algorithm based on inductive logic\nprogramming from noisy examples to extract task specifications (i.e., action\npreconditions, constraints and effects) directly from raw data of few\nheterogeneous (i.e., not repetitive) robotic executions. Our algorithm\nleverages on the output of any unsupervised action identification algorithm\nfrom video-kinematic recordings. Combining it with the definition of very\nbasic, almost task-agnostic, commonsense concepts about the environment, which\ncontribute to the interpretability of our methodology, we are able to learn\nlogical axioms encoding preconditions of actions, as well as their effects in\nthe event calculus paradigm. Since the quality of learned specifications\ndepends mainly on the accuracy of the action identification algorithm, we also\npropose an online framework for incremental refinement of task knowledge from\nuser feedback, guaranteeing safe execution. Results in a standard manipulation\ntask and benchmark for user training in the safety-critical surgical robotic\nscenario, show the robustness, data- and time-efficiency of our methodology,\nwith promising results towards the scalability in more complex domains.",
      "tldr_zh": "该论文针对机器人自治带来的信任和接受度挑战，提出了一种基于归纳逻辑编程(Inductive Logic Programming)的离线算法，从少量异质机器人执行的原始数据中直接学习任务规范，包括动作先决条件、约束和效果。该算法结合无监督动作识别算法和基本常识概念，使用事件演算(Event Calculus)范式生成可解释的逻辑公理，并引入在线框架通过用户反馈进行增量精炼，确保机器人安全执行。在标准操作任务和安全关键的手术机器人场景中，实验结果证明了该方法的鲁棒性、数据和时间效率，并显示了其向更复杂领域的扩展潜力。",
      "categories": [
        "cs.AI",
        "cs.LO",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07507v1",
      "published_date": "2025-01-13 17:25:46 UTC",
      "updated_date": "2025-01-13 17:25:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:58:55.745611"
    },
    {
      "arxiv_id": "2501.07502v1",
      "title": "RbRL2.0: Integrated Reward and Policy Learning for Rating-based Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mingkang Wu",
        "Devin White",
        "Vernon Lawhern",
        "Nicholas R. Waytowich",
        "Yongcan Cao"
      ],
      "abstract": "Reinforcement learning (RL), a common tool in decision making, learns\npolicies from various experiences based on the associated cumulative\nreturn/rewards without treating them differently. On the contrary, humans often\nlearn to distinguish from different levels of performance and extract the\nunderlying trends towards improving their decision making for best performance.\nMotivated by this, this paper proposes a novel RL method that mimics humans'\ndecision making process by differentiating among collected experiences for\neffective policy learning. The main idea is to extract important directional\ninformation from experiences with different performance levels, named ratings,\nso that policies can be updated towards desired deviation from these\nexperiences with different ratings. Specifically, we propose a new policy loss\nfunction that penalizes distribution similarities between the current policy\nand failed experiences with different ratings, and assign different weights to\nthe penalty terms based on the rating classes. Meanwhile, reward learning from\nthese rated samples can be integrated with the new policy loss towards an\nintegrated reward and policy learning from rated samples. Optimizing the\nintegrated reward and policy loss function will lead to the discovery of\ndirections for policy improvement towards maximizing cumulative rewards and\npenalizing most from the lowest performance level while least from the highest\nperformance level. To evaluate the effectiveness of the proposed method, we\npresent results for experiments on a few typical environments that show\nimproved convergence and overall performance over the existing rating-based\nreinforcement learning method with only reward learning.",
      "tldr_zh": "该论文提出 RbRL2.0，一种基于评级（ratings）的强化学习（Reinforcement Learning）方法，旨在模仿人类决策过程，通过区分不同性能水平的体验来提升策略学习。核心创新包括设计一个新的策略损失函数，该函数惩罚当前策略与失败体验的分布相似度，并根据评分类别分配权重，同时整合奖励学习以从评分样本中优化策略。实验结果显示，该方法在典型环境中比现有基于评级的强化学习方法实现了更好的收敛速度和整体性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Collaborative AI and Modeling of Humans Bridge\n  Program at AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07502v1",
      "published_date": "2025-01-13 17:19:34 UTC",
      "updated_date": "2025-01-13 17:19:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:59:07.236039"
    },
    {
      "arxiv_id": "2501.07487v1",
      "title": "Data and System Perspectives of Sustainable Artificial Intelligence",
      "title_zh": "可持续人工智能的数据与系统视角",
      "authors": [
        "Tao Xie",
        "David Harel",
        "Dezhi Ran",
        "Zhenwen Li",
        "Maoliang Li",
        "Zhi Yang",
        "Leye Wang",
        "Xiang Chen",
        "Ying Zhang",
        "Wentao Zhang",
        "Meng Li",
        "Chen Zhang",
        "Linyi Li",
        "Assaf Marron"
      ],
      "abstract": "Sustainable AI is a subfield of AI for concerning developing and using AI\nsystems in ways of aiming to reduce environmental impact and achieve\nsustainability. Sustainable AI is increasingly important given that training of\nand inference with AI models such as large langrage models are consuming a\nlarge amount of computing power. In this article, we discuss current issues,\nopportunities and example solutions for addressing these issues, and future\nchallenges to tackle, from the data and system perspectives, related to data\nacquisition, data processing, and AI model training and inference.",
      "tldr_zh": "这篇论文从数据和系统视角探讨Sustainable AI，即开发和使用AI系统以减少环境影响并实现可持续性的子领域。论文强调，AI models如large language models的训练和推理消耗大量计算资源，导致环境问题，并分析了相关当前问题、机会和示例解决方案。重点讨论了数据获取、数据处理、AI模型训练和推理等环节的挑战，并提出了未来应对策略，以推动AI领域的可持续发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07487v1",
      "published_date": "2025-01-13 17:04:23 UTC",
      "updated_date": "2025-01-13 17:04:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:59:20.228849"
    },
    {
      "arxiv_id": "2501.07486v1",
      "title": "Smart Learning in the 21st Century: Advancing Constructionism Across Three Digital Epochs",
      "title_zh": "翻译失败",
      "authors": [
        "Ilya Levin",
        "Alexei L. Semenov",
        "Mikael Gorsky"
      ],
      "abstract": "This article explores the evolution of constructionism as an educational\nframework, tracing its relevance and transformation across three pivotal eras:\nthe advent of personal computing, the networked society, and the current era of\ngenerative AI. Rooted in Seymour Papert constructionist philosophy, this study\nexamines how constructionist principles align with the expanding role of\ndigital technology in personal and collective learning. We discuss the\ntransformation of educational environments from hierarchical instructionism to\nconstructionist models that emphasize learner autonomy and interactive,\ncreative engagement. Central to this analysis is the concept of an expanded\npersonality, wherein digital tools and AI integration fundamentally reshape\nindividual self-perception and social interactions. By integrating\nconstructionism into the paradigm of smart education, we propose it as a\nfoundational approach to personalized and democratized learning. Our findings\nunderscore constructionism enduring relevance in navigating the complexities of\ntechnology-driven education, providing insights for educators and policymakers\nseeking to harness digital innovations to foster adaptive, student-centered\nlearning experiences.",
      "tldr_zh": "这篇文章探讨了 constructionism 作为教育框架的演变，跨越个人计算、网络化社会和 generative AI 三个数字时代，并基于 Seymour Papert 的哲学考察其与数字技术在学习中的整合。研究分析了教育环境从 hierarchical instructionism 向强调学习者自治、互动和创造性参与的 constructionist 模型的转变。作者引入 expanded personality 概念，解释数字工具和 AI 如何重塑个体自我认知和社会互动，并提出将 constructionism 作为 smart education 的核心方法，以推动个性化、民主化的学习。最后，研究强调 constructionism 在技术驱动教育中的持续相关性，为教育者和政策制定者提供利用数字创新促进学生中心学习体验的洞见。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "22 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07486v1",
      "published_date": "2025-01-13 17:04:06 UTC",
      "updated_date": "2025-01-13 17:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:59:33.176860"
    },
    {
      "arxiv_id": "2501.07482v2",
      "title": "TiEBe: Tracking Language Model Recall of Notable Worldwide Events Through Time",
      "title_zh": "翻译失败",
      "authors": [
        "Thales Sales Almeida",
        "Giovana Kerche Bonás",
        "João Guilherme Alves Santos",
        "Hugo Abonizio",
        "Rodrigo Nogueira"
      ],
      "abstract": "As the knowledge landscape evolves and large language models (LLMs) become\nincreasingly widespread, there is a growing need to keep these models updated\nwith current events. While existing benchmarks assess general factual recall,\nfew studies explore how LLMs retain knowledge over time or across different\nregions. To address these gaps, we present the Timely Events Benchmark (TiEBe),\na dataset of over 23,000 question-answer pairs centered on notable global and\nregional events, spanning more than 10 years of events, 23 regions, and 13\nlanguages. TiEBe leverages structured retrospective data from Wikipedia to\nidentify notable events through time. These events are then used to construct a\nbenchmark to evaluate LLMs' understanding of global and regional developments,\ngrounded in factual evidence beyond Wikipedia itself. Our results reveal\nsignificant geographic disparities in factual recall, emphasizing the need for\nmore balanced global representation in LLM training. We also observe a Pearson\ncorrelation of more than 0.7 between models' performance in TiEBe and various\ncountries' socioeconomic indicators, such as HDI. In addition, we examine the\nimpact of language on factual recall by posing questions in the native language\nof the region where each event occurred, uncovering substantial performance\ngaps for low-resource languages.",
      "tldr_zh": "这篇论文提出了 TiEBe 基准数据集，用于评估大型语言模型 (LLMs) 对全球和区域重要事件的知识保留，涵盖超过 23,000 个问题-答案对，涉及 10 多年、23 个地区和 13 种语言，并利用 Wikipedia 的结构化数据构建。TiEBe 通过事实证据测试 LLMs 对全球发展的理解，结果显示存在显著的地理差异，以及模型性能与国家 socioeconomic indicators 如 HDI 的 Pearson correlation 高达 0.7 以上。研究还发现，使用事件发生地区的本地语言提问时，低资源语言的 factual recall 表现存在明显差距，这强调了 LLM 训练中需要更均衡的全球表示。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07482v2",
      "published_date": "2025-01-13 16:58:32 UTC",
      "updated_date": "2025-05-20 17:09:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:59:44.307959"
    },
    {
      "arxiv_id": "2501.07474v1",
      "title": "Estimating Musical Surprisal in Audio",
      "title_zh": "翻译失败",
      "authors": [
        "Mathias Rose Bjare",
        "Giorgia Cantisani",
        "Stefan Lattner",
        "Gerhard Widmer"
      ],
      "abstract": "In modeling musical surprisal expectancy with computational methods, it has\nbeen proposed to use the information content (IC) of one-step predictions from\nan autoregressive model as a proxy for surprisal in symbolic music. With an\nappropriately chosen model, the IC of musical events has been shown to\ncorrelate with human perception of surprise and complexity aspects, including\ntonal and rhythmic complexity. This work investigates whether an analogous\nmethodology can be applied to music audio. We train an autoregressive\nTransformer model to predict compressed latent audio representations of a\npretrained autoencoder network. We verify learning effects by estimating the\ndecrease in IC with repetitions. We investigate the mean IC of musical segment\ntypes (e.g., A or B) and find that segment types appearing later in a piece\nhave a higher IC than earlier ones on average. We investigate the IC's relation\nto audio and musical features and find it correlated with timbral variations\nand loudness and, to a lesser extent, dissonance, rhythmic complexity, and\nonset density related to audio and musical features. Finally, we investigate if\nthe IC can predict EEG responses to songs and thus model humans' surprisal in\nmusic. We provide code for our method on github.com/sonycslparis/audioic.",
      "tldr_zh": "这篇论文探讨了使用信息内容（IC）来估计音频音乐中的惊喜感，扩展了之前在符号音乐中的方法。研究者训练了一个自回归 Transformer 模型来预测预训练自编码器的压缩音频表示，并通过分析 IC 的变化验证了模型的学习效果。结果显示，IC 与音色变化和响度高度相关，与不和谐、节奏复杂性和起始密度有较弱关联；此外，IC 能预测 EEG 对歌曲的响应，表明它可用于模拟人类的音乐惊喜。最终，论文提供了相关代码以促进进一步研究。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 pages, 2 figures, 1 table. Accepted at the 2025 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP 2025),\n  Hyderabad, India",
      "pdf_url": "http://arxiv.org/pdf/2501.07474v1",
      "published_date": "2025-01-13 16:46:45 UTC",
      "updated_date": "2025-01-13 16:46:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T22:59:56.010871"
    },
    {
      "arxiv_id": "2501.07468v3",
      "title": "From Screens to Scenes: A Survey of Embodied AI in Healthcare",
      "title_zh": "从屏幕到场景：具身 AI 在医疗保健中的综述",
      "authors": [
        "Yihao Liu",
        "Xu Cao",
        "Tingting Chen",
        "Yankai Jiang",
        "Junjie You",
        "Minghua Wu",
        "Xiaosong Wang",
        "Mengling Feng",
        "Yaochu Jin",
        "Jintai Chen"
      ],
      "abstract": "Healthcare systems worldwide face persistent challenges in efficiency,\naccessibility, and personalization. Powered by modern AI technologies such as\nmultimodal large language models and world models, Embodied AI (EmAI)\nrepresents a transformative frontier, offering enhanced autonomy and the\nability to interact with the physical world to address these challenges. As an\ninterdisciplinary and rapidly evolving research domain, \"EmAI in healthcare\"\nspans diverse fields such as algorithms, robotics, and biomedicine. This\ncomplexity underscores the importance of timely reviews and analyses to track\nadvancements, address challenges, and foster cross-disciplinary collaboration.\nIn this paper, we provide a comprehensive overview of the \"brain\" of EmAI for\nhealthcare, wherein we introduce foundational AI algorithms for perception,\nactuation, planning, and memory, and focus on presenting the healthcare\napplications spanning clinical interventions, daily care & companionship,\ninfrastructure support, and biomedical research. Despite its promise, the\ndevelopment of EmAI for healthcare is hindered by critical challenges such as\nsafety concerns, gaps between simulation platforms and real-world applications,\nthe absence of standardized benchmarks, and uneven progress across\ninterdisciplinary domains. We discuss the technical barriers and explore\nethical considerations, offering a forward-looking perspective on the future of\nEmAI in healthcare. A hierarchical framework of intelligent levels for EmAI\nsystems is also introduced to guide further development. By providing\nsystematic insights, this work aims to inspire innovation and practical\napplications, paving the way for a new era of intelligent, patient-centered\nhealthcare.",
      "tldr_zh": "这篇论文对Embodied AI (EmAI)在医疗领域的应用进行了全面调查，旨在解决医疗系统的效率、可访问性和个性化挑战。论文介绍了EmAI的核心AI算法，包括感知、执行、规划和记忆，并探讨了其在临床干预、日常护理、基础设施支持以及生物医学研究中的实际应用。尽管EmAI具有巨大潜力，但论文指出了关键障碍，如安全问题、模拟与现实差距、缺乏标准化基准，以及跨学科进展不均，并探讨了道德考虑。最终，论文提出一个层次化智能水平框架，以指导未来发展，并推动创新，实现智能、患者中心化的医疗新时代。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "56 pages, 11 figures, manuscript accepted by Information Fusion",
      "pdf_url": "http://arxiv.org/pdf/2501.07468v3",
      "published_date": "2025-01-13 16:35:52 UTC",
      "updated_date": "2025-03-02 16:57:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:00:07.840871"
    },
    {
      "arxiv_id": "2501.07458v1",
      "title": "Understanding and Benchmarking Artificial Intelligence: OpenAI's o3 Is Not AGI",
      "title_zh": "翻译失败",
      "authors": [
        "Rolf Pfister",
        "Hansueli Jud"
      ],
      "abstract": "OpenAI's o3 achieves a high score of 87.5 % on ARC-AGI, a benchmark proposed\nto measure intelligence. This raises the question whether systems based on\nLarge Language Models (LLMs), particularly o3, demonstrate intelligence and\nprogress towards artificial general intelligence (AGI). Building on the\ndistinction between skills and intelligence made by Fran\\c{c}ois Chollet, the\ncreator of ARC-AGI, a new understanding of intelligence is introduced: an agent\nis the more intelligent, the more efficiently it can achieve the more diverse\ngoals in the more diverse worlds with the less knowledge. An analysis of the\nARC-AGI benchmark shows that its tasks represent a very specific type of\nproblem that can be solved by massive trialling of combinations of predefined\noperations. This method is also applied by o3, achieving its high score through\nthe extensive use of computing power. However, for most problems in the\nphysical world and in the human domain, solutions cannot be tested in advance\nand predefined operations are not available. Consequently, massive trialling of\npredefined operations, as o3 does, cannot be a basis for AGI - instead, new\napproaches are required that can reliably solve a wide variety of problems\nwithout existing skills. To support this development, a new benchmark for\nintelligence is outlined that covers a much higher diversity of unknown tasks\nto be solved, thus enabling a comprehensive assessment of intelligence and of\nprogress towards AGI.",
      "tldr_zh": "该论文分析了 OpenAI 的 o3 模型在 ARC-AGI 基准上取得 87.5% 高分，但强调这并不代表真正的智能或 AGI。作者引入了新的智能定义：一个代理的智能程度取决于它能以更少的知识在更多样化的世界中更高效地实现更多样化的目标。研究发现，o3 通过大规模试验预定义操作的组合来解决 ARC-AGI 任务，这依赖于计算资源，但无法应用于现实世界的未知问题，因此不是 AGI 的基础。论文提出一个新的基准测试，以涵盖更广泛的未知任务，从而更全面地评估智能和向 AGI 的进展。",
      "categories": [
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07458v1",
      "published_date": "2025-01-13 16:28:01 UTC",
      "updated_date": "2025-01-13 16:28:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:00:20.818586"
    },
    {
      "arxiv_id": "2501.07445v1",
      "title": "Online inductive learning from answer sets for efficient reinforcement learning exploration",
      "title_zh": "翻译失败",
      "authors": [
        "Celeste Veronese",
        "Daniele Meli",
        "Alessandro Farinelli"
      ],
      "abstract": "This paper presents a novel approach combining inductive logic programming\nwith reinforcement learning to improve training performance and explainability.\nWe exploit inductive learning of answer set programs from noisy examples to\nlearn a set of logical rules representing an explainable approximation of the\nagent policy at each batch of experience. We then perform answer set reasoning\non the learned rules to guide the exploration of the learning agent at the next\nbatch, without requiring inefficient reward shaping and preserving optimality\nwith soft bias. The entire procedure is conducted during the online execution\nof the reinforcement learning algorithm. We preliminarily validate the efficacy\nof our approach by integrating it into the Q-learning algorithm for the Pac-Man\nscenario in two maps of increasing complexity. Our methodology produces a\nsignificant boost in the discounted return achieved by the agent, even in the\nfirst batches of training. Moreover, inductive learning does not compromise the\ncomputational time required by Q-learning and learned rules quickly converge to\nan explanation of the agent policy.",
      "tldr_zh": "本论文提出了一种结合归纳逻辑编程(inductive logic programming)和强化学习(reinforcement learning)的创新方法，以提高训练效率和代理策略的可解释性。该方法通过从噪声示例中学习答案集程序(answer set programs)的逻辑规则，并利用答案集推理(answer set reasoning)在线指导代理的探索过程，从而避免了低效的奖励整形并保持最优性。在 Pac-Man 场景的 Q-learning 实验中，该方法显著提升了代理的折扣回报，甚至在训练初期就显现效果，且不增加计算时间，学习规则快速收敛。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07445v1",
      "published_date": "2025-01-13 16:13:22 UTC",
      "updated_date": "2025-01-13 16:13:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:00:32.814713"
    },
    {
      "arxiv_id": "2501.07440v2",
      "title": "Attention when you need",
      "title_zh": "翻译失败",
      "authors": [
        "Lokesh Boominathan",
        "Yizhou Chen",
        "Matthew McGinley",
        "Xaq Pitkow"
      ],
      "abstract": "Being attentive to task-relevant features can improve task performance, but\npaying attention comes with its own metabolic cost. Therefore, strategic\nallocation of attention is crucial in performing the task efficiently. This\nwork aims to understand this strategy. Recently, de Gee et al. conducted\nexperiments involving mice performing an auditory sustained attention-value\ntask. This task required the mice to exert attention to identify whether a\nhigh-order acoustic feature was present amid the noise. By varying the trial\nduration and reward magnitude, the task allows us to investigate how an agent\nshould strategically deploy their attention to maximize their benefits and\nminimize their costs. In our work, we develop a reinforcement learning-based\nnormative model of the mice to understand how it balances attention cost\nagainst its benefits. The model is such that at each moment the mice can choose\nbetween two levels of attention and decide when to take costly actions that\ncould obtain rewards. Our model suggests that efficient use of attentional\nresources involves alternating blocks of high attention with blocks of low\nattention. In the extreme case where the agent disregards sensory input during\nlow attention states, we see that high attention is used rhythmically. Our\nmodel provides evidence about how one should deploy attention as a function of\ntask utility, signal statistics, and how attention affects sensory evidence.",
      "tldr_zh": "本研究探讨了注意力的战略分配，以平衡其对任务性能的提升与代谢成本。作者基于老鼠的听觉持续注意-价值任务实验，开发了一个强化学习(reinforcement learning)规范模型(normative model)，允许代理在每个时刻选择高或低注意力水平，并优化何时采取成本性行动以最大化收益。模型发现，高效的注意力使用涉及交替高注意力和低注意力块，尤其在低注意力状态忽略感官输入时，高注意力呈现节奏性模式。该模型还提供了根据任务效用、信号统计和注意力对感官证据的影响来部署注意力的证据。",
      "categories": [
        "q-bio.NC",
        "cs.AI"
      ],
      "primary_category": "q-bio.NC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07440v2",
      "published_date": "2025-01-13 16:08:47 UTC",
      "updated_date": "2025-01-29 16:04:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:00:44.606421"
    },
    {
      "arxiv_id": "2501.07432v1",
      "title": "Empirical Evaluation of the Implicit Hitting Set Approach for Weighted CSPs",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksandra Petrova",
        "Javier Larrosa",
        "Emma Rollón"
      ],
      "abstract": "SAT technology has proven to be surprisingly effective in a large variety of\ndomains. However, for the Weighted CSP problem dedicated algorithms have always\nbeen superior. One approach not well-studied so far is the use of SAT in\nconjunction with the Implicit Hitting Set approach. In this work, we explore\nsome alternatives to the existing algorithm of reference. The alternatives,\nmostly borrowed from related boolean frameworks, consider trade-offs for the\ntwo main components of the IHS approach: the computation of low-cost hitting\nvectors, and their transformation into high-cost cores. For each one, we\npropose 4 levels of intensity. Since we also test the usefulness of cost\nfunction merging, our experiments consider 32 different implementations. Our\nempirical study shows that for WCSP it is not easy to identify the best\nalternative. Nevertheless, the cost-function merging encoding and extracting\nmaximal cores seems to be a robust approach.",
      "tldr_zh": "这篇论文评估了 Implicit Hitting Set (IHS) 方法在 Weighted CSPs 中的应用，通过结合 SAT 技术探索现有算法的替代方案。作者针对 IHS 的两个核心组件——计算低成本 hitting vectors 和将其转化为高成本 cores——提出了每组件 4 个强度级别的变体，并测试了 cost-function merging 的效果，导致 32 个不同实现。实验结果显示，虽然在 Weighted CSPs 中难以确定最佳替代方案，但 cost-function merging 和提取 maximal cores 是一种稳健且有效的策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07432v1",
      "published_date": "2025-01-13 15:59:28 UTC",
      "updated_date": "2025-01-13 15:59:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:00:56.247831"
    },
    {
      "arxiv_id": "2501.07430v2",
      "title": "Introducing 3D Representation for Medical Image Volume-to-Volume Translation via Score Fusion",
      "title_zh": "翻译失败",
      "authors": [
        "Xiyue Zhu",
        "Dou Hoon Kwark",
        "Ruike Zhu",
        "Kaiwen Hong",
        "Yiqi Tao",
        "Shirui Luo",
        "Yudu Li",
        "Zhi-Pei Liang",
        "Volodymyr Kindratenko"
      ],
      "abstract": "In volume-to-volume translations in medical images, existing models often\nstruggle to capture the inherent volumetric distribution using 3D voxelspace\nrepresentations, due to high computational dataset demands. We present\nScore-Fusion, a novel volumetric translation model that effectively learns 3D\nrepresentations by ensembling perpendicularly trained 2D diffusion models in\nscore function space. By carefully initializing our model to start with an\naverage of 2D models as in TPDM, we reduce 3D training to a fine-tuning process\nand thereby mitigate both computational and data demands. Furthermore, we\nexplicitly design the 3D model's hierarchical layers to learn ensembles of 2D\nfeatures, further enhancing efficiency and performance. Moreover, Score-Fusion\nnaturally extends to multi-modality settings, by fusing diffusion models\nconditioned on different inputs for flexible, accurate integration. We\ndemonstrate that 3D representation is essential for better performance in\ndownstream recognition tasks, such as tumor segmentation, where most\nsegmentation models are based on 3D representation. Extensive experiments\ndemonstrate that Score-Fusion achieves superior accuracy and volumetric\nfidelity in 3D medical image super-resolution and modality translation. Beyond\nthese improvements, our work also provides broader insight into learning-based\napproaches for score function fusion.",
      "tldr_zh": "本研究针对医疗图像volume-to-volume translation中的问题，提出Score-Fusion模型，通过集成垂直训练的2D diffusion models在score function空间学习3D representation，从而克服高计算和数据需求的挑战。模型从TPDM的平均2D模型初始化，将3D训练简化为微调过程，并设计层次化层来融合2D特征，同时扩展到多模态设置以提升灵活性和准确性。实验结果显示，Score-Fusion在3D医疗图像超分辨率和模态翻译任务中实现 superior accuracy和volumetric fidelity，并证明3D representation对下游任务如tumor segmentation至关重要，为score function fusion的学习方法提供了新见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07430v2",
      "published_date": "2025-01-13 15:54:21 UTC",
      "updated_date": "2025-02-06 20:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:01:08.472185"
    },
    {
      "arxiv_id": "2501.07423v1",
      "title": "An Investigation into Seasonal Variations in Energy Forecasting for Student Residences",
      "title_zh": "对学生宿舍能源预测中季节性变化的调查研究",
      "authors": [
        "Muhammad Umair Danish",
        "Mathumitha Sureshkumar",
        "Thanuri Fonseka",
        "Umeshika Uthayakumar",
        "Vinura Galwaduge"
      ],
      "abstract": "This research provides an in-depth evaluation of various machine learning\nmodels for energy forecasting, focusing on the unique challenges of seasonal\nvariations in student residential settings. The study assesses the performance\nof baseline models, such as LSTM and GRU, alongside state-of-the-art\nforecasting methods, including Autoregressive Feedforward Neural Networks,\nTransformers, and hybrid approaches. Special attention is given to predicting\nenergy consumption amidst challenges like seasonal patterns, vacations,\nmeteorological changes, and irregular human activities that cause sudden\nfluctuations in usage. The findings reveal that no single model consistently\noutperforms others across all seasons, emphasizing the need for season-specific\nmodel selection or tailored designs. Notably, the proposed Hyper Network based\nLSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal\nvariations, effectively capturing abrupt changes in energy consumption during\nsummer months. This study advances the energy forecasting field by emphasizing\nthe critical role of seasonal dynamics and model-specific behavior in achieving\naccurate predictions.",
      "tldr_zh": "这篇论文调查了机器学习模型在学生宿舍能源预测中的性能，重点评估季节变化（如季节模式、假期和气象影响）带来的挑战。研究比较了基线模型如 LSTM 和 GRU，以及先进方法包括 Autoregressive Feedforward Neural Networks、Transformers 和混合方法。结果显示，没有单一模型在所有季节均表现最佳，但提出的 Hyper Network based LSTM 和 MiniAutoEncXGBoost 模型展现出较强适应性，能有效捕捉夏季等时期的突发能源波动。该研究突出了季节动态和模型特定行为在提升预测准确性方面的关键作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07423v1",
      "published_date": "2025-01-13 15:43:22 UTC",
      "updated_date": "2025-01-13 15:43:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:03:20.147828"
    },
    {
      "arxiv_id": "2501.07408v1",
      "title": "Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion",
      "title_zh": "基于传感器的开放词汇活动识别通过文本嵌入反演的初步发现",
      "authors": [
        "Lala Shakti Swarup Ray",
        "Bo Zhou",
        "Sungho Suh",
        "Paul Lukowicz"
      ],
      "abstract": "Conventional human activity recognition (HAR) relies on classifiers trained\nto predict discrete activity classes, inherently limiting recognition to\nactivities explicitly present in the training set. Such classifiers would\ninvariably fail, putting zero likelihood, when encountering unseen activities.\nWe propose Open Vocabulary HAR (OV-HAR), a framework that overcomes this\nlimitation by first converting each activity into natural language and breaking\nit into a sequence of elementary motions. This descriptive text is then encoded\ninto a fixed-size embedding. The model is trained to regress this embedding,\nwhich is subsequently decoded back into natural language using a pre-trained\nembedding inversion model. Unlike other works that rely on auto-regressive\nlarge language models (LLMs) at their core, OV-HAR achieves open vocabulary\nrecognition without the computational overhead of such models. The generated\ntext can be transformed into a single activity class using LLM prompt\nengineering. We have evaluated our approach on different modalities, including\nvision (pose), IMU, and pressure sensors, demonstrating robust generalization\nacross unseen activities and modalities, offering a fundamentally different\nparadigm from contemporary classifiers.",
      "tldr_zh": "本论文探讨了基于传感器的开放词汇活动识别（OV-HAR），旨在解决传统人类活动识别（HAR）系统仅限于训练集活动的局限性。OV-HAR 通过将活动转换为自然语言描述并分解为基本动作序列，然后编码成固定大小的嵌入，并使用预训练的嵌入反演模型解码回文本，从而实现对未见活动的识别。该方法避免了依赖大型语言模型（LLMs）的计算开销，并在视觉（姿势）、IMU 和压力传感器等模态上进行评估，展示了在未见活动和模态上的鲁棒泛化，提供了一种全新的 HAR 范式。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07408v1",
      "published_date": "2025-01-13 15:24:10 UTC",
      "updated_date": "2025-01-13 15:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:01:32.385340"
    },
    {
      "arxiv_id": "2501.07405v1",
      "title": "PROTECT: Protein circadian time prediction using unsupervised learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aram Ansary Ogholbake",
        "Qiang Cheng"
      ],
      "abstract": "Circadian rhythms regulate the physiology and behavior of humans and animals.\nDespite advancements in understanding these rhythms and predicting circadian\nphases at the transcriptional level, predicting circadian phases from proteomic\ndata remains elusive. This challenge is largely due to the scarcity of time\nlabels in proteomic datasets, which are often characterized by small sample\nsizes, high dimensionality, and significant noise. Furthermore, existing\nmethods for predicting circadian phases from transcriptomic data typically rely\non prior knowledge of known rhythmic genes, making them unsuitable for\nproteomic datasets. To address this gap, we developed a novel computational\nmethod using unsupervised deep learning techniques to predict circadian sample\nphases from proteomic data without requiring time labels or prior knowledge of\nproteins or genes. Our model involves a two-stage training process optimized\nfor robust circadian phase prediction: an initial greedy one-layer-at-a-time\npre-training which generates informative initial parameters followed by\nfine-tuning. During fine-tuning, a specialized loss function guides the model\nto align protein expression levels with circadian patterns, enabling it to\naccurately capture the underlying rhythmic structure within the data. We tested\nour method on both time-labeled and unlabeled proteomic data. For labeled data,\nwe compared our predictions to the known time labels, achieving high accuracy,\nwhile for unlabeled human datasets, including postmortem brain regions and\nurine samples, we explored circadian disruptions. Notably, our analysis\nidentified disruptions in rhythmic proteins between Alzheimer's disease and\ncontrol subjects across these samples.",
      "tldr_zh": "这篇论文提出了PROTECT，一种基于无监督深度学习的方法，用于从蛋白质数据(proteomic data)中预测昼夜节律相位(circadian phases)，无需时间标签或先验知识来解决现有方法的局限性。该方法采用两阶段训练过程：先进行贪婪的一层一层预训练(greedy one-layer-at-a-time pre-training)生成初始参数，然后通过微调和专用损失函数来对齐蛋白质表达水平与昼夜节律模式。在实验中，PROTECT在有标签数据上实现了高准确性，并在无标签人类数据集（如 postmortem 脑区和尿样）中识别了阿尔茨海默病患者与对照组在节律蛋白上的差异，为探索昼夜节律干扰提供了新工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07405v1",
      "published_date": "2025-01-13 15:21:20 UTC",
      "updated_date": "2025-01-13 15:21:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:01:45.064353"
    },
    {
      "arxiv_id": "2501.07400v1",
      "title": "Derivation of effective gradient flow equations and dynamical truncation of training data in Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Chen"
      ],
      "abstract": "We derive explicit equations governing the cumulative biases and weights in\nDeep Learning with ReLU activation function, based on gradient descent for the\nEuclidean cost in the input layer, and under the assumption that the weights\nare, in a precise sense, adapted to the coordinate system distinguished by the\nactivations. We show that gradient descent corresponds to a dynamical process\nin the input layer, whereby clusters of data are progressively reduced in\ncomplexity (\"truncated\") at an exponential rate that increases with the number\nof data points that have already been truncated. We provide a detailed\ndiscussion of several types of solutions to the gradient flow equations. A main\nmotivation for this work is to shed light on the interpretability question in\nsupervised learning.",
      "tldr_zh": "本文推导了在深度学习中使用 ReLU 激活函数和梯度下降的欧氏距离成本函数时，控制累积偏差和权重的显式方程，假设权重适应于激活函数区分的坐标系统。研究显示，gradient descent 对应于输入层中的动态过程，导致训练数据簇逐步以指数率减少复杂度（dynamical truncation），且截断速率随已截断数据点数量增加而加快。论文讨论了多种方程解决方案类型，并旨在提升监督学习中的可解释性问题。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.AP",
        "math.OC",
        "stat.ML",
        "57R70, 62M45"
      ],
      "primary_category": "cs.LG",
      "comment": "AMS Latex, 35 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07400v1",
      "published_date": "2025-01-13 15:17:28 UTC",
      "updated_date": "2025-01-13 15:17:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:01:56.441081"
    },
    {
      "arxiv_id": "2501.07392v1",
      "title": "The Essentials of AI for Life and Society: An AI Literacy Course for the University Community",
      "title_zh": "翻译失败",
      "authors": [
        "Joydeep Biswas",
        "Don Fussell",
        "Peter Stone",
        "Kristin Patterson",
        "Kristen Procko",
        "Lea Sabatini",
        "Zifan Xu"
      ],
      "abstract": "We describe the development of a one-credit course to promote AI literacy at\nThe University of Texas at Austin. In response to a call for the rapid\ndeployment of class to serve a broad audience in Fall of 2023, we designed a\n14-week seminar-style course that incorporated an interdisciplinary group of\nspeakers who lectured on topics ranging from the fundamentals of AI to societal\nconcerns including disinformation and employment. University students, faculty,\nand staff, and even community members outside of the University, were invited\nto enroll in this online offering: The Essentials of AI for Life and Society.\nWe collected feedback from course participants through weekly reflections and a\nfinal survey. Satisfyingly, we found that attendees reported gains in their AI\nliteracy. We sought critical feedback through quantitative and qualitative\nanalysis, which uncovered challenges in designing a course for this general\naudience. We utilized the course feedback to design a three-credit version of\nthe course that is being offered in Fall of 2024. The lessons we learned and\nour plans for this new iteration may serve as a guide to instructors designing\nAI courses for a broad audience.",
      "tldr_zh": "该研究描述了在德克萨斯大学奥斯汀分校开发的一个一学分课程“The Essentials of AI for Life and Society”，旨在提升 AI literacy（AI 识读能力），针对学生、教职员工和社区成员等广泛受众。课程采用 14 周的在线研讨会形式，邀请跨学科演讲者讨论 AI 基础知识和社会问题，如虚假信息和就业影响，并通过每周反思和最终调查收集反馈。结果显示，参与者报告了 AI 识读能力的显著提升，但也揭示了为一般受众设计课程的挑战；基于此，研究团队迭代设计了 2024 年秋季的三学分版本，并分享经验教训以指导类似课程的开发。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to EAAI-25: The 15th Symposium on Educational Advances in\n  Artificial Intelligence, collocated with AAAI-25",
      "pdf_url": "http://arxiv.org/pdf/2501.07392v1",
      "published_date": "2025-01-13 15:08:32 UTC",
      "updated_date": "2025-01-13 15:08:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:03:32.590800"
    },
    {
      "arxiv_id": "2501.07391v1",
      "title": "Enhancing Retrieval-Augmented Generation: A Study of Best Practices",
      "title_zh": "翻译失败",
      "authors": [
        "Siran Li",
        "Linus Stenzel",
        "Carsten Eickhoff",
        "Seyed Ali Bahrainian"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) systems have recently shown remarkable\nadvancements by integrating retrieval mechanisms into language models,\nenhancing their ability to produce more accurate and contextually relevant\nresponses. However, the influence of various components and configurations\nwithin RAG systems remains underexplored. A comprehensive understanding of\nthese elements is essential for tailoring RAG systems to complex retrieval\ntasks and ensuring optimal performance across diverse applications. In this\npaper, we develop several advanced RAG system designs that incorporate query\nexpansion, various novel retrieval strategies, and a novel Contrastive\nIn-Context Learning RAG. Our study systematically investigates key factors,\nincluding language model size, prompt design, document chunk size, knowledge\nbase size, retrieval stride, query expansion techniques, Contrastive In-Context\nLearning knowledge bases, multilingual knowledge bases, and Focus Mode\nretrieving relevant context at sentence-level. Through extensive\nexperimentation, we provide a detailed analysis of how these factors influence\nresponse quality. Our findings offer actionable insights for developing RAG\nsystems, striking a balance between contextual richness and\nretrieval-generation efficiency, thereby paving the way for more adaptable and\nhigh-performing RAG frameworks in diverse real-world scenarios. Our code and\nimplementation details are publicly available.",
      "tldr_zh": "这篇论文研究了 Retrieval-Augmented Generation (RAG) 系统的优化最佳实践，探讨了其组件和配置如何影响性能。作者开发了先进的设计，包括查询扩展、新颖检索策略和 Contrastive In-Context Learning RAG，并系统调查了语言模型大小、提示设计、文档块大小等关键因素。实验结果显示，这些因素显著影响响应质量，并提供了平衡上下文丰富性和检索生成效率的行动性见解，为适应多样化真实场景的 RAG 框架提供了指导。代码和实现细节已公开可用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07391v1",
      "published_date": "2025-01-13 15:07:55 UTC",
      "updated_date": "2025-01-13 15:07:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:03:43.746759"
    },
    {
      "arxiv_id": "2501.07382v1",
      "title": "Information-Theoretic Dual Memory System for Continual Learning",
      "title_zh": "基于信息理论的双重记忆系统用于持续学习",
      "authors": [
        "RunQing Wu",
        "KaiHui Huang",
        "HanYi Zhang",
        "QiHe Liu",
        "GuoJin Yu",
        "JingSong Deng",
        "Fei Ye"
      ],
      "abstract": "Continuously acquiring new knowledge from a dynamic environment is a\nfundamental capability for animals, facilitating their survival and ability to\naddress various challenges. This capability is referred to as continual\nlearning, which focuses on the ability to learn a sequence of tasks without the\ndetriment of previous knowledge. A prevalent strategy to tackle continual\nlearning involves selecting and storing numerous essential data samples from\nprior tasks within a fixed-size memory buffer. However, the majority of current\nmemory-based techniques typically utilize a single memory buffer, which poses\nchallenges in concurrently managing newly acquired and previously learned\nsamples. Drawing inspiration from the Complementary Learning Systems (CLS)\ntheory, which defines rapid and gradual learning mechanisms for processing\ninformation, we propose an innovative dual memory system called the\nInformation-Theoretic Dual Memory System (ITDMS). This system comprises a fast\nmemory buffer designed to retain temporary and novel samples, alongside a slow\nmemory buffer dedicated to preserving critical and informative samples. The\nfast memory buffer is optimized employing an efficient reservoir sampling\nprocess. Furthermore, we introduce a novel information-theoretic memory\noptimization strategy that selectively identifies and retains diverse and\ninformative data samples for the slow memory buffer. Additionally, we propose a\nnovel balanced sample selection procedure that automatically identifies and\neliminates redundant memorized samples, thus freeing up memory capacity for new\ndata acquisitions, which can deal with a growing array of tasks. Our\nmethodology is rigorously assessed through a series of continual learning\nexperiments, with empirical results underscoring the effectiveness of the\nproposed system.",
      "tldr_zh": "本论文针对持续学习（Continual Learning）问题，提出了一种受 Complementary Learning Systems (CLS) 理论启发的创新框架，即 Information-Theoretic Dual Memory System (ITDMS)，旨在同时管理新旧知识而避免遗忘。ITDMS 包括一个快速内存缓冲区（使用 reservoir sampling 处理临时和新型样本）和一个缓慢内存缓冲区（通过 information-theoretic memory optimization 策略选择多样且信息丰富的样本），并引入 balanced sample selection procedure 来自动识别并删除冗余样本，从而释放空间适应更多任务。实验结果显示，该系统在各种持续学习任务上表现出色，证明了其在提升模型性能和效率方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 9 figures, submitted to Knowledge-Based Systems",
      "pdf_url": "http://arxiv.org/pdf/2501.07382v1",
      "published_date": "2025-01-13 15:01:12 UTC",
      "updated_date": "2025-01-13 15:01:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:03:55.191935"
    },
    {
      "arxiv_id": "2501.07359v1",
      "title": "Emergent effects of scaling on the functional hierarchies within large language models",
      "title_zh": "规模扩展对大型语言模型内部功能层次结构的涌现效应",
      "authors": [
        "Paul C. Bogdan"
      ],
      "abstract": "Large language model (LLM) architectures are often described as functionally\nhierarchical: Early layers process syntax, middle layers begin to parse\nsemantics, and late layers integrate information. The present work revisits\nthese ideas. This research submits simple texts to an LLM (e.g., \"A church and\norgan\") and extracts the resulting activations. Then, for each layer, support\nvector machines and ridge regressions are fit to predict a text's label and\nthus examine whether a given layer encodes some information. Analyses using a\nsmall model (Llama-3.2-3b; 28 layers) partly bolster the common hierarchical\nperspective: Item-level semantics are most strongly represented early (layers\n2-7), then two-item relations (layers 8-12), and then four-item analogies\n(layers 10-15). Afterward, the representation of items and simple relations\ngradually decreases in deeper layers that focus on more global information.\nHowever, several findings run counter to a steady hierarchy view: First,\nalthough deep layers can represent document-wide abstractions, deep layers also\ncompress information from early portions of the context window without\nmeaningful abstraction. Second, when examining a larger model\n(Llama-3.3-70b-Instruct), stark fluctuations in abstraction level appear: As\ndepth increases, two-item relations and four-item analogies initially increase\nin their representation, then markedly decrease, and afterward increase again\nmomentarily. This peculiar pattern consistently emerges across several\nexperiments. Third, another emergent effect of scaling is coordination between\nthe attention mechanisms of adjacent layers. Across multiple experiments using\nthe larger model, adjacent layers fluctuate between what information they each\nspecialize in representing. In sum, an abstraction hierarchy often manifests\nacross layers, but large models also deviate from this structure in curious\nways.",
      "tldr_zh": "本文研究了大型语言模型(LLM)内部功能层级的涌现效应，通过向模型输入简单文本并分析激活层，使用支持向量机和岭回归预测文本标签。实验显示，在Llama-3.2-3b模型中，早期层(2-7)主要表示项目级语义，中层(8-15)处理关系和类比，深层则聚焦全局信息，但也存在信息压缩现象。在更大模型Llama-3.3-70b-Instruct中，抽象水平出现显著波动，如关系和类比表示先增后减再增，以及相邻层注意力机制的协调，这些发现揭示了模型规模化对功能层级的复杂影响。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07359v1",
      "published_date": "2025-01-13 14:27:39 UTC",
      "updated_date": "2025-01-13 14:27:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:04:08.356567"
    },
    {
      "arxiv_id": "2501.07335v2",
      "title": "TempoGPT: Enhancing Time Series Reasoning via Quantizing Embedding",
      "title_zh": "TempoGPT: 通过量化嵌入增强时间序列推理",
      "authors": [
        "Haochuan Zhang",
        "Chunhua Yang",
        "Jie Han",
        "Liyang Qin",
        "Xiaoli Wang"
      ],
      "abstract": "Multi-modal language model has made advanced progress in vision and audio,\nbut still faces significant challenges in dealing with complex reasoning tasks\nin the time series domain. The reasons are twofold. First, labels for\nmulti-modal time series data are coarse and devoid of analysis or reasoning\nprocesses. Training with these data cannot improve the model's reasoning\ncapabilities. Second, due to the lack of precise tokenization in processing\ntime series, the representation patterns for temporal and textual information\nare inconsistent, which hampers the effectiveness of multi-modal alignment. To\naddress these challenges, we propose a multi-modal time series data\nconstruction approach and a multi-modal time series language model (TLM),\nTempoGPT. Specially, we construct multi-modal data for complex reasoning tasks\nby analyzing the variable-system relationships within a white-box system.\nAdditionally, proposed TempoGPT achieves consistent representation between\ntemporal and textual information by quantizing temporal embeddings, where\ntemporal embeddings are quantized into a series of discrete tokens using a\npredefined codebook; subsequently, a shared embedding layer processes both\ntemporal and textual tokens. Extensive experiments demonstrate that TempoGPT\naccurately perceives temporal information, logically infers conclusions, and\nachieves state-of-the-art in the constructed complex time series reasoning\ntasks. Moreover, we quantitatively demonstrate the effectiveness of quantizing\ntemporal embeddings in enhancing multi-modal alignment and the reasoning\ncapabilities of TLMs. Code and data are available at\nhttps://github.com/zhanghaochuan20/TempoGPT.",
      "tldr_zh": "本文研究发现，多模态语言模型在时间序列领域处理复杂推理任务时面临挑战，主要由于数据标签粗糙缺乏推理过程以及时间和文本信息表示不一致的问题。为解决这些问题，作者提出TempoGPT，一种多模态时间序列语言模型，通过量化时间嵌入（Quantizing Embedding）将时间嵌入转化为离散标记，并使用共享嵌入层实现多模态对齐，同时构建基于白盒系统的多模态数据。实验结果表明，TempoGPT在复杂时间序列推理任务中达到最先进水平，显著提升了模型的推理能力和多模态对齐效果。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07335v2",
      "published_date": "2025-01-13 13:47:05 UTC",
      "updated_date": "2025-03-07 01:43:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:04:21.776072"
    },
    {
      "arxiv_id": "2501.07334v1",
      "title": "Anonymization of Documents for Law Enforcement with Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Eberhardinger",
        "Patrick Takenaka",
        "Daniel Grießhaber",
        "Johannes Maucher"
      ],
      "abstract": "The steadily increasing utilization of data-driven methods and approaches in\nareas that handle sensitive personal information such as in law enforcement\nmandates an ever increasing effort in these institutions to comply with data\nprotection guidelines. In this work, we present a system for automatically\nanonymizing images of scanned documents, reducing manual effort while ensuring\ndata protection compliance. Our method considers the viability of further\nforensic processing after anonymization by minimizing automatically redacted\nareas by combining automatic detection of sensitive regions with knowledge from\na manually anonymized reference document. Using a self-supervised image model\nfor instance retrieval of the reference document, our approach requires only\none anonymized example to efficiently redact all documents of the same type,\nsignificantly reducing processing time. We show that our approach outperforms\nboth a purely automatic redaction system and also a naive copy-paste scheme of\nthe reference anonymization to other documents on a hand-crafted dataset of\nground truth redactions.",
      "tldr_zh": "这篇论文提出了一种使用机器学习自动匿名化执法部门扫描文档图像的系统，旨在减少手动工作量并确保数据保护合规，同时维持后续取证处理的可用性。方法结合自动检测敏感区域与手动匿名化参考文档的知识，通过自监督图像模型进行实例检索，仅需一个匿名化示例即可高效处理所有同类型文档。实验结果表明，该系统在手工制作的真实红acted数据集上，优于纯自动redaction系统和naive copy-paste方案。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at IEEE Symposium on CI in Security, Defence and Biometrics\n  2025 (IEEE CISDB)",
      "pdf_url": "http://arxiv.org/pdf/2501.07334v1",
      "published_date": "2025-01-13 13:47:00 UTC",
      "updated_date": "2025-01-13 13:47:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:04:32.217380"
    },
    {
      "arxiv_id": "2501.07317v3",
      "title": "Evaluation of Artificial Intelligence Methods for Lead Time Prediction in Non-Cycled Areas of Automotive Production",
      "title_zh": "翻译失败",
      "authors": [
        "Cornelius Hake",
        "Jonas Weigele",
        "Frederik Reichert",
        "Christian Friedrich"
      ],
      "abstract": "The present study examines the effectiveness of applying Artificial\nIntelligence methods in an automotive production environment to predict unknown\nlead times in a non-cycle-controlled production area. Data structures are\nanalyzed to identify contextual features and then preprocessed using one-hot\nencoding. Methods selection focuses on supervised machine learning techniques.\nIn supervised learning methods, regression and classification methods are\nevaluated. Continuous regression based on target size distribution is not\nfeasible. Classification methods analysis shows that Ensemble Learning and\nSupport Vector Machines are the most suitable. Preliminary study results\nindicate that gradient boosting algorithms LightGBM, XGBoost, and CatBoost\nyield the best results. After further testing and extensive hyperparameter\noptimization, the final method choice is the LightGBM algorithm. Depending on\nfeature availability and prediction interval granularity, relative prediction\naccuracies of up to 90% can be achieved. Further tests highlight the importance\nof periodic retraining of AI models to accurately represent complex production\nprocesses using the database. The research demonstrates that AI methods can be\neffectively applied to highly variable production data, adding business value\nby providing an additional metric for various control tasks while outperforming\ncurrent non AI-based systems.",
      "tldr_zh": "本研究评估了在汽车生产非循环控制区域中使用 Artificial Intelligence 方法预测未知提前时间（Lead Time）的有效性，通过分析数据结构并采用 one-hot encoding 预处理，焦点放在监督机器学习技术上。研究发现，回归方法不可行，而分类方法中 Ensemble Learning 和 Support Vector Machines 最适合，最终选择了 LightGBM 算法，经过超参数优化后，实现最高90%的相对预测准确率。结果强调定期重新训练 AI 模型的重要性，并证明这些方法能有效处理高度可变的生產数据，提供比非 AI 系统更强的业务价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07317v3",
      "published_date": "2025-01-13 13:28:03 UTC",
      "updated_date": "2025-01-15 14:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:04:43.098786"
    },
    {
      "arxiv_id": "2501.07301v1",
      "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning",
      "title_zh": "在数学推理中开发",
      "authors": [
        "Zhenru Zhang",
        "Chujie Zheng",
        "Yangzhen Wu",
        "Beichen Zhang",
        "Runji Lin",
        "Bowen Yu",
        "Dayiheng Liu",
        "Jingren Zhou",
        "Junyang Lin"
      ],
      "abstract": "Process Reward Models (PRMs) emerge as a promising approach for process\nsupervision in mathematical reasoning of Large Language Models (LLMs), which\naim to identify and mitigate intermediate errors in the reasoning processes.\nHowever, the development of effective PRMs faces significant challenges,\nparticularly in data annotation and evaluation methodologies. In this paper,\nthrough extensive experiments, we demonstrate that commonly used Monte Carlo\n(MC) estimation-based data synthesis for PRMs typically yields inferior\nperformance and generalization compared to LLM-as-a-judge and human annotation\nmethods. MC estimation relies on completion models to evaluate current-step\ncorrectness, leading to inaccurate step verification. Furthermore, we identify\npotential biases in conventional Best-of-N (BoN) evaluation strategies for\nPRMs: (1) The unreliable policy models generate responses with correct answers\nbut flawed processes, leading to a misalignment between the evaluation criteria\nof BoN and the PRM objectives of process verification. (2) The tolerance of\nPRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a\nsignificant proportion of minimum scores concentrated on the final answer\nsteps, revealing the shift from process to outcome-based assessment in BoN\nOptimized PRMs. To address these challenges, we develop a consensus filtering\nmechanism that effectively integrates MC estimation with LLM-as-a-judge and\nadvocates a more comprehensive evaluation framework that combines\nresponse-level and step-level metrics. Based on the mechanisms, we\nsignificantly improve both model performance and data efficiency in the BoN\nevaluation and the step-wise error identification task. Finally, we release a\nnew state-of-the-art PRM that outperforms existing open-source alternatives and\nprovides practical guidelines for future research in building process\nsupervision models.",
      "tldr_zh": "本文研究了在数学推理中开发 Process Reward Models (PRMs) 的关键教训，旨在通过过程监督识别和缓解 Large Language Models (LLMs) 的中间错误。实验发现，常用的 Monte Carlo (MC) estimation-based 数据合成方法在性能和泛化性上逊色于 LLM-as-a-judge 和人类标注，因为它依赖完成模型导致步骤验证不准确，且 Best-of-N (BoN) 评估存在偏见，如对有正确答案但过程缺陷响应的容忍。作者提出共识过滤机制，将 MC estimation 与 LLM-as-a-judge 整合，并引入结合响应级和步骤级指标的全面评估框架，从而显著提升了模型性能、数据效率和步骤错误识别能力。最终，该研究发布了新的 state-of-the-art PRM，超越现有开源模型，并为未来过程监督模型的构建提供了实用指南。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07301v1",
      "published_date": "2025-01-13 13:10:16 UTC",
      "updated_date": "2025-01-13 13:10:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:04:57.856077"
    },
    {
      "arxiv_id": "2501.07290v1",
      "title": "Principles for Responsible AI Consciousness Research",
      "title_zh": "负责任 AI 意识研究原则",
      "authors": [
        "Patrick Butlin",
        "Theodoros Lappas"
      ],
      "abstract": "Recent research suggests that it may be possible to build conscious AI\nsystems now or in the near future. Conscious AI systems would arguably deserve\nmoral consideration, and it may be the case that large numbers of conscious\nsystems could be created and caused to suffer. Furthermore, AI systems or\nAI-generated characters may increasingly give the impression of being\nconscious, leading to debate about their moral status. Organisations involved\nin AI research must establish principles and policies to guide research and\ndeployment choices and public communication concerning consciousness. Even if\nan organisation chooses not to study AI consciousness as such, it will still\nneed policies in place, as those developing advanced AI systems risk\ninadvertently creating conscious entities. Responsible research and deployment\npractices are essential to address this possibility. We propose five principles\nfor responsible research and argue that research organisations should make\nvoluntary, public commitments to principles on these lines. Our principles\nconcern research objectives and procedures, knowledge sharing and public\ncommunications.",
      "tldr_zh": "该论文讨论了随着AI技术发展，可能构建出有意识AI系统带来的道德挑战，这些系统可能值得道德考虑，并可能导致大量系统遭受痛苦或引发公众辩论。作者提出五条原则，指导AI consciousness研究，包括研究目标、程序、知识共享和公共沟通，以确保负责任的研发实践。即使组织不直接研究AI意识，也应制定政策避免意外创建有意识实体。最终，论文呼吁研究机构公开承诺这些原则，促进可信赖的AI部署。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07290v1",
      "published_date": "2025-01-13 12:59:53 UTC",
      "updated_date": "2025-01-13 12:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:05:06.717845"
    },
    {
      "arxiv_id": "2501.07288v2",
      "title": "LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zan-Kai Chong",
        "Hiroyuki Ohsaki",
        "Bryan Ng"
      ],
      "abstract": "The centralization of Large Language Models (LLMs) development has created\nsignificant barriers to AI advancement, limiting the democratization of these\npowerful technologies. This centralization, coupled with the scarcity of\nhigh-quality training data and mounting complexity of maintaining comprehensive\nexpertise across rapidly expanding knowledge domains, poses critical challenges\nto the continued growth of LLMs. While solutions like Retrieval-Augmented\nGeneration (RAG) offer potential remedies, maintaining up-to-date expert\nknowledge across diverse domains remains a significant challenge, particularly\ngiven the exponential growth of specialized information. This paper introduces\nLLMs Networks (LLM-Net), a blockchain-based framework that democratizes\nLLMs-as-a-Service through a decentralized network of specialized LLM providers.\nBy leveraging collective computational resources and distributed domain\nexpertise, LLM-Net incorporates fine-tuned expert models for various specific\ndomains, ensuring sustained knowledge growth while maintaining service quality\nthrough collaborative prompting mechanisms. The framework's robust design\nincludes blockchain technology for transparent transaction and performance\nvalidation, establishing an immutable record of service delivery. Our\nsimulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet,\nLlama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the\nreputation-based mechanism in maintaining service quality by selecting\nhigh-performing respondents (LLM providers). Thereby it demonstrates the\npotential of LLM-Net to sustain AI advancement through the integration of\ndecentralized expertise and blockchain-based accountability.",
      "tldr_zh": "该论文指出了大型语言模型(LLMs)开发的集中化问题，导致AI进步受限，包括高质量训练数据稀缺和跨领域知识维护的挑战。作者提出LLM-Net框架，这是一个基于区块链的去中心化网络，将LLMs-as-a-Service民主化，通过整合专业领域的微调专家模型和协作提示机制，实现集体计算资源共享和知识持续增长。实验模拟基于Claude 3.5 Sonnet、Llama 3.1、Grok-2和GPT-4o等模型，验证了声誉机制的有效性，提高了服务质量选择，并展示了区块链透明性和问责制在维持AI进步中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07288v2",
      "published_date": "2025-01-13 12:56:05 UTC",
      "updated_date": "2025-02-02 00:43:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:05:19.564960"
    },
    {
      "arxiv_id": "2501.07278v1",
      "title": "Lifelong Learning of Large Language Model based Agents: A Roadmap",
      "title_zh": "翻译失败",
      "authors": [
        "Junhao Zheng",
        "Chengming Shi",
        "Xidi Cai",
        "Qiuke Li",
        "Duzhen Zhang",
        "Chenxing Li",
        "Dong Yu",
        "Qianli Ma"
      ],
      "abstract": "Lifelong learning, also known as continual or incremental learning, is a\ncrucial component for advancing Artificial General Intelligence (AGI) by\nenabling systems to continuously adapt in dynamic environments. While large\nlanguage models (LLMs) have demonstrated impressive capabilities in natural\nlanguage processing, existing LLM agents are typically designed for static\nsystems and lack the ability to adapt over time in response to new challenges.\nThis survey is the first to systematically summarize the potential techniques\nfor incorporating lifelong learning into LLM-based agents. We categorize the\ncore components of these agents into three modules: the perception module for\nmultimodal input integration, the memory module for storing and retrieving\nevolving knowledge, and the action module for grounded interactions with the\ndynamic environment. We highlight how these pillars collectively enable\ncontinuous adaptation, mitigate catastrophic forgetting, and improve long-term\nperformance. This survey provides a roadmap for researchers and practitioners\nworking to develop lifelong learning capabilities in LLM agents, offering\ninsights into emerging trends, evaluation metrics, and application scenarios.\nRelevant literature and resources are available at \\href{this\nurl}{https://github.com/qianlima-lab/awesome-lifelong-llm-agent}.",
      "tldr_zh": "这篇调查论文探讨了终身学习(Lifelong Learning)如何融入基于大型语言模型(LLMs)的代理，以推动人工智能通用智能(AGI)在动态环境中的持续适应。论文将LLM代理的核心组件分为三个模块：感知模块(Perception Module)用于整合多模态输入、记忆模块(Memory Module)用于存储和检索演化知识，以及行动模块(Action Module)用于与环境互动，从而缓解灾难性遗忘(Catastrophic Forgetting)和提升长期性能。作为第一篇系统总结，该研究提供路线图，包括新兴趋势、评估指标和应用场景，并附带相关资源链接。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "46 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07278v1",
      "published_date": "2025-01-13 12:42:04 UTC",
      "updated_date": "2025-01-13 12:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:05:32.582896"
    },
    {
      "arxiv_id": "2501.07276v2",
      "title": "Bridging Smart Meter Gaps: A Benchmark of Statistical, Machine Learning and Time Series Foundation Models for Data Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Amir Sartipi",
        "Joaquín Delgado Fernández",
        "Sergio Potenciano Menci",
        "Alessio Magitteri"
      ],
      "abstract": "The integrity of time series data in smart grids is often compromised by\nmissing values due to sensor failures, transmission errors, or disruptions.\nGaps in smart meter data can bias consumption analyses and hinder reliable\npredictions, causing technical and economic inefficiencies. As smart meter data\ngrows in volume and complexity, conventional techniques struggle with its\nnonlinear and nonstationary patterns. In this context, Generative Artificial\nIntelligence offers promising solutions that may outperform traditional\nstatistical methods. In this paper, we evaluate two general-purpose Large\nLanguage Models and five Time Series Foundation Models for smart meter data\nimputation, comparing them with conventional Machine Learning and statistical\nmodels. We introduce artificial gaps (30 minutes to one day) into an anonymized\npublic dataset to test inference capabilities. Results show that Time Series\nFoundation Models, with their contextual understanding and pattern recognition,\ncould significantly enhance imputation accuracy in certain cases. However, the\ntrade-off between computational cost and performance gains remains a critical\nconsideration.",
      "tldr_zh": "这篇论文针对智能电表数据中的缺失值问题（如传感器故障导致），提出一个基准测试，比较了Statistical、Machine Learning和Time Series Foundation Models的Data Imputation性能，同时评估两个Large Language Models。研究者使用匿名公共数据集，引入人工间隙（30分钟至一天）来测试模型的推断能力。结果表明，Time Series Foundation Models在某些场景下显著提升了插值准确性，但计算成本与性能收益的权衡仍是关键挑战。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07276v2",
      "published_date": "2025-01-13 12:41:27 UTC",
      "updated_date": "2025-02-20 09:02:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:05:44.729200"
    },
    {
      "arxiv_id": "2501.07260v1",
      "title": "Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion",
      "title_zh": "翻译失败",
      "authors": [
        "Li Liang",
        "Naveed Akhtar",
        "Jordan Vice",
        "Xiangrui Kong",
        "Ajmal Saeed Mian"
      ],
      "abstract": "3D semantic scene completion is critical for multiple downstream tasks in\nautonomous systems. It estimates missing geometric and semantic information in\nthe acquired scene data. Due to the challenging real-world conditions, this\ntask usually demands complex models that process multi-modal data to achieve\nacceptable performance. We propose a unique neural model, leveraging advances\nfrom the state space and diffusion generative modeling to achieve remarkable 3D\nsemantic scene completion performance with monocular image input. Our technique\nprocesses the data in the conditioned latent space of a variational autoencoder\nwhere diffusion modeling is carried out with an innovative state space\ntechnique. A key component of our neural network is the proposed Skimba (Skip\nMamba) denoiser, which is adept at efficiently processing long-sequence data.\nThe Skimba diffusion model is integral to our 3D scene completion network,\nincorporating a triple Mamba structure, dimensional decomposition residuals and\nvarying dilations along three directions. We also adopt a variant of this\nnetwork for the subsequent semantic segmentation stage of our method. Extensive\nevaluation on the standard SemanticKITTI and SSCBench-KITTI360 datasets show\nthat our approach not only outperforms other monocular techniques by a large\nmargin, it also achieves competitive performance against stereo methods. The\ncode is available at https://github.com/xrkong/skimba",
      "tldr_zh": "本研究提出了一种名为 Skip Mamba Diffusion 的神经模型，用于从单目图像实现 3D Semantic Scene Completion，帮助估计场景数据的缺失几何和语义信息。模型在变分自编码器（VAE）的条件潜在空间中进行扩散建模，引入创新的状态空间技术，并以 Skimba（Skip Mamba）去噪器为核心组件，该组件采用三重 Mamba 结构、维度分解残差和多方向扩张来高效处理长序列数据。实验在 SemanticKITTI 和 SSCBench-KITTI360 数据集上显示，该方法显著优于其他单目技术，并在性能上与立体方法不相上下。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07260v1",
      "published_date": "2025-01-13 12:18:58 UTC",
      "updated_date": "2025-01-13 12:18:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:05:56.313457"
    },
    {
      "arxiv_id": "2501.07251v2",
      "title": "MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework",
      "title_zh": "MOS-Attack：一个可扩展的多目标对抗攻击框架",
      "authors": [
        "Ping Guo",
        "Cheng Gong",
        "Xi Lin",
        "Fei Liu",
        "Zhichao Lu",
        "Qingfu Zhang",
        "Zhenkun Wang"
      ],
      "abstract": "Crafting adversarial examples is crucial for evaluating and enhancing the\nrobustness of Deep Neural Networks (DNNs), presenting a challenge equivalent to\nmaximizing a non-differentiable 0-1 loss function.\n  However, existing single objective methods, namely adversarial attacks focus\non a surrogate loss function, do not fully harness the benefits of engaging\nmultiple loss functions, as a result of insufficient understanding of their\nsynergistic and conflicting nature.\n  To overcome these limitations, we propose the Multi-Objective Set-based\nAttack (MOS Attack), a novel adversarial attack framework leveraging multiple\nloss functions and automatically uncovering their interrelations.\n  The MOS Attack adopts a set-based multi-objective optimization strategy,\nenabling the incorporation of numerous loss functions without additional\nparameters.\n  It also automatically mines synergistic patterns among various losses,\nfacilitating the generation of potent adversarial attacks with fewer\nobjectives.\n  Extensive experiments have shown that our MOS Attack outperforms\nsingle-objective attacks. Furthermore, by harnessing the identified synergistic\npatterns, MOS Attack continues to show superior results with a reduced number\nof loss functions.",
      "tldr_zh": "这篇论文提出了 MOS-Attack，一种可扩展的多目标对抗攻击框架，用于评估和提升 Deep Neural Networks (DNNs) 的鲁棒性，通过整合多个损失函数来解决现有单目标方法的局限性。框架采用基于集的 multi-objective optimization 策略，无需额外参数即可自动挖掘损失函数之间的协同和冲突关系，从而生成更有效的对抗样本。实验结果显示，MOS-Attack 优于单目标攻击，并在减少损失函数数量的情况下仍保持卓越性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Under Review of CVPR 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07251v2",
      "published_date": "2025-01-13 12:00:34 UTC",
      "updated_date": "2025-01-23 01:40:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:06:07.148547"
    },
    {
      "arxiv_id": "2501.07238v1",
      "title": "Lessons From Red Teaming 100 Generative AI Products",
      "title_zh": "从 Red Teaming 100 个生成式 AI 产品中学到的教训",
      "authors": [
        "Blake Bullwinkel",
        "Amanda Minnich",
        "Shiven Chawla",
        "Gary Lopez",
        "Martin Pouliot",
        "Whitney Maxwell",
        "Joris de Gruyter",
        "Katherine Pratt",
        "Saphir Qi",
        "Nina Chikanov",
        "Roman Lutz",
        "Raja Sekhar Rao Dheekonda",
        "Bolor-Erdene Jagdagdorj",
        "Eugenia Kim",
        "Justin Song",
        "Keegan Hines",
        "Daniel Jones",
        "Giorgio Severi",
        "Richard Lundeen",
        "Sam Vaughan",
        "Victoria Westerhoff",
        "Pete Bryan",
        "Ram Shankar Siva Kumar",
        "Yonatan Zunger",
        "Chang Kawaguchi",
        "Mark Russinovich"
      ],
      "abstract": "In recent years, AI red teaming has emerged as a practice for probing the\nsafety and security of generative AI systems. Due to the nascency of the field,\nthere are many open questions about how red teaming operations should be\nconducted. Based on our experience red teaming over 100 generative AI products\nat Microsoft, we present our internal threat model ontology and eight main\nlessons we have learned:\n  1. Understand what the system can do and where it is applied\n  2. You don't have to compute gradients to break an AI system\n  3. AI red teaming is not safety benchmarking\n  4. Automation can help cover more of the risk landscape\n  5. The human element of AI red teaming is crucial\n  6. Responsible AI harms are pervasive but difficult to measure\n  7. LLMs amplify existing security risks and introduce new ones\n  8. The work of securing AI systems will never be complete\n  By sharing these insights alongside case studies from our operations, we\noffer practical recommendations aimed at aligning red teaming efforts with real\nworld risks. We also highlight aspects of AI red teaming that we believe are\noften misunderstood and discuss open questions for the field to consider.",
      "tldr_zh": "这篇论文基于微软红队测试(red teaming)超过100个生成式AI产品的经验，介绍了内部威胁模型本体和八个关键教训，包括理解系统能力和应用范围、攻击AI系统不需计算梯度、AI红队测试并非安全基准测试，以及自动化和人类因素的重要性。研究发现，负责任AI harms普遍存在但难测量，大语言模型(LLMs)会放大现有安全风险并引入新风险，且确保AI系统安全的工作永无止境。通过案例研究，论文提供实用推荐，帮助优化红队测试实践，并讨论常见误解和领域开放问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07238v1",
      "published_date": "2025-01-13 11:36:33 UTC",
      "updated_date": "2025-01-13 11:36:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:06:20.191791"
    },
    {
      "arxiv_id": "2501.07237v1",
      "title": "Breaking Memory Limits: Gradient Wavelet Transform Enhances LLMs Training",
      "title_zh": "打破内存限制：梯度小波变换增强LLMs训练",
      "authors": [
        "Ziqing Wen",
        "Ping Luo",
        "Jiahuan Wang",
        "Xiaoge Deng",
        "Jinping Zou",
        "Kun Yuan",
        "Tao Sun",
        "Dongsheng Li"
      ],
      "abstract": "Large language models (LLMs) have shown impressive performance across a range\nof natural language processing tasks. However, their vast number of parameters\nintroduces significant memory challenges during training, particularly when\nusing memory-intensive optimizers like Adam. Existing memory-efficient\nalgorithms often rely on techniques such as singular value decomposition\nprojection or weight freezing. While these approaches help alleviate memory\nconstraints, they generally produce suboptimal results compared to full-rank\nupdates. In this paper, we investigate the memory-efficient method beyond\nlow-rank training, proposing a novel solution called Gradient Wavelet Transform\n(GWT), which applies wavelet transforms to gradients in order to significantly\nreduce the memory requirements for maintaining optimizer states. We demonstrate\nthat GWT can be seamlessly integrated with memory-intensive optimizers,\nenabling efficient training without sacrificing performance. Through extensive\nexperiments on both pre-training and fine-tuning tasks, we show that GWT\nachieves state-of-the-art performance compared with advanced memory-efficient\noptimizers and full-rank approaches in terms of both memory usage and training\nperformance.",
      "tldr_zh": "大语言模型(LLMs)训练面临内存限制问题，尤其是使用内存密集型优化器如Adam，导致性能受限。论文提出Gradient Wavelet Transform (GWT)，一种通过对梯度应用小波变换的方法，以显著减少优化器状态的内存需求，同时确保与现有优化器无缝整合。实验结果表明，GWT在预训练和微调任务上，内存使用和训练性能均优于先进内存高效优化器和全秩方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07237v1",
      "published_date": "2025-01-13 11:35:09 UTC",
      "updated_date": "2025-01-13 11:35:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:06:31.754263"
    },
    {
      "arxiv_id": "2501.07221v1",
      "title": "Exploring the Use of Contrastive Language-Image Pre-Training for Human Posture Classification: Insights from Yoga Pose Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Andrzej D. Dobrzycki",
        "Ana M. Bernardos",
        "Luca Bergesio",
        "Andrzej Pomirski",
        "Daniel Sáez-Trigueros"
      ],
      "abstract": "Accurate human posture classification in images and videos is crucial for\nautomated applications across various fields, including work safety, physical\nrehabilitation, sports training, or daily assisted living. Recently, multimodal\nlearning methods, such as Contrastive Language-Image Pretraining (CLIP), have\nadvanced significantly in jointly understanding images and text. This study\naims to assess the effectiveness of CLIP in classifying human postures,\nfocusing on its application in yoga. Despite the initial limitations of the\nzero-shot approach, applying transfer learning on 15,301 images (real and\nsynthetic) with 82 classes has shown promising results. The article describes\nthe full procedure for fine-tuning, including the choice for image description\nsyntax, models and hyperparameters adjustment. The fine-tuned CLIP model,\ntested on 3826 images, achieves an accuracy of over 85%, surpassing the current\nstate-of-the-art of previous works on the same dataset by approximately 6%, its\ntraining time being 3.5 times lower than what is needed to fine-tune a\nYOLOv8-based model. For more application-oriented scenarios, with smaller\ndatasets of six postures each, containing 1301 and 401 training images, the\nfine-tuned models attain an accuracy of 98.8% and 99.1%, respectively.\nFurthermore, our experiments indicate that training with as few as 20 images\nper pose can yield around 90% accuracy in a six-class dataset. This study\ndemonstrates that this multimodal technique can be effectively used for yoga\npose classification, and possibly for human posture classification, in general.\nAdditionally, CLIP inference time (around 7 ms) supports that the model can be\nintegrated into automated systems for posture evaluation, e.g., for developing\na real-time personal yoga assistant for performance assessment.",
      "tldr_zh": "这篇论文探讨了 Contrastive Language-Image Pretraining (CLIP) 在人类姿势分类中的应用潜力，特别是针对瑜伽姿势分析，通过转移学习（transfer learning）对 CLIP 模型进行微调。研究使用 15,301 张图像（包括真实和合成数据）的 dataset 训练模型，并在 3826 张测试图像上实现了超过 85% 的准确率，比现有基于 YOLOv8 的最先进模型高约 6%，且训练时间缩短 3.5 倍。在更小的六类姿势数据集上，模型准确率可达 98.8% 和 99.1%，甚至仅用每类 20 张图像即可达到约 90% 的准确率。该方法证明 CLIP 适用于高效的瑜伽姿势分类和一般人类姿势识别，并支持实时应用，如开发个人瑜伽辅助系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07221v1",
      "published_date": "2025-01-13 11:20:44 UTC",
      "updated_date": "2025-01-13 11:20:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:06:45.374059"
    },
    {
      "arxiv_id": "2501.07213v1",
      "title": "Multi-face emotion detection for effective Human-Robot Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed Ala Yahyaoui",
        "Mouaad Oujabour",
        "Leila Ben Letaifa",
        "Amine Bohi"
      ],
      "abstract": "The integration of dialogue interfaces in mobile devices has become\nubiquitous, providing a wide array of services. As technology progresses,\nhumanoid robots designed with human-like features to interact effectively with\npeople are gaining prominence, and the use of advanced human-robot dialogue\ninterfaces is continually expanding. In this context, emotion recognition plays\na crucial role in enhancing human-robot interaction by enabling robots to\nunderstand human intentions. This research proposes a facial emotion detection\ninterface integrated into a mobile humanoid robot, capable of displaying\nreal-time emotions from multiple individuals on a user interface. To this end,\nvarious deep neural network models for facial expression recognition were\ndeveloped and evaluated under consistent computer-based conditions, yielding\npromising results. Afterwards, a trade-off between accuracy and memory\nfootprint was carefully considered to effectively implement this application on\na mobile humanoid robot.",
      "tldr_zh": "该研究针对有效的人机互动(Human-Robot Interaction)，提出了一种多脸部情感检测接口，整合到移动人形机器人中，以实时识别并显示多个个体的面部情绪，从而帮助机器人理解人类意图。研究开发并评估了各种深度神经网络模型(deep neural network models)用于面部表情识别(facial expression recognition)，在计算机环境下取得了良好的性能。最终，通过权衡准确性和内存占用(memory footprint)，成功实现了该接口在移动人形机器人上的高效应用。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.HC",
      "comment": "9 pages, 8 figures and 1 table. Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025), Porto,\n  Portugal",
      "pdf_url": "http://arxiv.org/pdf/2501.07213v1",
      "published_date": "2025-01-13 11:12:47 UTC",
      "updated_date": "2025-01-13 11:12:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:06:54.874114"
    },
    {
      "arxiv_id": "2501.07196v1",
      "title": "Crowdsourced human-based computational approach for tagging peripheral blood smear sample images from Sickle Cell Disease patients using non-expert users",
      "title_zh": "翻译失败",
      "authors": [
        "José María Buades Rubio",
        "Gabriel Moyà-Alcover",
        "Antoni Jaume-i-Capó",
        "Nataša Petrović"
      ],
      "abstract": "In this paper, we present a human-based computation approach for the analysis\nof peripheral blood smear (PBS) images images in patients with Sickle Cell\nDisease (SCD). We used the Mechanical Turk microtask market to crowdsource the\nlabeling of PBS images. We then use the expert-tagged erythrocytesIDB dataset\nto assess the accuracy and reliability of our proposal. Our results showed that\nwhen a robust consensus is achieved among the Mechanical Turk workers,\nprobability of error is very low, based on comparison with expert analysis.\nThis suggests that our proposed approach can be used to annotate datasets of\nPBS images, which can then be used to train automated methods for the diagnosis\nof SCD. In future work, we plan to explore the potential integration of our\nfindings with outcomes obtained through automated methodologies. This could\nlead to the development of more accurate and reliable methods for the diagnosis\nof SCD",
      "tldr_zh": "本论文提出了一种基于Mechanical Turk的众包计算方法，使用非专家用户对Sickle Cell Disease (SCD)患者的peripheral blood smear (PBS)图像进行标记。研究利用erythrocytesIDB专家标记数据集评估该方法的准确性和可靠性，结果显示，当Mechanical Turk工人达成稳健共识时，与专家分析相比，错误概率非常低。该方法可用于创建大规模PBS图像数据集，以训练自动化SCD诊断模型，并计划未来与自动化技术整合以提升诊断的准确性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07196v1",
      "published_date": "2025-01-13 10:42:55 UTC",
      "updated_date": "2025-01-13 10:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:07:07.169224"
    },
    {
      "arxiv_id": "2501.07186v2",
      "title": "Generalizable Graph Neural Networks for Robust Power Grid Topology Control",
      "title_zh": "可泛化图神经网络用于鲁棒电力网格拓扑控制",
      "authors": [
        "Matthijs de Jong",
        "Jan Viebahn",
        "Yuliya Shapovalova"
      ],
      "abstract": "The energy transition necessitates new congestion management methods. One\nsuch method is controlling the grid topology with machine learning (ML). This\napproach has gained popularity following the Learning to Run a Power Network\n(L2RPN) competitions. Graph neural networks (GNNs) are a class of ML models\nthat reflect graph structure in their computation, which makes them suitable\nfor power grid modeling. Various GNN approaches for topology control have thus\nbeen proposed. We propose the first GNN model for grid topology control that\nuses only GNN layers. Additionally, we identify the busbar information\nasymmetry problem that the popular homogeneous graph representation suffers\nfrom, and propose a heterogeneous graph representation to resolve it. We train\nboth homogeneous and heterogeneous GNNs and fully connected neural networks\n(FCNN) baselines on an imitation learning task. We evaluate the models\naccording to their classification accuracy and grid operation ability. We find\nthat the heterogeneous GNNs perform best on in-distribution networks, followed\nby the FCNNs, and lastly, the homogeneous GNNs. We also find that both GNN\ntypes generalize better to out-of-distribution networks than FCNNs.",
      "tldr_zh": "本论文提出了一种通用的 Graph Neural Networks (GNNs) 模型，用于稳健的电力电网拓扑控制，以应对能源转型中的拥堵管理需求。创新点包括开发第一个仅使用 GNN 层的拓扑控制模型，并通过引入 heterogeneous graph 表示来解决同构图表示中的 busbar 信息不对称问题。实验结果显示，heterogeneous GNN 在分布内网络上性能最佳，优于全连接神经网络 (FCNN)，且 GNN 类型在分布外网络上表现出更好的泛化能力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07186v2",
      "published_date": "2025-01-13 10:31:36 UTC",
      "updated_date": "2025-02-18 18:20:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:07:20.157163"
    },
    {
      "arxiv_id": "2501.07183v1",
      "title": "Kriging and Gaussian Process Interpolation for Georeferenced Data Augmentation",
      "title_zh": "翻译失败",
      "authors": [
        "Frédérick Fabre Ferber",
        "Dominique Gay",
        "Jean-Christophe Soulié",
        "Jean Diatta",
        "Odalric-Ambrym Maillard"
      ],
      "abstract": "Data augmentation is a crucial step in the development of robust supervised\nlearning models, especially when dealing with limited datasets. This study\nexplores interpolation techniques for the augmentation of geo-referenced data,\nwith the aim of predicting the presence of Commelina benghalensis L. in\nsugarcane plots in La R{\\'e}union. Given the spatial nature of the data and the\nhigh cost of data collection, we evaluated two interpolation approaches:\nGaussian processes (GPs) with different kernels and kriging with various\nvariograms. The objectives of this work are threefold: (i) to identify which\ninterpolation methods offer the best predictive performance for various\nregression algorithms, (ii) to analyze the evolution of performance as a\nfunction of the number of observations added, and (iii) to assess the spatial\nconsistency of augmented datasets. The results show that GP-based methods, in\nparticular with combined kernels (GP-COMB), significantly improve the\nperformance of regression algorithms while requiring less additional data.\nAlthough kriging shows slightly lower performance, it is distinguished by a\nmore homogeneous spatial coverage, a potential advantage in certain contexts.",
      "tldr_zh": "本研究探讨了 Kriging 和 Gaussian Processes (GPs) 插值技术，用于地理参考数据的增强，以预测法属留尼汪岛甘蔗地块中 Commelina benghalensis L. 的存在，旨在提升监督学习模型的鲁棒性。研究评估了不同核的 GPs 和变差函数的 Kriging 方法，目标包括识别最佳插值方法、分析性能随添加观察数的变化，以及评估增强数据的空间一致性。结果显示，GPs 尤其是结合核的 GP-COMB 方法显著提高了回归算法的预测性能，同时需要较少额外数据；尽管 Kriging 的性能略低，但其在空间覆盖的均匀性上更具优势，为地理数据增强提供了实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07183v1",
      "published_date": "2025-01-13 10:29:09 UTC",
      "updated_date": "2025-01-13 10:29:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:07:31.648734"
    },
    {
      "arxiv_id": "2501.09031v1",
      "title": "Synthetic Data and Health Privacy",
      "title_zh": "合成数据与健康隐私",
      "authors": [
        "Gwénolé Abgrall",
        "Xavier Monnet",
        "Anmol Arora"
      ],
      "abstract": "This Viewpoint discusses generative artificial intelligence and safeguarding\nprivacy by using synthetic data as a substitute for private health data.",
      "tldr_zh": "这篇观点文章讨论了生成式人工智能（generative artificial intelligence）在保护健康隐私方面的作用，提出使用合成数据（synthetic data）作为私人健康数据的替代品。作者强调，通过这种方法，可以有效减少直接使用真实数据带来的隐私风险。总体而言，该观点为在医疗领域应用 AI 时平衡数据利用与隐私保护提供了实用建议。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "JAMA Cardiology, 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.09031v1",
      "published_date": "2025-01-13 10:23:14 UTC",
      "updated_date": "2025-01-13 10:23:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:07:42.362228"
    },
    {
      "arxiv_id": "2501.07178v1",
      "title": "The Spoils of Algorithmic Collusion: Profit Allocation Among Asymmetric Firms",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Martin",
        "Hans-Theo Normann",
        "Paul Püplichhuisen",
        "Tobias Werner"
      ],
      "abstract": "We study the propensity of independent algorithms to collude in repeated\nCournot duopoly games. Specifically, we investigate the predictive power of\ndifferent oligopoly and bargaining solutions regarding the effect of asymmetry\nbetween firms. We find that both consumers and firms can benefit from\nasymmetry. Algorithms produce more competitive outcomes when firms are\nsymmetric, but less when they are very asymmetric. Although the static Nash\nequilibrium underestimates the effect on total quantity and overestimates the\neffect on profits, it delivers surprisingly accurate predictions in terms of\ntotal welfare. The best description of our results is provided by the equal\nrelative gains solution. In particular, we find algorithms to agree on profits\nthat are on or close to the Pareto frontier for all degrees of asymmetry. Our\nresults suggest that the common belief that symmetric industries are more prone\nto collusion may no longer hold when algorithms increasingly drive managerial\ndecisions.",
      "tldr_zh": "本研究探讨了独立算法在重复Cournot双寡头游戏中的勾结倾向，特别关注企业不对称性对利润分配的影响。研究发现，企业不对称时，算法产生的竞争结果更少，而对称时则更具竞争性；尽管静态Nash equilibrium低估了总产量影响但在总福利预测上准确，equal relative gains solution最能解释结果。总体而言，算法在各种不对称程度下达成的利润位于或接近Pareto frontier，这表明传统观点——对称行业更易勾结——在算法主导决策的时代可能不再适用。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07178v1",
      "published_date": "2025-01-13 10:16:48 UTC",
      "updated_date": "2025-01-13 10:16:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:07:55.089033"
    },
    {
      "arxiv_id": "2501.07172v1",
      "title": "Anomalous Agreement: How to find the Ideal Number of Anomaly Classes in Correlated, Multivariate Time Series Data",
      "title_zh": "翻译失败",
      "authors": [
        "Ferdinand Rewicki",
        "Joachim Denzler",
        "Julia Niebling"
      ],
      "abstract": "Detecting and classifying abnormal system states is critical for condition\nmonitoring, but supervised methods often fall short due to the rarity of\nanomalies and the lack of labeled data. Therefore, clustering is often used to\ngroup similar abnormal behavior. However, evaluating cluster quality without\nground truth is challenging, as existing measures such as the Silhouette Score\n(SSC) only evaluate the cohesion and separation of clusters and ignore possible\nprior knowledge about the data. To address this challenge, we introduce the\nSynchronized Anomaly Agreement Index (SAAI), which exploits the synchronicity\nof anomalies across multivariate time series to assess cluster quality. We\ndemonstrate the effectiveness of SAAI by showing that maximizing SAAI improves\naccuracy on the task of finding the true number of anomaly classes K in\ncorrelated time series by 0.23 compared to SSC and by 0.32 compared to X-Means.\nWe also show that clusters obtained by maximizing SAAI are easier to interpret\ncompared to SSC.",
      "tldr_zh": "该论文针对相关多变量时间序列数据中的异常检测问题，指出监督方法因异常稀少和标签数据不足而受限，因此提出使用聚类分组异常行为，但现有评估指标如 Silhouette Score (SSC) 忽略了数据先验知识。作者引入了 Synchronized Anomaly Agreement Index (SAAI)，该指标利用异常在多变量时间序列中的同步性来评估聚类质量。实验结果显示，通过最大化 SAAI，可以将找到真实异常类数 K 的准确性比 SSC 提高 0.23、比 X-Means 提高 0.32，且获得的聚类更易解释，从而为异常分类提供更可靠的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Acccepted at AAAI Workshop on AI for Time Series Analysis (AI4TS)\n  2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07172v1",
      "published_date": "2025-01-13 10:04:55 UTC",
      "updated_date": "2025-01-13 10:04:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:08:07.906870"
    },
    {
      "arxiv_id": "2501.07166v1",
      "title": "Natural Language-Assisted Multi-modal Medication Recommendation",
      "title_zh": "自然语言辅助多模态药物推荐",
      "authors": [
        "Jie Tan",
        "Yu Rong",
        "Kangfei Zhao",
        "Tian Bian",
        "Tingyang Xu",
        "Junzhou Huang",
        "Hong Cheng",
        "Helen Meng"
      ],
      "abstract": "Combinatorial medication recommendation(CMR) is a fundamental task of\nhealthcare, which offers opportunities for clinical physicians to provide more\nprecise prescriptions for patients with intricate health conditions,\nparticularly in the scenarios of long-term medical care. Previous research\nefforts have sought to extract meaningful information from electronic health\nrecords (EHRs) to facilitate combinatorial medication recommendations. Existing\nlearning-based approaches further consider the chemical structures of\nmedications, but ignore the textual medication descriptions in which the\nfunctionalities are clearly described. Furthermore, the textual knowledge\nderived from the EHRs of patients remains largely underutilized. To address\nthese issues, we introduce the Natural Language-Assisted Multi-modal Medication\nRecommendation(NLA-MMR), a multi-modal alignment framework designed to learn\nknowledge from the patient view and medication view jointly. Specifically,\nNLA-MMR formulates CMR as an alignment problem from patient and medication\nmodalities. In this vein, we employ pretrained language models(PLMs) to extract\nin-domain knowledge regarding patients and medications, serving as the\nfoundational representation for both modalities. In the medication modality, we\nexploit both chemical structures and textual descriptions to create medication\nrepresentations. In the patient modality, we generate the patient\nrepresentations based on textual descriptions of diagnosis, procedure, and\nsymptom. Extensive experiments conducted on three publicly accessible datasets\ndemonstrate that NLA-MMR achieves new state-of-the-art performance, with a\nnotable average improvement of 4.72% in Jaccard score. Our source code is\npublicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.",
      "tldr_zh": "这篇论文提出了 Natural Language-Assisted Multi-modal Medication Recommendation (NLA-MMR)，一个多模态对齐框架，用于提升组合用药推荐 (CMR)，以帮助医生为复杂健康状况的患者提供更精确处方。NLA-MMR 通过预训练语言模型 (PLMs) 联合提取患者和药物视图的知识，包括药物模态的化学结构和文本描述，以及患者模态的诊断、程序和症状文本描述，将 CMR 问题转化为模态对齐任务。实验在三个公开数据集上证明，该框架在 Jaccard 分数上平均提高了 4.72%，实现了新的最先进性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2501.07166v1",
      "published_date": "2025-01-13 09:51:50 UTC",
      "updated_date": "2025-01-13 09:51:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:08:20.224767"
    },
    {
      "arxiv_id": "2501.07161v1",
      "title": "QuantuneV2: Compiler-Based Local Metric-Driven Mixed Precision Quantization for Practical Embedded AI Applications",
      "title_zh": "QuantuneV2：基于编译器的局部指标驱动混合精度量化，用于实际嵌入式 AI 应用",
      "authors": [
        "Jeongseok Kim",
        "Jemin Lee",
        "Yongin Kwon",
        "Daeyoung Kim"
      ],
      "abstract": "Mixed-precision quantization methods have been proposed to reduce model size\nwhile minimizing accuracy degradation. However, existing studies require\nretraining and do not consider the computational overhead and intermediate\nrepresentations (IR) generated during the compilation process, limiting their\napplication at the compiler level. This computational overhead refers to the\nruntime latency caused by frequent quantization and dequantization operations\nduring inference. Performing these operations at the individual operator level\ncauses significant runtime delays. To address these issues, we propose\nQuantuneV2, a compiler-based mixed-precision quantization method designed for\npractical embedded AI applications. QuantuneV2 performs inference only twice,\nonce before quantization and once after quantization, and operates with a\ncomputational complexity of O(n) that increases linearly with the number of\nmodel parameters. We also made the sensitivity analysis more stable by using\nlocal metrics like weights, activation values, the Signal to Quantization Noise\nRatio, and the Mean Squared Error. We also cut down on computational overhead\nby choosing the best IR and using operator fusion. Experimental results show\nthat QuantuneV2 achieved up to a 10.28 percent improvement in accuracy and a\n12.52 percent increase in speed compared to existing methods across five\nmodels: ResNet18v1, ResNet50v1, SqueezeNetv1, VGGNet, and MobileNetv2. This\ndemonstrates that QuantuneV2 enhances model performance while maintaining\ncomputational efficiency, making it suitable for deployment in embedded AI\nenvironments.",
      "tldr_zh": "本研究提出QuantuneV2，一种基于编译器的本地指标驱动混合精度量化(Mixed-Precision Quantization)方法，旨在为嵌入式AI应用减少模型大小并最小化准确性损失，同时避免现有方法的重新训练需求和计算开销。QuantuneV2仅需两次推理（量化前后），计算复杂度为O(n)，并通过使用本地指标（如权重、激活值、Signal to Quantization Noise Ratio和Mean Squared Error）优化敏感性分析，以及选择最佳中间表示(IR)和操作符融合来降低运行时延迟。实验结果显示，在ResNet18v1、ResNet50v1、SqueezeNetv1、VGGNet和MobileNetv2五个模型上，QuantuneV2相较现有方法提高了高达10.28%的准确性和12.52%的速度，提升了嵌入式AI应用的性能和效率。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 10 figures, Accepted in Future Generation Computer Systems\n  Journal",
      "pdf_url": "http://arxiv.org/pdf/2501.07161v1",
      "published_date": "2025-01-13 09:41:54 UTC",
      "updated_date": "2025-01-13 09:41:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:08:31.596780"
    },
    {
      "arxiv_id": "2501.07158v1",
      "title": "Eye Sclera for Fair Face Image Quality Assessment",
      "title_zh": "翻译失败",
      "authors": [
        "Wassim Kabbani",
        "Kiran Raja",
        "Raghavendra Ramachandra",
        "Christoph Busch"
      ],
      "abstract": "Fair operational systems are crucial in gaining and maintaining society's\ntrust in face recognition systems (FRS). FRS start with capturing an image and\nassessing its quality before using it further for enrollment or verification.\nFair Face Image Quality Assessment (FIQA) schemes therefore become equally\nimportant in the context of fair FRS. This work examines the sclera as a\nquality assessment region for obtaining a fair FIQA. The sclera region is\nagnostic to demographic variations and skin colour for assessing the quality of\na face image. We analyze three skin tone related ISO/IEC face image quality\nassessment measures and assess the sclera region as an alternative area for\nassessing FIQ. Our analysis of the face dataset of individuals from different\ndemographic groups representing different skin tones indicates sclera as an\nalternative to measure dynamic range, over- and under-exposure of face using\nsclera region alone. The sclera region being agnostic to skin tone, i.e.,\ndemographic factors, provides equal utility as a fair FIQA as shown by our\nError-vs-Discard Characteristic (EDC) curve analysis.",
      "tldr_zh": "这篇论文探讨了使用eye sclera（眼白）区域作为Face Image Quality Assessment (FIQA) 的方法，以提升人脸识别系统（FRS）的公平性，因为sclera不受人口统计学差异（如肤色）的影响。作者分析了三种与肤色相关的ISO/IEC质量评估措施，并通过不同人群数据集的实验，证明sclera区域可有效评估图像的动态范围、过曝和欠曝。结果显示，这种基于sclera的FIQA在Error-vs-Discard Characteristic (EDC)曲线分析中提供了公平且等效的效用，为构建可信赖的FRS奠定了基础。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07158v1",
      "published_date": "2025-01-13 09:33:03 UTC",
      "updated_date": "2025-01-13 09:33:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:08:44.445258"
    },
    {
      "arxiv_id": "2501.07157v1",
      "title": "CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Jinlin Li",
        "Xiao Zhou"
      ],
      "abstract": "The early detection and prediction of health status decline among the elderly\nat the neighborhood level are of great significance for urban planning and\npublic health policymaking. While existing studies affirm the connection\nbetween living environments and health outcomes, most rely on single data\nmodalities or simplistic feature concatenation of multi-modal information,\nlimiting their ability to comprehensively profile the health-oriented urban\nenvironments. To fill this gap, we propose CureGraph, a contrastive multi-modal\nrepresentation learning framework for urban health prediction that employs\ngraph-based techniques to infer the prevalence of common chronic diseases among\nthe elderly within the urban living circles of each neighborhood. CureGraph\nleverages rich multi-modal information, including photos and textual reviews of\nresidential areas and their surrounding points of interest, to generate urban\nneighborhood embeddings. By integrating pre-trained visual and textual encoders\nwith graph modeling techniques, CureGraph captures cross-modal spatial\ndependencies, offering a comprehensive understanding of urban environments\ntailored to elderly health considerations. Extensive experiments on real-world\ndatasets demonstrate that CureGraph improves the best baseline by $28\\%$ on\naverage in terms of $R^2$ across elderly disease risk prediction tasks.\nMoreover, the model enables the identification of stage-wise chronic disease\nprogression and supports comparative public health analysis across\nneighborhoods, offering actionable insights for sustainable urban development\nand enhanced quality of life. The code is publicly available at\nhttps://github.com/jinlin2021/CureGraph.",
      "tldr_zh": "本研究提出CureGraph框架，通过对比式多模式图表示学习（Contrastive Multi-Modal Graph Representation Learning），针对城市社区环境评估老年人健康状况的早期检测和预测。\n该框架整合照片、文本评论等多模式数据，利用预训练视觉和文本编码器与图建模技术，捕捉跨模式空间依赖，从而生成社区嵌入并推断慢性病流行。\n实验在真实数据集上显示，CureGraph比最佳基线平均提高28%的R²值，并支持识别慢性病阶段性进展和社区间比较，提供可行动的城市规划与公共卫生见解。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07157v1",
      "published_date": "2025-01-13 09:30:38 UTC",
      "updated_date": "2025-01-13 09:30:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:08:56.147286"
    },
    {
      "arxiv_id": "2501.07146v1",
      "title": "TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary and Multi-Task Environments",
      "title_zh": "TIMRL：一种新颖的元强化学习框架，用于非平稳和多任务环境",
      "authors": [
        "Chenyang Qi",
        "Huiping Li",
        "Panfeng Huang"
      ],
      "abstract": "In recent years, meta-reinforcement learning (meta-RL) algorithm has been\nproposed to improve sample efficiency in the field of decision-making and\ncontrol, enabling agents to learn new knowledge from a small number of samples.\nHowever, most research uses the Gaussian distribution to extract task\nrepresentation, which is poorly adapted to tasks that change in non-stationary\nenvironment. To address this problem, we propose a novel meta-reinforcement\nlearning method by leveraging Gaussian mixture model and the transformer\nnetwork to construct task inference model. The Gaussian mixture model is\nutilized to extend the task representation and conduct explicit encoding of\ntasks. Specifically, the classification of tasks is encoded through transformer\nnetwork to determine the Gaussian component corresponding to the task. By\nleveraging task labels, the transformer network is trained using supervised\nlearning. We validate our method on MuJoCo benchmarks with non-stationary and\nmulti-task environments. Experimental results demonstrate that the proposed\nmethod dramatically improves sample efficiency and accurately recognizes the\nclassification of the tasks, while performing excellently in the environment.",
      "tldr_zh": "该研究提出了一种新型元强化学习(meta-reinforcement learning)框架 TIMRL，旨在解决现有算法在非平稳和多任务环境中使用高斯分布提取任务表示的适应性问题。TIMRL 通过引入高斯混合模型(Gaussian mixture model)来扩展任务表示，并结合 transformer network 进行任务分类编码，实现显式任务编码和监督学习训练。实验在 MuJoCo benchmarks 的非平稳多任务环境中验证，该方法显著提高了样本效率，准确识别任务分类，并在整体性能上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07146v1",
      "published_date": "2025-01-13 09:11:33 UTC",
      "updated_date": "2025-01-13 09:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:09:07.218746"
    },
    {
      "arxiv_id": "2501.07139v1",
      "title": "FlexQuant: Elastic Quantization Framework for Locally Hosted LLM on Edge Devices",
      "title_zh": "翻译失败",
      "authors": [
        "Yuji Chai",
        "Mujin Kwen",
        "David Brooks",
        "Gu-Yeon Wei"
      ],
      "abstract": "Deploying LLMs on edge devices presents serious technical challenges. Memory\nelasticity is crucial for edge devices with unified memory, where memory is\nshared and fluctuates dynamically. Existing solutions suffer from either poor\ntransition granularity or high storage costs. We propose FlexQuant, a novel\nelasticity framework that generates an ensemble of quantized models, providing\nan elastic hosting solution with 15x granularity improvement and 10x storage\nreduction compared to SoTA methods. FlexQuant works with most quantization\nmethods and creates a family of trade-off options under various storage limits\nthrough our pruning method. It brings great performance and flexibility to the\nedge deployment of LLMs.",
      "tldr_zh": "该研究针对在边缘设备上部署大型语言模型 (LLMs) 的挑战，提出 FlexQuant 框架，以解决内存弹性问题。FlexQuant 通过生成一组量化模型的集合，实现弹性托管解决方案，比现有最先进方法 (SoTA) 改善 15 倍粒度和减少 10 倍存储成本，同时兼容大多数量化方法。框架利用修剪技术创建各种存储限制下的性能权衡选项，最终提升了 LLMs 在边缘设备的部署灵活性和整体性能。",
      "categories": [
        "cs.AI",
        "cs.PF"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07139v1",
      "published_date": "2025-01-13 08:58:00 UTC",
      "updated_date": "2025-01-13 08:58:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:09:18.942146"
    },
    {
      "arxiv_id": "2501.07108v1",
      "title": "How GPT learns layer by layer",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Du",
        "Kelly Hong",
        "Alishba Imran",
        "Erfan Jahanparast",
        "Mehdi Khfifi",
        "Kaichun Qiao"
      ],
      "abstract": "Large Language Models (LLMs) excel at tasks like language processing,\nstrategy games, and reasoning but struggle to build generalizable internal\nrepresentations essential for adaptive decision-making in agents. For agents to\neffectively navigate complex environments, they must construct reliable world\nmodels. While LLMs perform well on specific benchmarks, they often fail to\ngeneralize, leading to brittle representations that limit their real-world\neffectiveness. Understanding how LLMs build internal world models is key to\ndeveloping agents capable of consistent, adaptive behavior across tasks. We\nanalyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a\ncontrolled testbed for studying representation learning. Despite being trained\nsolely on next-token prediction with random valid moves, OthelloGPT shows\nmeaningful layer-wise progression in understanding board state and gameplay.\nEarly layers capture static attributes like board edges, while deeper layers\nreflect dynamic tile changes. To interpret these representations, we compare\nSparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more\nrobust, disentangled insights into compositional features, whereas linear\nprobes mainly detect features useful for classification. We use SAEs to decode\nfeatures related to tile color and tile stability, a previously unexamined\nfeature that reflects complex gameplay concepts like board control and\nlong-term planning. We study the progression of linear probe accuracy and tile\ncolor using both SAE's and linear probes to compare their effectiveness at\ncapturing what the model is learning. Although we begin with a smaller language\nmodel, OthelloGPT, this study establishes a framework for understanding the\ninternal representations learned by GPT models, transformers, and LLMs more\nbroadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.",
      "tldr_zh": "本文研究大型语言模型 (LLMs) 如何逐层构建内部表示，以解决其在泛化决策中的局限性，使用 OthelloGPT 作为训练于 Othello 游戏的测试床。分析显示，模型的早期层捕获静态特征如棋盘边缘，而深层层则处理动态变化如棋子状态；通过比较 Sparse Autoencoders (SAEs) 和 linear probes，SAEs 提供更 robust 和 disentangled 的特征解码，包括新发现的棋子稳定性特征。研究为理解 GPT 模型、transformer 和更广泛 LLMs 的内部学习过程建立了一个框架，并公开了相关代码。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07108v1",
      "published_date": "2025-01-13 07:42:55 UTC",
      "updated_date": "2025-01-13 07:42:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:09:33.113054"
    },
    {
      "arxiv_id": "2501.07102v1",
      "title": "AdaCS: Adaptive Normalization for Enhanced Code-Switching ASR",
      "title_zh": "翻译失败",
      "authors": [
        "The Chuong Chu",
        "Vu Tuan Dat Pham",
        "Kien Dao",
        "Hoang Nguyen",
        "Quoc Hung Truong"
      ],
      "abstract": "Intra-sentential code-switching (CS) refers to the alternation between\nlanguages that happens within a single utterance and is a significant challenge\nfor Automatic Speech Recognition (ASR) systems. For example, when a Vietnamese\nspeaker uses foreign proper names or specialized terms within their speech. ASR\nsystems often struggle to accurately transcribe intra-sentential CS due to\ntheir training on monolingual data and the unpredictable nature of CS. This\nissue is even more pronounced for low-resource languages, where limited data\navailability hinders the development of robust models. In this study, we\npropose AdaCS, a normalization model integrates an adaptive bias attention\nmodule (BAM) into encoder-decoder network. This novel approach provides a\nrobust solution to CS ASR in unseen domains, thereby significantly enhancing\nour contribution to the field. By utilizing BAM to both identify and normalize\nCS phrases, AdaCS enhances its adaptive capabilities with a biased list of\nwords provided during inference. Our method demonstrates impressive performance\nand the ability to handle unseen CS phrases across various domains. Experiments\nshow that AdaCS outperforms previous state-of-the-art method on Vietnamese CS\nASR normalization by considerable WER reduction of 56.2% and 36.8% on the two\nproposed test sets.",
      "tldr_zh": "该论文针对代码切换（Code-Switching）在自动语音识别（ASR）中的挑战，提出了一种自适应归一化模型AdaCS，以解决低资源语言如越南语在跨语言短语处理上的不足。AdaCS 整合了自适应偏差注意力模块（BAM）到编码器-解码器网络中，通过识别和归一化代码切换短语，并在推理时利用偏差词列表增强模型的适应性。实验结果显示，AdaCS 在越南语代码切换 ASR 任务上，比现有最佳方法降低了 56.2% 和 36.8% 的 WER（Word Error Rate），显著提升了模型在未见领域的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07102v1",
      "published_date": "2025-01-13 07:27:00 UTC",
      "updated_date": "2025-01-13 07:27:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:09:44.538834"
    },
    {
      "arxiv_id": "2501.07100v1",
      "title": "Collaborative Learning for 3D Hand-Object Reconstruction and Compositional Action Recognition from Egocentric RGB Videos Using Superquadrics",
      "title_zh": "翻译失败",
      "authors": [
        "Tze Ho Elden Tse",
        "Runyang Feng",
        "Linfang Zheng",
        "Jiho Park",
        "Yixing Gao",
        "Jihie Kim",
        "Ales Leonardis",
        "Hyung Jin Chang"
      ],
      "abstract": "With the availability of egocentric 3D hand-object interaction datasets,\nthere is increasing interest in developing unified models for hand-object pose\nestimation and action recognition. However, existing methods still struggle to\nrecognise seen actions on unseen objects due to the limitations in representing\nobject shape and movement using 3D bounding boxes. Additionally, the reliance\non object templates at test time limits their generalisability to unseen\nobjects. To address these challenges, we propose to leverage superquadrics as\nan alternative 3D object representation to bounding boxes and demonstrate their\neffectiveness on both template-free object reconstruction and action\nrecognition tasks. Moreover, as we find that pure appearance-based methods can\noutperform the unified methods, the potential benefits from 3D geometric\ninformation remain unclear. Therefore, we study the compositionality of actions\nby considering a more challenging task where the training combinations of verbs\nand nouns do not overlap with the testing split. We extend H2O and FPHA\ndatasets with compositional splits and design a novel collaborative learning\nframework that can explicitly reason about the geometric relations between\nhands and the manipulated object. Through extensive quantitative and\nqualitative evaluations, we demonstrate significant improvements over the\nstate-of-the-arts in (compositional) action recognition.",
      "tldr_zh": "本论文提出一种协作学习框架，用于从egocentric RGB videos中进行3D手部-物体重建和组合性动作识别，采用superquadrics作为替代3D边界框的物体表示方法，以解决现有模型在处理未见物体和动作组合时的泛化性问题。该框架显式推理手部与物体之间的几何关系，并扩展了H2O和FPHA数据集，添加了verbs和nouns组合不重叠的挑战性分割。通过定量和定性评估，实验结果显示，该方法在组合性动作识别任务上显著优于现有最先进模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to AAAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07100v1",
      "published_date": "2025-01-13 07:26:05 UTC",
      "updated_date": "2025-01-13 07:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:09:55.599761"
    },
    {
      "arxiv_id": "2501.07088v2",
      "title": "MathReader : Text-to-Speech for Mathematical Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Sieun Hyeon",
        "Kyudan Jung",
        "Nam-Joon Kim",
        "Hyun Gon Ryu",
        "Jaeyoung Do"
      ],
      "abstract": "TTS (Text-to-Speech) document reader from Microsoft, Adobe, Apple, and OpenAI\nhave been serviced worldwide. They provide relatively good TTS results for\ngeneral plain text, but sometimes skip contents or provide unsatisfactory\nresults for mathematical expressions. This is because most modern academic\npapers are written in LaTeX, and when LaTeX formulas are compiled, they are\nrendered as distinctive text forms within the document. However, traditional\nTTS document readers output only the text as it is recognized, without\nconsidering the mathematical meaning of the formulas. To address this issue, we\npropose MathReader, which effectively integrates OCR, a fine-tuned T5 model,\nand TTS. MathReader demonstrated a lower Word Error Rate (WER) than existing\nTTS document readers, such as Microsoft Edge and Adobe Acrobat, when processing\ndocuments containing mathematical formulas. MathReader reduced the WER from\n0.510 to 0.281 compared to Microsoft Edge, and from 0.617 to 0.281 compared to\nAdobe Acrobat. This will significantly contribute to alleviating the\ninconvenience faced by users who want to listen to documents, especially those\nwho are visually impaired. The code is available at\nhttps://github.com/hyeonsieun/MathReader.",
      "tldr_zh": "本文提出MathReader，一种针对数学文档的Text-to-Speech (TTS) 系统，旨在解决现有TTS工具（如Microsoft Edge和Adobe Acrobat）在处理LaTeX公式时容易跳过内容或输出不准确的问题。MathReader通过整合OCR、fine-tuned T5模型和TTS，实现对数学表达式的有效识别和转换。实验结果显示，MathReader显著降低了Word Error Rate (WER)，将Microsoft Edge的WER从0.510降至0.281，并将Adobe Acrobat的WER从0.617降至0.281。该系统有助于缓解视力障碍用户聆听学术文档的不便，并已在GitHub开源。",
      "categories": [
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICASSP 2025",
      "pdf_url": "http://arxiv.org/pdf/2501.07088v2",
      "published_date": "2025-01-13 06:47:05 UTC",
      "updated_date": "2025-01-19 06:27:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:10:07.925217"
    },
    {
      "arxiv_id": "2501.07087v1",
      "title": "Video Quality Assessment for Online Processing: From Spatial to Temporal Sampling",
      "title_zh": "用于在线处理的视频质量评估：从空间到时间采样",
      "authors": [
        "Jiebin Yan",
        "Lei Wu",
        "Yuming Fang",
        "Xuelin Liu",
        "Xue Xia",
        "Weide Liu"
      ],
      "abstract": "With the rapid development of multimedia processing and deep learning\ntechnologies, especially in the field of video understanding, video quality\nassessment (VQA) has achieved significant progress. Although researchers have\nmoved from designing efficient video quality mapping models to various research\ndirections, in-depth exploration of the effectiveness-efficiency trade-offs of\nspatio-temporal modeling in VQA models is still less sufficient. Considering\nthe fact that videos have highly redundant information, this paper investigates\nthis problem from the perspective of joint spatial and temporal sampling,\naiming to seek the answer to how little information we should keep at least\nwhen feeding videos into the VQA models while with acceptable performance\nsacrifice. To this end, we drastically sample the video's information from both\nspatial and temporal dimensions, and the heavily squeezed video is then fed\ninto a stable VQA model. Comprehensive experiments regarding joint spatial and\ntemporal sampling are conducted on six public video quality databases, and the\nresults demonstrate the acceptable performance of the VQA model when throwing\naway most of the video information. Furthermore, with the proposed joint\nspatial and temporal sampling strategy, we make an initial attempt to design an\nonline VQA model, which is instantiated by as simple as possible a spatial\nfeature extractor, a temporal feature fusion module, and a global quality\nregression module. Through quantitative and qualitative experiments, we verify\nthe feasibility of online VQA model by simplifying itself and reducing input.",
      "tldr_zh": "这篇论文探讨了视频质量评估（VQA）中空间和时间采样的效果-效率权衡，针对视频的冗余信息，通过联合空间和时间采样策略，研究了在最小化输入信息的同时保持模型可接受性能的最低阈值。在六个公共视频质量数据库上进行的实验表明，即使丢弃大部分视频信息，VQA 模型仍能实现满意的性能。此外，作者基于这一策略设计了一种简化的在线 VQA 模型，包括简单的空间特征提取器、时间特征融合模块和全局质量回归模块，并通过定量和定性实验验证了其可行性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07087v1",
      "published_date": "2025-01-13 06:45:32 UTC",
      "updated_date": "2025-01-13 06:45:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:10:20.617072"
    },
    {
      "arxiv_id": "2501.07078v1",
      "title": "ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayang Wu",
        "Wensheng Gan",
        "Jiahao Zhang",
        "Philip S. Yu"
      ],
      "abstract": "In the current development of large language models (LLMs), it is important\nto ensure the accuracy and reliability of the underlying data sources. LLMs are\ncritical for various applications, but they often suffer from hallucinations\nand inaccuracies due to knowledge gaps in the training data. Knowledge graphs\n(KGs), as a powerful structural tool, could serve as a vital external\ninformation source to mitigate the aforementioned issues. By providing a\nstructured and comprehensive understanding of real-world data, KGs enhance the\nperformance and reliability of LLMs. However, it is common that errors exist in\nKGs while extracting triplets from unstructured data to construct KGs. This\ncould lead to degraded performance in downstream tasks such as\nquestion-answering and recommender systems. Therefore, anomaly detection in KGs\nis essential to identify and correct these errors. This paper presents an\nanomaly detection algorithm in knowledge graphs with dual-channel learning\n(ADKGD). ADKGD leverages a dual-channel learning approach to enhance\nrepresentation learning from both the entity-view and triplet-view\nperspectives. Furthermore, using a cross-layer approach, our framework\nintegrates internal information aggregation and context information\naggregation. We introduce a kullback-leibler (KL)-loss component to improve the\naccuracy of the scoring function between the dual channels. To evaluate ADKGD's\nperformance, we conduct empirical studies on three real-world KGs: WN18RR,\nFB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms\nthe state-of-the-art anomaly detection algorithms. The source code and datasets\nare publicly available at https://github.com/csjywu1/ADKGD.",
      "tldr_zh": "本论文针对大型语言模型(LLMs)中的幻觉和不准确性问题，提出使用知识图谱(KGs)作为外部信息源来提升可靠性，但强调KGs本身可能存在错误，需要进行异常检测。研究引入ADKGD算法，该算法采用双通道学习(dual-channel learning)从实体视角(entity-view)和三元组视角(triplet-view)增强表示学习，并通过跨层方法整合内部信息聚合和上下文信息聚合，同时使用Kullback-Leibler (KL)-loss优化评分函数。在WN18RR、FB15K和NELL-995等真实数据集上的实验表明，ADKGD优于现有最先进异常检测算法，源代码和数据集已在GitHub公开。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. 11 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.07078v1",
      "published_date": "2025-01-13 06:22:52 UTC",
      "updated_date": "2025-01-13 06:22:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:10:31.802938"
    },
    {
      "arxiv_id": "2501.07076v2",
      "title": "Representation Learning of Point Cloud Upsampling in Global and Local Inputs",
      "title_zh": "点云上采样在全局和局部输入中的表示学习",
      "authors": [
        "Tongxu Zhang",
        "Bei Wang"
      ],
      "abstract": "In recent years, point cloud upsampling has been widely applied in fields\nsuch as 3D reconstruction. Our study investigates the factors influencing point\ncloud upsampling on both global and local levels through representation\nlearning. Specifically, the paper inputs global and local information of the\nsame point cloud model object into two encoders to extract these features,\nfuses them, and then feeds the combined features into an upsampling decoder.\nThe goal is to address issues of sparsity and noise in point clouds by\nleveraging prior knowledge from both global and local inputs. And the proposed\nframework can be applied to any state-of-the-art point cloud upsampling neural\nnetwork. Experiments were conducted on a series of autoencoder-based models\nutilizing deep learning, yielding interpretability for both global and local\ninputs, and it has been proven in the results that our proposed framework can\nfurther improve the upsampling effect in previous SOTA works. At the same time,\nthe Saliency Map reflects the differences between global and local feature\ninputs, as well as the effectiveness of training with both inputs in parallel.",
      "tldr_zh": "本研究探讨了点云上sampling在全局和局部输入下的表示学习影响因素，提出了一种框架，将同一点云模型的全局和局部信息分别输入两个编码器提取特征，然后融合后输入上sampling解码器，以解决点云的稀疏性和噪声问题。该框架可应用于任何SOTA点云上sampling神经网络，实验在基于自动编码器的深度学习模型上显示，它能进一步提升上sampling效果，并通过Saliency Map展示了全局和局部特征输入的差异及并行训练的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07076v2",
      "published_date": "2025-01-13 06:13:25 UTC",
      "updated_date": "2025-02-28 14:19:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:10:44.252575"
    },
    {
      "arxiv_id": "2501.07071v1",
      "title": "Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMs Values",
      "title_zh": "翻译失败",
      "authors": [
        "Jing Yao",
        "Xiaoyuan Yi",
        "Shitong Duan",
        "Jindong Wang",
        "Yuzhuo Bai",
        "Muhua Huang",
        "Peng Zhang",
        "Tun Lu",
        "Zhicheng Dou",
        "Maosong Sun",
        "Xing Xie"
      ],
      "abstract": "As Large Language Models (LLMs) achieve remarkable breakthroughs, aligning\ntheir values with humans has become imperative for their responsible\ndevelopment and customized applications. However, there still lack evaluations\nof LLMs values that fulfill three desirable goals. (1) Value Clarification: We\nexpect to clarify the underlying values of LLMs precisely and comprehensively,\nwhile current evaluations focus narrowly on safety risks such as bias and\ntoxicity. (2) Evaluation Validity: Existing static, open-source benchmarks are\nprone to data contamination and quickly become obsolete as LLMs evolve.\nAdditionally, these discriminative evaluations uncover LLMs' knowledge about\nvalues, rather than valid assessments of LLMs' behavioral conformity to values.\n(3) Value Pluralism: The pluralistic nature of human values across individuals\nand cultures is largely ignored in measuring LLMs value alignment. To address\nthese challenges, we presents the Value Compass Leaderboard, with three\ncorrespondingly designed modules. It (i) grounds the evaluation on\nmotivationally distinct \\textit{basic values to clarify LLMs' underlying values\nfrom a holistic view; (ii) applies a \\textit{generative evolving evaluation\nframework with adaptive test items for evolving LLMs and direct value\nrecognition from behaviors in realistic scenarios; (iii) propose a metric that\nquantifies LLMs alignment with a specific value as a weighted sum over multiple\ndimensions, with weights determined by pluralistic values.",
      "tldr_zh": "该研究指出了评估大型语言模型（LLMs）价值观的三大挑战：Value Clarification（精确全面澄清LLMs的底层价值观，但现有评估仅聚焦安全风险如偏见和毒性）、Evaluation Validity（现有静态基准易受数据污染且过时，且评估知识而非行为）和Value Pluralism（忽略人类价值观的多元性）。为了解决这些问题，作者提出了Value Compass Leaderboard平台，该平台包括三个模块：（i）基于动机上不同的basic values来整体视角评估LLMs的底层价值观；（ii）采用generative evolving evaluation framework和自适应测试项目，从现实场景的行为中直接识别价值观；（iii）提出一个量化指标，将LLMs与特定价值观的对齐度作为多个维度的加权和，权重基于多元价值观。该平台为LLMs的负责任发展和价值观对齐提供了更可靠和全面的评估框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07071v1",
      "published_date": "2025-01-13 05:53:56 UTC",
      "updated_date": "2025-01-13 05:53:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:10:56.213600"
    },
    {
      "arxiv_id": "2501.07058v1",
      "title": "Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities",
      "title_zh": "逻辑遇见魔法：LLMs 破解智能合约漏洞",
      "authors": [
        "ZeKe Xiao",
        "Qin Wang",
        "Hammond Pearce",
        "Shiping Chen"
      ],
      "abstract": "Smart contract vulnerabilities caused significant economic losses in\nblockchain applications. Large Language Models (LLMs) provide new possibilities\nfor addressing this time-consuming task. However, state-of-the-art LLM-based\ndetection solutions are often plagued by high false-positive rates.\n  In this paper, we push the boundaries of existing research in two key ways.\nFirst, our evaluation is based on Solidity v0.8, offering the most up-to-date\ninsights compared to prior studies that focus on older versions (v0.4). Second,\nwe leverage the latest five LLM models (across companies), ensuring\ncomprehensive coverage across the most advanced capabilities in the field.\n  We conducted a series of rigorous evaluations. Our experiments demonstrate\nthat a well-designed prompt can reduce the false-positive rate by over 60%.\nSurprisingly, we also discovered that the recall rate for detecting some\nspecific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to\nearlier versions (i.e., v0.4). Further analysis reveals the root cause of this\ndecline: the reliance of LLMs on identifying changes in newly introduced\nlibraries and frameworks during detection.",
      "tldr_zh": "本文研究了大语言模型 (LLMs) 在检测智能合约漏洞方面的潜力，针对现有方法的假阳性率高问题，使用 Solidity v0.8 版本和最新的五个 LLM 模型进行评估。实验结果显示，通过精心设计的提示，可以将假阳性率降低超过 60%。然而，对于某些特定漏洞，召回率降至 13%，原因是 LLMs 依赖于识别新引入的库和框架变化，这揭示了模型在区块链安全领域的局限性，并为优化检测策略提供了新见解。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07058v1",
      "published_date": "2025-01-13 04:42:45 UTC",
      "updated_date": "2025-01-13 04:42:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:11:07.714949"
    },
    {
      "arxiv_id": "2501.07054v1",
      "title": "PoAct: Policy and Action Dual-Control Agent for Generalized Applications",
      "title_zh": "PoAct：策略和行动双重控制代理用于泛化应用",
      "authors": [
        "Guozhi Yuan",
        "Youfeng Liu",
        "Jingli Yang",
        "Wei Jia",
        "Kai Lin",
        "Yansong Gao",
        "Shan He",
        "Zilin Ding",
        "Haitao Li"
      ],
      "abstract": "Based on their superior comprehension and reasoning capabilities, Large\nLanguage Model (LLM) driven agent frameworks have achieved significant success\nin numerous complex reasoning tasks. ReAct-like agents can solve various\nintricate problems step-by-step through progressive planning and tool calls,\niteratively optimizing new steps based on environmental feedback. However, as\nthe planning capabilities of LLMs improve, the actions invoked by tool calls in\nReAct-like frameworks often misalign with complex planning and challenging data\norganization. Code Action addresses these issues while also introducing the\nchallenges of a more complex action space and more difficult action\norganization. To leverage Code Action and tackle the challenges of its\ncomplexity, this paper proposes Policy and Action Dual-Control Agent (PoAct)\nfor generalized applications. The aim is to achieve higher-quality code actions\nand more accurate reasoning paths by dynamically switching reasoning policies\nand modifying the action space. Experimental results on the Agent Benchmark for\nboth legal and generic scenarios demonstrate the superior reasoning\ncapabilities and reduced token consumption of our approach in complex tasks. On\nthe LegalAgentBench, our method shows a 20 percent improvement over the\nbaseline while requiring fewer tokens. We conducted experiments and analyses on\nthe GPT-4o and GLM-4 series models, demonstrating the significant potential and\nscalability of our approach to solve complex problems.",
      "tldr_zh": "该论文提出PoAct（Policy and Action Dual-Control Agent），一种基于Large Language Model (LLM)的代理框架，用于泛化应用，以解决ReAct-like代理中工具调用与规划不匹配的问题，同时利用Code Action的优势。PoAct通过动态切换推理策略（policies）和修改行动空间（action space），实现更高质量的代码行动和更准确的推理路径。实验结果显示，在Agent Benchmark和LegalAgentBench上，PoAct比基线模型提高了20%的性能，同时减少了token消耗，并在GPT-4o和GLM-4系列模型上展现出显著的潜力和可扩展性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07054v1",
      "published_date": "2025-01-13 04:28:40 UTC",
      "updated_date": "2025-01-13 04:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:11:19.188844"
    },
    {
      "arxiv_id": "2501.07048v1",
      "title": "Unveiling the Potential of Text in High-Dimensional Time Series Forecasting",
      "title_zh": "揭示文本在高维时间序列预测中的潜力",
      "authors": [
        "Xin Zhou",
        "Weiqing Wang",
        "Shilin Qu",
        "Zhiqiang Zhang",
        "Christoph Bergmeir"
      ],
      "abstract": "Time series forecasting has traditionally focused on univariate and\nmultivariate numerical data, often overlooking the benefits of incorporating\nmultimodal information, particularly textual data. In this paper, we propose a\nnovel framework that integrates time series models with Large Language Models\nto improve high-dimensional time series forecasting. Inspired by multimodal\nmodels, our method combines time series and textual data in the dual-tower\nstructure. This fusion of information creates a comprehensive representation,\nwhich is then processed through a linear layer to generate the final forecast.\nExtensive experiments demonstrate that incorporating text enhances\nhigh-dimensional time series forecasting performance. This work paves the way\nfor further research in multimodal time series forecasting.",
      "tldr_zh": "这篇论文揭示了在高维时间序列预测中整合文本数据的潜力，提出一个新框架，将时间序列模型与 Large Language Models 结合，以克服传统方法忽略多模态信息的局限。方法采用双塔结构（dual-tower structure）融合时间序列和文本数据，形成全面表示，然后通过线性层生成最终预测。实验结果显示，这种整合显著提升了高维时间序列预测的性能。该工作为多模态时间序列预测的研究开辟了新方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by NeurIPS24 TSALM Workshop",
      "pdf_url": "http://arxiv.org/pdf/2501.07048v1",
      "published_date": "2025-01-13 04:10:45 UTC",
      "updated_date": "2025-01-13 04:10:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:11:31.701124"
    },
    {
      "arxiv_id": "2501.07045v1",
      "title": "ACCon: Angle-Compensated Contrastive Regularizer for Deep Regression",
      "title_zh": "ACCon：角度补偿对比正则化器用于深度回归",
      "authors": [
        "Botao Zhao",
        "Xiaoyang Qu",
        "Zuheng Kang",
        "Junqing Peng",
        "Jing Xiao",
        "Jianzong Wang"
      ],
      "abstract": "In deep regression, capturing the relationship among continuous labels in\nfeature space is a fundamental challenge that has attracted increasing\ninterest. Addressing this issue can prevent models from converging to\nsuboptimal solutions across various regression tasks, leading to improved\nperformance, especially for imbalanced regression and under limited sample\nsizes. However, existing approaches often rely on order-aware representation\nlearning or distance-based weighting. In this paper, we hypothesize a linear\nnegative correlation between label distances and representation similarities in\nregression tasks. To implement this, we propose an angle-compensated\ncontrastive regularizer for deep regression, which adjusts the cosine distance\nbetween anchor and negative samples within the contrastive learning framework.\nOur method offers a plug-and-play compatible solution that extends most\nexisting contrastive learning methods for regression tasks. Extensive\nexperiments and theoretical analysis demonstrate that our proposed\nangle-compensated contrastive regularizer not only achieves competitive\nregression performance but also excels in data efficiency and effectiveness on\nimbalanced datasets.",
      "tldr_zh": "本研究针对深度回归（deep regression）中捕捉连续标签在特征空间关系的挑战，假设标签距离与表示相似性之间存在线性负相关，从而提出ACCon（Angle-Compensated Contrastive Regularizer）——一个在对比学习（contrastive learning）框架中调整锚点和负样本余弦距离的正则化器。该方法作为即插即用的解决方案，能兼容大多数现有对比学习方法，并显著提升模型在不平衡数据集和样本有限场景下的性能。实验和理论分析证明，ACCon不仅在回归任务中实现竞争性表现，还展示了出色的数据效率和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accept by AAAI-2025 (The 39th Annual AAAI Conference on Artificial\n  Intelligence)",
      "pdf_url": "http://arxiv.org/pdf/2501.07045v1",
      "published_date": "2025-01-13 03:55:59 UTC",
      "updated_date": "2025-01-13 03:55:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:11:43.460665"
    },
    {
      "arxiv_id": "2501.07024v1",
      "title": "A Proposed Large Language Model-Based Smart Search for Archive System",
      "title_zh": "翻译失败",
      "authors": [
        "Ha Dung Nguyen",
        "Thi-Hoang Anh Nguyen",
        "Thanh Binh Nguyen"
      ],
      "abstract": "This study presents a novel framework for smart search in digital archival\nsystems, leveraging the capabilities of Large Language Models (LLMs) to enhance\ninformation retrieval. By employing a Retrieval-Augmented Generation (RAG)\napproach, the framework enables the processing of natural language queries and\ntransforming non-textual data into meaningful textual representations. The\nsystem integrates advanced metadata generation techniques, a hybrid retrieval\nmechanism, a router query engine, and robust response synthesis, the results\nproved search precision and relevance. We present the architecture and\nimplementation of the system and evaluate its performance in four experiments\nconcerning LLM efficiency, hybrid retrieval optimizations, multilingual query\nhandling, and the impacts of individual components. Obtained results show\nsignificant improvements over conventional approaches and have demonstrated the\npotential of AI-powered systems to transform modern archival practices.",
      "tldr_zh": "这篇论文提出了一种基于 Large Language Models (LLMs) 的智能搜索框架，用于提升数字档案系统的信息检索效率。该框架采用 Retrieval-Augmented Generation (RAG) 方法处理自然语言查询，并将非文本数据转化为有意义的文本表示，同时整合元数据生成、混合检索机制、路由查询引擎和响应合成技术。实验结果显示，该系统在 LLM 效率、混合检索优化、多语言查询处理等方面比传统方法显著改进，证明了 AI 驱动系统在现代档案实践中的转型潜力。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "The 13th International Symposium on Information and Communication\n  Technology (SOICT 2024)",
      "pdf_url": "http://arxiv.org/pdf/2501.07024v1",
      "published_date": "2025-01-13 02:53:07 UTC",
      "updated_date": "2025-01-13 02:53:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:11:55.262211"
    },
    {
      "arxiv_id": "2501.07021v2",
      "title": "Neural Probabilistic Circuits: Enabling Compositional and Interpretable Predictions through Logical Reasoning",
      "title_zh": "神经概率电路：通过逻辑推理实现组合性和可解释预测",
      "authors": [
        "Weixin Chen",
        "Simon Yu",
        "Huajie Shao",
        "Lui Sha",
        "Han Zhao"
      ],
      "abstract": "End-to-end deep neural networks have achieved remarkable success across\nvarious domains but are often criticized for their lack of interpretability.\nWhile post hoc explanation methods attempt to address this issue, they often\nfail to accurately represent these black-box models, resulting in misleading or\nincomplete explanations. To overcome these challenges, we propose an inherently\ntransparent model architecture called Neural Probabilistic Circuits (NPCs),\nwhich enable compositional and interpretable predictions through logical\nreasoning. In particular, an NPC consists of two modules: an attribute\nrecognition model, which predicts probabilities for various attributes, and a\ntask predictor built on a probabilistic circuit, which enables logical\nreasoning over recognized attributes to make class predictions. To train NPCs,\nwe introduce a three-stage training algorithm comprising attribute recognition,\ncircuit construction, and joint optimization. Moreover, we theoretically\ndemonstrate that an NPC's error is upper-bounded by a linear combination of the\nerrors from its modules. To further demonstrate the interpretability of NPC, we\nprovide both the most probable explanations and the counterfactual\nexplanations. Empirical results on four benchmark datasets show that NPCs\nstrike a balance between interpretability and performance, achieving results\ncompetitive even with those of end-to-end black-box models while providing\nenhanced interpretability.",
      "tldr_zh": "该研究针对端到端深度神经网络缺乏可解释性的问题，提出了一种固有透明的模型架构——Neural Probabilistic Circuits (NPCs)，通过逻辑推理实现可组合和可解释的预测。NPCs 由两个模块组成：属性识别模型（预测属性概率）和任务预测器（基于 probabilistic circuit 进行逻辑推理）。研究引入了三阶段训练算法，包括属性识别、电路构建和联合优化，并理论证明了 NPCs 的错误被上界为模块错误的线性组合。实验在四个基准数据集上显示，NPCs 在保持高性能的同时，提供最可能解释和反事实解释，从而在可解释性和准确性之间取得良好平衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07021v2",
      "published_date": "2025-01-13 02:47:49 UTC",
      "updated_date": "2025-01-20 04:00:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:12:07.692807"
    },
    {
      "arxiv_id": "2501.07020v1",
      "title": "ViSoLex: An Open-Source Repository for Vietnamese Social Media Lexical Normalization",
      "title_zh": "ViSoLex：越南社交媒体词汇规范化的开源仓库",
      "authors": [
        "Anh Thi-Hoang Nguyen",
        "Dung Ha Nguyen",
        "Kiet Van Nguyen"
      ],
      "abstract": "ViSoLex is an open-source system designed to address the unique challenges of\nlexical normalization for Vietnamese social media text. The platform provides\ntwo core services: Non-Standard Word (NSW) Lookup and Lexical Normalization,\nenabling users to retrieve standard forms of informal language and standardize\ntext containing NSWs. ViSoLex's architecture integrates pre-trained language\nmodels and weakly supervised learning techniques to ensure accurate and\nefficient normalization, overcoming the scarcity of labeled data in Vietnamese.\nThis paper details the system's design, functionality, and its applications for\nresearchers and non-technical users. Additionally, ViSoLex offers a flexible,\ncustomizable framework that can be adapted to various datasets and research\nrequirements. By publishing the source code, ViSoLex aims to contribute to the\ndevelopment of more robust Vietnamese natural language processing tools and\nencourage further research in lexical normalization. Future directions include\nexpanding the system's capabilities for additional languages and improving the\nhandling of more complex non-standard linguistic patterns.",
      "tldr_zh": "ViSoLex 是一个开源仓库，旨在解决越南社交媒体文本的词汇规范化问题，提供 Non-Standard Word (NSW) Lookup 和 Lexical Normalization 服务，帮助用户检索和标准化非标准词汇。系统采用预训练语言模型和弱监督学习技术，克服了越南语标注数据稀缺的挑战，并提供灵活的框架以适应各种数据集和研究需求。该系统不仅详细阐述了其设计、功能和应用，还通过开源代码促进越南自然语言处理工具的发展，并计划未来扩展到其他语言和更复杂的语言模式。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The 31st International Conference on Computational Linguistics\n  (COLING 2025)",
      "pdf_url": "http://arxiv.org/pdf/2501.07020v1",
      "published_date": "2025-01-13 02:47:13 UTC",
      "updated_date": "2025-01-13 02:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:12:18.963904"
    },
    {
      "arxiv_id": "2501.07017v2",
      "title": "UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM",
      "title_zh": "翻译失败",
      "authors": [
        "Xuhui Guo",
        "Tanmoy Dam",
        "Rohan Dhamdhere",
        "Gourav Modanwal",
        "Anant Madabhushi"
      ],
      "abstract": "3D medical image segmentation has progressed considerably due to\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these\nmethods struggle to balance long-range dependency acquisition with\ncomputational efficiency. To address this challenge, we propose UNETVL (U-Net\nVision-LSTM), a novel architecture that leverages recent advancements in\ntemporal information processing. UNETVL incorporates Vision-LSTM (ViL) for\nimproved scalability and memory functions, alongside an efficient Chebyshev\nKolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency\npatterns more effectively. We validated our method on the ACDC and AMOS2022\n(post challenge Task 2) benchmark datasets, showing a significant improvement\nin mean Dice score compared to recent state-of-the-art approaches, especially\nover its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,\nrespectively. Extensive ablation studies were conducted to demonstrate the\nimpact of each component in UNETVL, providing a comprehensive understanding of\nits architecture. Our code is available at https://github.com/tgrex6/UNETVL,\nfacilitating further research and applications in this domain.",
      "tldr_zh": "该研究针对 3D 医疗图像分割中 CNNs 和 ViTs 在获取长程依赖与计算效率间的平衡问题，提出了 UNETVL 架构，该架构整合 Vision-LSTM (ViL) 以提升可扩展性和记忆功能，并使用 Chebyshev KAN 来更有效地处理复杂依赖模式。\nUNETVL 在 ACDC 和 AMOS2022 数据集上进行验证，与现有方法相比，mean Dice score 分别提高了 7.3% 和 15.6%，显著优于其前身 UNETR。\n此外，通过广泛的消融研究，证实了各组件对整体性能的贡献，并开源代码以支持进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07017v2",
      "published_date": "2025-01-13 02:33:28 UTC",
      "updated_date": "2025-01-19 19:06:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:12:32.593816"
    },
    {
      "arxiv_id": "2501.07016v1",
      "title": "A Multi-Modal Deep Learning Framework for Pan-Cancer Prognosis",
      "title_zh": "翻译失败",
      "authors": [
        "Binyu Zhang",
        "Shichao Li",
        "Junpeng Jian",
        "Zhu Meng",
        "Limei Guo",
        "Zhicheng Zhao"
      ],
      "abstract": "Prognostic task is of great importance as it closely related to the survival\nanalysis of patients, the optimization of treatment plans and the allocation of\nresources. The existing prognostic models have shown promising results on\nspecific datasets, but there are limitations in two aspects. On the one hand,\nthey merely explore certain types of modal data, such as patient histopathology\nWSI and gene expression analysis. On the other hand, they adopt the\nper-cancer-per-model paradigm, which means the trained models can only predict\nthe prognostic effect of a single type of cancer, resulting in weak\ngeneralization ability. In this paper, a deep-learning based model, named\nUMPSNet, is proposed. Specifically, to comprehensively understand the condition\nof patients, in addition to constructing encoders for histopathology images and\ngenomic expression profiles respectively, UMPSNet further integrates four types\nof important meta data (demographic information, cancer type information,\ntreatment protocols, and diagnosis results) into text templates, and then\nintroduces a text encoder to extract textual features. In addition, the optimal\ntransport OT-based attention mechanism is utilized to align and fuse features\nof different modalities. Furthermore, a guided soft mixture of experts (GMoE)\nmechanism is introduced to effectively address the issue of distribution\ndifferences among multiple cancer datasets. By incorporating the multi-modality\nof patient data and joint training, UMPSNet outperforms all SOTA approaches,\nand moreover, it demonstrates the effectiveness and generalization ability of\nthe proposed learning paradigm of a single model for multiple cancer types. The\ncode of UMPSNet is available at https://github.com/binging512/UMPSNet.",
      "tldr_zh": "本文提出 UMPSNet，一种多模态深度学习框架，用于泛癌症预后预测，以解决现有模型仅依赖单一模态数据（如组织病理学 WSI 和基因表达分析）且采用 per-cancer-per-model 范式的局限性。UMPSNet 整合了组织病理学图像、基因组表达配置文件以及四种元数据（demographic information、cancer type information、treatment protocols 和 diagnosis results），并利用 optimal transport (OT)-based attention mechanism 融合特征，以及 guided soft mixture of experts (GMoE) 机制处理多癌症数据集的分布差异。通过多模态数据联合训练，UMPSNet 超越了所有最先进方法，并在泛化能力上表现出色，代码开源于 GitHub。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07016v1",
      "published_date": "2025-01-13 02:29:42 UTC",
      "updated_date": "2025-01-13 02:29:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:12:45.004017"
    },
    {
      "arxiv_id": "2501.07014v3",
      "title": "AlgoRxplorers | Precision in Mutation: Enhancing Drug Design with Advanced Protein Stability Prediction Tools",
      "title_zh": "翻译失败",
      "authors": [
        "Karishma Thakrar",
        "Jiangqin Ma",
        "Max Diamond",
        "Akash Patel"
      ],
      "abstract": "Predicting the impact of single-point amino acid mutations on protein\nstability is essential for understanding disease mechanisms and advancing drug\ndevelopment. Protein stability, quantified by changes in Gibbs free energy\n($\\Delta\\Delta G$), is influenced by these mutations. However, the scarcity of\ndata and the complexity of model interpretation pose challenges in accurately\npredicting stability changes. This study proposes the application of deep\nneural networks, leveraging transfer learning and fusing complementary\ninformation from different models, to create a feature-rich representation of\nthe protein stability landscape. We developed four models, with our third\nmodel, ThermoMPNN+, demonstrating the best performance in predicting\n$\\Delta\\Delta G$ values. This approach, which integrates diverse feature sets\nand embeddings through latent transfusion techniques, aims to refine\n$\\Delta\\Delta G$ predictions and contribute to a deeper understanding of\nprotein dynamics, potentially leading to advancements in disease research and\ndrug discovery.",
      "tldr_zh": "该研究针对预测单点氨基酸突变对蛋白质稳定性的影响，提出了一种利用深度神经网络的方法，以提升药物设计精度。研究通过转移学习和融合不同模型的互补信息，创建丰富的蛋白质稳定性表示，并开发了四个模型，其中ThermoMPNN+在预测Gibbs自由能变化($\\Delta\\Delta G$)值方面表现出最佳性能。借助潜在转移(latent transfusion)技术，该方法整合多样特征集，旨在深化蛋白质动态理解，并为疾病研究和药物发现带来潜在进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.07014v3",
      "published_date": "2025-01-13 02:17:01 UTC",
      "updated_date": "2025-01-30 02:45:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:12:55.448111"
    },
    {
      "arxiv_id": "2501.06999v1",
      "title": "Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps",
      "title_zh": "通过分层体积保持映射的级联扩散模型似然训练",
      "authors": [
        "Henry Li",
        "Ronen Basri",
        "Yuval Kluger"
      ],
      "abstract": "Cascaded models are multi-scale generative models with a marked capacity for\nproducing perceptually impressive samples at high resolutions. In this work, we\nshow that they can also be excellent likelihood models, so long as we overcome\na fundamental difficulty with probabilistic multi-scale models: the\nintractability of the likelihood function. Chiefly, in cascaded models each\nintermediary scale introduces extraneous variables that cannot be tractably\nmarginalized out for likelihood evaluation. This issue vanishes by modeling the\ndiffusion process on latent spaces induced by a class of transformations we\ncall hierarchical volume-preserving maps, which decompose spatially structured\ndata in a hierarchical fashion without introducing local distortions in the\nlatent space. We demonstrate that two such maps are well-known in the\nliterature for multiscale modeling: Laplacian pyramids and wavelet transforms.\nNot only do such reparameterizations allow the likelihood function to be\ndirectly expressed as a joint likelihood over the scales, we show that the\nLaplacian pyramid and wavelet transform also produces significant improvements\nto the state-of-the-art on a selection of benchmarks in likelihood modeling,\nincluding density estimation, lossless compression, and out-of-distribution\ndetection. Investigating the theoretical basis of our empirical gains we\nuncover deep connections to score matching under the Earth Mover's Distance\n(EMD), which is a well-known surrogate for perceptual similarity. Code can be\nfound at \\href{https://github.com/lihenryhfl/pcdm}{this https url}.",
      "tldr_zh": "本研究提出了一种通过分层体积保持映射(hierarchical volume-preserving maps)训练级联扩散模型(cascaded diffusion models)的方法，以解决多尺度模型中似然函数不可计算的问题。这些映射（如Laplacian pyramids和wavelet transforms）能层次化分解结构化数据，避免潜在空间的局部扭曲，从而使似然函数直接表达为尺度的联合似然。实验结果显示，该方法在密度估计、无损压缩和异常检测等基准上显著提升了现有最佳性能，并揭示了与Earth Mover's Distance(EMD)下的分数匹配的深层理论联系。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Spotlight at ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2501.06999v1",
      "published_date": "2025-01-13 01:20:23 UTC",
      "updated_date": "2025-01-13 01:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:13:08.690898"
    },
    {
      "arxiv_id": "2501.06994v1",
      "title": "Motion Tracks: A Unified Representation for Human-Robot Transfer in Few-Shot Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Juntao Ren",
        "Priya Sundaresan",
        "Dorsa Sadigh",
        "Sanjiban Choudhury",
        "Jeannette Bohg"
      ],
      "abstract": "Teaching robots to autonomously complete everyday tasks remains a challenge.\nImitation Learning (IL) is a powerful approach that imbues robots with skills\nvia demonstrations, but is limited by the labor-intensive process of collecting\nteleoperated robot data. Human videos offer a scalable alternative, but it\nremains difficult to directly train IL policies from them due to the lack of\nrobot action labels. To address this, we propose to represent actions as\nshort-horizon 2D trajectories on an image. These actions, or motion tracks,\ncapture the predicted direction of motion for either human hands or robot\nend-effectors. We instantiate an IL policy called Motion Track Policy (MT-pi)\nwhich receives image observations and outputs motion tracks as actions. By\nleveraging this unified, cross-embodiment action space, MT-pi completes tasks\nwith high success given just minutes of human video and limited additional\nrobot demonstrations. At test time, we predict motion tracks from two camera\nviews, recovering 6DoF trajectories via multi-view synthesis. MT-pi achieves an\naverage success rate of 86.5% across 4 real-world tasks, outperforming\nstate-of-the-art IL baselines which do not leverage human data or our action\nspace by 40%, and generalizes to scenarios seen only in human videos. Code and\nvideos are available on our website\nhttps://portal-cornell.github.io/motion_track_policy/.",
      "tldr_zh": "本文提出Motion Tracks，一种统一的动作表示方法，用于Few-Shot Imitation Learning中实现人类视频到机器人的知识转移，解决传统Imitation Learning (IL)因收集机器人数据繁琐而带来的挑战。Motion Track Policy (MT-pi)作为核心策略，接受图像观察并输出短时段2D轨迹，捕捉人类手或机器人末端执行器的运动方向，并在测试时通过多视图合成恢复6DoF轨迹。实验结果显示，MT-pi在4个真实任务上平均成功率达86.5%，比不使用人类数据或该动作空间的基线模型高出40%，并能泛化到仅在人类视频中出现的情景。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06994v1",
      "published_date": "2025-01-13 01:01:44 UTC",
      "updated_date": "2025-01-13 01:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:13:20.211090"
    },
    {
      "arxiv_id": "2501.06985v1",
      "title": "Graph Contrastive Learning on Multi-label Classification for Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Jiayang Wu",
        "Wensheng Gan",
        "Huashen Lu",
        "Philip S. Yu"
      ],
      "abstract": "In business analysis, providing effective recommendations is essential for\nenhancing company profits. The utilization of graph-based structures, such as\nbipartite graphs, has gained popularity for their ability to analyze complex\ndata relationships. Link prediction is crucial for recommending specific items\nto users. Traditional methods in this area often involve identifying patterns\nin the graph structure or using representational techniques like graph neural\nnetworks (GNNs). However, these approaches encounter difficulties as the volume\nof data increases. To address these challenges, we propose a model called Graph\nContrastive Learning for Multi-label Classification (MCGCL). MCGCL leverages\ncontrastive learning to enhance recommendation effectiveness. The model\nincorporates two training stages: a main task and a subtask. The main task is\nholistic user-item graph learning to capture user-item relationships. The\nhomogeneous user-user (item-item) subgraph is constructed to capture user-user\nand item-item relationships in the subtask. We assessed the performance using\nreal-world datasets from Amazon Reviews in multi-label classification tasks.\nComparative experiments with state-of-the-art methods confirm the effectiveness\nof MCGCL, highlighting its potential for improving recommendation systems.",
      "tldr_zh": "该论文针对推荐系统中的多标签分类问题，提出了一种基于图对比学习(Graph Contrastive Learning)的模型MCGCL，以解决传统方法如GNNs在处理大规模数据时遇到的挑战。MCGCL包括两个训练阶段：主任务通过整体用户-物品图学习捕捉用户-物品关系，子任务则构建同质用户-用户和物品-物品子图来增强关系建模。在Amazon Reviews的真实数据集上进行实验，结果显示MCGCL在多标签分类任务中优于现有最先进方法，提升了推荐系统的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Preprint. 10 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2501.06985v1",
      "published_date": "2025-01-13 00:29:29 UTC",
      "updated_date": "2025-01-13 00:29:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:13:31.358071"
    },
    {
      "arxiv_id": "2501.06981v1",
      "title": "Data Enrichment Work and AI Labor in Latin America and the Caribbean",
      "title_zh": "翻译失败",
      "authors": [
        "Gianna Williams",
        "Maya De Los Santos",
        "Alexandra To",
        "Saiph Savage"
      ],
      "abstract": "The global AI surge demands crowdworkers from diverse languages and cultures.\nThey are pivotal in labeling data for enabling global AI systems. Despite\nglobal significance, research has primarily focused on understanding the\nperspectives and experiences of US and India crowdworkers, leaving a notable\ngap. To bridge this, we conducted a survey with 100 crowdworkers across 16\nLatin American and Caribbean countries. We discovered that these workers\nexhibited pride and respect for their digital labor, with strong support and\nadmiration from their families. Notably, crowd work was also seen as a stepping\nstone to financial and professional independence. Surprisingly, despite wanting\nmore connection, these workers also felt isolated from peers and doubtful of\nothers' labor quality. They resisted collaboration and gender-based tools,\nvaluing gender-neutrality. Our work advances HCI understanding of Latin\nAmerican and Caribbean crowdwork, offering insights for digital resistance\ntools for the region.",
      "tldr_zh": "该研究调查了拉丁美洲和加勒比地区100名众包工人（crowworkers）在AI数据标记工作中的经历，填补了现有研究对该区域的忽视。调查发现，这些工人对他们的数字劳动感到自豪，并获得家庭的支持，将其视为实现财务和职业独立的途径；然而，他们也感受到与同行的隔离、对他人劳动质量的怀疑，并抵制合作和基于性别的工具，强调性别中立。总体而言，该工作推进了HCI（人机交互）领域对该地区AI劳动的理解，并为开发适合该区域的数字抵抗工具提供了宝贵见解。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "K.4; I.2"
      ],
      "primary_category": "cs.CY",
      "comment": "17 pages of content with 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2501.06981v1",
      "published_date": "2025-01-13 00:11:47 UTC",
      "updated_date": "2025-01-13 00:11:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:13:43.491885"
    },
    {
      "arxiv_id": "2501.06980v1",
      "title": "Combining LLM decision and RL action selection to improve RL policy for adaptive interventions",
      "title_zh": "结合 LLM 决策和 RL 动作选择以改进 RL 策略，用于自适应干预",
      "authors": [
        "Karine Karine",
        "Benjamin M. Marlin"
      ],
      "abstract": "Reinforcement learning (RL) is increasingly being used in the healthcare\ndomain, particularly for the development of personalized health adaptive\ninterventions. Inspired by the success of Large Language Models (LLMs), we are\ninterested in using LLMs to update the RL policy in real time, with the goal of\naccelerating personalization. We use the text-based user preference to\ninfluence the action selection on the fly, in order to immediately incorporate\nthe user preference. We use the term \"user preference\" as a broad term to refer\nto a user personal preference, constraint, health status, or a statement\nexpressing like or dislike, etc. Our novel approach is a hybrid method that\ncombines the LLM response and the RL action selection to improve the RL policy.\nGiven an LLM prompt that incorporates the user preference, the LLM acts as a\nfilter in the typical RL action selection. We investigate different prompting\nstrategies and action selection strategies. To evaluate our approach, we\nimplement a simulation environment that generates the text-based user\npreferences and models the constraints that impact behavioral dynamics. We show\nthat our approach is able to take into account the text-based user preferences,\nwhile improving the RL policy, thus improving personalization in adaptive\nintervention.",
      "tldr_zh": "本文提出一种混合方法，将大型语言模型 (LLMs) 与强化学习 (RL) 结合，用于实时更新 RL 策略，以加速健康适应性干预的个性化。方法中，LLM 作为过滤器，根据文本-based 用户偏好（如个人偏好、约束或健康状态）影响 RL 行动选择，并探索不同的提示和行动策略。实验结果显示，该方法在模拟环境中成功整合用户偏好，同时提升了 RL 策略的性能，从而提高了适应性干预的个性化水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2501.06980v1",
      "published_date": "2025-01-13 00:03:20 UTC",
      "updated_date": "2025-01-13 00:03:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-21T23:15:55.986493"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 83,
  "processed_papers_count": 83,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-21T23:16:15.126016"
}