[
  {
    "arxiv_id": "2501.07755v1",
    "title": "Performance Optimization of Ratings-Based Reinforcement Learning",
    "authors": [
      "Evelyn Rose",
      "Devin White",
      "Mingkang Wu",
      "Vernon Lawhern",
      "Nicholas R. Waytowich",
      "Yongcan Cao"
    ],
    "abstract": "This paper explores multiple optimization methods to improve the performance\nof rating-based reinforcement learning (RbRL). RbRL, a method based on the idea\nof human ratings, has been developed to infer reward functions in reward-free\nenvironments for the subsequent policy learning via standard reinforcement\nlearning, which requires the availability of reward functions. Specifically,\nRbRL minimizes the cross entropy loss that quantifies the differences between\nhuman ratings and estimated ratings derived from the inferred reward. Hence, a\nlow loss means a high degree of consistency between human ratings and estimated\nratings. Despite its simple form, RbRL has various hyperparameters and can be\nsensitive to various factors. Therefore, it is critical to provide\ncomprehensive experiments to understand the impact of various hyperparameters\non the performance of RbRL. This paper is a work in progress, providing users\nsome general guidelines on how to select hyperparameters in RbRL.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the Collaborative AI and Modeling of Humans Bridge\n  Program at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07755v1",
    "published_date": "2025-01-13 23:56:24 UTC",
    "updated_date": "2025-01-13 23:56:24 UTC"
  },
  {
    "arxiv_id": "2501.07751v2",
    "title": "Rethinking AI Cultural Alignment",
    "authors": [
      "Michal Bravansky",
      "Filip Trhlik",
      "Fazl Barez"
    ],
    "abstract": "As general-purpose artificial intelligence (AI) systems become increasingly\nintegrated with diverse human communities, cultural alignment has emerged as a\ncrucial element in their deployment. Most existing approaches treat cultural\nalignment as one-directional, embedding predefined cultural values from\nstandardized surveys and repositories into AI systems. To challenge this\nperspective, we highlight research showing that humans' cultural values must be\nunderstood within the context of specific AI systems. We then use a GPT-4o case\nstudy to demonstrate that AI systems' cultural alignment depends on how humans\nstructure their interactions with the system. Drawing on these findings, we\nargue that cultural alignment should be reframed as a bidirectional process:\nrather than merely imposing standardized values on AIs, we should query the\nhuman cultural values most relevant to each AI-based system and align it to\nthese values through interaction frameworks shaped by human users.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07751v2",
    "published_date": "2025-01-13 23:42:37 UTC",
    "updated_date": "2025-03-07 21:15:07 UTC"
  },
  {
    "arxiv_id": "2502.05181v1",
    "title": "Enhancing Team Diversity with Generative AI: A Novel Project Management Framework",
    "authors": [
      "Johnny Chan",
      "Yuming Li"
    ],
    "abstract": "This research-in-progress paper presents a new project management framework\nthat utilises GenAI technology. The framework is designed to address the common\nchallenge of uniform team compositions in academic and research project teams,\nparticularly in universities and research institutions. It does so by\nintegrating sociologically identified patterns of successful team member\npersonalities and roles, using GenAI agents to fill gaps in team dynamics. This\napproach adds an additional layer of analysis to conventional project\nmanagement processes by evaluating team members' personalities and roles and\nemploying GenAI agents, fine-tuned on personality datasets, to fill specific\nteam roles. Our initial experiments have shown improvements in the model's\nability to understand and process personality traits, suggesting the potential\neffectiveness of GenAI teammates in real-world project settings. This paper\naims to explore the practical application of AI in enhancing team diversity and\nproject management",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "A published version can be found from here -\n  https://www.computer.org/csdl/proceedings-article/compsac/2024/769600b648/1ZIUInSDC0w",
    "pdf_url": "http://arxiv.org/pdf/2502.05181v1",
    "published_date": "2025-01-13 21:39:06 UTC",
    "updated_date": "2025-01-13 21:39:06 UTC"
  },
  {
    "arxiv_id": "2501.07674v2",
    "title": "CDS: Data Synthesis Method Guided by Cognitive Diagnosis Theory",
    "authors": [
      "Haokun Zhao",
      "Jinyi Han",
      "Jiaqing Liang",
      "Yanghua Xiao"
    ],
    "abstract": "Large Language Models (LLMs) have achieved significant advancements, but the\nincreasing complexity of tasks and higher performance demands highlight the\nneed for continuous improvement. Some approaches utilize synthetic data\ngenerated by advanced LLMs based on evaluation results to train models.\nHowever, conventional evaluation methods fail to provide detailed, fine-grained\nprofiles of LLMs, limiting their guidance for data synthesis. In this paper, we\nintroduce the Cognitive Diagnostic Synthesis (CDS) method, which incorporates a\ndiagnostic process inspired by Cognitive Diagnosis Theory (CDT) to refine\nevaluation results and characterize model profiles at the knowledge component\nlevel. Based on these diagnostics, we propose two diagnosis-synthesis\nstrategies for weakness-targeted data synthesis. Additionally, we present an\nenhanced data augmentation and selection pipeline to improve the quality and\ndiversity of synthesized data. Our experiments with several open-source models\nshow significant improvements across multiple benchmarks, achieving up to 6.00%\nimprovement in code generation, 13.10% in mathematical reasoning, and 5.43% in\nacademic exams. Code and data are available on GitHub.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07674v2",
    "published_date": "2025-01-13 20:13:59 UTC",
    "updated_date": "2025-03-05 18:39:05 UTC"
  },
  {
    "arxiv_id": "2501.07653v2",
    "title": "Large Language Models for Interpretable Mental Health Diagnosis",
    "authors": [
      "Brian Hyeongseok Kim",
      "Chao Wang"
    ],
    "abstract": "We propose a clinical decision support system (CDSS) for mental health\ndiagnosis that combines the strengths of large language models (LLMs) and\nconstraint logic programming (CLP). Having a CDSS is important because of the\nhigh complexity of diagnostic manuals used by mental health professionals and\nthe danger of diagnostic errors. Our CDSS is a software tool that uses an LLM\nto translate diagnostic manuals to a logic program and solves the program using\nan off-the-shelf CLP engine to query a patient's diagnosis based on the encoded\nrules and provided data. By giving domain experts the opportunity to inspect\nthe LLM-generated logic program, and making modifications when needed, our CDSS\nensures that the diagnosis is not only accurate but also interpretable. We\nexperimentally compare it with two baseline approaches of using LLMs:\ndiagnosing patients using the LLM-only approach, and using the LLM-generated\nlogic program but without expert inspection. The results show that, while LLMs\nare extremely useful in generating candidate logic programs, these programs\nstill require expert inspection and modification to guarantee faithfulness to\nthe official diagnostic manuals. Additionally, ethical concerns arise from the\ndirect use of patient data in LLMs, underscoring the need for a safer hybrid\napproach like our proposed method.",
    "categories": [
      "cs.AI",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at AAAI 2025 Workshop on Large Language Models and\n  Generative AI for Health (GenAI4Health)",
    "pdf_url": "http://arxiv.org/pdf/2501.07653v2",
    "published_date": "2025-01-13 19:26:09 UTC",
    "updated_date": "2025-02-21 17:32:46 UTC"
  },
  {
    "arxiv_id": "2501.07647v1",
    "title": "BlobGEN-Vid: Compositional Text-to-Video Generation with Blob Video Representations",
    "authors": [
      "Weixi Feng",
      "Chao Liu",
      "Sifei Liu",
      "William Yang Wang",
      "Arash Vahdat",
      "Weili Nie"
    ],
    "abstract": "Existing video generation models struggle to follow complex text prompts and\nsynthesize multiple objects, raising the need for additional grounding input\nfor improved controllability. In this work, we propose to decompose videos into\nvisual primitives - blob video representation, a general representation for\ncontrollable video generation. Based on blob conditions, we develop a\nblob-grounded video diffusion model named BlobGEN-Vid that allows users to\ncontrol object motions and fine-grained object appearance. In particular, we\nintroduce a masked 3D attention module that effectively improves regional\nconsistency across frames. In addition, we introduce a learnable module to\ninterpolate text embeddings so that users can control semantics in specific\nframes and obtain smooth object transitions. We show that our framework is\nmodel-agnostic and build BlobGEN-Vid based on both U-Net and DiT-based video\ndiffusion models. Extensive experimental results show that BlobGEN-Vid achieves\nsuperior zero-shot video generation ability and state-of-the-art layout\ncontrollability on multiple benchmarks. When combined with an LLM for layout\nplanning, our framework even outperforms proprietary text-to-video generators\nin terms of compositional accuracy.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://blobgen-vid2.github.io/",
    "pdf_url": "http://arxiv.org/pdf/2501.07647v1",
    "published_date": "2025-01-13 19:17:06 UTC",
    "updated_date": "2025-01-13 19:17:06 UTC"
  },
  {
    "arxiv_id": "2501.07639v1",
    "title": "SafePowerGraph-LLM: Novel Power Grid Graph Embedding and Optimization with Large Language Models",
    "authors": [
      "Fabien Bernier",
      "Jun Cao",
      "Maxime Cordy",
      "Salah Ghamizi"
    ],
    "abstract": "Efficiently solving Optimal Power Flow (OPF) problems in power systems is\ncrucial for operational planning and grid management. There is a growing need\nfor scalable algorithms capable of handling the increasing variability,\nconstraints, and uncertainties in modern power networks while providing\naccurate and fast solutions. To address this, machine learning techniques,\nparticularly Graph Neural Networks (GNNs) have emerged as promising approaches.\nThis letter introduces SafePowerGraph-LLM, the first framework explicitly\ndesigned for solving OPF problems using Large Language Models (LLM)s. The\nproposed approach combines graph and tabular representations of power grids to\neffectively query LLMs, capturing the complex relationships and constraints in\npower systems. A new implementation of in-context learning and fine-tuning\nprotocols for LLMs is introduced, tailored specifically for the OPF problem.\nSafePowerGraph-LLM demonstrates reliable performances using off-the-shelf LLM.\nOur study reveals the impact of LLM architecture, size, and fine-tuning and\ndemonstrates our framework's ability to handle realistic grid components and\nconstraints.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07639v1",
    "published_date": "2025-01-13 19:01:58 UTC",
    "updated_date": "2025-01-13 19:01:58 UTC"
  },
  {
    "arxiv_id": "2501.07575v1",
    "title": "Dataset Distillation via Committee Voting",
    "authors": [
      "Jiacheng Cui",
      "Zhaoyi Li",
      "Xiaochen Ma",
      "Xinyue Bi",
      "Yaxin Luo",
      "Zhiqiang Shen"
    ],
    "abstract": "Dataset distillation aims to synthesize a smaller, representative dataset\nthat preserves the essential properties of the original data, enabling\nefficient model training with reduced computational resources. Prior work has\nprimarily focused on improving the alignment or matching process between\noriginal and synthetic data, or on enhancing the efficiency of distilling large\ndatasets. In this work, we introduce ${\\bf C}$ommittee ${\\bf V}$oting for ${\\bf\nD}$ataset ${\\bf D}$istillation (CV-DD), a novel and orthogonal approach that\nleverages the collective wisdom of multiple models or experts to create\nhigh-quality distilled datasets. We start by showing how to establish a strong\nbaseline that already achieves state-of-the-art accuracy through leveraging\nrecent advancements and thoughtful adjustments in model design and optimization\nprocesses. By integrating distributions and predictions from a committee of\nmodels while generating high-quality soft labels, our method captures a wider\nspectrum of data features, reduces model-specific biases and the adverse\neffects of distribution shifts, leading to significant improvements in\ngeneralization. This voting-based strategy not only promotes diversity and\nrobustness within the distilled dataset but also significantly reduces\noverfitting, resulting in improved performance on post-eval tasks. Extensive\nexperiments across various datasets and IPCs (images per class) demonstrate\nthat Committee Voting leads to more reliable and adaptable distilled data\ncompared to single/multi-model distillation methods, demonstrating its\npotential for efficient and accurate dataset distillation. Code is available\nat: https://github.com/Jiacheng8/CV-DD.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code at: https://github.com/Jiacheng8/CV-DD",
    "pdf_url": "http://arxiv.org/pdf/2501.07575v1",
    "published_date": "2025-01-13 18:59:48 UTC",
    "updated_date": "2025-01-13 18:59:48 UTC"
  },
  {
    "arxiv_id": "2501.07574v1",
    "title": "UnCommon Objects in 3D",
    "authors": [
      "Xingchen Liu",
      "Piyush Tayal",
      "Jianyuan Wang",
      "Jesus Zarzar",
      "Tom Monnier",
      "Konstantinos Tertikas",
      "Jiali Duan",
      "Antoine Toisoul",
      "Jason Y. Zhang",
      "Natalia Neverova",
      "Andrea Vedaldi",
      "Roman Shapovalov",
      "David Novotny"
    ],
    "abstract": "We introduce Uncommon Objects in 3D (uCO3D), a new object-centric dataset for\n3D deep learning and 3D generative AI. uCO3D is the largest publicly-available\ncollection of high-resolution videos of objects with 3D annotations that\nensures full-360$^{\\circ}$ coverage. uCO3D is significantly more diverse than\nMVImgNet and CO3Dv2, covering more than 1,000 object categories. It is also of\nhigher quality, due to extensive quality checks of both the collected videos\nand the 3D annotations. Similar to analogous datasets, uCO3D contains\nannotations for 3D camera poses, depth maps and sparse point clouds. In\naddition, each object is equipped with a caption and a 3D Gaussian Splat\nreconstruction. We train several large 3D models on MVImgNet, CO3Dv2, and uCO3D\nand obtain superior results using the latter, showing that uCO3D is better for\nlearning applications.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07574v1",
    "published_date": "2025-01-13 18:59:20 UTC",
    "updated_date": "2025-01-13 18:59:20 UTC"
  },
  {
    "arxiv_id": "2501.07572v2",
    "title": "WebWalker: Benchmarking LLMs in Web Traversal",
    "authors": [
      "Jialong Wu",
      "Wenbiao Yin",
      "Yong Jiang",
      "Zhenglin Wang",
      "Zekun Xi",
      "Runnan Fang",
      "Linhai Zhang",
      "Yulan He",
      "Deyu Zhou",
      "Pengjun Xie",
      "Fei Huang"
    ],
    "abstract": "Retrieval-augmented generation (RAG) demonstrates remarkable performance\nacross tasks in open-domain question-answering. However, traditional search\nengines may retrieve shallow content, limiting the ability of LLMs to handle\ncomplex, multi-layered information. To address it, we introduce WebWalkerQA, a\nbenchmark designed to assess the ability of LLMs to perform web traversal. It\nevaluates the capacity of LLMs to traverse a website's subpages to extract\nhigh-quality data systematically. We propose WebWalker, which is a multi-agent\nframework that mimics human-like web navigation through an explore-critic\nparadigm. Extensive experimental results show that WebWalkerQA is challenging\nand demonstrates the effectiveness of RAG combined with WebWalker, through the\nhorizontal and vertical integration in real-world scenarios.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07572v2",
    "published_date": "2025-01-13 18:58:07 UTC",
    "updated_date": "2025-01-14 15:06:56 UTC"
  },
  {
    "arxiv_id": "2501.07531v1",
    "title": "Evaluating Agent-based Program Repair at Google",
    "authors": [
      "Pat Rondon",
      "Renyao Wei",
      "José Cambronero",
      "Jürgen Cito",
      "Aaron Sun",
      "Siddhant Sanyam",
      "Michele Tufano",
      "Satish Chandra"
    ],
    "abstract": "Agent-based program repair offers to automatically resolve complex bugs\nend-to-end by combining the planning, tool use, and code generation abilities\nof modern LLMs. Recent work has explored the use of agent-based repair\napproaches on the popular open-source SWE-Bench, a collection of bugs from\nhighly-rated GitHub Python projects. In addition, various agentic approaches\nsuch as SWE-Agent have been proposed to solve bugs in this benchmark. This\npaper explores the viability of using an agentic approach to address bugs in an\nenterprise context. To investigate this, we curate an evaluation set of 178\nbugs drawn from Google's issue tracking system. This dataset spans both\nhuman-reported (78) and machine-reported bugs (100).\n  To establish a repair performance baseline on this benchmark, we implement\nPasserine, an agent similar in spirit to SWE-Agent that can work within\nGoogle's development environment. We show that with 20 trajectory samples and\nGemini 1.5 Pro, Passerine can produce a patch that passes bug tests (i.e.,\nplausible) for 73% of machine-reported and 25.6% of human-reported bugs in our\nevaluation set. After manual examination, we found that 43% of machine-reported\nbugs and 17.9% of human-reported bugs have at least one patch that is\nsemantically equivalent to the ground-truth patch.\n  These results establish a baseline on an industrially relevant benchmark,\nwhich as we show, contains bugs drawn from a different distribution -- in terms\nof language diversity, size, and spread of changes, etc. -- compared to those\nin the popular SWE-Bench dataset.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07531v1",
    "published_date": "2025-01-13 18:09:25 UTC",
    "updated_date": "2025-01-13 18:09:25 UTC"
  },
  {
    "arxiv_id": "2501.07525v1",
    "title": "RadAlign: Advancing Radiology Report Generation with Vision-Language Concept Alignment",
    "authors": [
      "Difei Gu",
      "Yunhe Gao",
      "Yang Zhou",
      "Mu Zhou",
      "Dimitris Metaxas"
    ],
    "abstract": "Automated chest radiographs interpretation requires both accurate disease\nclassification and detailed radiology report generation, presenting a\nsignificant challenge in the clinical workflow. Current approaches either focus\non classification accuracy at the expense of interpretability or generate\ndetailed but potentially unreliable reports through image captioning\ntechniques. In this study, we present RadAlign, a novel framework that combines\nthe predictive accuracy of vision-language models (VLMs) with the reasoning\ncapabilities of large language models (LLMs). Inspired by the radiologist's\nworkflow, RadAlign first employs a specialized VLM to align visual features\nwith key medical concepts, achieving superior disease classification with an\naverage AUC of 0.885 across multiple diseases. These recognized medical\nconditions, represented as text-based concepts in the aligned visual-language\nspace, are then used to prompt LLM-based report generation. Enhanced by a\nretrieval-augmented generation mechanism that grounds outputs in similar\nhistorical cases, RadAlign delivers superior report quality with a GREEN score\nof 0.678, outperforming state-of-the-art methods' 0.634. Our framework\nmaintains strong clinical interpretability while reducing hallucinations,\nadvancing automated medical imaging and report analysis through integrated\npredictive and generative AI. Code is available at\nhttps://github.com/difeigu/RadAlign.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07525v1",
    "published_date": "2025-01-13 17:55:32 UTC",
    "updated_date": "2025-01-13 17:55:32 UTC"
  },
  {
    "arxiv_id": "2501.07523v2",
    "title": "Parallel Key-Value Cache Fusion for Position Invariant RAG",
    "authors": [
      "Philhoon Oh",
      "Jinwoo Shin",
      "James Thorne"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) underscore the necessity\nof Retrieval Augmented Generation (RAG) to leverage external information.\nHowever, LLMs are sensitive to the position of relevant information within\ncontexts and tend to generate incorrect responses when such information is\nplaced in the middle, known as `Lost in the Middle' phenomenon. In this paper,\nwe introduce a framework that generates consistent outputs for decoder-only\nmodels, irrespective of the input context order. Experimental results for three\nopen domain question answering tasks demonstrate position invariance, where the\nmodel is not sensitive to input context order, and superior robustness to\nirrelevent passages compared to prevailing approaches for RAG pipelines.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "5 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07523v2",
    "published_date": "2025-01-13 17:50:30 UTC",
    "updated_date": "2025-01-23 06:48:22 UTC"
  },
  {
    "arxiv_id": "2501.07515v1",
    "title": "The Paradox of Success in Evolutionary and Bioinspired Optimization: Revisiting Critical Issues, Key Studies, and Methodological Pathways",
    "authors": [
      "Daniel Molina",
      "Javier Del Ser",
      "Javier Poyatos",
      "Francisco Herrera"
    ],
    "abstract": "Evolutionary and bioinspired computation are crucial for efficiently\naddressing complex optimization problems across diverse application domains. By\nmimicking processes observed in nature, like evolution itself, these algorithms\noffer innovative solutions beyond the reach of traditional optimization\nmethods. They excel at finding near-optimal solutions in large, complex search\nspaces, making them invaluable in numerous fields. However, both areas are\nplagued by challenges at their core, including inadequate benchmarking,\nproblem-specific overfitting, insufficient theoretical grounding, and\nsuperfluous proposals justified only by their biological metaphor. This\noverview recapitulates and analyzes in depth the criticisms concerning the lack\nof innovation and rigor in experimental studies within the field. To this end,\nwe examine the judgmental positions of the existing literature in an informed\nattempt to guide the research community toward directions of solid contribution\nand advancement in these areas. We summarize guidelines for the design of\nevolutionary and bioinspired optimizers, the development of experimental\ncomparisons, and the derivation of novel proposals that take a step further in\nthe field. We provide a brief note on automating the process of creating these\nalgorithms, which may help align metaheuristic optimization research with its\nprimary objective (solving real-world problems), provided that our identified\npathways are followed. Our conclusions underscore the need for a sustained push\ntowards innovation and the enforcement of methodological rigor in prospective\nstudies to fully realize the potential of these advanced computational\ntechniques.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "I.2.8; I.2"
    ],
    "primary_category": "cs.NE",
    "comment": "38 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2501.07515v1",
    "published_date": "2025-01-13 17:37:37 UTC",
    "updated_date": "2025-01-13 17:37:37 UTC"
  },
  {
    "arxiv_id": "2501.07507v1",
    "title": "Inductive Learning of Robot Task Knowledge from Raw Data and Online Expert Feedback",
    "authors": [
      "Daniele Meli",
      "Paolo Fiorini"
    ],
    "abstract": "The increasing level of autonomy of robots poses challenges of trust and\nsocial acceptance, especially in human-robot interaction scenarios. This\nrequires an interpretable implementation of robotic cognitive capabilities,\npossibly based on formal methods as logics for the definition of task\nspecifications. However, prior knowledge is often unavailable in complex\nrealistic scenarios.\n  In this paper, we propose an offline algorithm based on inductive logic\nprogramming from noisy examples to extract task specifications (i.e., action\npreconditions, constraints and effects) directly from raw data of few\nheterogeneous (i.e., not repetitive) robotic executions. Our algorithm\nleverages on the output of any unsupervised action identification algorithm\nfrom video-kinematic recordings. Combining it with the definition of very\nbasic, almost task-agnostic, commonsense concepts about the environment, which\ncontribute to the interpretability of our methodology, we are able to learn\nlogical axioms encoding preconditions of actions, as well as their effects in\nthe event calculus paradigm. Since the quality of learned specifications\ndepends mainly on the accuracy of the action identification algorithm, we also\npropose an online framework for incremental refinement of task knowledge from\nuser feedback, guaranteeing safe execution. Results in a standard manipulation\ntask and benchmark for user training in the safety-critical surgical robotic\nscenario, show the robustness, data- and time-efficiency of our methodology,\nwith promising results towards the scalability in more complex domains.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07507v1",
    "published_date": "2025-01-13 17:25:46 UTC",
    "updated_date": "2025-01-13 17:25:46 UTC"
  },
  {
    "arxiv_id": "2501.07502v1",
    "title": "RbRL2.0: Integrated Reward and Policy Learning for Rating-based Reinforcement Learning",
    "authors": [
      "Mingkang Wu",
      "Devin White",
      "Vernon Lawhern",
      "Nicholas R. Waytowich",
      "Yongcan Cao"
    ],
    "abstract": "Reinforcement learning (RL), a common tool in decision making, learns\npolicies from various experiences based on the associated cumulative\nreturn/rewards without treating them differently. On the contrary, humans often\nlearn to distinguish from different levels of performance and extract the\nunderlying trends towards improving their decision making for best performance.\nMotivated by this, this paper proposes a novel RL method that mimics humans'\ndecision making process by differentiating among collected experiences for\neffective policy learning. The main idea is to extract important directional\ninformation from experiences with different performance levels, named ratings,\nso that policies can be updated towards desired deviation from these\nexperiences with different ratings. Specifically, we propose a new policy loss\nfunction that penalizes distribution similarities between the current policy\nand failed experiences with different ratings, and assign different weights to\nthe penalty terms based on the rating classes. Meanwhile, reward learning from\nthese rated samples can be integrated with the new policy loss towards an\nintegrated reward and policy learning from rated samples. Optimizing the\nintegrated reward and policy loss function will lead to the discovery of\ndirections for policy improvement towards maximizing cumulative rewards and\npenalizing most from the lowest performance level while least from the highest\nperformance level. To evaluate the effectiveness of the proposed method, we\npresent results for experiments on a few typical environments that show\nimproved convergence and overall performance over the existing rating-based\nreinforcement learning method with only reward learning.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to the Collaborative AI and Modeling of Humans Bridge\n  Program at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07502v1",
    "published_date": "2025-01-13 17:19:34 UTC",
    "updated_date": "2025-01-13 17:19:34 UTC"
  },
  {
    "arxiv_id": "2501.07487v1",
    "title": "Data and System Perspectives of Sustainable Artificial Intelligence",
    "authors": [
      "Tao Xie",
      "David Harel",
      "Dezhi Ran",
      "Zhenwen Li",
      "Maoliang Li",
      "Zhi Yang",
      "Leye Wang",
      "Xiang Chen",
      "Ying Zhang",
      "Wentao Zhang",
      "Meng Li",
      "Chen Zhang",
      "Linyi Li",
      "Assaf Marron"
    ],
    "abstract": "Sustainable AI is a subfield of AI for concerning developing and using AI\nsystems in ways of aiming to reduce environmental impact and achieve\nsustainability. Sustainable AI is increasingly important given that training of\nand inference with AI models such as large langrage models are consuming a\nlarge amount of computing power. In this article, we discuss current issues,\nopportunities and example solutions for addressing these issues, and future\nchallenges to tackle, from the data and system perspectives, related to data\nacquisition, data processing, and AI model training and inference.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07487v1",
    "published_date": "2025-01-13 17:04:23 UTC",
    "updated_date": "2025-01-13 17:04:23 UTC"
  },
  {
    "arxiv_id": "2501.07486v1",
    "title": "Smart Learning in the 21st Century: Advancing Constructionism Across Three Digital Epochs",
    "authors": [
      "Ilya Levin",
      "Alexei L. Semenov",
      "Mikael Gorsky"
    ],
    "abstract": "This article explores the evolution of constructionism as an educational\nframework, tracing its relevance and transformation across three pivotal eras:\nthe advent of personal computing, the networked society, and the current era of\ngenerative AI. Rooted in Seymour Papert constructionist philosophy, this study\nexamines how constructionist principles align with the expanding role of\ndigital technology in personal and collective learning. We discuss the\ntransformation of educational environments from hierarchical instructionism to\nconstructionist models that emphasize learner autonomy and interactive,\ncreative engagement. Central to this analysis is the concept of an expanded\npersonality, wherein digital tools and AI integration fundamentally reshape\nindividual self-perception and social interactions. By integrating\nconstructionism into the paradigm of smart education, we propose it as a\nfoundational approach to personalized and democratized learning. Our findings\nunderscore constructionism enduring relevance in navigating the complexities of\ntechnology-driven education, providing insights for educators and policymakers\nseeking to harness digital innovations to foster adaptive, student-centered\nlearning experiences.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "22 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07486v1",
    "published_date": "2025-01-13 17:04:06 UTC",
    "updated_date": "2025-01-13 17:04:06 UTC"
  },
  {
    "arxiv_id": "2501.07482v2",
    "title": "TiEBe: Tracking Language Model Recall of Notable Worldwide Events Through Time",
    "authors": [
      "Thales Sales Almeida",
      "Giovana Kerche Bonás",
      "João Guilherme Alves Santos",
      "Hugo Abonizio",
      "Rodrigo Nogueira"
    ],
    "abstract": "As the knowledge landscape evolves and large language models (LLMs) become\nincreasingly widespread, there is a growing need to keep these models updated\nwith current events. While existing benchmarks assess general factual recall,\nfew studies explore how LLMs retain knowledge over time or across different\nregions. To address these gaps, we present the Timely Events Benchmark (TiEBe),\na dataset of over 23,000 question-answer pairs centered on notable global and\nregional events, spanning more than 10 years of events, 23 regions, and 13\nlanguages. TiEBe leverages structured retrospective data from Wikipedia to\nidentify notable events through time. These events are then used to construct a\nbenchmark to evaluate LLMs' understanding of global and regional developments,\ngrounded in factual evidence beyond Wikipedia itself. Our results reveal\nsignificant geographic disparities in factual recall, emphasizing the need for\nmore balanced global representation in LLM training. We also observe a Pearson\ncorrelation of more than 0.7 between models' performance in TiEBe and various\ncountries' socioeconomic indicators, such as HDI. In addition, we examine the\nimpact of language on factual recall by posing questions in the native language\nof the region where each event occurred, uncovering substantial performance\ngaps for low-resource languages.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07482v2",
    "published_date": "2025-01-13 16:58:32 UTC",
    "updated_date": "2025-05-20 17:09:53 UTC"
  },
  {
    "arxiv_id": "2501.07474v1",
    "title": "Estimating Musical Surprisal in Audio",
    "authors": [
      "Mathias Rose Bjare",
      "Giorgia Cantisani",
      "Stefan Lattner",
      "Gerhard Widmer"
    ],
    "abstract": "In modeling musical surprisal expectancy with computational methods, it has\nbeen proposed to use the information content (IC) of one-step predictions from\nan autoregressive model as a proxy for surprisal in symbolic music. With an\nappropriately chosen model, the IC of musical events has been shown to\ncorrelate with human perception of surprise and complexity aspects, including\ntonal and rhythmic complexity. This work investigates whether an analogous\nmethodology can be applied to music audio. We train an autoregressive\nTransformer model to predict compressed latent audio representations of a\npretrained autoencoder network. We verify learning effects by estimating the\ndecrease in IC with repetitions. We investigate the mean IC of musical segment\ntypes (e.g., A or B) and find that segment types appearing later in a piece\nhave a higher IC than earlier ones on average. We investigate the IC's relation\nto audio and musical features and find it correlated with timbral variations\nand loudness and, to a lesser extent, dissonance, rhythmic complexity, and\nonset density related to audio and musical features. Finally, we investigate if\nthe IC can predict EEG responses to songs and thus model humans' surprisal in\nmusic. We provide code for our method on github.com/sonycslparis/audioic.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "5 pages, 2 figures, 1 table. Accepted at the 2025 IEEE International\n  Conference on Acoustics, Speech and Signal Processing (ICASSP 2025),\n  Hyderabad, India",
    "pdf_url": "http://arxiv.org/pdf/2501.07474v1",
    "published_date": "2025-01-13 16:46:45 UTC",
    "updated_date": "2025-01-13 16:46:45 UTC"
  },
  {
    "arxiv_id": "2501.07468v3",
    "title": "From Screens to Scenes: A Survey of Embodied AI in Healthcare",
    "authors": [
      "Yihao Liu",
      "Xu Cao",
      "Tingting Chen",
      "Yankai Jiang",
      "Junjie You",
      "Minghua Wu",
      "Xiaosong Wang",
      "Mengling Feng",
      "Yaochu Jin",
      "Jintai Chen"
    ],
    "abstract": "Healthcare systems worldwide face persistent challenges in efficiency,\naccessibility, and personalization. Powered by modern AI technologies such as\nmultimodal large language models and world models, Embodied AI (EmAI)\nrepresents a transformative frontier, offering enhanced autonomy and the\nability to interact with the physical world to address these challenges. As an\ninterdisciplinary and rapidly evolving research domain, \"EmAI in healthcare\"\nspans diverse fields such as algorithms, robotics, and biomedicine. This\ncomplexity underscores the importance of timely reviews and analyses to track\nadvancements, address challenges, and foster cross-disciplinary collaboration.\nIn this paper, we provide a comprehensive overview of the \"brain\" of EmAI for\nhealthcare, wherein we introduce foundational AI algorithms for perception,\nactuation, planning, and memory, and focus on presenting the healthcare\napplications spanning clinical interventions, daily care & companionship,\ninfrastructure support, and biomedical research. Despite its promise, the\ndevelopment of EmAI for healthcare is hindered by critical challenges such as\nsafety concerns, gaps between simulation platforms and real-world applications,\nthe absence of standardized benchmarks, and uneven progress across\ninterdisciplinary domains. We discuss the technical barriers and explore\nethical considerations, offering a forward-looking perspective on the future of\nEmAI in healthcare. A hierarchical framework of intelligent levels for EmAI\nsystems is also introduced to guide further development. By providing\nsystematic insights, this work aims to inspire innovation and practical\napplications, paving the way for a new era of intelligent, patient-centered\nhealthcare.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "56 pages, 11 figures, manuscript accepted by Information Fusion",
    "pdf_url": "http://arxiv.org/pdf/2501.07468v3",
    "published_date": "2025-01-13 16:35:52 UTC",
    "updated_date": "2025-03-02 16:57:11 UTC"
  },
  {
    "arxiv_id": "2501.07458v1",
    "title": "Understanding and Benchmarking Artificial Intelligence: OpenAI's o3 Is Not AGI",
    "authors": [
      "Rolf Pfister",
      "Hansueli Jud"
    ],
    "abstract": "OpenAI's o3 achieves a high score of 87.5 % on ARC-AGI, a benchmark proposed\nto measure intelligence. This raises the question whether systems based on\nLarge Language Models (LLMs), particularly o3, demonstrate intelligence and\nprogress towards artificial general intelligence (AGI). Building on the\ndistinction between skills and intelligence made by Fran\\c{c}ois Chollet, the\ncreator of ARC-AGI, a new understanding of intelligence is introduced: an agent\nis the more intelligent, the more efficiently it can achieve the more diverse\ngoals in the more diverse worlds with the less knowledge. An analysis of the\nARC-AGI benchmark shows that its tasks represent a very specific type of\nproblem that can be solved by massive trialling of combinations of predefined\noperations. This method is also applied by o3, achieving its high score through\nthe extensive use of computing power. However, for most problems in the\nphysical world and in the human domain, solutions cannot be tested in advance\nand predefined operations are not available. Consequently, massive trialling of\npredefined operations, as o3 does, cannot be a basis for AGI - instead, new\napproaches are required that can reliably solve a wide variety of problems\nwithout existing skills. To support this development, a new benchmark for\nintelligence is outlined that covers a much higher diversity of unknown tasks\nto be solved, thus enabling a comprehensive assessment of intelligence and of\nprogress towards AGI.",
    "categories": [
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07458v1",
    "published_date": "2025-01-13 16:28:01 UTC",
    "updated_date": "2025-01-13 16:28:01 UTC"
  },
  {
    "arxiv_id": "2501.07445v1",
    "title": "Online inductive learning from answer sets for efficient reinforcement learning exploration",
    "authors": [
      "Celeste Veronese",
      "Daniele Meli",
      "Alessandro Farinelli"
    ],
    "abstract": "This paper presents a novel approach combining inductive logic programming\nwith reinforcement learning to improve training performance and explainability.\nWe exploit inductive learning of answer set programs from noisy examples to\nlearn a set of logical rules representing an explainable approximation of the\nagent policy at each batch of experience. We then perform answer set reasoning\non the learned rules to guide the exploration of the learning agent at the next\nbatch, without requiring inefficient reward shaping and preserving optimality\nwith soft bias. The entire procedure is conducted during the online execution\nof the reinforcement learning algorithm. We preliminarily validate the efficacy\nof our approach by integrating it into the Q-learning algorithm for the Pac-Man\nscenario in two maps of increasing complexity. Our methodology produces a\nsignificant boost in the discounted return achieved by the agent, even in the\nfirst batches of training. Moreover, inductive learning does not compromise the\ncomputational time required by Q-learning and learned rules quickly converge to\nan explanation of the agent policy.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07445v1",
    "published_date": "2025-01-13 16:13:22 UTC",
    "updated_date": "2025-01-13 16:13:22 UTC"
  },
  {
    "arxiv_id": "2501.07440v2",
    "title": "Attention when you need",
    "authors": [
      "Lokesh Boominathan",
      "Yizhou Chen",
      "Matthew McGinley",
      "Xaq Pitkow"
    ],
    "abstract": "Being attentive to task-relevant features can improve task performance, but\npaying attention comes with its own metabolic cost. Therefore, strategic\nallocation of attention is crucial in performing the task efficiently. This\nwork aims to understand this strategy. Recently, de Gee et al. conducted\nexperiments involving mice performing an auditory sustained attention-value\ntask. This task required the mice to exert attention to identify whether a\nhigh-order acoustic feature was present amid the noise. By varying the trial\nduration and reward magnitude, the task allows us to investigate how an agent\nshould strategically deploy their attention to maximize their benefits and\nminimize their costs. In our work, we develop a reinforcement learning-based\nnormative model of the mice to understand how it balances attention cost\nagainst its benefits. The model is such that at each moment the mice can choose\nbetween two levels of attention and decide when to take costly actions that\ncould obtain rewards. Our model suggests that efficient use of attentional\nresources involves alternating blocks of high attention with blocks of low\nattention. In the extreme case where the agent disregards sensory input during\nlow attention states, we see that high attention is used rhythmically. Our\nmodel provides evidence about how one should deploy attention as a function of\ntask utility, signal statistics, and how attention affects sensory evidence.",
    "categories": [
      "q-bio.NC",
      "cs.AI"
    ],
    "primary_category": "q-bio.NC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07440v2",
    "published_date": "2025-01-13 16:08:47 UTC",
    "updated_date": "2025-01-29 16:04:17 UTC"
  },
  {
    "arxiv_id": "2501.07432v1",
    "title": "Empirical Evaluation of the Implicit Hitting Set Approach for Weighted CSPs",
    "authors": [
      "Aleksandra Petrova",
      "Javier Larrosa",
      "Emma Rollón"
    ],
    "abstract": "SAT technology has proven to be surprisingly effective in a large variety of\ndomains. However, for the Weighted CSP problem dedicated algorithms have always\nbeen superior. One approach not well-studied so far is the use of SAT in\nconjunction with the Implicit Hitting Set approach. In this work, we explore\nsome alternatives to the existing algorithm of reference. The alternatives,\nmostly borrowed from related boolean frameworks, consider trade-offs for the\ntwo main components of the IHS approach: the computation of low-cost hitting\nvectors, and their transformation into high-cost cores. For each one, we\npropose 4 levels of intensity. Since we also test the usefulness of cost\nfunction merging, our experiments consider 32 different implementations. Our\nempirical study shows that for WCSP it is not easy to identify the best\nalternative. Nevertheless, the cost-function merging encoding and extracting\nmaximal cores seems to be a robust approach.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07432v1",
    "published_date": "2025-01-13 15:59:28 UTC",
    "updated_date": "2025-01-13 15:59:28 UTC"
  },
  {
    "arxiv_id": "2501.07430v2",
    "title": "Introducing 3D Representation for Medical Image Volume-to-Volume Translation via Score Fusion",
    "authors": [
      "Xiyue Zhu",
      "Dou Hoon Kwark",
      "Ruike Zhu",
      "Kaiwen Hong",
      "Yiqi Tao",
      "Shirui Luo",
      "Yudu Li",
      "Zhi-Pei Liang",
      "Volodymyr Kindratenko"
    ],
    "abstract": "In volume-to-volume translations in medical images, existing models often\nstruggle to capture the inherent volumetric distribution using 3D voxelspace\nrepresentations, due to high computational dataset demands. We present\nScore-Fusion, a novel volumetric translation model that effectively learns 3D\nrepresentations by ensembling perpendicularly trained 2D diffusion models in\nscore function space. By carefully initializing our model to start with an\naverage of 2D models as in TPDM, we reduce 3D training to a fine-tuning process\nand thereby mitigate both computational and data demands. Furthermore, we\nexplicitly design the 3D model's hierarchical layers to learn ensembles of 2D\nfeatures, further enhancing efficiency and performance. Moreover, Score-Fusion\nnaturally extends to multi-modality settings, by fusing diffusion models\nconditioned on different inputs for flexible, accurate integration. We\ndemonstrate that 3D representation is essential for better performance in\ndownstream recognition tasks, such as tumor segmentation, where most\nsegmentation models are based on 3D representation. Extensive experiments\ndemonstrate that Score-Fusion achieves superior accuracy and volumetric\nfidelity in 3D medical image super-resolution and modality translation. Beyond\nthese improvements, our work also provides broader insight into learning-based\napproaches for score function fusion.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07430v2",
    "published_date": "2025-01-13 15:54:21 UTC",
    "updated_date": "2025-02-06 20:31:27 UTC"
  },
  {
    "arxiv_id": "2501.07423v1",
    "title": "An Investigation into Seasonal Variations in Energy Forecasting for Student Residences",
    "authors": [
      "Muhammad Umair Danish",
      "Mathumitha Sureshkumar",
      "Thanuri Fonseka",
      "Umeshika Uthayakumar",
      "Vinura Galwaduge"
    ],
    "abstract": "This research provides an in-depth evaluation of various machine learning\nmodels for energy forecasting, focusing on the unique challenges of seasonal\nvariations in student residential settings. The study assesses the performance\nof baseline models, such as LSTM and GRU, alongside state-of-the-art\nforecasting methods, including Autoregressive Feedforward Neural Networks,\nTransformers, and hybrid approaches. Special attention is given to predicting\nenergy consumption amidst challenges like seasonal patterns, vacations,\nmeteorological changes, and irregular human activities that cause sudden\nfluctuations in usage. The findings reveal that no single model consistently\noutperforms others across all seasons, emphasizing the need for season-specific\nmodel selection or tailored designs. Notably, the proposed Hyper Network based\nLSTM and MiniAutoEncXGBoost models exhibit strong adaptability to seasonal\nvariations, effectively capturing abrupt changes in energy consumption during\nsummer months. This study advances the energy forecasting field by emphasizing\nthe critical role of seasonal dynamics and model-specific behavior in achieving\naccurate predictions.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07423v1",
    "published_date": "2025-01-13 15:43:22 UTC",
    "updated_date": "2025-01-13 15:43:22 UTC"
  },
  {
    "arxiv_id": "2501.07408v1",
    "title": "Initial Findings on Sensor based Open Vocabulary Activity Recognition via Text Embedding Inversion",
    "authors": [
      "Lala Shakti Swarup Ray",
      "Bo Zhou",
      "Sungho Suh",
      "Paul Lukowicz"
    ],
    "abstract": "Conventional human activity recognition (HAR) relies on classifiers trained\nto predict discrete activity classes, inherently limiting recognition to\nactivities explicitly present in the training set. Such classifiers would\ninvariably fail, putting zero likelihood, when encountering unseen activities.\nWe propose Open Vocabulary HAR (OV-HAR), a framework that overcomes this\nlimitation by first converting each activity into natural language and breaking\nit into a sequence of elementary motions. This descriptive text is then encoded\ninto a fixed-size embedding. The model is trained to regress this embedding,\nwhich is subsequently decoded back into natural language using a pre-trained\nembedding inversion model. Unlike other works that rely on auto-regressive\nlarge language models (LLMs) at their core, OV-HAR achieves open vocabulary\nrecognition without the computational overhead of such models. The generated\ntext can be transformed into a single activity class using LLM prompt\nengineering. We have evaluated our approach on different modalities, including\nvision (pose), IMU, and pressure sensors, demonstrating robust generalization\nacross unseen activities and modalities, offering a fundamentally different\nparadigm from contemporary classifiers.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07408v1",
    "published_date": "2025-01-13 15:24:10 UTC",
    "updated_date": "2025-01-13 15:24:10 UTC"
  },
  {
    "arxiv_id": "2501.07405v1",
    "title": "PROTECT: Protein circadian time prediction using unsupervised learning",
    "authors": [
      "Aram Ansary Ogholbake",
      "Qiang Cheng"
    ],
    "abstract": "Circadian rhythms regulate the physiology and behavior of humans and animals.\nDespite advancements in understanding these rhythms and predicting circadian\nphases at the transcriptional level, predicting circadian phases from proteomic\ndata remains elusive. This challenge is largely due to the scarcity of time\nlabels in proteomic datasets, which are often characterized by small sample\nsizes, high dimensionality, and significant noise. Furthermore, existing\nmethods for predicting circadian phases from transcriptomic data typically rely\non prior knowledge of known rhythmic genes, making them unsuitable for\nproteomic datasets. To address this gap, we developed a novel computational\nmethod using unsupervised deep learning techniques to predict circadian sample\nphases from proteomic data without requiring time labels or prior knowledge of\nproteins or genes. Our model involves a two-stage training process optimized\nfor robust circadian phase prediction: an initial greedy one-layer-at-a-time\npre-training which generates informative initial parameters followed by\nfine-tuning. During fine-tuning, a specialized loss function guides the model\nto align protein expression levels with circadian patterns, enabling it to\naccurately capture the underlying rhythmic structure within the data. We tested\nour method on both time-labeled and unlabeled proteomic data. For labeled data,\nwe compared our predictions to the known time labels, achieving high accuracy,\nwhile for unlabeled human datasets, including postmortem brain regions and\nurine samples, we explored circadian disruptions. Notably, our analysis\nidentified disruptions in rhythmic proteins between Alzheimer's disease and\ncontrol subjects across these samples.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07405v1",
    "published_date": "2025-01-13 15:21:20 UTC",
    "updated_date": "2025-01-13 15:21:20 UTC"
  },
  {
    "arxiv_id": "2501.07400v1",
    "title": "Derivation of effective gradient flow equations and dynamical truncation of training data in Deep Learning",
    "authors": [
      "Thomas Chen"
    ],
    "abstract": "We derive explicit equations governing the cumulative biases and weights in\nDeep Learning with ReLU activation function, based on gradient descent for the\nEuclidean cost in the input layer, and under the assumption that the weights\nare, in a precise sense, adapted to the coordinate system distinguished by the\nactivations. We show that gradient descent corresponds to a dynamical process\nin the input layer, whereby clusters of data are progressively reduced in\ncomplexity (\"truncated\") at an exponential rate that increases with the number\nof data points that have already been truncated. We provide a detailed\ndiscussion of several types of solutions to the gradient flow equations. A main\nmotivation for this work is to shed light on the interpretability question in\nsupervised learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.AP",
      "math.OC",
      "stat.ML",
      "57R70, 62M45"
    ],
    "primary_category": "cs.LG",
    "comment": "AMS Latex, 35 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07400v1",
    "published_date": "2025-01-13 15:17:28 UTC",
    "updated_date": "2025-01-13 15:17:28 UTC"
  },
  {
    "arxiv_id": "2501.07392v1",
    "title": "The Essentials of AI for Life and Society: An AI Literacy Course for the University Community",
    "authors": [
      "Joydeep Biswas",
      "Don Fussell",
      "Peter Stone",
      "Kristin Patterson",
      "Kristen Procko",
      "Lea Sabatini",
      "Zifan Xu"
    ],
    "abstract": "We describe the development of a one-credit course to promote AI literacy at\nThe University of Texas at Austin. In response to a call for the rapid\ndeployment of class to serve a broad audience in Fall of 2023, we designed a\n14-week seminar-style course that incorporated an interdisciplinary group of\nspeakers who lectured on topics ranging from the fundamentals of AI to societal\nconcerns including disinformation and employment. University students, faculty,\nand staff, and even community members outside of the University, were invited\nto enroll in this online offering: The Essentials of AI for Life and Society.\nWe collected feedback from course participants through weekly reflections and a\nfinal survey. Satisfyingly, we found that attendees reported gains in their AI\nliteracy. We sought critical feedback through quantitative and qualitative\nanalysis, which uncovered challenges in designing a course for this general\naudience. We utilized the course feedback to design a three-credit version of\nthe course that is being offered in Fall of 2024. The lessons we learned and\nour plans for this new iteration may serve as a guide to instructors designing\nAI courses for a broad audience.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to EAAI-25: The 15th Symposium on Educational Advances in\n  Artificial Intelligence, collocated with AAAI-25",
    "pdf_url": "http://arxiv.org/pdf/2501.07392v1",
    "published_date": "2025-01-13 15:08:32 UTC",
    "updated_date": "2025-01-13 15:08:32 UTC"
  },
  {
    "arxiv_id": "2501.07391v1",
    "title": "Enhancing Retrieval-Augmented Generation: A Study of Best Practices",
    "authors": [
      "Siran Li",
      "Linus Stenzel",
      "Carsten Eickhoff",
      "Seyed Ali Bahrainian"
    ],
    "abstract": "Retrieval-Augmented Generation (RAG) systems have recently shown remarkable\nadvancements by integrating retrieval mechanisms into language models,\nenhancing their ability to produce more accurate and contextually relevant\nresponses. However, the influence of various components and configurations\nwithin RAG systems remains underexplored. A comprehensive understanding of\nthese elements is essential for tailoring RAG systems to complex retrieval\ntasks and ensuring optimal performance across diverse applications. In this\npaper, we develop several advanced RAG system designs that incorporate query\nexpansion, various novel retrieval strategies, and a novel Contrastive\nIn-Context Learning RAG. Our study systematically investigates key factors,\nincluding language model size, prompt design, document chunk size, knowledge\nbase size, retrieval stride, query expansion techniques, Contrastive In-Context\nLearning knowledge bases, multilingual knowledge bases, and Focus Mode\nretrieving relevant context at sentence-level. Through extensive\nexperimentation, we provide a detailed analysis of how these factors influence\nresponse quality. Our findings offer actionable insights for developing RAG\nsystems, striking a balance between contextual richness and\nretrieval-generation efficiency, thereby paving the way for more adaptable and\nhigh-performing RAG frameworks in diverse real-world scenarios. Our code and\nimplementation details are publicly available.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07391v1",
    "published_date": "2025-01-13 15:07:55 UTC",
    "updated_date": "2025-01-13 15:07:55 UTC"
  },
  {
    "arxiv_id": "2501.07382v1",
    "title": "Information-Theoretic Dual Memory System for Continual Learning",
    "authors": [
      "RunQing Wu",
      "KaiHui Huang",
      "HanYi Zhang",
      "QiHe Liu",
      "GuoJin Yu",
      "JingSong Deng",
      "Fei Ye"
    ],
    "abstract": "Continuously acquiring new knowledge from a dynamic environment is a\nfundamental capability for animals, facilitating their survival and ability to\naddress various challenges. This capability is referred to as continual\nlearning, which focuses on the ability to learn a sequence of tasks without the\ndetriment of previous knowledge. A prevalent strategy to tackle continual\nlearning involves selecting and storing numerous essential data samples from\nprior tasks within a fixed-size memory buffer. However, the majority of current\nmemory-based techniques typically utilize a single memory buffer, which poses\nchallenges in concurrently managing newly acquired and previously learned\nsamples. Drawing inspiration from the Complementary Learning Systems (CLS)\ntheory, which defines rapid and gradual learning mechanisms for processing\ninformation, we propose an innovative dual memory system called the\nInformation-Theoretic Dual Memory System (ITDMS). This system comprises a fast\nmemory buffer designed to retain temporary and novel samples, alongside a slow\nmemory buffer dedicated to preserving critical and informative samples. The\nfast memory buffer is optimized employing an efficient reservoir sampling\nprocess. Furthermore, we introduce a novel information-theoretic memory\noptimization strategy that selectively identifies and retains diverse and\ninformative data samples for the slow memory buffer. Additionally, we propose a\nnovel balanced sample selection procedure that automatically identifies and\neliminates redundant memorized samples, thus freeing up memory capacity for new\ndata acquisitions, which can deal with a growing array of tasks. Our\nmethodology is rigorously assessed through a series of continual learning\nexperiments, with empirical results underscoring the effectiveness of the\nproposed system.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "35 pages, 9 figures, submitted to Knowledge-Based Systems",
    "pdf_url": "http://arxiv.org/pdf/2501.07382v1",
    "published_date": "2025-01-13 15:01:12 UTC",
    "updated_date": "2025-01-13 15:01:12 UTC"
  },
  {
    "arxiv_id": "2501.07359v1",
    "title": "Emergent effects of scaling on the functional hierarchies within large language models",
    "authors": [
      "Paul C. Bogdan"
    ],
    "abstract": "Large language model (LLM) architectures are often described as functionally\nhierarchical: Early layers process syntax, middle layers begin to parse\nsemantics, and late layers integrate information. The present work revisits\nthese ideas. This research submits simple texts to an LLM (e.g., \"A church and\norgan\") and extracts the resulting activations. Then, for each layer, support\nvector machines and ridge regressions are fit to predict a text's label and\nthus examine whether a given layer encodes some information. Analyses using a\nsmall model (Llama-3.2-3b; 28 layers) partly bolster the common hierarchical\nperspective: Item-level semantics are most strongly represented early (layers\n2-7), then two-item relations (layers 8-12), and then four-item analogies\n(layers 10-15). Afterward, the representation of items and simple relations\ngradually decreases in deeper layers that focus on more global information.\nHowever, several findings run counter to a steady hierarchy view: First,\nalthough deep layers can represent document-wide abstractions, deep layers also\ncompress information from early portions of the context window without\nmeaningful abstraction. Second, when examining a larger model\n(Llama-3.3-70b-Instruct), stark fluctuations in abstraction level appear: As\ndepth increases, two-item relations and four-item analogies initially increase\nin their representation, then markedly decrease, and afterward increase again\nmomentarily. This peculiar pattern consistently emerges across several\nexperiments. Third, another emergent effect of scaling is coordination between\nthe attention mechanisms of adjacent layers. Across multiple experiments using\nthe larger model, adjacent layers fluctuate between what information they each\nspecialize in representing. In sum, an abstraction hierarchy often manifests\nacross layers, but large models also deviate from this structure in curious\nways.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07359v1",
    "published_date": "2025-01-13 14:27:39 UTC",
    "updated_date": "2025-01-13 14:27:39 UTC"
  },
  {
    "arxiv_id": "2501.07335v2",
    "title": "TempoGPT: Enhancing Time Series Reasoning via Quantizing Embedding",
    "authors": [
      "Haochuan Zhang",
      "Chunhua Yang",
      "Jie Han",
      "Liyang Qin",
      "Xiaoli Wang"
    ],
    "abstract": "Multi-modal language model has made advanced progress in vision and audio,\nbut still faces significant challenges in dealing with complex reasoning tasks\nin the time series domain. The reasons are twofold. First, labels for\nmulti-modal time series data are coarse and devoid of analysis or reasoning\nprocesses. Training with these data cannot improve the model's reasoning\ncapabilities. Second, due to the lack of precise tokenization in processing\ntime series, the representation patterns for temporal and textual information\nare inconsistent, which hampers the effectiveness of multi-modal alignment. To\naddress these challenges, we propose a multi-modal time series data\nconstruction approach and a multi-modal time series language model (TLM),\nTempoGPT. Specially, we construct multi-modal data for complex reasoning tasks\nby analyzing the variable-system relationships within a white-box system.\nAdditionally, proposed TempoGPT achieves consistent representation between\ntemporal and textual information by quantizing temporal embeddings, where\ntemporal embeddings are quantized into a series of discrete tokens using a\npredefined codebook; subsequently, a shared embedding layer processes both\ntemporal and textual tokens. Extensive experiments demonstrate that TempoGPT\naccurately perceives temporal information, logically infers conclusions, and\nachieves state-of-the-art in the constructed complex time series reasoning\ntasks. Moreover, we quantitatively demonstrate the effectiveness of quantizing\ntemporal embeddings in enhancing multi-modal alignment and the reasoning\ncapabilities of TLMs. Code and data are available at\nhttps://github.com/zhanghaochuan20/TempoGPT.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07335v2",
    "published_date": "2025-01-13 13:47:05 UTC",
    "updated_date": "2025-03-07 01:43:30 UTC"
  },
  {
    "arxiv_id": "2501.07334v1",
    "title": "Anonymization of Documents for Law Enforcement with Machine Learning",
    "authors": [
      "Manuel Eberhardinger",
      "Patrick Takenaka",
      "Daniel Grießhaber",
      "Johannes Maucher"
    ],
    "abstract": "The steadily increasing utilization of data-driven methods and approaches in\nareas that handle sensitive personal information such as in law enforcement\nmandates an ever increasing effort in these institutions to comply with data\nprotection guidelines. In this work, we present a system for automatically\nanonymizing images of scanned documents, reducing manual effort while ensuring\ndata protection compliance. Our method considers the viability of further\nforensic processing after anonymization by minimizing automatically redacted\nareas by combining automatic detection of sensitive regions with knowledge from\na manually anonymized reference document. Using a self-supervised image model\nfor instance retrieval of the reference document, our approach requires only\none anonymized example to efficiently redact all documents of the same type,\nsignificantly reducing processing time. We show that our approach outperforms\nboth a purely automatic redaction system and also a naive copy-paste scheme of\nthe reference anonymization to other documents on a hand-crafted dataset of\nground truth redactions.",
    "categories": [
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at IEEE Symposium on CI in Security, Defence and Biometrics\n  2025 (IEEE CISDB)",
    "pdf_url": "http://arxiv.org/pdf/2501.07334v1",
    "published_date": "2025-01-13 13:47:00 UTC",
    "updated_date": "2025-01-13 13:47:00 UTC"
  },
  {
    "arxiv_id": "2501.07317v3",
    "title": "Evaluation of Artificial Intelligence Methods for Lead Time Prediction in Non-Cycled Areas of Automotive Production",
    "authors": [
      "Cornelius Hake",
      "Jonas Weigele",
      "Frederik Reichert",
      "Christian Friedrich"
    ],
    "abstract": "The present study examines the effectiveness of applying Artificial\nIntelligence methods in an automotive production environment to predict unknown\nlead times in a non-cycle-controlled production area. Data structures are\nanalyzed to identify contextual features and then preprocessed using one-hot\nencoding. Methods selection focuses on supervised machine learning techniques.\nIn supervised learning methods, regression and classification methods are\nevaluated. Continuous regression based on target size distribution is not\nfeasible. Classification methods analysis shows that Ensemble Learning and\nSupport Vector Machines are the most suitable. Preliminary study results\nindicate that gradient boosting algorithms LightGBM, XGBoost, and CatBoost\nyield the best results. After further testing and extensive hyperparameter\noptimization, the final method choice is the LightGBM algorithm. Depending on\nfeature availability and prediction interval granularity, relative prediction\naccuracies of up to 90% can be achieved. Further tests highlight the importance\nof periodic retraining of AI models to accurately represent complex production\nprocesses using the database. The research demonstrates that AI methods can be\neffectively applied to highly variable production data, adding business value\nby providing an additional metric for various control tasks while outperforming\ncurrent non AI-based systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07317v3",
    "published_date": "2025-01-13 13:28:03 UTC",
    "updated_date": "2025-01-15 14:01:15 UTC"
  },
  {
    "arxiv_id": "2501.07301v1",
    "title": "The Lessons of Developing Process Reward Models in Mathematical Reasoning",
    "authors": [
      "Zhenru Zhang",
      "Chujie Zheng",
      "Yangzhen Wu",
      "Beichen Zhang",
      "Runji Lin",
      "Bowen Yu",
      "Dayiheng Liu",
      "Jingren Zhou",
      "Junyang Lin"
    ],
    "abstract": "Process Reward Models (PRMs) emerge as a promising approach for process\nsupervision in mathematical reasoning of Large Language Models (LLMs), which\naim to identify and mitigate intermediate errors in the reasoning processes.\nHowever, the development of effective PRMs faces significant challenges,\nparticularly in data annotation and evaluation methodologies. In this paper,\nthrough extensive experiments, we demonstrate that commonly used Monte Carlo\n(MC) estimation-based data synthesis for PRMs typically yields inferior\nperformance and generalization compared to LLM-as-a-judge and human annotation\nmethods. MC estimation relies on completion models to evaluate current-step\ncorrectness, leading to inaccurate step verification. Furthermore, we identify\npotential biases in conventional Best-of-N (BoN) evaluation strategies for\nPRMs: (1) The unreliable policy models generate responses with correct answers\nbut flawed processes, leading to a misalignment between the evaluation criteria\nof BoN and the PRM objectives of process verification. (2) The tolerance of\nPRMs of such responses leads to inflated BoN scores. (3) Existing PRMs have a\nsignificant proportion of minimum scores concentrated on the final answer\nsteps, revealing the shift from process to outcome-based assessment in BoN\nOptimized PRMs. To address these challenges, we develop a consensus filtering\nmechanism that effectively integrates MC estimation with LLM-as-a-judge and\nadvocates a more comprehensive evaluation framework that combines\nresponse-level and step-level metrics. Based on the mechanisms, we\nsignificantly improve both model performance and data efficiency in the BoN\nevaluation and the step-wise error identification task. Finally, we release a\nnew state-of-the-art PRM that outperforms existing open-source alternatives and\nprovides practical guidelines for future research in building process\nsupervision models.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07301v1",
    "published_date": "2025-01-13 13:10:16 UTC",
    "updated_date": "2025-01-13 13:10:16 UTC"
  },
  {
    "arxiv_id": "2501.07290v1",
    "title": "Principles for Responsible AI Consciousness Research",
    "authors": [
      "Patrick Butlin",
      "Theodoros Lappas"
    ],
    "abstract": "Recent research suggests that it may be possible to build conscious AI\nsystems now or in the near future. Conscious AI systems would arguably deserve\nmoral consideration, and it may be the case that large numbers of conscious\nsystems could be created and caused to suffer. Furthermore, AI systems or\nAI-generated characters may increasingly give the impression of being\nconscious, leading to debate about their moral status. Organisations involved\nin AI research must establish principles and policies to guide research and\ndeployment choices and public communication concerning consciousness. Even if\nan organisation chooses not to study AI consciousness as such, it will still\nneed policies in place, as those developing advanced AI systems risk\ninadvertently creating conscious entities. Responsible research and deployment\npractices are essential to address this possibility. We propose five principles\nfor responsible research and argue that research organisations should make\nvoluntary, public commitments to principles on these lines. Our principles\nconcern research objectives and procedures, knowledge sharing and public\ncommunications.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07290v1",
    "published_date": "2025-01-13 12:59:53 UTC",
    "updated_date": "2025-01-13 12:59:53 UTC"
  },
  {
    "arxiv_id": "2501.07288v2",
    "title": "LLM-Net: Democratizing LLMs-as-a-Service through Blockchain-based Expert Networks",
    "authors": [
      "Zan-Kai Chong",
      "Hiroyuki Ohsaki",
      "Bryan Ng"
    ],
    "abstract": "The centralization of Large Language Models (LLMs) development has created\nsignificant barriers to AI advancement, limiting the democratization of these\npowerful technologies. This centralization, coupled with the scarcity of\nhigh-quality training data and mounting complexity of maintaining comprehensive\nexpertise across rapidly expanding knowledge domains, poses critical challenges\nto the continued growth of LLMs. While solutions like Retrieval-Augmented\nGeneration (RAG) offer potential remedies, maintaining up-to-date expert\nknowledge across diverse domains remains a significant challenge, particularly\ngiven the exponential growth of specialized information. This paper introduces\nLLMs Networks (LLM-Net), a blockchain-based framework that democratizes\nLLMs-as-a-Service through a decentralized network of specialized LLM providers.\nBy leveraging collective computational resources and distributed domain\nexpertise, LLM-Net incorporates fine-tuned expert models for various specific\ndomains, ensuring sustained knowledge growth while maintaining service quality\nthrough collaborative prompting mechanisms. The framework's robust design\nincludes blockchain technology for transparent transaction and performance\nvalidation, establishing an immutable record of service delivery. Our\nsimulation, built on top of state-of-the-art LLMs such as Claude 3.5 Sonnet,\nLlama 3.1, Grok-2, and GPT-4o, validates the effectiveness of the\nreputation-based mechanism in maintaining service quality by selecting\nhigh-performing respondents (LLM providers). Thereby it demonstrates the\npotential of LLM-Net to sustain AI advancement through the integration of\ndecentralized expertise and blockchain-based accountability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07288v2",
    "published_date": "2025-01-13 12:56:05 UTC",
    "updated_date": "2025-02-02 00:43:45 UTC"
  },
  {
    "arxiv_id": "2501.07278v1",
    "title": "Lifelong Learning of Large Language Model based Agents: A Roadmap",
    "authors": [
      "Junhao Zheng",
      "Chengming Shi",
      "Xidi Cai",
      "Qiuke Li",
      "Duzhen Zhang",
      "Chenxing Li",
      "Dong Yu",
      "Qianli Ma"
    ],
    "abstract": "Lifelong learning, also known as continual or incremental learning, is a\ncrucial component for advancing Artificial General Intelligence (AGI) by\nenabling systems to continuously adapt in dynamic environments. While large\nlanguage models (LLMs) have demonstrated impressive capabilities in natural\nlanguage processing, existing LLM agents are typically designed for static\nsystems and lack the ability to adapt over time in response to new challenges.\nThis survey is the first to systematically summarize the potential techniques\nfor incorporating lifelong learning into LLM-based agents. We categorize the\ncore components of these agents into three modules: the perception module for\nmultimodal input integration, the memory module for storing and retrieving\nevolving knowledge, and the action module for grounded interactions with the\ndynamic environment. We highlight how these pillars collectively enable\ncontinuous adaptation, mitigate catastrophic forgetting, and improve long-term\nperformance. This survey provides a roadmap for researchers and practitioners\nworking to develop lifelong learning capabilities in LLM agents, offering\ninsights into emerging trends, evaluation metrics, and application scenarios.\nRelevant literature and resources are available at \\href{this\nurl}{https://github.com/qianlima-lab/awesome-lifelong-llm-agent}.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "46 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07278v1",
    "published_date": "2025-01-13 12:42:04 UTC",
    "updated_date": "2025-01-13 12:42:04 UTC"
  },
  {
    "arxiv_id": "2501.07276v2",
    "title": "Bridging Smart Meter Gaps: A Benchmark of Statistical, Machine Learning and Time Series Foundation Models for Data Imputation",
    "authors": [
      "Amir Sartipi",
      "Joaquín Delgado Fernández",
      "Sergio Potenciano Menci",
      "Alessio Magitteri"
    ],
    "abstract": "The integrity of time series data in smart grids is often compromised by\nmissing values due to sensor failures, transmission errors, or disruptions.\nGaps in smart meter data can bias consumption analyses and hinder reliable\npredictions, causing technical and economic inefficiencies. As smart meter data\ngrows in volume and complexity, conventional techniques struggle with its\nnonlinear and nonstationary patterns. In this context, Generative Artificial\nIntelligence offers promising solutions that may outperform traditional\nstatistical methods. In this paper, we evaluate two general-purpose Large\nLanguage Models and five Time Series Foundation Models for smart meter data\nimputation, comparing them with conventional Machine Learning and statistical\nmodels. We introduce artificial gaps (30 minutes to one day) into an anonymized\npublic dataset to test inference capabilities. Results show that Time Series\nFoundation Models, with their contextual understanding and pattern recognition,\ncould significantly enhance imputation accuracy in certain cases. However, the\ntrade-off between computational cost and performance gains remains a critical\nconsideration.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07276v2",
    "published_date": "2025-01-13 12:41:27 UTC",
    "updated_date": "2025-02-20 09:02:33 UTC"
  },
  {
    "arxiv_id": "2501.07260v1",
    "title": "Skip Mamba Diffusion for Monocular 3D Semantic Scene Completion",
    "authors": [
      "Li Liang",
      "Naveed Akhtar",
      "Jordan Vice",
      "Xiangrui Kong",
      "Ajmal Saeed Mian"
    ],
    "abstract": "3D semantic scene completion is critical for multiple downstream tasks in\nautonomous systems. It estimates missing geometric and semantic information in\nthe acquired scene data. Due to the challenging real-world conditions, this\ntask usually demands complex models that process multi-modal data to achieve\nacceptable performance. We propose a unique neural model, leveraging advances\nfrom the state space and diffusion generative modeling to achieve remarkable 3D\nsemantic scene completion performance with monocular image input. Our technique\nprocesses the data in the conditioned latent space of a variational autoencoder\nwhere diffusion modeling is carried out with an innovative state space\ntechnique. A key component of our neural network is the proposed Skimba (Skip\nMamba) denoiser, which is adept at efficiently processing long-sequence data.\nThe Skimba diffusion model is integral to our 3D scene completion network,\nincorporating a triple Mamba structure, dimensional decomposition residuals and\nvarying dilations along three directions. We also adopt a variant of this\nnetwork for the subsequent semantic segmentation stage of our method. Extensive\nevaluation on the standard SemanticKITTI and SSCBench-KITTI360 datasets show\nthat our approach not only outperforms other monocular techniques by a large\nmargin, it also achieves competitive performance against stereo methods. The\ncode is available at https://github.com/xrkong/skimba",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07260v1",
    "published_date": "2025-01-13 12:18:58 UTC",
    "updated_date": "2025-01-13 12:18:58 UTC"
  },
  {
    "arxiv_id": "2501.07251v2",
    "title": "MOS-Attack: A Scalable Multi-objective Adversarial Attack Framework",
    "authors": [
      "Ping Guo",
      "Cheng Gong",
      "Xi Lin",
      "Fei Liu",
      "Zhichao Lu",
      "Qingfu Zhang",
      "Zhenkun Wang"
    ],
    "abstract": "Crafting adversarial examples is crucial for evaluating and enhancing the\nrobustness of Deep Neural Networks (DNNs), presenting a challenge equivalent to\nmaximizing a non-differentiable 0-1 loss function.\n  However, existing single objective methods, namely adversarial attacks focus\non a surrogate loss function, do not fully harness the benefits of engaging\nmultiple loss functions, as a result of insufficient understanding of their\nsynergistic and conflicting nature.\n  To overcome these limitations, we propose the Multi-Objective Set-based\nAttack (MOS Attack), a novel adversarial attack framework leveraging multiple\nloss functions and automatically uncovering their interrelations.\n  The MOS Attack adopts a set-based multi-objective optimization strategy,\nenabling the incorporation of numerous loss functions without additional\nparameters.\n  It also automatically mines synergistic patterns among various losses,\nfacilitating the generation of potent adversarial attacks with fewer\nobjectives.\n  Extensive experiments have shown that our MOS Attack outperforms\nsingle-objective attacks. Furthermore, by harnessing the identified synergistic\npatterns, MOS Attack continues to show superior results with a reduced number\nof loss functions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Under Review of CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07251v2",
    "published_date": "2025-01-13 12:00:34 UTC",
    "updated_date": "2025-01-23 01:40:37 UTC"
  },
  {
    "arxiv_id": "2501.07238v1",
    "title": "Lessons From Red Teaming 100 Generative AI Products",
    "authors": [
      "Blake Bullwinkel",
      "Amanda Minnich",
      "Shiven Chawla",
      "Gary Lopez",
      "Martin Pouliot",
      "Whitney Maxwell",
      "Joris de Gruyter",
      "Katherine Pratt",
      "Saphir Qi",
      "Nina Chikanov",
      "Roman Lutz",
      "Raja Sekhar Rao Dheekonda",
      "Bolor-Erdene Jagdagdorj",
      "Eugenia Kim",
      "Justin Song",
      "Keegan Hines",
      "Daniel Jones",
      "Giorgio Severi",
      "Richard Lundeen",
      "Sam Vaughan",
      "Victoria Westerhoff",
      "Pete Bryan",
      "Ram Shankar Siva Kumar",
      "Yonatan Zunger",
      "Chang Kawaguchi",
      "Mark Russinovich"
    ],
    "abstract": "In recent years, AI red teaming has emerged as a practice for probing the\nsafety and security of generative AI systems. Due to the nascency of the field,\nthere are many open questions about how red teaming operations should be\nconducted. Based on our experience red teaming over 100 generative AI products\nat Microsoft, we present our internal threat model ontology and eight main\nlessons we have learned:\n  1. Understand what the system can do and where it is applied\n  2. You don't have to compute gradients to break an AI system\n  3. AI red teaming is not safety benchmarking\n  4. Automation can help cover more of the risk landscape\n  5. The human element of AI red teaming is crucial\n  6. Responsible AI harms are pervasive but difficult to measure\n  7. LLMs amplify existing security risks and introduce new ones\n  8. The work of securing AI systems will never be complete\n  By sharing these insights alongside case studies from our operations, we\noffer practical recommendations aimed at aligning red teaming efforts with real\nworld risks. We also highlight aspects of AI red teaming that we believe are\noften misunderstood and discuss open questions for the field to consider.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07238v1",
    "published_date": "2025-01-13 11:36:33 UTC",
    "updated_date": "2025-01-13 11:36:33 UTC"
  },
  {
    "arxiv_id": "2501.07237v1",
    "title": "Breaking Memory Limits: Gradient Wavelet Transform Enhances LLMs Training",
    "authors": [
      "Ziqing Wen",
      "Ping Luo",
      "Jiahuan Wang",
      "Xiaoge Deng",
      "Jinping Zou",
      "Kun Yuan",
      "Tao Sun",
      "Dongsheng Li"
    ],
    "abstract": "Large language models (LLMs) have shown impressive performance across a range\nof natural language processing tasks. However, their vast number of parameters\nintroduces significant memory challenges during training, particularly when\nusing memory-intensive optimizers like Adam. Existing memory-efficient\nalgorithms often rely on techniques such as singular value decomposition\nprojection or weight freezing. While these approaches help alleviate memory\nconstraints, they generally produce suboptimal results compared to full-rank\nupdates. In this paper, we investigate the memory-efficient method beyond\nlow-rank training, proposing a novel solution called Gradient Wavelet Transform\n(GWT), which applies wavelet transforms to gradients in order to significantly\nreduce the memory requirements for maintaining optimizer states. We demonstrate\nthat GWT can be seamlessly integrated with memory-intensive optimizers,\nenabling efficient training without sacrificing performance. Through extensive\nexperiments on both pre-training and fine-tuning tasks, we show that GWT\nachieves state-of-the-art performance compared with advanced memory-efficient\noptimizers and full-rank approaches in terms of both memory usage and training\nperformance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07237v1",
    "published_date": "2025-01-13 11:35:09 UTC",
    "updated_date": "2025-01-13 11:35:09 UTC"
  },
  {
    "arxiv_id": "2501.07221v1",
    "title": "Exploring the Use of Contrastive Language-Image Pre-Training for Human Posture Classification: Insights from Yoga Pose Analysis",
    "authors": [
      "Andrzej D. Dobrzycki",
      "Ana M. Bernardos",
      "Luca Bergesio",
      "Andrzej Pomirski",
      "Daniel Sáez-Trigueros"
    ],
    "abstract": "Accurate human posture classification in images and videos is crucial for\nautomated applications across various fields, including work safety, physical\nrehabilitation, sports training, or daily assisted living. Recently, multimodal\nlearning methods, such as Contrastive Language-Image Pretraining (CLIP), have\nadvanced significantly in jointly understanding images and text. This study\naims to assess the effectiveness of CLIP in classifying human postures,\nfocusing on its application in yoga. Despite the initial limitations of the\nzero-shot approach, applying transfer learning on 15,301 images (real and\nsynthetic) with 82 classes has shown promising results. The article describes\nthe full procedure for fine-tuning, including the choice for image description\nsyntax, models and hyperparameters adjustment. The fine-tuned CLIP model,\ntested on 3826 images, achieves an accuracy of over 85%, surpassing the current\nstate-of-the-art of previous works on the same dataset by approximately 6%, its\ntraining time being 3.5 times lower than what is needed to fine-tune a\nYOLOv8-based model. For more application-oriented scenarios, with smaller\ndatasets of six postures each, containing 1301 and 401 training images, the\nfine-tuned models attain an accuracy of 98.8% and 99.1%, respectively.\nFurthermore, our experiments indicate that training with as few as 20 images\nper pose can yield around 90% accuracy in a six-class dataset. This study\ndemonstrates that this multimodal technique can be effectively used for yoga\npose classification, and possibly for human posture classification, in general.\nAdditionally, CLIP inference time (around 7 ms) supports that the model can be\nintegrated into automated systems for posture evaluation, e.g., for developing\na real-time personal yoga assistant for performance assessment.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07221v1",
    "published_date": "2025-01-13 11:20:44 UTC",
    "updated_date": "2025-01-13 11:20:44 UTC"
  },
  {
    "arxiv_id": "2501.07213v1",
    "title": "Multi-face emotion detection for effective Human-Robot Interaction",
    "authors": [
      "Mohamed Ala Yahyaoui",
      "Mouaad Oujabour",
      "Leila Ben Letaifa",
      "Amine Bohi"
    ],
    "abstract": "The integration of dialogue interfaces in mobile devices has become\nubiquitous, providing a wide array of services. As technology progresses,\nhumanoid robots designed with human-like features to interact effectively with\npeople are gaining prominence, and the use of advanced human-robot dialogue\ninterfaces is continually expanding. In this context, emotion recognition plays\na crucial role in enhancing human-robot interaction by enabling robots to\nunderstand human intentions. This research proposes a facial emotion detection\ninterface integrated into a mobile humanoid robot, capable of displaying\nreal-time emotions from multiple individuals on a user interface. To this end,\nvarious deep neural network models for facial expression recognition were\ndeveloped and evaluated under consistent computer-based conditions, yielding\npromising results. Afterwards, a trade-off between accuracy and memory\nfootprint was carefully considered to effectively implement this application on\na mobile humanoid robot.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CV",
      "cs.RO"
    ],
    "primary_category": "cs.HC",
    "comment": "9 pages, 8 figures and 1 table. Accepted at the 17th International\n  Conference on Agents and Artificial Intelligence (ICAART 2025), Porto,\n  Portugal",
    "pdf_url": "http://arxiv.org/pdf/2501.07213v1",
    "published_date": "2025-01-13 11:12:47 UTC",
    "updated_date": "2025-01-13 11:12:47 UTC"
  },
  {
    "arxiv_id": "2501.07196v1",
    "title": "Crowdsourced human-based computational approach for tagging peripheral blood smear sample images from Sickle Cell Disease patients using non-expert users",
    "authors": [
      "José María Buades Rubio",
      "Gabriel Moyà-Alcover",
      "Antoni Jaume-i-Capó",
      "Nataša Petrović"
    ],
    "abstract": "In this paper, we present a human-based computation approach for the analysis\nof peripheral blood smear (PBS) images images in patients with Sickle Cell\nDisease (SCD). We used the Mechanical Turk microtask market to crowdsource the\nlabeling of PBS images. We then use the expert-tagged erythrocytesIDB dataset\nto assess the accuracy and reliability of our proposal. Our results showed that\nwhen a robust consensus is achieved among the Mechanical Turk workers,\nprobability of error is very low, based on comparison with expert analysis.\nThis suggests that our proposed approach can be used to annotate datasets of\nPBS images, which can then be used to train automated methods for the diagnosis\nof SCD. In future work, we plan to explore the potential integration of our\nfindings with outcomes obtained through automated methodologies. This could\nlead to the development of more accurate and reliable methods for the diagnosis\nof SCD",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07196v1",
    "published_date": "2025-01-13 10:42:55 UTC",
    "updated_date": "2025-01-13 10:42:55 UTC"
  },
  {
    "arxiv_id": "2501.07186v2",
    "title": "Generalizable Graph Neural Networks for Robust Power Grid Topology Control",
    "authors": [
      "Matthijs de Jong",
      "Jan Viebahn",
      "Yuliya Shapovalova"
    ],
    "abstract": "The energy transition necessitates new congestion management methods. One\nsuch method is controlling the grid topology with machine learning (ML). This\napproach has gained popularity following the Learning to Run a Power Network\n(L2RPN) competitions. Graph neural networks (GNNs) are a class of ML models\nthat reflect graph structure in their computation, which makes them suitable\nfor power grid modeling. Various GNN approaches for topology control have thus\nbeen proposed. We propose the first GNN model for grid topology control that\nuses only GNN layers. Additionally, we identify the busbar information\nasymmetry problem that the popular homogeneous graph representation suffers\nfrom, and propose a heterogeneous graph representation to resolve it. We train\nboth homogeneous and heterogeneous GNNs and fully connected neural networks\n(FCNN) baselines on an imitation learning task. We evaluate the models\naccording to their classification accuracy and grid operation ability. We find\nthat the heterogeneous GNNs perform best on in-distribution networks, followed\nby the FCNNs, and lastly, the homogeneous GNNs. We also find that both GNN\ntypes generalize better to out-of-distribution networks than FCNNs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07186v2",
    "published_date": "2025-01-13 10:31:36 UTC",
    "updated_date": "2025-02-18 18:20:08 UTC"
  },
  {
    "arxiv_id": "2501.07183v1",
    "title": "Kriging and Gaussian Process Interpolation for Georeferenced Data Augmentation",
    "authors": [
      "Frédérick Fabre Ferber",
      "Dominique Gay",
      "Jean-Christophe Soulié",
      "Jean Diatta",
      "Odalric-Ambrym Maillard"
    ],
    "abstract": "Data augmentation is a crucial step in the development of robust supervised\nlearning models, especially when dealing with limited datasets. This study\nexplores interpolation techniques for the augmentation of geo-referenced data,\nwith the aim of predicting the presence of Commelina benghalensis L. in\nsugarcane plots in La R{\\'e}union. Given the spatial nature of the data and the\nhigh cost of data collection, we evaluated two interpolation approaches:\nGaussian processes (GPs) with different kernels and kriging with various\nvariograms. The objectives of this work are threefold: (i) to identify which\ninterpolation methods offer the best predictive performance for various\nregression algorithms, (ii) to analyze the evolution of performance as a\nfunction of the number of observations added, and (iii) to assess the spatial\nconsistency of augmented datasets. The results show that GP-based methods, in\nparticular with combined kernels (GP-COMB), significantly improve the\nperformance of regression algorithms while requiring less additional data.\nAlthough kriging shows slightly lower performance, it is distinguished by a\nmore homogeneous spatial coverage, a potential advantage in certain contexts.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07183v1",
    "published_date": "2025-01-13 10:29:09 UTC",
    "updated_date": "2025-01-13 10:29:09 UTC"
  },
  {
    "arxiv_id": "2501.09031v1",
    "title": "Synthetic Data and Health Privacy",
    "authors": [
      "Gwénolé Abgrall",
      "Xavier Monnet",
      "Anmol Arora"
    ],
    "abstract": "This Viewpoint discusses generative artificial intelligence and safeguarding\nprivacy by using synthetic data as a substitute for private health data.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CR",
    "comment": "JAMA Cardiology, 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.09031v1",
    "published_date": "2025-01-13 10:23:14 UTC",
    "updated_date": "2025-01-13 10:23:14 UTC"
  },
  {
    "arxiv_id": "2501.07178v1",
    "title": "The Spoils of Algorithmic Collusion: Profit Allocation Among Asymmetric Firms",
    "authors": [
      "Simon Martin",
      "Hans-Theo Normann",
      "Paul Püplichhuisen",
      "Tobias Werner"
    ],
    "abstract": "We study the propensity of independent algorithms to collude in repeated\nCournot duopoly games. Specifically, we investigate the predictive power of\ndifferent oligopoly and bargaining solutions regarding the effect of asymmetry\nbetween firms. We find that both consumers and firms can benefit from\nasymmetry. Algorithms produce more competitive outcomes when firms are\nsymmetric, but less when they are very asymmetric. Although the static Nash\nequilibrium underestimates the effect on total quantity and overestimates the\neffect on profits, it delivers surprisingly accurate predictions in terms of\ntotal welfare. The best description of our results is provided by the equal\nrelative gains solution. In particular, we find algorithms to agree on profits\nthat are on or close to the Pareto frontier for all degrees of asymmetry. Our\nresults suggest that the common belief that symmetric industries are more prone\nto collusion may no longer hold when algorithms increasingly drive managerial\ndecisions.",
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "primary_category": "econ.GN",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07178v1",
    "published_date": "2025-01-13 10:16:48 UTC",
    "updated_date": "2025-01-13 10:16:48 UTC"
  },
  {
    "arxiv_id": "2501.07172v1",
    "title": "Anomalous Agreement: How to find the Ideal Number of Anomaly Classes in Correlated, Multivariate Time Series Data",
    "authors": [
      "Ferdinand Rewicki",
      "Joachim Denzler",
      "Julia Niebling"
    ],
    "abstract": "Detecting and classifying abnormal system states is critical for condition\nmonitoring, but supervised methods often fall short due to the rarity of\nanomalies and the lack of labeled data. Therefore, clustering is often used to\ngroup similar abnormal behavior. However, evaluating cluster quality without\nground truth is challenging, as existing measures such as the Silhouette Score\n(SSC) only evaluate the cohesion and separation of clusters and ignore possible\nprior knowledge about the data. To address this challenge, we introduce the\nSynchronized Anomaly Agreement Index (SAAI), which exploits the synchronicity\nof anomalies across multivariate time series to assess cluster quality. We\ndemonstrate the effectiveness of SAAI by showing that maximizing SAAI improves\naccuracy on the task of finding the true number of anomaly classes K in\ncorrelated time series by 0.23 compared to SSC and by 0.32 compared to X-Means.\nWe also show that clusters obtained by maximizing SAAI are easier to interpret\ncompared to SSC.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Acccepted at AAAI Workshop on AI for Time Series Analysis (AI4TS)\n  2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07172v1",
    "published_date": "2025-01-13 10:04:55 UTC",
    "updated_date": "2025-01-13 10:04:55 UTC"
  },
  {
    "arxiv_id": "2501.07166v1",
    "title": "Natural Language-Assisted Multi-modal Medication Recommendation",
    "authors": [
      "Jie Tan",
      "Yu Rong",
      "Kangfei Zhao",
      "Tian Bian",
      "Tingyang Xu",
      "Junzhou Huang",
      "Hong Cheng",
      "Helen Meng"
    ],
    "abstract": "Combinatorial medication recommendation(CMR) is a fundamental task of\nhealthcare, which offers opportunities for clinical physicians to provide more\nprecise prescriptions for patients with intricate health conditions,\nparticularly in the scenarios of long-term medical care. Previous research\nefforts have sought to extract meaningful information from electronic health\nrecords (EHRs) to facilitate combinatorial medication recommendations. Existing\nlearning-based approaches further consider the chemical structures of\nmedications, but ignore the textual medication descriptions in which the\nfunctionalities are clearly described. Furthermore, the textual knowledge\nderived from the EHRs of patients remains largely underutilized. To address\nthese issues, we introduce the Natural Language-Assisted Multi-modal Medication\nRecommendation(NLA-MMR), a multi-modal alignment framework designed to learn\nknowledge from the patient view and medication view jointly. Specifically,\nNLA-MMR formulates CMR as an alignment problem from patient and medication\nmodalities. In this vein, we employ pretrained language models(PLMs) to extract\nin-domain knowledge regarding patients and medications, serving as the\nfoundational representation for both modalities. In the medication modality, we\nexploit both chemical structures and textual descriptions to create medication\nrepresentations. In the patient modality, we generate the patient\nrepresentations based on textual descriptions of diagnosis, procedure, and\nsymptom. Extensive experiments conducted on three publicly accessible datasets\ndemonstrate that NLA-MMR achieves new state-of-the-art performance, with a\nnotable average improvement of 4.72% in Jaccard score. Our source code is\npublicly available on https://github.com/jtan1102/NLA-MMR_CIKM_2024.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.07166v1",
    "published_date": "2025-01-13 09:51:50 UTC",
    "updated_date": "2025-01-13 09:51:50 UTC"
  },
  {
    "arxiv_id": "2501.07161v1",
    "title": "QuantuneV2: Compiler-Based Local Metric-Driven Mixed Precision Quantization for Practical Embedded AI Applications",
    "authors": [
      "Jeongseok Kim",
      "Jemin Lee",
      "Yongin Kwon",
      "Daeyoung Kim"
    ],
    "abstract": "Mixed-precision quantization methods have been proposed to reduce model size\nwhile minimizing accuracy degradation. However, existing studies require\nretraining and do not consider the computational overhead and intermediate\nrepresentations (IR) generated during the compilation process, limiting their\napplication at the compiler level. This computational overhead refers to the\nruntime latency caused by frequent quantization and dequantization operations\nduring inference. Performing these operations at the individual operator level\ncauses significant runtime delays. To address these issues, we propose\nQuantuneV2, a compiler-based mixed-precision quantization method designed for\npractical embedded AI applications. QuantuneV2 performs inference only twice,\nonce before quantization and once after quantization, and operates with a\ncomputational complexity of O(n) that increases linearly with the number of\nmodel parameters. We also made the sensitivity analysis more stable by using\nlocal metrics like weights, activation values, the Signal to Quantization Noise\nRatio, and the Mean Squared Error. We also cut down on computational overhead\nby choosing the best IR and using operator fusion. Experimental results show\nthat QuantuneV2 achieved up to a 10.28 percent improvement in accuracy and a\n12.52 percent increase in speed compared to existing methods across five\nmodels: ResNet18v1, ResNet50v1, SqueezeNetv1, VGGNet, and MobileNetv2. This\ndemonstrates that QuantuneV2 enhances model performance while maintaining\ncomputational efficiency, making it suitable for deployment in embedded AI\nenvironments.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 10 figures, Accepted in Future Generation Computer Systems\n  Journal",
    "pdf_url": "http://arxiv.org/pdf/2501.07161v1",
    "published_date": "2025-01-13 09:41:54 UTC",
    "updated_date": "2025-01-13 09:41:54 UTC"
  },
  {
    "arxiv_id": "2501.07158v1",
    "title": "Eye Sclera for Fair Face Image Quality Assessment",
    "authors": [
      "Wassim Kabbani",
      "Kiran Raja",
      "Raghavendra Ramachandra",
      "Christoph Busch"
    ],
    "abstract": "Fair operational systems are crucial in gaining and maintaining society's\ntrust in face recognition systems (FRS). FRS start with capturing an image and\nassessing its quality before using it further for enrollment or verification.\nFair Face Image Quality Assessment (FIQA) schemes therefore become equally\nimportant in the context of fair FRS. This work examines the sclera as a\nquality assessment region for obtaining a fair FIQA. The sclera region is\nagnostic to demographic variations and skin colour for assessing the quality of\na face image. We analyze three skin tone related ISO/IEC face image quality\nassessment measures and assess the sclera region as an alternative area for\nassessing FIQ. Our analysis of the face dataset of individuals from different\ndemographic groups representing different skin tones indicates sclera as an\nalternative to measure dynamic range, over- and under-exposure of face using\nsclera region alone. The sclera region being agnostic to skin tone, i.e.,\ndemographic factors, provides equal utility as a fair FIQA as shown by our\nError-vs-Discard Characteristic (EDC) curve analysis.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07158v1",
    "published_date": "2025-01-13 09:33:03 UTC",
    "updated_date": "2025-01-13 09:33:03 UTC"
  },
  {
    "arxiv_id": "2501.07157v1",
    "title": "CureGraph: Contrastive Multi-Modal Graph Representation Learning for Urban Living Circle Health Profiling and Prediction",
    "authors": [
      "Jinlin Li",
      "Xiao Zhou"
    ],
    "abstract": "The early detection and prediction of health status decline among the elderly\nat the neighborhood level are of great significance for urban planning and\npublic health policymaking. While existing studies affirm the connection\nbetween living environments and health outcomes, most rely on single data\nmodalities or simplistic feature concatenation of multi-modal information,\nlimiting their ability to comprehensively profile the health-oriented urban\nenvironments. To fill this gap, we propose CureGraph, a contrastive multi-modal\nrepresentation learning framework for urban health prediction that employs\ngraph-based techniques to infer the prevalence of common chronic diseases among\nthe elderly within the urban living circles of each neighborhood. CureGraph\nleverages rich multi-modal information, including photos and textual reviews of\nresidential areas and their surrounding points of interest, to generate urban\nneighborhood embeddings. By integrating pre-trained visual and textual encoders\nwith graph modeling techniques, CureGraph captures cross-modal spatial\ndependencies, offering a comprehensive understanding of urban environments\ntailored to elderly health considerations. Extensive experiments on real-world\ndatasets demonstrate that CureGraph improves the best baseline by $28\\%$ on\naverage in terms of $R^2$ across elderly disease risk prediction tasks.\nMoreover, the model enables the identification of stage-wise chronic disease\nprogression and supports comparative public health analysis across\nneighborhoods, offering actionable insights for sustainable urban development\nand enhanced quality of life. The code is publicly available at\nhttps://github.com/jinlin2021/CureGraph.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07157v1",
    "published_date": "2025-01-13 09:30:38 UTC",
    "updated_date": "2025-01-13 09:30:38 UTC"
  },
  {
    "arxiv_id": "2501.07146v1",
    "title": "TIMRL: A Novel Meta-Reinforcement Learning Framework for Non-Stationary and Multi-Task Environments",
    "authors": [
      "Chenyang Qi",
      "Huiping Li",
      "Panfeng Huang"
    ],
    "abstract": "In recent years, meta-reinforcement learning (meta-RL) algorithm has been\nproposed to improve sample efficiency in the field of decision-making and\ncontrol, enabling agents to learn new knowledge from a small number of samples.\nHowever, most research uses the Gaussian distribution to extract task\nrepresentation, which is poorly adapted to tasks that change in non-stationary\nenvironment. To address this problem, we propose a novel meta-reinforcement\nlearning method by leveraging Gaussian mixture model and the transformer\nnetwork to construct task inference model. The Gaussian mixture model is\nutilized to extend the task representation and conduct explicit encoding of\ntasks. Specifically, the classification of tasks is encoded through transformer\nnetwork to determine the Gaussian component corresponding to the task. By\nleveraging task labels, the transformer network is trained using supervised\nlearning. We validate our method on MuJoCo benchmarks with non-stationary and\nmulti-task environments. Experimental results demonstrate that the proposed\nmethod dramatically improves sample efficiency and accurately recognizes the\nclassification of the tasks, while performing excellently in the environment.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07146v1",
    "published_date": "2025-01-13 09:11:33 UTC",
    "updated_date": "2025-01-13 09:11:33 UTC"
  },
  {
    "arxiv_id": "2501.07139v1",
    "title": "FlexQuant: Elastic Quantization Framework for Locally Hosted LLM on Edge Devices",
    "authors": [
      "Yuji Chai",
      "Mujin Kwen",
      "David Brooks",
      "Gu-Yeon Wei"
    ],
    "abstract": "Deploying LLMs on edge devices presents serious technical challenges. Memory\nelasticity is crucial for edge devices with unified memory, where memory is\nshared and fluctuates dynamically. Existing solutions suffer from either poor\ntransition granularity or high storage costs. We propose FlexQuant, a novel\nelasticity framework that generates an ensemble of quantized models, providing\nan elastic hosting solution with 15x granularity improvement and 10x storage\nreduction compared to SoTA methods. FlexQuant works with most quantization\nmethods and creates a family of trade-off options under various storage limits\nthrough our pruning method. It brings great performance and flexibility to the\nedge deployment of LLMs.",
    "categories": [
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07139v1",
    "published_date": "2025-01-13 08:58:00 UTC",
    "updated_date": "2025-01-13 08:58:00 UTC"
  },
  {
    "arxiv_id": "2501.07108v1",
    "title": "How GPT learns layer by layer",
    "authors": [
      "Jason Du",
      "Kelly Hong",
      "Alishba Imran",
      "Erfan Jahanparast",
      "Mehdi Khfifi",
      "Kaichun Qiao"
    ],
    "abstract": "Large Language Models (LLMs) excel at tasks like language processing,\nstrategy games, and reasoning but struggle to build generalizable internal\nrepresentations essential for adaptive decision-making in agents. For agents to\neffectively navigate complex environments, they must construct reliable world\nmodels. While LLMs perform well on specific benchmarks, they often fail to\ngeneralize, leading to brittle representations that limit their real-world\neffectiveness. Understanding how LLMs build internal world models is key to\ndeveloping agents capable of consistent, adaptive behavior across tasks. We\nanalyze OthelloGPT, a GPT-based model trained on Othello gameplay, as a\ncontrolled testbed for studying representation learning. Despite being trained\nsolely on next-token prediction with random valid moves, OthelloGPT shows\nmeaningful layer-wise progression in understanding board state and gameplay.\nEarly layers capture static attributes like board edges, while deeper layers\nreflect dynamic tile changes. To interpret these representations, we compare\nSparse Autoencoders (SAEs) with linear probes, finding that SAEs offer more\nrobust, disentangled insights into compositional features, whereas linear\nprobes mainly detect features useful for classification. We use SAEs to decode\nfeatures related to tile color and tile stability, a previously unexamined\nfeature that reflects complex gameplay concepts like board control and\nlong-term planning. We study the progression of linear probe accuracy and tile\ncolor using both SAE's and linear probes to compare their effectiveness at\ncapturing what the model is learning. Although we begin with a smaller language\nmodel, OthelloGPT, this study establishes a framework for understanding the\ninternal representations learned by GPT models, transformers, and LLMs more\nbroadly. Our code is publicly available: https://github.com/ALT-JS/OthelloSAE.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07108v1",
    "published_date": "2025-01-13 07:42:55 UTC",
    "updated_date": "2025-01-13 07:42:55 UTC"
  },
  {
    "arxiv_id": "2501.07102v1",
    "title": "AdaCS: Adaptive Normalization for Enhanced Code-Switching ASR",
    "authors": [
      "The Chuong Chu",
      "Vu Tuan Dat Pham",
      "Kien Dao",
      "Hoang Nguyen",
      "Quoc Hung Truong"
    ],
    "abstract": "Intra-sentential code-switching (CS) refers to the alternation between\nlanguages that happens within a single utterance and is a significant challenge\nfor Automatic Speech Recognition (ASR) systems. For example, when a Vietnamese\nspeaker uses foreign proper names or specialized terms within their speech. ASR\nsystems often struggle to accurately transcribe intra-sentential CS due to\ntheir training on monolingual data and the unpredictable nature of CS. This\nissue is even more pronounced for low-resource languages, where limited data\navailability hinders the development of robust models. In this study, we\npropose AdaCS, a normalization model integrates an adaptive bias attention\nmodule (BAM) into encoder-decoder network. This novel approach provides a\nrobust solution to CS ASR in unseen domains, thereby significantly enhancing\nour contribution to the field. By utilizing BAM to both identify and normalize\nCS phrases, AdaCS enhances its adaptive capabilities with a biased list of\nwords provided during inference. Our method demonstrates impressive performance\nand the ability to handle unseen CS phrases across various domains. Experiments\nshow that AdaCS outperforms previous state-of-the-art method on Vietnamese CS\nASR normalization by considerable WER reduction of 56.2% and 36.8% on the two\nproposed test sets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07102v1",
    "published_date": "2025-01-13 07:27:00 UTC",
    "updated_date": "2025-01-13 07:27:00 UTC"
  },
  {
    "arxiv_id": "2501.07100v1",
    "title": "Collaborative Learning for 3D Hand-Object Reconstruction and Compositional Action Recognition from Egocentric RGB Videos Using Superquadrics",
    "authors": [
      "Tze Ho Elden Tse",
      "Runyang Feng",
      "Linfang Zheng",
      "Jiho Park",
      "Yixing Gao",
      "Jihie Kim",
      "Ales Leonardis",
      "Hyung Jin Chang"
    ],
    "abstract": "With the availability of egocentric 3D hand-object interaction datasets,\nthere is increasing interest in developing unified models for hand-object pose\nestimation and action recognition. However, existing methods still struggle to\nrecognise seen actions on unseen objects due to the limitations in representing\nobject shape and movement using 3D bounding boxes. Additionally, the reliance\non object templates at test time limits their generalisability to unseen\nobjects. To address these challenges, we propose to leverage superquadrics as\nan alternative 3D object representation to bounding boxes and demonstrate their\neffectiveness on both template-free object reconstruction and action\nrecognition tasks. Moreover, as we find that pure appearance-based methods can\noutperform the unified methods, the potential benefits from 3D geometric\ninformation remain unclear. Therefore, we study the compositionality of actions\nby considering a more challenging task where the training combinations of verbs\nand nouns do not overlap with the testing split. We extend H2O and FPHA\ndatasets with compositional splits and design a novel collaborative learning\nframework that can explicitly reason about the geometric relations between\nhands and the manipulated object. Through extensive quantitative and\nqualitative evaluations, we demonstrate significant improvements over the\nstate-of-the-arts in (compositional) action recognition.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted to AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07100v1",
    "published_date": "2025-01-13 07:26:05 UTC",
    "updated_date": "2025-01-13 07:26:05 UTC"
  },
  {
    "arxiv_id": "2501.07088v2",
    "title": "MathReader : Text-to-Speech for Mathematical Documents",
    "authors": [
      "Sieun Hyeon",
      "Kyudan Jung",
      "Nam-Joon Kim",
      "Hyun Gon Ryu",
      "Jaeyoung Do"
    ],
    "abstract": "TTS (Text-to-Speech) document reader from Microsoft, Adobe, Apple, and OpenAI\nhave been serviced worldwide. They provide relatively good TTS results for\ngeneral plain text, but sometimes skip contents or provide unsatisfactory\nresults for mathematical expressions. This is because most modern academic\npapers are written in LaTeX, and when LaTeX formulas are compiled, they are\nrendered as distinctive text forms within the document. However, traditional\nTTS document readers output only the text as it is recognized, without\nconsidering the mathematical meaning of the formulas. To address this issue, we\npropose MathReader, which effectively integrates OCR, a fine-tuned T5 model,\nand TTS. MathReader demonstrated a lower Word Error Rate (WER) than existing\nTTS document readers, such as Microsoft Edge and Adobe Acrobat, when processing\ndocuments containing mathematical formulas. MathReader reduced the WER from\n0.510 to 0.281 compared to Microsoft Edge, and from 0.617 to 0.281 compared to\nAdobe Acrobat. This will significantly contribute to alleviating the\ninconvenience faced by users who want to listen to documents, especially those\nwho are visually impaired. The code is available at\nhttps://github.com/hyeonsieun/MathReader.",
    "categories": [
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.07088v2",
    "published_date": "2025-01-13 06:47:05 UTC",
    "updated_date": "2025-01-19 06:27:48 UTC"
  },
  {
    "arxiv_id": "2501.07087v1",
    "title": "Video Quality Assessment for Online Processing: From Spatial to Temporal Sampling",
    "authors": [
      "Jiebin Yan",
      "Lei Wu",
      "Yuming Fang",
      "Xuelin Liu",
      "Xue Xia",
      "Weide Liu"
    ],
    "abstract": "With the rapid development of multimedia processing and deep learning\ntechnologies, especially in the field of video understanding, video quality\nassessment (VQA) has achieved significant progress. Although researchers have\nmoved from designing efficient video quality mapping models to various research\ndirections, in-depth exploration of the effectiveness-efficiency trade-offs of\nspatio-temporal modeling in VQA models is still less sufficient. Considering\nthe fact that videos have highly redundant information, this paper investigates\nthis problem from the perspective of joint spatial and temporal sampling,\naiming to seek the answer to how little information we should keep at least\nwhen feeding videos into the VQA models while with acceptable performance\nsacrifice. To this end, we drastically sample the video's information from both\nspatial and temporal dimensions, and the heavily squeezed video is then fed\ninto a stable VQA model. Comprehensive experiments regarding joint spatial and\ntemporal sampling are conducted on six public video quality databases, and the\nresults demonstrate the acceptable performance of the VQA model when throwing\naway most of the video information. Furthermore, with the proposed joint\nspatial and temporal sampling strategy, we make an initial attempt to design an\nonline VQA model, which is instantiated by as simple as possible a spatial\nfeature extractor, a temporal feature fusion module, and a global quality\nregression module. Through quantitative and qualitative experiments, we verify\nthe feasibility of online VQA model by simplifying itself and reducing input.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07087v1",
    "published_date": "2025-01-13 06:45:32 UTC",
    "updated_date": "2025-01-13 06:45:32 UTC"
  },
  {
    "arxiv_id": "2501.07078v1",
    "title": "ADKGD: Anomaly Detection in Knowledge Graphs with Dual-Channel Training",
    "authors": [
      "Jiayang Wu",
      "Wensheng Gan",
      "Jiahao Zhang",
      "Philip S. Yu"
    ],
    "abstract": "In the current development of large language models (LLMs), it is important\nto ensure the accuracy and reliability of the underlying data sources. LLMs are\ncritical for various applications, but they often suffer from hallucinations\nand inaccuracies due to knowledge gaps in the training data. Knowledge graphs\n(KGs), as a powerful structural tool, could serve as a vital external\ninformation source to mitigate the aforementioned issues. By providing a\nstructured and comprehensive understanding of real-world data, KGs enhance the\nperformance and reliability of LLMs. However, it is common that errors exist in\nKGs while extracting triplets from unstructured data to construct KGs. This\ncould lead to degraded performance in downstream tasks such as\nquestion-answering and recommender systems. Therefore, anomaly detection in KGs\nis essential to identify and correct these errors. This paper presents an\nanomaly detection algorithm in knowledge graphs with dual-channel learning\n(ADKGD). ADKGD leverages a dual-channel learning approach to enhance\nrepresentation learning from both the entity-view and triplet-view\nperspectives. Furthermore, using a cross-layer approach, our framework\nintegrates internal information aggregation and context information\naggregation. We introduce a kullback-leibler (KL)-loss component to improve the\naccuracy of the scoring function between the dual channels. To evaluate ADKGD's\nperformance, we conduct empirical studies on three real-world KGs: WN18RR,\nFB15K, and NELL-995. Experimental results demonstrate that ADKGD outperforms\nthe state-of-the-art anomaly detection algorithms. The source code and datasets\nare publicly available at https://github.com/csjywu1/ADKGD.",
    "categories": [
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.AI",
    "comment": "Preprint. 11 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.07078v1",
    "published_date": "2025-01-13 06:22:52 UTC",
    "updated_date": "2025-01-13 06:22:52 UTC"
  },
  {
    "arxiv_id": "2501.07076v2",
    "title": "Representation Learning of Point Cloud Upsampling in Global and Local Inputs",
    "authors": [
      "Tongxu Zhang",
      "Bei Wang"
    ],
    "abstract": "In recent years, point cloud upsampling has been widely applied in fields\nsuch as 3D reconstruction. Our study investigates the factors influencing point\ncloud upsampling on both global and local levels through representation\nlearning. Specifically, the paper inputs global and local information of the\nsame point cloud model object into two encoders to extract these features,\nfuses them, and then feeds the combined features into an upsampling decoder.\nThe goal is to address issues of sparsity and noise in point clouds by\nleveraging prior knowledge from both global and local inputs. And the proposed\nframework can be applied to any state-of-the-art point cloud upsampling neural\nnetwork. Experiments were conducted on a series of autoencoder-based models\nutilizing deep learning, yielding interpretability for both global and local\ninputs, and it has been proven in the results that our proposed framework can\nfurther improve the upsampling effect in previous SOTA works. At the same time,\nthe Saliency Map reflects the differences between global and local feature\ninputs, as well as the effectiveness of training with both inputs in parallel.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07076v2",
    "published_date": "2025-01-13 06:13:25 UTC",
    "updated_date": "2025-02-28 14:19:29 UTC"
  },
  {
    "arxiv_id": "2501.07071v1",
    "title": "Value Compass Leaderboard: A Platform for Fundamental and Validated Evaluation of LLMs Values",
    "authors": [
      "Jing Yao",
      "Xiaoyuan Yi",
      "Shitong Duan",
      "Jindong Wang",
      "Yuzhuo Bai",
      "Muhua Huang",
      "Peng Zhang",
      "Tun Lu",
      "Zhicheng Dou",
      "Maosong Sun",
      "Xing Xie"
    ],
    "abstract": "As Large Language Models (LLMs) achieve remarkable breakthroughs, aligning\ntheir values with humans has become imperative for their responsible\ndevelopment and customized applications. However, there still lack evaluations\nof LLMs values that fulfill three desirable goals. (1) Value Clarification: We\nexpect to clarify the underlying values of LLMs precisely and comprehensively,\nwhile current evaluations focus narrowly on safety risks such as bias and\ntoxicity. (2) Evaluation Validity: Existing static, open-source benchmarks are\nprone to data contamination and quickly become obsolete as LLMs evolve.\nAdditionally, these discriminative evaluations uncover LLMs' knowledge about\nvalues, rather than valid assessments of LLMs' behavioral conformity to values.\n(3) Value Pluralism: The pluralistic nature of human values across individuals\nand cultures is largely ignored in measuring LLMs value alignment. To address\nthese challenges, we presents the Value Compass Leaderboard, with three\ncorrespondingly designed modules. It (i) grounds the evaluation on\nmotivationally distinct \\textit{basic values to clarify LLMs' underlying values\nfrom a holistic view; (ii) applies a \\textit{generative evolving evaluation\nframework with adaptive test items for evolving LLMs and direct value\nrecognition from behaviors in realistic scenarios; (iii) propose a metric that\nquantifies LLMs alignment with a specific value as a weighted sum over multiple\ndimensions, with weights determined by pluralistic values.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07071v1",
    "published_date": "2025-01-13 05:53:56 UTC",
    "updated_date": "2025-01-13 05:53:56 UTC"
  },
  {
    "arxiv_id": "2501.07058v1",
    "title": "Logic Meets Magic: LLMs Cracking Smart Contract Vulnerabilities",
    "authors": [
      "ZeKe Xiao",
      "Qin Wang",
      "Hammond Pearce",
      "Shiping Chen"
    ],
    "abstract": "Smart contract vulnerabilities caused significant economic losses in\nblockchain applications. Large Language Models (LLMs) provide new possibilities\nfor addressing this time-consuming task. However, state-of-the-art LLM-based\ndetection solutions are often plagued by high false-positive rates.\n  In this paper, we push the boundaries of existing research in two key ways.\nFirst, our evaluation is based on Solidity v0.8, offering the most up-to-date\ninsights compared to prior studies that focus on older versions (v0.4). Second,\nwe leverage the latest five LLM models (across companies), ensuring\ncomprehensive coverage across the most advanced capabilities in the field.\n  We conducted a series of rigorous evaluations. Our experiments demonstrate\nthat a well-designed prompt can reduce the false-positive rate by over 60%.\nSurprisingly, we also discovered that the recall rate for detecting some\nspecific vulnerabilities in Solidity v0.8 has dropped to just 13% compared to\nearlier versions (i.e., v0.4). Further analysis reveals the root cause of this\ndecline: the reliance of LLMs on identifying changes in newly introduced\nlibraries and frameworks during detection.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07058v1",
    "published_date": "2025-01-13 04:42:45 UTC",
    "updated_date": "2025-01-13 04:42:45 UTC"
  },
  {
    "arxiv_id": "2501.07054v1",
    "title": "PoAct: Policy and Action Dual-Control Agent for Generalized Applications",
    "authors": [
      "Guozhi Yuan",
      "Youfeng Liu",
      "Jingli Yang",
      "Wei Jia",
      "Kai Lin",
      "Yansong Gao",
      "Shan He",
      "Zilin Ding",
      "Haitao Li"
    ],
    "abstract": "Based on their superior comprehension and reasoning capabilities, Large\nLanguage Model (LLM) driven agent frameworks have achieved significant success\nin numerous complex reasoning tasks. ReAct-like agents can solve various\nintricate problems step-by-step through progressive planning and tool calls,\niteratively optimizing new steps based on environmental feedback. However, as\nthe planning capabilities of LLMs improve, the actions invoked by tool calls in\nReAct-like frameworks often misalign with complex planning and challenging data\norganization. Code Action addresses these issues while also introducing the\nchallenges of a more complex action space and more difficult action\norganization. To leverage Code Action and tackle the challenges of its\ncomplexity, this paper proposes Policy and Action Dual-Control Agent (PoAct)\nfor generalized applications. The aim is to achieve higher-quality code actions\nand more accurate reasoning paths by dynamically switching reasoning policies\nand modifying the action space. Experimental results on the Agent Benchmark for\nboth legal and generic scenarios demonstrate the superior reasoning\ncapabilities and reduced token consumption of our approach in complex tasks. On\nthe LegalAgentBench, our method shows a 20 percent improvement over the\nbaseline while requiring fewer tokens. We conducted experiments and analyses on\nthe GPT-4o and GLM-4 series models, demonstrating the significant potential and\nscalability of our approach to solve complex problems.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07054v1",
    "published_date": "2025-01-13 04:28:40 UTC",
    "updated_date": "2025-01-13 04:28:40 UTC"
  },
  {
    "arxiv_id": "2501.07048v1",
    "title": "Unveiling the Potential of Text in High-Dimensional Time Series Forecasting",
    "authors": [
      "Xin Zhou",
      "Weiqing Wang",
      "Shilin Qu",
      "Zhiqiang Zhang",
      "Christoph Bergmeir"
    ],
    "abstract": "Time series forecasting has traditionally focused on univariate and\nmultivariate numerical data, often overlooking the benefits of incorporating\nmultimodal information, particularly textual data. In this paper, we propose a\nnovel framework that integrates time series models with Large Language Models\nto improve high-dimensional time series forecasting. Inspired by multimodal\nmodels, our method combines time series and textual data in the dual-tower\nstructure. This fusion of information creates a comprehensive representation,\nwhich is then processed through a linear layer to generate the final forecast.\nExtensive experiments demonstrate that incorporating text enhances\nhigh-dimensional time series forecasting performance. This work paves the way\nfor further research in multimodal time series forecasting.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by NeurIPS24 TSALM Workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.07048v1",
    "published_date": "2025-01-13 04:10:45 UTC",
    "updated_date": "2025-01-13 04:10:45 UTC"
  },
  {
    "arxiv_id": "2501.07045v1",
    "title": "ACCon: Angle-Compensated Contrastive Regularizer for Deep Regression",
    "authors": [
      "Botao Zhao",
      "Xiaoyang Qu",
      "Zuheng Kang",
      "Junqing Peng",
      "Jing Xiao",
      "Jianzong Wang"
    ],
    "abstract": "In deep regression, capturing the relationship among continuous labels in\nfeature space is a fundamental challenge that has attracted increasing\ninterest. Addressing this issue can prevent models from converging to\nsuboptimal solutions across various regression tasks, leading to improved\nperformance, especially for imbalanced regression and under limited sample\nsizes. However, existing approaches often rely on order-aware representation\nlearning or distance-based weighting. In this paper, we hypothesize a linear\nnegative correlation between label distances and representation similarities in\nregression tasks. To implement this, we propose an angle-compensated\ncontrastive regularizer for deep regression, which adjusts the cosine distance\nbetween anchor and negative samples within the contrastive learning framework.\nOur method offers a plug-and-play compatible solution that extends most\nexisting contrastive learning methods for regression tasks. Extensive\nexperiments and theoretical analysis demonstrate that our proposed\nangle-compensated contrastive regularizer not only achieves competitive\nregression performance but also excels in data efficiency and effectiveness on\nimbalanced datasets.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accept by AAAI-2025 (The 39th Annual AAAI Conference on Artificial\n  Intelligence)",
    "pdf_url": "http://arxiv.org/pdf/2501.07045v1",
    "published_date": "2025-01-13 03:55:59 UTC",
    "updated_date": "2025-01-13 03:55:59 UTC"
  },
  {
    "arxiv_id": "2501.07024v1",
    "title": "A Proposed Large Language Model-Based Smart Search for Archive System",
    "authors": [
      "Ha Dung Nguyen",
      "Thi-Hoang Anh Nguyen",
      "Thanh Binh Nguyen"
    ],
    "abstract": "This study presents a novel framework for smart search in digital archival\nsystems, leveraging the capabilities of Large Language Models (LLMs) to enhance\ninformation retrieval. By employing a Retrieval-Augmented Generation (RAG)\napproach, the framework enables the processing of natural language queries and\ntransforming non-textual data into meaningful textual representations. The\nsystem integrates advanced metadata generation techniques, a hybrid retrieval\nmechanism, a router query engine, and robust response synthesis, the results\nproved search precision and relevance. We present the architecture and\nimplementation of the system and evaluate its performance in four experiments\nconcerning LLM efficiency, hybrid retrieval optimizations, multilingual query\nhandling, and the impacts of individual components. Obtained results show\nsignificant improvements over conventional approaches and have demonstrated the\npotential of AI-powered systems to transform modern archival practices.",
    "categories": [
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "The 13th International Symposium on Information and Communication\n  Technology (SOICT 2024)",
    "pdf_url": "http://arxiv.org/pdf/2501.07024v1",
    "published_date": "2025-01-13 02:53:07 UTC",
    "updated_date": "2025-01-13 02:53:07 UTC"
  },
  {
    "arxiv_id": "2501.07021v2",
    "title": "Neural Probabilistic Circuits: Enabling Compositional and Interpretable Predictions through Logical Reasoning",
    "authors": [
      "Weixin Chen",
      "Simon Yu",
      "Huajie Shao",
      "Lui Sha",
      "Han Zhao"
    ],
    "abstract": "End-to-end deep neural networks have achieved remarkable success across\nvarious domains but are often criticized for their lack of interpretability.\nWhile post hoc explanation methods attempt to address this issue, they often\nfail to accurately represent these black-box models, resulting in misleading or\nincomplete explanations. To overcome these challenges, we propose an inherently\ntransparent model architecture called Neural Probabilistic Circuits (NPCs),\nwhich enable compositional and interpretable predictions through logical\nreasoning. In particular, an NPC consists of two modules: an attribute\nrecognition model, which predicts probabilities for various attributes, and a\ntask predictor built on a probabilistic circuit, which enables logical\nreasoning over recognized attributes to make class predictions. To train NPCs,\nwe introduce a three-stage training algorithm comprising attribute recognition,\ncircuit construction, and joint optimization. Moreover, we theoretically\ndemonstrate that an NPC's error is upper-bounded by a linear combination of the\nerrors from its modules. To further demonstrate the interpretability of NPC, we\nprovide both the most probable explanations and the counterfactual\nexplanations. Empirical results on four benchmark datasets show that NPCs\nstrike a balance between interpretability and performance, achieving results\ncompetitive even with those of end-to-end black-box models while providing\nenhanced interpretability.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07021v2",
    "published_date": "2025-01-13 02:47:49 UTC",
    "updated_date": "2025-01-20 04:00:48 UTC"
  },
  {
    "arxiv_id": "2501.07020v1",
    "title": "ViSoLex: An Open-Source Repository for Vietnamese Social Media Lexical Normalization",
    "authors": [
      "Anh Thi-Hoang Nguyen",
      "Dung Ha Nguyen",
      "Kiet Van Nguyen"
    ],
    "abstract": "ViSoLex is an open-source system designed to address the unique challenges of\nlexical normalization for Vietnamese social media text. The platform provides\ntwo core services: Non-Standard Word (NSW) Lookup and Lexical Normalization,\nenabling users to retrieve standard forms of informal language and standardize\ntext containing NSWs. ViSoLex's architecture integrates pre-trained language\nmodels and weakly supervised learning techniques to ensure accurate and\nefficient normalization, overcoming the scarcity of labeled data in Vietnamese.\nThis paper details the system's design, functionality, and its applications for\nresearchers and non-technical users. Additionally, ViSoLex offers a flexible,\ncustomizable framework that can be adapted to various datasets and research\nrequirements. By publishing the source code, ViSoLex aims to contribute to the\ndevelopment of more robust Vietnamese natural language processing tools and\nencourage further research in lexical normalization. Future directions include\nexpanding the system's capabilities for additional languages and improving the\nhandling of more complex non-standard linguistic patterns.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The 31st International Conference on Computational Linguistics\n  (COLING 2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.07020v1",
    "published_date": "2025-01-13 02:47:13 UTC",
    "updated_date": "2025-01-13 02:47:13 UTC"
  },
  {
    "arxiv_id": "2501.07017v2",
    "title": "UNetVL: Enhancing 3D Medical Image Segmentation with Chebyshev KAN Powered Vision-LSTM",
    "authors": [
      "Xuhui Guo",
      "Tanmoy Dam",
      "Rohan Dhamdhere",
      "Gourav Modanwal",
      "Anant Madabhushi"
    ],
    "abstract": "3D medical image segmentation has progressed considerably due to\nConvolutional Neural Networks (CNNs) and Vision Transformers (ViTs), yet these\nmethods struggle to balance long-range dependency acquisition with\ncomputational efficiency. To address this challenge, we propose UNETVL (U-Net\nVision-LSTM), a novel architecture that leverages recent advancements in\ntemporal information processing. UNETVL incorporates Vision-LSTM (ViL) for\nimproved scalability and memory functions, alongside an efficient Chebyshev\nKolmogorov-Arnold Networks (KAN) to handle complex and long-range dependency\npatterns more effectively. We validated our method on the ACDC and AMOS2022\n(post challenge Task 2) benchmark datasets, showing a significant improvement\nin mean Dice score compared to recent state-of-the-art approaches, especially\nover its predecessor, UNETR, with increases of 7.3% on ACDC and 15.6% on AMOS,\nrespectively. Extensive ablation studies were conducted to demonstrate the\nimpact of each component in UNETVL, providing a comprehensive understanding of\nits architecture. Our code is available at https://github.com/tgrex6/UNETVL,\nfacilitating further research and applications in this domain.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07017v2",
    "published_date": "2025-01-13 02:33:28 UTC",
    "updated_date": "2025-01-19 19:06:32 UTC"
  },
  {
    "arxiv_id": "2501.07016v1",
    "title": "A Multi-Modal Deep Learning Framework for Pan-Cancer Prognosis",
    "authors": [
      "Binyu Zhang",
      "Shichao Li",
      "Junpeng Jian",
      "Zhu Meng",
      "Limei Guo",
      "Zhicheng Zhao"
    ],
    "abstract": "Prognostic task is of great importance as it closely related to the survival\nanalysis of patients, the optimization of treatment plans and the allocation of\nresources. The existing prognostic models have shown promising results on\nspecific datasets, but there are limitations in two aspects. On the one hand,\nthey merely explore certain types of modal data, such as patient histopathology\nWSI and gene expression analysis. On the other hand, they adopt the\nper-cancer-per-model paradigm, which means the trained models can only predict\nthe prognostic effect of a single type of cancer, resulting in weak\ngeneralization ability. In this paper, a deep-learning based model, named\nUMPSNet, is proposed. Specifically, to comprehensively understand the condition\nof patients, in addition to constructing encoders for histopathology images and\ngenomic expression profiles respectively, UMPSNet further integrates four types\nof important meta data (demographic information, cancer type information,\ntreatment protocols, and diagnosis results) into text templates, and then\nintroduces a text encoder to extract textual features. In addition, the optimal\ntransport OT-based attention mechanism is utilized to align and fuse features\nof different modalities. Furthermore, a guided soft mixture of experts (GMoE)\nmechanism is introduced to effectively address the issue of distribution\ndifferences among multiple cancer datasets. By incorporating the multi-modality\nof patient data and joint training, UMPSNet outperforms all SOTA approaches,\nand moreover, it demonstrates the effectiveness and generalization ability of\nthe proposed learning paradigm of a single model for multiple cancer types. The\ncode of UMPSNet is available at https://github.com/binging512/UMPSNet.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07016v1",
    "published_date": "2025-01-13 02:29:42 UTC",
    "updated_date": "2025-01-13 02:29:42 UTC"
  },
  {
    "arxiv_id": "2501.07014v3",
    "title": "AlgoRxplorers | Precision in Mutation: Enhancing Drug Design with Advanced Protein Stability Prediction Tools",
    "authors": [
      "Karishma Thakrar",
      "Jiangqin Ma",
      "Max Diamond",
      "Akash Patel"
    ],
    "abstract": "Predicting the impact of single-point amino acid mutations on protein\nstability is essential for understanding disease mechanisms and advancing drug\ndevelopment. Protein stability, quantified by changes in Gibbs free energy\n($\\Delta\\Delta G$), is influenced by these mutations. However, the scarcity of\ndata and the complexity of model interpretation pose challenges in accurately\npredicting stability changes. This study proposes the application of deep\nneural networks, leveraging transfer learning and fusing complementary\ninformation from different models, to create a feature-rich representation of\nthe protein stability landscape. We developed four models, with our third\nmodel, ThermoMPNN+, demonstrating the best performance in predicting\n$\\Delta\\Delta G$ values. This approach, which integrates diverse feature sets\nand embeddings through latent transfusion techniques, aims to refine\n$\\Delta\\Delta G$ predictions and contribute to a deeper understanding of\nprotein dynamics, potentially leading to advancements in disease research and\ndrug discovery.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.07014v3",
    "published_date": "2025-01-13 02:17:01 UTC",
    "updated_date": "2025-01-30 02:45:31 UTC"
  },
  {
    "arxiv_id": "2501.06999v1",
    "title": "Likelihood Training of Cascaded Diffusion Models via Hierarchical Volume-preserving Maps",
    "authors": [
      "Henry Li",
      "Ronen Basri",
      "Yuval Kluger"
    ],
    "abstract": "Cascaded models are multi-scale generative models with a marked capacity for\nproducing perceptually impressive samples at high resolutions. In this work, we\nshow that they can also be excellent likelihood models, so long as we overcome\na fundamental difficulty with probabilistic multi-scale models: the\nintractability of the likelihood function. Chiefly, in cascaded models each\nintermediary scale introduces extraneous variables that cannot be tractably\nmarginalized out for likelihood evaluation. This issue vanishes by modeling the\ndiffusion process on latent spaces induced by a class of transformations we\ncall hierarchical volume-preserving maps, which decompose spatially structured\ndata in a hierarchical fashion without introducing local distortions in the\nlatent space. We demonstrate that two such maps are well-known in the\nliterature for multiscale modeling: Laplacian pyramids and wavelet transforms.\nNot only do such reparameterizations allow the likelihood function to be\ndirectly expressed as a joint likelihood over the scales, we show that the\nLaplacian pyramid and wavelet transform also produces significant improvements\nto the state-of-the-art on a selection of benchmarks in likelihood modeling,\nincluding density estimation, lossless compression, and out-of-distribution\ndetection. Investigating the theoretical basis of our empirical gains we\nuncover deep connections to score matching under the Earth Mover's Distance\n(EMD), which is a well-known surrogate for perceptual similarity. Code can be\nfound at \\href{https://github.com/lihenryhfl/pcdm}{this https url}.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Spotlight at ICLR 2024",
    "pdf_url": "http://arxiv.org/pdf/2501.06999v1",
    "published_date": "2025-01-13 01:20:23 UTC",
    "updated_date": "2025-01-13 01:20:23 UTC"
  },
  {
    "arxiv_id": "2501.06994v1",
    "title": "Motion Tracks: A Unified Representation for Human-Robot Transfer in Few-Shot Imitation Learning",
    "authors": [
      "Juntao Ren",
      "Priya Sundaresan",
      "Dorsa Sadigh",
      "Sanjiban Choudhury",
      "Jeannette Bohg"
    ],
    "abstract": "Teaching robots to autonomously complete everyday tasks remains a challenge.\nImitation Learning (IL) is a powerful approach that imbues robots with skills\nvia demonstrations, but is limited by the labor-intensive process of collecting\nteleoperated robot data. Human videos offer a scalable alternative, but it\nremains difficult to directly train IL policies from them due to the lack of\nrobot action labels. To address this, we propose to represent actions as\nshort-horizon 2D trajectories on an image. These actions, or motion tracks,\ncapture the predicted direction of motion for either human hands or robot\nend-effectors. We instantiate an IL policy called Motion Track Policy (MT-pi)\nwhich receives image observations and outputs motion tracks as actions. By\nleveraging this unified, cross-embodiment action space, MT-pi completes tasks\nwith high success given just minutes of human video and limited additional\nrobot demonstrations. At test time, we predict motion tracks from two camera\nviews, recovering 6DoF trajectories via multi-view synthesis. MT-pi achieves an\naverage success rate of 86.5% across 4 real-world tasks, outperforming\nstate-of-the-art IL baselines which do not leverage human data or our action\nspace by 40%, and generalizes to scenarios seen only in human videos. Code and\nvideos are available on our website\nhttps://portal-cornell.github.io/motion_track_policy/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06994v1",
    "published_date": "2025-01-13 01:01:44 UTC",
    "updated_date": "2025-01-13 01:01:44 UTC"
  },
  {
    "arxiv_id": "2501.06985v1",
    "title": "Graph Contrastive Learning on Multi-label Classification for Recommendations",
    "authors": [
      "Jiayang Wu",
      "Wensheng Gan",
      "Huashen Lu",
      "Philip S. Yu"
    ],
    "abstract": "In business analysis, providing effective recommendations is essential for\nenhancing company profits. The utilization of graph-based structures, such as\nbipartite graphs, has gained popularity for their ability to analyze complex\ndata relationships. Link prediction is crucial for recommending specific items\nto users. Traditional methods in this area often involve identifying patterns\nin the graph structure or using representational techniques like graph neural\nnetworks (GNNs). However, these approaches encounter difficulties as the volume\nof data increases. To address these challenges, we propose a model called Graph\nContrastive Learning for Multi-label Classification (MCGCL). MCGCL leverages\ncontrastive learning to enhance recommendation effectiveness. The model\nincorporates two training stages: a main task and a subtask. The main task is\nholistic user-item graph learning to capture user-item relationships. The\nhomogeneous user-user (item-item) subgraph is constructed to capture user-user\nand item-item relationships in the subtask. We assessed the performance using\nreal-world datasets from Amazon Reviews in multi-label classification tasks.\nComparative experiments with state-of-the-art methods confirm the effectiveness\nof MCGCL, highlighting its potential for improving recommendation systems.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Preprint. 10 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.06985v1",
    "published_date": "2025-01-13 00:29:29 UTC",
    "updated_date": "2025-01-13 00:29:29 UTC"
  },
  {
    "arxiv_id": "2501.06981v1",
    "title": "Data Enrichment Work and AI Labor in Latin America and the Caribbean",
    "authors": [
      "Gianna Williams",
      "Maya De Los Santos",
      "Alexandra To",
      "Saiph Savage"
    ],
    "abstract": "The global AI surge demands crowdworkers from diverse languages and cultures.\nThey are pivotal in labeling data for enabling global AI systems. Despite\nglobal significance, research has primarily focused on understanding the\nperspectives and experiences of US and India crowdworkers, leaving a notable\ngap. To bridge this, we conducted a survey with 100 crowdworkers across 16\nLatin American and Caribbean countries. We discovered that these workers\nexhibited pride and respect for their digital labor, with strong support and\nadmiration from their families. Notably, crowd work was also seen as a stepping\nstone to financial and professional independence. Surprisingly, despite wanting\nmore connection, these workers also felt isolated from peers and doubtful of\nothers' labor quality. They resisted collaboration and gender-based tools,\nvaluing gender-neutrality. Our work advances HCI understanding of Latin\nAmerican and Caribbean crowdwork, offering insights for digital resistance\ntools for the region.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "K.4; I.2"
    ],
    "primary_category": "cs.CY",
    "comment": "17 pages of content with 2 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.06981v1",
    "published_date": "2025-01-13 00:11:47 UTC",
    "updated_date": "2025-01-13 00:11:47 UTC"
  },
  {
    "arxiv_id": "2501.06980v1",
    "title": "Combining LLM decision and RL action selection to improve RL policy for adaptive interventions",
    "authors": [
      "Karine Karine",
      "Benjamin M. Marlin"
    ],
    "abstract": "Reinforcement learning (RL) is increasingly being used in the healthcare\ndomain, particularly for the development of personalized health adaptive\ninterventions. Inspired by the success of Large Language Models (LLMs), we are\ninterested in using LLMs to update the RL policy in real time, with the goal of\naccelerating personalization. We use the text-based user preference to\ninfluence the action selection on the fly, in order to immediately incorporate\nthe user preference. We use the term \"user preference\" as a broad term to refer\nto a user personal preference, constraint, health status, or a statement\nexpressing like or dislike, etc. Our novel approach is a hybrid method that\ncombines the LLM response and the RL action selection to improve the RL policy.\nGiven an LLM prompt that incorporates the user preference, the LLM acts as a\nfilter in the typical RL action selection. We investigate different prompting\nstrategies and action selection strategies. To evaluate our approach, we\nimplement a simulation environment that generates the text-based user\npreferences and models the constraints that impact behavioral dynamics. We show\nthat our approach is able to take into account the text-based user preferences,\nwhile improving the RL policy, thus improving personalization in adaptive\nintervention.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.06980v1",
    "published_date": "2025-01-13 00:03:20 UTC",
    "updated_date": "2025-01-13 00:03:20 UTC"
  }
]