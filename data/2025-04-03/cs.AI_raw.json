[
  {
    "arxiv_id": "2504.03085v2",
    "title": "From Questions to Insights: Exploring XAI Challenges Reported on Stack Overflow Questions",
    "authors": [
      "Saumendu Roy",
      "Saikat Mondal",
      "Banani Roy",
      "Chanchal Roy"
    ],
    "abstract": "The lack of interpretability is a major barrier that limits the practical\nusage of AI models. Several eXplainable AI (XAI) techniques (e.g., SHAP, LIME)\nhave been employed to interpret these models' performance. However, users often\nface challenges when leveraging these techniques in real-world scenarios and\nthus submit questions in technical Q&A forums like Stack Overflow (SO) to\nresolve these challenges. We conducted an exploratory study to expose these\nchallenges, their severity, and features that can make XAI techniques more\naccessible and easier to use. Our contributions to this study are fourfold.\nFirst, we manually analyzed 663 SO questions that discussed challenges related\nto XAI techniques. Our careful investigation produced a catalog of seven\nchallenges (e.g., disagreement issues). We then analyzed their prevalence and\nfound that model integration and disagreement issues emerged as the most\nprevalent challenges. Second, we attempt to estimate the severity of each XAI\nchallenge by determining the correlation between challenge types and answer\nmetadata (e.g., the presence of accepted answers). Our analysis suggests that\nmodel integration issues is the most severe challenge. Third, we attempt to\nperceive the severity of these challenges based on practitioners' ability to\nuse XAI techniques effectively in their work. Practitioners' responses suggest\nthat disagreement issues most severely affect the use of XAI techniques.\nFourth, we seek agreement from practitioners on improvements or features that\ncould make XAI techniques more accessible and user-friendly. The majority of\nthem suggest consistency in explanations and simplified integration. Our study\nfindings might (a) help to enhance the accessibility and usability of XAI and\n(b) act as the initial benchmark that can inspire future research.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted in 29th International Conference on Evaluation and\n  Assessment in Software Engineering (EASE 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.03085v2",
    "published_date": "2025-04-03 23:33:46 UTC",
    "updated_date": "2025-04-17 23:05:40 UTC"
  },
  {
    "arxiv_id": "2504.03077v1",
    "title": "Integrating Identity-Based Identification against Adaptive Adversaries in Federated Learning",
    "authors": [
      "Jakub Kacper Szelag",
      "Ji-Jian Chin",
      "Lauren Ansell",
      "Sook-Chin Yip"
    ],
    "abstract": "Federated Learning (FL) has recently emerged as a promising paradigm for\nprivacy-preserving, distributed machine learning. However, FL systems face\nsignificant security threats, particularly from adaptive adversaries capable of\nmodifying their attack strategies to evade detection. One such threat is the\npresence of Reconnecting Malicious Clients (RMCs), which exploit FLs open\nconnectivity by reconnecting to the system with modified attack strategies. To\naddress this vulnerability, we propose integration of Identity-Based\nIdentification (IBI) as a security measure within FL environments. By\nleveraging IBI, we enable FL systems to authenticate clients based on\ncryptographic identity schemes, effectively preventing previously disconnected\nmalicious clients from re-entering the system. Our approach is implemented\nusing the TNC-IBI (Tan-Ng-Chin) scheme over elliptic curves to ensure\ncomputational efficiency, particularly in resource-constrained environments\nlike Internet of Things (IoT). Experimental results demonstrate that\nintegrating IBI with secure aggregation algorithms, such as Krum and Trimmed\nMean, significantly improves FL robustness by mitigating the impact of RMCs. We\nfurther discuss the broader implications of IBI in FL security, highlighting\nresearch directions for adaptive adversary detection, reputation-based\nmechanisms, and the applicability of identity-based cryptographic frameworks in\ndecentralized FL architectures. Our findings advocate for a holistic approach\nto FL security, emphasizing the necessity of proactive defence strategies\nagainst evolving adaptive adversarial threats.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "10 pages, 5 figures, research article, IEEE possible publication (in\n  submission)",
    "pdf_url": "http://arxiv.org/pdf/2504.03077v1",
    "published_date": "2025-04-03 22:58:27 UTC",
    "updated_date": "2025-04-03 22:58:27 UTC"
  },
  {
    "arxiv_id": "2504.03071v1",
    "title": "AD-GPT: Large Language Models in Alzheimer's Disease",
    "authors": [
      "Ziyu Liu",
      "Lintao Tang",
      "Zeliang Sun",
      "Zhengliang Liu",
      "Yanjun Lyu",
      "Wei Ruan",
      "Yangshuang Xu",
      "Liang Shan",
      "Jiyoon Shin",
      "Xiaohe Chen",
      "Dajiang Zhu",
      "Tianming Liu",
      "Rongjie Liu",
      "Chao Huang"
    ],
    "abstract": "Large language models (LLMs) have emerged as powerful tools for medical\ninformation retrieval, yet their accuracy and depth remain limited in\nspecialized domains such as Alzheimer's disease (AD), a growing global health\nchallenge. To address this gap, we introduce AD-GPT, a domain-specific\ngenerative pre-trained transformer designed to enhance the retrieval and\nanalysis of AD-related genetic and neurobiological information. AD-GPT\nintegrates diverse biomedical data sources, including potential AD-associated\ngenes, molecular genetic information, and key gene variants linked to brain\nregions. We develop a stacked LLM architecture combining Llama3 and BERT,\noptimized for four critical tasks in AD research: (1) genetic information\nretrieval, (2) gene-brain region relationship assessment, (3) gene-AD\nrelationship analysis, and (4) brain region-AD relationship mapping.\nComparative evaluations against state-of-the-art LLMs demonstrate AD-GPT's\nsuperior precision and reliability across these tasks, underscoring its\npotential as a robust and specialized AI tool for advancing AD research and\nbiomarker discovery.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03071v1",
    "published_date": "2025-04-03 22:49:10 UTC",
    "updated_date": "2025-04-03 22:49:10 UTC"
  },
  {
    "arxiv_id": "2504.03069v1",
    "title": "Properties of Fixed Points of Generalised Extra Gradient Methods Applied to Min-Max Problems",
    "authors": [
      "Amir Ali Farzin",
      "Yuen-Man Pun",
      "Philipp Braun",
      "Iman Shames"
    ],
    "abstract": "This paper studies properties of fixed points of generalised Extra-gradient\n(GEG) algorithms applied to min-max problems. We discuss connections between\nsaddle points of the objective function of the min-max problem and GEG fixed\npoints. We show that, under appropriate step-size selections, the set of saddle\npoints (Nash equilibria) is a subset of stable fixed points of GEG. Convergence\nproperties of the GEG algorithm are obtained through a stability analysis of a\ndiscrete-time dynamical system. The results and benefits when compared to\nexisting methods are illustrated through numerical examples.",
    "categories": [
      "math.OC",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "math.OC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03069v1",
    "published_date": "2025-04-03 22:48:39 UTC",
    "updated_date": "2025-04-03 22:48:39 UTC"
  },
  {
    "arxiv_id": "2504.03068v2",
    "title": "Design of AI-Powered Tool for Self-Regulation Support in Programming Education",
    "authors": [
      "Huiyong Li",
      "Boxuan Ma"
    ],
    "abstract": "Large Language Model (LLM) tools have demonstrated their potential to deliver\nhigh-quality assistance by providing instant, personalized feedback that is\ncrucial for effective programming education. However, many of these tools\noperate independently from institutional Learning Management Systems, which\ncreates a significant disconnect. This isolation limits the ability to leverage\nlearning materials and exercise context for generating tailored, context-aware\nfeedback. Furthermore, previous research on self-regulated learning and LLM\nsupport mainly focused on knowledge acquisition, not the development of\nimportant self-regulation skills. To address these challenges, we developed\nCodeRunner Agent, an LLM-based programming assistant that integrates the\nCodeRunner, a student-submitted code executing and automated grading plugin in\nMoodle. CodeRunner Agent empowers educators to customize AI-generated feedback\nby incorporating detailed context from lecture materials, programming\nquestions, student answers, and execution results. Additionally, it enhances\nstudents' self-regulated learning by providing strategy-based AI responses.\nThis integrated, context-aware, and skill-focused approach offers promising\navenues for data-driven improvements in programming education.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03068v2",
    "published_date": "2025-04-03 22:47:33 UTC",
    "updated_date": "2025-04-07 01:30:12 UTC"
  },
  {
    "arxiv_id": "2504.03064v1",
    "title": "Context-Aware Self-Adaptation for Domain Generalization",
    "authors": [
      "Hao Yan",
      "Yuhong Guo"
    ],
    "abstract": "Domain generalization aims at developing suitable learning algorithms in\nsource training domains such that the model learned can generalize well on a\ndifferent unseen testing domain. We present a novel two-stage approach called\nContext-Aware Self-Adaptation (CASA) for domain generalization. CASA simulates\nan approximate meta-generalization scenario and incorporates a self-adaptation\nmodule to adjust pre-trained meta source models to the meta-target domains\nwhile maintaining their predictive capability on the meta-source domains. The\ncore concept of self-adaptation involves leveraging contextual information,\nsuch as the mean of mini-batch features, as domain knowledge to automatically\nadapt a model trained in the first stage to new contexts in the second stage.\nLastly, we utilize an ensemble of multiple meta-source models to perform\ninference on the testing domain. Experimental results demonstrate that our\nproposed method achieves state-of-the-art performance on standard benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICML 2023 AdvML Frontiers workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.03064v1",
    "published_date": "2025-04-03 22:33:38 UTC",
    "updated_date": "2025-04-03 22:33:38 UTC"
  },
  {
    "arxiv_id": "2504.03052v1",
    "title": "Cooperative Inference for Real-Time 3D Human Pose Estimation in Multi-Device Edge Networks",
    "authors": [
      "Hyun-Ho Choi",
      "Kangsoo Kim",
      "Ki-Ho Lee",
      "Kisong Lee"
    ],
    "abstract": "Accurate and real-time three-dimensional (3D) pose estimation is challenging\nin resource-constrained and dynamic environments owing to its high\ncomputational complexity. To address this issue, this study proposes a novel\ncooperative inference method for real-time 3D human pose estimation in mobile\nedge computing (MEC) networks. In the proposed method, multiple end devices\nequipped with lightweight inference models employ dual confidence thresholds to\nfilter ambiguous images. Only the filtered images are offloaded to an edge\nserver with a more powerful inference model for re-evaluation, thereby\nimproving the estimation accuracy under computational and communication\nconstraints. We numerically analyze the performance of the proposed inference\nmethod in terms of the inference accuracy and end-to-end delay and formulate a\njoint optimization problem to derive the optimal confidence thresholds and\ntransmission time for each device, with the objective of minimizing the mean\nper-joint position error (MPJPE) while satisfying the required end-to-end delay\nconstraint. To solve this problem, we demonstrate that minimizing the MPJPE is\nequivalent to maximizing the sum of the inference accuracies for all devices,\ndecompose the problem into manageable subproblems, and present a low-complexity\noptimization algorithm to obtain a near-optimal solution. The experimental\nresults show that a trade-off exists between the MPJPE and end-to-end delay\ndepending on the confidence thresholds. Furthermore, the results confirm that\nthe proposed cooperative inference method achieves a significant reduction in\nthe MPJPE through the optimal selection of confidence thresholds and\ntransmission times, while consistently satisfying the end-to-end delay\nrequirement in various MEC environments.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 12 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.03052v1",
    "published_date": "2025-04-03 21:58:29 UTC",
    "updated_date": "2025-04-03 21:58:29 UTC"
  },
  {
    "arxiv_id": "2504.03051v1",
    "title": "Task as Context Prompting for Accurate Medical Symptom Coding Using Large Language Models",
    "authors": [
      "Chengyang He",
      "Wenlong Zhang",
      "Violet Xinying Chen",
      "Yue Ning",
      "Ping Wang"
    ],
    "abstract": "Accurate medical symptom coding from unstructured clinical text, such as\nvaccine safety reports, is a critical task with applications in\npharmacovigilance and safety monitoring. Symptom coding, as tailored in this\nstudy, involves identifying and linking nuanced symptom mentions to\nstandardized vocabularies like MedDRA, differentiating it from broader medical\ncoding tasks. Traditional approaches to this task, which treat symptom\nextraction and linking as independent workflows, often fail to handle the\nvariability and complexity of clinical narratives, especially for rare cases.\nRecent advancements in Large Language Models (LLMs) offer new opportunities but\nface challenges in achieving consistent performance. To address these issues,\nwe propose Task as Context (TACO) Prompting, a novel framework that unifies\nextraction and linking tasks by embedding task-specific context into LLM\nprompts. Our study also introduces SYMPCODER, a human-annotated dataset derived\nfrom Vaccine Adverse Event Reporting System (VAERS) reports, and a two-stage\nevaluation framework to comprehensively assess both symptom linking and mention\nfidelity. Our comprehensive evaluation of multiple LLMs, including Llama2-chat,\nJackalope-7b, GPT-3.5 Turbo, GPT-4 Turbo, and GPT-4o, demonstrates TACO's\neffectiveness in improving flexibility and accuracy for tailored tasks like\nsymptom coding, paving the way for more specific coding tasks and advancing\nclinical text processing methodologies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 5 figures, 5 Tables, ACM/IEEE International Conference on\n  Connected Health: Applications, Systems and Engineering Technologies (CHASE\n  '25), June 24--26, 2025, New York, NY, USA",
    "pdf_url": "http://arxiv.org/pdf/2504.03051v1",
    "published_date": "2025-04-03 21:57:17 UTC",
    "updated_date": "2025-04-03 21:57:17 UTC"
  },
  {
    "arxiv_id": "2504.03040v1",
    "title": "Safety Modulation: Enhancing Safety in Reinforcement Learning through Cost-Modulated Rewards",
    "authors": [
      "Hanping Zhang",
      "Yuhong Guo"
    ],
    "abstract": "Safe Reinforcement Learning (Safe RL) aims to train an RL agent to maximize\nits performance in real-world environments while adhering to safety\nconstraints, as exceeding safety violation limits can result in severe\nconsequences. In this paper, we propose a novel safe RL approach called Safety\nModulated Policy Optimization (SMPO), which enables safe policy function\nlearning within the standard policy optimization framework through safety\nmodulated rewards. In particular, we consider safety violation costs as\nfeedback from the RL environments that are parallel to the standard awards, and\nintroduce a Q-cost function as safety critic to estimate expected future\ncumulative costs. Then we propose to modulate the rewards using a cost-aware\nweighting function, which is carefully designed to ensure the safety limits\nbased on the estimation of the safety critic, while maximizing the expected\nrewards. The policy function and the safety critic are simultaneously learned\nthrough gradient descent during online interactions with the environment. We\nconduct experiments using multiple RL environments and the experimental results\ndemonstrate that our method outperforms several classic and state-of-the-art\ncomparison methods in terms of overall safe RL performance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03040v1",
    "published_date": "2025-04-03 21:35:22 UTC",
    "updated_date": "2025-04-03 21:35:22 UTC"
  },
  {
    "arxiv_id": "2504.08775v1",
    "title": "Layers at Similar Depths Generate Similar Activations Across LLM Architectures",
    "authors": [
      "Christopher Wolfram",
      "Aaron Schein"
    ],
    "abstract": "How do the latent spaces used by independently-trained LLMs relate to one\nanother? We study the nearest neighbor relationships induced by activations at\ndifferent layers of 24 open-weight LLMs, and find that they 1) tend to vary\nfrom layer to layer within a model, and 2) are approximately shared between\ncorresponding layers of different models. Claim 2 shows that these nearest\nneighbor relationships are not arbitrary, as they are shared across models, but\nClaim 1 shows that they are not \"obvious\" either, as there is no single set of\nnearest neighbor relationships that is universally shared. Together, these\nsuggest that LLMs generate a progression of activation geometries from layer to\nlayer, but that this entire progression is largely shared between models,\nstretched and squeezed to fit into different architectures.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.08775v1",
    "published_date": "2025-04-03 21:02:30 UTC",
    "updated_date": "2025-04-03 21:02:30 UTC"
  },
  {
    "arxiv_id": "2504.03024v1",
    "title": "Deep Reinforcement Learning via Object-Centric Attention",
    "authors": [
      "Jannis Blüml",
      "Cedric Derstroff",
      "Bjarne Gregori",
      "Elisabeth Dillies",
      "Quentin Delfosse",
      "Kristian Kersting"
    ],
    "abstract": "Deep reinforcement learning agents, trained on raw pixel inputs, often fail\nto generalize beyond their training environments, relying on spurious\ncorrelations and irrelevant background details. To address this issue,\nobject-centric agents have recently emerged. However, they require different\nrepresentations tailored to the task specifications. Contrary to deep agents,\nno single object-centric architecture can be applied to any environment.\nInspired by principles of cognitive science and Occam's Razor, we introduce\nObject-Centric Attention via Masking (OCCAM), which selectively preserves\ntask-relevant entities while filtering out irrelevant visual information.\nSpecifically, OCCAM takes advantage of the object-centric inductive bias.\nEmpirical evaluations on Atari benchmarks demonstrate that OCCAM significantly\nimproves robustness to novel perturbations and reduces sample complexity while\nshowing similar or improved performance compared to conventional pixel-based\nRL. These results suggest that structured abstraction can enhance\ngeneralization without requiring explicit symbolic representations or\ndomain-specific object extraction pipelines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "26 pages, 11 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.03024v1",
    "published_date": "2025-04-03 20:48:27 UTC",
    "updated_date": "2025-04-03 20:48:27 UTC"
  },
  {
    "arxiv_id": "2504.03022v1",
    "title": "The Dual-Route Model of Induction",
    "authors": [
      "Sheridan Feucht",
      "Eric Todd",
      "Byron Wallace",
      "David Bau"
    ],
    "abstract": "Prior work on in-context copying has shown the existence of induction heads,\nwhich attend to and promote individual tokens during copying. In this work we\nintroduce a new type of induction head: concept-level induction heads, which\ncopy entire lexical units instead of individual tokens. Concept induction heads\nlearn to attend to the ends of multi-token words throughout training, working\nin parallel with token-level induction heads to copy meaningful text. We show\nthat these heads are responsible for semantic tasks like word-level\ntranslation, whereas token induction heads are vital for tasks that can only be\ndone verbatim, like copying nonsense tokens. These two \"routes\" operate\nindependently: in fact, we show that ablation of token induction heads causes\nmodels to paraphrase where they would otherwise copy verbatim. In light of\nthese findings, we argue that although token induction heads are vital for\nspecific tasks, concept induction heads may be more broadly relevant for\nin-context learning.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7"
    ],
    "primary_category": "cs.CL",
    "comment": "36 pages, 39 figures. Code and data at https://dualroute.baulab.info",
    "pdf_url": "http://arxiv.org/pdf/2504.03022v1",
    "published_date": "2025-04-03 20:40:31 UTC",
    "updated_date": "2025-04-03 20:40:31 UTC"
  },
  {
    "arxiv_id": "2504.02984v1",
    "title": "Language Models Guidance with Multi-Aspect-Cueing: A Case Study for Competitor Analysis",
    "authors": [
      "Amir Hadifar",
      "Christopher Ochs",
      "Arjan Van Ewijk"
    ],
    "abstract": "Competitor analysis is essential in modern business due to the influence of\nindustry rivals on strategic planning. It involves assessing multiple aspects\nand balancing trade-offs to make informed decisions. Recent Large Language\nModels (LLMs) have demonstrated impressive capabilities to reason about such\ntrade-offs but grapple with inherent limitations such as a lack of knowledge\nabout contemporary or future realities and an incomplete understanding of a\nmarket's competitive landscape. In this paper, we address this gap by\nincorporating business aspects into LLMs to enhance their understanding of a\ncompetitive market. Through quantitative and qualitative experiments, we\nillustrate how integrating such aspects consistently improves model\nperformance, thereby enhancing analytical efficacy in competitor analysis.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02984v1",
    "published_date": "2025-04-03 19:18:11 UTC",
    "updated_date": "2025-04-03 19:18:11 UTC"
  },
  {
    "arxiv_id": "2504.02976v1",
    "title": "Localized Definitions and Distributed Reasoning: A Proof-of-Concept Mechanistic Interpretability Study via Activation Patching",
    "authors": [
      "Nooshin Bahador"
    ],
    "abstract": "This study investigates the localization of knowledge representation in\nfine-tuned GPT-2 models using Causal Layer Attribution via Activation Patching\n(CLAP), a method that identifies critical neural layers responsible for correct\nanswer generation. The model was fine-tuned on 9,958 PubMed abstracts\n(epilepsy: 20,595 mentions, EEG: 11,674 mentions, seizure: 13,921 mentions)\nusing two configurations with validation loss monitoring for early stopping.\nCLAP involved (1) caching clean (correct answer) and corrupted (incorrect\nanswer) activations, (2) computing logit difference to quantify model\npreference, and (3) patching corrupted activations with clean ones to assess\nrecovery. Results revealed three findings: First, patching the first\nfeedforward layer recovered 56% of correct preference, demonstrating that\nassociative knowledge is distributed across multiple layers. Second, patching\nthe final output layer completely restored accuracy (100% recovery), indicating\nthat definitional knowledge is localised. The stronger clean logit difference\nfor definitional questions further supports this localized representation.\nThird, minimal recovery from convolutional layer patching (13.6%) suggests\nlow-level features contribute marginally to high-level reasoning. Statistical\nanalysis confirmed significant layer-specific effects (p<0.01). These findings\ndemonstrate that factual knowledge is more localized and associative knowledge\ndepends on distributed representations. We also showed that editing efficacy\ndepends on task type. Our findings not only reconcile conflicting observations\nabout localization in model editing but also emphasize on using task-adaptive\ntechniques for reliable, interpretable updates.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02976v1",
    "published_date": "2025-04-03 18:54:50 UTC",
    "updated_date": "2025-04-03 18:54:50 UTC"
  },
  {
    "arxiv_id": "2504.02972v1",
    "title": "Improved Compact Genetic Algorithms with Efficient Caching",
    "authors": [
      "Prasanta Dutta",
      "Anirban Mukhopadhyay"
    ],
    "abstract": "Compact Genetic Algorithms (cGAs) are condensed variants of classical Genetic\nAlgorithms (GAs) that use a probability vector representation of the population\ninstead of the complete population. cGAs have been shown to significantly\nreduce the number of function evaluations required while producing outcomes\nsimilar to those of classical GAs. However, cGAs have a tendency to repeatedly\ngenerate the same chromosomes as they approach convergence, resulting in\nunnecessary evaluations of identical chromosomes. This article introduces the\nconcept of caching in cGAs as a means of avoiding redundant evaluations of the\nsame chromosomes. Our proposed approach operates equivalently to cGAs, but\nenhances the algorithm's time efficiency by reducing the number of function\nevaluations. We also present a data structure for efficient cache maintenance\nto ensure low overhead. The proposed caching approach has an asymptotically\nconstant time complexity on average. The proposed method further generalizes\nthe caching mechanism with higher selection pressure for elitism-based cGAs. We\nconduct a rigorous analysis based on experiments on benchmark optimization\nproblems using two well-known cache replacement strategies. The results\ndemonstrate that caching significantly reduces the number of function\nevaluations required while maintaining the same level of performance accuracy.",
    "categories": [
      "cs.NE",
      "cs.AI"
    ],
    "primary_category": "cs.NE",
    "comment": "13 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.02972v1",
    "published_date": "2025-04-03 18:47:26 UTC",
    "updated_date": "2025-04-03 18:47:26 UTC"
  },
  {
    "arxiv_id": "2505.13453v1",
    "title": "Pel, A Programming Language for Orchestrating AI Agents",
    "authors": [
      "Behnam Mohammadi"
    ],
    "abstract": "The proliferation of Large Language Models (LLMs) has opened new frontiers in\ncomputing, yet controlling and orchestrating their capabilities beyond simple\ntext generation remains a challenge. Current methods, such as function/tool\ncalling and direct code generation, suffer from limitations in expressiveness,\nscalability, cost, security, and the ability to enforce fine-grained control.\nThis paper introduces Pel, a novel programming language specifically designed\nto bridge this gap. Inspired by the strengths of Lisp, Elixir, Gleam, and\nHaskell, Pel provides a syntactically simple, homoiconic, and semantically rich\nplatform for LLMs to express complex actions, control flow, and inter-agent\ncommunication safely and efficiently. Pel's design emphasizes a minimal, easily\nmodifiable grammar suitable for constrained LLM generation, eliminating the\nneed for complex sandboxing by enabling capability control at the syntax level.\nKey features include a powerful piping mechanism for linear composition,\nfirst-class closures enabling easy partial application and functional patterns,\nbuilt-in support for natural language conditions evaluated by LLMs, and an\nadvanced Read-Eval-Print-Loop (REPeL) with Common Lisp-style restarts and\nLLM-powered helper agents for automated error correction. Furthermore, Pel\nincorporates automatic parallelization of independent operations via static\ndependency analysis, crucial for performant agentic systems. We argue that Pel\noffers a more robust, secure, and expressive paradigm for LLM orchestration,\npaving the way for more sophisticated and reliable AI agentic frameworks.",
    "categories": [
      "cs.PL",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "cs.PL",
    "comment": "Added relevant figures and the section 4.5",
    "pdf_url": "http://arxiv.org/pdf/2505.13453v1",
    "published_date": "2025-04-03 18:46:53 UTC",
    "updated_date": "2025-04-03 18:46:53 UTC"
  },
  {
    "arxiv_id": "2504.02968v1",
    "title": "Global-Order GFlowNets",
    "authors": [
      "Lluís Pastor-Pérez",
      "Javier Alonso-Garcia",
      "Lukas Mauch"
    ],
    "abstract": "Order-Preserving (OP) GFlowNets have demonstrated remarkable success in\ntackling complex multi-objective (MOO) black-box optimization problems using\nstochastic optimization techniques. Specifically, they can be trained online to\nefficiently sample diverse candidates near the Pareto front. A key advantage of\nOP GFlowNets is their ability to impose a local order on training samples based\non Pareto dominance, eliminating the need for scalarization - a common\nrequirement in other approaches like Preference-Conditional GFlowNets. However,\nwe identify an important limitation of OP GFlowNets: imposing a local order on\ntraining samples can lead to conflicting optimization objectives. To address\nthis issue, we introduce Global-Order GFlowNets, which transform the local\norder into a global one, thereby resolving these conflicts. Our experimental\nevaluations on various benchmarks demonstrate the efficacy and promise of our\nproposed method.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages, ICLR 2025 Workshop format",
    "pdf_url": "http://arxiv.org/pdf/2504.02968v1",
    "published_date": "2025-04-03 18:43:52 UTC",
    "updated_date": "2025-04-03 18:43:52 UTC"
  },
  {
    "arxiv_id": "2504.02965v2",
    "title": "CoLa -- Learning to Interactively Collaborate with Large LMs",
    "authors": [
      "Abhishek Sharma",
      "Dan Goldwasser"
    ],
    "abstract": "LLMs' remarkable ability to tackle a wide range of language tasks opened new\nopportunities for collaborative human-AI problem solving. LLMs can amplify\nhuman capabilities by applying their intuitions and reasoning strategies at\nscale. We explore whether human guides can be simulated, by generalizing from\nhuman demonstrations of guiding an AI system to solve complex language\nproblems. We introduce CoLa, a novel self-guided learning paradigm for training\nautomated $\\textit{guides}$ and evaluate it on two QA datasets, a\npuzzle-solving task, and a constrained text generation task. Our empirical\nresults show that CoLa consistently outperforms competitive approaches across\nall domains. Moreover, a small-sized trained guide outperforms a strong model\nlike GPT-4 when acting as a guide. We compare the strategies employed by humans\nand automated guides by conducting a human study on a QA dataset. We show that\nautomated guides outperform humans by adapting their strategies to reasoners'\ncapabilities and conduct qualitative analyses highlighting distinct differences\nin guiding strategies.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02965v2",
    "published_date": "2025-04-03 18:34:36 UTC",
    "updated_date": "2025-04-07 01:08:58 UTC"
  },
  {
    "arxiv_id": "2504.02963v1",
    "title": "Digital Forensics in the Age of Large Language Models",
    "authors": [
      "Zhipeng Yin",
      "Zichong Wang",
      "Weifeng Xu",
      "Jun Zhuang",
      "Pallab Mozumder",
      "Antoinette Smith",
      "Wenbin Zhang"
    ],
    "abstract": "Digital forensics plays a pivotal role in modern investigative processes,\nutilizing specialized methods to systematically collect, analyze, and interpret\ndigital evidence for judicial proceedings. However, traditional digital\nforensic techniques are primarily based on manual labor-intensive processes,\nwhich become increasingly insufficient with the rapid growth and complexity of\ndigital data. To this end, Large Language Models (LLMs) have emerged as\npowerful tools capable of automating and enhancing various digital forensic\ntasks, significantly transforming the field. Despite the strides made, general\npractitioners and forensic experts often lack a comprehensive understanding of\nthe capabilities, principles, and limitations of LLM, which limits the full\npotential of LLM in forensic applications. To fill this gap, this paper aims to\nprovide an accessible and systematic overview of how LLM has revolutionized the\ndigital forensics approach. Specifically, it takes a look at the basic concepts\nof digital forensics, as well as the evolution of LLM, and emphasizes the\nsuperior capabilities of LLM. To connect theory and practice, relevant examples\nand real-world scenarios are discussed. We also critically analyze the current\nlimitations of applying LLMs to digital forensics, including issues related to\nillusion, interpretability, bias, and ethical considerations. In addition, this\npaper outlines the prospects for future research, highlighting the need for\neffective use of LLMs for transparency, accountability, and robust\nstandardization in the forensic process.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02963v1",
    "published_date": "2025-04-03 18:32:15 UTC",
    "updated_date": "2025-04-03 18:32:15 UTC"
  },
  {
    "arxiv_id": "2504.02962v1",
    "title": "Level Up Peer Review in Education: Investigating genAI-driven Gamification system and its influence on Peer Feedback Effectiveness",
    "authors": [
      "Rafal Wlodarski",
      "Leonardo da Silva Sousa",
      "Allison Connell Pensky"
    ],
    "abstract": "In software engineering (SE), the ability to review code and critique designs\nis essential for professional practice. However, these skills are rarely\nemphasized in formal education, and peer feedback quality and engagement can\nvary significantly among students. This paper introduces Socratique, a gamified\npeer-assessment platform integrated with Generative AI (GenAI) assistance,\ndesigned to develop students' peer-review skills in a functional programming\ncourse. By incorporating game elements, Socratique aims to motivate students to\nprovide more feedback, while the GenAI assistant offers real-time support in\ncrafting high quality, constructive comments. To evaluate the impact of this\napproach, we conducted a randomized controlled experiment with master's\nstudents comparing a treatment group with a gamified, GenAI-driven setup\nagainst a control group with minimal gamification. Results show that students\nin the treatment group provided significantly more voluntary feedback, with\nhigher scores on clarity, relevance, and specificity - all key aspects of\neffective code and design reviews. This study provides evidence for the\neffectiveness of combining gamification and AI to improve peer review\nprocesses, with implications for fostering review-related competencies in\nsoftware engineering curricula.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02962v1",
    "published_date": "2025-04-03 18:30:25 UTC",
    "updated_date": "2025-04-03 18:30:25 UTC"
  },
  {
    "arxiv_id": "2504.02949v1",
    "title": "VARGPT-v1.1: Improve Visual Autoregressive Large Unified Model via Iterative Instruction Tuning and Reinforcement Learning",
    "authors": [
      "Xianwei Zhuang",
      "Yuxin Xie",
      "Yufan Deng",
      "Dongchao Yang",
      "Liming Liang",
      "Jinghan Ru",
      "Yuguo Yin",
      "Yuexian Zou"
    ],
    "abstract": "In this work, we present VARGPT-v1.1, an advanced unified visual\nautoregressive model that builds upon our previous framework VARGPT. The model\npreserves the dual paradigm of next-token prediction for visual understanding\nand next-scale generation for image synthesis. Specifically, VARGPT-v1.1\nintegrates: (1) a novel training strategy combining iterative visual\ninstruction tuning with reinforcement learning through Direct Preference\nOptimization (DPO), (2) an expanded training corpus containing 8.3M\nvisual-generative instruction pairs, (3) an upgraded language model backbone\nusing Qwen2, (4) enhanced image generation resolution, and (5) emergent image\nediting capabilities without architectural modifications. These advancements\nenable VARGPT-v1.1 to achieve state-of-the-art performance in multimodal\nunderstanding and text-to-image instruction-following tasks, demonstrating\nsignificant improvements in both comprehension and generation metrics. Notably,\nthrough visual instruction tuning, the model acquires image editing\nfunctionality while maintaining architectural consistency with its predecessor,\nrevealing the potential for unified visual understanding, generation, and\nediting. Our findings suggest that well-designed unified visual autoregressive\nmodels can effectively adopt flexible training strategies from large language\nmodels (LLMs), exhibiting promising scalability. The codebase and model weights\nare publicly available at https://github.com/VARGPT-family/VARGPT-v1.1.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Code is available at: https://github.com/VARGPT-family/VARGPT-v1.1.\n  arXiv admin note: text overlap with arXiv:2501.12327",
    "pdf_url": "http://arxiv.org/pdf/2504.02949v1",
    "published_date": "2025-04-03 18:06:28 UTC",
    "updated_date": "2025-04-03 18:06:28 UTC"
  },
  {
    "arxiv_id": "2504.02938v1",
    "title": "Graph Attention for Heterogeneous Graphs with Positional Encoding",
    "authors": [
      "Nikhil Shivakumar Nayak"
    ],
    "abstract": "Graph Neural Networks (GNNs) have emerged as the de facto standard for\nmodeling graph data, with attention mechanisms and transformers significantly\nenhancing their performance on graph-based tasks. Despite these advancements,\nthe performance of GNNs on heterogeneous graphs often remains complex, with\nnetworks generally underperforming compared to their homogeneous counterparts.\nThis work benchmarks various GNN architectures to identify the most effective\nmethods for heterogeneous graphs, with a particular focus on node\nclassification and link prediction. Our findings reveal that graph attention\nnetworks excel in these tasks. As a main contribution, we explore enhancements\nto these attention networks by integrating positional encodings for node\nembeddings. This involves utilizing the full Laplacian spectrum to accurately\ncapture both the relative and absolute positions of each node within the graph,\nfurther enhancing performance on downstream tasks such as node classification\nand link prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DM",
      "math.DG",
      "stat.ML",
      "53-02",
      "G.2.2; I.2.0; I.2.4; G.3"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02938v1",
    "published_date": "2025-04-03 18:00:02 UTC",
    "updated_date": "2025-04-03 18:00:02 UTC"
  },
  {
    "arxiv_id": "2504.02828v1",
    "title": "Concept Lancet: Image Editing with Compositional Representation Transplant",
    "authors": [
      "Jinqi Luo",
      "Tianjiao Ding",
      "Kwan Ho Ryan Chan",
      "Hancheng Min",
      "Chris Callison-Burch",
      "René Vidal"
    ],
    "abstract": "Diffusion models are widely used for image editing tasks. Existing editing\nmethods often design a representation manipulation procedure by curating an\nedit direction in the text embedding or score space. However, such a procedure\nfaces a key challenge: overestimating the edit strength harms visual\nconsistency while underestimating it fails the editing task. Notably, each\nsource image may require a different editing strength, and it is costly to\nsearch for an appropriate strength via trial-and-error. To address this\nchallenge, we propose Concept Lancet (CoLan), a zero-shot plug-and-play\nframework for principled representation manipulation in diffusion-based image\nediting. At inference time, we decompose the source input in the latent (text\nembedding or diffusion score) space as a sparse linear combination of the\nrepresentations of the collected visual concepts. This allows us to accurately\nestimate the presence of concepts in each image, which informs the edit. Based\non the editing task (replace/add/remove), we perform a customized concept\ntransplant process to impose the corresponding editing direction. To\nsufficiently model the concept space, we curate a conceptual representation\ndataset, CoLan-150K, which contains diverse descriptions and scenarios of\nvisual terms and phrases for the latent dictionary. Experiments on multiple\ndiffusion-based image editing baselines show that methods equipped with CoLan\nachieve state-of-the-art performance in editing effectiveness and consistency\npreservation.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted in CVPR 2025. Project page at\n  https://peterljq.github.io/project/colan",
    "pdf_url": "http://arxiv.org/pdf/2504.02828v1",
    "published_date": "2025-04-03 17:59:58 UTC",
    "updated_date": "2025-04-03 17:59:58 UTC"
  },
  {
    "arxiv_id": "2504.02827v1",
    "title": "On Vanishing Variance in Transformer Length Generalization",
    "authors": [
      "Ruining Li",
      "Gabrijel Boduljak",
      "Jensen",
      "Zhou"
    ],
    "abstract": "It is a widely known issue that Transformers, when trained on shorter\nsequences, fail to generalize robustly to longer ones at test time. This raises\nthe question of whether Transformer models are real reasoning engines, despite\ntheir impressive abilities in mathematical problem solving and code synthesis.\nIn this paper, we offer a vanishing variance perspective on this issue. To the\nbest of our knowledge, we are the first to demonstrate that even for today's\nfrontier models, a longer sequence length results in a decrease in variance in\nthe output of the multi-head attention modules. On the argmax retrieval and\ndictionary lookup tasks, our experiments show that applying layer normalization\nafter the attention outputs leads to significantly better length\ngeneralization. Our analyses attribute this improvement to a reduction-though\nnot a complete elimination-of the distribution shift caused by vanishing\nvariance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Project page: https://ruiningli.com/vanishing-variance. The first two\n  authors contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2504.02827v1",
    "published_date": "2025-04-03 17:59:56 UTC",
    "updated_date": "2025-04-03 17:59:56 UTC"
  },
  {
    "arxiv_id": "2504.02822v1",
    "title": "Do Two AI Scientists Agree?",
    "authors": [
      "Xinghong Fu",
      "Ziming Liu",
      "Max Tegmark"
    ],
    "abstract": "When two AI models are trained on the same scientific task, do they learn the\nsame theory or two different theories? Throughout history of science, we have\nwitnessed the rise and fall of theories driven by experimental validation or\nfalsification: many theories may co-exist when experimental data is lacking,\nbut the space of survived theories become more constrained with more\nexperimental data becoming available. We show the same story is true for AI\nscientists. With increasingly more systems provided in training data, AI\nscientists tend to converge in the theories they learned, although sometimes\nthey form distinct groups corresponding to different theories. To\nmechanistically interpret what theories AI scientists learn and quantify their\nagreement, we propose MASS, Hamiltonian-Lagrangian neural networks as AI\nScientists, trained on standard problems in physics, aggregating training\nresults across many seeds simulating the different configurations of AI\nscientists. Our findings suggests for AI scientists switch from learning a\nHamiltonian theory in simple setups to a Lagrangian formulation when more\ncomplex systems are introduced. We also observe strong seed dependence of the\ntraining dynamics and final learned weights, controlling the rise and fall of\nrelevant theories. We finally demonstrate that not only can our neural networks\naid interpretability, it can also be applied to higher dimensional problems.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02822v1",
    "published_date": "2025-04-03 17:58:44 UTC",
    "updated_date": "2025-04-03 17:58:44 UTC"
  },
  {
    "arxiv_id": "2504.02821v1",
    "title": "Sparse Autoencoders Learn Monosemantic Features in Vision-Language Models",
    "authors": [
      "Mateusz Pach",
      "Shyamgopal Karthik",
      "Quentin Bouniot",
      "Serge Belongie",
      "Zeynep Akata"
    ],
    "abstract": "Sparse Autoencoders (SAEs) have recently been shown to enhance\ninterpretability and steerability in Large Language Models (LLMs). In this\nwork, we extend the application of SAEs to Vision-Language Models (VLMs), such\nas CLIP, and introduce a comprehensive framework for evaluating monosemanticity\nin vision representations. Our experimental results reveal that SAEs trained on\nVLMs significantly enhance the monosemanticity of individual neurons while also\nexhibiting hierarchical representations that align well with expert-defined\nstructures (e.g., iNaturalist taxonomy). Most notably, we demonstrate that\napplying SAEs to intervene on a CLIP vision encoder, directly steer output from\nmultimodal LLMs (e.g., LLaVA) without any modifications to the underlying\nmodel. These findings emphasize the practicality and efficacy of SAEs as an\nunsupervised approach for enhancing both the interpretability and control of\nVLMs.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Preprint. The code is available at\n  https://github.com/ExplainableML/sae-for-vlm",
    "pdf_url": "http://arxiv.org/pdf/2504.02821v1",
    "published_date": "2025-04-03 17:58:35 UTC",
    "updated_date": "2025-04-03 17:58:35 UTC"
  },
  {
    "arxiv_id": "2504.02819v1",
    "title": "GMR-Conv: An Efficient Rotation and Reflection Equivariant Convolution Kernel Using Gaussian Mixture Rings",
    "authors": [
      "Yuexi Du",
      "Jiazhen Zhang",
      "Nicha C. Dvornek",
      "John A. Onofrey"
    ],
    "abstract": "Symmetry, where certain features remain invariant under geometric\ntransformations, can often serve as a powerful prior in designing convolutional\nneural networks (CNNs). While conventional CNNs inherently support\ntranslational equivariance, extending this property to rotation and reflection\nhas proven challenging, often forcing a compromise between equivariance,\nefficiency, and information loss. In this work, we introduce Gaussian Mixture\nRing Convolution (GMR-Conv), an efficient convolution kernel that smooths\nradial symmetry using a mixture of Gaussian-weighted rings. This design\nmitigates discretization errors of circular kernels, thereby preserving robust\nrotation and reflection equivariance without incurring computational overhead.\nWe further optimize both the space and speed efficiency of GMR-Conv via a novel\nparameterization and computation strategy, allowing larger kernels at an\nacceptable cost. Extensive experiments on eight classification and one\nsegmentation datasets demonstrate that GMR-Conv not only matches conventional\nCNNs' performance but can also surpass it in applications with orientation-less\ndata. GMR-Conv is also proven to be more robust and efficient than the\nstate-of-the-art equivariant learning methods. Our work provides inspiring\nempirical evidence that carefully applied radial symmetry can alleviate the\nchallenges of information loss, marking a promising advance in equivariant\nnetwork architectures. The code is available at\nhttps://github.com/XYPB/GMR-Conv.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "eess.IV",
      "eess.SP"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02819v1",
    "published_date": "2025-04-03 17:58:18 UTC",
    "updated_date": "2025-04-03 17:58:18 UTC"
  },
  {
    "arxiv_id": "2504.02810v2",
    "title": "Generative Evaluation of Complex Reasoning in Large Language Models",
    "authors": [
      "Haowei Lin",
      "Xiangyu Wang",
      "Ruilin Yan",
      "Baizhou Huang",
      "Haotian Ye",
      "Jianhua Zhu",
      "Zihao Wang",
      "James Zou",
      "Jianzhu Ma",
      "Yitao Liang"
    ],
    "abstract": "With powerful large language models (LLMs) demonstrating superhuman reasoning\ncapabilities, a critical question arises: Do LLMs genuinely reason, or do they\nmerely recall answers from their extensive, web-scraped training datasets?\nPublicly released benchmarks inevitably become contaminated once incorporated\ninto subsequent LLM training sets, undermining their reliability as faithful\nassessments. To address this, we introduce KUMO, a generative evaluation\nframework designed specifically for assessing reasoning in LLMs. KUMO\nsynergistically combines LLMs with symbolic engines to dynamically produce\ndiverse, multi-turn reasoning tasks that are partially observable and\nadjustable in difficulty. Through an automated pipeline, KUMO continuously\ngenerates novel tasks across open-ended domains, compelling models to\ndemonstrate genuine generalization rather than memorization. We evaluated 23\nstate-of-the-art LLMs on 5,000 tasks across 100 domains created by KUMO,\nbenchmarking their reasoning abilities against university students. Our\nfindings reveal that many LLMs have outperformed university-level performance\non easy reasoning tasks, and reasoning-scaled LLMs reach university-level\nperformance on complex reasoning challenges. Moreover, LLM performance on KUMO\ntasks correlates strongly with results on newly released real-world reasoning\nbenchmarks, underscoring KUMO's value as a robust, enduring assessment tool for\ngenuine LLM reasoning capabilities.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02810v2",
    "published_date": "2025-04-03 17:54:18 UTC",
    "updated_date": "2025-04-25 12:02:19 UTC"
  },
  {
    "arxiv_id": "2504.02807v1",
    "title": "MegaMath: Pushing the Limits of Open Math Corpora",
    "authors": [
      "Fan Zhou",
      "Zengzhi Wang",
      "Nikhil Ranjan",
      "Zhoujun Cheng",
      "Liping Tang",
      "Guowei He",
      "Zhengzhong Liu",
      "Eric P. Xing"
    ],
    "abstract": "Mathematical reasoning is a cornerstone of human intelligence and a key\nbenchmark for advanced capabilities in large language models (LLMs). However,\nthe research community still lacks an open, large-scale, high-quality corpus\ntailored to the demands of math-centric LLM pre-training. We present MegaMath,\nan open dataset curated from diverse, math-focused sources through following\npractices: (1) Revisiting web data: We re-extracted mathematical documents from\nCommon Crawl with math-oriented HTML optimizations, fasttext-based filtering\nand deduplication, all for acquiring higher-quality data on the Internet. (2)\nRecalling Math-related code data: We identified high quality math-related code\nfrom large code training corpus, Stack-V2, further enhancing data diversity.\n(3) Exploring Synthetic data: We synthesized QA-style text, math-related code,\nand interleaved text-code blocks from web data or code data. By integrating\nthese strategies and validating their effectiveness through extensive\nablations, MegaMath delivers 371B tokens with the largest quantity and top\nquality among existing open math pre-training datasets.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 15 figures, 22 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.02807v1",
    "published_date": "2025-04-03 17:52:07 UTC",
    "updated_date": "2025-04-03 17:52:07 UTC"
  },
  {
    "arxiv_id": "2504.02922v1",
    "title": "Robustly identifying concepts introduced during chat fine-tuning using crosscoders",
    "authors": [
      "Julian Minder",
      "Clement Dumas",
      "Caden Juang",
      "Bilal Chugtai",
      "Neel Nanda"
    ],
    "abstract": "Model diffing is the study of how fine-tuning changes a model's\nrepresentations and internal algorithms. Many behaviours of interest are\nintroduced during fine-tuning, and model diffing offers a promising lens to\ninterpret such behaviors. Crosscoders are a recent model diffing method that\nlearns a shared dictionary of interpretable concepts represented as latent\ndirections in both the base and fine-tuned models, allowing us to track how\nconcepts shift or emerge during fine-tuning. Notably, prior work has observed\nconcepts with no direction in the base model, and it was hypothesized that\nthese model-specific latents were concepts introduced during fine-tuning.\nHowever, we identify two issues which stem from the crosscoders L1 training\nloss that can misattribute concepts as unique to the fine-tuned model, when\nthey really exist in both models. We develop Latent Scaling to flag these\nissues by more accurately measuring each latent's presence across models. In\nexperiments comparing Gemma 2 2B base and chat models, we observe that the\nstandard crosscoder suffers heavily from these issues. Building on these\ninsights, we train a crosscoder with BatchTopK loss and show that it\nsubstantially mitigates these issues, finding more genuinely chat-specific and\nhighly interpretable concepts. We recommend practitioners adopt similar\ntechniques. Using the BatchTopK crosscoder, we successfully identify a set of\ngenuinely chat-specific latents that are both interpretable and causally\neffective, representing concepts such as $\\textit{false information}$ and\n$\\textit{personal question}$, along with multiple refusal-related latents that\nshow nuanced preferences for different refusal triggers. Overall, our work\nadvances best practices for the crosscoder-based methodology for model diffing\nand demonstrates that it can provide concrete insights into how chat tuning\nmodifies language model behavior.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "47 pages, 27 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02922v1",
    "published_date": "2025-04-03 17:50:24 UTC",
    "updated_date": "2025-04-03 17:50:24 UTC"
  },
  {
    "arxiv_id": "2504.02799v1",
    "title": "Systematic Evaluation of Large Vision-Language Models for Surgical Artificial Intelligence",
    "authors": [
      "Anita Rau",
      "Mark Endo",
      "Josiah Aklilu",
      "Jaewoo Heo",
      "Khaled Saab",
      "Alberto Paderno",
      "Jeffrey Jopling",
      "F. Christopher Holsinger",
      "Serena Yeung-Levy"
    ],
    "abstract": "Large Vision-Language Models offer a new paradigm for AI-driven image\nunderstanding, enabling models to perform tasks without task-specific training.\nThis flexibility holds particular promise across medicine, where\nexpert-annotated data is scarce. Yet, VLMs' practical utility in\nintervention-focused domains--especially surgery, where decision-making is\nsubjective and clinical scenarios are variable--remains uncertain. Here, we\npresent a comprehensive analysis of 11 state-of-the-art VLMs across 17 key\nvisual understanding tasks in surgical AI--from anatomy recognition to skill\nassessment--using 13 datasets spanning laparoscopic, robotic, and open\nprocedures. In our experiments, VLMs demonstrate promising generalizability, at\ntimes outperforming supervised models when deployed outside their training\nsetting. In-context learning, incorporating examples during testing, boosted\nperformance up to three-fold, suggesting adaptability as a key strength. Still,\ntasks requiring spatial or temporal reasoning remained difficult. Beyond\nsurgery, our findings offer insights into VLMs' potential for tackling complex\nand dynamic scenarios in clinical and broader real-world applications.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02799v1",
    "published_date": "2025-04-03 17:42:56 UTC",
    "updated_date": "2025-04-03 17:42:56 UTC"
  },
  {
    "arxiv_id": "2504.02793v1",
    "title": "A Framework for Situating Innovations, Opportunities, and Challenges in Advancing Vertical Systems with Large AI Models",
    "authors": [
      "Gaurav Verma",
      "Jiawei Zhou",
      "Mohit Chandra",
      "Srijan Kumar",
      "Munmun De Choudhury"
    ],
    "abstract": "Large artificial intelligence (AI) models have garnered significant attention\nfor their remarkable, often \"superhuman\", performance on standardized\nbenchmarks. However, when these models are deployed in high-stakes verticals\nsuch as healthcare, education, and law, they often reveal notable limitations.\nFor instance, they exhibit brittleness to minor variations in input data,\npresent contextually uninformed decisions in critical settings, and undermine\nuser trust by confidently producing or reproducing inaccuracies. These\nchallenges in applying large models necessitate cross-disciplinary innovations\nto align the models' capabilities with the needs of real-world applications. We\nintroduce a framework that addresses this gap through a layer-wise abstraction\nof innovations aimed at meeting users' requirements with large models. Through\nmultiple case studies, we illustrate how researchers and practitioners across\nvarious fields can operationalize this framework. Beyond modularizing the\npipeline of transforming large models into useful \"vertical systems\", we also\nhighlight the dynamism that exists within different layers of the framework.\nFinally, we discuss how our framework can guide researchers and practitioners\nto (i) optimally situate their innovations (e.g., when vertical-specific\ninsights can empower broadly impactful vertical-agnostic innovations), (ii)\nuncover overlooked opportunities (e.g., spotting recurring problems across\nverticals to develop practically useful foundation models instead of chasing\nbenchmarks), and (iii) facilitate cross-disciplinary communication of critical\nchallenges (e.g., enabling a shared vocabulary for AI developers, domain\nexperts, and human-computer interaction scholars).",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "primary_category": "cs.AI",
    "comment": "pre-print; 7 pages of main content, 1 figure, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.02793v1",
    "published_date": "2025-04-03 17:40:11 UTC",
    "updated_date": "2025-04-03 17:40:11 UTC"
  },
  {
    "arxiv_id": "2504.02792v2",
    "title": "Unified World Models: Coupling Video and Action Diffusion for Pretraining on Large Robotic Datasets",
    "authors": [
      "Chuning Zhu",
      "Raymond Yu",
      "Siyuan Feng",
      "Benjamin Burchfiel",
      "Paarth Shah",
      "Abhishek Gupta"
    ],
    "abstract": "Imitation learning has emerged as a promising approach towards building\ngeneralist robots. However, scaling imitation learning for large robot\nfoundation models remains challenging due to its reliance on high-quality\nexpert demonstrations. Meanwhile, large amounts of video data depicting a wide\nrange of environments and diverse behaviors are readily available. This data\nprovides a rich source of information about real-world dynamics and\nagent-environment interactions. Leveraging this data directly for imitation\nlearning, however, has proven difficult due to the lack of action annotation\nrequired for most contemporary methods. In this work, we present Unified World\nModels (UWM), a framework that allows for leveraging both video and action data\nfor policy learning. Specifically, a UWM integrates an action diffusion process\nand a video diffusion process within a unified transformer architecture, where\nindependent diffusion timesteps govern each modality. By simply controlling\neach diffusion timestep, UWM can flexibly represent a policy, a forward\ndynamics, an inverse dynamics, and a video generator. Through simulated and\nreal-world experiments, we show that: (1) UWM enables effective pretraining on\nlarge-scale multitask robot datasets with both dynamics and action predictions,\nresulting in more generalizable and robust policies than imitation learning,\n(2) UWM naturally facilitates learning from action-free video data through\nindependent control of modality-specific diffusion timesteps, further improving\nthe performance of finetuned policies. Our results suggest that UWM offers a\npromising step toward harnessing large, heterogeneous datasets for scalable\nrobot learning, and provides a simple unification between the often disparate\nparadigms of imitation learning and world modeling. Videos and code are\navailable at https://weirdlabuw.github.io/uwm/.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02792v2",
    "published_date": "2025-04-03 17:38:59 UTC",
    "updated_date": "2025-04-16 20:27:54 UTC"
  },
  {
    "arxiv_id": "2504.02781v1",
    "title": "Towards Green AI-Native Networks: Evaluation of Neural Circuit Policy for Estimating Energy Consumption of Base Stations",
    "authors": [
      "Selim Ickin",
      "Shruti Bothe",
      "Aman Raparia",
      "Nitin Khanna",
      "Erik Sanders"
    ],
    "abstract": "Optimization of radio hardware and AI-based network management software yield\nsignificant energy savings in radio access networks. The execution of\nunderlying Machine Learning (ML) models, which enable energy savings through\nrecommended actions, may require additional compute and energy, highlighting\nthe opportunity to explore and adopt accurate and energy-efficient ML\ntechnologies. This work evaluates the novel use of sparsely structured Neural\nCircuit Policies (NCPs) in a use case to estimate the energy consumption of\nbase stations. Sparsity in ML models yields reduced memory, computation and\nenergy demand, hence facilitating a low-cost and scalable solution. We also\nevaluate the generalization capability of NCPs in comparison to traditional and\nwidely used ML models such as Long Short Term Memory (LSTM), via quantifying\ntheir sensitivity to varying model hyper-parameters (HPs). NCPs demonstrated a\nclear reduction in computational overhead and energy consumption. Moreover,\nresults indicated that the NCPs are robust to varying HPs such as number of\nepochs and neurons in each layer, making them a suitable option to ease model\nmanagement and to reduce energy consumption in Machine Learning Operations\n(MLOps) in telecommunications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02781v1",
    "published_date": "2025-04-03 17:22:39 UTC",
    "updated_date": "2025-04-03 17:22:39 UTC"
  },
  {
    "arxiv_id": "2504.02780v1",
    "title": "From Consumption to Collaboration: Measuring Interaction Patterns to Augment Human Cognition in Open-Ended Tasks",
    "authors": [
      "Joshua Holstein",
      "Moritz Diener",
      "Philipp Spitzer"
    ],
    "abstract": "The rise of Generative AI, and Large Language Models (LLMs) in particular, is\nfundamentally changing cognitive processes in knowledge work, raising critical\nquestions about their impact on human reasoning and problem-solving\ncapabilities. As these AI systems become increasingly integrated into\nworkflows, they offer unprecedented opportunities for augmenting human thinking\nwhile simultaneously risking cognitive erosion through passive consumption of\ngenerated answers. This tension is particularly pronounced in open-ended tasks,\nwhere effective solutions require deep contextualization and integration of\ndomain knowledge. Unlike structured tasks with established metrics, measuring\nthe quality of human-LLM interaction in such open-ended tasks poses significant\nchallenges due to the absence of ground truth and the iterative nature of\nsolution development. To address this, we present a framework that analyzes\ninteraction patterns along two dimensions: cognitive activity mode (exploration\nvs. exploitation) and cognitive engagement mode (constructive vs. detrimental).\nThis framework provides systematic measurements to evaluate when LLMs are\neffective tools for thought rather than substitutes for human cognition,\nadvancing theoretical understanding and practical guidance for developing AI\nsystems that protect and augment human cognitive capabilities.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Accepted at Tools for Thought Workshop (CHI'25)",
    "pdf_url": "http://arxiv.org/pdf/2504.02780v1",
    "published_date": "2025-04-03 17:20:36 UTC",
    "updated_date": "2025-04-03 17:20:36 UTC"
  },
  {
    "arxiv_id": "2504.02778v1",
    "title": "Multi-Head Adaptive Graph Convolution Network for Sparse Point Cloud-Based Human Activity Recognition",
    "authors": [
      "Vincent Gbouna Zakka",
      "Luis J. Manso",
      "Zhuangzhuang Dai"
    ],
    "abstract": "Human activity recognition is increasingly vital for supporting independent\nliving, particularly for the elderly and those in need of assistance. Domestic\nservice robots with monitoring capabilities can enhance safety and provide\nessential support. Although image-based methods have advanced considerably in\nthe past decade, their adoption remains limited by concerns over privacy and\nsensitivity to low-light or dark conditions. As an alternative, millimetre-wave\n(mmWave) radar can produce point cloud data which is privacy-preserving.\nHowever, processing the sparse and noisy point clouds remains a long-standing\nchallenge. While graph-based methods and attention mechanisms show promise,\nthey predominantly rely on \"fixed\" kernels; kernels that are applied uniformly\nacross all neighbourhoods, highlighting the need for adaptive approaches that\ncan dynamically adjust their kernels to the specific geometry of each local\nneighbourhood in point cloud data. To overcome this limitation, we introduce an\nadaptive approach within the graph convolutional framework. Instead of a single\nshared weight function, our Multi-Head Adaptive Kernel (MAK) module generates\nmultiple dynamic kernels, each capturing different aspects of the local feature\nspace. By progressively refining local features while maintaining global\nspatial context, our method enables convolution kernels to adapt to varying\nlocal features. Experimental results on benchmark datasets confirm the\neffectiveness of our approach, achieving state-of-the-art performance in human\nactivity recognition. Our source code is made publicly available at:\nhttps://github.com/Gbouna/MAK-GCN",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02778v1",
    "published_date": "2025-04-03 17:19:20 UTC",
    "updated_date": "2025-04-03 17:19:20 UTC"
  },
  {
    "arxiv_id": "2504.02767v1",
    "title": "How Deep Do Large Language Models Internalize Scientific Literature and Citation Practices?",
    "authors": [
      "Andres Algaba",
      "Vincent Holst",
      "Floriano Tori",
      "Melika Mobini",
      "Brecht Verbeken",
      "Sylvia Wenmackers",
      "Vincent Ginis"
    ],
    "abstract": "The spread of scientific knowledge depends on how researchers discover and\ncite previous work. The adoption of large language models (LLMs) in the\nscientific research process introduces a new layer to these citation practices.\nHowever, it remains unclear to what extent LLMs align with human citation\npractices, how they perform across domains, and may influence citation\ndynamics. Here, we show that LLMs systematically reinforce the Matthew effect\nin citations by consistently favoring highly cited papers when generating\nreferences. This pattern persists across scientific domains despite significant\nfield-specific variations in existence rates, which refer to the proportion of\ngenerated references that match existing records in external bibliometric\ndatabases. Analyzing 274,951 references generated by GPT-4o for 10,000 papers,\nwe find that LLM recommendations diverge from traditional citation patterns by\npreferring more recent references with shorter titles and fewer authors.\nEmphasizing their content-level relevance, the generated references are\nsemantically aligned with the content of each paper at levels comparable to the\nground truth references and display similar network effects while reducing\nauthor self-citations. These findings illustrate how LLMs may reshape citation\npractices and influence the trajectory of scientific discovery by reflecting\nand amplifying established trends. As LLMs become more integrated into the\nscientific research process, it is important to understand their role in\nshaping how scientific communities discover and build upon prior work.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.LG",
      "cs.SI"
    ],
    "primary_category": "cs.DL",
    "comment": "32 pages, 17 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02767v1",
    "published_date": "2025-04-03 17:04:56 UTC",
    "updated_date": "2025-04-03 17:04:56 UTC"
  },
  {
    "arxiv_id": "2504.02764v1",
    "title": "Scene Splatter: Momentum 3D Scene Generation from Single Image with Video Diffusion Model",
    "authors": [
      "Shengjun Zhang",
      "Jinzhao Li",
      "Xin Fei",
      "Hao Liu",
      "Yueqi Duan"
    ],
    "abstract": "In this paper, we propose Scene Splatter, a momentum-based paradigm for video\ndiffusion to generate generic scenes from single image. Existing methods, which\nemploy video generation models to synthesize novel views, suffer from limited\nvideo length and scene inconsistency, leading to artifacts and distortions\nduring further reconstruction. To address this issue, we construct noisy\nsamples from original features as momentum to enhance video details and\nmaintain scene consistency. However, for latent features with the perception\nfield that spans both known and unknown regions, such latent-level momentum\nrestricts the generative ability of video diffusion in unknown regions.\nTherefore, we further introduce the aforementioned consistent video as a\npixel-level momentum to a directly generated video without momentum for better\nrecovery of unseen regions. Our cascaded momentum enables video diffusion\nmodels to generate both high-fidelity and consistent novel views. We further\nfinetune the global Gaussian representations with enhanced frames and render\nnew frames for momentum update in the next step. In this manner, we can\niteratively recover a 3D scene, avoiding the limitation of video length.\nExtensive experiments demonstrate the generalization capability and superior\nperformance of our method in high-fidelity and consistent scene generation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02764v1",
    "published_date": "2025-04-03 17:00:44 UTC",
    "updated_date": "2025-04-03 17:00:44 UTC"
  },
  {
    "arxiv_id": "2504.02737v2",
    "title": "RBT4DNN: Requirements-based Testing of Neural Networks",
    "authors": [
      "Nusrat Jahan Mozumder",
      "Felipe Toledo",
      "Swaroopa Dola",
      "Matthew B. Dwyer"
    ],
    "abstract": "Deep neural network (DNN) testing is crucial for the reliability and safety\nof critical systems, where failures can have severe consequences. Although\nvarious techniques have been developed to create robustness test suites,\nrequirements-based testing for DNNs remains largely unexplored - yet such tests\nare recognized as an essential component of software validation of critical\nsystems. In this work, we propose a requirements-based test suite generation\nmethod that uses structured natural language requirements formulated in a\nsemantic feature space to create test suites by prompting text-conditional\nlatent diffusion models with the requirement precondition and then using the\nassociated postcondition to define a test oracle to judge outputs of the DNN\nunder test. We investigate the approach using fine-tuned variants of\npre-trained generative models. Our experiments on the MNIST, CelebA-HQ,\nImageNet, and autonomous car driving datasets demonstrate that the generated\ntest suites are realistic, diverse, consistent with preconditions, and capable\nof revealing faults.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02737v2",
    "published_date": "2025-04-03 16:24:49 UTC",
    "updated_date": "2025-04-04 01:24:07 UTC"
  },
  {
    "arxiv_id": "2504.03784v3",
    "title": "Robust Reinforcement Learning from Human Feedback for Large Language Models Fine-Tuning",
    "authors": [
      "Kai Ye",
      "Hongyi Zhou",
      "Jin Zhu",
      "Francesco Quinzan",
      "Chengchung Shi"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a key\ntechnique for aligning the output of large language models (LLMs) with human\npreferences. To learn the reward function, most existing RLHF algorithms use\nthe Bradley-Terry model, which relies on assumptions about human preferences\nthat may not reflect the complexity and variability of real-world judgments. In\nthis paper, we propose a robust algorithm to enhance the performance of\nexisting approaches under such reward model misspecifications. Theoretically,\nour algorithm reduces the variance of reward and policy estimators, leading to\nimproved regret bounds. Empirical evaluations on LLM benchmark datasets\ndemonstrate that the proposed algorithm consistently outperforms existing\nmethods, with 77-81% of responses being favored over baselines on the Anthropic\nHelpful and Harmless dataset.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03784v3",
    "published_date": "2025-04-03 16:16:35 UTC",
    "updated_date": "2025-04-15 09:29:06 UTC"
  },
  {
    "arxiv_id": "2504.03783v4",
    "title": "FAST: Federated Active Learning with Foundation Models for Communication-efficient Sampling and Training",
    "authors": [
      "Haoyuan Li",
      "Mathias Funk",
      "Jindong Wang",
      "Aaqib Saeed"
    ],
    "abstract": "Federated Active Learning (FAL) has emerged as a promising framework to\nleverage large quantities of unlabeled data across distributed clients while\npreserving data privacy. However, real-world deployments remain limited by high\nannotation costs and communication-intensive sampling processes, particularly\nin a cross-silo setting, when clients possess substantial local datasets. This\npaper addresses the crucial question: What is the best practice to reduce\ncommunication costs in human-in-the-loop learning with minimal annotator\neffort? Existing FAL methods typically rely on iterative annotation processes\nthat separate active sampling from federated updates, leading to multiple\nrounds of expensive communication and annotation. In response, we introduce\nFAST, a two-pass FAL framework that harnesses foundation models for weak\nlabeling in a preliminary pass, followed by a refinement pass focused\nexclusively on the most uncertain samples. By leveraging representation\nknowledge from foundation models and integrating refinement steps into a\nstreamlined workflow, FAST substantially reduces the overhead incurred by\niterative active sampling. Extensive experiments on diverse medical and natural\nimage benchmarks demonstrate that FAST outperforms existing FAL methods by an\naverage of 4.36% while reducing communication rounds eightfold under a limited\n5% labeling budget.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE Internet of Things Journal",
    "pdf_url": "http://arxiv.org/pdf/2504.03783v4",
    "published_date": "2025-04-03 16:12:03 UTC",
    "updated_date": "2025-05-19 09:39:42 UTC"
  },
  {
    "arxiv_id": "2504.02724v1",
    "title": "Autonomous Human-Robot Interaction via Operator Imitation",
    "authors": [
      "Sammy Christen",
      "David Müller",
      "Agon Serifi",
      "Ruben Grandia",
      "Georg Wiedebach",
      "Michael A. Hopkins",
      "Espen Knoop",
      "Moritz Bächer"
    ],
    "abstract": "Teleoperated robotic characters can perform expressive interactions with\nhumans, relying on the operators' experience and social intuition. In this\nwork, we propose to create autonomous interactive robots, by training a model\nto imitate operator data. Our model is trained on a dataset of human-robot\ninteractions, where an expert operator is asked to vary the interactions and\nmood of the robot, while the operator commands as well as the pose of the human\nand robot are recorded. Our approach learns to predict continuous operator\ncommands through a diffusion process and discrete commands through a\nclassifier, all unified within a single transformer architecture. We evaluate\nthe resulting model in simulation and with a user study on the real system. We\nshow that our method enables simple autonomous human-robot interactions that\nare comparable to the expert-operator baseline, and that users can recognize\nthe different robot moods as generated by our model. Finally, we demonstrate a\nzero-shot transfer of our model onto a different robotic platform with the same\noperator interface.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02724v1",
    "published_date": "2025-04-03 16:06:44 UTC",
    "updated_date": "2025-04-03 16:06:44 UTC"
  },
  {
    "arxiv_id": "2504.02701v2",
    "title": "Responsible Development of Offensive AI",
    "authors": [
      "Ryan Marinelli"
    ],
    "abstract": "As AI advances, broader consensus is needed to determine research priorities.\nThis endeavor discusses offensive AI and provides guidance by leveraging\nSustainable Development Goals (SDGs) and interpretability techniques. The\nobjective is to more effectively establish priorities that balance societal\nbenefits against risks. The two forms of offensive AI evaluated in this study\nare vulnerability detection agents, which solve Capture- The-Flag challenges,\nand AI-powered malware.",
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02701v2",
    "published_date": "2025-04-03 15:37:38 UTC",
    "updated_date": "2025-04-05 15:00:29 UTC"
  },
  {
    "arxiv_id": "2504.02698v3",
    "title": "SCMPPI: Supervised Contrastive Multimodal Framework for Predicting Protein-Protein Interactions",
    "authors": [
      "Shengrui XU",
      "Tianchi Lu",
      "Zikun Wang",
      "Jixiu Zhai"
    ],
    "abstract": "Protein-protein interaction (PPI) prediction plays a pivotal role in\ndeciphering cellular functions and disease mechanisms. To address the\nlimitations of traditional experimental methods and existing computational\napproaches in cross-modal feature fusion and false-negative suppression, we\npropose SCMPPI-a novel supervised contrastive multimodal framework. By\neffectively integrating sequence-based features (AAC, DPC, ESMC-CKSAAP) with\nnetwork topology (Node2Vec embeddings) and incorporating an enhanced\ncontrastive learning strategy with negative sample filtering, SCMPPI achieves\nsuperior prediction performance. Extensive experiments on eight benchmark\ndatasets demonstrate its state-of-the-art accuracy(98.13%) and AUC(99.69%),\nalong with excellent cross-species generalization (AUC>99%). Successful\napplications in CD9 networks, Wnt pathway analysis, and cancer-specific\nnetworks further highlight its potential for disease target discovery,\nestablishing SCMPPI as a powerful tool for multimodal biological data analysis.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM",
      "92C40, 68T07",
      "I.2.6; J.3"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages,9 figures,conference",
    "pdf_url": "http://arxiv.org/pdf/2504.02698v3",
    "published_date": "2025-04-03 15:34:02 UTC",
    "updated_date": "2025-04-27 12:55:30 UTC"
  },
  {
    "arxiv_id": "2504.02685v1",
    "title": "STOOD-X methodology: using statistical nonparametric test for OOD Detection Large-Scale datasets enhanced with explainability",
    "authors": [
      "Iván Sevillano-García",
      "Julián Luengo",
      "Francisco Herrera"
    ],
    "abstract": "Out-of-Distribution (OOD) detection is a critical task in machine learning,\nparticularly in safety-sensitive applications where model failures can have\nserious consequences. However, current OOD detection methods often suffer from\nrestrictive distributional assumptions, limited scalability, and a lack of\ninterpretability. To address these challenges, we propose STOOD-X, a two-stage\nmethodology that combines a Statistical nonparametric Test for OOD Detection\nwith eXplainability enhancements. In the first stage, STOOD-X uses\nfeature-space distances and a Wilcoxon-Mann-Whitney test to identify OOD\nsamples without assuming a specific feature distribution. In the second stage,\nit generates user-friendly, concept-based visual explanations that reveal the\nfeatures driving each decision, aligning with the BLUE XAI paradigm. Through\nextensive experiments on benchmark datasets and multiple architectures, STOOD-X\nachieves competitive performance against state-of-the-art post hoc OOD\ndetectors, particularly in high-dimensional and complex settings. In addition,\nits explainability framework enables human oversight, bias detection, and model\ndebugging, fostering trust and collaboration between humans and AI systems. The\nSTOOD-X methodology therefore offers a robust, explainable, and scalable\nsolution for real-world OOD detection tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.HC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 7 Figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02685v1",
    "published_date": "2025-04-03 15:26:03 UTC",
    "updated_date": "2025-04-03 15:26:03 UTC"
  },
  {
    "arxiv_id": "2504.02670v2",
    "title": "Affordable AI Assistants with Knowledge Graph of Thoughts",
    "authors": [
      "Maciej Besta",
      "Lorenzo Paleari",
      "Jia Hao Andrea Jiang",
      "Robert Gerstenberger",
      "You Wu",
      "Patrick Iff",
      "Ales Kubicek",
      "Piotr Nyczyk",
      "Diana Khimey",
      "Jón Gunnar Hannesson",
      "Grzegorz Kwaśniewski",
      "Marcin Copik",
      "Hubert Niewiadomski",
      "Torsten Hoefler"
    ],
    "abstract": "Large Language Models (LLMs) are revolutionizing the development of AI\nassistants capable of performing diverse tasks across domains. However, current\nstate-of-the-art LLM-driven agents face significant challenges, including high\noperational costs and limited success rates on complex benchmarks like GAIA. To\naddress these issues, we propose the Knowledge Graph of Thoughts (KGoT), an\ninnovative AI assistant architecture that integrates LLM reasoning with\ndynamically constructed knowledge graphs (KGs). KGoT extracts and structures\ntask-relevant knowledge into a dynamic KG representation, iteratively enhanced\nthrough external tools such as math solvers, web crawlers, and Python scripts.\nSuch structured representation of task-relevant knowledge enables low-cost\nmodels to solve complex tasks effectively. For example, KGoT achieves a 29%\nimprovement in task success rates on the GAIA benchmark compared to Hugging\nFace Agents with GPT-4o mini, while reducing costs by over 36x compared to\nGPT-4o. Improvements for recent reasoning models are similar, e.g., 36% and\n37.5% for Qwen2.5-32B and Deepseek-R1-70B, respectively. KGoT offers a\nscalable, affordable, and high-performing solution for AI assistants.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02670v2",
    "published_date": "2025-04-03 15:11:55 UTC",
    "updated_date": "2025-04-10 14:44:34 UTC"
  },
  {
    "arxiv_id": "2504.02654v1",
    "title": "SymDQN: Symbolic Knowledge and Reasoning in Neural Network-based Reinforcement Learning",
    "authors": [
      "Ivo Amador",
      "Nina Gierasimczuk"
    ],
    "abstract": "We propose a learning architecture that allows symbolic control and guidance\nin reinforcement learning with deep neural networks. We introduce SymDQN, a\nnovel modular approach that augments the existing Dueling Deep Q-Networks\n(DuelDQN) architecture with modules based on the neuro-symbolic framework of\nLogic Tensor Networks (LTNs). The modules guide action policy learning and\nallow reinforcement learning agents to display behaviour consistent with\nreasoning about the environment. Our experiment is an ablation study performed\non the modules. It is conducted in a reinforcement learning environment of a\n5x5 grid navigated by an agent that encounters various shapes, each associated\nwith a given reward. The underlying DuelDQN attempts to learn the optimal\nbehaviour of the agent in this environment, while the modules facilitate shape\nrecognition and reward prediction. We show that our architecture significantly\nimproves learning, both in terms of performance and the precision of the agent.\nThe modularity of SymDQN allows reflecting on the intricacies and complexities\nof combining neural and symbolic approaches in reinforcement learning.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "cs.NE",
      "I.2.6"
    ],
    "primary_category": "cs.AI",
    "comment": "8 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02654v1",
    "published_date": "2025-04-03 14:51:11 UTC",
    "updated_date": "2025-04-03 14:51:11 UTC"
  },
  {
    "arxiv_id": "2504.02646v1",
    "title": "Prompt Optimization with Logged Bandit Data",
    "authors": [
      "Haruka Kiyohara",
      "Daniel Yiming Cao",
      "Yuta Saito",
      "Thorsten Joachims"
    ],
    "abstract": "We study how to use naturally available user feedback, such as clicks, to\noptimize large language model (LLM) pipelines for generating personalized\nsentences using prompts. Naive approaches, which estimate the policy gradient\nin the prompt space, suffer either from variance caused by the large action\nspace of prompts or bias caused by inaccurate reward predictions. To circumvent\nthese challenges, we propose a novel kernel-based off-policy gradient method,\nwhich estimates the policy gradient by leveraging similarity among generated\nsentences, substantially reducing variance while suppressing the bias.\nEmpirical results on our newly established suite of benchmarks demonstrate the\neffectiveness of the proposed approach in generating personalized descriptions\nfor movie recommendations, particularly when the number of candidate prompts is\nlarge.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Preprint",
    "pdf_url": "http://arxiv.org/pdf/2504.02646v1",
    "published_date": "2025-04-03 14:40:40 UTC",
    "updated_date": "2025-04-03 14:40:40 UTC"
  },
  {
    "arxiv_id": "2504.02623v3",
    "title": "Multi-Mission Tool Bench: Assessing the Robustness of LLM based Agents through Related and Dynamic Missions",
    "authors": [
      "Peijie Yu",
      "Yifan Yang",
      "Jinjian Li",
      "Zelong Zhang",
      "Haorui Wang",
      "Xiao Feng",
      "Feng Zhang"
    ],
    "abstract": "Large language models (LLMs) demonstrate strong potential as agents for tool\ninvocation due to their advanced comprehension and planning capabilities. Users\nincreasingly rely on LLM-based agents to solve complex missions through\niterative interactions. However, existing benchmarks predominantly access\nagents in single-mission scenarios, failing to capture real-world complexity.\nTo bridge this gap, we propose the Multi-Mission Tool Bench. In the benchmark,\neach test case comprises multiple interrelated missions. This design requires\nagents to dynamically adapt to evolving demands. Moreover, the proposed\nbenchmark explores all possible mission-switching patterns within a fixed\nmission number. Specifically, we propose a multi-agent data generation\nframework to construct the benchmark. We also propose a novel method to\nevaluate the accuracy and efficiency of agent decisions with dynamic decision\ntrees. Experiments on diverse open-source and closed-source LLMs reveal\ncritical factors influencing agent robustness and provide actionable insights\nto the tool invocation society.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02623v3",
    "published_date": "2025-04-03 14:21:33 UTC",
    "updated_date": "2025-04-16 06:22:29 UTC"
  },
  {
    "arxiv_id": "2504.02620v1",
    "title": "Efficient Model Editing with Task-Localized Sparse Fine-tuning",
    "authors": [
      "Leonardo Iurada",
      "Marco Ciccone",
      "Tatiana Tommasi"
    ],
    "abstract": "Task arithmetic has emerged as a promising approach for editing models by\nrepresenting task-specific knowledge as composable task vectors. However,\nexisting methods rely on network linearization to derive task vectors, leading\nto computational bottlenecks during training and inference. Moreover,\nlinearization alone does not ensure weight disentanglement, the key property\nthat enables conflict-free composition of task vectors. To address this, we\npropose TaLoS which allows to build sparse task vectors with minimal\ninterference without requiring explicit linearization and sharing information\nacross tasks. We find that pre-trained models contain a subset of parameters\nwith consistently low gradient sensitivity across tasks, and that sparsely\nupdating only these parameters allows for promoting weight disentanglement\nduring fine-tuning. Our experiments prove that TaLoS improves training and\ninference efficiency while outperforming current methods in task addition and\nnegation. By enabling modular parameter editing, our approach fosters practical\ndeployment of adaptable foundation models in real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted ICLR 2025 - https://github.com/iurada/talos-task-arithmetic",
    "pdf_url": "http://arxiv.org/pdf/2504.02620v1",
    "published_date": "2025-04-03 14:20:06 UTC",
    "updated_date": "2025-04-03 14:20:06 UTC"
  },
  {
    "arxiv_id": "2504.02607v1",
    "title": "Learning Geometrically-Informed Lyapunov Functions with Deep Diffeomorphic RBF Networks",
    "authors": [
      "Samuel Tesfazgi",
      "Leonhard Sprandl",
      "Sandra Hirche"
    ],
    "abstract": "The practical deployment of learning-based autonomous systems would greatly\nbenefit from tools that flexibly obtain safety guarantees in the form of\ncertificate functions from data. While the geometrical properties of such\ncertificate functions are well understood, synthesizing them using machine\nlearning techniques still remains a challenge. To mitigate this issue, we\npropose a diffeomorphic function learning framework where prior structural\nknowledge of the desired output is encoded in the geometry of a simple\nsurrogate function, which is subsequently augmented through an expressive,\ntopology-preserving state-space transformation. Thereby, we achieve an indirect\nfunction approximation framework that is guaranteed to remain in the desired\nhypothesis space. To this end, we introduce a novel approach to construct\ndiffeomorphic maps based on RBF networks, which facilitate precise, local\ntransformations around data. Finally, we demonstrate our approach by learning\ndiffeomorphic Lyapunov functions from real-world data and apply our method to\ndifferent attractor systems.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02607v1",
    "published_date": "2025-04-03 14:09:17 UTC",
    "updated_date": "2025-04-03 14:09:17 UTC"
  },
  {
    "arxiv_id": "2504.02606v1",
    "title": "Improving Counterfactual Truthfulness for Molecular Property Prediction through Uncertainty Quantification",
    "authors": [
      "Jonas Teufel",
      "Annika Leinweber",
      "Pascal Friederich"
    ],
    "abstract": "Explainable AI (xAI) interventions aim to improve interpretability for\ncomplex black-box models, not only to improve user trust but also as a means to\nextract scientific insights from high-performing predictive systems. In\nmolecular property prediction, counterfactual explanations offer a way to\nunderstand predictive behavior by highlighting which minimal perturbations in\nthe input molecular structure cause the greatest deviation in the predicted\nproperty. However, such explanations only allow for meaningful scientific\ninsights if they reflect the distribution of the true underlying property -- a\nfeature we define as counterfactual truthfulness. To increase this\ntruthfulness, we propose the integration of uncertainty estimation techniques\nto filter counterfactual candidates with high predicted uncertainty. Through\ncomputational experiments with synthetic and real-world datasets, we\ndemonstrate that traditional uncertainty estimation methods, such as ensembles\nand mean-variance estimation, can already substantially reduce the average\nprediction error and increase counterfactual truthfulness, especially for\nout-of-distribution settings. Our results highlight the importance and\npotential impact of incorporating uncertainty estimation into explainability\nmethods, especially considering the relatively high effectiveness of low-effort\ninterventions like model ensembles.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "24 pages, 5 figures, 4 tabels, accepted at the 3rd xAI World\n  Conference",
    "pdf_url": "http://arxiv.org/pdf/2504.02606v1",
    "published_date": "2025-04-03 14:07:30 UTC",
    "updated_date": "2025-04-03 14:07:30 UTC"
  },
  {
    "arxiv_id": "2504.02605v1",
    "title": "Multi-SWE-bench: A Multilingual Benchmark for Issue Resolving",
    "authors": [
      "Daoguang Zan",
      "Zhirong Huang",
      "Wei Liu",
      "Hanwu Chen",
      "Linhao Zhang",
      "Shulin Xin",
      "Lu Chen",
      "Qi Liu",
      "Xiaojian Zhong",
      "Aoyan Li",
      "Siyao Liu",
      "Yongsheng Xiao",
      "Liangqiang Chen",
      "Yuyu Zhang",
      "Jing Su",
      "Tianyu Liu",
      "Rui Long",
      "Kai Shen",
      "Liang Xiang"
    ],
    "abstract": "The task of issue resolving is to modify a codebase to generate a patch that\naddresses a given issue. However, existing benchmarks, such as SWE-bench, focus\nalmost exclusively on Python, making them insufficient for evaluating Large\nLanguage Models (LLMs) across diverse software ecosystems. To address this, we\nintroduce a multilingual issue-resolving benchmark, called Multi-SWE-bench,\ncovering Java, TypeScript, JavaScript, Go, Rust, C, and C++. It includes a\ntotal of 1,632 high-quality instances, which were carefully annotated from\n2,456 candidates by 68 expert annotators, ensuring that the benchmark can\nprovide an accurate and reliable evaluation. Based on Multi-SWE-bench, we\nevaluate a series of state-of-the-art models using three representative methods\n(Agentless, SWE-agent, and OpenHands) and present a comprehensive analysis with\nkey empirical insights. In addition, we launch a Multi-SWE-RL open-source\ncommunity, aimed at building large-scale reinforcement learning (RL) training\ndatasets for issue-resolving tasks. As an initial contribution, we release a\nset of 4,723 well-structured instances spanning seven programming languages,\nlaying a solid foundation for RL research in this domain. More importantly, we\nopen-source our entire data production pipeline, along with detailed tutorials,\nencouraging the open-source community to continuously contribute and expand the\ndataset. We envision our Multi-SWE-bench and the ever-growing Multi-SWE-RL\ncommunity as catalysts for advancing RL toward its full potential, bringing us\none step closer to the dawn of AGI.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02605v1",
    "published_date": "2025-04-03 14:06:17 UTC",
    "updated_date": "2025-04-03 14:06:17 UTC"
  },
  {
    "arxiv_id": "2504.02589v1",
    "title": "Knowledge Graph Completion with Mixed Geometry Tensor Factorization",
    "authors": [
      "Viacheslav Yusupov",
      "Maxim Rakhuba",
      "Evgeny Frolov"
    ],
    "abstract": "In this paper, we propose a new geometric approach for knowledge graph\ncompletion via low rank tensor approximation. We augment a pretrained and\nwell-established Euclidean model based on a Tucker tensor decomposition with a\nnovel hyperbolic interaction term. This correction enables more nuanced\ncapturing of distributional properties in data better aligned with real-world\nknowledge graphs. By combining two geometries together, our approach improves\nexpressivity of the resulting model achieving new state-of-the-art link\nprediction accuracy with a significantly lower number of parameters compared to\nthe previous Euclidean and hyperbolic models.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted to AISTATS 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02589v1",
    "published_date": "2025-04-03 13:54:43 UTC",
    "updated_date": "2025-04-03 13:54:43 UTC"
  },
  {
    "arxiv_id": "2504.02586v1",
    "title": "Deep learning for music generation. Four approaches and their comparative evaluation",
    "authors": [
      "Razvan Paroiu",
      "Stefan Trausan-Matu"
    ],
    "abstract": "This paper introduces four different artificial intelligence algorithms for\nmusic generation and aims to compare these methods not only based on the\naesthetic quality of the generated music but also on their suitability for\nspecific applications. The first set of melodies is produced by a slightly\nmodified visual transformer neural network that is used as a language model.\nThe second set of melodies is generated by combining chat sonification with a\nclassic transformer neural network (the same method of music generation is\npresented in a previous research), the third set of melodies is generated by\ncombining the Schillinger rhythm theory together with a classic transformer\nneural network, and the fourth set of melodies is generated using GPT3\ntransformer provided by OpenAI. A comparative analysis is performed on the\nmelodies generated by these approaches and the results indicate that\nsignificant differences can be observed between them and regarding the\naesthetic value of them, GPT3 produced the most pleasing melodies, and the\nnewly introduced Schillinger method proved to generate better sounding music\nthan previous sonification methods.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02586v1",
    "published_date": "2025-04-03 13:51:07 UTC",
    "updated_date": "2025-04-03 13:51:07 UTC"
  },
  {
    "arxiv_id": "2504.16937v1",
    "title": "A Framework for the Assurance of AI-Enabled Systems",
    "authors": [
      "Ariel S. Kapusta",
      "David Jin",
      "Peter M. Teague",
      "Robert A. Houston",
      "Jonathan B. Elliott",
      "Grace Y. Park",
      "Shelby S. Holdren"
    ],
    "abstract": "The United States Department of Defense (DOD) looks to accelerate the\ndevelopment and deployment of AI capabilities across a wide spectrum of defense\napplications to maintain strategic advantages. However, many common features of\nAI algorithms that make them powerful, such as capacity for learning,\nlarge-scale data ingestion, and problem-solving, raise new technical, security,\nand ethical challenges. These challenges may hinder adoption due to uncertainty\nin development, testing, assurance, processes, and requirements.\nTrustworthiness through assurance is essential to achieve the expected value\nfrom AI.\n  This paper proposes a claims-based framework for risk management and\nassurance of AI systems that addresses the competing needs for faster\ndeployment, successful adoption, and rigorous evaluation. This framework\nsupports programs across all acquisition pathways provide grounds for\nsufficient confidence that an AI-enabled system (AIES) meets its intended\nmission goals without introducing unacceptable risks throughout its lifecycle.\nThe paper's contributions are a framework process for AI assurance, a set of\nrelevant definitions to enable constructive conversations on the topic of AI\nassurance, and a discussion of important considerations in AI assurance. The\nframework aims to provide the DOD a robust yet efficient mechanism for swiftly\nfielding effective AI capabilities without overlooking critical risks or\nundermining stakeholder trust.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "12 pages, 2 figures, published in conference proceedings of SPIE\n  Defense and Commercial Sensing conference on Assurance and Security for\n  AI-enabled Systems 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.16937v1",
    "published_date": "2025-04-03 13:44:01 UTC",
    "updated_date": "2025-04-03 13:44:01 UTC"
  },
  {
    "arxiv_id": "2504.02577v1",
    "title": "Reasoning Inconsistencies and How to Mitigate Them in Deep Learning",
    "authors": [
      "Erik Arakelyan"
    ],
    "abstract": "The recent advancements in Deep Learning models and techniques have led to\nsignificant strides in performance across diverse tasks and modalities.\nHowever, while the overall capabilities of models show promising growth, our\nunderstanding of their internal reasoning processes remains limited,\nparticularly concerning systematic inconsistencies or errors patterns of\nlogical or inferential flaws. These inconsistencies may manifest as\ncontradictory outputs, failure to generalize across similar tasks, or erroneous\nconclusions in specific contexts. Even detecting and measuring such reasoning\ndiscrepancies is challenging, as they may arise from opaque internal\nprocedures, biases and imbalances in training data, or the inherent complexity\nof the task. Without effective methods to detect, measure, and mitigate these\nerrors, there is a risk of deploying models that are biased, exploitable, or\nlogically unreliable. This thesis aims to address these issues by producing\nnovel methods for deep learning models that reason over knowledge graphs,\nnatural language, and images. The thesis contributes two techniques for\ndetecting and quantifying predictive inconsistencies originating from opaque\ninternal procedures in natural language and image processing models. To\nmitigate inconsistencies from biases in training data, this thesis presents a\ndata efficient sampling method to improve fairness and performance and a\nsynthetic dataset generation approach in low resource scenarios. Finally, the\nthesis offers two techniques to optimize the models for complex reasoning\ntasks. These methods enhance model performance while allowing for more faithful\nand interpretable exploration and exploitation during inference. Critically,\nthis thesis provides a comprehensive framework to improve the robustness,\nfairness, and interpretability of deep learning models across diverse tasks and\nmodalities.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.LO"
    ],
    "primary_category": "cs.AI",
    "comment": "PhD thesis",
    "pdf_url": "http://arxiv.org/pdf/2504.02577v1",
    "published_date": "2025-04-03 13:40:55 UTC",
    "updated_date": "2025-04-03 13:40:55 UTC"
  },
  {
    "arxiv_id": "2504.02917v1",
    "title": "Bias in Large Language Models Across Clinical Applications: A Systematic Review",
    "authors": [
      "Thanathip Suenghataiphorn",
      "Narisara Tribuddharat",
      "Pojsakorn Danpanichkul",
      "Narathorn Kulthamrongsri"
    ],
    "abstract": "Background: Large language models (LLMs) are rapidly being integrated into\nhealthcare, promising to enhance various clinical tasks. However, concerns\nexist regarding their potential for bias, which could compromise patient care\nand exacerbate health inequities. This systematic review investigates the\nprevalence, sources, manifestations, and clinical implications of bias in LLMs.\nMethods: We conducted a systematic search of PubMed, OVID, and EMBASE from\ndatabase inception through 2025, for studies evaluating bias in LLMs applied to\nclinical tasks. We extracted data on LLM type, bias source, bias manifestation,\naffected attributes, clinical task, evaluation methods, and outcomes. Risk of\nbias was assessed using a modified ROBINS-I tool. Results: Thirty-eight studies\nmet inclusion criteria, revealing pervasive bias across various LLMs and\nclinical applications. Both data-related bias (from biased training data) and\nmodel-related bias (from model training) were significant contributors. Biases\nmanifested as: allocative harm (e.g., differential treatment recommendations);\nrepresentational harm (e.g., stereotypical associations, biased image\ngeneration); and performance disparities (e.g., variable output quality). These\nbiases affected multiple attributes, most frequently race/ethnicity and gender,\nbut also age, disability, and language. Conclusions: Bias in clinical LLMs is a\npervasive and systemic issue, with a potential to lead to misdiagnosis and\ninappropriate treatment, particularly for marginalized patient populations.\nRigorous evaluation of the model is crucial. Furthermore, the development and\nimplementation of effective mitigation strategies, coupled with continuous\nmonitoring in real-world clinical settings, are essential to ensure the safe,\nequitable, and trustworthy deployment of LLMs in healthcare.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02917v1",
    "published_date": "2025-04-03 13:32:08 UTC",
    "updated_date": "2025-04-03 13:32:08 UTC"
  },
  {
    "arxiv_id": "2504.02558v1",
    "title": "Rip Current Segmentation: A Novel Benchmark and YOLOv8 Baseline Results",
    "authors": [
      "Andrei Dumitriu",
      "Florin Tatui",
      "Florin Miron",
      "Radu Tudor Ionescu",
      "Radu Timofte"
    ],
    "abstract": "Rip currents are the leading cause of fatal accidents and injuries on many\nbeaches worldwide, emphasizing the importance of automatically detecting these\nhazardous surface water currents. In this paper, we address a novel task: rip\ncurrent instance segmentation. We introduce a comprehensive dataset containing\n$2,466$ images with newly created polygonal annotations for instance\nsegmentation, used for training and validation. Additionally, we present a\nnovel dataset comprising $17$ drone videos (comprising about $24K$ frames)\ncaptured at $30 FPS$, annotated with both polygons for instance segmentation\nand bounding boxes for object detection, employed for testing purposes. We\ntrain various versions of YOLOv8 for instance segmentation on static images and\nassess their performance on the test dataset (videos). The best results were\nachieved by the YOLOv8-nano model (runnable on a portable device), with an\nmAP50 of $88.94%$ on the validation dataset and $81.21%$ macro average on the\ntest dataset. The results provide a baseline for future research in rip current\nsegmentation. Our work contributes to the existing literature by introducing a\ndetailed, annotated dataset, and training a deep learning model for instance\nsegmentation of rip currents. The code, training details and the annotated\ndataset are made publicly available at https://github.com/Irikos/rip_currents.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.0; I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at CVPR 2023 NTIRE Workshop",
    "pdf_url": "http://arxiv.org/pdf/2504.02558v1",
    "published_date": "2025-04-03 13:14:16 UTC",
    "updated_date": "2025-04-03 13:14:16 UTC"
  },
  {
    "arxiv_id": "2504.02546v3",
    "title": "GPG: A Simple and Strong Reinforcement Learning Baseline for Model Reasoning",
    "authors": [
      "Xiangxiang Chu",
      "Hailang Huang",
      "Xiao Zhang",
      "Fei Wei",
      "Yong Wang"
    ],
    "abstract": "Reinforcement Learning (RL) can directly enhance the reasoning capabilities\nof large language models without extensive reliance on Supervised Fine-Tuning\n(SFT). In this work, we revisit the traditional Policy Gradient (PG) mechanism\nand propose a minimalist RL approach termed Group Policy Gradient (GPG). Unlike\nconventional methods, GPG directly optimize the original RL objective, thus\nobviating the need for surrogate loss functions. By eliminating the critic and\nreference models, avoiding KL divergence constraints, and addressing the\nadvantage and gradient estimation bias, our approach significantly simplifies\nthe training process compared to Group Relative Policy Optimization (GRPO). Our\napproach achieves superior performance without relying on auxiliary techniques\nor adjustments. As illustrated in Figure 1, extensive experiments demonstrate\nthat our method not only reduces computational costs but also consistently\noutperforms GRPO across various unimodal and multimodal tasks. Our code is\navailable at https://github.com/AMAP-ML/GPG.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02546v3",
    "published_date": "2025-04-03 12:53:41 UTC",
    "updated_date": "2025-05-01 15:21:09 UTC"
  },
  {
    "arxiv_id": "2504.02544v2",
    "title": "Fourier Sliced-Wasserstein Embedding for Multisets and Measures",
    "authors": [
      "Tal Amir",
      "Nadav Dym"
    ],
    "abstract": "We present the Fourier Sliced-Wasserstein (FSW) embedding - a novel method to\nembed multisets and measures over $\\mathbb{R}^d$ into Euclidean space.\n  Our proposed embedding approximately preserves the sliced Wasserstein\ndistance on distributions, thereby yielding geometrically meaningful\nrepresentations that better capture the structure of the input. Moreover, it is\ninjective on measures and bi-Lipschitz on multisets - a significant advantage\nover prevalent methods based on sum- or max-pooling, which are provably not\nbi-Lipschitz, and, in many cases, not even injective. The required output\ndimension for these guarantees is near-optimal: roughly $2 N d$, where $N$ is\nthe maximal input multiset size.\n  Furthermore, we prove that it is impossible to embed distributions over\n$\\mathbb{R}^d$ into Euclidean space in a bi-Lipschitz manner. Thus, the metric\nproperties of our embedding are, in a sense, the best possible.\n  Through numerical experiments, we demonstrate that our method yields superior\nmultiset representations that improve performance in practical learning tasks.\nSpecifically, we show that (a) a simple combination of the FSW embedding with\nan MLP achieves state-of-the-art performance in learning the (non-sliced)\nWasserstein distance; and (b) replacing max-pooling with the FSW embedding\nmakes PointNet significantly more robust to parameter reduction, with only\nminor performance degradation even after a 40-fold reduction.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This is an erroneous submission that duplicates arXiv:2405.16519. It\n  has been withdrawn; please see arXiv:2405.16519 for the intended version and\n  all future updates",
    "pdf_url": "http://arxiv.org/pdf/2504.02544v2",
    "published_date": "2025-04-03 12:51:40 UTC",
    "updated_date": "2025-04-14 13:02:13 UTC"
  },
  {
    "arxiv_id": "2504.02526v1",
    "title": "Improving User Experience with FAICO: Towards a Framework for AI Communication in Human-AI Co-Creativity",
    "authors": [
      "Jeba Rezwana",
      "Corey Ford"
    ],
    "abstract": "How AI communicates with humans is crucial for effective human-AI\nco-creation. However, many existing co-creative AI tools cannot communicate\neffectively, limiting their potential as collaborators. This paper introduces\nour initial design of a Framework for designing AI Communication (FAICO) for\nco-creative AI based on a systematic review of 107 full-length papers. FAICO\npresents key aspects of AI communication and their impacts on user experience\nto guide the design of effective AI communication. We then show actionable ways\nto translate our framework into two practical tools: design cards for designers\nand a configuration tool for users. The design cards enable designers to\nconsider AI communication strategies that cater to a diverse range of users in\nco-creative contexts, while the configuration tool empowers users to customize\nAI communication based on their needs and creative workflows. This paper\ncontributes new insights within the literature on human-AI co-creativity and\nHuman-Computer Interaction, focusing on designing AI communication to enhance\nuser experience.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02526v1",
    "published_date": "2025-04-03 12:29:53 UTC",
    "updated_date": "2025-04-03 12:29:53 UTC"
  },
  {
    "arxiv_id": "2504.02512v1",
    "title": "Towards Generalizing Temporal Action Segmentation to Unseen Views",
    "authors": [
      "Emad Bahrami",
      "Olga Zatsarynna",
      "Gianpiero Francesca",
      "Juergen Gall"
    ],
    "abstract": "While there has been substantial progress in temporal action segmentation,\nthe challenge to generalize to unseen views remains unaddressed. Hence, we\ndefine a protocol for unseen view action segmentation where camera views for\nevaluating the model are unavailable during training. This includes changing\nfrom top-frontal views to a side view or even more challenging from exocentric\nto egocentric views. Furthermore, we present an approach for temporal action\nsegmentation that tackles this challenge. Our approach leverages a shared\nrepresentation at both the sequence and segment levels to reduce the impact of\nview differences during training. We achieve this by introducing a sequence\nloss and an action loss, which together facilitate consistent video and action\nrepresentations across different views. The evaluation on the Assembly101,\nIkeaASM, and EgoExoLearn datasets demonstrate significant improvements, with a\n12.8% increase in F1@50 for unseen exocentric views and a substantial 54%\nimprovement for unseen egocentric views.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02512v1",
    "published_date": "2025-04-03 11:53:59 UTC",
    "updated_date": "2025-04-03 11:53:59 UTC"
  },
  {
    "arxiv_id": "2504.02509v1",
    "title": "A Memory-Augmented LLM-Driven Method for Autonomous Merging of 3D Printing Work Orders",
    "authors": [
      "Yuhao Liu",
      "Maolin Yang",
      "Pingyu Jiang"
    ],
    "abstract": "With the rapid development of 3D printing, the demand for personalized and\ncustomized production on the manufacturing line is steadily increasing.\nEfficient merging of printing workpieces can significantly enhance the\nprocessing efficiency of the production line. Addressing the challenge, a Large\nLanguage Model (LLM)-driven method is established in this paper for the\nautonomous merging of 3D printing work orders, integrated with a\nmemory-augmented learning strategy. In industrial scenarios, both device and\norder features are modeled into LLM-readable natural language prompt templates,\nand develop an order-device matching tool along with a merging interference\nchecking module. By incorporating a self-memory learning strategy, an\nintelligent agent for autonomous order merging is constructed, resulting in\nimproved accuracy and precision in order allocation. The proposed method\neffectively leverages the strengths of LLMs in industrial applications while\nreducing hallucination.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "6 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02509v1",
    "published_date": "2025-04-03 11:50:29 UTC",
    "updated_date": "2025-04-03 11:50:29 UTC"
  },
  {
    "arxiv_id": "2504.03777v1",
    "title": "Explainable and Interpretable Forecasts on Non-Smooth Multivariate Time Series for Responsible Gameplay",
    "authors": [
      "Hussain Jagirdar",
      "Rukma Talwadker",
      "Aditya Pareek",
      "Pulkit Agrawal",
      "Tridib Mukherjee"
    ],
    "abstract": "Multi-variate Time Series (MTS) forecasting has made large strides (with very\nnegligible errors) through recent advancements in neural networks, e.g.,\nTransformers. However, in critical situations like predicting gaming\noverindulgence that affects one's mental well-being; an accurate forecast\nwithout a contributing evidence (explanation) is irrelevant. Hence, it becomes\nimportant that the forecasts are Interpretable - intermediate representation of\nthe forecasted trajectory is comprehensible; as well as Explainable - attentive\ninput features and events are accessible for a personalized and timely\nintervention of players at risk. While the contributing state of the art\nresearch on interpretability primarily focuses on temporally-smooth\nsingle-process driven time series data, our online multi-player gameplay data\ndemonstrates intractable temporal randomness due to intrinsic orthogonality\nbetween player's game outcome and their intent to engage further. We introduce\na novel deep Actionable Forecasting Network (AFN), which addresses the\ninter-dependent challenges associated with three exclusive objectives - 1)\nforecasting accuracy; 2) smooth comprehensible trajectory and 3) explanations\nvia multi-dimensional input features while tackling the challenges introduced\nby our non-smooth temporal data, together in one single solution. AFN\nestablishes a \\it{new benchmark} via: (i) achieving 25% improvement on the MSE\nof the forecasts on player data in comparison to the SOM-VAE based SOTA\nnetworks; (ii) attributing unfavourable progression of a player's time series\nto a specific future time step(s), with the premise of eliminating near-future\noverindulgent player volume by over 18% with player specific actionable inputs\nfeature(s) and (iii) proactively detecting over 23% (100% jump from SOTA) of\nthe to-be overindulgent, players on an average, 4 weeks in advance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03777v1",
    "published_date": "2025-04-03 11:49:24 UTC",
    "updated_date": "2025-04-03 11:49:24 UTC"
  },
  {
    "arxiv_id": "2504.02495v2",
    "title": "Inference-Time Scaling for Generalist Reward Modeling",
    "authors": [
      "Zijun Liu",
      "Peiyi Wang",
      "Runxin Xu",
      "Shirong Ma",
      "Chong Ruan",
      "Peng Li",
      "Yang Liu",
      "Yu Wu"
    ],
    "abstract": "Reinforcement learning (RL) has been widely adopted in post-training for\nlarge language models (LLMs) at scale. Recently, the incentivization of\nreasoning capabilities in LLMs from RL indicates that $\\textit{proper learning\nmethods could enable effective inference-time scalability}$. A key challenge of\nRL is to obtain accurate reward signals for LLMs in various domains beyond\nverifiable questions or artificial rules. In this work, we investigate how to\nimprove reward modeling (RM) with more inference compute for general queries,\ni.e. the $\\textbf{inference-time scalability of generalist RM}$, and further,\nhow to improve the effectiveness of performance-compute scaling with proper\nlearning methods. For the RM approach, we adopt pointwise generative reward\nmodeling (GRM) to enable flexibility for different input types and potential\nfor inference-time scaling. For the learning method, we propose Self-Principled\nCritique Tuning (SPCT) to foster scalable reward generation behaviors in GRMs\nthrough online RL, to generate principles adaptively and critiques accurately,\nresulting in $\\textbf{DeepSeek-GRM}$ models. Furthermore, for effective\ninference-time scaling, we use parallel sampling to expand compute usage, and\nintroduce a meta RM to guide voting process for better scaling performance.\nEmpirically, we show that SPCT significantly improves the quality and\nscalability of GRMs, outperforming existing methods and models in various RM\nbenchmarks without severe biases, and could achieve better performance compared\nto training-time scaling. DeepSeek-GRM still meets challenges in some tasks,\nwhich we believe can be addressed by future efforts in generalist reward\nsystems. The models will be released and open-sourced.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Preprint, under review. 42 pages",
    "pdf_url": "http://arxiv.org/pdf/2504.02495v2",
    "published_date": "2025-04-03 11:19:49 UTC",
    "updated_date": "2025-04-05 17:04:00 UTC"
  },
  {
    "arxiv_id": "2504.02492v1",
    "title": "Industrial Internet Robot Collaboration System and Edge Computing Optimization",
    "authors": [
      "Qian Zuo",
      "Dajun Tao",
      "Tian Qi",
      "Jieyi Xie",
      "Zijie Zhou",
      "Zhen Tian",
      "Yu Mingyu"
    ],
    "abstract": "In a complex environment, for a mobile robot to safely and collision - free\navoid all obstacles, it poses high requirements for its intelligence level.\nGiven that the information such as the position and geometric characteristics\nof obstacles is random, the control parameters of the robot, such as velocity\nand angular velocity, are also prone to random deviations. To address this\nissue in the framework of the Industrial Internet Robot Collaboration System,\nthis paper proposes a global path control scheme for mobile robots based on\ndeep learning. First of all, the dynamic equation of the mobile robot is\nestablished. According to the linear velocity and angular velocity of the\nmobile robot, its motion behaviors are divided into obstacle - avoidance\nbehavior, target - turning behavior, and target approaching behavior.\nSubsequently, the neural network method in deep learning is used to build a\nglobal path planning model for the robot. On this basis, a fuzzy controller is\ndesigned with the help of a fuzzy control algorithm to correct the deviations\nthat occur during path planning, thereby achieving optimized control of the\nrobot's global path. In addition, considering edge computing optimization, the\nproposed model can process local data at the edge device, reducing the\ncommunication burden between the robot and the central server, and improving\nthe real time performance of path planning. The experimental results show that\nfor the mobile robot controlled by the research method in this paper, the\ndeviation distance of the path angle is within 5 cm, the deviation convergence\ncan be completed within 10 ms, and the planned path is shorter. This indicates\nthat the proposed scheme can effectively improve the global path planning\nability of mobile robots in the industrial Internet environment and promote the\ncollaborative operation of robots through edge computing optimization.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02492v1",
    "published_date": "2025-04-03 11:15:10 UTC",
    "updated_date": "2025-04-03 11:15:10 UTC"
  },
  {
    "arxiv_id": "2504.02912v1",
    "title": "Haphazard Inputs as Images in Online Learning",
    "authors": [
      "Rohit Agarwal",
      "Aryan Dessai",
      "Arif Ahmed Sekh",
      "Krishna Agarwal",
      "Alexander Horsch",
      "Dilip K. Prasad"
    ],
    "abstract": "The field of varying feature space in online learning settings, also known as\nhaphazard inputs, is very prominent nowadays due to its applicability in\nvarious fields. However, the current solutions to haphazard inputs are\nmodel-dependent and cannot benefit from the existing advanced deep-learning\nmethods, which necessitate inputs of fixed dimensions. Therefore, we propose to\ntransform the varying feature space in an online learning setting to a\nfixed-dimension image representation on the fly. This simple yet novel approach\nis model-agnostic, allowing any vision-based models to be applicable for\nhaphazard inputs, as demonstrated using ResNet and ViT. The image\nrepresentation handles the inconsistent input data seamlessly, making our\nproposed approach scalable and robust. We show the efficacy of our method on\nfour publicly available datasets. The code is available at\nhttps://github.com/Rohit102497/HaphazardInputsAsImages.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.ET",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at IJCNN 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02912v1",
    "published_date": "2025-04-03 11:14:05 UTC",
    "updated_date": "2025-04-03 11:14:05 UTC"
  },
  {
    "arxiv_id": "2504.02489v1",
    "title": "The Self-Learning Agent with a Progressive Neural Network Integrated Transformer",
    "authors": [
      "Ajay Sivakumar",
      "Shalini",
      "Vasantha Raj",
      "Sebastian Sylvester"
    ],
    "abstract": "This paper introduces a self-learning agent that integrates LLaMA 3.2 with a\nProgressive Neural Network (PNN) for continual learning in conversational AI\nand code generation. The framework dynamically collects data, fine-tunes tasks\nwith minimal samples, and leverages Meta-Learning for rapid adaptation. LoRA\noptimizes fine-tuning, while Elastic Weight Consolidation (EWC) enhances\nknowledge retention. Experimental results demonstrate improved adaptability and\nmemory stability, positioning this approach as a scalable step toward\nArtificial General Intelligence (AGI).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "7 pages, 2 figures, focuses on continual learning with PNN and LLaMA.\n  Experiments demonstrate scalability and lifelong learning capabilities",
    "pdf_url": "http://arxiv.org/pdf/2504.02489v1",
    "published_date": "2025-04-03 11:13:31 UTC",
    "updated_date": "2025-04-03 11:13:31 UTC"
  },
  {
    "arxiv_id": "2504.02486v1",
    "title": "We Need Improved Data Curation and Attribution in AI for Scientific Discovery",
    "authors": [
      "Mara Graziani",
      "Antonio Foncubierta",
      "Dimitrios Christofidellis",
      "Irina Espejo-Morales",
      "Malina Molnar",
      "Marvin Alberts",
      "Matteo Manica",
      "Jannis Born"
    ],
    "abstract": "As the interplay between human-generated and synthetic data evolves, new\nchallenges arise in scientific discovery concerning the integrity of the data\nand the stability of the models. In this work, we examine the role of synthetic\ndata as opposed to that of real experimental data for scientific research. Our\nanalyses indicate that nearly three-quarters of experimental datasets available\non open-access platforms have relatively low adoption rates, opening new\nopportunities to enhance their discoverability and usability by automated\nmethods. Additionally, we observe an increasing difficulty in distinguishing\nsynthetic from real experimental data. We propose supplementing ongoing efforts\nin automating synthetic data detection by increasing the focus on watermarking\nreal experimental data, thereby strengthening data traceability and integrity.\nOur estimates suggest that watermarking even less than half of the real world\ndata generated annually could help sustain model robustness, while promoting a\nbalanced integration of synthetic and human-generated content.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02486v1",
    "published_date": "2025-04-03 11:07:52 UTC",
    "updated_date": "2025-04-03 11:07:52 UTC"
  },
  {
    "arxiv_id": "2504.02911v1",
    "title": "Noiser: Bounded Input Perturbations for Attributing Large Language Models",
    "authors": [
      "Mohammad Reza Ghasemi Madani",
      "Aryo Pradipta Gema",
      "Gabriele Sarti",
      "Yu Zhao",
      "Pasquale Minervini",
      "Andrea Passerini"
    ],
    "abstract": "Feature attribution (FA) methods are common post-hoc approaches that explain\nhow Large Language Models (LLMs) make predictions. Accordingly, generating\nfaithful attributions that reflect the actual inner behavior of the model is\ncrucial. In this paper, we introduce Noiser, a perturbation-based FA method\nthat imposes bounded noise on each input embedding and measures the robustness\nof the model against partially noised input to obtain the input attributions.\nAdditionally, we propose an answerability metric that employs an instructed\njudge model to assess the extent to which highly scored tokens suffice to\nrecover the predicted output. Through a comprehensive evaluation across six\nLLMs and three tasks, we demonstrate that Noiser consistently outperforms\nexisting gradient-based, attention-based, and perturbation-based FA methods in\nterms of both faithfulness and answerability, making it a robust and effective\napproach for explaining language model predictions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02911v1",
    "published_date": "2025-04-03 10:59:37 UTC",
    "updated_date": "2025-04-03 10:59:37 UTC"
  },
  {
    "arxiv_id": "2504.02480v1",
    "title": "Graph Attention-Driven Bayesian Deep Unrolling for Dual-Peak Single-Photon Lidar Imaging",
    "authors": [
      "Kyungmin Choi",
      "JaKeoung Koo",
      "Stephen McLaughlin",
      "Abderrahim Halimi"
    ],
    "abstract": "Single-photon Lidar imaging offers a significant advantage in 3D imaging due\nto its high resolution and long-range capabilities, however it is challenging\nto apply in noisy environments with multiple targets per pixel. To tackle these\nchallenges, several methods have been proposed. Statistical methods demonstrate\ninterpretability on the inferred parameters, but they are often limited in\ntheir ability to handle complex scenes. Deep learning-based methods have shown\nsuperior performance in terms of accuracy and robustness, but they lack\ninterpretability or they are limited to a single-peak per pixel. In this paper,\nwe propose a deep unrolling algorithm for dual-peak single-photon Lidar\nimaging. We introduce a hierarchical Bayesian model for multiple targets and\npropose a neural network that unrolls the underlying statistical method. To\nsupport multiple targets, we adopt a dual depth maps representation and exploit\ngeometric deep learning to extract features from the point cloud. The proposed\nmethod takes advantages of statistical methods and learning-based methods in\nterms of accuracy and quantifying uncertainty. The experimental results on\nsynthetic and real data demonstrate the competitive performance when compared\nto existing methods, while also providing uncertainty information.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02480v1",
    "published_date": "2025-04-03 10:57:26 UTC",
    "updated_date": "2025-04-03 10:57:26 UTC"
  },
  {
    "arxiv_id": "2504.02479v1",
    "title": "Hierarchical Policy-Gradient Reinforcement Learning for Multi-Agent Shepherding Control of Non-Cohesive Targets",
    "authors": [
      "Stefano Covone",
      "Italo Napolitano",
      "Francesco De Lellis",
      "Mario di Bernardo"
    ],
    "abstract": "We propose a decentralized reinforcement learning solution for multi-agent\nshepherding of non-cohesive targets using policy-gradient methods. Our\narchitecture integrates target-selection with target-driving through Proximal\nPolicy Optimization, overcoming discrete-action constraints of previous Deep\nQ-Network approaches and enabling smoother agent trajectories. This model-free\nframework effectively solves the shepherding problem without prior dynamics\nknowledge. Experiments demonstrate our method's effectiveness and scalability\nwith increased target numbers and limited sensing capabilities.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02479v1",
    "published_date": "2025-04-03 10:56:57 UTC",
    "updated_date": "2025-04-03 10:56:57 UTC"
  },
  {
    "arxiv_id": "2504.03776v1",
    "title": "Advancing Air Quality Monitoring: TinyML-Based Real-Time Ozone Prediction with Cost-Effective Edge Devices",
    "authors": [
      "Huam Ming Ken",
      "Mehran Behjati"
    ],
    "abstract": "The escalation of urban air pollution necessitates innovative solutions for\nreal-time air quality monitoring and prediction. This paper introduces a novel\nTinyML-based system designed to predict ozone concentration in real-time. The\nsystem employs an Arduino Nano 33 BLE Sense microcontroller equipped with an\nMQ7 sensor for carbon monoxide (CO) detection and built-in sensors for\ntemperature and pressure measurements. The data, sourced from a Kaggle dataset\non air quality parameters from India, underwent thorough cleaning and\npreprocessing. Model training and evaluation were performed using Edge Impulse,\nconsidering various combinations of input parameters (CO, temperature, and\npressure). The optimal model, incorporating all three variables, achieved a\nmean squared error (MSE) of 0.03 and an R-squared value of 0.95, indicating\nhigh predictive accuracy. The regression model was deployed on the\nmicrocontroller via the Arduino IDE, showcasing robust real-time performance.\nSensitivity analysis identified CO levels as the most critical predictor of\nozone concentration, followed by pressure and temperature. The system's\nlow-cost and low-power design makes it suitable for widespread implementation,\nparticularly in resource-constrained settings. This TinyML approach provides\nprecise real-time predictions of ozone levels, enabling prompt responses to\npollution events and enhancing public health protection.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "This is a preprint version of a paper accepted and published in\n  Springer Lecture Notes in Networks and Systems. The final version is\n  available at https://doi.org/10.1007/978-981-96-3949-6_42",
    "pdf_url": "http://arxiv.org/pdf/2504.03776v1",
    "published_date": "2025-04-03 10:48:24 UTC",
    "updated_date": "2025-04-03 10:48:24 UTC"
  },
  {
    "arxiv_id": "2504.02910v1",
    "title": "Systematic Literature Review: Explainable AI Definitions and Challenges in Education",
    "authors": [
      "Zaid M. Altukhi",
      "Sojen Pradhan"
    ],
    "abstract": "Explainable AI (XAI) seeks to transform black-box algorithmic processes into\ntransparent ones, enhancing trust in AI applications across various sectors\nsuch as education. This review aims to examine the various definitions of XAI\nwithin the literature and explore the challenges of XAI in education. Our goal\nis to shed light on how XAI can contribute to enhancing the educational field.\nThis systematic review, utilising the PRISMA method for rigorous and\ntransparent research, identified 19 relevant studies. Our findings reveal 15\ndefinitions and 62 challenges. These challenges are categorised using thematic\nanalysis into seven groups: explainability, ethical, technical, human-computer\ninteraction (HCI), trustworthiness, policy and guideline, and others, thereby\ndeepening our understanding of the implications of XAI in education. Our\nanalysis highlights the absence of standardised definitions for XAI, leading to\nconfusion, especially because definitions concerning ethics, trustworthiness,\ntechnicalities, and explainability tend to overlap and vary.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02910v1",
    "published_date": "2025-04-03 10:43:35 UTC",
    "updated_date": "2025-04-03 10:43:35 UTC"
  },
  {
    "arxiv_id": "2504.02467v1",
    "title": "BOOST: Bootstrapping Strategy-Driven Reasoning Programs for Program-Guided Fact-Checking",
    "authors": [
      "Qisheng Hu",
      "Quanyu Long",
      "Wenya Wang"
    ],
    "abstract": "Program-guided reasoning has shown promise in complex claim fact-checking by\ndecomposing claims into function calls and executing reasoning programs.\nHowever, prior work primarily relies on few-shot in-context learning (ICL) with\nad-hoc demonstrations, which limit program diversity and require manual design\nwith substantial domain knowledge. Fundamentally, the underlying principles of\neffective reasoning program generation still remain underexplored, making it\nchallenging to construct effective demonstrations. To address this, we propose\nBOOST, a bootstrapping-based framework for few-shot reasoning program\ngeneration. BOOST explicitly integrates claim decomposition and\ninformation-gathering strategies as structural guidance for program generation,\niteratively refining bootstrapped demonstrations in a strategy-driven and\ndata-centric manner without human intervention. This enables a seamless\ntransition from zero-shot to few-shot strategic program-guided learning,\nenhancing interpretability and effectiveness. Experimental results show that\nBOOST outperforms prior few-shot baselines in both zero-shot and few-shot\nsettings for complex claim verification.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "18 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02467v1",
    "published_date": "2025-04-03 10:38:45 UTC",
    "updated_date": "2025-04-03 10:38:45 UTC"
  },
  {
    "arxiv_id": "2504.02463v1",
    "title": "Evaluating AI Recruitment Sourcing Tools by Human Preference",
    "authors": [
      "Vladimir Slaykovskiy",
      "Maksim Zvegintsev",
      "Yury Sakhonchyk",
      "Hrachik Ajamian"
    ],
    "abstract": "This study introduces a benchmarking methodology designed to evaluate the\nperformance of AI-driven recruitment sourcing tools. We created and utilized a\ndataset to perform a comparative analysis of search results generated by\nleading AI-based solutions, LinkedIn Recruiter, and our proprietary system,\nPearch.ai. Human experts assessed the relevance of the returned candidates, and\nan Elo rating system was applied to quantitatively measure each tool's\ncomparative performance. Our findings indicate that AI-driven recruitment\nsourcing tools consistently outperform LinkedIn Recruiter in candidate\nrelevance, with Pearch.ai achieving the highest performance scores.\nFurthermore, we found a strong alignment between AI-based evaluations and human\njudgments, highlighting the potential for advanced AI technologies to\nsubstantially enhance talent acquisition effectiveness. Code and supporting\ndata are publicly available at\nhttps://github.com/vslaykovsky/ai-sourcing-benchmark",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02463v1",
    "published_date": "2025-04-03 10:33:43 UTC",
    "updated_date": "2025-04-03 10:33:43 UTC"
  },
  {
    "arxiv_id": "2504.02464v1",
    "title": "CornerPoint3D: Look at the Nearest Corner Instead of the Center",
    "authors": [
      "Ruixiao Zhang",
      "Runwei Guan",
      "Xiangyu Chen",
      "Adam Prugel-Bennett",
      "Xiaohao Cai"
    ],
    "abstract": "3D object detection aims to predict object centers, dimensions, and rotations\nfrom LiDAR point clouds. Despite its simplicity, LiDAR captures only the near\nside of objects, making center-based detectors prone to poor localization\naccuracy in cross-domain tasks with varying point distributions. Meanwhile,\nexisting evaluation metrics designed for single-domain assessment also suffer\nfrom overfitting due to dataset-specific size variations. A key question\narises: Do we really need models to maintain excellent performance in the\nentire 3D bounding boxes after being applied across domains? Actually, one of\nour main focuses is on preventing collisions between vehicles and other\nobstacles, especially in cross-domain scenarios where correctly predicting the\nsizes is much more difficult. To address these issues, we rethink cross-domain\n3D object detection from a practical perspective. We propose two new metrics\nthat evaluate a model's ability to detect objects' closer-surfaces to the LiDAR\nsensor. Additionally, we introduce EdgeHead, a refinement head that guides\nmodels to focus more on learnable closer surfaces, significantly improving\ncross-domain performance under both our new and traditional BEV/3D metrics.\nFurthermore, we argue that predicting the nearest corner rather than the object\ncenter enhances robustness. We propose a novel 3D object detector, coined as\nCornerPoint3D, which is built upon CenterPoint and uses heatmaps to supervise\nthe learning and detection of the nearest corner of each object. Our proposed\nmethods realize a balanced trade-off between the detection quality of entire\nbounding boxes and the locating accuracy of closer surfaces to the LiDAR\nsensor, outperforming the traditional center-based detector CenterPoint in\nmultiple cross-domain tasks and providing a more practically reasonable and\nrobust cross-domain 3D object detection solution.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "arXiv admin note: substantial text overlap with arXiv:2407.04061",
    "pdf_url": "http://arxiv.org/pdf/2504.02464v1",
    "published_date": "2025-04-03 10:33:43 UTC",
    "updated_date": "2025-04-03 10:33:43 UTC"
  },
  {
    "arxiv_id": "2504.02461v1",
    "title": "Am I Being Treated Fairly? A Conceptual Framework for Individuals to Ascertain Fairness",
    "authors": [
      "Juliett Suárez Ferreira",
      "Marija Slavkovik",
      "Jorge Casillas"
    ],
    "abstract": "Current fairness metrics and mitigation techniques provide tools for\npractitioners to asses how non-discriminatory Automatic Decision Making (ADM)\nsystems are. What if I, as an individual facing a decision taken by an ADM\nsystem, would like to know: Am I being treated fairly? We explore how to create\nthe affordance for users to be able to ask this question of ADM. In this paper,\nwe argue for the reification of fairness not only as a property of ADM, but\nalso as an epistemic right of an individual to acquire information about the\ndecisions that affect them and use that information to contest and seek\neffective redress against those decisions, in case they are proven to be\ndiscriminatory. We examine key concepts from existing research not only in\nalgorithmic fairness but also in explainable artificial intelligence,\naccountability, and contestability. Integrating notions from these domains, we\npropose a conceptual framework to ascertain fairness by combining different\ntools that empower the end-users of ADM systems. Our framework shifts the focus\nfrom technical solutions aimed at practitioners to mechanisms that enable\nindividuals to understand, challenge, and verify the fairness of decisions, and\nalso serves as a blueprint for organizations and policymakers, bridging the gap\nbetween technical requirements and practical, user-centered accountability.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.MA",
      "I.2; J.4"
    ],
    "primary_category": "cs.CY",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02461v1",
    "published_date": "2025-04-03 10:28:19 UTC",
    "updated_date": "2025-04-03 10:28:19 UTC"
  },
  {
    "arxiv_id": "2504.02458v1",
    "title": "Retrieval-Augmented Purifier for Robust LLM-Empowered Recommendation",
    "authors": [
      "Liangbo Ning",
      "Wenqi Fan",
      "Qing Li"
    ],
    "abstract": "Recently, Large Language Model (LLM)-empowered recommender systems have\nrevolutionized personalized recommendation frameworks and attracted extensive\nattention. Despite the remarkable success, existing LLM-empowered RecSys have\nbeen demonstrated to be highly vulnerable to minor perturbations. To mitigate\nthe negative impact of such vulnerabilities, one potential solution is to\nemploy collaborative signals based on item-item co-occurrence to purify the\nmalicious collaborative knowledge from the user's historical interactions\ninserted by attackers. On the other hand, due to the capabilities to expand\ninsufficient internal knowledge of LLMs, Retrieval-Augmented Generation (RAG)\ntechniques provide unprecedented opportunities to enhance the robustness of\nLLM-empowered recommender systems by introducing external collaborative\nknowledge. Therefore, in this paper, we propose a novel framework (RETURN) by\nretrieving external collaborative signals to purify the poisoned user profiles\nand enhance the robustness of LLM-empowered RecSys in a plug-and-play manner.\nSpecifically, retrieval-augmented perturbation positioning is proposed to\nidentify potential perturbations within the users' historical sequences by\nretrieving external knowledge from collaborative item graphs. After that, we\nfurther retrieve the collaborative knowledge to cleanse the perturbations by\nusing either deletion or replacement strategies and introduce a robust ensemble\nrecommendation strategy to generate final robust predictions. Extensive\nexperiments on three real-world datasets demonstrate the effectiveness of the\nproposed RETURN.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02458v1",
    "published_date": "2025-04-03 10:22:30 UTC",
    "updated_date": "2025-04-03 10:22:30 UTC"
  },
  {
    "arxiv_id": "2504.02450v3",
    "title": "CHARMS: A Cognitive Hierarchical Agent for Reasoning and Motion Stylization in Autonomous Driving",
    "authors": [
      "Jingyi Wang",
      "Duanfeng Chu",
      "Zejian Deng",
      "Liping Lu",
      "Jinxiang Wang",
      "Chen Sun"
    ],
    "abstract": "To address the challenge of insufficient interactivity and behavioral\ndiversity in autonomous driving decision-making, this paper proposes a\nCognitive Hierarchical Agent for Reasoning and Motion Stylization (CHARMS). By\nleveraging Level-k game theory, CHARMS captures human-like reasoning patterns\nthrough a two-stage training pipeline comprising reinforcement learning\npretraining and supervised fine-tuning. This enables the resulting models to\nexhibit diverse and human-like behaviors, enhancing their decision-making\ncapacity and interaction fidelity in complex traffic environments. Building\nupon this capability, we further develop a scenario generation framework that\nutilizes the Poisson cognitive hierarchy theory to control the distribution of\nvehicles with different driving styles through Poisson and binomial sampling.\nExperimental results demonstrate that CHARMS is capable of both making\nintelligent driving decisions as an ego vehicle and generating diverse,\nrealistic driving scenarios as environment vehicles. The code for CHARMS is\nreleased at https://github.com/chuduanfeng/CHARMS.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02450v3",
    "published_date": "2025-04-03 10:15:19 UTC",
    "updated_date": "2025-04-28 15:26:59 UTC"
  },
  {
    "arxiv_id": "2504.02441v2",
    "title": "Cognitive Memory in Large Language Models",
    "authors": [
      "Lianlei Shan",
      "Shixian Luo",
      "Zezhou Zhu",
      "Yu Yuan",
      "Yong Wu"
    ],
    "abstract": "This paper examines memory mechanisms in Large Language Models (LLMs),\nemphasizing their importance for context-rich responses, reduced\nhallucinations, and improved efficiency. It categorizes memory into sensory,\nshort-term, and long-term, with sensory memory corresponding to input prompts,\nshort-term memory processing immediate context, and long-term memory\nimplemented via external databases or structures. The text-based memory section\ncovers acquisition (selection and summarization), management (updating,\naccessing, storing, and resolving conflicts), and utilization (full-text\nsearch, SQL queries, semantic search). The KV cache-based memory section\ndiscusses selection methods (regularity-based summarization, score-based\napproaches, special token embeddings) and compression techniques (low-rank\ncompression, KV merging, multimodal compression), along with management\nstrategies like offloading and shared attention mechanisms. Parameter-based\nmemory methods (LoRA, TTT, MoE) transform memories into model parameters to\nenhance efficiency, while hidden-state-based memory approaches (chunk\nmechanisms, recurrent transformers, Mamba model) improve long-text processing\nby combining RNN hidden states with current methods. Overall, the paper offers\na comprehensive analysis of LLM memory mechanisms, highlighting their\nsignificance and future research directions.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "37 pages, 9 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02441v2",
    "published_date": "2025-04-03 09:58:19 UTC",
    "updated_date": "2025-04-24 01:47:25 UTC"
  },
  {
    "arxiv_id": "2504.02438v4",
    "title": "Scaling Video-Language Models to 10K Frames via Hierarchical Differential Distillation",
    "authors": [
      "Chuanqi Cheng",
      "Jian Guan",
      "Wei Wu",
      "Rui Yan"
    ],
    "abstract": "Long-form video processing fundamentally challenges vision-language models\n(VLMs) due to the high computational costs of handling extended temporal\nsequences. Existing token pruning and feature merging methods often sacrifice\ncritical temporal dependencies or dilute semantic information. We introduce\ndifferential distillation, a principled approach that systematically preserves\ntask-relevant information while suppressing redundancy. Based on this\nprinciple, we develop ViLAMP, a hierarchical video-language model that\nprocesses hour-long videos at \"mixed precision\" through two key mechanisms: (1)\ndifferential keyframe selection that maximizes query relevance while\nmaintaining temporal distinctiveness at the frame level and (2) differential\nfeature merging that preserves query-salient features in non-keyframes at the\npatch level. Hence, ViLAMP retains full information in keyframes while reducing\nnon-keyframes to their most salient features, resembling mixed-precision\ntraining. Extensive experiments demonstrate ViLAMP's superior performance\nacross five video understanding benchmarks, particularly on long-form content.\nNotably, ViLAMP can process ultra-long videos (up to 10K frames) on a single\nNVIDIA A100 GPU, achieving substantial computational efficiency while\nmaintaining state-of-the-art performance. Code and model are available at\nhttps://github.com/steven-ccq/ViLAMP.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by ICML 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02438v4",
    "published_date": "2025-04-03 09:55:09 UTC",
    "updated_date": "2025-05-20 09:55:21 UTC"
  },
  {
    "arxiv_id": "2504.02430v1",
    "title": "How Artificial Intelligence Leads to Knowledge Why: An Inquiry Inspired by Aristotle's Posterior Analytics",
    "authors": [
      "Guus Eelink",
      "Kilian Rückschloß",
      "Felix Weitkämper"
    ],
    "abstract": "Bayesian networks and causal models provide frameworks for handling queries\nabout external interventions and counterfactuals, enabling tasks that go beyond\nwhat probability distributions alone can address. While these formalisms are\noften informally described as capturing causal knowledge, there is a lack of a\nformal theory characterizing the type of knowledge required to predict the\neffects of external interventions. This work introduces the theoretical\nframework of causal systems to clarify Aristotle's distinction between\nknowledge that and knowledge why within artificial intelligence. By\ninterpreting existing artificial intelligence technologies as causal systems,\nit investigates the corresponding types of knowledge. Furthermore, it argues\nthat predicting the effects of external interventions is feasible only with\nknowledge why, providing a more precise understanding of the knowledge\nnecessary for such tasks.",
    "categories": [
      "cs.AI",
      "cs.LO",
      "I.2.4"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02430v1",
    "published_date": "2025-04-03 09:37:05 UTC",
    "updated_date": "2025-04-03 09:37:05 UTC"
  },
  {
    "arxiv_id": "2504.02426v1",
    "title": "Narrative Studio: Visual narrative exploration using LLMs and Monte Carlo Tree Search",
    "authors": [
      "Parsa Ghaffari",
      "Chris Hokamp"
    ],
    "abstract": "Interactive storytelling benefits from planning and exploring multiple 'what\nif' scenarios. Modern LLMs are useful tools for ideation and exploration, but\ncurrent chat-based user interfaces restrict users to a single linear flow. To\naddress this limitation, we propose Narrative Studio -- a novel in-browser\nnarrative exploration environment featuring a tree-like interface that allows\nbranching exploration from user-defined points in a story. Each branch is\nextended via iterative LLM inference guided by system and user-defined prompts.\nAdditionally, we employ Monte Carlo Tree Search (MCTS) to automatically expand\npromising narrative paths based on user-specified criteria, enabling more\ndiverse and robust story development. We also allow users to enhance narrative\ncoherence by grounding the generated text in an entity graph that represents\nthe actors and environment of the story.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02426v1",
    "published_date": "2025-04-03 09:31:07 UTC",
    "updated_date": "2025-04-03 09:31:07 UTC"
  },
  {
    "arxiv_id": "2504.02417v1",
    "title": "Leveraging Static Relationships for Intra-Type and Inter-Type Message Passing in Video Question Answering",
    "authors": [
      "Lili Liang",
      "Guanglu Sun"
    ],
    "abstract": "Video Question Answering (VideoQA) is an important research direction in the\nfield of artificial intelligence, enabling machines to understand video content\nand perform reasoning and answering based on natural language questions.\nAlthough methods based on static relationship reasoning have made certain\nprogress, there are still deficiencies in the accuracy of static relationship\nrecognition and representation, and they have not fully utilized the static\nrelationship information in videos for in-depth reasoning and analysis.\nTherefore, this paper proposes a reasoning method for intra-type and inter-type\nmessage passing based on static relationships. This method constructs a dual\ngraph for intra-type message passing reasoning and builds a heterogeneous graph\nbased on static relationships for inter-type message passing reasoning. The\nintra-type message passing reasoning model captures the neighborhood\ninformation of targets and relationships related to the question in the dual\ngraph, updating the dual graph to obtain intra-type clues for answering the\nquestion. The inter-type message passing reasoning model captures the\nneighborhood information of targets and relationships from different categories\nrelated to the question in the heterogeneous graph, updating the heterogeneous\ngraph to obtain inter-type clues for answering the question. Finally, the\nanswers are inferred by combining the intra-type and inter-type clues based on\nstatic relationships. Experimental results on the ANetQA and Next-QA datasets\ndemonstrate the effectiveness of this method.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02417v1",
    "published_date": "2025-04-03 09:14:41 UTC",
    "updated_date": "2025-04-03 09:14:41 UTC"
  },
  {
    "arxiv_id": "2504.02408v1",
    "title": "Translation of Fetal Brain Ultrasound Images into Pseudo-MRI Images using Artificial Intelligence",
    "authors": [
      "Naomi Silverstein",
      "Efrat Leibowitz",
      "Ron Beloosesky",
      "Haim Azhari"
    ],
    "abstract": "Ultrasound is a widely accessible and cost-effective medical imaging tool\ncommonly used for prenatal evaluation of the fetal brain. However, it has\nlimitations, particularly in the third trimester, where the complexity of the\nfetal brain requires high image quality for extracting quantitative data. In\ncontrast, magnetic resonance imaging (MRI) offers superior image quality and\ntissue differentiation but is less available, expensive, and requires\ntime-consuming acquisition. Thus, transforming ultrasonic images into an\nMRI-mimicking display may be advantageous and allow better tissue anatomy\npresentation. To address this goal, we have examined the use of artificial\nintelligence, implementing a diffusion model renowned for generating\nhigh-quality images. The proposed method, termed \"Dual Diffusion Imposed\nCorrelation\" (DDIC), leverages a diffusion-based translation methodology,\nassuming a shared latent space between ultrasound and MRI domains. Model\ntraining was obtained utilizing the \"HC18\" dataset for ultrasound and the \"CRL\nfetal brain atlas\" along with the \"FeTA \" datasets for MRI. The generated\npseudo-MRI images provide notable improvements in visual discrimination of\nbrain tissue, especially in the lateral ventricles and the Sylvian fissure,\ncharacterized by enhanced contrast clarity. Improvement was demonstrated in\nMutual information, Peak signal-to-noise ratio, Fr\\'echet Inception Distance,\nand Contrast-to-noise ratio. Findings from these evaluations indicate\nstatistically significant superior performance of the DDIC compared to other\ntranslation methodologies. In addition, a Medical Opinion Test was obtained\nfrom 5 gynecologists. The results demonstrated display improvement in 81% of\nthe tested images. In conclusion, the presented pseudo-MRI images hold the\npotential for streamlining diagnosis and enhancing clinical outcomes through\nimproved representation.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "13 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02408v1",
    "published_date": "2025-04-03 08:59:33 UTC",
    "updated_date": "2025-04-03 08:59:33 UTC"
  },
  {
    "arxiv_id": "2504.03775v1",
    "title": "FlowKV: A Disaggregated Inference Framework with Low-Latency KV Cache Transfer and Load-Aware Scheduling",
    "authors": [
      "Weiqing Li",
      "Guochao Jiang",
      "Xiangyong Ding",
      "Zhangcheng Tao",
      "Chuzhan Hao",
      "Chenfeng Xu",
      "Yuewei Zhang",
      "Hao Wang"
    ],
    "abstract": "Disaggregated inference has become an essential framework that separates the\nprefill (P) and decode (D) stages in large language model inference to improve\nthroughput. However, the KV cache transfer faces significant delays between\nprefill and decode nodes. The block-wise calling method and discontinuous KV\ncache memory allocation increase the number of calls to the transmission\nkernel. Additionally, existing frameworks often fix the roles of P and D nodes,\nleading to computational imbalances. In this paper, we propose FlowKV, a novel\ndisaggregated inference framework, which reduces the average transmission\nlatency of KV cache by 96%, from 0.944s to 0.053s, almost eliminating the\ntransfer time relative to the total request latency by optimizing the KV cache\ntransfer. FlowKV introduces the Load-Aware Scheduler for balanced request\nscheduling and flexible PD node allocation. This design maximizes hardware\nresource utilization, achieving peak system throughput across various\nscenarios, including normal, computational imbalance, and extreme overload\nconditions. Experimental results demonstrate that FlowKV significantly\naccelerates inference by 15.2%-48.9% on LongBench dataset compared to the\nbaseline and supports applications with heterogeneous GPUs.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03775v1",
    "published_date": "2025-04-03 08:58:05 UTC",
    "updated_date": "2025-04-03 08:58:05 UTC"
  },
  {
    "arxiv_id": "2504.02402v1",
    "title": "EvMic: Event-based Non-contact sound recovery from effective spatial-temporal modeling",
    "authors": [
      "Hao Yin",
      "Shi Guo",
      "Xu Jia",
      "Xudong XU",
      "Lu Zhang",
      "Si Liu",
      "Dong Wang",
      "Huchuan Lu",
      "Tianfan Xue"
    ],
    "abstract": "When sound waves hit an object, they induce vibrations that produce\nhigh-frequency and subtle visual changes, which can be used for recovering the\nsound. Early studies always encounter trade-offs related to sampling rate,\nbandwidth, field of view, and the simplicity of the optical path. Recent\nadvances in event camera hardware show good potential for its application in\nvisual sound recovery, because of its superior ability in capturing\nhigh-frequency signals. However, existing event-based vibration recovery\nmethods are still sub-optimal for sound recovery. In this work, we propose a\nnovel pipeline for non-contact sound recovery, fully utilizing spatial-temporal\ninformation from the event stream. We first generate a large training set using\na novel simulation pipeline. Then we designed a network that leverages the\nsparsity of events to capture spatial information and uses Mamba to model\nlong-term temporal information. Lastly, we train a spatial aggregation block to\naggregate information from different locations to further improve signal\nquality. To capture event signals caused by sound waves, we also designed an\nimaging system using a laser matrix to enhance the gradient and collected\nmultiple data sequences for testing. Experimental results on synthetic and\nreal-world data demonstrate the effectiveness of our method.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Our project page: https://yyzq1.github.io/EvMic/",
    "pdf_url": "http://arxiv.org/pdf/2504.02402v1",
    "published_date": "2025-04-03 08:51:17 UTC",
    "updated_date": "2025-04-03 08:51:17 UTC"
  },
  {
    "arxiv_id": "2504.02388v3",
    "title": "Steiner Traveling Salesman Problem with Quantum Annealing",
    "authors": [
      "Alessia Ciacco",
      "Francesca Guerriero",
      "Eneko Osaba"
    ],
    "abstract": "The Steiner Traveling Salesman Problem (STSP) is a variant of the classical\nTraveling Salesman Problem. The STSP involves incorporating steiner nodes,\nwhich are extra nodes not originally part of the required visit set but that\ncan be added to the route to enhance the overall solution and minimize the\ntotal travel cost. Given the NP-hard nature of the STSP, we propose a quantum\napproach to address it. Specifically, we employ quantum annealing using\nD-Wave's hardware to explore its potential for solving this problem. To enhance\ncomputational feasibility, we develop a preprocessing method that effectively\nreduces the network size. Our experimental results demonstrate that this\nreduction technique significantly decreases the problem complexity, making the\nQuadratic Unconstrained Binary Optimization formulation, the standard input for\nquantum annealers, better suited for existing quantum hardware. Furthermore,\nthe results highlight the potential of quantum annealing as a promising and\ninnovative approach for solving the STSP.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.ET"
    ],
    "primary_category": "quant-ph",
    "comment": "7 pages, 1 figure, 6 tables. Paper accepted in The Genetic and\n  Evolutionary Computation Conference (GECCO 2025)",
    "pdf_url": "http://arxiv.org/pdf/2504.02388v3",
    "published_date": "2025-04-03 08:29:57 UTC",
    "updated_date": "2025-05-13 16:49:40 UTC"
  },
  {
    "arxiv_id": "2504.03774v1",
    "title": "Exploring energy consumption of AI frameworks on a 64-core RV64 Server CPU",
    "authors": [
      "Giulio Malenza",
      "Francesco Targa",
      "Adriano Marques Garcia",
      "Marco Aldinucci",
      "Robert Birke"
    ],
    "abstract": "In today's era of rapid technological advancement, artificial intelligence\n(AI) applications require large-scale, high-performance, and data-intensive\ncomputations, leading to significant energy demands. Addressing this challenge\nnecessitates a combined approach involving both hardware and software\ninnovations. Hardware manufacturers are developing new, efficient, and\nspecialized solutions, with the RISC-V architecture emerging as a prominent\nplayer due to its open, extensible, and energy-efficient instruction set\narchitecture (ISA). Simultaneously, software developers are creating new\nalgorithms and frameworks, yet their energy efficiency often remains unclear.\nIn this study, we conduct a comprehensive benchmark analysis of machine\nlearning (ML) applications on the 64-core SOPHON SG2042 RISC-V architecture. We\nspecifically analyze the energy consumption of deep learning inference models\nacross three leading AI frameworks: PyTorch, ONNX Runtime, and TensorFlow. Our\nfindings show that frameworks using the XNNPACK back-end, such as ONNX Runtime\nand TensorFlow, consume less energy compared to PyTorch, which is compiled with\nthe native OpenBLAS back-end.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03774v1",
    "published_date": "2025-04-03 08:27:10 UTC",
    "updated_date": "2025-04-03 08:27:10 UTC"
  },
  {
    "arxiv_id": "2504.02382v1",
    "title": "Benchmark of Segmentation Techniques for Pelvic Fracture in CT and X-ray: Summary of the PENGWIN 2024 Challenge",
    "authors": [
      "Yudi Sang",
      "Yanzhen Liu",
      "Sutuke Yibulayimu",
      "Yunning Wang",
      "Benjamin D. Killeen",
      "Mingxu Liu",
      "Ping-Cheng Ku",
      "Ole Johannsen",
      "Karol Gotkowski",
      "Maximilian Zenk",
      "Klaus Maier-Hein",
      "Fabian Isensee",
      "Peiyan Yue",
      "Yi Wang",
      "Haidong Yu",
      "Zhaohong Pan",
      "Yutong He",
      "Xiaokun Liang",
      "Daiqi Liu",
      "Fuxin Fan",
      "Artur Jurgas",
      "Andrzej Skalski",
      "Yuxi Ma",
      "Jing Yang",
      "Szymon Płotka",
      "Rafał Litka",
      "Gang Zhu",
      "Yingchun Song",
      "Mathias Unberath",
      "Mehran Armand",
      "Dan Ruan",
      "S. Kevin Zhou",
      "Qiyong Cao",
      "Chunpeng Zhao",
      "Xinbao Wu",
      "Yu Wang"
    ],
    "abstract": "The segmentation of pelvic fracture fragments in CT and X-ray images is\ncrucial for trauma diagnosis, surgical planning, and intraoperative guidance.\nHowever, accurately and efficiently delineating the bone fragments remains a\nsignificant challenge due to complex anatomy and imaging limitations. The\nPENGWIN challenge, organized as a MICCAI 2024 satellite event, aimed to advance\nautomated fracture segmentation by benchmarking state-of-the-art algorithms on\nthese complex tasks. A diverse dataset of 150 CT scans was collected from\nmultiple clinical centers, and a large set of simulated X-ray images was\ngenerated using the DeepDRR method. Final submissions from 16 teams worldwide\nwere evaluated under a rigorous multi-metric testing scheme. The top-performing\nCT algorithm achieved an average fragment-wise intersection over union (IoU) of\n0.930, demonstrating satisfactory accuracy. However, in the X-ray task, the\nbest algorithm attained an IoU of 0.774, highlighting the greater challenges\nposed by overlapping anatomical structures. Beyond the quantitative evaluation,\nthe challenge revealed methodological diversity in algorithm design. Variations\nin instance representation, such as primary-secondary classification versus\nboundary-core separation, led to differing segmentation strategies. Despite\npromising results, the challenge also exposed inherent uncertainties in\nfragment definition, particularly in cases of incomplete fractures. These\nfindings suggest that interactive segmentation approaches, integrating human\ndecision-making with task-relevant information, may be essential for improving\nmodel reliability and clinical applicability.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "eess.IV",
    "comment": "PENGWIN 2024 Challenge Report",
    "pdf_url": "http://arxiv.org/pdf/2504.02382v1",
    "published_date": "2025-04-03 08:19:36 UTC",
    "updated_date": "2025-04-03 08:19:36 UTC"
  },
  {
    "arxiv_id": "2504.03773v1",
    "title": "SHapley Estimated Explanation (SHEP): A Fast Post-Hoc Attribution Method for Interpreting Intelligent Fault Diagnosis",
    "authors": [
      "Qian Chen",
      "Xingjian Dong",
      "Zhike Peng",
      "Guang Meng"
    ],
    "abstract": "Despite significant progress in intelligent fault diagnosis (IFD), the lack\nof interpretability remains a critical barrier to practical industrial\napplications, driving the growth of interpretability research in IFD. Post-hoc\ninterpretability has gained popularity due to its ability to preserve network\nflexibility and scalability without modifying model structures. However, these\nmethods often yield suboptimal time-domain explanations. Recently, combining\ndomain transform with SHAP has improved interpretability by extending\nexplanations to more informative domains. Nonetheless, the computational\nexpense of SHAP, exacerbated by increased dimensions from domain transforms,\nremains a major challenge. To address this, we propose patch-wise attribution\nand SHapley Estimated Explanation (SHEP). Patch-wise attribution reduces\nfeature dimensions at the cost of explanation granularity, while SHEP\nsimplifies subset enumeration to approximate SHAP, reducing complexity from\nexponential to linear. Together, these methods significantly enhance SHAP's\ncomputational efficiency, providing feasibility for real-time interpretation in\nmonitoring tasks. Extensive experiments confirm SHEP's efficiency,\ninterpretability, and reliability in approximating SHAP. Additionally, with\nopen-source code, SHEP has the potential to serve as a benchmark for post-hoc\ninterpretability in IFD. The code is available on\nhttps://github.com/ChenQian0618/SHEP.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 21 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.03773v1",
    "published_date": "2025-04-03 07:56:07 UTC",
    "updated_date": "2025-04-03 07:56:07 UTC"
  },
  {
    "arxiv_id": "2504.02906v1",
    "title": "Enhancing Chart-to-Code Generation in Multimodal Large Language Models via Iterative Dual Preference Learning",
    "authors": [
      "Zhihan Zhang",
      "Yixin Cao",
      "Lizi Liao"
    ],
    "abstract": "Chart-to-code generation, the process of converting chart images into\nexecutable plotting scripts, provides a lossless representation of chart\ninformation, requiring models to accurately capture and summarize all visual\nand structural elements. However, this remains a significant challenge for\nmultimodal large language models (MLLMs), which are not inherently well-aligned\nwith code generation tasks. To bridge this gap, we introduce Chart2Code, a\nnovel iterative dual preference learning framework designed to enhance MLLMs'\nchart-to-code generation capabilities through structured code variant\ngeneration and fine-grained dual reward signals. We validate Chart2Code across\nthree MLLMs and find that iterative preference learning consistently improves\nout-of-distribution chart-to-code generation quality. Throughout this process,\nour dual scoring method, which evaluates both the textual code structure and\nits visual representation, leads to greater performance improvements, even with\na reduced preference dataset size. Further analysis explores the key components\nof our framework and highlights the interplay between chart-to-code generation\nand broader chart reasoning, paving the way for future advancements in chart\ncomprehension.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "21 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2504.02906v1",
    "published_date": "2025-04-03 07:51:20 UTC",
    "updated_date": "2025-04-03 07:51:20 UTC"
  },
  {
    "arxiv_id": "2504.02351v1",
    "title": "Agglomerating Large Vision Encoders via Distillation for VFSS Segmentation",
    "authors": [
      "Chengxi Zeng",
      "Yuxuan Jiang",
      "Fan Zhang",
      "Alberto Gambaruto",
      "Tilo Burghardt"
    ],
    "abstract": "The deployment of foundation models for medical imaging has demonstrated\nconsiderable success. However, their training overheads associated with\ndownstream tasks remain substantial due to the size of the image encoders\nemployed, and the inference complexity is also significantly high. Although\nlightweight variants have been obtained for these foundation models, their\nperformance is constrained by their limited model capacity and suboptimal\ntraining strategies. In order to achieve an improved tradeoff between\ncomplexity and performance, we propose a new framework to improve the\nperformance of low complexity models via knowledge distillation from multiple\nlarge medical foundation models (e.g., MedSAM, RAD-DINO, MedCLIP), each\nspecializing in different vision tasks, with the goal to effectively bridge the\nperformance gap for medical image segmentation tasks. The agglomerated model\ndemonstrates superior generalization across 12 segmentation tasks, whereas\nspecialized models require explicit training for each task. Our approach\nachieved an average performance gain of 2\\% in Dice coefficient compared to\nsimple distillation.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02351v1",
    "published_date": "2025-04-03 07:38:09 UTC",
    "updated_date": "2025-04-03 07:38:09 UTC"
  },
  {
    "arxiv_id": "2504.08772v1",
    "title": "Reward Generation via Large Vision-Language Model in Offline Reinforcement Learning",
    "authors": [
      "Younghwan Lee",
      "Tung M. Luu",
      "Donghoon Lee",
      "Chang D. Yoo"
    ],
    "abstract": "In offline reinforcement learning (RL), learning from fixed datasets presents\na promising solution for domains where real-time interaction with the\nenvironment is expensive or risky. However, designing dense reward signals for\noffline dataset requires significant human effort and domain expertise.\nReinforcement learning with human feedback (RLHF) has emerged as an\nalternative, but it remains costly due to the human-in-the-loop process,\nprompting interest in automated reward generation models. To address this, we\npropose Reward Generation via Large Vision-Language Models (RG-VLM), which\nleverages the reasoning capabilities of LVLMs to generate rewards from offline\ndata without human involvement. RG-VLM improves generalization in long-horizon\ntasks and can be seamlessly integrated with the sparse reward signals to\nenhance task performance, demonstrating its potential as an auxiliary reward\nsignal.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "5 pages, ICASSP 2025. First two authors are equally contributed",
    "pdf_url": "http://arxiv.org/pdf/2504.08772v1",
    "published_date": "2025-04-03 07:11:18 UTC",
    "updated_date": "2025-04-03 07:11:18 UTC"
  },
  {
    "arxiv_id": "2504.02317v1",
    "title": "Temporal Gaussian Copula For Clinical Multivariate Time Series Data Imputation",
    "authors": [
      "Ye Su",
      "Hezhe Qiao",
      "Di Wu",
      "Yuwen Chen",
      "Lin Chen"
    ],
    "abstract": "The imputation of the Multivariate time series (MTS) is particularly\nchallenging since the MTS typically contains irregular patterns of missing\nvalues due to various factors such as instrument failures, interference from\nirrelevant data, and privacy regulations. Existing statistical methods and deep\nlearning methods have shown promising results in time series imputation. In\nthis paper, we propose a Temporal Gaussian Copula Model (TGC) for three-order\nMTS imputation. The key idea is to leverage the Gaussian Copula to explore the\ncross-variable and temporal relationships based on the latent Gaussian\nrepresentation. Subsequently, we employ an Expectation-Maximization (EM)\nalgorithm to improve robustness in managing data with varying missing rates.\nComprehensive experiments were conducted on three real-world MTS datasets. The\nresults demonstrate that our TGC substantially outperforms the state-of-the-art\nimputation methods. Additionally, the TGC model exhibits stronger robustness to\nthe varying missing ratios in the test dataset. Our code is available at\nhttps://github.com/MVL-Lab/TGC-MTS.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted in BIBM2024",
    "pdf_url": "http://arxiv.org/pdf/2504.02317v1",
    "published_date": "2025-04-03 06:44:05 UTC",
    "updated_date": "2025-04-03 06:44:05 UTC"
  },
  {
    "arxiv_id": "2504.02316v1",
    "title": "ConsDreamer: Advancing Multi-View Consistency for Zero-Shot Text-to-3D Generation",
    "authors": [
      "Yuan Zhou",
      "Shilong Jin",
      "Litao Hua",
      "Wanjun Lv",
      "Haoran Duan",
      "Jungong Han"
    ],
    "abstract": "Recent advances in zero-shot text-to-3D generation have revolutionized 3D\ncontent creation by enabling direct synthesis from textual descriptions. While\nstate-of-the-art methods leverage 3D Gaussian Splatting with score distillation\nto enhance multi-view rendering through pre-trained text-to-image (T2I) models,\nthey suffer from inherent view biases in T2I priors. These biases lead to\ninconsistent 3D generation, particularly manifesting as the multi-face Janus\nproblem, where objects exhibit conflicting features across views. To address\nthis fundamental challenge, we propose ConsDreamer, a novel framework that\nmitigates view bias by refining both the conditional and unconditional terms in\nthe score distillation process: (1) a View Disentanglement Module (VDM) that\neliminates viewpoint biases in conditional prompts by decoupling irrelevant\nview components and injecting precise camera parameters; and (2) a\nsimilarity-based partial order loss that enforces geometric consistency in the\nunconditional term by aligning cosine similarities with azimuth relationships.\nExtensive experiments demonstrate that ConsDreamer effectively mitigates the\nmulti-face Janus problem in text-to-3D generation, outperforming existing\nmethods in both visual quality and consistency.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "13 pages, 11 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2504.02316v1",
    "published_date": "2025-04-03 06:43:23 UTC",
    "updated_date": "2025-04-03 06:43:23 UTC"
  },
  {
    "arxiv_id": "2504.02312v1",
    "title": "OmniCam: Unified Multimodal Video Generation via Camera Control",
    "authors": [
      "Xiaoda Yang",
      "Jiayang Xu",
      "Kaixuan Luan",
      "Xinyu Zhan",
      "Hongshun Qiu",
      "Shijun Shi",
      "Hao Li",
      "Shuai Yang",
      "Li Zhang",
      "Checheng Yu",
      "Cewu Lu",
      "Lixin Yang"
    ],
    "abstract": "Camera control, which achieves diverse visual effects by changing camera\nposition and pose, has attracted widespread attention. However, existing\nmethods face challenges such as complex interaction and limited control\ncapabilities. To address these issues, we present OmniCam, a unified multimodal\ncamera control framework. Leveraging large language models and video diffusion\nmodels, OmniCam generates spatio-temporally consistent videos. It supports\nvarious combinations of input modalities: the user can provide text or video\nwith expected trajectory as camera path guidance, and image or video as content\nreference, enabling precise control over camera motion. To facilitate the\ntraining of OmniCam, we introduce the OmniTr dataset, which contains a large\ncollection of high-quality long-sequence trajectories, videos, and\ncorresponding descriptions. Experimental results demonstrate that our model\nachieves state-of-the-art performance in high-quality camera-controlled video\ngeneration across various metrics.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02312v1",
    "published_date": "2025-04-03 06:38:30 UTC",
    "updated_date": "2025-04-03 06:38:30 UTC"
  },
  {
    "arxiv_id": "2504.02904v1",
    "title": "How Post-Training Reshapes LLMs: A Mechanistic View on Knowledge, Truthfulness, Refusal, and Confidence",
    "authors": [
      "Hongzhe Du",
      "Weikai Li",
      "Min Cai",
      "Karim Saraipour",
      "Zimin Zhang",
      "Himabindu Lakkaraju",
      "Yizhou Sun",
      "Shichang Zhang"
    ],
    "abstract": "Post-training is essential for the success of large language models (LLMs),\ntransforming pre-trained base models into more useful and aligned post-trained\nmodels. While plenty of works have studied post-training algorithms and\nevaluated post-training models by their outputs, it remains understudied how\npost-training reshapes LLMs internally. In this paper, we compare base and\npost-trained LLMs mechanistically from four perspectives to better understand\npost-training effects. Our findings across model families and datasets reveal\nthat: (1) Post-training does not change the factual knowledge storage\nlocations, and it adapts knowledge representations from the base model while\ndeveloping new knowledge representations; (2) Both truthfulness and refusal can\nbe represented by linear vectors in the hidden representation space. The\ntruthfulness direction is highly similar between the base and post-trained\nmodel, and it is effectively transferable for interventions; (3) The refusal\ndirection is different between the base and post-trained models, and it shows\nlimited forward transferability; (4) Differences in confidence between the base\nand post-trained models cannot be attributed to entropy neurons. Our study\nprovides insights into the fundamental mechanisms preserved and altered during\npost-training, facilitates downstream tasks like model steering, and could\npotentially benefit future research in interpretability and LLM post-training.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02904v1",
    "published_date": "2025-04-03 06:30:55 UTC",
    "updated_date": "2025-04-03 06:30:55 UTC"
  },
  {
    "arxiv_id": "2504.02293v1",
    "title": "State-of-the-Art Translation of Text-to-Gloss using mBART : A case study of Bangla",
    "authors": [
      "Sharif Md. Abdullah",
      "Abhijit Paul",
      "Shebuti Rayana",
      "Ahmedul Kabir",
      "Zarif Masud"
    ],
    "abstract": "Despite a large deaf and dumb population of 1.7 million, Bangla Sign Language\n(BdSL) remains a understudied domain. Specifically, there are no works on\nBangla text-to-gloss translation task. To address this gap, we begin by\naddressing the dataset problem. We take inspiration from grammatical rule based\ngloss generation used in Germany and American sign langauage (ASL) and adapt it\nfor BdSL. We also leverage LLM to generate synthetic data and use\nback-translation, text generation for data augmentation. With dataset prepared,\nwe started experimentation. We fine-tuned pretrained mBART-50 and\nmBERT-multiclass-uncased model on our dataset. We also trained GRU, RNN and a\nnovel seq-to-seq model with multi-head attention. We observe significant high\nperformance (ScareBLEU=79.53) with fine-tuning pretrained mBART-50 multilingual\nmodel from Facebook. We then explored why we observe such high performance with\nmBART. We soon notice an interesting property of mBART -- it was trained on\nshuffled and masked text data. And as we know, gloss form has shuffling\nproperty. So we hypothesize that mBART is inherently good at text-to-gloss\ntasks. To find support against this hypothesis, we trained mBART-50 on\nPHOENIX-14T benchmark and evaluated it with existing literature. Our mBART-50\nfinetune demonstrated State-of-the-Art performance on PHOENIX-14T benchmark,\nfar outperforming existing models in all 6 metrics (ScareBLEU = 63.89, BLEU-1 =\n55.14, BLEU-2 = 38.07, BLEU-3 = 27.13, BLEU-4 = 20.68, COMET = 0.624). Based on\nthe results, this study proposes a new paradigm for text-to-gloss task using\nmBART models. Additionally, our results show that BdSL text-to-gloss task can\ngreatly benefit from rule-based synthetic dataset.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Initial Version",
    "pdf_url": "http://arxiv.org/pdf/2504.02293v1",
    "published_date": "2025-04-03 05:47:51 UTC",
    "updated_date": "2025-04-03 05:47:51 UTC"
  },
  {
    "arxiv_id": "2504.03771v1",
    "title": "Flow State: Humans Enabling AI Systems to Program Themselves",
    "authors": [
      "Helena Zhang",
      "Jakobi Haskell",
      "Yosef Frost"
    ],
    "abstract": "Compound AI systems, orchestrating multiple AI components and external APIs,\nare increasingly vital but face challenges in managing complexity, handling\nambiguity, and enabling effective development workflows. Existing frameworks\noften introduce significant overhead, implicit complexity, or restrictive\nabstractions, hindering maintainability and iterative refinement, especially in\nHuman-AI collaborative settings. We argue that overcoming these hurdles\nrequires a foundational architecture prioritizing structural clarity and\nexplicit control. To this end, we introduce Pocketflow, a platform centered on\nHuman-AI co-design, enabled by Pocketflow. Pocketflow is a Python framework\nbuilt upon a deliberately minimal yet synergistic set of core abstractions:\nmodular Nodes with a strict lifecycle, declarative Flow orchestration, native\nhierarchical nesting (Flow-as-Node), and explicit action-based conditional\nlogic. This unique combination provides a robust, vendor-agnostic foundation\nwith very little code that demonstrably reduces overhead while offering the\nexpressiveness needed for complex patterns like agentic workflows and RAG.\nComplemented by Pocket AI, an assistant leveraging this structure for system\ndesign, Pocketflow provides an effective environment for iteratively\nprototyping, refining, and deploying the adaptable, scalable AI systems\ndemanded by modern enterprises.",
    "categories": [
      "cs.AI",
      "68T99, 68N19, 68U35",
      "I.2.1; D.2.11; H.5.2"
    ],
    "primary_category": "cs.AI",
    "comment": "25 pages, 4 figures, 5 tables. Describes a minimalist framework for\n  human-AI co-design of compound AI systems",
    "pdf_url": "http://arxiv.org/pdf/2504.03771v1",
    "published_date": "2025-04-03 05:25:46 UTC",
    "updated_date": "2025-04-03 05:25:46 UTC"
  },
  {
    "arxiv_id": "2504.02285v1",
    "title": "Tree-based Models for Vertical Federated Learning: A Survey",
    "authors": [
      "Bingchen Qian",
      "Yuexiang Xie",
      "Yaliang Li",
      "Bolin Ding",
      "Jingren Zhou"
    ],
    "abstract": "Tree-based models have achieved great success in a wide range of real-world\napplications due to their effectiveness, robustness, and interpretability,\nwhich inspired people to apply them in vertical federated learning (VFL)\nscenarios in recent years. In this paper, we conduct a comprehensive study to\ngive an overall picture of applying tree-based models in VFL, from the\nperspective of their communication and computation protocols. We categorize\ntree-based models in VFL into two types, i.e., feature-gathering models and\nlabel-scattering models, and provide a detailed discussion regarding their\ncharacteristics, advantages, privacy protection mechanisms, and applications.\nThis study also focuses on the implementation of tree-based models in VFL,\nsummarizing several design principles for better satisfying various\nrequirements from both academic research and industrial deployment. We conduct\na series of experiments to provide empirical observations on the differences\nand advances of different types of tree-based models.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by ACM Computing Surveys (CSUR)",
    "pdf_url": "http://arxiv.org/pdf/2504.02285v1",
    "published_date": "2025-04-03 05:16:09 UTC",
    "updated_date": "2025-04-03 05:16:09 UTC"
  },
  {
    "arxiv_id": "2504.03770v2",
    "title": "JailDAM: Jailbreak Detection with Adaptive Memory for Vision-Language Model",
    "authors": [
      "Yi Nian",
      "Shenzhe Zhu",
      "Yuehan Qin",
      "Li Li",
      "Ziyi Wang",
      "Chaowei Xiao",
      "Yue Zhao"
    ],
    "abstract": "Multimodal large language models (MLLMs) excel in vision-language tasks but\nalso pose significant risks of generating harmful content, particularly through\njailbreak attacks. Jailbreak attacks refer to intentional manipulations that\nbypass safety mechanisms in models, leading to the generation of inappropriate\nor unsafe content. Detecting such attacks is critical to ensuring the\nresponsible deployment of MLLMs. Existing jailbreak detection methods face\nthree primary challenges: (1) Many rely on model hidden states or gradients,\nlimiting their applicability to white-box models, where the internal workings\nof the model are accessible; (2) They involve high computational overhead from\nuncertainty-based analysis, which limits real-time detection, and (3) They\nrequire fully labeled harmful datasets, which are often scarce in real-world\nsettings. To address these issues, we introduce a test-time adaptive framework\ncalled JAILDAM. Our method leverages a memory-based approach guided by\npolicy-driven unsafe knowledge representations, eliminating the need for\nexplicit exposure to harmful data. By dynamically updating unsafe knowledge\nduring test-time, our framework improves generalization to unseen jailbreak\nstrategies while maintaining efficiency. Experiments on multiple VLM jailbreak\nbenchmarks demonstrate that JAILDAM delivers state-of-the-art performance in\nharmful content detection, improving both accuracy and speed.",
    "categories": [
      "cs.CR",
      "cs.AI"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.03770v2",
    "published_date": "2025-04-03 05:00:28 UTC",
    "updated_date": "2025-04-08 20:25:30 UTC"
  },
  {
    "arxiv_id": "2504.02277v2",
    "title": "Beyond Conventional Transformers: The Medical X-ray Attention (MXA) Block for Improved Multi-Label Diagnosis Using Knowledge Distillation",
    "authors": [
      "Amit Rand",
      "Hadi Ibrahim"
    ],
    "abstract": "Medical imaging, particularly X-ray analysis, often involves detecting\nmultiple conditions simultaneously within a single scan, making multi-label\nclassification crucial for real-world clinical applications. We present the\nMedical X-ray Attention (MXA) block, a novel attention mechanism tailored\nspecifically to address the unique challenges of X-ray abnormality detection.\nThe MXA block enhances traditional Multi-Head Self Attention (MHSA) by\nintegrating a specialized module that efficiently captures both detailed local\ninformation and broader global context. To the best of our knowledge, this is\nthe first work to propose a task-specific attention mechanism for diagnosing\nchest X-rays, as well as to attempt multi-label classification using an\nEfficient Vision Transformer (EfficientViT). By embedding the MXA block within\nthe EfficientViT architecture and employing knowledge distillation, our\nproposed model significantly improves performance on the CheXpert dataset, a\nwidely used benchmark for multi-label chest X-ray abnormality detection. Our\napproach achieves an area under the curve (AUC) of 0.85, an absolute\nimprovement of 0.19 compared to our baseline model's AUC of 0.66, corresponding\nto a substantial approximate 233% relative improvement over random guessing\n(AUC = 0.5).",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "19 pages, 9 figures, 6 tables. For supplementary material and code,\n  see https://github.com/Hadi-M-Ibrahim/Beyond-Conventional-Transformers/",
    "pdf_url": "http://arxiv.org/pdf/2504.02277v2",
    "published_date": "2025-04-03 04:55:42 UTC",
    "updated_date": "2025-05-18 05:07:13 UTC"
  },
  {
    "arxiv_id": "2504.02902v1",
    "title": "Beyond Accuracy: The Role of Calibration in Self-Improving Large Language Models",
    "authors": [
      "Liangjie Huang",
      "Dawei Li",
      "Huan Liu",
      "Lu Cheng"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated remarkable self-improvement\ncapabilities, whereby models iteratively revise their outputs through\nself-generated feedback. While this reflective mechanism has shown promise in\nenhancing task performance, recent studies suggest that it may also introduce\nundesirable biases-most notably, self-bias, or the tendency of LLMs to favor\ntheir own prior outputs. In this work, we extend this line of inquiry by\ninvestigating the impact on confidence estimation. We evaluate three\nrepresentative self-improvement paradigms-basic prompting, Chain-of-Thought\n(CoT) prompting, and tuning-based methods and find that iterative\nself-improvement can lead to systematic overconfidence, as evidenced by a\nsteadily increasing Expected Calibration Error (ECE) and lower accuracy with\nhigh confidence. We then further explore the integration of confidence\ncalibration techniques with self-improvement. Specifically, we compare three\nstrategies: (1) applying calibration after multiple rounds of self-improvement,\n(2) calibrating before self-improvement, and (3) applying calibration\niteratively at each self-improvement step. Our results show that iterative\ncalibration is most effective in reducing ECE, yielding improved calibration.\nOur work pioneers the study of self-improving LLMs from a calibration\nperspective, offering valuable insights into balancing model performance and\nreliability.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02902v1",
    "published_date": "2025-04-03 04:39:54 UTC",
    "updated_date": "2025-04-03 04:39:54 UTC"
  },
  {
    "arxiv_id": "2504.02901v1",
    "title": "Hide and Seek in Noise Labels: Noise-Robust Collaborative Active Learning with LLM-Powered Assistance",
    "authors": [
      "Bo Yuan",
      "Yulin Chen",
      "Yin Zhang",
      "Wei Jiang"
    ],
    "abstract": "Learning from noisy labels (LNL) is a challenge that arises in many\nreal-world scenarios where collected training data can contain incorrect or\ncorrupted labels. Most existing solutions identify noisy labels and adopt\nactive learning to query human experts on them for denoising. In the era of\nlarge language models (LLMs), although we can reduce the human effort to\nimprove these methods, their performances are still subject to accurately\nseparating the clean and noisy samples from noisy data. In this paper, we\npropose an innovative collaborative learning framework NoiseAL based on active\nlearning to combine LLMs and small models (SMs) for learning from noisy labels.\nDuring collaborative training, we first adopt two SMs to form a co-prediction\nnetwork and propose a dynamic-enhanced threshold strategy to divide the noisy\ndata into different subsets, then select the clean and noisy samples from these\nsubsets to feed the active annotator LLMs to rectify noisy samples. Finally, we\nemploy different optimization objectives to conquer subsets with different\ndegrees of label noises. Extensive experiments on synthetic and real-world\nnoise datasets further demonstrate the superiority of our framework over\nstate-of-the-art baselines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02901v1",
    "published_date": "2025-04-03 04:36:39 UTC",
    "updated_date": "2025-04-03 04:36:39 UTC"
  },
  {
    "arxiv_id": "2504.02269v3",
    "title": "Engineering Artificial Intelligence: Framework, Challenges, and Future Direction",
    "authors": [
      "Jay Lee",
      "Hanqi Su",
      "Dai-Yan Ji",
      "Takanobu Minami"
    ],
    "abstract": "Over the past ten years, the application of artificial intelligence (AI) and\nmachine learning (ML) in engineering domains has gained significant popularity,\nshowcasing their potential in data-driven contexts. However, the complexity and\ndiversity of engineering problems often require the development of\ndomain-specific AI approaches, which are frequently hindered by a lack of\nsystematic methodologies, scalability, and robustness during the development\nprocess. To address this gap, this paper introduces the \"ABCDE\" as the key\nelements of Engineering AI and proposes a unified, systematic engineering AI\necosystem framework, including eight essential layers, along with attributes,\ngoals, and applications, to guide the development and deployment of AI\nsolutions for specific engineering needs. Additionally, key challenges are\nexamined, and eight future research directions are highlighted. By providing a\ncomprehensive perspective, this paper aims to advance the strategic\nimplementation of AI, fostering the development of next-generation engineering\nAI solutions.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "The paper submitted to the Journal Machine Learning: Engineering has\n  been accepted",
    "pdf_url": "http://arxiv.org/pdf/2504.02269v3",
    "published_date": "2025-04-03 04:30:10 UTC",
    "updated_date": "2025-04-23 18:36:36 UTC"
  },
  {
    "arxiv_id": "2504.02260v1",
    "title": "Implicit Neural Differential Model for Spatiotemporal Dynamics",
    "authors": [
      "Deepak Akhare",
      "Pan Du",
      "Tengfei Luo",
      "Jian-Xun Wang"
    ],
    "abstract": "Hybrid neural-physics modeling frameworks through differentiable programming\nhave emerged as powerful tools in scientific machine learning, enabling the\nintegration of known physics with data-driven learning to improve prediction\naccuracy and generalizability. However, most existing hybrid frameworks rely on\nexplicit recurrent formulations, which suffer from numerical instability and\nerror accumulation during long-horizon forecasting. In this work, we introduce\nIm-PiNDiff, a novel implicit physics-integrated neural differentiable solver\nfor stable and accurate modeling of spatiotemporal dynamics. Inspired by deep\nequilibrium models, Im-PiNDiff advances the state using implicit fixed-point\nlayers, enabling robust long-term simulation while remaining fully end-to-end\ndifferentiable. To enable scalable training, we introduce a hybrid gradient\npropagation strategy that integrates adjoint-state methods with reverse-mode\nautomatic differentiation. This approach eliminates the need to store\nintermediate solver states and decouples memory complexity from the number of\nsolver iterations, significantly reducing training overhead. We further\nincorporate checkpointing techniques to manage memory in long-horizon rollouts.\nNumerical experiments on various spatiotemporal PDE systems, including\nadvection-diffusion processes, Burgers' dynamics, and multi-physics chemical\nvapor infiltration processes, demonstrate that Im-PiNDiff achieves superior\npredictive performance, enhanced numerical stability, and substantial\nreductions in memory and runtime cost relative to explicit and naive implicit\nbaselines. This work provides a principled, efficient, and scalable framework\nfor hybrid neural-physics modeling.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02260v1",
    "published_date": "2025-04-03 04:07:18 UTC",
    "updated_date": "2025-04-03 04:07:18 UTC"
  },
  {
    "arxiv_id": "2504.02254v1",
    "title": "LLMs as Deceptive Agents: How Role-Based Prompting Induces Semantic Ambiguity in Puzzle Tasks",
    "authors": [
      "Seunghyun Yoo"
    ],
    "abstract": "Recent advancements in Large Language Models (LLMs) have not only showcased\nimpressive creative capabilities but also revealed emerging agentic behaviors\nthat exploit linguistic ambiguity in adversarial settings. In this study, we\ninvestigate how an LLM, acting as an autonomous agent, leverages semantic\nambiguity to generate deceptive puzzles that mislead and challenge human users.\nInspired by the popular puzzle game \"Connections\", we systematically compare\npuzzles produced through zero-shot prompting, role-injected adversarial\nprompts, and human-crafted examples, with an emphasis on understanding the\nunderlying agent decision-making processes. Employing computational analyses\nwith HateBERT to quantify semantic ambiguity, alongside subjective human\nevaluations, we demonstrate that explicit adversarial agent behaviors\nsignificantly heighten semantic ambiguity -- thereby increasing cognitive load\nand reducing fairness in puzzle solving. These findings provide critical\ninsights into the emergent agentic qualities of LLMs and underscore important\nethical considerations for evaluating and safely deploying autonomous language\nsystems in both educational technologies and entertainment.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "68T50, 68T05, 68U35"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2504.02254v1",
    "published_date": "2025-04-03 03:45:58 UTC",
    "updated_date": "2025-04-03 03:45:58 UTC"
  },
  {
    "arxiv_id": "2504.02252v1",
    "title": "Adapting World Models with Latent-State Dynamics Residuals",
    "authors": [
      "JB Lanier",
      "Kyungmin Kim",
      "Armin Karamzade",
      "Yifei Liu",
      "Ankita Sinha",
      "Kat He",
      "Davide Corsi",
      "Roy Fox"
    ],
    "abstract": "Simulation-to-reality reinforcement learning (RL) faces the critical\nchallenge of reconciling discrepancies between simulated and real-world\ndynamics, which can severely degrade agent performance. A promising approach\ninvolves learning corrections to simulator forward dynamics represented as a\nresidual error function, however this operation is impractical with\nhigh-dimensional states such as images. To overcome this, we propose ReDRAW, a\nlatent-state autoregressive world model pretrained in simulation and calibrated\nto target environments through residual corrections of latent-state dynamics\nrather than of explicit observed states. Using this adapted world model, ReDRAW\nenables RL agents to be optimized with imagined rollouts under corrected\ndynamics and then deployed in the real world. In multiple vision-based MuJoCo\ndomains and a physical robot visual lane-following task, ReDRAW effectively\nmodels changes to dynamics and avoids overfitting in low data regimes where\ntraditional transfer methods fail.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 11 figures. Project website at https://redraw.jblanier.net/",
    "pdf_url": "http://arxiv.org/pdf/2504.02252v1",
    "published_date": "2025-04-03 03:41:30 UTC",
    "updated_date": "2025-04-03 03:41:30 UTC"
  },
  {
    "arxiv_id": "2504.02234v1",
    "title": "LLM Social Simulations Are a Promising Research Method",
    "authors": [
      "Jacy Reese Anthis",
      "Ryan Liu",
      "Sean M. Richardson",
      "Austin C. Kozlowski",
      "Bernard Koch",
      "James Evans",
      "Erik Brynjolfsson",
      "Michael Bernstein"
    ],
    "abstract": "Accurate and verifiable large language model (LLM) simulations of human\nresearch subjects promise an accessible data source for understanding human\nbehavior and training new AI systems. However, results to date have been\nlimited, and few social scientists have adopted these methods. In this position\npaper, we argue that the promise of LLM social simulations can be achieved by\naddressing five tractable challenges. We ground our argument in a literature\nsurvey of empirical comparisons between LLMs and human research subjects,\ncommentaries on the topic, and related work. We identify promising directions\nwith prompting, fine-tuning, and complementary methods. We believe that LLM\nsocial simulations can already be used for exploratory research, such as pilot\nexperiments for psychology, economics, sociology, and marketing. More\nwidespread use may soon be possible with rapidly advancing LLM capabilities,\nand researchers should prioritize developing conceptual models and evaluations\nthat can be iteratively deployed and refined at pace with ongoing AI advances.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02234v1",
    "published_date": "2025-04-03 03:01:26 UTC",
    "updated_date": "2025-04-03 03:01:26 UTC"
  },
  {
    "arxiv_id": "2504.02231v1",
    "title": "AC-LoRA: Auto Component LoRA for Personalized Artistic Style Image Generation",
    "authors": [
      "Zhipu Cui",
      "Andong Tian",
      "Zhi Ying",
      "Jialiang Lu"
    ],
    "abstract": "Personalized image generation allows users to preserve styles or subjects of\na provided small set of images for further image generation. With the\nadvancement in large text-to-image models, many techniques have been developed\nto efficiently fine-tune those models for personalization, such as Low Rank\nAdaptation (LoRA). However, LoRA-based methods often face the challenge of\nadjusting the rank parameter to achieve satisfactory results. To address this\nchallenge, AutoComponent-LoRA (AC-LoRA) is proposed, which is able to\nautomatically separate the signal component and noise component of the LoRA\nmatrices for fast and efficient personalized artistic style image generation.\nThis method is based on Singular Value Decomposition (SVD) and dynamic\nheuristics to update the hyperparameters during training. Superior performance\nover existing methods in overcoming model underfitting or overfitting problems\nis demonstrated. The results were validated using FID, CLIP, DINO, and\nImageReward, achieving an average of 9% improvement.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T05, 68U10",
      "I.2.6; I.4.0"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 4 figures, ICCGV 2025, SPIE",
    "pdf_url": "http://arxiv.org/pdf/2504.02231v1",
    "published_date": "2025-04-03 02:56:01 UTC",
    "updated_date": "2025-04-03 02:56:01 UTC"
  },
  {
    "arxiv_id": "2504.02227v1",
    "title": "VEGAS: Towards Visually Explainable and Grounded Artificial Social Intelligence",
    "authors": [
      "Hao Li",
      "Hao Fei",
      "Zechao Hu",
      "Zhengwei Yang",
      "Zheng Wang"
    ],
    "abstract": "Social Intelligence Queries (Social-IQ) serve as the primary multimodal\nbenchmark for evaluating a model's social intelligence level. While impressive\nmultiple-choice question(MCQ) accuracy is achieved by current solutions,\nincreasing evidence shows that they are largely, and in some cases entirely,\ndependent on language modality, overlooking visual context. Additionally, the\nclosed-set nature further prevents the exploration of whether and to what\nextent the reasoning path behind selection is correct. To address these\nlimitations, we propose the Visually Explainable and Grounded Artificial Social\nIntelligence (VEGAS) model. As a generative multimodal model, VEGAS leverages\nopen-ended answering to provide explainable responses, which enhances the\nclarity and evaluation of reasoning paths. To enable visually grounded\nanswering, we propose a novel sampling strategy to provide the model with more\nrelevant visual frames. We then enhance the model's interpretation of these\nframes through Generalist Instruction Fine-Tuning (GIFT), which aims to: i)\nlearn multimodal-language transformations for fundamental emotional social\ntraits, and ii) establish multimodal joint reasoning capabilities. Extensive\nexperiments, comprising modality ablation, open-ended assessments, and\nsupervised MCQ evaluations, consistently show that VEGAS effectively utilizes\nvisual information in reasoning to produce correct and also credible answers.\nWe expect this work to of fer a new perspective on Social-IQ and advance the\ndevelopment of human-like social AI.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "9 pages, 5 figures, AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02227v1",
    "published_date": "2025-04-03 02:48:21 UTC",
    "updated_date": "2025-04-03 02:48:21 UTC"
  },
  {
    "arxiv_id": "2504.02221v1",
    "title": "Learning and Improving Backgammon Strategy",
    "authors": [
      "Gregory R. Galperin"
    ],
    "abstract": "A novel approach to learning is presented, combining features of on-line and\noff-line methods to achieve considerable performance in the task of learning a\nbackgammon value function in a process that exploits the processing power of\nparallel supercomputers. The off-line methods comprise a set of techniques for\nparallelizing neural network training and $TD(\\lambda)$ reinforcement learning;\nhere Monte-Carlo ``Rollouts'' are introduced as a massively parallel on-line\npolicy improvement technique which applies resources to the decision points\nencountered during the search of the game tree to further augment the learned\nvalue function estimate. A level of play roughly as good as, or possibly better\nthan, the current champion human and computer backgammon players has been\nachieved in a short period of learning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "Accompanied by oral presentation by Gregory Galperin at the CBCL\n  Learning Day 1994",
    "pdf_url": "http://arxiv.org/pdf/2504.02221v1",
    "published_date": "2025-04-03 02:27:22 UTC",
    "updated_date": "2025-04-03 02:27:22 UTC"
  },
  {
    "arxiv_id": "2504.02211v1",
    "title": "FT-Transformer: Resilient and Reliable Transformer with End-to-End Fault Tolerant Attention",
    "authors": [
      "Huangliang Dai",
      "Shixun Wu",
      "Hairui Zhao",
      "Jiajun Huang",
      "Zizhe Jian",
      "Yue Zhu",
      "Haiyang Hu",
      "Zizhong Chen"
    ],
    "abstract": "Transformer models leverage self-attention mechanisms to capture complex\ndependencies, demonstrating exceptional performance in various applications.\nHowever, the long-duration high-load computations required for model inference\nimpose stringent reliability demands on the computing platform, as soft errors\nthat occur during execution can significantly degrade model performance.\nExisting fault tolerance methods protect each operation separately using\ndecoupled kernels, incurring substantial computational and memory overhead. In\nthis paper, we propose a novel error-resilient framework for Transformer\nmodels, integrating end-to-end fault tolerant attention (EFTA) to improve\ninference reliability against soft errors. Our approach enables error detection\nand correction within a fully fused attention kernel, reducing redundant data\naccess and thereby mitigating memory faults. To further enhance error coverage\nand reduce overhead, we design a hybrid fault tolerance scheme tailored for the\nEFTA, introducing for the first time: 1) architecture-aware algorithm-based\nfault tolerance (ABFT) using tensor checksum, which minimizes inter-thread\ncommunication overhead on tensor cores during error detection; 2) selective\nneuron value restriction, which selectively applies adaptive fault tolerance\nconstraints to neuron values, balancing error coverage and overhead; 3) unified\nverification, reusing checksums to streamline multiple computation steps into a\nsingle verification process. Experimental results show that EFTA achieves up to\n7.56x speedup over traditional methods with an average fault tolerance overhead\nof 13.9%.",
    "categories": [
      "cs.DC",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02211v1",
    "published_date": "2025-04-03 02:05:08 UTC",
    "updated_date": "2025-04-03 02:05:08 UTC"
  },
  {
    "arxiv_id": "2504.02199v1",
    "title": "ESC: Erasing Space Concept for Knowledge Deletion",
    "authors": [
      "Tae-Young Lee",
      "Sundong Park",
      "Minwoo Jeon",
      "Hyoseok Hwang",
      "Gyeong-Moon Park"
    ],
    "abstract": "As concerns regarding privacy in deep learning continue to grow, individuals\nare increasingly apprehensive about the potential exploitation of their\npersonal knowledge in trained models. Despite several research efforts to\naddress this, they often fail to consider the real-world demand from users for\ncomplete knowledge erasure. Furthermore, our investigation reveals that\nexisting methods have a risk of leaking personal knowledge through embedding\nfeatures. To address these issues, we introduce a novel concept of Knowledge\nDeletion (KD), an advanced task that considers both concerns, and provides an\nappropriate metric, named Knowledge Retention score (KR), for assessing\nknowledge retention in feature space. To achieve this, we propose a novel\ntraining-free erasing approach named Erasing Space Concept (ESC), which\nrestricts the important subspace for the forgetting knowledge by eliminating\nthe relevant activations in the feature. In addition, we suggest ESC with\nTraining (ESC-T), which uses a learnable mask to better balance the trade-off\nbetween forgetting and preserving knowledge in KD. Our extensive experiments on\nvarious datasets and models demonstrate that our proposed methods achieve the\nfastest and state-of-the-art performance. Notably, our methods are applicable\nto diverse forgetting scenarios, such as facial domain setting, demonstrating\nthe generalizability of our methods. The code is available at\nhttp://github.com/KU-VGI/ESC .",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "22 pages, 14 figures, 18 tables, CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2504.02199v1",
    "published_date": "2025-04-03 00:53:09 UTC",
    "updated_date": "2025-04-03 00:53:09 UTC"
  },
  {
    "arxiv_id": "2504.02193v1",
    "title": "More is Less: The Pitfalls of Multi-Model Synthetic Preference Data in DPO Safety Alignment",
    "authors": [
      "Yifan Wang",
      "Runjin Chen",
      "Bolian Li",
      "David Cho",
      "Yihe Deng",
      "Ruqi Zhang",
      "Tianlong Chen",
      "Zhangyang Wang",
      "Ananth Grama",
      "Junyuan Hong"
    ],
    "abstract": "Aligning large language models (LLMs) with human values is an increasingly\ncritical step in post-training. Direct Preference Optimization (DPO) has\nemerged as a simple, yet effective alternative to reinforcement learning from\nhuman feedback (RLHF). Synthetic preference data with its low cost and high\nquality enable effective alignment through single- or multi-model generated\npreference data. Our study reveals a striking, safety-specific phenomenon\nassociated with DPO alignment: Although multi-model generated data enhances\nperformance on general tasks (ARC, Hellaswag, MMLU, TruthfulQA, Winogrande) by\nproviding diverse responses, it also tends to facilitate reward hacking during\ntraining. This can lead to a high attack success rate (ASR) when models\nencounter jailbreaking prompts. The issue is particularly pronounced when\nemploying stronger models like GPT-4o or larger models in the same family to\ngenerate chosen responses paired with target model self-generated rejected\nresponses, resulting in dramatically poorer safety outcomes. Furthermore, with\nrespect to safety, using solely self-generated responses (single-model\ngeneration) for both chosen and rejected pairs significantly outperforms\nconfigurations that incorporate responses from stronger models, whether used\ndirectly as chosen data or as part of a multi-model response pool. We\ndemonstrate that multi-model preference data exhibits high linear separability\nbetween chosen and rejected responses, which allows models to exploit\nsuperficial cues rather than internalizing robust safety constraints. Our\nexperiments, conducted on models from the Llama, Mistral, and Qwen families,\nconsistently validate these findings.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2504.02193v1",
    "published_date": "2025-04-03 00:36:40 UTC",
    "updated_date": "2025-04-03 00:36:40 UTC"
  }
]