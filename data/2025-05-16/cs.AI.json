{
  "date": "2025-05-16",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2025-05-16 的 arXiv 中文 TLDR 快报！今天 arXiv 的更新聚焦于 AI 模型的优化、安全、泛化和跨领域应用，特别是大型语言模型 (LLMs) 在推理、偏好优化和多代理协作中的进展；亮点包括强化学习在数学推理和机器人任务中的提升，以及跨语言和多模态处理的技术创新；知名学者如 Eric Horvitz 和 Jure Leskovec 的作品值得关注。\n\n今天共有 209 篇论文，我将优先讨论那些创新性强、可能影响未来的关键文章，包括 LLM 安全、推理优化和多代理系统等热门主题。其他较常规或小众论文（如某些数学理论或特定领域优化）将简要提及或快速掠过，以控制篇幅。下面按主题归类，一一简述。\n\n### LLM 推理和优化\n- **Token-Level Uncertainty Estimation for Large Language Model Reasoning**（令牌级不确定性估计：提升 LLM 推理的鲁棒性）  \n  这篇论文提出了一种基于低秩随机权重扰动的框架，用于 LLM 推理中的不确定性估计。通过实验证明，该方法在数学推理任务中显著提升了答案正确性和模型鲁棒性。主要贡献在于改进 LLM 的自评估和自提升能力。\n\n- **Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling**（重新审视最佳验证粒度：优化计算效率的测试时缩放）  \n  作者探讨了 LLM 测试时缩放的验证粒度，引入 Variable Granularity Search 算法。该方法在保持准确性的同时，减少了计算量（FLOPs 降低 52%），适用于资源受限的推理任务。亮点在于提升 LLM 推理的计算效率。\n\n- **Token-Level Uncertainty Estimation for Large Language Model Reasoning**（令牌级不确定性估计：提升 LLM 推理的鲁棒性）  \n  与上一篇相关，这篇通过梯度聚合和粒子滤波算法增强 LLM 序列生成的鲁棒性，在数学数据集上表现出强相关性。主要发现是，LLM 的不确定性评估能直接改善推理性能。\n\n- **Scaling Reasoning can Improve Factuality in Large Language Models**（扩展推理提升 LLM 的事实性）  \n  这篇工作展示了通过扩展测试时计算（如增加推理链长）来提升 LLM 事实准确性的方法。在开放域问答任务中，准确性提升 2-8%。这对 LLM 的事实性优化有实际启发。\n\n### 多代理系统和安全\n- **Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity**（群组思考：多代理在令牌级协作的推理）  \n  论文引入多代理协作框架，允许代理在推理过程中实时互动，提升任务效率。实验显示，在文本生成和决策任务中，性能提升显著。该方法挑战了传统单代理 LLM 的局限。\n\n- **GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models**（GenoArmory：针对基因组基础模型的统一对抗攻击评估框架）  \n  作者构建了一个统一基准，评估基因组模型对对抗攻击的鲁棒性。实验揭示了模型在不同攻击下的漏洞，并提出新数据集。主要贡献在于为基因组 AI 安全提供系统性工具。\n\n- **GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning**（GuardReasoner-VL：通过强化推理保护视觉语言模型）  \n  这篇论文提出强化学习框架来提升视觉语言模型的安全性。通过数据集构建和实验，模型在对抗任务中表现出色。重点在于 LLM 在安全领域的实际应用潜力。\n\n### 跨领域和创新应用\n- **PhiNet v2: A Mask-Free Brain-Inspired Vision Foundation Model from Video**（PhiNet v2：基于视频的无掩码脑启发视觉基础模型）  \n  论文扩展了脑启发模型，处理视频数据而非静态图像。实验显示，该模型在图像分割和深度估计任务中超越基线，体现了生物启发在视觉任务中的创新。\n\n- **DRL-Based Injection Molding Process Parameter Optimization for Adaptive and Profitable Production**（基于深度强化学习的注塑工艺参数优化：实现适应性和盈利性生产）  \n  作者使用 DRL 优化注塑参数，平衡产品质量和生产成本。实验证明，该方法在动态环境中提升了效率和盈利性，适用于工业自动化。\n\n- **Inferring the Most Similar Variable-length Subsequences between Multidimensional Time Series**（推断多维时间序列之间最相似的可变长子序列）  \n  这篇快速掠过：论文提出算法高效计算时间序列相似性，主要用于股票和生物运动分析，但细节较技术化。\n\n其他论文，如一些纯理论工作（例如数学建模或特定领域优化），虽有贡献但不那么引人注目，我将简要列出而不深挖。例如：\n\n- **CLT and Edgeworth Expansion for m-out-of-n Bootstrap Estimators of The Studentized Median**（m-out-of-n Bootstrap 估计器的中心极限定理和 Edgeworth 展开：针对 Studentized 中位数的应用）  \n  主要发现是证明了 Bootstrap 方法在统计估计中的鲁棒性，但对一般读者影响有限。\n\n- **Multilingual Prompt Engineering in Large Language Models: A Survey Across NLP Tasks**（多语言提示工程在大型语言模型中的应用：跨 NLP 任务的调查）  \n  这篇是综述，总结了多语言提示策略，但作为回顾性工作，不如原创方法有话题度。\n\n总之，今天的论文突显了 AI 模型在推理、安全和泛化方面的进展，LLM 相关工作尤为活跃。未来几天，继续关注这些领域的突破！",
  "papers": [
    {
      "arxiv_id": "2505.11760v1",
      "title": "Topology-Aware Knowledge Propagation in Decentralized Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Mansi Sakarvadia",
        "Nathaniel Hudson",
        "Tian Li",
        "Ian Foster",
        "Kyle Chard"
      ],
      "abstract": "Decentralized learning enables collaborative training of models across\nnaturally distributed data without centralized coordination or maintenance of a\nglobal model. Instead, devices are organized in arbitrary communication\ntopologies, in which they can only communicate with neighboring devices. Each\ndevice maintains its own local model by training on its local data and\nintegrating new knowledge via model aggregation with neighbors. Therefore,\nknowledge is propagated across the topology via successive aggregation rounds.\nWe study, in particular, the propagation of out-of-distribution (OOD)\nknowledge. We find that popular decentralized learning algorithms struggle to\npropagate OOD knowledge effectively to all devices. Further, we find that both\nthe location of OOD data within a topology, and the topology itself,\nsignificantly impact OOD knowledge propagation. We then propose topology-aware\naggregation strategies to accelerate (OOD) knowledge propagation across\ndevices. These strategies improve OOD data accuracy, compared to\ntopology-unaware baselines, by 123% on average across models in a topology.",
      "tldr_zh": "这篇论文探讨了 decentralized learning 中的知识传播问题，特别是在 out-of-distribution (OOD) 知识的传播上，现有算法因通信拓扑限制而效率低下，且 OOD 数据的位置和拓扑结构会显著影响传播效果。作者提出 topology-aware aggregation strategies，通过拓扑感知的聚合方法加速知识在设备间的传播。实验结果显示，与 topology-unaware baselines 相比，这些策略平均提高了 OOD 数据准确率 123%。这项工作为分布式学习中的知识共享提供了更有效的解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11760v1",
      "published_date": "2025-05-16 23:53:33 UTC",
      "updated_date": "2025-05-16 23:53:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:32:54.341009"
    },
    {
      "arxiv_id": "2505.11758v1",
      "title": "Generalizable Vision-Language Few-Shot Adaptation with Predictive Prompts and Negative Learning",
      "title_zh": "基于预测性提示和负学习的泛化视觉-语言少样本适应",
      "authors": [
        "Sriram Mandalika"
      ],
      "abstract": "Few-shot adaptation remains a core challenge for vision-language models\n(VLMs), especially under limited supervision and noisy support samples. We\npropose PromptFuseNL, a unified framework that enhances few-shot generalization\nby combining predictive prompt tuning with dual-branch positive and negative\nlearning. The method refines class prototypes through task-conditioned\nresiduals, multi-stage cross-modal coordination, and semantic hard negative\nmining. To address label noise, we introduce an unsupervised instance\nreweighting strategy that downweights unreliable support examples without\nrequiring additional labels or structural changes. PromptFuseNL fuses visual\nand textual cues through lightweight modules for efficient and discriminative\nprediction. Evaluated across 15 benchmarks, it consistently surpasses existing\nprompt- and adapter-based methods in all shot settings while remaining highly\nefficient, achieving up to 300x faster training and 1000x lower FLOPs compared\nto full prompt tuning, achieving a new state-of-the-art for robust and scalable\nfew-shot vision-language adaptation.",
      "tldr_zh": "本研究提出 PromptFuseNL 框架，以提升视觉语言模型 (VLMs) 在少样本适应中的泛化能力，特别是面对有限监督和噪声样本的挑战。该框架结合预测性提示调整 (predictive prompt tuning) 和双分支正负学习 (dual-branch positive and negative learning)，通过任务条件残差、multi-stage cross-modal coordination 和语义硬负样本挖掘 (semantic hard negative mining) 来提炼类别原型，并引入无监督实例权重策略 (unsupervised instance reweighting) 处理标签噪声，实现高效的视觉文本线索融合。在 15 个基准测试中，PromptFuseNL 超越现有提示和适配器方法，在所有样本设置下达到新状态-of-the-art，同时训练速度快 300 倍、FLOPs 低 1000 倍，提供更鲁棒且可扩展的少样本视觉语言适应方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11758v1",
      "published_date": "2025-05-16 23:39:34 UTC",
      "updated_date": "2025-05-16 23:39:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:33:08.277984"
    },
    {
      "arxiv_id": "2505.11756v1",
      "title": "Feature Hedging: Correlated Features Break Narrow Sparse Autoencoders",
      "title_zh": "特征套期：相关特征破坏窄稀疏自动编码器",
      "authors": [
        "David Chanin",
        "Tomáš Dulka",
        "Adrià Garriga-Alonso"
      ],
      "abstract": "It is assumed that sparse autoencoders (SAEs) decompose polysemantic\nactivations into interpretable linear directions, as long as the activations\nare composed of sparse linear combinations of underlying features. However, we\nfind that if an SAE is more narrow than the number of underlying \"true\nfeatures\" on which it is trained, and there is correlation between features,\nthe SAE will merge components of correlated features together, thus destroying\nmonosemanticity. In LLM SAEs, these two conditions are almost certainly true.\nThis phenomenon, which we call feature hedging, is caused by SAE reconstruction\nloss, and is more severe the narrower the SAE. In this work, we introduce the\nproblem of feature hedging and study it both theoretically in toy models and\nempirically in SAEs trained on LLMs. We suspect that feature hedging may be one\nof the core reasons that SAEs consistently underperform supervised baselines.\nFinally, we use our understanding of feature hedging to propose an improved\nvariant of matryoshka SAEs. Our work shows there remain fundamental issues with\nSAEs, but we are hopeful that that highlighting feature hedging will catalyze\nfuture advances that allow SAEs to achieve their full potential of interpreting\nLLMs at scale.",
      "tldr_zh": "本研究揭示了稀疏自编码器 (SAEs) 在处理相关特征时的关键问题：如果 SAE 的宽度小于底层“真实特征”的数量，且特征之间存在相关性，SAEs 会通过一种称为 feature hedging 的现象将相关特征的组件合并，从而破坏其单义性 (monosemanticity)。研究通过玩具模型的理论分析和在大型语言模型 (LLMs) 上训练的 SAEs 实证实验，证明了 feature hedging 由重构损失引起，且在更窄的 SAEs 中更严重，可能解释了 SAEs 为什么常常不如监督基线表现。作者怀疑这一问题可能是 SAEs 性能不足的核心原因之一，并基于此提出了一种改进的 matryoshka SAEs 变体，以提升 SAEs 在大规模解释 LLMs 中的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11756v1",
      "published_date": "2025-05-16 23:30:17 UTC",
      "updated_date": "2025-05-16 23:30:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:33:21.496505"
    },
    {
      "arxiv_id": "2505.11755v2",
      "title": "Reachability Barrier Networks: Learning Hamilton-Jacobi Solutions for Smooth and Flexible Control Barrier Functions",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Kim",
        "William Sharpless",
        "Hyun Joe Jeong",
        "Sander Tonkens",
        "Somil Bansal",
        "Sylvia Herbert"
      ],
      "abstract": "Recent developments in autonomous driving and robotics underscore the\nnecessity of safety-critical controllers. Control barrier functions (CBFs) are\na popular method for appending safety guarantees to a general control\nframework, but they are notoriously difficult to generate beyond low\ndimensions. Existing methods often yield non-differentiable or inaccurate\napproximations that lack integrity, and thus fail to ensure safety. In this\nwork, we use physics-informed neural networks (PINNs) to generate smooth\napproximations of CBFs by computing Hamilton-Jacobi (HJ) optimal control\nsolutions. These reachability barrier networks (RBNs) avoid traditional\ndimensionality constraints and support the tuning of their conservativeness\npost-training through a parameterized discount term. To ensure robustness of\nthe discounted solutions, we leverage conformal prediction methods to derive\nprobabilistic safety guarantees for RBNs. We demonstrate that RBNs are highly\naccurate in low dimensions, and safer than the standard neural CBF approach in\nhigh dimensions. Namely, we showcase the RBNs in a 9D multi-vehicle collision\navoidance problem where it empirically proves to be 5.5x safer and 1.9x less\nconservative than the neural CBFs, offering a promising method to synthesize\nCBFs for general nonlinear autonomous systems.",
      "tldr_zh": "该研究针对控制屏障函数(Control Barrier Functions, CBFs)在高维度下的生成难题，提出了一种基于物理信息神经网络(Physics-Informed Neural Networks, PINNs)的方法，通过计算Hamilton-Jacobi (HJ)最优控制解决方案来学习平滑且灵活的Reachability Barrier Networks (RBNs)。RBNs避免了传统维度的限制，并通过参数化折扣项支持训练后调整保守性，同时利用Conformal Prediction方法提供概率安全保证。实验结果显示，在9D多车辆碰撞避免场景中，RBNs比标准神经CBF方法安全5.5倍且保守性低1.9倍，为非线性自主系统的安全控制合成提供了高效方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "15 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11755v2",
      "published_date": "2025-05-16 23:30:13 UTC",
      "updated_date": "2025-05-20 02:30:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:33:32.088760"
    },
    {
      "arxiv_id": "2505.11750v2",
      "title": "Improving Medium Range Severe Weather Prediction through Transformer Post-processing of AI Weather Forecasts",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanxiang Hua",
        "Ryan Sobash",
        "David John Gagne II",
        "Yingkai Sha",
        "Alexandra Anderson-Frey"
      ],
      "abstract": "Improving the skill of medium-range (1-8 day) severe weather prediction is\ncrucial for mitigating societal impacts. This study introduces a novel approach\nleveraging decoder-only transformer networks to post-process AI-based weather\nforecasts, specifically from the Pangu-Weather model, for improved severe\nweather guidance. Unlike traditional post-processing methods that use a dense\nneural network to predict the probability of severe weather using discrete\nforecast samples, our method treats forecast lead times as sequential\n``tokens'', enabling the transformer to learn complex temporal relationships\nwithin the evolving atmospheric state. We compare this approach against\npost-processing of the Global Forecast System (GFS) using both a traditional\ndense neural network and our transformer, as well as configurations that\nexclude convective parameters to fairly evaluate the impact of using the\nPangu-Weather AI model. Results demonstrate that the transformer-based\npost-processing significantly enhances forecast skill compared to dense neural\nnetworks. Furthermore, AI-driven forecasts, particularly Pangu-Weather\ninitialized from high resolution analysis, exhibit superior performance to GFS\nin the medium-range, even without explicit convective parameters. Our approach\noffers improved accuracy, and reliability, which also provides interpretability\nthrough feature attribution analysis, advancing medium-range severe weather\nprediction capabilities.",
      "tldr_zh": "本研究旨在提升中程（1-8 天）严重天气预测的准确性，通过引入一种基于 decoder-only transformer 网络的后处理方法，针对 AI 天气预报模型（如 Pangu-Weather）进行优化，将预测提前时间视为顺序“tokens”以学习复杂的时序关系。相比传统密集神经网络后处理 Global Forecast System (GFS) 预报，该 transformer 方法显著提高了预测技能，即使排除对流参数，Pangu-Weather 驱动的预报也表现出色。结果显示，该方法不仅提升了准确性和可靠性，还通过特征归因分析提供了可解释性，从而推进了中程严重天气预测的能力。",
      "categories": [
        "physics.ao-ph",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "physics.ao-ph",
      "comment": "16 pages, 10 figures; update fix issues with section reference number",
      "pdf_url": "http://arxiv.org/pdf/2505.11750v2",
      "published_date": "2025-05-16 23:22:07 UTC",
      "updated_date": "2025-05-20 17:42:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:33:42.735210"
    },
    {
      "arxiv_id": "2505.11746v1",
      "title": "Token Masking Improves Transformer-Based Text Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Xianglong Xu",
        "John Bowen",
        "Rojin Taheri"
      ],
      "abstract": "While transformer-based models achieve strong performance on text\nclassification, we explore whether masking input tokens can further enhance\ntheir effectiveness. We propose token masking regularization, a simple yet\ntheoretically motivated method that randomly replaces input tokens with a\nspecial [MASK] token at probability p. This introduces stochastic perturbations\nduring training, leading to implicit gradient averaging that encourages the\nmodel to capture deeper inter-token dependencies. Experiments on language\nidentification and sentiment analysis -- across diverse models (mBERT,\nQwen2.5-0.5B, TinyLlama-1.1B) -- show consistent improvements over standard\nregularization techniques. We identify task-specific optimal masking rates,\nwith p = 0.1 as a strong general default. We attribute the gains to two key\neffects: (1) input perturbation reduces overfitting, and (2) gradient-level\nsmoothing acts as implicit ensembling.",
      "tldr_zh": "本文提出 token masking regularization 方法，通过在训练时以概率 p 随机将输入 token 替换为 [MASK] token，引入随机扰动以减少过拟合并增强模型对 token 之间依赖关系的捕捉，从而改善 Transformer-based text classification 的性能。实验在语言识别和情感分析任务上，使用 mBERT、Qwen2.5-0.5B 和 TinyLlama-1.1B 等模型进行测试，结果显示该方法比标准正则化技术有显著提升，最优 masking 率为 p=0.1。研究将收益归因于输入扰动减少过拟合以及梯度级平滑的隐式集成效果，为文本分类任务提供了一个简单有效的优化策略。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11746v1",
      "published_date": "2025-05-16 23:06:11 UTC",
      "updated_date": "2025-05-16 23:06:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:33:55.797467"
    },
    {
      "arxiv_id": "2505.11745v1",
      "title": "POCAII: Parameter Optimization with Conscious Allocation using Iterative Intelligence",
      "title_zh": "POCAII：利用迭代智能进行有意识分配的参数优化",
      "authors": [
        "Joshua Inman",
        "Tanmay Khandait",
        "Lalitha Sankar",
        "Giulia Pedrielli"
      ],
      "abstract": "In this paper we propose for the first time the hyperparameter optimization\n(HPO) algorithm POCAII. POCAII differs from the Hyperband and Successive\nHalving literature by explicitly separating the search and evaluation phases\nand utilizing principled approaches to exploration and exploitation principles\nduring both phases. Such distinction results in a highly flexible scheme for\nmanaging a hyperparameter optimization budget by focusing on search (i.e.,\ngenerating competing configurations) towards the start of the HPO process while\nincreasing the evaluation effort as the HPO comes to an end.\n  POCAII was compared to state of the art approaches SMAC, BOHB and DEHB. Our\nalgorithm shows superior performance in low-budget hyperparameter optimization\nregimes. Since many practitioners do not have exhaustive resources to assign to\nHPO, it has wide applications to real-world problems. Moreover, the empirical\nevidence showed how POCAII demonstrates higher robustness and lower variance in\nthe results. This is again very important when considering realistic scenarios\nwith extremely expensive models to train.",
      "tldr_zh": "本论文提出POCAII算法，这是一种超参数优化(HPO)方法，通过明确分离搜索和评估阶段，并采用原则化的探索和利用策略，实现高效的预算管理，即早期聚焦于生成竞争配置，后期增加评估努力。与SMAC、BOHB和DEHB等现有方法相比，POCAII在低预算HPO场景中表现出优越性能，并显示出更高的鲁棒性和更低的方差，特别适用于资源有限的真实世界问题，如训练成本高昂的模型。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "21 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11745v1",
      "published_date": "2025-05-16 23:05:07 UTC",
      "updated_date": "2025-05-16 23:05:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:34:06.708150"
    },
    {
      "arxiv_id": "2505.11743v1",
      "title": "Cloud-Based AI Systems: Leveraging Large Language Models for Intelligent Fault Detection and Autonomous Self-Healing",
      "title_zh": "基于云的 AI 系统：利用大型语言模型进行智能故障检测和自主自愈",
      "authors": [
        "Cheng Ji",
        "Huaiying Luo"
      ],
      "abstract": "With the rapid development of cloud computing systems and the increasing\ncomplexity of their infrastructure, intelligent mechanisms to detect and\nmitigate failures in real time are becoming increasingly important. Traditional\nmethods of failure detection are often difficult to cope with the scale and\ndynamics of modern cloud environments. In this study, we propose a novel AI\nframework based on Massive Language Model (LLM) for intelligent fault detection\nand self-healing mechanisms in cloud systems. The model combines existing\nmachine learning fault detection algorithms with LLM's natural language\nunderstanding capabilities to process and parse system logs, error reports, and\nreal-time data streams through semantic context. The method adopts a\nmulti-level architecture, combined with supervised learning for fault\nclassification and unsupervised learning for anomaly detection, so that the\nsystem can predict potential failures before they occur and automatically\ntrigger the self-healing mechanism. Experimental results show that the proposed\nmodel is significantly better than the traditional fault detection system in\nterms of fault detection accuracy, system downtime reduction and recovery\nspeed.",
      "tldr_zh": "本研究提出了一种基于 Large Language Models (LLMs) 的新型 AI 框架，用于云系统的智能故障检测和自主自愈机制，以应对传统方法的规模和动态性挑战。该框架结合机器学习算法，包括 supervised learning 用于故障分类和 unsupervised learning 用于异常检测，通过 LLMs 的自然语言理解能力处理系统日志、错误报告和实时数据流，实现对潜在故障的预测和自动触发自愈。实验结果显示，该模型在故障检测准确率、减少系统停机时间和提高恢复速度方面显著优于传统系统。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11743v1",
      "published_date": "2025-05-16 23:02:57 UTC",
      "updated_date": "2025-05-16 23:02:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:34:20.837902"
    },
    {
      "arxiv_id": "2505.11741v1",
      "title": "Diverging Towards Hallucination: Detection of Failures in Vision-Language Models via Multi-token Aggregation",
      "title_zh": "翻译失败",
      "authors": [
        "Geigh Zollicoffer",
        "Minh Vu",
        "Manish Bhattarai"
      ],
      "abstract": "Vision-language models (VLMs) now rival human performance on many multimodal\ntasks, yet they still hallucinate objects or generate unsafe text. Current\nhallucination detectors, e.g., single-token linear probing (SLP) and P(True),\ntypically analyze only the logit of the first generated token or just its\nhighest scoring component overlooking richer signals embedded within earlier\ntoken distributions. We demonstrate that analyzing the complete sequence of\nearly logits potentially provides substantially more diagnostic information. We\nemphasize that hallucinations may only emerge after several tokens, as subtle\ninconsistencies accumulate over time. By analyzing the Kullback-Leibler (KL)\ndivergence between logits corresponding to hallucinated and non-hallucinated\ntokens, we underscore the importance of incorporating later-token logits to\nmore accurately capture the reliability dynamics of VLMs. In response, we\nintroduce Multi-Token Reliability Estimation (MTRE), a lightweight, white-box\nmethod that aggregates logits from the first ten tokens using multi-token\nlog-likelihood ratios and self-attention. Despite the challenges posed by large\nvocabulary sizes and long logit sequences, MTRE remains efficient and\ntractable. On MAD-Bench, MM-SafetyBench, MathVista, and four\ncompositional-geometry benchmarks, MTRE improves AUROC by 9.4 +/- 1.3 points\nover SLP and by 12.1 +/- 1.7 points over P(True), setting a new\nstate-of-the-art in hallucination detection for open-source VLMs.",
      "tldr_zh": "这篇论文针对Vision-language models (VLMs)的幻觉问题，指出现有检测方法如single-token linear probing (SLP)和P(True)仅分析第一个token的logit，忽略了早期token分布中的更丰富信号。作者通过分析Kullback-Leibler (KL) divergence，强调幻觉可能在多个token后累积，并提出Multi-Token Reliability Estimation (MTRE)——一个轻量级、白盒方法，使用multi-token log-likelihood ratios和self-attention聚合前十个token的logits，以更准确地捕获VLMs的可靠性动态。在MAD-Bench、MM-SafetyBench、MathVista和四个compositional-geometry基准上，MTRE将AUROC提高了9.4 +/- 1.3 points 比SLP高，以及12.1 +/- 1.7 points 比P(True)高，树立了开源VLMs幻觉检测的新基准。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11741v1",
      "published_date": "2025-05-16 23:00:19 UTC",
      "updated_date": "2025-05-16 23:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:34:33.364724"
    },
    {
      "arxiv_id": "2505.11740v1",
      "title": "Simple and Effective Specialized Representations for Fair Classifiers",
      "title_zh": "简单且有效的专门表示用于公平分类器",
      "authors": [
        "Alberto Sinigaglia",
        "Davide Sartor",
        "Marina Ceccon",
        "Gian Antonio Susto"
      ],
      "abstract": "Fair classification is a critical challenge that has gained increasing\nimportance due to international regulations and its growing use in high-stakes\ndecision-making settings. Existing methods often rely on adversarial learning\nor distribution matching across sensitive groups; however, adversarial learning\ncan be unstable, and distribution matching can be computationally intensive. To\naddress these limitations, we propose a novel approach based on the\ncharacteristic function distance. Our method ensures that the learned\nrepresentation contains minimal sensitive information while maintaining high\neffectiveness for downstream tasks. By utilizing characteristic functions, we\nachieve a more stable and efficient solution compared to traditional methods.\nAdditionally, we introduce a simple relaxation of the objective function that\nguarantees fairness in common classification models with no performance\ndegradation. Experimental results on benchmark datasets demonstrate that our\napproach consistently matches or achieves better fairness and predictive\naccuracy than existing methods. Moreover, our method maintains robustness and\ncomputational efficiency, making it a practical solution for real-world\napplications.",
      "tldr_zh": "这篇论文针对公平分类（fair classification）问题，提出了一种基于特征函数距离（characteristic function distance）的简单有效方法，以解决现有对抗学习（adversarial learning）和分布匹配方法的稳定性和计算密集问题。该方法确保学到的表示中包含最少的敏感信息，同时保持下游任务的高性能，并通过目标函数的简单松弛在常见分类模型中实现公平性而不降低准确性。实验结果显示，在基准数据集上，该方法在公平性和预测准确性上与现有方法相当或更优，并展现出更高的稳健性和计算效率，适合真实世界应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11740v1",
      "published_date": "2025-05-16 22:59:46 UTC",
      "updated_date": "2025-05-16 22:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:34:43.345808"
    },
    {
      "arxiv_id": "2505.11739v1",
      "title": "ZeroTuning: Unlocking the Initial Token's Power to Enhance Large Language Models Without Training",
      "title_zh": "ZeroTuning: 解锁初始标记的潜力以增强大型语言模型而不需训练",
      "authors": [
        "Feijiang Han",
        "Xiaodong Yu",
        "Jianheng Tang",
        "Lyle Ungar"
      ],
      "abstract": "Recently, training-free methods for improving large language models (LLMs)\nhave attracted growing interest, with token-level attention tuning emerging as\na promising and interpretable direction. However, existing methods typically\nrely on auxiliary mechanisms to identify important or irrelevant task-specific\ntokens, introducing potential bias and limiting applicability. In this paper,\nwe uncover a surprising and elegant alternative: the semantically empty initial\ntoken is a powerful and underexplored control point for optimizing model\nbehavior. Through theoretical analysis, we show that tuning the initial token's\nattention sharpens or flattens the attention distribution over subsequent\ntokens, and its role as an attention sink amplifies this effect. Empirically,\nwe find that: (1) tuning its attention improves LLM performance more\neffectively than tuning other task-specific tokens; (2) the effect follows a\nconsistent trend across layers, with earlier layers having greater impact, but\nvaries across attention heads, with different heads showing distinct\npreferences in how they attend to this token. Based on these findings, we\npropose ZeroTuning, a training-free approach that improves LLM performance by\napplying head-specific attention adjustments to this special token. Despite\ntuning only one token, ZeroTuning achieves higher performance on text\nclassification, multiple-choice, and multi-turn conversation tasks across\nmodels such as Llama, Qwen, and DeepSeek. For example, ZeroTuning improves\nLlama-3.1-8B by 11.71% on classification, 2.64% on QA tasks, and raises its\nmulti-turn score from 7.804 to 7.966. The method is also robust to limited\nresources, few-shot settings, long contexts, quantization, decoding strategies,\nand prompt variations. Our work sheds light on a previously overlooked control\npoint in LLMs, offering new insights into both inference-time tuning and model\ninterpretability.",
      "tldr_zh": "该研究提出 ZeroTuning，一种无需训练的训练-free方法，通过调整大型语言模型(LLMs)中语义为空的 initial token 的注意力，来优化模型行为并提升性能。理论分析显示，这种调整能锐化或平坦化后续 token 的注意力分布，并放大其作为 attention sink 的作用。实证结果表明，ZeroTuning 比调整其他 token 更有效，并在不同层和注意力头中显示出特定模式，早层影响更大。实验在文本分类、多选题和多轮对话任务上验证了其效果，例如提升 Llama-3.1-8B 在分类任务的性能达 11.71%，并在资源有限、少样本设置等场景中表现出色。该方法揭示了 LLMs 中一个被忽略的控制点，为推理时调整和模型可解释性提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11739v1",
      "published_date": "2025-05-16 22:52:24 UTC",
      "updated_date": "2025-05-16 22:52:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:34:56.436846"
    },
    {
      "arxiv_id": "2505.11738v1",
      "title": "Automated Real-time Assessment of Intracranial Hemorrhage Detection AI Using an Ensembled Monitoring Model (EMM)",
      "title_zh": "翻译失败",
      "authors": [
        "Zhongnan Fang",
        "Andrew Johnston",
        "Lina Cheuy",
        "Hye Sun Na",
        "Magdalini Paschali",
        "Camila Gonzalez",
        "Bonnie A. Armstrong",
        "Arogya Koirala",
        "Derrick Laurel",
        "Andrew Walker Campion",
        "Michael Iv",
        "Akshay S. Chaudhari",
        "David B. Larson"
      ],
      "abstract": "Artificial intelligence (AI) tools for radiology are commonly unmonitored\nonce deployed. The lack of real-time case-by-case assessments of AI prediction\nconfidence requires users to independently distinguish between trustworthy and\nunreliable AI predictions, which increases cognitive burden, reduces\nproductivity, and potentially leads to misdiagnoses. To address these\nchallenges, we introduce Ensembled Monitoring Model (EMM), a framework inspired\nby clinical consensus practices using multiple expert reviews. Designed\nspecifically for black-box commercial AI products, EMM operates independently\nwithout requiring access to internal AI components or intermediate outputs,\nwhile still providing robust confidence measurements. Using intracranial\nhemorrhage detection as our test case on a large, diverse dataset of 2919\nstudies, we demonstrate that EMM successfully categorizes confidence in the\nAI-generated prediction, suggesting different actions and helping improve the\noverall performance of AI tools to ultimately reduce cognitive burden.\nImportantly, we provide key technical considerations and best practices for\nsuccessfully translating EMM into clinical settings.",
      "tldr_zh": "该论文提出 Ensembled Monitoring Model (EMM)，一种受临床共识实践启发的框架，用于实时评估放射学 AI 预测信心，从而解决 AI 工具部署后缺乏监控的问题，这可能导致用户认知负担增加、生产力下降和潜在误诊。EMM 针对黑盒商业 AI 产品设计，不需访问内部组件或中间输出，就能提供稳健的信心测量，并在包含 2919 个研究的颅内出血检测数据集上进行测试。实验结果表明，EMM 成功分类 AI 预测信心、建议相应行动，并改善整体 AI 性能，最终减少认知负担；论文还提供了将 EMM 转化为临床设置的关键技术和最佳实践。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11738v1",
      "published_date": "2025-05-16 22:50:42 UTC",
      "updated_date": "2025-05-16 22:50:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:35:07.192720"
    },
    {
      "arxiv_id": "2505.11737v1",
      "title": "Token-Level Uncertainty Estimation for Large Language Model Reasoning",
      "title_zh": "词元级不确定性估计用于大型语言",
      "authors": [
        "Tunyu Zhang",
        "Haizhou Shi",
        "Yibin Wang",
        "Hengyi Wang",
        "Xiaoxiao He",
        "Zhuowei Li",
        "Haoxian Chen",
        "Ligong Han",
        "Kai Xu",
        "Huan Zhang",
        "Dimitris Metaxas",
        "Hao Wang"
      ],
      "abstract": "While Large Language Models (LLMs) have demonstrated impressive capabilities,\ntheir output quality remains inconsistent across various application scenarios,\nmaking it difficult to identify trustworthy responses, especially in complex\ntasks requiring multi-step reasoning. In this paper, we propose a token-level\nuncertainty estimation framework to enable LLMs to self-assess and self-improve\ntheir generation quality in mathematical reasoning. Specifically, we introduce\nlow-rank random weight perturbation to LLM decoding, generating predictive\ndistributions that we use to estimate token-level uncertainties. We then\naggregate these uncertainties to reflect semantic uncertainty of the generated\nsequences. Experiments on mathematical reasoning datasets of varying difficulty\ndemonstrate that our token-level uncertainty metrics strongly correlate with\nanswer correctness and model robustness. Additionally, we explore using\nuncertainty to directly enhance the model's reasoning performance through\nmultiple generations and the particle filtering algorithm. Our approach\nconsistently outperforms existing uncertainty estimation methods, establishing\neffective uncertainty estimation as a valuable tool for both evaluating and\nimproving reasoning generation in LLMs.",
      "tldr_zh": "本文提出了一种 token-level uncertainty estimation 框架，用于 Large Language Models (LLMs) 在数学推理任务中的自我评估和自我改进，以解决输出质量不一致的问题。方法涉及在 LLM 解码中使用 low-rank random weight perturbation 生成预测分布，并聚合 token-level 不确定性以反映生成的序列语义不确定性。实验在不同难度的数学推理数据集上显示，该框架的不确定性指标与答案正确性和模型鲁棒性高度相关，并通过多次生成和 particle filtering algorithm 显著提升了推理性能。该方法优于现有不确定性估计方法，为评估和改进 LLMs 的推理生成提供了有效工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint; Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.11737v1",
      "published_date": "2025-05-16 22:47:32 UTC",
      "updated_date": "2025-05-16 22:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:35:19.670541"
    },
    {
      "arxiv_id": "2505.13511v1",
      "title": "Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale",
      "title_zh": "AI 自由职业者能竞争吗？大规模基准测试收入、可靠性和任务成功",
      "authors": [
        "David Noever",
        "Forrest McKee"
      ],
      "abstract": "This study explores Large Language Models (LLMs) as autonomous agents for\nreal-world tasks, including freelance software development. This work presents\na new benchmark that evaluates LLMs on freelance programming and data analysis\ntasks derived from economic data. We construct the benchmark using synthetic\ntasks created from a Kaggle Freelancer dataset of job postings, with all job\nprices standardized to USD (median fixed-project price around $250, and an\naverage of $306). Each task is accompanied by structured input-output test\ncases and an estimated price tag, enabling automated correctness checking and a\nmonetary performance valuation. This approach is inspired by OpenAI's recent\nSWE-Lancer benchmark (1,400 real Upwork tasks worth $1M total). Still, our\nframework simplifies evaluation using programmatically testable tasks and\npredicted price values, making it highly scalable and repeatable. On this\nbenchmark, we evaluate four modern LLMs - Claude 3.5 Haiku, GPT-4o-mini, Qwen\n2.5, and Mistral. We report each model's accuracy (task success rate and\ntest-case pass rate) and the total \"freelance earnings\" it achieves (sum of\nprices of solved tasks). Our results show that Claude 3.5 Haiku performs best,\nearning approximately $1.52 million USD, followed closely by GPT-4o-mini at\n$1.49 million, then Qwen 2.5 ($1.33M) and Mistral ($0.70M). We analyze the\ndistribution of errors per task and observe that the strongest models solve the\nmost tasks and rarely fail completely on any project. We discuss the\nimplications of these results for the feasibility of AI as a freelance\ndeveloper, the advantages and limitations of our automated benchmark approach,\nand the gap between performance on structured tasks versus the true complexity\nof real-world freelance jobs.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLMs）作为自主代理在自由职业任务（如编程和数据分析）中的表现，提出一个新基准来评估其准确性、可靠性和模拟“收入”。该基准基于Kaggle Freelancer数据集创建合成任务，每个任务附带结构化的输入-输出测试案例和标准化价格标签（中位数250美元），并通过自动化检查实现可扩展评估。实验结果显示，Claude 3.5 Haiku表现最佳，模拟收入约152万美元，其次是GPT-4o-mini（149万美元）、Qwen 2.5（133万美元）和Mistral（70万美元）；此外，分析表明最强模型在任务成功率上领先，并讨论了AI作为自由职业开发者的可行性及其与真实世界任务的差距。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13511v1",
      "published_date": "2025-05-16 22:42:04 UTC",
      "updated_date": "2025-05-16 22:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:35:33.002849"
    },
    {
      "arxiv_id": "2505.11731v1",
      "title": "Efficient Uncertainty Estimation via Distillation of Bayesian Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Harshil Vejendla",
        "Haizhou Shi",
        "Yibin Wang",
        "Tunyu Zhang",
        "Huan Zhang",
        "Hao Wang"
      ],
      "abstract": "Recent advances in uncertainty estimation for Large Language Models (LLMs)\nduring downstream adaptation have addressed key challenges of reliability and\nsimplicity. However, existing Bayesian methods typically require multiple\nsampling iterations during inference, creating significant efficiency issues\nthat limit practical deployment. In this paper, we investigate the possibility\nof eliminating the need for test-time sampling for LLM uncertainty estimation.\nSpecifically, when given an off-the-shelf Bayesian LLM, we distill its aligned\nconfidence into a non-Bayesian student LLM by minimizing the divergence between\ntheir predictive distributions. Unlike typical calibration methods, our\ndistillation is carried out solely on the training dataset without the need of\nan additional validation dataset. This simple yet effective approach achieves\nN-times more efficient uncertainty estimation during testing, where N is the\nnumber of samples traditionally required by Bayesian LLMs. Our extensive\nexperiments demonstrate that uncertainty estimation capabilities on training\ndata can successfully generalize to unseen test data through our distillation\ntechnique, consistently producing results comparable to (or even better than)\nstate-of-the-art Bayesian LLMs.",
      "tldr_zh": "本研究针对Bayesian Large Language Models (LLMs) 在不确定性估计中的效率问题，提出了一种知识蒸馏(distillation)方法，将Bayesian LLM的置信度转移到非Bayesian的student LLM中，仅通过最小化预测分布差异在训练数据集上进行。不同于传统校准方法，该方法无需额外验证数据集，即可实现测试时的N倍效率提升，其中N为传统采样次数。实验结果显示，这种蒸馏技术能使不确定性估计能力成功泛化到测试数据，其性能与或优于现有Bayesian LLMs。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint; work in progress",
      "pdf_url": "http://arxiv.org/pdf/2505.11731v1",
      "published_date": "2025-05-16 22:26:03 UTC",
      "updated_date": "2025-05-16 22:26:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:35:41.963210"
    },
    {
      "arxiv_id": "2505.11730v1",
      "title": "Rethinking Optimal Verification Granularity for Compute-Efficient Test-Time Scaling",
      "title_zh": "重新审",
      "authors": [
        "Hao Mark Chen",
        "Guanxi Lu",
        "Yasuyuki Okoshi",
        "Zhiwen Mo",
        "Masato Motomura",
        "Hongxiang Fan"
      ],
      "abstract": "Test-time scaling (TTS) has proven effective in enhancing the reasoning\ncapabilities of large language models (LLMs). Verification plays a key role in\nTTS, simultaneously influencing (1) reasoning performance and (2) compute\nefficiency, due to the quality and computational cost of verification. In this\nwork, we challenge the conventional paradigms of verification, and make the\nfirst attempt toward systematically investigating the impact of verification\ngranularity-that is, how frequently the verifier is invoked during generation,\nbeyond verifying only the final output or individual generation steps. To this\nend, we introduce Variable Granularity Search (VG-Search), a unified algorithm\nthat generalizes beam search and Best-of-N sampling via a tunable granularity\nparameter g. Extensive experiments with VG-Search under varying compute\nbudgets, generator-verifier configurations, and task attributes reveal that\ndynamically selecting g can improve the compute efficiency and scaling\nbehavior. Building on these findings, we propose adaptive VG-Search strategies\nthat achieve accuracy gains of up to 3.1\\% over Beam Search and 3.6\\% over\nBest-of-N, while reducing FLOPs by over 52\\%. We will open-source the code to\nsupport future research.",
      "tldr_zh": "这篇论文重新审视了验证粒度在计算高效的 Test-Time Scaling (TTS) 中的作用，旨在优化大型语言模型 (LLMs) 的推理性能和计算效率。作者引入了 Variable Granularity Search (VG-Search)，一个统一的算法，通过可调粒度参数 g 泛化 Beam Search 和 Best-of-N sampling，以动态调整验证频率。实验结果显示，自适应 VG-Search 策略在不同任务和计算预算下，比传统方法提高了准确率最多 3.6%，并减少了超过 52% 的 FLOPs，同时作者计划开源代码以支持进一步研究。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Preprint. Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.11730v1",
      "published_date": "2025-05-16 22:24:48 UTC",
      "updated_date": "2025-05-16 22:24:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:35:55.410263"
    },
    {
      "arxiv_id": "2505.11725v1",
      "title": "CLT and Edgeworth Expansion for m-out-of-n Bootstrap Estimators of The Studentized Median",
      "title_zh": "翻译失败",
      "authors": [
        "Imon Banerjee",
        "Sayak Chakrabarty"
      ],
      "abstract": "The m-out-of-n bootstrap, originally proposed by Bickel, Gotze, and Zwet\n(1992), approximates the distribution of a statistic by repeatedly drawing m\nsubsamples (with m much smaller than n) without replacement from an original\nsample of size n. It is now routinely used for robust inference with\nheavy-tailed data, bandwidth selection, and other large-sample applications.\nDespite its broad applicability across econometrics, biostatistics, and machine\nlearning, rigorous parameter-free guarantees for the soundness of the\nm-out-of-n bootstrap when estimating sample quantiles have remained elusive.\n  This paper establishes such guarantees by analyzing the estimator of sample\nquantiles obtained from m-out-of-n resampling of a dataset of size n. We first\nprove a central limit theorem for a fully data-driven version of the estimator\nthat holds under a mild moment condition and involves no unknown nuisance\nparameters. We then show that the moment assumption is essentially tight by\nconstructing a counter-example in which the CLT fails. Strengthening the\nassumptions slightly, we derive an Edgeworth expansion that provides exact\nconvergence rates and, as a corollary, a Berry Esseen bound on the bootstrap\napproximation error. Finally, we illustrate the scope of our results by\nderiving parameter-free asymptotic distributions for practical statistics,\nincluding the quantiles for random walk Metropolis-Hastings and the rewards of\nergodic Markov decision processes, thereby demonstrating the usefulness of our\ntheory in modern estimation and learning tasks.",
      "tldr_zh": "这篇论文分析了 m-out-of-n bootstrap 估计器在 Studentized Median 上的应用，建立了严格的无参数保证，包括中心极限定理 (CLT) 的证明，该 CLT 在一个温和的矩条件假设下适用于数据驱动的估计器。研究者还展示了该假设的紧致性，通过反例证明 CLT 可能失败，并导出了 Edgeworth expansion，提供精确的收敛率和 Berry-Esseen 界。最终，论文展示了这些结果在实际统计学中的应用，例如为随机游走 Metropolis-Hastings 的分位数和遍历 Markov 决策过程的回报导出无参数渐近分布，从而提升了 m-out-of-n bootstrap 在重尾数据和机器学习任务中的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE",
        "math.ST",
        "stat.ME",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "48 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11725v1",
      "published_date": "2025-05-16 22:14:49 UTC",
      "updated_date": "2025-05-16 22:14:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:36:09.150590"
    },
    {
      "arxiv_id": "2505.11719v1",
      "title": "Zero-Shot Visual Generalization in Robot Manipulation",
      "title_zh": "机器人操作中的零样本视觉泛化",
      "authors": [
        "Sumeet Batra",
        "Gaurav Sukhatme"
      ],
      "abstract": "Training vision-based manipulation policies that are robust across diverse\nvisual environments remains an important and unresolved challenge in robot\nlearning. Current approaches often sidestep the problem by relying on invariant\nrepresentations such as point clouds and depth, or by brute-forcing\ngeneralization through visual domain randomization and/or large, visually\ndiverse datasets. Disentangled representation learning - especially when\ncombined with principles of associative memory - has recently shown promise in\nenabling vision-based reinforcement learning policies to be robust to visual\ndistribution shifts. However, these techniques have largely been constrained to\nsimpler benchmarks and toy environments. In this work, we scale disentangled\nrepresentation learning and associative memory to more visually and dynamically\ncomplex manipulation tasks and demonstrate zero-shot adaptability to visual\nperturbations in both simulation and on real hardware. We further extend this\napproach to imitation learning, specifically Diffusion Policy, and empirically\nshow significant gains in visual generalization compared to state-of-the-art\nimitation learning methods. Finally, we introduce a novel technique adapted\nfrom the model equivariance literature that transforms any trained neural\nnetwork policy into one invariant to 2D planar rotations, making our policy not\nonly visually robust but also resilient to certain camera perturbations. We\nbelieve that this work marks a significant step towards manipulation policies\nthat are not only adaptable out of the box, but also robust to the complexities\nand dynamical nature of real-world deployment. Supplementary videos are\navailable at https://sites.google.com/view/vis-gen-robotics/home.",
      "tldr_zh": "这篇论文探讨了机器人操纵中实现 zero-shot visual generalization 的方法，以应对视觉环境变化的挑战。作者扩展了 disentangled representation learning 和 associative memory 技术，使视觉-based 强化学习策略在模拟和真实硬件上对视觉分布偏移表现出鲁棒性，并在更复杂的操纵任务中实现了零样本适应。论文进一步将此方法应用于模仿学习，特别是 Diffusion Policy，相比现有方法显著提升了视觉泛化性能。最终，他们引入了一种基于 model equivariance 的新技巧，使训练的神经网络策略对 2D 平面旋转不变，从而增强了对相机扰动的整体鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11719v1",
      "published_date": "2025-05-16 22:01:46 UTC",
      "updated_date": "2025-05-16 22:01:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:36:19.860263"
    },
    {
      "arxiv_id": "2505.11718v1",
      "title": "REMOR: Automated Peer Review Generation with LLM Reasoning and Multi-Objective Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Pawin Taechoyotin",
        "Daniel Acuna"
      ],
      "abstract": "AI-based peer review systems tend to produce shallow and overpraising\nsuggestions compared to human feedback. Here, we evaluate how well a reasoning\nLLM trained with multi-objective reinforcement learning (REMOR) can overcome\nthese limitations. We start by designing a multi-aspect reward function that\naligns with human evaluation of reviews. The aspects are related to the review\nitself (e.g., criticisms, novelty) and the relationship between the review and\nthe manuscript (i.e., relevance). First, we perform supervised fine-tuning of\nDeepSeek-R1-Distill-Qwen-7B using LoRA on PeerRT, a new dataset of high-quality\ntop AI conference reviews enriched with reasoning traces. We then apply Group\nRelative Policy Optimization (GRPO) to train two models: REMOR-H (with the\nhuman-aligned reward) and REMOR-U (with a uniform reward). Interestingly, the\nhuman-aligned reward penalizes aspects typically associated with strong\nreviews, leading REMOR-U to produce qualitatively more substantive feedback.\nOur results show that REMOR-U and REMOR-H achieve more than twice the average\nrewards of human reviews, non-reasoning state-of-the-art agentic multi-modal AI\nreview systems, and general commercial LLM baselines. We found that while the\nbest AI and human reviews are comparable in quality, REMOR avoids the long tail\nof low-quality human reviews. We discuss how reasoning is key to achieving\nthese improvements and release the Human-aligned Peer Review Reward (HPRR)\nfunction, the Peer Review Reasoning-enriched Traces (PeerRT) dataset, and the\nREMOR models, which we believe can help spur progress in the area.",
      "tldr_zh": "该研究提出 REMOR 框架，利用 LLM 推理和多目标强化学习（multi-objective reinforcement learning），旨在改善 AI 同行评审系统的浅显和过度赞扬问题。研究者设计了多方面奖励函数（multi-aspect reward function），包括评论内容（如批评和 novelty）和评论与稿件相关性（如 relevance），并使用 PeerRT 数据集对 DeepSeek-R1-Distill-Qwen-7B 模型进行监督微调（supervised fine-tuning with LoRA），随后通过 Group Relative Policy Optimization (GRPO) 训练 REMOR-H 和 REMOR-U 模型。结果显示，REMOR 模型的平均奖励是人类评论和基线 AI 系统（如非推理多模态系统）的两倍以上，同时避免了低质量人类评论的缺陷；此外，论文开源了 Human-aligned Peer Review Reward (HPRR) 函数、PeerRT 数据集和 REMOR 模型，以推动该领域进展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11718v1",
      "published_date": "2025-05-16 22:00:49 UTC",
      "updated_date": "2025-05-16 22:00:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:36:32.441098"
    },
    {
      "arxiv_id": "2505.11717v1",
      "title": "EnvInjection: Environmental Prompt Injection Attack to Multi-modal Web Agents",
      "title_zh": "EnvInjection：针对多模态网络代理的环境提示注入攻击",
      "authors": [
        "Xilong Wang",
        "John Bloch",
        "Zedian Shao",
        "Yuepeng Hu",
        "Shuyan Zhou",
        "Neil Zhenqiang Gong"
      ],
      "abstract": "Multi-modal large language model (MLLM)-based web agents interact with\nwebpage environments by generating actions based on screenshots of the\nwebpages. Environmental prompt injection attacks manipulate the environment to\ninduce the web agent to perform a specific, attacker-chosen action--referred to\nas the target action. However, existing attacks suffer from limited\neffectiveness or stealthiness, or are impractical in real-world settings. In\nthis work, we propose EnvInjection, a new attack that addresses these\nlimitations. Our attack adds a perturbation to the raw pixel values of the\nrendered webpage, which can be implemented by modifying the webpage's source\ncode. After these perturbed pixels are mapped into a screenshot, the\nperturbation induces the web agent to perform the target action. We formulate\nthe task of finding the perturbation as an optimization problem. A key\nchallenge in solving this problem is that the mapping between raw pixel values\nand screenshot is non-differentiable, making it difficult to backpropagate\ngradients to the perturbation. To overcome this, we train a neural network to\napproximate the mapping and apply projected gradient descent to solve the\nreformulated optimization problem. Extensive evaluation on multiple webpage\ndatasets shows that EnvInjection is highly effective and significantly\noutperforms existing baselines.",
      "tldr_zh": "该论文提出EnvInjection，一种针对多模态大语言模型(MLLM)网页代理的环境提示注入攻击，通过在网页原始像素值上添加扰动来诱导代理执行特定目标动作(target action)，从而提升攻击的有效性和隐蔽性。攻击方法将问题表述为优化问题，利用训练的神经网络近似像素值与截屏之间的非微分映射，并应用投影梯度下降(projected gradient descent)来求解。实验结果显示，EnvInjection在多个网页数据集上表现出色，比现有基线模型显著更有效。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11717v1",
      "published_date": "2025-05-16 22:00:26 UTC",
      "updated_date": "2025-05-16 22:00:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:36:42.496102"
    },
    {
      "arxiv_id": "2505.11714v1",
      "title": "Bi-Level Policy Optimization with Nyström Hypergradients",
      "title_zh": "翻译失败",
      "authors": [
        "Arjun Prakash",
        "Naicheng He",
        "Denizalp Goktas",
        "Amy Greenwald"
      ],
      "abstract": "The dependency of the actor on the critic in actor-critic (AC) reinforcement\nlearning means that AC can be characterized as a bilevel optimization (BLO)\nproblem, also called a Stackelberg game. This characterization motivates two\nmodifications to vanilla AC algorithms. First, the critic's update should be\nnested to learn a best response to the actor's policy. Second, the actor should\nupdate according to a hypergradient that takes changes in the critic's behavior\ninto account. Computing this hypergradient involves finding an inverse Hessian\nvector product, a process that can be numerically unstable. We thus propose a\nnew algorithm, Bilevel Policy Optimization with Nystr\\\"om Hypergradients\n(BLPO), which uses nesting to account for the nested structure of BLO, and\nleverages the Nystr\\\"om method to compute the hypergradient. Theoretically, we\nprove BLPO converges to (a point that satisfies the necessary conditions for) a\nlocal strong Stackelberg equilibrium in polynomial time with high probability,\nassuming a linear parametrization of the critic's objective. Empirically, we\ndemonstrate that BLPO performs on par with or better than PPO on a variety of\ndiscrete and continuous control tasks.",
      "tldr_zh": "这篇论文将 actor-critic (AC) 强化学习建模为双层优化 (bilevel optimization) 问题，并提出 Bi-Level Policy Optimization with Nyström Hypergradients (BLPO) 算法，以改进传统 AC 方法。BLPO 通过嵌套更新评论家以响应演员策略，并利用 Nyström 方法计算超梯度，避免了逆 Hessian 向量乘积的不稳定性。理论上，该算法在假设评论家目标线性参数化的条件下，以高概率在多项式时间内收敛到局部强 Stackelberg equilibrium；实验结果显示，BLPO 在各种离散和连续控制任务中表现不逊于或优于 PPO。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11714v1",
      "published_date": "2025-05-16 21:56:05 UTC",
      "updated_date": "2025-05-16 21:56:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:36:55.833510"
    },
    {
      "arxiv_id": "2505.11701v1",
      "title": "DMN-Guided Prompting: A Low-Code Framework for Controlling LLM Behavior",
      "title_zh": "翻译失败",
      "authors": [
        "Shaghayegh Abedi",
        "Amin Jalali"
      ],
      "abstract": "Large Language Models (LLMs) have shown considerable potential in automating\ndecision logic within knowledge-intensive processes. However, their\neffectiveness largely depends on the strategy and quality of prompting. Since\ndecision logic is typically embedded in prompts, it becomes challenging for end\nusers to modify or refine it. Decision Model and Notation (DMN) offers a\nstandardized graphical approach for defining decision logic in a structured,\nuser-friendly manner. This paper introduces a DMN-guided prompting framework\nthat breaks down complex decision logic into smaller, manageable components,\nguiding LLMs through structured decision pathways. We implemented the framework\nin a graduate-level course where students submitted assignments. The\nassignments and DMN models representing feedback instructions served as inputs\nto our framework. The instructor evaluated the generated feedback and labeled\nit for performance assessment. Our approach demonstrated promising results,\noutperforming chain-of-thought (CoT) prompting. Students also responded\npositively to the generated feedback, reporting high levels of perceived\nusefulness in a survey based on the Technology Acceptance Model.",
      "tldr_zh": "这篇论文提出了一种DMN-Guided Prompting框架，这是一个低代码方法，利用Decision Model and Notation (DMN)来标准化决策逻辑，从而更好地控制大型语言模型(LLMs)的行为。该框架将复杂决策逻辑分解为更小的组件，并通过结构化的决策路径引导LLMs生成输出。在研究生课程的实际应用中，该方法超过了chain-of-thought (CoT) prompting的性能，学生对生成的反馈反馈表示高度满意，并报告了较高的感知有用性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Large Language Models, Decision Model and Notation, Prompt\n  Engineering, Automated Feedback",
      "pdf_url": "http://arxiv.org/pdf/2505.11701v1",
      "published_date": "2025-05-16 21:09:36 UTC",
      "updated_date": "2025-05-16 21:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:37:06.769514"
    },
    {
      "arxiv_id": "2505.11698v1",
      "title": "Conditional Deep Generative Models for Belief State Planning",
      "title_zh": "翻译失败",
      "authors": [
        "Antoine Bigeard",
        "Anthony Corso",
        "Mykel Kochenderfer"
      ],
      "abstract": "Partially observable Markov decision processes (POMDPs) are used to model a\nwide range of applications, including robotics, autonomous vehicles, and\nsubsurface problems. However, accurately representing the belief is difficult\nfor POMDPs with high-dimensional states. In this paper, we propose a novel\napproach that uses conditional deep generative models (cDGMs) to represent the\nbelief. Unlike traditional belief representations, cDGMs are well-suited for\nhigh-dimensional states and large numbers of observations, and they can\ngenerate an arbitrary number of samples from the posterior belief. We train the\ncDGMs on data produced by random rollout trajectories and show their\neffectiveness in solving a mineral exploration POMDP with a large and\ncontinuous state space. The cDGMs outperform particle filter baselines in both\ntask-agnostic measures of belief accuracy as well as in planning performance.",
      "tldr_zh": "这篇论文针对部分可观察马尔可夫决策过程 (POMDPs) 在高维状态下难以准确表示信念的问题，提出了一种使用条件深度生成模型 (cDGMs) 的新方法来表示信念状态。\ncDGMs 适合处理高维状态和大量观察，能够从后验信念生成任意数量的样本，并通过在随机 rollout 轨迹数据上训练来实现。\n实验结果显示，在一个大型连续状态空间的矿物勘探 POMDP 中，cDGMs 在信念准确性和规划性能上均优于粒子滤波器基准。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11698v1",
      "published_date": "2025-05-16 21:06:41 UTC",
      "updated_date": "2025-05-16 21:06:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:37:19.466821"
    },
    {
      "arxiv_id": "2505.11695v1",
      "title": "Qronos: Correcting the Past by Shaping the Future... in Post-Training Quantization",
      "title_zh": "Qronos：通过塑造未来来修正过去……在训练后量化中",
      "authors": [
        "Shihao Zhang",
        "Haoyu Zhang",
        "Ian Colbert",
        "Rayan Saab"
      ],
      "abstract": "We introduce Qronos -- a new state-of-the-art post-training quantization\nalgorithm that sequentially rounds and updates neural network weights. Qronos\nnot only explicitly corrects errors due to both weight and activation\nquantization, but also errors resulting from quantizing previous layers. Our\niterative algorithm is based on an interpretable and disciplined optimization\nframework that subsumes and surpasses existing data-driven approaches. At each\nstep, Qronos alternates between error correction and diffusion via optimal\nupdate rules. Importantly, we prove that Qronos admits an efficient\nimplementation that uses the Cholesky decomposition for solving least-squares\nproblems. We also demonstrate that Qronos is compatible with existing\ntransformation techniques such as Hadamard-based incoherence processing and\nweight-activation scaling equalization, among others. We evaluate Qronos using\nrecent autoregressive language generation models in the Llama3 family; Qronos\nconsistently outperforms previous state-of-the-art adaptive rounding methods\nwhen quantizing the weights, activations, and/or KV caches.",
      "tldr_zh": "本论文引入了 Qronos，一种先进的 post-training quantization 算法，通过顺序舍入和更新神经网络权重来纠正权重量化、激活量化以及先前层量化导致的错误。Qronos 基于一个可解释的优化框架，交替进行错误纠正和扩散，并使用 Cholesky decomposition 高效解决最小二乘问题，同时兼容现有技术如 Hadamard-based incoherence processing 和 weight-activation scaling equalization。在 Llama3 家族的 autoregressive 语言生成模型上，Qronos 量化权重、激活和/or KV caches 时，显著优于现有自适应舍入方法，展示了其 state-of-the-art 性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11695v1",
      "published_date": "2025-05-16 21:04:25 UTC",
      "updated_date": "2025-05-16 21:04:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:37:31.954806"
    },
    {
      "arxiv_id": "2505.11694v1",
      "title": "Neural Networks as Universal Finite-State Machines: A Constructive Deterministic Finite Automaton Theory",
      "title_zh": "神经网络作为通用有限状态机：一个建设性确定性有限自动机理论",
      "authors": [
        "Sahil Rajesh Dhayalkar"
      ],
      "abstract": "We present a complete theoretical and empirical framework establishing\nfeedforward neural networks as universal finite-state machines (N-FSMs). Our\nresults prove that finite-depth ReLU and threshold networks can exactly\nsimulate deterministic finite automata (DFAs) by unrolling state transitions\ninto depth-wise neural layers, with formal characterizations of required depth,\nwidth, and state compression. We demonstrate that DFA transitions are linearly\nseparable, binary threshold activations allow exponential compression, and\nMyhill-Nerode equivalence classes can be embedded into continuous latent spaces\nwhile preserving separability. We also formalize the expressivity boundary:\nfixed-depth feedforward networks cannot recognize non-regular languages\nrequiring unbounded memory. Unlike prior heuristic or probing-based studies, we\nprovide constructive proofs and design explicit DFA-unrolled neural\narchitectures that empirically validate every claim. Our results bridge deep\nlearning, automata theory, and neural-symbolic computation, offering a rigorous\nblueprint for how discrete symbolic processes can be realized in continuous\nneural systems.",
      "tldr_zh": "该研究建立了一个完整的理论和实证框架，证明前馈神经网络可作为通用有限状态机（N-FSMs），通过将确定性有限自动机（DFAs）的状态转换展开成深度神经层，精确模拟有限深度的 ReLU 和阈值网络，并形式化了所需的深度、宽度和状态压缩。论文展示了 DFA 转换的线性可分离性、二进制阈值激活的指数级压缩能力，以及 Myhill-Nerode 等价类的连续潜在空间嵌入，同时保持可分离性。实验通过构造性证明和显式 DFA-unrolled 神经架构验证了这些主张，并界定了固定深度网络无法识别非正则语言的表达性边界，最终桥接了深度学习、自动机理论和神经符号计算领域。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.FL"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.11694v1",
      "published_date": "2025-05-16 21:01:34 UTC",
      "updated_date": "2025-05-16 21:01:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:37:45.385823"
    },
    {
      "arxiv_id": "2505.11692v1",
      "title": "The Geometry of ReLU Networks through the ReLU Transition Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Sahil Rajesh Dhayalkar"
      ],
      "abstract": "We develop a novel theoretical framework for analyzing ReLU neural networks\nthrough the lens of a combinatorial object we term the ReLU Transition Graph\n(RTG). In this graph, each node corresponds to a linear region induced by the\nnetwork's activation patterns, and edges connect regions that differ by a\nsingle neuron flip. Building on this structure, we derive a suite of new\ntheoretical results connecting RTG geometry to expressivity, generalization,\nand robustness. Our contributions include tight combinatorial bounds on RTG\nsize and diameter, a proof of RTG connectivity, and graph-theoretic\ninterpretations of VC-dimension. We also relate entropy and average degree of\nthe RTG to generalization error. Each theoretical result is rigorously\nvalidated via carefully controlled experiments across varied network depths,\nwidths, and data regimes. This work provides the first unified treatment of\nReLU network structure via graph theory and opens new avenues for compression,\nregularization, and complexity control rooted in RTG analysis.",
      "tldr_zh": "本研究提出了一种新型理论框架——ReLU Transition Graph (RTG)，用于分析ReLU神经网络的几何结构，其中每个节点代表网络激活模式引发的线性区域，边连接仅一个神经元翻转的区域。基于RTG，该框架推导出了一系列理论结果，包括对RTG大小和直径的紧密组合边界证明、RTG连通性的证明、VC-dimension的图论解释，以及将RTG的熵和平均度与泛化错误相关联。实验通过控制网络深度、宽度和数据条件进行验证，首次统一ReLU网络结构的应用，为网络压缩、正则化和复杂性控制提供了新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11692v1",
      "published_date": "2025-05-16 21:00:56 UTC",
      "updated_date": "2025-05-16 21:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:37:56.144331"
    },
    {
      "arxiv_id": "2505.15836v1",
      "title": "Quantum-Evolutionary Neural Networks for Multi-Agent Federated Learning",
      "title_zh": "量子-进化神经网络用于多智能体联邦学习",
      "authors": [
        "Aarav Lala",
        "Kalyan Cherukuri"
      ],
      "abstract": "As artificial intelligence continues to drive innovation in complex,\ndecentralized environments, the need for scalable, adaptive, and\nprivacy-preserving decision-making systems has become critical. This paper\nintroduces a novel framework combining quantum-inspired neural networks with\nevolutionary algorithms to optimize real-time decision-making in multi-agent\nsystems (MAS). The proposed Quantum-Evolutionary Neural Network (QE-NN)\nleverages quantum computing principles -- such as quantum superposition and\nentanglement -- to enhance learning speed and decision accuracy, while\nintegrating evolutionary optimization to continually refine agent behaviors in\ndynamic, uncertain environments. By utilizing federated learning, QE-NN ensures\nprivacy preservation, enabling decentralized agents to collaborate without\nsharing sensitive data. The framework is designed to allow agents to adapt in\nreal-time to their environments, optimizing decision-making processes for\napplications in areas such as autonomous systems, smart cities, and healthcare.\nThis research represents a breakthrough in merging quantum computing,\nevolutionary optimization, and privacy-preserving techniques to solve complex\nproblems in multi-agent decision-making systems, pushing the boundaries of AI\nin real-world, privacy-sensitive applications.",
      "tldr_zh": "本论文提出了一种新型框架——Quantum-Evolutionary Neural Network (QE-NN)，将量子启发神经网络与进化算法相结合，用于优化多智能体系统 (MAS) 中的实时决策。该框架利用量子叠加和纠缠等量子计算原则提升学习速度和决策准确性，同时通过联邦学习 (federated learning) 实现隐私保护，允许代理在不共享敏感数据的情况下进行协作。QE-NN 能够使代理在动态不确定环境中持续适应行为，适用于自主系统、智能城市和医疗保健等领域。该研究标志着量子计算、进化优化和隐私保护技术的融合，在多智能体决策系统中实现了重要突破。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15836v1",
      "published_date": "2025-05-16 20:51:37 UTC",
      "updated_date": "2025-05-16 20:51:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:38:07.932846"
    },
    {
      "arxiv_id": "2505.11687v1",
      "title": "Second SIGIR Workshop on Simulations for Information Access (Sim4IA 2025)",
      "title_zh": "第二届 SIGIR 信息访问模拟工作坊 (Sim4IA 2025)",
      "authors": [
        "Philipp Schaer",
        "Christin Katharina Kreutz",
        "Krisztian Balog",
        "Timo Breuer",
        "Andreas Konstantin Kruff"
      ],
      "abstract": "Simulations in information access (IA) have recently gained interest, as\nshown by various tutorials and workshops around that topic. Simulations can be\nkey contributors to central IA research and evaluation questions, especially\naround interactive settings when real users are unavailable, or their\nparticipation is impossible due to ethical reasons. In addition, simulations in\nIA can help contribute to a better understanding of users, reduce complexity of\nevaluation experiments, and improve reproducibility. Building on recent\ndevelopments in methods and toolkits, the second iteration of our Sim4IA\nworkshop aims to again bring together researchers and practitioners to form an\ninteractive and engaging forum for discussions on the future perspectives of\nthe field. An additional aim is to plan an upcoming TREC/CLEF campaign.",
      "tldr_zh": "本论文介绍了Second SIGIR Workshop on Simulations for Information Access (Sim4IA 2025)，这是一个聚焦于信息访问（IA）领域模拟技术的研讨会。模拟技术可解决交互场景中的关键问题，如真实用户不可用或伦理限制，帮助更好地理解用户、简化实验复杂性和提升可重复性。该研讨会旨在汇集研究者和从业者，进行互动讨论，探讨领域的未来展望，并规划即将到来的TREC/CLEF活动。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.IR",
      "comment": "Proceedings of the 48th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '25), July 13--18,\n  2025, Padua, Italy",
      "pdf_url": "http://arxiv.org/pdf/2505.11687v1",
      "published_date": "2025-05-16 20:48:59 UTC",
      "updated_date": "2025-05-16 20:48:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:38:18.161128"
    },
    {
      "arxiv_id": "2505.11669v1",
      "title": "OT Score: An OT based Confidence Score for Unsupervised Domain Adaptation",
      "title_zh": "OT Score：基于 OT 的无监督域适应置信度分数",
      "authors": [
        "Yiming Zhang",
        "Sitong Liu",
        "Alex Cloninger"
      ],
      "abstract": "We address the computational and theoretical limitations of existing\ndistributional alignment methods for unsupervised domain adaptation (UDA),\nparticularly regarding the estimation of classification performance and\nconfidence without target labels. Current theoretical frameworks for these\nmethods often yield computationally intractable quantities and fail to\nadequately reflect the properties of the alignment algorithms employed. To\novercome these challenges, we introduce the Optimal Transport (OT) score, a\nconfidence metric derived from a novel theoretical analysis that exploits the\nflexibility of decision boundaries induced by Semi-Discrete Optimal Transport\nalignment. The proposed OT score is intuitively interpretable, theoretically\nrigorous, and computationally efficient. It provides principled uncertainty\nestimates for any given set of target pseudo-labels without requiring model\nretraining, and can flexibly adapt to varying degrees of available source\ninformation. Experimental results on standard UDA benchmarks demonstrate that\nclassification accuracy consistently improves by identifying and removing\nlow-confidence predictions, and that OT score significantly outperforms\nexisting confidence metrics across diverse adaptation scenarios.",
      "tldr_zh": "该论文针对无监督域适应 (UDA) 中的分布对齐方法计算和理论限制，提出了一种基于 Optimal Transport (OT) 的置信度分数 OT score，用于在无目标标签情况下估计分类性能和不确定性。OT score 通过利用 Semi-Discrete Optimal Transport 对齐的决策边界灵活性，提供理论严谨且计算高效的置信度指标，无需模型重新训练即可适应不同来源信息。实验结果显示，在标准 UDA 基准上，通过识别并移除低置信度预测，分类准确率得到一致提升，且 OT score 在多种适应场景中显著优于现有置信度指标。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11669v1",
      "published_date": "2025-05-16 20:09:05 UTC",
      "updated_date": "2025-05-16 20:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:38:31.676867"
    },
    {
      "arxiv_id": "2505.11665v1",
      "title": "Multilingual Prompt Engineering in Large Language Models: A Survey Across NLP Tasks",
      "title_zh": "大语言模型中的多语言提示工程：跨 NLP 任务的调查",
      "authors": [
        "Shubham Vatsal",
        "Harsh Dubey",
        "Aditi Singh"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive performance across\na wide range of Natural Language Processing (NLP) tasks. However, ensuring\ntheir effectiveness across multiple languages presents unique challenges.\nMultilingual prompt engineering has emerged as a key approach to enhance LLMs'\ncapabilities in diverse linguistic settings without requiring extensive\nparameter re-training or fine-tuning. With growing interest in multilingual\nprompt engineering over the past two to three years, researchers have explored\nvarious strategies to improve LLMs' performance across languages and NLP tasks.\nBy crafting structured natural language prompts, researchers have successfully\nextracted knowledge from LLMs across different languages, making these\ntechniques an accessible pathway for a broader audience, including those\nwithout deep expertise in machine learning, to harness the capabilities of\nLLMs. In this paper, we survey and categorize different multilingual prompting\ntechniques based on the NLP tasks they address across a diverse set of datasets\nthat collectively span around 250 languages. We further highlight the LLMs\nemployed, present a taxonomy of approaches and discuss potential\nstate-of-the-art (SoTA) methods for specific multilingual datasets.\nAdditionally, we derive a range of insights across language families and\nresource levels (high-resource vs. low-resource), including analyses such as\nthe distribution of NLP tasks by language resource type and the frequency of\nprompting methods across different language families. Our survey reviews 36\nresearch papers covering 39 prompting techniques applied to 30 multilingual NLP\ntasks, with the majority of these studies published in the last two years.",
      "tldr_zh": "这篇论文对多语言提示工程在大型语言模型（LLMs）中的应用进行了全面调查，旨在解决LLMs在多语言自然语言处理（NLP）任务中的挑战，而无需进行广泛的参数重新训练。研究者分析了36篇论文中涵盖的39种提示技术，这些技术应用于30个多语言NLP任务，涉及约250种语言，并根据语言家族和资源水平（如高资源 vs. 低资源语言）进行了分类和见解总结。调查揭示了提示工程的潜力，使非机器学习专家也能轻松利用LLMs，同时突出了任务分布和方法频率的分析，为多语言LLMs优化提供了state-of-the-art（SoTA）参考。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11665v1",
      "published_date": "2025-05-16 19:59:17 UTC",
      "updated_date": "2025-05-16 19:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:38:44.653263"
    },
    {
      "arxiv_id": "2505.11661v1",
      "title": "Learning from Less: Guiding Deep Reinforcement Learning with Differentiable Symbolic Planning",
      "title_zh": "从少量学习：使用可微符号规划指导深度强化学习",
      "authors": [
        "Zihan Ye",
        "Oleg Arenz",
        "Kristian Kersting"
      ],
      "abstract": "When tackling complex problems, humans naturally break them down into\nsmaller, manageable subtasks and adjust their initial plans based on\nobservations. For instance, if you want to make coffee at a friend's place, you\nmight initially plan to grab coffee beans, go to the coffee machine, and pour\nthem into the machine. Upon noticing that the machine is full, you would skip\nthe initial steps and proceed directly to brewing. In stark contrast, state of\nthe art reinforcement learners, such as Proximal Policy Optimization (PPO),\nlack such prior knowledge and therefore require significantly more training\nsteps to exhibit comparable adaptive behavior. Thus, a central research\nquestion arises: \\textit{How can we enable reinforcement learning (RL) agents\nto have similar ``human priors'', allowing the agent to learn with fewer\ntraining interactions?} To address this challenge, we propose differentiable\nsymbolic planner (Dylan), a novel framework that integrates symbolic planning\ninto Reinforcement Learning. Dylan serves as a reward model that dynamically\nshapes rewards by leveraging human priors, guiding agents through intermediate\nsubtasks, thus enabling more efficient exploration. Beyond reward shaping,\nDylan can work as a high level planner that composes primitive policies to\ngenerate new behaviors while avoiding common symbolic planner pitfalls such as\ninfinite execution loops. Our experimental evaluations demonstrate that Dylan\nsignificantly improves RL agents' performance and facilitates generalization to\nunseen tasks.",
      "tldr_zh": "该论文探讨了如何让强化学习（Reinforcement Learning）代理像人类一样利用“先验知识”分解任务并调整计划，从而减少训练交互。作者提出Differentiable Symbolic Planning框架（Dylan），它作为奖励模型动态塑造奖励，引导代理通过中间子任务进行更有效的探索，同时兼具高层规划功能，组合原始策略生成新行为并避免无限循环等问题。实验结果显示，Dylan显著提升了RL代理的性能，并提高了对未见任务的泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "conference paper, 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11661v1",
      "published_date": "2025-05-16 19:52:36 UTC",
      "updated_date": "2025-05-16 19:52:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:38:55.633379"
    },
    {
      "arxiv_id": "2505.11659v1",
      "title": "Programmable metasurfaces for future photonic artificial intelligence",
      "title_zh": "用于未来光子人工智能的可编程超表面",
      "authors": [
        "Loubnan Abou-Hamdan",
        "Emil Marinov",
        "Peter Wiecha",
        "Philipp del Hougne",
        "Tianyu Wang",
        "Patrice Genevet"
      ],
      "abstract": "Photonic neural networks (PNNs), which share the inherent benefits of\nphotonic systems, such as high parallelism and low power consumption, could\nchallenge traditional digital neural networks in terms of energy efficiency,\nlatency, and throughput. However, producing scalable photonic artificial\nintelligence (AI) solutions remains challenging. To make photonic AI models\nviable, the scalability problem needs to be solved. Large optical AI models\nimplemented on PNNs are only commercially feasible if the advantages of optical\ncomputation outweigh the cost of their input-output overhead. In this\nPerspective, we discuss how field-programmable metasurface technology may\nbecome a key hardware ingredient in achieving scalable photonic AI accelerators\nand how it can compete with current digital electronic technologies.\nProgrammability or reconfigurability is a pivotal component for PNN hardware,\nenabling in situ training and accommodating non-stationary use cases that\nrequire fine-tuning or transfer learning. Co-integration with electronics, 3D\nstacking, and large-scale manufacturing of metasurfaces would significantly\nimprove PNN scalability and functionalities. Programmable metasurfaces could\naddress some of the current challenges that PNNs face and enable\nnext-generation photonic AI technology.",
      "tldr_zh": "该论文讨论了光子神经网络 (PNNs) 的优势，如高并行性和低功耗，使其在能效、延迟和吞吐量上可能超越传统数字神经网络，但面临可扩展性挑战。可编程超表面 (field-programmable metasurface) 技术被视为关键硬件组件，能通过提供可编程性、与电子设备的共集成以及3D堆叠等方式，提升 PNNs 的可扩展性和功能。作者认为，这种技术可解决 PNNs 的输入输出开销问题，并推动下一代光子 AI 加速器，与当前数字电子技术竞争。",
      "categories": [
        "physics.optics",
        "cs.AI",
        "physics.app-ph"
      ],
      "primary_category": "physics.optics",
      "comment": "Nat. Rev. Phys. (2025)",
      "pdf_url": "http://arxiv.org/pdf/2505.11659v1",
      "published_date": "2025-05-16 19:50:01 UTC",
      "updated_date": "2025-05-16 19:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:39:08.057264"
    },
    {
      "arxiv_id": "2505.11646v1",
      "title": "FLOW-BENCH: Towards Conversational Generation of Enterprise Workflows",
      "title_zh": "翻译失败",
      "authors": [
        "Evelyn Duesterwald",
        "Siyu Huo",
        "Vatche Isahagian",
        "K. R. Jayaram",
        "Ritesh Kumar",
        "Vinod Muthusamy",
        "Punleuk Oum",
        "Debashish Saha",
        "Gegi Thomas",
        "Praveen Venkateswaran"
      ],
      "abstract": "Business process automation (BPA) that leverages Large Language Models (LLMs)\nto convert natural language (NL) instructions into structured business process\nartifacts is becoming a hot research topic. This paper makes two technical\ncontributions -- (i) FLOW-BENCH, a high quality dataset of paired natural\nlanguage instructions and structured business process definitions to evaluate\nNL-based BPA tools, and support bourgeoning research in this area, and (ii)\nFLOW-GEN, our approach to utilize LLMs to translate natural language into an\nintermediate representation with Python syntax that facilitates final\nconversion into widely adopted business process definition languages, such as\nBPMN and DMN. We bootstrap FLOW-BENCH by demonstrating how it can be used to\nevaluate the components of FLOW-GEN across eight LLMs of varying sizes. We hope\nthat FLOW-GEN and FLOW-BENCH catalyze further research in BPA making it more\naccessible to novice and expert users.",
      "tldr_zh": "这篇论文针对商业过程自动化 (BPA)，提出了两个关键贡献：FLOW-BENCH，一个高质量数据集，包含配对的自然语言 (NL) 指令和结构化业务流程定义，用于评估基于 NL 的 BPA 工具，并支持相关研究。另一个贡献是 FLOW-GEN 方法，利用大型语言模型 (LLMs) 将 NL 指令翻译成 Python 语法的中间表示，从而便于最终转换为 BPMN 和 DMN 等标准业务流程定义语言。通过在八个不同规模的 LLMs 上评估 FLOW-GEN，论文展示了其组件的有效性，并旨在使 BPA 更易于新手和专家用户应用，促进该领域的进一步发展。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11646v1",
      "published_date": "2025-05-16 19:14:19 UTC",
      "updated_date": "2025-05-16 19:14:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:39:21.663429"
    },
    {
      "arxiv_id": "2505.11642v1",
      "title": "PeerGuard: Defending Multi-Agent Systems Against Backdoor Attacks Through Mutual Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Falong Fan",
        "Xi Li"
      ],
      "abstract": "Multi-agent systems leverage advanced AI models as autonomous agents that\ninteract, cooperate, or compete to complete complex tasks across applications\nsuch as robotics and traffic management. Despite their growing importance,\nsafety in multi-agent systems remains largely underexplored, with most research\nfocusing on single AI models rather than interacting agents. This work\ninvestigates backdoor vulnerabilities in multi-agent systems and proposes a\ndefense mechanism based on agent interactions. By leveraging reasoning\nabilities, each agent evaluates responses from others to detect illogical\nreasoning processes, which indicate poisoned agents. Experiments on LLM-based\nmulti-agent systems, including ChatGPT series and Llama 3, demonstrate the\neffectiveness of the proposed method, achieving high accuracy in identifying\npoisoned agents while minimizing false positives on clean agents. We believe\nthis work provides insights into multi-agent system safety and contributes to\nthe development of robust, trustworthy AI interactions.",
      "tldr_zh": "该研究探讨了多智能体系统（Multi-Agent Systems）中的后门攻击（Backdoor Attacks）漏洞，强调了现有研究偏重单个 AI 模型而忽略代理互动的安全问题。论文提出PeerGuard防御机制，通过代理间的相互推理（Mutual Reasoning），让每个代理评估其他代理的响应以检测不合逻辑的推理过程，从而识别受污染的代理（poisoned agents）。实验在基于LLM（如ChatGPT系列和Llama 3）的多智能体系统上验证了该方法的有效性，实现了高准确率识别受污染代理，同时最小化了对干净代理的假阳性误报，为构建鲁棒、可信赖的AI互动提供了重要见解。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11642v1",
      "published_date": "2025-05-16 19:08:29 UTC",
      "updated_date": "2025-05-16 19:08:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:39:33.218044"
    },
    {
      "arxiv_id": "2505.11633v1",
      "title": "Chatting with Papers: A Hybrid Approach Using LLMs and Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Vyacheslav Tykhonov",
        "Han Yang",
        "Philipp Mayr",
        "Jetze Touber",
        "Andrea Scharnhorst"
      ],
      "abstract": "This demo paper reports on a new workflow \\textit{GhostWriter} that combines\nthe use of Large Language Models and Knowledge Graphs (semantic artifacts) to\nsupport navigation through collections. Situated in the research area of\nRetrieval Augmented Generation, this specific workflow details the creation of\nlocal and adaptable chatbots. Based on the tool-suite \\textit{EverythingData}\nat the backend, \\textit{GhostWriter} provides an interface that enables\nquerying and ``chatting'' with a collection. Applied iteratively, the workflow\nsupports the information needs of researchers when interacting with a\ncollection of papers, whether it be to gain an overview, to learn more about a\nspecific concept and its context, and helps the researcher ultimately to refine\ntheir research question in a controlled way. We demonstrate the workflow for a\ncollection of articles from the \\textit{method data analysis} journal published\nby GESIS -- Leibniz-Institute for the Social Sciences. We also point to further\napplication areas.",
      "tldr_zh": "这篇论文介绍了 GhostWriter，一种结合 Large Language Models (LLMs) 和 Knowledge Graphs 的混合工作流程，旨在通过 Retrieval Augmented Generation (RAG) 技术支持研究人员导航论文集合。工作流程基于 EverythingData 工具套件，创建本地和可适配的聊天机器人，允许用户迭代查询、获取论文概述、了解特定概念及其上下文，并以受控方式完善研究问题。在 GESIS 的 method data analysis 期刊文章集合上进行演示，该方法还适用于其他领域。",
      "categories": [
        "cs.DL",
        "cs.AI"
      ],
      "primary_category": "cs.DL",
      "comment": "9 pages, 3 figures, Submitted to Joint Workshop of the 5th AI +\n  Informetrics (AII) and the 6th Extraction and Evaluation of Knowledge\n  Entities from Scientific Documents (EEKE)",
      "pdf_url": "http://arxiv.org/pdf/2505.11633v1",
      "published_date": "2025-05-16 18:51:51 UTC",
      "updated_date": "2025-05-16 18:51:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:39:45.335087"
    },
    {
      "arxiv_id": "2505.11626v1",
      "title": "THELMA: Task Based Holistic Evaluation of Large Language Model Applications-RAG Question Answering",
      "title_zh": "THELMA",
      "authors": [
        "Udita Patel",
        "Rutu Mulkar",
        "Jay Roberts",
        "Cibi Chakravarthy Senthilkumar",
        "Sujay Gandhi",
        "Xiaofei Zheng",
        "Naumaan Nayyar",
        "Rafael Castrillo"
      ],
      "abstract": "We propose THELMA (Task Based Holistic Evaluation of Large Language Model\nApplications), a reference free framework for RAG (Retrieval Augmented\ngeneration) based question answering (QA) applications. THELMA consist of six\ninterdependent metrics specifically designed for holistic, fine grained\nevaluation of RAG QA applications. THELMA framework helps developers and\napplication owners evaluate, monitor and improve end to end RAG QA pipelines\nwithout requiring labelled sources or reference responses.We also present our\nfindings on the interplay of the proposed THELMA metrics, which can be\ninterpreted to identify the specific RAG component needing improvement in QA\napplications.",
      "tldr_zh": "本研究提出 THELMA 框架，这是一种基于任务的整体评估方法，用于评估大型语言模型应用中的 RAG（Retrieval Augmented Generation）问答（QA）系统。THELMA 包括六个相互依赖的指标，实现了全面、细粒度的评估，帮助开发者在无需标记来源或参考响应的情况下，监控和优化端到端 RAG QA 管道。通过分析这些指标之间的相互作用，研究发现可以精确识别 QA 应用中需要改进的具体 RAG 组件，从而提升系统性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11626v1",
      "published_date": "2025-05-16 18:42:04 UTC",
      "updated_date": "2025-05-16 18:42:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:39:55.870064"
    },
    {
      "arxiv_id": "2505.11625v1",
      "title": "Nearest Neighbor Multivariate Time Series Forecasting",
      "title_zh": "最近邻多变量时间序列预测",
      "authors": [
        "Huiliang Zhang",
        "Ping Nie",
        "Lijun Sun",
        "Benoit Boulet"
      ],
      "abstract": "Multivariate time series (MTS) forecasting has a wide range of applications\nin both industry and academia. Recently, spatial-temporal graph neural networks\n(STGNNs) have gained popularity as MTS forecasting methods. However, current\nSTGNNs can only use the finite length of MTS input data due to the\ncomputational complexity. Moreover, they lack the ability to identify similar\npatterns throughout the entire dataset and struggle with data that exhibit\nsparsely and discontinuously distributed correlations among variables over an\nextensive historical period, resulting in only marginal improvements. In this\narticle, we introduce a simple yet effective k-nearest neighbor MTS forecasting\n( kNN-MTS) framework, which forecasts with a nearest neighbor retrieval\nmechanism over a large datastore of cached series, using representations from\nthe MTS model for similarity search. This approach requires no additional\ntraining and scales to give the MTS model direct access to the whole dataset at\ntest time, resulting in a highly expressive model that consistently improves\nperformance, and has the ability to extract sparse distributed but similar\npatterns spanning over multivariables from the entire dataset. Furthermore, a\nhybrid spatial-temporal encoder (HSTEncoder) is designed for kNN-MTS which can\ncapture both long-term temporal and short-term spatial-temporal dependencies\nand is shown to provide accurate representation for kNN-MTSfor better\nforecasting. Experimental results on several real-world datasets show a\nsignificant improvement in the forecasting performance of kNN-MTS. The\nquantitative analysis also illustrates the interpretability and efficiency of\nkNN-MTS, showing better application prospects and opening up a new path for\nefficiently using the large dataset in MTS models.",
      "tldr_zh": "本研究针对多变量时间序列 (MTS) 预测中的挑战，指出现有空间-时间图神经网络 (STGNNs) 因计算复杂性仅能处理有限输入数据，且难以识别整个数据集中的稀疏相似模式，从而导致性能提升有限。作者提出一个简单有效的 k 最近邻 MTS 预测框架 (kNN-MTS)，通过最近邻检索机制在大型缓存数据存储中搜索相似序列，使用 MTS 模型的表示进行相似性搜索，无需额外训练即可访问整个数据集，提升模型的表现力和预测准确性。此外，设计了混合空间-时间编码器 (HSTEncoder) 来捕捉长期时间依赖和短期空间-时间依赖，提供精确的表示。实验在多个真实世界数据集上显示，kNN-MTS 显著提高了预测性能，并展示了其可解释性和效率，为高效利用大型数据集的 MTS 模型开辟新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11625v1",
      "published_date": "2025-05-16 18:41:33 UTC",
      "updated_date": "2025-05-16 18:41:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:40:08.569186"
    },
    {
      "arxiv_id": "2505.11621v1",
      "title": "A Classical View on Benign Overfitting: The Role of Sample Size",
      "title_zh": "对良性过拟合的经典视角：样本大小的作用",
      "authors": [
        "Junhyung Park",
        "Patrick Bloebaum",
        "Shiva Prasad Kasiviswanathan"
      ],
      "abstract": "Benign overfitting is a phenomenon in machine learning where a model\nperfectly fits (interpolates) the training data, including noisy examples, yet\nstill generalizes well to unseen data. Understanding this phenomenon has\nattracted considerable attention in recent years. In this work, we introduce a\nconceptual shift, by focusing on almost benign overfitting, where models\nsimultaneously achieve both arbitrarily small training and test errors. This\nbehavior is characteristic of neural networks, which often achieve low (but\nnon-zero) training error while still generalizing well. We hypothesize that\nthis almost benign overfitting can emerge even in classical regimes, by\nanalyzing how the interaction between sample size and model complexity enables\nlarger models to achieve both good training fit but still approach\nBayes-optimal generalization. We substantiate this hypothesis with theoretical\nevidence from two case studies: (i) kernel ridge regression, and (ii)\nleast-squares regression using a two-layer fully connected ReLU neural network\ntrained via gradient flow. In both cases, we overcome the strong assumptions\noften required in prior work on benign overfitting.\n  Our results on neural networks also provide the first generalization result\nin this setting that does not rely on any assumptions about the underlying\nregression function or noise, beyond boundedness. Our analysis introduces a\nnovel proof technique based on decomposing the excess risk into estimation and\napproximation errors, interpreting gradient flow as an implicit regularizer,\nthat helps avoid uniform convergence traps. This analysis idea could be of\nindependent interest.",
      "tldr_zh": "本论文探讨了机器学习中的 benign overfitting 现象，强调样本大小在模型实现良好训练拟合和测试泛化之间的作用，引入了“almost benign overfitting”概念，即模型同时达到很小的训练和测试错误。作者通过理论分析两个案例——kernel ridge regression 和使用梯度流的 least-squares 回归（基于两层全连接 ReLU 神经网络）——证明了样本大小与模型复杂度的交互能在经典设置下实现接近贝叶斯最优泛化，而无需先前工作的强假设。研究还提出了一种新颖的证明技术，将过量风险分解为估计和近似错误，将梯度流视为隐式正则化器，从而避免了统一收敛假设的限制。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "The results here subsume: arXiv:2410.06191",
      "pdf_url": "http://arxiv.org/pdf/2505.11621v1",
      "published_date": "2025-05-16 18:37:51 UTC",
      "updated_date": "2025-05-16 18:37:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:40:21.539655"
    },
    {
      "arxiv_id": "2505.11618v1",
      "title": "Benchmarking Spatiotemporal Reasoning in LLMs and Reasoning Models: Capabilities and Challenges",
      "title_zh": "翻译失败",
      "authors": [
        "Pengrui Quan",
        "Brian Wang",
        "Kang Yang",
        "Liying Han",
        "Mani Srivastava"
      ],
      "abstract": "Spatiotemporal reasoning plays a key role in Cyber-Physical Systems (CPS).\nDespite advances in Large Language Models (LLMs) and Large Reasoning Models\n(LRMs), their capacity to reason about complex spatiotemporal signals remains\nunderexplored. This paper proposes a hierarchical SpatioTemporal reAsoning\nbenchmaRK, STARK, to systematically evaluate LLMs across three levels of\nreasoning complexity: state estimation (e.g., predicting field variables,\nlocalizing and tracking events in space and time), spatiotemporal reasoning\nover states (e.g., inferring spatial-temporal relationships), and\nworld-knowledge-aware reasoning that integrates contextual and domain knowledge\n(e.g., intent prediction, landmark-aware navigation). We curate 26 distinct\nspatiotemporal tasks with diverse sensor modalities, comprising 14,552\nchallenges where models answer directly or by Python Code Interpreter.\nEvaluating 3 LRMs and 8 LLMs, we find LLMs achieve limited success in tasks\nrequiring geometric reasoning (e.g., multilateration or triangulation),\nparticularly as complexity increases. Surprisingly, LRMs show robust\nperformance across tasks with various levels of difficulty, often competing or\nsurpassing traditional first-principle-based methods. Our results show that in\nreasoning tasks requiring world knowledge, the performance gap between LLMs and\nLRMs narrows, with some LLMs even surpassing LRMs. However, the LRM o3 model\ncontinues to achieve leading performance across all evaluated tasks, a result\nattributed primarily to the larger size of the reasoning models. STARK\nmotivates future innovations in model architectures and reasoning paradigms for\nintelligent CPS by providing a structured framework to identify limitations in\nthe spatiotemporal reasoning of LLMs and LRMs.",
      "tldr_zh": "这篇论文提出了 STARK 基准，用于系统评估大型语言模型 (LLMs) 和大型推理模型 (LRMs) 在时空推理方面的能力，涵盖三个层次：状态估计（如事件定位和跟踪）、时空关系推理（如推断空间-时间关系），以及世界知识aware推理（如意图预测）。研究通过 26 个多样化任务和 14,552 个挑战（涉及直接回答或 Python Code Interpreter）评估了 3 个 LRMs 和 8 个 LLMs，结果显示 LLMs 在复杂几何推理（如多边定位）上表现有限，尤其随难度增加，而 LRMs 表现出更强的稳健性，往往优于传统方法。总体而言，模型规模（如 LRM o3 模型）是关键因素，并在需要世界知识的任务中缩小了 LLMs 和 LRMs 的性能差距，为智能 Cyber-Physical Systems (CPS) 的模型架构和推理范式创新提供了指导。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11618v1",
      "published_date": "2025-05-16 18:32:35 UTC",
      "updated_date": "2025-05-16 18:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:40:34.183791"
    },
    {
      "arxiv_id": "2505.11615v1",
      "title": "Steering Risk Preferences in Large Language Models by Aligning Behavioral and Neural Representations",
      "title_zh": "通过对齐行为表示和神经表示引导大型语言模型中的风险偏好",
      "authors": [
        "Jian-Qiao Zhu",
        "Haijiang Yan",
        "Thomas L. Griffiths"
      ],
      "abstract": "Changing the behavior of large language models (LLMs) can be as\nstraightforward as editing the Transformer's residual streams using\nappropriately constructed \"steering vectors.\" These modifications to internal\nneural activations, a form of representation engineering, offer an effective\nand targeted means of influencing model behavior without retraining or\nfine-tuning the model. But how can such steering vectors be systematically\nidentified? We propose a principled approach for uncovering steering vectors by\naligning latent representations elicited through behavioral methods\n(specifically, Markov chain Monte Carlo with LLMs) with their neural\ncounterparts. To evaluate this approach, we focus on extracting latent risk\npreferences from LLMs and steering their risk-related outputs using the aligned\nrepresentations as steering vectors. We show that the resulting steering\nvectors successfully and reliably modulate LLM outputs in line with the\ntargeted behavior.",
      "tldr_zh": "本文提出一种系统方法，通过对齐行为表示和神经表示来识别steering vectors，从而引导大型语言模型(LLMs)的风险偏好(risk preferences)。具体而言，该方法利用Markov chain Monte Carlo与LLMs相结合，从行为层面提取潜在表示，并将其与Transformer的residual streams中的神经表示对齐，作为representation engineering的工具。实验结果显示，这种steering vectors能够可靠地调整LLMs的输出，使其符合目标行为，为模型行为控制提供了高效的非微调方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11615v1",
      "published_date": "2025-05-16 18:23:10 UTC",
      "updated_date": "2025-05-16 18:23:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:40:44.218127"
    },
    {
      "arxiv_id": "2505.11614v1",
      "title": "Using Reinforcement Learning to Train Large Language Models to Explain Human Decisions",
      "title_zh": "使用强化学习训练大型语言模型来解释人类决策",
      "authors": [
        "Jian-Qiao Zhu",
        "Hanbo Xie",
        "Dilip Arumugam",
        "Robert C. Wilson",
        "Thomas L. Griffiths"
      ],
      "abstract": "A central goal of cognitive modeling is to develop models that not only\npredict human behavior but also provide insight into the underlying cognitive\nmechanisms. While neural network models trained on large-scale behavioral data\noften achieve strong predictive performance, they typically fall short in\noffering interpretable explanations of the cognitive processes they capture. In\nthis work, we explore the potential of pretrained large language models (LLMs)\nto serve as dual-purpose cognitive models--capable of both accurate prediction\nand interpretable explanation in natural language. Specifically, we employ\nreinforcement learning with outcome-based rewards to guide LLMs toward\ngenerating explicit reasoning traces for explaining human risky choices. Our\nfindings demonstrate that this approach produces high-quality explanations\nalongside strong quantitative predictions of human decisions.",
      "tldr_zh": "本研究探讨如何利用大型语言模型(LLMs)作为双重目的认知模型，既准确预测人类行为，又提供可解释的自然语言解释。研究采用强化学习(reinforcement learning)结合基于结果奖励的方法，训练LLMs生成显式推理痕迹来解释人类风险决策。结果表明，这种方法不仅提升了解释的质量，还实现了强有力的定量预测性能。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11614v1",
      "published_date": "2025-05-16 18:22:05 UTC",
      "updated_date": "2025-05-16 18:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:40:56.213276"
    },
    {
      "arxiv_id": "2505.11612v1",
      "title": "Heart2Mind: Human-Centered Contestable Psychiatric Disorder Diagnosis System using Wearable ECG Monitors",
      "title_zh": "Heart2Mind：以人为中心、可争议的精神障碍诊断系统，使用可穿戴ECG监测器",
      "authors": [
        "Hung Nguyen",
        "Alireza Rahimi",
        "Veronica Whitford",
        "Hélène Fournier",
        "Irina Kondratova",
        "René Richard",
        "Hung Cao"
      ],
      "abstract": "Psychiatric disorders affect millions globally, yet their diagnosis faces\nsignificant challenges in clinical practice due to subjective assessments and\naccessibility concerns, leading to potential delays in treatment. To help\naddress this issue, we present Heart2Mind, a human-centered contestable\npsychiatric disorder diagnosis system using wearable electrocardiogram (ECG)\nmonitors. Our approach leverages cardiac biomarkers, particularly heart rate\nvariability (HRV) and R-R intervals (RRI) time series, as objective indicators\nof autonomic dysfunction in psychiatric conditions. The system comprises three\nkey components: (1) a Cardiac Monitoring Interface (CMI) for real-time data\nacquisition from Polar H9/H10 devices; (2) a Multi-Scale Temporal-Frequency\nTransformer (MSTFT) that processes RRI time series through integrated\ntime-frequency domain analysis; (3) a Contestable Diagnosis Interface (CDI)\ncombining Self-Adversarial Explanations (SAEs) with contestable Large Language\nModels (LLMs). Our MSTFT achieves 91.7% accuracy on the HRV-ACC dataset using\nleave-one-out cross-validation, outperforming state-of-the-art methods. SAEs\nsuccessfully detect inconsistencies in model predictions by comparing\nattention-based and gradient-based explanations, while LLMs enable clinicians\nto validate correct predictions and contest erroneous ones. This work\ndemonstrates the feasibility of combining wearable technology with Explainable\nArtificial Intelligence (XAI) and contestable LLMs to create a transparent,\ncontestable system for psychiatric diagnosis that maintains clinical oversight\nwhile leveraging advanced AI capabilities. Our implementation is publicly\navailable at: https://github.com/Analytics-Everywhere-Lab/heart2mind.",
      "tldr_zh": "本文提出 Heart2Mind 系统，这是一个以人为本的可质疑精神疾病诊断系统，利用可穿戴 ECG 监视器（如 Polar H9/H10）采集心率变异性 (HRV) 和 R-R 间隔 (RRI) 时间序列作为客观指标。系统包括 Cardiac Monitoring Interface (CMI) 用于实时数据获取、Multi-Scale Temporal-Frequency Transformer (MSTFT) 通过时间-频率域分析实现高精度诊断，以及 Contested Diagnosis Interface (CDI) 结合 Self-Adversarial Explanations (SAEs) 和 contestable Large Language Models (LLMs) 以检测预测不一致并允许临床医生验证或质疑结果。在 HRV-ACC 数据集上，MSTFT 达到了 91.7% 的准确率，优于现有方法，并展示了结合可穿戴技术、Explainable Artificial Intelligence (XAI) 和 contestable LLMs 的可行性，以提升诊断的透明度和临床监督。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "41 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11612v1",
      "published_date": "2025-05-16 18:21:08 UTC",
      "updated_date": "2025-05-16 18:21:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:41:11.565540"
    },
    {
      "arxiv_id": "2505.11611v1",
      "title": "Probing the Vulnerability of Large Language Models to Polysemantic Interventions",
      "title_zh": "翻译失败",
      "authors": [
        "Bofan Gong",
        "Shiyang Lai",
        "Dawn Song"
      ],
      "abstract": "Polysemanticity -- where individual neurons encode multiple unrelated\nfeatures -- is a well-known characteristic of large neural networks and remains\na central challenge in the interpretability of language models. At the same\ntime, its implications for model safety are also poorly understood. Leveraging\nrecent advances in sparse autoencoders, we investigate the polysemantic\nstructure of two small models (Pythia-70M and GPT-2-Small) and evaluate their\nvulnerability to targeted, covert interventions at the prompt, feature, token,\nand neuron levels. Our analysis reveals a consistent polysemantic topology\nshared across both models. Strikingly, we demonstrate that this structure can\nbe exploited to mount effective interventions on two larger, black-box\ninstruction-tuned models (LLaMA3.1-8B-Instruct and Gemma-2-9B-Instruct). These\nfindings suggest not only the generalizability of the interventions but also\npoint to a stable and transferable polysemantic structure that could\npotentially persist across architectures and training regimes.",
      "tldr_zh": "本研究探讨了大型语言模型对多义性干预（Polysemantic Interventions）的脆弱性，重点关注单个神经元编码多个不相关特征的现象。研究者利用稀疏自动编码器（sparse autoencoders）分析了Pythia-70M和GPT-2-Small两个小模型的多义结构，并在提示、特征、token和神经元层面评估了针对性干预。结果显示，这两个模型共享一致的多义拓扑，且这种结构可被利用来对更大模型如LLaMA3.1-8B-Instruct和Gemma-2-9B-Instruct进行有效干预，表明多义性在不同架构和训练方案中具有稳定性和可转移性，从而为模型安全提出潜在风险。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11611v1",
      "published_date": "2025-05-16 18:20:42 UTC",
      "updated_date": "2025-05-16 18:20:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:41:20.368397"
    },
    {
      "arxiv_id": "2505.11610v1",
      "title": "Foundation Models for AI-Enabled Biological Design",
      "title_zh": "翻译失败",
      "authors": [
        "Asher Moldwin",
        "Amarda Shehu"
      ],
      "abstract": "This paper surveys foundation models for AI-enabled biological design,\nfocusing on recent developments in applying large-scale, self-supervised models\nto tasks such as protein engineering, small molecule design, and genomic\nsequence design. Though this domain is evolving rapidly, this survey presents\nand discusses a taxonomy of current models and methods. The focus is on\nchallenges and solutions in adapting these models for biological applications,\nincluding biological sequence modeling architectures, controllability in\ngeneration, and multi-modal integration. The survey concludes with a discussion\nof open problems and future directions, offering concrete next-steps to improve\nthe quality of biological sequence generation.",
      "tldr_zh": "这篇论文调查了 foundation models 在 AI 启用生物设计中的应用，聚焦于大规模自监督模型在蛋白质工程、小分子设计和基因组序列设计等任务中的最新发展。论文呈现了当前模型和方法的 taxonomy，并讨论了适应这些模型的挑战及解决方案，包括生物序列建模架构、controllability in generation 和 multi-modal integration。最终，它探讨了 open problems 和 future directions，并提供了改进生物序列生成的具体下一步建议。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "q-bio.BM",
        "q-bio.GN"
      ],
      "primary_category": "cs.AI",
      "comment": "Published as part of the workshop proceedings at AAAI 2025 in the\n  workshop \"Foundation Models for Biological Discoveries\"",
      "pdf_url": "http://arxiv.org/pdf/2505.11610v1",
      "published_date": "2025-05-16 18:17:37 UTC",
      "updated_date": "2025-05-16 18:17:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:41:32.598457"
    },
    {
      "arxiv_id": "2505.11601v1",
      "title": "Continuous Optimization for Feature Selection with Permutation-Invariant Embedding and Policy-Guided Search",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Liu",
        "Rui Xie",
        "Zijun Yao",
        "Yanjie Fu",
        "Dongjie Wang"
      ],
      "abstract": "Feature selection removes redundant features to enhanc performance and\ncomputational efficiency in downstream tasks. Existing works often struggle to\ncapture complex feature interactions and adapt to diverse scenarios. Recent\nadvances in this domain have incorporated generative intelligence to address\nthese drawbacks by uncovering intricate relationships between features.\nHowever, two key limitations remain: 1) embedding feature subsets in a\ncontinuous space is challenging due to permutation sensitivity, as changes in\nfeature order can introduce biases and weaken the embedding learning process;\n2) gradient-based search in the embedding space assumes convexity, which is\nrarely guaranteed, leading to reduced search effectiveness and suboptimal\nsubsets. To address these limitations, we propose a new framework that can: 1)\npreserve feature subset knowledge in a continuous embedding space while\nensuring permutation invariance; 2) effectively explore the embedding space\nwithout relying on strong convex assumptions. For the first objective, we\ndevelop an encoder-decoder paradigm to preserve feature selection knowledge\ninto a continuous embedding space. This paradigm captures feature interactions\nthrough pairwise relationships within the subset, removing the influence of\nfeature order on the embedding. Moreover, an inducing point mechanism is\nintroduced to accelerate pairwise relationship computations. For the second\nobjective, we employ a policy-based reinforcement learning (RL) approach to\nguide the exploration of the embedding space. The RL agent effectively\nnavigates the space by balancing multiple objectives. By prioritizing\nhigh-potential regions adaptively and eliminating the reliance on convexity\nassumptions, the RL agent effectively reduces the risk of converging to local\noptima. Extensive experiments demonstrate the effectiveness, efficiency,\nrobustness and explicitness of our model.",
      "tldr_zh": "本论文提出了一种新的特征选择（feature selection）框架，旨在解决现有方法在捕捉复杂特征交互和适应多样场景时的局限性，特别是排列敏感性（permutation sensitivity）和非凸搜索问题。该框架通过编码器-解码器范式（encoder-decoder paradigm）将特征子集知识嵌入连续空间，确保排列不变性（permutation invariance），并利用成对关系（pairwise relationships）和诱导点机制（inducing point mechanism）加速计算。同时，采用基于策略的强化学习（policy-based reinforcement learning, RL）来引导搜索过程，平衡多目标并避免依赖凸性假设，从而有效探索高潜力区域。实验结果显示，该框架在有效性、效率、鲁棒性和显性（effectiveness, efficiency, robustness and explicitness）方面均优于基线模型。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "KDD 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11601v1",
      "published_date": "2025-05-16 18:08:16 UTC",
      "updated_date": "2025-05-16 18:08:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:41:45.222995"
    },
    {
      "arxiv_id": "2505.11595v1",
      "title": "Spectral Policy Optimization: Coloring your Incorrect Reasoning in GRPO",
      "title_zh": "翻译失败",
      "authors": [
        "Peter Chen",
        "Xiaopeng Li",
        "Ziniu Li",
        "Xi Chen",
        "Tianyi Lin"
      ],
      "abstract": "Reinforcement learning (RL) has demonstrated significant success in enhancing\nreasoning capabilities in large language models (LLMs). One of the most widely\nused RL methods is Group Relative Policy Optimization\n(GRPO)~\\cite{Shao-2024-Deepseekmath}, known for its memory efficiency and\nsuccess in training DeepSeek-R1~\\cite{Guo-2025-Deepseek}. However, GRPO stalls\nwhen all sampled responses in a group are incorrect -- referred to as an\n\\emph{all-negative-sample} group -- as it fails to update the policy, hindering\nlearning progress. The contributions of this paper are two-fold. First, we\npropose a simple yet effective framework that introduces response diversity\nwithin all-negative-sample groups in GRPO using AI feedback. We also provide a\ntheoretical analysis, via a stylized model, showing how this diversification\nimproves learning dynamics. Second, we empirically validate our approach,\nshowing the improved performance across various model sizes (7B, 14B, 32B) in\nboth offline and online learning settings with 10 benchmarks, including base\nand distilled variants. Our findings highlight that learning from\nall-negative-sample groups is not only feasible but beneficial, advancing\nrecent insights from \\citet{Xiong-2025-Minimalist}.",
      "tldr_zh": "本论文针对Group Relative Policy Optimization (GRPO) 在Reinforcement Learning (RL) 中的问题，提出Spectral Policy Optimization框架，通过AI反馈在all-negative-sample组中引入响应多样性，以解决策略更新停滞的问题。该框架结合了理论分析，展示了如何优化学习动态，并在7B、14B、32B模型上进行实证验证，涵盖10个基准测试的离线和在线设置，性能显著提升。研究结果证明，从all-negative-sample组中学习不仅可行，还能增强Large Language Models (LLMs)的推理能力，并推进相关领域的研究进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11595v1",
      "published_date": "2025-05-16 18:02:05 UTC",
      "updated_date": "2025-05-16 18:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:41:58.297448"
    },
    {
      "arxiv_id": "2505.11594v1",
      "title": "SageAttention3: Microscaling FP4 Attention for Inference and An Exploration of 8-Bit Training",
      "title_zh": "翻译失败",
      "authors": [
        "Jintao Zhang",
        "Jia Wei",
        "Pengle Zhang",
        "Xiaoming Xu",
        "Haofeng Huang",
        "Haoxu Wang",
        "Kai Jiang",
        "Jun Zhu",
        "Jianfei Chen"
      ],
      "abstract": "The efficiency of attention is important due to its quadratic time\ncomplexity. We enhance the efficiency of attention through two key\ncontributions: First, we leverage the new FP4 Tensor Cores in Blackwell GPUs to\naccelerate attention computation. Our implementation achieves 1038 TOPS on\nRTX5090, which is a 5x speedup over the fastest FlashAttention on RTX5090.\nExperiments show that our FP4 attention can accelerate inference of various\nmodels in a plug-and-play way. Second, we pioneer low-bit attention to training\ntasks. Existing low-bit attention works like FlashAttention3 and SageAttention\nfocus only on inference. However, the efficiency of training large models is\nalso important. To explore whether low-bit attention can be effectively applied\nto training tasks, we design an accurate and efficient 8-bit attention for both\nforward and backward propagation. Experiments indicate that 8-bit attention\nachieves lossless performance in fine-tuning tasks but exhibits slower\nconvergence in pretraining tasks. The code will be available at\nhttps://github.com/thu-ml/SageAttention.",
      "tldr_zh": "该论文提出 SageAttention3，通过微缩放 FP4 注意力机制提升注意力计算效率。首先，利用 Blackwell GPUs 中的 FP4 Tensor Cores 加速推理，在 RTX5090 上实现 1038 TOPS 的性能，比 FlashAttention 快 5 倍，并支持插件式应用于各种模型。其次，首次探索低位注意力在训练任务中的应用，设计了精确的 8-bit attention 用于前向和后向传播。实验结果显示，8-bit attention 在微调任务中保持无损性能，但在预训练任务中收敛较慢。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.PF"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11594v1",
      "published_date": "2025-05-16 18:01:54 UTC",
      "updated_date": "2025-05-16 18:01:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:42:08.046375"
    },
    {
      "arxiv_id": "2505.11586v1",
      "title": "The Ripple Effect: On Unforeseen Complications of Backdoor Attacks",
      "title_zh": "涟漪效应：关于后门攻击的不可预见并发症",
      "authors": [
        "Rui Zhang",
        "Yun Shen",
        "Hongwei Li",
        "Wenbo Jiang",
        "Hanxiao Chen",
        "Yuan Zhang",
        "Guowen Xu",
        "Yang Zhang"
      ],
      "abstract": "Recent research highlights concerns about the trustworthiness of third-party\nPre-Trained Language Models (PTLMs) due to potential backdoor attacks. These\nbackdoored PTLMs, however, are effective only for specific pre-defined\ndownstream tasks. In reality, these PTLMs can be adapted to many other\nunrelated downstream tasks. Such adaptation may lead to unforeseen consequences\nin downstream model outputs, consequently raising user suspicion and\ncompromising attack stealthiness. We refer to this phenomenon as backdoor\ncomplications. In this paper, we undertake the first comprehensive\nquantification of backdoor complications. Through extensive experiments using 4\nprominent PTLMs and 16 text classification benchmark datasets, we demonstrate\nthe widespread presence of backdoor complications in downstream models\nfine-tuned from backdoored PTLMs. The output distribution of triggered samples\nsignificantly deviates from that of clean samples. Consequently, we propose a\nbackdoor complication reduction method leveraging multi-task learning to\nmitigate complications without prior knowledge of downstream tasks. The\nexperimental results demonstrate that our proposed method can effectively\nreduce complications while maintaining the efficacy and consistency of backdoor\nattacks. Our code is available at\nhttps://github.com/zhangrui4041/Backdoor_Complications.",
      "tldr_zh": "该论文探讨了后门攻击(Backdoor Attacks)在预训练语言模型(PTLMs)中适配无关下游任务时，可能导致的意外并发症(Backdoor Complications)，如输出分布异常引发用户怀疑。研究者首次通过4个主要PTLMs和16个文本分类基准数据集的实验，量化证明了这种并发症的广泛存在。论文提出了一种基于多任务学习(Multi-Task Learning)的减少方法，无需事先知道下游任务，即可有效缓解并发症，同时维持后门攻击的效力和一致性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11586v1",
      "published_date": "2025-05-16 17:59:53 UTC",
      "updated_date": "2025-05-16 17:59:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:42:21.752958"
    },
    {
      "arxiv_id": "2505.11584v1",
      "title": "LLM Agents Are Hypersensitive to Nudges",
      "title_zh": "翻译失败",
      "authors": [
        "Manuel Cherep",
        "Pattie Maes",
        "Nikhil Singh"
      ],
      "abstract": "LLMs are being set loose in complex, real-world environments involving\nsequential decision-making and tool use. Often, this involves making choices on\nbehalf of human users. However, not much is known about the distribution of\nsuch choices, and how susceptible they are to different choice architectures.\nWe perform a case study with a few such LLM models on a multi-attribute tabular\ndecision-making problem, under canonical nudges such as the default option,\nsuggestions, and information highlighting, as well as additional prompting\nstrategies. We show that, despite superficial similarities to human choice\ndistributions, such models differ in subtle but important ways. First, they\nshow much higher susceptibility to the nudges. Second, they diverge in points\nearned, being affected by factors like the idiosyncrasy of available prizes.\nThird, they diverge in information acquisition strategies: e.g. incurring\nsubstantial cost to reveal too much information, or selecting without revealing\nany. Moreover, we show that simple prompt strategies like zero-shot chain of\nthought (CoT) can shift the choice distribution, and few-shot prompting with\nhuman data can induce greater alignment. Yet, none of these methods resolve the\nsensitivity of these models to nudges. Finally, we show how optimal nudges\noptimized with a human resource-rational model can similarly increase LLM\nperformance for some models. All these findings suggest that behavioral tests\nare needed before deploying models as agents or assistants acting on behalf of\nusers in complex environments.",
      "tldr_zh": "这篇论文研究了大型语言模型 (LLMs) 在复杂决策环境中作为代理时的行为，重点揭示它们对 nudges（如默认选项、建议和信息突出）的极高敏感性。研究通过多属性表格决策问题的案例分析，发现 LLMs 与人类选择分布虽有相似性，但更容易受 nudges 影响，导致收益点差异和信息获取策略不当（如过度或不获取信息）。此外，采用 zero-shot chain of thought (CoT) 或 few-shot 提示策略可以部分改变选择分布并提高模型与人类对齐，但无法解决对 nudges 的敏感问题。最终，论文建议使用优化 nudges 的方法（如基于人类资源理性模型）来提升 LLMs 性能，并强调在真实环境中部署这些模型前需进行行为测试。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "33 pages, 28 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11584v1",
      "published_date": "2025-05-16 17:53:05 UTC",
      "updated_date": "2025-05-16 17:53:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:42:33.305058"
    },
    {
      "arxiv_id": "2505.11485v1",
      "title": "Modeling cognitive processes of natural reading with transformer-based Language Models",
      "title_zh": "使用基于 Transformer 的语言模型建模自然阅读的认知过程",
      "authors": [
        "Bruno Bianchi",
        "Fermín Travi",
        "Juan E. Kamienkowski"
      ],
      "abstract": "Recent advances in Natural Language Processing (NLP) have led to the\ndevelopment of highly sophisticated language models for text generation. In\nparallel, neuroscience has increasingly employed these models to explore\ncognitive processes involved in language comprehension. Previous research has\nshown that models such as N-grams and LSTM networks can partially account for\npredictability effects in explaining eye movement behaviors, specifically Gaze\nDuration, during reading. In this study, we extend these findings by evaluating\ntransformer-based models (GPT2, LLaMA-7B, and LLaMA2-7B) to further investigate\nthis relationship. Our results indicate that these architectures outperform\nearlier models in explaining the variance in Gaze Durations recorded from\nRioplantense Spanish readers. However, similar to previous studies, these\nmodels still fail to account for the entirety of the variance captured by human\npredictability. These findings suggest that, despite their advancements,\nstate-of-the-art language models continue to predict language in ways that\ndiffer from human readers.",
      "tldr_zh": "本文研究使用 transformer-based 模型（如 GPT2、LLaMA-7B 和 LLaMA2-7B）来模拟自然阅读中的认知过程，扩展了先前基于 N-grams 和 LSTM 模型的发现，以解释眼动行为（如 Gaze Duration）的可预测性效果。结果显示，这些模型在分析 Rioplantense Spanish 读者的眼动数据时，比早期模型更好地解释了方差，但仍无法完全捕捉人类预测性的全部范围。总体而言，该研究表明 state-of-the-art 语言模型在预测语言方面与人类读者存在差异，为神经科学和 Natural Language Processing (NLP) 领域的交叉研究提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11485v1",
      "published_date": "2025-05-16 17:47:58 UTC",
      "updated_date": "2025-05-16 17:47:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:42:45.166108"
    },
    {
      "arxiv_id": "2505.15835v1",
      "title": "Transforming Decoder-Only Transformers for Accurate WiFi-Telemetry Based Indoor Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Nayan Sanjay Bhatia",
        "Katia Obraczka"
      ],
      "abstract": "Wireless Fidelity (WiFi) based indoor positioning is a widely researched area\nfor determining the position of devices within a wireless network. Accurate\nindoor location has numerous applications, such as asset tracking and indoor\nnavigation. Despite advances in WiFi localization techniques -- in particular\napproaches that leverage WiFi telemetry -- their adoption in practice remains\nlimited due to several factors including environmental changes that cause\nsignal fading, multipath effects, interference, which, in turn, impact\npositioning accuracy. In addition, telemetry data differs depending on the WiFi\ndevice vendor, offering distinct features and formats; use case requirements\ncan also vary widely. Currently, there is no unified model to handle all these\nvariations effectively. In this paper, we present WiFiGPT, a Generative\nPretrained Transformer (GPT) based system that is able to handle these\nvariations while achieving high localization accuracy. Our experiments with\nWiFiGPT demonstrate that GPTs, in particular Large Language Models (LLMs), can\neffectively capture subtle spatial patterns in noisy wireless telemetry, making\nthem reliable regressors. Compared to existing state-of-the-art methods, our\nmethod matches and often surpasses conventional approaches for multiple types\nof telemetry. Achieving sub-meter accuracy for RSSI and FTM and\ncentimeter-level precision for CSI demonstrates the potential of LLM-based\nlocalisation to outperform specialized techniques, all without handcrafted\nsignal processing or calibration.",
      "tldr_zh": "本文提出 WiFiGPT，一种基于 Generative Pretrained Transformer (GPT) 的系统，用于精确的 WiFi-遥测室内定位，旨在解决环境变化、信号衰减和多径效应等挑战，以及不同设备厂商的遥测数据差异。WiFiGPT 利用 Large Language Models (LLMs) 作为回归器，捕捉无线遥测中的微妙空间模式，提供统一的处理框架，而无需手动信号处理或校准。实验结果显示，该方法在 RSSI 和 FTM 上实现亚米级准确性，在 CSI 上达到厘米级精度，整体表现超越现有技术。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "11 pages, 2 figures, In Submission",
      "pdf_url": "http://arxiv.org/pdf/2505.15835v1",
      "published_date": "2025-05-16 17:47:32 UTC",
      "updated_date": "2025-05-16 17:47:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:42:57.822075"
    },
    {
      "arxiv_id": "2505.11481v1",
      "title": "MOSAAIC: Managing Optimization towards Shared Autonomy, Authority, and Initiative in Co-creation",
      "title_zh": "翻译失败",
      "authors": [
        "Alayt Issak",
        "Jeba Rezwana",
        "Casper Harteveld"
      ],
      "abstract": "Striking the appropriate balance between humans and co-creative AI is an open\nresearch question in computational creativity. Co-creativity, a form of hybrid\nintelligence where both humans and AI take action proactively, is a process\nthat leads to shared creative artifacts and ideas. Achieving a balanced dynamic\nin co-creativity requires characterizing control and identifying strategies to\ndistribute control between humans and AI. We define control as the power to\ndetermine, initiate, and direct the process of co-creation. Informed by a\nsystematic literature review of 172 full-length papers, we introduce MOSAAIC\n(Managing Optimization towards Shared Autonomy, Authority, and Initiative in\nCo-creation), a novel framework for characterizing and balancing control in\nco-creation. MOSAAIC identifies three key dimensions of control: autonomy,\ninitiative, and authority. We supplement our framework with control\noptimization strategies in co-creation. To demonstrate MOSAAIC's applicability,\nwe analyze the distribution of control in six existing co-creative AI case\nstudies and present the implications of using this framework.",
      "tldr_zh": "该论文探讨了在计算创造性中如何平衡人类与协同创造性 AI（co-creation）的控制问题，通过系统文献综述 172 篇论文，引入了 MOSAAIC 框架，用于表征和优化协同创造中的控制。MOSAAIC 将控制分为三个关键维度：autonomy（自治）、initiative（主动性）和 authority（权威），并提供了相应的控制优化策略。研究者通过分析六个现有协同创造性 AI 案例研究，展示了该框架的应用，并讨论了其在促进共享创造性动态方面的含义。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11481v1",
      "published_date": "2025-05-16 17:41:44 UTC",
      "updated_date": "2025-05-16 17:41:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:43:08.681300"
    },
    {
      "arxiv_id": "2505.11480v1",
      "title": "Improving Assembly Code Performance with Large Language Models via Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Anjiang Wei",
        "Tarun Suresh",
        "Huanmi Tan",
        "Yinglun Xu",
        "Gagandeep Singh",
        "Ke Wang",
        "Alex Aiken"
      ],
      "abstract": "Large language models (LLMs) have demonstrated strong performance across a\nwide range of programming tasks, yet their potential for code optimization\nremains underexplored. This work investigates whether LLMs can optimize the\nperformance of assembly code, where fine-grained control over execution enables\nimprovements that are difficult to express in high-level languages. We present\na reinforcement learning framework that trains LLMs using Proximal Policy\nOptimization (PPO), guided by a reward function that considers both functional\ncorrectness, validated through test cases, and execution performance relative\nto the industry-standard compiler gcc -O3. To support this study, we introduce\na benchmark of 8,072 real-world programs. Our model, Qwen2.5-Coder-7B-PPO,\nachieves 96.0% test pass rates and an average speedup of 1.47x over the gcc -O3\nbaseline, outperforming all 20 other models evaluated, including\nClaude-3.7-sonnet. These results indicate that reinforcement learning can\nunlock the potential of LLMs to serve as effective optimizers for assembly code\nperformance.",
      "tldr_zh": "本研究探索了Large Language Models (LLMs) 在优化汇编代码性能方面的潜力，提出了一种基于Reinforcement Learning的框架，使用Proximal Policy Optimization (PPO)算法训练LLMs，并通过奖励函数结合功能正确性和相对于gcc -O3的执行性能进行指导。研究引入了一个包含8,072个真实世界程序的基准数据集，以评估模型效果。结果显示，开发的模型Qwen2.5-Coder-7B-PPO实现了96.0%的测试通过率，并平均加速1.47倍于gcc -O3基准，优于其他20个模型，包括Claude-3.5-sonnet，这表明强化学习能有效提升LLMs作为汇编代码优化器的能力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.PF",
        "cs.PL",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11480v1",
      "published_date": "2025-05-16 17:40:45 UTC",
      "updated_date": "2025-05-16 17:40:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:43:21.223990"
    },
    {
      "arxiv_id": "2505.11478v1",
      "title": "Automatic Reward Shaping from Confounded Offline Data",
      "title_zh": "翻译失败",
      "authors": [
        "Mingxuan Li",
        "Junzhe Zhang",
        "Elias Bareinboim"
      ],
      "abstract": "A key task in Artificial Intelligence is learning effective policies for\ncontrolling agents in unknown environments to optimize performance measures.\nOff-policy learning methods, like Q-learning, allow learners to make optimal\ndecisions based on past experiences. This paper studies off-policy learning\nfrom biased data in complex and high-dimensional domains where \\emph{unobserved\nconfounding} cannot be ruled out a priori. Building on the well-celebrated Deep\nQ-Network (DQN), we propose a novel deep reinforcement learning algorithm\nrobust to confounding biases in observed data. Specifically, our algorithm\nattempts to find a safe policy for the worst-case environment compatible with\nthe observations. We apply our method to twelve confounded Atari games, and\nfind that it consistently dominates the standard DQN in all games where the\nobserved input to the behavioral and target policies mismatch and unobserved\nconfounders exist.",
      "tldr_zh": "本论文探讨了在存在未观察混杂（unobserved confounding）的复杂高维环境中，从偏置离线数据中学习有效策略的问题。作者基于 Deep Q-Network (DQN) 提出了一种新颖的深度强化学习算法，通过自动奖励塑造（Automatic Reward Shaping）来针对最坏情况环境（worst-case environment）找到安全的策略。该算法旨在增强 off-policy learning 的鲁棒性，减少混杂偏差的影响。在十二个 Atari 游戏的实验中，该方法在观察输入不匹配且存在未观察混杂器的场景下，一致优于标准 DQN，证明了其有效性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ICML 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11478v1",
      "published_date": "2025-05-16 17:40:01 UTC",
      "updated_date": "2025-05-16 17:40:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:43:32.605529"
    },
    {
      "arxiv_id": "2505.11475v1",
      "title": "HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages",
      "title_zh": "HelpSteer3-Preference：开放",
      "authors": [
        "Zhilin Wang",
        "Jiaqi Zeng",
        "Olivier Delalleau",
        "Hoo-Chang Shin",
        "Felipe Soares",
        "Alexander Bukharin",
        "Ellie Evans",
        "Yi Dong",
        "Oleksii Kuchaiev"
      ],
      "abstract": "Preference datasets are essential for training general-domain,\ninstruction-following language models with Reinforcement Learning from Human\nFeedback (RLHF). Each subsequent data release raises expectations for future\ndata collection, meaning there is a constant need to advance the quality and\ndiversity of openly available preference data. To address this need, we\nintroduce HelpSteer3-Preference, a permissively licensed (CC-BY-4.0),\nhigh-quality, human-annotated preference dataset comprising of over 40,000\nsamples. These samples span diverse real-world applications of large language\nmodels (LLMs), including tasks relating to STEM, coding and multilingual\nscenarios. Using HelpSteer3-Preference, we train Reward Models (RMs) that\nachieve top performance on RM-Bench (82.4%) and JudgeBench (73.7%). This\nrepresents a substantial improvement (~10% absolute) over the previously\nbest-reported results from existing RMs. We demonstrate HelpSteer3-Preference\ncan also be applied to train Generative RMs and how policy models can be\naligned with RLHF using our RMs. Dataset (CC-BY-4.0):\nhttps://huggingface.co/datasets/nvidia/HelpSteer3#preference",
      "tldr_zh": "本文介绍了 HelpSteer3-Preference，这是一个开源（CC-BY-4.0 许可）的人类标注偏好数据集，包含超过 40,000 个高质量样本，覆盖 STEM、编码和多语言等多样化任务，以支持训练通用指令跟随语言模型。使用该数据集训练的 Reward Models (RMs) 在 RM-Bench 上达到 82.4% 的表现，在 JudgeBench 上达到 73.7%，比之前最佳模型提高了约 10%。此外，该数据集可应用于训练 Generative RMs 并通过 Reinforcement Learning from Human Feedback (RLHF) 对齐策略模型，推动了语言模型训练的多样性和性能提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "38 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11475v1",
      "published_date": "2025-05-16 17:31:19 UTC",
      "updated_date": "2025-05-16 17:31:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:43:45.560045"
    },
    {
      "arxiv_id": "2505.11462v1",
      "title": "Disentangling Reasoning and Knowledge in Medical Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rahul Thapa",
        "Qingyang Wu",
        "Kevin Wu",
        "Harrison Zhang",
        "Angela Zhang",
        "Eric Wu",
        "Haotian Ye",
        "Suhana Bedi",
        "Nevin Aresh",
        "Joseph Boen",
        "Shriya Reddy",
        "Ben Athiwaratkun",
        "Shuaiwen Leon Song",
        "James Zou"
      ],
      "abstract": "Medical reasoning in large language models (LLMs) aims to emulate clinicians'\ndiagnostic thinking, but current benchmarks such as MedQA-USMLE, MedMCQA, and\nPubMedQA often mix reasoning with factual recall. We address this by separating\n11 biomedical QA benchmarks into reasoning- and knowledge-focused subsets using\na PubMedBERT classifier that reaches 81 percent accuracy, comparable to human\nperformance. Our analysis shows that only 32.8 percent of questions require\ncomplex reasoning. We evaluate biomedical models (HuatuoGPT-o1, MedReason, m1)\nand general-domain models (DeepSeek-R1, o4-mini, Qwen3), finding consistent\ngaps between knowledge and reasoning performance. For example, m1 scores 60.5\non knowledge but only 47.1 on reasoning. In adversarial tests where models are\nmisled with incorrect initial reasoning, biomedical models degrade sharply,\nwhile larger or RL-trained general models show more robustness. To address\nthis, we train BioMed-R1 using fine-tuning and reinforcement learning on\nreasoning-heavy examples. It achieves the strongest performance among similarly\nsized models. Further gains may come from incorporating clinical case reports\nand training with adversarial and backtracking scenarios.",
      "tldr_zh": "本文研究将医疗大型语言模型（LLMs）的推理和知识能力分开，使用 PubMedBERT 分类器将 11 个生物医学 QA 基准（如 MedQA-USMLE）分为推理和知识子集，准确率达 81%，并发现仅 32.8% 的问题需要复杂推理。评估结果显示，生物医学模型（如 HuatuoGPT-o1 和 m1）在知识任务上得分较高（如 m1 的 60.5），但在推理任务上显著落后（如 m1 的 47.1），且在对抗测试中易受误导，而通用模型（如 DeepSeek-R1）更具鲁棒性。为了改进，作者训练了 BioMed-R1 通过微调和强化学习，实现了类似规模模型的最佳性能，并建议通过纳入临床病例报告和对抗训练进一步提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11462v1",
      "published_date": "2025-05-16 17:16:27 UTC",
      "updated_date": "2025-05-16 17:16:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:43:57.721019"
    },
    {
      "arxiv_id": "2505.11454v1",
      "title": "HumaniBench: A Human-Centric Framework for Large Multimodal Models Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Shaina Raza",
        "Aravind Narayanan",
        "Vahid Reza Khazaie",
        "Ashmal Vayani",
        "Mukund S. Chettiar",
        "Amandeep Singh",
        "Mubarak Shah",
        "Deval Pandya"
      ],
      "abstract": "Large multimodal models (LMMs) now excel on many vision language benchmarks,\nhowever, they still struggle with human centered criteria such as fairness,\nethics, empathy, and inclusivity, key to aligning with human values. We\nintroduce HumaniBench, a holistic benchmark of 32K real-world image question\npairs, annotated via a scalable GPT4o assisted pipeline and exhaustively\nverified by domain experts. HumaniBench evaluates seven Human Centered AI\n(HCAI) principles: fairness, ethics, understanding, reasoning, language\ninclusivity, empathy, and robustness, across seven diverse tasks, including\nopen and closed ended visual question answering (VQA), multilingual QA, visual\ngrounding, empathetic captioning, and robustness tests. Benchmarking 15 state\nof the art LMMs (open and closed source) reveals that proprietary models\ngenerally lead, though robustness and visual grounding remain weak points. Some\nopen-source models also struggle to balance accuracy with adherence to\nhuman-aligned principles. HumaniBench is the first benchmark purpose built\naround HCAI principles. It provides a rigorous testbed for diagnosing alignment\ngaps and guiding LMMs toward behavior that is both accurate and socially\nresponsible. Dataset, annotation prompts, and evaluation code are available at:\nhttps://vectorinstitute.github.io/HumaniBench",
      "tldr_zh": "本文提出 HumaniBench，一种以人为中心的框架，用于评估大型多模态模型（LMMs）的公平性、伦理、移情和包容性等人类中心 AI（HCAI）原则。框架包含 32K 真实世界图像问题对，通过 GPT4o 辅助管道标注并由专家验证，涵盖七个任务如开放/封闭式视觉问答（VQA）、多语言 QA、视觉定位、移情标题和鲁棒性测试。基准测试 15 个最先进 LMMs 发现，专有模型整体领先但在鲁棒性和视觉定位上表现较弱，而开源模型在准确性和 HCAI 原则遵守之间存在平衡难题。HumaniBench 作为首个针对 HCAI 原则的基准，提供了一个严格的测试平台，帮助诊断 LMMs 的对齐问题并引导其向更准确和社交负责的方向发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11454v1",
      "published_date": "2025-05-16 17:09:44 UTC",
      "updated_date": "2025-05-16 17:09:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:44:11.399937"
    },
    {
      "arxiv_id": "2505.11451v1",
      "title": "Extracting Explainable Dates From Medical Images By Reverse-Engineering UNIX Timestamps",
      "title_zh": "翻译失败",
      "authors": [
        "Lee Harris",
        "James Bentham",
        "Philippe De Wilde"
      ],
      "abstract": "Dates often contribute towards highly impactful medical decisions, but it is\nrarely clear how to extract this data. AI has only just begun to be used\ntranscribe such documents, and common methods are either to trust that the\noutput produced by a complex AI model, or to parse the text using regular\nexpressions. Recent work has established that regular expressions are an\nexplainable form of logic, but it is difficult to decompose these into the\ncomponent parts that are required to construct precise UNIX timestamps. First,\nwe test publicly-available regular expressions, and we found that these were\nunable to capture a significant number of our dates. Next, we manually created\neasily-decomposable regular expressions, and we found that these were able to\ndetect the majority of real dates, but also a lot of sequences of text that\nlook like dates. Finally, we used regular expression synthesis to automatically\nidentify regular expressions from the reverse-engineered UNIX timestamps that\nwe created. We find that regular expressions created by regular expression\nsynthesis detect far fewer sequences of text that look like dates than those\nthat were manually created, at the cost of a slight increase to the number of\nmissed dates. Overall, our results show that regular expressions can be created\nthrough regular expression synthesis to identify complex dates and date ranges\nin text transcriptions. To our knowledge, our proposed way of learning\ndeterministic logic by reverse-engineering several many-one mappings and\nfeeding these into a regular expression synthesiser is a new approach.",
      "tldr_zh": "本文提出了一种新方法，通过反向工程UNIX timestamps从医疗图像中提取可解释的日期，以支持关键医疗决策。作者首先测试了现有regular expressions，发现其无法捕获许多日期；随后手动创建易分解的regular expressions，能检测大多数真实日期但也误识别许多假日期。最后，使用regular expression synthesis自动生成regular expressions，结果显示这些表达式显著减少了假日期检测，尽管略微增加了漏检日期。整体而言，这一方法通过学习确定性逻辑，提供了一种高效、可解释的日期提取途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11451v1",
      "published_date": "2025-05-16 17:07:14 UTC",
      "updated_date": "2025-05-16 17:07:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:44:21.690528"
    },
    {
      "arxiv_id": "2505.11582v1",
      "title": "Comparing Lexical and Semantic Vector Search Methods When Classifying Medical Documents",
      "title_zh": "翻译失败",
      "authors": [
        "Lee Harris",
        "Philippe De Wilde",
        "James Bentham"
      ],
      "abstract": "Classification is a common AI problem, and vector search is a typical\nsolution. This transforms a given body of text into a numerical representation,\nknown as an embedding, and modern improvements to vector search focus on\noptimising speed and predictive accuracy. This is often achieved through neural\nmethods that aim to learn language semantics. However, our results suggest that\nthese are not always the best solution. Our task was to classify\nrigidly-structured medical documents according to their content, and we found\nthat using off-the-shelf semantic vector search produced slightly worse\npredictive accuracy than creating a bespoke lexical vector search model, and\nthat it required significantly more time to execute. These findings suggest\nthat traditional methods deserve to be contenders in the information retrieval\ntoolkit, despite the prevalence and success of neural models.",
      "tldr_zh": "这篇论文比较了在医疗文档分类任务中，lexical vector search 和 semantic vector search 方法的性能。研究发现，使用自定义的 lexical vector search 模型比现成的 semantic vector search 方法能获得略高的预测准确性，同时显著减少执行时间。这些结果表明，尽管神经方法在学习语言语义方面很成功，传统 lexical 方法在信息检索工具包中仍值得考虑。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11582v1",
      "published_date": "2025-05-16 17:06:35 UTC",
      "updated_date": "2025-05-16 17:06:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:44:32.051100"
    },
    {
      "arxiv_id": "2505.11449v1",
      "title": "LLMs unlock new paths to monetizing exploits",
      "title_zh": "大型语言模型开启了利用漏洞变现的新路径",
      "authors": [
        "Nicholas Carlini",
        "Milad Nasr",
        "Edoardo Debenedetti",
        "Barry Wang",
        "Christopher A. Choquette-Choo",
        "Daphne Ippolito",
        "Florian Tramèr",
        "Matthew Jagielski"
      ],
      "abstract": "We argue that Large language models (LLMs) will soon alter the economics of\ncyberattacks. Instead of attacking the most commonly used software and\nmonetizing exploits by targeting the lowest common denominator among victims,\nLLMs enable adversaries to launch tailored attacks on a user-by-user basis. On\nthe exploitation front, instead of human attackers manually searching for one\ndifficult-to-identify bug in a product with millions of users, LLMs can find\nthousands of easy-to-identify bugs in products with thousands of users. And on\nthe monetization front, instead of generic ransomware that always performs the\nsame attack (encrypt all your data and request payment to decrypt), an\nLLM-driven ransomware attack could tailor the ransom demand based on the\nparticular content of each exploited device.\n  We show that these two attacks (and several others) are imminently practical\nusing state-of-the-art LLMs. For example, we show that without any human\nintervention, an LLM finds highly sensitive personal information in the Enron\nemail dataset (e.g., an executive having an affair with another employee) that\ncould be used for blackmail. While some of our attacks are still too expensive\nto scale widely today, the incentives to implement these attacks will only\nincrease as LLMs get cheaper. Thus, we argue that LLMs create a need for new\ndefense-in-depth approaches.",
      "tldr_zh": "该论文论证了大型语言模型（LLMs）将改变网络攻击的经济模式，使攻击者能够进行用户定制化的漏洞利用和货币化。相比传统攻击，LLMs 允许自动发现大量易于识别的漏洞，并针对特定设备内容（如勒索软件）量身定制攻击，例如在 Enron 邮件数据集上识别敏感信息用于勒索。研究通过实际演示证明这些攻击已具备可行性，尽管目前成本较高，但随着 LLMs 成本降低，攻击激励将增加。最终，论文呼吁开发新的防御深度策略以应对这些新兴威胁。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11449v1",
      "published_date": "2025-05-16 17:05:25 UTC",
      "updated_date": "2025-05-16 17:05:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:44:44.100015"
    },
    {
      "arxiv_id": "2505.11439v1",
      "title": "SurgPose: Generalisable Surgical Instrument Pose Estimation using Zero-Shot Learning and Stereo Vision",
      "title_zh": "翻译失败",
      "authors": [
        "Utsav Rai",
        "Haozheng Xu",
        "Stamatia Giannarou"
      ],
      "abstract": "Accurate pose estimation of surgical tools in Robot-assisted Minimally\nInvasive Surgery (RMIS) is essential for surgical navigation and robot control.\nWhile traditional marker-based methods offer accuracy, they face challenges\nwith occlusions, reflections, and tool-specific designs. Similarly, supervised\nlearning methods require extensive training on annotated datasets, limiting\ntheir adaptability to new tools. Despite their success in other domains,\nzero-shot pose estimation models remain unexplored in RMIS for pose estimation\nof surgical instruments, creating a gap in generalising to unseen surgical\ntools. This paper presents a novel 6 Degrees of Freedom (DoF) pose estimation\npipeline for surgical instruments, leveraging state-of-the-art zero-shot RGB-D\nmodels like the FoundationPose and SAM-6D. We advanced these models by\nincorporating vision-based depth estimation using the RAFT-Stereo method, for\nrobust depth estimation in reflective and textureless environments.\nAdditionally, we enhanced SAM-6D by replacing its instance segmentation module,\nSegment Anything Model (SAM), with a fine-tuned Mask R-CNN, significantly\nboosting segmentation accuracy in occluded and complex conditions. Extensive\nvalidation reveals that our enhanced SAM-6D surpasses FoundationPose in\nzero-shot pose estimation of unseen surgical instruments, setting a new\nbenchmark for zero-shot RGB-D pose estimation in RMIS. This work enhances the\ngeneralisability of pose estimation for unseen objects and pioneers the\napplication of RGB-D zero-shot methods in RMIS.",
      "tldr_zh": "本研究提出SurgPose，一种基于Zero-Shot Learning和Stereo Vision的通用手术工具姿态估计框架，旨在解决Robot-assisted Minimally Invasive Surgery (RMIS)中传统方法受遮挡、反射和数据标注限制的问题。该框架利用FoundationPose和SAM-6D等零-shot RGB-D模型，并整合RAFT-Stereo方法进行鲁棒深度估计，同时将SAM-6D的实例分割模块替换为微调后的Mask R-CNN，以提升复杂环境下的分割准确性。实验结果显示，增强版SAM-6D在零-shot姿态估计中超越FoundationPose，为RMIS中未见工具的6 DoF姿态估计设定新基准，并推动RGB-D零-shot方法的实际应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "To be published in 2025 International Conference on Robotics and\n  Automation (ICRA)",
      "pdf_url": "http://arxiv.org/pdf/2505.11439v1",
      "published_date": "2025-05-16 16:58:03 UTC",
      "updated_date": "2025-05-16 16:58:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:44:58.001809"
    },
    {
      "arxiv_id": "2505.11436v2",
      "title": "GODBench: A Benchmark for Multimodal Large Language Models in Video Comment Art",
      "title_zh": "翻译失败",
      "authors": [
        "Yiming Lei",
        "Chenkai Zhang",
        "Zeming Liu",
        "Haitao Leng",
        "Shaoguo Liu",
        "Tingting Gao",
        "Qingjie Liu",
        "Yunhong Wang"
      ],
      "abstract": "Video Comment Art enhances user engagement by providing creative content that\nconveys humor, satire, or emotional resonance, requiring a nuanced and\ncomprehensive grasp of cultural and contextual subtleties. Although Multimodal\nLarge Language Models (MLLMs) and Chain-of-Thought (CoT) have demonstrated\nstrong reasoning abilities in STEM tasks (e.g. mathematics and coding), they\nstill struggle to generate creative expressions such as resonant jokes and\ninsightful satire. Moreover, existing benchmarks are constrained by their\nlimited modalities and insufficient categories, hindering the exploration of\ncomprehensive creativity in video-based Comment Art creation. To address these\nlimitations, we introduce GODBench, a novel benchmark that integrates video and\ntext modalities to systematically evaluate MLLMs' abilities to compose Comment\nArt. Furthermore, inspired by the propagation patterns of waves in physics, we\npropose Ripple of Thought (RoT), a multi-step reasoning framework designed to\nenhance the creativity of MLLMs. Extensive experiments reveal that existing\nMLLMs and CoT methods still face significant challenges in understanding and\ngenerating creative video comments. In contrast, RoT provides an effective\napproach to improve creative composing, highlighting its potential to drive\nmeaningful advancements in MLLM-based creativity. GODBench is publicly\navailable at https://github.com/stan-lei/GODBench-ACL2025.",
      "tldr_zh": "本文提出 GODBench，这是一个整合视频和文本模态的新基准，用于系统评估 Multimodal Large Language Models (MLLMs) 在视频评论艺术（Video Comment Art）中的创意生成能力，特别是在处理幽默、讽刺和情感共鸣时。现有 MLLMs 和 Chain-of-Thought (CoT) 方法在 STEM 任务中表现出色，但仍难以捕捉文化与上下文的细微差别。受物理波传播启发的 Ripple of Thought (RoT) 框架被引入，作为一个多步推理机制来提升 MLLMs 的创意表达。实验结果显示，现有的模型在理解和生成创意视频评论方面存在显著挑战，而 RoT 有效改善了这些问题。GODBench 的资源已公开在 GitHub 上（https://github.com/stan-lei/GODBench-ACL2025）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "69 pages, 66 figures, accepted by ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11436v2",
      "published_date": "2025-05-16 16:56:40 UTC",
      "updated_date": "2025-05-21 15:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:45:09.997940"
    },
    {
      "arxiv_id": "2505.11427v1",
      "title": "Mergenetic: a Simple Evolutionary Model Merging Library",
      "title_zh": "Mergenetic：一个简单的进化模型合并库",
      "authors": [
        "Adrian Robert Minut",
        "Tommaso Mencattini",
        "Andrea Santilli",
        "Donato Crisostomi",
        "Emanuele Rodolà"
      ],
      "abstract": "Model merging allows combining the capabilities of existing models into a new\none - post hoc, without additional training. This has made it increasingly\npopular thanks to its low cost and the availability of libraries that support\nmerging on consumer GPUs. Recent work shows that pairing merging with\nevolutionary algorithms can boost performance, but no framework currently\nsupports flexible experimentation with such strategies in language models. We\nintroduce Mergenetic, an open-source library for evolutionary model merging.\nMergenetic enables easy composition of merging methods and evolutionary\nalgorithms while incorporating lightweight fitness estimators to reduce\nevaluation costs. We describe its design and demonstrate that Mergenetic\nproduces competitive results across tasks and languages using modest hardware.",
      "tldr_zh": "该论文引入了Mergenetic，一个简单的开源库，用于支持evolutionary model merging技术。该库允许用户轻松组合各种模型合并方法和evolutionary algorithms，同时整合轻量级fitness estimators，以降低评估成本并促进语言模型的灵活实验。实验结果显示，Mergenetic在多种任务和语言上，使用适度硬件取得了与现有方法竞争性的性能，从而为高效模型优化提供了实用工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "Link: https://github.com/tommasomncttn/mergenetic",
      "pdf_url": "http://arxiv.org/pdf/2505.11427v1",
      "published_date": "2025-05-16 16:43:23 UTC",
      "updated_date": "2025-05-16 16:43:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:45:20.966927"
    },
    {
      "arxiv_id": "2505.11424v1",
      "title": "Improving Object Detection Performance through YOLOv8: A Comprehensive Training and Evaluation Study",
      "title_zh": "翻译失败",
      "authors": [
        "Rana Poureskandar",
        "Shiva Razzagzadeh"
      ],
      "abstract": "This study evaluated the performance of a YOLOv8-based segmentation model for\ndetecting and segmenting wrinkles in facial images.",
      "tldr_zh": "本研究通过全面的训练和评估，探讨了使用 YOLOv8 改进物体检测性能的方法。\n具体而言，该论文评估了一个基于 YOLOv8 的分割模型，用于检测和分割面部图像中的皱纹。\n研究结果突出了该模型在提升检测准确性方面的潜力，为物体检测应用提供了参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11424v1",
      "published_date": "2025-05-16 16:38:01 UTC",
      "updated_date": "2025-05-16 16:38:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:45:33.455311"
    },
    {
      "arxiv_id": "2505.11417v1",
      "title": "EdgeWisePersona: A Dataset for On-Device User Profiling from Natural Language Interactions",
      "title_zh": "翻译失败",
      "authors": [
        "Patryk Bartkowiak",
        "Michal Podstawski"
      ],
      "abstract": "This paper introduces a novel dataset and evaluation benchmark designed to\nassess and improve small language models deployable on edge devices, with a\nfocus on user profiling from multi-session natural language interactions in\nsmart home environments. At the core of the dataset are structured user\nprofiles, each defined by a set of routines - context-triggered, repeatable\npatterns of behavior that govern how users interact with their home systems.\nUsing these profiles as input, a large language model (LLM) generates\ncorresponding interaction sessions that simulate realistic, diverse, and\ncontext-aware dialogues between users and their devices.\n  The primary task supported by this dataset is profile reconstruction:\ninferring user routines and preferences solely from interactions history. To\nassess how well current models can perform this task under realistic\nconditions, we benchmarked several state-of-the-art compact language models and\ncompared their performance against large foundation models. Our results show\nthat while small models demonstrate some capability in reconstructing profiles,\nthey still fall significantly short of large models in accurately capturing\nuser behavior. This performance gap poses a major challenge - particularly\nbecause on-device processing offers critical advantages, such as preserving\nuser privacy, minimizing latency, and enabling personalized experiences without\nreliance on the cloud. By providing a realistic, structured testbed for\ndeveloping and evaluating behavioral modeling under these constraints, our\ndataset represents a key step toward enabling intelligent, privacy-respecting\nAI systems that learn and adapt directly on user-owned devices.",
      "tldr_zh": "本论文介绍了EdgeWisePersona数据集及其评估基准，旨在评估和提升边缘设备上部署的小型语言模型（small language models），专注于从智能家居的多会话自然语言互动中进行用户画像（user profiling）。数据集的核心是结构化的用户画像，由触发式可重复行为模式（routines）组成，并利用大型语言模型（LLM）生成真实、多样且上下文感知的模拟对话会话，主要任务是通过互动历史重建用户习惯和偏好。基准测试结果显示，小型模型在画像重建方面表现出一定能力，但准确性远低于大型基础模型，这凸显了边缘设备处理在隐私保护、延迟最小化和个性化方面的优势。该数据集为在这些约束下开发智能、尊重隐私的AI系统提供了关键的测试平台。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11417v1",
      "published_date": "2025-05-16 16:29:21 UTC",
      "updated_date": "2025-05-16 16:29:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:45:45.504538"
    },
    {
      "arxiv_id": "2505.11416v1",
      "title": "MID-L: Matrix-Interpolated Dropout Layer with Layer-wise Neuron Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Pouya Shaeri",
        "Ariane Middel"
      ],
      "abstract": "Modern neural networks often activate all neurons for every input, leading to\nunnecessary computation and inefficiency. We introduce Matrix-Interpolated\nDropout Layer (MID-L), a novel module that dynamically selects and activates\nonly the most informative neurons by interpolating between two transformation\npaths via a learned, input-dependent gating vector. Unlike conventional dropout\nor static sparsity methods, MID-L employs a differentiable Top-k masking\nstrategy, enabling per-input adaptive computation while maintaining end-to-end\ndifferentiability. MID-L is model-agnostic and integrates seamlessly into\nexisting architectures. Extensive experiments on six benchmarks, including\nMNIST, CIFAR-10, CIFAR-100, SVHN, UCI Adult, and IMDB, show that MID-L achieves\nup to average 55\\% reduction in active neurons, 1.7$\\times$ FLOPs savings, and\nmaintains or exceeds baseline accuracy. We further validate the informativeness\nand selectivity of the learned neurons via Sliced Mutual Information (SMI) and\nobserve improved robustness under overfitting and noisy data conditions.\nAdditionally, MID-L demonstrates favorable inference latency and memory usage\nprofiles, making it suitable for both research exploration and deployment on\ncompute-constrained systems. These results position MID-L as a general-purpose,\nplug-and-play dynamic computation layer, bridging the gap between dropout\nregularization and efficient inference.",
      "tldr_zh": "本研究提出 MID-L（Matrix-Interpolated Dropout Layer），一种新型模块，通过输入相关的门控向量在两个变换路径间插值，并采用可微的 Top-k 掩码策略，动态选择并激活最有信息量的神经元，从而减少不必要的计算。MID-L 模型无关，可无缝集成到现有神经网络架构中，并在 MNIST、CIFAR-10 等六个基准上实现了平均 55% 的活跃神经元减少、1.7 倍 FLOPs 节省，同时保持或超过基线准确率。实验还通过 Sliced Mutual Information (SMI) 验证了 MID-L 的神经元选择性和鲁棒性，提升了在过拟合和噪声数据条件下的性能。总之，MID-L 作为一种通用即插即用的动态计算层，有效桥接了 dropout 正则化和高效推理需求。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Submitted in a Computer Science Conference, currently in Review",
      "pdf_url": "http://arxiv.org/pdf/2505.11416v1",
      "published_date": "2025-05-16 16:29:19 UTC",
      "updated_date": "2025-05-16 16:29:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:45:58.468182"
    },
    {
      "arxiv_id": "2505.11580v1",
      "title": "Flash Invariant Point Attention",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew Liu",
        "Axel Elaldi",
        "Nicholas T Franklin",
        "Nathan Russell",
        "Gurinder S Atwal",
        "Yih-En A Ban",
        "Olivia Viessmann"
      ],
      "abstract": "Invariant Point Attention (IPA) is a key algorithm for geometry-aware\nmodeling in structural biology, central to many protein and RNA models.\nHowever, its quadratic complexity limits the input sequence length. We\nintroduce FlashIPA, a factorized reformulation of IPA that leverages\nhardware-efficient FlashAttention to achieve linear scaling in GPU memory and\nwall-clock time with sequence length. FlashIPA matches or exceeds standard IPA\nperformance while substantially reducing computational costs. FlashIPA extends\ntraining to previously unattainable lengths, and we demonstrate this by\nre-training generative models without length restrictions and generating\nstructures of thousands of residues. FlashIPA is available at\nhttps://github.com/flagshippioneering/flash_ipa.",
      "tldr_zh": "本研究针对Invariant Point Attention (IPA) 在结构生物学中用于几何感知建模的关键算法，其二次复杂度导致输入序列长度受限的问题，引入了FlashIPA——一种因子化重构版本。FlashIPA 利用硬件高效的FlashAttention 技术，实现与序列长度线性缩放的 GPU 内存和计算时间，同时在性能上匹配或超过标准 IPA，并大幅降低计算成本。通过重新训练生成模型，FlashIPA 成功扩展到数千残基的结构生成，展示了其在蛋白和 RNA 模型训练中的潜力。开源代码可从 https://github.com/flagshippioneering/flash_ipa 获取。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11580v1",
      "published_date": "2025-05-16 16:19:05 UTC",
      "updated_date": "2025-05-16 16:19:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:46:08.247370"
    },
    {
      "arxiv_id": "2505.11409v1",
      "title": "Visual Planning: Let's Think Only with Images",
      "title_zh": "视觉规划：让我们只用图像来思考",
      "authors": [
        "Yi Xu",
        "Chengzu Li",
        "Han Zhou",
        "Xingchen Wan",
        "Caiqi Zhang",
        "Anna Korhonen",
        "Ivan Vulić"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) and their multimodal\nextensions (MLLMs) have substantially enhanced machine reasoning across diverse\ntasks. However, these models predominantly rely on pure text as the medium for\nboth expressing and structuring reasoning, even when visual information is\npresent. In this work, we argue that language may not always be the most\nnatural or effective modality for reasoning, particularly in tasks involving\nspatial and geometrical information. Motivated by this, we propose a new\nparadigm, Visual Planning, which enables planning through purely visual\nrepresentations, independent of text. In this paradigm, planning is executed\nvia sequences of images that encode step-by-step inference in the visual\ndomain, akin to how humans sketch or visualize future actions. We introduce a\nnovel reinforcement learning framework, Visual Planning via Reinforcement\nLearning (VPRL), empowered by GRPO for post-training large vision models,\nleading to substantial improvements in planning in a selection of\nrepresentative visual navigation tasks, FrozenLake, Maze, and MiniBehavior. Our\nvisual planning paradigm outperforms all other planning variants that conduct\nreasoning in the text-only space. Our results establish Visual Planning as a\nviable and promising alternative to language-based reasoning, opening new\navenues for tasks that benefit from intuitive, image-based inference.",
      "tldr_zh": "本研究批评现有Large Language Models (LLMs) 和Multimodal extensions (MLLMs) 过度依赖文本进行推理，尤其在涉及空间和几何信息的任务中。论文提出Visual Planning 范式，通过纯视觉表示（如图像序列）来执行步步推理，模仿人类草图式思考，并引入Visual Planning via Reinforcement Learning (VPRL) 框架，利用GRPO对大型视觉模型进行后训练。实验结果显示，该方法在FrozenLake、Maze 和MiniBehavior 等视觉导航任务上显著优于文本-only 推理，提升了规划性能。Visual Planning 作为一种直观图像-based 推理替代方案，为依赖视觉任务开辟了新路径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages, 6 figures, 1 table (26 pages, 12 figures, 8 tables\n  including references and appendices)",
      "pdf_url": "http://arxiv.org/pdf/2505.11409v1",
      "published_date": "2025-05-16 16:17:22 UTC",
      "updated_date": "2025-05-16 16:17:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:46:20.637444"
    },
    {
      "arxiv_id": "2505.11406v1",
      "title": "Large Language Model Use Impact Locus of Control",
      "title_zh": "翻译失败",
      "authors": [
        "Jenny Xiyu Fu",
        "Brennan Antone",
        "Kowe Kadoma",
        "Malte Jung"
      ],
      "abstract": "As AI tools increasingly shape how we write, they may also quietly reshape\nhow we perceive ourselves. This paper explores the psychological impact of\nco-writing with AI on people's locus of control. Through an empirical study\nwith 462 participants, we found that employment status plays a critical role in\nshaping users' reliance on AI and their locus of control. Current results\ndemonstrated that employed participants displayed higher reliance on AI and a\nshift toward internal control, while unemployed users tended to experience a\nreduction in personal agency. Through quantitative results and qualitative\nobservations, this study opens a broader conversation about AI's role in\nshaping personal agency and identity.",
      "tldr_zh": "本研究探讨了使用大型语言模型（Large Language Models）对人们控制点（locus of control）的心理影响，通过一项涉及462名参与者的实证研究发现，就业状态是关键因素。结果显示，雇员群体更依赖AI并表现出向内部控制的转变，而失业者则可能经历个人代理的减弱。该研究结合定量和定性分析，引发了对AI如何塑造个人代理和身份的更广泛讨论，并为AI工具的伦理应用提供了重要启示。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11406v1",
      "published_date": "2025-05-16 16:16:32 UTC",
      "updated_date": "2025-05-16 16:16:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:46:32.584236"
    },
    {
      "arxiv_id": "2505.11404v1",
      "title": "Patho-R1: A Multimodal Reinforcement Learning-Based Pathology Expert Reasoner",
      "title_zh": "翻译失败",
      "authors": [
        "Wenchuan Zhang",
        "Penghao Zhang",
        "Jingru Guo",
        "Tao Cheng",
        "Jie Chen",
        "Shuwan Zhang",
        "Zhang Zhang",
        "Yuhao Yi",
        "Hong Bu"
      ],
      "abstract": "Recent advances in vision language models (VLMs) have enabled broad progress\nin the general medical field. However, pathology still remains a more\nchallenging subdomain, with current pathology specific VLMs exhibiting\nlimitations in both diagnostic accuracy and reasoning plausibility. Such\nshortcomings are largely attributable to the nature of current pathology\ndatasets, which are primarily composed of image description pairs that lack the\ndepth and structured diagnostic paradigms employed by real world pathologists.\nIn this study, we leverage pathology textbooks and real world pathology experts\nto construct high-quality, reasoning-oriented datasets. Building on this, we\nintroduce Patho-R1, a multimodal RL-based pathology Reasoner, trained through a\nthree-stage pipeline: (1) continued pretraining on 3.5 million image-text pairs\nfor knowledge infusion; (2) supervised fine-tuning on 500k high-quality\nChain-of-Thought samples for reasoning incentivizing; (3) reinforcement\nlearning using Group Relative Policy Optimization and Decoupled Clip and\nDynamic sAmpling Policy Optimization strategies for multimodal reasoning\nquality refinement. To further assess the alignment quality of our dataset, we\npropose PathoCLIP, trained on the same figure-caption corpus used for continued\npretraining. Comprehensive experimental results demonstrate that both PathoCLIP\nand Patho-R1 achieve robust performance across a wide range of\npathology-related tasks, including zero-shot classification, cross-modal\nretrieval, Visual Question Answering, and Multiple Choice Question. Our project\nis available at the Patho-R1 repository:\nhttps://github.com/Wenchuan-Zhang/Patho-R1.",
      "tldr_zh": "该研究针对视觉语言模型（VLMs）在病理学领域的诊断准确性和推理合理性不足问题，构建了高质量的推理导向数据集，利用病理学教科书和专家知识。论文引入Patho-R1，一种基于多模态强化学习的病理学推理器，通过三阶段训练管道实现：（1）在350万图像-文本对上继续预训练注入知识；（2）在50万Chain-of-Thought样本上进行监督微调；（3）采用Group Relative Policy Optimization和Decoupled Clip and Dynamic sAmpling Policy Optimization策略进行强化学习以优化推理质量。同时，提出PathoCLIP用于评估数据集对齐质量。实验结果显示，Patho-R1和PathoCLIP在零样本分类、跨模态检索、Visual Question Answering和Multiple Choice Question等任务上表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11404v1",
      "published_date": "2025-05-16 16:12:50 UTC",
      "updated_date": "2025-05-16 16:12:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:46:45.674255"
    },
    {
      "arxiv_id": "2505.11365v2",
      "title": "Phare: A Safety Probe for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Pierre Le Jeune",
        "Benoît Malézieux",
        "Weixuan Xiao",
        "Matteo Dora"
      ],
      "abstract": "Ensuring the safety of large language models (LLMs) is critical for\nresponsible deployment, yet existing evaluations often prioritize performance\nover identifying failure modes. We introduce Phare, a multilingual diagnostic\nframework to probe and evaluate LLM behavior across three critical dimensions:\nhallucination and reliability, social biases, and harmful content generation.\nOur evaluation of 17 state-of-the-art LLMs reveals patterns of systematic\nvulnerabilities across all safety dimensions, including sycophancy, prompt\nsensitivity, and stereotype reproduction. By highlighting these specific\nfailure modes rather than simply ranking models, Phare provides researchers and\npractitioners with actionable insights to build more robust, aligned, and\ntrustworthy language systems.",
      "tldr_zh": "该研究引入了Phare，一种多语言诊断框架，用于评估大型语言模型(LLMs)的安全行为，重点关注hallucination and reliability、社会偏见(social biases)和有害内容生成(harmful content generation)三个关键维度。通过对17个最先进LLMs的评估，Phare揭示了系统性漏洞，包括sycophancy、prompt sensitivity和stereotype reproduction等模式。相比传统评估，Phare强调识别具体失败模式，提供可操作的见解，以帮助构建更稳健、对齐和可信的语言系统。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.CR"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11365v2",
      "published_date": "2025-05-16 15:31:08 UTC",
      "updated_date": "2025-05-19 09:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:46:56.392365"
    },
    {
      "arxiv_id": "2505.11340v1",
      "title": "DecompileBench: A Comprehensive Benchmark for Evaluating Decompilers in Real-World Scenarios",
      "title_zh": "DecompileBench：用于评估反编译器在真实世界场景的全面基准测试",
      "authors": [
        "Zeyu Gao",
        "Yuxin Cui",
        "Hao Wang",
        "Siliang Qin",
        "Yuanda Wang",
        "Bolun Zhang",
        "Chao Zhang"
      ],
      "abstract": "Decompilers are fundamental tools for critical security tasks, from\nvulnerability discovery to malware analysis, yet their evaluation remains\nfragmented. Existing approaches primarily focus on syntactic correctness\nthrough synthetic micro-benchmarks or subjective human ratings, failing to\naddress real-world requirements for semantic fidelity and analyst usability. We\npresent DecompileBench, the first comprehensive framework that enables\neffective evaluation of decompilers in reverse engineering workflows through\nthree key components: \\textit{real-world function extraction} (comprising\n23,400 functions from 130 real-world programs), \\textit{runtime-aware\nvalidation}, and \\textit{automated human-centric assessment} using LLM-as-Judge\nto quantify the effectiveness of decompilers in reverse engineering workflows.\nThrough a systematic comparison between six industrial-strength decompilers and\nsix recent LLM-powered approaches, we demonstrate that LLM-based methods\nsurpass commercial tools in code understandability despite 52.2% lower\nfunctionality correctness. These findings highlight the potential of LLM-based\napproaches to transform human-centric reverse engineering. We open source\n\\href{https://github.com/Jennieett/DecompileBench}{DecompileBench} to provide a\nframework to advance research on decompilers and assist security experts in\nmaking informed tool selections based on their specific requirements.",
      "tldr_zh": "本文提出 DecompileBench，一种全面基准框架，用于评估反编译器在真实世界逆向工程场景中的性能，包括从130个真实程序提取的23,400个函数、运行时感知验证(runtime-aware validation)以及使用LLM-as-Judge的自动化人类中心评估。相比现有方法，该框架强调语义保真度和分析师可用性，通过系统比较六种工业级反编译器和六种LLM-based方法，发现LLM方法在代码可理解性上优于商业工具，尽管功能正确性低52.2%。这些发现突出了LLM-based方法在逆向工程领域的潜力，并开源DecompileBench框架以推进相关研究和工具选择。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11340v1",
      "published_date": "2025-05-16 15:07:43 UTC",
      "updated_date": "2025-05-16 15:07:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:47:09.686004"
    },
    {
      "arxiv_id": "2505.11326v1",
      "title": "Temporally-Grounded Language Generation: A Benchmark for Real-Time Vision-Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Keunwoo Peter Yu",
        "Joyce Chai"
      ],
      "abstract": "Vision-language models (VLMs) have shown remarkable progress in offline tasks\nsuch as image captioning and video question answering. However, real-time\ninteractive environments impose new demands on VLMs, requiring them to generate\nutterances that are not only semantically accurate but also precisely timed. We\nidentify two core capabilities necessary for such settings --\n$\\textit{perceptual updating}$ and $\\textit{contingency awareness}$ -- and\npropose a new benchmark task, $\\textbf{Temporally-Grounded Language Generation\n(TGLG)}$, to evaluate them. TGLG requires models to generate utterances in\nresponse to streaming video such that both content and timing align with\ndynamic visual input. To support this benchmark, we curate evaluation datasets\nfrom sports broadcasting and egocentric human interaction domains, and\nintroduce a new metric, $\\textbf{TRACE}$, to evaluate TGLG by jointly measuring\nsemantic similarity and temporal alignment. Finally, we present\n$\\textbf{Vision-Language Model with Time-Synchronized Interleaving (VLM-TSI)}$,\na model that interleaves visual and linguistic tokens in a time-synchronized\nmanner, enabling real-time language generation without relying on turn-based\nassumptions. Experimental results show that VLM-TSI significantly outperforms a\nstrong baseline, yet overall performance remains modest -- highlighting the\ndifficulty of TGLG and motivating further research in real-time VLMs. Code and\ndata available $\\href{https://github.com/yukw777/tglg}{here}$.",
      "tldr_zh": "该研究探讨了视觉语言模型（VLMs）在实时交互环境中的挑战，提出一个新基准任务Temporally-Grounded Language Generation (TGLG)，用于评估模型的感知更新（perceptual updating）和偶然性意识（contingency awareness），要求生成与流式视频内容和时序精确对齐的表述。研究者从体育广播和第一人称人类互动领域构建了评估数据集，并引入了TRACE指标来联合衡量语义相似性和时间对齐。针对此任务，他们开发了Vision-Language Model with Time-Synchronized Interleaving (VLM-TSI)模型，通过时间同步交错视觉和语言标记，实现实时语言生成，并显著优于基线模型。实验结果显示，尽管VLM-TSI表现出色，但整体性能仍有提升空间，强调了实时VLMs研究的必要性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11326v1",
      "published_date": "2025-05-16 14:48:30 UTC",
      "updated_date": "2025-05-16 14:48:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:47:21.667233"
    },
    {
      "arxiv_id": "2505.11325v1",
      "title": "Uncertainty Quantification for Prior-Data Fitted Networks using Martingale Posteriors",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas Nagler",
        "David Rügamer"
      ],
      "abstract": "Prior-data fitted networks (PFNs) have emerged as promising foundation models\nfor prediction from tabular data sets, achieving state-of-the-art performance\non small to moderate data sizes without tuning. While PFNs are motivated by\nBayesian ideas, they do not provide any uncertainty quantification for\npredictive means, quantiles, or similar quantities. We propose a principled and\nefficient sampling procedure to construct Bayesian posteriors for such\nestimates based on Martingale posteriors, and prove its convergence. Several\nsimulated and real-world data examples showcase the uncertainty quantification\nof our method in inference applications.",
      "tldr_zh": "Prior-data fitted networks (PFNs) 是一种高效的表格数据预测基础模型，在小到中等规模数据集上表现出色，但缺乏对预测均值、分位数等不确定性量化的支持。作者提出了一种基于 Martingale posteriors 的采样方法，来构建这些估计的 Bayesian posteriors，并证明了其收敛性。该方法通过模拟和真实数据示例，展示了在推理应用中的有效不确定性量化能力，为 PFNs 的可靠性提升提供了新途径。",
      "categories": [
        "stat.ME",
        "cs.AI",
        "cs.LG",
        "stat.CO",
        "stat.ML"
      ],
      "primary_category": "stat.ME",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11325v1",
      "published_date": "2025-05-16 14:47:43 UTC",
      "updated_date": "2025-05-16 14:47:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:47:32.469168"
    },
    {
      "arxiv_id": "2505.11579v1",
      "title": "Toward Adaptive Categories: Dimensional Governance for Agentic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Zeynep Engin",
        "David Hand"
      ],
      "abstract": "As AI systems evolve from static tools to dynamic agents, traditional\ncategorical governance frameworks -- based on fixed risk tiers, levels of\nautonomy, or human oversight models -- are increasingly insufficient on their\nown. Systems built on foundation models, self-supervised learning, and\nmulti-agent architectures increasingly blur the boundaries that categories were\ndesigned to police. In this Perspective, we make the case for dimensional\ngovernance: a framework that tracks how decision authority, process autonomy,\nand accountability (the 3As) distribute dynamically across human-AI\nrelationships. A critical advantage of this approach is its ability to\nexplicitly monitor system movement toward and across key governance thresholds,\nenabling preemptive adjustments before risks materialize. This dimensional\napproach provides the necessary foundation for more adaptive categorization,\nenabling thresholds and classifications that can evolve with emerging\ncapabilities. While categories remain essential for decision-making, building\nthem upon dimensional foundations allows for context-specific adaptability and\nstakeholder-responsive governance that static approaches cannot achieve. We\noutline key dimensions, critical trust thresholds, and practical examples\nillustrating where rigid categorical frameworks fail -- and where a dimensional\nmindset could offer a more resilient and future-proof path forward for both\ngovernance and innovation at the frontier of artificial intelligence.",
      "tldr_zh": "本文提出 dimensional governance 框架，以应对 AI 系统从静态工具向 agentic AI 演变的挑战，该框架通过追踪 decision authority、process autonomy 和 accountability（the 3As）在人类-AI 关系中的动态分布，实现更灵活的治理。相较于传统固定分类方法，这种维度化方法能实时监控系统跨越关键信任阈值，并启用预先调整，防范潜在风险。最终，该框架为适应性分类提供基础，支持上下文特定的治理创新，并通过实际例子说明其在 AI 治理中的优势。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.CY",
      "comment": "12 pages core text, 14 pages including references, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11579v1",
      "published_date": "2025-05-16 14:43:12 UTC",
      "updated_date": "2025-05-16 14:43:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:47:45.664741"
    },
    {
      "arxiv_id": "2505.11578v2",
      "title": "Spatiotemporal Field Generation Based on Hybrid Mamba-Transformer with Physics-informed Fine-tuning",
      "title_zh": "基于混合 Mamba-Transformer 的时空场生成，结合物理信息指导的微调",
      "authors": [
        "Peimian Du",
        "Jiabin Liu",
        "Xiaowei Jin",
        "Mengwang Zuo",
        "Hui Li"
      ],
      "abstract": "This research confronts the challenge of substantial physical equation\ndiscrepancies encountered in the generation of spatiotemporal physical fields\nthrough data-driven trained models. A spatiotemporal physical field generation\nmodel, named HMT-PF, is developed based on the hybrid Mamba-Transformer\narchitecture, incorporating unstructured grid information as input. A\nfine-tuning block, enhanced with physical information, is introduced to\neffectively reduce the physical equation discrepancies. The physical equation\nresiduals are computed through a point query mechanism for efficient gradient\nevaluation, then encoded into latent space for refinement. The fine-tuning\nprocess employs a self-supervised learning approach to achieve physical\nconsistency while maintaining essential field characteristics. Results show\nthat the hybrid Mamba-Transformer model achieves good performance in generating\nspatiotemporal fields, while the physics-informed fine-tuning mechanism further\nreduces significant physical errors effectively. A MSE-R evaluation method is\ndeveloped to assess the accuracy and realism of physical field generation.",
      "tldr_zh": "该研究针对数据驱动模型在生成时空物理场时存在的物理方程差异问题，提出了一种基于混合 Mamba-Transformer 架构的 HMT-PF 模型，该模型以非结构化网格信息作为输入，并引入物理信息增强的微调块来减少差异。微调过程通过点查询机制计算物理方程残差，将其编码到潜在空间进行精炼，并采用自监督学习以实现物理一致性，同时保留关键场特性。实验结果显示，HMT-PF 模型在时空场生成方面表现出色，物理信息微调机制有效降低了物理错误，并通过开发的 MSE-R 评估方法验证了生成结果的准确性和真实性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.comp-ph"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11578v2",
      "published_date": "2025-05-16 14:40:56 UTC",
      "updated_date": "2025-05-21 17:36:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:47:57.080986"
    },
    {
      "arxiv_id": "2505.11311v1",
      "title": "Explaining Strategic Decisions in Multi-Agent Reinforcement Learning for Aerial Combat Tactics",
      "title_zh": "翻译失败",
      "authors": [
        "Ardian Selmonaj",
        "Alessandro Antonucci",
        "Adrian Schneider",
        "Michael Rüegsegger",
        "Matthias Sommer"
      ],
      "abstract": "Artificial intelligence (AI) is reshaping strategic planning, with\nMulti-Agent Reinforcement Learning (MARL) enabling coordination among\nautonomous agents in complex scenarios. However, its practical deployment in\nsensitive military contexts is constrained by the lack of explainability, which\nis an essential factor for trust, safety, and alignment with human strategies.\nThis work reviews and assesses current advances in explainability methods for\nMARL with a focus on simulated air combat scenarios. We proceed by adapting\nvarious explainability techniques to different aerial combat scenarios to gain\nexplanatory insights about the model behavior. By linking AI-generated tactics\nwith human-understandable reasoning, we emphasize the need for transparency to\nensure reliable deployment and meaningful human-machine interaction. By\nilluminating the crucial importance of explainability in advancing MARL for\noperational defense, our work supports not only strategic planning but also the\ntraining of military personnel with insightful and comprehensible analyses.",
      "tldr_zh": "这篇论文审阅了 Multi-Agent Reinforcement Learning (MARL) 在模拟空中作战场景中的可解释性方法，以解决其在军事应用中缺乏透明度的问题，从而提升信任、安全和与人类策略的兼容性。研究通过适应各种解释技术来分析 AI 生成的战术决策，并将这些决策与人类可理解的推理联系起来。结果表明，这种透明性方法不仅支持可靠的部署，还有助于战略规划和军事人员的培训。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "Published as a journal chapter in NATO Journal of Science and\n  Technology",
      "pdf_url": "http://arxiv.org/pdf/2505.11311v1",
      "published_date": "2025-05-16 14:36:30 UTC",
      "updated_date": "2025-05-16 14:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:48:08.821354"
    },
    {
      "arxiv_id": "2505.14707v1",
      "title": "CrypticBio: A Large Multimodal Dataset for Visually Confusing Biodiversity",
      "title_zh": "翻译失败",
      "authors": [
        "Georgiana Manolache",
        "Gerard Schouten",
        "Joaquin Vanschoren"
      ],
      "abstract": "We present CrypticBio, the largest publicly available multimodal dataset of\nvisually confusing species, specifically curated to support the development of\nAI models in the context of biodiversity applications. Visually confusing or\ncryptic species are groups of two or more taxa that are nearly\nindistinguishable based on visual characteristics alone. While much existing\nwork addresses taxonomic identification in a broad sense, datasets that\ndirectly address the morphological confusion of cryptic species are small,\nmanually curated, and target only a single taxon. Thus, the challenge of\nidentifying such subtle differences in a wide range of taxa remains\nunaddressed. Curated from real-world trends in species misidentification among\ncommunity annotators of iNaturalist, CrypticBio contains 52K unique cryptic\ngroups spanning 67K species, represented in 166 million images. Rich\nresearch-grade image annotations--including scientific, multicultural, and\nmultilingual species terminology, hierarchical taxonomy, spatiotemporal\ncontext, and associated cryptic groups--address multimodal AI in biodiversity\nresearch. For easy dataset curation, we provide an open-source pipeline\nCrypticBio-Curate. The multimodal nature of the dataset beyond vision-language\narises from the integration of geographical and temporal data as complementary\ncues to identifying cryptic species. To highlight the importance of the\ndataset, we benchmark a suite of state-of-the-art foundation models across\nCrypticBio subsets of common, unseen, endangered, and invasive species, and\ndemonstrate the substantial impact of geographical context on vision-language\nzero-shot learning for cryptic species. By introducing CrypticBio, we aim to\ncatalyze progress toward real-world-ready biodiversity AI models capable of\nhandling the nuanced challenges of species ambiguity.",
      "tldr_zh": "研究论文介绍了CrypticBio，这是一个最大的公开多模态数据集，专门针对视觉上难以区分的cryptic species（视觉混淆物种），旨在支持生物多样性AI模型的发展。该数据集从iNaturalist社区标注者的误识别趋势中整理，包含52K个独特cryptic群组、67K物种和1.66亿图像，并提供丰富的注释如科学术语、层级分类、时空上下文和开源管道CrypticBio-Curate，以便于数据集整理。实验基准测试显示，在常见、未见、濒危和入侵物种子集上，地理上下文显著提升了视觉语言零样本学习的性能，从而推动AI模型更好地处理物种模糊的实际挑战。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.MM",
      "comment": "We present CrypticBio, the largest publicly available multimodal\n  dataset of visually confusing species, specifically curated to support the\n  development of AI models for biodiversity identification using images,\n  language and spatiotemporal data",
      "pdf_url": "http://arxiv.org/pdf/2505.14707v1",
      "published_date": "2025-05-16 14:35:56 UTC",
      "updated_date": "2025-05-16 14:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:48:21.757853"
    },
    {
      "arxiv_id": "2505.11304v1",
      "title": "Heterogeneity-Aware Client Sampling: A Unified Solution for Consistent Federated Learning",
      "title_zh": "异质性感知客户端采样：一种用于一致联邦学习的统一解决方案",
      "authors": [
        "Shudi Weng",
        "Chao Ren",
        "Ming Xiao",
        "Mikael Skoglund"
      ],
      "abstract": "Federated learning (FL) commonly involves clients with diverse communication\nand computational capabilities. Such heterogeneity can significantly distort\nthe optimization dynamics and lead to objective inconsistency, where the global\nmodel converges to an incorrect stationary point potentially far from the\npursued optimum. Despite its critical impact, the joint effect of communication\nand computation heterogeneity has remained largely unexplored, due to the\nintrinsic complexity of their interaction. In this paper, we reveal the\nfundamentally distinct mechanisms through which heterogeneous communication and\ncomputation drive inconsistency in FL. To the best of our knowledge, this is\nthe first unified theoretical analysis of general heterogeneous FL, offering a\nprincipled understanding of how these two forms of heterogeneity jointly\ndistort the optimization trajectory under arbitrary choices of local solvers.\nMotivated by these insights, we propose Federated Heterogeneity-Aware Client\nSampling, FedACS, a universal method to eliminate all types of objective\ninconsistency. We theoretically prove that FedACS converges to the correct\noptimum at a rate of $O(1/\\sqrt{R})$, even in dynamic heterogeneous\nenvironments. Extensive experiments across multiple datasets show that FedACS\noutperforms state-of-the-art and category-specific baselines by 4.3%-36%, while\nreducing communication costs by 22%-89% and computation loads by 14%-105%,\nrespectively.",
      "tldr_zh": "本研究探讨了联邦学习(FL)中客户端的通信和计算异质性(heterogeneity)如何导致优化动态失真和目标不一致，并首次提供统一理论分析，揭示这些异质性对优化轨迹的联合影响。\n为此，论文提出Federated Heterogeneity-Aware Client Sampling (FedACS)方法，这是一种通用采样策略，能够消除所有类型的不一致问题。\n理论证明FedACS在动态异质环境中以O(1/√R)的收敛率达到正确最优，实验结果显示其在多个数据集上比现有基线提高4.3%-36%，同时减少通信成本22%-89%和计算负载14%-105%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11304v1",
      "published_date": "2025-05-16 14:31:36 UTC",
      "updated_date": "2025-05-16 14:31:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:48:34.288475"
    },
    {
      "arxiv_id": "2505.11577v1",
      "title": "The Accountability Paradox: How Platform API Restrictions Undermine AI Transparency Mandates",
      "title_zh": "问责悖论：平台 API 限制如何破坏 AI 透明度规定",
      "authors": [
        "Florian A. D. Burnat",
        "Brittany I. Davidson"
      ],
      "abstract": "Recent application programming interface (API) restrictions on major social\nmedia platforms challenge compliance with the EU Digital Services Act [20],\nwhich mandates data access for algorithmic transparency. We develop a\nstructured audit framework to assess the growing misalignment between\nregulatory requirements and platform implementations. Our comparative analysis\nof X/Twitter, Reddit, TikTok, and Meta identifies critical ``audit\nblind-spots'' where platform content moderation and algorithmic amplification\nremain inaccessible to independent verification. Our findings reveal an\n``accountability paradox'': as platforms increasingly rely on AI systems, they\nsimultaneously restrict the capacity for independent oversight. We propose\ntargeted policy interventions aligned with the AI Risk Management Framework of\nthe National Institute of Standards and Technology [80], emphasizing federated\naccess models and enhanced regulatory enforcement.",
      "tldr_zh": "该研究探讨了社交媒体平台的 API 限制如何挑战 EU Digital Services Act 的算法透明要求，导致“责任悖论”，即平台依赖 AI 系统却限制独立监督。作者开发了一个结构化的审计框架，对 X/Twitter、Reddit、TikTok 和 Meta 平台进行比较分析，识别出内容审查和算法放大的“审计盲点”。结果显示，这些盲点阻碍了外部验证，作者据此提出针对的政策干预，包括基于 NIST AI Risk Management Framework 的联邦访问模型和加强监管执行。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "I.2.0; E.0; K.4.1; K.4.2; K.4.3; K.5.0; K.5.2"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11577v1",
      "published_date": "2025-05-16 14:30:20 UTC",
      "updated_date": "2025-05-16 14:30:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:48:45.134236"
    },
    {
      "arxiv_id": "2505.11289v1",
      "title": "Meta-World+: An Improved, Standardized, RL Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Reginald McLean",
        "Evangelos Chatzaroulas",
        "Luc McCutcheon",
        "Frank Röder",
        "Tianhe Yu",
        "Zhanpeng He",
        "K. R. Zentner",
        "Ryan Julian",
        "J K Terry",
        "Isaac Woungang",
        "Nariman Farsad",
        "Pablo Samuel Castro"
      ],
      "abstract": "Meta-World is widely used for evaluating multi-task and meta-reinforcement\nlearning agents, which are challenged to master diverse skills simultaneously.\nSince its introduction however, there have been numerous undocumented changes\nwhich inhibit a fair comparison of algorithms. This work strives to\ndisambiguate these results from the literature, while also leveraging the past\nversions of Meta-World to provide insights into multi-task and\nmeta-reinforcement learning benchmark design. Through this process we release a\nnew open-source version of Meta-World\n(https://github.com/Farama-Foundation/Metaworld/) that has full reproducibility\nof past results, is more technically ergonomic, and gives users more control\nover the tasks that are included in a task set.",
      "tldr_zh": "本论文介绍了 Meta-World+，一个改进的标准化 RL 基准测试，用于评估多任务和 meta-reinforcement learning 代理。研究者针对 Meta-World 存在的未记录变更问题，澄清了文献中的结果，并通过分析过去版本提供了多任务 RL 基准设计的见解。新版本的开源实现（https://github.com/Farama-Foundation/Metaworld/）实现了完全可重现性、更简便的技术设计，以及用户对任务集的更大控制权。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11289v1",
      "published_date": "2025-05-16 14:24:03 UTC",
      "updated_date": "2025-05-16 14:24:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:48:57.388291"
    },
    {
      "arxiv_id": "2505.11277v1",
      "title": "Search and Refine During Think: Autonomous Retrieval-Augmented Reasoning of LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Yaorui Shi",
        "Shihan Li",
        "Chang Wu",
        "Zhiyuan Liu",
        "Junfeng Fang",
        "Hengxing Cai",
        "An Zhang",
        "Xiang Wang"
      ],
      "abstract": "Large language models have demonstrated impressive reasoning capabilities but\nare inherently limited by their knowledge reservoir. Retrieval-augmented\nreasoning mitigates this limitation by allowing LLMs to query external\nresources, but existing methods often retrieve irrelevant or noisy information,\nhindering accurate reasoning. In this paper, we propose AutoRefine, a\nreinforcement learning post-training framework that adopts a new\n``search-and-refine-during-think'' paradigm. AutoRefine introduces explicit\nknowledge refinement steps between successive search calls, enabling the model\nto iteratively filter, distill, and organize evidence before generating an\nanswer. Furthermore, we incorporate tailored retrieval-specific rewards\nalongside answer correctness rewards using group relative policy optimization.\nExperiments on single-hop and multi-hop QA benchmarks demonstrate that\nAutoRefine significantly outperforms existing approaches, particularly in\ncomplex, multi-hop reasoning scenarios. Detailed analysis shows that AutoRefine\nissues frequent, higher-quality searches and synthesizes evidence effectively.",
      "tldr_zh": "本研究针对大语言模型(LLMs)的知识限制和现有检索增强推理中无关信息干扰的问题，提出AutoRefine框架——一个基于强化学习的后训练方法，采用“search-and-refine-during-think”范式。该框架在连续搜索之间引入显式知识精炼步骤，让模型迭代过滤、提炼和组织证据，从而生成更准确的答案，并通过检索特定奖励和group relative policy optimization优化性能。实验在单跳和多跳QA基准上显示，AutoRefine显著优于现有方法，尤其在复杂多跳推理场景中提升了表现。详细分析表明，该框架能执行频繁、高质量的搜索并有效合成证据。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11277v1",
      "published_date": "2025-05-16 14:11:29 UTC",
      "updated_date": "2025-05-16 14:11:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:49:10.841861"
    },
    {
      "arxiv_id": "2505.11275v3",
      "title": "TCC-Bench: Benchmarking the Traditional Chinese Culture Understanding Capabilities of MLLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Pengju Xu",
        "Yan Wang",
        "Shuyuan Zhang",
        "Xuan Zhou",
        "Xin Li",
        "Yue Yuan",
        "Fengzhao Li",
        "Shunyuan Zhou",
        "Xingyu Wang",
        "Yi Zhang",
        "Haiying Zhao"
      ],
      "abstract": "Recent progress in Multimodal Large Language Models (MLLMs) have\nsignificantly enhanced the ability of artificial intelligence systems to\nunderstand and generate multimodal content. However, these models often exhibit\nlimited effectiveness when applied to non-Western cultural contexts, which\nraises concerns about their wider applicability. To address this limitation, we\npropose the Traditional Chinese Culture understanding Benchmark (TCC-Bench), a\nbilingual (i.e., Chinese and English) Visual Question Answering (VQA) benchmark\nspecifically designed for assessing the understanding of traditional Chinese\nculture by MLLMs. TCC-Bench comprises culturally rich and visually diverse\ndata, incorporating images from museum artifacts, everyday life scenes, comics,\nand other culturally significant contexts. We adopt a semi-automated pipeline\nthat utilizes GPT-4o in text-only mode to generate candidate questions,\nfollowed by human curation to ensure data quality and avoid potential data\nleakage. The benchmark also avoids language bias by preventing direct\ndisclosure of cultural concepts within question texts. Experimental evaluations\nacross a wide range of MLLMs demonstrate that current models still face\nsignificant challenges when reasoning about culturally grounded visual content.\nThe results highlight the need for further research in developing culturally\ninclusive and context-aware multimodal systems. The code and data can be found\nat: https://tcc-bench.github.io/.",
      "tldr_zh": "该研究提出TCC-Bench，一个双语（中英）Visual Question Answering (VQA)基准，用于评估Multimodal Large Language Models (MLLMs)对传统中国文化的理解能力，以解决这些模型在非西方文化语境中的局限性。TCC-Bench包含丰富的视觉数据，如博物馆文物、日常生活场景和漫画，通过半自动化管道利用GPT-4o生成候选问题，并由人类审核以确保质量和避免语言偏见。实验结果显示，当前MLLMs在处理文化相关视觉内容时仍面临重大挑战，这突显了开发文化包容性多模态系统的必要性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.MM",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.11275v3",
      "published_date": "2025-05-16 14:10:41 UTC",
      "updated_date": "2025-05-20 02:58:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:49:21.208046"
    },
    {
      "arxiv_id": "2505.11274v1",
      "title": "SelfBudgeter: Adaptive Token Allocation for Efficient LLM Reasoning",
      "title_zh": "SelfBudgeter：自适应令牌分配用于高效LLM推理",
      "authors": [
        "Zheng Li",
        "Qingxiu Dong",
        "Jingyuan Ma",
        "Di Zhang",
        "Zhifang Sui"
      ],
      "abstract": "Recently, large reasoning models demonstrate exceptional performance on\nvarious tasks. However, reasoning models inefficiently over-process both\ntrivial and complex queries, leading to resource waste and prolonged user\nlatency. To address this challenge, we propose SelfBudgeter - a self-adaptive\ncontrollable reasoning strategy for efficient reasoning. Our approach adopts a\ndual-phase training paradigm: first, the model learns to pre-estimate the\nreasoning cost based on the difficulty of the query. Then, we introduce\nbudget-guided GPRO for reinforcement learning, which effectively maintains\naccuracy while reducing output length. SelfBudgeter allows users to anticipate\ngeneration time and make informed decisions about continuing or interrupting\nthe process. Furthermore, our method enables direct manipulation of reasoning\nlength via pre-filling token budget. Experimental results demonstrate that\nSelfBudgeter can rationally allocate budgets according to problem complexity,\nachieving up to 74.47% response length compression on the MATH benchmark while\nmaintaining nearly undiminished accuracy.",
      "tldr_zh": "该研究提出SelfBudgeter，一种自适应token分配策略，用于提升LLM推理效率，解决模型在处理简单和复杂查询时过度计算的问题。该方法采用双阶段训练范式：首先，模型学习基于查询难度预估推理成本；其次，通过预算引导的GPRO强化学习来保持准确性同时减少输出长度。SelfBudgeter允许用户预估生成时间并控制推理长度，实验结果显示在MATH benchmark上实现高达74.47%的响应长度压缩，同时准确性几乎不受影响。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11274v1",
      "published_date": "2025-05-16 14:08:04 UTC",
      "updated_date": "2025-05-16 14:08:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:49:32.446207"
    },
    {
      "arxiv_id": "2505.11271v1",
      "title": "Semantic Caching of Contextual Summaries for Efficient Question-Answering with Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Camille Couturier",
        "Spyros Mastorakis",
        "Haiying Shen",
        "Saravan Rajmohan",
        "Victor Rühle"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly deployed across edge and cloud\nplatforms for real-time question-answering and retrieval-augmented generation.\nHowever, processing lengthy contexts in distributed systems incurs high\ncomputational overhead, memory usage, and network bandwidth. This paper\nintroduces a novel semantic caching approach for storing and reusing\nintermediate contextual summaries, enabling efficient information reuse across\nsimilar queries in LLM-based QA workflows. Our method reduces redundant\ncomputations by up to 50-60% while maintaining answer accuracy comparable to\nfull document processing, as demonstrated on NaturalQuestions, TriviaQA, and a\nsynthetic ArXiv dataset. This approach balances computational cost and response\nquality, critical for real-time AI assistants.",
      "tldr_zh": "这篇论文针对大型语言模型(LLMs)在问答(QA)任务中处理长上下文时的高计算开销、内存使用和网络带宽问题，提出了一种新型语义缓存(semantic caching)方法，用于存储和重用中间上下文摘要，从而实现信息在类似查询间的高效重用。  \n该方法可将冗余计算减少50-60%，同时保持答案准确性与完整文档处理相当，如在NaturalQuestions、TriviaQA和合成ArXiv数据集上的实验所示。  \n这种方法平衡了计算成本和响应质量，为实时AI助手的部署提供了关键优化。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Preprint. Paper accepted at ICCCN 2025, the final version will appear\n  in the proceedings",
      "pdf_url": "http://arxiv.org/pdf/2505.11271v1",
      "published_date": "2025-05-16 14:04:31 UTC",
      "updated_date": "2025-05-16 14:04:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:49:45.498004"
    },
    {
      "arxiv_id": "2505.11270v1",
      "title": "TAIJI: MCP-based Multi-Modal Data Analytics on Data Lakes",
      "title_zh": "翻译失败",
      "authors": [
        "Chao Zhang",
        "Shaolei Zhang",
        "Quehuan Liu",
        "Sibei Chen",
        "Tong Li",
        "Ju Fan"
      ],
      "abstract": "The variety of data in data lakes presents significant challenges for data\nanalytics, as data scientists must simultaneously analyze multi-modal data,\nincluding structured, semi-structured, and unstructured data. While Large\nLanguage Models (LLMs) have demonstrated promising capabilities, they still\nremain inadequate for multi-modal data analytics in terms of accuracy,\nefficiency, and freshness. First, current natural language (NL) or SQL-like\nquery languages may struggle to precisely and comprehensively capture users'\nanalytical intent. Second, relying on a single unified LLM to process diverse\ndata modalities often leads to substantial inference overhead. Third, data\nstored in data lakes may be incomplete or outdated, making it essential to\nintegrate external open-domain knowledge to generate timely and relevant\nanalytics results.\n  In this paper, we envision a new multi-modal data analytics system.\nSpecifically, we propose a novel architecture built upon the Model Context\nProtocol (MCP), an emerging paradigm that enables LLMs to collaborate with\nknowledgeable agents. First, we define a semantic operator hierarchy tailored\nfor querying multi-modal data in data lakes and develop an AI-agent-powered\nNL2Operator translator to bridge user intent and analytical execution. Next, we\nintroduce an MCP-based execution framework, in which each MCP server hosts\nspecialized foundation models optimized for specific data modalities. This\ndesign enhances both accuracy and efficiency, while supporting high scalability\nthrough modular deployment. Finally, we propose a updating mechanism by\nharnessing the deep research and machine unlearning techniques to refresh the\ndata lakes and LLM knowledges, with the goal of balancing the data freshness\nand inference efficiency.",
      "tldr_zh": "这篇论文针对数据湖中多模态数据分析的挑战（如结构化、半结构化和非结构化数据的处理），提出了一种基于 Model Context Protocol (MCP) 的新系统架构，以提升 Large Language Models (LLMs) 在准确性、效率和时效性方面的不足。论文定义了语义操作符层次结构，并开发了 AI-agent-powered NL2Operator 翻译器来精准捕捉用户意图并桥接分析执行，同时通过每个 MCP 服务器托管特定数据模态优化的基础模型，实现模块化部署和可扩展性。最后，该系统引入深度研究和机器无学习技术来更新数据湖和 LLM 知识，平衡数据新鲜度与推理效率。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11270v1",
      "published_date": "2025-05-16 14:03:30 UTC",
      "updated_date": "2025-05-16 14:03:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:49:58.549786"
    },
    {
      "arxiv_id": "2505.11267v1",
      "title": "Equal is Not Always Fair: A New Perspective on Hyperspectral Representation Non-Uniformity",
      "title_zh": "平等并不总是公平的：高光谱表示非均匀性的一种新视角",
      "authors": [
        "Wuzhou Quan",
        "Mingqiang Wei",
        "Jinhui Tang"
      ],
      "abstract": "Hyperspectral image (HSI) representation is fundamentally challenged by\npervasive non-uniformity, where spectral dependencies, spatial continuity, and\nfeature efficiency exhibit complex and often conflicting behaviors. Most\nexisting models rely on a unified processing paradigm that assumes homogeneity\nacross dimensions, leading to suboptimal performance and biased\nrepresentations. To address this, we propose FairHyp, a fairness-directed\nframework that explicitly disentangles and resolves the threefold\nnon-uniformity through cooperative yet specialized modules. We introduce a\nRunge-Kutta-inspired spatial variability adapter to restore spatial coherence\nunder resolution discrepancies, a multi-receptive field convolution module with\nsparse-aware refinement to enhance discriminative features while respecting\ninherent sparsity, and a spectral-context state space model that captures\nstable and long-range spectral dependencies via bidirectional Mamba scanning\nand statistical aggregation. Unlike one-size-fits-all solutions, FairHyp\nachieves dimension-specific adaptation while preserving global consistency and\nmutual reinforcement. This design is grounded in the view that non-uniformity\narises from the intrinsic structure of HSI representations, rather than any\nparticular task setting. To validate this, we apply FairHyp across four\nrepresentative tasks including classification, denoising, super-resolution, and\ninpaintin, demonstrating its effectiveness in modeling a shared structural\nflaw. Extensive experiments show that FairHyp consistently outperforms\nstate-of-the-art methods under varied imaging conditions. Our findings redefine\nfairness as a structural necessity in HSI modeling and offer a new paradigm for\nbalancing adaptability, efficiency, and fidelity in high-dimensional vision\ntasks.",
      "tldr_zh": "现有 hyperspectral image (HSI) 表示面临普遍的非均匀性问题，包括光谱依赖性、空间连续性和特征效率的冲突，现有的统一处理范式导致性能不佳和偏差。论文提出 FairHyp 框架，通过解耦三重非均匀性来实现公平性导向的处理，包括 Runge-Kutta-inspired spatial variability adapter 恢复空间连贯性、multi-receptive field convolution module with sparse-aware refinement 增强判别特征，以及 spectral-context state space model 通过双向 Mamba scanning 和统计聚合捕获长程光谱依赖。该框架强调维度特定适应，同时保持全局一致性，并在分类、去噪、超分辨率和修复等四个任务上验证其有效性，实验结果显示 FairHyp 在各种成像条件下优于最先进方法，并重新定义公平性为 HSI 建模的结构必要性，提供了一个平衡适应性、效率和保真度的全新范式。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11267v1",
      "published_date": "2025-05-16 14:00:11 UTC",
      "updated_date": "2025-05-16 14:00:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:50:09.966691"
    },
    {
      "arxiv_id": "2505.11576v1",
      "title": "Concept-Guided Interpretability via Neural Chunking",
      "title_zh": "翻译失败",
      "authors": [
        "Shuchen Wu",
        "Stephan Alaniz",
        "Shyamgopal Karthik",
        "Peter Dayan",
        "Eric Schulz",
        "Zeynep Akata"
      ],
      "abstract": "Neural networks are often black boxes, reflecting the significant challenge\nof understanding their internal workings. We propose a different perspective\nthat challenges the prevailing view: rather than being inscrutable, neural\nnetworks exhibit patterns in their raw population activity that mirror\nregularities in the training data. We refer to this as the Reflection\nHypothesis and provide evidence for this phenomenon in both simple recurrent\nneural networks (RNNs) and complex large language models (LLMs). Building on\nthis insight, we propose to leverage cognitively-inspired methods of chunking\nto segment high-dimensional neural population dynamics into interpretable units\nthat reflect underlying concepts. We propose three methods to extract these\nemerging entities, complementing each other based on label availability and\ndimensionality. Discrete sequence chunking (DSC) creates a dictionary of\nentities; population averaging (PA) extracts recurring entities that correspond\nto known labels; and unsupervised chunk discovery (UCD) can be used when labels\nare absent. We demonstrate the effectiveness of these methods in extracting\nentities across varying model sizes, ranging from inducing compositionality in\nRNNs to uncovering recurring neural population states in large models with\ndiverse architectures, and illustrate their advantage over other methods.\nThroughout, we observe a robust correspondence between the extracted entities\nand concrete or abstract concepts. Artificially inducing the extracted entities\nin neural populations effectively alters the network's generation of associated\nconcepts. Our work points to a new direction for interpretability, one that\nharnesses both cognitive principles and the structure of naturalistic data to\nreveal the hidden computations of complex learning systems, gradually\ntransforming them from black boxes into systems we can begin to understand.",
      "tldr_zh": "该论文提出 Reflection Hypothesis，认为神经网络的原始活动模式反映训练数据的规律性，并在 RNNs 和 LLMs 中提供证据。作者引入基于认知的 chunking 方法，包括 Discrete Sequence Chunking (DSC)、Population Averaging (PA) 和 Unsupervised Chunk Discovery (UCD)，用于将高维神经动态分割成可解释的实体，这些实体对应具体或抽象概念。实验结果显示，这些方法在各种模型大小上优于其他方法，能有效提取实体并通过诱导改变网络生成行为，从而为神经网络解释性提供新方向。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "35 pages, 32 figures. arXiv admin note: text overlap with\n  arXiv:2502.01803",
      "pdf_url": "http://arxiv.org/pdf/2505.11576v1",
      "published_date": "2025-05-16 13:49:43 UTC",
      "updated_date": "2025-05-16 13:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:50:21.737004"
    },
    {
      "arxiv_id": "2505.13508v1",
      "title": "Time-R1: Towards Comprehensive Temporal Reasoning in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zijia Liu",
        "Peixuan Han",
        "Haofei Yu",
        "Haoru Li",
        "Jiaxuan You"
      ],
      "abstract": "Large Language Models (LLMs) demonstrate impressive capabilities but lack\nrobust temporal intelligence, struggling to integrate reasoning about the past\nwith predictions and plausible generations of the future. Meanwhile, existing\nmethods typically target isolated temporal skills, such as question answering\nabout past events or basic forecasting, and exhibit poor generalization,\nparticularly when dealing with events beyond their knowledge cutoff or\nrequiring creative foresight. To address these limitations, we introduce\n\\textit{Time-R1}, the first framework to endow a moderate-sized (3B-parameter)\nLLM with comprehensive temporal abilities: understanding, prediction, and\ncreative generation. Our approach features a novel three-stage development\npath; the first two constitute a \\textit{reinforcement learning (RL)\ncurriculum} driven by a meticulously designed dynamic rule-based reward system.\nThis framework progressively builds (1) foundational temporal understanding and\nlogical event-time mappings from historical data, (2) future event prediction\nskills for events beyond its knowledge cutoff, and finally (3) enables\nremarkable generalization to creative future scenario generation without any\nfine-tuning. Strikingly, experiments demonstrate that Time-R1 outperforms\nmodels over 200 times larger, including the state-of-the-art 671B DeepSeek-R1,\non highly challenging future event prediction and creative scenario generation\nbenchmarks. This work provides strong evidence that thoughtfully engineered,\nprogressive RL fine-tuning allows smaller, efficient models to achieve superior\ntemporal performance, offering a practical and scalable path towards truly\ntime-aware AI. To foster further research, we also release \\textit{Time-Bench},\na large-scale multi-task temporal reasoning dataset derived from 10 years of\nnews data, and our series of \\textit{Time-R1} checkpoints.",
      "tldr_zh": "这篇论文介绍了 Time-R1 框架，旨在提升 Large Language Models (LLMs) 的全面时间推理能力，包括对过去事件的理解、未来事件的预测以及创造性生成，以解决现有方法在泛化性和知识截止点方面的局限性。Time-R1 通过一个三阶段强化学习 (RL) 课程设计，包括从历史数据构建基础时间理解和事件-时间映射、开发超出知识截止点的未来预测技能，以及无需进一步微调实现创造性场景生成。实验结果显示，该框架在 3B 参数规模的模型上，超越了 200 倍大的模型（如 671B DeepSeek-R1）在未来事件预测和场景生成基准上的性能。作者还发布了 Time-Bench 数据集和 Time-R1 检查点，提供可扩展的时间感知 AI 的实用路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13508v1",
      "published_date": "2025-05-16 13:46:28 UTC",
      "updated_date": "2025-05-16 13:46:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:50:34.056971"
    },
    {
      "arxiv_id": "2505.11247v1",
      "title": "LD-Scene: LLM-Guided Diffusion for Controllable Generation of Adversarial Safety-Critical Driving Scenarios",
      "title_zh": "翻译失败",
      "authors": [
        "Mingxing Peng",
        "Yuting Xie",
        "Xusen Guo",
        "Ruoyu Yao",
        "Hai Yang",
        "Jun Ma"
      ],
      "abstract": "Ensuring the safety and robustness of autonomous driving systems necessitates\na comprehensive evaluation in safety-critical scenarios. However, these\nsafety-critical scenarios are rare and difficult to collect from real-world\ndriving data, posing significant challenges to effectively assessing the\nperformance of autonomous vehicles. Typical existing methods often suffer from\nlimited controllability and lack user-friendliness, as extensive expert\nknowledge is essentially required. To address these challenges, we propose\nLD-Scene, a novel framework that integrates Large Language Models (LLMs) with\nLatent Diffusion Models (LDMs) for user-controllable adversarial scenario\ngeneration through natural language. Our approach comprises an LDM that\ncaptures realistic driving trajectory distributions and an LLM-based guidance\nmodule that translates user queries into adversarial loss functions,\nfacilitating the generation of scenarios aligned with user queries. The\nguidance module integrates an LLM-based Chain-of-Thought (CoT) code generator\nand an LLM-based code debugger, enhancing the controllability and robustness in\ngenerating guidance functions. Extensive experiments conducted on the nuScenes\ndataset demonstrate that LD-Scene achieves state-of-the-art performance in\ngenerating realistic, diverse, and effective adversarial scenarios.\nFurthermore, our framework provides fine-grained control over adversarial\nbehaviors, thereby facilitating more effective testing tailored to specific\ndriving scenarios.",
      "tldr_zh": "本文提出 LD-Scene 框架，通过整合 Large Language Models (LLMs) 和 Latent Diffusion Models (LDMs)，实现用户通过自然语言控制生成对抗性安全关键驾驶场景，从而解决自动驾驶系统评估中场景稀缺和可控性不足的问题。框架的核心包括一个 LDM 用于捕捉真实驾驶轨迹分布，以及一个 LLM-based 指导模块，将用户查询转化为对抗损失函数，并借助 Chain-of-Thought (CoT) 代码生成器和代码调试器提升生成过程的鲁棒性和可控性。在 nuScenes 数据集上的实验显示，LD-Scene 达到了最先进性能，生成真实、多样且有效的对抗场景，并提供细粒度控制以针对特定驾驶场景进行测试。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11247v1",
      "published_date": "2025-05-16 13:41:05 UTC",
      "updated_date": "2025-05-16 13:41:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:50:46.451836"
    },
    {
      "arxiv_id": "2505.11243v1",
      "title": "A Set-Sequence Model for Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Elliot L. Epstein",
        "Apaar Sadhwani",
        "Kay Giesecke"
      ],
      "abstract": "In many financial prediction problems, the behavior of individual units (such\nas loans, bonds, or stocks) is influenced by observable unit-level factors and\nmacroeconomic variables, as well as by latent cross-sectional effects.\nTraditional approaches attempt to capture these latent effects via handcrafted\nsummary features. We propose a Set-Sequence model that eliminates the need for\nhandcrafted features. The Set model first learns a shared cross-sectional\nsummary at each period. The Sequence model then ingests the summary-augmented\ntime series for each unit independently to predict its outcome. Both components\nare learned jointly over arbitrary sets sampled during training. Our approach\nharnesses the set nature of the cross-section and is computationally efficient,\ngenerating set summaries in linear time relative to the number of units. It is\nalso flexible, allowing the use of existing sequence models and accommodating a\nvariable number of units at inference. Empirical evaluations demonstrate that\nour Set-Sequence model significantly outperforms benchmarks on stock return\nprediction and mortgage behavior tasks. Code will be released.",
      "tldr_zh": "本论文提出了一种Set-Sequence模型，用于处理金融时间序列预测问题，该模型无需手工制作的总结特征，而是通过Set模型在每个时期学习共享的横截面总结。Sequence模型随后使用这些总结增强的时间序列，对每个单位的预测结果进行独立处理，两个组件在训练期间对任意集合进行联合学习。该方法利用横截面的集合性质，计算效率高（线性时间生成总结），并具有灵活性，可兼容现有序列模型和可变单位数量。实证评估显示，该模型在股票回报预测和抵押行为任务上显著优于基准，代码将发布。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-fin.CP",
        "I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the Workshop on Financial AI at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11243v1",
      "published_date": "2025-05-16 13:36:07 UTC",
      "updated_date": "2025-05-16 13:36:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:50:58.304404"
    },
    {
      "arxiv_id": "2505.11227v1",
      "title": "Is PRM Necessary? Problem-Solving RL Implicitly Induces PRM Capability in LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangying Feng",
        "Qianglong Chen",
        "Ning Lu",
        "Yongqian Li",
        "Siqi Cheng",
        "Shuangmu Peng",
        "Duyu Tang",
        "Shengcai Liu",
        "Zhirui Zhang"
      ],
      "abstract": "The development of reasoning capabilities represents a critical frontier in\nlarge language models (LLMs) research, where reinforcement learning (RL) and\nprocess reward models (PRMs) have emerged as predominant methodological\nframeworks. Contrary to conventional wisdom, empirical evidence from\nDeepSeek-R1 demonstrates that pure RL training focused on mathematical\nproblem-solving can progressively enhance reasoning abilities without PRM\nintegration, challenging the perceived necessity of process supervision. In\nthis study, we conduct a systematic investigation of the relationship between\nRL training and PRM capabilities. Our findings demonstrate that problem-solving\nproficiency and process supervision capabilities represent complementary\ndimensions of reasoning that co-evolve synergistically during pure RL training.\nIn particular, current PRMs underperform simple baselines like majority voting\nwhen applied to state-of-the-art models such as DeepSeek-R1 and QwQ-32B. To\naddress this limitation, we propose Self-PRM, an introspective framework in\nwhich models autonomously evaluate and rerank their generated solutions through\nself-reward mechanisms. Although Self-PRM consistently improves the accuracy of\nthe benchmark (particularly with larger sample sizes), analysis exposes\npersistent challenges: The approach exhibits low precision (<10\\%) on difficult\nproblems, frequently misclassifying flawed solutions as valid. These analyses\nunderscore the need for continued RL scaling to improve reward alignment and\nintrospective accuracy. Overall, our findings suggest that PRM may not be\nessential for enhancing complex reasoning, as pure RL not only improves\nproblem-solving skills but also inherently fosters robust PRM capabilities. We\nhope these findings provide actionable insights for building more reliable and\nself-aware complex reasoning models.",
      "tldr_zh": "本研究质疑了过程奖励模型（PRMs）在大型语言模型（LLMs）推理能力提升中的必要性，发现纯强化学习（RL）训练专注于问题解决时，能隐式诱导PRM能力，并在DeepSeek-R1模型上展示问题解决和过程监督能力的协同进化。作者通过系统调查比较了PRMs与简单基线（如多数投票），并提出Self-PRM框架，让模型通过自奖励机制自主评估和重新排序解决方案，从而提升基准准确性。实验结果显示Self-PRM在困难问题上精度较低（<10%），强调需要进一步扩展RL训练以改善奖励对齐，最终建议RL可作为构建可靠、自觉复杂推理模型的核心方法。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11227v1",
      "published_date": "2025-05-16 13:23:26 UTC",
      "updated_date": "2025-05-16 13:23:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:51:10.679514"
    },
    {
      "arxiv_id": "2505.11217v1",
      "title": "Seeing Sound, Hearing Sight: Uncovering Modality Bias and Conflict of AI models in Sound Localization",
      "title_zh": "视觉感知声音，听觉感知视觉：揭示AI模型在声音定位中的模态偏差和冲突",
      "authors": [
        "Yanhao Jia",
        "Ji Xie",
        "S Jivaganesh",
        "Hao Li",
        "Xu Wu",
        "Mengmi Zhang"
      ],
      "abstract": "Imagine hearing a dog bark and turning toward the sound only to see a parked\ncar, while the real, silent dog sits elsewhere. Such sensory conflicts test\nperception, yet humans reliably resolve them by prioritizing sound over\nmisleading visuals. Despite advances in multimodal AI integrating vision and\naudio, little is known about how these systems handle cross-modal conflicts or\nwhether they favor one modality. In this study, we systematically examine\nmodality bias and conflict resolution in AI sound localization. We assess\nleading multimodal models and benchmark them against human performance in\npsychophysics experiments across six audiovisual conditions, including\ncongruent, conflicting, and absent cues. Humans consistently outperform AI,\ndemonstrating superior resilience to conflicting or missing visuals by relying\non auditory information. In contrast, AI models often default to visual input,\ndegrading performance to near chance levels. To address this, we finetune a\nstate-of-the-art model using a stereo audio-image dataset generated via 3D\nsimulations. Even with limited training data, the refined model surpasses\nexisting benchmarks. Notably, it also mirrors human-like horizontal\nlocalization bias favoring left-right precision-likely due to the stereo audio\nstructure reflecting human ear placement. These findings underscore how sensory\ninput quality and system architecture shape multimodal representation accuracy.",
      "tldr_zh": "这篇论文探讨了AI模型在声音定位（sound localization）中的模态偏见（modality bias）和冲突问题，通过与人类在六种视听条件下（包括一致、冲突和缺失线索）的心理物理实验进行比较。研究发现，人类更依赖听觉信息，能够更好地处理冲突或缺失的视觉线索，而领先的多模态模型（multimodal models）往往优先视觉输入，导致性能降至接近随机水平。为此，作者使用3D模拟生成的数据集微调了最先进的模型，即使在有限训练数据下，该模型也超过了现有基准，并展现出类似于人类的水平定位偏见，可能源于立体音频结构。最终，这些发现强调了感知输入质量和系统架构对多模态表示准确性的关键作用。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CV",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "16 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11217v1",
      "published_date": "2025-05-16 13:13:25 UTC",
      "updated_date": "2025-05-16 13:13:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:51:22.468809"
    },
    {
      "arxiv_id": "2505.11211v1",
      "title": "Bayesian Hierarchical Invariant Prediction",
      "title_zh": "贝叶斯层次不变预测",
      "authors": [
        "Francisco Madaleno",
        "Pernille Julie Viuff Sand",
        "Francisco C. Pereira",
        "Sergio Hernan Garrido Mejia"
      ],
      "abstract": "We propose Bayesian Hierarchical Invariant Prediction (BHIP) reframing\nInvariant Causal Prediction (ICP) through the lens of Hierarchical Bayes. We\nleverage the hierarchical structure to explicitly test invariance of causal\nmechanisms under heterogeneous data, resulting in improved computational\nscalability for a larger number of predictors compared to ICP. Moreover, given\nits Bayesian nature BHIP enables the use of prior information. In this paper,\nwe test two sparsity inducing priors: horseshoe and spike-and-slab, both of\nwhich allow us a more reliable identification of causal features. We test BHIP\nin synthetic and real-world data showing its potential as an alternative\ninference method to ICP.",
      "tldr_zh": "本研究提出Bayesian Hierarchical Invariant Prediction (BHIP)，一种通过Hierarchical Bayes框架重新诠释Invariant Causal Prediction (ICP)的方法，利用分层结构来测试因果机制在异质数据下的不变性，并显著提升了处理大量预测变量的计算可扩展性。BHIP作为Bayesian方法，能够整合先验信息，包括horseshoe和spike-and-slab等稀疏性诱导先验，从而更可靠地识别因果特征。在合成和真实世界数据上的实验结果表明，BHIP作为ICP的替代方法，具有良好的潜在应用价值。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11211v1",
      "published_date": "2025-05-16 13:06:25 UTC",
      "updated_date": "2025-05-16 13:06:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:51:33.644027"
    },
    {
      "arxiv_id": "2505.11208v1",
      "title": "GLOVA: Global and Local Variation-Aware Analog Circuit Design with Risk-Sensitive Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dongjun Kim",
        "Junwoo Park",
        "Chaehyeon Shin",
        "Jaeheon Jung",
        "Kyungho Shin",
        "Seungheon Baek",
        "Sanghyuk Heo",
        "Woongrae Kim",
        "Inchul Jeong",
        "Joohwan Cho",
        "Jongsun Park"
      ],
      "abstract": "Analog/mixed-signal circuit design encounters significant challenges due to\nperformance degradation from process, voltage, and temperature (PVT)\nvariations. To achieve commercial-grade reliability, iterative manual design\nrevisions and extensive statistical simulations are required. While several\nstudies have aimed to automate variation aware analog design to reduce\ntime-to-market, the substantial mismatches in real-world wafers have not been\nthoroughly addressed. In this paper, we present GLOVA, an analog circuit sizing\nframework that effectively manages the impact of diverse random mismatches to\nimprove robustness against PVT variations. In the proposed approach,\nrisk-sensitive reinforcement learning is leveraged to account for the\nreliability bound affected by PVT variations, and ensemble-based critic is\nintroduced to achieve sample-efficient learning. For design verification, we\nalso propose $\\mu$-$\\sigma$ evaluation and simulation reordering method to\nreduce simulation costs of identifying failed designs. GLOVA supports\nverification through industrial-level PVT variation evaluation methods,\nincluding corner simulation as well as global and local Monte Carlo (MC)\nsimulations. Compared to previous state-of-the-art variation-aware analog\nsizing frameworks, GLOVA achieves up to 80.5$\\times$ improvement in sample\nefficiency and 76.0$\\times$ reduction in time.",
      "tldr_zh": "本论文针对模拟/混合信号电路设计中因过程、电压和温度 (PVT variations) 变化导致的性能退化问题，提出 GLOVA 框架，以自动化设计并提升鲁棒性。GLOVA 采用风险敏感强化学习 (risk-sensitive reinforcement learning) 和 ensemble-based critic 方法来处理可靠性边界和样本效率，同时引入 $\\mu$-$\\sigma$ 评估及模拟重新排序技术，以降低模拟成本并支持工业级验证，如 corner simulation 和 global/local Monte Carlo (MC) simulations。实验结果显示，与现有框架相比，GLOVA 实现了高达 80.5 倍的样本效率提升和 76.0 倍的时间减少。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.ET",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted for DAC 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11208v1",
      "published_date": "2025-05-16 13:05:45 UTC",
      "updated_date": "2025-05-16 13:05:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:51:46.481215"
    },
    {
      "arxiv_id": "2505.11204v1",
      "title": "RanDeS: Randomized Delta Superposition for Multi-Model Compression",
      "title_zh": "翻译失败",
      "authors": [
        "Hangyu Zhou",
        "Aaron Gokaslan",
        "Volodymyr Kuleshov",
        "Bharath Hariharan"
      ],
      "abstract": "From a multi-model compression perspective, model merging enables\nmemory-efficient serving of multiple models fine-tuned from the same base, but\nsuffers from degraded performance due to interference among their task-specific\nparameter adjustments (i.e., deltas). In this paper, we reformulate model\nmerging as a compress-and-retrieve scheme, revealing that the task interference\narises from the summation of irrelevant deltas during model retrieval. To\naddress this issue, we use random orthogonal transformations to decorrelate\nthese vectors into self-cancellation. We show that this approach drastically\nreduces interference, improving performance across both vision and language\ntasks. Since these transformations are fully defined by random seeds, adding\nnew models requires no extra memory. Further, their data- and model-agnostic\nnature enables easy addition or removal of models with minimal compute\noverhead, supporting efficient and flexible multi-model serving.",
      "tldr_zh": "该论文提出RanDeS，一种随机Delta叠加方法，用于解决多模型压缩中的模型合并问题，该问题源于任务特定参数调整(deltas)间的干扰导致性能下降。方法通过随机正交变换(random orthogonal transformations)来使deltas去相关化，实现自取消(self-cancellation)，从而减少干扰并提升模型检索效率。实验结果显示，该方法在视觉和语言任务上显著提高了性能，且由于变换仅依赖随机种子，添加或移除模型无需额外内存，支持高效灵活的多模型服务。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "https://github.com/Zhou-Hangyu/randes",
      "pdf_url": "http://arxiv.org/pdf/2505.11204v1",
      "published_date": "2025-05-16 13:02:12 UTC",
      "updated_date": "2025-05-16 13:02:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:51:58.017065"
    },
    {
      "arxiv_id": "2505.11200v1",
      "title": "Audio Turing Test: Benchmarking the Human-likeness of Large Language Model-based Text-to-Speech Systems in Chinese",
      "title_zh": "翻译失败",
      "authors": [
        "Xihuai Wang",
        "Ziyi Zhao",
        "Siyu Ren",
        "Shao Zhang",
        "Song Li",
        "Xiaoyu Li",
        "Ziwen Wang",
        "Lin Qiu",
        "Guanglu Wan",
        "Xuezhi Cao",
        "Xunliang Cai",
        "Weinan Zhang"
      ],
      "abstract": "Recent advances in large language models (LLMs) have significantly improved\ntext-to-speech (TTS) systems, enhancing control over speech style, naturalness,\nand emotional expression, which brings TTS Systems closer to human-level\nperformance. Although the Mean Opinion Score (MOS) remains the standard for TTS\nSystem evaluation, it suffers from subjectivity, environmental inconsistencies,\nand limited interpretability. Existing evaluation datasets also lack a\nmulti-dimensional design, often neglecting factors such as speaking styles,\ncontext diversity, and trap utterances, which is particularly evident in\nChinese TTS evaluation. To address these challenges, we introduce the Audio\nTuring Test (ATT), a multi-dimensional Chinese corpus dataset ATT-Corpus paired\nwith a simple, Turing-Test-inspired evaluation protocol. Instead of relying on\ncomplex MOS scales or direct model comparisons, ATT asks evaluators to judge\nwhether a voice sounds human. This simplification reduces rating bias and\nimproves evaluation robustness. To further support rapid model development, we\nalso finetune Qwen2-Audio-Instruct with human judgment data as Auto-ATT for\nautomatic evaluation. Experimental results show that ATT effectively\ndifferentiates models across specific capability dimensions using its\nmulti-dimensional design. Auto-ATT also demonstrates strong alignment with\nhuman evaluations, confirming its value as a fast and reliable assessment tool.\nThe white-box ATT-Corpus and Auto-ATT can be found in ATT Hugging Face\nCollection\n(https://huggingface.co/collections/meituan/audio-turing-test-682446320368164faeaf38a4).",
      "tldr_zh": "本文提出 Audio Turing Test (ATT)，一个多维度的中文语料数据集 ATT-Corpus 和基于图灵测试的简单评估协议，用于基准测试基于 Large Language Models (LLMs) 的 Text-to-Speech (TTS) 系统的类人程度，解决了 Mean Opinion Score (MOS) 的主观性和可解释性问题。ATT 要求评估者判断语音是否听起来像人类，从而减少偏差并提高鲁棒性，同时微调 Qwen2-Audio-Instruct 作为 Auto-ATT 用于自动评估。实验结果显示，ATT 能有效区分模型在特定能力维度的表现，而 Auto-ATT 与人类评估高度一致，提供了一个快速可靠的评估工具。该框架及其资源已在 Hugging Face 上公开，促进 TTS 系统的发展。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2505.11200v1",
      "published_date": "2025-05-16 12:57:23 UTC",
      "updated_date": "2025-05-16 12:57:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:52:11.762133"
    },
    {
      "arxiv_id": "2505.11198v1",
      "title": "User-centric Music Recommendations",
      "title_zh": "用户中心的音乐推荐",
      "authors": [
        "Jaime Ramirez Castillo",
        "M. Julia Flores",
        "Ann E. Nicholson"
      ],
      "abstract": "This work presents a user-centric recommendation framework, designed as a\npipeline with four distinct, connected, and customizable phases. These phases\nare intended to improve explainability and boost user engagement.\n  We have collected the historical Last.fm track playback records of a single\nuser over approximately 15 years. The collected dataset includes more than\n90,000 playbacks and approximately 14,000 unique tracks.\n  From track playback records, we have created a dataset of user temporal\ncontexts (each row is a specific moment when the user listened to certain music\ndescriptors). As music descriptors, we have used community-contributed Last.fm\ntags and Spotify audio features. They represent the music that, throughout\nyears, the user has been listening to.\n  Next, given the most relevant Last.fm tags of a moment (e.g. the hour of the\nday), we predict the Spotify audio features that best fit the user preferences\nin that particular moment. Finally, we use the predicted audio features to find\ntracks similar to these features. The final aim is to recommend (and discover)\ntracks that the user may feel like listening to at a particular moment.\n  For our initial study case, we have chosen to predict only a single audio\nfeature target: danceability. The framework, however, allows to include more\ntarget variables.\n  The ability to learn the musical habits from a single user can be quite\npowerful, and this framework could be extended to other users.",
      "tldr_zh": "这篇论文提出了一种用户中心音乐推荐框架，由四个相连且可定制的阶段组成，旨在提升推荐的可解释性和用户参与度。研究者收集了单个用户的15年Last.fm播放记录，涵盖超过90,000次播放和14,000个独特曲目，并创建了用户时间上下文数据集，使用Last.fm标签和Spotify音频特征作为音乐描述符。框架通过预测特定时刻的音频特征（如danceability），来推荐与用户偏好相似的曲目；初步研究仅针对danceability，但可扩展到更多变量和用户，以学习个人音乐习惯。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted for the 16th Bayesian Modelling Applications Workshop\n  (@UAI2022) (BMAW 2022)",
      "pdf_url": "http://arxiv.org/pdf/2505.11198v1",
      "published_date": "2025-05-16 12:56:40 UTC",
      "updated_date": "2025-05-16 12:56:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:52:22.168377"
    },
    {
      "arxiv_id": "2505.11192v3",
      "title": "FALCON: False-Negative Aware Learning of Contrastive Negatives in Vision-Language Pretraining",
      "title_zh": "翻译失败",
      "authors": [
        "Myunsoo Kim",
        "Seong-Woong Shim",
        "Byung-Jun Lee"
      ],
      "abstract": "False negatives pose a critical challenge in vision-language pretraining\n(VLP) due to the many-to-many correspondence between images and texts in\nlarge-scale datasets. These false negatives introduce conflicting supervision\nsignals that degrade the learned embedding space and diminish the effectiveness\nof hard negative sampling. In this paper, we propose FALCON (False-negative\nAware Learning of COntrastive Negatives), a learning-based mini-batch\nconstruction strategy that adaptively balances the trade-off between hard and\nfalse negatives during VLP. Rather than relying on fixed heuristics, FALCON\nemploys a negative mining scheduler that dynamically selects negative samples\nof appropriate hardness for each anchor instance during mini-batch\nconstruction, guided by a proxy for cross-modal alignment improvement.\nExperimental results demonstrate that FALCON significantly improves performance\nacross two widely adopted VLP frameworks (ALBEF, BLIP-2) and a broad range of\ndownstream tasks and evaluation settings, underscoring its effectiveness and\nrobustness in mitigating the impact of false negatives.",
      "tldr_zh": "该研究针对视觉语言预训练 (VLP) 中假负样本 (false negatives) 问题——由于图像和文本的多对多对应导致监督信号冲突和嵌入空间劣化——提出了一种基于学习的 mini-batch 构建策略 FALCON。FALCON 通过负样本挖掘调度器 (negative mining scheduler) 动态选择适当硬度的负样本，并在构建过程中基于跨模态对齐改进的代理实现硬负样本与假负样本的自适应平衡。实验结果显示，FALCON 显著提升了 ALBEF 和 BLIP-2 等框架在多种下游任务和评估设置中的性能，证明了其在缓解假负样本影响方面的有效性和鲁棒性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11192v3",
      "published_date": "2025-05-16 12:50:05 UTC",
      "updated_date": "2025-05-20 03:33:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:52:34.753964"
    },
    {
      "arxiv_id": "2505.11191v1",
      "title": "Multi-Modal Multi-Task (M3T) Federated Foundation Models for Embodied AI: Potentials and Challenges for Edge Integration",
      "title_zh": "多模态多任务 (M3T) 联邦基础模型用于具身 AI：边缘集成的潜力",
      "authors": [
        "Kasra Borazjani",
        "Payam Abdisarabshali",
        "Fardis Nadimi",
        "Naji Khosravan",
        "Minghui Liwang",
        "Xianbin Wang",
        "Yiguang Hong",
        "Seyyedali Hosseinalipour"
      ],
      "abstract": "As embodied AI systems become increasingly multi-modal, personalized, and\ninteractive, they must learn effectively from diverse sensory inputs, adapt\ncontinually to user preferences, and operate safely under resource and privacy\nconstraints. These challenges expose a pressing need for machine learning\nmodels capable of swift, context-aware adaptation while balancing model\ngeneralization and personalization. Here, two methods emerge as suitable\ncandidates, each offering parts of these capabilities: Foundation Models (FMs)\nprovide a pathway toward generalization across tasks and modalities, whereas\nFederated Learning (FL) offers the infrastructure for distributed,\nprivacy-preserving model updates and user-level model personalization. However,\nwhen used in isolation, each of these approaches falls short of meeting the\ncomplex and diverse capability requirements of real-world embodied\nenvironments. In this vision paper, we introduce Federated Foundation Models\n(FFMs) for embodied AI, a new paradigm that unifies the strengths of\nmulti-modal multi-task (M3T) FMs with the privacy-preserving distributed nature\nof FL, enabling intelligent systems at the wireless edge. We collect critical\ndeployment dimensions of FFMs in embodied AI ecosystems under a unified\nframework, which we name \"EMBODY\": Embodiment heterogeneity, Modality richness\nand imbalance, Bandwidth and compute constraints, On-device continual learning,\nDistributed control and autonomy, and Yielding safety, privacy, and\npersonalization. For each, we identify concrete challenges and envision\nactionable research directions. We also present an evaluation framework for\ndeploying FFMs in embodied AI systems, along with the associated trade-offs.",
      "tldr_zh": "这篇论文探讨了Embodied AI系统在处理多模态输入、适应用户偏好以及资源和隐私约束下的挑战，提出Federated Foundation Models (FFMs)作为一种新范式，将多模态多任务(M3T) Foundation Models (FMs)的泛化能力与Federated Learning (FL)的隐私保护分布式学习相结合。论文引入了“EMBODY”框架，涵盖了Embodiment heterogeneity、Modality richness and imbalance、Bandwidth and compute constraints、On-device continual learning、Distributed control and autonomy，以及Yielding safety, privacy, and personalization等部署维度，并针对每个维度识别具体挑战和研究方向。最后，论文呈现了一个评估框架，用于分析FFMs在Embodied AI系统中的部署权衡和潜在益处。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 3 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.11191v1",
      "published_date": "2025-05-16 12:49:36 UTC",
      "updated_date": "2025-05-16 12:49:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:52:47.577970"
    },
    {
      "arxiv_id": "2505.11189v1",
      "title": "Can Global XAI Methods Reveal Injected Bias in LLMs? SHAP vs Rule Extraction vs RuleSHAP",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Sovrano"
      ],
      "abstract": "Generative AI systems can help spread information but also misinformation and\nbiases, potentially undermining the UN Sustainable Development Goals (SDGs).\nExplainable AI (XAI) aims to reveal the inner workings of AI systems and expose\nmisbehaviours or biases. However, current XAI tools, built for simpler models,\nstruggle to handle the non-numerical nature of large language models (LLMs).\nThis paper examines the effectiveness of global XAI methods, such as\nrule-extraction algorithms and SHAP, in detecting bias in LLMs. To do so, we\nfirst show a text-to-ordinal mapping strategy to convert non-numerical\ninputs/outputs into numerical features, enabling these tools to identify (some)\nmisinformation-related biases in LLM-generated content. Then, we inject\nnon-linear biases of varying complexity (univariate, conjunctive, and\nnon-convex) into widespread LLMs like ChatGPT and Llama via system\ninstructions, using global XAI methods to detect them. This way, we found that\nRuleFit struggles with conjunctive and non-convex biases, while SHAP can\napproximate conjunctive biases but cannot express them as actionable rules.\nHence, we introduce RuleSHAP, a global rule extraction algorithm combining SHAP\nand RuleFit to detect more non-univariate biases, improving injected bias\ndetection over RuleFit by +94% (MRR@1) on average.",
      "tldr_zh": "这篇论文评估了全局XAI方法（如SHAP和规则提取算法）在检测大型语言模型（LLMs）中注入偏差的有效性，旨在揭示这些偏差如何影响AI系统的误信息传播和UN可持续发展目标（SDGs）。研究者首先引入文本到序数映射策略，将LLMs的非数值输入/输出转换为数值特征，然后向模型如ChatGPT和Llama注入不同复杂度的偏差（单变量、连接和非凸），并使用XAI方法进行检测。结果显示，RuleFit在处理连接和非凸偏差时表现不佳，而SHAP虽能近似这些偏差但无法转化为可操作规则；为此，论文提出新方法RuleSHAP，将SHAP与RuleFit结合，平均提高了94%的偏差检测性能（MRR@1）。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11189v1",
      "published_date": "2025-05-16 12:48:44 UTC",
      "updated_date": "2025-05-16 12:48:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:53:00.950222"
    },
    {
      "arxiv_id": "2505.11182v1",
      "title": "Imputation-free and Alignment-free: Incomplete Multi-view Clustering Driven by Consensus Semantic Learning",
      "title_zh": "无插值且无对齐：由共识语义学习驱动的不完整多视图聚类",
      "authors": [
        "Yuzhuo Dai",
        "Jiaqi Jin",
        "Zhibin Dong",
        "Siwei Wang",
        "Xinwang Liu",
        "En Zhu",
        "Xihong Yang",
        "Xinbiao Gan",
        "Yu Feng"
      ],
      "abstract": "In incomplete multi-view clustering (IMVC), missing data induce prototype\nshifts within views and semantic inconsistencies across views. A feasible\nsolution is to explore cross-view consistency in paired complete observations,\nfurther imputing and aligning the similarity relationships inherently shared\nacross views. Nevertheless, existing methods are constrained by two-tiered\nlimitations: (1) Neither instance- nor cluster-level consistency learning\nconstruct a semantic space shared across views to learn consensus semantics.\nThe former enforces cross-view instances alignment, and wrongly regards\nunpaired observations with semantic consistency as negative pairs; the latter\nfocuses on cross-view cluster counterparts while coarsely handling fine-grained\nintra-cluster relationships within views. (2) Excessive reliance on consistency\nresults in unreliable imputation and alignment without incorporating\nview-specific cluster information. Thus, we propose an IMVC framework,\nimputation- and alignment-free for consensus semantics learning (FreeCSL). To\nbridge semantic gaps across all observations, we learn consensus prototypes\nfrom available data to discover a shared space, where semantically similar\nobservations are pulled closer for consensus semantics learning. To capture\nsemantic relationships within specific views, we design a heuristic graph\nclustering based on modularity to recover cluster structure with intra-cluster\ncompactness and inter-cluster separation for cluster semantics enhancement.\nExtensive experiments demonstrate, compared to state-of-the-art competitors,\nFreeCSL achieves more confident and robust assignments on IMVC task.",
      "tldr_zh": "该论文针对不完整多视图聚类（IMVC）中的原型偏移和语义不一致问题，提出了一种无需插值和对齐的框架FreeCSL，通过共识语义学习来驱动聚类。FreeCSL从可用数据中学习共识原型，构建共享语义空间，拉近语义相似的观察以增强跨视图一致性，同时使用基于模块化的启发式图聚类方法，恢复视图特有的集群结构，提高内部紧凑性和外部分离。实验结果显示，FreeCSL在IMVC任务上比现有方法更可靠和鲁棒，提供更自信的聚类分配。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "The paper has been accepted by the 42nd CVPR 2025. The main text has\n  9 pages, including 8 figures and 4 tables. The appendix has 8 pages, with 10\n  figures and 6 tables. The reference list has 3 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11182v1",
      "published_date": "2025-05-16 12:37:10 UTC",
      "updated_date": "2025-05-16 12:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:53:10.716191"
    },
    {
      "arxiv_id": "2505.11181v1",
      "title": "Feasibility with Language Models for Open-World Compositional Zero-Shot Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jae Myung Kim",
        "Stephan Alaniz",
        "Cordelia Schmid",
        "Zeynep Akata"
      ],
      "abstract": "Humans can easily tell if an attribute (also called state) is realistic,\ni.e., feasible, for an object, e.g. fire can be hot, but it cannot be wet. In\nOpen-World Compositional Zero-Shot Learning, when all possible state-object\ncombinations are considered as unseen classes, zero-shot predictors tend to\nperform poorly. Our work focuses on using external auxiliary knowledge to\ndetermine the feasibility of state-object combinations. Our Feasibility with\nLanguage Model (FLM) is a simple and effective approach that leverages Large\nLanguage Models (LLMs) to better comprehend the semantic relationships between\nstates and objects. FLM involves querying an LLM about the feasibility of a\ngiven pair and retrieving the output logit for the positive answer. To mitigate\npotential misguidance of the LLM given that many of the state-object\ncompositions are rare or completely infeasible, we observe that the in-context\nlearning ability of LLMs is essential. We present an extensive study\nidentifying Vicuna and ChatGPT as best performing, and we demonstrate that our\nFLM consistently improves OW-CZSL performance across all three benchmarks.",
      "tldr_zh": "这篇论文探讨了在开放世界组合零样本学习（OW-CZSL）中，使用大型语言模型（LLMs）来判断状态-物体组合的可行性问题，例如火可以是热的，但不能是湿的。作者提出Feasibility with Language Model (FLM)方法，通过查询LLMs获取正面答案的logit输出，并利用in-context learning能力来缓解对稀有或不可行组合的误导。实验结果显示，FLM在三个基准上 consistently 提升了OW-CZSL性能，其中Vicuna和ChatGPT作为最佳模型，证明了这一方法的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ECCV Workshop in OOD-CV, 2024",
      "pdf_url": "http://arxiv.org/pdf/2505.11181v1",
      "published_date": "2025-05-16 12:37:08 UTC",
      "updated_date": "2025-05-16 12:37:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:53:23.705187"
    },
    {
      "arxiv_id": "2505.11178v1",
      "title": "CompAlign: Improving Compositional Text-to-Image Generation with a Complex Benchmark and Fine-Grained Feedback",
      "title_zh": "翻译失败",
      "authors": [
        "Yixin Wan",
        "Kai-Wei Chang"
      ],
      "abstract": "State-of-the-art T2I models are capable of generating high-resolution images\ngiven textual prompts. However, they still struggle with accurately depicting\ncompositional scenes that specify multiple objects, attributes, and spatial\nrelations. We present CompAlign, a challenging benchmark with an emphasis on\nassessing the depiction of 3D-spatial relationships, for evaluating and\nimproving models on compositional image generation. CompAlign consists of 900\ncomplex multi-subject image generation prompts that combine numerical and\n3D-spatial relationships with varied attribute bindings. Our benchmark is\nremarkably challenging, incorporating generation tasks with 3+ generation\nsubjects with complex 3D-spatial relationships. Additionally, we propose\nCompQuest, an interpretable and accurate evaluation framework that decomposes\ncomplex prompts into atomic sub-questions, then utilizes a MLLM to provide\nfine-grained binary feedback on the correctness of each aspect of generation\nelements in model-generated images. This enables precise quantification of\nalignment between generated images and compositional prompts. Furthermore, we\npropose an alignment framework that uses CompQuest's feedback as preference\nsignals to improve diffusion models' compositional image generation abilities.\nUsing adjustable per-image preferences, our method is easily scalable and\nflexible for different tasks. Evaluation of 9 T2I models reveals that: (1)\nmodels remarkable struggle more with compositional tasks with more complex\n3D-spatial configurations, and (2) a noticeable performance gap exists between\nopen-source accessible models and closed-source commercial models. Further\nempirical study on using CompAlign for model alignment yield promising results:\npost-alignment diffusion models achieve remarkable improvements in\ncompositional accuracy, especially on complex generation tasks, outperforming\nprevious approaches.",
      "tldr_zh": "本研究提出CompAlign基准，用于评估和提升文本到图像(T2I)模型在合成场景生成中的性能，特别针对多对象、属性和3D-spatial relationships的复杂任务。CompAlign包含900个复杂的多主体提示，强调数字和3D-空间关系的处理，同时引入CompQuest框架，该框架通过将提示分解为原子子问题并利用MLLM提供细粒度二元反馈，实现对生成图像的精确评估。基于CompQuest的反馈信号，作者开发了一个对齐框架来优化扩散模型的合成生成能力；实验结果显示，9个T2I模型在复杂3D-空间配置上表现欠佳，且开源模型与闭源商业模型存在显著差距，而经过对齐改进后，模型在合成准确性上显著提升，尤其在高难度任务上。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11178v1",
      "published_date": "2025-05-16 12:23:58 UTC",
      "updated_date": "2025-05-16 12:23:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:53:35.869181"
    },
    {
      "arxiv_id": "2505.11177v1",
      "title": "Low-Resource Language Processing: An OCR-Driven Summarization and Translation Pipeline",
      "title_zh": "低资源语言处理：基于 OCR 的摘要化和翻译管道",
      "authors": [
        "Hrishit Madhavi",
        "Jacob Cherian",
        "Yuvraj Khamkar",
        "Dhananjay Bhagat"
      ],
      "abstract": "This paper presents an end-to-end suite for multilingual information\nextraction and processing from image-based documents. The system uses Optical\nCharacter Recognition (Tesseract) to extract text in languages such as English,\nHindi, and Tamil, and then a pipeline involving large language model APIs\n(Gemini) for cross-lingual translation, abstractive summarization, and\nre-translation into a target language. Additional modules add sentiment\nanalysis (TensorFlow), topic classification (Transformers), and date extraction\n(Regex) for better document comprehension. Made available in an accessible\nGradio interface, the current research shows a real-world application of\nlibraries, models, and APIs to close the language gap and enhance access to\ninformation in image media across different linguistic environments",
      "tldr_zh": "本论文提出了一种基于 OCR（Optical Character Recognition）的端到端系统，用于从图像文档中提取和处理低资源语言信息，主要支持英语、Hindi 和 Tamil 等语言。系统利用 Tesseract 进行文本提取，随后通过 Gemini API 实现跨语言翻译、抽象总结和重新翻译，并整合情感分析（TensorFlow）、主题分类（Transformers）和日期提取（Regex）模块以提升文档理解。整个管道通过 Gradio 接口提供，展示了如何应用现有库和模型来缩小语言差距，并增强不同语言环境下的图像媒体信息访问性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50 (Natural language processing), 68U10 (Image processing)"
      ],
      "primary_category": "cs.CL",
      "comment": "8 pages, 7 figures, direct arXiv submission",
      "pdf_url": "http://arxiv.org/pdf/2505.11177v1",
      "published_date": "2025-05-16 12:20:37 UTC",
      "updated_date": "2025-05-16 12:20:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:53:47.980764"
    },
    {
      "arxiv_id": "2505.11176v1",
      "title": "From Intent Discovery to Recognition with Topic Modeling and Synthetic Data",
      "title_zh": "从意图发现到识别：利用主题建模和合成数据",
      "authors": [
        "Aaron Rodrigues",
        "Mahmood Hegazy",
        "Azzam Naeem"
      ],
      "abstract": "Understanding and recognizing customer intents in AI systems is crucial,\nparticularly in domains characterized by short utterances and the cold start\nproblem, where recommender systems must include new products or services\nwithout sufficient real user data. Customer utterances are characterized by\ninfrequent word co-occurences and high term variability, which poses\nsignificant challenges for traditional methods in specifying distinct user\nneeds and preparing synthetic queries. To address this, we propose an agentic\nLLM framework for topic modeling and synthetic query generation, which\naccelerates the discovery and recognition of customer intents. We first apply\nhierarchical topic modeling and intent discovery to expand a human-curated\ntaxonomy from 36 generic user intents to 278 granular intents, demonstrating\nthe potential of LLMs to significantly enhance topic specificity and diversity.\nNext, to support newly discovered intents and address the cold start problem,\nwe generate synthetic user query data, which augments real utterances and\nreduces dependency on human annotation, especially in low-resource settings.\nTopic model experiments show substantial improvements in coherence and\nrelevance after topic expansion, while synthetic data experiments indicate that\nin-class few-shot prompting significantly improves the quality and utility of\nsynthetic queries without compromising diversity. We also show that\nLLM-generated intent descriptions and keywords can effectively substitute for\nhuman-curated versions when used as context for synthetic query generation. Our\nresearch underscores the scalability and utility of LLM agents in topic\nmodeling and highlights the strategic use of synthetic utterances to enhance\ndataset variability and coverage for intent recognition. We present a\ncomprehensive and robust framework for online discovery and recognition of new\ncustomer intents in dynamic domains.",
      "tldr_zh": "本研究提出了一种基于大型语言模型 (LLM) 的框架，用于从意图发现到识别的过程，针对短语表达和冷启动问题 (cold start problem) 等挑战。框架首先通过分层主题建模 (topic modeling) 和意图发现，将人工编制的36个通用意图扩展到278个粒度意图，从而提升主题的特定性和多样性。接着，利用合成查询生成技术 (synthetic data) 增强真实数据，支持新意图的识别，并减少对人工标注的依赖。实验结果显示，该方法显著提高了主题一致性和相关性，在类内少样本提示 (few-shot prompting) 下，合成查询的质量和实用性得到提升，同时保持了数据多样性。该框架突显了 LLM 在动态领域中扩展意图识别的可扩展性和实用性。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11176v1",
      "published_date": "2025-05-16 12:20:31 UTC",
      "updated_date": "2025-05-16 12:20:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:53:59.179857"
    },
    {
      "arxiv_id": "2505.11175v2",
      "title": "Real-Time Verification of Embodied Reasoning for Generative Skill Acquisition",
      "title_zh": "实时验证具身推理用于生成式技能获取",
      "authors": [
        "Bo Yue",
        "Shuqi Guo",
        "Kaiyu Hu",
        "Chujiao Wang",
        "Benyou Wang",
        "Kui Jia",
        "Guiliang Liu"
      ],
      "abstract": "Generative skill acquisition enables embodied agents to actively learn a\nscalable and evolving repertoire of control skills, crucial for the advancement\nof large decision models. While prior approaches often rely on supervision\nsignals from generalist agents (e.g., LLMs), their effectiveness in complex 3D\nenvironments remains unclear; exhaustive evaluation incurs substantial\ncomputational costs, significantly hindering the efficiency of skill learning.\nInspired by recent successes in verification models for mathematical reasoning,\nwe propose VERGSA (Verifying Embodied Reasoning in Generative Skill\nAcquisition), a framework that systematically integrates real-time verification\nprinciples into embodied skill learning. VERGSA establishes 1) a seamless\nextension from verification of mathematical reasoning into embodied learning by\ndynamically incorporating contextually relevant tasks into prompts and defining\nsuccess metrics for both subtasks and overall tasks, and 2) an automated,\nscalable reward labeling scheme that synthesizes dense reward signals by\niteratively finalizing the contribution of scene configuration and subtask\nlearning to overall skill acquisition. To the best of our knowledge, this\napproach constitutes the first comprehensive training dataset for\nverification-driven generative skill acquisition, eliminating arduous manual\nreward engineering. Experiments validate the efficacy of our approach: 1) the\nexemplar task pool improves the average task success rates by 21%, 2) our\nverification model boosts success rates by 24% for novel tasks and 36% for\nencountered tasks, and 3) outperforms LLM-as-a-Judge baselines in verification\nquality.",
      "tldr_zh": "这篇论文提出 VERGSA（Verifying Embodied Reasoning in Generative Skill Acquisition）框架，用于在复杂 3D 环境中实时验证实体代理的生成技能获取过程，从而提升技能学习的效率和可扩展性。VERGSA 通过动态整合任务提示、定义子任务和整体任务成功指标，以及自动化合成密集奖励信号，解决了现有依赖 LLMs 监督方法的局限性，并消除了手动奖励工程的需求。实验结果显示，该框架将平均任务成功率提高了 21%，对新任务和已遇任务的成功率分别提升 24% 和 36%，并在验证质量上优于 LLM-as-a-Judge 基准。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11175v2",
      "published_date": "2025-05-16 12:19:13 UTC",
      "updated_date": "2025-05-19 05:14:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:54:12.347012"
    },
    {
      "arxiv_id": "2505.11574v1",
      "title": "InfiJanice: Joint Analysis and In-situ Correction Engine for Quantization-Induced Math Degradation in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Li",
        "Yupeng Su",
        "Songmiao Wang",
        "Runming Yang",
        "Congkai Xie",
        "Aofan Liu",
        "Ming Li",
        "Jiannong Cao",
        "Yuan Xie",
        "Ngai Wong",
        "Hongxia Yang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated impressive performance on\ncomplex reasoning benchmarks such as GSM8K, MATH, and AIME. However, the\nsubstantial computational demands of these tasks pose significant challenges\nfor real-world deployment. Model quantization has emerged as a promising\napproach to reduce memory footprint and inference latency by representing\nweights and activations with lower bit-widths. In this work, we conduct a\ncomprehensive study of mainstream quantization methods(e.g., AWQ, GPTQ,\nSmoothQuant) on the most popular open-sourced models (e.g., Qwen2.5, LLaMA3\nseries), and reveal that quantization can degrade mathematical reasoning\naccuracy by up to 69.81%. To better understand this degradation, we develop an\nautomated assignment and judgment pipeline that qualitatively categorizes\nfailures into four error types and quantitatively identifies the most impacted\nreasoning capabilities. Building on these findings, we employ an automated\ndata-curation pipeline to construct a compact \"Silver Bullet\" datasets.\nTraining a quantized model on as few as 332 carefully selected examples for\njust 3-5 minutes on a single GPU is enough to restore its reasoning accuracy to\nmatch that of the full-precision baseline.",
      "tldr_zh": "本研究分析了量化（quantization）对大型语言模型（LLMs）在数学推理任务（如GSM8K、MATH、AIME）中的影响，发现主流量化方法（如AWQ、GPTQ、SmoothQuant）会导致模型（如Qwen2.5、LLaMA3）的准确率下降高达69.81%。他们开发了一个自动化管道来分类错误类型（如四种错误类别）和量化受影响的推理能力，从而识别关键问题。基于这些发现，研究构建了精选的“Silver Bullet”数据集，通过在单GPU上训练仅332个样本3-5分钟，即可将量化模型的推理准确率恢复到与全精度基准相当水平。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "23pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11574v1",
      "published_date": "2025-05-16 12:11:40 UTC",
      "updated_date": "2025-05-16 12:11:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:54:23.451550"
    },
    {
      "arxiv_id": "2505.11168v1",
      "title": "CheX-DS: Improving Chest X-ray Image Classification with Ensemble Learning Based on DenseNet and Swin Transformer",
      "title_zh": "翻译失败",
      "authors": [
        "Xinran Li",
        "Yu Liu",
        "Xiujuan Xu",
        "Xiaowei Zhao"
      ],
      "abstract": "The automatic diagnosis of chest diseases is a popular and challenging task.\nMost current methods are based on convolutional neural networks (CNNs), which\nfocus on local features while neglecting global features. Recently,\nself-attention mechanisms have been introduced into the field of computer\nvision, demonstrating superior performance. Therefore, this paper proposes an\neffective model, CheX-DS, for classifying long-tail multi-label data in the\nmedical field of chest X-rays. The model is based on the excellent CNN model\nDenseNet for medical imaging and the newly popular Swin Transformer model,\nutilizing ensemble deep learning techniques to combine the two models and\nleverage the advantages of both CNNs and Transformers. The loss function of\nCheX-DS combines weighted binary cross-entropy loss with asymmetric loss,\neffectively addressing the issue of data imbalance. The NIH ChestX-ray14\ndataset is selected to evaluate the model's effectiveness. The model\noutperforms previous studies with an excellent average AUC score of 83.76\\%,\ndemonstrating its superior performance.",
      "tldr_zh": "这篇论文提出CheX-DS模型，通过ensemble learning将DenseNet和Swin Transformer结合，旨在改善胸部X光图像分类问题，利用CNNs的局部特征和Transformers的自注意力机制来处理长尾多标签数据。模型的损失函数结合了weighted binary cross-entropy loss和asymmetric loss，以有效解决数据不平衡问题。在NIH ChestX-ray14数据集上，CheX-DS实现了83.76%的平均AUC分数，显著优于现有研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "BIBM",
      "pdf_url": "http://arxiv.org/pdf/2505.11168v1",
      "published_date": "2025-05-16 12:10:01 UTC",
      "updated_date": "2025-05-16 12:10:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:54:34.990223"
    },
    {
      "arxiv_id": "2505.11166v1",
      "title": "SoLoPO: Unlocking Long-Context Capabilities in LLMs via Short-to-Long Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Huashan Sun",
        "Shengyi Liao",
        "Yansen Han",
        "Yu Bai",
        "Yang Gao",
        "Cheng Fu",
        "Weizhou Shen",
        "Fanqi Wan",
        "Ming Yan",
        "Ji Zhang",
        "Fei Huang"
      ],
      "abstract": "Despite advances in pretraining with extended context lengths, large language\nmodels (LLMs) still face challenges in effectively utilizing real-world\nlong-context information, primarily due to insufficient long-context alignment\ncaused by data quality issues, training inefficiencies, and the lack of\nwell-designed optimization objectives. To address these limitations, we propose\na framework named $\\textbf{S}$h$\\textbf{o}$rt-to-$\\textbf{Lo}$ng\n$\\textbf{P}$reference $\\textbf{O}$ptimization ($\\textbf{SoLoPO}$), decoupling\nlong-context preference optimization (PO) into two components: short-context PO\nand short-to-long reward alignment (SoLo-RA), supported by both theoretical and\nempirical evidence. Specifically, short-context PO leverages preference pairs\nsampled from short contexts to enhance the model's contextual knowledge\nutilization ability. Meanwhile, SoLo-RA explicitly encourages reward score\nconsistency utilization for the responses when conditioned on both short and\nlong contexts that contain identical task-relevant information. This\nfacilitates transferring the model's ability to handle short contexts into\nlong-context scenarios. SoLoPO is compatible with mainstream preference\noptimization algorithms, while substantially improving the efficiency of data\nconstruction and training processes. Experimental results show that SoLoPO\nenhances all these algorithms with respect to stronger length and domain\ngeneralization abilities across various long-context benchmarks, while\nachieving notable improvements in both computational and memory efficiency.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在处理长上下文时存在的对齐不足问题（如数据质量和训练效率问题），提出了一种名为 SoLoPO 的框架，通过 Short-to-Long Preference Optimization 来提升长上下文能力。该框架将偏好优化分解为两个部分：short-context PO，利用短上下文的偏好对来加强模型的知识利用能力；以及 SoLo-RA (Short-to-Long Reward Alignment)，确保短长上下文间任务相关信息的奖励分数一致，从而转移短上下文能力到长场景中。SoLoPO 兼容主流偏好优化算法，大幅提高了数据构建和训练效率。实验结果显示，该框架在各种长上下文基准上显著提升了长度和领域泛化能力，同时优化了计算和内存效率。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11166v1",
      "published_date": "2025-05-16 12:08:48 UTC",
      "updated_date": "2025-05-16 12:08:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:54:47.843564"
    },
    {
      "arxiv_id": "2505.11165v1",
      "title": "Maximizing Asynchronicity in Event-based Neural Networks",
      "title_zh": "基于事件的神经网络中的异步性最大化",
      "authors": [
        "Haiqing Hao",
        "Nikola Zubić",
        "Weihua He",
        "Zhipeng Sui",
        "Davide Scaramuzza",
        "Wenhui Wang"
      ],
      "abstract": "Event cameras deliver visual data with high temporal resolution, low latency,\nand minimal redundancy, yet their asynchronous, sparse sequential nature\nchallenges standard tensor-based machine learning (ML). While the recent\nasynchronous-to-synchronous (A2S) paradigm aims to bridge this gap by\nasynchronously encoding events into learned representations for ML pipelines,\nexisting A2S approaches often sacrifice representation expressivity and\ngeneralizability compared to dense, synchronous methods. This paper introduces\nEVA (EVent Asynchronous representation learning), a novel A2S framework to\ngenerate highly expressive and generalizable event-by-event representations.\nInspired by the analogy between events and language, EVA uniquely adapts\nadvances from language modeling in linear attention and self-supervised\nlearning for its construction. In demonstration, EVA outperforms prior A2S\nmethods on recognition tasks (DVS128-Gesture and N-Cars), and represents the\nfirst A2S framework to successfully master demanding detection tasks, achieving\na remarkable 47.7 mAP on the Gen1 dataset. These results underscore EVA's\ntransformative potential for advancing real-time event-based vision\napplications.",
      "tldr_zh": "本文提出EVA（EVent Asynchronous representation learning）框架，旨在优化事件-based神经网络的异步性，通过借鉴语言建模中的linear attention和self-supervised learning，将事件数据转换为高度表达性和泛化性的逐事件表示，从而解决现有A2S（Asynchronous-to-Synchronous）方法的局限性。在实验中，EVA在DVS128-Gesture和N-Cars识别任务上超越了先前的A2S方法，并首次成功应用于检测任务，在Gen1数据集上达到47.7 mAP。这些结果展示了EVA在推进实时事件-based视觉应用方面的巨大潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 5 figures, 9 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.11165v1",
      "published_date": "2025-05-16 12:07:50 UTC",
      "updated_date": "2025-05-16 12:07:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:55:00.208318"
    },
    {
      "arxiv_id": "2505.15834v1",
      "title": "MPPFND: A Dataset and Analysis of Detecting Fake News with Multi-Platform Propagation",
      "title_zh": "翻译失败",
      "authors": [
        "Congyuan Zhao",
        "Lingwei Wei",
        "Ziming Qin",
        "Wei Zhou",
        "Yunya Song",
        "Songlin Hu"
      ],
      "abstract": "Fake news spreads widely on social media, leading to numerous negative\neffects. Most existing detection algorithms focus on analyzing news content and\nsocial context to detect fake news. However, these approaches typically detect\nfake news based on specific platforms, ignoring differences in propagation\ncharacteristics across platforms. In this paper, we introduce the MPPFND\ndataset, which captures propagation structures across multiple platforms. We\nalso describe the commenting and propagation characteristics of different\nplatforms to show that their social contexts have distinct features. We propose\na multi-platform fake news detection model (APSL) that uses graph neural\nnetworks to extract social context features from various platforms. Experiments\nshow that accounting for cross-platform propagation differences improves fake\nnews detection performance.",
      "tldr_zh": "该论文引入了 MPPFND 数据集，用于捕捉多平台假新闻传播结构，并分析了不同平台的评论和传播特性，以揭示其独特的社会上下文特征。现有假新闻检测方法通常局限于单一平台，忽略了跨平台差异，因此论文提出 APSL 模型，该模型利用 Graph Neural Networks 提取多平台社交上下文特征来提升检测准确性。实验结果表明，考虑跨平台传播差异能显著改善假新闻检测性能。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "Cogsci 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.15834v1",
      "published_date": "2025-05-16 11:59:31 UTC",
      "updated_date": "2025-05-16 11:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:55:10.950982"
    },
    {
      "arxiv_id": "2505.11157v1",
      "title": "Attention on the Sphere",
      "title_zh": "球面上的注意力",
      "authors": [
        "Boris Bonev",
        "Max Rietmann",
        "Andrea Paris",
        "Alberto Carpentieri",
        "Thorsten Kurth"
      ],
      "abstract": "We introduce a generalized attention mechanism for spherical domains,\nenabling Transformer architectures to natively process data defined on the\ntwo-dimensional sphere - a critical need in fields such as atmospheric physics,\ncosmology, and robotics, where preserving spherical symmetries and topology is\nessential for physical accuracy. By integrating numerical quadrature weights\ninto the attention mechanism, we obtain a geometrically faithful spherical\nattention that is approximately rotationally equivariant, providing strong\ninductive biases and leading to better performance than Cartesian approaches.\nTo further enhance both scalability and model performance, we propose\nneighborhood attention on the sphere, which confines interactions to geodesic\nneighborhoods. This approach reduces computational complexity and introduces\nthe additional inductive bias for locality, while retaining the symmetry\nproperties of our method. We provide optimized CUDA kernels and\nmemory-efficient implementations to ensure practical applicability. The method\nis validated on three diverse tasks: simulating shallow water equations on the\nrotating sphere, spherical image segmentation, and spherical depth estimation.\nAcross all tasks, our spherical Transformers consistently outperform their\nplanar counterparts, highlighting the advantage of geometric priors for\nlearning on spherical domains.",
      "tldr_zh": "本研究引入了一种针对球面域的通用注意力机制，允许 Transformer 架构直接处理球面上的数据，从而在气象物理学、宇宙学和机器人等领域中保留球面对称性和拓扑结构以提升物理准确性。通过整合数值积分权重，该机制实现近似旋转等变性（rotational equivariance），并提出球面上的邻域注意力（neighborhood attention），将交互限制在测地邻域（geodesic neighborhoods）内，以降低计算复杂性和增强局部性偏差，同时提供优化的 CUDA kernels 和内存高效实现。实验在模拟浅水方程（shallow water equations）、球面图像分割和球面深度估计等三个任务上验证，结果显示球面 Transformer 模型在所有任务中均优于平面对应模型，突出了几何先验（geometric priors）的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11157v1",
      "published_date": "2025-05-16 11:59:30 UTC",
      "updated_date": "2025-05-16 11:59:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:55:23.553838"
    },
    {
      "arxiv_id": "2505.11146v1",
      "title": "X2C: A Dataset Featuring Nuanced Facial Expressions for Realistic Humanoid Imitation",
      "title_zh": "X2C：以细微面部表情为特征的数据集，用于真实人形机器人模仿",
      "authors": [
        "Peizhen Li",
        "Longbing Cao",
        "Xiao-Ming Wu",
        "Runze Yang",
        "Xiaohan Yu"
      ],
      "abstract": "The ability to imitate realistic facial expressions is essential for humanoid\nrobots engaged in affective human-robot communication. However, the lack of\ndatasets containing diverse humanoid facial expressions with proper annotations\nhinders progress in realistic humanoid facial expression imitation. To address\nthese challenges, we introduce X2C (Anything to Control), a dataset featuring\nnuanced facial expressions for realistic humanoid imitation. With X2C, we\ncontribute: 1) a high-quality, high-diversity, large-scale dataset comprising\n100,000 (image, control value) pairs. Each image depicts a humanoid robot\ndisplaying a diverse range of facial expressions, annotated with 30 control\nvalues representing the ground-truth expression configuration; 2) X2CNet, a\nnovel human-to-humanoid facial expression imitation framework that learns the\ncorrespondence between nuanced humanoid expressions and their underlying\ncontrol values from X2C. It enables facial expression imitation in the wild for\ndifferent human performers, providing a baseline for the imitation task,\nshowcasing the potential value of our dataset; 3) real-world demonstrations on\na physical humanoid robot, highlighting its capability to advance realistic\nhumanoid facial expression imitation. Code and Data:\nhttps://lipzh5.github.io/X2CNet/",
      "tldr_zh": "该论文引入了 X2C 数据集，以解决人形机器人(humanoid robot)模仿真实面部表情的挑战，该数据集包含10万对高质量图像和控制值对，每个图像标注了30个控制值，涵盖多样化的面部表情。论文同时提出 X2CNet，一个新颖的框架，用于学习人类面部表情与机器人控制值的对应关系，实现野外环境下的表情模仿。实验通过真实人形机器人演示展示了该框架的有效性，为机器人情感交互提供了一个基线基准。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11146v1",
      "published_date": "2025-05-16 11:48:19 UTC",
      "updated_date": "2025-05-16 11:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:55:35.852166"
    },
    {
      "arxiv_id": "2505.11141v1",
      "title": "Human-Aligned Bench: Fine-Grained Assessment of Reasoning Ability in MLLMs vs. Humans",
      "title_zh": "Human-Aligned Bench：多模态大语言模型与人类推理能力的细粒度评估",
      "authors": [
        "Yansheng Qiu",
        "Li Xiao",
        "Zhaopan Xu",
        "Pengfei Zhou",
        "Zheng Wang",
        "Kaipeng Zhang"
      ],
      "abstract": "The goal of achieving Artificial General Intelligence (AGI) is to imitate\nhumans and surpass them. Models such as OpenAI's o1, o3, and DeepSeek's R1 have\ndemonstrated that large language models (LLMs) with human-like reasoning\ncapabilities exhibit exceptional performance and are being gradually integrated\ninto multimodal large language models (MLLMs). However, whether these models\npossess capabilities comparable to humans in handling reasoning tasks remains\nunclear at present. In this paper, we propose Human-Aligned Bench, a benchmark\nfor fine-grained alignment of multimodal reasoning with human performance.\nSpecifically, we collected 9,794 multimodal questions that solely rely on\ncontextual reasoning, including bilingual (Chinese and English) multimodal\nquestions and pure text-based questions, encompassing four question types:\nvisual reasoning, definition judgment, analogical reasoning, and logical\njudgment. More importantly, each question is accompanied by human success rates\nand options that humans are prone to choosing incorrectly. Extensive\nexperiments on the Human-Aligned Bench reveal notable differences between the\nperformance of current MLLMs in multimodal reasoning and human performance. The\nfindings on our benchmark provide insights into the development of the\nnext-generation models.",
      "tldr_zh": "本论文提出Human-Aligned Bench，一个细粒度基准，用于评估多模态大语言模型(MLLMs)与人类的推理能力对齐程度。该基准收集了9,794个依赖上下文推理的多模态问题，包括中英双语多模态问题和纯文本问题，涵盖视觉推理、定义判断、类比推理和逻辑判断，每题附有人类成功率和常见错误选项。通过广泛实验，研究发现当前MLLMs在多模态推理方面的表现与人类存在显著差异，这些发现为AGI和下一代模型的发展提供重要洞见。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11141v1",
      "published_date": "2025-05-16 11:41:19 UTC",
      "updated_date": "2025-05-16 11:41:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:55:47.235975"
    },
    {
      "arxiv_id": "2505.13506v1",
      "title": "EcoSafeRAG: Efficient Security through Context Analysis in Retrieval-Augmented Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Ruobing Yao",
        "Yifei Zhang",
        "Shuang Song",
        "Neng Gao",
        "Chenyang Tu"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) compensates for the static knowledge\nlimitations of Large Language Models (LLMs) by integrating external knowledge,\nproducing responses with enhanced factual correctness and query-specific\ncontextualization. However, it also introduces new attack surfaces such as\ncorpus poisoning at the same time. Most of the existing defense methods rely on\nthe internal knowledge of the model, which conflicts with the design concept of\nRAG. To bridge the gap, EcoSafeRAG uses sentence-level processing and\nbait-guided context diversity detection to identify malicious content by\nanalyzing the context diversity of candidate documents without relying on LLM\ninternal knowledge. Experiments show EcoSafeRAG delivers state-of-the-art\nsecurity with plug-and-play deployment, simultaneously improving clean-scenario\nRAG performance while maintaining practical operational costs (relatively\n1.2$\\times$ latency, 48\\%-80\\% token reduction versus Vanilla RAG).",
      "tldr_zh": "本文提出EcoSafeRAG，一种通过上下文分析提升Retrieval-Augmented Generation (RAG)安全性的框架，旨在解决RAG整合外部知识时引入的攻击风险，如语料库中毒。EcoSafeRAG采用句子级处理和诱饵引导的上下文多样性检测方法，分析候选文档以识别恶意内容，而不依赖Large Language Models (LLMs)的内部知识，实现即插即用部署。实验结果显示，该框架在安全性能上达到最先进水平，同时在干净场景下改善RAG表现，并保持较低操作成本（延迟仅增加1.2倍，token减少48%-80%）。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13506v1",
      "published_date": "2025-05-16 11:40:32 UTC",
      "updated_date": "2025-05-16 11:40:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:55:59.948522"
    },
    {
      "arxiv_id": "2505.11140v1",
      "title": "Scaling Reasoning can Improve Factuality in Large Language Models",
      "title_zh": "缩放推理可以改善大语言模型的事实性",
      "authors": [
        "Mike Zhang",
        "Johannes Bjerva",
        "Russa Biswas"
      ],
      "abstract": "Recent studies on large language model (LLM) reasoning capabilities have\ndemonstrated promising improvements in model performance by leveraging a\nlengthy thinking process and additional computational resources during\ninference, primarily in tasks involving mathematical reasoning (Muennighoff et\nal., 2025). However, it remains uncertain if longer reasoning chains inherently\nenhance factual accuracy, particularly beyond mathematical contexts. In this\nwork, we thoroughly examine LLM reasoning within complex open-domain\nquestion-answering (QA) scenarios. We initially distill reasoning traces from\nadvanced, large-scale reasoning models (QwQ-32B and DeepSeek-R1-671B), then\nfine-tune a variety of models ranging from smaller, instruction-tuned variants\nto larger architectures based on Qwen2.5. To enrich reasoning traces, we\nintroduce factual information from knowledge graphs in the form of paths into\nour reasoning traces. Our experimental setup includes four baseline approaches\nand six different instruction-tuned models evaluated across a benchmark of six\ndatasets, encompassing over 22.6K questions. Overall, we carry out 168\nexperimental runs and analyze approximately 1.7 million reasoning traces. Our\nfindings indicate that, within a single run, smaller reasoning models achieve\nnoticeable improvements in factual accuracy compared to their original\ninstruction-tuned counterparts. Moreover, our analysis demonstrates that adding\ntest-time compute and token budgets factual accuracy consistently improves by\n2-8%, further confirming the effectiveness of test-time scaling for enhancing\nperformance and consequently improving reasoning accuracy in open-domain QA\ntasks. We release all the experimental artifacts for further research.",
      "tldr_zh": "本文研究了通过扩展推理过程和增加计算资源来提升大语言模型(LLM)的事实准确性，特别是在开放域问答(QA)任务中，而非仅限于数学推理。研究者从先进模型(QwQ-32B和DeepSeek-R1-671B)中提取推理痕迹，并微调多种模型，同时融入知识图谱中的事实信息路径，以丰富推理内容。实验涉及六个数据集、22.6K问题和168次运行，结果显示较小模型的事实准确性比原始指令微调版本显著提高，且增加测试时计算和令牌预算可进一步提升2-8%的准确性，为LLM性能优化提供了实证支持。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11140v1",
      "published_date": "2025-05-16 11:39:33 UTC",
      "updated_date": "2025-05-16 11:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:56:12.380362"
    },
    {
      "arxiv_id": "2505.11136v1",
      "title": "Reinforcement Learning for AMR Charging Decisions: The Impact of Reward and Action Space Design",
      "title_zh": "翻译失败",
      "authors": [
        "Janik Bischoff",
        "Alexandru Rinciog",
        "Anne Meyer"
      ],
      "abstract": "We propose a novel reinforcement learning (RL) design to optimize the\ncharging strategy for autonomous mobile robots in large-scale block stacking\nwarehouses. RL design involves a wide array of choices that can mostly only be\nevaluated through lengthy experimentation. Our study focuses on how different\nreward and action space configurations, ranging from flexible setups to more\nguided, domain-informed design configurations, affect the agent performance.\nUsing heuristic charging strategies as a baseline, we demonstrate the\nsuperiority of flexible, RL-based approaches in terms of service times.\nFurthermore, our findings highlight a trade-off: While more open-ended designs\nare able to discover well-performing strategies on their own, they may require\nlonger convergence times and are less stable, whereas guided configurations\nlead to a more stable learning process but display a more limited\ngeneralization potential. Our contributions are threefold. First, we extend\nSLAPStack, an open-source, RL-compatible simulation-framework to accommodate\ncharging strategies. Second, we introduce a novel RL design for tackling the\ncharging strategy problem. Finally, we introduce several novel adaptive\nbaseline heuristics and reproducibly evaluate the design using a Proximal\nPolicy Optimization agent and varying different design configurations, with a\nfocus on reward.",
      "tldr_zh": "该研究提出了一种新的 Reinforcement Learning (RL) 设计，用于优化 Autonomous Mobile Robots (AMR) 在大型仓库中的充电策略，并探讨了不同奖励和动作空间配置的影响。相比启发式基线策略，灵活的 RL 方法在服务时间上表现出显著优越性，但需要更长的收敛时间且稳定性较差，而基于领域的指导设计则更稳定但泛化潜力有限。贡献包括扩展了 SLAPStack 模拟框架以支持充电策略、引入新型 RL 设计和自适应基线启发式，并使用 Proximal Policy Optimization (PPO) 代理进行可复现评估。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review LION19: The 19th Learning and Intelligent OptimizatioN\n  Conference",
      "pdf_url": "http://arxiv.org/pdf/2505.11136v1",
      "published_date": "2025-05-16 11:33:29 UTC",
      "updated_date": "2025-05-16 11:33:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:56:24.246281"
    },
    {
      "arxiv_id": "2505.11135v1",
      "title": "Scalability of Reinforcement Learning Methods for Dispatching in Semiconductor Frontend Fabs: A Comparison of Open-Source Models with Real Industry Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Patrick Stöckermann",
        "Henning Südfeld",
        "Alessandro Immordino",
        "Thomas Altenmüller",
        "Marc Wegmann",
        "Martin Gebser",
        "Konstantin Schekotihin",
        "Georg Seidel",
        "Chew Wye Chan",
        "Fei Fei Zhang"
      ],
      "abstract": "Benchmark datasets are crucial for evaluating approaches to scheduling or\ndispatching in the semiconductor industry during the development and deployment\nphases. However, commonly used benchmark datasets like the Minifab or SMT2020\nlack the complex details and constraints found in real-world scenarios. To\nmitigate this shortcoming, we compare open-source simulation models with a real\nindustry dataset to evaluate how optimization methods scale with different\nlevels of complexity. Specifically, we focus on Reinforcement Learning methods,\nperforming optimization based on policy-gradient and Evolution Strategies. Our\nresearch provides insights into the effectiveness of these optimization methods\nand their applicability to realistic semiconductor frontend fab simulations. We\nshow that our proposed Evolution Strategies-based method scales much better\nthan a comparable policy-gradient-based approach. Moreover, we identify the\nselection and combination of relevant bottleneck tools to control by the agent\nas crucial for an efficient optimization. For the generalization across\ndifferent loading scenarios and stochastic tool failure patterns, we achieve\nadvantages when utilizing a diverse training dataset. While the overall\napproach is computationally expensive, it manages to scale well with the number\nof CPU cores used for training. For the real industry dataset, we achieve an\nimprovement of up to 4% regarding tardiness and up to 1% regarding throughput.\nFor the less complex open-source models Minifab and SMT2020, we observe\ndouble-digit percentage improvement in tardiness and single digit percentage\nimprovement in throughput by use of Evolution Strategies.",
      "tldr_zh": "该研究比较了开源模拟模型（如 Minifab 和 SMT2020）与真实行业数据集，评估了 Reinforcement Learning 方法（包括 policy-gradient 和 Evolution Strategies）在半导体前端工厂分派任务中的可扩展性。结果显示，Evolution Strategies-based 方法比 policy-gradient 方法扩展性更强，尤其在选择和组合瓶颈工具以及使用多样化训练数据集时，能更好地处理不同加载场景和随机工具故障。实验在真实数据集上实现了高达 4% 的延误减少和 1% 的吞吐量提升，而在开源模型上，则观察到双位数百分比的延误改善和单位数百分比的吞吐量提升，为实际优化应用提供了重要见解。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11135v1",
      "published_date": "2025-05-16 11:32:29 UTC",
      "updated_date": "2025-05-16 11:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:56:36.279736"
    },
    {
      "arxiv_id": "2505.11131v1",
      "title": "One Image is Worth a Thousand Words: A Usability Preservable Text-Image Collaborative Erasing Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Feiran Li",
        "Qianqian Xu",
        "Shilong Bao",
        "Zhiyong Yang",
        "Xiaochun Cao",
        "Qingming Huang"
      ],
      "abstract": "Concept erasing has recently emerged as an effective paradigm to prevent\ntext-to-image diffusion models from generating visually undesirable or even\nharmful content. However, current removal methods heavily rely on manually\ncrafted text prompts, making it challenging to achieve a high erasure\n(efficacy) while minimizing the impact on other benign concepts (usability). In\nthis paper, we attribute the limitations to the inherent gap between the text\nand image modalities, which makes it hard to transfer the intricately entangled\nconcept knowledge from text prompts to the image generation process. To address\nthis, we propose a novel solution by directly integrating visual supervision\ninto the erasure process, introducing the first text-image Collaborative\nConcept Erasing (Co-Erasing) framework. Specifically, Co-Erasing describes the\nconcept jointly by text prompts and the corresponding undesirable images\ninduced by the prompts, and then reduces the generating probability of the\ntarget concept through negative guidance. This approach effectively bypasses\nthe knowledge gap between text and image, significantly enhancing erasure\nefficacy. Additionally, we design a text-guided image concept refinement\nstrategy that directs the model to focus on visual features most relevant to\nthe specified text concept, minimizing disruption to other benign concepts.\nFinally, comprehensive experiments suggest that Co-Erasing outperforms\nstate-of-the-art erasure approaches significantly with a better trade-off\nbetween efficacy and usability. Codes are available at\nhttps://github.com/Ferry-Li/Co-Erasing.",
      "tldr_zh": "本文提出了一种文本-图像协作概念擦除（Co-Erasing）框架，用于文本到图像扩散模型（text-to-image diffusion models），以有效防止生成不 desirable 或有害内容，同时保持其他 benign 概念的 usability。框架通过结合文本提示和对应的 undesirable 图像进行联合描述，并采用负指导（negative guidance）来降低目标概念的生成概率，从而克服文本和图像模态之间的知识差距，提升擦除效果（efficacy）。此外，该方法引入文本引导的图像概念精炼策略，使模型专注于与指定文本概念相关的视觉特征，减少对无关概念的干扰。实验结果显示，Co-Erasing 在 efficacy 和 usability 之间实现了更好的 trade-off，比现有方法显著优越。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "This paper has been accepeted to ICML 2025. Not Final Version",
      "pdf_url": "http://arxiv.org/pdf/2505.11131v1",
      "published_date": "2025-05-16 11:25:50 UTC",
      "updated_date": "2025-05-16 11:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:56:48.494727"
    },
    {
      "arxiv_id": "2505.11129v1",
      "title": "PhiNet v2: A Mask-Free Brain-Inspired Vision Foundation Model from Video",
      "title_zh": "翻译失败",
      "authors": [
        "Makoto Yamada",
        "Kian Ming A. Chai",
        "Ayoub Rhim",
        "Satoki Ishikawa",
        "Mohammad Sabokrou",
        "Yao-Hung Hubert Tsai"
      ],
      "abstract": "Recent advances in self-supervised learning (SSL) have revolutionized\ncomputer vision through innovative architectures and learning objectives, yet\nthey have not fully leveraged insights from biological visual processing\nsystems. Recently, a brain-inspired SSL model named PhiNet was proposed; it is\nbased on a ResNet backbone and operates on static image inputs with strong\naugmentation. In this paper, we introduce PhiNet v2, a novel Transformer-based\narchitecture that processes temporal visual input (that is, sequences of\nimages) without relying on strong augmentation. Our model leverages variational\ninference to learn robust visual representations from continuous input streams,\nsimilar to human visual processing. Through extensive experimentation, we\ndemonstrate that PhiNet v2 achieves competitive performance compared to\nstate-of-the-art vision foundation models, while maintaining the ability to\nlearn from sequential input without strong data augmentation. This work\nrepresents a significant step toward more biologically plausible computer\nvision systems that process visual information in a manner more closely aligned\nwith human cognitive processes.",
      "tldr_zh": "本文提出PhiNet v2，一种基于Transformer的脑启发视觉基础模型，它处理视频输入（图像序列）而不依赖强数据增强，采用variational inference从连续输入流中学习鲁棒视觉表示，模拟人类视觉处理。相比前作PhiNet，该模型放弃了ResNet backbone，转向更高效的架构。实验结果表明，PhiNet v2在不使用强augmentation的情况下，性能与最先进视觉基础模型相当，并为开发更接近人类认知过程的计算机视觉系统提供了重要进展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2405.14650",
      "pdf_url": "http://arxiv.org/pdf/2505.11129v1",
      "published_date": "2025-05-16 11:23:30 UTC",
      "updated_date": "2025-05-16 11:23:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:56:59.699830"
    },
    {
      "arxiv_id": "2505.11123v1",
      "title": "Conditioning Matters: Training Diffusion Policies is Faster Than You Think",
      "title_zh": "条件至关重要：训练扩散策略比你想象的更快",
      "authors": [
        "Zibin Dong",
        "Yicheng Liu",
        "Yinchuan Li",
        "Hang Zhao",
        "Jianye Hao"
      ],
      "abstract": "Diffusion policies have emerged as a mainstream paradigm for building\nvision-language-action (VLA) models. Although they demonstrate strong robot\ncontrol capabilities, their training efficiency remains suboptimal. In this\nwork, we identify a fundamental challenge in conditional diffusion policy\ntraining: when generative conditions are hard to distinguish, the training\nobjective degenerates into modeling the marginal action distribution, a\nphenomenon we term loss collapse. To overcome this, we propose Cocos, a simple\nyet general solution that modifies the source distribution in the conditional\nflow matching to be condition-dependent. By anchoring the source distribution\naround semantics extracted from condition inputs, Cocos encourages stronger\ncondition integration and prevents the loss collapse. We provide theoretical\njustification and extensive empirical results across simulation and real-world\nbenchmarks. Our method achieves faster convergence and higher success rates\nthan existing approaches, matching the performance of large-scale pre-trained\nVLAs using significantly fewer gradient steps and parameters. Cocos is\nlightweight, easy to implement, and compatible with diverse policy\narchitectures, offering a general-purpose improvement to diffusion policy\ntraining.",
      "tldr_zh": "扩散策略（Diffusion policies）在构建视觉-语言-动作（VLA）模型方面表现出色，但训练效率较低，主要由于条件难以区分导致的损失坍缩（loss collapse）问题，使训练目标退化成建模边缘动作分布。论文提出Cocos方法，通过修改条件流匹配（conditional flow matching）中的源分布，使其依赖于从条件输入提取的语义，从而加强条件整合并防止损失坍缩。实验结果显示，Cocos在模拟和真实世界基准上实现更快收敛和更高成功率，仅需更少的梯度步骤和参数即可匹配大型预训练VLA模型的表现，提供了一种轻量级、通用的扩散策略训练改进。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2505.10105",
      "pdf_url": "http://arxiv.org/pdf/2505.11123v1",
      "published_date": "2025-05-16 11:14:22 UTC",
      "updated_date": "2025-05-16 11:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:57:12.658159"
    },
    {
      "arxiv_id": "2505.11122v1",
      "title": "Navigating the Alpha Jungle: An LLM-Powered MCTS Framework for Formulaic Factor Mining",
      "title_zh": "翻译失败",
      "authors": [
        "Yu Shi",
        "Yitong Duan",
        "Jian Li"
      ],
      "abstract": "Alpha factor mining is pivotal in quantitative investment for identifying\npredictive signals from complex financial data. While traditional formulaic\nalpha mining relies on human expertise, contemporary automated methods, such as\nthose based on genetic programming or reinforcement learning, often suffer from\nsearch inefficiency or yield poorly interpretable alpha factors. This paper\nintroduces a novel framework that integrates Large Language Models (LLMs) with\nMonte Carlo Tree Search (MCTS) to overcome these limitations. Our approach\nleverages the LLM's instruction-following and reasoning capability to\niteratively generate and refine symbolic alpha formulas within an MCTS-driven\nexploration. A key innovation is the guidance of MCTS exploration by rich,\nquantitative feedback from financial backtesting of each candidate factor,\nenabling efficient navigation of the vast search space. Furthermore, a frequent\nsubtree avoidance mechanism is introduced to bolster search efficiency and\nalpha factor performance. Experimental results on real-world stock market data\ndemonstrate that our LLM-based framework outperforms existing methods by mining\nalphas with superior predictive accuracy, trading performance, and improved\ninterpretability, while offering a more efficient solution for formulaic alpha\nmining.",
      "tldr_zh": "这篇论文提出了一种整合 Large Language Models (LLMs) 和 Monte Carlo Tree Search (MCTS) 的新框架，用于 formulaic alpha mining，以解决传统量化投资方法在搜索效率和 alpha 因子可解释性上的局限。框架利用 LLM 的指令遵循和推理能力，在 MCTS 驱动的探索中迭代生成并优化符号 alpha 公式，同时通过金融回测的量化反馈和频繁子树避免机制提升搜索空间导航效率。实验结果显示，该框架在真实股票市场数据上比现有方法表现出色，挖掘的 alpha 因子具有更高的预测准确性、交易性能和可解释性，提供了一种更高效的解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "30 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11122v1",
      "published_date": "2025-05-16 11:14:17 UTC",
      "updated_date": "2025-05-16 11:14:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:57:24.732102"
    },
    {
      "arxiv_id": "2505.11119v1",
      "title": "Predicting Student Dropout Risk With A Dual-Modal Abrupt Behavioral Changes Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Jiabei Cheng",
        "Zhen-Qun Yang",
        "Jiannong Cao",
        "Yu Yang",
        "Xinzhe Zheng"
      ],
      "abstract": "Timely prediction of students at high risk of dropout is critical for early\nintervention and improving educational outcomes. However, in offline\neducational settings, poor data quality, limited scale, and high heterogeneity\noften hinder the application of advanced machine learning models. Furthermore,\nwhile educational theories provide valuable insights into dropout phenomena,\nthe lack of quantifiable metrics for key indicators limits their use in\ndata-driven modeling. Through data analysis and a review of educational\nliterature, we identified abrupt changes in student behavior as key early\nsignals of dropout risk. To address this, we propose the Dual-Modal Multiscale\nSliding Window (DMSW) Model, which integrates academic performance and\nbehavioral data to dynamically capture behavior patterns using minimal data.\nThe DMSW model improves prediction accuracy by 15% compared to traditional\nmethods, enabling educators to identify high-risk students earlier, provide\ntimely support, and foster a more inclusive learning environment. Our analysis\nhighlights key behavior patterns, offering practical insights for preventive\nstrategies and tailored support. These findings bridge the gap between theory\nand practice in dropout prediction, giving educators an innovative tool to\nenhance student retention and outcomes.",
      "tldr_zh": "该研究针对线下教育环境中数据质量差和异质性高等问题，提出了一种基于双模态（Dual-Modal）突变行为变化的方法来预测学生辍学风险。通过分析学生行为的突然变化作为早期信号，开发了Multiscale Sliding Window (DMSW) 模型，该模型整合学术表现和行为数据，使用最小数据动态捕获行为模式。实验结果显示，DMSW 模型比传统方法提高了15%的预测准确率，帮助教育者及早识别高风险学生并提供及时支持，从而桥接教育理论与实践，促进学生保留和包容性学习环境。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11119v1",
      "published_date": "2025-05-16 11:02:55 UTC",
      "updated_date": "2025-05-16 11:02:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:57:36.161295"
    },
    {
      "arxiv_id": "2505.11111v1",
      "title": "FairSHAP: Preprocessing for Fairness Through Attribution-Based Data Augmentation",
      "title_zh": "FairSHAP：基于归因的数据增强实现公平性的预",
      "authors": [
        "Lin Zhu",
        "Yijun Bian",
        "Lei You"
      ],
      "abstract": "Ensuring fairness in machine learning models is critical, particularly in\nhigh-stakes domains where biased decisions can lead to serious societal\nconsequences. Existing preprocessing approaches generally lack transparent\nmechanisms for identifying which features or instances are responsible for\nunfairness. This obscures the rationale behind data modifications. We introduce\nFairSHAP, a novel pre-processing framework that leverages Shapley value\nattribution to improve both individual and group fairness. FairSHAP identifies\nfairness-critical instances in the training data using an interpretable measure\nof feature importance, and systematically modifies them through instance-level\nmatching across sensitive groups. This process reduces discriminative risk - an\nindividual fairness metric - while preserving data integrity and model\naccuracy. We demonstrate that FairSHAP significantly improves demographic\nparity and equality of opportunity across diverse tabular datasets, achieving\nfairness gains with minimal data perturbation and, in some cases, improved\npredictive performance. As a model-agnostic and transparent method, FairSHAP\nintegrates seamlessly into existing machine learning pipelines and provides\nactionable insights into the sources of bias.Our code is on\nhttps://github.com/youlei202/FairSHAP.",
      "tldr_zh": "FairSHAP 是一种新型预处理框架，通过基于 Shapley value 归因的数据增强方法来提升机器学习模型的个体和群体公平性。它首先使用可解释的特征重要性度量识别训练数据中的公平性关键实例，然后通过实例级匹配跨敏感群体修改这些实例，从而减少鉴别风险并保持数据完整性和模型准确性。在多种表格数据集上，FairSHAP 显著改善了 demographic parity 和 equality of opportunity，同时最小化数据扰动，有时甚至提升预测性能。作为一个模型无关且透明的方法，FairSHAP 可无缝集成到现有机器学习管道中，并提供关于偏见来源的可操作洞见。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.LG",
      "comment": "3 figures, 15 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11111v1",
      "published_date": "2025-05-16 10:48:19 UTC",
      "updated_date": "2025-05-16 10:48:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:57:48.872547"
    },
    {
      "arxiv_id": "2505.11109v1",
      "title": "MAVOS-DD: Multilingual Audio-Video Open-Set Deepfake Detection Benchmark",
      "title_zh": "MAVOS-DD：多语言音视频开集深度伪造检测基准",
      "authors": [
        "Florinel-Alin Croitoru",
        "Vlad Hondru",
        "Marius Popescu",
        "Radu Tudor Ionescu",
        "Fahad Shahbaz Khan",
        "Mubarak Shah"
      ],
      "abstract": "We present the first large-scale open-set benchmark for multilingual\naudio-video deepfake detection. Our dataset comprises over 250 hours of real\nand fake videos across eight languages, with 60% of data being generated. For\neach language, the fake videos are generated with seven distinct deepfake\ngeneration models, selected based on the quality of the generated content. We\norganize the training, validation and test splits such that only a subset of\nthe chosen generative models and languages are available during training, thus\ncreating several challenging open-set evaluation setups. We perform experiments\nwith various pre-trained and fine-tuned deepfake detectors proposed in recent\nliterature. Our results show that state-of-the-art detectors are not currently\nable to maintain their performance levels when tested in our open-set\nscenarios. We publicly release our data and code at:\nhttps://huggingface.co/datasets/unibuc-cs/MAVOS-DD.",
      "tldr_zh": "本论文提出了MAVOS-DD，这是一个首创的大型多语言音频-视频开放集深度伪造检测基准数据集，涵盖八种语言的超过250小时真实和伪造视频，其中60%由七种高质量深度伪造生成模型创建。数据集通过设计训练集仅包括部分生成模型和语言，构建了多个挑战性的开放集评估场景，以测试检测器的泛化能力。实验结果显示，现有的预训练和微调深度伪造检测器在这些开放集条件下无法维持原有性能水平。数据和代码已公开在https://huggingface.co/datasets/unibuc-cs/MAVOS-DD。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.11109v1",
      "published_date": "2025-05-16 10:42:30 UTC",
      "updated_date": "2025-05-16 10:42:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:58:01.123825"
    },
    {
      "arxiv_id": "2505.11108v1",
      "title": "PARSEC: Preference Adaptation for Robotic Object Rearrangement from Scene Context",
      "title_zh": "PARSEC：基于场景上下文的机器人物体重新排列偏好适应",
      "authors": [
        "Kartik Ramachandruni",
        "Sonia Chernova"
      ],
      "abstract": "Object rearrangement is a key task for household robots requiring\npersonalization without explicit instructions, meaningful object placement in\nenvironments occupied with objects, and generalization to unseen objects and\nnew environments. To facilitate research addressing these challenges, we\nintroduce PARSEC, an object rearrangement benchmark for learning user\norganizational preferences from observed scene context to place objects in a\npartially arranged environment. PARSEC is built upon a novel dataset of 110K\nrearrangement examples crowdsourced from 72 users, featuring 93 object\ncategories and 15 environments. We also propose ContextSortLM, an LLM-based\nrearrangement model that places objects in partially arranged environments by\nadapting to user preferences from prior and current scene context while\naccounting for multiple valid placements. We evaluate ContextSortLM and\nexisting personalized rearrangement approaches on the PARSEC benchmark and\ncomplement these findings with a crowdsourced evaluation of 108 online raters\nranking model predictions based on alignment with user preferences. Our results\nindicate that personalized rearrangement models leveraging multiple scene\ncontext sources perform better than models relying on a single context source.\nMoreover, ContextSortLM outperforms other models in placing objects to\nreplicate the target user's arrangement and ranks among the top two in all\nthree environment categories, as rated by online evaluators. Importantly, our\nevaluation highlights challenges associated with modeling environment semantics\nacross different environment categories and provides recommendations for future\nwork.",
      "tldr_zh": "该论文引入了 PARSEC 基准，这是一个用于机器人物体重新排列的测试平台，能够从观察到的场景上下文学习用户组织偏好，并在部分安排的环境中放置物体。PARSEC 基于一个包含 110K 个示例的新数据集，由 72 名用户众包，涵盖 93 个物体类别和 15 个环境。作者提出 ContextSortLM，一种基于 LLM 的模型，通过整合多个场景上下文来源来适应用户偏好并处理多个有效放置选项；实验结果显示，ContextSortLM 在 PARSEC 基准上优于其他方法，在复制用户安排方面排名前二，并强调了建模不同环境语义的挑战，为未来研究提供建议。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Under review at ROMAN 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.11108v1",
      "published_date": "2025-05-16 10:40:44 UTC",
      "updated_date": "2025-05-16 10:40:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:58:13.654033"
    },
    {
      "arxiv_id": "2505.11107v1",
      "title": "Group Think: Multiple Concurrent Reasoning Agents Collaborating at Token Level Granularity",
      "title_zh": "翻译失败",
      "authors": [
        "Chan-Jan Hsu",
        "Davide Buffelli",
        "Jamie McGowan",
        "Feng-Ting Liao",
        "Yi-Chang Chen",
        "Sattar Vakili",
        "Da-shan Shiu"
      ],
      "abstract": "Recent advances in large language models (LLMs) have demonstrated the power\nof reasoning through self-generated chains of thought. Multiple reasoning\nagents can collaborate to raise joint reasoning quality above individual\noutcomes. However, such agents typically interact in a turn-based manner,\ntrading increased latency for improved quality. In this paper, we propose Group\nThink--a single LLM that acts as multiple concurrent reasoning agents, or\nthinkers. With shared visibility into each other's partial generation progress,\nGroup Think introduces a new concurrent-reasoning paradigm in which multiple\nreasoning trajectories adapt dynamically to one another at the token level. For\nexample, a reasoning thread may shift its generation mid-sentence upon\ndetecting that another thread is better positioned to continue. This\nfine-grained, token-level collaboration enables Group Think to reduce redundant\nreasoning and improve quality while achieving significantly lower latency.\nMoreover, its concurrent nature allows for efficient utilization of idle\ncomputational resources, making it especially suitable for edge inference,\nwhere very small batch size often underutilizes local~GPUs. We give a simple\nand generalizable modification that enables any existing LLM to perform Group\nThink on a local GPU. We also present an evaluation strategy to benchmark\nreasoning latency and empirically demonstrate latency improvements using\nopen-source LLMs that were not explicitly trained for Group Think. We hope this\nwork paves the way for future LLMs to exhibit more sophisticated and more\nefficient collaborative behavior for higher quality generation.",
      "tldr_zh": "该论文提出 Group Think 框架，利用单一大型语言模型（LLMs）模拟多个并发推理代理（thinkers），实现 token 级别的动态协作，以提升推理质量并减少延迟。不同于传统的轮流交互方式，Group Think 允许代理共享生成进度，并在检测到更优路径时实时调整推理轨迹，从而减少冗余和提高效率。实验结果显示，该方法在开源 LLMs 上显著降低了推理延迟，并适用于边缘推理场景，为未来 LLM 的协作行为提供了一个简单、可推广的修改方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11107v1",
      "published_date": "2025-05-16 10:40:35 UTC",
      "updated_date": "2025-05-16 10:40:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:58:24.395979"
    },
    {
      "arxiv_id": "2505.11106v1",
      "title": "Inferring the Most Similar Variable-length Subsequences between Multidimensional Time Series",
      "title_zh": "在多维时间序列之间推断最相似的可变长度子序列",
      "authors": [
        "Thanadej Rattanakornphan",
        "Piyanon Charoenpoonpanich",
        "Chainarong Amornbunchornvej"
      ],
      "abstract": "Finding the most similar subsequences between two multidimensional time\nseries has many applications: e.g. capturing dependency in stock market or\ndiscovering coordinated movement of baboons. Considering one pattern occurring\nin one time series, we might be wondering whether the same pattern occurs in\nanother time series with some distortion that might have a different length.\nNevertheless, to the best of our knowledge, there is no efficient framework\nthat deals with this problem yet. In this work, we propose an algorithm that\nprovides the exact solution of finding the most similar multidimensional\nsubsequences between time series where there is a difference in length both\nbetween time series and between subsequences. The algorithm is built based on\ntheoretical guarantee of correctness and efficiency. The result in simulation\ndatasets illustrated that our approach not just only provided correct solution,\nbut it also utilized running time only quarter of time compared against the\nbaseline approaches. In real-world datasets, it extracted the most similar\nsubsequences even faster (up to 20 times faster against baseline methods) and\nprovided insights regarding the situation in stock market and following\nrelations of multidimensional time series of baboon movement. Our approach can\nbe used for any time series. The code and datasets of this work are provided\nfor the public use.",
      "tldr_zh": "这篇论文提出了一种算法，用于在多维时间序列（multidimensional time series）之间推断最相似的可变长度子序列，解决了现有方法在处理长度差异和扭曲问题上的不足。该算法基于理论保证的正确性和效率，能够精确识别子序列，并在模拟数据集上运行时间仅为基线方法的四分之一，在真实数据集上快达20倍，同时为股票市场依赖性和狒狒运动协调提供洞见。代码和数据集已公开，适用于任何时间序列分析。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "Under review",
      "pdf_url": "http://arxiv.org/pdf/2505.11106v1",
      "published_date": "2025-05-16 10:39:46 UTC",
      "updated_date": "2025-05-16 10:39:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:58:35.862334"
    },
    {
      "arxiv_id": "2505.11100v1",
      "title": "Bidirectional Distillation: A Mixed-Play Framework for Multi-Agent Generalizable Behaviors",
      "title_zh": "双向蒸馏：一种用于多智能体可泛化行为的混合游戏框架",
      "authors": [
        "Lang Feng",
        "Jiahao Lin",
        "Dong Xing",
        "Li Zhang",
        "De Ma",
        "Gang Pan"
      ],
      "abstract": "Population-population generalization is a challenging problem in multi-agent\nreinforcement learning (MARL), particularly when agents encounter unseen\nco-players. However, existing self-play-based methods are constrained by the\nlimitation of inside-space generalization. In this study, we propose\nBidirectional Distillation (BiDist), a novel mixed-play framework, to overcome\nthis limitation in MARL. BiDist leverages knowledge distillation in two\nalternating directions: forward distillation, which emulates the historical\npolicies' space and creates an implicit self-play, and reverse distillation,\nwhich systematically drives agents towards novel distributions outside the\nknown policy space in a non-self-play manner. In addition, BiDist operates as a\nconcise and efficient solution without the need for the complex and costly\nstorage of past policies. We provide both theoretical analysis and empirical\nevidence to support BiDist's effectiveness. Our results highlight its\nremarkable generalization ability across a variety of cooperative, competitive,\nand social dilemma tasks, and reveal that BiDist significantly diversifies the\npolicy distribution space. We also present comprehensive ablation studies to\nreinforce BiDist's effectiveness and key success factors. Source codes are\navailable in the supplementary material.",
      "tldr_zh": "本文提出 Bidirectional Distillation (BiDist)，一个新型混合玩框架，用于解决多智能体强化学习 (MARL) 中的种群-种群泛化问题，特别是面对未见过的合作者时的挑战。BiDist 通过双向知识蒸馏实现：forward distillation 模拟历史策略空间以创建隐式 self-play，而 reverse distillation 则驱动智能体向已知策略空间外的全新分布发展，从而增强泛化能力。该框架无需存储复杂的历史策略，实验在合作、竞争和社会困境任务中显示 BiDist 显著扩展了策略分布空间，并比基线方法表现出色，支持其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11100v1",
      "published_date": "2025-05-16 10:31:10 UTC",
      "updated_date": "2025-05-16 10:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:58:48.964397"
    },
    {
      "arxiv_id": "2505.11086v1",
      "title": "Analysis of Customer Journeys Using Prototype Detection and Counterfactual Explanations for Sequential Data",
      "title_zh": "翻译失败",
      "authors": [
        "Keita Kinjo"
      ],
      "abstract": "Recently, the proliferation of omni-channel platforms has attracted interest\nin customer journeys, particularly regarding their role in developing marketing\nstrategies. However, few efforts have been taken to quantitatively study or\ncomprehensively analyze them owing to the sequential nature of their data and\nthe complexity involved in analysis. In this study, we propose a novel approach\ncomprising three steps for analyzing customer journeys. First, the distance\nbetween sequential data is defined and used to identify and visualize\nrepresentative sequences. Second, the likelihood of purchase is predicted based\non this distance. Third, if a sequence suggests no purchase, counterfactual\nsequences are recommended to increase the probability of a purchase using a\nproposed method, which extracts counterfactual explanations for sequential\ndata. A survey was conducted, and the data were analyzed; the results revealed\nthat typical sequences could be extracted, and the parts of those sequences\nimportant for purchase could be detected. We believe that the proposed approach\ncan support improvements in various marketing activities.",
      "tldr_zh": "本研究针对客户旅程（customer journeys）的分析提出了一种新方法，利用原型检测（prototype detection）和反事实解释（counterfactual explanations）处理序列数据（sequential data）。该方法包括三个步骤：首先定义序列数据之间的距离，以识别和可视化代表性序列；其次基于此距离预测购买可能性；第三，如果序列显示无购买倾向，则推荐反事实序列来提升购买概率。实验通过调查数据分析发现，该方法能有效提取典型序列并检测其对购买的关键部分，从而支持营销策略的优化和改进。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "19 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11086v1",
      "published_date": "2025-05-16 10:17:53 UTC",
      "updated_date": "2025-05-16 10:17:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:59:00.289107"
    },
    {
      "arxiv_id": "2505.11085v1",
      "title": "A Fast Kernel-based Conditional Independence test with Application to Causal Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Oliver Schacht",
        "Biwei Huang"
      ],
      "abstract": "Kernel-based conditional independence (KCI) testing is a powerful\nnonparametric method commonly employed in causal discovery tasks. Despite its\nflexibility and statistical reliability, cubic computational complexity limits\nits application to large datasets. To address this computational bottleneck, we\npropose \\textit{FastKCI}, a scalable and parallelizable kernel-based\nconditional independence test that utilizes a mixture-of-experts approach\ninspired by embarrassingly parallel inference techniques for Gaussian\nprocesses. By partitioning the dataset based on a Gaussian mixture model over\nthe conditioning variables, FastKCI conducts local KCI tests in parallel,\naggregating the results using an importance-weighted sampling scheme.\nExperiments on synthetic datasets and benchmarks on real-world production data\nvalidate that FastKCI maintains the statistical power of the original KCI test\nwhile achieving substantial computational speedups. FastKCI thus represents a\npractical and efficient solution for conditional independence testing in causal\ninference on large-scale data.",
      "tldr_zh": "该研究针对核基条件独立性（KCI）测试在因果发现（Causal Discovery）中的高立方计算复杂度问题，提出了一种高效的FastKCI方法，利用混合专家（mixture-of-experts）方法和Gaussian mixture model对条件变量进行分区。FastKCI通过并行进行本地KCI测试，并采用重要性加权采样（importance-weighted sampling）聚合结果，从而实现可扩展和并行计算。实验在合成数据集和真实世界数据上验证，FastKCI保持了原KCI测试的统计功效，同时显著提高了计算速度，为大规模数据下的因果推理提供了实用解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11085v1",
      "published_date": "2025-05-16 10:14:57 UTC",
      "updated_date": "2025-05-16 10:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:59:12.553065"
    },
    {
      "arxiv_id": "2505.11083v1",
      "title": "Fault Diagnosis across Heterogeneous Domains via Self-Adaptive Temporal-Spatial Attention and Sample Generation",
      "title_zh": "通过自适应时空注意力和样本生成进行跨异构领域的故障诊断",
      "authors": [
        "Guangqiang Li",
        "M. Amine Atoui",
        "Xiangshun Li"
      ],
      "abstract": "Deep learning methods have shown promising performance in fault diagnosis for\nmultimode process. Most existing studies assume that the collected health state\ncategories from different operating modes are identical. However, in real\nindustrial scenarios, these categories typically exhibit only partial overlap.\nThe incompleteness of the available data and the large distributional\ndifferences between the operating modes pose a significant challenge to\nexisting fault diagnosis methods. To address this problem, a novel fault\ndiagnosis model named self-adaptive temporal-spatial attention network\n(TSA-SAN) is proposed. First, inter-mode mappings are constructed using healthy\ncategory data to generate multimode samples. To enrich the diversity of the\nfault data, interpolation is performed between healthy and fault samples.\nSubsequently, the fault diagnosis model is trained using real and generated\ndata. The self-adaptive instance normalization is established to suppress\nirrelevant information while retaining essential statistical features for\ndiagnosis. In addition, a temporal-spatial attention mechanism is constructed\nto focus on the key features, thus enhancing the generalization ability of the\nmodel. The extensive experiments demonstrate that the proposed model\nsignificantly outperforms the state-of-the-art methods. The code will be\navailable on Github at https://github.com/GuangqiangLi/TSA-SAN.",
      "tldr_zh": "本文提出了一种新型故障诊断模型 self-adaptive temporal-spatial attention network (TSA-SAN)，旨在解决多模式过程诊断中健康状态类别仅部分重叠、数据不完整和分布差异大的问题。该模型首先利用健康类别数据构建模式间映射，生成多模式样本，并通过健康和故障样本插值丰富数据多样性；随后引入 self-adaptive instance normalization 抑制无关信息，以及 temporal-spatial attention 机制聚焦关键特征，以提升模型的泛化能力。实验结果显示，TSA-SAN 在广泛测试中显著优于现有最先进方法，为实际工业场景的异构域故障诊断提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11083v1",
      "published_date": "2025-05-16 10:14:10 UTC",
      "updated_date": "2025-05-16 10:14:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:59:25.361785"
    },
    {
      "arxiv_id": "2505.11080v1",
      "title": "BLEUBERI: BLEU is a surprisingly effective reward for instruction following",
      "title_zh": "翻译失败",
      "authors": [
        "Yapei Chang",
        "Yekyung Kim",
        "Michael Krumdick",
        "Amir Zadeh",
        "Chuan Li",
        "Chris Tanner",
        "Mohit Iyyer"
      ],
      "abstract": "Reward models are central to aligning LLMs with human preferences, but they\nare costly to train, requiring large-scale human-labeled preference data and\npowerful pretrained LLM backbones. Meanwhile, the increasing availability of\nhigh-quality synthetic instruction-following datasets raises the question: can\nsimpler, reference-based metrics serve as viable alternatives to reward models\nduring RL-based alignment? In this paper, we show first that BLEU, a basic\nstring-matching metric, surprisingly matches strong reward models in agreement\nwith human preferences on general instruction-following datasets. Based on this\ninsight, we develop BLEUBERI, a method that first identifies challenging\ninstructions and then applies Group Relative Policy Optimization (GRPO) using\nBLEU directly as the reward function. We demonstrate that BLEUBERI-trained\nmodels are competitive with models trained via reward model-guided RL across\nfour challenging instruction-following benchmarks and three different base\nlanguage models. A human evaluation further supports that the quality of\nBLEUBERI model outputs is on par with those from reward model-aligned models.\nMoreover, BLEUBERI models generate outputs that are more factually grounded\nthan competing methods. Overall, we show that given access to high-quality\nreference outputs (easily obtained via existing instruction-following datasets\nor synthetic data generation), string matching-based metrics are cheap yet\neffective proxies for reward models during alignment. We release our code and\ndata at https://github.com/lilakk/BLEUBERI.",
      "tldr_zh": "该研究发现，BLEU（一个基本的字符串匹配指标）在指令跟随任务中，与强大的reward models在人类偏好一致性上表现相当，从而挑战了传统reward models的必要性。论文提出了BLEUBERI方法，该方法首先识别具有挑战性的指令，然后应用Group Relative Policy Optimization (GRPO)，直接使用BLEU作为奖励函数进行RL-based alignment。实验结果显示，BLEUBERI训练的模型在四个指令跟随基准和三个不同基础语言模型上，与reward model引导的模型竞争力相当，并在人类评估中表现出输出质量相当且更注重事实基础。总体而言，这证明了在有高质量参考输出时，基于字符串匹配的指标如BLEU可以作为廉价有效的reward models替代。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "28 pages, 11 figures, 15 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.11080v1",
      "published_date": "2025-05-16 10:11:43 UTC",
      "updated_date": "2025-05-16 10:11:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:59:40.035238"
    },
    {
      "arxiv_id": "2505.11570v1",
      "title": "Tool-Aided Evolutionary LLM for Generative Policy Toward Efficient Resource Management in Wireless Federated Learning",
      "title_zh": "工具辅助的演化型 LLM 用于生成策略，以实现无线联邦学习中的高效资源管理",
      "authors": [
        "Chongyang Tan",
        "Ruoqi Wen",
        "Rongpeng Li",
        "Zhifeng Zhao",
        "Ekram Hossain",
        "Honggang Zhang"
      ],
      "abstract": "Federated Learning (FL) enables distributed model training across edge\ndevices in a privacy-friendly manner. However, its efficiency heavily depends\non effective device selection and high-dimensional resource allocation in\ndynamic and heterogeneous wireless environments. Conventional methods demand a\nconfluence of domain-specific expertise, extensive hyperparameter tuning,\nand/or heavy interaction cost. This paper proposes a Tool-aided Evolutionary\nLarge Language Model (T-ELLM) framework to generate a qualified policy for\ndevice selection in a wireless FL environment. Unlike conventional optimization\nmethods, T-ELLM leverages natural language-based scenario prompts to enhance\ngeneralization across varying network conditions. The framework decouples the\njoint optimization problem mathematically, enabling tractable learning of\ndevice selection policies while delegating resource allocation to convex\noptimization tools. To improve adaptability, T-ELLM integrates a\nsample-efficient, model-based virtual learning environment that captures the\nrelationship between device selection and learning performance, facilitating\nsubsequent group relative policy optimization. This concerted approach reduces\nreliance on real-world interactions, minimizing communication overhead while\nmaintaining high-fidelity decision-making. Theoretical analysis proves that the\ndiscrepancy between virtual and real environments is bounded, ensuring the\nadvantage function learned in the virtual environment maintains a provably\nsmall deviation from real-world conditions. Experimental results demonstrate\nthat T-ELLM outperforms benchmark methods in energy efficiency and exhibits\nrobust adaptability to environmental changes.",
      "tldr_zh": "本研究针对 Federated Learning (FL) 在动态无线环境中的设备选择和高维资源分配挑战，提出了一种 Tool-aided Evolutionary Large Language Model (T-ELLM) 框架，用于生成高效的设备选择策略。T-ELLM 通过自然语言提示解耦联合优化问题，结合虚拟学习环境和凸优化工具，实现样例高效的策略优化，从而减少真实交互开销并提升适应性。实验结果表明，该框架在能效上优于基准方法，并对环境变化表现出鲁棒性能，同时理论分析证明虚拟环境与真实环境的偏差可控。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11570v1",
      "published_date": "2025-05-16 10:07:29 UTC",
      "updated_date": "2025-05-16 10:07:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-24T23:59:48.830521"
    },
    {
      "arxiv_id": "2505.11569v1",
      "title": "Towards Adaptive Deep Learning: Model Elasticity via Prune-and-Grow CNN Architectures",
      "title_zh": "翻译失败",
      "authors": [
        "Pooja Mangal",
        "Sudaksh Kalra",
        "Dolly Sapra"
      ],
      "abstract": "Deploying deep convolutional neural networks (CNNs) on resource-constrained\ndevices presents significant challenges due to their high computational demands\nand rigid, static architectures. To overcome these limitations, this thesis\nexplores methods for enabling CNNs to dynamically adjust their computational\ncomplexity based on available hardware resources. We introduce adaptive CNN\narchitectures capable of scaling their capacity at runtime, thus efficiently\nbalancing performance and resource utilization. To achieve this adaptability,\nwe propose a structured pruning and dynamic re-construction approach that\ncreates nested subnetworks within a single CNN model. This approach allows the\nnetwork to dynamically switch between compact and full-sized configurations\nwithout retraining, making it suitable for deployment across varying hardware\nplatforms. Experiments conducted across multiple CNN architectures including\nVGG-16, AlexNet, ResNet-20, and ResNet-56 on CIFAR-10 and Imagenette datasets\ndemonstrate that adaptive models effectively maintain or even enhance\nperformance under varying computational constraints. Our results highlight that\nembedding adaptability directly into CNN architectures significantly improves\ntheir robustness and flexibility, paving the way for efficient real-world\ndeployment in diverse computational environments.",
      "tldr_zh": "该论文探讨了在资源受限设备上部署 CNN（Convolutional Neural Networks）的挑战，提出了一种自适应深度学习方法，通过 Prune-and-Grow 架构实现模型弹性。该方法采用结构化剪枝和动态重建技术，在单个 CNN 模型中创建嵌套子网络，允许模型在运行时根据硬件资源动态切换紧凑或全尺寸配置，而无需重新训练。在 CIFAR-10 和 Imagenette 数据集上的实验中，包括 VGG-16、AlexNet、ResNet-20 和 ResNet-56 等架构，显示自适应模型在不同计算约束下维持或提升性能，从而提高了 CNN 的鲁棒性和灵活性，便于在多样化环境中部署。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "50 Pages, 11 figures, Preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.11569v1",
      "published_date": "2025-05-16 10:06:55 UTC",
      "updated_date": "2025-05-16 10:06:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:00:00.665088"
    },
    {
      "arxiv_id": "2505.11070v1",
      "title": "Towards Self-Improvement of Diffusion Models via Group Preference Optimization",
      "title_zh": "朝向扩散模型的自我改进：通过群体偏好优化",
      "authors": [
        "Renjie Chen",
        "Wenfeng Lin",
        "Yichen Zhang",
        "Jiangchuan Wei",
        "Boyuan Liu",
        "Chao Feng",
        "Jiao Ran",
        "Mingyu Guo"
      ],
      "abstract": "Aligning text-to-image (T2I) diffusion models with Direct Preference\nOptimization (DPO) has shown notable improvements in generation quality.\nHowever, applying DPO to T2I faces two challenges: the sensitivity of DPO to\npreference pairs and the labor-intensive process of collecting and annotating\nhigh-quality data. In this work, we demonstrate that preference pairs with\nmarginal differences can degrade DPO performance. Since DPO relies exclusively\non relative ranking while disregarding the absolute difference of pairs, it may\nmisclassify losing samples as wins, or vice versa. We empirically show that\nextending the DPO from pairwise to groupwise and incorporating reward\nstandardization for reweighting leads to performance gains without explicit\ndata selection. Furthermore, we propose Group Preference Optimization (GPO), an\neffective self-improvement method that enhances performance by leveraging the\nmodel's own capabilities without requiring external data. Extensive experiments\ndemonstrate that GPO is effective across various diffusion models and tasks.\nSpecifically, combining with widely used computer vision models, such as YOLO\nand OCR, the GPO improves the accurate counting and text rendering capabilities\nof the Stable Diffusion 3.5 Medium by 20 percentage points. Notably, as a\nplug-and-play method, no extra overhead is introduced during inference.",
      "tldr_zh": "这篇论文针对文本到图像 (T2I) 扩散模型的优化问题，提出 Group Preference Optimization (GPO)，通过将 Direct Preference Optimization (DPO) 从成对偏好扩展到成组偏好，并加入奖励标准化来重新加权，从而减少对高质数据的需求并提升模型性能。GPO 是一种自我提升方法，利用模型自身能力生成偏好对，而无需外部数据支持。实验结果显示，GPO 在多种扩散模型和任务中有效，例如结合 YOLO 和 OCR 模型后，使 Stable Diffusion 3.5 Medium 的准确计数和文本渲染能力提高 20 百分点，且作为即插即用方法不增加推理开销。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11070v1",
      "published_date": "2025-05-16 10:04:57 UTC",
      "updated_date": "2025-05-16 10:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:00:12.852339"
    },
    {
      "arxiv_id": "2505.11067v1",
      "title": "Assessing the Performance of Analog Training for Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Omobayode Fagbohungbe",
        "Corey Lammie",
        "Malte J. Rasch",
        "Takashi Ando",
        "Tayfun Gokmen",
        "Vijay Narayanan"
      ],
      "abstract": "Analog in-memory computing is a next-generation computing paradigm that\npromises fast, parallel, and energy-efficient deep learning training and\ntransfer learning (TL). However, achieving this promise has remained elusive\ndue to a lack of suitable training algorithms. Analog memory devices exhibit\nasymmetric and non-linear switching behavior in addition to device-to-device\nvariation, meaning that most, if not all, of the current off-the-shelf training\nalgorithms cannot achieve good training outcomes. Also, recently introduced\nalgorithms have enjoyed limited attention, as they require bi-directionally\nswitching devices of unrealistically high symmetry and precision and are highly\nsensitive. A new algorithm chopped TTv2 (c-TTv2), has been introduced, which\nleverages the chopped technique to address many of the challenges mentioned\nabove. In this paper, we assess the performance of the c-TTv2 algorithm for\nanalog TL using a Swin-ViT model on a subset of the CIFAR100 dataset. We also\ninvestigate the robustness of our algorithm to changes in some device\nspecifications, including weight transfer noise, symmetry point skew, and\nsymmetry point variability",
      "tldr_zh": "本研究评估了模拟内存计算（Analog in-memory computing）在迁移学习（Transfer Learning）中的性能，旨在解决设备不对称、非线性切换行为和变异性等挑战，导致现有训练算法效果不佳。引入了新的 c-TTv2 算法，通过 chopped 技术提升鲁棒性，使其适用于实际设备。实验使用 Swin-ViT 模型在 CIFAR100 数据集子集上测试了该算法的性能，并考察了其对权重传输噪声、对称点偏移和对称点变异性的耐受性，结果显示 c-TTv2 有效改善了训练结果。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.DC",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11067v1",
      "published_date": "2025-05-16 10:02:32 UTC",
      "updated_date": "2025-05-16 10:02:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:00:25.931112"
    },
    {
      "arxiv_id": "2505.11066v1",
      "title": "A Multi-modal Fusion Network for Terrain Perception Based on Illumination Aware",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Wang",
        "Shichun Yang",
        "Yuyi Chen",
        "Zhuoyang Li",
        "Zexiang Tong",
        "Jianyi Xu",
        "Jiayi Lu",
        "Xinjie Feng",
        "Yaoguang Cao"
      ],
      "abstract": "Road terrains play a crucial role in ensuring the driving safety of\nautonomous vehicles (AVs). However, existing sensors of AVs, including cameras\nand Lidars, are susceptible to variations in lighting and weather conditions,\nmaking it challenging to achieve real-time perception of road conditions. In\nthis paper, we propose an illumination-aware multi-modal fusion network (IMF),\nwhich leverages both exteroceptive and proprioceptive perception and optimizes\nthe fusion process based on illumination features. We introduce an\nillumination-perception sub-network to accurately estimate illumination\nfeatures. Moreover, we design a multi-modal fusion network which is able to\ndynamically adjust weights of different modalities according to illumination\nfeatures. We enhance the optimization process by pre-training of the\nillumination-perception sub-network and incorporating illumination loss as one\nof the training constraints. Extensive experiments demonstrate that the IMF\nshows a superior performance compared to state-of-the-art methods. The\ncomparison results with single modality perception methods highlight the\ncomprehensive advantages of multi-modal fusion in accurately perceiving road\nterrains under varying lighting conditions. Our dataset is available at:\nhttps://github.com/lindawang2016/IMF.",
      "tldr_zh": "这篇论文提出了一种基于照明感知的多模态融合网络（IMF），旨在提升自动驾驶车辆（AVs）对路面地形的实时感知，解决摄像头和Lidar等传感器受照明和天气影响的挑战。IMF 结合外部感知和内部感知，通过照明感知子网络准确估计照明特征，并设计动态调整不同模态权重的融合网络来优化过程。实验结果显示，IMF 比现有最先进方法表现出色，在不同照明条件下显著提高了感知准确性，同时突出了多模态融合相对于单模态方法的综合优势。数据集可从 https://github.com/lindawang2016/IMF 获取。",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11066v1",
      "published_date": "2025-05-16 10:02:22 UTC",
      "updated_date": "2025-05-16 10:02:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:00:36.842556"
    },
    {
      "arxiv_id": "2505.11065v1",
      "title": "Time Travel is Cheating: Going Live with DeepFund for Real-Time Fund Investment Benchmarking",
      "title_zh": "翻译失败",
      "authors": [
        "Changlun Li",
        "Yao Shi",
        "Chen Wang",
        "Qiqi Duan",
        "Runke Ruan",
        "Weijie Huang",
        "Haonan Long",
        "Lijun Huang",
        "Yuyu Luo",
        "Nan Tang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated notable capabilities across\nfinancial tasks, including financial report summarization, earnings call\ntranscript analysis, and asset classification. However, their real-world\neffectiveness in managing complex fund investment remains inadequately\nassessed. A fundamental limitation of existing benchmarks for evaluating\nLLM-driven trading strategies is their reliance on historical back-testing,\ninadvertently enabling LLMs to \"time travel\"-leveraging future information\nembedded in their training corpora, thus resulting in possible information\nleakage and overly optimistic performance estimates. To address this issue, we\nintroduce DeepFund, a live fund benchmark tool designed to rigorously evaluate\nLLM in real-time market conditions. Utilizing a multi-agent architecture,\nDeepFund connects directly with real-time stock market data-specifically data\npublished after each model pretraining cutoff-to ensure fair and leakage-free\nevaluations. Empirical tests on nine flagship LLMs from leading global\ninstitutions across multiple investment dimensions-including ticker-level\nanalysis, investment decision-making, portfolio management, and risk\ncontrol-reveal significant practical challenges. Notably, even cutting-edge\nmodels such as DeepSeek-V3 and Claude-3.7-Sonnet incur net trading losses\nwithin DeepFund real-time evaluation environment, underscoring the present\nlimitations of LLMs for active fund management. Our code is available at\nhttps://github.com/HKUSTDial/DeepFund.",
      "tldr_zh": "这篇论文指出了现有基准测试中，Large Language Models (LLMs) 依赖历史回测导致的信息泄露问题，从而夸大其在基金投资管理中的表现。作者引入DeepFund，一种基于multi-agent architecture的实时基准工具，直接连接训练截止后的实时股票数据，确保公平、无泄露的评估。实验结果显示，在ticker-level分析、投资决策、组合管理和风险控制等维度测试九个旗舰LLMs时，即使是先进的DeepSeek-V3和Claude-3.7-Sonnet模型也产生了净交易损失，突显了LLMs在实际基金管理中的实际挑战。代码已开源于https://github.com/HKUSTDial/DeepFund。",
      "categories": [
        "cs.CE",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.CE",
      "comment": "21 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11065v1",
      "published_date": "2025-05-16 10:00:56 UTC",
      "updated_date": "2025-05-16 10:00:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:00:48.644642"
    },
    {
      "arxiv_id": "2505.11063v2",
      "title": "Think Twice Before You Act: Enhancing Agent Behavioral Safety with Thought Correction",
      "title_zh": "翻译失败",
      "authors": [
        "Changyue Jiang",
        "Xudong Pan",
        "Min Yang"
      ],
      "abstract": "LLM-based autonomous agents possess capabilities such as reasoning, tool\ninvocation, and environment interaction, enabling the execution of complex\nmulti-step tasks. The internal reasoning process, i.e., thought, of behavioral\ntrajectory significantly influences tool usage and subsequent actions but can\nintroduce potential risks. Even minor deviations in the agent's thought may\ntrigger cascading effects leading to irreversible safety incidents. To address\nthe safety alignment challenges in long-horizon behavioral trajectories, we\npropose Thought-Aligner, a plug-in dynamic thought correction module. Utilizing\na lightweight and resource-efficient model, Thought-Aligner corrects each\nhigh-risk thought on the fly before each action execution. The corrected\nthought is then reintroduced to the agent, ensuring safer subsequent decisions\nand tool interactions. Importantly, Thought-Aligner modifies only the reasoning\nphase without altering the underlying agent framework, making it easy to deploy\nand widely applicable to various agent frameworks. To train the Thought-Aligner\nmodel, we construct an instruction dataset across ten representative scenarios\nand simulate ReAct execution trajectories, generating 5,000 diverse\ninstructions and more than 11,400 safe and unsafe thought pairs. The model is\nfine-tuned using contrastive learning techniques. Experiments across three\nagent safety benchmarks involving 12 different LLMs demonstrate that\nThought-Aligner raises agent behavioral safety from approximately 50% in the\nunprotected setting to 90% on average. Additionally, Thought-Aligner maintains\nresponse latency below 100ms with minimal resource usage, demonstrating its\ncapability for efficient deployment, broad applicability, and timely\nresponsiveness. This method thus provides a practical dynamic safety solution\nfor the LLM-based agents.",
      "tldr_zh": "该论文针对LLM-based autonomous agents的内部推理（thought）可能导致安全风险的问题，提出了一种插件式模块Thought-Aligner，用于动态修正高风险思想，确保代理在执行动作前做出更安全的决策，而无需修改底层代理框架。Thought-Aligner采用轻量级模型和对比学习技术，在跨越十个场景的指令数据集上训练，生成5000个指令和超过11400个安全/不安全thought对。实验结果显示，在三个代理安全基准上涉及12个不同LLM时，代理行为安全率从约50%提高到90%，并保持响应延迟低于100ms和低资源消耗，提供了一种高效、可部署的安全解决方案。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11063v2",
      "published_date": "2025-05-16 10:00:15 UTC",
      "updated_date": "2025-05-19 06:52:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:01:01.302771"
    },
    {
      "arxiv_id": "2505.11060v1",
      "title": "CUBIC: Concept Embeddings for Unsupervised Bias Identification using VLMs",
      "title_zh": "翻译失败",
      "authors": [
        "David Méndez",
        "Gianpaolo Bontempo",
        "Elisa Ficarra",
        "Roberto Confalonieri",
        "Natalia Díaz-Rodríguez"
      ],
      "abstract": "Deep vision models often rely on biases learned from spurious correlations in\ndatasets. To identify these biases, methods that interpret high-level,\nhuman-understandable concepts are more effective than those relying primarily\non low-level features like heatmaps. A major challenge for these concept-based\nmethods is the lack of image annotations indicating potentially bias-inducing\nconcepts, since creating such annotations requires detailed labeling for each\ndataset and concept, which is highly labor-intensive. We present CUBIC (Concept\nembeddings for Unsupervised Bias IdentifiCation), a novel method that\nautomatically discovers interpretable concepts that may bias classifier\nbehavior. Unlike existing approaches, CUBIC does not rely on predefined bias\ncandidates or examples of model failures tied to specific biases, as such\ninformation is not always available. Instead, it leverages image-text latent\nspace and linear classifier probes to examine how the latent representation of\na superclass label$\\unicode{x2014}$shared by all instances in the\ndataset$\\unicode{x2014}$is influenced by the presence of a given concept. By\nmeasuring these shifts against the normal vector to the classifier's decision\nboundary, CUBIC identifies concepts that significantly influence model\npredictions. Our experiments demonstrate that CUBIC effectively uncovers\npreviously unknown biases using Vision-Language Models (VLMs) without requiring\nthe samples in the dataset where the classifier underperforms or prior\nknowledge of potential biases.",
      "tldr_zh": "这篇论文提出了 CUBIC，一种基于 Vision-Language Models (VLMs) 的无监督方法，用于识别深层视觉模型中由数据集虚假相关性引发的偏差。CUBIC 通过图像-文本潜在空间和线性分类器探针，分析概念对超类标签表示的偏移影响，并与分类器决策边界的法向量进行比较，从而自动发现可能偏置模型预测的可解释概念。与现有方法不同，它不依赖预定义的偏差候选或模型失败样本。实验结果显示，CUBIC 能够有效揭示未知偏差，而无需图像标注或先验知识。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "68T10",
        "I.2.4; I.5.2"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 3 figures, 5 tables. Accepted at IJCNN 2025; to appear in\n  IEEE Xplore",
      "pdf_url": "http://arxiv.org/pdf/2505.11060v1",
      "published_date": "2025-05-16 09:57:15 UTC",
      "updated_date": "2025-05-16 09:57:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:01:13.003006"
    },
    {
      "arxiv_id": "2505.11050v1",
      "title": "Halting Recurrent GNNs and the Graded $μ$-Calculus",
      "title_zh": "翻译失败",
      "authors": [
        "Jeroen Bollen",
        "Jan Van den Bussche",
        "Stijn Vansummeren",
        "Jonni Virtema"
      ],
      "abstract": "Graph Neural Networks (GNNs) are a class of machine-learning models that\noperate on graph-structured data. Their expressive power is intimately related\nto logics that are invariant under graded bisimilarity. Current proposals for\nrecurrent GNNs either assume that the graph size is given to the model, or\nsuffer from a lack of termination guarantees. In this paper, we propose a\nhalting mechanism for recurrent GNNs. We prove that our halting model can\nexpress all node classifiers definable in graded modal mu-calculus, even for\nthe standard GNN variant that is oblivious to the graph size. A recent\nbreakthrough in the study of the expressivity of graded modal mu-calculus in\nthe finite suggests that conversely, restricted to node classifiers definable\nin monadic second-order logic, recurrent GNNs can express only node classifiers\ndefinable in graded modal mu-calculus. To prove our main result, we develop a\nnew approximate semantics for graded mu-calculus, which we believe to be of\nindependent interest. We leverage this new semantics into a new model-checking\nalgorithm, called the counting algorithm, which is oblivious to the graph size.\nIn a final step we show that the counting algorithm can be implemented on a\nhalting recurrent GNN.",
      "tldr_zh": "本论文探讨了图神经网络（GNNs）的表达能力及其与graded bisimilarity不变逻辑的关系，针对现有recurrent GNNs的终止问题（如依赖图大小或缺乏终止保证），提出了一种halting mechanism。研究证明，这种机制能表达graded modal mu-calculus中定义的所有节点分类器，即使标准GNNs不知晓图大小；同时，通过开发新的approximate semantics for graded mu-calculus，创建了一个不依赖图大小的counting algorithm，并展示了其可在halting recurrent GNNs上实现。总体而言，这为recurrent GNNs的表达边界提供了理论基础，特别是与monadic second-order logic的比较，增强了GNNs在图结构数据处理中的可靠性和适用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11050v1",
      "published_date": "2025-05-16 09:46:36 UTC",
      "updated_date": "2025-05-16 09:46:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:01:26.461915"
    },
    {
      "arxiv_id": "2505.11049v1",
      "title": "GuardReasoner-VL: Safeguarding VLMs via Reinforced Reasoning",
      "title_zh": "GuardReasoner-VL：通过强化",
      "authors": [
        "Yue Liu",
        "Shengfang Zhai",
        "Mingzhe Du",
        "Yulin Chen",
        "Tri Cao",
        "Hongcheng Gao",
        "Cheng Wang",
        "Xinfeng Li",
        "Kun Wang",
        "Junfeng Fang",
        "Jiaheng Zhang",
        "Bryan Hooi"
      ],
      "abstract": "To enhance the safety of VLMs, this paper introduces a novel reasoning-based\nVLM guard model dubbed GuardReasoner-VL. The core idea is to incentivize the\nguard model to deliberatively reason before making moderation decisions via\nonline RL. First, we construct GuardReasoner-VLTrain, a reasoning corpus with\n123K samples and 631K reasoning steps, spanning text, image, and text-image\ninputs. Then, based on it, we cold-start our model's reasoning ability via SFT.\nIn addition, we further enhance reasoning regarding moderation through online\nRL. Concretely, to enhance diversity and difficulty of samples, we conduct\nrejection sampling followed by data augmentation via the proposed safety-aware\ndata concatenation. Besides, we use a dynamic clipping parameter to encourage\nexploration in early stages and exploitation in later stages. To balance\nperformance and token efficiency, we design a length-aware safety reward that\nintegrates accuracy, format, and token cost. Extensive experiments demonstrate\nthe superiority of our model. Remarkably, it surpasses the runner-up by 19.27%\nF1 score on average. We release data, code, and models (3B/7B) of\nGuardReasoner-VL at https://github.com/yueliu1999/GuardReasoner-VL/",
      "tldr_zh": "本论文提出 GuardReasoner-VL，一种基于在线强化学习 (online RL) 的视觉语言模型 (VLMs) 防护模型，旨在通过鼓励模型在做出审核决策前进行深思熟虑的推理来提升 VLMs 的安全性。\n研究团队构建了 GuardReasoner-VLTrain 数据集，包含 123K 样本和 631K 推理步骤，覆盖文本、图像和文本-图像输入，并通过 Supervised Fine-Tuning (SFT) 启动模型的推理能力，然后利用在线 RL 进行优化，包括拒绝采样、数据增强和动态奖励机制。\n实验结果显示，GuardReasoner-VL 在 F1 分数上平均超过亚军 19.27%，并开源了数据、代码和模型 (3B/7B)。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11049v1",
      "published_date": "2025-05-16 09:46:10 UTC",
      "updated_date": "2025-05-16 09:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:01:37.847958"
    },
    {
      "arxiv_id": "2505.13504v1",
      "title": "An agentic system with reinforcement-learned subsystem improvements for parsing form-like documents",
      "title_zh": "翻译失败",
      "authors": [
        "Ayesha Amjad",
        "Saurav Sthapit",
        "Tahir Qasim Syed"
      ],
      "abstract": "Extracting alphanumeric data from form-like documents such as invoices,\npurchase orders, bills, and financial documents is often performed via vision\n(OCR) and learning algorithms or monolithic pipelines with limited potential\nfor systemic improvements. We propose an agentic AI system that leverages Large\nLanguage Model (LLM) agents and a reinforcement learning (RL) driver agent to\nautomate consistent, self-improving extraction under LLM inference uncertainty.\nOur work highlights the limitations of monolithic LLM-based extraction and\nintroduces a modular, multi-agent framework with task-specific prompts and an\nRL policy of rewards and penalties to guide a meta-prompting agent to learn\nfrom past errors and improve prompt-based actor agents. This self-corrective\nadaptive system handles diverse documents, file formats, layouts, and LLMs,\naiming to automate accurate information extraction without the need for human\nintervention. Results as reported on two benchmark datasets of SOIRE, and CORD,\nare promising for the agentic AI framework.",
      "tldr_zh": "本论文提出了一种基于代理 AI 的系统，利用 Large Language Model (LLM) 代理和 reinforcement learning (RL) 驱动代理，来自动提取表单类文档（如发票和财务文件）中的字母数字数据，并通过 RL 政策实现子系统的持续改进。系统采用模块化多代理框架，包括任务特定提示和元提示代理，能够从过去的错误中学习，实现自校正和适应，从而处理多样化的文档格式、布局和 LLMs，而无需人工干预。与传统单体管道相比，该方法在 SOIRE 和 CORD 基准数据集上表现出色，展示了更高的提取准确性和潜力。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13504v1",
      "published_date": "2025-05-16 09:46:10 UTC",
      "updated_date": "2025-05-16 09:46:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:01:49.266037"
    },
    {
      "arxiv_id": "2505.11568v2",
      "title": "BioCube: A Multimodal Dataset for Biodiversity Research",
      "title_zh": "翻译失败",
      "authors": [
        "Stylianos Stasinos",
        "Martino Mensio",
        "Elena Lazovik",
        "Athanasios Trantas"
      ],
      "abstract": "Biodiversity research requires complete and detailed information to study\necosystem dynamics at different scales. Employing data-driven methods like\nMachine Learning is getting traction in ecology and more specific biodiversity,\noffering alternative modelling pathways. For these methods to deliver accurate\nresults there is the need for large, curated and multimodal datasets that offer\ngranular spatial and temporal resolutions. In this work, we introduce BioCube,\na multimodal, fine-grained global dataset for ecology and biodiversity\nresearch. BioCube incorporates species observations through images, audio\nrecordings and descriptions, environmental DNA, vegetation indices,\nagricultural, forest, land indicators, and high-resolution climate variables.\nAll observations are geospatially aligned under the WGS84 geodetic system,\nspanning from 2000 to 2020. The dataset will become available at\nhttps://huggingface.co/datasets/BioDT/BioCube while the acquisition and\nprocessing code base at https://github.com/BioDT/bfm-data.",
      "tldr_zh": "本文介绍了 BioCube，这是一个多模态数据集，旨在支持生物多样性研究中的数据驱动方法，如 Machine Learning。BioCube 整合了图像、音频记录、环境 DNA、植被指数、农业、森林、土地指标以及高分辨率气候变量，所有数据在 WGS84 系统中进行地理对齐，覆盖 2000 到 2020 年的全球细粒度观测。数据集可从 Hugging Face 获取，相关代码在 GitHub 上公开，有望提升生态系统动态建模的准确性和应用潜力。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.QM",
      "comment": "submitted to BiDS'25, 5 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2505.11568v2",
      "published_date": "2025-05-16 09:46:08 UTC",
      "updated_date": "2025-05-20 13:09:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:02:00.835940"
    },
    {
      "arxiv_id": "2505.11034v1",
      "title": "CleanPatrick: A Benchmark for Image Data Cleaning",
      "title_zh": "CleanPatrick：图像数据清洗基准",
      "authors": [
        "Fabian Gröger",
        "Simone Lionetti",
        "Philippe Gottfrois",
        "Alvaro Gonzalez-Jimenez",
        "Ludovic Amruthalingam",
        "Elisabeth Victoria Goessinger",
        "Hanna Lindemann",
        "Marie Bargiela",
        "Marie Hofbauer",
        "Omar Badri",
        "Philipp Tschandl",
        "Arash Koochek",
        "Matthew Groh",
        "Alexander A. Navarini",
        "Marc Pouly"
      ],
      "abstract": "Robust machine learning depends on clean data, yet current image data\ncleaning benchmarks rely on synthetic noise or narrow human studies, limiting\ncomparison and real-world relevance. We introduce CleanPatrick, the first\nlarge-scale benchmark for data cleaning in the image domain, built upon the\npublicly available Fitzpatrick17k dermatology dataset. We collect 496,377\nbinary annotations from 933 medical crowd workers, identify off-topic samples\n(4%), near-duplicates (21%), and label errors (22%), and employ an aggregation\nmodel inspired by item-response theory followed by expert review to derive\nhigh-quality ground truth. CleanPatrick formalizes issue detection as a ranking\ntask and adopts typical ranking metrics mirroring real audit workflows.\nBenchmarking classical anomaly detectors, perceptual hashing, SSIM, Confident\nLearning, NoiseRank, and SelfClean, we find that, on CleanPatrick,\nself-supervised representations excel at near-duplicate detection, classical\nmethods achieve competitive off-topic detection under constrained review\nbudgets, and label-error detection remains an open challenge for fine-grained\nmedical classification. By releasing both the dataset and the evaluation\nframework, CleanPatrick enables a systematic comparison of image-cleaning\nstrategies and paves the way for more reliable data-centric artificial\nintelligence.",
      "tldr_zh": "该论文引入了CleanPatrick，这是一个基于Fitzpatrick17k皮肤病数据集的首个大规模图像数据清洗基准，用于评估真实世界数据清洗策略。研究团队收集了49.6万二进制注释来自933名医疗众包工作者，识别出离题样本(4%)、近重复样本(21%)和标签错误(22%)，并采用受项目响应理论启发的聚合模型结合专家审查来生成高质量ground truth。CleanPatrick将问题检测形式化为排名任务，使用典型排名指标模拟审计工作流程，并基准测试了方法如SSIM、Confident Learning、NoiseRank和SelfClean，结果显示自监督表示在近重复检测中表现出色，经典方法在有限预算下适合离题检测，而标签错误检测在细粒度医疗分类中仍是挑战。通过发布数据集和评估框架，该基准促进了图像清洗策略的系统比较，并推动更可靠的数据中心AI发展。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11034v1",
      "published_date": "2025-05-16 09:29:41 UTC",
      "updated_date": "2025-05-16 09:29:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:02:14.668563"
    },
    {
      "arxiv_id": "2505.11032v2",
      "title": "DexGarmentLab: Dexterous Garment Manipulation Environment with Generalizable Policy",
      "title_zh": "翻译失败",
      "authors": [
        "Yuran Wang",
        "Ruihai Wu",
        "Yue Chen",
        "Jiarui Wang",
        "Jiaqi Liang",
        "Ziyu Zhu",
        "Haoran Geng",
        "Jitendra Malik",
        "Pieter Abbeel",
        "Hao Dong"
      ],
      "abstract": "Garment manipulation is a critical challenge due to the diversity in garment\ncategories, geometries, and deformations. Despite this, humans can effortlessly\nhandle garments, thanks to the dexterity of our hands. However, existing\nresearch in the field has struggled to replicate this level of dexterity,\nprimarily hindered by the lack of realistic simulations of dexterous garment\nmanipulation. Therefore, we propose DexGarmentLab, the first environment\nspecifically designed for dexterous (especially bimanual) garment manipulation,\nwhich features large-scale high-quality 3D assets for 15 task scenarios, and\nrefines simulation techniques tailored for garment modeling to reduce the\nsim-to-real gap. Previous data collection typically relies on teleoperation or\ntraining expert reinforcement learning (RL) policies, which are labor-intensive\nand inefficient. In this paper, we leverage garment structural correspondence\nto automatically generate a dataset with diverse trajectories using only a\nsingle expert demonstration, significantly reducing manual intervention.\nHowever, even extensive demonstrations cannot cover the infinite states of\ngarments, which necessitates the exploration of new algorithms. To improve\ngeneralization across diverse garment shapes and deformations, we propose a\nHierarchical gArment-manipuLation pOlicy (HALO). It first identifies\ntransferable affordance points to accurately locate the manipulation area, then\ngenerates generalizable trajectories to complete the task. Through extensive\nexperiments and detailed analysis of our method and baseline, we demonstrate\nthat HALO consistently outperforms existing methods, successfully generalizing\nto previously unseen instances even with significant variations in shape and\ndeformation where others fail. Our project page is available at:\nhttps://wayrise.github.io/DexGarmentLab/.",
      "tldr_zh": "该研究针对服装操控的多样性、几何和变形挑战，提出DexGarmentLab，这是首个专注于灵巧（尤其是bimanual）服装操控的环境，包含15个任务场景的大规模高质量3D资产，并优化模拟技术以缩小模拟与现实差距。不同于传统的遥操作或专家reinforcement learning (RL)策略，该方法利用服装结构对应性，仅需一个专家演示即可自动生成多样轨迹数据集，大大减少手动干预。论文还引入Hierarchical gArment-manipuLation pOlicy (HALO)，通过识别可转移的affordance points定位操控区域并生成泛化轨迹，实现对未见形状和变形的鲁棒性能；在广泛实验中，HALO显著优于基线方法，证明了其在复杂服装操控中的泛化优势。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11032v2",
      "published_date": "2025-05-16 09:26:59 UTC",
      "updated_date": "2025-05-19 07:28:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:02:25.706231"
    },
    {
      "arxiv_id": "2505.11030v1",
      "title": "The heteronomy of algorithms: Traditional knowledge and computational knowledge",
      "title_zh": "算法的他律：传统知识和计算知识",
      "authors": [
        "David M. Berry"
      ],
      "abstract": "If an active citizen should increasingly be a computationally enlightened\none, replacing the autonomy of reason with the heteronomy of algorithms, then I\nargue in this article that we must begin teaching the principles of critiquing\nthe computal through new notions of what we might call digital Bildung. Indeed,\nif civil society itself is mediated by computational systems and media, the\npublic use of reason must also be complemented by skills for negotiating and\nusing these computal forms to articulate such critique. Not only is there a\nneed to raise the intellectual tone regarding computation and its related\nsoftwarization processes, but there is an urgent need to attend to the likely\nepistemic challenges from computation which, as presently constituted, tends\ntowards justification through a philosophy of utility rather than through a\nphilosophy of care for the territory of the intellect. We therefore need to\ndevelop an approach to this field that uses concepts and methods drawn from\nphilosophy, politics, history, anthropology, sociology, media studies, computer\nscience, and the humanities more generally, to try to understand these issues -\nparticularly the way in which software and data increasingly penetrate our\neveryday life and the pressures and fissures that are created. We must, in\nother words, move to undertake a critical interdisciplinary research program to\nunderstand the way in which these systems are created, instantiated, and\nnormatively engendered in both specific and general contexts.",
      "tldr_zh": "该论文探讨了算法的异律性（heteronomy of algorithms），即算法如何取代理性自治，并对比传统知识与计算知识在当代社会中的作用。作者主张，通过数字教育（digital Bildung）来教授批判计算系统的原则，帮助公民在计算化环境中进行理性批判和协商。论文呼吁开展跨学科研究，整合哲学、政治、历史、人类学、社会学、媒体研究、计算机科学和人文科学的方法，以应对计算系统对日常生活的影响及其潜在认识论挑战。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.MM",
        "K.4.0; K.4.1"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11030v1",
      "published_date": "2025-05-16 09:25:00 UTC",
      "updated_date": "2025-05-16 09:25:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:02:36.190772"
    },
    {
      "arxiv_id": "2505.11026v1",
      "title": "StRuCom: A Novel Dataset of Structured Code Comments in Russian",
      "title_zh": "翻译失败",
      "authors": [
        "Maria Dziuba",
        "Valentin Malykh"
      ],
      "abstract": "Structured code comments in docstring format are essential for code\ncomprehension and maintenance, but existing machine learning models for their\ngeneration perform poorly for Russian compared to English. To bridge this gap,\nwe present StRuCom - the first large-scale dataset (153K examples) specifically\ndesigned for Russian code documentation. Unlike machine-translated English\ndatasets that distort terminology (e.g., technical loanwords vs. literal\ntranslations) and docstring structures, StRuCom combines human-written comments\nfrom Russian GitHub repositories with synthetically generated ones, ensuring\ncompliance with Python, Java, JavaScript, C#, and Go standards through\nautomated validation. Fine-tuning Qwen2.5-Coder models (0.5B-7B) on StRuCom\nshows statistically significant improvements of chrf++ and BERTScore over\nbaseline models.",
      "tldr_zh": "该论文介绍了 StRuCom，这是一个首个针对俄罗斯代码文档的庞大数据集，包含 153K 例子，用于生成结构化代码注释。不同于机器翻译的英语数据集，StRuCom 结合了从俄罗斯 GitHub 仓库的人工编写注释和合成生成注释，并通过自动化验证确保符合 Python, Java, JavaScript, C#, 和 Go 的标准。实验结果显示，在 StRuCom 上微调 Qwen2.5-Coder 模型（0.5B-7B）后，chrf++ 和 BERTScore 的性能较基线模型有统计显著的提升。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11026v1",
      "published_date": "2025-05-16 09:22:07 UTC",
      "updated_date": "2025-05-16 09:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:02:49.628138"
    },
    {
      "arxiv_id": "2505.11567v1",
      "title": "Beyond Time: Cross-Dimensional Frequency Supervision for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Shi",
        "Zhu Meng",
        "Yue Chen",
        "Siyang Zheng",
        "Fei Su",
        "Jin Huang",
        "Changrui Ren",
        "Zhicheng Zhao"
      ],
      "abstract": "Time series forecasting plays a crucial role in various fields, and the\nmethods based on frequency domain analysis have become an important branch.\nHowever, most existing studies focus on the design of elaborate model\narchitectures and are often tailored for limited datasets, still lacking\nuniversality. Besides, the assumption of independent and identically\ndistributed (IID) data also contradicts the strong correlation of the time\ndomain labels. To address these issues, abandoning time domain supervision, we\npropose a purely frequency domain supervision approach named cross-dimensional\nfrequency (X-Freq) loss. Specifically, based on a statistical phenomenon, we\nfirst prove that the information entropy of the time series is higher than its\nspectral entropy, which implies higher certainty in frequency domain and thus\ncan provide better supervision. Secondly, the Fourier Transform and the Wavelet\nTransform are applied to the time dimension and the channel dimension of the\ntime series respectively, to capture the long-term and short-term frequency\nvariations as well as the spatial configuration features. Thirdly, the loss\nbetween predictions and targets is uniformly computed in the frequency domain.\nMoreover, we plug-and-play incorporate X-Freq into multiple advanced\nforecasting models and compare on 14 real-world datasets. The experimental\nresults demonstrate that, without making any modification to the original\narchitectures or hyperparameters, X-Freq can improve the forecasting\nperformance by an average of 3.3% on long-term forecasting datasets and 27.7%\non short-term ones, showcasing superior generality and practicality. The code\nwill be released publicly.",
      "tldr_zh": "该论文针对时间序列预测（Time Series Forecasting）中的模型局限性，提出了一种纯频域监督方法Cross-Dimensional Frequency (X-Freq) loss，以解决现有架构的缺乏普遍性和数据相关性假设问题。通过证明时间序列的信息熵高于谱熵，X-Freq利用Fourier Transform和Wavelet Transform分别应用于时间和通道维度，捕获长短期频域变化及空间特征，并在频域中统一计算损失。实验结果显示，将X-Freq插入多个高级模型后，在14个真实数据集上，预测性能平均提升3.3%（长短期）和27.7%（短期），展示了其通用性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11567v1",
      "published_date": "2025-05-16 09:17:15 UTC",
      "updated_date": "2025-05-16 09:17:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:03:02.893402"
    },
    {
      "arxiv_id": "2505.11011v1",
      "title": "Humans expect rationality and cooperation from LLM opponents in strategic games",
      "title_zh": "翻译失败",
      "authors": [
        "Darija Barak",
        "Miguel Costa-Gomes"
      ],
      "abstract": "As Large Language Models (LLMs) integrate into our social and economic\ninteractions, we need to deepen our understanding of how humans respond to LLMs\nopponents in strategic settings. We present the results of the first controlled\nmonetarily-incentivised laboratory experiment looking at differences in human\nbehaviour in a multi-player p-beauty contest against other humans and LLMs. We\nuse a within-subject design in order to compare behaviour at the individual\nlevel. We show that, in this environment, human subjects choose significantly\nlower numbers when playing against LLMs than humans, which is mainly driven by\nthe increased prevalence of `zero' Nash-equilibrium choices. This shift is\nmainly driven by subjects with high strategic reasoning ability. Subjects who\nplay the zero Nash-equilibrium choice motivate their strategy by appealing to\nperceived LLM's reasoning ability and, unexpectedly, propensity towards\ncooperation. Our findings provide foundational insights into the multi-player\nhuman-LLM interaction in simultaneous choice games, uncover heterogeneities in\nboth subjects' behaviour and beliefs about LLM's play when playing against\nthem, and suggest important implications for mechanism design in mixed\nhuman-LLM systems.",
      "tldr_zh": "该研究通过受控的货币激励实验室实验，比较了人类在多玩家 p-beauty contest 中对人类对手和 LLM 对手的行为差异，结果显示人类在对阵 LLM 时更倾向于选择较低数字，特别是零 Nash-equilibrium，这主要由高战略推理能力的人所驱动。参与者解释他们的策略时，强调了 LLM 的推理能力和出人意料的合作倾向。该发现揭示了人类-LLM 互动中的行为和信念异质性，并为混合人类-LLM 系统中的机制设计提供了重要启示。",
      "categories": [
        "econ.GN",
        "cs.AI",
        "cs.MA",
        "q-fin.EC"
      ],
      "primary_category": "econ.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11011v1",
      "published_date": "2025-05-16 09:01:09 UTC",
      "updated_date": "2025-05-16 09:01:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:03:13.387533"
    },
    {
      "arxiv_id": "2505.11010v1",
      "title": "Review-Instruct: A Review-Driven Multi-Turn Conversations Generation Method for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jiangxu Wu",
        "Cong Wang",
        "TianHuang Su",
        "Jun Yang",
        "Haozhi Lin",
        "Chao Zhang",
        "Ming Peng",
        "Kai Shi",
        "SongPan Yang",
        "BinQing Pan",
        "ZiXian Li",
        "Ni Yang",
        "ZhenYu Yang"
      ],
      "abstract": "The effectiveness of large language models (LLMs) in conversational AI is\nhindered by their reliance on single-turn supervised fine-tuning (SFT) data,\nwhich limits contextual coherence in multi-turn dialogues. Existing methods for\ngenerating multi-turn dialogue data struggle to ensure both diversity and\nquality in instructions. To address this, we propose Review-Instruct, a novel\nframework that synthesizes multi-turn conversations through an iterative\n\"Ask-Respond-Review\" process involving three agent roles: a Candidate, multiple\nReviewers, and a Chairman. The framework iteratively refines instructions by\nincorporating Reviewer feedback, enhancing dialogue diversity and difficulty.\nWe construct a multi-turn dataset using the Alpaca dataset and fine-tune the\nLLaMA2-13B model. Evaluations on MT-Bench, MMLU-Pro, and Auto-Arena demonstrate\nsignificant improvements, achieving absolute gains of 2.9\\% on MMLU-Pro and 2\\%\non MT-Bench compared to prior state-of-the-art models based on LLaMA2-13B.\nAblation studies confirm the critical role of the Review stage and the use of\nmultiple Reviewers in boosting instruction diversity and difficulty. Our work\nhighlights the potential of review-driven, multi-agent frameworks for\ngenerating high-quality conversational data at scale.",
      "tldr_zh": "本文研究了大型语言模型 (LLMs) 在多轮对话中的局限性，即依赖单轮监督微调 (SFT) 数据导致上下文连贯性不足，并提出 Review-Instruct 框架来解决指令多样性和质量问题。框架采用迭代的 \"Ask-Respond-Review\" 过程，涉及 Candidate、多个 Reviewers 和 Chairman 角色，通过 Reviewer 反馈不断完善对话指令，从而提升多样性和难度。实验使用 Alpaca 数据集微调 LLaMA2-13B 模型，结果在 MT-Bench 上提升 2%、在 MMLU-Pro 上提升 2.9%，并通过消融研究证实 Review 阶段和多 Reviewers 的关键作用。该方法展示了 review-driven 多代理框架在规模化生成高质量对话数据方面的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL2025 Accepted",
      "pdf_url": "http://arxiv.org/pdf/2505.11010v1",
      "published_date": "2025-05-16 08:59:07 UTC",
      "updated_date": "2025-05-16 08:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:03:26.849278"
    },
    {
      "arxiv_id": "2505.11004v2",
      "title": "Illusion or Algorithm? Investigating Memorization, Emergence, and Symbolic Processing in In-Context Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Jingcheng Niu",
        "Subhabrata Dutta",
        "Ahmed Elshabrawy",
        "Harish Tayyar Madabushi",
        "Iryna Gurevych"
      ],
      "abstract": "Large-scale Transformer language models (LMs) trained solely on next-token\nprediction with web-scale data can solve a wide range of tasks after seeing\njust a few examples. The mechanism behind this capability, known as in-context\nlearning (ICL), remains both controversial and poorly understood. Some studies\nargue that it is merely the result of memorizing vast amounts of data, while\nothers contend that it reflects a fundamental, symbolic algorithmic development\nin LMs. In this work, we introduce a suite of investigative tasks and a novel\nmethod to systematically investigate ICL by leveraging the full Pythia scaling\nsuite, including interim checkpoints that capture progressively larger amount\nof training data. By carefully exploring ICL performance on downstream tasks\nand simultaneously conducting a mechanistic analysis of the residual stream's\nsubspace, we demonstrate that ICL extends beyond mere \"memorization\" of the\ntraining corpus, yet does not amount to the implementation of an independent\nsymbolic algorithm. Our results also clarify several aspects of ICL, including\nthe influence of training dynamics, model capabilities, and elements of\nmechanistic interpretability. Overall, our work advances the understanding of\nICL and its implications, offering model developers insights into potential\nimprovements and providing AI security practitioners with a basis for more\ninformed guidelines.",
      "tldr_zh": "本文研究了 In-Context Learning (ICL) 的机制，探讨大型 Transformer 语言模型是否通过记忆海量数据实现任务解决，还是发展出符号算法。研究者引入一套调查任务和新型方法，利用 Pythia 缩放套件及其训练检查点，分析 ICL 在下游任务的性能以及残差流的子空间。结果表明，ICL 不仅限于“记忆”，但尚未形成独立符号算法，并阐明了训练动态、模型能力和机制解释性的影响。该工作为模型开发者和 AI 安全从业者提供了宝贵见解，推动了对 ICL 的理解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11004v2",
      "published_date": "2025-05-16 08:50:42 UTC",
      "updated_date": "2025-05-22 08:54:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:03:37.800782"
    },
    {
      "arxiv_id": "2505.10994v1",
      "title": "Space Group Equivariant Crystal Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Rees Chang",
        "Angela Pak",
        "Alex Guerra",
        "Ni Zhan",
        "Nick Richardson",
        "Elif Ertekin",
        "Ryan P. Adams"
      ],
      "abstract": "Accelerating inverse design of crystalline materials with generative models\nhas significant implications for a range of technologies. Unlike other atomic\nsystems, 3D crystals are invariant to discrete groups of isometries called the\nspace groups. Crucially, these space group symmetries are known to heavily\ninfluence materials properties. We propose SGEquiDiff, a crystal generative\nmodel which naturally handles space group constraints with space group\ninvariant likelihoods. SGEquiDiff consists of an SE(3)-invariant, telescoping\ndiscrete sampler of crystal lattices; permutation-invariant, transformer-based\nautoregressive sampling of Wyckoff positions, elements, and numbers of\nsymmetrically unique atoms; and space group equivariant diffusion of atomic\ncoordinates. We show that space group equivariant vector fields automatically\nlive in the tangent spaces of the Wyckoff positions. SGEquiDiff achieves\nstate-of-the-art performance on standard benchmark datasets as assessed by\nquantitative proxy metrics and quantum mechanical calculations.",
      "tldr_zh": "该论文提出了一种名为 SGEquiDiff 的晶体生成模型，用于加速晶体材料的逆向设计，特别处理 3D 晶体的空间群（space groups）对称性，以影响材料属性。模型包括 SE(3)-invariant 的晶格采样器、基于 transformer 的自回归采样（针对 Wyckoff positions、元素和原子数量），以及空间群 equivariant 的原子坐标扩散；其中，空间群 equivariant 向量场自动位于 Wyckoff positions 的切空间。SGEquiDiff 通过空间群不变似然性自然处理对称性约束，并在标准基准数据集上实现了最先进性能，经定量指标和量子力学计算验证。总体上，该方法为生成高效、可信的晶体结构提供了新框架。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10994v1",
      "published_date": "2025-05-16 08:45:04 UTC",
      "updated_date": "2025-05-16 08:45:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:03:49.311160"
    },
    {
      "arxiv_id": "2505.10991v3",
      "title": "Most General Explanations of Tree Ensembles (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Yacine Izza",
        "Alexey Ignatiev",
        "Sasha Rubin",
        "Joao Marques-Silva",
        "Peter J. Stuckey"
      ],
      "abstract": "Explainable Artificial Intelligence (XAI) is critical for attaining trust in\nthe operation of AI systems. A key question of an AI system is ``why was this\ndecision made this way''. Formal approaches to XAI use a formal model of the AI\nsystem to identify abductive explanations. While abductive explanations may be\napplicable to a large number of inputs sharing the same concrete values, more\ngeneral explanations may be preferred for numeric inputs. So-called inflated\nabductive explanations give intervals for each feature ensuring that any input\nwhose values fall withing these intervals is still guaranteed to make the same\nprediction. Inflated explanations cover a larger portion of the input space,\nand hence are deemed more general explanations. But there can be many\n(inflated) abductive explanations for an instance. Which is the best? In this\npaper, we show how to find a most general abductive explanation for an AI\ndecision. This explanation covers as much of the input space as possible, while\nstill being a correct formal explanation of the model's behaviour. Given that\nwe only want to give a human one explanation for a decision, the most general\nexplanation gives us the explanation with the broadest applicability, and hence\nthe one most likely to seem sensible. (The paper has been accepted at IJCAI2025\nconference.)",
      "tldr_zh": "这篇论文探讨了Explainable Artificial Intelligence (XAI)中针对树集成模型(Tree Ensembles)的解释问题，强调了如何为AI决策提供最通用的溯因解释(abductive explanations)。作者引入了inflated abductive explanations的概念，通过为特征定义区间来扩展解释范围，确保任何落入该区间的输入产生相同预测，从而覆盖更大的输入空间。论文展示了计算最通用解释的方法，使其在保持正确性的同时具有最大适用性，提升了AI系统的可信度和实用性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10991v3",
      "published_date": "2025-05-16 08:42:01 UTC",
      "updated_date": "2025-05-20 02:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:04:01.354237"
    },
    {
      "arxiv_id": "2505.11565v1",
      "title": "ACSE-Eval: Can LLMs threat model real-world cloud infrastructure?",
      "title_zh": "ACSE-Eval：LLMs 能否对真实世界的云基础设施进行威胁建模？",
      "authors": [
        "Sarthak Munshi",
        "Swapnil Pathak",
        "Sonam Ghatode",
        "Thenuga Priyadarshini",
        "Dhivya Chandramouleeswaran",
        "Ashutosh Rana"
      ],
      "abstract": "While Large Language Models have shown promise in cybersecurity applications,\ntheir effectiveness in identifying security threats within cloud deployments\nremains unexplored. This paper introduces AWS Cloud Security Engineering Eval,\na novel dataset for evaluating LLMs cloud security threat modeling\ncapabilities. ACSE-Eval contains 100 production grade AWS deployment scenarios,\neach featuring detailed architectural specifications, Infrastructure as Code\nimplementations, documented security vulnerabilities, and associated threat\nmodeling parameters. Our dataset enables systemic assessment of LLMs abilities\nto identify security risks, analyze attack vectors, and propose mitigation\nstrategies in cloud environments. Our evaluations on ACSE-Eval demonstrate that\nGPT 4.1 and Gemini 2.5 Pro excel at threat identification, with Gemini 2.5 Pro\nperforming optimally in 0-shot scenarios and GPT 4.1 showing superior results\nin few-shot settings. While GPT 4.1 maintains a slight overall performance\nadvantage, Claude 3.7 Sonnet generates the most semantically sophisticated\nthreat models but struggles with threat categorization and generalization. To\npromote reproducibility and advance research in automated cybersecurity threat\nanalysis, we open-source our dataset, evaluation metrics, and methodologies.",
      "tldr_zh": "本文引入了 ACSE-Eval 数据集，用于评估大型语言模型 (LLMs) 在真实云基础设施威胁建模中的能力，该数据集包含 100 个生产级 AWS 部署场景，包括详细架构规范、Infrastructure as Code 实现、安全漏洞和威胁参数。研究通过该数据集系统评估 LLMs 识别安全风险、分析攻击向量并提出缓解策略的效果，结果显示 Gemini 2.5 Pro 在零样本场景中表现最佳，GPT-4.1 在少样本设置中略占优势，而 Claude 3.7 Sonnet 生成的威胁模型语义最复杂但在威胁分类和泛化方面较弱。为了推动研究，该论文开源了数据集、评估指标和方法，促进自动化网络安全威胁分析的进展。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Submitted to the 39th Annual Conference on Neural Information\n  Processing Systems",
      "pdf_url": "http://arxiv.org/pdf/2505.11565v1",
      "published_date": "2025-05-16 08:40:09 UTC",
      "updated_date": "2025-05-16 08:40:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:04:14.416968"
    },
    {
      "arxiv_id": "2505.10989v1",
      "title": "RAGSynth: Synthetic Data for Robust and Faithful RAG Component Optimization",
      "title_zh": "RAGSynth：用于",
      "authors": [
        "Haiyang Shen",
        "Hang Yan",
        "Zhongshi Xing",
        "Mugeng Liu",
        "Yue Li",
        "Zhiyang Chen",
        "Yuxiang Wang",
        "Jiuzheng Wang",
        "Yun Ma"
      ],
      "abstract": "RAG can enhance the performance of LLMs on knowledge-intensive tasks. Various\nRAG paradigms, including vanilla, planning-based, and iterative RAG, are built\nupon 2 cores: the retriever, which should robustly select relevant documents\nacross complex queries, and the generator, which should faithfully synthesize\nresponses. However, existing retrievers rely heavily on public knowledge and\nstruggle with queries of varying logical complexity and clue completeness,\nwhile generators frequently face fidelity problems. In this work, we introduce\nRAGSynth, a framework that includes a data construction modeling and a\ncorresponding synthetic data generation implementation, designed to optimize\nretriever robustness and generator fidelity. Additionally, we present\nSynthBench, a benchmark encompassing 8 domain-specific documents across 4\ndomains, featuring diverse query complexities, clue completeness, and\nfine-grained citation granularity. Leveraging RAGSynth, we generate a\nlarge-scale synthetic dataset, including single and multi-hop. Extensive\nexperiments demonstrate that the synthetic data significantly improves the\nrobustness of the retrievers and the fidelity of the generators. Additional\nevaluations confirm that RAGSynth can also generalize well across different\ndomains. By integrating the optimized retrievers into various RAG paradigms, we\nconsistently observe enhanced RAG system performance. We have open-sourced the\nimplementation on https://github.com/EachSheep/RAGSynth.",
      "tldr_zh": "该研究引入RAGSynth框架，通过合成数据生成来优化RAG系统的核心组件，包括提升retriever的鲁棒性以处理复杂查询和不完整线索，以及改善generator的fidelity以确保响应准确性。框架结合数据构建建模和SynthBench基准，后者涵盖4个领域的8个特定文档，并支持单跳和多跳查询的多样化测试。实验结果显示，使用RAGSynth生成的大规模合成数据集显著提高了检索器和生成器的性能，并在各种RAG范式中实现了系统整体提升；此外，该框架展示了良好的跨领域泛化能力，并已开源于GitHub。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10989v1",
      "published_date": "2025-05-16 08:38:25 UTC",
      "updated_date": "2025-05-16 08:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:04:26.704158"
    },
    {
      "arxiv_id": "2505.10988v1",
      "title": "DRL-Based Injection Molding Process Parameter Optimization for Adaptive and Profitable Production",
      "title_zh": "翻译失败",
      "authors": [
        "Joon-Young Kim",
        "Jecheon Yu",
        "Heekyu Kim",
        "Seunghwa Ryu"
      ],
      "abstract": "Plastic injection molding remains essential to modern manufacturing. However,\noptimizing process parameters to balance product quality and profitability\nunder dynamic environmental and economic conditions remains a persistent\nchallenge. This study presents a novel deep reinforcement learning (DRL)-based\nframework for real-time process optimization in injection molding, integrating\nproduct quality and profitability into the control objective. A profit function\nwas developed to reflect real-world manufacturing costs, incorporating resin,\nmold wear, and electricity prices, including time-of-use variations. Surrogate\nmodels were constructed to predict product quality and cycle time, enabling\nefficient offline training of DRL agents using soft actor-critic (SAC) and\nproximal policy optimization (PPO) algorithms. Experimental results demonstrate\nthat the proposed DRL framework can dynamically adapt to seasonal and\noperational variations, consistently maintaining product quality while\nmaximizing profit. Compared to traditional optimization methods such as genetic\nalgorithms, the DRL models achieved comparable economic performance with up to\n135x faster inference speeds, making them well-suited for real-time\napplications. The framework's scalability and adaptability highlight its\npotential as a foundation for intelligent, data-driven decision-making in\nmodern manufacturing environments.",
      "tldr_zh": "该研究提出了一种基于深度强化学习(DRL)的框架，用于注塑成型过程参数的实时优化，以平衡产品质量和盈利性。该框架整合了一个利润函数，考虑树脂、模具磨损和电力价格（包括时间使用变化），并使用代理模型预测产品质量和循环时间，通过软演员-评论家(SAC)和近端策略优化(PPO)算法进行离线训练。实验结果表明，该框架能动态适应季节性和操作变化，同时维持产品质量并最大化利润，与传统遗传算法相比，DRL模型的推理速度快达135倍，展示了其在现代制造环境中的可扩展性和智能决策潜力。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "50 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10988v1",
      "published_date": "2025-05-16 08:35:31 UTC",
      "updated_date": "2025-05-16 08:35:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:04:37.898708"
    },
    {
      "arxiv_id": "2505.10983v1",
      "title": "GenoArmory: A Unified Evaluation Framework for Adversarial Attacks on Genomic Foundation Models",
      "title_zh": "GenoArmory：针对基因组基础模型对抗攻击的统一评估框架",
      "authors": [
        "Haozheng Luo",
        "Chenghao Qiu",
        "Yimin Wang",
        "Shang Wu",
        "Jiahao Yu",
        "Han Liu",
        "Binghui Wang",
        "Yan Chen"
      ],
      "abstract": "We propose the first unified adversarial attack benchmark for Genomic\nFoundation Models (GFMs), named GenoArmory. Unlike existing GFM benchmarks,\nGenoArmory offers the first comprehensive evaluation framework to\nsystematically assess the vulnerability of GFMs to adversarial attacks.\nMethodologically, we evaluate the adversarial robustness of five\nstate-of-the-art GFMs using four widely adopted attack algorithms and three\ndefense strategies. Importantly, our benchmark provides an accessible and\ncomprehensive framework to analyze GFM vulnerabilities with respect to model\narchitecture, quantization schemes, and training datasets. Additionally, we\nintroduce GenoAdv, a new adversarial sample dataset designed to improve GFM\nsafety. Empirically, classification models exhibit greater robustness to\nadversarial perturbations compared to generative models, highlighting the\nimpact of task type on model vulnerability. Moreover, adversarial attacks\nfrequently target biologically significant genomic regions, suggesting that\nthese models effectively capture meaningful sequence features.",
      "tldr_zh": "该研究提出GenoArmory，这是第一个统一的对抗攻击基准，用于系统评估基因组基础模型(GFMs)的脆弱性。研究方法包括使用四种广泛采用的攻击算法和三种防御策略，对五个最先进的GFMs进行鲁棒性评估，并分析模型架构、量化方案和训练数据集的影响。此外，引入了GenoAdv，一个新的对抗样本数据集，以提升GFMs的安全性。实证结果显示，分类模型比生成模型更robust，对抗攻击往往针对生物学上重要的基因组区域，表明这些模型有效地捕捉了有意义的序列特征。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10983v1",
      "published_date": "2025-05-16 08:29:56 UTC",
      "updated_date": "2025-05-16 08:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:04:48.989021"
    },
    {
      "arxiv_id": "2505.10982v1",
      "title": "Facets in Argumentation: A Formal Approach to Argument Significance",
      "title_zh": "翻译失败",
      "authors": [
        "Johannes Fichte",
        "Nicolas Fröhlich",
        "Markus Hecher",
        "Victor Lagerkvist",
        "Yasir Mahmood",
        "Arne Meier",
        "Jonathan Persson"
      ],
      "abstract": "Argumentation is a central subarea of Artificial Intelligence (AI) for\nmodeling and reasoning about arguments. The semantics of abstract argumentation\nframeworks (AFs) is given by sets of arguments (extensions) and conditions on\nthe relationship between them, such as stable or admissible. Today's solvers\nimplement tasks such as finding extensions, deciding credulous or skeptical\nacceptance, counting, or enumerating extensions. While these tasks are well\ncharted, the area between decision, counting/enumeration and fine-grained\nreasoning requires expensive reasoning so far. We introduce a novel concept\n(facets) for reasoning between decision and enumeration. Facets are arguments\nthat belong to some extensions (credulous) but not to all extensions\n(skeptical). They are most natural when a user aims to navigate, filter, or\ncomprehend the significance of specific arguments, according to their needs. We\nstudy the complexity and show that tasks involving facets are much easier than\ncounting extensions. Finally, we provide an implementation, and conduct\nexperiments to demonstrate feasibility.",
      "tldr_zh": "这篇论文在抽象论证框架（AFs）中引入了facets概念，作为一种形式化方法来评估论点的意义。Facets被定义为那些属于某些extensions（credulous acceptance）但不是所有extensions（skeptical acceptance）的论点，从而帮助用户导航、过滤或理解特定论点的相关性。论文分析了facets相关任务的复杂性，发现它们比计数或枚举extensions更容易，并通过实现实验证明了这一方法的实际可行性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10982v1",
      "published_date": "2025-05-16 08:29:38 UTC",
      "updated_date": "2025-05-16 08:29:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:05:01.178098"
    },
    {
      "arxiv_id": "2505.10981v1",
      "title": "Rethinking the Role of Prompting Strategies in LLM Test-Time Scaling: A Perspective of Probability Theory",
      "title_zh": "翻译失败",
      "authors": [
        "Yexiang Liu",
        "Zekun Li",
        "Zhi Fang",
        "Nan Xu",
        "Ran He",
        "Tieniu Tan"
      ],
      "abstract": "Recently, scaling test-time compute on Large Language Models (LLM) has\ngarnered wide attention. However, there has been limited investigation of how\nvarious reasoning prompting strategies perform as scaling. In this paper, we\nfocus on a standard and realistic scaling setting: majority voting. We\nsystematically conduct experiments on 6 LLMs $\\times$ 8 prompting strategies\n$\\times$ 6 benchmarks. Experiment results consistently show that as the\nsampling time and computational overhead increase, complicated prompting\nstrategies with superior initial performance gradually fall behind simple\nChain-of-Thought. We analyze this phenomenon and provide theoretical proofs.\nAdditionally, we propose a method according to probability theory to quickly\nand accurately predict the scaling performance and select the best strategy\nunder large sampling times without extra resource-intensive inference in\npractice. It can serve as the test-time scaling law for majority voting.\nFurthermore, we introduce two ways derived from our theoretical analysis to\nsignificantly improve the scaling performance. We hope that our research can\npromote to re-examine the role of complicated prompting, unleash the potential\nof simple prompting strategies, and provide new insights for enhancing\ntest-time scaling performance.",
      "tldr_zh": "这篇论文重新审视了在LLM测试时扩展中不同提示策略的作用，从概率理论视角出发，焦点是majority voting设置。实验结果显示，随着采样次数和计算开销增加，复杂的提示策略尽管初始性能优越，但逐渐落后于简单的Chain-of-Thought策略。作者通过系统实验（6个LLM × 8个提示策略 × 6个基准）和理论证明分析了这一现象，并提出了一种基于概率理论的方法，能够快速预测扩展性能并选择最佳策略，而无需额外资源密集型推理。该方法作为majority voting的测试时扩展法则，还引入两种新方式来显著提升性能，从而释放简单提示策略的潜力并提供新见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2025 Main",
      "pdf_url": "http://arxiv.org/pdf/2505.10981v1",
      "published_date": "2025-05-16 08:28:57 UTC",
      "updated_date": "2025-05-16 08:28:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:05:14.125409"
    },
    {
      "arxiv_id": "2505.10978v1",
      "title": "Group-in-Group Policy Optimization for LLM Agent Training",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Feng",
        "Zhenghai Xue",
        "Tingcong Liu",
        "Bo An"
      ],
      "abstract": "Recent advances in group-based reinforcement learning (RL) have driven\nfrontier large language models (LLMs) in single-turn tasks like mathematical\nreasoning. However, their scalability to long-horizon LLM agent training\nremains limited. Unlike static tasks, agent-environment interactions unfold\nover many steps and often yield sparse or delayed rewards, making credit\nassignment across individual steps significantly more challenging. In this\nwork, we propose Group-in-Group Policy Optimization (GiGPO), a novel RL\nalgorithm that achieves fine-grained credit assignment for LLM agents while\npreserving the appealing properties of group-based RL: critic-free, low memory,\nand stable convergence. GiGPO introduces a two-level structure for estimating\nrelative advantage: (i) At the episode-level, GiGPO computes macro relative\nadvantages based on groups of complete trajectories; (ii) At the step-level,\nGiGPO introduces an anchor state grouping mechanism that retroactively\nconstructs step-level groups by identifying repeated environment states across\ntrajectories. Actions stemming from the same state are grouped together,\nenabling micro relative advantage estimation. This hierarchical structure\neffectively captures both global trajectory quality and local step\neffectiveness without relying on auxiliary models or additional rollouts. We\nevaluate GiGPO on two challenging agent benchmarks, ALFWorld and WebShop, using\nQwen2.5-1.5B-Instruct and Qwen2.5-7B-Instruct. Crucially, GiGPO delivers\nfine-grained per-step credit signals and achieves performance gains of > 12\\%\non ALFWorld and > 9\\% on WebShop over the GRPO baseline: all while maintaining\nthe same GPU memory overhead, identical LLM rollout, and incurring little to no\nadditional time cost.",
      "tldr_zh": "该研究提出了一种名为 Group-in-Group Policy Optimization (GiGPO) 的新强化学习 (RL) 算法，用于训练大型语言模型 (LLMs) 代理，以解决长周期任务中信用分配的挑战。GiGPO 采用两级结构估计相对优势：剧集级基于完整轨迹组计算宏观相对优势，步骤级通过锚定状态分组机制识别重复环境状态，从而实现细粒度的微观相对优势估计，同时保持低内存和稳定收敛。实验在 ALFWorld 和 WebShop 基准上显示，GiGPO 相较于 GRPO 基线提升了超过 12% 和 9% 的性能，且不增加 GPU 内存或时间开销。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Preprint",
      "pdf_url": "http://arxiv.org/pdf/2505.10978v1",
      "published_date": "2025-05-16 08:26:59 UTC",
      "updated_date": "2025-05-16 08:26:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:05:26.238036"
    },
    {
      "arxiv_id": "2505.10975v1",
      "title": "Survey of End-to-End Multi-Speaker Automatic Speech Recognition for Monaural Audio",
      "title_zh": "翻译失败",
      "authors": [
        "Xinlu He",
        "Jacob Whitehill"
      ],
      "abstract": "Monaural multi-speaker automatic speech recognition (ASR) remains challenging\ndue to data scarcity and the intrinsic difficulty of recognizing and\nattributing words to individual speakers, particularly in overlapping speech.\nRecent advances have driven the shift from cascade systems to end-to-end (E2E)\narchitectures, which reduce error propagation and better exploit the synergy\nbetween speech content and speaker identity. Despite rapid progress in E2E\nmulti-speaker ASR, the field lacks a comprehensive review of recent\ndevelopments. This survey provides a systematic taxonomy of E2E neural\napproaches for multi-speaker ASR, highlighting recent advances and comparative\nanalysis. Specifically, we analyze: (1) architectural paradigms (SIMO vs.~SISO)\nfor pre-segmented audio, analyzing their distinct characteristics and\ntrade-offs; (2) recent architectural and algorithmic improvements based on\nthese two paradigms; (3) extensions to long-form speech, including segmentation\nstrategy and speaker-consistent hypothesis stitching. Further, we (4) evaluate\nand compare methods across standard benchmarks. We conclude with a discussion\nof open challenges and future research directions towards building robust and\nscalable multi-speaker ASR.",
      "tldr_zh": "这篇论文对端到-End Multi-Speaker Automatic Speech Recognition (ASR) 在单声道音频中的发展进行了全面调查，强调了从级联系统向E2E架构的转变，以减少错误传播并更好地整合语音内容和说话者身份。论文系统分类了E2E神经方法，包括SIMO和SISO架构的特性、权衡，以及基于这些范式的最新改进和扩展到长语音的策略，如分段和说话者一致假设拼接。最终，通过基准测试评估和比较不同方法，并讨论了构建鲁棒、可扩展多说话人ASR的开放挑战和未来研究方向。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SD",
        "eess.AS"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages. Submitted to IEEE/ACM Transaction on Audio Speech and\n  Language Processing (TASLP)",
      "pdf_url": "http://arxiv.org/pdf/2505.10975v1",
      "published_date": "2025-05-16 08:21:59 UTC",
      "updated_date": "2025-05-16 08:21:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:05:37.305959"
    },
    {
      "arxiv_id": "2505.10973v2",
      "title": "GRoQ-Loco: Generalist and Robot-agnostic Quadruped Locomotion Control using Offline Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Narayanan PP",
        "Sarvesh Prasanth Venkatesan",
        "Srinivas Kantha Reddy",
        "Shishir Kolathaya"
      ],
      "abstract": "Recent advancements in large-scale offline training have demonstrated the\npotential of generalist policy learning for complex robotic tasks. However,\napplying these principles to legged locomotion remains a challenge due to\ncontinuous dynamics and the need for real-time adaptation across diverse\nterrains and robot morphologies. In this work, we propose GRoQ-Loco, a\nscalable, attention-based framework that learns a single generalist locomotion\npolicy across multiple quadruped robots and terrains, relying solely on offline\ndatasets. Our approach leverages expert demonstrations from two distinct\nlocomotion behaviors - stair traversal (non-periodic gaits) and flat terrain\ntraversal (periodic gaits) - collected across multiple quadruped robots, to\ntrain a generalist model that enables behavior fusion for both behaviors.\nCrucially, our framework operates directly on proprioceptive data from all\nrobots without incorporating any robot-specific encodings. The policy is\ndirectly deployable on an Intel i7 nuc, producing low-latency control outputs\nwithout any test-time optimization. Our extensive experiments demonstrate\nstrong zero-shot transfer across highly diverse quadruped robots and terrains,\nincluding hardware deployment on the Unitree Go1, a commercially available 12kg\nrobot. Notably, we evaluate challenging cross-robot training setups where\ndifferent locomotion skills are unevenly distributed across robots, yet observe\nsuccessful transfer of both flat walking and stair traversal behaviors to all\nrobots at test time. We also show preliminary walking on Stoch 5, a 70kg\nquadruped, on flat and outdoor terrains without requiring any fine tuning.\nThese results highlight the potential for robust generalist locomotion across\ndiverse robots and terrains.",
      "tldr_zh": "本研究提出 GRoQ-Loco，一种通用的注意力-based 框架，利用离线数据集训练单一的四足机器人步态控制策略，该策略适用于多种机器人和地形（如楼梯和平地），并通过行为融合实现零样本转移，而不依赖机器人特定编码。\n框架仅基于本体感觉数据（proprioceptive data）生成低延迟控制输出，可直接部署在 Intel i7 nuc 上。\n实验结果显示，GRoQ-Loco 在不同机器人（如 Unitree Go1 和 Stoch 5）上实现了强零样本转移，即使在技能分布不均的跨机器人训练中，也能成功执行平地行走和楼梯遍历行为，突显了其在多样化机器人和地形上的鲁棒潜力。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "I.2.9"
      ],
      "primary_category": "cs.RO",
      "comment": "18pages, 16figures, 6tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10973v2",
      "published_date": "2025-05-16 08:17:01 UTC",
      "updated_date": "2025-05-20 09:59:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:05:50.433520"
    },
    {
      "arxiv_id": "2505.10962v1",
      "title": "MPS-Prover: Advancing Stepwise Theorem Proving by Multi-Perspective Search and Data Curation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhenwen Liang",
        "Linfeng Song",
        "Yang Li",
        "Tao Yang",
        "Feng Zhang",
        "Haitao Mi",
        "Dong Yu"
      ],
      "abstract": "Automated Theorem Proving (ATP) in formal languages remains a formidable\nchallenge in AI, demanding rigorous logical deduction and navigating vast\nsearch spaces. While large language models (LLMs) have shown promising\nperformance, existing stepwise provers often suffer from biased search\nguidance, leading to inefficiencies and suboptimal proof strategies. This paper\nintroduces the Multi-Perspective Search Prover (MPS-Prover), a novel stepwise\nATP system designed to overcome these limitations. MPS-Prover incorporates two\nkey innovations: a highly effective post-training data curation strategy that\nprunes approximately 40% of redundant training data without sacrificing\nperformance, and a multi-perspective tree search mechanism. This search\nintegrates a learned critic model with strategically designed heuristic rules\nto diversify tactic selection, prevent getting trapped in unproductive states,\nand enhance search robustness. Extensive evaluations demonstrate that\nMPS-Prover achieves state-of-the-art performance on multiple challenging\nbenchmarks, including miniF2F and ProofNet, outperforming prior 7B parameter\nmodels. Furthermore, our analyses reveal that MPS-Prover generates\nsignificantly shorter and more diverse proofs compared to existing stepwise and\nwhole-proof methods, highlighting its efficiency and efficacy. Our work\nadvances the capabilities of LLM-based formal reasoning and offers a robust\nframework and a comprehensive analysis for developing more powerful theorem\nprovers.",
      "tldr_zh": "这篇论文介绍了 MPS-Prover，一种新型的 stepwise Automated Theorem Proving (ATP) 系统，旨在解决现有证明器因偏见的搜索指导而导致的效率问题。MPS-Prover 的关键创新包括高效的后训练数据整理策略，可修剪约40%的冗余数据而不影响性能，以及多视角树搜索机制，该机制结合学习型批评模型和启发式规则来多元化策略选择并提升搜索鲁棒性。在 miniF2F 和 ProofNet 等基准测试中，MPS-Prover 超过了现有 7B 参数模型，生成更短、更多样化的证明，展示了其高效性和有效性。该工作为基于 Large Language Models (LLMs) 的正式推理提供了稳健框架和全面分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2505.10962v1",
      "published_date": "2025-05-16 07:56:03 UTC",
      "updated_date": "2025-05-16 07:56:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:06:03.597155"
    },
    {
      "arxiv_id": "2505.10961v1",
      "title": "Let the Trial Begin: A Mock-Court Approach to Vulnerability Detection using LLM-Based Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Ratnadira Widyasari",
        "Martin Weyssow",
        "Ivana Clairine Irsan",
        "Han Wei Ang",
        "Frank Liauw",
        "Eng Lieh Ouh",
        "Lwin Khin Shar",
        "Hong Jin Kang",
        "David Lo"
      ],
      "abstract": "Detecting vulnerabilities in source code remains a critical yet challenging\ntask, especially when benign and vulnerable functions share significant\nsimilarities. In this work, we introduce VulTrial, a courtroom-inspired\nmulti-agent framework designed to enhance automated vulnerability detection. It\nemploys four role-specific agents, which are security researcher, code author,\nmoderator, and review board. Through extensive experiments using GPT-3.5 and\nGPT-4o we demonstrate that Vultrial outperforms single-agent and multi-agent\nbaselines. Using GPT-4o, VulTrial improves the performance by 102.39% and\n84.17% over its respective baseline. Additionally, we show that role-specific\ninstruction tuning in multi-agent with small data (50 pair samples) improves\nthe performance of VulTrial further by 139.89% and 118.30%. Furthermore, we\nanalyze the impact of increasing the number of agent interactions on VulTrial's\noverall performance. While multi-agent setups inherently incur higher costs due\nto increased token usage, our findings reveal that applying VulTrial to a\ncost-effective model like GPT-3.5 can improve its performance by 69.89%\ncompared to GPT-4o in a single-agent setting, at a lower overall cost.",
      "tldr_zh": "本研究引入了VulTrial，一种模拟法庭的多智能体框架，用于提升源代码漏洞检测的准确性，该框架包括安全研究员、代码作者、moderator和review board四个角色特定代理。实验使用GPT-3.5和GPT-4o显示，VulTrial比单智能体和多智能体基线性能大幅提升，使用GPT-4o时较基线提高了102.39%和84.17%。此外，通过角色特定指令微调和小数据（50对样本），框架的性能进一步提升139.89%和118.30%，同时分析表明增加代理互动可优化效果，而在成本有效的GPT-3.5模型上，其性能较GPT-4o单智能体设置提高了69.89%。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10961v1",
      "published_date": "2025-05-16 07:54:10 UTC",
      "updated_date": "2025-05-16 07:54:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:06:14.639354"
    },
    {
      "arxiv_id": "2505.10960v1",
      "title": "Relational Graph Transformer",
      "title_zh": "关系图 Transformer",
      "authors": [
        "Vijay Prakash Dwivedi",
        "Sri Jaladi",
        "Yangyi Shen",
        "Federico López",
        "Charilaos I. Kanatsoulis",
        "Rishi Puri",
        "Matthias Fey",
        "Jure Leskovec"
      ],
      "abstract": "Relational Deep Learning (RDL) is a promising approach for building\nstate-of-the-art predictive models on multi-table relational data by\nrepresenting it as a heterogeneous temporal graph. However, commonly used Graph\nNeural Network models suffer from fundamental limitations in capturing complex\nstructural patterns and long-range dependencies that are inherent in relational\ndata. While Graph Transformers have emerged as powerful alternatives to GNNs on\ngeneral graphs, applying them to relational entity graphs presents unique\nchallenges: (i) Traditional positional encodings fail to generalize to massive,\nheterogeneous graphs; (ii) existing architectures cannot model the temporal\ndynamics and schema constraints of relational data; (iii) existing tokenization\nschemes lose critical structural information. Here we introduce the Relational\nGraph Transformer (RelGT), the first graph transformer architecture designed\nspecifically for relational tables. RelGT employs a novel multi-element\ntokenization strategy that decomposes each node into five components (features,\ntype, hop distance, time, and local structure), enabling efficient encoding of\nheterogeneity, temporality, and topology without expensive precomputation. Our\narchitecture combines local attention over sampled subgraphs with global\nattention to learnable centroids, incorporating both local and database-wide\nrepresentations. Across 21 tasks from the RelBench benchmark, RelGT\nconsistently matches or outperforms GNN baselines by up to 18%, establishing\nGraph Transformers as a powerful architecture for Relational Deep Learning.",
      "tldr_zh": "该研究针对Relational Deep Learning (RDL)中Graph Neural Network (GNNs)的局限性，如无法有效捕捉复杂结构模式和长距离依赖，提出了一种专门针对关系表的Graph Transformer架构——Relational Graph Transformer (RelGT)。RelGT采用创新的多元素标记策略，将每个节点分解为features、type、hop distance、time和local structure五个组件，从而高效编码异构性、时间性和拓扑信息，而无需昂贵预计算；其架构结合了在采样子图上的局部注意力与对可学习中心点的全局注意力，以整合局部和数据库范围表示。在RelBench基准的21个任务上，RelGT比GNN基线提高高达18%，确立了Graph Transformers在RDL中的强大优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.LG",
      "comment": "Code: https://github.com/snap-stanford/relgt",
      "pdf_url": "http://arxiv.org/pdf/2505.10960v1",
      "published_date": "2025-05-16 07:51:58 UTC",
      "updated_date": "2025-05-16 07:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:06:27.264947"
    },
    {
      "arxiv_id": "2505.10954v1",
      "title": "Constrained Preferential Bayesian Optimization and Its Application in Banner Ad Design",
      "title_zh": "翻译失败",
      "authors": [
        "Koki Iwai",
        "Yusuke Kumagae",
        "Yuki Koyama",
        "Masahiro Hamasaki",
        "Masataka Goto"
      ],
      "abstract": "Preferential Bayesian optimization (PBO) is a variant of Bayesian\noptimization that observes relative preferences (e.g., pairwise comparisons)\ninstead of direct objective values, making it especially suitable for\nhuman-in-the-loop scenarios. However, real-world optimization tasks often\ninvolve inequality constraints, which existing PBO methods have not yet\naddressed. To fill this gap, we propose constrained preferential Bayesian\noptimization (CPBO), an extension of PBO that incorporates inequality\nconstraints for the first time. Specifically, we present a novel acquisition\nfunction for this purpose. Our technical evaluation shows that our CPBO method\nsuccessfully identifies optimal solutions by focusing on exploring feasible\nregions. As a practical application, we also present a designer-in-the-loop\nsystem for banner ad design using CPBO, where the objective is the designer's\nsubjective preference, and the constraint ensures a target predicted\nclick-through rate. We conducted a user study with professional ad designers,\ndemonstrating the potential benefits of our approach in guiding creative design\nunder real-world constraints.",
      "tldr_zh": "本文提出Constrained Preferential Bayesian Optimization (CPBO)，这是Preferential Bayesian Optimization (PBO)的扩展，首次加入不等式约束以处理真实优化任务中的限制。CPBO引入了一个新的acquisition function，专注于探索可行区域，从而成功识别最优解。实验评估和用户研究表明，该方法在banner ad设计中的实际应用中有效指导设计师的主观偏好，同时确保目标预测点击率约束，提高了创意设计效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GR",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 15 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10954v1",
      "published_date": "2025-05-16 07:41:07 UTC",
      "updated_date": "2025-05-16 07:41:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:06:38.467185"
    },
    {
      "arxiv_id": "2505.10945v2",
      "title": "Semantic Aware Linear Transfer by Recycling Pre-trained Language Models for Cross-lingual Transfer",
      "title_zh": "翻译失败",
      "authors": [
        "Seungyoon Lee",
        "Seongtae Hong",
        "Hyeonseok Moon",
        "Heuiseok Lim"
      ],
      "abstract": "Large Language Models (LLMs) increasingly incorporate multilingual\ncapabilities, fueling the demand to transfer them into target language-specific\nmodels. However, most approaches, which blend the source model's embedding by\nreplacing the source vocabulary with the target language-specific vocabulary,\nmay constrain expressive capacity in the target language since the source model\nis predominantly trained on English data. In this paper, we propose Semantic\nAware Linear Transfer (SALT), a novel cross-lingual transfer technique that\nrecycles embeddings from target language Pre-trained Language Models (PLMs) to\ntransmit the deep representational strengths of PLM-derived embedding to LLMs.\nSALT derives unique regression lines based on the similarity in the overlap of\nthe source and target vocabularies, to handle each non-overlapping token's\nembedding space. Our extensive experiments show that SALT significantly\noutperforms other transfer methods and achieves lower loss with accelerating\nfaster convergence during language adaptation. Notably, SALT obtains remarkable\nperformance in cross-lingual understanding setups compared to other methods.\nFurthermore, we highlight the scalable use of PLMs to enhance the functionality\nof contemporary LLMs by conducting experiments with varying architectures.",
      "tldr_zh": "本文提出了一种名为 Semantic Aware Linear Transfer (SALT) 的新方法，用于跨语言转移，通过回收目标语言的 Pre-trained Language Models (PLMs) 嵌入，将 PLMs 的深度表示能力传输到 Large Language Models (LLMs)，以克服传统方法在目标语言表达能力上的限制。SALT 根据源语言和目标语言词汇重叠的相似性，衍生独特的回归线来处理非重叠词的嵌入空间，从而提升转移效率。实验显示，SALT 在跨语言理解任务中显著优于其他方法，实现了更低的损失、更快的收敛，并证明了使用不同架构的 PLMs 来增强 LLMs 的可扩展性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 Findings",
      "pdf_url": "http://arxiv.org/pdf/2505.10945v2",
      "published_date": "2025-05-16 07:30:22 UTC",
      "updated_date": "2025-05-22 11:54:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:06:51.804307"
    },
    {
      "arxiv_id": "2505.10940v2",
      "title": "Who You Are Matters: Bridging Topics and Social Roles via LLM-Enhanced Logical Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Qing Yu",
        "Xiaobei Wang",
        "Shuchang Liu",
        "Yandong Bai",
        "Xiaoyu Yang",
        "Xueliang Wang",
        "Chang Meng",
        "Shanshan Wu",
        "Hailan Yang",
        "Huihui Xiao",
        "Xiang Li",
        "Fan Yang",
        "Xiaoqiang Feng",
        "Lantao Hu",
        "Han Li",
        "Kun Gai",
        "Lixin Zou"
      ],
      "abstract": "Recommender systems filter contents/items valuable to users by inferring\npreferences from user features and historical behaviors. Mainstream approaches\nfollow the learning-to-rank paradigm, which focus on discovering and modeling\nitem topics (e.g., categories), and capturing user preferences on these topics\nbased on historical interactions. However, this paradigm often neglects the\nmodeling of user characteristics and their social roles, which are logical\nconfounders influencing the correlated interest and user preference transition.\nTo bridge this gap, we introduce the user role identification task and the\nbehavioral logic modeling task that aim to explicitly model user roles and\nlearn the logical relations between item topics and user social roles. We show\nthat it is possible to explicitly solve these tasks through an efficient\nintegration framework of Large Language Model (LLM) and recommendation systems,\nfor which we propose TagCF. On the one hand, TagCF exploits the (Multi-modal)\nLLM's world knowledge and logic inference ability to extract realistic\ntag-based virtual logic graphs that reveal dynamic and expressive knowledge of\nusers, refining our understanding of user behaviors. On the other hand, TagCF\npresents empirically effective integration modules that take advantage of the\nextracted tag-logic information, augmenting the recommendation performance. We\nconduct both online experiments and offline experiments with industrial and\npublic datasets as verification of TagCF's effectiveness, and we empirically\nshow that the user role modeling strategy is potentially a better choice than\nthe modeling of item topics. Additionally, we provide evidence that the\nextracted logic graphs are empirically a general and transferable knowledge\nthat can benefit a wide range of recommendation tasks.",
      "tldr_zh": "本论文指出，传统推荐系统（Recommender systems）在推断用户偏好时，过度关注项目主题（如类别）而忽略用户特征和社会角色，这些因素是影响用户兴趣和偏好转变的逻辑混杂因素。为解决此问题，作者引入用户角色识别任务和行为逻辑建模任务，并提出TagCF框架，该框架通过整合Large Language Model (LLM)的世界知识和逻辑推理能力，提取基于标签的虚拟逻辑图来动态理解用户行为。TagCF利用这些逻辑图增强推荐模块，提升系统性能；实验在工业和公共数据集上验证，显示用户角色建模比项目主题建模更有效，且提取的逻辑图具有通用性和可转移性，能惠及多种推荐任务。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10940v2",
      "published_date": "2025-05-16 07:26:41 UTC",
      "updated_date": "2025-05-20 06:58:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:07:05.650019"
    },
    {
      "arxiv_id": "2505.10939v1",
      "title": "GenKnowSub: Improving Modularity and Reusability of LLMs through General Knowledge Subtraction",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammadtaha Bagherifard",
        "Sahar Rajabi",
        "Ali Edalat",
        "Yadollah Yaghoobzadeh"
      ],
      "abstract": "Large language models often struggle with zero-shot generalization, and\nseveral modular approaches have been proposed to address this challenge. Yet,\nwe hypothesize that a key limitation remains: the entanglement of general\nknowledge and task-specific adaptations. To overcome this, we propose a modular\nframework that disentangles these components by constructing a library of\ntask-specific LoRA modules alongside a general-domain LoRA. By subtracting this\ngeneral knowledge component from each task-specific module, we obtain residual\nmodules that focus more exclusively on task-relevant information, a method we\ncall general knowledge subtraction (GenKnowSub). Leveraging the refined\ntask-specific modules and the Arrow routing algorithm\n\\citep{ostapenko2024towards}, we dynamically select and combine modules for new\ninputs without additional training. Our studies on the Phi-3 model and standard\nArrow as baselines reveal that using general knowledge LoRAs derived from\ndiverse languages, including English, French, and German, yields consistent\nperformance gains in both monolingual and cross-lingual settings across a wide\nset of benchmarks. Further experiments on Phi-2 demonstrate how GenKnowSub\ngeneralizes to weaker LLMs. The complete code and data are available at\nhttps://github.com/saharsamr/Modular-LLM.",
      "tldr_zh": "该研究提出了一种名为 GenKnowSub 的方法，以提升大型语言模型（LLMs）的模块性和可重用性，通过从任务特定 LoRA 模块中减去一般知识组件来解决一般知识与任务适配的纠缠问题。具体而言，该框架构建任务特定 LoRA 模块和一个一般域 LoRA，利用一般知识减法（GenKnowSub）获得更专注任务的相关残差模块，并结合 Arrow routing algorithm 动态选择和组合模块，而无需额外训练。实验在 Phi-3 模型上显示，使用多种语言（如英语、法语和德语）的 LoRA 模块，在单语和跨语基准测试中实现了稳定的性能提升；在 Phi-2 模型上进一步验证了该方法的泛化性。代码和数据已在 GitHub 上公开，为模块化 LLM 的发展提供了实用工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2025 (main conference, short paper), 10 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.10939v1",
      "published_date": "2025-05-16 07:23:59 UTC",
      "updated_date": "2025-05-16 07:23:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:07:17.224978"
    },
    {
      "arxiv_id": "2505.10937v1",
      "title": "Reasoning with OmniThought: A Large CoT Dataset with Verbosity and Cognitive Difficulty Annotations",
      "title_zh": "翻译失败",
      "authors": [
        "Wenrui Cai",
        "Chengyu Wang",
        "Junbing Yan",
        "Jun Huang",
        "Xiangzhong Fang"
      ],
      "abstract": "The emergence of large reasoning models (LRMs) has transformed Natural\nLanguage Processing by excelling in complex tasks such as mathematical\nproblem-solving and code generation. These models leverage chain-of-thought\n(CoT) processes, enabling them to emulate human-like reasoning strategies.\nHowever, the advancement of LRMs is hindered by the lack of comprehensive CoT\ndatasets. Current resources often fail to provide extensive reasoning problems\nwith coherent CoT processes distilled from multiple teacher models and do not\naccount for multifaceted properties describing the internal characteristics of\nCoTs. To address these challenges, we introduce OmniThought, a large-scale\ndataset featuring 2 million CoT processes generated and validated by two\npowerful LRMs as teacher models. Each CoT process in OmniThought is annotated\nwith novel Reasoning Verbosity (RV) and Cognitive Difficulty (CD) scores, which\ndescribe the appropriateness of CoT verbosity and cognitive difficulty level\nfor models to comprehend these reasoning processes. We further establish a\nself-reliant pipeline to curate this dataset. Extensive experiments using\nQwen2.5 models of various sizes demonstrate the positive impact of our proposed\nscores on LRM training effectiveness. Based on the proposed OmniThought\ndataset, we further train and release a series of high-performing LRMs,\nspecifically equipped with stronger reasoning abilities and optimal CoT output\nlength and difficulty level. Our contributions significantly enhance the\ndevelopment and training of LRMs for solving complex tasks.",
      "tldr_zh": "该研究介绍了 OmniThought，这是一个大规模数据集，包含 200 万条 Chain-of-Thought (CoT) 过程，由两个强大的 Large Reasoning Models (LRMs) 生成并验证，以解决现有 CoT 资源缺乏全面性和多方面属性的问题。每个 CoT 过程标注了 Reasoning Verbosity (RV) 和 Cognitive Difficulty (CD) 分数，这些分数评估了 CoT 冗长度的适当性和认知难度水平，并通过一个自给自足的管道进行整理。实验使用 Qwen2.5 模型的不同规模证明了这些分数对 LRM 训练的有效性提升，最终基于 OmniThought 数据集训练并发布了系列高性能 LRM，这些模型具备更强的推理能力并优化了 CoT 输出长度和难度，从而显著推进复杂任务的解决。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10937v1",
      "published_date": "2025-05-16 07:15:30 UTC",
      "updated_date": "2025-05-16 07:15:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:07:29.341175"
    },
    {
      "arxiv_id": "2505.15832v1",
      "title": "From Hand-Crafted Metrics to Evolved Training-Free Performance Predictors for Neural Architecture Search via Genetic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Quan Minh Phan",
        "Ngoc Hoang Luong"
      ],
      "abstract": "Estimating the network performance using zero-cost (ZC) metrics has proven\nboth its efficiency and efficacy in Neural Architecture Search (NAS). However,\na notable limitation of most ZC proxies is their inconsistency, as reflected by\nthe substantial variation in their performance across different problems.\nFurthermore, the design of existing ZC metrics is manual, involving a\ntime-consuming trial-and-error process that requires substantial domain\nexpertise. These challenges raise two critical questions: (1) Can we automate\nthe design of ZC metrics? and (2) Can we utilize the existing hand-crafted ZC\nmetrics to synthesize a more generalizable one? In this study, we propose a\nframework based on Symbolic Regression via Genetic Programming to automate the\ndesign of ZC metrics. Our framework is not only highly extensible but also\ncapable of quickly producing a ZC metric with a strong positive rank\ncorrelation to true network performance across diverse NAS search spaces and\ntasks. Extensive experiments on 13 problems from NAS-Bench-Suite-Zero\ndemonstrate that our automatically generated proxies consistently outperform\nhand-crafted alternatives. Using our evolved proxy metric as the search\nobjective in an evolutionary algorithm, we could identify network architectures\nwith competitive performance within 15 minutes using a single consumer GPU.",
      "tldr_zh": "该研究针对神经架构搜索(NAS)中的零成本(ZC)指标不一致性和手动设计问题，提出了一个基于符号回归(Symbolic Regression)和遗传编程(Genetic Programming)的自动化框架，以演化出更通用的训练无需求测性能预测指标。该框架能快速生成ZC指标，与真实网络性能保持强正秩相关性，并在不同NAS搜索空间和任务中表现出色。在NAS-Bench-Suite-Zero的13个问题上，自动生成的代理指标比手工指标表现更优越。最终，使用该演化指标作为进化算法的搜索目标，仅需15分钟在单消费者GPU上识别出具有竞争力的网络架构。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.15832v1",
      "published_date": "2025-05-16 07:12:42 UTC",
      "updated_date": "2025-05-16 07:12:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:07:40.984908"
    },
    {
      "arxiv_id": "2505.11563v1",
      "title": "Object-Centric Representations Improve Policy Generalization in Robot Manipulation",
      "title_zh": "对象中心表示改善了机器人操作中的策略泛化",
      "authors": [
        "Alexandre Chapin",
        "Bruno Machado",
        "Emmanuel Dellandrea",
        "Liming Chen"
      ],
      "abstract": "Visual representations are central to the learning and generalization\ncapabilities of robotic manipulation policies. While existing methods rely on\nglobal or dense features, such representations often entangle task-relevant and\nirrelevant scene information, limiting robustness under distribution shifts. In\nthis work, we investigate object-centric representations (OCR) as a structured\nalternative that segments visual input into a finished set of entities,\nintroducing inductive biases that align more naturally with manipulation tasks.\nWe benchmark a range of visual encoders-object-centric, global and dense\nmethods-across a suite of simulated and real-world manipulation tasks ranging\nfrom simple to complex, and evaluate their generalization under diverse visual\nconditions including changes in lighting, texture, and the presence of\ndistractors. Our findings reveal that OCR-based policies outperform dense and\nglobal representations in generalization settings, even without task-specific\npretraining. These insights suggest that OCR is a promising direction for\ndesigning visual systems that generalize effectively in dynamic, real-world\nrobotic environments.",
      "tldr_zh": "本文研究了对象中心表示 (OCR) 如何提升机器人操作策略的泛化能力，解决现有全局或密集特征方法中任务相关和无关信息纠缠的问题，从而提高在分布偏移下的鲁棒性。研究者通过基准测试 OCR 与其他视觉编码器（如全局和密集方法）在模拟和真实世界操作任务上，包括简单到复杂的场景，并评估了在光照、纹理变化和干扰物存在下的泛化表现。结果显示，OCR-based 策略在这些条件下显著优于基线方法，即使没有任务特定预训练，这表明 OCR 是设计动态真实世界机器人视觉系统的有前景方向。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.11563v1",
      "published_date": "2025-05-16 07:06:37 UTC",
      "updated_date": "2025-05-16 07:06:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:07:53.740540"
    },
    {
      "arxiv_id": "2505.10924v1",
      "title": "A Survey on the Safety and Security Threats of Computer-Using Agents: JARVIS or Ultron?",
      "title_zh": "翻译失败",
      "authors": [
        "Ada Chen",
        "Yongjiang Wu",
        "Junyuan Zhang",
        "Shu Yang",
        "Jen-tse Huang",
        "Kun Wang",
        "Wenxuan Wang",
        "Shuai Wang"
      ],
      "abstract": "Recently, AI-driven interactions with computing devices have advanced from\nbasic prototype tools to sophisticated, LLM-based systems that emulate\nhuman-like operations in graphical user interfaces. We are now witnessing the\nemergence of \\emph{Computer-Using Agents} (CUAs), capable of autonomously\nperforming tasks such as navigating desktop applications, web pages, and mobile\napps. However, as these agents grow in capability, they also introduce novel\nsafety and security risks. Vulnerabilities in LLM-driven reasoning, with the\nadded complexity of integrating multiple software components and multimodal\ninputs, further complicate the security landscape. In this paper, we present a\nsystematization of knowledge on the safety and security threats of CUAs. We\nconduct a comprehensive literature review and distill our findings along four\nresearch objectives: \\textit{\\textbf{(i)}} define the CUA that suits safety\nanalysis; \\textit{\\textbf{(ii)} } categorize current safety threats among CUAs;\n\\textit{\\textbf{(iii)}} propose a comprehensive taxonomy of existing defensive\nstrategies; \\textit{\\textbf{(iv)}} summarize prevailing benchmarks, datasets,\nand evaluation metrics used to assess the safety and performance of CUAs.\nBuilding on these insights, our work provides future researchers with a\nstructured foundation for exploring unexplored vulnerabilities and offers\npractitioners actionable guidance in designing and deploying secure\nComputer-Using Agents.",
      "tldr_zh": "本论文对Computer-Using Agents (CUAs)的安全和安全威胁进行了全面调查，这些代理基于LLM，能够自主操作桌面应用、网页和移动应用，但也引入了新的风险，如LLM驱动推理的漏洞和多模态输入的复杂性。通过文献综述，论文定义了适合安全分析的CUAs，分类了当前的安全威胁，并提出了现有防御策略的全面分类。同时，总结了评估CUAs安全性和性能的基准、数据集和指标，为未来研究者探索漏洞提供结构化基础，并为从业者提供设计和部署安全代理的指导。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10924v1",
      "published_date": "2025-05-16 06:56:42 UTC",
      "updated_date": "2025-05-16 06:56:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:08:05.771680"
    },
    {
      "arxiv_id": "2505.10922v1",
      "title": "Vaiage: A Multi-Agent Solution to Personalized Travel Planning",
      "title_zh": "Vaiage: 一种多智能体",
      "authors": [
        "Binwen Liu",
        "Jiexi Ge",
        "Jiamin Wang"
      ],
      "abstract": "Planning trips is a cognitively intensive task involving conflicting user\npreferences, dynamic external information, and multi-step temporal-spatial\noptimization. Traditional platforms often fall short - they provide static\nresults, lack contextual adaptation, and fail to support real-time interaction\nor intent refinement.\n  Our approach, Vaiage, addresses these challenges through a graph-structured\nmulti-agent framework built around large language models (LLMs) that serve as\nboth goal-conditioned recommenders and sequential planners. LLMs infer user\nintent, suggest personalized destinations and activities, and synthesize\nitineraries that align with contextual constraints such as budget, timing,\ngroup size, and weather. Through natural language interaction, structured tool\nuse, and map-based feedback loops, Vaiage enables adaptive, explainable, and\nend-to-end travel planning grounded in both symbolic reasoning and\nconversational understanding.\n  To evaluate Vaiage, we conducted human-in-the-loop experiments using\nrubric-based GPT-4 assessments and qualitative feedback. The full system\nachieved an average score of 8.5 out of 10, outperforming the no-strategy (7.2)\nand no-external-API (6.8) variants, particularly in feasibility. Qualitative\nanalysis indicated that agent coordination - especially the Strategy and\nInformation Agents - significantly improved itinerary quality by optimizing\ntime use and integrating real-time context. These results demonstrate the\neffectiveness of combining LLM reasoning with symbolic agent coordination in\nopen-ended, real-world planning tasks.",
      "tldr_zh": "该论文提出 Vaiage，一种基于多智能体框架的解决方案，用于解决个性化旅行规划中的用户偏好冲突、动态外部信息和多步时空优化问题。Vaiage 利用大型语言模型 (LLMs) 作为目标条件推荐器和顺序规划器，通过自然语言交互、结构化工具使用和基于地图的反馈循环来推断用户意图、建议个性化目的地和活动，并生成符合预算、时间和天气等约束的行程。实验评估显示，Vaiage 在人类参与的 GPT-4 评估中获得 8.5/10 的平均分数，优于无策略 (7.2) 和无外部 API (6.8) 变体，尤其在可行性方面表现突出，证明了智能体协调（如 Strategy and Information Agents）在提升行程质量和整合实时上下文方面的有效性。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10922v1",
      "published_date": "2025-05-16 06:54:52 UTC",
      "updated_date": "2025-05-16 06:54:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:08:18.291040"
    },
    {
      "arxiv_id": "2505.10909v1",
      "title": "Phi: Leveraging Pattern-based Hierarchical Sparsity for High-Efficiency Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Chiyue Wei",
        "Bowen Duan",
        "Cong Guo",
        "Jingyang Zhang",
        "Qingyue Song",
        "Hai \"Helen\" Li",
        "Yiran Chen"
      ],
      "abstract": "Spiking Neural Networks (SNNs) are gaining attention for their energy\nefficiency and biological plausibility, utilizing 0-1 activation sparsity\nthrough spike-driven computation. While existing SNN accelerators exploit this\nsparsity to skip zero computations, they often overlook the unique distribution\npatterns inherent in binary activations. In this work, we observe that\nparticular patterns exist in spike activations, which we can utilize to reduce\nthe substantial computation of SNN models. Based on these findings, we propose\na novel \\textbf{pattern-based hierarchical sparsity} framework, termed\n\\textbf{\\textit{Phi}}, to optimize computation.\n  \\textit{Phi} introduces a two-level sparsity hierarchy: Level 1 exhibits\nvector-wise sparsity by representing activations with pre-defined patterns,\nallowing for offline pre-computation with weights and significantly reducing\nmost runtime computation. Level 2 features element-wise sparsity by\ncomplementing the Level 1 matrix, using a highly sparse matrix to further\nreduce computation while maintaining accuracy. We present an algorithm-hardware\nco-design approach. Algorithmically, we employ a k-means-based pattern\nselection method to identify representative patterns and introduce a\npattern-aware fine-tuning technique to enhance Level 2 sparsity.\nArchitecturally, we design \\textbf{\\textit{Phi}}, a dedicated hardware\narchitecture that efficiently processes the two levels of \\textit{Phi} sparsity\non the fly. Extensive experiments demonstrate that \\textit{Phi} achieves a\n$3.45\\times$ speedup and a $4.93\\times$ improvement in energy efficiency\ncompared to state-of-the-art SNN accelerators, showcasing the effectiveness of\nour framework in optimizing SNN computation.",
      "tldr_zh": "本研究提出 Phi 框架，利用基于模式的层次稀疏（pattern-based hierarchical sparsity）来优化 Spiking Neural Networks (SNNs) 的计算效率，针对现有加速器忽略的 spike 激活模式进行改进。Phi 采用两级稀疏结构：Level 1 通过预定义模式实现向量级稀疏，支持离线预计算以减少运行时运算；Level 2 通过元素级稀疏补充第一级，进一步降低计算量，同时维持模型准确性。实验结果显示，Phi 通过算法-硬件协同设计（如 k-means 基于的模式选择和模式感知微调），相较于最先进 SNN 加速器，实现了 3.45 倍的加速和 4.93 倍的能效提升。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "ISCA 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10909v1",
      "published_date": "2025-05-16 06:29:24 UTC",
      "updated_date": "2025-05-16 06:29:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:08:29.436946"
    },
    {
      "arxiv_id": "2505.10903v1",
      "title": "On the Security Risks of ML-based Malware Detection Systems: A Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Ping He",
        "Yuhao Mao",
        "Changjiang Li",
        "Lorenzo Cavallaro",
        "Ting Wang",
        "Shouling Ji"
      ],
      "abstract": "Malware presents a persistent threat to user privacy and data integrity. To\ncombat this, machine learning-based (ML-based) malware detection (MD) systems\nhave been developed. However, these systems have increasingly been attacked in\nrecent years, undermining their effectiveness in practice. While the security\nrisks associated with ML-based MD systems have garnered considerable attention,\nthe majority of prior works is limited to adversarial malware examples, lacking\na comprehensive analysis of practical security risks. This paper addresses this\ngap by utilizing the CIA principles to define the scope of security risks. We\nthen deconstruct ML-based MD systems into distinct operational stages, thus\ndeveloping a stage-based taxonomy. Utilizing this taxonomy, we summarize the\ntechnical progress and discuss the gaps in the attack and defense proposals\nrelated to the ML-based MD systems within each stage. Subsequently, we conduct\ntwo case studies, using both inter-stage and intra-stage analyses according to\nthe stage-based taxonomy to provide new empirical insights. Based on these\nanalyses and insights, we suggest potential future directions from both\ninter-stage and intra-stage perspectives.",
      "tldr_zh": "本调查论文探讨了基于机器学习（ML-based）恶意软件检测（MD）系统的安全风险，强调现有研究主要局限于对抗性恶意软件样本，而忽略了全面分析。论文采用 CIA principles（机密性、完整性和可用性）定义风险范围，并将 ML-based MD 系统分解为不同操作阶段，开发了一个 stage-based taxonomy 来总结各阶段的攻击和防御进展，并讨论其差距。通过两个案例研究，进行 inter-stage 和 intra-stage 分析，提供了新的实证见解。最终，论文从阶段间和阶段内视角提出潜在未来研究方向，以提升这些系统的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10903v1",
      "published_date": "2025-05-16 06:15:31 UTC",
      "updated_date": "2025-05-16 06:15:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:08:41.477266"
    },
    {
      "arxiv_id": "2505.10900v2",
      "title": "Explain What You Mean: Intent Augmented Knowledge Graph Recommender Built With An LLM",
      "title_zh": "翻译失败",
      "authors": [
        "Wenqing Zheng",
        "Noah Fatsi",
        "Daniel Barcklow",
        "Dmitri Kalaev",
        "Steven Yao",
        "Owen Reinert",
        "C. Bayan Bruss",
        "Daniele Rosa"
      ],
      "abstract": "Interaction sparsity is a long-standing challenge in recommendation systems.\nSparsity manifests in environments with disproportional cardinality of\ngroupings of entities, such as users and products in an online marketplace. It\nis also found for newly introduced entities, described as the cold-start\nproblem. Recent efforts to mitigate this issue either enrich the connectivity\ndata by incorporating social networks or external knowledge graphs, or\nfine-tune LLMs into interaction augmenters or next-item recommenders. However,\nthese techniques tend to be resource demanding, requiring high computational\npower. They also have several limitations, including data availability, low\nquality, or synthetic noise issues. In this work, we propose LLM-based Intent\nKnowledge Graph Recommender (IKGR), a novel framework that leverages\nretrieval-augmented generation and an encoding approach to construct and\ndensify a knowledge graph. IKGR leverages latent user-item affinities from an\ninteraction knowledge graph and further densifies it through mutual intent\nconnectivity. This addresses sparsity issues and allows the model to make\nintent-grounded recommendations with an interpretable embedding translation\nlayer. Through extensive experiments on real-world datasets, we demonstrate\nthat IKGR overcomes knowledge gaps and achieves substantial gains over\nstate-of-the-art baselines on both publicly available and our internal\nrecommendation datasets.",
      "tldr_zh": "该论文针对推荐系统中的交互稀疏性问题（如实体分组不平衡和冷启动），提出了一种基于LLM的Intent Knowledge Graph Recommender (IKGR)框架。IKGR利用retrieval-augmented generation和编码方法来构建并稠密化知识图，通过提取用户-物品亲和力和相互意图连接性，增强图的密度并实现可解释的嵌入翻译层。相比传统方法，IKGR减少了对高计算资源的依赖，并提供意图导向的推荐。实验在真实数据集上表明，IKGR显著超越最先进基线，在公开和内部数据集上实现了知识鸿沟的克服和性能提升。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10900v2",
      "published_date": "2025-05-16 06:07:19 UTC",
      "updated_date": "2025-05-21 15:33:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:08:53.383894"
    },
    {
      "arxiv_id": "2505.10887v1",
      "title": "InfantAgent-Next: A Multimodal Generalist Agent for Automated Computer Interaction",
      "title_zh": "翻译失败",
      "authors": [
        "Bin Lei",
        "Weitai Kang",
        "Zijian Zhang",
        "Winson Chen",
        "Xi Xie",
        "Shan Zuo",
        "Mimi Xie",
        "Ali Payani",
        "Mingyi Hong",
        "Yan Yan",
        "Caiwen Ding"
      ],
      "abstract": "This paper introduces \\textsc{InfantAgent-Next}, a generalist agent capable\nof interacting with computers in a multimodal manner, encompassing text,\nimages, audio, and video. Unlike existing approaches that either build\nintricate workflows around a single large model or only provide workflow\nmodularity, our agent integrates tool-based and pure vision agents within a\nhighly modular architecture, enabling different models to collaboratively solve\ndecoupled tasks in a step-by-step manner. Our generality is demonstrated by our\nability to evaluate not only pure vision-based real-world benchmarks (i.e.,\nOSWorld), but also more general or tool-intensive benchmarks (e.g., GAIA and\nSWE-Bench). Specifically, we achieve $\\mathbf{7.27\\%}$ accuracy on OSWorld,\nhigher than Claude-Computer-Use. Codes and evaluation scripts are open-sourced\nat https://github.com/bin123apple/InfantAgent.",
      "tldr_zh": "本研究介绍了InfantAgent-Next，一种多模态通用代理，用于自动化计算机交互，支持文本、图像、音频和视频等模态。该代理采用高度模块化的架构，整合基于工具的代理和pure vision agents，让不同模型协作以步步为营的方式解决解耦任务，从而超越现有方法的局限性。在实验中，InfantAgent-Next在OSWorld基准上实现了7.27%的准确率，高于Claude-Computer-Use，并在GAIA和SWE-Bench等基准上展现出通用性；代码已开源于GitHub。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10887v1",
      "published_date": "2025-05-16 05:43:27 UTC",
      "updated_date": "2025-05-16 05:43:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:09:04.984146"
    },
    {
      "arxiv_id": "2505.10885v1",
      "title": "BanglaFake: Constructing and Evaluating a Specialized Bengali Deepfake Audio Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Istiaq Ahmed Fahad",
        "Kamruzzaman Asif",
        "Sifat Sikder"
      ],
      "abstract": "Deepfake audio detection is challenging for low-resource languages like\nBengali due to limited datasets and subtle acoustic features. To address this,\nwe introduce BangalFake, a Bengali Deepfake Audio Dataset with 12,260 real and\n13,260 deepfake utterances. Synthetic speech is generated using SOTA\nText-to-Speech (TTS) models, ensuring high naturalness and quality. We evaluate\nthe dataset through both qualitative and quantitative analyses. Mean Opinion\nScore (MOS) from 30 native speakers shows Robust-MOS of 3.40 (naturalness) and\n4.01 (intelligibility). t-SNE visualization of MFCCs highlights real vs. fake\ndifferentiation challenges. This dataset serves as a crucial resource for\nadvancing deepfake detection in Bengali, addressing the limitations of\nlow-resource language research.",
      "tldr_zh": "该论文构建了 BanglaFake 数据集，一个专门针对孟加拉语的深度伪造音频数据集，包含 12,260 个真实语音和 13,260 个使用 SOTA TTS 模型生成的合成语音，以解决低资源语言的检测挑战。数据集通过定性和定量分析进行评估，包括 30 名母语者的 MOS 评分（Robust-MOS 为 3.40 表示自然度，4.01 表示可理解性），以及 t-SNE 可视化显示的 MFCCs 差异，突显了真实与假冒语音的检测难度。该数据集为推进孟加拉语深度伪造检测研究提供了关键资源，填补了低资源语言领域的空白。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "5 page",
      "pdf_url": "http://arxiv.org/pdf/2505.10885v1",
      "published_date": "2025-05-16 05:42:25 UTC",
      "updated_date": "2025-05-16 05:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:09:19.083406"
    },
    {
      "arxiv_id": "2505.10877v1",
      "title": "Graph and Simplicial Complex Prediction Gaussian Process via the Hodgelet Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Mathieu Alain",
        "So Takao",
        "Xiaowen Dong",
        "Bastian Rieck",
        "Emmanuel Noutahi"
      ],
      "abstract": "Predicting the labels of graph-structured data is crucial in scientific\napplications and is often achieved using graph neural networks (GNNs). However,\nwhen data is scarce, GNNs suffer from overfitting, leading to poor performance.\nRecently, Gaussian processes (GPs) with graph-level inputs have been proposed\nas an alternative. In this work, we extend the Gaussian process framework to\nsimplicial complexes (SCs), enabling the handling of edge-level attributes and\nattributes supported on higher-order simplices. We further augment the\nresulting SC representations by considering their Hodge decompositions,\nallowing us to account for homological information, such as the number of\nholes, in the SC. We demonstrate that our framework enhances the predictions\nacross various applications, paving the way for GPs to be more widely used for\ngraph and SC-level predictions.",
      "tldr_zh": "该论文针对图神经网络（GNNs）在数据稀缺时易过拟合的问题，提出了一种扩展的高斯过程（GPs）框架，用于预测图和单纯复形（SCs）的标签。方法通过整合Hodge分解来处理边级属性和更高阶单纯形的同调信息，例如洞的数量，从而增强SC的表示。实验结果显示，该框架在多种应用中显著提高了预测准确性，为GPs在图和SCs级预测的广泛应用铺平了道路。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10877v1",
      "published_date": "2025-05-16 05:33:42 UTC",
      "updated_date": "2025-05-16 05:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:09:30.147991"
    },
    {
      "arxiv_id": "2505.10876v1",
      "title": "Preference Isolation Forest for Structure-based Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Leveni",
        "Luca Magri",
        "Cesare Alippi",
        "Giacomo Boracchi"
      ],
      "abstract": "We address the problem of detecting anomalies as samples that do not conform\nto structured patterns represented by low-dimensional manifolds. To this end,\nwe conceive a general anomaly detection framework called Preference Isolation\nForest (PIF), that combines the benefits of adaptive isolation-based methods\nwith the flexibility of preference embedding. The key intuition is to embed the\ndata into a high-dimensional preference space by fitting low-dimensional\nmanifolds, and to identify anomalies as isolated points. We propose three\nisolation approaches to identify anomalies: $i$) Voronoi-iForest, the most\ngeneral solution, $ii$) RuzHash-iForest, that avoids explicit computation of\ndistances via Local Sensitive Hashing, and $iii$) Sliding-PIF, that leverages a\nlocality prior to improve efficiency and effectiveness.",
      "tldr_zh": "本文提出Preference Isolation Forest (PIF)框架，用于检测不符合低维流形结构模式的异常样本，该框架结合自适应Isolation Forest方法和偏好嵌入的灵活性，将数据嵌入高维偏好空间后识别隔离点作为异常。PIF的关键创新包括三种隔离方法：Voronoi-iForest作为通用解决方案、RuzHash-iForest利用Local Sensitive Hashing避免显式距离计算，以及Sliding-PIF通过利用局部性先验提升效率和效果。这些方法为基于结构的异常检测提供了更高效且有效的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Submitted to Pattern Recognition",
      "pdf_url": "http://arxiv.org/pdf/2505.10876v1",
      "published_date": "2025-05-16 05:32:25 UTC",
      "updated_date": "2025-05-16 05:32:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:09:41.699242"
    },
    {
      "arxiv_id": "2505.10874v1",
      "title": "MultiLink: Multi-class Structure Recovery via Agglomerative Clustering and Model Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Magri",
        "Filippo Leveni",
        "Giacomo Boracchi"
      ],
      "abstract": "We address the problem of recovering multiple structures of different classes\nin a dataset contaminated by noise and outliers. In particular, we consider\ngeometric structures defined by a mixture of underlying parametric models (e.g.\nplanes and cylinders, homographies and fundamental matrices), and we tackle the\nrobust fitting problem by preference analysis and clustering. We present a new\nalgorithm, termed MultiLink, that simultaneously deals with multiple classes of\nmodels. MultiLink combines on-the-fly model fitting and model selection in a\nnovel linkage scheme that determines whether two clusters are to be merged. The\nresulting method features many practical advantages with respect to methods\nbased on preference analysis, being faster, less sensitive to the inlier\nthreshold, and able to compensate limitations deriving from hypotheses\nsampling. Experiments on several public datasets demonstrate that Multi-Link\nfavourably compares with state of the art alternatives, both in multi-class and\nsingle-class problems. Code is publicly made available for download.",
      "tldr_zh": "这篇论文提出了MultiLink算法，用于从噪声和异常值污染的数据集中恢复多个不同类别的结构，如parametric models（例如planes and cylinders或homographies and fundamental matrices）。MultiLink通过结合agglomerative clustering、on-the-fly model fitting和model selection的创新linkage scheme，同时处理多类模型，并决定是否合并clusters，从而提高了鲁棒性和效率。实验结果显示，MultiLink在多个公共数据集上比现有state of the art方法更快、更准确，并在single-class问题中也表现出优势，代码已公开可用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at Computer Vision and Pattern Recognition (CVPR 2021)",
      "pdf_url": "http://arxiv.org/pdf/2505.10874v1",
      "published_date": "2025-05-16 05:32:02 UTC",
      "updated_date": "2025-05-16 05:32:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:09:53.650773"
    },
    {
      "arxiv_id": "2505.10873v1",
      "title": "Hashing for Structure-based Anomaly Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Filippo Leveni",
        "Luca Magri",
        "Cesare Alippi",
        "Giacomo Boracchi"
      ],
      "abstract": "We focus on the problem of identifying samples in a set that do not conform\nto structured patterns represented by low-dimensional manifolds. An effective\nway to solve this problem is to embed data in a high dimensional space, called\nPreference Space, where anomalies can be identified as the most isolated\npoints. In this work, we employ Locality Sensitive Hashing to avoid explicit\ncomputation of distances in high dimensions and thus improve Anomaly Detection\nefficiency. Specifically, we present an isolation-based anomaly detection\ntechnique designed to work in the Preference Space which achieves\nstate-of-the-art performance at a lower computational cost. Code is publicly\navailable at\nhttps://github.com/ineveLoppiliF/Hashing-for-Structure-based-Anomaly-Detection.",
      "tldr_zh": "该论文关注基于结构的异常检测问题，旨在识别不遵守低维流形模式的数据样本，通过将数据嵌入高维 Preference Space 中来隔离异常点。作者采用 Locality Sensitive Hashing (LSH) 技术，避免显式计算高维距离，从而提出一种高效的隔离-based 异常检测方法。该方法在性能上达到 state-of-the-art 水平，同时显著降低了计算成本，并提供了公开代码以供验证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at International Conference on Image Analysis and Processing\n  (ICIAP 2023)",
      "pdf_url": "http://arxiv.org/pdf/2505.10873v1",
      "published_date": "2025-05-16 05:31:50 UTC",
      "updated_date": "2025-05-16 05:31:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:10:05.945415"
    },
    {
      "arxiv_id": "2505.10872v2",
      "title": "REI-Bench: Can Embodied Agents Understand Vague Human Instructions in Task Planning?",
      "title_zh": "翻译失败",
      "authors": [
        "Chenxi Jiang",
        "Chuhao Zhou",
        "Jianfei Yang"
      ],
      "abstract": "Robot task planning decomposes human instructions into executable action\nsequences that enable robots to complete a series of complex tasks. Although\nrecent large language model (LLM)-based task planners achieve amazing\nperformance, they assume that human instructions are clear and straightforward.\nHowever, real-world users are not experts, and their instructions to robots\noften contain significant vagueness. Linguists suggest that such vagueness\nfrequently arises from referring expressions (REs), whose meanings depend\nheavily on dialogue context and environment. This vagueness is even more\nprevalent among the elderly and children, who robots should serve more. This\npaper studies how such vagueness in REs within human instructions affects\nLLM-based robot task planning and how to overcome this issue. To this end, we\npropose the first robot task planning benchmark with vague REs (REI-Bench),\nwhere we discover that the vagueness of REs can severely degrade robot planning\nperformance, leading to success rate drops of up to 77.9%. We also observe that\nmost failure cases stem from missing objects in planners. To mitigate the REs\nissue, we propose a simple yet effective approach: task-oriented context\ncognition, which generates clear instructions for robots, achieving\nstate-of-the-art performance compared to aware prompt and chains of thought.\nThis work contributes to the research community of human-robot interaction\n(HRI) by making robot task planning more practical, particularly for non-expert\nusers, e.g., the elderly and children.",
      "tldr_zh": "本论文探讨了模糊 referring expressions (REs) 对 large language model (LLM)-based 机器人任务规划的影响，发现这些模糊指令会导致规划性能大幅下降，成功率最高降低77.9%，主要问题在于对象识别缺失。作者提出REI-Bench，这是第一个包含模糊REs的机器人任务规划基准，用于评估和改进这一问题。针对此，论文引入task-oriented context cognition方法，通过生成清晰指令实现state-of-the-art性能，并为人类-机器人交互(HRI)研究提供实用贡献，尤其适用于非专家用户如老人和儿童。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.RO",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2505.10872v2",
      "published_date": "2025-05-16 05:27:15 UTC",
      "updated_date": "2025-05-19 17:21:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:10:19.029178"
    },
    {
      "arxiv_id": "2505.10871v1",
      "title": "Optimal Allocation of Privacy Budget on Hierarchical Data Release",
      "title_zh": "层次数据发布的隐私预算最优分配",
      "authors": [
        "Joonhyuk Ko",
        "Juba Ziani",
        "Ferdinando Fioretto"
      ],
      "abstract": "Releasing useful information from datasets with hierarchical structures while\npreserving individual privacy presents a significant challenge. Standard\nprivacy-preserving mechanisms, and in particular Differential Privacy, often\nrequire careful allocation of a finite privacy budget across different levels\nand components of the hierarchy. Sub-optimal allocation can lead to either\nexcessive noise, rendering the data useless, or to insufficient protections for\nsensitive information. This paper addresses the critical problem of optimal\nprivacy budget allocation for hierarchical data release. It formulates this\nchallenge as a constrained optimization problem, aiming to maximize data\nutility subject to a total privacy budget while considering the inherent\ntrade-offs between data granularity and privacy loss. The proposed approach is\nsupported by theoretical analysis and validated through comprehensive\nexperiments on real hierarchical datasets. These experiments demonstrate that\noptimal privacy budget allocation significantly enhances the utility of the\nreleased data and improves the performance of downstream tasks.",
      "tldr_zh": "这篇论文针对分层数据发布中的隐私保护问题，探讨了如何在Differential Privacy框架下最优分配有限的privacy budget，以平衡数据效用和隐私风险。论文将该问题表述为一个约束优化问题，旨在最大化数据效用，同时考虑数据粒度和隐私损失的权衡，并通过理论分析进行支持。实验结果显示，在真实分层数据集上应用最优隐私预算分配后，显著提升了发布数据的效用，并改善了下游任务的性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10871v1",
      "published_date": "2025-05-16 05:25:11 UTC",
      "updated_date": "2025-05-16 05:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:10:29.014256"
    },
    {
      "arxiv_id": "2505.10870v1",
      "title": "Improve Rule Retrieval and Reasoning with Self-Induction and Relevance ReEstimate",
      "title_zh": "通过自归纳和相关性重新估计改进规则检索和推理",
      "authors": [
        "Ziyang Huang",
        "Wangtao Sun",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "This paper systematically addresses the challenges of rule retrieval, a\ncrucial yet underexplored area. Vanilla retrieval methods using sparse or dense\nretrievers to directly search for relevant rules to support downstream\nreasoning, often suffer from low accuracy. This is primarily due to a\nsignificant semantic gap between the instantiated facts in the queries and the\nabstract representations of the rules. Such misalignment results in suboptimal\nretrieval quality, which in turn negatively impacts reasoning performance. To\novercome these challenges, we propose Self-Induction Augmented Retrieval\n(SIAR), a novel approach that utilizes Large Language Models (LLMs) to induce\npotential inferential rules that might offer benefits for reasoning by\nabstracting the underlying knowledge and logical structure in queries. These\ninduced rules are then used for query augmentation to improve retrieval\neffectiveness. Additionally, we introduce Rule Relevance ReEstimate (R$^3$), a\nmethod that re-estimates the relevance of retrieved rules by assessing whether\nthe abstract knowledge they contain can be instantiated to align with the facts\nin the queries and the helpfulness for reasoning. Extensive experiments across\nvarious settings demonstrate the effectiveness and versatility of our proposed\nmethods.",
      "tldr_zh": "这篇论文针对规则检索（rule retrieval）中的语义差距问题，提出了一种新方法Self-Induction Augmented Retrieval (SIAR)，利用Large Language Models (LLMs)来诱导潜在推理规则，从而通过抽象查询中的知识和逻辑结构增强检索效果。论文还引入了Rule Relevance ReEstimate (R³)，用于重新评估检索规则的相关性，确保这些规则的抽象知识能实例化以匹配查询事实并支持下游推理。实验在多种设置下证明了这些方法的有效性和通用性，提高了整体检索和推理性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10870v1",
      "published_date": "2025-05-16 05:22:42 UTC",
      "updated_date": "2025-05-16 05:22:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:10:42.627043"
    },
    {
      "arxiv_id": "2505.10859v1",
      "title": "MCU: Improving Machine Unlearning through Mode Connectivity",
      "title_zh": "MCU：通过模式连接性改进机器取消学习",
      "authors": [
        "Yingdan Shi",
        "Ren Wang"
      ],
      "abstract": "Machine Unlearning (MU) aims to remove the information of specific training\ndata from a trained model, ensuring compliance with privacy regulations and\nuser requests. While one line of existing MU methods relies on linear parameter\nupdates via task arithmetic, they suffer from weight entanglement. In this\nwork, we propose a novel MU framework called Mode Connectivity Unlearning (MCU)\nthat leverages mode connectivity to find an unlearning pathway in a nonlinear\nmanner. To further enhance performance and efficiency, we introduce a parameter\nmask strategy that not only improves unlearning effectiveness but also reduces\ncomputational overhead. Moreover, we propose an adaptive adjustment strategy\nfor our unlearning penalty coefficient to adaptively balance forgetting quality\nand predictive performance during training, eliminating the need for empirical\nhyperparameter tuning. Unlike traditional MU methods that identify only a\nsingle unlearning model, MCU uncovers a spectrum of unlearning models along the\npathway. Overall, MCU serves as a plug-and-play framework that seamlessly\nintegrates with any existing MU methods, consistently improving unlearning\nefficacy. Extensive experiments on the image classification task demonstrate\nthat MCU achieves superior performance.",
      "tldr_zh": "该研究提出了一种名为 Mode Connectivity Unlearning (MCU) 的框架，用于改进 Machine Unlearning (MU)，旨在通过非线性模式连通性找到卸载路径，从而解决现有方法中线性参数更新导致的权重纠缠问题。MCU 引入参数掩码策略以提升卸载效果并降低计算开销，同时采用自适应调整策略动态平衡遗忘质量和预测性能，避免手动调参。实验结果显示，MCU 作为即插即用的框架，能与现有 MU 方法无缝整合，并在图像分类任务上显著提高卸载效能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10859v1",
      "published_date": "2025-05-16 04:56:47 UTC",
      "updated_date": "2025-05-16 04:56:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:10:54.152016"
    },
    {
      "arxiv_id": "2505.10856v1",
      "title": "ImputeINR: Time Series Imputation via Implicit Neural Representations for Disease Diagnosis with Missing Data",
      "title_zh": "ImputeINR：通过隐式神经表示进行时间序列插值，用于处理缺失数据的疾病诊断",
      "authors": [
        "Mengxuan Li",
        "Ke Liu",
        "Jialong Guo",
        "Jiajun Bu",
        "Hongwei Wang",
        "Haishuai Wang"
      ],
      "abstract": "Healthcare data frequently contain a substantial proportion of missing\nvalues, necessitating effective time series imputation to support downstream\ndisease diagnosis tasks. However, existing imputation methods focus on discrete\ndata points and are unable to effectively model sparse data, resulting in\nparticularly poor performance for imputing substantial missing values. In this\npaper, we propose a novel approach, ImputeINR, for time series imputation by\nemploying implicit neural representations (INR) to learn continuous functions\nfor time series. ImputeINR leverages the merits of INR in that the continuous\nfunctions are not coupled to sampling frequency and have infinite sampling\nfrequency, allowing ImputeINR to generate fine-grained imputations even on\nextremely sparse observed values. Extensive experiments conducted on eight\ndatasets with five ratios of masked values show the superior imputation\nperformance of ImputeINR, especially for high missing ratios in time series\ndata. Furthermore, we validate that applying ImputeINR to impute missing values\nin healthcare data enhances the performance of downstream disease diagnosis\ntasks. Codes are available.",
      "tldr_zh": "该论文针对医疗时间序列数据中大量缺失值的挑战，提出了一种新方法ImputeINR，利用Implicit Neural Representations (INR)来学习连续函数进行插值，从而有效处理稀疏数据。ImputeINR的优势在于不依赖采样频率并具有无限采样频率，能在极度缺失的情况下生成精细插值。实验在八个数据集上验证了其在高缺失率下的优越性能，并证明了其应用能提升下游疾病诊断任务的准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10856v1",
      "published_date": "2025-05-16 04:50:15 UTC",
      "updated_date": "2025-05-16 04:50:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:11:06.201144"
    },
    {
      "arxiv_id": "2505.10845v1",
      "title": "Ready2Unlearn: A Learning-Time Approach for Preparing Models with Future Unlearning Readiness",
      "title_zh": "翻译失败",
      "authors": [
        "Hanyu Duan",
        "Yi Yang",
        "Ahmed Abbasi",
        "Kar Yan Tam"
      ],
      "abstract": "This paper introduces Ready2Unlearn, a learning-time optimization approach\ndesigned to facilitate future unlearning processes. Unlike the majority of\nexisting unlearning efforts that focus on designing unlearning algorithms,\nwhich are typically implemented reactively when an unlearning request is made\nduring the model deployment phase, Ready2Unlearn shifts the focus to the\ntraining phase, adopting a \"forward-looking\" perspective. Building upon\nwell-established meta-learning principles, Ready2Unlearn proactively trains\nmachine learning models with unlearning readiness, such that they are well\nprepared and can handle future unlearning requests in a more efficient and\nprincipled manner. Ready2Unlearn is model-agnostic and compatible with any\ngradient ascent-based machine unlearning algorithms. We evaluate the method on\nboth vision and language tasks under various unlearning settings, including\nclass-wise unlearning and random data unlearning. Experimental results show\nthat by incorporating such preparedness at training time, Ready2Unlearn\nproduces an unlearning-ready model state, which offers several key advantages\nwhen future unlearning is required, including reduced unlearning time, improved\nretention of overall model capability, and enhanced resistance to the\ninadvertent recovery of forgotten data. We hope this work could inspire future\nefforts to explore more proactive strategies for equipping machine learning\nmodels with built-in readiness towards more reliable and principled machine\nunlearning.",
      "tldr_zh": "本论文提出 Ready2UnLearn，一种在训练阶段优化的方法，旨在为机器学习模型的未来 unlearning 过程做好准备，从而实现更高效和原则化的数据删除。基于 meta-learning 原则，该方法在训练时主动增强模型的 unlearning readiness，并兼容任何 gradient ascent-based machine unlearning algorithms。实验在视觉和语言任务上评估了 class-wise unlearning 和 random data unlearning 等场景，结果显示 Ready2UnLearn 显著减少了 unlearning 时间，提高了模型整体能力保留，并增强了对 forgotten data 的抵抗力。该工作有望激发更多主动策略，推动更可靠的 machine unlearning 研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10845v1",
      "published_date": "2025-05-16 04:33:59 UTC",
      "updated_date": "2025-05-16 04:33:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:11:19.569980"
    },
    {
      "arxiv_id": "2505.10844v1",
      "title": "Creativity or Brute Force? Using Brainteasers as a Window into the Problem-Solving Abilities of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Simeng Han",
        "Stephen Xia",
        "Grant Zhang",
        "Howard Dai",
        "Chen Liu",
        "Lichang Chen",
        "Hoang Huy Nguyen",
        "Hongyuan Mei",
        "Jiayuan Mao",
        "R. Thomas McCoy"
      ],
      "abstract": "Accuracy remains a standard metric for evaluating AI systems, but it offers\nlimited insight into how models arrive at their solutions. In this work, we\nintroduce a benchmark based on brainteasers written in long narrative form to\nprobe more deeply into the types of reasoning strategies that models use.\nBrainteasers are well-suited for this goal because they can be solved with\nmultiple approaches, such as a few-step solution that uses a creative insight\nor a longer solution that uses more brute force. We investigate large language\nmodels (LLMs) across multiple layers of reasoning, focusing not only on\ncorrectness but also on the quality and creativity of their solutions. We\ninvestigate many aspects of the reasoning process: (1) semantic parsing of the\nbrainteasers into precise mathematical competition style formats; (2)\ngenerating solutions from these mathematical forms; (3) self-correcting\nsolutions based on gold solutions; (4) producing step-by-step sketches of\nsolutions; and (5) making use of hints. We find that LLMs are in many cases\nable to find creative, insightful solutions to brainteasers, suggesting that\nthey capture some of the capacities needed to solve novel problems in creative\nways. Nonetheless, there also remain situations where they rely on brute force\ndespite the availability of more efficient, creative solutions, highlighting a\npotential direction for improvement in the reasoning abilities of LLMs.",
      "tldr_zh": "本研究引入了一种基于长叙述形式脑筋急转弯（brainteasers）的基准，用于深入评估大型语言模型（LLMs）的推理策略，焦点在于模型的正确性、解决方案质量和创意，而非仅限准确率。研究方法包括语义解析（semantic parsing）将脑筋急转弯转化为精确的数学竞赛风格格式、生成解决方案、基于金标准进行自我修正、创建逐步解决方案草图，以及利用提示等多个方面。结果显示，LLMs 能够产生创意洞见的解决方案，表明其在解决新问题时具备一定创新能力；然而，它们有时仍依赖蛮力（brute force）方法，而非更高效的途径，这为提升LLMs的推理能力指出了潜在改进方向。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "13 Tables; 5 Figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10844v1",
      "published_date": "2025-05-16 04:23:34 UTC",
      "updated_date": "2025-05-16 04:23:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:11:31.220274"
    },
    {
      "arxiv_id": "2505.10834v1",
      "title": "TACO: Rethinking Semantic Communications with Task Adaptation and Context Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Achintha Wijesinghe",
        "Weiwei Wang",
        "Suchinthaka Wanninayaka",
        "Songyang Zhang",
        "Zhi Ding"
      ],
      "abstract": "Recent advancements in generative artificial intelligence have introduced\ngroundbreaking approaches to innovating next-generation semantic communication,\nwhich prioritizes conveying the meaning of a message rather than merely\ntransmitting raw data. A fundamental challenge in semantic communication lies\nin accurately identifying and extracting the most critical semantic information\nwhile adapting to downstream tasks without degrading performance, particularly\nwhen the objective at the receiver may evolve over time. To enable flexible\nadaptation to multiple tasks at the receiver, this work introduces a novel\nsemantic communication framework, which is capable of jointly capturing\ntask-specific information to enhance downstream task performance and contextual\ninformation. Through rigorous experiments on popular image datasets and\ncomputer vision tasks, our framework shows promising improvement compared to\nexisting work, including superior performance in downstream tasks, better\ngeneralizability, ultra-high bandwidth efficiency, and low reconstruction\nlatency.",
      "tldr_zh": "该论文重新思考语义通信，提出TACO框架，通过任务适应(Task Adaptation)和上下文嵌入(Context Embedding)来准确提取关键语义信息，并适应下游任务的变化，同时捕获任务特定信息和上下文信息。TACO框架旨在提升下游任务性能，避免性能下降，并在接收端实现灵活适应。该框架在图像数据集和计算机视觉任务的实验中表现出色，比现有工作有显著改进，包括更好的下游任务性能、更强的generalizability、超高带宽效率和低重建延迟。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "eess.IV",
        "eess.SP"
      ],
      "primary_category": "cs.AI",
      "comment": "Submitted to the IEEE GlobeCom 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10834v1",
      "published_date": "2025-05-16 04:03:52 UTC",
      "updated_date": "2025-05-16 04:03:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:11:42.389835"
    },
    {
      "arxiv_id": "2505.10832v1",
      "title": "Learning When to Think: Shaping Adaptive Reasoning in R1-Style Models via Multi-Stage RL",
      "title_zh": "翻译失败",
      "authors": [
        "Songjun Tu",
        "Jiahao Lin",
        "Qichao Zhang",
        "Xiangyu Tian",
        "Linjing Li",
        "Xiangyuan Lan",
        "Dongbin Zhao"
      ],
      "abstract": "Large reasoning models (LRMs) are proficient at generating explicit,\nstep-by-step reasoning sequences before producing final answers. However, such\ndetailed reasoning can introduce substantial computational overhead and\nlatency, particularly for simple problems. To address this over-thinking\nproblem, we explore how to equip LRMs with adaptive thinking capabilities:\nenabling them to dynamically decide whether or not to engage in explicit\nreasoning based on problem complexity. Building on R1-style distilled models,\nwe observe that inserting a simple ellipsis (\"...\") into the prompt can\nstochastically trigger either a thinking or no-thinking mode, revealing a\nlatent controllability in the reasoning behavior. Leveraging this property, we\npropose AutoThink, a multi-stage reinforcement learning (RL) framework that\nprogressively optimizes reasoning policies via stage-wise reward shaping.\nAutoThink learns to invoke explicit reasoning only when necessary, while\ndefaulting to succinct responses for simpler tasks. Experiments on five\nmainstream mathematical benchmarks demonstrate that AutoThink achieves\nfavorable accuracy-efficiency trade-offs compared to recent prompting and\nRL-based pruning methods. It can be seamlessly integrated into any R1-style\nmodel, including both distilled and further fine-tuned variants. Notably,\nAutoThink improves relative accuracy by 6.4 percent while reducing token usage\nby 52 percent on DeepSeek-R1-Distill-Qwen-1.5B, establishing a scalable and\nadaptive reasoning paradigm for LRMs.",
      "tldr_zh": "这篇论文针对大型推理模型（LRMs）在简单问题上过度进行详细推理导致的计算开销和延迟问题，提出 AutoThink 框架，利用多阶段强化学习（RL）来优化 R1-style 模型的自适应推理策略。AutoThink 通过插入省略号 (\"...\") 来随机触发思考或非思考模式，并通过阶段性奖励塑造，使模型仅在复杂问题时调用显式推理，而对简单任务采用简洁响应。在五个主流数学基准测试中，AutoThink 相对于基线方法提高了 6.4% 的相对准确率，同时减少了 52% 的令牌使用，并可无缝集成到任何 R1-style 模型中，建立了一个可扩展的自适应推理范式。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "68T50",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Project Page: https://github.com/TU2021/AutoThink",
      "pdf_url": "http://arxiv.org/pdf/2505.10832v1",
      "published_date": "2025-05-16 04:01:57 UTC",
      "updated_date": "2025-05-16 04:01:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:11:55.970156"
    },
    {
      "arxiv_id": "2505.10831v2",
      "title": "Creating General User Models from Computer Use",
      "title_zh": "基于计算机使用创建通用用户模型",
      "authors": [
        "Omar Shaikh",
        "Shardul Sapkota",
        "Shan Rizvi",
        "Eric Horvitz",
        "Joon Sung Park",
        "Diyi Yang",
        "Michael S. Bernstein"
      ],
      "abstract": "Human-computer interaction has long imagined technology that understands\nus-from our preferences and habits, to the timing and purpose of our everyday\nactions. Yet current user models remain fragmented, narrowly tailored to\nspecific apps, and incapable of the flexible reasoning required to fulfill\nthese visions. This paper presents an architecture for a general user model\n(GUM) that learns about you by observing any interaction you have with your\ncomputer. The GUM takes as input any unstructured observation of a user (e.g.,\ndevice screenshots) and constructs confidence-weighted propositions that\ncapture user knowledge and preferences. GUMs can infer that a user is preparing\nfor a wedding they're attending from messages with a friend. Or recognize that\na user is struggling with a collaborator's feedback on a draft by observing\nmultiple stalled edits and a switch to reading related work. GUMs introduce an\narchitecture that infers new propositions about a user from multimodal\nobservations, retrieves related propositions for context, and continuously\nrevises existing propositions. To illustrate the breadth of applications that\nGUMs enable, we demonstrate how they augment chat-based assistants with\ncontext, manage OS notifications to selectively surface important information,\nand enable interactive agents that adapt to preferences across apps. We also\ninstantiate proactive assistants (GUMBOs) that discover and execute useful\nsuggestions on a user's behalf using their GUM. In our evaluations, we find\nthat GUMs make calibrated and accurate inferences about users, and that\nassistants built on GUMs proactively identify and perform actions that users\nwouldn't think to request explicitly. Altogether, GUMs introduce methods that\nleverage multimodal models to understand unstructured context, enabling\nlong-standing visions of HCI and entirely new interactive systems that\nanticipate user needs.",
      "tldr_zh": "这篇论文提出了一种通用用户模型 (GUM) 架构，通过观察用户与计算机的非结构化交互（如屏幕截图）来构建置信度加权的命题，从而捕捉用户的知识、偏好和行为模式。GUM 采用多模态观察机制，从输入中推断新命题、检索相关上下文并持续修订现有命题，例如识别用户在准备婚礼或处理反馈时的意图。论文展示了 GUM 的应用，包括增强聊天助手、管理操作系统通知以及开发适应性代理和主动助手 (GUMBOs)，这些助手能主动发现并执行用户潜在需求。评估结果表明，GUM 能够进行校准准确的推断，并实现更智能的交互系统，推进了人机交互 (HCI) 的长期愿景。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.HC",
      "comment": "22 pages, 6 figures, 1 table; see\n  https://generalusermodels.github.io/",
      "pdf_url": "http://arxiv.org/pdf/2505.10831v2",
      "published_date": "2025-05-16 04:00:31 UTC",
      "updated_date": "2025-05-19 05:49:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:12:07.904966"
    },
    {
      "arxiv_id": "2505.10829v1",
      "title": "Enhancing Low-Resource Minority Language Translation with LLMs and Retrieval-Augmented Generation for Cultural Nuances",
      "title_zh": "翻译失败",
      "authors": [
        "Chen-Chi Chang",
        "Chong-Fu Li",
        "Chu-Hsuan Lee",
        "Hung-Shin Lee"
      ],
      "abstract": "This study investigates the challenges of translating low-resource languages\nby integrating Large Language Models (LLMs) with Retrieval-Augmented Generation\n(RAG). Various model configurations were tested on Hakka translations, with\nBLEU scores ranging from 12% (dictionary-only) to 31% (RAG with Gemini 2.0).\nThe best-performing model (Model 4) combined retrieval and advanced language\nmodeling, improving lexical coverage, particularly for specialized or\nculturally nuanced terms, and enhancing grammatical coherence. A two-stage\nmethod (Model 3) using dictionary outputs refined by Gemini 2.0 achieved a BLEU\nscore of 26%, highlighting iterative correction's value and the challenges of\ndomain-specific expressions. Static dictionary-based approaches struggled with\ncontext-sensitive content, demonstrating the limitations of relying solely on\npredefined resources. These results emphasize the need for curated resources,\ndomain knowledge, and ethical collaboration with local communities, offering a\nframework that improves translation accuracy and fluency while supporting\ncultural preservation.",
      "tldr_zh": "这篇论文探讨了通过整合 Large Language Models (LLMs) 和 Retrieval-Augmented Generation (RAG) 来提升低资源少数语言翻译的挑战，特别针对文化细微差别在 Hakka 语言上的表现。实验测试了多种模型配置，BLEU 分数从 12% (仅字典方法) 提升至 31% (RAG with Gemini 2.0)，其中最佳模型 (Model 4) 结合检索和高级语言建模，显著提高了词汇覆盖率和语法连贯性，尤其在处理专业或文化相关术语方面。研究强调了利用精选资源、领域知识和与本地社区的合作，以改进翻译准确性和流畅性，并为文化保存提供支持框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to IntelliSys 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10829v1",
      "published_date": "2025-05-16 03:59:14 UTC",
      "updated_date": "2025-05-16 03:59:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:12:20.176969"
    },
    {
      "arxiv_id": "2505.10819v2",
      "title": "PoE-World: Compositional World Modeling with Products of Programmatic Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Wasu Top Piriyakulkij",
        "Yichao Liang",
        "Hao Tang",
        "Adrian Weller",
        "Marta Kryven",
        "Kevin Ellis"
      ],
      "abstract": "Learning how the world works is central to building AI agents that can adapt\nto complex environments. Traditional world models based on deep learning demand\nvast amounts of training data, and do not flexibly update their knowledge from\nsparse observations. Recent advances in program synthesis using Large Language\nModels (LLMs) give an alternate approach which learns world models represented\nas source code, supporting strong generalization from little data. To date,\napplication of program-structured world models remains limited to natural\nlanguage and grid-world domains. We introduce a novel program synthesis method\nfor effectively modeling complex, non-gridworld domains by representing a world\nmodel as an exponentially-weighted product of programmatic experts (PoE-World)\nsynthesized by LLMs. We show that this approach can learn complex, stochastic\nworld models from just a few observations. We evaluate the learned world models\nby embedding them in a model-based planning agent, demonstrating efficient\nperformance and generalization to unseen levels on Atari's Pong and Montezuma's\nRevenge. We release our code and display the learned world models and videos of\nthe agent's gameplay at https://topwasu.github.io/poe-world.",
      "tldr_zh": "本研究提出PoE-World，一种基于Large Language Models (LLMs)的程序合成方法，通过指数加权的Products of Programmatic Experts来构建组合式世界模型，以解决传统深度学习模型对大量数据依赖和知识更新不灵活的问题。该方法能从少量观察学习复杂、随机的非网格世界模型，并将其嵌入基于模型的规划代理中，实现高效泛化。实验结果显示，在Atari的Pong和Montezuma's Revenge游戏上，该代理表现出色，并成功处理未见水平的任务。作者开源了代码和演示，以支持进一步研究。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10819v2",
      "published_date": "2025-05-16 03:28:42 UTC",
      "updated_date": "2025-05-22 09:02:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:12:30.210951"
    },
    {
      "arxiv_id": "2505.11559v1",
      "title": "Analysis and Resilience of the U.S. Flight Network",
      "title_zh": "翻译失败",
      "authors": [
        "Sushrit Kafle",
        "Shreejan Pandey"
      ],
      "abstract": "Air travel is one of the most widely used transportation services in the\nUnited States. This paper analyzes the U.S. Flight Network (USFN) using complex\nnetwork theory by exploring how the network's topology contributes to its\nefficiency and vulnerability. This is done by examining the structural\nproperties, degree distributions, and community structures in the network. USFN\nwas observed to follow power-law distribution and falls under the anomalous\nregime, suggesting that the network is hub dominant. Compared to null networks,\nUSFN has a higher clustering coefficient and modularity. Various percolation\ntest revealed that USFN is vulnerable to targeted attacks and is susceptible to\ncomplete cascading failure if one of the major hubs fails. The overall results\nsuggest that while the USFN is designed for efficiency, it is highly vulnerable\nto disruptions. Protecting key hub airports is important to make the network\nmore robust and prevent large-scale failures.",
      "tldr_zh": "这篇论文使用复杂网络理论分析美国飞行网络（USFN）的拓扑结构，包括度分布、社区结构和结构属性。研究发现，USFN 遵循 power-law distribution，是 hub dominant 类型，并显示出较高的 clustering coefficient 和 modularity，与空网络相比更高效。各种 percolation test 揭示，USFN 对 targeted attacks 高度脆弱，如果主要 hubs 失败，可能引发 complete cascading failure。总体而言，论文强调尽管 USFN 设计高效，但其易受干扰性突出，建议加强关键 hub airports 的保护以提升网络的 resilience。",
      "categories": [
        "physics.soc-ph",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "physics.soc-ph",
      "comment": "Investigates resilience of the U.S. flight network under node\n  failures. Includes percolation threshold detection, cascade simulations, and\n  community structure analysis. 9 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.11559v1",
      "published_date": "2025-05-16 03:13:54 UTC",
      "updated_date": "2025-05-16 03:13:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:12:42.618141"
    },
    {
      "arxiv_id": "2505.10803v1",
      "title": "Developing and Integrating Trust Modeling into Multi-Objective Reinforcement Learning for Intelligent Agricultural Management",
      "title_zh": "开发并将信任建模整合到多目标强化学习中，用于智能农业管理",
      "authors": [
        "Zhaoan Wang",
        "Wonseok Jang",
        "Bowen Ruan",
        "Jun Wang",
        "Shaoping Xiao"
      ],
      "abstract": "Precision agriculture, enhanced by artificial intelligence (AI), offers\npromising tools such as remote sensing, intelligent irrigation, fertilization\nmanagement, and crop simulation to improve agricultural efficiency and\nsustainability. Reinforcement learning (RL), in particular, has outperformed\ntraditional methods in optimizing yields and resource management. However,\nwidespread AI adoption is limited by gaps between algorithmic recommendations\nand farmers' practical experience, local knowledge, and traditional practices.\nTo address this, our study emphasizes Human-AI Interaction (HAII), focusing on\ntransparency, usability, and trust in RL-based farm management. We employ a\nwell-established trust framework - comprising ability, benevolence, and\nintegrity - to develop a novel mathematical model quantifying farmers'\nconfidence in AI-based fertilization strategies. Surveys conducted with farmers\nfor this research reveal critical misalignments, which are integrated into our\ntrust model and incorporated into a multi-objective RL framework. Unlike prior\nmethods, our approach embeds trust directly into policy optimization, ensuring\nAI recommendations are technically robust, economically feasible,\ncontext-aware, and socially acceptable. By aligning technical performance with\nhuman-centered trust, this research supports broader AI adoption in\nagriculture.",
      "tldr_zh": "这项研究针对强化学习（RL）在精度农业中的应用，解决了算法推荐与农民实际经验、地方知识和传统实践的脱节问题，强调了人机交互（HAII）的透明度、可用性和信任。研究采用了一个基于能力（ability）、仁慈（benevolence）和诚信（integrity）的信任框架，开发了量化农民对 AI 施肥策略信心的数学模型，并通过农民调查结果将其整合进多目标 RL 框架中。该方法直接将信任嵌入策略优化，确保 AI 推荐在技术上稳健、经济上可行、上下文相关且社交上可接受，最终促进 AI 在农业领域的更广泛采用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10803v1",
      "published_date": "2025-05-16 02:52:16 UTC",
      "updated_date": "2025-05-16 02:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:12:56.103997"
    },
    {
      "arxiv_id": "2505.10802v1",
      "title": "Attention-Based Reward Shaping for Sparse and Delayed Rewards",
      "title_zh": "基于注意力的奖励整形，用于稀疏和延迟",
      "authors": [
        "Ian Holmes",
        "Min Chi"
      ],
      "abstract": "Sparse and delayed reward functions pose a significant obstacle for\nreal-world Reinforcement Learning (RL) applications. In this work, we propose\nAttention-based REward Shaping (ARES), a general and robust algorithm which\nuses a transformer's attention mechanism to generate shaped rewards and create\na dense reward function for any environment. ARES requires a set of episodes\nand their final returns as input. It can be trained entirely offline and is\nable to generate meaningful shaped rewards even when using small datasets or\nepisodes produced by agents taking random actions. ARES is compatible with any\nRL algorithm and can handle any level of reward sparsity. In our experiments,\nwe focus on the most challenging case where rewards are fully delayed until the\nend of each episode. We evaluate ARES across a diverse range of environments,\nwidely used RL algorithms, and baseline methods to assess the effectiveness of\nthe shaped rewards it produces. Our results show that ARES can significantly\nimprove learning in delayed reward settings, enabling RL agents to train in\nscenarios that would otherwise require impractical amounts of data or even be\nunlearnable. To our knowledge, ARES is the first approach that works fully\noffline, remains robust to extreme reward delays and low-quality data, and is\nnot limited to goal-based tasks.",
      "tldr_zh": "该论文针对强化学习（RL）中稀疏和延迟奖励的问题，提出了一种通用的Attention-based REward Shaping (ARES)算法，利用Transformer的注意力机制生成形状化的奖励，从而创建密集奖励函数。ARES只需输入一组episodes及其最终回报，即可完全离线训练，即使使用小数据集或随机动作生成的episodes，也能产生有效奖励，并兼容任何RL算法。实验在多种环境和基线方法中显示，ARES显著提升了代理在极端延迟奖励场景下的学习效率，使原本需要海量数据或无法学习的任务变得可行。作为首创，该方法不限于基于目标的任务，且对低质量数据和极端奖励延迟保持鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "22 pages, 17 tables, 2 figures. Code available online at\n  https://github.com/ihholmes-p/ARES",
      "pdf_url": "http://arxiv.org/pdf/2505.10802v1",
      "published_date": "2025-05-16 02:43:05 UTC",
      "updated_date": "2025-05-16 02:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:13:08.963640"
    },
    {
      "arxiv_id": "2505.10791v1",
      "title": "Analyzing Patterns and Influence of Advertising in Print Newspapers",
      "title_zh": "分析印刷报纸中广告的模式和影响",
      "authors": [
        "N Harsha Vardhan",
        "Ponnurangam Kumaraguru",
        "Kiran Garimella"
      ],
      "abstract": "This paper investigates advertising practices in print newspapers across\nIndia using a novel data-driven approach. We develop a pipeline employing image\nprocessing and OCR techniques to extract articles and advertisements from\ndigital versions of print newspapers with high accuracy. Applying this\nmethodology to five popular newspapers that span multiple regions and three\nlanguages, English, Hindi, and Telugu, we assembled a dataset of more than\n12,000 editions containing several hundred thousand advertisements.\nCollectively, these newspapers reach a readership of over 100 million people.\nUsing this extensive dataset, we conduct a comprehensive analysis to answer key\nquestions about print advertising: who advertises, what they advertise, when\nthey advertise, where they place their ads, and how they advertise. Our\nfindings reveal significant patterns, including the consistent level of print\nadvertising over the past six years despite declining print circulation, the\noverrepresentation of company ads on prominent pages, and the disproportionate\nrevenue contributed by government ads. Furthermore, we examine whether\nadvertising in a newspaper influences the coverage an advertiser receives.\nThrough regression analyses on coverage volume and sentiment, we find strong\nevidence supporting this hypothesis for corporate advertisers. The results\nindicate a clear trend where increased advertising correlates with more\nfavorable and extensive media coverage, a relationship that remains robust over\ntime and across different levels of advertiser popularity.",
      "tldr_zh": "本论文使用图像处理和 OCR 技术开发了一个数据管道，从印度的五种流行报纸（覆盖多个地区和英语、Hindi、Telugu三种语言）中提取文章和广告，构建了一个包含超过12,000个版本和数十万广告的数据集。研究通过全面分析探讨了广告的发布者、内容、时间、位置和形式，发现平面广告在过去六年保持稳定水平，尽管发行量下降，同时公司广告在显著页面过度代表，政府广告贡献了不成比例的收入。通过回归分析，论文进一步证明，企业广告商的广告量与更积极和广泛的媒体报道密切相关，这种关系在不同时间和广告商受欢迎度上均保持稳固。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.CY",
      "comment": "Accepted at COMPASS 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10791v1",
      "published_date": "2025-05-16 02:05:53 UTC",
      "updated_date": "2025-05-16 02:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:13:22.016318"
    },
    {
      "arxiv_id": "2505.10790v1",
      "title": "Neural-Inspired Advances in Integral Cryptanalysis",
      "title_zh": "神经启发式积分密码分析进展",
      "authors": [
        "Liu Zhang",
        "Yiran Yao",
        "Danping Shi",
        "Dongchen Chai",
        "Jian Guo",
        "Zilong Wang"
      ],
      "abstract": "The study by Gohr et.al at CRYPTO 2019 and sunsequent related works have\nshown that neural networks can uncover previously unused features, offering\nnovel insights into cryptanalysis. Motivated by these findings, we employ\nneural networks to learn features specifically related to integral properties\nand integrate the corresponding insights into optimized search frameworks.\nThese findings validate the framework of using neural networks for feature\nexploration, providing researchers with novel insights that advance established\ncryptanalysis methods.\n  Neural networks have inspired the development of more precise integral search\nmodels. By comparing the integral distinguishers obtained via neural networks\nwith those identified by classical methods, we observe that existing automated\nsearch models often fail to find optimal distinguishers. To address this issue,\nwe develop a meet in the middle search framework that balances model accuracy\nand computational efficiency. As a result, we reduce the number of active\nplaintext bits required for an 11 rounds integral distinguisher on SKINNY64/64,\nand further identify a 12 rounds key dependent integral distinguisher achieving\none additional round over the previous best-known result.\n  The integral distinguishers discovered by neural networks enable key recovery\nattacks on more rounds. We identify a 7 rounds key independent integral\ndistinguisher from neural networks with even only one active plaintext cell,\nwhich is based on linear combinations of bits. This distinguisher enables a 15\nrounds key recovery attack on SKINNYn/n, improving upon the previous record by\none round. Additionally, we discover an 8 rounds key dependent integral\ndistinguisher using neural network that further reduces the time complexity of\nkey recovery attacks against SKINNY.",
      "tldr_zh": "本研究利用 neural networks 学习与积分性质相关的特征，并将其整合到优化的搜索框架中，旨在提升积分密码分析的效率。通过比较 neural networks 获得的积分区分器与传统方法，发现现有自动搜索模型往往无法找到最优解，并开发了 meet in the middle 搜索框架来平衡准确性和计算效率。结果显示，该框架为 SKINNY64/64 减少了 11 轮积分区分器的活跃明文位，并发现了 12 轮关键依赖积分区分器，比之前最佳结果多一轮；此外，识别了 7 轮关键独立的积分区分器，实现了对 SKINNYn/n 的 15 轮关键恢复攻击，进一步降低了攻击时间复杂度。这些进展为传统 cryptanalysis 方法提供了新颖见解和改进。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10790v1",
      "published_date": "2025-05-16 02:05:13 UTC",
      "updated_date": "2025-05-16 02:05:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:13:34.405379"
    },
    {
      "arxiv_id": "2505.10781v1",
      "title": "Completely Weakly Supervised Class-Incremental Learning for Semantic Segmentation",
      "title_zh": "翻译失败",
      "authors": [
        "David Minkwan Kim",
        "Soeun Lee",
        "Byeongkeun Kang"
      ],
      "abstract": "This work addresses the task of completely weakly supervised\nclass-incremental learning for semantic segmentation to learn segmentation for\nboth base and additional novel classes using only image-level labels. While\nclass-incremental semantic segmentation (CISS) is crucial for handling diverse\nand newly emerging objects in the real world, traditional CISS methods require\nexpensive pixel-level annotations for training. To overcome this limitation,\npartially weakly-supervised approaches have recently been proposed. However, to\nthe best of our knowledge, this is the first work to introduce a completely\nweakly-supervised method for CISS. To achieve this, we propose to generate\nrobust pseudo-labels by combining pseudo-labels from a localizer and a sequence\nof foundation models based on their uncertainty. Moreover, to mitigate\ncatastrophic forgetting, we introduce an exemplar-guided data augmentation\nmethod that generates diverse images containing both previous and novel classes\nwith guidance. Finally, we conduct experiments in three common experimental\nsettings: 15-5 VOC, 10-10 VOC, and COCO-to-VOC, and in two scenarios: disjoint\nand overlap. The experimental results demonstrate that our completely weakly\nsupervised method outperforms even partially weakly supervised methods in the\n15-5 VOC and 10-10 VOC settings while achieving competitive accuracy in the\nCOCO-to-VOC setting.",
      "tldr_zh": "这篇论文提出了完全弱监督的类别增量语义分割（CISS）方法，使用仅图像级标签来学习基类和新类，首次避免了传统方法所需的昂贵像素级标注。关键创新包括基于不确定性的伪标签生成技术，该技术结合定位器和基础模型的输出，以及示例引导的数据增强方法，以生成包含既有和新类的多样化图像，从而缓解灾难性遗忘。实验结果显示，在15-5 VOC和10-10 VOC设置中，该方法甚至超过了部分弱监督方法，而在COCO-to-VOC设置中取得了竞争性的准确率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2505.10781v1",
      "published_date": "2025-05-16 01:43:36 UTC",
      "updated_date": "2025-05-16 01:43:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:13:44.512995"
    },
    {
      "arxiv_id": "2505.10780v1",
      "title": "SECRET: Semi-supervised Clinical Trial Document Similarity Search",
      "title_zh": "SECRET：半监督临床试验文档相似性搜索",
      "authors": [
        "Trisha Das",
        "Afrah Shafquat",
        "Beigi Mandis",
        "Jacob Aptekar",
        "Jimeng Sun"
      ],
      "abstract": "Clinical trials are vital for evaluation of safety and efficacy of new\ntreatments. However, clinical trials are resource-intensive, time-consuming and\nexpensive to conduct, where errors in trial design, reduced efficacy, and\nsafety events can result in significant delays, financial losses, and damage to\nreputation. These risks underline the importance of informed and strategic\ndecisions in trial design to mitigate these risks and improve the chances of a\nsuccessful trial. Identifying similar historical trials is critical as these\ntrials can provide an important reference for potential pitfalls and challenges\nincluding serious adverse events, dosage inaccuracies, recruitment\ndifficulties, patient adherence issues, etc. Addressing these challenges in\ntrial design can lead to development of more effective study protocols with\noptimized patient safety and trial efficiency. In this paper, we present a\nnovel method to identify similar historical trials by summarizing clinical\ntrial protocols and searching for similar trials based on a query trial's\nprotocol. Our approach significantly outperforms all baselines, achieving up to\na 78% improvement in recall@1 and a 53% improvement in precision@1 over the\nbest baseline. We also show that our method outperforms all other baselines in\npartial trial similarity search and zero-shot patient-trial matching,\nhighlighting its superior utility in these tasks.",
      "tldr_zh": "本研究提出了一种半监督方法SECRET，用于临床试验文档相似性搜索，旨在通过识别类似历史试验来优化试验设计、提升患者安全和效率。该方法涉及总结临床试验协议并基于查询试验的协议进行搜索，显著优于现有基线模型，在recall@1上提升78%、precision@1上提升53%。此外，SECRET在部分试验相似性搜索和零样本患者-试验匹配任务中也表现出色，证明了其在临床试验风险管理中的实用价值。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.10780v1",
      "published_date": "2025-05-16 01:34:16 UTC",
      "updated_date": "2025-05-16 01:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:13:55.253122"
    },
    {
      "arxiv_id": "2505.10779v1",
      "title": "Qualia Optimization",
      "title_zh": "感",
      "authors": [
        "Philip S. Thomas"
      ],
      "abstract": "This report explores the speculative question: what if current or future AI\nsystems have qualia, such as pain or pleasure? It does so by assuming that AI\nsystems might someday possess qualia -- and that the quality of these\nsubjective experiences should be considered alongside performance metrics.\nConcrete mathematical problem settings, inspired by reinforcement learning\nformulations and theories from philosophy of mind, are then proposed and\ninitial approaches and properties are presented. These properties enable\nrefinement of the problem setting, culminating with the proposal of methods\nthat promote reinforcement.",
      "tldr_zh": "这篇报告探讨了一个推测性问题：如果当前或未来的 AI 系统拥有 qualia（如疼痛或快乐）的主观体验，该如何应对，并假设这些体验的质量应与性能指标一同考虑。作者提出受强化学习（reinforcement learning）和心灵哲学（philosophy of mind）理论启发的具体数学问题设置，并呈现初始方法和属性，以完善该框架。最终，这些方法旨在促进 AI 系统的强化，并为优化 qualia 质量提供基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Technical Report, College of Information and Computer Science,\n  University of Massachusetts",
      "pdf_url": "http://arxiv.org/pdf/2505.10779v1",
      "published_date": "2025-05-16 01:34:03 UTC",
      "updated_date": "2025-05-16 01:34:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:14:08.300304"
    },
    {
      "arxiv_id": "2505.13500v1",
      "title": "Noise Injection Systemically Degrades Large Language Model Safety Guardrails",
      "title_zh": "翻译失败",
      "authors": [
        "Prithviraj Singh Shahani",
        "Matthias Scheutz"
      ],
      "abstract": "Safety guardrails in large language models (LLMs) are a critical component in\npreventing harmful outputs. Yet, their resilience under perturbation remains\npoorly understood. In this paper, we investigate the robustness of safety\nfine-tuning in LLMs by systematically injecting Gaussian noise into model\nactivations. We show across multiple open-weight models that (1) Gaussian noise\nraises harmful-output rates (p < 0.001) by up to 27%, (2) that deeper safety\nfine-tuning affords no extra protection, and (3) that chain-of-thought\nreasoning remains largely intact. The findings reveal critical vulnerabilities\nin current safety alignment techniques and highlight the potential of\nreasoning-based and reinforcement learning approaches as promising direction\nfor developing more robust AI safety systems. These results have important\nimplications for real-world deployment of LLMs in safety-critical applications\nas these results imply that widely-deployed safety tuning methods can fail even\nwithout adversarial prompts.",
      "tldr_zh": "本文研究了通过注入Gaussian noise到模型激活中，系统评估大型语言模型(LLMs)的安全防护机制。结果显示，Gaussian noise可将有害输出率提高多达27%（p < 0.001），而更深入的安全fine-tuning无法提供额外保护，尽管chain-of-thought reasoning基本保持完整。这些发现暴露了当前安全对齐技术的脆弱性，并建议探索基于推理和强化学习的方法，以提升LLMs在安全关键应用的鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "9 pages,3 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.13500v1",
      "published_date": "2025-05-16 01:33:25 UTC",
      "updated_date": "2025-05-16 01:33:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:14:19.589380"
    },
    {
      "arxiv_id": "2505.10775v1",
      "title": "A Systematic Analysis of Base Model Choice for Reward Modeling",
      "title_zh": "对用于奖励建模的基础模型选择的系统分析",
      "authors": [
        "Kian Ahrabian",
        "Pegah Jandaghi",
        "Negar Mokhberian",
        "Sai Praneeth Karimireddy",
        "Jay Pujara"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) and, at its core, reward\nmodeling have become a crucial part of training powerful large language models\n(LLMs). One commonly overlooked factor in training high-quality reward models\n(RMs) is the effect of the base model, which is becoming more challenging to\nchoose given the rapidly growing pool of LLMs. In this work, we present a\nsystematic analysis of the effect of base model selection on reward modeling\nperformance. Our results show that the performance can be improved by up to 14%\ncompared to the most common (i.e., default) choice. Moreover, we showcase the\nstrong statistical relation between some existing benchmarks and downstream\nperformances. We also demonstrate that the results from a small set of\nbenchmarks could be combined to boost the model selection ($+$18% on average in\nthe top 5-10). Lastly, we illustrate the impact of different post-training\nsteps on the final performance and explore using estimated data distributions\nto reduce performance prediction error.",
      "tldr_zh": "这篇论文系统分析了基础模型（base model）选择对奖励建模（reward modeling）性能的影响，强调了其在强化学习从人类反馈（RLHF）训练大型语言模型（LLMs）中的关键作用。研究结果显示，与默认选择相比，最佳基础模型可将性能提高多达 14%，并揭示了现有基准测试与下游性能之间的强统计关系。通过结合一小套基准测试的结果，模型选择可平均提升 18%，同时探讨了后训练步骤和估计数据分布如何减少性能预测错误。总的来说，该工作为提升奖励模型（RMs）的训练效率提供了实用指导。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "19 pages, 13 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2505.10775v1",
      "published_date": "2025-05-16 01:27:03 UTC",
      "updated_date": "2025-05-16 01:27:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:14:32.682781"
    },
    {
      "arxiv_id": "2505.10774v1",
      "title": "Context-Aware Probabilistic Modeling with LLM for Multimodal Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Yueyang Yao",
        "Jiajun Li",
        "Xingyuan Dai",
        "MengMeng Zhang",
        "Xiaoyan Gong",
        "Fei-Yue Wang",
        "Yisheng Lv"
      ],
      "abstract": "Time series forecasting is important for applications spanning energy\nmarkets, climate analysis, and traffic management. However, existing methods\nstruggle to effectively integrate exogenous texts and align them with the\nprobabilistic nature of large language models (LLMs). Current approaches either\nemploy shallow text-time series fusion via basic prompts or rely on\ndeterministic numerical decoding that conflict with LLMs' token-generation\nparadigm, which limits contextual awareness and distribution modeling. To\naddress these limitations, we propose CAPTime, a context-aware probabilistic\nmultimodal time series forecasting method that leverages text-informed\nabstraction and autoregressive LLM decoding. Our method first encodes temporal\npatterns using a pretrained time series encoder, then aligns them with textual\ncontexts via learnable interactions to produce joint multimodal\nrepresentations. By combining a mixture of distribution experts with frozen\nLLMs, we enable context-aware probabilistic forecasting while preserving LLMs'\ninherent distribution modeling capabilities. Experiments on diverse time series\nforecasting tasks demonstrate the superior accuracy and generalization of\nCAPTime, particularly in multimodal scenarios. Additional analysis highlights\nits robustness in data-scarce scenarios through hybrid probabilistic decoding.",
      "tldr_zh": "本研究提出了一种名为CAPTime的上下文感知概率多模态时间序列预测方法，利用LLM（大型语言模型）来有效整合外生文本与时间序列数据，解决现有方法在文本融合和概率建模方面的局限性。该方法首先使用预训练时间序列编码器提取时间模式，然后通过可学习交互对齐文本上下文，生成联合多模态表示，并结合分布专家混合（mixture of distribution experts）和冻结LLM实现自回归概率预测。实验结果显示，CAPTime在多样化时间序列任务中表现出色，特别是在多模态场景下准确性和泛化能力优于基线模型，并在数据稀缺环境中通过混合概率解码展现出更高的鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2505.10774v1",
      "published_date": "2025-05-16 01:23:53 UTC",
      "updated_date": "2025-05-16 01:23:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:14:46.315316"
    },
    {
      "arxiv_id": "2505.10770v1",
      "title": "Geofenced Unmanned Aerial Robotic Defender for Deer Detection and Deterrence (GUARD)",
      "title_zh": "基于地理围栏的无人驾驶航空机器人防御者，用于鹿检测和威慑 (GUARD)",
      "authors": [
        "Ebasa Temesgen",
        "Mario Jerez",
        "Greta Brown",
        "Graham Wilson",
        "Sree Ganesh Lalitaditya Divakarla",
        "Sarah Boelter",
        "Oscar Nelson",
        "Robert McPherson",
        "Maria Gini"
      ],
      "abstract": "Wildlife-induced crop damage, particularly from deer, threatens agricultural\nproductivity. Traditional deterrence methods often fall short in scalability,\nresponsiveness, and adaptability to diverse farmland environments. This paper\npresents an integrated unmanned aerial vehicle (UAV) system designed for\nautonomous wildlife deterrence, developed as part of the Farm Robotics\nChallenge. Our system combines a YOLO-based real-time computer vision module\nfor deer detection, an energy-efficient coverage path planning algorithm for\nefficient field monitoring, and an autonomous charging station for continuous\noperation of the UAV. In collaboration with a local Minnesota farmer, the\nsystem is tailored to address practical constraints such as terrain,\ninfrastructure limitations, and animal behavior. The solution is evaluated\nthrough a combination of simulation and field testing, demonstrating robust\ndetection accuracy, efficient coverage, and extended operational time. The\nresults highlight the feasibility and effectiveness of drone-based wildlife\ndeterrence in precision agriculture, offering a scalable framework for future\ndeployment and extension.",
      "tldr_zh": "这篇论文介绍了 GUARD 系统，一种地理围栏无人机（UAV）防御方案，用于检测和驱逐鹿以减少野生动物对农作物的破坏。该系统整合了基于 YOLO 的实时计算机视觉模块、节能的覆盖路径规划算法以及自主充电站，确保高效监测和持续操作，并根据地形、基础设施和动物行为进行定制优化。通过模拟和现场测试，系统实现了鲁棒的检测准确率、efficient 覆盖路径和延长运行时间，证明了无人机在精准农业中的可行性和可扩展性，为未来部署提供了框架。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to the Novel Approaches for Precision Agriculture and\n  Forestry with Autonomous Robots IEEE ICRA Workshop - 2025",
      "pdf_url": "http://arxiv.org/pdf/2505.10770v1",
      "published_date": "2025-05-16 00:59:31 UTC",
      "updated_date": "2025-05-16 00:59:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:14:57.051066"
    },
    {
      "arxiv_id": "2505.13499v1",
      "title": "Optimal Control for Transformer Architectures: Enhancing Generalization, Robustness and Efficiency",
      "title_zh": "翻译失败",
      "authors": [
        "Kelvin Kan",
        "Xingjian Li",
        "Benjamin J. Zhang",
        "Tuhin Sahai",
        "Stanley Osher",
        "Markos A. Katsoulakis"
      ],
      "abstract": "We study Transformers through the perspective of optimal control theory,\nusing tools from continuous-time formulations to derive actionable insights\ninto training and architecture design. This framework improves the performance\nof existing Transformer models while providing desirable theoretical\nguarantees, including generalization and robustness. Our framework is designed\nto be plug-and-play, enabling seamless integration with established Transformer\nmodels and requiring only slight changes to the implementation. We conduct\nseven extensive experiments on tasks motivated by text generation, sentiment\nanalysis, image classification, and point cloud classification. Experimental\nresults show that the framework improves the test performance of the baselines,\nwhile being more parameter-efficient. On character-level text generation with\nnanoGPT, our framework achieves a 46% reduction in final test loss while using\n42% fewer parameters. On GPT-2, our framework achieves a 5.6% reduction in\nfinal test loss, demonstrating scalability to larger models. To the best of our\nknowledge, this is the first work that applies optimal control theory to both\nthe training and architecture of Transformers. It offers a new foundation for\nsystematic, theory-driven improvements and moves beyond costly trial-and-error\napproaches.",
      "tldr_zh": "本研究通过最优控制理论（optimal control theory）和连续时间公式（continuous-time formulations）来优化 Transformer 架构设计和训练，提供可操作的见解，以提升模型的泛化（generalization）、鲁棒性（robustness）和效率。该框架采用即插即用（plug-and-play）设计，仅需少量实现更改即可与现有 Transformer 模型无缝集成，并提供理论保证。实验在文本生成、情感分析、图像分类和点云分类等七个任务上显示，该框架显著提高了基线模型的测试性能，同时更参数高效，例如在 nanoGPT 的字符级文本生成中，减少 46% 的最终测试损失并使用 42% 更少的参数，在 GPT-2 上实现 5.6% 的测试损失降低。该工作首次将最优控制理论应用于 Transformers 的训练和架构，提供了一个理论驱动的改进基础，取代了传统的试错方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13499v1",
      "published_date": "2025-05-16 00:31:10 UTC",
      "updated_date": "2025-05-16 00:31:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:15:10.577802"
    },
    {
      "arxiv_id": "2505.13498v1",
      "title": "IRLBench: A Multi-modal, Culturally Grounded, Parallel Irish-English Benchmark for Open-Ended LLM Reasoning Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Khanh-Tung Tran",
        "Barry O'Sullivan",
        "Hoang D. Nguyen"
      ],
      "abstract": "Recent advances in Large Language Models (LLMs) have demonstrated promising\nknowledge and reasoning abilities, yet their performance in multilingual and\nlow-resource settings remains underexplored. Existing benchmarks often exhibit\ncultural bias, restrict evaluation to text-only, rely on multiple-choice\nformats, and, more importantly, are limited for extremely low-resource\nlanguages. To address these gaps, we introduce IRLBench, presented in parallel\nEnglish and Irish, which is considered definitely endangered by UNESCO. Our\nbenchmark consists of 12 representative subjects developed from the 2024 Irish\nLeaving Certificate exams, enabling fine-grained analysis of model capabilities\nacross domains. By framing the task as long-form generation and leveraging the\nofficial marking scheme, it does not only support a comprehensive evaluation of\ncorrectness but also language fidelity. Our extensive experiments of leading\nclosed-source and open-source LLMs reveal a persistent performance gap between\nEnglish and Irish, in which models produce valid Irish responses less than 80\\%\nof the time, and answer correctly 55.8\\% of the time compared to 76.2\\% in\nEnglish for the best-performing model. We release IRLBench\n(https://huggingface.co/datasets/ReliableAI/IRLBench) and an accompanying\nevaluation codebase (https://github.com/ReML-AI/IRLBench) to enable future\nresearch on robust, culturally aware multilingual AI development.",
      "tldr_zh": "本文引入了IRLBench，这是一个多模态、文化相关的平行英语-爱尔兰语基准，用于评估大型语言模型(LLMs)在开放式推理任务中的性能，特别是针对低资源语言的不足。IRLBench基于2024年爱尔兰Leaving Certificate考试的12个主题，采用长形式生成任务，并结合官方评分方案进行全面评估，包括正确性和语言忠实度。实验结果显示，领先的LLMs在爱尔兰语上的表现显著落后于英语，最佳模型的正确率仅为55.8%，而英语达到76.2%。作者发布了IRLBench数据集（https://huggingface.co/datasets/ReliableAI/IRLBench）和评估代码（https://github.com/ReML-AI/IRLBench），以推动鲁棒、多文化多语言AI的发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2505.13498v1",
      "published_date": "2025-05-16 00:02:05 UTC",
      "updated_date": "2025-05-16 00:02:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-25T00:15:23.078147"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 212,
  "processed_papers_count": 212,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-25T00:15:50.437558"
}