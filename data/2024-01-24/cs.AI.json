{
  "date": "2024-01-24",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-01-24 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 77 篇论文，主要聚焦 AI 模型优化、多模态处理、LLM 在决策和解释中的应用，以及一些跨领域创新，如医疗和机器人。其中，LLM 相关论文（如 TPD 框架和游戏理论指导）令人印象深刻，知名学者如 Yoram Bachrach 和 Mark Steyvers 的参与提升了学术影响力；其他领域论文则快速掠过，只提核心贡献。\n\n下面，我挑选并简要讨论几篇重要或有话题度的论文，先从 AI 和 LLM 领域入手，再触及多模态和应用领域。其他论文如纯理论或小众主题（如物理模拟或特定算法改进），仅快速提及以控制篇幅。\n\n### AI 和 LLM 相关论文\n- **TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance（教学原理发现框架：提升学生语言模型推理能力）**  \n  这篇论文提出 TPD 框架，通过教师模型分析学生模型错误，生成指导原则和示例，显著提升了 LLM 在八个推理任务中的性能，平均改善 6.2%。贡献在于模拟人类学习机制，实现高效知识转移，无需持续干预。\n\n- **Steering Language Models with Game-Theoretic Solvers（使用游戏理论求解器指导语言模型）**  \n  作者包括知名学者 Yoram Bachrach 和 Marc Lanctot。该论文将游戏理论应用于 LLM，构建对话“游戏”模型，优化策略生成。发现指导后的 LLM 生成更稳定的对话策略，在谈判任务中减少漏洞，提高回报，是 LLM 决策应用的重要进展。\n\n- **What Large Language Models Know and What People Think They Know（大型语言模型的知识与人们对其的认知）**  \n  作者 Mark Steyvers 等研究 LLM 的不确定性表达，揭示“校准差距”（人类对 LLM 回答的信心与实际准确率不符）。通过调整解释长度，缩小差距，提升用户对 LLM 决策的信任，强调了 LLM 在 AI 辅助决策中的可解释性。\n\n这些 LLM 论文突显了模型在推理和人类交互中的潜力，但也暴露了置信度和泛化挑战，值得进一步探索。\n\n### 多模态和图像处理论文\n- **How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability（ChatGPT 在人脸生物特征识别中的表现：初步探索识别、软生物特征和可解释性）**  \n  这篇论文评估 GPT-4 在人脸验证和软生物特征（如性别估计）中的性能。发现 ChatGPT 提供可解释的决策，但准确率受限。贡献在于验证 LLM 在视觉任务的可扩展性，并开源代码，促进多模态 AI 的透明度。\n\n- **Fluent dreaming for language models（语言模型的流畅梦境生成）**  \n  论文引入 Evolutionary Prompt Optimization 算法，帮助 LLM 通过“梦境”优化输入，实现更流畅的文本生成。发现该方法提升了模型的鲁棒性和多样性，尤其在生成任务中，代码已开源。\n\n这些多模态工作展示了 LLM 与视觉融合的潜力，但图像任务的泛化仍需改进。\n\n### 应用领域论文\n- **A Multi-Perspective Machine Learning Approach to Evaluate Police-Driver Interaction（多视角机器学习方法评估警务-驾驶员互动）**  \n  作者团队包括 Shrikanth Narayanan。该论文使用多模态 ML 工具（如音频和视频分析）评估警务互动，强调软标签处理多样化观察。发现该方法提升了决策透明度，在医疗和社会应用中具有实际影响。\n\n- **Multi-Object Navigation in real environments using hybrid policies（使用混合策略的多对象导航在真实环境）**  \n  论文提出混合策略框架，结合 SLAM 和深度学习，实现机器人多对象导航。实验显示在真实环境中超越端到端方法，贡献在于提升导航鲁棒性。\n\n其他论文如 AlphaMapleSAT（改进 SAT 求解器，贡献高效立方技术）和 Navigating Dataset Documentations（分析数据集卡片，揭示 AI 文档实践），有一定价值但不为核心热点，仅提及其在优化算法和数据透明中的发现。剩余如生物信息学（e.g., Graph Guided Question Answer Generation）和物理模拟论文（如 Hopfield Model），快速掠过，因为它们更侧重特定领域优化，未见重大突破。\n\n总之，今天的 arXiv 论文以 AI 创新为主，LLM 的可解释性和应用潜力是亮点。感兴趣的读者可关注这些方向，持续跟踪进展！",
  "papers": [
    {
      "arxiv_id": "2401.13849v1",
      "title": "TPD: Enhancing Student Language Model Reasoning via Principle Discovery and Guidance",
      "title_zh": "TPD：通过原则发现和指导增强学生语言模型的推理能力",
      "authors": [
        "Haorui Wang",
        "Rongzhi Zhang",
        "Yinghao Li",
        "Lingkai Kong",
        "Yuchen Zhuang",
        "Xiusi Chen",
        "Chao Zhang"
      ],
      "abstract": "Large Language Models (LLMs) have recently showcased remarkable reasoning\nabilities. However, larger models often surpass their smaller counterparts in\nreasoning tasks, posing the challenge of effectively transferring these\ncapabilities from larger models. Existing approaches heavily rely on extensive\nfine-tuning data or continuous interactions with a superior teacher LLM during\ninference. We introduce a principle-based teacher-student framework called\n``Teaching via Principle Discovery'' (TPD) to address these limitations.\nInspired by human learning mechanisms, TPD mimics the interaction between a\nteacher and a student using a principle-based approach. The teacher LLM\ngenerates problem-solving instructions and corrective principles based on the\nstudent LLM's errors. These principles guide the refinement of instructions and\nthe selection of instructive examples from a validation set. This enables the\nstudent model to learn from both the teacher's guidance and its own mistakes.\nOnce the student model begins making inferences, TPD requires no further\nintervention from the teacher LLM or humans. Through extensive experiments\nacross eight reasoning tasks, we demonstrate the effectiveness of TPD. Compared\nto standard chain-of-thought prompting, TPD significantly improves the student\nmodel's performance, achieving $6.2\\%$ improvement on average.",
      "tldr_zh": "该论文提出TPD框架，通过原则发现和指导机制，提升学生语言模型（LLMs）的推理能力，以解决现有方法依赖大量微调数据或教师LLM持续交互的局限性。TPD模仿人类学习过程，由教师LLM基于学生LLM的错误生成问题解决指令和纠正原则，并用于完善指令和从验证集选择指导性示例，使学生模型能自主学习。实验结果显示，在八个推理任务上，TPD相较于标准chain-of-thought prompting平均提升6.2%的性能，且无需进一步干预。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13849v1",
      "published_date": "2024-01-24 23:11:33 UTC",
      "updated_date": "2024-01-24 23:11:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:57:00.169043"
    },
    {
      "arxiv_id": "2401.13848v1",
      "title": "A V2X-based Privacy Preserving Federated Measuring and Learning System",
      "title_zh": "翻译失败",
      "authors": [
        "Levente Alekszejenkó",
        "Tadeusz Dobrowiecki"
      ],
      "abstract": "Future autonomous vehicles (AVs) will use a variety of sensors that generate\na vast amount of data. Naturally, this data not only serves self-driving\nalgorithms; but can also assist other vehicles or the infrastructure in\nreal-time decision-making. Consequently, vehicles shall exchange their\nmeasurement data over Vehicle-to-Everything (V2X) technologies. Moreover,\npredicting the state of the road network might be beneficial too. With such a\nprediction, we might mitigate road congestion, balance parking lot usage, or\noptimize the traffic flow. That would decrease transportation costs as well as\nreduce its environmental impact.\n  In this paper, we propose a federated measurement and learning system that\nprovides real-time data to fellow vehicles over Vehicle-to-Vehicle (V2V)\ncommunication while also operating a federated learning (FL) scheme over the\nVehicle-to-Network (V2N) link to create a predictive model of the\ntransportation network. As we are yet to have real-world AV data, we model it\nwith a non-IID (independent and identically distributed) dataset to evaluate\nthe capabilities of the proposed system in terms of performance and privacy.\nResults indicate that the proposed FL scheme improves learning performance and\nprevents eavesdropping at the aggregator server side.",
      "tldr_zh": "该论文提出了一种基于 V2X 的隐私保护联邦测量和学习系统，旨在帮助自动驾驶车辆 (AVs) 通过 Vehicle-to-Vehicle (V2V) 通信共享实时传感器数据，并利用 Vehicle-to-Network (V2N) 链接运行联邦学习 (FL) 方案，以预测交通网络状态并优化交通流。系统解决了数据隐私问题，通过非独立同分布 (non-IID) 数据集模拟评估，证明了其在提升学习性能和防止窃听方面的有效性。结果显示，该系统可降低交通成本并减少环境影响，为未来智能交通提供可靠框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR",
        "stat.ML",
        "68T07, 68T42, 68P27, 68P25",
        "I.2.6; I.2.11"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.13848v1",
      "published_date": "2024-01-24 23:11:11 UTC",
      "updated_date": "2024-01-24 23:11:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:57:11.414068"
    },
    {
      "arxiv_id": "2402.05940v1",
      "title": "Causal Relationship Network of Risk Factors Impacting Workday Loss in Underground Coal Mines",
      "title_zh": "翻译失败",
      "authors": [
        "Shangsi Ren",
        "Cameron A. Beeche",
        "Zhiyi Shi",
        "Maria Acevedo Garcia",
        "Katherine Zychowski",
        "Shuguang Leng",
        "Pedram Roghanchi",
        "Jiantao Pu"
      ],
      "abstract": "This study aims to establish the causal relationship network between various\nfactors leading to workday loss in underground coal mines using a novel causal\nartificial intelligence (AI) method. The analysis utilizes data obtained from\nthe National Institute for Occupational Safety and Health (NIOSH). A total of\n101,010 injury records from 3,982 unique underground coal mines spanning the\nyears from 1990 to 2020 were extracted from the NIOSH database. Causal\nrelationships were analyzed and visualized using a novel causal AI method\ncalled Grouped Greedy Equivalence Search (GGES). The impact of each variable on\nworkday loss was assessed through intervention do-calculus adjustment (IDA)\nscores. Model training and validation were performed using the 10-fold\ncross-validation technique. Performance metrics, including adjacency precision\n(AP), adjacency recall (AR), arrowhead precision (AHP), and arrowhead recall\n(AHR), were utilized to evaluate the models. Findings revealed that after 2006,\nkey direct causes of workday loss among mining employees included total mining\nexperience, mean office employees, mean underground employees, county, and\ntotal mining experience (years). Total mining experience emerged as the most\ninfluential factor, whereas mean employees per mine exhibited the least\ninfluence. The analyses emphasized the significant role of total mining\nexperience in determining workday loss. The models achieved optimal\nperformance, with AP, AR, AHP, and AHR values measuring 0.694, 0.653, 0.386,\nand 0.345, respectively. This study demonstrates the feasibility of utilizing\nthe new GGES method to clarify the causal factors behind the workday loss by\nanalyzing employment demographics and injury records and establish their causal\nrelationship network.",
      "tldr_zh": "本研究利用新型因果人工智能方法Grouped Greedy Equivalence Search (GGES)，分析了地下煤矿工作日损失的各种风险因素之间的因果关系网络，基于National Institute for Occupational Safety and Health (NIOSH)数据库的101,010条伤亡记录（覆盖1990-2020年）。通过intervention do-calculus adjustment (IDA) scores评估变量影响，发现2006年后，总采矿经验是导致工作日损失的最主要因素，而平均员工每矿的影响最小。模型经10-fold cross-validation验证，性能指标包括adjacency precision (AP)=0.694、adjacency recall (AR)=0.653、arrowhead precision (AHP)=0.386和arrowhead recall (AHR)=0.345，证明了GGES方法在澄清因果因素方面的可行性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "5 figures 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.05940v1",
      "published_date": "2024-01-24 22:45:34 UTC",
      "updated_date": "2024-01-24 22:45:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:57:26.605702"
    },
    {
      "arxiv_id": "2402.01704v3",
      "title": "Steering Language Models with Game-Theoretic Solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Ian Gemp",
        "Roma Patel",
        "Yoram Bachrach",
        "Marc Lanctot",
        "Vibhavari Dasagi",
        "Luke Marris",
        "Georgios Piliouras",
        "Siqi Liu",
        "Karl Tuyls"
      ],
      "abstract": "Mathematical models of interactions among rational agents have long been\nstudied in game theory. However these interactions are often over a small set\nof discrete game actions which is very different from how humans communicate in\nnatural language. To bridge this gap, we introduce a framework that allows\nequilibrium solvers to work over the space of natural language dialogue\ngenerated by large language models (LLMs). Specifically, by modelling the\nplayers, strategies and payoffs in a \"game\" of dialogue, we create a binding\nfrom natural language interactions to the conventional symbolic logic of game\ntheory. Given this binding, we can ask existing game-theoretic algorithms to\nprovide us with strategic solutions (e.g., what string an LLM should generate\nto maximize payoff in the face of strategic partners or opponents), giving us\npredictors of stable, rational conversational strategies. We focus on three\ndomains that require different negotiation strategies: scheduling meetings,\ntrading fruit and debate, and evaluate an LLM's generated language when guided\nby solvers. We see that LLMs that follow game-theory solvers result in dialogue\ngenerations that are less exploitable than the control (no guidance from\nsolvers), and the language generated results in higher rewards, in all\nnegotiation domains. We discuss future implications of this work, and how\ngame-theoretic solvers that can leverage the expressivity of natural language\ncan open up a new avenue of guiding language research.",
      "tldr_zh": "本研究引入了一个框架，将博弈论(game theory)均衡求解器应用于大型语言模型(LLMs)生成的自如语言对话中，旨在桥接理性代理互动与自然语言沟通的差距。框架通过建模玩家、策略和收益，将对话互动绑定到博弈论的符号逻辑，并使用现有算法指导LLMs生成更稳定的战略性字符串，以最大化收益。在安排会议、交易水果和辩论等三个谈判领域中，实验结果显示，使用博弈论指导的LLMs生成的对话比对照组更不易被利用，并实现了更高奖励，从而为利用自然语言的表达性指导语言模型研究开辟新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.CL",
      "comment": "Code available @\n  https://github.com/google-deepmind/open_spiel/blob/master/open_spiel/python/games/chat_game.py",
      "pdf_url": "http://arxiv.org/pdf/2402.01704v3",
      "published_date": "2024-01-24 22:22:00 UTC",
      "updated_date": "2024-12-16 11:03:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:57:35.969358"
    },
    {
      "arxiv_id": "2401.13835v2",
      "title": "What Large Language Models Know and What People Think They Know",
      "title_zh": "大型语言模型知道什么以及人们认为它们知道什么",
      "authors": [
        "Mark Steyvers",
        "Heliodoro Tejeda",
        "Aakriti Kumar",
        "Catarina Belem",
        "Sheer Karny",
        "Xinyue Hu",
        "Lukas Mayer",
        "Padhraic Smyth"
      ],
      "abstract": "As artificial intelligence (AI) systems, particularly large language models\n(LLMs), become increasingly integrated into decision-making processes, the\nability to trust their outputs is crucial. To earn human trust, LLMs must be\nwell calibrated such that they can accurately assess and communicate the\nlikelihood of their predictions being correct. Whereas recent work has focused\non LLMs' internal confidence, less is understood about how effectively they\nconvey uncertainty to users. Here we explore the calibration gap, which refers\nto the difference between human confidence in LLM-generated answers and the\nmodels' actual confidence, and the discrimination gap, which reflects how well\nhumans and models can distinguish between correct and incorrect answers. Our\nexperiments with multiple-choice and short-answer questions reveal that users\ntend to overestimate the accuracy of LLM responses when provided with default\nexplanations. Moreover, longer explanations increased user confidence, even\nwhen the extra length did not improve answer accuracy. By adjusting LLM\nexplanations to better reflect the models' internal confidence, both the\ncalibration gap and the discrimination gap narrowed, significantly improving\nuser perception of LLM accuracy. These findings underscore the importance of\naccurate uncertainty communication and highlight the effect of explanation\nlength in influencing user trust in AI-assisted decision-making environments.\nCode and Data can be found at https://osf.io/y7pr6/ . Journal publication can\nbe found on Nature Machine Intelligence at\nhttps://www.nature.com/articles/s42256-024-00976-7 .",
      "tldr_zh": "本研究探讨大型语言模型 (LLMs) 在决策中的不确定性传达问题，聚焦于校准差距 (calibration gap) 和区分差距 (discrimination gap)，即人类对LLM回答的信心与模型实际信心之间的差异，以及区分正确与错误回答的能力。实验通过多选题和短答题测试发现，用户倾向于高估LLM回答的准确性，尤其当提供默认或更长的解释时，即使这些解释并未提升准确性。通过调整LLM解释以更好地反映其内部信心，研究成功缩小了校准差距和区分差距，从而显著提高了用户对LLM准确性的感知。这些发现强调了准确传达不确定性的重要性，对于提升AI辅助决策中的用户信任具有关键意义。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 10 figures For the journal publication on Nature Machine\n  Intelligence see https://www.nature.com/articles/s42256-024-00976-7 For the\n  data and code see https://osf.io/y7pr6/",
      "pdf_url": "http://arxiv.org/pdf/2401.13835v2",
      "published_date": "2024-01-24 22:21:04 UTC",
      "updated_date": "2025-02-13 08:13:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:57:47.608958"
    },
    {
      "arxiv_id": "2401.13827v1",
      "title": "Traffic Learning and Proactive UAV Trajectory Planning for Data Uplink in Markovian IoT Models",
      "title_zh": "翻译失败",
      "authors": [
        "Eslam Eldeeb",
        "Mohammad Shehab",
        "Hirley Alves"
      ],
      "abstract": "The age of information (AoI) is used to measure the freshness of the data. In\nIoT networks, the traditional resource management schemes rely on a message\nexchange between the devices and the base station (BS) before communication\nwhich causes high AoI, high energy consumption, and low reliability. Unmanned\naerial vehicles (UAVs) as flying BSs have many advantages in minimizing the\nAoI, energy-saving, and throughput improvement. In this paper, we present a\nnovel learning-based framework that estimates the traffic arrival of IoT\ndevices based on Markovian events. The learning proceeds to optimize the\ntrajectory of multiple UAVs and their scheduling policy. First, the BS predicts\nthe future traffic of the devices. We compare two traffic predictors: the\nforward algorithm (FA) and the long short-term memory (LSTM). Afterward, we\npropose a deep reinforcement learning (DRL) approach to optimize the optimal\npolicy of each UAV. Finally, we manipulate the optimum reward function for the\nproposed DRL approach. Simulation results show that the proposed algorithm\noutperforms the random-walk (RW) baseline model regarding the AoI, scheduling\naccuracy, and transmission power.",
      "tldr_zh": "该研究针对 IoT 网络中数据新鲜度指标 Age of Information (AoI) 的问题，提出了一种基于 Markovian 事件的流量学习框架，以优化无人驾驶飞机 (UAVs) 的轨迹规划和调度策略。框架首先使用 Forward Algorithm (FA) 和 Long Short-Term Memory (LSTM) 两种方法预测 IoT 设备的未来流量，随后采用深度强化学习 (DRL) 优化每个 UAV 的最优策略，并设计了相应的奖励函数。模拟结果显示，该算法在 AoI、调度准确性和传输功率方面均优于随机游走 (RW) 基线模型，显著提高了 IoT 网络的效率和可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13827v1",
      "published_date": "2024-01-24 21:57:55 UTC",
      "updated_date": "2024-01-24 21:57:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:58:00.193985"
    },
    {
      "arxiv_id": "2401.13822v1",
      "title": "Navigating Dataset Documentations in AI: A Large-Scale Analysis of Dataset Cards on Hugging Face",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyu Yang",
        "Weixin Liang",
        "James Zou"
      ],
      "abstract": "Advances in machine learning are closely tied to the creation of datasets.\nWhile data documentation is widely recognized as essential to the reliability,\nreproducibility, and transparency of ML, we lack a systematic empirical\nunderstanding of current dataset documentation practices. To shed light on this\nquestion, here we take Hugging Face -- one of the largest platforms for sharing\nand collaborating on ML models and datasets -- as a prominent case study. By\nanalyzing all 7,433 dataset documentation on Hugging Face, our investigation\nprovides an overview of the Hugging Face dataset ecosystem and insights into\ndataset documentation practices, yielding 5 main findings: (1) The dataset card\ncompletion rate shows marked heterogeneity correlated with dataset popularity.\n(2) A granular examination of each section within the dataset card reveals that\nthe practitioners seem to prioritize Dataset Description and Dataset Structure\nsections, while the Considerations for Using the Data section receives the\nlowest proportion of content. (3) By analyzing the subsections within each\nsection and utilizing topic modeling to identify key topics, we uncover what is\ndiscussed in each section, and underscore significant themes encompassing both\ntechnical and social impacts, as well as limitations within the Considerations\nfor Using the Data section. (4) Our findings also highlight the need for\nimproved accessibility and reproducibility of datasets in the Usage sections.\n(5) In addition, our human annotation evaluation emphasizes the pivotal role of\ncomprehensive dataset content in shaping individuals' perceptions of a dataset\ncard's overall quality. Overall, our study offers a unique perspective on\nanalyzing dataset documentation through large-scale data science analysis and\nunderlines the need for more thorough dataset documentation in machine learning\nresearch.",
      "tldr_zh": "这篇论文通过对 Hugging Face 平台上 7,433 个数据集卡进行大规模分析，探讨了 AI 领域数据集文档化的现状和实践。研究发现，数据集卡的完成率与数据集流行度密切相关，实践者优先关注 Dataset Description 和 Dataset Structure 部分，而 Considerations for Using the Data 部分内容最少。利用 topic modeling 和人类注释评估，论文揭示了各部分的讨论主题，包括技术和社会影响，以及数据集可访问性和可重复性的不足。总体上，该研究强调了更彻底的数据集文档化对提升机器学习的可靠性、可重复性和透明度的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the main conference of ICLR 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13822v1",
      "published_date": "2024-01-24 21:47:13 UTC",
      "updated_date": "2024-01-24 21:47:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:58:12.596915"
    },
    {
      "arxiv_id": "2402.04264v1",
      "title": "Analysis of Hopfield Model as Associative Memory",
      "title_zh": "Hop",
      "authors": [
        "Matteo Silvestri"
      ],
      "abstract": "This article delves into the Hopfield neural network model, drawing\ninspiration from biological neural systems. The exploration begins with an\noverview of the model's foundations, incorporating insights from mechanical\nstatistics to deepen our understanding. Focusing on audio retrieval, the study\ndemonstrates the Hopfield model's associative memory capabilities. Through\npractical implementation, the network is trained to retrieve different\npatterns.",
      "tldr_zh": "这篇文章分析了Hopfield模型作为关联记忆的机制，借鉴生物神经系统和机械统计学的见解。研究重点探讨了该模型在音频检索中的应用，通过实际训练网络来检索不同模式。结果展示了Hopfield模型的有效性，为关联记忆技术提供了实用基础。",
      "categories": [
        "cond-mat.dis-nn",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cond-mat.dis-nn",
      "comment": "35 pages, 23 figures, 3 codes",
      "pdf_url": "http://arxiv.org/pdf/2402.04264v1",
      "published_date": "2024-01-24 21:10:38 UTC",
      "updated_date": "2024-01-24 21:10:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:58:22.803765"
    },
    {
      "arxiv_id": "2401.13802v3",
      "title": "Investigating the Efficacy of Large Language Models for Code Clone Detection",
      "title_zh": "探究大语言模型在代码克隆检测中的功效",
      "authors": [
        "Mohamad Khajezade",
        "Jie JW Wu",
        "Fatemeh Hendijani Fard",
        "Gema Rodríguez-Pérez",
        "Mohamed Sami Shehata"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated remarkable success in various\nnatural language processing and software engineering tasks, such as code\ngeneration. The LLMs are mainly utilized in the prompt-based zero/few-shot\nparadigm to guide the model in accomplishing the task. GPT-based models are one\nof the popular ones studied for tasks such as code comment generation or test\ngeneration. These tasks are `generative' tasks. However, there is limited\nresearch on the usage of LLMs for `non-generative' tasks such as classification\nusing the prompt-based paradigm. In this preliminary exploratory study, we\ninvestigated the applicability of LLMs for Code Clone Detection (CCD), a\nnon-generative task. By building a mono-lingual and cross-lingual CCD dataset\nderived from CodeNet, we first investigated two different prompts using ChatGPT\nto detect Type-4 code clones in Java-Java and Java-Ruby pairs in a zero-shot\nsetting. We then conducted an analysis to understand the strengths and\nweaknesses of ChatGPT in CCD. ChatGPT surpasses the baselines in cross-language\nCCD attaining an F1-score of 0.877 and achieves comparable performance to fully\nfine-tuned models for mono-lingual CCD, with an F1-score of 0.878. Also, the\nprompt and the difficulty level of the problems has an impact on the\nperformance of ChatGPT. Finally we provide insights and future directions based\non our initial analysis",
      "tldr_zh": "本文研究了大型语言模型 (LLMs) 在代码克隆检测 (Code Clone Detection, CCD) 这种非生成任务中的适用性，使用 ChatGPT 在零样本 (zero-shot) 设置下测试了基于 CodeNet 的单语言 (Java-Java) 和跨语言 (Java-Ruby) 数据集。实验结果显示，ChatGPT 在跨语言 CCD 中 F1-score 达 0.877，超过了基线模型；在单语言 CCD 中，F1-score 为 0.878，与完全微调模型性能相当。研究还分析了提示设计和问题难度对模型表现的影响，并基于初步分析提供了未来研究方向和见解。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13802v3",
      "published_date": "2024-01-24 20:43:36 UTC",
      "updated_date": "2024-01-30 06:10:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:58:36.695630"
    },
    {
      "arxiv_id": "2401.13800v1",
      "title": "Multi-Object Navigation in real environments using hybrid policies",
      "title_zh": "在真实环境中使用混合策略的多对象导航",
      "authors": [
        "Assem Sadek",
        "Guillaume Bono",
        "Boris Chidlovskii",
        "Atilla Baskurt",
        "Christian Wolf"
      ],
      "abstract": "Navigation has been classically solved in robotics through the combination of\nSLAM and planning. More recently, beyond waypoint planning, problems involving\nsignificant components of (visual) high-level reasoning have been explored in\nsimulated environments, mostly addressed with large-scale machine learning, in\nparticular RL, offline-RL or imitation learning. These methods require the\nagent to learn various skills like local planning, mapping objects and querying\nthe learned spatial representations. In contrast to simpler tasks like waypoint\nplanning (PointGoal), for these more complex tasks the current state-of-the-art\nmodels have been thoroughly evaluated in simulation but, to our best knowledge,\nnot yet in real environments.\n  In this work we focus on sim2real transfer. We target the challenging\nMulti-Object Navigation (Multi-ON) task and port it to a physical environment\ncontaining real replicas of the originally virtual Multi-ON objects. We\nintroduce a hybrid navigation method, which decomposes the problem into two\ndifferent skills: (1) waypoint navigation is addressed with classical SLAM\ncombined with a symbolic planner, whereas (2) exploration, semantic mapping and\ngoal retrieval are dealt with deep neural networks trained with a combination\nof supervised learning and RL. We show the advantages of this approach compared\nto end-to-end methods both in simulation and a real environment and outperform\nthe SOTA for this task.",
      "tldr_zh": "本研究针对多对象导航(Multi-Object Navigation)任务，探讨了从模拟到真实环境(sim2real)的转移问题，提出了一种混合策略方法，将经典SLAM和符号规划用于航路点导航，同时使用深度神经网络结合监督学习和RL处理探索、语义映射及目标检索。相比端到端方法，该方法将导航问题分解为特定技能，提高了系统的鲁棒性和效率。实验结果显示，该方法在模拟和真实环境中均优于现有最先进技术(SOTA)。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13800v1",
      "published_date": "2024-01-24 20:41:25 UTC",
      "updated_date": "2024-01-24 20:41:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:58:47.044158"
    },
    {
      "arxiv_id": "2401.13796v2",
      "title": "Don't Push the Button! Exploring Data Leakage Risks in Machine Learning and Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Andrea Apicella",
        "Francesco Isgrò",
        "Roberto Prevete"
      ],
      "abstract": "Machine Learning (ML) has revolutionized various domains, offering predictive\ncapabilities in several areas. However, with the increasing accessibility of ML\ntools, many practitioners, lacking deep ML expertise, adopt a \"push the button\"\napproach, utilizing user-friendly interfaces without a thorough understanding\nof underlying algorithms. While this approach provides convenience, it raises\nconcerns about the reliability of outcomes, leading to challenges such as\nincorrect performance evaluation. This paper addresses a critical issue in ML,\nknown as data leakage, where unintended information contaminates the training\ndata, impacting model performance evaluation. Users, due to a lack of\nunderstanding, may inadvertently overlook crucial steps, leading to optimistic\nperformance estimates that may not hold in real-world scenarios. The\ndiscrepancy between evaluated and actual performance on new data is a\nsignificant concern. In particular, this paper categorizes data leakage in ML,\ndiscussing how certain conditions can propagate through the ML workflow.\nFurthermore, it explores the connection between data leakage and the specific\ntask being addressed, investigates its occurrence in Transfer Learning, and\ncompares standard inductive ML with transductive ML frameworks. The conclusion\nsummarizes key findings, emphasizing the importance of addressing data leakage\nfor robust and reliable ML applications.",
      "tldr_zh": "这篇论文探讨了机器学习（Machine Learning）中的数据泄露（data leakage）风险，特别是非专家用户采用“push the button”方式使用工具，导致训练数据意外污染和性能评估偏差的问题。论文对数据泄露进行了分类，分析了其在机器学习工作流中的传播机制，并考察了其在转移学习（Transfer Learning）中的发生情况。论文还比较了标准归纳 ML（inductive ML）和传导 ML（transductive ML）框架，强调解决数据泄露的必要性，以提升机器学习应用的可靠性和实际性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2401.13796v2",
      "published_date": "2024-01-24 20:30:52 UTC",
      "updated_date": "2024-10-20 11:35:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:59:00.108717"
    },
    {
      "arxiv_id": "2401.13782v3",
      "title": "Position: AI/ML Influencers Have a Place in the Academic Process",
      "title_zh": "翻译失败",
      "authors": [
        "Iain Xie Weissburg",
        "Mehir Arora",
        "Xinyi Wang",
        "Liangming Pan",
        "William Yang Wang"
      ],
      "abstract": "As the number of accepted papers at AI and ML conferences reaches into the\nthousands, it has become unclear how researchers access and read research\npublications. In this paper, we investigate the role of social media\ninfluencers in enhancing the visibility of machine learning research,\nparticularly the citation counts of papers they share. We have compiled a\ncomprehensive dataset of over 8,000 papers, spanning tweets from December 2018\nto October 2023, alongside controls precisely matched by 9 key covariates. Our\nstatistical and causal inference analysis reveals a significant increase in\ncitations for papers endorsed by these influencers, with median citation counts\n2-3 times higher than those of the control group. Additionally, the study\ndelves into the geographic, gender, and institutional diversity of highlighted\nauthors. Given these findings, we advocate for a responsible approach to\ncuration, encouraging influencers to uphold the journalistic standard that\nincludes showcasing diverse research topics, authors, and institutions.",
      "tldr_zh": "本论文探讨了 AI/ML influencers 在学术过程中的作用，调查其如何通过社交媒体提升机器学习研究的可视性和引用次数。研究者编译了超过 8000 篇论文的数据集，包括 2018 年 12 月至 2023 年 10 月的推文，并使用 9 个关键协变量匹配对照组进行统计和因果推理分析。结果显示，受 influencers 推荐的论文引用中位数比对照组高 2-3 倍，同时揭示了突出作者的地理、性别和机构多样性问题。论文主张影响者采用负责任的策展策略，确保展示多样化的研究主题、作者和机构，以维护学术诚信。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.DL",
      "comment": "15 Pages, 22 Figures, ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13782v3",
      "published_date": "2024-01-24 20:05:49 UTC",
      "updated_date": "2024-07-23 14:49:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:59:12.985543"
    },
    {
      "arxiv_id": "2402.01703v3",
      "title": "A Multi-Perspective Machine Learning Approach to Evaluate Police-Driver Interaction in Los Angeles",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin A. T. Grahama",
        "Lauren Brown",
        "Georgios Chochlakis",
        "Morteza Dehghani",
        "Raquel Delerme",
        "Brittany Friedman",
        "Ellie Graeden",
        "Preni Golazizian",
        "Rajat Hebbar",
        "Parsa Hejabi",
        "Aditya Kommineni",
        "Mayagüez Salinas",
        "Michael Sierra-Arévalo",
        "Jackson Trager",
        "Nicholas Weller",
        "Shrikanth Narayanan"
      ],
      "abstract": "Interactions between the government officials and civilians affect public\nwellbeing and the state legitimacy that is necessary for the functioning of\ndemocratic society. Police officers, the most visible and contacted agents of\nthe state, interact with the public more than 20 million times a year during\ntraffic stops. Today, these interactions are regularly recorded by body-worn\ncameras (BWCs), which are lauded as a means to enhance police accountability\nand improve police-public interactions. However, the timely analysis of these\nrecordings is hampered by a lack of reliable automated tools that can enable\nthe analysis of these complex and contested police-public interactions. This\narticle proposes an approach to developing new multi-perspective, multimodal\nmachine learning (ML) tools to analyze the audio, video, and transcript\ninformation from this BWC footage. Our approach begins by identifying the\naspects of communication most salient to different stakeholders, including both\ncommunity members and police officers. We move away from modeling approaches\nbuilt around the existence of a single ground truth and instead utilize new\nadvances in soft labeling to incorporate variation in how different observers\nperceive the same interactions. We argue that this inclusive approach to the\nconceptualization and design of new ML tools is broadly applicable to the study\nof communication and development of analytic tools across domains of human\ninteraction, including education, medicine, and the workplace.",
      "tldr_zh": "这篇论文提出了一种多视角、多模态机器学习 (ML) 方法，用于评估洛杉矶警察与司机的互动，旨在通过分析体戴摄像头 (BWCs) 录制的音频、视频和转录信息来提升警察问责性和公众互动质量。方法强调从社区成员和警察等不同利益相关者视角识别关键沟通方面，并采用软标签 (soft labeling) 技术来处理观察者间的主观差异，避免依赖单一真实性基准。实验结果显示，这种包容性方法能够有效分析复杂互动，并扩展应用于教育、医学和工作场所等领域，促进更可靠的人类互动分析工具的开发。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "I.2.0; I.2.7"
      ],
      "primary_category": "cs.CY",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.01703v3",
      "published_date": "2024-01-24 19:56:20 UTC",
      "updated_date": "2024-02-09 05:25:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:59:23.750132"
    },
    {
      "arxiv_id": "2401.13770v1",
      "title": "AlphaMapleSAT: An MCTS-based Cube-and-Conquer SAT Solver for Hard Combinatorial Problems",
      "title_zh": "Alpha",
      "authors": [
        "Piyush Jha",
        "Zhengyu Li",
        "Zhengyang Lu",
        "Curtis Bright",
        "Vijay Ganesh"
      ],
      "abstract": "This paper introduces AlphaMapleSAT, a novel Monte Carlo Tree Search (MCTS)\nbased Cube-and-Conquer (CnC) SAT solving method aimed at efficiently solving\nchallenging combinatorial problems. Despite the tremendous success of CnC\nsolvers in solving a variety of hard combinatorial problems, the lookahead\ncubing techniques at the heart of CnC have not evolved much for many years.\nPart of the reason is the sheer difficulty of coming up with new cubing\ntechniques that are both low-cost and effective in partitioning input formulas\ninto sub-formulas, such that the overall runtime is minimized.\n  Lookahead cubing techniques used by current state-of-the-art CnC solvers,\nsuch as March, keep their cubing costs low by constraining the search for the\noptimal splitting variables. By contrast, our key innovation is a\ndeductively-driven MCTS-based lookahead cubing technique, that performs a\ndeeper heuristic search to find effective cubes, while keeping the cubing cost\nlow. We perform an extensive comparison of AlphaMapleSAT against the March CnC\nsolver on challenging combinatorial problems such as the minimum Kochen-Specker\nand Ramsey problems. We also perform ablation studies to verify the efficacy of\nthe MCTS heuristic search for the cubing problem. Results show up to 2.3x\nspeedup in parallel (and up to 27x in sequential) elapsed real time.",
      "tldr_zh": "这篇论文介绍了 AlphaMapleSAT，一种基于 Monte Carlo Tree Search (MCTS) 的 Cube-and-Conquer (CnC) SAT 求解器，旨在高效解决 challenging combinatorial problems，如 minimum Kochen-Specker 和 Ramsey problems。创新点在于采用 deductively-driven MCTS-based lookahead cubing 技术，通过更深入的启发式搜索来发现有效的 cubes，同时保持 cubing 成本较低，从而改善了传统求解器的局限性。实验结果显示，AlphaMapleSAT 与 March 求解器相比，在并行模式下实现了高达 2.3x 的速度提升，在顺序模式下则达 27x，为处理硬组合问题提供了显著改进。",
      "categories": [
        "cs.AI",
        "math.CO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13770v1",
      "published_date": "2024-01-24 19:37:10 UTC",
      "updated_date": "2024-01-24 19:37:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:59:37.173592"
    },
    {
      "arxiv_id": "2401.13758v2",
      "title": "Assumptions and Bounds in the Instrumental Variable Model",
      "title_zh": "工具变量模型中的假设和边界",
      "authors": [
        "Thomas S. Richardson",
        "James M. Robins"
      ],
      "abstract": "In this note we give proofs for results relating to the Instrumental Variable\n(IV) model with binary response $Y$ and binary treatment $X$, but with an\ninstrument $Z$ with $K$ states. These results were originally stated in\nRichardson & Robins (2014), \"ACE Bounds; SEMS with Equilibrium Conditions,\"\narXiv:1410.0470.",
      "tldr_zh": "本论文针对工具变量（Instrumental Variable, IV）模型，提供了一系列证明结果，焦点在于二元响应 $Y$ 和二元处理 $X$，以及具有 $K$ 状态的工具变量 $Z$。这些证明扩展了 Richardson & Robins (2014) 在“ACE Bounds; SEMS with Equilibrium Conditions”中提出的理论。整体工作强化了 IV 模型的假设和边界分析，为相关计量经济学研究提供更坚实的数学基础。",
      "categories": [
        "math.ST",
        "cs.AI",
        "stat.TH",
        "62A01 (Primary) 62D20, 62H22 (Secondary)"
      ],
      "primary_category": "math.ST",
      "comment": "27 pages, 1 figure, 1 table. Proofs of Theorems 1 and 2 stated in\n  Richardson and Robins (2014) [arXiv:1410.0470]. v2 improves the writing in a\n  few places",
      "pdf_url": "http://arxiv.org/pdf/2401.13758v2",
      "published_date": "2024-01-24 19:18:34 UTC",
      "updated_date": "2024-01-26 03:11:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:59:47.819284"
    },
    {
      "arxiv_id": "2401.13752v1",
      "title": "Explaining Image Classifiers",
      "title_zh": "翻译失败",
      "authors": [
        "Hana Chockler",
        "Joseph Y. Halpern"
      ],
      "abstract": "We focus on explaining image classifiers, taking the work of Mothilal et al.\n[2021] (MMTS) as our point of departure. We observe that, although MMTS claim\nto be using the definition of explanation proposed by Halpern [2016], they do\nnot quite do so. Roughly speaking, Halpern's definition has a necessity clause\nand a sufficiency clause. MMTS replace the necessity clause by a requirement\nthat, as we show, implies it. Halpern's definition also allows agents to\nrestrict the set of options considered. While these difference may seem minor,\nas we show, they can have a nontrivial impact on explanations. We also show\nthat, essentially without change, Halpern's definition can handle two issues\nthat have proved difficult for other approaches: explanations of absence (when,\nfor example, an image classifier for tumors outputs \"no tumor\") and\nexplanations of rare events (such as tumors).",
      "tldr_zh": "这篇论文探讨了图像分类器的解释问题，以Mothilal et al. (2021) 的MMTS方法作为起点，指出MMTS虽声称采用Halpern [2016]的解释定义，但未完全遵循，因为它替换了必要性(necessity)条款，导致潜在的影响。作者展示了Halpern的定义，包括必要性和充分性(sufficiency)条款，能够更准确地处理解释中的代理选项限制。论文的关键发现是，Halpern的框架无需重大修改即可有效解释缺失事件（如图像分类器输出“no tumor”）和稀有事件（如肿瘤检测），从而提升解释的鲁棒性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13752v1",
      "published_date": "2024-01-24 19:12:38 UTC",
      "updated_date": "2024-01-24 19:12:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-16T23:59:59.524558"
    },
    {
      "arxiv_id": "2401.13751v2",
      "title": "A Training Rate and Survival Heuristic for Inference and Robustness Evaluation (TRASHFIRE)",
      "title_zh": "翻译失败",
      "authors": [
        "Charles Meyers",
        "Mohammad Reza Saleh Sedghpour",
        "Tommy Löfstedt",
        "Erik Elmroth"
      ],
      "abstract": "Machine learning models -- deep neural networks in particular -- have\nperformed remarkably well on benchmark datasets across a wide variety of\ndomains. However, the ease of finding adversarial counter-examples remains a\npersistent problem when training times are measured in hours or days and the\ntime needed to find a successful adversarial counter-example is measured in\nseconds. Much work has gone into generating and defending against these\nadversarial counter-examples, however the relative costs of attacks and\ndefences are rarely discussed. Additionally, machine learning research is\nalmost entirely guided by test/train metrics, but these would require billions\nof samples to meet industry standards. The present work addresses the problem\nof understanding and predicting how particular model hyper-parameters influence\nthe performance of a model in the presence of an adversary. The proposed\napproach uses survival models, worst-case examples, and a cost-aware analysis\nto precisely and accurately reject a particular model change during routine\nmodel training procedures rather than relying on real-world deployment,\nexpensive formal verification methods, or accurate simulations of very\ncomplicated systems (\\textit{e.g.}, digitally recreating every part of a car or\na plane). Through an evaluation of many pre-processing techniques, adversarial\ncounter-examples, and neural network configurations, the conclusion is that\ndeeper models do offer marginal gains in survival times compared to more\nshallow counterparts. However, we show that those gains are driven more by the\nmodel inference time than inherent robustness properties. Using the proposed\nmethodology, we show that ResNet is hopelessly insecure against even the\nsimplest of white box attacks.",
      "tldr_zh": "本研究提出TRASHFIRE框架，一种基于训练速率和生存启发式的方法，用于评估机器学习模型在对抗环境下的鲁棒性，旨在通过生存模型(survival models)、最坏情况示例(worst-case examples)和成本aware分析来预测模型超参数对性能的影响，从而在训练过程中快速拒绝无效模型变化。不同于依赖实际部署或昂贵的形式验证，该方法强调成本效率，并在各种预处理技术、对抗样本(adversarial counter-examples)和神经网络配置上进行了评估。结果显示，更深层的模型（如ResNet）仅在生存时间上获得微弱优势，主要归因于推理时间而非内在鲁棒性，且ResNet对简单白盒攻击(white box attacks)高度脆弱。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13751v2",
      "published_date": "2024-01-24 19:12:37 UTC",
      "updated_date": "2024-09-11 20:55:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:00:12.145213"
    },
    {
      "arxiv_id": "2401.13662v2",
      "title": "The Definitive Guide to Policy Gradients in Deep Reinforcement Learning: Theory, Algorithms and Implementations",
      "title_zh": "深度强化学习中策略梯度的权威指南：理论、算法和实现",
      "authors": [
        "Matthias Lehmann"
      ],
      "abstract": "In recent years, various powerful policy gradient algorithms have been\nproposed in deep reinforcement learning. While all these algorithms build on\nthe Policy Gradient Theorem, the specific design choices differ significantly\nacross algorithms. We provide a holistic overview of on-policy policy gradient\nalgorithms to facilitate the understanding of both their theoretical\nfoundations and their practical implementations. In this overview, we include a\ndetailed proof of the continuous version of the Policy Gradient Theorem,\nconvergence results and a comprehensive discussion of practical algorithms. We\ncompare the most prominent algorithms on continuous control environments and\nprovide insights on the benefits of regularization. All code is available at\nhttps://github.com/Matt00n/PolicyGradientsJax.",
      "tldr_zh": "这篇论文提供了深度强化学习中策略梯度(policy gradient)算法的全面指南，涵盖了理论基础、算法设计和实际实现。作者详细证明了Policy Gradient Theorem的连续版本，并讨论了on-policy policy gradient算法的收敛结果以及关键设计选择。通过在连续控制环境中比较主要算法，论文揭示了正则化的潜在好处，并提供开源代码（https://github.com/Matt00n/PolicyGradientsJax）以便实践应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13662v2",
      "published_date": "2024-01-24 18:56:53 UTC",
      "updated_date": "2024-03-01 08:58:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:00:24.374065"
    },
    {
      "arxiv_id": "2401.13657v2",
      "title": "Inadequacy of common stochastic neural networks for reliable clinical decision support",
      "title_zh": "常见随机神经网络在可靠临床决策支持中的不足",
      "authors": [
        "Adrian Lindenmeyer",
        "Malte Blattmann",
        "Stefan Franke",
        "Thomas Neumuth",
        "Daniel Schneider"
      ],
      "abstract": "Widespread adoption of AI for medical decision making is still hindered due\nto ethical and safety-related concerns. For AI-based decision support systems\nin healthcare settings it is paramount to be reliable and trustworthy. Common\ndeep learning approaches, however, have the tendency towards overconfidence\nunder data shift. Such inappropriate extrapolation beyond evidence-based\nscenarios may have dire consequences. This highlights the importance of\nreliable estimation of local uncertainty and its communication to the end user.\nWhile stochastic neural networks have been heralded as a potential solution to\nthese issues, this study investigates their actual reliability in clinical\napplications. We centered our analysis on the exemplary use case of mortality\nprediction for ICU hospitalizations using EHR from MIMIC3 study. For\npredictions on the EHR time series, Encoder-Only Transformer models were\nemployed. Stochasticity of model functions was achieved by incorporating common\nmethods such as Bayesian neural network layers and model ensembles. Our models\nachieve state of the art performance in terms of discrimination performance\n(AUC ROC: 0.868+-0.011, AUC PR: 0.554+-0.034) and calibration on the mortality\nprediction benchmark. However, epistemic uncertainty is critically\nunderestimated by the selected stochastic deep learning methods. A heuristic\nproof for the responsible collapse of the posterior distribution is provided.\nOur findings reveal the inadequacy of commonly used stochastic deep learning\napproaches to reliably recognize OoD samples. In both methods, unsubstantiated\nmodel confidence is not prevented due to strongly biased functional posteriors,\nrendering them inappropriate for reliable clinical decision support. This\nhighlights the need for approaches with more strictly enforced or inherent\ndistance-awareness to known data points, e.g., using kernel-based techniques.",
      "tldr_zh": "本研究揭示了常见随机神经网络（stochastic neural networks）在临床决策支持中的不足，这些方法在数据偏移（data shift）下易出现过度自信，导致不可靠的预测。研究者使用 Encoder-Only Transformer 模型、Bayesian neural network layers 和模型集成（model ensembles），在 MIMIC3 数据集上进行 ICU 住院患者死亡率预测，模型在区分性能和校准上达到最先进水平（AUC ROC: 0.868±0.011, AUC PR: 0.554±0.034）。然而，epistemic uncertainty 被严重低估，无法可靠识别 Out-of-Distribution (OoD) 样本，导致后验分布崩溃。作者强调，需要采用更严格的距离感知方法，如基于核的技巧（kernel-based techniques），以提升 AI 在医疗决策中的可靠性和可信度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Keywords: probabilistic inference, uncertainty estimation,\n  uncertainty quantification, epistemic uncertainty, clinical prognosis,\n  electronic health records",
      "pdf_url": "http://arxiv.org/pdf/2401.13657v2",
      "published_date": "2024-01-24 18:49:30 UTC",
      "updated_date": "2024-01-25 12:31:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:00:37.880163"
    },
    {
      "arxiv_id": "2401.13652v4",
      "title": "Graph-Instructed Neural Networks for Sparse Grid-Based Discontinuity Detectors",
      "title_zh": "翻译失败",
      "authors": [
        "Francesco Della Santa",
        "Sandra Pieraccini"
      ],
      "abstract": "In this paper, we present a novel approach for detecting the discontinuity\ninterfaces of a discontinuous function. This approach leverages\nGraph-Instructed Neural Networks (GINNs) and sparse grids to address\ndiscontinuity detection also in domains of dimension larger than 3. GINNs,\ntrained to identify troubled points on sparse grids, exploit graph structures\nbuilt on the grids to achieve efficient and accurate discontinuity detection\nperformances. We also introduce a recursive algorithm for general sparse\ngrid-based detectors, characterized by convergence properties and easy\napplicability. Numerical experiments on functions with dimensions n = 2 and n =\n4 demonstrate the efficiency and robust generalization properties of GINNs in\ndetecting discontinuity interfaces. Notably, the trained GINNs offer\nportability and versatility, allowing integration into various algorithms and\nsharing among users.",
      "tldr_zh": "这篇论文提出了一种新方法，利用 Graph-Instructed Neural Networks (GINNs) 和 sparse grids 来检测高维不连续函数的接口，适用于维度大于3的领域。GINNs 通过在 sparse grids 上构建图结构并训练识别问题点，实现高效准确的检测，并引入一个递归算法以确保检测器的收敛性和易用性。在 n=2 和 n=4 维函数的数值实验中，GINNs 展示了出色的效率、鲁棒泛化性能和可移植性，便于集成到各种算法中并共享。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NA",
        "math.NA",
        "68T07, 03D32, 65D40"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13652v4",
      "published_date": "2024-01-24 18:44:14 UTC",
      "updated_date": "2025-03-26 16:57:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:00:49.147919"
    },
    {
      "arxiv_id": "2401.13641v2",
      "title": "How Good is ChatGPT at Face Biometrics? A First Look into Recognition, Soft Biometrics, and Explainability",
      "title_zh": "翻译失败",
      "authors": [
        "Ivan DeAndres-Tame",
        "Ruben Tolosana",
        "Ruben Vera-Rodriguez",
        "Aythami Morales",
        "Julian Fierrez",
        "Javier Ortega-Garcia"
      ],
      "abstract": "Large Language Models (LLMs) such as GPT developed by OpenAI, have already\nshown astonishing results, introducing quick changes in our society. This has\nbeen intensified by the release of ChatGPT which allows anyone to interact in a\nsimple conversational way with LLMs, without any experience in the field\nneeded. As a result, ChatGPT has been rapidly applied to many different tasks\nsuch as code- and song-writer, education, virtual assistants, etc., showing\nimpressive results for tasks for which it was not trained (zero-shot learning).\n  The present study aims to explore the ability of ChatGPT, based on the recent\nGPT-4 multimodal LLM, for the task of face biometrics. In particular, we\nanalyze the ability of ChatGPT to perform tasks such as face verification,\nsoft-biometrics estimation, and explainability of the results. ChatGPT could be\nvery valuable to further increase the explainability and transparency of\nautomatic decisions in human scenarios. Experiments are carried out in order to\nevaluate the performance and robustness of ChatGPT, using popular public\nbenchmarks and comparing the results with state-of-the-art methods in the\nfield. The results achieved in this study show the potential of LLMs such as\nChatGPT for face biometrics, especially to enhance explainability. For\nreproducibility reasons, we release all the code in GitHub.",
      "tldr_zh": "本研究评估了ChatGPT（基于GPT-4的多模态LLM）在面部生物识别任务中的性能，具体包括face verification、soft-biometrics estimation和explainability。\n实验使用流行公共基准与最先进方法比较，结果表明ChatGPT在这些任务上表现出色，尤其能显著提升决策的可解释性和透明度。\n为促进复现，该研究已开源所有代码至GitHub。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13641v2",
      "published_date": "2024-01-24 18:10:39 UTC",
      "updated_date": "2024-02-27 11:00:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:01:02.854730"
    },
    {
      "arxiv_id": "2402.01702v1",
      "title": "Fluent dreaming for language models",
      "title_zh": "语言模型的流畅梦境生成",
      "authors": [
        "T. Ben Thompson",
        "Zygimantas Straznickas",
        "Michael Sklar"
      ],
      "abstract": "Feature visualization, also known as \"dreaming\", offers insights into vision\nmodels by optimizing the inputs to maximize a neuron's activation or other\ninternal component. However, dreaming has not been successfully applied to\nlanguage models because the input space is discrete. We extend Greedy\nCoordinate Gradient, a method from the language model adversarial attack\nliterature, to design the Evolutionary Prompt Optimization (EPO) algorithm. EPO\noptimizes the input prompt to simultaneously maximize the Pareto frontier\nbetween a chosen internal feature and prompt fluency, enabling fluent dreaming\nfor language models. We demonstrate dreaming with neurons, output logits and\narbitrary directions in activation space. We measure the fluency of the\nresulting prompts and compare language model dreaming with max-activating\ndataset examples. Critically, fluent dreaming allows automatically exploring\nthe behavior of model internals in reaction to mildly out-of-distribution\nprompts. Code for running EPO is available at\nhttps://github.com/Confirm-Solutions/dreamy. A companion page demonstrating\ncode usage is at https://confirmlabs.org/posts/dreamy.html",
      "tldr_zh": "本研究针对语言模型的离散输入空间，引入了 Evolutionary Prompt Optimization (EPO) 算法，以实现特征可视化（feature visualization），也称为“dreaming”。EPO 基于 Greedy Coordinate Gradient 方法，优化提示以最大化内部特征（如神经元激活或输出 logits）的 Pareto frontier，同时保持提示的流畅性，从而使语言模型能够进行流畅 dreaming。实验结果显示，该方法能生成高流畅度的提示，并与数据集中的最大激活示例进行比较，揭示模型对轻微分布外（out-of-distribution）提示的内部行为。总之，EPO 为探索语言模型的内部机制提供了自动化的工具，支持更深入的模型分析。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 6 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.01702v1",
      "published_date": "2024-01-24 17:57:12 UTC",
      "updated_date": "2024-01-24 17:57:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:01:13.495904"
    },
    {
      "arxiv_id": "2401.13613v1",
      "title": "Enhancing Image Retrieval : A Comprehensive Study on Photo Search using the CLIP Mode",
      "title_zh": "翻译失败",
      "authors": [
        "Naresh Kumar Lahajal",
        "Harini S"
      ],
      "abstract": "Photo search, the task of retrieving images based on textual queries, has\nwitnessed significant advancements with the introduction of CLIP (Contrastive\nLanguage-Image Pretraining) model. CLIP leverages a vision-language pre\ntraining approach, wherein it learns a shared representation space for images\nand text, enabling cross-modal understanding. This model demonstrates the\ncapability to understand the semantic relationships between diverse image and\ntext pairs, allowing for efficient and accurate retrieval of images based on\nnatural language queries. By training on a large-scale dataset containing\nimages and their associated textual descriptions, CLIP achieves remarkable\ngeneralization, providing a powerful tool for tasks such as zero-shot learning\nand few-shot classification. This abstract summarizes the foundational\nprinciples of CLIP and highlights its potential impact on advancing the field\nof photo search, fostering a seamless integration of natural language\nunderstanding and computer vision for improved information retrieval in\nmultimedia applications",
      "tldr_zh": "本研究对使用 CLIP（Contrastive Language-Image Pretraining）模型进行照片搜索进行了全面分析，旨在提升基于文本查询的图像检索性能。CLIP 通过大规模视觉-语言预训练学习图像和文本的共享表示空间，实现对语义关系的跨模态理解，从而支持高效的自然语言查询检索。实验结果显示，CLIP 在零-shot learning 和 few-shot classification 等任务中表现出色，显著提高了检索准确性和泛化能力。该方法推动了自然语言理解与计算机视觉的整合，为多媒体应用中的信息检索提供了强大工具。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13613v1",
      "published_date": "2024-01-24 17:35:38 UTC",
      "updated_date": "2024-01-24 17:35:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:01:25.934287"
    },
    {
      "arxiv_id": "2402.16871v1",
      "title": "Bike3S: A Tool for Bike Sharing Systems Simulation",
      "title_zh": "Bike3S",
      "authors": [
        "Alberto Fernández",
        "Holger Billhardt",
        "Sascha Ossowski",
        "Óscar Sánchez"
      ],
      "abstract": "Vehicle sharing systems are becoming increasingly popular. The effectiveness\nof such systems depends, among other factors, on different strategic and\noperational management decisions and policies, like the dimension of the fleet\nor the distribution of vehicles. It is of foremost importance to be able to\nanticipate and evaluate the potential effects of such strategies before they\ncan be successfully deployed. In this paper we present Bike3S, a simulator for\na station-based bike sharing system. The simulator performs semi-realistic\nsimulations of the operation of a bike sharing system and allows for evaluating\nand testing different management decisions and strategies. In particular, the\nsimulator has been designed to test different station capacities, station\ndistributions, and balancing strategies. The simulator carries out microscopic\nagent-based simulations, where users of different types can be defined that act\naccording to their individual goals and objectives which influences the overall\ndynamics of the whole system.",
      "tldr_zh": "本论文介绍了Bike3S，一种用于模拟基于站点的自行车共享系统的工具。该工具通过微观agent-based模拟，允许用户定义不同类型的使用者及其个人目标，从而模拟系统整体动态，并评估各种管理决策，如车队规模、车辆分布、车站容量和平衡策略。Bike3S有助于在实际部署前预测这些策略的效果，提高共享系统的效率和优化。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.16871v1",
      "published_date": "2024-01-24 17:33:40 UTC",
      "updated_date": "2024-01-24 17:33:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:01:36.669810"
    },
    {
      "arxiv_id": "2401.13611v1",
      "title": "Non-Intrusive Speech Intelligibility Prediction for Hearing-Impaired Users using Intermediate ASR Features and Human Memory Models",
      "title_zh": "翻译失败",
      "authors": [
        "Rhiannon Mogridge",
        "George Close",
        "Robert Sutherland",
        "Thomas Hain",
        "Jon Barker",
        "Stefan Goetze",
        "Anton Ragni"
      ],
      "abstract": "Neural networks have been successfully used for non-intrusive speech\nintelligibility prediction. Recently, the use of feature representations\nsourced from intermediate layers of pre-trained self-supervised and\nweakly-supervised models has been found to be particularly useful for this\ntask. This work combines the use of Whisper ASR decoder layer representations\nas neural network input features with an exemplar-based, psychologically\nmotivated model of human memory to predict human intelligibility ratings for\nhearing-aid users. Substantial performance improvement over an established\nintrusive HASPI baseline system is found, including on enhancement systems and\nlisteners unseen in the training data, with a root mean squared error of 25.3\ncompared with the baseline of 28.7.",
      "tldr_zh": "这篇论文提出了一种非侵入式方法，使用Whisper ASR解码器层中间特征与基于人类记忆的示例模型，预测听力障碍用户的语音可懂度评分。该方法结合神经网络和心理激励模型，旨在提升预测准确性。实验结果显示，与传统的intrusive HASPI基线系统相比，该方法在增强系统和训练数据中未见的听众上表现更优，根均方误差从28.7降低到25.3。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted paper. IEEE International Conference on Acoustics Speech and\n  Signal Processing (ICASSP), Seoul, Korea, April 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13611v1",
      "published_date": "2024-01-24 17:31:07 UTC",
      "updated_date": "2024-01-24 17:31:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:01:50.369622"
    },
    {
      "arxiv_id": "2401.13604v1",
      "title": "Stream-based perception for cognitive agents in mobile ecosystems",
      "title_zh": "翻译失败",
      "authors": [
        "Jeremias Dötterl",
        "Ralf Bruns",
        "Jürgen Dunkel",
        "Sascha Ossowski"
      ],
      "abstract": "Cognitive agent abstractions can help to engineer intelligent systems across\nmobile devices. On smartphones, the data obtained from onboard sensors can give\nvaluable insights into the user's current situation. Unfortunately, today's\ncognitive agent frameworks cannot cope well with the challenging\ncharacteristics of sensor data. Sensor data is located on a low abstraction\nlevel and the individual data elements are not meaningful when observed in\nisolation. In contrast, cognitive agents operate on high-level percepts and\nlack the means to effectively detect complex spatio-temporal patterns in\nsequences of multiple percepts. In this paper, we present a stream-based\nperception approach that enables the agents to perceive meaningful situations\nin low-level sensor data streams. We present a crowdshipping case study where\nautonomous, self-interested agents collaborate to deliver parcels to their\ndestinations. We show how situations derived from smartphone sensor data can\ntrigger and guide auctions, which the agents use to reach agreements.\nExperiments with real smartphone data demonstrate the benefits of stream-based\nagent perception.",
      "tldr_zh": "本论文探讨了认知代理（cognitive agents）在移动生态系统中的应用，强调智能手机传感器数据在感知用户情况方面的潜力，但现有框架难以处理低抽象级别的数据和孤立数据元素。论文提出了一种基于流的感知方法（stream-based perception），允许代理从传感器数据流中检测复杂时空模式，从而生成高水平感知（high-level percepts）。通过一个众包运输（crowdshipping）案例研究，代理利用传感器数据触发的拍卖机制实现自治合作和包裹交付。实验使用真实智能手机数据证明，该方法显著提升了代理的感知能力和协作效率。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13604v1",
      "published_date": "2024-01-24 17:14:50 UTC",
      "updated_date": "2024-01-24 17:14:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:02:01.209836"
    },
    {
      "arxiv_id": "2401.13594v1",
      "title": "Graph Guided Question Answer Generation for Procedural Question-Answering",
      "title_zh": "基于图指导的问题答案生成，用于程序性问答",
      "authors": [
        "Hai X. Pham",
        "Isma Hadji",
        "Xinnuo Xu",
        "Ziedune Degutyte",
        "Jay Rainey",
        "Evangelos Kazakos",
        "Afsaneh Fazly",
        "Georgios Tzimiropoulos",
        "Brais Martinez"
      ],
      "abstract": "In this paper, we focus on task-specific question answering (QA). To this\nend, we introduce a method for generating exhaustive and high-quality training\ndata, which allows us to train compact (e.g., run on a mobile device),\ntask-specific QA models that are competitive against GPT variants. The key\ntechnological enabler is a novel mechanism for automatic question-answer\ngeneration from procedural text which can ingest large amounts of textual\ninstructions and produce exhaustive in-domain QA training data. While current\nQA data generation methods can produce well-formed and varied data, their\nnon-exhaustive nature is sub-optimal for training a QA model. In contrast, we\nleverage the highly structured aspect of procedural text and represent each\nstep and the overall flow of the procedure as graphs. We then condition on\ngraph nodes to automatically generate QA pairs in an exhaustive and\ncontrollable manner. Comprehensive evaluations of our method show that: 1)\nsmall models trained with our data achieve excellent performance on the target\nQA task, even exceeding that of GPT3 and ChatGPT despite being several orders\nof magnitude smaller. 2) semantic coverage is the key indicator for downstream\nQA performance. Crucially, while large language models excel at syntactic\ndiversity, this does not necessarily result in improvements on the end QA\nmodel. In contrast, the higher semantic coverage provided by our method is\ncritical for QA performance.",
      "tldr_zh": "本论文提出了一种基于图指导的问答 (QA) 生成方法，针对程序性文本自动生成详尽、高质量的训练数据，以训练紧凑的任务特定 QA 模型，这些模型可在移动设备上运行并与 GPT 变体竞争。方法通过将程序性文本的步骤和整体流程表示为 graphs，然后基于图节点生成全面可控的 QA 对，解决了现有方法非详尽性的问题。实验结果显示，使用该数据训练的小模型在目标 QA 任务上表现卓越，甚至超过 GPT3 和 ChatGPT，尽管后者规模大几个数量级；此外，语义覆盖率是下游 QA 性能的关键，而非句法多样性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to EACL 2024 as long paper. 25 pages including appendix",
      "pdf_url": "http://arxiv.org/pdf/2401.13594v1",
      "published_date": "2024-01-24 17:01:42 UTC",
      "updated_date": "2024-01-24 17:01:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:02:15.478008"
    },
    {
      "arxiv_id": "2401.13588v1",
      "title": "Evaluation of General Large Language Models in Contextually Assessing Semantic Concepts Extracted from Adult Critical Care Electronic Health Record Notes",
      "title_zh": "翻译失败",
      "authors": [
        "Darren Liu",
        "Cheng Ding",
        "Delgersuren Bold",
        "Monique Bouvier",
        "Jiaying Lu",
        "Benjamin Shickel",
        "Craig S. Jabaley",
        "Wenhui Zhang",
        "Soojin Park",
        "Michael J. Young",
        "Mark S. Wainwright",
        "Gilles Clermont",
        "Parisa Rashidi",
        "Eric S. Rosenthal",
        "Laurie Dimisko",
        "Ran Xiao",
        "Joo Heung Yoon",
        "Carl Yang",
        "Xiao Hu"
      ],
      "abstract": "The field of healthcare has increasingly turned its focus towards Large\nLanguage Models (LLMs) due to their remarkable performance. However, their\nperformance in actual clinical applications has been underexplored. Traditional\nevaluations based on question-answering tasks don't fully capture the nuanced\ncontexts. This gap highlights the need for more in-depth and practical\nassessments of LLMs in real-world healthcare settings. Objective: We sought to\nevaluate the performance of LLMs in the complex clinical context of adult\ncritical care medicine using systematic and comprehensible analytic methods,\nincluding clinician annotation and adjudication. Methods: We investigated the\nperformance of three general LLMs in understanding and processing real-world\nclinical notes. Concepts from 150 clinical notes were identified by MetaMap and\nthen labeled by 9 clinicians. Each LLM's proficiency was evaluated by\nidentifying the temporality and negation of these concepts using different\nprompts for an in-depth analysis. Results: GPT-4 showed overall superior\nperformance compared to other LLMs. In contrast, both GPT-3.5 and\ntext-davinci-003 exhibit enhanced performance when the appropriate prompting\nstrategies are employed. The GPT family models have demonstrated considerable\nefficiency, evidenced by their cost-effectiveness and time-saving capabilities.\nConclusion: A comprehensive qualitative performance evaluation framework for\nLLMs is developed and operationalized. This framework goes beyond singular\nperformance aspects. With expert annotations, this methodology not only\nvalidates LLMs' capabilities in processing complex medical data but also\nestablishes a benchmark for future LLM evaluations across specialized domains.",
      "tldr_zh": "这篇论文评估了通用 Large Language Models (LLMs) 在处理成人重症监护电子健康记录笔记中提取的语义概念时的性能，重点关注上下文中的时态（temporality）和否定（negation）。研究方法包括使用 MetaMap 从 150 份临床笔记中提取概念，并由 9 名临床医生进行标注和评估，以系统化方式测试三个 LLMs（包括 GPT-4、GPT-3.5 和 text-davinci-003）的表现。结果表明，GPT-4 整体表现最佳，而其他模型通过优化提示策略可显著提升效率；该研究还开发了一个全面的定性评估框架，作为未来 LLMs 在医疗领域评估的基准。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13588v1",
      "published_date": "2024-01-24 16:52:37 UTC",
      "updated_date": "2024-01-24 16:52:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:02:27.665910"
    },
    {
      "arxiv_id": "2401.13586v4",
      "title": "Instruction Fine-Tuning: Does Prompt Loss Matter?",
      "title_zh": "翻译失败",
      "authors": [
        "Mathew Huerta-Enochian",
        "Seung Yong Ko"
      ],
      "abstract": "We present a novel study analyzing the effects of various prompt loss token\nweights (PLW) for supervised instruction fine-tuning (SIFT). While\nprompt-masking (PLW = 0) is common for SIFT, some fine-tuning APIs support\nfractional PLWs and suggest that using a small non-zero PLW can help stabilize\nlearning when fine-tuning on short-completion data. However, there has never\nbeen a study confirming this claim, and OpenAI, a major cloud-based SIFT\nprovider, recently removed this parameter from their fine-tuning API. We found\nthat performance of models fine-tuned on short-completion data had a\nstatistically-significant negative quadratic relationship with PLW. Using small\nvalues (0.01 - 0.5) of PLW produced better results on multiple-choice and\nshort-generation benchmarks (outperforming models fine-tuned on long-completion\ndata) while large values (~ 1.0) of PLW produced better results on\nlong-generation benchmarks. We explained this effect and verified its\nimportance through additional experiments. This research serves as a warning to\nAPI providers about the importance of providing a PLW parameter for SIFT.",
      "tldr_zh": "该研究探讨了在监督指令微调（Supervised Instruction Fine-Tuning, SIFT）中，prompt loss token weights (PLW) 是否影响模型性能。实验发现，PLW 与性能呈负二次关系：使用小值 PLW（0.01-0.5）能在多选和短生成基准上取得更好结果，甚至优于长完成数据微调的模型，而大值 PLW（约1.0）则更适合长生成任务。通过额外实验验证了这一效应，并警告 API 提供者应保留 PLW 参数以优化微调过程。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "EMNLP 2024: Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2401.13586v4",
      "published_date": "2024-01-24 16:51:23 UTC",
      "updated_date": "2024-10-14 01:16:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:02:37.644243"
    },
    {
      "arxiv_id": "2401.13555v3",
      "title": "Benchmarking the Fairness of Image Upsampling Methods",
      "title_zh": "图像上采样方法的公平性基准测试",
      "authors": [
        "Mike Laszkiewicz",
        "Imant Daunhawer",
        "Julia E. Vogt",
        "Asja Fischer",
        "Johannes Lederer"
      ],
      "abstract": "Recent years have witnessed a rapid development of deep generative models for\ncreating synthetic media, such as images and videos. While the practical\napplications of these models in everyday tasks are enticing, it is crucial to\nassess the inherent risks regarding their fairness. In this work, we introduce\na comprehensive framework for benchmarking the performance and fairness of\nconditional generative models. We develop a set of\nmetrics$\\unicode{x2013}$inspired by their supervised fairness\ncounterparts$\\unicode{x2013}$to evaluate the models on their fairness and\ndiversity. Focusing on the specific application of image upsampling, we create\na benchmark covering a wide variety of modern upsampling methods. As part of\nthe benchmark, we introduce UnfairFace, a subset of FairFace that replicates\nthe racial distribution of common large-scale face datasets. Our empirical\nstudy highlights the importance of using an unbiased training set and reveals\nvariations in how the algorithms respond to dataset imbalances. Alarmingly, we\nfind that none of the considered methods produces statistically fair and\ndiverse results. All experiments can be reproduced using our provided\nrepository.",
      "tldr_zh": "本研究引入了一个全面框架，用于基准测试条件生成模型的性能和公平性，特别针对图像上采样（image upsampling）方法。研究者开发了受监督公平性启发的指标，以评估模型的公平性（fairness）和多样性，并创建了一个涵盖多种现代上采样方法的基准数据集。论文还推出了UnfairFace数据集，这是一个基于FairFace的子集，模拟了常见大规模人脸数据集的种族分布。实证结果强调了使用无偏训练集的重要性，并揭示了不同算法对数据集不平衡的响应差异，但令人警醒的是，没有任何方法能产生统计上公平和多样的输出。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "This is the author's version of the work. It is posted here for your\n  personal use. Not for redistribution. The definitive Version of Record was\n  published at the 2024 ACM Conference on Fairness, Accountability, and\n  Transparency (FAccT '24)",
      "pdf_url": "http://arxiv.org/pdf/2401.13555v3",
      "published_date": "2024-01-24 16:13:26 UTC",
      "updated_date": "2024-04-29 12:39:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:02:50.989577"
    },
    {
      "arxiv_id": "2402.09430v2",
      "title": "WiMANS: A Benchmark Dataset for WiFi-based Multi-user Activity Sensing",
      "title_zh": "翻译失败",
      "authors": [
        "Shuokang Huang",
        "Kaihan Li",
        "Di You",
        "Yichong Chen",
        "Arvin Lin",
        "Siying Liu",
        "Xiaohui Li",
        "Julie A. McCann"
      ],
      "abstract": "WiFi-based human sensing has exhibited remarkable potential to analyze user\nbehaviors in a non-intrusive and device-free manner, benefiting applications as\ndiverse as smart homes and healthcare. However, most previous works focus on\nsingle-user sensing, which has limited practicability in scenarios involving\nmultiple users. Although recent studies have begun to investigate WiFi-based\nmulti-user sensing, there remains a lack of benchmark datasets to facilitate\nreproducible and comparable research. To bridge this gap, we present WiMANS, to\nour knowledge, the first dataset for multi-user sensing based on WiFi. WiMANS\ncontains over 9.4 hours of dual-band WiFi Channel State Information (CSI), as\nwell as synchronized videos, monitoring simultaneous activities of multiple\nusers. We exploit WiMANS to benchmark the performance of state-of-the-art\nWiFi-based human sensing models and video-based models, posing new challenges\nand opportunities for future work. We believe WiMANS can push the boundaries of\ncurrent studies and catalyze the research on WiFi-based multi-user sensing.",
      "tldr_zh": "该论文介绍了WiMANS，这是一个针对WiFi-based多用户活动感知的首个基准数据集，旨在解决现有研究偏重单用户感知的局限性。WiMANS包含超过9.4小时的双频WiFi Channel State Information (CSI)数据以及同步视频，用于监控多个用户的活动。研究者利用WiMANS对现有WiFi-based和视频-based人类感知模型进行了性能基准测试，揭示了新挑战，并推动了WiFi-based多用户感知领域的未来发展。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "eess.SP",
      "comment": "We present WiMANS, to our knowledge, the first dataset for multi-user\n  activity sensing based on WiFi",
      "pdf_url": "http://arxiv.org/pdf/2402.09430v2",
      "published_date": "2024-01-24 16:10:14 UTC",
      "updated_date": "2024-03-12 11:48:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:03:02.899796"
    },
    {
      "arxiv_id": "2402.00048v1",
      "title": "IICONGRAPH: improved Iconographic and Iconological Statements in Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Bruno Sartini"
      ],
      "abstract": "Iconography and iconology are fundamental domains when it comes to\nunderstanding artifacts of cultural heritage. Iconography deals with the study\nand interpretation of visual elements depicted in artifacts and their\nsymbolism, while iconology delves deeper, exploring the underlying cultural and\nhistorical meanings. Despite the advances in representing cultural heritage\nwith Linked Open Data (LOD), recent studies show persistent gaps in the\nrepresentation of iconographic and iconological statements in current knowledge\ngraphs (KGs). To address them, this paper presents IICONGRAPH, a KG that was\ncreated by refining and extending the iconographic and iconological statements\nof ArCo (the Italian KG of cultural heritage) and Wikidata. The development of\nIICONGRAPH was also driven by a series of requirements emerging from research\ncase studies that were unattainable in the non-reengineered versions of the\nKGs. The evaluation results demonstrate that IICONGRAPH not only outperforms\nArCo and Wikidata through domain-specific assessments from the literature but\nalso serves as a robust platform for addressing the formulated research\nquestions. IICONGRAPH is released and documented in accordance with the FAIR\nprinciples to guarantee the resource's reusability. The algorithms used to\ncreate it and assess the research questions have also been made available to\nensure transparency and reproducibility. While future work focuses on ingesting\nmore data into the KG, and on implementing it as a backbone of LLM-based\nquestion answering systems, the current version of IICONGRAPH still emerges as\na valuable asset, contributing to the evolving landscape of cultural heritage\nrepresentation within Knowledge Graphs, the Semantic Web, and beyond.",
      "tldr_zh": "本论文介绍了 IICONGRAPH，一种改进后的知识图谱 (Knowledge Graphs)，旨在提升对文化遗产中 Iconography 和 Iconology 语句的表示。Iconography 涉及视觉元素的描绘和象征意义，而 Iconology 则探讨其深层文化与历史内涵；为此，IICONGRAPH 通过精炼和扩展 ArCo 和 Wikidata 中的相关语句，满足了实际研究案例的需求。评估结果显示，IICONGRAPH 在领域特定评估中优于现有知识图谱，并能有效回答研究问题；该图谱已按照 FAIR 原则发布，并公开算法以确保透明性和可重复性，为文化遗产表示和 Semantic Web 领域提供宝贵资源。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "18 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.00048v1",
      "published_date": "2024-01-24 15:44:16 UTC",
      "updated_date": "2024-01-24 15:44:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:03:16.276941"
    },
    {
      "arxiv_id": "2401.13722v1",
      "title": "Proactive Emotion Tracker: AI-Driven Continuous Mood and Emotion Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Asif",
        "Sudhakar Mishra",
        "Ankush Sonker",
        "Sanidhya Gupta",
        "Somesh Kumar Maurya",
        "Uma Shanker Tiwary"
      ],
      "abstract": "This research project aims to tackle the growing mental health challenges in\ntoday's digital age. It employs a modified pre-trained BERT model to detect\ndepressive text within social media and users' web browsing data, achieving an\nimpressive 93% test accuracy. Simultaneously, the project aims to incorporate\nphysiological signals from wearable devices, such as smartwatches and EEG\nsensors, to provide long-term tracking and prognosis of mood disorders and\nemotional states. This comprehensive approach holds promise for enhancing early\ndetection of depression and advancing overall mental health outcomes.",
      "tldr_zh": "本研究开发了Proactive Emotion Tracker，一种AI驱动的系统，用于持续监测情绪和心理状态，以应对数字时代的精神健康挑战。该系统采用修改后的预训练BERT模型分析社交媒体和网络浏览数据中的抑郁文本，实现93%的测试准确率；同时整合可穿戴设备（如smartwatches和EEG sensors）的生理信号，进行长期情绪障碍跟踪和预测。这种综合方法有望提升抑郁的早期检测，并改善整体心理健康结果。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13722v1",
      "published_date": "2024-01-24 15:05:11 UTC",
      "updated_date": "2024-01-24 15:05:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:03:26.073927"
    },
    {
      "arxiv_id": "2401.13498v1",
      "title": "Expressive Acoustic Guitar Sound Synthesis with an Instrument-Specific Input Representation and Diffusion Outpainting",
      "title_zh": "翻译失败",
      "authors": [
        "Hounsu Kim",
        "Soonbeom Choi",
        "Juhan Nam"
      ],
      "abstract": "Synthesizing performing guitar sound is a highly challenging task due to the\npolyphony and high variability in expression. Recently, deep generative models\nhave shown promising results in synthesizing expressive polyphonic instrument\nsounds from music scores, often using a generic MIDI input. In this work, we\npropose an expressive acoustic guitar sound synthesis model with a customized\ninput representation to the instrument, which we call guitarroll. We implement\nthe proposed approach using diffusion-based outpainting which can generate\naudio with long-term consistency. To overcome the lack of MIDI/audio-paired\ndatasets, we used not only an existing guitar dataset but also collected data\nfrom a high quality sample-based guitar synthesizer. Through quantitative and\nqualitative evaluations, we show that our proposed model has higher audio\nquality than the baseline model and generates more realistic timbre sounds than\nthe previous leading work.",
      "tldr_zh": "这篇论文针对声学吉他的多音(polyphony)和高变异性声音合成挑战，提出了一种新模型，使用自定义输入表示guitarroll和基于diffusion的outpainting方法，以从音乐分数生成更具表现力的音频。模型通过整合现有吉他数据集和高品质样本-based合成器收集的数据，解决了MIDI/音频配对数据集的不足。实验评估显示，该模型比基线模型音频质量更高，并生成比先前领先工作更真实的音色。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS",
        "eess.SP"
      ],
      "primary_category": "cs.SD",
      "comment": "Accepted to ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13498v1",
      "published_date": "2024-01-24 14:44:01 UTC",
      "updated_date": "2024-01-24 14:44:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:03:39.663214"
    },
    {
      "arxiv_id": "2401.13486v1",
      "title": "Separable Physics-Informed Neural Networks for the solution of elasticity problems",
      "title_zh": "可分离的物理信息神经网络用于弹性问题的求解",
      "authors": [
        "Vasiliy A. Es'kin",
        "Danil V. Davydov",
        "Julia V. Gur'eva",
        "Alexey O. Malkhanov",
        "Mikhail E. Smorkalov"
      ],
      "abstract": "A method for solving elasticity problems based on separable physics-informed\nneural networks (SPINN) in conjunction with the deep energy method (DEM) is\npresented. Numerical experiments have been carried out for a number of problems\nshowing that this method has a significantly higher convergence rate and\naccuracy than the vanilla physics-informed neural networks (PINN) and even\nSPINN based on a system of partial differential equations (PDEs). In addition,\nusing the SPINN in the framework of DEM approach it is possible to solve\nproblems of the linear theory of elasticity on complex geometries, which is\nunachievable with the help of PINNs in frames of partial differential\nequations. Considered problems are very close to the industrial problems in\nterms of geometry, loading, and material parameters.",
      "tldr_zh": "本论文提出了一种基于 Separable Physics-Informed Neural Networks (SPINN) 与 Deep Energy Method (DEM) 相结合的方法，用于解决弹性问题。该方法在数值实验中显示出比传统的 Physics-Informed Neural Networks (PINN) 更高的收敛率和准确性，甚至优于基于 partial differential equations (PDEs) 的 SPINN 变体。此外，SPINN 在 DEM 框架下能够处理复杂几何形状的线性弹性问题，这在基于 PDEs 的 PINN 中无法实现，而这些实验问题在几何、加载和材料参数方面接近工业实际。",
      "categories": [
        "math.NA",
        "cs.AI",
        "cs.LG",
        "cs.NA",
        "physics.app-ph",
        "68T07, 65Z05, 65M99",
        "I.2.1; I.2.7; J.2"
      ],
      "primary_category": "math.NA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13486v1",
      "published_date": "2024-01-24 14:34:59 UTC",
      "updated_date": "2024-01-24 14:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:03:53.154766"
    },
    {
      "arxiv_id": "2401.13481v2",
      "title": "How AI Ideas Affect the Creativity, Diversity, and Evolution of Human Ideas: Evidence From a Large, Dynamic Experiment",
      "title_zh": "翻译失败",
      "authors": [
        "Joshua Ashkinaze",
        "Julia Mendelsohn",
        "Li Qiwei",
        "Ceren Budak",
        "Eric Gilbert"
      ],
      "abstract": "Exposure to large language model output is rapidly increasing. How will\nseeing AI-generated ideas affect human ideas? We conducted an experiment (800+\nparticipants, 40+ countries) where participants viewed creative ideas that were\nfrom ChatGPT or prior experimental participants and then brainstormed their own\nidea. We varied the number of AI-generated examples (none, low, or high\nexposure) and if the examples were labeled as 'AI' (disclosure). Our dynamic\nexperiment design -- ideas from prior participants in an experimental condition\nare used as stimuli for future participants in the same experimental condition\n-- speaks to the interdependent process of cultural creation: creative ideas\nare built upon prior ideas. Hence, we capture the compounding effects of having\nLLMs 'in the culture loop'. We find that high AI exposure (but not low AI\nexposure) did not affect the creativity of individual ideas but did increase\nthe average amount and rate of change of collective idea diversity. AI made\nideas different, not better. There were no main effects of disclosure. We also\nfound that self-reported creative people were less influenced by knowing an\nidea was from AI and that participants may knowingly adopt AI ideas when the\ntask is difficult. Our findings suggest that introducing AI ideas may increase\ncollective diversity but not individual creativity.",
      "tldr_zh": "本研究通过一个大规模动态实验（涉及800+参与者、40+国家）探讨了AI生成想法对人类想法的创造力、多样性和演变的影响。实验设计让参与者查看不同数量的ChatGPT或人类生成想法（无、低或高暴露），并在部分条件下标记为“AI”，以模拟文化创造的相互依赖过程。结果显示，高AI暴露增加了集体想法的多样性和变化率，但不影响个体想法的创造力；AI使想法变得不同而非更好，且披露标签没有主要效果。自称有创造力的人较少受AI影响，而在任务困难时，参与者可能主动采用AI想法。总体而言，该研究表明引入AI想法可能提升集体多样性，但不提升个体创造力。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL",
        "cs.HC"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13481v2",
      "published_date": "2024-01-24 14:29:39 UTC",
      "updated_date": "2024-07-04 17:14:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:04:07.393022"
    },
    {
      "arxiv_id": "2401.13462v1",
      "title": "Growing from Exploration: A self-exploring framework for robots based on foundation models",
      "title_zh": "从探索中成长：基于基础模型的机器人自探索框架",
      "authors": [
        "Shoujie Li",
        "Ran Yu",
        "Tong Wu",
        "JunWen Zhong",
        "Xiao-Ping Zhang",
        "Wenbo Ding"
      ],
      "abstract": "Intelligent robot is the ultimate goal in the robotics field. Existing works\nleverage learning-based or optimization-based methods to accomplish\nhuman-defined tasks. However, the challenge of enabling robots to explore\nvarious environments autonomously remains unresolved. In this work, we propose\na framework named GExp, which enables robots to explore and learn autonomously\nwithout human intervention. To achieve this goal, we devise modules including\nself-exploration, knowledge-base-building, and close-loop feedback based on\nfoundation models. Inspired by the way that infants interact with the world,\nGExp encourages robots to understand and explore the environment with a series\nof self-generated tasks. During the process of exploration, the robot will\nacquire skills from beneficial experiences that are useful in the future. GExp\nprovides robots with the ability to solve complex tasks through\nself-exploration. GExp work is independent of prior interactive knowledge and\nhuman intervention, allowing it to adapt directly to different scenarios,\nunlike previous studies that provided in-context examples as few-shot learning.\nIn addition, we propose a workflow of deploying the real-world robot system\nwith self-learned skills as an embodied assistant.",
      "tldr_zh": "本文提出 GExp 框架，利用 foundation models 让机器人实现自主探索和学习，无需人类干预。框架包括 self-exploration、knowledge-base-building 和 close-loop feedback 模块，机器人通过生成一系列自我任务（如婴儿互动方式）来理解环境，并在探索过程中从有益经验中获取技能，以解决复杂任务。相比传统方法，GExp 不依赖 prior interactive knowledge 或 in-context examples 作为 few-shot learning，能直接适应不同场景，并提供部署真实世界机器人系统作为 embodied assistant 的工作流程。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.13462v1",
      "published_date": "2024-01-24 14:04:08 UTC",
      "updated_date": "2024-01-24 14:04:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:04:16.916625"
    },
    {
      "arxiv_id": "2401.13460v3",
      "title": "Multi-Agent Diagnostics for Robustness via Illuminated Diversity",
      "title_zh": "翻译失败",
      "authors": [
        "Mikayel Samvelyan",
        "Davide Paglieri",
        "Minqi Jiang",
        "Jack Parker-Holder",
        "Tim Rocktäschel"
      ],
      "abstract": "In the rapidly advancing field of multi-agent systems, ensuring robustness in\nunfamiliar and adversarial settings is crucial. Notwithstanding their\noutstanding performance in familiar environments, these systems often falter in\nnew situations due to overfitting during the training phase. This is especially\npronounced in settings where both cooperative and competitive behaviours are\npresent, encapsulating a dual nature of overfitting and generalisation\nchallenges. To address this issue, we present Multi-Agent Diagnostics for\nRobustness via Illuminated Diversity (MADRID), a novel approach for generating\ndiverse adversarial scenarios that expose strategic vulnerabilities in\npre-trained multi-agent policies. Leveraging the concepts from open-ended\nlearning, MADRID navigates the vast space of adversarial settings, employing a\ntarget policy's regret to gauge the vulnerabilities of these settings. We\nevaluate the effectiveness of MADRID on the 11vs11 version of Google Research\nFootball, one of the most complex environments for multi-agent reinforcement\nlearning. Specifically, we employ MADRID for generating a diverse array of\nadversarial settings for TiZero, the state-of-the-art approach which \"masters\"\nthe game through 45 days of training on a large-scale distributed\ninfrastructure. We expose key shortcomings in TiZero's tactical\ndecision-making, underlining the crucial importance of rigorous evaluation in\nmulti-agent systems.",
      "tldr_zh": "在多智能体系统中，确保鲁棒性尤为重要，因为这些系统在熟悉环境中表现出色，但在陌生或对抗环境中往往因训练过拟合而失败。为解决这一问题，本文提出 MADRID（Multi-Agent Diagnostics for Robustness via Illuminated Diversity），一种基于开放式学习生成多样化对抗场景的方法，利用目标策略的 regret 来评估并暴露策略漏洞。在 Google Research Football 的 11vs11 环境中，MADRID 成功揭示了先进策略 TiZero 在战术决策中的关键短板，强调了多智能体系统进行严格评估的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13460v3",
      "published_date": "2024-01-24 14:02:09 UTC",
      "updated_date": "2024-11-03 21:13:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:04:29.789859"
    },
    {
      "arxiv_id": "2402.01700v1",
      "title": "Question answering systems for health professionals at the point of care -- a systematic review",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Kell",
        "Angus Roberts",
        "Serge Umansky",
        "Linglong Qian",
        "Davide Ferrari",
        "Frank Soboczenski",
        "Byron Wallace",
        "Nikhil Patel",
        "Iain J Marshall"
      ],
      "abstract": "Objective: Question answering (QA) systems have the potential to improve the\nquality of clinical care by providing health professionals with the latest and\nmost relevant evidence. However, QA systems have not been widely adopted. This\nsystematic review aims to characterize current medical QA systems, assess their\nsuitability for healthcare, and identify areas of improvement.\n  Materials and methods: We searched PubMed, IEEE Xplore, ACM Digital Library,\nACL Anthology and forward and backward citations on 7th February 2023. We\nincluded peer-reviewed journal and conference papers describing the design and\nevaluation of biomedical QA systems. Two reviewers screened titles, abstracts,\nand full-text articles. We conducted a narrative synthesis and risk of bias\nassessment for each study. We assessed the utility of biomedical QA systems.\n  Results: We included 79 studies and identified themes, including question\nrealism, answer reliability, answer utility, clinical specialism, systems,\nusability, and evaluation methods. Clinicians' questions used to train and\nevaluate QA systems were restricted to certain sources, types and complexity\nlevels. No system communicated confidence levels in the answers or sources.\nMany studies suffered from high risks of bias and applicability concerns. Only\n8 studies completely satisfied any criterion for clinical utility, and only 7\nreported user evaluations. Most systems were built with limited input from\nclinicians.\n  Discussion: While machine learning methods have led to increased accuracy,\nmost studies imperfectly reflected real-world healthcare information needs. Key\nresearch priorities include developing more realistic healthcare QA datasets\nand considering the reliability of answer sources, rather than merely focusing\non accuracy.",
      "tldr_zh": "这篇系统回顾评估了问答(QA)系统在医疗点护理中的应用，旨在描述当前系统的特征、适合性，并识别改进领域。通过搜索多个数据库并分析79篇同行评议研究，作者发现这些系统在问题真实性、答案可靠性和实用性方面存在缺陷，例如临床问题受限于来源和复杂度，且多数系统未传达答案置信度或缺乏临床输入。结果显示，只有8个系统完全满足临床实用性标准，且仅有7个研究进行了用户评估。尽管机器学习提高了准确性，但研究强调未来应优先开发更真实的医疗QA数据集，并关注答案来源的可靠性而非仅追求准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the Journal of the American Medical Informatics\n  Association (JAMIA)",
      "pdf_url": "http://arxiv.org/pdf/2402.01700v1",
      "published_date": "2024-01-24 13:47:39 UTC",
      "updated_date": "2024-01-24 13:47:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:04:41.035904"
    },
    {
      "arxiv_id": "2401.13444v3",
      "title": "Fine-Grained Stateful Knowledge Exploration: A Novel Paradigm for Integrating Knowledge Graphs with Large Language Models",
      "title_zh": "细粒度有状态知识探索：一种集成知识图谱与大型语言模型的新范式",
      "authors": [
        "Dehao Tao",
        "Congqi Wang",
        "Feng Huang",
        "Junhao Chen",
        "Yongfeng Huang",
        "Minghu Jiang"
      ],
      "abstract": "Large Language Models (LLMs) have shown impressive capabilities, yet updating\ntheir knowledge remains a significant challenge, often leading to outdated or\ninaccurate responses. A proposed solution is the integration of external\nknowledge bases, such as knowledge graphs, with LLMs. Most existing methods use\na paradigm that treats the question as the objective, with relevant knowledge\nbeing incrementally retrieved from the knowledge graph. However, this strategy\nfrequently experiences an mismatch in the granularity of knowledge between the\ntarget question and the entities and relations being retrieved. As a result,\nthe information in the question cannot precisely correspond to the retrieved\nknowledge. This may cause redundant exploration or omission of vital knowledge,\nthereby leading to enhanced computational consumption and reduced retrieval\naccuracy. In this paper, we propose a novel paradigm of fine-grained stateful\nknowledge exploration, which addresses the `information granularity mismatch'\nissue. We extract fine-grained information from questions and explore the\nsemantic mapping between this information and the knowledge in graph. By\ndynamically updating the mapping records, we avoid redundant exploration and\nensure no pertinent information is overlooked, thereby reducing computational\noverhead and improving the accuracy of knowledge exploration. The use of\nfine-grained information also eliminates the need for a priori knowledge, a\ncommon requirement in existing methods. Experiments on multiple datasets\nrevealed that our paradigm surpasses current advanced methods in knowledge\nretrieval while significantly reducing the average number of LLM invocations.",
      "tldr_zh": "这篇论文提出了一种新范式，名为Fine-Grained Stateful Knowledge Exploration，用于整合知识图谱与Large Language Models (LLMs)，以解决现有方法中知识粒度不匹配问题导致的冗余探索和信息遗漏。方法包括从问题中提取细粒度信息、动态探索其与知识图谱中知识的语义映射，并通过更新映射记录来减少计算开销，同时无需先验知识。实验在多个数据集上表明，该范式在知识检索准确性上超越了先进方法，并显著降低了LLM调用次数。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13444v3",
      "published_date": "2024-01-24 13:36:50 UTC",
      "updated_date": "2025-01-27 09:39:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:04:51.763073"
    },
    {
      "arxiv_id": "2401.13432v2",
      "title": "Semi-Supervised Coupled Thin-Plate Spline Model for Rotation Correction and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Lang Nie",
        "Chunyu Lin",
        "Kang Liao",
        "Shuaicheng Liu",
        "Yao Zhao"
      ],
      "abstract": "Thin-plate spline (TPS) is a principal warp that allows for representing\nelastic, nonlinear transformation with control point motions. With the increase\nof control points, the warp becomes increasingly flexible but usually\nencounters a bottleneck caused by undesired issues, e.g., content distortion.\nIn this paper, we explore generic applications of TPS in single-image-based\nwarping tasks, such as rotation correction, rectangling, and portrait\ncorrection. To break this bottleneck, we propose the coupled thin-plate spline\nmodel (CoupledTPS), which iteratively couples multiple TPS with limited control\npoints into a more flexible and powerful transformation. Concretely, we first\ndesign an iterative search to predict new control points according to the\ncurrent latent condition. Then, we present the warping flow as a bridge for the\ncoupling of different TPS transformations, effectively eliminating\ninterpolation errors caused by multiple warps. Besides, in light of the\nlaborious annotation cost, we develop a semi-supervised learning scheme to\nimprove warping quality by exploiting unlabeled data. It is formulated through\ndual transformation between the searched control points of unlabeled data and\nits graphic augmentation, yielding an implicit correction consistency\nconstraint. Finally, we collect massive unlabeled data to exhibit the benefit\nof our semi-supervised scheme in rotation correction. Extensive experiments\ndemonstrate the superiority and universality of CoupledTPS over the existing\nstate-of-the-art (SoTA) solutions for rotation correction and beyond. The code\nand data are available at https://github.com/nie-lang/CoupledTPS.",
      "tldr_zh": "这篇论文提出了一种半监督耦合 Thin-plate Spline (TPS) 模型，名为 CoupledTPS，用于处理单图像变形任务，如旋转校正、rectangling 和 portrait correction，以解决传统 TPS 在增加控制点时可能导致的内容扭曲问题。CoupledTPS 通过迭代搜索预测新控制点，并利用 warping flow 作为桥梁来耦合多个 TPS 变换，从而消除多重变形引起的插值错误。论文还引入半监督学习方案，通过未标注数据的双重变换和隐式校正一致性约束，提高变形质量，而无需大量标注。实验证明，CoupledTPS 在旋转校正等任务中比现有最先进（SoTA）方法表现出色，并提供了代码和数据以供进一步验证。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted to TPAMI2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13432v2",
      "published_date": "2024-01-24 13:03:28 UTC",
      "updated_date": "2024-06-18 10:29:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:05:06.044785"
    },
    {
      "arxiv_id": "2401.13408v2",
      "title": "Causal Perception",
      "title_zh": "翻译失败",
      "authors": [
        "Jose M. Alvarez",
        "Salvatore Ruggieri"
      ],
      "abstract": "Perception occurs when two individuals interpret the same information\ndifferently. Despite being a known phenomenon with implications for bias in\ndecision-making, as individual experience determines interpretation, perception\nremains largely overlooked in machine learning (ML) research. Modern decision\nflows, whether partially or fully automated, involve human experts interacting\nwith ML applications. How might we then, e.g., account for two experts that\ninterpret differently a deferred instance or an explanation from a ML model? To\naccount for perception, we first need to formulate it. In this work, we define\nperception under causal reasoning using structural causal models (SCM). Our\nframework formalizes individual experience as additional causal knowledge that\ncomes with and is used by a human expert (read, decision maker). We present two\nkinds of causal perception, unfaithful and inconsistent, based on the SCM\nproperties of faithfulness and consistency. Further, we motivate the importance\nof perception within fairness problems. We illustrate our framework through a\nseries of decision flow examples involving ML applications and human experts.",
      "tldr_zh": "该论文探讨了“因果感知”（Causal Perception），即不同个体对相同信息产生不同解读的现象，并强调其在机器学习（ML）决策中的偏见问题。该框架使用“结构因果模型”（SCM）来形式化个人经验作为额外的因果知识，定义了两种感知类型：“unfaithful”（不忠实）和“inconsistent”（不一致）。作者通过决策流程示例，展示了因果感知在公平性问题中的重要性，并为ML应用中处理人类专家解读差异提供了新方法。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2305.09535 by other authors",
      "pdf_url": "http://arxiv.org/pdf/2401.13408v2",
      "published_date": "2024-01-24 12:08:58 UTC",
      "updated_date": "2024-05-22 14:04:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:05:15.713128"
    },
    {
      "arxiv_id": "2402.01698v1",
      "title": "Large language model empowered participatory urban planning",
      "title_zh": "大型语言模型赋能的参与式城市规划",
      "authors": [
        "Zhilun Zhou",
        "Yuming Lin",
        "Yong Li"
      ],
      "abstract": "Participatory urban planning is the mainstream of modern urban planning and\ninvolves the active engagement of different stakeholders. However, the\ntraditional participatory paradigm encounters challenges in time and manpower,\nwhile the generative planning tools fail to provide adjustable and inclusive\nsolutions. This research introduces an innovative urban planning approach\nintegrating Large Language Models (LLMs) within the participatory process. The\nframework, based on the crafted LLM agent, consists of role-play, collaborative\ngeneration, and feedback iteration, solving a community-level land-use task\ncatering to 1000 distinct interests. Empirical experiments in diverse urban\ncommunities exhibit LLM's adaptability and effectiveness across varied planning\nscenarios. The results were evaluated on four metrics, surpassing human experts\nin satisfaction and inclusion, and rivaling state-of-the-art reinforcement\nlearning methods in service and ecology. Further analysis shows the advantage\nof LLM agents in providing adjustable and inclusive solutions with natural\nlanguage reasoning and strong scalability. While implementing the recent\nadvancements in emulating human behavior for planning, this work envisions both\nplanners and citizens benefiting from low-cost, efficient LLM agents, which is\ncrucial for enhancing participation and realizing participatory urban planning.",
      "tldr_zh": "这篇论文提出了一种利用Large Language Models (LLMs)增强的参与式城市规划方法，通过LLM代理的角色扮演、协作生成和反馈迭代模块，解决传统规划在时间和人力上的挑战，并为社区级土地使用任务提供可调整和包容的解决方案。实验在多样化城市社区中验证了该框架的适应性和有效性，在四个指标（满意度、包容性、服务和生态）上超越人类专家，并在服务和生态方面与最先进强化学习方法相当。研究强调，LLM代理通过自然语言推理和强扩展性，能实现低成本、高效的规划参与，从而提升城市规划的包容性和可持续性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 7 figures, 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.01698v1",
      "published_date": "2024-01-24 10:50:01 UTC",
      "updated_date": "2024-01-24 10:50:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:05:30.027677"
    },
    {
      "arxiv_id": "2401.13346v2",
      "title": "Past, Present, Future: A Comprehensive Exploration of AI Use Cases in the UMBRELLA IoT Testbed",
      "title_zh": "翻译失败",
      "authors": [
        "Peizheng Li",
        "Ioannis Mavromatis",
        "Aftab Khan"
      ],
      "abstract": "UMBRELLA is a large-scale, open-access Internet of Things (IoT) ecosystem\nincorporating over 200 multi-sensor multi-wireless nodes, 20 collaborative\nrobots, and edge-intelligence-enabled devices. This paper provides a guide to\nthe implemented and prospective artificial intelligence (AI) capabilities of\nUMBRELLA in real-world IoT systems. Four existing UMBRELLA applications are\npresented in detail: 1) An automated streetlight monitoring for detecting\nissues and triggering maintenance alerts; 2) A Digital twin of building\nenvironments providing enhanced air quality sensing with reduced cost; 3) A\nlarge-scale Federated Learning framework for reducing communication overhead;\nand 4) An intrusion detection for containerised applications identifying\nmalicious activities. Additionally, the potential of UMBRELLA is outlined for\nfuture smart city and multi-robot crowdsensing applications enhanced by\nsemantic communications and multi-agent planning. Finally, to realise the above\nuse-cases we discuss the need for a tailored MLOps platform to automate\nUMBRELLA model pipelines and establish trust.",
      "tldr_zh": "这篇论文全面探讨了UMBRELLA IoT测试床的AI用例，该测试床是一个大型开放生态系统，包含超过200个多传感器多无线节点、20个协作机器人和边缘智能设备。论文详细介绍了四个现有应用：自动街灯监控系统用于检测问题并触发维护警报、建筑环境的Digital twin提供低成本的空气质量监测、大规模Federated Learning框架减少通信开销，以及入侵检测系统识别容器化应用的恶意活动。同时，论文概述了UMBRELLA在未来智能城市和多机器人众包感知中的潜力，包括语义通信和多代理规划的增强，并强调了定制MLOps平台的需求，以自动化模型管道并建立信任。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pgaes, 4 figures. This work has been accepted by PerCom TrustSense\n  workshop 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13346v2",
      "published_date": "2024-01-24 10:17:59 UTC",
      "updated_date": "2024-02-01 18:20:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:05:42.450103"
    },
    {
      "arxiv_id": "2401.13335v1",
      "title": "Full Bayesian Significance Testing for Neural Networks",
      "title_zh": "神经网络的全贝叶斯显著性检验",
      "authors": [
        "Zehua Liu",
        "Zimeng Li",
        "Jingyuan Wang",
        "Yue He"
      ],
      "abstract": "Significance testing aims to determine whether a proposition about the\npopulation distribution is the truth or not given observations. However,\ntraditional significance testing often needs to derive the distribution of the\ntesting statistic, failing to deal with complex nonlinear relationships. In\nthis paper, we propose to conduct Full Bayesian Significance Testing for neural\nnetworks, called \\textit{n}FBST, to overcome the limitation in relationship\ncharacterization of traditional approaches. A Bayesian neural network is\nutilized to fit the nonlinear and multi-dimensional relationships with small\nerrors and avoid hard theoretical derivation by computing the evidence value.\nBesides, \\textit{n}FBST can test not only global significance but also local\nand instance-wise significance, which previous testing methods don't focus on.\nMoreover, \\textit{n}FBST is a general framework that can be extended based on\nthe measures selected, such as Grad-\\textit{n}FBST, LRP-\\textit{n}FBST,\nDeepLIFT-\\textit{n}FBST, LIME-\\textit{n}FBST. A range of experiments on both\nsimulated and real data are conducted to show the advantages of our method.",
      "tldr_zh": "这篇论文提出了一种名为 nFBST 的全贝叶斯显著性测试方法，应用于神经网络，以克服传统方法在处理复杂非线性关系时的局限性。nFBST 利用贝叶斯神经网络来拟合多维非线性关系，通过计算证据值避免了繁琐的理论推导，并支持全局、局部和实例级别的显著性测试，这在以往方法中未被强调。该框架具有通用性，可基于不同度量扩展，如 Grad-nFBST、LRP-nFBST 等。实验在模拟和真实数据上验证了 nFBST 的优势，展示了其在关系表征和测试灵活性上的改进。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Published as a conference paper at AAAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13335v1",
      "published_date": "2024-01-24 09:59:48 UTC",
      "updated_date": "2024-01-24 09:59:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:05:52.911267"
    },
    {
      "arxiv_id": "2401.13334v2",
      "title": "Explainable Bayesian Optimization",
      "title_zh": "可解释的贝叶斯优化",
      "authors": [
        "Tanmay Chakraborty",
        "Christian Wirth",
        "Christin Seifert"
      ],
      "abstract": "Manual parameter tuning of cyber-physical systems is a common practice, but\nit is labor-intensive. Bayesian Optimization (BO) offers an automated\nalternative, yet its black-box nature reduces trust and limits human-BO\ncollaborative system tuning. Experts struggle to interpret BO recommendations\ndue to the lack of explanations. This paper addresses the post-hoc BO\nexplainability problem for cyber-physical systems. We introduce TNTRules\n(Tune-No-Tune Rules), a novel algorithm that provides both global and local\nexplanations for BO recommendations. TNTRules generates actionable rules and\nvisual graphs, identifying optimal solution bounds and ranges, as well as\npotential alternative solutions. Unlike existing explainable AI (XAI) methods,\nTNTRules is tailored specifically for BO, by encoding uncertainty via a\nvariance pruning technique and hierarchical agglomerative clustering. A\nmulti-objective optimization approach allows maximizing explanation quality. We\nevaluate TNTRules using established XAI metrics (Correctness, Completeness, and\nCompactness) and compare it against adapted baseline methods. The results\ndemonstrate that TNTRules generates high-fidelity, compact, and complete\nexplanations, significantly outperforming three baselines on 5 multi-objective\ntesting functions and 2 hyperparameter tuning problems.",
      "tldr_zh": "本研究针对Bayesian Optimization (BO) 的黑盒性质导致的信任和协作问题，提出了一种后验解释方法，以提升BO在网络物理系统参数调整中的可解释性。论文引入TNTRules算法，通过方差修剪技术和层次聚类编码不确定性，并采用多目标优化来生成全局和局部解释，包括可操作规则、可视化图表、最优解边界以及备选方案。与现有Explainable AI (XAI)方法不同，TNTRules专门针对BO进行优化。实验结果显示，TNTRules在Correctness、Completeness和Compactness等XAI指标上显著优于基线方法，在5个多目标测试函数和2个超参数调优问题上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13334v2",
      "published_date": "2024-01-24 09:59:22 UTC",
      "updated_date": "2025-04-01 15:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:06:04.720990"
    },
    {
      "arxiv_id": "2401.13324v6",
      "title": "Information That Matters: Exploring Information Needs of People Affected by Algorithmic Decisions",
      "title_zh": "重要的信息：探索受算法决策影响人群的信息需求",
      "authors": [
        "Timothée Schmude",
        "Laura Koesten",
        "Torsten Möller",
        "Sebastian Tschiatschek"
      ],
      "abstract": "Every AI system that makes decisions about people has a group of stakeholders\nthat are personally affected by these decisions. However, explanations of AI\nsystems rarely address the information needs of this stakeholder group, who\noften are AI novices. This creates a gap between conveyed information and\ninformation that matters to those who are impacted by the system's decisions,\nsuch as domain experts and decision subjects. To address this, we present the\n\"XAI Novice Question Bank,\" an extension of the XAI Question Bank containing a\ncatalog of information needs from AI novices in two use cases: employment\nprediction and health monitoring. The catalog covers the categories of data,\nsystem context, system usage, and system specifications. We gathered\ninformation needs through task-based interviews where participants asked\nquestions about two AI systems to decide on their adoption and received verbal\nexplanations in response. Our analysis showed that participants' confidence\nincreased after receiving explanations but that their understanding faced\nchallenges. These included difficulties in locating information and in\nassessing their own understanding, as well as attempts to outsource\nunderstanding. Additionally, participants' prior perceptions of the systems'\nrisks and benefits influenced their information needs. Participants who\nperceived high risks sought explanations about the intentions behind a system's\ndeployment, while those who perceived low risks rather asked about the system's\noperation. Our work aims to support the inclusion of AI novices in\nexplainability efforts by highlighting their information needs, aims, and\nchallenges. We summarize our findings as five key implications that can inform\nthe design of future explanations for lay stakeholder audiences.",
      "tldr_zh": "本研究探讨了 AI 决策对相关方（stakeholders）的影响，强调现有 XAI（可解释 AI）解释未能满足 AI 新手（如领域专家和决策对象）的信息需求。研究者开发了“XAI Novice Question Bank”，通过任务-based 访谈在就业预测和健康监测两个用例中收集了 AI 新手的问答目录，涵盖数据、系统上下文、系统使用和系统规范等类别。结果显示，解释后参与者的信心提升，但理解面临挑战，包括信息定位困难、自我评估问题和外包理解倾向；此外，先验风险认知影响需求，高风险者关注系统部署意图，低风险者更注重系统操作。该工作总结了五个关键启示，以指导未来针对非专业受众的解释设计。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Published version available at the International Journal of\n  Human-Computer Studies, please refer to:\n  https://doi.org/10.1016/j.ijhcs.2024.103380. Main text: 26 pages, 4 figures.\n  Supplementary material is provided",
      "pdf_url": "http://arxiv.org/pdf/2401.13324v6",
      "published_date": "2024-01-24 09:39:39 UTC",
      "updated_date": "2024-10-28 12:45:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:06:17.585924"
    },
    {
      "arxiv_id": "2401.13315v1",
      "title": "Deep Learning for Improved Polyp Detection from Synthetic Narrow-Band Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Mathias Ramm Haugland",
        "Hemin Ali Qadir",
        "Ilangko Balasingham"
      ],
      "abstract": "To cope with the growing prevalence of colorectal cancer (CRC), screening\nprograms for polyp detection and removal have proven their usefulness.\nColonoscopy is considered the best-performing procedure for CRC screening. To\nease the examination, deep learning based methods for automatic polyp detection\nhave been developed for conventional white-light imaging (WLI). Compared with\nWLI, narrow-band imaging (NBI) can improve polyp classification during\ncolonoscopy but requires special equipment. We propose a CycleGAN-based\nframework to convert images captured with regular WLI to synthetic NBI (SNBI)\nas a pre-processing method for improving object detection on WLI when NBI is\nunavailable. This paper first shows that better results for polyp detection can\nbe achieved on NBI compared to a relatively similar dataset of WLI. Secondly,\nexperimental results demonstrate that our proposed modality translation can\nachieve improved polyp detection on SNBI images generated from WLI compared to\nthe original WLI. This is because our WLI-to-SNBI translation model can enhance\nthe observation of polyp surface patterns in the generated SNBI images.",
      "tldr_zh": "该研究针对结肠癌（CRC）筛查中息肉检测的挑战，提出使用深度学习（Deep Learning）方法，通过 CycleGAN 框架将常规白光成像（WLI）图像转换为合成窄带成像（SNBI），以改善检测性能。实验结果显示，NBI 图像在息肉检测上比相似的 WLI 数据集表现更好，而将 WLI 转换为 SNBI 后，检测准确性进一步提升，因为 SNBI 增强了息肉表面图案的可观察性。该方法为在无 NBI 设备情况下提升结肠镜检查效率提供了实用解决方案。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13315v1",
      "published_date": "2024-01-24 09:14:33 UTC",
      "updated_date": "2024-01-24 09:14:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:06:28.801918"
    },
    {
      "arxiv_id": "2402.01353v1",
      "title": "Efficient compilation of expressive problem space specifications to neural network solvers",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew L. Daggitt",
        "Wen Kokke",
        "Robert Atkey"
      ],
      "abstract": "Recent work has described the presence of the embedding gap in neural network\nverification. On one side of the gap is a high-level specification about the\nnetwork's behaviour, written by a domain expert in terms of the interpretable\nproblem space. On the other side are a logically-equivalent set of\nsatisfiability queries, expressed in the uninterpretable embedding space in a\nform suitable for neural network solvers. In this paper we describe an\nalgorithm for compiling the former to the latter. We explore and overcome\ncomplications that arise from targeting neural network solvers as opposed to\nstandard SMT solvers.",
      "tldr_zh": "该论文解决了神经网络验证中的 embedding gap 问题，即将领域专家用可解释问题空间编写的网络行为高阶规范，编译成逻辑等价的可满足性查询，这些查询以不可解释的嵌入空间形式适配 neural network solvers。研究提出了一种高效编译算法，针对 neural network solvers 的独特挑战（如与标准 SMT solvers 的差异）进行优化，以桥接规范与查询间的差距。通过探讨和克服这些复杂问题，该方法为神经网络验证提供了更有效的工具。",
      "categories": [
        "cs.LO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.LO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.01353v1",
      "published_date": "2024-01-24 09:13:09 UTC",
      "updated_date": "2024-01-24 09:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:06:40.387898"
    },
    {
      "arxiv_id": "2401.13311v3",
      "title": "ConTextual: Evaluating Context-Sensitive Text-Rich Visual Reasoning in Large Multimodal Models",
      "title_zh": "ConTextual：评估大型多模态模型中上下文敏感的文本丰富视觉推理",
      "authors": [
        "Rohan Wadhawan",
        "Hritik Bansal",
        "Kai-Wei Chang",
        "Nanyun Peng"
      ],
      "abstract": "Many real-world tasks require an agent to reason jointly over text and visual\nobjects, (e.g., navigating in public spaces), which we refer to as\ncontext-sensitive text-rich visual reasoning. Specifically, these tasks require\nan understanding of the context in which the text interacts with visual\nelements within an image. However, there is a lack of existing datasets to\nbenchmark the state-of-the-art multimodal models' capability on\ncontext-sensitive text-rich visual reasoning. In this paper, we introduce\nConTextual, a novel dataset featuring human-crafted instructions that require\ncontext-sensitive reasoning for text-rich images. We conduct experiments to\nassess the performance of 14 foundation models (GPT-4V, Gemini-Pro-Vision,\nLLaVA-Next) and establish a human performance baseline. Further, we perform\nhuman evaluations of the model responses and observe a significant performance\ngap of 30.8% between GPT-4V (the current best-performing Large Multimodal\nModel) and human performance. Our fine-grained analysis reveals that GPT-4V\nencounters difficulties interpreting time-related data and infographics.\nHowever, it demonstrates proficiency in comprehending abstract visual contexts\nsuch as memes and quotes. Finally, our qualitative analysis uncovers various\nfactors contributing to poor performance including lack of precise visual\nperception and hallucinations. Our dataset, code, and leaderboard can be found\non the project page https://con-textual.github.io/",
      "tldr_zh": "该论文引入了ConTextual数据集，用于评估大型多模态模型（Large Multimodal Models）在上下文敏感文本丰富视觉推理（context-sensitive text-rich visual reasoning）方面的能力，该数据集包含人类编写的指令，针对文本丰富的图像进行测试。研究者评估了14个基础模型（如GPT-4V、Gemini-Pro-Vision和LLaVA-Next）的性能，并与人类基准进行比较，结果显示GPT-4V与人类表现存在30.8%的差距。分析发现，模型在解释时间相关数据和信息图方面表现较差，但擅长处理抽象视觉上下文如memes和quotes；此外，定性评估揭示了问题包括缺乏精确视觉感知和hallucinations。数据集、代码和排行榜可在项目页面获取。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13311v3",
      "published_date": "2024-01-24 09:07:11 UTC",
      "updated_date": "2024-07-16 03:36:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:06:55.862202"
    },
    {
      "arxiv_id": "2401.13298v1",
      "title": "Towards Explainable Harmful Meme Detection through Multimodal Debate between Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Hongzhan Lin",
        "Ziyang Luo",
        "Wei Gao",
        "Jing Ma",
        "Bo Wang",
        "Ruichao Yang"
      ],
      "abstract": "The age of social media is flooded with Internet memes, necessitating a clear\ngrasp and effective identification of harmful ones. This task presents a\nsignificant challenge due to the implicit meaning embedded in memes, which is\nnot explicitly conveyed through the surface text and image. However, existing\nharmful meme detection methods do not present readable explanations that unveil\nsuch implicit meaning to support their detection decisions. In this paper, we\npropose an explainable approach to detect harmful memes, achieved through\nreasoning over conflicting rationales from both harmless and harmful positions.\nSpecifically, inspired by the powerful capacity of Large Language Models (LLMs)\non text generation and reasoning, we first elicit multimodal debate between\nLLMs to generate the explanations derived from the contradictory arguments.\nThen we propose to fine-tune a small language model as the debate judge for\nharmfulness inference, to facilitate multimodal fusion between the harmfulness\nrationales and the intrinsic multimodal information within memes. In this way,\nour model is empowered to perform dialectical reasoning over intricate and\nimplicit harm-indicative patterns, utilizing multimodal explanations\noriginating from both harmless and harmful arguments. Extensive experiments on\nthree public meme datasets demonstrate that our harmful meme detection approach\nachieves much better performance than state-of-the-art methods and exhibits a\nsuperior capacity for explaining the meme harmfulness of the model predictions.",
      "tldr_zh": "这篇论文针对社交媒体上有害模因的检测挑战，提出了一种可解释的方法，通过 Large Language Models (LLMs) 进行多模态辩论，生成来自无害和有害角度的冲突理由，以揭示模因的隐含含义。方法包括先利用 LLMs 进行辩论产生解释，然后微调一个小型语言模型作为辩论裁判，实现多模态融合和辩证推理，从而识别复杂的有害模式。实验在三个公共数据集上表明，该方法比最先进技术性能更优，并显著提升了模型预测的可解释性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "The first work towards explainable harmful meme detection by\n  harnessing advanced LLMs",
      "pdf_url": "http://arxiv.org/pdf/2401.13298v1",
      "published_date": "2024-01-24 08:37:16 UTC",
      "updated_date": "2024-01-24 08:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:07:09.011801"
    },
    {
      "arxiv_id": "2401.13716v1",
      "title": "Can I trust my fake data -- A comprehensive quality assessment framework for synthetic tabular data in healthcare",
      "title_zh": "翻译失败",
      "authors": [
        "Vibeke Binz Vallevik",
        "Aleksandar Babic",
        "Serena Elizabeth Marshall",
        "Severin Elvatun",
        "Helga Brøgger",
        "Sharmini Alagaratnam",
        "Bjørn Edwin",
        "Narasimha Raghavan Veeraragavan",
        "Anne Kjersti Befring",
        "Jan Franz Nygård"
      ],
      "abstract": "Ensuring safe adoption of AI tools in healthcare hinges on access to\nsufficient data for training, testing and validation. In response to privacy\nconcerns and regulatory requirements, using synthetic data has been suggested.\nSynthetic data is created by training a generator on real data to produce a\ndataset with similar statistical properties. Competing metrics with differing\ntaxonomies for quality evaluation have been suggested, resulting in a complex\nlandscape. Optimising quality entails balancing considerations that make the\ndata fit for use, yet relevant dimensions are left out of existing frameworks.\nWe performed a comprehensive literature review on the use of quality evaluation\nmetrics on SD within the scope of tabular healthcare data and SD made using\ndeep generative methods. Based on this and the collective team experiences, we\ndeveloped a conceptual framework for quality assurance. The applicability was\nbenchmarked against a practical case from the Dutch National Cancer Registry.\nWe present a conceptual framework for quality assurance of SD for AI\napplications in healthcare that aligns diverging taxonomies, expands on common\nquality dimensions to include the dimensions of Fairness and Carbon footprint,\nand proposes stages necessary to support real-life applications. Building trust\nin synthetic data by increasing transparency and reducing the safety risk will\naccelerate the development and uptake of trustworthy AI tools for the benefit\nof patients. Despite the growing emphasis on algorithmic fairness and carbon\nfootprint, these metrics were scarce in the literature review. The overwhelming\nfocus was on statistical similarity using distance metrics while sequential\nlogic detection was scarce. A consensus-backed framework that includes all\nrelevant quality dimensions can provide assurance for safe and responsible\nreal-life applications of SD.",
      "tldr_zh": "本研究针对医疗保健领域合成表格数据（Synthetic Data, SD）的质量评估问题，提出一个全面的概念框架，以解决现有指标体系的复杂性和缺失。该框架基于文献综述和团队经验，整合了不同分类，扩展了常见质量维度，包括公平性（Fairness）和碳足迹（Carbon footprint），并通过荷兰国家癌症登记处的实际案例进行基准测试。结果显示，现有评估主要聚焦于统计相似性（如距离指标），而对顺序逻辑检测关注不足；该框架提升了SD的透明度和安全性，有助于加速可信赖AI工具的开发和应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13716v1",
      "published_date": "2024-01-24 08:14:20 UTC",
      "updated_date": "2024-01-24 08:14:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:07:21.149575"
    },
    {
      "arxiv_id": "2401.14426v1",
      "title": "M$^3$TN: Multi-gate Mixture-of-Experts based Multi-valued Treatment Network for Uplift Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Zexu Sun",
        "Xu Chen"
      ],
      "abstract": "Uplift modeling is a technique used to predict the effect of a treatment\n(e.g., discounts) on an individual's response. Although several methods have\nbeen proposed for multi-valued treatment, they are extended from binary\ntreatment methods. There are still some limitations. Firstly, existing methods\ncalculate uplift based on predicted responses, which may not guarantee a\nconsistent uplift distribution between treatment and control groups. Moreover,\nthis may cause cumulative errors for multi-valued treatment. Secondly, the\nmodel parameters become numerous with many prediction heads, leading to reduced\nefficiency. To address these issues, we propose a novel \\underline{M}ulti-gate\n\\underline{M}ixture-of-Experts based \\underline{M}ulti-valued\n\\underline{T}reatment \\underline{N}etwork (M$^3$TN). M$^3$TN consists of two\ncomponents: 1) a feature representation module with Multi-gate\nMixture-of-Experts to improve the efficiency; 2) a reparameterization module by\nmodeling uplift explicitly to improve the effectiveness. We also conduct\nextensive experiments to demonstrate the effectiveness and efficiency of our\nM$^3$TN.",
      "tldr_zh": "本论文针对 Uplift Modeling 中的多值治疗（multi-valued treatment）问题，指出现有方法基于预测响应计算 uplift 可能导致治疗组和控制组分布不一致、累积错误以及模型参数过多而效率低下。作者提出 M$^3$TN（Multi-gate Mixture-of-Experts based Multi-valued Treatment Network）模型，该模型包括两个关键组件：Multi-gate Mixture-of-Experts 特征表示模块以提升效率，以及显式建模 uplift 的重新参数化模块以提高有效性。通过广泛实验，M$^3$TN 证明了其在有效性和效率方面的显著优势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ME"
      ],
      "primary_category": "cs.LG",
      "comment": "ICASSP 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.14426v1",
      "published_date": "2024-01-24 08:10:36 UTC",
      "updated_date": "2024-01-24 08:10:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:07:33.492742"
    },
    {
      "arxiv_id": "2401.14425v1",
      "title": "No Longer Trending on Artstation: Prompt Analysis of Generative AI Art",
      "title_zh": "翻译失败",
      "authors": [
        "Jon McCormack",
        "Maria Teresa Llano",
        "Stephen James Krol",
        "Nina Rajcic"
      ],
      "abstract": "Image generation using generative AI is rapidly becoming a major new source\nof visual media, with billions of AI generated images created using diffusion\nmodels such as Stable Diffusion and Midjourney over the last few years. In this\npaper we collect and analyse over 3 million prompts and the images they\ngenerate. Using natural language processing, topic analysis and visualisation\nmethods we aim to understand collectively how people are using text prompts,\nthe impact of these systems on artists, and more broadly on the visual cultures\nthey promote. Our study shows that prompting focuses largely on surface\naesthetics, reinforcing cultural norms, popular conventional representations\nand imagery. We also find that many users focus on popular topics (such as\nmaking colouring books, fantasy art, or Christmas cards), suggesting that the\ndominant use for the systems analysed is recreational rather than artistic.",
      "tldr_zh": "这篇论文分析了超过 300 万个生成式 AI 提示及其生成的图像，旨在理解人们如何使用文本提示及其对艺术家和视觉文化的影响。研究采用自然语言处理(NLP)、主题分析和可视化方法，揭示提示主要聚焦于表面美学，强化文化规范和流行形象。结果显示，许多用户偏好娱乐性主题，如着色书、幻想艺术或圣诞卡，表明这些系统更多用于休闲而非专业艺术创作。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CV",
        "cs.CY",
        "cs.NE",
        "J.5; I.2"
      ],
      "primary_category": "cs.HC",
      "comment": "Paper accepted for EvoMUSART 2024, Aberystwyth, Wales, United\n  Kingdom, 3-5 April 2024",
      "pdf_url": "http://arxiv.org/pdf/2401.14425v1",
      "published_date": "2024-01-24 08:03:13 UTC",
      "updated_date": "2024-01-24 08:03:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:07:44.144181"
    },
    {
      "arxiv_id": "2401.14424v3",
      "title": "Discovering Mathematical Formulas from Data via GPT-guided Monte Carlo Tree Search",
      "title_zh": "翻译失败",
      "authors": [
        "Yanjie Li",
        "Weijun Li",
        "Lina Yu",
        "Min Wu",
        "Jingyi Liu",
        "Wenqiang Li",
        "Meilan Hao",
        "Shu Wei",
        "Yusong Deng"
      ],
      "abstract": "Finding a concise and interpretable mathematical formula that accurately\ndescribes the relationship between each variable and the predicted value in the\ndata is a crucial task in scientific research, as well as a significant\nchallenge in artificial intelligence. This problem is referred to as symbolic\nregression, which is an NP-hard problem. In the previous year, a novel symbolic\nregression methodology utilizing Monte Carlo Tree Search (MCTS) was advanced,\nachieving state-of-the-art results on a diverse range of datasets. although\nthis algorithm has shown considerable improvement in recovering target\nexpressions compared to previous methods, the lack of guidance during the MCTS\nprocess severely hampers its search efficiency. Recently, some algorithms have\nadded a pre-trained policy network to guide the search of MCTS, but the\npre-trained policy network generalizes poorly. To optimize the trade-off\nbetween efficiency and versatility, we introduce SR-GPT, a novel algorithm for\nsymbolic regression that integrates Monte Carlo Tree Search (MCTS) with a\nGenerative Pre-Trained Transformer (GPT). By using GPT to guide the MCTS, the\nsearch efficiency of MCTS is significantly improved. Next, we utilize the MCTS\nresults to further refine the GPT, enhancing its capabilities and providing\nmore accurate guidance for the MCTS. MCTS and GPT are coupled together and\noptimize each other until the target expression is successfully determined. We\nconducted extensive evaluations of SR-GPT using 222 expressions sourced from\nover 10 different symbolic regression datasets. The experimental results\ndemonstrate that SR-GPT outperforms existing state-of-the-art algorithms in\naccurately recovering symbolic expressions both with and without added noise.",
      "tldr_zh": "这篇论文提出了 SR-GPT 算法，用于解决符号回归(symbolic regression)问题，该算法通过 Generative Pre-Trained Transformer (GPT) 指导 Monte Carlo Tree Search (MCTS)，显著提升了从数据中发现数学公式的搜索效率。SR-GPT 让 GPT 提供初始指导，同时利用 MCTS 的结果来进一步优化 GPT，使两者相互迭代以准确确定目标表达式。在对 222 个表达式（来自超过 10 个数据集）的广泛实验中，SR-GPT 在有噪声和无噪声条件下均优于现有 state-of-the-art 算法，展示了其在效率和准确性方面的优势。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2401.14424v3",
      "published_date": "2024-01-24 07:47:04 UTC",
      "updated_date": "2024-01-30 09:27:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:07:57.769172"
    },
    {
      "arxiv_id": "2401.13282v1",
      "title": "RefreshNet: Learning Multiscale Dynamics through Hierarchical Refreshing",
      "title_zh": "RefreshNet：通过层次化刷新学习多尺度动态",
      "authors": [
        "Junaid Farooq",
        "Danish Rafiq",
        "Pantelis R. Vlachas",
        "Mohammad Abid Bazaz"
      ],
      "abstract": "Forecasting complex system dynamics, particularly for long-term predictions,\nis persistently hindered by error accumulation and computational burdens. This\nstudy presents RefreshNet, a multiscale framework developed to overcome these\nchallenges, delivering an unprecedented balance between computational\nefficiency and predictive accuracy. RefreshNet incorporates convolutional\nautoencoders to identify a reduced order latent space capturing essential\nfeatures of the dynamics, and strategically employs multiple recurrent neural\nnetwork (RNN) blocks operating at varying temporal resolutions within the\nlatent space, thus allowing the capture of latent dynamics at multiple temporal\nscales. The unique \"refreshing\" mechanism in RefreshNet allows coarser blocks\nto reset inputs of finer blocks, effectively controlling and alleviating error\naccumulation. This design demonstrates superiority over existing techniques\nregarding computational efficiency and predictive accuracy, especially in\nlong-term forecasting. The framework is validated using three benchmark\napplications: the FitzHugh-Nagumo system, the Reaction-Diffusion equation, and\nKuramoto-Sivashinsky dynamics. RefreshNet significantly outperforms\nstate-of-the-art methods in long-term forecasting accuracy and speed, marking a\nsignificant advancement in modeling complex systems and opening new avenues in\nunderstanding and predicting their behavior.",
      "tldr_zh": "这篇论文介绍了 RefreshNet，一种多尺度框架，旨在解决复杂系统动态预测中的错误积累和计算负担问题，通过结合计算效率和预测准确性来实现长期预测的改进。RefreshNet 利用 convolutional autoencoders 识别减少阶潜在空间，并部署多个在不同时间分辨率的 RNN 块，以及独特的 refreshing 机制来重置输入，从而捕捉多时间尺度的动态并缓解错误积累。在 FitzHugh-Nagumo 系统、Reaction-Diffusion 方程和 Kuramoto-Sivashinsky 动态等基准应用上，RefreshNet 显著超过了现有方法，在长期预测准确性和速度方面取得了重大进展。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13282v1",
      "published_date": "2024-01-24 07:47:01 UTC",
      "updated_date": "2024-01-24 07:47:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:08:10.388395"
    },
    {
      "arxiv_id": "2401.13275v2",
      "title": "Can AI Assistants Know What They Don't Know?",
      "title_zh": "AI 助手能知道自己不知道的东西吗？",
      "authors": [
        "Qinyuan Cheng",
        "Tianxiang Sun",
        "Xiangyang Liu",
        "Wenwei Zhang",
        "Zhangyue Yin",
        "Shimin Li",
        "Linyang Li",
        "Zhengfu He",
        "Kai Chen",
        "Xipeng Qiu"
      ],
      "abstract": "Recently, AI assistants based on large language models (LLMs) show surprising\nperformance in many tasks, such as dialogue, solving math problems, writing\ncode, and using tools. Although LLMs possess intensive world knowledge, they\nstill make factual errors when facing some knowledge intensive tasks, like\nopen-domain question answering. These untruthful responses from the AI\nassistant may cause significant risks in practical applications. We believe\nthat an AI assistant's refusal to answer questions it does not know is a\ncrucial method for reducing hallucinations and making the assistant truthful.\nTherefore, in this paper, we ask the question \"Can AI assistants know what they\ndon't know and express them through natural language?\" To answer this question,\nwe construct a model-specific \"I don't know\" (Idk) dataset for an assistant,\nwhich contains its known and unknown questions, based on existing open-domain\nquestion answering datasets. Then we align the assistant with its corresponding\nIdk dataset and observe whether it can refuse to answer its unknown questions\nafter alignment. Experimental results show that after alignment with Idk\ndatasets, the assistant can refuse to answer most its unknown questions. For\nquestions they attempt to answer, the accuracy is significantly higher than\nbefore the alignment.",
      "tldr_zh": "该论文探讨了基于大语言模型(LLMs)的AI助手是否能识别并通过自然语言表达自己不知道的问题，以减少幻觉和提升回答真实性。作者构建了模型特定的\"I don't know\"(Idk)数据集，基于现有开放域问答数据集，包含已知和未知问题，并通过对齐过程训练助手。实验结果表明，对齐后，助手能够拒绝回答大多数未知问题，而对于尝试回答的问题，准确率显著提高。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2401.13275v2",
      "published_date": "2024-01-24 07:34:55 UTC",
      "updated_date": "2024-01-28 09:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:08:20.640742"
    },
    {
      "arxiv_id": "2401.13270v2",
      "title": "Audio-Infused Automatic Image Colorization by Exploiting Audio Scene Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Pengcheng Zhao",
        "Yanxiang Chen",
        "Yang Zhao",
        "Zhao Zhang"
      ],
      "abstract": "Automatic image colorization is inherently an ill-posed problem with\nuncertainty, which requires an accurate semantic understanding of scenes to\nestimate reasonable colors for grayscale images. Although recent\ninteraction-based methods have achieved impressive performance, it is still a\nvery difficult task to infer realistic and accurate colors for automatic\ncolorization. To reduce the difficulty of semantic understanding of grayscale\nscenes, this paper tries to utilize corresponding audio, which naturally\ncontains extra semantic information about the same scene. Specifically, a novel\nand pluggable audio-infused automatic image colorization (AIAIC) method is\nproposed, which consists of three stages. First, we take color image semantics\nas a bridge and pretrain a colorization network guided by color image\nsemantics. Second, the natural co-occurrence of audio and video is utilized to\nlearn the color semantic correlations between audio and visual scenes. Third,\nthe implicit audio semantic representation is fed into the pretrained network\nto finally realize the audio-guided colorization. The whole process is trained\nin a self-supervised manner without human annotation. Experiments demonstrate\nthat audio guidance can effectively improve the performance of automatic\ncolorization, especially for some scenes that are difficult to understand only\nfrom visual modality.",
      "tldr_zh": "这篇论文提出了一种利用音频语义辅助的自动图像着色（Automatic Image Colorization）方法，名为AIAIC，以解决灰度图像色化中语义理解的模糊性和不确定性问题。该方法分为三个阶段：首先，通过彩色图像语义预训练一个色化网络；其次，利用音频和视频的自然共现学习音频与视觉场景的颜色语义相关性；最后，将音频语义表示输入预训练网络，实现音频引导的色化。整个过程采用自监督（self-supervised）训练，无需人工标注，实验结果显示，音频指导显著提升了色化性能，尤其在仅靠视觉模态难以理解的场景中。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICONIP-2024",
      "pdf_url": "http://arxiv.org/pdf/2401.13270v2",
      "published_date": "2024-01-24 07:22:05 UTC",
      "updated_date": "2024-12-18 02:43:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:08:34.323622"
    },
    {
      "arxiv_id": "2401.13262v1",
      "title": "Designing Redistribution Mechanisms for Reducing Transaction Fees in Blockchains",
      "title_zh": "设计区块链交易费用重分配机制以减少交易费用",
      "authors": [
        "Sankarshan Damle",
        "Manisha Padala",
        "Sujit Gujar"
      ],
      "abstract": "Blockchains deploy Transaction Fee Mechanisms (TFMs) to determine which user\ntransactions to include in blocks and determine their payments (i.e.,\ntransaction fees). Increasing demand and scarce block resources have led to\nhigh user transaction fees. As these blockchains are a public resource, it may\nbe preferable to reduce these transaction fees. To this end, we introduce\nTransaction Fee Redistribution Mechanisms (TFRMs) -- redistributing VCG\npayments collected from such TFM as rebates to minimize transaction fees.\nClassic redistribution mechanisms (RMs) achieve this while ensuring Allocative\nEfficiency (AE) and User Incentive Compatibility (UIC). Our first result shows\nthe non-triviality of applying RM in TFMs. More concretely, we prove that it is\nimpossible to reduce transaction fees when (i) transactions that are not\nconfirmed do not receive rebates and (ii) the miner can strategically\nmanipulate the mechanism. Driven by this, we propose \\emph{Robust} TFRM\n(\\textsf{R-TFRM}): a mechanism that compromises on an honest miner's individual\nrationality to guarantee strictly positive rebates to the users. We then\nintroduce \\emph{robust} and \\emph{rational} TFRM (\\textsf{R}$^2$\\textsf{-TFRM})\nthat uses trusted on-chain randomness that additionally guarantees miner's\nindividual rationality (in expectation) and strictly positive rebates. Our\nresults show that TFRMs provide a promising new direction for reducing\ntransaction fees in public blockchains.",
      "tldr_zh": "该研究针对区块链中高交易费问题，设计了交易费再分配机制（TFRMs），通过再分配 VCG 支付作为返还来降低用户交易费，同时保持分配效率（AE）和用户激励兼容性（UIC）。作者证明，在未确认交易不获返还且矿工可操纵机制的条件下，减少交易费是不可能的，因此提出 Robust TFRM（R-TFRM），以牺牲诚实矿工个别理性为代价，确保用户获得正返还。进一步，他们引入 robust and rational TFRM（R²-TFRM），利用可信链上随机性，在预期上保证矿工个别理性并提供正返还。这些机制为公共区块链减少交易费提供了有前景的新方向。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.GT",
      "comment": "Full Paper (AAMAS '24)",
      "pdf_url": "http://arxiv.org/pdf/2401.13262v1",
      "published_date": "2024-01-24 07:09:32 UTC",
      "updated_date": "2024-01-24 07:09:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:08:46.868692"
    },
    {
      "arxiv_id": "2401.13256v3",
      "title": "UniMS-RAG: A Unified Multi-source Retrieval-Augmented Generation for Personalized Dialogue Systems",
      "title_zh": "UniMS-RAG：统一的多源检索增强生成，用于个性化对话系统",
      "authors": [
        "Hongru Wang",
        "Wenyu Huang",
        "Yang Deng",
        "Rui Wang",
        "Zezhong Wang",
        "Yufei Wang",
        "Fei Mi",
        "Jeff Z. Pan",
        "Kam-Fai Wong"
      ],
      "abstract": "Large Language Models (LLMs) has shown exceptional capabilities in many\nnatual language understanding and generation tasks. However, the\npersonalization issue still remains a much-coveted property, especially when it\ncomes to the multiple sources involved in the dialogue system. To better plan\nand incorporate the use of multiple sources in generating personalized\nresponse, we firstly decompose it into three sub-tasks: Knowledge Source\nSelection, Knowledge Retrieval, and Response Generation. We then propose a\nnovel Unified Multi-Source Retrieval-Augmented Generation system (UniMS-RAG)\nSpecifically, we unify these three sub-tasks with different formulations into\nthe same sequence-to-sequence paradigm during the training, to adaptively\nretrieve evidences and evaluate the relevance on-demand using special tokens,\ncalled acting tokens and evaluation tokens. Enabling language models to\ngenerate acting tokens facilitates interaction with various knowledge sources,\nallowing them to adapt their behavior to diverse task requirements. Meanwhile,\nevaluation tokens gauge the relevance score between the dialogue context and\nthe retrieved evidence. In addition, we carefully design a self-refinement\nmechanism to iteratively refine the generated response considering 1) the\nconsistency scores between the generated response and retrieved evidence; and\n2) the relevance scores. Experiments on two personalized datasets (DuLeMon and\nKBP) show that UniMS-RAG achieves state-of-the-art performance on the knowledge\nsource selection and response generation task with itself as a retriever in a\nunified manner. Extensive analyses and discussions are provided for shedding\nsome new perspectives for personalized dialogue systems.",
      "tldr_zh": "该研究针对大型语言模型（LLMs）在多来源个性化对话系统中的个性化问题，提出了一种统一的UniMS-RAG系统，将知识来源选择、知识检索和响应生成三个子任务整合到sequence-to-sequence范式中。系统通过acting tokens和evaluation tokens实现适应性证据检索和相关性评估，允许模型根据任务需求互动并评估对话上下文与证据的相关性。此外，UniMS-RAG引入自精炼机制，利用一致性和相关性分数迭代优化响应生成。实验在DuLeMon和KBP数据集上表明，该系统在知识来源选择和响应生成任务上实现了最先进性能，并为个性化对话系统提供了新视角。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13256v3",
      "published_date": "2024-01-24 06:50:20 UTC",
      "updated_date": "2024-11-26 12:37:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:08:56.971175"
    },
    {
      "arxiv_id": "2402.08429v1",
      "title": "Is 3-(F)WL Enough to Distinguish All 3D Graphs?",
      "title_zh": "翻译失败",
      "authors": [
        "Wanghan Xu"
      ],
      "abstract": "The problem of graph isomorphism is an important but challenging problem in\nthe field of graph analysis, for example: analyzing the similarity of two\nchemical molecules, or studying the expressive ability of graph neural\nnetworks. WL test is a method to judge whether two graphs are isomorphic, but\nit cannot distinguish all non-isomorphic graphs. As an improvement of WL, k-WL\nhas stronger isomorphism discrimination ability, and as k increases, its\ndiscrimination ability is strictly increasing. However, whether the isomorphic\ndiscrimination power of k-WL is strictly increasing for more complex 3D graphs,\nor whether there exists k that can discriminate all 3D graphs, remains\nunexplored. This paper attempts to explore this problem from the perspective of\ngraph generation.",
      "tldr_zh": "这篇论文探讨了在 3D Graphs 上，3-(F)WL 是否能有效区分所有非同构图的问题，针对图同构(Graph Isomorphism)这一图分析领域的挑战，如化学分子相似性分析或图神经网络的表达能力。论文回顾了 WL Test 的局限性及其改进版 k-WL 的增强区分能力，随着 k 增加其能力严格提升，但对 3D Graphs 是否同样适用尚未明确。作者从图生成(Graph Generation)的视角进行探索，旨在评估 k-WL 是否存在能完全区分所有 3D Graphs 的值，从而推进相关理论研究。",
      "categories": [
        "cs.OH",
        "cs.AI"
      ],
      "primary_category": "cs.OH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08429v1",
      "published_date": "2024-01-24 06:22:08 UTC",
      "updated_date": "2024-01-24 06:22:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:09:12.116615"
    },
    {
      "arxiv_id": "2402.09427v2",
      "title": "DoorINet: Door Heading Prediction through Inertial Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Aleksei Zakharchenko",
        "Sharon Farber",
        "Itzik Klein"
      ],
      "abstract": "Inertial sensors are widely used in a variety of applications. A common task\nis orientation estimation. To tackle such a task, attitude and heading\nreference system algorithms are applied. Relying on the gyroscope readings, the\naccelerometer measurements are used to update the attitude angles, and\nmagnetometer measurements are utilized to update the heading angle. In indoor\nenvironments, magnetometers suffer from interference that degrades their\nperformance resulting in poor heading angle estimation. Therefore, applications\nthat estimate the heading angle of moving objects, such as walking pedestrians,\nclosets, and refrigerators, are prone to error. To circumvent such situations,\nwe propose DoorINet, an end-to-end deep-learning framework to calculate the\nheading angle from door-mounted, low-cost inertial sensors without using\nmagnetometers. To evaluate our approach, we record a unique dataset containing\n391 minutes of accelerometer and gyroscope measurements and corresponding\nground-truth heading angle. We show that our proposed approach outperforms\ncommonly used, model based approaches and data-driven methods.",
      "tldr_zh": "本研究针对室内环境磁力计（magnetometers）干扰导致的航向角估计错误问题，提出DoorINet，一种基于惯性深度学习（Inertial Deep Learning）的端到端框架。该框架利用门安装的低成本惯性传感器，仅依赖加速度计（accelerometer）和陀螺仪（gyroscope）数据来预测物体航向角，而无需磁力计。研究者收集了一个包含391分钟传感器测量和地面真实航向角的独特数据集，结果显示DoorINet在性能上优于传统的基于模型的AHRS算法和数据驱动方法。总的来说，这一方法为可靠的室内方向估计提供了新途径。",
      "categories": [
        "eess.SP",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "eess.SP",
      "comment": "10 pages, 14 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.09427v2",
      "published_date": "2024-01-24 05:28:29 UTC",
      "updated_date": "2024-12-01 08:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:09:23.120725"
    },
    {
      "arxiv_id": "2401.13229v1",
      "title": "From Random to Informed Data Selection: A Diversity-Based Approach to Optimize Human Annotation and Few-Shot Learning",
      "title_zh": "从随机到知情数据选择：一种基于多样性的方法来优化人类标注和少样本学习",
      "authors": [
        "Alexandre Alcoforado",
        "Thomas Palmeira Ferraz",
        "Lucas Hideki Okamura",
        "Israel Campos Fama",
        "Arnold Moya Lavado",
        "Bárbara Dias Bueno",
        "Bruno Veloso",
        "Anna Helena Reali Costa"
      ],
      "abstract": "A major challenge in Natural Language Processing is obtaining annotated data\nfor supervised learning. An option is the use of crowdsourcing platforms for\ndata annotation. However, crowdsourcing introduces issues related to the\nannotator's experience, consistency, and biases. An alternative is to use\nzero-shot methods, which in turn have limitations compared to their few-shot or\nfully supervised counterparts. Recent advancements driven by large language\nmodels show potential, but struggle to adapt to specialized domains with\nseverely limited data. The most common approaches therefore involve the human\nitself randomly annotating a set of datapoints to build initial datasets. But\nrandomly sampling data to be annotated is often inefficient as it ignores the\ncharacteristics of the data and the specific needs of the model. The situation\nworsens when working with imbalanced datasets, as random sampling tends to\nheavily bias towards the majority classes, leading to excessive annotated data.\nTo address these issues, this paper contributes an automatic and informed data\nselection architecture to build a small dataset for few-shot learning. Our\nproposal minimizes the quantity and maximizes diversity of data selected for\nhuman annotation, while improving model performance.",
      "tldr_zh": "这篇论文针对自然语言处理（Natural Language Processing）中获取标注数据的挑战，指出随机采样方法低效，尤其在不平衡数据集上容易偏向多数类，导致过度标注和模型偏差。作者提出了一种基于多样性的数据选择方法（Diversity-Based Approach），通过自动架构最小化人类标注量并最大化数据多样性，以构建高效的小数据集。实验结果显示，该方法显著优化了 few-shot learning 的性能，提高了模型的适应性和整体效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at PROPOR 2024 - The 16th International Conference on\n  Computational Processing of Portuguese",
      "pdf_url": "http://arxiv.org/pdf/2401.13229v1",
      "published_date": "2024-01-24 04:57:32 UTC",
      "updated_date": "2024-01-24 04:57:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:09:33.083901"
    },
    {
      "arxiv_id": "2401.13227v3",
      "title": "LPNL: Scalable Link Prediction with Large Language Models",
      "title_zh": "LPNL：使用大型语言模型",
      "authors": [
        "Baolong Bi",
        "Shenghua Liu",
        "Yiwei Wang",
        "Lingrui Mei",
        "Xueqi Cheng"
      ],
      "abstract": "Exploring the application of large language models (LLMs) to graph learning\nis a emerging endeavor. However, the vast amount of information inherent in\nlarge graphs poses significant challenges to this process. This work focuses on\nthe link prediction task and introduces $\\textbf{LPNL}$ (Link Prediction via\nNatural Language), a framework based on large language models designed for\nscalable link prediction on large-scale heterogeneous graphs. We design novel\nprompts for link prediction that articulate graph details in natural language.\nWe propose a two-stage sampling pipeline to extract crucial information from\nthe graphs, and a divide-and-conquer strategy to control the input tokens\nwithin predefined limits, addressing the challenge of overwhelming information.\nWe fine-tune a T5 model based on our self-supervised learning designed for link\nprediction. Extensive experimental results demonstrate that LPNL outperforms\nmultiple advanced baselines in link prediction tasks on large-scale graphs.",
      "tldr_zh": "这篇论文介绍了 LPNL 框架，一种基于大型语言模型 (LLMs) 的可扩展链接预测方法，针对大规模异构图的链接预测任务设计。框架通过新型提示将图细节表述为自然语言，并采用两阶段采样管道和分治策略来提取关键信息并控制输入标记数量，同时微调 T5 模型以自监督学习方式优化预测。实验结果显示，LPNL 在大型图的链接预测任务中优于多个高级基线，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.SI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13227v3",
      "published_date": "2024-01-24 04:50:16 UTC",
      "updated_date": "2024-02-20 03:53:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:09:45.632056"
    },
    {
      "arxiv_id": "2401.13223v3",
      "title": "TAT-LLM: A Specialized Language Model for Discrete Reasoning over Tabular and Textual Data",
      "title_zh": "TAT-LLM：针对表格和文本数据的离散推理专用语言模型",
      "authors": [
        "Fengbin Zhu",
        "Ziyang Liu",
        "Fuli Feng",
        "Chao Wang",
        "Moxin Li",
        "Tat-Seng Chua"
      ],
      "abstract": "In this work, we address question answering (QA) over a hybrid of tabular and\ntextual data that are very common content on the Web (e.g. SEC filings), where\ndiscrete reasoning capabilities are often required. Recently, large language\nmodels (LLMs) like GPT-4 have demonstrated strong multi-step reasoning\ncapabilities. We then consider harnessing the amazing power of LLMs to solve\nour task. We abstract a Step-wise Pipeline for tabular and textual QA, which\nconsists of three key steps, including Extractor, Reasoner and Executor, and\ninitially design an instruction to instantiate the pipeline and validate that\nGPT-4 outperforms all existing methods. However, utilizing an online LLM like\nGPT-4 holds various challenges in terms of cost, latency, and data security\nrisk, which motivates us to specialize smaller LLMs in this task. We develop a\nTAT-LLM language model by fine-tuning LLaMA 2 with the training data generated\nautomatically from existing expert-annotated datasets following the Step-wise\nPipeline. The experimental results have verified that our TAT-LLM model can\noutperform all baseline models, including the previous best fine-tuned models\nand very large-scale LLMs like GPT-4 on FinQA, TAT-QA and TAT-DQA benchmarks.",
      "tldr_zh": "这篇论文针对表格和文本混合数据的问答任务，提出了TAT-LLM，一种专门用于离散推理的语言模型，以解决此类常见Web内容（如SEC filings）中的推理挑战。作者设计了Step-wise Pipeline，包括Extractor、Reasoner和Executor三个关键步骤，并通过微调LLaMA 2模型，使用自动生成的数据进行训练，以克服使用GPT-4的成本、延迟和安全问题。实验结果表明，TAT-LLM在FinQA、TAT-QA和TAT-DQA基准上超越了GPT-4和其他基线模型，展示了其高效性和优越性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by ICAIF 24",
      "pdf_url": "http://arxiv.org/pdf/2401.13223v3",
      "published_date": "2024-01-24 04:28:50 UTC",
      "updated_date": "2024-09-28 01:40:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:09:58.038484"
    },
    {
      "arxiv_id": "2401.13219v1",
      "title": "TEPI: Taxonomy-aware Embedding and Pseudo-Imaging for Scarcely-labeled Zero-shot Genome Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Sathyanarayanan Aakur",
        "Vishalini R. Laguduva",
        "Priyadharsini Ramamurthy",
        "Akhilesh Ramachandran"
      ],
      "abstract": "A species' genetic code or genome encodes valuable evolutionary, biological,\nand phylogenetic information that aids in species recognition, taxonomic\nclassification, and understanding genetic predispositions like drug resistance\nand virulence. However, the vast number of potential species poses significant\nchallenges in developing a general-purpose whole genome classification tool.\nTraditional bioinformatics tools have made notable progress but lack\nscalability and are computationally expensive. Machine learning-based\nframeworks show promise but must address the issue of large classification\nvocabularies with long-tail distributions. In this study, we propose addressing\nthis problem through zero-shot learning using TEPI, Taxonomy-aware Embedding\nand Pseudo-Imaging. We represent each genome as pseudo-images and map them to a\ntaxonomy-aware embedding space for reasoning and classification. This embedding\nspace captures compositional and phylogenetic relationships of species,\nenabling predictions in extensive search spaces. We evaluate TEPI using two\nrigorous zero-shot settings and demonstrate its generalization capabilities\nqualitatively on curated, large-scale, publicly sourced data.",
      "tldr_zh": "本研究针对基因组分类面临的挑战，包括大量物种的系统发育信息处理和标签稀缺问题，提出TEPI框架，即Taxonomy-aware Embedding and Pseudo-Imaging方法。TEPI通过将基因组表示为pseudo-images，并映射到taxonomy-aware embedding space，捕捉物种的组合和系统发育关系，从而实现零样本学习和大规模预测。实验在两个严格的零样本设置下评估了TEPI的泛化能力，并在大型公共数据上进行了定性验证，展示了其在高效基因组分类中的潜力。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "Accepted to IEEE JBHI",
      "pdf_url": "http://arxiv.org/pdf/2401.13219v1",
      "published_date": "2024-01-24 04:16:28 UTC",
      "updated_date": "2024-01-24 04:16:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:10:09.718801"
    },
    {
      "arxiv_id": "2401.13214v1",
      "title": "AMANet: Advancing SAR Ship Detection with Adaptive Multi-Hierarchical Attention Network",
      "title_zh": "AMANet：利用自适应多层次注意力网络推进 SAR 船舶检测",
      "authors": [
        "Xiaolin Ma",
        "Junkai Cheng",
        "Aihua Li",
        "Yuhua Zhang",
        "Zhilong Lin"
      ],
      "abstract": "Recently, methods based on deep learning have been successfully applied to\nship detection for synthetic aperture radar (SAR) images. Despite the\ndevelopment of numerous ship detection methodologies, detecting small and\ncoastal ships remains a significant challenge due to the limited features and\nclutter in coastal environments. For that, a novel adaptive multi-hierarchical\nattention module (AMAM) is proposed to learn multi-scale features and\nadaptively aggregate salient features from various feature layers, even in\ncomplex environments. Specifically, we first fuse information from adjacent\nfeature layers to enhance the detection of smaller targets, thereby achieving\nmulti-scale feature enhancement. Then, to filter out the adverse effects of\ncomplex backgrounds, we dissect the previously fused multi-level features on\nthe channel, individually excavate the salient regions, and adaptively\namalgamate features originating from different channels. Thirdly, we present a\nnovel adaptive multi-hierarchical attention network (AMANet) by embedding the\nAMAM between the backbone network and the feature pyramid network (FPN).\nBesides, the AMAM can be readily inserted between different frameworks to\nimprove object detection. Lastly, extensive experiments on two large-scale SAR\nship detection datasets demonstrate that our AMANet method is superior to\nstate-of-the-art methods.",
      "tldr_zh": "该研究针对合成孔径雷达(SAR)图像中船舶检测的挑战，特别是小船和沿海环境的复杂背景干扰，提出了一种新型的自适应多层次注意力模块(AMAM)。AMAM 通过融合相邻特征层的信息实现多尺度特征增强，并对多级特征进行通道级分解，以自适应地挖掘和聚合显著区域，从而过滤复杂背景的不利影响。最终，构建了自适应多层次注意力网络(AMANet)，将 AMAM 嵌入主干网络和特征金字塔网络(FPN)之间，并在两个大规模 SAR 船舶检测数据集上实验证明，该方法优于现有最先进技术。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "68T45",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.13214v1",
      "published_date": "2024-01-24 03:56:33 UTC",
      "updated_date": "2024-01-24 03:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:10:22.304925"
    },
    {
      "arxiv_id": "2401.13212v1",
      "title": "AdCorDA: Classifier Refinement via Adversarial Correction and Domain Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Lulan Shen",
        "Ali Edalati",
        "Brett Meyer",
        "Warren Gross",
        "James J. Clark"
      ],
      "abstract": "This paper describes a simple yet effective technique for refining a\npretrained classifier network. The proposed AdCorDA method is based on\nmodification of the training set and making use of the duality between network\nweights and layer inputs. We call this input space training. The method\nconsists of two stages - adversarial correction followed by domain adaptation.\nAdversarial correction uses adversarial attacks to correct incorrect\ntraining-set classifications. The incorrectly classified samples of the\ntraining set are removed and replaced with the adversarially corrected samples\nto form a new training set, and then, in the second stage, domain adaptation is\nperformed back to the original training set. Extensive experimental validations\nshow significant accuracy boosts of over 5% on the CIFAR-100 dataset. The\ntechnique can be straightforwardly applied to refinement of weight-quantized\nneural networks, where experiments show substantial enhancement in performance\nover the baseline. The adversarial correction technique also results in\nenhanced robustness to adversarial attacks.",
      "tldr_zh": "本文提出 AdCorDA 方法，一种简单有效的技术，用于通过输入空间训练（input space training）精炼预训练分类器网络。该方法分为两个阶段：首先进行对抗修正（adversarial correction），利用对抗攻击修正训练集中的错误分类，并替换样本；其次执行领域适应（domain adaptation）回原训练集。实验结果显示，在 CIFAR-100 数据集上准确率提升超过 5%，并显著增强了模型对对抗攻击的鲁棒性，同时适用于权重量化神经网络的优化。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13212v1",
      "published_date": "2024-01-24 03:49:51 UTC",
      "updated_date": "2024-01-24 03:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:10:33.770026"
    },
    {
      "arxiv_id": "2401.13205v1",
      "title": "Boosting the Transferability of Adversarial Examples via Local Mixup and Adaptive Step Size",
      "title_zh": "翻译失败",
      "authors": [
        "Junlin Liu",
        "Xinchen Lyu"
      ],
      "abstract": "Adversarial examples are one critical security threat to various visual\napplications, where injected human-imperceptible perturbations can confuse the\noutput.Generating transferable adversarial examples in the black-box setting is\ncrucial but challenging in practice. Existing input-diversity-based methods\nadopt different image transformations, but may be inefficient due to\ninsufficient input diversity and an identical perturbation step size. Motivated\nby the fact that different image regions have distinctive weights in\nclassification, this paper proposes a black-box adversarial generative\nframework by jointly designing enhanced input diversity and adaptive step\nsizes. We design local mixup to randomly mix a group of transformed adversarial\nimages, strengthening the input diversity. For precise adversarial generation,\nwe project the perturbation into the $tanh$ space to relax the boundary\nconstraint. Moreover, the step sizes of different regions can be dynamically\nadjusted by integrating a second-order momentum.Extensive experiments on\nImageNet validate that our framework can achieve superior transferability\ncompared to state-of-the-art baselines.",
      "tldr_zh": "该论文针对对抗样本（adversarial examples）对视觉应用的潜在威胁，提出了一种黑盒生成框架，以提升对抗样本的可转移性（transferability）。框架通过引入 local mixup 方法随机混合变换后的图像组，增强输入多样性，并采用 adaptive step size 动态调整不同区域的扰动步长，同时将扰动投影到 tanh 空间以放松边界约束。实验结果显示，该框架在 ImageNet 数据集上比现有最先进基线实现了更高的可转移性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13205v1",
      "published_date": "2024-01-24 03:26:34 UTC",
      "updated_date": "2024-01-24 03:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:10:45.488852"
    },
    {
      "arxiv_id": "2402.01695v3",
      "title": "Language-Guided World Models: A Model-Based Approach to AI Control",
      "title_zh": "语言引导的世界模型：一种基于模型的方法用于 AI 控制",
      "authors": [
        "Alex Zhang",
        "Khanh Nguyen",
        "Jens Tuyls",
        "Albert Lin",
        "Karthik Narasimhan"
      ],
      "abstract": "This paper introduces the concept of Language-Guided World Models (LWMs) --\nprobabilistic models that can simulate environments by reading texts. Agents\nequipped with these models provide humans with more extensive and efficient\ncontrol, allowing them to simultaneously alter agent behaviors in multiple\ntasks via natural verbal communication. In this work, we take initial steps in\ndeveloping robust LWMs that can generalize to compositionally novel language\ndescriptions. We design a challenging world modeling benchmark based on the\ngame of MESSENGER (Hanjie et al., 2021), featuring evaluation settings that\nrequire varying degrees of compositional generalization. Our experiments reveal\nthe lack of generalizability of the state-of-the-art Transformer model, as it\noffers marginal improvements in simulation quality over a no-text baseline. We\ndevise a more robust model by fusing the Transformer with the EMMA attention\nmechanism (Hanjie et al., 2021). Our model substantially outperforms the\nTransformer and approaches the performance of a model with an oracle semantic\nparsing and grounding capability. To demonstrate the practicality of this model\nin improving AI safety and transparency, we simulate a scenario in which the\nmodel enables an agent to present plans to a human before execution, and to\nrevise plans based on their language feedback.",
      "tldr_zh": "这篇论文提出了 Language-Guided World Models (LWMs)，一种通过文本阅读来模拟环境的概率模型，以增强人类对 AI 代理的控制，允许通过自然语言同时调整多个任务的行为。研究者设计了基于 MESSENGER 游戏的基准测试，评估模型在组合性泛化方面的性能，并发现标准 Transformer 模型的泛化能力有限，仅略优于无文本基准。作者开发了一种融合 Transformer 和 EMMA attention 机制的更鲁棒模型，显著提升了模拟质量，几乎达到理想语义解析水平的性能，并在 AI 安全场景中展示了其实际应用，如代理展示计划并根据人类反馈修改。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "SpLU-RoboNLP workshop at ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.01695v3",
      "published_date": "2024-01-24 03:11:36 UTC",
      "updated_date": "2024-09-04 19:13:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:10:58.958074"
    },
    {
      "arxiv_id": "2401.13201v3",
      "title": "MLLMReID: Multimodal Large Language Model-based Person Re-identification",
      "title_zh": "MLLMReID：基于多模态大语言模型的人员再识别",
      "authors": [
        "Shan Yang",
        "Yongfei Zhang"
      ],
      "abstract": "Multimodal large language models (MLLM) have achieved satisfactory results in\nmany tasks. However, their performance in the task of ReID (ReID) has not been\nexplored to date. This paper will investigate how to adapt them for the task of\nReID. An intuitive idea is to fine-tune MLLM with ReID image-text datasets, and\nthen use their visual encoder as a backbone for ReID. However, there still\nexist two apparent issues: (1) Designing instructions for ReID, MLLMs may\noverfit specific instructions, and designing a variety of instructions will\nlead to higher costs. (2) When fine-tuning the visual encoder of a MLLM, it is\nnot trained synchronously with the ReID task. As a result, the effectiveness of\nthe visual encoder fine-tuning cannot be directly reflected in the performance\nof the ReID task. To address these problems, this paper proposes MLLMReID:\nMultimodal Large Language Model-based ReID. Firstly, we proposed Common\nInstruction, a simple approach that leverages the essence ability of LLMs to\ncontinue writing, avoiding complex and diverse instruction design. Secondly, we\npropose a multi-task learning-based synchronization module to ensure that the\nvisual encoder of the MLLM is trained synchronously with the ReID task. The\nexperimental results demonstrate the superiority of our method.",
      "tldr_zh": "这篇论文探讨了如何将 Multimodal Large Language Models (MLLMs) 应用于 Person Re-identification (ReID) 任务，并提出 MLLMReID 方法来提升其性能。论文针对现有问题——指令设计可能导致过拟合以及视觉编码器未与 ReID 任务同步训练——引入 Common Instruction 策略，利用 LLMs 的续写能力简化指令设计，以及多任务学习-based synchronization module 确保编码器同步训练。实验结果显示，该方法在 ReID 任务上优于基线模型，证明了其有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13201v3",
      "published_date": "2024-01-24 03:07:26 UTC",
      "updated_date": "2024-06-10 10:21:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:11:11.988181"
    },
    {
      "arxiv_id": "2401.13193v1",
      "title": "Catch-Up Mix: Catch-Up Class for Struggling Filters in CNN",
      "title_zh": "翻译失败",
      "authors": [
        "Minsoo Kang",
        "Minkoo Kang",
        "Suhyun Kim"
      ],
      "abstract": "Deep learning has made significant advances in computer vision, particularly\nin image classification tasks. Despite their high accuracy on training data,\ndeep learning models often face challenges related to complexity and\noverfitting. One notable concern is that the model often relies heavily on a\nlimited subset of filters for making predictions. This dependency can result in\ncompromised generalization and an increased vulnerability to minor variations.\nWhile regularization techniques like weight decay, dropout, and data\naugmentation are commonly used to address this issue, they may not directly\ntackle the reliance on specific filters. Our observations reveal that the heavy\nreliance problem gets severe when slow-learning filters are deprived of\nlearning opportunities due to fast-learning filters. Drawing inspiration from\nimage augmentation research that combats over-reliance on specific image\nregions by removing and replacing parts of images, our idea is to mitigate the\nproblem of over-reliance on strong filters by substituting highly activated\nfeatures. To this end, we present a novel method called Catch-up Mix, which\nprovides learning opportunities to a wide range of filters during training,\nfocusing on filters that may lag behind. By mixing activation maps with\nrelatively lower norms, Catch-up Mix promotes the development of more diverse\nrepresentations and reduces reliance on a small subset of filters. Experimental\nresults demonstrate the superiority of our method in various vision\nclassification datasets, providing enhanced robustness.",
      "tldr_zh": "这篇论文针对 CNN 中过滤器的过度依赖问题，提出了一种名为 Catch-Up Mix 的新方法，通过混合激活映射（尤其是规范较低的映射）来为慢速学习的过滤器提供更多学习机会，从而缓解模型对特定过滤器的依赖并促进更多样化的特征表示。传统正则化技术如权重衰减和 dropout 无法直接解决这一问题，而 Catch-Up Mix 受图像增强启发，通过替换高度激活的特征来平衡过滤器学习。实验结果显示，该方法在各种视觉分类数据集上显著提升了模型的鲁棒性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at AAAI2024, Equal contribution of first two authors",
      "pdf_url": "http://arxiv.org/pdf/2401.13193v1",
      "published_date": "2024-01-24 02:42:50 UTC",
      "updated_date": "2024-01-24 02:42:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:11:24.650540"
    },
    {
      "arxiv_id": "2401.13192v3",
      "title": "Generative Design of Crystal Structures by Point Cloud Representations and Diffusion Model",
      "title_zh": "翻译失败",
      "authors": [
        "Zhelin Li",
        "Rami Mrad",
        "Runxian Jiao",
        "Guan Huang",
        "Jun Shan",
        "Shibing Chu",
        "Yuanping Chen"
      ],
      "abstract": "Efficiently generating energetically stable crystal structures has long been\na challenge in material design, primarily due to the immense arrangement of\natoms in a crystal lattice. To facilitate the discovery of stable material, we\npresent a framework for the generation of synthesizable materials, leveraging a\npoint cloud representation to encode intricate structural information. At the\nheart of this framework lies the introduction of a diffusion model as its\nfoundational pillar. To gauge the efficacy of our approach, we employ it to\nreconstruct input structures from our training datasets, rigorously validating\nits high reconstruction performance. Furthermore, we demonstrate the profound\npotential of Point Cloud-Based Crystal Diffusion (PCCD) by generating entirely\nnew materials, emphasizing their synthesizability. Our research stands as a\nnoteworthy contribution to the advancement of materials design and synthesis\nthrough the cutting-edge avenue of generative design instead of the\nconventional substitution or experience-based discovery.",
      "tldr_zh": "本研究针对高效生成能量稳定晶体结构面临的挑战，提出了一种框架，使用point cloud representation编码复杂结构信息，并以diffusion model为核心进行生成式设计。该框架通过重建训练数据集的输入结构，验证了其高重建性能，并成功生成全新的可合成材料。相比传统的替代或经验-based方法，此创新方法显著推进了材料设计和合成的进步。",
      "categories": [
        "cs.AI",
        "cond-mat.mtrl-sci",
        "cs.LG",
        "physics.comp-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "I have submitted to a journal",
      "pdf_url": "http://arxiv.org/pdf/2401.13192v3",
      "published_date": "2024-01-24 02:36:52 UTC",
      "updated_date": "2024-08-30 06:49:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:11:34.787379"
    },
    {
      "arxiv_id": "2401.13178v2",
      "title": "AgentBoard: An Analytical Evaluation Board of Multi-turn LLM Agents",
      "title_zh": "AgentBoard：多轮 LLM 代理的分析评估板",
      "authors": [
        "Chang Ma",
        "Junlei Zhang",
        "Zhihao Zhu",
        "Cheng Yang",
        "Yujiu Yang",
        "Yaohui Jin",
        "Zhenzhong Lan",
        "Lingpeng Kong",
        "Junxian He"
      ],
      "abstract": "Evaluating Large Language Models (LLMs) as general-purpose agents is\nessential for understanding their capabilities and facilitating their\nintegration into practical applications. However, the evaluation process\npresents substantial challenges. A primary obstacle is the benchmarking of\nagent performance across diverse scenarios within a unified framework,\nespecially in maintaining partially-observable environments and ensuring\nmulti-round interactions. Moreover, current evaluation frameworks mostly focus\non the final success rate, revealing few insights during the process and\nfailing to provide a deep understanding of the model abilities. To address\nthese challenges, we introduce AgentBoard, a pioneering comprehensive benchmark\nand accompanied open-source evaluation framework tailored to analytical\nevaluation of LLM agents. AgentBoard offers a fine-grained progress rate metric\nthat captures incremental advancements as well as a comprehensive evaluation\ntoolkit that features easy assessment of agents for multi-faceted analysis.\nThis not only sheds light on the capabilities and limitations of LLM agents but\nalso propels the interpretability of their performance to the forefront.\nUltimately, AgentBoard serves as a step towards demystifying agent behaviors\nand accelerating the development of stronger LLM agents.",
      "tldr_zh": "本论文提出了 AgentBoard，一种全面的开源评估框架，旨在评估大型语言模型 (LLMs) 作为多轮代理的能力，解决现有基准在跨场景测试、多轮交互和部分可观察环境中的挑战。AgentBoard 引入细粒度的进展率指标（fine-grained progress rate metric）和多方面分析工具，能够捕捉代理过程的增量进展，并提供对模型能力的深入解读。该框架不仅揭示了 LLM 代理的优点和局限性，还提升了性能的可解释性，推动更强代理的开发。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "NeurIPS 2024 (Oral)",
      "pdf_url": "http://arxiv.org/pdf/2401.13178v2",
      "published_date": "2024-01-24 01:51:00 UTC",
      "updated_date": "2024-12-23 20:12:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:11:48.057992"
    },
    {
      "arxiv_id": "2401.13171v2",
      "title": "Compositional Generative Inverse Design",
      "title_zh": "翻译失败",
      "authors": [
        "Tailin Wu",
        "Takashi Maruyama",
        "Long Wei",
        "Tao Zhang",
        "Yilun Du",
        "Gianluca Iaccarino",
        "Jure Leskovec"
      ],
      "abstract": "Inverse design, where we seek to design input variables in order to optimize\nan underlying objective function, is an important problem that arises across\nfields such as mechanical engineering to aerospace engineering. Inverse design\nis typically formulated as an optimization problem, with recent works\nleveraging optimization across learned dynamics models. However, as models are\noptimized they tend to fall into adversarial modes, preventing effective\nsampling. We illustrate that by instead optimizing over the learned energy\nfunction captured by the diffusion model, we can avoid such adversarial\nexamples and significantly improve design performance. We further illustrate\nhow such a design system is compositional, enabling us to combine multiple\ndifferent diffusion models representing subcomponents of our desired system to\ndesign systems with every specified component. In an N-body interaction task\nand a challenging 2D multi-airfoil design task, we demonstrate that by\ncomposing the learned diffusion model at test time, our method allows us to\ndesign initial states and boundary shapes that are more complex than those in\nthe training data. Our method generalizes to more objects for N-body dataset\nand discovers formation flying to minimize drag in the multi-airfoil design\ntask. Project website and code can be found at\nhttps://github.com/AI4Science-WestlakeU/cindm.",
      "tldr_zh": "本研究提出了一种可组合的生成逆设计（Compositional Generative Inverse Design）方法，通过优化扩散模型（diffusion model）的能量函数（energy function），避免了传统优化在学习动态模型时遇到的对抗示例问题，从而提升设计性能。该方法允许将多个扩散模型组合起来，代表系统子组件，以设计更复杂的系统。在 N-body interaction 任务和 2D multi-airfoil design 任务中，实验证明该方法能生成比训练数据更复杂的初始状态和边界形状，并实现了对更多对象的泛化，如发现最小阻力编队飞行。该框架为工程领域如机械和航空提供更高效的设计工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "ICLR 2024 spotlight. 30 pages, 17 figures",
      "pdf_url": "http://arxiv.org/pdf/2401.13171v2",
      "published_date": "2024-01-24 01:33:39 UTC",
      "updated_date": "2024-03-11 15:25:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:11:58.827693"
    },
    {
      "arxiv_id": "2401.13713v1",
      "title": "EMP: Effective Multidimensional Persistence for Graph Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ignacio Segovia-Dominguez",
        "Yuzhou Chen",
        "Cuneyt G. Akcora",
        "Zhiwei Zhen",
        "Murat Kantarcioglu",
        "Yulia R. Gel",
        "Baris Coskunuzer"
      ],
      "abstract": "Topological data analysis (TDA) is gaining prominence across a wide spectrum\nof machine learning tasks that spans from manifold learning to graph\nclassification. A pivotal technique within TDA is persistent homology (PH),\nwhich furnishes an exclusive topological imprint of data by tracing the\nevolution of latent structures as a scale parameter changes. Present PH tools\nare confined to analyzing data through a single filter parameter. However, many\nscenarios necessitate the consideration of multiple relevant parameters to\nattain finer insights into the data. We address this issue by introducing the\nEffective Multidimensional Persistence (EMP) framework. This framework empowers\nthe exploration of data by simultaneously varying multiple scale parameters.\nThe framework integrates descriptor functions into the analysis process,\nyielding a highly expressive data summary. It seamlessly integrates established\nsingle PH summaries into multidimensional counterparts like EMP Landscapes,\nSilhouettes, Images, and Surfaces. These summaries represent data's\nmultidimensional aspects as matrices and arrays, aligning effectively with\ndiverse ML models. We provide theoretical guarantees and stability proofs for\nEMP summaries. We demonstrate EMP's utility in graph classification tasks,\nshowing its effectiveness. Results reveal that EMP enhances various single PH\ndescriptors, outperforming cutting-edge methods on multiple benchmark datasets.",
      "tldr_zh": "该论文提出了Effective Multidimensional Persistence (EMP)框架，用于拓扑数据分析(TDA)中的图表示学习，解决了传统持久同调(PH)工具仅限于单一过滤参数的局限性。EMP框架通过整合描述符函数，同时处理多个规模参数，将单维PH摘要扩展为多维形式，如EMP Landscapes、Silhouettes、Images和Surfaces，这些以矩阵和数组表示的数据摘要更适合机器学习(ML)模型。论文提供了理论保证和稳定性证明，并在图分类任务上实验验证，EMP显著提升了性能，在多个基准数据集上优于现有先进方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.LG",
      "comment": "arXiv admin note: text overlap with arXiv:2401.13157",
      "pdf_url": "http://arxiv.org/pdf/2401.13713v1",
      "published_date": "2024-01-24 00:41:51 UTC",
      "updated_date": "2024-01-24 00:41:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:12:11.694908"
    },
    {
      "arxiv_id": "2401.13157v1",
      "title": "Time-Aware Knowledge Representations of Dynamic Objects with Multidimensional Persistence",
      "title_zh": "翻译失败",
      "authors": [
        "Baris Coskunuzer",
        "Ignacio Segovia-Dominguez",
        "Yuzhou Chen",
        "Yulia R. Gel"
      ],
      "abstract": "Learning time-evolving objects such as multivariate time series and dynamic\nnetworks requires the development of novel knowledge representation mechanisms\nand neural network architectures, which allow for capturing implicit\ntime-dependent information contained in the data. Such information is typically\nnot directly observed but plays a key role in the learning task performance. In\nturn, lack of time dimension in knowledge encoding mechanisms for\ntime-dependent data leads to frequent model updates, poor learning performance,\nand, as a result, subpar decision-making. Here we propose a new approach to a\ntime-aware knowledge representation mechanism that notably focuses on implicit\ntime-dependent topological information along multiple geometric dimensions. In\nparticular, we propose a new approach, named \\textit{Temporal MultiPersistence}\n(TMP), which produces multidimensional topological fingerprints of the data by\nusing the existing single parameter topological summaries. The main idea behind\nTMP is to merge the two newest directions in topological representation\nlearning, that is, multi-persistence which simultaneously describes data shape\nevolution along multiple key parameters, and zigzag persistence to enable us to\nextract the most salient data shape information over time. We derive\ntheoretical guarantees of TMP vectorizations and show its utility, in\napplication to forecasting on benchmark traffic flow, Ethereum blockchain, and\nelectrocardiogram datasets, demonstrating the competitive performance,\nespecially, in scenarios of limited data records. In addition, our TMP method\nimproves the computational efficiency of the state-of-the-art multipersistence\nsummaries up to 59.5 times.",
      "tldr_zh": "这篇论文针对学习时间演化对象（如多变量时间序列和动态网络）的问题，提出了一种新的时间感知知识表示机制，以捕捉隐含的时间相关拓扑信息。作者开发了 Temporal MultiPersistence (TMP) 方法，通过整合 multi-persistence 和 zigzag persistence，生成多维拓扑指纹，从而同时描述数据形状在多个关键参数和时间上的演化。TMP 提供了向量化理论保证，并在交通流量、Ethereum 区块链和心电图数据集的预测任务中表现出色，尤其在数据记录有限的场景下，与现有方法相比提高了计算效率多达 59.5 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2401.13157v1",
      "published_date": "2024-01-24 00:33:53 UTC",
      "updated_date": "2024-01-24 00:33:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T00:12:24.370619"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 77,
  "processed_papers_count": 77,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T00:12:44.344214"
}