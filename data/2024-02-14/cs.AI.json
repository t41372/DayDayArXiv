{
  "date": "2024-02-14",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-02-14 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、强化学习、多模态生成（如 LLM 和图像处理）的创新应用，以及少量数学推理和医疗领域的进展。其中，LLM 的越狱攻击防御和偏好对齐（如 SafeDecoding 和 MaxMin-RLHF）是最令人印象深刻的主题，涉及知名学者如 Yejin Choi 和 Xuezhi Wang 的工作；这些论文突出了 LLM 在实际部署中的潜在风险和优化策略。\n\n下面，我挑选并简要概述了部分关键论文，先优先讨论 LLM 安全、对齐和强化学习相关的内容（这些有话题度和影响力），然后快速掠过其他领域的亮点。每个条目列出论文标题（中文 + 英文），并清晰描述主要贡献和发现。\n\n### LLM 安全与对齐\n- **SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding**（SafeDecoding: 通过安全感知解码防御越狱攻击）：提出一种安全感知解码策略，显著降低 LLM 越狱攻击成功率，同时保持对良性查询的响应质量，在实验中优于现有防御方法。\n- **Puzzler: Indirect Jailbreak Attack with Implicit Clues**（Puzzler: 通过隐式线索的间接越狱攻击）：探索间接越狱攻击方法，利用 LLM 内部线索诱导恶意响应，实验显示攻击成功率高达 96.6%，强调了 LLM 防御的复杂性。\n- **MaxMin-RLHF: Alignment with Diverse Human Preferences**（MaxMin-RLHF: 与多样化人类偏好对齐）：引入一种基于 Egalitarian 原则的强化学习框架，提升 LLM 与多样偏好的对齐效果，实验表明在多个任务中提升 16% 以上性能。\n- **Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation**（Self-Alignment for Factuality: 通过自评估缓解 LLM 幻觉）：设计自评估机制，让 LLM 自行校正事实性错误，在 TruthfulQA 等任务中显著减少幻觉。\n- **InfoRM: Mitigating Reward Hacking in RLHF via Information-Theoretic Reward Modeling**（InfoRM: 通过信息理论奖励建模缓解 RLHF 中的奖励黑客攻击）：使用信息瓶颈优化奖励模型，减少 LLM 奖励黑客问题，并在实验中证明其鲁棒性。\n- **ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization**（ICDPO: 通过上下文直接偏好优化借用他者对齐能力）：提出 LLM 间知识借用框架，提升偏好对齐效率，实验显示在推荐任务中性能提升明显。\n- **AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability**（AQA-Bench: 评估 LLM 顺序推理能力的交互基准）：构建交互基准测试 LLM 的顺序推理，揭示模型在算法任务中的局限性，如深度优先搜索。\n- **DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning**（DolphCoder: 通过多样化多目标指令微调定位代码 LLM）：使用多样指令微调提升代码生成 LLM 的鲁棒性，实验在 HumanEval 上表现突出。\n\n### 强化学习与推荐系统\n- **Scalable Graph Self-Supervised Learning**（Scalable Graph Self-Supervised Learning: 可扩展的图自监督学习）：提出采样方法优化图神经网络的自监督学习，减少计算成本，同时保持下游任务性能。\n- **Reinforcement Learning from Human Feedback with Active Queries**（Reinforcement Learning from Human Feedback with Active Queries: 使用主动查询的人类反馈强化学习）：设计主动查询机制提升 RLHF 效率，实验显示在 API 生成任务中显著改进模型泛化。\n- **Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference**（Get More with LESS: 通过 KV 缓存压缩合成循环以提升 LLM 推理效率）：引入缓存压缩策略优化 LLM 推理，减少内存使用并提升速度，在实验中证明其有效性。\n- **AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems**（AgentLens: LLM 自主系统中的代理行为可视分析）：开发可视化工具分析 LLM 代理行为，支持用户交互地诊断决策过程。\n- **Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues**（Play Guessing Game with LLM: 通过隐式线索的间接越狱攻击）：快速提及，该文与上述 LLM 安全相关，强调攻击策略的创新。\n\n### 图像、视频和多模态处理\n- **CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding**（CLIP-MUSED: CLIP 引导的多主体视觉神经信息语义解码）：使用 CLIP 提升多主体 fMRI 数据解码准确性，实验在脑科学任务中表现出色。\n- **Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls**（Arrange, Inpaint, and Refine: 通过内容基控制的可指导长期音乐音频生成和编辑）：提出音乐生成框架，支持基于内容的编辑，实验显示在音频任务中提升生成质量。\n- **Magic-Me: Identity-Specific Video Customized Diffusion**（Magic-Me: 身份特定视频定制扩散）：设计视频生成模型，支持身份特定定制，实验证明其在人脸视频生成中的鲁棒性。\n\n### 其他领域（快速掠过）\n- **Medical Image Segmentation with InTEnt: Integrated Entropy Weighting for Single Image Test-Time Adaptation**（Medical Image Segmentation with InTEnt: 用于单图像测试时适应的集成熵加权）：贡献在于改进医疗图像分割的自适应方法，提升 Dice 系数 2.9%，但非核心主题。\n- **LogicPrpBank: A Corpus for Logical Implication and Equivalence**（LogicPrpBank: 用于逻辑蕴含和等价的语料库）：构建逻辑推理语料库，支持 LLM 在命题逻辑任务上的训练，实验显示模型改进潜力。\n- **Towards Privacy-Aware Sign Language Translation at Scale**（Towards Privacy-Aware Sign Language Translation at Scale: 面向大规模的隐私感知手语翻译）：提出隐私保护框架，提升手语翻译性能 3 BLEU-4 分，但应用较为特定。\n- 其余论文如社交网络分析、医疗诊断和数学推理（如 FGeo-DRL），贡献在于特定领域优化（如特征选择或推理基准），但整体影响力有限，故仅简要提及它们提供了实用工具或数据集，而非主流焦点。\n\n今天的 arXiv 更新显示，AI 社区正积极应对 LLM 的安全挑战，同时探索高效学习和多模态融合。重点论文强调了实际应用中的鲁棒性和伦理问题，值得关注！如果有特定领域兴趣，建议查看相关论文的完整摘要。",
  "papers": [
    {
      "arxiv_id": "2402.09617v1",
      "title": "LLM-Enhanced User-Item Interactions: Leveraging Edge Information for Optimized Recommendations",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyuan Wang",
        "Liang Wu",
        "Liangjie Hong",
        "Hao Liu",
        "Yanjie Fu"
      ],
      "abstract": "The extraordinary performance of large language models has not only reshaped\nthe research landscape in the field of NLP but has also demonstrated its\nexceptional applicative potential in various domains. However, the potential of\nthese models in mining relationships from graph data remains under-explored.\nGraph neural networks, as a popular research area in recent years, have\nnumerous studies on relationship mining. Yet, current cutting-edge research in\ngraph neural networks has not been effectively integrated with large language\nmodels, leading to limited efficiency and capability in graph relationship\nmining tasks. A primary challenge is the inability of LLMs to deeply exploit\nthe edge information in graphs, which is critical for understanding complex\nnode relationships. This gap limits the potential of LLMs to extract meaningful\ninsights from graph structures, limiting their applicability in more complex\ngraph-based analysis. We focus on how to utilize existing LLMs for mining and\nunderstanding relationships in graph data, applying these techniques to\nrecommendation tasks. We propose an innovative framework that combines the\nstrong contextual representation capabilities of LLMs with the relationship\nextraction and analysis functions of GNNs for mining relationships in graph\ndata. Specifically, we design a new prompt construction framework that\nintegrates relational information of graph data into natural language\nexpressions, aiding LLMs in more intuitively grasping the connectivity\ninformation within graph data. Additionally, we introduce graph relationship\nunderstanding and analysis functions into LLMs to enhance their focus on\nconnectivity information in graph data. Our evaluation on real-world datasets\ndemonstrates the framework's ability to understand connectivity information in\ngraph data.",
      "tldr_zh": "这篇论文探讨了如何利用大型语言模型（LLMs）来挖掘图数据中的关系，特别是边信息（edge information），以优化推荐系统，因为现有 LLMs 在处理图结构时效率有限。研究提出一个创新框架，将 LLMs 的上下文表示能力与图神经网络（GNNs）的关系提取功能相结合，设计了一个新的提示构造框架，将图数据的关系信息转化为自然语言表达，帮助 LLMs 更直观地理解图的连接信息。同时，该框架引入图关系理解和分析功能，增强 LLMs 对连接信息的关注。实验结果在真实数据集上证明，该方法显著提高了关系挖掘的效率和推荐任务的性能。",
      "categories": [
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09617v1",
      "published_date": "2024-02-14 23:12:09 UTC",
      "updated_date": "2024-02-14 23:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:04:33.481171"
    },
    {
      "arxiv_id": "2402.09615v6",
      "title": "API Pack: A Massive Multi-Programming Language Dataset for API Call Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhen Guo",
        "Adriana Meza Soria",
        "Wei Sun",
        "Yikang Shen",
        "Rameswar Panda"
      ],
      "abstract": "We introduce API Pack, a massive multi-programming language dataset\ncontaining over one million instruction-API calls for improving the API call\ngeneration capabilities of large language models. Our evaluation highlights\nthree key findings: First, fine-tuning on API Pack enables open-source models\nto outperform GPT-3.5 and GPT-4 in generating code for entirely new API calls.\nWe show this by fine-tuning CodeLlama-13B on 20,000 Python instances from API\nPack. Second, fine-tuning on a large dataset in one language, combined with\nsmaller datasets from others, improves API generation accuracy across multiple\nlanguages. Third, we confirm the benefits of larger datasets for API\ngeneralization, as increasing fine-tuning data to one million instances\nenhances generalization to new APIs. To support further research, we\nopen-source the API Pack dataset, trained model, and code at\nhttps://github.com/zguo0525/API-Pack.",
      "tldr_zh": "本研究引入了API Pack，这是一个包含超过一百万条指令-API调用的庞大数据集，旨在提升大型语言模型的API调用生成能力。实验结果显示，在API Pack上微调开源模型（如CodeLlama-13B）后，其在新API调用代码生成上超过了GPT-3.5和GPT-4。研究还发现，将一种语言的大型数据集与其它语言的小型数据集结合微调，能提高多语言API生成准确性；同时，增加微调数据至一百万实例显著增强了模型对新API的泛化能力。为促进进一步研究，该数据集、训练模型和代码已在GitHub开源。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09615v6",
      "published_date": "2024-02-14 23:09:15 UTC",
      "updated_date": "2025-02-13 20:05:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:04:45.711670"
    },
    {
      "arxiv_id": "2402.09614v3",
      "title": "Reasoning over Uncertain Text by Generative Large Language Models",
      "title_zh": "通过生成式大语言模型对不确定文本进行推理",
      "authors": [
        "Aliakbar Nafar",
        "Kristen Brent Venable",
        "Parisa Kordjamshidi"
      ],
      "abstract": "This paper considers the challenges Large Language Models (LLMs) face when\nreasoning over text that includes information involving uncertainty explicitly\nquantified via probability values. This type of reasoning is relevant to a\nvariety of contexts ranging from everyday conversations to medical\ndecision-making. Despite improvements in the mathematical reasoning\ncapabilities of LLMs, they still exhibit significant difficulties when it comes\nto probabilistic reasoning. To deal with this problem, we introduce the\nBayesian Linguistic Inference Dataset (BLInD), a new dataset specifically\ndesigned to test the probabilistic reasoning capabilities of LLMs. We use BLInD\nto find out the limitations of LLMs for tasks involving probabilistic\nreasoning. In addition, we present several prompting strategies that map the\nproblem to different formal representations, including Python code,\nprobabilistic algorithms, and probabilistic logical programming. We conclude by\nproviding an evaluation of our methods on BLInD and an adaptation of a causal\nreasoning question-answering dataset. Our empirical results highlight the\neffectiveness of our proposed strategies for multiple LLMs.",
      "tldr_zh": "本论文探讨了生成式大型语言模型 (LLMs) 在处理包含概率不确定性文本时的推理挑战，这些挑战在日常对话和医疗决策等场景中尤为重要。研究者引入了新的数据集 Bayesian Linguistic Inference Dataset (BLInD)，用于评估 LLMs 的概率推理能力，并提出了多种提示策略，如将问题映射到 Python code、probabilistic algorithms 和 probabilistic logical programming。实验结果显示，这些策略在 BLInD 以及一个因果推理问答数据集上显著提升了 LLMs 的性能，突显了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09614v3",
      "published_date": "2024-02-14 23:05:44 UTC",
      "updated_date": "2024-12-27 18:43:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:04:56.605205"
    },
    {
      "arxiv_id": "2402.09611v2",
      "title": "Towards Privacy-Aware Sign Language Translation at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "Phillip Rust",
        "Bowen Shi",
        "Skyler Wang",
        "Necati Cihan Camgöz",
        "Jean Maillard"
      ],
      "abstract": "A major impediment to the advancement of sign language translation (SLT) is\ndata scarcity. Much of the sign language data currently available on the web\ncannot be used for training supervised models due to the lack of aligned\ncaptions. Furthermore, scaling SLT using large-scale web-scraped datasets bears\nprivacy risks due to the presence of biometric information, which the\nresponsible development of SLT technologies should account for. In this work,\nwe propose a two-stage framework for privacy-aware SLT at scale that addresses\nboth of these issues. We introduce SSVP-SLT, which leverages self-supervised\nvideo pretraining on anonymized and unannotated videos, followed by supervised\nSLT finetuning on a curated parallel dataset. SSVP-SLT achieves\nstate-of-the-art finetuned and zero-shot gloss-free SLT performance on the\nHow2Sign dataset, outperforming the strongest respective baselines by over 3\nBLEU-4. Based on controlled experiments, we further discuss the advantages and\nlimitations of self-supervised pretraining and anonymization via facial\nobfuscation for SLT.",
      "tldr_zh": "该研究针对手语翻译（SLT）面临的数据稀缺和隐私风险问题，提出了一种两阶段隐私保护框架。框架首先利用自监督视频预训练（SSVP-SLT）在匿名化和无标注视频上进行预训练，然后在精选的平行数据集上进行监督微调。该方法在 How2Sign 数据集上实现了最先进的微调和零样本无词汇 SLT 性能，比最强基线提高了超过 3 BLEU-4。通过控制实验，论文讨论了自监督预训练和面部模糊化（facial obfuscation）匿名化的优势与局限性，为大规模隐私aware SLT 提供了可行路径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09611v2",
      "published_date": "2024-02-14 22:57:03 UTC",
      "updated_date": "2024-08-07 19:27:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:05:09.491045"
    },
    {
      "arxiv_id": "2402.09609v1",
      "title": "LogicPrpBank: A Corpus for Logical Implication and Equivalence",
      "title_zh": "翻译失败",
      "authors": [
        "Zhexiong Liu",
        "Jing Zhang",
        "Jiaying Lu",
        "Wenjing Ma",
        "Joyce C Ho"
      ],
      "abstract": "Logic reasoning has been critically needed in problem-solving and\ndecision-making. Although Language Models (LMs) have demonstrated capabilities\nof handling multiple reasoning tasks (e.g., commonsense reasoning), their\nability to reason complex mathematical problems, specifically propositional\nlogic, remains largely underexplored. This lack of exploration can be\nattributed to the limited availability of annotated corpora. Here, we present a\nwell-labeled propositional logic corpus, LogicPrpBank, containing 7093\nPropositional Logic Statements (PLSs) across six mathematical subjects, to\nstudy a brand-new task of reasoning logical implication and equivalence. We\nbenchmark LogicPrpBank with widely-used LMs to show that our corpus offers a\nuseful resource for this challenging task and there is ample room for model\nimprovement.",
      "tldr_zh": "本研究指出，语言模型 (LMs) 在处理复杂数学问题如命题逻辑推理时能力不足，主要由于标注语料库的可用性有限。研究者构建了 LogicPrpBank 语料库，该语料库包含 7093 个 Propositional Logic Statements (PLSs)，覆盖六个数学主题，用于支持一个新的任务：推理逻辑蕴含和等价。基准测试显示，LogicPrpBank 为这一挑战性任务提供了有价值的资源，但模型性能仍有显著改进空间。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "In the 5th AI4ED Workshop, held in conjunction with The 38th AAAI\n  Conference on Artificial Intelligence, February 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09609v1",
      "published_date": "2024-02-14 22:36:07 UTC",
      "updated_date": "2024-02-14 22:36:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:05:22.157017"
    },
    {
      "arxiv_id": "2402.09604v2",
      "title": "Medical Image Segmentation with InTEnt: Integrated Entropy Weighting for Single Image Test-Time Adaptation",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Dong",
        "Nicholas Konz",
        "Hanxue Gu",
        "Maciej A. Mazurowski"
      ],
      "abstract": "Test-time adaptation (TTA) refers to adapting a trained model to a new domain\nduring testing. Existing TTA techniques rely on having multiple test images\nfrom the same domain, yet this may be impractical in real-world applications\nsuch as medical imaging, where data acquisition is expensive and imaging\nconditions vary frequently. Here, we approach such a task, of adapting a\nmedical image segmentation model with only a single unlabeled test image. Most\nTTA approaches, which directly minimize the entropy of predictions, fail to\nimprove performance significantly in this setting, in which we also observe the\nchoice of batch normalization (BN) layer statistics to be a highly important\nyet unstable factor due to only having a single test domain example. To\novercome this, we propose to instead integrate over predictions made with\nvarious estimates of target domain statistics between the training and test\nstatistics, weighted based on their entropy statistics. Our method, validated\non 24 source/target domain splits across 3 medical image datasets surpasses the\nleading method by 2.9% Dice coefficient on average.",
      "tldr_zh": "该论文针对医疗图像分割中的测试时适应（Test-Time Adaptation, TTA）问题，提出了一种新方法InTEnt，用于仅使用单个无标签测试图像进行模型适应，以应对现实场景中数据获取的限制和批量归一化（Batch Normalization, BN）层统计的不稳定性。InTEnt通过整合训练和测试统计的各种估计，并基于熵统计进行加权，优化预测过程，从而提升模型在目标域的性能。在3个医疗图像数据集的24个源/目标域分割上验证，该方法平均Dice系数比领先方法提高了2.9%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Code and pre-trained weights:\n  https://github.com/mazurowski-lab/single-image-test-time-adaptation",
      "pdf_url": "http://arxiv.org/pdf/2402.09604v2",
      "published_date": "2024-02-14 22:26:07 UTC",
      "updated_date": "2024-02-16 15:53:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:05:32.668480"
    },
    {
      "arxiv_id": "2402.09603v1",
      "title": "Scalable Graph Self-Supervised Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ali Saheb Pasand",
        "Reza Moravej",
        "Mahdi Biparva",
        "Raika Karimi",
        "Ali Ghodsi"
      ],
      "abstract": "In regularization Self-Supervised Learning (SSL) methods for graphs,\ncomputational complexity increases with the number of nodes in graphs and\nembedding dimensions. To mitigate the scalability of non-contrastive graph SSL,\nwe propose a novel approach to reduce the cost of computing the covariance\nmatrix for the pre-training loss function with volume-maximization terms. Our\nwork focuses on reducing the cost associated with the loss computation via\ngraph node or dimension sampling. We provide theoretical insight into why\ndimension sampling would result in accurate loss computations and support it\nwith mathematical derivation of the novel approach. We develop our experimental\nsetup on the node-level graph prediction tasks, where SSL pre-training has\nshown to be difficult due to the large size of real world graphs. Our\nexperiments demonstrate that the cost associated with the loss computation can\nbe reduced via node or dimension sampling without lowering the downstream\nperformance. Our results demonstrate that sampling mostly results in improved\ndownstream performance. Ablation studies and experimental analysis are provided\nto untangle the role of the different factors in the experimental setup.",
      "tldr_zh": "这篇论文针对图自监督学习(SSL)中的正则化方法，提出了一种可扩展的新方法，通过节点或维度采样来减少计算协方差矩阵的成本，从而降低预训练损失函数的计算复杂度。作者提供了理论洞见和数学推导，解释了维度采样如何保持损失计算的准确性。实验在节点级图预测任务上验证了该方法，能够显著降低计算开销，同时不降低或甚至提升下游性能，为处理大规模真实世界图提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09603v1",
      "published_date": "2024-02-14 22:23:35 UTC",
      "updated_date": "2024-02-14 22:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:05:44.969525"
    },
    {
      "arxiv_id": "2403.12075v3",
      "title": "Adversarial Nibbler: An Open Red-Teaming Method for Identifying Diverse Harms in Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jessica Quaye",
        "Alicia Parrish",
        "Oana Inel",
        "Charvi Rastogi",
        "Hannah Rose Kirk",
        "Minsuk Kahng",
        "Erin van Liemt",
        "Max Bartolo",
        "Jess Tsang",
        "Justin White",
        "Nathan Clement",
        "Rafael Mosquera",
        "Juan Ciro",
        "Vijay Janapa Reddi",
        "Lora Aroyo"
      ],
      "abstract": "With the rise of text-to-image (T2I) generative AI models reaching wide\naudiences, it is critical to evaluate model robustness against non-obvious\nattacks to mitigate the generation of offensive images. By focusing on\n``implicitly adversarial'' prompts (those that trigger T2I models to generate\nunsafe images for non-obvious reasons), we isolate a set of difficult safety\nissues that human creativity is well-suited to uncover. To this end, we built\nthe Adversarial Nibbler Challenge, a red-teaming methodology for crowdsourcing\na diverse set of implicitly adversarial prompts. We have assembled a suite of\nstate-of-the-art T2I models, employed a simple user interface to identify and\nannotate harms, and engaged diverse populations to capture long-tail safety\nissues that may be overlooked in standard testing. The challenge is run in\nconsecutive rounds to enable a sustained discovery and analysis of safety\npitfalls in T2I models.\n  In this paper, we present an in-depth account of our methodology, a\nsystematic study of novel attack strategies and discussion of safety failures\nrevealed by challenge participants. We also release a companion visualization\ntool for easy exploration and derivation of insights from the dataset. The\nfirst challenge round resulted in over 10k prompt-image pairs with machine\nannotations for safety. A subset of 1.5k samples contains rich human\nannotations of harm types and attack styles. We find that 14% of images that\nhumans consider harmful are mislabeled as ``safe'' by machines. We have\nidentified new attack strategies that highlight the complexity of ensuring T2I\nmodel robustness. Our findings emphasize the necessity of continual auditing\nand adaptation as new vulnerabilities emerge. We are confident that this work\nwill enable proactive, iterative safety assessments and promote responsible\ndevelopment of T2I models.",
      "tldr_zh": "该研究提出了一种开放的红队方法——Adversarial Nibbler Challenge，用于识别文本到图像（T2I）生成模型中的多样化安全危害，特别是针对隐式对抗性提示，这些提示可能导致生成不明显但 offensive 的图像。方法通过众包方式，结合一组最先进的 T2I 模型、简单用户界面和多样化人群参与，来收集并标注超过 10k 的提示-图像对，并识别长尾安全问题。实验结果显示，14% 的被人类视为有害的图像被机器错误标记为安全，同时揭示了新型攻击策略，如复杂的人类创意驱动的攻击。总体而言，此工作强调了持续审计和适应的必要性，促进 T2I 模型的责任开发和鲁棒性提升。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CR",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "10 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.12075v3",
      "published_date": "2024-02-14 22:21:12 UTC",
      "updated_date": "2024-05-14 01:24:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:05:57.593935"
    },
    {
      "arxiv_id": "2402.09592v1",
      "title": "A Web-Based Tool for Automatic Data Collection, Curation, and Visualization of Complex Healthcare Survey Studies including Social Network Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "José Alberto Benítez-Andrades",
        "José Emilio Labra",
        "Enedina Quiroga",
        "Vicente Martín",
        "Isaías García",
        "Pilar Marqués-Sánchez",
        "Carmen Benavides"
      ],
      "abstract": "There is a great concern nowadays regarding alcohol consumption and drug\nabuse, especially in young people. Analyzing the social environment where these\nadolescents are immersed, as well as a series of measures determining the\nalcohol abuse risk or personal situation and perception using a number of\nquestionnaires like AUDIT, FAS, KIDSCREEN, and others, it is possible to gain\ninsight into the current situation of a given individual regarding his/her\nconsumption behavior. But this analysis, in order to be achieved, requires the\nuse of tools that can ease the process of questionnaire creation, data\ngathering, curation and representation, and later analysis and visualization to\nthe user. This research presents the design and construction of a web-based\nplatform able to facilitate each of the mentioned processes by integrating the\ndifferent phases into an intuitive system with a graphical user interface that\nhides the complexity underlying each of the questionnaires and techniques used\nand presenting the results in a flexible and visual way, avoiding any manual\nhandling of data during the process. Advantages of this approach are shown and\ncompared to the previous situation where some of the tasks were accomplished by\ntime consuming and error prone manipulations of data.",
      "tldr_zh": "这篇论文开发了一个web-based工具，用于自动收集、整理和可视化复杂的医疗调查研究，包括Social Network Analysis，针对青少年酒精消费和药物滥用问题。工具整合了问卷创建（如AUDIT、FAS、KIDSCREEN）、数据收集、分析和可视化过程，提供直观的图形用户界面，简化了整个流程并避免手动数据处理。与传统手动方法相比，该平台显著提高了效率，减少了错误率和时间消耗。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09592v1",
      "published_date": "2024-02-14 21:37:59 UTC",
      "updated_date": "2024-02-14 21:37:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:06:08.519349"
    },
    {
      "arxiv_id": "2402.09588v2",
      "title": "Emerging Opportunities of Using Large Language Models for Translation Between Drug Molecules and Indications",
      "title_zh": "使用大型语言模型进行药物分子与适应症之间翻译的新兴机会",
      "authors": [
        "David Oniani",
        "Jordan Hilsman",
        "Chengxi Zang",
        "Junmei Wang",
        "Lianjin Cai",
        "Jan Zawala",
        "Yanshan Wang"
      ],
      "abstract": "A drug molecule is a substance that changes the organism's mental or physical\nstate. Every approved drug has an indication, which refers to the therapeutic\nuse of that drug for treating a particular medical condition. While the Large\nLanguage Model (LLM), a generative Artificial Intelligence (AI) technique, has\nrecently demonstrated effectiveness in translating between molecules and their\ntextual descriptions, there remains a gap in research regarding their\napplication in facilitating the translation between drug molecules and\nindications, or vice versa, which could greatly benefit the drug discovery\nprocess. The capability of generating a drug from a given indication would\nallow for the discovery of drugs targeting specific diseases or targets and\nultimately provide patients with better treatments. In this paper, we first\npropose a new task, which is the translation between drug molecules and\ncorresponding indications, and then test existing LLMs on this new task.\nSpecifically, we consider nine variations of the T5 LLM and evaluate them on\ntwo public datasets obtained from ChEMBL and DrugBank. Our experiments show the\nearly results of using LLMs for this task and provide a perspective on the\nstate-of-the-art. We also emphasize the current limitations and discuss future\nwork that has the potential to improve the performance on this task. The\ncreation of molecules from indications, or vice versa, will allow for more\nefficient targeting of diseases and significantly reduce the cost of drug\ndiscovery, with the potential to revolutionize the field of drug discovery in\nthe era of generative AI.",
      "tldr_zh": "本研究探讨了使用Large Language Models (LLMs) 在药物分子和适应症(indications)之间进行翻译的可能性，这有助于加速药物发现过程。论文提出一个新任务，即将药物分子转化为适应症或反之，并测试了九种T5 LLM变体在ChEMBL和DrugBank公开数据集上的性能。实验结果展示了LLMs在这一任务上的初步表现，同时指出了当前局限性，并讨论了未来改进方向，如提升准确性以降低药物发现成本并革新该领域。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09588v2",
      "published_date": "2024-02-14 21:33:13 UTC",
      "updated_date": "2024-02-16 20:55:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:06:20.319861"
    },
    {
      "arxiv_id": "2402.09584v2",
      "title": "Large Language Model-Based Interpretable Machine Learning Control in Building Energy Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Liang Zhang",
        "Zhelun Chen"
      ],
      "abstract": "The potential of Machine Learning Control (MLC) in HVAC systems is hindered\nby its opaque nature and inference mechanisms, which is challenging for users\nand modelers to fully comprehend, ultimately leading to a lack of trust in\nMLC-based decision-making. To address this challenge, this paper investigates\nand explores Interpretable Machine Learning (IML), a branch of Machine Learning\n(ML) that enhances transparency and understanding of models and their\ninferences, to improve the credibility of MLC and its industrial application in\nHVAC systems. Specifically, we developed an innovative framework that combines\nthe principles of Shapley values and the in-context learning feature of Large\nLanguage Models (LLMs). While the Shapley values are instrumental in dissecting\nthe contributions of various features in ML models, LLM provides an in-depth\nunderstanding of the non-data-driven or rule-based elements in MLC; combining\nthem, LLM further packages these insights into a coherent, human-understandable\nnarrative. The paper presents a case study to demonstrate the feasibility of\nthe developed IML framework for model predictive control-based precooling under\ndemand response events in a virtual testbed. The results indicate that the\ndeveloped framework generates and explains the control signals in accordance\nwith the rule-based rationale.",
      "tldr_zh": "这篇论文针对 Machine Learning Control (MLC) 在 HVAC 系统中的不透明性问题，提出使用 Interpretable Machine Learning (IML) 来提升模型的可信度和工业应用潜力。\n他们开发了一个创新框架，将 Shapley values 用于分析特征贡献，与 Large Language Models (LLMs) 的 in-context learning 相结合，以理解非数据驱动元素并生成易懂的叙述。\n在虚拟测试床的案例研究中，该框架成功应用于模型预测控制的预冷场景，结果显示生成的控制信号符合规则-based 推理，从而增强了 MLC 的可解释性和信任度。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09584v2",
      "published_date": "2024-02-14 21:19:33 UTC",
      "updated_date": "2024-11-15 18:34:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:06:33.545738"
    },
    {
      "arxiv_id": "2402.09581v2",
      "title": "Combatting deepfakes: Policies to address national security threats and rights violations",
      "title_zh": "对抗深度伪造：解决国家安全威胁和权利侵犯的政策",
      "authors": [
        "Andrea Miotti",
        "Akash Wasil"
      ],
      "abstract": "This paper provides policy recommendations to address threats from deepfakes.\nFirst, we provide background information about deepfakes and review the harms\nthey pose. We describe how deepfakes are currently used to proliferate sexual\nabuse material, commit fraud, manipulate voter behavior, and pose threats to\nnational security. Second, we review previous legislative proposals designed to\naddress deepfakes. Third, we present a comprehensive policy proposal that\nfocuses on addressing multiple parts of the deepfake supply chain. The deepfake\nsupply chain begins with a small number of model developers, model providers,\nand compute providers, and it expands to include billions of potential deepfake\ncreators. We describe this supply chain in greater detail and describe how\nentities at each step of the supply chain ought to take reasonable measures to\nprevent the creation and proliferation of deepfakes. Finally, we address\npotential counterpoints of our proposal. Overall, deepfakes will present\nincreasingly severe threats to global security and individual liberties. To\naddress these threats, we call on policymakers to enact legislation that\naddresses multiple parts of the deepfake supply chain.",
      "tldr_zh": "这篇论文针对 deepfakes 的威胁，提供政策推荐，以应对国家安全风险和权利侵犯。首先，它回顾了 deepfakes 的背景及其危害，包括用于传播性虐待材料、实施欺诈、操纵选民行为和威胁国家安全。其次，论文分析了现有立法提案，并提出一个全面政策框架，针对 deepfakes 供应链的各个环节（如模型开发者、提供者和计算提供者），要求相关实体采取合理措施防止 deepfakes 的创建和传播。最后，它回应潜在反驳，并呼吁决策者通过立法多方面应对这些日益严重的全球安全和个人自由威胁。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09581v2",
      "published_date": "2024-02-14 21:05:55 UTC",
      "updated_date": "2024-02-19 18:39:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:06:44.809725"
    },
    {
      "arxiv_id": "2402.09579v2",
      "title": "Advancing Building Energy Modeling with Large Language Models: Exploration and Case Studies",
      "title_zh": "使用大型语言模型推进建筑能源建模：探索和案例研究",
      "authors": [
        "Liang Zhang",
        "Zhelun Chen",
        "Vitaly Ford"
      ],
      "abstract": "The rapid progression in artificial intelligence has facilitated the\nemergence of large language models like ChatGPT, offering potential\napplications extending into specialized engineering modeling, especially\nphysics-based building energy modeling. This paper investigates the innovative\nintegration of large language models with building energy modeling software,\nfocusing specifically on the fusion of ChatGPT with EnergyPlus. A literature\nreview is first conducted to reveal a growing trend of incorporating large\nlanguage models in engineering modeling, albeit limited research on their\napplication in building energy modeling. We underscore the potential of large\nlanguage models in addressing building energy modeling challenges and outline\npotential applications including simulation input generation, simulation output\nanalysis and visualization, conducting error analysis, co-simulation,\nsimulation knowledge extraction and training, and simulation optimization.\nThree case studies reveal the transformative potential of large language models\nin automating and optimizing building energy modeling tasks, underscoring the\npivotal role of artificial intelligence in advancing sustainable building\npractices and energy efficiency. The case studies demonstrate that selecting\nthe right large language model techniques is essential to enhance performance\nand reduce engineering efforts. The findings advocate a multidisciplinary\napproach in future artificial intelligence research, with implications\nextending beyond building energy modeling to other specialized engineering\nmodeling.",
      "tldr_zh": "本研究探讨了大型语言模型（Large Language Models，如 ChatGPT）与建筑能源建模软件（如 EnergyPlus）的整合，旨在解决相关领域的挑战。通过文献综述，论文突出了大型语言模型在工程建模中的应用趋势，并提出了潜在用途，包括模拟输入生成、输出分析、错误分析、联合模拟、知识提取和优化。三个案例研究展示了这些模型在自动化建筑能源建模任务中的潜力，能够显著提升性能、减少工程努力，并推动可持续建筑实践。最终，研究倡导采用多学科方法，将其影响扩展到其他工程建模领域。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09579v2",
      "published_date": "2024-02-14 21:02:07 UTC",
      "updated_date": "2024-11-15 18:20:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:06:57.226908"
    },
    {
      "arxiv_id": "2402.09565v2",
      "title": "Graph-Skeleton: ~1% Nodes are Sufficient to Represent Billion-Scale Graph",
      "title_zh": "翻译失败",
      "authors": [
        "Linfeng Cao",
        "Haoran Deng",
        "Yang Yang",
        "Chunping Wang",
        "Lei Chen"
      ],
      "abstract": "Due to the ubiquity of graph data on the web, web graph mining has become a\nhot research spot. Nonetheless, the prevalence of large-scale web graphs in\nreal applications poses significant challenges to storage, computational\ncapacity and graph model design. Despite numerous studies to enhance the\nscalability of graph models, a noticeable gap remains between academic research\nand practical web graph mining applications. One major cause is that in most\nindustrial scenarios, only a small part of nodes in a web graph are actually\nrequired to be analyzed, where we term these nodes as target nodes, while\nothers as background nodes. In this paper, we argue that properly fetching and\ncondensing the background nodes from massive web graph data might be a more\neconomical shortcut to tackle the obstacles fundamentally. To this end, we make\nthe first attempt to study the problem of massive background nodes compression\nfor target nodes classification. Through extensive experiments, we reveal two\ncritical roles played by the background nodes in target node classification:\nenhancing structural connectivity between target nodes, and feature correlation\nwith target nodes. Followingthis, we propose a novel Graph-Skeleton1 model,\nwhich properly fetches the background nodes, and further condenses the semantic\nand topological information of background nodes within similar\ntarget-background local structures. Extensive experiments on various web graph\ndatasets demonstrate the effectiveness and efficiency of the proposed method.\nIn particular, for MAG240M dataset with 0.24 billion nodes, our generated\nskeleton graph achieves highly comparable performance while only containing\n1.8% nodes of the original graph.",
      "tldr_zh": "该论文探讨了大规模网络图（web graph）挖掘面临的存储和计算挑战，提出通过压缩背景节点来优化针对目标节点的分类问题。Graph-Skeleton 模型首次尝试获取并浓缩背景节点的语义和拓扑信息，强调背景节点在增强目标节点结构连通性和特征相关性方面的关键作用。在各种数据集上的实验证明，该方法高效且有效，例如在 MAG240M 数据集上，仅使用 1.8% 的节点就实现了与原图相当的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "21 pages, 11 figures, In Proceedings of the ACM Web Conference 2024\n  (WWW'24)",
      "pdf_url": "http://arxiv.org/pdf/2402.09565v2",
      "published_date": "2024-02-14 20:33:11 UTC",
      "updated_date": "2024-03-06 22:22:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:07:08.895414"
    },
    {
      "arxiv_id": "2402.09558v3",
      "title": "Bidirectional Generative Pre-training for Improving Healthcare Time-series Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyang Song",
        "Qincheng Lu",
        "He Zhu",
        "David Buckeridge",
        "Yue Li"
      ],
      "abstract": "Learning time-series representations for discriminative tasks, such as\nclassification and regression, has been a long-standing challenge in the\nhealthcare domain. Current pre-training methods are limited in either\nunidirectional next-token prediction or randomly masked token prediction. We\npropose a novel architecture called Bidirectional Timely Generative Pre-trained\nTransformer (BiTimelyGPT), which pre-trains on biosignals and longitudinal\nclinical records by both next-token and previous-token prediction in\nalternating transformer layers. This pre-training task preserves original\ndistribution and data shapes of the time-series. Additionally, the full-rank\nforward and backward attention matrices exhibit more expressive representation\ncapabilities. Using biosignals and longitudinal clinical records, BiTimelyGPT\ndemonstrates superior performance in predicting neurological functionality,\ndisease diagnosis, and physiological signs. By visualizing the attention\nheatmap, we observe that the pre-trained BiTimelyGPT can identify\ndiscriminative segments from biosignal time-series sequences, even more so\nafter fine-tuning on the task.",
      "tldr_zh": "本研究针对医疗领域的时间序列表示学习面临的挑战，提出了一种新型架构Bidirectional Timely Generative Pre-trained Transformer (BiTimelyGPT)，通过在交替Transformer层上进行下一个标记和上一个标记预测的双向预训练，保留了生物信号和纵向临床记录的原始分布和数据形状。相比现有单向预训练方法，该架构利用全秩的前向和后向注意力矩阵，提升了表示能力的表现力。实验结果显示，BiTimelyGPT在神经功能预测、疾病诊断和生理指标预测任务上表现出色，并通过注意力热图可视化证明其能有效识别生物信号序列中的关键区分性段。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09558v3",
      "published_date": "2024-02-14 20:19:24 UTC",
      "updated_date": "2024-08-23 18:25:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:07:20.683710"
    },
    {
      "arxiv_id": "2402.09553v1",
      "title": "Statistical and Machine Learning Models for Predicting Fire and Other Emergency Events",
      "title_zh": "用于预测火灾和其他紧急事件的统计和机器学习模型",
      "authors": [
        "Dilli Prasad Sharma",
        "Nasim Beigi-Mohammadi",
        "Hongxiang Geng",
        "Dawn Dixon",
        "Rob Madro",
        "Phil Emmenegger",
        "Carlos Tobar",
        "Jeff Li",
        "Alberto Leon-Garcia"
      ],
      "abstract": "Emergency events in a city cause considerable economic loss to individuals,\ntheir families, and the community. Accurate and timely prediction of events can\nhelp the emergency fire and rescue services in preparing for and mitigating the\nconsequences of emergency events. In this paper, we present a systematic\ndevelopment of predictive models for various types of emergency events in the\nCity of Edmonton, Canada. We present methods for (i) data collection and\ndataset development; (ii) descriptive analysis of each event type and its\ncharacteristics at different spatiotemporal levels; (iii) feature analysis and\nselection based on correlation coefficient analysis and feature importance\nanalysis; and (iv) development of prediction models for the likelihood of\noccurrence of each event type at different temporal and spatial resolutions. We\nanalyze the association of event types with socioeconomic and demographic data\nat the neighborhood level, identify a set of predictors for each event type,\nand develop predictive models with negative binomial regression. We conduct\nevaluations at neighborhood and fire station service area levels. Our results\nshow that the models perform well for most of the event types with acceptable\nprediction errors for weekly and monthly periods. The evaluation shows that the\nprediction accuracy is consistent at the level of the fire station, so the\npredictions can be used in management by fire rescue service departments for\nplanning resource allocation for these time periods. We also examine the impact\nof the COVID-19 pandemic on the occurrence of events and on the accuracy of\nevent predictor models. Our findings show that COVID-19 had a significant\nimpact on the performance of the event prediction models.",
      "tldr_zh": "本研究开发了统计和机器学习模型，用于预测城市紧急事件（如火灾），以帮助紧急服务部门进行准备和资源分配。研究聚焦于加拿大埃德蒙顿市，涉及数据收集、描述性分析、特征选择（如相关系数和重要性分析），并使用 Negative Binomial Regression 模型分析事件与社会经济、人口数据的关联。结果显示，模型在大多数事件类型上表现良好，预测错误在周度和月度周期内可接受，且在消防站服务区域级别预测准确性一致，可用于规划资源分配；此外，COVID-19 大流行显著影响了事件发生和模型预测性能。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09553v1",
      "published_date": "2024-02-14 20:10:30 UTC",
      "updated_date": "2024-02-14 20:10:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:07:33.013770"
    },
    {
      "arxiv_id": "2402.09546v1",
      "title": "How Secure Are Large Language Models (LLMs) for Navigation in Urban Environments?",
      "title_zh": "大语言模型 (LLMs) 在城市环境导航",
      "authors": [
        "Congcong Wen",
        "Jiazhao Liang",
        "Shuaihang Yuan",
        "Hao Huang",
        "Yi Fang"
      ],
      "abstract": "In the field of robotics and automation, navigation systems based on Large\nLanguage Models (LLMs) have recently shown impressive performance. However, the\nsecurity aspects of these systems have received relatively less attention. This\npaper pioneers the exploration of vulnerabilities in LLM-based navigation\nmodels in urban outdoor environments, a critical area given the technology's\nwidespread application in autonomous driving, logistics, and emergency\nservices. Specifically, we introduce a novel Navigational Prompt Suffix (NPS)\nAttack that manipulates LLM-based navigation models by appending\ngradient-derived suffixes to the original navigational prompt, leading to\nincorrect actions. We conducted comprehensive experiments on an LLMs-based\nnavigation model that employs various LLMs for reasoning. Our results, derived\nfrom the Touchdown and Map2Seq street-view datasets under both few-shot\nlearning and fine-tuning configurations, demonstrate notable performance\ndeclines across three metrics in the face of both white-box and black-box\nattacks. These results highlight the generalizability and transferability of\nthe NPS Attack, emphasizing the need for enhanced security in LLM-based\nnavigation systems. As an initial countermeasure, we propose the Navigational\nPrompt Engineering (NPE) Defense strategy, concentrating on navigation-relevant\nkeywords to reduce the impact of adversarial suffixes. While initial findings\nindicate that this strategy enhances navigational safety, there remains a\ncritical need for the wider research community to develop stronger defense\nmethods to effectively tackle the real-world challenges faced by these systems.",
      "tldr_zh": "这篇论文探讨了大型语言模型(LLMs)在城市环境导航系统中的安全漏洞，首次引入Navigational Prompt Suffix (NPS) Attack，该攻击通过在导航提示后附加基于梯度的后缀来操纵模型，导致错误行为。实验在Touchdown和Map2Seq数据集上进行，显示在few-shot learning和fine-tuning配置下，模型性能在白盒和黑盒攻击中显著下降，证明了攻击的泛化性和可转移性。作为初步对策，作者提出Navigational Prompt Engineering (NPE) Defense策略，聚焦导航相关关键词以减轻攻击影响，但强调需要社区开发更强的防御方法来应对现实挑战。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09546v1",
      "published_date": "2024-02-14 19:45:17 UTC",
      "updated_date": "2024-02-14 19:45:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:07:45.708217"
    },
    {
      "arxiv_id": "2402.09540v1",
      "title": "Why Does Differential Privacy with Large Epsilon Defend Against Practical Membership Inference Attacks?",
      "title_zh": "为什么大ε差分隐私能够防御实际成员推断攻击？",
      "authors": [
        "Andrew Lowy",
        "Zhuohang Li",
        "Jing Liu",
        "Toshiaki Koike-Akino",
        "Kieran Parsons",
        "Ye Wang"
      ],
      "abstract": "For small privacy parameter $\\epsilon$, $\\epsilon$-differential privacy (DP)\nprovides a strong worst-case guarantee that no membership inference attack\n(MIA) can succeed at determining whether a person's data was used to train a\nmachine learning model. The guarantee of DP is worst-case because: a) it holds\neven if the attacker already knows the records of all but one person in the\ndata set; and b) it holds uniformly over all data sets. In practical\napplications, such a worst-case guarantee may be overkill: practical attackers\nmay lack exact knowledge of (nearly all of) the private data, and our data set\nmight be easier to defend, in some sense, than the worst-case data set. Such\nconsiderations have motivated the industrial deployment of DP models with large\nprivacy parameter (e.g. $\\epsilon \\geq 7$), and it has been observed\nempirically that DP with large $\\epsilon$ can successfully defend against\nstate-of-the-art MIAs. Existing DP theory cannot explain these empirical\nfindings: e.g., the theoretical privacy guarantees of $\\epsilon \\geq 7$ are\nessentially vacuous. In this paper, we aim to close this gap between theory and\npractice and understand why a large DP parameter can prevent practical MIAs. To\ntackle this problem, we propose a new privacy notion called practical\nmembership privacy (PMP). PMP models a practical attacker's uncertainty about\nthe contents of the private data. The PMP parameter has a natural\ninterpretation in terms of the success rate of a practical MIA on a given data\nset. We quantitatively analyze the PMP parameter of two fundamental DP\nmechanisms: the exponential mechanism and Gaussian mechanism. Our analysis\nreveals that a large DP parameter often translates into a much smaller PMP\nparameter, which guarantees strong privacy against practical MIAs. Using our\nfindings, we offer principled guidance for practitioners in choosing the DP\nparameter.",
      "tldr_zh": "本论文探讨了为什么ε-differential privacy 在ε较大（如ε ≥ 7）时能有效防御实际的Membership Inference Attacks (MIAs)，尽管其理论worst-case 保证较弱。作者引入了新的隐私概念practical membership privacy (PMP)，该概念考虑攻击者对私有数据的不确定性，并将其与MIA的成功率相关联。通过分析exponential mechanism和Gaussian mechanism的PMP参数，研究发现大ε值往往对应较小的PMP参数，从而提供更强的实际隐私保护。最后，论文为从业者提供选择DP参数的指导原则，以平衡隐私和实用性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "68P27"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at PPAI-24: AAAI Workshop on Privacy-Preserving Artificial\n  Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2402.09540v1",
      "published_date": "2024-02-14 19:31:45 UTC",
      "updated_date": "2024-02-14 19:31:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:07:57.526101"
    },
    {
      "arxiv_id": "2402.09508v3",
      "title": "Arrange, Inpaint, and Refine: Steerable Long-term Music Audio Generation and Editing via Content-based Controls",
      "title_zh": "翻译失败",
      "authors": [
        "Liwei Lin",
        "Gus Xia",
        "Yixiao Zhang",
        "Junyan Jiang"
      ],
      "abstract": "Controllable music generation plays a vital role in human-AI music\nco-creation. While Large Language Models (LLMs) have shown promise in\ngenerating high-quality music, their focus on autoregressive generation limits\ntheir utility in music editing tasks. To address this gap, we propose a novel\napproach leveraging a parameter-efficient heterogeneous adapter combined with a\nmasking training scheme. This approach enables autoregressive language models\nto seamlessly address music inpainting tasks. Additionally, our method\nintegrates frame-level content-based controls, facilitating track-conditioned\nmusic refinement and score-conditioned music arrangement. We apply this method\nto fine-tune MusicGen, a leading autoregressive music generation model. Our\nexperiments demonstrate promising results across multiple music editing tasks,\noffering more flexible controls for future AI-driven music editing tools. The\nsource codes and a demo page showcasing our work are available at\nhttps://kikyo-16.github.io/AIR.",
      "tldr_zh": "该论文提出了一种新方法，通过参数高效的异构适配器（heterogeneous adapter）和掩码训练方案（masking training scheme），使 Large Language Models (LLMs) 能够处理音乐修复（inpainting）任务，从而扩展其在音乐编辑中的应用。方法整合了帧级基于内容的控制，支持轨道条件音乐精炼（track-conditioned music refinement）和分数条件音乐安排（score-conditioned music arrangement），并应用于细调 MusicGen 模型。实验结果显示，该方法在多个音乐编辑任务上表现出色，提供更灵活的控制，为 AI 驱动的音乐工具带来潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09508v3",
      "published_date": "2024-02-14 19:00:01 UTC",
      "updated_date": "2024-10-06 21:26:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:08:09.970943"
    },
    {
      "arxiv_id": "2402.09500v1",
      "title": "On Formally Undecidable Traits of Intelligent Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Matthew Fox"
      ],
      "abstract": "Building on work by Alfonseca et al. (2021), we study the conditions\nnecessary for it to be logically possible to prove that an arbitrary\nartificially intelligent machine will exhibit certain behavior. To do this, we\ndevelop a formalism like -- but mathematically distinct from -- the theory of\nformal languages and their properties. Our formalism affords a precise means\nfor not only talking about the traits we desire of machines (such as them being\nintelligent, contained, moral, and so forth), but also for detailing the\nconditions necessary for it to be logically possible to decide whether a given\narbitrary machine possesses such a trait or not. Contrary to Alfonseca et al.'s\n(2021) results, we find that Rice's theorem from computability theory cannot in\ngeneral be used to determine whether an arbitrary machine possesses a given\ntrait or not. Therefore, it is not necessarily the case that deciding whether\nan arbitrary machine is intelligent, contained, moral, and so forth is\nlogically impossible.",
      "tldr_zh": "该论文基于Alfonseca et al. (2021)的研究，探讨了证明任意人工智能机器是否会表现出特定行为（如智能、受限或道德）的逻辑可能性，并开发了一个类似于形式语言理论但数学上不同的形式主义。  \n这种形式主义允许精确定义机器的期望特性，并分析决定任意机器是否具有这些特性的必要条件。  \n与先前的结果相反，论文发现Rice's theorem不能普遍应用于此类决策，因此判断机器是否智能或道德等特性并非逻辑上不可能。",
      "categories": [
        "cs.AI",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.09500v1",
      "published_date": "2024-02-14 18:59:37 UTC",
      "updated_date": "2024-02-14 18:59:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:08:20.416887"
    },
    {
      "arxiv_id": "2402.09404v1",
      "title": "AQA-Bench: An Interactive Benchmark for Evaluating LLMs' Sequential Reasoning Ability",
      "title_zh": "翻译失败",
      "authors": [
        "Siwei Yang",
        "Bingchen Zhao",
        "Cihang Xie"
      ],
      "abstract": "This paper introduces AQA-Bench, a novel benchmark to assess the sequential\nreasoning capabilities of large language models (LLMs) in algorithmic contexts,\nsuch as depth-first search (DFS). The key feature of our evaluation benchmark\nlies in its interactive evaluation protocol -- for example, in DFS, the\navailability of each node's connected edge is contingent upon the model's\ntraversal to that node, thereby necessitating the LLM's ability to effectively\nremember visited nodes and strategize subsequent moves. We comprehensively\nbuild AQA-Bench with three different algorithms, namely binary search,\ndepth-first search, and breadth-first search, and to evaluate the sequential\nreasoning ability of 12 different LLMs. Our investigations reveal several\ninteresting findings: (1) Closed-source models like GPT-4 and Gemini generally\nshow strong sequential reasoning ability, significantly outperforming\nopen-source LLMs. (2) Naively providing interactive examples may inadvertently\nhurt few-shot performance. (3) A very limited number of predecessor steps\nfollowing the optimal policy can substantially boost small models' performance.\n(4) The scaling correlation between performance and model size is not always\nsignificant, sometimes even showcasing an inverse trend. We hope our study can\ncatalyze future work on advancing the understanding and enhancement of LLMs'\ncapabilities in sequential reasoning. The code is available at\nhttps://github.com/UCSC-VLAA/AQA-Bench.",
      "tldr_zh": "本论文引入了AQA-Bench，一个交互式基准，用于评估大型语言模型(LLMs)的顺序推理能力，特别是针对算法上下文如深度优先搜索(DFS)。AQA-Bench构建了binary search、DFS和breadth-first search三种算法的交互式评估协议，要求模型记忆访问节点并规划后续步骤，以测试其动态推理性能。实验评估了12个LLMs，发现闭源模型如GPT-4和Gemini显著优于开源模型；简单提供交互式例子可能降低少样本性能；有限的前驱步骤可大幅提升小模型表现；且模型大小与性能间无显著正相关，有时甚至呈反向趋势。该研究旨在推动LLMs顺序推理能力的深入理解和改进。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09404v1",
      "published_date": "2024-02-14 18:59:33 UTC",
      "updated_date": "2024-02-14 18:59:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:08:34.191936"
    },
    {
      "arxiv_id": "2402.09401v2",
      "title": "Reinforcement Learning from Human Feedback with Active Queries",
      "title_zh": "翻译失败",
      "authors": [
        "Kaixuan Ji",
        "Jiafan He",
        "Quanquan Gu"
      ],
      "abstract": "Aligning large language models (LLM) with human preference plays a key role\nin building modern generative models and can be achieved by reinforcement\nlearning from human feedback (RLHF). Despite their superior performance,\ncurrent RLHF approaches often require a large amount of human-labelled\npreference data, which is expensive to collect. In this paper, inspired by the\nsuccess of active learning, we address this problem by proposing\nquery-efficient RLHF methods. We first formalize the alignment problem as a\ncontextual dueling bandit problem and design an active-query-based proximal\npolicy optimization (APPO) algorithm with an $\\tilde{O}(d^2/\\Delta)$\ninstance-dependent regret bound and an $\\tilde{O}(d^2/\\Delta^2)$ query\ncomplexity, where $d$ is the dimension of feature space and $\\Delta$ is the\nsub-optimality gap over all the contexts. We then propose ADPO, a practical\nversion of our algorithm based on direct preference optimization (DPO) and\napply it to fine-tuning LLMs. Our experiments show that ADPO, while only making\nabout half of queries for human preference, matches the performance of the\nstate-of-the-art DPO method.",
      "tldr_zh": "本研究针对强化学习从人类反馈（RLHF）中对齐大型语言模型（LLM）的过程，提出了一种查询高效的方法，以减少昂贵的偏好数据收集需求。作者将对齐问题形式化为上下文双人博弈问题（contextual dueling bandit），并设计了基于主动查询的近端策略优化算法（APPO），该算法具有$\\tilde{O}(d^2/\\Delta)$的遗憾界和$\\tilde{O}(d^2/\\Delta^2)$的查询复杂度，其中$d$为特征空间维度，$\\Delta$为次优差距。基于此，他们开发了ADPO，一种实用版本的算法，结合直接偏好优化（DPO）用于LLM微调。实验结果显示，ADPO仅需约一半的人类查询，就可与最先进的DPO方法匹配性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "28 pages, 1 figure, 4 table",
      "pdf_url": "http://arxiv.org/pdf/2402.09401v2",
      "published_date": "2024-02-14 18:58:40 UTC",
      "updated_date": "2025-02-11 18:18:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:08:45.495529"
    },
    {
      "arxiv_id": "2402.09398v2",
      "title": "Get More with LESS: Synthesizing Recurrence with KV Cache Compression for Efficient LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Harry Dong",
        "Xinyu Yang",
        "Zhenyu Zhang",
        "Zhangyang Wang",
        "Yuejie Chi",
        "Beidi Chen"
      ],
      "abstract": "Many computational factors limit broader deployment of large language models.\nIn this paper, we focus on a memory bottleneck imposed by the key-value (KV)\ncache, a computational shortcut that requires storing previous KV pairs during\ndecoding. While existing KV cache methods approach this problem by pruning or\nevicting large swaths of relatively less important KV pairs to dramatically\nreduce the memory footprint of the cache, they can have limited success in\ntasks that require recollecting a majority of previous tokens. To alleviate\nthis issue, we propose LESS, a simple integration of a (nearly free) constant\nsized cache with eviction-based cache methods, such that all tokens can be\nqueried at later decoding steps. Its ability to retain information throughout\ntime shows merit on a variety of tasks where we demonstrate LESS can help\nreduce the performance gap from caching everything, sometimes even matching it,\nall while being efficient. Relevant code can be found at\nhttps://github.com/hdong920/LESS.",
      "tldr_zh": "该论文针对大型语言模型(LLM)推理中的内存瓶颈问题，聚焦于关键-值(KV)缓存，该缓存在解码过程中需要存储先前KV对，但现有方法通过修剪或驱逐不重要KV对虽能减少内存占用，却在需要回想多数标记的任务中效果有限。作者提出LESS框架，这是一种简单整合，将一个几乎免费的恒定大小缓存与基于驱逐的缓存方法结合，允许所有标记在后续解码步骤中被查询，从而更好地保留历史信息。在各种任务中，LESS显著缩小了与完整缓存的性能差距，有时甚至匹配其表现，同时保持高效，相关代码可在GitHub上获取。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09398v2",
      "published_date": "2024-02-14 18:54:56 UTC",
      "updated_date": "2024-06-12 06:08:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:08:56.548840"
    },
    {
      "arxiv_id": "2402.10240v2",
      "title": "A Dynamical View of the Question of Why",
      "title_zh": "翻译失败",
      "authors": [
        "Mehdi Fatemi",
        "Sindhu Gowda"
      ],
      "abstract": "We address causal reasoning in multivariate time series data generated by\nstochastic processes. Existing approaches are largely restricted to static\nsettings, ignoring the continuity and emission of variations across time. In\ncontrast, we propose a learning paradigm that directly establishes causation\nbetween events in the course of time. We present two key lemmas to compute\ncausal contributions and frame them as reinforcement learning problems. Our\napproach offers formal and computational tools for uncovering and quantifying\ncausal relationships in diffusion processes, subsuming various important\nsettings such as discrete-time Markov decision processes. Finally, in fairly\nintricate experiments and through sheer learning, our framework reveals and\nquantifies causal links, which otherwise seem inexplicable.",
      "tldr_zh": "这篇论文从动态视角探讨多元时间序列数据中由随机过程(stochastic processes)生成的事件间的因果推理(causal reasoning)，克服了现有方法局限于静态设置的局限性。作者提出了一种新学习范式，通过两个关键引理(lems)计算因果贡献，并将其转化为强化学习(reinforcement learning)问题，提供工具来揭示和量化扩散过程(diffusion processes)中的因果关系，包括离散时间Markov决策过程(Markov decision processes)。实验结果显示，该框架在复杂场景中成功识别并量化了原本难以解释的因果链接。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the Twelfth International Conference on Learning\n  Representations (ICLR'24)",
      "pdf_url": "http://arxiv.org/pdf/2402.10240v2",
      "published_date": "2024-02-14 18:44:05 UTC",
      "updated_date": "2024-02-27 22:11:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:09:09.102601"
    },
    {
      "arxiv_id": "2402.09392v1",
      "title": "LL-GABR: Energy Efficient Live Video Streaming Using Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Adithya Raman",
        "Bekir Turkkan",
        "Tevfik Kosar"
      ],
      "abstract": "Over the recent years, research and development in adaptive bitrate (ABR)\nalgorithms for live video streaming have been successful in improving users'\nquality of experience (QoE) by reducing latency to near real-time levels while\ndelivering higher bitrate videos with minimal rebuffering time. However, the\nQoE models used by these ABR algorithms do not take into account that a large\nportion of live video streaming clients use mobile devices where a higher\nbitrate does not necessarily translate into higher perceived quality. Ignoring\nperceived quality results in playing videos at higher bitrates without a\nsignificant increase in perceptual video quality and becomes a burden for\nbattery-constrained mobile devices due to higher energy consumption. In this\npaper, we propose LL-GABR, a deep reinforcement learning approach that models\nthe QoE using perceived video quality instead of bitrate and uses energy\nconsumption along with other metrics like latency, rebuffering events, and\nsmoothness. LL-GABR makes no assumptions about the underlying video,\nenvironment, or network settings and can operate flexibly on different video\ntitles, each having a different bitrate encoding ladder without additional\nre-training, unlike existing learning-based ABRs. Trace-driven experimental\nresults show that LL-GABR outperforms the state-of-the-art approaches by up to\n44% in terms of perceptual QoE and a 73% increase in energy efficiency as a\nresult of reducing net energy consumption by 11%.",
      "tldr_zh": "论文提出 LL-GABR，一种基于深度强化学习的算法，用于实现能量高效的直播视频流。不同于传统 ABR 算法，LL-GABR 通过使用感知视频质量代替比特率来建模 QoE，同时整合能量消耗、延迟、缓冲事件和流畅性指标，且无需针对不同视频标题或网络环境进行额外训练。实验结果显示，LL-GABR 比现有方法在感知 QoE 上提升多达 44%，并通过减少 11% 的净能量消耗，实现 73% 的能量效率提高。",
      "categories": [
        "cs.MM",
        "cs.AI"
      ],
      "primary_category": "cs.MM",
      "comment": "10 pages, 3 figures, 3 Tables",
      "pdf_url": "http://arxiv.org/pdf/2402.09392v1",
      "published_date": "2024-02-14 18:43:19 UTC",
      "updated_date": "2024-02-14 18:43:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:09:20.987041"
    },
    {
      "arxiv_id": "2402.09391v4",
      "title": "LlaSMol: Advancing Large Language Models for Chemistry with a Large-Scale, Comprehensive, High-Quality Instruction Tuning Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Botao Yu",
        "Frazier N. Baker",
        "Ziqi Chen",
        "Xia Ning",
        "Huan Sun"
      ],
      "abstract": "Chemistry plays a crucial role in many domains, such as drug discovery and\nmaterial science. While large language models (LLMs) such as GPT-4 exhibit\nremarkable capabilities on natural language processing tasks, existing research\nindicates that their performance on chemistry tasks is discouragingly low. In\nthis paper, however, we demonstrate that our developed LLMs can achieve very\nstrong results on a comprehensive set of chemistry tasks, outperforming the\nmost advanced GPT-4 and Claude 3 Opus by a substantial margin. To accomplish\nthis, we propose SMolInstruct, a large-scale, comprehensive, and high-quality\ndataset for instruction tuning. It contains 14 selected chemistry tasks and\nover three million samples, laying a solid foundation for training and\nevaluating LLMs for chemistry. Using SMolInstruct, we fine-tune a set of\nopen-source LLMs, among which, we find that Mistral serves as the best base\nmodel for chemistry tasks. Our analysis further demonstrates the critical role\nof the proposed dataset in driving the performance improvements.",
      "tldr_zh": "该研究指出，现有的LLMs如GPT-4在化学任务上表现不佳，因此提出LlaSMol框架及其SMolInstruct数据集，该数据集包含14个化学任务和超过300万高质量样本，用于指令微调。研究人员使用SMolInstruct对开源LLMs进行微调，发现Mistral作为基模型在化学任务上表现最佳，并大幅超过GPT-4和Claude 3 Opus。分析显示，该数据集是驱动性能提升的关键，为LLMs在化学领域的应用奠定了坚实基础。",
      "categories": [
        "cs.AI",
        "cs.CE",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09391v4",
      "published_date": "2024-02-14 18:42:25 UTC",
      "updated_date": "2024-08-10 13:28:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:09:32.407820"
    },
    {
      "arxiv_id": "2402.09390v2",
      "title": "HGOT: Hierarchical Graph of Thoughts for Retrieval-Augmented In-Context Learning in Factuality Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Yihao Fang",
        "Stephen W. Thomas",
        "Xiaodan Zhu"
      ],
      "abstract": "With the widespread adoption of large language models (LLMs) in numerous\napplications, the challenge of factuality and the propensity for hallucinations\nhas emerged as a significant concern. To address this issue, particularly in\nretrieval-augmented in-context learning, we introduce the hierarchical graph of\nthoughts (HGOT), a structured, multi-layered graph approach designed to enhance\nthe retrieval of pertinent passages during in-context learning. The framework\nutilizes the emergent planning capabilities of LLMs, employing the\ndivide-and-conquer strategy to break down complex queries into manageable\nsub-queries. It refines self-consistency majority voting for answer selection,\nwhich incorporates the recently proposed citation recall and precision metrics\nto assess the quality of thoughts, linking an answer's credibility\nintrinsically to the thought's quality. This methodology introduces a weighted\nsystem in majority voting, prioritizing answers based on the citation quality\nof their thoughts. Additionally, we propose a scoring mechanism for evaluating\nretrieved passages, considering factors such as citation frequency and quality,\nself-consistency confidence, and the retrieval module's ranking. Experiments\nindicate that HGOT excels as a versatile approach, outperforming competing\nmodels in FEVER by up to $7\\%$ and matching leading models such as\nRetrieve-then-Read in Open-SQuAD, and DSP in HotPotQA, demonstrating its\nefficacy in enhancing LLMs' factuality.",
      "tldr_zh": "本文提出 HGOT（Hierarchical Graph of Thoughts），一种分层图结构框架，用于提升检索增强的 in-context learning 在事实性评估中的性能，旨在解决大型语言模型（LLMs）面临的幻觉问题。HGOT 利用 LLMs 的规划能力，通过 divide-and-conquer 策略分解复杂查询为子查询，并改进 self-consistency majority voting 机制，结合 citation recall 和 precision 指标评估 thoughts 质量，并引入加权系统和检索段落评分机制。实验结果表明，HGOT 在 FEVER 数据集上比竞争模型提升高达 7%，并在 Open-SQuAD 和 HotPotQA 上与领先模型（如 Retrieve-then-Read 和 DSP）匹配或超越，显著提高了 LLMs 的事实性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09390v2",
      "published_date": "2024-02-14 18:41:19 UTC",
      "updated_date": "2024-07-02 12:42:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:09:47.220005"
    },
    {
      "arxiv_id": "2402.09388v1",
      "title": "Entropy-regularized Point-based Value Iteration",
      "title_zh": "翻译失败",
      "authors": [
        "Harrison Delecki",
        "Marcell Vazquez-Chanlatte",
        "Esen Yel",
        "Kyle Wray",
        "Tomer Arnon",
        "Stefan Witwicki",
        "Mykel J. Kochenderfer"
      ],
      "abstract": "Model-based planners for partially observable problems must accommodate both\nmodel uncertainty during planning and goal uncertainty during objective\ninference. However, model-based planners may be brittle under these types of\nuncertainty because they rely on an exact model and tend to commit to a single\noptimal behavior. Inspired by results in the model-free setting, we propose an\nentropy-regularized model-based planner for partially observable problems.\nEntropy regularization promotes policy robustness for planning and objective\ninference by encouraging policies to be no more committed to a single action\nthan necessary. We evaluate the robustness and objective inference performance\nof entropy-regularized policies in three problem domains. Our results show that\nentropy-regularized policies outperform non-entropy-regularized baselines in\nterms of higher expected returns under modeling errors and higher accuracy\nduring objective inference.",
      "tldr_zh": "该论文提出了一种熵正则化的点-based 值迭代（Entropy-regularized Point-based Value Iteration）方法，用于处理部分可观测问题中的模型不确定性和目标不确定性。相比传统模型-based planners，该方法通过熵正则化鼓励策略不偏向单一动作，从而提升策略的鲁棒性和目标推断的性能。在三个问题领域评估中，熵正则化策略在建模错误下实现了更高的预期回报，并显著提高了目标推断的准确性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09388v1",
      "published_date": "2024-02-14 18:37:47 UTC",
      "updated_date": "2024-02-14 18:37:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:09:56.147976"
    },
    {
      "arxiv_id": "2402.09384v2",
      "title": "Persuasion, Delegation, and Private Information in Algorithm-Assisted Decisions",
      "title_zh": "翻译失败",
      "authors": [
        "Ruqing Xu"
      ],
      "abstract": "A principal designs an algorithm that generates a publicly observable\nprediction of a binary state. She must decide whether to act directly based on\nthe prediction or to delegate the decision to an agent with private information\nbut potential misalignment. We study the optimal design of the prediction\nalgorithm and the delegation rule in such environments. Three key findings\nemerge: (1) Delegation is optimal if and only if the principal would make the\nsame binary decision as the agent had she observed the agent's information. (2)\nProviding the most informative algorithm may be suboptimal even if the\nprincipal can act on the algorithm's prediction. Instead, the optimal algorithm\nmay provide more information about one state and restrict information about the\nother. (3) Well-intentioned policies aiming to provide more information, such\nas keeping a \"human-in-the-loop\" or requiring maximal prediction accuracy,\ncould strictly worsen decision quality compared to systems with no human or no\nalgorithmic assistance. These findings predict the underperformance of\nhuman-machine collaborations if no measures are taken to mitigate common\npreference misalignment between algorithms and human decision-makers.",
      "tldr_zh": "该研究探讨了在算法辅助决策中，principal（决策者）如何设计一个生成二元状态预测的算法，并决定是基于预测自行行动还是委托给有private information但可能偏好的agent（代理人）。主要发现包括：委托仅在principal会与agent做出相同决策时才是最优的；最信息丰富的算法可能并非最优，最优设计可能优先提供一种状态的信息而限制另一种；以及某些政策如“human-in-the-loop”或追求最大预测准确性，可能使决策质量低于无辅助系统。这些结果突显了缓解算法与人类偏好不一致的重要性，以避免人机协作表现不佳。",
      "categories": [
        "econ.TH",
        "cs.AI",
        "cs.CY",
        "cs.GT",
        "cs.HC"
      ],
      "primary_category": "econ.TH",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09384v2",
      "published_date": "2024-02-14 18:32:30 UTC",
      "updated_date": "2024-02-21 18:01:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:10:10.053173"
    },
    {
      "arxiv_id": "2402.09372v1",
      "title": "Deep Rib Fracture Instance Segmentation and Classification from CT on the RibFrac Challenge",
      "title_zh": "翻译失败",
      "authors": [
        "Jiancheng Yang",
        "Rui Shi",
        "Liang Jin",
        "Xiaoyang Huang",
        "Kaiming Kuang",
        "Donglai Wei",
        "Shixuan Gu",
        "Jianying Liu",
        "Pengfei Liu",
        "Zhizhong Chai",
        "Yongjie Xiao",
        "Hao Chen",
        "Liming Xu",
        "Bang Du",
        "Xiangyi Yan",
        "Hao Tang",
        "Adam Alessio",
        "Gregory Holste",
        "Jiapeng Zhang",
        "Xiaoming Wang",
        "Jianye He",
        "Lixuan Che",
        "Hanspeter Pfister",
        "Ming Li",
        "Bingbing Ni"
      ],
      "abstract": "Rib fractures are a common and potentially severe injury that can be\nchallenging and labor-intensive to detect in CT scans. While there have been\nefforts to address this field, the lack of large-scale annotated datasets and\nevaluation benchmarks has hindered the development and validation of deep\nlearning algorithms. To address this issue, the RibFrac Challenge was\nintroduced, providing a benchmark dataset of over 5,000 rib fractures from 660\nCT scans, with voxel-level instance mask annotations and diagnosis labels for\nfour clinical categories (buckle, nondisplaced, displaced, or segmental). The\nchallenge includes two tracks: a detection (instance segmentation) track\nevaluated by an FROC-style metric and a classification track evaluated by an\nF1-style metric. During the MICCAI 2020 challenge period, 243 results were\nevaluated, and seven teams were invited to participate in the challenge\nsummary. The analysis revealed that several top rib fracture detection\nsolutions achieved performance comparable or even better than human experts.\nNevertheless, the current rib fracture classification solutions are hardly\nclinically applicable, which can be an interesting area in the future. As an\nactive benchmark and research resource, the data and online evaluation of the\nRibFrac Challenge are available at the challenge website. As an independent\ncontribution, we have also extended our previous internal baseline by\nincorporating recent advancements in large-scale pretrained networks and\npoint-based rib segmentation techniques. The resulting FracNet+ demonstrates\ncompetitive performance in rib fracture detection, which lays a foundation for\nfurther research and development in AI-assisted rib fracture detection and\ndiagnosis.",
      "tldr_zh": "该论文介绍了RibFrac Challenge，这是一个针对CT扫描中肋骨骨折检测的基准数据集，包含超过5,000个骨折实例的体素级实例掩码标注和四类临床分类（buckle, nondisplaced, displaced, or segmental）。挑战包括检测（instance segmentation，使用FROC-style metric评估）和分类（使用F1-style metric评估）两个轨道，分析显示顶级AI解决方案在检测性能上已达到或超过人类专家水平，但分类方法仍需改进。作为独立贡献，作者扩展了FracNet+模型，整合大型预训练网络和点云分割技术，展示了竞争性的骨折检测性能，为AI辅助诊断奠定基础。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Challenge paper for MICCAI RibFrac Challenge\n  (https://ribfrac.grand-challenge.org/)",
      "pdf_url": "http://arxiv.org/pdf/2402.09372v1",
      "published_date": "2024-02-14 18:18:33 UTC",
      "updated_date": "2024-02-14 18:18:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:10:22.998167"
    },
    {
      "arxiv_id": "2402.09371v1",
      "title": "Transformers Can Achieve Length Generalization But Not Robustly",
      "title_zh": "Transformers 可以实现长度泛化，但并非稳健",
      "authors": [
        "Yongchao Zhou",
        "Uri Alon",
        "Xinyun Chen",
        "Xuezhi Wang",
        "Rishabh Agarwal",
        "Denny Zhou"
      ],
      "abstract": "Length generalization, defined as the ability to extrapolate from shorter\ntraining sequences to longer test ones, is a significant challenge for language\nmodels. This issue persists even with large-scale Transformers handling\nrelatively straightforward tasks. In this paper, we test the Transformer's\nability of length generalization using the task of addition of two integers. We\nshow that the success of length generalization is intricately linked to the\ndata format and the type of position encoding. Using the right combination of\ndata format and position encodings, we show for the first time that standard\nTransformers can extrapolate to a sequence length that is 2.5x the input\nlength. Nevertheless, unlike in-distribution generalization, length\ngeneralization remains fragile, significantly influenced by factors like random\nweight initialization and training data order, leading to large variances\nacross different random seeds.",
      "tldr_zh": "本研究探讨了Transformer模型在长度泛化（Length Generalization）方面的能力，即从较短训练序列外推到较长测试序列的挑战。作者使用整数加法任务作为测试基准，分析了数据格式和位置编码（Position Encoding）类型的影响，发现合适的组合能使标准Transformer外推到序列长度达输入长度的2.5倍。尽管取得了这一进展，但长度泛化不如分布内泛化稳健，受随机权重初始化和训练数据顺序的影响，导致不同随机种子间表现差异巨大。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09371v1",
      "published_date": "2024-02-14 18:18:29 UTC",
      "updated_date": "2024-02-14 18:18:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:10:36.059958"
    },
    {
      "arxiv_id": "2402.09370v2",
      "title": "Pseudorandom Error-Correcting Codes",
      "title_zh": "伪随机纠错码",
      "authors": [
        "Miranda Christ",
        "Sam Gunn"
      ],
      "abstract": "We construct pseudorandom error-correcting codes (or simply pseudorandom\ncodes), which are error-correcting codes with the property that any polynomial\nnumber of codewords are pseudorandom to any computationally-bounded adversary.\nEfficient decoding of corrupted codewords is possible with the help of a\ndecoding key.\n  We build pseudorandom codes that are robust to substitution and deletion\nerrors, where pseudorandomness rests on standard cryptographic assumptions.\nSpecifically, pseudorandomness is based on either $2^{O(\\sqrt{n})}$-hardness of\nLPN, or polynomial hardness of LPN and the planted XOR problem at low density.\n  As our primary application of pseudorandom codes, we present an undetectable\nwatermarking scheme for outputs of language models that is robust to cropping\nand a constant rate of random substitutions and deletions. The watermark is\nundetectable in the sense that any number of samples of watermarked text are\ncomputationally indistinguishable from text output by the original model. This\nis the first undetectable watermarking scheme that can tolerate a constant rate\nof errors.\n  Our second application is to steganography, where a secret message is hidden\nin innocent-looking content. We present a constant-rate stateless steganography\nscheme with robustness to a constant rate of substitutions. Ours is the first\nstateless steganography scheme with provable steganographic security and any\nrobustness to errors.",
      "tldr_zh": "该论文引入了 pseudorandom error-correcting codes，一种纠错码，能够使任何多项式数量的码字对计算受限的对手呈现伪随机性，同时支持高效解码。研究基于标准加密假设（如 LPN 的 $2^{O(\\sqrt{n})}$ 硬度或 LPN 和 planted XOR problem 的多项式硬度）构建了针对替换和删除错误的鲁棒码。论文的主要应用包括一个对语言模型输出的 undetectable watermarking 方案，能抵抗裁剪和恒定比例的随机替换/删除错误，这是首个能容忍此类错误率的不检测水印方法。另一个应用是 steganography，提供了一个恒定率的无状态隐写方案，具有对替换错误的鲁棒性和可证明的安全性，这是该领域的首次创新。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09370v2",
      "published_date": "2024-02-14 18:17:45 UTC",
      "updated_date": "2024-06-18 01:00:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:10:48.151775"
    },
    {
      "arxiv_id": "2402.09368v2",
      "title": "Magic-Me: Identity-Specific Video Customized Diffusion",
      "title_zh": "Magic-Me：身份特定的视频定制扩散",
      "authors": [
        "Ze Ma",
        "Daquan Zhou",
        "Chun-Hsiao Yeh",
        "Xue-She Wang",
        "Xiuyu Li",
        "Huanrui Yang",
        "Zhen Dong",
        "Kurt Keutzer",
        "Jiashi Feng"
      ],
      "abstract": "Creating content with specified identities (ID) has attracted significant\ninterest in the field of generative models. In the field of text-to-image\ngeneration (T2I), subject-driven creation has achieved great progress with the\nidentity controlled via reference images. However, its extension to video\ngeneration is not well explored. In this work, we propose a simple yet\neffective subject identity controllable video generation framework, termed\nVideo Custom Diffusion (VCD). With a specified identity defined by a few\nimages, VCD reinforces the identity characteristics and injects frame-wise\ncorrelation at the initialization stage for stable video outputs. To achieve\nthis, we propose three novel components that are essential for high-quality\nidentity preservation and stable video generation: 1) a noise initialization\nmethod with 3D Gaussian Noise Prior for better inter-frame stability; 2) an ID\nmodule based on extended Textual Inversion trained with the cropped identity to\ndisentangle the ID information from the background 3) Face VCD and Tiled VCD\nmodules to reinforce faces and upscale the video to higher resolution while\npreserving the identity's features. We conducted extensive experiments to\nverify that VCD is able to generate stable videos with better ID over the\nbaselines. Besides, with the transferability of the encoded identity in the ID\nmodule, VCD is also working well with personalized text-to-image models\navailable publicly. The codes are available at\nhttps://github.com/Zhen-Dong/Magic-Me.",
      "tldr_zh": "该论文提出 Magic-Me 框架，即 Identity-Specific Video Customized Diffusion (VCD)，一种简单有效的视频生成方法，通过几张参考图像实现主体身份的精确控制。VCD 在初始化阶段强化身份特征并注入帧间相关性，包括三个关键组件：1) 使用 3D Gaussian Noise Prior 的噪声初始化方法提升视频稳定性；2) 基于扩展 Textual Inversion 的 ID 模块，通过训练裁剪的身份图像分离 ID 信息和背景；3) Face VCD 和 Tiled VCD 模块，用于强化面部特征并提升视频分辨率，同时保持身份完整。实验结果表明，VCD 生成的视频在身份保留和稳定性上优于基线模型，且其 ID 模块的身份编码具有可转移性，可与公共的个性化文本到图像模型兼容。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page at https://magic-me-webpage.github.io",
      "pdf_url": "http://arxiv.org/pdf/2402.09368v2",
      "published_date": "2024-02-14 18:13:51 UTC",
      "updated_date": "2024-03-20 17:36:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:11:02.387113"
    },
    {
      "arxiv_id": "2402.09360v1",
      "title": "HiRE: High Recall Approximate Top-$k$ Estimation for Efficient LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Yashas Samaga B L",
        "Varun Yerram",
        "Chong You",
        "Srinadh Bhojanapalli",
        "Sanjiv Kumar",
        "Prateek Jain",
        "Praneeth Netrapalli"
      ],
      "abstract": "Autoregressive decoding with generative Large Language Models (LLMs) on\naccelerators (GPUs/TPUs) is often memory-bound where most of the time is spent\non transferring model parameters from high bandwidth memory (HBM) to cache. On\nthe other hand, recent works show that LLMs can maintain quality with\nsignificant sparsity/redundancy in the feedforward (FFN) layers by\nappropriately training the model to operate on a top-$k$ fraction of\nrows/columns (where $k \\approx 0.05$), there by suggesting a way to reduce the\ntransfer of model parameters, and hence latency. However, exploiting this\nsparsity for improving latency is hindered by the fact that identifying top\nrows/columns is data-dependent and is usually performed using full matrix\noperations, severely limiting potential gains. To address these issues, we\nintroduce HiRE (High Recall Approximate Top-k Estimation). HiRE comprises of\ntwo novel components: (i) a compression scheme to cheaply predict top-$k$\nrows/columns with high recall, followed by full computation restricted to the\npredicted subset, and (ii) DA-TOP-$k$: an efficient multi-device approximate\ntop-$k$ operator. We demonstrate that on a one billion parameter model, HiRE\napplied to both the softmax as well as feedforward layers, achieves almost\nmatching pretraining and downstream accuracy, and speeds up inference latency\nby $1.47\\times$ on a single TPUv5e device.",
      "tldr_zh": "该论文提出 HiRE（High Recall Approximate Top-$k$ Estimation），一种高效方法，用于优化生成式 Large Language Models (LLMs) 的推理过程，以解决内存传输瓶颈问题。HiRE 包括两个关键组件：一个高召回率的压缩方案，用于快速预测并仅在 top-$k$ 子集上进行全矩阵计算，以及 DA-TOP-$k$，一个多设备近似 top-$k$ 运算符。实验结果显示，在一个十亿参数模型上，HiRE 应用于 softmax 和 feedforward (FFN) 层后，保持了预训练和下游准确性，并在单个 TPUv5e 设备上将推理延迟加速 1.47 倍。总的来说，该方法为减少 LLM 推理中的参数传输提供了可行途径，提升了整体效率。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09360v1",
      "published_date": "2024-02-14 18:04:36 UTC",
      "updated_date": "2024-02-14 18:04:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:11:12.280754"
    },
    {
      "arxiv_id": "2402.09358v1",
      "title": "Integrating ChatGPT into Secure Hospital Networks: A Case Study on Improving Radiology Report Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Kyungsu Kim",
        "Junhyun Park",
        "Saul Langarica",
        "Adham Mahmoud Alkhadrawi",
        "Synho Do"
      ],
      "abstract": "This study demonstrates the first in-hospital adaptation of a cloud-based AI,\nsimilar to ChatGPT, into a secure model for analyzing radiology reports,\nprioritizing patient data privacy. By employing a unique sentence-level\nknowledge distillation method through contrastive learning, we achieve over 95%\naccuracy in detecting anomalies. The model also accurately flags uncertainties\nin its predictions, enhancing its reliability and interpretability for\nphysicians with certainty indicators. These advancements represent significant\nprogress in developing secure and efficient AI tools for healthcare, suggesting\na promising future for in-hospital AI applications with minimal supervision.",
      "tldr_zh": "本研究首次将类似ChatGPT的云AI整合到医院安全网络中，用于放射学报告分析，同时优先保护患者数据隐私。采用独特的句子级知识蒸馏(sentence-level knowledge distillation)方法，通过对比学习(contrastive learning)，实现了超过95%的异常检测准确率，并能准确标记预测不确定性，从而提升模型的可靠性和可解释性。实验结果表明，这种方法为开发安全、高效的医疗AI工具提供了重大进展，预示着未来医院AI应用的前景广阔，且只需最少监督。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09358v1",
      "published_date": "2024-02-14 18:02:24 UTC",
      "updated_date": "2024-02-14 18:02:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:11:22.956808"
    },
    {
      "arxiv_id": "2402.09355v1",
      "title": "Single-Reset Divide & Conquer Imitation Learning",
      "title_zh": "单次重置分治模仿学习",
      "authors": [
        "Alexandre Chenu",
        "Olivier Serris",
        "Olivier Sigaud",
        "Nicolas Perrin-Gilbert"
      ],
      "abstract": "Demonstrations are commonly used to speed up the learning process of Deep\nReinforcement Learning algorithms. To cope with the difficulty of accessing\nmultiple demonstrations, some algorithms have been developed to learn from a\nsingle demonstration. In particular, the Divide & Conquer Imitation Learning\nalgorithms leverage a sequential bias to learn a control policy for complex\nrobotic tasks using a single state-based demonstration. The latest version,\nDCIL-II demonstrates remarkable sample efficiency. This novel method operates\nwithin an extended Goal-Conditioned Reinforcement Learning framework, ensuring\ncompatibility between intermediate and subsequent goals extracted from the\ndemonstration. However, a fundamental limitation arises from the assumption\nthat the system can be reset to specific states along the demonstrated\ntrajectory, confining the application to simulated systems. In response, we\nintroduce an extension called Single-Reset DCIL (SR-DCIL), designed to overcome\nthis constraint by relying on a single initial state reset rather than\nsequential resets. To address this more challenging setting, we integrate two\nmechanisms inspired by the Learning from Demonstrations literature, including a\nDemo-Buffer and Value Cloning, to guide the agent toward compatible success\nstates. In addition, we introduce Approximate Goal Switching to facilitate\ntraining to reach goals distant from the reset state. Our paper makes several\ncontributions, highlighting the importance of the reset assumption in DCIL-II,\npresenting the mechanisms of SR-DCIL variants and evaluating their performance\nin challenging robotic tasks compared to DCIL-II. In summary, this work offers\ninsights into the significance of reset assumptions in the framework of DCIL\nand proposes SR-DCIL, a first step toward a versatile algorithm capable of\nlearning control policies under a weaker reset assumption.",
      "tldr_zh": "该研究扩展了 Divide & Conquer Imitation Learning (DCIL-II)，提出 Single-Reset DCIL (SR-DCIL) 算法，以克服 DCIL-II 对系统多次重置的依赖，仅需单个初始状态重置即可学习复杂机器人任务的控制策略。SR-DCIL 整合了 Demo-Buffer、Value Cloning 和 Approximate Goal Switching 等机制，帮助代理从演示中提取目标并引导其达到兼容的成功状态。实验结果显示，SR-DCIL 在挑战性机器人任务中表现出色，与 DCIL-II 相比提升了性能，并为在更弱重置假设下实现通用强化学习提供了重要见解。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09355v1",
      "published_date": "2024-02-14 17:59:47 UTC",
      "updated_date": "2024-02-14 17:59:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:11:37.088812"
    },
    {
      "arxiv_id": "2402.09346v3",
      "title": "LLMAuditor: A Framework for Auditing Large Language Models Using Human-in-the-Loop",
      "title_zh": "翻译失败",
      "authors": [
        "Maryam Amirizaniani",
        "Jihan Yao",
        "Adrian Lavergne",
        "Elizabeth Snell Okada",
        "Aman Chadha",
        "Tanya Roosta",
        "Chirag Shah"
      ],
      "abstract": "As Large Language Models (LLMs) become more pervasive across various users\nand scenarios, identifying potential issues when using these models becomes\nessential. Examples of such issues include: bias, inconsistencies, and\nhallucination. Although auditing the LLM for these problems is often warranted,\nsuch a process is neither easy nor accessible for most. An effective method is\nto probe the LLM using different versions of the same question. This could\nexpose inconsistencies in its knowledge or operation, indicating potential for\nbias or hallucination. However, to operationalize this auditing method at\nscale, we need an approach to create those probes reliably and automatically.\nIn this paper we propose the LLMAuditor framework which is an automatic, and\nscalable solution, where one uses a different LLM along with human-in-the-loop\n(HIL). This approach offers verifiability and transparency, while avoiding\ncircular reliance on the same LLM, and increasing scientific rigor and\ngeneralizability. Specifically, LLMAuditor includes two phases of verification\nusing humans: standardized evaluation criteria to verify responses, and a\nstructured prompt template to generate desired probes. A case study using\nquestions from the TruthfulQA dataset demonstrates that we can generate a\nreliable set of probes from one LLM that can be used to audit inconsistencies\nin a different LLM. This process is enhanced by our structured prompt template\nwith HIL, which not only boosts the reliability of our approach in auditing but\nalso yields the delivery of less hallucinated results. The novelty of our\nresearch stems from the development of a comprehensive, general-purpose\nframework that includes a HIL verified prompt template for auditing responses\ngenerated by LLMs.",
      "tldr_zh": "该研究提出 LLMAuditor 框架，用于审计 Large Language Models (LLMs) 的潜在问题，如 bias、inconsistencies 和 hallucination，通过 Human-in-the-Loop (HIL) 机制实现可扩展性和可靠性。框架的核心方法是使用另一个 LLM 生成探测问题，并结合两阶段 HIL 验证：标准化评估标准验证响应，以及结构化提示模板自动创建高质量探测。案例研究基于 TruthfulQA 数据集，展示了该框架能有效识别其他 LLM 的不一致性，并显著减少幻觉现象。总体上，LLMAuditor 提供了一个全面的通用解决方案，提升了审计过程的透明度、科学严谨性和泛化能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09346v3",
      "published_date": "2024-02-14 17:49:31 UTC",
      "updated_date": "2024-05-22 17:17:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:11:49.764258"
    },
    {
      "arxiv_id": "2402.09345v5",
      "title": "InfoRM: Mitigating Reward Hacking in RLHF via Information-Theoretic Reward Modeling",
      "title_zh": "InfoRM：通过信息论奖励建模减轻 RLHF 中的奖励黑客",
      "authors": [
        "Yuchun Miao",
        "Sen Zhang",
        "Liang Ding",
        "Rong Bao",
        "Lefei Zhang",
        "Dacheng Tao"
      ],
      "abstract": "Despite the success of reinforcement learning from human feedback (RLHF) in\naligning language models with human values, reward hacking, also termed reward\noveroptimization, remains a critical challenge. This issue primarily arises\nfrom reward misgeneralization, where reward models (RMs) compute reward using\nspurious features that are irrelevant to human preferences. In this work, we\ntackle this problem from an information-theoretic perspective and propose a\nframework for reward modeling, namely InfoRM, by introducing a variational\ninformation bottleneck objective to filter out irrelevant information. Notably,\nwe further identify a correlation between overoptimization and outliers in the\nIB latent space of InfoRM, establishing it as a promising tool for detecting\nreward overoptimization. Inspired by this finding, we propose the Cluster\nSeparation Index (CSI), which quantifies deviations in the IB latent space, as\nan indicator of reward overoptimization to facilitate the development of online\nmitigation strategies. Extensive experiments on a wide range of settings and RM\nscales (70M, 440M, 1.4B, and 7B) demonstrate the effectiveness of InfoRM.\nFurther analyses reveal that InfoRM's overoptimization detection mechanism is\nnot only effective but also robust across a broad range of datasets, signifying\na notable advancement in the field of RLHF. The code will be released upon\nacceptance.",
      "tldr_zh": "该论文针对强化学习从人类反馈（RLHF）中的奖励黑客（reward hacking）问题，提出InfoRM框架，通过引入变分信息瓶颈目标（variational information bottleneck objective）来过滤奖励模型（RMs）中与人类偏好无关的虚假特征，从而缓解奖励过优化。\nInfoRM进一步发现过优化与信息瓶颈（IB）潜在空间中的异常值相关，并开发了Cluster Separation Index (CSI)作为量化潜在空间偏差的检测工具，以支持在线缓解策略。\n实验在多种设置和RM规模（70M、440M、1.4B和7B）上验证了InfoRM的有效性，并证明其检测机制在不同数据集上均表现出色和鲁棒性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "The paper has been accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09345v5",
      "published_date": "2024-02-14 17:49:07 UTC",
      "updated_date": "2024-11-01 06:30:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:12:00.452044"
    },
    {
      "arxiv_id": "2402.09338v2",
      "title": "Neural Networks Asymptotic Behaviours for the Resolution of Inverse Problems",
      "title_zh": "神经网络渐近行为用于逆问题的求解",
      "authors": [
        "Luigi Del Debbio",
        "Manuel Naviglio",
        "Francesco Tarantelli"
      ],
      "abstract": "This paper presents a study of the effectiveness of Neural Network (NN)\ntechniques for deconvolution inverse problems relevant for applications in\nQuantum Field Theory, but also in more general contexts. We consider NN's\nasymptotic limits, corresponding to Gaussian Processes (GPs), where\nnon-linearities in the parameters of the NN can be neglected. Using these\nresulting GPs, we address the deconvolution inverse problem in the case of a\nquantum harmonic oscillator simulated through Monte Carlo techniques on a\nlattice. In this simple toy model, the results of the inversion can be compared\nwith the known analytical solution. Our findings indicate that solving the\ninverse problem with a NN yields less performing results than those obtained\nusing the GPs derived from NN's asymptotic limits. Furthermore, we observe the\ntrained NN's accuracy approaching that of GPs with increasing layer width.\nNotably, one of these GPs defies interpretation as a probabilistic model,\noffering a novel perspective compared to established methods in the literature.\nOur results suggest the need for detailed studies of the training dynamics in\nmore realistic set-ups.",
      "tldr_zh": "本论文研究了神经网络（NN）在反演问题（deconvolution inverse problems）中的有效性，特别是应用于量子场论（Quantum Field Theory）和其他领域。作者分析了 NN 的渐近极限，即对应于高斯过程（GPs）的行为，通过忽略参数非线性，并使用这些 GPs 解决量子谐振子模型的模拟反演问题。结果显示，NN 的性能不如从其渐近极限得出的 GPs，且随着层宽度的增加，训练后的 NN 准确率逐渐接近 GPs；此外，其中一个 GPs 无法解释为概率模型，提供了一个新颖视角。论文建议在更现实的场景中进行深入的训练动态研究，以改进这些方法。",
      "categories": [
        "physics.comp-ph",
        "cs.AI",
        "hep-lat",
        "hep-th"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09338v2",
      "published_date": "2024-02-14 17:42:24 UTC",
      "updated_date": "2024-02-15 12:07:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:12:12.382579"
    },
    {
      "arxiv_id": "2402.09334v2",
      "title": "AuditLLM: A Tool for Auditing Large Language Models Using Multiprobe Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Maryam Amirizaniani",
        "Elias Martin",
        "Tanya Roosta",
        "Aman Chadha",
        "Chirag Shah"
      ],
      "abstract": "As Large Language Models (LLMs) are integrated into various sectors, ensuring\ntheir reliability and safety is crucial. This necessitates rigorous probing and\nauditing to maintain their effectiveness and trustworthiness in practical\napplications. Subjecting LLMs to varied iterations of a single query can unveil\npotential inconsistencies in their knowledge base or functional capacity.\nHowever, a tool for performing such audits with a easy to execute workflow, and\nlow technical threshold is lacking. In this demo, we introduce ``AuditLLM,'' a\nnovel tool designed to audit the performance of various LLMs in a methodical\nway. AuditLLM's primary function is to audit a given LLM by deploying multiple\nprobes derived from a single question, thus detecting any inconsistencies in\nthe model's comprehension or performance. A robust, reliable, and consistent\nLLM is expected to generate semantically similar responses to variably phrased\nversions of the same question. Building on this premise, AuditLLM generates\neasily interpretable results that reflect the LLM's consistency based on a\nsingle input question provided by the user. A certain level of inconsistency\nhas been shown to be an indicator of potential bias, hallucinations, and other\nissues. One could then use the output of AuditLLM to further investigate issues\nwith the aforementioned LLM. To facilitate demonstration and practical uses,\nAuditLLM offers two key modes: (1) Live mode which allows instant auditing of\nLLMs by analyzing responses to real-time queries; and (2) Batch mode which\nfacilitates comprehensive LLM auditing by processing multiple queries at once\nfor in-depth analysis. This tool is beneficial for both researchers and general\nusers, as it enhances our understanding of LLMs' capabilities in generating\nresponses, using a standardized auditing platform.",
      "tldr_zh": "该研究引入了 AuditLLM，这是一个用于审计 Large Language Models (LLMs) 的工具，采用 Multiprobe Approach 通过对单一查询的多个变体进行测试，检测模型在响应一致性方面的潜在问题，如偏差和幻觉。AuditLLM 的核心功能是生成易解释的结果，帮助用户识别 LLMs 的知识缺口或功能缺陷，并提供 Live mode（实时查询审计）和 Batch mode（批量处理分析）两种模式，以简化审计流程。该工具降低了技术门槛，适用于研究者和一般用户，促进了对 LLMs 可靠性和性能的标准化评估。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09334v2",
      "published_date": "2024-02-14 17:31:04 UTC",
      "updated_date": "2024-06-17 18:24:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:12:24.234844"
    },
    {
      "arxiv_id": "2402.09320v1",
      "title": "ICDPO: Effectively Borrowing Alignment Capability of Others via In-context Direct Preference Optimization",
      "title_zh": "ICDPO：通过上下文直接偏好优化有效地借用他人的对齐能力",
      "authors": [
        "Feifan Song",
        "Yuxuan Fan",
        "Xin Zhang",
        "Peiyi Wang",
        "Houfeng Wang"
      ],
      "abstract": "Large Language Models (LLMs) rely on Human Preference Alignment (HPA) to\nensure the generation of safe content. Due to the heavy cost associated with\nfine-tuning, fine-tuning-free methods have emerged, typically modifying LLM\ndecoding with external auxiliary methods. However, these methods do not\nessentially enhance the LLM itself. In this paper, we rethink the derivation\nprocedures of DPO, based on which we conversely build an instant scorer using\nthe states of the LLM before and after In-context Learning (ICL). Accordingly,\nwe propose a novel approach called In-Context Direct Preference Optimization\n(ICDPO). It enables LLMs to borrow the HPA capabilities from superior LLMs with\nICL, generating well-aligned responses as estimated by the aforementioned\ninstant scorer, thereby enhancing the final performance. ICDPO can be further\nenhanced with a two-stage retriever and an upgraded scorer, both offering\nbenefits. Extensive experiments show its effectiveness, particularly in\noutperforming two fine-tuning-free baselines, and it exhibits competitiveness\nwith SFT + LoRA. We also conduct detailed analyses to offer comprehensive\ninsights into ICDPO.",
      "tldr_zh": "本研究针对大语言模型（LLMs）的人类偏好对齐（HPA）问题，提出了一种免微调方法In-Context Direct Preference Optimization (ICDPO)，通过In-context Learning (ICL)借用其他优秀LLMs的HPA能力，从而生成更优的对齐响应。ICDPO基于DPO的推导过程构建即时评分器，利用ICL前后LLM的状态进行评估，并可通过两阶段检索器和升级评分器进一步增强。实验结果显示，ICDPO在性能上优于两个免微调基线，并与SFT + LoRA方法具有竞争力，同时通过详细分析提供了全面洞见。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09320v1",
      "published_date": "2024-02-14 17:14:34 UTC",
      "updated_date": "2024-02-14 17:14:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:12:36.962914"
    },
    {
      "arxiv_id": "2402.09318v1",
      "title": "Leveraging Pre-Trained Autoencoders for Interpretable Prototype Learning of Music Audio",
      "title_zh": "利用预训练自编码器实现音乐音频的可",
      "authors": [
        "Pablo Alonso-Jiménez",
        "Leonardo Pepino",
        "Roser Batlle-Roca",
        "Pablo Zinemanas",
        "Dmitry Bogdanov",
        "Xavier Serra",
        "Martín Rocamora"
      ],
      "abstract": "We present PECMAE, an interpretable model for music audio classification\nbased on prototype learning. Our model is based on a previous method, APNet,\nwhich jointly learns an autoencoder and a prototypical network. Instead, we\npropose to decouple both training processes. This enables us to leverage\nexisting self-supervised autoencoders pre-trained on much larger data\n(EnCodecMAE), providing representations with better generalization. APNet\nallows prototypes' reconstruction to waveforms for interpretability relying on\nthe nearest training data samples. In contrast, we explore using a diffusion\ndecoder that allows reconstruction without such dependency. We evaluate our\nmethod on datasets for music instrument classification (Medley-Solos-DB) and\ngenre recognition (GTZAN and a larger in-house dataset), the latter being a\nmore challenging task not addressed with prototypical networks before. We find\nthat the prototype-based models preserve most of the performance achieved with\nthe autoencoder embeddings, while the sonification of prototypes benefits\nunderstanding the behavior of the classifier.",
      "tldr_zh": "本研究提出 PECMAE 模型，一种基于原型学习的音乐音频分类方法，通过解耦自编码器和原型网络的训练，利用预训练的自监督自编码器（如 EnCodecMAE）来获得更好的泛化表示。不同于之前的 APNet 方法，PECMAE 采用 diffusion decoder 进行原型重建，从而无需依赖最近的训练样本，提升了模型的可解释性。在音乐仪器分类（Medley-Solos-DB）和流派识别（GTZAN 等数据集）上的实验显示，该模型保留了自编码器嵌入的大部分性能，同时通过原型的声学重建，有助于更好地理解分类器的行为。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.MM",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09318v1",
      "published_date": "2024-02-14 17:13:36 UTC",
      "updated_date": "2024-02-14 17:13:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:12:49.695872"
    },
    {
      "arxiv_id": "2402.09305v1",
      "title": "Embracing the black box: Heading towards foundation models for causal discovery from time series data",
      "title_zh": "翻译失败",
      "authors": [
        "Gideon Stein",
        "Maha Shadaydeh",
        "Joachim Denzler"
      ],
      "abstract": "Causal discovery from time series data encompasses many existing solutions,\nincluding those based on deep learning techniques. However, these methods\ntypically do not endorse one of the most prevalent paradigms in deep learning:\nEnd-to-end learning. To address this gap, we explore what we call Causal\nPretraining. A methodology that aims to learn a direct mapping from\nmultivariate time series to the underlying causal graphs in a supervised\nmanner. Our empirical findings suggest that causal discovery in a supervised\nmanner is possible, assuming that the training and test time series samples\nshare most of their dynamics. More importantly, we found evidence that the\nperformance of Causal Pretraining can increase with data and model size, even\nif the additional data do not share the same dynamics. Further, we provide\nexamples where causal discovery for real-world data with causally pretrained\nneural networks is possible within limits. We argue that this hints at the\npossibility of a foundation model for causal discovery.",
      "tldr_zh": "该论文探讨了从时间序列数据(time series data)中进行因果发现(causal discovery)的深度学习方法，提出了一种名为Causal Pretraining的端到端(end-to-end)学习方法，通过监督方式直接从多变量时间序列映射到底层因果图(causal graphs)。实验结果表明，这种方法在训练和测试数据共享大部分动态时可行，且其性能随数据和模型规模增加而提升，即使新数据不共享相同动态。作者提供了在真实世界数据上的应用示例，并论证了开发因果发现基础模型(foundation model)的可能性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "68T07"
      ],
      "primary_category": "cs.LG",
      "comment": "AAAI Workshop (AI4TS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09305v1",
      "published_date": "2024-02-14 16:49:13 UTC",
      "updated_date": "2024-02-14 16:49:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:13:00.024526"
    },
    {
      "arxiv_id": "2402.09303v3",
      "title": "Comparing supervised learning dynamics: Deep neural networks match human data efficiency but show a generalisation lag",
      "title_zh": "翻译失败",
      "authors": [
        "Lukas S. Huber",
        "Fred W. Mast",
        "Felix A. Wichmann"
      ],
      "abstract": "Recent research has seen many behavioral comparisons between humans and deep\nneural networks (DNNs) in the domain of image classification. Often, comparison\nstudies focus on the end-result of the learning process by measuring and\ncomparing the similarities in the representations of object categories once\nthey have been formed. However, the process of how these representations emerge\n-- that is, the behavioral changes and intermediate stages observed during the\nacquisition -- is less often directly and empirically compared. Here we report\na detailed investigation of the learning dynamics in human observers and\nvarious classic and state-of-the-art DNNs. We develop a constrained supervised\nlearning environment to align learning-relevant conditions such as starting\npoint, input modality, available input data and the feedback provided. Across\nthe whole learning process we evaluate and compare how well learned\nrepresentations can be generalized to previously unseen test data. Comparisons\nacross the entire learning process indicate that DNNs demonstrate a level of\ndata efficiency comparable to human learners, challenging some prevailing\nassumptions in the field. However, our results also reveal representational\ndifferences: while DNNs' learning is characterized by a pronounced\ngeneralisation lag, humans appear to immediately acquire generalizable\nrepresentations without a preliminary phase of learning training set-specific\ninformation that is only later transferred to novel data.",
      "tldr_zh": "本文比较了人类和深度神经网络（DNNs）在图像分类任务中的监督学习动态，重点考察学习过程的中间阶段而非最终结果。研究者设计了一个受限的学习环境，使人类和DNNs在起始点、输入模式、数据和反馈等方面保持一致，以评估整个学习过程中的泛化能力。结果表明，DNNs的数据效率与人类相当，但存在明显的泛化滞后（generalisation lag），即先学习训练集特定信息后才转移到新数据，而人类则能立即形成可泛化的表示。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "q-bio.NC"
      ],
      "primary_category": "cs.CV",
      "comment": "Final version accepted @ ICLR 2024 Workshop on Representational\n  Alignment (Re-Align)",
      "pdf_url": "http://arxiv.org/pdf/2402.09303v3",
      "published_date": "2024-02-14 16:47:20 UTC",
      "updated_date": "2024-07-12 12:47:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:13:13.086103"
    },
    {
      "arxiv_id": "2402.09498v1",
      "title": "Detection of the most influential variables for preventing postpartum urinary incontinence using machine learning techniques",
      "title_zh": "翻译失败",
      "authors": [
        "José Alberto Benítez-Andrades",
        "María Teresa García-Ordás",
        "María Álvarez-González",
        "Raquel Leirós-Rodríguez",
        "Ana F López Rodríguez"
      ],
      "abstract": "Background: Postpartum urinary incontinence (PUI) is a common issue among\npostnatal women. Previous studies identified potential related variables, but\nlacked analysis on certain intrinsic and extrinsic patient variables during\npregnancy.\n  Objective: The study aims to evaluate the most influential variables in PUI\nusing machine learning, focusing on intrinsic, extrinsic, and combined variable\ngroups.\n  Methods: Data from 93 pregnant women were analyzed using machine learning and\noversampling techniques. Four key variables were predicted: occurrence,\nfrequency, intensity of urinary incontinence, and stress urinary incontinence.\n  Results: Models using extrinsic variables were most accurate, with 70%\naccuracy for urinary incontinence, 77% for frequency, 71% for intensity, and\n93% for stress urinary incontinence.\n  Conclusions: The study highlights extrinsic variables as significant\npredictors of PUI issues. This suggests that PUI prevention might be achievable\nthrough healthy habits during pregnancy, although further research is needed\nfor confirmation.",
      "tldr_zh": "这篇论文使用 machine learning 技术分析 93 名孕妇的数据，旨在识别影响产后 urinary incontinence (PUI) 的最重要变量，包括内在、extrinsic 和组合变量组。研究采用 machine learning 和 oversampling 技术来预测四个关键指标：尿失禁的发生、频率、强度以及 stress urinary incontinence。结果显示，基于 extrinsic variables 的模型准确率最高，分别为尿失禁 70%、频率 77%、强度 71% 和压力性尿失禁 93%。论文结论强调 extrinsic variables 是 PUI 的关键预测因素，并建议通过孕期健康习惯进行预防，但需要更多研究来验证。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09498v1",
      "published_date": "2024-02-14 16:45:10 UTC",
      "updated_date": "2024-02-14 16:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:13:26.849727"
    },
    {
      "arxiv_id": "2403.12073v1",
      "title": "Feasibility of Social-Network-Based eHealth Intervention on the Improvement of Healthy Habits among Children",
      "title_zh": "基于社交网络的电子健康干预在改善儿童健康习惯的可行性",
      "authors": [
        "José Alberto Benítez-Andrades",
        "Natalia Arias",
        "María Teresa García-Ordás",
        "Marta Martínez-Martínez",
        "Isaías García-Rodríguez"
      ],
      "abstract": "This study shows the feasibility of an eHealth solution for tackling eating\nhabits and physical activity in the adolescent population. The participants\nwere children from 11 to 15 years old. An intervention was carried out on 139\nstudents in the intervention group and 91 students in the control group, in two\nschools during 14 weeks. The intervention group had access to the web through a\nuser account and a password. They were able to create friendship relationships,\npost comments, give likes and interact with other users, as well as receive\nnotifications and information about nutrition and physical activity on a daily\nbasis and get (virtual) rewards for improving their habits. The control group\ndid not have access to any of these features. The homogeneity of the samples in\nterms of gender, age, body mass index and initial health-related habits was\ndemonstrated. Pre- and post-measurements were collected through self-reports on\nthe application website. After applying multivariate analysis of variance, a\nsignificant alteration in the age-adjusted body mass index percentile was\nobserved in the intervention group versus the control group, as well as in the\nPAQ-A score and the KIDMED score. It can be concluded that eHealth\ninterventions can help to obtain healthy habits. More research is needed to\nexamine the effectiveness in achieving adherence to these new habits.",
      "tldr_zh": "本研究评估了基于社交网络的 eHealth 干预方案在改善 11-15 岁儿童饮食习惯和身体活动方面的可行性。研究对 139 名干预组学生和 91 名对照组学生进行了 14 周试验，干预组通过网页平台建立社交互动、接收营养和身体活动通知，并获得虚拟奖励，而对照组无此访问。结果显示，干预组在年龄调整体重指数百分位、PAQ-A 得分和 KIDMED 得分方面有显著改善。总体而言，eHealth 干预有助于培养健康习惯，但需进一步研究以验证其长期效果。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.12073v1",
      "published_date": "2024-02-14 16:23:48 UTC",
      "updated_date": "2024-02-14 16:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:13:36.935206"
    },
    {
      "arxiv_id": "2402.09290v1",
      "title": "Learning Interpretable Policies in Hindsight-Observable POMDPs through Partially Supervised Reinforcement Learning",
      "title_zh": "通过部分监督强化学习在事后可观察的 POMDPs 中学习",
      "authors": [
        "Michael Lanier",
        "Ying Xu",
        "Nathan Jacobs",
        "Chongjie Zhang",
        "Yevgeniy Vorobeychik"
      ],
      "abstract": "Deep reinforcement learning has demonstrated remarkable achievements across\ndiverse domains such as video games, robotic control, autonomous driving, and\ndrug discovery. Common methodologies in partially-observable domains largely\nlean on end-to-end learning from high-dimensional observations, such as images,\nwithout explicitly reasoning about true state. We suggest an alternative\ndirection, introducing the Partially Supervised Reinforcement Learning (PSRL)\nframework. At the heart of PSRL is the fusion of both supervised and\nunsupervised learning. The approach leverages a state estimator to distill\nsupervised semantic state information from high-dimensional observations which\nare often fully observable at training time. This yields more interpretable\npolicies that compose state predictions with control. In parallel, it captures\nan unsupervised latent representation. These two-the semantic state and the\nlatent state-are then fused and utilized as inputs to a policy network. This\njuxtaposition offers practitioners a flexible and dynamic spectrum: from\nemphasizing supervised state information to integrating richer, latent\ninsights. Extensive experimental results indicate that by merging these dual\nrepresentations, PSRL offers a potent balance, enhancing model interpretability\nwhile preserving, and often significantly outperforming, the performance\nbenchmarks set by traditional methods in terms of reward and convergence speed.",
      "tldr_zh": "该论文提出了一种部分监督强化学习（Partially Supervised Reinforcement Learning, PSRL）框架，用于在后视可观测部分可观测马尔可夫决策过程（Hindsight-Observable POMDPs）中学习可解释策略，以解决传统端到端学习忽略真实状态的问题。PSRL 通过状态估计器从高维观察（如图像）中提取监督的语义状态信息，同时捕获无监督的潜在表示，并将两者融合作为策略网络的输入，提供从强调监督信息到整合潜在洞见的灵活选项。实验结果显示，该方法显著提升了模型的可解释性，同时在奖励和收敛速度上优于传统强化学习方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09290v1",
      "published_date": "2024-02-14 16:23:23 UTC",
      "updated_date": "2024-02-14 16:23:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:13:50.582913"
    },
    {
      "arxiv_id": "2402.09286v1",
      "title": "Nutrition Facts, Drug Facts, and Model Facts: Putting AI Ethics into Practice in Gun Violence Research",
      "title_zh": "营养事实、药物事实和模型事实：将AI伦理应用于枪",
      "authors": [
        "Jessica Zhu",
        "Michel Cukier",
        "Joseph Richardson Jr"
      ],
      "abstract": "Objective: Firearm injury research necessitates using data from\noften-exploited vulnerable populations of Black and Brown Americans. In order\nto minimize distrust, this study provides a framework for establishing AI trust\nand transparency with the general population. Methods: We propose a Model Facts\ntemplate that is easily extendable and decomposes accuracy and demographics\ninto standardized and minimally complex values. This framework allows general\nusers to assess the validity and biases of a model without diving into\ntechnical model documentation. Examples: We apply the Model Facts template on\ntwo previously published models, a violence risk identification model and a\nsuicide risk prediction model. We demonstrate the ease of accessing the\nappropriate information when the data is structured appropriately. Discussion:\nThe Model Facts template is limited in its current form to human based data and\nbiases. Like nutrition facts, it also will require some educational resources\nfor users to grasp its full utility. Human computer interaction experiments\nshould be conducted to ensure that the interaction between user interface and\nmodel interface is as desired. Conclusion: The Model Facts label is the first\nframework dedicated to establishing trust with end users and general population\nconsumers. Implementation of Model Facts into firearm injury research will\nprovide public health practitioners and those impacted by firearm injury\ngreater faith in the tools the research provides.",
      "tldr_zh": "该研究针对枪支暴力研究中AI伦理的实践，提出Model Facts框架，以提升对AI模型的信任和透明度，特别是针对易受剥削的Black和Brown美国人群体。该框架通过一个易扩展的模板，将模型的准确性和人口统计数据分解为标准化、简单值，允许普通用户无需查阅技术文档即可评估模型的效度和偏差。作者将Model Facts应用于两个已发表模型（暴力风险识别模型和自杀风险预测模型），展示了其易用性；尽管目前限于人类数据和偏差，并需教育资源和人机交互实验，但该框架有望在公共卫生领域增强对AI工具的信心。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09286v1",
      "published_date": "2024-02-14 16:19:09 UTC",
      "updated_date": "2024-02-14 16:19:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:14:01.089721"
    },
    {
      "arxiv_id": "2402.12390v1",
      "title": "A Semantic Social Network Analysis Tool for Sensitivity Analysis and What-If Scenario Testing in Alcohol Consumption Studies",
      "title_zh": "翻译失败",
      "authors": [
        "José Alberto Benítez-Andrades",
        "Alejandro Rodríguez-González",
        "Carmen Benavides",
        "Leticia Sánchez-Valdeón",
        "Isaías García"
      ],
      "abstract": "Social Network Analysis (SNA) is a set of techniques developed in the field\nof social and behavioral sciences research, in order to characterize and study\nthe social relationships that are established among a set of individuals. When\nbuilding a social network for performing an SNA analysis, an initial process of\ndata gathering is achieved in order to extract the characteristics of the\nindividuals and their relationships. This is usually done by completing a\nquestionnaire containing different types of questions that will be later used\nto obtain the SNA measures needed to perform the study. There are, then, a\ngreat number of different possible network generating questions and also many\npossibilities for mapping the responses to the corresponding characteristics\nand relationships. Many variations may be introduced into these questions (the\nway they are posed, the weights given to each of the responses, etc.) that may\nhave an effect on the resulting networks. All these different variations are\ndifficult to achieve manually, because the process is time-consuming and error\nprone. The tool described in this paper uses semantic knowledge representation\ntechniques in order to facilitate this kind of sensitivity studies. The base of\nthe tool is a conceptual structure, called \"ontology\" that is able to represent\nthe different concepts and their definitions. The tool is compared to other\nsimilar ones, and the advantages of the approach are highlighted, giving some\nparticular examples from an ongoing SNA study about alcohol consumption habits\nin adolescents.",
      "tldr_zh": "本论文提出了一种语义社交网络分析（SNA）工具，用于在酒精消费研究中进行敏感性分析和假设场景测试（what-if scenario testing），以处理问卷数据变体（如问题形式和权重设置）对网络结构的影响。工具基于本体（ontology）等语义知识表示技术，自动化提取个体特征和关系，简化了传统手动数据收集过程的复杂性和错误风险。通过与类似工具的比较，该方法在青少年饮酒习惯的SNA研究中展示了显著优势，提高了分析效率和准确性。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.12390v1",
      "published_date": "2024-02-14 16:17:04 UTC",
      "updated_date": "2024-02-14 16:17:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:14:12.576027"
    },
    {
      "arxiv_id": "2402.09283v3",
      "title": "Attacks, Defenses and Evaluations for LLM Conversation Safety: A Survey",
      "title_zh": "针对 LLM 对话安全的攻击、防御和评估：一项调查",
      "authors": [
        "Zhichen Dong",
        "Zhanhui Zhou",
        "Chao Yang",
        "Jing Shao",
        "Yu Qiao"
      ],
      "abstract": "Large Language Models (LLMs) are now commonplace in conversation\napplications. However, their risks of misuse for generating harmful responses\nhave raised serious societal concerns and spurred recent research on LLM\nconversation safety. Therefore, in this survey, we provide a comprehensive\noverview of recent studies, covering three critical aspects of LLM conversation\nsafety: attacks, defenses, and evaluations. Our goal is to provide a structured\nsummary that enhances understanding of LLM conversation safety and encourages\nfurther investigation into this important subject. For easy reference, we have\ncategorized all the studies mentioned in this survey according to our taxonomy,\navailable at: https://github.com/niconi19/LLM-conversation-safety.",
      "tldr_zh": "这篇调查论文系统概述了大型语言模型（LLMs）在对话应用中的安全问题，包括攻击、防御和评估三个关键方面。论文总结了LLMs生成有害响应的潜在风险，并对现有研究进行结构化分类，以提升对对话安全的理解。最终，该工作提供了一个易于参考的taxonomy（可访问GitHub），旨在鼓励更多针对LLM conversation safety的深入研究。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09283v3",
      "published_date": "2024-02-14 16:14:03 UTC",
      "updated_date": "2024-03-27 13:55:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:14:24.533716"
    },
    {
      "arxiv_id": "2402.09281v3",
      "title": "Synergistic eigenanalysis of covariance and Hessian matrices for enhanced binary classification",
      "title_zh": "协同特征分析协方差和Hessian矩阵以增强二元分类",
      "authors": [
        "Agus Hartoyo",
        "Jan Argasiński",
        "Aleksandra Trenk",
        "Kinga Przybylska",
        "Anna Błasiak",
        "Alessandro Crimi"
      ],
      "abstract": "Covariance and Hessian matrices have been analyzed separately in the\nliterature for classification problems. However, integrating these matrices has\nthe potential to enhance their combined power in improving classification\nperformance. We present a novel approach that combines the eigenanalysis of a\ncovariance matrix evaluated on a training set with a Hessian matrix evaluated\non a deep learning model to achieve optimal class separability in binary\nclassification tasks. Our approach is substantiated by formal proofs that\nestablish its capability to maximize between-class mean distance (the concept\nof \\textit{separation}) and minimize within-class variances (the concept of\n\\textit{compactness}), which together define the two linear discriminant\nanalysis (LDA) criteria, particularly under ideal data conditions such as\nisotropy around class means and dominant leading eigenvalues. By projecting\ndata into the combined space of the most relevant eigendirections from both\nmatrices, we achieve optimal class separability as per these LDA criteria.\nEmpirical validation across neural and health datasets consistently supports\nour theoretical framework and demonstrates that our method outperforms\nestablished methods. Our method stands out by addressing both separation and\ncompactness criteria, unlike PCA and the Hessian method, which predominantly\nemphasize one criterion each. This comprehensive approach captures intricate\npatterns and relationships, enhancing classification performance. Furthermore,\nthrough the utilization of both LDA criteria, our method outperforms LDA itself\nby leveraging higher-dimensional feature spaces, in accordance with Cover's\ntheorem, which favors linear separability in higher dimensions. Additionally,\nour approach sheds light on complex DNN decision-making, rendering them\ncomprehensible within a 2D space.",
      "tldr_zh": "本研究提出了一种协同特征分析方法，将协方差矩阵和Hessian矩阵的特征分析相结合，以提升二元分类任务的性能。该方法通过在训练集上计算协方差矩阵并结合深度学习模型的Hessian矩阵，最大化类间距离（separation）和最小化类内方差（compactness），从而满足线性判别分析（LDA）的标准，并在理想数据条件下实现最佳类可分性。实验验证在神经和健康数据集上显示，该方法优于PCA（主要强调紧凑性）和Hessian方法（主要强调分离），整体分类性能得到提升，并通过利用更高维特征空间（符合Cover's theorem），超越传统LDA。此外，该方法还增强了对复杂深度神经网络（DNN）决策过程的可解释性，将其可视化于2D空间。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "31 pages, 13 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.09281v3",
      "published_date": "2024-02-14 16:10:42 UTC",
      "updated_date": "2024-10-08 16:19:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:14:38.786911"
    },
    {
      "arxiv_id": "2402.10967v1",
      "title": "Social network analysis for personalized characterization and risk assessment of alcohol use disorders in adolescents using semantic technologies",
      "title_zh": "翻译失败",
      "authors": [
        "José Alberto Benítez-Andrades",
        "Isaías García-Rodríguez",
        "Carmen Benavides",
        "Héctor Alaiz-Moretón",
        "Alejandro Rodríguez-González"
      ],
      "abstract": "Alcohol Use Disorder (AUD) is a major concern for public health organizations\nworldwide, especially as regards the adolescent population. The consumption of\nalcohol in adolescents is known to be influenced by seeing friends and even\nparents drinking alcohol. Building on this fact, a number of studies into\nalcohol consumption among adolescents have made use of Social Network Analysis\n(SNA) techniques to study the different social networks (peers, friends,\nfamily, etc.) with whom the adolescent is involved. These kinds of studies need\nan initial phase of data gathering by means of questionnaires and a subsequent\nanalysis phase using the SNA techniques. The process involves a number of\nmanual data handling stages that are time consuming and error-prone. The use of\nknowledge engineering techniques (including the construction of a domain\nontology) to represent the information, allows the automation of all the\nactivities, from the initial data collection to the results of the SNA study.\nThis paper shows how a knowledge model is constructed, and compares the results\nobtained using the traditional method with this, fully automated model,\ndetailing the main advantages of the latter. In the case of the SNA analysis,\nthe validity of the results obtained with the knowledge engineering approach\nare compared to those obtained manually using the UCINET, Cytoscape, Pajek and\nGephi to test the accuracy of the knowledge model.",
      "tldr_zh": "该研究利用社会网络分析(Social Network Analysis, SNA)结合语义技术，针对青少年的酒精使用障碍(Alcohol Use Disorder, AUD)进行个性化特征描述和风险评估，强调社会网络（如朋友和家人）对青少年的影响。传统方法依赖手动问卷数据收集和分析工具（如UCINET、Cytoscape、Pajek和Gephi），但过程耗时且易出错。论文提出构建领域本体(ontology)的知识工程模型，实现从数据收集到SNA分析的全自动化。结果显示，该自动化方法与传统方法相比，不仅准确性相当，还显著提高了效率和可靠性，为未来AUD风险评估提供了更高效的框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10967v1",
      "published_date": "2024-02-14 16:09:05 UTC",
      "updated_date": "2024-02-14 16:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:14:49.273015"
    },
    {
      "arxiv_id": "2402.09269v2",
      "title": "Personalized Large Language Models",
      "title_zh": "个性化的大型语言模型",
      "authors": [
        "Stanisław Woźniak",
        "Bartłomiej Koptyra",
        "Arkadiusz Janz",
        "Przemysław Kazienko",
        "Jan Kocoń"
      ],
      "abstract": "Large language models (LLMs) have significantly advanced Natural Language\nProcessing (NLP) tasks in recent years. However, their universal nature poses\nlimitations in scenarios requiring personalized responses, such as\nrecommendation systems and chatbots. This paper investigates methods to\npersonalize LLMs, comparing fine-tuning and zero-shot reasoning approaches on\nsubjective tasks. Results demonstrate that personalized fine-tuning improves\nmodel reasoning compared to non-personalized models. Experiments on datasets\nfor emotion recognition and hate speech detection show consistent performance\ngains with personalized methods across different LLM architectures. These\nfindings underscore the importance of personalization for enhancing LLM\ncapabilities in subjective text perception tasks.",
      "tldr_zh": "本论文探讨了大型语言模型 (LLMs) 在自然语言处理 (NLP) 任务中的进展，但强调其通用性限制了在个性化场景（如推荐系统和聊天机器人）中的表现。研究者比较了 fine-tuning 和 zero-shot reasoning 等方法，在主观任务上进行评估，结果显示个性化 fine-tuning 显著提升了模型的推理能力。实验在情感识别和仇恨言论检测数据集上证明，个性化方法在不同 LLM 架构中均实现了性能提升，这些发现突出了个性化在主观文本感知任务中的关键作用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to SENTIRE 2024 (ICDM Workshops):\n  https://sentic.net/sentire2024wozniak.pdf",
      "pdf_url": "http://arxiv.org/pdf/2402.09269v2",
      "published_date": "2024-02-14 15:55:30 UTC",
      "updated_date": "2024-11-07 16:43:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:15:01.121872"
    },
    {
      "arxiv_id": "2402.09267v2",
      "title": "Self-Alignment for Factuality: Mitigating Hallucinations in LLMs via Self-Evaluation",
      "title_zh": "针对事实性的自我对齐：通过自我评估缓解 LLMs 中的幻觉",
      "authors": [
        "Xiaoying Zhang",
        "Baolin Peng",
        "Ye Tian",
        "Jingyan Zhou",
        "Lifeng Jin",
        "Linfeng Song",
        "Haitao Mi",
        "Helen Meng"
      ],
      "abstract": "Despite showing increasingly human-like abilities, large language models\n(LLMs) often struggle with factual inaccuracies, i.e. \"hallucinations\", even\nwhen they hold relevant knowledge. To address these hallucinations, current\napproaches typically necessitate high-quality human factuality annotations. In\nthis work, we explore Self-Alignment for Factuality, where we leverage the\nself-evaluation capability of an LLM to provide training signals that steer the\nmodel towards factuality. Specifically, we incorporate Self-Eval, a\nself-evaluation component, to prompt an LLM to validate the factuality of its\nown generated responses solely based on its internal knowledge. Additionally,\nwe design Self-Knowledge Tuning (SK-Tuning) to augment the LLM's\nself-evaluation ability by improving the model's confidence estimation and\ncalibration. We then utilize these self-annotated responses to fine-tune the\nmodel via Direct Preference Optimization algorithm. We show that the proposed\nself-alignment approach substantially enhances factual accuracy over Llama\nfamily models across three key knowledge-intensive tasks on TruthfulQA and\nBioGEN.",
      "tldr_zh": "本文提出Self-Alignment for Factuality方法，利用LLMs的自评估能力来减少幻觉问题，避免依赖高质量的人工标注。核心组件包括Self-Eval，让模型基于内部知识验证自身生成的响应准确性，以及Self-Knowledge Tuning (SK-Tuning)来提升模型的置信度和校准。随后，通过Direct Preference Optimization算法利用这些自标注数据微调模型。实验结果显示，该方法在TruthfulQA和BioGEN等知识密集型任务上显著提高了Llama家族模型的事实准确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "20 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.09267v2",
      "published_date": "2024-02-14 15:52:42 UTC",
      "updated_date": "2024-06-11 12:22:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:15:13.173235"
    },
    {
      "arxiv_id": "2402.09266v1",
      "title": "Machine Learning in management of precautionary closures caused by lipophilic biotoxins",
      "title_zh": "翻译失败",
      "authors": [
        "Andres Molares-Ulloa",
        "Enrique Fernandez-Blanco",
        "Alejandro Pazos",
        "Daniel Rivero"
      ],
      "abstract": "Mussel farming is one of the most important aquaculture industries. The main\nrisk to mussel farming is harmful algal blooms (HABs), which pose a risk to\nhuman consumption. In Galicia, the Spanish main producer of cultivated mussels,\nthe opening and closing of the production areas is controlled by a monitoring\nprogram. In addition to the closures resulting from the presence of toxicity\nexceeding the legal threshold, in the absence of a confirmatory sampling and\nthe existence of risk factors, precautionary closures may be applied. These\ndecisions are made by experts without the support or formalisation of the\nexperience on which they are based. Therefore, this work proposes a predictive\nmodel capable of supporting the application of precautionary closures.\nAchieving sensitivity, accuracy and kappa index values of 97.34%, 91.83% and\n0.75 respectively, the kNN algorithm has provided the best results. This allows\nthe creation of a system capable of helping in complex situations where\nforecast errors are more common.",
      "tldr_zh": "本研究探讨了机器学习在管理脂溶性生物毒素引起的预防性关闭中的应用，针对贻贝养殖业面临的有害藻华(HABs)风险。研究提出一个预测模型，使用kNN algorithm来辅助决策，支持Galicia地区监测程序中的预防性关闭决策。模型在实验中取得了97.34%的sensitivity、91.83%的accuracy和0.75的kappa index，显著提高了在复杂情况下的预测准确性。该方法有助于正式化专家经验，创建可靠的系统减少预测错误。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09266v1",
      "published_date": "2024-02-14 15:51:58 UTC",
      "updated_date": "2024-02-14 15:51:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:15:23.878794"
    },
    {
      "arxiv_id": "2402.09265v2",
      "title": "Computational Complexity of Preferred Subset Repairs on Data-Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Nina Pardal",
        "Santiago Cifuentes",
        "Edwin Pin",
        "Maria Vanina Martinez",
        "Sergio Abriola"
      ],
      "abstract": "Preferences are a pivotal component in practical reasoning, especially in\ntasks that involve decision-making over different options or courses of action\nthat could be pursued. In this work, we focus on repairing and querying\ninconsistent knowledge bases in the form of graph databases, which involves\nfinding a way to solve conflicts in the knowledge base and considering answers\nthat are entailed from every possible repair, respectively. Without a priori\ndomain knowledge, all possible repairs are equally preferred. Though that may\nbe adequate for some settings, it seems reasonable to establish and exploit\nsome form of preference order among the potential repairs. We study the problem\nof computing prioritized repairs over graph databases with data values, using a\nnotion of consistency based on GXPath expressions as integrity constraints. We\npresent several preference criteria based on the standard subset repair\nsemantics, incorporating weights, multisets, and set-based priority levels. We\nshow that it is possible to maintain the same computational complexity as in\nthe case where no preference criterion is available for exploitation. Finally,\nwe explore the complexity of consistent query answering in this setting and\nobtain tight lower and upper bounds for all the preference criteria introduced.",
      "tldr_zh": "本论文探讨了在数据图（Data-Graphs）上计算偏好子集修复（Preferred Subset Repairs）的计算复杂度，旨在通过引入偏好标准来处理图数据库中不一致知识基的修复和查询问题。论文基于subset repair semantics，提出了几种偏好标准，包括weights、multisets和set-based priority levels，并使用GXPath表达式作为完整性约束。研究发现，这些偏好标准不会增加计算复杂度，与无偏好设置保持相同复杂度；此外，论文分析了consistent query answering的复杂度，并给出了紧致的下限和上限界限。总的来说，这为优先化知识基修复提供了高效的理论基础。",
      "categories": [
        "cs.DB",
        "cs.AI",
        "cs.LO",
        "68P15, 68T27, 03B70, 68T37"
      ],
      "primary_category": "cs.DB",
      "comment": "Appendix",
      "pdf_url": "http://arxiv.org/pdf/2402.09265v2",
      "published_date": "2024-02-14 15:51:55 UTC",
      "updated_date": "2024-05-27 15:24:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:15:37.633252"
    },
    {
      "arxiv_id": "2402.09497v2",
      "title": "Instruction Tuning for Secure Code Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Jingxuan He",
        "Mark Vero",
        "Gabriela Krasnopolska",
        "Martin Vechev"
      ],
      "abstract": "Modern language models (LMs) have gained widespread acceptance in everyday\nand professional contexts, particularly in programming. An essential procedure\nenabling this adoption is instruction tuning, which substantially enhances LMs'\npractical utility by training them to follow user instructions and human\npreferences. However, existing instruction tuning schemes overlook a crucial\naspect: the security of generated code. As a result, even the state-of-the-art\ninstruction-tuned LMs frequently produce unsafe code, posing significant\nsecurity risks. In this work, we introduce SafeCoder to address this gap.\nSafeCoder performs security-centric fine-tuning using a diverse and\nhigh-quality dataset that we collected using an automated pipeline. We\nintegrate the security fine-tuning with standard instruction tuning, to\nfacilitate a joint optimization of both security and utility. Despite its\nsimplicity, we show that SafeCoder is effective across a variety of popular LMs\nand datasets. It is able to drastically improve security (by about 30%), while\npreserving utility.",
      "tldr_zh": "现有语言模型（LMs）的指令微调（instruction tuning）虽然提升了模型遵循用户指令和人类偏好的实用性，但往往忽略了生成代码的安全性，导致潜在风险。本文提出SafeCoder框架，通过一个自动管道收集的多样、高质量数据集进行安全导向的微调，并将其与标准指令微调整合，实现安全性和实用性的联合优化。尽管方法简单，SafeCoder在多种流行LMs和数据集上有效，提高了约30%的代码安全性，同时保持了模型的整体性能。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09497v2",
      "published_date": "2024-02-14 15:47:46 UTC",
      "updated_date": "2024-07-12 15:45:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:15:49.662664"
    },
    {
      "arxiv_id": "2402.09259v2",
      "title": "SyntaxShap: Syntax-aware Explainability Method for Text Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kenza Amara",
        "Rita Sevastjanova",
        "Mennatallah El-Assady"
      ],
      "abstract": "To harness the power of large language models in safety-critical domains, we\nneed to ensure the explainability of their predictions. However, despite the\nsignificant attention to model interpretability, there remains an unexplored\ndomain in explaining sequence-to-sequence tasks using methods tailored for\ntextual data. This paper introduces SyntaxShap, a local, model-agnostic\nexplainability method for text generation that takes into consideration the\nsyntax in the text data. The presented work extends Shapley values to account\nfor parsing-based syntactic dependencies. Taking a game theoric approach,\nSyntaxShap only considers coalitions constraint by the dependency tree. We\nadopt a model-based evaluation to compare SyntaxShap and its weighted form to\nstate-of-the-art explainability methods adapted to text generation tasks, using\ndiverse metrics including faithfulness, coherency, and semantic alignment of\nthe explanations to the model. We show that our syntax-aware method produces\nexplanations that help build more faithful and coherent explanations for\npredictions by autoregressive models. Confronted with the misalignment of human\nand AI model reasoning, this paper also highlights the need for cautious\nevaluation strategies in explainable AI.",
      "tldr_zh": "这篇论文提出了 SyntaxShap，一种本地、模型无关的可解释性方法，用于文本生成任务，特别考虑了文本数据的 syntactic dependencies。方法扩展了 Shapley values，通过博弈论仅评估依赖树约束的联盟，确保解释的准确性。研究采用模型-based 评估，将 SyntaxShap 与其加权形式与其他最先进方法比较，使用 faithfulness、coherency 和 semantic alignment 等指标，结果显示它能生成更 faithful 和 coherent 的解释。最后，论文强调了在可解释 AI 中谨慎评估策略的必要性，以应对人类和 AI 推理可能的不一致。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09259v2",
      "published_date": "2024-02-14 15:45:56 UTC",
      "updated_date": "2024-06-03 10:30:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:16:01.481098"
    },
    {
      "arxiv_id": "2402.09251v2",
      "title": "Universal Machine Learning Kohn-Sham Hamiltonian for Materials",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhong",
        "Hongyu Yu",
        "Jihui Yang",
        "Xingyu Guo",
        "Hongjun Xiang",
        "Xingao Gong"
      ],
      "abstract": "While density functional theory (DFT) serves as a prevalent computational\napproach in electronic structure calculations, its computational demands and\nscalability limitations persist. Recently, leveraging neural networks to\nparameterize the Kohn-Sham DFT Hamiltonian has emerged as a promising avenue\nfor accelerating electronic structure computations. Despite advancements,\nchallenges such as the necessity for computing extensive DFT training data to\nexplore each new system and the complexity of establishing accurate ML models\nfor multi-elemental materials still exist. Addressing these hurdles, this study\nintroduces a universal electronic Hamiltonian model trained on Hamiltonian\nmatrices obtained from first-principles DFT calculations of nearly all crystal\nstructures on the Materials Project. We demonstrate its generality in\npredicting electronic structures across the whole periodic table, including\ncomplex multi-elemental systems, solid-state electrolytes, Moir\\'e twisted\nbilayer heterostructure, and metal-organic frameworks (MOFs). Moreover, we\nutilize the universal model to conduct high-throughput calculations of\nelectronic structures for crystals in GeNOME datasets, identifying 3,940\ncrystals with direct band gaps and 5,109 crystals with flat bands. By offering\na reliable efficient framework for computing electronic properties, this\nuniversal Hamiltonian model lays the groundwork for advancements in diverse\nfields, such as easily providing a huge data set of electronic structures and\nalso making the materials design across the whole periodic table possible.",
      "tldr_zh": "本研究提出一个通用机器学习Kohn-Sham Hamiltonian模型，通过训练于Materials Project中几乎所有晶体结构的DFT计算数据，解决了传统电子结构计算的计算需求和扩展性问题。该模型展示了广泛的适用性，能够准确预测整个周期表的电子结构，包括多元素系统、固态电解质、Moiré扭转双层异结构和金属有机框架(MOFs)。此外，利用该模型对GeNOME数据集进行高通量计算，识别出3,940个具有直接带隙的晶体和5,109个具有平坦带的晶体，为材料设计和电子结构大数据生成提供了高效可靠的框架。",
      "categories": [
        "physics.comp-ph",
        "cond-mat.mtrl-sci",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "20 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.09251v2",
      "published_date": "2024-02-14 15:38:56 UTC",
      "updated_date": "2024-04-15 06:20:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:16:15.236869"
    },
    {
      "arxiv_id": "2402.09246v4",
      "title": "Who Plays First? Optimizing the Order of Play in Stackelberg Games with Many Robots",
      "title_zh": "翻译失败",
      "authors": [
        "Haimin Hu",
        "Gabriele Dragotto",
        "Zixu Zhang",
        "Kaiqu Liang",
        "Bartolomeo Stellato",
        "Jaime F. Fisac"
      ],
      "abstract": "We consider the multi-agent spatial navigation problem of computing the\nsocially optimal order of play, i.e., the sequence in which the agents commit\nto their decisions, and its associated equilibrium in an N-player Stackelberg\ntrajectory game. We model this problem as a mixed-integer optimization problem\nover the space of all possible Stackelberg games associated with the order of\nplay's permutations. To solve the problem, we introduce Branch and Play (B&P),\nan efficient and exact algorithm that provably converges to a socially optimal\norder of play and its Stackelberg equilibrium. As a subroutine for B&P, we\nemploy and extend sequential trajectory planning, i.e., a popular multi-agent\ncontrol approach, to scalably compute valid local Stackelberg equilibria for\nany given order of play. We demonstrate the practical utility of B&P to\ncoordinate air traffic control, swarm formation, and delivery vehicle fleets.\nWe find that B&P consistently outperforms various baselines, and computes the\nsocially optimal equilibrium.",
      "tldr_zh": "这篇论文探讨了多智能体空间导航问题，旨在优化代理在N玩家Stackelberg轨迹游戏中的行动顺序，以实现社会最优均衡。作者将问题建模为与行动顺序排列相关的混合整数优化问题，并引入Branch and Play (B&P)算法，该算法通过扩展顺序轨迹规划作为子程序，来高效且精确地计算局部Stackelberg均衡。实验结果显示，B&P在协调空中交通控制、群集形成和交付车辆车队等方面显著优于基线方法，并成功计算出社会最优均衡。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "Robotics: Science and Systems (RSS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09246v4",
      "published_date": "2024-02-14 15:34:38 UTC",
      "updated_date": "2024-06-25 02:55:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:16:25.907269"
    },
    {
      "arxiv_id": "2402.09236v2",
      "title": "Learning Interpretable Concepts: Unifying Causal Representation Learning and Foundation Models",
      "title_zh": "翻译失败",
      "authors": [
        "Goutham Rajendran",
        "Simon Buchholz",
        "Bryon Aragam",
        "Bernhard Schölkopf",
        "Pradeep Ravikumar"
      ],
      "abstract": "To build intelligent machine learning systems, there are two broad\napproaches. One approach is to build inherently interpretable models, as\nendeavored by the growing field of causal representation learning. The other\napproach is to build highly-performant foundation models and then invest\nefforts into understanding how they work. In this work, we relate these two\napproaches and study how to learn human-interpretable concepts from data.\nWeaving together ideas from both fields, we formally define a notion of\nconcepts and show that they can be provably recovered from diverse data.\nExperiments on synthetic data and large language models show the utility of our\nunified approach.",
      "tldr_zh": "该论文探讨了构建智能机器学习系统的两种方法：一种是通过因果表示学习（Causal Representation Learning）构建固有可解释模型，另一种是开发高性能基础模型（Foundation Models）并分析其工作原理。作者将这些方法统一起来，正式定义了可解释概念（Interpretable Concepts），并证明这些概念可以从多样数据中可靠地恢复。实验在合成数据和大型语言模型上展示了这一统一方法的实用性和有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.ST",
        "stat.ML",
        "stat.TH"
      ],
      "primary_category": "cs.LG",
      "comment": "To appear in NeurIPS 2024 under the modified title 'From Causal to\n  Concept-Based Representation Learning'",
      "pdf_url": "http://arxiv.org/pdf/2402.09236v2",
      "published_date": "2024-02-14 15:23:59 UTC",
      "updated_date": "2024-12-09 09:00:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:16:37.586921"
    },
    {
      "arxiv_id": "2402.09233v1",
      "title": "Design and Realization of a Benchmarking Testbed for Evaluating Autonomous Platooning Algorithms",
      "title_zh": "自主编队算法评估基准测试平台的设计与实现",
      "authors": [
        "Michael Shaham",
        "Risha Ranjan",
        "Engin Kirda",
        "Taskin Padir"
      ],
      "abstract": "Autonomous vehicle platoons present near- and long-term opportunities to\nenhance operational efficiencies and save lives. The past 30 years have seen\nrapid development in the autonomous driving space, enabling new technologies\nthat will alleviate the strain placed on human drivers and reduce vehicle\nemissions. This paper introduces a testbed for evaluating and benchmarking\nplatooning algorithms on 1/10th scale vehicles with onboard sensors. To\ndemonstrate the testbed's utility, we evaluate three algorithms, linear\nfeedback and two variations of distributed model predictive control, and\ncompare their results on a typical platooning scenario where the lead vehicle\ntracks a reference trajectory that changes speed multiple times. We validate\nour algorithms in simulation to analyze the performance as the platoon size\nincreases, and find that the distributed model predictive control algorithms\noutperform linear feedback on hardware and in simulation.",
      "tldr_zh": "本研究设计并实现了用于评估自主编队算法的基准测试平台，该平台采用1/10比例车辆和传感器，旨在提升车辆操作效率并减少排放。研究者评估了三种算法，包括linear feedback和两种distributed model predictive control，在典型场景中让领队车辆跟踪多变的速度参考轨迹。实验结果显示，在模拟和硬件测试中，distributed model predictive control算法在编队规模增加时表现出色，优于linear feedback算法。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.MA",
        "cs.SY",
        "eess.SY",
        "math.OC"
      ],
      "primary_category": "cs.RO",
      "comment": "To be published in International Symposium on Experimental Robotics,\n  2023",
      "pdf_url": "http://arxiv.org/pdf/2402.09233v1",
      "published_date": "2024-02-14 15:22:24 UTC",
      "updated_date": "2024-02-14 15:22:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:16:49.396831"
    },
    {
      "arxiv_id": "2402.09225v2",
      "title": "Is my Data in your AI Model? Membership Inference Test with Application to Face Images",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel DeAlcala",
        "Aythami Morales",
        "Julian Fierrez",
        "Gonzalo Mancera",
        "Ruben Tolosana",
        "Javier Ortega-Garcia"
      ],
      "abstract": "This article introduces the Membership Inference Test (MINT), a novel\napproach that aims to empirically assess if given data was used during the\ntraining of AI/ML models. Specifically, we propose two MINT architectures\ndesigned to learn the distinct activation patterns that emerge when an Audited\nModel is exposed to data used during its training process. These architectures\nare based on Multilayer Perceptrons (MLPs) and Convolutional Neural Networks\n(CNNs). The experimental framework focuses on the challenging task of Face\nRecognition, considering three state-of-the-art Face Recognition systems.\nExperiments are carried out using six publicly available databases, comprising\nover 22 million face images in total. Different experimental scenarios are\nconsidered depending on the context of the AI model to test. Our proposed MINT\napproach achieves promising results, with up to 90% accuracy, indicating the\npotential to recognize if an AI model has been trained with specific data. The\nproposed MINT approach can serve to enforce privacy and fairness in several AI\napplications, e.g., revealing if sensitive or private data was used for\ntraining or tuning Large Language Models (LLMs).",
      "tldr_zh": "本文提出 Membership Inference Test (MINT)，一种新方法，用于检测特定数据是否被用于 AI/ML 模型的训练，通过学习模型在处理训练数据时产生的独特激活模式。MINT 基于 Multilayer Perceptrons (MLPs) 和 Convolutional Neural Networks (CNNs) 两种架构，并在人脸识别任务上进行实验，使用六个公开数据库共超过 2200 万张面部图像，实现了高达 90% 的准确率。实验涵盖多种场景，证明了 MINT 在不同 AI 模型中的有效性。该方法可应用于强化隐私和公平性，例如识别敏感数据是否用于训练 Large Language Models (LLMs)。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages including references and authors",
      "pdf_url": "http://arxiv.org/pdf/2402.09225v2",
      "published_date": "2024-02-14 15:09:01 UTC",
      "updated_date": "2024-09-06 11:15:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:17:03.800261"
    },
    {
      "arxiv_id": "2402.09221v1",
      "title": "Spectral Filters, Dark Signals, and Attention Sinks",
      "title_zh": "翻译失败",
      "authors": [
        "Nicola Cancedda"
      ],
      "abstract": "Projecting intermediate representations onto the vocabulary is an\nincreasingly popular interpretation tool for transformer-based LLMs, also known\nas the logit lens. We propose a quantitative extension to this approach and\ndefine spectral filters on intermediate representations based on partitioning\nthe singular vectors of the vocabulary embedding and unembedding matrices into\nbands. We find that the signals exchanged in the tail end of the spectrum are\nresponsible for attention sinking (Xiao et al. 2023), of which we provide an\nexplanation. We find that the loss of pretrained models can be kept low despite\nsuppressing sizable parts of the embedding spectrum in a layer-dependent way,\nas long as attention sinking is preserved. Finally, we discover that the\nrepresentation of tokens that draw attention from many tokens have large\nprojections on the tail end of the spectrum.",
      "tldr_zh": "本研究扩展了logit lens方法，通过定义基于词汇嵌入和反嵌入矩阵奇异向量的谱过滤器（spectral filters），对transformer-based LLMs的中间表示进行定量分析。研究发现，谱尾端的信号（dark signals）是注意力下沉（attention sinks）的主要原因，并提供了其机制解释。同时，实验显示，预训练模型的损失可保持较低，即使层依赖性地抑制部分嵌入谱，前提是保留注意力下沉。最后，研究揭示，那些吸引大量注意力的标记在谱尾端有较大投影，为理解LLMs的内部动态提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09221v1",
      "published_date": "2024-02-14 15:01:07 UTC",
      "updated_date": "2024-02-14 15:01:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:17:14.823860"
    },
    {
      "arxiv_id": "2402.09211v1",
      "title": "DivaTrack: Diverse Bodies and Motions from Acceleration-Enhanced Three-Point Trackers",
      "title_zh": "翻译失败",
      "authors": [
        "Dongseok Yang",
        "Jiho Kang",
        "Lingni Ma",
        "Joseph Greer",
        "Yuting Ye",
        "Sung-Hee Lee"
      ],
      "abstract": "Full-body avatar presence is crucial for immersive social and environmental\ninteractions in digital reality. However, current devices only provide three\nsix degrees of freedom (DOF) poses from the headset and two controllers (i.e.\nthree-point trackers). Because it is a highly under-constrained problem,\ninferring full-body pose from these inputs is challenging, especially when\nsupporting the full range of body proportions and use cases represented by the\ngeneral population. In this paper, we propose a deep learning framework,\nDivaTrack, which outperforms existing methods when applied to diverse body\nsizes and activities. We augment the sparse three-point inputs with linear\naccelerations from Inertial Measurement Units (IMU) to improve foot contact\nprediction. We then condition the otherwise ambiguous lower-body pose with the\npredictions of foot contact and upper-body pose in a two-stage model. We\nfurther stabilize the inferred full-body pose in a wide range of configurations\nby learning to blend predictions that are computed in two reference frames,\neach of which is designed for different types of motions. We demonstrate the\neffectiveness of our design on a large dataset that captures 22 subjects\nperforming challenging locomotion for three-point tracking, including lunges,\nhula-hooping, and sitting. As shown in a live demo using the Meta VR headset\nand Xsens IMUs, our method runs in real-time while accurately tracking a user's\nmotion when they perform a diverse set of movements.",
      "tldr_zh": "本研究提出DivaTrack，一个深度学习框架，用于从三点追踪器（three-point trackers）推断全身体势，支持多样化的体型和动作，以提升数字现实中的沉浸式互动。框架通过整合Inertial Measurement Units (IMU)提供的线性加速度来增强输入，提高脚部接触预测，并采用两阶段模型结合上身姿势预测来解决下身姿势的模糊性，同时学习在两种参考框架中混合预测以稳定各种运动配置。实验在包含22个受试者的数据集上验证了其有效性，涵盖挑战性动作如弓步、呼啦圈和坐姿，并在Meta VR头戴设备和Xsens IMUs的实时演示中，准确跟踪用户的多样化运动，超越现有方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted to Eurographics 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09211v1",
      "published_date": "2024-02-14 14:46:03 UTC",
      "updated_date": "2024-02-14 14:46:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:17:27.009133"
    },
    {
      "arxiv_id": "2402.09205v2",
      "title": "Tell Me More! Towards Implicit User Intention Understanding of Language Model Driven Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Cheng Qian",
        "Bingxiang He",
        "Zhong Zhuang",
        "Jia Deng",
        "Yujia Qin",
        "Xin Cong",
        "Zhong Zhang",
        "Jie Zhou",
        "Yankai Lin",
        "Zhiyuan Liu",
        "Maosong Sun"
      ],
      "abstract": "Current language model-driven agents often lack mechanisms for effective user\nparticipation, which is crucial given the vagueness commonly found in user\ninstructions. Although adept at devising strategies and performing tasks, these\nagents struggle with seeking clarification and grasping precise user\nintentions. To bridge this gap, we introduce Intention-in-Interaction (IN3), a\nnovel benchmark designed to inspect users' implicit intentions through explicit\nqueries. Next, we propose the incorporation of model experts as the upstream in\nagent designs to enhance user-agent interaction. Employing IN3, we empirically\ntrain Mistral-Interact, a powerful model that proactively assesses task\nvagueness, inquires user intentions, and refines them into actionable goals\nbefore starting downstream agent task execution. Integrating it into the XAgent\nframework, we comprehensively evaluate the enhanced agent system regarding user\ninstruction understanding and execution, revealing that our approach notably\nexcels at identifying vague user tasks, recovering and summarizing critical\nmissing information, setting precise and necessary agent execution goals, and\nminimizing redundant tool usage, thus boosting overall efficiency. All the data\nand codes are released.",
      "tldr_zh": "该研究针对语言模型驱动代理在处理用户指令模糊性时的不足，提出Intention-in-Interaction (IN3)基准，用于评估代理通过显式查询理解用户隐含意图的能力。作者引入模型专家作为代理设计的上游组件，并训练了Mistral-Interact模型，使其能主动评估任务模糊性、询问用户意图并细化为可行动目标。实验结果显示，将Mistral-Interact集成到XAgent框架后，代理在识别模糊任务、恢复关键信息、设置精确目标和减少冗余工具使用方面表现出显著提升，从而提高了整体交互效率。所有数据和代码已公开。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "26 pages, 5 tables, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.09205v2",
      "published_date": "2024-02-14 14:36:30 UTC",
      "updated_date": "2024-02-15 09:59:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:17:39.895947"
    },
    {
      "arxiv_id": "2402.09200v1",
      "title": "Discovering Command and Control (C2) Channels on Tor and Public Networks Using Reinforcement Learning",
      "title_zh": "利用强化学习发现 Tor 和公共网络上的命令与控制 (C2) 通道",
      "authors": [
        "Cheng Wang",
        "Christopher Redino",
        "Abdul Rahman",
        "Ryan Clark",
        "Daniel Radke",
        "Tyler Cody",
        "Dhruv Nandakumar",
        "Edward Bowen"
      ],
      "abstract": "Command and control (C2) channels are an essential component of many types of\ncyber attacks, as they enable attackers to remotely control their\nmalware-infected machines and execute harmful actions, such as propagating\nmalicious code across networks, exfiltrating confidential data, or initiating\ndistributed denial of service (DDoS) attacks. Identifying these C2 channels is\ntherefore crucial in helping to mitigate and prevent cyber attacks. However,\nidentifying C2 channels typically involves a manual process, requiring deep\nknowledge and expertise in cyber operations. In this paper, we propose a\nreinforcement learning (RL) based approach to automatically emulate C2 attack\ncampaigns using both the normal (public) and the Tor networks. In addition,\npayload size and network firewalls are configured to simulate real-world attack\nscenarios. Results on a typical network configuration show that the RL agent\ncan automatically discover resilient C2 attack paths utilizing both Tor-based\nand conventional communication channels, while also bypassing network\nfirewalls.",
      "tldr_zh": "本文研究了命令与控制 (C2) 渠道在网络攻击中的关键作用，这些渠道允许攻击者远程控制受感染设备，但传统识别方法依赖手动操作，需要专业知识。作者提出了一种基于强化学习 (RL) 的方法，来自动模拟 C2 攻击活动，利用公共网络和 Tor 网络，并通过配置 payload 大小和网络防火墙来模仿真实场景。实验结果表明，RL 代理能够自动发现弹性 C2 攻击路径，同时绕过防火墙，从而为自动化识别和防范网络攻击提供高效工具。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09200v1",
      "published_date": "2024-02-14 14:33:17 UTC",
      "updated_date": "2024-02-14 14:33:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:17:50.853797"
    },
    {
      "arxiv_id": "2402.09199v1",
      "title": "Ten Words Only Still Help: Improving Black-Box AI-Generated Text Detection via Proxy-Guided Efficient Re-Sampling",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhui Shi",
        "Qiang Sheng",
        "Juan Cao",
        "Hao Mi",
        "Beizhe Hu",
        "Danding Wang"
      ],
      "abstract": "With the rapidly increasing application of large language models (LLMs),\ntheir abuse has caused many undesirable societal problems such as fake news,\nacademic dishonesty, and information pollution. This makes AI-generated text\n(AIGT) detection of great importance. Among existing methods, white-box methods\nare generally superior to black-box methods in terms of performance and\ngeneralizability, but they require access to LLMs' internal states and are not\napplicable to black-box settings. In this paper, we propose to estimate word\ngeneration probabilities as pseudo white-box features via multiple re-sampling\nto help improve AIGT detection under the black-box setting. Specifically, we\ndesign POGER, a proxy-guided efficient re-sampling method, which selects a\nsmall subset of representative words (e.g., 10 words) for performing multiple\nre-sampling in black-box AIGT detection. Experiments on datasets containing\ntexts from humans and seven LLMs show that POGER outperforms all baselines in\nmacro F1 under black-box, partial white-box, and out-of-distribution settings\nand maintains lower re-sampling costs than its existing counterparts.",
      "tldr_zh": "该论文针对大型语言模型（LLMs）的滥用问题（如假新闻和学术不端），提出了一种改进黑盒 AI 生成文本（AIGT）检测的方法。研究设计了 POGER，一种代理引导的高效 re-sampling 技术，只需选择少量代表性单词（如 10 个）进行多次重采样，以估计词生成概率作为伪白盒特征，从而提升检测性能。在包含人类文本和七个 LLMs 的数据集上，实验结果显示 POGER 在黑盒、部分白盒和分布外设置下，macro F1 分数优于所有基线，同时保持更低的 re-sampling 成本。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "13 pages, 6 figures, 7 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.09199v1",
      "published_date": "2024-02-14 14:32:16 UTC",
      "updated_date": "2024-02-14 14:32:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:18:03.782899"
    },
    {
      "arxiv_id": "2402.10236v1",
      "title": "Discovering Sensorimotor Agency in Cellular Automata using Diversity Search",
      "title_zh": "翻译失败",
      "authors": [
        "Gautier Hamon",
        "Mayalen Etcheverry",
        "Bert Wang-Chak Chan",
        "Clément Moulin-Frier",
        "Pierre-Yves Oudeyer"
      ],
      "abstract": "The research field of Artificial Life studies how life-like phenomena such as\nautopoiesis, agency, or self-regulation can self-organize in computer\nsimulations. In cellular automata (CA), a key open-question has been whether it\nit is possible to find environment rules that self-organize robust\n\"individuals\" from an initial state with no prior existence of things like\n\"bodies\", \"brain\", \"perception\" or \"action\". In this paper, we leverage recent\nadvances in machine learning, combining algorithms for diversity search,\ncurriculum learning and gradient descent, to automate the search of such\n\"individuals\", i.e. localized structures that move around with the ability to\nreact in a coherent manner to external obstacles and maintain their integrity,\nhence primitive forms of sensorimotor agency. We show that this approach\nenables to find systematically environmental conditions in CA leading to\nself-organization of such basic forms of agency. Through multiple experiments,\nwe show that the discovered agents have surprisingly robust capabilities to\nmove, maintain their body integrity and navigate among various obstacles. They\nalso show strong generalization abilities, with robustness to changes of scale,\nrandom updates or perturbations from the environment not seen during training.\nWe discuss how this approach opens new perspectives in AI and synthetic\nbioengineering.",
      "tldr_zh": "本研究探讨了在 Cellular Automata 中，通过 Diversity Search 等算法，自动发现自组织的 sensorimotor agency，即能够移动、响应外部障碍并维护自身完整性的原始个体，从而模拟 Artificial Life 中的生命现象。\n研究结合了 Diversity Search、Curriculum Learning 和 Gradient Descent 方法，从无初始结构（如 bodies 或 brains）的状态出发，系统地搜索环境规则以实现这种 agency 的自组织。\n实验结果显示，发现的代理具有高度鲁棒性，能在各种障碍中导航，并对规模变化、随机更新和环境扰动表现出强泛化能力。\n这项工作为 AI 和 synthetic bioengineering 领域提供了新视角，推动了对生命自组织机制的理解。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.10236v1",
      "published_date": "2024-02-14 14:30:42 UTC",
      "updated_date": "2024-02-14 14:30:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:18:16.001906"
    },
    {
      "arxiv_id": "2402.09193v2",
      "title": "(Ir)rationality and Cognitive Biases in Large Language Models",
      "title_zh": "大型语言模型中的（非）理性和认知偏差",
      "authors": [
        "Olivia Macmillan-Scott",
        "Mirco Musolesi"
      ],
      "abstract": "Do large language models (LLMs) display rational reasoning? LLMs have been\nshown to contain human biases due to the data they have been trained on;\nwhether this is reflected in rational reasoning remains less clear. In this\npaper, we answer this question by evaluating seven language models using tasks\nfrom the cognitive psychology literature. We find that, like humans, LLMs\ndisplay irrationality in these tasks. However, the way this irrationality is\ndisplayed does not reflect that shown by humans. When incorrect answers are\ngiven by LLMs to these tasks, they are often incorrect in ways that differ from\nhuman-like biases. On top of this, the LLMs reveal an additional layer of\nirrationality in the significant inconsistency of the responses. Aside from the\nexperimental results, this paper seeks to make a methodological contribution by\nshowing how we can assess and compare different capabilities of these types of\nmodels, in this case with respect to rational reasoning.",
      "tldr_zh": "本研究探讨了大型语言模型(LLMs)是否显示理性推理，以及它们是否像人类一样受认知偏见影响。研究者通过使用认知心理学任务评估了七个LLMs，发现这些模型确实表现出非理性，但其表现方式不同于人类，错误答案往往不遵循人类偏见，且响应存在显著不一致性。该论文不仅提供了实验证据，还贡献了评估和比较LLMs理性推理能力的方法论框架。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09193v2",
      "published_date": "2024-02-14 14:17:21 UTC",
      "updated_date": "2024-02-15 11:09:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:18:26.038372"
    },
    {
      "arxiv_id": "2402.09177v2",
      "title": "Leveraging the Context through Multi-Round Interactions for Jailbreaking Attacks",
      "title_zh": "通过多轮互动利用上下文进行越",
      "authors": [
        "Yixin Cheng",
        "Markos Georgopoulos",
        "Volkan Cevher",
        "Grigorios G. Chrysos"
      ],
      "abstract": "Large Language Models (LLMs) are susceptible to Jailbreaking attacks, which\naim to extract harmful information by subtly modifying the attack query. As\ndefense mechanisms evolve, directly obtaining harmful information becomes\nincreasingly challenging for Jailbreaking attacks. In this work, inspired from\nChomsky's transformational-generative grammar theory and human practices of\nindirect context to elicit harmful information, we focus on a new attack form,\ncalled Contextual Interaction Attack. We contend that the prior\ncontext\\u2014the information preceding the attack query\\u2014plays a pivotal\nrole in enabling strong Jailbreaking attacks. Specifically, we propose a first\nmulti-turn approach that leverages benign preliminary questions to interact\nwith the LLM. Due to the autoregressive nature of LLMs, which use previous\nconversation rounds as context during generation, we guide the model's\nquestion-response pair to construct a context that is semantically aligned with\nthe attack query to execute the attack. We conduct experiments on seven\ndifferent LLMs and demonstrate the efficacy of this attack, which is black-box\nand can also transfer across LLMs. We believe this can lead to further\ndevelopments and understanding of security in LLMs.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）易受Jailbreaking attacks的影响，这些攻击通过微妙修改查询来提取有害信息，但随着防御机制的增强，直接攻击变得困难。论文提出了一种新形式攻击——Contextual Interaction Attack，受Chomsky的生成语法理论启发，利用多轮交互通过benign初步问题构建语义一致的上下文，引导LLMs的自回归机制执行攻击。实验在七个不同LLMs上验证了该黑盒攻击的有效性，并证明其可跨模型转移，这有助于深化对LLMs安全性的理解和改进。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "29 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.09177v2",
      "published_date": "2024-02-14 13:45:19 UTC",
      "updated_date": "2024-10-02 10:43:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:18:39.201702"
    },
    {
      "arxiv_id": "2402.09161v1",
      "title": "Role-Playing Simulation Games using ChatGPT",
      "title_zh": "使用 ChatGPT 的角色扮演模拟游戏",
      "authors": [
        "Rita Stampfl",
        "Igor Ivkić",
        "Barbara Geyer"
      ],
      "abstract": "Since the COVID-19 pandemic, educational institutions have embarked on\ndigital transformation projects. The success of these projects depends on\nintegrating new technologies and understanding the needs of digitally literate\nstudents. The \"learning by doing\" approach suggests that real success in\nlearning new skills is achieved when students can try out and practise these\nskills. In this article, we demonstrate how Large Language Models (LLMs) can\nenhance the quality of teaching by using ChatGPT in a role-playing simulation\ngame scenario to promote active learning. Moreover, we discuss how LLMs can\nboost students' interest in learning by allowing them to practice real-life\nscenarios using ChatGPT.",
      "tldr_zh": "这篇论文探讨了在 COVID-19 后教育数字化转型中使用 ChatGPT 进行角色扮演模拟游戏，以促进“学习即实践”的教学方法。研究展示了如何利用大型语言模型 (LLMs) 如 ChatGPT，让学生在模拟游戏中实践真实场景，从而提升教学质量和主动学习效果。同时，论文强调了 LLMs 在增加学生学习兴趣方面的潜力，为教育技术应用提供了新见解。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Link to online article:\n  https://ercim-news.ercim.eu/en136/special/role-playing-simulation-games-using-chatgpt",
      "pdf_url": "http://arxiv.org/pdf/2402.09161v1",
      "published_date": "2024-02-14 13:24:21 UTC",
      "updated_date": "2024-02-14 13:24:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:18:49.377666"
    },
    {
      "arxiv_id": "2402.09495v2",
      "title": "On the Potential of Network-Based Features for Fraud Detection",
      "title_zh": "基于网络特征在欺诈",
      "authors": [
        "Catayoun Azarm",
        "Erman Acar",
        "Mickey van Zeelt"
      ],
      "abstract": "Online transaction fraud presents substantial challenges to businesses and\nconsumers, risking significant financial losses. Conventional rule-based\nsystems struggle to keep pace with evolving fraud tactics, leading to high\nfalse positive rates and missed detections. Machine learning techniques offer a\npromising solution by leveraging historical data to identify fraudulent\npatterns. This article explores using the personalised PageRank (PPR) algorithm\nto capture the social dynamics of fraud by analysing relationships between\nfinancial accounts. The primary objective is to compare the performance of\ntraditional features with the addition of PPR in fraud detection models.\nResults indicate that integrating PPR enhances the model's predictive power,\nsurpassing the baseline model. Additionally, the PPR feature provides unique\nand valuable information, evidenced by its high feature importance score.\nFeature stability analysis confirms consistent feature distributions across\ntraining and test datasets.",
      "tldr_zh": "该论文探讨了在线交易欺诈检测的挑战，指出传统规则系统难以应对演变的欺诈策略，而机器学习技术可通过历史数据识别模式。研究重点使用 personalized PageRank (PPR) 算法分析金融账户之间的关系，作为网络-based 特征，与传统特征进行比较。结果表明，整合 PPR 提升了模型的预测性能，超过基线模型，且 PPR 特征显示出高重要性和特征分布稳定性，为欺诈检测提供了更有效的工具。",
      "categories": [
        "q-fin.RM",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.RM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09495v2",
      "published_date": "2024-02-14 13:20:09 UTC",
      "updated_date": "2024-02-19 11:58:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:19:03.173917"
    },
    {
      "arxiv_id": "2402.09494v2",
      "title": "Can AI and humans genuinely communicate?",
      "title_zh": "翻译失败",
      "authors": [
        "Constant Bonard"
      ],
      "abstract": "Can AI and humans genuinely communicate? In this article, after giving some\nbackground and motivating my proposal (sections 1 to 3), I explore a way to\nanswer this question that I call the \"mental-behavioral methodology\" (sections\n4 and 5). This methodology follows the following three steps: First, spell out\nwhat mental capacities are sufficient for human communication (as opposed to\ncommunication more generally). Second, spell out the experimental paradigms\nrequired to test whether a behavior exhibits these capacities. Third, apply or\nadapt these paradigms to test whether an AI displays the relevant behaviors. If\nthe first two steps are successfully completed, and if the AI passes the tests\nwith human-like results, this constitutes evidence that this AI and humans can\ngenuinely communicate. This mental-behavioral methodology has the advantage\nthat we don't need to understand the workings of black-box algorithms, such as\nstandard deep neural networks. This is comparable to the fact that we don't\nneed to understand how human brains work to know that humans can genuinely\ncommunicate. This methodology also has its disadvantages and I will discuss\nsome of them (section 6).",
      "tldr_zh": "本论文探讨了AI是否能与人类真正沟通，提出了一种“mental-behavioral methodology”方法来回答这一问题。该方法包括三个步骤：首先，定义人类沟通所需的心理能力；其次，设计实验范式来测试这些能力；第三，将这些范式应用于AI，以检查其行为是否与人类类似。如果AI通过测试并显示出人类-like的结果，这将作为AI和人类能真正沟通的证据。该方法的优势在于无需了解AI内部算法（如深度神经网络），类似于无需理解大脑机制即可确认人类沟通，但作者也指出了其潜在缺点，如可能存在的局限性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "March 2024 preprint",
      "pdf_url": "http://arxiv.org/pdf/2402.09494v2",
      "published_date": "2024-02-14 13:00:40 UTC",
      "updated_date": "2024-03-25 16:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:19:14.253769"
    },
    {
      "arxiv_id": "2402.09147v4",
      "title": "Into the Unknown: Self-Learning Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Teddy Ferdinan",
        "Jan Kocoń",
        "Przemysław Kazienko"
      ],
      "abstract": "We address the main problem of self-learning LLM: the question of what to\nlearn. We propose a self-learning LLM framework that enables an LLM to\nindependently learn previously unknown knowledge through self-assessment of\ntheir own hallucinations. We introduce a concept called Point in the Unknown\n(PiU) to identify atomic knowledge unknown to a model, along with four methods\nfor automatic PiUs identification, facilitating the creation of a self-learning\nloop that focuses exclusively on the absorption of currently unknown knowledge\ninto the model. Additionally, we developed evaluation metrics to gauge an LLM's\nself-learning capability. Our experiments revealed that LLMs with at least 3B\nparameters that have undergone some instruction training would be able to\nperform self-learning well. We further proved the effectiveness of\nself-learning by comparing the performance of a model that has undergone\nself-learning to a model that has not. Our self-learning concept allows more\nefficient LLM updates and opens new perspectives for LLM knowledge exchange.",
      "tldr_zh": "本文提出一种自学习 Large Language Models (LLMs) 框架，解决“学什么”的核心问题，通过自我评估 hallucinations 来独立学习未知知识。框架引入 Point in the Unknown (PiU) 概念及四种自动识别方法，构建一个专注于吸收未知知识的自学习循环。研究者还开发了评估指标，并通过实验验证，至少 3B 参数的经过指令训练的 LLMs 可以有效进行自学习，与未自学习模型相比显著提升性能。该方法促进更高效的 LLM 更新，并为知识交换开辟新路径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to SENTIRE 2024 (ICDM Workshops):\n  https://sentic.net/sentire2024ferdinan.pdf",
      "pdf_url": "http://arxiv.org/pdf/2402.09147v4",
      "published_date": "2024-02-14 12:56:58 UTC",
      "updated_date": "2024-11-12 03:50:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:19:27.239164"
    },
    {
      "arxiv_id": "2402.09141v1",
      "title": "Advancing NLP Models with Strategic Text Augmentation: A Comprehensive Study of Augmentation Methods and Curriculum Strategies",
      "title_zh": "通过战略文本增强推进自然语言处理模型：增强方法和课程策略的全面研究",
      "authors": [
        "Himmet Toprak Kesgin",
        "Mehmet Fatih Amasyali"
      ],
      "abstract": "This study conducts a thorough evaluation of text augmentation techniques\nacross a variety of datasets and natural language processing (NLP) tasks to\naddress the lack of reliable, generalized evidence for these methods. It\nexamines the effectiveness of these techniques in augmenting training sets to\nimprove performance in tasks such as topic classification, sentiment analysis,\nand offensive language detection. The research emphasizes not only the\naugmentation methods, but also the strategic order in which real and augmented\ninstances are introduced during training. A major contribution is the\ndevelopment and evaluation of Modified Cyclical Curriculum Learning (MCCL) for\naugmented datasets, which represents a novel approach in the field. Results\nshow that specific augmentation methods, especially when integrated with MCCL,\nsignificantly outperform traditional training approaches in NLP model\nperformance. These results underscore the need for careful selection of\naugmentation techniques and sequencing strategies to optimize the balance\nbetween speed and quality improvement in various NLP tasks. The study concludes\nthat the use of augmentation methods, especially in conjunction with MCCL,\nleads to improved results in various classification tasks, providing a\nfoundation for future advances in text augmentation strategies in NLP.",
      "tldr_zh": "这篇论文对文本增强技术进行了全面评估，应用于多种数据集和NLP任务（如主题分类、情感分析和攻击性语言检测），以解决这些方法缺乏可靠泛化证据的问题。研究不仅考察了增强方法的有效性，还探索了引入真实和增强实例的顺序策略，并开发了Modified Cyclical Curriculum Learning (MCCL)作为一种新颖的课程学习方法。结果表明，特定增强方法与MCCL结合后，显著提高了NLP模型性能，优于传统训练方法，并强调了精心选择技术和序列策略以优化速度与质量平衡的重要性。该研究为NLP中的文本增强策略提供了重要基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09141v1",
      "published_date": "2024-02-14 12:41:09 UTC",
      "updated_date": "2024-02-14 12:41:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:19:38.780022"
    },
    {
      "arxiv_id": "2402.09136v1",
      "title": "DolphCoder: Echo-Locating Code Large Language Models with Diverse and Multi-Objective Instruction Tuning",
      "title_zh": "翻译失败",
      "authors": [
        "Yejie Wang",
        "Keqing He",
        "Guanting Dong",
        "Pei Wang",
        "Weihao Zeng",
        "Muxi Diao",
        "Yutao Mou",
        "Mengdi Zhang",
        "Jingang Wang",
        "Xunliang Cai",
        "Weiran Xu"
      ],
      "abstract": "Code Large Language Models (Code LLMs) have demonstrated outstanding\nperformance in code-related tasks. Several instruction tuning approaches have\nbeen proposed to boost the code generation performance of pre-trained Code\nLLMs. In this paper, we introduce a diverse instruction model (DolphCoder) with\nself-evaluating for code generation. It learns diverse instruction targets and\ncombines a code evaluation objective to enhance its code generation ability.\nOur model achieves superior performance on the HumanEval and MBPP benchmarks,\ndemonstrating new insights for future code instruction tuning work. Our key\nfindings are: (1) Augmenting more diverse responses with distinct reasoning\npaths increases the code capability of LLMs. (2) Improving one's ability to\nevaluate the correctness of code solutions also enhances their ability to\ncreate it.",
      "tldr_zh": "本研究提出DolphCoder，一种多样化且多目标指令调优模型，用于提升Code LLMs在代码生成任务中的性能。它通过学习多样化的指令目标并结合代码评估目标（code evaluation objective），使模型能够生成更多多样化的响应和不同的推理路径，并在HumanEval和MBPP基准测试中表现出色。关键发现包括：（1）增加多样化响应能显著提高LLMs的代码能力；（2）提升代码正确性评估能力也能间接增强代码生成能力。该方法为未来的代码指令调优工作提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.09136v1",
      "published_date": "2024-02-14 12:34:58 UTC",
      "updated_date": "2024-02-14 12:34:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:19:49.877163"
    },
    {
      "arxiv_id": "2402.09132v4",
      "title": "Exploring the Adversarial Capabilities of Large Language Models",
      "title_zh": "探索大型语言模型的对抗能力",
      "authors": [
        "Lukas Struppek",
        "Minh Hieu Le",
        "Dominik Hintersdorf",
        "Kristian Kersting"
      ],
      "abstract": "The proliferation of large language models (LLMs) has sparked widespread and\ngeneral interest due to their strong language generation capabilities, offering\ngreat potential for both industry and research. While previous research delved\ninto the security and privacy issues of LLMs, the extent to which these models\ncan exhibit adversarial behavior remains largely unexplored. Addressing this\ngap, we investigate whether common publicly available LLMs have inherent\ncapabilities to perturb text samples to fool safety measures, so-called\nadversarial examples resp.~attacks. More specifically, we investigate whether\nLLMs are inherently able to craft adversarial examples out of benign samples to\nfool existing safe rails. Our experiments, which focus on hate speech\ndetection, reveal that LLMs succeed in finding adversarial perturbations,\neffectively undermining hate speech detection systems. Our findings carry\nsignificant implications for (semi-)autonomous systems relying on LLMs,\nhighlighting potential challenges in their interaction with existing systems\nand safety measures.",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 的对抗能力，调查它们是否能从无害样本中生成对抗性示例 (adversarial examples) 来欺骗安全措施。研究重点是通过实验测试 LLMs 在仇恨言论检测 (hate speech detection) 任务中的表现，结果显示这些模型能够成功创建扰动样本，从而破坏检测系统的有效性。这些发现突出了依赖 LLMs 的半自主系统在与现有安全措施互动时面临的潜在风险。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09132v4",
      "published_date": "2024-02-14 12:28:38 UTC",
      "updated_date": "2024-07-08 12:10:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:20:02.184652"
    },
    {
      "arxiv_id": "2402.09129v1",
      "title": "Optimal Automated Market Makers: Differentiable Economics and Strong Duality",
      "title_zh": "最优自动化做市商：可微经济学和强对偶",
      "authors": [
        "Michael J. Curry",
        "Zhou Fan",
        "David C. Parkes"
      ],
      "abstract": "The role of a market maker is to simultaneously offer to buy and sell\nquantities of goods, often a financial asset such as a share, at specified\nprices. An automated market maker (AMM) is a mechanism that offers to trade\naccording to some predetermined schedule; the best choice of this schedule\ndepends on the market maker's goals. The literature on the design of AMMs has\nmainly focused on prediction markets with the goal of information elicitation.\nMore recent work motivated by DeFi has focused instead on the goal of profit\nmaximization, but considering only a single type of good (traded with a\nnumeraire), including under adverse selection (Milionis et al. 2022). Optimal\nmarket making in the presence of multiple goods, including the possibility of\ncomplex bundling behavior, is not well understood. In this paper, we show that\nfinding an optimal market maker is dual to an optimal transport problem, with\nspecific geometric constraints on the transport plan in the dual. We show that\noptimal mechanisms for multiple goods and under adverse selection can take\nadvantage of bundling, both improved prices for bundled purchases and sales as\nwell as sometimes accepting payment \"in kind.\" We present conjectures of\noptimal mechanisms in additional settings which show further complex behavior.\nFrom a methodological perspective, we make essential use of the tools of\ndifferentiable economics to generate conjectures of optimal mechanisms, and\ngive a proof-of-concept for the use of such tools in guiding theoretical\ninvestigations.",
      "tldr_zh": "这篇论文探讨了最优 Automated Market Makers (AMM) 的设计，证明了在多商品场景下，寻找最优市场制造者等价于一个最优运输问题，并引入了特定的几何约束和 Strong Duality。作者利用 Differentiable Economics 工具生成机制猜想，展示了最优机制如何通过捆绑行为（如改进捆绑购买/销售价格和接受“in kind”支付）来应对逆向选择(Adverse Selection)。这些发现为 DeFi 等领域的市场机制优化提供了新框架，并证明了该方法在理论研究中的实用性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "econ.TH",
        "q-fin.TR"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09129v1",
      "published_date": "2024-02-14 12:27:54 UTC",
      "updated_date": "2024-02-14 12:27:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:20:15.187102"
    },
    {
      "arxiv_id": "2402.09126v2",
      "title": "MPIrigen: MPI Code Generation through Domain-Specific Language Models",
      "title_zh": "MPIrigen：通过领域特定语言模型的 MPI 代码生成",
      "authors": [
        "Nadav Schneider",
        "Niranjan Hasabnis",
        "Vy A. Vo",
        "Tal Kadosh",
        "Neva Krien",
        "Mihai Capotă",
        "Guy Tamir",
        "Ted Willke",
        "Nesreen Ahmed",
        "Yuval Pinter",
        "Timothy Mattson",
        "Gal Oren"
      ],
      "abstract": "The imperative need to scale computation across numerous nodes highlights the\nsignificance of efficient parallel computing, particularly in the realm of\nMessage Passing Interface (MPI) integration. The challenging parallel\nprogramming task of generating MPI-based parallel programs has remained\nunexplored. This study first investigates the performance of state-of-the-art\nlanguage models in generating MPI-based parallel programs. Findings reveal that\nwidely used models such as GPT-3.5 and PolyCoder (specialized multi-lingual\ncode models) exhibit notable performance degradation, when generating MPI-based\nprograms compared to general-purpose programs. In contrast, domain-specific\nmodels such as MonoCoder, which are pretrained on MPI-related programming\nlanguages of C and C++, outperform larger models. Subsequently, we introduce a\ndedicated downstream task of MPI-based program generation by fine-tuning\nMonoCoder on HPCorpusMPI. We call the resulting model as MPIrigen. We propose\nan innovative preprocessing for completion only after observing the whole code,\nthus enabling better completion with a wider context. Comparative analysis\nagainst GPT-3.5 zero-shot performance, using a novel HPC-oriented evaluation\nmethod, demonstrates that MPIrigen excels in generating accurate MPI functions\nup to 0.8 accuracy in location and function predictions, and with more than 0.9\naccuracy for argument predictions. The success of this tailored solution\nunderscores the importance of domain-specific fine-tuning in optimizing\nlanguage models for parallel computing code generation, paving the way for a\nnew generation of automatic parallelization tools. The sources of this work are\navailable at our GitHub MPIrigen repository:\nhttps://github.com/Scientific-Computing-Lab-NRCN/MPI-rigen",
      "tldr_zh": "本研究探讨了语言模型在生成 MPI（Message Passing Interface）并行程序时的性能问题，发现通用模型如 GPT-3.5 和 PolyCoder 在处理 MPI 代码时表现显著下降，而域特定模型 MonoCoder 则表现出色。研究团队通过 fine-tuning MonoCoder 于 HPCorpusMPI 数据集，开发了 MPIrigen 模型，并引入一种创新预处理方法，以全代码上下文提升生成准确性。与 GPT-3.5 的零样本性能相比，MPIrigen 在位置和函数预测上达到 0.8 准确率，参数预测准确率超过 0.9。整体结果突显了域特定 fine-tuning 在优化并行计算代码生成方面的关键作用，为自动并行化工具的发展提供了新路径。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SE"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09126v2",
      "published_date": "2024-02-14 12:24:21 UTC",
      "updated_date": "2024-04-23 16:59:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:20:28.455971"
    },
    {
      "arxiv_id": "2402.09109v1",
      "title": "Stochastic Spiking Attention: Accelerating Attention with Stochastic Computing in Spiking Networks",
      "title_zh": "随机脉冲注意力：利用随机计算加速脉冲网络中的注意力机制",
      "authors": [
        "Zihang Song",
        "Prabodh Katti",
        "Osvaldo Simeone",
        "Bipin Rajendran"
      ],
      "abstract": "Spiking Neural Networks (SNNs) have been recently integrated into Transformer\narchitectures due to their potential to reduce computational demands and to\nimprove power efficiency. Yet, the implementation of the attention mechanism\nusing spiking signals on general-purpose computing platforms remains\ninefficient. In this paper, we propose a novel framework leveraging stochastic\ncomputing (SC) to effectively execute the dot-product attention for SNN-based\nTransformers. We demonstrate that our approach can achieve high classification\naccuracy ($83.53\\%$) on CIFAR-10 within 10 time steps, which is comparable to\nthe performance of a baseline artificial neural network implementation\n($83.66\\%$). We estimate that the proposed SC approach can lead to over\n$6.3\\times$ reduction in computing energy and $1.7\\times$ reduction in memory\naccess costs for a digital CMOS-based ASIC design. We experimentally validate\nour stochastic attention block design through an FPGA implementation, which is\nshown to achieve $48\\times$ lower latency as compared to a GPU implementation,\nwhile consuming $15\\times$ less power.",
      "tldr_zh": "该论文提出了一种名为Stochastic Spiking Attention的框架，利用随机计算(Stochastic Computing, SC)来加速Spiking Neural Networks (SNNs)中Transformer的点积注意力机制，从而降低计算需求并提升能效。实验显示，该方法在CIFAR-10数据集上实现了83.53%的分类准确率，仅需10个时间步，与基线人工神经网络(83.66%)相当，同时估计可减少6.3倍计算能量和1.7倍内存访问成本。通过FPGA实现验证，该框架相比GPU降低了48倍延迟和15倍功耗，为高效SNN-based Transformer应用奠定了基础。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "eess.SP"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09109v1",
      "published_date": "2024-02-14 11:47:19 UTC",
      "updated_date": "2024-02-14 11:47:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:20:40.711041"
    },
    {
      "arxiv_id": "2402.09099v6",
      "title": "Neuron-based Multifractal Analysis of Neuron Interaction Dynamics in Large Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xiongye Xiao",
        "Heng Ping",
        "Chenyu Zhou",
        "Defu Cao",
        "Yaxing Li",
        "Yi-Zhuo Zhou",
        "Shixuan Li",
        "Nikos Kanakaris",
        "Paul Bogdan"
      ],
      "abstract": "In recent years, there has been increasing attention on the capabilities of\nlarge models, particularly in handling complex tasks that small-scale models\nare unable to perform. Notably, large language models (LLMs) have demonstrated\n``intelligent'' abilities such as complex reasoning and abstract language\ncomprehension, reflecting cognitive-like behaviors. However, current research\non emergent abilities in large models predominantly focuses on the relationship\nbetween model performance and size, leaving a significant gap in the systematic\nquantitative analysis of the internal structures and mechanisms driving these\nemergent abilities. Drawing inspiration from neuroscience research on brain\nnetwork structure and self-organization, we propose (i) a general network\nrepresentation of large models, (ii) a new analytical framework, called\nNeuron-based Multifractal Analysis (NeuroMFA), for structural analysis, and\n(iii) a novel structure-based metric as a proxy for emergent abilities of large\nmodels. By linking structural features to the capabilities of large models,\nNeuroMFA provides a quantitative framework for analyzing emergent phenomena in\nlarge models. Our experiments show that the proposed method yields a\ncomprehensive measure of network's evolving heterogeneity and organization,\noffering theoretical foundations and a new perspective for investigating\nemergent abilities in large models.",
      "tldr_zh": "该研究关注大型模型（如Large Language Models, LLMs）的内部结构与新兴能力，指出现有工作主要聚焦模型规模与性能的关系，而忽略了对神经元互动动态的系统量化分析。受神经科学启发，作者提出了一种通用网络表示、Neuron-based Multifractal Analysis (NeuroMFA) 分析框架，以及一个基于结构的度量指标，作为大型模型新兴能力的代理指标。NeuroMFA 通过量化网络的演变异质性和组织，将结构特征与模型能力联系起来，提供了一个全面的分析框架。实验结果显示，该方法为探索大型模型的智能行为提供了新的理论基础和视角。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICLR 2025: https://openreview.net/forum?id=nt8gBX58Kh",
      "pdf_url": "http://arxiv.org/pdf/2402.09099v6",
      "published_date": "2024-02-14 11:20:09 UTC",
      "updated_date": "2025-02-04 07:46:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:20:52.894858"
    },
    {
      "arxiv_id": "2402.09097v1",
      "title": "A Digital Twin prototype for traffic sign recognition of a learning-enabled autonomous vehicle",
      "title_zh": "翻译失败",
      "authors": [
        "Mohamed AbdElSalam",
        "Loai Ali",
        "Saddek Bensalem",
        "Weicheng He",
        "Panagiotis Katsaros",
        "Nikolaos Kekatos",
        "Doron Peled",
        "Anastasios Temperekidis",
        "Changshun Wu"
      ],
      "abstract": "In this paper, we present a novel digital twin prototype for a\nlearning-enabled self-driving vehicle. The primary objective of this digital\ntwin is to perform traffic sign recognition and lane keeping. The digital twin\narchitecture relies on co-simulation and uses the Functional Mock-up Interface\nand SystemC Transaction Level Modeling standards. The digital twin consists of\nfour clients, i) a vehicle model that is designed in Amesim tool, ii) an\nenvironment model developed in Prescan, iii) a lane-keeping controller designed\nin Robot Operating System, and iv) a perception and speed control module\ndeveloped in the formal modeling language of BIP (Behavior, Interaction,\nPriority). These clients interface with the digital twin platform,\nPAVE360-Veloce System Interconnect (PAVE360-VSI). PAVE360-VSI acts as the\nco-simulation orchestrator and is responsible for synchronization,\ninterconnection, and data exchange through a server. The server establishes\nconnections among the different clients and also ensures adherence to the\nEthernet protocol. We conclude with illustrative digital twin simulations and\nrecommendations for future work.",
      "tldr_zh": "本论文提出了一种数字孪生原型，用于学习型自动驾驶车辆的交通标志识别和车道保持功能。原型架构基于联合模拟，采用 Functional Mock-up Interface 和 SystemC Transaction Level Modeling 标准，包括 Amesim 车辆模型、Prescan 环境模型、Robot Operating System 车道保持控制器，以及 BIP 语言的感知和速度控制模块。这些组件通过 PAVE360-VSI 平台进行同步、互连和数据交换。论文展示了模拟示例，并为未来工作提供了推荐。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09097v1",
      "published_date": "2024-02-14 11:17:14 UTC",
      "updated_date": "2024-02-14 11:17:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:21:06.231063"
    },
    {
      "arxiv_id": "2402.09091v2",
      "title": "Play Guessing Game with LLM: Indirect Jailbreak Attack with Implicit Clues",
      "title_zh": "与LLM玩猜谜游戏：隐",
      "authors": [
        "Zhiyuan Chang",
        "Mingyang Li",
        "Yi Liu",
        "Junjie Wang",
        "Qing Wang",
        "Yang Liu"
      ],
      "abstract": "With the development of LLMs, the security threats of LLMs are getting more\nand more attention. Numerous jailbreak attacks have been proposed to assess the\nsecurity defense of LLMs. Current jailbreak attacks primarily utilize scenario\ncamouflage techniques. However their explicitly mention of malicious intent\nwill be easily recognized and defended by LLMs. In this paper, we propose an\nindirect jailbreak attack approach, Puzzler, which can bypass the LLM's defense\nstrategy and obtain malicious response by implicitly providing LLMs with some\nclues about the original malicious query. In addition, inspired by the wisdom\nof \"When unable to attack, defend\" from Sun Tzu's Art of War, we adopt a\ndefensive stance to gather clues about the original malicious query through\nLLMs. Extensive experimental results show that Puzzler achieves a query success\nrate of 96.6% on closed-source LLMs, which is 57.9%-82.7% higher than\nbaselines. Furthermore, when tested against the state-of-the-art jailbreak\ndetection approaches, Puzzler proves to be more effective at evading detection\ncompared to baselines.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）的安全威胁，提出了一种新的间接jailbreak attack方法，名为Puzzler，通过隐式提供关于原始恶意查询的线索（如间接提示），来绕过LLMs的防御策略并诱导生成恶意响应。灵感来源于孙子兵法的“攻守兼备”智慧，该方法采用防御姿态来收集相关线索，避免直接提及恶意意图。实验结果显示，Puzzler在闭源LLMs上的查询成功率达到96.6%，比基线方法高57.9%-82.7%，并在对抗state-of-the-art jailbreak detection时表现出更强的逃避能力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CR",
      "comment": "13 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.09091v2",
      "published_date": "2024-02-14 11:11:51 UTC",
      "updated_date": "2024-02-16 10:24:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:21:16.627946"
    },
    {
      "arxiv_id": "2402.09085v3",
      "title": "Polynomial Semantics of Tractable Probabilistic Circuits",
      "title_zh": "可处理概率电路的多项式",
      "authors": [
        "Oliver Broadrick",
        "Honghua Zhang",
        "Guy Van den Broeck"
      ],
      "abstract": "Probabilistic circuits compute multilinear polynomials that represent\nmultivariate probability distributions. They are tractable models that support\nefficient marginal inference. However, various polynomial semantics have been\nconsidered in the literature (e.g., network polynomials, likelihood\npolynomials, generating functions, and Fourier transforms). The relationships\nbetween circuit representations of these polynomial encodings of distributions\nis largely unknown. In this paper, we prove that for distributions over binary\nvariables, each of these probabilistic circuit models is equivalent in the\nsense that any circuit for one of them can be transformed into a circuit for\nany of the others with only a polynomial increase in size. They are therefore\nall tractable for marginal inference on the same class of distributions.\nFinally, we explore the natural extension of one such polynomial semantics,\ncalled probabilistic generating circuits, to categorical random variables, and\nestablish that inference becomes #P-hard.",
      "tldr_zh": "该论文探讨了可处理概率电路（probabilistic circuits）的多项式语义，包括网络多项式（network polynomials）、似然多项式（likelihood polynomials）、生成函数（generating functions）和傅立叶变换（Fourier transforms）。研究证明，对于二元变量（binary variables）的分布，这些电路模型是等价的：一个模型的电路可以通过多项式大小的增加转换为其他模型，从而在同一类分布上支持高效的边际推断（marginal inference）。此外，论文扩展了概率生成电路（probabilistic generating circuits）到分类随机变量（categorical random variables），并证明其推断问题变得#P-hard，这突显了模型局限性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09085v3",
      "published_date": "2024-02-14 11:02:04 UTC",
      "updated_date": "2024-08-08 05:58:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:21:29.078283"
    },
    {
      "arxiv_id": "2402.09084v1",
      "title": "Sobolev Training for Operator Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Namkyeong Cho",
        "Junseung Ryu",
        "Hyung Ju Hwang"
      ],
      "abstract": "This study investigates the impact of Sobolev Training on operator learning\nframeworks for improving model performance. Our research reveals that\nintegrating derivative information into the loss function enhances the training\nprocess, and we propose a novel framework to approximate derivatives on\nirregular meshes in operator learning. Our findings are supported by both\nexperimental evidence and theoretical analysis. This demonstrates the\neffectiveness of Sobolev Training in approximating the solution operators\nbetween infinite-dimensional spaces.",
      "tldr_zh": "本研究探讨了 Sobolev Training 对操作符学习框架的影响，通过将导数信息整合到损失函数中来提升模型性能。研究提出了一种创新框架，用于在不规则网格上近似导数，以更好地处理复杂数据。实验证据和理论分析证明了 Sobolev Training 在无限维空间之间近似解操作符方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09084v1",
      "published_date": "2024-02-14 10:57:29 UTC",
      "updated_date": "2024-02-14 10:57:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:21:41.498881"
    },
    {
      "arxiv_id": "2402.09078v2",
      "title": "Exploiting Estimation Bias in Clipped Double Q-Learning for Continous Control Reinforcement Learning Tasks",
      "title_zh": "翻译失败",
      "authors": [
        "Niccolò Turcato",
        "Alberto Sinigaglia",
        "Alberto Dalla Libera",
        "Ruggero Carli",
        "Gian Antonio Susto"
      ],
      "abstract": "Continuous control Deep Reinforcement Learning (RL) approaches are known to\nsuffer from estimation biases, leading to suboptimal policies. This paper\nintroduces innovative methods in RL, focusing on addressing and exploiting\nestimation biases in Actor-Critic methods for continuous control tasks, using\nDeep Double Q-Learning. We design a Bias Exploiting (BE) mechanism to\ndynamically select the most advantageous estimation bias during training of the\nRL agent. Most State-of-the-art Deep RL algorithms can be equipped with the BE\nmechanism, without hindering performance or computational complexity. Our\nextensive experiments across various continuous control tasks demonstrate the\neffectiveness of our approaches. We show that RL algorithms equipped with this\nmethod can match or surpass their counterparts, particularly in environments\nwhere estimation biases significantly impact learning. The results underline\nthe importance of bias exploitation in improving policy learning in RL.",
      "tldr_zh": "该论文探讨了连续控制强化学习（RL）中的估计偏差问题，这些偏差会导致次优策略。研究者引入了Bias Exploiting (BE) 机制，结合Deep Double Q-Learning和Actor-Critic方法，动态选择训练过程中最有利的估计偏差，从而优化RL代理的学习过程。该机制可以无缝整合到大多数最先进深度RL算法中，而不增加性能或计算开销。在各种连续控制任务的广泛实验中，配备BE机制的算法表现出色，能够在估计偏差显著影响的环境中匹配或超越基准模型，强调了利用偏差来提升策略学习的重要性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09078v2",
      "published_date": "2024-02-14 10:44:03 UTC",
      "updated_date": "2024-10-11 13:42:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:21:53.450583"
    },
    {
      "arxiv_id": "2402.09066v3",
      "title": "Solid Waste Detection, Monitoring and Mapping in Remote Sensing Images: A Survey",
      "title_zh": "遥感图像中固体废物检测、监测和映射",
      "authors": [
        "Piero Fraternali",
        "Luca Morandini",
        "Sergio Luis Herrera González"
      ],
      "abstract": "The detection and characterization of illegal solid waste disposal sites are\nessential for environmental protection, particularly for mitigating pollution\nand health hazards. Improperly managed landfills contaminate soil and\ngroundwater via rainwater infiltration, posing threats to both animals and\nhumans. Traditional landfill identification approaches, such as on-site\ninspections, are time-consuming and expensive. Remote sensing is a\ncost-effective solution for the identification and monitoring of solid waste\ndisposal sites that enables broad coverage and repeated acquisitions over time.\nEarth Observation (EO) satellites, equipped with an array of sensors and\nimaging capabilities, have been providing high-resolution data for several\ndecades. Researchers proposed specialized techniques that leverage remote\nsensing imagery to perform a range of tasks such as waste site detection,\ndumping site monitoring, and assessment of suitable locations for new\nlandfills. This review aims to provide a detailed illustration of the most\nrelevant proposals for the detection and monitoring of solid waste sites by\ndescribing and comparing the approaches, the implemented techniques, and the\nemployed data. Furthermore, since the data sources are of the utmost importance\nfor developing an effective solid waste detection model, a comprehensive\noverview of the satellites and publicly available data sets is presented.\nFinally, this paper identifies the open issues in the state-of-the-art and\ndiscusses the relevant research directions for reducing the costs and improving\nthe effectiveness of novel solid waste detection methods.",
      "tldr_zh": "本综述论文探讨了利用遥感图像进行固体废物检测、监测和映射的技术，强调了这些方法在环境保护中的重要性，例如缓解污染和健康风险。论文比较了各种基于Earth Observation (EO)卫星的高分辨率数据和传感器技术，用于废物站点识别、监测以及评估新垃圾填埋场位置，并概述了公开可用数据集。最终，它指出了现有方法的开放问题，如成本和有效性挑战，并讨论了未来研究方向，以改进固体废物检测模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09066v3",
      "published_date": "2024-02-14 10:24:04 UTC",
      "updated_date": "2024-12-13 07:26:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:22:06.735810"
    },
    {
      "arxiv_id": "2402.09059v1",
      "title": "I can't see it but I can Fine-tune it: On Encrypted Fine-tuning of Transformers using Fully Homomorphic Encryption",
      "title_zh": "翻译失败",
      "authors": [
        "Prajwal Panzade",
        "Daniel Takabi",
        "Zhipeng Cai"
      ],
      "abstract": "In today's machine learning landscape, fine-tuning pretrained transformer\nmodels has emerged as an essential technique, particularly in scenarios where\naccess to task-aligned training data is limited. However, challenges surface\nwhen data sharing encounters obstacles due to stringent privacy regulations or\nuser apprehension regarding personal information disclosure. Earlier works\nbased on secure multiparty computation (SMC) and fully homomorphic encryption\n(FHE) for privacy-preserving machine learning (PPML) focused more on\nprivacy-preserving inference than privacy-preserving training. In response, we\nintroduce BlindTuner, a privacy-preserving fine-tuning system that enables\ntransformer training exclusively on homomorphically encrypted data for image\nclassification. Our extensive experimentation validates BlindTuner's\neffectiveness by demonstrating comparable accuracy to non-encrypted models.\nNotably, our findings highlight a substantial speed enhancement of 1.5x to 600x\nover previous work in this domain.",
      "tldr_zh": "该论文探讨了在严格隐私法规下对Transformer模型进行Fine-tuning的挑战，提出了一种名为BlindTuner's隐私保护系统，使用Fully Homomorphic Encryption (FHE)来在加密数据上实现图像分类训练。相比以往基于Secure Multiparty Computation (SMC)或FHE的Privacy-Preserving Machine Learning (PPML)方法，该系统更注重训练而非推理。实验结果显示，BlindTuner的准确性与非加密模型相当，同时在速度上比先前工作提升了1.5x到600x，为隐私敏感环境下的模型Fine-tuning提供了高效解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for the presentation at PPAI @The 38th Annual AAAI\n  Conference on Artificial Intelligence 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09059v1",
      "published_date": "2024-02-14 10:15:43 UTC",
      "updated_date": "2024-02-14 10:15:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:22:16.707015"
    },
    {
      "arxiv_id": "2402.09056v3",
      "title": "Is Epistemic Uncertainty Faithfully Represented by Evidential Deep Learning Methods?",
      "title_zh": "证据深度学习方法是否忠实地表示了认识论不确定性？",
      "authors": [
        "Mira Jürgens",
        "Nis Meinert",
        "Viktor Bengs",
        "Eyke Hüllermeier",
        "Willem Waegeman"
      ],
      "abstract": "Trustworthy ML systems should not only return accurate predictions, but also\na reliable representation of their uncertainty. Bayesian methods are commonly\nused to quantify both aleatoric and epistemic uncertainty, but alternative\napproaches, such as evidential deep learning methods, have become popular in\nrecent years. The latter group of methods in essence extends empirical risk\nminimization (ERM) for predicting second-order probability distributions over\noutcomes, from which measures of epistemic (and aleatoric) uncertainty can be\nextracted. This paper presents novel theoretical insights of evidential deep\nlearning, highlighting the difficulties in optimizing second-order loss\nfunctions and interpreting the resulting epistemic uncertainty measures. With a\nsystematic setup that covers a wide range of approaches for classification,\nregression and counts, it provides novel insights into issues of\nidentifiability and convergence in second-order loss minimization, and the\nrelative (rather than absolute) nature of epistemic uncertainty measures.",
      "tldr_zh": "这篇论文探讨了认知不确定性（epistemic uncertainty）是否能被evidential deep learning方法准确表示，强调可信赖的机器学习系统需提供准确预测和可靠不确定性量化。论文比较了Bayesian方法与evidential deep learning方法，后者通过扩展经验风险最小化（ERM）来预测二阶概率分布，从而提取认知不确定性和随机不确定性（aleatoric uncertainty）。研究通过系统设置分析分类、回归和计数任务，揭示了优化二阶损失函数的困难、可识别性和收敛性问题，并指出认知不确定性措施更具相对性而非绝对性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09056v3",
      "published_date": "2024-02-14 10:07:05 UTC",
      "updated_date": "2024-09-09 20:54:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:22:28.328755"
    },
    {
      "arxiv_id": "2402.09055v3",
      "title": "Comment-aided Video-Language Alignment via Contrastive Pre-training for Short-form Video Humor Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Liu",
        "Tongfei Shen",
        "Dong Zhang",
        "Qingying Sun",
        "Shoushan Li",
        "Guodong Zhou"
      ],
      "abstract": "The growing importance of multi-modal humor detection within affective\ncomputing correlates with the expanding influence of short-form video sharing\non social media platforms. In this paper, we propose a novel two-branch\nhierarchical model for short-form video humor detection (SVHD), named\nComment-aided Video-Language Alignment (CVLA) via data-augmented multi-modal\ncontrastive pre-training. Notably, our CVLA not only operates on raw signals\nacross various modal channels but also yields an appropriate multi-modal\nrepresentation by aligning the video and language components within a\nconsistent semantic space. The experimental results on two humor detection\ndatasets, including DY11k and UR-FUNNY, demonstrate that CVLA dramatically\noutperforms state-of-the-art and several competitive baseline approaches. Our\ndataset, code and model release at https://github.com/yliu-cs/CVLA.",
      "tldr_zh": "本研究提出了一种名为 Comment-aided Video-Language Alignment (CVLA) 的两分支层次模型，用于短视频幽默检测 (Short-form Video Humor Detection)。CVLA 通过数据增强的多模态对比预训练 (Contrastive Pre-training) 方法，实现视频和语言组件在统一语义空间中的对齐，同时处理各种模态信号以生成合适的 multi-modal representation。实验结果显示，该模型在 DY11k 和 UR-FUNNY 数据集上大幅优于现有 state-of-the-art 和基线方法，为情感计算中的多模态幽默检测提供了高效解决方案。作者还开源了数据集、代码和模型，以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICMR 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.09055v3",
      "published_date": "2024-02-14 10:05:19 UTC",
      "updated_date": "2024-04-15 03:23:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:22:40.286619"
    },
    {
      "arxiv_id": "2402.09052v1",
      "title": "L3GO: Language Agents with Chain-of-3D-Thoughts for Generating Unconventional Objects",
      "title_zh": "翻译失败",
      "authors": [
        "Yutaro Yamada",
        "Khyathi Chandu",
        "Yuchen Lin",
        "Jack Hessel",
        "Ilker Yildirim",
        "Yejin Choi"
      ],
      "abstract": "Diffusion-based image generation models such as DALL-E 3 and Stable\nDiffusion-XL demonstrate remarkable capabilities in generating images with\nrealistic and unique compositions. Yet, these models are not robust in\nprecisely reasoning about physical and spatial configurations of objects,\nespecially when instructed with unconventional, thereby out-of-distribution\ndescriptions, such as \"a chair with five legs\". In this paper, we propose a\nlanguage agent with chain-of-3D-thoughts (L3GO), an inference-time approach\nthat can reason about part-based 3D mesh generation of unconventional objects\nthat current data-driven diffusion models struggle with. More concretely, we\nuse large language models as agents to compose a desired object via\ntrial-and-error within the 3D simulation environment. To facilitate our\ninvestigation, we develop a new benchmark, Unconventionally Feasible Objects\n(UFO), as well as SimpleBlenv, a wrapper environment built on top of Blender\nwhere language agents can build and compose atomic building blocks via API\ncalls. Human and automatic GPT-4V evaluations show that our approach surpasses\nthe standard GPT-4 and other language agents (e.g., ReAct and Reflexion) for 3D\nmesh generation on ShapeNet. Moreover, when tested on our UFO benchmark, our\napproach outperforms other state-of-the-art text-to-2D image and text-to-3D\nmodels based on human evaluation.",
      "tldr_zh": "本研究提出L3GO，一种基于Chain-of-3D-Thoughts的语言代理方法，用于生成非常规物体，解决扩散模型（如DALL-E 3和Stable Diffusion-XL）在处理物理和空间配置（如“a chair with five legs”）时的不足。L3GO利用大语言模型作为代理，通过试错在3D模拟环境中组合部分网格，实现精确的推理和生成。论文开发了新基准Unconventionally Feasible Objects (UFO)以及基于Blender的SimpleBlenv环境，以评估代理性能。实验结果显示，L3GO在ShapeNet上超越了GPT-4、ReAct和Reflexion等方法，并在UFO基准中通过人类和GPT-4V评估优于现有文本到2D/3D模型的SOTA技术。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09052v1",
      "published_date": "2024-02-14 09:51:05 UTC",
      "updated_date": "2024-02-14 09:51:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:22:53.796845"
    },
    {
      "arxiv_id": "2402.09051v2",
      "title": "FGeo-DRL: Deductive Reasoning for Geometric Problems through Deep Reinforcement Learning",
      "title_zh": "FGeo-D",
      "authors": [
        "Jia Zou",
        "Xiaokai Zhang",
        "Yiming He",
        "Na Zhu",
        "Tuo Leng"
      ],
      "abstract": "The human-like automatic deductive reasoning has always been one of the most\nchallenging open problems in the interdiscipline of mathematics and artificial\nintelligence. This paper is the third in a series of our works. We built a\nneural-symbolic system, called FGeoDRL, to automatically perform human-like\ngeometric deductive reasoning. The neural part is an AI agent based on\nreinforcement learning, capable of autonomously learning problem-solving\nmethods from the feedback of a formalized environment, without the need for\nhuman supervision. It leverages a pre-trained natural language model to\nestablish a policy network for theorem selection and employ Monte Carlo Tree\nSearch for heuristic exploration. The symbolic part is a reinforcement learning\nenvironment based on geometry formalization theory and FormalGeo, which models\nGPS as a Markov Decision Process. In this formal symbolic system, the known\nconditions and objectives of the problem form the state space, while the set of\ntheorems forms the action space. Leveraging FGeoDRL, we have achieved readable\nand verifiable automated solutions to geometric problems. Experiments conducted\non the formalgeo7k dataset have achieved a problem-solving success rate of\n86.40%. The project is available at https://github.com/PersonNoName/FGeoDRL.",
      "tldr_zh": "本研究提出 FGeo-DRL，一种神经符号系统，用于实现人类般的几何问题演绎推理。该系统结合 Deep Reinforcement Learning 的 AI 代理，从形式化环境反馈中自主学习问题解决方法，使用预训练的自然语言模型作为策略网络，并通过 Monte Carlo Tree Search 进行启发式探索。同时，符号部分基于几何形式化理论和 FormalGeo，将几何问题求解建模为 Markov Decision Process，其中状态空间由已知条件和目标组成，动作空间由定理集合构成。在 formalgeo7k 数据集上的实验中，FGeo-DRL 实现了 86.40% 的问题解决成功率，并提供可读性和可验证的自动化解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.09051v2",
      "published_date": "2024-02-14 09:48:39 UTC",
      "updated_date": "2024-02-15 04:50:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:23:04.480956"
    },
    {
      "arxiv_id": "2402.09047v1",
      "title": "FGeo-TP: A Language Model-Enhanced Solver for Geometry Problems",
      "title_zh": "FGeo-TP：一种语言模型增强的几何问题求解器",
      "authors": [
        "Yiming He",
        "Jia Zou",
        "Xiaokai Zhang",
        "Na Zhu",
        "Tuo Leng"
      ],
      "abstract": "The application of contemporary artificial intelligence techniques to address\ngeometric problems and automated deductive proof has always been a grand\nchallenge to the interdiscipline field of mathematics and artificial\nIntelligence. This is the fourth article in a series of our works, in our\nprevious work, we established of a geometric formalized system known as\nFormalGeo. Moreover we annotated approximately 7000 geometric problems, forming\nthe FormalGeo7k dataset. Despite the FGPS (Formal Geometry Problem Solver) can\nachieve interpretable algebraic equation solving and human-like deductive\nreasoning, it often experiences timeouts due to the complexity of the search\nstrategy. In this paper, we introduced FGeo-TP (Theorem Predictor), which\nutilizes the language model to predict theorem sequences for solving geometry\nproblems. We compared the effectiveness of various Transformer architectures,\nsuch as BART or T5, in theorem prediction, implementing pruning in the search\nprocess of FGPS, thereby improving its performance in solving geometry\nproblems. Our results demonstrate a significant increase in the problem-solving\nrate of the language model-enhanced FGeo-TP on the FormalGeo7k dataset, rising\nfrom 39.7% to 80.86%. Furthermore, FGeo-TP exhibits notable reductions in\nsolving time and search steps across problems of varying difficulty levels.",
      "tldr_zh": "本论文提出了 FGeo-TP，一种基于语言模型的几何问题求解器，旨在解决传统 FGPS 系统在搜索策略复杂性导致的超时问题。FGeo-TP 通过利用 Transformer 架构（如 BART 或 T5）来预测定理序列，并在 FGPS 的搜索过程中实施修剪，从而提升问题解决效率。实验结果显示，在 FormalGeo7k 数据集上，问题解决率从 39.7% 显著提高到 80.86%，并减少了解决时间和搜索步骤，为几何问题自动演绎推理提供了更可靠的方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.09047v1",
      "published_date": "2024-02-14 09:44:28 UTC",
      "updated_date": "2024-02-14 09:44:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:23:17.948017"
    },
    {
      "arxiv_id": "2402.09046v1",
      "title": "Inference of Abstraction for a Unified Account of Reasoning and Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Hiroyuki Kido"
      ],
      "abstract": "Inspired by Bayesian approaches to brain function in neuroscience, we give a\nsimple theory of probabilistic inference for a unified account of reasoning and\nlearning. We simply model how data cause symbolic knowledge in terms of its\nsatisfiability in formal logic. The underlying idea is that reasoning is a\nprocess of deriving symbolic knowledge from data via abstraction, i.e.,\nselective ignorance. The logical consequence relation is discussed for its\nproof-based theoretical correctness. The MNIST dataset is discussed for its\nexperiment-based empirical correctness.",
      "tldr_zh": "这篇论文受贝叶斯方法（Bayesian approaches）启发，提出了一种简单的概率推理理论（probabilistic inference），旨在统一解释推理和学习过程。核心机制是将数据通过抽象（abstraction），即选择性忽略，转化为形式逻辑中的符号知识的可满足性（satisfiability）。论文讨论了逻辑后果关系的证明基础理论正确性，并通过 MNIST 数据集的实验验证了其经验正确性。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: substantial text overlap with arXiv:2402.08646",
      "pdf_url": "http://arxiv.org/pdf/2402.09046v1",
      "published_date": "2024-02-14 09:43:35 UTC",
      "updated_date": "2024-02-14 09:43:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:23:28.665745"
    },
    {
      "arxiv_id": "2402.09034v1",
      "title": "Enhancing Sequential Model Performance with Squared Sigmoid TanH (SST) Activation Under Data Constraints",
      "title_zh": "在数据约束下，通过平方 Sigmoid TanH (SST) 激活函数增强序列模型性能",
      "authors": [
        "Barathi Subramanian",
        "Rathinaraja Jeyaraj",
        "Rakhmonov Akhrorjon Akhmadjon Ugli",
        "Jeonghong Kim"
      ],
      "abstract": "Activation functions enable neural networks to learn complex representations\nby introducing non-linearities. While feedforward models commonly use rectified\nlinear units, sequential models like recurrent neural networks, long short-term\nmemory (LSTMs) and gated recurrent units (GRUs) still rely on Sigmoid and TanH\nactivation functions. However, these classical activation functions often\nstruggle to model sparse patterns when trained on small sequential datasets to\neffectively capture temporal dependencies. To address this limitation, we\npropose squared Sigmoid TanH (SST) activation specifically tailored to enhance\nthe learning capability of sequential models under data constraints. SST\napplies mathematical squaring to amplify differences between strong and weak\nactivations as signals propagate over time, facilitating improved gradient flow\nand information filtering. We evaluate SST-powered LSTMs and GRUs for diverse\napplications, such as sign language recognition, regression, and time-series\nclassification tasks, where the dataset is limited. Our experiments demonstrate\nthat SST models consistently outperform RNN-based models with baseline\nactivations, exhibiting improved test accuracy.",
      "tldr_zh": "该论文针对数据有限的顺序模型（如RNN、LSTM和GRU）中，传统Sigmoid和TanH激活函数难以捕捉稀疏模式和时间依赖的问题，提出了一种新型激活函数Squared Sigmoid TanH (SST)。SST通过对Sigmoid和TanH的平方操作放大激活差异，从而改善梯度流动和信息过滤，提升模型的学习能力。在实验中，应用SST增强的LSTM和GRU模型在手语识别、回归以及时间序列分类任务上，表现出比基线模型更高的测试准确率，证明了其在数据约束场景下的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages,9 figures, Submitted to IJCAI 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2402.09034v1",
      "published_date": "2024-02-14 09:20:13 UTC",
      "updated_date": "2024-02-14 09:20:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:23:40.825486"
    },
    {
      "arxiv_id": "2402.09023v1",
      "title": "Review-Incorporated Model-Agnostic Profile Injection Attacks on Recommender Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyi Yang",
        "Lina Yao",
        "Chen Wang",
        "Xiwei Xu",
        "Liming Zhu"
      ],
      "abstract": "Recent studies have shown that recommender systems (RSs) are highly\nvulnerable to data poisoning attacks. Understanding attack tactics helps\nimprove the robustness of RSs. We intend to develop efficient attack methods\nthat use limited resources to generate high-quality fake user profiles to\nachieve 1) transferability among black-box RSs 2) and imperceptibility among\ndetectors. In order to achieve these goals, we introduce textual reviews of\nproducts to enhance the generation quality of the profiles. Specifically, we\npropose a novel attack framework named R-Trojan, which formulates the attack\nobjectives as an optimization problem and adopts a tailored transformer-based\ngenerative adversarial network (GAN) to solve it so that high-quality attack\nprofiles can be produced. Comprehensive experiments on real-world datasets\ndemonstrate that R-Trojan greatly outperforms state-of-the-art attack methods\non various victim RSs under black-box settings and show its good\nimperceptibility.",
      "tldr_zh": "该研究提出了一种名为R-Trojan的攻击框架，针对Recommender Systems的模型无关型配置文件注入攻击，通过整合产品文本评论来生成高质量的假用户配置文件，实现攻击在黑箱系统间的可转移性和对检测器的隐蔽性。框架将攻击目标表述为优化问题，并采用定制的Transformer-based GAN来解决，确保高效生成攻击配置文件。实验结果显示，在真实数据集上，R-Trojan在各种受害Recommender Systems下显著优于现有方法，具有良好的隐蔽性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted by ICDM 2023",
      "pdf_url": "http://arxiv.org/pdf/2402.09023v1",
      "published_date": "2024-02-14 08:56:41 UTC",
      "updated_date": "2024-02-14 08:56:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:23:54.118849"
    },
    {
      "arxiv_id": "2402.09015v3",
      "title": "Towards better Human-Agent Alignment: Assessing Task Utility in LLM-Powered Applications",
      "title_zh": "迈向更好的人类-代理对齐：评估LLM驱动应用程序中的任务效用",
      "authors": [
        "Negar Arabzadeh",
        "Julia Kiseleva",
        "Qingyun Wu",
        "Chi Wang",
        "Ahmed Awadallah",
        "Victor Dibia",
        "Adam Fourney",
        "Charles Clarke"
      ],
      "abstract": "The rapid development in the field of Large Language Models (LLMs) has led to\na surge in applications that facilitate collaboration among multiple agents to\nassist humans in their daily tasks. However, a significant gap remains in\nassessing whether LLM-powered applications genuinely enhance user experience\nand task execution efficiency. This highlights the pressing need for methods to\nverify utility of LLM-powered applications, particularly by ensuring alignment\nbetween the application's functionality and end-user needs. We introduce\nAgentEval provides an implementation for the math problems, a novel framework\ndesigned to simplify the utility verification process by automatically\nproposing a set of criteria tailored to the unique purpose of any given\napplication. This allows for a comprehensive assessment, quantifying the\nutility of an application against the suggested criteria. We present a\ncomprehensive analysis of the robustness of quantifier's work.",
      "tldr_zh": "这篇论文探讨了如何提升人类-代理对齐，重点评估LLM驱动应用的任务效用，以验证这些应用是否真正改善用户体验和任务执行效率。研究引入了AgentEval框架，该框架通过自动提出针对特定应用的评估标准，实现对应用功能的全面量化评估。实验结果显示，该方法在分析量化器(quantifier)的稳健性方面表现出色，为优化LLM-powered应用提供了可靠的工具。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.09015v3",
      "published_date": "2024-02-14 08:46:15 UTC",
      "updated_date": "2024-02-22 23:49:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:24:04.679919"
    },
    {
      "arxiv_id": "2402.08995v1",
      "title": "AgentLens: Visual Analysis for Agent Behaviors in LLM-based Autonomous Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaying Lu",
        "Bo Pan",
        "Jieyi Chen",
        "Yingchaojie Feng",
        "Jingyuan Hu",
        "Yuchen Peng",
        "Wei Chen"
      ],
      "abstract": "Recently, Large Language Model based Autonomous system(LLMAS) has gained\ngreat popularity for its potential to simulate complicated behaviors of human\nsocieties. One of its main challenges is to present and analyze the dynamic\nevents evolution of LLMAS. In this work, we present a visualization approach to\nexplore detailed statuses and agents' behavior within LLMAS. We propose a\ngeneral pipeline that establishes a behavior structure from raw LLMAS execution\nevents, leverages a behavior summarization algorithm to construct a\nhierarchical summary of the entire structure in terms of time sequence, and a\ncause trace method to mine the causal relationship between agent behaviors. We\nthen develop AgentLens, a visual analysis system that leverages a hierarchical\ntemporal visualization for illustrating the evolution of LLMAS, and supports\nusers to interactively investigate details and causes of agents' behaviors. Two\nusage scenarios and a user study demonstrate the effectiveness and usability of\nour AgentLens.",
      "tldr_zh": "该论文介绍了AgentLens，一种用于分析LLM-based Autonomous Systems (LLMAS) 中代理行为的视觉分析系统，旨在解决动态事件演变的呈现挑战。研究提出一个通用管道，包括从原始执行事件构建行为结构、使用行为总结算法生成基于时间序列的层次化摘要，以及采用原因追踪方法挖掘代理行为间的因果关系。AgentLens系统通过层次化时间可视化和交互式调查功能，帮助用户详细探索代理行为的演变和原因。两个使用场景及用户研究验证了AgentLens的有效性和可用性。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08995v1",
      "published_date": "2024-02-14 07:48:16 UTC",
      "updated_date": "2024-02-14 07:48:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:24:18.284381"
    },
    {
      "arxiv_id": "2402.08994v1",
      "title": "CLIP-MUSED: CLIP-Guided Multi-Subject Visual Neural Information Semantic Decoding",
      "title_zh": "翻译失败",
      "authors": [
        "Qiongyi Zhou",
        "Changde Du",
        "Shengpei Wang",
        "Huiguang He"
      ],
      "abstract": "The study of decoding visual neural information faces challenges in\ngeneralizing single-subject decoding models to multiple subjects, due to\nindividual differences. Moreover, the limited availability of data from a\nsingle subject has a constraining impact on model performance. Although prior\nmulti-subject decoding methods have made significant progress, they still\nsuffer from several limitations, including difficulty in extracting global\nneural response features, linear scaling of model parameters with the number of\nsubjects, and inadequate characterization of the relationship between neural\nresponses of different subjects to various stimuli. To overcome these\nlimitations, we propose a CLIP-guided Multi-sUbject visual neural information\nSEmantic Decoding (CLIP-MUSED) method. Our method consists of a\nTransformer-based feature extractor to effectively model global neural\nrepresentations. It also incorporates learnable subject-specific tokens that\nfacilitates the aggregation of multi-subject data without a linear increase of\nparameters. Additionally, we employ representational similarity analysis (RSA)\nto guide token representation learning based on the topological relationship of\nvisual stimuli in the representation space of CLIP, enabling full\ncharacterization of the relationship between neural responses of different\nsubjects under different stimuli. Finally, token representations are used for\nmulti-subject semantic decoding. Our proposed method outperforms single-subject\ndecoding methods and achieves state-of-the-art performance among the existing\nmulti-subject methods on two fMRI datasets. Visualization results provide\ninsights into the effectiveness of our proposed method. Code is available at\nhttps://github.com/CLIP-MUSED/CLIP-MUSED.",
      "tldr_zh": "本研究提出 CLIP-MUSED 方法，用于解决视觉神经信息语义解码的多主体泛化挑战，包括个体差异、数据限制以及现有方法在提取全局神经特征和参数扩展方面的不足。CLIP-MUSED 采用 Transformer-based 特征提取器来建模全局神经表示，并引入 learnable subject-specific tokens，以聚合多主体数据而不导致参数线性增加；同时，利用 Representational Similarity Analysis (RSA) 基于 CLIP 的视觉刺激拓扑关系指导 token 表示学习，从而全面表征不同主体对刺激的神经响应关系。实验结果显示，该方法在两个 fMRI 数据集上优于单主体解码方法，并达到现有多主体方法的 state-of-the-art 性能，可视化分析进一步验证了其有效性。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ICLR2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08994v1",
      "published_date": "2024-02-14 07:41:48 UTC",
      "updated_date": "2024-02-14 07:41:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:24:29.664302"
    },
    {
      "arxiv_id": "2402.08983v4",
      "title": "SafeDecoding: Defending against Jailbreak Attacks via Safety-Aware Decoding",
      "title_zh": "SafeDecoding: 通过安全感知解码防御越狱攻击",
      "authors": [
        "Zhangchen Xu",
        "Fengqing Jiang",
        "Luyao Niu",
        "Jinyuan Jia",
        "Bill Yuchen Lin",
        "Radha Poovendran"
      ],
      "abstract": "As large language models (LLMs) become increasingly integrated into\nreal-world applications such as code generation and chatbot assistance,\nextensive efforts have been made to align LLM behavior with human values,\nincluding safety. Jailbreak attacks, aiming to provoke unintended and unsafe\nbehaviors from LLMs, remain a significant/leading LLM safety threat. In this\npaper, we aim to defend LLMs against jailbreak attacks by introducing\nSafeDecoding, a safety-aware decoding strategy for LLMs to generate helpful and\nharmless responses to user queries. Our insight in developing SafeDecoding is\nbased on the observation that, even though probabilities of tokens representing\nharmful contents outweigh those representing harmless responses, safety\ndisclaimers still appear among the top tokens after sorting tokens by\nprobability in descending order. This allows us to mitigate jailbreak attacks\nby identifying safety disclaimers and amplifying their token probabilities,\nwhile simultaneously attenuating the probabilities of token sequences that are\naligned with the objectives of jailbreak attacks. We perform extensive\nexperiments on five LLMs using six state-of-the-art jailbreak attacks and four\nbenchmark datasets. Our results show that SafeDecoding significantly reduces\nthe attack success rate and harmfulness of jailbreak attacks without\ncompromising the helpfulness of responses to benign user queries. SafeDecoding\noutperforms six defense methods.",
      "tldr_zh": "这篇论文提出了 SafeDecoding，一种基于安全意识解码的安全防御策略，旨在保护大型语言模型 (LLMs) 免受监狱突破攻击 (jailbreak attacks)，从而生成有帮助且无害的响应。SafeDecoding 的方法基于观察，即即使有害内容的 tokens 概率较高，安全免责声明 (safety disclaimers) 仍出现在概率排序的顶部，因此通过放大这些声明的 token 概率并减弱与攻击目标相关的序列概率来缓解攻击。实验结果显示，该策略在五个 LLMs 和六种最先进攻击上显著降低了攻击成功率和有害性，同时不影响对良性查询的帮助性，且优于六种其他防御方法。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08983v4",
      "published_date": "2024-02-14 06:54:31 UTC",
      "updated_date": "2024-07-25 22:59:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:24:43.338721"
    },
    {
      "arxiv_id": "2402.08982v1",
      "title": "MEL: Efficient Multi-Task Evolutionary Learning for High-Dimensional Feature Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Xubin Wang",
        "Haojiong Shangguan",
        "Fengyi Huang",
        "Shangrui Wu",
        "Weijia Jia"
      ],
      "abstract": "Feature selection is a crucial step in data mining to enhance model\nperformance by reducing data dimensionality. However, the increasing\ndimensionality of collected data exacerbates the challenge known as the \"curse\nof dimensionality\", where computation grows exponentially with the number of\ndimensions. To tackle this issue, evolutionary computational (EC) approaches\nhave gained popularity due to their simplicity and applicability.\nUnfortunately, the diverse designs of EC methods result in varying abilities to\nhandle different data, often underutilizing and not sharing information\neffectively. In this paper, we propose a novel approach called PSO-based\nMulti-task Evolutionary Learning (MEL) that leverages multi-task learning to\naddress these challenges. By incorporating information sharing between\ndifferent feature selection tasks, MEL achieves enhanced learning ability and\nefficiency. We evaluate the effectiveness of MEL through extensive experiments\non 22 high-dimensional datasets. Comparing against 24 EC approaches, our method\nexhibits strong competitiveness. Additionally, we have open-sourced our code on\nGitHub at https://github.com/wangxb96/MEL.",
      "tldr_zh": "本论文提出了一种高效的多任务进化学习方法 MEL（Multi-Task Evolutionary Learning），基于粒子群优化（PSO）算法，旨在解决高维度数据特征选择中的“维数灾难”问题。MEL 通过多任务学习机制在不同特征选择任务间共享信息，提升了学习能力和计算效率。与传统进化计算（EC）方法相比，该方法在 22 个高维度数据集上的实验中表现出强竞争力，优于 24 个基准方法。代码已开源在 GitHub，便于进一步研究和应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08982v1",
      "published_date": "2024-02-14 06:51:49 UTC",
      "updated_date": "2024-02-14 06:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:24:55.085034"
    },
    {
      "arxiv_id": "2402.08979v1",
      "title": "Learning-enabled Flexible Job-shop Scheduling for Scalable Smart Manufacturing",
      "title_zh": "学习启用的柔性作业车间调度用于可扩展智能制造",
      "authors": [
        "Sihoon Moon",
        "Sanghoon Lee",
        "Kyung-Joon Park"
      ],
      "abstract": "In smart manufacturing systems (SMSs), flexible job-shop scheduling with\ntransportation constraints (FJSPT) is essential to optimize solutions for\nmaximizing productivity, considering production flexibility based on automated\nguided vehicles (AGVs). Recent developments in deep reinforcement learning\n(DRL)-based methods for FJSPT have encountered a scale generalization\nchallenge. These methods underperform when applied to environment at scales\ndifferent from their training set, resulting in low-quality solutions. To\naddress this, we introduce a novel graph-based DRL method, named the\nHeterogeneous Graph Scheduler (HGS). Our method leverages locally extracted\nrelational knowledge among operations, machines, and vehicle nodes for\nscheduling, with a graph-structured decision-making framework that reduces\nencoding complexity and enhances scale generalization. Our performance\nevaluation, conducted with benchmark datasets, reveals that the proposed method\noutperforms traditional dispatching rules, meta-heuristics, and existing\nDRL-based approaches in terms of makespan performance, even on large-scale\ninstances that have not been experienced during training.",
      "tldr_zh": "这篇论文针对智能制造系统中的柔性作业车间调度问题（FJSPT），提出了一种基于深度强化学习（DRL）的创新方法——Heterogeneous Graph Scheduler (HGS)，以解决现有方法在不同规模环境下的泛化挑战。HGS 通过提取操作、机器和自动引导车辆（AGVs）节点之间的局部关系知识，并采用图结构决策框架，降低了编码复杂性并提升了规模泛化能力。实验结果显示，在基准数据集上，HGS 在完工时间（makespan）性能方面优于传统调度规则、元启发式方法和现有DRL 方法，甚至在训练中未见过的规模实例上表现突出。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08979v1",
      "published_date": "2024-02-14 06:49:23 UTC",
      "updated_date": "2024-02-14 06:49:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:25:07.705554"
    },
    {
      "arxiv_id": "2402.08975v1",
      "title": "Research and application of Transformer based anomaly detection model: A literature review",
      "title_zh": "基于 Transformer 的异常检测模型的研究和应用：文献综述",
      "authors": [
        "Mingrui Ma",
        "Lansheng Han",
        "Chunjie Zhou"
      ],
      "abstract": "Transformer, as one of the most advanced neural network models in Natural\nLanguage Processing (NLP), exhibits diverse applications in the field of\nanomaly detection. To inspire research on Transformer-based anomaly detection,\nthis review offers a fresh perspective on the concept of anomaly detection. We\nexplore the current challenges of anomaly detection and provide detailed\ninsights into the operating principles of Transformer and its variants in\nanomaly detection tasks. Additionally, we delineate various application\nscenarios for Transformer-based anomaly detection models and discuss the\ndatasets and evaluation metrics employed. Furthermore, this review highlights\nthe key challenges in Transformer-based anomaly detection research and conducts\na comprehensive analysis of future research trends in this domain. The review\nincludes an extensive compilation of over 100 core references related to\nTransformer-based anomaly detection. To the best of our knowledge, this is the\nfirst comprehensive review that focuses on the research related to Transformer\nin the context of anomaly detection. We hope that this paper can provide\ndetailed technical information to researchers interested in Transformer-based\nanomaly detection tasks.",
      "tldr_zh": "这篇文献综述探讨了Transformer在异常检测领域的应用，提供了一个新的视角，分析了异常检测的概念、挑战以及Transformer及其变体的运作原理。\n论文详细阐述了Transformer-based模型在各种应用场景中的使用，包括相关数据集、评估指标，并总结了超过100篇核心参考文献。\n作为首个专注于此主题的全面综述，该研究突出了关键挑战和未来趋势，旨在为感兴趣的研究人员提供详细的技术指导和研究灵感。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "77 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2402.08975v1",
      "published_date": "2024-02-14 06:39:54 UTC",
      "updated_date": "2024-02-14 06:39:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:25:17.746468"
    },
    {
      "arxiv_id": "2402.08968v1",
      "title": "GrounDial: Human-norm Grounded Safe Dialog Response Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Siwon Kim",
        "Shuyang Dai",
        "Mohammad Kachuee",
        "Shayan Ray",
        "Tara Taghavi",
        "Sungroh Yoon"
      ],
      "abstract": "Current conversational AI systems based on large language models (LLMs) are\nknown to generate unsafe responses, agreeing to offensive user input or\nincluding toxic content. Previous research aimed to alleviate the toxicity, by\nfine-tuning LLM with manually annotated safe dialogue histories. However, the\ndependency on additional tuning requires substantial costs. To remove the\ndependency, we propose GrounDial, where response safety is achieved by\ngrounding responses to commonsense social rules without requiring fine-tuning.\nA hybrid approach of in-context learning and human-norm-guided decoding of\nGrounDial enables the response to be quantitatively and qualitatively safer\neven without additional data or tuning.",
      "tldr_zh": "该论文针对基于 LLMs 的对话 AI 系统可能生成不安全响应（如同意攻击性输入或包含有毒内容）的问题，提出 GrounDial 方法，通过将响应基于 commonsense social rules（人类规范）来实现安全性，而无需额外微调。GrounDial 采用 in-context learning 和 human-norm-guided decoding 的混合策略，使响应在定量和定性上更安全。实验结果表明，该方法无需额外数据或调优，即可显著提升对话生成的可靠性和安全性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to findings of EACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08968v1",
      "published_date": "2024-02-14 06:25:50 UTC",
      "updated_date": "2024-02-14 06:25:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:25:31.903828"
    },
    {
      "arxiv_id": "2402.08963v1",
      "title": "DUEL: Duplicate Elimination on Active Memory for Self-Supervised Class-Imbalanced Learning",
      "title_zh": "DUEL：基于活跃内存的重复消除，用于自监督类别不平衡学习",
      "authors": [
        "Won-Seok Choi",
        "Hyundo Lee",
        "Dong-Sig Han",
        "Junseok Park",
        "Heeyeon Koo",
        "Byoung-Tak Zhang"
      ],
      "abstract": "Recent machine learning algorithms have been developed using well-curated\ndatasets, which often require substantial cost and resources. On the other\nhand, the direct use of raw data often leads to overfitting towards frequently\noccurring class information. To address class imbalances cost-efficiently, we\npropose an active data filtering process during self-supervised pre-training in\nour novel framework, Duplicate Elimination (DUEL). This framework integrates an\nactive memory inspired by human working memory and introduces distinctiveness\ninformation, which measures the diversity of the data in the memory, to\noptimize both the feature extractor and the memory. The DUEL policy, which\nreplaces the most duplicated data with new samples, aims to enhance the\ndistinctiveness information in the memory and thereby mitigate class\nimbalances. We validate the effectiveness of the DUEL framework in\nclass-imbalanced environments, demonstrating its robustness and providing\nreliable results in downstream tasks. We also analyze the role of the DUEL\npolicy in the training process through various metrics and visualizations.",
      "tldr_zh": "这篇论文提出了 DUEL 框架，用于在 self-supervised learning 中处理类别不平衡问题，通过主动数据过滤过程来避免模型过度拟合常见类别。DUEL 整合了基于人类工作记忆的 active memory，并引入 distinctiveness information 来衡量和优化内存中数据的多样性，其核心策略是替换最重复的数据以提升数据多样性。实验验证显示，DUEL 在类别不平衡环境中表现出色，提高了下游任务的鲁棒性和可靠性，并通过各种指标和可视化分析了其在训练过程中的作用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a full paper at AAAI 2024: The 38th Annual AAAI\n  Conference on Artificial Intelligence (Main Tech Track). 7 pages (main\n  paper), 2 pages (references), 11 pages (appendix) each",
      "pdf_url": "http://arxiv.org/pdf/2402.08963v1",
      "published_date": "2024-02-14 06:09:36 UTC",
      "updated_date": "2024-02-14 06:09:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:25:43.378081"
    },
    {
      "arxiv_id": "2402.08961v3",
      "title": "HyCubE: Efficient Knowledge Hypergraph 3D Circular Convolutional Embedding",
      "title_zh": "翻译失败",
      "authors": [
        "Zhao Li",
        "Xin Wang",
        "Jun Zhao",
        "Wenbin Guo",
        "Jianxin Li"
      ],
      "abstract": "Knowledge hypergraph embedding models are usually computationally expensive\ndue to the inherent complex semantic information. However, existing works\nmainly focus on improving the effectiveness of knowledge hypergraph embedding,\nmaking the model architecture more complex and redundant. It is desirable and\nchallenging for knowledge hypergraph embedding to reach a trade-off between\nmodel effectiveness and efficiency. In this paper, we propose an end-to-end\nefficient knowledge hypergraph embedding model, HyCubE, which designs a novel\n3D circular convolutional neural network and the alternate mask stack strategy\nto enhance the interaction and extraction of feature information\ncomprehensively. Furthermore, our proposed model achieves a better trade-off\nbetween effectiveness and efficiency by adaptively adjusting the 3D circular\nconvolutional layer structure to handle n-ary knowledge tuples of different\narities with fewer parameters. In addition, we use a knowledge hypergraph 1-N\nmultilinear scoring way to accelerate the model training efficiency further.\nFinally, extensive experimental results on all datasets demonstrate that our\nproposed model consistently outperforms state-of-the-art baselines, with an\naverage improvement of 8.22% and a maximum improvement of 33.82% across all\nmetrics. Meanwhile, HyCubE is 6.12x faster, GPU memory usage is 52.67% lower,\nand the number of parameters is reduced by 85.21% compared with the average\nmetric of the latest state-of-the-art baselines.",
      "tldr_zh": "该论文提出 HyCubE，一种高效的知识超图嵌入模型，旨在解决现有模型计算开销大和架构冗余的问题，通过引入新型 3D Circular Convolutional Neural Network 和交替掩码堆栈策略来全面增强特征信息的交互与提取。HyCubE 还采用自适应调整 3D 循环卷积层结构处理不同元组的 n-ary 知识元组，并使用知识超图 1-N 多线性评分方式加速训练，进一步减少参数数量。实验结果显示，HyCubE 在所有数据集上优于最先进基线，平均提升 8.22%，速度快 6.12 倍，同时 GPU 内存使用降低 52.67% 和参数减少 85.21%。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.08961v3",
      "published_date": "2024-02-14 06:05:37 UTC",
      "updated_date": "2024-11-04 09:13:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:25:55.699557"
    },
    {
      "arxiv_id": "2402.08960v2",
      "title": "Open-Vocabulary Segmentation with Unpaired Mask-Text Supervision",
      "title_zh": "开放词汇分割的未配对掩码-文本监督",
      "authors": [
        "Zhaoqing Wang",
        "Xiaobo Xia",
        "Ziye Chen",
        "Xiao He",
        "Yandong Guo",
        "Mingming Gong",
        "Tongliang Liu"
      ],
      "abstract": "Current state-of-the-art open-vocabulary segmentation methods typically rely\non image-mask-text triplet annotations for supervision. However, acquiring such\ndetailed annotations is labour-intensive and poses scalability challenges in\ncomplex real-world scenarios. While existing weakly-supervised approaches\nleverage image-text pairs to reduce the expansive annotation cost, the lack of\nmask supervision makes it difficult for the model to locate multiple instances\nand accurately group pixels with similar semantics, significantly hampering\nversatility and performance. In this paper, we introduce Unpair-Seg, a novel\nweakly-supervised open-vocabulary segmentation framework that learns from\nunpaired image-mask and image-text pairs, which can be independently and\nefficiently collected. Unpair-Seg initially predicts a set of binary masks and\ngenerates pseudo labels by identifying confident pairs of masks and text\nentities. We then train a feature adapter to align region embeddings with text\nembeddings based on these pseudo labels, achieving open-vocabulary\nsegmentation. However, the inherent noise in the mask-entity correspondence\nposes a challenge to obtaining reliable pairs. To address this, we employ a\nvision-language large model to re-caption the input images and extract precise\nentities, and we design a multi-scale matching strategy to reduce noisy\nmask-entity pairs. Our Unpair-Seg framework demonstrates impressive\nperformance, achieving 14.6\\% and 19.5\\% mIoU on the ADE-847 and PASCAL\nContext-459 datasets, significantly narrowing the gap between fully-supervised\nand weakly-supervised methods.",
      "tldr_zh": "该论文提出了一种名为 Unpair-Seg 的弱监督开源词汇分割框架，使用未配对的图像-掩码和图像-文本对进行训练，以减少传统方法依赖图像-掩码-文本三元组注释的劳动密集型问题。框架首先预测二进制掩码并通过识别置信的掩码-文本实体对生成伪标签，然后训练特征适配器来对齐区域嵌入和文本嵌入，实现高效的开源词汇分割。为解决掩码-实体对应中的噪声，该方法利用视觉-语言大模型重新标注图像并采用多尺度匹配策略优化伪标签。实验结果显示，Unpair-Seg 在 ADE-847 和 PASCAL Context-459 数据集上分别达到 14.6% 和 19.5% mIoU，显著缩小了全监督和弱监督方法之间的性能差距。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "27 pages, 18 figures, 10 tables",
      "pdf_url": "http://arxiv.org/pdf/2402.08960v2",
      "published_date": "2024-02-14 06:01:44 UTC",
      "updated_date": "2024-06-11 17:01:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:26:07.686590"
    },
    {
      "arxiv_id": "2402.08958v3",
      "title": "Towards Next-Level Post-Training Quantization of Hyper-Scale Transformers",
      "title_zh": "翻译失败",
      "authors": [
        "Junhan Kim",
        "Chungman Lee",
        "Eulrang Cho",
        "Kyungphil Park",
        "Ho-young Kim",
        "Joonyoung Kim",
        "Yongkweon Jeon"
      ],
      "abstract": "With the increasing complexity of generative AI models, post-training\nquantization (PTQ) has emerged as a promising solution for deploying\nhyper-scale models on edge devices such as mobile and TVs. Existing PTQ\nschemes, however, consume considerable time and resources, which could be a\nbottleneck in real situations where frequent model updates and multiple\nhyperparameter tunings are required. As a cost-effective alternative,\nlearning-free PTQ schemes have been proposed. However, the performance is\nsomewhat limited because they cannot consider the inter-layer dependency within\nthe attention module, which is a significant feature of Transformers. In this\npaper, we thus propose a novel PTQ algorithm that balances accuracy and\nefficiency. The key idea of the proposed algorithm called aespa is to perform\nquantization layer-wise for efficiency while targeting attention-wise\nreconstruction to consider the cross-layer dependency. Through extensive\nexperiments on various language models and complexity analysis, we demonstrate\nthat aespa is accurate and efficient in quantizing Transformer models.",
      "tldr_zh": "随着生成式 AI 模型的复杂性增加，后训练量化 (PTQ) 被视为部署超大规模 Transformer 模型于边缘设备的关键方案，但现有方法耗时资源大，且无法有效处理注意力模块的跨层依赖 (inter-layer dependency)。本文提出了一种新型 PTQ 算法 aespa，它通过层级量化 (layer-wise quantization) 提升效率，同时采用注意力机制重建 (attention-wise reconstruction) 来平衡准确性和跨层依赖问题。在各种语言模型上的广泛实验和复杂性分析中，aespa 展示了显著的准确性和高效性表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2402.08958v3",
      "published_date": "2024-02-14 05:58:43 UTC",
      "updated_date": "2024-11-05 08:04:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:26:18.669882"
    },
    {
      "arxiv_id": "2402.08957v3",
      "title": "MUSTARD: Mastering Uniform Synthesis of Theorem and Proof Data",
      "title_zh": "翻译失败",
      "authors": [
        "Yinya Huang",
        "Xiaohan Lin",
        "Zhengying Liu",
        "Qingxing Cao",
        "Huajian Xin",
        "Haiming Wang",
        "Zhenguo Li",
        "Linqi Song",
        "Xiaodan Liang"
      ],
      "abstract": "Recent large language models (LLMs) have witnessed significant advancement in\nvarious tasks, including mathematical reasoning and theorem proving. As these\ntwo tasks require strict and formal multi-step inference, they are appealing\ndomains for exploring the reasoning ability of LLMs but still face important\nchallenges. Previous studies such as Chain-of-Thought (CoT) have revealed the\neffectiveness of intermediate steps guidance. However, such step-wise\nannotation requires heavy labor, leading to insufficient training steps for\ncurrent benchmarks. To fill this gap, this work introduces MUSTARD, a data\ngeneration framework that masters uniform synthesis of theorem and proof data\nof high quality and diversity. MUSTARD synthesizes data in three stages: (1) It\nsamples a few mathematical concept seeds as the problem category. (2) Then, it\nprompts a generative language model with the sampled concepts to obtain both\nthe problems and their step-wise formal solutions. (3) Lastly, the framework\nutilizes a proof assistant (e.g., Lean Prover) to filter the valid proofs. With\nthe proposed MUSTARD, we present a theorem-and-proof benchmark MUSTARDSAUCE\nwith 5,866 valid data points. Each data point contains an informal statement,\nan informal proof, and a translated formal proof that passes the prover\nvalidation. We perform extensive analysis and demonstrate that MUSTARD\ngenerates validated high-quality step-by-step data. We further apply the\nMUSTARDSAUCE for fine-tuning smaller language models. The fine-tuned Llama 2-7B\nachieves a 15.41% average relative performance gain in automated theorem\nproving, and 8.18% in math word problems. Codes and data are available at\nhttps://github.com/Eleanor-H/MUSTARD.",
      "tldr_zh": "这篇论文引入了 MUSTARD 框架，用于高效合成高质量、多样化的定理和证明数据，以解决大型语言模型 (LLMs) 在数学推理和定理证明任务中面临的数据不足问题。MUSTARD 通过三阶段过程实现：首先采样数学概念种子作为问题类别，其次使用生成语言模型创建问题及其逐步正式解决方案，最后利用证明助手如 Lean Prover 过滤有效证明。基于此框架，论文构建了 MUSTARDSAUCE 基准数据集，包含 5,866 个有效数据点，每条包括非正式陈述、非正式证明和翻译的正式证明。实验结果显示，使用该数据集微调 Llama 2-7B 模型，在自动定理证明任务中提升了 15.41% 的性能，在数学文字问题上提升了 8.18%。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.FL",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08957v3",
      "published_date": "2024-02-14 05:57:58 UTC",
      "updated_date": "2024-05-23 03:13:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:26:32.143518"
    },
    {
      "arxiv_id": "2402.08955v1",
      "title": "Using Counterfactual Tasks to Evaluate the Generality of Analogical Reasoning in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Martha Lewis",
        "Melanie Mitchell"
      ],
      "abstract": "Large language models (LLMs) have performed well on several reasoning\nbenchmarks, including ones that test analogical reasoning abilities. However,\nit has been debated whether they are actually performing humanlike abstract\nreasoning or instead employing less general processes that rely on similarity\nto what has been seen in their training data. Here we investigate the\ngenerality of analogy-making abilities previously claimed for LLMs (Webb,\nHolyoak, & Lu, 2023). We take one set of analogy problems used to evaluate LLMs\nand create a set of \"counterfactual\" variants-versions that test the same\nabstract reasoning abilities but that are likely dissimilar from any\npre-training data. We test humans and three GPT models on both the original and\ncounterfactual problems, and show that, while the performance of humans remains\nhigh for all the problems, the GPT models' performance declines sharply on the\ncounterfactual set. This work provides evidence that, despite previously\nreported successes of LLMs on analogical reasoning, these models lack the\nrobustness and generality of human analogy-making.",
      "tldr_zh": "这篇论文使用“counterfactual tasks”来评估 Large Language Models (LLMs) 在类比推理（analogical reasoning）方面的普遍性，旨在检验 LLMs 是否进行真正的人类-like 抽象推理，还是依赖训练数据的相似性。研究者基于先前类比问题创建了与预训练数据可能不类似的变体任务，并比较人类和三个 GPT 模型的表现。结果显示，人类在原问题和 counterfactual 问题上均保持高性能，而 GPT 模型在 counterfactual 任务上的准确率急剧下降。该研究提供了证据，表明尽管 LLMs 在某些基准上表现出色，但它们缺乏人类类比推理的鲁棒性和一般性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08955v1",
      "published_date": "2024-02-14 05:52:23 UTC",
      "updated_date": "2024-02-14 05:52:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:26:45.733746"
    },
    {
      "arxiv_id": "2402.08939v3",
      "title": "Premise Order Matters in Reasoning with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyun Chen",
        "Ryan A. Chi",
        "Xuezhi Wang",
        "Denny Zhou"
      ],
      "abstract": "Large language models (LLMs) have accomplished remarkable reasoning\nperformance in various domains. However, in the domain of reasoning tasks, we\ndiscover a frailty: LLMs are surprisingly brittle to the ordering of the\npremises, despite the fact that such ordering does not alter the underlying\ntask. In particular, we observe that LLMs achieve the best performance when the\npremise order aligns with the context required in intermediate reasoning steps.\nFor example, in deductive reasoning tasks, presenting the premises in the same\norder as the ground truth proof in the prompt (as opposed to random ordering)\ndrastically increases the model's accuracy. We first examine the effect of\npremise ordering on deductive reasoning on a variety of LLMs, and our\nevaluation shows that permuting the premise order can cause a performance drop\nof over 30%. In addition, we release the benchmark R-GSM, based on GSM8K, to\nexamine the ordering effect for mathematical problem-solving, and we again\nobserve a significant drop in accuracy, relative to the original GSM8K\nbenchmark.",
      "tldr_zh": "该研究发现大型语言模型 (LLMs) 在推理任务中对前提顺序高度敏感，即使顺序改变不影响任务本质，导致性能显著下降。论文通过评估多种 LLMs 在演绎推理任务中的表现，表明当前提顺序与真实证明步骤一致时，准确率最高，而随机顺序可导致准确率下降超过30%。此外，他们发布了基于 GSM8K 的新基准 R-GSM，用于数学问题求解实验，并观察到类似准确率显著下降，这揭示了 LLMs 的脆弱性并为模型改进提供重要见解。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at ICML 2024. Xinyun and Ryan contribute equally",
      "pdf_url": "http://arxiv.org/pdf/2402.08939v3",
      "published_date": "2024-02-14 04:50:18 UTC",
      "updated_date": "2024-05-28 04:32:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:26:57.482787"
    },
    {
      "arxiv_id": "2402.08925v2",
      "title": "MaxMin-RLHF: Alignment with Diverse Human Preferences",
      "title_zh": "翻译失败",
      "authors": [
        "Souradip Chakraborty",
        "Jiahao Qiu",
        "Hui Yuan",
        "Alec Koppel",
        "Furong Huang",
        "Dinesh Manocha",
        "Amrit Singh Bedi",
        "Mengdi Wang"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) aligns language models to\nhuman preferences by employing a singular reward model derived from preference\ndata. However, such an approach overlooks the rich diversity of human\npreferences inherent in data collected from multiple users. In this work, we\nfirst derive an impossibility result of alignment with single reward RLHF,\nthereby highlighting its insufficiency in representing diverse human\npreferences. To provide an equitable solution to the problem, we learn a\nmixture of preference distributions via an expectation-maximization algorithm\nand propose a MaxMin alignment objective for policy learning inspired by the\nEgalitarian principle in social choice theory to better represent diverse human\npreferences. We elucidate the connection of our proposed approach to\ndistributionally robust optimization and general utility RL, thereby\nhighlighting the generality and robustness of our proposed solution. We present\ncomprehensive experimental results on small-scale (GPT-2) and large-scale\nlanguage models (with Tulu2-7B) and show the efficacy of the proposed approach\nin the presence of diversity among human preferences. Our algorithm achieves an\naverage improvement of more than 16% in win-rates over conventional RLHF\nalgorithms and improves the win-rate (accuracy) for minority groups by over 33%\nwithout compromising the performance of majority groups, showcasing the\nrobustness and fairness of our approach. We remark that our findings in this\nwork are not only limited to language models but also extend to reinforcement\nlearning in general.",
      "tldr_zh": "本文指出，传统 Reinforcement Learning from Human Feedback (RLHF) 使用单一奖励模型无法充分代表人类偏好的多样性，并通过一个 impossibility result 证明了其不足。作者提出一种新方法，包括使用 expectation-maximization algorithm 学习偏好分布的混合，并引入 MaxMin alignment objective 受 Egalitarian principle 启发，以优化政策学习并提升公平性。实验在 GPT-2 和 Tulu2-7B 语言模型上显示，该方法比传统 RLHF 平均胜率提高超过 16%，并为少数群体提升胜率（准确率）超过 33%，而不影响多数群体的性能。该方法的应用不仅限于语言模型，还扩展到一般强化学习领域。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08925v2",
      "published_date": "2024-02-14 03:56:27 UTC",
      "updated_date": "2024-12-26 00:15:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:27:10.100834"
    },
    {
      "arxiv_id": "2402.08921v1",
      "title": "Enhancing ID and Text Fusion via Alternative Training in Session-based Recommendation",
      "title_zh": "在基于会话推荐中，通过备选训练增强 ID 和文本融合",
      "authors": [
        "Juanhui Li",
        "Haoyu Han",
        "Zhikai Chen",
        "Harry Shomer",
        "Wei Jin",
        "Amin Javari",
        "Jiliang Tang"
      ],
      "abstract": "Session-based recommendation has gained increasing attention in recent years,\nwith its aim to offer tailored suggestions based on users' historical behaviors\nwithin sessions.\n  To advance this field, a variety of methods have been developed, with\nID-based approaches typically demonstrating promising performance. However,\nthese methods often face challenges with long-tail items and overlook other\nrich forms of information, notably valuable textual semantic information. To\nintegrate text information, various methods have been introduced, mostly\nfollowing a naive fusion framework. Surprisingly, we observe that fusing these\ntwo modalities does not consistently outperform the best single modality by\nfollowing the naive fusion framework. Further investigation reveals an\npotential imbalance issue in naive fusion, where the ID dominates and text\nmodality is undertrained. This suggests that the unexpected observation may\nstem from naive fusion's failure to effectively balance the two modalities,\noften over-relying on the stronger ID modality. This insight suggests that\nnaive fusion might not be as effective in combining ID and text as previously\nexpected. To address this, we propose a novel alternative training strategy\nAlterRec. It separates the training of ID and text, thereby avoiding the\nimbalance issue seen in naive fusion. Additionally, AlterRec designs a novel\nstrategy to facilitate the interaction between the two modalities, enabling\nthem to mutually learn from each other and integrate the text more effectively.\nComprehensive experiments demonstrate the effectiveness of AlterRec in\nsession-based recommendation. The implementation is available at\nhttps://github.com/Juanhui28/AlterRec.",
      "tldr_zh": "本研究针对基于会话的推荐（Session-based Recommendation）系统，探讨了 ID 和文本模态融合的挑战，指出传统 naive fusion 方法由于 ID 模态主导导致文本模态训练不足，从而无法有效提升性能。针对这一不平衡问题，作者提出了一种新型策略 AlterRec，通过交替训练 ID 和文本模态，并设计模态间交互机制，使两者相互学习并更好地整合文本信息。实验结果显示，AlterRec 在会话推荐任务中显著提高了推荐准确性，并提供了开源实现（https://github.com/Juanhui28/AlterRec）。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08921v1",
      "published_date": "2024-02-14 03:41:50 UTC",
      "updated_date": "2024-02-14 03:41:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:27:20.117148"
    },
    {
      "arxiv_id": "2402.08918v3",
      "title": "SimMLP: Training MLPs on Graphs without Supervision",
      "title_zh": "翻译失败",
      "authors": [
        "Zehong Wang",
        "Zheyuan Zhang",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "Graph Neural Networks (GNNs) have demonstrated their effectiveness in various\ngraph learning tasks, yet their reliance on neighborhood aggregation during\ninference poses challenges for deployment in latency-sensitive applications,\nsuch as real-time financial fraud detection. To address this limitation, recent\nstudies have proposed distilling knowledge from teacher GNNs into student\nMulti-Layer Perceptrons (MLPs) trained on node content, aiming to accelerate\ninference. However, these approaches often inadequately explore structural\ninformation when inferring unseen nodes. To this end, we introduce SimMLP, a\nSelf-supervised framework for learning MLPs on graphs, designed to fully\nintegrate rich structural information into MLPs. Notably, SimMLP is the first\nMLP-learning method that can achieve equivalence to GNNs in the optimal case.\nThe key idea is to employ self-supervised learning to align the representations\nencoded by graph context-aware GNNs and neighborhood dependency-free MLPs,\nthereby fully integrating the structural information into MLPs. We provide a\ncomprehensive theoretical analysis, demonstrating the equivalence between\nSimMLP and GNNs based on mutual information and inductive bias, highlighting\nSimMLP's advanced structural learning capabilities. Additionally, we conduct\nextensive experiments on 20 benchmark datasets, covering node classification,\nlink prediction, and graph classification, to showcase SimMLP's superiority\nover state-of-the-art baselines, particularly in scenarios involving unseen\nnodes (e.g., inductive and cold-start node classification) where structural\ninsights are crucial. Our codes are available at:\nhttps://github.com/Zehong-Wang/SimMLP.",
      "tldr_zh": "这篇论文提出 SimMLP，一种自监督框架，用于在图上训练 Multi-Layer Perceptrons (MLPs)，以解决 Graph Neural Networks (GNNs) 在延迟敏感应用（如实时金融欺诈检测）中依赖邻居聚合的部署难题。SimMLP 通过自监督学习对齐 GNNs 和 MLPs 的表示，从而充分整合图的结构信息，并在最优情况下实现与 GNNs 的等效。论文提供全面理论分析，基于互信息和归纳偏差，证明了 SimMLP 的高级结构学习能力。在 20 个基准数据集上的实验显示，SimMLP 在节点分类、链接预测和图分类任务中优于现有基线，尤其在处理未见节点（如归纳和冷启动场景）时表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "New Version: arXiv:2412.03864",
      "pdf_url": "http://arxiv.org/pdf/2402.08918v3",
      "published_date": "2024-02-14 03:16:13 UTC",
      "updated_date": "2024-12-06 02:46:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:27:34.650550"
    },
    {
      "arxiv_id": "2402.08907v2",
      "title": "Subgraph Pooling: Tackling Negative Transfer on Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Zehong Wang",
        "Zheyuan Zhang",
        "Chuxu Zhang",
        "Yanfang Ye"
      ],
      "abstract": "Transfer learning aims to enhance performance on a target task by using\nknowledge from related tasks. However, when the source and target tasks are not\nclosely aligned, it can lead to reduced performance, known as negative\ntransfer. Unlike in image or text data, we find that negative transfer could\ncommonly occur in graph-structured data, even when source and target graphs\nhave semantic similarities. Specifically, we identify that structural\ndifferences significantly amplify the dissimilarities in the node embeddings\nacross graphs. To mitigate this, we bring a new insight in this paper: for\nsemantically similar graphs, although structural differences lead to\nsignificant distribution shift in node embeddings, their impact on subgraph\nembeddings could be marginal. Building on this insight, we introduce Subgraph\nPooling (SP) by aggregating nodes sampled from a k-hop neighborhood and\nSubgraph Pooling++ (SP++) by a random walk, to mitigate the impact of graph\nstructural differences on knowledge transfer. We theoretically analyze the role\nof SP in reducing graph discrepancy and conduct extensive experiments to\nevaluate its superiority under various settings. The proposed SP methods are\neffective yet elegant, which can be easily applied on top of any backbone Graph\nNeural Networks (GNNs). Our code and data are available at:\nhttps://github.com/Zehong-Wang/Subgraph-Pooling.",
      "tldr_zh": "该论文探讨了转移学习（Transfer learning）在图结构数据中的问题，指出即使源图和目标图语义相似，结构差异也可能导致负迁移（negative transfer），从而影响节点嵌入的分布。作者发现子图嵌入对结构差异的敏感性较低，并据此提出 Subgraph Pooling (SP) 方法，通过聚合 k-hop 邻域的节点，以及 Subgraph Pooling++ (SP++) 方法，使用随机游走来缓解知识转移中的图差异影响。实验结果显示，SP 方法在各种设置下显著提升了性能，并通过理论分析证明其在减少图差异方面的有效性，可轻松应用于任何 Graph Neural Networks (GNNs)。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by IJCAI 24",
      "pdf_url": "http://arxiv.org/pdf/2402.08907v2",
      "published_date": "2024-02-14 02:46:47 UTC",
      "updated_date": "2024-05-04 19:41:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:27:45.160785"
    },
    {
      "arxiv_id": "2402.08876v2",
      "title": "DUDF: Differentiable Unsigned Distance Fields with Hyperbolic Scaling",
      "title_zh": "翻译失败",
      "authors": [
        "Miguel Fainstein",
        "Viviana Siless",
        "Emmanuel Iarussi"
      ],
      "abstract": "In recent years, there has been a growing interest in training Neural\nNetworks to approximate Unsigned Distance Fields (UDFs) for representing open\nsurfaces in the context of 3D reconstruction. However, UDFs are\nnon-differentiable at the zero level set which leads to significant errors in\ndistances and gradients, generally resulting in fragmented and discontinuous\nsurfaces. In this paper, we propose to learn a hyperbolic scaling of the\nunsigned distance field, which defines a new Eikonal problem with distinct\nboundary conditions. This allows our formulation to integrate seamlessly with\nstate-of-the-art continuously differentiable implicit neural representation\nnetworks, largely applied in the literature to represent signed distance\nfields. Our approach not only addresses the challenge of open surface\nrepresentation but also demonstrates significant improvement in reconstruction\nquality and training performance. Moreover, the unlocked field's\ndifferentiability allows the accurate computation of essential topological\nproperties such as normal directions and curvatures, pervasive in downstream\ntasks such as rendering. Through extensive experiments, we validate our\napproach across various data sets and against competitive baselines. The\nresults demonstrate enhanced accuracy and up to an order of magnitude increase\nin speed compared to previous methods.",
      "tldr_zh": "本文提出 DUDF，一种通过 Hyperbolic Scaling 来学习 Differentiable Unsigned Distance Fields (UDFs) 的方法，旨在解决 UDFs 在零水平集处不可微导致的表面重建错误问题。 该方法定义了一个新的 Eikonal problem 和边界条件，能够无缝整合到现有的 Implicit Neural Representation Networks 中，用于开放表面表示，并显著提升重建质量、训练性能和拓扑属性计算（如 Normal Directions 和 Curvatures）。 通过广泛实验验证，DUDF 在各种数据集上比竞争基线模型提高了准确性，并实现了高达一个数量级的速度提升。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "I.2.10; I.4.10; I.3.7"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08876v2",
      "published_date": "2024-02-14 00:42:19 UTC",
      "updated_date": "2024-06-02 14:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:28:00.100732"
    },
    {
      "arxiv_id": "2402.08869v1",
      "title": "ScamSpot: Fighting Financial Fraud in Instagram Comments",
      "title_zh": "ScamSpot：在 Instagram 评论中打击金融欺诈",
      "authors": [
        "Stefan Erben",
        "Andreas Waldis"
      ],
      "abstract": "The long-standing problem of spam and fraudulent messages in the comment\nsections of Instagram pages in the financial sector claims new victims every\nday. Instagram's current spam filter proves inadequate, and existing research\napproaches are primarily confined to theoretical concepts. Practical\nimplementations with evaluated results are missing. To solve this problem, we\npropose ScamSpot, a comprehensive system that includes a browser extension, a\nfine-tuned BERT model and a REST API. This approach ensures public\naccessibility of our results for Instagram users using the Chrome browser.\nFurthermore, we conduct a data annotation study, shedding light on the reasons\nand causes of the problem and evaluate the system through user feedback and\ncomparison with existing models. ScamSpot is an open-source project and is\npublicly available at https://scamspot.github.io/.",
      "tldr_zh": "本研究针对Instagram金融页面评论中的垃圾和欺诈问题，提出ScamSpot系统，以填补现有过滤器和研究的实际应用空白。ScamSpot包括浏览器扩展、fine-tuned BERT model和REST API，确保Chrome用户能够轻松访问和使用。研究还开展了数据标注研究，以分析问题成因，并通过用户反馈和与其他模型的比较来评估系统性能。作为开源项目，ScamSpot已在https://scamspot.github.io/公开可用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "EACL 2024 Demo Paper, 11 pages",
      "pdf_url": "http://arxiv.org/pdf/2402.08869v1",
      "published_date": "2024-02-14 00:30:18 UTC",
      "updated_date": "2024-02-14 00:30:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:28:08.980092"
    },
    {
      "arxiv_id": "2402.08859v1",
      "title": "Large Language Model with Graph Convolution for Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yingpeng Du",
        "Ziyan Wang",
        "Zhu Sun",
        "Haoyan Chua",
        "Hongzhi Liu",
        "Zhonghai Wu",
        "Yining Ma",
        "Jie Zhang",
        "Youchen Sun"
      ],
      "abstract": "In recent years, efforts have been made to use text information for better\nuser profiling and item characterization in recommendations. However, text\ninformation can sometimes be of low quality, hindering its effectiveness for\nreal-world applications. With knowledge and reasoning capabilities capsuled in\nLarge Language Models (LLMs), utilizing LLMs emerges as a promising way for\ndescription improvement. However, existing ways of prompting LLMs with raw\ntexts ignore structured knowledge of user-item interactions, which may lead to\nhallucination problems like inconsistent description generation. To this end,\nwe propose a Graph-aware Convolutional LLM method to elicit LLMs to capture\nhigh-order relations in the user-item graph. To adapt text-based LLMs with\nstructured graphs, We use the LLM as an aggregator in graph processing,\nallowing it to understand graph-based information step by step. Specifically,\nthe LLM is required for description enhancement by exploring multi-hop\nneighbors layer by layer, thereby propagating information progressively in the\ngraph. To enable LLMs to capture large-scale graph information, we break down\nthe description task into smaller parts, which drastically reduces the context\nlength of the token input with each step. Extensive experiments on three\nreal-world datasets show that our method consistently outperforms\nstate-of-the-art methods.",
      "tldr_zh": "该论文提出了一种Graph-aware Convolutional LLM方法，将大型语言模型(LLMs)与图卷积相结合，用于提升推荐系统的用户画像和物品特征描述，以解决文本信息质量低和幻觉问题。该方法将LLMs用作图处理中的聚合器，通过逐步探索多跳邻居并层级化传播信息，来捕获用户-物品图中的高阶关系，同时通过任务分解减少上下文长度以处理大规模图数据。在三个真实数据集上的广泛实验表明，该方法 consistently outperforms 现有的最先进方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2402.08859v1",
      "published_date": "2024-02-14 00:04:33 UTC",
      "updated_date": "2024-02-14 00:04:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T06:28:20.594958"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 119,
  "processed_papers_count": 119,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T06:28:47.066139"
}