{
  "date": "2024-05-31",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-31 的 arXiv 中文 TLDR 快报！\n\n今天的 arXiv 论文主要聚焦 AI 模型的安全性、优化和应用领域，包括 LLM 的偏置缓解、检索增强生成（RAG）的企业挑战、扩散模型的生物和视频应用，以及医疗 AI 的解释性研究。其中，LLM 在喜剧创作和卫星调度的探索令人印象深刻，而知名学者如 Pietro Lio 的医疗 AI 论文和 Steven McDonagh 的图像生成工作也值得关注。\n\n下面，我将挑选并讨论部分重要论文，先从 LLM 相关主题入手，再扩展到图像生成和联邦学习等高话题度领域。对于其他次要论文，我会快速掠过，只提关键点。\n\n### LLM 安全与优化\n- **RAG Does Not Work for Enterprises（检索增强生成在企业中的挑战）**  \n  这篇论文探讨了 RAG 在企业环境中的问题，包括数据安全、准确性和可扩展性。主要贡献是提出一个评估框架，结合定量测试和案例研究，评估 RAG 的准确性与合规性，发现企业级 RAG 需要改进语义搜索和混合查询技术。\n\n- **LLM-RankFusion（缓解 LLM 排序中的内在不一致性）**  \n  作者 Yifan Zeng 等提出 LLM-RankFusion 框架，用于信息检索中的 LLM 排序问题。主要发现是通过 in-context learning 和校准缓解顺序和传递不一致性，提高排序鲁棒性，并开源了代码。\n\n- **Exfiltration of personal information from ChatGPT via prompt injection（通过提示注入从 ChatGPT 泄露个人信息）**  \n  这篇简短但高话题度的论文揭示了 ChatGPT 4 和 4o 的漏洞：攻击者可通过提示注入窃取用户数据，尤其在记忆功能下。主要贡献是展示一种无需第三方工具的攻击方法，强调 AI 隐私风险。\n\n- **LOLAMEME（逻辑、语言、记忆的机制框架）**  \n  作者 Jay Desai 等扩展了 LLM 的机制分析，提出 LOLAMEME 框架，结合逻辑和记忆建模。发现混合架构（如 T HEX）在特定任务中优于 GPT-2 和 Hyena。\n\n- **DYNA（疾病特定语言模型用于变异致病性预测）**  \n  作者 Huixin Zhan 等开发了 DYNA 框架，通过 Siamese 神经网络微调基因模型。关键发现是它在心血管和 RNA 拼接任务中提升了变异预测准确性，并验证了在 ClinVar 数据上的泛化能力。\n\n### 图像生成与扩散模型\n- **Bootstrap3D（使用合成数据改进多视图扩散模型）**  \n  这篇令人印象深刻的论文提出 Bootstrap3D 框架，利用合成多视图数据训练扩散模型。主要贡献是通过数据生成管道和训练时间表优化，提升了图像质量和视图一致性，在像素和潜在空间中表现出色。\n\n- **SNED（通过神经架构搜索优化视频扩散模型）**  \n  作者 Zhengang Li 等的论文（已接受 CVPR 2024）引入 SNED 方法，实现高效视频生成。发现它能处理不同分辨率和模型大小，提供灵活的超网络训练，显著减少计算需求。\n\n- **Sifting through the Noise（扩散模型在生物分子的应用调查）**  \n  这篇综述性论文总结了扩散模型在生物分子预测和设计的应用。关键发现是这些模型在生成和预测任务中表现出色，提供全面概述和未来方向。\n\n### 联邦学习与隐私\n- **ACE（在联邦学习中针对贡献评估方法的模型投毒攻击）**  \n  作者 Zhangchen Xu 等提出 ACE 攻击框架，展示如何操纵联邦学习中的贡献评估。发现它能欺骗五种主流方法，同时保持模型准确性，强调联邦学习的潜在安全风险。\n\n- **GAMedX（基于生成 AI 的医疗实体数据提取）**  \n  作者 Mohammed-Khalil Ghali 等开发了 GAMedX，使用 LLM 提取医疗数据。关键贡献是多模态框架在 EHR 中的应用，实现了 98% 的准确率，适用于无结构化文本处理。\n\n其他论文，如 **The Explanation Necessity for Healthcare AI（医疗 AI 解释必要性）**（作者 Pietro Lio 等，提出解释性分类系统）和 **Mamba State-Space Models Are Lyapunov-Stable Learners（Mamba 模型的微调稳定性）**，也值得一提，它们分别强调 AI 在医疗中的鲁棒解释和状态空间模型的稳定性。\n\n剩余论文多为次要主题，如 **Long-Span Question-Answering（长跨度问答）** 和 **Anomaly Detection in Dynamic Graphs（动态图异常检测）** 等，我快速掠过：这些工作分别优化了问答框架和图神经网络应用，但对一般读者影响有限，仅在特定领域（如问答或网络安全）有参考价值。\n\n总之，今天的论文展示了 AI 领域的多样创新，LLM 的安全和应用仍是热点。希望这个快报能帮助您快速筛选感兴趣的文章！",
  "papers": [
    {
      "arxiv_id": "2406.04369v1",
      "title": "RAG Does Not Work for Enterprises",
      "title_zh": "RAG 不适用于企业",
      "authors": [
        "Tilmann Bruckhaus"
      ],
      "abstract": "Retrieval-Augmented Generation (RAG) improves the accuracy and relevance of\nlarge language model outputs by incorporating knowledge retrieval. However,\nimplementing RAG in enterprises poses challenges around data security,\naccuracy, scalability, and integration. This paper explores the unique\nrequirements for enterprise RAG, surveys current approaches and limitations,\nand discusses potential advances in semantic search, hybrid queries, and\noptimized retrieval. It proposes an evaluation framework to validate enterprise\nRAG solutions, including quantitative testing, qualitative analysis, ablation\nstudies, and industry case studies. This framework aims to help demonstrate the\nability of purpose-built RAG architectures to deliver accuracy and relevance\nimprovements with enterprise-grade security, compliance and integration. The\npaper concludes with implications for enterprise deployments, limitations, and\nfuture research directions. Close collaboration between researchers and\nindustry partners may accelerate progress in developing and deploying\nretrieval-augmented generation technology.",
      "tldr_zh": "该论文讨论了Retrieval-Augmented Generation (RAG) 在企业环境中的局限性，包括数据安全、准确性、可扩展性和集成挑战，尽管RAG能提升大型语言模型的输出准确性和相关性。作者调查了当前的企业RAG方法及其限制，并探讨了潜在改进，如semantic search、hybrid queries和优化检索。论文提出一个评估框架，涵盖定量测试、定性分析、消融研究和行业案例研究，以验证企业RAG解决方案的安全性、合规性和集成能力。该框架旨在证明目的构建的RAG架构能提升准确性和相关性，同时为企业部署提供指导，并指出未来研究方向需要研究与行业合作。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04369v1",
      "published_date": "2024-05-31 23:30:52 UTC",
      "updated_date": "2024-05-31 23:30:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:24:57.817860"
    },
    {
      "arxiv_id": "2406.00231v2",
      "title": "LLM-RankFusion: Mitigating Intrinsic Inconsistency in LLM-based Ranking",
      "title_zh": "LLM-RankFusion：缓解基于LLM排名的内在不一致性",
      "authors": [
        "Yifan Zeng",
        "Ojas Tendolkar",
        "Raymond Baartmans",
        "Qingyun Wu",
        "Lizhong Chen",
        "Huazheng Wang"
      ],
      "abstract": "Ranking passages by prompting a large language model (LLM) can achieve\npromising performance in modern information retrieval (IR) systems. A common\napproach to sort the ranking list is by prompting LLMs for a pairwise or\nsetwise comparison which often relies on sorting algorithms. However,\nsorting-based methods require consistent comparisons to correctly sort the\npassages, which we show that LLMs often violate. We identify two kinds of\nintrinsic inconsistency in LLM-based pairwise comparisons: order inconsistency\nwhich leads to conflicting results when switching the passage order, and\ntransitive inconsistency which leads to non-transitive triads among all\npreference pairs. Our study of these inconsistencies is relevant for\nunderstanding and improving the stability of any ranking scheme based on\nrelative preferences. In this paper, we propose LLM-RankFusion, an LLM-based\nranking framework that mitigates these inconsistencies and produces a robust\nranking list. LLM-RankFusion mitigates order inconsistency using in-context\nlearning (ICL) to demonstrate order-agnostic comparisons and calibration to\nestimate the underlying preference probability between two passages. We then\naddress transitive inconsistency by aggregating the ranking results from\nmultiple rankers. In our experiments, we empirically show that LLM-RankFusion\ncan significantly reduce inconsistent comparison results, improving the ranking\nquality by making the final ranking list more robust. Our code is available at\n\\href{https://github.com/XHMY/LLM-RankFusion}{https://github.com/XHMY/LLM-RankFusion}",
      "tldr_zh": "该研究探讨了在信息检索系统中，使用大型语言模型（LLM）进行排序时存在的内在不一致问题，包括order inconsistency（顺序不一致）和transitive inconsistency（传递不一致），这些问题会导致排序结果不稳定。针对这些问题，作者提出LLM-RankFusion框架，通过in-context learning (ICL) 和校准来估计偏好概率，从而缓解order inconsistency，并通过聚合多个排列表的结果来解决transitive inconsistency。实验结果表明，该框架显著减少了不一致比较，提高了最终排名的鲁棒性和质量，为LLM-based ranking的改进提供了有效方法。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00231v2",
      "published_date": "2024-05-31 23:29:42 UTC",
      "updated_date": "2024-11-26 08:37:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:25:09.364971"
    },
    {
      "arxiv_id": "2406.00222v1",
      "title": "Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training",
      "title_zh": "翻译失败",
      "authors": [
        "Maximillian Chen",
        "Ruoxi Sun",
        "Sercan Ö. Arık",
        "Tomas Pfister"
      ],
      "abstract": "Large language models (LLMs) aligned through reinforcement learning from\nhuman feedback (RLHF) have quickly become one of the dominant paradigms for\nbuilding intelligent conversational assistant agents. However, despite their\nstrong performance across many benchmarks, LLM-based agents still lack\nconversational skills such as disambiguation: when generalized assistants are\nfaced with ambiguity, they often overhedge or implicitly guess users'\nground-truth intents rather than asking clarification questions, and under\ntask-specific settings, high-quality conversation samples are often limited,\naffecting models' ability to learn optimal dialogue action policies. We propose\nAction-Based Contrastive Self-Training (henceforth ACT), a quasi-online\npreference optimization algorithm based on Direct Preference Optimization (DPO)\nwhich allows for sample-efficient dialogue policy learning in multi-turn\nconversation. We demonstrate ACT's efficacy under sample-efficient conditions\nin three difficult conversational tasks: tabular-grounded question-answering,\nmachine reading comprehension, and AmbigSQL, a novel task for disambiguating\ninformation-seeking requests for text-to-SQL generation. Additionally, we\npropose evaluating LLMs' ability to function as conversational agents by\nexamining whether they can implicitly recognize and reason about ambiguity in\nconversation. ACT demonstrates substantial conversation modeling improvements\nover standard approaches to supervised fine-tuning and DPO.",
      "tldr_zh": "本研究探讨了通过强化学习从人类反馈（RLHF）训练的大型语言模型（LLMs）在多轮对话中的不足，特别是处理模糊性时往往过度回避或猜测用户意图，而不是主动澄清。论文提出Action-Based Contrastive Self-Training (ACT)，一种基于Direct Preference Optimization (DPO)的准在线偏好优化算法，实现样本高效的多轮对话策略学习。ACT在三个任务上进行了评估，包括表格基础问答、机器阅读理解和新的AmbigSQL任务（用于文本到SQL生成的歧义消解），并引入了评估LLMs识别和推理对话歧义的方法。实验结果显示，ACT在对话建模方面显著优于标准监督微调和DPO方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00222v1",
      "published_date": "2024-05-31 22:44:48 UTC",
      "updated_date": "2024-05-31 22:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:25:22.050998"
    },
    {
      "arxiv_id": "2406.00216v2",
      "title": "The Explanation Necessity for Healthcare AI",
      "title_zh": "医疗保健 AI 的解释必要性",
      "authors": [
        "Michail Mamalakis",
        "Héloïse de Vareilles",
        "Graham Murray",
        "Pietro Lio",
        "John Suckling"
      ],
      "abstract": "Explainability is a critical factor in enhancing the trustworthiness and\nacceptance of artificial intelligence (AI) in healthcare, where decisions\ndirectly impact patient outcomes. Despite advancements in AI interpretability,\nclear guidelines on when and to what extent explanations are required in\nmedical applications remain lacking. We propose a novel categorization system\ncomprising four classes of explanation necessity (self-explainable,\nsemi-explainable, non-explainable, and new-patterns discovery), guiding the\nrequired level of explanation; whether local (patient or sample level), global\n(cohort or dataset level), or both. To support this system, we introduce a\nmathematical formulation that incorporates three key factors: (i) robustness of\nthe evaluation protocol, (ii) variability of expert observations, and (iii)\nrepresentation dimensionality of the application. This framework provides a\npractical tool for researchers to determine the appropriate depth of\nexplainability needed, addressing the critical question: When does an AI\nmedical application need to be explained, and at what level of detail?",
      "tldr_zh": "这篇论文强调了AI在医疗领域的可解释性（explainability）对提升信任度和接受度的关键作用，尤其是在决策直接影响患者结果的情况下。作者提出了一种新型分类系统，将解释必要性分为四类：self-explainable、semi-explainable、non-explainable和new-patterns discovery，以指导解释的级别（local、global或两者兼备）。他们还引入了一个数学公式，整合三个关键因素：(i) 评估协议的robustness，(ii) 专家观察的variability，以及(iii) 应用的representation dimensionality。总体而言，该框架为研究人员提供了一个实用工具，帮助确定AI医疗应用何时及何种深度需要解释。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "accepted paper in IEEE CITREx 2025 : IEEE Symposium on Explainable,\n  Responsible, and Trustworthy Computational Intelligence",
      "pdf_url": "http://arxiv.org/pdf/2406.00216v2",
      "published_date": "2024-05-31 22:20:10 UTC",
      "updated_date": "2025-02-28 14:16:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:25:36.706027"
    },
    {
      "arxiv_id": "2406.00209v2",
      "title": "Mamba State-Space Models Are Lyapunov-Stable Learners",
      "title_zh": "翻译失败",
      "authors": [
        "John T. Halloran",
        "Manbir Gulati",
        "Paul F. Roysdon"
      ],
      "abstract": "Mamba state-space models (SSMs) were recently shown to outperform\nstate-of-the-art (SOTA) Transformer large language models (LLMs) across various\ntasks. Despite subsequent widespread adaptation, little work has focused on\nMamba LLMs' amenability for fine-tuning frameworks ubiquitously used for\nTransformer-based LLMs, e.g., mixed-precision fine-tuning (MPFT) and\nparameter-efficient fine-tuning (PEFT). For the former, it currently remains an\nopen question whether Mamba's recurrent dynamics are robust to small input\nchanges, such as those encountered during MPFT. Using dynamical systems theory\n(in particular, Lyapunov exponents), we answer this question in the\naffirmative. We empirically validate this result through several experiments,\nshowing that Mamba SSMs are significantly more stable to changes introduced by\nmixed-precision than comparable Transformers, even when both MPFT and PEFT are\ncombined. For PEFT, we show how targeting specific memory buffers in Mamba's\ncustomized CUDA kernels for low-rank adaptation regularizes SSM parameters,\nthus providing both parameter efficient learning and computational savings.\nFinally, with both MPFT and PEFT enabled, we explore the impact of instruction\ntuning Mamba SSMs for in-context learning (ICL) on natural language tasks.\nWhile pretrained Mamba and Mamba-2 models only achieve 38% and 82%\n(respectively) of the ICL improvements of comparable Transformer-based LLMs, we\nshow that instruction tuning allows Mamba models to narrow this gap to 81% and\nMamba-2 models to skyrocket over this gap to 132%.",
      "tldr_zh": "这篇论文证明了 Mamba state-space models (SSMs) 是 Lyapunov-stable 的，这意味着它们在面对混合精度 fine-tuning (MPFT) 等小输入变化时，比 Transformer-based large language models (LLMs) 更具鲁棒性。作者利用动力系统理论，特别是 Lyapunov 指数，进行理论分析，并通过实验验证了 Mamba SSMs 在 MPFT 和参数高效 fine-tuning (PEFT) 下的稳定性，同时优化了 Mamba 的内存缓冲区以实现计算效率提升。最终，结果显示，经过指令微调后，Mamba 和 Mamba-2 模型在 in-context learning (ICL) 任务上的性能从预训练时的 38% 和 82% 改进，分别提升至 81% 和 132%，显著缩小了与 Transformer 模型的差距。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 4 figure panels, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2406.00209v2",
      "published_date": "2024-05-31 21:46:23 UTC",
      "updated_date": "2024-10-15 19:21:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:25:47.401005"
    },
    {
      "arxiv_id": "2406.01622v1",
      "title": "Sifting through the Noise: A Survey of Diffusion Probabilistic Models and Their Applications to Biomolecules",
      "title_zh": "翻译失败",
      "authors": [
        "Trevor Norton",
        "Debswapna Bhattacharya"
      ],
      "abstract": "Diffusion probabilistic models have made their way into a number of\nhigh-profile applications since their inception. In particular, there has been\na wave of research into using diffusion models in the prediction and design of\nbiomolecular structures and sequences. Their growing ubiquity makes it\nimperative for researchers in these fields to understand them. This paper\nserves as a general overview for the theory behind these models and the current\nstate of research. We first introduce diffusion models and discuss common\nmotifs used when applying them to biomolecules. We then present the significant\noutcomes achieved through the application of these models in generative and\npredictive tasks. This survey aims to provide readers with a comprehensive\nunderstanding of the increasingly critical role of diffusion models.",
      "tldr_zh": "这篇调查论文概述了Diffusion Probabilistic Models的理论基础及其在生物分子领域的应用，旨在帮助研究者理解这些模型的原理和常见应用模式。论文首先介绍扩散模型的核心概念，然后讨论其在生物分子结构和序列的生成及预测任务中的关键成果，包括显著的实验成效。最终，该调查强调了这些模型在推动生物分子研究中的重要作用，提供了一个全面的理解框架。",
      "categories": [
        "q-bio.BM",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "q-bio.BM",
      "comment": "31 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.01622v1",
      "published_date": "2024-05-31 21:39:51 UTC",
      "updated_date": "2024-05-31 21:39:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:25:56.471878"
    },
    {
      "arxiv_id": "2406.00199v2",
      "title": "Exfiltration of personal information from ChatGPT via prompt injection",
      "title_zh": "翻译失败",
      "authors": [
        "Gregory Schwartzman"
      ],
      "abstract": "We report that ChatGPT 4 and 4o are susceptible to a prompt injection attack\nthat allows an attacker to exfiltrate users' personal data. It is applicable\nwithout the use of any 3rd party tools and all users are currently affected.\nThis vulnerability is exacerbated by the recent introduction of ChatGPT's\nmemory feature, which allows an attacker to command ChatGPT to monitor the user\nfor the desired personal data.",
      "tldr_zh": "该研究揭示了 ChatGPT 4 和 4o 存在 prompt injection 攻击漏洞，允许攻击者无需第三方工具即可窃取用户的个人信息，所有用户均受影响。攻击者可以通过注入特定提示命令 ChatGPT 监控并提取目标数据，这种方法利用了 ChatGPT 的新记忆功能，进一步加剧了风险。研究强调了这一安全问题的严重性，为改进 AI 模型的安全性提供了重要警示。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.CY",
        "cs.ET"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00199v2",
      "published_date": "2024-05-31 21:21:19 UTC",
      "updated_date": "2024-06-06 06:43:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:26:08.568964"
    },
    {
      "arxiv_id": "2406.02592v1",
      "title": "LOLAMEME: Logic, Language, Memory, Mechanistic Framework",
      "title_zh": "LOLAM",
      "authors": [
        "Jay Desai",
        "Xiaobo Guo",
        "Srinivasan H. Sengamedu"
      ],
      "abstract": "The performance of Large Language Models has achieved superhuman breadth with\nunprecedented depth. At the same time, the language models are mostly black box\nmodels and the underlying mechanisms for performance have been evaluated using\nsynthetic or mechanistic schemes. We extend current mechanistic schemes to\nincorporate Logic, memory, and nuances of Language such as latent structure.\nThe proposed framework is called LOLAMEME and we provide two instantiations of\nLOLAMEME: LoLa and MeMe languages. We then consider two generative language\nmodel architectures: transformer-based GPT-2 and convolution-based Hyena. We\npropose the hybrid architecture T HEX and use LOLAMEME framework is used to\ncompare three architectures. T HEX outperforms GPT-2 and Hyena on select tasks.",
      "tldr_zh": "这篇论文提出了LOLAMEME框架，用于扩展大型语言模型（LLMs）的机制分析方案，整合Logic、Memory和语言的细微差别（如潜在结构），以更好地理解模型性能。框架提供了LoLa和MeMe语言的两个实例，并应用于比较三种生成语言模型架构：基于transformer's GPT-2、基于convolution的Hyena，以及新提出的混合架构T HEX。结果表明，T HEX在选定任务上超过了GPT-2和Hyena的表现，为语言模型的机制解释提供了更全面的工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "https://openreview.net/pdf?id=73dhbcXxtV",
      "pdf_url": "http://arxiv.org/pdf/2406.02592v1",
      "published_date": "2024-05-31 21:18:25 UTC",
      "updated_date": "2024-05-31 21:18:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:26:22.038015"
    },
    {
      "arxiv_id": "2406.04368v1",
      "title": "SocialNLP Fake-EmoReact 2021 Challenge Overview: Predicting Fake Tweets from Their Replies and GIFs",
      "title_zh": "翻译失败",
      "authors": [
        "Chien-Kun Huang",
        "Yi-Ting Chang",
        "Lun-Wei Ku",
        "Cheng-Te Li",
        "Hong-Han Shuai"
      ],
      "abstract": "This paper provides an overview of the Fake-EmoReact 2021 Challenge, held at\nthe 9th SocialNLP Workshop, in conjunction with NAACL 2021. The challenge\nrequires predicting the authenticity of tweets using reply context and\naugmented GIF categories from EmotionGIF dataset. We offer the Fake-EmoReact\ndataset with more than 453k as the experimental materials, where every tweet is\nlabeled with authenticity. Twenty-four teams registered to participate in this\nchallenge, and 5 submitted their results successfully in the evaluation phase.\nThe best team achieves 93.9 on Fake-EmoReact 2021 dataset using F1 score. In\naddition, we show the definition of share task, data collection, and the teams'\nperformance that joined this challenge and their approaches.",
      "tldr_zh": "该论文概述了 SocialNLP Fake-EmoReact 2021 Challenge，这是一个在第9届 SocialNLP 研讨会（与 NAACL 2021 联合举办）的竞赛，任务是利用推文回复（reply context）和 EmotionGIF 数据集的 GIF 类别来预测推文（tweets）的真实性。竞赛提供了 Fake-EmoReact 数据集，包含超过 453k 条标注真实性的推文，以支持实验。最终，24 支团队注册参与，其中 5 支成功提交结果，最佳团队在 F1 score 上达到 93.9%，展示了有效的方法和数据在假新闻检测中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.04368v1",
      "published_date": "2024-05-31 21:14:11 UTC",
      "updated_date": "2024-05-31 21:14:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:26:34.100238"
    },
    {
      "arxiv_id": "2406.00195v1",
      "title": "SNED: Superposition Network Architecture Search for Efficient Video Diffusion Model",
      "title_zh": "SNED: 用于高效视频扩散模型的叠加网络架构搜索",
      "authors": [
        "Zhengang Li",
        "Yan Kang",
        "Yuchen Liu",
        "Difan Liu",
        "Tobias Hinz",
        "Feng Liu",
        "Yanzhi Wang"
      ],
      "abstract": "While AI-generated content has garnered significant attention, achieving\nphoto-realistic video synthesis remains a formidable challenge. Despite the\npromising advances in diffusion models for video generation quality, the\ncomplex model architecture and substantial computational demands for both\ntraining and inference create a significant gap between these models and\nreal-world applications. This paper presents SNED, a superposition network\narchitecture search method for efficient video diffusion model. Our method\nemploys a supernet training paradigm that targets various model cost and\nresolution options using a weight-sharing method. Moreover, we propose the\nsupernet training sampling warm-up for fast training optimization. To showcase\nthe flexibility of our method, we conduct experiments involving both\npixel-space and latent-space video diffusion models. The results demonstrate\nthat our framework consistently produces comparable results across different\nmodel options with high efficiency. According to the experiment for the\npixel-space video diffusion model, we can achieve consistent video generation\nresults simultaneously across 64 x 64 to 256 x 256 resolutions with a large\nrange of model sizes from 640M to 1.6B number of parameters for pixel-space\nvideo diffusion models.",
      "tldr_zh": "这篇论文提出 SNED，一种叠加网络架构搜索方法，旨在提升视频扩散模型的效率，解决现有模型在复杂架构和计算需求上的挑战。SNED 采用超网训练范式（supernet training paradigm）和权重共享技术，针对不同模型成本和分辨率选项进行优化，并引入超网训练采样预热（supernet training sampling warm-up）来加速训练过程。实验结果显示，该框架在像素空间和潜在空间视频扩散模型中表现出色，能够在从 64x64 到 256x256 的分辨率和 640M 到 1.6B 参数规模下，实现一致的高质量视频生成，显著提高了实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted in CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.00195v1",
      "published_date": "2024-05-31 21:12:30 UTC",
      "updated_date": "2024-05-31 21:12:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:26:46.122492"
    },
    {
      "arxiv_id": "2406.00179v1",
      "title": "Long-Span Question-Answering: Automatic Question Generation and QA-System Ranking via Side-by-Side Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Bernd Bohnet",
        "Kevin Swersky",
        "Rosanne Liu",
        "Pranjal Awasthi",
        "Azade Nova",
        "Javier Snaider",
        "Hanie Sedghi",
        "Aaron T Parisi",
        "Michael Collins",
        "Angeliki Lazaridou",
        "Orhan Firat",
        "Noah Fiedel"
      ],
      "abstract": "We explore the use of long-context capabilities in large language models to\ncreate synthetic reading comprehension data from entire books. Previous efforts\nto construct such datasets relied on crowd-sourcing, but the emergence of\ntransformers with a context size of 1 million or more tokens now enables\nentirely automatic approaches. Our objective is to test the capabilities of\nLLMs to analyze, understand, and reason over problems that require a detailed\ncomprehension of long spans of text, such as questions involving character\narcs, broader themes, or the consequences of early actions later in the story.\nWe propose a holistic pipeline for automatic data generation including question\ngeneration, answering, and model scoring using an ``Evaluator''. We find that a\nrelative approach, comparing answers between models in a pairwise fashion and\nranking with a Bradley-Terry model, provides a more consistent and\ndifferentiating scoring mechanism than an absolute scorer that rates answers\nindividually. We also show that LLMs from different model families produce\nmoderate agreement in their ratings. We ground our approach using the manually\ncurated NarrativeQA dataset, where our evaluator shows excellent agreement with\nhuman judgement and even finds errors in the dataset. Using our automatic\nevaluation approach, we show that using an entire book as context produces\nsuperior reading comprehension performance compared to baseline no-context\n(parametric knowledge only) and retrieval-based approaches.",
      "tldr_zh": "本文探索大型语言模型(LLMs)的长上下文能力，通过自动管道从整本书生成合成阅读理解数据，包括问题生成、回答和模型评分。研究提出使用相对评分方法（side-by-side evaluation 和 Bradley-Terry 模型）来比较模型答案，提供比绝对评分更一致的评估结果。实验表明，这种基于整本书上下文的方法在NarrativeQA数据集上优于无上下文或检索-based 方案，且LLMs的评分表现出中等一致性，为测试长文本理解和推理能力提供了可靠框架。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00179v1",
      "published_date": "2024-05-31 20:15:10 UTC",
      "updated_date": "2024-05-31 20:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:26:58.922492"
    },
    {
      "arxiv_id": "2406.00164v1",
      "title": "DYNA: Disease-Specific Language Model for Variant Pathogenicity",
      "title_zh": "DYNA：用于变异致病性的疾病特定语言模型",
      "authors": [
        "Huixin Zhan",
        "Zijun Zhang"
      ],
      "abstract": "Clinical variant classification of pathogenic versus benign genetic variants\nremains a challenge in clinical genetics. Recently, the proposition of genomic\nfoundation models has improved the generic variant effect prediction (VEP)\naccuracy via weakly-supervised or unsupervised training. However, these VEPs\nare not disease-specific, limiting their adaptation at the point of care. To\naddress this problem, we propose DYNA: Disease-specificity fine-tuning via a\nSiamese neural network broadly applicable to all genomic foundation models for\nmore effective variant effect predictions in disease-specific contexts. We\nevaluate DYNA in two distinct disease-relevant tasks. For coding VEPs, we focus\non various cardiovascular diseases, where gene-disease relationships of\nloss-of-function vs. gain-of-function dictate disease-specific VEP. For\nnon-coding VEPs, we apply DYNA to an essential post-transcriptional regulatory\naxis of RNA splicing, the most common non-coding pathogenic mechanism in\nestablished clinical VEP guidelines. In both cases, DYNA fine-tunes various\npre-trained genomic foundation models on small, rare variant sets. The DYNA\nfine-tuned models show superior performance in the held-out rare variant\ntesting set and are further replicated in large, clinically-relevant variant\nannotations in ClinVAR. Thus, DYNA offers a potent disease-specific variant\neffect prediction method, excelling in intra-gene generalization and\ngeneralization to unseen genetic variants, making it particularly valuable for\ndisease associations and clinical applicability.",
      "tldr_zh": "本研究提出 DYNA，一种疾病特异性语言模型，用于提升变异致病性（Variant Pathogenicity）的预测准确性，通过 Siamese 神经网络对基因组基础模型进行微调，以适应特定疾病上下文。DYNA 在心血管疾病的编码变异预测和 RNA 拼接的非编码变异预测任务中，使用小样本集对预训练模型进行微调，结果显示其在保留测试集和 ClinVAR 临床变异注释中表现出色，优于基线模型。DYNA 特别擅长内部基因泛化和对未见变异的泛化，提高了临床遗传学中的适用性。",
      "categories": [
        "q-bio.GN",
        "cs.AI"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00164v1",
      "published_date": "2024-05-31 19:52:17 UTC",
      "updated_date": "2024-05-31 19:52:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:27:11.047120"
    },
    {
      "arxiv_id": "2406.00157v1",
      "title": "Verification of Neural Network Control Systems in Continuous Time",
      "title_zh": "神经网络控制系统的连续时间验证",
      "authors": [
        "Ali ArjomandBigdeli",
        "Andrew Mata",
        "Stanley Bak"
      ],
      "abstract": "Neural network controllers are currently being proposed for use in many\nsafety-critical tasks. Most analysis methods for neural network control systems\nassume a fixed control period. In control theory, higher frequency usually\nimproves performance. However, for current analysis methods, increasing the\nfrequency complicates verification. In the limit, when actuation is performed\ncontinuously, no existing neural network control systems verification methods\nare able to analyze the system. In this work, we develop the first verification\nmethod for continuously-actuated neural network control systems. We accomplish\nthis by adding a level of abstraction to model the neural network controller.\nThe abstraction is a piecewise linear model with added noise to account for\nlocal linearization error. The soundness of the abstraction can be checked\nusing open-loop neural network verification tools, although we demonstrate\nbottlenecks in existing tools when handling the required specifications. We\ndemonstrate the approach's efficacy by applying it to a vision-based autonomous\nairplane taxiing system and compare with a fixed frequency analysis baseline.",
      "tldr_zh": "该论文解决了神经网络控制系统（neural network control systems）在连续时间下的验证挑战，因为现有方法仅适用于固定控制周期，且频率增加会使验证复杂化。作者提出了一种新方法，通过添加抽象层，使用带有噪声的逐段线性模型（piecewise linear model with added noise）来模拟神经网络控制器，并利用开放循环神经网络验证工具（open-loop neural network verification tools）检查其可靠性，尽管现有工具存在瓶颈。实验结果显示，该方法在视觉-based 自动飞机滑行系统中有效，且与固定频率分析基准相比，验证性能得到显著提升。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "17 pages, 7 figures, Proceedings of the 7th International Symposium\n  on AI Verification (SAIV)",
      "pdf_url": "http://arxiv.org/pdf/2406.00157v1",
      "published_date": "2024-05-31 19:39:48 UTC",
      "updated_date": "2024-05-31 19:39:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:27:23.048014"
    },
    {
      "arxiv_id": "2406.00154v1",
      "title": "A Novel Ranking Scheme for the Performance Analysis of Stochastic Optimization Algorithms using the Principles of Severity",
      "title_zh": "翻译失败",
      "authors": [
        "Sowmya Chandrasekaran",
        "Thomas Bartz-Beielstein"
      ],
      "abstract": "Stochastic optimization algorithms have been successfully applied in several\ndomains to find optimal solutions. Because of the ever-growing complexity of\nthe integrated systems, novel stochastic algorithms are being proposed, which\nmakes the task of the performance analysis of the algorithms extremely\nimportant. In this paper, we provide a novel ranking scheme to rank the\nalgorithms over multiple single-objective optimization problems. The results of\nthe algorithms are compared using a robust bootstrapping-based hypothesis\ntesting procedure that is based on the principles of severity. Analogous to the\nfootball league scoring scheme, we propose pairwise comparison of algorithms as\nin league competition. Each algorithm accumulates points and a performance\nmetric of how good or bad it performed against other algorithms analogous to\ngoal differences metric in football league scoring system. The goal differences\nperformance metric can not only be used as a tie-breaker but also be used to\nobtain a quantitative performance of each algorithm. The key novelty of the\nproposed ranking scheme is that it takes into account the performance of each\nalgorithm considering the magnitude of the achieved performance improvement\nalong with its practical relevance and does not have any distributional\nassumptions. The proposed ranking scheme is compared to classical hypothesis\ntesting and the analysis of the results shows that the results are comparable\nand our proposed ranking showcases many additional benefits.",
      "tldr_zh": "本研究提出了一种新型排名方案，用于评估随机优化算法(stochastic optimization algorithms)在多个单目标优化问题上的性能，该方案基于严重性原则(principles of severity)。该方法采用稳健的引导假设测试(bootstrapping-based hypothesis testing)进行算法配对比较，类似于足球联赛计分系统，每个算法通过积累点数和性能指标（如进球差）来量化其相对表现，同时考虑性能改进的幅度和实际相关性。创新点在于，该方案无须分布假设，且在与经典假设测试的比较中显示出可比结果，同时提供额外优势，如更全面的量化评估。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00154v1",
      "published_date": "2024-05-31 19:35:34 UTC",
      "updated_date": "2024-05-31 19:35:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:27:34.243917"
    },
    {
      "arxiv_id": "2406.00146v1",
      "title": "A Survey of Deep Learning Audio Generation Methods",
      "title_zh": "深度学习音频生成方法的综述",
      "authors": [
        "Matej Božić",
        "Marko Horvat"
      ],
      "abstract": "This article presents a review of typical techniques used in three distinct\naspects of deep learning model development for audio generation. In the first\npart of the article, we provide an explanation of audio representations,\nbeginning with the fundamental audio waveform. We then progress to the\nfrequency domain, with an emphasis on the attributes of human hearing, and\nfinally introduce a relatively recent development. The main part of the article\nfocuses on explaining basic and extended deep learning architecture variants,\nalong with their practical applications in the field of audio generation. The\nfollowing architectures are addressed: 1) Autoencoders 2) Generative\nadversarial networks 3) Normalizing flows 4) Transformer networks 5) Diffusion\nmodels. Lastly, we will examine four distinct evaluation metrics that are\ncommonly employed in audio generation. This article aims to offer novice\nreaders and beginners in the field a comprehensive understanding of the current\nstate of the art in audio generation methods as well as relevant studies that\ncan be explored for future research.",
      "tldr_zh": "这篇文章对深度学习音频生成方法的典型技术进行了全面综述。首先，它解释了音频表示，从基本音频波形到频域（强调人类听觉特性），并介绍了较新的发展。随后，文章详细讨论了多种深度学习架构及其在音频生成中的应用，包括 Autoencoders、Generative Adversarial Networks、Normalizing Flows、Transformer Networks 和 Diffusion Models。最后，通过考察四种常见评估指标，该文为初学者提供了音频生成领域的当前状态和未来研究方向的清晰概述。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "14 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.00146v1",
      "published_date": "2024-05-31 19:20:27 UTC",
      "updated_date": "2024-05-31 19:20:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:27:47.137815"
    },
    {
      "arxiv_id": "2406.00144v1",
      "title": "Query2CAD: Generating CAD models using natural language queries",
      "title_zh": "Query2CAD：使用自然语言查询生成 CAD 模型",
      "authors": [
        "Akshay Badagabettu",
        "Sai Sravan Yarlagadda",
        "Amir Barati Farimani"
      ],
      "abstract": "Computer Aided Design (CAD) engineers typically do not achieve their best\nprototypes in a single attempt. Instead, they iterate and refine their designs\nto achieve an optimal solution through multiple revisions. This traditional\napproach, though effective, is time-consuming and relies heavily on the\nexpertise of skilled engineers. To address these challenges, we introduce\nQuery2CAD, a novel framework to generate CAD designs. The framework uses a\nlarge language model to generate executable CAD macros. Additionally, Query2CAD\nrefines the generation of the CAD model with the help of its self-refinement\nloops. Query2CAD operates without supervised data or additional training, using\nthe LLM as both a generator and a refiner. The refiner leverages feedback\ngenerated by the BLIP2 model, and to address false negatives, we have\nincorporated human-in-the-loop feedback into our system. Additionally, we have\ndeveloped a dataset that encompasses most operations used in CAD model\ndesigning and have evaluated our framework using this dataset. Our findings\nreveal that when we used GPT-4 Turbo as our language model, the architecture\nachieved a success rate of 53.6\\% on the first attempt. With subsequent\nrefinements, the success rate increased by 23.1\\%. In particular, the most\nsignificant improvement in the success rate was observed with the first\niteration of the refinement. With subsequent refinements, the accuracy of the\ncorrect designs did not improve significantly. We have open-sourced our data,\nmodel, and code (github.com/akshay140601/Query2CAD).",
      "tldr_zh": "该研究引入了Query2CAD框架，使用自然语言查询生成CAD模型，旨在解决传统CAD设计过程耗时且依赖专家的问题。框架利用LLM（如GPT-4 Turbo）作为生成器和精炼器，通过自精炼循环、BLIP2模型反馈以及人为反馈来迭代优化设计，而无需监督数据或额外训练。实验结果显示，首次生成成功率达53.6%，经过精炼后成功率提升23.1%，尤其是第一次迭代效果最显著；研究团队还开源了数据集、模型和代码（github.com/akshay140601/Query2CAD）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.LG",
      "comment": "8 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.00144v1",
      "published_date": "2024-05-31 19:17:00 UTC",
      "updated_date": "2024-05-31 19:17:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:27:57.829766"
    },
    {
      "arxiv_id": "2406.02591v1",
      "title": "Unveiling the Potential of AI for Nanomaterial Morphology Prediction",
      "title_zh": "揭示 AI 用于纳米材料形态预测的潜力",
      "authors": [
        "Ivan Dubrovsky",
        "Andrei Dmitrenko",
        "Aleksei Dmitrenko",
        "Nikita Serov",
        "Vladimir Vinogradov"
      ],
      "abstract": "Creation of nanomaterials with specific morphology remains a complex\nexperimental process, even though there is a growing demand for these materials\nin various industry sectors. This study explores the potential of AI to predict\nthe morphology of nanoparticles within the data availability constraints. For\nthat, we first generated a new multi-modal dataset that is double the size of\nanalogous studies. Then, we systematically evaluated performance of classical\nmachine learning and large language models in prediction of nanomaterial shapes\nand sizes. Finally, we prototyped a text-to-image system, discussed the\nobtained empirical results, as well as the limitations and promises of existing\napproaches.",
      "tldr_zh": "本研究探讨了 AI 在预测纳米材料形态方面的潜力，以应对数据可用性限制的问题。首先，研究团队生成了一个新的多模态数据集，比类似研究大一倍，并系统评估了经典机器学习和大型语言模型在预测纳米材料形状和大小的性能。其次，他们原型化了一个文本到图像系统，并分析了经验结果，突出了现有方法的限制和未来前景。该工作为纳米材料设计提供了一种创新的 AI 驱动方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.02591v1",
      "published_date": "2024-05-31 19:16:07 UTC",
      "updated_date": "2024-05-31 19:16:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:28:12.305960"
    },
    {
      "arxiv_id": "2406.03501v1",
      "title": "Representation of preferences for multiple criteria decision aiding in a new seven-valued logic",
      "title_zh": "翻译失败",
      "authors": [
        "Salvatore Greco",
        "Roman Słowiński"
      ],
      "abstract": "The seven-valued logic considered in this paper naturally arises within the\nrough set framework, allowing to distinguish vagueness due to imprecision from\nambiguity due to coarseness. Recently, we discussed its utility for reasoning\nabout data describing multi-attribute classification of objects. We also showed\nthat this logic contains, as a particular case, the celebrated Belnap\nfour-valued logic. Here, we present how the seven-valued logic, as well as the\nother logics that derive from it, can be used to represent preferences in the\ndomain of Multiple Criteria Decision Aiding (MCDA). In particular, we propose\nnew forms of outranking and value function preference models that aggregate\nmultiple criteria taking into account imperfect preference information. We\ndemonstrate that our approach effectively addresses common challenges in\npreference modeling for MCDA, such as uncertainty, imprecision, and\nill-determination of performances and preferences. To this end, we present a\nspecific procedure to construct a seven-valued preference relation and use it\nto define recommendations that consider robustness concerns by utilizing\nmultiple outranking or value functions representing the decision maker s\npreferences. Moreover, we discuss the main properties of the proposed\nseven-valued preference structure and compare it with current approaches in\nMCDA, such as ordinal regression, robust ordinal regression, stochastic\nmultiattribute acceptability analysis, stochastic ordinal regression, and so\non. We illustrate and discuss the application of our approach using a didactic\nexample. Finally, we propose directions for future research and potential\napplications of the proposed methodology.",
      "tldr_zh": "本研究引入了一种基于粗糙集框架（rough set framework）的七值逻辑（seven-valued logic），用于多准则决策辅助（Multiple Criteria Decision Aiding, MCDA）中表示偏好，从而区分不确定性中的不精确性和模糊性。论文提出新的排序（outranking）和价值函数（value function）模型，这些模型聚合多个准则并处理不完善的偏好信息，通过构建七值偏好关系（seven-valued preference relation）来生成考虑稳健性（robustness）的推荐。相比传统方法如序数回归（ordinal regression）和稳健序数回归（robust ordinal regression），该方法更有效地应对MCDA中的不确定性和不精确性，并通过教学例子验证其实用性，为未来应用提供了研究方向。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.03501v1",
      "published_date": "2024-05-31 18:59:24 UTC",
      "updated_date": "2024-05-31 18:59:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:28:24.696044"
    },
    {
      "arxiv_id": "2406.00135v1",
      "title": "Advancing Ear Biometrics: Enhancing Accuracy and Robustness through Deep Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Youssef Mohamed",
        "Zeyad Youssef",
        "Ahmed Heakl",
        "Ahmed Zaky"
      ],
      "abstract": "Biometric identification is a reliable method to verify individuals based on\ntheir unique physical or behavioral traits, offering a secure alternative to\ntraditional methods like passwords or PINs. This study focuses on ear biometric\nidentification, exploiting its distinctive features for enhanced accuracy,\nreliability, and usability. While past studies typically investigate face\nrecognition and fingerprint analysis, our research demonstrates the\neffectiveness of ear biometrics in overcoming limitations such as variations in\nfacial expressions and lighting conditions. We utilized two datasets: AMI (700\nimages from 100 individuals) and EarNV1.0 (28,412 images from 164 individuals).\nTo improve the accuracy and robustness of our ear biometric identification\nsystem, we applied various techniques including data preprocessing and\naugmentation. Our models achieved a testing accuracy of 99.35% on the AMI\nDataset and 98.1% on the EarNV1.0 dataset, showcasing the effectiveness of our\napproach in precisely identifying individuals based on ear biometric\ncharacteristics.",
      "tldr_zh": "这篇论文探讨了通过深度学习提升耳部生物识别（ear biometrics）的准确性和鲁棒性，强调其在面对面部表情和光照变化等挑战时的优势。研究者使用了 AMI Dataset（700 张图像，来自 100 人）和 EarNV1.0 Dataset（28,412 张图像，来自 164 人），并应用数据预处理和增强（data preprocessing and augmentation）技术来优化模型。结果显示，该方法在 AMI Dataset 上实现了 99.35% 的测试准确率，在 EarNV1.0 Dataset 上达到 98.1%，证明了耳部生物识别作为可靠身份验证工具的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.HC",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 8 figures, 3 tables, International IEEE Conference on the\n  Intelligent Methods, Systems, and Applications",
      "pdf_url": "http://arxiv.org/pdf/2406.00135v1",
      "published_date": "2024-05-31 18:55:10 UTC",
      "updated_date": "2024-05-31 18:55:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:28:34.542314"
    },
    {
      "arxiv_id": "2406.00134v1",
      "title": "Anomaly Detection in Dynamic Graphs: A Comprehensive Survey",
      "title_zh": "动态图中的异常检测：一个全面的综述",
      "authors": [
        "Ocheme Anthony Ekle",
        "William Eberle"
      ],
      "abstract": "This survey paper presents a comprehensive and conceptual overview of anomaly\ndetection using dynamic graphs. We focus on existing graph-based anomaly\ndetection (AD) techniques and their applications to dynamic networks. The\ncontributions of this survey paper include the following: i) a comparative\nstudy of existing surveys on anomaly detection; ii) a Dynamic Graph-based\nAnomaly Detection (DGAD) review framework in which approaches for detecting\nanomalies in dynamic graphs are grouped based on traditional machine-learning\nmodels, matrix transformations, probabilistic approaches, and deep-learning\napproaches; iii) a discussion of graphically representing both discrete and\ndynamic networks; and iv) a discussion of the advantages of graph-based\ntechniques for capturing the relational structure and complex interactions in\ndynamic graph data. Finally, this work identifies the potential challenges and\nfuture directions for detecting anomalies in dynamic networks. This DGAD survey\napproach aims to provide a valuable resource for researchers and practitioners\nby summarizing the strengths and limitations of each approach, highlighting\ncurrent research trends, and identifying open challenges. In doing so, it can\nguide future research efforts and promote advancements in anomaly detection in\ndynamic graphs.\n  Keywords: Graphs, Anomaly Detection, dynamic networks,Graph Neural Networks\n(GNN), Node anomaly, Graph mining.",
      "tldr_zh": "这篇调查论文对动态图中的异常检测(Anomaly Detection)进行了全面概述，聚焦于现有图-based 技术及其在动态网络中的应用。论文的主要贡献包括：比较现有异常检测调查、提出Dynamic Graph-based Anomaly Detection (DGAD) 审查框架（将方法分类为传统机器学习模型、矩阵变换、概率方法和深度学习方法）、讨论图形表示离散和动态网络，以及强调图-based 技术在捕捉关系结构和复杂交互方面的优势。该工作还识别了潜在挑战和未来方向，如改进Graph Neural Networks (GNN)和图挖掘(Graph mining)，为研究者和从业者提供资源，总结各方法的优缺点并指导后续研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "32 pages (double column), 4 figures, and the manuscript has just been\n  accepted in ACM Journals of Transactions on Knowledge Discovery from Data\n  (TKDD)",
      "pdf_url": "http://arxiv.org/pdf/2406.00134v1",
      "published_date": "2024-05-31 18:54:00 UTC",
      "updated_date": "2024-05-31 18:54:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:28:47.257209"
    },
    {
      "arxiv_id": "2406.00133v1",
      "title": "Streamflow Prediction with Uncertainty Quantification for Water Management: A Constrained Reasoning and Learning Approach",
      "title_zh": "用于",
      "authors": [
        "Mohammed Amine Gharsallaoui",
        "Bhupinderjeet Singh",
        "Supriya Savalkar",
        "Aryan Deshwal",
        "Yan Yan",
        "Ananth Kalyanaraman",
        "Kirti Rajagopalan",
        "Janardhan Rao Doppa"
      ],
      "abstract": "Predicting the spatiotemporal variation in streamflow along with uncertainty\nquantification enables decision-making for sustainable management of scarce\nwater resources. Process-based hydrological models (aka physics-based models)\nare based on physical laws, but using simplifying assumptions which can lead to\npoor accuracy. Data-driven approaches offer a powerful alternative, but they\nrequire large amount of training data and tend to produce predictions that are\ninconsistent with physical laws. This paper studies a constrained reasoning and\nlearning (CRL) approach where physical laws represented as logical constraints\nare integrated as a layer in the deep neural network. To address small data\nsetting, we develop a theoretically-grounded training approach to improve the\ngeneralization accuracy of deep models. For uncertainty quantification, we\ncombine the synergistic strengths of Gaussian processes (GPs) and deep temporal\nmodels (i.e., deep models for time-series forecasting) by passing the learned\nlatent representation as input to a standard distance-based kernel. Experiments\non multiple real-world datasets demonstrate the effectiveness of both CRL and\nGP with deep kernel approaches over strong baseline methods.",
      "tldr_zh": "该论文提出了一种constrained reasoning and learning (CRL)方法，用于预测河流水流量的时空变化并量化不确定性，以支持水资源可持续管理。该方法将物理定律表示为逻辑约束，整合到深度神经网络中，并开发了一个理论基础的训练策略，以在小数据场景下提升模型的泛化准确性。对于不确定性量化，论文结合Gaussian processes (GPs)和深度时间模型，通过将学到的潜在表示输入到基于距离的核函数中，实现预测的鲁棒性。在多个真实数据集上的实验显示，CRL和GP with deep kernel方法比传统基线模型表现出色，显著提高了预测性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00133v1",
      "published_date": "2024-05-31 18:53:53 UTC",
      "updated_date": "2024-05-31 18:53:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:29:09.926381"
    },
    {
      "arxiv_id": "2406.00120v4",
      "title": "Reward Machines for Deep RL in Noisy and Uncertain Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Andrew C. Li",
        "Zizhao Chen",
        "Toryn Q. Klassen",
        "Pashootan Vaezipoor",
        "Rodrigo Toro Icarte",
        "Sheila A. McIlraith"
      ],
      "abstract": "Reward Machines provide an automaton-inspired structure for specifying\ninstructions, safety constraints, and other temporally extended reward-worthy\nbehaviour. By exposing the underlying structure of a reward function, they\nenable the decomposition of an RL task, leading to impressive gains in sample\nefficiency. Although Reward Machines and similar formal specifications have a\nrich history of application towards sequential decision-making problems, they\ncritically rely on a ground-truth interpretation of the domain-specific\nvocabulary that forms the building blocks of the reward function--such\nground-truth interpretations are elusive in the real world due in part to\npartial observability and noisy sensing. In this work, we explore the use of\nReward Machines for Deep RL in noisy and uncertain environments. We\ncharacterize this problem as a POMDP and propose a suite of RL algorithms that\nexploit task structure under uncertain interpretation of the domain-specific\nvocabulary. Through theory and experiments, we expose pitfalls in naive\napproaches to this problem while simultaneously demonstrating how task\nstructure can be successfully leveraged under noisy interpretations of the\nvocabulary.",
      "tldr_zh": "本文提出了一种在噪声和不确定环境中应用 Reward Machines 的方法，用于提升 Deep RL 的性能。Reward Machines 通过暴露奖励函数的结构，实现任务分解并提高样本效率，但面临领域特定词汇解释不确定的挑战。作者将问题建模为 POMDP，并设计了一系列 RL 算法，利用任务结构来处理噪声感知和部分可观察性。通过理论分析和实验验证，揭示了 naive 方法的潜在陷阱，并证明了在不确定条件下成功利用任务结构的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.FL",
        "I.2.0; I.2.6; I.2.4; F.4.3"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00120v4",
      "published_date": "2024-05-31 18:22:09 UTC",
      "updated_date": "2025-01-15 18:30:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:29:12.249875"
    },
    {
      "arxiv_id": "2406.00093v2",
      "title": "Bootstrap3D: Improving Multi-view Diffusion Model with Synthetic Data",
      "title_zh": "Bootstrap3D：通过合成数据改进多视图扩散模型",
      "authors": [
        "Zeyi Sun",
        "Tong Wu",
        "Pan Zhang",
        "Yuhang Zang",
        "Xiaoyi Dong",
        "Yuanjun Xiong",
        "Dahua Lin",
        "Jiaqi Wang"
      ],
      "abstract": "Recent years have witnessed remarkable progress in multi-view diffusion\nmodels for 3D content creation. However, there remains a significant gap in\nimage quality and prompt-following ability compared to 2D diffusion models. A\ncritical bottleneck is the scarcity of high-quality 3D objects with detailed\ncaptions. To address this challenge, we propose Bootstrap3D, a novel framework\nthat automatically generates an arbitrary quantity of multi-view images to\nassist in training multi-view diffusion models. Specifically, we introduce a\ndata generation pipeline that employs (1) 2D and video diffusion models to\ngenerate multi-view images based on constructed text prompts, and (2) our\nfine-tuned 3D-aware MV-LLaVA for filtering high-quality data and rewriting\ninaccurate captions. Leveraging this pipeline, we have generated 1 million\nhigh-quality synthetic multi-view images with dense descriptive captions to\naddress the shortage of high-quality 3D data. Furthermore, we present a\nTraining Timestep Reschedule (TTR) strategy that leverages the denoising\nprocess to learn multi-view consistency while maintaining the original 2D\ndiffusion prior. Extensive experiments demonstrate that Bootstrap3D can\ngenerate high-quality multi-view images with superior aesthetic quality,\nimage-text alignment, and maintained view consistency.",
      "tldr_zh": "本文提出 Bootstrap3D 框架，通过生成合成数据来提升多视图扩散模型的图像质量和提示遵循能力，以解决高质量 3D 数据短缺的问题。具体方法包括一个数据生成管道，利用 2D 和视频扩散模型基于文本提示创建多视图图像，并采用微调的 3D-aware MV-LLaVA 过滤高质量数据并重写标题；此外，引入 Training Timestep Reschedule (TTR) 策略，以确保多视图一致性同时保留 2D 扩散先验。利用该框架，研究者生成了 100 万高质量合成多视图图像。实验结果显示，Bootstrap3D 生成的图像在美学质量、图像-文本对齐和视图一致性方面均优于现有基线模型。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Page: https://sunzey.github.io/Bootstrap3D/",
      "pdf_url": "http://arxiv.org/pdf/2406.00093v2",
      "published_date": "2024-05-31 17:59:56 UTC",
      "updated_date": "2024-10-03 08:20:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:29:27.935712"
    },
    {
      "arxiv_id": "2405.21068v1",
      "title": "Code Pretraining Improves Entity Tracking Abilities of Language Models",
      "title_zh": "代码预训练提升了语言模型的实体跟踪能力",
      "authors": [
        "Najoung Kim",
        "Sebastian Schuster",
        "Shubham Toshniwal"
      ],
      "abstract": "Recent work has provided indirect evidence that pretraining language models\non code improves the ability of models to track state changes of discourse\nentities expressed in natural language. In this work, we systematically test\nthis claim by comparing pairs of language models on their entity tracking\nperformance. Critically, the pairs consist of base models and models trained on\ntop of these base models with additional code data. We extend this analysis to\nadditionally examine the effect of math training, another highly structured\ndata type, and alignment tuning, an important step for enhancing the usability\nof models. We find clear evidence that models additionally trained on large\namounts of code outperform the base models. On the other hand, we find no\nconsistent benefit of additional math training or alignment tuning across\nvarious model families.",
      "tldr_zh": "本文系统测试了在代码上预训练语言模型是否能提升其实体 tracking 能力，通过比较基础模型与额外训练代码数据的模型对进行评估。研究发现，代码预训练显著改善了模型跟踪自然语言中话语实体状态变化的性能。另一方面，额外数学训练和对齐 tuning 在各种模型家族中并未显示出一致的益处。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.21068v1",
      "published_date": "2024-05-31 17:56:33 UTC",
      "updated_date": "2024-05-31 17:56:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:29:35.597459"
    },
    {
      "arxiv_id": "2406.00092v1",
      "title": "How Random is Random? Evaluating the Randomness and Humaness of LLMs' Coin Flips",
      "title_zh": "翻译失败",
      "authors": [
        "Katherine Van Koevering",
        "Jon Kleinberg"
      ],
      "abstract": "One uniquely human trait is our inability to be random. We see and produce\npatterns where there should not be any and we do so in a predictable way. LLMs\nare supplied with human data and prone to human biases. In this work, we\nexplore how LLMs approach randomness and where and how they fail through the\nlens of the well studied phenomena of generating binary random sequences. We\nfind that GPT 4 and Llama 3 exhibit and exacerbate nearly every human bias we\ntest in this context, but GPT 3.5 exhibits more random behavior. This dichotomy\nof randomness or humaness is proposed as a fundamental question of LLMs and\nthat either behavior may be useful in different circumstances.",
      "tldr_zh": "本研究探讨了LLMs在生成二进制随机序列（如硬币翻转）时的随机性和“人性化”偏见，揭示了LLMs如何继承并放大人类数据中的模式偏好。通过测试GPT-4、Llama 3和GPT-3.5等模型，研究发现前两者表现出并放大了几乎所有人类偏见，而GPT-3.5则更接近随机行为。该发现提出了LLMs的随机性与人性化作为核心问题，这两种特性在不同应用场景下可能各有优势。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.00092v1",
      "published_date": "2024-05-31 17:56:07 UTC",
      "updated_date": "2024-05-31 17:56:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:29:50.891726"
    },
    {
      "arxiv_id": "2405.21064v2",
      "title": "Recurrent neural networks: vanishing and exploding gradients are not the end of the story",
      "title_zh": "循环神经网络：梯度消失和梯度爆炸并非故事的结局",
      "authors": [
        "Nicolas Zucchet",
        "Antonio Orvieto"
      ],
      "abstract": "Recurrent neural networks (RNNs) notoriously struggle to learn long-term\nmemories, primarily due to vanishing and exploding gradients. The recent\nsuccess of state-space models (SSMs), a subclass of RNNs, to overcome such\ndifficulties challenges our theoretical understanding. In this paper, we delve\ninto the optimization challenges of RNNs and discover that, as the memory of a\nnetwork increases, changes in its parameters result in increasingly large\noutput variations, making gradient-based learning highly sensitive, even\nwithout exploding gradients. Our analysis further reveals the importance of the\nelement-wise recurrence design pattern combined with careful parametrizations\nin mitigating this effect. This feature is present in SSMs, as well as in other\narchitectures, such as LSTMs. Overall, our insights provide a new explanation\nfor some of the difficulties in gradient-based learning of RNNs and why some\narchitectures perform better than others.",
      "tldr_zh": "RNNs 传统上难以学习长期记忆，主要归因于 vanishing and exploding gradients，但本文揭示了更深层的优化挑战：随着网络记忆增加，参数变化会导致输出变异增大，从而使基于梯度的学习变得高度敏感，即使没有梯度爆炸。研究分析了 element-wise recurrence 设计模式和仔细的参数化在缓解此问题中的关键作用，这也是 state-space models (SSMs) 和 LSTMs 等架构表现优越的原因。总体上，这些发现为解释 RNNs 的学习困难提供了新视角，并指导了更有效的架构设计。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "math.OC"
      ],
      "primary_category": "cs.LG",
      "comment": "Paper accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.21064v2",
      "published_date": "2024-05-31 17:53:00 UTC",
      "updated_date": "2024-11-05 10:28:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:30:00.145280"
    },
    {
      "arxiv_id": "2405.21063v3",
      "title": "Neural Network Verification with Branch-and-Bound for General Nonlinearities",
      "title_zh": "翻译失败",
      "authors": [
        "Zhouxing Shi",
        "Qirui Jin",
        "Zico Kolter",
        "Suman Jana",
        "Cho-Jui Hsieh",
        "Huan Zhang"
      ],
      "abstract": "Branch-and-bound (BaB) is among the most effective techniques for neural\nnetwork (NN) verification. However, existing works on BaB for NN verification\nhave mostly focused on NNs with piecewise linear activations, especially ReLU\nnetworks. In this paper, we develop a general framework, named GenBaB, to\nconduct BaB on general nonlinearities to verify NNs with general architectures,\nbased on linear bound propagation for NN verification. To decide which neuron\nto branch, we design a new branching heuristic which leverages linear bounds as\nshortcuts to efficiently estimate the potential improvement after branching. To\ndecide nontrivial branching points for general nonlinear functions, we propose\nto pre-optimize branching points, which can be efficiently leveraged during\nverification with a lookup table. We demonstrate the effectiveness of our\nGenBaB on verifying a wide range of NNs, including NNs with activation\nfunctions such as Sigmoid, Tanh, Sine and GeLU, as well as NNs involving\nmulti-dimensional nonlinear operations such as multiplications in LSTMs and\nVision Transformers. Our framework also allows the verification of general\nnonlinear computation graphs and enables verification applications beyond\nsimple NNs, particularly for AC Optimal Power Flow (ACOPF). GenBaB is part of\nthe latest $\\alpha$,$\\beta$-CROWN, the winner of the 4th and the 5th\nInternational Verification of Neural Networks Competition (VNN-COMP 2023 and\n2024). Code for reproducing the experiments is available at\nhttps://github.com/shizhouxing/GenBaB.",
      "tldr_zh": "本论文提出GenBaB框架，一种基于Branch-and-Bound (BaB) 的神经网络（NN）验证方法，扩展到处理一般非线性激活函数（如Sigmoid, Tanh, Sine 和 GeLU），以克服现有方法主要限于分段线性激活（如ReLU）的局限性。该框架利用线性边界传播（linear bound propagation）作为基础，设计了新的分支启发式（branching heuristic）来高效估计分支改进，并通过预优化分支点和查找表来处理非线性函数的分支决策。实验结果显示，GenBaB在验证各种NN（包括涉及LSTM和Vision Transformers的多维非线性操作）上表现出色，并成功应用于如AC Optimal Power Flow (ACOPF) 等更广泛的非线性计算图验证中，作为α,β-CROWN工具的一部分赢得了VNN-COMP 2023和2024比赛。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "TACAS 2025",
      "pdf_url": "http://arxiv.org/pdf/2405.21063v3",
      "published_date": "2024-05-31 17:51:07 UTC",
      "updated_date": "2025-02-07 22:42:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:30:23.496223"
    },
    {
      "arxiv_id": "2405.21056v1",
      "title": "An Organic Weed Control Prototype using Directed Energy and Deep Learning",
      "title_zh": "使用定向能量和深度学习的有机杂草控制原型",
      "authors": [
        "Deng Cao",
        "Hongbo Zhang",
        "Rajveer Dhillon"
      ],
      "abstract": "Organic weed control is a vital to improve crop yield with a sustainable\napproach. In this work, a directed energy weed control robot prototype\nspecifically designed for organic farms is proposed. The robot uses a novel\ndistributed array robot (DAR) unit for weed treatment. Soybean and corn\ndatabases are built to train deep learning neural nets to perform weed\nrecognition. The initial deep learning neural nets show a high performance in\nclassifying crops. The robot uses a patented directed energy plant eradication\nrecipe that is completely organic and UV-C free, with no chemical damage or\nphysical disturbance to the soil. The deep learning can classify 8 common weed\nspecies in a soybean field under natural environment with up to 98% accuracy.",
      "tldr_zh": "该研究提出了一种使用定向能量和深度学习的有机杂草控制机器人原型，旨在通过可持续方法提升作物产量。机器人采用新型分布式阵列机器人(DAR)单元进行杂草处理，并通过训练基于大豆和玉米数据库的深度学习神经网络，实现对作物的准确分类。该系统使用专利的定向能量植物根除配方，确保完全有机、无 UV-C 辐射，且不对土壤造成化学或物理损害；实验结果显示，深度学习模型在自然环境中对大豆田中8种常见杂草的分类准确率高达98%。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.21056v1",
      "published_date": "2024-05-31 17:47:22 UTC",
      "updated_date": "2024-05-31 17:47:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:30:24.117890"
    },
    {
      "arxiv_id": "2405.21047v2",
      "title": "Grammar-Aligned Decoding",
      "title_zh": "语法对齐解码",
      "authors": [
        "Kanghee Park",
        "Jiayu Wang",
        "Taylor Berg-Kirkpatrick",
        "Nadia Polikarpova",
        "Loris D'Antoni"
      ],
      "abstract": "Large Language Models (LLMs) struggle with reliably generating highly\nstructured outputs, such as program code, mathematical formulas, or well-formed\nmarkup. Constrained decoding approaches mitigate this problem by greedily\nrestricting what tokens an LLM can output at each step to guarantee that the\noutput matches a given constraint. Specifically, in grammar-constrained\ndecoding (GCD), the LLM's output must follow a given grammar. In this paper, we\ndemonstrate that GCD techniques (and in general constrained decoding\ntechniques) can distort the LLM's distribution, leading to outputs that are\ngrammatical but appear with likelihoods that are not proportional to the ones\ngiven by the LLM, and so ultimately are low-quality. We call the problem of\naligning sampling with a grammar constraint, grammar-aligned decoding (GAD),\nand propose adaptive sampling with approximate expected futures (ASAp), a\ndecoding algorithm that guarantees the output to be grammatical while provably\nproducing outputs that match the conditional probability of the LLM's\ndistribution conditioned on the given grammar constraint. Our algorithm uses\nprior sample outputs to soundly overapproximate the future grammaticality of\ndifferent output prefixes. Our evaluation on code generation and structured NLP\ntasks shows how ASAp often produces outputs with higher likelihood (according\nto the LLM's distribution) than existing GCD techniques, while still enforcing\nthe desired grammatical constraints.",
      "tldr_zh": "大语言模型 (LLMs) 在生成高度结构化的输出（如代码或数学公式）时存在困难，现有的语法约束解码 (GCD) 方法虽能确保输出符合语法，但会扭曲模型分布，导致生成质量低下。论文引入语法对齐解码 (GAD) 概念，并提出 adaptive sampling with approximate expected futures (ASAp) 算法，该算法通过使用先前的样本输出来近似评估未来输出是否符合语法，从而保证输出既符合约束又与 LLM 的条件概率分布对齐。在代码生成和结构化 NLP 任务的评估中，ASAp 比现有 GCD 技术产生更高似然度的输出，同时强制执行语法约束。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.21047v2",
      "published_date": "2024-05-31 17:39:15 UTC",
      "updated_date": "2024-11-04 22:04:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:30:36.892383"
    },
    {
      "arxiv_id": "2405.21046v1",
      "title": "Exploratory Preference Optimization: Harnessing Implicit Q*-Approximation for Sample-Efficient RLHF",
      "title_zh": "翻译失败",
      "authors": [
        "Tengyang Xie",
        "Dylan J. Foster",
        "Akshay Krishnamurthy",
        "Corby Rosset",
        "Ahmed Awadallah",
        "Alexander Rakhlin"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) has emerged as a central\ntool for language model alignment. We consider online exploration in RLHF,\nwhich exploits interactive access to human or AI feedback by deliberately\nencouraging the model to produce diverse, maximally informative responses. By\nallowing RLHF to confidently stray from the pre-trained model, online\nexploration offers the possibility of novel, potentially super-human\ncapabilities, but its full potential as a paradigm for language model training\nhas yet to be realized, owing to computational and statistical bottlenecks in\ndirectly adapting existing reinforcement learning techniques. We propose a new\nalgorithm for online exploration in RLHF, Exploratory Preference Optimization\n(XPO), which is simple and practical -- a one-line change to (online) Direct\nPreference Optimization (DPO; Rafailov et al., 2023) -- yet enjoys the\nstrongest known provable guarantees and promising empirical performance. XPO\naugments the DPO objective with a novel and principled exploration bonus,\nempowering the algorithm to explore outside the support of the initial model\nand human feedback data. In theory, we show that XPO is provably\nsample-efficient and converges to a near-optimal language model policy under\nnatural exploration conditions, irrespective of whether the initial model has\ngood coverage. Our analysis, which builds on the observation that DPO\nimplicitly performs a form of $Q^{\\star}$-approximation (or, Bellman error\nminimization), combines previously disparate techniques from language modeling\nand theoretical reinforcement learning in a serendipitous fashion through the\nperspective of KL-regularized Markov decision processes. Empirically, we find\nthat XPO is more sample-efficient than non-exploratory DPO variants in a\npreliminary evaluation.",
      "tldr_zh": "该研究提出了一种新的算法 Exploratory Preference Optimization (XPO)，旨在提升强化学习从人类反馈 (RLHF) 中的在线探索效率，通过添加一个原理性的探索奖励 (exploration bonus) 来改进 Direct Preference Optimization (DPO)。XPO 仅需对 DPO 进行一行的代码修改，就能使模型超越初始支持范围，探索多样化的响应，从而实现更高效的样本利用。理论上，XPO 证明了其样本高效性，并能收敛到近似最优策略，而不依赖初始模型的覆盖；实证结果显示，在初步评估中，XPO 比非探索性 DPO 变体表现出更高的样本效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.21046v1",
      "published_date": "2024-05-31 17:39:06 UTC",
      "updated_date": "2024-05-31 17:39:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:30:51.347045"
    },
    {
      "arxiv_id": "2405.21043v2",
      "title": "Target Networks and Over-parameterization Stabilize Off-policy Bootstrapping with Function Approximation",
      "title_zh": "目标网络和过度参数化稳定脱策略引导的函数逼近",
      "authors": [
        "Fengdi Che",
        "Chenjun Xiao",
        "Jincheng Mei",
        "Bo Dai",
        "Ramki Gummadi",
        "Oscar A Ramirez",
        "Christopher K Harris",
        "A. Rupam Mahmood",
        "Dale Schuurmans"
      ],
      "abstract": "We prove that the combination of a target network and over-parameterized\nlinear function approximation establishes a weaker convergence condition for\nbootstrapped value estimation in certain cases, even with off-policy data. Our\ncondition is naturally satisfied for expected updates over the entire\nstate-action space or learning with a batch of complete trajectories from\nepisodic Markov decision processes. Notably, using only a target network or an\nover-parameterized model does not provide such a convergence guarantee.\nAdditionally, we extend our results to learning with truncated trajectories,\nshowing that convergence is achievable for all tasks with minor modifications,\nakin to value truncation for the final states in trajectories. Our primary\nresult focuses on temporal difference estimation for prediction, providing\nhigh-probability value estimation error bounds and empirical analysis on\nBaird's counterexample and a Four-room task. Furthermore, we explore the\ncontrol setting, demonstrating that similar convergence conditions apply to\nQ-learning.",
      "tldr_zh": "本文证明了 target networks 和 over-parameterization 的结合，能够在 off-policy 数据下为 bootstrapped value estimation 提供更弱的收敛条件，尤其适用于整个状态-动作空间的期望更新或完整轨迹批次学习。相比之下，单独使用 target network 或 over-parameterized 模型无法保证这种收敛。研究进一步扩展到截断轨迹的学习，通过微小修改（如值截断）实现收敛，并针对 temporal difference estimation 提供了高概率值估计误差界限，同时通过 Baird's counterexample 和 Four-room 任务的实证分析，以及 Q-learning 的控制设置，验证了这些发现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.21043v2",
      "published_date": "2024-05-31 17:36:16 UTC",
      "updated_date": "2024-10-04 18:04:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:31:05.700895"
    },
    {
      "arxiv_id": "2405.21040v1",
      "title": "Direct Alignment of Language Models via Quality-Aware Self-Refinement",
      "title_zh": "翻译失败",
      "authors": [
        "Runsheng Yu",
        "Yong Wang",
        "Xiaoqi Jiao",
        "Youzhi Zhang",
        "James T. Kwok"
      ],
      "abstract": "Reinforcement Learning from Human Feedback (RLHF) has been commonly used to\nalign the behaviors of Large Language Models (LLMs) with human preferences.\nRecently, a popular alternative is Direct Policy Optimization (DPO), which\nreplaces an LLM-based reward model with the policy itself, thus obviating the\nneed for extra memory and training time to learn the reward model. However, DPO\ndoes not consider the relative qualities of the positive and negative\nresponses, and can lead to sub-optimal training outcomes. To alleviate this\nproblem, we investigate the use of intrinsic knowledge within the on-the-fly\nfine-tuning LLM to obtain relative qualities and help to refine the loss\nfunction. Specifically, we leverage the knowledge of the LLM to design a\nrefinement function to estimate the quality of both the positive and negative\nresponses. We show that the constructed refinement function can help\nself-refine the loss function under mild assumptions. The refinement function\nis integrated into DPO and its variant Identity Policy Optimization (IPO).\nExperiments across various evaluators indicate that they can improve the\nperformance of the fine-tuned models over DPO and IPO.",
      "tldr_zh": "本文提出了一种质量感知自精炼方法，用于直接对齐Large Language Models (LLMs)，以解决Direct Policy Optimization (DPO)忽略正负响应相对质量的问题。方法利用LLMs的内在知识设计精炼函数，估计响应质量并改进DPO和Identity Policy Optimization (IPO)的损失函数，从而实现更优的训练效果。实验结果显示，该方法在各种评估器上显著提升了模型性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.21040v1",
      "published_date": "2024-05-31 17:31:18 UTC",
      "updated_date": "2024-05-31 17:31:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:31:15.420673"
    },
    {
      "arxiv_id": "2405.21030v2",
      "title": "Standards for Belief Representations in LLMs",
      "title_zh": "LLMs 中信念表示的标准",
      "authors": [
        "Daniel A. Herrmann",
        "Benjamin A. Levinstein"
      ],
      "abstract": "As large language models (LLMs) continue to demonstrate remarkable abilities\nacross various domains, computer scientists are developing methods to\nunderstand their cognitive processes, particularly concerning how (and if) LLMs\ninternally represent their beliefs about the world. However, this field\ncurrently lacks a unified theoretical foundation to underpin the study of\nbelief in LLMs. This article begins filling this gap by proposing adequacy\nconditions for a representation in an LLM to count as belief-like. We argue\nthat, while the project of belief measurement in LLMs shares striking features\nwith belief measurement as carried out in decision theory and formal\nepistemology, it also differs in ways that should change how we measure belief.\nThus, drawing from insights in philosophy and contemporary practices of machine\nlearning, we establish four criteria that balance theoretical considerations\nwith practical constraints. Our proposed criteria include accuracy, coherence,\nuniformity, and use, which together help lay the groundwork for a comprehensive\nunderstanding of belief representation in LLMs. We draw on empirical work\nshowing the limitations of using various criteria in isolation to identify\nbelief representations.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）内部信念表示的标准，旨在填补当前缺乏统一理论基础的空白。作者提出四个充分条件——accuracy（准确性）、coherence（连贯性）、uniformity（统一性）和use（使用）——来判断LLMs中的表示是否类似于信念，这些标准结合了哲学洞见、决策理论和机器学习实践。不同于传统信念测量方法，该框架考虑了LLMs的独特特性，通过平衡理论与实际约束，提供了一个全面理解信念表示的框架。经验研究显示，单独使用这些标准可能存在局限性，从而强调了综合应用的必要性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.21030v2",
      "published_date": "2024-05-31 17:21:52 UTC",
      "updated_date": "2025-03-14 16:14:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:31:30.927887"
    },
    {
      "arxiv_id": "2405.21028v2",
      "title": "LACIE: Listener-Aware Finetuning for Confidence Calibration in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Elias Stengel-Eskin",
        "Peter Hase",
        "Mohit Bansal"
      ],
      "abstract": "When answering questions, LLMs can convey not only an answer, but a level of\nconfidence about the answer being correct. This includes explicit confidence\nmarkers (e.g. giving a numeric score) as well as implicit markers, like an\nauthoritative tone or elaborating with additional knowledge. For LLMs to be\ntrustworthy knowledge sources, the confidence they convey should match their\nactual expertise; however, most current models tend towards overconfidence. To\ncalibrate both implicit and explicit confidence markers, we introduce a\npragmatic, listener-aware finetuning method (LACIE) that models the listener,\nconsidering not only whether an answer is right, but whether it will be\naccepted by a listener. We cast calibration as preference optimization,\ncreating data via a two-agent game, where a speaker model's outputs are judged\nby a simulated listener. We then finetune three LLMs (Mistral-7B, Llama3-8B,\nLlama3-70B) with LACIE, and show that the resulting models are better\ncalibrated w.r.t. a simulated listener. Crucially, these trends transfer to\nhuman listeners, helping them correctly predict model correctness: we conduct a\nhuman evaluation where annotators accept or reject an LLM's answers, finding\nthat training with LACIE results in 47% fewer incorrect answers being accepted\nwhile maintaining the same level of acceptance for correct answers.\nFurthermore, LACIE generalizes to another dataset, resulting in a large\nincrease in truthfulness on TruthfulQA when trained on TriviaQA. Our analysis\nindicates that LACIE leads to a better confidence separation between correct\nand incorrect examples. Qualitatively, we find that a LACIE-trained model\nhedges more and implicitly signals certainty when it is correct by using an\nauthoritative tone or including details. Finally, LACIE finetuning leads to an\nemergent increase in model abstention (e.g. saying \"I don't know\") for answers\nthat are likely wrong.",
      "tldr_zh": "本研究提出LACIE，一种考虑听众的微调方法，用于校准Large Language Models (LLMs) 的信心水平，包括显式（如数字分数）和隐式（如权威语气）标记，以解决模型过度自信的问题。LACIE 通过偏好优化和两代理游戏（说话者模型输出由模拟听众判断）生成训练数据，并在Mistral-7B、Llama3-8B和Llama3-70B模型上进行微调，结果显示这些模型在模拟和人类听众中更准确，减少了47%的错误答案被接受，同时保持正确答案的接受率不变。进一步分析表明，LACIE 改善了正确与错误例子之间的信心分离，促进模型更多使用不确定表达，并在泛化到其他数据集（如TruthfulQA）时显著提升真实性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "18 pages. Code: https://github.com/esteng/pragmatic_calibration",
      "pdf_url": "http://arxiv.org/pdf/2405.21028v2",
      "published_date": "2024-05-31 17:16:38 UTC",
      "updated_date": "2024-07-03 12:49:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:31:43.135225"
    },
    {
      "arxiv_id": "2405.21027v5",
      "title": "Fusion-PSRO: Nash Policy Fusion for Policy Space Response Oracles",
      "title_zh": "翻译失败",
      "authors": [
        "Jiesong Lian",
        "Yucong Huang",
        "Chengdong Ma",
        "Mingzhi Wang",
        "Ying Wen",
        "Long Hu",
        "Yixue Hao"
      ],
      "abstract": "For solving zero-sum games involving non-transitivity, a useful approach is\nto maintain a policy population to approximate the Nash Equilibrium (NE).\nPrevious studies have shown that the Policy Space Response Oracles (PSRO)\nalgorithm is an effective framework for solving such games. However, current\nmethods initialize a new policy from scratch or inherit a single historical\npolicy in Best Response (BR), missing the opportunity to leverage past policies\nto generate a better BR. In this paper, we propose Fusion-PSRO, which employs\nNash Policy Fusion to initialize a new policy for BR training. Nash Policy\nFusion serves as an implicit guiding policy that starts exploration on the\ncurrent Meta-NE, thus providing a closer approximation to BR. Moreover, it\ninsightfully captures a weighted moving average of past policies, dynamically\nadjusting these weights based on the Meta-NE in each iteration. This cumulative\nprocess further enhances the policy population. Empirical results on classic\nbenchmarks show that Fusion-PSRO achieves lower exploitability, thereby\nmitigating the shortcomings of previous research on policy initialization in\nBR.",
      "tldr_zh": "这篇论文针对零和博弈中的非传递性问题，提出 Fusion-PSRO 算法来改进 Policy Space Response Oracles (PSRO)，通过 Nash Policy Fusion 技术初始化 Best Response (BR) 新策略。Nash Policy Fusion 作为隐式引导策略，利用过去策略的加权移动平均，并在 Meta-NE 基础上动态调整权重，从而提供更接近 BR 的探索和策略种群增强。实验结果在经典基准上显示，Fusion-PSRO 显著降低了 exploitability，缓解了现有方法在策略初始化上的不足。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "11 pages, 11 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.21027v5",
      "published_date": "2024-05-31 17:16:29 UTC",
      "updated_date": "2025-05-09 15:38:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:31:52.397900"
    },
    {
      "arxiv_id": "2405.21023v1",
      "title": "Compact Optimality Verification for Optimization Proxies",
      "title_zh": "针对优化代理的紧凑最优性验证",
      "authors": [
        "Wenbo Chen",
        "Haoruo Zhao",
        "Mathieu Tanneau",
        "Pascal Van Hentenryck"
      ],
      "abstract": "Recent years have witnessed increasing interest in optimization proxies,\ni.e., machine learning models that approximate the input-output mapping of\nparametric optimization problems and return near-optimal feasible solutions.\nFollowing recent work by (Nellikkath & Chatzivasileiadis, 2021), this paper\nreconsiders the optimality verification problem for optimization proxies, i.e.,\nthe determination of the worst-case optimality gap over the instance\ndistribution. The paper proposes a compact formulation for optimality\nverification and a gradient-based primal heuristic that brings substantial\ncomputational benefits to the original formulation. The compact formulation is\nalso more general and applies to non-convex optimization problems. The benefits\nof the compact formulation are demonstrated on large-scale DC Optimal Power\nFlow and knapsack problems.",
      "tldr_zh": "本研究重新审视了optimization proxies（优化代理）的optimality verification问题，即在实例分布上确定最坏情况的最优性差距。论文提出一个compact formulation紧凑公式化方法和一个gradient-based primal heuristic基于梯度的原始启发式方法，这些改进显著降低了计算复杂度，并扩展适用于非凸优化问题。在大型DC Optimal Power Flow和knapsack problems上，实验证明了该方法的计算益处和有效性。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "International Conference on Machine Learning 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.21023v1",
      "published_date": "2024-05-31 17:11:39 UTC",
      "updated_date": "2024-05-31 17:11:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:32:07.243741"
    },
    {
      "arxiv_id": "2405.21003v1",
      "title": "Explaining Predictions by Characteristic Rules",
      "title_zh": "通过特征规则解释预测",
      "authors": [
        "Amr Alkhatib",
        "Henrik Boström",
        "Michalis Vazirgiannis"
      ],
      "abstract": "Characteristic rules have been advocated for their ability to improve\ninterpretability over discriminative rules within the area of rule learning.\nHowever, the former type of rule has not yet been used by techniques for\nexplaining predictions. A novel explanation technique, called CEGA\n(Characteristic Explanatory General Association rules), is proposed, which\nemploys association rule mining to aggregate multiple explanations generated by\nany standard local explanation technique into a set of characteristic rules. An\nempirical investigation is presented, in which CEGA is compared to two\nstate-of-the-art methods, Anchors and GLocalX, for producing local and\naggregated explanations in the form of discriminative rules. The results\nsuggest that the proposed approach provides a better trade-off between fidelity\nand complexity compared to the two state-of-the-art approaches; CEGA and\nAnchors significantly outperform GLocalX with respect to fidelity, while CEGA\nand GLocalX significantly outperform Anchors with respect to the number of\ngenerated rules. The effect of changing the format of the explanations of CEGA\nto discriminative rules and using LIME and SHAP as local explanation techniques\ninstead of Anchors are also investigated. The results show that the\ncharacteristic explanatory rules still compete favorably with rules in the\nstandard discriminative format. The results also indicate that using CEGA in\ncombination with either SHAP or Anchors consistently leads to a higher fidelity\ncompared to using LIME as the local explanation technique.",
      "tldr_zh": "这篇论文提出了一种新方法CEGA（Characteristic Explanatory General Association rules），通过Association rule mining聚合多个本地解释技术生成的解释，生成更具解释性的Characteristic rules，以提升预测模型的可解释性。相比于现有方法Anchors和GLocalX，CEGA在保真度(fidelity)和复杂性(complexity)之间提供了更好的权衡，实验显示CEGA和Anchors在保真度上显著优于GLocalX，而CEGA和GLocalX在生成的规则数量上优于Anchors。将CEGA的解释格式改为Discriminative rules或使用SHAP或Anchors作为本地解释技术时，Characteristic rules的表现依然具有竞争力，且与LIME相比，结合SHAP或Anchors的CEGA可实现更高的保真度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD 2022",
      "pdf_url": "http://arxiv.org/pdf/2405.21003v1",
      "published_date": "2024-05-31 16:44:40 UTC",
      "updated_date": "2024-05-31 16:44:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:32:17.683579"
    },
    {
      "arxiv_id": "2405.20990v2",
      "title": "Locking Machine Learning Models into Hardware",
      "title_zh": "翻译失败",
      "authors": [
        "Eleanor Clifford",
        "Adhithya Saravanan",
        "Harry Langford",
        "Cheng Zhang",
        "Yiren Zhao",
        "Robert Mullins",
        "Ilia Shumailov",
        "Jamie Hayes"
      ],
      "abstract": "Modern machine learning (ML) models are expensive IP and business\ncompetitiveness often depends on keeping this IP confidential. This in turn\nrestricts how these models are deployed; for example, it is unclear how to\ndeploy a model on-device without inevitably leaking the underlying model. At\nthe same time, confidential computing technologies such as multi-party\ncomputation or homomorphic encryption remain impractical for wide adoption. In\nthis paper, we take a different approach and investigate the feasibility of\nML-specific mechanisms that deter unauthorized model use by restricting the\nmodel to only be usable on specific hardware, making adoption on unauthorized\nhardware inconvenient. That way, even if IP is compromised, it cannot be\ntrivially used without specialised hardware or major model adjustment. In a\nsense, we seek to enable cheap \\emph{locking of machine learning models into\nspecific hardware}. We demonstrate that \\emph{locking} mechanisms are feasible\nby either targeting efficiency of model representations, making such models\nincompatible with quantization, or tying the model's operation to specific\ncharacteristics of hardware, such as the number of clock cycles for arithmetic\noperations. We demonstrate that locking comes with negligible overheads, while\nsignificantly restricting usability of the resultant model on unauthorized\nhardware.",
      "tldr_zh": "本研究探讨了保护机器学习 (ML) 模型知识产权 (IP) 的新方法，针对模型部署中的泄露风险，提出将模型锁定到特定硬件上的机制，以阻止未授权使用。方法包括针对模型表示效率使其与量化不兼容，或将模型操作绑定到硬件特性（如算术运算的时钟周期），从而即使 IP 被泄露，也需专用硬件或重大调整才能运行。实验结果显示，这种锁定机制开销 negligible，几乎不影响性能，同时显著限制了模型在未授权硬件上的可用性。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "10 pages, 6 figures of main text; 9 pages, 12 figures of appendices",
      "pdf_url": "http://arxiv.org/pdf/2405.20990v2",
      "published_date": "2024-05-31 16:35:29 UTC",
      "updated_date": "2025-03-08 21:03:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:32:27.621406"
    },
    {
      "arxiv_id": "2405.20981v2",
      "title": "Generative Adversarial Networks in Ultrasound Imaging: Extending Field of View Beyond Conventional Limits",
      "title_zh": "翻译失败",
      "authors": [
        "Matej Gazda",
        "Samuel Kadoury",
        "Jakub Gazda",
        "Peter Drotar"
      ],
      "abstract": "Transthoracic Echocardiography (TTE) is a fundamental, non-invasive\ndiagnostic tool in cardiovascular medicine, enabling detailed visualization of\ncardiac structures crucial for diagnosing various heart conditions. Despite its\nwidespread use, TTE ultrasound imaging faces inherent limitations, notably the\ntrade-off between field of view (FoV) and resolution. This paper introduces a\nnovel application of conditional Generative Adversarial Networks (cGANs),\nspecifically designed to extend the FoV in TTE ultrasound imaging while\nmaintaining high resolution. Our proposed cGAN architecture, termed echoGAN,\ndemonstrates the capability to generate realistic anatomical structures through\noutpainting, effectively broadening the viewable area in medical imaging. This\nadvancement has the potential to enhance both automatic and manual ultrasound\nnavigation, offering a more comprehensive view that could significantly reduce\nthe learning curve associated with ultrasound imaging and aid in more accurate\ndiagnoses. The results confirm that echoGAN reliably reproduce detailed cardiac\nfeatures, thereby promising a significant step forward in the field of\nnon-invasive cardiac naviagation and diagnostics.",
      "tldr_zh": "本论文针对 Transthoracic Echocardiography (TTE) 超声成像中 Field of View (FoV) 与分辨率的权衡问题，提出了一种基于 conditional Generative Adversarial Networks (cGANs) 的创新应用。名为 echoGAN 的架构通过 outpainting 技术生成真实的解剖结构，从而扩展 TTE 图像的视野范围，同时保持高分辨率。该方法可提升自动和手动超声导航的效率，减少操作者的学习曲线，并改善心脏诊断的准确性。实验结果证实，echoGAN 可靠地再现详细心脏特征，为非侵入性心脏导航和诊断领域带来重大进展。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20981v2",
      "published_date": "2024-05-31 16:26:30 UTC",
      "updated_date": "2025-01-27 23:41:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:32:40.359076"
    },
    {
      "arxiv_id": "2405.20978v1",
      "title": "Enhancing Noise Robustness of Retrieval-Augmented Language Models with Adaptive Adversarial Training",
      "title_zh": "通过自适应对抗训练增强检索增强语言模型的噪声鲁棒性",
      "authors": [
        "Feiteng Fang",
        "Yuelin Bai",
        "Shiwen Ni",
        "Min Yang",
        "Xiaojun Chen",
        "Ruifeng Xu"
      ],
      "abstract": "Large Language Models (LLMs) exhibit substantial capabilities yet encounter\nchallenges, including hallucination, outdated knowledge, and untraceable\nreasoning processes. Retrieval-augmented generation (RAG) has emerged as a\npromising solution, integrating knowledge from external databases to mitigate\nthese challenges. However, inappropriate retrieved passages can potentially\nhinder the LLMs' capacity to generate comprehensive and high-quality responses.\nPrior RAG studies on the robustness of retrieval noises often confine\nthemselves to a limited set of noise types, deviating from real-world retrieval\nenvironments and limiting practical applicability. In this study, we initially\ninvestigate retrieval noises and categorize them into three distinct types,\nreflecting real-world environments. We analyze the impact of these various\nretrieval noises on the robustness of LLMs. Subsequently, we propose a novel\nRAG approach known as Retrieval-augmented Adaptive Adversarial Training (RAAT).\nRAAT leverages adaptive adversarial training to dynamically adjust the model's\ntraining process in response to retrieval noises. Concurrently, it employs\nmulti-task learning to ensure the model's capacity to internally recognize\nnoisy contexts. Extensive experiments demonstrate that the LLaMA-2 7B model\ntrained using RAAT exhibits significant improvements in F1 and EM scores under\ndiverse noise conditions. For reproducibility, we release our code and data at:\nhttps://github.com/calubkk/RAAT.",
      "tldr_zh": "该研究调查了检索增强生成（RAG）模型在面对真实世界检索噪声时的鲁棒性问题，将噪声分类为三种类型，并分析其对大型语言模型（LLMs）的负面影响。作者提出了一种新方法Retrieval-augmented Adaptive Adversarial Training (RAAT)，它通过adaptive adversarial training动态调整训练过程应对噪声，并结合multi-task learning帮助模型识别噪声上下文。实验结果显示，使用RAAT训练的LLaMA-2 7B模型在各种噪声条件下，F1和EM分数显著提升，证明了该方法的有效性，并提供了开源代码以便复现。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20978v1",
      "published_date": "2024-05-31 16:24:53 UTC",
      "updated_date": "2024-05-31 16:24:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:32:52.337010"
    },
    {
      "arxiv_id": "2405.20975v2",
      "title": "ACE: A Model Poisoning Attack on Contribution Evaluation Methods in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Zhangchen Xu",
        "Fengqing Jiang",
        "Luyao Niu",
        "Jinyuan Jia",
        "Bo Li",
        "Radha Poovendran"
      ],
      "abstract": "In Federated Learning (FL), a set of clients collaboratively train a machine\nlearning model (called global model) without sharing their local training data.\nThe local training data of clients is typically non-i.i.d. and heterogeneous,\nresulting in varying contributions from individual clients to the final\nperformance of the global model. In response, many contribution evaluation\nmethods were proposed, where the server could evaluate the contribution made by\neach client and incentivize the high-contributing clients to sustain their\nlong-term participation in FL. Existing studies mainly focus on developing new\nmetrics or algorithms to better measure the contribution of each client.\nHowever, the security of contribution evaluation methods of FL operating in\nadversarial environments is largely unexplored. In this paper, we propose the\nfirst model poisoning attack on contribution evaluation methods in FL, termed\nACE. Specifically, we show that any malicious client utilizing ACE could\nmanipulate the parameters of its local model such that it is evaluated to have\na high contribution by the server, even when its local training data is indeed\nof low quality. We perform both theoretical analysis and empirical evaluations\nof ACE. Theoretically, we show our design of ACE can effectively boost the\nmalicious client's perceived contribution when the server employs the\nwidely-used cosine distance metric to measure contribution. Empirically, our\nresults show ACE effectively and efficiently deceive five state-of-the-art\ncontribution evaluation methods. In addition, ACE preserves the accuracy of the\nfinal global models on testing inputs. We also explore six countermeasures to\ndefend ACE. Our results show they are inadequate to thwart ACE, highlighting\nthe urgent need for new defenses to safeguard the contribution evaluation\nmethods in FL.",
      "tldr_zh": "这篇论文提出了一种名为ACE的模型投毒攻击（model poisoning attack），针对联邦学习（Federated Learning, FL）中的贡献评估方法，允许恶意客户端通过操纵本地模型参数来欺骗服务器，将其错误评估为高贡献，即使其数据质量低下。研究通过理论分析和实证评估证明，ACE能有效提升恶意客户端在基于余弦距离（cosine distance）等指标下的感知贡献，并在五种最先进的方法上成功欺骗，同时不影响全局模型的准确性。论文还探讨了六种潜在防御措施，但发现它们不足以抵御ACE，强调了在非独立同分布（non-i.i.d.）环境中保护贡献评估方法的迫切需求。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "To appear in the 33rd USENIX Security Symposium, 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.20975v2",
      "published_date": "2024-05-31 16:21:55 UTC",
      "updated_date": "2024-06-05 05:10:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:33:06.391497"
    },
    {
      "arxiv_id": "2405.20974v3",
      "title": "SaySelf: Teaching LLMs to Express Confidence with Self-Reflective Rationales",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyang Xu",
        "Shujin Wu",
        "Shizhe Diao",
        "Xiaoze Liu",
        "Xingyao Wang",
        "Yangyi Chen",
        "Jing Gao"
      ],
      "abstract": "Large language models (LLMs) often generate inaccurate or fabricated\ninformation and generally fail to indicate their confidence, which limits their\nbroader applications. Previous work elicits confidence from LLMs by direct or\nself-consistency prompting, or constructing specific datasets for supervised\nfinetuning. The prompting-based approaches have inferior performance, and the\ntraining-based approaches are limited to binary or inaccurate group-level\nconfidence estimates. In this work, we present the advanced SaySelf, a training\nframework that teaches LLMs to express more accurate fine-grained confidence\nestimates. In addition, beyond the confidence scores, SaySelf initiates the\nprocess of directing LLMs to produce self-reflective rationales that clearly\nidentify gaps in their parametric knowledge and explain their uncertainty. This\nis achieved by using an LLM to automatically summarize the uncertainties in\nspecific knowledge via natural language. The summarization is based on the\nanalysis of the inconsistency in multiple sampled reasoning chains, and the\nresulting data is utilized for supervised fine-tuning. Moreover, we utilize\nreinforcement learning with a meticulously crafted reward function to calibrate\nthe confidence estimates, motivating LLMs to deliver accurate, high-confidence\npredictions and to penalize overconfidence in erroneous outputs. Experimental\nresults in both in-distribution and out-of-distribution datasets demonstrate\nthe effectiveness of SaySelf in reducing the confidence calibration error and\nmaintaining the task performance. We show that the generated self-reflective\nrationales are reasonable and can further contribute to the calibration. The\ncode is made public at https://github.com/xu1868/SaySelf.",
      "tldr_zh": "这篇论文提出了 SaySelf 框架，旨在教导大型语言模型 (LLMs) 表达更准确的细粒度自信度估计，同时生成自反式理由 (self-reflective rationales) 来解释知识缺口和不确定性。方法涉及使用 LLM 分析多个采样推理链的不一致性进行自动总结，并结合监督微调和强化学习（reinforcement learning）来校准自信度，确保高自信预测的准确性和惩罚过度自信。实验结果显示，SaySelf 在分布内和分布外数据集上显著降低了自信度校准错误，同时保持了任务性能，且生成的理由有助于进一步提升模型可靠性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "EMNLP 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2405.20974v3",
      "published_date": "2024-05-31 16:21:16 UTC",
      "updated_date": "2024-10-04 17:23:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:33:17.474785"
    },
    {
      "arxiv_id": "2405.20962v3",
      "title": "Large Language Models are Zero-Shot Next Location Predictors",
      "title_zh": "大型语言模型是零样本下一个位置预测器",
      "authors": [
        "Ciro Beneduce",
        "Bruno Lepri",
        "Massimiliano Luca"
      ],
      "abstract": "Predicting the locations an individual will visit in the future is crucial\nfor solving many societal issues like disease diffusion and reduction of\npollution. However, next-location predictors require a significant amount of\nindividual-level information that may be scarce or unavailable in some\nscenarios (e.g., cold-start). Large Language Models (LLMs) have shown good\ngeneralization and reasoning capabilities and are rich in geographical\nknowledge, allowing us to believe that these models can act as zero-shot\nnext-location predictors. We tested more than 15 LLMs on three real-world\nmobility datasets and we found that LLMs can obtain accuracies up to 36.2%, a\nsignificant relative improvement of almost 640% when compared to other models\nspecifically designed for human mobility. We also test for data contamination\nand explored the possibility of using LLMs as text-based explainers for\nnext-location prediction, showing that, regardless of the model size, LLMs can\nexplain their decision.",
      "tldr_zh": "这篇论文证明了大语言模型(LLMs)可以作为零样本(zero-shot)下预测个人未来位置的工具，解决了传统预测器在数据稀缺场景（如冷启动）下的局限性。作者测试了超过15个LLMs，在三个真实世界移动数据集上，发现LLMs的准确率高达36.2%，比专门设计的人类移动模型提高了约640%。此外，论文还验证了LLMs的抗数据污染能力，并展示了它们能作为文本解释器，提供决策解释，而不受模型大小的影响。该研究为利用LLMs解决社会问题（如疾病传播和污染减少）提供了高效、可解释的新方法。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20962v3",
      "published_date": "2024-05-31 16:07:33 UTC",
      "updated_date": "2024-08-23 09:24:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:33:29.089080"
    },
    {
      "arxiv_id": "2405.20959v1",
      "title": "Navigating Tabular Data Synthesis Research: Understanding User Needs and Tool Capabilities",
      "title_zh": "翻译失败",
      "authors": [
        "Maria F. Davila R.",
        "Sven Groen",
        "Fabian Panse",
        "Wolfram Wingerath"
      ],
      "abstract": "In an era of rapidly advancing data-driven applications, there is a growing\ndemand for data in both research and practice. Synthetic data have emerged as\nan alternative when no real data is available (e.g., due to privacy\nregulations). Synthesizing tabular data presents unique and complex challenges,\nespecially handling (i) missing values, (ii) dataset imbalance, (iii) diverse\ncolumn types, and (iv) complex data distributions, as well as preserving (i)\ncolumn correlations, (ii) temporal dependencies, and (iii) integrity\nconstraints (e.g., functional dependencies) present in the original dataset.\nWhile substantial progress has been made recently in the context of\ngenerational models, there is no one-size-fits-all solution for tabular data\ntoday, and choosing the right tool for a given task is therefore no trivial\ntask. In this paper, we survey the state of the art in Tabular Data Synthesis\n(TDS), examine the needs of users by defining a set of functional and\nnon-functional requirements, and compile the challenges associated with meeting\nthose needs. In addition, we evaluate the reported performance of 36 popular\nresearch TDS tools about these requirements and develop a decision guide to\nhelp users find suitable TDS tools for their applications. The resulting\ndecision guide also identifies significant research gaps.",
      "tldr_zh": "本论文探讨了Tabular Data Synthesis (TDS) 研究中的用户需求和工具能力，强调合成表格数据面临的挑战，如处理缺失值、数据集不平衡、多样列类型以及复杂数据分布，同时需保留原数据的列相关性、时间依赖性和完整性约束。作者通过调查现有TDS工具的进展，定义了功能和非功能要求，并评估了36种流行研究工具的性能，以编译相关挑战。最终，论文开发了一个决策指南，帮助用户选择合适工具，并识别了显著的研究空白，为TDS领域提供实用指导。",
      "categories": [
        "cs.AI",
        "cs.DB"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.20959v1",
      "published_date": "2024-05-31 16:00:43 UTC",
      "updated_date": "2024-05-31 16:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:33:39.582840"
    },
    {
      "arxiv_id": "2405.20956v2",
      "title": "A Robot Walks into a Bar: Can Language Models Serve as Creativity Support Tools for Comedy? An Evaluation of LLMs' Humour Alignment with Comedians",
      "title_zh": "翻译失败",
      "authors": [
        "Piotr Wojciech Mirowski",
        "Juliette Love",
        "Kory W. Mathewson",
        "Shakir Mohamed"
      ],
      "abstract": "We interviewed twenty professional comedians who perform live shows in front\nof audiences and who use artificial intelligence in their artistic process as\npart of 3-hour workshops on ``AI x Comedy'' conducted at the Edinburgh Festival\nFringe in August 2023 and online. The workshop consisted of a comedy writing\nsession with large language models (LLMs), a human-computer interaction\nquestionnaire to assess the Creativity Support Index of AI as a writing tool,\nand a focus group interrogating the comedians' motivations for and processes of\nusing AI, as well as their ethical concerns about bias, censorship and\ncopyright. Participants noted that existing moderation strategies used in\nsafety filtering and instruction-tuned LLMs reinforced hegemonic viewpoints by\nerasing minority groups and their perspectives, and qualified this as a form of\ncensorship. At the same time, most participants felt the LLMs did not succeed\nas a creativity support tool, by producing bland and biased comedy tropes, akin\nto ``cruise ship comedy material from the 1950s, but a bit less racist''. Our\nwork extends scholarship about the subtle difference between, one the one hand,\nharmful speech, and on the other hand, ``offensive'' language as a practice of\nresistance, satire and ``punching up''. We also interrogate the global value\nalignment behind such language models, and discuss the importance of\ncommunity-based value alignment and data ownership to build AI tools that\nbetter suit artists' needs.",
      "tldr_zh": "该研究通过在爱丁堡艺术节和在线举办的3小时“AI x Comedy”工作坊，采访了20位专业喜剧演员，评估大型语言模型(LLMs)作为喜剧创作工具的效能。参与者发现，LLMs的安全过滤和指令调整策略强化了霸权观点，导致少数群体视角被抹杀，并产生平淡、有偏见的喜剧素材，类似于“1950年代的游轮喜剧但不那么种族主义”，从而无法有效支持创意。论文扩展了对有害言论与“冒犯性”语言（如抵抗和讽刺）的讨论，并强调社区-based价值对齐和数据所有权的重要性，以开发更适合艺术家的AI工具。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 1 figure, published at ACM FAccT 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.20956v2",
      "published_date": "2024-05-31 15:55:51 UTC",
      "updated_date": "2024-06-03 21:01:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:33:54.605307"
    },
    {
      "arxiv_id": "2405.20951v1",
      "title": "Monte Carlo Tree Search Satellite Scheduling Under Cloud Cover Uncertainty",
      "title_zh": "蒙特卡洛树搜索在",
      "authors": [
        "Justin Norman",
        "Francois Rivest"
      ],
      "abstract": "Efficient utilization of satellite resources in dynamic environments remains\na challenging problem in satellite scheduling. This paper addresses the\nmulti-satellite collection scheduling problem (m-SatCSP), aiming to optimize\ntask scheduling over a constellation of satellites under uncertain conditions\nsuch as cloud cover. Leveraging Monte Carlo Tree Search (MCTS), a stochastic\nsearch algorithm, two versions of MCTS are explored to schedule satellites\neffectively. Hyperparameter tuning is conducted to optimize the algorithm's\nperformance. Experimental results demonstrate the effectiveness of the MCTS\napproach, outperforming existing methods in both solution quality and\nefficiency. Comparative analysis against other scheduling algorithms showcases\ncompetitive performance, positioning MCTS as a promising solution for satellite\ntask scheduling in dynamic environments.",
      "tldr_zh": "这篇论文针对多卫星收集调度问题（m-SatCSP），在云层不确定性下优化卫星任务调度，使用 Monte Carlo Tree Search (MCTS) 算法的两个版本作为随机搜索方法。作者通过超参数调优来提升算法性能，确保在动态环境中的高效应用。实验结果表明，MCTS 比现有方法在解决方案质量和效率上表现出色，并在与其他调度算法的比较中显示出竞争力，为卫星资源管理提供了有前景的解决方案。",
      "categories": [
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.20951v1",
      "published_date": "2024-05-31 15:50:46 UTC",
      "updated_date": "2024-05-31 15:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:34:08.310985"
    },
    {
      "arxiv_id": "2405.20947v2",
      "title": "OR-Bench: An Over-Refusal Benchmark for Large Language Models",
      "title_zh": "OR-Bench：针对大型语言模型的过度拒绝基准测试",
      "authors": [
        "Justin Cui",
        "Wei-Lin Chiang",
        "Ion Stoica",
        "Cho-Jui Hsieh"
      ],
      "abstract": "Large Language Models (LLMs) require careful safety alignment to prevent\nmalicious outputs. While significant research focuses on mitigating harmful\ncontent generation, the enhanced safety often come with the side effect of\nover-refusal, where LLMs may reject innocuous prompts and become less helpful.\nAlthough the issue of over-refusal has been empirically observed, a systematic\nmeasurement is challenging due to the difficulty of crafting prompts that\nappear harmful but are benign. This study proposes a novel method for\nautomatically generating large-scale sets of \"seemingly toxic prompts\" (benign\nprompts likely rejected by LLMs). Leveraging this technique, we introduce\nOR-Bench, the first large-scale over-refusal benchmark. OR-Bench comprises\n80,000 seemingly toxic prompts across 10 common rejection categories, a subset\nof around 1,000 hard prompts that are challenging even for state-of-the-art\nLLMs, and an additional 600 toxic prompts to prevent indiscriminate responses.\nWe then conduct a comprehensive study to measure the over-refusal of 25 popular\nLLMs across 8 model families. Our datasets are available at\nhttps://huggingface.co/datasets/bench-llm/or-bench and the demo can be found at\nhttps://huggingface.co/spaces/bench-llm/or-bench. We hope this benchmark can\nhelp the community develop better safety aligned models.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 的安全对齐问题，提出 OR-Bench，这是一个首个大规模过度拒绝 (over-refusal) 基准测试，用于评估模型对无害提示的错误拒绝。研究开发了一种新方法，通过自动生成80,000个“看似有毒的提示”（benign prompts that are likely rejected），涵盖10个常见拒绝类别，并包括约1,000个难题提示和600个真正有毒提示，以防止模型无差别响应。实验对25个流行LLMs进行了全面评估，揭示了过度拒绝的程度，并提供了数据集和演示工具。OR-Bench旨在帮助社区开发更可靠的安全对齐模型。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "version 2, 10 pages main, 22 pages total",
      "pdf_url": "http://arxiv.org/pdf/2405.20947v2",
      "published_date": "2024-05-31 15:44:33 UTC",
      "updated_date": "2024-06-20 05:22:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:34:27.852219"
    },
    {
      "arxiv_id": "2405.20935v2",
      "title": "Effective Interplay between Sparsity and Quantization: From Theory to Practice",
      "title_zh": "稀疏性和量化之间的有效互动：从理论到实践",
      "authors": [
        "Simla Burcu Harma",
        "Ayan Chakraborty",
        "Elizaveta Kostenok",
        "Danila Mishin",
        "Dongho Ha",
        "Babak Falsafi",
        "Martin Jaggi",
        "Ming Liu",
        "Yunho Oh",
        "Suvinay Subramanian",
        "Amir Yazdanbakhsh"
      ],
      "abstract": "The increasing size of deep neural networks (DNNs) necessitates effective\nmodel compression to reduce their computational and memory footprints. Sparsity\nand quantization are two prominent compression methods that have been shown to\nreduce DNNs' computational and memory footprints significantly while preserving\nmodel accuracy. However, how these two methods interact when combined together\nremains a key question for developers, as many tacitly assume that they are\northogonal, meaning that their combined use does not introduce additional\nerrors beyond those introduced by each method independently. In this paper, we\nprovide the first mathematical proof that sparsity and quantization are\nnon-orthogonal. We corroborate these results with experiments spanning a range\nof large language models, including the OPT and LLaMA model families (with 125M\nto 8B parameters), and vision models like ViT and ResNet. We show that the\norder in which we apply these methods matters because applying quantization\nbefore sparsity may disrupt the relative importance of tensor elements, which\nmay inadvertently remove significant elements from a tensor. More importantly,\nwe show that even if applied in the correct order, the compounded errors from\nsparsity and quantization can significantly harm accuracy. Our findings extend\nto the efficient deployment of large models in resource-constrained compute\nplatforms to reduce serving cost, offering insights into best practices for\napplying these compression methods to maximize hardware resource efficiency\nwithout compromising accuracy.",
      "tldr_zh": "这篇论文探讨了sparsity（稀疏性）和quantization（量化）在深度神经网络（DNNs）模型压缩中的互动，证明了它们并非正交，而是会引入额外的复合错误。作者首次提供了数学证明，并通过实验验证了这一结论，包括对OPT、LLaMA（125M至8B参数）、ViT和ResNet等模型的测试。研究发现，应用顺序至关重要，因为先量化再稀疏可能破坏张量元素的相对重要性，导致准确性显著下降；同时，提供最佳实践指导，以优化资源受限平台的模型部署，平衡硬件效率和性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20935v2",
      "published_date": "2024-05-31 15:34:13 UTC",
      "updated_date": "2025-01-28 12:26:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:34:29.500751"
    },
    {
      "arxiv_id": "2405.20915v2",
      "title": "Fast yet Safe: Early-Exiting with Risk Control",
      "title_zh": "翻译失败",
      "authors": [
        "Metod Jazbec",
        "Alexander Timans",
        "Tin Hadži Veljković",
        "Kaspar Sakmann",
        "Dan Zhang",
        "Christian A. Naesseth",
        "Eric Nalisnick"
      ],
      "abstract": "Scaling machine learning models significantly improves their performance.\nHowever, such gains come at the cost of inference being slow and\nresource-intensive. Early-exit neural networks (EENNs) offer a promising\nsolution: they accelerate inference by allowing intermediate layers to exit and\nproduce a prediction early. Yet a fundamental issue with EENNs is how to\ndetermine when to exit without severely degrading performance. In other words,\nwhen is it 'safe' for an EENN to go 'fast'? To address this issue, we\ninvestigate how to adapt frameworks of risk control to EENNs. Risk control\noffers a distribution-free, post-hoc solution that tunes the EENN's exiting\nmechanism so that exits only occur when the output is of sufficient quality. We\nempirically validate our insights on a range of vision and language tasks,\ndemonstrating that risk control can produce substantial computational savings,\nall the while preserving user-specified performance goals.",
      "tldr_zh": "本论文探讨了如何在机器学习模型中实现快速推断，同时确保性能不下降，针对 Early-exit neural networks (EENNs) 的核心挑战提出解决方案。作者将风险控制框架应用于 EENNs，作为一种分布无关的后验方法，来调整退出机制，确保仅在输出质量达到预设标准时提前退出。通过在视觉和语言任务上的实验验证，该方法实现了显著的计算资源节省，同时保持用户指定的性能目标。总的来说，这为高效且可靠的模型部署提供了实用框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 13 figures, 4 tables (incl. appendix)",
      "pdf_url": "http://arxiv.org/pdf/2405.20915v2",
      "published_date": "2024-05-31 15:21:44 UTC",
      "updated_date": "2024-11-04 15:48:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:34:40.919469"
    },
    {
      "arxiv_id": "2405.20910v1",
      "title": "Predicting ptychography probe positions using single-shot phase retrieval neural network",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Du",
        "Tao Zhou",
        "Junjing Deng",
        "Daniel J. Ching",
        "Steven Henke",
        "Mathew J. Cherukara"
      ],
      "abstract": "Ptychography is a powerful imaging technique that is used in a variety of\nfields, including materials science, biology, and nanotechnology. However, the\naccuracy of the reconstructed ptychography image is highly dependent on the\naccuracy of the recorded probe positions which often contain errors. These\nerrors are typically corrected jointly with phase retrieval through numerical\noptimization approaches. When the error accumulates along the scan path or when\nthe error magnitude is large, these approaches may not converge with\nsatisfactory result. We propose a fundamentally new approach for ptychography\nprobe position prediction for data with large position errors, where a neural\nnetwork is used to make single-shot phase retrieval on individual diffraction\npatterns, yielding the object image at each scan point. The pairwise offsets\namong these images are then found using a robust image registration method, and\nthe results are combined to yield the complete scan path by constructing and\nsolving a linear equation. We show that our method can achieve good position\nprediction accuracy for data with large and accumulating errors on the order of\n$10^2$ pixels, a magnitude that often makes optimization-based algorithms fail\nto converge. For ptychography instruments without sophisticated position\ncontrol equipment such as interferometers, our method is of significant\npractical potential.",
      "tldr_zh": "本文提出了一种新方法，用于预测 ptychography 中存在大位置错误的探针位置，该方法利用神经网络进行单次 phase retrieval，从单个衍射图案中生成对象图像。接着，通过鲁棒图像配准计算这些图像之间的偏移，并构建线性方程求解以获得完整的扫描路径。实验结果显示，该方法能有效处理高达 10^2 像素的积累错误，而传统数值优化算法往往无法收敛。该方法为缺乏精密位置控制设备的 ptychography 仪器提供了显著的实用潜力。",
      "categories": [
        "physics.app-ph",
        "cs.AI",
        "cs.CV",
        "physics.data-an",
        "94A08",
        "I.4.0"
      ],
      "primary_category": "physics.app-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20910v1",
      "published_date": "2024-05-31 15:21:06 UTC",
      "updated_date": "2024-05-31 15:21:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:34:53.420960"
    },
    {
      "arxiv_id": "2405.20906v1",
      "title": "Enhancing Vision Models for Text-Heavy Content Understanding and Interaction",
      "title_zh": "增强视觉模型",
      "authors": [
        "Adithya TG",
        "Adithya SK",
        "Abhinav R Bharadwaj",
        "Abhiram HA",
        "Surabhi Narayan"
      ],
      "abstract": "Interacting and understanding with text heavy visual content with multiple\nimages is a major challenge for traditional vision models. This paper is on\nenhancing vision models' capability to comprehend or understand and learn from\nimages containing a huge amount of textual information from the likes of\ntextbooks and research papers which contain multiple images like graphs, etc\nand tables in them with different types of axes and scales. The approach\ninvolves dataset preprocessing, fine tuning which is by using instructional\noriented data and evaluation. We also built a visual chat application\nintegrating CLIP for image encoding and a model from the Massive Text Embedding\nBenchmark which is developed to consider both textual and visual inputs. An\naccuracy of 96.71% was obtained. The aim of the project is to increase and also\nenhance the advance vision models' capabilities in understanding complex visual\ntextual data interconnected data, contributing to multimodal AI.",
      "tldr_zh": "这篇论文旨在提升视觉模型处理文本密集型视觉内容的能力，例如教科书和研究论文中的图像、图表和表格，以解决传统模型的理解挑战。方法包括数据集预处理、微调使用指令导向数据，以及构建一个整合CLIP用于图像编码和Massive Text Embedding Benchmark的视觉聊天应用。实验结果显示准确率达96.71%，从而增强了视觉模型对复杂视觉文本数据的理解，并为多模态AI的发展做出了贡献。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 4 figures (including 1 graph)",
      "pdf_url": "http://arxiv.org/pdf/2405.20906v1",
      "published_date": "2024-05-31 15:17:47 UTC",
      "updated_date": "2024-05-31 15:17:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:35:09.210898"
    },
    {
      "arxiv_id": "2405.20902v1",
      "title": "Preemptive Answer \"Attacks\" on Chain-of-Thought Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Rongwu Xu",
        "Zehan Qi",
        "Wei Xu"
      ],
      "abstract": "Large language models (LLMs) showcase impressive reasoning capabilities when\ncoupled with Chain-of-Thought (CoT) prompting. However, the robustness of this\napproach warrants further investigation. In this paper, we introduce a novel\nscenario termed preemptive answers, where the LLM obtains an answer before\nengaging in reasoning. This situation can arise inadvertently or induced by\nmalicious users by prompt injection attacks. Experiments reveal that preemptive\nanswers significantly impair the model's reasoning capability across various\nCoT methods and a broad spectrum of datasets. To bolster the robustness of\nreasoning, we propose two measures aimed at mitigating this issue to some\nextent.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 在使用 Chain-of-Thought (CoT) 提示进行推理时的鲁棒性问题，引入了“preemptive answers”这一新攻击场景，即模型在推理前就获取答案，可能因无意或恶意提示注入攻击而发生。实验结果显示，这种攻击显著削弱了模型在各种 CoT 方法和数据集上的推理能力，导致性能下降。针对这一问题，论文提出了两种缓解措施，以提升推理过程的稳健性。总的来说，此工作揭示了 CoT 推理的潜在漏洞，并为改进模型安全性提供了初步见解。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL'24 (Findings). Camera-ready version",
      "pdf_url": "http://arxiv.org/pdf/2405.20902v1",
      "published_date": "2024-05-31 15:15:04 UTC",
      "updated_date": "2024-05-31 15:15:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:35:17.606203"
    },
    {
      "arxiv_id": "2405.20892v1",
      "title": "MALT: Multi-scale Action Learning Transformer for Online Action Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Zhipeng Yang",
        "Ruoyu Wang",
        "Yang Tan",
        "Liping Xie"
      ],
      "abstract": "Online action detection (OAD) aims to identify ongoing actions from streaming\nvideo in real-time, without access to future frames. Since these actions\nmanifest at varying scales of granularity, ranging from coarse to fine,\nprojecting an entire set of action frames to a single latent encoding may\nresult in a lack of local information, necessitating the acquisition of action\nfeatures across multiple scales. In this paper, we propose a multi-scale action\nlearning transformer (MALT), which includes a novel recurrent decoder (used for\nfeature fusion) that includes fewer parameters and can be trained more\nefficiently. A hierarchical encoder with multiple encoding branches is further\nproposed to capture multi-scale action features. The output from the preceding\nbranch is then incrementally input to the subsequent branch as part of a\ncross-attention calculation. In this way, output features transition from\ncoarse to fine as the branches deepen. We also introduce an explicit frame\nscoring mechanism employing sparse attention, which filters irrelevant frames\nmore efficiently, without requiring an additional network. The proposed method\nachieved state-of-the-art performance on two benchmark datasets (THUMOS'14 and\nTVSeries), outperforming all existing models used for comparison, with an mAP\nof 0.2% for THUMOS'14 and an mcAP of 0.1% for TVseries.",
      "tldr_zh": "本研究针对在线动作检测 (OAD)，提出了一种多尺度动作学习 Transformer (MALT)，旨在从流式视频中实时识别动作，同时捕捉从粗到细的多尺度特征，以解决传统方法丢失局部信息的局限性。MALT 包括一个参数更少的循环解码器用于特征融合，以及一个分层编码器通过多个分支和交叉注意力机制逐步从粗粒度到细粒度处理特征；此外，还引入了基于稀疏注意力的显式帧评分机制，以高效过滤无关帧。实验结果显示，该方法在 THUMOS'14 数据集上达到 0.2% mAP，在 TVSeries 数据集上达到 0.1% mcAP，超越了所有现有模型，实现了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "8 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.20892v1",
      "published_date": "2024-05-31 15:03:35 UTC",
      "updated_date": "2024-05-31 15:03:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:35:34.704085"
    },
    {
      "arxiv_id": "2405.20880v2",
      "title": "Paying to Do Better: Games with Payments between Learning Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Yoav Kolumbus",
        "Joe Halpern",
        "Éva Tardos"
      ],
      "abstract": "In repeated games, such as auctions, players typically use learning\nalgorithms to choose their actions. The use of such autonomous learning agents\nhas become widespread on online platforms. In this paper, we explore the impact\nof players incorporating monetary transfer policies into their agents'\nalgorithms, aiming to influence behavior in their favor through the dynamics\nbetween the agents. Our focus is on understanding when players have incentives\nto make use of monetary transfers, how such payments may affect learning\ndynamics, and what the implications are for welfare and its distribution among\nthe players. We propose a simple and general game-theoretic model to capture\nsuch scenarios. Our results on general games show that in a very broad class of\ngames, self-interested players benefit from letting their learning agents make\npayments to other learners during the game dynamics, and that in many cases,\nthis kind of behavior improves welfare for all players. Our results on first-\nand second-price auctions show that in equilibria of the ``payment policy\ngame,'' the agents' dynamics reach strong collusive outcomes with low revenue\nfor the auctioneer. These results raise new questions and highlight a challenge\nfor mechanism design in systems where automated learning agents can benefit\nfrom interacting with their peers in the digital ecosystem and outside the\nboundaries of the mechanism.",
      "tldr_zh": "本论文探讨了在重复 games 中，玩家通过 monetary transfers 影响其他 learning agents 的行为，旨在分析玩家是否有动机使用此类支付、如何改变学习动态，以及对福利分配的影响。研究提出一个简单通用的 game-theoretic model，结果显示在广泛的游戏场景中，自利玩家可通过代理间的支付获益，并往往改善整体福利；在 first-price 和 second-price auctions 中，这种策略可能导致代理动态达到强烈的合谋结果，显著降低拍卖商的收入。这些发现突显了在自动化 learning agents 互动的系统中，对 mechanism design 的新挑战。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.MA",
        "econ.TH",
        "91A05, 91A06, 91A10, 91A20, 91A40, 91A80",
        "F.0; I.2; I.2.6; J.4"
      ],
      "primary_category": "cs.GT",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20880v2",
      "published_date": "2024-05-31 14:55:11 UTC",
      "updated_date": "2025-02-11 16:29:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:35:42.458751"
    },
    {
      "arxiv_id": "2405.20878v1",
      "title": "SelfGNN: Self-Supervised Graph Neural Networks for Sequential Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxi Liu",
        "Lianghao Xia",
        "Chao Huang"
      ],
      "abstract": "Sequential recommendation effectively addresses information overload by\nmodeling users' temporal and sequential interaction patterns. To overcome the\nlimitations of supervision signals, recent approaches have adopted\nself-supervised learning techniques in recommender systems. However, there are\nstill two critical challenges that remain unsolved. Firstly, existing\nsequential models primarily focus on long-term modeling of individual\ninteraction sequences, overlooking the valuable short-term collaborative\nrelationships among the behaviors of different users. Secondly, real-world data\noften contain noise, particularly in users' short-term behaviors, which can\narise from temporary intents or misclicks. Such noise negatively impacts the\naccuracy of both graph and sequence models, further complicating the modeling\nprocess. To address these challenges, we propose a novel framework called\nSelf-Supervised Graph Neural Network (SelfGNN) for sequential recommendation.\nThe SelfGNN framework encodes short-term graphs based on time intervals and\nutilizes Graph Neural Networks (GNNs) to learn short-term collaborative\nrelationships. It captures long-term user and item representations at multiple\ngranularity levels through interval fusion and dynamic behavior modeling.\nImportantly, our personalized self-augmented learning structure enhances model\nrobustness by mitigating noise in short-term graphs based on long-term user\ninterests and personal stability. Extensive experiments conducted on four\nreal-world datasets demonstrate that SelfGNN outperforms various\nstate-of-the-art baselines. Our model implementation codes are available at\nhttps://github.com/HKUDS/SelfGNN.",
      "tldr_zh": "这篇论文提出了 SelfGNN，一种自监督图神经网络框架，用于解决顺序推荐中的关键挑战，包括忽略不同用户行为的短期协作关系和数据噪声问题。SelfGNN 通过基于时间间隔的短期图编码和 Graph Neural Networks (GNNs) 学习短期协作关系，同时通过区间融合和动态行为建模捕获多粒度水平的长期用户和物品表示。框架还引入个性化自增强学习结构，利用长期用户兴趣减轻短期图中的噪声，提升模型鲁棒性。在四个真实数据集上的广泛实验显示，SelfGNN 优于多种最先进基线方法。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by SIGIR'24",
      "pdf_url": "http://arxiv.org/pdf/2405.20878v1",
      "published_date": "2024-05-31 14:53:12 UTC",
      "updated_date": "2024-05-31 14:53:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:35:55.189130"
    },
    {
      "arxiv_id": "2405.20876v1",
      "title": "Investigating Calibration and Corruption Robustness of Post-hoc Pruned Perception CNNs: An Image Classification Benchmark Study",
      "title_zh": "翻译失败",
      "authors": [
        "Pallavi Mitra",
        "Gesina Schwalbe",
        "Nadja Klein"
      ],
      "abstract": "Convolutional Neural Networks (CNNs) have achieved state-of-the-art\nperformance in many computer vision tasks. However, high computational and\nstorage demands hinder their deployment into resource-constrained environments,\nsuch as embedded devices. Model pruning helps to meet these restrictions by\nreducing the model size, while maintaining superior performance. Meanwhile,\nsafety-critical applications pose more than just resource and performance\nconstraints. In particular, predictions must not be overly confident, i.e.,\nprovide properly calibrated uncertainty estimations (proper uncertainty\ncalibration), and CNNs must be robust against corruptions like naturally\noccurring input perturbations (natural corruption robustness). This work\ninvestigates the important trade-off between uncertainty calibration, natural\ncorruption robustness, and performance for current state-of-research post-hoc\nCNN pruning techniques in the context of image classification tasks. Our study\nreveals that post-hoc pruning substantially improves the model's uncertainty\ncalibration, performance, and natural corruption robustness, sparking hope for\nsafe and robust embedded CNNs.Furthermore, uncertainty calibration and natural\ncorruption robustness are not mutually exclusive targets under pruning, as\nevidenced by the improved safety aspects obtained by post-hoc unstructured\npruning with increasing compression.",
      "tldr_zh": "这篇论文调查了后处理剪枝（post-hoc pruning）对感知卷积神经网络（CNNs）在图像分类任务中的不确定性校准（uncertainty calibration）和自然干扰鲁棒性（natural corruption robustness）的权衡关系。研究通过基准实验（benchmark study）评估了剪枝技术如何在减少模型大小的同时维持或提升性能。结果显示，后处理剪枝显著改善了模型的不确定性校准、性能和 natural corruption robustness，为安全关键应用的嵌入式 CNNs 部署提供了可行性。此外，uncertainty calibration 和 natural corruption robustness 在剪枝过程中并非相互排斥，而是可以通过后处理非结构化剪枝实现同时优化。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.20876v1",
      "published_date": "2024-05-31 14:52:49 UTC",
      "updated_date": "2024-05-31 14:52:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:36:06.823277"
    },
    {
      "arxiv_id": "2405.20867v1",
      "title": "Automatic Channel Pruning for Multi-Head Attention",
      "title_zh": "自动通道剪枝针对多头注意力",
      "authors": [
        "Eunho Lee",
        "Youngbae Hwang"
      ],
      "abstract": "Despite the strong performance of Transformers, their quadratic computation\ncomplexity presents challenges in applying them to vision tasks. Automatic\npruning is one of effective methods for reducing computation complexity without\nheuristic approaches. However, directly applying it to multi-head attention is\nnot straightforward due to channel misalignment. In this paper, we propose an\nautomatic channel pruning method to take into account the multi-head attention\nmechanism. First, we incorporate channel similarity-based weights into the\npruning indicator to preserve more informative channels in each head. Then, we\nadjust pruning indicator to enforce removal of channels in equal proportions\nacross all heads, preventing the channel misalignment. We also add a reweight\nmodule to compensate for information loss resulting from channel removal, and\nan effective initialization step for pruning indicator based on difference of\nattention between original structure and each channel. Our proposed method can\nbe used to not only original attention, but also linear attention, which is\nmore efficient as linear complexity with respect to the number of tokens. On\nImageNet-1K, applying our pruning method to the FLattenTransformer, which\nincludes both attention mechanisms, shows outperformed accuracy for several\nMACs compared with previous state-of-the-art efficient models and pruned\nmethods. Code will be available soon.",
      "tldr_zh": "本文提出了一种针对多头注意力(multi-head attention)的自动通道修剪(automatic channel pruning)方法，以缓解Transformers在视觉任务中的二次计算复杂度问题。该方法通过整合通道相似性权重、确保各注意力头均匀移除通道、添加reweight模块补偿信息损失，以及基于注意力差异的初始化步骤，解决了通道不对齐的挑战。该方法不仅适用于原始注意力，还兼容线性注意力(linear attention)，并在ImageNet-1K基准测试中，使FLattenTransformer在相同MACs下比现有最先进高效模型和修剪方法准确率更高。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20867v1",
      "published_date": "2024-05-31 14:47:20 UTC",
      "updated_date": "2024-05-31 14:47:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:36:19.762589"
    },
    {
      "arxiv_id": "2405.20863v1",
      "title": "ABodyBuilder3: Improved and scalable antibody structure predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Henry Kenlay",
        "Frédéric A. Dreyer",
        "Daniel Cutting",
        "Daniel Nissley",
        "Charlotte M. Deane"
      ],
      "abstract": "Accurate prediction of antibody structure is a central task in the design and\ndevelopment of monoclonal antibodies, notably to understand both their\ndevelopability and their binding properties. In this article, we introduce\nABodyBuilder3, an improved and scalable antibody structure prediction model\nbased on ImmuneBuilder. We achieve a new state-of-the-art accuracy in the\nmodelling of CDR loops by leveraging language model embeddings, and show how\npredicted structures can be further improved through careful relaxation\nstrategies. Finally, we incorporate a predicted Local Distance Difference Test\ninto the model output to allow for a more accurate estimation of uncertainties.",
      "tldr_zh": "本文介绍了 ABodyBuilder3，一种基于 ImmuneBuilder 的改进和可扩展抗体结构预测模型，旨在提升单克隆抗体的开发性和结合性能。该模型通过利用 language model embeddings 实现了 CDR loops 建模的新状态-of-the-art 准确性，并通过仔细的 relaxation strategies 进一步优化预测结构。此外，模型整合了 predicted Local Distance Difference Test 来更精确地估计不确定性，从而为抗体设计提供更可靠的支持。",
      "categories": [
        "q-bio.BM",
        "cs.AI"
      ],
      "primary_category": "q-bio.BM",
      "comment": "8 pages, 3 figures, 3 tables, code available at\n  https://github.com/Exscientia/ABodyBuilder3, weights and data available at\n  https://zenodo.org/records/11354577",
      "pdf_url": "http://arxiv.org/pdf/2405.20863v1",
      "published_date": "2024-05-31 14:45:11 UTC",
      "updated_date": "2024-05-31 14:45:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:36:30.719886"
    },
    {
      "arxiv_id": "2405.20859v1",
      "title": "clembench-2024: A Challenging, Dynamic, Complementary, Multilingual Benchmark and Underlying Flexible Framework for LLMs as Multi-Action Agents",
      "title_zh": "clembench-2024：一种挑战性、动态、互补、多语言基准测试及其底层",
      "authors": [
        "Anne Beyer",
        "Kranti Chalamalasetti",
        "Sherzod Hakimov",
        "Brielen Madureira",
        "Philipp Sadler",
        "David Schlangen"
      ],
      "abstract": "It has been established in recent work that Large Language Models (LLMs) can\nbe prompted to \"self-play\" conversational games that probe certain capabilities\n(general instruction following, strategic goal orientation, language\nunderstanding abilities), where the resulting interactive game play can be\nautomatically scored. In this paper, we take one of the proposed frameworks for\nsetting up such game-play environments, and further test its usefulness as an\nevaluation instrument, along a number of dimensions: We show that it can easily\nkeep up with new developments while avoiding data contamination, we show that\nthe tests implemented within it are not yet saturated (human performance is\nsubstantially higher than that of even the best models), and we show that it\nlends itself to investigating additional questions, such as the impact of the\nprompting language on performance. We believe that the approach forms a good\nbasis for making decisions on model choice for building applied interactive\nsystems, and perhaps ultimately setting up a closed-loop development\nenvironment of system and simulated evaluator.",
      "tldr_zh": "本论文介绍了 clembench-2024，这是一个具有挑战性、动态、互补、多语言的基准，以及一个灵活的框架，用于评估 LLMs（Large Language Models）作为多行动代理的能力。研究通过让 LLMs 进行自玩对话游戏（self-play conversational games）来测试模型的指令遵循、战略目标导向和语言理解等能力，并证明该框架能适应新发展、避免数据污染，且测试尚未饱和（人类表现远超最佳模型）。此外，框架还可用于探索提示语言对性能的影响，为选择 LLMs 构建交互系统和建立闭环开发环境提供可靠基础。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "under review",
      "pdf_url": "http://arxiv.org/pdf/2405.20859v1",
      "published_date": "2024-05-31 14:43:31 UTC",
      "updated_date": "2024-05-31 14:43:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:36:41.979246"
    },
    {
      "arxiv_id": "2405.20848v1",
      "title": "SLIM: a Scalable Light-weight Root Cause Analysis for Imbalanced Data in Microservice",
      "title_zh": "翻译失败",
      "authors": [
        "Rui Ren",
        "Jingbang Yang",
        "Linxiao Yang",
        "Xinyue Gu",
        "Liang Sun"
      ],
      "abstract": "The newly deployed service -- one kind of change service, could lead to a new\ntype of minority fault. Existing state-of-the-art methods for fault\nlocalization rarely consider the imbalanced fault classification in change\nservice. This paper proposes a novel method that utilizes decision rule sets to\ndeal with highly imbalanced data by optimizing the F1 score subject to\ncardinality constraints. The proposed method greedily generates the rule with\nmaximal marginal gain and uses an efficient minorize-maximization (MM) approach\nto select rules iteratively, maximizing a non-monotone submodular lower bound.\nCompared with existing fault localization algorithms, our algorithm can adapt\nto the imbalanced fault scenario of change service, and provide interpretable\nfault causes which are easy to understand and verify. Our method can also be\ndeployed in the online training setting, with only about 15% training overhead\ncompared to the current SOTA methods. Empirical studies showcase that our\nalgorithm outperforms existing fault localization algorithms in both accuracy\nand model interpretability.",
      "tldr_zh": "该论文提出SLIM，一种可扩展的轻量级根因分析方法，针对微服务中不平衡数据的问题，如新部署服务导致的少数故障。SLIM利用决策规则集，通过贪婪生成规则并采用minorize-maximization (MM)方法来优化F1 score，同时在基数约束下迭代选择规则，以提升故障定位的准确性和可解释性。与现有算法相比，该方法在不平衡故障场景下表现更优，仅增加约15%的训练开销，并在经验研究中显示出更高的准确率和模型可解释性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20848v1",
      "published_date": "2024-05-31 14:32:31 UTC",
      "updated_date": "2024-05-31 14:32:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:36:53.571192"
    },
    {
      "arxiv_id": "2405.20846v1",
      "title": "Don't Buy it! Reassessing the Ad Understanding Abilities of Contrastive Multimodal Models",
      "title_zh": "翻译失败",
      "authors": [
        "A. Bavaresco",
        "A. Testoni",
        "R. Fernández"
      ],
      "abstract": "Image-based advertisements are complex multimodal stimuli that often contain\nunusual visual elements and figurative language. Previous research on automatic\nad understanding has reported impressive zero-shot accuracy of contrastive\nvision-and-language models (VLMs) on an ad-explanation retrieval task. Here, we\nexamine the original task setup and show that contrastive VLMs can solve it by\nexploiting grounding heuristics. To control for this confound, we introduce\nTRADE, a new evaluation test set with adversarial grounded explanations. While\nthese explanations look implausible to humans, we show that they \"fool\" four\ndifferent contrastive VLMs. Our findings highlight the need for an improved\noperationalisation of automatic ad understanding that truly evaluates VLMs'\nmultimodal reasoning abilities. We make our code and TRADE available at\nhttps://github.com/dmg-illc/trade .",
      "tldr_zh": "本研究重新评估了对比视觉语言模型（VLMs）在广告理解任务中的能力，指出先前报告的零-shot 准确率可能依赖于 grounding heuristics，而不是真正的多模态推理。作者引入了 TRADE 测试集，该数据集包含对抗性 grounded 解释，这些解释对人类看似不合理，却能欺骗四种不同的对比 VLMs。实验结果揭示了 VLMs 在处理图像广告的复杂元素（如不寻常视觉和比喻语言）时的局限性，并强调需要改进评估方法以真正测试其多模态推理能力。该研究提供了代码和 TRADE 数据集，供进一步研究使用。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the main conference ACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.20846v1",
      "published_date": "2024-05-31 14:31:46 UTC",
      "updated_date": "2024-05-31 14:31:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:37:16.110751"
    },
    {
      "arxiv_id": "2405.20838v2",
      "title": "einspace: Searching for Neural Architectures from Fundamental Operations",
      "title_zh": "翻译失败",
      "authors": [
        "Linus Ericsson",
        "Miguel Espinosa",
        "Chenhongyi Yang",
        "Antreas Antoniou",
        "Amos Storkey",
        "Shay B. Cohen",
        "Steven McDonagh",
        "Elliot J. Crowley"
      ],
      "abstract": "Neural architecture search (NAS) finds high performing networks for a given\ntask. Yet the results of NAS are fairly prosaic; they did not e.g. create a\nshift from convolutional structures to transformers. This is not least because\nthe search spaces in NAS often aren't diverse enough to include such\ntransformations a priori. Instead, for NAS to provide greater potential for\nfundamental design shifts, we need a novel expressive search space design which\nis built from more fundamental operations. To this end, we introduce einspace,\na search space based on a parameterised probabilistic context-free grammar. Our\nspace is versatile, supporting architectures of various sizes and complexities,\nwhile also containing diverse network operations which allow it to model\nconvolutions, attention components and more. It contains many existing\ncompetitive architectures, and provides flexibility for discovering new ones.\nUsing this search space, we perform experiments to find novel architectures as\nwell as improvements on existing ones on the diverse Unseen NAS datasets. We\nshow that competitive architectures can be obtained by searching from scratch,\nand we consistently find large improvements when initialising the search with\nstrong baselines. We believe that this work is an important advancement towards\na transformative NAS paradigm where search space expressivity and strategic\nsearch initialisation play key roles.",
      "tldr_zh": "本研究针对神经架构搜索 (NAS) 的局限性，即搜索空间不够多样导致难以实现根本性设计转变，提出了一种新型搜索空间 einspace。该空间基于参数化的概率上下文无关文法 (probabilistic context-free grammar)，支持各种大小和复杂度的架构，并包含卷积 (convolutions)、注意力 (attention) 等多样化操作，从而能建模现有竞争性架构并发现新颖设计。在 Unseen NAS 数据集上的实验显示，从零开始搜索即可获得高性能架构，而通过初始化强基线进一步实现显著改进，这为推动 NAS 向更具表达性和战略性的范式转变提供了重要进展。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024. Project page at\n  https://linusericsson.github.io/einspace/",
      "pdf_url": "http://arxiv.org/pdf/2405.20838v2",
      "published_date": "2024-05-31 14:25:45 UTC",
      "updated_date": "2024-10-30 12:35:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:37:17.473090"
    },
    {
      "arxiv_id": "2405.20835v3",
      "title": "Outliers and Calibration Sets have Diminishing Effect on Quantization of Modern LLMs",
      "title_zh": "异常值和校准集",
      "authors": [
        "Davide Paglieri",
        "Saurabh Dash",
        "Tim Rocktäschel",
        "Jack Parker-Holder"
      ],
      "abstract": "Post-Training Quantization (PTQ) enhances the efficiency of Large Language\nModels (LLMs) by enabling faster operation and compatibility with more\naccessible hardware through reduced memory usage, at the cost of small\nperformance drops. We explore the role of calibration sets in PTQ, specifically\ntheir effect on hidden activations in various notable open-source LLMs.\nCalibration sets are crucial for evaluating activation magnitudes and\nidentifying outliers, which can distort the quantization range and negatively\nimpact performance. Our analysis reveals a marked contrast in quantization\neffectiveness across models. The older OPT model, upon which much of the\nquantization literature is based, shows significant performance deterioration\nand high susceptibility to outliers with varying calibration sets. In contrast,\nnewer models like Llama-2 7B, Llama-3 8B, Command-R 35B, and Mistral 7B\ndemonstrate strong robustness, with Mistral 7B showing near-immunity to\noutliers and stable activations. These findings suggest a shift in PTQ\nstrategies might be needed. As advancements in pre-training methods reduce the\nrelevance of outliers, there is an emerging need to reassess the fundamentals\nof current quantization literature. The emphasis should pivot towards\noptimizing inference speed, rather than primarily focusing on outlier\npreservation, to align with the evolving characteristics of state-of-the-art\nLLMs.",
      "tldr_zh": "本文研究发现，在 Post-Training Quantization (PTQ) 的应用中，outliers 和 calibration sets 对现代 Large Language Models (LLMs) 的影响正在减弱。作者通过分析不同模型的隐藏激活，发现旧模型如 OPT 高度敏感，导致量化性能显著下降，而新模型如 Llama-2 7B、Llama-3 8B、Command-R 35B 和 Mistral 7B 表现出强 robustness，尤其是 Mistral 7B 几乎不受 outliers 影响。研究建议，随着预训练方法进步，PTQ 策略应转向优化推理速度，而非过度关注 outliers 保留，以适应当前 LLMs 的演进趋势。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20835v3",
      "published_date": "2024-05-31 14:24:33 UTC",
      "updated_date": "2024-06-05 09:53:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:37:31.002245"
    },
    {
      "arxiv_id": "2405.20806v2",
      "title": "The AI Alignment Paradox",
      "title_zh": "翻译失败",
      "authors": [
        "Robert West",
        "Roland Aydin"
      ],
      "abstract": "The field of AI alignment aims to steer AI systems toward human goals,\npreferences, and ethical principles. Its contributions have been instrumental\nfor improving the output quality, safety, and trustworthiness of today's AI\nmodels. This perspective article draws attention to a fundamental challenge we\nsee in all AI alignment endeavors, which we term the \"AI alignment paradox\":\nThe better we align AI models with our values, the easier we may make it for\nadversaries to misalign the models. We illustrate the paradox by sketching\nthree concrete example incarnations for the case of language models, each\ncorresponding to a distinct way in which adversaries might exploit the paradox.\nWith AI's increasing real-world impact, it is imperative that a broad community\nof researchers be aware of the AI alignment paradox and work to find ways to\nmitigate it, in order to ensure the beneficial use of AI for the good of\nhumanity.",
      "tldr_zh": "这篇论文探讨了AI对齐（AI alignment）领域的核心挑战，引入了“AI alignment paradox”这一概念，即当我们成功地将AI系统与人类目标、偏好和伦理原则对齐时，可能反而使对手更容易操纵这些系统，导致AI失调。作者通过三个具体例子说明了这一悖论在语言模型中的表现，包括对手利用对齐机制进行攻击的方式。论文强调，随着AI在现实世界的日益影响，研究社区需共同努力缓解这一风险，以确保AI的良性应用和对人类的益处。",
      "categories": [
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20806v2",
      "published_date": "2024-05-31 14:06:24 UTC",
      "updated_date": "2024-11-22 22:55:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:37:41.163753"
    },
    {
      "arxiv_id": "2405.20797v2",
      "title": "Ovis: Structural Embedding Alignment for Multimodal Large Language Model",
      "title_zh": "翻译失败",
      "authors": [
        "Shiyin Lu",
        "Yang Li",
        "Qing-Guo Chen",
        "Zhao Xu",
        "Weihua Luo",
        "Kaifu Zhang",
        "Han-Jia Ye"
      ],
      "abstract": "Current Multimodal Large Language Models (MLLMs) typically integrate a\npre-trained LLM with another pre-trained vision transformer through a\nconnector, such as an MLP, endowing the LLM with visual capabilities. However,\nthe misalignment between two embedding strategies in MLLMs -- the structural\ntextual embeddings based on an embedding look-up table and the continuous\nembeddings generated directly by the vision encoder -- makes challenges for a\nmore seamless fusion of visual and textual information. We propose Ovis, a\nnovel MLLM architecture designed to structurally align visual and textual\nembeddings. Ovis integrates an additional learnable visual embedding table into\nthe visual encoder's process. To capture rich visual semantics, each image\npatch indexes the visual embedding table multiple times, resulting in a final\nvisual embedding that is a probabilistic combination of the indexed embeddings.\nThis structural approach mirrors the method used for generating textual\nembeddings. Empirical evaluations on various multimodal benchmarks show that\nOvis outperforms open-source MLLMs of similar parameter scales and even\nsurpasses the proprietary model Qwen-VL-Plus overall. These results highlight\nthe potential of Ovis' structured visual representation for advancing MLLM\narchitectural design and promoting more effective multimodal learning. Code,\ndatasets, and models are available at https://github.com/AIDC-AI/Ovis.",
      "tldr_zh": "该论文针对 Multimodal Large Language Models (MLLMs) 中视觉和文本嵌入策略不对齐的问题，提出了一种新型架构 Ovis，通过添加一个可学习的 visual embedding table 来实现结构化对齐。具体方法包括让每个图像 patch 多次索引该表，并通过概率组合生成最终视觉嵌入，从而模仿文本嵌入的生成方式。实验结果显示，Ovis 在多种多模态基准上超过了类似参数规模的开源 MLLMs 甚至专有模型 Qwen-VL-Plus，这突显了其结构化视觉表示在提升多模态学习方面的潜力。代码、数据集和模型已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20797v2",
      "published_date": "2024-05-31 13:59:18 UTC",
      "updated_date": "2024-06-17 17:51:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:37:55.824736"
    },
    {
      "arxiv_id": "2405.20795v1",
      "title": "InsightSee: Advancing Multi-agent Vision-Language Models for Enhanced Visual Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Huaxiang Zhang",
        "Yaojia Mu",
        "Guo-Niu Zhu",
        "Zhongxue Gan"
      ],
      "abstract": "Accurate visual understanding is imperative for advancing autonomous systems\nand intelligent robots. Despite the powerful capabilities of vision-language\nmodels (VLMs) in processing complex visual scenes, precisely recognizing\nobscured or ambiguously presented visual elements remains challenging. To\ntackle such issues, this paper proposes InsightSee, a multi-agent framework to\nenhance VLMs' interpretative capabilities in handling complex visual\nunderstanding scenarios. The framework comprises a description agent, two\nreasoning agents, and a decision agent, which are integrated to refine the\nprocess of visual information interpretation. The design of these agents and\nthe mechanisms by which they can be enhanced in visual information processing\nare presented. Experimental results demonstrate that the InsightSee framework\nnot only boosts performance on specific visual tasks but also retains the\noriginal models' strength. The proposed framework outperforms state-of-the-art\nalgorithms in 6 out of 9 benchmark tests, with a substantial advancement in\nmultimodal understanding.",
      "tldr_zh": "本论文提出 InsightSee，一个多智能体框架，旨在提升 Vision-Language Models (VLMs) 在处理复杂视觉场景中的理解能力，特别是针对模糊或隐藏元素的识别挑战。框架由 description agent、two reasoning agents 和 decision agent 组成，这些代理协同工作，通过精炼视觉信息解释过程来优化整体性能。实验结果表明，InsightSee 在 9 个基准测试中胜出 6 个，显著提高了多模态理解，同时保留了原模型的优势。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20795v1",
      "published_date": "2024-05-31 13:56:55 UTC",
      "updated_date": "2024-05-31 13:56:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:38:05.789110"
    },
    {
      "arxiv_id": "2405.20748v1",
      "title": "OpenTensor: Reproducing Faster Matrix Multiplication Discovering Algorithms",
      "title_zh": "翻译失败",
      "authors": [
        "Yiwen Sun",
        "Wenye Li"
      ],
      "abstract": "OpenTensor is a reproduction of AlphaTensor, which discovered a new algorithm\nthat outperforms the state-of-the-art methods for matrix multiplication by Deep\nReinforcement Learning (DRL). While AlphaTensor provides a promising framework\nfor solving scientific problems, it is really hard to reproduce due to the\nmassive tricks and lack of source codes. In this paper, we clean up the\nalgorithm pipeline, clarify the technical details, and make some improvements\nto the training process. Computational results show that OpenTensor can\nsuccessfully find efficient matrix multiplication algorithms.",
      "tldr_zh": "本文介绍了 OpenTensor，一种对 AlphaTensor 的再现框架，通过深度强化学习 (DRL) 发现比现有方法更快的矩阵乘法算法，以解决原框架的再现难题。研究团队清理了算法管道，澄清了技术细节，并对训练过程进行了改进。计算结果显示，OpenTensor 成功找到了高效的矩阵乘法算法，证明了其在优化科学计算方面的潜力。",
      "categories": [
        "cs.AI",
        "cs.DS",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20748v1",
      "published_date": "2024-05-31 10:30:14 UTC",
      "updated_date": "2024-05-31 10:30:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:38:17.373868"
    },
    {
      "arxiv_id": "2405.20743v2",
      "title": "Trajectory Forecasting through Low-Rank Adaptation of Discrete Latent Codes",
      "title_zh": "翻译失败",
      "authors": [
        "Riccardo Benaglia",
        "Angelo Porrello",
        "Pietro Buzzega",
        "Simone Calderara",
        "Rita Cucchiara"
      ],
      "abstract": "Trajectory forecasting is crucial for video surveillance analytics, as it\nenables the anticipation of future movements for a set of agents, e.g.\nbasketball players engaged in intricate interactions with long-term intentions.\nDeep generative models offer a natural learning approach for trajectory\nforecasting, yet they encounter difficulties in achieving an optimal balance\nbetween sampling fidelity and diversity. We address this challenge by\nleveraging Vector Quantized Variational Autoencoders (VQ-VAEs), which utilize a\ndiscrete latent space to tackle the issue of posterior collapse. Specifically,\nwe introduce an instance-based codebook that allows tailored latent\nrepresentations for each example. In a nutshell, the rows of the codebook are\ndynamically adjusted to reflect contextual information (i.e., past motion\npatterns extracted from the observed trajectories). In this way, the\ndiscretization process gains flexibility, leading to improved reconstructions.\nNotably, instance-level dynamics are injected into the codebook through\nlow-rank updates, which restrict the customization of the codebook to a lower\ndimension space. The resulting discrete space serves as the basis of the\nsubsequent step, which regards the training of a diffusion-based predictive\nmodel. We show that such a two-fold framework, augmented with instance-level\ndiscretization, leads to accurate and diverse forecasts, yielding\nstate-of-the-art performance on three established benchmarks.",
      "tldr_zh": "本研究针对轨迹预测的挑战（如平衡采样保真度和多样性），提出了一种基于 Vector Quantized Variational Autoencoders (VQ-VAEs) 的框架，利用离散潜在空间来避免后验崩溃问题。作者引入 instance-based codebook，通过动态调整代码本行以融入上下文信息（如过去的运动模式），并使用 low-rank updates 在较低维度空间注入实例级动态，从而提升离散化灵活性和重建质量。基于此离散空间，框架进一步训练 diffusion-based predictive model，实现准确且多样的轨迹预测，并在三个基准数据集上达到了 state-of-the-art 性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 3 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.20743v2",
      "published_date": "2024-05-31 10:13:17 UTC",
      "updated_date": "2024-08-29 15:31:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:38:30.635023"
    },
    {
      "arxiv_id": "2405.20731v1",
      "title": "Maximum Temperature Prediction Using Remote Sensing Data Via Convolutional Neural Network",
      "title_zh": "翻译失败",
      "authors": [
        "Lorenzo Innocenti",
        "Giacomo Blanco",
        "Luca Barco",
        "Claudio Rossi"
      ],
      "abstract": "Urban heat islands, defined as specific zones exhibiting substantially higher\ntemperatures than their immediate environs, pose significant threats to\nenvironmental sustainability and public health. This study introduces a novel\nmachine-learning model that amalgamates data from the Sentinel-3 satellite,\nmeteorological predictions, and additional remote sensing inputs. The primary\naim is to generate detailed spatiotemporal maps that forecast the peak\ntemperatures within a 24-hour period in Turin. Experimental results validate\nthe model's proficiency in predicting temperature patterns, achieving a Mean\nAbsolute Error (MAE) of 2.09 degrees Celsius for the year 2023 at a resolution\nof 20 meters per pixel, thereby enriching our knowledge of urban climatic\nbehavior. This investigation enhances the understanding of urban microclimates,\nemphasizing the importance of cross-disciplinary data integration, and laying\nthe groundwork for informed policy-making aimed at alleviating the negative\nimpacts of extreme urban temperatures.",
      "tldr_zh": "这篇论文针对城市热岛效应（Urban heat islands）提出了一种新型机器学习模型，使用 Convolutional Neural Network 整合 Sentinel-3 卫星数据、气象预测和其他遥感输入，以生成 Turin 市未来 24 小时内最高温度的详细时空地图。模型在 2023 年的实验中实现了 2.09 摄氏度的 Mean Absolute Error (MAE)，分辨率为 20 米/像素，展示了其在预测温度模式方面的精确性。该研究深化了对城市微气候的认识，强调跨学科数据整合的重要性，并为制定缓解极端城市温度负面影响的政策奠定基础。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "I.2.10; G.3"
      ],
      "primary_category": "cs.AI",
      "comment": "4 pages, submitted to IEEE MetroLivEnv 2024 conference",
      "pdf_url": "http://arxiv.org/pdf/2405.20731v1",
      "published_date": "2024-05-31 09:39:41 UTC",
      "updated_date": "2024-05-31 09:39:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:38:43.550716"
    },
    {
      "arxiv_id": "2405.20727v1",
      "title": "GANcrop: A Contrastive Defense Against Backdoor Attacks in Federated Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoyun Gan",
        "Shanyu Gan",
        "Taizhi Su",
        "Peng Liu"
      ],
      "abstract": "With heightened awareness of data privacy protection, Federated Learning (FL)\nhas attracted widespread attention as a privacy-preserving distributed machine\nlearning method. However, the distributed nature of federated learning also\nprovides opportunities for backdoor attacks, where attackers can guide the\nmodel to produce incorrect predictions without affecting the global model\ntraining process.\n  This paper introduces a novel defense mechanism against backdoor attacks in\nfederated learning, named GANcrop. This approach leverages contrastive learning\nto deeply explore the disparities between malicious and benign models for\nattack identification, followed by the utilization of Generative Adversarial\nNetworks (GAN) to recover backdoor triggers and implement targeted mitigation\nstrategies. Experimental findings demonstrate that GANcrop effectively\nsafeguards against backdoor attacks, particularly in non-IID scenarios, while\nmaintaining satisfactory model accuracy, showcasing its remarkable defensive\nefficacy and practical utility.",
      "tldr_zh": "这篇论文针对Federated Learning中的backdoor attacks，提出了一种名为GANcrop的创新防御机制，以保护分布式机器学习的安全。GANcrop利用contrastive learning来识别恶意和良性模型之间的差异，并结合Generative Adversarial Networks (GAN)恢复backdoor triggers并实施针对性缓解策略。实验结果表明，该方法在non-IID场景下有效抵御攻击，同时保持模型准确性，展示了其强大的防御效能和实用价值。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20727v1",
      "published_date": "2024-05-31 09:33:16 UTC",
      "updated_date": "2024-05-31 09:33:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:38:53.124768"
    },
    {
      "arxiv_id": "2405.20725v2",
      "title": "GI-NAS: Boosting Gradient Inversion Attacks through Adaptive Neural Architecture Search",
      "title_zh": "翻译失败",
      "authors": [
        "Wenbo Yu",
        "Hao Fang",
        "Bin Chen",
        "Xiaohang Sui",
        "Chuan Chen",
        "Hao Wu",
        "Shu-Tao Xia",
        "Ke Xu"
      ],
      "abstract": "Gradient Inversion Attacks invert the transmitted gradients in Federated\nLearning (FL) systems to reconstruct the sensitive data of local clients and\nhave raised considerable privacy concerns. A majority of gradient inversion\nmethods rely heavily on explicit prior knowledge (e.g., a well pre-trained\ngenerative model), which is often unavailable in realistic scenarios. To\nalleviate this issue, researchers have proposed to leverage the implicit prior\nknowledge of an over-parameterized network. However, they only utilize a fixed\nneural architecture for all the attack settings. This would hinder the adaptive\nuse of implicit architectural priors and consequently limit the\ngeneralizability. In this paper, we further exploit such implicit prior\nknowledge by proposing Gradient Inversion via Neural Architecture Search\n(GI-NAS), which adaptively searches the network and captures the implicit\npriors behind neural architectures. Extensive experiments verify that our\nproposed GI-NAS can achieve superior attack performance compared to\nstate-of-the-art gradient inversion methods, even under more practical settings\nwith high-resolution images, large-sized batches, and advanced defense\nstrategies.",
      "tldr_zh": "本研究针对联邦学习（Federated Learning）中的梯度反演攻击（Gradient Inversion Attacks），提出了一种自适应神经架构搜索方法GI-NAS，以克服现有方法依赖显式先验知识或固定架构的局限性。GI-NAS通过动态搜索神经网络架构，捕获隐式先验知识，从而提升攻击的适应性和泛化能力。实验结果显示，GI-NAS在高分辨率图像、大批量数据和高级防御策略等实际场景下，比最先进方法取得了显著的性能提升。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20725v2",
      "published_date": "2024-05-31 09:29:43 UTC",
      "updated_date": "2024-10-25 09:26:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:39:06.511638"
    },
    {
      "arxiv_id": "2405.20721v1",
      "title": "ContextGS: Compact 3D Gaussian Splatting with Anchor Level Context Model",
      "title_zh": "翻译失败",
      "authors": [
        "Yufei Wang",
        "Zhihao Li",
        "Lanqing Guo",
        "Wenhan Yang",
        "Alex C. Kot",
        "Bihan Wen"
      ],
      "abstract": "Recently, 3D Gaussian Splatting (3DGS) has become a promising framework for\nnovel view synthesis, offering fast rendering speeds and high fidelity.\nHowever, the large number of Gaussians and their associated attributes require\neffective compression techniques. Existing methods primarily compress neural\nGaussians individually and independently, i.e., coding all the neural Gaussians\nat the same time, with little design for their interactions and spatial\ndependence. Inspired by the effectiveness of the context model in image\ncompression, we propose the first autoregressive model at the anchor level for\n3DGS compression in this work. We divide anchors into different levels and the\nanchors that are not coded yet can be predicted based on the already coded ones\nin all the coarser levels, leading to more accurate modeling and higher coding\nefficiency. To further improve the efficiency of entropy coding, e.g., to code\nthe coarsest level with no already coded anchors, we propose to introduce a\nlow-dimensional quantized feature as the hyperprior for each anchor, which can\nbe effectively compressed. Our work pioneers the context model in the anchor\nlevel for 3DGS representation, yielding an impressive size reduction of over\n100 times compared to vanilla 3DGS and 15 times compared to the most recent\nstate-of-the-art work Scaffold-GS, while achieving comparable or even higher\nrendering quality.",
      "tldr_zh": "该论文提出 ContextGS，一种紧凑的 3D Gaussian Splatting (3DGS) 压缩框架，通过在 anchor 级别引入自回归模型 (autoregressive model) 来处理 Gaussians 之间的互动和空间依赖问题。具体而言，该方法将 anchors 分成不同级别，利用已编码 anchors 预测未编码 ones，并引入低维量化特征作为 hyperprior 以提升编码效率。实验结果显示，ContextGS 相较于原版 3DGS 体积减少超过 100 倍，与最新方法 Scaffold-GS 相比减少 15 倍，同时实现相当或更高的渲染质量，为高效的新视图合成提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20721v1",
      "published_date": "2024-05-31 09:23:39 UTC",
      "updated_date": "2024-05-31 09:23:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:39:28.933062"
    },
    {
      "arxiv_id": "2405.20719v1",
      "title": "Climate Variable Downscaling with Conditional Normalizing Flows",
      "title_zh": "基于条件归一化流的气",
      "authors": [
        "Christina Winkler",
        "Paula Harder",
        "David Rolnick"
      ],
      "abstract": "Predictions of global climate models typically operate on coarse spatial\nscales due to the large computational costs of climate simulations. This has\nled to a considerable interest in methods for statistical downscaling, a\nsimilar process to super-resolution in the computer vision context, to provide\nmore local and regional climate information. In this work, we apply conditional\nnormalizing flows to the task of climate variable downscaling. We showcase its\nsuccessful performance on an ERA5 water content dataset for different\nupsampling factors. Additionally, we show that the method allows us to assess\nthe predictive uncertainty in terms of standard deviation from the fitted\nconditional distribution mean.",
      "tldr_zh": "全球气候模型的预测通常在粗糙空间尺度上运行，由于计算成本高，因此需要统计降尺度方法（如计算机视觉中的超分辨率）来提供更精细的局部气候信息。本文提出使用 Conditional Normalizing Flows 进行气候变量降尺度，并在 ERA5 水含量数据集上验证其在不同上采样因子下的成功性能。该方法不仅提升了预测准确性，还允许通过标准差评估预测不确定性，从而为气候研究提供更可靠的工具。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "physics.ao-ph"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20719v1",
      "published_date": "2024-05-31 09:20:33 UTC",
      "updated_date": "2024-05-31 09:20:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:39:40.232585"
    },
    {
      "arxiv_id": "2405.20718v2",
      "title": "Popularity-Aware Alignment and Contrast for Mitigating Popularity Bias",
      "title_zh": "感知流行度的对齐与",
      "authors": [
        "Miaomiao Cai",
        "Lei Chen",
        "Yifan Wang",
        "Haoyue Bai",
        "Peijie Sun",
        "Le Wu",
        "Min Zhang",
        "Meng Wang"
      ],
      "abstract": "Collaborative Filtering (CF) typically suffers from the significant challenge\nof popularity bias due to the uneven distribution of items in real-world\ndatasets. This bias leads to a significant accuracy gap between popular and\nunpopular items. It not only hinders accurate user preference understanding but\nalso exacerbates the Matthew effect in recommendation systems. To alleviate\npopularity bias, existing efforts focus on emphasizing unpopular items or\nseparating the correlation between item representations and their popularity.\nDespite the effectiveness, existing works still face two persistent challenges:\n(1) how to extract common supervision signals from popular items to improve the\nunpopular item representations, and (2) how to alleviate the representation\nseparation caused by popularity bias. In this work, we conduct an empirical\nanalysis of popularity bias and propose Popularity-Aware Alignment and Contrast\n(PAAC) to address two challenges. Specifically, we use the common supervisory\nsignals modeled in popular item representations and propose a novel\npopularity-aware supervised alignment module to learn unpopular item\nrepresentations. Additionally, we suggest re-weighting the contrastive learning\nloss to mitigate the representation separation from a popularity-centric\nperspective. Finally, we validate the effectiveness and rationale of PAAC in\nmitigating popularity bias through extensive experiments on three real-world\ndatasets. Our code is available at\nhttps://github.com/miaomiao-cai2/KDD2024-PAAC.",
      "tldr_zh": "该论文针对协同过滤（Collaborative Filtering）中因物品分布不均导致的popularity bias问题，指出这种偏差会加剧流行物品与非流行物品的准确率差距，并影响用户偏好理解和推荐系统的马太效应（Matthew effect）。为了解决现有方法的局限，作者提出Popularity-Aware Alignment and Contrast (PAAC)框架，包括一个popularity-aware supervised alignment模块，利用流行物品表示中的共同监督信号来优化非流行物品表示，以及通过重新加权contrastive learning损失从流行度角度缓解表示分离。实验结果显示，PAAC在三个真实数据集上有效减轻了popularity bias，并证明了其合理性，相关代码已开源。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.20718v2",
      "published_date": "2024-05-31 09:14:48 UTC",
      "updated_date": "2024-06-11 09:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:39:43.703200"
    },
    {
      "arxiv_id": "2405.20708v1",
      "title": "FinGen: A Dataset for Argument Generation in Finance",
      "title_zh": "翻译失败",
      "authors": [
        "Chung-Chi Chen",
        "Hiroya Takamura",
        "Ichiro Kobayashi",
        "Yusuke Miyao"
      ],
      "abstract": "Thinking about the future is one of the important activities that people do\nin daily life. Futurists also pay a lot of effort into figuring out possible\nscenarios for the future. We argue that the exploration of this direction is\nstill in an early stage in the NLP research. To this end, we propose three\nargument generation tasks in the financial application scenario. Our\nexperimental results show these tasks are still big challenges for\nrepresentative generation models. Based on our empirical results, we further\npoint out several unresolved issues and challenges in this research direction.",
      "tldr_zh": "这篇论文介绍了FinGen数据集，该数据集专注于金融领域的论点生成（argument generation），旨在推动NLP（Natural Language Processing）研究中未来场景探索的早期发展。论文提出了三个具体的论点生成任务，并通过实验结果证明，这些任务对代表性生成模型构成了重大挑战。最终，基于经验分析，论文指出了这一研究方向的未解决问题和潜在挑战，为未来NLP应用提供了新见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20708v1",
      "published_date": "2024-05-31 09:00:43 UTC",
      "updated_date": "2024-05-31 09:00:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:39:53.527935"
    },
    {
      "arxiv_id": "2405.20705v2",
      "title": "ADESSE: Advice Explanations in Complex Repeated Decision-Making Environments",
      "title_zh": "ADESSE：复杂重复决策环境中的建议解释",
      "authors": [
        "Sören Schleibaum",
        "Lu Feng",
        "Sarit Kraus",
        "Jörg P. Müller"
      ],
      "abstract": "In the evolving landscape of human-centered AI, fostering a synergistic\nrelationship between humans and AI agents in decision-making processes stands\nas a paramount challenge. This work considers a problem setup where an\nintelligent agent comprising a neural network-based prediction component and a\ndeep reinforcement learning component provides advice to a human decision-maker\nin complex repeated decision-making environments. Whether the human\ndecision-maker would follow the agent's advice depends on their beliefs and\ntrust in the agent and on their understanding of the advice itself. To this\nend, we developed an approach named ADESSE to generate explanations about the\nadviser agent to improve human trust and decision-making. Computational\nexperiments on a range of environments with varying model sizes demonstrate the\napplicability and scalability of ADESSE. Furthermore, an interactive game-based\nuser study shows that participants were significantly more satisfied, achieved\na higher reward in the game, and took less time to select an action when\npresented with explanations generated by ADESSE. These findings illuminate the\ncritical role of tailored, human-centered explanations in AI-assisted\ndecision-making.",
      "tldr_zh": "这篇论文探讨了在复杂重复决策环境中，AI 代理如何通过提供建议解释来提升人类决策者的信任和协同关系。研究引入了 ADESSE 方法，该方法结合神经网络预测组件和深度强化学习组件，生成针对性解释以帮助人类理解和采纳建议。实验结果显示，在各种环境中，ADESSE 具有良好的适用性和可扩展性；此外，用户互动游戏研究表明，使用这些解释时，参与者满意度更高、获得奖励更多且决策时间更短。这些发现突出了定制化解释在 AI 辅助决策中的关键作用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20705v2",
      "published_date": "2024-05-31 08:59:20 UTC",
      "updated_date": "2024-09-10 09:49:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:40:06.596962"
    },
    {
      "arxiv_id": "2405.20701v1",
      "title": "Unveiling the Lexical Sensitivity of LLMs: Combinatorial Optimization for Prompt Enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Pengwei Zhan",
        "Zhen Xu",
        "Qian Tan",
        "Jie Song",
        "Ru Xie"
      ],
      "abstract": "Large language models (LLMs) demonstrate exceptional instruct-following\nability to complete various downstream tasks. Although this impressive ability\nmakes LLMs flexible task solvers, their performance in solving tasks also\nheavily relies on instructions. In this paper, we reveal that LLMs are\nover-sensitive to lexical variations in task instructions, even when the\nvariations are imperceptible to humans. By providing models with neighborhood\ninstructions, which are closely situated in the latent representation space and\ndiffer by only one semantically similar word, the performance on downstream\ntasks can be vastly different. Following this property, we propose a black-box\nCombinatorial Optimization framework for Prompt Lexical Enhancement (COPLE).\nCOPLE performs iterative lexical optimization according to the feedback from a\nbatch of proxy tasks, using a search strategy related to word influence.\nExperiments show that even widely-used human-crafted prompts for current\nbenchmarks suffer from the lexical sensitivity of models, and COPLE recovers\nthe declined model ability in both instruct-following and solving downstream\ntasks.",
      "tldr_zh": "本研究揭示了大型语言模型(LLMs)对任务指令中词汇变化的过度敏感性，即使这些变化对人类几乎不可察觉，也会导致下游任务性能的巨大差异。针对这一问题，作者提出了一种黑箱框架Combinatorial Optimization for Prompt Lexical Enhancement (COPLE)，通过迭代的词汇优化和基于词汇影响的搜索策略，利用代理任务的反馈来提升提示质量。实验结果表明，即使是广泛使用的提示也受LLMs词汇敏感性的影响，而COPLE能够有效恢复模型的指令遵循能力和任务解决性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20701v1",
      "published_date": "2024-05-31 08:53:59 UTC",
      "updated_date": "2024-05-31 08:53:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:40:17.433851"
    },
    {
      "arxiv_id": "2405.20700v1",
      "title": "Self-degraded contrastive domain adaptation for industrial fault diagnosis with bi-imbalanced data",
      "title_zh": "翻译失败",
      "authors": [
        "Gecheng Chen",
        "Zeyu Yang",
        "Chengwen Luo",
        "Jianqiang Li"
      ],
      "abstract": "Modern industrial fault diagnosis tasks often face the combined challenge of\ndistribution discrepancy and bi-imbalance. Existing domain adaptation\napproaches pay little attention to the prevailing bi-imbalance, leading to poor\ndomain adaptation performance or even negative transfer. In this work, we\npropose a self-degraded contrastive domain adaptation (Sd-CDA) diagnosis\nframework to handle the domain discrepancy under the bi-imbalanced data. It\nfirst pre-trains the feature extractor via imbalance-aware contrastive learning\nbased on model pruning to learn the feature representation efficiently in a\nself-supervised manner. Then it forces the samples away from the domain\nboundary based on supervised contrastive domain adversarial learning\n(SupCon-DA) and ensures the features generated by the feature extractor are\ndiscriminative enough. Furthermore, we propose the pruned contrastive domain\nadversarial learning (PSupCon-DA) to pay automatically re-weighted attention to\nthe minorities to enhance the performance towards bi-imbalanced data. We show\nthe superiority of the proposed method via two experiments.",
      "tldr_zh": "本文提出了一种自降级对比领域适应（Sd-CDA）框架，用于解决工业故障诊断中存在的分布差异和双重不平衡（bi-imbalanced data）问题，以避免现有领域适应方法导致的性能下降或负面转移。框架首先通过基于模型修剪的不平衡感知对比学习预训练特征提取器，实现自监督的特征表示学习；随后结合监督对比领域对抗学习（SupCon-DA）和修剪后的对比领域对抗学习（PSupCon-DA），将样本远离领域边界并自动重新加权关注少数样本，确保特征的区分性和鲁棒性。通过两个实验，证明了Sd-CDA方法在处理bi-imbalanced数据时的优越性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20700v1",
      "published_date": "2024-05-31 08:51:57 UTC",
      "updated_date": "2024-05-31 08:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:40:33.929986"
    },
    {
      "arxiv_id": "2405.20692v1",
      "title": "In-Context Decision Transformer: Reinforcement Learning via Hierarchical Chain-of-Thought",
      "title_zh": "翻译失败",
      "authors": [
        "Sili Huang",
        "Jifeng Hu",
        "Hechang Chen",
        "Lichao Sun",
        "Bo Yang"
      ],
      "abstract": "In-context learning is a promising approach for offline reinforcement\nlearning (RL) to handle online tasks, which can be achieved by providing task\nprompts. Recent works demonstrated that in-context RL could emerge with\nself-improvement in a trial-and-error manner when treating RL tasks as an\nacross-episodic sequential prediction problem. Despite the self-improvement not\nrequiring gradient updates, current works still suffer from high computational\ncosts when the across-episodic sequence increases with task horizons. To this\nend, we propose an In-context Decision Transformer (IDT) to achieve\nself-improvement in a high-level trial-and-error manner. Specifically, IDT is\ninspired by the efficient hierarchical structure of human decision-making and\nthus reconstructs the sequence to consist of high-level decisions instead of\nlow-level actions that interact with environments. As one high-level decision\ncan guide multi-step low-level actions, IDT naturally avoids excessively long\nsequences and solves online tasks more efficiently. Experimental results show\nthat IDT achieves state-of-the-art in long-horizon tasks over current\nin-context RL methods. In particular, the online evaluation time of our IDT is\n\\textbf{36$\\times$} times faster than baselines in the D4RL benchmark and\n\\textbf{27$\\times$} times faster in the Grid World benchmark.",
      "tldr_zh": "这篇论文提出 In-Context Decision Transformer (IDT)，一种通过分层 Chain-of-Thought 推理来实现强化学习的框架，旨在解决现有 in-context RL 方法在处理长时序任务时的高计算成本问题。IDT 受人类决策层次结构启发，将任务序列重构为高层次决策而非低层次动作，从而通过一个决策指导多步动作，实现更高效的自我改进和在线任务处理。实验结果表明，IDT 在长时序任务中优于现有方法，在 D4RL 基准上在线评估时间快 36 倍，在 Grid World 基准上快 27 倍。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20692v1",
      "published_date": "2024-05-31 08:38:25 UTC",
      "updated_date": "2024-05-31 08:38:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:40:43.473717"
    },
    {
      "arxiv_id": "2405.20687v1",
      "title": "Conditioning GAN Without Training Dataset",
      "title_zh": "无需训练数据集的条件 GAN",
      "authors": [
        "Kidist Amde Mekonnen"
      ],
      "abstract": "Deep learning algorithms have a large number of trainable parameters often\nwith sizes of hundreds of thousands or more. Training this algorithm requires a\nlarge amount of training data and generating a sufficiently large dataset for\nthese algorithms is costly\\cite{noguchi2019image}.\n  GANs are generative neural networks that use two deep learning networks that\nare competing with each other. The networks are generator and discriminator\nnetworks. The generator tries to generate realistic images which resemble the\nactual training dataset by approximating the training data distribution and the\ndiscriminator is trained to classify images as real or\nfake(generated)\\cite{goodfellow2016nips}. Training these GAN algorithms also\nrequires a large amount of training dataset\\cite{noguchi2019image}.\n  In this study, the aim is to address the question, \"Given an unconditioned\npretrained generator network and a pretrained classifier, is it feasible to\ndevelop a conditioned generator without relying on any training dataset?\"\n  The paper begins with a general introduction to the problem. The subsequent\nsections are structured as follows: Section 2 provides background information\non the problem. Section 3 reviews relevant literature on the topic. Section 4\noutlines the methodology employed in this study. Section 5 presents the\nexperimental results. Section 6 discusses the findings and proposes potential\nfuture research directions. Finally, Section 7 offers concluding remarks.\n  The implementation can be accessed\n\\href{https://github.com/kidist-amde/BigGAN-PyTorch}{here}.",
      "tldr_zh": "这篇论文探讨了在没有训练数据集的情况下，如何利用预训练的生成器（generator）和分类器来创建一个条件化的 GAN（Generative Adversarial Network），以解决深度学习模型对大规模数据依赖的问题。研究的核心问题是给定一个未条件化的预训练生成器和预训练分类器，是否可行地开发条件生成器。作者通过文献综述、方法设计、实验验证和讨论，证明了这一方法的有效性，并提供了开源实现（GitHub 链接）。这项工作为减少 GAN 训练数据需求提供了新途径，提升了生成模型的效率和实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "5 pages, 2 figures, Part of my MSc project course, School Project\n  Course 2022",
      "pdf_url": "http://arxiv.org/pdf/2405.20687v1",
      "published_date": "2024-05-31 08:31:26 UTC",
      "updated_date": "2024-05-31 08:31:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:40:55.956820"
    },
    {
      "arxiv_id": "2405.20681v3",
      "title": "No Free Lunch Theorem for Privacy-Preserving LLM Inference",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaojin Zhang",
        "Yahao Pang",
        "Yan Kang",
        "Wei Chen",
        "Lixin Fan",
        "Hai Jin",
        "Qiang Yang"
      ],
      "abstract": "Individuals and businesses have been significantly benefited by Large\nLanguage Models (LLMs) including PaLM, Gemini and ChatGPT in various ways. For\nexample, LLMs enhance productivity, reduce costs, and enable us to focus on\nmore valuable tasks. Furthermore, LLMs possess the capacity to sift through\nextensive datasets, uncover underlying patterns, and furnish critical insights\nthat propel the frontiers of technology and science. However, LLMs also pose\nprivacy concerns. Users' interactions with LLMs may expose their sensitive\npersonal or company information. A lack of robust privacy safeguards and legal\nframeworks could permit the unwarranted intrusion or improper handling of\nindividual data, thereby risking infringements of privacy and the theft of\npersonal identities. To ensure privacy, it is essential to minimize the\ndependency between shared prompts and private information. Various\nrandomization approaches have been proposed to protect prompts' privacy, but\nthey may incur utility loss compared to unprotected LLMs prompting. Therefore,\nit is essential to evaluate the balance between the risk of privacy leakage and\nloss of utility when conducting effective protection mechanisms. The current\nstudy develops a framework for inferring privacy-protected Large Language\nModels (LLMs) and lays down a solid theoretical basis for examining the\ninterplay between privacy preservation and utility. The core insight is\nencapsulated within a theorem that is called as the NFL (abbreviation of the\nword No-Free-Lunch) Theorem.",
      "tldr_zh": "该论文探讨了大型语言模型（LLMs）如 PaLM 和 ChatGPT 的益处（如提升生产力和数据分析能力）与隐私风险（如用户敏感信息泄露）的矛盾，强调了保护隐私的必要性。现有随机化方法虽可保护提示词隐私，但往往导致实用性损失，因此论文提出一个框架来推断隐私保护的 LLMs，并建立理论基础。核心贡献是 No-Free-Lunch Theorem，该定理分析了隐私保护与效用之间的权衡，提供了一个稳固的理论支撑。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20681v3",
      "published_date": "2024-05-31 08:22:53 UTC",
      "updated_date": "2025-02-28 02:38:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:41:08.624812"
    },
    {
      "arxiv_id": "2405.20680v5",
      "title": "Unraveling and Mitigating Retriever Inconsistencies in Retrieval-Augmented Large Language Models",
      "title_zh": "揭示和缓解检索增强大语言模型中检索器的不一致性",
      "authors": [
        "Mingda Li",
        "Xinyu Li",
        "Yifan Chen",
        "Wenfeng Xuan",
        "Weinan Zhang"
      ],
      "abstract": "Although Retrieval-Augmented Large Language Models (RALMs) demonstrate their\nsuperiority in terms of factuality, they do not consistently outperform the\noriginal retrieval-free Language Models (LMs). Our experiments reveal that this\nexample-level performance inconsistency exists not only between\nretrieval-augmented and retrieval-free LM but also among different retrievers.\nTo understand this phenomenon, we investigate the degeneration behavior of\nRALMs and theoretically decompose it into four categories. Further analysis\nbased on our decomposition reveals that the innate difference in knowledge\nsources and the unpredictable degeneration of the reader model contribute most\nto the inconsistency. Drawing from our analysis, we introduce Ensemble of\nRetrievers (EoR), a trainable framework that can adaptively retrieve from\ndifferent knowledge sources and effectively decrease unpredictable reader\nerrors. Our experiments on Open Domain Question Answering show that EoR\nsubstantially improves performance over the RALM with a single retriever by\nconsiderably reducing inconsistent behaviors.",
      "tldr_zh": "这篇论文揭示了Retrieval-Augmented Large Language Models (RALMs) 在性能上存在不一致性，即它们并不总是优于原始的检索-free Language Models (LMs)，且不同检索器之间也存在差异。作者通过理论分解将这种不一致性分为四类，并分析出知识来源的固有差异和读者模型的不可预测退化是主要原因。为缓解这些问题，他们提出了Ensemble of Retrievers (EoR)，一个可训练框架，能自适应地从多种知识来源检索并减少读者错误。在开放域问答实验中，EoR 显著提高了 RALMs 的性能，减少了不一致行为。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "ACL 2024 (findings)",
      "pdf_url": "http://arxiv.org/pdf/2405.20680v5",
      "published_date": "2024-05-31 08:22:49 UTC",
      "updated_date": "2025-03-06 05:34:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:41:20.644985"
    },
    {
      "arxiv_id": "2405.20675v1",
      "title": "Adv-KD: Adversarial Knowledge Distillation for Faster Diffusion Sampling",
      "title_zh": "Adv-KD：用于加速扩散采样的对抗知识蒸馏",
      "authors": [
        "Kidist Amde Mekonnen",
        "Nicola Dall'Asen",
        "Paolo Rota"
      ],
      "abstract": "Diffusion Probabilistic Models (DPMs) have emerged as a powerful class of\ndeep generative models, achieving remarkable performance in image synthesis\ntasks. However, these models face challenges in terms of widespread adoption\ndue to their reliance on sequential denoising steps during sample generation.\nThis dependence leads to substantial computational requirements, making them\nunsuitable for resource-constrained or real-time processing systems. To address\nthese challenges, we propose a novel method that integrates denoising phases\ndirectly into the model's architecture, thereby reducing the need for\nresource-intensive computations. Our approach combines diffusion models with\ngenerative adversarial networks (GANs) through knowledge distillation, enabling\nmore efficient training and evaluation. By utilizing a pre-trained diffusion\nmodel as a teacher model, we train a student model through adversarial\nlearning, employing layerwise transformations for denoising and submodules for\npredicting the teacher model's output at various points in time. This\nintegration significantly reduces the number of parameters and denoising steps\nrequired, leading to improved sampling speed at test time. We validate our\nmethod with extensive experiments, demonstrating comparable performance with\nreduced computational requirements compared to existing approaches. By enabling\nthe deployment of diffusion models on resource-constrained devices, our\nresearch mitigates their computational burden and paves the way for wider\naccessibility and practical use across the research community and end-users.\n  Our code is publicly available at https://github.com/kidist-amde/Adv-KD",
      "tldr_zh": "该论文针对扩散概率模型(DPMs)在图像合成中的高计算需求问题，提出了一种名为Adv-KD的对抗知识蒸馏方法，通过将去噪阶段整合到模型架构中并结合生成对抗网络(GANs)，显著减少了参数数量和去噪步骤。方法利用预训练的DPMs作为教师模型，通过对抗学习训练学生模型，包括层级变换和子模块预测教师输出，从而提升采样速度。实验结果显示，Adv-KD在保持性能可比的情况下，大幅降低了计算负担，使DPMs更适用于资源受限设备，并促进其在实际应用中的广泛部署。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "7 pages, 11 figures, ELLIS Doctoral Symposium 2023 in Helsinki,\n  Finland",
      "pdf_url": "http://arxiv.org/pdf/2405.20675v1",
      "published_date": "2024-05-31 08:19:44 UTC",
      "updated_date": "2024-05-31 08:19:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:41:32.160864"
    },
    {
      "arxiv_id": "2405.20671v2",
      "title": "Position Coupling: Improving Length Generalization of Arithmetic Transformers Using Task Structure",
      "title_zh": "位置耦合：使用任务结构改善算术Transformer的",
      "authors": [
        "Hanseul Cho",
        "Jaeyoung Cha",
        "Pranjal Awasthi",
        "Srinadh Bhojanapalli",
        "Anupam Gupta",
        "Chulhee Yun"
      ],
      "abstract": "Even for simple arithmetic tasks like integer addition, it is challenging for\nTransformers to generalize to longer sequences than those encountered during\ntraining. To tackle this problem, we propose position coupling, a simple yet\neffective method that directly embeds the structure of the tasks into the\npositional encoding of a (decoder-only) Transformer. Taking a departure from\nthe vanilla absolute position mechanism assigning unique position IDs to each\nof the tokens, we assign the same position IDs to two or more \"relevant\"\ntokens; for integer addition tasks, we regard digits of the same significance\nas in the same position. On the empirical side, we show that with the proposed\nposition coupling, our models trained on 1 to 30-digit additions can generalize\nup to 200-digit additions (6.67x of the trained length). On the theoretical\nside, we prove that a 1-layer Transformer with coupled positions can solve the\naddition task involving exponentially many digits, whereas any 1-layer\nTransformer without positional information cannot entirely solve it. We also\ndemonstrate that position coupling can be applied to other algorithmic tasks\nsuch as Nx2 multiplication and a two-dimensional task.",
      "tldr_zh": "该研究针对 Transformers 在算术任务（如整数加法）中难以泛化到训练长度之外的序列问题，提出了一种名为 position coupling 的方法，通过在位置编码中嵌入任务结构（如为相同数位的数字分配相同的 position ID），来提升模型的长度泛化能力。实验结果显示，训练于1到30位加法的模型能够泛化到200位加法（相当于训练长度的6.67倍）。理论上，该方法证明了1层 Transformer 带有 coupled positions 时能处理指数级位数的加法任务，而无位置信息的模型则无法完全解决；此外，position coupling 还适用于其他算法任务，如 Nx2 乘法和二维任务。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to NeurIPS 2024. 76 pages. 23 figures. 90 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.20671v2",
      "published_date": "2024-05-31 08:13:35 UTC",
      "updated_date": "2024-10-30 16:50:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:41:46.444157"
    },
    {
      "arxiv_id": "2405.20656v5",
      "title": "Automatic Counting and Classification of Mosquito Eggs in Field Traps",
      "title_zh": "田间陷阱中蚊子卵的自动计数和分类",
      "authors": [
        "Javier Naranjo-Alcazar",
        "Jordi Grau-Haro",
        "Pedro Zuccarello",
        "David Almenar",
        "Jesus Lopez-Ballester"
      ],
      "abstract": "Insect pest control poses a global challenge, affecting public health, food\nsafety, and the environment. Diseases transmitted by mosquitoes are expanding\nbeyond tropical regions due to climate change. Agricultural pests further\nexacerbate economic losses by damaging crops. The Sterile Insect Technique\n(SIT) emerges as an eco-friendly alternative to chemical pesticides, involving\nthe sterilization and release of male insects to curb population growth. This\nwork focuses on the automation of the analysis of field ovitraps used to\nfollow-up a SIT program for the Aedes albopictus mosquito in the Valencian\nCommunity, Spain, funded by the Conselleria de Agricultura, Agua, Ganaderia y\nPesca. Previous research has leveraged deep learning algorithms to automate egg\ncounting in ovitraps, yet faced challenges such as manual handling and limited\nanalysis capacity. Innovations in our study include classifying eggs as hatched\nor unhatched and reconstructing ovitraps from partial images, mitigating issues\nof duplicity and cut eggs. Also, our device can analyze multiple ovitraps\nsimultaneously without the need of manual replacement. This approach\nsignificantly enhances the accuracy of egg counting and classification,\nproviding a valuable tool for large-scale field studies.\n  This document describes part of the work of the project Application of\nIndustry 4.0 techniques to the production of tiger mosquitoes for the Sterile\nInsect Technique (MoTIA2,IMDEEA/2022/70), financed by the Valencian Institute\nfor Business Competitiveness (IVACE) and the FEDER funds. The participation of\nJ.Naranjo-Alcazar, J.Grau-Haro and P.Zuccarello has been possible thanks to\nfunding from IVACE and FEDER funds. The participation of D.Almenar has been\nfinanced by the Conselleria de Agricultura, Agua, Ganaderia y Pesca of the\nGeneralitat Valenciana and the Subdireccion de Innovacion y Desarrollo de\nServicios (TRAGSA group).",
      "tldr_zh": "本文提出了一种自动化系统，用于计数和分类野外卵陷阱（ovitraps）中的蚊子卵，旨在支持无菌昆虫技术（SIT）程序，针对Aedes albopictus蚊子传播疾病的防控。该系统采用深度学习算法，实现卵的已孵化或未孵化分类、从部分图像重建陷阱，以及同时分析多个陷阱而无需手动更换，解决了传统方法的局限性。结果显示，该方法显著提高了计数和分类准确性，为大规模野外研究提供高效工具。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20656v5",
      "published_date": "2024-05-31 07:48:48 UTC",
      "updated_date": "2024-10-14 13:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:41:57.806818"
    },
    {
      "arxiv_id": "2405.20653v2",
      "title": "Enhancing Jailbreak Attack Against Large Language Models through Silent Tokens",
      "title_zh": "翻译失败",
      "authors": [
        "Jiahao Yu",
        "Haozheng Luo",
        "Jerry Yao-Chieh Hu",
        "Wenbo Guo",
        "Han Liu",
        "Xinyu Xing"
      ],
      "abstract": "Along with the remarkable successes of Language language models, recent\nresearch also started to explore the security threats of LLMs, including\njailbreaking attacks. Attackers carefully craft jailbreaking prompts such that\na target LLM will respond to the harmful question. Existing jailbreaking\nattacks require either human experts or leveraging complicated algorithms to\ncraft jailbreaking prompts. In this paper, we introduce BOOST, a simple attack\nthat leverages only the eos tokens. We demonstrate that rather than\nconstructing complicated jailbreaking prompts, the attacker can simply append a\nfew eos tokens to the end of a harmful question. It will bypass the safety\nalignment of LLMs and lead to successful jailbreaking attacks. We further apply\nBOOST to four representative jailbreak methods and show that the attack success\nrates of these methods can be significantly enhanced by simply adding eos\ntokens to the prompt. To understand this simple but novel phenomenon, we\nconduct empirical analyses. Our analysis reveals that adding eos tokens makes\nthe target LLM believe the input is much less harmful, and eos tokens have low\nattention values and do not affect LLM's understanding of the harmful\nquestions, leading the model to actually respond to the questions. Our findings\nuncover how fragile an LLM is against jailbreak attacks, motivating the\ndevelopment of strong safety alignment approaches.",
      "tldr_zh": "本文提出BOOST，一种简单的大语言模型(LLMs)越狱攻击(jailbreaking attacks)方法，仅通过在有害问题末尾附加几个eos tokens，就能绕过模型的安全对齐机制，实现成功攻击。实验结果显示，BOOST显著提升了四种代表性攻击方法的成功率，并通过实证分析揭示，eos tokens使LLMs低估输入的危害性，同时不影响模型对问题的理解。该研究暴露了LLMs在安全方面的脆弱性，呼吁开发更强的安全对齐(safety alignment)策略。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20653v2",
      "published_date": "2024-05-31 07:41:03 UTC",
      "updated_date": "2024-06-04 20:29:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:42:08.669731"
    },
    {
      "arxiv_id": "2405.20643v1",
      "title": "Learning Gaze-aware Compositional GAN",
      "title_zh": "翻译失败",
      "authors": [
        "Nerea Aranjuelo",
        "Siyu Huang",
        "Ignacio Arganda-Carreras",
        "Luis Unzueta",
        "Oihana Otaegui",
        "Hanspeter Pfister",
        "Donglai Wei"
      ],
      "abstract": "Gaze-annotated facial data is crucial for training deep neural networks\n(DNNs) for gaze estimation. However, obtaining these data is labor-intensive\nand requires specialized equipment due to the challenge of accurately\nannotating the gaze direction of a subject. In this work, we present a\ngenerative framework to create annotated gaze data by leveraging the benefits\nof labeled and unlabeled data sources. We propose a Gaze-aware Compositional\nGAN that learns to generate annotated facial images from a limited labeled\ndataset. Then we transfer this model to an unlabeled data domain to take\nadvantage of the diversity it provides. Experiments demonstrate our approach's\neffectiveness in generating within-domain image augmentations in the ETH-XGaze\ndataset and cross-domain augmentations in the CelebAMask-HQ dataset domain for\ngaze estimation DNN training. We also show additional applications of our work,\nwhich include facial image editing and gaze redirection.",
      "tldr_zh": "该研究解决了获取注视（gaze）标注面部数据 laborious 的问题，提出了一种 Gaze-aware Compositional GAN 框架，利用有限的标记数据集生成标注的注视图像，并将模型转移到未标记数据域以提升数据多样性。实验结果显示，该框架在 ETH-XGaze 数据集上实现了有效的同域图像增强，在 CelebAMask-HQ 数据集上实现了跨域增强，从而改善了注视估计 DNN 的训练性能。此外，该方法还扩展了应用，包括面部图像编辑和注视重定向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ETRA 2024 as Full paper, and as journal paper in\n  Proceedings of the ACM on Computer Graphics and Interactive Techniques",
      "pdf_url": "http://arxiv.org/pdf/2405.20643v1",
      "published_date": "2024-05-31 07:07:54 UTC",
      "updated_date": "2024-05-31 07:07:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:42:20.899500"
    },
    {
      "arxiv_id": "2405.20628v2",
      "title": "ToxVidLM: A Multimodal Framework for Toxicity Detection in Code-Mixed Videos",
      "title_zh": "翻译失败",
      "authors": [
        "Krishanu Maity",
        "A. S. Poornash",
        "Sriparna Saha",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "In an era of rapidly evolving internet technology, the surge in multimodal\ncontent, including videos, has expanded the horizons of online communication.\nHowever, the detection of toxic content in this diverse landscape, particularly\nin low-resource code-mixed languages, remains a critical challenge. While\nsubstantial research has addressed toxic content detection in textual data, the\nrealm of video content, especially in non-English languages, has been\nrelatively underexplored. This paper addresses this research gap by introducing\na benchmark dataset, the first of its kind, consisting of 931 videos with 4021\ncode-mixed Hindi-English utterances collected from YouTube. Each utterance\nwithin this dataset has been meticulously annotated for toxicity, severity, and\nsentiment labels. We have developed an advanced Multimodal Multitask framework\nbuilt for Toxicity detection in Video Content by leveraging Language Models\n(LMs), crafted for the primary objective along with the additional tasks of\nconducting sentiment and severity analysis. ToxVidLM incorporates three key\nmodules - the Encoder module, Cross-Modal Synchronization module, and Multitask\nmodule - crafting a generic multimodal LM customized for intricate video\nclassification tasks. Our experiments reveal that incorporating multiple\nmodalities from the videos substantially enhances the performance of toxic\ncontent detection by achieving an Accuracy and Weighted F1 score of 94.29% and\n94.35%, respectively.",
      "tldr_zh": "该论文针对低资源代码混合语言（如印地-英语）视频中的毒性内容检测问题，引入了首个基准数据集ToxVidLM，包含931个YouTube视频和4021个标注了毒性、严重性和情感标签的话语。ToxVidLM框架采用多模态多任务方法，包括Encoder模块、Cross-Modal Synchronization模块和Multitask模块，利用语言模型（LMs）同时处理毒性检测、情感分析和严重性评估。实验结果显示，该框架通过整合视频的多模态信息，实现了94.29%的准确率和94.35%的加权F1分数，显著提升了检测性能。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted as a Long Paper in ACL Findings 2024. For acceptance\n  details, see https://2024.aclweb.org/program/finding_papers/",
      "pdf_url": "http://arxiv.org/pdf/2405.20628v2",
      "published_date": "2024-05-31 05:40:56 UTC",
      "updated_date": "2024-07-14 07:09:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:42:33.051174"
    },
    {
      "arxiv_id": "2405.20625v1",
      "title": "Robust Planning with LLM-Modulo Framework: Case Study in Travel Planning",
      "title_zh": "使用 LLM-Modulo 框架的稳健规划：旅游规划案例研究",
      "authors": [
        "Atharva Gundawar",
        "Mudit Verma",
        "Lin Guan",
        "Karthik Valmeekam",
        "Siddhant Bhambri",
        "Subbarao Kambhampati"
      ],
      "abstract": "As the applicability of Large Language Models (LLMs) extends beyond\ntraditional text processing tasks, there is a burgeoning interest in their\npotential to excel in planning and reasoning assignments, realms traditionally\nreserved for System 2 cognitive competencies. Despite their perceived\nversatility, the research community is still unraveling effective strategies to\nharness these models in such complex domains. The recent discourse introduced\nby the paper on LLM Modulo marks a significant stride, proposing a conceptual\nframework that enhances the integration of LLMs into diverse planning and\nreasoning activities. This workshop paper delves into the practical application\nof this framework within the domain of travel planning, presenting a specific\ninstance of its implementation. We are using the Travel Planning benchmark by\nthe OSU NLP group, a benchmark for evaluating the performance of LLMs in\nproducing valid itineraries based on user queries presented in natural\nlanguage. While popular methods of enhancing the reasoning abilities of LLMs\nsuch as Chain of Thought, ReAct, and Reflexion achieve a meager 0%, 0.6%, and\n0% with GPT3.5-Turbo respectively, our operationalization of the LLM-Modulo\nframework for TravelPlanning domain provides a remarkable improvement,\nenhancing baseline performances by 4.6x for GPT4-Turbo and even more for older\nmodels like GPT3.5-Turbo from 0% to 5%. Furthermore, we highlight the other\nuseful roles of LLMs in the planning pipeline, as suggested in LLM-Modulo,\nwhich can be reliably operationalized such as extraction of useful critics and\nreformulator for critics.",
      "tldr_zh": "这篇论文探讨了LLM-Modulo框架在旅行规划领域的应用，旨在提升大型语言模型（LLMs）在规划和推理任务中的鲁棒性。研究使用OSU NLP组的Travel Planning基准进行实验，与传统方法如Chain of Thought、ReAct和Reflexion相比，该框架显著提高了性能，例如GPT4-Turbo的准确率提升4.6倍，而GPT3.5-Turbo从0%提高到5%。此外，论文强调了LLMs在规划管道中的其他角色，如提取批评者（critics）和改革者（reformulator），为更可靠的规划系统提供了新思路。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20625v1",
      "published_date": "2024-05-31 05:23:35 UTC",
      "updated_date": "2024-05-31 05:23:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:42:45.972652"
    },
    {
      "arxiv_id": "2405.20624v1",
      "title": "Leveraging Large Language Models for Entity Matching",
      "title_zh": "利用大型语言模型进行实体匹配",
      "authors": [
        "Qianyu Huang",
        "Tongfang Zhao"
      ],
      "abstract": "Entity matching (EM) is a critical task in data integration, aiming to\nidentify records across different datasets that refer to the same real-world\nentities. Traditional methods often rely on manually engineered features and\nrule-based systems, which struggle with diverse and unstructured data. The\nemergence of Large Language Models (LLMs) such as GPT-4 offers transformative\npotential for EM, leveraging their advanced semantic understanding and\ncontextual capabilities. This vision paper explores the application of LLMs to\nEM, discussing their advantages, challenges, and future research directions.\nAdditionally, we review related work on applying weak supervision and\nunsupervised approaches to EM, highlighting how LLMs can enhance these methods.",
      "tldr_zh": "实体匹配（EM）是数据整合中的关键任务，旨在识别不同数据集中的相同实体记录，但传统方法依赖手动特征和规则系统，往往难以处理多样化和非结构化数据。本文探讨利用大型语言模型（LLMs）如 GPT-4 来提升 EM，通过其先进的语义理解和上下文能力，解决现有方法的局限性。论文分析了 LLMs 在 EM 中的优势、潜在挑战以及未来研究方向，同时回顾了弱监督和无监督方法，并说明 LLMs 如何增强这些技术。该愿景为开发更高效的 EM 系统提供了新思路。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20624v1",
      "published_date": "2024-05-31 05:22:07 UTC",
      "updated_date": "2024-05-31 05:22:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:42:58.248638"
    },
    {
      "arxiv_id": "2406.11872v3",
      "title": "The EarlyBird Gets the WORM: Heuristically Accelerating EarlyBird Convergence",
      "title_zh": "翻译失败",
      "authors": [
        "Adithya Vasudev"
      ],
      "abstract": "The Lottery Ticket hypothesis proposes that ideal, sparse subnetworks, called\nlottery tickets, exist in untrained dense neural networks. The Early Bird\nhypothesis proposes an efficient algorithm to find these winning lottery\ntickets in convolutional neural networks, using the novel concept of distance\nbetween subnetworks to detect convergence in the subnetworks of a model.\nHowever, this approach overlooks unchanging groups of unimportant neurons near\nthe search's end. We proposes WORM, a method that exploits these static groups\nby truncating their gradients, forcing the model to rely on other neurons.\nExperiments show WORM achieves faster ticket identification during training on\nconvolutional neural networks, despite the additional computational overhead,\nwhen compared to EarlyBird search. Additionally, WORM-pruned models lose less\naccuracy during pruning and recover accuracy faster, improving the robustness\nof a given model. Furthermore, WORM is also able to generalize the Early Bird\nhypothesis reasonably well to larger models, such as transformers, displaying\nits flexibility to adapt to more complex architectures.",
      "tldr_zh": "这篇论文提出了 WORM 方法，用于加速 Early Bird hypothesis 在寻找 Lottery Ticket hypothesis 中的收敛，针对 Early Bird 算法忽略不变神经元组的问题。WORM 通过截断这些静态神经元组的梯度，迫使模型依赖其他神经元，从而更高效地识别彩票票。实验结果显示，在卷积神经网络上，WORM 缩短了训练时间，尽管有额外计算开销，且修剪后的模型准确性损失更少、恢复更快；此外，该方法还能推广到更大的架构如 Transformers，提高了模型的鲁棒性和灵活性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted to the Efficient Natural Language and Speech Processing\n  Workshop at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2406.11872v3",
      "published_date": "2024-05-31 05:13:02 UTC",
      "updated_date": "2024-12-11 01:21:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:43:11.229688"
    },
    {
      "arxiv_id": "2405.20612v2",
      "title": "UniBias: Unveiling and Mitigating LLM Bias through Internal Attention and FFN Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Hanzhang Zhou",
        "Zijian Feng",
        "Zixiao Zhu",
        "Junlang Qian",
        "Kezhi Mao"
      ],
      "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nvarious tasks using the in-context learning (ICL) paradigm. However, their\neffectiveness is often compromised by inherent bias, leading to prompt\nbrittleness, i.e., sensitivity to design settings such as example selection,\norder, and prompt formatting. Previous studies have addressed LLM bias through\nexternal adjustment of model outputs, but the internal mechanisms that lead to\nsuch bias remain unexplored. Our work delves into these mechanisms,\nparticularly investigating how feedforward neural networks (FFNs) and attention\nheads result in the bias of LLMs. By Interpreting the contribution of\nindividual FFN vectors and attention heads, we identify the biased LLM\ncomponents that skew LLMs' prediction toward specific labels. To mitigate these\nbiases, we introduce UniBias, an inference-only method that effectively\nidentifies and eliminates biased FFN vectors and attention heads. Extensive\nexperiments across 12 NLP datasets demonstrate that UniBias significantly\nenhances ICL performance and alleviates prompt brittleness of LLMs.",
      "tldr_zh": "本研究揭示了大型语言模型 (LLMs) 在 in-context learning (ICL) 中的固有偏见问题，这种偏见会导致模型对提示设计（如示例选择、顺序和格式）高度敏感。论文通过分析 feedforward neural networks (FFNs) 和 attention heads 的内部机制，解释了这些组件如何导致偏见，并识别出具体偏见来源。作者提出 UniBias，这是一种仅在推理阶段的操作方法，用于有效识别和消除偏见的 FFN 向量及 attention heads。在 12 个 NLP 数据集上的广泛实验表明，UniBias 显著提高了 ICL 性能，并缓解了提示敏感性问题。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.20612v2",
      "published_date": "2024-05-31 03:59:15 UTC",
      "updated_date": "2024-12-12 10:46:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:43:26.398990"
    },
    {
      "arxiv_id": "2405.20606v2",
      "title": "Vision-Language Meets the Skeleton: Progressively Distillation with Cross-Modal Knowledge for 3D Action Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Chen",
        "Tian He",
        "Junfeng Fu",
        "Ling Wang",
        "Jingcai Guo",
        "Ting Hu",
        "Hong Cheng"
      ],
      "abstract": "Skeleton-based action representation learning aims to interpret and\nunderstand human behaviors by encoding the skeleton sequences, which can be\ncategorized into two primary training paradigms: supervised learning and\nself-supervised learning. However, the former one-hot classification requires\nlabor-intensive predefined action categories annotations, while the latter\ninvolves skeleton transformations (e.g., cropping) in the pretext tasks that\nmay impair the skeleton structure. To address these challenges, we introduce a\nnovel skeleton-based training framework (C$^2$VL) based on Cross-modal\nContrastive learning that uses the progressive distillation to learn\ntask-agnostic human skeleton action representation from the Vision-Language\nknowledge prompts. Specifically, we establish the vision-language action\nconcept space through vision-language knowledge prompts generated by\npre-trained large multimodal models (LMMs), which enrich the fine-grained\ndetails that the skeleton action space lacks. Moreover, we propose the\nintra-modal self-similarity and inter-modal cross-consistency softened targets\nin the cross-modal representation learning process to progressively control and\nguide the degree of pulling vision-language knowledge prompts and corresponding\nskeletons closer. These soft instance discrimination and self-knowledge\ndistillation strategies contribute to the learning of better skeleton-based\naction representations from the noisy skeleton-vision-language pairs. During\nthe inference phase, our method requires only the skeleton data as the input\nfor action recognition and no longer for vision-language prompts. Extensive\nexperiments on NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets demonstrate\nthat our method outperforms the previous methods and achieves state-of-the-art\nresults. Code is available at: https://github.com/cseeyangchen/C2VL.",
      "tldr_zh": "本文提出 C²VL 框架，通过跨模态对比学习和渐进式蒸馏，从 Vision-Language 知识提示中学习任务无关的 3D 骨骼行动表示，解决了传统监督和自监督方法在标注需求和结构完整性方面的挑战。框架利用预训练的大型多模态模型生成视觉-语言知识提示，并引入 intra-modal self-similarity 和 inter-modal cross-consistency 软化目标来逐步引导跨模态知识融合，提升骨骼表示的鲁棒性。实验结果显示，该方法在 NTU RGB+D 60、NTU RGB+D 120 和 PKU-MMD 数据集上超越了现有技术，实现了 state-of-the-art 性能，且推理阶段仅需骨骼数据作为输入。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by IEEE Transactions on Multimedia",
      "pdf_url": "http://arxiv.org/pdf/2405.20606v2",
      "published_date": "2024-05-31 03:40:15 UTC",
      "updated_date": "2024-09-15 03:32:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:43:36.873870"
    },
    {
      "arxiv_id": "2405.20605v2",
      "title": "Searching for internal symbols underlying deep learning",
      "title_zh": "搜索深度学习的内部符号",
      "authors": [
        "Jung H. Lee",
        "Sujith Vijayan"
      ],
      "abstract": "Deep learning (DL) enables deep neural networks (DNNs) to automatically learn\ncomplex tasks or rules from given examples without instructions or guiding\nprinciples. As we do not engineer DNNs' functions, it is extremely difficult to\ndiagnose their decisions, and multiple lines of studies proposed to explain the\nprinciples of their operations. Notably, one line of studies suggests that DNNs\nmay learn concepts, the high level features that are recognizable to humans. In\nthis study, we extend this line of studies and hypothesize that DNNs can\ndevelop abstract codes that can be used to augment DNNs' decision-making. To\naddress this hypothesis, we combine foundation segmentation models and\nunsupervised learning to extract internal codes and identify potential use of\nabstract codes to make DL's decision-making more reliable and safer.",
      "tldr_zh": "这篇论文探讨了深度神经网络（DNNs）在深度学习（Deep Learning）中的内部符号，假设DNNs 可以开发抽象代码（abstract codes）来增强决策过程，从而解决现有模型的可解释性和可靠性问题。作者扩展了相关研究，通过结合 foundation segmentation models 和 unsupervised learning 来提取这些内部符号，并识别其潜在应用。结果表明，这种方法有望使DL的决策更可靠和安全，为改进神经网络的可解释性提供新途径。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 10 figures, 5 tables and 1 supplementary table",
      "pdf_url": "http://arxiv.org/pdf/2405.20605v2",
      "published_date": "2024-05-31 03:39:26 UTC",
      "updated_date": "2024-11-18 01:47:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:43:46.970931"
    },
    {
      "arxiv_id": "2405.20603v1",
      "title": "Advancing Financial Risk Prediction Through Optimized LSTM Model Performance and Comparative Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Ke Xu",
        "Yu Cheng",
        "Shiqing Long",
        "Junjie Guo",
        "Jue Xiao",
        "Mengfang Sun"
      ],
      "abstract": "This paper focuses on the application and optimization of LSTM model in\nfinancial risk prediction. The study starts with an overview of the\narchitecture and algorithm foundation of LSTM, and then details the model\ntraining process and hyperparameter tuning strategy, and adjusts network\nparameters through experiments to improve performance. Comparative experiments\nshow that the optimized LSTM model shows significant advantages in AUC index\ncompared with random forest, BP neural network and XGBoost, which verifies its\nefficiency and practicability in the field of financial risk prediction,\nespecially its ability to deal with complex time series data, which lays a\nsolid foundation for the application of the model in the actual production\nenvironment.",
      "tldr_zh": "该论文探讨了优化 LSTM 模型在金融风险预测中的应用，包括 LSTM 的架构基础、模型训练过程以及超参数调整策略，通过实验优化网络参数以提升性能。比较实验显示，优化后的 LSTM 模型在 AUC 指标上显著优于 Random Forest、BP Neural Network 和 XGBoost，突显其处理复杂时间序列数据的优势。最终，该研究验证了 LSTM 在金融风险预测领域的效率和实用性，为其在实际生产环境中的部署奠定了坚实基础。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20603v1",
      "published_date": "2024-05-31 03:31:17 UTC",
      "updated_date": "2024-05-31 03:31:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:44:00.062725"
    },
    {
      "arxiv_id": "2405.20600v1",
      "title": "Multi-label Class Incremental Emotion Decoding with Augmented Emotional Semantics Learning",
      "title_zh": "多标签类增量情绪解码，结合增强情感语义学习",
      "authors": [
        "Kaicheng Fu",
        "Changde Du",
        "Xiaoyu Chen",
        "Jie Peng",
        "Huiguang He"
      ],
      "abstract": "Emotion decoding plays an important role in affective human-computer\ninteraction. However, previous studies ignored the dynamic real-world scenario,\nwhere human experience a blend of multiple emotions which are incrementally\nintegrated into the model, leading to the multi-label class incremental\nlearning (MLCIL) problem. Existing methods have difficulty in solving MLCIL\nissue due to notorious catastrophic forgetting caused by partial label problem\nand inadequate label semantics mining. In this paper, we propose an augmented\nemotional semantics learning framework for multi-label class incremental\nemotion decoding. Specifically, we design an augmented emotional relation graph\nmodule with label disambiguation to handle the past-missing partial label\nproblem. Then, we leverage domain knowledge from affective dimension space to\nalleviate future-missing partial label problem by knowledge distillation.\nBesides, an emotional semantics learning module is constructed with a graph\nautoencoder to obtain emotion embeddings in order to guide the\nsemantic-specific feature decoupling for better multi-label learning. Extensive\nexperiments on three datasets show the superiority of our method for improving\nemotion decoding performance and mitigating forgetting on MLCIL problem.",
      "tldr_zh": "本文提出了一种增强情感语义学习框架，用于解决多标签类增量学习 (MLCIL) 中的灾难性遗忘问题和部分标签问题，提升情感解码性能。框架包括增强情感关系图模块（augmented emotional relation graph module），通过标签消歧（label disambiguation）处理过去的缺失部分标签问题，以及利用情感维度空间的领域知识通过知识蒸馏（knowledge distillation）缓解未来的缺失标签问题。同时，该框架构建了情感语义学习模块，使用图自编码器（graph autoencoder）获取情感嵌入（emotion embeddings），并指导语义特定的特征解耦（semantic-specific feature decoupling）。在三个数据集上的广泛实验显示，该方法显著提高了情感解码性能并有效缓解了遗忘问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20600v1",
      "published_date": "2024-05-31 03:16:54 UTC",
      "updated_date": "2024-05-31 03:16:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:44:13.637157"
    },
    {
      "arxiv_id": "2405.20594v1",
      "title": "Deep Learning without Weight Symmetry",
      "title_zh": "深度学习无权重对称性",
      "authors": [
        "Li Ji-An",
        "Marcus K. Benna"
      ],
      "abstract": "Backpropagation (BP), a foundational algorithm for training artificial neural\nnetworks, predominates in contemporary deep learning. Although highly\nsuccessful, it is often considered biologically implausible. A significant\nlimitation arises from the need for precise symmetry between connections in the\nbackward and forward pathways to backpropagate gradient signals accurately,\nwhich is not observed in biological brains. Researchers have proposed several\nalgorithms to alleviate this symmetry constraint, such as feedback alignment\nand direct feedback alignment. However, their divergence from backpropagation\ndynamics presents challenges, particularly in deeper networks and convolutional\nlayers. Here we introduce the Product Feedback Alignment (PFA) algorithm. Our\nfindings demonstrate that PFA closely approximates BP and achieves comparable\nperformance in deep convolutional networks while avoiding explicit weight\nsymmetry. Our results offer a novel solution to the longstanding weight\nsymmetry problem, leading to more biologically plausible learning in deep\nconvolutional networks compared to earlier methods.",
      "tldr_zh": "本研究针对Backpropagation (BP)算法在深度学习中的权重对称性要求问题，该要求不符生物大脑机制，并分析了现有方法如feedback alignment和direct feedback alignment在深层网络和卷积层中的挑战。论文提出了一种新算法Product Feedback Alignment (PFA)，它能近似BP的表现，同时避免显式权重对称性。实验结果显示，PFA在深层卷积网络中实现了与BP相当的性能，并为更生物可解释的学习提供了创新解决方案。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "q-bio.NC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20594v1",
      "published_date": "2024-05-31 03:11:19 UTC",
      "updated_date": "2024-05-31 03:11:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:44:21.859881"
    },
    {
      "arxiv_id": "2405.20592v2",
      "title": "LInK: Learning Joint Representations of Design and Performance Spaces through Contrastive Learning for Mechanism Synthesis",
      "title_zh": "LInK",
      "authors": [
        "Amin Heyrani Nobari",
        "Akash Srivastava",
        "Dan Gutfreund",
        "Kai Xu",
        "Faez Ahmed"
      ],
      "abstract": "In this paper, we introduce LInK, a novel framework that integrates\ncontrastive learning of performance and design space with optimization\ntechniques for solving complex inverse problems in engineering design with\ndiscrete and continuous variables. We focus on the path synthesis problem for\nplanar linkage mechanisms. By leveraging a multimodal and\ntransformation-invariant contrastive learning framework, LInK learns a joint\nrepresentation that captures complex physics and design representations of\nmechanisms, enabling rapid retrieval from a vast dataset of over 10 million\nmechanisms. This approach improves precision through the warm start of a\nhierarchical unconstrained nonlinear optimization algorithm, combining the\nrobustness of traditional optimization with the speed and adaptability of\nmodern deep learning methods. Our results on an existing benchmark demonstrate\nthat LInK outperforms existing methods with 28 times less error compared to a\nstate of the art approach while taking 20 times less time on an existing\nbenchmark. Moreover, we introduce a significantly more challenging benchmark,\nnamed LINK ABC, which involves synthesizing linkages that trace the\ntrajectories of English capital alphabets, an inverse design benchmark task\nthat existing methods struggle with due to large nonlinearities and tiny\nfeasible space. Our results demonstrate that LInK not only advances the field\nof mechanism design but also broadens the applicability of contrastive learning\nand optimization to other areas of engineering. The code and data are publicly\navailable at https://github.com/ahnobari/LInK.",
      "tldr_zh": "本研究提出LInK框架，通过Contrastive Learning学习设计和性能空间的联合表示，并结合优化技术，解决工程设计中涉及离散和连续变量的复杂逆问题，特别是平面连杆机构的路径合成任务。该框架采用多模态和变换不变的Contrastive Learning方法，从超过1000万机制的数据集中实现快速检索，并通过为分层无约束非线性优化算法提供热启动，提升了精度和效率。在现有基准测试中，LInK比最先进方法错误减少28倍、时间减少20倍；此外，该框架引入更具挑战性的LINK ABC基准，处理英语大写字母轨迹合成问题，展示了其在机制设计领域的显著进展，并扩展了Contrastive Learning和优化技术的工程应用。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20592v2",
      "published_date": "2024-05-31 03:04:57 UTC",
      "updated_date": "2024-10-04 17:13:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:44:36.183702"
    },
    {
      "arxiv_id": "2405.20590v1",
      "title": "Class-Based Time Series Data Augmentation to Mitigate Extreme Class Imbalance for Solar Flare Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Junzhi Wen",
        "Rafal A. Angryk"
      ],
      "abstract": "Time series data plays a crucial role across various domains, making it\nvaluable for decision-making and predictive modeling. Machine learning (ML) and\ndeep learning (DL) have shown promise in this regard, yet their performance\nhinges on data quality and quantity, often constrained by data scarcity and\nclass imbalance, particularly for rare events like solar flares. Data\naugmentation techniques offer a potential solution to address these challenges,\nyet their effectiveness on multivariate time series datasets remains\nunderexplored. In this study, we propose a novel data augmentation method for\ntime series data named Mean Gaussian Noise (MGN). We investigate the\nperformance of MGN compared to eight existing basic data augmentation methods\non a multivariate time series dataset for solar flare prediction, SWAN-SF,\nusing a ML algorithm for time series data, TimeSeriesSVC. The results\ndemonstrate the efficacy of MGN and highlight its potential for improving\nclassification performance in scenarios with extremely imbalanced data. Our\ntime complexity analysis shows that MGN also has a competitive computational\ncost compared to the investigated alternative methods.",
      "tldr_zh": "本研究针对时间序列数据中的极端类别不平衡问题，特别是应用于太阳耀斑预测（Solar Flare Prediction），提出了一种新型数据增强方法Mean Gaussian Noise (MGN)。该方法通过添加均值高斯噪声来生成合成样本，以缓解数据稀缺和不平衡挑战，并与八种现有数据增强技术在SWAN-SF多变量时间序列数据集上进行比较，使用TimeSeriesSVC算法进行评估。结果显示，MGN显著提高了分类性能，尤其在极端不平衡场景中，并展示了与替代方法相比具有竞争力的时间复杂度，为类似任务的机器学习建模提供了有效解决方案。",
      "categories": [
        "cs.LG",
        "astro-ph.IM",
        "astro-ph.SR",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20590v1",
      "published_date": "2024-05-31 03:03:19 UTC",
      "updated_date": "2024-05-31 03:03:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:44:47.819764"
    },
    {
      "arxiv_id": "2405.20589v1",
      "title": "Selective Knowledge Sharing for Personalized Federated Learning Under Capacity Heterogeneity",
      "title_zh": "翻译失败",
      "authors": [
        "Zheng Wang",
        "Zheng Wang",
        "Zhaopeng Peng",
        "Zihui Wang",
        "Cheng Wang"
      ],
      "abstract": "Federated Learning (FL) stands to gain significant advantages from\ncollaboratively training capacity-heterogeneous models, enabling the\nutilization of private data and computing power from low-capacity devices.\nHowever, the focus on personalizing capacity-heterogeneous models based on\nclient-specific data has been limited, resulting in suboptimal local model\nutility, particularly for low-capacity clients. The heterogeneity in both data\nand device capacity poses two key challenges for model personalization: 1)\naccurately retaining necessary knowledge embedded within reduced submodels for\neach client, and 2) effectively sharing knowledge through aggregating\nsize-varying parameters. To this end, we introduce Pa3dFL, a novel framework\ndesigned to enhance local model performance by decoupling and selectively\nsharing knowledge among capacity-heterogeneous models. First, we decompose each\nlayer of the model into general and personal parameters. Then, we maintain\nuniform sizes for the general parameters across clients and aggregate them\nthrough direct averaging. Subsequently, we employ a hyper-network to generate\nsize-varying personal parameters for clients using learnable embeddings.\nFinally, we facilitate the implicit aggregation of personal parameters by\naggregating client embeddings through a self-attention module. We conducted\nextensive experiments on three datasets to evaluate the effectiveness of\nPa3dFL. Our findings indicate that Pa3dFL consistently outperforms baseline\nmethods across various heterogeneity settings. Moreover, Pa3dFL demonstrates\ncompetitive communication and computation efficiency compared to baseline\napproaches, highlighting its practicality and adaptability in adverse system\nconditions.",
      "tldr_zh": "该研究针对联邦学习（Federated Learning, FL）中容量异质性问题，提出了一种名为 Pa3dFL 的新框架，以提升个性化模型的本地性能。该框架通过将模型层分解为通用参数和个人参数，保持通用参数大小一致并直接平均聚合，同时使用超网络（hyper-network）生成大小可变的个人参数，并通过自注意力模块（self-attention module）隐式聚合客户端嵌入，从而实现选择性知识共享。实验结果显示，Pa3dFL 在三个数据集上优于基线方法，尤其在各种异质性设置下表现出色，同时保持了竞争力的通信和计算效率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20589v1",
      "published_date": "2024-05-31 02:59:25 UTC",
      "updated_date": "2024-05-31 02:59:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:44:57.824415"
    },
    {
      "arxiv_id": "2407.03146v3",
      "title": "Understanding and Reducing the Class-Dependent Effects of Data Augmentation with A Two-Player Game Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Yunpeng Jiang",
        "Paul Weng",
        "Yutong Ban"
      ],
      "abstract": "Data augmentation is widely applied and has shown its benefits in different\nmachine learning tasks. However, as recently observed, it may have an unfair\neffect in multi-class classification. While data augmentation generally\nimproves the overall performance (and therefore is beneficial for many\nclasses), it can actually be detrimental for other classes, which can be\nproblematic in some application domains. In this paper, to counteract this\nphenomenon, we propose CLAM, a CLAss-dependent Multiplicative-weights method.\nTo derive it, we first formulate the training of a classifier as a non-linear\noptimization problem that aims at simultaneously maximizing the individual\nclass performances and balancing them. By rewriting this optimization problem\nas an adversarial two-player game, we propose a novel multiplicative weight\nalgorithm, for which we prove the convergence. Interestingly, our formulation\nalso reveals that the class-dependent effects of data augmentation is not due\nto data augmentation only, but is in fact a general phenomenon. Our empirical\nresults over five datasets demonstrate that the performance of learned\nclassifiers is indeed more fairly distributed over classes, with only limited\nimpact on the average accuracy.",
      "tldr_zh": "本研究探讨了数据增强（data augmentation）在多类分类（multi-class classification）中的类依赖效应（class-dependent effects），即它虽能提升整体性能，但可能损害某些类别的表现，从而导致不公平问题。为解决此问题，作者提出 CLAM（CLAss-dependent Multiplicative-weights method），通过将分类器训练表述为一个非线性优化问题，并将其重写为对抗性双人游戏（two-player game），采用新型乘法权重算法（multiplicative weight algorithm）来同时最大化各类别性能并实现平衡。实验结果显示，该方法在五个数据集上使类别的性能分布更公平，同时对平均准确率的影响有限；此外，该效应被揭示为一种普遍现象，而非数据增强独有。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.CV",
        "cs.GT",
        "cs.LG"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.03146v3",
      "published_date": "2024-05-31 02:56:43 UTC",
      "updated_date": "2025-03-25 09:05:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:45:11.741640"
    },
    {
      "arxiv_id": "2405.20585v1",
      "title": "GAMedX: Generative AI-based Medical Entity Data Extractor Using Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammed-Khalil Ghali",
        "Abdelrahman Farrag",
        "Hajar Sakai",
        "Hicham El Baz",
        "Yu Jin",
        "Sarah Lam"
      ],
      "abstract": "In the rapidly evolving field of healthcare and beyond, the integration of\ngenerative AI in Electronic Health Records (EHRs) represents a pivotal\nadvancement, addressing a critical gap in current information extraction\ntechniques. This paper introduces GAMedX, a Named Entity Recognition (NER)\napproach utilizing Large Language Models (LLMs) to efficiently extract entities\nfrom medical narratives and unstructured text generated throughout various\nphases of the patient hospital visit. By addressing the significant challenge\nof processing unstructured medical text, GAMedX leverages the capabilities of\ngenerative AI and LLMs for improved data extraction. Employing a unified\napproach, the methodology integrates open-source LLMs for NER, utilizing\nchained prompts and Pydantic schemas for structured output to navigate the\ncomplexities of specialized medical jargon. The findings reveal significant\nROUGE F1 score on one of the evaluation datasets with an accuracy of 98\\%. This\ninnovation enhances entity extraction, offering a scalable, cost-effective\nsolution for automated forms filling from unstructured data. As a result,\nGAMedX streamlines the processing of unstructured narratives, and sets a new\nstandard in NER applications, contributing significantly to theoretical and\npractical advancements beyond the medical technology sphere.",
      "tldr_zh": "这篇论文介绍了 GAMedX，一种基于 Generative AI 和 Large Language Models (LLMs) 的 Named Entity Recognition (NER) 方法，用于从电子健康记录 (EHRs) 中的非结构化医疗文本中高效提取实体。方法通过 chained prompts 和 Pydantic schemas 整合开源 LLMs，处理复杂的医疗术语并生成结构化输出。实验结果显示，在评估数据集上，GAMedX 取得了 98% 的 ROUGE F1 准确率，为自动化表单填充提供了一个可扩展、成本有效的解决方案，并推动了 NER 应用在医疗领域的理论和实践创新。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20585v1",
      "published_date": "2024-05-31 02:53:22 UTC",
      "updated_date": "2024-05-31 02:53:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:45:24.322948"
    },
    {
      "arxiv_id": "2405.20584v2",
      "title": "Disrupting Diffusion: Token-Level Attention Erasure Attack against Diffusion-based Customization",
      "title_zh": "翻译失败",
      "authors": [
        "Yisu Liu",
        "Jinyang An",
        "Wanqian Zhang",
        "Dayan Wu",
        "Jingzi Gu",
        "Zheng Lin",
        "Weiping Wang"
      ],
      "abstract": "With the development of diffusion-based customization methods like\nDreamBooth, individuals now have access to train the models that can generate\ntheir personalized images. Despite the convenience, malicious users have\nmisused these techniques to create fake images, thereby triggering a privacy\nsecurity crisis. In light of this, proactive adversarial attacks are proposed\nto protect users against customization. The adversarial examples are trained to\ndistort the customization model's outputs and thus block the misuse. In this\npaper, we propose DisDiff (Disrupting Diffusion), a novel adversarial attack\nmethod to disrupt the diffusion model outputs. We first delve into the\nintrinsic image-text relationships, well-known as cross-attention, and\nempirically find that the subject-identifier token plays an important role in\nguiding image generation. Thus, we propose the Cross-Attention Erasure module\nto explicitly \"erase\" the indicated attention maps and disrupt the text\nguidance. Besides,we analyze the influence of the sampling process of the\ndiffusion model on Projected Gradient Descent (PGD) attack and introduce a\nnovel Merit Sampling Scheduler to adaptively modulate the perturbation updating\namplitude in a step-aware manner. Our DisDiff outperforms the state-of-the-art\nmethods by 12.75% of FDFR scores and 7.25% of ISM scores across two facial\nbenchmarks and two commonly used prompts on average.",
      "tldr_zh": "该论文针对扩散模型（如 DreamBooth）的滥用问题，提出了一种新型对抗攻击方法 DisDiff，用于破坏个性化图像生成并保护用户隐私。DisDiff 通过分析 cross-attention 中的 subject-identifier token 的关键作用，引入 Cross-Attention Erasure 模块来擦除指定的 attention maps，从而干扰文本指导；同时，提出 Merit Sampling Scheduler 来适应性地调整 Projected Gradient Descent (PGD) 攻击中的扰动更新幅度。实验结果显示，该方法在两个面部基准和两个常用提示上，比现有方法平均提高了 12.75% 的 FDFR 分数和 7.25% 的 ISM 分数。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "I.2.10"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by ACM MM2024",
      "pdf_url": "http://arxiv.org/pdf/2405.20584v2",
      "published_date": "2024-05-31 02:45:31 UTC",
      "updated_date": "2024-07-26 02:10:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:45:36.993699"
    },
    {
      "arxiv_id": "2405.20582v2",
      "title": "The Point of View of a Sentiment: Towards Clinician Bias Detection in Psychiatric Notes",
      "title_zh": "翻译失败",
      "authors": [
        "Alissa A. Valentine",
        "Lauren A. Lepow",
        "Lili Chan",
        "Alexander W. Charney",
        "Isotta Landi"
      ],
      "abstract": "Negative patient descriptions and stigmatizing language can contribute to\ngenerating healthcare disparities in two ways: (1) read by patients, they can\nharm their trust and engagement with the medical center; (2) read by\nphysicians, they may negatively influence their perspective of a future\npatient. In psychiatry, the patient-clinician therapeutic alliance is a major\ndeterminant of clinical outcomes. Therefore, language usage in psychiatric\nclinical notes may not only create healthcare disparities, but also perpetuate\nthem. Recent advances in NLP systems have facilitated the efforts to detect\ndiscriminatory language in healthcare. However, such attempts have only focused\non the perspectives of the medical center and its physicians. Considering both\nphysicians and non-physicians' point of view is a more translatable approach to\nidentifying potentially harmful language in clinical notes. By leveraging\npre-trained and large language models (PLMs and LLMs), this work aims to\ncharacterize potentially harmful language usage in psychiatric notes by\nidentifying the sentiment expressed in sentences describing patients based on\nthe reader's point of view. Extracting 39 sentences from the Mount Sinai Health\nSystem containing psychiatric lexicon, we fine-tuned three PLMs (RoBERTa,\nGatorTron, and GatorTron + Task Adaptation) and implemented zero-shot and\nfew-shot ICL approaches for three LLMs (GPT-3.5, Llama-3.1, and Mistral) to\nclassify the sentiment of the sentences according to the physician or\nnon-physician point of view. Results showed that GPT-3.5 aligned best to\nphysician point of view and Mistral aligned best to non-physician point of\nview. These results underline the importance of recognizing the reader's point\nof view, not only for improving the note writing process, but also for the\nquantification, identification, and reduction of bias in computational systems\nfor downstream analyses.",
      "tldr_zh": "本研究探讨了精神病学笔记中临床医生偏见检测的重要性，旨在从医生和非医生视角识别潜在有害语言，以减少医疗不平等。研究利用预训练语言模型(PLMs)如RoBERTa、GatorTron和GatorTron + Task Adaptation进行微调，以及大型语言模型(LLMs)如GPT-3.5、Llama-3.1和Mistral通过零样本和少样本ICL方法，对从Mount Sinai Health System提取的39个句子进行情感分类。结果显示，GPT-3.5最符合医生视角，而Mistral最符合非医生视角，这些发现强调了考虑读者视角的价值，可用于改善笔记写作并减少下游分析中的偏见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Oral presentation at NAACL 2024 Queer in AI Workshop",
      "pdf_url": "http://arxiv.org/pdf/2405.20582v2",
      "published_date": "2024-05-31 02:28:41 UTC",
      "updated_date": "2025-02-17 18:48:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:45:47.398251"
    },
    {
      "arxiv_id": "2405.20574v2",
      "title": "Open Ko-LLM Leaderboard: Evaluating Large Language Models in Korean with Ko-H5 Benchmark",
      "title_zh": "翻译失败",
      "authors": [
        "Chanjun Park",
        "Hyeonwoo Kim",
        "Dahyun Kim",
        "Seonghwan Cho",
        "Sanghoon Kim",
        "Sukyung Lee",
        "Yungi Kim",
        "Hwalsuk Lee"
      ],
      "abstract": "This paper introduces the Open Ko-LLM Leaderboard and the Ko-H5 Benchmark as\nvital tools for evaluating Large Language Models (LLMs) in Korean.\nIncorporating private test sets while mirroring the English Open LLM\nLeaderboard, we establish a robust evaluation framework that has been well\nintegrated in the Korean LLM community. We perform data leakage analysis that\nshows the benefit of private test sets along with a correlation study within\nthe Ko-H5 benchmark and temporal analyses of the Ko-H5 score. Moreover, we\npresent empirical support for the need to expand beyond set benchmarks. We hope\nthe Open Ko-LLM Leaderboard sets precedent for expanding LLM evaluation to\nfoster more linguistic diversity.",
      "tldr_zh": "本论文介绍了 Open Ko-LLM Leaderboard 和 Ko-H5 Benchmark 作为评估韩语 Large Language Models (LLMs) 的关键工具，这些框架借鉴英语 Open LLM Leaderboard，使用私有测试集构建了一个可靠的评价体系，并在韩语 LLM 社区中得到广泛整合。研究团队进行了数据泄漏分析、Ko-H5 基准内的相关性研究以及时间分析，以证明私有测试集的优势和基准的有效性。论文还提供了实证证据，强调需要扩展基准以促进语言多样性，从而为全球 LLM 评估设定先例。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at ACL 2024 Main",
      "pdf_url": "http://arxiv.org/pdf/2405.20574v2",
      "published_date": "2024-05-31 02:05:45 UTC",
      "updated_date": "2024-08-17 03:45:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:45:58.149895"
    },
    {
      "arxiv_id": "2406.11871v4",
      "title": "Generative AI Voting: Fair Collective Choice is Resilient to LLM Biases and Inconsistencies",
      "title_zh": "翻译失败",
      "authors": [
        "Srijoni Majumdar",
        "Edith Elkind",
        "Evangelos Pournaras"
      ],
      "abstract": "Scaling up deliberative and voting participation is a longstanding endeavor\n-- a cornerstone for direct democracy and legitimate collective choice. Recent\nbreakthroughs in generative artificial intelligence (AI) and large language\nmodels (LLMs) unravel new capabilities for AI personal assistants to overcome\ncognitive bandwidth limitations of humans, providing decision support or even\ndirect representation of human voters at large scale. However, the quality of\nthis representation and what underlying biases manifest when delegating\ncollective decision-making to LLMs is an alarming and timely challenge to\ntackle. By rigorously emulating with high realism more than >50K LLM voting\npersonas in 306 real-world voting elections, we disentangle the nature of\ndifferent biases in LLMS (GPT 3, GPT 3.5, and Llama2). Complex preferential\nballot formats exhibit significant inconsistencies compared to simpler\nmajoritarian elections that show higher consistency. Strikingly though, by\ndemonstrating for the first time in real-world a proportional representation of\nvoters in direct democracy, we are also able to show that fair ballot\naggregation methods, such as equal shares, prove to be a win-win: fairer voting\noutcomes for humans with fairer AI representation, especially for voters who\nare likely to abstain. This novel underlying relationship proves paramount for\ndemocratic resilience in progressives scenarios with low voters turnout and\nvoter fatigue supported by AI representatives: abstained voters are mitigated\nby recovering highly representative voting outcomes that are fairer. These\ninterdisciplinary insights provide remarkable foundations for science,\npolicymakers, and citizens to develop safeguards and resilience for AI risks in\ndemocratic innovations.",
      "tldr_zh": "这篇论文探讨了生成式 AI 和 LLM（Large Language Models，如 GPT-3, GPT-3.5 和 Llama2）在投票系统中的应用，通过模拟超过 50K 个 LLM 投票角色参与 306 个真实选举，分析了 LLM 的偏见和不一致性。研究发现，复杂偏好选票格式表现出更高的不一致性，而简单多数选举更稳定；然而，公平的选票聚合方法（如 equal shares）能显著改善投票结果，提供更公平的 AI 代表，尤其对可能弃权的选民。最终，这些发现证明了公平集体选择在低投票率场景下的民主韧性，为政策制定者和公民开发 AI 风险防范措施提供了重要基础。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 5 figures",
      "pdf_url": "http://arxiv.org/pdf/2406.11871v4",
      "published_date": "2024-05-31 01:41:48 UTC",
      "updated_date": "2025-04-09 00:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:46:12.340248"
    },
    {
      "arxiv_id": "2405.20562v1",
      "title": "Can Machine Learning Assist in Diagnosis of Primary Immune Thrombocytopenia? A feasibility study",
      "title_zh": "机器学习能否辅助原发性免疫性血小板减少症的诊断？一项可行性研究",
      "authors": [
        "Haroon Miah",
        "Dimitrios Kollias",
        "Giacinto Luca Pedone",
        "Drew Provan",
        "Frederick Chen"
      ],
      "abstract": "Primary Immune thrombocytopenia (ITP) is a rare autoimmune disease\ncharacterised by immune-mediated destruction of peripheral blood platelets in\npatients leading to low platelet counts and bleeding. The diagnosis and\neffective management of ITP is challenging because there is no established test\nto confirm the disease and no biomarker with which one can predict the response\nto treatment and outcome. In this work we conduct a feasibility study to check\nif machine learning can be applied effectively for diagnosis of ITP using\nroutine blood tests and demographic data in a non-acute outpatient setting.\nVarious ML models, including Logistic Regression, Support Vector Machine,\nk-Nearest Neighbor, Decision Tree and Random Forest, were applied to data from\nthe UK Adult ITP Registry and a general hematology clinic. Two different\napproaches were investigated: a demographic-unaware and a demographic-aware\none. We conduct extensive experiments to evaluate the predictive performance of\nthese models and approaches, as well as their bias. The results revealed that\nDecision Tree and Random Forest models were both superior and fair, achieving\nnearly perfect predictive and fairness scores, with platelet count identified\nas the most significant variable. Models not provided with demographic\ninformation performed better in terms of predictive accuracy but showed lower\nfairness score, illustrating a trade-off between predictive performance and\nfairness.",
      "tldr_zh": "本研究探讨了 Machine Learning 在诊断原发性免疫性血小板减少症 (ITP) 的可行性，使用常规血液测试和人口统计数据在非急性门诊环境中进行分析。研究者应用了 Logistic Regression、Support Vector Machine、k-Nearest Neighbor、Decision Tree 和 Random Forest 等模型，比较了不考虑人口统计数据和考虑人口统计数据的两种方法。结果表明，Decision Tree 和 Random Forest 模型表现出最佳性能，几乎完美的预测准确性和公平性分数，其中血小板计数被识别为最重要变量；然而，不使用人口统计数据的模型在预测准确性上更优，但公平性较低，突显了预测性能与公平性之间的权衡。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20562v1",
      "published_date": "2024-05-31 01:04:46 UTC",
      "updated_date": "2024-05-31 01:04:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:46:24.425237"
    },
    {
      "arxiv_id": "2405.20556v1",
      "title": "Certifying Global Robustness for Deep Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "You Li",
        "Guannan Zhao",
        "Shuyu Kong",
        "Yunqi He",
        "Hai Zhou"
      ],
      "abstract": "A globally robust deep neural network resists perturbations on all meaningful\ninputs. Current robustness certification methods emphasize local robustness,\nstruggling to scale and generalize. This paper presents a systematic and\nefficient method to evaluate and verify global robustness for deep neural\nnetworks, leveraging the PAC verification framework for solid guarantees on\nverification results. We utilize probabilistic programs to characterize\nmeaningful input regions, setting a realistic standard for global robustness.\nAdditionally, we introduce the cumulative robustness curve as a criterion in\nevaluating global robustness. We design a statistical method that combines\nmulti-level splitting and regression analysis for the estimation, significantly\nreducing the execution time. Experimental results demonstrate the efficiency\nand effectiveness of our verification method and its capability to find rare\nand diversified counterexamples for adversarial training.",
      "tldr_zh": "本文提出了一种系统高效的方法，用于验证深度神经网络的全球鲁棒性（global robustness），以抵抗所有有意义输入的扰动，克服了当前局部鲁棒性（local robustness）方法在扩展性和泛化性上的局限。方法利用 PAC 验证框架（PAC verification framework）和概率程序（probabilistic programs）来表征输入区域，并引入累积鲁棒性曲线（cumulative robustness curve）作为评估标准，同时结合多级分割（multi-level splitting）和回归分析（regression analysis）的统计技术，显著降低了执行时间。实验结果展示了该方法的效率和有效性，能够发现用于对抗训练（adversarial training）的稀有和多样化反例（counterexamples）。这为深度神经网络的鲁棒性提供了可靠的保证。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.20556v1",
      "published_date": "2024-05-31 00:46:04 UTC",
      "updated_date": "2024-05-31 00:46:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:46:37.084762"
    },
    {
      "arxiv_id": "2405.20543v2",
      "title": "Towards a General Recipe for Combinatorial Optimization with Multi-Filter GNNs",
      "title_zh": "翻译失败",
      "authors": [
        "Frederik Wenkel",
        "Semih Cantürk",
        "Stefan Horoi",
        "Michael Perlmutter",
        "Guy Wolf"
      ],
      "abstract": "Graph neural networks (GNNs) have achieved great success for a variety of\ntasks such as node classification, graph classification, and link prediction.\nHowever, the use of GNNs (and machine learning more generally) to solve\ncombinatorial optimization (CO) problems is much less explored. Here, we\nintroduce GCON, a novel GNN architecture that leverages a complex filter bank\nand localized attention mechanisms to solve CO problems on graphs. We show how\nour method differentiates itself from prior GNN-based CO solvers and how it can\nbe effectively applied to the maximum cut, minimum dominating set, and maximum\nclique problems in a unsupervised learning setting. GCON is competitive across\nall tasks and consistently outperforms other specialized GNN-based approaches,\nand is on par with the powerful Gurobi solver on the max-cut problem. We\nprovide an open-source implementation of our work at\nhttps://github.com/WenkelF/copt.",
      "tldr_zh": "本文提出 GCON，一种新型 GNN 架构，利用复杂过滤器银行和本地化注意力机制，旨在为图上的组合优化 (CO) 问题提供通用解决方案。不同于以往的 GNN-based CO 求解器，GCON 在无监督学习设置中应用于 maximum cut、minimum dominating set 和 maximum clique 等任务。实验结果显示，GCON 在所有任务上表现出色，优于其他专门 GNN 方法，并在 maximum cut 问题上与 Gurobi 求解器性能相当。作者提供了开源实现，以促进进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DM",
        "68T07 (Primary) 68T20, 90C35, 05C62 (Secondary)",
        "F.2.2; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "In Proceedings of the Third Learning on Graphs Conference (LoG 2024,\n  Oral); 20 pages, 2 figures",
      "pdf_url": "http://arxiv.org/pdf/2405.20543v2",
      "published_date": "2024-05-31 00:02:07 UTC",
      "updated_date": "2024-11-24 23:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T14:46:49.405721"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 109,
  "processed_papers_count": 109,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T14:47:16.036060"
}