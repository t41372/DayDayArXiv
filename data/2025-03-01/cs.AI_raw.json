[
  {
    "arxiv_id": "2503.00664v1",
    "title": "Generative Artificial Intelligence for Academic Research: Evidence from Guidance Issued for Researchers by Higher Education Institutions in the United States",
    "authors": [
      "Amrita Ganguly",
      "Aditya Johri",
      "Areej Ali",
      "Nora McDonald"
    ],
    "abstract": "The recent development and use of generative AI (GenAI) has signaled a\nsignificant shift in research activities such as brainstorming, proposal\nwriting, dissemination, and even reviewing. This has raised questions about how\nto balance the seemingly productive uses of GenAI with ethical concerns such as\nauthorship and copyright issues, use of biased training data, lack of\ntransparency, and impact on user privacy. To address these concerns, many\nHigher Education Institutions (HEIs) have released institutional guidance for\nresearchers. To better understand the guidance that is being provided we report\nfindings from a thematic analysis of guidelines from thirty HEIs in the United\nStates that are classified as R1 or 'very high research activity.' We found\nthat guidance provided to researchers: (1) asks them to refer to external\nsources of information such as funding agencies and publishers to keep updated\nand use institutional resources for training and education; (2) asks them to\nunderstand and learn about specific GenAI attributes that shape research such\nas predictive modeling, knowledge cutoff date, data provenance, and model\nlimitations, and educate themselves about ethical concerns such as authorship,\nattribution, privacy, and intellectual property issues; and (3) includes\ninstructions on how to acknowledge sources and disclose the use of GenAI, how\nto communicate effectively about their GenAI use, and alerts researchers to\nlong term implications such as over reliance on GenAI, legal consequences, and\nrisks to their institutions from GenAI use. Overall, guidance places the onus\nof compliance on individual researchers making them accountable for any lapses,\nthereby increasing their responsibility.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00664v1",
    "published_date": "2025-03-01 23:34:02 UTC",
    "updated_date": "2025-03-01 23:34:02 UTC"
  },
  {
    "arxiv_id": "2503.00643v1",
    "title": "Deep Change Monitoring: A Hyperbolic Representative Learning Framework and a Dataset for Long-term Fine-grained Tree Change Detection",
    "authors": [
      "Yante Li",
      "Hanwen Qi",
      "Haoyu Chen",
      "Xinlian Liang",
      "Guoying Zhao"
    ],
    "abstract": "In environmental protection, tree monitoring plays an essential role in\nmaintaining and improving ecosystem health. However, precise monitoring is\nchallenging because existing datasets fail to capture continuous fine-grained\nchanges in trees due to low-resolution images and high acquisition costs. In\nthis paper, we introduce UAVTC, a large-scale, long-term, high-resolution\ndataset collected using UAVs equipped with cameras, specifically designed to\ndetect individual Tree Changes (TCs). UAVTC includes rich annotations and\nstatistics based on biological knowledge, offering a fine-grained view for tree\nmonitoring. To address environmental influences and effectively model the\nhierarchical diversity of physiological TCs, we propose a novel Hyperbolic\nSiamese Network (HSN) for TC detection, enabling compact and hierarchical\nrepresentations of dynamic tree changes.\n  Extensive experiments show that HSN can effectively capture complex\nhierarchical changes and provide a robust solution for fine-grained TC\ndetection. In addition, HSN generalizes well to cross-domain face anti-spoofing\ntask, highlighting its broader significance in AI. We believe our work,\ncombining ecological insights and interdisciplinary expertise, will benefit the\ncommunity by offering a new benchmark and innovative AI technologies.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00643v1",
    "published_date": "2025-03-01 22:29:29 UTC",
    "updated_date": "2025-03-01 22:29:29 UTC"
  },
  {
    "arxiv_id": "2503.00634v1",
    "title": "Efficiently Editing Mixture-of-Experts Models with Compressed Experts",
    "authors": [
      "Yifei He",
      "Yang Liu",
      "Chen Liang",
      "Hany Hassan Awadalla"
    ],
    "abstract": "Mixture-of-Experts (MoE) models have become a key approach for scaling large\nlanguage models efficiently by activating only a subset of experts during\ntraining and inference. Typically, the number of activated experts presents a\ntrade-off: fewer experts reduce computational costs, while more experts improve\nperformance. Recent studies reveal that not all activated experts contribute\nequally to model performance, with some providing minimal utility, particularly\nwhen finetuning pretrained MoE models for specialized downstream tasks. The\nco-existence of significant and redundant parameters in experts provides us an\nopportunity to reduce the number of activated experts while maintaining model\nperformance. In this work, we propose the concept of compressed experts,\nlightweight modules that serve as compact representations of full experts. Our\napproach preserves the most important experts while replacing other auxiliary\nactivated experts with compressed experts. The reduction of active parameters\nsignificantly lowers inference costs while achieving comparable performance.\nExtensive experiments on models including Phi-MoE and OLMoE demonstrate that\ncompressed experts recover over 90% of full expert performance across various\ntasks while reducing more than 30% active parameters and saving 20% in\ninference costs. This approach enables efficient deployment of MoE models in\nresource-constrained settings and facilitates scaling to larger models with\nmanageable overhead. Our code is available at\nhttps://github.com/yifei-he/Compressed-Experts.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00634v1",
    "published_date": "2025-03-01 22:00:03 UTC",
    "updated_date": "2025-03-01 22:00:03 UTC"
  },
  {
    "arxiv_id": "2503.00624v1",
    "title": "An evaluation of DeepSeek Models in Biomedical Natural Language Processing",
    "authors": [
      "Zaifu Zhan",
      "Shuang Zhou",
      "Huixue Zhou",
      "Jiawen Deng",
      "Yu Hou",
      "Jeremy Yeung",
      "Rui Zhang"
    ],
    "abstract": "The advancement of Large Language Models (LLMs) has significantly impacted\nbiomedical Natural Language Processing (NLP), enhancing tasks such as named\nentity recognition, relation extraction, event extraction, and text\nclassification. In this context, the DeepSeek series of models have shown\npromising potential in general NLP tasks, yet their capabilities in the\nbiomedical domain remain underexplored. This study evaluates multiple DeepSeek\nmodels (Distilled-DeepSeek-R1 series and Deepseek-LLMs) across four key\nbiomedical NLP tasks using 12 datasets, benchmarking them against\nstate-of-the-art alternatives (Llama3-8B, Qwen2.5-7B, Mistral-7B, Phi-4-14B,\nGemma-2-9B). Our results reveal that while DeepSeek models perform\ncompetitively in named entity recognition and text classification, challenges\npersist in event and relation extraction due to precision-recall trade-offs. We\nprovide task-specific model recommendations and highlight future research\ndirections. This evaluation underscores the strengths and limitations of\nDeepSeek models in biomedical NLP, guiding their future deployment and\noptimization.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Plan to submit to AMIA 2025 Annual Symposium. 10 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.00624v1",
    "published_date": "2025-03-01 21:26:29 UTC",
    "updated_date": "2025-03-01 21:26:29 UTC"
  },
  {
    "arxiv_id": "2503.01919v2",
    "title": "Reinforcement learning with combinatorial actions for coupled restless bandits",
    "authors": [
      "Lily Xu",
      "Bryan Wilder",
      "Elias B. Khalil",
      "Milind Tambe"
    ],
    "abstract": "Reinforcement learning (RL) has increasingly been applied to solve real-world\nplanning problems, with progress in handling large state spaces and time\nhorizons. However, a key bottleneck in many domains is that RL methods cannot\naccommodate large, combinatorially structured action spaces. In such settings,\neven representing the set of feasible actions at a single step may require a\ncomplex discrete optimization formulation. We leverage recent advances in\nembedding trained neural networks into optimization problems to propose\nSEQUOIA, an RL algorithm that directly optimizes for long-term reward over the\nfeasible action space. Our approach embeds a Q-network into a mixed-integer\nprogram to select a combinatorial action in each timestep. Here, we focus on\nplanning over restless bandits, a class of planning problems which capture many\nreal-world examples of sequential decision making. We introduce coRMAB, a\nbroader class of restless bandits with combinatorial actions that cannot be\ndecoupled across the arms of the restless bandit, requiring direct solving over\nthe joint, exponentially large action space. We empirically validate SEQUOIA on\nfour novel restless bandit problems with combinatorial constraints: multiple\ninterventions, path constraints, bipartite matching, and capacity constraints.\nOur approach significantly outperforms existing methods -- which cannot address\nsequential planning and combinatorial selection simultaneously -- by an average\nof 24.8\\% on these difficult instances.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "To appear at ICLR 2025. Code at\n  https://github.com/lily-x/combinatorial-rmab",
    "pdf_url": "http://arxiv.org/pdf/2503.01919v2",
    "published_date": "2025-03-01 21:25:21 UTC",
    "updated_date": "2025-03-17 22:59:28 UTC"
  },
  {
    "arxiv_id": "2503.00619v1",
    "title": "PinLanding: Content-First Keyword Landing Page Generation via Multi-Modal AI for Web-Scale Discovery",
    "authors": [
      "Faye Zhang",
      "Jasmine Wan",
      "Qianyu Cheng",
      "Jinfeng Rao"
    ],
    "abstract": "Online platforms like Pinterest hosting vast content collections\ntraditionally rely on manual curation or user-generated search logs to create\nkeyword landing pages (KLPs) -- topic-centered collection pages that serve as\nentry points for content discovery. While manual curation ensures quality, it\ndoesn't scale to millions of collections, and search log approaches result in\nlimited topic coverage and imprecise content matching. In this paper, we\npresent PinLanding, a novel content-first architecture that transforms the way\nplatforms create topical collections. Instead of deriving topics from user\nbehavior, our system employs a multi-stage pipeline combining vision-language\nmodel (VLM) for attribute extraction, large language model (LLM) for topic\ngeneration, and a CLIP-based dual-encoder architecture for precise content\nmatching. Our model achieves 99.7% Recall@10 on Fashion200K benchmark,\ndemonstrating strong attribute understanding capabilities. In production\ndeployment for search engine optimization with 4.2 million shopping landing\npages, the system achieves a 4X increase in topic coverage and 14.29%\nimprovement in collection attribute precision over the traditional search\nlog-based approach via human evaluation. The architecture can be generalized\nbeyond search traffic to power various user experiences, including content\ndiscovery and recommendations, providing a scalable solution to transform\nunstructured content into curated topical collections across any content\ndomain.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00619v1",
    "published_date": "2025-03-01 20:55:28 UTC",
    "updated_date": "2025-03-01 20:55:28 UTC"
  },
  {
    "arxiv_id": "2503.00611v1",
    "title": "Modeling Arbitrarily Applicable Relational Responding with the Non-Axiomatic Reasoning System: A Machine Psychology Approach",
    "authors": [
      "Robert Johansson"
    ],
    "abstract": "Arbitrarily Applicable Relational Responding (AARR) is a cornerstone of human\nlanguage and reasoning, referring to the learned ability to relate symbols in\nflexible, context-dependent ways. In this paper, we present a novel theoretical\napproach for modeling AARR within an artificial intelligence framework using\nthe Non-Axiomatic Reasoning System (NARS). NARS is an adaptive reasoning system\ndesigned for learning under uncertainty. By integrating principles from\nRelational Frame Theory - the behavioral psychology account of AARR - with the\nreasoning mechanisms of NARS, we conceptually demonstrate how key properties of\nAARR (mutual entailment, combinatorial entailment, and transformation of\nstimulus functions) can emerge from the inference rules and memory structures\nof NARS. Two theoretical experiments illustrate this approach: one modeling\nstimulus equivalence and transfer of function, and another modeling complex\nrelational networks involving opposition frames. In both cases, the system\nlogically demonstrates the derivation of untrained relations and\ncontext-sensitive transformations of stimulus significance, mirroring\nestablished human cognitive phenomena. These results suggest that AARR - long\nconsidered uniquely human - can be conceptually captured by suitably designed\nAI systems, highlighting the value of integrating behavioral science insights\ninto artificial general intelligence (AGI) research.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "5 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2503.00611v1",
    "published_date": "2025-03-01 20:37:11 UTC",
    "updated_date": "2025-03-01 20:37:11 UTC"
  },
  {
    "arxiv_id": "2503.00610v1",
    "title": "Urban Safety Perception Through the Lens of Large Multimodal Models: A Persona-based Approach",
    "authors": [
      "Ciro Beneduce",
      "Bruno Lepri",
      "Massimiliano Luca"
    ],
    "abstract": "Understanding how urban environments are perceived in terms of safety is\ncrucial for urban planning and policymaking. Traditional methods like surveys\nare limited by high cost, required time, and scalability issues. To overcome\nthese challenges, this study introduces Large Multimodal Models (LMMs),\nspecifically Llava 1.6 7B, as a novel approach to assess safety perceptions of\nurban spaces using street-view images. In addition, the research investigated\nhow this task is affected by different socio-demographic perspectives,\nsimulated by the model through Persona-based prompts. Without additional\nfine-tuning, the model achieved an average F1-score of 59.21% in classifying\nurban scenarios as safe or unsafe, identifying three key drivers of perceived\nunsafety: isolation, physical decay, and urban infrastructural challenges.\nMoreover, incorporating Persona-based prompts revealed significant variations\nin safety perceptions across the socio-demographic groups of age, gender, and\nnationality. Elder and female Personas consistently perceive higher levels of\nunsafety than younger or male Personas. Similarly, nationality-specific\ndifferences were evident in the proportion of unsafe classifications ranging\nfrom 19.71% in Singapore to 40.15% in Botswana. Notably, the model's default\nconfiguration aligned most closely with a middle-aged, male Persona. These\nfindings highlight the potential of LMMs as a scalable and cost-effective\nalternative to traditional methods for urban safety perceptions. While the\nsensitivity of these models to socio-demographic factors underscores the need\nfor thoughtful deployment, their ability to provide nuanced perspectives makes\nthem a promising tool for AI-driven urban planning.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00610v1",
    "published_date": "2025-03-01 20:34:30 UTC",
    "updated_date": "2025-03-01 20:34:30 UTC"
  },
  {
    "arxiv_id": "2503.02895v1",
    "title": "Adaptive Entanglement Routing with Deep Q-Networks in Quantum Networks",
    "authors": [
      "Lamarana Jallow",
      "Majid Iqbal Khan"
    ],
    "abstract": "The quantum internet holds transformative potential for global communication\nby harnessing the principles of quantum information processing. Despite\nsignificant advancements in quantum communication technologies, the efficient\ndistribution of critical resources, such as qubits, remains a persistent and\nunresolved challenge. Conventional approaches often fall short of achieving\noptimal resource allocation, underscoring the necessity for more effective\nsolutions. This study proposes a novel reinforcement learning-based adaptive\nentanglement routing framework designed to enable resource allocation tailored\nto the specific demands of quantum applications. The introduced QuDQN model\nutilizes reinforcement learning to optimize the management of quantum networks,\nallocate resources efficiently, and enhance entanglement routing. The model\nintegrates key considerations, including fidelity requirements, network\ntopology, qubit capacity, and request demands.",
    "categories": [
      "quant-ph",
      "cs.AI"
    ],
    "primary_category": "quant-ph",
    "comment": "14 pages, 10 images. To be submitted to Quantum joural, this is to\n  fullfill the requirements",
    "pdf_url": "http://arxiv.org/pdf/2503.02895v1",
    "published_date": "2025-03-01 20:05:54 UTC",
    "updated_date": "2025-03-01 20:05:54 UTC"
  },
  {
    "arxiv_id": "2503.00600v1",
    "title": "Semantic Integrity Constraints: Declarative Guardrails for AI-Augmented Data Processing Systems",
    "authors": [
      "Alexander W. Lee",
      "Justin Chan",
      "Michael Fu",
      "Nicolas Kim",
      "Akshay Mehta",
      "Deepti Raghavan",
      "Ugur Cetintemel"
    ],
    "abstract": "The emergence of AI-augmented Data Processing Systems (DPSs) has introduced\npowerful semantic operators that extend traditional data management\ncapabilities with LLM-based processing. However, these systems face fundamental\nreliability (a.k.a. trust) challenges, as LLMs can generate erroneous outputs,\nlimiting their adoption in critical domains. Existing approaches to LLM\nconstraints--ranging from user-defined functions to constrained decoding--are\nfragmented, imperative, and lack semantics-aware integration into query\nexecution. To address this gap, we introduce Semantic Integrity Constraints\n(SICs), a novel declarative abstraction that extends traditional database\nintegrity constraints to govern and optimize semantic operators within DPSs.\nSICs integrate seamlessly into the relational model, allowing users to specify\ncommon classes of constraints (e.g., grounding and soundness) while enabling\nquery-aware enforcement and optimization strategies.\n  In this paper, we present the core design of SICs, describe their formal\nintegration into query execution, and detail our conception of grounding\nconstraints, a key SIC class that ensures factual consistency of generated\noutputs. In addition, we explore novel enforcement mechanisms, combining\nproactive (constrained decoding) and reactive (validation and recovery)\ntechniques to optimize efficiency and reliability. Our work establishes SICs as\na foundational framework for trustworthy, high-performance AI-augmented data\nprocessing, paving the way for future research in constraint-driven\noptimizations, adaptive enforcement, and enterprise-scale deployments.",
    "categories": [
      "cs.DB",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.DB",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00600v1",
    "published_date": "2025-03-01 19:59:25 UTC",
    "updated_date": "2025-03-01 19:59:25 UTC"
  },
  {
    "arxiv_id": "2503.00597v1",
    "title": "Zero-Shot Keyphrase Generation: Investigating Specialized Instructions and Multi-Sample Aggregation on Large Language Models",
    "authors": [
      "Jayanth Mohan",
      "Jishnu Ray Chowdhury",
      "Tomas Malik",
      "Cornelia Caragea"
    ],
    "abstract": "Keyphrases are the essential topical phrases that summarize a document.\nKeyphrase generation is a long-standing NLP task for automatically generating\nkeyphrases for a given document. While the task has been comprehensively\nexplored in the past via various models, only a few works perform some\npreliminary analysis of Large Language Models (LLMs) for the task. Given the\nimpact of LLMs in the field of NLP, it is important to conduct a more thorough\nexamination of their potential for keyphrase generation. In this paper, we\nattempt to meet this demand with our research agenda. Specifically, we focus on\nthe zero-shot capabilities of open-source instruction-tuned LLMs (Phi-3,\nLlama-3) and the closed-source GPT-4o for this task. We systematically\ninvestigate the effect of providing task-relevant specialized instructions in\nthe prompt. Moreover, we design task-specific counterparts to\nself-consistency-style strategies for LLMs and show significant benefits from\nour proposals over the baselines.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at NAACL 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00597v1",
    "published_date": "2025-03-01 19:38:57 UTC",
    "updated_date": "2025-03-01 19:38:57 UTC"
  },
  {
    "arxiv_id": "2503.00596v1",
    "title": "BadJudge: Backdoor Vulnerabilities of LLM-as-a-Judge",
    "authors": [
      "Terry Tong",
      "Fei Wang",
      "Zhe Zhao",
      "Muhao Chen"
    ],
    "abstract": "This paper proposes a novel backdoor threat attacking the LLM-as-a-Judge\nevaluation regime, where the adversary controls both the candidate and\nevaluator model. The backdoored evaluator victimizes benign users by unfairly\nassigning inflated scores to adversary. A trivial single token backdoor\npoisoning 1% of the evaluator training data triples the adversary's score with\nrespect to their legitimate score. We systematically categorize levels of data\naccess corresponding to three real-world settings, (1) web poisoning, (2)\nmalicious annotator, and (3) weight poisoning. These regimes reflect a weak to\nstrong escalation of data access that highly correlates with attack severity.\nUnder the weakest assumptions - web poisoning (1), the adversary still induces\na 20% score inflation. Likewise, in the (3) weight poisoning regime, the\nstronger assumptions enable the adversary to inflate their scores from 1.5/5 to\n4.9/5. The backdoor threat generalizes across different evaluator\narchitectures, trigger designs, evaluation tasks, and poisoning rates. By\npoisoning 10% of the evaluator training data, we control toxicity judges\n(Guardrails) to misclassify toxic prompts as non-toxic 89% of the time, and\ndocument reranker judges in RAG to rank the poisoned document first 97% of the\ntime. LLM-as-a-Judge is uniquely positioned at the intersection of ethics and\ntechnology, where social implications of mislead model selection and evaluation\nconstrain the available defensive tools. Amidst these challenges, model merging\nemerges as a principled tool to offset the backdoor, reducing ASR to near 0%\nwhilst maintaining SOTA performance. Model merging's low computational cost and\nconvenient integration into the current LLM Judge training pipeline position it\nas a promising avenue for backdoor mitigation in the LLM-as-a-Judge setting.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.CL",
    "comment": "Published to ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00596v1",
    "published_date": "2025-03-01 19:35:01 UTC",
    "updated_date": "2025-03-01 19:35:01 UTC"
  },
  {
    "arxiv_id": "2503.01917v1",
    "title": "How to Steer LLM Latents for Hallucination Detection?",
    "authors": [
      "Seongheon Park",
      "Xuefeng Du",
      "Min-Hsuan Yeh",
      "Haobo Wang",
      "Yixuan Li"
    ],
    "abstract": "Hallucinations in LLMs pose a significant concern to their safe deployment in\nreal-world applications. Recent approaches have leveraged the latent space of\nLLMs for hallucination detection, but their embeddings, optimized for\nlinguistic coherence rather than factual accuracy, often fail to clearly\nseparate truthful and hallucinated content. To this end, we propose the\nTruthfulness Separator Vector (TSV), a lightweight and flexible steering vector\nthat reshapes the LLM's representation space during inference to enhance the\nseparation between truthful and hallucinated outputs, without altering model\nparameters. Our two-stage framework first trains TSV on a small set of labeled\nexemplars to form compact and well-separated clusters. It then augments the\nexemplar set with unlabeled LLM generations, employing an optimal\ntransport-based algorithm for pseudo-labeling combined with a confidence-based\nfiltering process. Extensive experiments demonstrate that TSV achieves\nstate-of-the-art performance with minimal labeled data, exhibiting strong\ngeneralization across datasets and providing a practical solution for\nreal-world LLM applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR Workshop on Quantify Uncertainty and Hallucination in Foundation\n  Models (QUESTION), 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.01917v1",
    "published_date": "2025-03-01 19:19:34 UTC",
    "updated_date": "2025-03-01 19:19:34 UTC"
  },
  {
    "arxiv_id": "2503.00583v1",
    "title": "Space-Time Graphs of Convex Sets for Multi-Robot Motion Planning",
    "authors": [
      "Jingtao Tang",
      "Zining Mao",
      "Lufan Yang",
      "Hang Ma"
    ],
    "abstract": "We address the Multi-Robot Motion Planning (MRMP) problem of computing\ncollision-free trajectories for multiple robots in shared continuous\nenvironments. While existing frameworks effectively decompose MRMP into\nsingle-robot subproblems, spatiotemporal motion planning with dynamic obstacles\nremains challenging, particularly in cluttered or narrow-corridor settings. We\npropose Space-Time Graphs of Convex Sets (ST-GCS), a novel planner that\nsystematically covers the collision-free space-time domain with convex sets\ninstead of relying on random sampling. By extending Graphs of Convex Sets (GCS)\ninto the time dimension, ST-GCS formulates time-optimal trajectories in a\nunified convex optimization that naturally accommodates velocity bounds and\nflexible arrival times. We also propose Exact Convex Decomposition (ECD) to\n\"reserve\" trajectories as spatiotemporal obstacles, maintaining a\ncollision-free space-time graph of convex sets for subsequent planning.\nIntegrated into two prioritized-planning frameworks, ST-GCS consistently\nachieves higher success rates and better solution quality than state-of-the-art\nsampling-based planners -- often at orders-of-magnitude faster runtimes --\nunderscoring its benefits for MRMP in challenging settings.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "submitted to IROS'25",
    "pdf_url": "http://arxiv.org/pdf/2503.00583v1",
    "published_date": "2025-03-01 18:28:57 UTC",
    "updated_date": "2025-03-01 18:28:57 UTC"
  },
  {
    "arxiv_id": "2503.00580v1",
    "title": "Brain Foundation Models: A Survey on Advancements in Neural Signal Processing and Brain Discovery",
    "authors": [
      "Xinliang Zhou",
      "Chenyu Liu",
      "Zhisheng Chen",
      "Kun Wang",
      "Yi Ding",
      "Ziyu Jia",
      "Qingsong Wen"
    ],
    "abstract": "Brain foundation models (BFMs) have emerged as a transformative paradigm in\ncomputational neuroscience, offering a revolutionary framework for processing\ndiverse neural signals across different brain-related tasks. These models\nleverage large-scale pre-training techniques, allowing them to generalize\neffectively across multiple scenarios, tasks, and modalities, thus overcoming\nthe traditional limitations faced by conventional artificial intelligence (AI)\napproaches in understanding complex brain data. By tapping into the power of\npretrained models, BFMs provide a means to process neural data in a more\nunified manner, enabling advanced analysis and discovery in the field of\nneuroscience. In this survey, we define BFMs for the first time, providing a\nclear and concise framework for constructing and utilizing these models in\nvarious applications. We also examine the key principles and methodologies for\ndeveloping these models, shedding light on how they transform the landscape of\nneural signal processing. This survey presents a comprehensive review of the\nlatest advancements in BFMs, covering the most recent methodological\ninnovations, novel views of application areas, and challenges in the field.\nNotably, we highlight the future directions and key challenges that need to be\naddressed to fully realize the potential of BFMs. These challenges include\nimproving the quality of brain data, optimizing model architecture for better\ngeneralization, increasing training efficiency, and enhancing the\ninterpretability and robustness of BFMs in real-world applications.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00580v1",
    "published_date": "2025-03-01 18:12:50 UTC",
    "updated_date": "2025-03-01 18:12:50 UTC"
  },
  {
    "arxiv_id": "2503.00572v1",
    "title": "LoR2C : Low-Rank Residual Connection Adaptation for Parameter-Efficient Fine-Tuning",
    "authors": [
      "Jiancheng Zhao",
      "Xingda Yu",
      "Yuxiang Zhang",
      "Zhen Yang"
    ],
    "abstract": "In recent years, pretrained large language models have demonstrated\noutstanding performance across various natural language processing tasks.\nHowever, full-parameter fine-tuning methods require adjusting all model\nparameters, leading to immense computational resource demands. Although\nparameter-efficient fine-tuning methods like LoRA have significantly reduced\nthe number of parameters, they still face challenges such as gradient vanishing\nand the potential for further parameter reduction. To address these issues,\nthis paper proposes a novel parameter-efficient fine-tuning method called LoR2C\n(Low-Rank Residual Connection Adaptation). LoR2C introduces residual\nconnections with low-rank matrices within the model layers, which not only\nreduces the number of fine-tuning parameters but also effectively alleviates\nthe gradient vanishing problem. Additionally, this paper presents three\noptimization variants of LoR2C: ShareLoR2C, MergeLoR2C, and InjectLoR2C. These\nvariants further improve parameter efficiency and model performance through\nparameter sharing, module merging, and injection mechanisms, respectively.\nExperimental results on multiple natural language understanding and natural\nlanguage generation tasks demonstrate that LoR2C and its optimized variants\nsignificantly reduce parameter overhead while maintaining or even improving\nperformance, outperforming existing mainstream parameter-efficient fine-tuning\nmethods.Our code is publicly available at https://github.com/Oblivioniss/LoR2C.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00572v1",
    "published_date": "2025-03-01 17:42:57 UTC",
    "updated_date": "2025-03-01 17:42:57 UTC"
  },
  {
    "arxiv_id": "2503.00566v1",
    "title": "Instructor-Worker Large Language Model System for Policy Recommendation: a Case Study on Air Quality Analysis of the January 2025 Los Angeles Wildfires",
    "authors": [
      "Kyle Gao",
      "Dening Lu",
      "Liangzhi Li",
      "Nan Chen",
      "Hongjie He",
      "Linlin Xu",
      "Jonathan Li"
    ],
    "abstract": "The Los Angeles wildfires of January 2025 caused more than 250 billion\ndollars in damage and lasted for nearly an entire month before containment.\nFollowing our previous work, the Digital Twin Building, we modify and leverage\nthe multi-agent large language model framework as well as the cloud-mapping\nintegration to study the air quality during the Los Angeles wildfires. Recent\nadvances in large language models have allowed for out-of-the-box automated\nlarge-scale data analysis. We use a multi-agent large language system comprised\nof an Instructor agent and Worker agents. Upon receiving the users'\ninstructions, the Instructor agent retrieves the data from the cloud platform\nand produces instruction prompts to the Worker agents. The Worker agents then\nanalyze the data and provide summaries. The summaries are finally input back\ninto the Instructor agent, which then provides the final data analysis. We test\nthis system's capability for data-based policy recommendation by assessing our\nInstructor-Worker LLM system's health recommendations based on air quality\nduring the Los Angeles wildfires.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00566v1",
    "published_date": "2025-03-01 17:29:26 UTC",
    "updated_date": "2025-03-01 17:29:26 UTC"
  },
  {
    "arxiv_id": "2503.00563v1",
    "title": "A Guide to Failure in Machine Learning: Reliability and Robustness from Foundations to Practice",
    "authors": [
      "Eric Heim",
      "Oren Wright",
      "David Shriver"
    ],
    "abstract": "One of the main barriers to adoption of Machine Learning (ML) is that ML\nmodels can fail unexpectedly. In this work, we aim to provide practitioners a\nguide to better understand why ML models fail and equip them with techniques\nthey can use to reason about failure. Specifically, we discuss failure as\neither being caused by lack of reliability or lack of robustness.\nDifferentiating the causes of failure in this way allows us to formally define\nwhy models fail from first principles and tie these definitions to engineering\nconcepts and real-world deployment settings. Throughout the document we provide\n1) a summary of important theoretic concepts in reliability and robustness, 2)\na sampling current techniques that practitioners can utilize to reason about ML\nmodel reliability and robustness, and 3) examples that show how these concepts\nand techniques can apply to real-world settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00563v1",
    "published_date": "2025-03-01 17:21:36 UTC",
    "updated_date": "2025-03-01 17:21:36 UTC"
  },
  {
    "arxiv_id": "2503.00555v1",
    "title": "Safety Tax: Safety Alignment Makes Your Large Reasoning Models Less Reasonable",
    "authors": [
      "Tiansheng Huang",
      "Sihao Hu",
      "Fatih Ilhan",
      "Selim Furkan Tekin",
      "Zachary Yahn",
      "Yichang Xu",
      "Ling Liu"
    ],
    "abstract": "Safety alignment is an important procedure before the official deployment of\na Large Language Model (LLM). While safety alignment has been extensively\nstudied for LLM, there is still a large research gap for Large Reasoning Models\n(LRMs) that equip with improved reasoning capability. We in this paper\nsystematically examine a simplified pipeline for producing safety aligned LRMs.\nWith our evaluation of various LRMs, we deliver two main findings: i) Safety\nalignment can be done upon the LRM to restore its safety capability. ii) Safety\nalignment leads to a degradation of the reasoning capability of LRMs. The two\nfindings show that there exists a trade-off between reasoning and safety\ncapability with the sequential LRM production pipeline. The discovered\ntrade-off, which we name Safety Tax, should shed light on future endeavors of\nsafety research on LRMs. As a by-product, we curate a dataset called\nDirectRefusal, which might serve as an alternative dataset for safety\nalignment. Our source code is available at\nhttps://github.com/git-disl/Safety-Tax.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00555v1",
    "published_date": "2025-03-01 16:42:01 UTC",
    "updated_date": "2025-03-01 16:42:01 UTC"
  },
  {
    "arxiv_id": "2503.00539v1",
    "title": "Distributionally Robust Reinforcement Learning with Human Feedback",
    "authors": [
      "Debmalya Mandal",
      "Paulius Sasnauskas",
      "Goran Radanovic"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) has evolved to be one of\nthe main methods for fine-tuning large language models (LLMs). However,\nexisting RLHF methods are non-robust, and their performance deteriorates if the\ndownstream task differs significantly from the preference dataset used in\nfine-tuning. In order to mitigate this problem, we introduce a distributionally\nrobust RLHF for fine-tuning LLMs. In particular, our goal is to ensure that a\nfine-tuned model retains its performance even when the distribution of prompts\nsignificantly differs from the distribution encountered during fine-tuning. We\nformulate distributionally robust optimization (DRO) version of two popular\nfine-tuning methods -- (1) reward-based RLHF and (2) reward-free DPO (direct\npreference optimization). We propose a minibatch gradient descent based\nalgorithms for both of them, and theoretically prove convergence guarantees for\nthe algorithms. Subsequently, we evaluate our algorithms on an\nout-of-distribution (OOD) task by first training the model on the\nUnified-Feedback dataset and evaluating its performance on two different\ndatasets. The experimental results show that our robust training improves the\naccuracy of the learned reward models on average, and markedly on some tasks,\nsuch as reasoning. Furthermore, we show that the robust versions of policy\noptimization methods, similarly improve performance on OOD tasks.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00539v1",
    "published_date": "2025-03-01 15:43:39 UTC",
    "updated_date": "2025-03-01 15:43:39 UTC"
  },
  {
    "arxiv_id": "2503.00535v1",
    "title": "What Makes a Good Diffusion Planner for Decision Making?",
    "authors": [
      "Haofei Lu",
      "Dongqi Han",
      "Yifei Shen",
      "Dongsheng Li"
    ],
    "abstract": "Diffusion models have recently shown significant potential in solving\ndecision-making problems, particularly in generating behavior plans -- also\nknown as diffusion planning. While numerous studies have demonstrated the\nimpressive performance of diffusion planning, the mechanisms behind the key\ncomponents of a good diffusion planner remain unclear and the design choices\nare highly inconsistent in existing studies. In this work, we address this\nissue through systematic empirical experiments on diffusion planning in an\noffline reinforcement learning (RL) setting, providing practical insights into\nthe essential components of diffusion planning. We trained and evaluated over\n6,000 diffusion models, identifying the critical components such as guided\nsampling, network architecture, action generation and planning strategy. We\nrevealed that some design choices opposite to the common practice in previous\nwork in diffusion planning actually lead to better performance, e.g.,\nunconditional sampling with selection can be better than guided sampling and\nTransformer outperforms U-Net as denoising network. Based on these insights, we\nsuggest a simple yet strong diffusion planning baseline that achieves\nstate-of-the-art results on standard offline RL benchmarks.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "ICLR 2025 (Spotlight), Code:\n  https://github.com/Josh00-Lu/DiffusionVeteran",
    "pdf_url": "http://arxiv.org/pdf/2503.00535v1",
    "published_date": "2025-03-01 15:31:14 UTC",
    "updated_date": "2025-03-01 15:31:14 UTC"
  },
  {
    "arxiv_id": "2503.00527v1",
    "title": "Never too Prim to Swim: An LLM-Enhanced RL-based Adaptive S-Surface Controller for AUVs under Extreme Sea Conditions",
    "authors": [
      "Guanwen Xie",
      "Jingzehua Xu",
      "Yimian Ding",
      "Zhi Zhang",
      "Shuai Zhang",
      "Yi Li"
    ],
    "abstract": "The adaptivity and maneuvering capabilities of Autonomous Underwater Vehicles\n(AUVs) have drawn significant attention in oceanic research, due to the\nunpredictable disturbances and strong coupling among the AUV's degrees of\nfreedom. In this paper, we developed large language model (LLM)-enhanced\nreinforcement learning (RL)-based adaptive S-surface controller for AUVs.\nSpecifically, LLMs are introduced for the joint optimization of controller\nparameters and reward functions in RL training. Using multi-modal and\nstructured explicit task feedback, LLMs enable joint adjustments, balance\nmultiple objectives, and enhance task-oriented performance and adaptability. In\nthe proposed controller, the RL policy focuses on upper-level tasks, outputting\ntask-oriented high-level commands that the S-surface controller then converts\ninto control signals, ensuring cancellation of nonlinear effects and\nunpredictable external disturbances in extreme sea conditions. Under extreme\nsea conditions involving complex terrain, waves, and currents, the proposed\ncontroller demonstrates superior performance and adaptability in high-level\ntasks such as underwater target tracking and data collection, outperforming\ntraditional PID and SMC controllers.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00527v1",
    "published_date": "2025-03-01 15:01:50 UTC",
    "updated_date": "2025-03-01 15:01:50 UTC"
  },
  {
    "arxiv_id": "2503.00524v1",
    "title": "End-To-End Learning of Gaussian Mixture Priors for Diffusion Sampler",
    "authors": [
      "Denis Blessing",
      "Xiaogang Jia",
      "Gerhard Neumann"
    ],
    "abstract": "Diffusion models optimized via variational inference (VI) have emerged as a\npromising tool for generating samples from unnormalized target densities. These\nmodels create samples by simulating a stochastic differential equation,\nstarting from a simple, tractable prior, typically a Gaussian distribution.\nHowever, when the support of this prior differs greatly from that of the target\ndistribution, diffusion models often struggle to explore effectively or suffer\nfrom large discretization errors. Moreover, learning the prior distribution can\nlead to mode-collapse, exacerbated by the mode-seeking nature of reverse\nKullback-Leibler divergence commonly used in VI. To address these challenges,\nwe propose end-to-end learnable Gaussian mixture priors (GMPs). GMPs offer\nimproved control over exploration, adaptability to target support, and\nincreased expressiveness to counteract mode collapse. We further leverage the\nstructure of mixture models by proposing a strategy to iteratively refine the\nmodel by adding mixture components during training. Our experimental results\ndemonstrate significant performance improvements across a diverse range of\nreal-world and synthetic benchmark problems when using GMPs without requiring\nadditional target evaluations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00524v1",
    "published_date": "2025-03-01 14:58:14 UTC",
    "updated_date": "2025-03-01 14:58:14 UTC"
  },
  {
    "arxiv_id": "2503.00509v1",
    "title": "Functional multi-armed bandit and the best function identification problems",
    "authors": [
      "Yuriy Dorn",
      "Aleksandr Katrutsa",
      "Ilgam Latypov",
      "Anastasiia Soboleva"
    ],
    "abstract": "Bandit optimization usually refers to the class of online optimization\nproblems with limited feedback, namely, a decision maker uses only the\nobjective value at the current point to make a new decision and does not have\naccess to the gradient of the objective function. While this name accurately\ncaptures the limitation in feedback, it is somehow misleading since it does not\nhave any connection with the multi-armed bandits (MAB) problem class. We\npropose two new classes of problems: the functional multi-armed bandit problem\n(FMAB) and the best function identification problem. They are modifications of\na multi-armed bandit problem and the best arm identification problem,\nrespectively, where each arm represents an unknown black-box function. These\nproblem classes are a surprisingly good fit for modeling real-world problems\nsuch as competitive LLM training. To solve the problems from these classes, we\npropose a new reduction scheme to construct UCB-type algorithms, namely, the\nF-LCB algorithm, based on algorithms for nonlinear optimization with known\nconvergence rates. We provide the regret upper bounds for this reduction scheme\nbased on the base algorithms' convergence rates. We add numerical experiments\nthat demonstrate the performance of the proposed scheme.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00509v1",
    "published_date": "2025-03-01 14:28:52 UTC",
    "updated_date": "2025-03-01 14:28:52 UTC"
  },
  {
    "arxiv_id": "2503.00495v1",
    "title": "Towards High-fidelity 3D Talking Avatar with Personalized Dynamic Texture",
    "authors": [
      "Xuanchen Li",
      "Jianyu Wang",
      "Yuhao Cheng",
      "Yikun Zeng",
      "Xingyu Ren",
      "Wenhan Zhu",
      "Weiming Zhao",
      "Yichao Yan"
    ],
    "abstract": "Significant progress has been made for speech-driven 3D face animation, but\nmost works focus on learning the motion of mesh/geometry, ignoring the impact\nof dynamic texture. In this work, we reveal that dynamic texture plays a key\nrole in rendering high-fidelity talking avatars, and introduce a\nhigh-resolution 4D dataset \\textbf{TexTalk4D}, consisting of 100 minutes of\naudio-synced scan-level meshes with detailed 8K dynamic textures from 100\nsubjects. Based on the dataset, we explore the inherent correlation between\nmotion and texture, and propose a diffusion-based framework \\textbf{TexTalker}\nto simultaneously generate facial motions and dynamic textures from speech.\nFurthermore, we propose a novel pivot-based style injection strategy to capture\nthe complicity of different texture and motion styles, which allows\ndisentangled control. TexTalker, as the first method to generate audio-synced\nfacial motion with dynamic texture, not only outperforms the prior arts in\nsynthesising facial motions, but also produces realistic textures that are\nconsistent with the underlying facial movements. Project page:\nhttps://xuanchenli.github.io/TexTalk/.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00495v1",
    "published_date": "2025-03-01 13:51:37 UTC",
    "updated_date": "2025-03-01 13:51:37 UTC"
  },
  {
    "arxiv_id": "2503.00493v2",
    "title": "LLaSE-G1: Incentivizing Generalization Capability for LLaMA-based Speech Enhancement",
    "authors": [
      "Boyi Kang",
      "Xinfa Zhu",
      "Zihan Zhang",
      "Zhen Ye",
      "Mingshuai Liu",
      "Ziqian Wang",
      "Yike Zhu",
      "Guobin Ma",
      "Jun Chen",
      "Longshuai Xiao",
      "Chao Weng",
      "Wei Xue",
      "Lei Xie"
    ],
    "abstract": "Recent advancements in language models (LMs) have demonstrated strong\ncapabilities in semantic understanding and contextual modeling, which have\nflourished in generative speech enhancement (SE). However, many LM-based SE\napproaches primarily focus on semantic information, often neglecting the\ncritical role of acoustic information, which leads to acoustic inconsistency\nafter enhancement and limited generalization across diverse SE tasks. In this\npaper, we introduce LLaSE-G1, a LLaMA-based language model that incentivizes\ngeneralization capabilities for speech enhancement. LLaSE-G1 offers the\nfollowing key contributions: First, to mitigate acoustic inconsistency,\nLLaSE-G1 employs continuous representations from WavLM as input and predicts\nspeech tokens from X-Codec2, maximizing acoustic preservation. Second, to\npromote generalization capability, LLaSE-G1 introduces dual-channel inputs and\noutputs, unifying multiple SE tasks without requiring task-specific IDs. Third,\nLLaSE-G1 outperforms prior task-specific discriminative and generative SE\nmodels, demonstrating scaling effects at test time and emerging capabilities\nfor unseen SE tasks. Additionally, we release our code and models to support\nfurther research in this area.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "13 pages, 2 figures, 8 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.00493v2",
    "published_date": "2025-03-01 13:44:50 UTC",
    "updated_date": "2025-03-04 12:32:13 UTC"
  },
  {
    "arxiv_id": "2503.00489v1",
    "title": "Embracing Diversity: A Multi-Perspective Approach with Soft Labels",
    "authors": [
      "Benedetta Muscato",
      "Praveen Bushipaka",
      "Gizem Gezici",
      "Lucia Passaro",
      "Fosca Giannotti",
      "Tommaso Cucinotta"
    ],
    "abstract": "Prior studies show that adopting the annotation diversity shaped by different\nbackgrounds and life experiences and incorporating them into the model\nlearning, i.e. multi-perspective approach, contribute to the development of\nmore responsible models. Thus, in this paper we propose a new framework for\ndesigning and further evaluating perspective-aware models on stance detection\ntask,in which multiple annotators assign stances based on a controversial\ntopic. We also share a new dataset established through obtaining both human and\nLLM annotations. Results show that the multi-perspective approach yields better\nclassification performance (higher F1-scores), outperforming the traditional\napproaches that use a single ground-truth, while displaying lower model\nconfidence scores, probably due to the high level of subjectivity of the stance\ndetection task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00489v1",
    "published_date": "2025-03-01 13:33:38 UTC",
    "updated_date": "2025-03-01 13:33:38 UTC"
  },
  {
    "arxiv_id": "2503.00483v1",
    "title": "Interacting with AI Reasoning Models: Harnessing \"Thoughts\" for AI-Driven Software Engineering",
    "authors": [
      "Christoph Treude",
      "Raula Gaikovina Kula"
    ],
    "abstract": "Recent advances in AI reasoning models provide unprecedented transparency\ninto their decision-making processes, transforming them from traditional\nblack-box systems into models that articulate step-by-step chains of thought\nrather than producing opaque outputs. This shift has the potential to improve\nsoftware quality, explainability, and trust in AI-augmented development.\nHowever, software engineers rarely have the time or cognitive bandwidth to\nanalyze, verify, and interpret every AI-generated thought in detail. Without an\neffective interface, this transparency could become a burden rather than a\nbenefit.\n  In this paper, we propose a vision for structuring the interaction between AI\nreasoning models and software engineers to maximize trust, efficiency, and\ndecision-making power. We argue that simply exposing AI's reasoning is not\nenough -- software engineers need tools and frameworks that selectively\nhighlight critical insights, filter out noise, and facilitate rapid validation\nof key assumptions. To illustrate this challenge, we present motivating\nexamples in which AI reasoning models state their assumptions when deciding\nwhich external library to use and produce divergent reasoning paths and\nrecommendations about security vulnerabilities, highlighting the need for an\ninterface that prioritizes actionable insights while managing uncertainty and\nresolving conflicts. We then outline a research roadmap for integrating\nautomated summarization, assumption validation, and multi-model conflict\nresolution into software engineering workflows. Achieving this vision will\nunlock the full potential of AI reasoning models to enable software engineers\nto make faster, more informed decisions without being overwhelmed by\nunnecessary detail.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.HC"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00483v1",
    "published_date": "2025-03-01 13:19:15 UTC",
    "updated_date": "2025-03-01 13:19:15 UTC"
  },
  {
    "arxiv_id": "2503.00481v1",
    "title": "Challenges in Testing Large Language Model Based Software: A Faceted Taxonomy",
    "authors": [
      "Felix Dobslaw",
      "Robert Feldt",
      "Juyeon Yoon",
      "Shin Yoo"
    ],
    "abstract": "Large Language Models (LLMs) and Multi-Agent LLMs (MALLMs) introduce\nnon-determinism unlike traditional or machine learning software, requiring new\napproaches to verifying correctness beyond simple output comparisons or\nstatistical accuracy over test datasets.\n  This paper presents a taxonomy for LLM test case design, informed by both the\nresearch literature, our experience, and open-source tools that represent the\nstate of practice. We identify key variation points that impact test\ncorrectness and highlight open challenges that the research, industry, and\nopen-source communities must address as LLMs become integral to software\nsystems.\n  Our taxonomy defines four facets of LLM test case design, addressing\nambiguity in both inputs and outputs while establishing best practices. It\ndistinguishes variability in goals, the system under test, and inputs, and\nintroduces two key oracle types: atomic and aggregated. Our mapping indicates\nthat current tools insufficiently account for these variability points,\nhighlighting the need for closer collaboration between academia and\npractitioners to improve the reliability and reproducibility of LLM testing.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00481v1",
    "published_date": "2025-03-01 13:15:56 UTC",
    "updated_date": "2025-03-01 13:15:56 UTC"
  },
  {
    "arxiv_id": "2503.00461v1",
    "title": "Leveraging Compute-in-Memory for Efficient Generative Model Inference in TPUs",
    "authors": [
      "Zhantong Zhu",
      "Hongou Li",
      "Wenjie Ren",
      "Meng Wu",
      "Le Ye",
      "Ru Huang",
      "Tianyu Jia"
    ],
    "abstract": "With the rapid advent of generative models, efficiently deploying these\nmodels on specialized hardware has become critical. Tensor Processing Units\n(TPUs) are designed to accelerate AI workloads, but their high power\nconsumption necessitates innovations for improving efficiency.\nCompute-in-memory (CIM) has emerged as a promising paradigm with superior area\nand energy efficiency. In this work, we present a TPU architecture that\nintegrates digital CIM to replace conventional digital systolic arrays in\nmatrix multiply units (MXUs). We first establish a CIM-based TPU architecture\nmodel and simulator to evaluate the benefits of CIM for diverse generative\nmodel inference. Building upon the observed design insights, we further explore\nvarious CIM-based TPU architectural design choices. Up to 44.2% and 33.8%\nperformance improvement for large language model and diffusion transformer\ninference, and 27.3x reduction in MXU energy consumption can be achieved with\ndifferent design choices, compared to the baseline TPUv4i architecture.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted to appear at DATE 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00461v1",
    "published_date": "2025-03-01 12:03:25 UTC",
    "updated_date": "2025-03-01 12:03:25 UTC"
  },
  {
    "arxiv_id": "2503.00455v1",
    "title": "PodAgent: A Comprehensive Framework for Podcast Generation",
    "authors": [
      "Yujia Xiao",
      "Lei He",
      "Haohan Guo",
      "Fenglong Xie",
      "Tan Lee"
    ],
    "abstract": "Existing Existing automatic audio generation methods struggle to generate\npodcast-like audio programs effectively. The key challenges lie in in-depth\ncontent generation, appropriate and expressive voice production. This paper\nproposed PodAgent, a comprehensive framework for creating audio programs.\nPodAgent 1) generates informative topic-discussion content by designing a\nHost-Guest-Writer multi-agent collaboration system, 2) builds a voice pool for\nsuitable voice-role matching and 3) utilizes LLM-enhanced speech synthesis\nmethod to generate expressive conversational speech. Given the absence of\nstandardized evaluation criteria for podcast-like audio generation, we\ndeveloped comprehensive assessment guidelines to effectively evaluate the\nmodel's performance. Experimental results demonstrate PodAgent's effectiveness,\nsignificantly surpassing direct GPT-4 generation in topic-discussion dialogue\ncontent, achieving an 87.4% voice-matching accuracy, and producing more\nexpressive speech through LLM-guided synthesis. Demo page:\nhttps://podcast-agent.github.io/demo/. Source code:\nhttps://github.com/yujxx/PodAgent.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.MA",
      "cs.MM",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00455v1",
    "published_date": "2025-03-01 11:35:17 UTC",
    "updated_date": "2025-03-01 11:35:17 UTC"
  },
  {
    "arxiv_id": "2503.16471v1",
    "title": "A Review of Brain-Computer Interface Technologies: Signal Acquisition Methods and Interaction Paradigms",
    "authors": [
      "Yifan Wang",
      "Cheng Jiang",
      "Chenzhong Li"
    ],
    "abstract": "Brain-Computer Interface (BCI) technology facilitates direct communication\nbetween the human brain and external devices, representing a substantial\nadvancement in human-machine interaction. This review provides an in-depth\nanalysis of various BCI paradigms, including classic paradigms, current\nclassifications, and hybrid paradigms, each with distinct characteristics and\napplications. Additionally, we explore a range of signal acquisition methods,\nclassified into non-implantation, intervention, and implantation techniques,\nelaborating on their principles and recent advancements. By examining the\ninterdependence between paradigms and signal acquisition technologies, this\nreview offers a comprehensive perspective on how innovations in one domain\npropel progress in the other. The goal is to present insights into the future\ndevelopment of more efficient, user-friendly, and versatile BCI systems,\nemphasizing the synergy between paradigm design and signal acquisition\ntechniques and their potential to transform the field.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "J.3"
    ],
    "primary_category": "cs.HC",
    "comment": "12 figures,20 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.16471v1",
    "published_date": "2025-03-01 11:22:47 UTC",
    "updated_date": "2025-03-01 11:22:47 UTC"
  },
  {
    "arxiv_id": "2503.00449v1",
    "title": "Rehearse With User: Personalized Opinion Summarization via Role-Playing based on Large Language Models",
    "authors": [
      "Yanyue Zhang",
      "Yulan He",
      "Deyu Zhou"
    ],
    "abstract": "Personalized opinion summarization is crucial as it considers individual user\ninterests while generating product summaries. Recent studies show that although\nlarge language models demonstrate powerful text summarization and evaluation\ncapabilities without the need for training data, they face difficulties in\npersonalized tasks involving long texts. To address this, \\textbf{Rehearsal}, a\npersonalized opinion summarization framework via LLMs-based role-playing is\nproposed. Having the model act as the user, the model can better understand the\nuser's personalized needs. Additionally, a role-playing supervisor and practice\nprocess are introduced to improve the role-playing ability of the LLMs, leading\nto a better expression of user needs. Furthermore, through suggestions from\nvirtual users, the summary generation is intervened, ensuring that the\ngenerated summary includes information of interest to the user, thus achieving\npersonalized summary generation. Experiment results demonstrate that our method\ncan effectively improve the level of personalization in large model-generated\nsummaries.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "17 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00449v1",
    "published_date": "2025-03-01 11:05:01 UTC",
    "updated_date": "2025-03-01 11:05:01 UTC"
  },
  {
    "arxiv_id": "2503.00436v1",
    "title": "HalCECE: A Framework for Explainable Hallucination Detection through Conceptual Counterfactuals in Image Captioning",
    "authors": [
      "Maria Lymperaiou",
      "Giorgos FIlandrianos",
      "Angeliki Dimitriou",
      "Athanasios Voulodimos",
      "Giorgos Stamou"
    ],
    "abstract": "In the dynamic landscape of artificial intelligence, the exploration of\nhallucinations within vision-language (VL) models emerges as a critical\nfrontier. This work delves into the intricacies of hallucinatory phenomena\nexhibited by widely used image captioners, unraveling interesting patterns.\nSpecifically, we step upon previously introduced techniques of conceptual\ncounterfactual explanations to address VL hallucinations. The deterministic and\nefficient nature of the employed conceptual counterfactuals backbone is able to\nsuggest semantically minimal edits driven by hierarchical knowledge, so that\nthe transition from a hallucinated caption to a non-hallucinated one is\nperformed in a black-box manner. HalCECE, our proposed hallucination detection\nframework is highly interpretable, by providing semantically meaningful edits\napart from standalone numbers, while the hierarchical decomposition of\nhallucinated concepts leads to a thorough hallucination analysis. Another\nnovelty tied to the current work is the investigation of role hallucinations,\nbeing one of the first works to involve interconnections between visual\nconcepts in hallucination detection. Overall, HalCECE recommends an explainable\ndirection to the crucial field of VL hallucination detection, thus fostering\ntrustworthy evaluation of current and future VL systems.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00436v1",
    "published_date": "2025-03-01 10:28:19 UTC",
    "updated_date": "2025-03-01 10:28:19 UTC"
  },
  {
    "arxiv_id": "2503.00433v1",
    "title": "Unveiling AI's Threats to Child Protection: Regulatory efforts to Criminalize AI-Generated CSAM and Emerging Children's Rights Violations",
    "authors": [
      "Emmanouela Kokolaki",
      "Paraskevi Fragopoulou"
    ],
    "abstract": "This paper aims to present new alarming trends in the field of child sexual\nabuse through imagery, as part of SafeLine's research activities in the field\nof cybercrime, child sexual abuse material and the protection of children's\nrights to safe online experiences. It focuses primarily on the phenomenon of\nAI-generated CSAM, sophisticated ways employed for its production which are\ndiscussed in dark web forums and the crucial role that the open-source AI\nmodels play in the evolution of this overwhelming phenomenon. The paper's main\ncontribution is a correlation analysis between the hotline's reports and domain\nnames identified in dark web forums, where users' discussions focus on\nexchanging information specifically related to the generation of AI-CSAM. The\nobjective was to reveal the close connection of clear net and dark web content,\nwhich was accomplished through the use of the ATLAS dataset of the Voyager\nsystem. Furthermore, through the analysis of a set of posts' content drilled\nfrom the above dataset, valuable conclusions on forum members' techniques\nemployed for the production of AI-generated CSAM are also drawn, while users'\nviews on this type of content and routes followed in order to overcome\ntechnological barriers set with the aim of preventing malicious purposes are\nalso presented. As the ultimate contribution of this research, an overview of\nthe current legislative developments in all country members of the INHOPE\norganization and the issues arising in the process of regulating the AI- CSAM\nis presented, shedding light in the legal challenges regarding the regulation\nand limitation of the phenomenon.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00433v1",
    "published_date": "2025-03-01 10:18:00 UTC",
    "updated_date": "2025-03-01 10:18:00 UTC"
  },
  {
    "arxiv_id": "2503.01914v1",
    "title": "Conceptual Contrastive Edits in Textual and Vision-Language Retrieval",
    "authors": [
      "Maria Lymperaiou",
      "Giorgos Stamou"
    ],
    "abstract": "As deep learning models grow in complexity, achieving model-agnostic\ninterpretability becomes increasingly vital. In this work, we employ post-hoc\nconceptual contrastive edits to expose noteworthy patterns and biases imprinted\nin representations of retrieval models. We systematically design optimal and\ncontrollable contrastive interventions targeting various parts of speech, and\neffectively apply them to explain both linguistic and visiolinguistic\npre-trained models in a black-box manner. Additionally, we introduce a novel\nmetric to assess the per-word impact of contrastive interventions on model\noutcomes, providing a comprehensive evaluation of each intervention's\neffectiveness.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.01914v1",
    "published_date": "2025-03-01 10:14:28 UTC",
    "updated_date": "2025-03-01 10:14:28 UTC"
  },
  {
    "arxiv_id": "2503.00427v1",
    "title": "Language Model Mapping in Multimodal Music Learning: A Grand Challenge Proposal",
    "authors": [
      "Daniel Chin",
      "Gus Xia"
    ],
    "abstract": "We have seen remarkable success in representation learning and language\nmodels (LMs) using deep neural networks. Many studies aim to build the\nunderlying connections among different modalities via the alignment and\nmappings at the token or embedding level, but so far, most methods are very\ndata-hungry, limiting their performance in domains such as music where paired\ndata are less abundant. We argue that the embedding alignment is only at the\nsurface level of multimodal alignment. In this paper, we propose a grand\nchallenge of \\textit{language model mapping} (LMM), i.e., how to map the\nessence implied in the LM of one domain to the LM of another domain under the\nassumption that LMs of different modalities are tracking the same underlying\nphenomena. We first introduce a basic setup of LMM, highlighting the goal to\nunveil a deeper aspect of cross-modal alignment as well as to achieve more\nsample-efficiency learning. We then discuss why music is an ideal domain in\nwhich to conduct LMM research. After that, we connect LMM in music with a more\ngeneral and challenging scientific problem of \\textit{learning to take actions\nbased on both sensory input and abstract symbols}, and in the end, present an\nadvanced version of the challenge problem setup.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00427v1",
    "published_date": "2025-03-01 10:04:36 UTC",
    "updated_date": "2025-03-01 10:04:36 UTC"
  },
  {
    "arxiv_id": "2503.00426v1",
    "title": "Auto-encoding Molecules: Graph-Matching Capabilities Matter",
    "authors": [
      "Magnus Cunow",
      "Gerrit Großmann"
    ],
    "abstract": "Autoencoders are effective deep learning models that can function as\ngenerative models and learn latent representations for downstream tasks. The\nuse of graph autoencoders - with both encoder and decoder implemented as\nmessage passing networks - is intriguing due to their ability to generate\npermutation-invariant graph representations. However, this approach faces\ndifficulties because decoding a graph structure from a single vector is\nchallenging, and comparing input and output graphs requires an effective\npermutation-invariant similarity measure. As a result, many studies rely on\napproximate methods.\n  In this work, we explore the effect of graph matching precision on the\ntraining behavior and generation capabilities of a Variational Autoencoder\n(VAE). Our contribution is two-fold: (1) we propose a transformer-based message\npassing graph decoder as an alternative to a graph neural network decoder, that\nis more robust and expressive by leveraging global attention mechanisms. (2) We\nshow that the precision of graph matching has significant impact on training\nbehavior and is essential for effective de novo (molecular) graph generation.\n  Code is available at https://github.com/mcunow/graph-matching",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00426v1",
    "published_date": "2025-03-01 10:00:37 UTC",
    "updated_date": "2025-03-01 10:00:37 UTC"
  },
  {
    "arxiv_id": "2503.00420v1",
    "title": "A physics-informed Bayesian optimization method for rapid development of electrical machines",
    "authors": [
      "Pedram Asef",
      "Christopher Vagg"
    ],
    "abstract": "Advanced slot and winding designs are imperative to create future high\nperformance electrical machines (EM). As a result, the development of methods\nto design and improve slot filling factor (SFF) has attracted considerable\nresearch. Recent developments in manufacturing processes, such as additive\nmanufacturing and alternative materials, has also highlighted a need for novel\nhigh-fidelity design techniques to develop high performance complex geometries\nand topologies. This study therefore introduces a novel physics-informed\nmachine learning (PIML) design optimization process for improving SFF in\ntraction electrical machines used in electric vehicles. A maximum entropy\nsampling algorithm (MESA) is used to seed a physics-informed Bayesian\noptimization (PIBO) algorithm, where the target function and its approximations\nare produced by Gaussian processes (GP)s. The proposed PIBO-MESA is coupled\nwith a 2D finite element model (FEM) to perform a GP-based surrogate and\nprovide the first demonstration of the optimal combination of complex design\nvariables for an electrical machine. Significant computational gains were\nachieved using the new PIBO-MESA approach, which is 45% faster than existing\nstochastic methods, such as the non-dominated sorting genetic algorithm II\n(NSGA-II). The FEM results confirm that the new design optimization process and\nkeystone shaped wires lead to a higher SFF (i.e. by 20%) and electromagnetic\nimprovements (e.g. maximum torque by 12%) with similar resistivity. The newly\ndeveloped PIBO-MESA design optimization process therefore presents significant\nbenefits in the design of high-performance electric machines, with reduced\ndevelopment time and costs.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00420v1",
    "published_date": "2025-03-01 09:43:58 UTC",
    "updated_date": "2025-03-01 09:43:58 UTC"
  },
  {
    "arxiv_id": "2503.00416v1",
    "title": "Breaking the Loop: Detecting and Mitigating Denial-of-Service Vulnerabilities in Large Language Models",
    "authors": [
      "Junzhe Yu",
      "Yi Liu",
      "Huijia Sun",
      "Ling Shi",
      "Yuqi Chen"
    ],
    "abstract": "Large Language Models (LLMs) have significantly advanced text understanding\nand generation, becoming integral to applications across education, software\ndevelopment, healthcare, entertainment, and legal services. Despite\nconsiderable progress in improving model reliability, latency remains\nunder-explored, particularly through recurrent generation, where models\nrepeatedly produce similar or identical outputs, causing increased latency and\npotential Denial-of-Service (DoS) vulnerabilities.\n  We propose RecurrentGenerator, a black-box evolutionary algorithm that\nefficiently identifies recurrent generation scenarios in prominent LLMs like\nLLama-3 and GPT-4o. Additionally, we introduce RecurrentDetector, a lightweight\nreal-time classifier trained on activation patterns, achieving 95.24% accuracy\nand an F1 score of 0.87 in detecting recurrent loops. Our methods provide\npractical solutions to mitigate latency-related vulnerabilities, and we\npublicly share our tools and data to support further research.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.PF"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00416v1",
    "published_date": "2025-03-01 09:32:17 UTC",
    "updated_date": "2025-03-01 09:32:17 UTC"
  },
  {
    "arxiv_id": "2503.00401v2",
    "title": "Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with Query-Oriented Pivot Tasks",
    "authors": [
      "Zongru Wu",
      "Pengzhou Cheng",
      "Zheng Wu",
      "Tianjie Ju",
      "Zhuosheng Zhang",
      "Gongshen Liu"
    ],
    "abstract": "Perception-enhanced pre-training, particularly through grounding techniques,\nis widely adopted to enhance the performance of graphical user interface (GUI)\nagents. However, in resource-constrained scenarios, the format discrepancy\nbetween coordinate-oriented grounding and action-oriented reasoning limits the\neffectiveness of grounding for reasoning tasks. To address this challenge, we\npropose a query-oriented pivot approach called query inference, which serves as\na bridge between GUI grounding and reasoning. By inferring potential user\nqueries from a screenshot and its associated element coordinates, query\ninference improves the understanding of coordinates while aligning more closely\nwith reasoning tasks. Experimental results show that query inference\noutperforms previous grounding techniques under the same training data scale.\nNotably, query inference achieves comparable or even better performance to\nlarge-scale grounding-enhanced OS-Atlas with less than 0.1% of training data.\nFurthermore, we explore the impact of reasoning formats and demonstrate that\nintegrating additional semantic information into the input further boosts\nreasoning performance. The code is publicly available at\nhttps://github.com/ZrW00/GUIPivot.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.HC"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00401v2",
    "published_date": "2025-03-01 08:29:59 UTC",
    "updated_date": "2025-03-04 12:04:26 UTC"
  },
  {
    "arxiv_id": "2503.07627v1",
    "title": "Psychological Counseling Ability of Large Language Models",
    "authors": [
      "Fangyu Peng",
      "Jingxin Nie"
    ],
    "abstract": "With the development of science and the continuous progress of artificial\nintelligence technology, Large Language Models (LLMs) have begun to be widely\nutilized across various fields. However, in the field of psychological\ncounseling, the ability of LLMs have not been systematically assessed. In this\nstudy, we assessed the psychological counseling ability of mainstream LLMs\nusing 1096 psychological counseling skill questions which were selected from\nthe Chinese National Counselor Level 3 Examination, including Knowledge-based,\nAnalytical-based, and Application-based question types. The analysis showed\nthat the correctness rates of the LLMs for Chinese questions, in descending\norder, were GLM-3 (46.5%), GPT-4 (46.1%), Gemini (45.0%), ERNIE-3.5 (45.7%) and\nGPT-3.5 (32.9%). The correctness rates of the LLMs for English questions, in\ndescending order, were ERNIE-3.5 (43.9%), GPT-4 (40.6%), Gemini (36.6%), GLM-3\n(29.9%) and GPT-3.5 (29.5%). A chi-square test indicated significant\ndifferences in the LLMs' performance on Chinese and English questions.\nFurthermore, we subsequently utilized the Counselor's Guidebook (Level 3) as a\nreference for ERNIE-3.5, resulting in a new correctness rate of 59.6%, a 13.8%\nimprovement over its initial rate of 45.8%. In conclusion, the study assessed\nthe psychological counseling ability of LLMs for the first time, which may\nprovide insights for future enhancement and improvement of psychological\ncounseling ability of LLMs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "25 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2503.07627v1",
    "published_date": "2025-03-01 08:01:25 UTC",
    "updated_date": "2025-03-01 08:01:25 UTC"
  },
  {
    "arxiv_id": "2503.00393v1",
    "title": "Reservoir Network with Structural Plasticity for Human Activity Recognition",
    "authors": [
      "Abdullah M. Zyarah",
      "Alaa M. Abdul-Hadi",
      "Dhireesha Kudithipudi"
    ],
    "abstract": "The unprecedented dissemination of edge devices is accompanied by a growing\ndemand for neuromorphic chips that can process time-series data natively\nwithout cloud support. Echo state network (ESN) is a class of recurrent neural\nnetworks that can be used to identify unique patterns in time-series data and\npredict future events. It is known for minimal computing resource requirements\nand fast training, owing to the use of linear optimization solely at the\nreadout stage. In this work, a custom-design neuromorphic chip based on ESN\ntargeting edge devices is proposed. The proposed system supports various\nlearning mechanisms, including structural plasticity and synaptic plasticity,\nlocally on-chip. This provides the network with an additional degree of freedom\nto continuously learn, adapt, and alter its structure and sparsity level,\nensuring high performance and continuous stability. We demonstrate the\nperformance of the proposed system as well as its robustness to noise against\nreal-world time-series datasets while considering various topologies of data\nmovement. An average accuracy of 95.95% and 85.24% are achieved on human\nactivity recognition and prosthetic finger control, respectively. We also\nillustrate that the proposed system offers a throughput of 6x10^4 samples/sec\nwith a power consumption of 47.7mW on a 65nm IBM process.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00393v1",
    "published_date": "2025-03-01 07:57:22 UTC",
    "updated_date": "2025-03-01 07:57:22 UTC"
  },
  {
    "arxiv_id": "2503.00392v1",
    "title": "Progressive Sparse Attention: Algorithm and System Co-design for Efficient Attention in LLM Serving",
    "authors": [
      "Qihui Zhou",
      "Peiqi Yin",
      "Pengfei Zuo",
      "James Cheng"
    ],
    "abstract": "Processing long contexts has become a critical capability for modern large\nlanguage models (LLMs). However, serving long-context LLMs comes with\nsignificant inference costs due to the high memory overhead of the key-value\n(KV) cache. Existing work leverages dynamic sparse attention algorithms (DSAes)\nto mitigate the KV cache overhead, but these algorithms rely on top-$k$ KV\ncache selection, which results in a trade-off between accuracy and efficiency.\nA larger $k$ improves accuracy but decreases efficiency, while a smaller $k$\nboosts efficiency but compromises accuracy. To overcome this trade-off, this\npaper presents PSA, a $\\underline{P}$rogressive $\\underline{S}$parse\n$\\underline{A}$ttention mechanism that integrates algorithmic innovations with\nsystem co-design to achieve both high inference accuracy and improved\nefficiency in LLM serving. The PSA algorithm adaptively adjusts the KV cache\nbudget of different tokens and layers according to their real attention weight\ndistributions, rather than relying on a fixed budget $k$. This enables high\naccuracy while minimizing KV cache usage. To further enhance execution\nefficiency, we introduce a pipelined iteration scheme that reduces CPU-GPU\ninterleaving and synchronization overhead during PSA computation. Additionally,\nwe implement unified GPU memory management that optimizes PSA's memory\nutilization by accounting for uneven memory requirements across different model\nlayers. Extensive experimental results demonstrate that PSA reduces KV cache\nusage for attention computation by up to 2.4$\\times$ and 8.8$\\times$, and\nincreases end-to-end serving throughput by up to 1.4$\\times$ and 2.0$\\times$,\ncompared to state-of-the-art DSAes and systems without sparse attention,\nrespectively.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "12 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00392v1",
    "published_date": "2025-03-01 07:56:42 UTC",
    "updated_date": "2025-03-01 07:56:42 UTC"
  },
  {
    "arxiv_id": "2503.00389v1",
    "title": "BGM2Pose: Active 3D Human Pose Estimation with Non-Stationary Sounds",
    "authors": [
      "Yuto Shibata",
      "Yusuke Oumi",
      "Go Irie",
      "Akisato Kimura",
      "Yoshimitsu Aoki",
      "Mariko Isogawa"
    ],
    "abstract": "We propose BGM2Pose, a non-invasive 3D human pose estimation method using\narbitrary music (e.g., background music) as active sensing signals. Unlike\nexisting approaches that significantly limit practicality by employing\nintrusive chirp signals within the audible range, our method utilizes natural\nmusic that causes minimal discomfort to humans. Estimating human poses from\nstandard music presents significant challenges. In contrast to sound sources\nspecifically designed for measurement, regular music varies in both volume and\npitch. These dynamic changes in signals caused by music are inevitably mixed\nwith alterations in the sound field resulting from human motion, making it hard\nto extract reliable cues for pose estimation. To address these challenges,\nBGM2Pose introduces a Contrastive Pose Extraction Module that employs\ncontrastive learning and hard negative sampling to eliminate musical components\nfrom the recorded data, isolating the pose information. Additionally, we\npropose a Frequency-wise Attention Module that enables the model to focus on\nsubtle acoustic variations attributable to human movement by dynamically\ncomputing attention across frequency bands. Experiments suggest that our method\noutperforms the existing methods, demonstrating substantial potential for\nreal-world applications. Our datasets and code will be made publicly available.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.SD",
      "eess.AS"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00389v1",
    "published_date": "2025-03-01 07:32:19 UTC",
    "updated_date": "2025-03-01 07:32:19 UTC"
  },
  {
    "arxiv_id": "2503.00387v1",
    "title": "LNUCB-TA: Linear-nonlinear Hybrid Bandit Learning with Temporal Attention",
    "authors": [
      "Hamed Khosravi",
      "Mohammad Reza Shafie",
      "Ahmed Shoyeb Raihan",
      "Srinjoy Das",
      "Imtiaz Ahmed"
    ],
    "abstract": "Existing contextual multi-armed bandit (MAB) algorithms fail to effectively\ncapture both long-term trends and local patterns across all arms, leading to\nsuboptimal performance in environments with rapidly changing reward structures.\nThey also rely on static exploration rates, which do not dynamically adjust to\nchanging conditions. To overcome these limitations, we propose LNUCB-TA, a\nhybrid bandit model integrating a novel nonlinear component (adaptive k-Nearest\nNeighbors (k-NN)) for reducing time complexity, alongside a global-and-local\nattention-based exploration mechanism. Our approach uniquely combines linear\nand nonlinear estimation techniques, with the nonlinear module dynamically\nadjusting k based on reward variance to enhance spatiotemporal pattern\nrecognition. This reduces the likelihood of selecting suboptimal arms while\nimproving reward estimation accuracy and computational efficiency. The\nattention-based mechanism ranks arms by past performance and selection\nfrequency, dynamically adjusting exploration and exploitation in real time\nwithout requiring manual tuning of exploration rates. By integrating global\nattention (assessing all arms collectively) and local attention (focusing on\nindividual arms), LNUCB-TA efficiently adapts to temporal and spatial\ncomplexities. Empirical results show LNUCB-TA significantly outperforms\nstate-of-the-art linear, nonlinear, and hybrid bandits in cumulative and mean\nreward, convergence, and robustness across different exploration rates.\nTheoretical analysis further confirms its reliability with a sub-linear regret\nbound.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00387v1",
    "published_date": "2025-03-01 07:24:54 UTC",
    "updated_date": "2025-03-01 07:24:54 UTC"
  },
  {
    "arxiv_id": "2503.00384v1",
    "title": "A Survey of Adversarial Defenses in Vision-based Systems: Categorization, Methods and Challenges",
    "authors": [
      "Nandish Chattopadhyay",
      "Abdul Basit",
      "Bassem Ouni",
      "Muhammad Shafique"
    ],
    "abstract": "Adversarial attacks have emerged as a major challenge to the trustworthy\ndeployment of machine learning models, particularly in computer vision\napplications. These attacks have a varied level of potency and can be\nimplemented in both white box and black box approaches. Practical attacks\ninclude methods to manipulate the physical world and enforce adversarial\nbehaviour by the corresponding target neural network models. Multiple different\napproaches to mitigate different kinds of such attacks are available in the\nliterature, each with their own advantages and limitations. In this survey, we\npresent a comprehensive systematization of knowledge on adversarial defenses,\nfocusing on two key computer vision tasks: image classification and object\ndetection. We review the state-of-the-art adversarial defense techniques and\ncategorize them for easier comparison. In addition, we provide a schematic\nrepresentation of these categories within the context of the overall machine\nlearning pipeline, facilitating clearer understanding and benchmarking of\ndefenses. Furthermore, we map these defenses to the types of adversarial\nattacks and datasets where they are most effective, offering practical insights\nfor researchers and practitioners. This study is necessary for understanding\nthe scope of how the available defenses are able to address the adversarial\nthreats, and their shortcomings as well, which is necessary for driving the\nresearch in this area in the most appropriate direction, with the aim of\nbuilding trustworthy AI systems for regular practical use-cases.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00384v1",
    "published_date": "2025-03-01 07:17:18 UTC",
    "updated_date": "2025-03-01 07:17:18 UTC"
  },
  {
    "arxiv_id": "2503.00383v1",
    "title": "Theoretical Insights in Model Inversion Robustness and Conditional Entropy Maximization for Collaborative Inference Systems",
    "authors": [
      "Song Xia",
      "Yi Yu",
      "Wenhan Yang",
      "Meiwen Ding",
      "Zhuo Chen",
      "Lingyu Duan",
      "Alex C. Kot",
      "Xudong Jiang"
    ],
    "abstract": "By locally encoding raw data into intermediate features, collaborative\ninference enables end users to leverage powerful deep learning models without\nexposure of sensitive raw data to cloud servers. However, recent studies have\nrevealed that these intermediate features may not sufficiently preserve\nprivacy, as information can be leaked and raw data can be reconstructed via\nmodel inversion attacks (MIAs). Obfuscation-based methods, such as noise\ncorruption, adversarial representation learning, and information filters,\nenhance the inversion robustness by obfuscating the task-irrelevant redundancy\nempirically. However, methods for quantifying such redundancy remain elusive,\nand the explicit mathematical relation between this redundancy minimization and\ninversion robustness enhancement has not yet been established. To address that,\nthis work first theoretically proves that the conditional entropy of inputs\ngiven intermediate features provides a guaranteed lower bound on the\nreconstruction mean square error (MSE) under any MIA. Then, we derive a\ndifferentiable and solvable measure for bounding this conditional entropy based\non the Gaussian mixture estimation and propose a conditional entropy\nmaximization (CEM) algorithm to enhance the inversion robustness. Experimental\nresults on four datasets demonstrate the effectiveness and adaptability of our\nproposed CEM; without compromising feature utility and computing efficiency,\nplugging the proposed CEM into obfuscation-based defense mechanisms\nconsistently boosts their inversion robustness, achieving average gains ranging\nfrom 12.9\\% to 48.2\\%. Code is available at\n\\href{https://github.com/xiasong0501/CEM}{https://github.com/xiasong0501/CEM}.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by CVPR2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00383v1",
    "published_date": "2025-03-01 07:15:21 UTC",
    "updated_date": "2025-03-01 07:15:21 UTC"
  },
  {
    "arxiv_id": "2503.00378v1",
    "title": "Conditioning on Local Statistics for Scalable Heterogeneous Federated Learning",
    "authors": [
      "Rickard Brännvall"
    ],
    "abstract": "Federated learning is a distributed machine learning approach where multiple\nclients collaboratively train a model without sharing their local data, which\ncontributes to preserving privacy. A challenge in federated learning is\nmanaging heterogeneous data distributions across clients, which can hinder\nmodel convergence and performance due to the need for the global model to\ngeneralize well across diverse local datasets. We propose to use local\ncharacteristic statistics, by which we mean some statistical properties\ncalculated independently by each client using only their local training\ndataset. These statistics, such as means, covariances, and higher moments, are\nused to capture the characteristics of the local data distribution. They are\nnot shared with other clients or a central node. During training, these local\nstatistics help the model learn how to condition on the local data\ndistribution, and during inference, they guide the client's predictions. Our\nexperiments show that this approach allows for efficient handling of\nheterogeneous data across the federation, has favorable scaling compared to\napproaches that directly try to identify peer nodes that share distribution\ncharacteristics, and maintains privacy as no additional information needs to be\ncommunicated.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "cs.DC",
      "68T09 (Primary) 68T05 (Secondary)",
      "D.4.6; K.6.5; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "7 pages, 2 figures, 7 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.00378v1",
    "published_date": "2025-03-01 07:10:58 UTC",
    "updated_date": "2025-03-01 07:10:58 UTC"
  },
  {
    "arxiv_id": "2503.00374v2",
    "title": "MIRROR: Multi-Modal Pathological Self-Supervised Representation Learning via Modality Alignment and Retention",
    "authors": [
      "Tianyi Wang",
      "Jianan Fan",
      "Dingxin Zhang",
      "Dongnan Liu",
      "Yong Xia",
      "Heng Huang",
      "Weidong Cai"
    ],
    "abstract": "Histopathology and transcriptomics are fundamental modalities in oncology,\nencapsulating the morphological and molecular aspects of the disease.\nMulti-modal self-supervised learning has demonstrated remarkable potential in\nlearning pathological representations by integrating diverse data sources.\nConventional multi-modal integration methods primarily emphasize modality\nalignment, while paying insufficient attention to retaining the\nmodality-specific structures. However, unlike conventional scenarios where\nmulti-modal inputs share highly overlapping features, histopathology and\ntranscriptomics exhibit pronounced heterogeneity, offering orthogonal yet\ncomplementary insights. Histopathology provides morphological and spatial\ncontext, elucidating tissue architecture and cellular topology, whereas\ntranscriptomics delineates molecular signatures through gene expression\npatterns. This inherent disparity introduces a major challenge in aligning them\nwhile maintaining modality-specific fidelity. To address these challenges, we\npresent MIRROR, a novel multi-modal representation learning method designed to\nfoster both modality alignment and retention. MIRROR employs dedicated encoders\nto extract comprehensive features for each modality, which is further\ncomplemented by a modality alignment module to achieve seamless integration\nbetween phenotype patterns and molecular profiles. Furthermore, a modality\nretention module safeguards unique attributes from each modality, while a style\nclustering module mitigates redundancy and enhances disease-relevant\ninformation by modeling and aligning consistent pathological signatures within\na clustering space. Extensive evaluations on TCGA cohorts for cancer subtyping\nand survival analysis highlight MIRROR's superior performance, demonstrating\nits effectiveness in constructing comprehensive oncological feature\nrepresentations and benefiting the cancer diagnosis.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages, 5 figures, 4 tables. Code available at\n  https://github.com/TianyiFranklinWang/MIRROR. Project page:\n  https://tianyifranklinwang.github.io/MIRROR",
    "pdf_url": "http://arxiv.org/pdf/2503.00374v2",
    "published_date": "2025-03-01 07:02:30 UTC",
    "updated_date": "2025-03-19 02:50:30 UTC"
  },
  {
    "arxiv_id": "2503.00372v1",
    "title": "Nucleolus Credit Assignment for Effective Coalitions in Multi-agent Reinforcement Learning",
    "authors": [
      "Yugu Li",
      "Zehong Cao",
      "Jianglin Qiao",
      "Siyi Hu"
    ],
    "abstract": "In cooperative multi-agent reinforcement learning (MARL), agents typically\nform a single grand coalition based on credit assignment to tackle a composite\ntask, often resulting in suboptimal performance. This paper proposed a\nnucleolus-based credit assignment grounded in cooperative game theory, enabling\nthe autonomous partitioning of agents into multiple small coalitions that can\neffectively identify and complete subtasks within a larger composite task.\nSpecifically, our designed nucleolus Q-learning could assign fair credits to\neach agent, and the nucleolus Q-operator provides theoretical guarantees with\ninterpretability for both learning convergence and the stability of the formed\nsmall coalitions. Through experiments on Predator-Prey and StarCraft scenarios\nacross varying difficulty levels, our approach demonstrated the emergence of\nmultiple effective coalitions during MARL training, leading to faster learning\nand superior performance in terms of win rate and cumulative rewards especially\nin hard and super-hard environments, compared to four baseline methods. Our\nnucleolus-based credit assignment showed the promise for complex composite\ntasks requiring effective subteams of agents.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00372v1",
    "published_date": "2025-03-01 07:01:58 UTC",
    "updated_date": "2025-03-01 07:01:58 UTC"
  },
  {
    "arxiv_id": "2503.00366v1",
    "title": "AI-Augmented Thyroid Scintigraphy for Robust Classification",
    "authors": [
      "Maziar Sabouri",
      "Ghasem Hajianfar",
      "Alireza Rafiei Sardouei",
      "Milad Yazdani",
      "Azin Asadzadeh",
      "Soroush Bagheri",
      "Mohsen Arabi",
      "Seyed Rasoul Zakavi",
      "Emran Askari",
      "Atena Aghaee",
      "Dena Shahriari",
      "Habib Zaidi",
      "Arman Rahmim"
    ],
    "abstract": "Thyroid scintigraphy is a key imaging modality for diagnosing thyroid\ndisorders. Deep learning models for thyroid scintigraphy classification often\nface challenges due to limited and imbalanced datasets, leading to suboptimal\ngeneralization. In this study, we investigate the effectiveness of different\ndata augmentation techniques including Stable Diffusion (SD), Flow Matching\n(FM), and Conventional Augmentation (CA) to enhance the performance of a\nResNet18 classifier for thyroid condition classification. Our results showed\nthat FM-based augmentation consistently outperforms SD-based approaches,\nparticularly when combined with original (O) data and CA (O+FM+CA), achieving\nboth high accuracy and fair classification across Diffuse Goiter (DG), Nodular\nGoiter (NG), Normal (NL), and Thyroiditis (TI) cases. The Wilcoxon statistical\nanalysis further validated the superiority of O+FM and its variants (O+FM+CA)\nover SD-based augmentations in most scenarios. These findings highlight the\npotential of FM-based augmentation as a superior approach for generating\nhigh-quality synthetic thyroid scintigraphy images and improving model\ngeneralization in medical image classification.",
    "categories": [
      "physics.med-ph",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "physics.med-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00366v1",
    "published_date": "2025-03-01 06:21:46 UTC",
    "updated_date": "2025-03-01 06:21:46 UTC"
  },
  {
    "arxiv_id": "2503.00361v1",
    "title": "Octopus: Alleviating Hallucination via Dynamic Contrastive Decoding",
    "authors": [
      "Wei Suo",
      "Lijun Zhang",
      "Mengyang Sun",
      "Lin Yuanbo Wu",
      "Peng Wang",
      "Yanning Zhang"
    ],
    "abstract": "Large Vision-Language Models (LVLMs) have obtained impressive performance in\nvisual content understanding and multi-modal reasoning. Unfortunately, these\nlarge models suffer from serious hallucination problems and tend to generate\nfabricated responses. Recently, several Contrastive Decoding (CD) strategies\nhave been proposed to alleviate hallucination by introducing disturbed inputs.\nAlthough great progress has been made, these CD strategies mostly apply a\none-size-fits-all approach for all input conditions. In this paper, we revisit\nthis process through extensive experiments. Related results show that\nhallucination causes are hybrid and each generative step faces a unique\nhallucination challenge. Leveraging these meaningful insights, we introduce a\nsimple yet effective Octopus-like framework that enables the model to\nadaptively identify hallucination types and create a dynamic CD workflow. Our\nOctopus framework not only outperforms existing methods across four benchmarks\nbut also demonstrates excellent deployability and expansibility. Code is\navailable at https://github.com/LijunZhang01/Octopus.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00361v1",
    "published_date": "2025-03-01 06:00:34 UTC",
    "updated_date": "2025-03-01 06:00:34 UTC"
  },
  {
    "arxiv_id": "2503.00358v1",
    "title": "CRUPL: A Semi-Supervised Cyber Attack Detection with Consistency Regularization and Uncertainty-aware Pseudo-Labeling in Smart Grid",
    "authors": [
      "Smruti P. Dash",
      "Kedar V. Khandeparkar",
      "Nipun Agrawal"
    ],
    "abstract": "The modern power grids are integrated with digital technologies and\nautomation systems. The inclusion of digital technologies has made the smart\ngrids vulnerable to cyber-attacks. Cyberattacks on smart grids can compromise\ndata integrity and jeopardize the reliability of the power supply. Traditional\nintrusion detection systems often need help to effectively detect novel and\nsophisticated attacks due to their reliance on labeled training data, which may\nonly encompass part of the spectrum of potential threats. This work proposes a\nsemi-supervised method for cyber-attack detection in smart grids by leveraging\nthe labeled and unlabeled measurement data. We implement consistency\nregularization and pseudo-labeling to identify deviations from expected\nbehavior and predict the attack classes. We use a curriculum learning approach\nto improve pseudo-labeling performance, capturing the model uncertainty. We\ndemonstrate the efficiency of the proposed method in detecting different types\nof cyberattacks, minimizing the false positives by implementing them on\npublicly available datasets. The method proposes a promising solution by\nimproving the detection accuracy to 99% in the presence of unknown samples and\nsignificantly reducing false positives.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG",
      "68T07 (Primary), 68T27, 68T37 (Secondary)",
      "I.2.m"
    ],
    "primary_category": "cs.CR",
    "comment": "20 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00358v1",
    "published_date": "2025-03-01 05:49:23 UTC",
    "updated_date": "2025-03-01 05:49:23 UTC"
  },
  {
    "arxiv_id": "2503.00356v1",
    "title": "BERT-based model for Vietnamese Fact Verification Dataset",
    "authors": [
      "Bao Tran",
      "T. N. Khanh",
      "Khang Nguyen Tuong",
      "Thien Dang",
      "Quang Nguyen",
      "Nguyen T. Thinh",
      "Vo T. Hung"
    ],
    "abstract": "The rapid advancement of information and communication technology has\nfacilitated easier access to information. However, this progress has also\nnecessitated more stringent verification measures to ensure the accuracy of\ninformation, particularly within the context of Vietnam. This paper introduces\nan approach to address the challenges of Fact Verification using the Vietnamese\ndataset by integrating both sentence selection and classification modules into\na unified network architecture. The proposed approach leverages the power of\nlarge language models by utilizing pre-trained PhoBERT and XLM-RoBERTa as the\nbackbone of the network. The proposed model was trained on a Vietnamese\ndataset, named ISE-DSC01, and demonstrated superior performance compared to the\nbaseline model across all three metrics. Notably, we achieved a Strict Accuracy\nlevel of 75.11\\%, indicating a remarkable 28.83\\% improvement over the baseline\nmodel.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted for Oral Presentation in CITA 2024 (The 13th Conference on\n  Information Technology and Its Applications) and will be published in VOLUME\n  1 OF CITA 2024 (Volume of the Lecture Notes in Network and Systems, Springer)",
    "pdf_url": "http://arxiv.org/pdf/2503.00356v1",
    "published_date": "2025-03-01 05:31:04 UTC",
    "updated_date": "2025-03-01 05:31:04 UTC"
  },
  {
    "arxiv_id": "2503.00355v1",
    "title": "Structured Reasoning for Fairness: A Multi-Agent Approach to Bias Detection in Textual Data",
    "authors": [
      "Tianyi Huang",
      "Elsa Fan"
    ],
    "abstract": "From disinformation spread by AI chatbots to AI recommendations that\ninadvertently reinforce stereotypes, textual bias poses a significant challenge\nto the trustworthiness of large language models (LLMs). In this paper, we\npropose a multi-agent framework that systematically identifies biases by\ndisentangling each statement as fact or opinion, assigning a bias intensity\nscore, and providing concise, factual justifications. Evaluated on 1,500\nsamples from the WikiNPOV dataset, the framework achieves 84.9%\naccuracy$\\unicode{x2014}$an improvement of 13.0% over the zero-shot\nbaseline$\\unicode{x2014}$demonstrating the efficacy of explicitly modeling fact\nversus opinion prior to quantifying bias intensity. By combining enhanced\ndetection accuracy with interpretable explanations, this approach sets a\nfoundation for promoting fairness and accountability in modern language models.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted Paper (Oral Presentation) in the Workshop on the Social\n  Impact of AI: Research, Diversity and Inclusion Frameworks at AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00355v1",
    "published_date": "2025-03-01 05:27:54 UTC",
    "updated_date": "2025-03-01 05:27:54 UTC"
  },
  {
    "arxiv_id": "2503.00334v1",
    "title": "MCNet: Monotonic Calibration Networks for Expressive Uncertainty Calibration in Online Advertising",
    "authors": [
      "Quanyu Dai",
      "Jiaren Xiao",
      "Zhaocheng Du",
      "Jieming Zhu",
      "Chengxiao Luo",
      "Xiao-Ming Wu",
      "Zhenhua Dong"
    ],
    "abstract": "In online advertising, uncertainty calibration aims to adjust a ranking\nmodel's probability predictions to better approximate the true likelihood of an\nevent, e.g., a click or a conversion. However, existing calibration approaches\nmay lack the ability to effectively model complex nonlinear relations, consider\ncontext features, and achieve balanced performance across different data\nsubsets. To tackle these challenges, we introduce a novel model called\nMonotonic Calibration Networks, featuring three key designs: a monotonic\ncalibration function (MCF), an order-preserving regularizer, and a\nfield-balance regularizer. The nonlinear MCF is capable of naturally modeling\nand universally approximating the intricate relations between uncalibrated\npredictions and the posterior probabilities, thus being much more expressive\nthan existing methods. MCF can also integrate context features using a flexible\nmodel architecture, thereby achieving context awareness. The order-preserving\nand field-balance regularizers promote the monotonic relationship between\nadjacent bins and the balanced calibration performance on data subsets,\nrespectively. Experimental results on both public and industrial datasets\ndemonstrate the superior performance of our method in generating\nwell-calibrated probability predictions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML",
      "H.0"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by WWW2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00334v1",
    "published_date": "2025-03-01 03:54:58 UTC",
    "updated_date": "2025-03-01 03:54:58 UTC"
  },
  {
    "arxiv_id": "2503.01910v1",
    "title": "dyAb: Flow Matching for Flexible Antibody Design with AlphaFold-driven Pre-binding Antigen",
    "authors": [
      "Cheng Tan",
      "Yijie Zhang",
      "Zhangyang Gao",
      "Yufei Huang",
      "Haitao Lin",
      "Lirong Wu",
      "Fandi Wu",
      "Mathieu Blanchette",
      "Stan. Z. Li"
    ],
    "abstract": "The development of therapeutic antibodies heavily relies on accurate\npredictions of how antigens will interact with antibodies. Existing\ncomputational methods in antibody design often overlook crucial conformational\nchanges that antigens undergo during the binding process, significantly\nimpacting the reliability of the resulting antibodies. To bridge this gap, we\nintroduce dyAb, a flexible framework that incorporates AlphaFold2-driven\npredictions to model pre-binding antigen structures and specifically addresses\nthe dynamic nature of antigen conformation changes. Our dyAb model leverages a\nunique combination of coarse-grained interface alignment and fine-grained flow\nmatching techniques to simulate the interaction dynamics and structural\nevolution of the antigen-antibody complex, providing a realistic representation\nof the binding process. Extensive experiments show that dyAb significantly\noutperforms existing models in antibody design involving changing antigen\nconformations. These results highlight dyAb's potential to streamline the\ndesign process for therapeutic antibodies, promising more efficient development\ncycles and improved outcomes in clinical applications.",
    "categories": [
      "q-bio.QM",
      "cs.AI"
    ],
    "primary_category": "q-bio.QM",
    "comment": "AAAI 2025 Oral",
    "pdf_url": "http://arxiv.org/pdf/2503.01910v1",
    "published_date": "2025-03-01 03:53:18 UTC",
    "updated_date": "2025-03-01 03:53:18 UTC"
  },
  {
    "arxiv_id": "2503.00333v1",
    "title": "More of the Same: Persistent Representational Harms Under Increased Representation",
    "authors": [
      "Jennifer Mickel",
      "Maria De-Arteaga",
      "Leqi Liu",
      "Kevin Tian"
    ],
    "abstract": "To recognize and mitigate the harms of generative AI systems, it is crucial\nto consider who is represented in the outputs of generative AI systems and how\npeople are represented. A critical gap emerges when naively improving who is\nrepresented, as this does not imply bias mitigation efforts have been applied\nto address how people are represented. We critically examined this by\ninvestigating gender representation in occupation across state-of-the-art large\nlanguage models. We first show evidence suggesting that over time there have\nbeen interventions to models altering the resulting gender distribution, and we\nfind that women are more represented than men when models are prompted to\ngenerate biographies or personas. We then demonstrate that representational\nbiases persist in how different genders are represented by examining\nstatistically significant word differences across genders. This results in a\nproliferation of representational harms, stereotypes, and neoliberalism ideals\nthat, despite existing interventions to increase female representation,\nreinforce existing systems of oppression.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "26 pages, 7 figures, 6 tables, pre-print",
    "pdf_url": "http://arxiv.org/pdf/2503.00333v1",
    "published_date": "2025-03-01 03:45:35 UTC",
    "updated_date": "2025-03-01 03:45:35 UTC"
  },
  {
    "arxiv_id": "2503.00332v2",
    "title": "Investigating the contribution of terrain-following coordinates and conservation schemes in AI-driven precipitation forecasts",
    "authors": [
      "Yingkai Sha",
      "John S. Schreck",
      "William Chapman",
      "David John Gagne II"
    ],
    "abstract": "Artificial Intelligence (AI) weather prediction (AIWP) models often produce\n\"blurry\" precipitation forecasts that overestimate drizzle and underestimate\nextremes. This study provides a novel solution to tackle this problem --\nintegrating terrain-following coordinates with global mass and energy\nconservation schemes into AIWP models. Forecast experiments are conducted to\nevaluate the effectiveness of this solution using FuXi, an example AIWP model,\nadapted to 1.0-degree grid spacing data. Verification results show large\nperformance gains. The conservation schemes are found to reduce drizzle bias,\nwhereas using terrain-following coordinates improves the estimation of extreme\nevents and precipitation intensity spectra. Furthermore, a case study reveals\nthat terrain-following coordinates capture near-surface winds better over\nmountains, offering AIWP models more accurate information on understanding the\ndynamics of precipitation processes. The proposed solution of this study can\nbenefit a wide range of AIWP models and bring insights into how atmospheric\ndomain knowledge can support the development of AIWP models.",
    "categories": [
      "physics.ao-ph",
      "cs.AI"
    ],
    "primary_category": "physics.ao-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00332v2",
    "published_date": "2025-03-01 03:44:46 UTC",
    "updated_date": "2025-03-17 16:06:25 UTC"
  },
  {
    "arxiv_id": "2503.00331v1",
    "title": "PINN-DT: Optimizing Energy Consumption in Smart Building Using Hybrid Physics-Informed Neural Networks and Digital Twin Framework with Blockchain Security",
    "authors": [
      "Hajar Kazemi Naeini",
      "Roya Shomali",
      "Abolhassan Pishahang",
      "Hamidreza Hasanzadeh",
      "Mahdieh Mohammadi",
      "Saeid Asadi",
      "Ahmad Gholizadeh Lonbar"
    ],
    "abstract": "The advancement of smart grid technologies necessitates the integration of\ncutting-edge computational methods to enhance predictive energy optimization.\nThis study proposes a multi-faceted approach by incorporating (1) Deep\nReinforcement Learning (DRL) agents trained using data from Digital Twins (DTs)\nto optimize energy consumption in real time, (2) Physics-Informed Neural\nNetworks (PINNs) to seamlessly embed physical laws within the optimization\nprocess, ensuring model accuracy and interpretability, and (3) Blockchain (BC)\ntechnology to facilitate secure and transparent communication across the smart\ngrid infrastructure. The model was trained and validated using comprehensive\ndatasets, including smart meter energy consumption data, renewable energy\noutputs, dynamic pricing, and user preferences collected from IoT devices. The\nproposed framework achieved superior predictive performance with a Mean\nAbsolute Error (MAE) of 0.237 kWh, Root Mean Square Error (RMSE) of 0.298 kWh,\nand an R-squared (R2) value of 0.978, indicating a 97.8% explanation of data\nvariance. Classification metrics further demonstrated the model's robustness,\nachieving 97.7% accuracy, 97.8% precision, 97.6% recall, and an F1 Score of\n97.7%. Comparative analysis with traditional models like Linear Regression,\nRandom Forest, SVM, LSTM, and XGBoost revealed the superior accuracy and\nreal-time adaptability of the proposed method. In addition to enhancing energy\nefficiency, the model reduced energy costs by 35%, maintained a 96% user\ncomfort index, and increased renewable energy utilization to 40%. This study\ndemonstrates the transformative potential of integrating PINNs, DT, and\nBlockchain technologies to optimize energy consumption in smart grids, paving\nthe way for sustainable, secure, and efficient energy management systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00331v1",
    "published_date": "2025-03-01 03:37:09 UTC",
    "updated_date": "2025-03-01 03:37:09 UTC"
  },
  {
    "arxiv_id": "2503.04792v1",
    "title": "Cross-linguistic disagreement as a conflict of semantic alignment norms in multilingual AI~Linguistic Diversity as a Problem for Philosophy, Cognitive Science, and AI~",
    "authors": [
      "Masaharu Mizumoto",
      "Dat Tien Nguyen",
      "Justin Sytsma",
      "Mark Alfano",
      "Yu Izumi",
      "Koji Fujita",
      "Nguyen Le Minh"
    ],
    "abstract": "Multilingual large language models (LLMs) face an often-overlooked challenge\nstemming from intrinsic semantic differences across languages. Linguistic\ndivergence can sometimes lead to cross-linguistic disagreements--disagreements\npurely due to semantic differences about a relevant concept. This paper\nidentifies such disagreements as conflicts between two fundamental alignment\nnorms in multilingual LLMs: cross-linguistic consistency (CL-consistency),\nwhich seeks universal concepts across languages, and consistency with folk\njudgments (Folk-consistency), which respects language-specific semantic norms.\nThrough examining responses of conversational multilingual AIs in English and\nJapanese with the cases used in philosophy (cases of knowledge-how\nattributions), this study demonstrates that even state-of-the-art LLMs provide\ndivergent and internally inconsistent responses. Such findings reveal a novel\nqualitative limitation in crosslingual knowledge transfer, or conceptual\ncrosslingual knowledge barriers, challenging the assumption that universal\nrepresentations and cross-linguistic transfer capabilities are inherently\ndesirable. Moreover, they reveal conflicts of alignment policies of their\ndevelopers, highlighting critical normative questions for LLM researchers and\ndevelopers. The implications extend beyond technical alignment challenges,\nraising normative, moral-political, and metaphysical questions about the ideals\nunderlying AI development--questions that are shared with philosophers and\ncognitive scientists but for which no one yet has definitive answers, inviting\na multidisciplinary approach to balance the practical benefits of\ncross-linguistic consistency and respect for linguistic diversity.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.04792v1",
    "published_date": "2025-03-01 03:31:40 UTC",
    "updated_date": "2025-03-01 03:31:40 UTC"
  },
  {
    "arxiv_id": "2503.00323v1",
    "title": "FLStore: Efficient Federated Learning Storage for non-training workloads",
    "authors": [
      "Ahmad Faraz Khan",
      "Samuel Fountain",
      "Ahmed M. Abdelmoniem",
      "Ali R. Butt",
      "Ali Anwar"
    ],
    "abstract": "Federated Learning (FL) is an approach for privacy-preserving Machine\nLearning (ML), enabling model training across multiple clients without\ncentralized data collection. With an aggregator server coordinating training,\naggregating model updates, and storing metadata across rounds. In addition to\ntraining, a substantial part of FL systems are the non-training workloads such\nas scheduling, personalization, clustering, debugging, and incentivization.\nMost existing systems rely on the aggregator to handle non-training workloads\nand use cloud services for data storage. This results in high latency and\nincreased costs as non-training workloads rely on large volumes of metadata,\nincluding weight parameters from client updates, hyperparameters, and\naggregated updates across rounds, making the situation even worse. We propose\nFLStore, a serverless framework for efficient FL non-training workloads and\nstorage. FLStore unifies the data and compute planes on a serverless cache,\nenabling locality-aware execution via tailored caching policies to reduce\nlatency and costs. Per our evaluations, compared to cloud object store based\naggregator server FLStore reduces per request average latency by 71% and costs\nby 92.45%, with peak improvements of 99.7% and 98.8%, respectively. Compared to\nan in-memory cloud cache based aggregator server, FLStore reduces average\nlatency by 64.6% and costs by 98.83%, with peak improvements of 98.8% and\n99.6%, respectively. FLStore integrates seamlessly with existing FL frameworks\nwith minimal modifications, while also being fault-tolerant and highly\nscalable.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "11 pages, 19 figures, 2 tables This paper has been accepted at the\n  The Eighth Annual Conference on Machine Learning and Systems (MLSys 2025)",
    "pdf_url": "http://arxiv.org/pdf/2503.00323v1",
    "published_date": "2025-03-01 03:20:30 UTC",
    "updated_date": "2025-03-01 03:20:30 UTC"
  },
  {
    "arxiv_id": "2503.00322v1",
    "title": "T-REX: A 68-567 μs/token, 0.41-3.95 μJ/token Transformer Accelerator with Reduced External Memory Access and Enhanced Hardware Utilization in 16nm FinFET",
    "authors": [
      "Seunghyun Moon",
      "Mao Li",
      "Gregory Chen",
      "Phil Knag",
      "Ram Krishnamurthy",
      "Mingoo Seok"
    ],
    "abstract": "This work introduces novel training and post-training compression schemes to\nreduce external memory access during transformer model inference. Additionally,\na new control flow mechanism, called dynamic batching, and a novel buffer\narchitecture, termed a two-direction accessible register file, further reduce\nexternal memory access while improving hardware utilization.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "Accepted to IEEE ISSCC 2025",
    "pdf_url": "http://arxiv.org/pdf/2503.00322v1",
    "published_date": "2025-03-01 03:18:12 UTC",
    "updated_date": "2025-03-01 03:18:12 UTC"
  },
  {
    "arxiv_id": "2503.00320v2",
    "title": "Shifting Power: Leveraging LLMs to Simulate Human Aversion in ABMs of Bilateral Financial Exchanges, A bond market study",
    "authors": [
      "Alicia Vidler",
      "Toby Walsh"
    ],
    "abstract": "Bilateral markets, such as those for government bonds, involve decentralized\nand opaque transactions between market makers (MMs) and clients, posing\nsignificant challenges for traditional modeling approaches. To address these\ncomplexities, we introduce TRIBE an agent-based model augmented with a large\nlanguage model (LLM) to simulate human-like decision-making in trading\nenvironments. TRIBE leverages publicly available data and stylized facts to\ncapture realistic trading dynamics, integrating human biases like risk aversion\nand ambiguity sensitivity into the decision-making processes of agents. Our\nresearch yields three key contributions: first, we demonstrate that integrating\nLLMs into agent-based models to enhance client agency is feasible and enriches\nthe simulation of agent behaviors in complex markets; second, we find that even\nslight trade aversion encoded within the LLM leads to a complete cessation of\ntrading activity, highlighting the sensitivity of market dynamics to agents'\nrisk profiles; third, we show that incorporating human-like variability shifts\npower dynamics towards clients and can disproportionately affect the entire\nsystem, often resulting in systemic agent collapse across simulations. These\nfindings underscore the emergent properties that arise when introducing\nstochastic, human-like decision processes, revealing new system behaviors that\nenhance the realism and complexity of artificial societies.",
    "categories": [
      "q-fin.TR",
      "cs.AI",
      "cs.MA"
    ],
    "primary_category": "q-fin.TR",
    "comment": "9 pages",
    "pdf_url": "http://arxiv.org/pdf/2503.00320v2",
    "published_date": "2025-03-01 03:15:13 UTC",
    "updated_date": "2025-03-04 16:36:54 UTC"
  },
  {
    "arxiv_id": "2503.00309v1",
    "title": "Pseudo-Knowledge Graph: Meta-Path Guided Retrieval and In-Graph Text for RAG-Equipped LLM",
    "authors": [
      "Yuxin Yang",
      "Haoyang Wu",
      "Tao Wang",
      "Jia Yang",
      "Hao Ma",
      "Guojie Luo"
    ],
    "abstract": "The advent of Large Language Models (LLMs) has revolutionized natural\nlanguage processing. However, these models face challenges in retrieving\nprecise information from vast datasets. Retrieval-Augmented Generation (RAG)\nwas developed to combining LLMs with external information retrieval systems to\nenhance the accuracy and context of responses. Despite improvements, RAG still\nstruggles with comprehensive retrieval in high-volume, low-information-density\ndatabases and lacks relational awareness, leading to fragmented answers.\n  To address this, this paper introduces the Pseudo-Knowledge Graph (PKG)\nframework, designed to overcome these limitations by integrating Meta-path\nRetrieval, In-graph Text and Vector Retrieval into LLMs. By preserving natural\nlanguage text and leveraging various retrieval techniques, the PKG offers a\nricher knowledge representation and improves accuracy in information retrieval.\nExtensive evaluations using Open Compass and MultiHop-RAG benchmarks\ndemonstrate the framework's effectiveness in managing large volumes of data and\ncomplex relationships.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00309v1",
    "published_date": "2025-03-01 02:39:37 UTC",
    "updated_date": "2025-03-01 02:39:37 UTC"
  },
  {
    "arxiv_id": "2503.00299v1",
    "title": "Hidden Convexity of Fair PCA and Fast Solver via Eigenvalue Optimization",
    "authors": [
      "Junhui Shen",
      "Aaron J. Davis",
      "Ding Lu",
      "Zhaojun Bai"
    ],
    "abstract": "Principal Component Analysis (PCA) is a foundational technique in machine\nlearning for dimensionality reduction of high-dimensional datasets. However,\nPCA could lead to biased outcomes that disadvantage certain subgroups of the\nunderlying datasets. To address the bias issue, a Fair PCA (FPCA) model was\nintroduced by Samadi et al. (2018) for equalizing the reconstruction loss\nbetween subgroups. The semidefinite relaxation (SDR) based approach proposed by\nSamadi et al. (2018) is computationally expensive even for suboptimal\nsolutions. To improve efficiency, several alternative variants of the FPCA\nmodel have been developed. These variants often shift the focus away from\nequalizing the reconstruction loss. In this paper, we identify a hidden\nconvexity in the FPCA model and introduce an algorithm for convex optimization\nvia eigenvalue optimization. Our approach achieves the desired fairness in\nreconstruction loss without sacrificing performance. As demonstrated in\nreal-world datasets, the proposed FPCA algorithm runs $8\\times$ faster than the\nSDR-based algorithm, and only at most 85% slower than the standard PCA.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00299v1",
    "published_date": "2025-03-01 02:13:20 UTC",
    "updated_date": "2025-03-01 02:13:20 UTC"
  },
  {
    "arxiv_id": "2503.00286v1",
    "title": "A Unified Framework for Heterogeneous Semi-supervised Learning",
    "authors": [
      "Marzi Heidari",
      "Abdullah Alchihabi",
      "Hao Yan",
      "Yuhong Guo"
    ],
    "abstract": "In this work, we introduce a novel problem setup termed as Heterogeneous\nSemi-Supervised Learning (HSSL), which presents unique challenges by bridging\nthe semi-supervised learning (SSL) task and the unsupervised domain adaptation\n(UDA) task, and expanding standard semi-supervised learning to cope with\nheterogeneous training data. At its core, HSSL aims to learn a prediction model\nusing a combination of labeled and unlabeled training data drawn separately\nfrom heterogeneous domains that share a common set of semantic categories; this\nmodel is intended to differentiate the semantic categories of test instances\nsampled from both the labeled and unlabeled domains. In particular, the labeled\nand unlabeled domains have dissimilar label distributions and class feature\ndistributions. This heterogeneity, coupled with the assorted sources of the\ntest data, introduces significant challenges to standard SSL and UDA methods.\nTherefore, we propose a novel method, Unified Framework for Heterogeneous\nSemi-supervised Learning (Uni-HSSL), to address HSSL by directly learning a\nfine-grained classifier from the heterogeneous data, which adaptively handles\nthe inter-domain heterogeneity while leveraging both the unlabeled data and the\ninter-domain semantic class relationships for cross-domain knowledge transfer\nand adaptation. We conduct comprehensive experiments and the experimental\nresults validate the efficacy and superior performance of the proposed Uni-HSSL\nover state-of-the-art semi-supervised learning and unsupervised domain\nadaptation methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00286v1",
    "published_date": "2025-03-01 01:32:02 UTC",
    "updated_date": "2025-03-01 01:32:02 UTC"
  },
  {
    "arxiv_id": "2503.00269v1",
    "title": "Reducing Large Language Model Safety Risks in Women's Health using Semantic Entropy",
    "authors": [
      "Jahan C. Penny-Dimri",
      "Magdalena Bachmann",
      "William R. Cooke",
      "Sam Mathewlynn",
      "Samuel Dockree",
      "John Tolladay",
      "Jannik Kossen",
      "Lin Li",
      "Yarin Gal",
      "Gabriel Davis Jones"
    ],
    "abstract": "Large language models (LLMs) hold substantial promise for clinical decision\nsupport. However, their widespread adoption in medicine, particularly in\nhealthcare, is hindered by their propensity to generate false or misleading\noutputs, known as hallucinations. In high-stakes domains such as women's health\n(obstetrics & gynaecology), where errors in clinical reasoning can have\nprofound consequences for maternal and neonatal outcomes, ensuring the\nreliability of AI-generated responses is critical. Traditional methods for\nquantifying uncertainty, such as perplexity, fail to capture meaning-level\ninconsistencies that lead to misinformation. Here, we evaluate semantic entropy\n(SE), a novel uncertainty metric that assesses meaning-level variation, to\ndetect hallucinations in AI-generated medical content. Using a clinically\nvalidated dataset derived from UK RCOG MRCOG examinations, we compared SE with\nperplexity in identifying uncertain responses. SE demonstrated superior\nperformance, achieving an AUROC of 0.76 (95% CI: 0.75-0.78), compared to 0.62\n(0.60-0.65) for perplexity. Clinical expert validation further confirmed its\neffectiveness, with SE achieving near-perfect uncertainty discrimination\n(AUROC: 0.97). While semantic clustering was successful in only 30% of cases,\nSE remains a valuable tool for improving AI safety in women's health. These\nfindings suggest that SE could enable more reliable AI integration into\nclinical practice, particularly in resource-limited settings where LLMs could\naugment care. This study highlights the potential of SE as a key safeguard in\nthe responsible deployment of AI-driven tools in women's health, leading to\nsafer and more effective digital health interventions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2503.00269v1",
    "published_date": "2025-03-01 00:57:52 UTC",
    "updated_date": "2025-03-01 00:57:52 UTC"
  },
  {
    "arxiv_id": "2503.00268v1",
    "title": "Input Specific Neural Networks",
    "authors": [
      "Asghar A. Jadoon",
      "D. Thomas Seidl",
      "Reese E. Jones",
      "Jan N. Fuhg"
    ],
    "abstract": "The black-box nature of neural networks limits the ability to encode or\nimpose specific structural relationships between inputs and outputs. While\nvarious studies have introduced architectures that ensure the network's output\nadheres to a particular form in relation to certain inputs, the majority of\nthese approaches impose constraints on only a single set of inputs. This paper\nintroduces a novel neural network architecture, termed the Input Specific\nNeural Network (ISNN), which extends this concept by allowing scalar-valued\noutputs to be subject to multiple constraints. Specifically, the ISNN can\nenforce convexity in some inputs, non-decreasing monotonicity combined with\nconvexity with respect to others, and simple non-decreasing monotonicity or\narbitrary relationships with additional inputs. The paper presents two distinct\nISNN architectures, along with equations for the first and second derivatives\nof the output with respect to the inputs. These networks are broadly\napplicable.\n  In this work, we restrict their usage to solving problems in computational\nmechanics. In particular, we show how they can be effectively applied to\nfitting data-driven constitutive models. We then embed our trained data-driven\nconstitutive laws into a finite element solver where significant time savings\ncan be achieved by using explicit manual differentiation using the derived\nequations as opposed to automatic differentiation. We also show how ISNNs can\nbe used to learn structural relationships between inputs and outputs via a\nbinary gating mechanism. Particularly, ISNNs are employed to model an\nanisotropic free energy potential to get the homogenized macroscopic response\nin a decoupled multiscale setting, where the network learns whether or not the\npotential should be modeled as polyconvex, and retains only the relevant layers\nwhile using the minimum number of inputs.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.00268v1",
    "published_date": "2025-03-01 00:57:16 UTC",
    "updated_date": "2025-03-01 00:57:16 UTC"
  },
  {
    "arxiv_id": "2503.05793v1",
    "title": "MedSimAI: Simulation and Formative Feedback Generation to Enhance Deliberate Practice in Medical Education",
    "authors": [
      "Yann Hicke",
      "Jadon Geathers",
      "Niroop Rajashekar",
      "Colleen Chan",
      "Anyanate Gwendolyne Jack",
      "Justin Sewell",
      "Mackenzi Preston",
      "Susannah Cornes",
      "Dennis Shung",
      "Rene Kizilcec"
    ],
    "abstract": "Medical education faces challenges in scalability, accessibility, and\nconsistency, particularly in clinical skills training for physician-patient\ncommunication. Traditional simulation-based learning, while effective, is\nresource-intensive, difficult to schedule, and often highly variable in\nfeedback quality. Through a collaboration between AI, learning science, and\nmedical education experts, we co-developed MedSimAI, an AI-powered simulation\nplatform that enables deliberate practice, self-regulated learning (SRL), and\nautomated assessment through interactive patient encounters. Leveraging large\nlanguage models (LLMs), MedSimAI generates realistic clinical interactions and\nprovides immediate, structured feedback using established medical evaluation\nframeworks such as the Master Interview Rating Scale (MIRS). In a pilot study\nwith 104 first-year medical students, we examined engagement, conversation\npatterns, and user perceptions. Students found MedSimAI beneficial for\nrepeated, realistic patient-history practice. Conversation analysis revealed\nthat certain higher-order skills were often overlooked, though students\ngenerally performed systematic histories and empathic listening. By integrating\nunlimited practice opportunities, real-time AI assessment, and SRL principles,\nMedSimAI addresses key limitations of traditional simulation-based training,\nmaking high-quality clinical education more accessible and scalable.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.05793v1",
    "published_date": "2025-03-01 00:51:55 UTC",
    "updated_date": "2025-03-01 00:51:55 UTC"
  },
  {
    "arxiv_id": "2503.00258v1",
    "title": "Decoupling Content and Expression: Two-Dimensional Detection of AI-Generated Text",
    "authors": [
      "Guangsheng Bao",
      "Lihua Rong",
      "Yanbin Zhao",
      "Qiji Zhou",
      "Yue Zhang"
    ],
    "abstract": "The wide usage of LLMs raises critical requirements on detecting AI\nparticipation in texts. Existing studies investigate these detections in\nscattered contexts, leaving a systematic and unified approach unexplored. In\nthis paper, we present HART, a hierarchical framework of AI risk levels, each\ncorresponding to a detection task. To address these tasks, we propose a novel\n2D Detection Method, decoupling a text into content and language expression.\nOur findings show that content is resistant to surface-level changes, which can\nserve as a key feature for detection. Experiments demonstrate that 2D method\nsignificantly outperforms existing detectors, achieving an AUROC improvement\nfrom 0.705 to 0.849 for level-2 detection and from 0.807 to 0.886 for RAID. We\nrelease our data and code at https://github.com/baoguangsheng/truth-mirror.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "8 pages, 8 tables, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2503.00258v1",
    "published_date": "2025-03-01 00:19:13 UTC",
    "updated_date": "2025-03-01 00:19:13 UTC"
  }
]