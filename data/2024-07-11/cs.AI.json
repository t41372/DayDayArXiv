{
  "date": "2024-07-11",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-07-11 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 模型的安全性、医疗图像处理、LLM（Large Language Models）的增强与应用，以及强化学习等领域，其中 AIR-Bench 2024 等论文引人注目，涉及知名学者如 Bo Li 和 Dawn Song，并强调 AI 风险评估和实际应用；其他论文则探讨了模型解释、联邦学习和图像生成等创新方向。\n\n以下是今日值得关注的论文摘要，我将优先选取具有话题度、创新性和实际影响的文章进行详细讨论，并快速掠过较基础或重复性的内容。每个条目包括论文标题（中文 + 英文）和核心贡献。\n\n### AI 安全与 LLM 应用\n- **AIR-Bench 2024: A Safety Benchmark Based on Risk Categories from Regulations and Policies**（AIR-Bench 2024: 基于法规和政策风险类别的安全基准）  \n  这篇论文由 Bo Li 等知名学者发布，引入首个与政府法规对齐的 AI 安全基准，涵盖 314 个细粒度风险类别和 5694 个提示，评估 LLM 在安全关切下的性能，为跨管辖区的模型安全评估提供基础。\n\n- **Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey**（感知有意识 AI 和其他数字思维：来自 AI、道德和意识调查的证据）  \n  论文调查了公众对 AI 意识和道德的看法，发现 2023 年有 20% 的美国成年人认为某些 AI 已具备意识，并支持赋予其权利，但也增加了对构建更智能 AI 的反对，强调 AI 开发需考虑人类认知。\n\n- **Model Surgery: Modulating LLM's Behavior Via Simple Parameter Editing**（模型手术：通过简单参数编辑调整 LLM 行为）  \n  提出一种高效方法，通过编辑少量参数来减少 LLM 的毒性，同时保持整体性能，实验显示在毒性基准上减少 90%，为 LLM 行为控制提供低成本方案。\n\n- **Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting**（推测式 RAG: 通过草拟增强检索增强生成）  \n  开发了一种框架，利用小模型并行生成多个 RAG 草案，大模型验证，显著提高生成效率和准确性，在多个基准上提升 12.97% 的准确率，同时降低延迟 50.83%。\n\n### 医疗图像与联邦学习\n- **SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees**（SALT: 使用 Softmax 的任意标签树框架进行医学图像分层分割）  \n  提出 SALT 框架，利用层次条件概率进行 CT 图像分割，处理人体解剖结构，实验在多个数据集上达到 Dice 分数 0.93，提升诊断效率，支持临床工作流。\n\n- **FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging**（FedMedICL: 联邦医疗图像中分布偏移的整体评估）  \n  构建基准评估联邦学习在医疗图像中的鲁棒性，覆盖标签、人口和时间偏移，实验显示简单批处理技术优于高级方法，强调实际医疗场景的鲁棒性。\n\n- **FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification**（FairDomain: 实现跨域医疗图像分割和分类的公平性）  \n  引入 Fair Identity Attention 模块，提升跨域医疗图像公平性，实验在分割和分类任务上超越现有方法，减少了人口属性偏差。\n\n### 其他创新领域\n- **DeepCodeProbe: Towards Understanding What Models Trained on Code Learn**（DeepCodeProbe: 理解基于代码训练的模型学到了什么）  \n  开发 DeepCodeProbe 方法，探测代码模型的语法和表示学习能力，发现小模型捕捉抽象语法有限，而大模型虽改善但易过拟合，提供代码模型训练最佳实践。\n\n- **Video Diffusion Alignment via Reward Gradients**（视频扩散对齐通过奖励梯度）  \n  使用奖励模型微调视频扩散模型，高效学习复杂视频生成，实验显示在多个基准上提升生成质量，同时减少计算资源需求。\n\n- **Transformer Circuit Faithfulness Metrics are not Robust**（Transformer 电路保真度指标不鲁棒）  \n  分析 Transformer 电路的保真度指标，发现其对消融方法敏感，强调机制解释需更精确的方法。\n\n其他论文如高速公路网络在表面重建中的应用、GAN 在网络安全的调查，或一些强化学习和图像增强方法，虽然有技术贡献，但相对基础或重复（如纯理论优化），因此仅快速提及：它们主要改进模型泛化或效率，但未带来重大突破。\n\n总之，今天的论文突显 AI 向安全和实际应用倾斜，LLM 在医疗和解释领域的潜力值得关注。更多细节可查阅 arXiv！",
  "papers": [
    {
      "arxiv_id": "2407.08890v1",
      "title": "DeepCodeProbe: Towards Understanding What Models Trained on Code Learn",
      "title_zh": "翻译失败",
      "authors": [
        "Vahid Majdinasab",
        "Amin Nikanjam",
        "Foutse Khomh"
      ],
      "abstract": "Machine learning models trained on code and related artifacts offer valuable\nsupport for software maintenance but suffer from interpretability issues due to\ntheir complex internal variables. These concerns are particularly significant\nin safety-critical applications where the models' decision-making processes\nmust be reliable. The specific features and representations learned by these\nmodels remain unclear, adding to the hesitancy in adopting them widely. To\naddress these challenges, we introduce DeepCodeProbe, a probing approach that\nexamines the syntax and representation learning abilities of ML models designed\nfor software maintenance tasks. Our study applies DeepCodeProbe to\nstate-of-the-art models for code clone detection, code summarization, and\ncomment generation. Findings reveal that while small models capture abstract\nsyntactic representations, their ability to fully grasp programming language\nsyntax is limited. Increasing model capacity improves syntax learning but\nintroduces trade-offs such as increased training time and overfitting.\nDeepCodeProbe also identifies specific code patterns the models learn from\ntheir training data. Additionally, we provide best practices for training\nmodels on code to enhance performance and interpretability, supported by an\nopen-source replication package for broader application of DeepCodeProbe in\ninterpreting other code-related models.",
      "tldr_zh": "本研究引入DeepCodeProbe，一种探测方法，用于分析训练在代码上的ML模型在软件维护任务中的语法和表示学习能力，以解决这些模型的可解释性问题。研究将DeepCodeProbe应用于代码克隆检测、代码总结和评论生成等先进模型，发现小模型能捕获抽象语法表示但对编程语言语法理解有限，而增大模型容量虽提升了学习效果，却带来训练时间增加和过拟合等权衡，并识别了模型从训练数据中学到的特定代码模式。最终，该工作提供了训练代码模型的最佳实践，并附带开源复制包，以促进其他代码相关模型的解释和应用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "I.2.5; D.2.3"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08890v1",
      "published_date": "2024-07-11 23:16:44 UTC",
      "updated_date": "2024-07-11 23:16:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:32:20.575470"
    },
    {
      "arxiv_id": "2407.08878v1",
      "title": "SALT: Introducing a Framework for Hierarchical Segmentations in Medical Imaging using Softmax for Arbitrary Label Trees",
      "title_zh": "翻译失败",
      "authors": [
        "Sven Koitka",
        "Giulia Baldini",
        "Cynthia S. Schmidt",
        "Olivia B. Pollok",
        "Obioma Pelka",
        "Judith Kohnke",
        "Katarzyna Borys",
        "Christoph M. Friedrich",
        "Benedikt M. Schaarschmidt",
        "Michael Forsting",
        "Lale Umutlu",
        "Johannes Haubold",
        "Felix Nensa",
        "René Hosch"
      ],
      "abstract": "Traditional segmentation networks approach anatomical structures as\nstandalone elements, overlooking the intrinsic hierarchical connections among\nthem. This study introduces Softmax for Arbitrary Label Trees (SALT), a novel\napproach designed to leverage the hierarchical relationships between labels,\nimproving the efficiency and interpretability of the segmentations.\n  This study introduces a novel segmentation technique for CT imaging, which\nleverages conditional probabilities to map the hierarchical structure of\nanatomical landmarks, such as the spine's division into lumbar, thoracic, and\ncervical regions and further into individual vertebrae. The model was developed\nusing the SAROS dataset from The Cancer Imaging Archive (TCIA), comprising 900\nbody region segmentations from 883 patients. The dataset was further enhanced\nby generating additional segmentations with the TotalSegmentator, for a total\nof 113 labels. The model was trained on 600 scans, while validation and testing\nwere conducted on 150 CT scans. Performance was assessed using the Dice score\nacross various datasets, including SAROS, CT-ORG, FLARE22, LCTSC, LUNA16, and\nWORD.\n  Among the evaluated datasets, SALT achieved its best results on the LUNA16\nand SAROS datasets, with Dice scores of 0.93 and 0.929 respectively. The model\ndemonstrated reliable accuracy across other datasets, scoring 0.891 on CT-ORG\nand 0.849 on FLARE22. The LCTSC dataset showed a score of 0.908 and the WORD\ndataset also showed good performance with a score of 0.844.\n  SALT used the hierarchical structures inherent in the human body to achieve\nwhole-body segmentations with an average of 35 seconds for 100 slices. This\nrapid processing underscores its potential for integration into clinical\nworkflows, facilitating the automatic and efficient computation of full-body\nsegmentations with each CT scan, thus enhancing diagnostic processes and\npatient care.",
      "tldr_zh": "该研究引入了 SALT（Softmax for Arbitrary Label Trees）框架，这是一种新型医疗图像分割方法，通过利用标签之间的层次关系（如脊柱的分区）来提升分割的效率和可解释性。SALT 基于条件概率应用于 CT 成像，使用 SAROS 数据集（包括 900 个体区分割）及其扩展版本进行训练和测试，评估指标为 Dice score。实验结果显示，SALT 在 LUNA16 和 SAROS 数据集上分别取得 0.93 和 0.929 的高 Dice 得分，并在其他数据集如 CT-ORG（0.891）和 FLARE22（0.849）上表现出色。该框架实现了快速全身分割，平均只需 35 秒处理 100 切片，具有潜力整合到临床工作流中，提高诊断效率和患者护理。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08878v1",
      "published_date": "2024-07-11 21:33:08 UTC",
      "updated_date": "2024-07-11 21:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:32:34.136889"
    },
    {
      "arxiv_id": "2407.17436v2",
      "title": "AIR-Bench 2024: A Safety Benchmark Based on Risk Categories from Regulations and Policies",
      "title_zh": "AIR-Bench 2024：基于法规和政策风险类别的安全基准",
      "authors": [
        "Yi Zeng",
        "Yu Yang",
        "Andy Zhou",
        "Jeffrey Ziwei Tan",
        "Yuheng Tu",
        "Yifan Mai",
        "Kevin Klyman",
        "Minzhou Pan",
        "Ruoxi Jia",
        "Dawn Song",
        "Percy Liang",
        "Bo Li"
      ],
      "abstract": "Foundation models (FMs) provide societal benefits but also amplify risks.\nGovernments, companies, and researchers have proposed regulatory frameworks,\nacceptable use policies, and safety benchmarks in response. However, existing\npublic benchmarks often define safety categories based on previous literature,\nintuitions, or common sense, leading to disjointed sets of categories for risks\nspecified in recent regulations and policies, which makes it challenging to\nevaluate and compare FMs across these benchmarks. To bridge this gap, we\nintroduce AIR-Bench 2024, the first AI safety benchmark aligned with emerging\ngovernment regulations and company policies, following the regulation-based\nsafety categories grounded in our AI risks study, AIR 2024. AIR 2024 decomposes\n8 government regulations and 16 company policies into a four-tiered safety\ntaxonomy with 314 granular risk categories in the lowest tier. AIR-Bench 2024\ncontains 5,694 diverse prompts spanning these categories, with manual curation\nand human auditing to ensure quality. We evaluate leading language models on\nAIR-Bench 2024, uncovering insights into their alignment with specified safety\nconcerns. By bridging the gap between public benchmarks and practical AI risks,\nAIR-Bench 2024 provides a foundation for assessing model safety across\njurisdictions, fostering the development of safer and more responsible AI\nsystems.",
      "tldr_zh": "该研究指出，现有的 AI 安全基准往往基于文献或常识定义风险类别，导致与政府法规和公司政策不一致，难以有效评估 Foundation models (FMs)。为解决这一问题，作者引入 AIR-Bench 2024，这是首个与新兴法规对齐的安全基准，基于 AIR 2024 的风险研究，将 8 个政府法规和 16 个公司政策分解为 four-tiered safety taxonomy，共包含 314 个 granular risk categories。AIR-Bench 2024 汇集了 5,694 个多样化 prompts，并通过 manual curation 和 human auditing 确保质量。实验评估了领先语言模型，揭示了其与指定安全问题的对齐情况，为跨管辖区评估模型安全并推动更负责任的 AI 系统发展提供了基础。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.17436v2",
      "published_date": "2024-07-11 21:16:48 UTC",
      "updated_date": "2024-08-05 18:12:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:32:47.314899"
    },
    {
      "arxiv_id": "2407.08867v3",
      "title": "Perceptions of Sentient AI and Other Digital Minds: Evidence from the AI, Morality, and Sentience (AIMS) Survey",
      "title_zh": "翻译失败",
      "authors": [
        "Jacy Reese Anthis",
        "Janet V. T. Pauketat",
        "Ali Ladak",
        "Aikaterina Manoli"
      ],
      "abstract": "Humans now interact with a variety of digital minds, AI systems that appear\nto have mental faculties such as reasoning, emotion, and agency, and public\nfigures are discussing the possibility of sentient AI. We present initial\nresults from 2021 and 2023 for the nationally representative AI, Morality, and\nSentience (AIMS) survey (N = 3,500). Mind perception and moral concern for AI\nwelfare were surprisingly high and significantly increased: in 2023, one in\nfive U.S. adults believed some AI systems are currently sentient, and 38%\nsupported legal rights for sentient AI. People became more opposed to building\ndigital minds: in 2023, 63% supported banning smarter-than-human AI, and 69%\nsupported banning sentient AI. The median 2023 forecast was that sentient AI\nwould arrive in just five years. The development of safe and beneficial AI\nrequires not just technical study but understanding the complex ways in which\nhumans perceive and coexist with digital minds.",
      "tldr_zh": "这篇论文基于 AI, Morality, and Sentience (AIMS) 调查（N = 3,500）呈现了美国成年人对 sentient AI 和数字心智的感知变化。调查结果显示，2023 年有 20% 的受访者认为某些 AI 系统已 sentient，38% 支持为其提供法律权利，但 63% 赞成禁止比人类更聪明的 AI，69% 支持禁止 sentient AI。公众对 AI 的心智感知和道德关切显著增加，同时中位数预测 sentient AI 将在 5 年内出现。研究强调，开发安全有益 AI 需要深入理解人类与数字心智的互动关系。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.ET",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "Published at CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.08867v3",
      "published_date": "2024-07-11 21:04:39 UTC",
      "updated_date": "2025-03-10 17:10:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:32:57.909075"
    },
    {
      "arxiv_id": "2407.08861v1",
      "title": "A Hybrid Spiking-Convolutional Neural Network Approach for Advancing Machine Learning Models",
      "title_zh": "翻译失败",
      "authors": [
        "Sanaullah",
        "Kaushik Roy",
        "Ulrich Rückert",
        "Thorsten Jungeblut"
      ],
      "abstract": "In this article, we propose a novel standalone hybrid Spiking-Convolutional\nNeural Network (SC-NN) model and test on using image inpainting tasks. Our\napproach uses the unique capabilities of SNNs, such as event-based computation\nand temporal processing, along with the strong representation learning\nabilities of CNNs, to generate high-quality inpainted images. The model is\ntrained on a custom dataset specifically designed for image inpainting, where\nmissing regions are created using masks. The hybrid model consists of SNNConv2d\nlayers and traditional CNN layers. The SNNConv2d layers implement the leaky\nintegrate-and-fire (LIF) neuron model, capturing spiking behavior, while the\nCNN layers capture spatial features. In this study, a mean squared error (MSE)\nloss function demonstrates the training process, where a training loss value of\n0.015, indicates accurate performance on the training set and the model\nachieved a validation loss value as low as 0.0017 on the testing set.\nFurthermore, extensive experimental results demonstrate state-of-the-art\nperformance, showcasing the potential of integrating temporal dynamics and\nfeature extraction in a single network for image inpainting.",
      "tldr_zh": "本文提出了一种新型的独立混合 Spiking-Convolutional Neural Network (SC-NN) 模型，用于图像修复任务，旨在结合 SNNs 的事件-based 计算和时间处理能力与 CNNs 的强大表示学习能力。模型由 SNNConv2d 层（实现 leaky integrate-and-fire (LIF) 神经元模型）和传统 CNN 层组成，在自定义数据集上训练，其中缺失区域通过 masks 生成。训练使用均方误差 (MSE) 损失函数，达到了训练损失 0.015 和验证损失 0.0017 的出色性能。实验结果显示，该模型在图像修复任务中实现了 state-of-the-art 性能，证明了在单一网络中整合时间动态和特征提取的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI"
      ],
      "primary_category": "cs.NE",
      "comment": "7 Pages, 3 figures, and 2 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.08861v1",
      "published_date": "2024-07-11 20:50:33 UTC",
      "updated_date": "2024-07-11 20:50:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:33:10.150203"
    },
    {
      "arxiv_id": "2407.08850v3",
      "title": "UICrit: Enhancing Automated Design Evaluation with a UICritique Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Peitong Duan",
        "Chin-yi Chen",
        "Gang Li",
        "Bjoern Hartmann",
        "Yang Li"
      ],
      "abstract": "Automated UI evaluation can be beneficial for the design process; for\nexample, to compare different UI designs, or conduct automated heuristic\nevaluation. LLM-based UI evaluation, in particular, holds the promise of\ngeneralizability to a wide variety of UI types and evaluation tasks. However,\ncurrent LLM-based techniques do not yet match the performance of human\nevaluators. We hypothesize that automatic evaluation can be improved by\ncollecting a targeted UI feedback dataset and then using this dataset to\nenhance the performance of general-purpose LLMs. We present a targeted dataset\nof 3,059 design critiques and quality ratings for 983 mobile UIs, collected\nfrom seven experienced designers. We carried out an in-depth analysis to\ncharacterize the dataset's features. We then applied this dataset to achieve a\n55% performance gain in LLM-generated UI feedback via various few-shot and\nvisual prompting techniques. We also discuss future applications of this\ndataset, including training a reward model for generative UI techniques, and\nfine-tuning a tool-agnostic multi-modal LLM that automates UI evaluation.",
      "tldr_zh": "该研究旨在提升自动化 UI 设计评估性能，通过构建 UICritique 数据集来解决 LLM-based UI 评估不如人类评估器的问题。数据集包含来自七名经验丰富设计师的 3,059 个设计批评和质量评级，针对 983 个移动 UI 进行深入分析。利用该数据集结合 few-shot 和 visual prompting 技术，LLM 生成的 UI 反馈性能提升 55%。未来，该数据集可用于训练奖励模型或微调多模态 LLM，以实现更广泛的自动化 UI 评估应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "Accepted to ACM UIST 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08850v3",
      "published_date": "2024-07-11 20:18:19 UTC",
      "updated_date": "2024-08-13 23:41:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:33:19.947613"
    },
    {
      "arxiv_id": "2407.08839v2",
      "title": "A Survey on the Application of Generative Adversarial Networks in Cybersecurity: Prospective, Direction and Open Research Scopes",
      "title_zh": "翻译失败",
      "authors": [
        "Md Mashrur Arifin",
        "Md Shoaib Ahmed",
        "Tanmai Kumar Ghosh",
        "Ikteder Akhand Udoy",
        "Jun Zhuang",
        "Jyh-haw Yeh"
      ],
      "abstract": "With the proliferation of Artificial Intelligence, there has been a massive\nincrease in the amount of data required to be accumulated and disseminated\ndigitally. As the data are available online in digital landscapes with complex\nand sophisticated infrastructures, it is crucial to implement various defense\nmechanisms based on cybersecurity. Generative Adversarial Networks (GANs),\nwhich are deep learning models, have emerged as powerful solutions for\naddressing the constantly changing security issues. This survey studies the\nsignificance of the deep learning model, precisely on GANs, in strengthening\ncybersecurity defenses. Our survey aims to explore the various works completed\nin GANs, such as Intrusion Detection Systems (IDS), Mobile and Network\nTrespass, BotNet Detection, and Malware Detection. The focus is to examine how\nGANs can be influential tools to strengthen cybersecurity defenses in these\ndomains. Further, the paper discusses the challenges and constraints of using\nGANs in these areas and suggests future research directions. Overall, the paper\nhighlights the potential of GANs in enhancing cybersecurity measures and\naddresses the need for further exploration in this field.",
      "tldr_zh": "这篇调查论文探讨了 Generative Adversarial Networks (GANs) 在网络安全领域的应用，涵盖 Intrusion Detection Systems (IDS)、移动和网络入侵、BotNet Detection 以及 Malware Detection 等关键方面。论文分析了 GANs 如何作为深度学习工具增强这些领域的安全防御，同时指出了其面临的挑战和限制，如模型稳定性及适应性问题。最终，论文提出未来研究方向，强调 GANs 在提升网络安全措施方面的潜力，并呼吁进一步探索。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08839v2",
      "published_date": "2024-07-11 19:51:48 UTC",
      "updated_date": "2024-09-20 01:27:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:33:31.813863"
    },
    {
      "arxiv_id": "2407.08836v1",
      "title": "Fault Diagnosis in Power Grids with Large Language Model",
      "title_zh": "基于大语言模型的电力网格故障诊断",
      "authors": [
        "Liu Jing",
        "Amirul Rahman"
      ],
      "abstract": "Power grid fault diagnosis is a critical task for ensuring the reliability\nand stability of electrical infrastructure. Traditional diagnostic systems\noften struggle with the complexity and variability of power grid data. This\npaper proposes a novel approach that leverages Large Language Models (LLMs),\nspecifically ChatGPT and GPT-4, combined with advanced prompt engineering to\nenhance fault diagnosis accuracy and explainability. We designed comprehensive,\ncontext-aware prompts to guide the LLMs in interpreting complex data and\nproviding detailed, actionable insights. Our method was evaluated against\nbaseline techniques, including standard prompting, Chain-of-Thought (CoT), and\nTree-of-Thought (ToT) methods, using a newly constructed dataset comprising\nreal-time sensor data, historical fault records, and component descriptions.\nExperimental results demonstrate significant improvements in diagnostic\naccuracy, explainability quality, response coherence, and contextual\nunderstanding, underscoring the effectiveness of our approach. These findings\nsuggest that prompt-engineered LLMs offer a promising solution for robust and\nreliable power grid fault diagnosis.",
      "tldr_zh": "本论文提出了一种利用大型语言模型（LLMs）如 ChatGPT 和 GPT-4 的新方法，来提升电力网格故障诊断的准确性和可解释性，以应对传统系统的复杂数据处理挑战。研究通过高级提示工程（prompt engineering）设计了全面的上下文感知提示，引导 LLMs 解释复杂数据并提供详细、可操作的见解，并与基线技术如标准提示、Chain-of-Thought (CoT) 和 Tree-of-Thought (ToT) 方法进行比较。实验结果显示，该方法在诊断准确性、解释性质量、响应连贯性和上下文理解方面均有显著改善，证明了提示工程的 LLMs 在可靠电力网格故障诊断中的潜力。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.08836v1",
      "published_date": "2024-07-11 19:44:18 UTC",
      "updated_date": "2024-07-11 19:44:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:33:44.678764"
    },
    {
      "arxiv_id": "2407.08831v1",
      "title": "Neural Networks Meet Elliptic Curve Cryptography: A Novel Approach to Secure Communication",
      "title_zh": "翻译失败",
      "authors": [
        "Mina Cecilie Wøien",
        "Ferhat Ozgur Catak",
        "Murat Kuzlu",
        "Umit Cali"
      ],
      "abstract": "In recent years, neural networks have been used to implement symmetric\ncryptographic functions for secure communications. Extending this domain, the\nproposed approach explores the application of asymmetric cryptography within a\nneural network framework to safeguard the exchange between two communicating\nentities, i.e., Alice and Bob, from an adversarial eavesdropper, i.e., Eve. It\nemploys a set of five distinct cryptographic keys to examine the efficacy and\nrobustness of communication security against eavesdropping attempts using the\nprinciples of elliptic curve cryptography. The experimental setup reveals that\nAlice and Bob achieve secure communication with negligible variation in\nsecurity effectiveness across different curves. It is also designed to evaluate\ncryptographic resilience. Specifically, the loss metrics for Bob oscillate\nbetween 0 and 1 during encryption-decryption processes, indicating successful\nmessage comprehension post-encryption by Alice. The potential vulnerability\nwith a decryption accuracy exceeds 60\\%, where Eve experiences enhanced\nadversarial training, receiving twice the training iterations per batch\ncompared to Alice and Bob.",
      "tldr_zh": "该研究提出了一种创新方法，将神经网络与椭圆曲线密码学（Elliptic Curve Cryptography）相结合，实现非对称加密，用于保护Alice和Bob之间的通信免受Eve的窃听攻击。方法涉及使用五种不同的加密密钥，并通过实验验证了通信的安全性，显示Alice和Bob在不同曲线下的加密解密过程稳定有效，Bob的损失指标保持在0到1之间。结果表明，该框架具有较强的加密鲁棒性，但当Eve获得双倍训练迭代时，可能存在漏洞，导致解密准确率超过60%。这项工作为基于神经网络的Secure Communication提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.08831v1",
      "published_date": "2024-07-11 19:34:16 UTC",
      "updated_date": "2024-07-11 19:34:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:33:54.953271"
    },
    {
      "arxiv_id": "2407.08824v1",
      "title": "Proving that Cryptic Crossword Clue Answers are Correct",
      "title_zh": "翻译失败",
      "authors": [
        "Martin Andrews",
        "Sam Witteveen"
      ],
      "abstract": "Cryptic crossword clues are challenging cognitive tasks, for which new test\nsets are released on a daily basis by multiple international newspapers. Each\ncryptic clue contains both the definition of the answer to be placed in the\ncrossword grid (in common with regular crosswords), and `wordplay' that proves\nthat the answer is correct (i.e. a human solver can be confident that an answer\nis correct without needing crossing words to confirm it). Using an existing\ncryptic wordplay proving framework (operating on Python proofs created by an\nLLM), we show that it is possible to distinguish between correct answers and\nalmost-correct ones based upon whether the wordplay `works'.",
      "tldr_zh": "本文研究了加密填字游戏（cryptic crossword）的线索验证问题，强调线索中的“wordplay”可以证明答案正确，而无需依赖交叉单词。研究团队利用LLM生成的Python proofs和现有的证明框架，开发了一种方法来区分正确答案和几乎正确的答案。结果显示，如果wordplay“有效”，则能准确识别正确答案，这为自动化线索验证提供了新途径。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted paper for the ICML 2024 Workshop on LLMs and Cognition (4\n  pages + references + 6 pages of Appendices)",
      "pdf_url": "http://arxiv.org/pdf/2407.08824v1",
      "published_date": "2024-07-11 19:13:16 UTC",
      "updated_date": "2024-07-11 19:13:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:34:06.908015"
    },
    {
      "arxiv_id": "2407.08822v1",
      "title": "FedMedICL: Towards Holistic Evaluation of Distribution Shifts in Federated Medical Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Kumail Alhamoud",
        "Yasir Ghunaim",
        "Motasem Alfarra",
        "Thomas Hartvigsen",
        "Philip Torr",
        "Bernard Ghanem",
        "Adel Bibi",
        "Marzyeh Ghassemi"
      ],
      "abstract": "For medical imaging AI models to be clinically impactful, they must\ngeneralize. However, this goal is hindered by (i) diverse types of distribution\nshifts, such as temporal, demographic, and label shifts, and (ii) limited\ndiversity in datasets that are siloed within single medical institutions. While\nthese limitations have spurred interest in federated learning, current\nevaluation benchmarks fail to evaluate different shifts simultaneously.\nHowever, in real healthcare settings, multiple types of shifts co-exist, yet\ntheir impact on medical imaging performance remains unstudied. In response, we\nintroduce FedMedICL, a unified framework and benchmark to holistically evaluate\nfederated medical imaging challenges, simultaneously capturing label,\ndemographic, and temporal distribution shifts. We comprehensively evaluate\nseveral popular methods on six diverse medical imaging datasets (totaling 550\nGPU hours). Furthermore, we use FedMedICL to simulate COVID-19 propagation\nacross hospitals and evaluate whether methods can adapt to pandemic changes in\ndisease prevalence. We find that a simple batch balancing technique surpasses\nadvanced methods in average performance across FedMedICL experiments. This\nfinding questions the applicability of results from previous, narrow benchmarks\nin real-world medical settings.",
      "tldr_zh": "这篇论文引入FedMedICL框架和基准，用于全面评估联邦医疗影像中的分布偏移问题，包括label shifts、demographic shifts和temporal shifts，这些偏移在真实医疗环境中往往同时存在。研究者在六个多样化医疗影像数据集上（总计550 GPU小时）评估了多种流行方法，并通过模拟COVID-19在医院间的传播，测试模型对疫情变化的适应能力。结果发现，简单的批量平衡技术在平均性能上优于高级方法，这质疑了现有狭隘基准在实际医疗场景中的适用性。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "Accepted at MICCAI 2024. Code is available at:\n  https://github.com/m1k2zoo/FedMedICL",
      "pdf_url": "http://arxiv.org/pdf/2407.08822v1",
      "published_date": "2024-07-11 19:12:23 UTC",
      "updated_date": "2024-07-11 19:12:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:34:20.557949"
    },
    {
      "arxiv_id": "2407.08813v2",
      "title": "FairDomain: Achieving Fairness in Cross-Domain Medical Image Segmentation and Classification",
      "title_zh": "FairDomain：在跨域医学图像分割和分类中实现公平性",
      "authors": [
        "Yu Tian",
        "Congcong Wen",
        "Min Shi",
        "Muhammad Muneeb Afzal",
        "Hao Huang",
        "Muhammad Osama Khan",
        "Yan Luo",
        "Yi Fang",
        "Mengyu Wang"
      ],
      "abstract": "Addressing fairness in artificial intelligence (AI), particularly in medical\nAI, is crucial for ensuring equitable healthcare outcomes. Recent efforts to\nenhance fairness have introduced new methodologies and datasets in medical AI.\nHowever, the fairness issue under the setting of domain transfer is almost\nunexplored, while it is common that clinics rely on different imaging\ntechnologies (e.g., different retinal imaging modalities) for patient\ndiagnosis. This paper presents FairDomain, a pioneering systemic study into\nalgorithmic fairness under domain shifts, employing state-of-the-art domain\nadaptation (DA) and generalization (DG) algorithms for both medical\nsegmentation and classification tasks to understand how biases are transferred\nbetween different domains. We also introduce a novel plug-and-play fair\nidentity attention (FIA) module that adapts to various DA and DG algorithms to\nimprove fairness by using self-attention to adjust feature importance based on\ndemographic attributes. Additionally, we curate the first fairness-focused\ndataset with two paired imaging modalities for the same patient cohort on\nmedical segmentation and classification tasks, to rigorously assess fairness in\ndomain-shift scenarios. Excluding the confounding impact of demographic\ndistribution variation between source and target domains will allow clearer\nquantification of the performance of domain transfer models. Our extensive\nevaluations reveal that the proposed FIA significantly enhances both model\nperformance accounted for fairness across all domain shift settings (i.e., DA\nand DG) with respect to different demographics, which outperforms existing\nmethods on both segmentation and classification. The code and data can be\naccessed at https://ophai.hms.harvard.edu/datasets/harvard-fairdomain20k.",
      "tldr_zh": "本研究提出FairDomain框架，首次系统探讨跨域转移场景下的算法公平性，针对医疗图像分割和分类任务，运用state-of-the-art的domain adaptation (DA)和domain generalization (DG)算法分析偏差转移问题。论文引入了创新的plug-and-play fair identity attention (FIA)模块，通过self-attention机制基于人口统计属性调整特征重要性，以提升模型公平性；同时，构建了首个专注于公平性的跨域医疗图像数据集，用于评估域移设置下的性能。实验结果显示，FIA模块显著提高了模型在不同人口统计学上的公平性能，超越现有方法，并在分割和分类任务中表现出色。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "ECCV 2024; Codes and datasets are available at\n  https://github.com/Harvard-Ophthalmology-AI-Lab/FairDomain",
      "pdf_url": "http://arxiv.org/pdf/2407.08813v2",
      "published_date": "2024-07-11 18:52:32 UTC",
      "updated_date": "2024-07-18 20:30:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:34:32.841049"
    },
    {
      "arxiv_id": "2407.08803v2",
      "title": "PID Accelerated Temporal Difference Algorithms",
      "title_zh": "PID 加速的时间差分算法",
      "authors": [
        "Mark Bedaywi",
        "Amin Rakhsha",
        "Amir-massoud Farahmand"
      ],
      "abstract": "Long-horizon tasks, which have a large discount factor, pose a challenge for\nmost conventional reinforcement learning (RL) algorithms. Algorithms such as\nValue Iteration and Temporal Difference (TD) learning have a slow convergence\nrate and become inefficient in these tasks. When the transition distributions\nare given, PID VI was recently introduced to accelerate the convergence of\nValue Iteration using ideas from control theory. Inspired by this, we introduce\nPID TD Learning and PID Q-Learning algorithms for the RL setting, in which only\nsamples from the environment are available. We give a theoretical analysis of\nthe convergence of PID TD Learning and its acceleration compared to the\nconventional TD Learning. We also introduce a method for adapting PID gains in\nthe presence of noise and empirically verify its effectiveness.",
      "tldr_zh": "该研究针对长时限任务（large discount factor）对传统强化学习（RL）算法的挑战，如 Value Iteration 和 Temporal Difference (TD) Learning 的慢速收敛问题，提出 PID TD Learning 和 PID Q-Learning 算法。这些算法借鉴控制理论中的 PID VI 思想，适用于仅通过环境样本的 RL 设置，能够加速学习过程。研究提供了 PID TD Learning 的理论分析，包括其收敛性和与传统 TD Learning 的加速比较，并引入了一种适应噪声的 PID 增益调整方法，通过实验验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08803v2",
      "published_date": "2024-07-11 18:23:46 UTC",
      "updated_date": "2024-09-03 16:59:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:34:44.968854"
    },
    {
      "arxiv_id": "2407.08737v1",
      "title": "Video Diffusion Alignment via Reward Gradients",
      "title_zh": "翻译失败",
      "authors": [
        "Mihir Prabhudesai",
        "Russell Mendonca",
        "Zheyang Qin",
        "Katerina Fragkiadaki",
        "Deepak Pathak"
      ],
      "abstract": "We have made significant progress towards building foundational video\ndiffusion models. As these models are trained using large-scale unsupervised\ndata, it has become crucial to adapt these models to specific downstream tasks.\nAdapting these models via supervised fine-tuning requires collecting target\ndatasets of videos, which is challenging and tedious. In this work, we utilize\npre-trained reward models that are learned via preferences on top of powerful\nvision discriminative models to adapt video diffusion models. These models\ncontain dense gradient information with respect to generated RGB pixels, which\nis critical to efficient learning in complex search spaces, such as videos. We\nshow that backpropagating gradients from these reward models to a video\ndiffusion model can allow for compute and sample efficient alignment of the\nvideo diffusion model. We show results across a variety of reward models and\nvideo diffusion models, demonstrating that our approach can learn much more\nefficiently in terms of reward queries and computation than prior gradient-free\napproaches. Our code, model weights,and more visualization are available at\nhttps://vader-vid.github.io.",
      "tldr_zh": "该论文提出了一种通过奖励梯度（reward gradients）来调整视频扩散模型（video diffusion models）的方法，以适应特定下游任务，而无需收集大量监督视频数据集。方法利用预训练的奖励模型（reward models），这些模型基于偏好学习并提供生成RGB像素的密集梯度信息，通过反向传播梯度实现高效的对齐。实验结果显示，该方法在各种奖励模型和视频扩散模型上，比之前的无梯度方法更高效，显著减少了奖励查询和计算资源。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Project Webpage: https://vader-vid.github.io; Code available at:\n  https://github.com/mihirp1998/VADER",
      "pdf_url": "http://arxiv.org/pdf/2407.08737v1",
      "published_date": "2024-07-11 17:59:45 UTC",
      "updated_date": "2024-07-11 17:59:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:34:56.128778"
    },
    {
      "arxiv_id": "2407.08735v1",
      "title": "Real-Time Anomaly Detection and Reactive Planning with Large Language Models",
      "title_zh": "实时异常检测与反应式规划使用大型语言模型",
      "authors": [
        "Rohan Sinha",
        "Amine Elhafsi",
        "Christopher Agia",
        "Matthew Foutter",
        "Edward Schmerling",
        "Marco Pavone"
      ],
      "abstract": "Foundation models, e.g., large language models (LLMs), trained on\ninternet-scale data possess zero-shot generalization capabilities that make\nthem a promising technology towards detecting and mitigating\nout-of-distribution failure modes of robotic systems. Fully realizing this\npromise, however, poses two challenges: (i) mitigating the considerable\ncomputational expense of these models such that they may be applied online, and\n(ii) incorporating their judgement regarding potential anomalies into a safe\ncontrol framework. In this work, we present a two-stage reasoning framework:\nFirst is a fast binary anomaly classifier that analyzes observations in an LLM\nembedding space, which may then trigger a slower fallback selection stage that\nutilizes the reasoning capabilities of generative LLMs. These stages correspond\nto branch points in a model predictive control strategy that maintains the\njoint feasibility of continuing along various fallback plans to account for the\nslow reasoner's latency as soon as an anomaly is detected, thus ensuring\nsafety. We show that our fast anomaly classifier outperforms autoregressive\nreasoning with state-of-the-art GPT models, even when instantiated with\nrelatively small language models. This enables our runtime monitor to improve\nthe trustworthiness of dynamic robotic systems, such as quadrotors or\nautonomous vehicles, under resource and time constraints. Videos illustrating\nour approach in both simulation and real-world experiments are available on\nthis project page: https://sites.google.com/view/aesop-llm.",
      "tldr_zh": "这篇论文提出了一种两阶段推理框架，利用 Large Language Models (LLMs) 实现机器人系统的实时异常检测和反应规划，以解决计算开销和安全整合的挑战。第一阶段采用快速二元异常分类器在 LLM 嵌入空间分析观察数据，一旦检测到异常，便触发第二阶段的生成式 LLM 进行后备方案选择。该框架整合到模型预测控制 (Model Predictive Control) 策略中，确保在资源和时间受限环境下维持安全。实验结果显示，该分类器即使使用较小语言模型，也优于最先进的 GPT 模型，从而提升了动态机器人系统（如四旋翼无人机或自动车辆）的可信度和可靠性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to Robotics: Science and Systems (RSS) 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08735v1",
      "published_date": "2024-07-11 17:59:22 UTC",
      "updated_date": "2024-07-11 17:59:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:35:10.052045"
    },
    {
      "arxiv_id": "2407.08734v1",
      "title": "Transformer Circuit Faithfulness Metrics are not Robust",
      "title_zh": "Transformer 电路忠实度指标不稳健",
      "authors": [
        "Joseph Miller",
        "Bilal Chughtai",
        "William Saunders"
      ],
      "abstract": "Mechanistic interpretability work attempts to reverse engineer the learned\nalgorithms present inside neural networks. One focus of this work has been to\ndiscover 'circuits' -- subgraphs of the full model that explain behaviour on\nspecific tasks. But how do we measure the performance of such circuits? Prior\nwork has attempted to measure circuit 'faithfulness' -- the degree to which the\ncircuit replicates the performance of the full model. In this work, we survey\nmany considerations for designing experiments that measure circuit faithfulness\nby ablating portions of the model's computation. Concerningly, we find existing\nmethods are highly sensitive to seemingly insignificant changes in the ablation\nmethodology. We conclude that existing circuit faithfulness scores reflect both\nthe methodological choices of researchers as well as the actual components of\nthe circuit - the task a circuit is required to perform depends on the ablation\nused to test it. The ultimate goal of mechanistic interpretability work is to\nunderstand neural networks, so we emphasize the need for more clarity in the\nprecise claims being made about circuits. We open source a library at\nhttps://github.com/UFO-101/auto-circuit that includes highly efficient\nimplementations of a wide range of ablation methodologies and circuit discovery\nalgorithms.",
      "tldr_zh": "这篇论文探讨了Transformer模型中电路（circuits）的忠诚度（faithfulness）度量方法的不鲁棒性问题，指出现有机械解释性（mechanistic interpretability）实验在通过消融（ablation）部分模型计算来评估电路性能时，对微小方法变化高度敏感。研究发现，这些度量分数不仅反映电路的实际组件，还受研究者方法选择的影响，从而影响了对电路任务的理解。作者强调需要更清晰地声明电路的相关声明，并开源了一个库（https://github.com/UFO-101/auto-circuit），提供高效的消融方法和电路发现算法，以推进神经网络的可解释性研究。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "CoLM 2024 Conference Paper. 11 page main body. 11 page appendix. 12\n  figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08734v1",
      "published_date": "2024-07-11 17:59:00 UTC",
      "updated_date": "2024-07-11 17:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:35:19.722905"
    },
    {
      "arxiv_id": "2407.08725v2",
      "title": "MetaUrban: An Embodied AI Simulation Platform for Urban Micromobility",
      "title_zh": "翻译失败",
      "authors": [
        "Wayne Wu",
        "Honglin He",
        "Jack He",
        "Yiran Wang",
        "Chenda Duan",
        "Zhizheng Liu",
        "Quanyi Li",
        "Bolei Zhou"
      ],
      "abstract": "Public urban spaces like streetscapes and plazas serve residents and\naccommodate social life in all its vibrant variations. Recent advances in\nRobotics and Embodied AI make public urban spaces no longer exclusive to\nhumans. Food delivery bots and electric wheelchairs have started sharing\nsidewalks with pedestrians, while robot dogs and humanoids have recently\nemerged in the street. Micromobility enabled by AI for short-distance travel in\npublic urban spaces plays a crucial component in the future transportation\nsystem. Ensuring the generalizability and safety of AI models maneuvering\nmobile machines is essential. In this work, we present MetaUrban, a\ncompositional simulation platform for the AI-driven urban micromobility\nresearch. MetaUrban can construct an infinite number of interactive urban\nscenes from compositional elements, covering a vast array of ground plans,\nobject placements, pedestrians, vulnerable road users, and other mobile agents'\nappearances and dynamics. We design point navigation and social navigation\ntasks as the pilot study using MetaUrban for urban micromobility research and\nestablish various baselines of Reinforcement Learning and Imitation Learning.\nWe conduct extensive evaluation across mobile machines, demonstrating that\nheterogeneous mechanical structures significantly influence the learning and\nexecution of AI policies. We perform a thorough ablation study, showing that\nthe compositional nature of the simulated environments can substantially\nimprove the generalizability and safety of the trained mobile agents. MetaUrban\nwill be made publicly available to provide research opportunities and foster\nsafe and trustworthy embodied AI and micromobility in cities. The code and\ndataset will be publicly available.",
      "tldr_zh": "这篇论文介绍了 MetaUrban，一个用于城市微型移动性（Micromobility）的 Embodied AI 模拟平台，旨在模拟公共城市空间中 AI 驱动的移动设备，如送货机器人和电动轮椅。平台通过组合元素构建无限交互城市场景，包括地面计划、物体放置、行人和移动代理的动态，并设计了点导航和社交导航任务作为初步研究，使用 Reinforcement Learning 和 Imitation Learning 建立了基线。实验评估显示，不同机械结构显著影响 AI 策略的学习和执行，而模拟环境的组合性质可提升代理的泛化性和安全性。MetaUrban 将公开其代码和数据集，以促进安全可靠的城市 Embodied AI 和微型移动性研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.CV",
      "comment": "Technical report. Project page:\n  https://metadriverse.github.io/metaurban/",
      "pdf_url": "http://arxiv.org/pdf/2407.08725v2",
      "published_date": "2024-07-11 17:56:49 UTC",
      "updated_date": "2024-10-11 09:41:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:35:33.336887"
    },
    {
      "arxiv_id": "2407.08770v2",
      "title": "Model Surgery: Modulating LLM's Behavior Via Simple Parameter Editing",
      "title_zh": "模型手术：通过简单参数编辑调节 LLM 的行为",
      "authors": [
        "Huanqian Wang",
        "Yang Yue",
        "Rui Lu",
        "Jingxin Shi",
        "Andrew Zhao",
        "Shenzhi Wang",
        "Shiji Song",
        "Gao Huang"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated great potential as generalist\nassistants, showcasing powerful task understanding and problem-solving\ncapabilities. To deploy LLMs as AI assistants, it is crucial that these models\nexhibit desirable behavioral traits, such as non-toxicity and resilience\nagainst jailbreak attempts. Current approaches for detoxification or preventing\njailbreaking usually involve Supervised Fine-Tuning (SFT) or Reinforcement\nLearning from Human Feedback (RLHF), which requires finetuning billions of\nparameters through gradient descent with substantial computational cost.\nFurthermore, models modified through SFT and RLHF may deviate from the\npretrained models, potentially leading to a degradation in foundational LLM\ncapabilities. In this paper, we observe that surprisingly, directly editing a\nsmall subset of parameters can effectively modulate specific behaviors of LLMs,\nsuch as detoxification and resistance to jailbreaking, with only\ninference-level computational resources. Experiments demonstrate that in the\ndetoxification task, our approach achieves reductions of up to 90.0% in\ntoxicity on the RealToxicityPrompts dataset and 49.2% on ToxiGen, while\nmaintaining the LLM's general capabilities in areas such as common sense,\nquestion answering, and mathematics",
      "tldr_zh": "该研究提出了“Model Surgery”方法，通过简单编辑大型语言模型(LLMs)的一小部分参数，来有效调整其行为，如减少毒性和增强对越狱(jailbreak)攻击的抵抗力，而无需进行昂贵的Supervised Fine-Tuning(SFT)或Reinforcement Learning from Human Feedback(RLH F)。这项方法仅需推理级别的计算资源，就能避免传统微调可能导致的模型基础能力下降。实验显示，在detoxification任务中，它在RealToxicityPrompts数据集上将毒性降低高达90.0%，在ToxiGen上降低49.2%，同时保持LLMs在常识、问答和数学等方面的原有性能。",
      "categories": [
        "cs.AI",
        "68T50 (Primary) 68T07, 62M45 (Secondary)",
        "I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08770v2",
      "published_date": "2024-07-11 17:52:03 UTC",
      "updated_date": "2025-02-11 15:39:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:35:43.465293"
    },
    {
      "arxiv_id": "2407.08717v1",
      "title": "WhisperNetV2: SlowFast Siamese Network For Lip-Based Biometrics",
      "title_zh": "翻译失败",
      "authors": [
        "Abdollah Zakeri",
        "Hamid Hassanpour",
        "Mohammad Hossein Khosravi",
        "Amir Masoud Nourollah"
      ],
      "abstract": "Lip-based biometric authentication (LBBA) has attracted many researchers\nduring the last decade. The lip is specifically interesting for biometric\nresearchers because it is a twin biometric with the potential to function both\nas a physiological and a behavioral trait. Although much valuable research was\nconducted on LBBA, none of them considered the different emotions of the client\nduring the video acquisition step of LBBA, which can potentially affect the\nclient's facial expressions and speech tempo. We proposed a novel network\nstructure called WhisperNetV2, which extends our previously proposed network\ncalled WhisperNet. Our proposed network leverages a deep Siamese structure with\ntriplet loss having three identical SlowFast networks as embedding networks.\nThe SlowFast network is an excellent candidate for our task since the fast\npathway extracts motion-related features (behavioral lip movements) with a high\nframe rate and low channel capacity. The slow pathway extracts visual features\n(physiological lip appearance) with a low frame rate and high channel capacity.\nUsing an open-set protocol, we trained our network using the CREMA-D dataset\nand acquired an Equal Error Rate (EER) of 0.005 on the test set. Considering\nthat the acquired EER is less than most similar LBBA methods, our method can be\nconsidered as a state-of-the-art LBBA method.",
      "tldr_zh": "本研究提出WhisperNetV2，一种基于SlowFast Siamese Network的唇部生物识别系统（Lip-Based Biometrics），旨在解决用户情绪对面部表情和语音节奏的影响，从而提升认证准确性。WhisperNetV2扩展了先前的WhisperNet，使用深度Siamese结构结合triplet loss和三个相同的SlowFast网络，其中fast pathway以高帧率提取行为相关特征（如唇部动作），slow pathway以低帧率提取生理相关特征（如唇部外观）。实验在CREMA-D数据集上采用开放集协议进行训练，测试集的Equal Error Rate (EER)达到0.005，优于类似方法，确立了其作为最先进的LBBA技术的地位。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08717v1",
      "published_date": "2024-07-11 17:51:49 UTC",
      "updated_date": "2024-07-11 17:51:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:35:56.466763"
    },
    {
      "arxiv_id": "2407.08713v2",
      "title": "GTA: A Benchmark for General Tool Agents",
      "title_zh": "GTA",
      "authors": [
        "Jize Wang",
        "Zerun Ma",
        "Yining Li",
        "Songyang Zhang",
        "Cailian Chen",
        "Kai Chen",
        "Xinyi Le"
      ],
      "abstract": "Significant focus has been placed on integrating large language models (LLMs)\nwith various tools in developing general-purpose agents. This poses a challenge\nto LLMs' tool-use capabilities. However, there are evident gaps between\nexisting tool-use evaluations and real-world scenarios. Current evaluations\noften use AI-generated queries, single-step tasks, dummy tools, and text-only\ninteractions, failing to reveal the agents' real-world problem-solving\nabilities effectively. To address this, we propose GTA, a benchmark for General\nTool Agents, featuring three main aspects: (i) Real user queries: human-written\nqueries with simple real-world objectives but implicit tool-use, requiring the\nLLM to reason the suitable tools and plan the solution steps. (ii) Real\ndeployed tools: an evaluation platform equipped with tools across perception,\noperation, logic, and creativity categories to evaluate the agents' actual task\nexecution performance. (iii) Real multimodal inputs: authentic image files,\nsuch as spatial scenes, web page screenshots, tables, code snippets, and\nprinted/handwritten materials, used as the query contexts to align with\nreal-world scenarios closely. We design 229 real-world tasks and executable\ntool chains to evaluate mainstream LLMs. Our findings show that real-world user\nqueries are challenging for existing LLMs, with GPT-4 completing less than 50%\nof the tasks and most LLMs achieving below 25%. This evaluation reveals the\nbottlenecks in the tool-use capabilities of current LLMs in real-world\nscenarios, which provides future direction for advancing general-purpose tool\nagents. The code and dataset are available at\nhttps://github.com/open-compass/GTA.",
      "tldr_zh": "该研究提出GTA基准，用于评估大型语言模型(LLMs)在真实场景中作为通用工具代理的能力，以弥补现有评估的不足。GTA包括三个关键方面：(i) Real user queries，由人类编写的隐含工具使用查询，需要LLMs推理工具和规划步骤；(ii) Real deployed tools，一个配备感知、操作、逻辑和创造力类工具的平台，用于测试实际任务执行；(iii) Real multimodal inputs，如图像文件和表格，作为查询上下文以模拟真实世界。实验评估了229个真实任务，发现GPT-4完成率不足50%，大多数LLMs低于25%，揭示了当前LLMs工具使用能力的瓶颈，并为未来通用工具代理的发展提供指导方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Github repo: https://github.com/open-compass/GTA",
      "pdf_url": "http://arxiv.org/pdf/2407.08713v2",
      "published_date": "2024-07-11 17:50:09 UTC",
      "updated_date": "2024-11-22 11:25:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:36:09.873703"
    },
    {
      "arxiv_id": "2407.08708v2",
      "title": "eyeballvul: a future-proof benchmark for vulnerability detection in the wild",
      "title_zh": "翻译失败",
      "authors": [
        "Timothee Chauvin"
      ],
      "abstract": "Long contexts of recent LLMs have enabled a new use case: asking models to\nfind security vulnerabilities in entire codebases. To evaluate model\nperformance on this task, we introduce eyeballvul: a benchmark designed to test\nthe vulnerability detection capabilities of language models at scale, that is\nsourced and updated weekly from the stream of published vulnerabilities in\nopen-source repositories. The benchmark consists of a list of revisions in\ndifferent repositories, each associated with the list of known vulnerabilities\npresent at that revision. An LLM-based scorer is used to compare the list of\npossible vulnerabilities returned by a model to the list of known\nvulnerabilities for each revision. As of July 2024, eyeballvul contains 24,000+\nvulnerabilities across 6,000+ revisions and 5,000+ repositories, and is around\n55GB in size.",
      "tldr_zh": "该研究引入了eyeballvul基准，这是一个未来导向的测试平台，旨在评估语言模型(LLMs)在真实环境中检测代码库安全漏洞的能力。eyeballvul从开源仓库的已发布漏洞中每周更新，包含数千个修订版本，每个版本关联已知漏洞列表，并使用LLM-based scorer比较模型检测结果与实际漏洞。基准目前涵盖5,000+仓库、6,000+修订版本和24,000+漏洞，总大小约55GB，为大规模vulnerability detection提供了一个动态、可靠的评估工具。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Due to a bug in the litellm library (we haven't tracked exactly which\n  one, but probably at least\n  https://github.com/BerriAI/litellm/commit/2452753e084e8134c0c484b32c63fb5f2950c5ba),\n  our Gemini 1.5 Pro inference costs were incorrect. We've updated the relevant\n  plot (Fig 7) and its interpretation (both Gemini 1.5 Pro and Claude 3.5\n  Sonnet stand out from the other models, not just Gemini 1.5 Pro)",
      "pdf_url": "http://arxiv.org/pdf/2407.08708v2",
      "published_date": "2024-07-11 17:46:21 UTC",
      "updated_date": "2024-07-13 10:44:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:36:21.474601"
    },
    {
      "arxiv_id": "2407.08704v1",
      "title": "Towards Efficient Deployment of Hybrid SNNs on Neuromorphic and Edge AI Hardware",
      "title_zh": "翻译失败",
      "authors": [
        "James Seekings",
        "Peyton Chandarana",
        "Mahsa Ardakani",
        "MohammadReza Mohammadi",
        "Ramtin Zand"
      ],
      "abstract": "This paper explores the synergistic potential of neuromorphic and edge\ncomputing to create a versatile machine learning (ML) system tailored for\nprocessing data captured by dynamic vision sensors. We construct and train\nhybrid models, blending spiking neural networks (SNNs) and artificial neural\nnetworks (ANNs) using PyTorch and Lava frameworks. Our hybrid architecture\nintegrates an SNN for temporal feature extraction and an ANN for\nclassification. We delve into the challenges of deploying such hybrid\nstructures on hardware. Specifically, we deploy individual components on\nIntel's Neuromorphic Processor Loihi (for SNN) and Jetson Nano (for ANN). We\nalso propose an accumulator circuit to transfer data from the spiking to the\nnon-spiking domain. Furthermore, we conduct comprehensive performance analyses\nof hybrid SNN-ANN models on a heterogeneous system of neuromorphic and edge AI\nhardware, evaluating accuracy, latency, power, and energy consumption. Our\nfindings demonstrate that the hybrid spiking networks surpass the baseline ANN\nmodel across all metrics and outperform the baseline SNN model in accuracy and\nlatency.",
      "tldr_zh": "这篇论文探讨了在神经形态和边缘AI硬件上部署混合SNNs（Spiking Neural Networks）和ANNs（Artificial Neural Networks）的潜力，以高效处理动态视觉传感器数据。研究团队构建并训练了混合模型，使用SNN提取时间特征、ANN进行分类，并通过PyTorch和Lava框架实现；部署时将SNN组件置于Intel的Neuromorphic Processor Loihi上，ANN组件置于Jetson Nano上，并引入accumulator circuit来桥接尖峰和非尖峰数据域。实验结果表明，混合模型在准确率、延迟、功率和能耗方面均优于基线ANN模型，并在准确率和延迟上超越基线SNN模型，从而提升了机器学习系统的整体性能。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.AR",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08704v1",
      "published_date": "2024-07-11 17:40:39 UTC",
      "updated_date": "2024-07-11 17:40:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:36:35.735716"
    },
    {
      "arxiv_id": "2407.08700v1",
      "title": "Flex-TPU: A Flexible TPU with Runtime Reconfigurable Dataflow Architecture",
      "title_zh": "Flex-TPU：一种具有运行时可重配置数据流架构的灵活 TPU",
      "authors": [
        "Mohammed Elbtity",
        "Peyton Chandarana",
        "Ramtin Zand"
      ],
      "abstract": "Tensor processing units (TPUs) are one of the most well-known machine\nlearning (ML) accelerators utilized at large scale in data centers as well as\nin tiny ML applications. TPUs offer several improvements and advantages over\nconventional ML accelerators, like graphical processing units (GPUs), being\ndesigned specifically to perform the multiply-accumulate (MAC) operations\nrequired in the matrix-matrix and matrix-vector multiplies extensively present\nthroughout the execution of deep neural networks (DNNs). Such improvements\ninclude maximizing data reuse and minimizing data transfer by leveraging the\ntemporal dataflow paradigms provided by the systolic array architecture. While\nthis design provides a significant performance benefit, the current\nimplementations are restricted to a single dataflow consisting of either input,\noutput, or weight stationary architectures. This can limit the achievable\nperformance of DNN inference and reduce the utilization of compute units.\nTherefore, the work herein consists of developing a reconfigurable dataflow\nTPU, called the Flex-TPU, which can dynamically change the dataflow per layer\nduring run-time. Our experiments thoroughly test the viability of the Flex-TPU\ncomparing it to conventional TPU designs across multiple well-known ML\nworkloads. The results show that our Flex-TPU design achieves a significant\nperformance increase of up to 2.75x compared to conventional TPU, with only\nminor area and power overheads.",
      "tldr_zh": "本文提出 Flex-TPU，一种可运行时重新配置数据流的 TPU 架构，旨在解决传统 TPU 受限于单一数据流（如输入、输出或权重固定）而导致的性能限制问题。Flex-TPU 通过动态调整数据流来优化深度神经网络（DNNs）的矩阵乘法操作，提高计算单元利用率。实验结果显示，在多种机器学习（ML）工作负载上，Flex-TPU 比传统 TPU 性能提升高达 2.75 倍，同时仅带来微小的面积和功耗开销。",
      "categories": [
        "cs.AR",
        "cs.AI",
        "cs.DC",
        "cs.LG",
        "cs.PF"
      ],
      "primary_category": "cs.AR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08700v1",
      "published_date": "2024-07-11 17:33:38 UTC",
      "updated_date": "2024-07-11 17:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:36:45.725720"
    },
    {
      "arxiv_id": "2407.08694v1",
      "title": "Cloud Atlas: Efficient Fault Localization for Cloud Systems using Language Models and Causal Insight",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang Xie",
        "Yujia Zheng",
        "Lizi Ottens",
        "Kun Zhang",
        "Christos Kozyrakis",
        "Jonathan Mace"
      ],
      "abstract": "Runtime failure and performance degradation is commonplace in modern cloud\nsystems. For cloud providers, automatically determining the root cause of\nincidents is paramount to ensuring high reliability and availability as prompt\nfault localization can enable faster diagnosis and triage for timely\nresolution. A compelling solution explored in recent work is causal reasoning\nusing causal graphs to capture relationships between varied cloud system\nperformance metrics. To be effective, however, systems developers must\ncorrectly define the causal graph of their system, which is a time-consuming,\nbrittle, and challenging task that increases in difficulty for large and\ndynamic systems and requires domain expertise. Alternatively, automated\ndata-driven approaches have limited efficacy for cloud systems due to the\ninherent rarity of incidents. In this work, we present Atlas, a novel approach\nto automatically synthesizing causal graphs for cloud systems. Atlas leverages\nlarge language models (LLMs) to generate causal graphs using system\ndocumentation, telemetry, and deployment feedback. Atlas is complementary to\ndata-driven causal discovery techniques, and we further enhance Atlas with a\ndata-driven validation step. We evaluate Atlas across a range of fault\nlocalization scenarios and demonstrate that Atlas is capable of generating\ncausal graphs in a scalable and generalizable manner, with performance that far\nsurpasses that of data-driven algorithms and is commensurate to the\nground-truth baseline.",
      "tldr_zh": "该研究针对云系统的运行时故障和性能下降问题，提出了一种高效的故障定位方法Cloud Atlas，利用大语言模型(LLMs)基于系统文档、遥测数据和部署反馈自动合成因果图(causal graphs)。Atlas 结合了数据驱动验证步骤，解决了传统手动构建因果图的耗时性和易出错问题，以及数据驱动方法在事件稀少场景下的局限性。在多种故障定位场景的评估中，Atlas 显示出卓越的可扩展性和泛化性，其性能远超数据驱动算法，并接近 ground-truth 基线。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08694v1",
      "published_date": "2024-07-11 17:31:12 UTC",
      "updated_date": "2024-07-11 17:31:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:36:57.779882"
    },
    {
      "arxiv_id": "2407.08691v1",
      "title": "ElasticAST: An Audio Spectrogram Transformer for All Length and Resolutions",
      "title_zh": "翻译失败",
      "authors": [
        "Jiu Feng",
        "Mehmet Hamza Erol",
        "Joon Son Chung",
        "Arda Senocak"
      ],
      "abstract": "Transformers have rapidly overtaken CNN-based architectures as the new\nstandard in audio classification. Transformer-based models, such as the Audio\nSpectrogram Transformers (AST), also inherit the fixed-size input paradigm from\nCNNs. However, this leads to performance degradation for ASTs in the inference\nwhen input lengths vary from the training. This paper introduces an approach\nthat enables the use of variable-length audio inputs with AST models during\nboth training and inference. By employing sequence packing, our method\nElasticAST, accommodates any audio length during training, thereby offering\nflexibility across all lengths and resolutions at the inference. This\nflexibility allows ElasticAST to maintain evaluation capabilities at various\nlengths or resolutions and achieve similar performance to standard ASTs trained\nat specific lengths or resolutions. Moreover, experiments demonstrate\nElasticAST's better performance when trained and evaluated on native-length\naudio datasets.",
      "tldr_zh": "这篇论文提出 ElasticAST，一种音频频谱 Transformer，能处理任意长度和分辨率的音频输入，以解决标准 Audio Spectrogram Transformers (AST) 在输入长度变化时性能下降的问题。通过采用 sequence packing 技术，ElasticAST 允许在训练和推理阶段使用可变长度音频，提供更高的灵活性，并保持与标准 AST 相似的性能。实验结果表明，ElasticAST 在原生长度音频数据集上表现出色，进一步提升了音频分类的鲁棒性。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "Interspeech 2024. Code is available at\n  https://github.com/JiuFengSC/ElasticAST",
      "pdf_url": "http://arxiv.org/pdf/2407.08691v1",
      "published_date": "2024-07-11 17:29:56 UTC",
      "updated_date": "2024-07-11 17:29:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:37:10.038063"
    },
    {
      "arxiv_id": "2407.08689v1",
      "title": "Operationalizing the Blueprint for an AI Bill of Rights: Recommendations for Practitioners, Researchers, and Policy Makers",
      "title_zh": "操作化 AI 权利法案蓝图：针对从业者、研究人员和政策制定",
      "authors": [
        "Alex Oesterling",
        "Usha Bhalla",
        "Suresh Venkatasubramanian",
        "Himabindu Lakkaraju"
      ],
      "abstract": "As Artificial Intelligence (AI) tools are increasingly employed in diverse\nreal-world applications, there has been significant interest in regulating\nthese tools. To this end, several regulatory frameworks have been introduced by\ndifferent countries worldwide. For example, the European Union recently passed\nthe AI Act, the White House issued an Executive Order on safe, secure, and\ntrustworthy AI, and the White House Office of Science and Technology Policy\nissued the Blueprint for an AI Bill of Rights (AI BoR). Many of these\nframeworks emphasize the need for auditing and improving the trustworthiness of\nAI tools, underscoring the importance of safety, privacy, explainability,\nfairness, and human fallback options. Although these regulatory frameworks\nhighlight the necessity of enforcement, practitioners often lack detailed\nguidance on implementing them. Furthermore, the extensive research on\noperationalizing each of these aspects is frequently buried in technical papers\nthat are difficult for practitioners to parse. In this write-up, we address\nthis shortcoming by providing an accessible overview of existing literature\nrelated to operationalizing regulatory principles. We provide\neasy-to-understand summaries of state-of-the-art literature and highlight\nvarious gaps that exist between regulatory guidelines and existing AI research,\nincluding the trade-offs that emerge during operationalization. We hope that\nthis work not only serves as a starting point for practitioners interested in\nlearning more about operationalizing the regulatory guidelines outlined in the\nBlueprint for an AI BoR but also provides researchers with a list of critical\nopen problems and gaps between regulations and state-of-the-art AI research.\nFinally, we note that this is a working paper and we invite feedback in line\nwith the purpose of this document as described in the introduction.",
      "tldr_zh": "该论文探讨了如何将《AI Bill of Rights》蓝图转化为实际操作，提供针对从业者、研究者和政策制定者的实用建议。作者总结了现有文献，概述了AI工具的可信度审计方法，包括安全、隐私、explainability、fairness和human fallback options等领域，并强调了监管指南与AI研究之间的差距及操作化过程中的权衡。最终，该工作旨在为从业者提供学习起点，并为研究者指明关键开放问题，作为工作论文欢迎反馈。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.08689v1",
      "published_date": "2024-07-11 17:28:07 UTC",
      "updated_date": "2024-07-11 17:28:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:37:22.309835"
    },
    {
      "arxiv_id": "2407.08675v2",
      "title": "CAD-Prompted Generative Models: A Pathway to Feasible and Novel Engineering Designs",
      "title_zh": "翻译失败",
      "authors": [
        "Leah Chong",
        "Jude Rayan",
        "Steven Dow",
        "Ioanna Lykourentzou",
        "Faez Ahmed"
      ],
      "abstract": "Text-to-image generative models have increasingly been used to assist\ndesigners during concept generation in various creative domains, such as\ngraphic design, user interface design, and fashion design. However, their\napplications in engineering design remain limited due to the models' challenges\nin generating images of feasible designs concepts. To address this issue, this\npaper introduces a method that improves the design feasibility by prompting the\ngeneration with feasible CAD images. In this work, the usefulness of this\nmethod is investigated through a case study with a bike design task using an\noff-the-shelf text-to-image model, Stable Diffusion 2.1. A diverse set of bike\ndesigns are produced in seven different generation settings with varying CAD\nimage prompting weights, and these designs are evaluated on their perceived\nfeasibility and novelty. Results demonstrate that the CAD image prompting\nsuccessfully helps text-to-image models like Stable Diffusion 2.1 create\nvisibly more feasible design images. While a general tradeoff is observed\nbetween feasibility and novelty, when the prompting weight is kept low around\n0.35, the design feasibility is significantly improved while its novelty\nremains on par with those generated by text prompts alone. The insights from\nthis case study offer some guidelines for selecting the appropriate CAD image\nprompting weight for different stages of the engineering design process. When\nutilized effectively, our CAD image prompting method opens doors to a wider\nrange of applications of text-to-image models in engineering design.",
      "tldr_zh": "本文提出了一种CAD-Prompted方法，通过使用可行的CAD图像作为提示，来提升文本-to-image生成模型在工程设计中的图像可行性，解决模型生成不可行设计概念的挑战。研究通过一个自行车设计案例，使用Stable Diffusion 2.1模型在七种不同CAD图像提示权重设置下生成多样设计，并评估其可行性和新颖性。结果表明，CAD图像提示显著提高了设计可行性，而当提示权重保持在约0.35时，新颖性与纯文本提示相当；这一方法为工程设计过程的不同阶段提供指导，并扩展了文本-to-image模型的应用潜力。",
      "categories": [
        "cs.AI",
        "I.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2407.08675v2",
      "published_date": "2024-07-11 17:07:32 UTC",
      "updated_date": "2024-07-22 06:49:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:37:36.026816"
    },
    {
      "arxiv_id": "2407.08662v1",
      "title": "Uncertainty Estimation of Large Language Models in Medical Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Jiaxin Wu",
        "Yizhou Yu",
        "Hong-Yu Zhou"
      ],
      "abstract": "Large Language Models (LLMs) show promise for natural language generation in\nhealthcare, but risk hallucinating factually incorrect information. Deploying\nLLMs for medical question answering necessitates reliable uncertainty\nestimation (UE) methods to detect hallucinations. In this work, we benchmark\npopular UE methods with different model sizes on medical question-answering\ndatasets. Our results show that current approaches generally perform poorly in\nthis domain, highlighting the challenge of UE for medical applications. We also\nobserve that larger models tend to yield better results, suggesting a\ncorrelation between model size and the reliability of UE. To address these\nchallenges, we propose Two-phase Verification, a probability-free Uncertainty\nEstimation approach. First, an LLM generates a step-by-step explanation\nalongside its initial answer, followed by formulating verification questions to\ncheck the factual claims in the explanation. The model then answers these\nquestions twice: first independently, and then referencing the explanation.\nInconsistencies between the two sets of answers measure the uncertainty in the\noriginal response. We evaluate our approach on three biomedical\nquestion-answering datasets using Llama 2 Chat models and compare it against\nthe benchmarked baseline methods. The results show that our Two-phase\nVerification method achieves the best overall accuracy and stability across\nvarious datasets and model sizes, and its performance scales as the model size\nincreases.",
      "tldr_zh": "这篇论文探讨了 Large Language Models (LLMs) 在医疗问答中的不确定性估计 (UE)，旨在检测幻觉问题以确保可靠性。研究者基准测试了流行 UE 方法，发现这些方法在医疗数据集上表现不佳，但模型大小越大，效果越好。为解决这一挑战，他们提出 Two-phase Verification 一种基于概率的非方法：先生成逐步解释和初始答案，然后通过制定验证问题并两次回答（独立和参考解释）来衡量答案不一致性。实验结果显示，该方法在使用 Llama 2 Chat 模型的三个生物医学问答数据集上，实现了最佳的准确性和稳定性，且性能随模型大小增加而提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08662v1",
      "published_date": "2024-07-11 16:51:33 UTC",
      "updated_date": "2024-07-11 16:51:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:37:47.502919"
    },
    {
      "arxiv_id": "2407.08655v1",
      "title": "SPOCKMIP: Segmentation of Vessels in MRAs with Enhanced Continuity using Maximum Intensity Projection as Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Chethan Radhakrishna",
        "Karthikesh Varma Chintalapati",
        "Sri Chandana Hudukula Ram Kumar",
        "Raviteja Sutrave",
        "Hendrik Mattern",
        "Oliver Speck",
        "Andreas Nürnberger",
        "Soumick Chatterjee"
      ],
      "abstract": "Identification of vessel structures of different sizes in biomedical images\nis crucial in the diagnosis of many neurodegenerative diseases. However, the\nsparsity of good-quality annotations of such images makes the task of vessel\nsegmentation challenging. Deep learning offers an efficient way to segment\nvessels of different sizes by learning their high-level feature representations\nand the spatial continuity of such features across dimensions. Semi-supervised\npatch-based approaches have been effective in identifying small vessels of one\nto two voxels in diameter. This study focuses on improving the segmentation\nquality by considering the spatial correlation of the features using the\nMaximum Intensity Projection~(MIP) as an additional loss criterion. Two methods\nare proposed with the incorporation of MIPs of label segmentation on the\nsingle~(z-axis) and multiple perceivable axes of the 3D volume. The proposed\nMIP-based methods produce segmentations with improved vessel continuity, which\nis evident in visual examinations of ROIs. Patch-based training is improved by\nintroducing an additional loss term, MIP loss, to penalise the predicted\ndiscontinuity of vessels. A training set of 14 volumes is selected from the\nStudyForrest dataset comprising of 18 7-Tesla 3D Time-of-Flight~(ToF) Magnetic\nResonance Angiography (MRA) images. The generalisation performance of the\nmethod is evaluated using the other unseen volumes in the dataset. It is\nobserved that the proposed method with multi-axes MIP loss produces better\nquality segmentations with a median Dice of $80.245 \\pm 0.129$. Also, the\nmethod with single-axis MIP loss produces segmentations with a median Dice of\n$79.749 \\pm 0.109$. Furthermore, a visual comparison of the ROIs in the\npredicted segmentation reveals a significant improvement in the continuity of\nthe vessels when MIP loss is incorporated into training.",
      "tldr_zh": "本研究提出SPOCKMIP框架，用于改善Magnetic Resonance Angiography (MRA)图像中血管结构的分割，针对标注稀少和小血管识别的挑战。方法通过引入Maximum Intensity Projection (MIP)作为额外损失函数，惩罚预测中的血管不连续性，包括单轴（z轴）和多轴MIP损失，以增强分割的连续性和空间相关性。实验在StudyForrest数据集的14个3D Time-of-Flight (ToF) MRA图像上训练，结果显示多轴MIP损失方法的中位Dice系数为80.245 ± 0.129，单轴方法为79.749 ± 0.109，并通过视觉比较证实了血管连续性的显著提升。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.LG",
        "physics.med-ph"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08655v1",
      "published_date": "2024-07-11 16:39:24 UTC",
      "updated_date": "2024-07-11 16:39:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:37:58.765168"
    },
    {
      "arxiv_id": "2407.09573v1",
      "title": "Have We Reached AGI? Comparing ChatGPT, Claude, and Gemini to Human Literacy and Education Benchmarks",
      "title_zh": "翻译失败",
      "authors": [
        "Mfon Akpan"
      ],
      "abstract": "Recent advancements in AI, particularly in large language models (LLMs) like\nChatGPT, Claude, and Gemini, have prompted questions about their proximity to\nArtificial General Intelligence (AGI). This study compares LLM performance on\neducational benchmarks with Americans' average educational attainment and\nliteracy levels, using data from the U.S. Census Bureau and technical reports.\nResults show that LLMs significantly outperform human benchmarks in tasks such\nas undergraduate knowledge and advanced reading comprehension, indicating\nsubstantial progress toward AGI. However, true AGI requires broader cognitive\nassessments. The study highlights the implications for AI development,\neducation, and societal impact, emphasizing the need for ongoing research and\nethical considerations.",
      "tldr_zh": "这篇论文比较了大型语言模型(LLMs)如 ChatGPT、Claude 和 Gemini 与人类的平均教育水平和识字率，旨在评估它们是否接近人工通用智能(AGI)。研究使用美国人口普查局的数据和技术报告作为基准，结果显示 LLMs 在本科知识和高级阅读理解任务中显著优于人类标准，表明 AI 向 AGI 的进展已相当可观。论文强调，虽然这些模型表现出色，但实现真正的 AGI 仍需更全面的认知评估，并呼吁持续研究以应对 AI 发展、教育和社会伦理影响。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.09573v1",
      "published_date": "2024-07-11 16:38:40 UTC",
      "updated_date": "2024-07-11 16:38:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:38:09.927761"
    },
    {
      "arxiv_id": "2407.08649v2",
      "title": "Confidence-based Estimators for Predictive Performance in Model Monitoring",
      "title_zh": "翻译失败",
      "authors": [
        "Juhani Kivimäki",
        "Jakub Białek",
        "Jukka K. Nurminen",
        "Wojtek Kuberski"
      ],
      "abstract": "After a machine learning model has been deployed into production, its\npredictive performance needs to be monitored. Ideally, such monitoring can be\ncarried out by comparing the model's predictions against ground truth labels.\nFor this to be possible, the ground truth labels must be available relatively\nsoon after inference. However, there are many use cases where ground truth\nlabels are available only after a significant delay, or in the worst case, not\nat all. In such cases, directly monitoring the model's predictive performance\nis impossible.\n  Recently, novel methods for estimating the predictive performance of a model\nwhen ground truth is unavailable have been developed. Many of these methods\nleverage model confidence or other uncertainty estimates and are experimentally\ncompared against a naive baseline method, namely Average Confidence (AC), which\nestimates model accuracy as the average of confidence scores for a given set of\npredictions. However, until now the theoretical properties of the AC method\nhave not been properly explored. In this paper, we try to fill this gap by\nreviewing the AC method and show that under certain general assumptions, it is\nan unbiased and consistent estimator of model accuracy with many desirable\nproperties. We also compare this baseline estimator against some more complex\nestimators empirically and show that in many cases the AC method is able to\nbeat the others, although the comparative quality of the different estimators\nis heavily case-dependent.",
      "tldr_zh": "本论文探讨了机器学习模型部署后，在真实标签延迟或不可用时，如何估算预测性能。作者审查了基于置信度的估算方法，特别是 Average Confidence (AC) 方法，将模型准确率估算为置信度分数的平均值，并证明在某些一般假设下，AC 是 unbiased 和 consistent 的估计器。实验结果显示，AC 方法在许多场景中优于其他复杂估计器，但其表现依赖于具体情况，从而为模型监控提供了可靠的基准。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "This version corresponds to the final published version in JAIR. The\n  published article is available at [https://doi.org/10.1613/jair.1.16709]",
      "pdf_url": "http://arxiv.org/pdf/2407.08649v2",
      "published_date": "2024-07-11 16:28:31 UTC",
      "updated_date": "2025-02-12 14:49:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:38:22.615997"
    },
    {
      "arxiv_id": "2407.08639v2",
      "title": "$β$-DPO: Direct Preference Optimization with Dynamic $β$",
      "title_zh": "翻译失败",
      "authors": [
        "Junkang Wu",
        "Yuexiang Xie",
        "Zhengyi Yang",
        "Jiancan Wu",
        "Jinyang Gao",
        "Bolin Ding",
        "Xiang Wang",
        "Xiangnan He"
      ],
      "abstract": "Direct Preference Optimization (DPO) has emerged as a compelling approach for\ntraining Large Language Models (LLMs) to adhere to human preferences. However,\nthe performance of DPO is sensitive to the fine-tuning of its trade-off\nparameter $\\beta$, as well as to the quality of the preference data. We analyze\nthe impact of $\\beta$ and data quality on DPO, uncovering that optimal $\\beta$\nvalues vary with the informativeness of pairwise data. Addressing the\nlimitations of static $\\beta$ values, we introduce a novel framework that\ndynamically calibrates $\\beta$ at the batch level, informed by data quality\nconsiderations. Additionally, our method incorporates $\\beta$-guided data\nfiltering to safeguard against the influence of outliers. Through empirical\nevaluation, we demonstrate that our dynamic $\\beta$ adjustment technique\nsignificantly improves DPO's performance across a range of models and datasets,\noffering a more robust and adaptable training paradigm for aligning LLMs with\nhuman feedback. The code is available at\n\\url{https://github.com/junkangwu/beta-DPO}.",
      "tldr_zh": "Direct Preference Optimization (DPO) 是一种训练 Large Language Models (LLMs) 以符合人类偏好的方法，但其性能高度依赖于 β 参数的微调和数据质量。论文分析了 β 值与数据信息量的关系，并提出了一种新型框架，通过在批次级别动态校准 β 值并结合 β 引导的数据过滤，解决了静态 β 的局限性。实验结果表明，该动态 β 调整技术显著提升了 DPO 在多种模型和数据集上的表现，提供了一种更稳健、可适应的 LLM 训练范式。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08639v2",
      "published_date": "2024-07-11 16:21:18 UTC",
      "updated_date": "2024-10-13 08:53:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:38:34.779701"
    },
    {
      "arxiv_id": "2407.08633v2",
      "title": "A Novel Framework for Automated Warehouse Layout Generation",
      "title_zh": "一种用于自动仓库布局生成的新颖框架",
      "authors": [
        "Atefeh Shahroudnejad",
        "Payam Mousavi",
        "Oleksii Perepelytsia",
        "Sahir",
        "David Staszak",
        "Matthew E. Taylor",
        "Brent Bawel"
      ],
      "abstract": "Optimizing warehouse layouts is crucial due to its significant impact on\nefficiency and productivity. We present an AI-driven framework for automated\nwarehouse layout generation. This framework employs constrained beam search to\nderive optimal layouts within given spatial parameters, adhering to all\nfunctional requirements. The feasibility of the generated layouts is verified\nbased on criteria such as item accessibility, required minimum clearances, and\naisle connectivity. A scoring function is then used to evaluate the feasible\nlayouts considering the number of storage locations, access points, and\naccessibility costs. We demonstrate our method's ability to produce feasible,\noptimal layouts for a variety of warehouse dimensions and shapes, diverse door\nplacements, and interconnections. This approach, currently being prepared for\ndeployment, will enable human designers to rapidly explore and confirm options,\nfacilitating the selection of the most appropriate layout for their use-case.",
      "tldr_zh": "该论文提出了一种新型 AI 驱动框架，用于自动生成仓库布局，以提升效率和生产力。该框架采用 constrained beam search 方法，在给定空间参数下生成符合功能要求的优化布局，并通过验证物品可达性、最小间隙和通道连通性来确保布局可行性。接着，使用评分函数评估布局基于存储位置数量、访问点和可达性成本等多因素。结果表明，该方法能为各种仓库尺寸、形状和门置处理方案产生最佳布局，并即将部署，帮助人类设计师快速探索和确认合适选项。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08633v2",
      "published_date": "2024-07-11 16:15:09 UTC",
      "updated_date": "2024-07-12 19:06:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:38:46.050717"
    },
    {
      "arxiv_id": "2407.08608v2",
      "title": "FlashAttention-3: Fast and Accurate Attention with Asynchrony and Low-precision",
      "title_zh": "翻译失败",
      "authors": [
        "Jay Shah",
        "Ganesh Bikshandi",
        "Ying Zhang",
        "Vijay Thakkar",
        "Pradeep Ramani",
        "Tri Dao"
      ],
      "abstract": "Attention, as a core layer of the ubiquitous Transformer architecture, is the\nbottleneck for large language models and long-context applications.\nFlashAttention elaborated an approach to speed up attention on GPUs through\nminimizing memory reads/writes. However, it has yet to take advantage of new\ncapabilities present in recent hardware, with FlashAttention-2 achieving only\n35% utilization on the H100 GPU. We develop three main techniques to speed up\nattention on Hopper GPUs: exploiting asynchrony of the Tensor Cores and TMA to\n(1) overlap overall computation and data movement via warp-specialization and\n(2) interleave block-wise matmul and softmax operations, and (3) block\nquantization and incoherent processing that leverages hardware support for FP8\nlow-precision. We demonstrate that our method, FlashAttention-3, achieves\nspeedup on H100 GPUs by 1.5-2.0$\\times$ with FP16 reaching up to 740 TFLOPs/s\n(75% utilization), and with FP8 reaching close to 1.2 PFLOPs/s. We validate\nthat FP8 FlashAttention-3 achieves 2.6$\\times$ lower numerical error than a\nbaseline FP8 attention.",
      "tldr_zh": "该论文提出FlashAttention-3，一种针对Hopper GPUs优化的Attention层加速方法，通过利用Tensor Cores和TMA的异步性，实现（1）warp-specialization重叠计算与数据移动、（2）交错block-wise matmul和softmax操作，以及（3）block quantization和incoherent processing以支持FP8低精度。相比FlashAttention-2，该方法在H100 GPUs上实现了1.5-2.0倍的速度提升，使用FP16时达到740 TFLOPs/s（75%利用率），使用FP8时接近1.2 PFLOPs/s。实验验证，FP8 FlashAttention-3的数值错误比基线FP8 attention低2.6倍，从而提升了Transformer模型在大语言模型和长上下文应用中的效率和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08608v2",
      "published_date": "2024-07-11 15:44:48 UTC",
      "updated_date": "2024-07-12 22:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:39:00.029995"
    },
    {
      "arxiv_id": "2407.08590v2",
      "title": "A Review of Nine Physics Engines for Reinforcement Learning Research",
      "title_zh": "对九个物理引擎在强化学习研究中的综述",
      "authors": [
        "Michael Kaup",
        "Cornelius Wolff",
        "Hyerim Hwang",
        "Julius Mayer",
        "Elia Bruni"
      ],
      "abstract": "We present a review of popular simulation engines and frameworks used in\nreinforcement learning (RL) research, aiming to guide researchers in selecting\ntools for creating simulated physical environments for RL and training setups.\nIt evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX,\nPyBullet, Webots, and Unity) based on their popularity, feature range, quality,\nusability, and RL capabilities. We highlight the challenges in selecting and\nutilizing physics engines for RL research, including the need for detailed\ncomparisons and an understanding of each framework's capabilities. Key findings\nindicate MuJoCo as the leading framework due to its performance and\nflexibility, despite usability challenges. Unity is noted for its ease of use\nbut lacks scalability and simulation fidelity. The study calls for further\ndevelopment to improve simulation engines' usability and performance and\nstresses the importance of transparency and reproducibility in RL research.\nThis review contributes to the RL community by offering insights into the\nselection process for simulation engines, facilitating informed\ndecision-making.",
      "tldr_zh": "本论文审阅了九个流行的物理引擎框架（Brax、Chrono、Gazebo、MuJoCo、ODE、PhysX、PyBullet、Webots 和 Unity），旨在指导强化学习 (RL) 研究者选择合适的模拟工具用于创建物理环境和训练设置。评估基于框架的流行度、功能范围、质量、可用性和 RL 能力，结果显示 MuJoCo 因性能和灵活性而领先，尽管存在可用性挑战，而 Unity 则以易用性著称但在可扩展性和模拟保真度上不足。论文强调了选择引擎的挑战，呼吁进一步开发以提升可用性和性能，并强调透明度和可重复性对 RL 研究的重要性，为社区提供决策参考。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.MA",
        "I.2.0"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08590v2",
      "published_date": "2024-07-11 15:13:28 UTC",
      "updated_date": "2024-08-23 07:16:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:39:12.851205"
    },
    {
      "arxiv_id": "2407.08585v1",
      "title": "HACMan++: Spatially-Grounded Motion Primitives for Manipulation",
      "title_zh": "翻译失败",
      "authors": [
        "Bowen Jiang",
        "Yilin Wu",
        "Wenxuan Zhou",
        "Chris Paxton",
        "David Held"
      ],
      "abstract": "Although end-to-end robot learning has shown some success for robot\nmanipulation, the learned policies are often not sufficiently robust to\nvariations in object pose or geometry. To improve the policy generalization, we\nintroduce spatially-grounded parameterized motion primitives in our method\nHACMan++. Specifically, we propose an action representation consisting of three\ncomponents: what primitive type (such as grasp or push) to execute, where the\nprimitive will be grounded (e.g. where the gripper will make contact with the\nworld), and how the primitive motion is executed, such as parameters specifying\nthe push direction or grasp orientation. These three components define a novel\ndiscrete-continuous action space for reinforcement learning. Our framework\nenables robot agents to learn to chain diverse motion primitives together and\nselect appropriate primitive parameters to complete long-horizon manipulation\ntasks. By grounding the primitives on a spatial location in the environment,\nour method is able to effectively generalize across object shape and pose\nvariations. Our approach significantly outperforms existing methods,\nparticularly in complex scenarios demanding both high-level sequential\nreasoning and object generalization. With zero-shot sim-to-real transfer, our\npolicy succeeds in challenging real-world manipulation tasks, with\ngeneralization to unseen objects. Videos can be found on the project website:\nhttps://sgmp-rss2024.github.io.",
      "tldr_zh": "本文提出HACMan++方法，通过引入spatially-grounded motion primitives来提升机器人操作任务的鲁棒性和泛化能力，解决端到端学习在对象姿势或几何变化下的局限性。该方法定义了一个新型discrete-continuous action space，包括基元类型（如抓取或推动）、空间定位（如抓取点）和执行参数（如推动方向），使机器人代理能够学习连接多种动作基元并完成长horizon任务。实验结果显示，HACMan++在复杂场景中显著优于现有方法，并实现了zero-shot sim-to-real transfer，在真实世界挑战性操作任务中泛化到未见对象。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08585v1",
      "published_date": "2024-07-11 15:10:14 UTC",
      "updated_date": "2024-07-11 15:10:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:39:23.892148"
    },
    {
      "arxiv_id": "2407.08583v2",
      "title": "The Synergy between Data and Multi-Modal Large Language Models: A Survey from Co-Development Perspective",
      "title_zh": "数据与多模态大型语言模型之间的协同作用：从共同发展视角的调查",
      "authors": [
        "Zhen Qin",
        "Daoyuan Chen",
        "Wenhao Zhang",
        "Liuyi Yao",
        "Yilun Huang",
        "Bolin Ding",
        "Yaliang Li",
        "Shuiguang Deng"
      ],
      "abstract": "The rapid development of large language models (LLMs) has been witnessed in\nrecent years. Based on the powerful LLMs, multi-modal LLMs (MLLMs) extend the\nmodality from text to a broader spectrum of domains, attracting widespread\nattention due to the broader range of application scenarios. As LLMs and MLLMs\nrely on vast amounts of model parameters and data to achieve emergent\ncapabilities, the importance of data is receiving increasingly widespread\nattention and recognition. Tracing and analyzing recent data-oriented works for\nMLLMs, we find that the development of models and data is not two separate\npaths but rather interconnected. On the one hand, vaster and higher-quality\ndata contribute to better performance of MLLMs; on the other hand, MLLMs can\nfacilitate the development of data. The co-development of multi-modal data and\nMLLMs requires a clear view of 1) at which development stages of MLLMs specific\ndata-centric approaches can be employed to enhance certain MLLM capabilities,\nand 2) how MLLMs, utilizing those capabilities, can contribute to multi-modal\ndata in specific roles. To promote the data-model co-development for MLLM\ncommunity, we systematically review existing works related to MLLMs from the\ndata-model co-development perspective. A regularly maintained project\nassociated with this survey is accessible at\nhttps://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md.",
      "tldr_zh": "这篇调查论文探讨了数据与多模态大型语言模型（MLLMs）之间的协同作用，从共同发展的视角出发，强调高质量数据如何提升 MLLMs 的性能，同时 MLLMs 也能促进多模态数据的生成和优化。论文分析了在 MLLMs 的不同发展阶段（如能力增强），可以使用特定数据中心方法来改进模型，并说明 MLLMs 如何通过其能力反向贡献于数据开发。总体而言，该研究系统回顾了相关工作，提供了一个框架来推动 MLLM 社区的数据-模型共同进步，并附带了一个维护项目链接。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Ongoing work. 21 pages. Related materials are continually maintained\n  and available at\n  https://github.com/modelscope/data-juicer/blob/main/docs/awesome_llm_data.md",
      "pdf_url": "http://arxiv.org/pdf/2407.08583v2",
      "published_date": "2024-07-11 15:08:11 UTC",
      "updated_date": "2024-08-05 10:31:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:39:35.440892"
    },
    {
      "arxiv_id": "2407.08571v2",
      "title": "Multi-Group Proportional Representation in Retrieval",
      "title_zh": "翻译失败",
      "authors": [
        "Alex Oesterling",
        "Claudio Mayrink Verdun",
        "Carol Xuan Long",
        "Alexander Glynn",
        "Lucas Monteiro Paes",
        "Sajani Vithana",
        "Martina Cardone",
        "Flavio P. Calmon"
      ],
      "abstract": "Image search and retrieval tasks can perpetuate harmful stereotypes, erase\ncultural identities, and amplify social disparities. Current approaches to\nmitigate these representational harms balance the number of retrieved items\nacross population groups defined by a small number of (often binary)\nattributes. However, most existing methods overlook intersectional groups\ndetermined by combinations of group attributes, such as gender, race, and\nethnicity. We introduce Multi-Group Proportional Representation (MPR), a novel\nmetric that measures representation across intersectional groups. We develop\npractical methods for estimating MPR, provide theoretical guarantees, and\npropose optimization algorithms to ensure MPR in retrieval. We demonstrate that\nexisting methods optimizing for equal and proportional representation metrics\nmay fail to promote MPR. Crucially, our work shows that optimizing MPR yields\nmore proportional representation across multiple intersectional groups\nspecified by a rich function class, often with minimal compromise in retrieval\naccuracy.",
      "tldr_zh": "该论文探讨了图像检索任务如何强化有害刻板印象、抹杀文化身份并放大社会不平等，现有方法仅关注少量属性的群体代表性，而忽略了intersectional groups（如性别、种族和民族的组合）。为了解决这一问题，研究者引入了Multi-Group Proportional Representation (MPR)指标，并开发了实用估算方法、理论保证和优化算法，以在检索中确保交叉群体的比例代表。结果表明，优化MPR能显著提升多个intersectional groups的代表性，同时对retrieval accuracy的影响最小。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.IT",
        "cs.LG",
        "math.IT",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "48 pages, 33 figures. Accepted as poster at NeurIPS 2024. Code can be\n  found at\n  https://github.com/alex-oesterling/multigroup-proportional-representation",
      "pdf_url": "http://arxiv.org/pdf/2407.08571v2",
      "published_date": "2024-07-11 14:59:17 UTC",
      "updated_date": "2024-10-31 20:30:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:39:46.699716"
    },
    {
      "arxiv_id": "2407.08564v1",
      "title": "The Career Interests of Large Language Models",
      "title_zh": "大型语言模型的职业兴趣",
      "authors": [
        "Meng Hua",
        "Yuan Cheng",
        "Hengshu Zhu"
      ],
      "abstract": "Recent advancements in Large Language Models (LLMs) have significantly\nextended their capabilities, evolving from basic text generation to complex,\nhuman-like interactions. In light of the possibilities that LLMs could assume\nsignificant workplace responsibilities, it becomes imminently necessary to\nexplore LLMs' capacities as professional assistants. This study focuses on the\naspect of career interests by applying the Occupation Network's Interest\nProfiler short form to LLMs as if they were human participants and investigates\ntheir hypothetical career interests and competence, examining how these vary\nwith language changes and model advancements. We analyzed the answers using a\ngeneral linear mixed model approach and found distinct career interest\ninclinations among LLMs, particularly towards the social and artistic domains.\nInterestingly, these preferences did not align with the occupations where LLMs\nexhibited higher competence. This novel approach of using psychometric\ninstruments and sophisticated statistical tools on LLMs unveils fresh\nperspectives on their integration into professional environments, highlighting\nhuman-like tendencies and promoting a reevaluation of LLMs' self-perception and\ncompetency alignment in the workforce.",
      "tldr_zh": "本研究探讨了大型语言模型 (LLMs) 的职业兴趣，旨在评估它们作为专业助手的潜力，通过将职业网络的兴趣评估器 (Occupation Network's Interest Profiler short form) 应用于 LLMs，并分析其答案如何随语言变化和模型进步而变化。研究采用一般线性混合模型 (general linear mixed model) 进行分析，发现 LLMs 更倾向于社会和艺术领域，但这些偏好与它们实际擅长的职业不匹配。这种创新方法使用心理测量工具揭示了 LLMs 的类人倾向，并促进了对其在职场中的自我认知和能力匹配的重新评估。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08564v1",
      "published_date": "2024-07-11 14:54:46 UTC",
      "updated_date": "2024-07-11 14:54:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:40:09.072745"
    },
    {
      "arxiv_id": "2407.08563v1",
      "title": "Vox Populi, Vox AI? Using Language Models to Estimate German Public Opinion",
      "title_zh": "翻译失败",
      "authors": [
        "Leah von der Heyde",
        "Anna-Carolina Haensch",
        "Alexander Wenz"
      ],
      "abstract": "The recent development of large language models (LLMs) has spurred\ndiscussions about whether LLM-generated \"synthetic samples\" could complement or\nreplace traditional surveys, considering their training data potentially\nreflects attitudes and behaviors prevalent in the population. A number of\nmostly US-based studies have prompted LLMs to mimic survey respondents, with\nsome of them finding that the responses closely match the survey data. However,\nseveral contextual factors related to the relationship between the respective\ntarget population and LLM training data might affect the generalizability of\nsuch findings. In this study, we investigate the extent to which LLMs can\nestimate public opinion in Germany, using the example of vote choice. We\ngenerate a synthetic sample of personas matching the individual characteristics\nof the 2017 German Longitudinal Election Study respondents. We ask the LLM\nGPT-3.5 to predict each respondent's vote choice and compare these predictions\nto the survey-based estimates on the aggregate and subgroup levels. We find\nthat GPT-3.5 does not predict citizens' vote choice accurately, exhibiting a\nbias towards the Green and Left parties. While the LLM captures the tendencies\nof \"typical\" voter subgroups, such as partisans, it misses the multifaceted\nfactors swaying individual voter choices. By examining the LLM-based prediction\nof voting behavior in a new context, our study contributes to the growing body\nof research about the conditions under which LLMs can be leveraged for studying\npublic opinion. The findings point to disparities in opinion representation in\nLLMs and underscore the limitations in applying them for public opinion\nestimation.",
      "tldr_zh": "本研究探讨大型语言模型(LLMs)是否能用于估计德国公共舆论，特别以投票选择为例，评估其是否能替代传统调查。研究方法包括生成合成样本，匹配2017年德国纵向选举研究受访者的特征，并使用GPT-3.5预测每个受访者的投票选择，然后与实际调查数据进行比较。结果显示，GPT-3.5的预测准确性较低，偏向绿党和左翼党，尽管它能捕捉典型选民子群体的趋势，如党派倾向，但未能全面反映个体投票的复杂因素。该研究突出了LLMs在意见表示上的差异，并强调其在公共舆论估计中的局限性。",
      "categories": [
        "cs.AI",
        "cs.CY",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08563v1",
      "published_date": "2024-07-11 14:52:18 UTC",
      "updated_date": "2024-07-11 14:52:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:40:13.834866"
    },
    {
      "arxiv_id": "2407.08558v1",
      "title": "ST-Mamba: Spatial-Temporal Mamba for Traffic Flow Estimation Recovery using Limited Data",
      "title_zh": "翻译失败",
      "authors": [
        "Doncheng Yuan",
        "Jianzhe Xue",
        "Jinshan Su",
        "Wenchao Xu",
        "Haibo Zhou"
      ],
      "abstract": "Traffic flow estimation (TFE) is crucial for urban intelligent traffic\nsystems. While traditional on-road detectors are hindered by limited coverage\nand high costs, cloud computing and data mining of vehicular network data, such\nas driving speeds and GPS coordinates, present a promising and cost-effective\nalternative. Furthermore, minimizing data collection can significantly reduce\noverhead. However, limited data can lead to inaccuracies and instability in\nTFE. To address this, we introduce the spatial-temporal Mamba (ST-Mamba), a\ndeep learning model combining a convolutional neural network (CNN) with a Mamba\nframework. ST-Mamba is designed to enhance TFE accuracy and stability by\neffectively capturing the spatial-temporal patterns within traffic flow. Our\nmodel aims to achieve results comparable to those from extensive data sets\nwhile only utilizing minimal data. Simulations using real-world datasets have\nvalidated our model's ability to deliver precise and stable TFE across an urban\nlandscape based on limited data, establishing a cost-efficient solution for\nTFE.",
      "tldr_zh": "该论文提出ST-Mamba模型，用于在数据有限的情况下恢复和估计交通流量(TFE)，以提升城市智能交通系统的效率。ST-Mamba结合卷积神经网络(CNN)和Mamba框架，高效捕获交通流的空间-时间模式，从而提高估计的准确性和稳定性。实验结果显示，该模型使用最小数据即可实现与大规模数据集相当的表现，并在真实城市数据集模拟中验证了其成本高效的潜力，为TFE提供可靠解决方案。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by 2024 IEEE/CIC International Conference on Communications\n  in China (ICCC)",
      "pdf_url": "http://arxiv.org/pdf/2407.08558v1",
      "published_date": "2024-07-11 14:43:03 UTC",
      "updated_date": "2024-07-11 14:43:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:40:25.764502"
    },
    {
      "arxiv_id": "2407.08554v2",
      "title": "Establishing Rigorous and Cost-effective Clinical Trials for Artificial Intelligence Models",
      "title_zh": "为人工智能模型建立严格且成本有效的临床试验",
      "authors": [
        "Wanling Gao",
        "Yunyou Huang",
        "Dandan Cui",
        "Zhuoming Yu",
        "Wenjing Liu",
        "Xiaoshuang Liang",
        "Jiahui Zhao",
        "Jiyue Xie",
        "Hao Li",
        "Li Ma",
        "Ning Ye",
        "Yumiao Kang",
        "Dingfeng Luo",
        "Peng Pan",
        "Wei Huang",
        "Zhongmou Liu",
        "Jizhong Hu",
        "Gangyuan Zhao",
        "Chongrong Jiang",
        "Fan Huang",
        "Tianyi Wei",
        "Suqin Tang",
        "Bingjie Xia",
        "Zhifei Zhang",
        "Jianfeng Zhan"
      ],
      "abstract": "A profound gap persists between artificial intelligence (AI) and clinical\npractice in medicine, primarily due to the lack of rigorous and cost-effective\nevaluation methodologies. State-of-the-art and state-of-the-practice AI model\nevaluations are limited to laboratory studies on medical datasets or direct\nclinical trials with no or solely patient-centered controls. Moreover, the\ncrucial role of clinicians in collaborating with AI, pivotal for determining\nits impact on clinical practice, is often overlooked. For the first time, we\nemphasize the critical necessity for rigorous and cost-effective evaluation\nmethodologies for AI models in clinical practice, featuring\npatient/clinician-centered (dual-centered) AI randomized controlled trials\n(DC-AI RCTs) and virtual clinician-based in-silico trials (VC-MedAI) as an\neffective proxy for DC-AI RCTs. Leveraging 7500 diagnosis records from two-step\ninaugural DC-AI RCTs across 14 medical centers with 125 clinicians, our results\ndemonstrate the necessity of DC-AI RCTs and the effectiveness of VC-MedAI.\nNotably, VC-MedAI performs comparably to human clinicians, replicating insights\nand conclusions from prospective DC-AI RCTs. We envision DC-AI RCTs and\nVC-MedAI as pivotal advancements, presenting innovative and transformative\nevaluation methodologies for AI models in clinical practice, offering a\npreclinical-like setting mirroring conventional medicine, and reshaping\ndevelopment paradigms in a cost-effective and fast-iterative manner. Chinese\nClinical Trial Registration: ChiCTR2400086816.",
      "tldr_zh": "该论文强调了人工智能（AI）在医疗临床实践中的评估缺口，提出采用以患者和临床医生为中心的双重中心AI随机对照试验（DC-AI RCTs）和基于虚拟临床医生的in-silico试验（VC-MedAI），以实现严格且成本有效的评估方法。研究利用7500条诊断记录，从14个医疗中心和125名临床医生开展的两步DC-AI RCTs，证明了这些方法的必要性，并显示VC-MedAI的表现可与人类临床医生媲美，能复制真实试验的见解。总体而言，该框架有望革新AI模型的临床评估范式，提供快速迭代的预临床环境，促进AI在医疗中的可靠应用。",
      "categories": [
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.AI",
      "comment": "24 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.08554v2",
      "published_date": "2024-07-11 14:37:08 UTC",
      "updated_date": "2024-07-28 15:33:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:40:41.310636"
    },
    {
      "arxiv_id": "2407.08550v1",
      "title": "Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility",
      "title_zh": "将大语言模型整合到生产系统中以增强任务自动化和灵活性",
      "authors": [
        "Yuchen Xia",
        "Jize Zhang",
        "Nasser Jazdi",
        "Michael Weyrich"
      ],
      "abstract": "This paper introduces a novel approach to integrating large language model\n(LLM) agents into automated production systems, aimed at enhancing task\nautomation and flexibility. We organize production operations within a\nhierarchical framework based on the automation pyramid. Atomic operation\nfunctionalities are modeled as microservices, which are executed through\ninterface invocation within a dedicated digital twin system. This allows for a\nscalable and flexible foundation for orchestrating production processes. In\nthis digital twin system, low-level, hardware-specific data is semantically\nenriched and made interpretable for LLMs for production planning and control\ntasks. Large language model agents are systematically prompted to interpret\nthese production-specific data and knowledge. Upon receiving a user request or\nidentifying a triggering event, the LLM agents generate a process plan. This\nplan is then decomposed into a series of atomic operations, executed as\nmicroservices within the real-world automation system. We implement this\noverall approach on an automated modular production facility at our laboratory,\ndemonstrating how the LLMs can handle production planning and control tasks\nthrough a concrete case study. This results in an intuitive production facility\nwith higher levels of task automation and flexibility. Finally, we reveal the\nseveral limitations in realizing the full potential of the large language\nmodels in autonomous systems and point out promising benefits. Demos of this\nseries of ongoing research series can be accessed at:\nhttps://github.com/YuchenXia/GPT4IndustrialAutomation",
      "tldr_zh": "本文提出了一种将 Large Language Models (LLM) 代理集成到自动化生产系统的新方法，以提升任务自动化和灵活性。方法基于自动化金字塔的层次框架，将原子操作功能建模为微服务，并在数字孪生系统中对硬件数据进行语义丰富，使其可供 LLM 解释生成过程计划。实验在实验室的模块化生产设施中验证，实现了更直观的控制和更高灵活性，同时指出了 LLM 在自主系统中的局限性及其潜在益处。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.MA",
        "cs.RO",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08550v1",
      "published_date": "2024-07-11 14:34:43 UTC",
      "updated_date": "2024-07-11 14:34:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:40:50.661554"
    },
    {
      "arxiv_id": "2407.08516v5",
      "title": "Converging Paradigms: The Synergy of Symbolic and Connectionist AI in LLM-Empowered Autonomous Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyi Xiong",
        "Zhiyuan Wang",
        "Xuhong Li",
        "Jiang Bian",
        "Zeke Xie",
        "Shahid Mumtaz",
        "Anwer Al-Dulaimi",
        "Laura E. Barnes"
      ],
      "abstract": "This article explores the convergence of connectionist and symbolic\nartificial intelligence (AI), from historical debates to contemporary\nadvancements. Traditionally considered distinct paradigms, connectionist AI\nfocuses on neural networks, while symbolic AI emphasizes symbolic\nrepresentation and logic. Recent advancements in large language models (LLMs),\nexemplified by ChatGPT and GPT-4, highlight the potential of connectionist\narchitectures in handling human language as a form of symbols. The study argues\nthat LLM-empowered Autonomous Agents (LAAs) embody this paradigm convergence.\nBy utilizing LLMs for text-based knowledge modeling and representation, LAAs\nintegrate neuro-symbolic AI principles, showcasing enhanced reasoning and\ndecision-making capabilities. Comparing LAAs with Knowledge Graphs within the\nneuro-symbolic AI theme highlights the unique strengths of LAAs in mimicking\nhuman-like reasoning processes, scaling effectively with large datasets, and\nleveraging in-context samples without explicit re-training. The research\nunderscores promising avenues in neuro-vector-symbolic integration,\ninstructional encoding, and implicit reasoning, aimed at further enhancing LAA\ncapabilities. By exploring the progression of neuro-symbolic AI and proposing\nfuture research trajectories, this work advances the understanding and\ndevelopment of AI technologies.",
      "tldr_zh": "这篇论文探讨了connectionist AI（基于神经网络）和symbolic AI（强调符号表示和逻辑）的融合，从历史争论到现代进展，特别强调large language models (LLMs)如ChatGPT和GPT-4在处理符号方面的潜力。论文认为LLM-empowered Autonomous Agents (LAAs)体现了neuro-symbolic AI原则，通过LLMs进行文本知识建模和表示，提升了代理的推理和决策能力。相比Knowledge Graphs，LAAs在模仿人类推理、扩展大型数据集以及利用in-context samples方面表现出独特优势，并提出未来研究方向，如neuro-vector-symbolic integration和implicit reasoning，以推进AI技术的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08516v5",
      "published_date": "2024-07-11 14:00:53 UTC",
      "updated_date": "2024-10-14 16:55:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:41:03.164983"
    },
    {
      "arxiv_id": "2407.08515v2",
      "title": "15M Multimodal Facial Image-Text Dataset",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Dai",
        "YuTang Li",
        "YingGe Liu",
        "Mingming Jia",
        "Zhang YuanHui",
        "Guoyin Wang"
      ],
      "abstract": "Currently, image-text-driven multi-modal deep learning models have\ndemonstrated their outstanding potential in many fields. In practice, tasks\ncentered around facial images have broad application prospects. This paper\npresents \\textbf{FaceCaption-15M}, a large-scale, diverse, and high-quality\ndataset of facial images accompanied by their natural language descriptions\n(facial image-to-text). This dataset aims to facilitate a study on\nface-centered tasks. FaceCaption-15M comprises over 15 million pairs of facial\nimages and their corresponding natural language descriptions of facial\nfeatures, making it the largest facial image-caption dataset to date. We\nconducted a comprehensive analysis of image quality, text naturalness, text\ncomplexity, and text-image relevance to demonstrate the superiority of\nFaceCaption-15M. To validate the effectiveness of FaceCaption-15M, we first\ntrained a facial language-image pre-training model (FLIP, similar to CLIP) to\nalign facial image with its corresponding captions in feature space.\nSubsequently, using both image and text encoders and fine-tuning only the\nlinear layer, our FLIP-based models achieved state-of-the-art results on two\nchallenging face-centered tasks. The purpose is to promote research in the\nfield of face-related tasks through the availability of the proposed\nFaceCaption-15M dataset. All data, codes, and models are publicly available.\nhttps://huggingface.co/datasets/OpenFace-CQUPT/FaceCaption-15M",
      "tldr_zh": "本文介绍了 FaceCaption-15M，这是一个包含超过 1500 万对面部图像和自然语言描述的大型数据集，是目前最大的面部图像-文本数据集，旨在推动面部相关任务的研究。数据集经过全面分析，展示了其在图像质量、文本自然性、复杂性和相关性方面的优势。作者训练了 FLIP 模型（类似于 CLIP），通过对齐图像和描述特征空间，仅微调线性层即在两个挑战性面部任务上达到了最先进的结果。所有数据、代码和模型已公开可用，以促进该领域的进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "15 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08515v2",
      "published_date": "2024-07-11 14:00:14 UTC",
      "updated_date": "2024-07-12 01:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:41:13.809942"
    },
    {
      "arxiv_id": "2407.08500v2",
      "title": "Latent Conditional Diffusion-based Data Augmentation for Continuous-Time Dynamic Graph Model",
      "title_zh": "基于潜在条件扩散的数据增强，用于连续时间动态图模型",
      "authors": [
        "Yuxing Tian",
        "Yiyan Qi",
        "Aiwen Jiang",
        "Qi Huang",
        "Jian Guo"
      ],
      "abstract": "Continuous-Time Dynamic Graph (CTDG) precisely models evolving real-world\nrelationships, drawing heightened interest in dynamic graph learning across\nacademia and industry. However, existing CTDG models encounter challenges\nstemming from noise and limited historical data. Graph Data Augmentation (GDA)\nemerges as a critical solution, yet current approaches primarily focus on\nstatic graphs and struggle to effectively address the dynamics inherent in\nCTDGs. Moreover, these methods often demand substantial domain expertise for\nparameter tuning and lack theoretical guarantees for augmentation efficacy. To\naddress these issues, we propose Conda, a novel latent diffusion-based GDA\nmethod tailored for CTDGs. Conda features a sandwich-like architecture,\nincorporating a Variational Auto-Encoder (VAE) and a conditional diffusion\nmodel, aimed at generating enhanced historical neighbor embeddings for target\nnodes. Unlike conventional diffusion models trained on entire graphs via\npre-training, Conda requires historical neighbor sequence embeddings of target\nnodes for training, thus facilitating more targeted augmentation. We integrate\nConda into the CTDG model and adopt an alternating training strategy to\noptimize performance. Extensive experimentation across six widely used\nreal-world datasets showcases the consistent performance improvement of our\napproach, particularly in scenarios with limited historical data.",
      "tldr_zh": "本文提出 Conda，一种基于潜在条件扩散的 Graph Data Augmentation (GDA) 方法，针对 Continuous-Time Dynamic Graph (CTDG) 模型中噪声和历史数据有限的问题。Conda 采用 sandwich-like 架构，结合 Variational Auto-Encoder (VAE) 和 conditional diffusion model，来生成目标节点的增强历史邻居嵌入，从而实现更针对性的动态图数据增强。与传统方法不同，该方法仅需目标节点的歷史邻居序列嵌入进行训练，并通过交替训练策略集成到 CTDG 模型中优化性能。在六个真实数据集上的广泛实验显示，Conda 显著提高了模型性能，尤其在历史数据有限的场景下。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08500v2",
      "published_date": "2024-07-11 13:35:22 UTC",
      "updated_date": "2024-07-20 06:44:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:41:27.447721"
    },
    {
      "arxiv_id": "2407.08497v2",
      "title": "CE-QArg: Counterfactual Explanations for Quantitative Bipolar Argumentation Frameworks (Technical Report)",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang Yin",
        "Nico Potyka",
        "Francesca Toni"
      ],
      "abstract": "There is a growing interest in understanding arguments' strength in\nQuantitative Bipolar Argumentation Frameworks (QBAFs). Most existing studies\nfocus on attribution-based methods that explain an argument's strength by\nassigning importance scores to other arguments but fail to explain how to\nchange the current strength to a desired one. To solve this issue, we introduce\ncounterfactual explanations for QBAFs. We discuss problem variants and propose\nan iterative algorithm named Counterfactual Explanations for Quantitative\nbipolar Argumentation frameworks (CE-QArg). CE-QArg can identify valid and\ncost-effective counterfactual explanations based on two core modules, polarity\nand priority, which help determine the updating direction and magnitude for\neach argument, respectively. We discuss some formal properties of our\ncounterfactual explanations and empirically evaluate CE-QArg on randomly\ngenerated QBAFs.",
      "tldr_zh": "该研究针对Quantitative Bipolar Argumentation Frameworks (QBAFs)中论证强度的解释问题，指出现有归因方法虽能分配重要性分数，但无法指导如何将当前强度调整至期望值。作者引入counterfactual explanations for QBAFs，并提出迭代算法CE-QArg，该算法利用polarity和priority模块来确定每个论证的更新方向和幅度，从而生成有效且成本优化的解释。实验结果显示，CE-QArg在随机生成的QBAFs上表现出良好性能，并满足某些正式属性，为QBAFs的解释性增强提供了新框架。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "This paper has been accepted at KR 2024 (21st International\n  Conference on Principles of Knowledge Representation and Reasoning)",
      "pdf_url": "http://arxiv.org/pdf/2407.08497v2",
      "published_date": "2024-07-11 13:34:11 UTC",
      "updated_date": "2024-11-11 11:19:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:41:37.724815"
    },
    {
      "arxiv_id": "2407.08488v2",
      "title": "Lynx: An Open Source Hallucination Evaluation Model",
      "title_zh": "Lynx：一个开源幻觉评估模型",
      "authors": [
        "Selvan Sunitha Ravi",
        "Bartosz Mielczarek",
        "Anand Kannappan",
        "Douwe Kiela",
        "Rebecca Qian"
      ],
      "abstract": "Retrieval Augmented Generation (RAG) techniques aim to mitigate\nhallucinations in Large Language Models (LLMs). However, LLMs can still produce\ninformation that is unsupported or contradictory to the retrieved contexts. We\nintroduce LYNX, a SOTA hallucination detection LLM that is capable of advanced\nreasoning on challenging real-world hallucination scenarios. To evaluate LYNX,\nwe present HaluBench, a comprehensive hallucination evaluation benchmark,\nconsisting of 15k samples sourced from various real-world domains. Our\nexperiment results show that LYNX outperforms GPT-4o, Claude-3-Sonnet, and\nclosed and open-source LLM-as-a-judge models on HaluBench. We release LYNX,\nHaluBench and our evaluation code for public access.",
      "tldr_zh": "本文提出 LYNX，一种开源的 SOTA 幻觉检测模型，旨在通过高级推理评估 Large Language Models (LLMs) 中由 Retrieval Augmented Generation (RAG) 技术未能完全解决的幻觉问题。研究团队构建了 HaluBench 基准，该基准包含15k个真实领域样本，用于全面测试幻觉场景。实验结果显示，LYNX 在 HaluBench 上超越了 GPT-4o、Claude-3-Sonnet 等模型，并已公开发布 LYNX、基准和评估代码，以推动相关研究。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08488v2",
      "published_date": "2024-07-11 13:22:17 UTC",
      "updated_date": "2024-07-22 18:41:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:41:50.062540"
    },
    {
      "arxiv_id": "2407.08479v1",
      "title": "Robust Generalization of Graph Neural Networks for Carrier Scheduling",
      "title_zh": "翻译失败",
      "authors": [
        "Daniel F. Perez-Ramirez",
        "Carlos Pérez-Penichet",
        "Nicolas Tsiftes",
        "Dejan Kostic",
        "Magnus Boman",
        "Thiemo Voigt"
      ],
      "abstract": "Battery-free sensor tags are devices that leverage backscatter techniques to\ncommunicate with standard IoT devices, thereby augmenting a network's sensing\ncapabilities in a scalable way. For communicating, a sensor tag relies on an\nunmodulated carrier provided by a neighboring IoT device, with a schedule\ncoordinating this provisioning across the network. Carrier\nscheduling--computing schedules to interrogate all sensor tags while minimizing\nenergy, spectrum utilization, and latency--is an NP-Hard optimization problem.\nRecent work introduces learning-based schedulers that achieve resource savings\nover a carefully-crafted heuristic, generalizing to networks of up to 60 nodes.\nHowever, we find that their advantage diminishes in networks with hundreds of\nnodes, and degrades further in larger setups. This paper introduces\nRobustGANTT, a GNN-based scheduler that improves generalization (without\nre-training) to networks up to 1000 nodes (100x training topology sizes).\nRobustGANTT not only achieves better and more consistent generalization, but\nalso computes schedules requiring up to 2x less resources than existing\nsystems. Our scheduler exhibits average runtimes of hundreds of milliseconds,\nallowing it to react fast to changing network conditions. Our work not only\nimproves resource utilization in large-scale backscatter networks, but also\noffers valuable insights in learning-based scheduling.",
      "tldr_zh": "该论文探讨了Carrier Scheduling问题，这是一个NP-Hard优化任务，用于协调Battery-free sensor tags在IoT网络中的通信，以最小化能量、频谱利用和延迟。作者提出RobustGANTT，一种基于Graph Neural Networks (GNN)的调度器，能够在不需重新训练的情况下泛化到高达1000节点的网络（比训练拓扑大100倍）。实验结果显示，RobustGANTT比现有系统节省高达2倍资源，并以数百毫秒的平均运行时间快速响应网络变化，从而提升大规模backscatter networks的资源利用并提供学习-based调度的宝贵见解。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 Pages, 12 Figures. Pre-print, under review",
      "pdf_url": "http://arxiv.org/pdf/2407.08479v1",
      "published_date": "2024-07-11 13:13:24 UTC",
      "updated_date": "2024-07-11 13:13:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:42:02.436477"
    },
    {
      "arxiv_id": "2407.08473v1",
      "title": "Natural language is not enough: Benchmarking multi-modal generative AI for Verilog generation",
      "title_zh": "翻译失败",
      "authors": [
        "Kaiyan Chang",
        "Zhirong Chen",
        "Yunhao Zhou",
        "Wenlong Zhu",
        "kun wang",
        "Haobo Xu",
        "Cangyuan Li",
        "Mengdi Wang",
        "Shengwen Liang",
        "Huawei Li",
        "Yinhe Han",
        "Ying Wang"
      ],
      "abstract": "Natural language interfaces have exhibited considerable potential in the\nautomation of Verilog generation derived from high-level specifications through\nthe utilization of large language models, garnering significant attention.\nNevertheless, this paper elucidates that visual representations contribute\nessential contextual information critical to design intent for hardware\narchitectures possessing spatial complexity, potentially surpassing the\nefficacy of natural-language-only inputs. Expanding upon this premise, our\npaper introduces an open-source benchmark for multi-modal generative models\ntailored for Verilog synthesis from visual-linguistic inputs, addressing both\nsingular and complex modules. Additionally, we introduce an open-source visual\nand natural language Verilog query language framework to facilitate efficient\nand user-friendly multi-modal queries. To evaluate the performance of the\nproposed multi-modal hardware generative AI in Verilog generation tasks, we\ncompare it with a popular method that relies solely on natural language. Our\nresults demonstrate a significant accuracy improvement in the multi-modal\ngenerated Verilog compared to queries based solely on natural language. We hope\nto reveal a new approach to hardware design in the large-hardware-design-model\nera, thereby fostering a more diversified and productive approach to hardware\ndesign.",
      "tldr_zh": "本论文指出，仅使用自然语言生成 Verilog 代码不足以捕捉硬件架构的空间复杂性，视觉表示能提供关键的上下文信息，从而提升设计意图的准确性。研究团队引入了一个开源基准，用于评估多模态生成 AI 模型从视觉-语言输入合成 Verilog，包括单一和复杂模块，并开发了一个开源框架支持高效的多模态查询。实验结果显示，与仅依赖自然语言的方法相比，多模态方法在 Verilog 生成任务中准确性显著提升。最终，该工作旨在为大型硬件设计模型时代开辟新途径，促进硬件设计的多样化和生产力。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "Accepted by ICCAD 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08473v1",
      "published_date": "2024-07-11 13:10:09 UTC",
      "updated_date": "2024-07-11 13:10:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:42:14.750828"
    },
    {
      "arxiv_id": "2407.08470v1",
      "title": "Brain Tumor Segmentation in MRI Images with 3D U-Net and Contextual Transformer",
      "title_zh": "脑",
      "authors": [
        "Thien-Qua T. Nguyen",
        "Hieu-Nghia Nguyen",
        "Thanh-Hieu Bui",
        "Thien B. Nguyen-Tat",
        "Vuong M. Ngo"
      ],
      "abstract": "This research presents an enhanced approach for precise segmentation of brain\ntumor masses in magnetic resonance imaging (MRI) using an advanced 3D-UNet\nmodel combined with a Context Transformer (CoT). By architectural expansion\nCoT, the proposed model extends its architecture to a 3D format, integrates it\nsmoothly with the base model to utilize the complex contextual information\nfound in MRI scans, emphasizing how elements rely on each other across an\nextended spatial range. The proposed model synchronizes tumor mass\ncharacteristics from CoT, mutually reinforcing feature extraction, facilitating\nthe precise capture of detailed tumor mass structures, including location,\nsize, and boundaries. Several experimental results present the outstanding\nsegmentation performance of the proposed method in comparison to current\nstate-of-the-art approaches, achieving Dice score of 82.0%, 81.5%, 89.0% for\nEnhancing Tumor, Tumor Core and Whole Tumor, respectively, on BraTS2019.",
      "tldr_zh": "本研究提出了一种改进的脑肿瘤分割方法，使用 3D U-Net 模型结合 Contextual Transformer (CoT)，针对 MRI 图像实现精确识别。CoT 被扩展到 3D 格式，并与基础模型无缝整合，利用复杂上下文信息来同步肿瘤特征，增强特征提取并准确捕捉肿瘤的位置、大小和边界。实验结果显示，该方法在 BraTS2019 数据集上取得了出色的性能，分别获得 Enhancing Tumor 82.0%、Tumor Core 81.5% 和 Whole Tumor 89.0% 的 Dice score，优于现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08470v1",
      "published_date": "2024-07-11 13:04:20 UTC",
      "updated_date": "2024-07-11 13:04:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:42:27.712975"
    },
    {
      "arxiv_id": "2407.08464v2",
      "title": "TLDR: Unsupervised Goal-Conditioned RL via Temporal Distance-Aware Representations",
      "title_zh": "翻译失败",
      "authors": [
        "Junik Bae",
        "Kwanyoung Park",
        "Youngwoon Lee"
      ],
      "abstract": "Unsupervised goal-conditioned reinforcement learning (GCRL) is a promising\nparadigm for developing diverse robotic skills without external supervision.\nHowever, existing unsupervised GCRL methods often struggle to cover a wide\nrange of states in complex environments due to their limited exploration and\nsparse or noisy rewards for GCRL. To overcome these challenges, we propose a\nnovel unsupervised GCRL method that leverages TemporaL Distance-aware\nRepresentations (TLDR). Based on temporal distance, TLDR selects faraway goals\nto initiate exploration and computes intrinsic exploration rewards and\ngoal-reaching rewards. Specifically, our exploration policy seeks states with\nlarge temporal distances (i.e. covering a large state space), while the\ngoal-conditioned policy learns to minimize the temporal distance to the goal\n(i.e. reaching the goal). Our results in six simulated locomotion environments\ndemonstrate that TLDR significantly outperforms prior unsupervised GCRL methods\nin achieving a wide range of states.",
      "tldr_zh": "这篇论文提出了一种名为 TLDR 的 unsupervised goal-conditioned reinforcement learning (GCRL) 方法，通过 Temporal Distance-aware Representations 来解决现有方法在复杂环境中探索有限和奖励稀疏的问题。TLDR 基于 temporal distance 选择远距离目标启动探索，并计算内在探索奖励和目标到达奖励，从而使探索策略覆盖更大的状态空间，同时使目标条件策略最小化 temporal distance 以实现目标。实验结果显示，在六个模拟的 locomotion environments 中，TLDR 显著优于现有 unsupervised GCRL 方法，在实现广泛的状态覆盖方面表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CoRL 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08464v2",
      "published_date": "2024-07-11 13:01:18 UTC",
      "updated_date": "2024-12-09 08:50:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:42:39.153949"
    },
    {
      "arxiv_id": "2407.08448v2",
      "title": "Paving the way toward foundation models for irregular and unaligned Satellite Image Time Series",
      "title_zh": "翻译失败",
      "authors": [
        "Iris Dumeur",
        "Silvia Valero",
        "Jordi Inglada"
      ],
      "abstract": "Although recently several foundation models for satellite remote sensing\nimagery have been proposed, they fail to address major challenges of\nreal/operational applications. Indeed, embeddings that don't take into account\nthe spectral, spatial and temporal dimensions of the data as well as the\nirregular or unaligned temporal sampling are of little use for most real world\nuses. As a consequence, we propose an ALIgned Sits Encoder (ALISE), a novel\napproach that leverages the spatial, spectral, and temporal dimensions of\nirregular and unaligned SITS while producing aligned latent representations.\nUnlike SSL models currently available for SITS, ALISE incorporates a flexible\nquery mechanism to project the SITS into a common and learned temporal\nprojection space. Additionally, thanks to a multi-view framework, we explore\nintegration of instance discrimination along a masked autoencoding task to\nSITS. The quality of the produced representation is assessed through three\ndownstream tasks: crop segmentation (PASTIS), land cover segmentation\n(MultiSenGE), and a novel crop change detection dataset. Furthermore, the\nchange detection task is performed without supervision. The results suggest\nthat the use of aligned representations is more effective than previous SSL\nmethods for linear probing segmentation tasks.",
      "tldr_zh": "该论文针对卫星图像时间序列（SITS）的光谱、空间和时间维度，以及不规则或未对齐采样等问题，提出了一种新型编码器 ALISE（ALIgned SITS Encoder），它通过灵活的查询机制将 SITS 投影到共同的学习时间投影空间中，并结合多视图框架整合实例区分和掩码自编码任务，以生成对齐的潜在表示。相比现有 SSL 方法，ALISE 在下游任务中表现出色，包括作物分割（PASTIS）、土地覆盖分割（MultiSenGE）和一个新的无监督作物变化检测数据集。实验结果表明，使用对齐表示在线性探测分割任务上更有效，为卫星遥感基础模型的发展铺平了道路。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08448v2",
      "published_date": "2024-07-11 12:42:10 UTC",
      "updated_date": "2024-09-30 08:13:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:42:51.700618"
    },
    {
      "arxiv_id": "2407.08442v2",
      "title": "How Deep is your Guess? A Fresh Perspective on Deep Learning for Medical Time-Series Imputation",
      "title_zh": "翻译失败",
      "authors": [
        "Linglong Qian",
        "Tao Wang",
        "Jun Wang",
        "Hugh Logan Ellis",
        "Robin Mitra",
        "Richard Dobson",
        "Zina Ibrahim"
      ],
      "abstract": "We present a comprehensive analysis of deep learning approaches for\nElectronic Health Record (EHR) time-series imputation, examining how\narchitectural and framework biases combine to influence model performance. Our\ninvestigation reveals varying capabilities of deep imputers in capturing\ncomplex spatiotemporal dependencies within EHRs, and that model effectiveness\ndepends on how its combined biases align with medical time-series\ncharacteristics. Our experimental evaluation challenges common assumptions\nabout model complexity, demonstrating that larger models do not necessarily\nimprove performance. Rather, carefully designed architectures can better\ncapture the complex patterns inherent in clinical data. The study highlights\nthe need for imputation approaches that prioritise clinically meaningful data\nreconstruction over statistical accuracy. Our experiments show imputation\nperformance variations of up to 20\\% based on preprocessing and implementation\nchoices, emphasising the need for standardised benchmarking methodologies.\nFinally, we identify critical gaps between current deep imputation methods and\nmedical requirements, highlighting the importance of integrating clinical\ninsights to achieve more reliable imputation approaches for healthcare\napplications.",
      "tldr_zh": "这篇论文对深度学习在Electronic Health Record (EHR) 时间序列插值中的应用进行了全面分析，探讨了架构和框架偏差如何影响模型捕捉复杂时空依赖(spatiotemporal dependencies)的能力。研究发现，模型的有效性取决于其偏差与医疗数据特性的匹配，而非模型复杂度，实验证明更大的模型并不一定提升性能，反而精心设计的架构更能捕捉临床数据的模式。最终，该研究强调了优先考虑临床意义的数据重建、标准化基准测试的必要性，并呼吁整合临床洞见以改进EHR插值方法。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08442v2",
      "published_date": "2024-07-11 12:33:28 UTC",
      "updated_date": "2025-02-04 00:12:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:43:02.964054"
    },
    {
      "arxiv_id": "2407.08441v2",
      "title": "Are Large Language Models Really Bias-Free? Jailbreak Prompts for Assessing Adversarial Robustness to Bias Elicitation",
      "title_zh": "大型语言模型真的无偏见吗？用于评估对偏见诱发的对抗鲁",
      "authors": [
        "Riccardo Cantini",
        "Giada Cosenza",
        "Alessio Orsino",
        "Domenico Talia"
      ],
      "abstract": "Large Language Models (LLMs) have revolutionized artificial intelligence,\ndemonstrating remarkable computational power and linguistic capabilities.\nHowever, these models are inherently prone to various biases stemming from\ntheir training data. These include selection, linguistic, and confirmation\nbiases, along with common stereotypes related to gender, ethnicity, sexual\norientation, religion, socioeconomic status, disability, and age. This study\nexplores the presence of these biases within the responses given by the most\nrecent LLMs, analyzing the impact on their fairness and reliability. We also\ninvestigate how known prompt engineering techniques can be exploited to\neffectively reveal hidden biases of LLMs, testing their adversarial robustness\nagainst jailbreak prompts specially crafted for bias elicitation. Extensive\nexperiments are conducted using the most widespread LLMs at different scales,\nconfirming that LLMs can still be manipulated to produce biased or\ninappropriate responses, despite their advanced capabilities and sophisticated\nalignment processes. Our findings underscore the importance of enhancing\nmitigation techniques to address these safety issues, toward a more sustainable\nand inclusive artificial intelligence.",
      "tldr_zh": "本研究评估了大型语言模型（LLMs）是否真正无偏见，焦点在于其固有的选择偏见、语言偏见、确认偏见以及与性别、种族等相关的刻板印象对模型公平性和可靠性的影响。研究者利用提示工程技术设计 jailbreak prompts 来测试 LLMs 的对抗鲁棒性，通过广泛实验证明这些模型仍可被操纵产生偏见或不适当响应。结果强调了加强偏见缓解技术的必要性，以推动更可持续和包容的人工智能发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08441v2",
      "published_date": "2024-07-11 12:30:19 UTC",
      "updated_date": "2025-02-13 11:30:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:43:14.661212"
    },
    {
      "arxiv_id": "2407.08440v4",
      "title": "Beyond Instruction Following: Evaluating Inferential Rule Following of Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Wangtao Sun",
        "Chenxiang Zhang",
        "XueYou Zhang",
        "Xuanqing Yu",
        "Ziyang Huang",
        "Pei Chen",
        "Haotian Xu",
        "Shizhu He",
        "Jun Zhao",
        "Kang Liu"
      ],
      "abstract": "Although Large Language Models (LLMs) have demonstrated strong ability, they\nare further supposed to be controlled and guided by in real-world scenarios to\nbe safe, accurate, and intelligent. This demands the possession of capability\nof LLMs. However, no prior work has made a clear evaluation of the inferential\nrule-following capability of LLMs. Previous studies that try to evaluate the\ninferential rule-following capability of LLMs fail to distinguish the\ninferential rule-following scenarios from the instruction-following scenarios.\nTherefore, this paper first clarifies the concept of inferential rule-following\nand proposes a comprehensive benchmark, RuleBench, to evaluate a diversified\nrange of inferential rule-following abilities. Our experimental results on a\nvariety of LLMs show that they are still limited in following rules. Our\nanalysis based on the evaluation results provides insights into the\nimprovements for LLMs toward a better inferential rule-following intelligent\nagent. We further propose Inferential Rule-Following Tuning (IRFT). The\nexperimental results show that through IRFT, LLMs can learn abstract\nrule-following abilities from purely synthetic data and then generalize to\nRuleBench. The data and code can be found at:\nhttps://anonymous.4open.science/r/llm-rule-following-B3E3/",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 的推理规则遵循能力，强调其在现实场景中实现安全、准确和智能的重要性。该研究首先澄清了推理规则遵循的概念，并提出一个全面基准 RuleBench，以评估 LLMs 在多样化推理规则遵循任务中的表现。实验结果显示，现有 LLMs 在遵循规则方面仍存在局限，但通过提出的 Inferential Rule-Following Tuning (IRFT) 方法，利用纯合成数据训练，LLMs 可以学会抽象规则遵循能力并泛化到 RuleBench，从而为提升其智能代理性能提供改进路径。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08440v4",
      "published_date": "2024-07-11 12:26:55 UTC",
      "updated_date": "2024-10-17 07:00:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:43:27.381703"
    },
    {
      "arxiv_id": "2407.08428v1",
      "title": "A Comprehensive Survey on Human Video Generation: Challenges, Methods, and Insights",
      "title_zh": "关于人类视频生成的全面调查：挑战、方法和洞见",
      "authors": [
        "Wentao Lei",
        "Jinting Wang",
        "Fengji Ma",
        "Guanjie Huang",
        "Li Liu"
      ],
      "abstract": "Human video generation is a dynamic and rapidly evolving task that aims to\nsynthesize 2D human body video sequences with generative models given control\nconditions such as text, audio, and pose. With the potential for wide-ranging\napplications in film, gaming, and virtual communication, the ability to\ngenerate natural and realistic human video is critical. Recent advancements in\ngenerative models have laid a solid foundation for the growing interest in this\narea. Despite the significant progress, the task of human video generation\nremains challenging due to the consistency of characters, the complexity of\nhuman motion, and difficulties in their relationship with the environment. This\nsurvey provides a comprehensive review of the current state of human video\ngeneration, marking, to the best of our knowledge, the first extensive\nliterature review in this domain. We start with an introduction to the\nfundamentals of human video generation and the evolution of generative models\nthat have facilitated the field's growth. We then examine the main methods\nemployed for three key sub-tasks within human video generation: text-driven,\naudio-driven, and pose-driven motion generation. These areas are explored\nconcerning the conditions that guide the generation process. Furthermore, we\noffer a collection of the most commonly utilized datasets and the evaluation\nmetrics that are crucial in assessing the quality and realism of generated\nvideos. The survey concludes with a discussion of the current challenges in the\nfield and suggests possible directions for future research. The goal of this\nsurvey is to offer the research community a clear and holistic view of the\nadvancements in human video generation, highlighting the milestones achieved\nand the challenges that lie ahead.",
      "tldr_zh": "这篇论文对Human video generation进行了全面调查，聚焦于使用生成模型合成2D人类视频序列的挑战、方法和见解，该任务受文本、音频和姿势等控制条件驱动。尽管生成模型取得了显著进展，但仍面临人物一致性、人类运动复杂性和环境互动等难题。论文详细审视了文本-driven、音频-driven和姿势-driven的子任务，介绍了常用数据集和评估指标，并讨论了当前挑战以及未来研究方向，以为研究社区提供整体视角。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08428v1",
      "published_date": "2024-07-11 12:09:05 UTC",
      "updated_date": "2024-07-11 12:09:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:43:40.018434"
    },
    {
      "arxiv_id": "2407.08422v2",
      "title": "On the (In)Security of LLM App Stores",
      "title_zh": "翻译失败",
      "authors": [
        "Xinyi Hou",
        "Yanjie Zhao",
        "Haoyu Wang"
      ],
      "abstract": "LLM app stores have seen rapid growth, leading to the proliferation of\nnumerous custom LLM apps. However, this expansion raises security concerns. In\nthis study, we propose a three-layer concern framework to identify the\npotential security risks of LLM apps, i.e., LLM apps with abusive potential,\nLLM apps with malicious intent, and LLM apps with exploitable vulnerabilities.\nOver five months, we collected 786,036 LLM apps from six major app stores: GPT\nStore, FlowGPT, Poe, Coze, Cici, and Character.AI. Our research integrates\nstatic and dynamic analysis, the development of a large-scale toxic word\ndictionary (i.e., ToxicDict) comprising over 31,783 entries, and automated\nmonitoring tools to identify and mitigate threats. We uncovered that 15,146\napps had misleading descriptions, 1,366 collected sensitive personal\ninformation against their privacy policies, and 15,996 generated harmful\ncontent such as hate speech, self-harm, extremism, etc. Additionally, we\nevaluated the potential for LLM apps to facilitate malicious activities,\nfinding that 616 apps could be used for malware generation, phishing, etc. Our\nfindings highlight the urgent need for robust regulatory frameworks and\nenhanced enforcement mechanisms.",
      "tldr_zh": "本研究探讨了LLM应用商店的安全问题，提出一个三层关注框架，包括LLM apps的滥用潜力、恶意意图和可利用漏洞。研究团队从GPT Store、FlowGPT、Poe、Coze、Cici和Character.AI等六大平台收集了786,036个LLM apps，并结合静态和动态分析、ToxicDict（一个包含31,783条目的毒害词字典）以及自动化监控工具进行威胁识别。结果显示，15,146个apps有误导性描述，1,366个apps违反隐私政策收集敏感信息，15,996个apps生成有害内容（如仇恨言论、自残和极端主义），且616个apps可用于恶意活动如恶意软件生成和钓鱼。该研究强调了建立robust regulatory frameworks和enhanced enforcement mechanisms的迫切需求，以提升LLM apps的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08422v2",
      "published_date": "2024-07-11 12:03:32 UTC",
      "updated_date": "2024-07-29 11:18:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:43:51.301711"
    },
    {
      "arxiv_id": "2407.08410v2",
      "title": "Specialized curricula for training vision-language models in retinal image analysis",
      "title_zh": "针对视网膜图像分析训练视觉语言模型的专业课程",
      "authors": [
        "Robbie Holland",
        "Thomas R. P. Taylor",
        "Christopher Holmes",
        "Sophie Riedl",
        "Julia Mai",
        "Maria Patsiamanidi",
        "Dimitra Mitsopoulou",
        "Paul Hager",
        "Philip Müller",
        "Hendrik P. N. Scholl",
        "Hrvoje Bogunović",
        "Ursula Schmidt-Erfurth",
        "Daniel Rueckert",
        "Sobha Sivaprasad",
        "Andrew J. Lotery",
        "Martin J. Menten"
      ],
      "abstract": "Clinicians spend a significant amount of time reviewing medical images and\ntranscribing their findings regarding patient diagnosis, referral and treatment\nin text form. Vision-language models (VLMs), which automatically interpret\nimages and summarize their findings as text, have enormous potential to\nalleviate clinical workloads and increase patient access to high-quality\nmedical care. While foundational models have stirred considerable interest in\nthe medical community, it is unclear whether their general capabilities\ntranslate to real-world clinical utility. In this work, we demonstrate that\nOpenAI's ChatGPT-4o model, in addition to two foundation VLMs designed for\nmedical use, markedly underperform compared to practicing ophthalmologists on\nspecialist tasks crucial to the care of patients with age-related macular\ndegeneration (AMD). To address this, we initially identified the essential\ncapabilities required for image-based clinical decision-making, and then\ndeveloped a curriculum to selectively train VLMs in these skills. The resulting\nmodel, RetinaVLM, can be instructed to write reports that significantly\noutperform those written by leading foundation medical VLMs and ChatGPT-4o in\ndisease staging (F1 score of 0.63 vs. 0.33) and patient referral (0.67 vs.\n0.50), and approaches the diagnostic performance of junior ophthalmologists\n(who achieve 0.77 and 0.78 on the respective tasks). Furthermore, in a\nsingle-blind reader study two senior ophthalmologists with up to 32 years of\nexperience found RetinaVLM's reports were found to be substantially more\naccurate than those by ChatGPT-4o (64.3% vs. 14.3%). These results reinforce\nthat our curriculum-based approach provides a blueprint towards specializing\nfoundation medical VLMs for real-world clinical tasks.",
      "tldr_zh": "本研究发现，现有的视觉语言模型（VLMs）如 ChatGPT-4o 在处理年龄相关性黄斑变性（AMD）的视网膜图像分析任务上，表现远逊于眼科医生，导致临床决策准确性不足。为解决这一问题，研究团队开发了专门的课程，针对图像-based 临床决策的关键能力进行选择性训练，创建了新模型 RetinaVLM。实验结果显示，RetinaVLM 在疾病分期（F1 分数 0.63）和患者转诊（0.67）任务上显著优于基线模型，并接近初级眼科医生的表现（分别为 0.77 和 0.78）。此外，在单盲阅读研究中，资深眼科医生认为 RetinaVLM 的报告准确率远高于 ChatGPT-4o（64.3% vs. 14.3%），为针对真实临床任务专门化训练基础医疗 VLMs 提供了有效蓝图。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Under review at npj Digital Medicine",
      "pdf_url": "http://arxiv.org/pdf/2407.08410v2",
      "published_date": "2024-07-11 11:31:48 UTC",
      "updated_date": "2025-02-25 01:54:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:44:05.729710"
    },
    {
      "arxiv_id": "2407.08408v1",
      "title": "A Two-Stage Machine Learning-Aided Approach for Quench Identification at the European XFEL",
      "title_zh": "翻译失败",
      "authors": [
        "Lynda Boukela",
        "Annika Eichler",
        "Julien Branlard",
        "Nur Zulaiha Jomhari"
      ],
      "abstract": "This paper introduces a machine learning-aided fault detection and isolation\nmethod applied to the case study of quench identification at the European X-Ray\nFree-Electron Laser. The plant utilizes 800 superconducting radio-frequency\ncavities in order to accelerate electron bunches to high energies of up to 17.5\nGeV. Various faulty events can disrupt the nominal functioning of the\naccelerator, including quenches that can lead to a loss of the\nsuperconductivity of the cavities and the interruption of their operation. In\nthis context, our solution consists in analyzing signals reflecting the\ndynamics of the cavities in a two-stage approach. (I) Fault detection that uses\nanalytical redundancy to process the data and generate a residual. The\nevaluation of the residual through the generalized likelihood ratio allows\ndetecting the faulty behaviors. (II) Fault isolation which involves the\ndistinction of the quenches from the other faults. To this end, we proceed with\na data-driven model of the k-medoids algorithm that explores different\nsimilarity measures, namely, the Euclidean and the dynamic time warping.\nFinally, we evaluate the new method and compare it to the currently deployed\nquench detection system, the results show the improved performance achieved by\nour method.",
      "tldr_zh": "这篇论文提出了一种两阶段机器学习辅助方法，用于在European XFEL的超导射频腔系统中识别quench（淬火）故障，该系统利用800个腔体加速电子束至17.5 GeV。  \n第一阶段的fault detection通过analytical redundancy处理数据生成residual，并使用generalized likelihood ratio评估残差来检测故障行为。  \n第二阶段的fault isolation采用k-medoids算法结合Euclidean和dynamic time warping相似性度量，对数据进行驱动建模，以区分quench与其他故障。  \n实验结果表明，该方法比当前部署的quench检测系统表现出显著性能改进。",
      "categories": [
        "physics.ins-det",
        "cs.AI"
      ],
      "primary_category": "physics.ins-det",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08408v1",
      "published_date": "2024-07-11 11:21:41 UTC",
      "updated_date": "2024-07-11 11:21:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:44:15.903058"
    },
    {
      "arxiv_id": "2407.08400v3",
      "title": "Self-training Language Models for Arithmetic Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Marek Kadlčík",
        "Michal Štefánik"
      ],
      "abstract": "Recent language models achieve impressive results in tasks involving complex\nmultistep reasoning, but scaling these capabilities further traditionally\nrequires expensive collection of more annotated data. In this work, we explore\nthe potential of improving models' reasoning capabilities without new data,\nmerely using automated feedback to the validity of their predictions in\narithmetic reasoning (self-training).\n  In systematic experimentation across six different arithmetic reasoning\ndatasets, we find that models can substantially improve in both single-round\n(offline) and online self-training, reaching a correct result in +13.9% and\n+25.9% more cases, respectively, underlining the importance of actuality of\nself-training feedback. We further find that in the single-round, offline\nself-training, traditional supervised training can deliver gains comparable to\npreference optimization, but in online self-training, preference optimization\nmethods largely outperform supervised training thanks to their superior\nstability and robustness on unseen types of problems.",
      "tldr_zh": "本文研究了如何通过 self-training 改进语言模型在 arithmetic reasoning 中的推理能力，而无需收集新标注数据，仅使用自动反馈来验证预测的正确性。在六个算术推理数据集上的实验显示，模型在单轮（离线）self-training 中正确率提高了13.9%，而在在线self-training 中提升了25.9%。此外，研究发现，在离线self-training 中，传统监督训练与 preference optimization 效果相当，但在线self-training 中，preference optimization 方法因其稳定性与鲁棒性而显著优于监督训练。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear in Findings of EMNLP 2024. Reproducible implementations and\n  references to resulting models can be found on\n  https://github.com/prompteus/calc-x",
      "pdf_url": "http://arxiv.org/pdf/2407.08400v3",
      "published_date": "2024-07-11 11:06:05 UTC",
      "updated_date": "2024-10-23 20:43:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:44:28.662924"
    },
    {
      "arxiv_id": "2407.08388v1",
      "title": "On the attribution of confidence to large language models",
      "title_zh": "翻译失败",
      "authors": [
        "Geoff Keeling",
        "Winnie Street"
      ],
      "abstract": "Credences are mental states corresponding to degrees of confidence in\npropositions. Attribution of credences to Large Language Models (LLMs) is\ncommonplace in the empirical literature on LLM evaluation. Yet the theoretical\nbasis for LLM credence attribution is unclear. We defend three claims. First,\nour semantic claim is that LLM credence attributions are (at least in general)\ncorrectly interpreted literally, as expressing truth-apt beliefs on the part of\nscientists that purport to describe facts about LLM credences. Second, our\nmetaphysical claim is that the existence of LLM credences is at least\nplausible, although current evidence is inconclusive. Third, our epistemic\nclaim is that LLM credence attributions made in the empirical literature on LLM\nevaluation are subject to non-trivial sceptical concerns. It is a distinct\npossibility that even if LLMs have credences, LLM credence attributions are\ngenerally false because the experimental techniques used to assess LLM\ncredences are not truth-tracking.",
      "tldr_zh": "该论文探讨了将信心度（credences）归因于大型语言模型（LLMs）的理论基础，分析了这种归因在LLM评估实证文献中的应用。作者捍卫三个关键主张：首先，语义上，LLM信心度归因通常是字面正确的，表达科学家关于LLM信心度事实的真实信念；其次，形而上学上，LLMs拥有信心度是合理的，但现有证据尚不确定；第三，认识论上，LLM评估中的信心度归因面临严重怀疑，因为实验技术可能无法准确追踪真实信心度，从而导致归因错误。总之，该研究强调了LLM信心度归因的复杂性，并呼吁更可靠的评估方法以提升科学准确性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 0 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08388v1",
      "published_date": "2024-07-11 10:51:06 UTC",
      "updated_date": "2024-07-11 10:51:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:44:39.726715"
    },
    {
      "arxiv_id": "2407.08380v1",
      "title": "Digital twins to alleviate the need for real field data in vision-based vehicle speed detection systems",
      "title_zh": "使用数字孪生缓解基于视觉的车辆速度检测系统对真实现场数据的需求",
      "authors": [
        "Antonio Hernández Martínez",
        "Iván García Daza",
        "Carlos Fernández López",
        "David Fernández Llorca"
      ],
      "abstract": "Accurate vision-based speed estimation is much more cost-effective than\ntraditional methods based on radar or LiDAR. However, it is also challenging\ndue to the limitations of perspective projection on a discrete sensor, as well\nas the high sensitivity to calibration, lighting and weather conditions.\nInterestingly, deep learning approaches (which dominate the field of computer\nvision) are very limited in this context due to the lack of available data.\nIndeed, obtaining video sequences of real road traffic with accurate speed\nvalues associated with each vehicle is very complex and costly, and the number\nof available datasets is very limited. Recently, some approaches are focusing\non the use of synthetic data. However, it is still unclear how models trained\non synthetic data can be effectively applied to real world conditions. In this\nwork, we propose the use of digital-twins using CARLA simulator to generate a\nlarge dataset representative of a specific real-world camera. The synthetic\ndataset contains a large variability of vehicle types, colours, speeds,\nlighting and weather conditions. A 3D CNN model is trained on the digital twin\nand tested on the real sequences. Unlike previous approaches that generate\nmulti-camera sequences, we found that the gap between the the real and the\nvirtual conditions is a key factor in obtaining low speed estimation errors.\nEven with a preliminary approach, the mean absolute error obtained remains\nbelow 3km/h.",
      "tldr_zh": "本研究针对视觉-based车辆速度检测系统的问题，提出使用digital twins技术（如CARLA模拟器）生成合成数据集，以减少对昂贵真实数据的需求。该方法创建了一个包含多种车辆类型、颜色、速度、光照和天气条件的多样化数据集，并训练一个3D CNN模型在合成数据上进行学习。实验结果显示，该模型在真实序列测试中，平均绝对误差(mean absolute error)低于3km/h，证明了缩小真实与虚拟条件差距的关键作用，从而为更经济有效的速度估算提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Paper accepted at the 27th IEEE International Conference on\n  Intelligent Transportation Systems (ITSC 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.08380v1",
      "published_date": "2024-07-11 10:41:20 UTC",
      "updated_date": "2024-07-11 10:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:44:51.773192"
    },
    {
      "arxiv_id": "2407.08348v2",
      "title": "Skywork-Math: Data Scaling Laws for Mathematical Reasoning in Large Language Models -- The Story Goes On",
      "title_zh": "Skywork-Math：大型语言模型中数学推理的数据规模定律——故事还在继续",
      "authors": [
        "Liang Zeng",
        "Liangjun Zhong",
        "Liang Zhao",
        "Tianwen Wei",
        "Liu Yang",
        "Jujie He",
        "Cheng Cheng",
        "Rui Hu",
        "Yang Liu",
        "Shuicheng Yan",
        "Han Fang",
        "Yahui Zhou"
      ],
      "abstract": "In this paper, we investigate the underlying factors that potentially enhance\nthe mathematical reasoning capabilities of large language models (LLMs). We\nargue that the data scaling law for math reasoning capabilities in modern LLMs\nis far from being saturated, highlighting how the model's quality improves with\nincreases in data quantity. To support this claim, we introduce the\nSkywork-Math model series, supervised fine-tuned (SFT) on common 7B LLMs using\nour proposed 2.5M-instance Skywork-MathQA dataset. Skywork-Math 7B has achieved\nimpressive accuracies of 51.2% on the competition-level MATH benchmark and\n83.9% on the GSM8K benchmark using only SFT data, outperforming an early\nversion of GPT-4 on MATH. The superior performance of Skywork-Math models\ncontributes to our novel two-stage data synthesis and model SFT pipelines,\nwhich include three different augmentation methods and a diverse seed problem\nset, ensuring both the quantity and quality of Skywork-MathQA dataset across\nvarying difficulty levels. Most importantly, we provide several practical\ntakeaways to enhance math reasoning abilities in LLMs for both research and\nindustry applications.",
      "tldr_zh": "本研究探讨了数据规模对大型语言模型 (LLMs) 数学推理能力的影响，证明这种能力远未饱和，模型性能随数据量增加而显著提升。\n他们引入 Skywork-Math 模型系列，通过 2.5M 实例的 Skywork-MathQA 数据集对 7B LLMs 进行监督微调 (SFT)，并采用新型的两阶段数据合成管道，包括三种增强方法和多样化种子问题集，以确保数据集的质量和多样性。\nSkywork-Math 7B 在 MATH 基准上达到 51.2% 准确率，在 GSM8K 基准上达 83.9%，优于早期 GPT-4，并提供实用建议，帮助研究和工业应用提升 LLMs 的数学推理能力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08348v2",
      "published_date": "2024-07-11 09:56:51 UTC",
      "updated_date": "2024-07-17 16:28:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:45:06.102931"
    },
    {
      "arxiv_id": "2407.08331v2",
      "title": "Towards Explainable Evolution Strategies with Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jill Baumann",
        "Oliver Kramer"
      ],
      "abstract": "This paper introduces an approach that integrates self-adaptive Evolution\nStrategies (ES) with Large Language Models (LLMs) to enhance the explainability\nof complex optimization processes. By employing a self-adaptive ES equipped\nwith a restart mechanism, we effectively navigate the challenging landscapes of\nbenchmark functions, capturing detailed logs of the optimization journey. The\nlogs include fitness evolution, step-size adjustments and restart events due to\nstagnation. An LLM is then utilized to process these logs, generating concise,\nuser-friendly summaries that highlight key aspects such as convergence\nbehavior, optimal fitness achievements, and encounters with local optima. Our\ncase study on the Rastrigin function demonstrates how our approach makes the\ncomplexities of ES optimization transparent. Our findings highlight the\npotential of using LLMs to bridge the gap between advanced optimization\nalgorithms and their interpretability.",
      "tldr_zh": "这篇论文提出了一种整合自适应进化策略（Evolution Strategies, ES）和大型语言模型（Large Language Models, LLMs）的approach，以提升复杂优化过程的可解释性。具体方法包括使用自适应 ES 配重启机制来记录优化日志，如适应度演变、步长调整和停滞重启事件，然后由 LLMs 处理这些日志生成简洁的用户友好摘要。案例研究在 Rastrigin 函数上展示了该方法如何使 ES 优化的复杂性变得透明。总体而言，该研究突出了 LLMs 在弥合高级优化算法与可解释性差距方面的潜力。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted at ESANN 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08331v2",
      "published_date": "2024-07-11 09:28:27 UTC",
      "updated_date": "2024-08-05 08:13:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:45:16.856953"
    },
    {
      "arxiv_id": "2407.08328v1",
      "title": "Unveiling Disparities in Maternity Care: A Topic Modelling Approach to Analysing Maternity Incident Investigation Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Georgina Cosma",
        "Mohit Kumar Singh",
        "Patrick Waterson",
        "Gyuchan Thomas Jun",
        "Jonathan Back"
      ],
      "abstract": "This study applies Natural Language Processing techniques, including Latent\nDirichlet Allocation, to analyse anonymised maternity incident investigation\nreports from the Healthcare Safety Investigation Branch. The reports underwent\npreprocessing, annotation using the Safety Intelligence Research taxonomy, and\ntopic modelling to uncover prevalent topics and detect differences in maternity\ncare across ethnic groups. A combination of offline and online methods was\nutilised to ensure data protection whilst enabling advanced analysis, with\noffline processing for sensitive data and online processing for non-sensitive\ndata using the `Claude 3 Opus' language model. Interactive topic analysis and\nsemantic network visualisation were employed to extract and display thematic\ntopics and visualise semantic relationships among keywords. The analysis\nrevealed disparities in care among different ethnic groups, with distinct focus\nareas for the Black, Asian, and White British ethnic groups. The study\ndemonstrates the effectiveness of topic modelling and NLP techniques in\nanalysing maternity incident investigation reports and highlighting disparities\nin care. The findings emphasise the crucial role of advanced data analysis in\nimproving maternity care quality and equity.",
      "tldr_zh": "本研究利用 Natural Language Processing (NLP) 技术，包括 Latent Dirichlet Allocation (LDA)，分析 Healthcare Safety Investigation Branch 的匿名产科事件调查报告，以揭示不同民族群体在产科护理中的差异。报告经过预处理和 Safety Intelligence Research taxonomy 标注后，进行主题建模，并结合离线处理敏感数据和在线使用 Claude 3 Opus 模型的混合方法，确保数据安全。交互式主题分析及语义网络可视化帮助提取关键主题并展示关键词关系，结果显示 Black, Asian 和 White British 民族群体在护理焦点方面存在显著差异。该研究证明了 NLP 和主题建模在突出护理不平等方面的有效性，并强调先进数据分析对提升产科护理质量和公平性的重要作用。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08328v1",
      "published_date": "2024-07-11 09:26:05 UTC",
      "updated_date": "2024-07-11 09:26:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:45:29.772868"
    },
    {
      "arxiv_id": "2407.08324v1",
      "title": "A Cantor-Kantorovich Metric Between Markov Decision Processes with Application to Transfer Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Adrien Banse",
        "Venkatraman Renganathan",
        "Raphaël M. Jungers"
      ],
      "abstract": "We extend the notion of Cantor-Kantorovich distance between Markov chains\nintroduced by (Banse et al., 2023) in the context of Markov Decision Processes\n(MDPs). The proposed metric is well-defined and can be efficiently approximated\ngiven a finite horizon. Then, we provide numerical evidences that the latter\nmetric can lead to interesting applications in the field of reinforcement\nlearning. In particular, we show that it could be used for forecasting the\nperformance of transfer learning algorithms.",
      "tldr_zh": "这篇论文扩展了 Cantor-Kantorovich distance 的概念，将其从 Markov chains 应用到 Markov Decision Processes (MDPs)，并证明该度量在有限地平线上定义良好且可高效近似。研究者通过数值证据展示了该度量在强化学习领域的潜力，特别是用于预测转移学习算法的性能。总体而言，此工作为强化学习中的任务转移提供了新的量化工具。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Presented at the 26th International Symposium on Mathematical Theory\n  of Networks and Systems (Cambridge, UK)",
      "pdf_url": "http://arxiv.org/pdf/2407.08324v1",
      "published_date": "2024-07-11 09:13:11 UTC",
      "updated_date": "2024-07-11 09:13:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:45:41.340647"
    },
    {
      "arxiv_id": "2407.08322v1",
      "title": "Intelligent Multi-Document Summarisation for Extracting Insights on Racial Inequalities from Maternity Incident Investigation Reports",
      "title_zh": "翻译失败",
      "authors": [
        "Georgina Cosma",
        "Mohit Kumar Singh",
        "Patrick Waterson",
        "Gyuchan Thomas Jun",
        "Jonathan Back"
      ],
      "abstract": "In healthcare, thousands of safety incidents occur every year, but learning\nfrom these incidents is not effectively aggregated. Analysing incident reports\nusing AI could uncover critical insights to prevent harm by identifying\nrecurring patterns and contributing factors. To aggregate and extract valuable\ninformation, natural language processing (NLP) and machine learning techniques\ncan be employed to summarise and mine unstructured data, potentially surfacing\nsystemic issues and priority areas for improvement. This paper presents\nI-SIRch:CS, a framework designed to facilitate the aggregation and analysis of\nsafety incident reports while ensuring traceability throughout the process. The\nframework integrates concept annotation using the Safety Intelligence Research\n(SIRch) taxonomy with clustering, summarisation, and analysis capabilities.\nUtilising a dataset of 188 anonymised maternity investigation reports annotated\nwith 27 SIRch human factors concepts, I-SIRch:CS groups the annotated sentences\ninto clusters using sentence embeddings and k-means clustering, maintaining\ntraceability via file and sentence IDs. Summaries are generated for each\ncluster using offline state-of-the-art abstractive summarisation models (BART,\nDistilBART, T5), which are evaluated and compared using metrics assessing\nsummary quality attributes. The generated summaries are linked back to the\noriginal file and sentence IDs, ensuring traceability and allowing for\nverification of the summarised information. Results demonstrate BART's\nstrengths in creating informative and concise summaries.",
      "tldr_zh": "这篇论文提出 I-SIRch:CS 框架，用于从 188 份匿名产科安全事件报告中提取种族不平等洞见，通过整合 Safety Intelligence Research (SIRch) 分类法来标注 27 个人类因素概念。框架采用句子嵌入和 k-means clustering 将标注句子分组，并使用 abstractive summarisation 模型（如 BART、DistilBART 和 T5）生成每个聚类的总结，同时确保通过文件和句子 ID 实现可追溯性。实验结果显示，BART 在创建信息性且简洁的总结方面表现最佳，有助于识别医疗系统中 recurring patterns 和系统性问题。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08322v1",
      "published_date": "2024-07-11 09:11:20 UTC",
      "updated_date": "2024-07-11 09:11:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:45:54.178045"
    },
    {
      "arxiv_id": "2407.18945v2",
      "title": "CogNarr Ecosystem: Facilitating Group Cognition at Scale",
      "title_zh": "翻译失败",
      "authors": [
        "John C. Boik"
      ],
      "abstract": "Human groups of all sizes and kinds engage in deliberation, problem solving,\nstrategizing, decision making, and more generally, cognition. Some groups are\nlarge, and that setting presents unique challenges. The small-group setting\noften involves face-to-face dialogue, but group cognition in the large-group\nsetting typically requires some form of online interaction. New approaches are\nneeded to facilitate the kind of rich communication and information processing\nthat are required for effective, functional cognition in the online setting,\nespecially for groups characterized by thousands to millions of participants\nwho wish to share potentially complex, nuanced, and dynamic perspectives. This\nconcept paper proposes the CogNarr (Cognitive Narrative) ecosystem, which is\ndesigned to facilitate functional cognition in the large-group setting. The\npaper's contribution is a novel vision as to how recent developments in\ncognitive science, artificial intelligence, natural language processing, and\nrelated fields might be scaled and applied to large-group cognition, using an\napproach that itself promotes further scientific advancement. A key perspective\nis to view a group as an organism that uses some form of cognitive architecture\nto sense the world, process information, remember, learn, predict, make\ndecisions, and adapt to changing conditions. The CogNarr ecosystem is designed\nto serve as a component within that architecture.",
      "tldr_zh": "本论文探讨了大型群体在在线环境中进行认知活动（如审议、问题解决和决策）的挑战，强调了数千到数百万参与者需要复杂、动态的沟通机制。论文提出 CogNarr（Cognitive Narrative）生态系统，这是一个创新框架，利用认知科学、AI 和自然语言处理等领域的最新进展，帮助大规模群体实现有效的认知过程。关键视角是将群体视为一个有机体，配备认知架构来感知世界、处理信息、学习和适应；CogNarr 旨在作为该架构的组成部分，促进科学进步和大规模群体认知。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "F.4.1, I.2.7"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.18945v2",
      "published_date": "2024-07-11 08:59:17 UTC",
      "updated_date": "2024-07-31 20:58:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:46:03.944881"
    },
    {
      "arxiv_id": "2407.08306v3",
      "title": "Let Network Decide What to Learn: Symbolic Music Understanding Model Based on Large-scale Adversarial Pre-training",
      "title_zh": "让网络决定学什么：基于大规模对抗预",
      "authors": [
        "Zijian Zhao"
      ],
      "abstract": "As a crucial aspect of Music Information Retrieval (MIR), Symbolic Music\nUnderstanding (SMU) has garnered significant attention for its potential to\nassist both musicians and enthusiasts in learning and creating music. Recently,\npre-trained language models have been widely adopted in SMU due to the\nsubstantial similarities between symbolic music and natural language, as well\nas the ability of these models to leverage limited music data effectively.\nHowever, some studies have shown the common pre-trained methods like Mask\nLanguage Model (MLM) may introduce bias issues like racism discrimination in\nNatural Language Process (NLP) and affects the performance of downstream tasks,\nwhich also happens in SMU. This bias often arises when masked tokens cannot be\ninferred from their context, forcing the model to overfit the training set\ninstead of generalizing. To address this challenge, we propose\nAdversarial-MidiBERT for SMU, which adaptively determines what to mask during\nMLM via a masker network, rather than employing random masking. By avoiding the\nmasking of tokens that are difficult to infer from context, our model is better\nequipped to capture contextual structures and relationships, rather than merely\nconforming to the training data distribution. We evaluate our method across\nfour SMU tasks, and our approach demonstrates excellent performance in all\ncases. The code for our model is publicly available at\nhttps://github.com/RS2002/Adversarial-MidiBERT .",
      "tldr_zh": "该论文针对 Symbolic Music Understanding (SMU) 任务提出 Adversarial-MidiBERT 模型，通过大规模对抗预训练来解决传统 Mask Language Model (MLM) 引入的偏置问题，如种族歧视和模型过拟合。不同于随机掩码，该方法使用一个 masker 网络自适应决定哪些令牌需要掩码，从而更好地捕捉音乐符号的上下文结构和关系。实验结果显示，Adversarial-MidiBERT 在四个 SMU 任务上表现出色，代码已公开在 GitHub 上。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08306v3",
      "published_date": "2024-07-11 08:54:38 UTC",
      "updated_date": "2025-04-30 05:22:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:46:16.796737"
    },
    {
      "arxiv_id": "2407.08303v2",
      "title": "DenseFusion-1M: Merging Vision Experts for Comprehensive Multimodal Perception",
      "title_zh": "DenseFusion-1M：合并视觉专家用于全面多模态感知",
      "authors": [
        "Xiaotong Li",
        "Fan Zhang",
        "Haiwen Diao",
        "Yueze Wang",
        "Xinlong Wang",
        "Ling-Yu Duan"
      ],
      "abstract": "Existing Multimodal Large Language Models (MLLMs) increasingly emphasize\ncomplex understanding of various visual elements, including multiple objects,\ntext information, and spatial relations. Their development for comprehensive\nvisual perception hinges on the availability of high-quality image-text\ndatasets that offer diverse visual elements and throughout image descriptions.\nHowever, the scarcity of such hyper-detailed datasets currently hinders\nprogress within the MLLM community. The bottleneck stems from the limited\nperceptual capabilities of current caption engines, which fall short in\nproviding complete and accurate annotations. To facilitate the cutting-edge\nresearch of MLLMs on comprehensive vision perception, we thereby propose\nPerceptual Fusion, using a low-budget but highly effective caption engine for\ncomplete and accurate image descriptions. Specifically, Perceptual Fusion\nintegrates diverse perception experts as image priors to provide explicit\ninformation on visual elements and adopts an efficient MLLM as a centric pivot\nto mimic advanced MLLMs' perception abilities. We carefully select 1M highly\nrepresentative images from uncurated LAION dataset and generate dense\ndescriptions using our engine, dubbed DenseFusion-1M. Extensive experiments\nvalidate that our engine outperforms its counterparts, where the resulting\ndataset significantly improves the perception and cognition abilities of\nexisting MLLMs across diverse vision-language benchmarks, especially with\nhigh-resolution images as inputs. The dataset and code are publicly available\nat https://github.com/baaivision/DenseFusion.",
      "tldr_zh": "该论文指出，现有的Multimodal Large Language Models (MLLMs) 在处理多种视觉元素（如多个对象、文本信息和空间关系）时，面临高质量图像-文本数据集短缺的问题，导致感知能力受限。作者提出Perceptual Fusion框架，这是一种低成本高效的标题引擎，通过整合多样感知专家作为图像先验，并使用高效MLLM作为中心枢纽，生成完整准确的图像描述。基于此，他们从LAION数据集选取100万张代表性图像，创建了DenseFusion-1M数据集。实验结果显示，该引擎和数据集显著提升了现有MLLM在各种视觉-语言基准上的感知和认知能力，尤其在高分辨率图像输入时。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted by NeurIPS 2024. Project is available at\n  https://github.com/baaivision/DenseFusion",
      "pdf_url": "http://arxiv.org/pdf/2407.08303v2",
      "published_date": "2024-07-11 08:48:06 UTC",
      "updated_date": "2024-11-24 13:14:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:46:30.413075"
    },
    {
      "arxiv_id": "2407.08302v1",
      "title": "Impact Measures for Gradual Argumentation Semantics",
      "title_zh": "翻译失败",
      "authors": [
        "Caren Al Anaissy",
        "Jérôme Delobelle",
        "Srdjan Vesic",
        "Bruno Yun"
      ],
      "abstract": "Argumentation is a formalism allowing to reason with contradictory\ninformation by modeling arguments and their interactions. There are now an\nincreasing number of gradual semantics and impact measures that have emerged to\nfacilitate the interpretation of their outcomes. An impact measure assesses,\nfor each argument, the impact of other arguments on its score. In this paper,\nwe refine an existing impact measure from Delobelle and Villata and introduce a\nnew impact measure rooted in Shapley values. We introduce several principles to\nevaluate those two impact measures w.r.t. some well-known gradual semantics.\nThis comprehensive analysis provides deeper insights into their functionality\nand desirability.",
      "tldr_zh": "本论文探讨了渐进式论证语义（gradual semantics）中的影响度量（impact measures），旨在评估其他论证对特定论证得分的冲击，以更好地解释语义输出。论文细化了Delobelle和Villata的现有影响度量，并引入了一个基于Shapley values的新影响度量。作者还提出了几个原则来评估这些度量相对于知名渐进式语义的效果，提供更深入的功能性和可取性分析。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08302v1",
      "published_date": "2024-07-11 08:47:44 UTC",
      "updated_date": "2024-07-11 08:47:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:46:40.761815"
    },
    {
      "arxiv_id": "2407.08289v1",
      "title": "Predicting Heart Failure with Attention Learning Techniques Utilizing Cardiovascular Data",
      "title_zh": "利用心血管数据和注意力学习技术预测心力衰竭",
      "authors": [
        "Ershadul Haque",
        "Manoranjan Paul",
        "Faranak Tohidi"
      ],
      "abstract": "Cardiovascular diseases (CVDs) encompass a group of disorders affecting the\nheart and blood vessels, including conditions such as coronary artery disease,\nheart failure, stroke, and hypertension. In cardiovascular diseases, heart\nfailure is one of the main causes of death and also long-term suffering in\npatients worldwide. Prediction is one of the risk factors that is highly\nvaluable for treatment and intervention to minimize heart failure. In this\nwork, an attention learning-based heart failure prediction approach is proposed\non EHR(electronic health record) cardiovascular data such as ejection fraction\nand serum creatinine. Moreover, different optimizers with various learning rate\napproaches are applied to fine-tune the proposed approach. Serum creatinine and\nejection fraction are the two most important features to predict the patient's\nheart failure. The computational result shows that the RMSProp optimizer with\n0.001 learning rate has a better prediction based on serum creatinine. On the\nother hand, the combination of SGD optimizer with 0.01 learning rate exhibits\noptimum performance based on ejection fraction features. Overall, the proposed\nattention learning-based approach performs very efficiently in predicting heart\nfailure compared to the existing state-of-the-art such as LSTM approach.",
      "tldr_zh": "本研究提出了一种基于 attention learning 的心力衰竭预测方法，利用电子健康记录 (EHR) 数据，如 ejection fraction 和 serum creatinine，针对心血管疾病患者的风险评估。研究应用了不同优化器和学习率进行微调，结果显示 RMSProp 优化器与 0.001 学习率在 serum creatinine 特征上表现最佳，而 SGD 优化器与 0.01 学习率在 ejection fraction 特征上取得最佳预测性能。该方法整体上比现有的最先进技术（如 LSTM 模型）更高效，显著提高了心力衰竭的预测准确性。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 37 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08289v1",
      "published_date": "2024-07-11 08:33:42 UTC",
      "updated_date": "2024-07-11 08:33:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:46:53.765130"
    },
    {
      "arxiv_id": "2407.08279v1",
      "title": "Continually Learn to Map Visual Concepts to Large Language Models in Resource-constrained Environments",
      "title_zh": "翻译失败",
      "authors": [
        "Clea Rebillard",
        "Julio Hurtado",
        "Andrii Krutsylo",
        "Lucia Passaro",
        "Vincenzo Lomonaco"
      ],
      "abstract": "Learning continually from a stream of non-i.i.d. data is an open challenge in\ndeep learning, even more so when working in resource-constrained environments\nsuch as embedded devices. Visual models that are continually updated through\nsupervised learning are often prone to overfitting, catastrophic forgetting,\nand biased representations. On the other hand, large language models contain\nknowledge about multiple concepts and their relations, which can foster a more\nrobust, informed and coherent learning process. This work proposes Continual\nVisual Mapping (CVM), an approach that continually ground vision\nrepresentations to a knowledge space extracted from a fixed Language model.\nSpecifically, CVM continually trains a small and efficient visual model to map\nits representations into a conceptual space established by a fixed Large\nLanguage Model. Due to their smaller nature, CVM can be used when directly\nadapting large visual pre-trained models is unfeasible due to computational or\ndata constraints. CVM overcome state-of-the-art continual learning methods on\nfive benchmarks and offers a promising avenue for addressing generalization\ncapabilities in continual learning, even in computationally constrained\ndevices.",
      "tldr_zh": "该论文探讨了在资源受限环境中，从非独立同分布（non-i.i.d.）数据流中进行持续学习的问题，视觉模型常面临过拟合、catastrophic forgetting 和偏差表示的挑战。作者提出 Continual Visual Mapping (CVM) 方法，通过持续训练一个小型高效的视觉模型，将视觉表示映射到由固定 Large Language Models 建立的概念空间，从而利用语言模型的知识提升学习稳健性。CVM 适用于计算和数据受限的设备，如嵌入式系统，并克服了直接适应大型视觉预训练模型的限制。在五个基准测试中，CVM 超越了现有 state-of-the-art 持续学习方法，并为提升持续学习的泛化能力提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08279v1",
      "published_date": "2024-07-11 08:28:40 UTC",
      "updated_date": "2024-07-11 08:28:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:47:05.797665"
    },
    {
      "arxiv_id": "2407.08270v1",
      "title": "SciQu: Accelerating Materials Properties Prediction with Automated Literature Mining for Self-Driving Laboratories",
      "title_zh": "SciQu: 通过自动文献",
      "authors": [
        "Anand Babu"
      ],
      "abstract": "Assessing different material properties to predict specific attributes, such\nas band gap, resistivity, young modulus, work function, and refractive index,\nis a fundamental requirement for materials science-based applications. However,\nthe process is time-consuming and often requires extensive literature reviews\nand numerous experiments. Our study addresses these challenges by leveraging\nmachine learning to analyze material properties with greater precision and\nefficiency. By automating the data extraction process and using the extracted\ninformation to train machine learning models, our developed model, SciQu,\noptimizes material properties. As a proof of concept, we predicted the\nrefractive index of materials using data extracted from numerous research\narticles with SciQu, considering input descriptors such as space group, volume,\nand bandgap with Root Mean Square Error (RMSE) 0.068 and R2 0.94. Thus, SciQu\nnot only predicts the properties of materials but also plays a key role in\nself-driving laboratories by optimizing the synthesis parameters to achieve\nprecise shape, size, and phase of the materials subjected to the input\nparameters.",
      "tldr_zh": "本研究针对材料属性预测（如band gap、resistivity、young modulus、work function和refractive index）的耗时问题，提出SciQu模型，通过自动化文献挖掘（Automated Literature Mining）和机器学习训练，加速数据提取和属性优化。SciQu使用输入描述符如space group、volume和bandgap，成功预测材料的refractive index，达到RMSE 0.068和R2 0.94的精确性。作为概念证明，该模型不仅提升了预测效率，还在self-driving laboratories中发挥关键作用，通过优化合成参数来精确控制材料的形状、大小和相位。",
      "categories": [
        "cond-mat.mtrl-sci",
        "cs.AI",
        "cs.LG",
        "physics.app-ph"
      ],
      "primary_category": "cond-mat.mtrl-sci",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08270v1",
      "published_date": "2024-07-11 08:12:46 UTC",
      "updated_date": "2024-07-11 08:12:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:47:17.304622"
    },
    {
      "arxiv_id": "2407.08257v1",
      "title": "Knowledge distillation to effectively attain both region-of-interest and global semantics from an image where multiple objects appear",
      "title_zh": "翻译失败",
      "authors": [
        "Seonwhee Jin"
      ],
      "abstract": "Models based on convolutional neural networks (CNN) and transformers have\nsteadily been improved. They also have been applied in various computer vision\ndownstream tasks. However, in object detection tasks, accurately localizing and\nclassifying almost infinite categories of foods in images remains challenging.\nTo address these problems, we first segmented the food as the\nregion-of-interest (ROI) by using the segment-anything model (SAM) and masked\nthe rest of the region except ROI as black pixels. This process simplified the\nproblems into a single classification for which annotation and training were\nmuch simpler than object detection. The images in which only the ROI was\npreserved were fed as inputs to fine-tune various off-the-shelf models that\nencoded their own inductive biases. Among them, Data-efficient image\nTransformers (DeiTs) had the best classification performance. Nonetheless, when\nfoods' shapes and textures were similar, the contextual features of the\nROI-only images were not enough for accurate classification. Therefore, we\nintroduced a novel type of combined architecture, RveRNet, which consisted of\nROI, extra-ROI, and integration modules that allowed it to account for both the\nROI's and global contexts. The RveRNet's F1 score was 10% better than other\nindividual models when classifying ambiguous food images. If the RveRNet's\nmodules were DeiT with the knowledge distillation from the CNN, performed the\nbest. We investigated how architectures can be made robust against input noise\ncaused by permutation and translocation. The results indicated that there was a\ntrade-off between how much the CNN teacher's knowledge could be distilled to\nDeiT and DeiT's innate strength. Code is publicly available at:\nhttps://github.com/Seonwhee-Genome/RveRNet.",
      "tldr_zh": "该研究针对图像中多个物体（如食物）的检测挑战，提出了一种知识蒸馏方法，首先使用 Segment-Anything Model (SAM) 提取 Region-of-Interest (ROI) 并遮挡其他区域，以简化分类任务。接着，他们开发了新型架构 RveRNet，包括 ROI、extra-ROI 和 integration 模块，能够同时捕捉 ROI 和全局语义，从而提升对形状相似的食物图像的分类准确性。实验结果显示，RveRNet 的 F1 分数比其他模型高 10%，特别是在通过 Knowledge Distillation 从 CNN 到 Data-efficient image Transformers (DeiTs) 的过程中表现最佳，但也揭示了知识转移与模型固有优势之间的权衡。代码已在 GitHub 上公开。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08257v1",
      "published_date": "2024-07-11 07:57:33 UTC",
      "updated_date": "2024-07-11 07:57:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:47:30.456894"
    },
    {
      "arxiv_id": "2407.08254v2",
      "title": "United We Stand: Decentralized Multi-Agent Planning With Attrition",
      "title_zh": "翻译失败",
      "authors": [
        "Nhat Nguyen",
        "Duong Nguyen",
        "Gianluca Rizzo",
        "Hung Nguyen"
      ],
      "abstract": "Decentralized planning is a key element of cooperative multi-agent systems\nfor information gathering tasks. However, despite the high frequency of agent\nfailures in realistic large deployment scenarios, current approaches perform\npoorly in the presence of failures, by not converging at all, and/or by making\nvery inefficient use of resources (e.g. energy). In this work, we propose\nAttritable MCTS (A-MCTS), a decentralized MCTS algorithm capable of timely and\nefficient adaptation to changes in the set of active agents. It is based on the\nuse of a global reward function for the estimation of each agent's local\ncontribution, and regret matching for coordination. We evaluate its\neffectiveness in realistic data-harvesting problems under different scenarios.\nWe show both theoretically and experimentally that A-MCTS enables efficient\nadaptation even under high failure rates. Results suggest that, in the presence\nof frequent failures, our solution improves substantially over the best\nexisting approaches in terms of global utility and scalability.",
      "tldr_zh": "本研究针对分散式多智能体规划在代理失败高发场景下的问题，提出了一种名为 Attritable MCTS (A-MCTS) 的算法，以实现及时高效的适应。A-MCTS 基于 Monte Carlo Tree Search (MCTS)，利用全局奖励函数估算每个代理的本地贡献，并通过 regret matching 机制进行协调。实验结果显示，在现实数据收集任务中，A-MCTS 即使在高失败率下，也显著提高了全局效用和可扩展性，优于现有方法。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "To appear in ECAI 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08254v2",
      "published_date": "2024-07-11 07:55:50 UTC",
      "updated_date": "2024-09-02 02:35:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:47:41.462495"
    },
    {
      "arxiv_id": "2407.08250v1",
      "title": "Gradient Boosting Reinforcement Learning",
      "title_zh": "梯度提升强化学习",
      "authors": [
        "Benjamin Fuhrer",
        "Chen Tessler",
        "Gal Dalal"
      ],
      "abstract": "Neural networks (NN) achieve remarkable results in various tasks, but lack\nkey characteristics: interpretability, support for categorical features, and\nlightweight implementations suitable for edge devices. While ongoing efforts\naim to address these challenges, Gradient Boosting Trees (GBT) inherently meet\nthese requirements. As a result, GBTs have become the go-to method for\nsupervised learning tasks in many real-world applications and competitions.\nHowever, their application in online learning scenarios, notably in\nreinforcement learning (RL), has been limited. In this work, we bridge this gap\nby introducing Gradient-Boosting RL (GBRL), a framework that extends the\nadvantages of GBT to the RL domain. Using the GBRL framework, we implement\nvarious actor-critic algorithms and compare their performance with their NN\ncounterparts. Inspired by shared backbones in NN we introduce a tree-sharing\napproach for policy and value functions with distinct learning rates, enhancing\nlearning efficiency over millions of interactions. GBRL achieves competitive\nperformance across a diverse array of tasks, excelling in domains with\nstructured or categorical features. Additionally, we present a\nhigh-performance, GPU-accelerated implementation that integrates seamlessly\nwith widely-used RL libraries (available at https://github.com/NVlabs/gbrl).\nGBRL expands the toolkit for RL practitioners, demonstrating the viability and\npromise of GBT within the RL paradigm, particularly in domains characterized by\nstructured or categorical features.",
      "tldr_zh": "该研究提出Gradient-Boosting RL (GBRL)框架，将Gradient Boosting Trees (GBT)的优势（如可解释性、对categorical features的支持和轻量级实现）扩展到Reinforcement Learning (RL)领域，以解决神经网络(NN)在这些方面的局限性。GBRL通过实现各种actor-critic算法，并引入tree-sharing方法（为策略和价值函数设置不同学习率），显著提高了学习效率。实验结果显示，GBRL在多种任务中表现出与NN相当的性能，尤其在具有结构化或categorical features的领域中表现出色；此外，该框架提供了一个高性能的GPU加速实现，便于与现有RL库集成。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08250v1",
      "published_date": "2024-07-11 07:52:33 UTC",
      "updated_date": "2024-07-11 07:52:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:47:54.326860"
    },
    {
      "arxiv_id": "2407.08249v1",
      "title": "GeNet: A Multimodal LLM-Based Co-Pilot for Network Topology and Configuration",
      "title_zh": "翻译失败",
      "authors": [
        "Beni Ifland",
        "Elad Duani",
        "Rubin Krief",
        "Miro Ohana",
        "Aviram Zilberman",
        "Andres Murillo",
        "Ofir Manor",
        "Ortal Lavi",
        "Hikichi Kenji",
        "Asaf Shabtai",
        "Yuval Elovici",
        "Rami Puzis"
      ],
      "abstract": "Communication network engineering in enterprise environments is traditionally\na complex, time-consuming, and error-prone manual process. Most research on\nnetwork engineering automation has concentrated on configuration synthesis,\noften overlooking changes in the physical network topology. This paper\nintroduces GeNet, a multimodal co-pilot for enterprise network engineers. GeNet\nis a novel framework that leverages a large language model (LLM) to streamline\nnetwork design workflows. It uses visual and textual modalities to interpret\nand update network topologies and device configurations based on user intents.\nGeNet was evaluated on enterprise network scenarios adapted from Cisco\ncertification exercises. Our results demonstrate GeNet's ability to interpret\nnetwork topology images accurately, potentially reducing network engineers'\nefforts and accelerating network design processes in enterprise environments.\nFurthermore, we show the importance of precise topology understanding when\nhandling intents that require modifications to the network's topology.",
      "tldr_zh": "本研究针对传统企业通信网络工程的复杂性和易出错性，提出GeNet——一个基于大型语言模型(LLM)的多模态辅助工具，用于简化网络拓扑和配置的设计工作流。GeNet通过整合视觉和文本模态，准确解释用户意图并更新网络拓扑和设备配置，并在基于Cisco认证场景的评估中表现出色。结果显示，GeNet显著提高了拓扑图像解释的准确率，减少了工程师的工作量，并强调了精确拓扑理解在处理网络修改意图时的关键作用。",
      "categories": [
        "cs.NI",
        "cs.AI"
      ],
      "primary_category": "cs.NI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08249v1",
      "published_date": "2024-07-11 07:51:57 UTC",
      "updated_date": "2024-07-11 07:51:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:48:04.996030"
    },
    {
      "arxiv_id": "2407.08248v2",
      "title": "Toward accessible comics for blind and low vision readers",
      "title_zh": "面向盲人及弱视读者的可访问漫画",
      "authors": [
        "Christophe Rigaud",
        "Jean-Christophe Burie",
        "Samuel Petit"
      ],
      "abstract": "This work explores how to fine-tune large language models using prompt\nengineering techniques with contextual information for generating an accurate\ntext description of the full story, ready to be forwarded to off-the-shelve\nspeech synthesis tools. We propose to use existing computer vision and optical\ncharacter recognition techniques to build a grounded context from the comic\nstrip image content, such as panels, characters, text, reading order and the\nassociation of bubbles and characters. Then we infer character identification\nand generate comic book script with context-aware panel description including\ncharacter's appearance, posture, mood, dialogues etc. We believe that such\nenriched content description can be easily used to produce audiobook and eBook\nwith various voices for characters, captions and playing sound effects.",
      "tldr_zh": "这篇论文探讨了如何通过微调大型语言模型（LLMs）并结合提示工程技巧和上下文信息，为盲人和视力低下者生成漫画故事的准确文本描述。方法包括使用计算机视觉和光学字符识别（OCR）技术，从漫画图像中提取面板、人物、文本、阅读顺序以及气泡与人物的关联，然后通过推理人物识别生成上下文感知的脚本，涵盖人物外貌、姿势、情绪和对话。最终，该框架可用于创建丰富的 audiobook 和 eBook，支持多种声音和音效，从而提升漫画的可访问性。实验结果表明，这种方法能有效提供高质量的描述内容，方便语音合成工具应用。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to MANPU 2024 (Athens, Greece, August 30, 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.08248v2",
      "published_date": "2024-07-11 07:50:25 UTC",
      "updated_date": "2024-09-10 07:59:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:48:19.657667"
    },
    {
      "arxiv_id": "2407.08240v1",
      "title": "Leveraging LLMs to Predict Affective States via Smartphone Sensor Features",
      "title_zh": "翻译失败",
      "authors": [
        "Tianyi Zhang",
        "Songyan Teng",
        "Hong Jia",
        "Simon D'Alfonso"
      ],
      "abstract": "As mental health issues for young adults present a pressing public health\nconcern, daily digital mood monitoring for early detection has become an\nimportant prospect. An active research area, digital phenotyping, involves\ncollecting and analysing data from personal digital devices such as smartphones\n(usage and sensors) and wearables to infer behaviours and mental health. Whilst\nthis data is standardly analysed using statistical and machine learning\napproaches, the emergence of large language models (LLMs) offers a new approach\nto make sense of smartphone sensing data. Despite their effectiveness across\nvarious domains, LLMs remain relatively unexplored in digital mental health,\nparticularly in integrating mobile sensor data. Our study aims to bridge this\ngap by employing LLMs to predict affect outcomes based on smartphone sensing\ndata from university students. We demonstrate the efficacy of zero-shot and\nfew-shot embedding LLMs in inferring general wellbeing. Our findings reveal\nthat LLMs can make promising predictions of affect measures using solely\nsmartphone sensing data. This research sheds light on the potential of LLMs for\naffective state prediction, emphasizing the intricate link between smartphone\nbehavioral patterns and affective states. To our knowledge, this is the first\nwork to leverage LLMs for affective state prediction and digital phenotyping\ntasks.",
      "tldr_zh": "本文研究利用大型语言模型(LLMs)分析智能手机传感器数据，以预测大学生的情绪状态(affective states)，旨在解决年轻人心理健康监测的迫切需求。作者采用zero-shot和few-shot embedding LLMs方法，对数字表型(digital phenotyping)数据进行处理，证明LLMs能有效推断一般福祉，仅基于手机行为模式。结果显示，LLMs在预测情绪指标方面表现出色，强调了智能手机数据与心理健康的紧密联系，这是首次将LLMs应用于此类任务。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08240v1",
      "published_date": "2024-07-11 07:37:52 UTC",
      "updated_date": "2024-07-11 07:37:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:48:33.057806"
    },
    {
      "arxiv_id": "2407.08227v3",
      "title": "DALL-M: Context-Aware Clinical Data Augmentation with LLMs",
      "title_zh": "翻译失败",
      "authors": [
        "Chihcheng Hsieh",
        "Catarina Moreira",
        "Isabel Blanco Nobre",
        "Sandra Costa Sousa",
        "Chun Ouyang",
        "Margot Brereton",
        "Joaquim Jorge",
        "Jacinto C. Nascimento"
      ],
      "abstract": "X-ray images are vital in medical diagnostics, but their effectiveness is\nlimited without clinical context. Radiologists often find chest X-rays\ninsufficient for diagnosing underlying diseases, necessitating the integration\nof structured clinical features with radiology reports.\n  To address this, we introduce DALL-M, a novel framework that enhances\nclinical datasets by generating contextual synthetic data. DALL-M augments\nstructured patient data, including vital signs (e.g., heart rate, oxygen\nsaturation), radiology findings (e.g., lesion presence), and demographic\nfactors. It integrates this tabular data with contextual knowledge extracted\nfrom radiology reports and domain-specific resources (e.g., Radiopaedia,\nWikipedia), ensuring clinical consistency and reliability.\n  DALL-M follows a three-phase process: (i) clinical context storage, (ii)\nexpert query generation, and (iii) context-aware feature augmentation. Using\nlarge language models (LLMs), it generates both contextual synthetic values for\nexisting clinical features and entirely new, clinically relevant features.\n  Applied to 799 cases from the MIMIC-IV dataset, DALL-M expanded the original\n9 clinical features to 91. Empirical validation with machine learning models\n(including Decision Trees, Random Forests, XGBoost, and TabNET) demonstrated a\n16.5% improvement in F1 score and a 25% increase in Precision and Recall.\n  DALL-M bridges an important gap in clinical data augmentation by preserving\ndata integrity while enhancing predictive modeling in healthcare. Our results\nshow that integrating LLM-generated synthetic features significantly improves\nmodel performance, making DALL-M a scalable and practical approach for\nAI-driven medical diagnostics.",
      "tldr_zh": "该研究提出 DALL-M 框架，利用大型语言模型 (LLMs) 进行上下文感知的临床数据增强，以解决 X 光图像诊断中缺乏临床上下文的问题。框架通过三阶段过程——临床上下文存储、专家查询生成和上下文感知特征增强——整合结构化患者数据（如生命体征、放射学发现和人口统计因素）与放射学报告及领域资源（如 Radiopaedia），生成可靠的合成特征。应用于 MIMIC-IV 数据集的 799 病例，DALL-M 将原有的 9 个临床特征扩展到 91 个，并在机器学习模型（如 Decision Trees、Random Forests、XGBoost 和 TabNET）上实现了 F1 分数提升 16.5% 以及 Precision 和 Recall 各提高 25%。这项创新方法桥接了临床数据增强的空白，提升了 AI 驱动医疗诊断的预测性能，同时确保数据完整性。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "I.5.1; J.3; H.3.3; I.2.7"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08227v3",
      "published_date": "2024-07-11 07:01:50 UTC",
      "updated_date": "2025-03-15 06:25:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:48:45.190307"
    },
    {
      "arxiv_id": "2407.08224v1",
      "title": "stEnTrans: Transformer-based deep learning for spatial transcriptomics enhancement",
      "title_zh": "翻译失败",
      "authors": [
        "Shuailin Xue",
        "Fangfang Zhu",
        "Changmiao Wang",
        "Wenwen Min"
      ],
      "abstract": "The spatial location of cells within tissues and organs is crucial for the\nmanifestation of their specific functions.Spatial transcriptomics technology\nenables comprehensive measurement of the gene expression patterns in tissues\nwhile retaining spatial information. However, current popular spatial\ntranscriptomics techniques either have shallow sequencing depth or low\nresolution. We present stEnTrans, a deep learning method based on Transformer\narchitecture that provides comprehensive predictions for gene expression in\nunmeasured areas or unexpectedly lost areas and enhances gene expression in\noriginal and inputed spots. Utilizing a self-supervised learning approach,\nstEnTrans establishes proxy tasks on gene expression profile without requiring\nadditional data, mining intrinsic features of the tissues as supervisory\ninformation. We evaluate stEnTrans on six datasets and the results indicate\nsuperior performance in enhancing spots resolution and predicting gene\nexpression in unmeasured areas compared to other deep learning and traditional\ninterpolation methods. Additionally, Our method also can help the discovery of\nspatial patterns in Spatial Transcriptomics and enrich to more biologically\nsignificant pathways. Our source code is available at\nhttps://github.com/shuailinxue/stEnTrans.",
      "tldr_zh": "本研究提出stEnTrans，一种基于Transformer架构的深度学习方法，用于提升spatial transcriptomics的空间分辨率和基因表达预测。该方法采用self-supervised learning，通过基因表达配置文件建立代理任务，挖掘组织的内在特征，而无需额外数据，从而预测未测量区域的基因表达并增强原有点的表达质量。在六个数据集上的评估显示，stEnTrans在增强分辨率和预测准确性方面优于其他深度学习和传统插值方法，并有助于发现spatial patterns和生物学意义通路。",
      "categories": [
        "q-bio.QM",
        "cs.AI"
      ],
      "primary_category": "q-bio.QM",
      "comment": "ISBRA2024, Code: https://github.com/shuailinxue/stEnTrans",
      "pdf_url": "http://arxiv.org/pdf/2407.08224v1",
      "published_date": "2024-07-11 06:50:34 UTC",
      "updated_date": "2024-07-11 06:50:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:48:55.374571"
    },
    {
      "arxiv_id": "2407.08223v2",
      "title": "Speculative RAG: Enhancing Retrieval Augmented Generation through Drafting",
      "title_zh": "翻译失败",
      "authors": [
        "Zilong Wang",
        "Zifeng Wang",
        "Long Le",
        "Huaixiu Steven Zheng",
        "Swaroop Mishra",
        "Vincent Perot",
        "Yuwei Zhang",
        "Anush Mattapalli",
        "Ankur Taly",
        "Jingbo Shang",
        "Chen-Yu Lee",
        "Tomas Pfister"
      ],
      "abstract": "Retrieval augmented generation (RAG) combines the generative abilities of\nlarge language models (LLMs) with external knowledge sources to provide more\naccurate and up-to-date responses. Recent RAG advancements focus on improving\nretrieval outcomes through iterative LLM refinement or self-critique\ncapabilities acquired through additional instruction tuning of LLMs. In this\nwork, we introduce Speculative RAG - a framework that leverages a larger\ngeneralist LM to efficiently verify multiple RAG drafts produced in parallel by\na smaller, distilled specialist LM. Each draft is generated from a distinct\nsubset of retrieved documents, offering diverse perspectives on the evidence\nwhile reducing input token counts per draft. This approach enhances\ncomprehension of each subset and mitigates potential position bias over long\ncontext. Our method accelerates RAG by delegating drafting to the smaller\nspecialist LM, with the larger generalist LM performing a single verification\npass over the drafts. Extensive experiments demonstrate that Speculative RAG\nachieves state-of-the-art performance with reduced latency on TriviaQA,\nMuSiQue, PopQA, PubHealth, and ARC-Challenge benchmarks. It notably enhances\naccuracy by up to 12.97% while reducing latency by 50.83% compared to\nconventional RAG systems on PubHealth.",
      "tldr_zh": "本研究提出 Speculative RAG 框架，通过一个更大的通用语言模型（LM）高效验证由更小的专业化 LM 生成的多个 RAG 草案，每个草案基于不同的检索文档子集，从而减少输入标记并缓解位置偏差。相比传统 RAG 系统，该方法将草案生成委托给更小模型，并由更大模型进行单次验证，提高了系统效率和证据多样性。在 TriviaQA、MuSiQue、PopQA、PubHealth 和 ARC-Challenge 等基准上，实验显示 Speculative RAG 提升准确率最多 12.97%，并将延迟减少最多 50.83%。这为检索增强生成（RAG）提供了更高效且高性能的解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.08223v2",
      "published_date": "2024-07-11 06:50:19 UTC",
      "updated_date": "2025-02-27 19:03:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:49:08.649886"
    },
    {
      "arxiv_id": "2407.08216v1",
      "title": "Multimodal contrastive learning for spatial gene expression prediction using histology images",
      "title_zh": "翻译失败",
      "authors": [
        "Wenwen Min",
        "Zhiceng Shi",
        "Jun Zhang",
        "Jun Wan",
        "Changmiao Wang"
      ],
      "abstract": "In recent years, the advent of spatial transcriptomics (ST) technology has\nunlocked unprecedented opportunities for delving into the complexities of gene\nexpression patterns within intricate biological systems. Despite its\ntransformative potential, the prohibitive cost of ST technology remains a\nsignificant barrier to its widespread adoption in large-scale studies. An\nalternative, more cost-effective strategy involves employing artificial\nintelligence to predict gene expression levels using readily accessible\nwhole-slide images (WSIs) stained with Hematoxylin and Eosin (H\\&E). However,\nexisting methods have yet to fully capitalize on multimodal information\nprovided by H&E images and ST data with spatial location. In this paper, we\npropose \\textbf{mclSTExp}, a multimodal contrastive learning with Transformer\nand Densenet-121 encoder for Spatial Transcriptomics Expression prediction. We\nconceptualize each spot as a \"word\", integrating its intrinsic features with\nspatial context through the self-attention mechanism of a Transformer encoder.\nThis integration is further enriched by incorporating image features via\ncontrastive learning, thereby enhancing the predictive capability of our model.\nOur extensive evaluation of \\textbf{mclSTExp} on two breast cancer datasets and\na skin squamous cell carcinoma dataset demonstrates its superior performance in\npredicting spatial gene expression. Moreover, mclSTExp has shown promise in\ninterpreting cancer-specific overexpressed genes, elucidating immune-related\ngenes, and identifying specialized spatial domains annotated by pathologists.\nOur source code is available at https://github.com/shizhiceng/mclSTExp.",
      "tldr_zh": "该研究针对空间转录组学 (ST) 技术的成本问题，提出了一种基于多模态对比学习 (multimodal contrastive learning) 的模型 mclSTExp，用于利用 Hematoxylin and Eosin (H&E) 染色的全滑玻图像 (WSIs) 预测基因表达水平。模型采用 Transformer 和 Densenet-121 编码器，将每个斑点视为“词”通过自注意力机制整合内在特征和空间上下文，并通过对比学习增强图像特征，以提高预测准确性。在两个乳腺癌数据集和一个皮肤鳞状细胞癌数据集上的评估显示，mclSTExp 表现出优越性能，能够解释癌症过表达基因、免疫相关基因并识别病理学家注释的空间域。源代码已开源，可从指定仓库获取。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "q-bio.QM"
      ],
      "primary_category": "eess.IV",
      "comment": "BIB, Code: https://github.com/shizhiceng/mclSTExp",
      "pdf_url": "http://arxiv.org/pdf/2407.08216v1",
      "published_date": "2024-07-11 06:33:38 UTC",
      "updated_date": "2024-07-11 06:33:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:49:31.532777"
    },
    {
      "arxiv_id": "2407.08214v1",
      "title": "Towards stable training of parallel continual learning",
      "title_zh": "翻译失败",
      "authors": [
        "Li Yuepan",
        "Fan Lyu",
        "Yuyang Li",
        "Wei Feng",
        "Guangcan Liu",
        "Fanhua Shang"
      ],
      "abstract": "Parallel Continual Learning (PCL) tasks investigate the training methods for\ncontinual learning with multi-source input, where data from different tasks are\nlearned as they arrive. PCL offers high training efficiency and is well-suited\nfor complex multi-source data systems, such as autonomous vehicles equipped\nwith multiple sensors. However, at any time, multiple tasks need to be trained\nsimultaneously, leading to severe training instability in PCL. This instability\nmanifests during both forward and backward propagation, where features are\nentangled and gradients are conflict. This paper introduces Stable Parallel\nContinual Learning (SPCL), a novel approach that enhances the training\nstability of PCL for both forward and backward propagation. For the forward\npropagation, we apply Doubly-block Toeplit (DBT) Matrix based orthogonality\nconstraints to network parameters to ensure stable and consistent propagation.\nFor the backward propagation, we employ orthogonal decomposition for gradient\nmanagement stabilizes backpropagation and mitigates gradient conflicts across\ntasks. By optimizing gradients by ensuring orthogonality and minimizing the\ncondition number, SPCL effectively stabilizing the gradient descent in complex\noptimization tasks. Experimental results demonstrate that SPCL outperforms\nstate-of-the-art methjods and achieve better training stability.",
      "tldr_zh": "本论文探讨了Parallel Continual Learning (PCL)，一种处理多源输入持续学习的训练方法，能高效适应复杂系统如自动驾驶车辆的多传感器数据，但面临前向和后向传播中的特征纠缠及梯度冲突导致的训练不稳定性。针对这些问题，作者提出Stable Parallel Continual Learning (SPCL)框架，通过在前向传播中使用Doubly-block Toeplitz (DBT) Matrix based orthogonality constraints来约束网络参数，确保传播的稳定性和一致性，并在后向传播中应用orthogonal decomposition管理梯度，减少任务间的冲突并优化梯度下降。实验结果显示，SPCL在训练稳定性上优于现有方法，证明了其在复杂优化任务中的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08214v1",
      "published_date": "2024-07-11 06:31:04 UTC",
      "updated_date": "2024-07-11 06:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:49:33.109118"
    },
    {
      "arxiv_id": "2407.08204v1",
      "title": "Chromosomal Structural Abnormality Diagnosis by Homologous Similarity",
      "title_zh": "基于同源相似性的染色体结构异常诊断",
      "authors": [
        "Juren Li",
        "Fanzhe Fu",
        "Ran Wei",
        "Yifei Sun",
        "Zeyu Lai",
        "Ning Song",
        "Xin Chen",
        "Yang Yang"
      ],
      "abstract": "Pathogenic chromosome abnormalities are very common among the general\npopulation. While numerical chromosome abnormalities can be quickly and\nprecisely detected, structural chromosome abnormalities are far more complex\nand typically require considerable efforts by human experts for identification.\nThis paper focuses on investigating the modeling of chromosome features and the\nidentification of chromosomes with structural abnormalities. Most existing\ndata-driven methods concentrate on a single chromosome and consider each\nchromosome independently, overlooking the crucial aspect of homologous\nchromosomes. In normal cases, homologous chromosomes share identical\nstructures, with the exception that one of them is abnormal. Therefore, we\npropose an adaptive method to align homologous chromosomes and diagnose\nstructural abnormalities through homologous similarity. Inspired by the process\nof human expert diagnosis, we incorporate information from multiple pairs of\nhomologous chromosomes simultaneously, aiming to reduce noise disturbance and\nimprove prediction performance. Extensive experiments on real-world datasets\nvalidate the effectiveness of our model compared to baselines.",
      "tldr_zh": "这篇论文针对染色体结构异常（chromosomal structural abnormality）的诊断问题，提出了一种基于同源相似度（homologous similarity）的自适应方法，通过对齐同源染色体（homologous chromosomes）来识别异常。不同于现有数据驱动方法仅关注单个染色体，该方法模仿专家诊断过程，同时分析多个同源染色体对，以减少噪声干扰并提升预测性能。实验在真实数据集上验证了该模型的有效性，比基线方法表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08204v1",
      "published_date": "2024-07-11 06:04:21 UTC",
      "updated_date": "2024-07-11 06:04:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:49:44.340218"
    },
    {
      "arxiv_id": "2407.08196v1",
      "title": "SoupLM: Model Integration in Large Language and Multi-Modal Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Bai",
        "Zichen Zhang",
        "Jiasen Lu",
        "Yun Fu"
      ],
      "abstract": "Training large language models (LLMs) and multimodal LLMs necessitates\nsignificant computing resources, and existing publicly available LLMs are\ntypically pre-trained on diverse, privately curated datasets spanning various\ntasks. For instance, LLaMA, Vicuna, and LLaVA are three LLM variants trained\nwith LLaMA base models using very different training recipes, tasks, and data\nmodalities. The training cost and complexity for such LLM variants grow\nrapidly. In this study, we propose to use a soup strategy to assemble these LLM\nvariants into a single well-generalized multimodal LLM (SoupLM) in a\ncost-efficient manner. Assembling these LLM variants efficiently brings\nknowledge and specialities trained from different domains and data modalities\ninto an integrated one (e.g., chatbot speciality from user-shared conversations\nfor Vicuna, and visual capacity from vision-language data for LLaVA),\ntherefore, to avoid computing costs of repetitive training on several different\ndomains. We propose series of soup strategies to systematically benchmark\nperformance gains across various configurations, and probe the soup behavior\nacross base models in the interpolation space.",
      "tldr_zh": "该论文提出了一种名为 SoupLM 的方法，使用 soup strategy 来高效整合大型语言模型 (LLMs) 和多模态模型的变体，例如 LLaMA、Vicuna 和 LLaVA，从而避免重复训练不同领域数据的计算成本。SoupLM 通过汇集这些模型的专长（如 Vicuna 的聊天能力及 LLaVA 的视觉处理能力），创建一个通用化的多模态 LLM。研究者通过系列 benchmark 测试了各种配置下的性能提升，并分析了模型在插值空间的行为，以验证整合策略的有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08196v1",
      "published_date": "2024-07-11 05:38:15 UTC",
      "updated_date": "2024-07-11 05:38:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:49:56.281567"
    },
    {
      "arxiv_id": "2407.08195v2",
      "title": "A Text-to-Game Engine for UGC-Based Role-Playing Games",
      "title_zh": "翻译失败",
      "authors": [
        "Lei Zhang",
        "Xuezheng Peng",
        "Shuyi Yang",
        "Feiyang Wang"
      ],
      "abstract": "The transition from professionally generated content (PGC) to user-generated\ncontent (UGC) has reshaped various media formats, encompassing formats such as\ntext and video. With rapid advancements in generative AI, a similar\ntransformation is set to redefine the gaming industry, particularly within the\ndomain of role-playing games (RPGs). This paper introduces a novel framework\nfor a text-to-game engine that leverages foundation models to transform simple\ntextual inputs into intricate, multi-modal RPG experiences. The engine\ndynamically generates game narratives, integrating text, visuals, and\nmechanics, while adapting characters, environments, and gameplay in realtime\nbased on player interactions. To evaluate and demonstrate the feasibility and\nversatility of this framework, we developed the 'Zagii' game engine. Zagii has\nsuccessfully powered hundreds of RPG games across diverse genres and\nfacilitated tens of thousands of online gameplay sessions, showcasing its\nscalability and adaptability. These results highlight the framework's\neffectiveness and its potential to foster a more open and democratized approach\nto game development. Our work underscores the transformative role of generative\nAI in reshaping the gaming lifecycle and advancing the boundaries of\ninteractive entertainment.",
      "tldr_zh": "这篇论文介绍了基于用户生成内容(UGC)的角色扮演游戏(RPG)的一个新型文本到游戏引擎框架，利用 foundation models 将简单文本输入转化为复杂的多模态游戏体验，包括动态生成叙事、整合文本、视觉和机制，并根据玩家互动实时适应。框架旨在推动从专业生成内容(PGC)向UGC的转变，促进游戏行业的民主化。研究团队开发了'Zagii'引擎，已成功应用于数百个RPG游戏和数万个在线游戏会话，展示了其可扩展性和适应性。这些结果强调了生成式AI在重塑游戏开发流程和扩展互动娱乐边界方面的变革潜力。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, 9 figures",
      "pdf_url": "http://arxiv.org/pdf/2407.08195v2",
      "published_date": "2024-07-11 05:33:19 UTC",
      "updated_date": "2025-01-11 07:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:50:20.061742"
    },
    {
      "arxiv_id": "2407.08192v3",
      "title": "Dynamic Co-Optimization Compiler: Leveraging Multi-Agent Reinforcement Learning for Enhanced DNN Accelerator Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Arya Fayyazi",
        "Mehdi Kamal",
        "Massoud Pedram"
      ],
      "abstract": "This paper introduces a novel Dynamic Co-Optimization Compiler (DCOC), which\nemploys an adaptive Multi-Agent Reinforcement Learning (MARL) framework to\nenhance the efficiency of mapping machine learning (ML) models, particularly\nDeep Neural Networks (DNNs), onto diverse hardware platforms. DCOC incorporates\nthree specialized actor-critic agents within MARL, each dedicated to different\noptimization facets: one for hardware and two for software. This cooperative\nstrategy results in an integrated hardware/software co-optimization approach,\nimproving the precision and speed of DNN deployments. By focusing on\nhigh-confidence configurations, DCOC effectively reduces the search space,\nachieving remarkable performance over existing methods. Our results demonstrate\nthat DCOC enhances throughput by up to 37.95% while reducing optimization time\nby up to 42.2% across various DNN models, outperforming current\nstate-of-the-art frameworks.",
      "tldr_zh": "本论文提出了一种新型动态协同优化编译器(Dynamic Co-Optimization Compiler, DCOC)，利用自适应多智能体强化学习(Multi-Agent Reinforcement Learning, MARL)框架来提升Deep Neural Networks (DNNs)模型在各种硬件平台上的映射效率。DCOC 包含三个专门的 actor-critic 智能体，分别负责硬件优化和软件优化，实现硬件/软件协同策略，从而减少搜索空间并提高部署的精度和速度。实验结果显示，DCOC 在多种 DNN 模型上将吞吐量提升高达 37.95%，并将优化时间减少高达 42.2%，优于现有最先进框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.LG",
      "comment": "Proceeding of ASP-DAC25",
      "pdf_url": "http://arxiv.org/pdf/2407.08192v3",
      "published_date": "2024-07-11 05:22:04 UTC",
      "updated_date": "2025-02-21 21:17:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:50:22.170016"
    },
    {
      "arxiv_id": "2407.08189v1",
      "title": "fairBERTs: Erasing Sensitive Information Through Semantic and Fairness-aware Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Jinfeng Li",
        "Yuefeng Chen",
        "Xiangyu Liu",
        "Longtao Huang",
        "Rong Zhang",
        "Hui Xue"
      ],
      "abstract": "Pre-trained language models (PLMs) have revolutionized both the natural\nlanguage processing research and applications. However, stereotypical biases\n(e.g., gender and racial discrimination) encoded in PLMs have raised negative\nethical implications for PLMs, which critically limits their broader\napplications. To address the aforementioned unfairness issues, we present\nfairBERTs, a general framework for learning fair fine-tuned BERT series models\nby erasing the protected sensitive information via semantic and fairness-aware\nperturbations generated by a generative adversarial network. Through extensive\nqualitative and quantitative experiments on two real-world tasks, we\ndemonstrate the great superiority of fairBERTs in mitigating unfairness while\nmaintaining the model utility. We also verify the feasibility of transferring\nadversarial components in fairBERTs to other conventionally trained BERT-like\nmodels for yielding fairness improvements. Our findings may shed light on\nfurther research on building fairer fine-tuned PLMs.",
      "tldr_zh": "该研究针对预训练语言模型 (PLMs) 中存在的刻板偏见（如性别和种族歧视）问题，提出了 fairBERTs 框架，通过生成对抗网络 (GAN) 生成语义和公平感知的扰动，来擦除受保护的敏感信息，从而学习更公平的微调 BERT 系列模型。在两个真实任务上的定性和定量实验中，fairBERTs 显著降低了模型的不公平性，同时保持了模型的效用，并证明了其对抗组件可以转移到其他传统训练的 BERT-like 模型上以提升公平性。该框架为构建更公平的微调 PLMs 提供了重要启发。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08189v1",
      "published_date": "2024-07-11 05:13:38 UTC",
      "updated_date": "2024-07-11 05:13:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:50:35.185663"
    },
    {
      "arxiv_id": "2407.12057v1",
      "title": "NinjaLLM: Fast, Scalable and Cost-effective RAG using Amazon SageMaker and AWS Trainium and Inferentia2",
      "title_zh": "翻译失败",
      "authors": [
        "Tengfei Xue",
        "Xuefeng Li",
        "Roman Smirnov",
        "Tahir Azim",
        "Arash Sadrieh",
        "Babak Pahlavan"
      ],
      "abstract": "Retrieval-augmented generation (RAG) techniques are widely used today to\nretrieve and present information in a conversational format. This paper\npresents a set of enhancements to traditional RAG techniques, focusing on large\nlanguage models (LLMs) fine-tuned and hosted on AWS Trainium and Inferentia2 AI\nchips via SageMaker. These chips are characterized by their elasticity,\naffordability, and efficient performance for AI compute tasks. Besides enabling\ndeployment on these chips, this work aims to improve tool usage, add citation\ncapabilities, and mitigate the risks of hallucinations and unsafe responses due\nto context bias. We benchmark our RAG system's performance on the Natural\nQuestions and HotPotQA datasets, achieving an accuracy of 62% and 59%\nrespectively, exceeding other models such as DBRX and Mixtral Instruct.",
      "tldr_zh": "该论文介绍了NinjaLLM，一种快速、可扩展且成本有效的RAG（Retrieval-augmented generation）系统，利用Amazon SageMaker和AWS Trainium及Inferentia2芯片来微调和托管大型语言模型（LLMs）。该系统通过改进工具使用、添加引用功能，并缓解幻觉和不安全响应风险（如上下文偏差），提升了RAG的可靠性和性能。实验结果显示，在Natural Questions和HotPotQA数据集上，NinjaLLM分别实现了62%和59%的准确率，超过了DBRX和Mixtral Instruct等模型。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "I.2.7"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.12057v1",
      "published_date": "2024-07-11 05:04:44 UTC",
      "updated_date": "2024-07-11 05:04:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:50:45.844287"
    },
    {
      "arxiv_id": "2407.08179v1",
      "title": "CoGS: Causality Constrained Counterfactual Explanations using goal-directed ASP",
      "title_zh": "翻译失败",
      "authors": [
        "Sopam Dasgupta",
        "Joaquín Arias",
        "Elmer Salazar",
        "Gopal Gupta"
      ],
      "abstract": "Machine learning models are increasingly used in areas such as loan approvals\nand hiring, yet they often function as black boxes, obscuring their\ndecision-making processes. Transparency is crucial, and individuals need\nexplanations to understand decisions, especially for the ones not desired by\nthe user. Ethical and legal considerations require informing individuals of\nchanges in input attribute values (features) that could lead to a desired\noutcome for the user. Our work aims to generate counterfactual explanations by\nconsidering causal dependencies between features. We present the CoGS\n(Counterfactual Generation with s(CASP)) framework that utilizes the\ngoal-directed Answer Set Programming system s(CASP) to generate counterfactuals\nfrom rule-based machine learning models, specifically the FOLD-SE algorithm.\nCoGS computes realistic and causally consistent changes to attribute values\ntaking causal dependencies between them into account. It finds a path from an\nundesired outcome to a desired one using counterfactuals. We present details of\nthe CoGS framework along with its evaluation.",
      "tldr_zh": "这篇论文提出了 CoGS 框架，利用 goal-directed Answer Set Programming (s(CASP)) 系统，从规则-based 机器学习模型（如 FOLD-SE）生成考虑因果依赖的反事实解释 (counterfactual explanations)，以提升模型决策的透明性。CoGS 通过计算现实且因果一致的属性值变化，帮助用户从不良结果转向期望结果，同时处理特征间的因果关系。实验评估显示，该框架在生成可解释性和可靠性方面表现出色，为伦理和法律合规的 AI 决策提供支持。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.LO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08179v1",
      "published_date": "2024-07-11 04:50:51 UTC",
      "updated_date": "2024-07-11 04:50:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:50:58.487035"
    },
    {
      "arxiv_id": "2407.08176v1",
      "title": "Foundation Model Engineering: Engineering Foundation Models Just as Engineering Software",
      "title_zh": "翻译失败",
      "authors": [
        "Dezhi Ran",
        "Mengzhou Wu",
        "Wei Yang",
        "Tao Xie"
      ],
      "abstract": "By treating data and models as the source code, Foundation Models (FMs)\nbecome a new type of software. Mirroring the concept of software crisis, the\nincreasing complexity of FMs making FM crisis a tangible concern in the coming\ndecade, appealing for new theories and methodologies from the field of software\nengineering. In this paper, we outline our vision of introducing Foundation\nModel (FM) engineering, a strategic response to the anticipated FM crisis with\nprincipled engineering methodologies. FM engineering aims to mitigate potential\nissues in FM development and application through the introduction of\ndeclarative, automated, and unified programming interfaces for both data and\nmodel management, reducing the complexities involved in working with FMs by\nproviding a more structured and intuitive process for developers. Through the\nestablishment of FM engineering, we aim to provide a robust, automated, and\nextensible framework that addresses the imminent challenges, and discovering\nnew research opportunities for the software engineering field.",
      "tldr_zh": "该论文将基础模型（Foundation Models, FMs）视为一种新软件类型，将其数据和模型比作源代码，以应对日益复杂的FM危机，类似于软件工程领域的历史挑战。作者提出基础模型工程（FM engineering）作为战略响应，通过引入声明式、自动化和统一的编程接口来简化数据和模型管理，提供更结构化和直观的开发过程。最终，该框架旨在缓解FM开发中的潜在问题，建立一个稳健、可扩展的系统，并为软件工程领域发现新的研究机会。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted by 2030 Software Engineering Workshop, co-located with\n  FSE24; Invited to ACM TOSEM 2030 Roadmap for Software Engineering",
      "pdf_url": "http://arxiv.org/pdf/2407.08176v1",
      "published_date": "2024-07-11 04:40:02 UTC",
      "updated_date": "2024-07-11 04:40:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:51:09.515730"
    },
    {
      "arxiv_id": "2407.08169v2",
      "title": "The Approximate Fisher Influence Function: Faster Estimation of Data Influence in Statistical Models",
      "title_zh": "翻译失败",
      "authors": [
        "Omri Lev",
        "Ashia C. Wilson"
      ],
      "abstract": "Quantifying the influence of infinitesimal changes in training data on model\nperformance is crucial for understanding and improving machine learning models.\nIn this work, we reformulate this problem as a weighted empirical risk\nminimization and enhance existing influence function-based methods by using\ninformation geometry to derive a new algorithm to estimate influence. Our\nformulation proves versatile across various applications, and we further\ndemonstrate in simulations how it remains informative even in non-convex cases.\nFurthermore, we show that our method offers significant computational\nadvantages over current Newton step-based methods.",
      "tldr_zh": "本文提出 Approximate Fisher Influence Function，一种基于信息几何的新算法，用于更快地估计训练数据微小变化对机器学习模型性能的影响。该方法将问题重新表述为加权 empirical risk minimization，提升了现有影响函数技术的适用性和准确性。模拟实验显示，即使在非凸情况下，该算法也能提供可靠的信息，且在计算效率上显著优于 Newton step-based methods。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08169v2",
      "published_date": "2024-07-11 04:19:28 UTC",
      "updated_date": "2025-04-10 02:33:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:51:22.160670"
    },
    {
      "arxiv_id": "2407.08166v1",
      "title": "Synthetic Electroretinogram Signal Generation Using Conditional Generative Adversarial Network for Enhancing Classification of Autism Spectrum Disorder",
      "title_zh": "翻译失败",
      "authors": [
        "Mikhail Kulyabin",
        "Paul A. Constable",
        "Aleksei Zhdanov",
        "Irene O. Lee",
        "David H. Skuse",
        "Dorothy A. Thompson",
        "Andreas Maier"
      ],
      "abstract": "The electroretinogram (ERG) is a clinical test that records the retina's\nelectrical response to light. The ERG is a promising way to study different\nneurodevelopmental and neurodegenerative disorders, including autism spectrum\ndisorder (ASD) - a neurodevelopmental condition that impacts language,\ncommunication, and reciprocal social interactions. However, in heterogeneous\npopulations, such as ASD, where the ability to collect large datasets is\nlimited, the application of artificial intelligence (AI) is complicated.\nSynthetic ERG signals generated from real ERG recordings carry similar\ninformation as natural ERGs and, therefore, could be used as an extension for\nnatural data to increase datasets so that AI applications can be fully\nutilized. As proof of principle, this study presents a Generative Adversarial\nNetwork capable of generating synthetic ERG signals of children with ASD and\ntypically developing control individuals. We applied a Time Series Transformer\nand Visual Transformer with Continuous Wavelet Transform to enhance\nclassification results on the extended synthetic signals dataset. This approach\nmay support classification models in related psychiatric conditions where the\nERG may help classify disorders.",
      "tldr_zh": "本研究针对自闭症谱系障碍（Autism Spectrum Disorder, ASD）的数据集有限问题，提出使用条件生成式对抗网络（Conditional Generative Adversarial Network, GAN）生成合成电生理图（Electroretinogram, ERG）信号，以扩展数据集并提升AI分类性能。方法包括从真实ERG记录中生成合成信号，并结合Time Series Transformer和Visual Transformer with Continuous Wavelet Transform模型，对ASD儿童和正常对照组的扩展数据集进行分类实验。结果显示，该方法有效提高了分类准确性，并为ERG在相关精神疾病诊断中的应用提供了潜在支持。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "eess.SP"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08166v1",
      "published_date": "2024-07-11 04:11:52 UTC",
      "updated_date": "2024-07-11 04:11:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:51:34.304410"
    },
    {
      "arxiv_id": "2407.08164v2",
      "title": "Hierarchical Consensus-Based Multi-Agent Reinforcement Learning for Multi-Robot Cooperation Tasks",
      "title_zh": "基于层级共识的多",
      "authors": [
        "Pu Feng",
        "Junkang Liang",
        "Size Wang",
        "Xin Yu",
        "Xin Ji",
        "Yiting Chen",
        "Kui Zhang",
        "Rongye Shi",
        "Wenjun Wu"
      ],
      "abstract": "In multi-agent reinforcement learning (MARL), the Centralized Training with\nDecentralized Execution (CTDE) framework is pivotal but struggles due to a gap:\nglobal state guidance in training versus reliance on local observations in\nexecution, lacking global signals. Inspired by human societal consensus\nmechanisms, we introduce the Hierarchical Consensus-based Multi-Agent\nReinforcement Learning (HC-MARL) framework to address this limitation. HC-MARL\nemploys contrastive learning to foster a global consensus among agents,\nenabling cooperative behavior without direct communication. This approach\nenables agents to form a global consensus from local observations, using it as\nan additional piece of information to guide collaborative actions during\nexecution. To cater to the dynamic requirements of various tasks, consensus is\ndivided into multiple layers, encompassing both short-term and long-term\nconsiderations. Short-term observations prompt the creation of an immediate,\nlow-layer consensus, while long-term observations contribute to the formation\nof a strategic, high-layer consensus. This process is further refined through\nan adaptive attention mechanism that dynamically adjusts the influence of each\nconsensus layer. This mechanism optimizes the balance between immediate\nreactions and strategic planning, tailoring it to the specific demands of the\ntask at hand. Extensive experiments and real-world applications in multi-robot\nsystems showcase our framework's superior performance, marking significant\nadvancements over baselines.",
      "tldr_zh": "该论文针对多智能体强化学习(MARL)中 Centralized Training with Decentralized Execution (CTDE) 框架的局限性，即训练时依赖全局状态而执行时仅用局部观察缺少全局信号，提出 Hierarchical Consensus-based Multi-Agent Reinforcement Learning (HC-MARL) 框架。HC-MARL 通过对比学习(contrastive learning)帮助代理从局部观察中形成全局共识，实现无需直接通信的合作行为，并将共识分层设计，包括短期低层共识和长期高层共识，以平衡即时反应和战略规划；此外，自适应注意力机制动态调整各层影响。实验和实际多机器人系统应用显示，HC-MARL 显著优于基线模型，提升了多机器人合作任务的性能。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages, 10 figures. Accepted for presentation at the IEEE/RSJ\n  International Conference on Intelligent Robots and Systems (IROS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2407.08164v2",
      "published_date": "2024-07-11 03:55:55 UTC",
      "updated_date": "2024-08-23 13:07:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:51:45.753746"
    },
    {
      "arxiv_id": "2407.08152v2",
      "title": "Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models (Extended Version)",
      "title_zh": "翻译失败",
      "authors": [
        "Aydin Abadi",
        "Vishnu Asutosh Dasu",
        "Sumanta Sarkar"
      ],
      "abstract": "Deduplication is a vital preprocessing step that enhances machine learning\nmodel performance and saves training time and energy. However, enhancing\nfederated learning through deduplication poses challenges, especially regarding\nscalability and potential privacy violations if deduplication involves sharing\nall clients' data. In this paper, we address the problem of deduplication in a\nfederated setup by introducing a pioneering protocol, Efficient\nPrivacy-Preserving Multi-Party Deduplication (EP-MPD). It efficiently removes\nduplicates from multiple clients' datasets without compromising data privacy.\nEP-MPD is constructed in a modular fashion, utilizing two novel variants of the\nPrivate Set Intersection protocol. Our extensive experiments demonstrate the\nsignificant benefits of deduplication in federated learning of large language\nmodels. For instance, we observe up to 19.62\\% improvement in perplexity and up\nto 27.95\\% reduction in running time while varying the duplication level\nbetween 10\\% and 30\\%. EP-MPD effectively balances privacy and performance in\nfederated learning, making it a valuable solution for large-scale applications.",
      "tldr_zh": "这篇论文针对联邦学习(Federated Learning)中数据去重(Deduplication)的隐私挑战，提出了一种新型协议Efficient Privacy-Preserving Multi-Party Deduplication (EP-MPD)，它能高效地在多个客户端的数据中去除重复，同时保护数据隐私。EP-MPD采用模块化设计，基于两种创新的Private Set Intersection协议来实现这一功能。实验结果显示，在大型语言模型的联邦学习中，该协议在重复率10%至30%的情况下，改善Perplexity高达19.62%、减少运行时间高达27.95%。总体而言，EP-MPD在隐私保护和性能提升之间实现了良好平衡，适用于大规模应用。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.CR",
      "comment": "Accepted at the Network and Distributed Systems Security (NDSS)\n  Symposium, 2025",
      "pdf_url": "http://arxiv.org/pdf/2407.08152v2",
      "published_date": "2024-07-11 03:10:27 UTC",
      "updated_date": "2024-12-04 17:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:51:59.488806"
    },
    {
      "arxiv_id": "2407.08147v1",
      "title": "Looks can be Deceptive: Distinguishing Repetition Disfluency from Reduplication",
      "title_zh": "翻译失败",
      "authors": [
        "Arif Ahmad",
        "Mothika Gayathri Khyathi",
        "Pushpak Bhattacharyya"
      ],
      "abstract": "Reduplication and repetition, though similar in form, serve distinct\nlinguistic purposes. Reduplication is a deliberate morphological process used\nto express grammatical, semantic, or pragmatic nuances, while repetition is\noften unintentional and indicative of disfluency. This paper presents the first\nlarge-scale study of reduplication and repetition in speech using computational\nlinguistics. We introduce IndicRedRep, a new publicly available dataset\ncontaining Hindi, Telugu, and Marathi text annotated with reduplication and\nrepetition at the word level. We evaluate transformer-based models for\nmulti-class reduplication and repetition token classification, utilizing the\nReparandum-Interregnum-Repair structure to distinguish between the two\nphenomena. Our models achieve macro F1 scores of up to 85.62% in Hindi, 83.95%\nin Telugu, and 84.82% in Marathi for reduplication-repetition classification.",
      "tldr_zh": "该论文探讨了 Reduplication（故意的形态学过程，用于表达语法、语义或语用细微差别）和 Repetition（无意的流利问题）的区别，首次通过计算语言学进行大规模研究。\n研究团队引入了公开数据集 IndicRedRep，包含 Hindi、Telugu 和 Marathi 的单词级别标注文本，并使用 Transformer-based 模型结合 Reparandum-Interregnum-Repair 结构进行多类分类。\n实验结果显示，模型在 Hindi、Telugu 和 Marathi 上分别达到了 85.62%、83.95% 和 84.82% 的宏 F1 分数，有效区分了两种现象。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08147v1",
      "published_date": "2024-07-11 03:00:14 UTC",
      "updated_date": "2024-07-11 03:00:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:52:11.539988"
    },
    {
      "arxiv_id": "2407.08134v1",
      "title": "Highway Networks for Improved Surface Reconstruction: The Role of Residuals and Weight Updates",
      "title_zh": "Highway Networks 用于改进表面重建：残差和权重更新的作用",
      "authors": [
        "A. Noorizadegan",
        "Y. C. Hon",
        "D. L. Young",
        "C. S. Chen"
      ],
      "abstract": "Surface reconstruction from point clouds is a fundamental challenge in\ncomputer graphics and medical imaging. In this paper, we explore the\napplication of advanced neural network architectures for the accurate and\nefficient reconstruction of surfaces from data points. We introduce a novel\nvariant of the Highway network (Hw) called Square-Highway (SqrHw) within the\ncontext of multilayer perceptrons and investigate its performance alongside\nplain neural networks and a simplified Hw in various numerical examples. These\nexamples include the reconstruction of simple and complex surfaces, such as\nspheres, human hands, and intricate models like the Stanford Bunny. We analyze\nthe impact of factors such as the number of hidden layers, interior and\nexterior points, and data distribution on surface reconstruction quality. Our\nresults show that the proposed SqrHw architecture outperforms other neural\nnetwork configurations, achieving faster convergence and higher-quality surface\nreconstructions. Additionally, we demonstrate the SqrHw's ability to predict\nsurfaces over missing data, a valuable feature for challenging applications\nlike medical imaging. Furthermore, our study delves into further details,\ndemonstrating that the proposed method based on highway networks yields more\nstable weight norms and backpropagation gradients compared to the Plain Network\narchitecture. This research not only advances the field of computer graphics\nbut also holds utility for other purposes such as function interpolation and\nphysics-informed neural networks, which integrate multilayer perceptrons into\ntheir algorithms.",
      "tldr_zh": "本文研究了从点云（point clouds）中重建表面的挑战，提出了一种新型神经网络架构 Square-Highway (SqrHw)，作为 Highway network (Hw) 的变体，应用于多层感知器 (multilayer perceptrons)，并与普通神经网络和简化 Hw 进行了比较。实验涉及简单和复杂表面的重建，如 spheres、human hands 和 Stanford Bunny，分析了隐藏层数、数据分布等因素对重建质量的影响。结果表明，SqrHw 实现了更快收敛、更高质量的表面重建，并能有效预测缺失数据，同时权重范数和反向传播梯度更稳定。该方法不仅提升了计算机图形学和医学成像的应用，还扩展到函数插值和 physics-informed neural networks 等领域。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08134v1",
      "published_date": "2024-07-11 02:15:21 UTC",
      "updated_date": "2024-07-11 02:15:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:52:23.949675"
    },
    {
      "arxiv_id": "2407.08133v2",
      "title": "Nonverbal Interaction Detection",
      "title_zh": "非语言互动检测",
      "authors": [
        "Jianan Wei",
        "Tianfei Zhou",
        "Yi Yang",
        "Wenguan Wang"
      ],
      "abstract": "This work addresses a new challenge of understanding human nonverbal\ninteraction in social contexts. Nonverbal signals pervade virtually every\ncommunicative act. Our gestures, facial expressions, postures, gaze, even\nphysical appearance all convey messages, without anything being said. Despite\ntheir critical role in social life, nonverbal signals receive very limited\nattention as compared to the linguistic counterparts, and existing solutions\ntypically examine nonverbal cues in isolation. Our study marks the first\nsystematic effort to enhance the interpretation of multifaceted nonverbal\nsignals. First, we contribute a novel large-scale dataset, called NVI, which is\nmeticulously annotated to include bounding boxes for humans and corresponding\nsocial groups, along with 22 atomic-level nonverbal behaviors under five broad\ninteraction types. Second, we establish a new task NVI-DET for nonverbal\ninteraction detection, which is formalized as identifying triplets in the form\n<individual, group, interaction> from images. Third, we propose a nonverbal\ninteraction detection hypergraph (NVI-DEHR), a new approach that explicitly\nmodels high-order nonverbal interactions using hypergraphs. Central to the\nmodel is a dual multi-scale hypergraph that adeptly addresses\nindividual-to-individual and group-to-group correlations across varying scales,\nfacilitating interactional feature learning and eventually improving\ninteraction prediction. Extensive experiments on NVI show that NVI-DEHR\nimproves various baselines significantly in NVI-DET. It also exhibits leading\nperformance on HOI-DET, confirming its versatility in supporting related tasks\nand strong generalization ability. We hope that our study will offer the\ncommunity new avenues to explore nonverbal signals in more depth.",
      "tldr_zh": "本研究针对社交语境中人类非语言互动的理解问题，强调非语言信号（如手势、面部表情和姿势）的重要性，但现有方法往往孤立分析。研究贡献了一个大型数据集 NVI，包括人类边界框、社会群体和22种原子级非语言行为，分为五种互动类型，并定义了新任务 NVI-DET，即从图像中识别<individual, group, interaction>的三元组。作者提出了一种新方法 NVI-DEHR，使用 hypergraphs 显式建模高阶互动，通过双重多尺度超图处理个体间和群体间的相关性，提升互动特征学习。实验结果显示，NVI-DEHR 在 NVI 数据集上显著优于基线模型，并在 HOI-DET 任务中表现出色，证明了其通用性和泛化能力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024; Project page: https://github.com/weijianan1/NVI",
      "pdf_url": "http://arxiv.org/pdf/2407.08133v2",
      "published_date": "2024-07-11 02:14:06 UTC",
      "updated_date": "2024-07-14 13:33:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:52:37.106088"
    },
    {
      "arxiv_id": "2407.08126v1",
      "title": "Label-anticipated Event Disentanglement for Audio-Visual Video Parsing",
      "title_zh": "基于标签预期的音频-视觉视频解析中的事件解耦",
      "authors": [
        "Jinxing Zhou",
        "Dan Guo",
        "Yuxin Mao",
        "Yiran Zhong",
        "Xiaojun Chang",
        "Meng Wang"
      ],
      "abstract": "Audio-Visual Video Parsing (AVVP) task aims to detect and temporally locate\nevents within audio and visual modalities. Multiple events can overlap in the\ntimeline, making identification challenging. While traditional methods usually\nfocus on improving the early audio-visual encoders to embed more effective\nfeatures, the decoding phase -- crucial for final event classification, often\nreceives less attention. We aim to advance the decoding phase and improve its\ninterpretability. Specifically, we introduce a new decoding paradigm,\n\\underline{l}abel s\\underline{e}m\\underline{a}ntic-based \\underline{p}rojection\n(LEAP), that employs labels texts of event categories, each bearing distinct\nand explicit semantics, for parsing potentially overlapping events.LEAP works\nby iteratively projecting encoded latent features of audio/visual segments onto\nsemantically independent label embeddings. This process, enriched by modeling\ncross-modal (audio/visual-label) interactions, gradually disentangles event\nsemantics within video segments to refine relevant label embeddings,\nguaranteeing a more discriminative and interpretable decoding process. To\nfacilitate the LEAP paradigm, we propose a semantic-aware optimization\nstrategy, which includes a novel audio-visual semantic similarity loss\nfunction. This function leverages the Intersection over Union of audio and\nvisual events (EIoU) as a novel metric to calibrate audio-visual similarities\nat the feature level, accommodating the varied event densities across\nmodalities. Extensive experiments demonstrate the superiority of our method,\nachieving new state-of-the-art performance for AVVP and also enhancing the\nrelevant audio-visual event localization task.",
      "tldr_zh": "本文针对 Audio-Visual Video Parsing (AVVP) 任务，提出一种新的解码范式 LEAP（Label Semantic-based Projection），通过将音频/视觉段的编码特征迭代投影到语义独立的标签嵌入上，并建模跨模态（音频/视觉-标签）交互，来逐步分离潜在重叠事件，提高解码过程的可解释性和区分度。LEAP 结合语义感知优化策略，包括一个基于音频-视觉事件 Intersection over Union (EIoU) 的损失函数，用于在特征级别校准模态间相似性，以适应不同事件密度。实验结果表明，该方法在 AVVP 任务和相关音频-视觉事件定位任务上实现了新的 state-of-the-art 性能。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by ECCV2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08126v1",
      "published_date": "2024-07-11 01:57:08 UTC",
      "updated_date": "2024-07-11 01:57:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:52:49.464005"
    },
    {
      "arxiv_id": "2407.08112v2",
      "title": "How Well Can a Long Sequence Model Model Long Sequences? Comparing Architechtural Inductive Biases on Long-Context Abilities",
      "title_zh": "翻译失败",
      "authors": [
        "Jerry Huang"
      ],
      "abstract": "Long sequences occur in abundance within real-world scenarios, hence properly\nmodelling them opens numerous down-stream use-cases. Deep neural networks,\nhowever, have often struggled with these for a variety of reasons. Recent\nadvances, both in system engineering as well as model design, have enabled the\nscaling up of model that are purported to support extended context length. In\nparticular, the state-space and linear recurrent neural network families of\nmodels hypothetically can entend to infinite sequence lenth. However, is this\ntoo good to be true? We conduct an evaluation to show that while such claims\nmay be sound theoretically, there remain large practical gaps that are\nempirically observed. In particular, recurrent models still suffer in the same\nsettings as long-context LLMs with attention. We further show that different\ninductive biases have inconsistent extrapolation capabilities, highlighting the\nneed to further study such paradigms and investigate why long-context models\nseemingly fail to behave as one might expect.",
      "tldr_zh": "本研究评估了长序列模型在处理长序列时的实际性能，比较了不同架构的归纳偏差（inductive biases），以检验这些模型是否能如理论预期的支持无限长度序列。实验结果显示，尽管状态空间和线性RNN模型理论上强大，但它们在实际场景中表现不佳，与长上下文LLMs类似，存在显著差距。研究进一步发现，不同归纳偏差的模型在外推能力上不一致，突出了需要深入探究长上下文模型失败原因的必要性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "Work In Progress. 9 pages",
      "pdf_url": "http://arxiv.org/pdf/2407.08112v2",
      "published_date": "2024-07-11 01:08:39 UTC",
      "updated_date": "2024-07-26 17:31:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:53:00.768868"
    },
    {
      "arxiv_id": "2407.08109v1",
      "title": "Urban Waterlogging Detection: A Challenging Benchmark and Large-Small Model Co-Adapter",
      "title_zh": "城市积水检测：一个具有挑战性的基准以及大型-小型模型协同适配器",
      "authors": [
        "Suqi Song",
        "Chenxu Zhang",
        "Peng Zhang",
        "Pengkun Li",
        "Fenglong Song",
        "Lei Zhang"
      ],
      "abstract": "Urban waterlogging poses a major risk to public safety and infrastructure.\nConventional methods using water-level sensors need high-maintenance to hardly\nachieve full coverage. Recent advances employ surveillance camera imagery and\ndeep learning for detection, yet these struggle amidst scarce data and adverse\nenvironmental conditions. In this paper, we establish a challenging Urban\nWaterlogging Benchmark (UW-Bench) under diverse adverse conditions to advance\nreal-world applications. We propose a Large-Small Model co-adapter paradigm\n(LSM-adapter), which harnesses the substantial generic segmentation potential\nof large model and the specific task-directed guidance of small model.\nSpecifically, a Triple-S Prompt Adapter module alongside a Dynamic Prompt\nCombiner are proposed to generate then merge multiple prompts for mask decoder\nadaptation. Meanwhile, a Histogram Equalization Adap-ter module is designed to\ninfuse the image specific information for image encoder adaptation. Results and\nanalysis show the challenge and superiority of our developed benchmark and\nalgorithm. Project page: \\url{https://github.com/zhang-chenxu/LSM-Adapter}",
      "tldr_zh": "本研究针对城市水浸（Urban Waterlogging）检测面临的挑战，如数据稀缺和不利环境条件，建立了 Urban Waterlogging Benchmark (UW-Bench) 基准，以多样化场景推进实际应用。论文提出 Large-Small Model co-adapter paradigm (LSM-adapter)，通过整合大模型的通用分割潜力与小模型的任务导向指导，提升检测性能。具体而言，该方法包括 Triple-S Prompt Adapter 和 Dynamic Prompt Combiner 用于生成并合并提示以适应掩码解码器，以及 Histogram Equalization Adapter 用于注入图像特定信息以适应图像编码器。实验结果展示了 UW-Bench 的挑战性和 LSM-adapter 的优越性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "ECCV 2024",
      "pdf_url": "http://arxiv.org/pdf/2407.08109v1",
      "published_date": "2024-07-11 01:03:02 UTC",
      "updated_date": "2024-07-11 01:03:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:53:14.714825"
    },
    {
      "arxiv_id": "2407.08108v2",
      "title": "CADC: Encoding User-Item Interactions for Compressing Recommendation Model Training Data",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Entezari Zarch",
        "Abdulla Alshabanah",
        "Chaoyi Jiang",
        "Murali Annavaram"
      ],
      "abstract": "Deep learning recommendation models (DLRMs) are at the heart of the current\ne-commerce industry. However, the amount of training data used to train these\nlarge models is growing exponentially, leading to substantial training hurdles.\nThe training dataset contains two primary types of information: content-based\ninformation (features of users and items) and collaborative information\n(interactions between users and items). One approach to reduce the training\ndataset is to remove user-item interactions. But that significantly diminishes\ncollaborative information, which is crucial for maintaining accuracy due to its\ninclusion of interaction histories. This loss profoundly impacts DLRM\nperformance.\n  This paper makes an important observation that if one can capture the\nuser-item interaction history to enrich the user and item embeddings, then the\ninteraction history can be compressed without losing model accuracy. Thus, this\nwork, Collaborative Aware Data Compression (CADC), takes a two-step approach to\ntraining dataset compression. In the first step, we use matrix factorization of\nthe user-item interaction matrix to create a novel embedding representation for\nboth the users and items. Once the user and item embeddings are enriched by the\ninteraction history information the approach then applies uniform random\nsampling of the training dataset to drastically reduce the training dataset\nsize while minimizing model accuracy drop. The source code of CADC is available\nat\n\\href{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}{https://anonymous.4open.science/r/DSS-RM-8C1D/README.md}.",
      "tldr_zh": "这篇论文针对深度学习推荐模型（DLRMs）的训练数据爆炸式增长问题，提出了一种协作感知数据压缩方法（CADC），旨在通过编码用户-物品互动信息来减少数据集大小。CADC 的两步方法包括：首先，使用矩阵分解（matrix factorization）对用户-物品互动矩阵进行处理，以丰富用户和物品的 embedding 表示；其次，应用均匀随机采样（uniform random sampling）来大幅压缩训练数据集，同时最小化模型准确性损失。该方法有效地保留了协作信息（collaborative information），为高效的推荐模型训练提供了实用解决方案。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2407.08108v2",
      "published_date": "2024-07-11 00:54:56 UTC",
      "updated_date": "2024-07-24 03:37:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:53:24.630988"
    },
    {
      "arxiv_id": "2407.08105v2",
      "title": "Federated Learning and AI Regulation in the European Union: Who is Responsible? -- An Interdisciplinary Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Herbert Woisetschläger",
        "Simon Mertel",
        "Christoph Krönke",
        "Ruben Mayer",
        "Hans-Arno Jacobsen"
      ],
      "abstract": "The European Union Artificial Intelligence Act mandates clear stakeholder\nresponsibilities in developing and deploying machine learning applications to\navoid substantial fines, prioritizing private and secure data processing with\ndata remaining at its origin. Federated Learning (FL) enables the training of\ngenerative AI Models across data siloes, sharing only model parameters while\nimproving data security. Since FL is a cooperative learning paradigm, clients\nand servers naturally share legal responsibility in the FL pipeline. Our work\ncontributes to clarifying the roles of both parties, explains strategies for\nshifting responsibilities to the server operator, and points out open technical\nchallenges that we must solve to improve FL's practical applicability under the\nEU AI Act.",
      "tldr_zh": "欧盟人工智能法案（EU AI Act）要求在开发和部署机器学习应用时明确利益相关者的责任，以避免巨额罚款，并优先保护数据隐私和安全性。论文通过跨学科分析探讨了Federated Learning (FL)——一种仅共享模型参数的合作学习范式——在欧盟法规下的应用，强调客户端和服务器在FL管道中共享法律责任。研究贡献包括澄清双方的角色、提出将责任转移到服务器操作者的策略，并指出需解决的技术挑战，以提升FL在EU AI Act下的实际可行性。",
      "categories": [
        "cs.AI",
        "K.5; I.2.11; C.2.4; D.2.1"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the GenLaw'24 workshop in conjunction with ICML'24",
      "pdf_url": "http://arxiv.org/pdf/2407.08105v2",
      "published_date": "2024-07-11 00:41:16 UTC",
      "updated_date": "2024-07-12 13:37:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-19T05:53:35.846184"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 106,
  "processed_papers_count": 106,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-19T05:53:57.106371"
}