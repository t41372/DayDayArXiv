{
  "date": "2024-11-05",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-11-05 的 arXiv 中文 TLDR 快报！今天 arXiv 的论文主要聚焦于 AI 模型的优化、安全和应用创新，特别是 Large Language Models (LLMs) 在数据科学、化学和生物领域的作用，以及多模态模型在机器人和图像生成中的潜力；令人印象深刻的包括 Yoshua Bengio 等学者参与的 AI 安全国际报告，以及 LLM 驱动的自治代理和高效生成模型。\n\n下面，我将逐一简要概述今天的论文，先优先讨论重要或有话题度的文章（如涉及知名学者、突破性贡献的），然后快速掠过其他较为常规的技术论文。每个条目包括论文标题（中文 + 英文）和核心贡献与发现，保留关键学术术语，如 Graph Neural Networks (GNNs) 或 Diffusion Models，确保描述简洁明了。\n\n### 重点论文讨论\n**1. Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level**  \n这篇论文由多位作者包括 Balazs Kegl 和 Jun Wang 合作，介绍了 Agent K v1.0，一个自治数据科学代理，使用结构化推理框架优化记忆和决策，实现92.5%的任务成功率，并在 Kaggle 竞赛中达到 Grandmaster 水平（6金3银7铜），展示了 LLM 在复杂数据科学任务中的潜力。\n\n**38. International Scientific Report on the Safety of Advanced AI (Interim Report)**  \nYoshua Bengio 等知名学者主导的报告，系统分析了 AI 安全问题，包括风险评估和监管建议；主要贡献是综合多领域专家观点，提供 AI 技术发展趋势的客观快照，强调能源需求和伦理挑战，是 AI 安全领域的重要参考。\n\n**5. Two-Stage Pretraining for Molecular Property Prediction in the Wild**  \n论文提出 MoleVers 模型，通过两阶段预训练（无标签数据上的掩码预测和有辅助标签的监督学习），在稀缺标签条件下实现分子属性预测，在22个数据集上达到最先进性能，显著提升了化学领域的 AI 泛化能力。\n\n**3. Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry**  \n作者探讨了 LLM 在化学领域的领域预训练，相比零样本或少样本方法，指令微调后的模型在命名实体识别和分子生成任务上表现出色，证明了针对性预训练在科学领域的实用价值。\n\n**8. Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs**  \n论文评估 LLM 在 lncRNA 转录调控分析中的潜力，通过细调基因组模型处理序列数据，突出了任务复杂性、模型选择和数据质量的影响，为生物信息学应用提供了新见解。\n\n**18. Character-level Tokenizations as Powerful Inductive Biases for RNA Foundational Models**  \n引入 ChaRNABERT 模型，使用可学习分词处理 RNA 序列，实现状态-of-the-art 在 RNA-蛋白交互预测上，强调字符级分词的归纳偏差优势，推进了 RNA 药物发现的计算生物学。\n\n**9. AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution**  \n论文提出 AI Metropolis 系统，通过乱序执行调度优化 LLM 多代理模拟，实现1.3x到4.15x的速度提升，解决了多代理模拟中的并行性瓶颈，适用于社会科学和游戏场景。\n\n**10. Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy**  \n作者开发动态层剪枝方法，使用 Layer Redundancy 评分优化 LLM（如 Llama3-8B），在多项基准上提升性能达5%，并开源代码，展示了模型压缩在高效推理中的应用。\n\n**15. Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents**  \n论文引入 Watson 框架，提供 LLM 代理的推理可观测性，通过运行时纠错提升代理性能，在 MMLU 和 SWE-bench-lite 上提高 Pass@1 达13.45%，增强了 AI 代理的调试和可靠性。\n\n**19. STEER: Flexible Robotic Manipulation via Dense Language Grounding**  \n提出 STEER 框架，使用语言指导的多模态策略实现机器人操作，允许人类或 VLM 协调行为，无需额外数据训练，展示了机器人任务的灵活性和泛化能力。\n\n### 其他相关论文简述\n以下论文主题较为集中，我将相关内容归类快速概述，避免冗长。\n\n**LLM 和生成模型优化（相关论文：2、4、6、7、11、12、14、16、22、26、32、39、40、47、48、50、51、54、55、56、57、58、59、63、64、65、66、67、68、69、71、72、73、74、75、76、77、78、79、80、81、82、83、84、85、86、87、88、89、90、91、92、93、94、95、96、97、98、99、100、101）**  \n- **2. Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via Controllable Image Generation**：使用 Diffusion Models 生成 HRCT 图像，提高纤维化分割的准确性，减少手动标注需求。  \n- **4. Utilizing RNN for Real-time Cryptocurrency Price Prediction and Trading Strategy Optimization**：RNN 模型捕获时间序列模式，提升加密货币预测准确性，并优化交易策略。  \n- **6. Personalized Video Summarization by Multimodal Video Understanding**：提出 VSL 管道，使用 VLMs 进行用户偏好视频总结，超越无监督模型，提高适应性和效率。  \n- **7. Mitigating Metric Bias in Minimum Bayes Risk Decoding**：通过度量集成减少 MBR 解码偏置，提升翻译质量，避免奖励操纵。  \n- **11. Automatic Generation of Question Hints for Mathematics Problems using Large Language Models**：LLM 生成数学问题提示，帮助模拟学生自纠错，提高教育技术效果。  \n- **14. dafny-annotator: AI-Assisted Verification of Dafny Programs**：使用 LLM 和搜索工具自动添加 Dafny 程序注解，提升形式验证效率。  \n- **16. Personalized Video Summarization by Multimodal Video Understanding**：(重复第6)优化视频总结模型。  \n- **22. VERITAS: A Unified Approach to Reliability Evaluation**：VERITAS 框架检测 LLM 幻觉，提供跨任务鲁棒性评估。  \n- **26. SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents**：SMoA 通过稀疏代理混合提升多代理 LLM 效率和多样性。  \n- **32. DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models**：DiffLM 生成高质量合成数据，提升下游任务性能。  \n- **39. On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models**：优化扩散模型预训练，提升图像生成质量。  \n- **40. Navigating Extremes: Dynamic Sparsity in Large Output Spaces**：提出动态稀疏技术，处理大规模输出空间的 LLM 效率。  \n其他如 LLM 在化学、RNA 分析和文本生成的论文（如48、65、74等），主要贡献在于预训练策略和鲁棒性提升，但细节较常规，故从略。\n\n**机器人和多模态应用（相关论文：13、17、20、21、23、24、25、27、28、29、30、31、33、34、35、36、37、41、42、43、44、45、46、49、52、53、60、61、62、70、81、92）**  \n- **13. LLM Generated Distribution-Based Prediction of US Electoral Results**：使用 LLM 输出概率预测选举结果，引入分布预测框架，提升算法透明度。  \n- **20. Neurons for Neutrons: A Transformer Model for Computation Load Estimation**：Transformer 模型估计核反应堆计算负载，加速模拟优化。  \n- **23. Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy**：提出对象中心策略恢复 OOD 场景，提升机器人视觉操作鲁棒性。  \n- **25. The Future of Intelligent Healthcare: A Systematic Analysis on LLM-based Robots**：讨论 LLM 在医疗机器人的应用，强调多模态交互和伦理挑战。  \n- **27. Causal Responsibility Attribution for Human-AI Collaboration**：使用结构因果模型分析 AI 协作责任，提升决策可解释性。  \n- **33. Formal Logic-guided Robust Federated Learning**：整合形式逻辑提升联邦学习抗攻击能力，适用于时间序列任务。  \n- **41. Evaluating Machine Learning Models against Clinical Protocols**：比较 ML 模型与临床协议，提出新指标评估模型一致性和连续性。  \n- **43. HFGaussian: Learning Generalizable Gaussian Human**：HFGaussian 模型融合人体特征，实现实时3D人体重建。  \n其他机器人和多模态论文（如52、60等），主要在强化学习和交互优化上取得进展，但不为核心亮点，故简要提及。\n\n**图像和视觉相关（相关论文：17、28、29、31、46、47、49、53、54、55、61、62、63、64、66、67、68、69、70、71、72、73、74、75、76、77、78、79、80、81、82、83、84、85、86、87、88、89、90、91、92、93、94、95、96、97、98、99、100、101）**  \n- **17. Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters**：分析 VLM 推理优化，发现减少视觉标记和增加参数可提升性能。  \n- **28. An Open API Architecture for Explainable AI in Cloud Services**：提出 XAI 服务框架，提供云 AI 的特征贡献解释，提升模型可解释性。  \n- **46. Interaction2Code: Benchmarking MLLM-based Interactive Webpage Code Generation**：建立 Interaction2Code 基准，评估 MLLM 在交互网页生成的性能。  \n- **49. GIS Copilot: Towards an Autonomous GIS Agent**：GIS Copilot 使用 LLM 实现地理信息系统自动化，提升任务执行效率。  \n- **53. Local Lesion Generation for Capsule Endoscopy Data Augmentation**：提出局部病变生成方法，提升内镜图像分类准确性。  \n- **54. Discovering Data Structures: Nearest Neighbor Search and Beyond**：使用强化学习发现数据结构，优化最近邻搜索。  \n其他视觉论文（如66、84等），聚焦生成和检测改进，但整体贡献较局部，故快速掠过。\n\n**安全和评估相关（相关论文：21、24、30、34、35、36、37、42、44、45、50、51、52、55、56、57、58、59、60、61、62、70、81、92）**  \n- **21. AI Multi-Agent Interoperability for Multiparty Conversations**：扩展多代理互操作性，支持安全的多方对话管理。  \n- **24. Solving Trojan Detection with Linear Weight Classification**：提出检测神经网络木马的新框架，提升模型安全。  \n- **34. Formal Logic-guided Robust Federated Learning**：(重复第33)增强联邦学习鲁棒性。  \n- **36. Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation**：应用 GNNs 于遥感数据分析，提升环境监测精度。  \n- **42. Self-supervised Cross-modality Learning for Uncertainty-aware Detection**：开发自监督方法，提高机器人目标检测不确定性估计。  \n- **44. Formal Verification with LLM Assistance**：使用 LLM 辅助 Dafny 程序验证，生成合成数据集提升效率。  \n- **45. Gradient-Guided Conditional Diffusion Models**：分析扩散模型在隐私重建中的对抗影响。  \n其他安全论文（如55、92等），主要在模型鲁棒性和隐私保护上有所进展，但非重点。\n\n**快速掠过的论文**  \n剩余论文（如13、17、20、29、31、37、47、50、51、52、57、58、59、60、61、62、63、64、65、66、67、68、69、70、71、72、73、74、75、76、77、78、79、80、81、82、83、84、85、86、87、88、89、90、91、93、94、95、96、97、98、99、100、101）涉及主题如时间序列预测、图神经网络和强化学习等，但贡献较为技术性或重复（如第101篇的图嵌入方法），故仅列标题不详述：  \n- **13. LLM Generated Distribution-Based Prediction of US Electoral Results**  \n- **17. Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters**  \n- **20. Neurons for Neutrons: A Transformer Model for Computation Load Estimation**  \n- **29. Character-level Tokenizations as Powerful Inductive Biases for RNA Foundational Models**  \n- **31. Spontaneous Emergence of Agent Individuality through Social Interactions**  \n- **37. Causal Responsibility Attribution for Human-AI Collaboration**  \n- **47. GIS Copilot: Towards an Autonomous GIS Agent**  \n- **50. Discovering Data Structures: Nearest Neighbor Search and Beyond**  \n- **51. DA-MoE: Improving Multi-agent Large Language Models**  \n- **52. Flashy Backdoor: Real-world Environment Backdoor Attack on SNNs**  \n- **57. Confidence Calibration of Classifiers with Many Classes**  \n- **58. Data Quality Awareness: A Journey from Traditional Data Management**  \n- **59. Exploring the Interplay Between Video Generation and World Models**  \n- **60. Autonomous Decision Making for UAV Cooperative Pursuit-Evasion**  \n- **61. Region-Guided Attack on the Segment Anything Model**  \n- **62. PRObot: Enhancing Patient-Reported Outcome Measures**  \n- **63. Speaker Emotion Recognition: Leveraging Self-Supervised Models**  \n- **64. Enhanced Real-Time Threat Detection in 5G Networks**  \n- **65. A Mamba Foundation Model for Time Series Forecasting**  \n- **66. A Post-Training Enhanced Optimization Approach**  \n- **67. Multimodal Commonsense Knowledge Distillation**  \n- **68. JPEC: A Novel Graph Neural Network for Competitor Retrieval**  \n- **69. The Evolution of RWKV: Advancements in Efficient Language Modeling**  \n- **70. Language Models and Cycle Consistency for Self-Reflective Machine Translation**  \n- **71. When to Localize? A Risk-Constrained Reinforcement Learning Approach**  \n- **72. Stochastic Monkeys at Play: Random Augmentations**  \n- **73. EcoCropsAID: Economic Crops Aerial Image Dataset**  \n- **74. Generative Artificial Intelligence Meets Synthetic Aperture Radar**  \n- **75. A Bayesian Explanation of Machine Learning Models**  \n- **76. Self-Calibrated Tuning of Vision-Language Models**  \n- **77. V-DPO: Mitigating Hallucination in Large Vision Language Models**  \n- **78. Exploring Response Uncertainty in MLLMs**  \n- **79. RT-Affordance: Affordances are Versatile Intermediate Representations**  \n- **80. JEL: Applying End-to-End Neural Entity Linking**  \n- **81. JPEC: A Novel Graph Neural Network** (重复)  \n- **82. Game Plot Design with an LLM-powered Assistant**  \n- **83. Interaction2Code: Benchmarking MLLM-based Interactive Webpage Code Generation** (重复)  \n- **84. The Future of Intelligent Healthcare** (重复)  \n- **85. SMoA: Improving Multi-agent Large Language Models** (重复)  \n- **86. Causal Responsibility Attribution** (重复)  \n- **87. GeMID: Generalizable Models for IoT Device Identification**  \n- **88. An Open API Architecture** (重复)  \n- **89. Discovering Data Structures** (重复)  \n- **90. Spontaneous Emergence of Agent Individuality** (重复)  \n- **91. DiffLM: Controllable Synthetic Data Generation** (重复)  \n- **92. On the Detection of Non-Cooperative RISs**  \n- **93. Formal Logic-guided Robust Federated Learning** (重复)  \n- **94. Knowledge Graphs of Driving Scenes**  \n- **95. Beyond Grid Data: Exploring Graph Neural Networks** (重复)  \n- **96. AtlasSeg: Atlas Prior Guided Dual-U-Net**  \n- **97. Graph-DPEP: Decomposed Plug and Ensemble Play**  \n- **98. LLM Generated Distribution-Based Prediction** (重复)  \n- **99. dafny-annotator: AI-Assisted Verification** (重复)  \n- **100. Watson: A Cognitive Observability Framework** (重复)  \n- **101. AI Horizon Scanning -- White Paper** (重复)  \n\n总之，今天的论文突出了 AI 模型在实际应用中的创新潜力，但也暴露了安全和泛化挑战。欢迎读者关注这些前沿进展，并根据兴趣深入探索相关论文！",
  "papers": [
    {
      "arxiv_id": "2411.03562v1",
      "title": "Large Language Models Orchestrating Structured Reasoning Achieve Kaggle Grandmaster Level",
      "title_zh": "翻译失败",
      "authors": [
        "Antoine Grosnit",
        "Alexandre Maraval",
        "James Doran",
        "Giuseppe Paolo",
        "Albert Thomas",
        "Refinath Shahul Hameed Nabeezath Beevi",
        "Jonas Gonzalez",
        "Khyati Khandelwal",
        "Ignacio Iacobacci",
        "Abdelhakim Benechehab",
        "Hamza Cherkaoui",
        "Youssef Attia El-Hili",
        "Kun Shao",
        "Jianye Hao",
        "Jun Yao",
        "Balazs Kegl",
        "Haitham Bou-Ammar",
        "Jun Wang"
      ],
      "abstract": "We introduce Agent K v1.0, an end-to-end autonomous data science agent\ndesigned to automate, optimise, and generalise across diverse data science\ntasks. Fully automated, Agent K v1.0 manages the entire data science life cycle\nby learning from experience. It leverages a highly flexible structured\nreasoning framework to enable it to dynamically process memory in a nested\nstructure, effectively learning from accumulated experience stored to handle\ncomplex reasoning tasks. It optimises long- and short-term memory by\nselectively storing and retrieving key information, guiding future decisions\nbased on environmental rewards. This iterative approach allows it to refine\ndecisions without fine-tuning or backpropagation, achieving continuous\nimprovement through experiential learning. We evaluate our agent's apabilities\nusing Kaggle competitions as a case study. Following a fully automated\nprotocol, Agent K v1.0 systematically addresses complex and multimodal data\nscience tasks, employing Bayesian optimisation for hyperparameter tuning and\nfeature engineering. Our new evaluation framework rigorously assesses Agent K\nv1.0's end-to-end capabilities to generate and send submissions starting from a\nKaggle competition URL. Results demonstrate that Agent K v1.0 achieves a 92.5\\%\nsuccess rate across tasks, spanning tabular, computer vision, NLP, and\nmultimodal domains. When benchmarking against 5,856 human Kaggle competitors by\ncalculating Elo-MMR scores for each, Agent K v1.0 ranks in the top 38\\%,\ndemonstrating an overall skill level comparable to Expert-level users. Notably,\nits Elo-MMR score falls between the first and third quartiles of scores\nachieved by human Grandmasters. Furthermore, our results indicate that Agent K\nv1.0 has reached a performance level equivalent to Kaggle Grandmaster, with a\nrecord of 6 gold, 3 silver, and 7 bronze medals, as defined by Kaggle's\nprogression system.",
      "tldr_zh": "该论文介绍了 Agent K v1.0，这是一个基于 Large Language Models 的端到端自治数据科学代理，能够自动化优化并泛化各种数据科学任务。代理采用灵活的 structured reasoning framework 和嵌套内存管理，通过经验学习和环境奖励优化长短期记忆，实现无需微调或反向传播的持续改进。实验结果显示，Agent K v1.0 在 Kaggle 比赛中取得 92.5% 的成功率，覆盖表格、计算机视觉、NLP 和多模态任务，其 Elo-MMR 得分排名前 38%，相当于 Kaggle Grandmaster 水平，并获得等效的 6 金、3 银和 7 铜奖牌。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03562v1",
      "published_date": "2024-11-05 23:55:23 UTC",
      "updated_date": "2024-11-05 23:55:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:21:51.526682"
    },
    {
      "arxiv_id": "2411.03551v1",
      "title": "Enhancing Weakly Supervised Semantic Segmentation for Fibrosis via Controllable Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiling Yue",
        "Yingying Fang",
        "Liutao Yang",
        "Nikhil Baid",
        "Simon Walsh",
        "Guang Yang"
      ],
      "abstract": "Fibrotic Lung Disease (FLD) is a severe condition marked by lung stiffening\nand scarring, leading to respiratory decline. High-resolution computed\ntomography (HRCT) is critical for diagnosing and monitoring FLD; however,\nfibrosis appears as irregular, diffuse patterns with unclear boundaries,\nleading to high inter-observer variability and time-intensive manual\nannotation. To tackle this challenge, we propose DiffSeg, a novel weakly\nsupervised semantic segmentation (WSSS) method that uses image-level\nannotations to generate pixel-level fibrosis segmentation, reducing the need\nfor fine-grained manual labeling. Additionally, our DiffSeg incorporates a\ndiffusion-based generative model to synthesize HRCT images with different\nlevels of fibrosis from healthy slices, enabling the generation of the\nfibrosis-injected slices and their paired fibrosis location. Experiments\nindicate that our method significantly improves the accuracy of pseudo masks\ngenerated by existing WSSS methods, greatly reducing the complexity of manual\nlabeling and enhancing the consistency of the generated masks.",
      "tldr_zh": "该研究针对纤维化肺疾病 (FLD) 的诊断挑战，提出了一种名为 DiffSeg 的弱监督语义分割 (WSSS) 方法，利用图像级标注生成像素级纤维化分割，以减少精细手动标注的需求。DiffSeg 整合了基于扩散的生成模型，从健康 HRCT 切片合成不同纤维化水平的图像，并生成对应的纤维化位置配对，从而提升伪掩码的准确性和一致性。实验结果显示，该方法显著提高了现有 WSSS 方法的性能，降低了手动标注复杂性，为 FLD 的监测和诊断提供了更高效的工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03551v1",
      "published_date": "2024-11-05 23:11:26 UTC",
      "updated_date": "2024-11-05 23:11:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:22:01.667273"
    },
    {
      "arxiv_id": "2411.03542v1",
      "title": "Exploring the Benefits of Domain-Pretraining of Generative Large Language Models for Chemistry",
      "title_zh": "探索生成式大型语言模型领域预训练在化学领域的益处",
      "authors": [
        "Anurag Acharya",
        "Shivam Sharma",
        "Robin Cosbey",
        "Megha Subramanian",
        "Scott Howland",
        "Maria Glenski"
      ],
      "abstract": "A proliferation of Large Language Models (the GPT series, BLOOM, LLaMA, and\nmore) are driving forward novel development of multipurpose AI for a variety of\ntasks, particularly natural language processing (NLP) tasks. These models\ndemonstrate strong performance on a range of tasks; however, there has been\nevidence of brittleness when applied to more niche or narrow domains where\nhallucinations or fluent but incorrect responses reduce performance. Given the\ncomplex nature of scientific domains, it is prudent to investigate the\ntrade-offs of leveraging off-the-shelf versus more targeted foundation models\nfor scientific domains. In this work, we examine the benefits of in-domain\npre-training for a given scientific domain, chemistry, and compare these to\nopen-source, off-the-shelf models with zero-shot and few-shot prompting. Our\nresults show that not only do in-domain base models perform reasonably well on\nin-domain tasks in a zero-shot setting but that further adaptation using\ninstruction fine-tuning yields impressive performance on chemistry-specific\ntasks such as named entity recognition and molecular formula generation.",
      "tldr_zh": "本研究探讨了在化学领域对生成式大型语言模型（Large Language Models，如GPT系列、BLOOM和LLaMA）进行领域预训练的益处，旨在解决这些模型在专业科学领域可能出现的幻觉和错误响应问题。研究者比较了领域预训练模型与开源现成模型在零样本（zero-shot）和少样本（few-shot prompting）设置下的性能，结果显示领域预训练基模型在化学任务上表现出色。进一步通过指令微调（instruction fine-tuning），这些模型在命名实体识别（named entity recognition）和分子式生成（molecular formula generation）等特定任务中取得了显著提升。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03542v1",
      "published_date": "2024-11-05 22:45:10 UTC",
      "updated_date": "2024-11-05 22:45:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:23:42.050709"
    },
    {
      "arxiv_id": "2411.05829v1",
      "title": "Utilizing RNN for Real-time Cryptocurrency Price Prediction and Trading Strategy Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Shamima Nasrin Tumpa",
        "Kehelwala Dewage Gayan Maduranga"
      ],
      "abstract": "This study explores the use of Recurrent Neural Networks (RNN) for real-time\ncryptocurrency price prediction and optimized trading strategies. Given the\nhigh volatility of the cryptocurrency market, traditional forecasting models\noften fall short. By leveraging RNNs' capability to capture long-term patterns\nin time-series data, this research aims to improve accuracy in price prediction\nand develop effective trading strategies. The project follows a structured\napproach involving data collection, preprocessing, and model refinement,\nfollowed by rigorous backtesting for profitability and risk assessment. This\nwork contributes to both the academic and practical fields by providing a\nrobust predictive model and optimized trading strategies that address the\nchallenges of cryptocurrency trading.",
      "tldr_zh": "本研究利用 Recurrent Neural Networks (RNN) 来实现实时加密货币价格预测，并优化交易策略，以应对加密货币市场的高波动性和传统模型的不足。RNN 通过捕捉时间序列数据中的长期模式，提高了价格预测的准确性，研究过程包括数据收集、预处理、模型优化以及严格的回测评估。结果显示，该方法为加密货币交易提供了稳健的预测模型和有效的策略，解决了实际挑战，并在学术和实践领域做出了贡献。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "q-fin.ST",
      "comment": "10 pages, 16 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2411.05829v1",
      "published_date": "2024-11-05 22:44:52 UTC",
      "updated_date": "2024-11-05 22:44:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:22:25.355111"
    },
    {
      "arxiv_id": "2411.03537v1",
      "title": "Two-Stage Pretraining for Molecular Property Prediction in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Kevin Tirta Wijaya",
        "Minghao Guo",
        "Michael Sun",
        "Hans-Peter Seidel",
        "Wojciech Matusik",
        "Vahid Babaei"
      ],
      "abstract": "Accurate property prediction is crucial for accelerating the discovery of new\nmolecules. Although deep learning models have achieved remarkable success,\ntheir performance often relies on large amounts of labeled data that are\nexpensive and time-consuming to obtain. Thus, there is a growing need for\nmodels that can perform well with limited experimentally-validated data. In\nthis work, we introduce MoleVers, a versatile pretrained model designed for\nvarious types of molecular property prediction in the wild, i.e., where\nexperimentally-validated molecular property labels are scarce. MoleVers adopts\na two-stage pretraining strategy. In the first stage, the model learns\nmolecular representations from large unlabeled datasets via masked atom\nprediction and dynamic denoising, a novel task enabled by a new branching\nencoder architecture. In the second stage, MoleVers is further pretrained using\nauxiliary labels obtained with inexpensive computational methods, enabling\nsupervised learning without the need for costly experimental data. This\ntwo-stage framework allows MoleVers to learn representations that generalize\neffectively across various downstream datasets. We evaluate MoleVers on a new\nbenchmark comprising 22 molecular datasets with diverse types of properties,\nthe majority of which contain 50 or fewer training labels reflecting real-world\nconditions. MoleVers achieves state-of-the-art results on 20 out of the 22\ndatasets, and ranks second among the remaining two, highlighting its ability to\nbridge the gap between data-hungry models and real-world conditions where\npractically-useful labels are scarce.",
      "tldr_zh": "本研究引入了MoleVers，一种通用预训练模型，用于在实验验证数据稀缺的真实场景下进行分子属性预测，以解决深度学习模型对大量标记数据的需求。MoleVers采用两阶段预训练策略：第一阶段通过masked atom prediction和dynamic denoising任务（利用新的branching encoder架构）从大型无标签数据集学习分子表示；第二阶段则使用廉价计算方法获得的辅助标签进行监督预训练，提升模型的泛化能力。在一个包含22个多样化分子数据集的新基准上，MoleVers在20个数据集上达到最先进水平，在剩余两个上排名第二，展示了其在标签稀缺条件下桥接数据饥饿模型与实际应用的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "physics.chem-ph",
        "q-bio.BM"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03537v1",
      "published_date": "2024-11-05 22:36:17 UTC",
      "updated_date": "2024-11-05 22:36:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:22:38.917556"
    },
    {
      "arxiv_id": "2411.03531v1",
      "title": "Personalized Video Summarization by Multimodal Video Understanding",
      "title_zh": "基于多模态视频理解的个性化视频摘要",
      "authors": [
        "Brian Chen",
        "Xiangyuan Zhao",
        "Yingnan Zhu"
      ],
      "abstract": "Video summarization techniques have been proven to improve the overall user\nexperience when it comes to accessing and comprehending video content. If the\nuser's preference is known, video summarization can identify significant\ninformation or relevant content from an input video, aiding them in obtaining\nthe necessary information or determining their interest in watching the\noriginal video. Adapting video summarization to various types of video and user\npreferences requires significant training data and expensive human labeling. To\nfacilitate such research, we proposed a new benchmark for video summarization\nthat captures various user preferences. Also, we present a pipeline called\nVideo Summarization with Language (VSL) for user-preferred video summarization\nthat is based on pre-trained visual language models (VLMs) to avoid the need to\ntrain a video summarization system on a large training dataset. The pipeline\ntakes both video and closed captioning as input and performs semantic analysis\nat the scene level by converting video frames into text. Subsequently, the\nuser's genre preference was used as the basis for selecting the pertinent\ntextual scenes. The experimental results demonstrate that our proposed pipeline\noutperforms current state-of-the-art unsupervised video summarization models.\nWe show that our method is more adaptable across different datasets compared to\nsupervised query-based video summarization models. In the end, the runtime\nanalysis demonstrates that our pipeline is more suitable for practical use when\nscaling up the number of user preferences and videos.",
      "tldr_zh": "这篇论文提出一个新基准，用于捕捉各种用户偏好，以支持个性化视频总结，同时引入 Video Summarization with Language (VSL) 管道，该管道基于预训练的 visual language models (VLMs)，通过将视频帧转换为文本并结合用户类型偏好在场景级别进行语义分析。VSL 避免了大量训练数据集的需求，仅需视频和闭合字幕作为输入，即可选择相关内容生成总结。实验结果表明，VSL 优于当前最先进的无监督视频总结模型，并在适应不同数据集和扩展用户偏好时表现出更高的灵活性和运行时效率。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "In Proceedings of CIKM 2024 Applied Research Track",
      "pdf_url": "http://arxiv.org/pdf/2411.03531v1",
      "published_date": "2024-11-05 22:14:35 UTC",
      "updated_date": "2024-11-05 22:14:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:22:50.602045"
    },
    {
      "arxiv_id": "2411.03524v1",
      "title": "Mitigating Metric Bias in Minimum Bayes Risk Decoding",
      "title_zh": "在最小贝叶斯风险解码中减轻度量偏差",
      "authors": [
        "Geza Kovacs",
        "Daniel Deutsch",
        "Markus Freitag"
      ],
      "abstract": "While Minimum Bayes Risk (MBR) decoding using metrics such as COMET or\nMetricX has outperformed traditional decoding methods such as greedy or beam\nsearch, it introduces a challenge we refer to as metric bias. As MBR decoding\naims to produce translations that score highly according to a specific utility\nmetric, this very process makes it impossible to use the same metric for both\ndecoding and evaluation, as improvements might simply be due to reward hacking\nrather than reflecting real quality improvements. In this work we find that\ncompared to human ratings, neural metrics not only overestimate the quality of\nMBR decoding when the same metric is used as the utility metric, but they also\noverestimate the quality of MBR/QE decoding with other neural utility metrics\nas well. We also show that the metric bias issue can be mitigated by using an\nensemble of utility metrics during MBR decoding: human evaluations show that\nMBR decoding using an ensemble of utility metrics outperforms a single utility\nmetric.",
      "tldr_zh": "这项研究探讨了 Minimum Bayes Risk (MBR) 解码在使用指标如 COMET 或 MetricX 时引发的 metric bias 问题，该问题导致指标高估翻译质量，可能因 reward hacking 而非真实改进。研究发现，神经指标不仅在使用相同指标时过度评估 MBR 解码质量，还会高估使用其他神经指标的 MBR/QE 解码表现。为缓解这一偏差，作者提出在 MBR 解码中使用 utility metrics 的集合方法。人类评估结果显示，这种集合方法优于单一指标，显著提升了解码性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "To appear at WMT2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03524v1",
      "published_date": "2024-11-05 22:01:27 UTC",
      "updated_date": "2024-11-05 22:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:23:44.205521"
    },
    {
      "arxiv_id": "2411.03522v1",
      "title": "Exploring the Potentials and Challenges of Using Large Language Models for the Analysis of Transcriptional Regulation of Long Non-coding RNAs",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Wang",
        "Zhichao Hou",
        "Xiaorui Liu",
        "Xinxia Peng"
      ],
      "abstract": "Research on long non-coding RNAs (lncRNAs) has garnered significant attention\ndue to their critical roles in gene regulation and disease mechanisms. However,\nthe complexity and diversity of lncRNA sequences, along with the limited\nknowledge of their functional mechanisms and the regulation of their\nexpressions, pose significant challenges to lncRNA studies. Given the\ntremendous success of large language models (LLMs) in capturing complex\ndependencies in sequential data, this study aims to systematically explore the\npotential and limitations of LLMs in the sequence analysis related to the\ntranscriptional regulation of lncRNA genes. Our extensive experiments\ndemonstrated promising performance of fine-tuned genome foundation models on\nprogressively complex tasks. Furthermore, we conducted an insightful analysis\nof the critical impact of task complexity, model selection, data quality, and\nbiological interpretability for the studies of the regulation of lncRNA gene\nexpression.",
      "tldr_zh": "本研究探讨了使用大型语言模型(LLMs)分析长非编码RNAs(lncRNAs)转录调控的潜力与挑战，针对lncRNAs序列的复杂性和功能机制知识不足等问题。研究通过广泛实验，展示了微调后的基因组基础模型在渐进复杂任务上的出色性能。最终，分析强调了任务复杂度、模型选择、数据质量和生物学可解释性对lncRNA基因表达调控研究的关键影响，为未来应用提供了重要洞见。",
      "categories": [
        "q-bio.GN",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-bio.GN",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03522v1",
      "published_date": "2024-11-05 21:57:38 UTC",
      "updated_date": "2024-11-05 21:57:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:23:13.713128"
    },
    {
      "arxiv_id": "2411.11808v1",
      "title": "Character-level Tokenizations as Powerful Inductive Biases for RNA Foundational Models",
      "title_zh": "字符级标记化作为 RNA 基础模型的强大归纳偏差",
      "authors": [
        "Adrián Morales-Pastor",
        "Raquel Vázquez-Reza",
        "Miłosz Wieczór",
        "Clàudia Valverde",
        "Manel Gil-Sorribes",
        "Bertran Miquel-Oliver",
        "Álvaro Ciudad",
        "Alexis Molina"
      ],
      "abstract": "RNA is a vital biomolecule with numerous roles and functions within cells,\nand interest in targeting it for therapeutic purposes has grown significantly\nin recent years. However, fully understanding and predicting RNA behavior,\nparticularly for applications in drug discovery, remains a challenge due to the\ncomplexity of RNA structures and interactions. While foundational models in\nbiology have demonstrated success in modeling several biomolecules, especially\nproteins, achieving similar breakthroughs for RNA has proven more difficult.\nCurrent RNA models have yet to match the performance observed in the protein\ndomain, leaving an important gap in computational biology. In this work, we\npresent ChaRNABERT, a suite of sample and parameter-efficient RNA foundational\nmodels, that through a learnable tokenization process, are able to reach\nstate-of-the-art performance on several tasks in established benchmarks. We\nextend its testing in relevant downstream tasks such as RNA-protein and\naptamer-protein interaction prediction. Weights and inference code for\nChaRNABERT-8M will be provided for academic research use. The other models will\nbe available upon request.",
      "tldr_zh": "本文研究RNA建模的挑战，指出现有模型在预测RNA结构和交互方面落后于蛋白质领域，导致计算生物学中的性能差距。为解决此问题，作者提出ChaRNABERT，一套基于character-level tokenizations的样本和参数高效RNA基础模型，通过可学习的tokenization过程，在多个基准任务上达到state-of-the-art性能，并在RNA-蛋白质和aptamer-蛋白质交互预测等下游任务中表现出色。模型权重和推理代码（如ChaRNABERT-8M）将提供给学术研究者，以促进进一步应用。",
      "categories": [
        "q-bio.QM",
        "cs.AI",
        "cs.LG",
        "q-bio.BM"
      ],
      "primary_category": "q-bio.QM",
      "comment": "First version. Work in progress",
      "pdf_url": "http://arxiv.org/pdf/2411.11808v1",
      "published_date": "2024-11-05 21:56:16 UTC",
      "updated_date": "2024-11-05 21:56:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:23:26.401695"
    },
    {
      "arxiv_id": "2411.03519v1",
      "title": "AI Metropolis: Scaling Large Language Model-based Multi-Agent Simulation with Out-of-order Execution",
      "title_zh": "翻译失败",
      "authors": [
        "Zhiqiang Xie",
        "Hao Kang",
        "Ying Sheng",
        "Tushar Krishna",
        "Kayvon Fatahalian",
        "Christos Kozyrakis"
      ],
      "abstract": "With more advanced natural language understanding and reasoning capabilities,\nlarge language model (LLM)-powered agents are increasingly developed in\nsimulated environments to perform complex tasks, interact with other agents,\nand exhibit emergent behaviors relevant to social science and gaming. However,\ncurrent multi-agent simulations frequently suffer from inefficiencies due to\nthe limited parallelism caused by false dependencies, resulting in performance\nbottlenecks. In this paper, we introduce AI Metropolis, a simulation engine\nthat improves the efficiency of LLM agent simulations by incorporating\nout-of-order execution scheduling. By dynamically tracking real dependencies\nbetween agents, AI Metropolis minimizes false dependencies, enhancing\nparallelism and enabling efficient hardware utilization. Our evaluations\ndemonstrate that AI Metropolis achieves speedups from 1.3x to 4.15x over\nstandard parallel simulation with global synchronization, approaching optimal\nperformance as the number of agents increases.",
      "tldr_zh": "该论文提出AI Metropolis，一种基于大型语言模型(LLM)的多代理模拟引擎，通过引入out-of-order execution调度来提升模拟效率。该系统动态跟踪代理间的真实依赖，减少虚假依赖，从而提高并行性和硬件利用率。实验结果显示，AI Metropolis相较于标准并行模拟实现1.3x至4.15x的速度提升，随着代理数量增加，其性能接近最优水平。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03519v1",
      "published_date": "2024-11-05 21:54:14 UTC",
      "updated_date": "2024-11-05 21:54:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:23:37.208551"
    },
    {
      "arxiv_id": "2411.03513v1",
      "title": "Change Is the Only Constant: Dynamic LLM Slicing based on Layer Redundancy",
      "title_zh": "变化是唯一的不变：",
      "authors": [
        "Razvan-Gabriel Dumitru",
        "Paul-Ioan Clotan",
        "Vikas Yadav",
        "Darius Peteleaza",
        "Mihai Surdeanu"
      ],
      "abstract": "This paper introduces a novel model compression approach through dynamic\nlayer-specific pruning in Large Language Models (LLMs), enhancing the\ntraditional methodology established by SliceGPT. By transitioning from constant\nto dynamic slicing, our method leverages the newly proposed Layer Redundancy\n(LR) score, which assesses how much change each layer changes its input by\nmeasuring the cosine similarity of the input to the output of the layer. We use\nthis score to prune parts of individual layers based on redundancy in such a\nway that the average pruned percentage for all layers is a fixed value. We\nconducted extensive experiments using models like Llama3-8B and Mistral-7B on\nmultiple datasets, evaluating different slicing bases and percentages to\ndetermine optimal configurations that balance efficiency and performance. Our\nfindings show that our dynamic slicing approach not only maintains but, in many\ncases, enhances model performance compared to the baseline established by\nconstant slicing methods. For instance, in several settings, we see performance\nimprovements of up to 5% over the SliceGPT baseline. Additionally, a perplexity\ndecrease by as much as 7% was observed across multiple benchmarks, validating\nthe effectiveness of our method. The code, model weights, and datasets are\nopen-sourced at https://github.com/RazvanDu/DynamicSlicing.",
      "tldr_zh": "本文提出了一种动态层级修剪方法，用于压缩 Large Language Models (LLMs)，通过新提出的 Layer Redundancy (LR) 评分来评估每个层的输入输出余弦相似度，从而动态修剪冗余部分，确保平均修剪百分比固定。相比传统常量切片方法如 SliceGPT，该方法在 Llama3-8B 和 Mistral-7B 模型上进行的多数据集实验中，不仅维持了性能，还在许多场景下提升了高达 5% 的准确率，并降低了高达 7% 的 perplexity。研究验证了动态切片的有效性，并已在 GitHub 开源相关代码、模型权重和数据集。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "I.2.7; I.2.0"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at EMNLP Findings 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03513v1",
      "published_date": "2024-11-05 21:19:49 UTC",
      "updated_date": "2024-11-05 21:19:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:23:57.612282"
    },
    {
      "arxiv_id": "2411.03495v1",
      "title": "Automatic Generation of Question Hints for Mathematics Problems using Large Language Models in Educational Technology",
      "title_zh": "使用大型语言模型在教育技术中自动生成数学问题的提示",
      "authors": [
        "Junior Cedric Tonga",
        "Benjamin Clement",
        "Pierre-Yves Oudeyer"
      ],
      "abstract": "The automatic generation of hints by Large Language Models (LLMs) within\nIntelligent Tutoring Systems (ITSs) has shown potential to enhance student\nlearning. However, generating pedagogically sound hints that address student\nmisconceptions and adhere to specific educational objectives remains\nchallenging. This work explores using LLMs (GPT-4o and Llama-3-8B-instruct) as\nteachers to generate effective hints for students simulated through LLMs\n(GPT-3.5-turbo, Llama-3-8B-Instruct, or Mistral-7B-instruct-v0.3) tackling math\nexercises designed for human high-school students, and designed using cognitive\nscience principles. We present here the study of several dimensions: 1)\nidentifying error patterns made by simulated students on secondary-level math\nexercises; 2) developing various prompts for GPT-4o as a teacher and evaluating\ntheir effectiveness in generating hints that enable simulated students to\nself-correct; and 3) testing the best-performing prompts, based on their\nability to produce relevant hints and facilitate error correction, with\nLlama-3-8B-Instruct as the teacher, allowing for a performance comparison with\nGPT-4o. The results show that model errors increase with higher temperature\nsettings. Notably, when hints are generated by GPT-4o, the most effective\nprompts include prompts tailored to specific errors as well as prompts\nproviding general hints based on common mathematical errors. Interestingly,\nLlama-3-8B-Instruct as a teacher showed better overall performance than GPT-4o.\nAlso the problem-solving and response revision capabilities of the LLMs as\nstudents, particularly GPT-3.5-turbo, improved significantly after receiving\nhints, especially at lower temperature settings. However, models like\nMistral-7B-Instruct demonstrated a decline in performance as the temperature\nincreased.",
      "tldr_zh": "本研究探讨使用 Large Language Models (LLMs) 如 GPT-4o 和 Llama-3-8B-instruct 在智能辅导系统 (ITSs) 中自动生成数学问题提示，以帮助学生纠正错误并提升学习效果。研究方法包括模拟学生 (如 GPT-3.5-turbo) 来识别错误模式，开发针对特定错误或常见数学错误的提示，并评估这些提示在不同温度设置下的有效性。结果显示，模型错误随温度增加而增多，GPT-4o 的最佳提示结合了特定和一般提示，而 Llama-3-8B-Instruct 作为教师的表现优于 GPT-4o。总体上，学生模型在接收提示后，尤其在低温度设置下，问题解决能力显著改善，为教育技术中的 LLMs 应用提供了重要见解。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at NeurIPS 2024 Workshop on Large Foundation Models for\n  Educational Assessment (FM-Assess)",
      "pdf_url": "http://arxiv.org/pdf/2411.03495v1",
      "published_date": "2024-11-05 20:18:53 UTC",
      "updated_date": "2024-11-05 20:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:24:10.338177"
    },
    {
      "arxiv_id": "2411.03486v1",
      "title": "LLM Generated Distribution-Based Prediction of US Electoral Results, Part I",
      "title_zh": "翻译失败",
      "authors": [
        "Caleb Bradshaw",
        "Caelen Miller",
        "Sean Warnick"
      ],
      "abstract": "This paper introduces distribution-based prediction, a novel approach to\nusing Large Language Models (LLMs) as predictive tools by interpreting output\ntoken probabilities as distributions representing the models' learned\nrepresentation of the world. This distribution-based nature offers an\nalternative perspective for analyzing algorithmic fidelity, complementing the\napproach used in silicon sampling. We demonstrate the use of distribution-based\nprediction in the context of recent United States presidential election,\nshowing that this method can be used to determine task specific bias, prompt\nnoise, and algorithmic fidelity. This approach has significant implications for\nassessing the reliability and increasing transparency of LLM-based predictions\nacross various domains.",
      "tldr_zh": "本论文提出了一种名为distribution-based prediction的新方法，利用Large Language Models (LLMs)将输出token概率解释为代表模型对世界的学习分布，从而作为预测工具。这种方法提供了一种分析算法保真度的替代视角，补充了silicon sampling的传统做法，并在美国总统选举的背景下进行了演示。研究显示，该方法能有效识别任务特定偏差、提示噪声和算法保真度，从而提升LLM-based预测的可靠性和透明性。该方法具有广泛的领域应用潜力，为改进AI预测系统的评估提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "17 pages, 10 Figures, Pre-print",
      "pdf_url": "http://arxiv.org/pdf/2411.03486v1",
      "published_date": "2024-11-05 20:10:25 UTC",
      "updated_date": "2024-11-05 20:10:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:24:19.017287"
    },
    {
      "arxiv_id": "2411.15143v1",
      "title": "dafny-annotator: AI-Assisted Verification of Dafny Programs",
      "title_zh": "dafny-annotator：人工智能辅助的 Dafny 程序验证",
      "authors": [
        "Gabriel Poesia",
        "Chloe Loughridge",
        "Nada Amin"
      ],
      "abstract": "Formal verification has the potential to drastically reduce software bugs,\nbut its high additional cost has hindered large-scale adoption. While Dafny\npresents a promise to significantly reduce the effort to write verified\nprograms, users are often required to provide logical annotations to aid the\nverifier. Here, we explore using a combination of Large Language Models and\nsearch to build dafny-annotator: a tool that adds logical annotations to a\nDafny method until the verifier can prove it correct. On a test set from the\nDafnyBench collection of programs, greedy search guided by LLaMa 3.1 8B\nsuccessfully annotates only 15.7% of the methods. Since this data-driven\napproach is hindered by the lack of large-scale training data, we propose a\nmethod for open-ended synthesis of new Dafny programs in a flexible pipeline\nwhere LLMs formulate high-level ideas, implement them, and incrementally\npropose changes to existing programs, which Dafny validates. This gives us a\nsynthetic dataset, DafnySynth, which we use to augment DafnyBench for training.\nFine-tuning on both datasets boosts LLaMa 8B's success rate to 50.6% --\nsignificantly better than the base model, or training on either dataset alone.\nOur results suggest a path towards capable AI assistants for languages that\ndon't yet have large-scale human-generated examples. In turn, such assistants\nmight reduce friction for users and ultimately drive adoption.",
      "tldr_zh": "该研究引入了 dafny-annotator，一种结合 Large Language Models (LLMs) 和搜索的工具，用于辅助验证 Dafny 程序，通过自动添加逻辑注解来减少正式验证的额外成本。在方法上，研究者使用 greedy search 引导 LLaMa 3.1 8B 模型处理 DafnyBench 测试集，但初始成功率仅为15.7%；为此，他们开发了合成数据集 DafnySynth，通过 LLMs 生成和改进程序，并对模型进行 fine-tuning，最终将成功率提升至50.6%。这些结果表明，AI 助手能为缺乏大规模人类示例的语言提供支持，从而降低用户摩擦并促进正式验证的广泛采用。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.15143v1",
      "published_date": "2024-11-05 19:27:56 UTC",
      "updated_date": "2024-11-05 19:27:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:24:31.656401"
    },
    {
      "arxiv_id": "2411.03455v2",
      "title": "Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents",
      "title_zh": "Watson：LLM驱动代理推理的认知可观察性框架",
      "authors": [
        "Benjamin Rombaut",
        "Sogol Masoumzadeh",
        "Kirill Vasilevski",
        "Dayi Lin",
        "Ahmed E. Hassan"
      ],
      "abstract": "As foundation models (FMs) play an increasingly prominent role in complex\nsoftware systems, such as agentic software, they introduce significant\nobservability and debuggability challenges. Although recent Large Reasoning\nModels (LRMs) generate their thought processes as part of the output, in many\nscenarios fast-thinking Large Language Models (LLMs) are still preferred due to\nlatency constraints. LLM-powered agents operate autonomously with opaque\nimplicit reasoning, making it difficult to debug their unexpected behaviors or\nerrors. In this paper, we introduce Watson, a novel framework that provides\nreasoning observability into the implicit reasoning processes of agents driven\nby fast-thinking LLMs, allowing the identification and localization of errors\nand guidance for corrections. We demonstrate the accuracy of the recovered\nimplicit reasoning trace by Watson and its usefulness through debugging and\nimproving the performance of LLM-powered agents in two scenarios: Massive\nMultitask Language Understanding (MMLU) benchmark and SWE-bench-lite. Using\nWatson, we were able to observe and identify the implicit reasoning errors, and\nautomatically provide targeted corrections at runtime that improve the Pass@1\nof agents on MMLU and SWE-bench-lite by 7.58 (13.45% relative improvement) and\n7.76 (12.31% relative improvement) percentage points, respectively, without\nupdates to models or the cognitive architecture of the agents.",
      "tldr_zh": "该研究提出Watson框架，一种认知可观察性工具，用于揭示由快速Large Language Models (LLMs)驱动的代理的隐式推理过程，从而解决代理行为不透明和调试难题。Watson通过恢复和分析隐式推理轨迹，帮助识别错误并提供自动修正指导，而无需修改模型或代理架构。在实验中，Watson显著提升了代理性能，在MMLU benchmark和SWE-bench-lite上，Pass@1准确率分别提高了7.58%（相对13.45%提升）和7.76%（相对12.31%提升）。这项工作为LLM-powered agents的调试和优化提供了实用方法。",
      "categories": [
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03455v2",
      "published_date": "2024-11-05 19:13:22 UTC",
      "updated_date": "2025-03-06 02:55:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:24:43.872026"
    },
    {
      "arxiv_id": "2411.03449v1",
      "title": "AI Horizon Scanning -- White Paper p3395, IEEE-SA. Part III: Technology Watch: a selection of key developments, emerging technologies, and industry trends in Artificial Intelligence",
      "title_zh": "翻译失败",
      "authors": [
        "George Tambouratzis",
        "Marina Cortês",
        "Andrew R. Liddle"
      ],
      "abstract": "Generative Artificial Intelligence (AI) technologies are in a phase of\nunprecedented rapid development following the landmark release of Chat-GPT,\nwhich brought the phenomenon to wide public attention. As the deployment of AI\nproducts rises geometrically, considerable attention is being given to the\nthreats and opportunities that AI technologies offer, and to the need for\nregulatory and standards initiatives to ensure that use of the technology\naligns with societal needs and generates broad benefits while mitigating risks\nand threats. This manuscript is the third of a series of White Papers informing\nthe development of IEEE-SA's p3995 {\\it `Standard for the Implementation of\nSafeguards, Controls, and Preventive Techniques for Artificial Intelligence\nModels'} \\cite{P3395}, Chair Marina Cort\\^{e}s. This part focuses on assessing\ncalmly and objectively, as far as is possible, the current state of Artificial\nIntelligence (AI) technology development and identifying predominant trends,\nprospects, and ensuing risks. It necessarily forms a snapshot of the current\ninstant of a rapidly-evolving landscape, with new products and innovations\nemerging continuously. While our main focus is on software and hardware\ndevelopments and their corporate context, we also briefly review progress on\nrobotics within the AI context and describe some implications of the\nsubstantial and growing AI energy demand.",
      "tldr_zh": "这篇白皮书是 IEEE-SA p3995 标准系列的第三部分，聚焦于对生成式 Artificial Intelligence (AI) 技术的监测和评估，特别是在 Chat-GPT 发布后 AI 的快速发展和带来的机会与威胁。作者客观分析了当前 AI 软件、硬件发展、机器人应用以及日益增长的能源需求等关键趋势和风险，并强调了制定监管和标准（如 p3995）以确保 AI 符合社会需求、最大化益处并减少威胁的必要性。该白皮书为 AI 技术展望提供了一个即时快照，旨在指导行业实践和政策制定。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "This is an interim version of our p3395 WG White Paper, Part III. We\n  will update this version, until publication by IEEE-SA, Sponsor Committee -\n  Artificial Intelligence Standards Committee (C/AISC);\n  https://standards.ieee.org/ieee/3395/11378/ This White Paper is companion to\n  Part I available at arXiv:2410.01808",
      "pdf_url": "http://arxiv.org/pdf/2411.03449v1",
      "published_date": "2024-11-05 19:04:42 UTC",
      "updated_date": "2024-11-05 19:04:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:26:49.418794"
    },
    {
      "arxiv_id": "2411.03445v1",
      "title": "Solving Trojan Detection Competitions with Linear Weight Classification",
      "title_zh": "翻译失败",
      "authors": [
        "Todd Huster",
        "Peter Lin",
        "Razvan Stefanescu",
        "Emmanuel Ekwedike",
        "Ritu Chadha"
      ],
      "abstract": "Neural networks can conceal malicious Trojan backdoors that allow a trigger\nto covertly change the model behavior. Detecting signs of these backdoors,\nparticularly without access to any triggered data, is the subject of ongoing\nresearch and open challenges. In one common formulation of the problem, we are\ngiven a set of clean and poisoned models and need to predict whether a given\ntest model is clean or poisoned. In this paper, we introduce a detector that\nworks remarkably well across many of the existing datasets and domains. It is\nobtained by training a binary classifier on a large number of models' weights\nafter performing a few different pre-processing steps including feature\nselection and standardization, reference model weights subtraction, and model\nalignment prior to detection. We evaluate this algorithm on a diverse set of\nTrojan detection benchmarks and domains and examine the cases where the\napproach is most and least effective.",
      "tldr_zh": "该论文提出了一种基于线性权重分类的方法，用于检测神经网络中的Trojan后门，从而在没有触发数据的情况下识别模型是否被恶意篡改。方法包括对模型权重进行预处理步骤，如特征选择、标准化、参考模型权重减法和模型对齐，然后训练一个二元分类器来区分干净和中毒模型。在多种Trojan检测基准和领域上进行评估，结果显示该算法在许多数据集上表现出色，但也揭示了其在某些场景中的局限性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 4 Figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03445v1",
      "published_date": "2024-11-05 19:00:34 UTC",
      "updated_date": "2024-11-05 19:00:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:25:07.558583"
    },
    {
      "arxiv_id": "2411.03312v2",
      "title": "Inference Optimal VLMs Need Fewer Visual Tokens and More Parameters",
      "title_zh": "推理最优的 VLMs 需要更少的视觉标记和更多的参数",
      "authors": [
        "Kevin Y. Li",
        "Sachin Goyal",
        "Joao D. Semedo",
        "J. Zico Kolter"
      ],
      "abstract": "Vision Language Models (VLMs) have demonstrated strong capabilities across\nvarious visual understanding and reasoning tasks, driven by incorporating image\nrepresentations into the token inputs of Large Language Models (LLMs). However,\ntheir real-world deployment is often constrained by high latency during\ninference due to the substantial compute required by the LLM to process the\nlarge number of input tokens, predominantly arising from the image. To reduce\ninference costs, one can either downsize the LLM or reduce the number of input\ntokens needed to represent the image, the latter of which has been the focus of\nmany recent efforts around token compression. However, it is unclear what the\noptimal trade-off is given a fixed inference budget. We first characterize this\noptimal trade-off between the number of visual tokens and LLM parameters by\nestablishing scaling laws that capture variations in performance with these two\nfactors. Our results reveal a surprising trend: for visual reasoning tasks, the\ninference-optimal behavior in VLMs is achieved by using the largest LLM that\nfits within the inference budget while minimizing visual token count - often to\na single token. While the token reduction literature has mainly focused on\nmaintaining base model performance by modestly reducing the token count (e.g.,\n$5-10\\times$), our results indicate that the compute-optimal inference regime\nrequires operating under even higher token compression ratios. Based on these\ninsights, we take the first steps toward designing token compression algorithms\ntailored for high-compression settings, utilizing prompt-based compression of\ntokens. Our work underscores the performance and efficiency benefits of\noperating in low visual token regimes and the importance of developing tailored\ntoken reduction algorithms for such conditions. Code is available at\nhttps://github.com/locuslab/llava-token-compression.",
      "tldr_zh": "该研究探讨了视觉语言模型(VLMs) 在推理过程中的最优配置，发现为了在固定预算下最大化性能，应优先使用更大的语言模型(LLMs)参数，同时将视觉token数量最小化，通常缩减到一个token。研究通过建立scaling laws，分析了视觉token数量和LLMs参数之间的权衡，揭示了当前token压缩方法（如5-10倍压缩）不足以达到计算最优状态，需要更高的压缩比。基于此，论文开发了基于prompt的token压缩算法，针对高压缩场景优化VLMs的性能和效率，为实际部署提供重要指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Published at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.03312v2",
      "published_date": "2024-11-05 18:54:21 UTC",
      "updated_date": "2025-04-21 09:34:59 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:25:19.930193"
    },
    {
      "arxiv_id": "2411.03409v1",
      "title": "STEER: Flexible Robotic Manipulation via Dense Language Grounding",
      "title_zh": "翻译失败",
      "authors": [
        "Laura Smith",
        "Alex Irpan",
        "Montserrat Gonzalez Arenas",
        "Sean Kirmani",
        "Dmitry Kalashnikov",
        "Dhruv Shah",
        "Ted Xiao"
      ],
      "abstract": "The complexity of the real world demands robotic systems that can\nintelligently adapt to unseen situations. We present STEER, a robot learning\nframework that bridges high-level, commonsense reasoning with precise, flexible\nlow-level control. Our approach translates complex situational awareness into\nactionable low-level behavior through training language-grounded policies with\ndense annotation. By structuring policy training around fundamental, modular\nmanipulation skills expressed in natural language, STEER exposes an expressive\ninterface for humans or Vision-Language Models (VLMs) to intelligently\norchestrate the robot's behavior by reasoning about the task and context. Our\nexperiments demonstrate the skills learned via STEER can be combined to\nsynthesize novel behaviors to adapt to new situations or perform completely new\ntasks without additional data collection or training.",
      "tldr_zh": "本研究提出 STEER 框架，用于实现灵活的机器人操作，通过密集语言标注将高层次常识推理与精确低层次控制相结合。STEER 通过训练基于自然语言的模块化操作技能政策，使机器人能够根据任务和上下文智能合成新行为。实验结果显示，该框架允许机器人适应未见情境或执行新任务，而无需额外数据收集或训练，从而提升了机器人系统的适应性和实用性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "Project website: https://lauramsmith.github.io/steer/",
      "pdf_url": "http://arxiv.org/pdf/2411.03409v1",
      "published_date": "2024-11-05 18:48:12 UTC",
      "updated_date": "2024-11-05 18:48:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:25:30.996891"
    },
    {
      "arxiv_id": "2411.03389v3",
      "title": "Neurons for Neutrons: A Transformer Model for Computation Load Estimation on Domain-Decomposed Neutron Transport Problems",
      "title_zh": "翻译失败",
      "authors": [
        "Alexander Mote",
        "Todd Palmer",
        "Lizhong Chen"
      ],
      "abstract": "Domain decomposition is a technique used to reduce memory overhead on large\nneutron transport problems. Currently, the optimal load-balanced processor\nallocation for these domains is typically determined through small-scale\nsimulations of the problem, which can be time-consuming for researchers and\nmust be repeated anytime a problem input is changed. We propose a Transformer\nmodel with a unique 3D input embedding, and input representations designed for\ndomain-decomposed neutron transport problems, which can predict the subdomain\ncomputation loads generated by small-scale simulations. We demonstrate that\nsuch a model trained on domain-decomposed Small Modular Reactor (SMR)\nsimulations achieves 98.2% accuracy while being able to skip the small-scale\nsimulation step entirely. Tests of the model's robustness on variant fuel\nassemblies, other problem geometries, and changes in simulation parameters are\nalso discussed.",
      "tldr_zh": "该研究针对领域分解（Domain decomposition）技术在大型中子传输（Neutron transport）问题中的应用，提出了一种Transformer模型，用于估计子域计算负载，从而避免耗时的初级模拟过程。该模型采用独特的3D输入嵌入和专为领域分解中子传输问题设计的输入表示，能够准确预测计算负载。在Small Modular Reactor (SMR)模拟数据集上训练后，该模型实现了98.2%的准确率，并通过测试证明了其在变体燃料组件、不同问题几何形状和模拟参数变化下的鲁棒性。",
      "categories": [
        "physics.comp-ph",
        "cs.AI"
      ],
      "primary_category": "physics.comp-ph",
      "comment": "25 pages, 14 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03389v3",
      "published_date": "2024-11-05 18:17:51 UTC",
      "updated_date": "2025-03-31 21:36:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:25:44.107264"
    },
    {
      "arxiv_id": "2411.05828v1",
      "title": "AI Multi-Agent Interoperability Extension for Managing Multiparty Conversations",
      "title_zh": "翻译失败",
      "authors": [
        "Diego Gosmar",
        "Deborah A. Dahl",
        "Emmett Coin",
        "David Attwater"
      ],
      "abstract": "This paper presents a novel extension to the existing Multi-Agent\nInteroperability specifications of the Open Voice Interoperability Initiative\n(originally also known as OVON from the Open Voice Network). This extension\nenables AI agents developed with different technologies to communicate using a\nuniversal, natural language-based API or NLP-based standard APIs. Focusing on\nthe management of multiparty AI conversations, this work introduces new\nconcepts such as the Convener Agent, Floor-Shared Conversational Space, Floor\nManager, Multi-Conversant Support, and mechanisms for handling Interruptions\nand Uninvited Agents. Additionally, it explores the Convener's role as a\nmessage relay and controller of participant interactions, enhancing both\nscalability and security. These advancements are crucial for ensuring smooth,\nefficient, and secure interactions in scenarios where multiple AI agents need\nto collaborate, debate, or contribute to a discussion. The paper elaborates on\nthese concepts and provides practical examples, illustrating their\nimplementation within the conversation envelope structure.",
      "tldr_zh": "本论文提出了一种对 Open Voice Interoperability Initiative 的 Multi-Agent Interoperability 规范扩展，允许不同技术的 AI 代理通过通用自然语言-based API 或 NLP-based 标准 API 进行通信，从而管理多方对话。关键创新包括引入 Convener Agent（作为消息中继和交互控制器）、Floor-Shared Conversational Space（共享对话空间）、Floor Manager（地板管理器）、Multi-Conversant Support（多对话支持），以及处理 Interruptions 和 Uninvited Agents 的机制，以提升对话的平滑性和安全性。实验和示例展示了这些概念在 conversation envelope 结构中的实际应用，有助于多 AI 代理在协作、辩论或讨论场景中的高效交互。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "20 pages, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05828v1",
      "published_date": "2024-11-05 18:11:55 UTC",
      "updated_date": "2024-11-05 18:11:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:27:01.252883"
    },
    {
      "arxiv_id": "2411.03300v1",
      "title": "VERITAS: A Unified Approach to Reliability Evaluation",
      "title_zh": "翻译失败",
      "authors": [
        "Rajkumar Ramamurthy",
        "Meghana Arakkal Rajeev",
        "Oliver Molenschot",
        "James Zou",
        "Nazneen Rajani"
      ],
      "abstract": "Large language models (LLMs) often fail to synthesize information from their\ncontext to generate an accurate response. This renders them unreliable in\nknowledge intensive settings where reliability of the output is key. A critical\ncomponent for reliable LLMs is the integration of a robust fact-checking system\nthat can detect hallucinations across various formats. While several\nopen-access fact-checking models are available, their functionality is often\nlimited to specific tasks, such as grounded question-answering or entailment\nverification, and they perform less effectively in conversational settings. On\nthe other hand, closed-access models like GPT-4 and Claude offer greater\nflexibility across different contexts, including grounded dialogue\nverification, but are hindered by high costs and latency. In this work, we\nintroduce VERITAS, a family of hallucination detection models designed to\noperate flexibly across diverse contexts while minimizing latency and costs.\nVERITAS achieves state-of-the-art results considering average performance on\nall major hallucination detection benchmarks, with $10\\%$ increase in average\nperformance when compared to similar-sized models and get close to the\nperformance of GPT4 turbo with LLM-as-a-judge setting.",
      "tldr_zh": "本研究针对大型语言模型 (LLMs) 在知识密集型环境中合成信息失败的问题，提出 VERITAS，这是一个统一的幻觉 (hallucinations) 检测模型家族。VERITAS 旨在灵活处理多种上下文，包括对话验证，同时最小化延迟和成本，以克服现有开源模型的功能局限性和闭源模型如 GPT-4 的高开销。实验结果显示，VERITAS 在主要幻觉检测基准上实现了最先进性能，比类似大小模型平均提高了 10%，并接近 GPT-4 turbo 的表现。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03300v1",
      "published_date": "2024-11-05 17:53:25 UTC",
      "updated_date": "2024-11-05 17:53:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:27:12.768798"
    },
    {
      "arxiv_id": "2411.03294v3",
      "title": "Out-of-Distribution Recovery with Object-Centric Keypoint Inverse Policy for Visuomotor Imitation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "George Jiayuan Gao",
        "Tianyu Li",
        "Nadia Figueroa"
      ],
      "abstract": "We propose an object-centric recovery (OCR) framework to address the\nchallenges of out-of-distribution (OOD) scenarios in visuomotor policy\nlearning. Previous behavior cloning (BC) methods rely heavily on a large amount\nof labeled data coverage, failing in unfamiliar spatial states. Without relying\non extra data collection, our approach learns a recovery policy constructed by\nan inverse policy inferred from the object keypoint manifold gradient in the\noriginal training data. The recovery policy serves as a simple add-on to any\nbase visuomotor BC policy, agnostic to a specific method, guiding the system\nback towards the training distribution to ensure task success even in OOD\nsituations. We demonstrate the effectiveness of our object-centric framework in\nboth simulation and real robot experiments, achieving an improvement of 77.7\\%\nover the base policy in OOD. Furthermore, we show OCR's capacity to\nautonomously collect demonstrations for continual learning. Overall, we believe\nthis framework represents a step toward improving the robustness of visuomotor\npolicies in real-world settings. Project Website:\nhttps://sites.google.com/view/ocr-penn",
      "tldr_zh": "我们提出了一种Object-Centric Recovery (OCR)框架，用于解决Visuomotor Imitation Learning中Out-of-Distribution (OOD)场景的挑战，该框架不依赖额外数据，通过从原始训练数据中推断的Object Keypoint Manifold Gradient构建一个Inverse Policy，作为任何基线Visuomotor BC策略的简单附加模块。OCR能引导系统返回训练分布，确保在OOD情况下任务成功。在模拟和真实机器人实验中，该框架比基线策略提高了77.7%的性能，并展示了自主收集演示用于持续学习的能力。总体上，这为提升Visuomotor策略在真实世界的鲁棒性提供了重要进展。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03294v3",
      "published_date": "2024-11-05 17:41:14 UTC",
      "updated_date": "2025-03-20 18:03:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:27:25.919963"
    },
    {
      "arxiv_id": "2411.03292v2",
      "title": "Interaction2Code: Benchmarking MLLM-based Interactive Webpage Code Generation from Interactive Prototyping",
      "title_zh": "Interaction2Code：基于MLLM的交互式网页",
      "authors": [
        "Jingyu Xiao",
        "Yuxuan Wan",
        "Yintong Huo",
        "Zixin Wang",
        "Xinyi Xu",
        "Wenxuan Wang",
        "Zhiyao Xu",
        "Yuhang Wang",
        "Michael R. Lyu"
      ],
      "abstract": "Multimodal Large Language Models (MLLMs) have demonstrated remarkable\nperformance on the design-to-code task, i.e., generating UI code from UI\nmock-ups. However, existing benchmarks only contain static web pages for\nevaluation and ignore the dynamic interaction, limiting the practicality,\nusability and user engagement of the generated webpages.\n  To bridge these gaps, we present the first systematic investigation of MLLMs\nin generating interactive webpages. Specifically, we formulate the\nInteraction-to-Code task and establish the Interaction2Code benchmark,\nencompassing 127 unique webpages and 374 distinct interactions across 15\nwebpage types and 31 interaction categories. Through comprehensive experiments\nutilizing state-of-the-art (SOTA) MLLMs, evaluated via both automatic metrics\nand human assessments, we identify four critical limitations of MLLM on\nInteraction-to-Code task: (1) inadequate generation of interaction compared\nwith full page, (2) prone to ten types of failure, (3) poor performance on\nvisually subtle interactions, and (4) insufficient undestanding on interaction\nwhen limited to single-modality visual descriptions. To address these\nlimitations, we propose four enhancement strategies: Interactive Element\nHighlighting, Failureaware Prompting (FAP), Visual Saliency Enhancement, and\nVisual-Textual Descriptions Combination, all aiming at improving MLLMs'\nperformance on the Interaction-toCode task. The Interaction2Code benchmark and\ncode are available in https://github. com/WebPAI/Interaction2Code.",
      "tldr_zh": "本研究针对 Multimodal Large Language Models (MLLMs) 在网页代码生成任务中的局限性，首次系统探讨了从交互原型生成交互式网页的 Interaction-to-Code 任务，并建立了 Interaction2Code 基准，该基准包含 127 个独特网页、374 个不同交互，覆盖 15 种网页类型和 31 种交互类别。实验通过自动指标和人工评估发现，MLLMs 存在四个关键问题：生成交互不足、易出现十种失败类型、在视觉微妙交互上表现差，以及在单模态视觉描述下理解交互不足。为了解决这些问题，研究提出了四种增强策略：Interactive Element Highlighting、Failureaware Prompting (FAP)、Visual Saliency Enhancement 和 Visual-Textual Descriptions Combination，从而显著提升了 MLLMs 在交互式网页生成上的性能。该基准和代码已在 GitHub 上开源。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.SE",
      "comment": "21 pages,14 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03292v2",
      "published_date": "2024-11-05 17:40:03 UTC",
      "updated_date": "2025-02-20 06:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:27:37.788060"
    },
    {
      "arxiv_id": "2411.03287v1",
      "title": "The Future of Intelligent Healthcare: A Systematic Analysis and Discussion on the Integration and Impact of Robots Using Large Language Models for Healthcare",
      "title_zh": "智能医疗保健的未来：关于使用大型语言模型的机器人在医疗保健中的集成和影响的系统分析和讨论",
      "authors": [
        "Souren Pashangpour",
        "Goldie Nejat"
      ],
      "abstract": "The potential use of large language models (LLMs) in healthcare robotics can\nhelp address the significant demand put on healthcare systems around the world\nwith respect to an aging demographic and a shortage of healthcare\nprofessionals. Even though LLMs have already been integrated into medicine to\nassist both clinicians and patients, the integration of LLMs within healthcare\nrobots has not yet been explored for clinical settings. In this perspective\npaper, we investigate the groundbreaking developments in robotics and LLMs to\nuniquely identify the needed system requirements for designing health specific\nLLM based robots in terms of multi modal communication through human robot\ninteractions (HRIs), semantic reasoning, and task planning. Furthermore, we\ndiscuss the ethical issues, open challenges, and potential future research\ndirections for this emerging innovative field.",
      "tldr_zh": "这篇论文系统分析了大型语言模型 (LLMs) 在医疗机器人的整合及其对智能医疗的影响，旨在应对全球老龄化和医疗专业人员短缺的挑战。通过调查机器人和 LLMs 的最新发展，论文识别了设计健康特定 LLM 基于机器人的关键系统要求，包括多模态通信、人机交互 (HRIs)、语义推理和任务规划。同时，论文讨论了伦理问题、开放挑战以及未来的研究方向，为 LLMs 在临床医疗机器人的应用提供指导。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03287v1",
      "published_date": "2024-11-05 17:36:32 UTC",
      "updated_date": "2024-11-05 17:36:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:27:48.698037"
    },
    {
      "arxiv_id": "2411.03284v1",
      "title": "SMoA: Improving Multi-agent Large Language Models with Sparse Mixture-of-Agents",
      "title_zh": "翻译失败",
      "authors": [
        "Dawei Li",
        "Zhen Tan",
        "Peijia Qian",
        "Yifan Li",
        "Kumar Satvik Chaudhary",
        "Lijie Hu",
        "Jiayi Shen"
      ],
      "abstract": "While multi-agent systems have been shown to significantly enhance the\nperformance of Large Language Models (LLMs) across various tasks and\napplications, the dense interaction between scaling agents potentially hampers\ntheir efficiency and diversity. To address these challenges, we draw\ninspiration from the sparse mixture-of-agents (SMoE) and propose a sparse\nmixture-of-agents (SMoA) framework to improve the efficiency and diversity of\nmulti-agent LLMs. Unlike completely connected structures, SMoA introduces novel\nResponse Selection and Early Stopping mechanisms to sparsify information flows\namong individual LLM agents, striking a balance between performance and\nefficiency. Additionally, inspired by the expert diversity principle in SMoE\nframeworks for workload balance between experts, we assign distinct role\ndescriptions to each LLM agent, fostering diverse and divergent thinking.\nExtensive experiments on reasoning, alignment, and fairness benchmarks\ndemonstrate that SMoA achieves performance comparable to traditional\nmixture-of-agents approaches but with significantly lower computational costs.\nFurther analysis reveals that SMoA is more stable, has a greater capacity to\nscale, and offers considerable potential through hyper-parameter optimization.\nCode and data will be available at: https://github.com/David-Li0406/SMoA.",
      "tldr_zh": "该研究提出SMoA框架，通过借鉴sparse mixture-of-agents (SMoE)思想，改善多智能体Large Language Models (LLMs)的效率和多样性，以解决密集交互带来的问题。SMoA引入Response Selection和Early Stopping机制来稀疏化信息流，并为每个LLM智能体分配独特的角色描述，促进发散性思考。实验结果显示，SMoA在推理、对齐和公平性基准上与传统方法性能相当，但计算成本显著降低，且表现出更高的稳定性和可扩展性。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "Under Review",
      "pdf_url": "http://arxiv.org/pdf/2411.03284v1",
      "published_date": "2024-11-05 17:33:39 UTC",
      "updated_date": "2024-11-05 17:33:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:28:00.986726"
    },
    {
      "arxiv_id": "2411.03275v1",
      "title": "Causal Responsibility Attribution for Human-AI Collaboration",
      "title_zh": "翻译失败",
      "authors": [
        "Yahang Qi",
        "Bernhard Schölkopf",
        "Zhijing Jin"
      ],
      "abstract": "As Artificial Intelligence (AI) systems increasingly influence\ndecision-making across various fields, the need to attribute responsibility for\nundesirable outcomes has become essential, though complicated by the complex\ninterplay between humans and AI. Existing attribution methods based on actual\ncausality and Shapley values tend to disproportionately blame agents who\ncontribute more to an outcome and rely on real-world measures of\nblameworthiness that may misalign with responsible AI standards. This paper\npresents a causal framework using Structural Causal Models (SCMs) to\nsystematically attribute responsibility in human-AI systems, measuring overall\nblameworthiness while employing counterfactual reasoning to account for agents'\nexpected epistemic levels. Two case studies illustrate the framework's\nadaptability in diverse human-AI collaboration scenarios.",
      "tldr_zh": "本文提出一个基于 Structural Causal Models (SCMs) 的因果框架，用于在人-AI 协作系统中系统归因责任。该框架通过测量整体责任感并运用反事实推理(counterfactual reasoning)来考虑代理的预期认知水平，从而避免现有方法（如基于实际因果和 Shapley values）过度指责贡献较大的代理。相比传统方法，该框架更符合负责任的 AI 标准，并在两个案例研究中展示了其在多样人-AI 场景中的适应性和有效性。",
      "categories": [
        "cs.AI",
        "cs.HC",
        "stat.AP"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03275v1",
      "published_date": "2024-11-05 17:17:45 UTC",
      "updated_date": "2024-11-05 17:17:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:28:12.449782"
    },
    {
      "arxiv_id": "2411.14441v1",
      "title": "GeMID: Generalizable Models for IoT Device Identification",
      "title_zh": "GeMID: IoT 设备识别的可泛化模型",
      "authors": [
        "Kahraman Kostas",
        "Rabia Yasa Kostas",
        "Mike Just",
        "Michael A. Lones"
      ],
      "abstract": "With the proliferation of Internet of Things (IoT) devices, ensuring their\nsecurity has become paramount. Device identification (DI), which distinguishes\nIoT devices based on their traffic patterns, plays a crucial role in both\ndifferentiating devices and identifying vulnerable ones, closing a serious\nsecurity gap. However, existing approaches to DI that build machine learning\nmodels often overlook the challenge of model generalizability across diverse\nnetwork environments. In this study, we propose a novel framework to address\nthis limitation and evaluate the generalizability of DI models across datasets\ncollected within different network environments. Our approach involves a\ntwo-step process: first, we develop a feature and model selection method that\nis more robust to generalization issues by using a genetic algorithm with\nexternal feedback and datasets from distinct environments to refine the\nselections. Second, the resulting DI models are then tested on further\nindependent datasets in order to robustly assess their generalizability. We\ndemonstrate the effectiveness of our method by empirically comparing it to\nalternatives, highlighting how fundamental limitations of commonly employed\ntechniques such as sliding window and flow statistics limit their\ngeneralizability. Our findings advance research in IoT security and device\nidentification, offering insights into improving model effectiveness and\nmitigating risks in IoT networks.",
      "tldr_zh": "这篇论文提出了 GeMID 框架，旨在提升 IoT 设备识别（DI）模型的泛化性，以应对不同网络环境下的挑战，从而加强 IoT 安全。框架采用两步方法：首先，使用遗传算法（genetic algorithm）结合外部反馈和多环境数据集进行鲁棒的特征和模型选择；其次，在独立数据集上测试模型的泛化性能。实验结果显示，GeMID 比传统技术如 sliding window 和 flow statistics 更有效，显著改善了模型的准确性和可靠性，为 IoT 网络风险缓解提供了重要见解。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "8 pages main (9 figures, 2 tables), 19 pages Supplementary Material,\n  27 pages total",
      "pdf_url": "http://arxiv.org/pdf/2411.14441v1",
      "published_date": "2024-11-05 17:09:43 UTC",
      "updated_date": "2024-11-05 17:09:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:28:24.792143"
    },
    {
      "arxiv_id": "2411.03376v1",
      "title": "An Open API Architecture to Discover the Trustworthy Explanation of Cloud AI Services",
      "title_zh": "一种",
      "authors": [
        "Zerui Wang",
        "Yan Liu",
        "Jun Huang"
      ],
      "abstract": "This article presents the design of an open-API-based explainable AI (XAI)\nservice to provide feature contribution explanations for cloud AI services.\nCloud AI services are widely used to develop domain-specific applications with\nprecise learning metrics. However, the underlying cloud AI services remain\nopaque on how the model produces the prediction. We argue that XAI operations\nare accessible as open APIs to enable the consolidation of the XAI operations\ninto the cloud AI services assessment. We propose a design using a microservice\narchitecture that offers feature contribution explanations for cloud AI\nservices without unfolding the network structure of the cloud models. We can\nalso utilize this architecture to evaluate the model performance and XAI\nconsistency metrics showing cloud AI services trustworthiness. We collect\nprovenance data from operational pipelines to enable reproducibility within the\nXAI service. Furthermore, we present the discovery scenarios for the\nexperimental tests regarding model performance and XAI consistency metrics for\nthe leading cloud vision AI services. The results confirm that the\narchitecture, based on open APIs, is cloud-agnostic. Additionally, data\naugmentations result in measurable improvements in XAI consistency metrics for\ncloud AI services.",
      "tldr_zh": "本文提出了一种基于 open API 的可解释 AI (XAI) 服务设计，用于为 cloud AI services 提供特征贡献解释，以解决模型预测过程不透明的问题。该设计采用微服务架构，能够在不暴露云模型网络结构的情况下评估模型性能和 XAI 一致性指标，并通过收集操作管道的来源数据确保 XAI 服务的可重复性。实验结果显示，该架构是 cloud-agnostic 的，并且数据增强可显著改善 XAI 一致性指标，从而提升 cloud AI services 的可信度。",
      "categories": [
        "cs.DC",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.DC",
      "comment": "Published in: IEEE Transactions on Cloud Computing ( Volume: 12,\n  Issue: 2, April-June 2024)",
      "pdf_url": "http://arxiv.org/pdf/2411.03376v1",
      "published_date": "2024-11-05 16:52:22 UTC",
      "updated_date": "2024-11-05 16:52:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:28:36.975965"
    },
    {
      "arxiv_id": "2411.03253v1",
      "title": "Discovering Data Structures: Nearest Neighbor Search and Beyond",
      "title_zh": "翻译失败",
      "authors": [
        "Omar Salemohamed",
        "Laurent Charlin",
        "Shivam Garg",
        "Vatsal Sharan",
        "Gregory Valiant"
      ],
      "abstract": "We propose a general framework for end-to-end learning of data structures.\nOur framework adapts to the underlying data distribution and provides\nfine-grained control over query and space complexity. Crucially, the data\nstructure is learned from scratch, and does not require careful initialization\nor seeding with candidate data structures/algorithms. We first apply this\nframework to the problem of nearest neighbor search. In several settings, we\nare able to reverse-engineer the learned data structures and query algorithms.\nFor 1D nearest neighbor search, the model discovers optimal distribution\n(in)dependent algorithms such as binary search and variants of interpolation\nsearch. In higher dimensions, the model learns solutions that resemble k-d\ntrees in some regimes, while in others, they have elements of\nlocality-sensitive hashing. The model can also learn useful representations of\nhigh-dimensional data and exploit them to design effective data structures. We\nalso adapt our framework to the problem of estimating frequencies over a data\nstream, and believe it could also be a powerful discovery tool for new\nproblems.",
      "tldr_zh": "我们提出一个端到端学习数据结构的通用框架，该框架能适应底层数据分布，提供对查询和空间复杂度的精细控制，并从零开始学习而不需初始化候选结构。应用于Nearest Neighbor Search时，该框架在1D场景中发现最优算法如binary search和interpolation search，在高维场景中学习类似于k-d trees或locality-sensitive hashing的解决方案，并能利用高维数据的有用表示设计有效数据结构。该框架还扩展到数据流频率估计问题，并展示出作为发现新算法工具的潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DS"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03253v1",
      "published_date": "2024-11-05 16:50:54 UTC",
      "updated_date": "2024-11-05 16:50:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:28:49.360846"
    },
    {
      "arxiv_id": "2411.03252v1",
      "title": "Spontaneous Emergence of Agent Individuality through Social Interactions in LLM-Based Communities",
      "title_zh": "翻译失败",
      "authors": [
        "Ryosuke Takata",
        "Atsushi Masumori",
        "Takashi Ikegami"
      ],
      "abstract": "We study the emergence of agency from scratch by using Large Language Model\n(LLM)-based agents. In previous studies of LLM-based agents, each agent's\ncharacteristics, including personality and memory, have traditionally been\npredefined. We focused on how individuality, such as behavior, personality, and\nmemory, can be differentiated from an undifferentiated state. The present LLM\nagents engage in cooperative communication within a group simulation,\nexchanging context-based messages in natural language. By analyzing this\nmulti-agent simulation, we report valuable new insights into how social norms,\ncooperation, and personality traits can emerge spontaneously. This paper\ndemonstrates that autonomously interacting LLM-powered agents generate\nhallucinations and hashtags to sustain communication, which, in turn, increases\nthe diversity of words within their interactions. Each agent's emotions shift\nthrough communication, and as they form communities, the personalities of the\nagents emerge and evolve accordingly. This computational modeling approach and\nits findings will provide a new method for analyzing collective artificial\nintelligence.",
      "tldr_zh": "本文研究了在LLM-based代理中，代理个性（如行为、个性、记忆）如何通过社会互动从无差异状态中自发出现。研究方法涉及多代理模拟，让代理在群组环境中进行合作沟通，交换自然语言消息，导致代理生成hallucinations和hashtags以维持互动并提升词汇多样性。主要发现是，代理的情绪通过沟通动态变化，形成社会规范、合作关系和演化个性，为分析集体人工智能提供了一种新的计算建模方法。",
      "categories": [
        "cs.AI",
        "cs.MA"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03252v1",
      "published_date": "2024-11-05 16:49:33 UTC",
      "updated_date": "2024-11-05 16:49:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:29:00.775732"
    },
    {
      "arxiv_id": "2411.03250v1",
      "title": "DiffLM: Controllable Synthetic Data Generation via Diffusion Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Ying Zhou",
        "Xinyao Wang",
        "Yulei Niu",
        "Yaojie Shen",
        "Lexin Tang",
        "Fan Chen",
        "Ben He",
        "Le Sun",
        "Longyin Wen"
      ],
      "abstract": "Recent advancements in large language models (LLMs) have significantly\nenhanced their knowledge and generative capabilities, leading to a surge of\ninterest in leveraging LLMs for high-quality data synthesis. However, synthetic\ndata generation via prompting LLMs remains challenging due to LLMs' limited\nunderstanding of target data distributions and the complexity of prompt\nengineering, especially for structured formatted data. To address these issues,\nwe introduce DiffLM, a controllable data synthesis framework based on\nvariational autoencoder (VAE), which further (1) leverages diffusion models to\nreserve more information of original distribution and format structure in the\nlearned latent distribution and (2) decouples the learning of target\ndistribution knowledge from the LLM's generative objectives via a plug-and-play\nlatent feature injection module. As we observed significant discrepancies\nbetween the VAE's latent representations and the real data distribution, the\nlatent diffusion module is introduced into our framework to learn a fully\nexpressive latent distribution. Evaluations on seven real-world datasets with\nstructured formatted data (i.e., Tabular, Code and Tool data) demonstrate that\nDiffLM generates high-quality data, with performance on downstream tasks\nsurpassing that of real data by 2-7 percent in certain cases. The data and code\nwill be publicly available upon completion of internal review.",
      "tldr_zh": "该研究提出 DiffLM 框架，利用变分自编码器 (VAE) 和扩散模型，解决大型语言模型 (LLMs) 在合成数据生成中的问题，如对目标数据分布理解有限和提示工程复杂。DiffLM 通过保留原始数据分布的更多信息、解耦目标分布知识学习与 LLM 生成目标，并引入潜在扩散模块来学习更全面的潜在表示，从而实现对结构化数据的可控生成（如 Tabular、Code 和 Tool 数据）。实验结果显示，在七个真实世界数据集上，DiffLM 生成的合成数据在下游任务中性能超过了真实数据 2-7%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "17 pages, 8 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03250v1",
      "published_date": "2024-11-05 16:47:53 UTC",
      "updated_date": "2024-11-05 16:47:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:29:13.389757"
    },
    {
      "arxiv_id": "2411.03237v1",
      "title": "On the Detection of Non-Cooperative RISs: Scan B-Testing via Deep Support Vector Data Description",
      "title_zh": "翻译失败",
      "authors": [
        "George Stamatelis",
        "Panagiotis Gavriilidis",
        "Aymen Fakhreddine",
        "George C. Alexandropoulos"
      ],
      "abstract": "In this paper, we study the problem of promptly detecting the presence of\nnon-cooperative activity from one or more Reconfigurable Intelligent Surfaces\n(RISs) with unknown characteristics lying in the vicinity of a Multiple-Input\nMultiple-Output (MIMO) communication system using Orthogonal Frequency-Division\nMultiplexing (OFDM) transmissions. We first present a novel wideband channel\nmodel incorporating RISs as well as non-reconfigurable stationary surfaces,\nwhich captures both the effect of the RIS actuation time on the channel in the\nfrequency domain as well as the difference between changing phase\nconfigurations during or among transmissions. Considering that RISs may operate\nunder the coordination of a third-party system, and thus, may negatively impact\nthe communication of the intended MIMO OFDM system, we present a novel RIS\nactivity detection framework that is unaware of the distribution of the phase\nconfiguration of any of the non-cooperative RISs. In particular, capitalizing\non the knowledge of the data distribution at the multi-antenna receiver, we\ndesign a novel online change point detection statistic that combines a deep\nsupport vector data description model with the scan $B$-test. The presented\nnumerical investigations demonstrate the improved detection accuracy as well as\ndecreased computational complexity of the proposed RIS detection approach over\nexisting change point detection schemes.",
      "tldr_zh": "该论文研究了在 MIMO OFDM 通信系统中检测非合作 Reconfigurable Intelligent Surfaces (RISs) 的问题，提出了一种新的宽带信道模型来捕捉 RISs 的激活时间和相位配置变化对信道的影响。作者设计了一个基于 deep support vector data description 模型和 scan B-test 的在线变化点检测框架，该框架无需了解非合作 RISs 的相位配置分布，就能有效识别潜在干扰。实验结果显示，该方法相比现有变化点检测方案，显著提高了检测准确率并降低了计算复杂度。",
      "categories": [
        "cs.NI",
        "cs.AI",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.NI",
      "comment": "6 pages, 4 figures, submitted to an IEEE conference",
      "pdf_url": "http://arxiv.org/pdf/2411.03237v1",
      "published_date": "2024-11-05 16:36:51 UTC",
      "updated_date": "2024-11-05 16:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:29:25.216227"
    },
    {
      "arxiv_id": "2411.03231v2",
      "title": "Formal Logic-guided Robust Federated Learning against Poisoning Attacks",
      "title_zh": "形式逻辑引导的鲁棒联邦学习对抗投毒攻击",
      "authors": [
        "Dung Thuy Nguyen",
        "Ziyan An",
        "Taylor T. Johnson",
        "Meiyi Ma",
        "Kevin Leach"
      ],
      "abstract": "Federated Learning (FL) offers a promising solution to the privacy concerns\nassociated with centralized Machine Learning (ML) by enabling decentralized,\ncollaborative learning. However, FL is vulnerable to various security threats,\nincluding poisoning attacks, where adversarial clients manipulate the training\ndata or model updates to degrade overall model performance. Recognizing this\nthreat, researchers have focused on developing defense mechanisms to counteract\npoisoning attacks in FL systems. However, existing robust FL methods\npredominantly focus on computer vision tasks, leaving a gap in addressing the\nunique challenges of FL with time series data. In this paper, we present\nFLORAL, a defense mechanism designed to mitigate poisoning attacks in federated\nlearning for time-series tasks, even in scenarios with heterogeneous client\ndata and a large number of adversarial participants. Unlike traditional\nmodel-centric defenses, FLORAL leverages logical reasoning to evaluate client\ntrustworthiness by aligning their predictions with global time-series patterns,\nrather than relying solely on the similarity of client updates. Our approach\nextracts logical reasoning properties from clients, then hierarchically infers\nglobal properties, and uses these to verify client updates. Through formal\nlogic verification, we assess the robustness of each client contribution,\nidentifying deviations indicative of adversarial behavior. Experimental results\non two datasets demonstrate the superior performance of our approach compared\nto existing baseline methods, highlighting its potential to enhance the\nrobustness of FL to time series applications. Notably, FLORAL reduced the\nprediction error by 93.27% in the best-case scenario compared to the\nsecond-best baseline. Our code is available at\nhttps://anonymous.4open.science/r/FLORAL-Robust-FTS.",
      "tldr_zh": "这篇论文提出了一种名为 FLORAL 的防御机制，用于抵抗 Federated Learning (FL) 中的 poisoning attacks，尤其针对时间序列任务的独特挑战。不同于传统的基于模型更新相似度的方法，FLORAL 通过逻辑推理提取客户端的推理属性，进行层次化全局属性推断，并利用正式逻辑验证来评估客户端贡献的可信度，从而识别潜在的攻击行为。在两个数据集上的实验结果表明，FLORAL 相较于基线方法显著提升了性能，在最佳场景下将预测错误减少了 93.27%，为 FL 的鲁棒性提供了新途径。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC",
        "cs.LO"
      ],
      "primary_category": "cs.CR",
      "comment": "12 pages, 4 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2411.03231v2",
      "published_date": "2024-11-05 16:23:19 UTC",
      "updated_date": "2024-11-06 02:56:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:29:36.803585"
    },
    {
      "arxiv_id": "2411.03225v2",
      "title": "Knowledge Graphs of Driving Scenes to Empower the Emerging Capabilities of Neurosymbolic AI",
      "title_zh": "翻译失败",
      "authors": [
        "Ruwan Wickramarachchi",
        "Cory Henson",
        "Amit Sheth"
      ],
      "abstract": "In the era of Generative AI, Neurosymbolic AI is emerging as a powerful\napproach for tasks spanning from perception to cognition. The use of\nNeurosymbolic AI has been shown to achieve enhanced capabilities, including\nimproved grounding, alignment, explainability, and reliability. However, due to\nits nascent stage, there is a lack of widely available real-world benchmark\ndatasets tailored to Neurosymbolic AI tasks. To address this gap and support\nthe evaluation of current and future methods, we introduce DSceneKG -- a suite\nof knowledge graphs of driving scenes built from real-world, high-quality\nscenes from multiple open autonomous driving datasets. In this article, we\ndetail the construction process of DSceneKG and highlight its application in\nseven different tasks. DSceneKG is publicly accessible at:\nhttps://github.com/ruwantw/DSceneKG",
      "tldr_zh": "该研究探讨了Neurosymbolic AI在感知和认知任务中的优势，包括提升的grounding、alignment、explainability和reliability，但强调了缺乏针对此类任务的真实世界基准数据集。为填补这一空白，研究引入了DSceneKG，这是一个基于多个开源自动驾驶数据集构建的驾驶场景知识图谱套件。DSceneKG详细阐述了其构建过程，并展示了在七个不同任务中的应用，支持未来方法的评估和优化，可通过https://github.com/ruwantw/DSceneKG公开访问。",
      "categories": [
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.AI",
      "comment": "8 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.03225v2",
      "published_date": "2024-11-05 16:15:33 UTC",
      "updated_date": "2024-11-07 15:41:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:29:48.264362"
    },
    {
      "arxiv_id": "2411.03223v2",
      "title": "Beyond Grid Data: Exploring Graph Neural Networks for Earth Observation",
      "title_zh": "翻译失败",
      "authors": [
        "Shan Zhao",
        "Zhaiyu Chen",
        "Zhitong Xiong",
        "Yilei Shi",
        "Sudipan Saha",
        "Xiao Xiang Zhu"
      ],
      "abstract": "Earth Observation (EO) data analysis has been significantly revolutionized by\ndeep learning (DL), with applications typically limited to grid-like data\nstructures. Graph Neural Networks (GNNs) emerge as an important innovation,\npropelling DL into the non-Euclidean domain. Naturally, GNNs can effectively\ntackle the challenges posed by diverse modalities, multiple sensors, and the\nheterogeneous nature of EO data. To introduce GNNs in the related domains, our\nreview begins by offering fundamental knowledge on GNNs. Then, we summarize the\ngeneric problems in EO, to which GNNs can offer potential solutions. Following\nthis, we explore a broad spectrum of GNNs' applications to scientific problems\nin Earth systems, covering areas such as weather and climate analysis, disaster\nmanagement, air quality monitoring, agriculture, land cover classification,\nhydrological process modeling, and urban modeling. The rationale behind\nadopting GNNs in these fields is explained, alongside methodologies for\norganizing graphs and designing favorable architectures for various tasks.\nFurthermore, we highlight methodological challenges of implementing GNNs in\nthese domains and possible solutions that could guide future research. While\nacknowledging that GNNs are not a universal solution, we conclude the paper by\ncomparing them with other popular architectures like transformers and analyzing\ntheir potential synergies.",
      "tldr_zh": "这篇论文探讨了Graph Neural Networks (GNNs) 在Earth Observation (EO) 数据分析中的应用，超越了传统的网格数据结构，将深度学习 (DL) 扩展到非欧空间领域。论文首先介绍GNNs 的基础知识，然后总结EO 中存在的通用问题，如多模态数据和异构性质，并说明GNNs 如何提供潜在解决方案。作者审视了GNNs 在天气气候分析、灾害管理、农业和城市建模等领域的广泛应用，包括图组织方法和架构设计，同时讨论了实施挑战、未来研究方向，并与transformers 等架构进行比较，以突出GNNs 的优势和协同潜力。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted for publication in Geoscience and Remote Sensing Magazine\n  (GRSM)",
      "pdf_url": "http://arxiv.org/pdf/2411.03223v2",
      "published_date": "2024-11-05 16:12:12 UTC",
      "updated_date": "2024-11-06 09:10:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:30:00.814104"
    },
    {
      "arxiv_id": "2411.03205v4",
      "title": "GIS Copilot: Towards an Autonomous GIS Agent for Spatial Analysis",
      "title_zh": "GIS Copilot：迈向自主 GIS 智能体用于空间分析",
      "authors": [
        "Temitope Akinboyewa",
        "Zhenlong Li",
        "Huan Ning",
        "M. Naser Lessani"
      ],
      "abstract": "Recent advancements in Generative AI offer promising capabilities for spatial\nanalysis. Despite their potential, the integration of generative AI with\nestablished GIS platforms remains underexplored. In this study, we propose a\nframework for integrating LLMs directly into existing GIS platforms, using QGIS\nas an example. Our approach leverages the reasoning and programming\ncapabilities of LLMs to autonomously generate spatial analysis workflows and\ncode through an informed agent that has comprehensive documentation of key GIS\ntools and parameters. The implementation of this framework resulted in the\ndevelopment of a \"GIS Copilot\" that allows GIS users to interact with QGIS\nusing natural language commands for spatial analysis. The GIS Copilot was\nevaluated with over 100 spatial analysis tasks with three complexity levels:\nbasic tasks that require one GIS tool and typically involve one data layer to\nperform simple operations; intermediate tasks involving multi-step processes\nwith multiple tools, guided by user instructions; and advanced tasks which\ninvolve multi-step processes that require multiple tools but not guided by user\ninstructions, necessitating the agent to independently decide on and executes\nthe necessary steps. The evaluation reveals that the GIS Copilot demonstrates\nstrong potential in automating foundational GIS operations, with a high success\nrate in tool selection and code generation for basic and intermediate tasks,\nwhile challenges remain in achieving full autonomy for more complex tasks. This\nstudy contributes to the emerging vision of Autonomous GIS, providing a pathway\nfor non-experts to engage with geospatial analysis with minimal prior\nexpertise. While full autonomy is yet to be achieved, the GIS Copilot\ndemonstrates significant potential for simplifying GIS workflows and enhancing\ndecision-making processes.",
      "tldr_zh": "本研究提出了一种框架，将大型语言模型（LLMs）整合到现有的 GIS 平台（如 QGIS）中，开发出“GIS Copilot”——一个自治 GIS 代理，用于自动化空间分析工作流和代码生成。框架利用 LLMs 的推理和编程能力，结合全面的 GIS 工具文档，让用户通过自然语言命令与 QGIS 交互执行任务。评估涉及超过 100 个空间分析任务，包括基本任务（单工具简单操作）、中间任务（多步多工具受指导过程）和高级任务（自主多步过程），结果显示 GIS Copilot 在基本和中间任务中表现出高成功率，但高级任务的完全自治仍面临挑战。该工作为 Autonomous GIS 的发展提供了路径，帮助非专家以最小专业知识参与地理空间分析，从而简化工作流并提升决策过程。",
      "categories": [
        "cs.AI",
        "cs.ET",
        "cs.HC",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03205v4",
      "published_date": "2024-11-05 15:53:59 UTC",
      "updated_date": "2024-11-22 02:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:30:12.769003"
    },
    {
      "arxiv_id": "2412.05282v2",
      "title": "International Scientific Report on the Safety of Advanced AI (Interim Report)",
      "title_zh": "翻译失败",
      "authors": [
        "Yoshua Bengio",
        "Sören Mindermann",
        "Daniel Privitera",
        "Tamay Besiroglu",
        "Rishi Bommasani",
        "Stephen Casper",
        "Yejin Choi",
        "Danielle Goldfarb",
        "Hoda Heidari",
        "Leila Khalatbari",
        "Shayne Longpre",
        "Vasilios Mavroudis",
        "Mantas Mazeika",
        "Kwan Yee Ng",
        "Chinasa T. Okolo",
        "Deborah Raji",
        "Theodora Skeadas",
        "Florian Tramèr",
        "Bayo Adekanmbi",
        "Paul Christiano",
        "David Dalrymple",
        "Thomas G. Dietterich",
        "Edward Felten",
        "Pascale Fung",
        "Pierre-Olivier Gourinchas",
        "Nick Jennings",
        "Andreas Krause",
        "Percy Liang",
        "Teresa Ludermir",
        "Vidushi Marda",
        "Helen Margetts",
        "John A. McDermid",
        "Arvind Narayanan",
        "Alondra Nelson",
        "Alice Oh",
        "Gopal Ramchurn",
        "Stuart Russell",
        "Marietje Schaake",
        "Dawn Song",
        "Alvaro Soto",
        "Lee Tiedrich",
        "Gaël Varoquaux",
        "Andrew Yao",
        "Ya-Qin Zhang"
      ],
      "abstract": "This is the interim publication of the first International Scientific Report\non the Safety of Advanced AI. The report synthesises the scientific\nunderstanding of general-purpose AI -- AI that can perform a wide variety of\ntasks -- with a focus on understanding and managing its risks. A diverse group\nof 75 AI experts contributed to this report, including an international Expert\nAdvisory Panel nominated by 30 countries, the EU, and the UN. Led by the Chair,\nthese independent experts collectively had full discretion over the report's\ncontent.\n  The final report is available at arXiv:2501.17805",
      "tldr_zh": "这份临时报告是第一个国际科学报告，聚焦于高级AI（Advanced AI）的安全问题，综合了关于通用AI（general-purpose AI）的科学理解，并强调风险的识别和管理。报告由75位AI专家共同撰写，包括由30个国家、欧盟和联合国提名的国际专家咨询小组，这些独立专家在主席的领导下对内容拥有完全自主权。该报告为全球AI风险管理提供科学基础，最终完整版本可在arXiv:2501.17805获取。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "Available under the open government license at\n  https://www.gov.uk/government/publications/international-scientific-report-on-the-safety-of-advanced-ai",
      "pdf_url": "http://arxiv.org/pdf/2412.05282v2",
      "published_date": "2024-11-05 15:47:23 UTC",
      "updated_date": "2025-04-09 11:34:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:30:24.674606"
    },
    {
      "arxiv_id": "2411.03177v2",
      "title": "On Improved Conditioning Mechanisms and Pre-training Strategies for Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tariq Berrada Ifriqi",
        "Pietro Astolfi",
        "Melissa Hall",
        "Reyhane Askari-Hemmat",
        "Yohann Benchetrit",
        "Marton Havasi",
        "Matthew Muckley",
        "Karteek Alahari",
        "Adriana Romero-Soriano",
        "Jakob Verbeek",
        "Michal Drozdzal"
      ],
      "abstract": "Large-scale training of latent diffusion models (LDMs) has enabled\nunprecedented quality in image generation. However, the key components of the\nbest performing LDM training recipes are oftentimes not available to the\nresearch community, preventing apple-to-apple comparisons and hindering the\nvalidation of progress in the field. In this work, we perform an in-depth study\nof LDM training recipes focusing on the performance of models and their\ntraining efficiency. To ensure apple-to-apple comparisons, we re-implement five\npreviously published models with their corresponding recipes. Through our\nstudy, we explore the effects of (i)~the mechanisms used to condition the\ngenerative model on semantic information (e.g., text prompt) and control\nmetadata (e.g., crop size, random flip flag, etc.) on the model performance,\nand (ii)~the transfer of the representations learned on smaller and\nlower-resolution datasets to larger ones on the training efficiency and model\nperformance. We then propose a novel conditioning mechanism that disentangles\nsemantic and control metadata conditionings and sets a new state-of-the-art in\nclass-conditional generation on the ImageNet-1k dataset -- with FID\nimprovements of 7% on 256 and 8% on 512 resolutions -- as well as text-to-image\ngeneration on the CC12M dataset -- with FID improvements of 8% on 256 and 23%\non 512 resolution.",
      "tldr_zh": "本研究深入探讨了潜在扩散模型（LDMs）的训练策略，重点关注条件机制（如文本提示和控制元数据）和预训练表示转移对模型性能及训练效率的影响。通过重新实现五个已发表模型并进行对照实验，作者分析了这些因素的作用。论文提出了一种新型条件机制，将语义信息和控制元数据分开处理，从而在ImageNet-1k数据集的类条件生成中实现FID改善7%（256分辨率）和8%（512分辨率），以及在CC12M数据集的文本到图像生成中实现FID改善8%（256分辨率）和23%（512分辨率），设定了新状态。总的来说，此工作提升了LDMs的生成质量和训练效率，为扩散模型领域提供了重要见解。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a conference paper (poster) for NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03177v2",
      "published_date": "2024-11-05 15:22:26 UTC",
      "updated_date": "2025-01-20 09:02:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:30:38.344491"
    },
    {
      "arxiv_id": "2411.03171v3",
      "title": "Navigating Extremes: Dynamic Sparsity in Large Output Spaces",
      "title_zh": "翻译失败",
      "authors": [
        "Nasib Ullah",
        "Erik Schultheis",
        "Mike Lasby",
        "Yani Ioannou",
        "Rohit Babbar"
      ],
      "abstract": "In recent years, Dynamic Sparse Training (DST) has emerged as an alternative\nto post-training pruning for generating efficient models. In principle, DST\nallows for a more memory efficient training process, as it maintains sparsity\nthroughout the entire training run. However, current DST implementations fail\nto capitalize on this in practice. Because sparse matrix multiplication is much\nless efficient than dense matrix multiplication on GPUs, most implementations\nsimulate sparsity by masking weights. In this paper, we leverage recent\nadvances in semi-structured sparse training to apply DST in the domain of\nclassification with large output spaces, where memory-efficiency is paramount.\nWith a label space of possibly millions of candidates, the classification layer\nalone will consume several gigabytes of memory. Switching from a dense to a\nfixed fan-in sparse layer updated with sparse evolutionary training (SET);\nhowever, severely hampers training convergence, especially at the largest label\nspaces. We find that poor gradient flow from the sparse classifier to the dense\ntext encoder make it difficult to learn good input representations. By\nemploying an intermediate layer or adding an auxiliary training objective, we\nrecover most of the generalisation performance of the dense model. Overall, we\ndemonstrate the applicability and practical benefits of DST in a challenging\ndomain -- characterized by a highly skewed label distribution that differs\nsubstantially from typical DST benchmark datasets -- which enables end-to-end\ntraining with millions of labels on commodity hardware.",
      "tldr_zh": "本研究探讨了 Dynamic Sparse Training (DST) 在大型输出空间分类任务中的应用，以解决内存效率问题。论文指出，现有 DST 实现因 GPU 上稀疏矩阵乘法效率低下而采用模拟稀疏，导致在数百万标签场景下训练收敛受阻，特别是从密集层切换到固定扇入稀疏层（如 Sparse Evolutionary Training (SET)）时，梯度流动不畅影响输入表示学习。通过引入中间层或辅助训练目标，研究者成功恢复了大部分密集模型的泛化性能。总体上，该工作证明了 DST 在高度倾斜标签分布的挑战性领域中的实用性，实现了在商品硬件上端到端训练数百万标签。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "27 pages, 7 figures, NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03171v3",
      "published_date": "2024-11-05 15:19:29 UTC",
      "updated_date": "2025-02-09 19:46:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:32:19.527758"
    },
    {
      "arxiv_id": "2411.03105v1",
      "title": "Evaluating Machine Learning Models against Clinical Protocols for Enhanced Interpretability and Continuity of Care",
      "title_zh": "评估机器学习模型与临床协议的对比，以提升可解释性和护理连续性",
      "authors": [
        "Christel Sirocchi",
        "Muhammad Suffian",
        "Federico Sabbatini",
        "Alessandro Bogliolo",
        "Sara Montagna"
      ],
      "abstract": "In clinical practice, decision-making relies heavily on established\nprotocols, often formalised as rules. Concurrently, Machine Learning (ML)\nmodels, trained on clinical data, aspire to integrate into medical\ndecision-making processes. However, despite the growing number of ML\napplications, their adoption into clinical practice remains limited. Two\ncritical concerns arise, relevant to the notions of consistency and continuity\nof care: (a) accuracy - the ML model, albeit more accurate, might introduce\nerrors that would not have occurred by applying the protocol; (b)\ninterpretability - ML models operating as black boxes might make predictions\nbased on relationships that contradict established clinical knowledge. In this\ncontext, the literature suggests using ML models integrating domain knowledge\nfor improved accuracy and interpretability. However, there is a lack of\nappropriate metrics for comparing ML models with clinical rules in addressing\nthese challenges. Accordingly, in this article, we first propose metrics to\nassess the accuracy of ML models with respect to the established protocol.\nSecondly, we propose an approach to measure the distance of explanations\nprovided by two rule sets, with the goal of comparing the explanation\nsimilarity between clinical rule-based systems and rules extracted from ML\nmodels. The approach is validated on the Pima Indians Diabetes dataset by\ntraining two neural networks - one exclusively on data, and the other\nintegrating a clinical protocol. Our findings demonstrate that the integrated\nML model achieves comparable performance to that of a fully data-driven model\nwhile exhibiting superior accuracy relative to the clinical protocol, ensuring\nenhanced continuity of care. Furthermore, we show that our integrated model\nprovides explanations for predictions that align more closely with the clinical\nprotocol compared to the data-driven model.",
      "tldr_zh": "本研究评估了 Machine Learning (ML) 模型与临床协议的比较，旨在提升模型的准确性和可解释性，以确保护理的连续性。论文提出新指标来衡量 ML 模型相对于临床规则的准确性，以及一种方法来测量解释距离，从而比较临床规则和 ML 提取规则的相似性。在 Pima Indians Diabetes 数据集上，通过训练一个整合临床协议的神经网络与纯数据驱动模型，结果显示整合模型的性能与数据驱动模型相当，但相对于临床协议具有更高的准确性，且其预测解释更接近临床知识。总的来说，该方法为 ML 在临床实践中的应用提供了更可靠的框架。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03105v1",
      "published_date": "2024-11-05 13:50:09 UTC",
      "updated_date": "2024-11-05 13:50:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:32:31.699082"
    },
    {
      "arxiv_id": "2411.03098v2",
      "title": "Local Lesion Generation is Effective for Capsule Endoscopy Image Data Augmentation in a Limited Data Setting",
      "title_zh": "翻译失败",
      "authors": [
        "Adrian B. Chłopowiec",
        "Adam R. Chłopowiec",
        "Krzysztof Galus",
        "Wojciech Cebula",
        "Martin Tabakov"
      ],
      "abstract": "Limited medical imaging datasets challenge deep learning models by increasing\nrisks of overfitting and reduced generalization, particularly in Generative\nAdversarial Networks (GANs), where discriminators may overfit, leading to\ntraining divergence. This constraint also impairs classification models trained\non small datasets. Generative Data Augmentation (GDA) addresses this by\nexpanding training datasets with synthetic data, although it requires training\na generative model. We propose and evaluate two local lesion generation\napproaches to address the challenge of augmenting small medical image datasets.\nThe first approach employs the Poisson Image Editing algorithm, a classical\nimage processing technique, to create realistic image composites that\noutperform current state-of-the-art methods. The second approach introduces a\nnovel generative method, leveraging a fine-tuned Image Inpainting GAN to\nsynthesize realistic lesions within specified regions of real training images.\nA comprehensive comparison of the two proposed methods demonstrates that\neffective local lesion generation in a data-constrained setting allows for\nreaching new state-of-the-art results in capsule endoscopy lesion\nclassification. Combination of our techniques achieves a macro F1-score of\n33.07%, surpassing the previous best result by 7.84 percentage points (p.p.) on\nthe highly imbalanced Kvasir Capsule Dataset, a benchmark for capsule\nendoscopy. To the best of our knowledge, this work is the first to apply a\nfine-tuned Image Inpainting GAN for GDA in medical imaging, demonstrating that\nan image-conditional GAN can be adapted effectively to limited datasets to\ngenerate high-quality examples, facilitating effective data augmentation.\nAdditionally, we show that combining this GAN-based approach with classical\nimage processing techniques further improves the results.",
      "tldr_zh": "该研究针对医疗图像数据集有限导致的深度学习模型过拟合问题，提出两种局部病变生成方法，用于胶囊内镜图像的生成数据扩充（GDA）。第一种方法采用Poisson Image Editing算法，通过经典图像处理技术创建更真实的图像合成；第二种方法则引入微调的Image Inpainting GAN，在真实图像的指定区域合成逼真的病变。实验结果显示，这两种方法的结合在高度不平衡的Kvasir Capsule Dataset上，使病变分类的宏F1分数达到33.07%，比先前最佳结果提高7.84百分点。论文首次证明，微调的Image Inpainting GAN可有效适应小数据集，并与传统图像处理技术相结合进一步提升分类性能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "54 pages, 35 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03098v2",
      "published_date": "2024-11-05 13:44:25 UTC",
      "updated_date": "2024-12-04 10:52:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:32:44.382785"
    },
    {
      "arxiv_id": "2411.03086v1",
      "title": "HFGaussian: Learning Generalizable Gaussian Human with Integrated Human Features",
      "title_zh": "翻译失败",
      "authors": [
        "Arnab Dey",
        "Cheng-You Lu",
        "Andrew I. Comport",
        "Srinath Sridhar",
        "Chin-Teng Lin",
        "Jean Martinet"
      ],
      "abstract": "Recent advancements in radiance field rendering show promising results in 3D\nscene representation, where Gaussian splatting-based techniques emerge as\nstate-of-the-art due to their quality and efficiency. Gaussian splatting is\nwidely used for various applications, including 3D human representation.\nHowever, previous 3D Gaussian splatting methods either use parametric body\nmodels as additional information or fail to provide any underlying structure,\nlike human biomechanical features, which are essential for different\napplications. In this paper, we present a novel approach called HFGaussian that\ncan estimate novel views and human features, such as the 3D skeleton, 3D key\npoints, and dense pose, from sparse input images in real time at 25 FPS. The\nproposed method leverages generalizable Gaussian splatting technique to\nrepresent the human subject and its associated features, enabling efficient and\ngeneralizable reconstruction. By incorporating a pose regression network and\nthe feature splatting technique with Gaussian splatting, HFGaussian\ndemonstrates improved capabilities over existing 3D human methods, showcasing\nthe potential of 3D human representations with integrated biomechanics. We\nthoroughly evaluate our HFGaussian method against the latest state-of-the-art\ntechniques in human Gaussian splatting and pose estimation, demonstrating its\nreal-time, state-of-the-art performance.",
      "tldr_zh": "本文提出HFGaussian方法，利用generalizable Gaussian splatting技术，从稀疏输入图像中实时重建3D人体表示，并整合人体特征，如3D skeleton、3D关键点和dense pose，实现25 FPS的实时性能。该方法结合pose regression network和feature splatting，解决了现有Gaussian splatting方法缺少底层生物力学结构的局限性。在人体Gaussian splatting和姿态估计任务上，HFGaussian比最新技术表现出更优的泛化性和准确率，展示了整合生物力学特征的潜力。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03086v1",
      "published_date": "2024-11-05 13:31:04 UTC",
      "updated_date": "2024-11-05 13:31:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:32:54.550579"
    },
    {
      "arxiv_id": "2411.03082v1",
      "title": "Self-supervised cross-modality learning for uncertainty-aware object detection and recognition in applications which lack pre-labelled training data",
      "title_zh": "翻译失败",
      "authors": [
        "Irum Mehboob",
        "Li Sun",
        "Alireza Astegarpanah",
        "Rustam Stolkin"
      ],
      "abstract": "This paper shows how an uncertainty-aware, deep neural network can be trained\nto detect, recognise and localise objects in 2D RGB images, in applications\nlacking annotated train-ng datasets. We propose a self-supervising\nteacher-student pipeline, in which a relatively simple teacher classifier,\ntrained with only a few labelled 2D thumbnails, automatically processes a\nlarger body of unlabelled RGB-D data to teach a student network based on a\nmodified YOLOv3 architecture. Firstly, 3D object detection with back projection\nis used to automatically extract and teach 2D detection and localisation\ninformation to the student network. Secondly, a weakly supervised 2D thumbnail\nclassifier, with minimal training on a small number of hand-labelled images, is\nused to teach object category recognition. Thirdly, we use a Gaussian Process\nGP to encode and teach a robust uncertainty estimation functionality, so that\nthe student can output confidence scores with each categorization. The\nresulting student significantly outperforms the same YOLO architecture trained\ndirectly on the same amount of labelled data. Our GP-based approach yields\nrobust and meaningful uncertainty estimations for complex industrial object\nclassifications. The end-to-end network is also capable of real-time\nprocessing, needed for robotics applications. Our method can be applied to many\nimportant industrial tasks, where labelled datasets are typically unavailable.\nIn this paper, we demonstrate an example of detection, localisation, and object\ncategory recognition of nuclear mixed-waste materials in highly cluttered and\nunstructured scenes. This is critical for robotic sorting and handling of\nlegacy nuclear waste, which poses complex environmental remediation challenges\nin many nuclearised nations.",
      "tldr_zh": "该论文提出了一种自监督的跨模态学习方法，用于在缺乏预标注训练数据的应用中，实现不确定性感知的物体检测、识别和定位，基于教师-学生管道。教师网络是一个简单分类器，仅用少量标注的2D缩略图训练，然后自动处理未标注的RGB-D数据，教导学生网络（修改后的YOLOv3架构），包括通过3D检测背投影提取2D定位信息、弱监督分类器教导类别识别，以及Gaussian Process (GP)编码不确定性估计以输出置信度分数。实验结果显示，该学生网络在相同数据量下显著优于直接训练的YOLO架构，提供鲁棒的不确定性评估，并支持实时处理，适用于工业任务如核废料检测和机器人排序。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.CV",
      "comment": "16 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.03082v1",
      "published_date": "2024-11-05 13:26:31 UTC",
      "updated_date": "2024-11-05 13:26:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:33:07.115723"
    },
    {
      "arxiv_id": "2411.03059v1",
      "title": "Enhancing DP-SGD through Non-monotonous Adaptive Scaling Gradient Weight",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Huang",
        "Qingyu Huang",
        "Xin Shi",
        "Jiayang Meng",
        "Guolong Zheng",
        "Xu Yang",
        "Xun Yi"
      ],
      "abstract": "In the domain of deep learning, the challenge of protecting sensitive data\nwhile maintaining model utility is significant. Traditional Differential\nPrivacy (DP) techniques such as Differentially Private Stochastic Gradient\nDescent (DP-SGD) typically employ strategies like direct or per-sample adaptive\ngradient clipping. These methods, however, compromise model accuracy due to\ntheir critical influence on gradient handling, particularly neglecting the\nsignificant contribution of small gradients during later training stages. In\nthis paper, we introduce an enhanced version of DP-SGD, named Differentially\nPrivate Per-sample Adaptive Scaling Clipping (DP-PSASC). This approach replaces\ntraditional clipping with non-monotonous adaptive gradient scaling, which\nalleviates the need for intensive threshold setting and rectifies the\ndisproportionate weighting of smaller gradients. Our contribution is twofold.\nFirst, we develop a novel gradient scaling technique that effectively assigns\nproper weights to gradients, particularly small ones, thus improving learning\nunder differential privacy. Second, we integrate a momentum-based method into\nDP-PSASC to reduce bias from stochastic sampling, enhancing convergence rates.\nOur theoretical and empirical analyses confirm that DP-PSASC preserves privacy\nand delivers superior performance across diverse datasets, setting new\nstandards for privacy-sensitive applications.",
      "tldr_zh": "这篇论文针对深度学习中保护敏感数据的挑战，提出了增强版的Differentially Private Stochastic Gradient Descent (DP-SGD)，即Differentially Private Per-sample Adaptive Scaling Clipping (DP-PSASC)。DP-PSASC 通过非单调的自适应梯度缩放替换传统剪裁方法，赋予小梯度适当权重并减少阈值设置的复杂性，同时整合基于动量的技术来降低随机采样的偏差，提高收敛率。主要贡献包括开发了新颖的梯度缩放技术，并在理论和实证分析中证明DP-PSASC 能保持Differential Privacy 同时提升模型性能，在多种数据集上表现出色。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03059v1",
      "published_date": "2024-11-05 12:47:30 UTC",
      "updated_date": "2024-11-05 12:47:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:34:55.462721"
    },
    {
      "arxiv_id": "2411.03055v3",
      "title": "ATM: Improving Model Merging by Alternating Tuning and Merging",
      "title_zh": "翻译失败",
      "authors": [
        "Luca Zhou",
        "Daniele Solombrino",
        "Donato Crisostomi",
        "Maria Sofia Bucarelli",
        "Fabrizio Silvestri",
        "Emanuele Rodolà"
      ],
      "abstract": "Model merging has recently emerged as a cost-efficient paradigm for\nmulti-task learning. Among current approaches, task arithmetic stands out for\nits simplicity and effectiveness. In this paper, we motivate the effectiveness\nof task vectors by linking them to multi-task gradients. We show that in a\nsingle-epoch scenario, if the optimization is performed via gradient descent,\ntask vectors are after one step mathematically equivalent to the gradients\nobtained via gradient descent in a multi-task setting, and still approximate\nthese gradients in subsequent epochs. Furthermore, we show that the\neffectiveness of task vectors is largely driven by the first epoch's gradient.\nGiven this parallel between task vectors and gradients, we propose viewing\nmodel merging as a single step in an iterative process that alternates between\ntuning and merging (ATM). We then propose two ways to utilize ATM. The first is\nto replace multi-task learning with ATM in scenarios where data sharing is\nprohibited, such as federated learning. The second is to improve the outcome of\nany model merging algorithm by applying a few post-hoc iterations of ATM on a\nsmall validation dataset, which is commonly available for hyperparameter\ntuning. Finally, we provide both empirical and theoretical support for the\neffectiveness of ATM, demonstrating that it minimizes an upper bound on the\nloss obtained by jointly finetuning all tasks.",
      "tldr_zh": "本论文探讨了模型合并（model merging）作为多任务学习的一种高效方法，并通过将任务向量（task vectors）与多任务梯度（multi-task gradients）联系起来，解释了其有效性。作者提出ATM（Alternating Tuning and Merging）框架，将模型合并视为交替调整和合并的迭代过程，能够在单轮优化中近似梯度下降的效果，并在后续迭代中进一步提升性能。ATM可用于数据共享受限场景（如federated learning）替代多任务学习，或通过在小验证集上进行后处理迭代来改进现有算法；实验和理论分析显示，ATM能最小化联合微调所有任务的损失上界，从而提升模型合并的整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Main paper: 9 Pages, 9 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2411.03055v3",
      "published_date": "2024-11-05 12:42:42 UTC",
      "updated_date": "2025-03-27 08:57:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:33:30.809855"
    },
    {
      "arxiv_id": "2411.03053v1",
      "title": "Gradient-Guided Conditional Diffusion Models for Private Image Reconstruction: Analyzing Adversarial Impacts of Differential Privacy and Denoising",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Huang",
        "Jiayang Meng",
        "Hong Chen",
        "Guolong Zheng",
        "Xu Yang",
        "Xun Yi",
        "Hua Wang"
      ],
      "abstract": "We investigate the construction of gradient-guided conditional diffusion\nmodels for reconstructing private images, focusing on the adversarial interplay\nbetween differential privacy noise and the denoising capabilities of diffusion\nmodels. While current gradient-based reconstruction methods struggle with\nhigh-resolution images due to computational complexity and prior knowledge\nrequirements, we propose two novel methods that require minimal modifications\nto the diffusion model's generation process and eliminate the need for prior\nknowledge. Our approach leverages the strong image generation capabilities of\ndiffusion models to reconstruct private images starting from randomly generated\nnoise, even when a small amount of differentially private noise has been added\nto the gradients. We also conduct a comprehensive theoretical analysis of the\nimpact of differential privacy noise on the quality of reconstructed images,\nrevealing the relationship among noise magnitude, the architecture of attacked\nmodels, and the attacker's reconstruction capability. Additionally, extensive\nexperiments validate the effectiveness of our proposed methods and the accuracy\nof our theoretical findings, suggesting new directions for privacy risk\nauditing using conditional diffusion models.",
      "tldr_zh": "本研究探讨了基于梯度引导的条件扩散模型（Gradient-Guided Conditional Diffusion Models）用于重建私有图像，重点分析差分隐私（Differential Privacy）噪声与扩散模型去噪能力的对抗性影响。作者提出两种新方法，仅需对扩散模型的生成过程进行最小修改，即可从随机噪声出发重建私有图像，而无需依赖先验知识，即使在添加少量差分隐私噪声的情况下也能实现有效重建。该方法通过理论分析揭示了噪声幅度、模型架构和攻击者重建能力之间的关系，并通过广泛实验验证了方法的有效性，为使用条件扩散模型进行隐私风险审计提供了新方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03053v1",
      "published_date": "2024-11-05 12:39:21 UTC",
      "updated_date": "2024-11-05 12:39:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:33:43.105985"
    },
    {
      "arxiv_id": "2411.03034v1",
      "title": "HumanVLM: Foundation for Human-Scene Vision-Language Model",
      "title_zh": "HumanVLM：人类-场景视觉语言模型的基础",
      "authors": [
        "Dawei Dai",
        "Xu Long",
        "Li Yutang",
        "Zhang Yuanhui",
        "Shuyin Xia"
      ],
      "abstract": "Human-scene vision-language tasks are increasingly prevalent in diverse\nsocial applications, yet recent advancements predominantly rely on models\nspecifically tailored to individual tasks. Emerging research indicates that\nlarge vision-language models (VLMs) can enhance performance across various\ndownstream vision-language understanding tasks. However, general-domain models\noften underperform in specialized fields. This study introduces a\ndomain-specific Large Vision-Language Model, Human-Scene Vision-Language Model\n(HumanVLM), designed to provide a foundation for human-scene Vision-Language\ntasks. Specifically, (1) we create a large-scale human-scene multimodal\nimage-text dataset (HumanCaption-10M) sourced from the Internet to facilitate\ndomain-specific alignment; (2) develop a captioning approach for human-centered\nimages, capturing human faces, bodies, and backgrounds, and construct a\nhigh-quality Human-Scene image-text dataset (HumanCaptionHQ, about 311k pairs)\nthat contain as much detailed information as possible about human; (3) Using\nHumanCaption-10M and HumanCaptionHQ, we train a HumanVLM. In the experiments,\nwe then evaluate our HumanVLM across varous downstream tasks, where it\ndemonstrates superior overall performance among multimodal models of comparable\nscale, particularly excelling in human-related tasks and significantly\noutperforming similar models, including Qwen2VL and ChatGPT-4o. HumanVLM,\nalongside the data introduced, will stimulate the research in human-around\nfields.",
      "tldr_zh": "这篇论文介绍了 HumanVLM，一种针对人类场景的领域特定 Large Vision-Language Model，旨在解决通用模型在人类场景任务中的表现不足问题。研究者创建了大规模多模态图像文本数据集 HumanCaption-10M，并开发了一种标题生成方法来捕捉人脸、身体和背景，构建了高质量数据集 HumanCaptionHQ（约311k对）。利用这些数据集训练的 HumanVLM 在各种下游视觉语言任务中表现出色，尤其在人类相关任务上，显著优于 Qwen2VL 和 ChatGPT-4o，为人类场景领域的进一步研究奠定基础。",
      "categories": [
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "34 pages,11 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.03034v1",
      "published_date": "2024-11-05 12:14:57 UTC",
      "updated_date": "2024-11-05 12:14:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:33:54.972912"
    },
    {
      "arxiv_id": "2411.05826v1",
      "title": "From Pixels to Prose: Advancing Multi-Modal Language Models for Remote Sensing",
      "title_zh": "从像素到散文：推进多模态语言模型用于遥感",
      "authors": [
        "Xintian Sun",
        "Benji Peng",
        "Charles Zhang",
        "Fei Jin",
        "Qian Niu",
        "Junyu Liu",
        "Keyu Chen",
        "Ming Li",
        "Pohsun Feng",
        "Ziqian Bi",
        "Ming Liu",
        "Yichao Zhang"
      ],
      "abstract": "Remote sensing has evolved from simple image acquisition to complex systems\ncapable of integrating and processing visual and textual data. This review\nexamines the development and application of multi-modal language models (MLLMs)\nin remote sensing, focusing on their ability to interpret and describe\nsatellite imagery using natural language. We cover the technical underpinnings\nof MLLMs, including dual-encoder architectures, Transformer models,\nself-supervised and contrastive learning, and cross-modal integration. The\nunique challenges of remote sensing data--varying spatial resolutions, spectral\nrichness, and temporal changes--are analyzed for their impact on MLLM\nperformance. Key applications such as scene description, object detection,\nchange detection, text-to-image retrieval, image-to-text generation, and visual\nquestion answering are discussed to demonstrate their relevance in\nenvironmental monitoring, urban planning, and disaster response. We review\nsignificant datasets and resources supporting the training and evaluation of\nthese models. Challenges related to computational demands, scalability, data\nquality, and domain adaptation are highlighted. We conclude by proposing future\nresearch directions and technological advancements to further enhance MLLM\nutility in remote sensing.",
      "tldr_zh": "这篇综述论文探讨了多模态语言模型 (MLLMs) 在遥感领域的进展，重点关注其通过自然语言解释和描述卫星图像的能力。论文回顾了MLLMs的技术基础，包括双编码器架构、Transformer 模型、自监督学习和对比学习，并分析了遥感数据的空间分辨率、光谱丰富性和时间变化对模型性能的影响。关键应用涵盖场景描述、物体检测、变化检测、文本到图像检索、图像到文本生成以及视觉问答，这些在环境监测、城市规划和灾害响应中发挥重要作用；同时，论文强调了计算需求、可扩展性、数据质量和领域适应的挑战，并提出未来研究方向以提升MLLMs在遥感中的实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2411.05826v1",
      "published_date": "2024-11-05 12:14:22 UTC",
      "updated_date": "2024-11-05 12:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:34:07.095974"
    },
    {
      "arxiv_id": "2411.03027v1",
      "title": "Adaptive Genetic Selection based Pinning Control with Asymmetric Coupling for Multi-Network Heterogeneous Vehicular Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Weian Guo",
        "Ruizhi Sha",
        "Li Li",
        "Lun Zhang",
        "Dongyang Li"
      ],
      "abstract": "To alleviate computational load on RSUs and cloud platforms, reduce\ncommunication bandwidth requirements, and provide a more stable vehicular\nnetwork service, this paper proposes an optimized pinning control approach for\nheterogeneous multi-network vehicular ad-hoc networks (VANETs). In such\nnetworks, vehicles participate in multiple task-specific networks with\nasymmetric coupling and dynamic topologies. We first establish a rigorous\ntheoretical foundation by proving the stability of pinning control strategies\nunder both single and multi-network conditions, deriving sufficient stability\nconditions using Lyapunov theory and linear matrix inequalities (LMIs).\nBuilding on this theoretical groundwork, we propose an adaptive genetic\nalgorithm tailored to select optimal pinning nodes, effectively balancing LMI\nconstraints while prioritizing overlapping nodes to enhance control efficiency.\nExtensive simulations across various network scales demonstrate that our\napproach achieves rapid consensus with a reduced number of control nodes,\nparticularly when leveraging network overlaps. This work provides a\ncomprehensive solution for efficient control node selection in complex\nvehicular networks, offering practical implications for deploying large-scale\nintelligent transportation systems.",
      "tldr_zh": "本文提出了一种基于自适应遗传算法(adaptive genetic algorithm)的优化 pinning control 策略，用于异构多网络车载自组网(VANETs)，以处理不对称耦合和动态拓扑问题，从而减轻 RSUs 和云平台的计算负载，并减少通信带宽需求。研究首先利用 Lyapunov theory 和 linear matrix inequalities (LMIs) 证明了 pinning control 在单网络和多网络条件下的稳定性。接着，通过该算法智能选择最优 pinning nodes，优先考虑网络重叠以提升控制效率。模拟实验在各种网络规模下显示，该方法实现了快速共识并显著减少控制节点数量，为大规模智能交通系统的部署提供了实用解决方案。",
      "categories": [
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03027v1",
      "published_date": "2024-11-05 11:49:26 UTC",
      "updated_date": "2024-11-05 11:49:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:34:20.369043"
    },
    {
      "arxiv_id": "2411.03025v1",
      "title": "DA-MoE: Addressing Depth-Sensitivity in Graph-Level Analysis through Mixture of Experts",
      "title_zh": "DA-MoE：通过专家混合解决图级分析中的深度敏感性",
      "authors": [
        "Zelin Yao",
        "Chuang Liu",
        "Xianke Meng",
        "Yibing Zhan",
        "Jia Wu",
        "Shirui Pan",
        "Wenbin Hu"
      ],
      "abstract": "Graph neural networks (GNNs) are gaining popularity for processing\ngraph-structured data. In real-world scenarios, graph data within the same\ndataset can vary significantly in scale. This variability leads to\ndepth-sensitivity, where the optimal depth of GNN layers depends on the scale\nof the graph data. Empirically, fewer layers are sufficient for message passing\nin smaller graphs, while larger graphs typically require deeper networks to\ncapture long-range dependencies and global features. However, existing methods\ngenerally use a fixed number of GNN layers to generate representations for all\ngraphs, overlooking the depth-sensitivity issue in graph structure data. To\naddress this challenge, we propose the depth adaptive mixture of expert\n(DA-MoE) method, which incorporates two main improvements to GNN backbone:\n\\textbf{1)} DA-MoE employs different GNN layers, each considered an expert with\nits own parameters. Such a design allows the model to flexibly aggregate\ninformation at different scales, effectively addressing the depth-sensitivity\nissue in graph data. \\textbf{2)} DA-MoE utilizes GNN to capture the structural\ninformation instead of the linear projections in the gating network. Thus, the\ngating network enables the model to capture complex patterns and dependencies\nwithin the data. By leveraging these improvements, each expert in DA-MoE\nspecifically learns distinct graph patterns at different scales. Furthermore,\ncomprehensive experiments on the TU dataset and open graph benchmark (OGB) have\nshown that DA-MoE consistently surpasses existing baselines on various tasks,\nincluding graph, node, and link-level analyses. The code are available at\n\\url{https://github.com/Celin-Yao/DA-MoE}.",
      "tldr_zh": "该论文针对图神经网络(GNNs)在处理不同规模图数据时存在的深度敏感性问题，提出了一种深度自适应混合专家(DA-MoE)方法。DA-MoE通过将多个GNN层设计为独立的专家，并使用GNN在gating网络中捕获结构信息，从而允许模型灵活聚合不同规模图的特征，避免了固定层数带来的局限性。实验结果显示，DA-MoE在TU dataset和OGB数据集上的图级、节点级和链接级任务中，均超过了现有基线模型，证明了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "8pages",
      "pdf_url": "http://arxiv.org/pdf/2411.03025v1",
      "published_date": "2024-11-05 11:46:27 UTC",
      "updated_date": "2024-11-05 11:46:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:35:06.958680"
    },
    {
      "arxiv_id": "2411.03022v1",
      "title": "Flashy Backdoor: Real-world Environment Backdoor Attack on SNNs with DVS Cameras",
      "title_zh": "翻译失败",
      "authors": [
        "Roberto Riaño",
        "Gorka Abad",
        "Stjepan Picek",
        "Aitor Urbieta"
      ],
      "abstract": "While security vulnerabilities in traditional Deep Neural Networks (DNNs)\nhave been extensively studied, the susceptibility of Spiking Neural Networks\n(SNNs) to adversarial attacks remains mostly underexplored. Until now, the\nmechanisms to inject backdoors into SNN models have been limited to digital\nscenarios; thus, we present the first evaluation of backdoor attacks in\nreal-world environments.\n  We begin by assessing the applicability of existing digital backdoor attacks\nand identifying their limitations for deployment in physical environments. To\naddress each of the found limitations, we present three novel backdoor attack\nmethods on SNNs, i.e., Framed, Strobing, and Flashy Backdoor. We also assess\nthe effectiveness of traditional backdoor procedures and defenses adapted for\nSNNs, such as pruning, fine-tuning, and fine-pruning. The results show that\nwhile these procedures and defenses can mitigate some attacks, they often fail\nagainst stronger methods like Flashy Backdoor or sacrifice too much clean\naccuracy, rendering the models unusable.\n  Overall, all our methods can achieve up to a 100% Attack Success Rate while\nmaintaining high clean accuracy in every tested dataset. Additionally, we\nevaluate the stealthiness of the triggers with commonly used metrics, finding\nthem highly stealthy. Thus, we propose new alternatives more suited for\nidentifying poisoned samples in these scenarios. Our results show that further\nresearch is needed to ensure the security of SNN-based systems against backdoor\nattacks and their safe application in real-world scenarios. The code,\nexperiments, and results are available in our repository.",
      "tldr_zh": "这篇论文探讨了 Spiking Neural Networks (SNNs) 的安全漏洞，首次评估了在真实世界环境下的后门攻击，特别是结合 DVS Cameras 的场景。作者评估了现有数字后门攻击的局限性，并提出了三种新方法——Framed、Strobing 和 Flashy Backdoor，以克服这些问题，同时保持高干净准确率。实验结果显示，这些攻击可实现高达 100% 的攻击成功率，而传统防御如 pruning、fine-tuning 和 fine-pruning 往往无法有效应对，或会显著牺牲模型性能。论文呼吁进一步研究以提升 SNNs 在实际应用中的安全性。",
      "categories": [
        "cs.CR",
        "cs.AI"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.03022v1",
      "published_date": "2024-11-05 11:44:54 UTC",
      "updated_date": "2024-11-05 11:44:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:35:19.423872"
    },
    {
      "arxiv_id": "2411.03012v1",
      "title": "Leveraging Large Language Models in Code Question Answering: Baselines and Issues",
      "title_zh": "翻译失败",
      "authors": [
        "Georgy Andryushchenko",
        "Vladimir Ivanov",
        "Vladimir Makharev",
        "Elizaveta Tukhtina",
        "Aidar Valeev"
      ],
      "abstract": "Question answering over source code provides software engineers and project\nmanagers with helpful information about the implemented features of a software\nproduct. This paper presents a work devoted to using large language models for\nquestion answering over source code in Python. The proposed method for\nimplementing a source code question answering system involves fine-tuning a\nlarge language model on a unified dataset of questions and answers for Python\ncode. To achieve the highest quality answers, we tested various models trained\non datasets preprocessed in different ways: a dataset without grammar\ncorrection, a dataset with grammar correction, and a dataset augmented with the\ngenerated summaries. The model answers were also analyzed for errors manually.\nWe report BLEU-4, BERTScore F1, BLEURT, and Exact Match metric values, along\nwith the conclusions from the manual error analysis. The obtained experimental\nresults highlight the current problems of the research area, such as poor\nquality of the public genuine question-answering datasets. In addition, the\nfindings include the positive effect of the grammar correction of the training\ndata on the testing metric values. The addressed findings and issues could be\nimportant for other researchers who attempt to improve the quality of source\ncode question answering solutions. The training and evaluation code is publicly\navailable at https://github.com/IU-AES-AI4Code/CodeQuestionAnswering.",
      "tldr_zh": "本研究探讨了利用Large Language Models (LLMs) 进行Python代码问答的方法，提出通过在统一数据集上微调LLMs来构建问答系统，并测试了不同数据预处理方式（如无语法修正、语法修正和添加生成摘要）的效果。实验评估使用BLEU-4、BERTScore F1、BLEURT和Exact Match等指标，结果显示语法修正能显著提升模型性能，但公共数据集质量差等问题是当前领域的关键挑战。作者通过手动错误分析总结了这些发现，并公开了训练和评估代码（https://github.com/IU-AES-AI4Code/CodeQuestionAnswering），以帮助其他研究者改进代码问答解决方案。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "15 pages, 3 figures, Accepted to NLP (CCIS) @ AIST'24",
      "pdf_url": "http://arxiv.org/pdf/2411.03012v1",
      "published_date": "2024-11-05 11:25:12 UTC",
      "updated_date": "2024-11-05 11:25:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:35:30.159672"
    },
    {
      "arxiv_id": "2411.03008v1",
      "title": "Hierarchical Orchestra of Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas P Cannon",
        "Özgür Simsek"
      ],
      "abstract": "Continual reinforcement learning poses a major challenge due to the tendency\nof agents to experience catastrophic forgetting when learning sequential tasks.\nIn this paper, we introduce a modularity-based approach, called Hierarchical\nOrchestra of Policies (HOP), designed to mitigate catastrophic forgetting in\nlifelong reinforcement learning. HOP dynamically forms a hierarchy of policies\nbased on a similarity metric between the current observations and previously\nencountered observations in successful tasks. Unlike other state-of-the-art\nmethods, HOP does not require task labelling, allowing for robust adaptation in\nenvironments where boundaries between tasks are ambiguous. Our experiments,\nconducted across multiple tasks in a procedurally generated suite of\nenvironments, demonstrate that HOP significantly outperforms baseline methods\nin retaining knowledge across tasks and performs comparably to state-of-the-art\ntransfer methods that require task labelling. Moreover, HOP achieves this\nwithout compromising performance when tasks remain constant, highlighting its\nversatility.",
      "tldr_zh": "本文针对持续强化学习（continual reinforcement learning）中代理学习连续任务时易发生的灾难性遗忘（catastrophic forgetting）问题，提出 Hierarchical Orchestra of Policies (HOP) 方法，该方法通过基于观察相似性的动态策略层次结构来组织和适应任务。HOP 不依赖任务标签（task labelling），使其适用于任务边界模糊的环境，并展示了更高的灵活性和鲁棒性。在多任务程序生成环境中，实验结果表明 HOP 显著优于基线方法，在知识保留方面与需要任务标签的先进转移方法相当，同时在任务不变时保持了出色性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted as a poster. NeurIPS IMOL",
      "pdf_url": "http://arxiv.org/pdf/2411.03008v1",
      "published_date": "2024-11-05 11:13:09 UTC",
      "updated_date": "2024-11-05 11:13:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:35:42.997755"
    },
    {
      "arxiv_id": "2411.03007v1",
      "title": "Data Quality Awareness: A Journey from Traditional Data Management to Data Science Systems",
      "title_zh": "数据质量意识：从传统数据管理到数据科学系统的旅程",
      "authors": [
        "Sijie Dong",
        "Soror Sahri",
        "Themis Palpanas"
      ],
      "abstract": "Artificial intelligence (AI) has transformed various fields, significantly\nimpacting our daily lives. A major factor in AI success is high-quality data.\nIn this paper, we present a comprehensive review of the evolution of data\nquality (DQ) awareness from traditional data management systems to modern\ndata-driven AI systems, which are integral to data science. We synthesize the\nexisting literature, highlighting the quality challenges and techniques that\nhave evolved from traditional data management to data science including big\ndata and ML fields. As data science systems support a wide range of activities,\nour focus in this paper lies specifically in the analytics aspect driven by\nmachine learning. We use the cause-effect connection between the quality\nchallenges of ML and those of big data to allow a more thorough understanding\nof emerging DQ challenges and the related quality awareness techniques in data\nscience systems. To the best of our knowledge, our paper is the first to\nprovide a review of DQ awareness spanning traditional and emergent data science\nsystems. We hope that readers will find this journey through the evolution of\ndata quality awareness insightful and valuable.",
      "tldr_zh": "这篇论文综述了数据质量 (DQ) 意识从传统数据管理系统向现代数据驱动 AI 系统的演变，强调高质量数据在 AI 成功中的关键作用。作者通过合成现有文献，分析了从传统数据管理到大数据和 Machine Learning (ML) 领域的质量挑战和技术，并利用大数据和 ML 之间因果关系来深入探讨新兴 DQ 挑战及相关意识技术。该研究聚焦于数据科学系统中由 ML 驱动的分析方面，并声称这是首篇全面回顾传统与新兴系统的 DQ 意识综述，为读者提供宝贵的洞见和价值。",
      "categories": [
        "cs.DB",
        "cs.AI"
      ],
      "primary_category": "cs.DB",
      "comment": "12 pages",
      "pdf_url": "http://arxiv.org/pdf/2411.03007v1",
      "published_date": "2024-11-05 11:12:25 UTC",
      "updated_date": "2024-11-05 11:12:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:35:55.525039"
    },
    {
      "arxiv_id": "2411.03004v1",
      "title": "Controlling for Unobserved Confounding with Large Language Model Classification of Patient Smoking Status",
      "title_zh": "通过大型语言模型对患者吸烟状态分类控制未观测混杂因素",
      "authors": [
        "Samuel Lee",
        "Zach Wood-Doughty"
      ],
      "abstract": "Causal understanding is a fundamental goal of evidence-based medicine. When\nrandomization is impossible, causal inference methods allow the estimation of\ntreatment effects from retrospective analysis of observational data. However,\nsuch analyses rely on a number of assumptions, often including that of no\nunobserved confounding. In many practical settings, this assumption is violated\nwhen important variables are not explicitly measured in the clinical record.\nPrior work has proposed to address unobserved confounding with machine learning\nby imputing unobserved variables and then correcting for the classifier's\nmismeasurement. When such a classifier can be trained and the necessary\nassumptions are met, this method can recover an unbiased estimate of a causal\neffect. However, such work has been limited to synthetic data, simple\nclassifiers, and binary variables. This paper extends this methodology by using\na large language model trained on clinical notes to predict patients' smoking\nstatus, which would otherwise be an unobserved confounder. We then apply a\nmeasurement error correction on the categorical predicted smoking status to\nestimate the causal effect of transthoracic echocardiography on mortality in\nthe MIMIC dataset.",
      "tldr_zh": "本研究针对因果推断（causal inference）中未观察混杂（unobserved confounding）的挑战，使用大型语言模型（Large Language Model）从临床笔记中分类患者吸烟状态，以作为未记录的混杂变量。该方法扩展了先前工作，通过预测吸烟状态并应用测量错误修正（measurement error correction），在MIMIC数据集上估计了经胸超声心动图（transthoracic echocardiography）对死亡率（mortality）的因果效果。结果表明，这种方法能提供更准确的治疗效果估计，提升了证据-based医学的可靠性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Advancements In Medical Foundation Models: Explainability,\n  Robustness, Security, and Beyond (AIM-FM) at NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03004v1",
      "published_date": "2024-11-05 11:05:53 UTC",
      "updated_date": "2024-11-05 11:05:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:36:07.959834"
    },
    {
      "arxiv_id": "2411.02998v3",
      "title": "Accelerating Task Generalisation with Multi-Level Skill Hierarchies",
      "title_zh": "翻译失败",
      "authors": [
        "Thomas P Cannon",
        "Özgür Simsek"
      ],
      "abstract": "Creating reinforcement learning agents that generalise effectively to new\ntasks is a key challenge in AI research. This paper introduces Fracture Cluster\nOptions (FraCOs), a multi-level hierarchical reinforcement learning method that\nachieves state-of-the-art performance on difficult generalisation tasks. FraCOs\nidentifies patterns in agent behaviour and forms options based on the expected\nfuture usefulness of those patterns, enabling rapid adaptation to new tasks. In\ntabular settings, FraCOs demonstrates effective transfer and improves\nperformance as it grows in hierarchical depth. We evaluate FraCOs against\nstate-of-the-art deep reinforcement learning algorithms in several complex\nprocedurally generated environments. Our results show that FraCOs achieves\nhigher in-distribution and out-of-distribution performance than competitors.",
      "tldr_zh": "该研究提出了一种名为 Fracture Cluster Options (FraCOs) 的多级层次强化学习方法，旨在加速强化学习代理在新任务上的泛化能力。FraCOs 通过识别代理行为的模式并基于这些模式的预期未来有用性形成选项(options)，从而实现快速适应和有效转移学习。在实验中，FraCOs 在表格设置和复杂程序生成环境中表现出色，比最先进的深度强化学习算法在分布内和分布外性能上更优。",
      "categories": [
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "10 pages, accepted at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.02998v3",
      "published_date": "2024-11-05 11:00:09 UTC",
      "updated_date": "2025-03-30 10:36:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:36:18.417774"
    },
    {
      "arxiv_id": "2411.02995v1",
      "title": "SUDS: A Strategy for Unsupervised Drift Sampling",
      "title_zh": "SUDS: 一种无监督漂移采样的策略",
      "authors": [
        "Christofer Fellicious",
        "Lorenz Wendlinger",
        "Mario Gancarski",
        "Jelena Mitrovic",
        "Michael Granitzer"
      ],
      "abstract": "Supervised machine learning often encounters concept drift, where the data\ndistribution changes over time, degrading model performance. Existing drift\ndetection methods focus on identifying these shifts but often overlook the\nchallenge of acquiring labeled data for model retraining after a shift occurs.\nWe present the Strategy for Drift Sampling (SUDS), a novel method that selects\nhomogeneous samples for retraining using existing drift detection algorithms,\nthereby enhancing model adaptability to evolving data. SUDS seamlessly\nintegrates with current drift detection techniques. We also introduce the\nHarmonized Annotated Data Accuracy Metric (HADAM), a metric that evaluates\nclassifier performance in relation to the quantity of annotated data required\nto achieve the stated performance, thereby taking into account the difficulty\nof acquiring labeled data. Our contributions are twofold: SUDS combines drift\ndetection with strategic sampling to improve the retraining process, and HADAM\nprovides a metric that balances classifier performance with the amount of\nlabeled data, ensuring efficient resource utilization. Empirical results\ndemonstrate the efficacy of SUDS in optimizing labeled data use in dynamic\nenvironments, significantly improving the performance of machine learning\napplications in real-world scenarios. Our code is open source and available at\nhttps://github.com/cfellicious/SUDS/",
      "tldr_zh": "该论文针对监督机器学习中的 concept drift 问题提出了一种新策略 SUDS（Strategy for Unsupervised Drift Sampling），它利用现有的漂移检测算法选择同质样本进行模型重新训练，从而提升模型对数据分布变化的适应性。SUDS 可以无缝集成到当前检测技术中，同时引入 HADAM（Harmonized Annotated Data Accuracy Metric）指标来评估分类器性能，并考虑标注数据获取的难度，以优化资源利用。实验结果显示，SUDS 在动态环境中显著提高了机器学习应用的性能，并高效降低了标注数据的需求；代码已开源。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "9 pages, 5 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.02995v1",
      "published_date": "2024-11-05 10:55:29 UTC",
      "updated_date": "2024-11-05 10:55:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:36:30.836651"
    },
    {
      "arxiv_id": "2411.02988v2",
      "title": "Confidence Calibration of Classifiers with Many Classes",
      "title_zh": "多类分类器的置信度校准",
      "authors": [
        "Adrien LeCoz",
        "Stéphane Herbin",
        "Faouzi Adjed"
      ],
      "abstract": "For classification models based on neural networks, the maximum predicted\nclass probability is often used as a confidence score. This score rarely\npredicts well the probability of making a correct prediction and requires a\npost-processing calibration step. However, many confidence calibration methods\nfail for problems with many classes. To address this issue, we transform the\nproblem of calibrating a multiclass classifier into calibrating a single\nsurrogate binary classifier. This approach allows for more efficient use of\nstandard calibration methods. We evaluate our approach on numerous neural\nnetworks used for image or text classification and show that it significantly\nenhances existing calibration methods.",
      "tldr_zh": "本论文针对神经网络分类模型的置信度校准(confidence calibration)问题，指出现有方法在多类场景下往往失败，因为最大预测类概率无法准确反映正确预测的概率。研究提出一种创新方法，将多类分类器的校准问题转化为校准一个单一的代理二元分类器(surrogate binary classifier)，从而更高效地利用标准校准技术。在图像和文本分类的神经网络上进行评估，结果显示该方法显著提升了现有校准方法的性能。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "NeurIPS 2024; code available at\n  https://github.com/allglc/tva-calibration",
      "pdf_url": "http://arxiv.org/pdf/2411.02988v2",
      "published_date": "2024-11-05 10:51:01 UTC",
      "updated_date": "2024-11-06 10:08:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:36:42.751767"
    },
    {
      "arxiv_id": "2411.02983v1",
      "title": "Autonomous Decision Making for UAV Cooperative Pursuit-Evasion Game with Reinforcement Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Yang Zhao",
        "Zidong Nie",
        "Kangsheng Dong",
        "Qinghua Huang",
        "Xuelong Li"
      ],
      "abstract": "The application of intelligent decision-making in unmanned aerial vehicle\n(UAV) is increasing, and with the development of UAV 1v1 pursuit-evasion game,\nmulti-UAV cooperative game has emerged as a new challenge. This paper proposes\na deep reinforcement learning-based model for decision-making in multi-role UAV\ncooperative pursuit-evasion game, to address the challenge of enabling UAV to\nautonomously make decisions in complex game environments. In order to enhance\nthe training efficiency of the reinforcement learning algorithm in UAV\npursuit-evasion game environment that has high-dimensional state-action space,\nthis paper proposes multi-environment asynchronous double deep Q-network with\npriority experience replay algorithm to effectively train the UAV's game\npolicy. Furthermore, aiming to improve cooperation ability and task completion\nefficiency, as well as minimize the cost of UAVs in the pursuit-evasion game,\nthis paper focuses on the allocation of roles and targets within multi-UAV\nenvironment. The cooperative game decision model with varying numbers of UAVs\nare obtained by assigning diverse tasks and roles to the UAVs in different\nscenarios. The simulation results demonstrate that the proposed method enables\nautonomous decision-making of the UAVs in pursuit-evasion game scenarios and\nexhibits significant capabilities in cooperation.",
      "tldr_zh": "这篇论文提出了一种基于深度强化学习的模型，用于无人机（UAV）在多角色合作追逐-逃避游戏中的自主决策，旨在解决复杂环境下的决策挑战。模型引入了多环境异步双深 Q 网络（multi-environment asynchronous double deep Q-network）结合优先经验回放（priority experience replay）算法，以提升训练效率，并通过角色和目标分配优化UAV的合作能力、任务完成效率和成本最小化。模拟结果表明，该方法使UAV能够在不同场景下实现有效的自主决策，并显著提升合作性能。",
      "categories": [
        "cs.AI",
        "cs.MA",
        "cs.RO",
        "I.2.6; I.2.8"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 12 figures, 31 conference",
      "pdf_url": "http://arxiv.org/pdf/2411.02983v1",
      "published_date": "2024-11-05 10:45:30 UTC",
      "updated_date": "2024-11-05 10:45:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:36:55.086577"
    },
    {
      "arxiv_id": "2411.02974v3",
      "title": "Region-Guided Attack on the Segment Anything Model (SAM)",
      "title_zh": "针对 Segment Anything Model (SAM) 的区域引导攻击",
      "authors": [
        "Xiaoliang Liu",
        "Furao Shen",
        "Jian Zhao"
      ],
      "abstract": "The Segment Anything Model (SAM) is a cornerstone of image segmentation,\ndemonstrating exceptional performance across various applications, particularly\nin autonomous driving and medical imaging, where precise segmentation is\ncrucial. However, SAM is vulnerable to adversarial attacks that can\nsignificantly impair its functionality through minor input perturbations.\nTraditional techniques, such as FGSM and PGD, are often ineffective in\nsegmentation tasks due to their reliance on global perturbations that overlook\nspatial nuances. Recent methods like Attack-SAM-K and UAD have begun to address\nthese challenges, but they frequently depend on external cues and do not fully\nleverage the structural interdependencies within segmentation processes. This\nlimitation underscores the need for a novel adversarial strategy that exploits\nthe unique characteristics of segmentation tasks. In response, we introduce the\nRegion-Guided Attack (RGA), designed specifically for SAM. RGA utilizes a\nRegion-Guided Map (RGM) to manipulate segmented regions, enabling targeted\nperturbations that fragment large segments and expand smaller ones, resulting\nin erroneous outputs from SAM. Our experiments demonstrate that RGA achieves\nhigh success rates in both white-box and black-box scenarios, emphasizing the\nneed for robust defenses against such sophisticated attacks. RGA not only\nreveals SAM's vulnerabilities but also lays the groundwork for developing more\nresilient defenses against adversarial threats in image segmentation.",
      "tldr_zh": "Segment Anything Model (SAM) 在图像分割领域表现出色，尤其在自动驾驶和医疗成像中，但容易受到对抗性攻击的影响，传统方法如 FGSM 和 PGD 因忽略空间细微差别而效果有限。论文提出 Region-Guided Attack (RGA)，通过 Region-Guided Map (RGM) 针对性地操纵分割区域，导致大区域碎片化和小区域扩展，从而使 SAM 输出错误。实验结果显示，RGA 在白盒和黑盒场景下均实现高成功率，这不仅暴露了 SAM 的漏洞，还为开发更强健的对抗防御奠定基础。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02974v3",
      "published_date": "2024-11-05 10:21:21 UTC",
      "updated_date": "2025-01-02 02:37:12 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:37:07.343226"
    },
    {
      "arxiv_id": "2411.02973v1",
      "title": "[Vision Paper] PRObot: Enhancing Patient-Reported Outcome Measures for Diabetic Retinopathy using Chatbots and Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Maren Pielka",
        "Tobias Schneider",
        "Jan Terheyden",
        "Rafet Sifa"
      ],
      "abstract": "We present an outline of the first large language model (LLM) based chatbot\napplication in the context of patient-reported outcome measures (PROMs) for\ndiabetic retinopathy. By utilizing the capabilities of current LLMs, we enable\npatients to provide feedback about their quality of life and treatment progress\nvia an interactive application. The proposed framework offers significant\nadvantages over the current approach, which encompasses only qualitative\ncollection of survey data or a static survey with limited answer options. Using\nthe PROBot LLM-PROM application, patients will be asked tailored questions\nabout their individual challenges, and can give more detailed feedback on the\nprogress of their treatment. Based on this input, we will use machine learning\nto infer conventional PROM scores, which can be used by clinicians to evaluate\nthe treatment status. The goal of the application is to improve adherence to\nthe healthcare system and treatments, and thus ultimately reduce cases of\nsubsequent vision impairment. The approach needs to be further validated using\na survey and a clinical study.",
      "tldr_zh": "本研究介绍了 PRObot，一种基于大语言模型 (LLM) 的聊天机器人应用，用于增强糖尿病视网膜病变的患者报告结局测量 (PROMs)。该框架允许患者通过交互式问题提供更详细的反馈，包括生活质量和治疗进展，从而克服传统静态调查的局限性，并利用机器学习推断常规 PROM 分数以辅助临床评估。相比现有方法，PRObot 旨在提高患者对医疗系统的依从性，最终减少视力损伤病例，但仍需通过调查和临床研究进一步验证。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02973v1",
      "published_date": "2024-11-05 10:18:53 UTC",
      "updated_date": "2024-11-05 10:18:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:37:18.565964"
    },
    {
      "arxiv_id": "2411.02964v2",
      "title": "Speaker Emotion Recognition: Leveraging Self-Supervised Models for Feature Extraction Using Wav2Vec2 and HuBERT",
      "title_zh": "说话者情感识别：利用自监督模型 Wav",
      "authors": [
        "Pourya Jafarzadeh",
        "Amir Mohammad Rostami",
        "Padideh Choobdar"
      ],
      "abstract": "Speech is the most natural way of expressing ourselves as humans. Identifying\nemotion from speech is a nontrivial task due to the ambiguous definition of\nemotion itself. Speaker Emotion Recognition (SER) is essential for\nunderstanding human emotional behavior. The SER task is challenging due to the\nvariety of speakers, background noise, complexity of emotions, and speaking\nstyles. It has many applications in education, healthcare, customer service,\nand Human-Computer Interaction (HCI). Previously, conventional machine learning\nmethods such as SVM, HMM, and KNN have been used for the SER task. In recent\nyears, deep learning methods have become popular, with convolutional neural\nnetworks and recurrent neural networks being used for SER tasks. The input of\nthese methods is mostly spectrograms and hand-crafted features. In this work,\nwe study the use of self-supervised transformer-based models, Wav2Vec2 and\nHuBERT, to determine the emotion of speakers from their voice. The models\nautomatically extract features from raw audio signals, which are then used for\nthe classification task. The proposed solution is evaluated on reputable\ndatasets, including RAVDESS, SHEMO, SAVEE, AESDD, and Emo-DB. The results show\nthe effectiveness of the proposed method on different datasets. Moreover, the\nmodel has been used for real-world applications like call center conversations,\nand the results demonstrate that the model accurately predicts emotions.",
      "tldr_zh": "该论文探讨了说话者情绪识别（SER），强调了从语音中识别情绪的挑战，包括说话者多样性、背景噪音和情绪复杂性。作者利用自监督Transformer模型Wav2Vec2和HuBERT，从原始音频信号自动提取特征，并应用于情绪分类任务。实验在RAVDESS、SHEMO、SAVEE、AESDD和Emo-DB数据集上验证了方法的有效性，并在真实场景如呼叫中心对话中实现了准确的情绪预测，展示了其在教育、医疗和HCI领域的潜力。",
      "categories": [
        "cs.SD",
        "cs.AI",
        "cs.LG",
        "eess.AS"
      ],
      "primary_category": "cs.SD",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02964v2",
      "published_date": "2024-11-05 10:06:40 UTC",
      "updated_date": "2024-11-06 14:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:37:31.248832"
    },
    {
      "arxiv_id": "2411.05028v1",
      "title": "Leveraging Transfer Learning and Multiple Instance Learning for HER2 Automatic Scoring of H\\&E Whole Slide Images",
      "title_zh": "利用迁移学习和多实例学习对 HER2 的 H&E 全滑片图像进行自动评分",
      "authors": [
        "Rawan S. Abdulsadig",
        "Bryan M. Williams",
        "Nikolay Burlutskiy"
      ],
      "abstract": "Expression of human epidermal growth factor receptor 2 (HER2) is an important\nbiomarker in breast cancer patients who can benefit from cost-effective\nautomatic Hematoxylin and Eosin (H\\&E) HER2 scoring. However, developing such\nscoring models requires large pixel-level annotated datasets. Transfer learning\nallows prior knowledge from different datasets to be reused while\nmultiple-instance learning (MIL) allows the lack of detailed annotations to be\nmitigated. The aim of this work is to examine the potential of transfer\nlearning on the performance of deep learning models pre-trained on (i)\nImmunohistochemistry (IHC) images, (ii) H\\&E images and (iii) non-medical\nimages. A MIL framework with an attention mechanism is developed using\npre-trained models as patch-embedding models. It was found that embedding\nmodels pre-trained on H\\&E images consistently outperformed the others,\nresulting in an average AUC-ROC value of $0.622$ across the 4 HER2 scores\n($0.59-0.80$ per HER2 score). Furthermore, it was found that using\nmultiple-instance learning with an attention layer not only allows for good\nclassification results to be achieved, but it can also help with producing\nvisual indication of HER2-positive areas in the H\\&E slide image by utilising\nthe patch-wise attention weights.",
      "tldr_zh": "本研究利用转移学习（Transfer Learning）和多实例学习（Multiple Instance Learning, MIL）来实现 Hematoxylin and Eosin (H&E) 全滑玻图像中 HER2 表达的自动评分，旨在为乳腺癌患者提供经济有效的生物标志物评估，同时缓解像素级标注数据集的需求。研究开发了一个基于注意力机制的 MIL 框架，使用预训练模型作为 patch-embedding 模型，并比较了在 Immunohistochemistry (IHC) 图像、H&E 图像和非医疗图像上预训练的模型。结果显示，在 H&E 图像上预训练的模型表现最佳，平均 AUC-ROC 值达 0.622（每个 HER2 评分范围 0.59-0.80），且框架能通过 patch-wise 注意力权重可视化 HER2 阳性区域，从而提升分类准确性和临床实用性。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "q-bio.QM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05028v1",
      "published_date": "2024-11-05 09:44:48 UTC",
      "updated_date": "2024-11-05 09:44:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:37:43.404869"
    },
    {
      "arxiv_id": "2411.02941v1",
      "title": "A Mamba Foundation Model for Time Series Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Haoyu Ma",
        "Yushu Chen",
        "Wenlai Zhao",
        "Jinzhe Yang",
        "Yingsheng Ji",
        "Xinghua Xu",
        "Xiaozhu Liu",
        "Hao Jing",
        "Shengzhuo Liu",
        "Guangwen Yang"
      ],
      "abstract": "Time series foundation models have demonstrated strong performance in\nzero-shot learning, making them well-suited for predicting rapidly evolving\npatterns in real-world applications where relevant training data are scarce.\nHowever, most of these models rely on the Transformer architecture, which\nincurs quadratic complexity as input length increases. To address this, we\nintroduce TSMamba, a linear-complexity foundation model for time series\nforecasting built on the Mamba architecture. The model captures temporal\ndependencies through both forward and backward Mamba encoders, achieving high\nprediction accuracy. To reduce reliance on large datasets and lower training\ncosts, TSMamba employs a two-stage transfer learning process that leverages\npretrained Mamba LLMs, allowing effective time series modeling with a moderate\ntraining set. In the first stage, the forward and backward backbones are\noptimized via patch-wise autoregressive prediction; in the second stage, the\nmodel trains a prediction head and refines other components for long-term\nforecasting. While the backbone assumes channel independence to manage varying\nchannel numbers across datasets, a channel-wise compressed attention module is\nintroduced to capture cross-channel dependencies during fine-tuning on specific\nmultivariate datasets. Experiments show that TSMamba's zero-shot performance is\ncomparable to state-of-the-art time series foundation models, despite using\nsignificantly less training data. It also achieves competitive or superior\nfull-shot performance compared to task-specific prediction models. The code\nwill be made publicly available.",
      "tldr_zh": "本研究提出 TSMamba，一种基于 Mamba 架构的线性复杂度时间序列预测基础模型，以解决 Transformer 模型的二次复杂度问题，并提升零样本学习性能。TSMamba 通过前向和后向 Mamba 编码器捕获时间依赖性，并采用两阶段转移学习过程：第一阶段优化骨干网络 via patch-wise 自回归预测，第二阶段训练预测头并引入 channel-wise compressed attention 模块以处理跨通道依赖，从而减少对大型数据集的依赖。实验结果显示，TSMamba 的零样本性能与最先进模型相当，但使用显著更少的数据，同时在全样本任务中实现与任务特定模型竞争或优于它们的预测准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02941v1",
      "published_date": "2024-11-05 09:34:05 UTC",
      "updated_date": "2024-11-05 09:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:37:56.033948"
    },
    {
      "arxiv_id": "2411.02939v1",
      "title": "A Post-Training Enhanced Optimization Approach for Small Language Models",
      "title_zh": "一种针对小型语言模型的后训练增强优化方法",
      "authors": [
        "Keke Zhai"
      ],
      "abstract": "This paper delves into the continuous post-training optimization methods for\nsmall language models, and proposes a continuous post-training alignment data\nconstruction method for small language models. The core of this method is based\non the data guidance of large models, optimizing the diversity and accuracy of\nalignment data. In addition, to verify the effectiveness of the methods in this\npaper, we used Qwen2-0.5B-Instruct model as the baseline model for small\nlanguage models, using the alignment dataset constructed by our proposed\nmethod, we trained and compared several groups of experiments, including SFT\n(Supervised Fine Tuning) post-training experiment and KTO (Kahneman Tversky\noptimization) post-training experiment, as well as SFT-KTO two-stage\npost-training experiment and model weight fusion experiment. Finally, we\nevaluated and analyzed the performance of post-training models, and confirmed\nthat the continuous post-training optimization method proposed by us can\nsignificantly improve the performance of small language models.",
      "tldr_zh": "本论文提出了一种针对小语言模型的持续后训练优化方法，核心是通过大模型数据指导构建多样性和准确的对齐数据，以提升模型性能。研究者使用 Qwen2-0.5B-Instruct 作为基线模型，进行了 SFT（Supervised Fine Tuning）、KTO（Kahneman-Tversky Optimization）、SFT-KTO 两阶段训练以及模型权重融合的实验组比较。结果显示，该方法显著提高了小语言模型的整体表现。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02939v1",
      "published_date": "2024-11-05 09:32:26 UTC",
      "updated_date": "2024-11-05 09:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:38:06.126134"
    },
    {
      "arxiv_id": "2411.02930v1",
      "title": "Textual Aesthetics in Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Lingjie Jiang",
        "Shaohan Huang",
        "Xun Wu",
        "Furu Wei"
      ],
      "abstract": "Image aesthetics is a crucial metric in the field of image generation.\nHowever, textual aesthetics has not been sufficiently explored. With the\nwidespread application of large language models (LLMs), previous work has\nprimarily focused on the correctness of content and the helpfulness of\nresponses. Nonetheless, providing responses with textual aesthetics is also an\nimportant factor for LLMs, which can offer a cleaner layout and ensure greater\nconsistency and coherence in content. In this work, we introduce a pipeline for\naesthetics polishing and help construct a textual aesthetics dataset named\nTexAes. We propose a textual aesthetics-powered fine-tuning method based on\ndirect preference optimization, termed TAPO, which leverages textual aesthetics\nwithout compromising content correctness. Additionally, we develop two\nevaluation methods for textual aesthetics based on text and image analysis,\nrespectively. Our experiments demonstrate that using textual aesthetics data\nand employing the TAPO fine-tuning method not only improves aesthetic scores\nbut also enhances performance on general evaluation datasets such as\nAlpacalEval and Anera-hard.",
      "tldr_zh": "这项研究探讨了大型语言模型（LLMs）中文本美学的概念，强调它能提升响应的一致性、连贯性和布局整洁性，但以往工作主要关注内容正确性和实用性。作者构建了名为TexAes的文本美学数据集，并提出了一种基于直接偏好优化的细调方法（TAPO），能够在不牺牲内容正确性的前提下优化文本美学。实验结果显示，使用TexAes数据和TAPO方法不仅提高了美学评分，还提升了在AlpacaEval和Anera-hard等通用评估数据集上的整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02930v1",
      "published_date": "2024-11-05 09:22:08 UTC",
      "updated_date": "2024-11-05 09:22:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:40:12.592964"
    },
    {
      "arxiv_id": "2411.02920v1",
      "title": "Domain Expansion and Boundary Growth for Open-Set Single-Source Domain Generalization",
      "title_zh": "开放集单源域泛化的领域扩展和边界增长",
      "authors": [
        "Pengkun Jiao",
        "Na Zhao",
        "Jingjing Chen",
        "Yu-Gang Jiang"
      ],
      "abstract": "Open-set single-source domain generalization aims to use a single-source\ndomain to learn a robust model that can be generalized to unknown target\ndomains with both domain shifts and label shifts. The scarcity of the source\ndomain and the unknown data distribution of the target domain pose a great\nchallenge for domain-invariant feature learning and unknown class recognition.\nIn this paper, we propose a novel learning approach based on domain expansion\nand boundary growth to expand the scarce source samples and enlarge the\nboundaries across the known classes that indirectly broaden the boundary\nbetween the known and unknown classes. Specifically, we achieve domain\nexpansion by employing both background suppression and style augmentation on\nthe source data to synthesize new samples. Then we force the model to distill\nconsistent knowledge from the synthesized samples so that the model can learn\ndomain-invariant information. Furthermore, we realize boundary growth across\nclasses by using edge maps as an additional modality of samples when training\nmulti-binary classifiers. In this way, it enlarges the boundary between the\ninliers and outliers, and consequently improves the unknown class recognition\nduring open-set generalization. Extensive experiments show that our approach\ncan achieve significant improvements and reach state-of-the-art performance on\nseveral cross-domain image classification datasets.",
      "tldr_zh": "该论文针对 Open-set single-source domain generalization 问题，提出了一种新方法，利用单一源域学习鲁棒模型，以应对未知目标域的域移和标签移挑战。方法包括 domain expansion，通过背景抑制和风格增强合成新样本，并从中提炼一致知识以学习域不变信息；同时，通过 boundary growth 使用边缘图作为额外模态训练多二元分类器，扩大已知类和未知类边界，从而提升未知类识别能力。实验结果显示，该方法在多个跨域图像分类数据集上实现了显著改进，并达到了最先进性能。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "TMM 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.02920v1",
      "published_date": "2024-11-05 09:08:46 UTC",
      "updated_date": "2024-11-05 09:08:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:38:30.934101"
    },
    {
      "arxiv_id": "2411.02914v1",
      "title": "Exploring the Interplay Between Video Generation and World Models in Autonomous Driving: A Survey",
      "title_zh": "探索视频生成与世界模型在自动驾驶中的相互作用：一项综",
      "authors": [
        "Ao Fu",
        "Yi Zhou",
        "Tao Zhou",
        "Yi Yang",
        "Bojun Gao",
        "Qun Li",
        "Guobin Wu",
        "Ling Shao"
      ],
      "abstract": "World models and video generation are pivotal technologies in the domain of\nautonomous driving, each playing a critical role in enhancing the robustness\nand reliability of autonomous systems. World models, which simulate the\ndynamics of real-world environments, and video generation models, which produce\nrealistic video sequences, are increasingly being integrated to improve\nsituational awareness and decision-making capabilities in autonomous vehicles.\nThis paper investigates the relationship between these two technologies,\nfocusing on how their structural parallels, particularly in diffusion-based\nmodels, contribute to more accurate and coherent simulations of driving\nscenarios. We examine leading works such as JEPA, Genie, and Sora, which\nexemplify different approaches to world model design, thereby highlighting the\nlack of a universally accepted definition of world models. These diverse\ninterpretations underscore the field's evolving understanding of how world\nmodels can be optimized for various autonomous driving tasks. Furthermore, this\npaper discusses the key evaluation metrics employed in this domain, such as\nChamfer distance for 3D scene reconstruction and Fr\\'echet Inception Distance\n(FID) for assessing the quality of generated video content. By analyzing the\ninterplay between video generation and world models, this survey identifies\ncritical challenges and future research directions, emphasizing the potential\nof these technologies to jointly advance the performance of autonomous driving\nsystems. The findings presented in this paper aim to provide a comprehensive\nunderstanding of how the integration of video generation and world models can\ndrive innovation in the development of safer and more reliable autonomous\nvehicles.",
      "tldr_zh": "这篇调查论文探讨了视频生成和世界模型在自动驾驶领域的互动，强调两者如何通过模拟环境动态和生成真实视频序列来提升系统的 situational awareness 和 decision-making 能力。论文分析了基于扩散模型的结构相似性，并考察了 JEPA、Genie 和 Sora 等领先作品，突出了世界模型定义的多样性及其在不同任务中的优化潜力。同时，它讨论了关键评估指标如 Chamfer distance 和 Fréchet Inception Distance (FID)，并指出了整合这些技术的挑战和未来方向，以推动更安全可靠的自动驾驶系统创新。",
      "categories": [
        "cs.AI",
        "cs.CV",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02914v1",
      "published_date": "2024-11-05 08:58:35 UTC",
      "updated_date": "2024-11-05 08:58:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:38:42.757801"
    },
    {
      "arxiv_id": "2411.05825v1",
      "title": "SurfGNN: A robust surface-based prediction model with interpretability for coactivation maps of spatial and cortical features",
      "title_zh": "翻译失败",
      "authors": [
        "Zhuoshuo Li",
        "Jiong Zhang",
        "Youbing Zeng",
        "Jiaying Lin",
        "Dan Zhang",
        "Jianjia Zhang",
        "Duan Xu",
        "Hosung Kim",
        "Bingguang Liu",
        "Mengting Liu"
      ],
      "abstract": "Current brain surface-based prediction models often overlook the variability\nof regional attributes at the cortical feature level. While graph neural\nnetworks (GNNs) excel at capturing regional differences, they encounter\nchallenges when dealing with complex, high-density graph structures. In this\nwork, we consider the cortical surface mesh as a sparse graph and propose an\ninterpretable prediction model-Surface Graph Neural Network (SurfGNN). SurfGNN\nemploys topology-sampling learning (TSL) and region-specific learning (RSL)\nstructures to manage individual cortical features at both lower and higher\nscales of the surface mesh, effectively tackling the challenges posed by the\noverly abundant mesh nodes and addressing the issue of heterogeneity in\ncortical regions. Building on this, a novel score-weighted fusion (SWF) method\nis implemented to merge nodal representations associated with each cortical\nfeature for prediction. We apply our model to a neonatal brain age prediction\ntask using a dataset of harmonized MR images from 481 subjects (503 scans).\nSurfGNN outperforms all existing state-of-the-art methods, demonstrating an\nimprovement of at least 9.0% and achieving a mean absolute error (MAE) of\n0.827+0.056 in postmenstrual weeks. Furthermore, it generates feature-level\nactivation maps, indicating its capability to identify robust regional\nvariations in different morphometric contributions for prediction.",
      "tldr_zh": "该研究提出SurfGNN，一种基于图神经网络(GNNs)的鲁棒脑表面预测模型，将皮层表面网格视为稀疏图，并采用topology-sampling learning (TSL)和region-specific learning (RSL)结构来处理不同规模的网格节点异质性，同时使用score-weighted fusion (SWF)方法融合节点表示以提升预测准确性。  \n在利用481名受试者MRI数据的新生儿脑年龄预测任务中，SurfGNN优于现有方法至少9.0%，实现平均绝对误差(MAE)为0.827周。  \n此外，该模型能生成特征级激活图，有效识别不同形态学贡献的区域变异，提供更高的可解释性。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.CV",
        "J.3"
      ],
      "primary_category": "q-bio.NC",
      "comment": "15 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.05825v1",
      "published_date": "2024-11-05 08:39:53 UTC",
      "updated_date": "2024-11-05 08:39:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:40:23.327945"
    },
    {
      "arxiv_id": "2411.02902v1",
      "title": "Membership Inference Attacks against Large Vision-Language Models",
      "title_zh": "针对大型视觉语言模型的成员推断攻击",
      "authors": [
        "Zhan Li",
        "Yongtao Wu",
        "Yihang Chen",
        "Francesco Tonin",
        "Elias Abad Rocamora",
        "Volkan Cevher"
      ],
      "abstract": "Large vision-language models (VLLMs) exhibit promising capabilities for\nprocessing multi-modal tasks across various application scenarios. However,\ntheir emergence also raises significant data security concerns, given the\npotential inclusion of sensitive information, such as private photos and\nmedical records, in their training datasets. Detecting inappropriately used\ndata in VLLMs remains a critical and unresolved issue, mainly due to the lack\nof standardized datasets and suitable methodologies. In this study, we\nintroduce the first membership inference attack (MIA) benchmark tailored for\nvarious VLLMs to facilitate training data detection. Then, we propose a novel\nMIA pipeline specifically designed for token-level image detection. Lastly, we\npresent a new metric called MaxR\\'enyi-K%, which is based on the confidence of\nthe model output and applies to both text and image data. We believe that our\nwork can deepen the understanding and methodology of MIAs in the context of\nVLLMs. Our code and datasets are available at\nhttps://github.com/LIONS-EPFL/VL-MIA.",
      "tldr_zh": "这项研究探讨了大型视觉语言模型 (VLLMs) 在处理多模态任务时的潜力，同时强调了数据安全风险，因为训练数据可能包含敏感信息如私人照片或医疗记录。作者引入了第一个针对各种 VLLMs 的成员推理攻击 (MIA) 基准，以便检测不当使用的训练数据。研究还提出了一种新型 MIA 管道，专门用于 token-level 图像检测，并开发了新的 MaxRényi-K% 指标，基于模型输出置信度，适用于文本和图像数据。该工作加深了对 VLLMs 中 MIA 的理解，并提供了开源代码和数据集以促进进一步研究。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.CL",
        "cs.CR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.02902v1",
      "published_date": "2024-11-05 08:35:08 UTC",
      "updated_date": "2024-11-05 08:35:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:40:35.941780"
    },
    {
      "arxiv_id": "2411.02886v2",
      "title": "TokenSelect: Efficient Long-Context Inference and Length Extrapolation for LLMs via Dynamic Token-Level KV Cache Selection",
      "title_zh": "翻译失败",
      "authors": [
        "Wei Wu",
        "Zhuoshi Pan",
        "Chao Wang",
        "Liyi Chen",
        "Yunchu Bai",
        "Tianfu Wang",
        "Kun Fu",
        "Zheng Wang",
        "Hui Xiong"
      ],
      "abstract": "The rapid advancement of Large Language Models (LLMs) has driven growing\ndemand for processing extended context sequences in contemporary applications.\nHowever, this progress faces two major challenges: performance degradation due\nto sequence lengths out-of-distribution, and excessively long inference times\ncaused by the quadratic computational complexity of attention. These issues\nhinder the application of LLMs in long-context scenarios. In this paper, we\npropose Dynamic Token-Level KV Cache Selection (TokenSelect), a training-free\nmethod for efficient and accurate long-context inference. TokenSelect builds\nupon the observation of non-contiguous attention sparsity, using Query-Key dot\nproducts to measure per-head KV Cache criticality at token-level. By per-head\nsoft voting mechanism, TokenSelect selectively involves a few critical KV cache\ntokens in attention calculation without sacrificing accuracy. To further\naccelerate TokenSelect, we design the Selection Cache based on observations of\nconsecutive Query similarity and implemented efficient dot product kernel,\nsignificantly reducing the overhead. A comprehensive evaluation of TokenSelect\ndemonstrates up to 23.84x speedup in attention computation and up to 2.28x\nacceleration in end-to-end latency, while providing superior performance\ncompared to state-of-the-art long-context inference methods.",
      "tldr_zh": "这篇论文针对大型语言模型（LLMs）在处理长上下文序列时面临的性能下降和注意力机制二次方计算复杂度问题，提出了TokenSelect方法——一个无需训练的动态token级KV Cache选择机制。TokenSelect基于非连续注意力稀疏性，通过Query-Key点积评估每个头的KV Cache关键性，并采用软投票机制选择性地参与关键tokens的注意力计算，从而维持准确性。论文还设计了Selection Cache，利用连续Query相似性和高效点积内核，进一步减少计算开销。实验结果显示，TokenSelect在注意力计算上实现高达23.84倍加速，在端到端延迟上提高2.28倍，且性能优于现有最先进方法。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02886v2",
      "published_date": "2024-11-05 07:56:24 UTC",
      "updated_date": "2025-03-03 05:49:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:40:48.049003"
    },
    {
      "arxiv_id": "2411.02867v2",
      "title": "AtlasSeg: Atlas Prior Guided Dual-U-Net for Cortical Segmentation in Fetal Brain MRI",
      "title_zh": "翻译失败",
      "authors": [
        "Haoan Xu",
        "Tianshu Zheng",
        "Xinyi Xu",
        "Yao Shen",
        "Jiwei Sun",
        "Cong Sun",
        "Guangbin Wang",
        "Zhaopeng Cui",
        "Dan Wu"
      ],
      "abstract": "Accurate automatic tissue segmentation in fetal brain MRI is a crucial step\nin clinical diagnosis but remains challenging, particularly due to the\ndynamically changing anatomy and tissue contrast during fetal development.\nExisting segmentation networks can only implicitly learn age-related features,\nleading to a decline in accuracy at extreme early or late gestational ages\n(GAs). To improve segmentation performance throughout gestation, we introduce\nAtlasSeg, a dual-U-shape convolution network that explicitly integrates\nGA-specific information as guidance. By providing a publicly available fetal\nbrain atlas with segmentation labels corresponding to relevant GAs, AtlasSeg\neffectively extracts age-specific patterns in the atlas branch and generates\nprecise tissue segmentation in the segmentation branch. Multi-scale spatial\nattention feature fusions are constructed during both encoding and decoding\nstages to enhance feature flow and facilitate better information interactions\nbetween two branches. We compared AtlasSeg with six well-established networks\nin a seven-tissue segmentation task, achieving the highest average Dice\nsimilarity coefficient of 0.91. The improvement was particularly evident in\nextreme early or late GA cases, where training data was scare. Furthermore,\nAtlasSeg exhibited minimal performance degradation on low-quality images with\ncontrast changes and noise, attributed to its anatomical shape priors. Overall,\nAtlasSeg demonstrated enhanced segmentation accuracy, better consistency across\nfetal ages, and robustness to perturbations, making it a powerful tool for\nreliable fetal brain MRI tissue segmentation, particularly suited for\ndiagnostic assessments during early gestation.",
      "tldr_zh": "该研究针对胎儿脑MRI中组织分割的挑战，提出AtlasSeg框架，该框架是一个基于Dual-U-Net的网络，通过显式整合孕周特定信息（GA-specific）作为指导来提升分割准确性。AtlasSeg利用公开的胎儿脑图谱（atlas）从图谱分支提取年龄相关模式，并在分割分支结合多尺度空间注意力特征融合，以增强编码和解码阶段的特征交互。实验结果显示，AtlasSeg在七组织分割任务中平均Dice相似系数达0.91，比六种基准网络表现更优，尤其在极早或极晚孕周（GAs）及低质量图像上显示出显著鲁棒性，从而为早期妊娠诊断提供可靠工具。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02867v2",
      "published_date": "2024-11-05 07:16:32 UTC",
      "updated_date": "2025-03-11 02:25:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:40:59.568126"
    },
    {
      "arxiv_id": "2411.02864v1",
      "title": "Graph-DPEP: Decomposed Plug and Ensemble Play for Few-Shot Document Relation Extraction with Graph-of-Thoughts Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Tao Zhang",
        "Ning Yan",
        "Masood Mortazavi",
        "Hoang H. Nguyen",
        "Zhongfen Deng",
        "Philip S. Yu"
      ],
      "abstract": "Large language models (LLMs) pre-trained on massive corpora have demonstrated\nimpressive few-shot learning capability on many NLP tasks. Recasting an NLP\ntask into a text-to-text generation task is a common practice so that\ngenerative LLMs can be prompted to resolve it. However, performing\ndocument-level relation extraction (DocRE) tasks with generative LLM models is\nstill challenging due to the structured output format of DocRE, which\ncomplicates the conversion to plain text. Limited information available in\nfew-shot samples and prompt instructions induce further difficulties and\nchallenges in relation extraction for mentioned entities in a document. In this\npaper, we represent the structured output as a graph-style triplet rather than\nnatural language expressions and leverage generative LLMs for the DocRE task.\nOur approach, the Graph-DPEP framework is grounded in the reasoning behind\ntriplet explanation thoughts presented in natural language. In this framework,\nwe first introduce a ``decomposed-plug\" method for performing the generation\nfrom LLMs over prompts with type-space decomposition to alleviate the burden of\ndistinguishing all relation types. Second, we employ a verifier for calibrating\nthe generation and identifying overlooked query entity pairs. Third, we develop\n\"ensemble-play\", reapplying generation on the entire type list by leveraging\nthe reasoning thoughts embedded in a sub-graph associated with the missing\nquery pair to address the missingness issue. Through extensive comparisons with\nexisting prompt techniques and alternative Language Models (LLMs), our\nframework demonstrates superior performance on publicly available benchmarks in\nexperiments.",
      "tldr_zh": "本研究提出Graph-DPEP框架，利用Graph-of-Thoughts Reasoning来提升大型语言模型(LLMs)在少样本文档关系提取(DocRE)任务中的性能，解决结构化输出和信息有限的挑战。框架通过“Decomposed-plug”方法分解类型空间减轻关系类型区分负担，结合Verifier校准生成并识别缺失实体对，以及“Ensemble-play”策略重新生成子图推理以处理遗漏问题。实验结果显示，该框架在公开基准上优于现有提示技术和LLMs基准，显著提高了DocRE的准确性和完整性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02864v1",
      "published_date": "2024-11-05 07:12:36 UTC",
      "updated_date": "2024-11-05 07:12:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:41:11.547763"
    },
    {
      "arxiv_id": "2411.03365v1",
      "title": "Enhanced Real-Time Threat Detection in 5G Networks: A Self-Attention RNN Autoencoder Approach for Spectral Intrusion Analysis",
      "title_zh": "在5G网络中增强的实时威胁检测：一种",
      "authors": [
        "Mohammadreza Kouchaki",
        "Minglong Zhang",
        "Aly S. Abdalla",
        "Guangchen Lan",
        "Christopher G. Brinton",
        "Vuk Marojevic"
      ],
      "abstract": "In the rapidly evolving landscape of 5G technology, safeguarding Radio\nFrequency (RF) environments against sophisticated intrusions is paramount,\nespecially in dynamic spectrum access and management. This paper presents an\nenhanced experimental model that integrates a self-attention mechanism with a\nRecurrent Neural Network (RNN)-based autoencoder for the detection of anomalous\nspectral activities in 5G networks at the waveform level. Our approach,\ngrounded in time-series analysis, processes in-phase and quadrature (I/Q)\nsamples to identify irregularities that could indicate potential jamming\nattacks. The model's architecture, augmented with a self-attention layer,\nextends the capabilities of RNN autoencoders, enabling a more nuanced\nunderstanding of temporal dependencies and contextual relationships within the\nRF spectrum. Utilizing a simulated 5G Radio Access Network (RAN) test-bed\nconstructed with srsRAN 5G and Software Defined Radios (SDRs), we generated a\ncomprehensive stream of data that reflects real-world RF spectrum conditions\nand attack scenarios. The model is trained to reconstruct standard signal\nbehavior, establishing a normative baseline against which deviations,\nindicative of security threats, are identified. The proposed architecture is\ndesigned to balance between detection precision and computational efficiency,\nso the LSTM network, enriched with self-attention, continues to optimize for\nminimal execution latency and power consumption. Conducted on a real-world\nSDR-based testbed, our results demonstrate the model's improved performance and\naccuracy in threat detection.\n  Keywords: self-attention, real-time intrusion detection, RNN autoencoder,\nTransformer architecture, LSTM, time series anomaly detection, 5G Security,\nspectrum access security.",
      "tldr_zh": "本论文提出了一种增强的自注意力(self-attention) RNN autoencoder 方法，用于在 5G 网络中实时检测光谱入侵，针对动态频谱访问中的异常活动如干扰攻击。该方法通过处理 I/Q 样本并整合自注意力层，扩展 RNN autoencoder 的能力，提升对时间序列依赖性和上下文关系的分析精度。在基于 srsRAN 5G 和 SDR 的模拟测试床上，实验结果显示该模型在威胁检测方面比基线方法准确性更高，同时平衡了检测精度与计算效率。关键贡献包括为 5G 安全提供可行的实时入侵检测框架。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.LG",
        "cs.NI"
      ],
      "primary_category": "cs.CR",
      "comment": "This article has been accepted for publication in WiOpt 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03365v1",
      "published_date": "2024-11-05 07:01:15 UTC",
      "updated_date": "2024-11-05 07:01:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:41:23.070963"
    },
    {
      "arxiv_id": "2411.02851v1",
      "title": "Learning to Unify Audio, Visual and Text for Audio-Enhanced Multilingual Visual Answer Localization",
      "title_zh": "翻译失败",
      "authors": [
        "Zhibin Wen",
        "Bin Li"
      ],
      "abstract": "The goal of Multilingual Visual Answer Localization (MVAL) is to locate a\nvideo segment that answers a given multilingual question. Existing methods\neither focus solely on visual modality or integrate visual and subtitle\nmodalities. However, these methods neglect the audio modality in videos,\nconsequently leading to incomplete input information and poor performance in\nthe MVAL task. In this paper, we propose a unified Audio-Visual-Textual Span\nLocalization (AVTSL) method that incorporates audio modality to augment both\nvisual and textual representations for the MVAL task. Specifically, we\nintegrate features from three modalities and develop three predictors, each\ntailored to the unique contributions of the fused modalities: an audio-visual\npredictor, a visual predictor, and a textual predictor. Each predictor\ngenerates predictions based on its respective modality. To maintain consistency\nacross the predicted results, we introduce an Audio-Visual-Textual Consistency\nmodule. This module utilizes a Dynamic Triangular Loss (DTL) function, allowing\neach modality's predictor to dynamically learn from the others. This\ncollaborative learning ensures that the model generates consistent and\ncomprehensive answers. Extensive experiments show that our proposed method\noutperforms several state-of-the-art (SOTA) methods, which demonstrates the\neffectiveness of the audio modality.",
      "tldr_zh": "这篇论文针对Multilingual Visual Answer Localization (MVAL)任务，提出了一种统一音频、视觉和文本模态的Audio-Visual-Textual Span Localization (AVTSL)方法，以解决现有方法忽略音频模态导致的信息不完整和性能不足的问题。具体而言，该方法整合三模态特征，开发了音频-视觉预测器、视觉预测器和文本预测器，并引入Audio-Visual-Textual Consistency模块，利用Dynamic Triangular Loss (DTL)函数实现预测结果的一致性和协作学习。实验结果显示，该方法在MVAL任务上超过了多种SOTA方法，证明了音频模态对提升视频段定位准确性的有效性。",
      "categories": [
        "cs.MM",
        "cs.AI",
        "cs.CL",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.MM",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02851v1",
      "published_date": "2024-11-05 06:49:14 UTC",
      "updated_date": "2024-11-05 06:49:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:41:36.406844"
    },
    {
      "arxiv_id": "2411.02850v2",
      "title": "WASHtsApp -- A RAG-powered WhatsApp Chatbot for supporting rural African clean water access, sanitation and hygiene",
      "title_zh": "翻译失败",
      "authors": [
        "Simon Kloker",
        "Alex Cedric Luyima",
        "Matthew Bazanya"
      ],
      "abstract": "This paper introduces WASHtsApp, a WhatsApp-based chatbot designed to educate\nrural African communities on clean water access, sanitation, and hygiene (WASH)\nprinciples. WASHtsApp leverages a Retrieval-Augmented Generation (RAG) approach\nto address the limitations of previous approaches with limited reach or missing\ncontextualization. The paper details the development process, employing Design\nScience Research Methodology. The evaluation consisted of two phases: content\nvalidation by four WASH experts and community validation by potential users.\nContent validation confirmed WASHtsApp's ability to provide accurate and\nrelevant WASH-related information. Community validation indicated high user\nacceptance and perceived usefulness of the chatbot. The paper concludes by\ndiscussing the potential for further development, including incorporating local\nlanguages and user data analysis for targeted interventions. It also proposes\nfuture research cycles focused on wider deployment and leveraging user data for\neducational purposes.",
      "tldr_zh": "本论文介绍了 WASHtsApp，一款基于 WhatsApp 的聊天机器人，利用 Retrieval-Augmented Generation (RAG) 技术来教育非洲农村社区关于清洁水获取、卫生和卫生（WASH）原则，从而解决以往方法的覆盖范围有限和上下文缺失问题。开发过程采用 Design Science Research Methodology，包括内容验证（由四位 WASH 专家确认信息的准确性和相关性）和社区验证（显示高用户接受度和感知有用性）。实验结果证明了该机器人的有效性，并提出未来方向，如整合本地语言、分析用户数据以进行针对性干预，以及扩大部署和利用数据进行教育研究。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "cs.HC",
        "cs.IR"
      ],
      "primary_category": "cs.CY",
      "comment": "Working Paper. Accepted at IST-Africa Conference 2025, Nairobi",
      "pdf_url": "http://arxiv.org/pdf/2411.02850v2",
      "published_date": "2024-11-05 06:44:15 UTC",
      "updated_date": "2025-02-18 10:43:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:41:46.931989"
    },
    {
      "arxiv_id": "2411.02847v3",
      "title": "Dissecting the Failure of Invariant Learning on Graphs",
      "title_zh": "剖析图上不变学习的失败",
      "authors": [
        "Qixun Wang",
        "Yifei Wang",
        "Yisen Wang",
        "Xianghua Ying"
      ],
      "abstract": "Enhancing node-level Out-Of-Distribution (OOD) generalization on graphs\nremains a crucial area of research. In this paper, we develop a Structural\nCausal Model (SCM) to theoretically dissect the performance of two prominent\ninvariant learning methods -- Invariant Risk Minimization (IRM) and\nVariance-Risk Extrapolation (VREx) -- in node-level OOD settings. Our analysis\nreveals a critical limitation: due to the lack of class-conditional invariance\nconstraints, these methods may struggle to accurately identify the structure of\nthe predictive invariant ego-graph and consequently rely on spurious features.\nTo address this, we propose Cross-environment Intra-class Alignment (CIA),\nwhich explicitly eliminates spurious features by aligning cross-environment\nrepresentations conditioned on the same class, bypassing the need for explicit\nknowledge of the causal pattern structure. To adapt CIA to node-level OOD\nscenarios where environment labels are hard to obtain, we further propose\nCIA-LRA (Localized Reweighting Alignment) that leverages the distribution of\nneighboring labels to selectively align node representations, effectively\ndistinguishing and preserving invariant features while removing spurious ones,\nall without relying on environment labels. We theoretically prove CIA-LRA's\neffectiveness by deriving an OOD generalization error bound based on\nPAC-Bayesian analysis. Experiments on graph OOD benchmarks validate the\nsuperiority of CIA and CIA-LRA, marking a significant advancement in node-level\nOOD generalization. The codes are available at\nhttps://github.com/NOVAglow646/NeurIPS24-Invariant-Learning-on-Graphs.",
      "tldr_zh": "本研究通过 Structural Causal Model (SCM) 分析了 Invariant Risk Minimization (IRM) 和 Variance-Risk Extrapolation (VREx) 在节点级 Out-Of-Distribution (OOD) 泛化上的失败原因，发现这些方法由于缺少 class-conditional invariance 约束，可能依赖于 spurious features，从而无法准确识别预测的 invariant ego-graph。针对这一问题，论文提出 Cross-environment Intra-class Alignment (CIA) 方法，通过对同一类的跨环境表示进行对齐来消除 spurious features；同时，引入 CIA-LRA (Localized Reweighting Alignment)，利用邻居标签分布选择性对齐节点表示，以适应环境标签难以获取的节点级 OOD 场景，并保留 invariant features。实验结果在图 OOD 基准上验证了 CIA 和 CIA-LRA 的优越性，并通过 PAC-Bayesian 分析理论证明了 CIA-LRA 的有效性，提供了一个更可靠的节点级 OOD 泛化框架。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02847v3",
      "published_date": "2024-11-05 06:36:48 UTC",
      "updated_date": "2025-01-03 10:55:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:41:59.870848"
    },
    {
      "arxiv_id": "2411.02844v1",
      "title": "Correlation of Object Detection Performance with Visual Saliency and Depth Estimation",
      "title_zh": "物体检测性能与视觉显著性和深度估计的相关性",
      "authors": [
        "Matthias Bartolo",
        "Dylan Seychell"
      ],
      "abstract": "As object detection techniques continue to evolve, understanding their\nrelationships with complementary visual tasks becomes crucial for optimising\nmodel architectures and computational resources. This paper investigates the\ncorrelations between object detection accuracy and two fundamental visual\ntasks: depth prediction and visual saliency prediction. Through comprehensive\nexperiments using state-of-the-art models (DeepGaze IIE, Depth Anything,\nDPT-Large, and Itti's model) on COCO and Pascal VOC datasets, we find that\nvisual saliency shows consistently stronger correlations with object detection\naccuracy (mA$\\rho$ up to 0.459 on Pascal VOC) compared to depth prediction\n(mA$\\rho$ up to 0.283). Our analysis reveals significant variations in these\ncorrelations across object categories, with larger objects showing correlation\nvalues up to three times higher than smaller objects. These findings suggest\nincorporating visual saliency features into object detection architectures\ncould be more beneficial than depth information, particularly for specific\nobject categories. The observed category-specific variations also provide\ninsights for targeted feature engineering and dataset design improvements,\npotentially leading to more efficient and accurate object detection systems.",
      "tldr_zh": "本研究探讨了物体检测性能与视觉显著性(visual saliency)和深度估计(depth estimation)之间的相关性，通过在COCO和Pascal VOC数据集上使用先进模型（如DeepGaze IIE、Depth Anything、DPT-Large和Itti's model）进行全面实验。结果显示，视觉显著性与物体检测准确率的相关性更强（mAρ高达0.459在Pascal VOC），而深度估计的相关性较低（mAρ高达0.283）。此外，不同物体类别间相关性存在显著差异，大物体相关值可达小物体的三倍。这些发现建议在物体检测架构中优先整合视觉显著性特征，以提升系统效率和准确性，并为针对性特征工程和数据集设计提供指导。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Code Available at:\n  https://github.com/mbar0075/Object-Detection-Correlation-Saliency-vs-Depth",
      "pdf_url": "http://arxiv.org/pdf/2411.02844v1",
      "published_date": "2024-11-05 06:34:19 UTC",
      "updated_date": "2024-11-05 06:34:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:42:11.087660"
    },
    {
      "arxiv_id": "2411.02832v2",
      "title": "PersianRAG: A Retrieval-Augmented Generation System for Persian Language",
      "title_zh": "翻译失败",
      "authors": [
        "Hossein Hosseini",
        "Mohammad Sobhan Zare",
        "Amir Hossein Mohammadi",
        "Arefeh Kazemi",
        "Zahra Zojaji",
        "Mohammad Ali Nematbakhsh"
      ],
      "abstract": "Retrieval augmented generation (RAG) models, which integrate large-scale\npre-trained generative models with external retrieval mechanisms, have shown\nsignificant success in various natural language processing (NLP) tasks.\nHowever, applying RAG models in Persian language as a low-resource language,\nposes distinct challenges. These challenges primarily involve the\npreprocessing, embedding, retrieval, prompt construction, language modeling,\nand response evaluation of the system. In this paper, we address the challenges\ntowards implementing a real-world RAG system for Persian language called\nPersianRAG. We propose novel solutions to overcome these obstacles and evaluate\nour approach using several Persian benchmark datasets. Our experimental results\ndemonstrate the capability of the PersianRAG framework to enhance question\nanswering task in Persian.",
      "tldr_zh": "本文提出 PersianRAG，一种针对波斯语的 Retrieval-Augmented Generation (RAG) 系统，旨在解决低资源语言在预处理、embedding、retrieval、prompt construction、language modeling 和 response evaluation 等方面的独特挑战。研究团队开发了创新解决方案，通过整合大型预训练生成模型和外部检索机制来优化系统性能。实验在多个波斯语基准数据集上进行，结果表明 PersianRAG 显著提升了问答任务的准确性和效果。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02832v2",
      "published_date": "2024-11-05 06:11:17 UTC",
      "updated_date": "2024-11-06 11:19:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:42:22.332084"
    },
    {
      "arxiv_id": "2411.02830v1",
      "title": "Mixtures of In-Context Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Giwon Hong",
        "Emile van Krieken",
        "Edoardo Ponti",
        "Nikolay Malkin",
        "Pasquale Minervini"
      ],
      "abstract": "In-context learning (ICL) adapts LLMs by providing demonstrations without\nfine-tuning the model parameters; however, it does not differentiate between\ndemonstrations and quadratically increases the complexity of Transformer LLMs,\nexhausting the memory. As a solution, we propose Mixtures of In-Context\nLearners (MoICL), a novel approach to treat subsets of demonstrations as\nexperts and learn a weighting function to merge their output distributions\nbased on a training set. In our experiments, we show performance improvements\non 5 out of 7 classification datasets compared to a set of strong baselines (up\nto +13\\% compared to ICL and LENS). Moreover, we enhance the Pareto frontier of\nICL by reducing the inference time needed to achieve the same performance with\nfewer demonstrations. Finally, MoICL is more robust to out-of-domain (up to\n+11\\%), imbalanced (up to +49\\%), or noisy demonstrations (up to +38\\%) or can\nfilter these out from datasets. Overall, MoICL is a more expressive approach to\nlearning from demonstrations without exhausting the context window or memory.",
      "tldr_zh": "这篇论文针对 In-context learning (ICL) 在大型语言模型 (LLMs) 中的问题，如不区分演示和计算复杂度增加导致内存消耗，提出了一种新方法 Mixtures of In-Context Learners (MoICL)。MoICL 将演示子集视为专家，并学习一个加权函数来合并它们的输出分布，从而提高模型的性能和效率。实验结果显示，在 7 个分类数据集中的 5 个上，MoICL 比基线模型（如 ICL 和 LENS）提升了最多 13%，并优化了 Pareto frontier，减少了推理时间和所需演示数量。此外，MoICL 在 out-of-domain 数据（提升最多 11%）、不平衡数据（提升最多 49%）或噪声演示（提升最多 38%）方面更具鲁棒性，提供了一种更具表现力的演示学习方式，而不耗尽上下文窗口或内存。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02830v1",
      "published_date": "2024-11-05 06:02:41 UTC",
      "updated_date": "2024-11-05 06:02:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:44:36.957537"
    },
    {
      "arxiv_id": "2411.05823v2",
      "title": "FlexCAD: Unified and Versatile Controllable CAD Generation with Fine-tuned Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zhanwei Zhang",
        "Shizhao Sun",
        "Wenxiao Wang",
        "Deng Cai",
        "Jiang Bian"
      ],
      "abstract": "Recently, there is a growing interest in creating computer-aided design (CAD)\nmodels based on user intent, known as controllable CAD generation. Existing\nwork offers limited controllability and needs separate models for different\ntypes of control, reducing efficiency and practicality. To achieve controllable\ngeneration across all CAD construction hierarchies, such as sketch-extrusion,\nextrusion, sketch, face, loop and curve, we propose FlexCAD, a unified model by\nfine-tuning large language models (LLMs). First, to enhance comprehension by\nLLMs, we represent a CAD model as a structured text by abstracting each\nhierarchy as a sequence of text tokens. Second, to address various controllable\ngeneration tasks in a unified model, we introduce a hierarchy-aware masking\nstrategy. Specifically, during training, we mask a hierarchy-aware field in the\nCAD text with a mask token. This field, composed of a sequence of tokens, can\nbe set flexibly to represent various hierarchies. Subsequently, we ask LLMs to\npredict this masked field. During inference, the user intent is converted into\na CAD text with a mask token replacing the part the user wants to modify, which\nis then fed into FlexCAD to generate new CAD models. Comprehensive experiments\non public dataset demonstrate the effectiveness of FlexCAD in both generation\nquality and controllability. Code will be available at\nhttps://github.com/microsoft/FlexCAD.",
      "tldr_zh": "该研究提出 FlexCAD，一种统一的、灵活的可控 CAD 生成模型，通过 fine-tuning large language models (LLMs) 来处理所有 CAD 建设层次（如 sketch-extrusion、extrusion 等），解决了现有方法的可控性有限和需要单独模型的问题。首先，FlexCAD 将 CAD 模型表示为结构化的文本序列，并采用 hierarchy-aware masking strategy，在训练中 mask 特定层次的字段让 LLMs 进行预测；在推理时，用户意图通过带 mask token 的文本输入生成新模型。实验在公开数据集上证明，FlexCAD 在生成质量和可控性方面表现出色，为高效的 CAD 生成提供了实用解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Published as a conference paper at ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2411.05823v2",
      "published_date": "2024-11-05 05:45:26 UTC",
      "updated_date": "2025-02-17 03:04:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:42:46.760804"
    },
    {
      "arxiv_id": "2411.02820v3",
      "title": "DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM Serving",
      "title_zh": "翻译失败",
      "authors": [
        "Yuhan Liu",
        "Yuyang Huang",
        "Jiayi Yao",
        "Zhuohan Gu",
        "Kuntai Du",
        "Hanchen Li",
        "Yihua Cheng",
        "Junchen Jiang",
        "Shan Lu",
        "Madan Musuvathi",
        "Esha Choukse"
      ],
      "abstract": "Large Language Models (LLMs) are increasingly employed in complex workflows,\nwhere different LLMs and fine-tuned variants collaboratively address complex\ntasks. However, these systems face significant inefficiencies due to redundant\ncontext processing of the shared context. We propose DroidSpeak, a framework\nthat optimizes context sharing between fine-tuned LLMs derived from the same\nfoundational model. DroidSpeak identifies critical layers in the KV cache and\nselectively recomputes them, enabling effective reuse of intermediate data\nwhile maintaining high accuracy.\n  Our approach balances computational efficiency and task fidelity,\nsignificantly reducing inference latency and throughput bottlenecks.\nExperiments on diverse datasets and model pairs demonstrate that DroidSpeak\nachieves up to 3x higher throughputs and 2.6x faster prefill times with\nnegligible accuracy loss compared to full recomputation.",
      "tldr_zh": "这篇论文提出了 DroidSpeak 框架，用于优化从同一基础模型派生的微调 LLMs 之间的上下文共享，解决复杂工作流中冗余上下文处理的效率问题。DroidSpeak 通过识别 KV cache 中的关键层并选择性重新计算中间数据，实现高效重用，同时保持高准确性。实验结果显示，该框架在多样数据集和模型对上实现了高达 3x 的吞吐量和 2.6x 的预填充时间提升，几乎没有准确性损失。",
      "categories": [
        "cs.MA",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02820v3",
      "published_date": "2024-11-05 05:41:41 UTC",
      "updated_date": "2024-12-19 23:52:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:42:58.271928"
    },
    {
      "arxiv_id": "2411.02817v1",
      "title": "Conditional Vendi Score: An Information-Theoretic Approach to Diversity Evaluation of Prompt-based Generative Models",
      "title_zh": "翻译失败",
      "authors": [
        "Mohammad Jalali",
        "Azim Ospanov",
        "Amin Gohari",
        "Farzan Farnia"
      ],
      "abstract": "Text-conditioned generation models are commonly evaluated based on the\nquality of the generated data and its alignment with the input text prompt. On\nthe other hand, several applications of prompt-based generative models require\nsufficient diversity in the generated data to ensure the models' capability of\ngenerating image and video samples possessing a variety of features. However,\nmost existing diversity metrics are designed for unconditional generative\nmodels, and thus cannot distinguish the diversity arising from variations in\ntext prompts and that contributed by the generative model itself. In this work,\nour goal is to quantify the prompt-induced and model-induced diversity in\nsamples generated by prompt-based models. We propose an information-theoretic\napproach for internal diversity quantification, where we decompose the\nkernel-based entropy $H(X)$ of the generated data $X$ into the sum of the\nconditional entropy $H(X|T)$, given text variable $T$, and the mutual\ninformation $I(X; T)$ between the text and data variables. We introduce the\n\\emph{Conditional-Vendi} score based on $H(X|T)$ to quantify the internal\ndiversity of the model and the \\emph{Information-Vendi} score based on $I(X;\nT)$ to measure the statistical relevance between the generated data and text\nprompts. We provide theoretical results to statistically interpret these scores\nand relate them to the unconditional Vendi score. We conduct several numerical\nexperiments to show the correlation between the Conditional-Vendi score and the\ninternal diversity of text-conditioned generative models. The codebase is\navailable at\n\\href{https://github.com/mjalali/conditional-vendi}{https://github.com/mjalali/conditional-vendi}.",
      "tldr_zh": "该论文提出了一种信息论方法，用于评估基于提示的生成模型的多样性，旨在区分文本提示引发的多样性与模型自身贡献的多样性。作者将生成数据 X 的核基熵 H(X) 分解为条件熵 H(X|T) 和互信息 I(X; T)，从而引入 Conditional-Vendi score 来量化模型的内部多样性，以及 Information-Vendi score 来衡量生成数据与文本提示的相关性。论文提供了理论分析，将这些分数与无条件 Vendi score 相关联，并通过数值实验证明了 Conditional-Vendi score 与文本条件生成模型内部多样性的强相关性，为更精确的生成模型评估提供了新工具。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "cs.IT",
        "math.IT",
        "68T07"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02817v1",
      "published_date": "2024-11-05 05:30:39 UTC",
      "updated_date": "2024-11-05 05:30:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:43:11.265182"
    },
    {
      "arxiv_id": "2411.02797v1",
      "title": "DeepContext: A Context-aware, Cross-platform, and Cross-framework Tool for Performance Profiling and Analysis of Deep Learning Workloads",
      "title_zh": "DeepContext：一个上下文感知、跨平台和跨框架",
      "authors": [
        "Qidong Zhao",
        "Hao Wu",
        "Yuming Hao",
        "Zilingfeng Ye",
        "Jiajia Li",
        "Xu Liu",
        "Keren Zhou"
      ],
      "abstract": "Effective performance profiling and analysis are essential for optimizing\ntraining and inference of deep learning models, especially given the growing\ncomplexity of heterogeneous computing environments. However, existing tools\noften lack the capability to provide comprehensive program context information\nand performance optimization insights for sophisticated interactions between\nCPUs and GPUs. This paper introduces DeepContext, a novel profiler that links\nprogram contexts across high-level Python code, deep learning frameworks,\nunderlying libraries written in C/C++, as well as device code executed on GPUs.\nDeepContext incorporates measurements of both coarse- and fine-grained\nperformance metrics for major deep learning frameworks, such as PyTorch and\nJAX, and is compatible with GPUs from both Nvidia and AMD, as well as various\nCPU architectures, including x86 and ARM. In addition, DeepContext integrates a\nnovel GUI that allows users to quickly identify hotpots and an innovative\nautomated performance analyzer that suggests users with potential optimizations\nbased on performance metrics and program context. Through detailed use cases,\nwe demonstrate how DeepContext can help users identify and analyze performance\nissues to enable quick and effective optimization of deep learning workloads.\nWe believe Deep Context is a valuable tool for users seeking to optimize\ncomplex deep learning workflows across multiple compute environments.",
      "tldr_zh": "这篇论文介绍了 DeepContext，一种上下文感知的性能分析工具，旨在优化深度学习模型的训练和推理，尤其针对 CPU 和 GPU 交互的复杂环境。DeepContext 能够链接从高层 Python 代码到底层 C/C++ 库以及 GPU 设备代码的程序上下文，支持测量粗粒度和细粒度性能指标，并兼容 PyTorch 和 JAX 等框架，以及 Nvidia、AMD GPU 和 x86、ARM CPU。工具还集成了 GUI 用于快速识别性能热点，以及一个自动性能分析器，根据指标和上下文提供优化建议。通过实际用例，论文展示了 DeepContext 如何帮助用户有效识别和解决性能问题，从而提升复杂深度学习工作负载的优化效率。",
      "categories": [
        "cs.PF",
        "cs.AI"
      ],
      "primary_category": "cs.PF",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02797v1",
      "published_date": "2024-11-05 04:15:26 UTC",
      "updated_date": "2024-11-05 04:15:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:43:23.120894"
    },
    {
      "arxiv_id": "2411.02796v2",
      "title": "Specialized Foundation Models Struggle to Beat Supervised Baselines",
      "title_zh": "专业化基础模型难以击败监督学习基准",
      "authors": [
        "Zongzhe Xu",
        "Ritvik Gupta",
        "Wenduo Cheng",
        "Alexander Shen",
        "Junhong Shen",
        "Ameet Talwalkar",
        "Mikhail Khodak"
      ],
      "abstract": "Following its success for vision and text, the \"foundation model\" (FM)\nparadigm -- pretraining large models on massive data, then fine-tuning on\ntarget tasks -- has rapidly expanded to domains in the sciences, engineering,\nhealthcare, and beyond. Has this achieved what the original FMs accomplished,\ni.e. the supplanting of traditional supervised learning in their domains? To\nanswer we look at three modalities -- genomics, satellite imaging, and time\nseries -- with multiple recent FMs and compare them to a standard supervised\nlearning workflow: model development, hyperparameter tuning, and training, all\nusing only data from the target task. Across these three specialized domains,\nwe find that it is consistently possible to train simple supervised models --\nno more complicated than a lightly modified wide ResNet or UNet -- that match\nor even outperform the latest foundation models. Our work demonstrates that the\nbenefits of large-scale pretraining have yet to be realized in many specialized\nareas, reinforces the need to compare new FMs to strong, well-tuned baselines,\nand introduces two new, easy-to-use, open-source, and automated workflows for\ndoing so.",
      "tldr_zh": "本文研究了在基因组学、卫星成像和时间序列等专业领域，专门的基础模型（FM）是否能取代传统的监督学习。作者将多个 FM 与标准监督学习工作流（包括模型开发、超参数调优和使用目标任务数据训练）进行比较，结果显示，简单监督模型（如轻微修改的宽 ResNet 或 UNet）能够匹配或超越 FM 的性能。这证明大规模预训练在这些领域尚未实现预期优势，并强调了需要与强基线比较，同时引入两个新的开源自动化工作流来简化此类评估。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV",
        "q-bio.GN"
      ],
      "primary_category": "cs.LG",
      "comment": "The first two authors contributed equally. The order was determined\n  by coin flip",
      "pdf_url": "http://arxiv.org/pdf/2411.02796v2",
      "published_date": "2024-11-05 04:10:59 UTC",
      "updated_date": "2025-03-21 03:59:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:43:35.968824"
    },
    {
      "arxiv_id": "2411.02795v1",
      "title": "The Evolution of RWKV: Advancements in Efficient Language Modeling",
      "title_zh": "翻译失败",
      "authors": [
        "Akul Datta"
      ],
      "abstract": "This paper reviews the development of the Receptance Weighted Key Value\n(RWKV) architecture, emphasizing its advancements in efficient language\nmodeling. RWKV combines the training efficiency of Transformers with the\ninference efficiency of RNNs through a novel linear attention mechanism. We\nexamine its core innovations, adaptations across various domains, and\nperformance advantages over traditional models. The paper also discusses\nchallenges and future directions for RWKV as a versatile architecture in deep\nlearning.",
      "tldr_zh": "这篇论文回顾了 Receptance Weighted Key Value (RWKV) 架构在高效语言建模领域的演变和发展。RWKV 通过一种新型的 linear attention mechanism，将 Transformers 的训练效率与 RNNs 的推理效率相结合，实现高效的模型性能。论文分析了 RWKV 的核心创新、跨领域适应性以及相对于传统模型的优势，并讨论了其面临的挑战和未来方向。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02795v1",
      "published_date": "2024-11-05 04:10:05 UTC",
      "updated_date": "2024-11-05 04:10:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:43:46.278969"
    },
    {
      "arxiv_id": "2411.02791v1",
      "title": "Language Models and Cycle Consistency for Self-Reflective Machine Translation",
      "title_zh": "翻译失败",
      "authors": [
        "Jianqiao Wangni"
      ],
      "abstract": "This paper introduces a novel framework that leverages large language models\n(LLMs) for machine translation (MT). We start with one conjecture: an ideal\ntranslation should contain complete and accurate information for a strong\nenough LLM to recover the original sentence. We generate multiple translation\ncandidates from a source language A to a target language B, and subsequently\ntranslate these candidates back to the original language A. By evaluating the\ncycle consistency between the original and back-translated sentences using\nmetrics such as token-level precision and accuracy, we implicitly estimate the\ntranslation quality in language B, without knowing its ground-truth. This also\nhelps to evaluate the LLM translation capability, only with monolingual\ncorpora. For each source sentence, we identify the translation candidate with\noptimal cycle consistency with the original sentence as the final answer. Our\nexperiments demonstrate that larger LLMs, or the same LLM with more forward\npasses during inference, exhibit increased cycle consistency, aligning with the\nLLM model size scaling law and test-time computation scaling law. This work\nprovide methods for, 1) to implicitly evaluate translation quality of a\nsentence in the target language, 2), to evaluate capability of LLM for\nany-to-any-language translation, and 3), how to generate a better translation\nfor a specific LLM.",
      "tldr_zh": "这篇论文提出了一种利用大型语言模型 (LLMs) 的自反式机器翻译框架，通过循环一致性 (cycle consistency) 评估方法来优化翻译质量。具体而言，该框架生成多个从源语言 A 到目标语言 B 的翻译候选，然后回译到 A，并使用 token-level 精度和准确率等指标评估原句与回译句的一致性，从而选择最佳候选。实验发现，更大规模的 LLMs 或增加前向传递能显著提升循环一致性，这与 LLM 模型大小缩放定律和测试时计算缩放定律相符。该方法提供了隐式评估翻译质量、评估 LLM 的任意语言翻译能力，以及生成更优翻译的三大贡献。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG",
        "cs.NE",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02791v1",
      "published_date": "2024-11-05 04:01:41 UTC",
      "updated_date": "2024-11-05 04:01:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:43:59.299965"
    },
    {
      "arxiv_id": "2411.02788v2",
      "title": "When to Localize? A Risk-Constrained Reinforcement Learning Approach",
      "title_zh": "翻译失败",
      "authors": [
        "Chak Lam Shek",
        "Kasra Torshizi",
        "Troi Williams",
        "Pratap Tokekar"
      ],
      "abstract": "In a standard navigation pipeline, a robot localizes at every time step to\nlower navigational errors. However, in some scenarios, a robot needs to\nselectively localize when it is expensive to obtain observations. For example,\nan underwater robot surfacing to localize too often hinders it from searching\nfor critical items underwater, such as black boxes from crashed aircraft. On\nthe other hand, if the robot never localizes, poor state estimates cause\nfailure to find the items due to inadvertently leaving the search area or\nentering hazardous, restricted areas. Motivated by these scenarios, we\ninvestigate approaches to help a robot determine \"when to localize?\" We\nformulate this as a bi-criteria optimization problem: minimize the number of\nlocalization actions while ensuring the probability of failure (due to\ncollision or not reaching a desired goal) remains bounded. In recent work, we\nshowed how to formulate this active localization problem as a constrained\nPartially Observable Markov Decision Process (POMDP), which was solved using an\nonline POMDP solver. However, this approach is too slow and requires full\nknowledge of the robot transition and observation models. In this paper, we\npresent RiskRL, a constrained Reinforcement Learning (RL) framework that\novercomes these limitations. RiskRL uses particle filtering and recurrent Soft\nActor-Critic network to learn a policy that minimizes the number of\nlocalizations while ensuring the probability of failure constraint is met. Our\nnumerical experiments show that RiskRL learns a robust policy that leads to at\nleast a 26% increase in success rates when traversing unseen test environments.",
      "tldr_zh": "本研究探讨了机器人导航中“何时进行定位”的问题，提出RiskRL框架，这是一种受限强化学习（Constrained Reinforcement Learning）方法，旨在最小化定位动作的数量，同时确保失败概率（如碰撞或未达目标）保持在预设界限内。\nRiskRL通过结合粒子过滤（Particle Filtering）和循环Soft Actor-Critic网络，学习一个鲁棒策略，克服了之前基于受限部分可观测Markov决策过程（POMDP）方法的计算速度慢和模型依赖性问题。\n实验结果表明，在未见测试环境中，RiskRL使成功率至少提高26%，为资源受限场景下的机器人自主导航提供了高效解决方案。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02788v2",
      "published_date": "2024-11-05 03:54:00 UTC",
      "updated_date": "2025-04-29 19:14:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:44:12.790080"
    },
    {
      "arxiv_id": "2411.02785v2",
      "title": "Stochastic Monkeys at Play: Random Augmentations Cheaply Break LLM Safety Alignment",
      "title_zh": "翻译失败",
      "authors": [
        "Jason Vega",
        "Junsheng Huang",
        "Gaokai Zhang",
        "Hangoo Kang",
        "Minjia Zhang",
        "Gagandeep Singh"
      ],
      "abstract": "Safety alignment of Large Language Models (LLMs) has recently become a\ncritical objective of model developers. In response, a growing body of work has\nbeen investigating how safety alignment can be bypassed through various\njailbreaking methods, such as adversarial attacks. However, these jailbreak\nmethods can be rather costly or involve a non-trivial amount of creativity and\neffort, introducing the assumption that malicious users are high-resource or\nsophisticated. In this paper, we study how simple random augmentations to the\ninput prompt affect safety alignment effectiveness in state-of-the-art LLMs,\nsuch as Llama 3 and Qwen 2. We perform an in-depth evaluation of 17 different\nmodels and investigate the intersection of safety under random augmentations\nwith multiple dimensions: augmentation type, model size, quantization,\nfine-tuning-based defenses, and decoding strategies (e.g., sampling\ntemperature). We show that low-resource and unsophisticated attackers, i.e.\n$\\textit{stochastic monkeys}$, can significantly improve their chances of\nbypassing alignment with just 25 random augmentations per prompt. Source code\nand data: https://github.com/uiuc-focal-lab/stochastic-monkeys/",
      "tldr_zh": "该论文研究了简单随机增强（random augmentations）如何低成本地破坏大型语言模型（LLMs）的安全对齐（safety alignment），挑战了现有对抗攻击方法的复杂性和资源需求。作者评估了17个模型（如Llama 3和Qwen 2），考察了增强类型、模型大小、量化、微调防御和解码策略（如采样温度）等因素。结果显示，即使攻击者资源有限，通过每条提示仅25个随机增强，就能显著提高绕过对齐的成功率，强调了LLMs安全性的脆弱性，并提供了源代码以供进一步研究。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "v2: Updated with changes from peer review rebuttal. v1: Version under\n  peer review",
      "pdf_url": "http://arxiv.org/pdf/2411.02785v2",
      "published_date": "2024-11-05 03:51:13 UTC",
      "updated_date": "2024-12-05 12:58:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:45:12.155609"
    },
    {
      "arxiv_id": "2411.02762v1",
      "title": "EcoCropsAID: Economic Crops Aerial Image Dataset for Land Use Classification",
      "title_zh": "EcoCropsAID：经济作物航空图像数据集，用于土地利用分类",
      "authors": [
        "Sangdaow Noppitak",
        "Emmanuel Okafor",
        "Olarik Surinta"
      ],
      "abstract": "The EcoCropsAID dataset is a comprehensive collection of 5,400 aerial images\ncaptured between 2014 and 2018 using the Google Earth application. This dataset\nfocuses on five key economic crops in Thailand: rice, sugarcane, cassava,\nrubber, and longan. The images were collected at various crop growth stages:\nearly cultivation, growth, and harvest, resulting in significant variability\nwithin each category and similarities across different categories. These\nvariations, coupled with differences in resolution, color, and contrast\nintroduced by multiple remote imaging sensors, present substantial challenges\nfor land use classification. The dataset is an interdisciplinary resource that\nspans multiple research domains, including remote sensing, geoinformatics,\nartificial intelligence, and computer vision. The unique features of the\nEcoCropsAID dataset offer opportunities for researchers to explore novel\napproaches, such as extracting spatial and temporal features, developing deep\nlearning architectures, and implementing transformer-based models. The\nEcoCropsAID dataset provides a valuable platform for advancing research in land\nuse classification, with implications for optimizing agricultural practices and\nenhancing sustainable development. This study explicitly investigates the use\nof deep learning algorithms to classify economic crop areas in northeastern\nThailand, utilizing satellite imagery to address the challenges posed by\ndiverse patterns and similarities across categories.",
      "tldr_zh": "EcoCropsAID 是一个包含 5400 张航拍图像的数据集，用于土地利用分类，聚焦于泰国五种经济作物：rice、sugarcane、cassava、rubber 和 longan，这些图像从 2014 到 2018 年使用 Google Earth 捕获，并覆盖作物生长阶段如 early cultivation、growth 和 harvest。\n数据集的独特特征包括类别内显著变异性和类别间相似性，以及图像分辨率、颜色和对比度的差异，增加了分类难度。\n研究采用 deep learning 算法对泰国东北部经济作物区域进行分类，并为遥感、人工智能和计算机视觉等领域提供资源，支持开发新型方法如提取 spatial and temporal features 和 transformer-based models，以优化农业实践并推动可持续性发展。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "12 pages, 7 figures",
      "pdf_url": "http://arxiv.org/pdf/2411.02762v1",
      "published_date": "2024-11-05 03:14:36 UTC",
      "updated_date": "2024-11-05 03:14:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:45:26.987737"
    },
    {
      "arxiv_id": "2411.05027v1",
      "title": "Generative Artificial Intelligence Meets Synthetic Aperture Radar: A Survey",
      "title_zh": "生成式人工智能遇见合成孔径雷达：一项调查",
      "authors": [
        "Zhongling Huang",
        "Xidan Zhang",
        "Zuqian Tang",
        "Feng Xu",
        "Mihai Datcu",
        "Junwei Han"
      ],
      "abstract": "SAR images possess unique attributes that present challenges for both human\nobservers and vision AI models to interpret, owing to their electromagnetic\ncharacteristics. The interpretation of SAR images encounters various hurdles,\nwith one of the primary obstacles being the data itself, which includes issues\nrelated to both the quantity and quality of the data. The challenges can be\naddressed using generative AI technologies. Generative AI, often known as\nGenAI, is a very advanced and powerful technology in the field of artificial\nintelligence that has gained significant attention. The advancement has created\npossibilities for the creation of texts, photorealistic pictures, videos, and\nmaterial in various modalities. This paper aims to comprehensively investigate\nthe intersection of GenAI and SAR. First, we illustrate the common data\ngeneration-based applications in SAR field and compare them with computer\nvision tasks, analyzing the similarity, difference, and general challenges of\nthem. Then, an overview of the latest GenAI models is systematically reviewed,\nincluding various basic models and their variations targeting the general\nchallenges. Additionally, the corresponding applications in SAR domain are also\nincluded. Specifically, we propose to summarize the physical model based\nsimulation approaches for SAR, and analyze the hybrid modeling methods that\ncombine the GenAI and interpretable models. The evaluation methods that have\nbeen or could be applied to SAR, are also explored. Finally, the potential\nchallenges and future prospects are discussed. To our best knowledge, this\nsurvey is the first exhaustive examination of the interdiscipline of SAR and\nGenAI, encompassing a wide range of topics, including deep neural networks,\nphysical models, computer vision, and SAR images. The resources of this survey\nare open-source at \\url{https://github.com/XAI4SAR/GenAIxSAR}.",
      "tldr_zh": "这篇调查论文探讨了生成式人工智能(GenAI)与合成孔径雷达(SAR)图像处理领域的交叉，针对SAR图像的电磁特性导致的解释挑战（如数据量和质量问题）提出使用GenAI作为解决方案。论文首先比较了SAR领域的常见数据生成应用与计算机视觉任务，分析了它们的相似性、差异和一般挑战，然后系统回顾了最新的GenAI模型及其在SAR中的应用，包括基于物理模型的模拟方法和结合GenAI的混合建模技术。最终，论文评估了潜在评估方法、挑战及未来前景，并声称这是首个全面考察这一交叉领域的调查，提供开源资源以供参考。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "eess.IV"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.05027v1",
      "published_date": "2024-11-05 03:06:00 UTC",
      "updated_date": "2024-11-05 03:06:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:45:36.062293"
    },
    {
      "arxiv_id": "2411.02746v1",
      "title": "A Bayesian explanation of machine learning models based on modes and functional ANOVA",
      "title_zh": "翻译失败",
      "authors": [
        "Quan Long"
      ],
      "abstract": "Most methods in explainable AI (XAI) focus on providing reasons for the\nprediction of a given set of features. However, we solve an inverse explanation\nproblem, i.e., given the deviation of a label, find the reasons of this\ndeviation. We use a Bayesian framework to recover the ``true'' features,\nconditioned on the observed label value. We efficiently explain the deviation\nof a label value from the mode, by identifying and ranking the influential\nfeatures using the ``distances'' in the ANOVA functional decomposition. We show\nthat the new method is more human-intuitive and robust than methods based on\nmean values, e.g., SHapley Additive exPlanations (SHAP values). The extra costs\nof solving a Bayesian inverse problem are dimension-independent.",
      "tldr_zh": "该论文提出了一种基于 Bayesian 框架的机器学习模型解释方法，通过 modes 和 functional ANOVA 来解决逆解释问题，即从标签偏差中找出原因。方法涉及恢复“真实”特征，并利用 ANOVA 功能分解中的“距离”来识别和排名影响特征，从而提供更人性化的解释。相比于基于均值的 SHAP values，这种方法更直观、更鲁棒，且计算成本与数据维度无关。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.CO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02746v1",
      "published_date": "2024-11-05 02:32:26 UTC",
      "updated_date": "2024-11-05 02:32:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:45:47.383002"
    },
    {
      "arxiv_id": "2411.03359v1",
      "title": "Self-Calibrated Tuning of Vision-Language Models for Out-of-Distribution Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Geng Yu",
        "Jianing Zhu",
        "Jiangchao Yao",
        "Bo Han"
      ],
      "abstract": "Out-of-distribution (OOD) detection is crucial for deploying reliable machine\nlearning models in open-world applications. Recent advances in CLIP-based OOD\ndetection have shown promising results via regularizing prompt tuning with OOD\nfeatures extracted from ID data. However, the irrelevant context mined from ID\ndata can be spurious due to the inaccurate foreground-background decomposition,\nthus limiting the OOD detection performance. In this work, we propose a novel\nframework, namely, Self-Calibrated Tuning (SCT), to mitigate this problem for\neffective OOD detection with only the given few-shot ID data. Specifically, SCT\nintroduces modulating factors respectively on the two components of the\noriginal learning objective. It adaptively directs the optimization process\nbetween the two tasks during training on data with different prediction\nuncertainty to calibrate the influence of OOD regularization, which is\ncompatible with many prompt tuning based OOD detection methods. Extensive\nexperiments and analyses have been conducted to characterize and demonstrate\nthe effectiveness of the proposed SCT. The code is publicly available.",
      "tldr_zh": "该研究针对视觉语言模型的Out-of-Distribution (OOD) 检测问题，提出了一种Self-Calibrated Tuning (SCT) 框架，以解决现有CLIP-based方法中因不准确的前景-背景分解而引入无关上下文的局限性。SCT通过在原始学习目标的两个组件上引入调制因子，自适应地根据预测不确定性调整优化过程，从而在仅使用少量ID数据的情况下增强OOD检测性能，并兼容多种基于prompt tuning的检测方法。实验结果显示，SCT在广泛测试中表现出色，有效提升了检测准确性，并公开了代码以促进进一步应用。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "accepted by NeurIPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2411.03359v1",
      "published_date": "2024-11-05 02:29:16 UTC",
      "updated_date": "2024-11-05 02:29:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:45:59.503944"
    },
    {
      "arxiv_id": "2411.02722v1",
      "title": "Multimodal Commonsense Knowledge Distillation for Visual Question Answering",
      "title_zh": "翻译失败",
      "authors": [
        "Shuo Yang",
        "Siwen Luo",
        "Soyeon Caren Han"
      ],
      "abstract": "Existing Multimodal Large Language Models (MLLMs) and Visual Language\nPretrained Models (VLPMs) have shown remarkable performances in the general\nVisual Question Answering (VQA). However, these models struggle with VQA\nquestions that require external commonsense knowledge due to the challenges in\ngenerating high-quality prompts and the high computational costs of\nfine-tuning. In this work, we propose a novel graph-based multimodal\ncommonsense knowledge distillation framework that constructs a unified\nrelational graph over commonsense knowledge, visual objects and questions\nthrough a Graph Convolutional Network (GCN) following a teacher-student\nenvironment. This proposed framework is flexible with any type of teacher and\nstudent models without further fine-tuning, and has achieved competitive\nperformances on the ScienceQA dataset.",
      "tldr_zh": "现有Multimodal Large Language Models (MLLMs) 和 Visual Language Pretrained Models (VLPMs) 在一般Visual Question Answering (VQA) 中表现出色，但处理需要外部commonsense knowledge 的问题时，由于提示生成和fine-tuning 的高计算成本而面临挑战。本文提出了一种新型graph-based multimodal commonsense knowledge distillation 框架，通过Graph Convolutional Network (GCN) 构建统一的relational graph，将commonsense knowledge、visual objects 和 questions 整合在teacher-student 环境中。该框架对任何teacher 和 student 模型都具有灵活性，无需进一步fine-tuning，并在ScienceQA 数据集上实现了有竞争力的性能。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "AAAI 2025 (Accepted, Oral)",
      "pdf_url": "http://arxiv.org/pdf/2411.02722v1",
      "published_date": "2024-11-05 01:37:16 UTC",
      "updated_date": "2024-11-05 01:37:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:46:12.008120"
    },
    {
      "arxiv_id": "2411.02714v1",
      "title": "Game Plot Design with an LLM-powered Assistant: An Empirical Study with Game Designers",
      "title_zh": "翻译失败",
      "authors": [
        "Seyed Hossein Alavi",
        "Weijia Xu",
        "Nebojsa Jojic",
        "Daniel Kennett",
        "Raymond T. Ng",
        "Sudha Rao",
        "Haiyan Zhang",
        "Bill Dolan",
        "Vered Shwartz"
      ],
      "abstract": "We introduce GamePlot, an LLM-powered assistant that supports game designers\nin crafting immersive narratives for turn-based games, and allows them to test\nthese games through a collaborative game play and refine the plot throughout\nthe process. Our user study with 14 game designers shows high levels of both\nsatisfaction with the generated game plots and sense of ownership over the\nnarratives, but also reconfirms that LLM are limited in their ability to\ngenerate complex and truly innovative content. We also show that diverse user\npopulations have different expectations from AI assistants, and encourage\nresearchers to study how tailoring assistants to diverse user groups could\npotentially lead to increased job satisfaction and greater creativity and\ninnovation over time.",
      "tldr_zh": "本研究引入了GamePlot，一种基于LLM的助手，帮助游戏设计师创建和测试转盘游戏的沉浸式叙事，并通过协作游戏玩法进行迭代优化。用户研究涉及14名设计师，结果显示他们对生成的游戏情节高度满意并感受到所有权，但LLM在生成复杂和创新内容方面存在局限。研究进一步揭示，不同用户群体对AI助手的期望各异，并建议通过针对性定制来提升工作满意度、创造力和长期创新潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.HC"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02714v1",
      "published_date": "2024-11-05 01:26:35 UTC",
      "updated_date": "2024-11-05 01:26:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:46:23.526125"
    },
    {
      "arxiv_id": "2411.02712v1",
      "title": "V-DPO: Mitigating Hallucination in Large Vision Language Models via Vision-Guided Direct Preference Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Yuxi Xie",
        "Guanzhen Li",
        "Xiao Xu",
        "Min-Yen Kan"
      ],
      "abstract": "Large vision-language models (LVLMs) suffer from hallucination, resulting in\nmisalignment between the output textual response and the input visual content.\nRecent research indicates that the over-reliance on the Large Language Model\n(LLM) backbone, as one cause of the LVLM hallucination, inherently introduces\nbias from language priors, leading to insufficient context attention to the\nvisual inputs.\n  We tackle this issue of hallucination by mitigating such over-reliance\nthrough preference learning. We propose Vision-guided Direct Preference\nOptimization (V-DPO) to enhance visual context learning at training time. To\ninterpret the effectiveness and generalizability of V-DPO on different types of\ntraining data, we construct a synthetic dataset containing both response- and\nimage-contrast preference pairs, compared against existing human-annotated\nhallucination samples. Our approach achieves significant improvements compared\nwith baseline methods across various hallucination benchmarks. Our analysis\nindicates that V-DPO excels in learning from image-contrast preference data,\ndemonstrating its superior ability to elicit and understand nuances of visual\ncontext. Our code is publicly available at https://github.com/YuxiXie/V-DPO.",
      "tldr_zh": "本研究针对大型视觉语言模型(LVLMs)的幻觉问题，提出V-DPO（Vision-guided Direct Preference Optimization）方法，通过视觉引导的直接偏好优化来减轻模型对LLM骨干的过度依赖，从而提升视觉上下文学习。研究构建了一个合成数据集，包含response-contrast和image-contrast偏好对，并与现有的人类标注数据进行比较。实验结果显示，V-DPO在各种幻觉基准上显著优于基线方法，尤其在image-contrast数据上表现出色，证明其在理解视觉细微差异方面的优势。代码已开源，供进一步验证和应用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "EMNLP 2024 Findings; 9 pages, 6 figures, 5 tables (16 pages, 8\n  figures, 8 tables including references and appendices)",
      "pdf_url": "http://arxiv.org/pdf/2411.02712v1",
      "published_date": "2024-11-05 01:24:37 UTC",
      "updated_date": "2024-11-05 01:24:37 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:46:35.605015"
    },
    {
      "arxiv_id": "2411.02708v1",
      "title": "Exploring Response Uncertainty in MLLMs: An Empirical Evaluation under Misleading Scenarios",
      "title_zh": "探索 MLLMs 的响应不确定性：在误导性场景下的实证评估",
      "authors": [
        "Yunkai Dang",
        "Mengxi Gao",
        "Yibo Yan",
        "Xin Zou",
        "Yanggan Gu",
        "Aiwei Liu",
        "Xuming Hu"
      ],
      "abstract": "Ensuring that Multimodal Large Language Models (MLLMs) maintain consistency\nin their responses is essential for developing trustworthy multimodal\nintelligence. However, existing benchmarks include many samples where all MLLMs\n\\textit{exhibit high response uncertainty when encountering misleading\ninformation}, requiring even 5-15 response attempts per sample to effectively\nassess uncertainty. Therefore, we propose a two-stage pipeline: first, we\ncollect MLLMs' responses without misleading information, and then gather\nmisleading ones via specific misleading instructions. By calculating the\nmisleading rate, and capturing both correct-to-incorrect and\nincorrect-to-correct shifts between the two sets of responses, we can\neffectively metric the model's response uncertainty. Eventually, we establish a\n\\textbf{\\underline{M}}ultimodal \\textbf{\\underline{U}}ncertainty\n\\textbf{\\underline{B}}enchmark (\\textbf{MUB}) that employs both explicit and\nimplicit misleading instructions to comprehensively assess the vulnerability of\nMLLMs across diverse domains. Our experiments reveal that all open-source and\nclose-source MLLMs are highly susceptible to misleading instructions, with an\naverage misleading rate exceeding 86\\%. To enhance the robustness of MLLMs, we\nfurther fine-tune all open-source MLLMs by incorporating explicit and implicit\nmisleading data, which demonstrates a significant reduction in misleading\nrates. Our code is available at:\n\\href{https://github.com/Yunkai696/MUB}{https://github.com/Yunkai696/MUB}",
      "tldr_zh": "该研究探讨了Multimodal Large Language Models (MLLMs)在误导场景下的响应不确定性，通过实证评估来提升多模态智能的可信度。研究者提出一个两阶段管道：首先收集MLLMs在无误导信息下的响应，然后通过特定误导指令获取误导性响应，并通过计算misleading rate以及响应转变（如正确到错误或反之）来量化不确定性。基于此，他们建立了Multimodal Uncertainty Benchmark (MUB)，使用显式和隐式误导指令评估MLLMs在不同领域的脆弱性。实验结果显示，所有开源和闭源MLLMs的平均misleading rate超过86%，而通过微调模型并融入误导数据，显著降低了误导率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02708v1",
      "published_date": "2024-11-05 01:11:28 UTC",
      "updated_date": "2024-11-05 01:11:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:46:48.433072"
    },
    {
      "arxiv_id": "2411.02704v1",
      "title": "RT-Affordance: Affordances are Versatile Intermediate Representations for Robot Manipulation",
      "title_zh": "RT-Affordance：Affordances 是用于机器人操作的多功能中间表示",
      "authors": [
        "Soroush Nasiriany",
        "Sean Kirmani",
        "Tianli Ding",
        "Laura Smith",
        "Yuke Zhu",
        "Danny Driess",
        "Dorsa Sadigh",
        "Ted Xiao"
      ],
      "abstract": "We explore how intermediate policy representations can facilitate\ngeneralization by providing guidance on how to perform manipulation tasks.\nExisting representations such as language, goal images, and trajectory sketches\nhave been shown to be helpful, but these representations either do not provide\nenough context or provide over-specified context that yields less robust\npolicies. We propose conditioning policies on affordances, which capture the\npose of the robot at key stages of the task. Affordances offer expressive yet\nlightweight abstractions, are easy for users to specify, and facilitate\nefficient learning by transferring knowledge from large internet datasets. Our\nmethod, RT-Affordance, is a hierarchical model that first proposes an\naffordance plan given the task language, and then conditions the policy on this\naffordance plan to perform manipulation. Our model can flexibly bridge\nheterogeneous sources of supervision including large web datasets and robot\ntrajectories. We additionally train our model on cheap-to-collect in-domain\naffordance images, allowing us to learn new tasks without collecting any\nadditional costly robot trajectories. We show on a diverse set of novel tasks\nhow RT-Affordance exceeds the performance of existing methods by over 50%, and\nwe empirically demonstrate that affordances are robust to novel settings.\nVideos available at https://snasiriany.me/rt-affordance",
      "tldr_zh": "该研究探讨了使用 affordances 作为机器人操作任务的中间表示，以提升策略的泛化能力。RT-Affordance 是一种分层模型，先基于任务语言生成 affordance 计划（捕捉机器人关键阶段的姿势），然后以此计划指导操作策略，实现对异构监督数据（如网络数据集和机器人轨迹）的灵活整合，并利用廉价的 in-domain affordance 图像学习新任务，而无需额外机器人轨迹。实验结果显示，RT-Affordance 在多种新颖任务上比现有方法性能提升超过 50%，并证明 affordances 对新环境更具鲁棒性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2411.02704v1",
      "published_date": "2024-11-05 01:02:51 UTC",
      "updated_date": "2024-11-05 01:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:46:59.671708"
    },
    {
      "arxiv_id": "2411.02695v1",
      "title": "JEL: Applying End-to-End Neural Entity Linking in JPMorgan Chase",
      "title_zh": "翻译失败",
      "authors": [
        "Wanying Ding",
        "Vinay K. Chaudhri",
        "Naren Chittar",
        "Krishna Konakanchi"
      ],
      "abstract": "Knowledge Graphs have emerged as a compelling abstraction for capturing key\nrelationship among the entities of interest to enterprises and for integrating\ndata from heterogeneous sources. JPMorgan Chase (JPMC) is leading this trend by\nleveraging knowledge graphs across the organization for multiple mission\ncritical applications such as risk assessment, fraud detection, investment\nadvice, etc. A core problem in leveraging a knowledge graph is to link mentions\n(e.g., company names) that are encountered in textual sources to entities in\nthe knowledge graph. Although several techniques exist for entity linking, they\nare tuned for entities that exist in Wikipedia, and fail to generalize for the\nentities that are of interest to an enterprise. In this paper, we propose a\nnovel end-to-end neural entity linking model (JEL) that uses minimal context\ninformation and a margin loss to generate entity embeddings, and a Wide & Deep\nLearning model to match character and semantic information respectively. We\nshow that JEL achieves the state-of-the-art performance to link mentions of\ncompany names in financial news with entities in our knowledge graph. We report\non our efforts to deploy this model in the company-wide system to generate\nalerts in response to financial news. The methodology used for JEL is directly\napplicable and usable by other enterprises who need entity linking solutions\nfor data that are unique to their respective situations.",
      "tldr_zh": "这篇论文提出JEL，一种端到端神经实体链接（End-to-End Neural Entity Linking）模型，针对企业知识图谱（Knowledge Graphs）中的特定实体（如金融公司名称）进行链接，解决现有方法（如基于Wikipedia的模型）在企业场景下泛化性差的问题。JEL模型使用最小上下文信息和Margin Loss生成实体嵌入，并结合Wide & Deep Learning模型来匹配字符和语义信息。实验结果显示，JEL在金融新闻中链接公司名称到知识图谱上达到了state-of-the-art性能，并已在JPMorgan Chase的系统中部署，用于生成金融新闻警报，该方法可扩展至其他企业的独特数据场景。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "8 pages, 4 figures, IAAI-21",
      "pdf_url": "http://arxiv.org/pdf/2411.02695v1",
      "published_date": "2024-11-05 00:46:25 UTC",
      "updated_date": "2024-11-05 00:46:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:47:13.024945"
    },
    {
      "arxiv_id": "2411.02692v1",
      "title": "JPEC: A Novel Graph Neural Network for Competitor Retrieval in Financial Knowledge Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Wanying Ding",
        "Manoj Cherukumalli",
        "Santosh Chikoti",
        "Vinay K. Chaudhri"
      ],
      "abstract": "Knowledge graphs have gained popularity for their ability to organize and\nanalyze complex data effectively. When combined with graph embedding\ntechniques, such as graph neural networks (GNNs), knowledge graphs become a\npotent tool in providing valuable insights. This study explores the application\nof graph embedding in identifying competitors from a financial knowledge graph.\nExisting state-of-the-art(SOTA) models face challenges due to the unique\nattributes of our knowledge graph, including directed and undirected\nrelationships, attributed nodes, and minimal annotated competitor connections.\nTo address these challenges, we propose a novel graph embedding model,\nJPEC(JPMorgan Proximity Embedding for Competitor Detection), which utilizes\ngraph neural network to learn from both first-order and second-order node\nproximity together with vital features for competitor retrieval. JPEC had\noutperformed most existing models in extensive experiments, showcasing its\neffectiveness in competitor retrieval.",
      "tldr_zh": "该研究探讨了在金融知识图谱中应用图嵌入技术（如 Graph Neural Networks, GNNs）来识别竞争对手，解决了现有 SOTA 模型在处理有向/无向关系、属性节点和最小标注连接时的挑战。作者提出了一种新颖的模型 JPEC（JPMorgan Proximity Embedding for Competitor Detection），它利用 GNNs 学习第一阶和第二阶节点邻近性以及关键特征，以提升竞争对手检索的准确性。在广泛实验中，JPEC 表现优于大多数现有模型，展示了其在金融知识图谱分析中的有效性。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CE"
      ],
      "primary_category": "cs.IR",
      "comment": "5 pages, 4 figures, accepted by SIGIR'24",
      "pdf_url": "http://arxiv.org/pdf/2411.02692v1",
      "published_date": "2024-11-05 00:39:22 UTC",
      "updated_date": "2024-11-05 00:39:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-20T21:47:25.491973"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 101,
  "processed_papers_count": 101,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-20T21:50:07.724453"
}