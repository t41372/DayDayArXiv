[
  {
    "arxiv_id": "2501.11790v3",
    "title": "Benchmarking Large Language Models via Random Variables",
    "authors": [
      "Zijin Hong",
      "Hao Wu",
      "Su Dong",
      "Junnan Dong",
      "Yilin Xiao",
      "Yujing Zhang",
      "Zhu Wang",
      "Feiran Huang",
      "Linyi Li",
      "Hongxia Yang",
      "Xiao Huang"
    ],
    "abstract": "Recent studies have raised concerns about the reliability of current\nmathematical benchmarks, highlighting issues such as simplistic design and\npotential data contamination. Therefore, creating a reliable benchmark that\neffectively evaluates the genuine capabilities of large language models (LLMs)\nin mathematical reasoning remains a significant challenge. To address this, we\npropose RV-Bench, a framework for Benchmarking LLMs via Random Variables in\nmathematical reasoning. Specifically, the background content of a random\nvariable question (RV question) mirrors the original problem in existing\nbenchmarks, but the variable combinations are randomized, making it \"unseen\" by\nthe LLMs. Models must completely understand the question pattern of the\noriginal problem to correctly answer RV questions with various variable values.\nAs a result, the LLM's genuine capability in mathematical reasoning is\nreflected by its accuracy and robustness on RV-Bench. We conducted extensive\nexperiments on over 30 representative LLMs across more than 1000 RV questions.\nOur findings suggest that LLMs exhibit an imbalance in proficiency between\nencountered and \"unseen\" data domains. Proficiency generalization across\nsimilar mathematical reasoning tasks is verified to be limited by accuracy and\nrobustness, but it can still be enhanced through test-time scaling.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Under review",
    "pdf_url": "http://arxiv.org/pdf/2501.11790v3",
    "published_date": "2025-01-20 23:41:22 UTC",
    "updated_date": "2025-03-15 09:20:49 UTC"
  },
  {
    "arxiv_id": "2501.11782v1",
    "title": "Human-AI Collaborative Game Testing with Vision Language Models",
    "authors": [
      "Boran Zhang",
      "Muhan Xu",
      "Zhijun Pan"
    ],
    "abstract": "As modern video games become increasingly complex, traditional manual testing\nmethods are proving costly and inefficient, limiting the ability to ensure\nhigh-quality game experiences. While advancements in Artificial Intelligence\n(AI) offer the potential to assist human testers, the effectiveness of AI in\ntruly enhancing real-world human performance remains underexplored. This study\ninvestigates how AI can improve game testing by developing and experimenting\nwith an AI-assisted workflow that leverages state-of-the-art machine learning\nmodels for defect detection. Through an experiment involving 800 test cases and\n276 participants of varying backgrounds, we evaluate the effectiveness of AI\nassistance under four conditions: with or without AI support, and with or\nwithout detailed knowledge of defects and design documentation. The results\nindicate that AI assistance significantly improves defect identification\nperformance, particularly when paired with detailed knowledge. However,\nchallenges arise when AI errors occur, negatively impacting human\ndecision-making. Our findings show the importance of optimizing human-AI\ncollaboration and implementing strategies to mitigate the effects of AI\ninaccuracies. By this research, we demonstrate AI's potential and problems in\nenhancing efficiency and accuracy in game testing workflows and offers\npractical insights for integrating AI into the testing process.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "Experiment Report",
    "pdf_url": "http://arxiv.org/pdf/2501.11782v1",
    "published_date": "2025-01-20 23:14:23 UTC",
    "updated_date": "2025-01-20 23:14:23 UTC"
  },
  {
    "arxiv_id": "2501.12420v2",
    "title": "Consolidating TinyML Lifecycle with Large Language Models: Reality, Illusion, or Opportunity?",
    "authors": [
      "Guanghan Wu",
      "Sasu Tarkoma",
      "Roberto Morabito"
    ],
    "abstract": "The evolving requirements of Internet of Things (IoT) applications are\ndriving an increasing shift toward bringing intelligence to the edge, enabling\nreal-time insights and decision-making within resource-constrained\nenvironments. Tiny Machine Learning (TinyML) has emerged as a key enabler of\nthis evolution, facilitating the deployment of ML models on devices such as\nmicrocontrollers and embedded systems. However, the complexity of managing the\nTinyML lifecycle, including stages such as data processing, model optimization\nand conversion, and device deployment, presents significant challenges and\noften requires substantial human intervention. Motivated by these challenges,\nwe began exploring whether Large Language Models (LLMs) could help automate and\nstreamline the TinyML lifecycle. We developed a framework that leverages the\nnatural language processing (NLP) and code generation capabilities of LLMs to\nreduce development time and lower the barriers to entry for TinyML deployment.\nThrough a case study involving a computer vision classification model, we\ndemonstrate the framework's ability to automate key stages of the TinyML\nlifecycle. Our findings suggest that LLM-powered automation holds potential for\nimproving the lifecycle development process and adapting to diverse\nrequirements. However, while this approach shows promise, there remain\nobstacles and limitations, particularly in achieving fully automated solutions.\nThis paper sheds light on both the challenges and opportunities of integrating\nLLMs into TinyML workflows, providing insights into the path forward for\nefficient, AI-assisted embedded system development.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "This paper has been accepted for publication in the IEEE Internet of\n  Things Magazine (Special Issue on Applications of Large Language Models in\n  IoT). The copyright will be transferred to IEEE upon publication. A\n  preliminary version of this work was presented at the Edge AI Foundation\n  event Beyond LLMs and Chatbots: The Journey to Generative AI at the Edge\n  (https://youtu.be/aFWfisdjQIs)",
    "pdf_url": "http://arxiv.org/pdf/2501.12420v2",
    "published_date": "2025-01-20 22:20:57 UTC",
    "updated_date": "2025-04-05 16:29:10 UTC"
  },
  {
    "arxiv_id": "2501.16360v1",
    "title": "Momentum Contrastive Learning with Enhanced Negative Sampling and Hard Negative Filtering",
    "authors": [
      "Duy Hoang",
      "Huy Ngo",
      "Khoi Pham",
      "Tri Nguyen",
      "Gia Bao",
      "Huy Phan"
    ],
    "abstract": "Contrastive learning has become pivotal in unsupervised representation\nlearning, with frameworks like Momentum Contrast (MoCo) effectively utilizing\nlarge negative sample sets to extract discriminative features. However,\ntraditional approaches often overlook the full potential of key embeddings and\nare susceptible to performance degradation from noisy negative samples in the\nmemory bank. This study addresses these challenges by proposing an enhanced\ncontrastive learning framework that incorporates two key innovations. First, we\nintroduce a dual-view loss function, which ensures balanced optimization of\nboth query and key embeddings, improving representation quality. Second, we\ndevelop a selective negative sampling strategy that emphasizes the most\nchallenging negatives based on cosine similarity, mitigating the impact of\nnoise and enhancing feature discrimination. Extensive experiments demonstrate\nthat our framework achieves superior performance on downstream tasks,\ndelivering robust and well-structured representations. These results highlight\nthe potential of optimized contrastive mechanisms to advance unsupervised\nlearning and extend its applicability across domains such as computer vision\nand natural language processing",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16360v1",
    "published_date": "2025-01-20 22:01:52 UTC",
    "updated_date": "2025-01-20 22:01:52 UTC"
  },
  {
    "arxiv_id": "2501.11765v1",
    "title": "Is logical analysis performed by transformers taking place in self-attention or in the fully connected part?",
    "authors": [
      "Evgeniy Shin",
      "Heinrich Matzinger"
    ],
    "abstract": "Transformers architecture apply self-attention to tokens represented as\nvectors, before a fully connected (neuronal network) layer. These two parts can\nbe layered many times. Traditionally, self-attention is seen as a mechanism for\naggregating information before logical operations are performed by the fully\nconnected layer. In this paper, we show, that quite counter-intuitively, the\nlogical analysis can also be performed within the self-attention. For this we\nimplement a handcrafted single-level encoder layer which performs the logical\nanalysis within self-attention. We then study the scenario in which a one-level\ntransformer model undergoes self-learning using gradient descent. We\ninvestigate whether the model utilizes fully connected layers or self-attention\nmechanisms for logical analysis when it has the choice. Given that gradient\ndescent can become stuck at undesired zeros, we explicitly calculate these\nunwanted zeros and find ways to avoid them. We do all this in the context of\npredicting grammatical category pairs of adjacent tokens in a text. We believe\nthat our findings have broader implications for understanding the potential\nlogical operations performed by self-attention.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T30",
      "I.2.4"
    ],
    "primary_category": "cs.CL",
    "comment": "42 pages, 3 figures, to be submitted",
    "pdf_url": "http://arxiv.org/pdf/2501.11765v1",
    "published_date": "2025-01-20 21:58:35 UTC",
    "updated_date": "2025-01-20 21:58:35 UTC"
  },
  {
    "arxiv_id": "2501.17167v2",
    "title": "QualityFlow: An Agentic Workflow for Program Synthesis Controlled by LLM Quality Checks",
    "authors": [
      "Yaojie Hu",
      "Qiang Zhou",
      "Qihong Chen",
      "Xiaopeng Li",
      "Linbo Liu",
      "Dejiao Zhang",
      "Amit Kachroo",
      "Talha Oz",
      "Omer Tripp"
    ],
    "abstract": "We introduce QualityFlow, a dynamic agentic workflow for program synthesis.\nGiven the English description of a programming problem and a set of unit tests,\nthe model's goal is to synthesize the correct program that solves the problem\nand passes the tests. QualityFlow includes large language model (LLM) agents\nresembling a software development team, including code generation, testing, and\nself-debugging. We propose the LLM Quality Checker, which explicitly \"imagines\"\nwhether the synthesized programs' execution would conform to the unit tests.\nThe Quality Checks dynamically control the workflow, including actions to\nsubmit the final answer, clarify the problem statement, and revert previous\nworkflow steps. Our experiments show that the Quality Checker can precisely\naccept any correct program, mitigate faulty synthesized tests, and prevent\npotential workflow deviation. QualityFlow establishes the state-of-the-art\nresults on four program synthesis benchmarks: MBPP, HumanEval, and stricter\nevaluations from MBPP-EvalPlus and HumanEval-EvalPlus.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17167v2",
    "published_date": "2025-01-20 21:47:06 UTC",
    "updated_date": "2025-03-24 19:10:04 UTC"
  },
  {
    "arxiv_id": "2502.15709v2",
    "title": "TutorLLM: Customizing Learning Recommendations with Knowledge Tracing and Retrieval-Augmented Generation",
    "authors": [
      "Zhaoxing Li",
      "Vahid Yazdanpanah",
      "Jindi Wang",
      "Wen Gu",
      "Lei Shi",
      "Alexandra I. Cristea",
      "Sarah Kiden",
      "Sebastian Stein"
    ],
    "abstract": "The integration of AI in education offers significant potential to enhance\nlearning efficiency. Large Language Models (LLMs), such as ChatGPT, Gemini, and\nLlama, allow students to query a wide range of topics, providing unprecedented\nflexibility. However, LLMs face challenges, such as handling varying content\nrelevance and lack of personalization. To address these challenges, we propose\nTutorLLM, a personalized learning recommender LLM system based on Knowledge\nTracing (KT) and Retrieval-Augmented Generation (RAG). The novelty of TutorLLM\nlies in its unique combination of KT and RAG techniques with LLMs, which\nenables dynamic retrieval of context-specific knowledge and provides\npersonalized learning recommendations based on the student's personal learning\nstate. Specifically, this integration allows TutorLLM to tailor responses based\non individual learning states predicted by the Multi-Features with Latent\nRelations BERT-based KT (MLFBK) model and to enhance response accuracy with a\nScraper model. The evaluation includes user assessment questionnaires and\nperformance metrics, demonstrating a 10% improvement in user satisfaction and a\n5\\% increase in quiz scores compared to using general LLMs alone.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.15709v2",
    "published_date": "2025-01-20 21:18:43 UTC",
    "updated_date": "2025-04-27 08:17:49 UTC"
  },
  {
    "arxiv_id": "2501.11747v2",
    "title": "Optimizing Pretraining Data Mixtures with LLM-Estimated Utility",
    "authors": [
      "William Held",
      "Bhargavi Paranjape",
      "Punit Singh Koura",
      "Mike Lewis",
      "Frank Zhang",
      "Todor Mihaylov"
    ],
    "abstract": "Large Language Models improve with increasing amounts of high-quality\ntraining data. However, leveraging larger datasets requires balancing quality,\nquantity, and diversity across sources. After evaluating nine baseline methods\nunder both compute- and data-constrained scenarios, we find token-count\nheuristics outperform manual and learned mixes, indicating that simple\napproaches accounting for dataset size and diversity are surprisingly\neffective. Building on this insight, we propose two complementary approaches:\nUtiliMax, which extends token-based heuristics by incorporating utility\nestimates from reduced-scale ablations, achieving up to a 10.6x speedup over\nmanual baselines; and Model Estimated Data Utility (MEDU), which leverages LLMs\nto estimate data utility from small samples, matching ablation-based\nperformance while reducing computational requirements by $\\sim$200x. Together,\nthese approaches establish a new framework for automated, compute-efficient\ndata mixing that is robust across training regimes.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "10 pages, 8 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11747v2",
    "published_date": "2025-01-20 21:10:22 UTC",
    "updated_date": "2025-01-23 20:45:47 UTC"
  },
  {
    "arxiv_id": "2501.11746v1",
    "title": "SILO: Solving Inverse Problems with Latent Operators",
    "authors": [
      "Ron Raphaeli",
      "Sean Man",
      "Michael Elad"
    ],
    "abstract": "Consistent improvement of image priors over the years has led to the\ndevelopment of better inverse problem solvers. Diffusion models are the\nnewcomers to this arena, posing the strongest known prior to date. Recently,\nsuch models operating in a latent space have become increasingly predominant\ndue to their efficiency. In recent works, these models have been applied to\nsolve inverse problems. Working in the latent space typically requires multiple\napplications of an Autoencoder during the restoration process, which leads to\nboth computational and restoration quality challenges. In this work, we propose\na new approach for handling inverse problems with latent diffusion models,\nwhere a learned degradation function operates within the latent space,\nemulating a known image space degradation. Usage of the learned operator\nreduces the dependency on the Autoencoder to only the initial and final steps\nof the restoration process, facilitating faster sampling and superior\nrestoration quality. We demonstrate the effectiveness of our method on a\nvariety of image restoration tasks and datasets, achieving significant\nimprovements over prior art.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page in https://ronraphaeli.github.io/SILO-website/",
    "pdf_url": "http://arxiv.org/pdf/2501.11746v1",
    "published_date": "2025-01-20 21:09:33 UTC",
    "updated_date": "2025-01-20 21:09:33 UTC"
  },
  {
    "arxiv_id": "2501.11739v2",
    "title": "Episodic memory in AI agents poses risks that should be studied and mitigated",
    "authors": [
      "Chad DeChant"
    ],
    "abstract": "Most current AI models have little ability to store and later retrieve a\nrecord or representation of what they do. In human cognition, episodic memories\nplay an important role in both recall of the past as well as planning for the\nfuture. The ability to form and use episodic memories would similarly enable a\nbroad range of improved capabilities in an AI agent that interacts with and\ntakes actions in the world. Researchers have begun directing more attention to\ndeveloping memory abilities in AI models. It is therefore likely that models\nwith such capability will be become widespread in the near future. This could\nin some ways contribute to making such AI agents safer by enabling users to\nbetter monitor, understand, and control their actions. However, as a new\ncapability with wide applications, we argue that it will also introduce\nsignificant new risks that researchers should begin to study and address. We\noutline these risks and benefits and propose four principles to guide the\ndevelopment of episodic memory capabilities so that these will enhance, rather\nthan undermine, the effort to keep AI safe and trustworthy.",
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted for publication at the 2025 Secure and Trustworthy Machine\n  Learning Conference (SaTML). The final version will be available on IEEE\n  Xplore",
    "pdf_url": "http://arxiv.org/pdf/2501.11739v2",
    "published_date": "2025-01-20 20:54:06 UTC",
    "updated_date": "2025-01-22 15:09:02 UTC"
  },
  {
    "arxiv_id": "2501.11730v1",
    "title": "Transformer Vibration Forecasting for Advancing Rail Safety and Maintenance 4.0",
    "authors": [
      "Darío C. Larese",
      "Almudena Bravo Cerrada",
      "Gabriel Dambrosio Tomei",
      "Alejandro Guerrero-López",
      "Pablo M. Olmos",
      "María Jesús Gómez García"
    ],
    "abstract": "Maintaining railway axles is critical to preventing severe accidents and\nfinancial losses. The railway industry is increasingly interested in advanced\ncondition monitoring techniques to enhance safety and efficiency, moving beyond\ntraditional periodic inspections toward Maintenance 4.0.\n  This study introduces a robust Deep Autoregressive solution that integrates\nseamlessly with existing systems to avert mechanical failures. Our approach\nsimulates and predicts vibration signals under various conditions and fault\nscenarios, improving dataset robustness for more effective detection systems.\nThese systems can alert maintenance needs, preventing accidents preemptively.\nWe use experimental vibration signals from accelerometers on train axles.\n  Our primary contributions include a transformer model, ShaftFormer, designed\nfor processing time series data, and an alternative model incorporating\nspectral methods and enhanced observation models. Simulating vibration signals\nunder diverse conditions mitigates the high cost of obtaining experimental\nsignals for all scenarios. Given the non-stationary nature of railway vibration\nsignals, influenced by speed and load changes, our models address these\ncomplexities, offering a powerful tool for predictive maintenance in the rail\nindustry.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11730v1",
    "published_date": "2025-01-20 20:29:40 UTC",
    "updated_date": "2025-01-20 20:29:40 UTC"
  },
  {
    "arxiv_id": "2501.11715v1",
    "title": "GL-ICNN: An End-To-End Interpretable Convolutional Neural Network for the Diagnosis and Prediction of Alzheimer's Disease",
    "authors": [
      "Wenjie Kang",
      "Lize Jiskoot",
      "Peter De Deyn",
      "Geert Biessels",
      "Huiberdina Koek",
      "Jurgen Claassen",
      "Huub Middelkoop",
      "Wiesje Flier",
      "Willemijn J. Jansen",
      "Stefan Klein",
      "Esther Bron"
    ],
    "abstract": "Deep learning methods based on Convolutional Neural Networks (CNNs) have\nshown great potential to improve early and accurate diagnosis of Alzheimer's\ndisease (AD) dementia based on imaging data. However, these methods have yet to\nbe widely adopted in clinical practice, possibly due to the limited\ninterpretability of deep learning models. The Explainable Boosting Machine\n(EBM) is a glass-box model but cannot learn features directly from input\nimaging data. In this study, we propose a novel interpretable model that\ncombines CNNs and EBMs for the diagnosis and prediction of AD. We develop an\ninnovative training strategy that alternatingly trains the CNN component as a\nfeature extractor and the EBM component as the output block to form an\nend-to-end model. The model takes imaging data as input and provides both\npredictions and interpretable feature importance measures. We validated the\nproposed model on the Alzheimer's Disease Neuroimaging Initiative (ADNI)\ndataset and the Health-RI Parelsnoer Neurodegenerative Diseases Biobank (PND)\nas an external testing set. The proposed model achieved an area-under-the-curve\n(AUC) of 0.956 for AD and control classification, and 0.694 for the prediction\nof conversion of mild cognitive impairment (MCI) to AD on the ADNI cohort. The\nproposed model is a glass-box model that achieves a comparable performance with\nother state-of-the-art black-box models. Our code is publicly available at:\nhttps://anonymous.4open.science/r/GL-ICNN.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "4 pages, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11715v1",
    "published_date": "2025-01-20 19:55:50 UTC",
    "updated_date": "2025-01-20 19:55:50 UTC"
  },
  {
    "arxiv_id": "2501.11705v1",
    "title": "Human services organizations and the responsible integration of AI: Considering ethics and contextualizing risk(s)",
    "authors": [
      "Brian E. Perron",
      "Lauri Goldkind",
      "Zia Qi",
      "Bryan G. Victor"
    ],
    "abstract": "This paper examines the responsible integration of artificial intelligence\n(AI) in human services organizations (HSOs), proposing a nuanced framework for\nevaluating AI applications across multiple dimensions of risk. The authors\nargue that ethical concerns about AI deployment -- including professional\njudgment displacement, environmental impact, model bias, and data laborer\nexploitation -- vary significantly based on implementation context and specific\nuse cases. They challenge the binary view of AI adoption, demonstrating how\ndifferent applications present varying levels of risk that can often be\neffectively managed through careful implementation strategies. The paper\nhighlights promising solutions, such as local large language models, that can\nfacilitate responsible AI integration while addressing common ethical concerns.\nThe authors propose a dimensional risk assessment approach that considers\nfactors like data sensitivity, professional oversight requirements, and\npotential impact on client wellbeing. They conclude by outlining a path forward\nthat emphasizes empirical evaluation, starting with lower-risk applications and\nbuilding evidence-based understanding through careful experimentation. This\napproach enables organizations to maintain high ethical standards while\nthoughtfully exploring how AI might enhance their capacity to serve clients and\ncommunities effectively.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "1 figure. Journal of Technology in Human Services (2025)",
    "pdf_url": "http://arxiv.org/pdf/2501.11705v1",
    "published_date": "2025-01-20 19:38:21 UTC",
    "updated_date": "2025-01-20 19:38:21 UTC"
  },
  {
    "arxiv_id": "2501.11695v2",
    "title": "Spatially-Delineated Domain-Adapted AI Classification: An Application for Oncology Data",
    "authors": [
      "Majid Farhadloo",
      "Arun Sharma",
      "Alexey Leontovich",
      "Svetomir N. Markovic",
      "Shashi Shekhar"
    ],
    "abstract": "Given multi-type point maps from different place-types (e.g., tumor regions),\nour objective is to develop a classifier trained on the source place-type to\naccurately distinguish between two classes of the target place-type based on\ntheir point arrangements. This problem is societally important for many\napplications, such as generating clinical hypotheses for designing new\nimmunotherapies for cancer treatment. The challenge lies in the spatial\nvariability, the inherent heterogeneity and variation observed in spatial\nproperties or arrangements across different locations (i.e., place-types).\nPrevious techniques focus on self-supervised tasks to learn domain-invariant\nfeatures and mitigate domain differences; however, they often neglect the\nunderlying spatial arrangements among data points, leading to significant\ndiscrepancies across different place-types. We explore a novel multi-task\nself-learning framework that targets spatial arrangements, such as spatial\nmix-up masking and spatial contrastive predictive coding, for\nspatially-delineated domain-adapted AI classification. Experimental results on\nreal-world datasets (e.g., oncology data) show that the proposed framework\nprovides higher prediction accuracy than baseline methods.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11695v2",
    "published_date": "2025-01-20 19:20:13 UTC",
    "updated_date": "2025-04-24 01:49:03 UTC"
  },
  {
    "arxiv_id": "2501.14818v1",
    "title": "Eagle 2: Building Post-Training Data Strategies from Scratch for Frontier Vision-Language Models",
    "authors": [
      "Zhiqi Li",
      "Guo Chen",
      "Shilong Liu",
      "Shihao Wang",
      "Vibashan VS",
      "Yishen Ji",
      "Shiyi Lan",
      "Hao Zhang",
      "Yilin Zhao",
      "Subhashree Radhakrishnan",
      "Nadine Chang",
      "Karan Sapra",
      "Amala Sanjay Deshmukh",
      "Tuomas Rintamaki",
      "Matthieu Le",
      "Ilia Karmanov",
      "Lukas Voegtle",
      "Philipp Fischer",
      "De-An Huang",
      "Timo Roman",
      "Tong Lu",
      "Jose M. Alvarez",
      "Bryan Catanzaro",
      "Jan Kautz",
      "Andrew Tao",
      "Guilin Liu",
      "Zhiding Yu"
    ],
    "abstract": "Recently, promising progress has been made by open-source vision-language\nmodels (VLMs) in bringing their capabilities closer to those of proprietary\nfrontier models. However, most open-source models only publish their final\nmodel weights, leaving the critical details of data strategies and\nimplementation largely opaque. In this work, we address VLM post-training from\na data-centric perspective, showing the key role of data strategy in developing\nfrontier VLMs. By studying and building our post-training data strategy from\nscratch, we share detailed insights into the development processes, aiming to\nbenefit the development of competitive models for the open-source community.\nOur introduced data strategy, together with training recipes and model design,\nleads to a family of performant VLMs named Eagle2. Specifically, Eagle2-9B\nachieves state-of-the-art results across various multimodal benchmarks,\nmatching certain competitive models with up to 70B parameters.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.14818v1",
    "published_date": "2025-01-20 18:40:47 UTC",
    "updated_date": "2025-01-20 18:40:47 UTC"
  },
  {
    "arxiv_id": "2501.13120v1",
    "title": "Multilinguality in LLM-Designed Reward Functions for Restless Bandits: Effects on Task Performance and Fairness",
    "authors": [
      "Ambreesh Parthasarathy",
      "Chandrasekar Subramanian",
      "Ganesh Senrayan",
      "Shreyash Adappanavar",
      "Aparna Taneja",
      "Balaraman Ravindran",
      "Milind Tambe"
    ],
    "abstract": "Restless Multi-Armed Bandits (RMABs) have been successfully applied to\nresource allocation problems in a variety of settings, including public health.\nWith the rapid development of powerful large language models (LLMs), they are\nincreasingly used to design reward functions to better match human preferences.\nRecent work has shown that LLMs can be used to tailor automated allocation\ndecisions to community needs using language prompts. However, this has been\nstudied primarily for English prompts and with a focus on task performance\nonly. This can be an issue since grassroots workers, especially in developing\ncountries like India, prefer to work in local languages, some of which are\nlow-resource. Further, given the nature of the problem, biases along population\ngroups unintended by the user are also undesirable. In this work, we study the\neffects on both task performance and fairness when the DLM algorithm, a recent\nwork on using LLMs to design reward functions for RMABs, is prompted with\nnon-English language commands. Specifically, we run the model on a synthetic\nenvironment for various prompts translated into multiple languages. The prompts\nthemselves vary in complexity. Our results show that the LLM-proposed reward\nfunctions are significantly better when prompted in English compared to other\nlanguages. We also find that the exact phrasing of the prompt impacts task\nperformance. Further, as prompt complexity increases, performance worsens for\nall languages; however, it is more robust with English prompts than with\nlower-resource languages. On the fairness side, we find that low-resource\nlanguages and more complex prompts are both highly likely to create unfairness\nalong unintended dimensions.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at the AAAI-2025 Deployable AI Workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.13120v1",
    "published_date": "2025-01-20 18:14:37 UTC",
    "updated_date": "2025-01-20 18:14:37 UTC"
  },
  {
    "arxiv_id": "2501.11639v2",
    "title": "StAyaL | Multilingual Style Transfer",
    "authors": [
      "Karishma Thakrar",
      "Katrina Lawrence",
      "Kyle Howard"
    ],
    "abstract": "Stylistic text generation plays a vital role in enhancing communication by\nreflecting the nuances of individual expression. This paper presents a novel\napproach for generating text in a specific speaker's style across different\nlanguages. We show that by leveraging only 100 lines of text, an individuals\nunique style can be captured as a high-dimensional embedding, which can be used\nfor both text generation and stylistic translation. This methodology breaks\ndown the language barrier by transferring the style of a speaker between\nlanguages. The paper is structured into three main phases: augmenting the\nspeaker's data with stylistically consistent external sources, separating style\nfrom content using machine learning and deep learning techniques, and\ngenerating an abstract style profile by mean pooling the learned embeddings.\nThe proposed approach is shown to be topic-agnostic, with test accuracy and F1\nscores of 74.9% and 0.75, respectively. The results demonstrate the potential\nof the style profile for multilingual communication, paving the way for further\napplications in personalized content generation and cross-linguistic stylistic\ntransfer.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "The primary authors, Karishma Thakrar and Katrina Lawrence,\n  contributed equally to this work",
    "pdf_url": "http://arxiv.org/pdf/2501.11639v2",
    "published_date": "2025-01-20 18:13:18 UTC",
    "updated_date": "2025-01-22 04:22:36 UTC"
  },
  {
    "arxiv_id": "2501.11632v2",
    "title": "Biomedical Knowledge Graph: A Survey of Domains, Tasks, and Real-World Applications",
    "authors": [
      "Yuxing Lu",
      "Sin Yee Goi",
      "Xukai Zhao",
      "Jinzhuo Wang"
    ],
    "abstract": "Biomedical knowledge graphs (BKGs) have emerged as powerful tools for\norganizing and leveraging the vast and complex data found across the biomedical\nfield. Yet, current reviews of BKGs often limit their scope to specific domains\nor methods, overlooking the broader landscape and the rapid technological\nprogress reshaping it. In this survey, we address this gap by offering a\nsystematic review of BKGs from three core perspectives: domains, tasks, and\napplications. We begin by examining how BKGs are constructed from diverse data\nsources, including molecular interactions, pharmacological datasets, and\nclinical records. Next, we discuss the essential tasks enabled by BKGs,\nfocusing on knowledge management, retrieval, reasoning, and interpretation.\nFinally, we highlight real-world applications in precision medicine, drug\ndiscovery, and scientific research, illustrating the translational impact of\nBKGs across multiple sectors. By synthesizing these perspectives into a unified\nframework, this survey not only clarifies the current state of BKG research but\nalso establishes a foundation for future exploration, enabling both innovative\nmethodological advances and practical implementations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CE",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "45 pages, 4 figures, 3 tables. Updated figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11632v2",
    "published_date": "2025-01-20 18:02:03 UTC",
    "updated_date": "2025-01-22 06:17:14 UTC"
  },
  {
    "arxiv_id": "2501.11631v1",
    "title": "Noise-Agnostic Multitask Whisper Training for Reducing False Alarm Errors in Call-for-Help Detection",
    "authors": [
      "Myeonghoon Ryu",
      "June-Woo Kim",
      "Minseok Oh",
      "Suji Lee",
      "Han Park"
    ],
    "abstract": "Keyword spotting is often implemented by keyword classifier to the encoder in\nacoustic models, enabling the classification of predefined or open vocabulary\nkeywords. Although keyword spotting is a crucial task in various applications\nand can be extended to call-for-help detection in emergencies, however, the\nprevious method often suffers from scalability limitations due to retraining\nrequired to introduce new keywords or adapt to changing contexts. We explore a\nsimple yet effective approach that leverages off-the-shelf pretrained ASR\nmodels to address these challenges, especially in call-for-help detection\nscenarios. Furthermore, we observed a substantial increase in false alarms when\ndeploying call-for-help detection system in real-world scenarios due to noise\nintroduced by microphones or different environments. To address this, we\npropose a novel noise-agnostic multitask learning approach that integrates a\nnoise classification head into the ASR encoder. Our method enhances the model's\nrobustness to noisy environments, leading to a significant reduction in false\nalarms and improved overall call-for-help performance. Despite the added\ncomplexity of multitask learning, our approach is computationally efficient and\nprovides a promising solution for call-for-help detection in real-world\nscenarios.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted to ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.11631v1",
    "published_date": "2025-01-20 18:01:42 UTC",
    "updated_date": "2025-01-20 18:01:42 UTC"
  },
  {
    "arxiv_id": "2501.11623v1",
    "title": "Early evidence of how LLMs outperform traditional systems on OCR/HTR tasks for historical records",
    "authors": [
      "Seorin Kim",
      "Julien Baudru",
      "Wouter Ryckbosch",
      "Hugues Bersini",
      "Vincent Ginis"
    ],
    "abstract": "We explore the ability of two LLMs -- GPT-4o and Claude Sonnet 3.5 -- to\ntranscribe historical handwritten documents in a tabular format and compare\ntheir performance to traditional OCR/HTR systems: EasyOCR, Keras, Pytesseract,\nand TrOCR. Considering the tabular form of the data, two types of experiments\nare executed: one where the images are split line by line and the other where\nthe entire scan is used as input. Based on CER and BLEU, we demonstrate that\nLLMs outperform the conventional OCR/HTR methods. Moreover, we also compare the\nevaluated CER and BLEU scores to human evaluations to better judge the outputs\nof whole-scan experiments and understand influential factors for CER and BLEU.\nCombining judgments from all the evaluation metrics, we conclude that two-shot\nGPT-4o for line-by-line images and two-shot Claude Sonnet 3.5 for whole-scan\nimages yield the transcriptions of the historical records most similar to the\nground truth.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "15 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11623v1",
    "published_date": "2025-01-20 17:46:12 UTC",
    "updated_date": "2025-01-20 17:46:12 UTC"
  },
  {
    "arxiv_id": "2501.11613v7",
    "title": "Conversation Routines: A Prompt Engineering Framework for Task-Oriented Dialog Systems",
    "authors": [
      "Giorgio Robino"
    ],
    "abstract": "This study introduces Conversation Routines (CR), a structured prompt\nengineering framework for developing task-oriented dialog systems using Large\nLanguage Models (LLMs). While LLMs demonstrate remarkable natural language\nunderstanding capabilities, engineering them to reliably execute complex\nbusiness workflows remains challenging. The proposed CR framework enables the\ndevelopment of Conversation Agentic Systems (CAS) through natural language\nspecifications, embedding task-oriented logic within LLM prompts. This approach\nprovides a systematic methodology for designing and implementing complex\nconversational workflows while maintaining behavioral consistency. We\ndemonstrate the framework's effectiveness through two proof-of-concept\nimplementations: a Train Ticket Booking System and an Interactive\nTroubleshooting Copilot. These case studies validate CR's capability to encode\nsophisticated behavioral patterns and decision logic while preserving natural\nconversational flexibility. Results show that CR enables domain experts to\ndesign conversational workflows in natural language while leveraging custom\nfunctions (tools) developed by software engineers, creating an efficient\ndivision of responsibilities where developers focus on core API implementation\nand domain experts handle conversation design. While the framework shows\npromise in accessibility and adaptability, we identify key challenges including\ncomputational overhead, non-deterministic behavior, and domain-specific logic\noptimization. Future research directions include CR evaluation methods based on\nprompt engineering frameworks driven by goal-oriented grading criteria,\nimproving scalability for complex multi-agent interactions, and enhancing\nsystem robustness to address the identified limitations across diverse business\napplications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.ET",
      "cs.HC",
      "cs.PL"
    ],
    "primary_category": "cs.CL",
    "comment": "Minor typos revision",
    "pdf_url": "http://arxiv.org/pdf/2501.11613v7",
    "published_date": "2025-01-20 17:19:02 UTC",
    "updated_date": "2025-02-24 17:40:38 UTC"
  },
  {
    "arxiv_id": "2501.11599v1",
    "title": "SR-FoT: A Syllogistic-Reasoning Framework of Thought for Large Language Models Tackling Knowledge-based Reasoning Tasks",
    "authors": [
      "Wentao Wan",
      "Zhuojie Yang",
      "Yongcan Chen",
      "Chenglin Luo",
      "Ruilin Wang",
      "Kehao Cai",
      "Nan Kang",
      "Liang Lin",
      "Keze Wang"
    ],
    "abstract": "Deductive reasoning is a crucial logical capability that assists us in\nsolving complex problems based on existing knowledge. Although augmented by\nChain-of-Thought prompts, Large Language Models (LLMs) might not follow the\ncorrect reasoning paths. Enhancing the deductive reasoning abilities of LLMs,\nand leveraging their extensive built-in knowledge for various reasoning tasks,\nremains an open question. Attempting to mimic the human deductive reasoning\nparadigm, we propose a multi-stage Syllogistic-Reasoning Framework of Thought\n(SR-FoT) that enables LLMs to perform syllogistic deductive reasoning to handle\ncomplex knowledge-based reasoning tasks. Our SR-FoT begins by interpreting the\nquestion and then uses the interpretation and the original question to propose\na suitable major premise. It proceeds by generating and answering minor premise\nquestions in two stages to match the minor premises. Finally, it guides LLMs to\nuse the previously generated major and minor premises to perform syllogistic\ndeductive reasoning to derive the answer to the original question. Extensive\nand thorough experiments on knowledge-based reasoning tasks have demonstrated\nthe effectiveness and advantages of our SR-FoT.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "This paper has been accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.11599v1",
    "published_date": "2025-01-20 17:00:41 UTC",
    "updated_date": "2025-01-20 17:00:41 UTC"
  },
  {
    "arxiv_id": "2501.11597v1",
    "title": "Fairness Testing through Extreme Value Theory",
    "authors": [
      "Verya Monjezi",
      "Ashutosh Trivedi",
      "Vladik Kreinovich",
      "Saeid Tizpaz-Niari"
    ],
    "abstract": "Data-driven software is increasingly being used as a critical component of\nautomated decision-support systems. Since this class of software learns its\nlogic from historical data, it can encode or amplify discriminatory practices.\nPrevious research on algorithmic fairness has focused on improving average-case\nfairness. On the other hand, fairness at the extreme ends of the spectrum,\nwhich often signifies lasting and impactful shifts in societal attitudes, has\nreceived significantly less emphasis.\n  Leveraging the statistics of extreme value theory (EVT), we propose a novel\nfairness criterion called extreme counterfactual discrimination (ECD). This\ncriterion estimates the worst-case amounts of disadvantage in outcomes for\nindividuals solely based on their memberships in a protected group. Utilizing\ntools from search-based software engineering and generative AI, we present a\nrandomized algorithm that samples a statistically significant set of points\nfrom the tail of ML outcome distributions even if the input dataset lacks a\nsufficient number of relevant samples.\n  We conducted several experiments on four ML models (deep neural networks,\nlogistic regression, and random forests) over 10 socially relevant tasks from\nthe literature on algorithmic fairness. First, we evaluate the generative AI\nmethods and find that they generate sufficient samples to infer valid EVT\ndistribution in 95% of cases. Remarkably, we found that the prevalent bias\nmitigators reduce the average-case discrimination but increase the worst-case\ndiscrimination significantly in 5% of cases. We also observed that even the\ntail-aware mitigation algorithm -- MiniMax-Fairness -- increased the worst-case\ndiscrimination in 30% of cases. We propose a novel ECD-based mitigator that\nimproves fairness in the tail in 90% of cases with no degradation of the\naverage-case discrimination.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CY",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "In IEEE/ACM 47th International Conference on Software Engineering\n  (ICSE'25)",
    "pdf_url": "http://arxiv.org/pdf/2501.11597v1",
    "published_date": "2025-01-20 16:56:10 UTC",
    "updated_date": "2025-01-20 16:56:10 UTC"
  },
  {
    "arxiv_id": "2501.13956v1",
    "title": "Zep: A Temporal Knowledge Graph Architecture for Agent Memory",
    "authors": [
      "Preston Rasmussen",
      "Pavlo Paliychuk",
      "Travis Beauvais",
      "Jack Ryan",
      "Daniel Chalef"
    ],
    "abstract": "We introduce Zep, a novel memory layer service for AI agents that outperforms\nthe current state-of-the-art system, MemGPT, in the Deep Memory Retrieval (DMR)\nbenchmark. Additionally, Zep excels in more comprehensive and challenging\nevaluations than DMR that better reflect real-world enterprise use cases. While\nexisting retrieval-augmented generation (RAG) frameworks for large language\nmodel (LLM)-based agents are limited to static document retrieval, enterprise\napplications demand dynamic knowledge integration from diverse sources\nincluding ongoing conversations and business data. Zep addresses this\nfundamental limitation through its core component Graphiti -- a\ntemporally-aware knowledge graph engine that dynamically synthesizes both\nunstructured conversational data and structured business data while maintaining\nhistorical relationships. In the DMR benchmark, which the MemGPT team\nestablished as their primary evaluation metric, Zep demonstrates superior\nperformance (94.8% vs 93.4%). Beyond DMR, Zep's capabilities are further\nvalidated through the more challenging LongMemEval benchmark, which better\nreflects enterprise use cases through complex temporal reasoning tasks. In this\nevaluation, Zep achieves substantial results with accuracy improvements of up\nto 18.5% while simultaneously reducing response latency by 90% compared to\nbaseline implementations. These results are particularly pronounced in\nenterprise-critical tasks such as cross-session information synthesis and\nlong-term context maintenance, demonstrating Zep's effectiveness for deployment\nin real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "12 pages, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.13956v1",
    "published_date": "2025-01-20 16:52:48 UTC",
    "updated_date": "2025-01-20 16:52:48 UTC"
  },
  {
    "arxiv_id": "2501.11592v2",
    "title": "Training-free Ultra Small Model for Universal Sparse Reconstruction in Compressed Sensing",
    "authors": [
      "Chaoqing Tang",
      "Huanze Zhuang",
      "Guiyun Tian",
      "Zhenli Zeng",
      "Yi Ding",
      "Wenzhong Liu",
      "Xiang Bai"
    ],
    "abstract": "Pre-trained large models attract widespread attention in recent years, but\nthey face challenges in applications that require high interpretability or have\nlimited resources, such as physical sensing, medical imaging, and\nbioinformatics. Compressed Sensing (CS) is a well-proved theory that drives\nmany recent breakthroughs in these applications. However, as a typical\nunder-determined linear system, CS suffers from excessively long sparse\nreconstruction times when using traditional iterative methods, particularly\nwith large-scale data. Current AI methods like deep unfolding fail to\nsubstitute them because pre-trained models exhibit poor generality beyond their\ntraining conditions and dataset distributions, or lack interpretability.\nInstead of following the big model fervor, this paper proposes ultra-small\nartificial neural models called coefficients learning (CL), enabling\ntraining-free and rapid sparse reconstruction while perfectly inheriting the\ngenerality and interpretability of traditional iterative methods, bringing new\nfeature of incorporating prior knowledges. In CL, a signal of length $n$ only\nneeds a minimal of $n$ trainable parameters. A case study model called CLOMP is\nimplemented for evaluation. Experiments are conducted on both synthetic and\nreal one-dimensional and two-dimensional signals, demonstrating significant\nimprovements in efficiency and accuracy. Compared to representative iterative\nmethods, CLOMP improves efficiency by 100 to 1000 folds for large-scale data.\nTest results on eight diverse image datasets indicate that CLOMP improves\nstructural similarity index by 292%, 98%, 45% for sampling rates of 0.1, 0.3,\n0.5, respectively. We believe this method can truly usher CS reconstruction\ninto the AI era, benefiting countless under-determined linear systems that rely\non sparse solution.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11592v2",
    "published_date": "2025-01-20 16:50:59 UTC",
    "updated_date": "2025-01-23 12:43:18 UTC"
  },
  {
    "arxiv_id": "2501.11587v2",
    "title": "Recurrent Diffusion for Large-Scale Parameter Generation",
    "authors": [
      "Kai Wang",
      "Dongwen Tang",
      "Wangbo Zhao",
      "Konstantin Schürholt",
      "Zhangyang Wang",
      "Yang You"
    ],
    "abstract": "Parameter generation has long struggled to match the scale of today large\nvision and language models, curbing its broader utility. In this paper, we\nintroduce Recurrent Diffusion for Large Scale Parameter Generation (RPG), a\nnovel framework that generates full neural network parameters up to hundreds of\nmillions on a single GPU. Our approach first partitions a networks parameters\ninto non-overlapping tokens, each corresponding to a distinct portion of the\nmodel. A recurrent mechanism then learns the inter token relationships,\nproducing prototypes which serve as conditions for a diffusion process that\nultimately synthesizes the full parameters. Across a spectrum of architectures\nand tasks including ResNets, ConvNeXts and ViTs on ImageNet 1K and COCO, and\neven LoRA based LLMs RPG achieves performance on par with fully trained\nnetworks while avoiding excessive memory overhead. Notably, it generalizes\nbeyond its training set to generate valid parameters for previously unseen\ntasks, highlighting its flexibility in dynamic and open ended scenarios. By\novercoming the longstanding memory and scalability barriers, RPG serves as a\ncritical advance in AI generating AI, potentially enabling efficient weight\ngeneration at scales previously deemed infeasible.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Generating 200 million parameters in just minutes",
    "pdf_url": "http://arxiv.org/pdf/2501.11587v2",
    "published_date": "2025-01-20 16:46:26 UTC",
    "updated_date": "2025-02-11 03:29:30 UTC"
  },
  {
    "arxiv_id": "2502.10399v1",
    "title": "Data Stewardship Decoded: Mapping Its Diverse Manifestations and Emerging Relevance at a time of AI",
    "authors": [
      "Stefaan Verhulst"
    ],
    "abstract": "Data stewardship has become a critical component of modern data governance,\nespecially with the growing use of artificial intelligence (AI). Despite its\nincreasing importance, the concept of data stewardship remains ambiguous and\nvaries in its application. This paper explores four distinct manifestations of\ndata stewardship to clarify its emerging position in the data governance\nlandscape. These manifestations include a) data stewardship as a set of\ncompetencies and skills, b) a function or role within organizations, c) an\nintermediary organization facilitating collaborations, and d) a set of guiding\nprinciples. The paper subsequently outlines the core competencies required for\neffective data stewardship, explains the distinction between data stewards and\nChief Data Officers (CDOs), and details the intermediary role of stewards in\nbridging gaps between data holders and external stakeholders. It also explores\nkey principles aligned with the FAIR framework (Findable, Accessible,\nInteroperable, Reusable) and introduces the emerging principle of AI readiness\nto ensure data meets the ethical and technical requirements of AI systems. The\npaper emphasizes the importance of data stewardship in enhancing data\ncollaboration, fostering public value, and managing data reuse responsibly,\nparticularly in the era of AI. It concludes by identifying challenges and\nopportunities for advancing data stewardship, including the need for\nstandardized definitions, capacity building efforts, and the creation of a\nprofessional association for data stewardship.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.DB"
    ],
    "primary_category": "cs.CY",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2502.10399v1",
    "published_date": "2025-01-20 16:24:22 UTC",
    "updated_date": "2025-01-20 16:24:22 UTC"
  },
  {
    "arxiv_id": "2501.11560v1",
    "title": "Explainable Lane Change Prediction for Near-Crash Scenarios Using Knowledge Graph Embeddings and Retrieval Augmented Generation",
    "authors": [
      "M. Manzour",
      "A. Ballardini",
      "R. Izquierdo",
      "M. Á. Sotelo"
    ],
    "abstract": "Lane-changing maneuvers, particularly those executed abruptly or in risky\nsituations, are a significant cause of road traffic accidents. However, current\nresearch mainly focuses on predicting safe lane changes. Furthermore, existing\naccident datasets are often based on images only and lack comprehensive sensory\ndata. In this work, we focus on predicting risky lane changes using the CRASH\ndataset (our own collected dataset specifically for risky lane changes), and\nsafe lane changes (using the HighD dataset). Then, we leverage KG and Bayesian\ninference to predict these maneuvers using linguistic contextual information,\nenhancing the model's interpretability and transparency. The model achieved a\n91.5% f1-score with anticipation time extending to four seconds for risky lane\nchanges, and a 90.0% f1-score for predicting safe lane changes with the same\nanticipation time. We validate our model by integrating it into a vehicle\nwithin the CARLA simulator in scenarios that involve risky lane changes. The\nmodel managed to anticipate sudden lane changes, thus providing automated\nvehicles with further time to plan and execute appropriate safe reactions.\nFinally, to enhance the explainability of our model, we utilize RAG to provide\nclear and natural language explanations for the given prediction.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.IR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11560v1",
    "published_date": "2025-01-20 16:02:26 UTC",
    "updated_date": "2025-01-20 16:02:26 UTC"
  },
  {
    "arxiv_id": "2502.10398v2",
    "title": "Practical Application and Limitations of AI Certification Catalogues in the Light of the AI Act",
    "authors": [
      "Gregor Autischer",
      "Kerstin Waxnegger",
      "Dominik Kowald"
    ],
    "abstract": "In this work-in-progress, we investigate the certification of AI systems,\nfocusing on the practical application and limitations of existing certification\ncatalogues in the light of the AI Act by attempting to certify a publicly\navailable AI system. We aim to evaluate how well current approaches work to\neffectively certify an AI system, and how publicly accessible AI systems, that\nmight not be actively maintained or initially intended for certification, can\nbe selected and used for a sample certification process. Our methodology\ninvolves leveraging the Fraunhofer AI Assessment Catalogue as a comprehensive\ntool to systematically assess an AI model's compliance with certification\nstandards. We find that while the catalogue effectively structures the\nevaluation process, it can also be cumbersome and time-consuming to use. We\nobserve the limitations of an AI system that has no active development team\nanymore and highlighted the importance of complete system documentation.\nFinally, we identify some limitations of the certification catalogues used and\nproposed ideas on how to streamline the certification process.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CY",
    "comment": "Bachelor thesis at Graz University of Technology, in preparation for\n  a conference paper submission at EWAF'25",
    "pdf_url": "http://arxiv.org/pdf/2502.10398v2",
    "published_date": "2025-01-20 15:54:57 UTC",
    "updated_date": "2025-02-18 07:59:54 UTC"
  },
  {
    "arxiv_id": "2502.07790v1",
    "title": "Can Generative AI be Egalitarian?",
    "authors": [
      "Philip Feldman",
      "James R. Foulds",
      "Shimei Pan"
    ],
    "abstract": "The recent explosion of \"foundation\" generative AI models has been built upon\nthe extensive extraction of value from online sources, often without\ncorresponding reciprocation. This pattern mirrors and intensifies the\nextractive practices of surveillance capitalism, while the potential for\nenormous profit has challenged technology organizations' commitments to\nresponsible AI practices, raising significant ethical and societal concerns.\nHowever, a promising alternative is emerging: the development of models that\nrely on content willingly and collaboratively provided by users. This article\nexplores this \"egalitarian\" approach to generative AI, taking inspiration from\nthe successful model of Wikipedia. We explore the potential implications of\nthis approach for the design, development, and constraints of future foundation\nmodels. We argue that such an approach is not only ethically sound but may also\nlead to models that are more responsive to user needs, more diverse in their\ntraining data, and ultimately more aligned with societal values. Furthermore,\nwe explore potential challenges and limitations of this approach, including\nissues of scalability, quality control, and potential biases inherent in\nvolunteer-contributed content.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "K.4.1"
    ],
    "primary_category": "cs.CY",
    "comment": "14 pages, 5 figures",
    "pdf_url": "http://arxiv.org/pdf/2502.07790v1",
    "published_date": "2025-01-20 15:40:44 UTC",
    "updated_date": "2025-01-20 15:40:44 UTC"
  },
  {
    "arxiv_id": "2501.11533v1",
    "title": "The impact of intrinsic rewards on exploration in Reinforcement Learning",
    "authors": [
      "Aya Kayal",
      "Eduardo Pignatelli",
      "Laura Toni"
    ],
    "abstract": "One of the open challenges in Reinforcement Learning is the hard exploration\nproblem in sparse reward environments. Various types of intrinsic rewards have\nbeen proposed to address this challenge by pushing towards diversity. This\ndiversity might be imposed at different levels, favouring the agent to explore\ndifferent states, policies or behaviours (State, Policy and Skill level\ndiversity, respectively). However, the impact of diversity on the agent's\nbehaviour remains unclear. In this work, we aim to fill this gap by studying\nthe effect of different levels of diversity imposed by intrinsic rewards on the\nexploration patterns of RL agents. We select four intrinsic rewards (State\nCount, Intrinsic Curiosity Module (ICM), Maximum Entropy, and Diversity is all\nyou need (DIAYN)), each pushing for a different diversity level. We conduct an\nempirical study on MiniGrid environment to compare their impact on exploration\nconsidering various metrics related to the agent's exploration, namely:\nepisodic return, observation coverage, agent's position coverage, policy\nentropy, and timeframes to reach the sparse reward. The main outcome of the\nstudy is that State Count leads to the best exploration performance in the case\nof low-dimensional observations. However, in the case of RGB observations, the\nperformance of State Count is highly degraded mostly due to representation\nlearning challenges. Conversely, Maximum Entropy is less impacted, resulting in\na more robust exploration, despite being not always optimal. Lastly, our\nempirical study revealed that learning diverse skills with DIAYN, often linked\nto improved robustness and generalisation, does not promote exploration in\nMiniGrid environments. This is because: i) learning the skill space itself can\nbe challenging, and ii) exploration within the skill space prioritises\ndifferentiating between behaviours rather than achieving uniform state\nvisitation.",
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "45 pages, 17 figures. Submitted to Neural Computing and Applications\n  Journal",
    "pdf_url": "http://arxiv.org/pdf/2501.11533v1",
    "published_date": "2025-01-20 15:17:24 UTC",
    "updated_date": "2025-01-20 15:17:24 UTC"
  },
  {
    "arxiv_id": "2501.13955v1",
    "title": "Guided Persona-based AI Surveys: Can we replicate personal mobility preferences at scale using LLMs?",
    "authors": [
      "Ioannis Tzachristas",
      "Santhanakrishnan Narayanan",
      "Constantinos Antoniou"
    ],
    "abstract": "This study explores the potential of Large Language Models (LLMs) to generate\nartificial surveys, with a focus on personal mobility preferences in Germany.\nBy leveraging LLMs for synthetic data creation, we aim to address the\nlimitations of traditional survey methods, such as high costs, inefficiency and\nscalability challenges. A novel approach incorporating \"Personas\" -\ncombinations of demographic and behavioural attributes - is introduced and\ncompared to five other synthetic survey methods, which vary in their use of\nreal-world data and methodological complexity. The MiD 2017 dataset, a\ncomprehensive mobility survey in Germany, serves as a benchmark to assess the\nalignment of synthetic data with real-world patterns. The results demonstrate\nthat LLMs can effectively capture complex dependencies between demographic\nattributes and preferences while offering flexibility to explore hypothetical\nscenarios. This approach presents valuable opportunities for transportation\nplanning and social science research, enabling scalable, cost-efficient and\nprivacy-preserving data generation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13955v1",
    "published_date": "2025-01-20 15:11:03 UTC",
    "updated_date": "2025-01-20 15:11:03 UTC"
  },
  {
    "arxiv_id": "2501.11526v1",
    "title": "Meta-Instance Selection. Instance Selection as a Classification Problem with Meta-Features",
    "authors": [
      "Marcin Blachnik",
      "Piotr Ciepliński"
    ],
    "abstract": "Data pruning, or instance selection, is an important problem in machine\nlearning especially in terms of nearest neighbour classifier. However, in data\npruning which speeds up the prediction phase, there is an issue related to the\nspeed and efficiency of the process itself. In response, the study proposes an\napproach involving transforming the instance selection process into a\nclassification task conducted in a unified meta-feature space where each\ninstance can be classified and assigned to either the \"to keep\" or \"to remove\"\nclass. This approach requires training an appropriate meta-classifier, which\ncan be developed based on historical instance selection results from other\ndatasets using reference instance selection methods as a labeling tool. This\nwork proposes constructing the meta-feature space based on properties extracted\nfrom the nearest neighbor graph. Experiments conducted on 17 datasets of\nvarying sizes and five reference instance selection methods (ENN, Drop3, ICF,\nHMN-EI, and CCIS) demonstrate that the proposed solution achieves results\ncomparable to reference instance selection methods while significantly reducing\ncomputational complexity. In the proposed approach, the computational\ncomplexity of the system depends only on identifying the k-nearest neighbors\nfor each data sample and running the meta-classifier. Additionally, the study\ndiscusses the choice of meta-classifier, recommending the use of Balanced\nRandom Forest.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11526v1",
    "published_date": "2025-01-20 15:08:19 UTC",
    "updated_date": "2025-01-20 15:08:19 UTC"
  },
  {
    "arxiv_id": "2501.11525v1",
    "title": "Technical Report for the Forgotten-by-Design Project: Targeted Obfuscation for Machine Learning",
    "authors": [
      "Rickard Brännvall",
      "Laurynas Adomaitis",
      "Olof Görnerup",
      "Anass Sedrati"
    ],
    "abstract": "The right to privacy, enshrined in various human rights declarations, faces\nnew challenges in the age of artificial intelligence (AI). This paper explores\nthe concept of the Right to be Forgotten (RTBF) within AI systems, contrasting\nit with traditional data erasure methods. We introduce Forgotten by Design, a\nproactive approach to privacy preservation that integrates instance-specific\nobfuscation techniques during the AI model training process. Unlike machine\nunlearning, which modifies models post-training, our method prevents sensitive\ndata from being embedded in the first place. Using the LIRA membership\ninference attack, we identify vulnerable data points and propose defenses that\ncombine additive gradient noise and weighting schemes. Our experiments on the\nCIFAR-10 dataset demonstrate that our techniques reduce privacy risks by at\nleast an order of magnitude while maintaining model accuracy (at 95%\nsignificance). Additionally, we present visualization methods for the\nprivacy-utility trade-off, providing a clear framework for balancing privacy\nrisk and model accuracy. This work contributes to the development of\nprivacy-preserving AI systems that align with human cognitive processes of\nmotivated forgetting, offering a robust framework for safeguarding sensitive\ninformation and ensuring compliance with privacy regulations.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR",
      "68T09 (Primary) 68T05 (Secondary)",
      "D.4.6; K.6.5; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11525v1",
    "published_date": "2025-01-20 15:07:59 UTC",
    "updated_date": "2025-01-20 15:07:59 UTC"
  },
  {
    "arxiv_id": "2501.11498v1",
    "title": "Dialect2SQL: A Novel Text-to-SQL Dataset for Arabic Dialects with a Focus on Moroccan Darija",
    "authors": [
      "Salmane Chafik",
      "Saad Ezzini",
      "Ismail Berrada"
    ],
    "abstract": "The task of converting natural language questions (NLQs) into executable SQL\nqueries, known as text-to-SQL, has gained significant interest in recent years,\nas it enables non-technical users to interact with relational databases. Many\nbenchmarks, such as SPIDER and WikiSQL, have contributed to the development of\nnew models and the evaluation of their performance. In addition, other\ndatasets, like SEDE and BIRD, have introduced more challenges and complexities\nto better map real-world scenarios. However, these datasets primarily focus on\nhigh-resource languages such as English and Chinese. In this work, we introduce\nDialect2SQL, the first large-scale, cross-domain text-to-SQL dataset in an\nArabic dialect. It consists of 9,428 NLQ-SQL pairs across 69 databases in\nvarious domains. Along with SQL-related challenges such as long schemas, dirty\nvalues, and complex queries, our dataset also incorporates the complexities of\nthe Moroccan dialect, which is known for its diverse source languages, numerous\nborrowed words, and unique expressions. This demonstrates that our dataset will\nbe a valuable contribution to both the text-to-SQL community and the\ndevelopment of resources for low-resource languages.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.DB"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11498v1",
    "published_date": "2025-01-20 14:06:40 UTC",
    "updated_date": "2025-01-20 14:06:40 UTC"
  },
  {
    "arxiv_id": "2501.11496v2",
    "title": "Generative AI and Large Language Models in Language Preservation: Opportunities and Challenges",
    "authors": [
      "Vincent Koc"
    ],
    "abstract": "The global crisis of language endangerment meets a technological turning\npoint as Generative AI (GenAI) and Large Language Models (LLMs) unlock new\nfrontiers in automating corpus creation, transcription, translation, and\ntutoring. However, this promise is imperiled by fragmented practices and the\ncritical lack of a methodology to navigate the fraught balance between LLM\ncapabilities and the profound risks of data scarcity, cultural\nmisappropriation, and ethical missteps. This paper introduces a novel\nanalytical framework that systematically evaluates GenAI applications against\nlanguage-specific needs, embedding community governance and ethical safeguards\nas foundational pillars. We demonstrate its efficacy through the Te Reo M\\=aori\nrevitalization, where it illuminates successes, such as community-led Automatic\nSpeech Recognition achieving 92% accuracy, while critically surfacing\npersistent challenges in data sovereignty and model bias for digital archives\nand educational tools. Our findings underscore that GenAI can indeed\nrevolutionize language preservation, but only when interventions are rigorously\nanchored in community-centric data stewardship, continuous evaluation, and\ntransparent risk management. Ultimately, this framework provides an\nindispensable toolkit for researchers, language communities, and policymakers,\naiming to catalyze the ethical and high-impact deployment of LLMs to safeguard\nthe world's linguistic heritage.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "68T50, 91F20",
      "I.2.7; I.2.6; J.5"
    ],
    "primary_category": "cs.CL",
    "comment": "9 pages, 3 figures, 2 tables, submitted for IEEE publication.\n  Pre-print updated as part of review process",
    "pdf_url": "http://arxiv.org/pdf/2501.11496v2",
    "published_date": "2025-01-20 14:03:40 UTC",
    "updated_date": "2025-05-19 12:46:41 UTC"
  },
  {
    "arxiv_id": "2501.11493v2",
    "title": "Communication-Efficient Federated Learning Based on Explanation-Guided Pruning for Remote Sensing Image Classification",
    "authors": [
      "Jonas Klotz",
      "Barış Büyüktaş",
      "Begüm Demir"
    ],
    "abstract": "Federated learning (FL) is a decentralized machine learning paradigm in which\nmultiple clients collaboratively train a global model by exchanging only model\nupdates with the central server without sharing the local data of the clients.\nDue to the large volume of model updates required to be transmitted between\nclients and the central server, most FL systems are associated with high\ntransfer costs (i.e., communication overhead). This issue is more critical for\noperational applications in remote sensing (RS), especially when large-scale RS\ndata is processed and analyzed through FL systems with restricted communication\nbandwidth. To address this issue, we introduce an explanation-guided pruning\nstrategy for communication-efficient FL in the context of RS image\nclassification. Our pruning strategy is defined based on the layer-wise\nrelevance propagation (LRP) driven explanations to: 1) efficiently and\neffectively identify the most relevant and informative model parameters (to be\nexchanged between clients and the central server); and 2) eliminate the\nnon-informative ones to minimize the volume of model updates. The experimental\nresults on the BigEarthNet-S2 dataset demonstrate that our strategy effectively\nreduces the number of shared model updates, while increasing the generalization\nability of the global model. The code of this work is publicly available at\nhttps://git.tu-berlin.de/rsim/FL-LRP.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at the IEEE International Geoscience and Remote Sensing\n  Symposium (IGARSS) 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.11493v2",
    "published_date": "2025-01-20 13:59:41 UTC",
    "updated_date": "2025-05-16 14:14:55 UTC"
  },
  {
    "arxiv_id": "2501.17880v1",
    "title": "Assessment of the January 2025 Los Angeles County wildfires: A multi-modal analysis of impact, response, and population exposure",
    "authors": [
      "Seyd Teymoor Seydi"
    ],
    "abstract": "This study presents a comprehensive analysis of four significant California\nwildfires: Palisades, Eaton, Kenneth, and Hurst, examining their impacts\nthrough multiple dimensions, including land cover change, jurisdictional\nmanagement, structural damage, and demographic vulnerability. Using the\nChebyshev-Kolmogorov-Arnold network model applied to Sentinel-2 imagery, the\nextent of burned areas was mapped, ranging from 315.36 to 10,960.98 hectares.\nOur analysis revealed that shrubland ecosystems were consistently the most\naffected, comprising 57.4-75.8% of burned areas across all events. The\njurisdictional assessment demonstrated varying management complexities, from\nsingular authority (98.7% in the Palisades Fire) to distributed management\nacross multiple agencies. A structural impact analysis revealed significant\ndisparities between urban interface fires (Eaton: 9,869 structures; Palisades:\n8,436 structures) and rural events (Kenneth: 24 structures; Hurst: 17\nstructures). The demographic analysis showed consistent gender distributions,\nwith 50.9% of the population identified as female and 49.1% as male.\nWorking-age populations made up the majority of the affected populations,\nranging from 53.7% to 54.1%, with notable temporal shifts in post-fire periods.\nThe study identified strong correlations between urban interface proximity,\nstructural damage, and population exposure. The Palisades and Eaton fires\naffected over 20,000 people each, compared to fewer than 500 in rural events.\nThese findings offer valuable insights for the development of targeted wildfire\nmanagement strategies, particularly in wildland urban interface zones, and\nemphasize the need for age- and gender-conscious approaches in emergency\nresponse planning.",
    "categories": [
      "eess.SP",
      "cs.AI",
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "primary_category": "eess.SP",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.17880v1",
    "published_date": "2025-01-20 13:50:16 UTC",
    "updated_date": "2025-01-20 13:50:16 UTC"
  },
  {
    "arxiv_id": "2501.12418v1",
    "title": "ImageRef-VL: Enabling Contextual Image Referencing in Vision-Language Models",
    "authors": [
      "Jingwei Yi",
      "Junhao Yin",
      "Ju Xu",
      "Peng Bao",
      "Yongliang Wang",
      "Wei Fan",
      "Hao Wang"
    ],
    "abstract": "Vision-Language Models (VLMs) have demonstrated remarkable capabilities in\nunderstanding multimodal inputs and have been widely integrated into\nRetrieval-Augmented Generation (RAG) based conversational systems. While\ncurrent VLM-powered chatbots can provide textual source references in their\nresponses, they exhibit significant limitations in referencing contextually\nrelevant images during conversations. In this paper, we introduce Contextual\nImage Reference -- the ability to appropriately reference relevant images from\nretrieval documents based on conversation context -- and systematically\ninvestigate VLMs' capability in this aspect. We conduct the first evaluation\nfor contextual image referencing, comprising a dedicated testing dataset and\nevaluation metrics. Furthermore, we propose ImageRef-VL, a method that\nsignificantly enhances open-source VLMs' image referencing capabilities through\ninstruction fine-tuning on a large-scale, manually curated multimodal\nconversation dataset. Experimental results demonstrate that ImageRef-VL not\nonly outperforms proprietary models but also achieves an 88% performance\nimprovement over state-of-the-art open-source VLMs in contextual image\nreferencing tasks. Our code is available at\nhttps://github.com/bytedance/ImageRef-VL.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.12418v1",
    "published_date": "2025-01-20 13:43:45 UTC",
    "updated_date": "2025-01-20 13:43:45 UTC"
  },
  {
    "arxiv_id": "2501.11478v2",
    "title": "Each Graph is a New Language: Graph Learning with LLMs",
    "authors": [
      "Huachi Zhou",
      "Jiahe Du",
      "Chuang Zhou",
      "Chang Yang",
      "Yilin Xiao",
      "Yuxuan Xie",
      "Xiao Huang"
    ],
    "abstract": "Recent efforts leverage Large Language Models (LLMs) for modeling\ntext-attributed graph structures in node classification tasks. These approaches\ndescribe graph structures for LLMs to understand or aggregate LLM-generated\ntextual attribute embeddings through graph structure. However, these approaches\nface two main limitations in modeling graph structures with LLMs. (i) Graph\ndescriptions become verbose in describing high-order graph structure. (ii)\nTextual attributes alone do not contain adequate graph structure information.\nIt is challenging to model graph structure concisely and adequately with LLMs.\nLLMs lack built-in mechanisms to model graph structures directly. They also\nstruggle with complex long-range dependencies between high-order nodes and\ntarget nodes.\n  Inspired by the observation that LLMs pre-trained on one language can achieve\nexceptional performance on another with minimal additional training, we propose\n\\textbf{G}raph-\\textbf{D}efined \\textbf{L}anguage for \\textbf{L}arge\n\\textbf{L}anguage \\textbf{M}odel (GDL4LLM). This novel framework enables LLMs\nto transfer their powerful language understanding capabilities to\ngraph-structured data. GDL4LLM translates graphs into a graph language corpus\ninstead of graph descriptions and pre-trains LLMs on this corpus to adequately\nunderstand graph structures. During fine-tuning, this corpus describes the\nstructural information of target nodes concisely with only a few tokens. By\ntreating graphs as a new language, GDL4LLM enables LLMs to model graph\nstructures adequately and concisely for node classification tasks. Extensive\nexperiments on three real-world datasets demonstrate that GDL4LLM outperforms\ndescription-based and textual attribute embeddings-based baselines by\nefficiently modeling different orders of graph structure with LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11478v2",
    "published_date": "2025-01-20 13:20:41 UTC",
    "updated_date": "2025-01-23 06:36:18 UTC"
  },
  {
    "arxiv_id": "2502.07789v1",
    "title": "Do AI assistants help students write formal specifications? A study with ChatGPT and the B-Method",
    "authors": [
      "Alfredo Capozucca",
      "Daniil Yampolskyi",
      "Alexander Goldberg",
      "Maximiliano Cristiá"
    ],
    "abstract": "This paper investigates the role of AI assistants, specifically OpenAI's\nChatGPT, in teaching formal methods (FM) to undergraduate students, using the\nB-method as a formal specification technique. While existing studies\ndemonstrate the effectiveness of AI in coding tasks, no study reports on its\nimpact on formal specifications. We examine whether ChatGPT provides an\nadvantage when writing B-specifications and analyse student trust in its\noutputs. Our findings indicate that the AI does not help students to enhance\nthe correctness of their specifications, with low trust correlating to better\noutcomes. Additionally, we identify a behavioural pattern with which to\ninteract with ChatGPT which may influence the correctness of B-specifications.",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2502.07789v1",
    "published_date": "2025-01-20 13:00:29 UTC",
    "updated_date": "2025-01-20 13:00:29 UTC"
  },
  {
    "arxiv_id": "2501.13117v1",
    "title": "MyGO Multiplex CoT: A Method for Self-Reflection in Large Language Models via Double Chain of Thought Thinking",
    "authors": [
      "Shihao Ji",
      "Zihui Song",
      "Fucheng Zhong",
      "Jisen Jia",
      "Zhaobo Wu",
      "Zheyi Cao",
      "Tianhao Xu"
    ],
    "abstract": "Recent advancements in large language models (LLMs) have demonstrated their\nimpressive abilities in various reasoning and decision-making tasks. However,\nthe quality and coherence of the reasoning process can still benefit from\nenhanced introspection and self-reflection. In this paper, we introduce\nMultiplex CoT (Chain of Thought), a method that enables LLMs to simulate a form\nof self-review while reasoning, by initiating double Chain of Thought (CoT)\nthinking. Multiplex CoT leverages the power of iterative reasoning, where the\nmodel generates an initial chain of thought and subsequently critiques and\nrefines this reasoning with a second round of thought generation. This\nrecursive approach allows for more coherent, logical, and robust answers,\nimproving the overall decision-making process. We demonstrate how this method\ncan be effectively implemented using simple prompt engineering in existing LLM\narchitectures, achieving an effect similar to that of the Learning-Refinement\nModel (LRM) without the need for additional training. Additionally, we present\na practical guide for implementing the method in Google Colab, enabling easy\nintegration into real-world applications.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13117v1",
    "published_date": "2025-01-20 12:54:57 UTC",
    "updated_date": "2025-01-20 12:54:57 UTC"
  },
  {
    "arxiv_id": "2501.11454v1",
    "title": "Improving thermal state preparation of Sachdev-Ye-Kitaev model with reinforcement learning on quantum hardware",
    "authors": [
      "Akash Kundu"
    ],
    "abstract": "The Sachdev-Ye-Kitaev (SYK) model, known for its strong quantum correlations\nand chaotic behavior, serves as a key platform for quantum gravity studies.\nHowever, variationally preparing thermal states on near-term quantum processors\nfor large systems (N>12, where N is the number of Majorana fermions) presents a\nsignificant challenge due to the rapid growth in the complexity of\nparameterized quantum circuits. This paper addresses this challenge by\nintegrating reinforcement learning (RL) with convolutional neural networks,\nemploying an iterative approach to optimize the quantum circuit and its\nparameters. The refinement process is guided by a composite reward signal\nderived from entropy and the expectation values of the SYK Hamiltonian. This\napproach reduces the number of CNOT gates by two orders of magnitude for\nsystems N>10 compared to traditional methods like first-order Trotterization.\nWe demonstrate the effectiveness of the RL framework in both noiseless and\nnoisy quantum hardware environments, maintaining high accuracy in thermal state\npreparation. This work contributes to the advancement of a scalable, RL-based\nframework with applications for computations of thermal out-of-time-order\ncorrelators in quantum many-body systems and quantum gravity studies on\nnear-term quantum hardware.",
    "categories": [
      "quant-ph",
      "cs.AI",
      "cs.LG",
      "hep-lat",
      "hep-th"
    ],
    "primary_category": "quant-ph",
    "comment": "The code and the data will be available soon. Comments are welcomed!",
    "pdf_url": "http://arxiv.org/pdf/2501.11454v1",
    "published_date": "2025-01-20 12:41:17 UTC",
    "updated_date": "2025-01-20 12:41:17 UTC"
  },
  {
    "arxiv_id": "2501.11447v1",
    "title": "Decomposing Interventional Causality into Synergistic, Redundant, and Unique Components",
    "authors": [
      "Abel Jansma"
    ],
    "abstract": "We introduce a novel framework for decomposing interventional causal effects\ninto synergistic, redundant, and unique components, building on the intuition\nof Partial Information Decomposition (PID) and the principle of M\\\"obius\ninversion. While recent work has explored a similar decomposition of an\nobservational measure, we argue that a proper causal decomposition must be\ninterventional in nature. We develop a mathematical approach that\nsystematically quantifies how causal power is distributed among variables in a\nsystem, using a recently derived closed-form expression for the M\\\"obius\nfunction of the redundancy lattice. The formalism is then illustrated by\ndecomposing the causal power in logic gates, cellular automata, and chemical\nreaction networks. Our results reveal how the distribution of causal power can\nbe context- and parameter-dependent. This decomposition provides new insights\ninto complex systems by revealing how causal influences are shared and combined\namong multiple variables, with potential applications ranging from attribution\nof responsibility in legal or AI systems, to the analysis of biological\nnetworks or climate models.",
    "categories": [
      "cs.AI",
      "cs.IT",
      "math.IT",
      "physics.data-an",
      "68T01 (Primary) 06A11, 62D20 (Secondary)",
      "I.2.4; F.2.1; G.2.1"
    ],
    "primary_category": "cs.AI",
    "comment": "10 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11447v1",
    "published_date": "2025-01-20 12:34:51 UTC",
    "updated_date": "2025-01-20 12:34:51 UTC"
  },
  {
    "arxiv_id": "2501.11430v5",
    "title": "A Survey on Diffusion Models for Anomaly Detection",
    "authors": [
      "Jing Liu",
      "Zhenchao Ma",
      "Zepu Wang",
      "Chenxuanyin Zou",
      "Jiayang Ren",
      "Zehua Wang",
      "Liang Song",
      "Bo Hu",
      "Yang Liu",
      "Victor C. M. Leung"
    ],
    "abstract": "Diffusion models (DMs) have emerged as a powerful class of generative AI\nmodels, showing remarkable potential in anomaly detection (AD) tasks across\nvarious domains, such as cybersecurity, fraud detection, healthcare, and\nmanufacturing. The intersection of these two fields, termed diffusion models\nfor anomaly detection (DMAD), offers promising solutions for identifying\ndeviations in increasingly complex and high-dimensional data. In this survey,\nwe review recent advances in DMAD research. We begin by presenting the\nfundamental concepts of AD and DMs, followed by a comprehensive analysis of\nclassic DM architectures including DDPMs, DDIMs, and Score SDEs. We further\ncategorize existing DMAD methods into reconstruction-based, density-based, and\nhybrid approaches, providing detailed examinations of their methodological\ninnovations. We also explore the diverse tasks across different data\nmodalities, encompassing image, time series, video, and multimodal data\nanalysis. Furthermore, we discuss critical challenges and emerging research\ndirections, including computational efficiency, model interpretability,\nrobustness enhancement, edge-cloud collaboration, and integration with large\nlanguage models. The collection of DMAD research papers and resources is\navailable at https://github.com/fdjingliu/DMAD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11430v5",
    "published_date": "2025-01-20 12:06:54 UTC",
    "updated_date": "2025-02-27 02:05:55 UTC"
  },
  {
    "arxiv_id": "2501.16357v1",
    "title": "EVolutionary Independent DEtermiNistiC Explanation",
    "authors": [
      "Vincenzo Dentamaro",
      "Paolo Giglio",
      "Donato Impedovo",
      "Giuseppe Pirlo"
    ],
    "abstract": "The widespread use of artificial intelligence deep neural networks in fields\nsuch as medicine and engineering necessitates understanding their\ndecision-making processes. Current explainability methods often produce\ninconsistent results and struggle to highlight essential signals influencing\nmodel inferences. This paper introduces the Evolutionary Independent\nDeterministic Explanation (EVIDENCE) theory, a novel approach offering a\ndeterministic, model-independent method for extracting significant signals from\nblack-box models. EVIDENCE theory, grounded in robust mathematical\nformalization, is validated through empirical tests on diverse datasets,\nincluding COVID-19 audio diagnostics, Parkinson's disease voice recordings, and\nthe George Tzanetakis music classification dataset (GTZAN). Practical\napplications of EVIDENCE include improving diagnostic accuracy in healthcare\nand enhancing audio signal analysis. For instance, in the COVID-19 use case,\nEVIDENCE-filtered spectrograms fed into a frozen Residual Network with 50\nlayers improved precision by 32% for positive cases and increased the area\nunder the curve (AUC) by 16% compared to baseline models. For Parkinson's\ndisease classification, EVIDENCE achieved near-perfect precision and\nsensitivity, with a macro average F1-Score of 0.997. In the GTZAN, EVIDENCE\nmaintained a high AUC of 0.996, demonstrating its efficacy in filtering\nrelevant features for accurate genre classification. EVIDENCE outperformed\nother Explainable Artificial Intelligence (XAI) methods such as LIME, SHAP, and\nGradCAM in almost all metrics. These findings indicate that EVIDENCE not only\nimproves classification accuracy but also provides a transparent and\nreproducible explanation mechanism, crucial for advancing the trustworthiness\nand applicability of AI systems in real-world settings.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP"
    ],
    "primary_category": "cs.LG",
    "comment": "20 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.16357v1",
    "published_date": "2025-01-20 12:05:14 UTC",
    "updated_date": "2025-01-20 12:05:14 UTC"
  },
  {
    "arxiv_id": "2501.11429v2",
    "title": "The Explanation Game -- Rekindled (Extended Version)",
    "authors": [
      "Joao Marques-Silva",
      "Xuanxiang Huang",
      "Olivier Letoffe"
    ],
    "abstract": "Recent work demonstrated the existence of critical flaws in the current use\nof Shapley values in explainable AI (XAI), i.e. the so-called SHAP scores.\nThese flaws are significant in that the scores provided to a human\ndecision-maker can be misleading. Although these negative results might appear\nto indicate that Shapley values ought not be used in XAI, this paper argues\notherwise. Concretely, this paper proposes a novel definition of SHAP scores\nthat overcomes existing flaws. Furthermore, the paper outlines a practically\nefficient solution for the rigorous estimation of the novel SHAP scores.\nPreliminary experimental results confirm our claims, and further underscore the\nflaws of the current SHAP scores.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11429v2",
    "published_date": "2025-01-20 12:00:36 UTC",
    "updated_date": "2025-02-15 03:49:28 UTC"
  },
  {
    "arxiv_id": "2501.11428v1",
    "title": "Enhancing Coronary Artery Calcium Scoring via Multi-Organ Segmentation on Non-Contrast Cardiac Computed Tomography",
    "authors": [
      "Jakub Nalepa",
      "Tomasz Bartczak",
      "Mariusz Bujny",
      "Jarosław Gośliński",
      "Katarzyna Jesionek",
      "Wojciech Malara",
      "Filip Malawski",
      "Karol Miszalski-Jamka",
      "Patrycja Rewa",
      "Marcin Kostur"
    ],
    "abstract": "Despite coronary artery calcium scoring being considered a largely solved\nproblem within the realm of medical artificial intelligence, this paper argues\nthat significant improvements can still be made. By shifting the focus from\npathology detection to a deeper understanding of anatomy, the novel algorithm\nproposed in the paper both achieves high accuracy in coronary artery calcium\nscoring and offers enhanced interpretability of the results. This approach not\nonly aids in the precise quantification of calcifications in coronary arteries,\nbut also provides valuable insights into the underlying anatomical structures.\nThrough this anatomically-informed methodology, the paper shows how a nuanced\nunderstanding of the heart's anatomy can lead to more accurate and\ninterpretable results in the field of cardiovascular health. We demonstrate the\nsuperior accuracy of the proposed method by evaluating it on an open-source\nmulti-vendor dataset, where we obtain results at the inter-observer level,\nsurpassing the current state of the art. Finally, the qualitative analyses show\nthe practical value of the algorithm in such tasks as labeling coronary artery\ncalcifications, identifying aortic calcifications, and filtering out false\npositive detections due to noise.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11428v1",
    "published_date": "2025-01-20 11:56:40 UTC",
    "updated_date": "2025-01-20 11:56:40 UTC"
  },
  {
    "arxiv_id": "2501.11425v3",
    "title": "Agent-R: Training Language Model Agents to Reflect via Iterative Self-Training",
    "authors": [
      "Siyu Yuan",
      "Zehui Chen",
      "Zhiheng Xi",
      "Junjie Ye",
      "Zhengyin Du",
      "Jiecao Chen"
    ],
    "abstract": "Large Language Models (LLMs) agents are increasingly pivotal for addressing\ncomplex tasks in interactive environments. Existing work mainly focuses on\nenhancing performance through behavior cloning from stronger experts, yet such\napproaches often falter in real-world applications, mainly due to the inability\nto recover from errors. However, step-level critique data is difficult and\nexpensive to collect. Automating and dynamically constructing self-critique\ndatasets is thus crucial to empowering models with intelligent agent\ncapabilities. In this work, we propose an iterative self-training framework,\nAgent-R, that enables language Agent to Reflect on the fly. Unlike traditional\nmethods that reward or penalize actions based on correctness, Agent-R leverages\nMCTS to construct training data that recover correct trajectories from\nerroneous ones. A key challenge of agent reflection lies in the necessity for\ntimely revision rather than waiting until the end of a rollout. To address\nthis, we introduce a model-guided critique construction mechanism: the actor\nmodel identifies the first error step (within its current capability) in a\nfailed trajectory. Starting from it, we splice it with the adjacent correct\npath, which shares the same parent node in the tree. This strategy enables the\nmodel to learn reflection based on its current policy, therefore yielding\nbetter learning efficiency. To further explore the scalability of this\nself-improvement paradigm, we investigate iterative refinement of both error\ncorrection capabilities and dataset construction. Our findings demonstrate that\nAgent-R continuously improves the model's ability to recover from errors and\nenables timely error correction. Experiments on three interactive environments\nshow that Agent-R effectively equips agents to correct erroneous actions while\navoiding loops, achieving superior performance compared to baseline methods\n(+5.59%).",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11425v3",
    "published_date": "2025-01-20 11:46:04 UTC",
    "updated_date": "2025-03-24 10:18:56 UTC"
  },
  {
    "arxiv_id": "2501.11422v2",
    "title": "Multi-View Spectral Clustering for Graphs with Multiple View Structures",
    "authors": [
      "Yorgos Tsitsikas",
      "Evangelos E. Papalexakis"
    ],
    "abstract": "Despite the fundamental importance of clustering, to this day, much of the\nrelevant research is still based on ambiguous foundations, leading to an\nunclear understanding of whether or how the various clustering methods are\nconnected with each other. In this work, we provide an additional stepping\nstone towards resolving such ambiguities by presenting a general clustering\nframework that subsumes a series of seemingly disparate clustering methods,\nincluding various methods belonging to the widely popular spectral clustering\nframework. In fact, the generality of the proposed framework is additionally\ncapable of shedding light to the largely unexplored area of multi-view graphs\nwhere each view may have differently clustered nodes. In turn, we propose\nGenClus: a method that is simultaneously an instance of this framework and a\ngeneralization of spectral clustering, while also being closely related to\nk-means as well. This results in a principled alternative to the few existing\nmethods studying this special type of multi-view graphs. Then, we conduct\nin-depth experiments, which demonstrate that GenClus is more computationally\nefficient than existing methods, while also attaining similar or better\nclustering performance. Lastly, a qualitative real-world case-study further\ndemonstrates the ability of GenClus to produce meaningful clusterings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "This work has been accepted for publication at the 2025 SIAM\n  International Conference on Data Mining (SDM2025), and this is the full\n  version of the paper",
    "pdf_url": "http://arxiv.org/pdf/2501.11422v2",
    "published_date": "2025-01-20 11:39:22 UTC",
    "updated_date": "2025-01-28 14:43:45 UTC"
  },
  {
    "arxiv_id": "2501.13954v1",
    "title": "Chat3GPP: An Open-Source Retrieval-Augmented Generation Framework for 3GPP Documents",
    "authors": [
      "Long Huang",
      "Ming Zhao",
      "Limin Xiao",
      "Xiujun Zhang",
      "Jungang Hu"
    ],
    "abstract": "The 3rd Generation Partnership Project (3GPP) documents is key standards in\nglobal telecommunications, while posing significant challenges for engineers\nand researchers in the telecommunications field due to the large volume and\ncomplexity of their contents as well as the frequent updates. Large language\nmodels (LLMs) have shown promise in natural language processing tasks, but\ntheir general-purpose nature limits their effectiveness in specific domains\nlike telecommunications. To address this, we propose Chat3GPP, an open-source\nretrieval-augmented generation (RAG) framework tailored for 3GPP\nspecifications. By combining chunking strategies, hybrid retrieval and\nefficient indexing methods, Chat3GPP can efficiently retrieve relevant\ninformation and generate accurate responses to user queries without requiring\ndomain-specific fine-tuning, which is both flexible and scalable, offering\nsignificant potential for adapting to other technical standards beyond 3GPP. We\nevaluate Chat3GPP on two telecom-specific datasets and demonstrate its superior\nperformance compared to existing methods, showcasing its potential for\ndownstream tasks like protocol generation and code automation.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DC",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13954v1",
    "published_date": "2025-01-20 11:38:42 UTC",
    "updated_date": "2025-01-20 11:38:42 UTC"
  },
  {
    "arxiv_id": "2501.11417v1",
    "title": "Neural Contextual Reinforcement Framework for Logical Structure Language Generation",
    "authors": [
      "Marcus Irvin",
      "William Cooper",
      "Edward Hughes",
      "Jessica Morgan",
      "Christopher Hamilton"
    ],
    "abstract": "The Neural Contextual Reinforcement Framework introduces an innovative\napproach to enhancing the logical coherence and structural consistency of text\ngenerated by large language models. Leveraging reinforcement learning\nprinciples, the framework integrates custom reward functions and dynamic\ncontext alignment mechanisms to address challenges inherent in maintaining\nlong-range dependencies across extended sequences. The architecture\nincorporates multi-head attention layers and hierarchical encoding modules,\nenabling the model to produce outputs that align closely with human\nexpectations of logical structure and semantic flow. Quantitative evaluations\nacross diverse datasets demonstrate substantial improvements in coherence\nmetrics, perplexity reduction, and semantic alignment, showcasing the\nframework's ability to outperform baseline models in both general and\ndomain-specific tasks. Qualitative analyses further highlight the framework's\ncapacity to generate text with improved narrative clarity and reduced\nredundancy, reflecting its effectiveness in balancing fluency with structural\nprecision. In addition to its performance gains, the framework exhibits\nrobustness in handling noisy input data and scalability across varying model\nsizes, reinforcing its versatility in practical applications. Experimental\nresults reveal that optimal context window sizes significantly influence\ncoherence outcomes, showing the importance of architectural flexibility in\nadapting to diverse linguistic structures. Cross-lingual performance\nevaluations affirm the framework's adaptability to multiple languages,\nextending its utility beyond monolingual contexts. Resource efficiency analyses\nindicate a reduction in computational overhead compared to traditional\napproaches, emphasizing the practicality of the framework for large-scale\ndeployment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11417v1",
    "published_date": "2025-01-20 11:34:28 UTC",
    "updated_date": "2025-01-20 11:34:28 UTC"
  },
  {
    "arxiv_id": "2501.11413v1",
    "title": "Generalization and Informativeness of Weighted Conformal Risk Control Under Covariate Shift",
    "authors": [
      "Matteo Zecchin",
      "Fredrik Hellström",
      "Sangwoo Park",
      "Shlomo Shamai",
      "Osvaldo Simeone"
    ],
    "abstract": "Predictive models are often required to produce reliable predictions under\nstatistical conditions that are not matched to the training data. A common type\nof training-testing mismatch is covariate shift, where the conditional\ndistribution of the target variable given the input features remains fixed,\nwhile the marginal distribution of the inputs changes. Weighted conformal risk\ncontrol (W-CRC) uses data collected during the training phase to convert point\npredictions into prediction sets with valid risk guarantees at test time\ndespite the presence of a covariate shift. However, while W-CRC provides\nstatistical reliability, its efficiency -- measured by the size of the\nprediction sets -- can only be assessed at test time. In this work, we relate\nthe generalization properties of the base predictor to the efficiency of W-CRC\nunder covariate shifts. Specifically, we derive a bound on the inefficiency of\nthe W-CRC predictor that depends on algorithmic hyperparameters and\ntask-specific quantities available at training time. This bound offers insights\non relationships between the informativeness of the prediction sets, the extent\nof the covariate shift, and the size of the calibration and training sets.\nExperiments on fingerprinting-based localization validate the theoretical\nresults.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11413v1",
    "published_date": "2025-01-20 11:26:36 UTC",
    "updated_date": "2025-01-20 11:26:36 UTC"
  },
  {
    "arxiv_id": "2501.11409v3",
    "title": "Unsupervised Learning in Echo State Networks for Input Reconstruction",
    "authors": [
      "Taiki Yamada",
      "Yuichi Katori",
      "Kantaro Fujiwara"
    ],
    "abstract": "Conventional echo state networks (ESNs) require supervised learning to train\nthe readout layer, using the desired outputs as training data. In this study,\nwe focus on input reconstruction (IR), which refers to training the readout\nlayer to reproduce the input time series in its output. We reformulate the\nlearning algorithm of the ESN readout layer to perform IR using unsupervised\nlearning (UL). By conducting theoretical analysis and numerical experiments, we\ndemonstrate that IR in ESNs can be effectively implemented under realistic\nconditions without explicitly using the desired outputs as training data; in\nthis way, UL is enabled. Furthermore, we demonstrate that applications relying\non IR, such as dynamical system replication and noise filtering, can be\nreformulated within the UL framework. Our findings establish a theoretically\nsound and universally applicable IR formulation, along with its related tasks\nin ESNs. This work paves the way for novel predictions and highlights\nunresolved theoretical challenges in ESNs, particularly in the context of\ntime-series processing methods and computational models of the brain.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "nlin.CD",
      "q-bio.NC"
    ],
    "primary_category": "cs.LG",
    "comment": "33 pages, 7 figures, regular paper",
    "pdf_url": "http://arxiv.org/pdf/2501.11409v3",
    "published_date": "2025-01-20 11:16:44 UTC",
    "updated_date": "2025-02-10 10:09:31 UTC"
  },
  {
    "arxiv_id": "2501.11407v1",
    "title": "A Truly Sparse and General Implementation of Gradient-Based Synaptic Plasticity",
    "authors": [
      "Jamie Lohoff",
      "Anil Kaya",
      "Florian Assmuth",
      "Emre Neftci"
    ],
    "abstract": "Online synaptic plasticity rules derived from gradient descent achieve high\naccuracy on a wide range of practical tasks. However, their software\nimplementation often requires tediously hand-derived gradients or using\ngradient backpropagation which sacrifices the online capability of the rules.\nIn this work, we present a custom automatic differentiation (AD) pipeline for\nsparse and online implementation of gradient-based synaptic plasticity rules\nthat generalizes to arbitrary neuron models. Our work combines the programming\nease of backpropagation-type methods for forward AD while being\nmemory-efficient. To achieve this, we exploit the advantageous compute and\nmemory scaling of online synaptic plasticity by providing an inherently sparse\nimplementation of AD where expensive tensor contractions are replaced with\nsimple element-wise multiplications if the tensors are diagonal. Gradient-based\nsynaptic plasticity rules such as eligibility propagation (e-prop) have exactly\nthis property and thus profit immensely from this feature. We demonstrate the\nalignment of our gradients with respect to gradient backpropagation on an\nsynthetic task where e-prop gradients are exact, as well as audio speech\nclassification benchmarks. We demonstrate how memory utilization scales with\nnetwork size without dependence on the sequence length, as expected from\nforward AD methods.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "8 pages, 7 figures",
    "pdf_url": "http://arxiv.org/pdf/2501.11407v1",
    "published_date": "2025-01-20 11:14:11 UTC",
    "updated_date": "2025-01-20 11:14:11 UTC"
  },
  {
    "arxiv_id": "2501.16356v1",
    "title": "Evaluating Binary Decision Biases in Large Language Models: Implications for Fair Agent-Based Financial Simulations",
    "authors": [
      "Alicia Vidler",
      "Toby Walsh"
    ],
    "abstract": "Large Language Models (LLMs) are increasingly being used to simulate\nhuman-like decision making in agent-based financial market models (ABMs). As\nmodels become more powerful and accessible, researchers can now incorporate\nindividual LLM decisions into ABM environments. However, integration may\nintroduce inherent biases that need careful evaluation. In this paper we test\nthree state-of-the-art GPT models for bias using two model sampling approaches:\none-shot and few-shot API queries. We observe significant variations in\ndistributions of outputs between specific models, and model sub versions, with\nGPT-4o-Mini-2024-07-18 showing notably better performance (32-43% yes\nresponses) compared to GPT-4-0125-preview's extreme bias (98-99% yes\nresponses). We show that sampling methods and model sub-versions significantly\nimpact results: repeated independent API calls produce different distributions\ncompared to batch sampling within a single call. While no current GPT model can\nsimultaneously achieve a uniform distribution and Markovian properties in\none-shot testing, few-shot sampling can approach uniform distributions under\ncertain conditions. We explore the Temperature parameter, providing a\ndefinition and comparative results. We further compare our results to true\nrandom binary series and test specifically for the common human bias of\nNegative Recency - finding LLMs have a mixed ability to 'beat' humans in this\none regard. These findings emphasise the critical importance of careful LLM\nintegration into ABMs for financial markets and more broadly.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "8 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.16356v1",
    "published_date": "2025-01-20 10:36:51 UTC",
    "updated_date": "2025-01-20 10:36:51 UTC"
  },
  {
    "arxiv_id": "2501.11378v1",
    "title": "Investigation of Whisper ASR Hallucinations Induced by Non-Speech Audio",
    "authors": [
      "Mateusz Barański",
      "Jan Jasiński",
      "Julitta Bartolewska",
      "Stanisław Kacprzak",
      "Marcin Witkowski",
      "Konrad Kowalczyk"
    ],
    "abstract": "Hallucinations of deep neural models are amongst key challenges in automatic\nspeech recognition (ASR). In this paper, we investigate hallucinations of the\nWhisper ASR model induced by non-speech audio segments present during\ninference. By inducting hallucinations with various types of sounds, we show\nthat there exists a set of hallucinations that appear frequently. We then study\nhallucinations caused by the augmentation of speech with such sounds. Finally,\nwe describe the creation of a bag of hallucinations (BoH) that allows to remove\nthe effect of hallucinations through the post-processing of text\ntranscriptions. The results of our experiments show that such post-processing\nis capable of reducing word error rate (WER) and acts as a good safeguard\nagainst problematic hallucinations.",
    "categories": [
      "cs.SD",
      "cs.AI",
      "eess.AS"
    ],
    "primary_category": "cs.SD",
    "comment": "Accepted for IEEE ICASSP 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.11378v1",
    "published_date": "2025-01-20 10:14:52 UTC",
    "updated_date": "2025-01-20 10:14:52 UTC"
  },
  {
    "arxiv_id": "2501.11360v1",
    "title": "Federated Learning with Sample-level Client Drift Mitigation",
    "authors": [
      "Haoran Xu",
      "Jiaze Li",
      "Wanyi Wu",
      "Hao Ren"
    ],
    "abstract": "Federated Learning (FL) suffers from severe performance degradation due to\nthe data heterogeneity among clients. Existing works reveal that the\nfundamental reason is that data heterogeneity can cause client drift where the\nlocal model update deviates from the global one, and thus they usually tackle\nthis problem from the perspective of calibrating the obtained local update.\nDespite effectiveness, existing methods substantially lack a deep understanding\nof how heterogeneous data samples contribute to the formation of client drift.\nIn this paper, we bridge this gap by identifying that the drift can be viewed\nas a cumulative manifestation of biases present in all local samples and the\nbias between samples is different. Besides, the bias dynamically changes as the\nFL training progresses. Motivated by this, we propose FedBSS that first\nmitigates the heterogeneity issue in a sample-level manner, orthogonal to\nexisting methods. Specifically, the core idea of our method is to adopt a\nbias-aware sample selection scheme that dynamically selects the samples from\nsmall biases to large epoch by epoch to train progressively the local model in\neach round. In order to ensure the stability of training, we set the\ndiversified knowledge acquisition stage as the warm-up stage to avoid the local\noptimality caused by knowledge deviation in the early stage of the model.\nEvaluation results show that FedBSS outperforms state-of-the-art baselines. In\naddition, we also achieved effective results on feature distribution skew and\nnoise label dataset setting, which proves that FedBSS can not only reduce\nheterogeneity, but also has scalability and robustness.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by AAAI 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.11360v1",
    "published_date": "2025-01-20 09:44:07 UTC",
    "updated_date": "2025-01-20 09:44:07 UTC"
  },
  {
    "arxiv_id": "2501.11357v2",
    "title": "On the dimension of pullback attractors in recurrent neural networks",
    "authors": [
      "Muhammed Fadera"
    ],
    "abstract": "Recurrent Neural Networks (RNNs) are high-dimensional state space models\ncapable of learning functions on sequence data. Recently, it has been\nconjectured that reservoir computers, a particular class of RNNs, trained on\nobservations of a dynamical systems can be interpreted as embeddings. This\nresult has been established for the case of linear reservoir systems. In this\nwork, we use a nonautonomous dynamical systems approach to establish an upper\nbound for the fractal dimension of the subset of reservoir state space\napproximated during training and prediction phase. We prove that when the input\nsequences comes from an Nin-dimensional invertible dynamical system, the\nfractal dimension of this set is bounded above by Nin. The result obtained here\nare useful in dimensionality reduction of computation in RNNs as well as\nestimating fractal dimensions of dynamical systems from limited observations of\ntheir time series. It is also a step towards understanding embedding properties\nof reservoir computers.",
    "categories": [
      "math.DS",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "math.DS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11357v2",
    "published_date": "2025-01-20 09:38:30 UTC",
    "updated_date": "2025-03-29 15:24:12 UTC"
  },
  {
    "arxiv_id": "2501.11354v1",
    "title": "Towards Advancing Code Generation with Large Language Models: A Research Roadmap",
    "authors": [
      "Haolin Jin",
      "Huaming Chen",
      "Qinghua Lu",
      "Liming Zhu"
    ],
    "abstract": "Recently, we have witnessed the rapid development of large language models,\nwhich have demonstrated excellent capabilities in the downstream task of code\ngeneration. However, despite their potential, LLM-based code generation still\nfaces numerous technical and evaluation challenges, particularly when embedded\nin real-world development. In this paper, we present our vision for current\nresearch directions, and provide an in-depth analysis of existing studies on\nthis task. We propose a six-layer vision framework that categorizes code\ngeneration process into distinct phases, namely Input Phase, Orchestration\nPhase, Development Phase, and Validation Phase. Additionally, we outline our\nvision workflow, which reflects on the currently prevalent frameworks. We\nsystematically analyse the challenges faced by large language models, including\nthose LLM-based agent frameworks, in code generation tasks. With these, we\noffer various perspectives and actionable recommendations in this area. Our aim\nis to provide guidelines for improving the reliability, robustness and\nusability of LLM-based code generation systems. Ultimately, this work seeks to\naddress persistent challenges and to provide practical suggestions for a more\npragmatic LLM-based solution for future code generation endeavors.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11354v1",
    "published_date": "2025-01-20 09:33:44 UTC",
    "updated_date": "2025-01-20 09:33:44 UTC"
  },
  {
    "arxiv_id": "2501.11335v1",
    "title": "Few-shot Policy (de)composition in Conversational Question Answering",
    "authors": [
      "Kyle Erwin",
      "Guy Axelrod",
      "Maria Chang",
      "Achille Fokoue",
      "Maxwell Crouse",
      "Soham Dan",
      "Tian Gao",
      "Rosario Uceda-Sosa",
      "Ndivhuwo Makondo",
      "Naweed Khan",
      "Alexander Gray"
    ],
    "abstract": "The task of policy compliance detection (PCD) is to determine if a scenario\nis in compliance with respect to a set of written policies. In a conversational\nsetting, the results of PCD can indicate if clarifying questions must be asked\nto determine compliance status. Existing approaches usually claim to have\nreasoning capabilities that are latent or require a large amount of annotated\ndata. In this work, we propose logical decomposition for policy compliance\n(LDPC): a neuro-symbolic framework to detect policy compliance using large\nlanguage models (LLMs) in a few-shot setting. By selecting only a few exemplars\nalongside recently developed prompting techniques, we demonstrate that our\napproach soundly reasons about policy compliance conversations by extracting\nsub-questions to be answered, assigning truth values from contextual\ninformation, and explicitly producing a set of logic statements from the given\npolicies. The formulation of explicit logic graphs can in turn help answer\nPCDrelated questions with increased transparency and explainability. We apply\nthis approach to the popular PCD and conversational machine reading benchmark,\nShARC, and show competitive performance with no task-specific finetuning. We\nalso leverage the inherently interpretable architecture of LDPC to understand\nwhere errors occur, revealing ambiguities in the ShARC dataset and highlighting\nthe challenges involved with reasoning for conversational question answering.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11335v1",
    "published_date": "2025-01-20 08:40:15 UTC",
    "updated_date": "2025-01-20 08:40:15 UTC"
  },
  {
    "arxiv_id": "2501.13953v1",
    "title": "Redundancy Principles for MLLMs Benchmarks",
    "authors": [
      "Zicheng Zhang",
      "Xiangyu Zhao",
      "Xinyu Fang",
      "Chunyi Li",
      "Xiaohong Liu",
      "Xiongkuo Min",
      "Haodong Duan",
      "Kai Chen",
      "Guangtao Zhai"
    ],
    "abstract": "With the rapid iteration of Multi-modality Large Language Models (MLLMs) and\nthe evolving demands of the field, the number of benchmarks produced annually\nhas surged into the hundreds. The rapid growth has inevitably led to\nsignificant redundancy among benchmarks. Therefore, it is crucial to take a\nstep back and critically assess the current state of redundancy and propose\ntargeted principles for constructing effective MLLM benchmarks. In this paper,\nwe focus on redundancy from three key perspectives: 1) Redundancy of benchmark\ncapability dimensions, 2) Redundancy in the number of test questions, and 3)\nCross-benchmark redundancy within specific domains. Through the comprehensive\nanalysis over hundreds of MLLMs' performance across more than 20 benchmarks, we\naim to quantitatively measure the level of redundancy lies in existing MLLM\nevaluations, provide valuable insights to guide the future development of MLLM\nbenchmarks, and offer strategies to refine and address redundancy issues\neffectively.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13953v1",
    "published_date": "2025-01-20 08:09:42 UTC",
    "updated_date": "2025-01-20 08:09:42 UTC"
  },
  {
    "arxiv_id": "2501.11325v1",
    "title": "CatV2TON: Taming Diffusion Transformers for Vision-Based Virtual Try-On with Temporal Concatenation",
    "authors": [
      "Zheng Chong",
      "Wenqing Zhang",
      "Shiyue Zhang",
      "Jun Zheng",
      "Xiao Dong",
      "Haoxiang Li",
      "Yiling Wu",
      "Dongmei Jiang",
      "Xiaodan Liang"
    ],
    "abstract": "Virtual try-on (VTON) technology has gained attention due to its potential to\ntransform online retail by enabling realistic clothing visualization of images\nand videos. However, most existing methods struggle to achieve high-quality\nresults across image and video try-on tasks, especially in long video\nscenarios. In this work, we introduce CatV2TON, a simple and effective\nvision-based virtual try-on (V2TON) method that supports both image and video\ntry-on tasks with a single diffusion transformer model. By temporally\nconcatenating garment and person inputs and training on a mix of image and\nvideo datasets, CatV2TON achieves robust try-on performance across static and\ndynamic settings. For efficient long-video generation, we propose an\noverlapping clip-based inference strategy that uses sequential frame guidance\nand Adaptive Clip Normalization (AdaCN) to maintain temporal consistency with\nreduced resource demands. We also present ViViD-S, a refined video try-on\ndataset, achieved by filtering back-facing frames and applying 3D mask\nsmoothing for enhanced temporal consistency. Comprehensive experiments\ndemonstrate that CatV2TON outperforms existing methods in both image and video\ntry-on tasks, offering a versatile and reliable solution for realistic virtual\ntry-ons across diverse scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "68T42 (Primary) 168T45 (Secondary)",
      "I.4.9"
    ],
    "primary_category": "cs.CV",
    "comment": "11 pages, 8 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2501.11325v1",
    "published_date": "2025-01-20 08:09:36 UTC",
    "updated_date": "2025-01-20 08:09:36 UTC"
  },
  {
    "arxiv_id": "2501.11309v2",
    "title": "Finer-CAM: Spotting the Difference Reveals Finer Details for Visual Explanation",
    "authors": [
      "Ziheng Zhang",
      "Jianyang Gu",
      "Arpita Chowdhury",
      "Zheda Mai",
      "David Carlyn",
      "Tanya Berger-Wolf",
      "Yu Su",
      "Wei-Lun Chao"
    ],
    "abstract": "Class activation map (CAM) has been widely used to highlight image regions\nthat contribute to class predictions. Despite its simplicity and computational\nefficiency, CAM often struggles to identify discriminative regions that\ndistinguish visually similar fine-grained classes. Prior efforts address this\nlimitation by introducing more sophisticated explanation processes, but at the\ncost of extra complexity. In this paper, we propose Finer-CAM, a method that\nretains CAM's efficiency while achieving precise localization of discriminative\nregions. Our key insight is that the deficiency of CAM lies not in \"how\" it\nexplains, but in \"what\" it explains. Specifically, previous methods attempt to\nidentify all cues contributing to the target class's logit value, which\ninadvertently also activates regions predictive of visually similar classes. By\nexplicitly comparing the target class with similar classes and spotting their\ndifferences, Finer-CAM suppresses features shared with other classes and\nemphasizes the unique, discriminative details of the target class. Finer-CAM is\neasy to implement, compatible with various CAM methods, and can be extended to\nmulti-modal models for accurate localization of specific concepts.\nAdditionally, Finer-CAM allows adjustable comparison strength, enabling users\nto selectively highlight coarse object contours or fine discriminative details.\nQuantitatively, we show that masking out the top 5% of activated pixels by\nFiner-CAM results in a larger relative confidence drop compared to baselines.\nThe source code and demo are available at\nhttps://github.com/Imageomics/Finer-CAM.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted by CVPR 2025",
    "pdf_url": "http://arxiv.org/pdf/2501.11309v2",
    "published_date": "2025-01-20 07:23:11 UTC",
    "updated_date": "2025-03-31 15:30:00 UTC"
  },
  {
    "arxiv_id": "2501.11306v1",
    "title": "Collaborative Imputation of Urban Time Series through Cross-city Meta-learning",
    "authors": [
      "Tong Nie",
      "Wei Ma",
      "Jian Sun",
      "Yu Yang",
      "Jiannong Cao"
    ],
    "abstract": "Urban time series, such as mobility flows, energy consumption, and pollution\nrecords, encapsulate complex urban dynamics and structures. However, data\ncollection in each city is impeded by technical challenges such as budget\nlimitations and sensor failures, necessitating effective data imputation\ntechniques that can enhance data quality and reliability. Existing imputation\nmodels, categorized into learning-based and analytics-based paradigms, grapple\nwith the trade-off between capacity and generalizability. Collaborative\nlearning to reconstruct data across multiple cities holds the promise of\nbreaking this trade-off. Nevertheless, urban data's inherent irregularity and\nheterogeneity issues exacerbate challenges of knowledge sharing and\ncollaboration across cities. To address these limitations, we propose a novel\ncollaborative imputation paradigm leveraging meta-learned implicit neural\nrepresentations (INRs). INRs offer a continuous mapping from domain coordinates\nto target values, integrating the strengths of both paradigms. By imposing\nembedding theory, we first employ continuous parameterization to handle\nirregularity and reconstruct the dynamical system. We then introduce a\ncross-city collaborative learning scheme through model-agnostic meta learning,\nincorporating hierarchical modulation and normalization techniques to\naccommodate multiscale representations and reduce variance in response to\nheterogeneity. Extensive experiments on a diverse urban dataset from 20 global\ncities demonstrate our model's superior imputation performance and\ngeneralizability, underscoring the effectiveness of collaborative imputation in\nresource-constrained settings.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11306v1",
    "published_date": "2025-01-20 07:12:40 UTC",
    "updated_date": "2025-01-20 07:12:40 UTC"
  },
  {
    "arxiv_id": "2501.11301v3",
    "title": "Question-to-Question Retrieval for Hallucination-Free Knowledge Access: An Approach for Wikipedia and Wikidata Question Answering",
    "authors": [
      "Santhosh Thottingal"
    ],
    "abstract": "This paper introduces an approach to question answering over knowledge bases\nlike Wikipedia and Wikidata by performing \"question-to-question\" matching and\nretrieval from a dense vector embedding store. Instead of embedding document\ncontent, we generate a comprehensive set of questions for each logical content\nunit using an instruction-tuned LLM. These questions are vector-embedded and\nstored, mapping to the corresponding content. Vector embedding of user queries\nare then matched against this question vector store. The highest similarity\nscore leads to direct retrieval of the associated article content, eliminating\nthe need for answer generation. Our method achieves high cosine similarity ( >\n0.9 ) for relevant question pairs, enabling highly precise retrieval. This\napproach offers several advantages including computational efficiency, rapid\nresponse times, and increased scalability. We demonstrate its effectiveness on\nWikipedia and Wikidata, including multimedia content through structured fact\nretrieval from Wikidata, opening up new pathways for multimodal question\nanswering.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11301v3",
    "published_date": "2025-01-20 07:05:15 UTC",
    "updated_date": "2025-02-21 04:58:38 UTC"
  },
  {
    "arxiv_id": "2501.13952v2",
    "title": "The Dual-use Dilemma in LLMs: Do Empowering Ethical Capacities Make a Degraded Utility?",
    "authors": [
      "Yiyi Zhang",
      "Xingyu Chen",
      "Kexin Chen",
      "Yuyang Du",
      "Xilin Dang",
      "Pheng-Ann Heng"
    ],
    "abstract": "Recent years have witnessed extensive efforts to enhance Large Language\nModels (LLMs) across various domains, alongside growing attention to their\nethical implications. However, a critical challenge remains largely overlooked:\nLLMs must balance between rejecting harmful requests for safety and\naccommodating legitimate ones for utility. This paper presents a Direct\nPreference Optimization (DPO) based alignment framework that achieves better\noverall performance by addressing this ethical-utility trade-off, using\nchemical domain applications as a proof-of-concept. Our alignment pipeline\nstarts with a GPT-assisted three-phase data generation scheme, in which we\ncreate LibraChemQA, a chemical question-answering dataset comprising 31.6k\ntriplet instances. By incorporating an innovative balanced seed in the data\ngeneration process, our framework systematically considers both legitimate and\nillegitimate requests. The framework also introduces a rephrasing mechanism for\nefficient data augmentation that enhances the model's chemical comprehension.\nWe further develop a novel hybrid evaluation scheme with LLM judges for precise\nassessment of both safety and utility. Experimental results demonstrate our\nmodel's substantial improvements in overall performance where both safety and\nutility are considered - the resulting model outperforms leading LLMs including\nClaude-3, GPT-4o, and LLaMA-3 by margins of 13.44%, 7.16%, and 7.10%\nrespectively on our released benchmark. At the end of this paper, we analyze\nexperimental results obtained from testing DeepSeek-R1 on our benchmark and\nreveal the critical ethical concerns raised by this highly acclaimed model. We\nhighlight that the long Chain-of-Thought (CoT) reasoning process employed by\nDeepSeek-R1, as well as other LLMs distilled from it, introduces significant\nethical vulnerabilities when exposed to users.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13952v2",
    "published_date": "2025-01-20 06:35:01 UTC",
    "updated_date": "2025-02-27 07:51:29 UTC"
  },
  {
    "arxiv_id": "2501.11293v1",
    "title": "A Machine Learning Framework for Handling Unreliable Absence Label and Class Imbalance for Marine Stinger Beaching Prediction",
    "authors": [
      "Amuche Ibenegbu",
      "Amandine Schaeffer",
      "Pierre Lafaye de Micheaux",
      "Rohitash Chandra"
    ],
    "abstract": "Bluebottles (\\textit{Physalia} spp.) are marine stingers resembling\njellyfish, whose presence on Australian beaches poses a significant public risk\ndue to their venomous nature. Understanding the environmental factors driving\nbluebottles ashore is crucial for mitigating their impact, and machine learning\ntools are to date relatively unexplored. We use bluebottle marine stinger\npresence/absence data from beaches in Eastern Sydney, Australia, and compare\nmachine learning models (Multilayer Perceptron, Random Forest, and XGBoost) to\nidentify factors influencing their presence. We address challenges such as\nclass imbalance, class overlap, and unreliable absence data by employing data\naugmentation techniques, including the Synthetic Minority Oversampling\nTechnique (SMOTE), Random Undersampling, and Synthetic Negative Approach that\nexcludes the negative class. Our results show that SMOTE failed to resolve\nclass overlap, but the presence-focused approach effectively handled imbalance,\nclass overlap, and ambiguous absence data. The data attributes such as the wind\ndirection, which is a circular variable, emerged as a key factor influencing\nbluebottle presence, confirming previous inference studies. However, in the\nabsence of population dynamics, biological behaviours, and life cycles, the\nbest predictive model appears to be Random Forests combined with Synthetic\nNegative Approach. This research contributes to mitigating the risks posed by\nbluebottles to beachgoers and provides insights into handling class overlap and\nunreliable negative class in environmental modelling.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11293v1",
    "published_date": "2025-01-20 06:28:27 UTC",
    "updated_date": "2025-01-20 06:28:27 UTC"
  },
  {
    "arxiv_id": "2501.11284v1",
    "title": "RedStar: Does Scaling Long-CoT Data Unlock Better Slow-Reasoning Systems?",
    "authors": [
      "Haotian Xu",
      "Xing Wu",
      "Weinong Wang",
      "Zhongzhi Li",
      "Da Zheng",
      "Boyuan Chen",
      "Yi Hu",
      "Shijia Kang",
      "Jiaming Ji",
      "Yingying Zhang",
      "Zhijiang Guo",
      "Yaodong Yang",
      "Muhan Zhang",
      "Debing Zhang"
    ],
    "abstract": "Can scaling transform reasoning? In this work, we explore the untapped\npotential of scaling Long Chain-of-Thought (Long-CoT) data to 1000k samples,\npioneering the development of a slow-thinking model, RedStar. Through extensive\nexperiments with various LLMs and different sizes, we uncover the ingredients\nfor specialization and scale for Long-CoT training. Surprisingly, even smaller\nmodels show significant performance gains with limited data, revealing the\nsample efficiency of Long-CoT and the critical role of sample difficulty in the\nlearning process. Our findings demonstrate that Long-CoT reasoning can be\neffectively triggered with just a few thousand examples, while larger models\nachieve unparalleled improvements. We also introduce reinforcement learning\n(RL)-scale training as a promising direction for advancing slow-thinking\nsystems. RedStar shines across domains: on the MATH-Hard benchmark,\nRedStar-code-math boosts performance from 66.2\\% to 81.6\\%, and on the USA Math\nOlympiad (AIME), it solves 46.7\\% of problems using only 21k mixed-code-math\ndatasets. In multimodal tasks like GeoQA and MathVista-GEO, RedStar-Geo\nachieves competitive results with minimal Long-CoT data, outperforming other\nslow-thinking systems like QvQ-Preview. Compared to QwQ, RedStar strikes the\nperfect balance between reasoning and generalizability. Our work highlights\nthat, with careful tuning, scaling Long-CoT can unlock extraordinary reasoning\ncapabilities-even with limited dataset and set a new standard for slow-thinking\nmodels across diverse challenges. Our data and models are released at\nhttps://huggingface.co/RedStar-Reasoning.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.LG",
    "comment": "technique-report, https://huggingface.co/RedStar-Reasoning",
    "pdf_url": "http://arxiv.org/pdf/2501.11284v1",
    "published_date": "2025-01-20 05:44:01 UTC",
    "updated_date": "2025-01-20 05:44:01 UTC"
  },
  {
    "arxiv_id": "2501.17879v1",
    "title": "Task and Perception-aware Distributed Source Coding for Correlated Speech under Bandwidth-constrained Channels",
    "authors": [
      "Sagnik Bhattacharya",
      "Muhammad Ahmed Mohsin",
      "Ahsan Bilal",
      "John M. Cioffi"
    ],
    "abstract": "Emerging wireless AR/VR applications require real-time transmission of\ncorrelated high-fidelity speech from multiple resource-constrained devices over\nunreliable, bandwidth-limited channels. Existing autoencoder-based speech\nsource coding methods fail to address the combination of the following - (1)\ndynamic bitrate adaptation without retraining the model, (2) leveraging\ncorrelations among multiple speech sources, and (3) balancing downstream task\nloss with realism of reconstructed speech. We propose a neural distributed\nprincipal component analysis (NDPCA)-aided distributed source coding algorithm\nfor correlated speech sources transmitting to a central receiver. Our method\nincludes a perception-aware downstream task loss function that balances\nperceptual realism with task-specific performance. Experiments show significant\nPSNR improvements under bandwidth constraints over naive autoencoder methods in\ntask-agnostic (19%) and task-aware settings (52%). It also approaches the\ntheoretical upper bound, where all correlated sources are sent to a single\nencoder, especially in low-bandwidth scenarios. Additionally, we present a\nrate-distortion-perception trade-off curve, enabling adaptive decisions based\non application-specific realism needs.",
    "categories": [
      "cs.IT",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "eess.SP",
      "math.IT"
    ],
    "primary_category": "cs.IT",
    "comment": "Published at AAAI 2025 Workshop",
    "pdf_url": "http://arxiv.org/pdf/2501.17879v1",
    "published_date": "2025-01-20 04:57:29 UTC",
    "updated_date": "2025-01-20 04:57:29 UTC"
  },
  {
    "arxiv_id": "2501.11270v1",
    "title": "Spatiotemporal Air Quality Mapping in Urban Areas Using Sparse Sensor Data, Satellite Imagery, Meteorological Factors, and Spatial Features",
    "authors": [
      "Osama Ahmad",
      "Zubair Khalid",
      "Muhammad Tahir",
      "Momin Uppal"
    ],
    "abstract": "Monitoring air pollution is crucial for protecting human health from exposure\nto harmful substances. Traditional methods of air quality monitoring, such as\nground-based sensors and satellite-based remote sensing, face limitations due\nto high deployment costs, sparse sensor coverage, and environmental\ninterferences. To address these challenges, this paper proposes a framework for\nhigh-resolution spatiotemporal Air Quality Index (AQI) mapping using sparse\nsensor data, satellite imagery, and various spatiotemporal factors. By\nleveraging Graph Neural Networks (GNNs), we estimate AQI values at unmonitored\nlocations based on both spatial and temporal dependencies. The framework\nincorporates a wide range of environmental features, including meteorological\ndata, road networks, points of interest (PoIs), population density, and urban\ngreen spaces, which enhance prediction accuracy. We illustrate the use of our\napproach through a case study in Lahore, Pakistan, where multi-resolution data\nis used to generate the air quality index map at a fine spatiotemporal scale.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11270v1",
    "published_date": "2025-01-20 04:39:13 UTC",
    "updated_date": "2025-01-20 04:39:13 UTC"
  },
  {
    "arxiv_id": "2501.11264v1",
    "title": "Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian",
    "authors": [
      "Wannita Takerngsaksiri",
      "Micheal Fu",
      "Chakkrit Tantithamthavorn",
      "Jirat Pasuksmit",
      "Kun Chen",
      "Ming Wu"
    ],
    "abstract": "Programmers spend a significant amount of time reading code during the\nsoftware development process. This trend is amplified by the emergence of large\nlanguage models (LLMs) that automatically generate code. However, little is\nknown about the readability of the LLM-generated code and whether it is still\nimportant from practitioners' perspectives in this new era. In this paper, we\nconduct a survey to explore the practitioners' perspectives on code readability\nin the age of LLMs and investigate the readability of our LLM-based software\ndevelopment agents framework, HULA, by comparing its generated code with\nhuman-written code in real-world scenarios. Overall, the findings underscore\nthat (1) readability remains a critical aspect of software development; (2) the\nreadability of our LLM-generated code is comparable to human-written code,\nfostering the establishment of appropriate trust and driving the broad adoption\nof our LLM-powered software development platform.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.SE",
    "comment": "6 pages, 2 figures, 5 tables, under review",
    "pdf_url": "http://arxiv.org/pdf/2501.11264v1",
    "published_date": "2025-01-20 04:11:21 UTC",
    "updated_date": "2025-01-20 04:11:21 UTC"
  },
  {
    "arxiv_id": "2501.13951v2",
    "title": "A Layered Multi-Expert Framework for Long-Context Mental Health Assessments",
    "authors": [
      "Jinwen Tang",
      "Qiming Guo",
      "Wenbo Sun",
      "Yi Shang"
    ],
    "abstract": "Long-form mental health assessments pose unique challenges for large language\nmodels (LLMs), which often exhibit hallucinations or inconsistent reasoning\nwhen handling extended, domain-specific contexts. We introduce Stacked\nMulti-Model Reasoning (SMMR), a layered framework that leverages multiple LLMs\nand specialized smaller models as coequal 'experts'. Early layers isolate\nshort, discrete subtasks, while later layers integrate and refine these partial\noutputs through more advanced long-context models. We evaluate SMMR on the\nDAIC-WOZ depression-screening dataset and 48 curated case studies with\npsychiatric diagnoses, demonstrating consistent improvements over single-model\nbaselines in terms of accuracy, F1-score, and PHQ-8 error reduction. By\nharnessing diverse 'second opinions', SMMR mitigates hallucinations, captures\nsubtle clinical nuances, and enhances reliability in high-stakes mental health\nassessments. Our findings underscore the value of multi-expert frameworks for\nmore trustworthy AI-driven screening.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13951v2",
    "published_date": "2025-01-20 03:22:19 UTC",
    "updated_date": "2025-02-07 20:22:31 UTC"
  },
  {
    "arxiv_id": "2501.11238v1",
    "title": "WSSM: Geographic-enhanced hierarchical state-space model for global station weather forecast",
    "authors": [
      "Songru Yang",
      "Zili Liu",
      "Zhenwei Shi",
      "Zhengxia Zou"
    ],
    "abstract": "Global Station Weather Forecasting (GSWF), a prominent meteorological\nresearch area, is pivotal in providing timely localized weather predictions.\nDespite the progress existing models have made in the overall accuracy of the\nGSWF, executing high-precision extreme event prediction still presents a\nsubstantial challenge. The recent emergence of state-space models, with their\nability to efficiently capture continuous-time dynamics and latent states,\noffer potential solutions. However, early investigations indicated that Mamba\nunderperforms in the context of GSWF, suggesting further adaptation and\noptimization. To tackle this problem, in this paper, we introduce Weather\nState-space Model (WSSM), a novel Mamba-based approach tailored for GSWF.\nGeographical knowledge is integrated in addition to the widely-used positional\nencoding to represent the absolute special-temporal position. The multi-scale\ntime-frequency features are synthesized from coarse to fine to model the\nseasonal to extreme weather dynamic. Our method effectively improves the\noverall prediction accuracy and addresses the challenge of forecasting extreme\nweather events. The state-of-the-art results obtained on the Weather-5K subset\nunderscore the efficacy of the WSSM",
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11238v1",
    "published_date": "2025-01-20 02:57:02 UTC",
    "updated_date": "2025-01-20 02:57:02 UTC"
  },
  {
    "arxiv_id": "2501.13949v1",
    "title": "Can OpenAI o1 Reason Well in Ophthalmology? A 6,990-Question Head-to-Head Evaluation Study",
    "authors": [
      "Sahana Srinivasan",
      "Xuguang Ai",
      "Minjie Zou",
      "Ke Zou",
      "Hyunjae Kim",
      "Thaddaeus Wai Soon Lo",
      "Krithi Pushpanathan",
      "Yiming Kong",
      "Anran Li",
      "Maxwell Singer",
      "Kai Jin",
      "Fares Antaki",
      "David Ziyou Chen",
      "Dianbo Liu",
      "Ron A. Adelman",
      "Qingyu Chen",
      "Yih Chung Tham"
    ],
    "abstract": "Question: What is the performance and reasoning ability of OpenAI o1 compared\nto other large language models in addressing ophthalmology-specific questions?\n  Findings: This study evaluated OpenAI o1 and five LLMs using 6,990\nophthalmological questions from MedMCQA. O1 achieved the highest accuracy\n(0.88) and macro-F1 score but ranked third in reasoning capabilities based on\ntext-generation metrics. Across subtopics, o1 ranked first in ``Lens'' and\n``Glaucoma'' but second to GPT-4o in ``Corneal and External Diseases'',\n``Vitreous and Retina'' and ``Oculoplastic and Orbital Diseases''. Subgroup\nanalyses showed o1 performed better on queries with longer ground truth\nexplanations.\n  Meaning: O1's reasoning enhancements may not fully extend to ophthalmology,\nunderscoring the need for domain-specific refinements to optimize performance\nin specialized fields like ophthalmology.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "44 pages",
    "pdf_url": "http://arxiv.org/pdf/2501.13949v1",
    "published_date": "2025-01-20 02:40:01 UTC",
    "updated_date": "2025-01-20 02:40:01 UTC"
  },
  {
    "arxiv_id": "2501.11223v3",
    "title": "Reasoning Language Models: A Blueprint",
    "authors": [
      "Maciej Besta",
      "Julia Barth",
      "Eric Schreiber",
      "Ales Kubicek",
      "Afonso Catarino",
      "Robert Gerstenberger",
      "Piotr Nyczyk",
      "Patrick Iff",
      "Yueling Li",
      "Sam Houliston",
      "Tomasz Sternal",
      "Marcin Copik",
      "Grzegorz Kwaśniewski",
      "Jürgen Müller",
      "Łukasz Flis",
      "Hannes Eberhard",
      "Hubert Niewiadomski",
      "Torsten Hoefler"
    ],
    "abstract": "Reasoning language models (RLMs), also known as Large Reasoning Models\n(LRMs), such as OpenAI's o1 and o3, DeepSeek-V3, and Alibaba's QwQ, have\nredefined AI's problem-solving capabilities by extending LLMs with advanced\nreasoning mechanisms. Yet, their high costs, proprietary nature, and complex\narchitectures - uniquely combining Reinforcement Learning (RL), search\nheuristics, and LLMs - present accessibility and scalability challenges. To\naddress these, we propose a comprehensive blueprint that organizes RLM\ncomponents into a modular framework, based on a survey and analysis of all RLM\nworks. This blueprint incorporates diverse reasoning structures (chains, trees,\ngraphs, and nested forms), reasoning strategies (e.g., Monte Carlo Tree Search,\nBeam Search), RL concepts (policy, value models and others), supervision\nschemes (Outcome-Based and Process-Based Supervision), and other related\nconcepts (e.g., Test-Time Compute, Retrieval-Augmented Generation, agent\ntools). We also provide detailed mathematical formulations and algorithmic\nspecifications to simplify RLM implementation. By showing how schemes like\nLLaMA-Berry, QwQ, Journey Learning, and Graph of Thoughts fit as special cases,\nwe demonstrate the blueprint's versatility and unifying potential. To\nillustrate its utility, we introduce x1, a modular implementation for rapid RLM\nprototyping and experimentation. Using x1 and a literature review, we provide\nkey insights, such as multi-phase training for policy and value models, and the\nimportance of familiar training distributions. Finally, we discuss scalable RLM\ncloud deployments and we outline how RLMs can integrate with a broader LLM\necosystem. Our work demystifies RLM construction, democratizes advanced\nreasoning capabilities, and fosters innovation, aiming to mitigate the gap\nbetween \"rich AI\" and \"poor AI\" by lowering barriers to RLM design and\nexperimentation.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.11223v3",
    "published_date": "2025-01-20 02:16:19 UTC",
    "updated_date": "2025-01-23 14:26:08 UTC"
  },
  {
    "arxiv_id": "2501.11218v3",
    "title": "Leveraging GANs For Active Appearance Models Optimized Model Fitting",
    "authors": [
      "Anurag Awasthi"
    ],
    "abstract": "Active Appearance Models (AAMs) are a well-established technique for fitting\ndeformable models to images, but they are limited by linear appearance\nassumptions and can struggle with complex variations. In this paper, we explore\nif the AAM fitting process can benefit from a Generative Adversarial Network\n(GAN). We uses a U-Net based generator and a PatchGAN discriminator for\nGAN-augmented framework in an attempt to refine the appearance model during\nfitting. This approach attempts to addresses challenges such as non-linear\nappearance variations and occlusions that traditional AAM optimization methods\nmay fail to handle. Limited experiments on face alignment datasets demonstrate\nthat the GAN-enhanced AAM can achieve higher accuracy and faster convergence\nthan classic approaches with some manual interventions. These results establish\nfeasibility of GANs as a tool for improving deformable model fitting in\nchallenging conditions while maintaining efficient performance, and establishes\nthe need for more future work to evaluate this approach at scale.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "The full text of this preprint has been withdrawn, as it was\n  submitted in error at a much earlier stage, with work still needing\n  substantial refinement and validation. Therefore, the authors do not wish\n  this work to be cited as a reference",
    "pdf_url": "http://arxiv.org/pdf/2501.11218v3",
    "published_date": "2025-01-20 01:49:37 UTC",
    "updated_date": "2025-04-07 04:07:08 UTC"
  },
  {
    "arxiv_id": "2501.16355v1",
    "title": "How Strategic Agents Respond: Comparing Analytical Models with LLM-Generated Responses in Strategic Classification",
    "authors": [
      "Tian Xie",
      "Pavan Rauch",
      "Xueru Zhang"
    ],
    "abstract": "When machine learning (ML) algorithms are used to automate human-related\ndecisions, human agents may gain knowledge of the decision policy and behave\nstrategically to obtain desirable outcomes. Strategic Classification (SC) has\nbeen proposed to address the interplay between agents and decision-makers.\nPrior work on SC has relied on assumptions that agents are perfectly or\napproximately rational, responding to decision policies by maximizing their\nutilities. Verifying these assumptions is challenging due to the difficulty of\ncollecting real-world agent responses. Meanwhile, the growing adoption of large\nlanguage models (LLMs) makes it increasingly likely that human agents in SC\nsettings will seek advice from these tools. We propose using strategic advice\ngenerated by LLMs to simulate human agent responses in SC. Specifically, we\nexamine five critical SC scenarios -- hiring, loan applications, school\nadmissions, personal income, and public assistance programs -- and simulate how\nhuman agents with diverse profiles seek advice from LLMs. We then compare the\nresulting agent responses with the best responses generated by existing\ntheoretical models. Our findings reveal that: (i) LLMs and theoretical models\ngenerally lead to agent score or qualification changes in the same direction\nacross most settings, with both achieving similar levels of fairness; (ii)\nstate-of-the-art commercial LLMs (e.g., GPT-3.5, GPT-4) consistently provide\nhelpful suggestions, though these suggestions typically do not result in\nmaximal score or qualification improvements; and (iii) LLMs tend to produce\nmore diverse agent responses, often favoring more balanced effort allocation\nstrategies. These results suggest that theoretical models align with LLMs to\nsome extent and that leveraging LLMs to simulate more realistic agent responses\noffers a promising approach to designing trustworthy ML systems.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.16355v1",
    "published_date": "2025-01-20 01:39:03 UTC",
    "updated_date": "2025-01-20 01:39:03 UTC"
  },
  {
    "arxiv_id": "2503.15499v1",
    "title": "Approach to Visual Attractiveness of Event Space Through Data-Driven Environment and Spatial Perception",
    "authors": [
      "Aliffi Majiid",
      "Riaz-Ul-Haque Mian",
      "Kouki Kurohara",
      "Yen-Khang Nguyen-Tran"
    ],
    "abstract": "Revitalizing Japan's remote areas has become a crucial task, and Matsue City\nexemplifies this effort in its temporary event spaces, created through\ncollective efforts to foster urban vibrancy and bring together residents and\nvisitors. This research examines the relationship between data-driven in-sights\nusing generative AI and visual attractiveness by evaluating tempo-rary events\nin Matsue City, particularly considering the cognitive-cultural differences in\nprocessing visual information of the participants. The first phase employs\nsemantic keyword extraction from interviews, categorizing responses into\nphysical elements, activities, and atmosphere. The second phase analyzes\nspatial perception through three categories: layout hierar-chy, product\nvisibility, and visual attention. The correlation indicates that successful\nevent design requires a balance between spatial efficiency and diverse needs,\nwith a spatial organization that optimizes visitor flow and visibility\nstrategies considering cultural and demographic diversity. These findings\ncontribute to understanding the urban quality of temporary event spaces and\noffer a replicable framework for enhancing the visual appeal of events in\nremote areas throughout Japan.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2503.15499v1",
    "published_date": "2025-01-20 00:55:15 UTC",
    "updated_date": "2025-01-20 00:55:15 UTC"
  },
  {
    "arxiv_id": "2501.13948v2",
    "title": "Longitudinal Abuse and Sentiment Analysis of Hollywood Movie Dialogues using LLMs",
    "authors": [
      "Rohitash Chandra",
      "Guoxiang Ren",
      "Group-H"
    ],
    "abstract": "Over the past decades, there has been an increasing concern about the\nprevalence of abusive and violent content in Hollywood movies. This study uses\nLarge Language Models (LLMs) to explore the longitudinal abuse and sentiment\nanalysis of Hollywood Oscar and blockbuster movie dialogues from 1950 to 2024.\nBy employing fine-tuned LLMs, we analyze subtitles for over a thousand movies\ncategorised into four genres to examine the trends and shifts in emotional and\nabusive content over the past seven decades. Our findings reveal significant\ntemporal changes in movie dialogues, which reflect broader social and cultural\ninfluences. Overall, the emotional tendencies in the films are diverse, and the\ndetection of abusive content also exhibits significant fluctuations. The\nresults show a gradual rise in abusive content in recent decades, reflecting\nsocial norms and regulatory policy changes. Genres such as thrillers still\npresent a higher frequency of abusive content that emphasises the ongoing\nnarrative role of violence and conflict. At the same time, underlying positive\nemotions such as humour and optimism remain prevalent in most of the movies.\nFurthermore, the gradual increase of abusive content in movie dialogues has\nbeen significant over the last two decades, where Oscar-nominated movies\novertook the top ten blockbusters.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2501.13948v2",
    "published_date": "2025-01-20 00:44:38 UTC",
    "updated_date": "2025-02-22 00:09:40 UTC"
  }
]