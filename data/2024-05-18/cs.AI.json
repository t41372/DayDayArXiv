{
  "date": "2024-05-18",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-05-18 的 arXiv 中文 TLDR 快报！\n\n今天 arXiv 的论文主要聚焦于 AI 和机器学习领域，包括多模态模型的创新（如 Uni-MoE 的混合专家架构）、强化学习基准（如 PDE Control Gym 的新环境）和鲁棒性提升（如 MapCoder 的代码生成 SOTA 性能），令人印象深刻的是这些论文展示了 AI 在实际应用中的潜力，例如 EyeFound 在眼科诊断和 RuleFuser 在机器人规划中的进展。\n\n下面，我将挑选并简要讨论部分重要论文，先从高影响力或话题度高的文章入手，再快速掠过其他相关内容。每个条目会列出论文标题（中文 + 英文），并清晰描述主要贡献和发现。\n\n### 1. **高影响力 AI 和多模态模型**\n- **MapCoder: Multi-Agent Code Generation for Competitive Problem Solving（多代理代码生成用于竞争问题求解）**  \n  这篇论文提出了一种多代理提示框架 MapCoder，由 Md. Ashraful Islam 等作者开发。它模拟人类编程流程，通过多个代理分别处理示例回忆、规划、代码生成和调试，实现了代码合成任务的新 SOTA 结果：在 HumanEval 上达到 93.9% 的 pass@1 准确率。该方法提升了代码生成在多语言和复杂场景下的鲁棒性，适用于编程自动化。\n\n- **Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts（使用混合专家扩展统一多模态大语言模型）**  \n  作者 Yunxin Li 等构建了 Uni-MoE，一个支持多种模态（如图像和文本）的混合专家模型。通过模态特定编码器和分层训练，模型在多模态任务中表现出色，显著提高了专家协作和泛化能力。该发现为多模态 LLM 扩展提供了高效路径，代码已在 GitHub 开源。\n\n- **EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging（眼科成像的多模态通用基础模型）**  \n  这篇论文由 Danli Shi 等作者提出，EyeFound 模型从 2.78 百万张眼科图像中学习泛化表示，能处理诊断、预测和视觉问答任务。它超越了先前的 RETFound，在检测罕见眼病和多模态任务中表现出色，减少了专家标注负担，促进临床 AI 应用。\n\n### 2. **强化学习和机器人规划**\n- **PDE Control Gym: A Benchmark for Data-Driven Boundary Control of Partial Differential Equations（PDE 控制基准：用于偏微分方程边界控制的数据驱动基准）**  \n  作者 Luke Bhan 等开发了第一个基于强化学习的 PDE 控制环境，包括 1D 和 2D 问题。该基准支持模型无关算法训练，实现了稳定性控制，虽然成本高于传统方法，但显著降低了学习 PDE 控制的门槛，已在 GitHub 开源。\n\n- **Meta-Control: Automatic Model-based Control Synthesis for Heterogeneous Robot Skills（元控制：用于异构机器人技能的自动模型化控制合成）**  \n  Tianhao Wei 等作者的这篇论文引入了 Meta-Control，使用 LLM 自动生成定制化控制策略。该方法模仿人类专家的层次思考模型，支持实时执行和鲁棒分析，适用于机器人任务规划，提升了机器人在复杂环境下的适应性。\n\n- **RuleFuser: An Evidential Bayes Approach for Rule Injection in Imitation Learned Planners（RuleFuser：用于模仿学习规划器的证据贝叶斯规则注入方法）**  \n  作者 Jay Patrikar 等提出了一种结合模仿学习和规则的框架，在 nuPlan 数据集上提升了机器人规划的鲁棒性。该方法在分布偏移场景下提高了安全指标（如减少碰撞），将 AI 规划与安全规则融合，具有实际部署潜力。\n\n### 3. **其他关键应用和方法（快速掠过）**\n- **GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing（GinAR：适合变量缺失的多变量时间序列预测端到端模型）**  \n  Chengqing Yu 等作者的模型使用插值注意力和自适应图卷积处理缺失数据，在 KDD 2024 基准上超越 SOTA，即使 90% 变量缺失时仍保持准确预测。该贡献提升了时间序列预测的鲁棒性。\n\n- **Double Correction Framework for Denoising Recommendation（推荐系统去噪的双重修正框架）**  \n  Zhuangzhuang He 等作者的框架通过损失修正和标签重标定减少隐式反馈噪声，在 KDD 2024 数据集上改善了推荐性能。该方法平衡了数据利用和准确性，避免了过度稀疏问题。\n\n- **SeBot: Structural Entropy Guided Multi-View Contrastive Learning for Social Bot Detection（SeBot：结构熵引导的多视图对比学习用于社交机器人检测）**  \n  Yingguang Yang 等作者的模型使用结构熵优化图结构，在 KDD 2024 上提升了检测准确率。该发现增强了社交网络的安全性，但细节较技术化。\n\n其他论文如 SimAD（时间序列异常检测）、Adaptive Stabilization（优化算法稳定化）和 EnviroExam（环境科学 LLM 基准）等，虽然有一定价值，但相对基础或领域特定，我这里仅简要提及：它们分别在异常检测、组合优化和知识评估上提供了新方法，但未达到广泛话题度，故不展开讨论。\n\n总之，今天的 arXiv 论文突出了 AI 模型的鲁棒性和实际应用潜力，读者可关注 Uni-MoE 和 MapCoder 等前沿工作。如果您对特定领域感兴趣，建议直接查看这些论文的摘要！",
  "papers": [
    {
      "arxiv_id": "2405.11412v1",
      "title": "Simulating Petri nets with Boolean Matrix Logic Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Lun Ai",
        "Stephen H. Muggleton",
        "Shi-Shun Liang",
        "Geoff S. Baldwin"
      ],
      "abstract": "Recent attention to relational knowledge bases has sparked a demand for\nunderstanding how relations change between entities. Petri nets can represent\nknowledge structure and dynamically simulate interactions between entities, and\nthus they are well suited for achieving this goal. However, logic programs\nstruggle to deal with extensive Petri nets due to the limitations of high-level\nsymbol manipulations. To address this challenge, we introduce a novel approach\ncalled Boolean Matrix Logic Programming (BMLP), utilising boolean matrices as\nan alternative computation mechanism for Prolog to evaluate logic programs.\nWithin this framework, we propose two novel BMLP algorithms for simulating a\nclass of Petri nets known as elementary nets. This is done by transforming\nelementary nets into logically equivalent datalog programs. We demonstrate\nempirically that BMLP algorithms can evaluate these programs 40 times faster\nthan tabled B-Prolog, SWI-Prolog, XSB-Prolog and Clingo. Our work enables the\nefficient simulation of elementary nets using Prolog, expanding the scope of\nanalysis, learning and verification of complex systems with logic programming\ntechniques.",
      "tldr_zh": "该研究针对逻辑程序在处理大型Petri nets时的高级符号操作限制，引入了Boolean Matrix Logic Programming (BMLP)框架，使用布尔矩阵作为Prolog的计算机制来模拟实体互动。研究者提出两种新BMLP算法，将一种Petri nets的子类——elementary nets——转化为等价的datalog程序，从而实现高效模拟。实验结果显示，这些算法比tabled B-Prolog、SWI-Prolog、XSB-Prolog和Clingo等基准系统快40倍，这扩展了逻辑编程在复杂系统分析、学习和验证中的应用潜力。",
      "categories": [
        "cs.AI",
        "cs.SC"
      ],
      "primary_category": "cs.AI",
      "comment": "arXiv admin note: text overlap with arXiv:2405.06724",
      "pdf_url": "http://arxiv.org/pdf/2405.11412v1",
      "published_date": "2024-05-18 23:17:00 UTC",
      "updated_date": "2024-05-18 23:17:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:26:44.873482"
    },
    {
      "arxiv_id": "2405.11403v1",
      "title": "MapCoder: Multi-Agent Code Generation for Competitive Problem Solving",
      "title_zh": "翻译失败",
      "authors": [
        "Md. Ashraful Islam",
        "Mohammed Eunus Ali",
        "Md Rizwan Parvez"
      ],
      "abstract": "Code synthesis, which requires a deep understanding of complex natural\nlanguage problem descriptions, generation of code instructions for complex\nalgorithms and data structures, and the successful execution of comprehensive\nunit tests, presents a significant challenge. While large language models\n(LLMs) demonstrate impressive proficiency in natural language processing, their\nperformance in code generation tasks remains limited. In this paper, we\nintroduce a new approach to code generation tasks leveraging multi-agent\nprompting that uniquely replicates the full cycle of program synthesis as\nobserved in human developers. Our framework, MapCoder, consists of four LLM\nagents specifically designed to emulate the stages of this cycle: recalling\nrelevant examples, planning, code generation, and debugging. After conducting\nthorough experiments, with multiple LLM ablations and analyses across eight\nchallenging competitive problem-solving and program synthesis benchmarks,\nMapCoder showcases remarkable code generation capabilities, achieving new\nstate-of-the-art results (pass@1) on HumanEval (93.9%), MBPP (83.1%), APPS\n(22.0%), CodeContests (28.5%), and xCodeEval (45.3%). Moreover, our method\nconsistently delivers superior performance across various programming languages\nand varying problem difficulties. We open-source our framework at\nhttps://github.com/Md-Ashraful-Pramanik/MapCoder.",
      "tldr_zh": "本研究提出MapCoder，一种基于多智能体提示(multi-agent prompting)的代码生成框架，旨在模拟人类开发者的程序合成过程，以解决大型语言模型(LLMs)在理解复杂问题描述、生成算法和数据结构代码以及执行单元测试等方面的局限性。MapCoder包括四个专门设计的LLM代理：回忆相关例子(recalling relevant examples)、规划、代码生成和调试，通过这些阶段实现高效的代码合成。在八个竞争性问题解决基准上进行实验，该框架取得了新的state-of-the-art结果，例如HumanEval (93.9%)、MBPP (83.1%)和APPS (22.0%)，并在多种编程语言和问题难度上表现出色，同时开源了框架以促进进一步研究。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11403v1",
      "published_date": "2024-05-18 22:10:15 UTC",
      "updated_date": "2024-05-18 22:10:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:26:57.327573"
    },
    {
      "arxiv_id": "2405.11402v1",
      "title": "A Model for Optimal Resilient Planning Subject to Fallible Actuators",
      "title_zh": "翻译失败",
      "authors": [
        "Kyle Baldes",
        "Diptanil Chaudhuri",
        "Jason M. O'Kane",
        "Dylan A. Shell"
      ],
      "abstract": "Robots incurring component failures ought to adapt their behavior to best\nrealize still-attainable goals under reduced capacity. We formulate the problem\nof planning with actuators known a priori to be susceptible to failure within\nthe Markov Decision Processes (MDP) framework. The model captures\nutilization-driven malfunction and state-action dependent likelihoods of\nactuator failure in order to enable reasoning about potential impairment and\nthe long-term implications of impoverished future control. This leads to\nbehavior differing qualitatively from plans which ignore failure. As actuators\nmalfunction, there are combinatorially many configurations which can arise. We\nidentify opportunities to save computation through re-use, exploiting the\nobservation that differing configurations yield closely related problems. Our\nresults show how strategic solutions are obtained so robots can respond when\nfailures do occur -- for instance, in prudently scheduling utilization in order\nto keep critical actuators in reserve.",
      "tldr_zh": "该论文提出了一种针对易故障执行器（fallible actuators）的优化弹性规划模型，使用Markov Decision Processes (MDP)框架来处理机器人组件故障问题。该模型捕捉利用驱动的故障和状态-动作依赖的故障可能性，允许机器人评估潜在损害并调整长期行为，从而与忽略故障的传统规划产生质的差异。为了应对故障导致的组合爆炸配置，论文识别了通过问题重用来节省计算的机会。实验结果显示，该方法能生成战略性解决方案，例如谨慎调度执行器利用率以保留关键组件，提高机器人在故障情境下的适应性。",
      "categories": [
        "cs.RO",
        "cs.AI"
      ],
      "primary_category": "cs.RO",
      "comment": "8 pages, 5 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)",
      "pdf_url": "http://arxiv.org/pdf/2405.11402v1",
      "published_date": "2024-05-18 22:07:38 UTC",
      "updated_date": "2024-05-18 22:07:38 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:27:08.275385"
    },
    {
      "arxiv_id": "2405.11401v2",
      "title": "PDE Control Gym: A Benchmark for Data-Driven Boundary Control of Partial Differential Equations",
      "title_zh": "翻译失败",
      "authors": [
        "Luke Bhan",
        "Yuexin Bian",
        "Miroslav Krstic",
        "Yuanyuan Shi"
      ],
      "abstract": "Over the last decade, data-driven methods have surged in popularity, emerging\nas valuable tools for control theory. As such, neural network approximations of\ncontrol feedback laws, system dynamics, and even Lyapunov functions have\nattracted growing attention. With the ascent of learning based control, the\nneed for accurate, fast, and easy-to-use benchmarks has increased. In this\nwork, we present the first learning-based environment for boundary control of\nPDEs. In our benchmark, we introduce three foundational PDE problems - a 1D\ntransport PDE, a 1D reaction-diffusion PDE, and a 2D Navier-Stokes PDE - whose\nsolvers are bundled in an user-friendly reinforcement learning gym. With this\ngym, we then present the first set of model-free, reinforcement learning\nalgorithms for solving this series of benchmark problems, achieving stability,\nalthough at a higher cost compared to model-based PDE backstepping. With the\nset of benchmark environments and detailed examples, this work significantly\nlowers the barrier to entry for learning-based PDE control - a topic largely\nunexplored by the data-driven control community. The entire benchmark is\navailable on Github along with detailed documentation and the presented\nreinforcement learning models are open sourced.",
      "tldr_zh": "本文提出PDE Control Gym，这是一个用于数据驱动边界控制的基准环境，旨在简化偏微分方程(PDE)控制问题的学习和实验。基准包括三个基础PDE问题：1D传输PDE、1D反应-扩散PDE和2D Navier-Stokes PDE，这些问题整合到一个用户友好的强化学习(reinforcement learning) gym中。作者展示了首个无模型的强化学习算法来解决这些基准问题，实现了系统稳定性，但比基于模型的PDE backstepping方法成本更高。该基准开源在GitHub上，提供详细文档和模型，显著降低了学习-based PDE控制的进入门槛。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.CE",
        "cs.LG",
        "cs.SY",
        "math.OC"
      ],
      "primary_category": "eess.SY",
      "comment": "26 pages 10 figures. Accepted L4DC 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11401v2",
      "published_date": "2024-05-18 22:01:55 UTC",
      "updated_date": "2024-05-24 01:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:27:20.796799"
    },
    {
      "arxiv_id": "2405.11397v1",
      "title": "Preparing for Black Swans: The Antifragility Imperative for Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Ming Jin"
      ],
      "abstract": "Operating safely and reliably despite continual distribution shifts is vital\nfor high-stakes machine learning applications. This paper builds upon the\ntransformative concept of ``antifragility'' introduced by (Taleb, 2014) as a\nconstructive design paradigm to not just withstand but benefit from volatility.\nWe formally define antifragility in the context of online decision making as\ndynamic regret's strictly concave response to environmental variability,\nrevealing limitations of current approaches focused on resisting rather than\nbenefiting from nonstationarity. Our contribution lies in proposing potential\ncomputational pathways for engineering antifragility, grounding the concept in\nonline learning theory and drawing connections to recent advancements in areas\nsuch as meta-learning, safe exploration, continual learning,\nmulti-objective/quality-diversity optimization, and foundation models. By\nidentifying promising mechanisms and future research directions, we aim to put\nantifragility on a rigorous theoretical foundation in machine learning. We\nfurther emphasize the need for clear guidelines, risk assessment frameworks,\nand interdisciplinary collaboration to ensure responsible application.",
      "tldr_zh": "这篇论文探讨了机器学习在高风险应用中应对持续分布变化的挑战，引入了Taleb (2014)提出的“antifragility”概念，作为一种不仅仅抵御波动，而是从中获益的设计范式。作者正式定义了在线决策中的antifragility，即dynamic regret对环境变异性的严格凹响应，并指出了当前专注于抵抗nonstationarity的方法的局限性。论文的主要贡献是提出工程antifragility的潜在计算路径，将其根植于在线学习理论，并与meta-learning、safe exploration、continual learning、多目标/质量多样性优化以及foundation models等领域的最新进展相联系。通过识别有前景的机制和未来研究方向，论文旨在为机器学习中的antifragility建立严格的理论基础，并强调需要清晰的指导方针、风险评估框架和跨学科合作以确保负责任的应用。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11397v1",
      "published_date": "2024-05-18 21:32:29 UTC",
      "updated_date": "2024-05-18 21:32:29 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:27:34.499091"
    },
    {
      "arxiv_id": "2405.11380v3",
      "title": "Meta-Control: Automatic Model-based Control Synthesis for Heterogeneous Robot Skills",
      "title_zh": "Meta-Control：针对异构机器人技能的自动基于模型的控制合成",
      "authors": [
        "Tianhao Wei",
        "Liqian Ma",
        "Rui Chen",
        "Weiye Zhao",
        "Changliu Liu"
      ],
      "abstract": "The requirements for real-world manipulation tasks are diverse and often\nconflicting; some tasks require precise motion while others require force\ncompliance; some tasks require avoidance of certain regions, while others\nrequire convergence to certain states. Satisfying these varied requirements\nwith a fixed state-action representation and control strategy is challenging,\nimpeding the development of a universal robotic foundation model. In this work,\nwe propose Meta-Control, the first LLM-enabled automatic control synthesis\napproach that creates customized state representations and control strategies\ntailored to specific tasks. Our core insight is that a meta-control system can\nbe built to automate the thought process that human experts use to design\ncontrol systems. Specifically, human experts heavily use a model-based,\nhierarchical (from abstract to concrete) thought model, then compose various\ndynamic models and controllers together to form a control system. Meta-Control\nmimics the thought model and harnesses LLM's extensive control knowledge with\nSocrates' \"art of midwifery\" to automate the thought process. Meta-Control\nstands out for its fully model-based nature, allowing rigorous analysis,\ngeneralizability, robustness, efficient parameter tuning, and reliable\nreal-time execution.",
      "tldr_zh": "该研究针对真实世界操作任务的多样性和冲突要求（如精确运动 vs. 力顺应、避开区域 vs. 收敛状态），提出Meta-Control，这是一个基于LLM的自动控制合成方法，能为特定任务创建定制的状态表示和控制策略。Meta-Control模仿人类专家的模型-based、层次化思考过程（从抽象到具体），通过结合动态模型和控制器来自动化设计控制系统，利用LLM的广泛知识实现“助产术”式推理。相比固定策略，该框架的优势在于其完全模型-based特性，支持严格分析、可推广性、鲁棒性、有效的参数调整以及可靠的实时执行，从而推进通用机器人基础模型的发展。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.SY",
        "eess.SY"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11380v3",
      "published_date": "2024-05-18 19:58:44 UTC",
      "updated_date": "2024-12-11 20:36:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:27:44.612464"
    },
    {
      "arxiv_id": "2405.11347v1",
      "title": "Cooperative Multi-agent Approach for Automated Computer Game Testing",
      "title_zh": "翻译失败",
      "authors": [
        "Samira Shirzadeh-hajimahmood",
        "I. S. W. B. Prasteya",
        "Mehdi Dastani",
        "Frank Dignum"
      ],
      "abstract": "Automated testing of computer games is a challenging problem, especially when\nlengthy scenarios have to be tested. Automating such a scenario boils down to\nfinding the right sequence of interactions given an abstract description of the\nscenario. Recent works have shown that an agent-based approach works well for\nthe purpose, e.g. due to agents' reactivity, hence enabling a test agent to\nimmediately react to game events and changing state. Many games nowadays are\nmulti-player. This opens up an interesting possibility to deploy multiple\ncooperative test agents to test such a game, for example to speed up the\nexecution of multiple testing tasks. This paper offers a cooperative\nmulti-agent testing approach and a study of its performance based on a case\nstudy on a 3D game called Lab Recruits.",
      "tldr_zh": "本研究针对自动化计算机游戏测试的挑战，特别是长场景测试中需要找到正确交互序列的问题，提出了一种合作 multi-agent 方法，利用多个代理的反应性和协作能力来加速测试任务。相比传统单代理方法，该框架允许代理协同处理多玩家游戏场景，从而提高测试效率。研究通过对 3D 游戏 Lab Recruits 的案例研究，评估了该方法的性能，展示了其在实际应用中的潜力。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11347v1",
      "published_date": "2024-05-18 17:31:26 UTC",
      "updated_date": "2024-05-18 17:31:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:27:55.948061"
    },
    {
      "arxiv_id": "2405.13045v1",
      "title": "CoLay: Controllable Layout Generation through Multi-conditional Latent Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Chin-Yi Cheng",
        "Ruiqi Gao",
        "Forrest Huang",
        "Yang Li"
      ],
      "abstract": "Layout design generation has recently gained significant attention due to its\npotential applications in various fields, including UI, graphic, and floor plan\ndesign. However, existing models face two main challenges that limits their\nadoption in practice. Firstly, the limited expressiveness of individual\ncondition types used in previous works restricts designers' ability to convey\ncomplex design intentions and constraints. Secondly, most existing models focus\non generating labels and coordinates, while real layouts contain a range of\nstyle properties. To address these limitations, we propose a novel framework,\nCoLay, that integrates multiple condition types and generates complex layouts\nwith diverse style properties. Our approach outperforms prior works in terms of\ngeneration quality and condition satisfaction while empowering users to express\ntheir design intents using a flexible combination of modalities, including\nnatural language prompts, layout guidelines, element types, and partially\ncompleted designs.",
      "tldr_zh": "该研究针对布局设计生成的局限性，提出了一种新型框架CoLay，通过Multi-conditional Latent Diffusion模型整合多种条件类型（如自然语言提示、布局指南、元素类型和部分设计），以生成包含复杂风格属性的布局。CoLay解决了现有模型在条件表达有限和忽略风格属性方面的挑战，允许设计师更灵活地传达设计意图。实验结果显示，该框架在生成质量和条件满足度上优于先前工作，为UI、图形和楼层规划等领域提供了更强大的工具。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13045v1",
      "published_date": "2024-05-18 17:30:48 UTC",
      "updated_date": "2024-05-18 17:30:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:28:07.479372"
    },
    {
      "arxiv_id": "2405.11346v2",
      "title": "Decision support system for Forest fire management using Ontology with Big Data and LLMs",
      "title_zh": "基于本体、大数据和LL",
      "authors": [
        "Ritesh Chandra",
        "Shashi Shekhar Kumar",
        "Rushil Patra",
        "Sonali Agarwal"
      ],
      "abstract": "Forests are crucial for ecological balance, but wildfires, a major cause of\nforest loss, pose significant risks. Fire weather indices, which assess\nwildfire risk and predict resource demands, are vital. With the rise of sensor\nnetworks in fields like healthcare and environmental monitoring, semantic\nsensor networks are increasingly used to gather climatic data such as wind\nspeed, temperature, and humidity. However, processing these data streams to\ndetermine fire weather indices presents challenges, underscoring the growing\nimportance of effective forest fire detection. This paper discusses using\nApache Spark for early forest fire detection, enhancing fire risk prediction\nwith meteorological and geographical data. Building on our previous development\nof Semantic Sensor Network (SSN) ontologies and Semantic Web Rules Language\n(SWRL) for managing forest fires in Monesterial Natural Park, we expanded SWRL\nto improve a Decision Support System (DSS) using a Large Language Models (LLMs)\nand Spark framework. We implemented real-time alerts with Spark streaming,\ntailored to various fire scenarios, and validated our approach using ontology\nmetrics, query-based evaluations, LLMs score precision, F1 score, and recall\nmeasures.",
      "tldr_zh": "这篇论文提出了一种决策支持系统(DSS)，利用本体(Ontology)、大数据(Big Data)和大型语言模型(LLMs)来提升森林火灾管理，包括早期检测和风险预测。方法基于扩展的Semantic Web Rules Language(SWRL)，结合Apache Spark进行实时数据流处理和警报生成，以整合气象、地理数据并应对不同火灾场景。实验结果通过本体指标、查询评估、LLMs精确度、F1分数和召回率验证，显示了系统在森林火险预测方面的显著改进。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11346v2",
      "published_date": "2024-05-18 17:30:30 UTC",
      "updated_date": "2024-09-23 06:13:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:28:20.489618"
    },
    {
      "arxiv_id": "2405.11345v3",
      "title": "City-Scale Multi-Camera Vehicle Tracking System with Improved Self-Supervised Camera Link Model",
      "title_zh": "城市规模多摄像头车辆跟踪系统，采用改进的自监督摄像头链接模型",
      "authors": [
        "Yuqiang Lin",
        "Sam Lockyer",
        "Nic Zhang"
      ],
      "abstract": "Multi-Target Multi-Camera Tracking (MTMCT) has broad applications and forms\nthe basis for numerous future city-wide systems (e.g. traffic management, crash\ndetection, etc.). However, the challenge of matching vehicle trajectories\nacross different cameras based solely on feature extraction poses significant\ndifficulties. This article introduces an innovative multi-camera vehicle\ntracking system that utilizes a self-supervised camera link model. In contrast\nto related works that rely on manual spatial-temporal annotations, our model\nautomatically extracts crucial multi-camera relationships for vehicle matching.\nThe camera link is established through a pre-matching process that evaluates\nfeature similarities, pair numbers, and time variance for high-quality tracks.\nThis process calculates the probability of spatial linkage for all camera\ncombinations, selecting the highest scoring pairs to create camera links. Our\napproach significantly improves deployment times by eliminating the need for\nhuman annotation, offering substantial improvements in efficiency and\ncost-effectiveness when it comes to real-world application. This pairing\nprocess supports cross camera matching by setting spatial-temporal constraints,\nreducing the searching space for potential vehicle matches. According to our\nexperimental results, the proposed method achieves a new state-of-the-art among\nautomatic camera-link based methods in CityFlow V2 benchmarks with 61.07% IDF1\nScore.",
      "tldr_zh": "这篇论文提出了一种改进的自监督摄像头链接模型，用于城市规模的多摄像头车辆追踪系统（Multi-Target Multi-Camera Tracking, MTMCT），旨在解决基于特征提取的跨摄像头车辆匹配挑战。模型通过自动提取多摄像头关系，包括预匹配过程评估特征相似性、配对数量和时间变化，以计算空间链接概率并选择最高评分配对，从而建立摄像头链接并设置空间-时间约束，减少匹配搜索空间。与依赖手动标注的相关工作相比，该方法显著提高了部署效率和成本效益。实验结果显示，在 CityFlow V2 基准测试中，该系统实现了 61.07% 的 IDF1 Score，在自动摄像头链接方法中达到新状态-of-the-art。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Upload the revised manuscript with the publisher's requirement",
      "pdf_url": "http://arxiv.org/pdf/2405.11345v3",
      "published_date": "2024-05-18 17:28:35 UTC",
      "updated_date": "2025-02-14 11:55:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:28:35.230734"
    },
    {
      "arxiv_id": "2405.11344v3",
      "title": "LiPost: Improved Content Understanding With Effective Use of Multi-task Contrastive Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Akanksha Bindal",
        "Sudarshan Ramanujam",
        "Dave Golland",
        "TJ Hazen",
        "Tina Jiang",
        "Fengyu Zhang",
        "Peng Yan"
      ],
      "abstract": "In enhancing LinkedIn core content recommendation models, a significant\nchallenge lies in improving their semantic understanding capabilities. This\npaper addresses the problem by leveraging multi-task learning, a method that\nhas shown promise in various domains. We fine-tune a pre-trained,\ntransformer-based LLM using multi-task contrastive learning with data from a\ndiverse set of semantic labeling tasks. We observe positive transfer, leading\nto superior performance across all tasks when compared to training\nindependently on each. Our model outperforms the baseline on zero shot learning\nand offers improved multilingual support, highlighting its potential for\nbroader application. The specialized content embeddings produced by our model\noutperform generalized embeddings offered by OpenAI on Linkedin dataset and\ntasks. This work provides a robust foundation for vertical teams across\nLinkedIn to customize and fine-tune the LLM to their specific applications. Our\nwork offers insights and best practices for the field to build on.",
      "tldr_zh": "本研究针对LinkedIn内容推荐模型的语义理解能力问题，提出LiPost框架，通过多任务对比学习(multi-task contrastive learning)微调预训练的transformer-based LLM，利用多种语义标注任务的数据进行训练。实验结果显示，该方法实现了正向转移(positive transfer)，在所有任务上优于独立训练的模型，并在零样本学习(zero shot learning)以及多语言支持(multilingual support)方面超越基线。LiPost生成的专用内容嵌入(content embeddings)比OpenAI的通用嵌入在LinkedIn数据集上表现更佳，为LinkedIn垂直团队定制和微调LLM提供了一个稳健的基础，并分享了相关见解和最佳实践。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11344v3",
      "published_date": "2024-05-18 17:28:29 UTC",
      "updated_date": "2024-07-13 20:00:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:28:47.403027"
    },
    {
      "arxiv_id": "2405.11338v2",
      "title": "EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging",
      "title_zh": "EyeFound: 用于眼科成像的多模",
      "authors": [
        "Danli Shi",
        "Weiyi Zhang",
        "Xiaolan Chen",
        "Yexin Liu",
        "Jiancheng Yang",
        "Siyu Huang",
        "Yih Chung Tham",
        "Yingfeng Zheng",
        "Mingguang He"
      ],
      "abstract": "Artificial intelligence (AI) is vital in ophthalmology, tackling tasks like\ndiagnosis, classification, and visual question answering (VQA). However,\nexisting AI models in this domain often require extensive annotation and are\ntask-specific, limiting their clinical utility. While recent developments have\nbrought about foundation models for ophthalmology, they are limited by the need\nto train separate weights for each imaging modality, preventing a comprehensive\nrepresentation of multi-modal features. This highlights the need for versatile\nfoundation models capable of handling various tasks and modalities in\nophthalmology. To address this gap, we present EyeFound, a multimodal\nfoundation model for ophthalmic images. Unlike existing models, EyeFound learns\ngeneralizable representations from unlabeled multimodal retinal images,\nenabling efficient model adaptation across multiple applications. Trained on\n2.78 million images from 227 hospitals across 11 ophthalmic modalities,\nEyeFound facilitates generalist representations and diverse multimodal\ndownstream tasks, even for detecting challenging rare diseases. It outperforms\nprevious work RETFound in diagnosing eye diseases, predicting systemic disease\nincidents, and zero-shot multimodal VQA. EyeFound provides a generalizable\nsolution to improve model performance and lessen the annotation burden on\nexperts, facilitating widespread clinical AI applications for retinal imaging.",
      "tldr_zh": "本论文提出 EyeFound，一种多模态基础模型，用于眼科成像领域，旨在解决现有 AI 模型在诊断、分类和视觉问答 (VQA) 等任务上需要大量标注且任务特定的局限性。EyeFound 通过从未标注的 2.78 百万多模态视网膜图像（覆盖 11 个眼科模式和 227 家医院）中学习泛化表示，实现高效适应多种下游任务，包括检测罕见疾病。实验结果显示，EyeFound 在诊断眼病、预测系统性疾病事件以及零样本多模态 VQA 上优于现有模型 RETFound，提高了性能并减轻了专家的标注负担，促进眼科临床 AI 应用的广泛采用。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "21 pages, 2 figures, 4 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.11338v2",
      "published_date": "2024-05-18 17:03:39 UTC",
      "updated_date": "2024-05-22 02:21:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:29:02.942626"
    },
    {
      "arxiv_id": "2405.11333v1",
      "title": "GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing",
      "title_zh": "翻译失败",
      "authors": [
        "Chengqing Yu",
        "Fei Wang",
        "Zezhi Shao",
        "Tangwen Qian",
        "Zhao Zhang",
        "Wei Wei",
        "Yongjun Xu"
      ],
      "abstract": "Multivariate time series forecasting (MTSF) is crucial for decision-making to\nprecisely forecast the future values/trends, based on the complex relationships\nidentified from historical observations of multiple sequences. Recently,\nSpatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme\nof MTSF model as their powerful capability in mining spatial-temporal\ndependencies, but almost of them heavily rely on the assumption of historical\ndata integrity. In reality, due to factors such as data collector failures and\ntime-consuming repairment, it is extremely challenging to collect the whole\nhistorical observations without missing any variable. In this case, STGNNs can\nonly utilize a subset of normal variables and easily suffer from the incorrect\nspatial-temporal dependency modeling issue, resulting in the degradation of\ntheir forecasting performance. To address the problem, in this paper, we\npropose a novel Graph Interpolation Attention Recursive Network (named GinAR)\nto precisely model the spatial-temporal dependencies over the limited collected\ndata for forecasting. In GinAR, it consists of two key components, that is,\ninterpolation attention and adaptive graph convolution to take place of the\nfully connected layer of simple recursive units, and thus are capable of\nrecovering all missing variables and reconstructing the correct\nspatial-temporal dependencies for recursively modeling of multivariate time\nseries data, respectively. Extensive experiments conducted on five real-world\ndatasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when\n90% of variables are missing, it can still accurately predict the future values\nof all variables.",
      "tldr_zh": "该研究针对多变量时间序列预测（MTSF）中变量缺失的问题，提出了一种端到端模型GinAR，以解决现有Spatial-Temporal Graph Neural Networks (STGNNs)对完整数据依赖的局限性。GinAR的核心组件包括interpolation attention用于恢复缺失变量，以及adaptive graph convolution重构正确的空间-时间依赖关系，从而实现对有限数据的递归建模。在五个真实数据集上的实验中，GinAR优于11个最先进基线，即使缺失90%的变量，仍然能准确预测所有变量的未来值。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted by KDD 2024 (Research track)",
      "pdf_url": "http://arxiv.org/pdf/2405.11333v1",
      "published_date": "2024-05-18 16:42:44 UTC",
      "updated_date": "2024-05-18 16:42:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:29:12.913742"
    },
    {
      "arxiv_id": "2405.11331v2",
      "title": "Generalized Multi-Objective Reinforcement Learning with Envelope Updates in URLLC-enabled Vehicular Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Zijiang Yan",
        "Hina Tabassum"
      ],
      "abstract": "We develop a novel multi-objective reinforcement learning (MORL) framework to\njointly optimize wireless network selection and autonomous driving policies in\na multi-band vehicular network operating on conventional sub-6GHz spectrum and\nTerahertz frequencies. The proposed framework is designed to 1. maximize the\ntraffic flow and 2. minimize collisions by controlling the vehicle's motion\ndynamics (i.e., speed and acceleration), and enhance the ultra-reliable\nlow-latency communication (URLLC) while minimizing handoffs (HOs). We cast this\nproblem as a multi-objective Markov Decision Process (MOMDP) and develop\nsolutions for both predefined and unknown preferences of the conflicting\nobjectives. Specifically, deep-Q-network and double deep-Q-network-based\nsolutions are developed first that consider scalarizing the transportation and\ntelecommunication rewards using predefined preferences. We then develop a novel\nenvelope MORL solution which develop policies that address multiple objectives\nwith unknown preferences to the agent. While this approach reduces reliance on\nscalar rewards, policy effectiveness varying with different preferences is a\nchallenge. To address this, we apply a generalized version of the Bellman\nequation and optimize the convex envelope of multi-objective Q values to learn\na unified parametric representation capable of generating optimal policies\nacross all possible preference configurations. Following an initial learning\nphase, our agent can execute optimal policies under any specified preference or\ninfer preferences from minimal data samples.Numerical results validate the\nefficacy of the envelope-based MORL solution and demonstrate interesting\ninsights related to the inter-dependency of vehicle motion dynamics, HOs, and\nthe communication data rate. The proposed policies enable autonomous vehicles\nto adopt safe driving behaviors with improved connectivity.",
      "tldr_zh": "本研究提出了一种通用的多目标强化学习 (MORL) 框架，用于在支持超可靠低延迟通信 (URLLC) 的车辆网络中，联合优化无线网络选择和自动驾驶策略，目标包括最大化交通流量、最小化碰撞、增强 URLLC 并减少切换 (HOs)。该框架将问题建模为多目标 Markov 决策过程 (MOMDP)，开发了基于 Deep-Q-Network (DQN) 和 Double DQN 的解决方案来处理预定义偏好，同时引入了新型 Envelope MORL 方法，通过优化多目标 Q 值的凸包学习统一的参数表示，以适应未知偏好并生成最佳策略。实验结果验证了 Envelope MORL 的有效性，展示了车辆运动动态、HOs 和通信数据速率的相互依赖，并证明了该方法能使自动车辆实现更安全的驾驶行为和改进的连接性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NI"
      ],
      "primary_category": "cs.LG",
      "comment": "Submission for possible publication",
      "pdf_url": "http://arxiv.org/pdf/2405.11331v2",
      "published_date": "2024-05-18 16:31:32 UTC",
      "updated_date": "2025-01-11 00:59:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:29:24.416872"
    },
    {
      "arxiv_id": "2405.11318v2",
      "title": "Smooth Kolmogorov Arnold networks enabling structural knowledge representation",
      "title_zh": "翻译失败",
      "authors": [
        "Moein E. Samadi",
        "Younes Müller",
        "Andreas Schuppert"
      ],
      "abstract": "Kolmogorov-Arnold Networks (KANs) offer an efficient and interpretable\nalternative to traditional multi-layer perceptron (MLP) architectures due to\ntheir finite network topology. However, according to the results of Kolmogorov\nand Vitushkin, the representation of generic smooth functions by KAN\nimplementations using analytic functions constrained to a finite number of\ncutoff points cannot be exact. Hence, the convergence of KAN throughout the\ntraining process may be limited. This paper explores the relevance of\nsmoothness in KANs, proposing that smooth, structurally informed KANs can\nachieve equivalence to MLPs in specific function classes. By leveraging\ninherent structural knowledge, KANs may reduce the data required for training\nand mitigate the risk of generating hallucinated predictions, thereby enhancing\nmodel reliability and performance in computational biomedicine.",
      "tldr_zh": "Kolmogorov-Arnold Networks (KANs) 作为一种高效且可解释的替代传统多层感知器 (MLPs) 的架构，由于其有限网络拓扑，无法精确表示通用平滑函数，从而可能限制训练过程中的收敛性。论文探讨了 KANs 中的平滑性，提出通过整合结构知识来构建平滑的 KANs，使其在特定函数类中实现与 MLPs 的等效。最终，这种方法能减少训练所需的数据，降低生成幻觉预测的风险，并提高模型在计算生物医学领域的可靠性和性能。",
      "categories": [
        "cs.LG",
        "cond-mat.dis-nn",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11318v2",
      "published_date": "2024-05-18 15:27:14 UTC",
      "updated_date": "2024-05-27 09:32:35 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:29:36.267961"
    },
    {
      "arxiv_id": "2405.11305v1",
      "title": "Large Neighborhood Prioritized Search for Combinatorial Optimization with Answer Set Programming",
      "title_zh": "翻译失败",
      "authors": [
        "Irumi Sugimori",
        "Katsumi Inoue",
        "Hidetomo Nabeshima",
        "Torsten Schaub",
        "Takehide Soh",
        "Naoyuki Tamura",
        "Mutsunori Banbara"
      ],
      "abstract": "We propose Large Neighborhood Prioritized Search (LNPS) for solving\ncombinatorial optimization problems in Answer Set Programming (ASP). LNPS is a\nmetaheuristic that starts with an initial solution and then iteratively tries\nto find better solutions by alternately destroying and prioritized searching\nfor a current solution. Due to the variability of neighborhoods, LNPS allows\nfor flexible search without strongly depending on the destroy operators. We\npresent an implementation of LNPS based on ASP. The resulting heulingo solver\ndemonstrates that LNPS can significantly enhance the solving performance of ASP\nfor optimization. Furthermore, we establish the competitiveness of our LNPS\napproach by empirically contrasting it to (adaptive) large neighborhood search.",
      "tldr_zh": "本研究提出了一种名为 Large Neighborhood Prioritized Search (LNPS) 的元启发式(metaheuristic)方法，用于在 Answer Set Programming (ASP) 中解决组合优化问题。LNPS 从一个初始解开始，通过交替破坏当前解和优先化搜索来迭代寻找更好解，其灵活的邻域变异性减少了对破坏操作符的依赖。研究实现了一个基于 ASP 的 LNPS 求解器 heulingo，并通过实验证明它显著提升了 ASP 的求解性能。最后，与自适应 large neighborhood search 对比，LNPS 显示出较高的竞争力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages",
      "pdf_url": "http://arxiv.org/pdf/2405.11305v1",
      "published_date": "2024-05-18 14:37:43 UTC",
      "updated_date": "2024-05-18 14:37:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:29:47.549391"
    },
    {
      "arxiv_id": "2405.11284v3",
      "title": "The Logic of Counterfactuals and the Epistemology of Causal Inference",
      "title_zh": "反事实的逻辑以及因果推理的认识论",
      "authors": [
        "Hanti Lin"
      ],
      "abstract": "The 2021 Nobel Prize in Economics recognized an epistemology of causal\ninference based on the Rubin causal model (Rubin 1974), which merits broader\nattention in philosophy. This model, in fact, presupposes a logical principle\nof counterfactuals, Conditional Excluded Middle (CEM), the locus of a pivotal\ndebate between Stalnaker (1968) and Lewis (1973) on the semantics of\ncounterfactuals. Proponents of CEM should recognize that this connection points\nto a new argument for CEM -- a Quine-Putnam indispensability argument grounded\nin the Nobel-winning applications of the Rubin model in health and social\nsciences. To advance the dialectic, I challenge this argument with an updated\nRubin causal model that retains its successes while dispensing with CEM. This\nnovel approach combines the strengths of the Rubin causal model and a causal\nmodel familiar in philosophy, the causal Bayes net. The takeaway: deductive\nlogic and inductive inference, often studied in isolation, are deeply\ninterconnected.",
      "tldr_zh": "本论文探讨了反事实逻辑（counterfactuals）和因果推理的认识论，聚焦于 Rubin causal model，该模型依赖于条件排中律（Conditional Excluded Middle, CEM），并将其与 Stalnaker 和 Lewis 的语义辩论相联系。作者提出一个基于 Quine-Putnam indispensability argument 的新论证，支持 CEM 在健康和社会科学中的应用。论文挑战这一观点，通过一个更新后的 Rubin causal model 结合 causal Bayes net，保留原有优势同时去除 CEM 的依赖，最终强调演绎逻辑和归纳推理的深层互连。",
      "categories": [
        "cs.AI",
        "econ.EM",
        "stat.ME",
        "stat.OT"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11284v3",
      "published_date": "2024-05-18 13:09:33 UTC",
      "updated_date": "2025-03-12 02:08:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:29:59.399162"
    },
    {
      "arxiv_id": "2405.11282v3",
      "title": "Estimating the Level of Dialectness Predicts Interannotator Agreement in Multi-dialect Arabic Datasets",
      "title_zh": "翻译失败",
      "authors": [
        "Amr Keleg",
        "Walid Magdy",
        "Sharon Goldwater"
      ],
      "abstract": "On annotating multi-dialect Arabic datasets, it is common to randomly assign\nthe samples across a pool of native Arabic speakers. Recent analyses\nrecommended routing dialectal samples to native speakers of their respective\ndialects to build higher-quality datasets. However, automatically identifying\nthe dialect of samples is hard. Moreover, the pool of annotators who are native\nspeakers of specific Arabic dialects might be scarce. Arabic Level of\nDialectness (ALDi) was recently introduced as a quantitative variable that\nmeasures how sentences diverge from Standard Arabic. On randomly assigning\nsamples to annotators, we hypothesize that samples of higher ALDi scores are\nharder to label especially if they are written in dialects that the annotators\ndo not speak. We test this by analyzing the relation between ALDi scores and\nthe annotators' agreement, on 15 public datasets having raw individual sample\nannotations for various sentence-classification tasks. We find strong evidence\nsupporting our hypothesis for 11 of them. Consequently, we recommend\nprioritizing routing samples of high ALDi scores to native speakers of each\nsample's dialect, for which the dialect could be automatically identified at\nhigher accuracies.",
      "tldr_zh": "这篇论文探讨了在多方言阿拉伯语数据集标注中，Arabic Level of Dialectness (ALDi)——一种量化句子偏离标准阿拉伯语程度的指标——如何预测标注者一致性。作者假设高 ALDi 分数的样本更难标注，特别是当标注者不熟悉该方言，并通过分析 15 个公共数据集的原始标注数据验证了这一观点，在 11 个数据集上发现强有力的证据支持。论文推荐优先将高 ALDi 样本路由给相应方言的母语者，以提高标注质量，即使自动识别方言存在挑战。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to ACL 2024 - Main (camera-ready version)",
      "pdf_url": "http://arxiv.org/pdf/2405.11282v3",
      "published_date": "2024-05-18 12:58:02 UTC",
      "updated_date": "2024-06-06 20:32:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:30:11.450422"
    },
    {
      "arxiv_id": "2405.11281v1",
      "title": "Cooperative Cognitive Dynamic System in UAV Swarms: Reconfigurable Mechanism and Framework",
      "title_zh": "翻译失败",
      "authors": [
        "Ziye Jia",
        "Jiahao You",
        "Chao Dong",
        "Qihui Wu",
        "Fuhui Zhou",
        "Dusit Niyato",
        "Zhu Han"
      ],
      "abstract": "As the demands for immediate and effective responses increase in both\ncivilian and military domains, the unmanned aerial vehicle (UAV) swarms emerge\nas effective solutions, in which multiple cooperative UAVs can work together to\nachieve specific goals. However, how to manage such complex systems to ensure\nreal-time adaptability lack sufficient researches. Hence, in this paper, we\npropose the cooperative cognitive dynamic system (CCDS), to optimize the\nmanagement for UAV swarms. CCDS leverages a hierarchical and cooperative\ncontrol structure that enables real-time data processing and decision.\nAccordingly, CCDS optimizes the UAV swarm management via dynamic\nreconfigurability and adaptive intelligent optimization. In addition, CCDS can\nbe integrated with the biomimetic mechanism to efficiently allocate tasks for\nUAV swarms. Further, the distributed coordination of CCDS ensures reliable and\nresilient control, thus enhancing the adaptability and robustness. Finally, the\npotential challenges and future directions are analyzed, to provide insights\ninto managing UAV swarms in dynamic heterogeneous networking.",
      "tldr_zh": "本研究针对无人驾驶航空器（UAV）群在民用和军用领域的实时适应性管理不足问题，提出了一种合作认知动态系统（CCDS）。CCDS 采用分层和合作控制结构，实现实时数据处理、动态可重构性以及适应性智能优化，并通过生物模拟机制（biomimetic mechanism）高效分配任务。实验表明，该系统通过分布式协调增强了 UAV 群的可靠性和鲁棒性，最终分析了潜在挑战和未来方向，以支持动态异构网络中的群管理。",
      "categories": [
        "cs.DC",
        "cs.AI"
      ],
      "primary_category": "cs.DC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11281v1",
      "published_date": "2024-05-18 12:45:00 UTC",
      "updated_date": "2024-05-18 12:45:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:30:22.997137"
    },
    {
      "arxiv_id": "2405.11277v2",
      "title": "Action Controlled Paraphrasing",
      "title_zh": "翻译失败",
      "authors": [
        "Ning Shi",
        "Zijun Wu"
      ],
      "abstract": "Recent studies have demonstrated the potential to control paraphrase\ngeneration, such as through syntax, which has broad applications in various\ndownstream tasks. However, these methods often require detailed parse trees or\nsyntactic exemplars, countering human-like paraphrasing behavior in language\nuse. Furthermore, an inference gap exists, as control specifications are only\navailable during training but not during inference. In this work, we propose a\nnew setup for controlled paraphrase generation. Specifically, we represent user\nintent as action tokens, embedding and concatenating them with text embeddings,\nthus flowing together into a self-attention encoder for representation fusion.\nTo address the inference gap, we introduce an optional action token as a\nplaceholder that encourages the model to determine the appropriate action\nindependently when users' intended actions are not provided. Experimental\nresults show that our method successfully enables precise action-controlled\nparaphrasing and preserves or even enhances performance compared to\nconventional uncontrolled methods when actions are not given. Our findings\npromote the concept of action-controlled paraphrasing for a more user-centered\ndesign.",
      "tldr_zh": "本文提出了一种新的控制改写生成方法，使用 action tokens 表示用户意图，将这些标记嵌入并与文本嵌入拼接后输入自注意力 encoder 进行融合，从而实现精确的意图控制。针对训练与推理间的差距，该方法引入可选的 action token 作为占位符，让模型在用户不提供意图时自行决定适当的动作。实验结果表明，该方法在动作控制改写上表现出色，并在无控制场景下与传统方法相比保持或提升性能，推动了更用户友好的改写生成设计。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Work in Progress",
      "pdf_url": "http://arxiv.org/pdf/2405.11277v2",
      "published_date": "2024-05-18 12:26:31 UTC",
      "updated_date": "2024-07-01 23:23:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:30:36.710655"
    },
    {
      "arxiv_id": "2405.11273v1",
      "title": "Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts",
      "title_zh": "翻译失败",
      "authors": [
        "Yunxin Li",
        "Shenyuan Jiang",
        "Baotian Hu",
        "Longyue Wang",
        "Wanqi Zhong",
        "Wenhan Luo",
        "Lin Ma",
        "Min Zhang"
      ],
      "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) underscore\nthe significance of scalable models and data to boost performance, yet this\noften incurs substantial computational costs. Although the Mixture of Experts\n(MoE) architecture has been employed to efficiently scale large language and\nimage-text models, these efforts typically involve fewer experts and limited\nmodalities. To address this, our work presents the pioneering attempt to\ndevelop a unified MLLM with the MoE architecture, named Uni-MoE that can handle\na wide array of modalities. Specifically, it features modality-specific\nencoders with connectors for a unified multimodal representation. We also\nimplement a sparse MoE architecture within the LLMs to enable efficient\ntraining and inference through modality-level data parallelism and expert-level\nmodel parallelism. To enhance the multi-expert collaboration and\ngeneralization, we present a progressive training strategy: 1) Cross-modality\nalignment using various connectors with different cross-modality data, 2)\nTraining modality-specific experts with cross-modality instruction data to\nactivate experts' preferences, and 3) Tuning the Uni-MoE framework utilizing\nLow-Rank Adaptation (LoRA) on mixed multimodal instruction data. We evaluate\nthe instruction-tuned Uni-MoE on a comprehensive set of multimodal datasets.\nThe extensive experimental results demonstrate Uni-MoE's principal advantage of\nsignificantly reducing performance bias in handling mixed multimodal datasets,\nalongside improved multi-expert collaboration and generalization. Our findings\nhighlight the substantial potential of MoE frameworks in advancing MLLMs and\nthe code is available at\nhttps://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs.",
      "tldr_zh": "该研究提出Uni-MoE，一种基于Mixture of Experts (MoE)架构的统一多模态大语言模型(MLLMs)，旨在通过高效扩展模型和数据处理多种模态，同时减少计算成本。Uni-MoE采用模态特定编码器与连接器实现统一多模态表示，并在LLMs中引入稀疏MoE架构，支持模态级数据并行和专家级模型并行；同时，通过渐进训练策略，包括跨模态对齐、训练模态特定专家以及使用Low-Rank Adaptation (LoRA)微调，提升多专家协作和泛化能力。实验结果显示，Uni-MoE在各种多模态数据集上显著减少性能偏差，并证明MoE框架在推进MLLMs方面的巨大潜力，代码已开源。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CV",
        "cs.MM"
      ],
      "primary_category": "cs.AI",
      "comment": "22 pages, 13 figures. Project Website: https://uni-moe.github.io/.\n  Working in progress",
      "pdf_url": "http://arxiv.org/pdf/2405.11273v1",
      "published_date": "2024-05-18 12:16:01 UTC",
      "updated_date": "2024-05-18 12:16:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:30:48.979272"
    },
    {
      "arxiv_id": "2405.11272v3",
      "title": "Double Correction Framework for Denoising Recommendation",
      "title_zh": "双重修正框架用于去噪推荐",
      "authors": [
        "Zhuangzhuang He",
        "Yifan Wang",
        "Yonghui Yang",
        "Peijie Sun",
        "Le Wu",
        "Haoyue Bai",
        "Jinqi Gong",
        "Richang Hong",
        "Min Zhang"
      ],
      "abstract": "As its availability and generality in online services, implicit feedback is\nmore commonly used in recommender systems. However, implicit feedback usually\npresents noisy samples in real-world recommendation scenarios (such as\nmisclicks or non-preferential behaviors), which will affect precise user\npreference learning. To overcome the noisy samples problem, a popular solution\nis based on dropping noisy samples in the model training phase, which follows\nthe observation that noisy samples have higher training losses than clean\nsamples. Despite the effectiveness, we argue that this solution still has\nlimits. (1) High training losses can result from model optimization instability\nor hard samples, not just noisy samples. (2) Completely dropping of noisy\nsamples will aggravate the data sparsity, which lacks full data exploitation.\nTo tackle the above limitations, we propose a Double Correction Framework for\nDenoising Recommendation (DCF), which contains two correction components from\nviews of more precise sample dropping and avoiding more sparse data. In the\nsample dropping correction component, we use the loss value of the samples over\ntime to determine whether it is noise or not, increasing dropping stability.\nInstead of averaging directly, we use the damping function to reduce the bias\neffect of outliers. Furthermore, due to the higher variance exhibited by hard\nsamples, we derive a lower bound for the loss through concentration inequality\nto identify and reuse hard samples. In progressive label correction, we\niteratively re-label highly deterministic noisy samples and retrain them to\nfurther improve performance. Finally, extensive experimental results on three\ndatasets and four backbones demonstrate the effectiveness and generalization of\nour proposed framework.",
      "tldr_zh": "该论文针对推荐系统中隐式反馈的噪音样本问题（如误点击或非偏好行为）提出了一种 Double Correction Framework for Denoising Recommendation (DCF)，以更精确地处理噪音并缓解数据稀疏问题。框架包括样本丢弃修正组件，通过跟踪样本损失随时间的变化、使用阻尼函数减少异常值影响，以及通过集中不等式推导损失下界来识别和重用难样本；以及渐进标签修正组件，通过迭代重新标记高度确定的噪音样本并重新训练，进一步提升性能。实验结果显示，该框架在三个数据集和四个骨干模型上表现出色，证明了其有效性和泛化能力。",
      "categories": [
        "cs.IR",
        "cs.AI"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted by KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11272v3",
      "published_date": "2024-05-18 12:15:10 UTC",
      "updated_date": "2024-05-28 03:54:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:31:02.337880"
    },
    {
      "arxiv_id": "2405.11265v1",
      "title": "EnviroExam: Benchmarking Environmental Science Knowledge of Large Language Models",
      "title_zh": "EnviroExam: 大语言模型环境科学知识的基准测试",
      "authors": [
        "Yu Huang",
        "Liang Guo",
        "Wanqian Guo",
        "Zhe Tao",
        "Yang Lv",
        "Zhihao Sun",
        "Dongfang Zhao"
      ],
      "abstract": "In the field of environmental science, it is crucial to have robust\nevaluation metrics for large language models to ensure their efficacy and\naccuracy. We propose EnviroExam, a comprehensive evaluation method designed to\nassess the knowledge of large language models in the field of environmental\nscience. EnviroExam is based on the curricula of top international\nuniversities, covering undergraduate, master's, and doctoral courses, and\nincludes 936 questions across 42 core courses. By conducting 0-shot and 5-shot\ntests on 31 open-source large language models, EnviroExam reveals the\nperformance differences among these models in the domain of environmental\nscience and provides detailed evaluation standards. The results show that 61.3%\nof the models passed the 5-shot tests, while 48.39% passed the 0-shot tests. By\nintroducing the coefficient of variation as an indicator, we evaluate the\nperformance of mainstream open-source large language models in environmental\nscience from multiple perspectives, providing effective criteria for selecting\nand fine-tuning language models in this field. Future research will involve\nconstructing more domain-specific test sets using specialized environmental\nscience textbooks to further enhance the accuracy and specificity of the\nevaluation.",
      "tldr_zh": "这篇论文提出了 EnviroExam，一种全面的基准测试方法，用于评估大型语言模型（Large Language Models）在环境科学知识方面的效能和准确性。该方法基于顶尖国际大学的课程，涵盖本科、硕士和博士级别，共包括 936 个问题和 42 门核心课程，并对 31 个开源模型进行了 0-shot 和 5-shot 测试。结果显示，61.3% 的模型通过了 5-shot 测试，48.39% 通过了 0-shot 测试，并通过变异系数（coefficient of variation）从多个角度评估了模型性能，为环境科学领域的模型选择和微调提供了有效标准。未来研究计划使用专业环境科学教材构建更多领域特定测试集，以提升评估的精确性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11265v1",
      "published_date": "2024-05-18 11:31:03 UTC",
      "updated_date": "2024-05-18 11:31:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:31:15.120070"
    },
    {
      "arxiv_id": "2405.11250v3",
      "title": "Argumentative Causal Discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Fabrizio Russo",
        "Anna Rapberger",
        "Francesca Toni"
      ],
      "abstract": "Causal discovery amounts to unearthing causal relationships amongst features\nin data. It is a crucial companion to causal inference, necessary to build\nscientific knowledge without resorting to expensive or impossible randomised\ncontrol trials. In this paper, we explore how reasoning with symbolic\nrepresentations can support causal discovery. Specifically, we deploy\nassumption-based argumentation (ABA), a well-established and powerful knowledge\nrepresentation formalism, in combination with causality theories, to learn\ngraphs which reflect causal dependencies in the data. We prove that our method\nexhibits desirable properties, notably that, under natural conditions, it can\nretrieve ground-truth causal graphs. We also conduct experiments with an\nimplementation of our method in answer set programming (ASP) on four datasets\nfrom standard benchmarks in causal discovery, showing that our method compares\nwell against established baselines.",
      "tldr_zh": "本论文探讨了因果发现（Causal Discovery）问题，即从数据中揭示变量间的因果关系，通过 assumption-based argumentation (ABA) 和 causality theories 相结合的方法来学习反映这些依赖的因果图。\n研究证明，该方法在自然条件下能够准确恢复真实因果图，并展示了其在 answer set programming (ASP) 实现下的鲁棒性。\n在四个标准基准数据集上的实验结果表明，该方法与 established baselines 相比表现良好，为无需随机对照试验的科学知识构建提供了新途径。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to KR2024. Version with Appendix",
      "pdf_url": "http://arxiv.org/pdf/2405.11250v3",
      "published_date": "2024-05-18 10:34:34 UTC",
      "updated_date": "2024-08-03 10:54:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:31:24.738637"
    },
    {
      "arxiv_id": "2405.13044v1",
      "title": "Case-Based Reasoning Approach for Solving Financial Question Answering",
      "title_zh": "基于案例推理的方法用于解决金融问答",
      "authors": [
        "Yikyung Kim",
        "Jay-Yoon Lee"
      ],
      "abstract": "Measuring a machine's understanding of human language often involves\nassessing its reasoning skills, i.e. logical process of deriving answers to\nquestions. While recent language models have shown remarkable proficiency in\ntext based tasks, their efficacy in complex reasoning problems involving\nheterogeneous information such as text, tables, and numbers remain uncertain.\nAddressing this gap, FinQA introduced a numerical reasoning dataset for\nfinancial documents and simultaneously proposed a program generation approach .\nOur investigation reveals that half of the errors (48%) stem from incorrect\noperations being generated. To address this issue, we propose a novel approach\nto tackle numerical reasoning problems using case based reasoning (CBR), an\nartificial intelligence paradigm that provides problem solving guidance by\noffering similar cases (i.e. similar questions and corresponding logical\nprograms). Our model retrieves relevant cases to address a given question, and\nthen generates an answer based on the retrieved cases and contextual\ninformation. Through experiments on the FinQA dataset, we demonstrate\ncompetitive performance of our approach and additionally show that by expanding\ncase repository, we can help solving complex multi step programs which FinQA\nshowed weakness of.",
      "tldr_zh": "本文针对语言模型在处理文本、表格和数字等异构信息的数值推理问题上存在的不足（如FinQA数据集中的48%错误源于操作生成错误），提出了一种基于Case-Based Reasoning (CBR)的方法。CBR方法通过检索类似问题及其逻辑程序的案例，并结合上下文信息来指导答案生成，从而提升推理准确性。在FinQA数据集上的实验表明，该方法表现出竞争性性能，并且通过扩展案例库，能够更好地处理复杂多步程序。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.13044v1",
      "published_date": "2024-05-18 10:06:55 UTC",
      "updated_date": "2024-05-18 10:06:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:31:38.158009"
    },
    {
      "arxiv_id": "2405.11238v1",
      "title": "SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection",
      "title_zh": "SimAD：一种基于差异性的简单方法用于时间序列异常检测",
      "authors": [
        "Zhijie Zhong",
        "Zhiwen Yu",
        "Xing Xi",
        "Yue Xu",
        "Jiahui Chen",
        "Kaixiang Yang"
      ],
      "abstract": "Despite the prevalence of reconstruction-based deep learning methods, time\nseries anomaly detection remains challenging. Existing approaches often\nstruggle with limited temporal contexts, inadequate representation of normal\npatterns, and flawed evaluation metrics, hindering their effectiveness in\nidentifying aberrant behavior. To address these issues, we introduce\n$\\textbf{{SimAD}}$, a $\\textbf{{Sim}}$ple dissimilarity-based approach for time\nseries $\\textbf{{A}}$nomaly $\\textbf{{D}}$etection. SimAD incorporates an\nadvanced feature extractor adept at processing extended temporal windows,\nutilizes the EmbedPatch encoder to integrate normal behavioral patterns\ncomprehensively, and introduces an innovative ContrastFusion module designed to\naccentuate distributional divergences between normal and abnormal data, thereby\nenhancing the robustness of anomaly discrimination. Additionally, we propose\ntwo robust evaluation metrics, UAff and NAff, addressing the limitations of\nexisting metrics and demonstrating their reliability through theoretical and\nexperimental analyses. Experiments across $\\textbf{seven}$ diverse time series\ndatasets demonstrate SimAD's superior performance compared to state-of-the-art\nmethods, achieving relative improvements of $\\textbf{19.85%}$ on F1,\n$\\textbf{4.44%}$ on Aff-F1, $\\textbf{77.79%}$ on NAff-F1, and $\\textbf{9.69%}$\non AUC on six multivariate datasets. Code and pre-trained models are available\nat https://github.com/EmorZz1G/SimAD.",
      "tldr_zh": "本论文提出了一种简单基于差异性的时间序列异常检测方法SimAD，以解决现有重建型深度学习方法在时序上下文有限、正常模式表示不足以及评估指标缺陷等方面的挑战。SimAD 采用先进的特征提取器处理更长的时序窗口、EmbedPatch 编码器全面整合正常行为模式，以及 ContrastFusion 模块突出正常和异常数据之间的分布差异，从而提升异常鉴别鲁棒性。同时，论文引入了两个新的评估指标 UAff 和 NAff，通过理论和实验分析验证其可靠性。在七个多样化数据集上的实验中，SimAD 相较最先进方法在六个多变量数据集上实现了 F1 提升 19.85%、Aff-F1 提升 4.44%、NAff-F1 提升 77.79% 以及 AUC 提升 9.69%。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "18 pages, 12 figures,7 tables, Under review",
      "pdf_url": "http://arxiv.org/pdf/2405.11238v1",
      "published_date": "2024-05-18 09:37:04 UTC",
      "updated_date": "2024-05-18 09:37:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:31:49.591526"
    },
    {
      "arxiv_id": "2405.11225v1",
      "title": "SeBot: Structural Entropy Guided Multi-View Contrastive Learning for Social Bot Detection",
      "title_zh": "翻译失败",
      "authors": [
        "Yingguang Yang",
        "Qi Wu",
        "Buyun He",
        "Hao Peng",
        "Renyu Yang",
        "Zhifeng Hao",
        "Yong Liao"
      ],
      "abstract": "Recent advancements in social bot detection have been driven by the adoption\nof Graph Neural Networks. The social graph, constructed from social network\ninteractions, contains benign and bot accounts that influence each other.\nHowever, previous graph-based detection methods that follow the transductive\nmessage-passing paradigm may not fully utilize hidden graph information and are\nvulnerable to adversarial bot behavior. The indiscriminate message passing\nbetween nodes from different categories and communities results in excessively\nhomogeneous node representations, ultimately reducing the effectiveness of\nsocial bot detectors. In this paper, we propose SEBot, a novel multi-view\ngraph-based contrastive learning-enabled social bot detector. In particular, we\nuse structural entropy as an uncertainty metric to optimize the entire graph's\nstructure and subgraph-level granularity, revealing the implicitly existing\nhierarchical community structure. And we design an encoder to enable message\npassing beyond the homophily assumption, enhancing robustness to adversarial\nbehaviors of social bots. Finally, we employ multi-view contrastive learning to\nmaximize mutual information between different views and enhance the detection\nperformance through multi-task learning. Experimental results demonstrate that\nour approach significantly improves the performance of social bot detection\ncompared with SOTA methods.",
      "tldr_zh": "该研究提出SeBot，一种基于结构熵（Structural Entropy）指导的多视图对比学习框架，用于提升社交机器人检测的性能。通过使用结构熵作为不确定性指标，SeBot优化图结构和子图粒度，揭示隐含的层次社区结构，并设计编码器实现超越同质性假设（homophily assumption）的消息传递，提高对对抗性机器人行为的鲁棒性。该框架还采用多视图对比学习最大化不同视图的互信息，并通过多任务学习增强检测效果。实验结果显示，SeBot显著优于现有最先进方法，在社交机器人检测任务中取得了更好的性能。",
      "categories": [
        "cs.SI",
        "cs.AI"
      ],
      "primary_category": "cs.SI",
      "comment": "KDD 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11225v1",
      "published_date": "2024-05-18 08:16:11 UTC",
      "updated_date": "2024-05-18 08:16:11 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:32:00.845977"
    },
    {
      "arxiv_id": "2405.11206v1",
      "title": "Towards Robust Policy: Enhancing Offline Reinforcement Learning with Adversarial Attacks and Defenses",
      "title_zh": "迈向鲁棒策略：通过对抗攻击和防御增强离线强化学习",
      "authors": [
        "Thanh Nguyen",
        "Tung M. Luu",
        "Tri Ton",
        "Chang D. Yoo"
      ],
      "abstract": "Offline reinforcement learning (RL) addresses the challenge of expensive and\nhigh-risk data exploration inherent in RL by pre-training policies on vast\namounts of offline data, enabling direct deployment or fine-tuning in\nreal-world environments. However, this training paradigm can compromise policy\nrobustness, leading to degraded performance in practical conditions due to\nobservation perturbations or intentional attacks. While adversarial attacks and\ndefenses have been extensively studied in deep learning, their application in\noffline RL is limited. This paper proposes a framework to enhance the\nrobustness of offline RL models by leveraging advanced adversarial attacks and\ndefenses. The framework attacks the actor and critic components by perturbing\nobservations during training and using adversarial defenses as regularization\nto enhance the learned policy. Four attacks and two defenses are introduced and\nevaluated on the D4RL benchmark. The results show the vulnerability of both the\nactor and critic to attacks and the effectiveness of the defenses in improving\npolicy robustness. This framework holds promise for enhancing the reliability\nof offline RL models in practical scenarios.",
      "tldr_zh": "本研究针对离线强化学习（Offline RL）的鲁棒性问题提出了一种框架，通过整合对抗攻击和防御来提升策略的可靠性。框架在训练过程中对 actor 和 critic 组件进行观察扰动攻击，并使用对抗防御作为正则化机制，以缓解实际环境中的性能下降。研究引入了四种攻击和两种防御，并在 D4RL 基准上进行评估，结果显示 actor 和 critic 组件易受攻击，而防御措施显著提高了策略的鲁棒性。该框架有望增强离线 RL 模型在真实场景中的可靠性和实用性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11206v1",
      "published_date": "2024-05-18 07:23:44 UTC",
      "updated_date": "2024-05-18 07:23:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:32:12.856155"
    },
    {
      "arxiv_id": "2405.11198v1",
      "title": "Adaptive Stabilization Based on Machine Learning for Column Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Yunzhuang Shen",
        "Yuan Sun",
        "Xiaodong Li",
        "Zhiguang Cao",
        "Andrew Eberhard",
        "Guangquan Zhang"
      ],
      "abstract": "Column generation (CG) is a well-established method for solving large-scale\nlinear programs. It involves iteratively optimizing a subproblem containing a\nsubset of columns and using its dual solution to generate new columns with\nnegative reduced costs. This process continues until the dual values converge\nto the optimal dual solution to the original problem. A natural phenomenon in\nCG is the heavy oscillation of the dual values during iterations, which can\nlead to a substantial slowdown in the convergence rate. Stabilization\ntechniques are devised to accelerate the convergence of dual values by using\ninformation beyond the state of the current subproblem. However, there remains\na significant gap in obtaining more accurate dual values at an earlier stage.\nTo further narrow this gap, this paper introduces a novel approach consisting\nof 1) a machine learning approach for accurate prediction of optimal dual\nsolutions and 2) an adaptive stabilization technique that effectively\ncapitalizes on accurate predictions. On the graph coloring problem, we show\nthat our method achieves a significantly improved convergence rate compared to\ntraditional methods.",
      "tldr_zh": "该论文针对 Column Generation (CG) 方法在解决大规模线性规划问题时存在的双重值震荡问题，提出了一种基于 Machine Learning 的自适应稳定技术，以加速收敛过程。具体而言，该方法包括使用机器学习模型准确预测最优双重解，以及一种适应性稳定技术来充分利用这些预测，从而更早地获得精确的双重值。在图着色问题上的实验表明，该方法相较于传统方法显著提高了收敛率。",
      "categories": [
        "math.OC",
        "cs.AI"
      ],
      "primary_category": "math.OC",
      "comment": "Accepted by ICML'24",
      "pdf_url": "http://arxiv.org/pdf/2405.11198v1",
      "published_date": "2024-05-18 06:52:50 UTC",
      "updated_date": "2024-05-18 06:52:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:32:23.743288"
    },
    {
      "arxiv_id": "2405.11195v1",
      "title": "Trustworthy Actionable Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Jesse Friedbaum",
        "Sudarshan Adiga",
        "Ravi Tandon"
      ],
      "abstract": "Counterfactuals, or modified inputs that lead to a different outcome, are an\nimportant tool for understanding the logic used by machine learning classifiers\nand how to change an undesirable classification. Even if a counterfactual\nchanges a classifier's decision, however, it may not affect the true underlying\nclass probabilities, i.e. the counterfactual may act like an adversarial attack\nand ``fool'' the classifier. We propose a new framework for creating modified\ninputs that change the true underlying probabilities in a beneficial way which\nwe call Trustworthy Actionable Perturbations (TAP). This includes a novel\nverification procedure to ensure that TAP change the true class probabilities\ninstead of acting adversarially. Our framework also includes new cost, reward,\nand goal definitions that are better suited to effectuating change in the real\nworld. We present PAC-learnability results for our verification procedure and\ntheoretically analyze our new method for measuring reward. We also develop a\nmethodology for creating TAP and compare our results to those achieved by\nprevious counterfactual methods.",
      "tldr_zh": "本论文针对机器学习分类器的 Counterfactuals（反事实）可能仅欺骗模型而不改变真实底层类概率的问题，提出 Trustworthy Actionable Perturbations (TAP) 框架，以创建有益的修改输入。TAP 框架包括一个新型验证过程来确保修改能真正影响类概率，并引入更适合现实世界的成本、奖励和目标定义。论文提供了 PAC-learnability 结果和奖励测量的理论分析，并开发了一种创建 TAP 的方法，其性能优于现有 Counterfactuals 方法。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IT",
        "math.IT"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at the 41st International Conference on Machine Learning\n  (ICML) 2024",
      "pdf_url": "http://arxiv.org/pdf/2405.11195v1",
      "published_date": "2024-05-18 06:14:00 UTC",
      "updated_date": "2024-05-18 06:14:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:32:37.911212"
    },
    {
      "arxiv_id": "2405.11181v1",
      "title": "Towards Knowledge-Infused Automated Disease Diagnosis Assistant",
      "title_zh": "翻译失败",
      "authors": [
        "Mohit Tomar",
        "Abhisek Tiwari",
        "Sriparna Saha"
      ],
      "abstract": "With the advancement of internet communication and telemedicine, people are\nincreasingly turning to the web for various healthcare activities. With an\never-increasing number of diseases and symptoms, diagnosing patients becomes\nchallenging. In this work, we build a diagnosis assistant to assist doctors,\nwhich identifies diseases based on patient-doctor interaction. During\ndiagnosis, doctors utilize both symptomatology knowledge and diagnostic\nexperience to identify diseases accurately and efficiently. Inspired by this,\nwe investigate the role of medical knowledge in disease diagnosis through\ndoctor-patient interaction. We propose a two-channel, knowledge-infused,\ndiscourse-aware disease diagnosis model (KI-DDI), where the first channel\nencodes patient-doctor communication using a transformer-based encoder, while\nthe other creates an embedding of symptom-disease using a graph attention\nnetwork (GAT). In the next stage, the conversation and knowledge graph\nembeddings are infused together and fed to a deep neural network for disease\nidentification. Furthermore, we first develop an empathetic conversational\nmedical corpus comprising conversations between patients and doctors, annotated\nwith intent and symptoms information. The proposed model demonstrates a\nsignificant improvement over the existing state-of-the-art models, establishing\nthe crucial roles of (a) a doctor's effort for additional symptom extraction\n(in addition to patient self-report) and (b) infusing medical knowledge in\nidentifying diseases effectively. Many times, patients also show their medical\nconditions, which acts as crucial evidence in diagnosis. Therefore, integrating\nvisual sensory information would represent an effective avenue for enhancing\nthe capabilities of diagnostic assistants.",
      "tldr_zh": "本研究针对互联网医疗和远程诊断的挑战，提出了一种知识注入的自动化疾病诊断助手 KI-DDI 模型。该模型采用两通道架构：第一通道使用 transformer-based 编码器处理患者-医生对话，第二通道利用图注意力网络 (GAT) 嵌入症状-疾病知识图，然后融合这些嵌入并通过深度神经网络进行疾病识别。此外，研究开发了一个包含意图和症状标注的医患对话语料库，实验结果显示 KI-DDI 显著优于现有最先进模型，强调了医生额外提取症状和医疗知识注入的关键作用，并建议整合视觉信息以进一步提升诊断能力。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11181v1",
      "published_date": "2024-05-18 05:18:50 UTC",
      "updated_date": "2024-05-18 05:18:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:32:49.880825"
    },
    {
      "arxiv_id": "2405.11154v1",
      "title": "Revisiting the Robust Generalization of Adversarial Prompt Tuning",
      "title_zh": "重新审视对抗提示调整的鲁棒泛化",
      "authors": [
        "Fan Yang",
        "Mingxuan Xia",
        "Sangzhou Xia",
        "Chicheng Ma",
        "Hui Hui"
      ],
      "abstract": "Understanding the vulnerability of large-scale pre-trained vision-language\nmodels like CLIP against adversarial attacks is key to ensuring zero-shot\ngeneralization capacity on various downstream tasks. State-of-the-art defense\nmechanisms generally adopt prompt learning strategies for adversarial\nfine-tuning to improve the adversarial robustness of the pre-trained model\nwhile keeping the efficiency of adapting to downstream tasks. Such a setup\nleads to the problem of over-fitting which impedes further improvement of the\nmodel's generalization capacity on both clean and adversarial examples. In this\nwork, we propose an adaptive Consistency-guided Adversarial Prompt Tuning\n(i.e., CAPT) framework that utilizes multi-modal prompt learning to enhance the\nalignment of image and text features for adversarial examples and leverage the\nstrong generalization of pre-trained CLIP to guide the model-enhancing its\nrobust generalization on adversarial examples while maintaining its accuracy on\nclean ones. We also design a novel adaptive consistency objective function to\nbalance the consistency of adversarial inputs and clean inputs between the\nfine-tuning model and the pre-trained model. We conduct extensive experiments\nacross 14 datasets and 4 data sparsity schemes (from 1-shot to full training\ndata settings) to show the superiority of CAPT over other state-of-the-art\nadaption methods. CAPT demonstrated excellent performance in terms of the\nin-distribution performance and the generalization under input distribution\nshift and across datasets.",
      "tldr_zh": "这篇论文重新审视了对抗提示调优（Adversarial Prompt Tuning）的鲁棒泛化问题，针对预训练视觉语言模型如 CLIP 在对抗攻击下的脆弱性。作者提出 CAPT（Consistency-guided Adversarial Prompt Tuning）框架，通过多模态提示学习增强图像和文本特征的 alignment，并设计一个自适应一致性目标函数来平衡模型在对抗样本和干净样本间的性能。实验在 14 个数据集和 4 种数据稀疏方案（从 1-shot 到完整训练数据）下证明，CAPT 优于现有方法，在分布内性能、输入分布偏移和跨数据集泛化方面表现出色。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11154v1",
      "published_date": "2024-05-18 02:54:41 UTC",
      "updated_date": "2024-05-18 02:54:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:33:03.922143"
    },
    {
      "arxiv_id": "2405.11151v1",
      "title": "Multi-scale Information Sharing and Selection Network with Boundary Attention for Polyp Segmentation",
      "title_zh": "多尺度信息共享与选择网络，带边界注意力，用于息肉",
      "authors": [
        "Xiaolu Kang",
        "Zhuoqi Ma",
        "Kang Liu",
        "Yunan Li",
        "Qiguang Miao"
      ],
      "abstract": "Polyp segmentation for colonoscopy images is of vital importance in clinical\npractice. It can provide valuable information for colorectal cancer diagnosis\nand surgery. While existing methods have achieved relatively good performance,\npolyp segmentation still faces the following challenges: (1) Varying lighting\nconditions in colonoscopy and differences in polyp locations, sizes, and\nmorphologies. (2) The indistinct boundary between polyps and surrounding\ntissue. To address these challenges, we propose a Multi-scale information\nsharing and selection network (MISNet) for polyp segmentation task. We design a\nSelectively Shared Fusion Module (SSFM) to enforce information sharing and\nactive selection between low-level and high-level features, thereby enhancing\nmodel's ability to capture comprehensive information. We then design a Parallel\nAttention Module (PAM) to enhance model's attention to boundaries, and a\nBalancing Weight Module (BWM) to facilitate the continuous refinement of\nboundary segmentation in the bottom-up process. Experiments on five polyp\nsegmentation datasets demonstrate that MISNet successfully improved the\naccuracy and clarity of segmentation result, outperforming state-of-the-art\nmethods.",
      "tldr_zh": "本研究针对结肠镜图像中的息肉分割问题，提出了一种Multi-scale information sharing and selection network (MISNet)，以应对光照变化、息肉多样性以及息肉与周围组织边界模糊的挑战。MISNet 包括Selectively Shared Fusion Module (SSFM) 用于低级和高級特征的信息共享与选择、Parallel Attention Module (PAM) 用于增强边界关注，以及Balancing Weight Module (BWM) 用于优化边界分割的连续精炼过程，从而提升模型的整体性能。在五个息肉分割数据集上的实验表明，MISNet 显著提高了分割的准确性和清晰度，超过了现有最先进方法。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11151v1",
      "published_date": "2024-05-18 02:48:39 UTC",
      "updated_date": "2024-05-18 02:48:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:33:14.080830"
    },
    {
      "arxiv_id": "2405.11145v4",
      "title": "Detecting Multimodal Situations with Insufficient Context and Abstaining from Baseless Predictions",
      "title_zh": "翻译失败",
      "authors": [
        "Junzhang Liu",
        "Zhecan Wang",
        "Hammad Ayyubi",
        "Haoxuan You",
        "Chris Thomas",
        "Rui Sun",
        "Shih-Fu Chang",
        "Kai-Wei Chang"
      ],
      "abstract": "Despite the widespread adoption of Vision-Language Understanding (VLU)\nbenchmarks such as VQA v2, OKVQA, A-OKVQA, GQA, VCR, SWAG, and VisualCOMET, our\nanalysis reveals a pervasive issue affecting their integrity: these benchmarks\ncontain samples where answers rely on assumptions unsupported by the provided\ncontext. Training models on such data foster biased learning and hallucinations\nas models tend to make similar unwarranted assumptions. To address this issue,\nwe collect contextual data for each sample whenever available and train a\ncontext selection module to facilitate evidence-based model predictions. Strong\nimprovements across multiple benchmarks demonstrate the effectiveness of our\napproach. Further, we develop a general-purpose Context-AwaRe Abstention (CARA)\ndetector to identify samples lacking sufficient context and enhance model\naccuracy by abstaining from responding if the required context is absent. CARA\nexhibits generalization to new benchmarks it wasn't trained on, underscoring\nits utility for future VLU benchmarks in detecting or cleaning samples with\ninadequate context. Finally, we curate a Context Ambiguity and Sufficiency\nEvaluation (CASE) set to benchmark the performance of insufficient context\ndetectors. Overall, our work represents a significant advancement in ensuring\nthat vision-language models generate trustworthy and evidence-based outputs in\ncomplex real-world scenarios.",
      "tldr_zh": "本研究发现，现有视觉语言理解(VLU)基准（如VQA v2、OKVQA等）中存在样本答案依赖于未提供支持的假设，导致模型产生偏见和幻觉。为解决此问题，作者收集上下文数据并训练上下文选择模块，以支持基于证据的预测，同时开发通用Context-AwaRe Abstention (CARA)检测器，用于识别缺乏足够上下文的样本并避免无依据回应。实验显示，该方法在多个基准上显著提升模型性能，且CARA在未训练基准上表现出泛化能力。最后，作者创建了Context Ambiguity and Sufficiency Evaluation (CASE)数据集，用于评估不足上下文检测器的效果，从而推动视觉语言模型生成更可靠的输出。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.MM"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2405.11145v4",
      "published_date": "2024-05-18 02:21:32 UTC",
      "updated_date": "2025-03-29 07:00:30 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:33:27.188941"
    },
    {
      "arxiv_id": "2405.11139v3",
      "title": "RuleFuser: An Evidential Bayes Approach for Rule Injection in Imitation Learned Planners and Predictors for Robustness under Distribution Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Jay Patrikar",
        "Sushant Veer",
        "Apoorva Sharma",
        "Marco Pavone",
        "Sebastian Scherer"
      ],
      "abstract": "Modern motion planners for autonomous driving frequently use imitation\nlearning (IL) to draw from expert driving logs. Although IL benefits from its\nability to glean nuanced and multi-modal human driving behaviors from large\ndatasets, the resulting planners often struggle with out-of-distribution (OOD)\nscenarios and with traffic rule compliance. On the other hand, classical\nrule-based planners, by design, can generate safe traffic rule compliant\nbehaviors while being robust to OOD scenarios, but these planners fail to\ncapture nuances in agent-to-agent interactions and human drivers' intent.\nRuleFuser, an evidential framework, combines IL planners with classical\nrule-based planners to draw on the complementary benefits of both, thereby\nstriking a balance between imitation and safety.\n  Our approach, tested on the real-world nuPlan dataset, combines the IL\nplanner's high performance in in-distribution (ID) scenarios with the\nrule-based planners' enhanced safety in out-of-distribution (OOD) scenarios,\nachieving a 38.43% average improvement on safety metrics over the IL planner\nwithout much detriment to imitation metrics in OOD scenarios.",
      "tldr_zh": "该研究提出RuleFuser，一种基于Evidential Bayes方法的框架，用于在模仿学习(IL)规划器中注入规则，以提升自动驾驶系统在分布外(OOD)场景下的鲁棒性和交通规则遵守能力。RuleFuser将IL规划器的细致行为模仿优势与经典规则-based规划器的安全性和OOD鲁棒性相结合，实现二者的平衡。在nuPlan真实数据集上的实验显示，该方法在OOD场景中使安全指标平均提升38.43%，同时对ID场景的模仿指标影响较小，为更可靠的自动驾驶规划器提供了新途径。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "17 pages, 5 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2405.11139v3",
      "published_date": "2024-05-18 01:49:16 UTC",
      "updated_date": "2024-09-16 18:44:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-18T09:33:38.540958"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 35,
  "processed_papers_count": 35,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-18T09:34:02.488379"
}