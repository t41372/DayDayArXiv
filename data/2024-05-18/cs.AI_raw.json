[
  {
    "arxiv_id": "2405.11412v1",
    "title": "Simulating Petri nets with Boolean Matrix Logic Programming",
    "authors": [
      "Lun Ai",
      "Stephen H. Muggleton",
      "Shi-Shun Liang",
      "Geoff S. Baldwin"
    ],
    "abstract": "Recent attention to relational knowledge bases has sparked a demand for\nunderstanding how relations change between entities. Petri nets can represent\nknowledge structure and dynamically simulate interactions between entities, and\nthus they are well suited for achieving this goal. However, logic programs\nstruggle to deal with extensive Petri nets due to the limitations of high-level\nsymbol manipulations. To address this challenge, we introduce a novel approach\ncalled Boolean Matrix Logic Programming (BMLP), utilising boolean matrices as\nan alternative computation mechanism for Prolog to evaluate logic programs.\nWithin this framework, we propose two novel BMLP algorithms for simulating a\nclass of Petri nets known as elementary nets. This is done by transforming\nelementary nets into logically equivalent datalog programs. We demonstrate\nempirically that BMLP algorithms can evaluate these programs 40 times faster\nthan tabled B-Prolog, SWI-Prolog, XSB-Prolog and Clingo. Our work enables the\nefficient simulation of elementary nets using Prolog, expanding the scope of\nanalysis, learning and verification of complex systems with logic programming\ntechniques.",
    "categories": [
      "cs.AI",
      "cs.SC"
    ],
    "primary_category": "cs.AI",
    "comment": "arXiv admin note: text overlap with arXiv:2405.06724",
    "pdf_url": "http://arxiv.org/pdf/2405.11412v1",
    "published_date": "2024-05-18 23:17:00 UTC",
    "updated_date": "2024-05-18 23:17:00 UTC"
  },
  {
    "arxiv_id": "2405.11403v1",
    "title": "MapCoder: Multi-Agent Code Generation for Competitive Problem Solving",
    "authors": [
      "Md. Ashraful Islam",
      "Mohammed Eunus Ali",
      "Md Rizwan Parvez"
    ],
    "abstract": "Code synthesis, which requires a deep understanding of complex natural\nlanguage problem descriptions, generation of code instructions for complex\nalgorithms and data structures, and the successful execution of comprehensive\nunit tests, presents a significant challenge. While large language models\n(LLMs) demonstrate impressive proficiency in natural language processing, their\nperformance in code generation tasks remains limited. In this paper, we\nintroduce a new approach to code generation tasks leveraging multi-agent\nprompting that uniquely replicates the full cycle of program synthesis as\nobserved in human developers. Our framework, MapCoder, consists of four LLM\nagents specifically designed to emulate the stages of this cycle: recalling\nrelevant examples, planning, code generation, and debugging. After conducting\nthorough experiments, with multiple LLM ablations and analyses across eight\nchallenging competitive problem-solving and program synthesis benchmarks,\nMapCoder showcases remarkable code generation capabilities, achieving new\nstate-of-the-art results (pass@1) on HumanEval (93.9%), MBPP (83.1%), APPS\n(22.0%), CodeContests (28.5%), and xCodeEval (45.3%). Moreover, our method\nconsistently delivers superior performance across various programming languages\nand varying problem difficulties. We open-source our framework at\nhttps://github.com/Md-Ashraful-Pramanik/MapCoder.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11403v1",
    "published_date": "2024-05-18 22:10:15 UTC",
    "updated_date": "2024-05-18 22:10:15 UTC"
  },
  {
    "arxiv_id": "2405.11402v1",
    "title": "A Model for Optimal Resilient Planning Subject to Fallible Actuators",
    "authors": [
      "Kyle Baldes",
      "Diptanil Chaudhuri",
      "Jason M. O'Kane",
      "Dylan A. Shell"
    ],
    "abstract": "Robots incurring component failures ought to adapt their behavior to best\nrealize still-attainable goals under reduced capacity. We formulate the problem\nof planning with actuators known a priori to be susceptible to failure within\nthe Markov Decision Processes (MDP) framework. The model captures\nutilization-driven malfunction and state-action dependent likelihoods of\nactuator failure in order to enable reasoning about potential impairment and\nthe long-term implications of impoverished future control. This leads to\nbehavior differing qualitatively from plans which ignore failure. As actuators\nmalfunction, there are combinatorially many configurations which can arise. We\nidentify opportunities to save computation through re-use, exploiting the\nobservation that differing configurations yield closely related problems. Our\nresults show how strategic solutions are obtained so robots can respond when\nfailures do occur -- for instance, in prudently scheduling utilization in order\nto keep critical actuators in reserve.",
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "primary_category": "cs.RO",
    "comment": "8 pages, 5 figures, submitted to 2024 IEEE/RSJ International\n  Conference on Intelligent Robots and Systems (IROS)",
    "pdf_url": "http://arxiv.org/pdf/2405.11402v1",
    "published_date": "2024-05-18 22:07:38 UTC",
    "updated_date": "2024-05-18 22:07:38 UTC"
  },
  {
    "arxiv_id": "2405.11401v2",
    "title": "PDE Control Gym: A Benchmark for Data-Driven Boundary Control of Partial Differential Equations",
    "authors": [
      "Luke Bhan",
      "Yuexin Bian",
      "Miroslav Krstic",
      "Yuanyuan Shi"
    ],
    "abstract": "Over the last decade, data-driven methods have surged in popularity, emerging\nas valuable tools for control theory. As such, neural network approximations of\ncontrol feedback laws, system dynamics, and even Lyapunov functions have\nattracted growing attention. With the ascent of learning based control, the\nneed for accurate, fast, and easy-to-use benchmarks has increased. In this\nwork, we present the first learning-based environment for boundary control of\nPDEs. In our benchmark, we introduce three foundational PDE problems - a 1D\ntransport PDE, a 1D reaction-diffusion PDE, and a 2D Navier-Stokes PDE - whose\nsolvers are bundled in an user-friendly reinforcement learning gym. With this\ngym, we then present the first set of model-free, reinforcement learning\nalgorithms for solving this series of benchmark problems, achieving stability,\nalthough at a higher cost compared to model-based PDE backstepping. With the\nset of benchmark environments and detailed examples, this work significantly\nlowers the barrier to entry for learning-based PDE control - a topic largely\nunexplored by the data-driven control community. The entire benchmark is\navailable on Github along with detailed documentation and the presented\nreinforcement learning models are open sourced.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.CE",
      "cs.LG",
      "cs.SY",
      "math.OC"
    ],
    "primary_category": "eess.SY",
    "comment": "26 pages 10 figures. Accepted L4DC 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.11401v2",
    "published_date": "2024-05-18 22:01:55 UTC",
    "updated_date": "2024-05-24 01:40:41 UTC"
  },
  {
    "arxiv_id": "2405.11397v1",
    "title": "Preparing for Black Swans: The Antifragility Imperative for Machine Learning",
    "authors": [
      "Ming Jin"
    ],
    "abstract": "Operating safely and reliably despite continual distribution shifts is vital\nfor high-stakes machine learning applications. This paper builds upon the\ntransformative concept of ``antifragility'' introduced by (Taleb, 2014) as a\nconstructive design paradigm to not just withstand but benefit from volatility.\nWe formally define antifragility in the context of online decision making as\ndynamic regret's strictly concave response to environmental variability,\nrevealing limitations of current approaches focused on resisting rather than\nbenefiting from nonstationarity. Our contribution lies in proposing potential\ncomputational pathways for engineering antifragility, grounding the concept in\nonline learning theory and drawing connections to recent advancements in areas\nsuch as meta-learning, safe exploration, continual learning,\nmulti-objective/quality-diversity optimization, and foundation models. By\nidentifying promising mechanisms and future research directions, we aim to put\nantifragility on a rigorous theoretical foundation in machine learning. We\nfurther emphasize the need for clear guidelines, risk assessment frameworks,\nand interdisciplinary collaboration to ensure responsible application.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11397v1",
    "published_date": "2024-05-18 21:32:29 UTC",
    "updated_date": "2024-05-18 21:32:29 UTC"
  },
  {
    "arxiv_id": "2405.11380v3",
    "title": "Meta-Control: Automatic Model-based Control Synthesis for Heterogeneous Robot Skills",
    "authors": [
      "Tianhao Wei",
      "Liqian Ma",
      "Rui Chen",
      "Weiye Zhao",
      "Changliu Liu"
    ],
    "abstract": "The requirements for real-world manipulation tasks are diverse and often\nconflicting; some tasks require precise motion while others require force\ncompliance; some tasks require avoidance of certain regions, while others\nrequire convergence to certain states. Satisfying these varied requirements\nwith a fixed state-action representation and control strategy is challenging,\nimpeding the development of a universal robotic foundation model. In this work,\nwe propose Meta-Control, the first LLM-enabled automatic control synthesis\napproach that creates customized state representations and control strategies\ntailored to specific tasks. Our core insight is that a meta-control system can\nbe built to automate the thought process that human experts use to design\ncontrol systems. Specifically, human experts heavily use a model-based,\nhierarchical (from abstract to concrete) thought model, then compose various\ndynamic models and controllers together to form a control system. Meta-Control\nmimics the thought model and harnesses LLM's extensive control knowledge with\nSocrates' \"art of midwifery\" to automate the thought process. Meta-Control\nstands out for its fully model-based nature, allowing rigorous analysis,\ngeneralizability, robustness, efficient parameter tuning, and reliable\nreal-time execution.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11380v3",
    "published_date": "2024-05-18 19:58:44 UTC",
    "updated_date": "2024-12-11 20:36:26 UTC"
  },
  {
    "arxiv_id": "2405.11347v1",
    "title": "Cooperative Multi-agent Approach for Automated Computer Game Testing",
    "authors": [
      "Samira Shirzadeh-hajimahmood",
      "I. S. W. B. Prasteya",
      "Mehdi Dastani",
      "Frank Dignum"
    ],
    "abstract": "Automated testing of computer games is a challenging problem, especially when\nlengthy scenarios have to be tested. Automating such a scenario boils down to\nfinding the right sequence of interactions given an abstract description of the\nscenario. Recent works have shown that an agent-based approach works well for\nthe purpose, e.g. due to agents' reactivity, hence enabling a test agent to\nimmediately react to game events and changing state. Many games nowadays are\nmulti-player. This opens up an interesting possibility to deploy multiple\ncooperative test agents to test such a game, for example to speed up the\nexecution of multiple testing tasks. This paper offers a cooperative\nmulti-agent testing approach and a study of its performance based on a case\nstudy on a 3D game called Lab Recruits.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11347v1",
    "published_date": "2024-05-18 17:31:26 UTC",
    "updated_date": "2024-05-18 17:31:26 UTC"
  },
  {
    "arxiv_id": "2405.13045v1",
    "title": "CoLay: Controllable Layout Generation through Multi-conditional Latent Diffusion",
    "authors": [
      "Chin-Yi Cheng",
      "Ruiqi Gao",
      "Forrest Huang",
      "Yang Li"
    ],
    "abstract": "Layout design generation has recently gained significant attention due to its\npotential applications in various fields, including UI, graphic, and floor plan\ndesign. However, existing models face two main challenges that limits their\nadoption in practice. Firstly, the limited expressiveness of individual\ncondition types used in previous works restricts designers' ability to convey\ncomplex design intentions and constraints. Secondly, most existing models focus\non generating labels and coordinates, while real layouts contain a range of\nstyle properties. To address these limitations, we propose a novel framework,\nCoLay, that integrates multiple condition types and generates complex layouts\nwith diverse style properties. Our approach outperforms prior works in terms of\ngeneration quality and condition satisfaction while empowering users to express\ntheir design intents using a flexible combination of modalities, including\nnatural language prompts, layout guidelines, element types, and partially\ncompleted designs.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13045v1",
    "published_date": "2024-05-18 17:30:48 UTC",
    "updated_date": "2024-05-18 17:30:48 UTC"
  },
  {
    "arxiv_id": "2405.11346v2",
    "title": "Decision support system for Forest fire management using Ontology with Big Data and LLMs",
    "authors": [
      "Ritesh Chandra",
      "Shashi Shekhar Kumar",
      "Rushil Patra",
      "Sonali Agarwal"
    ],
    "abstract": "Forests are crucial for ecological balance, but wildfires, a major cause of\nforest loss, pose significant risks. Fire weather indices, which assess\nwildfire risk and predict resource demands, are vital. With the rise of sensor\nnetworks in fields like healthcare and environmental monitoring, semantic\nsensor networks are increasingly used to gather climatic data such as wind\nspeed, temperature, and humidity. However, processing these data streams to\ndetermine fire weather indices presents challenges, underscoring the growing\nimportance of effective forest fire detection. This paper discusses using\nApache Spark for early forest fire detection, enhancing fire risk prediction\nwith meteorological and geographical data. Building on our previous development\nof Semantic Sensor Network (SSN) ontologies and Semantic Web Rules Language\n(SWRL) for managing forest fires in Monesterial Natural Park, we expanded SWRL\nto improve a Decision Support System (DSS) using a Large Language Models (LLMs)\nand Spark framework. We implemented real-time alerts with Spark streaming,\ntailored to various fire scenarios, and validated our approach using ontology\nmetrics, query-based evaluations, LLMs score precision, F1 score, and recall\nmeasures.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11346v2",
    "published_date": "2024-05-18 17:30:30 UTC",
    "updated_date": "2024-09-23 06:13:48 UTC"
  },
  {
    "arxiv_id": "2405.11345v3",
    "title": "City-Scale Multi-Camera Vehicle Tracking System with Improved Self-Supervised Camera Link Model",
    "authors": [
      "Yuqiang Lin",
      "Sam Lockyer",
      "Nic Zhang"
    ],
    "abstract": "Multi-Target Multi-Camera Tracking (MTMCT) has broad applications and forms\nthe basis for numerous future city-wide systems (e.g. traffic management, crash\ndetection, etc.). However, the challenge of matching vehicle trajectories\nacross different cameras based solely on feature extraction poses significant\ndifficulties. This article introduces an innovative multi-camera vehicle\ntracking system that utilizes a self-supervised camera link model. In contrast\nto related works that rely on manual spatial-temporal annotations, our model\nautomatically extracts crucial multi-camera relationships for vehicle matching.\nThe camera link is established through a pre-matching process that evaluates\nfeature similarities, pair numbers, and time variance for high-quality tracks.\nThis process calculates the probability of spatial linkage for all camera\ncombinations, selecting the highest scoring pairs to create camera links. Our\napproach significantly improves deployment times by eliminating the need for\nhuman annotation, offering substantial improvements in efficiency and\ncost-effectiveness when it comes to real-world application. This pairing\nprocess supports cross camera matching by setting spatial-temporal constraints,\nreducing the searching space for potential vehicle matches. According to our\nexperimental results, the proposed method achieves a new state-of-the-art among\nautomatic camera-link based methods in CityFlow V2 benchmarks with 61.07% IDF1\nScore.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Upload the revised manuscript with the publisher's requirement",
    "pdf_url": "http://arxiv.org/pdf/2405.11345v3",
    "published_date": "2024-05-18 17:28:35 UTC",
    "updated_date": "2025-02-14 11:55:30 UTC"
  },
  {
    "arxiv_id": "2405.11344v3",
    "title": "LiPost: Improved Content Understanding With Effective Use of Multi-task Contrastive Learning",
    "authors": [
      "Akanksha Bindal",
      "Sudarshan Ramanujam",
      "Dave Golland",
      "TJ Hazen",
      "Tina Jiang",
      "Fengyu Zhang",
      "Peng Yan"
    ],
    "abstract": "In enhancing LinkedIn core content recommendation models, a significant\nchallenge lies in improving their semantic understanding capabilities. This\npaper addresses the problem by leveraging multi-task learning, a method that\nhas shown promise in various domains. We fine-tune a pre-trained,\ntransformer-based LLM using multi-task contrastive learning with data from a\ndiverse set of semantic labeling tasks. We observe positive transfer, leading\nto superior performance across all tasks when compared to training\nindependently on each. Our model outperforms the baseline on zero shot learning\nand offers improved multilingual support, highlighting its potential for\nbroader application. The specialized content embeddings produced by our model\noutperform generalized embeddings offered by OpenAI on Linkedin dataset and\ntasks. This work provides a robust foundation for vertical teams across\nLinkedIn to customize and fine-tune the LLM to their specific applications. Our\nwork offers insights and best practices for the field to build on.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11344v3",
    "published_date": "2024-05-18 17:28:29 UTC",
    "updated_date": "2024-07-13 20:00:31 UTC"
  },
  {
    "arxiv_id": "2405.11338v2",
    "title": "EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic Imaging",
    "authors": [
      "Danli Shi",
      "Weiyi Zhang",
      "Xiaolan Chen",
      "Yexin Liu",
      "Jiancheng Yang",
      "Siyu Huang",
      "Yih Chung Tham",
      "Yingfeng Zheng",
      "Mingguang He"
    ],
    "abstract": "Artificial intelligence (AI) is vital in ophthalmology, tackling tasks like\ndiagnosis, classification, and visual question answering (VQA). However,\nexisting AI models in this domain often require extensive annotation and are\ntask-specific, limiting their clinical utility. While recent developments have\nbrought about foundation models for ophthalmology, they are limited by the need\nto train separate weights for each imaging modality, preventing a comprehensive\nrepresentation of multi-modal features. This highlights the need for versatile\nfoundation models capable of handling various tasks and modalities in\nophthalmology. To address this gap, we present EyeFound, a multimodal\nfoundation model for ophthalmic images. Unlike existing models, EyeFound learns\ngeneralizable representations from unlabeled multimodal retinal images,\nenabling efficient model adaptation across multiple applications. Trained on\n2.78 million images from 227 hospitals across 11 ophthalmic modalities,\nEyeFound facilitates generalist representations and diverse multimodal\ndownstream tasks, even for detecting challenging rare diseases. It outperforms\nprevious work RETFound in diagnosing eye diseases, predicting systemic disease\nincidents, and zero-shot multimodal VQA. EyeFound provides a generalizable\nsolution to improve model performance and lessen the annotation burden on\nexperts, facilitating widespread clinical AI applications for retinal imaging.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "21 pages, 2 figures, 4 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.11338v2",
    "published_date": "2024-05-18 17:03:39 UTC",
    "updated_date": "2024-05-22 02:21:07 UTC"
  },
  {
    "arxiv_id": "2405.11333v1",
    "title": "GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable for Variable Missing",
    "authors": [
      "Chengqing Yu",
      "Fei Wang",
      "Zezhi Shao",
      "Tangwen Qian",
      "Zhao Zhang",
      "Wei Wei",
      "Yongjun Xu"
    ],
    "abstract": "Multivariate time series forecasting (MTSF) is crucial for decision-making to\nprecisely forecast the future values/trends, based on the complex relationships\nidentified from historical observations of multiple sequences. Recently,\nSpatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme\nof MTSF model as their powerful capability in mining spatial-temporal\ndependencies, but almost of them heavily rely on the assumption of historical\ndata integrity. In reality, due to factors such as data collector failures and\ntime-consuming repairment, it is extremely challenging to collect the whole\nhistorical observations without missing any variable. In this case, STGNNs can\nonly utilize a subset of normal variables and easily suffer from the incorrect\nspatial-temporal dependency modeling issue, resulting in the degradation of\ntheir forecasting performance. To address the problem, in this paper, we\npropose a novel Graph Interpolation Attention Recursive Network (named GinAR)\nto precisely model the spatial-temporal dependencies over the limited collected\ndata for forecasting. In GinAR, it consists of two key components, that is,\ninterpolation attention and adaptive graph convolution to take place of the\nfully connected layer of simple recursive units, and thus are capable of\nrecovering all missing variables and reconstructing the correct\nspatial-temporal dependencies for recursively modeling of multivariate time\nseries data, respectively. Extensive experiments conducted on five real-world\ndatasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when\n90% of variables are missing, it can still accurately predict the future values\nof all variables.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted by KDD 2024 (Research track)",
    "pdf_url": "http://arxiv.org/pdf/2405.11333v1",
    "published_date": "2024-05-18 16:42:44 UTC",
    "updated_date": "2024-05-18 16:42:44 UTC"
  },
  {
    "arxiv_id": "2405.11331v2",
    "title": "Generalized Multi-Objective Reinforcement Learning with Envelope Updates in URLLC-enabled Vehicular Networks",
    "authors": [
      "Zijiang Yan",
      "Hina Tabassum"
    ],
    "abstract": "We develop a novel multi-objective reinforcement learning (MORL) framework to\njointly optimize wireless network selection and autonomous driving policies in\na multi-band vehicular network operating on conventional sub-6GHz spectrum and\nTerahertz frequencies. The proposed framework is designed to 1. maximize the\ntraffic flow and 2. minimize collisions by controlling the vehicle's motion\ndynamics (i.e., speed and acceleration), and enhance the ultra-reliable\nlow-latency communication (URLLC) while minimizing handoffs (HOs). We cast this\nproblem as a multi-objective Markov Decision Process (MOMDP) and develop\nsolutions for both predefined and unknown preferences of the conflicting\nobjectives. Specifically, deep-Q-network and double deep-Q-network-based\nsolutions are developed first that consider scalarizing the transportation and\ntelecommunication rewards using predefined preferences. We then develop a novel\nenvelope MORL solution which develop policies that address multiple objectives\nwith unknown preferences to the agent. While this approach reduces reliance on\nscalar rewards, policy effectiveness varying with different preferences is a\nchallenge. To address this, we apply a generalized version of the Bellman\nequation and optimize the convex envelope of multi-objective Q values to learn\na unified parametric representation capable of generating optimal policies\nacross all possible preference configurations. Following an initial learning\nphase, our agent can execute optimal policies under any specified preference or\ninfer preferences from minimal data samples.Numerical results validate the\nefficacy of the envelope-based MORL solution and demonstrate interesting\ninsights related to the inter-dependency of vehicle motion dynamics, HOs, and\nthe communication data rate. The proposed policies enable autonomous vehicles\nto adopt safe driving behaviors with improved connectivity.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NI"
    ],
    "primary_category": "cs.LG",
    "comment": "Submission for possible publication",
    "pdf_url": "http://arxiv.org/pdf/2405.11331v2",
    "published_date": "2024-05-18 16:31:32 UTC",
    "updated_date": "2025-01-11 00:59:43 UTC"
  },
  {
    "arxiv_id": "2405.11318v2",
    "title": "Smooth Kolmogorov Arnold networks enabling structural knowledge representation",
    "authors": [
      "Moein E. Samadi",
      "Younes MÃ¼ller",
      "Andreas Schuppert"
    ],
    "abstract": "Kolmogorov-Arnold Networks (KANs) offer an efficient and interpretable\nalternative to traditional multi-layer perceptron (MLP) architectures due to\ntheir finite network topology. However, according to the results of Kolmogorov\nand Vitushkin, the representation of generic smooth functions by KAN\nimplementations using analytic functions constrained to a finite number of\ncutoff points cannot be exact. Hence, the convergence of KAN throughout the\ntraining process may be limited. This paper explores the relevance of\nsmoothness in KANs, proposing that smooth, structurally informed KANs can\nachieve equivalence to MLPs in specific function classes. By leveraging\ninherent structural knowledge, KANs may reduce the data required for training\nand mitigate the risk of generating hallucinated predictions, thereby enhancing\nmodel reliability and performance in computational biomedicine.",
    "categories": [
      "cs.LG",
      "cond-mat.dis-nn",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11318v2",
    "published_date": "2024-05-18 15:27:14 UTC",
    "updated_date": "2024-05-27 09:32:35 UTC"
  },
  {
    "arxiv_id": "2405.11305v1",
    "title": "Large Neighborhood Prioritized Search for Combinatorial Optimization with Answer Set Programming",
    "authors": [
      "Irumi Sugimori",
      "Katsumi Inoue",
      "Hidetomo Nabeshima",
      "Torsten Schaub",
      "Takehide Soh",
      "Naoyuki Tamura",
      "Mutsunori Banbara"
    ],
    "abstract": "We propose Large Neighborhood Prioritized Search (LNPS) for solving\ncombinatorial optimization problems in Answer Set Programming (ASP). LNPS is a\nmetaheuristic that starts with an initial solution and then iteratively tries\nto find better solutions by alternately destroying and prioritized searching\nfor a current solution. Due to the variability of neighborhoods, LNPS allows\nfor flexible search without strongly depending on the destroy operators. We\npresent an implementation of LNPS based on ASP. The resulting heulingo solver\ndemonstrates that LNPS can significantly enhance the solving performance of ASP\nfor optimization. Furthermore, we establish the competitiveness of our LNPS\napproach by empirically contrasting it to (adaptive) large neighborhood search.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages",
    "pdf_url": "http://arxiv.org/pdf/2405.11305v1",
    "published_date": "2024-05-18 14:37:43 UTC",
    "updated_date": "2024-05-18 14:37:43 UTC"
  },
  {
    "arxiv_id": "2405.11284v3",
    "title": "The Logic of Counterfactuals and the Epistemology of Causal Inference",
    "authors": [
      "Hanti Lin"
    ],
    "abstract": "The 2021 Nobel Prize in Economics recognized an epistemology of causal\ninference based on the Rubin causal model (Rubin 1974), which merits broader\nattention in philosophy. This model, in fact, presupposes a logical principle\nof counterfactuals, Conditional Excluded Middle (CEM), the locus of a pivotal\ndebate between Stalnaker (1968) and Lewis (1973) on the semantics of\ncounterfactuals. Proponents of CEM should recognize that this connection points\nto a new argument for CEM -- a Quine-Putnam indispensability argument grounded\nin the Nobel-winning applications of the Rubin model in health and social\nsciences. To advance the dialectic, I challenge this argument with an updated\nRubin causal model that retains its successes while dispensing with CEM. This\nnovel approach combines the strengths of the Rubin causal model and a causal\nmodel familiar in philosophy, the causal Bayes net. The takeaway: deductive\nlogic and inductive inference, often studied in isolation, are deeply\ninterconnected.",
    "categories": [
      "cs.AI",
      "econ.EM",
      "stat.ME",
      "stat.OT"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11284v3",
    "published_date": "2024-05-18 13:09:33 UTC",
    "updated_date": "2025-03-12 02:08:24 UTC"
  },
  {
    "arxiv_id": "2405.11282v3",
    "title": "Estimating the Level of Dialectness Predicts Interannotator Agreement in Multi-dialect Arabic Datasets",
    "authors": [
      "Amr Keleg",
      "Walid Magdy",
      "Sharon Goldwater"
    ],
    "abstract": "On annotating multi-dialect Arabic datasets, it is common to randomly assign\nthe samples across a pool of native Arabic speakers. Recent analyses\nrecommended routing dialectal samples to native speakers of their respective\ndialects to build higher-quality datasets. However, automatically identifying\nthe dialect of samples is hard. Moreover, the pool of annotators who are native\nspeakers of specific Arabic dialects might be scarce. Arabic Level of\nDialectness (ALDi) was recently introduced as a quantitative variable that\nmeasures how sentences diverge from Standard Arabic. On randomly assigning\nsamples to annotators, we hypothesize that samples of higher ALDi scores are\nharder to label especially if they are written in dialects that the annotators\ndo not speak. We test this by analyzing the relation between ALDi scores and\nthe annotators' agreement, on 15 public datasets having raw individual sample\nannotations for various sentence-classification tasks. We find strong evidence\nsupporting our hypothesis for 11 of them. Consequently, we recommend\nprioritizing routing samples of high ALDi scores to native speakers of each\nsample's dialect, for which the dialect could be automatically identified at\nhigher accuracies.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to ACL 2024 - Main (camera-ready version)",
    "pdf_url": "http://arxiv.org/pdf/2405.11282v3",
    "published_date": "2024-05-18 12:58:02 UTC",
    "updated_date": "2024-06-06 20:32:45 UTC"
  },
  {
    "arxiv_id": "2405.11281v1",
    "title": "Cooperative Cognitive Dynamic System in UAV Swarms: Reconfigurable Mechanism and Framework",
    "authors": [
      "Ziye Jia",
      "Jiahao You",
      "Chao Dong",
      "Qihui Wu",
      "Fuhui Zhou",
      "Dusit Niyato",
      "Zhu Han"
    ],
    "abstract": "As the demands for immediate and effective responses increase in both\ncivilian and military domains, the unmanned aerial vehicle (UAV) swarms emerge\nas effective solutions, in which multiple cooperative UAVs can work together to\nachieve specific goals. However, how to manage such complex systems to ensure\nreal-time adaptability lack sufficient researches. Hence, in this paper, we\npropose the cooperative cognitive dynamic system (CCDS), to optimize the\nmanagement for UAV swarms. CCDS leverages a hierarchical and cooperative\ncontrol structure that enables real-time data processing and decision.\nAccordingly, CCDS optimizes the UAV swarm management via dynamic\nreconfigurability and adaptive intelligent optimization. In addition, CCDS can\nbe integrated with the biomimetic mechanism to efficiently allocate tasks for\nUAV swarms. Further, the distributed coordination of CCDS ensures reliable and\nresilient control, thus enhancing the adaptability and robustness. Finally, the\npotential challenges and future directions are analyzed, to provide insights\ninto managing UAV swarms in dynamic heterogeneous networking.",
    "categories": [
      "cs.DC",
      "cs.AI"
    ],
    "primary_category": "cs.DC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11281v1",
    "published_date": "2024-05-18 12:45:00 UTC",
    "updated_date": "2024-05-18 12:45:00 UTC"
  },
  {
    "arxiv_id": "2405.11277v2",
    "title": "Action Controlled Paraphrasing",
    "authors": [
      "Ning Shi",
      "Zijun Wu"
    ],
    "abstract": "Recent studies have demonstrated the potential to control paraphrase\ngeneration, such as through syntax, which has broad applications in various\ndownstream tasks. However, these methods often require detailed parse trees or\nsyntactic exemplars, countering human-like paraphrasing behavior in language\nuse. Furthermore, an inference gap exists, as control specifications are only\navailable during training but not during inference. In this work, we propose a\nnew setup for controlled paraphrase generation. Specifically, we represent user\nintent as action tokens, embedding and concatenating them with text embeddings,\nthus flowing together into a self-attention encoder for representation fusion.\nTo address the inference gap, we introduce an optional action token as a\nplaceholder that encourages the model to determine the appropriate action\nindependently when users' intended actions are not provided. Experimental\nresults show that our method successfully enables precise action-controlled\nparaphrasing and preserves or even enhances performance compared to\nconventional uncontrolled methods when actions are not given. Our findings\npromote the concept of action-controlled paraphrasing for a more user-centered\ndesign.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Work in Progress",
    "pdf_url": "http://arxiv.org/pdf/2405.11277v2",
    "published_date": "2024-05-18 12:26:31 UTC",
    "updated_date": "2024-07-01 23:23:41 UTC"
  },
  {
    "arxiv_id": "2405.11273v1",
    "title": "Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts",
    "authors": [
      "Yunxin Li",
      "Shenyuan Jiang",
      "Baotian Hu",
      "Longyue Wang",
      "Wanqi Zhong",
      "Wenhan Luo",
      "Lin Ma",
      "Min Zhang"
    ],
    "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) underscore\nthe significance of scalable models and data to boost performance, yet this\noften incurs substantial computational costs. Although the Mixture of Experts\n(MoE) architecture has been employed to efficiently scale large language and\nimage-text models, these efforts typically involve fewer experts and limited\nmodalities. To address this, our work presents the pioneering attempt to\ndevelop a unified MLLM with the MoE architecture, named Uni-MoE that can handle\na wide array of modalities. Specifically, it features modality-specific\nencoders with connectors for a unified multimodal representation. We also\nimplement a sparse MoE architecture within the LLMs to enable efficient\ntraining and inference through modality-level data parallelism and expert-level\nmodel parallelism. To enhance the multi-expert collaboration and\ngeneralization, we present a progressive training strategy: 1) Cross-modality\nalignment using various connectors with different cross-modality data, 2)\nTraining modality-specific experts with cross-modality instruction data to\nactivate experts' preferences, and 3) Tuning the Uni-MoE framework utilizing\nLow-Rank Adaptation (LoRA) on mixed multimodal instruction data. We evaluate\nthe instruction-tuned Uni-MoE on a comprehensive set of multimodal datasets.\nThe extensive experimental results demonstrate Uni-MoE's principal advantage of\nsignificantly reducing performance bias in handling mixed multimodal datasets,\nalongside improved multi-expert collaboration and generalization. Our findings\nhighlight the substantial potential of MoE frameworks in advancing MLLMs and\nthe code is available at\nhttps://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.MM"
    ],
    "primary_category": "cs.AI",
    "comment": "22 pages, 13 figures. Project Website: https://uni-moe.github.io/.\n  Working in progress",
    "pdf_url": "http://arxiv.org/pdf/2405.11273v1",
    "published_date": "2024-05-18 12:16:01 UTC",
    "updated_date": "2024-05-18 12:16:01 UTC"
  },
  {
    "arxiv_id": "2405.11272v3",
    "title": "Double Correction Framework for Denoising Recommendation",
    "authors": [
      "Zhuangzhuang He",
      "Yifan Wang",
      "Yonghui Yang",
      "Peijie Sun",
      "Le Wu",
      "Haoyue Bai",
      "Jinqi Gong",
      "Richang Hong",
      "Min Zhang"
    ],
    "abstract": "As its availability and generality in online services, implicit feedback is\nmore commonly used in recommender systems. However, implicit feedback usually\npresents noisy samples in real-world recommendation scenarios (such as\nmisclicks or non-preferential behaviors), which will affect precise user\npreference learning. To overcome the noisy samples problem, a popular solution\nis based on dropping noisy samples in the model training phase, which follows\nthe observation that noisy samples have higher training losses than clean\nsamples. Despite the effectiveness, we argue that this solution still has\nlimits. (1) High training losses can result from model optimization instability\nor hard samples, not just noisy samples. (2) Completely dropping of noisy\nsamples will aggravate the data sparsity, which lacks full data exploitation.\nTo tackle the above limitations, we propose a Double Correction Framework for\nDenoising Recommendation (DCF), which contains two correction components from\nviews of more precise sample dropping and avoiding more sparse data. In the\nsample dropping correction component, we use the loss value of the samples over\ntime to determine whether it is noise or not, increasing dropping stability.\nInstead of averaging directly, we use the damping function to reduce the bias\neffect of outliers. Furthermore, due to the higher variance exhibited by hard\nsamples, we derive a lower bound for the loss through concentration inequality\nto identify and reuse hard samples. In progressive label correction, we\niteratively re-label highly deterministic noisy samples and retrain them to\nfurther improve performance. Finally, extensive experimental results on three\ndatasets and four backbones demonstrate the effectiveness and generalization of\nour proposed framework.",
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted by KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.11272v3",
    "published_date": "2024-05-18 12:15:10 UTC",
    "updated_date": "2024-05-28 03:54:22 UTC"
  },
  {
    "arxiv_id": "2405.11265v1",
    "title": "EnviroExam: Benchmarking Environmental Science Knowledge of Large Language Models",
    "authors": [
      "Yu Huang",
      "Liang Guo",
      "Wanqian Guo",
      "Zhe Tao",
      "Yang Lv",
      "Zhihao Sun",
      "Dongfang Zhao"
    ],
    "abstract": "In the field of environmental science, it is crucial to have robust\nevaluation metrics for large language models to ensure their efficacy and\naccuracy. We propose EnviroExam, a comprehensive evaluation method designed to\nassess the knowledge of large language models in the field of environmental\nscience. EnviroExam is based on the curricula of top international\nuniversities, covering undergraduate, master's, and doctoral courses, and\nincludes 936 questions across 42 core courses. By conducting 0-shot and 5-shot\ntests on 31 open-source large language models, EnviroExam reveals the\nperformance differences among these models in the domain of environmental\nscience and provides detailed evaluation standards. The results show that 61.3%\nof the models passed the 5-shot tests, while 48.39% passed the 0-shot tests. By\nintroducing the coefficient of variation as an indicator, we evaluate the\nperformance of mainstream open-source large language models in environmental\nscience from multiple perspectives, providing effective criteria for selecting\nand fine-tuning language models in this field. Future research will involve\nconstructing more domain-specific test sets using specialized environmental\nscience textbooks to further enhance the accuracy and specificity of the\nevaluation.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11265v1",
    "published_date": "2024-05-18 11:31:03 UTC",
    "updated_date": "2024-05-18 11:31:03 UTC"
  },
  {
    "arxiv_id": "2405.11250v3",
    "title": "Argumentative Causal Discovery",
    "authors": [
      "Fabrizio Russo",
      "Anna Rapberger",
      "Francesca Toni"
    ],
    "abstract": "Causal discovery amounts to unearthing causal relationships amongst features\nin data. It is a crucial companion to causal inference, necessary to build\nscientific knowledge without resorting to expensive or impossible randomised\ncontrol trials. In this paper, we explore how reasoning with symbolic\nrepresentations can support causal discovery. Specifically, we deploy\nassumption-based argumentation (ABA), a well-established and powerful knowledge\nrepresentation formalism, in combination with causality theories, to learn\ngraphs which reflect causal dependencies in the data. We prove that our method\nexhibits desirable properties, notably that, under natural conditions, it can\nretrieve ground-truth causal graphs. We also conduct experiments with an\nimplementation of our method in answer set programming (ASP) on four datasets\nfrom standard benchmarks in causal discovery, showing that our method compares\nwell against established baselines.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to KR2024. Version with Appendix",
    "pdf_url": "http://arxiv.org/pdf/2405.11250v3",
    "published_date": "2024-05-18 10:34:34 UTC",
    "updated_date": "2024-08-03 10:54:18 UTC"
  },
  {
    "arxiv_id": "2405.13044v1",
    "title": "Case-Based Reasoning Approach for Solving Financial Question Answering",
    "authors": [
      "Yikyung Kim",
      "Jay-Yoon Lee"
    ],
    "abstract": "Measuring a machine's understanding of human language often involves\nassessing its reasoning skills, i.e. logical process of deriving answers to\nquestions. While recent language models have shown remarkable proficiency in\ntext based tasks, their efficacy in complex reasoning problems involving\nheterogeneous information such as text, tables, and numbers remain uncertain.\nAddressing this gap, FinQA introduced a numerical reasoning dataset for\nfinancial documents and simultaneously proposed a program generation approach .\nOur investigation reveals that half of the errors (48%) stem from incorrect\noperations being generated. To address this issue, we propose a novel approach\nto tackle numerical reasoning problems using case based reasoning (CBR), an\nartificial intelligence paradigm that provides problem solving guidance by\noffering similar cases (i.e. similar questions and corresponding logical\nprograms). Our model retrieves relevant cases to address a given question, and\nthen generates an answer based on the retrieved cases and contextual\ninformation. Through experiments on the FinQA dataset, we demonstrate\ncompetitive performance of our approach and additionally show that by expanding\ncase repository, we can help solving complex multi step programs which FinQA\nshowed weakness of.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.13044v1",
    "published_date": "2024-05-18 10:06:55 UTC",
    "updated_date": "2024-05-18 10:06:55 UTC"
  },
  {
    "arxiv_id": "2405.11238v1",
    "title": "SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly Detection",
    "authors": [
      "Zhijie Zhong",
      "Zhiwen Yu",
      "Xing Xi",
      "Yue Xu",
      "Jiahui Chen",
      "Kaixiang Yang"
    ],
    "abstract": "Despite the prevalence of reconstruction-based deep learning methods, time\nseries anomaly detection remains challenging. Existing approaches often\nstruggle with limited temporal contexts, inadequate representation of normal\npatterns, and flawed evaluation metrics, hindering their effectiveness in\nidentifying aberrant behavior. To address these issues, we introduce\n$\\textbf{{SimAD}}$, a $\\textbf{{Sim}}$ple dissimilarity-based approach for time\nseries $\\textbf{{A}}$nomaly $\\textbf{{D}}$etection. SimAD incorporates an\nadvanced feature extractor adept at processing extended temporal windows,\nutilizes the EmbedPatch encoder to integrate normal behavioral patterns\ncomprehensively, and introduces an innovative ContrastFusion module designed to\naccentuate distributional divergences between normal and abnormal data, thereby\nenhancing the robustness of anomaly discrimination. Additionally, we propose\ntwo robust evaluation metrics, UAff and NAff, addressing the limitations of\nexisting metrics and demonstrating their reliability through theoretical and\nexperimental analyses. Experiments across $\\textbf{seven}$ diverse time series\ndatasets demonstrate SimAD's superior performance compared to state-of-the-art\nmethods, achieving relative improvements of $\\textbf{19.85%}$ on F1,\n$\\textbf{4.44%}$ on Aff-F1, $\\textbf{77.79%}$ on NAff-F1, and $\\textbf{9.69%}$\non AUC on six multivariate datasets. Code and pre-trained models are available\nat https://github.com/EmorZz1G/SimAD.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "18 pages, 12 figures,7 tables, Under review",
    "pdf_url": "http://arxiv.org/pdf/2405.11238v1",
    "published_date": "2024-05-18 09:37:04 UTC",
    "updated_date": "2024-05-18 09:37:04 UTC"
  },
  {
    "arxiv_id": "2405.11225v1",
    "title": "SeBot: Structural Entropy Guided Multi-View Contrastive Learning for Social Bot Detection",
    "authors": [
      "Yingguang Yang",
      "Qi Wu",
      "Buyun He",
      "Hao Peng",
      "Renyu Yang",
      "Zhifeng Hao",
      "Yong Liao"
    ],
    "abstract": "Recent advancements in social bot detection have been driven by the adoption\nof Graph Neural Networks. The social graph, constructed from social network\ninteractions, contains benign and bot accounts that influence each other.\nHowever, previous graph-based detection methods that follow the transductive\nmessage-passing paradigm may not fully utilize hidden graph information and are\nvulnerable to adversarial bot behavior. The indiscriminate message passing\nbetween nodes from different categories and communities results in excessively\nhomogeneous node representations, ultimately reducing the effectiveness of\nsocial bot detectors. In this paper, we propose SEBot, a novel multi-view\ngraph-based contrastive learning-enabled social bot detector. In particular, we\nuse structural entropy as an uncertainty metric to optimize the entire graph's\nstructure and subgraph-level granularity, revealing the implicitly existing\nhierarchical community structure. And we design an encoder to enable message\npassing beyond the homophily assumption, enhancing robustness to adversarial\nbehaviors of social bots. Finally, we employ multi-view contrastive learning to\nmaximize mutual information between different views and enhance the detection\nperformance through multi-task learning. Experimental results demonstrate that\nour approach significantly improves the performance of social bot detection\ncompared with SOTA methods.",
    "categories": [
      "cs.SI",
      "cs.AI"
    ],
    "primary_category": "cs.SI",
    "comment": "KDD 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.11225v1",
    "published_date": "2024-05-18 08:16:11 UTC",
    "updated_date": "2024-05-18 08:16:11 UTC"
  },
  {
    "arxiv_id": "2405.11206v1",
    "title": "Towards Robust Policy: Enhancing Offline Reinforcement Learning with Adversarial Attacks and Defenses",
    "authors": [
      "Thanh Nguyen",
      "Tung M. Luu",
      "Tri Ton",
      "Chang D. Yoo"
    ],
    "abstract": "Offline reinforcement learning (RL) addresses the challenge of expensive and\nhigh-risk data exploration inherent in RL by pre-training policies on vast\namounts of offline data, enabling direct deployment or fine-tuning in\nreal-world environments. However, this training paradigm can compromise policy\nrobustness, leading to degraded performance in practical conditions due to\nobservation perturbations or intentional attacks. While adversarial attacks and\ndefenses have been extensively studied in deep learning, their application in\noffline RL is limited. This paper proposes a framework to enhance the\nrobustness of offline RL models by leveraging advanced adversarial attacks and\ndefenses. The framework attacks the actor and critic components by perturbing\nobservations during training and using adversarial defenses as regularization\nto enhance the learned policy. Four attacks and two defenses are introduced and\nevaluated on the D4RL benchmark. The results show the vulnerability of both the\nactor and critic to attacks and the effectiveness of the defenses in improving\npolicy robustness. This framework holds promise for enhancing the reliability\nof offline RL models in practical scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11206v1",
    "published_date": "2024-05-18 07:23:44 UTC",
    "updated_date": "2024-05-18 07:23:44 UTC"
  },
  {
    "arxiv_id": "2405.11198v1",
    "title": "Adaptive Stabilization Based on Machine Learning for Column Generation",
    "authors": [
      "Yunzhuang Shen",
      "Yuan Sun",
      "Xiaodong Li",
      "Zhiguang Cao",
      "Andrew Eberhard",
      "Guangquan Zhang"
    ],
    "abstract": "Column generation (CG) is a well-established method for solving large-scale\nlinear programs. It involves iteratively optimizing a subproblem containing a\nsubset of columns and using its dual solution to generate new columns with\nnegative reduced costs. This process continues until the dual values converge\nto the optimal dual solution to the original problem. A natural phenomenon in\nCG is the heavy oscillation of the dual values during iterations, which can\nlead to a substantial slowdown in the convergence rate. Stabilization\ntechniques are devised to accelerate the convergence of dual values by using\ninformation beyond the state of the current subproblem. However, there remains\na significant gap in obtaining more accurate dual values at an earlier stage.\nTo further narrow this gap, this paper introduces a novel approach consisting\nof 1) a machine learning approach for accurate prediction of optimal dual\nsolutions and 2) an adaptive stabilization technique that effectively\ncapitalizes on accurate predictions. On the graph coloring problem, we show\nthat our method achieves a significantly improved convergence rate compared to\ntraditional methods.",
    "categories": [
      "math.OC",
      "cs.AI"
    ],
    "primary_category": "math.OC",
    "comment": "Accepted by ICML'24",
    "pdf_url": "http://arxiv.org/pdf/2405.11198v1",
    "published_date": "2024-05-18 06:52:50 UTC",
    "updated_date": "2024-05-18 06:52:50 UTC"
  },
  {
    "arxiv_id": "2405.11195v1",
    "title": "Trustworthy Actionable Perturbations",
    "authors": [
      "Jesse Friedbaum",
      "Sudarshan Adiga",
      "Ravi Tandon"
    ],
    "abstract": "Counterfactuals, or modified inputs that lead to a different outcome, are an\nimportant tool for understanding the logic used by machine learning classifiers\nand how to change an undesirable classification. Even if a counterfactual\nchanges a classifier's decision, however, it may not affect the true underlying\nclass probabilities, i.e. the counterfactual may act like an adversarial attack\nand ``fool'' the classifier. We propose a new framework for creating modified\ninputs that change the true underlying probabilities in a beneficial way which\nwe call Trustworthy Actionable Perturbations (TAP). This includes a novel\nverification procedure to ensure that TAP change the true class probabilities\ninstead of acting adversarially. Our framework also includes new cost, reward,\nand goal definitions that are better suited to effectuating change in the real\nworld. We present PAC-learnability results for our verification procedure and\ntheoretically analyze our new method for measuring reward. We also develop a\nmethodology for creating TAP and compare our results to those achieved by\nprevious counterfactual methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at the 41st International Conference on Machine Learning\n  (ICML) 2024",
    "pdf_url": "http://arxiv.org/pdf/2405.11195v1",
    "published_date": "2024-05-18 06:14:00 UTC",
    "updated_date": "2024-05-18 06:14:00 UTC"
  },
  {
    "arxiv_id": "2405.11181v1",
    "title": "Towards Knowledge-Infused Automated Disease Diagnosis Assistant",
    "authors": [
      "Mohit Tomar",
      "Abhisek Tiwari",
      "Sriparna Saha"
    ],
    "abstract": "With the advancement of internet communication and telemedicine, people are\nincreasingly turning to the web for various healthcare activities. With an\never-increasing number of diseases and symptoms, diagnosing patients becomes\nchallenging. In this work, we build a diagnosis assistant to assist doctors,\nwhich identifies diseases based on patient-doctor interaction. During\ndiagnosis, doctors utilize both symptomatology knowledge and diagnostic\nexperience to identify diseases accurately and efficiently. Inspired by this,\nwe investigate the role of medical knowledge in disease diagnosis through\ndoctor-patient interaction. We propose a two-channel, knowledge-infused,\ndiscourse-aware disease diagnosis model (KI-DDI), where the first channel\nencodes patient-doctor communication using a transformer-based encoder, while\nthe other creates an embedding of symptom-disease using a graph attention\nnetwork (GAT). In the next stage, the conversation and knowledge graph\nembeddings are infused together and fed to a deep neural network for disease\nidentification. Furthermore, we first develop an empathetic conversational\nmedical corpus comprising conversations between patients and doctors, annotated\nwith intent and symptoms information. The proposed model demonstrates a\nsignificant improvement over the existing state-of-the-art models, establishing\nthe crucial roles of (a) a doctor's effort for additional symptom extraction\n(in addition to patient self-report) and (b) infusing medical knowledge in\nidentifying diseases effectively. Many times, patients also show their medical\nconditions, which acts as crucial evidence in diagnosis. Therefore, integrating\nvisual sensory information would represent an effective avenue for enhancing\nthe capabilities of diagnostic assistants.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11181v1",
    "published_date": "2024-05-18 05:18:50 UTC",
    "updated_date": "2024-05-18 05:18:50 UTC"
  },
  {
    "arxiv_id": "2405.11154v1",
    "title": "Revisiting the Robust Generalization of Adversarial Prompt Tuning",
    "authors": [
      "Fan Yang",
      "Mingxuan Xia",
      "Sangzhou Xia",
      "Chicheng Ma",
      "Hui Hui"
    ],
    "abstract": "Understanding the vulnerability of large-scale pre-trained vision-language\nmodels like CLIP against adversarial attacks is key to ensuring zero-shot\ngeneralization capacity on various downstream tasks. State-of-the-art defense\nmechanisms generally adopt prompt learning strategies for adversarial\nfine-tuning to improve the adversarial robustness of the pre-trained model\nwhile keeping the efficiency of adapting to downstream tasks. Such a setup\nleads to the problem of over-fitting which impedes further improvement of the\nmodel's generalization capacity on both clean and adversarial examples. In this\nwork, we propose an adaptive Consistency-guided Adversarial Prompt Tuning\n(i.e., CAPT) framework that utilizes multi-modal prompt learning to enhance the\nalignment of image and text features for adversarial examples and leverage the\nstrong generalization of pre-trained CLIP to guide the model-enhancing its\nrobust generalization on adversarial examples while maintaining its accuracy on\nclean ones. We also design a novel adaptive consistency objective function to\nbalance the consistency of adversarial inputs and clean inputs between the\nfine-tuning model and the pre-trained model. We conduct extensive experiments\nacross 14 datasets and 4 data sparsity schemes (from 1-shot to full training\ndata settings) to show the superiority of CAPT over other state-of-the-art\nadaption methods. CAPT demonstrated excellent performance in terms of the\nin-distribution performance and the generalization under input distribution\nshift and across datasets.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11154v1",
    "published_date": "2024-05-18 02:54:41 UTC",
    "updated_date": "2024-05-18 02:54:41 UTC"
  },
  {
    "arxiv_id": "2405.11151v1",
    "title": "Multi-scale Information Sharing and Selection Network with Boundary Attention for Polyp Segmentation",
    "authors": [
      "Xiaolu Kang",
      "Zhuoqi Ma",
      "Kang Liu",
      "Yunan Li",
      "Qiguang Miao"
    ],
    "abstract": "Polyp segmentation for colonoscopy images is of vital importance in clinical\npractice. It can provide valuable information for colorectal cancer diagnosis\nand surgery. While existing methods have achieved relatively good performance,\npolyp segmentation still faces the following challenges: (1) Varying lighting\nconditions in colonoscopy and differences in polyp locations, sizes, and\nmorphologies. (2) The indistinct boundary between polyps and surrounding\ntissue. To address these challenges, we propose a Multi-scale information\nsharing and selection network (MISNet) for polyp segmentation task. We design a\nSelectively Shared Fusion Module (SSFM) to enforce information sharing and\nactive selection between low-level and high-level features, thereby enhancing\nmodel's ability to capture comprehensive information. We then design a Parallel\nAttention Module (PAM) to enhance model's attention to boundaries, and a\nBalancing Weight Module (BWM) to facilitate the continuous refinement of\nboundary segmentation in the bottom-up process. Experiments on five polyp\nsegmentation datasets demonstrate that MISNet successfully improved the\naccuracy and clarity of segmentation result, outperforming state-of-the-art\nmethods.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11151v1",
    "published_date": "2024-05-18 02:48:39 UTC",
    "updated_date": "2024-05-18 02:48:39 UTC"
  },
  {
    "arxiv_id": "2405.11145v4",
    "title": "Detecting Multimodal Situations with Insufficient Context and Abstaining from Baseless Predictions",
    "authors": [
      "Junzhang Liu",
      "Zhecan Wang",
      "Hammad Ayyubi",
      "Haoxuan You",
      "Chris Thomas",
      "Rui Sun",
      "Shih-Fu Chang",
      "Kai-Wei Chang"
    ],
    "abstract": "Despite the widespread adoption of Vision-Language Understanding (VLU)\nbenchmarks such as VQA v2, OKVQA, A-OKVQA, GQA, VCR, SWAG, and VisualCOMET, our\nanalysis reveals a pervasive issue affecting their integrity: these benchmarks\ncontain samples where answers rely on assumptions unsupported by the provided\ncontext. Training models on such data foster biased learning and hallucinations\nas models tend to make similar unwarranted assumptions. To address this issue,\nwe collect contextual data for each sample whenever available and train a\ncontext selection module to facilitate evidence-based model predictions. Strong\nimprovements across multiple benchmarks demonstrate the effectiveness of our\napproach. Further, we develop a general-purpose Context-AwaRe Abstention (CARA)\ndetector to identify samples lacking sufficient context and enhance model\naccuracy by abstaining from responding if the required context is absent. CARA\nexhibits generalization to new benchmarks it wasn't trained on, underscoring\nits utility for future VLU benchmarks in detecting or cleaning samples with\ninadequate context. Finally, we curate a Context Ambiguity and Sufficiency\nEvaluation (CASE) set to benchmark the performance of insufficient context\ndetectors. Overall, our work represents a significant advancement in ensuring\nthat vision-language models generate trustworthy and evidence-based outputs in\ncomplex real-world scenarios.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.MM"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2405.11145v4",
    "published_date": "2024-05-18 02:21:32 UTC",
    "updated_date": "2025-03-29 07:00:30 UTC"
  },
  {
    "arxiv_id": "2405.11139v3",
    "title": "RuleFuser: An Evidential Bayes Approach for Rule Injection in Imitation Learned Planners and Predictors for Robustness under Distribution Shifts",
    "authors": [
      "Jay Patrikar",
      "Sushant Veer",
      "Apoorva Sharma",
      "Marco Pavone",
      "Sebastian Scherer"
    ],
    "abstract": "Modern motion planners for autonomous driving frequently use imitation\nlearning (IL) to draw from expert driving logs. Although IL benefits from its\nability to glean nuanced and multi-modal human driving behaviors from large\ndatasets, the resulting planners often struggle with out-of-distribution (OOD)\nscenarios and with traffic rule compliance. On the other hand, classical\nrule-based planners, by design, can generate safe traffic rule compliant\nbehaviors while being robust to OOD scenarios, but these planners fail to\ncapture nuances in agent-to-agent interactions and human drivers' intent.\nRuleFuser, an evidential framework, combines IL planners with classical\nrule-based planners to draw on the complementary benefits of both, thereby\nstriking a balance between imitation and safety.\n  Our approach, tested on the real-world nuPlan dataset, combines the IL\nplanner's high performance in in-distribution (ID) scenarios with the\nrule-based planners' enhanced safety in out-of-distribution (OOD) scenarios,\nachieving a 38.43% average improvement on safety metrics over the IL planner\nwithout much detriment to imitation metrics in OOD scenarios.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "17 pages, 5 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2405.11139v3",
    "published_date": "2024-05-18 01:49:16 UTC",
    "updated_date": "2024-09-16 18:44:47 UTC"
  }
]