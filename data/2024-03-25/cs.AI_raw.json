[
  {
    "arxiv_id": "2403.17266v1",
    "title": "Exploring CausalWorld: Enhancing robotic manipulation via knowledge transfer and curriculum learning",
    "authors": [
      "Xinrui Wang",
      "Yan Jin"
    ],
    "abstract": "This study explores a learning-based tri-finger robotic arm manipulating\ntask, which requires complex movements and coordination among the fingers. By\nemploying reinforcement learning, we train an agent to acquire the necessary\nskills for proficient manipulation. To enhance the efficiency and effectiveness\nof the learning process, two knowledge transfer strategies, fine-tuning and\ncurriculum learning, were utilized within the soft actor-critic architecture.\nFine-tuning allows the agent to leverage pre-trained knowledge and adapt it to\nnew tasks. Several variations like model transfer, policy transfer, and\nacross-task transfer were implemented and evaluated. To eliminate the need for\npretraining, curriculum learning decomposes the advanced task into simpler,\nprogressive stages, mirroring how humans learn. The number of learning stages,\nthe context of the sub-tasks, and the transition timing were found to be the\ncritical design parameters. The key factors of two learning strategies and\ncorresponding effects were explored in context-aware and context-unaware\nscenarios, enabling us to identify the scenarios where the methods demonstrate\noptimal performance, derive conclusive insights, and contribute to a broader\nrange of learning-based engineering applications.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17266v1",
    "published_date": "2024-03-25 23:19:19 UTC",
    "updated_date": "2024-03-25 23:19:19 UTC"
  },
  {
    "arxiv_id": "2403.17247v3",
    "title": "DASA: Delay-Adaptive Multi-Agent Stochastic Approximation",
    "authors": [
      "Nicolò Dal Fabbro",
      "Arman Adibi",
      "H. Vincent Poor",
      "Sanjeev R. Kulkarni",
      "Aritra Mitra",
      "George J. Pappas"
    ],
    "abstract": "We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tau_{mix}$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.",
    "categories": [
      "cs.AI",
      "cs.RO",
      "cs.SY",
      "eess.SY",
      "math.OC",
      "stat.ML"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17247v3",
    "published_date": "2024-03-25 22:49:56 UTC",
    "updated_date": "2024-08-02 09:03:09 UTC"
  },
  {
    "arxiv_id": "2403.17246v2",
    "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models",
    "authors": [
      "David Bai",
      "Ishika Singh",
      "David Traum",
      "Jesse Thomason"
    ],
    "abstract": "Classical planning formulations like the Planning Domain Definition Language\n(PDDL) admit action sequences guaranteed to achieve a goal state given an\ninitial state if any are possible. However, reasoning problems defined in PDDL\ndo not capture temporal aspects of action taking, such as concurrent actions\nbetween two agents when there are no conflicting conditions, without\nsignificant modification and definition to existing PDDL domains. A human\nexpert aware of such constraints can decompose a goal into subgoals, each\nreachable through single agent planning, to take advantage of simultaneous\nactions. In contrast to classical planning, large language models (LLMs)\ndirectly used for inferring plan steps rarely guarantee execution success, but\nare capable of leveraging commonsense reasoning to assemble action sequences.\nWe combine the strengths of both classical planning and LLMs by approximating\nhuman intuitions for multi-agent planning goal decomposition. We demonstrate\nthat LLM-based goal decomposition leads to faster planning times than solving\nmulti-agent PDDL problems directly while simultaneously achieving fewer plan\nexecution steps than a single agent plan alone, as well as most multiagent\nplans, while guaranteeing execution success. Additionally, we find that\nLLM-based approximations of subgoals result in similar multi-agent execution\nlengths to those specified by human experts. Website and resources at\nhttps://glamor-usc.github.io/twostep",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.MA",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.17246v2",
    "published_date": "2024-03-25 22:47:13 UTC",
    "updated_date": "2025-03-25 23:39:13 UTC"
  },
  {
    "arxiv_id": "2403.17237v1",
    "title": "DreamPolisher: Towards High-Quality Text-to-3D Generation via Geometric Diffusion",
    "authors": [
      "Yuanze Lin",
      "Ronald Clark",
      "Philip Torr"
    ],
    "abstract": "We present DreamPolisher, a novel Gaussian Splatting based method with\ngeometric guidance, tailored to learn cross-view consistency and intricate\ndetail from textual descriptions. While recent progress on text-to-3D\ngeneration methods have been promising, prevailing methods often fail to ensure\nview-consistency and textural richness. This problem becomes particularly\nnoticeable for methods that work with text input alone. To address this, we\npropose a two-stage Gaussian Splatting based approach that enforces geometric\nconsistency among views. Initially, a coarse 3D generation undergoes refinement\nvia geometric optimization. Subsequently, we use a ControlNet driven refiner\ncoupled with the geometric consistency term to improve both texture fidelity\nand overall consistency of the generated 3D asset. Empirical evaluations across\ndiverse textual prompts spanning various object categories demonstrate the\nefficacy of DreamPolisher in generating consistent and realistic 3D objects,\naligning closely with the semantics of the textual instructions.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "primary_category": "cs.CV",
    "comment": "Project webpage: https://yuanze-lin.me/DreamPolisher_page/",
    "pdf_url": "http://arxiv.org/pdf/2403.17237v1",
    "published_date": "2024-03-25 22:34:05 UTC",
    "updated_date": "2024-03-25 22:34:05 UTC"
  },
  {
    "arxiv_id": "2403.17234v2",
    "title": "Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking",
    "authors": [
      "Xinlong Zheng",
      "Xiaozhou Zhang",
      "Donghao Xu"
    ],
    "abstract": "In this paper, we address a method that integrates reinforcement learning\ninto the Monte Carlo tree search to boost online path planning under fully\nobservable environments for automated parking tasks. Sampling-based planning\nmethods under high-dimensional space can be computationally expensive and\ntime-consuming. State evaluation methods are useful by leveraging the prior\nknowledge into the search steps, making the process faster in a real-time\nsystem. Given the fact that automated parking tasks are often executed under\ncomplex environments, a solid but lightweight heuristic guidance is challenging\nto compose in a traditional analytical way. To overcome this limitation, we\npropose a reinforcement learning pipeline with a Monte Carlo tree search under\nthe path planning framework. By iteratively learning the value of a state and\nthe best action among samples from its previous cycle's outcomes, we are able\nto model a value estimator and a policy generator for given states. By doing\nthat, we build up a balancing mechanism between exploration and exploitation,\nspeeding up the path planning process while maintaining its quality without\nusing human expert driver data.",
    "categories": [
      "cs.AI",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted by IROS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.17234v2",
    "published_date": "2024-03-25 22:21:23 UTC",
    "updated_date": "2024-12-31 06:53:26 UTC"
  },
  {
    "arxiv_id": "2403.17224v2",
    "title": "Uncertainty Quantification for Gradient-based Explanations in Neural Networks",
    "authors": [
      "Mihir Mulye",
      "Matias Valdenegro-Toro"
    ],
    "abstract": "Explanation methods help understand the reasons for a model's prediction.\nThese methods are increasingly involved in model debugging, performance\noptimization, and gaining insights into the workings of a model. With such\ncritical applications of these methods, it is imperative to measure the\nuncertainty associated with the explanations generated by these methods. In\nthis paper, we propose a pipeline to ascertain the explanation uncertainty of\nneural networks by combining uncertainty estimation methods and explanation\nmethods. We use this pipeline to produce explanation distributions for the\nCIFAR-10, FER+, and California Housing datasets. By computing the coefficient\nof variation of these distributions, we evaluate the confidence in the\nexplanation and determine that the explanations generated using Guided\nBackpropagation have low uncertainty associated with them. Additionally, we\ncompute modified pixel insertion/deletion metrics to evaluate the quality of\nthe generated explanations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "13 pages, 11 figures, UNCV @ CVPR 2025 Camera ready",
    "pdf_url": "http://arxiv.org/pdf/2403.17224v2",
    "published_date": "2024-03-25 21:56:02 UTC",
    "updated_date": "2025-04-14 19:43:05 UTC"
  },
  {
    "arxiv_id": "2403.17223v1",
    "title": "Co-Occurring of Object Detection and Identification towards unlabeled object discovery",
    "authors": [
      "Binay Kumar Singh",
      "Niels Da Vitoria Lobo"
    ],
    "abstract": "In this paper, we propose a novel deep learning based approach for\nidentifying co-occurring objects in conjunction with base objects in multilabel\nobject categories. Nowadays, with the advancement in computer vision based\ntechniques we need to know about co-occurring objects with respect to base\nobject for various purposes. The pipeline of the proposed work is composed of\ntwo stages: in the first stage of the proposed model we detect all the bounding\nboxes present in the image and their corresponding labels, then in the second\nstage we perform co-occurrence matrix analysis. In co-occurrence matrix\nanalysis, we set base classes based on the maximum occurrences of the labels\nand build association rules and generate frequent patterns. These frequent\npatterns will show base classes and their corresponding co-occurring classes.\nWe performed our experiments on two publicly available datasets: Pascal VOC and\nMS-COCO. The experimental results on public benchmark dataset is reported in\nSec 4. Further we extend this work by considering all frequently objects as\nunlabeled and what if they are occluded as well.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "6 pages, 2 figures,",
    "pdf_url": "http://arxiv.org/pdf/2403.17223v1",
    "published_date": "2024-03-25 21:53:36 UTC",
    "updated_date": "2024-03-25 21:53:36 UTC"
  },
  {
    "arxiv_id": "2403.17219v2",
    "title": "SeSaMe: A Framework to Simulate Self-Reported Ground Truth for Mental Health Sensing Studies",
    "authors": [
      "Akshat Choube",
      "Vedant Das Swain",
      "Varun Mishra"
    ],
    "abstract": "Advances in mobile and wearable technologies have enabled the potential to\npassively monitor a person's mental, behavioral, and affective health. These\napproaches typically rely on longitudinal collection of self-reported outcomes,\ne.g., depression, stress, and anxiety, to train machine learning (ML) models.\nHowever, the need to continuously self-report adds a significant burden on the\nparticipants, often resulting in attrition, missing labels, or insincere\nresponses. In this work, we introduce the Scale Scores Simulation using Mental\nModels (SeSaMe) framework to alleviate participants' burden in digital mental\nhealth studies. By leveraging pre-trained large language models (LLMs), SeSaMe\nenables the simulation of participants' responses on psychological scales. In\nSeSaMe, researchers can prompt LLMs with information on participants' internal\nbehavioral dispositions, enabling LLMs to construct mental models of\nparticipants to simulate their responses on psychological scales. We\ndemonstrate an application of SeSaMe, where we use GPT-4 to simulate responses\non one scale using responses from another as behavioral information. We also\nevaluate the alignment between human and SeSaMe-simulated responses to\npsychological scales. Then, we present experiments to inspect the utility of\nSeSaMe-simulated responses as ground truth in training ML models by replicating\nestablished depression and anxiety screening tasks from a previous study. Our\nresults indicate SeSaMe to be a promising approach, but its alignment may vary\nacross scales and specific prediction objectives. We also observed that model\nperformance with simulated data was on par with using the real data for\ntraining in most evaluation scenarios. We conclude by discussing the potential\nimplications of SeSaMe in addressing some challenges researchers face with\nground-truth collection in passive sensing studies.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CY"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17219v2",
    "published_date": "2024-03-25 21:48:22 UTC",
    "updated_date": "2024-03-27 15:08:31 UTC"
  },
  {
    "arxiv_id": "2403.17217v2",
    "title": "DiffusionAct: Controllable Diffusion Autoencoder for One-shot Face Reenactment",
    "authors": [
      "Stella Bounareli",
      "Christos Tzelepis",
      "Vasileios Argyriou",
      "Ioannis Patras",
      "Georgios Tzimiropoulos"
    ],
    "abstract": "Video-driven neural face reenactment aims to synthesize realistic facial\nimages that successfully preserve the identity and appearance of a source face,\nwhile transferring the target head pose and facial expressions. Existing\nGAN-based methods suffer from either distortions and visual artifacts or poor\nreconstruction quality, i.e., the background and several important appearance\ndetails, such as hair style/color, glasses and accessories, are not faithfully\nreconstructed. Recent advances in Diffusion Probabilistic Models (DPMs) enable\nthe generation of high-quality realistic images. To this end, in this paper we\npresent DiffusionAct, a novel method that leverages the photo-realistic image\ngeneration of diffusion models to perform neural face reenactment.\nSpecifically, we propose to control the semantic space of a Diffusion\nAutoencoder (DiffAE), in order to edit the facial pose of the input images,\ndefined as the head pose orientation and the facial expressions. Our method\nallows one-shot, self, and cross-subject reenactment, without requiring\nsubject-specific fine-tuning. We compare against state-of-the-art GAN-,\nStyleGAN2-, and diffusion-based methods, showing better or on-par reenactment\nperformance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://stelabou.github.io/diffusionact/",
    "pdf_url": "http://arxiv.org/pdf/2403.17217v2",
    "published_date": "2024-03-25 21:46:53 UTC",
    "updated_date": "2025-03-25 09:47:55 UTC"
  },
  {
    "arxiv_id": "2403.17214v1",
    "title": "Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation",
    "authors": [
      "Marcos Macedo",
      "Yuan Tian",
      "Filipe R. Cogo",
      "Bram Adams"
    ],
    "abstract": "Code translation between programming languages is a long-existing and\ncritical task in software engineering, facilitating the modernization of legacy\nsystems, ensuring cross-platform compatibility, and enhancing software\nperformance. With the recent advances in large language models (LLMs) and their\napplications to code translation, there is an increasing need for comprehensive\nevaluation of these models. In this study, we empirically analyze the generated\noutputs of eleven popular instruct-tuned LLMs with parameters ranging from 1B\nup to 46.7B on 3,820 translation pairs across five languages, including C, C++,\nGo, Java, and Python. Our analysis found that between 26.4% and 73.7% of code\ntranslations produced by our evaluated LLMs necessitate post-processing, as\nthese translations often include a mix of code, quotes, and text rather than\nbeing purely source code. Overlooking the output format of these models can\ninadvertently lead to underestimation of their actual performance. This is\nparticularly evident when evaluating them with execution-based metrics such as\nComputational Accuracy (CA). Our results demonstrate that a strategic\ncombination of prompt engineering and regular expression can effectively\nextract the source code from the model generation output. In particular, our\nmethod can help eleven selected models achieve an average Code Extraction\nSuccess Rate (CSR) of 92.73%. Our findings shed light on and motivate future\nresearch to conduct more reliable benchmarks of LLMs for code translation.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "Accepted into 2024 IEEE/ACM First International Conference on AI\n  Foundation Models and Software Engineering (Forge)",
    "pdf_url": "http://arxiv.org/pdf/2403.17214v1",
    "published_date": "2024-03-25 21:41:31 UTC",
    "updated_date": "2024-03-25 21:41:31 UTC"
  },
  {
    "arxiv_id": "2403.17212v1",
    "title": "Sanity Checks for Explanation Uncertainty",
    "authors": [
      "Matias Valdenegro-Toro",
      "Mihir Mulye"
    ],
    "abstract": "Explanations for machine learning models can be hard to interpret or be\nwrong. Combining an explanation method with an uncertainty estimation method\nproduces explanation uncertainty. Evaluating explanation uncertainty is\ndifficult. In this paper we propose sanity checks for uncertainty explanation\nmethods, where a weight and data randomization tests are defined for\nexplanations with uncertainty, allowing for quick tests to combinations of\nuncertainty and explanation methods. We experimentally show the validity and\neffectiveness of these tests on the CIFAR10 and California Housing datasets,\nnoting that Ensembles seem to consistently pass both tests with Guided\nBackpropagation, Integrated Gradients, and LIME explanations.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 7 figures, 3 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.17212v1",
    "published_date": "2024-03-25 21:39:33 UTC",
    "updated_date": "2024-03-25 21:39:33 UTC"
  },
  {
    "arxiv_id": "2403.17210v2",
    "title": "CADGL: Context-Aware Deep Graph Learning for Predicting Drug-Drug Interactions",
    "authors": [
      "Azmine Toushik Wasi",
      "Taki Hasan Rafi",
      "Raima Islam",
      "Serbetar Karlo",
      "Dong-Kyu Chae"
    ],
    "abstract": "Examining Drug-Drug Interactions (DDIs) is a pivotal element in the process\nof drug development. DDIs occur when one drug's properties are affected by the\ninclusion of other drugs. Detecting favorable DDIs has the potential to pave\nthe way for creating and advancing innovative medications applicable in\npractical settings. However, existing DDI prediction models continue to face\nchallenges related to generalization in extreme cases, robust feature\nextraction, and real-life application possibilities. We aim to address these\nchallenges by leveraging the effectiveness of context-aware deep graph learning\nby introducing a novel framework named CADGL. Based on a customized variational\ngraph autoencoder (VGAE), we capture critical structural and physio-chemical\ninformation using two context preprocessors for feature extraction from two\ndifferent perspectives: local neighborhood and molecular context, in a\nheterogeneous graphical structure. Our customized VGAE consists of a graph\nencoder, a latent information encoder, and an MLP decoder. CADGL surpasses\nother state-of-the-art DDI prediction models, excelling in predicting\nclinically valuable novel DDIs, supported by rigorous case studies.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IR",
      "q-bio.BM",
      "q-bio.MN"
    ],
    "primary_category": "cs.LG",
    "comment": "8 Pages, 4 Figures; In review",
    "pdf_url": "http://arxiv.org/pdf/2403.17210v2",
    "published_date": "2024-03-25 21:37:31 UTC",
    "updated_date": "2024-03-27 21:47:49 UTC"
  },
  {
    "arxiv_id": "2403.17209v4",
    "title": "Generation of Asset Administration Shell with Large Language Model Agents: Toward Semantic Interoperability in Digital Twins in the Context of Industry 4.0",
    "authors": [
      "Yuchen Xia",
      "Zhewen Xiao",
      "Nasser Jazdi",
      "Michael Weyrich"
    ],
    "abstract": "This research introduces a novel approach for achieving semantic\ninteroperability in digital twins and assisting the creation of Asset\nAdministration Shell (AAS) as digital twin model within the context of Industry\n4.0. The foundational idea of our research is that the communication based on\nsemantics and the generation of meaningful textual data are directly linked,\nand we posit that these processes are equivalent if the exchanged information\ncan be serialized in text form. Based on this, we construct a \"semantic node\"\ndata structure in our research to capture the semantic essence of textual data.\nThen, a system powered by large language models is designed and implemented to\nprocess the \"semantic node\" and generate standardized digital twin models from\nraw textual data collected from datasheets describing technical assets. Our\nevaluation demonstrates an effective generation rate of 62-79%, indicating a\nsubstantial proportion of the information from the source text can be\ntranslated error-free to the target digital twin instance model with the\ngenerative capability of large language models. This result has a direct\napplication in the context of Industry 4.0, and the designed system is\nimplemented as a data model generation tool for reducing the manual effort in\ncreating AAS model. In our evaluation, a comparative analysis of different LLMs\nand an in-depth ablation study of Retrieval-Augmented Generation (RAG)\nmechanisms provide insights into the effectiveness of LLM systems for\ninterpreting technical concepts and translating data. Our findings emphasize\nLLMs' capability to automate AAS instance creation and contribute to the\nbroader field of semantic interoperability for digital twins in industrial\napplications. The prototype implementation and evaluation results are presented\non our GitHub Repository: https://github.com/YuchenXia/AASbyLLM.",
    "categories": [
      "cs.AI",
      "cs.IR",
      "cs.MA",
      "cs.SE"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in IEEE Access",
    "pdf_url": "http://arxiv.org/pdf/2403.17209v4",
    "published_date": "2024-03-25 21:37:30 UTC",
    "updated_date": "2024-06-24 12:04:06 UTC"
  },
  {
    "arxiv_id": "2403.17169v3",
    "title": "QuanTemp: A real-world open-domain benchmark for fact-checking numerical claims",
    "authors": [
      "Venktesh V",
      "Abhijit Anand",
      "Avishek Anand",
      "Vinay Setty"
    ],
    "abstract": "Automated fact checking has gained immense interest to tackle the growing\nmisinformation in the digital era. Existing systems primarily focus on\nsynthetic claims on Wikipedia, and noteworthy progress has also been made on\nreal-world claims. In this work, we release QuanTemp, a diverse, multi-domain\ndataset focused exclusively on numerical claims, encompassing temporal,\nstatistical and diverse aspects with fine-grained metadata and an evidence\ncollection without leakage. This addresses the challenge of verifying\nreal-world numerical claims, which are complex and often lack precise\ninformation, not addressed by existing works that mainly focus on synthetic\nclaims. We evaluate and quantify the limitations of existing solutions for the\ntask of verifying numerical claims. We also evaluate claim decomposition based\nmethods, numerical understanding based models and our best baselines achieves a\nmacro-F1 of 58.32. This demonstrates that QuanTemp serves as a challenging\nevaluation set for numerical claim verification.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "11 pages, 1 figure,Accepted for publication at the 47th International\n  ACM SIGIR Conference on Research and Development in Information Retrieval\n  (SIGIR 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.17169v3",
    "published_date": "2024-03-25 20:36:03 UTC",
    "updated_date": "2024-05-01 06:27:24 UTC"
  },
  {
    "arxiv_id": "2403.17164v2",
    "title": "Multi-Objective Quality-Diversity for Crystal Structure Prediction",
    "authors": [
      "Hannah Janmohamed",
      "Marta Wolinska",
      "Shikha Surana",
      "Thomas Pierrot",
      "Aron Walsh",
      "Antoine Cully"
    ],
    "abstract": "Crystal structures are indispensable across various domains, from batteries\nto solar cells, and extensive research has been dedicated to predicting their\nproperties based on their atomic configurations. However, prevailing Crystal\nStructure Prediction methods focus on identifying the most stable solutions\nthat lie at the global minimum of the energy function. This approach overlooks\nother potentially interesting materials that lie in neighbouring local minima\nand have different material properties such as conductivity or resistance to\ndeformation. By contrast, Quality-Diversity algorithms provide a promising\navenue for Crystal Structure Prediction as they aim to find a collection of\nhigh-performing solutions that have diverse characteristics. However, it may\nalso be valuable to optimise for the stability of crystal structures alongside\nother objectives such as magnetism or thermoelectric efficiency. Therefore, in\nthis work, we harness the power of Multi-Objective Quality-Diversity algorithms\nin order to find crystal structures which have diverse features and achieve\ndifferent trade-offs of objectives. We analyse our approach on 5 crystal\nsystems and demonstrate that it is not only able to re-discover known real-life\nstructures, but also find promising new ones. Moreover, we propose a method for\nilluminating the objective space to gain an understanding of what trade-offs\ncan be achieved.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted GECCO 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.17164v2",
    "published_date": "2024-03-25 20:29:04 UTC",
    "updated_date": "2024-06-21 09:26:34 UTC"
  },
  {
    "arxiv_id": "2403.17159v1",
    "title": "Less Is More -- On the Importance of Sparsification for Transformers and Graph Neural Networks for TSP",
    "authors": [
      "Attila Lischka",
      "Jiaming Wu",
      "Rafael Basso",
      "Morteza Haghir Chehreghani",
      "Balázs Kulcsár"
    ],
    "abstract": "Most of the recent studies tackling routing problems like the Traveling\nSalesman Problem (TSP) with machine learning use a transformer or Graph Neural\nNetwork (GNN) based encoder architecture. However, many of them apply these\nencoders naively by allowing them to aggregate information over the whole TSP\ninstances. We, on the other hand, propose a data preprocessing method that\nallows the encoders to focus on the most relevant parts of the TSP instances\nonly. In particular, we propose graph sparsification for TSP graph\nrepresentations passed to GNNs and attention masking for TSP instances passed\nto transformers where the masks correspond to the adjacency matrices of the\nsparse TSP graph representations. Furthermore, we propose ensembles of\ndifferent sparsification levels allowing models to focus on the most promising\nparts while also allowing information flow between all nodes of a TSP instance.\nIn the experimental studies, we show that for GNNs appropriate sparsification\nand ensembles of different sparsification levels lead to substantial\nperformance increases of the overall architecture. We also design a new,\nstate-of-the-art transformer encoder with ensembles of attention masking. These\ntransformers increase model performance from a gap of $0.16\\%$ to $0.10\\%$ for\nTSP instances of size 100 and from $0.02\\%$ to $0.00\\%$ for TSP instances of\nsize 50.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 6 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.17159v1",
    "published_date": "2024-03-25 20:16:16 UTC",
    "updated_date": "2024-03-25 20:16:16 UTC"
  },
  {
    "arxiv_id": "2403.17154v3",
    "title": "On the Impact of Black-box Deployment Strategies for Edge AI on Latency and Model Performance",
    "authors": [
      "Jaskirat Singh",
      "Emad Fallahzadeh",
      "Bram Adams",
      "Ahmed E. Hassan"
    ],
    "abstract": "Deciding what combination of operators to use across the Edge AI tiers to\nachieve specific latency and model performance requirements is an open question\nfor MLOps engineers. This study aims to empirically assess the accuracy vs\ninference time trade-off of different black-box Edge AI deployment strategies,\ni.e., combinations of deployment operators and deployment tiers. In this paper,\nwe conduct inference experiments involving 3 deployment operators (i.e.,\nPartitioning, Quantization, Early Exit), 3 deployment tiers (i.e., Mobile,\nEdge, Cloud) and their combinations on four widely used Computer-Vision models\nto investigate the optimal strategies from the point of view of MLOps\ndevelopers. Our findings suggest that Edge deployment using the hybrid\nQuantization + Early Exit operator could be preferred over non-hybrid operators\n(Quantization/Early Exit on Edge, Partition on Mobile-Edge) when faster latency\nis a concern at medium accuracy loss. However, when minimizing accuracy loss is\na concern, MLOps engineers should prefer using only a Quantization operator on\nedge at a latency reduction or increase, respectively over the Early\nExit/Partition (on edge/mobile-edge) and Quantized Early Exit (on edge)\noperators. In scenarios constrained by Mobile CPU/RAM resources, a preference\nfor Partitioning across mobile and edge tiers is observed over mobile\ndeployment. For models with smaller input data samples (such as FCN), a\nnetwork-constrained cloud deployment can also be a better alternative than\nMobile/Edge deployment and Partitioning strategies. For models with large input\ndata samples (ResNet, ResNext, DUC), an edge tier having higher\nnetwork/computational capabilities than Cloud/Mobile can be a more viable\noption than Partitioning and Mobile/Cloud deployment strategies.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17154v3",
    "published_date": "2024-03-25 20:09:46 UTC",
    "updated_date": "2025-05-11 17:15:02 UTC"
  },
  {
    "arxiv_id": "2403.17147v1",
    "title": "Hearing the shape of an arena with spectral swarm robotics",
    "authors": [
      "Leo Cazenille",
      "Nicolas Lobato-Dauzier",
      "Alessia Loi",
      "Mika Ito",
      "Olivier Marchal",
      "Nathanael Aubert-Kato",
      "Nicolas Bredeche",
      "Anthony J. Genot"
    ],
    "abstract": "Swarm robotics promises adaptability to unknown situations and robustness\nagainst failures. However, it still struggles with global tasks that require\nunderstanding the broader context in which the robots operate, such as\nidentifying the shape of the arena in which the robots are embedded. Biological\nswarms, such as shoals of fish, flocks of birds, and colonies of insects,\nroutinely solve global geometrical problems through the diffusion of local\ncues. This paradigm can be explicitly described by mathematical models that\ncould be directly computed and exploited by a robotic swarm. Diffusion over a\ndomain is mathematically encapsulated by the Laplacian, a linear operator that\nmeasures the local curvature of a function. Crucially the geometry of a domain\ncan generally be reconstructed from the eigenspectrum of its Laplacian. Here we\nintroduce spectral swarm robotics where robots diffuse information to their\nneighbors to emulate the Laplacian operator - enabling them to \"hear\" the\nspectrum of their arena. We reveal a universal scaling that links the optimal\nnumber of robots (a global parameter) with their optimal radius of interaction\n(a local parameter). We validate experimentally spectral swarm robotics under\nchallenging conditions with the one-shot classification of arena shapes using a\nsparse swarm of Kilobots. Spectral methods can assist with challenging tasks\nwhere robots need to build an emergent consensus on their environment, such as\nadaptation to unknown terrains, division of labor, or quorum sensing. Spectral\nmethods may extend beyond robotics to analyze and coordinate swarms of agents\nof various natures, such as traffic or crowds, and to better understand the\nlong-range dynamics of natural systems emerging from short-range interactions.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CG"
    ],
    "primary_category": "cs.RO",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17147v1",
    "published_date": "2024-03-25 19:50:07 UTC",
    "updated_date": "2024-03-25 19:50:07 UTC"
  },
  {
    "arxiv_id": "2403.17141v3",
    "title": "MetaAligner: Towards Generalizable Multi-Objective Alignment of Language Models",
    "authors": [
      "Kailai Yang",
      "Zhiwei Liu",
      "Qianqian Xie",
      "Jimin Huang",
      "Tianlin Zhang",
      "Sophia Ananiadou"
    ],
    "abstract": "Recent advancements in large language models (LLMs) focus on aligning to\nheterogeneous human expectations and values via multi-objective preference\nalignment. However, existing methods are dependent on the policy model\nparameters, which require high-cost repetition of their alignment algorithms\nfor each new policy model, and they cannot expand to unseen objectives due to\ntheir static alignment objectives. In this work, we propose Meta-Objective\nAligner (MetaAligner), the first policy-agnostic and generalizable method for\nmulti-objective preference alignment. MetaAligner models multi-objective\nalignment into three stages: (1) dynamic objectives reformulation algorithm\nreorganizes traditional alignment datasets to supervise the model on performing\nflexible alignment across different objectives; (2) conditional weak-to-strong\ncorrection paradigm aligns the weak outputs of fixed policy models to approach\nstrong outputs with higher preferences in the corresponding alignment\nobjectives, enabling plug-and-play inferences on any policy models, which\nsignificantly reduces training costs and facilitates alignment on close-source\npolicy models; (3) generalizable inference method flexibly adjusts target\nobjectives by updating their text descriptions in the prompts, facilitating\ngeneralizable alignment to unseen objectives. Experimental results show that\nMetaAligner achieves significant and balanced improvements in multi-objective\nalignments on 10 state-of-the-art policy models, and saves up to 93.63% of GPU\ntraining hours compared to previous alignment methods. The model also\neffectively aligns unseen objectives, marking the first step towards\ngeneralizable multi-objective preference alignment.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted by NeurIPS 2024 main track",
    "pdf_url": "http://arxiv.org/pdf/2403.17141v3",
    "published_date": "2024-03-25 19:28:10 UTC",
    "updated_date": "2024-10-07 03:19:16 UTC"
  },
  {
    "arxiv_id": "2403.17134v2",
    "title": "RepairAgent: An Autonomous, LLM-Based Agent for Program Repair",
    "authors": [
      "Islem Bouzenia",
      "Premkumar Devanbu",
      "Michael Pradel"
    ],
    "abstract": "Automated program repair has emerged as a powerful technique to mitigate the\nimpact of software bugs on system reliability and user experience. This paper\nintroduces RepairAgent, the first work to address the program repair challenge\nthrough an autonomous agent based on a large language model (LLM). Unlike\nexisting deep learning-based approaches, which prompt a model with a fixed\nprompt or in a fixed feedback loop, our work treats the LLM as an agent capable\nof autonomously planning and executing actions to fix bugs by invoking suitable\ntools. RepairAgent freely interleaves gathering information about the bug,\ngathering repair ingredients, and validating fixes, while deciding which tools\nto invoke based on the gathered information and feedback from previous fix\nattempts. Key contributions that enable RepairAgent include a set of tools that\nare useful for program repair, a dynamically updated prompt format that allows\nthe LLM to interact with these tools, and a finite state machine that guides\nthe agent in invoking the tools. Our evaluation on the popular Defects4J\ndataset demonstrates RepairAgent's effectiveness in autonomously repairing 164\nbugs, including 39 bugs not fixed by prior techniques. Interacting with the LLM\nimposes an average cost of 270,000 tokens per bug, which, under the current\npricing of OpenAI's GPT-3.5 model, translates to 14 cents of USD per bug. To\nthe best of our knowledge, this work is the first to present an autonomous,\nLLM-based agent for program repair, paving the way for future agent-based\ntechniques in software engineering.",
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17134v2",
    "published_date": "2024-03-25 19:17:43 UTC",
    "updated_date": "2024-10-28 17:33:27 UTC"
  },
  {
    "arxiv_id": "2403.17130v1",
    "title": "Exploring the potential of prototype-based soft-labels data distillation for imbalanced data classification",
    "authors": [
      "Radu-Andrei Rosu",
      "Mihaela-Elena Breaban",
      "Henri Luchian"
    ],
    "abstract": "Dataset distillation aims at synthesizing a dataset by a small number of\nartificially generated data items, which, when used as training data, reproduce\nor approximate a machine learning (ML) model as if it were trained on the\nentire original dataset. Consequently, data distillation methods are usually\ntied to a specific ML algorithm. While recent literature deals mainly with\ndistillation of large collections of images in the context of neural network\nmodels, tabular data distillation is much less represented and mainly focused\non a theoretical perspective. The current paper explores the potential of a\nsimple distillation technique previously proposed in the context of\nLess-than-one shot learning. The main goal is to push further the performance\nof prototype-based soft-labels distillation in terms of classification\naccuracy, by integrating optimization steps in the distillation process. The\nanalysis is performed on real-world data sets with various degrees of\nimbalance. Experimental studies trace the capability of the method to distill\nthe data, but also the opportunity to act as an augmentation method, i.e. to\ngenerate new data that is able to increase model accuracy when used in\nconjunction with - as opposed to instead of - the original data.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17130v1",
    "published_date": "2024-03-25 19:15:19 UTC",
    "updated_date": "2024-03-25 19:15:19 UTC"
  },
  {
    "arxiv_id": "2403.17125v1",
    "title": "The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition",
    "authors": [
      "Georgios Chochlakis",
      "Alexandros Potamianos",
      "Kristina Lerman",
      "Shrikanth Narayanan"
    ],
    "abstract": "In-context Learning (ICL) has emerged as a powerful paradigm for performing\nnatural language tasks with Large Language Models (LLM) without updating the\nmodels' parameters, in contrast to the traditional gradient-based finetuning.\nThe promise of ICL is that the LLM can adapt to perform the present task at a\ncompetitive or state-of-the-art level at a fraction of the cost. The ability of\nLLMs to perform tasks in this few-shot manner relies on their background\nknowledge of the task (or task priors). However, recent work has found that,\nunlike traditional learning, LLMs are unable to fully integrate information\nfrom demonstrations that contrast task priors. This can lead to performance\nsaturation at suboptimal levels, especially for subjective tasks such as\nemotion recognition, where the mapping from text to emotions can differ widely\ndue to variability in human annotations. In this work, we design experiments\nand propose measurements to explicitly quantify the consistency of proxies of\nLLM priors and their pull on the posteriors. We show that LLMs have strong yet\ninconsistent priors in emotion recognition that ossify their predictions. We\nalso find that the larger the model, the stronger these effects become. Our\nresults suggest that caution is needed when using ICL with larger LLMs for\naffect-centered tasks outside their pre-training domain and when interpreting\nICL results.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "30 pages, 27 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.17125v1",
    "published_date": "2024-03-25 19:07:32 UTC",
    "updated_date": "2024-03-25 19:07:32 UTC"
  },
  {
    "arxiv_id": "2403.17124v2",
    "title": "Grounding Language Plans in Demonstrations Through Counterfactual Perturbations",
    "authors": [
      "Yanwei Wang",
      "Tsun-Hsuan Wang",
      "Jiayuan Mao",
      "Michael Hagenow",
      "Julie Shah"
    ],
    "abstract": "Grounding the common-sense reasoning of Large Language Models (LLMs) in\nphysical domains remains a pivotal yet unsolved problem for embodied AI.\nWhereas prior works have focused on leveraging LLMs directly for planning in\nsymbolic spaces, this work uses LLMs to guide the search of task structures and\nconstraints implicit in multi-step demonstrations. Specifically, we borrow from\nmanipulation planning literature the concept of mode families, which group\nrobot configurations by specific motion constraints, to serve as an abstraction\nlayer between the high-level language representations of an LLM and the\nlow-level physical trajectories of a robot. By replaying a few human\ndemonstrations with synthetic perturbations, we generate coverage over the\ndemonstrations' state space with additional successful executions as well as\ncounterfactuals that fail the task. Our explanation-based learning framework\ntrains an end-to-end differentiable neural network to predict successful\ntrajectories from failures and as a by-product learns classifiers that ground\nlow-level states and images in mode families without dense labeling. The\nlearned grounding classifiers can further be used to translate language plans\ninto reactive policies in the physical domain in an interpretable manner. We\nshow our approach improves the interpretability and reactivity of imitation\nlearning through 2D navigation and simulated and real robot manipulation tasks.\nWebsite: https://yanweiw.github.io/glide",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.RO",
    "comment": "ICLR 2024 Spotlight",
    "pdf_url": "http://arxiv.org/pdf/2403.17124v2",
    "published_date": "2024-03-25 19:04:59 UTC",
    "updated_date": "2024-04-29 04:34:52 UTC"
  },
  {
    "arxiv_id": "2403.17108v1",
    "title": "Graph Protection under Multiple Simultaneous Attacks: A Heuristic Approach",
    "authors": [
      "Marko Djukanovic",
      "Stefan Kapunac",
      "Aleksandar Kartelj",
      "Dragan Matic"
    ],
    "abstract": "This work focuses on developing an effective meta-heuristic approach to\nprotect against simultaneous attacks on nodes of a network modeled using a\ngraph. Specifically, we focus on the $k$-strong Roman domination problem, a\ngeneralization of the well-known Roman domination problem on graphs. This\ngeneral problem is about assigning integer weights to nodes that represent the\nnumber of field armies stationed at each node in order to satisfy the\nprotection constraints while minimizing the total weights. These constraints\nconcern the protection of a graph against any simultaneous attack consisting of\n$k \\in \\mathbb{N}$ nodes. An attack is considered repelled if each node labeled\n0 can be defended by borrowing an army from one of its neighboring nodes,\nensuring that the neighbor retains at least one army for self-defense. The\n$k$-SRD problem has practical applications in various areas, such as developing\ncounter-terrorism strategies or managing supply chain disruptions. The solution\nto this problem is notoriously difficult to find, as even checking the\nfeasibility of the proposed solution requires an exponential number of steps.\nWe propose a variable neighborhood search algorithm in which the feasibility of\nthe solution is checked by introducing the concept of quasi-feasibility, which\nis realized by careful sampling within the set of all possible attacks.\nExtensive experimental evaluations show the scalability and robustness of the\nproposed approach compared to the two exact approaches from the literature.\nExperiments are conducted with random networks from the literature and newly\nintroduced random wireless networks as well as with real-world networks. A\npractical application scenario, using real-world networks, involves applying\nour approach to graphs extracted from GeoJSON files containing geographic\nfeatures of hundreds of cities or larger regions.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "32 pages, 10 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.17108v1",
    "published_date": "2024-03-25 18:46:13 UTC",
    "updated_date": "2024-03-25 18:46:13 UTC"
  },
  {
    "arxiv_id": "2403.17101v11",
    "title": "AI Consciousness is Inevitable: A Theoretical Computer Science Perspective",
    "authors": [
      "Lenore Blum",
      "Manuel Blum"
    ],
    "abstract": "We look at consciousness through the lens of Theoretical Computer Science, a\nbranch of mathematics that studies computation under resource limitations,\ndistinguishing functions that are efficiently computable from those that are\nnot. From this perspective, we develop a formal machine model for\nconsciousness. The model is inspired by Alan Turing's simple yet powerful model\nof computation and Bernard Baars' theater model of consciousness. Though\nextremely simple, the model (1) aligns at a high level with many of the major\nscientific theories of human and animal consciousness, (2) provides\nexplanations at a high level for many phenomena associated with consciousness,\n(3) gives insight into how a machine can have subjective consciousness, and (4)\nis clearly buildable. This combination supports our claim that machine\nconsciousness is not only plausible but inevitable.",
    "categories": [
      "cs.AI",
      "68T01",
      "F.1; I.2"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17101v11",
    "published_date": "2024-03-25 18:38:54 UTC",
    "updated_date": "2025-04-06 21:09:23 UTC"
  },
  {
    "arxiv_id": "2403.19710v1",
    "title": "STRUM-LLM: Attributed and Structured Contrastive Summarization",
    "authors": [
      "Beliz Gunel",
      "James B. Wendt",
      "Jing Xie",
      "Yichao Zhou",
      "Nguyen Vo",
      "Zachary Fisher",
      "Sandeep Tata"
    ],
    "abstract": "Users often struggle with decision-making between two options (A vs B), as it\nusually requires time-consuming research across multiple web pages. We propose\nSTRUM-LLM that addresses this challenge by generating attributed, structured,\nand helpful contrastive summaries that highlight key differences between the\ntwo options. STRUM-LLM identifies helpful contrast: the specific attributes\nalong which the two options differ significantly and which are most likely to\ninfluence the user's decision. Our technique is domain-agnostic, and does not\nrequire any human-labeled data or fixed attribute list as supervision.\nSTRUM-LLM attributes all extractions back to the input sources along with\ntextual evidence, and it does not have a limit on the length of input sources\nthat it can process. STRUM-LLM Distilled has 100x more throughput than the\nmodels with comparable performance while being 10x smaller. In this paper, we\nprovide extensive evaluations for our method and lay out future directions for\nour currently deployed system.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.19710v1",
    "published_date": "2024-03-25 18:32:44 UTC",
    "updated_date": "2024-03-25 18:32:44 UTC"
  },
  {
    "arxiv_id": "2403.17091v1",
    "title": "Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data",
    "authors": [
      "Zeyu Jia",
      "Alexander Rakhlin",
      "Ayush Sekhari",
      "Chen-Yu Wei"
    ],
    "abstract": "We revisit the problem of offline reinforcement learning with value function\nrealizability but without Bellman completeness. Previous work by Xie and Jiang\n(2021) and Foster et al. (2022) left open the question whether a bounded\nconcentrability coefficient along with trajectory-based offline data admits a\npolynomial sample complexity. In this work, we provide a negative answer to\nthis question for the task of offline policy evaluation. In addition to\naddressing this question, we provide a rather complete picture for offline\npolicy evaluation with only value function realizability. Our primary findings\nare threefold: 1) The sample complexity of offline policy evaluation is\ngoverned by the concentrability coefficient in an aggregated Markov Transition\nModel jointly determined by the function class and the offline data\ndistribution, rather than that in the original MDP. This unifies and\ngeneralizes the ideas of Xie and Jiang (2021) and Foster et al. (2022), 2) The\nconcentrability coefficient in the aggregated Markov Transition Model may grow\nexponentially with the horizon length, even when the concentrability\ncoefficient in the original MDP is small and the offline data is admissible\n(i.e., the data distribution equals the occupancy measure of some policy), 3)\nUnder value function realizability, there is a generic reduction that can\nconvert any hard instance with admissible data to a hard instance with\ntrajectory data, implying that trajectory data offers no extra benefits over\nadmissible data. These three pieces jointly resolve the open problem, though\neach of them could be of independent interest.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17091v1",
    "published_date": "2024-03-25 18:28:45 UTC",
    "updated_date": "2024-03-25 18:28:45 UTC"
  },
  {
    "arxiv_id": "2403.17089v2",
    "title": "GOLF: Goal-Oriented Long-term liFe tasks supported by human-AI collaboration",
    "authors": [
      "Ben Wang"
    ],
    "abstract": "The advent of ChatGPT and similar large language models (LLMs) has\nrevolutionized the human-AI interaction and information-seeking process.\nLeveraging LLMs as an alternative to search engines, users can now access\nsummarized information tailored to their queries, significantly reducing the\ncognitive load associated with navigating vast information resources. This\nshift underscores the potential of LLMs in redefining information access\nparadigms. Drawing on the foundation of task-focused information retrieval and\nLLMs' task planning ability, this research extends the scope of LLM\ncapabilities beyond routine task automation to support users in navigating\nlong-term and significant life tasks. It introduces the GOLF framework\n(Goal-Oriented Long-term liFe tasks), which focuses on enhancing LLMs' ability\nto assist in significant life decisions through goal orientation and long-term\nplanning. The methodology encompasses a comprehensive simulation study to test\nthe framework's efficacy, followed by model and human evaluations to develop a\ndataset benchmark for long-term life tasks, and experiments across different\nmodels and settings. By shifting the focus from short-term tasks to the broader\nspectrum of long-term life goals, this research underscores the transformative\npotential of LLMs in enhancing human decision-making processes and task\nmanagement, marking a significant step forward in the evolution of human-AI\ncollaboration.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17089v2",
    "published_date": "2024-03-25 18:25:10 UTC",
    "updated_date": "2024-04-17 15:00:58 UTC"
  },
  {
    "arxiv_id": "2403.17083v2",
    "title": "A Study in Dataset Pruning for Image Super-Resolution",
    "authors": [
      "Brian B. Moser",
      "Federico Raue",
      "Andreas Dengel"
    ],
    "abstract": "In image Super-Resolution (SR), relying on large datasets for training is a\ndouble-edged sword. While offering rich training material, they also demand\nsubstantial computational and storage resources. In this work, we analyze\ndataset pruning to solve these challenges. We introduce a novel approach that\nreduces a dataset to a core-set of training samples, selected based on their\nloss values as determined by a simple pre-trained SR model. By focusing the\ntraining on just 50\\% of the original dataset, specifically on the samples\ncharacterized by the highest loss values, we achieve results comparable to or\nsurpassing those obtained from training on the entire dataset. Interestingly,\nour analysis reveals that the top 5\\% of samples with the highest loss values\nnegatively affect the training process. Excluding these samples and adjusting\nthe selection to favor easier samples further enhances training outcomes. Our\nwork opens new perspectives to the untapped potential of dataset pruning in\nimage SR. It suggests that careful selection of training data based on\nloss-value metrics can lead to better SR models, challenging the conventional\nwisdom that more data inevitably leads to better performance.",
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "eess.IV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17083v2",
    "published_date": "2024-03-25 18:16:34 UTC",
    "updated_date": "2024-06-08 07:53:16 UTC"
  },
  {
    "arxiv_id": "2403.17064v2",
    "title": "Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions",
    "authors": [
      "Stefan Andreas Baumann",
      "Felix Krause",
      "Michael Neumayr",
      "Nick Stracke",
      "Melvin Sevi",
      "Vincent Tao Hu",
      "Björn Ommer"
    ],
    "abstract": "Recent advances in text-to-image (T2I) diffusion models have significantly\nimproved the quality of generated images. However, providing efficient control\nover individual subjects, particularly the attributes characterizing them,\nremains a key challenge. While existing methods have introduced mechanisms to\nmodulate attribute expression, they typically provide either detailed,\nobject-specific localization of such a modification or full-scale fine-grained,\nnuanced control of attributes. No current approach offers both simultaneously,\nresulting in a gap when trying to achieve precise continuous and\nsubject-specific attribute modulation in image generation. In this work, we\ndemonstrate that token-level directions exist within commonly used CLIP text\nembeddings that enable fine-grained, subject-specific control of high-level\nattributes in T2I models. We introduce two methods to identify these\ndirections: a simple, optimization-free technique and a learning-based approach\nthat utilizes the T2I model to characterize semantic concepts more\nspecifically. Our methods allow the augmentation of the prompt text input,\nenabling fine-grained control over multiple attributes of individual subjects\nsimultaneously, without requiring any modifications to the diffusion model\nitself. This approach offers a unified solution that fills the gap between\nglobal and localized control, providing competitive flexibility and precision\nin text-guided image generation. Project page:\nhttps://compvis.github.io/attribute-control. Code is available at\nhttps://github.com/CompVis/attribute-control.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "CVPR 2025. Project page: https://compvis.github.io/attribute-control",
    "pdf_url": "http://arxiv.org/pdf/2403.17064v2",
    "published_date": "2024-03-25 18:00:42 UTC",
    "updated_date": "2025-03-14 11:33:08 UTC"
  },
  {
    "arxiv_id": "2403.16995v1",
    "title": "Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows",
    "authors": [
      "Shujian Zhang",
      "Lemeng Wu",
      "Chengyue Gong",
      "Xingchao Liu"
    ],
    "abstract": "Recent works have demonstrated success in controlling sentence attributes\n($e.g.$, sentiment) and structure ($e.g.$, syntactic structure) based on the\ndiffusion language model. A key component that drives theimpressive performance\nfor generating high-quality samples from noise is iteratively denoise for\nthousands of steps. While beneficial, the complexity of starting from the noise\nand the learning steps has limited its implementation to many NLP real-world\napplications. This paper proposes Language Rectified Flow ({\\ours}). Our method\nis based on the reformulation of the standard probabilistic flow models.\nLanguage rectified flow learns (neural) ordinary differential equation models\nto transport between the source distribution and the target distribution, hence\nproviding a unified and effective solution to generative modeling and domain\ntransfer. From the source distribution, our language rectified flow yields fast\nsimulation and effectively decreases the inference time. Experiments on three\nchallenging fine-grained control tasks and multiple high-quality text editing\nshow that our method consistently outperforms its baselines. Extensive\nexperiments and ablation studies demonstrate that our method can be general,\neffective, and beneficial for many NLP tasks.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "stat.ML"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16995v1",
    "published_date": "2024-03-25 17:58:22 UTC",
    "updated_date": "2024-03-25 17:58:22 UTC"
  },
  {
    "arxiv_id": "2403.16990v1",
    "title": "Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation",
    "authors": [
      "Omer Dahary",
      "Or Patashnik",
      "Kfir Aberman",
      "Daniel Cohen-Or"
    ],
    "abstract": "Text-to-image diffusion models have an unprecedented ability to generate\ndiverse and high-quality images. However, they often struggle to faithfully\ncapture the intended semantics of complex input prompts that include multiple\nsubjects. Recently, numerous layout-to-image extensions have been introduced to\nimprove user control, aiming to localize subjects represented by specific\ntokens. Yet, these methods often produce semantically inaccurate images,\nespecially when dealing with multiple semantically or visually similar\nsubjects. In this work, we study and analyze the causes of these limitations.\nOur exploration reveals that the primary issue stems from inadvertent semantic\nleakage between subjects in the denoising process. This leakage is attributed\nto the diffusion model's attention layers, which tend to blend the visual\nfeatures of different subjects. To address these issues, we introduce Bounded\nAttention, a training-free method for bounding the information flow in the\nsampling process. Bounded Attention prevents detrimental leakage among subjects\nand enables guiding the generation to promote each subject's individuality,\neven with complex multi-subject conditioning. Through extensive\nexperimentation, we demonstrate that our method empowers the generation of\nmultiple subjects that better align with given prompts and layouts.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "Project page: https://omer11a.github.io/bounded-attention/",
    "pdf_url": "http://arxiv.org/pdf/2403.16990v1",
    "published_date": "2024-03-25 17:52:07 UTC",
    "updated_date": "2024-03-25 17:52:07 UTC"
  },
  {
    "arxiv_id": "2403.16984v2",
    "title": "Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings",
    "authors": [
      "Hanane Kteich",
      "Na Li",
      "Usashi Chatterjee",
      "Zied Bouraoui",
      "Steven Schockaert"
    ],
    "abstract": "Concept embeddings offer a practical and efficient mechanism for injecting\ncommonsense knowledge into downstream tasks. Their core purpose is often not to\npredict the commonsense properties of concepts themselves, but rather to\nidentify commonalities, i.e.\\ sets of concepts which share some property of\ninterest. Such commonalities are the basis for inductive generalisation, hence\nhigh-quality concept embeddings can make learning easier and more robust.\nUnfortunately, standard embeddings primarily reflect basic taxonomic\ncategories, making them unsuitable for finding commonalities that refer to more\nspecific aspects (e.g.\\ the colour of objects or the materials they are made\nof). In this paper, we address this limitation by explicitly modelling the\ndifferent facets of interest when learning concept embeddings. We show that\nthis leads to embeddings which capture a more diverse range of commonsense\nproperties, and consistently improves results in downstream tasks such as\nultra-fine entity typing and ontology completion.",
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16984v2",
    "published_date": "2024-03-25 17:44:45 UTC",
    "updated_date": "2024-06-04 21:36:42 UTC"
  },
  {
    "arxiv_id": "2403.16973v3",
    "title": "VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild",
    "authors": [
      "Puyuan Peng",
      "Po-Yao Huang",
      "Shang-Wen Li",
      "Abdelrahman Mohamed",
      "David Harwath"
    ],
    "abstract": "We introduce VoiceCraft, a token infilling neural codec language model, that\nachieves state-of-the-art performance on both speech editing and zero-shot\ntext-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft\nemploys a Transformer decoder architecture and introduces a token rearrangement\nprocedure that combines causal masking and delayed stacking to enable\ngeneration within an existing sequence. On speech editing tasks, VoiceCraft\nproduces edited speech that is nearly indistinguishable from unedited\nrecordings in terms of naturalness, as evaluated by humans; for zero-shot TTS,\nour model outperforms prior SotA models including VALLE and the popular\ncommercial model XTTS-v2. Crucially, the models are evaluated on challenging\nand realistic datasets, that consist of diverse accents, speaking styles,\nrecording conditions, and background noise and music, and our model performs\nconsistently well compared to other models and real recordings. In particular,\nfor speech editing evaluation, we introduce a high quality, challenging, and\nrealistic dataset named RealEdit. We encourage readers to listen to the demos\nat https://jasonppy.github.io/VoiceCraft_web.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SD"
    ],
    "primary_category": "eess.AS",
    "comment": "ACL 2024. Data, code, and model weights are available at\n  https://github.com/jasonppy/VoiceCraft",
    "pdf_url": "http://arxiv.org/pdf/2403.16973v3",
    "published_date": "2024-03-25 17:38:32 UTC",
    "updated_date": "2024-06-14 00:29:46 UTC"
  },
  {
    "arxiv_id": "2403.16971v4",
    "title": "AIOS: LLM Agent Operating System",
    "authors": [
      "Kai Mei",
      "Xi Zhu",
      "Wujiang Xu",
      "Wenyue Hua",
      "Mingyu Jin",
      "Zelong Li",
      "Shuyuan Xu",
      "Ruosong Ye",
      "Yingqiang Ge",
      "Yongfeng Zhang"
    ],
    "abstract": "LLM-based intelligent agents face significant deployment challenges,\nparticularly related to resource management. Allowing unrestricted access to\nLLM or tool resources can lead to inefficient or even potentially harmful\nresource allocation and utilization for agents. Furthermore, the absence of\nproper scheduling and resource management mechanisms in current agent designs\nhinders concurrent processing and limits overall system efficiency. As the\ndiversity and complexity of agents continue to grow, addressing these resource\nmanagement issues becomes increasingly critical to LLM-based agent systems. To\naddress these challenges, this paper proposes the architecture of AIOS\n(LLM-based AI Agent Operating System) under the context of managing LLM-based\nagents. It introduces a novel architecture for serving LLM-based agents by\nisolating resources and LLM-specific services from agent applications into an\nAIOS kernel. This AIOS kernel provides fundamental services (e.g., scheduling,\ncontext management, memory management, storage management, access control) and\nefficient management of resources (e.g., LLM and external tools) for runtime\nagents. To enhance usability, AIOS also includes an AIOS-Agent SDK, a\ncomprehensive suite of APIs designed for utilizing functionalities provided by\nthe AIOS kernel. Experimental results demonstrate that using AIOS can achieve\nup to 2.1x faster execution for serving agents built by various agent\nframeworks. The source code is available at\nhttps://github.com/agiresearch/AIOS.",
    "categories": [
      "cs.OS",
      "cs.AI",
      "cs.CL"
    ],
    "primary_category": "cs.OS",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16971v4",
    "published_date": "2024-03-25 17:32:23 UTC",
    "updated_date": "2025-05-11 20:23:45 UTC"
  },
  {
    "arxiv_id": "2404.00051v1",
    "title": "Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal Knowledge Graph Reasoning",
    "authors": [
      "Miao Peng",
      "Ben Liu",
      "Wenjie Xu",
      "Zihao Jiang",
      "Jiahui Zhu",
      "Min Peng"
    ],
    "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the task of inferring missing\nfacts for incomplete TKGs in complex scenarios (e.g., transductive and\ninductive settings), which has been gaining increasing attention. Recently, to\nmitigate dependence on structured connections in TKGs, text-based methods have\nbeen developed to utilize rich linguistic information from entity descriptions.\nHowever, suffering from the enormous parameters and inflexibility of\npre-trained language models, existing text-based methods struggle to balance\nthe textual knowledge and temporal information with computationally expensive\npurpose-built training strategies. To tap the potential of text-based models\nfor TKGR in various complex scenarios, we propose ChapTER, a Contrastive\nhistorical modeling framework with prefix-tuning for TEmporal Reasoning.\nChapTER feeds history-contextualized text into the pseudo-Siamese encoders to\nstrike a textual-temporal balance via contrastive estimation between queries\nand candidates. By introducing virtual time prefix tokens, it applies a\nprefix-based tuning method to facilitate the frozen PLM capable for TKGR tasks\nunder different settings. We evaluate ChapTER on four transductive and three\nfew-shot inductive TKGR benchmarks, and experimental results demonstrate that\nChapTER achieves superior performance compared to competitive baselines with\nonly 0.17% tuned parameters. We conduct thorough analysis to verify the\neffectiveness, flexibility and efficiency of ChapTER.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to NAACL 2024 Findings",
    "pdf_url": "http://arxiv.org/pdf/2404.00051v1",
    "published_date": "2024-03-25 17:25:40 UTC",
    "updated_date": "2024-03-25 17:25:40 UTC"
  },
  {
    "arxiv_id": "2403.19709v1",
    "title": "Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models",
    "authors": [
      "Tsendsuren Munkhdalai",
      "Youzheng Chen",
      "Khe Chai Sim",
      "Fadi Biadsy",
      "Tara Sainath",
      "Pedro Moreno Mengibar"
    ],
    "abstract": "Parameter efficient adaptation methods have become a key mechanism to train\nlarge pre-trained models for downstream tasks. However, their per-task\nparameter overhead is considered still high when the number of downstream tasks\nto adapt for is large. We introduce an adapter module that has a better\nefficiency in large scale multi-task adaptation scenario. Our adapter is\nhierarchical in terms of how the adapter parameters are allocated. The adapter\nconsists of a single shared controller network and multiple task-level adapter\nheads to reduce the per-task parameter overhead without performance regression\non downstream tasks. The adapter is also recurrent so the entire adapter\nparameters are reused across different layers of the pre-trained model. Our\nHierarchical Recurrent Adapter (HRA) outperforms the previous adapter-based\napproaches as well as full model fine-tuning baseline in both single and\nmulti-task adaptation settings when evaluated on automatic speech recognition\ntasks.",
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "eess.AS",
    "comment": "5 pages, 3 figures, 5 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.19709v1",
    "published_date": "2024-03-25 17:21:56 UTC",
    "updated_date": "2024-03-25 17:21:56 UTC"
  },
  {
    "arxiv_id": "2403.16952v2",
    "title": "Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance",
    "authors": [
      "Jiasheng Ye",
      "Peiju Liu",
      "Tianxiang Sun",
      "Jun Zhan",
      "Yunhua Zhou",
      "Xipeng Qiu"
    ],
    "abstract": "Pretraining data of large language models composes multiple domains (e.g.,\nweb texts, academic papers, codes), whose mixture proportions crucially impact\nthe competence of outcome models. While existing endeavors rely on heuristics\nor qualitative strategies to tune the proportions, we discover the quantitative\npredictability of model performance regarding the mixture proportions in\nfunction forms, which we refer to as the data mixing laws. Fitting such\nfunctions on sample mixtures unveils model performance on unseen mixtures\nbefore actual runs, thus guiding the selection of an ideal data mixture.\nFurthermore, we propose nested use of the scaling laws of training steps, model\nsizes, and our data mixing law to enable predicting the performance of large\nmodels trained on massive data under various mixtures with only small-scale\ntraining. Moreover, experimental results verify that our method effectively\noptimizes the training mixture of a 1B model trained for 100B tokens in\nRedPajama, reaching a performance comparable to the one trained for 48% more\nsteps on the default mixture. Extending the application of data mixing laws to\ncontinual training accurately predicts the critical mixture proportion that\navoids catastrophic forgetting and outlooks the potential for dynamic data\nschedules",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "accepted by ICLR2025, camera ready version",
    "pdf_url": "http://arxiv.org/pdf/2403.16952v2",
    "published_date": "2024-03-25 17:14:00 UTC",
    "updated_date": "2025-03-20 03:31:27 UTC"
  },
  {
    "arxiv_id": "2403.16950v5",
    "title": "Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators",
    "authors": [
      "Yinhong Liu",
      "Han Zhou",
      "Zhijiang Guo",
      "Ehsan Shareghi",
      "Ivan Vulić",
      "Anna Korhonen",
      "Nigel Collier"
    ],
    "abstract": "Large Language Models (LLMs) have demonstrated promising capabilities as\nautomatic evaluators in assessing the quality of generated natural language.\nHowever, LLMs still exhibit biases in evaluation and often struggle to generate\ncoherent evaluations that align with human assessments. In this work, we first\nconduct a systematic study of the misalignment between LLM evaluators and human\nevaluation, revealing that existing calibration methods aimed at mitigating\nbiases of LLMs are insufficient for effectively aligning LLM evaluators.\nInspired by the use of preference data in RLHF, we formulate the evaluation as\na ranking problem and introduce Pairwise-preference Search (PAIRS), an\nuncertainty-guided search-based rank aggregation method that employs LLMs to\nconduct pairwise comparisons locally and efficiently ranks candidate texts\nglobally. PAIRS achieves state-of-the-art performance on representative\nevaluation tasks in long-form generations and demonstrates significant\nimprovements over direct scoring. Furthermore, we provide insights into the\nrole of pairwise preference in quantifying the transitivity of LLMs and\ndemonstrate how PAIRS benefits from calibration using debiased pairwise\nevaluations.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "This paper has been accepted by COLM 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16950v5",
    "published_date": "2024-03-25 17:11:28 UTC",
    "updated_date": "2025-01-17 03:43:53 UTC"
  },
  {
    "arxiv_id": "2403.16941v1",
    "title": "SPACE-IDEAS: A Dataset for Salient Information Detection in Space Innovation",
    "authors": [
      "Andrés García-Silva",
      "Cristian Berrío",
      "José Manuel Gómez-Pérez"
    ],
    "abstract": "Detecting salient parts in text using natural language processing has been\nwidely used to mitigate the effects of information overflow. Nevertheless, most\nof the datasets available for this task are derived mainly from academic\npublications. We introduce SPACE-IDEAS, a dataset for salient information\ndetection from innovation ideas related to the Space domain. The text in\nSPACE-IDEAS varies greatly and includes informal, technical, academic and\nbusiness-oriented writing styles. In addition to a manually annotated dataset\nwe release an extended version that is annotated using a large generative\nlanguage model. We train different sentence and sequential sentence\nclassifiers, and show that the automatically annotated dataset can be leveraged\nusing multitask learning to train better classifiers.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.DL"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted in LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16941v1",
    "published_date": "2024-03-25 17:04:02 UTC",
    "updated_date": "2024-03-25 17:04:02 UTC"
  },
  {
    "arxiv_id": "2403.16933v3",
    "title": "Backpropagation through space, time, and the brain",
    "authors": [
      "Benjamin Ellenberger",
      "Paul Haider",
      "Jakob Jordan",
      "Kevin Max",
      "Ismael Jaras",
      "Laura Kriener",
      "Federico Benitez",
      "Mihai A. Petrovici"
    ],
    "abstract": "How physical networks of neurons, bound by spatio-temporal locality\nconstraints, can perform efficient credit assignment, remains, to a large\nextent, an open question. In machine learning, the answer is almost universally\ngiven by the error backpropagation algorithm, through both space and time.\nHowever, this algorithm is well-known to rely on biologically implausible\nassumptions, in particular with respect to spatio-temporal (non-)locality.\nAlternative forward-propagation models such as real-time recurrent learning\nonly partially solve the locality problem, but only at the cost of scaling, due\nto prohibitive storage requirements. We introduce Generalized Latent\nEquilibrium (GLE), a computational framework for fully local spatio-temporal\ncredit assignment in physical, dynamical networks of neurons. We start by\ndefining an energy based on neuron-local mismatches, from which we derive both\nneuronal dynamics via stationarity and parameter dynamics via gradient descent.\nThe resulting dynamics can be interpreted as a real-time, biologically\nplausible approximation of backpropagation through space and time in deep\ncortical networks with continuous-time neuronal dynamics and continuously\nactive, local synaptic plasticity. In particular, GLE exploits the morphology\nof dendritic trees to enable more complex information storage and processing in\nsingle neurons, as well as the ability of biological neurons to phase-shift\ntheir output rate with respect to their membrane potential, which is essential\nin both directions of information propagation. For the forward computation, it\nenables the mapping of time-continuous inputs to neuronal space, effectively\nperforming a spatio-temporal convolution. For the backward computation, it\npermits the temporal inversion of feedback signals, which consequently\napproximate the adjoint variables necessary for useful parameter updates.",
    "categories": [
      "q-bio.NC",
      "cs.AI",
      "cs.LG",
      "cs.NE",
      "eess.SP"
    ],
    "primary_category": "q-bio.NC",
    "comment": "First authorship shared by Benjamin Ellenberger and Paul Haider",
    "pdf_url": "http://arxiv.org/pdf/2403.16933v3",
    "published_date": "2024-03-25 16:57:02 UTC",
    "updated_date": "2025-05-05 14:43:33 UTC"
  },
  {
    "arxiv_id": "2403.16915v3",
    "title": "Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models",
    "authors": [
      "Atsushi Keyaki",
      "Ribeka Keyaki"
    ],
    "abstract": "Fine-tuning in information retrieval systems using pre-trained language\nmodels (PLM-based IR) requires learning query representations and\nquery-document relations, in addition to downstream task-specific learning.\nThis study introduces coarse-tuning as an intermediate learning stage that\nbridges pre-training and fine-tuning. By learning query representations and\nquery-document relations in coarse-tuning, we aim to reduce the load of\nfine-tuning and improve the learning effect of downstream IR tasks. We propose\nQuery-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the\nappropriateness of query-document pairs. Evaluation experiments show that the\nproposed method significantly improves MRR and/or nDCG@5 in four ad-hoc\ndocument retrieval datasets. Furthermore, the results of the query prediction\ntask suggested that coarse-tuning facilitated learning of query representation\nand query-document relations.",
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.IR",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16915v3",
    "published_date": "2024-03-25 16:32:50 UTC",
    "updated_date": "2024-03-27 01:53:36 UTC"
  },
  {
    "arxiv_id": "2403.16909v1",
    "title": "Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data",
    "authors": [
      "Shinka Mori",
      "Oana Ignat",
      "Andrew Lee",
      "Rada Mihalcea"
    ],
    "abstract": "Synthetic data generation has the potential to impact applications and\ndomains with scarce data. However, before such data is used for sensitive tasks\nsuch as mental health, we need an understanding of how different demographics\nare represented in it. In our paper, we analyze the potential of producing\nsynthetic data using GPT-3 by exploring the various stressors it attributes to\ndifferent race and gender combinations, to provide insight for future\nresearchers looking into using LLMs for data generation. Using GPT-3, we\ndevelop HEADROOM, a synthetic dataset of 3,120 posts about\ndepression-triggering stressors, by controlling for race, gender, and time\nframe (before and after COVID-19). Using this dataset, we conduct semantic and\nlexical analyses to (1) identify the predominant stressors for each demographic\ngroup; and (2) compare our synthetic data to a human-generated dataset. We\npresent the procedures to generate queries to develop depression data using\nGPT-3, and conduct analyzes to uncover the types of stressors it assigns to\ndemographic groups, which could be used to test the limitations of LLMs for\nsynthetic data generation for depression data. Our findings show that synthetic\ndata mimics some of the human-generated data distribution for the predominant\ndepression stressors across diverse demographics.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CY"
    ],
    "primary_category": "cs.AI",
    "comment": "14 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.16909v1",
    "published_date": "2024-03-25 16:21:25 UTC",
    "updated_date": "2024-03-25 16:21:25 UTC"
  },
  {
    "arxiv_id": "2403.16908v1",
    "title": "Towards Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations",
    "authors": [
      "Nassim Belmecheri",
      "Arnaud Gotlieb",
      "Nadjib Lazaar",
      "Helge Spieker"
    ],
    "abstract": "Understanding driving scenes and communicating automated vehicle decisions\nare key requirements for trustworthy automated driving. In this article, we\nintroduce the Qualitative Explainable Graph (QXG), which is a unified symbolic\nand qualitative representation for scene understanding in urban mobility. The\nQXG enables interpreting an automated vehicle's environment using sensor data\nand machine learning models. It utilizes spatio-temporal graphs and qualitative\nconstraints to extract scene semantics from raw sensor inputs, such as LiDAR\nand camera data, offering an interpretable scene model. A QXG can be\nincrementally constructed in real-time, making it a versatile tool for\nin-vehicle explanations across various sensor types. Our research showcases the\npotential of QXG, particularly in the context of automated driving, where it\ncan rationalize decisions by linking the graph with observed actions. These\nexplanations can serve diverse purposes, from informing passengers and alerting\nvulnerable road users to enabling post-hoc analysis of prior behaviors.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "SAE International Journal of Connected and Automated Vehicles",
    "pdf_url": "http://arxiv.org/pdf/2403.16908v1",
    "published_date": "2024-03-25 16:19:33 UTC",
    "updated_date": "2024-03-25 16:19:33 UTC"
  },
  {
    "arxiv_id": "2403.16904v1",
    "title": "Multi-Agent Optimization for Safety Analysis of Cyber-Physical Systems: Position Paper",
    "authors": [
      "Önder Gürcan",
      "Nataliya Yakymets",
      "Sara Tucci-Piergiovanni",
      "Ansgar Radermacher"
    ],
    "abstract": "Failure Mode, Effects and Criticality Analysis (FMECA) is one of the safety\nanalysis methods recommended by most of the international standards. The\nclassical FMECA is made in a form of a table filled in either manually or by\nusing safety analysis tools. In both cases, the design engineers have to choose\nthe trade-offs between safety and other development constraints. In the case of\ncomplex cyber-physical systems (CPS) with thousands of specified constraints,\nthis may lead to severe problems and significantly impact the overall\ncriticality of CPS. In this paper, we propose to adopt optimization techniques\nto automate the decision making process conducted after FMECA of CPS. We\ndescribe a multi-agent based optimization method which extends classical FMECA\nfor offering optimal solutions in terms of criticality and development\nconstraints of CPS.",
    "categories": [
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 2 figures, 1 table, \"2nd International Workshop on Emerging\n  Ideas and Trends in Engineering of Cyber-Physical Systems, part of\n  Cyber-Physical Systems Week, April 2015, Seattle, USA\"",
    "pdf_url": "http://arxiv.org/pdf/2403.16904v1",
    "published_date": "2024-03-25 16:14:45 UTC",
    "updated_date": "2024-03-25 16:14:45 UTC"
  },
  {
    "arxiv_id": "2403.16903v1",
    "title": "Towards Secure and Trusted-by-Design Smart Contracts",
    "authors": [
      "Zaynah Dargaye",
      "Önder Gürcan",
      "Florent Kirchner",
      "Sara Tucci-Piergiovanni"
    ],
    "abstract": "Distributed immutable ledgers, or blockchains, allow the secure digitization\nof evidential transactions without relying on a trusted third-party. Evidential\ntransactions involve the exchange of any form of physical evidence, such as\nmoney, birth certificate, visas, tickets, etc. Most of the time, evidential\ntransactions occur in the context of complex procedures, called evidential\nprotocols, among physical agents. The blockchain provides the mechanisms to\ntransfer evidence, while smart contracts - programs executing within the\nblockchain in a decentralized and replicated fashion - allow encoding\nevidential protocols on top of a blockchain.\n  As a smart contract foregoes trusted third-parties and runs on several\nmachines anonymously, it constitutes a highly critical program that has to be\nsecure and trusted-by-design. While most of the current smart contract\nlanguages focus on easy programmability, they do not directly address the need\nof guaranteeing trust and accountability, which becomes a significant issue\nwhen evidential protocols are encoded as smart contracts.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.CR",
    "comment": "17 pages, 1 algorithm, The 29th Francophone Days of Application\n  Languages - JFLA 2018",
    "pdf_url": "http://arxiv.org/pdf/2403.16903v1",
    "published_date": "2024-03-25 16:14:22 UTC",
    "updated_date": "2024-03-25 16:14:22 UTC"
  },
  {
    "arxiv_id": "2403.16895v1",
    "title": "\"It is there, and you need it, so why do you not use it?\" Achieving better adoption of AI systems by domain experts, in the case study of natural science research",
    "authors": [
      "Auste Simkute",
      "Ewa Luger",
      "Michael Evans",
      "Rhianne Jones"
    ],
    "abstract": "Artificial Intelligence (AI) is becoming ubiquitous in domains such as\nmedicine and natural science research. However, when AI systems are implemented\nin practice, domain experts often refuse them. Low acceptance hinders effective\nhuman-AI collaboration, even when it is essential for progress. In natural\nscience research, scientists' ineffective use of AI-enabled systems can impede\nthem from analysing their data and advancing their research. We conducted an\nethnographically informed study of 10 in-depth interviews with AI practitioners\nand natural scientists at the organisation facing low adoption of algorithmic\nsystems. Results were consolidated into recommendations for better AI adoption:\ni) actively supporting experts during the initial stages of system use, ii)\ncommunicating the capabilities of a system in a user-relevant way, and iii)\nfollowing predefined collaboration rules. We discuss the broader implications\nof our findings and expand on how our proposed requirements could support\npractitioners and experts across domains.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16895v1",
    "published_date": "2024-03-25 16:06:31 UTC",
    "updated_date": "2024-03-25 16:06:31 UTC"
  },
  {
    "arxiv_id": "2403.16877v2",
    "title": "Proprioception Is All You Need: Terrain Classification for Boreal Forests",
    "authors": [
      "Damien LaRocque",
      "William Guimont-Martin",
      "David-Alexandre Duclos",
      "Philippe Giguère",
      "François Pomerleau"
    ],
    "abstract": "Recent works in field robotics highlighted the importance of resiliency\nagainst different types of terrains. Boreal forests, in particular, are home to\nmany mobility-impeding terrains that should be considered for off-road\nautonomous navigation. Also, being one of the largest land biomes on Earth,\nboreal forests are an area where autonomous vehicles are expected to become\nincreasingly common. In this paper, we address this issue by introducing\nBorealTC, a publicly available dataset for proprioceptive-based terrain\nclassification (TC). Recorded with a Husky A200, our dataset contains 116 min\nof Inertial Measurement Unit (IMU), motor current, and wheel odometry data,\nfocusing on typical boreal forest terrains, notably snow, ice, and silty loam.\nCombining our dataset with another dataset from the state-of-the-art, we\nevaluate both a Convolutional Neural Network (CNN) and the novel state space\nmodel (SSM)-based Mamba architecture on a TC task. Interestingly, we show that\nwhile CNN outperforms Mamba on each separate dataset, Mamba achieves greater\naccuracy when trained on a combination of both. In addition, we demonstrate\nthat Mamba's learning capacity is greater than a CNN for increasing amounts of\ndata. We show that the combination of two TC datasets yields a latent space\nthat can be interpreted with the properties of the terrains. We also discuss\nthe implications of merging datasets on classification. Our source code and\ndataset are publicly available online:\nhttps://github.com/norlab-ulaval/BorealTC.",
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "primary_category": "cs.RO",
    "comment": "Accepted to the 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.16877v2",
    "published_date": "2024-03-25 15:42:09 UTC",
    "updated_date": "2024-09-27 17:14:26 UTC"
  },
  {
    "arxiv_id": "2404.03673v2",
    "title": "RL for Consistency Models: Faster Reward Guided Text-to-Image Generation",
    "authors": [
      "Owen Oertell",
      "Jonathan D. Chang",
      "Yiyi Zhang",
      "Kianté Brantley",
      "Wen Sun"
    ],
    "abstract": "Reinforcement learning (RL) has improved guided image generation with\ndiffusion models by directly optimizing rewards that capture image quality,\naesthetics, and instruction following capabilities. However, the resulting\ngenerative policies inherit the same iterative sampling process of diffusion\nmodels that causes slow generation. To overcome this limitation, consistency\nmodels proposed learning a new class of generative models that directly map\nnoise to data, resulting in a model that can generate an image in as few as one\nsampling iteration. In this work, to optimize text-to-image generative models\nfor task specific rewards and enable fast training and inference, we propose a\nframework for fine-tuning consistency models via RL. Our framework, called\nReinforcement Learning for Consistency Model (RLCM), frames the iterative\ninference process of a consistency model as an RL procedure. Comparing to RL\nfinetuned diffusion models, RLCM trains significantly faster, improves the\nquality of the generation measured under the reward objectives, and speeds up\nthe inference procedure by generating high quality images with as few as two\ninference steps. Experimentally, we show that RLCM can adapt text-to-image\nconsistency models to objectives that are challenging to express with\nprompting, such as image compressibility, and those derived from human\nfeedback, such as aesthetic quality. Our code is available at\nhttps://rlcm.owenoertell.com.",
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CV",
    "comment": "18 pages, 9 figures, 1 table",
    "pdf_url": "http://arxiv.org/pdf/2404.03673v2",
    "published_date": "2024-03-25 15:40:22 UTC",
    "updated_date": "2024-06-22 08:07:39 UTC"
  },
  {
    "arxiv_id": "2403.16863v1",
    "title": "SIP: Autotuning GPU Native Schedules via Stochastic Instruction Perturbation",
    "authors": [
      "Guoliang He",
      "Eiko Yoneki"
    ],
    "abstract": "Large language models (LLMs) have become a significant workload since their\nappearance. However, they are also computationally expensive as they have\nbillions of parameters and are trained with massive amounts of data. Thus,\nrecent works have developed dedicated CUDA kernels for LLM training and\ninference instead of relying on compilergenerated ones, so that hardware\nresources are as fully utilized as possible. In this work, we explore the\npossibility of GPU native instruction optimization to further push the CUDA\nkernels to extreme performance. Contrary to prior works, we adopt an automatic\noptimization approach by defining a search space of possible GPU native\ninstruction schedules, and then we apply stochastic search to perform\noptimization. Experiments show that SIP can further improve CUDA kernel\nthroughput by automatically discovering better GPU native instruction schedules\nand the optimized schedules are tested by 10 million test samples.",
    "categories": [
      "cs.AR",
      "cs.AI"
    ],
    "primary_category": "cs.AR",
    "comment": "EuroMLSys 24, April 22, 2024, Athens, Greece",
    "pdf_url": "http://arxiv.org/pdf/2403.16863v1",
    "published_date": "2024-03-25 15:26:50 UTC",
    "updated_date": "2024-03-25 15:26:50 UTC"
  },
  {
    "arxiv_id": "2404.07969v1",
    "title": "An End-to-End Structure with Novel Position Mechanism and Improved EMD for Stock Forecasting",
    "authors": [
      "Chufeng Li",
      "Jianyong Chen"
    ],
    "abstract": "As a branch of time series forecasting, stock movement forecasting is one of\nthe challenging problems for investors and researchers. Since Transformer was\nintroduced to analyze financial data, many researchers have dedicated\nthemselves to forecasting stock movement using Transformer or attention\nmechanisms. However, existing research mostly focuses on individual stock\ninformation but ignores stock market information and high noise in stock data.\nIn this paper, we propose a novel method using the attention mechanism in which\nboth stock market information and individual stock information are considered.\nMeanwhile, we propose a novel EMD-based algorithm for reducing short-term noise\nin stock data. Two randomly selected exchange-traded funds (ETFs) spanning over\nten years from US stock markets are used to demonstrate the superior\nperformance of the proposed attention-based method. The experimental analysis\ndemonstrates that the proposed attention-based method significantly outperforms\nother state-of-the-art baselines. Code is available at\nhttps://github.com/DurandalLee/ACEFormer.",
    "categories": [
      "q-fin.ST",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "q-fin.ST",
    "comment": "ICONIP 2023",
    "pdf_url": "http://arxiv.org/pdf/2404.07969v1",
    "published_date": "2024-03-25 15:23:22 UTC",
    "updated_date": "2024-03-25 15:23:22 UTC"
  },
  {
    "arxiv_id": "2403.16858v1",
    "title": "XAIport: A Service Framework for the Early Adoption of XAI in AI Model Development",
    "authors": [
      "Zerui Wang",
      "Yan Liu",
      "Abishek Arumugam Thiruselvi",
      "Abdelwahab Hamou-Lhadj"
    ],
    "abstract": "In this study, we propose the early adoption of Explainable AI (XAI) with a\nfocus on three properties: Quality of explanation, the explanation summaries\nshould be consistent across multiple XAI methods; Architectural Compatibility,\nfor effective integration in XAI, the architecture styles of both the XAI\nmethods and the models to be explained must be compatible with the framework;\nConfigurable operations, XAI explanations are operable, akin to machine\nlearning operations. Thus, an explanation for AI models should be reproducible\nand tractable to be trustworthy. We present XAIport, a framework of XAI\nmicroservices encapsulated into Open APIs to deliver early explanations as\nobservation for learning model quality assurance. XAIport enables configurable\nXAI operations along with machine learning development. We quantify the\noperational costs of incorporating XAI with three cloud computer vision\nservices on Microsoft Azure Cognitive Services, Google Cloud Vertex AI, and\nAmazon Rekognition. Our findings show comparable operational costs between XAI\nand traditional machine learning, with XAIport significantly improving both\ncloud AI model performance and explanation stability.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at the ICSE'24 conference, NIER track",
    "pdf_url": "http://arxiv.org/pdf/2403.16858v1",
    "published_date": "2024-03-25 15:22:06 UTC",
    "updated_date": "2024-03-25 15:22:06 UTC"
  },
  {
    "arxiv_id": "2403.16854v3",
    "title": "An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing",
    "authors": [
      "Ziwei Chai",
      "Guoyin Wang",
      "Jing Su",
      "Tianjie Zhang",
      "Xuanwen Huang",
      "Xuwu Wang",
      "Jingjing Xu",
      "Jianbo Yuan",
      "Hongxia Yang",
      "Fei Wu",
      "Yang Yang"
    ],
    "abstract": "We present Expert-Token-Routing, a unified generalist framework that\nfacilitates seamless integration of multiple expert LLMs. Our framework\nrepresents expert LLMs as special expert tokens within the vocabulary of a meta\nLLM. The meta LLM can route to an expert LLM like generating new tokens.\nExpert-Token-Routing not only supports learning the implicit expertise of\nexpert LLMs from existing instruction dataset but also allows for dynamic\nextension of new expert LLMs in a plug-and-play manner. It also conceals the\ndetailed collaboration process from the user's perspective, facilitating\ninteraction as though it were a singular LLM. Our framework outperforms various\nexisting multi-LLM collaboration paradigms across benchmarks that incorporate\nsix diverse expert domains, demonstrating effectiveness and robustness in\nbuilding generalist LLM system via synergizing multiple expert LLMs.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16854v3",
    "published_date": "2024-03-25 15:17:05 UTC",
    "updated_date": "2024-06-11 15:12:09 UTC"
  },
  {
    "arxiv_id": "2403.16852v2",
    "title": "Towards Explainability in Legal Outcome Prediction Models",
    "authors": [
      "Josef Valvoda",
      "Ryan Cotterell"
    ],
    "abstract": "Current legal outcome prediction models - a staple of legal NLP - do not\nexplain their reasoning. However, to employ these models in the real world,\nhuman legal actors need to be able to understand the model's decisions. In the\ncase of common law, legal practitioners reason towards the outcome of a case by\nreferring to past case law, known as precedent. We contend that precedent is,\ntherefore, a natural way of facilitating explainability for legal NLP models.\nIn this paper, we contribute a novel method for identifying the precedent\nemployed by legal outcome prediction models. Furthermore, by developing a\ntaxonomy of legal precedent, we are able to compare human judges and neural\nmodels with respect to the different types of precedent they rely on. We find\nthat while the models learn to predict outcomes reasonably well, their use of\nprecedent is unlike that of human judges.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16852v2",
    "published_date": "2024-03-25 15:15:41 UTC",
    "updated_date": "2024-04-16 03:53:28 UTC"
  },
  {
    "arxiv_id": "2403.16851v2",
    "title": "Can tweets predict article retractions? A comparison between human and LLM labelling",
    "authors": [
      "Er-Te Zheng",
      "Hui-Zhen Fu",
      "Mike Thelwall",
      "Zhichao Fang"
    ],
    "abstract": "Quickly detecting problematic research articles is crucial to safeguarding\nthe integrity of scientific research. This study explores whether Twitter\nmentions of retracted articles can signal potential problems with the articles\nprior to their retraction, potentially serving as an early warning system for\nscholars. To investigate this, we analysed a dataset of 4,354 Twitter mentions\nassociated with 504 retracted articles. The effectiveness of Twitter mentions\nin predicting article retractions was evaluated by both manual and Large\nLanguage Model (LLM) labelling. Manual labelling results indicated that 25.7%\nof tweets signalled problems before retraction. Using the manual labelling\nresults as the baseline, we found that LLMs (GPT-4o-mini, Gemini 1.5 Flash, and\nClaude-3.5-Haiku) outperformed lexicon-based sentiment analysis tools (e.g.,\nTextBlob) in detecting potential problems, suggesting that automatic detection\nof problematic articles from social media using LLMs is technically feasible.\nNevertheless, since only a small proportion of retracted articles (11.1%) were\ncriticised on Twitter prior to retraction, such automatic systems would detect\nonly a minority of problematic articles. Overall, this study offers insights\ninto how social media data, coupled with emerging generative AI techniques, can\nsupport research integrity.",
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.DL",
    "comment": "19 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.16851v2",
    "published_date": "2024-03-25 15:15:09 UTC",
    "updated_date": "2024-12-09 16:42:25 UTC"
  },
  {
    "arxiv_id": "2403.16846v1",
    "title": "GreeDy and CoDy: Counterfactual Explainers for Dynamic Graphs",
    "authors": [
      "Zhan Qu",
      "Daniel Gomm",
      "Michael Färber"
    ],
    "abstract": "Temporal Graph Neural Networks (TGNNs), crucial for modeling dynamic graphs\nwith time-varying interactions, face a significant challenge in explainability\ndue to their complex model structure. Counterfactual explanations, crucial for\nunderstanding model decisions, examine how input graph changes affect outcomes.\nThis paper introduces two novel counterfactual explanation methods for TGNNs:\nGreeDy (Greedy Explainer for Dynamic Graphs) and CoDy (Counterfactual Explainer\nfor Dynamic Graphs). They treat explanations as a search problem, seeking input\ngraph alterations that alter model predictions. GreeDy uses a simple, greedy\napproach, while CoDy employs a sophisticated Monte Carlo Tree Search algorithm.\nExperiments show both methods effectively generate clear explanations. Notably,\nCoDy outperforms GreeDy and existing factual methods, with up to 59\\% higher\nsuccess rate in finding significant counterfactual inputs. This highlights\nCoDy's potential in clarifying TGNN decision-making, increasing their\ntransparency and trustworthiness in practice.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16846v1",
    "published_date": "2024-03-25 15:07:50 UTC",
    "updated_date": "2024-03-25 15:07:50 UTC"
  },
  {
    "arxiv_id": "2403.16843v4",
    "title": "Do LLM Agents Have Regret? A Case Study in Online Learning and Games",
    "authors": [
      "Chanwoo Park",
      "Xiangyu Liu",
      "Asuman Ozdaglar",
      "Kaiqing Zhang"
    ],
    "abstract": "Large language models (LLMs) have been increasingly employed for\n(interactive) decision-making, via the development of LLM-based autonomous\nagents. Despite their emerging successes, the performance of LLM agents in\ndecision-making has not been fully investigated through quantitative metrics,\nespecially in the multi-agent setting when they interact with each other, a\ntypical scenario in real-world LLM-agent applications. To better understand the\nlimits of LLM agents in these interactive environments, we propose to study\ntheir interactions in benchmark decision-making settings in online learning and\ngame theory, through the performance metric of \\emph{regret}. We first\nempirically study the {no-regret} behaviors of LLMs in canonical\n(non-stationary) online learning problems, as well as the emergence of\nequilibria when LLM agents interact through playing repeated games. We then\nprovide some theoretical insights into the no-regret behaviors of LLM agents,\nunder certain assumptions on the supervised pre-training and the rationality\nmodel of human decision-makers who generate the data. Notably, we also identify\n(simple) cases where advanced LLMs such as GPT-4 fail to be no-regret. To\npromote the no-regret behaviors, we propose a novel \\emph{unsupervised}\ntraining loss of \\emph{regret-loss}, which, in contrast to the supervised\npre-training loss, does not require the labels of (optimal) actions. We then\nestablish the statistical guarantee of generalization bound for regret-loss\nminimization, followed by the optimization guarantee that minimizing such a\nloss may automatically lead to known no-regret learning algorithms. Our further\nexperiments demonstrate the effectiveness of our regret-loss, especially in\naddressing the above ``regrettable'' cases.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.GT"
    ],
    "primary_category": "cs.LG",
    "comment": "Camera ready version of ICLR 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.16843v4",
    "published_date": "2024-03-25 15:04:11 UTC",
    "updated_date": "2025-04-02 23:51:07 UTC"
  },
  {
    "arxiv_id": "2403.16831v3",
    "title": "UrbanVLP: Multi-Granularity Vision-Language Pretraining for Urban Socioeconomic Indicator Prediction",
    "authors": [
      "Xixuan Hao",
      "Wei Chen",
      "Yibo Yan",
      "Siru Zhong",
      "Kun Wang",
      "Qingsong Wen",
      "Yuxuan Liang"
    ],
    "abstract": "Urban socioeconomic indicator prediction aims to infer various metrics\nrelated to sustainable development in diverse urban landscapes using\ndata-driven methods. However, prevalent pretrained models, particularly those\nreliant on satellite imagery, face dual challenges. Firstly, concentrating\nsolely on macro-level patterns from satellite data may introduce bias, lacking\nnuanced details at micro levels, such as architectural details at a place.\nSecondly, the text generated by the precursor work UrbanCLIP, which fully\nutilizes the extensive knowledge of LLMs, frequently exhibits issues such as\nhallucination and homogenization, resulting in a lack of reliable quality. In\nresponse to these issues, we devise a novel framework entitled UrbanVLP based\non Vision-Language Pretraining. Our UrbanVLP seamlessly integrates\nmulti-granularity information from both macro (satellite) and micro\n(street-view) levels, overcoming the limitations of prior pretrained models.\nMoreover, it introduces automatic text generation and calibration, providing a\nrobust guarantee for producing high-quality text descriptions of urban imagery.\nRigorous experiments conducted across six socioeconomic indicator prediction\ntasks underscore its superior performance.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted as a full paper by AAAI'25 - AI for Social Impact Track",
    "pdf_url": "http://arxiv.org/pdf/2403.16831v3",
    "published_date": "2024-03-25 14:57:18 UTC",
    "updated_date": "2025-01-22 08:45:56 UTC"
  },
  {
    "arxiv_id": "2403.16829v3",
    "title": "Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm",
    "authors": [
      "Titouan Renard",
      "Andreas Schlaginhaufen",
      "Tingting Ni",
      "Maryam Kamgarpour"
    ],
    "abstract": "Given a dataset of expert demonstrations, inverse reinforcement learning\n(IRL) aims to recover a reward for which the expert is optimal. This work\nproposes a model-free algorithm to solve entropy-regularized IRL problem. In\nparticular, we employ a stochastic gradient descent update for the reward and a\nstochastic soft policy iteration update for the policy. Assuming access to a\ngenerative model, we prove that our algorithm is guaranteed to recover a reward\nfor which the expert is $\\varepsilon$-optimal using\n$\\mathcal{O}(1/\\varepsilon^{2})$ samples of the Markov decision process (MDP).\nFurthermore, with $\\mathcal{O}(1/\\varepsilon^{4})$ samples we prove that the\noptimal policy corresponding to the recovered reward is $\\varepsilon$-close to\nthe expert policy in total variation distance.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16829v3",
    "published_date": "2024-03-25 14:54:42 UTC",
    "updated_date": "2025-03-03 18:01:44 UTC"
  },
  {
    "arxiv_id": "2403.16824v1",
    "title": "On Policy Reuse: An Expressive Language for Representing and Executing General Policies that Call Other Policies",
    "authors": [
      "Blai Bonet",
      "Dominik Drexler",
      "Hector Geffner"
    ],
    "abstract": "Recently, a simple but powerful language for expressing and learning general\npolicies and problem decompositions (sketches) has been introduced in terms of\nrules defined over a set of Boolean and numerical features. In this work, we\nconsider three extensions of this language aimed at making policies and\nsketches more flexible and reusable: internal memory states, as in finite state\ncontrollers; indexical features, whose values are a function of the state and a\nnumber of internal registers that can be loaded with objects; and modules that\nwrap up policies and sketches and allow them to call each other by passing\nparameters. In addition, unlike general policies that select state transitions\nrather than ground actions, the new language allows for the selection of such\nactions. The expressive power of the resulting language for policies and\nsketches is illustrated through a number of examples.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "ICAPS 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16824v1",
    "published_date": "2024-03-25 14:48:54 UTC",
    "updated_date": "2024-03-25 14:48:54 UTC"
  },
  {
    "arxiv_id": "2403.16812v2",
    "title": "Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making",
    "authors": [
      "Shuai Ma",
      "Qiaoyi Chen",
      "Xinru Wang",
      "Chengbo Zheng",
      "Zhenhui Peng",
      "Ming Yin",
      "Xiaojuan Ma"
    ],
    "abstract": "In AI-assisted decision-making, humans often passively review AI's suggestion\nand decide whether to accept or reject it as a whole. In such a paradigm,\nhumans are found to rarely trigger analytical thinking and face difficulties in\ncommunicating the nuances of conflicting opinions to the AI when disagreements\noccur. To tackle this challenge, we propose Human-AI Deliberation, a novel\nframework to promote human reflection and discussion on conflicting human-AI\nopinions in decision-making. Based on theories in human deliberation, this\nframework engages humans and AI in dimension-level opinion elicitation,\ndeliberative discussion, and decision updates. To empower AI with deliberative\ncapabilities, we designed Deliberative AI, which leverages large language\nmodels (LLMs) as a bridge between humans and domain-specific models to enable\nflexible conversational interactions and faithful information provision. An\nexploratory evaluation on a graduate admissions task shows that Deliberative AI\noutperforms conventional explainable AI (XAI) assistants in improving humans'\nappropriate reliance and task performance. Based on a mixed-methods analysis of\nparticipant behavior, perception, user experience, and open-ended feedback, we\ndraw implications for future AI-assisted decision tool design.",
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "primary_category": "cs.HC",
    "comment": "23 pages, ACM CHI 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.16812v2",
    "published_date": "2024-03-25 14:34:06 UTC",
    "updated_date": "2025-03-11 19:23:23 UTC"
  },
  {
    "arxiv_id": "2403.16809v1",
    "title": "An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems",
    "authors": [
      "Hanqing Yang",
      "Marie Siew",
      "Carlee Joe-Wong"
    ],
    "abstract": "The increasing prevalence of Cyber-Physical Systems and the Internet of\nThings (CPS-IoT) applications and Foundation Models are enabling new\napplications that leverage real-time control of the environment. For example,\nreal-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems\ncan reduce its usage when not needed for the comfort of human occupants, hence\nreducing energy consumption. Collecting real-time feedback on human preferences\nin such human-in-the-loop (HITL) systems, however, is difficult in practice. We\npropose the use of large language models (LLMs) to deal with the challenges of\ndynamic environments and difficult-to-obtain data in CPS optimization. In this\npaper, we present a case study that employs LLM agents to mimic the behaviors\nand thermal preferences of various population groups (e.g. young families, the\nelderly) in a shopping mall. The aggregated thermal preferences are integrated\ninto an agent-in-the-loop based reinforcement learning algorithm AitL-RL, which\nemploys the LLM as a dynamic simulation of the physical environment to learn\nhow to balance between energy savings and occupant comfort. Our results show\nthat LLMs are capable of simulating complex population movements within large\nopen spaces. Besides, AitL-RL demonstrates superior performance compared to the\npopular existing policy of set point control, suggesting that adaptive and\npersonalized decision-making is critical for efficient optimization in CPS-IoT\napplications. Through this case study, we demonstrate the potential of\nintegrating advanced Foundation Models like LLMs into CPS-IoT to enhance system\nadaptability and efficiency. The project's code can be found on our GitHub\nrepository.",
    "categories": [
      "eess.SY",
      "cs.AI",
      "cs.LG",
      "cs.SY"
    ],
    "primary_category": "eess.SY",
    "comment": "Accepted at International Workshop on Foundation Models for\n  Cyber-Physical Systems & Internet of Things (FMSys) 2024, Co-located at\n  CPS-IoT Week 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16809v1",
    "published_date": "2024-03-25 14:32:28 UTC",
    "updated_date": "2024-03-25 14:32:28 UTC"
  },
  {
    "arxiv_id": "2403.16808v2",
    "title": "Navigating the EU AI Act: A Methodological Approach to Compliance for Safety-critical Products",
    "authors": [
      "J. Kelly",
      "S. Zafar",
      "L. Heidemann",
      "J. Zacchi",
      "D. Espinoza",
      "N. Mata"
    ],
    "abstract": "In December 2023, the European Parliament provisionally agreed on the EU AI\nAct. This unprecedented regulatory framework for AI systems lays out guidelines\nto ensure the safety, legality, and trustworthiness of AI products. This paper\npresents a methodology for interpreting the EU AI Act requirements for\nhigh-risk AI systems by leveraging product quality models. We first propose an\nextended product quality model for AI systems, incorporating attributes\nrelevant to the Act not covered by current quality models. We map the Act\nrequirements to relevant quality attributes with the goal of refining them into\nmeasurable characteristics. We then propose a contract-based approach to derive\ntechnical requirements at the stakeholder level. This facilitates the\ndevelopment and assessment of AI systems that not only adhere to established\nquality standards, but also comply with the regulatory requirements outlined in\nthe Act for high-risk (including safety-critical) AI systems. We demonstrate\nthe applicability of this methodology on an exemplary automotive supply chain\nuse case, where several stakeholders interact to achieve EU AI Act compliance.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "To be published in: 2024 IEEE Conference on Artificial Intelligence\n  (CAI 2024)",
    "pdf_url": "http://arxiv.org/pdf/2403.16808v2",
    "published_date": "2024-03-25 14:32:18 UTC",
    "updated_date": "2024-03-26 08:59:17 UTC"
  },
  {
    "arxiv_id": "2403.16798v3",
    "title": "Enhancing Neural Network Representations with Prior Knowledge-Based Normalization",
    "authors": [
      "Bilal Faye",
      "Hanane Azzag",
      "Mustapha Lebbah",
      "Djamel Bouchaffra"
    ],
    "abstract": "Deep learning models face persistent challenges in training, particularly due\nto internal covariate shift and label shift. While single-mode normalization\nmethods like Batch Normalization partially address these issues, they are\nconstrained by batch size dependencies and limiting distributional assumptions.\nMulti-mode normalization techniques mitigate these limitations but struggle\nwith computational demands when handling diverse Gaussian distributions. In\nthis paper, we introduce a new approach to multi-mode normalization that\nleverages prior knowledge to improve neural network representations. Our method\norganizes data into predefined structures, or \"contexts\", prior to training and\nnormalizes based on these contexts, with two variants: Context Normalization\n(CN) and Context Normalization - Extended (CN-X). When contexts are\nunavailable, we introduce Adaptive Context Normalization (ACN), which\ndynamically builds contexts in the latent space during training. Across tasks\nin image classification, domain adaptation, and image generation, our methods\ndemonstrate superior convergence and performance.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16798v3",
    "published_date": "2024-03-25 14:17:38 UTC",
    "updated_date": "2024-10-30 10:55:01 UTC"
  },
  {
    "arxiv_id": "2403.16782v1",
    "title": "The Anatomy of Adversarial Attacks: Concept-based XAI Dissection",
    "authors": [
      "Georgii Mikriukov",
      "Gesina Schwalbe",
      "Franz Motzkus",
      "Korinna Bade"
    ],
    "abstract": "Adversarial attacks (AAs) pose a significant threat to the reliability and\nrobustness of deep neural networks. While the impact of these attacks on model\npredictions has been extensively studied, their effect on the learned\nrepresentations and concepts within these models remains largely unexplored. In\nthis work, we perform an in-depth analysis of the influence of AAs on the\nconcepts learned by convolutional neural networks (CNNs) using eXplainable\nartificial intelligence (XAI) techniques. Through an extensive set of\nexperiments across various network architectures and targeted AA techniques, we\nunveil several key findings. First, AAs induce substantial alterations in the\nconcept composition within the feature space, introducing new concepts or\nmodifying existing ones. Second, the adversarial perturbation itself can be\nlinearly decomposed into a set of latent vector components, with a subset of\nthese being responsible for the attack's success. Notably, we discover that\nthese components are target-specific, i.e., are similar for a given target\nclass throughout different AA techniques and starting classes. Our findings\nprovide valuable insights into the nature of AAs and their impact on learned\nrepresentations, paving the way for the development of more robust and\ninterpretable deep learning models, as well as effective defenses against\nadversarial threats.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16782v1",
    "published_date": "2024-03-25 13:57:45 UTC",
    "updated_date": "2024-03-25 13:57:45 UTC"
  },
  {
    "arxiv_id": "2403.16768v1",
    "title": "DeepKnowledge: Generalisation-Driven Deep Learning Testing",
    "authors": [
      "Sondess Missaoui",
      "Simos Gerasimou",
      "Nikolaos Matragkas"
    ],
    "abstract": "Despite their unprecedented success, DNNs are notoriously fragile to small\nshifts in data distribution, demanding effective testing techniques that can\nassess their dependability. Despite recent advances in DNN testing, there is a\nlack of systematic testing approaches that assess the DNN's capability to\ngeneralise and operate comparably beyond data in their training distribution.\nWe address this gap with DeepKnowledge, a systematic testing methodology for\nDNN-based systems founded on the theory of knowledge generalisation, which aims\nto enhance DNN robustness and reduce the residual risk of 'black box' models.\nConforming to this theory, DeepKnowledge posits that core computational DNN\nunits, termed Transfer Knowledge neurons, can generalise under domain shift.\nDeepKnowledge provides an objective confidence measurement on testing\nactivities of DNN given data distribution shifts and uses this information to\ninstrument a generalisation-informed test adequacy criterion to check the\ntransfer knowledge capacity of a test set. Our empirical evaluation of several\nDNNs, across multiple datasets and state-of-the-art adversarial generation\ntechniques demonstrates the usefulness and effectiveness of DeepKnowledge and\nits ability to support the engineering of more dependable DNNs. We report\nimprovements of up to 10 percentage points over state-of-the-art coverage\ncriteria for detecting adversarial attacks on several benchmarks, including\nMNIST, SVHN, and CIFAR.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.LG",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.16768v1",
    "published_date": "2024-03-25 13:46:09 UTC",
    "updated_date": "2024-03-25 13:46:09 UTC"
  },
  {
    "arxiv_id": "2403.16760v5",
    "title": "As Good As A Coin Toss: Human detection of AI-generated images, videos, audio, and audiovisual stimuli",
    "authors": [
      "Di Cooke",
      "Abigail Edwards",
      "Sophia Barkoff",
      "Kathryn Kelly"
    ],
    "abstract": "One of the current principal defenses against weaponized synthetic media\ncontinues to be the ability of the targeted individual to visually or\nauditorily recognize AI-generated content when they encounter it. However, as\nthe realism of synthetic media continues to rapidly improve, it is vital to\nhave an accurate understanding of just how susceptible people currently are to\npotentially being misled by convincing but false AI generated content. We\nconducted a perceptual study with 1276 participants to assess how capable\npeople were at distinguishing between authentic and synthetic images, audio,\nvideo, and audiovisual media. We find that on average, people struggled to\ndistinguish between synthetic and authentic media, with the mean detection\nperformance close to a chance level performance of 50%. We also find that\naccuracy rates worsen when the stimuli contain any degree of synthetic content,\nfeatures foreign languages, and the media type is a single modality. People are\nalso less accurate at identifying synthetic images when they feature human\nfaces, and when audiovisual stimuli have heterogeneous authenticity. Finally,\nwe find that higher degrees of prior knowledgeability about synthetic media\ndoes not significantly impact detection accuracy rates, but age does, with\nolder individuals performing worse than their younger counterparts.\nCollectively, these results highlight that it is no longer feasible to rely on\nthe perceptual capabilities of people to protect themselves against the growing\nthreat of weaponized synthetic media, and that the need for alternative\ncountermeasures is more critical than ever before.",
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.SD",
      "eess.AS",
      "68T01",
      "I.2"
    ],
    "primary_category": "cs.HC",
    "comment": "For study pre-registration, see https://osf.io/fnhr3 V5: expanded on\n  ecological validation in Introduction; revised table in Results to add OR &\n  OR CI, previous data unchanged; added further details on study design in\n  Methods; added Appendix with survey screenshots; migrated list of dataset\n  sources from footnotes into references",
    "pdf_url": "http://arxiv.org/pdf/2403.16760v5",
    "published_date": "2024-03-25 13:39:33 UTC",
    "updated_date": "2025-04-10 20:30:04 UTC"
  },
  {
    "arxiv_id": "2403.16757v1",
    "title": "Bi-objective Optimization in Role Mining",
    "authors": [
      "Jason Crampton",
      "Eduard Eiben",
      "Gregory Gutin",
      "Daniel Karapetyan",
      "Diptapriyo Majumdar"
    ],
    "abstract": "Role mining is a technique used to derive a role-based authorization policy\nfrom an existing policy. Given a set of users $U$, a set of permissions $P$ and\na user-permission authorization relation $\\mahtit{UPA}\\subseteq U\\times P$, a\nrole mining algorithm seeks to compute a set of roles $R$, a user-role\nauthorization relation $\\mathit{UA}\\subseteq U\\times R$ and a permission-role\nauthorization relation $\\mathit{PA}\\subseteq R\\times P$, such that the\ncomposition of $\\mathit{UA}$ and $\\mathit{PA}$ is close (in some appropriate\nsense) to $\\mathit{UPA}$.\n  In this paper, we first introduce the Generalized Noise Role Mining problem\n(GNRM) -- a generalization of the MinNoise Role Mining problem -- which we\nbelieve has considerable practical relevance. Extending work of Fomin et al.,\nwe show that GNRM is fixed parameter tractable, with parameter $r + k$, where\n$r$ is the number of roles in the solution and $k$ is the number of\ndiscrepancies between $\\mathit{UPA}$ and the relation defined by the\ncomposition of $\\mathit{UA}$ and $\\mathit{PA}$. We further introduce a\nbi-objective optimization variant of GNRM, where we wish to minimize both $r$\nand $k$ subject to upper bounds $r\\le \\bar{r}$ and $k\\le \\bar{k}$, where\n$\\bar{r}$ and $\\bar{k}$ are constants. We show that the Pareto front of this\nbi-objective optimization problem (BO-GNRM) can be computed in fixed-parameter\ntractable time with parameter $\\bar{r}+\\bar{k}$.\n  We then report the results of our experimental work using the integer\nprogramming solver Gurobi to solve instances of BO-GNRM. Our key findings are\nthat (a) we obtained strong support that Gurobi's performance is\nfixed-parameter tractable, (b) our results suggest that our techniques may be\nuseful for role mining in practice, based on our experiments in the context of\nthree well-known real-world authorization policies.",
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CC"
    ],
    "primary_category": "cs.CR",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16757v1",
    "published_date": "2024-03-25 13:36:20 UTC",
    "updated_date": "2024-03-25 13:36:20 UTC"
  },
  {
    "arxiv_id": "2403.16750v1",
    "title": "All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification",
    "authors": [
      "Deepak Narayan Gadde",
      "Aman Kumar",
      "Thomas Nalapat",
      "Evgenii Rezunov",
      "Fabio Cappellini"
    ],
    "abstract": "Modern hardware designs have grown increasingly efficient and complex.\nHowever, they are often susceptible to Common Weakness Enumerations (CWEs).\nThis paper is focused on the formal verification of CWEs in a dataset of\nhardware designs written in SystemVerilog from Regenerative Artificial\nIntelligence (AI) powered by Large Language Models (LLMs). We applied formal\nverification to categorize each hardware design as vulnerable or CWE-free. This\ndataset was generated by 4 different LLMs and features a unique set of designs\nfor each of the 10 CWEs we target in our paper. We have associated the\nidentified vulnerabilities with CWE numbers for a dataset of 60,000 generated\nSystemVerilog Register Transfer Level (RTL) code. It was also found that most\nLLMs are not aware of any hardware CWEs; hence they are usually not considered\nwhen generating the hardware code. Our study reveals that approximately 60% of\nthe hardware designs generated by LLMs are prone to CWEs, posing potential\nsafety and security risks. The dataset could be ideal for training LLMs and\nMachine Learning (ML) algorithms to abstain from generating CWE-prone hardware\ndesigns.",
    "categories": [
      "cs.AI",
      "cs.AR"
    ],
    "primary_category": "cs.AI",
    "comment": "Published in DVCon U.S. 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16750v1",
    "published_date": "2024-03-25 13:23:24 UTC",
    "updated_date": "2024-03-25 13:23:24 UTC"
  },
  {
    "arxiv_id": "2403.16732v2",
    "title": "Enabling Uncertainty Estimation in Iterative Neural Networks",
    "authors": [
      "Nikita Durasov",
      "Doruk Oner",
      "Jonathan Donier",
      "Hieu Le",
      "Pascal Fua"
    ],
    "abstract": "Turning pass-through network architectures into iterative ones, which use\ntheir own output as input, is a well-known approach for boosting performance.\nIn this paper, we argue that such architectures offer an additional benefit:\nThe convergence rate of their successive outputs is highly correlated with the\naccuracy of the value to which they converge. Thus, we can use the convergence\nrate as a useful proxy for uncertainty. This results in an approach to\nuncertainty estimation that provides state-of-the-art estimates at a much lower\ncomputational cost than techniques like Ensembles, and without requiring any\nmodifications to the original iterative model. We demonstrate its practical\nvalue by embedding it in two application domains: road detection in aerial\nimages and the estimation of aerodynamic properties of 2D and 3D shapes.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted at ICML 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16732v2",
    "published_date": "2024-03-25 13:06:31 UTC",
    "updated_date": "2024-05-30 10:10:19 UTC"
  },
  {
    "arxiv_id": "2403.16728v1",
    "title": "Improving Diffusion Models's Data-Corruption Resistance using Scheduled Pseudo-Huber Loss",
    "authors": [
      "Artem Khrapov",
      "Vadim Popov",
      "Tasnima Sadekova",
      "Assel Yermekova",
      "Mikhail Kudinov"
    ],
    "abstract": "Diffusion models are known to be vulnerable to outliers in training data. In\nthis paper we study an alternative diffusion loss function, which can preserve\nthe high quality of generated data like the original squared $L_{2}$ loss while\nat the same time being robust to outliers. We propose to use pseudo-Huber loss\nfunction with a time-dependent parameter to allow for the trade-off between\nrobustness on the most vulnerable early reverse-diffusion steps and fine\ndetails restoration on the final steps. We show that pseudo-Huber loss with the\ntime-dependent parameter exhibits better performance on corrupted datasets in\nboth image and audio domains. In addition, the loss function we propose can\npotentially help diffusion models to resist dataset corruption while not\nrequiring data filtering or purification compared to conventional training\nalgorithms.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "13 pages, 16 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.16728v1",
    "published_date": "2024-03-25 13:02:43 UTC",
    "updated_date": "2024-03-25 13:02:43 UTC"
  },
  {
    "arxiv_id": "2403.16719v1",
    "title": "Towards a Formalisation of Value-based Actions and Consequentialist Ethics",
    "authors": [
      "Adam Wyner",
      "Tomasz Zurek",
      "DOrota Stachura-Zurek"
    ],
    "abstract": "Agents act to bring about a state of the world that is more compatible with\ntheir personal or institutional values. To formalise this intuition, the paper\nproposes an action framework based on the STRIPS formalisation. Technically,\nthe contribution expresses actions in terms of Value-based Formal Reasoning\n(VFR), which provides a set of propositions derived from an Agent's value\nprofile and the Agent's assessment of propositions with respect to the profile.\nConceptually, the contribution provides a computational framework for a form of\nconsequentialist ethics which is satisficing, luralistic, act-based, and\npreferential.",
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "primary_category": "cs.MA",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16719v1",
    "published_date": "2024-03-25 12:56:48 UTC",
    "updated_date": "2024-03-25 12:56:48 UTC"
  },
  {
    "arxiv_id": "2403.16707v2",
    "title": "One-Shot Domain Incremental Learning",
    "authors": [
      "Yasushi Esaki",
      "Satoshi Koide",
      "Takuro Kutsuna"
    ],
    "abstract": "Domain incremental learning (DIL) has been discussed in previous studies on\ndeep neural network models for classification. In DIL, we assume that samples\non new domains are observed over time. The models must classify inputs on all\ndomains. In practice, however, we may encounter a situation where we need to\nperform DIL under the constraint that the samples on the new domain are\nobserved only infrequently. Therefore, in this study, we consider the extreme\ncase where we have only one sample from the new domain, which we call one-shot\nDIL. We first empirically show that existing DIL methods do not work well in\none-shot DIL. We have analyzed the reason for this failure through various\ninvestigations. According to our analysis, we clarify that the difficulty of\none-shot DIL is caused by the statistics in the batch normalization layers.\nTherefore, we propose a technique regarding these statistics and demonstrate\nthe effectiveness of our technique through experiments on open datasets. The\ncode is available at https://github.com/ToyotaCRDL/OneShotDIL.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "Accepted at IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16707v2",
    "published_date": "2024-03-25 12:44:52 UTC",
    "updated_date": "2025-02-24 06:58:41 UTC"
  },
  {
    "arxiv_id": "2403.16687v5",
    "title": "Investigation of the effectiveness of applying ChatGPT in Dialogic Teaching Using Electroencephalography",
    "authors": [
      "Jiayue Zhang",
      "Yiheng Liu",
      "Wenqi Cai",
      "Lanlan Wu",
      "Yali Peng",
      "Jingjing Yu",
      "Senqing Qi",
      "Taotao Long",
      "Bao Ge"
    ],
    "abstract": "In recent years, the rapid development of artificial intelligence technology,\nespecially the emergence of large language models (LLMs) such as ChatGPT, has\npresented significant prospects for application in the field of education. LLMs\npossess the capability to interpret knowledge, answer questions, and consider\ncontext, thus providing support for dialogic teaching to students. Therefore,\nan examination of the capacity of LLMs to effectively fulfill instructional\nroles, thereby facilitating student learning akin to human educators within\ndialogic teaching scenarios, is an exceptionally valuable research topic. This\nresearch recruited 34 undergraduate students as participants, who were randomly\ndivided into two groups. The experimental group engaged in dialogic teaching\nusing ChatGPT, while the control group interacted with human teachers. Both\ngroups learned the histogram equalization unit in the information-related\ncourse \"Digital Image Processing\". The research findings show comparable scores\nbetween the two groups on the retention test. However, students who engaged in\ndialogue with ChatGPT exhibited lower performance on the transfer test.\nElectroencephalography data revealed that students who interacted with ChatGPT\nexhibited higher levels of cognitive activity, suggesting that ChatGPT could\nhelp students establish a knowledge foundation and stimulate cognitive\nactivity. However, its strengths on promoting students. knowledge application\nand creativity were insignificant. Based upon the research findings, it is\nevident that ChatGPT cannot fully excel in fulfilling teaching tasks in the\ndialogue teaching in information related courses. Combining ChatGPT with\ntraditional human teachers might be a more ideal approach. The synergistic use\nof both can provide students with more comprehensive learning support, thus\ncontributing to enhancing the quality of teaching.",
    "categories": [
      "cs.CY",
      "cs.AI",
      "physics.ed-ph"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16687v5",
    "published_date": "2024-03-25 12:23:12 UTC",
    "updated_date": "2024-06-11 03:35:03 UTC"
  },
  {
    "arxiv_id": "2403.17040v1",
    "title": "Enhancing Graph Representation Learning with Attention-Driven Spiking Neural Networks",
    "authors": [
      "Huifeng Yin",
      "Mingkun Xu",
      "Jing Pei",
      "Lei Deng"
    ],
    "abstract": "Graph representation learning has become a crucial task in machine learning\nand data mining due to its potential for modeling complex structures such as\nsocial networks, chemical compounds, and biological systems. Spiking neural\nnetworks (SNNs) have recently emerged as a promising alternative to traditional\nneural networks for graph learning tasks, benefiting from their ability to\nefficiently encode and process temporal and spatial information. In this paper,\nwe propose a novel approach that integrates attention mechanisms with SNNs to\nimprove graph representation learning. Specifically, we introduce an attention\nmechanism for SNN that can selectively focus on important nodes and\ncorresponding features in a graph during the learning process. We evaluate our\nproposed method on several benchmark datasets and show that it achieves\ncomparable performance compared to existing graph learning techniques.",
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.NE"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.17040v1",
    "published_date": "2024-03-25 12:15:10 UTC",
    "updated_date": "2024-03-25 12:15:10 UTC"
  },
  {
    "arxiv_id": "2403.16674v2",
    "title": "Understanding the Functional Roles of Modelling Components in Spiking Neural Networks",
    "authors": [
      "Huifeng Yin",
      "Hanle Zheng",
      "Jiayi Mao",
      "Siyuan Ding",
      "Xing Liu",
      "Mingkun Xu",
      "Yifan Hu",
      "Jing Pei",
      "Lei Deng"
    ],
    "abstract": "Spiking neural networks (SNNs), inspired by the neural circuits of the brain,\nare promising in achieving high computational efficiency with biological\nfidelity. Nevertheless, it is quite difficult to optimize SNNs because the\nfunctional roles of their modelling components remain unclear. By designing and\nevaluating several variants of the classic model, we systematically investigate\nthe functional roles of key modelling components, leakage, reset, and\nrecurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive\nexperiments, we demonstrate how these components influence the accuracy,\ngeneralization, and robustness of SNNs. Specifically, we find that the leakage\nplays a crucial role in balancing memory retention and robustness, the reset\nmechanism is essential for uninterrupted temporal processing and computational\nefficiency, and the recurrence enriches the capability to model complex\ndynamics at a cost of robustness degradation. With these interesting\nobservations, we provide optimization suggestions for enhancing the performance\nof SNNs in different scenarios. This work deepens the understanding of how SNNs\nwork, which offers valuable guidance for the development of more effective and\nrobust neuromorphic models.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16674v2",
    "published_date": "2024-03-25 12:13:20 UTC",
    "updated_date": "2025-01-27 02:47:57 UTC"
  },
  {
    "arxiv_id": "2403.16667v1",
    "title": "Deep Reinforcement Learning and Mean-Variance Strategies for Responsible Portfolio Optimization",
    "authors": [
      "Fernando Acero",
      "Parisa Zehtabi",
      "Nicolas Marchesotti",
      "Michael Cashmore",
      "Daniele Magazzeni",
      "Manuela Veloso"
    ],
    "abstract": "Portfolio optimization involves determining the optimal allocation of\nportfolio assets in order to maximize a given investment objective.\nTraditionally, some form of mean-variance optimization is used with the aim of\nmaximizing returns while minimizing risk, however, more recently, deep\nreinforcement learning formulations have been explored. Increasingly, investors\nhave demonstrated an interest in incorporating ESG objectives when making\ninvestment decisions, and modifications to the classical mean-variance\noptimization framework have been developed. In this work, we study the use of\ndeep reinforcement learning for responsible portfolio optimization, by\nincorporating ESG states and objectives, and provide comparisons against\nmodified mean-variance approaches. Our results show that deep reinforcement\nlearning policies can provide competitive performance against mean-variance\napproaches for responsible portfolio allocation across additive and\nmultiplicative utility functions of financial and ESG responsibility\nobjectives.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Presented at the AAAI 2024 Workshop on AI in Finance for Social\n  Impact",
    "pdf_url": "http://arxiv.org/pdf/2403.16667v1",
    "published_date": "2024-03-25 12:04:03 UTC",
    "updated_date": "2024-03-25 12:04:03 UTC"
  },
  {
    "arxiv_id": "2403.16666v1",
    "title": "Revisiting the Sleeping Beauty problem",
    "authors": [
      "Paulo S. Piva",
      "Gabriel Ruffolo"
    ],
    "abstract": "The Sleeping Beauty problem is a probability riddle with no definite solution\nfor more than two decades and its solution is of great interest in many fields\nof knowledge. There are two main competing solutions to the problem: the halfer\napproach, and the thirder approach. The main reason for disagreement in the\nliterature is connected to the use of different probability spaces to represent\nthe same probabilistic riddle. In this work, we analyse the problem from a\nmathematical perspective, identifying probability distributions induced\ndirectly from the thought experiment's rules. The precise choices of\nprobability spaces provide both halfer and thirder solutions to the problem. To\ntry and decide on which approach to follow, a criterion involving the\ninformation available to Sleeping Beauty is proposed.",
    "categories": [
      "math.HO",
      "cs.AI"
    ],
    "primary_category": "math.HO",
    "comment": "14 pages, 1 figure",
    "pdf_url": "http://arxiv.org/pdf/2403.16666v1",
    "published_date": "2024-03-25 12:01:27 UTC",
    "updated_date": "2024-03-25 12:01:27 UTC"
  },
  {
    "arxiv_id": "2403.16649v2",
    "title": "CLHA: A Simple yet Effective Contrastive Learning Framework for Human Alignment",
    "authors": [
      "Feiteng Fang",
      "Liang Zhu",
      "Min Yang",
      "Xi Feng",
      "Jinchang Hou",
      "Qixuan Zhao",
      "Chengming Li",
      "Xiping Hu",
      "Ruifeng Xu"
    ],
    "abstract": "Reinforcement learning from human feedback (RLHF) is a crucial technique in\naligning large language models (LLMs) with human preferences, ensuring these\nLLMs behave in beneficial and comprehensible ways to users. However, a\nlongstanding challenge in human alignment techniques based on reinforcement\nlearning lies in their inherent complexity and difficulty in training. To\naddress this challenge, we present a simple yet effective Contrastive Learning\nFramework for Human Alignment (CLHA) to align LLMs with human preferences\ndirectly. CLHA employs a novel rescoring strategy to evaluate the noise within\nthe data by considering its inherent quality and dynamically adjusting the\ntraining process. Simultaneously, CLHA utilizes pairwise contrastive loss and\nadaptive supervised fine-tuning loss to adaptively modify the likelihood of\ngenerating responses, ensuring enhanced alignment with human preferences. Using\nadvanced methods, CLHA surpasses other algorithms, showcasing superior\nperformance in terms of reward model scores, automatic evaluations, and human\nassessments on the widely used ``Helpful and Harmless'' dataset.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16649v2",
    "published_date": "2024-03-25 11:37:15 UTC",
    "updated_date": "2024-03-26 06:08:20 UTC"
  },
  {
    "arxiv_id": "2403.16591v3",
    "title": "Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy",
    "authors": [
      "Xiaojin Zhang",
      "Yulin Fei",
      "Wei Chen"
    ],
    "abstract": "The swift evolution of machine learning has led to emergence of various\ndefinitions of privacy due to the threats it poses to privacy, including the\nconcept of local differential privacy (LDP). Although widely embraced and\nutilized across numerous domains, this conventional approach to measure privacy\nstill exhibits certain limitations, spanning from failure to prevent\ninferential disclosure to lack of consideration for the adversary's background\nknowledge. In this comprehensive study, we introduce Bayesian privacy and delve\ninto the intricate relationship between LDP and its Bayesian counterparts,\nunveiling novel insights into utility-privacy trade-offs. We introduce a\nframework that encapsulates both attack and defense strategies, highlighting\ntheir interplay and effectiveness. The relationship between LDP and Maximum\nBayesian Privacy (MBP) is first revealed, demonstrating that under uniform\nprior distribution, a mechanism satisfying $\\xi$-LDP will satisfy $\\xi$-MBP and\nconversely $\\xi$-MBP also confers 2$\\xi$-LDP. Our next theoretical contribution\nare anchored in the rigorous definitions and relationships between Average\nBayesian Privacy (ABP) and Maximum Bayesian Privacy (MBP), encapsulated by\nequations $\\epsilon_{p,a} \\leq \\frac{1}{\\sqrt{2}}\\sqrt{(\\epsilon_{p,m} +\n\\epsilon)\\cdot(e^{\\epsilon_{p,m} + \\epsilon} - 1)}$. These relationships\nfortify our understanding of the privacy guarantees provided by various\nmechanisms. Our work not only lays the groundwork for future empirical\nexploration but also promises to facilitate the design of privacy-preserving\nalgorithms, thereby fostering the development of trustworthy machine learning\nsolutions.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CR"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16591v3",
    "published_date": "2024-03-25 10:06:45 UTC",
    "updated_date": "2024-04-02 14:28:06 UTC"
  },
  {
    "arxiv_id": "2403.16582v2",
    "title": "In the Search for Optimal Multi-view Learning Models for Crop Classification with Global Remote Sensing Data",
    "authors": [
      "Francisco Mena",
      "Diego Arenas",
      "Andreas Dengel"
    ],
    "abstract": "Studying and analyzing cropland is a difficult task due to its dynamic and\nheterogeneous growth behavior. Usually, diverse data sources can be collected\nfor its estimation. Although deep learning models have proven to excel in the\ncrop classification task, they face substantial challenges when dealing with\nmultiple inputs, named Multi-View Learning (MVL). The methods used in the MVL\nscenario can be structured based on the encoder architecture, the fusion\nstrategy, and the optimization technique. The literature has primarily focused\non using specific encoder architectures for local regions, lacking a deeper\nexploration of other components in the MVL methodology. In contrast, we\ninvestigate the simultaneous selection of the fusion strategy and encoder\narchitecture, assessing global-scale cropland and crop-type classifications. We\nuse a range of five fusion strategies (Input, Feature, Decision, Ensemble,\nHybrid) and five temporal encoders (LSTM, GRU, TempCNN, TAE, L-TAE) as possible\nconfigurations in the MVL method. We use the CropHarvest dataset for\nvalidation, which provides optical, radar, weather time series, and topographic\ninformation as input data. We found that in scenarios with a limited number of\nlabeled samples, a unique configuration is insufficient for all the cases.\nInstead, a specialized combination should be meticulously sought, including an\nencoder and fusion strategy. To streamline this search process, we suggest\nidentifying the optimal encoder architecture tailored for a particular fusion\nstrategy, and then determining the most suitable fusion strategy for the\nclassification task. We provide a methodological framework for researchers\nexploring crop classification through an MVL methodology.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.LG",
    "comment": "submitted to journal",
    "pdf_url": "http://arxiv.org/pdf/2403.16582v2",
    "published_date": "2024-03-25 09:49:42 UTC",
    "updated_date": "2024-09-04 11:14:18 UTC"
  },
  {
    "arxiv_id": "2403.16578v4",
    "title": "SegICL: A Multimodal In-context Learning Framework for Enhanced Segmentation in Medical Imaging",
    "authors": [
      "Lingdong Shen",
      "Fangxin Shang",
      "Xiaoshuang Huang",
      "Yehui Yang",
      "Haifeng Huang",
      "Shiming Xiang"
    ],
    "abstract": "In the field of medical image segmentation, tackling Out-of-Distribution\n(OOD) segmentation tasks in a cost-effective manner remains a significant\nchallenge. Universal segmentation models is a solution, which aim to generalize\nacross the diverse modality of medical images, yet their effectiveness often\ndiminishes when applied to OOD data modalities and tasks, requiring intricate\nfine-tuning of model for optimal performance. Few-shot learning segmentation\nmethods are typically designed for specific modalities of data and cannot be\ndirectly transferred for use with another modality. Therefore, we introduce\nSegICL, a novel approach leveraging In-Context Learning (ICL) for image\nsegmentation. Unlike existing methods, SegICL has the capability to employ\ntext-guided segmentation and conduct in-context learning with a small set of\nimage-mask pairs, eliminating the need for training the model from scratch or\nfine-tuning for OOD tasks (including OOD modality and dataset). Extensive\nexperimental demonstrates a positive correlation between the number of shots\nand segmentation performance on OOD tasks. The performance of segmentation when\nprovided thre-shots is approximately 1.5 times better than the performance in a\nzero-shot setting. This indicates that SegICL effectively address new\nsegmentation tasks based on contextual information. Additionally, SegICL also\nexhibits comparable performance to mainstream models on OOD and in-distribution\ntasks. Our code will be released after paper review.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16578v4",
    "published_date": "2024-03-25 09:43:56 UTC",
    "updated_date": "2024-05-30 03:35:06 UTC"
  },
  {
    "arxiv_id": "2403.16571v1",
    "title": "NSINA: A News Corpus for Sinhala",
    "authors": [
      "Hansi Hettiarachchi",
      "Damith Premasiri",
      "Lasitha Uyangodage",
      "Tharindu Ranasinghe"
    ],
    "abstract": "The introduction of large language models (LLMs) has advanced natural\nlanguage processing (NLP), but their effectiveness is largely dependent on\npre-training resources. This is especially evident in low-resource languages,\nsuch as Sinhala, which face two primary challenges: the lack of substantial\ntraining data and limited benchmarking datasets. In response, this study\nintroduces NSINA, a comprehensive news corpus of over 500,000 articles from\npopular Sinhala news websites, along with three NLP tasks: news media\nidentification, news category prediction, and news headline generation. The\nrelease of NSINA aims to provide a solution to challenges in adapting LLMs to\nSinhala, offering valuable resources and benchmarks for improving NLP in the\nSinhala language. NSINA is the largest news corpus for Sinhala, available up to\ndate.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to LREC-COLING 2024 (The 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation)",
    "pdf_url": "http://arxiv.org/pdf/2403.16571v1",
    "published_date": "2024-03-25 09:36:51 UTC",
    "updated_date": "2024-03-25 09:36:51 UTC"
  },
  {
    "arxiv_id": "2403.16561v1",
    "title": "FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning",
    "authors": [
      "Xinyuan Ji",
      "Zhaowei Zhu",
      "Wei Xi",
      "Olga Gadyatskaya",
      "Zilong Song",
      "Yong Cai",
      "Yang Liu"
    ],
    "abstract": "Federated Learning (FL) heavily depends on label quality for its performance.\nHowever, the label distribution among individual clients is always both noisy\nand heterogeneous. The high loss incurred by client-specific samples in\nheterogeneous label noise poses challenges for distinguishing between\nclient-specific and noisy label samples, impacting the effectiveness of\nexisting label noise learning approaches. To tackle this issue, we propose\nFedFixer, where the personalized model is introduced to cooperate with the\nglobal model to effectively select clean client-specific samples. In the dual\nmodels, updating the personalized model solely at a local level can lead to\noverfitting on noisy data due to limited samples, consequently affecting both\nthe local and global models' performance. To mitigate overfitting, we address\nthis concern from two perspectives. Firstly, we employ a confidence regularizer\nto alleviate the impact of unconfident predictions caused by label noise.\nSecondly, a distance regularizer is implemented to constrain the disparity\nbetween the personalized and global models. We validate the effectiveness of\nFedFixer through extensive experiments on benchmark datasets. The results\ndemonstrate that FedFixer can perform well in filtering noisy label samples on\ndifferent clients, especially in highly heterogeneous label noise scenarios.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "accepted by AAA24",
    "pdf_url": "http://arxiv.org/pdf/2403.16561v1",
    "published_date": "2024-03-25 09:24:05 UTC",
    "updated_date": "2024-03-25 09:24:05 UTC"
  },
  {
    "arxiv_id": "2403.16554v2",
    "title": "PE: A Poincare Explanation Method for Fast Text Hierarchy Generation",
    "authors": [
      "Qian Chen",
      "Dongyang Li",
      "Xiaofeng He",
      "Hongzhao Li",
      "Hongyu Yi"
    ],
    "abstract": "The black-box nature of deep learning models in NLP hinders their widespread\napplication. The research focus has shifted to Hierarchical Attribution (HA)\nfor its ability to model feature interactions. Recent works model\nnon-contiguous combinations with a time-costly greedy search in Eculidean\nspaces, neglecting underlying linguistic information in feature\nrepresentations. In this work, we introduce a novel method, namely Poincare\nExplanation (PE), for modeling feature interactions with hyperbolic spaces in a\ntime efficient manner. Specifically, we take building text hierarchies as\nfinding spanning trees in hyperbolic spaces. First we project the embeddings\ninto hyperbolic spaces to elicit inherit semantic and syntax hierarchical\nstructures. Then we propose a simple yet effective strategy to calculate\nShapley score. Finally we build the the hierarchy with proving the constructing\nprocess in the projected space could be viewed as building a minimum spanning\ntree and introduce a time efficient building algorithm. Experimental results\ndemonstrate the effectiveness of our approach.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16554v2",
    "published_date": "2024-03-25 09:04:14 UTC",
    "updated_date": "2024-06-12 11:17:47 UTC"
  },
  {
    "arxiv_id": "2403.16552v2",
    "title": "QKFormer: Hierarchical Spiking Transformer using Q-K Attention",
    "authors": [
      "Chenlin Zhou",
      "Han Zhang",
      "Zhaokun Zhou",
      "Liutao Yu",
      "Liwei Huang",
      "Xiaopeng Fan",
      "Li Yuan",
      "Zhengyu Ma",
      "Huihui Zhou",
      "Yonghong Tian"
    ],
    "abstract": "Spiking Transformers, which integrate Spiking Neural Networks (SNNs) with\nTransformer architectures, have attracted significant attention due to their\npotential for energy efficiency and high performance. However, existing models\nin this domain still suffer from suboptimal performance. We introduce several\ninnovations to improve the performance: i) We propose a novel spike-form Q-K\nattention mechanism, tailored for SNNs, which efficiently models the importance\nof token or channel dimensions through binary vectors with linear complexity.\nii) We incorporate the hierarchical structure, which significantly benefits the\nperformance of both the brain and artificial neural networks, into spiking\ntransformers to obtain multi-scale spiking representation. iii) We design a\nversatile and powerful patch embedding module with a deformed shortcut\nspecifically for spiking transformers. Together, we develop QKFormer, a\nhierarchical spiking transformer based on Q-K attention with direct training.\nQKFormer shows significantly superior performance over existing\nstate-of-the-art SNN models on various mainstream datasets. Notably, with\ncomparable size to Spikformer (66.34 M, 74.81%), QKFormer (64.96 M) achieves a\ngroundbreaking top-1 accuracy of 85.65% on ImageNet-1k, substantially\noutperforming Spikformer by 10.84%. To our best knowledge, this is the first\ntime that directly training SNNs have exceeded 85% accuracy on ImageNet-1K. The\ncode and models are publicly available at\nhttps://github.com/zhouchenlin2096/QKFormer",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.CV"
    ],
    "primary_category": "cs.NE",
    "comment": "Accepted by NeurIPS 2024 (Spotlight). Code and Model:\n  https://github.com/zhouchenlin2096/QKFormer",
    "pdf_url": "http://arxiv.org/pdf/2403.16552v2",
    "published_date": "2024-03-25 08:57:27 UTC",
    "updated_date": "2024-10-08 09:29:01 UTC"
  },
  {
    "arxiv_id": "2404.07968v1",
    "title": "AD-NEv++ : The multi-architecture neuroevolution-based multivariate anomaly detection framework",
    "authors": [
      "Marcin Pietroń",
      "Dominik Żurek",
      "Kamil Faber",
      "Roberto Corizzo"
    ],
    "abstract": "Anomaly detection tools and methods enable key analytical capabilities in\nmodern cyberphysical and sensor-based systems. Despite the fast-paced\ndevelopment in deep learning architectures for anomaly detection, model\noptimization for a given dataset is a cumbersome and time-consuming process.\nNeuroevolution could be an effective and efficient solution to this problem, as\na fully automated search method for learning optimal neural networks,\nsupporting both gradient and non-gradient fine tuning. However, existing\nframeworks incorporating neuroevolution lack of support for new layers and\narchitectures and are typically limited to convolutional and LSTM layers. In\nthis paper we propose AD-NEv++, a three-stage neuroevolution-based method that\nsynergically combines subspace evolution, model evolution, and fine-tuning. Our\nmethod overcomes the limitations of existing approaches by optimizing the\nmutation operator in the neuroevolution process, while supporting a wide\nspectrum of neural layers, including attention, dense, and graph convolutional\nlayers. Our extensive experimental evaluation was conducted with widely adopted\nmultivariate anomaly detection benchmark datasets, and showed that the models\ngenerated by AD-NEv++ outperform well-known deep learning architectures and\nneuroevolution-based approaches for anomaly detection. Moreover, results show\nthat AD-NEv++ can improve and outperform the state-of-the-art GNN (Graph Neural\nNetworks) model architecture in all anomaly detection benchmarks.",
    "categories": [
      "cs.NE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.NE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.07968v1",
    "published_date": "2024-03-25 08:40:58 UTC",
    "updated_date": "2024-03-25 08:40:58 UTC"
  },
  {
    "arxiv_id": "2403.16543v1",
    "title": "Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning",
    "authors": [
      "Philipp Borchert",
      "Jochen De Weerdt",
      "Marie-Francine Moens"
    ],
    "abstract": "Differentiating relationships between entity pairs with limited labeled\ninstances poses a significant challenge in few-shot relation classification.\nRepresentations of textual data extract rich information spanning the domain,\nentities, and relations. In this paper, we introduce a novel approach to\nenhance information extraction combining multiple sentence representations and\ncontrastive learning. While representations in relation classification are\ncommonly extracted using entity marker tokens, we argue that substantial\ninformation within the internal model representations remains untapped. To\naddress this, we propose aligning multiple sentence representations, such as\nthe [CLS] token, the [MASK] token used in prompting, and entity marker tokens.\nOur method employs contrastive learning to extract complementary discriminative\ninformation from these individual representations. This is particularly\nrelevant in low-resource settings where information is scarce. Leveraging\nmultiple sentence representations is especially effective in distilling\ndiscriminative information for relation classification when additional\ninformation, like relation descriptions, are not available. We validate the\nadaptability of our approach, maintaining robust performance in scenarios that\ninclude relation descriptions, and showcasing its flexibility to adapt to\ndifferent resource constraints.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "NAACL 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16543v1",
    "published_date": "2024-03-25 08:36:06 UTC",
    "updated_date": "2024-03-25 08:36:06 UTC"
  },
  {
    "arxiv_id": "2403.16530v1",
    "title": "An Intermediate Fusion ViT Enables Efficient Text-Image Alignment in Diffusion Models",
    "authors": [
      "Zizhao Hu",
      "Shaochong Jia",
      "Mohammad Rostami"
    ],
    "abstract": "Diffusion models have been widely used for conditional data cross-modal\ngeneration tasks such as text-to-image and text-to-video. However,\nstate-of-the-art models still fail to align the generated visual concepts with\nhigh-level semantics in a language such as object count, spatial relationship,\netc. We approach this problem from a multimodal data fusion perspective and\ninvestigate how different fusion strategies can affect vision-language\nalignment. We discover that compared to the widely used early fusion of\nconditioning text in a pretrained image feature space, a specially designed\nintermediate fusion can: (i) boost text-to-image alignment with improved\ngeneration quality and (ii) improve training and inference efficiency by\nreducing low-rank text-to-image attention calculations. We perform experiments\nusing a text-to-image generation task on the MS-COCO dataset. We compare our\nintermediate fusion mechanism with the classic early fusion mechanism on two\ncommon conditioning methods on a U-shaped ViT backbone. Our intermediate fusion\nmodel achieves a higher CLIP Score and lower FID, with 20% reduced FLOPs, and\n50% increased training speed compared to a strong U-ViT baseline with an early\nfusion.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16530v1",
    "published_date": "2024-03-25 08:16:06 UTC",
    "updated_date": "2024-03-25 08:16:06 UTC"
  },
  {
    "arxiv_id": "2403.16527v2",
    "title": "Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art",
    "authors": [
      "Neeloy Chakraborty",
      "Melkior Ornik",
      "Katherine Driggs-Campbell"
    ],
    "abstract": "Autonomous systems are soon to be ubiquitous, spanning manufacturing,\nagriculture, healthcare, entertainment, and other industries. Most of these\nsystems are developed with modular sub-components for decision-making,\nplanning, and control that may be hand-engineered or learning-based. While\nthese approaches perform well under the situations they were specifically\ndesigned for, they can perform especially poorly in out-of-distribution\nscenarios that will undoubtedly arise at test-time. The rise of foundation\nmodels trained on multiple tasks with impressively large datasets has led\nresearchers to believe that these models may provide \"common sense\" reasoning\nthat existing planners are missing, bridging the gap between algorithm\ndevelopment and deployment. While researchers have shown promising results in\ndeploying foundation models to decision-making tasks, these models are known to\nhallucinate and generate decisions that may sound reasonable, but are in fact\npoor. We argue there is a need to step back and simultaneously design systems\nthat can quantify the certainty of a model's decision, and detect when it may\nbe hallucinating. In this work, we discuss the current use cases of foundation\nmodels for decision-making tasks, provide a general definition for\nhallucinations with examples, discuss existing approaches to hallucination\ndetection and mitigation with a focus on decision problems, present guidelines,\nand explore areas for further research in this exciting field.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.RO"
    ],
    "primary_category": "cs.AI",
    "comment": "Accepted to ACM Computing Surveys; 55 pages, 5 tables, 3 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.16527v2",
    "published_date": "2024-03-25 08:11:02 UTC",
    "updated_date": "2025-02-11 17:40:41 UTC"
  },
  {
    "arxiv_id": "2403.16524v2",
    "title": "Harnessing the power of LLMs for normative reasoning in MASs",
    "authors": [
      "Bastin Tony Roy Savarimuthu",
      "Surangika Ranathunga",
      "Stephen Cranefield"
    ],
    "abstract": "Software agents, both human and computational, do not exist in isolation and\noften need to collaborate or coordinate with others to achieve their goals. In\nhuman society, social mechanisms such as norms ensure efficient functioning,\nand these techniques have been adopted by researchers in multi-agent systems\n(MAS) to create socially aware agents. However, traditional techniques have\nlimitations, such as operating in limited environments often using brittle\nsymbolic reasoning. The advent of Large Language Models (LLMs) offers a\npromising solution, providing a rich and expressive vocabulary for norms and\nenabling norm-capable agents that can perform a range of tasks such as norm\ndiscovery, normative reasoning and decision-making. This paper examines the\npotential of LLM-based agents to acquire normative capabilities, drawing on\nrecent Natural Language Processing (NLP) and LLM research. We present our\nvision for creating normative LLM agents. In particular, we discuss how the\nrecently proposed \"LLM agent\" approaches can be extended to implement such\nnormative LLM agents. We also highlight challenges in this emerging field. This\npaper thus aims to foster collaboration between MAS, NLP and LLM researchers in\norder to advance the field of normative agents.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "15 pages, 1 figure, presented at the COINE 2024 workshop at AAMAS\n  2024\n  (https://coin-workshop.github.io/coine-2024-auckland/accepted_papers.html).\n  This paper will appear in the post-proceedings of the COINE-2024 workshop",
    "pdf_url": "http://arxiv.org/pdf/2403.16524v2",
    "published_date": "2024-03-25 08:09:01 UTC",
    "updated_date": "2024-10-14 02:20:10 UTC"
  },
  {
    "arxiv_id": "2403.16523v1",
    "title": "Causal Discovery from Poisson Branching Structural Causal Model Using High-Order Cumulant with Path Analysis",
    "authors": [
      "Jie Qiao",
      "Yu Xiang",
      "Zhengming Chen",
      "Ruichu Cai",
      "Zhifeng Hao"
    ],
    "abstract": "Count data naturally arise in many fields, such as finance, neuroscience, and\nepidemiology, and discovering causal structure among count data is a crucial\ntask in various scientific and industrial scenarios. One of the most common\ncharacteristics of count data is the inherent branching structure described by\na binomial thinning operator and an independent Poisson distribution that\ncaptures both branching and noise. For instance, in a population count\nscenario, mortality and immigration contribute to the count, where survival\nfollows a Bernoulli distribution, and immigration follows a Poisson\ndistribution. However, causal discovery from such data is challenging due to\nthe non-identifiability issue: a single causal pair is Markov equivalent, i.e.,\n$X\\rightarrow Y$ and $Y\\rightarrow X$ are distributed equivalent. Fortunately,\nin this work, we found that the causal order from $X$ to its child $Y$ is\nidentifiable if $X$ is a root vertex and has at least two directed paths to\n$Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed\npath to $Y$ without passing $X$. Specifically, we propose a Poisson Branching\nStructure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using\nhigh-order cumulants. Theoretical results establish the connection between the\npath and cumulant and demonstrate that the path information can be obtained\nfrom the cumulant. With the path information, causal order is identifiable\nunder some graphical conditions. A practical algorithm for learning causal\nstructure under PB-SCM is proposed and the experiments demonstrate and verify\nthe effectiveness of the proposed method.",
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "stat.ML",
    "comment": "Accepted by AAAI-2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16523v1",
    "published_date": "2024-03-25 08:06:08 UTC",
    "updated_date": "2024-03-25 08:06:08 UTC"
  },
  {
    "arxiv_id": "2403.16512v5",
    "title": "LLMs Are Few-Shot In-Context Low-Resource Language Learners",
    "authors": [
      "Samuel Cahyawijaya",
      "Holy Lovenia",
      "Pascale Fung"
    ],
    "abstract": "In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages. Our code is publicly\nreleased at https://github.com/SamuelCahyawijaya/in-context-alignment",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16512v5",
    "published_date": "2024-03-25 07:55:29 UTC",
    "updated_date": "2024-06-25 11:54:23 UTC"
  },
  {
    "arxiv_id": "2403.16508v1",
    "title": "Return to Tradition: Learning Reliable Heuristics with Classical Machine Learning",
    "authors": [
      "Dillon Z. Chen",
      "Felipe Trevizan",
      "Sylvie Thiébaux"
    ],
    "abstract": "Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "Extended version of ICAPS 2024 paper",
    "pdf_url": "http://arxiv.org/pdf/2403.16508v1",
    "published_date": "2024-03-25 07:47:52 UTC",
    "updated_date": "2024-03-25 07:47:52 UTC"
  },
  {
    "arxiv_id": "2403.16501v3",
    "title": "Learning To Guide Human Decision Makers With Vision-Language Models",
    "authors": [
      "Debodeep Banerjee",
      "Stefano Teso",
      "Burcu Sayin",
      "Andrea Passerini"
    ],
    "abstract": "There is increasing interest in developing AIs for assisting human\ndecision-making in high-stakes tasks, such as medical diagnosis, for the\npurpose of improving decision quality and reducing cognitive strain. Mainstream\napproaches team up an expert with a machine learning model to which safer\ndecisions are offloaded, thus letting the former focus on cases that demand\ntheir attention. his separation of responsibilities setup, however, is\ninadequate for high-stakes scenarios. On the one hand, the expert may end up\nover-relying on the machine's decisions due to anchoring bias, thus losing the\nhuman oversight that is increasingly being required by regulatory agencies to\nensure trustworthy AI. On the other hand, the expert is left entirely\nunassisted on the (typically hardest) decisions on which the model abstained.\nAs a remedy, we introduce learning to guide (LTG), an alternative framework in\nwhich - rather than taking control from the human expert - the machine provides\nguidance useful for decision making, and the human is entirely responsible for\ncoming up with a decision. In order to ensure guidance is interpretable} and\ntask-specific, we develop SLOG, an approach for turning any vision-language\nmodel into a capable generator of textual guidance by leveraging a modicum of\nhuman feedback. Our empirical evaluation highlights the promise of \\method on a\nchallenging, real-world medical diagnosis task.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16501v3",
    "published_date": "2024-03-25 07:34:42 UTC",
    "updated_date": "2025-01-22 10:21:50 UTC"
  },
  {
    "arxiv_id": "2403.16495v1",
    "title": "LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural Network for Traffic Flow Forecasting",
    "authors": [
      "Qinyao Luo",
      "Silu He",
      "Xing Han",
      "Yuhan Wang",
      "Haifeng Li"
    ],
    "abstract": "Accurate traffic forecasting is a fundamental problem in intelligent\ntransportation systems and learning long-range traffic representations with key\ninformation through spatiotemporal graph neural networks (STGNNs) is a basic\nassumption of current traffic flow prediction models. However, due to\nstructural limitations, existing STGNNs can only utilize short-range traffic\nflow data; therefore, the models cannot adequately learn the complex trends and\nperiodic features in traffic flow. Besides, it is challenging to extract the\nkey temporal information from the long historical traffic series and obtain a\ncompact representation. To solve the above problems, we propose a novel LSTTN\n(Long-Short Term Transformer-based Network) framework comprehensively\nconsidering the long- and short-term features in historical traffic flow.\nFirst, we employ a masked subseries Transformer to infer the content of masked\nsubseries from a small portion of unmasked subseries and their temporal context\nin a pretraining manner, forcing the model to efficiently learn compressed and\ncontextual subseries temporal representations from long historical series.\nThen, based on the learned representations, long-term trend is extracted by\nusing stacked 1D dilated convolution layers, and periodic features are\nextracted by dynamic graph convolution layers. For the difficulties in making\ntime-step level prediction, LSTTN adopts a short-term trend extractor to learn\nfine-grained short-term temporal features. Finally, LSTTN fuses the long-term\ntrend, periodic features and short-term features to obtain the prediction\nresults. Experiments on four real-world datasets show that in 60-minute-ahead\nlong-term forecasting, the LSTTN model achieves a minimum improvement of 5.63\\%\nand a maximum improvement of 16.78\\% over baseline models. The source code is\navailable at https://github.com/GeoX-Lab/LSTTN.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.SI"
    ],
    "primary_category": "cs.LG",
    "comment": "15 pages, 10 figures, 6 tables",
    "pdf_url": "http://arxiv.org/pdf/2403.16495v1",
    "published_date": "2024-03-25 07:23:23 UTC",
    "updated_date": "2024-03-25 07:23:23 UTC"
  },
  {
    "arxiv_id": "2403.16460v2",
    "title": "FedAC: An Adaptive Clustered Federated Learning Framework for Heterogeneous Data",
    "authors": [
      "Yuxin Zhang",
      "Haoyu Chen",
      "Zheng Lin",
      "Zhe Chen",
      "Jin Zhao"
    ],
    "abstract": "Clustered federated learning (CFL) is proposed to mitigate the performance\ndeterioration stemming from data heterogeneity in federated learning (FL) by\ngrouping similar clients for cluster-wise model training. However, current CFL\nmethods struggle due to inadequate integration of global and intra-cluster\nknowledge and the absence of an efficient online model similarity metric, while\ntreating the cluster count as a fixed hyperparameter limits flexibility and\nrobustness. In this paper, we propose an adaptive CFL framework, named FedAC,\nwhich (1) efficiently integrates global knowledge into intra-cluster learning\nby decoupling neural networks and utilizing distinct aggregation methods for\neach submodule, significantly enhancing performance; (2) includes a\ncosteffective online model similarity metric based on dimensionality reduction;\n(3) incorporates a cluster number fine-tuning module for improved adaptability\nand scalability in complex, heterogeneous environments. Extensive experiments\nshow that FedAC achieves superior empirical performance, increasing the test\naccuracy by around 1.82% and 12.67% on CIFAR-10 and CIFAR-100 datasets,\nrespectively, under different non-IID settings compared to SOTA methods.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.DC"
    ],
    "primary_category": "cs.LG",
    "comment": "14 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.16460v2",
    "published_date": "2024-03-25 06:43:28 UTC",
    "updated_date": "2024-03-29 08:46:16 UTC"
  },
  {
    "arxiv_id": "2403.16451v4",
    "title": "DeepMachining: Online Prediction of Machining Errors of Lathe Machines",
    "authors": [
      "Xiang-Li Lu",
      "Hwai-Jung Hsu",
      "Che-Wei Chou",
      "H. T. Kung",
      "Chen-Hsin Lee",
      "Sheng-Mao Cheng"
    ],
    "abstract": "We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16451v4",
    "published_date": "2024-03-25 06:30:54 UTC",
    "updated_date": "2024-03-28 11:36:06 UTC"
  },
  {
    "arxiv_id": "2403.16443v1",
    "title": "CodeS: Natural Language to Code Repository via Multi-Layer Sketch",
    "authors": [
      "Daoguang Zan",
      "Ailun Yu",
      "Wei Liu",
      "Dong Chen",
      "Bo Shen",
      "Wei Li",
      "Yafen Yao",
      "Yongshun Gong",
      "Xiaolin Chen",
      "Bei Guan",
      "Zhiguang Yang",
      "Yongji Wang",
      "Qianxiang Wang",
      "Lizhen Cui"
    ],
    "abstract": "The impressive performance of large language models (LLMs) on code-related\ntasks has shown the potential of fully automated software development. In light\nof this, we introduce a new software engineering task, namely Natural Language\nto code Repository (NL2Repo). This task aims to generate an entire code\nrepository from its natural language requirements. To address this task, we\npropose a simple yet effective framework CodeS, which decomposes NL2Repo into\nmultiple sub-tasks by a multi-layer sketch. Specifically, CodeS includes three\nmodules: RepoSketcher, FileSketcher, and SketchFiller. RepoSketcher first\ngenerates a repository's directory structure for given requirements;\nFileSketcher then generates a file sketch for each file in the generated\nstructure; SketchFiller finally fills in the details for each function in the\ngenerated file sketch. To rigorously assess CodeS on the NL2Repo task, we carry\nout evaluations through both automated benchmarking and manual feedback\nanalysis. For benchmark-based evaluation, we craft a repository-oriented\nbenchmark, SketchEval, and design an evaluation metric, SketchBLEU. For\nfeedback-based evaluation, we develop a VSCode plugin for CodeS and engage 30\nparticipants in conducting empirical studies. Extensive experiments prove the\neffectiveness and practicality of CodeS on the NL2Repo task.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.SE"
    ],
    "primary_category": "cs.CL",
    "comment": "https://github.com/NL2Code/CodeS",
    "pdf_url": "http://arxiv.org/pdf/2403.16443v1",
    "published_date": "2024-03-25 06:09:55 UTC",
    "updated_date": "2024-03-25 06:09:55 UTC"
  },
  {
    "arxiv_id": "2403.16432v3",
    "title": "$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models",
    "authors": [
      "Yue Xu",
      "Wenjie Wang"
    ],
    "abstract": "Prompt-based learning is a new language model training paradigm that adapts\nthe Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes\nthe performance benchmarks across various natural language processing (NLP)\ntasks. Instead of using a fixed prompt template to fine-tune the model, some\nresearch demonstrates the effectiveness of searching for the prompt via\noptimization. Such prompt optimization process of prompt-based learning on PLMs\nalso gives insight into generating adversarial prompts to mislead the model,\nraising concerns about the adversarial vulnerability of this paradigm. Recent\nstudies have shown that universal adversarial triggers (UATs) can be generated\nto alter not only the predictions of the target PLMs but also the prediction of\ncorresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based\nlearning paradigm. However, UATs found in previous works are often unreadable\ntokens or characters and can be easily distinguished from natural texts with\nadaptive defenses. In this work, we consider the naturalness of the UATs and\ndevelop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs\nby a gradient-based beam search algorithm that not only effectively attacks the\ntarget PLMs and PFMs but also maintains the naturalness among the trigger\ntokens. Extensive results demonstrate the effectiveness of\n$\\textit{LinkPrompt}$, as well as the transferability of UATs generated by\n$\\textit{LinkPrompt}$ to open-sourced Large Language Model (LLM) Llama2 and\nAPI-accessed LLM GPT-3.5-turbo. The resource is available at\n$\\href{https://github.com/SavannahXu79/LinkPrompt}{https://github.com/SavannahXu79/LinkPrompt}$.",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted to the main conference of NAACL2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16432v3",
    "published_date": "2024-03-25 05:27:35 UTC",
    "updated_date": "2024-04-09 13:05:49 UTC"
  },
  {
    "arxiv_id": "2403.16431v1",
    "title": "DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding",
    "authors": [
      "Xiaoxuan Yu",
      "Hao Wang",
      "Weiming Li",
      "Qiang Wang",
      "Soonyong Cho",
      "Younghun Sung"
    ],
    "abstract": "Point scene understanding is a challenging task to process real-world scene\npoint cloud, which aims at segmenting each object, estimating its pose, and\nreconstructing its mesh simultaneously. Recent state-of-the-art method first\nsegments each object and then processes them independently with multiple stages\nfor the different sub-tasks. This leads to a complex pipeline to optimize and\nmakes it hard to leverage the relationship constraints between multiple\nobjects. In this work, we propose a novel Disentangled Object-Centric\nTRansformer (DOCTR) that explores object-centric representation to facilitate\nlearning with multiple objects for the multiple sub-tasks in a unified manner.\nEach object is represented as a query, and a Transformer decoder is adapted to\niteratively optimize all the queries involving their relationship. In\nparticular, we introduce a semantic-geometry disentangled query (SGDQ) design\nthat enables the query features to attend separately to semantic information\nand geometric information relevant to the corresponding sub-tasks. A hybrid\nbipartite matching module is employed to well use the supervisions from all the\nsub-tasks during training. Qualitative and quantitative experimental results\ndemonstrate that our method achieves state-of-the-art performance on the\nchallenging ScanNet dataset. Code is available at\nhttps://github.com/SAITPublic/DOCTR.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16431v1",
    "published_date": "2024-03-25 05:22:34 UTC",
    "updated_date": "2024-03-25 05:22:34 UTC"
  },
  {
    "arxiv_id": "2403.16427v4",
    "title": "Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation",
    "authors": [
      "Ziyan Wang",
      "Yingpeng Du",
      "Zhu Sun",
      "Haoyan Chua",
      "Kaidong Feng",
      "Wenya Wang",
      "Jie Zhang"
    ],
    "abstract": "Large Language Models (LLMs) are emerging as promising approaches to enhance\nsession-based recommendation (SBR), where both prompt-based and\nfine-tuning-based methods have been widely investigated to align LLMs with SBR.\nHowever, the former methods struggle with optimal prompts to elicit the correct\nreasoning of LLMs due to the lack of task-specific feedback, leading to\nunsatisfactory recommendations. Although the latter methods attempt to\nfine-tune LLMs with domain-specific knowledge, they face limitations such as\nhigh computational costs and reliance on open-source backbones. To address such\nissues, we propose a Reflective Reinforcement Large Language Model (Re2LLM) for\nSBR, guiding LLMs to focus on specialized knowledge essential for more accurate\nrecommendations effectively and efficiently. In particular, we first design the\nReflective Exploration Module to effectively extract knowledge that is readily\nunderstandable and digestible by LLMs. To be specific, we direct LLMs to\nexamine recommendation errors through self-reflection and construct a knowledge\nbase (KB) comprising hints capable of rectifying these errors. To efficiently\nelicit the correct reasoning of LLMs, we further devise the Reinforcement\nUtilization Module to train a lightweight retrieval agent. It learns to select\nhints from the constructed KB based on the task-specific feedback, where the\nhints can serve as guidance to help correct LLMs reasoning for better\nrecommendations. Extensive experiments on multiple real-world datasets\ndemonstrate that our method consistently outperforms state-of-the-art methods.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 4 figures",
    "pdf_url": "http://arxiv.org/pdf/2403.16427v4",
    "published_date": "2024-03-25 05:12:18 UTC",
    "updated_date": "2024-04-19 16:26:57 UTC"
  },
  {
    "arxiv_id": "2403.16424v3",
    "title": "An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations",
    "authors": [
      "Eric H. C. Chow",
      "TJ Kao",
      "Xiaoli Li"
    ],
    "abstract": "This study delves into the potential use of large language models (LLMs) for\ngenerating Library of Congress Subject Headings (LCSH). The authors employed\nChatGPT to generate subject headings for electronic theses and dissertations\n(ETDs) based on their titles and abstracts. The results suggests that LLMs such\nas ChatGPT have the potential to reduce cataloging time needed for assigning\nLCSH subject terms for ETDs as well as to improve the discovery of this type of\nresource in academic libraries. Nonetheless, human catalogers remain essential\nfor verifying and enhancing the validity, exhaustivity, and specificity of LCSH\ngenerated by LLMs.",
    "categories": [
      "cs.AI",
      "cs.DL",
      "cs.IR"
    ],
    "primary_category": "cs.AI",
    "comment": "23 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.16424v3",
    "published_date": "2024-03-25 05:04:52 UTC",
    "updated_date": "2024-07-10 07:14:32 UTC"
  },
  {
    "arxiv_id": "2403.16422v2",
    "title": "Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation",
    "authors": [
      "Sanyam Lakhanpal",
      "Shivang Chopra",
      "Vinija Jain",
      "Aman Chadha",
      "Man Luo"
    ],
    "abstract": "Over the past few years, Text-to-Image (T2I) generation approaches based on\ndiffusion models have gained significant attention. However, vanilla diffusion\nmodels often suffer from spelling inaccuracies in the text displayed within the\ngenerated images. The capability to generate visual text is crucial, offering\nboth academic interest and a wide range of practical applications. To produce\naccurate visual text images, state-of-the-art techniques adopt a\nglyph-controlled image generation approach, consisting of a text layout\ngenerator followed by an image generator that is conditioned on the generated\ntext layout. Nevertheless, our study reveals that these models still face three\nprimary challenges, prompting us to develop a testbed to facilitate future\nresearch. We introduce a benchmark, LenCom-Eval, specifically designed for\ntesting models' capability in generating images with Lengthy and Complex visual\ntext. Subsequently, we introduce a training-free framework to enhance the\ntwo-stage generation approaches. We examine the effectiveness of our approach\non both LenCom-Eval and MARIO-Eval benchmarks and demonstrate notable\nimprovements across a range of evaluation metrics, including CLIPScore, OCR\nprecision, recall, F1 score, accuracy, and edit distance scores. For instance,\nour proposed framework improves the backbone model, TextDiffuser, by more than\n23\\% and 13.5\\% in terms of OCR word F1 on LenCom-Eval and MARIO-Eval,\nrespectively. Our work makes a unique contribution to the field by focusing on\ngenerating images with long and rare text sequences, a niche previously\nunexplored by existing literature",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "Accepted at WACV 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.16422v2",
    "published_date": "2024-03-25 04:54:49 UTC",
    "updated_date": "2024-10-28 22:11:08 UTC"
  },
  {
    "arxiv_id": "2404.00045v2",
    "title": "Policy Optimization finds Nash Equilibrium in Regularized General-Sum LQ Games",
    "authors": [
      "Muhammad Aneeq uz Zaman",
      "Shubham Aggarwal",
      "Melih Bastopcu",
      "Tamer Başar"
    ],
    "abstract": "In this paper, we investigate the impact of introducing relative entropy\nregularization on the Nash Equilibria (NE) of General-Sum $N$-agent games,\nrevealing the fact that the NE of such games conform to linear Gaussian\npolicies. Moreover, it delineates sufficient conditions, contingent upon the\nadequacy of entropy regularization, for the uniqueness of the NE within the\ngame. As Policy Optimization serves as a foundational approach for\nReinforcement Learning (RL) techniques aimed at finding the NE, in this work we\nprove the linear convergence of a policy optimization algorithm which (subject\nto the adequacy of entropy regularization) is capable of provably attaining the\nNE. Furthermore, in scenarios where the entropy regularization proves\ninsufficient, we present a $\\delta$-augmentation technique, which facilitates\nthe achievement of an $\\epsilon$-NE within the game.",
    "categories": [
      "cs.GT",
      "cs.AI",
      "cs.LG",
      "cs.MA"
    ],
    "primary_category": "cs.GT",
    "comment": "Accepted for Conference on Decision and Control 2024",
    "pdf_url": "http://arxiv.org/pdf/2404.00045v2",
    "published_date": "2024-03-25 04:45:28 UTC",
    "updated_date": "2024-09-13 16:59:00 UTC"
  },
  {
    "arxiv_id": "2403.16418v2",
    "title": "An Incremental MaxSAT-based Model to Learn Interpretable and Balanced Classification Rules",
    "authors": [
      "Antônio Carlos Souza Ferreira Júnior",
      "Thiago Alves Rocha"
    ],
    "abstract": "The increasing advancements in the field of machine learning have led to the\ndevelopment of numerous applications that effectively address a wide range of\nproblems with accurate predictions. However, in certain cases, accuracy alone\nmay not be sufficient. Many real-world problems also demand explanations and\ninterpretability behind the predictions. One of the most popular interpretable\nmodels that are classification rules. This work aims to propose an incremental\nmodel for learning interpretable and balanced rules based on MaxSAT, called\nIMLIB. This new model was based on two other approaches, one based on SAT and\nthe other on MaxSAT. The one based on SAT limits the size of each generated\nrule, making it possible to balance them. We suggest that such a set of rules\nseem more natural to be understood compared to a mixture of large and small\nrules. The approach based on MaxSAT, called IMLI, presents a technique to\nincrease performance that involves learning a set of rules by incrementally\napplying the model in a dataset. Finally, IMLIB and IMLI are compared using\ndiverse databases. IMLIB obtained results comparable to IMLI in terms of\naccuracy, generating more balanced rules with smaller sizes.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.LO",
      "I.2.4; I.2.6"
    ],
    "primary_category": "cs.LG",
    "comment": "16 pages, 5 tables, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195",
    "pdf_url": "http://arxiv.org/pdf/2403.16418v2",
    "published_date": "2024-03-25 04:43:47 UTC",
    "updated_date": "2024-04-29 13:00:21 UTC"
  },
  {
    "arxiv_id": "2403.16416v1",
    "title": "How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation",
    "authors": [
      "Lixi Zhu",
      "Xiaowen Huang",
      "Jitao Sang"
    ],
    "abstract": "Conversational Recommender System (CRS) interacts with users through natural\nlanguage to understand their preferences and provide personalized\nrecommendations in real-time. CRS has demonstrated significant potential,\nprompting researchers to address the development of more realistic and reliable\nuser simulators as a key focus. Recently, the capabilities of Large Language\nModels (LLMs) have attracted a lot of attention in various fields.\nSimultaneously, efforts are underway to construct user simulators based on\nLLMs. While these works showcase innovation, they also come with certain\nlimitations that require attention. In this work, we aim to analyze the\nlimitations of using LLMs in constructing user simulators for CRS, to guide\nfuture research. To achieve this goal, we conduct analytical validation on the\nnotable work, iEvaLM. Through multiple experiments on two widely-used datasets\nin the field of conversational recommendation, we highlight several issues with\nthe current evaluation methods for user simulators based on LLMs: (1) Data\nleakage, which occurs in conversational history and the user simulator's\nreplies, results in inflated evaluation results. (2) The success of CRS\nrecommendations depends more on the availability and quality of conversational\nhistory than on the responses from user simulators. (3) Controlling the output\nof the user simulator through a single prompt template proves challenging. To\novercome these limitations, we propose SimpleUserSim, employing a\nstraightforward strategy to guide the topic toward the target items. Our study\nvalidates the ability of CRS models to utilize the interaction information,\nsignificantly improving the recommendation results.",
    "categories": [
      "cs.AI"
    ],
    "primary_category": "cs.AI",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16416v1",
    "published_date": "2024-03-25 04:21:06 UTC",
    "updated_date": "2024-03-25 04:21:06 UTC"
  },
  {
    "arxiv_id": "2403.16398v1",
    "title": "Rethinking the Representation in Federated Unsupervised Learning with Non-IID Data",
    "authors": [
      "Xinting Liao",
      "Weiming Liu",
      "Chaochao Chen",
      "Pengyang Zhou",
      "Fengyuan Yu",
      "Huabin Zhu",
      "Binhui Yao",
      "Tao Wang",
      "Xiaolin Zheng",
      "Yanchao Tan"
    ],
    "abstract": "Federated learning achieves effective performance in modeling decentralized\ndata. In practice, client data are not well-labeled, which makes it potential\nfor federated unsupervised learning (FUSL) with non-IID data. However, the\nperformance of existing FUSL methods suffers from insufficient representations,\ni.e., (1) representation collapse entanglement among local and global models,\nand (2) inconsistent representation spaces among local models. The former\nindicates that representation collapse in local model will subsequently impact\nthe global model and other local models. The latter means that clients model\ndata representation with inconsistent parameters due to the deficiency of\nsupervision signals. In this work, we propose FedU2 which enhances generating\nuniform and unified representation in FUSL with non-IID data. Specifically,\nFedU2 consists of flexible uniform regularizer (FUR) and efficient unified\naggregator (EUA). FUR in each client avoids representation collapse via\ndispersing samples uniformly, and EUA in server promotes unified representation\nby constraining consistent client model updating. To extensively validate the\nperformance of FedU2, we conduct both cross-device and cross-silo evaluation\nexperiments on two benchmark datasets, i.e., CIFAR10 and CIFAR100.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "CVPR 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16398v1",
    "published_date": "2024-03-25 03:26:01 UTC",
    "updated_date": "2024-03-25 03:26:01 UTC"
  },
  {
    "arxiv_id": "2403.16397v2",
    "title": "RadioGAT: A Joint Model-based and Data-driven Framework for Multi-band Radiomap Reconstruction via Graph Attention Networks",
    "authors": [
      "Xiaojie Li",
      "Songyang Zhang",
      "Hang Li",
      "Xiaoyang Li",
      "Lexi Xu",
      "Haigao Xu",
      "Hui Mei",
      "Guangxu Zhu",
      "Nan Qi",
      "Ming Xiao"
    ],
    "abstract": "Multi-band radiomap reconstruction (MB-RMR) is a key component in wireless\ncommunications for tasks such as spectrum management and network planning.\nHowever, traditional machine-learning-based MB-RMR methods, which rely heavily\non simulated data or complete structured ground truth, face significant\ndeployment challenges. These challenges stem from the differences between\nsimulated and actual data, as well as the scarcity of real-world measurements.\nTo address these challenges, our study presents RadioGAT, a novel framework\nbased on Graph Attention Network (GAT) tailored for MB-RMR within a single\narea, eliminating the need for multi-region datasets. RadioGAT innovatively\nmerges model-based spatial-spectral correlation encoding with data-driven\nradiomap generalization, thus minimizing the reliance on extensive data\nsources. The framework begins by transforming sparse multi-band data into a\ngraph structure through an innovative encoding strategy that leverages radio\npropagation models to capture the spatial-spectral correlation inherent in the\ndata. This graph-based representation not only simplifies data handling but\nalso enables tailored label sampling during training, significantly enhancing\nthe framework's adaptability for deployment. Subsequently, The GAT is employed\nto generalize the radiomap information across various frequency bands.\nExtensive experiments using raytracing datasets based on real-world\nenvironments have demonstrated RadioGAT's enhanced accuracy in supervised\nlearning settings and its robustness in semi-supervised scenarios. These\nresults underscore RadioGAT's effectiveness and practicality for MB-RMR in\nenvironments with limited data availability.",
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "primary_category": "eess.SP",
    "comment": "IEEE Transactions on Wireless Communications, early access, 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16397v2",
    "published_date": "2024-03-25 03:23:10 UTC",
    "updated_date": "2024-07-29 12:18:15 UTC"
  },
  {
    "arxiv_id": "2404.00044v2",
    "title": "UAlign: Pushing the Limit of Template-free Retrosynthesis Prediction with Unsupervised SMILES Alignment",
    "authors": [
      "Kaipeng Zeng",
      "Bo yang",
      "Xin Zhao",
      "Yu Zhang",
      "Fan Nie",
      "Xiaokang Yang",
      "Yaohui Jin",
      "Yanyan Xu"
    ],
    "abstract": "Motivation: Retrosynthesis planning poses a formidable challenge in the\norganic chemical industry. Single-step retrosynthesis prediction, a crucial\nstep in the planning process, has witnessed a surge in interest in recent years\ndue to advancements in AI for science. Various deep learning-based methods have\nbeen proposed for this task in recent years, incorporating diverse levels of\nadditional chemical knowledge dependency.\n  Results: This paper introduces UAlign, a template-free graph-to-sequence\npipeline for retrosynthesis prediction. By combining graph neural networks and\nTransformers, our method can more effectively leverage the inherent graph\nstructure of molecules. Based on the fact that the majority of molecule\nstructures remain unchanged during a chemical reaction, we propose a simple yet\neffective SMILES alignment technique to facilitate the reuse of unchanged\nstructures for reactant generation. Extensive experiments show that our method\nsubstantially outperforms state-of-the-art template-free and\nsemi-template-based approaches. Importantly, our template-free method achieves\neffectiveness comparable to, or even surpasses, established powerful\ntemplate-based methods.\n  Scientific contribution: We present a novel graph-to-sequence template-free\nretrosynthesis prediction pipeline that overcomes the limitations of\nTransformer-based methods in molecular representation learning and insufficient\nutilization of chemical information. We propose an unsupervised learning\nmechanism for establishing product-atom correspondence with reactant SMILES\ntokens, achieving even better results than supervised SMILES alignment methods.\nExtensive experiments demonstrate that UAlign significantly outperforms\nstate-of-the-art template-free methods and rivals or surpasses template-based\napproaches, with up to 5\\% (top-5) and 5.4\\% (top-10) increased accuracy over\nthe strongest baseline.",
    "categories": [
      "physics.chem-ph",
      "cs.AI",
      "cs.LG",
      "q-bio.QM"
    ],
    "primary_category": "physics.chem-ph",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2404.00044v2",
    "published_date": "2024-03-25 03:23:03 UTC",
    "updated_date": "2024-04-19 09:52:52 UTC"
  },
  {
    "arxiv_id": "2403.16393v1",
    "title": "Concurrent Linguistic Error Detection (CLED) for Large Language Models",
    "authors": [
      "Jinhua Zhu",
      "Javier Conde",
      "Zhen Gao",
      "Pedro Reviriego",
      "Shanshan Liu",
      "Fabrizio Lombardi"
    ],
    "abstract": "The wide adoption of Large language models (LLMs) makes their dependability a\npressing concern. Detection of errors is the first step to mitigating their\nimpact on a system and thus, efficient error detection for LLMs is an important\nissue. In many settings, the LLM is considered as a black box with no access to\nthe internal nodes; this prevents the use of many error detection schemes that\nneed access to the model's internal nodes. An interesting observation is that\nthe output of LLMs in error-free operation should be valid and normal text.\nTherefore, when the text is not valid or differs significantly from normal\ntext, it is likely that there is an error. Based on this observation we propose\nto perform Concurrent Linguistic Error Detection (CLED); this scheme extracts\nsome linguistic features of the text generated by the LLM and feeds them to a\nconcurrent classifier that detects errors. Since the proposed error detection\nmechanism only relies on the outputs of the model, then it can be used on LLMs\nin which there is no access to the internal nodes. The proposed CLED scheme has\nbeen evaluated on the T5 model when used for news summarization and on the\nOPUS-MT model when used for translation. In both cases, the same set of\nlinguistic features has been used for error detection to illustrate the\napplicability of the proposed scheme beyond a specific case. The results show\nthat CLED can detect most of the errors at a low overhead penalty. The use of\nthe concurrent classifier also enables a trade-off between error detection\neffectiveness and its associated overhead, so providing flexibility to a\ndesigner.",
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "primary_category": "cs.AI",
    "comment": "11 pages, 6 figures, 30 references",
    "pdf_url": "http://arxiv.org/pdf/2403.16393v1",
    "published_date": "2024-03-25 03:17:27 UTC",
    "updated_date": "2024-03-25 03:17:27 UTC"
  },
  {
    "arxiv_id": "2403.16386v1",
    "title": "Dia-LLaMA: Towards Large Language Model-driven CT Report Generation",
    "authors": [
      "Zhixuan Chen",
      "Luyang Luo",
      "Yequan Bie",
      "Hao Chen"
    ],
    "abstract": "Medical report generation has achieved remarkable advancements yet has still\nbeen faced with several challenges. First, the inherent imbalance in the\ndistribution of normal and abnormal cases may lead models to exhibit a biased\nfocus on normal samples, resulting in unreliable diagnoses. Second, the\nfrequent occurrence of common template sentences in the reports may overwhelm\nthe critical abnormal information. Moreover, existing works focus on 2D chest\nX-rays, leaving CT report generation underexplored due to the high-dimensional\nnature of CT images and the limited availability of CT-report pairs. Recently,\nLLM has shown a great ability to generate reliable answers with appropriate\nprompts, which shed light on addressing the aforementioned challenges. In this\npaper, we propose Dia-LLaMA, a framework to adapt the LLaMA2-7B for CT report\ngeneration by incorporating diagnostic information as guidance prompts.\nConsidering the high dimension of CT, we leverage a pre-trained ViT3D with\nperceiver to extract the visual information. To tailor the LLM for report\ngeneration and emphasize abnormality, we extract additional diagnostic\ninformation by referring to a disease prototype memory bank, which is updated\nduring training to capture common disease representations. Furthermore, we\nintroduce disease-aware attention to enable the model to adjust attention for\ndifferent diseases. Experiments on the chest CT dataset demonstrated that our\nproposed method outperformed previous methods and achieved state-of-the-art on\nboth clinical efficacy performance and natural language generation metrics. The\ncode will be made publically available.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "10 pages",
    "pdf_url": "http://arxiv.org/pdf/2403.16386v1",
    "published_date": "2024-03-25 03:02:51 UTC",
    "updated_date": "2024-03-25 03:02:51 UTC"
  },
  {
    "arxiv_id": "2404.08656v1",
    "title": "Linear Cross-document Event Coreference Resolution with X-AMR",
    "authors": [
      "Shafiuddin Rehan Ahmed",
      "George Arthur Baker",
      "Evi Judge",
      "Michael Regan",
      "Kristin Wright-Bettner",
      "Martha Palmer",
      "James H. Martin"
    ],
    "abstract": "Event Coreference Resolution (ECR) as a pairwise mention classification task\nis expensive both for automated systems and manual annotations. The task's\nquadratic difficulty is exacerbated when using Large Language Models (LLMs),\nmaking prompt engineering for ECR prohibitively costly. In this work, we\npropose a graphical representation of events, X-AMR, anchored around individual\nmentions using a \\textbf{cross}-document version of \\textbf{A}bstract\n\\textbf{M}eaning \\textbf{R}epresentation. We then linearize the ECR with a\nnovel multi-hop coreference algorithm over the event graphs. The event graphs\nsimplify ECR, making it a) LLM cost-effective, b) compositional and\ninterpretable, and c) easily annotated. For a fair assessment, we first enrich\nan existing ECR benchmark dataset with these event graphs using an\nannotator-friendly tool we introduce. Then, we employ GPT-4, the newest LLM by\nOpenAI, for these annotations. Finally, using the ECR algorithm, we assess\nGPT-4 against humans and analyze its limitations. Through this research, we aim\nto advance the state-of-the-art for efficient ECR and shed light on the\npotential shortcomings of current LLMs at this task. Code and annotations:\n\\url{https://github.com/ahmeshaf/gpt_coref}",
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "primary_category": "cs.CL",
    "comment": "LREC-COLING 2024 main conference",
    "pdf_url": "http://arxiv.org/pdf/2404.08656v1",
    "published_date": "2024-03-25 02:49:06 UTC",
    "updated_date": "2024-03-25 02:49:06 UTC"
  },
  {
    "arxiv_id": "2406.11844v1",
    "title": "Prompting the E-Brushes: Users as Authors in Generative AI",
    "authors": [
      "Yiyang Mei"
    ],
    "abstract": "Since its introduction in 2022, Generative AI has significantly impacted the\nart world, from winning state art fairs to creating complex videos from simple\nprompts. Amid this renaissance, a pivotal issue emerges: should users of\nGenerative AI be recognized as authors eligible for copyright protection? The\nCopyright Office, in its March 2023 Guidance, argues against this notion. By\ncomparing the prompts to clients' instructions for commissioned art, the Office\ndenies users authorship due to their limited role in the creative process. This\nArticle challenges this viewpoint and advocates for the recognition of\nGenerative AI users who incorporate these tools into their creative endeavors.\nIt argues that the current policy fails to consider the intricate and dynamic\ninteraction between Generative AI users and the models, where users actively\ninfluence the output through a process of adjustment, refinement, selection,\nand arrangement. Rather than dismissing the contributions generated by AI, this\nArticle suggests a simplified and streamlined registration process that\nacknowledges the role of AI in creation. This approach not only aligns with the\nconstitutional goal of promoting the progress of science and useful arts but\nalso encourages public engagement in the creative process, which contributes to\nthe pool of training data for AI. Moreover, it advocates for a flexible\nframework that evolves alongside technological advancements while ensuring\nsafety and public interest. In conclusion, by examining text-to-image\ngenerators and addressing misconceptions about Generative AI and user\ninteraction, this Article calls for a regulatory framework that adapts to\ntechnological developments and safeguards public interests",
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "primary_category": "cs.CY",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2406.11844v1",
    "published_date": "2024-03-25 02:20:14 UTC",
    "updated_date": "2024-03-25 02:20:14 UTC"
  },
  {
    "arxiv_id": "2403.16369v3",
    "title": "Learning Action-based Representations Using Invariance",
    "authors": [
      "Max Rudolph",
      "Caleb Chuck",
      "Kevin Black",
      "Misha Lvovsky",
      "Scott Niekum",
      "Amy Zhang"
    ],
    "abstract": "Robust reinforcement learning agents using high-dimensional observations must\nbe able to identify relevant state features amidst many exogeneous distractors.\nA representation that captures controllability identifies these state elements\nby determining what affects agent control. While methods such as inverse\ndynamics and mutual information capture controllability for a limited number of\ntimesteps, capturing long-horizon elements remains a challenging problem.\nMyopic controllability can capture the moment right before an agent crashes\ninto a wall, but not the control-relevance of the wall while the agent is still\nsome distance away. To address this we introduce action-bisimulation encoding,\na method inspired by the bisimulation invariance pseudometric, that extends\nsingle-step controllability with a recursive invariance constraint. By doing\nthis, action-bisimulation learns a multi-step controllability metric that\nsmoothly discounts distant state features that are relevant for control. We\ndemonstrate that action-bisimulation pretraining on reward-free, uniformly\nrandom data improves sample efficiency in several environments, including a\nphotorealistic 3D simulation domain, Habitat. Additionally, we provide\ntheoretical analysis and qualitative results demonstrating the information\ncaptured by action-bisimulation.",
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "primary_category": "cs.LG",
    "comment": "Published at the Reinforcement Learning Conference 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16369v3",
    "published_date": "2024-03-25 02:17:54 UTC",
    "updated_date": "2024-06-24 13:19:17 UTC"
  },
  {
    "arxiv_id": "2403.16354v4",
    "title": "ChatDBG: Augmenting Debugging with Large Language Models",
    "authors": [
      "Kyla H. Levin",
      "Nicolas van Kempen",
      "Emery D. Berger",
      "Stephen N. Freund"
    ],
    "abstract": "Debugging is a critical but challenging task for programmers. This paper\nproposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large\nlanguage models (LLMs) to significantly enhance the capabilities and\nuser-friendliness of conventional debuggers. ChatDBG lets programmers engage in\na collaborative dialogue with the debugger, allowing them to pose complex\nquestions about program state, perform root cause analysis for crashes or\nassertion failures, and explore open-ended queries like \"why is x null?\". To\nhandle these queries, ChatDBG grants the LLM autonomy to \"take the wheel\": it\ncan act as an independent agent capable of querying and controlling the\ndebugger to navigate through stacks and inspect program state. It then reports\nits findings and yields back control to the programmer. By leveraging the\nreal-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable\nonly through the use of domain-specific reasoning. Our ChatDBG prototype\nintegrates with standard debuggers including LLDB and GDB for native code and\nPdb for Python. Our evaluation across a diverse set of code, including C/C++\ncode with known bugs and a suite of Python code including standalone scripts\nand Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root\ncauses, explain bugs, and generate accurate fixes for a wide range of\nreal-world errors. For the Python programs, a single query led to an actionable\nbug fix 67% of the time; one additional follow-up query increased the success\nrate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more\nthan 75,000 times.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG",
      "cs.PL"
    ],
    "primary_category": "cs.SE",
    "comment": "22 pages, to appear at FSE 2025",
    "pdf_url": "http://arxiv.org/pdf/2403.16354v4",
    "published_date": "2024-03-25 01:12:57 UTC",
    "updated_date": "2025-04-23 15:48:42 UTC"
  },
  {
    "arxiv_id": "2403.16347v1",
    "title": "ChatGPT Incorrectness Detection in Software Reviews",
    "authors": [
      "Minaoar Hossain Tanzil",
      "Junaed Younus Khan",
      "Gias Uddin"
    ],
    "abstract": "We conducted a survey of 135 software engineering (SE) practitioners to\nunderstand how they use Generative AI-based chatbots like ChatGPT for SE tasks.\nWe find that they want to use ChatGPT for SE tasks like software library\nselection but often worry about the truthfulness of ChatGPT responses. We\ndeveloped a suite of techniques and a tool called CID (ChatGPT Incorrectness\nDetector) to automatically test and detect the incorrectness in ChatGPT\nresponses. CID is based on the iterative prompting to ChatGPT by asking it\ncontextually similar but textually divergent questions (using an approach that\nutilizes metamorphic relationships in texts). The underlying principle in CID\nis that for a given question, a response that is different from other responses\n(across multiple incarnations of the question) is likely an incorrect response.\nIn a benchmark study of library selection, we show that CID can detect\nincorrect responses from ChatGPT with an F1-score of 0.74 - 0.75.",
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.LG"
    ],
    "primary_category": "cs.SE",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16347v1",
    "published_date": "2024-03-25 00:50:27 UTC",
    "updated_date": "2024-03-25 00:50:27 UTC"
  },
  {
    "arxiv_id": "2403.16345v1",
    "title": "Enhanced Facet Generation with LLM Editing",
    "authors": [
      "Joosung Lee",
      "Jinhong Kim"
    ],
    "abstract": "In information retrieval, facet identification of a user query is an\nimportant task. If a search service can recognize the facets of a user's query,\nit has the potential to offer users a much broader range of search results.\nPrevious studies can enhance facet prediction by leveraging retrieved documents\nand related queries obtained through a search engine. However, there are\nchallenges in extending it to other applications when a search engine operates\nas part of the model. First, search engines are constantly updated. Therefore,\nadditional information may change during training and test, which may reduce\nperformance. The second challenge is that public search engines cannot search\nfor internal documents. Therefore, a separate search system needs to be built\nto incorporate documents from private domains within the company. We propose\ntwo strategies that focus on a framework that can predict facets by taking only\nqueries as input without a search engine. The first strategy is multi-task\nlearning to predict SERP. By leveraging SERP as a target instead of a source,\nthe proposed model deeply understands queries without relying on external\nmodules. The second strategy is to enhance the facets by combining Large\nLanguage Model (LLM) and the small model. Overall performance improves when\nsmall model and LLM are combined rather than facet generation individually.",
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "primary_category": "cs.CL",
    "comment": "Accepted at LREC-COLING 2024",
    "pdf_url": "http://arxiv.org/pdf/2403.16345v1",
    "published_date": "2024-03-25 00:43:44 UTC",
    "updated_date": "2024-03-25 00:43:44 UTC"
  },
  {
    "arxiv_id": "2403.16338v1",
    "title": "Impact of Video Compression Artifacts on Fisheye Camera Visual Perception Tasks",
    "authors": [
      "Madhumitha Sakthi",
      "Louis Kerofsky",
      "Varun Ravi Kumar",
      "Senthil Yogamani"
    ],
    "abstract": "Autonomous driving systems require extensive data collection schemes to cover\nthe diverse scenarios needed for building a robust and safe system. The data\nvolumes are in the order of Exabytes and have to be stored for a long period of\ntime (i.e., more than 10 years of the vehicle's life cycle). Lossless\ncompression doesn't provide sufficient compression ratios, hence, lossy video\ncompression has been explored. It is essential to prove that lossy video\ncompression artifacts do not impact the performance of the perception\nalgorithms. However, there is limited work in this area to provide a solid\nconclusion. In particular, there is no such work for fisheye cameras, which\nhave high radial distortion and where compression may have higher artifacts.\nFisheye cameras are commonly used in automotive systems for 3D object detection\ntask. In this work, we provide the first analysis of the impact of standard\nvideo compression codecs on wide FOV fisheye camera images. We demonstrate that\nthe achievable compression with negligible impact depends on the dataset and\ntemporal prediction of the video codec. We propose a radial distortion-aware\nzonal metric to evaluate the performance of artifacts in fisheye images. In\naddition, we present a novel method for estimating affine mode parameters of\nthe latest VVC codec, and suggest some areas for improvement in video codecs\nfor the application to fisheye imagery.",
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "primary_category": "cs.CV",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16338v1",
    "published_date": "2024-03-25 00:24:10 UTC",
    "updated_date": "2024-03-25 00:24:10 UTC"
  },
  {
    "arxiv_id": "2403.16334v1",
    "title": "Graphs Generalization under Distribution Shifts",
    "authors": [
      "Qin Tian",
      "Wenjun Wang",
      "Chen Zhao",
      "Minglai Shao",
      "Wang Zhang",
      "Dong Li"
    ],
    "abstract": "Traditional machine learning methods heavily rely on the independent and\nidentically distribution assumption, which imposes limitations when the test\ndistribution deviates from the training distribution. To address this crucial\nissue, out-of-distribution (OOD) generalization, which aims to achieve\nsatisfactory generalization performance when faced with unknown distribution\nshifts, has made a significant process. However, the OOD method for\ngraph-structured data currently lacks clarity and remains relatively unexplored\ndue to two primary challenges. Firstly, distribution shifts on graphs often\noccur simultaneously on node attributes and graph topology. Secondly, capturing\ninvariant information amidst diverse distribution shifts proves to be a\nformidable challenge. To overcome these obstacles, in this paper, we introduce\na novel framework, namely Graph Learning Invariant Domain genERation (GLIDER).\nThe goal is to (1) diversify variations across domains by modeling the\npotential seen or unseen variations of attribute distribution and topological\nstructure and (2) minimize the discrepancy of the variation in a representation\nspace where the target is to predict semantic labels. Extensive experiment\nresults indicate that our model outperforms baseline methods on node-level OOD\ngeneralization across domains in distribution shift on node features and\ntopological structures simultaneously.",
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "primary_category": "cs.LG",
    "comment": "",
    "pdf_url": "http://arxiv.org/pdf/2403.16334v1",
    "published_date": "2024-03-25 00:15:34 UTC",
    "updated_date": "2024-03-25 00:15:34 UTC"
  }
]