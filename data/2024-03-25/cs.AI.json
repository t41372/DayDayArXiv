{
  "date": "2024-03-25",
  "category": "cs.AI",
  "summary": "欢迎来到 UTC 时间 2024-03-25 的 arXiv 中文 TLDR 快报！今天 arXiv 更新了 120 篇论文，主要聚焦 AI、机器学习、强化学习和 LLMs 在决策、生成和优化中的创新应用，令人印象深刻的是多代理系统和 LLMs 框架（如 RepairAgent 和 MetaAligner），以及知名学者如 H. Vincent Poor 等参与的分布式计算工作。\n\n### 重点论文讨论\n我挑选了最具话题性和影响力的论文先聊，包括 LLMs 在代码生成和决策中的新进展，以及强化学习在机器人和规划中的应用。其他论文如语音生成和图神经网络等也会简要提及。\n\n1. **RepairAgent: An Autonomous, LLM-Based Agent for Program Repair（RepairAgent: 一个基于 LLMs 的自治代理用于程序修复）**  \n   本文提出 RepairAgent，一个基于 LLMs 的自治代理，用于自动化程序修复。它通过工具调用（如信息收集和验证）自主规划修复步骤，实现对 Defects4J 数据集的 164 个 bug 的修复，优于现有技术。主要贡献是首次将 LLMs 作为代理用于程序修复，发现其能高效处理复杂 bug，但成本约为每 bug 0.14 美元。\n\n2. **MetaAligner: Towards Generalizable Multi-Objective Alignment of Language Models（MetaAligner: 面向通用化多目标语言模型对齐）**  \n   作者包括 Sophia Ananiadou 等知名学者，论文引入 MetaAligner 框架，使用弱到强校正范式和动态目标重构，实现 LLMs 的多目标偏好对齐。无需微调模型，即可处理新目标。主要发现是它在 10 个任务上提升模型性能，同时节省高达 93.63% 的 GPU 训练时间，证明了 LLMs 在泛化对齐中的潜力。\n\n3. **DASA: Delay-Adaptive Multi-Agent Stochastic Approximation（DASA: 延迟自适应多代理随机逼近）**  \n   作者包括 H. Vincent Poor、Sanjeev R. Kulkarni 和 George J. Pappas 等知名专家，论文提出 DASA 算法，用于多代理随机逼近问题。它在延迟和马尔科夫采样下实现 N 倍加速收敛，主要贡献是首次依赖平均延迟和混合时间，提供适用于分布式 TD 学习和 Q 学习的理论保证。\n\n4. **TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models（TwoStep: 使用经典规划器和 LLMs 的多代理任务规划）**  \n   本文结合经典 PDDL 规划和 LLMs，实现多代理任务分解和并行执行。相比单代理规划，它减少执行步骤并加速规划。主要发现是 LLMs 的目标分解能模拟人类直觉，提高任务效率。\n\n5. **CodeS: Natural Language to Code Repository via Multi-Layer Sketch（CodeS: 通过多层草图的自然语言到代码仓库生成）**  \n   论文提出 CodeS 框架，将自然语言需求转化为完整代码仓库，使用多层草图（RepoSketcher、FileSketcher 和 SketchFiller）。主要贡献是自动化代码生成过程，发现它在真实数据集上超越模板方法，适用于软件开发。\n\n6. **Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking（通过强化学习加速 MCTS 的自动停车路径规划）**  \n   本文整合强化学习到 Monte Carlo Tree Search (MCTS)，用于复杂环境下的自动停车。关键发现是它在不依赖专家数据的情况下加速规划，同时保持路径质量，适用于 IROS 2024 场景。\n\n7. **VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild（VoiceCraft: 零样本野外语音编辑和文本到语音生成）**  \n   论文引入 VoiceCraft，使用神经编解码器实现零样本语音编辑和 TTS。主要贡献是它在真实音频上生成高质量语音，优于现有模型，代码和数据已开源。\n\n### 其他论文简评\n其余论文涉及 AI 伦理、图神经网络和计算机视觉等领域，但许多是基础或应用性较弱的扩展工作，我快速掠过：\n\n- **Exploring CausalWorld: Enhancing robotic manipulation via knowledge transfer and curriculum learning（Exploring CausalWorld: 通过知识转移和课程学习增强机器人操作）**：使用强化学习改进三指机器人臂操作，贡献在于知识转移策略提升效率。\n\n- **DreamPolisher: Towards High-Quality Text-to-3D Generation via Geometric Diffusion（DreamPolisher: 通过几何扩散实现高质量文本到 3D 生成）**：提出基于 Gaussian Splatting 的文本到 3D 方法，提高生成一致性和细节。\n\n- **Uncertainty Quantification for Gradient-based Explanations in Neural Networks（神经网络梯度解释的不确定性量化）**：量化解释方法的 uncertainty，贡献在于评估解释可靠性。\n\n- **Generation of Asset Administration Shell with Large Language Model Agents（使用 LLMs 代理生成资产管理外壳）**：LLMs 用于工业数字孪生，贡献在于语义互操作性。\n\n- 其他如光谱群机器人、图表示学习和语音模型等论文（如第38、15、9篇）虽有创新，但主题较 niche 或实验性强，未列出以控篇幅。\n\n今天的 arXiv 快报聚焦 AI 实用性，LLMs 和强化学习领域有突破性进展，值得跟踪！如果有特定兴趣，建议查阅上述关键论文。",
  "papers": [
    {
      "arxiv_id": "2403.17266v1",
      "title": "Exploring CausalWorld: Enhancing robotic manipulation via knowledge transfer and curriculum learning",
      "title_zh": "翻译失败",
      "authors": [
        "Xinrui Wang",
        "Yan Jin"
      ],
      "abstract": "This study explores a learning-based tri-finger robotic arm manipulating\ntask, which requires complex movements and coordination among the fingers. By\nemploying reinforcement learning, we train an agent to acquire the necessary\nskills for proficient manipulation. To enhance the efficiency and effectiveness\nof the learning process, two knowledge transfer strategies, fine-tuning and\ncurriculum learning, were utilized within the soft actor-critic architecture.\nFine-tuning allows the agent to leverage pre-trained knowledge and adapt it to\nnew tasks. Several variations like model transfer, policy transfer, and\nacross-task transfer were implemented and evaluated. To eliminate the need for\npretraining, curriculum learning decomposes the advanced task into simpler,\nprogressive stages, mirroring how humans learn. The number of learning stages,\nthe context of the sub-tasks, and the transition timing were found to be the\ncritical design parameters. The key factors of two learning strategies and\ncorresponding effects were explored in context-aware and context-unaware\nscenarios, enabling us to identify the scenarios where the methods demonstrate\noptimal performance, derive conclusive insights, and contribute to a broader\nrange of learning-based engineering applications.",
      "tldr_zh": "本研究探讨了在CausalWorld环境中，通过知识转移和课程学习（curriculum learning）提升三指机器人臂的操纵能力。研究采用强化学习（reinforcement learning）中的soft actor-critic架构，训练代理处理复杂的运动协调任务；其中，fine-tuning策略（如model transfer、policy transfer和across-task transfer）利用预训练知识适应新任务，而curriculum learning则将高级任务分解为渐进式子任务，模拟人类学习过程。关键参数包括学习阶段数、子任务上下文和转换时机，通过在context-aware和context-unaware场景中的实验，研究识别了这些策略的最佳应用场景，并为更广泛的学习工程应用提供了宝贵见解。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17266v1",
      "published_date": "2024-03-25 23:19:19 UTC",
      "updated_date": "2024-03-25 23:19:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:29:33.338926"
    },
    {
      "arxiv_id": "2403.17247v3",
      "title": "DASA: Delay-Adaptive Multi-Agent Stochastic Approximation",
      "title_zh": "翻译失败",
      "authors": [
        "Nicolò Dal Fabbro",
        "Arman Adibi",
        "H. Vincent Poor",
        "Sanjeev R. Kulkarni",
        "Aritra Mitra",
        "George J. Pappas"
      ],
      "abstract": "We consider a setting in which $N$ agents aim to speedup a common Stochastic\nApproximation (SA) problem by acting in parallel and communicating with a\ncentral server. We assume that the up-link transmissions to the server are\nsubject to asynchronous and potentially unbounded time-varying delays. To\nmitigate the effect of delays and stragglers while reaping the benefits of\ndistributed computation, we propose \\texttt{DASA}, a Delay-Adaptive algorithm\nfor multi-agent Stochastic Approximation. We provide a finite-time analysis of\n\\texttt{DASA} assuming that the agents' stochastic observation processes are\nindependent Markov chains. Significantly advancing existing results,\n\\texttt{DASA} is the first algorithm whose convergence rate depends only on the\nmixing time $\\tau_{mix}$ and on the average delay $\\tau_{avg}$ while jointly\nachieving an $N$-fold convergence speedup under Markovian sampling. Our work is\nrelevant for various SA applications, including multi-agent and distributed\ntemporal difference (TD) learning, Q-learning and stochastic optimization with\ncorrelated data.",
      "tldr_zh": "本研究针对多代理随机逼近(Stochastic Approximation)问题，提出DASA算法，以缓解异步和时变延迟对并行计算的影响。DASA通过自适应机制利用分布式计算的优势，在代理的随机观察过程为独立Markov链的假设下，提供有限时间收敛分析，其收敛率仅依赖于混合时间(τ_mix)和平均延迟(τ_avg)，并实现N倍的收敛加速。该算法适用于多种应用，包括多代理分布式时差学习(TD learning)、Q-learning和相关数据的随机优化。",
      "categories": [
        "cs.AI",
        "cs.RO",
        "cs.SY",
        "eess.SY",
        "math.OC",
        "stat.ML"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17247v3",
      "published_date": "2024-03-25 22:49:56 UTC",
      "updated_date": "2024-08-02 09:03:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:29:45.050751"
    },
    {
      "arxiv_id": "2403.17246v2",
      "title": "TwoStep: Multi-agent Task Planning using Classical Planners and Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "David Bai",
        "Ishika Singh",
        "David Traum",
        "Jesse Thomason"
      ],
      "abstract": "Classical planning formulations like the Planning Domain Definition Language\n(PDDL) admit action sequences guaranteed to achieve a goal state given an\ninitial state if any are possible. However, reasoning problems defined in PDDL\ndo not capture temporal aspects of action taking, such as concurrent actions\nbetween two agents when there are no conflicting conditions, without\nsignificant modification and definition to existing PDDL domains. A human\nexpert aware of such constraints can decompose a goal into subgoals, each\nreachable through single agent planning, to take advantage of simultaneous\nactions. In contrast to classical planning, large language models (LLMs)\ndirectly used for inferring plan steps rarely guarantee execution success, but\nare capable of leveraging commonsense reasoning to assemble action sequences.\nWe combine the strengths of both classical planning and LLMs by approximating\nhuman intuitions for multi-agent planning goal decomposition. We demonstrate\nthat LLM-based goal decomposition leads to faster planning times than solving\nmulti-agent PDDL problems directly while simultaneously achieving fewer plan\nexecution steps than a single agent plan alone, as well as most multiagent\nplans, while guaranteeing execution success. Additionally, we find that\nLLM-based approximations of subgoals result in similar multi-agent execution\nlengths to those specified by human experts. Website and resources at\nhttps://glamor-usc.github.io/twostep",
      "tldr_zh": "该研究提出TwoStep框架，将Classical Planners（如PDDL）和Large Language Models (LLMs) 相结合，解决多智能体任务规划中并发动作的挑战。框架利用LLMs进行目标分解，近似人类专家的直觉，将复杂目标拆分为子目标，然后通过Classical Planners实现高效的单智能体规划。实验结果显示，这种方法比直接解决多智能体PDDL问题更快，且比单智能体计划或大多数多智能体计划减少执行步骤，同时保证执行成功，并与人类专家的子目标分解结果类似。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.MA",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.17246v2",
      "published_date": "2024-03-25 22:47:13 UTC",
      "updated_date": "2025-03-25 23:39:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:29:57.445051"
    },
    {
      "arxiv_id": "2403.17237v1",
      "title": "DreamPolisher: Towards High-Quality Text-to-3D Generation via Geometric Diffusion",
      "title_zh": "翻译失败",
      "authors": [
        "Yuanze Lin",
        "Ronald Clark",
        "Philip Torr"
      ],
      "abstract": "We present DreamPolisher, a novel Gaussian Splatting based method with\ngeometric guidance, tailored to learn cross-view consistency and intricate\ndetail from textual descriptions. While recent progress on text-to-3D\ngeneration methods have been promising, prevailing methods often fail to ensure\nview-consistency and textural richness. This problem becomes particularly\nnoticeable for methods that work with text input alone. To address this, we\npropose a two-stage Gaussian Splatting based approach that enforces geometric\nconsistency among views. Initially, a coarse 3D generation undergoes refinement\nvia geometric optimization. Subsequently, we use a ControlNet driven refiner\ncoupled with the geometric consistency term to improve both texture fidelity\nand overall consistency of the generated 3D asset. Empirical evaluations across\ndiverse textual prompts spanning various object categories demonstrate the\nefficacy of DreamPolisher in generating consistent and realistic 3D objects,\naligning closely with the semantics of the textual instructions.",
      "tldr_zh": "本研究提出DreamPolisher，一种基于Gaussian Splatting的创新方法，通过几何指导实现高质量的text-to-3D生成，旨在解决现有方法在视图一致性和纹理丰富性方面的不足。该方法采用两阶段策略：首先，通过几何优化对粗略3D模型进行精炼；其次，使用ControlNet驱动的精炼器结合几何一致性术语，提升纹理保真度和整体一致性。在多样化文本提示下的实证评估中，DreamPolisher成功生成与文本语义紧密对齐的真实3D对象，展示了其在跨视图一致性上的显著效能。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR"
      ],
      "primary_category": "cs.CV",
      "comment": "Project webpage: https://yuanze-lin.me/DreamPolisher_page/",
      "pdf_url": "http://arxiv.org/pdf/2403.17237v1",
      "published_date": "2024-03-25 22:34:05 UTC",
      "updated_date": "2024-03-25 22:34:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:30:08.745952"
    },
    {
      "arxiv_id": "2403.17234v2",
      "title": "Speeding Up Path Planning via Reinforcement Learning in MCTS for Automated Parking",
      "title_zh": "翻译失败",
      "authors": [
        "Xinlong Zheng",
        "Xiaozhou Zhang",
        "Donghao Xu"
      ],
      "abstract": "In this paper, we address a method that integrates reinforcement learning\ninto the Monte Carlo tree search to boost online path planning under fully\nobservable environments for automated parking tasks. Sampling-based planning\nmethods under high-dimensional space can be computationally expensive and\ntime-consuming. State evaluation methods are useful by leveraging the prior\nknowledge into the search steps, making the process faster in a real-time\nsystem. Given the fact that automated parking tasks are often executed under\ncomplex environments, a solid but lightweight heuristic guidance is challenging\nto compose in a traditional analytical way. To overcome this limitation, we\npropose a reinforcement learning pipeline with a Monte Carlo tree search under\nthe path planning framework. By iteratively learning the value of a state and\nthe best action among samples from its previous cycle's outcomes, we are able\nto model a value estimator and a policy generator for given states. By doing\nthat, we build up a balancing mechanism between exploration and exploitation,\nspeeding up the path planning process while maintaining its quality without\nusing human expert driver data.",
      "tldr_zh": "本文提出了一种将强化学习集成到 Monte Carlo Tree Search (MCTS) 中的方法，以加速自动泊车任务在完全可观察环境下的在线路径规划。针对高维空间下采样-based规划的计算开销问题，该框架通过迭代学习状态价值和最佳动作，构建价值估计器和策略生成器，实现探索与利用的平衡机制。结果显示，该方法显著提高了路径规划效率，相比传统方式更快且保持质量，同时无需依赖人类专家数据。",
      "categories": [
        "cs.AI",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted by IROS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17234v2",
      "published_date": "2024-03-25 22:21:23 UTC",
      "updated_date": "2024-12-31 06:53:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:30:20.440071"
    },
    {
      "arxiv_id": "2403.17224v2",
      "title": "Uncertainty Quantification for Gradient-based Explanations in Neural Networks",
      "title_zh": "神经网络中基于梯度的解释不确定性量化",
      "authors": [
        "Mihir Mulye",
        "Matias Valdenegro-Toro"
      ],
      "abstract": "Explanation methods help understand the reasons for a model's prediction.\nThese methods are increasingly involved in model debugging, performance\noptimization, and gaining insights into the workings of a model. With such\ncritical applications of these methods, it is imperative to measure the\nuncertainty associated with the explanations generated by these methods. In\nthis paper, we propose a pipeline to ascertain the explanation uncertainty of\nneural networks by combining uncertainty estimation methods and explanation\nmethods. We use this pipeline to produce explanation distributions for the\nCIFAR-10, FER+, and California Housing datasets. By computing the coefficient\nof variation of these distributions, we evaluate the confidence in the\nexplanation and determine that the explanations generated using Guided\nBackpropagation have low uncertainty associated with them. Additionally, we\ncompute modified pixel insertion/deletion metrics to evaluate the quality of\nthe generated explanations.",
      "tldr_zh": "本论文针对神经网络的梯度-based解释方法，提出了一种量化不确定性的管道，以评估解释的可信度并提升模型调试和优化。方法通过结合不确定性估计技术与解释方法，生成解释分布，并应用于CIFAR-10、FER+和California Housing数据集。实验结果显示，Guided Backpropagation的解释不确定性较低，且通过计算变异系数和修改后的像素插入/删除指标，进一步验证了解释的质量。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "13 pages, 11 figures, UNCV @ CVPR 2025 Camera ready",
      "pdf_url": "http://arxiv.org/pdf/2403.17224v2",
      "published_date": "2024-03-25 21:56:02 UTC",
      "updated_date": "2025-04-14 19:43:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:30:34.097105"
    },
    {
      "arxiv_id": "2403.17223v1",
      "title": "Co-Occurring of Object Detection and Identification towards unlabeled object discovery",
      "title_zh": "翻译失败",
      "authors": [
        "Binay Kumar Singh",
        "Niels Da Vitoria Lobo"
      ],
      "abstract": "In this paper, we propose a novel deep learning based approach for\nidentifying co-occurring objects in conjunction with base objects in multilabel\nobject categories. Nowadays, with the advancement in computer vision based\ntechniques we need to know about co-occurring objects with respect to base\nobject for various purposes. The pipeline of the proposed work is composed of\ntwo stages: in the first stage of the proposed model we detect all the bounding\nboxes present in the image and their corresponding labels, then in the second\nstage we perform co-occurrence matrix analysis. In co-occurrence matrix\nanalysis, we set base classes based on the maximum occurrences of the labels\nand build association rules and generate frequent patterns. These frequent\npatterns will show base classes and their corresponding co-occurring classes.\nWe performed our experiments on two publicly available datasets: Pascal VOC and\nMS-COCO. The experimental results on public benchmark dataset is reported in\nSec 4. Further we extend this work by considering all frequently objects as\nunlabeled and what if they are occluded as well.",
      "tldr_zh": "本研究提出了一种基于深度学习的创新方法，用于识别多标签对象类别中与基础对象（base objects）共同出现的对象，从而实现未标记对象（unlabeled object）的发现。该方法分为两个阶段：首先，通过对象检测（object detection）获取图像中的所有边界框及其标签；其次，进行共现矩阵分析（co-occurrence matrix analysis），基于标签的最大出现频率设置基础类，并构建关联规则以生成频繁模式，这些模式揭示了基础类及其对应的共现类。在Pascal VOC和MS-COCO数据集上进行的实验证明了方法的有效性，并在后续扩展中考虑了频繁对象作为未标记的并处理遮挡情况，进一步提升了实际应用潜力。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "6 pages, 2 figures,",
      "pdf_url": "http://arxiv.org/pdf/2403.17223v1",
      "published_date": "2024-03-25 21:53:36 UTC",
      "updated_date": "2024-03-25 21:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:30:45.274729"
    },
    {
      "arxiv_id": "2403.17219v2",
      "title": "SeSaMe: A Framework to Simulate Self-Reported Ground Truth for Mental Health Sensing Studies",
      "title_zh": "翻译失败",
      "authors": [
        "Akshat Choube",
        "Vedant Das Swain",
        "Varun Mishra"
      ],
      "abstract": "Advances in mobile and wearable technologies have enabled the potential to\npassively monitor a person's mental, behavioral, and affective health. These\napproaches typically rely on longitudinal collection of self-reported outcomes,\ne.g., depression, stress, and anxiety, to train machine learning (ML) models.\nHowever, the need to continuously self-report adds a significant burden on the\nparticipants, often resulting in attrition, missing labels, or insincere\nresponses. In this work, we introduce the Scale Scores Simulation using Mental\nModels (SeSaMe) framework to alleviate participants' burden in digital mental\nhealth studies. By leveraging pre-trained large language models (LLMs), SeSaMe\nenables the simulation of participants' responses on psychological scales. In\nSeSaMe, researchers can prompt LLMs with information on participants' internal\nbehavioral dispositions, enabling LLMs to construct mental models of\nparticipants to simulate their responses on psychological scales. We\ndemonstrate an application of SeSaMe, where we use GPT-4 to simulate responses\non one scale using responses from another as behavioral information. We also\nevaluate the alignment between human and SeSaMe-simulated responses to\npsychological scales. Then, we present experiments to inspect the utility of\nSeSaMe-simulated responses as ground truth in training ML models by replicating\nestablished depression and anxiety screening tasks from a previous study. Our\nresults indicate SeSaMe to be a promising approach, but its alignment may vary\nacross scales and specific prediction objectives. We also observed that model\nperformance with simulated data was on par with using the real data for\ntraining in most evaluation scenarios. We conclude by discussing the potential\nimplications of SeSaMe in addressing some challenges researchers face with\nground-truth collection in passive sensing studies.",
      "tldr_zh": "这篇论文介绍了 SeSaMe 框架，一种利用预训练的大型语言模型 (LLMs) 来模拟心理健康研究中自报数据的工具，旨在减轻参与者的负担并解决数据缺失问题。在 SeSaMe 中，研究人员通过提供参与者的行为信息，让 LLMs 构建心理模型来模拟心理量表响应，例如使用 GPT-4 基于一个量表的响应模拟另一个量表。实验评估显示，SeSaMe 模拟数据在训练机器学习 (ML) 模型时，与真实数据性能相当，尤其在抑郁和焦虑筛查任务中，但模拟响应的对齐度可能因量表和预测目标而异。该框架为被动感知研究提供了潜在解决方案，帮助缓解地面真实数据收集的挑战。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.CY"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17219v2",
      "published_date": "2024-03-25 21:48:22 UTC",
      "updated_date": "2024-03-27 15:08:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:31:00.231025"
    },
    {
      "arxiv_id": "2403.17217v2",
      "title": "DiffusionAct: Controllable Diffusion Autoencoder for One-shot Face Reenactment",
      "title_zh": "翻译失败",
      "authors": [
        "Stella Bounareli",
        "Christos Tzelepis",
        "Vasileios Argyriou",
        "Ioannis Patras",
        "Georgios Tzimiropoulos"
      ],
      "abstract": "Video-driven neural face reenactment aims to synthesize realistic facial\nimages that successfully preserve the identity and appearance of a source face,\nwhile transferring the target head pose and facial expressions. Existing\nGAN-based methods suffer from either distortions and visual artifacts or poor\nreconstruction quality, i.e., the background and several important appearance\ndetails, such as hair style/color, glasses and accessories, are not faithfully\nreconstructed. Recent advances in Diffusion Probabilistic Models (DPMs) enable\nthe generation of high-quality realistic images. To this end, in this paper we\npresent DiffusionAct, a novel method that leverages the photo-realistic image\ngeneration of diffusion models to perform neural face reenactment.\nSpecifically, we propose to control the semantic space of a Diffusion\nAutoencoder (DiffAE), in order to edit the facial pose of the input images,\ndefined as the head pose orientation and the facial expressions. Our method\nallows one-shot, self, and cross-subject reenactment, without requiring\nsubject-specific fine-tuning. We compare against state-of-the-art GAN-,\nStyleGAN2-, and diffusion-based methods, showing better or on-par reenactment\nperformance.",
      "tldr_zh": "该论文提出DiffusionAct，一种基于Diffusion Probabilistic Models (DPMs)的可控Diffusion Autoencoder (DiffAE)，用于实现one-shot面部重演。方法通过控制DiffAE的语义空间，编辑输入图像的头部姿势和面部表情，从而合成保留源面部身份和外观的逼真图像，支持one-shot、self和cross-subject重演，而无需主体特定微调。与现有的GAN-based、StyleGAN2-based和扩散模型方法相比，DiffusionAct在重演性能上表现出优越或相当的水平，解决了传统方法中的扭曲伪影和重建质量问题。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://stelabou.github.io/diffusionact/",
      "pdf_url": "http://arxiv.org/pdf/2403.17217v2",
      "published_date": "2024-03-25 21:46:53 UTC",
      "updated_date": "2025-03-25 09:47:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:31:09.917978"
    },
    {
      "arxiv_id": "2403.17214v1",
      "title": "Exploring the Impact of the Output Format on the Evaluation of Large Language Models for Code Translation",
      "title_zh": "探索输出格式对大语言模型代码翻译评估的影响",
      "authors": [
        "Marcos Macedo",
        "Yuan Tian",
        "Filipe R. Cogo",
        "Bram Adams"
      ],
      "abstract": "Code translation between programming languages is a long-existing and\ncritical task in software engineering, facilitating the modernization of legacy\nsystems, ensuring cross-platform compatibility, and enhancing software\nperformance. With the recent advances in large language models (LLMs) and their\napplications to code translation, there is an increasing need for comprehensive\nevaluation of these models. In this study, we empirically analyze the generated\noutputs of eleven popular instruct-tuned LLMs with parameters ranging from 1B\nup to 46.7B on 3,820 translation pairs across five languages, including C, C++,\nGo, Java, and Python. Our analysis found that between 26.4% and 73.7% of code\ntranslations produced by our evaluated LLMs necessitate post-processing, as\nthese translations often include a mix of code, quotes, and text rather than\nbeing purely source code. Overlooking the output format of these models can\ninadvertently lead to underestimation of their actual performance. This is\nparticularly evident when evaluating them with execution-based metrics such as\nComputational Accuracy (CA). Our results demonstrate that a strategic\ncombination of prompt engineering and regular expression can effectively\nextract the source code from the model generation output. In particular, our\nmethod can help eleven selected models achieve an average Code Extraction\nSuccess Rate (CSR) of 92.73%. Our findings shed light on and motivate future\nresearch to conduct more reliable benchmarks of LLMs for code translation.",
      "tldr_zh": "这篇论文探讨了输出格式对评估大型语言模型(LLMs)进行代码翻译的影响，通过实证分析11个参数从1B到46.7B的模型在3820对翻译对（涉及C、C++、Go、Java和Python语言）上的表现。研究发现，26.4%至73.7%的代码翻译输出包含代码、引号和文本的混合形式，需要后处理，否则会导致模型性能被低估，尤其在使用执行-based指标如Computational Accuracy (CA)时。作者提出结合prompt engineering和regular expression的方法来提取纯源代码，这使11个模型的平均Code Extraction Success Rate (CSR)达到92.73%。这些发现为未来LLMs代码翻译的可靠基准测试提供了重要启示。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "Accepted into 2024 IEEE/ACM First International Conference on AI\n  Foundation Models and Software Engineering (Forge)",
      "pdf_url": "http://arxiv.org/pdf/2403.17214v1",
      "published_date": "2024-03-25 21:41:31 UTC",
      "updated_date": "2024-03-25 21:41:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:31:24.854865"
    },
    {
      "arxiv_id": "2403.17212v1",
      "title": "Sanity Checks for Explanation Uncertainty",
      "title_zh": "翻译失败",
      "authors": [
        "Matias Valdenegro-Toro",
        "Mihir Mulye"
      ],
      "abstract": "Explanations for machine learning models can be hard to interpret or be\nwrong. Combining an explanation method with an uncertainty estimation method\nproduces explanation uncertainty. Evaluating explanation uncertainty is\ndifficult. In this paper we propose sanity checks for uncertainty explanation\nmethods, where a weight and data randomization tests are defined for\nexplanations with uncertainty, allowing for quick tests to combinations of\nuncertainty and explanation methods. We experimentally show the validity and\neffectiveness of these tests on the CIFAR10 and California Housing datasets,\nnoting that Ensembles seem to consistently pass both tests with Guided\nBackpropagation, Integrated Gradients, and LIME explanations.",
      "tldr_zh": "这篇论文探讨了机器学习模型解释的不确定性问题，提出了一种评估解释不确定性的Sanity Checks方法，包括weight randomization和data randomization测试，以快速验证不确定性和解释方法的组合。研究通过实验在CIFAR10和California Housing数据集上验证了这些测试的有效性，发现Ensembles方法与Guided Backpropagation、Integrated Gradients和LIME解释结合时，能够一致通过这两项测试。这些贡献有助于提升解释方法的可靠性和可解释性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 7 figures, 3 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.17212v1",
      "published_date": "2024-03-25 21:39:33 UTC",
      "updated_date": "2024-03-25 21:39:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:31:38.725188"
    },
    {
      "arxiv_id": "2403.17210v2",
      "title": "CADGL: Context-Aware Deep Graph Learning for Predicting Drug-Drug Interactions",
      "title_zh": "CADGL: 上下文感知深度图学习用于预测",
      "authors": [
        "Azmine Toushik Wasi",
        "Taki Hasan Rafi",
        "Raima Islam",
        "Serbetar Karlo",
        "Dong-Kyu Chae"
      ],
      "abstract": "Examining Drug-Drug Interactions (DDIs) is a pivotal element in the process\nof drug development. DDIs occur when one drug's properties are affected by the\ninclusion of other drugs. Detecting favorable DDIs has the potential to pave\nthe way for creating and advancing innovative medications applicable in\npractical settings. However, existing DDI prediction models continue to face\nchallenges related to generalization in extreme cases, robust feature\nextraction, and real-life application possibilities. We aim to address these\nchallenges by leveraging the effectiveness of context-aware deep graph learning\nby introducing a novel framework named CADGL. Based on a customized variational\ngraph autoencoder (VGAE), we capture critical structural and physio-chemical\ninformation using two context preprocessors for feature extraction from two\ndifferent perspectives: local neighborhood and molecular context, in a\nheterogeneous graphical structure. Our customized VGAE consists of a graph\nencoder, a latent information encoder, and an MLP decoder. CADGL surpasses\nother state-of-the-art DDI prediction models, excelling in predicting\nclinically valuable novel DDIs, supported by rigorous case studies.",
      "tldr_zh": "该论文针对药物-药物相互作用（Drug-Drug Interactions, DDIs）的预测问题，提出了一种新的框架CADGL，利用上下文感知深度图学习（Context-Aware Deep Graph Learning）来解决现有模型在泛化、特征提取和实际应用方面的挑战。CADGL基于定制的变分图自编码器（VGAE），通过两个上下文预处理器从局部邻域和分子上下文两个角度提取异构图结构的结构和理化信息，包括图编码器、潜在信息编码器和MLP解码器。实验结果显示，CADGL在预测临床有价值的新的DDIs方面优于现有最先进模型，并通过严格的案例研究验证了其有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.IR",
        "q-bio.BM",
        "q-bio.MN"
      ],
      "primary_category": "cs.LG",
      "comment": "8 Pages, 4 Figures; In review",
      "pdf_url": "http://arxiv.org/pdf/2403.17210v2",
      "published_date": "2024-03-25 21:37:31 UTC",
      "updated_date": "2024-03-27 21:47:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:31:51.397296"
    },
    {
      "arxiv_id": "2403.17209v4",
      "title": "Generation of Asset Administration Shell with Large Language Model Agents: Toward Semantic Interoperability in Digital Twins in the Context of Industry 4.0",
      "title_zh": "翻译失败",
      "authors": [
        "Yuchen Xia",
        "Zhewen Xiao",
        "Nasser Jazdi",
        "Michael Weyrich"
      ],
      "abstract": "This research introduces a novel approach for achieving semantic\ninteroperability in digital twins and assisting the creation of Asset\nAdministration Shell (AAS) as digital twin model within the context of Industry\n4.0. The foundational idea of our research is that the communication based on\nsemantics and the generation of meaningful textual data are directly linked,\nand we posit that these processes are equivalent if the exchanged information\ncan be serialized in text form. Based on this, we construct a \"semantic node\"\ndata structure in our research to capture the semantic essence of textual data.\nThen, a system powered by large language models is designed and implemented to\nprocess the \"semantic node\" and generate standardized digital twin models from\nraw textual data collected from datasheets describing technical assets. Our\nevaluation demonstrates an effective generation rate of 62-79%, indicating a\nsubstantial proportion of the information from the source text can be\ntranslated error-free to the target digital twin instance model with the\ngenerative capability of large language models. This result has a direct\napplication in the context of Industry 4.0, and the designed system is\nimplemented as a data model generation tool for reducing the manual effort in\ncreating AAS model. In our evaluation, a comparative analysis of different LLMs\nand an in-depth ablation study of Retrieval-Augmented Generation (RAG)\nmechanisms provide insights into the effectiveness of LLM systems for\ninterpreting technical concepts and translating data. Our findings emphasize\nLLMs' capability to automate AAS instance creation and contribute to the\nbroader field of semantic interoperability for digital twins in industrial\napplications. The prototype implementation and evaluation results are presented\non our GitHub Repository: https://github.com/YuchenXia/AASbyLLM.",
      "tldr_zh": "本研究提出了一种新方法，使用 Large Language Model (LLMs) 代理生成 Asset Administration Shell (AAS)，以实现数字孪生中的 Semantic Interoperability，并在 Industry 4.0 背景下减少手动建模努力。核心创新包括构建“semantic node”数据结构来捕捉文本数据的语义本质，并通过 LLMs 驱动系统从原始技术资产数据表生成标准化数字孪生模型。实验结果显示，生成率达到 62-79%，并通过比较不同 LLMs 和 Retrieval-Augmented Generation (RAG) 机制的消融研究，证明了 LLMs 在自动化 AAS 创建和提升语义互操作性方面的显著潜力。",
      "categories": [
        "cs.AI",
        "cs.IR",
        "cs.MA",
        "cs.SE"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in IEEE Access",
      "pdf_url": "http://arxiv.org/pdf/2403.17209v4",
      "published_date": "2024-03-25 21:37:30 UTC",
      "updated_date": "2024-06-24 12:04:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:32:08.665684"
    },
    {
      "arxiv_id": "2403.17169v3",
      "title": "QuanTemp: A real-world open-domain benchmark for fact-checking numerical claims",
      "title_zh": "翻译失败",
      "authors": [
        "Venktesh V",
        "Abhijit Anand",
        "Avishek Anand",
        "Vinay Setty"
      ],
      "abstract": "Automated fact checking has gained immense interest to tackle the growing\nmisinformation in the digital era. Existing systems primarily focus on\nsynthetic claims on Wikipedia, and noteworthy progress has also been made on\nreal-world claims. In this work, we release QuanTemp, a diverse, multi-domain\ndataset focused exclusively on numerical claims, encompassing temporal,\nstatistical and diverse aspects with fine-grained metadata and an evidence\ncollection without leakage. This addresses the challenge of verifying\nreal-world numerical claims, which are complex and often lack precise\ninformation, not addressed by existing works that mainly focus on synthetic\nclaims. We evaluate and quantify the limitations of existing solutions for the\ntask of verifying numerical claims. We also evaluate claim decomposition based\nmethods, numerical understanding based models and our best baselines achieves a\nmacro-F1 of 58.32. This demonstrates that QuanTemp serves as a challenging\nevaluation set for numerical claim verification.",
      "tldr_zh": "该研究发布了 QuanTemp，这是一个真实世界的开放域基准数据集，专注于事实检查中的数字声明（numerical claims），涵盖时间、统计和多样化方面，并提供细粒度的元数据和无泄漏证据收集，以解决现有工作主要针对合成声明的局限性。QuanTemp 强调了验证复杂真实世界数字声明的挑战，这些声明往往缺乏精确信息。研究评估了声明分解方法（claim decomposition）和数字理解模型（numerical understanding based models），结果显示最佳基线模型的 macro-F1 分数为 58.32%，证明 QuanTemp 是一个高度挑战性的评估集，用于推动数字声明验证技术的进步。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "11 pages, 1 figure,Accepted for publication at the 47th International\n  ACM SIGIR Conference on Research and Development in Information Retrieval\n  (SIGIR 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.17169v3",
      "published_date": "2024-03-25 20:36:03 UTC",
      "updated_date": "2024-05-01 06:27:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:32:15.314596"
    },
    {
      "arxiv_id": "2403.17164v2",
      "title": "Multi-Objective Quality-Diversity for Crystal Structure Prediction",
      "title_zh": "翻译失败",
      "authors": [
        "Hannah Janmohamed",
        "Marta Wolinska",
        "Shikha Surana",
        "Thomas Pierrot",
        "Aron Walsh",
        "Antoine Cully"
      ],
      "abstract": "Crystal structures are indispensable across various domains, from batteries\nto solar cells, and extensive research has been dedicated to predicting their\nproperties based on their atomic configurations. However, prevailing Crystal\nStructure Prediction methods focus on identifying the most stable solutions\nthat lie at the global minimum of the energy function. This approach overlooks\nother potentially interesting materials that lie in neighbouring local minima\nand have different material properties such as conductivity or resistance to\ndeformation. By contrast, Quality-Diversity algorithms provide a promising\navenue for Crystal Structure Prediction as they aim to find a collection of\nhigh-performing solutions that have diverse characteristics. However, it may\nalso be valuable to optimise for the stability of crystal structures alongside\nother objectives such as magnetism or thermoelectric efficiency. Therefore, in\nthis work, we harness the power of Multi-Objective Quality-Diversity algorithms\nin order to find crystal structures which have diverse features and achieve\ndifferent trade-offs of objectives. We analyse our approach on 5 crystal\nsystems and demonstrate that it is not only able to re-discover known real-life\nstructures, but also find promising new ones. Moreover, we propose a method for\nilluminating the objective space to gain an understanding of what trade-offs\ncan be achieved.",
      "tldr_zh": "本研究指出，传统的 Crystal Structure Prediction 方法仅关注能量函数全局最小值的最稳定结构，从而忽略了邻近局部最小值中具有多样特性的潜在材料，如导电性或抗变形性。作者引入 Multi-Objective Quality-Diversity 算法，旨在优化晶体结构的稳定性与其他目标（如磁性和热电效率），以发现多样化的高性能解决方案。在5个晶体系统中进行实验，该方法不仅成功重新发现已知真实结构，还生成了有前景的新结构，并提出了一种阐明目标空间的方法，以理解可实现的权衡。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted GECCO 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.17164v2",
      "published_date": "2024-03-25 20:29:04 UTC",
      "updated_date": "2024-06-21 09:26:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:32:29.038587"
    },
    {
      "arxiv_id": "2403.17159v1",
      "title": "Less Is More -- On the Importance of Sparsification for Transformers and Graph Neural Networks for TSP",
      "title_zh": "翻译失败",
      "authors": [
        "Attila Lischka",
        "Jiaming Wu",
        "Rafael Basso",
        "Morteza Haghir Chehreghani",
        "Balázs Kulcsár"
      ],
      "abstract": "Most of the recent studies tackling routing problems like the Traveling\nSalesman Problem (TSP) with machine learning use a transformer or Graph Neural\nNetwork (GNN) based encoder architecture. However, many of them apply these\nencoders naively by allowing them to aggregate information over the whole TSP\ninstances. We, on the other hand, propose a data preprocessing method that\nallows the encoders to focus on the most relevant parts of the TSP instances\nonly. In particular, we propose graph sparsification for TSP graph\nrepresentations passed to GNNs and attention masking for TSP instances passed\nto transformers where the masks correspond to the adjacency matrices of the\nsparse TSP graph representations. Furthermore, we propose ensembles of\ndifferent sparsification levels allowing models to focus on the most promising\nparts while also allowing information flow between all nodes of a TSP instance.\nIn the experimental studies, we show that for GNNs appropriate sparsification\nand ensembles of different sparsification levels lead to substantial\nperformance increases of the overall architecture. We also design a new,\nstate-of-the-art transformer encoder with ensembles of attention masking. These\ntransformers increase model performance from a gap of $0.16\\%$ to $0.10\\%$ for\nTSP instances of size 100 and from $0.02\\%$ to $0.00\\%$ for TSP instances of\nsize 50.",
      "tldr_zh": "本文研究了在解决旅行 salesman problem (TSP) 时，对 Transformer 和 Graph Neural Networks (GNNs) 进行稀疏化的重要性，提出了一种数据预处理方法，通过 graph sparsification 和 attention masking，让模型仅关注 TSP 实例的最相关部分，同时引入不同稀疏化水平的 ensembles 以平衡信息流动和焦点。实验结果显示，这种方法显著提升了 GNNs 的整体性能，而新设计的 Transformer 编码器将 TSP 实例大小为 100 的性能差距从 0.16% 降低到 0.10%，并将大小为 50 的差距从 0.02% 降低到 0.00%。这项工作证明了稀疏化策略能有效提高模型效率和准确性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 6 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17159v1",
      "published_date": "2024-03-25 20:16:16 UTC",
      "updated_date": "2024-03-25 20:16:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:32:41.833883"
    },
    {
      "arxiv_id": "2403.17154v3",
      "title": "On the Impact of Black-box Deployment Strategies for Edge AI on Latency and Model Performance",
      "title_zh": "翻译失败",
      "authors": [
        "Jaskirat Singh",
        "Emad Fallahzadeh",
        "Bram Adams",
        "Ahmed E. Hassan"
      ],
      "abstract": "Deciding what combination of operators to use across the Edge AI tiers to\nachieve specific latency and model performance requirements is an open question\nfor MLOps engineers. This study aims to empirically assess the accuracy vs\ninference time trade-off of different black-box Edge AI deployment strategies,\ni.e., combinations of deployment operators and deployment tiers. In this paper,\nwe conduct inference experiments involving 3 deployment operators (i.e.,\nPartitioning, Quantization, Early Exit), 3 deployment tiers (i.e., Mobile,\nEdge, Cloud) and their combinations on four widely used Computer-Vision models\nto investigate the optimal strategies from the point of view of MLOps\ndevelopers. Our findings suggest that Edge deployment using the hybrid\nQuantization + Early Exit operator could be preferred over non-hybrid operators\n(Quantization/Early Exit on Edge, Partition on Mobile-Edge) when faster latency\nis a concern at medium accuracy loss. However, when minimizing accuracy loss is\na concern, MLOps engineers should prefer using only a Quantization operator on\nedge at a latency reduction or increase, respectively over the Early\nExit/Partition (on edge/mobile-edge) and Quantized Early Exit (on edge)\noperators. In scenarios constrained by Mobile CPU/RAM resources, a preference\nfor Partitioning across mobile and edge tiers is observed over mobile\ndeployment. For models with smaller input data samples (such as FCN), a\nnetwork-constrained cloud deployment can also be a better alternative than\nMobile/Edge deployment and Partitioning strategies. For models with large input\ndata samples (ResNet, ResNext, DUC), an edge tier having higher\nnetwork/computational capabilities than Cloud/Mobile can be a more viable\noption than Partitioning and Mobile/Cloud deployment strategies.",
      "tldr_zh": "这篇论文评估了不同黑箱 Edge AI 部署策略对延迟和模型性能的影响，针对 MLOps 工程师在选择部署操作符（如 Partitioning、Quantization 和 Early Exit）和部署层（如 Mobile、Edge 和 Cloud）的组合时进行经验性分析。研究通过在四个计算机视觉模型上进行推理实验，探讨了准确率与推理时间之间的权衡。关键发现包括：当追求更快延迟时，Edge 层上的 Quantization + Early Exit 混合操作符优于单一操作符或 Mobile-Edge 分区；但若优先最小化准确率损失，则应选择 Edge 上的 Quantization 操作符。总体而言，在资源受限的 Mobile 场景下，Partitioning 策略更具优势，而对于不同输入数据规模的模型，云或 Edge 部署可能更合适。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17154v3",
      "published_date": "2024-03-25 20:09:46 UTC",
      "updated_date": "2025-05-11 17:15:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:32:54.487615"
    },
    {
      "arxiv_id": "2403.17147v1",
      "title": "Hearing the shape of an arena with spectral swarm robotics",
      "title_zh": "翻译失败",
      "authors": [
        "Leo Cazenille",
        "Nicolas Lobato-Dauzier",
        "Alessia Loi",
        "Mika Ito",
        "Olivier Marchal",
        "Nathanael Aubert-Kato",
        "Nicolas Bredeche",
        "Anthony J. Genot"
      ],
      "abstract": "Swarm robotics promises adaptability to unknown situations and robustness\nagainst failures. However, it still struggles with global tasks that require\nunderstanding the broader context in which the robots operate, such as\nidentifying the shape of the arena in which the robots are embedded. Biological\nswarms, such as shoals of fish, flocks of birds, and colonies of insects,\nroutinely solve global geometrical problems through the diffusion of local\ncues. This paradigm can be explicitly described by mathematical models that\ncould be directly computed and exploited by a robotic swarm. Diffusion over a\ndomain is mathematically encapsulated by the Laplacian, a linear operator that\nmeasures the local curvature of a function. Crucially the geometry of a domain\ncan generally be reconstructed from the eigenspectrum of its Laplacian. Here we\nintroduce spectral swarm robotics where robots diffuse information to their\nneighbors to emulate the Laplacian operator - enabling them to \"hear\" the\nspectrum of their arena. We reveal a universal scaling that links the optimal\nnumber of robots (a global parameter) with their optimal radius of interaction\n(a local parameter). We validate experimentally spectral swarm robotics under\nchallenging conditions with the one-shot classification of arena shapes using a\nsparse swarm of Kilobots. Spectral methods can assist with challenging tasks\nwhere robots need to build an emergent consensus on their environment, such as\nadaptation to unknown terrains, division of labor, or quorum sensing. Spectral\nmethods may extend beyond robotics to analyze and coordinate swarms of agents\nof various natures, such as traffic or crowds, and to better understand the\nlong-range dynamics of natural systems emerging from short-range interactions.",
      "tldr_zh": "本研究提出了一种名为 spectral swarm robotics 的方法，让机器人群通过模拟 Laplacian 运算符来识别其所在场地的形状，从而解决群机器人系统在全局任务中的适应性和鲁棒性挑战。机器人通过向邻居扩散信息来仿真 Laplacian 的 eigenspectrum，从而“听到”场地的几何特征，并揭示了机器人最优数量（全局参数）和交互半径（局部参数）之间的普遍缩放关系。实验在 Kilobots 稀疏群上验证了该方法，能够实现场地形状的一次性分类，准确率显著提升。该框架不仅适用于机器人任务如适应未知地形或分工，还可扩展到分析交通人群或自然系统中的长程动态。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CG"
      ],
      "primary_category": "cs.RO",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17147v1",
      "published_date": "2024-03-25 19:50:07 UTC",
      "updated_date": "2024-03-25 19:50:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:33:05.005984"
    },
    {
      "arxiv_id": "2403.17141v3",
      "title": "MetaAligner: Towards Generalizable Multi-Objective Alignment of Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Kailai Yang",
        "Zhiwei Liu",
        "Qianqian Xie",
        "Jimin Huang",
        "Tianlin Zhang",
        "Sophia Ananiadou"
      ],
      "abstract": "Recent advancements in large language models (LLMs) focus on aligning to\nheterogeneous human expectations and values via multi-objective preference\nalignment. However, existing methods are dependent on the policy model\nparameters, which require high-cost repetition of their alignment algorithms\nfor each new policy model, and they cannot expand to unseen objectives due to\ntheir static alignment objectives. In this work, we propose Meta-Objective\nAligner (MetaAligner), the first policy-agnostic and generalizable method for\nmulti-objective preference alignment. MetaAligner models multi-objective\nalignment into three stages: (1) dynamic objectives reformulation algorithm\nreorganizes traditional alignment datasets to supervise the model on performing\nflexible alignment across different objectives; (2) conditional weak-to-strong\ncorrection paradigm aligns the weak outputs of fixed policy models to approach\nstrong outputs with higher preferences in the corresponding alignment\nobjectives, enabling plug-and-play inferences on any policy models, which\nsignificantly reduces training costs and facilitates alignment on close-source\npolicy models; (3) generalizable inference method flexibly adjusts target\nobjectives by updating their text descriptions in the prompts, facilitating\ngeneralizable alignment to unseen objectives. Experimental results show that\nMetaAligner achieves significant and balanced improvements in multi-objective\nalignments on 10 state-of-the-art policy models, and saves up to 93.63% of GPU\ntraining hours compared to previous alignment methods. The model also\neffectively aligns unseen objectives, marking the first step towards\ngeneralizable multi-objective preference alignment.",
      "tldr_zh": "该研究提出MetaAligner，一种政策无关且可泛化的多目标偏好对齐方法，旨在解决现有大型语言模型(LLMs)对齐方法依赖模型参数且无法扩展到未见目标的问题。MetaAligner包括三个关键阶段：动态目标重构算法重组数据集以支持灵活对齐、条件弱到强修正范式对固定策略模型的输出进行修正以减少训练成本，以及可泛化推理方法通过更新提示文本实现对新目标的适应。实验结果显示，MetaAligner在10个最先进策略模型上实现了显著且平衡的改进，节省高达93.63%的GPU训练时间，并成功对齐未见目标，推动了多目标偏好对齐的泛化发展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted by NeurIPS 2024 main track",
      "pdf_url": "http://arxiv.org/pdf/2403.17141v3",
      "published_date": "2024-03-25 19:28:10 UTC",
      "updated_date": "2024-10-07 03:19:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:33:16.052777"
    },
    {
      "arxiv_id": "2403.17134v2",
      "title": "RepairAgent: An Autonomous, LLM-Based Agent for Program Repair",
      "title_zh": "翻译失败",
      "authors": [
        "Islem Bouzenia",
        "Premkumar Devanbu",
        "Michael Pradel"
      ],
      "abstract": "Automated program repair has emerged as a powerful technique to mitigate the\nimpact of software bugs on system reliability and user experience. This paper\nintroduces RepairAgent, the first work to address the program repair challenge\nthrough an autonomous agent based on a large language model (LLM). Unlike\nexisting deep learning-based approaches, which prompt a model with a fixed\nprompt or in a fixed feedback loop, our work treats the LLM as an agent capable\nof autonomously planning and executing actions to fix bugs by invoking suitable\ntools. RepairAgent freely interleaves gathering information about the bug,\ngathering repair ingredients, and validating fixes, while deciding which tools\nto invoke based on the gathered information and feedback from previous fix\nattempts. Key contributions that enable RepairAgent include a set of tools that\nare useful for program repair, a dynamically updated prompt format that allows\nthe LLM to interact with these tools, and a finite state machine that guides\nthe agent in invoking the tools. Our evaluation on the popular Defects4J\ndataset demonstrates RepairAgent's effectiveness in autonomously repairing 164\nbugs, including 39 bugs not fixed by prior techniques. Interacting with the LLM\nimposes an average cost of 270,000 tokens per bug, which, under the current\npricing of OpenAI's GPT-3.5 model, translates to 14 cents of USD per bug. To\nthe best of our knowledge, this work is the first to present an autonomous,\nLLM-based agent for program repair, paving the way for future agent-based\ntechniques in software engineering.",
      "tldr_zh": "本文提出 RepairAgent，一种基于 LLM（Large Language Model）的自主代理，用于自动化程序修复，通过自主规划和执行行动（如收集 bug 信息、获取修复成分和验证修复）来超越传统固定提示方法。关键创新包括一套专用工具、动态更新的提示格式以及有限状态机来指导代理调用工具。在 Defects4J 数据集上，RepairAgent 成功修复了 164 个 bug，其中 39 个为先前技术无法处理的，平均每个 bug 的 LLM 交互成本仅为 14 美分。该工作首次探索 LLM 作为自主代理在软件工程中的应用，为未来程序修复技术铺平道路。",
      "categories": [
        "cs.SE",
        "cs.AI"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17134v2",
      "published_date": "2024-03-25 19:17:43 UTC",
      "updated_date": "2024-10-28 17:33:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:33:29.408868"
    },
    {
      "arxiv_id": "2403.17130v1",
      "title": "Exploring the potential of prototype-based soft-labels data distillation for imbalanced data classification",
      "title_zh": "探索基于原型的软标签数据蒸馏在不平衡数据分类中的潜力",
      "authors": [
        "Radu-Andrei Rosu",
        "Mihaela-Elena Breaban",
        "Henri Luchian"
      ],
      "abstract": "Dataset distillation aims at synthesizing a dataset by a small number of\nartificially generated data items, which, when used as training data, reproduce\nor approximate a machine learning (ML) model as if it were trained on the\nentire original dataset. Consequently, data distillation methods are usually\ntied to a specific ML algorithm. While recent literature deals mainly with\ndistillation of large collections of images in the context of neural network\nmodels, tabular data distillation is much less represented and mainly focused\non a theoretical perspective. The current paper explores the potential of a\nsimple distillation technique previously proposed in the context of\nLess-than-one shot learning. The main goal is to push further the performance\nof prototype-based soft-labels distillation in terms of classification\naccuracy, by integrating optimization steps in the distillation process. The\nanalysis is performed on real-world data sets with various degrees of\nimbalance. Experimental studies trace the capability of the method to distill\nthe data, but also the opportunity to act as an augmentation method, i.e. to\ngenerate new data that is able to increase model accuracy when used in\nconjunction with - as opposed to instead of - the original data.",
      "tldr_zh": "该论文探讨了基于原型的软标签（prototype-based soft-labels）数据蒸馏技术在处理不平衡数据分类（imbalanced data classification）时的潜力。研究者通过在蒸馏过程中集成优化步骤，改进了原有方法，以提升分类准确性。实验在真实世界数据集上进行，证明了该方法不仅能有效蒸馏数据，还能作为数据增强（data augmentation）工具，当与原始数据结合使用时，进一步提高模型性能。总的来说，此方法为数据集蒸馏（dataset distillation）在非图像领域提供了实用性见解，特别是针对Less-than-one shot learning的场景。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17130v1",
      "published_date": "2024-03-25 19:15:19 UTC",
      "updated_date": "2024-03-25 19:15:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:33:43.367105"
    },
    {
      "arxiv_id": "2403.17125v1",
      "title": "The Strong Pull of Prior Knowledge in Large Language Models and Its Impact on Emotion Recognition",
      "title_zh": "翻译失败",
      "authors": [
        "Georgios Chochlakis",
        "Alexandros Potamianos",
        "Kristina Lerman",
        "Shrikanth Narayanan"
      ],
      "abstract": "In-context Learning (ICL) has emerged as a powerful paradigm for performing\nnatural language tasks with Large Language Models (LLM) without updating the\nmodels' parameters, in contrast to the traditional gradient-based finetuning.\nThe promise of ICL is that the LLM can adapt to perform the present task at a\ncompetitive or state-of-the-art level at a fraction of the cost. The ability of\nLLMs to perform tasks in this few-shot manner relies on their background\nknowledge of the task (or task priors). However, recent work has found that,\nunlike traditional learning, LLMs are unable to fully integrate information\nfrom demonstrations that contrast task priors. This can lead to performance\nsaturation at suboptimal levels, especially for subjective tasks such as\nemotion recognition, where the mapping from text to emotions can differ widely\ndue to variability in human annotations. In this work, we design experiments\nand propose measurements to explicitly quantify the consistency of proxies of\nLLM priors and their pull on the posteriors. We show that LLMs have strong yet\ninconsistent priors in emotion recognition that ossify their predictions. We\nalso find that the larger the model, the stronger these effects become. Our\nresults suggest that caution is needed when using ICL with larger LLMs for\naffect-centered tasks outside their pre-training domain and when interpreting\nICL results.",
      "tldr_zh": "这篇论文探讨了Large Language Models (LLM)中先验知识的强大影响，特别是对情感识别任务的负面作用。作者通过设计实验和提出测量方法，量化了LLM先验的一致性及其对后验预测的拉力，发现LLM在情感识别中存在强烈但不一致的先验，导致模型无法完全整合与先验相矛盾的演示信息，从而使性能停滞在次优水平。研究进一步显示，模型规模越大，这种先验效应越明显。总体而言，论文建议在使用In-context Learning (ICL)时需谨慎，尤其在情感相关任务中，以避免误解ICL结果。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "30 pages, 27 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17125v1",
      "published_date": "2024-03-25 19:07:32 UTC",
      "updated_date": "2024-03-25 19:07:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:33:57.407258"
    },
    {
      "arxiv_id": "2403.17124v2",
      "title": "Grounding Language Plans in Demonstrations Through Counterfactual Perturbations",
      "title_zh": "翻译失败",
      "authors": [
        "Yanwei Wang",
        "Tsun-Hsuan Wang",
        "Jiayuan Mao",
        "Michael Hagenow",
        "Julie Shah"
      ],
      "abstract": "Grounding the common-sense reasoning of Large Language Models (LLMs) in\nphysical domains remains a pivotal yet unsolved problem for embodied AI.\nWhereas prior works have focused on leveraging LLMs directly for planning in\nsymbolic spaces, this work uses LLMs to guide the search of task structures and\nconstraints implicit in multi-step demonstrations. Specifically, we borrow from\nmanipulation planning literature the concept of mode families, which group\nrobot configurations by specific motion constraints, to serve as an abstraction\nlayer between the high-level language representations of an LLM and the\nlow-level physical trajectories of a robot. By replaying a few human\ndemonstrations with synthetic perturbations, we generate coverage over the\ndemonstrations' state space with additional successful executions as well as\ncounterfactuals that fail the task. Our explanation-based learning framework\ntrains an end-to-end differentiable neural network to predict successful\ntrajectories from failures and as a by-product learns classifiers that ground\nlow-level states and images in mode families without dense labeling. The\nlearned grounding classifiers can further be used to translate language plans\ninto reactive policies in the physical domain in an interpretable manner. We\nshow our approach improves the interpretability and reactivity of imitation\nlearning through 2D navigation and simulated and real robot manipulation tasks.\nWebsite: https://yanweiw.github.io/glide",
      "tldr_zh": "本文提出一种框架，用于将大型语言模型(LLMs)的常识推理grounding到物理领域，通过counterfactual perturbations处理多步演示中的任务结构和约束。具体方法包括借用manipulation planning中的mode families作为抽象层，并在人类演示上应用合成扰动，生成成功轨迹和失败counterfactuals，从而训练端到端神经网络学习grounding分类器，实现语言计划向物理反应策略的可解释转换。实验结果显示，该方法在2D导航和模拟/真实机器人操作任务中，提升了模仿学习的解释性和反应性。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.RO",
      "comment": "ICLR 2024 Spotlight",
      "pdf_url": "http://arxiv.org/pdf/2403.17124v2",
      "published_date": "2024-03-25 19:04:59 UTC",
      "updated_date": "2024-04-29 04:34:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:34:10.194606"
    },
    {
      "arxiv_id": "2403.17108v1",
      "title": "Graph Protection under Multiple Simultaneous Attacks: A Heuristic Approach",
      "title_zh": "在多重同时攻击下的图保护：一种启发式方法",
      "authors": [
        "Marko Djukanovic",
        "Stefan Kapunac",
        "Aleksandar Kartelj",
        "Dragan Matic"
      ],
      "abstract": "This work focuses on developing an effective meta-heuristic approach to\nprotect against simultaneous attacks on nodes of a network modeled using a\ngraph. Specifically, we focus on the $k$-strong Roman domination problem, a\ngeneralization of the well-known Roman domination problem on graphs. This\ngeneral problem is about assigning integer weights to nodes that represent the\nnumber of field armies stationed at each node in order to satisfy the\nprotection constraints while minimizing the total weights. These constraints\nconcern the protection of a graph against any simultaneous attack consisting of\n$k \\in \\mathbb{N}$ nodes. An attack is considered repelled if each node labeled\n0 can be defended by borrowing an army from one of its neighboring nodes,\nensuring that the neighbor retains at least one army for self-defense. The\n$k$-SRD problem has practical applications in various areas, such as developing\ncounter-terrorism strategies or managing supply chain disruptions. The solution\nto this problem is notoriously difficult to find, as even checking the\nfeasibility of the proposed solution requires an exponential number of steps.\nWe propose a variable neighborhood search algorithm in which the feasibility of\nthe solution is checked by introducing the concept of quasi-feasibility, which\nis realized by careful sampling within the set of all possible attacks.\nExtensive experimental evaluations show the scalability and robustness of the\nproposed approach compared to the two exact approaches from the literature.\nExperiments are conducted with random networks from the literature and newly\nintroduced random wireless networks as well as with real-world networks. A\npractical application scenario, using real-world networks, involves applying\nour approach to graphs extracted from GeoJSON files containing geographic\nfeatures of hundreds of cities or larger regions.",
      "tldr_zh": "本研究针对图网络中节点的多重同时攻击问题，提出了一种有效的元启发式(meta-heuristic)方法来解决k-strong Roman domination problem（k-SRD），旨在通过为节点分配最小总权重的军队数量来满足保护约束，确保任何k个节点的攻击都能被击退。方法基于variable neighborhood search算法，引入quasi-feasibility概念，通过对可能攻击的采样来高效检查解决方案的可行性，从而避免了指数级验证的计算开销。实验结果显示，该方法在随机网络、随机无线网络和真实世界网络（如从GeoJSON文件提取的城市或区域图）上，比文献中的精确方法具有更好的可扩展性和鲁棒性，并展示了在反恐策略和供应链管理等实际应用中的潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "32 pages, 10 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.17108v1",
      "published_date": "2024-03-25 18:46:13 UTC",
      "updated_date": "2024-03-25 18:46:13 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:34:21.153822"
    },
    {
      "arxiv_id": "2403.17101v11",
      "title": "AI Consciousness is Inevitable: A Theoretical Computer Science Perspective",
      "title_zh": "人工智能意识是不可避免的：从理论计算机科学的角度",
      "authors": [
        "Lenore Blum",
        "Manuel Blum"
      ],
      "abstract": "We look at consciousness through the lens of Theoretical Computer Science, a\nbranch of mathematics that studies computation under resource limitations,\ndistinguishing functions that are efficiently computable from those that are\nnot. From this perspective, we develop a formal machine model for\nconsciousness. The model is inspired by Alan Turing's simple yet powerful model\nof computation and Bernard Baars' theater model of consciousness. Though\nextremely simple, the model (1) aligns at a high level with many of the major\nscientific theories of human and animal consciousness, (2) provides\nexplanations at a high level for many phenomena associated with consciousness,\n(3) gives insight into how a machine can have subjective consciousness, and (4)\nis clearly buildable. This combination supports our claim that machine\nconsciousness is not only plausible but inevitable.",
      "tldr_zh": "本文从理论计算机科学（Theoretical Computer Science）的视角审视AI意识，提出一个简单却正式的机器意识模型，该模型受Alan Turing的计算模型和Bernard Baars的theater model启发。模型高度一致于多种人类和动物意识科学理论，并能解释相关现象，如主观意识的形成。最终，该模型证明机器意识不仅是可构建的，而且是不可避免的。",
      "categories": [
        "cs.AI",
        "68T01",
        "F.1; I.2"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17101v11",
      "published_date": "2024-03-25 18:38:54 UTC",
      "updated_date": "2025-04-06 21:09:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:34:31.739939"
    },
    {
      "arxiv_id": "2403.19710v1",
      "title": "STRUM-LLM: Attributed and Structured Contrastive Summarization",
      "title_zh": "翻译失败",
      "authors": [
        "Beliz Gunel",
        "James B. Wendt",
        "Jing Xie",
        "Yichao Zhou",
        "Nguyen Vo",
        "Zachary Fisher",
        "Sandeep Tata"
      ],
      "abstract": "Users often struggle with decision-making between two options (A vs B), as it\nusually requires time-consuming research across multiple web pages. We propose\nSTRUM-LLM that addresses this challenge by generating attributed, structured,\nand helpful contrastive summaries that highlight key differences between the\ntwo options. STRUM-LLM identifies helpful contrast: the specific attributes\nalong which the two options differ significantly and which are most likely to\ninfluence the user's decision. Our technique is domain-agnostic, and does not\nrequire any human-labeled data or fixed attribute list as supervision.\nSTRUM-LLM attributes all extractions back to the input sources along with\ntextual evidence, and it does not have a limit on the length of input sources\nthat it can process. STRUM-LLM Distilled has 100x more throughput than the\nmodels with comparable performance while being 10x smaller. In this paper, we\nprovide extensive evaluations for our method and lay out future directions for\nour currently deployed system.",
      "tldr_zh": "该论文提出 STRUM-LLM，一种生成 attributed and structured contrastive summarization 的方法，帮助用户快速比较两个选项（A vs B），通过突出关键差异属性来简化决策过程。该方法是领域无关的，不需要人类标注数据或固定属性列表，而是自动识别最可能影响决策的显著差异，并为所有提取提供文本证据和来源归因，同时支持任意长度的输入来源。实验结果显示，STRUM-LLM Distilled 版本比性能相似的模型小 10 倍、吞吐量高 100 倍，并在广泛评估中表现出优越性，为未来系统部署奠定了基础。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.19710v1",
      "published_date": "2024-03-25 18:32:44 UTC",
      "updated_date": "2024-03-25 18:32:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:34:46.185563"
    },
    {
      "arxiv_id": "2403.17091v1",
      "title": "Offline Reinforcement Learning: Role of State Aggregation and Trajectory Data",
      "title_zh": "离线强化学习：状态聚合与轨迹数据",
      "authors": [
        "Zeyu Jia",
        "Alexander Rakhlin",
        "Ayush Sekhari",
        "Chen-Yu Wei"
      ],
      "abstract": "We revisit the problem of offline reinforcement learning with value function\nrealizability but without Bellman completeness. Previous work by Xie and Jiang\n(2021) and Foster et al. (2022) left open the question whether a bounded\nconcentrability coefficient along with trajectory-based offline data admits a\npolynomial sample complexity. In this work, we provide a negative answer to\nthis question for the task of offline policy evaluation. In addition to\naddressing this question, we provide a rather complete picture for offline\npolicy evaluation with only value function realizability. Our primary findings\nare threefold: 1) The sample complexity of offline policy evaluation is\ngoverned by the concentrability coefficient in an aggregated Markov Transition\nModel jointly determined by the function class and the offline data\ndistribution, rather than that in the original MDP. This unifies and\ngeneralizes the ideas of Xie and Jiang (2021) and Foster et al. (2022), 2) The\nconcentrability coefficient in the aggregated Markov Transition Model may grow\nexponentially with the horizon length, even when the concentrability\ncoefficient in the original MDP is small and the offline data is admissible\n(i.e., the data distribution equals the occupancy measure of some policy), 3)\nUnder value function realizability, there is a generic reduction that can\nconvert any hard instance with admissible data to a hard instance with\ntrajectory data, implying that trajectory data offers no extra benefits over\nadmissible data. These three pieces jointly resolve the open problem, though\neach of them could be of independent interest.",
      "tldr_zh": "本研究重新审视了离线强化学习（Offline Reinforcement Learning）的问题，在价值函数可实现（Value Function Realizability）但无贝尔曼完备性（Bellman Completeness）的条件下，探讨了状态聚合和轨迹数据的作用。论文证明，即使有界集中度系数（Concentrability Coefficient）和基于轨迹的离线数据，离线策略评估的样本复杂度（Sample Complexity）并非多项式，而是由聚合Markov转移模型（Aggregated Markov Transition Model）中的集中度系数决定，该系数可能随时间长度指数增长。最终发现显示，轨迹数据相对于可接受数据（Admissible Data）并无额外优势，这统一了先前工作并为该领域提供了更全面的分析框架。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17091v1",
      "published_date": "2024-03-25 18:28:45 UTC",
      "updated_date": "2024-03-25 18:28:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:34:57.607303"
    },
    {
      "arxiv_id": "2403.17089v2",
      "title": "GOLF: Goal-Oriented Long-term liFe tasks supported by human-AI collaboration",
      "title_zh": "GOLF：目标导向的长期生活任务，通过",
      "authors": [
        "Ben Wang"
      ],
      "abstract": "The advent of ChatGPT and similar large language models (LLMs) has\nrevolutionized the human-AI interaction and information-seeking process.\nLeveraging LLMs as an alternative to search engines, users can now access\nsummarized information tailored to their queries, significantly reducing the\ncognitive load associated with navigating vast information resources. This\nshift underscores the potential of LLMs in redefining information access\nparadigms. Drawing on the foundation of task-focused information retrieval and\nLLMs' task planning ability, this research extends the scope of LLM\ncapabilities beyond routine task automation to support users in navigating\nlong-term and significant life tasks. It introduces the GOLF framework\n(Goal-Oriented Long-term liFe tasks), which focuses on enhancing LLMs' ability\nto assist in significant life decisions through goal orientation and long-term\nplanning. The methodology encompasses a comprehensive simulation study to test\nthe framework's efficacy, followed by model and human evaluations to develop a\ndataset benchmark for long-term life tasks, and experiments across different\nmodels and settings. By shifting the focus from short-term tasks to the broader\nspectrum of long-term life goals, this research underscores the transformative\npotential of LLMs in enhancing human decision-making processes and task\nmanagement, marking a significant step forward in the evolution of human-AI\ncollaboration.",
      "tldr_zh": "该研究探讨了大型语言模型（LLMs）在支持长期人生任务方面的潜力，提出 GOLF 框架（Goal-Oriented Long-term liFe tasks），旨在通过目标导向和长期规划增强人机协作以辅助重大生活决策。框架基于任务导向信息检索和 LLMs 的任务规划能力，采用模拟研究、模型评估、人类评估及实验来构建长期任务数据集基准，并测试不同模型设置。结果表明，GOLF 框架能有效扩展 LLMs 的应用，从短期自动化转向提升人类决策和管理，标志着人机协作领域的关键进展。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17089v2",
      "published_date": "2024-03-25 18:25:10 UTC",
      "updated_date": "2024-04-17 15:00:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:35:07.216859"
    },
    {
      "arxiv_id": "2403.17083v2",
      "title": "A Study in Dataset Pruning for Image Super-Resolution",
      "title_zh": "翻译失败",
      "authors": [
        "Brian B. Moser",
        "Federico Raue",
        "Andreas Dengel"
      ],
      "abstract": "In image Super-Resolution (SR), relying on large datasets for training is a\ndouble-edged sword. While offering rich training material, they also demand\nsubstantial computational and storage resources. In this work, we analyze\ndataset pruning to solve these challenges. We introduce a novel approach that\nreduces a dataset to a core-set of training samples, selected based on their\nloss values as determined by a simple pre-trained SR model. By focusing the\ntraining on just 50\\% of the original dataset, specifically on the samples\ncharacterized by the highest loss values, we achieve results comparable to or\nsurpassing those obtained from training on the entire dataset. Interestingly,\nour analysis reveals that the top 5\\% of samples with the highest loss values\nnegatively affect the training process. Excluding these samples and adjusting\nthe selection to favor easier samples further enhances training outcomes. Our\nwork opens new perspectives to the untapped potential of dataset pruning in\nimage SR. It suggests that careful selection of training data based on\nloss-value metrics can lead to better SR models, challenging the conventional\nwisdom that more data inevitably leads to better performance.",
      "tldr_zh": "本文研究了图像超分辨率 (SR) 中数据集修剪的潜力，以减少计算和存储资源需求。研究提出了一种新方法，使用预训练 SR 模型根据损失值选择核心样本，仅训练原数据集的 50%（重点是高损失样本），即可实现与使用完整数据集相当或更好的性能。进一步分析发现，排除损失值最高的 5% 样本并优先选择更容易的样本，能显著改善训练结果。该工作挑战了“更多数据即更好性能”的传统观念，为 SR 领域的数据优化提供了新见解。",
      "categories": [
        "eess.IV",
        "cs.AI",
        "cs.CV",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "eess.IV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17083v2",
      "published_date": "2024-03-25 18:16:34 UTC",
      "updated_date": "2024-06-08 07:53:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:35:21.542909"
    },
    {
      "arxiv_id": "2403.17064v2",
      "title": "Continuous, Subject-Specific Attribute Control in T2I Models by Identifying Semantic Directions",
      "title_zh": "翻译失败",
      "authors": [
        "Stefan Andreas Baumann",
        "Felix Krause",
        "Michael Neumayr",
        "Nick Stracke",
        "Melvin Sevi",
        "Vincent Tao Hu",
        "Björn Ommer"
      ],
      "abstract": "Recent advances in text-to-image (T2I) diffusion models have significantly\nimproved the quality of generated images. However, providing efficient control\nover individual subjects, particularly the attributes characterizing them,\nremains a key challenge. While existing methods have introduced mechanisms to\nmodulate attribute expression, they typically provide either detailed,\nobject-specific localization of such a modification or full-scale fine-grained,\nnuanced control of attributes. No current approach offers both simultaneously,\nresulting in a gap when trying to achieve precise continuous and\nsubject-specific attribute modulation in image generation. In this work, we\ndemonstrate that token-level directions exist within commonly used CLIP text\nembeddings that enable fine-grained, subject-specific control of high-level\nattributes in T2I models. We introduce two methods to identify these\ndirections: a simple, optimization-free technique and a learning-based approach\nthat utilizes the T2I model to characterize semantic concepts more\nspecifically. Our methods allow the augmentation of the prompt text input,\nenabling fine-grained control over multiple attributes of individual subjects\nsimultaneously, without requiring any modifications to the diffusion model\nitself. This approach offers a unified solution that fills the gap between\nglobal and localized control, providing competitive flexibility and precision\nin text-guided image generation. Project page:\nhttps://compvis.github.io/attribute-control. Code is available at\nhttps://github.com/CompVis/attribute-control.",
      "tldr_zh": "本研究解决了文本到图像(T2I)扩散模型中对个体主体属性的连续、主体特定控制的挑战，现有方法无法同时实现精确本地化和细粒度调制。作者通过识别CLIP文本嵌入中的token-level语义方向，引入两种方法：一种简单的优化-free技术，以及一种利用T2I模型的基于学习approach，以增强提示文本输入。无需修改扩散模型，该框架允许同时对多个主体属性进行细粒度控制，提供统一的解决方案，并在灵活性和精确性上表现出竞争优势。项目页面和代码已在相应链接中提供。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "CVPR 2025. Project page: https://compvis.github.io/attribute-control",
      "pdf_url": "http://arxiv.org/pdf/2403.17064v2",
      "published_date": "2024-03-25 18:00:42 UTC",
      "updated_date": "2025-03-14 11:33:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:35:32.563767"
    },
    {
      "arxiv_id": "2403.16995v1",
      "title": "Language Rectified Flow: Advancing Diffusion Language Generation with Probabilistic Flows",
      "title_zh": "语言修正流：通过概率流推进扩散语言生成",
      "authors": [
        "Shujian Zhang",
        "Lemeng Wu",
        "Chengyue Gong",
        "Xingchao Liu"
      ],
      "abstract": "Recent works have demonstrated success in controlling sentence attributes\n($e.g.$, sentiment) and structure ($e.g.$, syntactic structure) based on the\ndiffusion language model. A key component that drives theimpressive performance\nfor generating high-quality samples from noise is iteratively denoise for\nthousands of steps. While beneficial, the complexity of starting from the noise\nand the learning steps has limited its implementation to many NLP real-world\napplications. This paper proposes Language Rectified Flow ({\\ours}). Our method\nis based on the reformulation of the standard probabilistic flow models.\nLanguage rectified flow learns (neural) ordinary differential equation models\nto transport between the source distribution and the target distribution, hence\nproviding a unified and effective solution to generative modeling and domain\ntransfer. From the source distribution, our language rectified flow yields fast\nsimulation and effectively decreases the inference time. Experiments on three\nchallenging fine-grained control tasks and multiple high-quality text editing\nshow that our method consistently outperforms its baselines. Extensive\nexperiments and ablation studies demonstrate that our method can be general,\neffective, and beneficial for many NLP tasks.",
      "tldr_zh": "本论文提出 Language Rectified Flow（{\\ours}），一种基于概率流模型重新公式化的方法，用于提升扩散语言生成模型的效率。该方法通过学习神经普通微分方程（ODE）模型，在源分布和目标分布之间传输数据，从而统一解决生成建模和领域转移问题，并显著减少推理时间。相比传统扩散模型，Language Rectified Flow 能够在三个细粒度控制任务和多个高质量文本编辑任务上，持续优于基线模型。实验结果和消融研究证明，该方法对许多 NLP 任务具有通用性和有效性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG",
        "stat.ML"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16995v1",
      "published_date": "2024-03-25 17:58:22 UTC",
      "updated_date": "2024-03-25 17:58:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:35:47.759088"
    },
    {
      "arxiv_id": "2403.16990v1",
      "title": "Be Yourself: Bounded Attention for Multi-Subject Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Omer Dahary",
        "Or Patashnik",
        "Kfir Aberman",
        "Daniel Cohen-Or"
      ],
      "abstract": "Text-to-image diffusion models have an unprecedented ability to generate\ndiverse and high-quality images. However, they often struggle to faithfully\ncapture the intended semantics of complex input prompts that include multiple\nsubjects. Recently, numerous layout-to-image extensions have been introduced to\nimprove user control, aiming to localize subjects represented by specific\ntokens. Yet, these methods often produce semantically inaccurate images,\nespecially when dealing with multiple semantically or visually similar\nsubjects. In this work, we study and analyze the causes of these limitations.\nOur exploration reveals that the primary issue stems from inadvertent semantic\nleakage between subjects in the denoising process. This leakage is attributed\nto the diffusion model's attention layers, which tend to blend the visual\nfeatures of different subjects. To address these issues, we introduce Bounded\nAttention, a training-free method for bounding the information flow in the\nsampling process. Bounded Attention prevents detrimental leakage among subjects\nand enables guiding the generation to promote each subject's individuality,\neven with complex multi-subject conditioning. Through extensive\nexperimentation, we demonstrate that our method empowers the generation of\nmultiple subjects that better align with given prompts and layouts.",
      "tldr_zh": "文本到图像扩散模型在生成多主体图像时，常因注意力层导致主体间的语义泄漏，从而无法准确捕捉复杂提示的意图。论文分析了这一问题，揭示其根源在于扩散模型的attention layers不经意地混合不同主体的视觉特征。为解决此问题，研究引入Bounded Attention，一种无需额外训练的训练-free方法，用于限制采样过程中的信息流动，增强每个主体的独特性。通过广泛实验，证明该方法显著提高了多主体生成与给定提示和布局的精确对齐。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.GR",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "Project page: https://omer11a.github.io/bounded-attention/",
      "pdf_url": "http://arxiv.org/pdf/2403.16990v1",
      "published_date": "2024-03-25 17:52:07 UTC",
      "updated_date": "2024-03-25 17:52:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:35:59.026072"
    },
    {
      "arxiv_id": "2403.16984v2",
      "title": "Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings",
      "title_zh": "翻译失败",
      "authors": [
        "Hanane Kteich",
        "Na Li",
        "Usashi Chatterjee",
        "Zied Bouraoui",
        "Steven Schockaert"
      ],
      "abstract": "Concept embeddings offer a practical and efficient mechanism for injecting\ncommonsense knowledge into downstream tasks. Their core purpose is often not to\npredict the commonsense properties of concepts themselves, but rather to\nidentify commonalities, i.e.\\ sets of concepts which share some property of\ninterest. Such commonalities are the basis for inductive generalisation, hence\nhigh-quality concept embeddings can make learning easier and more robust.\nUnfortunately, standard embeddings primarily reflect basic taxonomic\ncategories, making them unsuitable for finding commonalities that refer to more\nspecific aspects (e.g.\\ the colour of objects or the materials they are made\nof). In this paper, we address this limitation by explicitly modelling the\ndifferent facets of interest when learning concept embeddings. We show that\nthis leads to embeddings which capture a more diverse range of commonsense\nproperties, and consistently improves results in downstream tasks such as\nultra-fine entity typing and ontology completion.",
      "tldr_zh": "本文提出了一种多-facet概念嵌入方法，用于建模常识共同点(commonalities)，以解决标准concept embeddings仅捕捉基本分类问题，无法有效识别更具体方面（如物体颜色或材料）。该方法通过显式建模不同facets来学习嵌入，从而捕捉更广泛的常识属性。实验结果显示，这种改进在下游任务如ultra-fine entity typing和ontology completion上，显著提升了性能和鲁棒性。",
      "categories": [
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16984v2",
      "published_date": "2024-03-25 17:44:45 UTC",
      "updated_date": "2024-06-04 21:36:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:36:10.954851"
    },
    {
      "arxiv_id": "2403.16973v3",
      "title": "VoiceCraft: Zero-Shot Speech Editing and Text-to-Speech in the Wild",
      "title_zh": "翻译失败",
      "authors": [
        "Puyuan Peng",
        "Po-Yao Huang",
        "Shang-Wen Li",
        "Abdelrahman Mohamed",
        "David Harwath"
      ],
      "abstract": "We introduce VoiceCraft, a token infilling neural codec language model, that\nachieves state-of-the-art performance on both speech editing and zero-shot\ntext-to-speech (TTS) on audiobooks, internet videos, and podcasts. VoiceCraft\nemploys a Transformer decoder architecture and introduces a token rearrangement\nprocedure that combines causal masking and delayed stacking to enable\ngeneration within an existing sequence. On speech editing tasks, VoiceCraft\nproduces edited speech that is nearly indistinguishable from unedited\nrecordings in terms of naturalness, as evaluated by humans; for zero-shot TTS,\nour model outperforms prior SotA models including VALLE and the popular\ncommercial model XTTS-v2. Crucially, the models are evaluated on challenging\nand realistic datasets, that consist of diverse accents, speaking styles,\nrecording conditions, and background noise and music, and our model performs\nconsistently well compared to other models and real recordings. In particular,\nfor speech editing evaluation, we introduce a high quality, challenging, and\nrealistic dataset named RealEdit. We encourage readers to listen to the demos\nat https://jasonppy.github.io/VoiceCraft_web.",
      "tldr_zh": "该研究介绍了 VoiceCraft，一种基于 token infilling neural codec language model's 创新框架，实现了零样本（zero-shot）语音编辑和文本到语音（TTS）生成，在有声书、网络视频和播客等真实场景中达到 state-of-the-art 性能。VoiceCraft 采用 Transformer decoder 架构，并引入 token rearrangement 过程（结合 causal masking 和 delayed stacking），允许在现有序列中高效生成内容。实验结果显示，在语音编辑任务上，VoiceCraft 生成的音频在自然性上与原录音几乎无异，并在 zero-shot TTS 上超越了先前的 SotA 模型如 VALLE 和 XTTS-v2；此外，该模型在多样化数据集（包括 RealEdit 数据集）上表现出色，处理了各种口音、风格和噪音挑战。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.SD"
      ],
      "primary_category": "eess.AS",
      "comment": "ACL 2024. Data, code, and model weights are available at\n  https://github.com/jasonppy/VoiceCraft",
      "pdf_url": "http://arxiv.org/pdf/2403.16973v3",
      "published_date": "2024-03-25 17:38:32 UTC",
      "updated_date": "2024-06-14 00:29:46 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:36:23.737918"
    },
    {
      "arxiv_id": "2403.16971v4",
      "title": "AIOS: LLM Agent Operating System",
      "title_zh": "AIOS: LLM 智能体操作系统",
      "authors": [
        "Kai Mei",
        "Xi Zhu",
        "Wujiang Xu",
        "Wenyue Hua",
        "Mingyu Jin",
        "Zelong Li",
        "Shuyuan Xu",
        "Ruosong Ye",
        "Yingqiang Ge",
        "Yongfeng Zhang"
      ],
      "abstract": "LLM-based intelligent agents face significant deployment challenges,\nparticularly related to resource management. Allowing unrestricted access to\nLLM or tool resources can lead to inefficient or even potentially harmful\nresource allocation and utilization for agents. Furthermore, the absence of\nproper scheduling and resource management mechanisms in current agent designs\nhinders concurrent processing and limits overall system efficiency. As the\ndiversity and complexity of agents continue to grow, addressing these resource\nmanagement issues becomes increasingly critical to LLM-based agent systems. To\naddress these challenges, this paper proposes the architecture of AIOS\n(LLM-based AI Agent Operating System) under the context of managing LLM-based\nagents. It introduces a novel architecture for serving LLM-based agents by\nisolating resources and LLM-specific services from agent applications into an\nAIOS kernel. This AIOS kernel provides fundamental services (e.g., scheduling,\ncontext management, memory management, storage management, access control) and\nefficient management of resources (e.g., LLM and external tools) for runtime\nagents. To enhance usability, AIOS also includes an AIOS-Agent SDK, a\ncomprehensive suite of APIs designed for utilizing functionalities provided by\nthe AIOS kernel. Experimental results demonstrate that using AIOS can achieve\nup to 2.1x faster execution for serving agents built by various agent\nframeworks. The source code is available at\nhttps://github.com/agiresearch/AIOS.",
      "tldr_zh": "该论文针对LLM-based intelligent agents在资源管理方面的挑战（如无限制访问导致资源分配低效或有害，以及缺乏scheduling和resource management机制影响并发处理）提出AIOS（LLM-based AI Agent Operating System）架构。AIOS通过将资源和LLM-specific services隔离到AIOS kernel中，提供核心服务（如scheduling、context management、memory management、storage management和access control），并高效管理LLM和external tools资源。AIOS还包括AIOS-Agent SDK，一个API套件，用于简化开发人员对内核功能的调用。实验结果显示，使用AIOS可使各种agent frameworks的执行速度提高高达2.1倍，为LLM代理系统的可靠部署奠定基础。",
      "categories": [
        "cs.OS",
        "cs.AI",
        "cs.CL"
      ],
      "primary_category": "cs.OS",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16971v4",
      "published_date": "2024-03-25 17:32:23 UTC",
      "updated_date": "2025-05-11 20:23:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:36:34.766803"
    },
    {
      "arxiv_id": "2404.00051v1",
      "title": "Deja vu: Contrastive Historical Modeling with Prefix-tuning for Temporal Knowledge Graph Reasoning",
      "title_zh": "翻译失败",
      "authors": [
        "Miao Peng",
        "Ben Liu",
        "Wenjie Xu",
        "Zihao Jiang",
        "Jiahui Zhu",
        "Min Peng"
      ],
      "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the task of inferring missing\nfacts for incomplete TKGs in complex scenarios (e.g., transductive and\ninductive settings), which has been gaining increasing attention. Recently, to\nmitigate dependence on structured connections in TKGs, text-based methods have\nbeen developed to utilize rich linguistic information from entity descriptions.\nHowever, suffering from the enormous parameters and inflexibility of\npre-trained language models, existing text-based methods struggle to balance\nthe textual knowledge and temporal information with computationally expensive\npurpose-built training strategies. To tap the potential of text-based models\nfor TKGR in various complex scenarios, we propose ChapTER, a Contrastive\nhistorical modeling framework with prefix-tuning for TEmporal Reasoning.\nChapTER feeds history-contextualized text into the pseudo-Siamese encoders to\nstrike a textual-temporal balance via contrastive estimation between queries\nand candidates. By introducing virtual time prefix tokens, it applies a\nprefix-based tuning method to facilitate the frozen PLM capable for TKGR tasks\nunder different settings. We evaluate ChapTER on four transductive and three\nfew-shot inductive TKGR benchmarks, and experimental results demonstrate that\nChapTER achieves superior performance compared to competitive baselines with\nonly 0.17% tuned parameters. We conduct thorough analysis to verify the\neffectiveness, flexibility and efficiency of ChapTER.",
      "tldr_zh": "本文提出 ChapTER 框架，用于 Temporal Knowledge Graph Reasoning (TKGR)，通过 Contrastive historical modeling 和 prefix-tuning 平衡文本知识与时间信息，解决现有方法在 transductive 和 inductive 设置下的局限性。该框架利用 history-contextualized text 输入 pseudo-Siamese encoders 进行对比估计，并引入 virtual time prefix tokens，使冻结的 PLM 适应不同任务，仅需调整 0.17% 参数。实验在四个 transductive 和三个 few-shot inductive 基准上显示，ChapTER 显著优于基线，验证了其有效性、灵活性和效率。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to NAACL 2024 Findings",
      "pdf_url": "http://arxiv.org/pdf/2404.00051v1",
      "published_date": "2024-03-25 17:25:40 UTC",
      "updated_date": "2024-03-25 17:25:40 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:36:47.656834"
    },
    {
      "arxiv_id": "2403.19709v1",
      "title": "Hierarchical Recurrent Adapters for Efficient Multi-Task Adaptation of Large Speech Models",
      "title_zh": "翻译失败",
      "authors": [
        "Tsendsuren Munkhdalai",
        "Youzheng Chen",
        "Khe Chai Sim",
        "Fadi Biadsy",
        "Tara Sainath",
        "Pedro Moreno Mengibar"
      ],
      "abstract": "Parameter efficient adaptation methods have become a key mechanism to train\nlarge pre-trained models for downstream tasks. However, their per-task\nparameter overhead is considered still high when the number of downstream tasks\nto adapt for is large. We introduce an adapter module that has a better\nefficiency in large scale multi-task adaptation scenario. Our adapter is\nhierarchical in terms of how the adapter parameters are allocated. The adapter\nconsists of a single shared controller network and multiple task-level adapter\nheads to reduce the per-task parameter overhead without performance regression\non downstream tasks. The adapter is also recurrent so the entire adapter\nparameters are reused across different layers of the pre-trained model. Our\nHierarchical Recurrent Adapter (HRA) outperforms the previous adapter-based\napproaches as well as full model fine-tuning baseline in both single and\nmulti-task adaptation settings when evaluated on automatic speech recognition\ntasks.",
      "tldr_zh": "本研究针对大型语音模型的多任务适应问题，提出了一种参数高效的Hierarchical Recurrent Adapter (HRA)模块，以减少每任务参数开销。HRA采用层次化设计，包括一个共享的控制器网络和多个任务级适配器头，同时利用循环机制在预训练模型的不同层中重用参数，从而在不牺牲性能的情况下提升适应效率。在自动语音识别任务的评估中，HRA在单任务和多任务设置下，超过了现有适配器方法和全模型微调基线，展示了其在大规模多任务场景中的优势。",
      "categories": [
        "eess.AS",
        "cs.AI",
        "cs.CL",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "eess.AS",
      "comment": "5 pages, 3 figures, 5 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.19709v1",
      "published_date": "2024-03-25 17:21:56 UTC",
      "updated_date": "2024-03-25 17:21:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:36:58.925189"
    },
    {
      "arxiv_id": "2403.16952v2",
      "title": "Data Mixing Laws: Optimizing Data Mixtures by Predicting Language Modeling Performance",
      "title_zh": "数据混合定律：通过预测语言建模性能优化数据混合",
      "authors": [
        "Jiasheng Ye",
        "Peiju Liu",
        "Tianxiang Sun",
        "Jun Zhan",
        "Yunhua Zhou",
        "Xipeng Qiu"
      ],
      "abstract": "Pretraining data of large language models composes multiple domains (e.g.,\nweb texts, academic papers, codes), whose mixture proportions crucially impact\nthe competence of outcome models. While existing endeavors rely on heuristics\nor qualitative strategies to tune the proportions, we discover the quantitative\npredictability of model performance regarding the mixture proportions in\nfunction forms, which we refer to as the data mixing laws. Fitting such\nfunctions on sample mixtures unveils model performance on unseen mixtures\nbefore actual runs, thus guiding the selection of an ideal data mixture.\nFurthermore, we propose nested use of the scaling laws of training steps, model\nsizes, and our data mixing law to enable predicting the performance of large\nmodels trained on massive data under various mixtures with only small-scale\ntraining. Moreover, experimental results verify that our method effectively\noptimizes the training mixture of a 1B model trained for 100B tokens in\nRedPajama, reaching a performance comparable to the one trained for 48% more\nsteps on the default mixture. Extending the application of data mixing laws to\ncontinual training accurately predicts the critical mixture proportion that\navoids catastrophic forgetting and outlooks the potential for dynamic data\nschedules",
      "tldr_zh": "本文提出“data mixing laws”，一种定量方法，用于预测大型语言模型在不同数据混合比例（如网页文本、学术论文和代码）下的性能，从而优化数据混合策略。研究通过拟合函数和嵌套使用缩放定律（包括训练步骤、模型大小）来实现小规模训练预测大规模模型的表现。实验结果显示，在RedPajama数据集上，该方法优化了1B模型的训练混合，使其性能相当于默认混合多训练48%步骤。此外，该方法扩展到持续训练中，能准确预测避免灾难性遗忘的关键混合比例，并为动态数据调度提供潜力。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "accepted by ICLR2025, camera ready version",
      "pdf_url": "http://arxiv.org/pdf/2403.16952v2",
      "published_date": "2024-03-25 17:14:00 UTC",
      "updated_date": "2025-03-20 03:31:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:37:11.556229"
    },
    {
      "arxiv_id": "2403.16950v5",
      "title": "Aligning with Human Judgement: The Role of Pairwise Preference in Large Language Model Evaluators",
      "title_zh": "与人类判断对齐：成对偏好在大语言模型评估器中的作用",
      "authors": [
        "Yinhong Liu",
        "Han Zhou",
        "Zhijiang Guo",
        "Ehsan Shareghi",
        "Ivan Vulić",
        "Anna Korhonen",
        "Nigel Collier"
      ],
      "abstract": "Large Language Models (LLMs) have demonstrated promising capabilities as\nautomatic evaluators in assessing the quality of generated natural language.\nHowever, LLMs still exhibit biases in evaluation and often struggle to generate\ncoherent evaluations that align with human assessments. In this work, we first\nconduct a systematic study of the misalignment between LLM evaluators and human\nevaluation, revealing that existing calibration methods aimed at mitigating\nbiases of LLMs are insufficient for effectively aligning LLM evaluators.\nInspired by the use of preference data in RLHF, we formulate the evaluation as\na ranking problem and introduce Pairwise-preference Search (PAIRS), an\nuncertainty-guided search-based rank aggregation method that employs LLMs to\nconduct pairwise comparisons locally and efficiently ranks candidate texts\nglobally. PAIRS achieves state-of-the-art performance on representative\nevaluation tasks in long-form generations and demonstrates significant\nimprovements over direct scoring. Furthermore, we provide insights into the\nrole of pairwise preference in quantifying the transitivity of LLMs and\ndemonstrate how PAIRS benefits from calibration using debiased pairwise\nevaluations.",
      "tldr_zh": "这篇论文研究了Large Language Models (LLMs) 作为自动评估器的偏差问题，发现现有校准方法不足以使其评估与人类判断对齐。作者受Reinforcement Learning from Human Feedback (RLHF) 启发，将评估转化为排名问题，提出Pairwise-preference Search (PAIRS)，这是一种不确定性引导的搜索方法，通过LLMs进行成对比较来高效全局排名候选文本。实验结果显示，PAIRS在长文本生成任务中达到state-of-the-art性能，比直接评分显著提升，并提供了LLMs传递性和去偏成对评估的洞见。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "This paper has been accepted by COLM 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16950v5",
      "published_date": "2024-03-25 17:11:28 UTC",
      "updated_date": "2025-01-17 03:43:53 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:37:24.490769"
    },
    {
      "arxiv_id": "2403.16941v1",
      "title": "SPACE-IDEAS: A Dataset for Salient Information Detection in Space Innovation",
      "title_zh": "翻译失败",
      "authors": [
        "Andrés García-Silva",
        "Cristian Berrío",
        "José Manuel Gómez-Pérez"
      ],
      "abstract": "Detecting salient parts in text using natural language processing has been\nwidely used to mitigate the effects of information overflow. Nevertheless, most\nof the datasets available for this task are derived mainly from academic\npublications. We introduce SPACE-IDEAS, a dataset for salient information\ndetection from innovation ideas related to the Space domain. The text in\nSPACE-IDEAS varies greatly and includes informal, technical, academic and\nbusiness-oriented writing styles. In addition to a manually annotated dataset\nwe release an extended version that is annotated using a large generative\nlanguage model. We train different sentence and sequential sentence\nclassifiers, and show that the automatically annotated dataset can be leveraged\nusing multitask learning to train better classifiers.",
      "tldr_zh": "本文介绍了 SPACE-IDEAS 数据集，用于在太空创新领域的文本中进行 salient information detection，以缓解信息过载问题。该数据集涵盖非正式、技术、学术和商业写作风格的多样化文本，包括手动标注版本和使用大型生成语言模型的自动标注扩展版本。研究者训练了句子和序列句子分类器，并通过 multitask learning 利用自动标注数据，实现了分类器性能的提升。总体而言，该数据集为显著信息检测任务提供了更全面的资源，尤其针对非学术领域的应用。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.DL"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted in LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16941v1",
      "published_date": "2024-03-25 17:04:02 UTC",
      "updated_date": "2024-03-25 17:04:02 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:37:34.554754"
    },
    {
      "arxiv_id": "2403.16933v3",
      "title": "Backpropagation through space, time, and the brain",
      "title_zh": "翻译失败",
      "authors": [
        "Benjamin Ellenberger",
        "Paul Haider",
        "Jakob Jordan",
        "Kevin Max",
        "Ismael Jaras",
        "Laura Kriener",
        "Federico Benitez",
        "Mihai A. Petrovici"
      ],
      "abstract": "How physical networks of neurons, bound by spatio-temporal locality\nconstraints, can perform efficient credit assignment, remains, to a large\nextent, an open question. In machine learning, the answer is almost universally\ngiven by the error backpropagation algorithm, through both space and time.\nHowever, this algorithm is well-known to rely on biologically implausible\nassumptions, in particular with respect to spatio-temporal (non-)locality.\nAlternative forward-propagation models such as real-time recurrent learning\nonly partially solve the locality problem, but only at the cost of scaling, due\nto prohibitive storage requirements. We introduce Generalized Latent\nEquilibrium (GLE), a computational framework for fully local spatio-temporal\ncredit assignment in physical, dynamical networks of neurons. We start by\ndefining an energy based on neuron-local mismatches, from which we derive both\nneuronal dynamics via stationarity and parameter dynamics via gradient descent.\nThe resulting dynamics can be interpreted as a real-time, biologically\nplausible approximation of backpropagation through space and time in deep\ncortical networks with continuous-time neuronal dynamics and continuously\nactive, local synaptic plasticity. In particular, GLE exploits the morphology\nof dendritic trees to enable more complex information storage and processing in\nsingle neurons, as well as the ability of biological neurons to phase-shift\ntheir output rate with respect to their membrane potential, which is essential\nin both directions of information propagation. For the forward computation, it\nenables the mapping of time-continuous inputs to neuronal space, effectively\nperforming a spatio-temporal convolution. For the backward computation, it\npermits the temporal inversion of feedback signals, which consequently\napproximate the adjoint variables necessary for useful parameter updates.",
      "tldr_zh": "这篇论文探讨了生物神经网络如何在时空局部约束下实现高效信用分配（credit assignment），并提出 Generalized Latent Equilibrium (GLE) 框架作为 backpropagation 的生物学可行替代，以解决传统算法的非局部性问题。GLE 通过基于神经元局部失配的能量模型，推导出神经元动态（via stationarity）和参数动态（via gradient descent），实现实时、局部的时空信用分配。框架利用树突形态（dendritic trees）和神经元输出相移（phase-shift output rate），在正向计算中进行时空卷积，在反向计算中逆转反馈信号以更新参数，从而为深度皮层网络的连续时间动态和局部突触可塑性提供近似支持。总的来说，GLE 促进了可解释的自主学习，桥接了机器学习与生物神经科学。",
      "categories": [
        "q-bio.NC",
        "cs.AI",
        "cs.LG",
        "cs.NE",
        "eess.SP"
      ],
      "primary_category": "q-bio.NC",
      "comment": "First authorship shared by Benjamin Ellenberger and Paul Haider",
      "pdf_url": "http://arxiv.org/pdf/2403.16933v3",
      "published_date": "2024-03-25 16:57:02 UTC",
      "updated_date": "2025-05-05 14:43:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:37:50.897826"
    },
    {
      "arxiv_id": "2403.16915v3",
      "title": "Coarse-Tuning for Ad-hoc Document Retrieval Using Pre-trained Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Atsushi Keyaki",
        "Ribeka Keyaki"
      ],
      "abstract": "Fine-tuning in information retrieval systems using pre-trained language\nmodels (PLM-based IR) requires learning query representations and\nquery-document relations, in addition to downstream task-specific learning.\nThis study introduces coarse-tuning as an intermediate learning stage that\nbridges pre-training and fine-tuning. By learning query representations and\nquery-document relations in coarse-tuning, we aim to reduce the load of\nfine-tuning and improve the learning effect of downstream IR tasks. We propose\nQuery-Document Pair Prediction (QDPP) for coarse-tuning, which predicts the\nappropriateness of query-document pairs. Evaluation experiments show that the\nproposed method significantly improves MRR and/or nDCG@5 in four ad-hoc\ndocument retrieval datasets. Furthermore, the results of the query prediction\ntask suggested that coarse-tuning facilitated learning of query representation\nand query-document relations.",
      "tldr_zh": "这篇论文提出 coarse-tuning 作为预训练和 fine-tuning 之间的中间阶段，用于提升基于 pre-trained language models (PLMs) 的 ad-hoc 文档检索系统性能。通过学习查询表示和查询-文档关系，coarse-tuning 旨在减轻 fine-tuning 的负担。作者引入了 Query-Document Pair Prediction (QDPP) 方法来预测查询-文档对的适当性，实验在四个数据集上显示显著提高了 MRR 和/或 nDCG@5，并证明了 coarse-tuning 有助于更好地学习查询表示和查询-文档关系。",
      "categories": [
        "cs.IR",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.IR",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16915v3",
      "published_date": "2024-03-25 16:32:50 UTC",
      "updated_date": "2024-03-27 01:53:36 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:38:01.465792"
    },
    {
      "arxiv_id": "2403.16909v1",
      "title": "Towards Algorithmic Fidelity: Mental Health Representation across Demographics in Synthetic vs. Human-generated Data",
      "title_zh": "翻译失败",
      "authors": [
        "Shinka Mori",
        "Oana Ignat",
        "Andrew Lee",
        "Rada Mihalcea"
      ],
      "abstract": "Synthetic data generation has the potential to impact applications and\ndomains with scarce data. However, before such data is used for sensitive tasks\nsuch as mental health, we need an understanding of how different demographics\nare represented in it. In our paper, we analyze the potential of producing\nsynthetic data using GPT-3 by exploring the various stressors it attributes to\ndifferent race and gender combinations, to provide insight for future\nresearchers looking into using LLMs for data generation. Using GPT-3, we\ndevelop HEADROOM, a synthetic dataset of 3,120 posts about\ndepression-triggering stressors, by controlling for race, gender, and time\nframe (before and after COVID-19). Using this dataset, we conduct semantic and\nlexical analyses to (1) identify the predominant stressors for each demographic\ngroup; and (2) compare our synthetic data to a human-generated dataset. We\npresent the procedures to generate queries to develop depression data using\nGPT-3, and conduct analyzes to uncover the types of stressors it assigns to\ndemographic groups, which could be used to test the limitations of LLMs for\nsynthetic data generation for depression data. Our findings show that synthetic\ndata mimics some of the human-generated data distribution for the predominant\ndepression stressors across diverse demographics.",
      "tldr_zh": "该论文探讨了使用 GPT-3 生成合成数据在心理健康领域中的算法忠实度，特别关注不同种族和性别群体的压力源表示，以评估其潜在局限性。研究者开发了 HEADROOM 数据集，该数据集包含 3120 个关于抑郁触发压力的合成帖子，并通过控制种族、性别和时间框架（COVID-19 前后）进行生成。利用语义和词汇分析，他们比较了合成数据与人类生成数据的分布，发现合成数据在主要抑郁压力源上部分模仿了人类数据的模式，为未来使用 LLMs 生成数据提供了重要见解。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.CY"
      ],
      "primary_category": "cs.AI",
      "comment": "14 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16909v1",
      "published_date": "2024-03-25 16:21:25 UTC",
      "updated_date": "2024-03-25 16:21:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:38:13.871823"
    },
    {
      "arxiv_id": "2403.16908v1",
      "title": "Towards Trustworthy Automated Driving through Qualitative Scene Understanding and Explanations",
      "title_zh": "翻译失败",
      "authors": [
        "Nassim Belmecheri",
        "Arnaud Gotlieb",
        "Nadjib Lazaar",
        "Helge Spieker"
      ],
      "abstract": "Understanding driving scenes and communicating automated vehicle decisions\nare key requirements for trustworthy automated driving. In this article, we\nintroduce the Qualitative Explainable Graph (QXG), which is a unified symbolic\nand qualitative representation for scene understanding in urban mobility. The\nQXG enables interpreting an automated vehicle's environment using sensor data\nand machine learning models. It utilizes spatio-temporal graphs and qualitative\nconstraints to extract scene semantics from raw sensor inputs, such as LiDAR\nand camera data, offering an interpretable scene model. A QXG can be\nincrementally constructed in real-time, making it a versatile tool for\nin-vehicle explanations across various sensor types. Our research showcases the\npotential of QXG, particularly in the context of automated driving, where it\ncan rationalize decisions by linking the graph with observed actions. These\nexplanations can serve diverse purposes, from informing passengers and alerting\nvulnerable road users to enabling post-hoc analysis of prior behaviors.",
      "tldr_zh": "本研究提出Qualitative Explainable Graph (QXG)，一种统一的符号和定性表示，用于提升自动驾驶的可信赖性，通过场景理解和解释来辅助车辆决策。QXG利用时空图和定性约束，从LiDAR和相机等传感器数据中提取场景语义，并结合机器学习模型实现实时增量构建的可解释场景模型。实验结果表明，QXG能将观察到的动作与决策关联，提供多用途解释，如通知乘客、警醒易受伤害的道路用户，以及进行事后行为分析，从而促进更安全和可信赖的自动驾驶系统。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "SAE International Journal of Connected and Automated Vehicles",
      "pdf_url": "http://arxiv.org/pdf/2403.16908v1",
      "published_date": "2024-03-25 16:19:33 UTC",
      "updated_date": "2024-03-25 16:19:33 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:38:26.486983"
    },
    {
      "arxiv_id": "2403.16904v1",
      "title": "Multi-Agent Optimization for Safety Analysis of Cyber-Physical Systems: Position Paper",
      "title_zh": "翻译失败",
      "authors": [
        "Önder Gürcan",
        "Nataliya Yakymets",
        "Sara Tucci-Piergiovanni",
        "Ansgar Radermacher"
      ],
      "abstract": "Failure Mode, Effects and Criticality Analysis (FMECA) is one of the safety\nanalysis methods recommended by most of the international standards. The\nclassical FMECA is made in a form of a table filled in either manually or by\nusing safety analysis tools. In both cases, the design engineers have to choose\nthe trade-offs between safety and other development constraints. In the case of\ncomplex cyber-physical systems (CPS) with thousands of specified constraints,\nthis may lead to severe problems and significantly impact the overall\ncriticality of CPS. In this paper, we propose to adopt optimization techniques\nto automate the decision making process conducted after FMECA of CPS. We\ndescribe a multi-agent based optimization method which extends classical FMECA\nfor offering optimal solutions in terms of criticality and development\nconstraints of CPS.",
      "tldr_zh": "这篇论文讨论了在复杂 cyber-physical systems (CPS) 中，使用 Failure Mode, Effects and Criticality Analysis (FMECA) 进行安全分析时，工程师需要在安全与其他开发约束之间权衡决策的问题，这种过程可能导致严重问题。论文提出一种基于多智能体优化(multi-agent based optimization)的方法，来自动化 FMECA 后的决策过程。這種方法扩展了经典 FMECA，通过优化技术提供在 CPS 关键性和开发约束方面的最优解决方案，从而提升整体系统安全性。",
      "categories": [
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 2 figures, 1 table, \"2nd International Workshop on Emerging\n  Ideas and Trends in Engineering of Cyber-Physical Systems, part of\n  Cyber-Physical Systems Week, April 2015, Seattle, USA\"",
      "pdf_url": "http://arxiv.org/pdf/2403.16904v1",
      "published_date": "2024-03-25 16:14:45 UTC",
      "updated_date": "2024-03-25 16:14:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:38:36.808786"
    },
    {
      "arxiv_id": "2403.16903v1",
      "title": "Towards Secure and Trusted-by-Design Smart Contracts",
      "title_zh": "翻译失败",
      "authors": [
        "Zaynah Dargaye",
        "Önder Gürcan",
        "Florent Kirchner",
        "Sara Tucci-Piergiovanni"
      ],
      "abstract": "Distributed immutable ledgers, or blockchains, allow the secure digitization\nof evidential transactions without relying on a trusted third-party. Evidential\ntransactions involve the exchange of any form of physical evidence, such as\nmoney, birth certificate, visas, tickets, etc. Most of the time, evidential\ntransactions occur in the context of complex procedures, called evidential\nprotocols, among physical agents. The blockchain provides the mechanisms to\ntransfer evidence, while smart contracts - programs executing within the\nblockchain in a decentralized and replicated fashion - allow encoding\nevidential protocols on top of a blockchain.\n  As a smart contract foregoes trusted third-parties and runs on several\nmachines anonymously, it constitutes a highly critical program that has to be\nsecure and trusted-by-design. While most of the current smart contract\nlanguages focus on easy programmability, they do not directly address the need\nof guaranteeing trust and accountability, which becomes a significant issue\nwhen evidential protocols are encoded as smart contracts.",
      "tldr_zh": "该论文探讨了区块链技术如何实现证据交易的安全数字化，而智能合约作为其核心组件，需要从设计上确保安全和可信任。当前智能合约语言虽注重易编程，但忽略了去中心化环境下的信任和责任机制，导致潜在风险。论文强调，应将信任和问责性融入智能合约的设计中，以更好地支持证据协议的执行，为构建可靠的区块链应用奠定基础。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.CR",
      "comment": "17 pages, 1 algorithm, The 29th Francophone Days of Application\n  Languages - JFLA 2018",
      "pdf_url": "http://arxiv.org/pdf/2403.16903v1",
      "published_date": "2024-03-25 16:14:22 UTC",
      "updated_date": "2024-03-25 16:14:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:38:50.263797"
    },
    {
      "arxiv_id": "2403.16895v1",
      "title": "\"It is there, and you need it, so why do you not use it?\" Achieving better adoption of AI systems by domain experts, in the case study of natural science research",
      "title_zh": "翻译失败",
      "authors": [
        "Auste Simkute",
        "Ewa Luger",
        "Michael Evans",
        "Rhianne Jones"
      ],
      "abstract": "Artificial Intelligence (AI) is becoming ubiquitous in domains such as\nmedicine and natural science research. However, when AI systems are implemented\nin practice, domain experts often refuse them. Low acceptance hinders effective\nhuman-AI collaboration, even when it is essential for progress. In natural\nscience research, scientists' ineffective use of AI-enabled systems can impede\nthem from analysing their data and advancing their research. We conducted an\nethnographically informed study of 10 in-depth interviews with AI practitioners\nand natural scientists at the organisation facing low adoption of algorithmic\nsystems. Results were consolidated into recommendations for better AI adoption:\ni) actively supporting experts during the initial stages of system use, ii)\ncommunicating the capabilities of a system in a user-relevant way, and iii)\nfollowing predefined collaboration rules. We discuss the broader implications\nof our findings and expand on how our proposed requirements could support\npractitioners and experts across domains.",
      "tldr_zh": "该研究探讨了AI系统在自然科学研究等领域的低采用率问题，指出领域专家（domain experts）的拒绝阻碍了人类-AI协作，并通过对10名AI从业者和科学家的民族志式深度访谈（ethnographically informed study）分析了原因。研究提出三点改进建议：i) 在系统使用初期积极支持专家，ii) 以用户相关方式沟通系统能力，iii) 遵循预定义的协作规则。这些发现不仅有助于提升自然科学研究的AI采用，还可扩展到其他领域，促进更有效的AI应用。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16895v1",
      "published_date": "2024-03-25 16:06:31 UTC",
      "updated_date": "2024-03-25 16:06:31 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:39:02.587864"
    },
    {
      "arxiv_id": "2403.16877v2",
      "title": "Proprioception Is All You Need: Terrain Classification for Boreal Forests",
      "title_zh": "翻译失败",
      "authors": [
        "Damien LaRocque",
        "William Guimont-Martin",
        "David-Alexandre Duclos",
        "Philippe Giguère",
        "François Pomerleau"
      ],
      "abstract": "Recent works in field robotics highlighted the importance of resiliency\nagainst different types of terrains. Boreal forests, in particular, are home to\nmany mobility-impeding terrains that should be considered for off-road\nautonomous navigation. Also, being one of the largest land biomes on Earth,\nboreal forests are an area where autonomous vehicles are expected to become\nincreasingly common. In this paper, we address this issue by introducing\nBorealTC, a publicly available dataset for proprioceptive-based terrain\nclassification (TC). Recorded with a Husky A200, our dataset contains 116 min\nof Inertial Measurement Unit (IMU), motor current, and wheel odometry data,\nfocusing on typical boreal forest terrains, notably snow, ice, and silty loam.\nCombining our dataset with another dataset from the state-of-the-art, we\nevaluate both a Convolutional Neural Network (CNN) and the novel state space\nmodel (SSM)-based Mamba architecture on a TC task. Interestingly, we show that\nwhile CNN outperforms Mamba on each separate dataset, Mamba achieves greater\naccuracy when trained on a combination of both. In addition, we demonstrate\nthat Mamba's learning capacity is greater than a CNN for increasing amounts of\ndata. We show that the combination of two TC datasets yields a latent space\nthat can be interpreted with the properties of the terrains. We also discuss\nthe implications of merging datasets on classification. Our source code and\ndataset are publicly available online:\nhttps://github.com/norlab-ulaval/BorealTC.",
      "tldr_zh": "本研究聚焦于北极森林地形的自主导航挑战，引入了公开数据集BorealTC，用于基于本体感觉(Proprioception)的地形分类(TC)。数据集由Husky A200机器人收集，包括116分钟的Inertial Measurement Unit (IMU)、电机电流和轮子里程数据，涵盖雪、冰和粉砂壤土等典型地形。研究比较了Convolutional Neural Network (CNN)和状态空间模型(SSM)-based Mamba架构在TC任务上的性能，发现Mamba在结合多个数据集时准确率更高，且其学习能力在数据量增加时优于CNN。最终，研究展示了合并数据集能生成可解释的地形潜在空间，并公开了源代码和数据集以促进进一步研究。",
      "categories": [
        "cs.RO",
        "cs.AI",
        "cs.LG",
        "eess.SP"
      ],
      "primary_category": "cs.RO",
      "comment": "Accepted to the 2024 IEEE/RSJ International Conference on Intelligent\n  Robots and Systems (IROS 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.16877v2",
      "published_date": "2024-03-25 15:42:09 UTC",
      "updated_date": "2024-09-27 17:14:26 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:39:15.116738"
    },
    {
      "arxiv_id": "2404.03673v2",
      "title": "RL for Consistency Models: Faster Reward Guided Text-to-Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Owen Oertell",
        "Jonathan D. Chang",
        "Yiyi Zhang",
        "Kianté Brantley",
        "Wen Sun"
      ],
      "abstract": "Reinforcement learning (RL) has improved guided image generation with\ndiffusion models by directly optimizing rewards that capture image quality,\naesthetics, and instruction following capabilities. However, the resulting\ngenerative policies inherit the same iterative sampling process of diffusion\nmodels that causes slow generation. To overcome this limitation, consistency\nmodels proposed learning a new class of generative models that directly map\nnoise to data, resulting in a model that can generate an image in as few as one\nsampling iteration. In this work, to optimize text-to-image generative models\nfor task specific rewards and enable fast training and inference, we propose a\nframework for fine-tuning consistency models via RL. Our framework, called\nReinforcement Learning for Consistency Model (RLCM), frames the iterative\ninference process of a consistency model as an RL procedure. Comparing to RL\nfinetuned diffusion models, RLCM trains significantly faster, improves the\nquality of the generation measured under the reward objectives, and speeds up\nthe inference procedure by generating high quality images with as few as two\ninference steps. Experimentally, we show that RLCM can adapt text-to-image\nconsistency models to objectives that are challenging to express with\nprompting, such as image compressibility, and those derived from human\nfeedback, such as aesthetic quality. Our code is available at\nhttps://rlcm.owenoertell.com.",
      "tldr_zh": "本研究提出 RLCM（Reinforcement Learning for Consistency Model）框架，通过强化学习（RL）微调一致性模型，以优化文本到图像生成过程，实现更快训练和推理。相比于 RL 微调的扩散模型（Diffusion Models），RLCM 显著缩短训练时间，提高生成质量（如基于奖励目标的图像美学和指令遵循），并仅需两步推理即可产出高质量图像。实验验证了 RLCM 在处理提示难以表达的目标（如图像可压缩性和人类反馈的美学质量）方面的有效性，为高效的奖励引导生成提供了新途径。",
      "categories": [
        "cs.CV",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CV",
      "comment": "18 pages, 9 figures, 1 table",
      "pdf_url": "http://arxiv.org/pdf/2404.03673v2",
      "published_date": "2024-03-25 15:40:22 UTC",
      "updated_date": "2024-06-22 08:07:39 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:39:26.402636"
    },
    {
      "arxiv_id": "2403.16863v1",
      "title": "SIP: Autotuning GPU Native Schedules via Stochastic Instruction Perturbation",
      "title_zh": "翻译失败",
      "authors": [
        "Guoliang He",
        "Eiko Yoneki"
      ],
      "abstract": "Large language models (LLMs) have become a significant workload since their\nappearance. However, they are also computationally expensive as they have\nbillions of parameters and are trained with massive amounts of data. Thus,\nrecent works have developed dedicated CUDA kernels for LLM training and\ninference instead of relying on compilergenerated ones, so that hardware\nresources are as fully utilized as possible. In this work, we explore the\npossibility of GPU native instruction optimization to further push the CUDA\nkernels to extreme performance. Contrary to prior works, we adopt an automatic\noptimization approach by defining a search space of possible GPU native\ninstruction schedules, and then we apply stochastic search to perform\noptimization. Experiments show that SIP can further improve CUDA kernel\nthroughput by automatically discovering better GPU native instruction schedules\nand the optimized schedules are tested by 10 million test samples.",
      "tldr_zh": "该论文针对大型语言模型(LLMs)的计算密集型特性，提出SIP方法，通过随机指令扰动(Stochastic Instruction Perturbation)自动优化GPU原生指令调度，以提升CUDA内核性能。SIP定义了一个可能的指令调度搜索空间，并采用随机搜索算法进行自动优化，旨在更充分地利用硬件资源。实验结果显示，该方法能显著提高CUDA内核的吞吐量，并在1,000万测试样本上验证了优化的有效性。",
      "categories": [
        "cs.AR",
        "cs.AI"
      ],
      "primary_category": "cs.AR",
      "comment": "EuroMLSys 24, April 22, 2024, Athens, Greece",
      "pdf_url": "http://arxiv.org/pdf/2403.16863v1",
      "published_date": "2024-03-25 15:26:50 UTC",
      "updated_date": "2024-03-25 15:26:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:39:35.763979"
    },
    {
      "arxiv_id": "2404.07969v1",
      "title": "An End-to-End Structure with Novel Position Mechanism and Improved EMD for Stock Forecasting",
      "title_zh": "翻译失败",
      "authors": [
        "Chufeng Li",
        "Jianyong Chen"
      ],
      "abstract": "As a branch of time series forecasting, stock movement forecasting is one of\nthe challenging problems for investors and researchers. Since Transformer was\nintroduced to analyze financial data, many researchers have dedicated\nthemselves to forecasting stock movement using Transformer or attention\nmechanisms. However, existing research mostly focuses on individual stock\ninformation but ignores stock market information and high noise in stock data.\nIn this paper, we propose a novel method using the attention mechanism in which\nboth stock market information and individual stock information are considered.\nMeanwhile, we propose a novel EMD-based algorithm for reducing short-term noise\nin stock data. Two randomly selected exchange-traded funds (ETFs) spanning over\nten years from US stock markets are used to demonstrate the superior\nperformance of the proposed attention-based method. The experimental analysis\ndemonstrates that the proposed attention-based method significantly outperforms\nother state-of-the-art baselines. Code is available at\nhttps://github.com/DurandalLee/ACEFormer.",
      "tldr_zh": "本文提出了一种新型端到端结构，用于股票预测，结合了新型位置机制和改进的EMD算法，以注意力机制同时整合股票市场信息和个股信息，同时通过改进的EMD算法减少股票数据中的短期噪声。该方法解决了现有研究忽略市场信息和高噪声问题的不足，在使用两个美国股票市场ETF超过十年的数据进行实验时，显著优于其他最先进基线模型。代码已在GitHub上提供，供进一步验证和应用。",
      "categories": [
        "q-fin.ST",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "q-fin.ST",
      "comment": "ICONIP 2023",
      "pdf_url": "http://arxiv.org/pdf/2404.07969v1",
      "published_date": "2024-03-25 15:23:22 UTC",
      "updated_date": "2024-03-25 15:23:22 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:39:50.766962"
    },
    {
      "arxiv_id": "2403.16858v1",
      "title": "XAIport: A Service Framework for the Early Adoption of XAI in AI Model Development",
      "title_zh": "XAIport：一个用于 AI",
      "authors": [
        "Zerui Wang",
        "Yan Liu",
        "Abishek Arumugam Thiruselvi",
        "Abdelwahab Hamou-Lhadj"
      ],
      "abstract": "In this study, we propose the early adoption of Explainable AI (XAI) with a\nfocus on three properties: Quality of explanation, the explanation summaries\nshould be consistent across multiple XAI methods; Architectural Compatibility,\nfor effective integration in XAI, the architecture styles of both the XAI\nmethods and the models to be explained must be compatible with the framework;\nConfigurable operations, XAI explanations are operable, akin to machine\nlearning operations. Thus, an explanation for AI models should be reproducible\nand tractable to be trustworthy. We present XAIport, a framework of XAI\nmicroservices encapsulated into Open APIs to deliver early explanations as\nobservation for learning model quality assurance. XAIport enables configurable\nXAI operations along with machine learning development. We quantify the\noperational costs of incorporating XAI with three cloud computer vision\nservices on Microsoft Azure Cognitive Services, Google Cloud Vertex AI, and\nAmazon Rekognition. Our findings show comparable operational costs between XAI\nand traditional machine learning, with XAIport significantly improving both\ncloud AI model performance and explanation stability.",
      "tldr_zh": "本研究提出XAIport框架，以促进Explainable AI (XAI)在AI模型开发中的早期采用，聚焦于解释质量的一致性、架构兼容性和可配置操作三大属性。XAIport通过封装XAI微服务成Open APIs，提供可重现且可追踪的解释服务，帮助确保模型质量并与机器学习开发无缝整合。实验评估显示，在Microsoft Azure Cognitive Services、Google Cloud Vertex AI和Amazon Rekognition上，XAIport的操作成本与传统机器学习相当，同时显著提升了AI模型性能和解释稳定性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at the ICSE'24 conference, NIER track",
      "pdf_url": "http://arxiv.org/pdf/2403.16858v1",
      "published_date": "2024-03-25 15:22:06 UTC",
      "updated_date": "2024-03-25 15:22:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:40:00.930693"
    },
    {
      "arxiv_id": "2403.16854v3",
      "title": "An Expert is Worth One Token: Synergizing Multiple Expert LLMs as Generalist via Expert Token Routing",
      "title_zh": "翻译失败",
      "authors": [
        "Ziwei Chai",
        "Guoyin Wang",
        "Jing Su",
        "Tianjie Zhang",
        "Xuanwen Huang",
        "Xuwu Wang",
        "Jingjing Xu",
        "Jianbo Yuan",
        "Hongxia Yang",
        "Fei Wu",
        "Yang Yang"
      ],
      "abstract": "We present Expert-Token-Routing, a unified generalist framework that\nfacilitates seamless integration of multiple expert LLMs. Our framework\nrepresents expert LLMs as special expert tokens within the vocabulary of a meta\nLLM. The meta LLM can route to an expert LLM like generating new tokens.\nExpert-Token-Routing not only supports learning the implicit expertise of\nexpert LLMs from existing instruction dataset but also allows for dynamic\nextension of new expert LLMs in a plug-and-play manner. It also conceals the\ndetailed collaboration process from the user's perspective, facilitating\ninteraction as though it were a singular LLM. Our framework outperforms various\nexisting multi-LLM collaboration paradigms across benchmarks that incorporate\nsix diverse expert domains, demonstrating effectiveness and robustness in\nbuilding generalist LLM system via synergizing multiple expert LLMs.",
      "tldr_zh": "本研究提出了一种名为 Expert-Token-Routing 的统一框架，用于无缝整合多个专家大型语言模型 (LLMs)，以构建一个通用的通用型 LLM 系统。该框架将专家 LLMs 表示为 meta LLM 词汇表中的特殊专家 tokens，允许 meta LLM 通过路由机制像生成新 tokens 一样调用专家 LLMs，从而支持从现有指令数据集学习隐性专长，并实现插件式动态扩展新专家。框架从用户视角隐藏协作细节，使交互如同单一 LLM；实验结果显示，在涵盖六个多样专家领域的基准测试中，该框架优于现有多-LLM 协作范式，证明了其在构建鲁棒通用型系统的有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16854v3",
      "published_date": "2024-03-25 15:17:05 UTC",
      "updated_date": "2024-06-11 15:12:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:40:14.511099"
    },
    {
      "arxiv_id": "2403.16852v2",
      "title": "Towards Explainability in Legal Outcome Prediction Models",
      "title_zh": "翻译失败",
      "authors": [
        "Josef Valvoda",
        "Ryan Cotterell"
      ],
      "abstract": "Current legal outcome prediction models - a staple of legal NLP - do not\nexplain their reasoning. However, to employ these models in the real world,\nhuman legal actors need to be able to understand the model's decisions. In the\ncase of common law, legal practitioners reason towards the outcome of a case by\nreferring to past case law, known as precedent. We contend that precedent is,\ntherefore, a natural way of facilitating explainability for legal NLP models.\nIn this paper, we contribute a novel method for identifying the precedent\nemployed by legal outcome prediction models. Furthermore, by developing a\ntaxonomy of legal precedent, we are able to compare human judges and neural\nmodels with respect to the different types of precedent they rely on. We find\nthat while the models learn to predict outcomes reasonably well, their use of\nprecedent is unlike that of human judges.",
      "tldr_zh": "这篇论文针对法律结果预测模型（legal outcome prediction models）的解释性不足问题，提出通过识别模型所引用的判例（precedent）来提升其可解释性。研究贡献包括一种新方法，用于检测模型在决策过程中使用的precedent，并开发了一个precedent的分类系统（taxonomy），以比较人类法官和神经模型的依赖模式。结果显示，虽然模型能合理预测法律结果，但其对precedent的运用方式与人类法官存在显著差异。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16852v2",
      "published_date": "2024-03-25 15:15:41 UTC",
      "updated_date": "2024-04-16 03:53:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:40:25.344950"
    },
    {
      "arxiv_id": "2403.16851v2",
      "title": "Can tweets predict article retractions? A comparison between human and LLM labelling",
      "title_zh": "推文能预测文章撤稿吗？ 人类与 LLM 标记的比较",
      "authors": [
        "Er-Te Zheng",
        "Hui-Zhen Fu",
        "Mike Thelwall",
        "Zhichao Fang"
      ],
      "abstract": "Quickly detecting problematic research articles is crucial to safeguarding\nthe integrity of scientific research. This study explores whether Twitter\nmentions of retracted articles can signal potential problems with the articles\nprior to their retraction, potentially serving as an early warning system for\nscholars. To investigate this, we analysed a dataset of 4,354 Twitter mentions\nassociated with 504 retracted articles. The effectiveness of Twitter mentions\nin predicting article retractions was evaluated by both manual and Large\nLanguage Model (LLM) labelling. Manual labelling results indicated that 25.7%\nof tweets signalled problems before retraction. Using the manual labelling\nresults as the baseline, we found that LLMs (GPT-4o-mini, Gemini 1.5 Flash, and\nClaude-3.5-Haiku) outperformed lexicon-based sentiment analysis tools (e.g.,\nTextBlob) in detecting potential problems, suggesting that automatic detection\nof problematic articles from social media using LLMs is technically feasible.\nNevertheless, since only a small proportion of retracted articles (11.1%) were\ncriticised on Twitter prior to retraction, such automatic systems would detect\nonly a minority of problematic articles. Overall, this study offers insights\ninto how social media data, coupled with emerging generative AI techniques, can\nsupport research integrity.",
      "tldr_zh": "本研究探讨Twitter提及是否能作为早期预警系统，预测文章撤回以维护科研完整性。通过分析4,354条Twitter提及和504篇撤回文章，采用人工标记和LLM（如GPT-4o-mini、Gemini 1.5 Flash、Claude-3.5-Haiku）进行比较评估，结果显示人工标记发现25.7%的推文在撤回前信号化问题。LLM在检测潜在问题上优于基于词汇的情感分析工具（如TextBlob），证明自动检测技术可行。然而，仅有11.1%的撤回文章在Twitter上提前受批评，因此此类系统只能识别少数问题。总体而言，该研究揭示社交媒体数据结合生成AI（如LLM）可增强研究诚信监控。",
      "categories": [
        "cs.DL",
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.DL",
      "comment": "19 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.16851v2",
      "published_date": "2024-03-25 15:15:09 UTC",
      "updated_date": "2024-12-09 16:42:25 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:40:39.849566"
    },
    {
      "arxiv_id": "2403.16846v1",
      "title": "GreeDy and CoDy: Counterfactual Explainers for Dynamic Graphs",
      "title_zh": "翻译失败",
      "authors": [
        "Zhan Qu",
        "Daniel Gomm",
        "Michael Färber"
      ],
      "abstract": "Temporal Graph Neural Networks (TGNNs), crucial for modeling dynamic graphs\nwith time-varying interactions, face a significant challenge in explainability\ndue to their complex model structure. Counterfactual explanations, crucial for\nunderstanding model decisions, examine how input graph changes affect outcomes.\nThis paper introduces two novel counterfactual explanation methods for TGNNs:\nGreeDy (Greedy Explainer for Dynamic Graphs) and CoDy (Counterfactual Explainer\nfor Dynamic Graphs). They treat explanations as a search problem, seeking input\ngraph alterations that alter model predictions. GreeDy uses a simple, greedy\napproach, while CoDy employs a sophisticated Monte Carlo Tree Search algorithm.\nExperiments show both methods effectively generate clear explanations. Notably,\nCoDy outperforms GreeDy and existing factual methods, with up to 59\\% higher\nsuccess rate in finding significant counterfactual inputs. This highlights\nCoDy's potential in clarifying TGNN decision-making, increasing their\ntransparency and trustworthiness in practice.",
      "tldr_zh": "这篇论文针对 Temporal Graph Neural Networks (TGNNs) 在动态图建模中的解释性挑战，提出了两种新颖的反事实解释方法：GreeDy 和 CoDy。GreeDy 采用贪婪算法，而 CoDy 则使用 Monte Carlo Tree Search 算法，将解释过程视为搜索问题，通过修改输入图来改变模型预测。实验结果显示，CoDy 比 GreeDy 和现有事实方法成功率高出最多 59%，从而显著提升了 TGNNs 的透明度和可信度。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16846v1",
      "published_date": "2024-03-25 15:07:50 UTC",
      "updated_date": "2024-03-25 15:07:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:40:51.971806"
    },
    {
      "arxiv_id": "2403.16843v4",
      "title": "Do LLM Agents Have Regret? A Case Study in Online Learning and Games",
      "title_zh": "翻译失败",
      "authors": [
        "Chanwoo Park",
        "Xiangyu Liu",
        "Asuman Ozdaglar",
        "Kaiqing Zhang"
      ],
      "abstract": "Large language models (LLMs) have been increasingly employed for\n(interactive) decision-making, via the development of LLM-based autonomous\nagents. Despite their emerging successes, the performance of LLM agents in\ndecision-making has not been fully investigated through quantitative metrics,\nespecially in the multi-agent setting when they interact with each other, a\ntypical scenario in real-world LLM-agent applications. To better understand the\nlimits of LLM agents in these interactive environments, we propose to study\ntheir interactions in benchmark decision-making settings in online learning and\ngame theory, through the performance metric of \\emph{regret}. We first\nempirically study the {no-regret} behaviors of LLMs in canonical\n(non-stationary) online learning problems, as well as the emergence of\nequilibria when LLM agents interact through playing repeated games. We then\nprovide some theoretical insights into the no-regret behaviors of LLM agents,\nunder certain assumptions on the supervised pre-training and the rationality\nmodel of human decision-makers who generate the data. Notably, we also identify\n(simple) cases where advanced LLMs such as GPT-4 fail to be no-regret. To\npromote the no-regret behaviors, we propose a novel \\emph{unsupervised}\ntraining loss of \\emph{regret-loss}, which, in contrast to the supervised\npre-training loss, does not require the labels of (optimal) actions. We then\nestablish the statistical guarantee of generalization bound for regret-loss\nminimization, followed by the optimization guarantee that minimizing such a\nloss may automatically lead to known no-regret learning algorithms. Our further\nexperiments demonstrate the effectiveness of our regret-loss, especially in\naddressing the above ``regrettable'' cases.",
      "tldr_zh": "这篇论文探讨了大型语言模型（LLM）代理在在线学习和游戏中的决策表现，特别使用regret作为量化指标来评估其在多代理互动环境下的表现。研究通过实验验证了LLM代理在非平稳在线学习问题中的无后悔行为，以及在重复游戏中均衡的出现，并提供了理论分析，假设基于监督预训练和人类决策者的理性模型。作者发现高级LLM如GPT-4在某些简单场景下未能实现无后悔行为，并提出了一种新型无监督训练损失regret-loss，以改善代理的表现；实验结果显示，该方法有效降低了regret并提供了统计和优化保证。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.GT"
      ],
      "primary_category": "cs.LG",
      "comment": "Camera ready version of ICLR 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.16843v4",
      "published_date": "2024-03-25 15:04:11 UTC",
      "updated_date": "2025-04-02 23:51:07 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:41:02.409629"
    },
    {
      "arxiv_id": "2403.16831v3",
      "title": "UrbanVLP: Multi-Granularity Vision-Language Pretraining for Urban Socioeconomic Indicator Prediction",
      "title_zh": "UrbanVLP：多粒度视觉-语言预训练用于城市社会经济指标预测",
      "authors": [
        "Xixuan Hao",
        "Wei Chen",
        "Yibo Yan",
        "Siru Zhong",
        "Kun Wang",
        "Qingsong Wen",
        "Yuxuan Liang"
      ],
      "abstract": "Urban socioeconomic indicator prediction aims to infer various metrics\nrelated to sustainable development in diverse urban landscapes using\ndata-driven methods. However, prevalent pretrained models, particularly those\nreliant on satellite imagery, face dual challenges. Firstly, concentrating\nsolely on macro-level patterns from satellite data may introduce bias, lacking\nnuanced details at micro levels, such as architectural details at a place.\nSecondly, the text generated by the precursor work UrbanCLIP, which fully\nutilizes the extensive knowledge of LLMs, frequently exhibits issues such as\nhallucination and homogenization, resulting in a lack of reliable quality. In\nresponse to these issues, we devise a novel framework entitled UrbanVLP based\non Vision-Language Pretraining. Our UrbanVLP seamlessly integrates\nmulti-granularity information from both macro (satellite) and micro\n(street-view) levels, overcoming the limitations of prior pretrained models.\nMoreover, it introduces automatic text generation and calibration, providing a\nrobust guarantee for producing high-quality text descriptions of urban imagery.\nRigorous experiments conducted across six socioeconomic indicator prediction\ntasks underscore its superior performance.",
      "tldr_zh": "该论文提出UrbanVLP框架，通过多粒度Vision-Language Pretraining整合宏观卫星图像和微观街景信息，解决现有模型在城市社会经济指标预测中存在的偏见和文本生成问题，如幻觉和同质化。UrbanVLP引入自动文本生成及校准机制，确保高质量的城市图像描述。实验在六个社会经济指标预测任务上验证了其优越性能，超越了先前的预训练模型。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted as a full paper by AAAI'25 - AI for Social Impact Track",
      "pdf_url": "http://arxiv.org/pdf/2403.16831v3",
      "published_date": "2024-03-25 14:57:18 UTC",
      "updated_date": "2025-01-22 08:45:56 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:41:13.135228"
    },
    {
      "arxiv_id": "2403.16829v3",
      "title": "Convergence of a model-free entropy-regularized inverse reinforcement learning algorithm",
      "title_zh": "翻译失败",
      "authors": [
        "Titouan Renard",
        "Andreas Schlaginhaufen",
        "Tingting Ni",
        "Maryam Kamgarpour"
      ],
      "abstract": "Given a dataset of expert demonstrations, inverse reinforcement learning\n(IRL) aims to recover a reward for which the expert is optimal. This work\nproposes a model-free algorithm to solve entropy-regularized IRL problem. In\nparticular, we employ a stochastic gradient descent update for the reward and a\nstochastic soft policy iteration update for the policy. Assuming access to a\ngenerative model, we prove that our algorithm is guaranteed to recover a reward\nfor which the expert is $\\varepsilon$-optimal using\n$\\mathcal{O}(1/\\varepsilon^{2})$ samples of the Markov decision process (MDP).\nFurthermore, with $\\mathcal{O}(1/\\varepsilon^{4})$ samples we prove that the\noptimal policy corresponding to the recovered reward is $\\varepsilon$-close to\nthe expert policy in total variation distance.",
      "tldr_zh": "该论文研究了无模型（model-free）的熵正则化逆强化学习（IRL）算法的收敛性，旨在从专家演示数据集恢复一个奖励函数，使专家策略成为最优的。算法采用随机梯度下降（SGD）更新奖励函数，并结合随机软策略迭代（stochastic soft policy iteration）更新策略，假设有生成模型（generative model）的访问。结果证明，该算法只需 O(1/ε²) 的马尔可夫决策过程（MDP）样本即可恢复一个奖励函数，使专家策略 ε-最优；进一步使用 O(1/ε⁴) 样本时，恢复奖励对应的最优策略在总变差距离（total variation distance）上与专家策略 ε-接近。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16829v3",
      "published_date": "2024-03-25 14:54:42 UTC",
      "updated_date": "2025-03-03 18:01:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:41:27.899898"
    },
    {
      "arxiv_id": "2403.16824v1",
      "title": "On Policy Reuse: An Expressive Language for Representing and Executing General Policies that Call Other Policies",
      "title_zh": "翻译失败",
      "authors": [
        "Blai Bonet",
        "Dominik Drexler",
        "Hector Geffner"
      ],
      "abstract": "Recently, a simple but powerful language for expressing and learning general\npolicies and problem decompositions (sketches) has been introduced in terms of\nrules defined over a set of Boolean and numerical features. In this work, we\nconsider three extensions of this language aimed at making policies and\nsketches more flexible and reusable: internal memory states, as in finite state\ncontrollers; indexical features, whose values are a function of the state and a\nnumber of internal registers that can be loaded with objects; and modules that\nwrap up policies and sketches and allow them to call each other by passing\nparameters. In addition, unlike general policies that select state transitions\nrather than ground actions, the new language allows for the selection of such\nactions. The expressive power of the resulting language for policies and\nsketches is illustrated through a number of examples.",
      "tldr_zh": "该论文扩展了一种基于布尔和数值特征的规则语言，用于表达和学习一般策略(policies)和问题分解(sketch)，使其更灵活和可重用。扩展包括引入内部内存状态（类似于有限状态控制器）、indexical features（其值依赖于状态和内部寄存器）和modules（允许策略和sketch相互调用并传递参数）。此外，新语言支持直接选择ground actions，而非仅限于状态转换，通过多个例子展示了其增强的表达能力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "ICAPS 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16824v1",
      "published_date": "2024-03-25 14:48:54 UTC",
      "updated_date": "2024-03-25 14:48:54 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:41:37.175300"
    },
    {
      "arxiv_id": "2403.16812v2",
      "title": "Towards Human-AI Deliberation: Design and Evaluation of LLM-Empowered Deliberative AI for AI-Assisted Decision-Making",
      "title_zh": "翻译失败",
      "authors": [
        "Shuai Ma",
        "Qiaoyi Chen",
        "Xinru Wang",
        "Chengbo Zheng",
        "Zhenhui Peng",
        "Ming Yin",
        "Xiaojuan Ma"
      ],
      "abstract": "In AI-assisted decision-making, humans often passively review AI's suggestion\nand decide whether to accept or reject it as a whole. In such a paradigm,\nhumans are found to rarely trigger analytical thinking and face difficulties in\ncommunicating the nuances of conflicting opinions to the AI when disagreements\noccur. To tackle this challenge, we propose Human-AI Deliberation, a novel\nframework to promote human reflection and discussion on conflicting human-AI\nopinions in decision-making. Based on theories in human deliberation, this\nframework engages humans and AI in dimension-level opinion elicitation,\ndeliberative discussion, and decision updates. To empower AI with deliberative\ncapabilities, we designed Deliberative AI, which leverages large language\nmodels (LLMs) as a bridge between humans and domain-specific models to enable\nflexible conversational interactions and faithful information provision. An\nexploratory evaluation on a graduate admissions task shows that Deliberative AI\noutperforms conventional explainable AI (XAI) assistants in improving humans'\nappropriate reliance and task performance. Based on a mixed-methods analysis of\nparticipant behavior, perception, user experience, and open-ended feedback, we\ndraw implications for future AI-assisted decision tool design.",
      "tldr_zh": "该研究针对传统 AI 辅助决策中人类被动审查和处理分歧的挑战，提出 Human-AI Deliberation 框架，以促进人类对冲突意见的反思和讨论。\n该框架基于人类审议理论，使用 LLMs 赋能的 Deliberative AI 系统，实现维度级别的意见提取、审议讨论和决策更新，从而增强 AI 与人类的互动。\n在研究生招生任务的探索性评估中，Deliberative AI 优于传统 XAI 助手，提高了人类的适当依赖和任务表现。\n通过混合方法分析参与者行为、感知和反馈，该研究为未来 AI 辅助决策工具的设计提供了关键启示。",
      "categories": [
        "cs.HC",
        "cs.AI"
      ],
      "primary_category": "cs.HC",
      "comment": "23 pages, ACM CHI 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.16812v2",
      "published_date": "2024-03-25 14:34:06 UTC",
      "updated_date": "2025-03-11 19:23:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:41:54.279440"
    },
    {
      "arxiv_id": "2403.16809v1",
      "title": "An LLM-Based Digital Twin for Optimizing Human-in-the Loop Systems",
      "title_zh": "翻译失败",
      "authors": [
        "Hanqing Yang",
        "Marie Siew",
        "Carlee Joe-Wong"
      ],
      "abstract": "The increasing prevalence of Cyber-Physical Systems and the Internet of\nThings (CPS-IoT) applications and Foundation Models are enabling new\napplications that leverage real-time control of the environment. For example,\nreal-time control of Heating, Ventilation and Air-Conditioning (HVAC) systems\ncan reduce its usage when not needed for the comfort of human occupants, hence\nreducing energy consumption. Collecting real-time feedback on human preferences\nin such human-in-the-loop (HITL) systems, however, is difficult in practice. We\npropose the use of large language models (LLMs) to deal with the challenges of\ndynamic environments and difficult-to-obtain data in CPS optimization. In this\npaper, we present a case study that employs LLM agents to mimic the behaviors\nand thermal preferences of various population groups (e.g. young families, the\nelderly) in a shopping mall. The aggregated thermal preferences are integrated\ninto an agent-in-the-loop based reinforcement learning algorithm AitL-RL, which\nemploys the LLM as a dynamic simulation of the physical environment to learn\nhow to balance between energy savings and occupant comfort. Our results show\nthat LLMs are capable of simulating complex population movements within large\nopen spaces. Besides, AitL-RL demonstrates superior performance compared to the\npopular existing policy of set point control, suggesting that adaptive and\npersonalized decision-making is critical for efficient optimization in CPS-IoT\napplications. Through this case study, we demonstrate the potential of\nintegrating advanced Foundation Models like LLMs into CPS-IoT to enhance system\nadaptability and efficiency. The project's code can be found on our GitHub\nrepository.",
      "tldr_zh": "这篇论文提出了一种基于大型语言模型 (LLMs) 的数字孪生系统，用于优化人机循环 (Human-in-the-Loop) 系统，如 Heating, Ventilation and Air-Conditioning (HVAC) 系统，以平衡能源节约和人类舒适度。研究通过案例研究，使用 LLM 代理模拟不同人群（如年轻家庭和老年群体）的行为和热偏好，并将其整合到 AitL-RL 强化学习算法中，作为动态环境模拟。结果表明，LLMs 能有效模拟复杂人群运动，且 AitL-RL 比传统 set point control 策略性能更优，在 CPS-IoT 应用中实现了更高的适应性和效率。总的来说，这展示了 LLMs 在提升 CPS-IoT 系统优化潜力方面的价值。",
      "categories": [
        "eess.SY",
        "cs.AI",
        "cs.LG",
        "cs.SY"
      ],
      "primary_category": "eess.SY",
      "comment": "Accepted at International Workshop on Foundation Models for\n  Cyber-Physical Systems & Internet of Things (FMSys) 2024, Co-located at\n  CPS-IoT Week 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16809v1",
      "published_date": "2024-03-25 14:32:28 UTC",
      "updated_date": "2024-03-25 14:32:28 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:42:06.404529"
    },
    {
      "arxiv_id": "2403.16808v2",
      "title": "Navigating the EU AI Act: A Methodological Approach to Compliance for Safety-critical Products",
      "title_zh": "欧盟 AI 法案的导航：一种针对安全关键产品的合规方法论方法",
      "authors": [
        "J. Kelly",
        "S. Zafar",
        "L. Heidemann",
        "J. Zacchi",
        "D. Espinoza",
        "N. Mata"
      ],
      "abstract": "In December 2023, the European Parliament provisionally agreed on the EU AI\nAct. This unprecedented regulatory framework for AI systems lays out guidelines\nto ensure the safety, legality, and trustworthiness of AI products. This paper\npresents a methodology for interpreting the EU AI Act requirements for\nhigh-risk AI systems by leveraging product quality models. We first propose an\nextended product quality model for AI systems, incorporating attributes\nrelevant to the Act not covered by current quality models. We map the Act\nrequirements to relevant quality attributes with the goal of refining them into\nmeasurable characteristics. We then propose a contract-based approach to derive\ntechnical requirements at the stakeholder level. This facilitates the\ndevelopment and assessment of AI systems that not only adhere to established\nquality standards, but also comply with the regulatory requirements outlined in\nthe Act for high-risk (including safety-critical) AI systems. We demonstrate\nthe applicability of this methodology on an exemplary automotive supply chain\nuse case, where several stakeholders interact to achieve EU AI Act compliance.",
      "tldr_zh": "这篇论文提出了一种方法论，帮助高风险 AI 系统（如安全关键产品）遵守欧盟 AI Act（EU AI Act）的规定，通过扩展产品质量模型并加入相关属性来实现。作者将法案要求映射到质量属性，并转化为可测量的特征，同时采用基于合同的方法定义利益相关者的技术要求，以确保 AI 系统符合质量标准和法规要求。在一个汽车供应链的示例用例中，演示了该方法论的有效性，为 AI 合规性提供了实用指导。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "To be published in: 2024 IEEE Conference on Artificial Intelligence\n  (CAI 2024)",
      "pdf_url": "http://arxiv.org/pdf/2403.16808v2",
      "published_date": "2024-03-25 14:32:18 UTC",
      "updated_date": "2024-03-26 08:59:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:42:15.514728"
    },
    {
      "arxiv_id": "2403.16798v3",
      "title": "Enhancing Neural Network Representations with Prior Knowledge-Based Normalization",
      "title_zh": "基于先验知识的归一化增强神经网络表示",
      "authors": [
        "Bilal Faye",
        "Hanane Azzag",
        "Mustapha Lebbah",
        "Djamel Bouchaffra"
      ],
      "abstract": "Deep learning models face persistent challenges in training, particularly due\nto internal covariate shift and label shift. While single-mode normalization\nmethods like Batch Normalization partially address these issues, they are\nconstrained by batch size dependencies and limiting distributional assumptions.\nMulti-mode normalization techniques mitigate these limitations but struggle\nwith computational demands when handling diverse Gaussian distributions. In\nthis paper, we introduce a new approach to multi-mode normalization that\nleverages prior knowledge to improve neural network representations. Our method\norganizes data into predefined structures, or \"contexts\", prior to training and\nnormalizes based on these contexts, with two variants: Context Normalization\n(CN) and Context Normalization - Extended (CN-X). When contexts are\nunavailable, we introduce Adaptive Context Normalization (ACN), which\ndynamically builds contexts in the latent space during training. Across tasks\nin image classification, domain adaptation, and image generation, our methods\ndemonstrate superior convergence and performance.",
      "tldr_zh": "本研究针对深度学习模型中内部协变量偏移(internal covariate shift)和标签偏移(label shift)的挑战，指出单模式归一化如 Batch Normalization 受批次大小和分布假设限制，而多模式归一化则面临计算负担问题。作者提出一种基于先验知识的多模式归一化方法，包括 Context Normalization (CN)、Context Normalization - Extended (CN-X) 和 Adaptive Context Normalization (ACN)，后者能在上下文不可用时动态构建潜在空间中的上下文。这些方法通过预定义数据结构进行归一化，在图像分类、域适应和图像生成任务上实现了优越的收敛和性能表现。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.NE"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16798v3",
      "published_date": "2024-03-25 14:17:38 UTC",
      "updated_date": "2024-10-30 10:55:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:42:28.580552"
    },
    {
      "arxiv_id": "2403.16782v1",
      "title": "The Anatomy of Adversarial Attacks: Concept-based XAI Dissection",
      "title_zh": "对抗攻击的解剖：基于概念的 XAI 剖析",
      "authors": [
        "Georgii Mikriukov",
        "Gesina Schwalbe",
        "Franz Motzkus",
        "Korinna Bade"
      ],
      "abstract": "Adversarial attacks (AAs) pose a significant threat to the reliability and\nrobustness of deep neural networks. While the impact of these attacks on model\npredictions has been extensively studied, their effect on the learned\nrepresentations and concepts within these models remains largely unexplored. In\nthis work, we perform an in-depth analysis of the influence of AAs on the\nconcepts learned by convolutional neural networks (CNNs) using eXplainable\nartificial intelligence (XAI) techniques. Through an extensive set of\nexperiments across various network architectures and targeted AA techniques, we\nunveil several key findings. First, AAs induce substantial alterations in the\nconcept composition within the feature space, introducing new concepts or\nmodifying existing ones. Second, the adversarial perturbation itself can be\nlinearly decomposed into a set of latent vector components, with a subset of\nthese being responsible for the attack's success. Notably, we discover that\nthese components are target-specific, i.e., are similar for a given target\nclass throughout different AA techniques and starting classes. Our findings\nprovide valuable insights into the nature of AAs and their impact on learned\nrepresentations, paving the way for the development of more robust and\ninterpretable deep learning models, as well as effective defenses against\nadversarial threats.",
      "tldr_zh": "本研究使用 eXplainable Artificial Intelligence (XAI) 技术，对对抗攻击 (Adversarial Attacks) 对卷积神经网络 (CNNs) 学习概念的影响进行深入分析，通过跨多种网络架构和攻击方法的实验，揭示了 AAs 会显著改变特征空间的概念组成，并将对抗扰动分解为目标特定的潜向量组件。研究发现，这些组件在不同攻击技术和起始类别中对特定目标类保持相似性，为理解 AAs 的本质提供了新洞见。最终，该工作为开发更鲁棒、可解释的深度学习模型以及有效的防御机制奠定了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16782v1",
      "published_date": "2024-03-25 13:57:45 UTC",
      "updated_date": "2024-03-25 13:57:45 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:42:42.513756"
    },
    {
      "arxiv_id": "2403.16768v1",
      "title": "DeepKnowledge: Generalisation-Driven Deep Learning Testing",
      "title_zh": "DeepKnowledge：泛化驱动的深度学习测试",
      "authors": [
        "Sondess Missaoui",
        "Simos Gerasimou",
        "Nikolaos Matragkas"
      ],
      "abstract": "Despite their unprecedented success, DNNs are notoriously fragile to small\nshifts in data distribution, demanding effective testing techniques that can\nassess their dependability. Despite recent advances in DNN testing, there is a\nlack of systematic testing approaches that assess the DNN's capability to\ngeneralise and operate comparably beyond data in their training distribution.\nWe address this gap with DeepKnowledge, a systematic testing methodology for\nDNN-based systems founded on the theory of knowledge generalisation, which aims\nto enhance DNN robustness and reduce the residual risk of 'black box' models.\nConforming to this theory, DeepKnowledge posits that core computational DNN\nunits, termed Transfer Knowledge neurons, can generalise under domain shift.\nDeepKnowledge provides an objective confidence measurement on testing\nactivities of DNN given data distribution shifts and uses this information to\ninstrument a generalisation-informed test adequacy criterion to check the\ntransfer knowledge capacity of a test set. Our empirical evaluation of several\nDNNs, across multiple datasets and state-of-the-art adversarial generation\ntechniques demonstrates the usefulness and effectiveness of DeepKnowledge and\nits ability to support the engineering of more dependable DNNs. We report\nimprovements of up to 10 percentage points over state-of-the-art coverage\ncriteria for detecting adversarial attacks on several benchmarks, including\nMNIST, SVHN, and CIFAR.",
      "tldr_zh": "本论文提出DeepKnowledge，一种基于知识泛化理论的系统测试方法，旨在评估DNNs在数据分布变化下的泛化能力，从而提升模型的鲁棒性和可靠性。DeepKnowledge通过识别核心计算单元Transfer Knowledge neurons来测量测试活动的置信度，并引入一个泛化信息驱动的测试充分性标准，以检查测试集的转移知识容量。该方法在多个数据集（如MNIST、SVHN和CIFAR）上进行了实证评估，结果显示其在检测adversarial attacks方面的性能比现有覆盖标准提高了多达10个百分点，证明了其在工程更可靠DNNs方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.LG",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.16768v1",
      "published_date": "2024-03-25 13:46:09 UTC",
      "updated_date": "2024-03-25 13:46:09 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:42:51.085800"
    },
    {
      "arxiv_id": "2403.16760v5",
      "title": "As Good As A Coin Toss: Human detection of AI-generated images, videos, audio, and audiovisual stimuli",
      "title_zh": "翻译失败",
      "authors": [
        "Di Cooke",
        "Abigail Edwards",
        "Sophia Barkoff",
        "Kathryn Kelly"
      ],
      "abstract": "One of the current principal defenses against weaponized synthetic media\ncontinues to be the ability of the targeted individual to visually or\nauditorily recognize AI-generated content when they encounter it. However, as\nthe realism of synthetic media continues to rapidly improve, it is vital to\nhave an accurate understanding of just how susceptible people currently are to\npotentially being misled by convincing but false AI generated content. We\nconducted a perceptual study with 1276 participants to assess how capable\npeople were at distinguishing between authentic and synthetic images, audio,\nvideo, and audiovisual media. We find that on average, people struggled to\ndistinguish between synthetic and authentic media, with the mean detection\nperformance close to a chance level performance of 50%. We also find that\naccuracy rates worsen when the stimuli contain any degree of synthetic content,\nfeatures foreign languages, and the media type is a single modality. People are\nalso less accurate at identifying synthetic images when they feature human\nfaces, and when audiovisual stimuli have heterogeneous authenticity. Finally,\nwe find that higher degrees of prior knowledgeability about synthetic media\ndoes not significantly impact detection accuracy rates, but age does, with\nolder individuals performing worse than their younger counterparts.\nCollectively, these results highlight that it is no longer feasible to rely on\nthe perceptual capabilities of people to protect themselves against the growing\nthreat of weaponized synthetic media, and that the need for alternative\ncountermeasures is more critical than ever before.",
      "tldr_zh": "这篇论文评估了人们识别AI-generated images、videos、audio和audiovisual stimuli的能力，通过一项涉及1276名参与者的感知研究。结果显示，平均检测准确率接近50%的随机水平，尤其在媒体包含合成内容、外语特征或单一模态时表现更差，且人脸图像或真实性不一致的音视频更难识别。研究发现，先前对synthetic media的知识并不会显著提高准确率，但年龄是影响因素，年长者检测能力较弱；总体结论是，依赖人类感知来防范AI生成媒体的威胁已不可行，需要紧急开发替代性对策。",
      "categories": [
        "cs.HC",
        "cs.AI",
        "cs.SD",
        "eess.AS",
        "68T01",
        "I.2"
      ],
      "primary_category": "cs.HC",
      "comment": "For study pre-registration, see https://osf.io/fnhr3 V5: expanded on\n  ecological validation in Introduction; revised table in Results to add OR &\n  OR CI, previous data unchanged; added further details on study design in\n  Methods; added Appendix with survey screenshots; migrated list of dataset\n  sources from footnotes into references",
      "pdf_url": "http://arxiv.org/pdf/2403.16760v5",
      "published_date": "2024-03-25 13:39:33 UTC",
      "updated_date": "2025-04-10 20:30:04 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:43:04.705942"
    },
    {
      "arxiv_id": "2403.16757v1",
      "title": "Bi-objective Optimization in Role Mining",
      "title_zh": "角色挖掘中的双目标优化",
      "authors": [
        "Jason Crampton",
        "Eduard Eiben",
        "Gregory Gutin",
        "Daniel Karapetyan",
        "Diptapriyo Majumdar"
      ],
      "abstract": "Role mining is a technique used to derive a role-based authorization policy\nfrom an existing policy. Given a set of users $U$, a set of permissions $P$ and\na user-permission authorization relation $\\mahtit{UPA}\\subseteq U\\times P$, a\nrole mining algorithm seeks to compute a set of roles $R$, a user-role\nauthorization relation $\\mathit{UA}\\subseteq U\\times R$ and a permission-role\nauthorization relation $\\mathit{PA}\\subseteq R\\times P$, such that the\ncomposition of $\\mathit{UA}$ and $\\mathit{PA}$ is close (in some appropriate\nsense) to $\\mathit{UPA}$.\n  In this paper, we first introduce the Generalized Noise Role Mining problem\n(GNRM) -- a generalization of the MinNoise Role Mining problem -- which we\nbelieve has considerable practical relevance. Extending work of Fomin et al.,\nwe show that GNRM is fixed parameter tractable, with parameter $r + k$, where\n$r$ is the number of roles in the solution and $k$ is the number of\ndiscrepancies between $\\mathit{UPA}$ and the relation defined by the\ncomposition of $\\mathit{UA}$ and $\\mathit{PA}$. We further introduce a\nbi-objective optimization variant of GNRM, where we wish to minimize both $r$\nand $k$ subject to upper bounds $r\\le \\bar{r}$ and $k\\le \\bar{k}$, where\n$\\bar{r}$ and $\\bar{k}$ are constants. We show that the Pareto front of this\nbi-objective optimization problem (BO-GNRM) can be computed in fixed-parameter\ntractable time with parameter $\\bar{r}+\\bar{k}$.\n  We then report the results of our experimental work using the integer\nprogramming solver Gurobi to solve instances of BO-GNRM. Our key findings are\nthat (a) we obtained strong support that Gurobi's performance is\nfixed-parameter tractable, (b) our results suggest that our techniques may be\nuseful for role mining in practice, based on our experiments in the context of\nthree well-known real-world authorization policies.",
      "tldr_zh": "这篇论文引入了 Generalized Noise Role Mining (GNRM) 问题，这是一种从现有用户权限关系中推导出角色授权策略的推广方法。作者证明了 GNRM 在参数 r + k 下是 fixed parameter tractable 的，并扩展到双目标优化变体 (BO-GNRM)，通过最小化角色数 r 和差异数 k（在上限 \\bar{r} 和 \\bar{k} 下）来计算 Pareto front，也在固定参数可计算时间内实现。实验使用整数规划求解器 Gurobi 验证了这些方法的效率，结果表明其性能符合理论预期，并在三个真实世界授权策略中显示出实际应用潜力。",
      "categories": [
        "cs.CR",
        "cs.AI",
        "cs.CC"
      ],
      "primary_category": "cs.CR",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16757v1",
      "published_date": "2024-03-25 13:36:20 UTC",
      "updated_date": "2024-03-25 13:36:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:43:17.359589"
    },
    {
      "arxiv_id": "2403.16750v1",
      "title": "All Artificial, Less Intelligence: GenAI through the Lens of Formal Verification",
      "title_zh": "全人工，少智能：通过形式验证审视生成式AI",
      "authors": [
        "Deepak Narayan Gadde",
        "Aman Kumar",
        "Thomas Nalapat",
        "Evgenii Rezunov",
        "Fabio Cappellini"
      ],
      "abstract": "Modern hardware designs have grown increasingly efficient and complex.\nHowever, they are often susceptible to Common Weakness Enumerations (CWEs).\nThis paper is focused on the formal verification of CWEs in a dataset of\nhardware designs written in SystemVerilog from Regenerative Artificial\nIntelligence (AI) powered by Large Language Models (LLMs). We applied formal\nverification to categorize each hardware design as vulnerable or CWE-free. This\ndataset was generated by 4 different LLMs and features a unique set of designs\nfor each of the 10 CWEs we target in our paper. We have associated the\nidentified vulnerabilities with CWE numbers for a dataset of 60,000 generated\nSystemVerilog Register Transfer Level (RTL) code. It was also found that most\nLLMs are not aware of any hardware CWEs; hence they are usually not considered\nwhen generating the hardware code. Our study reveals that approximately 60% of\nthe hardware designs generated by LLMs are prone to CWEs, posing potential\nsafety and security risks. The dataset could be ideal for training LLMs and\nMachine Learning (ML) algorithms to abstain from generating CWE-prone hardware\ndesigns.",
      "tldr_zh": "本研究通过正式验证(Formal Verification)视角，评估了由大型语言模型(LLMs)生成的硬件设计中常见的弱点枚举(Common Weakness Enumerations, CWEs)的风险。研究者创建了一个数据集，包括由4个不同LLMs生成的60,000个SystemVerilog Register Transfer Level (RTL)代码，针对10个特定CWEs进行分类，结果显示约60%的设计存在漏洞，且LLMs通常不了解硬件CWEs，从而忽略了这些潜在的安全和安全风险。该数据集可用于训练LLMs和机器学习(ML)算法，以减少生成易受CWEs影响的硬件设计的可能性。",
      "categories": [
        "cs.AI",
        "cs.AR"
      ],
      "primary_category": "cs.AI",
      "comment": "Published in DVCon U.S. 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16750v1",
      "published_date": "2024-03-25 13:23:24 UTC",
      "updated_date": "2024-03-25 13:23:24 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:43:29.273907"
    },
    {
      "arxiv_id": "2403.16732v2",
      "title": "Enabling Uncertainty Estimation in Iterative Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Nikita Durasov",
        "Doruk Oner",
        "Jonathan Donier",
        "Hieu Le",
        "Pascal Fua"
      ],
      "abstract": "Turning pass-through network architectures into iterative ones, which use\ntheir own output as input, is a well-known approach for boosting performance.\nIn this paper, we argue that such architectures offer an additional benefit:\nThe convergence rate of their successive outputs is highly correlated with the\naccuracy of the value to which they converge. Thus, we can use the convergence\nrate as a useful proxy for uncertainty. This results in an approach to\nuncertainty estimation that provides state-of-the-art estimates at a much lower\ncomputational cost than techniques like Ensembles, and without requiring any\nmodifications to the original iterative model. We demonstrate its practical\nvalue by embedding it in two application domains: road detection in aerial\nimages and the estimation of aerodynamic properties of 2D and 3D shapes.",
      "tldr_zh": "本文提出了一种利用迭代神经网络(Iterative Neural Networks)来启用不确定性估计(Uncertainty Estimation)的方法，通过观察迭代输出的收敛速率与最终准确性的高度相关性，将收敛速率作为不确定性的代理指标。相比于传统技术如 Ensembles，该方法无需修改原模型即可实现 state-of-the-art 的不确定性估计，同时显著降低计算成本。在航空图像道路检测和2D/3D形状空气动力学属性估计等应用中，实验验证了其实际有效性。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted at ICML 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16732v2",
      "published_date": "2024-03-25 13:06:31 UTC",
      "updated_date": "2024-05-30 10:10:19 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:43:39.884051"
    },
    {
      "arxiv_id": "2403.16728v1",
      "title": "Improving Diffusion Models's Data-Corruption Resistance using Scheduled Pseudo-Huber Loss",
      "title_zh": "翻译失败",
      "authors": [
        "Artem Khrapov",
        "Vadim Popov",
        "Tasnima Sadekova",
        "Assel Yermekova",
        "Mikhail Kudinov"
      ],
      "abstract": "Diffusion models are known to be vulnerable to outliers in training data. In\nthis paper we study an alternative diffusion loss function, which can preserve\nthe high quality of generated data like the original squared $L_{2}$ loss while\nat the same time being robust to outliers. We propose to use pseudo-Huber loss\nfunction with a time-dependent parameter to allow for the trade-off between\nrobustness on the most vulnerable early reverse-diffusion steps and fine\ndetails restoration on the final steps. We show that pseudo-Huber loss with the\ntime-dependent parameter exhibits better performance on corrupted datasets in\nboth image and audio domains. In addition, the loss function we propose can\npotentially help diffusion models to resist dataset corruption while not\nrequiring data filtering or purification compared to conventional training\nalgorithms.",
      "tldr_zh": "这篇论文针对 Diffusion models 在训练数据中异常值（outliers）的脆弱性，提出了一种改进方法，使用带有时间相关参数的 Scheduled Pseudo-Huber loss 函数。该函数能在早期逆扩散步骤上增强鲁棒性，同时在后期步骤上保持细细节的恢复，从而兼顾生成数据的质量和抗噪能力。实验结果显示，该方法在图像和音频领域的损坏数据集上表现出色，性能比传统 L2 loss 提升明显，且无需进行数据过滤或净化。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "13 pages, 16 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16728v1",
      "published_date": "2024-03-25 13:02:43 UTC",
      "updated_date": "2024-03-25 13:02:43 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:43:53.727927"
    },
    {
      "arxiv_id": "2403.16719v1",
      "title": "Towards a Formalisation of Value-based Actions and Consequentialist Ethics",
      "title_zh": "翻译失败",
      "authors": [
        "Adam Wyner",
        "Tomasz Zurek",
        "DOrota Stachura-Zurek"
      ],
      "abstract": "Agents act to bring about a state of the world that is more compatible with\ntheir personal or institutional values. To formalise this intuition, the paper\nproposes an action framework based on the STRIPS formalisation. Technically,\nthe contribution expresses actions in terms of Value-based Formal Reasoning\n(VFR), which provides a set of propositions derived from an Agent's value\nprofile and the Agent's assessment of propositions with respect to the profile.\nConceptually, the contribution provides a computational framework for a form of\nconsequentialist ethics which is satisficing, luralistic, act-based, and\npreferential.",
      "tldr_zh": "该论文旨在形式化代理基于个人或机构价值观的行动，提出一个以 STRIPS 形式化为基础的行动框架。框架引入 Value-based Formal Reasoning (VFR)，通过代理的价值配置文件衍生命题并评估其与价值观的兼容性。作为主要贡献，该框架提供了一个计算模型，支持一种 satisficing、pluralistic、act-based 和 preferential 的后果主义伦理。总的来说，这为代理决策的伦理建模提供了新的理论基础。",
      "categories": [
        "cs.MA",
        "cs.AI"
      ],
      "primary_category": "cs.MA",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16719v1",
      "published_date": "2024-03-25 12:56:48 UTC",
      "updated_date": "2024-03-25 12:56:48 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:44:06.049905"
    },
    {
      "arxiv_id": "2403.16707v2",
      "title": "One-Shot Domain Incremental Learning",
      "title_zh": "单样本领域增量学习",
      "authors": [
        "Yasushi Esaki",
        "Satoshi Koide",
        "Takuro Kutsuna"
      ],
      "abstract": "Domain incremental learning (DIL) has been discussed in previous studies on\ndeep neural network models for classification. In DIL, we assume that samples\non new domains are observed over time. The models must classify inputs on all\ndomains. In practice, however, we may encounter a situation where we need to\nperform DIL under the constraint that the samples on the new domain are\nobserved only infrequently. Therefore, in this study, we consider the extreme\ncase where we have only one sample from the new domain, which we call one-shot\nDIL. We first empirically show that existing DIL methods do not work well in\none-shot DIL. We have analyzed the reason for this failure through various\ninvestigations. According to our analysis, we clarify that the difficulty of\none-shot DIL is caused by the statistics in the batch normalization layers.\nTherefore, we propose a technique regarding these statistics and demonstrate\nthe effectiveness of our technique through experiments on open datasets. The\ncode is available at https://github.com/ToyotaCRDL/OneShotDIL.",
      "tldr_zh": "本研究探讨了One-Shot Domain Incremental Learning，即在领域增量学习(Domain Incremental Learning, DIL)中，仅有一个新领域样本的极端场景。现有DIL方法在这种情况下效果不佳，通过各种调查分析发现，问题主要源于batch normalization layers的统计。论文提出了一种针对这些统计的技术，以改进模型的适应性和性能。在开放数据集上的实验验证了该技术的有效性，并提供了开源代码（https://github.com/ToyotaCRDL/OneShotDIL）。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "Accepted at IEEE International Joint Conference on Neural Networks\n  (IJCNN) 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16707v2",
      "published_date": "2024-03-25 12:44:52 UTC",
      "updated_date": "2025-02-24 06:58:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:44:18.416749"
    },
    {
      "arxiv_id": "2403.16687v5",
      "title": "Investigation of the effectiveness of applying ChatGPT in Dialogic Teaching Using Electroencephalography",
      "title_zh": "使用脑电",
      "authors": [
        "Jiayue Zhang",
        "Yiheng Liu",
        "Wenqi Cai",
        "Lanlan Wu",
        "Yali Peng",
        "Jingjing Yu",
        "Senqing Qi",
        "Taotao Long",
        "Bao Ge"
      ],
      "abstract": "In recent years, the rapid development of artificial intelligence technology,\nespecially the emergence of large language models (LLMs) such as ChatGPT, has\npresented significant prospects for application in the field of education. LLMs\npossess the capability to interpret knowledge, answer questions, and consider\ncontext, thus providing support for dialogic teaching to students. Therefore,\nan examination of the capacity of LLMs to effectively fulfill instructional\nroles, thereby facilitating student learning akin to human educators within\ndialogic teaching scenarios, is an exceptionally valuable research topic. This\nresearch recruited 34 undergraduate students as participants, who were randomly\ndivided into two groups. The experimental group engaged in dialogic teaching\nusing ChatGPT, while the control group interacted with human teachers. Both\ngroups learned the histogram equalization unit in the information-related\ncourse \"Digital Image Processing\". The research findings show comparable scores\nbetween the two groups on the retention test. However, students who engaged in\ndialogue with ChatGPT exhibited lower performance on the transfer test.\nElectroencephalography data revealed that students who interacted with ChatGPT\nexhibited higher levels of cognitive activity, suggesting that ChatGPT could\nhelp students establish a knowledge foundation and stimulate cognitive\nactivity. However, its strengths on promoting students. knowledge application\nand creativity were insignificant. Based upon the research findings, it is\nevident that ChatGPT cannot fully excel in fulfilling teaching tasks in the\ndialogue teaching in information related courses. Combining ChatGPT with\ntraditional human teachers might be a more ideal approach. The synergistic use\nof both can provide students with more comprehensive learning support, thus\ncontributing to enhancing the quality of teaching.",
      "tldr_zh": "这篇论文调查了 ChatGPT 在对话式教学中的有效性，通过招募 34 名本科生分为实验组（使用 ChatGPT）和控制组（使用人类教师），并采用 Electroencephalography (EEG) 技术评估他们在“数字图像处理”课程直方图均衡单元的学习表现。结果显示，两组在保留测试成绩相当，但实验组在迁移测试中表现较差。EEG 数据揭示，使用 ChatGPT 的学生显示出更高的认知活动水平，能帮助建立知识基础并刺激思维，但其在促进知识应用和创造力方面效果有限。研究结论认为，ChatGPT 无法完全取代人类教师，建议将其与传统教学结合，以提供更全面的教育支持。",
      "categories": [
        "cs.CY",
        "cs.AI",
        "physics.ed-ph"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16687v5",
      "published_date": "2024-03-25 12:23:12 UTC",
      "updated_date": "2024-06-11 03:35:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:44:30.168863"
    },
    {
      "arxiv_id": "2403.17040v1",
      "title": "Enhancing Graph Representation Learning with Attention-Driven Spiking Neural Networks",
      "title_zh": "翻译失败",
      "authors": [
        "Huifeng Yin",
        "Mingkun Xu",
        "Jing Pei",
        "Lei Deng"
      ],
      "abstract": "Graph representation learning has become a crucial task in machine learning\nand data mining due to its potential for modeling complex structures such as\nsocial networks, chemical compounds, and biological systems. Spiking neural\nnetworks (SNNs) have recently emerged as a promising alternative to traditional\nneural networks for graph learning tasks, benefiting from their ability to\nefficiently encode and process temporal and spatial information. In this paper,\nwe propose a novel approach that integrates attention mechanisms with SNNs to\nimprove graph representation learning. Specifically, we introduce an attention\nmechanism for SNN that can selectively focus on important nodes and\ncorresponding features in a graph during the learning process. We evaluate our\nproposed method on several benchmark datasets and show that it achieves\ncomparable performance compared to existing graph learning techniques.",
      "tldr_zh": "本研究针对图表示学习(Graph Representation Learning)中建模复杂结构的需求，提出了一种将注意力机制融入脉冲神经网络(Spiking Neural Networks, SNNs)的新方法。该方法通过注意力机制选择性地关注图中的重要节点和特征，从而提升了网络对时间和空间信息的处理能力。在多个基准数据集上进行的实验表明，该方法与现有图学习技术相比，实现了可比的性能表现，为高效的图数据分析提供了新途径。",
      "categories": [
        "cs.AI",
        "cs.LG",
        "cs.NE"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.17040v1",
      "published_date": "2024-03-25 12:15:10 UTC",
      "updated_date": "2024-03-25 12:15:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:44:42.088941"
    },
    {
      "arxiv_id": "2403.16674v2",
      "title": "Understanding the Functional Roles of Modelling Components in Spiking Neural Networks",
      "title_zh": "理解脉冲神经网络中建模组件的功能作用",
      "authors": [
        "Huifeng Yin",
        "Hanle Zheng",
        "Jiayi Mao",
        "Siyuan Ding",
        "Xing Liu",
        "Mingkun Xu",
        "Yifan Hu",
        "Jing Pei",
        "Lei Deng"
      ],
      "abstract": "Spiking neural networks (SNNs), inspired by the neural circuits of the brain,\nare promising in achieving high computational efficiency with biological\nfidelity. Nevertheless, it is quite difficult to optimize SNNs because the\nfunctional roles of their modelling components remain unclear. By designing and\nevaluating several variants of the classic model, we systematically investigate\nthe functional roles of key modelling components, leakage, reset, and\nrecurrence, in leaky integrate-and-fire (LIF) based SNNs. Through extensive\nexperiments, we demonstrate how these components influence the accuracy,\ngeneralization, and robustness of SNNs. Specifically, we find that the leakage\nplays a crucial role in balancing memory retention and robustness, the reset\nmechanism is essential for uninterrupted temporal processing and computational\nefficiency, and the recurrence enriches the capability to model complex\ndynamics at a cost of robustness degradation. With these interesting\nobservations, we provide optimization suggestions for enhancing the performance\nof SNNs in different scenarios. This work deepens the understanding of how SNNs\nwork, which offers valuable guidance for the development of more effective and\nrobust neuromorphic models.",
      "tldr_zh": "本文研究了Spiking Neural Networks (SNNs)中关键建模组件的功能角色，包括leakage、reset和recurrence，通过设计和评估leaky integrate-and-fire (LIF)基于SNNs的变体进行系统调查。实验结果显示，leakage在平衡记忆保留和鲁棒性方面起关键作用，reset机制确保了不间断的时间处理和计算效率，而recurrence增强了建模复杂动态的能力但会降低鲁棒性。这些发现为SNNs的优化提供了实用建议，并加深了对神经形态模型工作原理的理解。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16674v2",
      "published_date": "2024-03-25 12:13:20 UTC",
      "updated_date": "2025-01-27 02:47:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:44:56.201855"
    },
    {
      "arxiv_id": "2403.16667v1",
      "title": "Deep Reinforcement Learning and Mean-Variance Strategies for Responsible Portfolio Optimization",
      "title_zh": "翻译失败",
      "authors": [
        "Fernando Acero",
        "Parisa Zehtabi",
        "Nicolas Marchesotti",
        "Michael Cashmore",
        "Daniele Magazzeni",
        "Manuela Veloso"
      ],
      "abstract": "Portfolio optimization involves determining the optimal allocation of\nportfolio assets in order to maximize a given investment objective.\nTraditionally, some form of mean-variance optimization is used with the aim of\nmaximizing returns while minimizing risk, however, more recently, deep\nreinforcement learning formulations have been explored. Increasingly, investors\nhave demonstrated an interest in incorporating ESG objectives when making\ninvestment decisions, and modifications to the classical mean-variance\noptimization framework have been developed. In this work, we study the use of\ndeep reinforcement learning for responsible portfolio optimization, by\nincorporating ESG states and objectives, and provide comparisons against\nmodified mean-variance approaches. Our results show that deep reinforcement\nlearning policies can provide competitive performance against mean-variance\napproaches for responsible portfolio allocation across additive and\nmultiplicative utility functions of financial and ESG responsibility\nobjectives.",
      "tldr_zh": "本文研究了深度强化学习（Deep Reinforcement Learning）和均值-方差策略（Mean-Variance Strategies）在负责任投资组合优化（Responsible Portfolio Optimization）中的应用，特别关注融入ESG（环境、社会和治理）目标。作者通过修改传统框架，将ESG状态和目标纳入深度强化学习模型，并与改进后的均值-方差方法进行比较。结果显示，深度强化学习策略在处理金融回报和ESG责任目标的加法及乘法效用函数时，能提供与均值-方差方法相媲美的性能。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Presented at the AAAI 2024 Workshop on AI in Finance for Social\n  Impact",
      "pdf_url": "http://arxiv.org/pdf/2403.16667v1",
      "published_date": "2024-03-25 12:04:03 UTC",
      "updated_date": "2024-03-25 12:04:03 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:45:06.448954"
    },
    {
      "arxiv_id": "2403.16666v1",
      "title": "Revisiting the Sleeping Beauty problem",
      "title_zh": "重新审视睡眠美人问题",
      "authors": [
        "Paulo S. Piva",
        "Gabriel Ruffolo"
      ],
      "abstract": "The Sleeping Beauty problem is a probability riddle with no definite solution\nfor more than two decades and its solution is of great interest in many fields\nof knowledge. There are two main competing solutions to the problem: the halfer\napproach, and the thirder approach. The main reason for disagreement in the\nliterature is connected to the use of different probability spaces to represent\nthe same probabilistic riddle. In this work, we analyse the problem from a\nmathematical perspective, identifying probability distributions induced\ndirectly from the thought experiment's rules. The precise choices of\nprobability spaces provide both halfer and thirder solutions to the problem. To\ntry and decide on which approach to follow, a criterion involving the\ninformation available to Sleeping Beauty is proposed.",
      "tldr_zh": "这篇论文重新审视了长期未决的概率谜题Sleeping Beauty problem，分析了halfer approach和thirder approach两种主要解决方案的分歧，该分歧源于不同概率空间的选择。作者从数学视角出发，识别出从思想实验规则中诱导的概率分布，从而证明这两种解决方案都能在精确概率空间中实现。为决定最佳方法，论文提出一个基于Sleeping Beauty可用信息的标准，以提供更可靠的决策框架。",
      "categories": [
        "math.HO",
        "cs.AI"
      ],
      "primary_category": "math.HO",
      "comment": "14 pages, 1 figure",
      "pdf_url": "http://arxiv.org/pdf/2403.16666v1",
      "published_date": "2024-03-25 12:01:27 UTC",
      "updated_date": "2024-03-25 12:01:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:45:18.841904"
    },
    {
      "arxiv_id": "2403.16649v2",
      "title": "CLHA: A Simple yet Effective Contrastive Learning Framework for Human Alignment",
      "title_zh": "CLHA：一种简单而有效的对比学习框架，用于人类对齐",
      "authors": [
        "Feiteng Fang",
        "Liang Zhu",
        "Min Yang",
        "Xi Feng",
        "Jinchang Hou",
        "Qixuan Zhao",
        "Chengming Li",
        "Xiping Hu",
        "Ruifeng Xu"
      ],
      "abstract": "Reinforcement learning from human feedback (RLHF) is a crucial technique in\naligning large language models (LLMs) with human preferences, ensuring these\nLLMs behave in beneficial and comprehensible ways to users. However, a\nlongstanding challenge in human alignment techniques based on reinforcement\nlearning lies in their inherent complexity and difficulty in training. To\naddress this challenge, we present a simple yet effective Contrastive Learning\nFramework for Human Alignment (CLHA) to align LLMs with human preferences\ndirectly. CLHA employs a novel rescoring strategy to evaluate the noise within\nthe data by considering its inherent quality and dynamically adjusting the\ntraining process. Simultaneously, CLHA utilizes pairwise contrastive loss and\nadaptive supervised fine-tuning loss to adaptively modify the likelihood of\ngenerating responses, ensuring enhanced alignment with human preferences. Using\nadvanced methods, CLHA surpasses other algorithms, showcasing superior\nperformance in terms of reward model scores, automatic evaluations, and human\nassessments on the widely used ``Helpful and Harmless'' dataset.",
      "tldr_zh": "这篇论文提出了 CLHA，一种简单有效的对比学习框架，用于直接对齐大型语言模型（LLMs）以符合人类偏好，旨在解决 RLHF（Reinforcement Learning from Human Feedback）方法在复杂性和训练难度方面的挑战。CLHA 引入了新型 rescoring 策略来评估数据噪声并动态调整训练过程，同时结合 pairwise contrastive loss 和 adaptive supervised fine-tuning loss，以适应性地提升模型生成响应的质量和人类偏好对齐。实验结果显示，CLHA 在“Helpful and Harmless”数据集上超越其他算法，在奖励模型分数、自动评估和人类评估中表现出色。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16649v2",
      "published_date": "2024-03-25 11:37:15 UTC",
      "updated_date": "2024-03-26 06:08:20 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:45:30.259803"
    },
    {
      "arxiv_id": "2403.16591v3",
      "title": "Deciphering the Interplay between Local Differential Privacy, Average Bayesian Privacy, and Maximum Bayesian Privacy",
      "title_zh": "解读本地差分隐私、平均贝叶斯隐私和最大贝叶斯隐私之间的相互作用",
      "authors": [
        "Xiaojin Zhang",
        "Yulin Fei",
        "Wei Chen"
      ],
      "abstract": "The swift evolution of machine learning has led to emergence of various\ndefinitions of privacy due to the threats it poses to privacy, including the\nconcept of local differential privacy (LDP). Although widely embraced and\nutilized across numerous domains, this conventional approach to measure privacy\nstill exhibits certain limitations, spanning from failure to prevent\ninferential disclosure to lack of consideration for the adversary's background\nknowledge. In this comprehensive study, we introduce Bayesian privacy and delve\ninto the intricate relationship between LDP and its Bayesian counterparts,\nunveiling novel insights into utility-privacy trade-offs. We introduce a\nframework that encapsulates both attack and defense strategies, highlighting\ntheir interplay and effectiveness. The relationship between LDP and Maximum\nBayesian Privacy (MBP) is first revealed, demonstrating that under uniform\nprior distribution, a mechanism satisfying $\\xi$-LDP will satisfy $\\xi$-MBP and\nconversely $\\xi$-MBP also confers 2$\\xi$-LDP. Our next theoretical contribution\nare anchored in the rigorous definitions and relationships between Average\nBayesian Privacy (ABP) and Maximum Bayesian Privacy (MBP), encapsulated by\nequations $\\epsilon_{p,a} \\leq \\frac{1}{\\sqrt{2}}\\sqrt{(\\epsilon_{p,m} +\n\\epsilon)\\cdot(e^{\\epsilon_{p,m} + \\epsilon} - 1)}$. These relationships\nfortify our understanding of the privacy guarantees provided by various\nmechanisms. Our work not only lays the groundwork for future empirical\nexploration but also promises to facilitate the design of privacy-preserving\nalgorithms, thereby fostering the development of trustworthy machine learning\nsolutions.",
      "tldr_zh": "这篇论文探讨了Local Differential Privacy (LDP)、Average Bayesian Privacy (ABP) 和 Maximum Bayesian Privacy (MBP) 之间的相互关系，旨在解决传统隐私测量方法的局限性，如未能防范推断性泄露和忽略攻击者背景知识。研究引入了一个包含攻击和防御策略的框架，并证明了关键理论联系，例如在均匀先验分布下，满足ξ-LDP的机制也满足ξ-MBP，反之ξ-MBP可推导出2ξ-LDP；同时，给出了ABP和MBP之间的数学关系，如ε_{p,a} ≤ (1/√2) √[(ε_{p,m} + ε) · (e^{ε_{p,m} + ε} - 1)]。这些发现深化了对效用-隐私权衡的理解，并为设计隐私保护算法和可信赖机器学习解决方案提供了基础。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CR"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16591v3",
      "published_date": "2024-03-25 10:06:45 UTC",
      "updated_date": "2024-04-02 14:28:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:45:42.054066"
    },
    {
      "arxiv_id": "2403.16582v2",
      "title": "In the Search for Optimal Multi-view Learning Models for Crop Classification with Global Remote Sensing Data",
      "title_zh": "翻译失败",
      "authors": [
        "Francisco Mena",
        "Diego Arenas",
        "Andreas Dengel"
      ],
      "abstract": "Studying and analyzing cropland is a difficult task due to its dynamic and\nheterogeneous growth behavior. Usually, diverse data sources can be collected\nfor its estimation. Although deep learning models have proven to excel in the\ncrop classification task, they face substantial challenges when dealing with\nmultiple inputs, named Multi-View Learning (MVL). The methods used in the MVL\nscenario can be structured based on the encoder architecture, the fusion\nstrategy, and the optimization technique. The literature has primarily focused\non using specific encoder architectures for local regions, lacking a deeper\nexploration of other components in the MVL methodology. In contrast, we\ninvestigate the simultaneous selection of the fusion strategy and encoder\narchitecture, assessing global-scale cropland and crop-type classifications. We\nuse a range of five fusion strategies (Input, Feature, Decision, Ensemble,\nHybrid) and five temporal encoders (LSTM, GRU, TempCNN, TAE, L-TAE) as possible\nconfigurations in the MVL method. We use the CropHarvest dataset for\nvalidation, which provides optical, radar, weather time series, and topographic\ninformation as input data. We found that in scenarios with a limited number of\nlabeled samples, a unique configuration is insufficient for all the cases.\nInstead, a specialized combination should be meticulously sought, including an\nencoder and fusion strategy. To streamline this search process, we suggest\nidentifying the optimal encoder architecture tailored for a particular fusion\nstrategy, and then determining the most suitable fusion strategy for the\nclassification task. We provide a methodological framework for researchers\nexploring crop classification through an MVL methodology.",
      "tldr_zh": "本研究探讨了使用全球遥感数据进行作物分类的最佳多视图学习（Multi-View Learning, MVL）模型，针对作物动态和异质性的挑战。作者评估了五种融合策略（Input, Feature, Decision, Ensemble, Hybrid）和五种时间编码器（LSTM, GRU, TempCNN, TAE, L-TAE）的组合，利用CropHarvest数据集（包括光学、雷达、天气时间序列和地形信息）进行全球规模的作物和作物类型分类。实验发现，在标签样本有限的场景下，没有单一配置适用于所有情况，而是需要针对特定任务选择最佳的编码器和融合策略组合。研究建议先优化适合特定融合策略的编码器架构，然后确定最合适的融合策略，从而提供了一个方法框架，帮助研究者提升MVL在作物分类中的性能。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.LG",
      "comment": "submitted to journal",
      "pdf_url": "http://arxiv.org/pdf/2403.16582v2",
      "published_date": "2024-03-25 09:49:42 UTC",
      "updated_date": "2024-09-04 11:14:18 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:45:56.353770"
    },
    {
      "arxiv_id": "2403.16578v4",
      "title": "SegICL: A Multimodal In-context Learning Framework for Enhanced Segmentation in Medical Imaging",
      "title_zh": "翻译失败",
      "authors": [
        "Lingdong Shen",
        "Fangxin Shang",
        "Xiaoshuang Huang",
        "Yehui Yang",
        "Haifeng Huang",
        "Shiming Xiang"
      ],
      "abstract": "In the field of medical image segmentation, tackling Out-of-Distribution\n(OOD) segmentation tasks in a cost-effective manner remains a significant\nchallenge. Universal segmentation models is a solution, which aim to generalize\nacross the diverse modality of medical images, yet their effectiveness often\ndiminishes when applied to OOD data modalities and tasks, requiring intricate\nfine-tuning of model for optimal performance. Few-shot learning segmentation\nmethods are typically designed for specific modalities of data and cannot be\ndirectly transferred for use with another modality. Therefore, we introduce\nSegICL, a novel approach leveraging In-Context Learning (ICL) for image\nsegmentation. Unlike existing methods, SegICL has the capability to employ\ntext-guided segmentation and conduct in-context learning with a small set of\nimage-mask pairs, eliminating the need for training the model from scratch or\nfine-tuning for OOD tasks (including OOD modality and dataset). Extensive\nexperimental demonstrates a positive correlation between the number of shots\nand segmentation performance on OOD tasks. The performance of segmentation when\nprovided thre-shots is approximately 1.5 times better than the performance in a\nzero-shot setting. This indicates that SegICL effectively address new\nsegmentation tasks based on contextual information. Additionally, SegICL also\nexhibits comparable performance to mainstream models on OOD and in-distribution\ntasks. Our code will be released after paper review.",
      "tldr_zh": "该研究针对医疗图像分割中Out-of-Distribution (OOD)任务的挑战，提出了一种新型框架SegICL，利用In-Context Learning (ICL)技术，通过文本引导的分割和少量图像-掩码对进行学习，而无需从零训练或微调模型。SegICL能够有效处理不同模态和数据集的OOD任务，实验显示样本数量与性能正相关，提供三样本时比零样本设置提升约1.5倍。总体上，SegICL在OOD和in-distribution任务上表现出与主流模型相当的性能，为高效的医疗图像分割提供了可扩展的解决方案。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16578v4",
      "published_date": "2024-03-25 09:43:56 UTC",
      "updated_date": "2024-05-30 03:35:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:46:07.933643"
    },
    {
      "arxiv_id": "2403.16571v1",
      "title": "NSINA: A News Corpus for Sinhala",
      "title_zh": "NSINA：一种用于僧伽罗语的",
      "authors": [
        "Hansi Hettiarachchi",
        "Damith Premasiri",
        "Lasitha Uyangodage",
        "Tharindu Ranasinghe"
      ],
      "abstract": "The introduction of large language models (LLMs) has advanced natural\nlanguage processing (NLP), but their effectiveness is largely dependent on\npre-training resources. This is especially evident in low-resource languages,\nsuch as Sinhala, which face two primary challenges: the lack of substantial\ntraining data and limited benchmarking datasets. In response, this study\nintroduces NSINA, a comprehensive news corpus of over 500,000 articles from\npopular Sinhala news websites, along with three NLP tasks: news media\nidentification, news category prediction, and news headline generation. The\nrelease of NSINA aims to provide a solution to challenges in adapting LLMs to\nSinhala, offering valuable resources and benchmarks for improving NLP in the\nSinhala language. NSINA is the largest news corpus for Sinhala, available up to\ndate.",
      "tldr_zh": "这篇论文针对低资源语言Sinhala的NLP（Natural Language Processing）挑战，引入了NSINA语料库，该语料库包含超过50万篇来自流行新闻网站的文章，以解决LLMs（Large Language Models）预训练数据不足的问题。NSINA同时提供了三个NLP任务：新闻媒体识别、新闻类别预测和新闻标题生成，作为基准数据集。研究表明，NSINA作为目前最大的Sinhala新闻语料库，将有助于提升LLMs在Sinhala语言中的适应性和整体性能。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to LREC-COLING 2024 (The 2024 Joint International Conference\n  on Computational Linguistics, Language Resources and Evaluation)",
      "pdf_url": "http://arxiv.org/pdf/2403.16571v1",
      "published_date": "2024-03-25 09:36:51 UTC",
      "updated_date": "2024-03-25 09:36:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:46:19.608700"
    },
    {
      "arxiv_id": "2403.16561v1",
      "title": "FedFixer: Mitigating Heterogeneous Label Noise in Federated Learning",
      "title_zh": "FedFixer：缓解联邦学习中异构标签噪声",
      "authors": [
        "Xinyuan Ji",
        "Zhaowei Zhu",
        "Wei Xi",
        "Olga Gadyatskaya",
        "Zilong Song",
        "Yong Cai",
        "Yang Liu"
      ],
      "abstract": "Federated Learning (FL) heavily depends on label quality for its performance.\nHowever, the label distribution among individual clients is always both noisy\nand heterogeneous. The high loss incurred by client-specific samples in\nheterogeneous label noise poses challenges for distinguishing between\nclient-specific and noisy label samples, impacting the effectiveness of\nexisting label noise learning approaches. To tackle this issue, we propose\nFedFixer, where the personalized model is introduced to cooperate with the\nglobal model to effectively select clean client-specific samples. In the dual\nmodels, updating the personalized model solely at a local level can lead to\noverfitting on noisy data due to limited samples, consequently affecting both\nthe local and global models' performance. To mitigate overfitting, we address\nthis concern from two perspectives. Firstly, we employ a confidence regularizer\nto alleviate the impact of unconfident predictions caused by label noise.\nSecondly, a distance regularizer is implemented to constrain the disparity\nbetween the personalized and global models. We validate the effectiveness of\nFedFixer through extensive experiments on benchmark datasets. The results\ndemonstrate that FedFixer can perform well in filtering noisy label samples on\ndifferent clients, especially in highly heterogeneous label noise scenarios.",
      "tldr_zh": "该研究针对 Federated Learning 中异质标签噪声（heterogeneous label noise）问题提出 FedFixer 框架，该框架通过引入个性化模型与全局模型合作，筛选出干净的客户端特定样本，从而缓解标签噪声对模型性能的影响。为防止个性化模型在本地更新时过拟合噪声数据，FedFixer 采用置信度正则化器（confidence regularizer）来减少不确定预测的影响，并使用距离正则化器（distance regularizer）来限制个性化模型与全局模型之间的差异。在基准数据集上的广泛实验证明，FedFixer 尤其在高度异质标签噪声场景中表现出色，能够有效过滤嘈杂标签样本并提升整体表现。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "accepted by AAA24",
      "pdf_url": "http://arxiv.org/pdf/2403.16561v1",
      "published_date": "2024-03-25 09:24:05 UTC",
      "updated_date": "2024-03-25 09:24:05 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:46:33.430743"
    },
    {
      "arxiv_id": "2403.16554v2",
      "title": "PE: A Poincare Explanation Method for Fast Text Hierarchy Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Qian Chen",
        "Dongyang Li",
        "Xiaofeng He",
        "Hongzhao Li",
        "Hongyu Yi"
      ],
      "abstract": "The black-box nature of deep learning models in NLP hinders their widespread\napplication. The research focus has shifted to Hierarchical Attribution (HA)\nfor its ability to model feature interactions. Recent works model\nnon-contiguous combinations with a time-costly greedy search in Eculidean\nspaces, neglecting underlying linguistic information in feature\nrepresentations. In this work, we introduce a novel method, namely Poincare\nExplanation (PE), for modeling feature interactions with hyperbolic spaces in a\ntime efficient manner. Specifically, we take building text hierarchies as\nfinding spanning trees in hyperbolic spaces. First we project the embeddings\ninto hyperbolic spaces to elicit inherit semantic and syntax hierarchical\nstructures. Then we propose a simple yet effective strategy to calculate\nShapley score. Finally we build the the hierarchy with proving the constructing\nprocess in the projected space could be viewed as building a minimum spanning\ntree and introduce a time efficient building algorithm. Experimental results\ndemonstrate the effectiveness of our approach.",
      "tldr_zh": "本文提出 Poincare Explanation (PE) 方法，利用双曲空间高效建模 NLP 中特征交互，以解决现有 Hierarchical Attribution (HA) 技术的耗时问题和忽略语言信息的局限。方法包括将嵌入投影到双曲空间以提取固有的语义和语法层次结构、计算 Shapley score 的简单策略，以及构建最小生成树作为文本层次结构，同时引入高效算法。实验结果表明，PE 方法在生成文本层次方面表现出色，证明了其有效性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16554v2",
      "published_date": "2024-03-25 09:04:14 UTC",
      "updated_date": "2024-06-12 11:17:47 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:46:46.639691"
    },
    {
      "arxiv_id": "2403.16552v2",
      "title": "QKFormer: Hierarchical Spiking Transformer using Q-K Attention",
      "title_zh": "QKFormer：使用 Q-K Attention 的层次化脉冲 Transformer",
      "authors": [
        "Chenlin Zhou",
        "Han Zhang",
        "Zhaokun Zhou",
        "Liutao Yu",
        "Liwei Huang",
        "Xiaopeng Fan",
        "Li Yuan",
        "Zhengyu Ma",
        "Huihui Zhou",
        "Yonghong Tian"
      ],
      "abstract": "Spiking Transformers, which integrate Spiking Neural Networks (SNNs) with\nTransformer architectures, have attracted significant attention due to their\npotential for energy efficiency and high performance. However, existing models\nin this domain still suffer from suboptimal performance. We introduce several\ninnovations to improve the performance: i) We propose a novel spike-form Q-K\nattention mechanism, tailored for SNNs, which efficiently models the importance\nof token or channel dimensions through binary vectors with linear complexity.\nii) We incorporate the hierarchical structure, which significantly benefits the\nperformance of both the brain and artificial neural networks, into spiking\ntransformers to obtain multi-scale spiking representation. iii) We design a\nversatile and powerful patch embedding module with a deformed shortcut\nspecifically for spiking transformers. Together, we develop QKFormer, a\nhierarchical spiking transformer based on Q-K attention with direct training.\nQKFormer shows significantly superior performance over existing\nstate-of-the-art SNN models on various mainstream datasets. Notably, with\ncomparable size to Spikformer (66.34 M, 74.81%), QKFormer (64.96 M) achieves a\ngroundbreaking top-1 accuracy of 85.65% on ImageNet-1k, substantially\noutperforming Spikformer by 10.84%. To our best knowledge, this is the first\ntime that directly training SNNs have exceeded 85% accuracy on ImageNet-1K. The\ncode and models are publicly available at\nhttps://github.com/zhouchenlin2096/QKFormer",
      "tldr_zh": "本研究提出 QKFormer，一种基于 Q-K Attention 的层次化 Spiking Transformer，旨在提升 Spiking Neural Networks (SNNs) 与 Transformer 架构的性能，以实现更高的能量效率。QKFormer 引入了 spike-form Q-K attention 机制（使用二进制向量高效建模 token 或 channel 的重要性）、层次化结构（获得多尺度 spiking 表示），以及一个专为 SNNs 设计的 patch embedding 模块，以支持直接训练。实验结果显示，QKFormer 在 ImageNet-1k 数据集上达到 85.65% 的 top-1 准确率，比 Spikformer 高出 10.84%，这是直接训练 SNNs 首次超过 85% 准确率，并在多种主流数据集上显著优于现有模型。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.CV"
      ],
      "primary_category": "cs.NE",
      "comment": "Accepted by NeurIPS 2024 (Spotlight). Code and Model:\n  https://github.com/zhouchenlin2096/QKFormer",
      "pdf_url": "http://arxiv.org/pdf/2403.16552v2",
      "published_date": "2024-03-25 08:57:27 UTC",
      "updated_date": "2024-10-08 09:29:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:46:58.834876"
    },
    {
      "arxiv_id": "2404.07968v1",
      "title": "AD-NEv++ : The multi-architecture neuroevolution-based multivariate anomaly detection framework",
      "title_zh": "翻译失败",
      "authors": [
        "Marcin Pietroń",
        "Dominik Żurek",
        "Kamil Faber",
        "Roberto Corizzo"
      ],
      "abstract": "Anomaly detection tools and methods enable key analytical capabilities in\nmodern cyberphysical and sensor-based systems. Despite the fast-paced\ndevelopment in deep learning architectures for anomaly detection, model\noptimization for a given dataset is a cumbersome and time-consuming process.\nNeuroevolution could be an effective and efficient solution to this problem, as\na fully automated search method for learning optimal neural networks,\nsupporting both gradient and non-gradient fine tuning. However, existing\nframeworks incorporating neuroevolution lack of support for new layers and\narchitectures and are typically limited to convolutional and LSTM layers. In\nthis paper we propose AD-NEv++, a three-stage neuroevolution-based method that\nsynergically combines subspace evolution, model evolution, and fine-tuning. Our\nmethod overcomes the limitations of existing approaches by optimizing the\nmutation operator in the neuroevolution process, while supporting a wide\nspectrum of neural layers, including attention, dense, and graph convolutional\nlayers. Our extensive experimental evaluation was conducted with widely adopted\nmultivariate anomaly detection benchmark datasets, and showed that the models\ngenerated by AD-NEv++ outperform well-known deep learning architectures and\nneuroevolution-based approaches for anomaly detection. Moreover, results show\nthat AD-NEv++ can improve and outperform the state-of-the-art GNN (Graph Neural\nNetworks) model architecture in all anomaly detection benchmarks.",
      "tldr_zh": "本论文提出 AD-NEv++，一个基于 neuroevolution 的多架构框架，用于多变量 anomaly detection，以简化深度学习模型在特定数据集上的优化过程。该框架采用三阶段方法，包括子空间进化、模型进化和发展微调，并优化突变操作符，支持多种神经层如 attention、dense 和 graph convolutional layers。实验结果显示，AD-NEv++ 在广泛采用的多变量异常检测基准数据集上，优于知名深度学习架构和现有 neuroevolution 方法，并在所有基准中超越最先进的 GNN 模型。",
      "categories": [
        "cs.NE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.NE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.07968v1",
      "published_date": "2024-03-25 08:40:58 UTC",
      "updated_date": "2024-03-25 08:40:58 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:47:08.830139"
    },
    {
      "arxiv_id": "2403.16543v1",
      "title": "Efficient Information Extraction in Few-Shot Relation Classification through Contrastive Representation Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Philipp Borchert",
        "Jochen De Weerdt",
        "Marie-Francine Moens"
      ],
      "abstract": "Differentiating relationships between entity pairs with limited labeled\ninstances poses a significant challenge in few-shot relation classification.\nRepresentations of textual data extract rich information spanning the domain,\nentities, and relations. In this paper, we introduce a novel approach to\nenhance information extraction combining multiple sentence representations and\ncontrastive learning. While representations in relation classification are\ncommonly extracted using entity marker tokens, we argue that substantial\ninformation within the internal model representations remains untapped. To\naddress this, we propose aligning multiple sentence representations, such as\nthe [CLS] token, the [MASK] token used in prompting, and entity marker tokens.\nOur method employs contrastive learning to extract complementary discriminative\ninformation from these individual representations. This is particularly\nrelevant in low-resource settings where information is scarce. Leveraging\nmultiple sentence representations is especially effective in distilling\ndiscriminative information for relation classification when additional\ninformation, like relation descriptions, are not available. We validate the\nadaptability of our approach, maintaining robust performance in scenarios that\ninclude relation descriptions, and showcasing its flexibility to adapt to\ndifferent resource constraints.",
      "tldr_zh": "本文提出了一种高效的信息提取方法，用于few-shot relation classification中区分实体对关系的挑战。该方法结合contrastive learning和多个句子表示（如[CLS] token、[MASK] token和entity marker tokens），通过对齐这些表示来提取互补的判别信息，从而在低资源设置下显著提升分类性能。实验结果显示，该方法在无额外信息（如关系描述）的情况下特别有效，同时保持了在不同资源约束场景中的适应性和鲁棒性。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "NAACL 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16543v1",
      "published_date": "2024-03-25 08:36:06 UTC",
      "updated_date": "2024-03-25 08:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:47:21.264258"
    },
    {
      "arxiv_id": "2403.16530v1",
      "title": "An Intermediate Fusion ViT Enables Efficient Text-Image Alignment in Diffusion Models",
      "title_zh": "翻译失败",
      "authors": [
        "Zizhao Hu",
        "Shaochong Jia",
        "Mohammad Rostami"
      ],
      "abstract": "Diffusion models have been widely used for conditional data cross-modal\ngeneration tasks such as text-to-image and text-to-video. However,\nstate-of-the-art models still fail to align the generated visual concepts with\nhigh-level semantics in a language such as object count, spatial relationship,\netc. We approach this problem from a multimodal data fusion perspective and\ninvestigate how different fusion strategies can affect vision-language\nalignment. We discover that compared to the widely used early fusion of\nconditioning text in a pretrained image feature space, a specially designed\nintermediate fusion can: (i) boost text-to-image alignment with improved\ngeneration quality and (ii) improve training and inference efficiency by\nreducing low-rank text-to-image attention calculations. We perform experiments\nusing a text-to-image generation task on the MS-COCO dataset. We compare our\nintermediate fusion mechanism with the classic early fusion mechanism on two\ncommon conditioning methods on a U-shaped ViT backbone. Our intermediate fusion\nmodel achieves a higher CLIP Score and lower FID, with 20% reduced FLOPs, and\n50% increased training speed compared to a strong U-ViT baseline with an early\nfusion.",
      "tldr_zh": "该研究探讨了扩散模型(Diffusion Models)在文本到图像生成任务中存在的视觉概念与文本高级语义（如物体数量和空间关系）对齐不足的问题，并从多模态数据融合角度提出一种中间融合(Intermediate Fusion)策略。相比于传统的早期融合(Early Fusion)，该策略使用U-shaped ViT骨干网，能够提升文本-图像对齐(Text-Image Alignment)，同时提高生成质量并减少低秩注意力计算，从而优化训练和推理效率。在MS-COCO数据集上的实验显示，该中间融合模型比基线模型CLIP Score更高、FID更低，同时FLOPs减少20%且训练速度提高50%。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16530v1",
      "published_date": "2024-03-25 08:16:06 UTC",
      "updated_date": "2024-03-25 08:16:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:47:33.797850"
    },
    {
      "arxiv_id": "2403.16527v2",
      "title": "Hallucination Detection in Foundation Models for Decision-Making: A Flexible Definition and Review of the State of the Art",
      "title_zh": "翻译失败",
      "authors": [
        "Neeloy Chakraborty",
        "Melkior Ornik",
        "Katherine Driggs-Campbell"
      ],
      "abstract": "Autonomous systems are soon to be ubiquitous, spanning manufacturing,\nagriculture, healthcare, entertainment, and other industries. Most of these\nsystems are developed with modular sub-components for decision-making,\nplanning, and control that may be hand-engineered or learning-based. While\nthese approaches perform well under the situations they were specifically\ndesigned for, they can perform especially poorly in out-of-distribution\nscenarios that will undoubtedly arise at test-time. The rise of foundation\nmodels trained on multiple tasks with impressively large datasets has led\nresearchers to believe that these models may provide \"common sense\" reasoning\nthat existing planners are missing, bridging the gap between algorithm\ndevelopment and deployment. While researchers have shown promising results in\ndeploying foundation models to decision-making tasks, these models are known to\nhallucinate and generate decisions that may sound reasonable, but are in fact\npoor. We argue there is a need to step back and simultaneously design systems\nthat can quantify the certainty of a model's decision, and detect when it may\nbe hallucinating. In this work, we discuss the current use cases of foundation\nmodels for decision-making tasks, provide a general definition for\nhallucinations with examples, discuss existing approaches to hallucination\ndetection and mitigation with a focus on decision problems, present guidelines,\nand explore areas for further research in this exciting field.",
      "tldr_zh": "这篇论文探讨了基础模型(foundation models)在决策任务中的幻觉(hallucination)检测问题，强调这些模型虽能提供“常识”推理，但可能在分布外场景下生成错误决策。作者提出一个灵活的幻觉定义，并审阅了现有检测和缓解方法，聚焦于决策问题的应用场景和量化不确定性策略。论文还提供了指导原则，并指出未来研究方向，以提升自主系统的可靠性和可信度。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.RO"
      ],
      "primary_category": "cs.AI",
      "comment": "Accepted to ACM Computing Surveys; 55 pages, 5 tables, 3 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16527v2",
      "published_date": "2024-03-25 08:11:02 UTC",
      "updated_date": "2025-02-11 17:40:41 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:47:44.189732"
    },
    {
      "arxiv_id": "2403.16524v2",
      "title": "Harnessing the power of LLMs for normative reasoning in MASs",
      "title_zh": "利用 LLMs 的力量在多智能体系统中进行规范推理",
      "authors": [
        "Bastin Tony Roy Savarimuthu",
        "Surangika Ranathunga",
        "Stephen Cranefield"
      ],
      "abstract": "Software agents, both human and computational, do not exist in isolation and\noften need to collaborate or coordinate with others to achieve their goals. In\nhuman society, social mechanisms such as norms ensure efficient functioning,\nand these techniques have been adopted by researchers in multi-agent systems\n(MAS) to create socially aware agents. However, traditional techniques have\nlimitations, such as operating in limited environments often using brittle\nsymbolic reasoning. The advent of Large Language Models (LLMs) offers a\npromising solution, providing a rich and expressive vocabulary for norms and\nenabling norm-capable agents that can perform a range of tasks such as norm\ndiscovery, normative reasoning and decision-making. This paper examines the\npotential of LLM-based agents to acquire normative capabilities, drawing on\nrecent Natural Language Processing (NLP) and LLM research. We present our\nvision for creating normative LLM agents. In particular, we discuss how the\nrecently proposed \"LLM agent\" approaches can be extended to implement such\nnormative LLM agents. We also highlight challenges in this emerging field. This\npaper thus aims to foster collaboration between MAS, NLP and LLM researchers in\norder to advance the field of normative agents.",
      "tldr_zh": "这篇论文探讨了如何利用大型语言模型(LLMs)提升多智能体系统(MASs)中的规范推理(normative reasoning)能力，以解决传统技术的局限性，如环境限制和符号推理的脆弱性。作者基于自然语言处理(NLP)和LLM研究，提出一种愿景：通过扩展现有的“LLM代理”方法，开发出具备规范能力的代理，用于规范发现、推理和决策。论文强调了这一领域的潜在挑战，并呼吁MAS、NLP和LLM研究者开展合作，以推进规范代理的发展。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "15 pages, 1 figure, presented at the COINE 2024 workshop at AAMAS\n  2024\n  (https://coin-workshop.github.io/coine-2024-auckland/accepted_papers.html).\n  This paper will appear in the post-proceedings of the COINE-2024 workshop",
      "pdf_url": "http://arxiv.org/pdf/2403.16524v2",
      "published_date": "2024-03-25 08:09:01 UTC",
      "updated_date": "2024-10-14 02:20:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:47:59.821926"
    },
    {
      "arxiv_id": "2403.16523v1",
      "title": "Causal Discovery from Poisson Branching Structural Causal Model Using High-Order Cumulant with Path Analysis",
      "title_zh": "翻译失败",
      "authors": [
        "Jie Qiao",
        "Yu Xiang",
        "Zhengming Chen",
        "Ruichu Cai",
        "Zhifeng Hao"
      ],
      "abstract": "Count data naturally arise in many fields, such as finance, neuroscience, and\nepidemiology, and discovering causal structure among count data is a crucial\ntask in various scientific and industrial scenarios. One of the most common\ncharacteristics of count data is the inherent branching structure described by\na binomial thinning operator and an independent Poisson distribution that\ncaptures both branching and noise. For instance, in a population count\nscenario, mortality and immigration contribute to the count, where survival\nfollows a Bernoulli distribution, and immigration follows a Poisson\ndistribution. However, causal discovery from such data is challenging due to\nthe non-identifiability issue: a single causal pair is Markov equivalent, i.e.,\n$X\\rightarrow Y$ and $Y\\rightarrow X$ are distributed equivalent. Fortunately,\nin this work, we found that the causal order from $X$ to its child $Y$ is\nidentifiable if $X$ is a root vertex and has at least two directed paths to\n$Y$, or the ancestor of $X$ with the most directed path to $X$ has a directed\npath to $Y$ without passing $X$. Specifically, we propose a Poisson Branching\nStructure Causal Model (PB-SCM) and perform a path analysis on PB-SCM using\nhigh-order cumulants. Theoretical results establish the connection between the\npath and cumulant and demonstrate that the path information can be obtained\nfrom the cumulant. With the path information, causal order is identifiable\nunder some graphical conditions. A practical algorithm for learning causal\nstructure under PB-SCM is proposed and the experiments demonstrate and verify\nthe effectiveness of the proposed method.",
      "tldr_zh": "本研究针对计数数据（如金融、神经科学中的数据）的因果发现问题，提出了Poisson Branching Structural Causal Model (PB-SCM)，该模型使用二项式稀释算子(binomial thinning operator)和独立Poisson distribution来捕捉数据的分支结构和噪声。作者通过高阶累积量(high-order cumulant)进行路径分析，建立了路径信息与累积量的理论联系，并在特定图形条件下（如根节点X有至少两条路径到Y）实现了因果顺序的可识别性。实验结果验证了该方法的有效性，为计数数据的因果结构学习提供了实用算法。",
      "categories": [
        "stat.ML",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "stat.ML",
      "comment": "Accepted by AAAI-2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16523v1",
      "published_date": "2024-03-25 08:06:08 UTC",
      "updated_date": "2024-03-25 08:06:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:48:11.228917"
    },
    {
      "arxiv_id": "2403.16512v5",
      "title": "LLMs Are Few-Shot In-Context Low-Resource Language Learners",
      "title_zh": "翻译失败",
      "authors": [
        "Samuel Cahyawijaya",
        "Holy Lovenia",
        "Pascale Fung"
      ],
      "abstract": "In-context learning (ICL) empowers large language models (LLMs) to perform\ndiverse tasks in underrepresented languages using only short in-context\ninformation, offering a crucial avenue for narrowing the gap between\nhigh-resource and low-resource languages. Nonetheless, there is only a handful\nof works explored ICL for low-resource languages with most of them focusing on\nrelatively high-resource languages, such as French and Spanish. In this work,\nwe extensively study ICL and its cross-lingual variation (X-ICL) on 25\nlow-resource and 7 relatively higher-resource languages. Our study not only\nassesses the effectiveness of ICL with LLMs in low-resource languages but also\nidentifies the shortcomings of in-context label alignment, and introduces a\nmore effective alternative: query alignment. Moreover, we provide valuable\ninsights into various facets of ICL for low-resource languages. Our study\nconcludes the significance of few-shot in-context information on enhancing the\nlow-resource understanding quality of LLMs through semantically relevant\ninformation by closing the language gap in the target language and aligning the\nsemantics between the targeted low-resource and the high-resource language that\nthe model is proficient in. Our work highlights the importance of advancing ICL\nresearch, particularly for low-resource languages. Our code is publicly\nreleased at https://github.com/SamuelCahyawijaya/in-context-alignment",
      "tldr_zh": "这篇论文探讨了大型语言模型 (LLMs) 通过少样本 In-Context Learning (ICL) 在低资源语言中的学习能力，旨在缩小高资源语言与低资源语言的差距。研究对 25 种低资源语言和 7 种相对高资源语言进行了广泛实验，评估了 ICL 及其跨语言变体 (X-ICL) 的有效性，并指出了 in-context label alignment 的缺点，同时引入了更有效的替代方案：query alignment。结果显示，通过语义相关信息的少样本输入，LLMs 能显著提升对低资源语言的理解，并通过语义对齐缩小语言差距。该工作强调了推进 ICL 研究的重要性，并公开了相关代码。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16512v5",
      "published_date": "2024-03-25 07:55:29 UTC",
      "updated_date": "2024-06-25 11:54:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:48:24.954095"
    },
    {
      "arxiv_id": "2403.16508v1",
      "title": "Return to Tradition: Learning Reliable Heuristics with Classical Machine Learning",
      "title_zh": "翻译失败",
      "authors": [
        "Dillon Z. Chen",
        "Felipe Trevizan",
        "Sylvie Thiébaux"
      ],
      "abstract": "Current approaches for learning for planning have yet to achieve competitive\nperformance against classical planners in several domains, and have poor\noverall performance. In this work, we construct novel graph representations of\nlifted planning tasks and use the WL algorithm to generate features from them.\nThese features are used with classical machine learning methods which have up\nto 2 orders of magnitude fewer parameters and train up to 3 orders of magnitude\nfaster than the state-of-the-art deep learning for planning models. Our novel\napproach, WL-GOOSE, reliably learns heuristics from scratch and outperforms the\n$h^{\\text{FF}}$ heuristic in a fair competition setting. It also outperforms or\nties with LAMA on 4 out of 10 domains on coverage and 7 out of 10 domains on\nplan quality. WL-GOOSE is the first learning for planning model which achieves\nthese feats. Furthermore, we study the connections between our novel WL feature\ngeneration method, previous theoretically flavoured learning architectures, and\nDescription Logic Features for planning.",
      "tldr_zh": "本文提出了一种名为 WL-GOOSE 的新方法，通过构建图表示并使用 WL algorithm 生成特征，与经典机器学习方法结合，来学习可靠的启发式(heuristics)用于规划任务。这种方法参数减少多达2个数量级，训练速度快3个数量级以上，比现有深度学习模型更高效。实验结果显示，WL-GOOSE 在公平竞争中优于 $h^{\\text{FF}}$ 启发式，并在10个领域中，在覆盖率上胜过或平局 LAMA 的4个领域，在计划质量上胜过或平局7个领域。此外，该方法首次实现这些性能，并探讨了其与理论相关架构和 Description Logic Features 的联系。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "Extended version of ICAPS 2024 paper",
      "pdf_url": "http://arxiv.org/pdf/2403.16508v1",
      "published_date": "2024-03-25 07:47:52 UTC",
      "updated_date": "2024-03-25 07:47:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:48:36.772945"
    },
    {
      "arxiv_id": "2403.16501v3",
      "title": "Learning To Guide Human Decision Makers With Vision-Language Models",
      "title_zh": "使用",
      "authors": [
        "Debodeep Banerjee",
        "Stefano Teso",
        "Burcu Sayin",
        "Andrea Passerini"
      ],
      "abstract": "There is increasing interest in developing AIs for assisting human\ndecision-making in high-stakes tasks, such as medical diagnosis, for the\npurpose of improving decision quality and reducing cognitive strain. Mainstream\napproaches team up an expert with a machine learning model to which safer\ndecisions are offloaded, thus letting the former focus on cases that demand\ntheir attention. his separation of responsibilities setup, however, is\ninadequate for high-stakes scenarios. On the one hand, the expert may end up\nover-relying on the machine's decisions due to anchoring bias, thus losing the\nhuman oversight that is increasingly being required by regulatory agencies to\nensure trustworthy AI. On the other hand, the expert is left entirely\nunassisted on the (typically hardest) decisions on which the model abstained.\nAs a remedy, we introduce learning to guide (LTG), an alternative framework in\nwhich - rather than taking control from the human expert - the machine provides\nguidance useful for decision making, and the human is entirely responsible for\ncoming up with a decision. In order to ensure guidance is interpretable} and\ntask-specific, we develop SLOG, an approach for turning any vision-language\nmodel into a capable generator of textual guidance by leveraging a modicum of\nhuman feedback. Our empirical evaluation highlights the promise of \\method on a\nchallenging, real-world medical diagnosis task.",
      "tldr_zh": "这篇论文探讨了使用视觉语言模型(Vision-Language Models)辅助人类决策的问题，特别是高风险任务如医疗诊断，以提升决策质量并减轻认知负担。传统方法将决策责任分离给AI，可能导致人类过度依赖（anchoring bias）或在AI弃权时完全无人协助。为解决这些问题，论文提出Learning to Guide (LTG)框架，让AI提供可解释的任务特定文本指导，而人类负责最终决策。作者开发了SLOG方法，通过少量人类反馈，将视觉语言模型转化为有效的指导生成器，并在真实医疗诊断任务上展示了LTG的显著潜力。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16501v3",
      "published_date": "2024-03-25 07:34:42 UTC",
      "updated_date": "2025-01-22 10:21:50 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:48:46.345873"
    },
    {
      "arxiv_id": "2403.16495v1",
      "title": "LSTTN: A Long-Short Term Transformer-based Spatio-temporal Neural Network for Traffic Flow Forecasting",
      "title_zh": "LSTTN：一种基于长短期 Transformer 的时空神经网络，用于交通流量预测",
      "authors": [
        "Qinyao Luo",
        "Silu He",
        "Xing Han",
        "Yuhan Wang",
        "Haifeng Li"
      ],
      "abstract": "Accurate traffic forecasting is a fundamental problem in intelligent\ntransportation systems and learning long-range traffic representations with key\ninformation through spatiotemporal graph neural networks (STGNNs) is a basic\nassumption of current traffic flow prediction models. However, due to\nstructural limitations, existing STGNNs can only utilize short-range traffic\nflow data; therefore, the models cannot adequately learn the complex trends and\nperiodic features in traffic flow. Besides, it is challenging to extract the\nkey temporal information from the long historical traffic series and obtain a\ncompact representation. To solve the above problems, we propose a novel LSTTN\n(Long-Short Term Transformer-based Network) framework comprehensively\nconsidering the long- and short-term features in historical traffic flow.\nFirst, we employ a masked subseries Transformer to infer the content of masked\nsubseries from a small portion of unmasked subseries and their temporal context\nin a pretraining manner, forcing the model to efficiently learn compressed and\ncontextual subseries temporal representations from long historical series.\nThen, based on the learned representations, long-term trend is extracted by\nusing stacked 1D dilated convolution layers, and periodic features are\nextracted by dynamic graph convolution layers. For the difficulties in making\ntime-step level prediction, LSTTN adopts a short-term trend extractor to learn\nfine-grained short-term temporal features. Finally, LSTTN fuses the long-term\ntrend, periodic features and short-term features to obtain the prediction\nresults. Experiments on four real-world datasets show that in 60-minute-ahead\nlong-term forecasting, the LSTTN model achieves a minimum improvement of 5.63\\%\nand a maximum improvement of 16.78\\% over baseline models. The source code is\navailable at https://github.com/GeoX-Lab/LSTTN.",
      "tldr_zh": "该研究针对交通流量预测中的问题，提出了一种基于 Transformer 的 LSTTN（Long-Short Term Transformer-based Network）框架，以解决现有 STGNNs（时空图神经网络）无法有效处理长历史序列、提取复杂趋势和周期特征的局限性。\nLSTTN 首先使用 masked subseries Transformer 在预训练中从长历史序列中学习压缩的子序列表示，然后通过堆叠 1D 膨胀卷积层提取长程趋势、动态图卷积层提取周期特征，以及短期趋势提取器学习细粒度短期时间特征，最后融合这些特征进行预测。\n实验结果显示，在四个真实数据集上，该模型在 60 分钟提前预测中比基线模型至少改善 5.63%，最高达 16.78%。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.SI"
      ],
      "primary_category": "cs.LG",
      "comment": "15 pages, 10 figures, 6 tables",
      "pdf_url": "http://arxiv.org/pdf/2403.16495v1",
      "published_date": "2024-03-25 07:23:23 UTC",
      "updated_date": "2024-03-25 07:23:23 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:48:59.244937"
    },
    {
      "arxiv_id": "2403.16460v2",
      "title": "FedAC: An Adaptive Clustered Federated Learning Framework for Heterogeneous Data",
      "title_zh": "Fed",
      "authors": [
        "Yuxin Zhang",
        "Haoyu Chen",
        "Zheng Lin",
        "Zhe Chen",
        "Jin Zhao"
      ],
      "abstract": "Clustered federated learning (CFL) is proposed to mitigate the performance\ndeterioration stemming from data heterogeneity in federated learning (FL) by\ngrouping similar clients for cluster-wise model training. However, current CFL\nmethods struggle due to inadequate integration of global and intra-cluster\nknowledge and the absence of an efficient online model similarity metric, while\ntreating the cluster count as a fixed hyperparameter limits flexibility and\nrobustness. In this paper, we propose an adaptive CFL framework, named FedAC,\nwhich (1) efficiently integrates global knowledge into intra-cluster learning\nby decoupling neural networks and utilizing distinct aggregation methods for\neach submodule, significantly enhancing performance; (2) includes a\ncosteffective online model similarity metric based on dimensionality reduction;\n(3) incorporates a cluster number fine-tuning module for improved adaptability\nand scalability in complex, heterogeneous environments. Extensive experiments\nshow that FedAC achieves superior empirical performance, increasing the test\naccuracy by around 1.82% and 12.67% on CIFAR-10 and CIFAR-100 datasets,\nrespectively, under different non-IID settings compared to SOTA methods.",
      "tldr_zh": "该论文提出 FedAC，一种适应性的集群联邦学习 (CFL) 框架，旨在解决传统联邦学习 (FL) 中数据异质性导致的性能下降问题，通过高效整合全局知识和集群内学习。FedAC 的关键方法包括解耦神经网络以采用不同的聚合策略、引入基于降维的成本有效在线模型相似性指标，以及添加集群数量微调模块，以提升框架的灵活性和可扩展性。在实验中，FedAC 在 CIFAR-10 和 CIFAR-100 数据集的非-IID 设置下，比现有最先进方法提高了约 1.82% 和 12.67% 的测试准确率。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.DC"
      ],
      "primary_category": "cs.LG",
      "comment": "14 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16460v2",
      "published_date": "2024-03-25 06:43:28 UTC",
      "updated_date": "2024-03-29 08:46:16 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:49:12.018128"
    },
    {
      "arxiv_id": "2403.16451v4",
      "title": "DeepMachining: Online Prediction of Machining Errors of Lathe Machines",
      "title_zh": "翻译失败",
      "authors": [
        "Xiang-Li Lu",
        "Hwai-Jung Hsu",
        "Che-Wei Chou",
        "H. T. Kung",
        "Chen-Hsin Lee",
        "Sheng-Mao Cheng"
      ],
      "abstract": "We describe DeepMachining, a deep learning-based AI system for online\nprediction of machining errors of lathe machine operations. We have built and\nevaluated DeepMachining based on manufacturing data from factories.\nSpecifically, we first pretrain a deep learning model for a given lathe\nmachine's operations to learn the salient features of machining states. Then,\nwe fine-tune the pretrained model to adapt to specific machining tasks. We\ndemonstrate that DeepMachining achieves high prediction accuracy for multiple\ntasks that involve different workpieces and cutting tools. To the best of our\nknowledge, this work is one of the first factory experiments using pre-trained\ndeep-learning models to predict machining errors of lathe machines.",
      "tldr_zh": "本研究介绍了 DeepMachining，一种基于 deep learning 的 AI 系统，用于在线预测车床加工错误。该系统利用工厂制造数据，首先对车床操作进行预训练（pretrain）以学习关键特征，然后微调（fine-tune）模型以适应特定加工任务。实验结果显示，DeepMachining 在涉及不同工件和切削工具的多任务上实现了高预测准确率，这也是首次在工厂环境中使用预训练深度学习模型来预测车床加工错误。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16451v4",
      "published_date": "2024-03-25 06:30:54 UTC",
      "updated_date": "2024-03-28 11:36:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:49:23.608620"
    },
    {
      "arxiv_id": "2403.16443v1",
      "title": "CodeS: Natural Language to Code Repository via Multi-Layer Sketch",
      "title_zh": "翻译失败",
      "authors": [
        "Daoguang Zan",
        "Ailun Yu",
        "Wei Liu",
        "Dong Chen",
        "Bo Shen",
        "Wei Li",
        "Yafen Yao",
        "Yongshun Gong",
        "Xiaolin Chen",
        "Bei Guan",
        "Zhiguang Yang",
        "Yongji Wang",
        "Qianxiang Wang",
        "Lizhen Cui"
      ],
      "abstract": "The impressive performance of large language models (LLMs) on code-related\ntasks has shown the potential of fully automated software development. In light\nof this, we introduce a new software engineering task, namely Natural Language\nto code Repository (NL2Repo). This task aims to generate an entire code\nrepository from its natural language requirements. To address this task, we\npropose a simple yet effective framework CodeS, which decomposes NL2Repo into\nmultiple sub-tasks by a multi-layer sketch. Specifically, CodeS includes three\nmodules: RepoSketcher, FileSketcher, and SketchFiller. RepoSketcher first\ngenerates a repository's directory structure for given requirements;\nFileSketcher then generates a file sketch for each file in the generated\nstructure; SketchFiller finally fills in the details for each function in the\ngenerated file sketch. To rigorously assess CodeS on the NL2Repo task, we carry\nout evaluations through both automated benchmarking and manual feedback\nanalysis. For benchmark-based evaluation, we craft a repository-oriented\nbenchmark, SketchEval, and design an evaluation metric, SketchBLEU. For\nfeedback-based evaluation, we develop a VSCode plugin for CodeS and engage 30\nparticipants in conducting empirical studies. Extensive experiments prove the\neffectiveness and practicality of CodeS on the NL2Repo task.",
      "tldr_zh": "该论文引入了NL2Repo任务，即从自然语言需求生成整个代码仓库，以实现全自动软件开发。作者提出CodeS框架，通过多层草图方法将任务分解为三个模块：RepoSketcher生成仓库目录结构、FileSketcher为每个文件创建草图，以及SketchFiller填充函数细节。实验评估包括自动基准测试（如SketchEval基准和SketchBLEU指标）和手动反馈分析（通过VSCode插件和30名参与者的实证研究），证明了CodeS在NL2Repo任务上的有效性和实用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.SE"
      ],
      "primary_category": "cs.CL",
      "comment": "https://github.com/NL2Code/CodeS",
      "pdf_url": "http://arxiv.org/pdf/2403.16443v1",
      "published_date": "2024-03-25 06:09:55 UTC",
      "updated_date": "2024-03-25 06:09:55 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:49:34.125063"
    },
    {
      "arxiv_id": "2403.16432v3",
      "title": "$\\textit{LinkPrompt}$: Natural and Universal Adversarial Attacks on Prompt-based Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Yue Xu",
        "Wenjie Wang"
      ],
      "abstract": "Prompt-based learning is a new language model training paradigm that adapts\nthe Pre-trained Language Models (PLMs) to downstream tasks, which revitalizes\nthe performance benchmarks across various natural language processing (NLP)\ntasks. Instead of using a fixed prompt template to fine-tune the model, some\nresearch demonstrates the effectiveness of searching for the prompt via\noptimization. Such prompt optimization process of prompt-based learning on PLMs\nalso gives insight into generating adversarial prompts to mislead the model,\nraising concerns about the adversarial vulnerability of this paradigm. Recent\nstudies have shown that universal adversarial triggers (UATs) can be generated\nto alter not only the predictions of the target PLMs but also the prediction of\ncorresponding Prompt-based Fine-tuning Models (PFMs) under the prompt-based\nlearning paradigm. However, UATs found in previous works are often unreadable\ntokens or characters and can be easily distinguished from natural texts with\nadaptive defenses. In this work, we consider the naturalness of the UATs and\ndevelop $\\textit{LinkPrompt}$, an adversarial attack algorithm to generate UATs\nby a gradient-based beam search algorithm that not only effectively attacks the\ntarget PLMs and PFMs but also maintains the naturalness among the trigger\ntokens. Extensive results demonstrate the effectiveness of\n$\\textit{LinkPrompt}$, as well as the transferability of UATs generated by\n$\\textit{LinkPrompt}$ to open-sourced Large Language Model (LLM) Llama2 and\nAPI-accessed LLM GPT-3.5-turbo. The resource is available at\n$\\href{https://github.com/SavannahXu79/LinkPrompt}{https://github.com/SavannahXu79/LinkPrompt}$.",
      "tldr_zh": "本研究探讨了基于提示的语言模型（Prompt-based learning）在预训练语言模型（PLMs）上的对抗性漏洞，提出了一种新的攻击算法 $\\textit{LinkPrompt}$，利用梯度-based beam search 生成自然且通用的对抗触发器（UATs）。$\\textit{LinkPrompt}$ 不仅能有效误导目标 PLMs 和提示微调模型（PFMs），还确保触发器在文本中保持自然性，避免易被检测。实验结果显示，该算法在多种场景下表现出色，并证明了其生成的 UATs 具有转移性，能够攻击开源大语言模型（LLM）如 Llama2 和 API 访问模型如 GPT-3.5-turbo，从而凸显了提示-based 学习范式的安全风险。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted to the main conference of NAACL2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16432v3",
      "published_date": "2024-03-25 05:27:35 UTC",
      "updated_date": "2024-04-09 13:05:49 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:49:46.810176"
    },
    {
      "arxiv_id": "2403.16431v1",
      "title": "DOCTR: Disentangled Object-Centric Transformer for Point Scene Understanding",
      "title_zh": "翻译失败",
      "authors": [
        "Xiaoxuan Yu",
        "Hao Wang",
        "Weiming Li",
        "Qiang Wang",
        "Soonyong Cho",
        "Younghun Sung"
      ],
      "abstract": "Point scene understanding is a challenging task to process real-world scene\npoint cloud, which aims at segmenting each object, estimating its pose, and\nreconstructing its mesh simultaneously. Recent state-of-the-art method first\nsegments each object and then processes them independently with multiple stages\nfor the different sub-tasks. This leads to a complex pipeline to optimize and\nmakes it hard to leverage the relationship constraints between multiple\nobjects. In this work, we propose a novel Disentangled Object-Centric\nTRansformer (DOCTR) that explores object-centric representation to facilitate\nlearning with multiple objects for the multiple sub-tasks in a unified manner.\nEach object is represented as a query, and a Transformer decoder is adapted to\niteratively optimize all the queries involving their relationship. In\nparticular, we introduce a semantic-geometry disentangled query (SGDQ) design\nthat enables the query features to attend separately to semantic information\nand geometric information relevant to the corresponding sub-tasks. A hybrid\nbipartite matching module is employed to well use the supervisions from all the\nsub-tasks during training. Qualitative and quantitative experimental results\ndemonstrate that our method achieves state-of-the-art performance on the\nchallenging ScanNet dataset. Code is available at\nhttps://github.com/SAITPublic/DOCTR.",
      "tldr_zh": "本研究针对点云场景理解任务（包括对象分割、姿态估计和网格重建）提出了一种新型Disentangled Object-Centric Transformer（DOCTR）框架，以统一处理多个对象及其子任务，避免传统多阶段管道的复杂性和对象间关系缺失。DOCTR使用对象为中心表示，每个对象作为查询，通过Transformer解码器迭代优化查询特征，并引入semantic-geometry disentangled query (SGDQ)设计，使查询分别关注语义和几何信息，同时采用hybrid bipartite matching模块增强训练监督。实验结果显示，该方法在ScanNet数据集上实现了最先进性能，证明了其在处理真实世界点云场景时的有效性。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16431v1",
      "published_date": "2024-03-25 05:22:34 UTC",
      "updated_date": "2024-03-25 05:22:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:50:01.444759"
    },
    {
      "arxiv_id": "2403.16427v4",
      "title": "Re2LLM: Reflective Reinforcement Large Language Model for Session-based Recommendation",
      "title_zh": "翻译失败",
      "authors": [
        "Ziyan Wang",
        "Yingpeng Du",
        "Zhu Sun",
        "Haoyan Chua",
        "Kaidong Feng",
        "Wenya Wang",
        "Jie Zhang"
      ],
      "abstract": "Large Language Models (LLMs) are emerging as promising approaches to enhance\nsession-based recommendation (SBR), where both prompt-based and\nfine-tuning-based methods have been widely investigated to align LLMs with SBR.\nHowever, the former methods struggle with optimal prompts to elicit the correct\nreasoning of LLMs due to the lack of task-specific feedback, leading to\nunsatisfactory recommendations. Although the latter methods attempt to\nfine-tune LLMs with domain-specific knowledge, they face limitations such as\nhigh computational costs and reliance on open-source backbones. To address such\nissues, we propose a Reflective Reinforcement Large Language Model (Re2LLM) for\nSBR, guiding LLMs to focus on specialized knowledge essential for more accurate\nrecommendations effectively and efficiently. In particular, we first design the\nReflective Exploration Module to effectively extract knowledge that is readily\nunderstandable and digestible by LLMs. To be specific, we direct LLMs to\nexamine recommendation errors through self-reflection and construct a knowledge\nbase (KB) comprising hints capable of rectifying these errors. To efficiently\nelicit the correct reasoning of LLMs, we further devise the Reinforcement\nUtilization Module to train a lightweight retrieval agent. It learns to select\nhints from the constructed KB based on the task-specific feedback, where the\nhints can serve as guidance to help correct LLMs reasoning for better\nrecommendations. Extensive experiments on multiple real-world datasets\ndemonstrate that our method consistently outperforms state-of-the-art methods.",
      "tldr_zh": "这篇论文提出了 Re2LLM，一种 Reflective Reinforcement Large Language Model，用于提升 Session-based Recommendation (SBR) 的性能，通过结合自省和强化学习来解决现有 prompt-based 和 fine-tuning-based 方法的局限性。Re2LLM 包括 Reflective Exploration Module，用于通过自省分析推荐错误并构建包含纠正提示的 Knowledge Base (KB)，以及 Reinforcement Utilization Module，用于训练轻量级检索代理根据任务特定反馈选择提示，从而指导 LLMs 进行更准确的推理。实验结果显示，在多个真实数据集上，Re2LLM  consistently outperforms state-of-the-art 方法。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 4 figures",
      "pdf_url": "http://arxiv.org/pdf/2403.16427v4",
      "published_date": "2024-03-25 05:12:18 UTC",
      "updated_date": "2024-04-19 16:26:57 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:50:14.027385"
    },
    {
      "arxiv_id": "2403.16424v3",
      "title": "An Experiment with the Use of ChatGPT for LCSH Subject Assignment on Electronic Theses and Dissertations",
      "title_zh": "翻译失败",
      "authors": [
        "Eric H. C. Chow",
        "TJ Kao",
        "Xiaoli Li"
      ],
      "abstract": "This study delves into the potential use of large language models (LLMs) for\ngenerating Library of Congress Subject Headings (LCSH). The authors employed\nChatGPT to generate subject headings for electronic theses and dissertations\n(ETDs) based on their titles and abstracts. The results suggests that LLMs such\nas ChatGPT have the potential to reduce cataloging time needed for assigning\nLCSH subject terms for ETDs as well as to improve the discovery of this type of\nresource in academic libraries. Nonetheless, human catalogers remain essential\nfor verifying and enhancing the validity, exhaustivity, and specificity of LCSH\ngenerated by LLMs.",
      "tldr_zh": "这篇论文实验性地使用大型语言模型 (LLMs) 如 ChatGPT，基于电子学位论文 (ETDs) 的标题和摘要生成 Library of Congress Subject Headings (LCSH)。结果表明，ChatGPT 可以显著减少编目时间并提升 ETDs 在学术图书馆中的发现率。然而，研究强调，人类编目员仍需介入，以验证和改进 LLMs 生成的 LCSH 在有效性、详尽性和具体性方面的不足。总的来说，这为图书馆自动化提供了潜在应用，但突出了人机协作的重要性。",
      "categories": [
        "cs.AI",
        "cs.DL",
        "cs.IR"
      ],
      "primary_category": "cs.AI",
      "comment": "23 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.16424v3",
      "published_date": "2024-03-25 05:04:52 UTC",
      "updated_date": "2024-07-10 07:14:32 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:50:24.990701"
    },
    {
      "arxiv_id": "2403.16422v2",
      "title": "Refining Text-to-Image Generation: Towards Accurate Training-Free Glyph-Enhanced Image Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Sanyam Lakhanpal",
        "Shivang Chopra",
        "Vinija Jain",
        "Aman Chadha",
        "Man Luo"
      ],
      "abstract": "Over the past few years, Text-to-Image (T2I) generation approaches based on\ndiffusion models have gained significant attention. However, vanilla diffusion\nmodels often suffer from spelling inaccuracies in the text displayed within the\ngenerated images. The capability to generate visual text is crucial, offering\nboth academic interest and a wide range of practical applications. To produce\naccurate visual text images, state-of-the-art techniques adopt a\nglyph-controlled image generation approach, consisting of a text layout\ngenerator followed by an image generator that is conditioned on the generated\ntext layout. Nevertheless, our study reveals that these models still face three\nprimary challenges, prompting us to develop a testbed to facilitate future\nresearch. We introduce a benchmark, LenCom-Eval, specifically designed for\ntesting models' capability in generating images with Lengthy and Complex visual\ntext. Subsequently, we introduce a training-free framework to enhance the\ntwo-stage generation approaches. We examine the effectiveness of our approach\non both LenCom-Eval and MARIO-Eval benchmarks and demonstrate notable\nimprovements across a range of evaluation metrics, including CLIPScore, OCR\nprecision, recall, F1 score, accuracy, and edit distance scores. For instance,\nour proposed framework improves the backbone model, TextDiffuser, by more than\n23\\% and 13.5\\% in terms of OCR word F1 on LenCom-Eval and MARIO-Eval,\nrespectively. Our work makes a unique contribution to the field by focusing on\ngenerating images with long and rare text sequences, a niche previously\nunexplored by existing literature",
      "tldr_zh": "本论文探讨了基于扩散模型的 Text-to-Image (T2I) 生成中视觉文字拼写不准确的问题，并引入 LenCom-Eval 基准来评估模型处理长而复杂文字的能力。研究团队提出一个无训练（training-free）框架，增强两阶段的 glyph-controlled 生成方法，包括文本布局生成器和条件图像生成器，以提高生成准确性。在 LenCom-Eval 和 MARIO-Eval 基准测试中，该框架显著提升了多种指标，如 CLIPScore 和 OCR 精确度、召回率、F1 分数等，例如使 TextDiffuser 的 OCR 词 F1 分数分别提高超过 23% 和 13.5%。这项工作首次专注于生成包含长和稀有文本序列的图像，为 T2I 生成领域提供了新的研究方向。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "Accepted at WACV 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.16422v2",
      "published_date": "2024-03-25 04:54:49 UTC",
      "updated_date": "2024-10-28 22:11:08 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:50:39.652846"
    },
    {
      "arxiv_id": "2404.00045v2",
      "title": "Policy Optimization finds Nash Equilibrium in Regularized General-Sum LQ Games",
      "title_zh": "翻译失败",
      "authors": [
        "Muhammad Aneeq uz Zaman",
        "Shubham Aggarwal",
        "Melih Bastopcu",
        "Tamer Başar"
      ],
      "abstract": "In this paper, we investigate the impact of introducing relative entropy\nregularization on the Nash Equilibria (NE) of General-Sum $N$-agent games,\nrevealing the fact that the NE of such games conform to linear Gaussian\npolicies. Moreover, it delineates sufficient conditions, contingent upon the\nadequacy of entropy regularization, for the uniqueness of the NE within the\ngame. As Policy Optimization serves as a foundational approach for\nReinforcement Learning (RL) techniques aimed at finding the NE, in this work we\nprove the linear convergence of a policy optimization algorithm which (subject\nto the adequacy of entropy regularization) is capable of provably attaining the\nNE. Furthermore, in scenarios where the entropy regularization proves\ninsufficient, we present a $\\delta$-augmentation technique, which facilitates\nthe achievement of an $\\epsilon$-NE within the game.",
      "tldr_zh": "本文研究了在Regularized General-Sum N-agent games中引入relative entropy regularization对Nash Equilibrium (NE)的影响，发现NE符合linear Gaussian policies，并给出了熵正则化充足条件下NE唯一性的充分条件。论文证明了Policy Optimization算法在这些条件下具有线性收敛性，能够可靠地找到NE。作为补充，当熵正则化不足时，提出δ-augmentation技术，以实现ε-NE，从而提升算法的鲁棒性。",
      "categories": [
        "cs.GT",
        "cs.AI",
        "cs.LG",
        "cs.MA"
      ],
      "primary_category": "cs.GT",
      "comment": "Accepted for Conference on Decision and Control 2024",
      "pdf_url": "http://arxiv.org/pdf/2404.00045v2",
      "published_date": "2024-03-25 04:45:28 UTC",
      "updated_date": "2024-09-13 16:59:00 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:50:48.265053"
    },
    {
      "arxiv_id": "2403.16418v2",
      "title": "An Incremental MaxSAT-based Model to Learn Interpretable and Balanced Classification Rules",
      "title_zh": "翻译失败",
      "authors": [
        "Antônio Carlos Souza Ferreira Júnior",
        "Thiago Alves Rocha"
      ],
      "abstract": "The increasing advancements in the field of machine learning have led to the\ndevelopment of numerous applications that effectively address a wide range of\nproblems with accurate predictions. However, in certain cases, accuracy alone\nmay not be sufficient. Many real-world problems also demand explanations and\ninterpretability behind the predictions. One of the most popular interpretable\nmodels that are classification rules. This work aims to propose an incremental\nmodel for learning interpretable and balanced rules based on MaxSAT, called\nIMLIB. This new model was based on two other approaches, one based on SAT and\nthe other on MaxSAT. The one based on SAT limits the size of each generated\nrule, making it possible to balance them. We suggest that such a set of rules\nseem more natural to be understood compared to a mixture of large and small\nrules. The approach based on MaxSAT, called IMLI, presents a technique to\nincrease performance that involves learning a set of rules by incrementally\napplying the model in a dataset. Finally, IMLIB and IMLI are compared using\ndiverse databases. IMLIB obtained results comparable to IMLI in terms of\naccuracy, generating more balanced rules with smaller sizes.",
      "tldr_zh": "该研究针对机器学习模型的可解释性问题，提出了一种基于 MaxSAT 的增量模型 IMLIB，用于学习可解释且平衡的分类规则。IMLIB 结合了先前基于 SAT 的规则大小限制方法和基于 MaxSAT 的 IMLI 增量学习技术，从而生成大小均匀、更易理解的规则集。与 IMLI 相比，IMLIB 在多种数据库上的准确性相当，但规则更平衡且规模更小。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "cs.LO",
        "I.2.4; I.2.6"
      ],
      "primary_category": "cs.LG",
      "comment": "16 pages, 5 tables, submitted to BRACIS 2023 (Brazilian Conference on\n  Intelligent Systems), accepted version published in Intelligent Systems,\n  LNCS, vol 14195",
      "pdf_url": "http://arxiv.org/pdf/2403.16418v2",
      "published_date": "2024-03-25 04:43:47 UTC",
      "updated_date": "2024-04-29 13:00:21 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:51:00.473831"
    },
    {
      "arxiv_id": "2403.16416v1",
      "title": "How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation",
      "title_zh": "你的模拟器有多可靠？ 当前基于LLM的用户模拟器在对话式推荐中的局限性分析",
      "authors": [
        "Lixi Zhu",
        "Xiaowen Huang",
        "Jitao Sang"
      ],
      "abstract": "Conversational Recommender System (CRS) interacts with users through natural\nlanguage to understand their preferences and provide personalized\nrecommendations in real-time. CRS has demonstrated significant potential,\nprompting researchers to address the development of more realistic and reliable\nuser simulators as a key focus. Recently, the capabilities of Large Language\nModels (LLMs) have attracted a lot of attention in various fields.\nSimultaneously, efforts are underway to construct user simulators based on\nLLMs. While these works showcase innovation, they also come with certain\nlimitations that require attention. In this work, we aim to analyze the\nlimitations of using LLMs in constructing user simulators for CRS, to guide\nfuture research. To achieve this goal, we conduct analytical validation on the\nnotable work, iEvaLM. Through multiple experiments on two widely-used datasets\nin the field of conversational recommendation, we highlight several issues with\nthe current evaluation methods for user simulators based on LLMs: (1) Data\nleakage, which occurs in conversational history and the user simulator's\nreplies, results in inflated evaluation results. (2) The success of CRS\nrecommendations depends more on the availability and quality of conversational\nhistory than on the responses from user simulators. (3) Controlling the output\nof the user simulator through a single prompt template proves challenging. To\novercome these limitations, we propose SimpleUserSim, employing a\nstraightforward strategy to guide the topic toward the target items. Our study\nvalidates the ability of CRS models to utilize the interaction information,\nsignificantly improving the recommendation results.",
      "tldr_zh": "本研究分析了基于 Large Language Models (LLMs) 的用户模拟器在 Conversational Recommender System (CRS) 中的可靠性问题，通过实验验证了著名框架 iEvaLM 的局限性，包括数据泄露导致评估结果夸大、CRS 成功更依赖对话历史而非模拟器响应，以及单提示模板难以控制输出。研究者在两个常用数据集上进行多实验，揭示了这些问题如何影响模拟器的性能。为解决这些局限，作者提出了 SimpleUserSim，一种简单策略引导话题向目标物品的框架，并证明其显著提升了 CRS 模型利用交互信息的能力，从而改善推荐结果。",
      "categories": [
        "cs.AI"
      ],
      "primary_category": "cs.AI",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16416v1",
      "published_date": "2024-03-25 04:21:06 UTC",
      "updated_date": "2024-03-25 04:21:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:51:13.629004"
    },
    {
      "arxiv_id": "2403.16398v1",
      "title": "Rethinking the Representation in Federated Unsupervised Learning with Non-IID Data",
      "title_zh": "翻译失败",
      "authors": [
        "Xinting Liao",
        "Weiming Liu",
        "Chaochao Chen",
        "Pengyang Zhou",
        "Fengyuan Yu",
        "Huabin Zhu",
        "Binhui Yao",
        "Tao Wang",
        "Xiaolin Zheng",
        "Yanchao Tan"
      ],
      "abstract": "Federated learning achieves effective performance in modeling decentralized\ndata. In practice, client data are not well-labeled, which makes it potential\nfor federated unsupervised learning (FUSL) with non-IID data. However, the\nperformance of existing FUSL methods suffers from insufficient representations,\ni.e., (1) representation collapse entanglement among local and global models,\nand (2) inconsistent representation spaces among local models. The former\nindicates that representation collapse in local model will subsequently impact\nthe global model and other local models. The latter means that clients model\ndata representation with inconsistent parameters due to the deficiency of\nsupervision signals. In this work, we propose FedU2 which enhances generating\nuniform and unified representation in FUSL with non-IID data. Specifically,\nFedU2 consists of flexible uniform regularizer (FUR) and efficient unified\naggregator (EUA). FUR in each client avoids representation collapse via\ndispersing samples uniformly, and EUA in server promotes unified representation\nby constraining consistent client model updating. To extensively validate the\nperformance of FedU2, we conduct both cross-device and cross-silo evaluation\nexperiments on two benchmark datasets, i.e., CIFAR10 and CIFAR100.",
      "tldr_zh": "该论文重新审视了在非-IID 数据下的联邦无监督学习（FUSL）中表示（representation）的不足问题，包括本地和全局模型间的表示崩溃纠缠，以及客户端模型表示空间的不一致。\n作者提出 FedU2 方法，通过灵活均匀正则化器（FUR）在每个客户端均匀分散样本以避免表示崩溃，以及高效统一聚合器（EUA）在服务器端约束客户端模型更新以促进表示统一。\n实验在 CIFAR10 和 CIFAR100 数据集上进行了跨设备和跨分区评估，证明了 FedU2 在处理非-IID 数据时的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "CVPR 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16398v1",
      "published_date": "2024-03-25 03:26:01 UTC",
      "updated_date": "2024-03-25 03:26:01 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:51:28.283645"
    },
    {
      "arxiv_id": "2403.16397v2",
      "title": "RadioGAT: A Joint Model-based and Data-driven Framework for Multi-band Radiomap Reconstruction via Graph Attention Networks",
      "title_zh": "RadioGAT：一种基于模型",
      "authors": [
        "Xiaojie Li",
        "Songyang Zhang",
        "Hang Li",
        "Xiaoyang Li",
        "Lexi Xu",
        "Haigao Xu",
        "Hui Mei",
        "Guangxu Zhu",
        "Nan Qi",
        "Ming Xiao"
      ],
      "abstract": "Multi-band radiomap reconstruction (MB-RMR) is a key component in wireless\ncommunications for tasks such as spectrum management and network planning.\nHowever, traditional machine-learning-based MB-RMR methods, which rely heavily\non simulated data or complete structured ground truth, face significant\ndeployment challenges. These challenges stem from the differences between\nsimulated and actual data, as well as the scarcity of real-world measurements.\nTo address these challenges, our study presents RadioGAT, a novel framework\nbased on Graph Attention Network (GAT) tailored for MB-RMR within a single\narea, eliminating the need for multi-region datasets. RadioGAT innovatively\nmerges model-based spatial-spectral correlation encoding with data-driven\nradiomap generalization, thus minimizing the reliance on extensive data\nsources. The framework begins by transforming sparse multi-band data into a\ngraph structure through an innovative encoding strategy that leverages radio\npropagation models to capture the spatial-spectral correlation inherent in the\ndata. This graph-based representation not only simplifies data handling but\nalso enables tailored label sampling during training, significantly enhancing\nthe framework's adaptability for deployment. Subsequently, The GAT is employed\nto generalize the radiomap information across various frequency bands.\nExtensive experiments using raytracing datasets based on real-world\nenvironments have demonstrated RadioGAT's enhanced accuracy in supervised\nlearning settings and its robustness in semi-supervised scenarios. These\nresults underscore RadioGAT's effectiveness and practicality for MB-RMR in\nenvironments with limited data availability.",
      "tldr_zh": "本文提出 RadioGAT 框架，这是一种结合模型驱动和数据驱动的创新方法，用于 Multi-band radiomap reconstruction (MB-RMR)，旨在解决无线通信中数据稀缺和模拟与实际差异的部署挑战。RadioGAT 通过无线传播模型将稀疏的多频带数据转化为图结构，捕获空谱相关性，并利用 Graph Attention Network (GAT) 进行辐射图信息的泛化，从而减少对大规模数据集的依赖。实验在基于真实环境的 raytracing 数据集上证明，该框架在监督和半监督场景中显著提高了准确性和鲁棒性，为数据有限的环境提供实用解决方案。",
      "categories": [
        "eess.SP",
        "cs.AI"
      ],
      "primary_category": "eess.SP",
      "comment": "IEEE Transactions on Wireless Communications, early access, 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16397v2",
      "published_date": "2024-03-25 03:23:10 UTC",
      "updated_date": "2024-07-29 12:18:15 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:51:38.374106"
    },
    {
      "arxiv_id": "2404.00044v2",
      "title": "UAlign: Pushing the Limit of Template-free Retrosynthesis Prediction with Unsupervised SMILES Alignment",
      "title_zh": "UAlign：通过无监督 SMILES 对齐推动无模板逆合成预测的极限",
      "authors": [
        "Kaipeng Zeng",
        "Bo yang",
        "Xin Zhao",
        "Yu Zhang",
        "Fan Nie",
        "Xiaokang Yang",
        "Yaohui Jin",
        "Yanyan Xu"
      ],
      "abstract": "Motivation: Retrosynthesis planning poses a formidable challenge in the\norganic chemical industry. Single-step retrosynthesis prediction, a crucial\nstep in the planning process, has witnessed a surge in interest in recent years\ndue to advancements in AI for science. Various deep learning-based methods have\nbeen proposed for this task in recent years, incorporating diverse levels of\nadditional chemical knowledge dependency.\n  Results: This paper introduces UAlign, a template-free graph-to-sequence\npipeline for retrosynthesis prediction. By combining graph neural networks and\nTransformers, our method can more effectively leverage the inherent graph\nstructure of molecules. Based on the fact that the majority of molecule\nstructures remain unchanged during a chemical reaction, we propose a simple yet\neffective SMILES alignment technique to facilitate the reuse of unchanged\nstructures for reactant generation. Extensive experiments show that our method\nsubstantially outperforms state-of-the-art template-free and\nsemi-template-based approaches. Importantly, our template-free method achieves\neffectiveness comparable to, or even surpasses, established powerful\ntemplate-based methods.\n  Scientific contribution: We present a novel graph-to-sequence template-free\nretrosynthesis prediction pipeline that overcomes the limitations of\nTransformer-based methods in molecular representation learning and insufficient\nutilization of chemical information. We propose an unsupervised learning\nmechanism for establishing product-atom correspondence with reactant SMILES\ntokens, achieving even better results than supervised SMILES alignment methods.\nExtensive experiments demonstrate that UAlign significantly outperforms\nstate-of-the-art template-free methods and rivals or surpasses template-based\napproaches, with up to 5\\% (top-5) and 5.4\\% (top-10) increased accuracy over\nthe strongest baseline.",
      "tldr_zh": "这篇论文引入了 UAlign，一种无模板的图到序列管道，用于单步回顾合成预测，通过结合 graph neural networks 和 Transformers 来更有效地利用分子图结构。核心创新是提出一种无监督 SMILES alignment 技术，利用化学反应中不变的分子部分来辅助生成反应物，从而提升模型的准确性和效率。实验结果显示，UAlign 显著超过了现有无模板和半模板方法，并在 top-5 和 top-10 准确率上分别提高了 5% 和 5.4%，甚至与模板-based 方法相当或更优。",
      "categories": [
        "physics.chem-ph",
        "cs.AI",
        "cs.LG",
        "q-bio.QM"
      ],
      "primary_category": "physics.chem-ph",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2404.00044v2",
      "published_date": "2024-03-25 03:23:03 UTC",
      "updated_date": "2024-04-19 09:52:52 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:51:50.540846"
    },
    {
      "arxiv_id": "2403.16393v1",
      "title": "Concurrent Linguistic Error Detection (CLED) for Large Language Models",
      "title_zh": "翻译失败",
      "authors": [
        "Jinhua Zhu",
        "Javier Conde",
        "Zhen Gao",
        "Pedro Reviriego",
        "Shanshan Liu",
        "Fabrizio Lombardi"
      ],
      "abstract": "The wide adoption of Large language models (LLMs) makes their dependability a\npressing concern. Detection of errors is the first step to mitigating their\nimpact on a system and thus, efficient error detection for LLMs is an important\nissue. In many settings, the LLM is considered as a black box with no access to\nthe internal nodes; this prevents the use of many error detection schemes that\nneed access to the model's internal nodes. An interesting observation is that\nthe output of LLMs in error-free operation should be valid and normal text.\nTherefore, when the text is not valid or differs significantly from normal\ntext, it is likely that there is an error. Based on this observation we propose\nto perform Concurrent Linguistic Error Detection (CLED); this scheme extracts\nsome linguistic features of the text generated by the LLM and feeds them to a\nconcurrent classifier that detects errors. Since the proposed error detection\nmechanism only relies on the outputs of the model, then it can be used on LLMs\nin which there is no access to the internal nodes. The proposed CLED scheme has\nbeen evaluated on the T5 model when used for news summarization and on the\nOPUS-MT model when used for translation. In both cases, the same set of\nlinguistic features has been used for error detection to illustrate the\napplicability of the proposed scheme beyond a specific case. The results show\nthat CLED can detect most of the errors at a low overhead penalty. The use of\nthe concurrent classifier also enables a trade-off between error detection\neffectiveness and its associated overhead, so providing flexibility to a\ndesigner.",
      "tldr_zh": "本研究提出了一种Concurrent Linguistic Error Detection (CLED)方法，用于检测Large Language Models (LLMs)的错误，以提升其可靠性和可用性。CLED基于观察，即错误输出通常表现为无效或异常文本，通过提取文本的语言特征并使用一个并发分类器进行实时检测，而无需访问模型的内部节点。在T5模型用于新闻摘要和OPUS-MT模型用于翻译的实验中，CLED成功检测了大多数错误，同时保持低开销，并允许设计师在检测效果和性能开销之间进行灵活权衡。",
      "categories": [
        "cs.AI",
        "cs.CL",
        "cs.LG"
      ],
      "primary_category": "cs.AI",
      "comment": "11 pages, 6 figures, 30 references",
      "pdf_url": "http://arxiv.org/pdf/2403.16393v1",
      "published_date": "2024-03-25 03:17:27 UTC",
      "updated_date": "2024-03-25 03:17:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:52:04.101730"
    },
    {
      "arxiv_id": "2403.16386v1",
      "title": "Dia-LLaMA: Towards Large Language Model-driven CT Report Generation",
      "title_zh": "翻译失败",
      "authors": [
        "Zhixuan Chen",
        "Luyang Luo",
        "Yequan Bie",
        "Hao Chen"
      ],
      "abstract": "Medical report generation has achieved remarkable advancements yet has still\nbeen faced with several challenges. First, the inherent imbalance in the\ndistribution of normal and abnormal cases may lead models to exhibit a biased\nfocus on normal samples, resulting in unreliable diagnoses. Second, the\nfrequent occurrence of common template sentences in the reports may overwhelm\nthe critical abnormal information. Moreover, existing works focus on 2D chest\nX-rays, leaving CT report generation underexplored due to the high-dimensional\nnature of CT images and the limited availability of CT-report pairs. Recently,\nLLM has shown a great ability to generate reliable answers with appropriate\nprompts, which shed light on addressing the aforementioned challenges. In this\npaper, we propose Dia-LLaMA, a framework to adapt the LLaMA2-7B for CT report\ngeneration by incorporating diagnostic information as guidance prompts.\nConsidering the high dimension of CT, we leverage a pre-trained ViT3D with\nperceiver to extract the visual information. To tailor the LLM for report\ngeneration and emphasize abnormality, we extract additional diagnostic\ninformation by referring to a disease prototype memory bank, which is updated\nduring training to capture common disease representations. Furthermore, we\nintroduce disease-aware attention to enable the model to adjust attention for\ndifferent diseases. Experiments on the chest CT dataset demonstrated that our\nproposed method outperformed previous methods and achieved state-of-the-art on\nboth clinical efficacy performance and natural language generation metrics. The\ncode will be made publically available.",
      "tldr_zh": "本论文提出 Dia-LLaMA 框架，利用 LLaMA2-7B 驱动 CT 报告生成，以解决医疗报告中的样本分布不平衡、模板句干扰和异常信息突出等问题。框架通过预训练的 ViT3D 和 Perceiver 提取 CT 图像的高维视觉信息，并引入疾病原型记忆银行（disease prototype memory bank）和疾病感知注意力（disease-aware attention）来强化诊断指导和异常强调。实验在胸部 CT 数据集上表明，Dia-LLaMA 优于现有方法，在临床效能和自然语言生成指标上达到了最先进水平。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "10 pages",
      "pdf_url": "http://arxiv.org/pdf/2403.16386v1",
      "published_date": "2024-03-25 03:02:51 UTC",
      "updated_date": "2024-03-25 03:02:51 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:52:18.289869"
    },
    {
      "arxiv_id": "2404.08656v1",
      "title": "Linear Cross-document Event Coreference Resolution with X-AMR",
      "title_zh": "翻译失败",
      "authors": [
        "Shafiuddin Rehan Ahmed",
        "George Arthur Baker",
        "Evi Judge",
        "Michael Regan",
        "Kristin Wright-Bettner",
        "Martha Palmer",
        "James H. Martin"
      ],
      "abstract": "Event Coreference Resolution (ECR) as a pairwise mention classification task\nis expensive both for automated systems and manual annotations. The task's\nquadratic difficulty is exacerbated when using Large Language Models (LLMs),\nmaking prompt engineering for ECR prohibitively costly. In this work, we\npropose a graphical representation of events, X-AMR, anchored around individual\nmentions using a \\textbf{cross}-document version of \\textbf{A}bstract\n\\textbf{M}eaning \\textbf{R}epresentation. We then linearize the ECR with a\nnovel multi-hop coreference algorithm over the event graphs. The event graphs\nsimplify ECR, making it a) LLM cost-effective, b) compositional and\ninterpretable, and c) easily annotated. For a fair assessment, we first enrich\nan existing ECR benchmark dataset with these event graphs using an\nannotator-friendly tool we introduce. Then, we employ GPT-4, the newest LLM by\nOpenAI, for these annotations. Finally, using the ECR algorithm, we assess\nGPT-4 against humans and analyze its limitations. Through this research, we aim\nto advance the state-of-the-art for efficient ECR and shed light on the\npotential shortcomings of current LLMs at this task. Code and annotations:\n\\url{https://github.com/ahmeshaf/gpt_coref}",
      "tldr_zh": "该论文针对事件共指解析 (ECR) 的高成本问题，提出了一种基于 X-AMR（跨文档抽象含义表示）的图形表示方法，并通过一个新的多跳共指算法线性化 ECR 处理。相比传统方法，该框架使 ECR 更具 LLM（Large Language Models）成本效益、可组合性、可解释性和易标注性。研究者使用一个标注友好工具增强了现有 ECR 基准数据集，并通过 GPT-4 进行标注，随后评估其与人类表现的差异，揭示了当前 LLMs 的潜在局限性，从而推进了高效 ECR 的研究进展。",
      "categories": [
        "cs.CL",
        "cs.AI"
      ],
      "primary_category": "cs.CL",
      "comment": "LREC-COLING 2024 main conference",
      "pdf_url": "http://arxiv.org/pdf/2404.08656v1",
      "published_date": "2024-03-25 02:49:06 UTC",
      "updated_date": "2024-03-25 02:49:06 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:52:31.519018"
    },
    {
      "arxiv_id": "2406.11844v1",
      "title": "Prompting the E-Brushes: Users as Authors in Generative AI",
      "title_zh": "翻译失败",
      "authors": [
        "Yiyang Mei"
      ],
      "abstract": "Since its introduction in 2022, Generative AI has significantly impacted the\nart world, from winning state art fairs to creating complex videos from simple\nprompts. Amid this renaissance, a pivotal issue emerges: should users of\nGenerative AI be recognized as authors eligible for copyright protection? The\nCopyright Office, in its March 2023 Guidance, argues against this notion. By\ncomparing the prompts to clients' instructions for commissioned art, the Office\ndenies users authorship due to their limited role in the creative process. This\nArticle challenges this viewpoint and advocates for the recognition of\nGenerative AI users who incorporate these tools into their creative endeavors.\nIt argues that the current policy fails to consider the intricate and dynamic\ninteraction between Generative AI users and the models, where users actively\ninfluence the output through a process of adjustment, refinement, selection,\nand arrangement. Rather than dismissing the contributions generated by AI, this\nArticle suggests a simplified and streamlined registration process that\nacknowledges the role of AI in creation. This approach not only aligns with the\nconstitutional goal of promoting the progress of science and useful arts but\nalso encourages public engagement in the creative process, which contributes to\nthe pool of training data for AI. Moreover, it advocates for a flexible\nframework that evolves alongside technological advancements while ensuring\nsafety and public interest. In conclusion, by examining text-to-image\ngenerators and addressing misconceptions about Generative AI and user\ninteraction, this Article calls for a regulatory framework that adapts to\ntechnological developments and safeguards public interests",
      "tldr_zh": "本文探讨了生成式 AI 用户在艺术创作中的作者身份问题，挑战版权办公室的观点，该观点将用户提示比作委托艺术的指令，从而否认用户作者资格。论文强调用户通过调整、精炼、选择和安排等动态互动，积极影响 AI 输出，主张应承认这些贡献。作者建议简化 AI 辅助创作的版权注册过程，以促进创新、鼓励公众参与，并呼吁一个灵活的监管框架来适应技术发展和保护公共利益。",
      "categories": [
        "cs.CY",
        "cs.AI"
      ],
      "primary_category": "cs.CY",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2406.11844v1",
      "published_date": "2024-03-25 02:20:14 UTC",
      "updated_date": "2024-03-25 02:20:14 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:52:41.031913"
    },
    {
      "arxiv_id": "2403.16369v3",
      "title": "Learning Action-based Representations Using Invariance",
      "title_zh": "利用不变性学习基于动作的表示",
      "authors": [
        "Max Rudolph",
        "Caleb Chuck",
        "Kevin Black",
        "Misha Lvovsky",
        "Scott Niekum",
        "Amy Zhang"
      ],
      "abstract": "Robust reinforcement learning agents using high-dimensional observations must\nbe able to identify relevant state features amidst many exogeneous distractors.\nA representation that captures controllability identifies these state elements\nby determining what affects agent control. While methods such as inverse\ndynamics and mutual information capture controllability for a limited number of\ntimesteps, capturing long-horizon elements remains a challenging problem.\nMyopic controllability can capture the moment right before an agent crashes\ninto a wall, but not the control-relevance of the wall while the agent is still\nsome distance away. To address this we introduce action-bisimulation encoding,\na method inspired by the bisimulation invariance pseudometric, that extends\nsingle-step controllability with a recursive invariance constraint. By doing\nthis, action-bisimulation learns a multi-step controllability metric that\nsmoothly discounts distant state features that are relevant for control. We\ndemonstrate that action-bisimulation pretraining on reward-free, uniformly\nrandom data improves sample efficiency in several environments, including a\nphotorealistic 3D simulation domain, Habitat. Additionally, we provide\ntheoretical analysis and qualitative results demonstrating the information\ncaptured by action-bisimulation.",
      "tldr_zh": "本文针对强化学习(reinforcement learning)代理在高维观察中识别可控状态特征的问题，提出 action-bisimulation encoding 方法。该方法基于 bisimulation invariance pseudometric，通过递归不变性约束扩展单步可控性到多步可控性度量，从而平滑折扣远处但对控制相关的状态特征。实验显示，在无奖励的均匀随机数据上预训练后，该方法显著提高了多个环境（如 Habitat）的样本效率。论文还提供了理论分析和定性结果，证明了 action-bisimulation 在捕捉长时段可控信息方面的有效性。",
      "categories": [
        "cs.LG",
        "cs.AI",
        "stat.ML"
      ],
      "primary_category": "cs.LG",
      "comment": "Published at the Reinforcement Learning Conference 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16369v3",
      "published_date": "2024-03-25 02:17:54 UTC",
      "updated_date": "2024-06-24 13:19:17 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:52:53.607491"
    },
    {
      "arxiv_id": "2403.16354v4",
      "title": "ChatDBG: Augmenting Debugging with Large Language Models",
      "title_zh": "ChatDBG：利用大语言模型增强调试",
      "authors": [
        "Kyla H. Levin",
        "Nicolas van Kempen",
        "Emery D. Berger",
        "Stephen N. Freund"
      ],
      "abstract": "Debugging is a critical but challenging task for programmers. This paper\nproposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large\nlanguage models (LLMs) to significantly enhance the capabilities and\nuser-friendliness of conventional debuggers. ChatDBG lets programmers engage in\na collaborative dialogue with the debugger, allowing them to pose complex\nquestions about program state, perform root cause analysis for crashes or\nassertion failures, and explore open-ended queries like \"why is x null?\". To\nhandle these queries, ChatDBG grants the LLM autonomy to \"take the wheel\": it\ncan act as an independent agent capable of querying and controlling the\ndebugger to navigate through stacks and inspect program state. It then reports\nits findings and yields back control to the programmer. By leveraging the\nreal-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable\nonly through the use of domain-specific reasoning. Our ChatDBG prototype\nintegrates with standard debuggers including LLDB and GDB for native code and\nPdb for Python. Our evaluation across a diverse set of code, including C/C++\ncode with known bugs and a suite of Python code including standalone scripts\nand Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root\ncauses, explain bugs, and generate accurate fixes for a wide range of\nreal-world errors. For the Python programs, a single query led to an actionable\nbug fix 67% of the time; one additional follow-up query increased the success\nrate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more\nthan 75,000 times.",
      "tldr_zh": "这篇论文介绍了 ChatDBG，一种利用 Large Language Models (LLMs) 增强编程调试过程的 AI 助手。ChatDBG 通过对话式交互允许程序员提出复杂查询，如程序状态分析和 root cause analysis，并赋予 LLMs 自主控制调试器（例如查询栈和检查状态）的能力，以诊断领域特定问题。实验结果显示，在 C/C++ 和 Python 代码上，ChatDBG 成功分析根因、解释错误并生成修复方案，Python 程序的单次查询修复成功率达 67%，后续查询后提升至 85%，并已获得超过 75,000 次下载。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG",
        "cs.PL"
      ],
      "primary_category": "cs.SE",
      "comment": "22 pages, to appear at FSE 2025",
      "pdf_url": "http://arxiv.org/pdf/2403.16354v4",
      "published_date": "2024-03-25 01:12:57 UTC",
      "updated_date": "2025-04-23 15:48:42 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:53:07.146683"
    },
    {
      "arxiv_id": "2403.16347v1",
      "title": "ChatGPT Incorrectness Detection in Software Reviews",
      "title_zh": "翻译失败",
      "authors": [
        "Minaoar Hossain Tanzil",
        "Junaed Younus Khan",
        "Gias Uddin"
      ],
      "abstract": "We conducted a survey of 135 software engineering (SE) practitioners to\nunderstand how they use Generative AI-based chatbots like ChatGPT for SE tasks.\nWe find that they want to use ChatGPT for SE tasks like software library\nselection but often worry about the truthfulness of ChatGPT responses. We\ndeveloped a suite of techniques and a tool called CID (ChatGPT Incorrectness\nDetector) to automatically test and detect the incorrectness in ChatGPT\nresponses. CID is based on the iterative prompting to ChatGPT by asking it\ncontextually similar but textually divergent questions (using an approach that\nutilizes metamorphic relationships in texts). The underlying principle in CID\nis that for a given question, a response that is different from other responses\n(across multiple incarnations of the question) is likely an incorrect response.\nIn a benchmark study of library selection, we show that CID can detect\nincorrect responses from ChatGPT with an F1-score of 0.74 - 0.75.",
      "tldr_zh": "这篇论文调查了135名软件工程从业者使用ChatGPT等生成式AI进行任务（如软件库选择）时的担忧，特别是对响应真实性的疑虑。研究团队开发了CID（ChatGPT Incorrectness Detector）工具，该工具通过迭代提示和利用metamorphic relationships生成上下文相似但文本不同的提问，来检测ChatGPT响应的不正确性，其原理是比较多个变体响应以识别异常。实验结果显示，在软件库选择的基准测试中，CID的F1-score达到0.74-0.75，证明了其有效性。",
      "categories": [
        "cs.SE",
        "cs.AI",
        "cs.LG"
      ],
      "primary_category": "cs.SE",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16347v1",
      "published_date": "2024-03-25 00:50:27 UTC",
      "updated_date": "2024-03-25 00:50:27 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:53:18.108761"
    },
    {
      "arxiv_id": "2403.16345v1",
      "title": "Enhanced Facet Generation with LLM Editing",
      "title_zh": "利用 LLM 编辑增强的分",
      "authors": [
        "Joosung Lee",
        "Jinhong Kim"
      ],
      "abstract": "In information retrieval, facet identification of a user query is an\nimportant task. If a search service can recognize the facets of a user's query,\nit has the potential to offer users a much broader range of search results.\nPrevious studies can enhance facet prediction by leveraging retrieved documents\nand related queries obtained through a search engine. However, there are\nchallenges in extending it to other applications when a search engine operates\nas part of the model. First, search engines are constantly updated. Therefore,\nadditional information may change during training and test, which may reduce\nperformance. The second challenge is that public search engines cannot search\nfor internal documents. Therefore, a separate search system needs to be built\nto incorporate documents from private domains within the company. We propose\ntwo strategies that focus on a framework that can predict facets by taking only\nqueries as input without a search engine. The first strategy is multi-task\nlearning to predict SERP. By leveraging SERP as a target instead of a source,\nthe proposed model deeply understands queries without relying on external\nmodules. The second strategy is to enhance the facets by combining Large\nLanguage Model (LLM) and the small model. Overall performance improves when\nsmall model and LLM are combined rather than facet generation individually.",
      "tldr_zh": "这篇论文针对信息检索中的facet识别问题，提出两种不依赖搜索引擎的策略，以提升查询理解和facet生成性能。第一策略采用多任务学习预测SERP（Search Engine Results Page），让模型更深入地分析查询。第二策略结合Large Language Model (LLM)和小型模型进行facet增强，实验结果显示这种结合方式比单独生成facet的性能更优整体上改善了facet预测的准确性和适用性。",
      "categories": [
        "cs.CL",
        "cs.AI",
        "cs.IR"
      ],
      "primary_category": "cs.CL",
      "comment": "Accepted at LREC-COLING 2024",
      "pdf_url": "http://arxiv.org/pdf/2403.16345v1",
      "published_date": "2024-03-25 00:43:44 UTC",
      "updated_date": "2024-03-25 00:43:44 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:53:28.115931"
    },
    {
      "arxiv_id": "2403.16338v1",
      "title": "Impact of Video Compression Artifacts on Fisheye Camera Visual Perception Tasks",
      "title_zh": "视频压缩伪影对鱼眼相机视觉感知任务的影响",
      "authors": [
        "Madhumitha Sakthi",
        "Louis Kerofsky",
        "Varun Ravi Kumar",
        "Senthil Yogamani"
      ],
      "abstract": "Autonomous driving systems require extensive data collection schemes to cover\nthe diverse scenarios needed for building a robust and safe system. The data\nvolumes are in the order of Exabytes and have to be stored for a long period of\ntime (i.e., more than 10 years of the vehicle's life cycle). Lossless\ncompression doesn't provide sufficient compression ratios, hence, lossy video\ncompression has been explored. It is essential to prove that lossy video\ncompression artifacts do not impact the performance of the perception\nalgorithms. However, there is limited work in this area to provide a solid\nconclusion. In particular, there is no such work for fisheye cameras, which\nhave high radial distortion and where compression may have higher artifacts.\nFisheye cameras are commonly used in automotive systems for 3D object detection\ntask. In this work, we provide the first analysis of the impact of standard\nvideo compression codecs on wide FOV fisheye camera images. We demonstrate that\nthe achievable compression with negligible impact depends on the dataset and\ntemporal prediction of the video codec. We propose a radial distortion-aware\nzonal metric to evaluate the performance of artifacts in fisheye images. In\naddition, we present a novel method for estimating affine mode parameters of\nthe latest VVC codec, and suggest some areas for improvement in video codecs\nfor the application to fisheye imagery.",
      "tldr_zh": "这篇论文探讨了视频压缩伪影对鱼眼相机视觉感知任务的影响，特别是自动驾驶系统中用于3D物体检测的鱼眼图像，由于其高径向畸变可能放大压缩伪影。研究首次分析了标准视频压缩编解码器（如VVC）对宽视场鱼眼图像的影响，发现可实现的压缩率取决于数据集和编解码器的时域预测，而这些伪影对感知算法性能的影响有限但需注意。作者提出了一种径向畸变感知的区域度量来评估鱼眼图像中的伪影性能，并开发了一种新方法来估计VVC编解码器的仿射模式参数，以优化压缩效果。最后，论文建议了针对鱼眼图像的视频编解码器改进方向，以支持长期数据存储和安全自动驾驶系统。",
      "categories": [
        "cs.CV",
        "cs.AI"
      ],
      "primary_category": "cs.CV",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16338v1",
      "published_date": "2024-03-25 00:24:10 UTC",
      "updated_date": "2024-03-25 00:24:10 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:53:43.326241"
    },
    {
      "arxiv_id": "2403.16334v1",
      "title": "Graphs Generalization under Distribution Shifts",
      "title_zh": "翻译失败",
      "authors": [
        "Qin Tian",
        "Wenjun Wang",
        "Chen Zhao",
        "Minglai Shao",
        "Wang Zhang",
        "Dong Li"
      ],
      "abstract": "Traditional machine learning methods heavily rely on the independent and\nidentically distribution assumption, which imposes limitations when the test\ndistribution deviates from the training distribution. To address this crucial\nissue, out-of-distribution (OOD) generalization, which aims to achieve\nsatisfactory generalization performance when faced with unknown distribution\nshifts, has made a significant process. However, the OOD method for\ngraph-structured data currently lacks clarity and remains relatively unexplored\ndue to two primary challenges. Firstly, distribution shifts on graphs often\noccur simultaneously on node attributes and graph topology. Secondly, capturing\ninvariant information amidst diverse distribution shifts proves to be a\nformidable challenge. To overcome these obstacles, in this paper, we introduce\na novel framework, namely Graph Learning Invariant Domain genERation (GLIDER).\nThe goal is to (1) diversify variations across domains by modeling the\npotential seen or unseen variations of attribute distribution and topological\nstructure and (2) minimize the discrepancy of the variation in a representation\nspace where the target is to predict semantic labels. Extensive experiment\nresults indicate that our model outperforms baseline methods on node-level OOD\ngeneralization across domains in distribution shift on node features and\ntopological structures simultaneously.",
      "tldr_zh": "传统机器学习依赖独立同分布假设，但当测试分布偏移时，尤其在图结构数据上，节点属性和拓扑结构同时变化会带来挑战。论文提出了一种新框架GLIDER（Graph Learning Invariant Domain genERation），通过建模属性分布和拓扑结构的潜在变化来多样化域间差异，并最小化表示空间中的变化差异，以提升Out-of-Distribution (OOD)泛化性能。实验结果显示，GLIDER在节点级OOD泛化任务中优于基线方法，特别是在节点特征和拓扑结构同时发生分布偏移的场景下。",
      "categories": [
        "cs.LG",
        "cs.AI"
      ],
      "primary_category": "cs.LG",
      "comment": "",
      "pdf_url": "http://arxiv.org/pdf/2403.16334v1",
      "published_date": "2024-03-25 00:15:34 UTC",
      "updated_date": "2024-03-25 00:15:34 UTC",
      "processing_status": "completed",
      "attempts": 0,
      "max_attempts": 3,
      "error": null,
      "completed_steps": [
        "translation",
        "tldr"
      ],
      "last_update": "2025-05-17T18:53:53.104963"
    }
  ],
  "raw_papers_fetched": true,
  "papers_count": 120,
  "processed_papers_count": 120,
  "failed_papers_count": 0,
  "summary_generated": true,
  "daily_data_saved": true,
  "last_update": "2025-05-17T18:54:26.201176"
}